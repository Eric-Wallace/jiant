09/16 12:22:32 PM: Git branch: master
09/16 12:22:32 PM: Git SHA: ce97551376ebcff91ec7c178ddad0ca53f8fcb03
09/16 12:22:33 PM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/pos-ontonotes-sts-only/",
  "exp_name": "experiments/pos-ontonotes-sts-only",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/pos-ontonotes-sts-only/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/sts",
  "pytorch_transformers_output_mode": "only",
  "remote_log_name": "experiments/pos-ontonotes-sts-only__run",
  "run_dir": "./experiments/pos-ontonotes-sts-only/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-pos-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 12:22:33 PM: Saved config to ./experiments/pos-ontonotes-sts-only/run/params.conf
09/16 12:22:33 PM: Using random seed 1234
09/16 12:22:34 PM: Using GPU 0
09/16 12:22:34 PM: Loading tasks...
09/16 12:22:34 PM: Writing pre-preprocessed tasks to ./experiments/pos-ontonotes-sts-only/
09/16 12:22:34 PM: 	Creating task edges-pos-ontonotes from scratch.
09/16 12:22:58 PM: Read=110514, Skip=5298, Total=115812 from ./probing_data/edges/ontonotes/const/pos/train.json.retokenized.bert-base-uncased
09/16 12:22:59 PM: Read=15060, Skip=620, Total=15680 from ./probing_data/edges/ontonotes/const/pos/development.json.retokenized.bert-base-uncased
09/16 12:23:04 PM: Read=11462, Skip=755, Total=12217 from ./probing_data/edges/ontonotes/const/pos/test.json.retokenized.bert-base-uncased
09/16 12:23:18 PM: 	Task 'edges-pos-ontonotes': |train|=110514 |val|=15060 |test|=11462
09/16 12:23:18 PM: 	Finished loading tasks: edges-pos-ontonotes.
09/16 12:23:18 PM: 	Building vocab from scratch.
09/16 12:23:18 PM: 	Counting units for task edges-pos-ontonotes.
09/16 12:23:20 PM: 	Task 'edges-pos-ontonotes': adding vocab namespace 'edges-pos-ontonotes_labels'
09/16 12:23:21 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:23:21 PM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 12:23:21 PM: 	Saved vocab to ./experiments/pos-ontonotes-sts-only/vocab
09/16 12:23:21 PM: Loading token dictionary from ./experiments/pos-ontonotes-sts-only/vocab.
09/16 12:23:21 PM: 	Loaded vocab from ./experiments/pos-ontonotes-sts-only/vocab
09/16 12:23:21 PM: 	Vocab namespace bert_uncased: size 30524
09/16 12:23:21 PM: 	Vocab namespace tokens: size 24015
09/16 12:23:21 PM: 	Vocab namespace edges-pos-ontonotes_labels: size 48
09/16 12:23:21 PM: 	Vocab namespace chars: size 81
09/16 12:23:21 PM: 	Finished building vocab.
09/16 12:23:21 PM: 	Task edges-pos-ontonotes (train): Indexing from scratch.
09/16 12:23:51 PM: 	Task edges-pos-ontonotes (train): Saved 110514 instances to ./experiments/pos-ontonotes-sts-only/preproc/edges-pos-ontonotes__train_data
09/16 12:23:51 PM: 	Task edges-pos-ontonotes (val): Indexing from scratch.
09/16 12:23:55 PM: 	Task edges-pos-ontonotes (val): Saved 15060 instances to ./experiments/pos-ontonotes-sts-only/preproc/edges-pos-ontonotes__val_data
09/16 12:23:55 PM: 	Task edges-pos-ontonotes (test): Indexing from scratch.
09/16 12:23:58 PM: 	Task edges-pos-ontonotes (test): Saved 11462 instances to ./experiments/pos-ontonotes-sts-only/preproc/edges-pos-ontonotes__test_data
09/16 12:23:58 PM: 	Finished indexing tasks
09/16 12:23:58 PM: 	Creating trimmed target-only version of edges-pos-ontonotes train.
09/16 12:23:58 PM: 	  Training on 
09/16 12:23:58 PM: 	  Evaluating on edges-pos-ontonotes
09/16 12:23:58 PM: 	Finished loading tasks in 84.581s
09/16 12:23:58 PM: 	 Tasks: ['edges-pos-ontonotes']
09/16 12:23:58 PM: Building model...
09/16 12:23:58 PM: Using BERT model (bert-base-uncased).
09/16 12:23:58 PM: LOADING A FUNETUNED MODEL from: 
09/16 12:23:58 PM: models/sts
09/16 12:23:58 PM: loading configuration file models/sts/config.json
09/16 12:23:58 PM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "sts-b",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 12:23:58 PM: loading weights file models/sts/pytorch_model.bin
09/16 12:24:01 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp86_yf4ib
09/16 12:24:03 PM: copying /tmp/tmp86_yf4ib to cache at ./experiments/pos-ontonotes-sts-only/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:24:03 PM: creating metadata file for ./experiments/pos-ontonotes-sts-only/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:24:03 PM: removing temp file /tmp/tmp86_yf4ib
09/16 12:24:03 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/pos-ontonotes-sts-only/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:24:03 PM: Initializing parameters
09/16 12:24:03 PM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 12:24:03 PM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 12:24:03 PM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 12:24:03 PM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 12:24:03 PM:    _text_field_embedder.model.pooler.dense.bias
09/16 12:24:03 PM:    _text_field_embedder.model.pooler.dense.weight
09/16 12:24:03 PM: 	Task 'edges-pos-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-pos-ontonotes"
}
09/16 12:24:08 PM: Model specification:
09/16 12:24:08 PM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-pos-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=48, bias=True)
    )
  )
)
09/16 12:24:08 PM: Model parameters:
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:08 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:08 PM: 	edges-pos-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 12:24:08 PM: 	edges-pos-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 12:24:08 PM: 	edges-pos-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 24576 with torch.Size([48, 512])
09/16 12:24:08 PM: 	edges-pos-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 48 with torch.Size([48])
09/16 12:24:08 PM: Total number of parameters: 109703728 (1.09704e+08)
09/16 12:24:08 PM: Number of trainable parameters: 221488 (221488)
09/16 12:24:08 PM: Finished building model in 9.501s
09/16 12:24:08 PM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-pos-ontonotes 

09/16 12:25:17 PM: patience = 9
09/16 12:25:17 PM: val_interval = 1000
09/16 12:25:17 PM: max_vals = 250
09/16 12:25:17 PM: cuda_device = 0
09/16 12:25:17 PM: grad_norm = 5.0
09/16 12:25:17 PM: grad_clipping = None
09/16 12:25:17 PM: lr_decay = 0.99
09/16 12:25:17 PM: min_lr = 1e-06
09/16 12:25:17 PM: keep_all_checkpoints = 0
09/16 12:25:17 PM: val_data_limit = 5000
09/16 12:25:17 PM: max_epochs = -1
09/16 12:25:17 PM: dec_val_scale = 250
09/16 12:25:17 PM: training_data_fraction = 1
09/16 12:25:17 PM: type = adam
09/16 12:25:17 PM: parameter_groups = None
09/16 12:25:17 PM: Number of trainable parameters: 221488
09/16 12:25:17 PM: infer_type_and_cast = True
09/16 12:25:17 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:25:17 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:25:17 PM: lr = 0.0001
09/16 12:25:17 PM: amsgrad = True
09/16 12:25:17 PM: type = reduce_on_plateau
09/16 12:25:17 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:25:17 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:25:17 PM: mode = max
09/16 12:25:17 PM: factor = 0.5
09/16 12:25:17 PM: patience = 3
09/16 12:25:17 PM: threshold = 0.0001
09/16 12:25:17 PM: threshold_mode = abs
09/16 12:25:17 PM: verbose = True
09/16 12:25:17 PM: type = adam
09/16 12:25:17 PM: parameter_groups = None
09/16 12:25:17 PM: Number of trainable parameters: 221488
09/16 12:25:17 PM: infer_type_and_cast = True
09/16 12:25:17 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:25:17 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:25:17 PM: lr = 0.0001
09/16 12:25:17 PM: amsgrad = True
09/16 12:25:17 PM: type = reduce_on_plateau
09/16 12:25:17 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:25:17 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:25:17 PM: mode = max
09/16 12:25:17 PM: factor = 0.5
09/16 12:25:17 PM: patience = 3
09/16 12:25:17 PM: threshold = 0.0001
09/16 12:25:17 PM: threshold_mode = abs
09/16 12:25:17 PM: verbose = True
09/16 12:25:17 PM: Starting training without restoring from a checkpoint.
09/16 12:25:17 PM: Training examples per task, before any subsampling: {'edges-pos-ontonotes': 110514}
09/16 12:25:17 PM: Beginning training with stopping criteria based on metric: edges-pos-ontonotes_f1
09/16 12:25:27 PM: Update 103: task edges-pos-ontonotes, batch 103 (103): mcc: 0.0670, acc: 0.0845, precision: 0.0465, recall: 0.2719, f1: 0.0794, edges-pos-ontonotes_loss: 0.3066
09/16 12:25:37 PM: Update 215: task edges-pos-ontonotes, batch 215 (215): mcc: 0.1224, acc: 0.1708, precision: 0.0901, recall: 0.2589, f1: 0.1337, edges-pos-ontonotes_loss: 0.1814
09/16 12:25:49 PM: Update 314: task edges-pos-ontonotes, batch 314 (314): mcc: 0.1827, acc: 0.2404, precision: 0.1418, recall: 0.3026, f1: 0.1931, edges-pos-ontonotes_loss: 0.1380
09/16 12:25:59 PM: Update 377: task edges-pos-ontonotes, batch 377 (377): mcc: 0.2337, acc: 0.2893, precision: 0.1909, recall: 0.3399, f1: 0.2445, edges-pos-ontonotes_loss: 0.1219
09/16 12:26:09 PM: Update 442: task edges-pos-ontonotes, batch 442 (442): mcc: 0.2766, acc: 0.3270, precision: 0.2347, recall: 0.3718, f1: 0.2878, edges-pos-ontonotes_loss: 0.1092
09/16 12:26:19 PM: Update 516: task edges-pos-ontonotes, batch 516 (516): mcc: 0.3274, acc: 0.3694, precision: 0.2889, recall: 0.4095, f1: 0.3388, edges-pos-ontonotes_loss: 0.0981
09/16 12:26:29 PM: Update 569: task edges-pos-ontonotes, batch 569 (569): mcc: 0.3591, acc: 0.3958, precision: 0.3235, recall: 0.4334, f1: 0.3705, edges-pos-ontonotes_loss: 0.0916
09/16 12:26:40 PM: Update 627: task edges-pos-ontonotes, batch 627 (627): mcc: 0.3893, acc: 0.4202, precision: 0.3573, recall: 0.4560, f1: 0.4006, edges-pos-ontonotes_loss: 0.0856
09/16 12:26:50 PM: Update 684: task edges-pos-ontonotes, batch 684 (684): mcc: 0.4247, acc: 0.4457, precision: 0.3990, recall: 0.4803, f1: 0.4359, edges-pos-ontonotes_loss: 0.0808
09/16 12:27:00 PM: Update 741: task edges-pos-ontonotes, batch 741 (741): mcc: 0.4543, acc: 0.4681, precision: 0.4339, recall: 0.5016, f1: 0.4653, edges-pos-ontonotes_loss: 0.0767
09/16 12:27:10 PM: Update 796: task edges-pos-ontonotes, batch 796 (796): mcc: 0.4758, acc: 0.4844, precision: 0.4591, recall: 0.5173, f1: 0.4865, edges-pos-ontonotes_loss: 0.0732
09/16 12:27:21 PM: Update 852: task edges-pos-ontonotes, batch 852 (852): mcc: 0.4964, acc: 0.5003, precision: 0.4832, recall: 0.5329, f1: 0.5068, edges-pos-ontonotes_loss: 0.0700
09/16 12:27:31 PM: Update 918: task edges-pos-ontonotes, batch 918 (918): mcc: 0.5219, acc: 0.5198, precision: 0.5128, recall: 0.5525, f1: 0.5319, edges-pos-ontonotes_loss: 0.0666
09/16 12:27:41 PM: Update 962: task edges-pos-ontonotes, batch 962 (962): mcc: 0.5355, acc: 0.5297, precision: 0.5291, recall: 0.5623, f1: 0.5452, edges-pos-ontonotes_loss: 0.0646
09/16 12:27:47 PM: ***** Step 1000 / Validation 1 *****
09/16 12:27:47 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:27:47 PM: Validating...
09/16 12:27:51 PM: Evaluate: task edges-pos-ontonotes, batch 43 (157): mcc: 0.8152, acc: 0.7411, precision: 0.8742, recall: 0.7669, f1: 0.8170, edges-pos-ontonotes_loss: 0.0200
09/16 12:28:01 PM: Evaluate: task edges-pos-ontonotes, batch 124 (157): mcc: 0.8269, acc: 0.7542, precision: 0.8851, recall: 0.7787, f1: 0.8285, edges-pos-ontonotes_loss: 0.0194
09/16 12:28:06 PM: Best result seen so far for edges-pos-ontonotes.
09/16 12:28:06 PM: Best result seen so far for micro.
09/16 12:28:06 PM: Best result seen so far for macro.
09/16 12:28:06 PM: Updating LR scheduler:
09/16 12:28:06 PM: 	Best result seen so far for macro_avg: 0.824
09/16 12:28:06 PM: 	# validation passes without improvement: 0
09/16 12:28:06 PM: edges-pos-ontonotes_loss: training: 0.063008 validation: 0.019732
09/16 12:28:06 PM: macro_avg: validation: 0.824443
09/16 12:28:06 PM: micro_avg: validation: 0.000000
09/16 12:28:06 PM: edges-pos-ontonotes_mcc: training: 0.547022 validation: 0.822935
09/16 12:28:06 PM: edges-pos-ontonotes_acc: training: 0.538215 validation: 0.748638
09/16 12:28:06 PM: edges-pos-ontonotes_precision: training: 0.543039 validation: 0.884388
09/16 12:28:06 PM: edges-pos-ontonotes_recall: training: 0.570690 validation: 0.772109
09/16 12:28:06 PM: edges-pos-ontonotes_f1: training: 0.556521 validation: 0.824443
09/16 12:28:06 PM: Global learning rate: 0.0001
09/16 12:28:06 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 12:28:11 PM: Update 1030: task edges-pos-ontonotes, batch 30 (1030): mcc: 0.8018, acc: 0.7082, precision: 0.8757, recall: 0.7410, f1: 0.8028, edges-pos-ontonotes_loss: 0.0229
09/16 12:28:21 PM: Update 1097: task edges-pos-ontonotes, batch 97 (1097): mcc: 0.8122, acc: 0.7231, precision: 0.8813, recall: 0.7551, f1: 0.8133, edges-pos-ontonotes_loss: 0.0222
09/16 12:28:31 PM: Update 1167: task edges-pos-ontonotes, batch 167 (1167): mcc: 0.8149, acc: 0.7276, precision: 0.8806, recall: 0.7606, f1: 0.8162, edges-pos-ontonotes_loss: 0.0215
09/16 12:28:41 PM: Update 1238: task edges-pos-ontonotes, batch 238 (1238): mcc: 0.8169, acc: 0.7312, precision: 0.8797, recall: 0.7651, f1: 0.8184, edges-pos-ontonotes_loss: 0.0212
09/16 12:28:57 PM: Update 1253: task edges-pos-ontonotes, batch 253 (1253): mcc: 0.8165, acc: 0.7313, precision: 0.8787, recall: 0.7653, f1: 0.8181, edges-pos-ontonotes_loss: 0.0212
09/16 12:29:07 PM: Update 1295: task edges-pos-ontonotes, batch 295 (1295): mcc: 0.8178, acc: 0.7333, precision: 0.8790, recall: 0.7674, f1: 0.8194, edges-pos-ontonotes_loss: 0.0209
09/16 12:29:17 PM: Update 1347: task edges-pos-ontonotes, batch 347 (1347): mcc: 0.8193, acc: 0.7359, precision: 0.8792, recall: 0.7701, f1: 0.8210, edges-pos-ontonotes_loss: 0.0207
09/16 12:29:27 PM: Update 1398: task edges-pos-ontonotes, batch 398 (1398): mcc: 0.8211, acc: 0.7387, precision: 0.8798, recall: 0.7728, f1: 0.8229, edges-pos-ontonotes_loss: 0.0205
09/16 12:29:37 PM: Update 1455: task edges-pos-ontonotes, batch 455 (1455): mcc: 0.8231, acc: 0.7418, precision: 0.8804, recall: 0.7760, f1: 0.8249, edges-pos-ontonotes_loss: 0.0203
09/16 12:29:47 PM: Update 1519: task edges-pos-ontonotes, batch 519 (1519): mcc: 0.8252, acc: 0.7452, precision: 0.8810, recall: 0.7793, f1: 0.8270, edges-pos-ontonotes_loss: 0.0201
09/16 12:29:58 PM: Update 1566: task edges-pos-ontonotes, batch 566 (1566): mcc: 0.8264, acc: 0.7472, precision: 0.8812, recall: 0.7813, f1: 0.8282, edges-pos-ontonotes_loss: 0.0199
09/16 12:30:08 PM: Update 1636: task edges-pos-ontonotes, batch 636 (1636): mcc: 0.8281, acc: 0.7499, precision: 0.8815, recall: 0.7842, f1: 0.8300, edges-pos-ontonotes_loss: 0.0197
09/16 12:30:18 PM: Update 1703: task edges-pos-ontonotes, batch 703 (1703): mcc: 0.8295, acc: 0.7520, precision: 0.8817, recall: 0.7866, f1: 0.8314, edges-pos-ontonotes_loss: 0.0195
09/16 12:30:28 PM: Update 1763: task edges-pos-ontonotes, batch 763 (1763): mcc: 0.8305, acc: 0.7539, precision: 0.8817, recall: 0.7886, f1: 0.8325, edges-pos-ontonotes_loss: 0.0193
09/16 12:30:38 PM: Update 1833: task edges-pos-ontonotes, batch 833 (1833): mcc: 0.8317, acc: 0.7558, precision: 0.8819, recall: 0.7905, f1: 0.8337, edges-pos-ontonotes_loss: 0.0191
09/16 12:30:48 PM: Update 1884: task edges-pos-ontonotes, batch 884 (1884): mcc: 0.8323, acc: 0.7570, precision: 0.8818, recall: 0.7919, f1: 0.8344, edges-pos-ontonotes_loss: 0.0190
09/16 12:30:59 PM: Update 1963: task edges-pos-ontonotes, batch 963 (1963): mcc: 0.8340, acc: 0.7594, precision: 0.8822, recall: 0.7946, f1: 0.8361, edges-pos-ontonotes_loss: 0.0187
09/16 12:31:03 PM: ***** Step 2000 / Validation 2 *****
09/16 12:31:03 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:31:03 PM: Validating...
09/16 12:31:09 PM: Evaluate: task edges-pos-ontonotes, batch 64 (157): mcc: 0.8340, acc: 0.7838, precision: 0.8800, recall: 0.7965, f1: 0.8362, edges-pos-ontonotes_loss: 0.0178
09/16 12:31:19 PM: Evaluate: task edges-pos-ontonotes, batch 133 (157): mcc: 0.8425, acc: 0.7928, precision: 0.8853, recall: 0.8077, f1: 0.8447, edges-pos-ontonotes_loss: 0.0167
09/16 12:31:23 PM: Best result seen so far for edges-pos-ontonotes.
09/16 12:31:23 PM: Best result seen so far for macro.
09/16 12:31:23 PM: Updating LR scheduler:
09/16 12:31:23 PM: 	Best result seen so far for macro_avg: 0.846
09/16 12:31:23 PM: 	# validation passes without improvement: 0
09/16 12:31:23 PM: edges-pos-ontonotes_loss: training: 0.018537 validation: 0.016542
09/16 12:31:23 PM: macro_avg: validation: 0.845798
09/16 12:31:23 PM: micro_avg: validation: 0.000000
09/16 12:31:23 PM: edges-pos-ontonotes_mcc: training: 0.834674 validation: 0.843615
09/16 12:31:23 PM: edges-pos-ontonotes_acc: training: 0.760315 validation: 0.793665
09/16 12:31:23 PM: edges-pos-ontonotes_precision: training: 0.882457 validation: 0.886880
09/16 12:31:23 PM: edges-pos-ontonotes_recall: training: 0.795633 validation: 0.808354
09/16 12:31:23 PM: edges-pos-ontonotes_f1: training: 0.836799 validation: 0.845798
09/16 12:31:23 PM: Global learning rate: 0.0001
09/16 12:31:23 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 12:31:29 PM: Update 2043: task edges-pos-ontonotes, batch 43 (2043): mcc: 0.8626, acc: 0.7960, precision: 0.8972, recall: 0.8345, f1: 0.8647, edges-pos-ontonotes_loss: 0.0143
09/16 12:31:39 PM: Update 2112: task edges-pos-ontonotes, batch 112 (2112): mcc: 0.8604, acc: 0.7950, precision: 0.8935, recall: 0.8340, f1: 0.8627, edges-pos-ontonotes_loss: 0.0141
09/16 12:31:50 PM: Update 2192: task edges-pos-ontonotes, batch 192 (2192): mcc: 0.8604, acc: 0.7956, precision: 0.8934, recall: 0.8340, f1: 0.8627, edges-pos-ontonotes_loss: 0.0139
09/16 12:32:00 PM: Update 2313: task edges-pos-ontonotes, batch 313 (2313): mcc: 0.8669, acc: 0.8045, precision: 0.8973, recall: 0.8428, f1: 0.8692, edges-pos-ontonotes_loss: 0.0131
09/16 12:32:10 PM: Update 2426: task edges-pos-ontonotes, batch 426 (2426): mcc: 0.8721, acc: 0.8116, precision: 0.9006, recall: 0.8496, f1: 0.8743, edges-pos-ontonotes_loss: 0.0126
09/16 12:32:20 PM: Update 2520: task edges-pos-ontonotes, batch 520 (2520): mcc: 0.8744, acc: 0.8150, precision: 0.9018, recall: 0.8527, f1: 0.8766, edges-pos-ontonotes_loss: 0.0125
09/16 12:32:30 PM: Update 2651: task edges-pos-ontonotes, batch 651 (2651): mcc: 0.8752, acc: 0.8162, precision: 0.9026, recall: 0.8535, f1: 0.8774, edges-pos-ontonotes_loss: 0.0126
09/16 12:32:40 PM: Update 2794: task edges-pos-ontonotes, batch 794 (2794): mcc: 0.8771, acc: 0.8194, precision: 0.9037, recall: 0.8561, f1: 0.8792, edges-pos-ontonotes_loss: 0.0124
09/16 12:32:50 PM: Update 2954: task edges-pos-ontonotes, batch 954 (2954): mcc: 0.8755, acc: 0.8185, precision: 0.9020, recall: 0.8547, f1: 0.8777, edges-pos-ontonotes_loss: 0.0125
09/16 12:32:53 PM: ***** Step 3000 / Validation 3 *****
09/16 12:32:53 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:32:53 PM: Validating...
09/16 12:33:00 PM: Evaluate: task edges-pos-ontonotes, batch 76 (157): mcc: 0.8535, acc: 0.8157, precision: 0.8874, recall: 0.8266, f1: 0.8559, edges-pos-ontonotes_loss: 0.0157
09/16 12:33:10 PM: Evaluate: task edges-pos-ontonotes, batch 147 (157): mcc: 0.8397, acc: 0.7947, precision: 0.8785, recall: 0.8088, f1: 0.8422, edges-pos-ontonotes_loss: 0.0167
09/16 12:33:12 PM: Updating LR scheduler:
09/16 12:33:12 PM: 	Best result seen so far for macro_avg: 0.846
09/16 12:33:12 PM: 	# validation passes without improvement: 1
09/16 12:33:12 PM: edges-pos-ontonotes_loss: training: 0.012529 validation: 0.016815
09/16 12:33:12 PM: macro_avg: validation: 0.841375
09/16 12:33:12 PM: micro_avg: validation: 0.000000
09/16 12:33:12 PM: edges-pos-ontonotes_mcc: training: 0.875060 validation: 0.838886
09/16 12:33:12 PM: edges-pos-ontonotes_acc: training: 0.818301 validation: 0.793729
09/16 12:33:12 PM: edges-pos-ontonotes_precision: training: 0.901536 validation: 0.877595
09/16 12:33:12 PM: edges-pos-ontonotes_recall: training: 0.854275 validation: 0.808026
09/16 12:33:12 PM: edges-pos-ontonotes_f1: training: 0.877269 validation: 0.841375
09/16 12:33:12 PM: Global learning rate: 0.0001
09/16 12:33:12 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 12:33:21 PM: Update 3131: task edges-pos-ontonotes, batch 131 (3131): mcc: 0.8578, acc: 0.8057, precision: 0.8846, recall: 0.8375, f1: 0.8604, edges-pos-ontonotes_loss: 0.0128
09/16 12:33:32 PM: Update 3177: task edges-pos-ontonotes, batch 177 (3177): mcc: 0.8414, acc: 0.7818, precision: 0.8710, recall: 0.8191, f1: 0.8442, edges-pos-ontonotes_loss: 0.0145
09/16 12:33:42 PM: Update 3212: task edges-pos-ontonotes, batch 212 (3212): mcc: 0.8367, acc: 0.7741, precision: 0.8691, recall: 0.8118, f1: 0.8395, edges-pos-ontonotes_loss: 0.0152
09/16 12:33:52 PM: Update 3253: task edges-pos-ontonotes, batch 253 (3253): mcc: 0.8358, acc: 0.7720, precision: 0.8698, recall: 0.8095, f1: 0.8386, edges-pos-ontonotes_loss: 0.0158
09/16 12:34:02 PM: Update 3309: task edges-pos-ontonotes, batch 309 (3309): mcc: 0.8357, acc: 0.7706, precision: 0.8712, recall: 0.8079, f1: 0.8383, edges-pos-ontonotes_loss: 0.0163
09/16 12:34:12 PM: Update 3370: task edges-pos-ontonotes, batch 370 (3370): mcc: 0.8352, acc: 0.7697, precision: 0.8714, recall: 0.8069, f1: 0.8379, edges-pos-ontonotes_loss: 0.0166
09/16 12:34:22 PM: Update 3429: task edges-pos-ontonotes, batch 429 (3429): mcc: 0.8356, acc: 0.7698, precision: 0.8717, recall: 0.8072, f1: 0.8382, edges-pos-ontonotes_loss: 0.0167
09/16 12:34:40 PM: Update 3461: task edges-pos-ontonotes, batch 461 (3461): mcc: 0.8349, acc: 0.7687, precision: 0.8713, recall: 0.8063, f1: 0.8375, edges-pos-ontonotes_loss: 0.0168
09/16 12:34:50 PM: Update 3567: task edges-pos-ontonotes, batch 567 (3567): mcc: 0.8380, acc: 0.7734, precision: 0.8733, recall: 0.8104, f1: 0.8407, edges-pos-ontonotes_loss: 0.0163
09/16 12:35:00 PM: Update 3680: task edges-pos-ontonotes, batch 680 (3680): mcc: 0.8405, acc: 0.7770, precision: 0.8746, recall: 0.8139, f1: 0.8432, edges-pos-ontonotes_loss: 0.0159
09/16 12:35:10 PM: Update 3774: task edges-pos-ontonotes, batch 774 (3774): mcc: 0.8421, acc: 0.7796, precision: 0.8753, recall: 0.8163, f1: 0.8448, edges-pos-ontonotes_loss: 0.0155
09/16 12:35:20 PM: Update 3860: task edges-pos-ontonotes, batch 860 (3860): mcc: 0.8434, acc: 0.7810, precision: 0.8758, recall: 0.8182, f1: 0.8460, edges-pos-ontonotes_loss: 0.0155
09/16 12:35:30 PM: Update 3939: task edges-pos-ontonotes, batch 939 (3939): mcc: 0.8445, acc: 0.7822, precision: 0.8765, recall: 0.8197, f1: 0.8472, edges-pos-ontonotes_loss: 0.0153
09/16 12:35:37 PM: ***** Step 4000 / Validation 4 *****
09/16 12:35:37 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:35:37 PM: Validating...
09/16 12:35:40 PM: Evaluate: task edges-pos-ontonotes, batch 28 (157): mcc: 0.8599, acc: 0.8275, precision: 0.8838, recall: 0.8422, f1: 0.8625, edges-pos-ontonotes_loss: 0.0144
09/16 12:35:50 PM: Evaluate: task edges-pos-ontonotes, batch 116 (157): mcc: 0.8645, acc: 0.8338, precision: 0.8875, recall: 0.8475, f1: 0.8671, edges-pos-ontonotes_loss: 0.0136
09/16 12:35:56 PM: Best result seen so far for edges-pos-ontonotes.
09/16 12:35:56 PM: Best result seen so far for macro.
09/16 12:35:56 PM: Updating LR scheduler:
09/16 12:35:56 PM: 	Best result seen so far for macro_avg: 0.859
09/16 12:35:56 PM: 	# validation passes without improvement: 0
09/16 12:35:56 PM: edges-pos-ontonotes_loss: training: 0.015238 validation: 0.014183
09/16 12:35:56 PM: macro_avg: validation: 0.859343
09/16 12:35:56 PM: micro_avg: validation: 0.000000
09/16 12:35:56 PM: edges-pos-ontonotes_mcc: training: 0.845391 validation: 0.856705
09/16 12:35:56 PM: edges-pos-ontonotes_acc: training: 0.783050 validation: 0.822460
09/16 12:35:56 PM: edges-pos-ontonotes_precision: training: 0.877140 validation: 0.881339
09/16 12:35:56 PM: edges-pos-ontonotes_recall: training: 0.820789 validation: 0.838418
09/16 12:35:56 PM: edges-pos-ontonotes_f1: training: 0.848029 validation: 0.859343
09/16 12:35:56 PM: Global learning rate: 0.0001
09/16 12:35:56 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 12:36:00 PM: Update 4032: task edges-pos-ontonotes, batch 32 (4032): mcc: 0.8608, acc: 0.8032, precision: 0.8849, recall: 0.8429, f1: 0.8634, edges-pos-ontonotes_loss: 0.0141
09/16 12:36:12 PM: Update 4087: task edges-pos-ontonotes, batch 87 (4087): mcc: 0.8581, acc: 0.7999, precision: 0.8847, recall: 0.8379, f1: 0.8607, edges-pos-ontonotes_loss: 0.0141
09/16 12:36:22 PM: Update 4159: task edges-pos-ontonotes, batch 159 (4159): mcc: 0.8510, acc: 0.7905, precision: 0.8784, recall: 0.8303, f1: 0.8537, edges-pos-ontonotes_loss: 0.0152
09/16 12:36:32 PM: Update 4226: task edges-pos-ontonotes, batch 226 (4226): mcc: 0.8501, acc: 0.7889, precision: 0.8774, recall: 0.8296, f1: 0.8528, edges-pos-ontonotes_loss: 0.0155
09/16 12:36:42 PM: Update 4292: task edges-pos-ontonotes, batch 292 (4292): mcc: 0.8506, acc: 0.7895, precision: 0.8777, recall: 0.8302, f1: 0.8533, edges-pos-ontonotes_loss: 0.0155
09/16 12:36:52 PM: Update 4346: task edges-pos-ontonotes, batch 346 (4346): mcc: 0.8508, acc: 0.7900, precision: 0.8777, recall: 0.8307, f1: 0.8535, edges-pos-ontonotes_loss: 0.0155
09/16 12:37:02 PM: Update 4396: task edges-pos-ontonotes, batch 396 (4396): mcc: 0.8507, acc: 0.7897, precision: 0.8777, recall: 0.8305, f1: 0.8534, edges-pos-ontonotes_loss: 0.0154
09/16 12:37:13 PM: Update 4449: task edges-pos-ontonotes, batch 449 (4449): mcc: 0.8500, acc: 0.7893, precision: 0.8772, recall: 0.8296, f1: 0.8527, edges-pos-ontonotes_loss: 0.0155
09/16 12:37:23 PM: Update 4519: task edges-pos-ontonotes, batch 519 (4519): mcc: 0.8507, acc: 0.7906, precision: 0.8779, recall: 0.8302, f1: 0.8534, edges-pos-ontonotes_loss: 0.0156
09/16 12:37:33 PM: Update 4582: task edges-pos-ontonotes, batch 582 (4582): mcc: 0.8504, acc: 0.7906, precision: 0.8775, recall: 0.8301, f1: 0.8531, edges-pos-ontonotes_loss: 0.0156
09/16 12:37:43 PM: Update 4644: task edges-pos-ontonotes, batch 644 (4644): mcc: 0.8510, acc: 0.7916, precision: 0.8781, recall: 0.8306, f1: 0.8537, edges-pos-ontonotes_loss: 0.0156
09/16 12:37:53 PM: Update 4704: task edges-pos-ontonotes, batch 704 (4704): mcc: 0.8513, acc: 0.7921, precision: 0.8785, recall: 0.8308, f1: 0.8540, edges-pos-ontonotes_loss: 0.0156
09/16 12:38:03 PM: Update 4761: task edges-pos-ontonotes, batch 761 (4761): mcc: 0.8516, acc: 0.7927, precision: 0.8787, recall: 0.8311, f1: 0.8542, edges-pos-ontonotes_loss: 0.0155
09/16 12:38:13 PM: Update 4831: task edges-pos-ontonotes, batch 831 (4831): mcc: 0.8518, acc: 0.7933, precision: 0.8790, recall: 0.8313, f1: 0.8544, edges-pos-ontonotes_loss: 0.0155
09/16 12:38:23 PM: Update 4903: task edges-pos-ontonotes, batch 903 (4903): mcc: 0.8520, acc: 0.7937, precision: 0.8792, recall: 0.8315, f1: 0.8547, edges-pos-ontonotes_loss: 0.0155
09/16 12:38:33 PM: Update 4976: task edges-pos-ontonotes, batch 976 (4976): mcc: 0.8524, acc: 0.7942, precision: 0.8795, recall: 0.8319, f1: 0.8550, edges-pos-ontonotes_loss: 0.0155
09/16 12:38:37 PM: ***** Step 5000 / Validation 5 *****
09/16 12:38:37 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:38:37 PM: Validating...
09/16 12:38:43 PM: Evaluate: task edges-pos-ontonotes, batch 63 (157): mcc: 0.8592, acc: 0.8283, precision: 0.8807, recall: 0.8438, f1: 0.8618, edges-pos-ontonotes_loss: 0.0149
09/16 12:38:53 PM: Evaluate: task edges-pos-ontonotes, batch 137 (157): mcc: 0.8629, acc: 0.8319, precision: 0.8843, recall: 0.8476, f1: 0.8655, edges-pos-ontonotes_loss: 0.0142
09/16 12:38:56 PM: Best result seen so far for edges-pos-ontonotes.
09/16 12:38:56 PM: Best result seen so far for macro.
09/16 12:38:56 PM: Updating LR scheduler:
09/16 12:38:56 PM: 	Best result seen so far for macro_avg: 0.866
09/16 12:38:56 PM: 	# validation passes without improvement: 0
09/16 12:38:56 PM: edges-pos-ontonotes_loss: training: 0.015530 validation: 0.014211
09/16 12:38:56 PM: macro_avg: validation: 0.866221
09/16 12:38:56 PM: micro_avg: validation: 0.000000
09/16 12:38:56 PM: edges-pos-ontonotes_mcc: training: 0.852486 validation: 0.863644
09/16 12:38:56 PM: edges-pos-ontonotes_acc: training: 0.794381 validation: 0.832503
09/16 12:38:56 PM: edges-pos-ontonotes_precision: training: 0.879614 validation: 0.885190
09/16 12:38:56 PM: edges-pos-ontonotes_recall: training: 0.831984 validation: 0.848048
09/16 12:38:56 PM: edges-pos-ontonotes_f1: training: 0.855136 validation: 0.866221
09/16 12:38:56 PM: Global learning rate: 0.0001
09/16 12:38:56 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 12:39:09 PM: Update 5026: task edges-pos-ontonotes, batch 26 (5026): mcc: 0.8630, acc: 0.8068, precision: 0.8909, recall: 0.8412, f1: 0.8654, edges-pos-ontonotes_loss: 0.0144
09/16 12:39:19 PM: Update 5100: task edges-pos-ontonotes, batch 100 (5100): mcc: 0.8584, acc: 0.8024, precision: 0.8855, recall: 0.8376, f1: 0.8609, edges-pos-ontonotes_loss: 0.0152
09/16 12:39:30 PM: Update 5173: task edges-pos-ontonotes, batch 173 (5173): mcc: 0.8598, acc: 0.8044, precision: 0.8862, recall: 0.8397, f1: 0.8623, edges-pos-ontonotes_loss: 0.0149
09/16 12:39:40 PM: Update 5243: task edges-pos-ontonotes, batch 243 (5243): mcc: 0.8592, acc: 0.8037, precision: 0.8852, recall: 0.8395, f1: 0.8617, edges-pos-ontonotes_loss: 0.0150
09/16 12:39:50 PM: Update 5309: task edges-pos-ontonotes, batch 309 (5309): mcc: 0.8591, acc: 0.8037, precision: 0.8849, recall: 0.8395, f1: 0.8616, edges-pos-ontonotes_loss: 0.0150
09/16 12:40:00 PM: Update 5361: task edges-pos-ontonotes, batch 361 (5361): mcc: 0.8582, acc: 0.8028, precision: 0.8838, recall: 0.8389, f1: 0.8607, edges-pos-ontonotes_loss: 0.0150
09/16 12:40:10 PM: Update 5445: task edges-pos-ontonotes, batch 445 (5445): mcc: 0.8594, acc: 0.8038, precision: 0.8850, recall: 0.8400, f1: 0.8619, edges-pos-ontonotes_loss: 0.0145
09/16 12:40:20 PM: Update 5521: task edges-pos-ontonotes, batch 521 (5521): mcc: 0.8610, acc: 0.8052, precision: 0.8864, recall: 0.8418, f1: 0.8635, edges-pos-ontonotes_loss: 0.0142
09/16 12:40:30 PM: Update 5590: task edges-pos-ontonotes, batch 590 (5590): mcc: 0.8618, acc: 0.8059, precision: 0.8870, recall: 0.8428, f1: 0.8643, edges-pos-ontonotes_loss: 0.0140
09/16 12:40:40 PM: Update 5647: task edges-pos-ontonotes, batch 647 (5647): mcc: 0.8626, acc: 0.8066, precision: 0.8876, recall: 0.8437, f1: 0.8651, edges-pos-ontonotes_loss: 0.0138
09/16 12:40:50 PM: Update 5725: task edges-pos-ontonotes, batch 725 (5725): mcc: 0.8644, acc: 0.8087, precision: 0.8890, recall: 0.8459, f1: 0.8669, edges-pos-ontonotes_loss: 0.0135
09/16 12:41:00 PM: Update 5836: task edges-pos-ontonotes, batch 836 (5836): mcc: 0.8673, acc: 0.8121, precision: 0.8912, recall: 0.8493, f1: 0.8698, edges-pos-ontonotes_loss: 0.0130
09/16 12:41:10 PM: Update 5928: task edges-pos-ontonotes, batch 928 (5928): mcc: 0.8693, acc: 0.8146, precision: 0.8927, recall: 0.8517, f1: 0.8717, edges-pos-ontonotes_loss: 0.0127
09/16 12:41:17 PM: ***** Step 6000 / Validation 6 *****
09/16 12:41:17 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:41:17 PM: Validating...
09/16 12:41:20 PM: Evaluate: task edges-pos-ontonotes, batch 30 (157): mcc: 0.8476, acc: 0.8027, precision: 0.8857, recall: 0.8170, f1: 0.8500, edges-pos-ontonotes_loss: 0.0155
09/16 12:41:30 PM: Evaluate: task edges-pos-ontonotes, batch 97 (157): mcc: 0.8550, acc: 0.8107, precision: 0.8898, recall: 0.8271, f1: 0.8573, edges-pos-ontonotes_loss: 0.0146
09/16 12:41:40 PM: Evaluate: task edges-pos-ontonotes, batch 137 (157): mcc: 0.8521, acc: 0.8063, precision: 0.8889, recall: 0.8225, f1: 0.8544, edges-pos-ontonotes_loss: 0.0148
09/16 12:41:43 PM: Updating LR scheduler:
09/16 12:41:43 PM: 	Best result seen so far for macro_avg: 0.866
09/16 12:41:43 PM: 	# validation passes without improvement: 1
09/16 12:41:43 PM: edges-pos-ontonotes_loss: training: 0.012638 validation: 0.014951
09/16 12:41:43 PM: macro_avg: validation: 0.853324
09/16 12:41:43 PM: micro_avg: validation: 0.000000
09/16 12:41:43 PM: edges-pos-ontonotes_mcc: training: 0.870228 validation: 0.851026
09/16 12:41:43 PM: edges-pos-ontonotes_acc: training: 0.815675 validation: 0.804491
09/16 12:41:43 PM: edges-pos-ontonotes_precision: training: 0.893506 validation: 0.888545
09/16 12:41:43 PM: edges-pos-ontonotes_recall: training: 0.852700 validation: 0.820788
09/16 12:41:43 PM: edges-pos-ontonotes_f1: training: 0.872626 validation: 0.853324
09/16 12:41:43 PM: Global learning rate: 0.0001
09/16 12:41:43 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 12:41:50 PM: Update 6089: task edges-pos-ontonotes, batch 89 (6089): mcc: 0.8887, acc: 0.8397, precision: 0.9079, recall: 0.8744, f1: 0.8909, edges-pos-ontonotes_loss: 0.0111
09/16 12:42:00 PM: Update 6175: task edges-pos-ontonotes, batch 175 (6175): mcc: 0.8907, acc: 0.8440, precision: 0.9081, recall: 0.8781, f1: 0.8928, edges-pos-ontonotes_loss: 0.0108
09/16 12:42:12 PM: Update 6278: task edges-pos-ontonotes, batch 278 (6278): mcc: 0.8908, acc: 0.8450, precision: 0.9073, recall: 0.8791, f1: 0.8929, edges-pos-ontonotes_loss: 0.0107
09/16 12:42:22 PM: Update 6396: task edges-pos-ontonotes, batch 396 (6396): mcc: 0.8834, acc: 0.8372, precision: 0.9011, recall: 0.8708, f1: 0.8857, edges-pos-ontonotes_loss: 0.0113
09/16 12:42:32 PM: Update 6542: task edges-pos-ontonotes, batch 542 (6542): mcc: 0.8796, acc: 0.8334, precision: 0.8981, recall: 0.8663, f1: 0.8819, edges-pos-ontonotes_loss: 0.0114
09/16 12:42:42 PM: Update 6622: task edges-pos-ontonotes, batch 622 (6622): mcc: 0.8731, acc: 0.8252, precision: 0.8930, recall: 0.8588, f1: 0.8756, edges-pos-ontonotes_loss: 0.0119
09/16 12:42:52 PM: Update 6703: task edges-pos-ontonotes, batch 703 (6703): mcc: 0.8665, acc: 0.8154, precision: 0.8886, recall: 0.8502, f1: 0.8690, edges-pos-ontonotes_loss: 0.0125
09/16 12:43:02 PM: Update 6757: task edges-pos-ontonotes, batch 757 (6757): mcc: 0.8623, acc: 0.8092, precision: 0.8862, recall: 0.8445, f1: 0.8648, edges-pos-ontonotes_loss: 0.0129
09/16 12:43:12 PM: Update 6832: task edges-pos-ontonotes, batch 832 (6832): mcc: 0.8592, acc: 0.8048, precision: 0.8841, recall: 0.8405, f1: 0.8618, edges-pos-ontonotes_loss: 0.0132
09/16 12:43:22 PM: Update 6907: task edges-pos-ontonotes, batch 907 (6907): mcc: 0.8573, acc: 0.8023, precision: 0.8831, recall: 0.8378, f1: 0.8599, edges-pos-ontonotes_loss: 0.0135
09/16 12:43:32 PM: Update 6977: task edges-pos-ontonotes, batch 977 (6977): mcc: 0.8567, acc: 0.8015, precision: 0.8826, recall: 0.8372, f1: 0.8593, edges-pos-ontonotes_loss: 0.0135
09/16 12:43:35 PM: ***** Step 7000 / Validation 7 *****
09/16 12:43:35 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:43:35 PM: Validating...
09/16 12:43:42 PM: Evaluate: task edges-pos-ontonotes, batch 74 (157): mcc: 0.8719, acc: 0.8440, precision: 0.8945, recall: 0.8550, f1: 0.8743, edges-pos-ontonotes_loss: 0.0131
09/16 12:43:52 PM: Evaluate: task edges-pos-ontonotes, batch 145 (157): mcc: 0.8588, acc: 0.8259, precision: 0.8833, recall: 0.8405, f1: 0.8614, edges-pos-ontonotes_loss: 0.0138
09/16 12:43:54 PM: Updating LR scheduler:
09/16 12:43:54 PM: 	Best result seen so far for macro_avg: 0.866
09/16 12:43:54 PM: 	# validation passes without improvement: 2
09/16 12:43:54 PM: edges-pos-ontonotes_loss: training: 0.013530 validation: 0.013916
09/16 12:43:54 PM: macro_avg: validation: 0.860482
09/16 12:43:54 PM: micro_avg: validation: 0.000000
09/16 12:43:54 PM: edges-pos-ontonotes_mcc: training: 0.856731 validation: 0.857865
09/16 12:43:54 PM: edges-pos-ontonotes_acc: training: 0.801591 validation: 0.824756
09/16 12:43:54 PM: edges-pos-ontonotes_precision: training: 0.882517 validation: 0.882437
09/16 12:43:54 PM: edges-pos-ontonotes_recall: training: 0.837341 validation: 0.839593
09/16 12:43:54 PM: edges-pos-ontonotes_f1: training: 0.859336 validation: 0.860482
09/16 12:43:54 PM: Global learning rate: 0.0001
09/16 12:43:54 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 12:44:03 PM: Update 7101: task edges-pos-ontonotes, batch 101 (7101): mcc: 0.8633, acc: 0.8129, precision: 0.8869, recall: 0.8457, f1: 0.8658, edges-pos-ontonotes_loss: 0.0124
09/16 12:44:13 PM: Update 7181: task edges-pos-ontonotes, batch 181 (7181): mcc: 0.8626, acc: 0.8113, precision: 0.8849, recall: 0.8464, f1: 0.8652, edges-pos-ontonotes_loss: 0.0127
09/16 12:44:23 PM: Update 7261: task edges-pos-ontonotes, batch 261 (7261): mcc: 0.8624, acc: 0.8110, precision: 0.8846, recall: 0.8463, f1: 0.8650, edges-pos-ontonotes_loss: 0.0128
09/16 12:44:33 PM: Update 7326: task edges-pos-ontonotes, batch 326 (7326): mcc: 0.8625, acc: 0.8101, precision: 0.8855, recall: 0.8456, f1: 0.8651, edges-pos-ontonotes_loss: 0.0129
09/16 12:44:43 PM: Update 7396: task edges-pos-ontonotes, batch 396 (7396): mcc: 0.8626, acc: 0.8090, precision: 0.8856, recall: 0.8456, f1: 0.8652, edges-pos-ontonotes_loss: 0.0130
09/16 12:44:53 PM: Update 7473: task edges-pos-ontonotes, batch 473 (7473): mcc: 0.8627, acc: 0.8084, precision: 0.8857, recall: 0.8459, f1: 0.8653, edges-pos-ontonotes_loss: 0.0130
09/16 12:45:12 PM: Update 7547: task edges-pos-ontonotes, batch 547 (7547): mcc: 0.8625, acc: 0.8081, precision: 0.8854, recall: 0.8456, f1: 0.8651, edges-pos-ontonotes_loss: 0.0130
09/16 12:45:22 PM: Update 7612: task edges-pos-ontonotes, batch 612 (7612): mcc: 0.8596, acc: 0.8039, precision: 0.8829, recall: 0.8425, f1: 0.8622, edges-pos-ontonotes_loss: 0.0134
09/16 12:45:32 PM: Update 7682: task edges-pos-ontonotes, batch 682 (7682): mcc: 0.8585, acc: 0.8025, precision: 0.8819, recall: 0.8414, f1: 0.8611, edges-pos-ontonotes_loss: 0.0136
09/16 12:45:42 PM: Update 7739: task edges-pos-ontonotes, batch 739 (7739): mcc: 0.8584, acc: 0.8023, precision: 0.8818, recall: 0.8412, f1: 0.8610, edges-pos-ontonotes_loss: 0.0136
09/16 12:45:52 PM: Update 7796: task edges-pos-ontonotes, batch 796 (7796): mcc: 0.8584, acc: 0.8023, precision: 0.8817, recall: 0.8413, f1: 0.8610, edges-pos-ontonotes_loss: 0.0137
09/16 12:46:02 PM: Update 7838: task edges-pos-ontonotes, batch 838 (7838): mcc: 0.8584, acc: 0.8024, precision: 0.8816, recall: 0.8415, f1: 0.8611, edges-pos-ontonotes_loss: 0.0137
09/16 12:46:12 PM: Update 7880: task edges-pos-ontonotes, batch 880 (7880): mcc: 0.8580, acc: 0.8020, precision: 0.8813, recall: 0.8409, f1: 0.8607, edges-pos-ontonotes_loss: 0.0138
09/16 12:46:23 PM: Update 7945: task edges-pos-ontonotes, batch 945 (7945): mcc: 0.8578, acc: 0.8020, precision: 0.8813, recall: 0.8407, f1: 0.8605, edges-pos-ontonotes_loss: 0.0139
09/16 12:46:31 PM: ***** Step 8000 / Validation 8 *****
09/16 12:46:31 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:46:31 PM: Validating...
09/16 12:46:33 PM: Evaluate: task edges-pos-ontonotes, batch 19 (157): mcc: 0.8591, acc: 0.8291, precision: 0.8814, recall: 0.8430, f1: 0.8618, edges-pos-ontonotes_loss: 0.0138
09/16 12:46:43 PM: Evaluate: task edges-pos-ontonotes, batch 112 (157): mcc: 0.8693, acc: 0.8416, precision: 0.8896, recall: 0.8546, f1: 0.8717, edges-pos-ontonotes_loss: 0.0133
09/16 12:46:50 PM: Best result seen so far for edges-pos-ontonotes.
09/16 12:46:50 PM: Best result seen so far for macro.
09/16 12:46:50 PM: Updating LR scheduler:
09/16 12:46:50 PM: 	Best result seen so far for macro_avg: 0.871
09/16 12:46:50 PM: 	# validation passes without improvement: 0
09/16 12:46:50 PM: edges-pos-ontonotes_loss: training: 0.013974 validation: 0.013378
09/16 12:46:50 PM: macro_avg: validation: 0.870788
09/16 12:46:50 PM: micro_avg: validation: 0.000000
09/16 12:46:50 PM: edges-pos-ontonotes_mcc: training: 0.857581 validation: 0.868291
09/16 12:46:50 PM: edges-pos-ontonotes_acc: training: 0.801850 validation: 0.839349
09/16 12:46:50 PM: edges-pos-ontonotes_precision: training: 0.881094 validation: 0.889195
09/16 12:46:50 PM: edges-pos-ontonotes_recall: training: 0.840335 validation: 0.853128
09/16 12:46:50 PM: edges-pos-ontonotes_f1: training: 0.860232 validation: 0.870788
09/16 12:46:50 PM: Global learning rate: 0.0001
09/16 12:46:50 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 12:46:53 PM: Update 8026: task edges-pos-ontonotes, batch 26 (8026): mcc: 0.8586, acc: 0.8060, precision: 0.8823, recall: 0.8412, f1: 0.8612, edges-pos-ontonotes_loss: 0.0151
09/16 12:47:03 PM: Update 8089: task edges-pos-ontonotes, batch 89 (8089): mcc: 0.8575, acc: 0.8045, precision: 0.8817, recall: 0.8396, f1: 0.8601, edges-pos-ontonotes_loss: 0.0149
09/16 12:47:13 PM: Update 8159: task edges-pos-ontonotes, batch 159 (8159): mcc: 0.8585, acc: 0.8051, precision: 0.8829, recall: 0.8403, f1: 0.8611, edges-pos-ontonotes_loss: 0.0148
09/16 12:47:23 PM: Update 8208: task edges-pos-ontonotes, batch 208 (8208): mcc: 0.8570, acc: 0.8037, precision: 0.8820, recall: 0.8383, f1: 0.8596, edges-pos-ontonotes_loss: 0.0149
09/16 12:47:33 PM: Update 8278: task edges-pos-ontonotes, batch 278 (8278): mcc: 0.8577, acc: 0.8045, precision: 0.8822, recall: 0.8395, f1: 0.8603, edges-pos-ontonotes_loss: 0.0149
09/16 12:47:43 PM: Update 8349: task edges-pos-ontonotes, batch 349 (8349): mcc: 0.8584, acc: 0.8054, precision: 0.8832, recall: 0.8399, f1: 0.8610, edges-pos-ontonotes_loss: 0.0149
09/16 12:47:53 PM: Update 8418: task edges-pos-ontonotes, batch 418 (8418): mcc: 0.8589, acc: 0.8061, precision: 0.8835, recall: 0.8405, f1: 0.8615, edges-pos-ontonotes_loss: 0.0149
09/16 12:48:05 PM: Update 8486: task edges-pos-ontonotes, batch 486 (8486): mcc: 0.8593, acc: 0.8067, precision: 0.8838, recall: 0.8410, f1: 0.8619, edges-pos-ontonotes_loss: 0.0148
09/16 12:48:15 PM: Update 8553: task edges-pos-ontonotes, batch 553 (8553): mcc: 0.8593, acc: 0.8069, precision: 0.8838, recall: 0.8411, f1: 0.8619, edges-pos-ontonotes_loss: 0.0148
09/16 12:48:25 PM: Update 8608: task edges-pos-ontonotes, batch 608 (8608): mcc: 0.8596, acc: 0.8070, precision: 0.8840, recall: 0.8413, f1: 0.8621, edges-pos-ontonotes_loss: 0.0148
09/16 12:48:35 PM: Update 8664: task edges-pos-ontonotes, batch 664 (8664): mcc: 0.8597, acc: 0.8071, precision: 0.8840, recall: 0.8417, f1: 0.8623, edges-pos-ontonotes_loss: 0.0148
09/16 12:48:45 PM: Update 8725: task edges-pos-ontonotes, batch 725 (8725): mcc: 0.8600, acc: 0.8073, precision: 0.8843, recall: 0.8419, f1: 0.8626, edges-pos-ontonotes_loss: 0.0147
09/16 12:48:55 PM: Update 8782: task edges-pos-ontonotes, batch 782 (8782): mcc: 0.8600, acc: 0.8073, precision: 0.8843, recall: 0.8420, f1: 0.8626, edges-pos-ontonotes_loss: 0.0147
09/16 12:49:05 PM: Update 8841: task edges-pos-ontonotes, batch 841 (8841): mcc: 0.8601, acc: 0.8075, precision: 0.8841, recall: 0.8424, f1: 0.8627, edges-pos-ontonotes_loss: 0.0146
09/16 12:49:15 PM: Update 8917: task edges-pos-ontonotes, batch 917 (8917): mcc: 0.8608, acc: 0.8080, precision: 0.8846, recall: 0.8432, f1: 0.8634, edges-pos-ontonotes_loss: 0.0144
09/16 12:49:26 PM: Update 8961: task edges-pos-ontonotes, batch 961 (8961): mcc: 0.8611, acc: 0.8081, precision: 0.8849, recall: 0.8434, f1: 0.8636, edges-pos-ontonotes_loss: 0.0143
09/16 12:49:30 PM: ***** Step 9000 / Validation 9 *****
09/16 12:49:30 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:49:30 PM: Validating...
09/16 12:49:36 PM: Evaluate: task edges-pos-ontonotes, batch 54 (157): mcc: 0.8560, acc: 0.8263, precision: 0.8799, recall: 0.8384, f1: 0.8586, edges-pos-ontonotes_loss: 0.0147
09/16 12:49:46 PM: Evaluate: task edges-pos-ontonotes, batch 113 (157): mcc: 0.8605, acc: 0.8303, precision: 0.8842, recall: 0.8430, f1: 0.8631, edges-pos-ontonotes_loss: 0.0141
09/16 12:49:54 PM: Updating LR scheduler:
09/16 12:49:54 PM: 	Best result seen so far for macro_avg: 0.871
09/16 12:49:54 PM: 	# validation passes without improvement: 1
09/16 12:49:54 PM: edges-pos-ontonotes_loss: training: 0.014237 validation: 0.013981
09/16 12:49:54 PM: macro_avg: validation: 0.864816
09/16 12:49:54 PM: micro_avg: validation: 0.000000
09/16 12:49:54 PM: edges-pos-ontonotes_mcc: training: 0.861475 validation: 0.862320
09/16 12:49:54 PM: edges-pos-ontonotes_acc: training: 0.808452 validation: 0.830143
09/16 12:49:54 PM: edges-pos-ontonotes_precision: training: 0.885242 validation: 0.887920
09/16 12:49:54 PM: edges-pos-ontonotes_recall: training: 0.843829 validation: 0.842884
09/16 12:49:54 PM: edges-pos-ontonotes_f1: training: 0.864040 validation: 0.864816
09/16 12:49:54 PM: Global learning rate: 0.0001
09/16 12:49:54 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 12:49:56 PM: Update 9016: task edges-pos-ontonotes, batch 16 (9016): mcc: 0.8841, acc: 0.8304, precision: 0.9054, recall: 0.8678, f1: 0.8862, edges-pos-ontonotes_loss: 0.0112
09/16 12:50:06 PM: Update 9106: task edges-pos-ontonotes, batch 106 (9106): mcc: 0.8741, acc: 0.8191, precision: 0.8959, recall: 0.8578, f1: 0.8764, edges-pos-ontonotes_loss: 0.0118
09/16 12:50:16 PM: Update 9112: task edges-pos-ontonotes, batch 112 (9112): mcc: 0.8745, acc: 0.8196, precision: 0.8962, recall: 0.8583, f1: 0.8768, edges-pos-ontonotes_loss: 0.0118
09/16 12:50:26 PM: Update 9234: task edges-pos-ontonotes, batch 234 (9234): mcc: 0.8830, acc: 0.8311, precision: 0.9021, recall: 0.8689, f1: 0.8852, edges-pos-ontonotes_loss: 0.0109
09/16 12:50:36 PM: Update 9349: task edges-pos-ontonotes, batch 349 (9349): mcc: 0.8875, acc: 0.8373, precision: 0.9057, recall: 0.8742, f1: 0.8897, edges-pos-ontonotes_loss: 0.0105
09/16 12:50:46 PM: Update 9445: task edges-pos-ontonotes, batch 445 (9445): mcc: 0.8883, acc: 0.8383, precision: 0.9060, recall: 0.8754, f1: 0.8905, edges-pos-ontonotes_loss: 0.0105
09/16 12:50:56 PM: Update 9573: task edges-pos-ontonotes, batch 573 (9573): mcc: 0.8887, acc: 0.8391, precision: 0.9063, recall: 0.8759, f1: 0.8909, edges-pos-ontonotes_loss: 0.0105
09/16 12:51:06 PM: Update 9701: task edges-pos-ontonotes, batch 701 (9701): mcc: 0.8898, acc: 0.8411, precision: 0.9068, recall: 0.8775, f1: 0.8919, edges-pos-ontonotes_loss: 0.0105
09/16 12:51:16 PM: Update 9851: task edges-pos-ontonotes, batch 851 (9851): mcc: 0.8880, acc: 0.8397, precision: 0.9052, recall: 0.8755, f1: 0.8901, edges-pos-ontonotes_loss: 0.0107
09/16 12:51:24 PM: ***** Step 10000 / Validation 10 *****
09/16 12:51:24 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:51:24 PM: Validating...
09/16 12:51:26 PM: Evaluate: task edges-pos-ontonotes, batch 20 (157): mcc: 0.8480, acc: 0.8201, precision: 0.8765, recall: 0.8263, f1: 0.8507, edges-pos-ontonotes_loss: 0.0157
09/16 12:51:36 PM: Evaluate: task edges-pos-ontonotes, batch 110 (157): mcc: 0.8564, acc: 0.8264, precision: 0.8829, recall: 0.8363, f1: 0.8590, edges-pos-ontonotes_loss: 0.0149
09/16 12:51:44 PM: Updating LR scheduler:
09/16 12:51:44 PM: 	Best result seen so far for macro_avg: 0.871
09/16 12:51:44 PM: 	# validation passes without improvement: 2
09/16 12:51:44 PM: edges-pos-ontonotes_loss: training: 0.010768 validation: 0.015476
09/16 12:51:44 PM: macro_avg: validation: 0.851636
09/16 12:51:44 PM: micro_avg: validation: 0.000000
09/16 12:51:44 PM: edges-pos-ontonotes_mcc: training: 0.886310 validation: 0.849041
09/16 12:51:44 PM: edges-pos-ontonotes_acc: training: 0.838612 validation: 0.814894
09/16 12:51:44 PM: edges-pos-ontonotes_precision: training: 0.903699 validation: 0.879942
09/16 12:51:44 PM: edges-pos-ontonotes_recall: training: 0.873826 validation: 0.825095
09/16 12:51:44 PM: edges-pos-ontonotes_f1: training: 0.888511 validation: 0.851636
09/16 12:51:44 PM: Global learning rate: 0.0001
09/16 12:51:44 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 12:51:46 PM: Update 10037: task edges-pos-ontonotes, batch 37 (10037): mcc: 0.8555, acc: 0.8078, precision: 0.8774, recall: 0.8398, f1: 0.8582, edges-pos-ontonotes_loss: 0.0131
09/16 12:51:57 PM: Update 10100: task edges-pos-ontonotes, batch 100 (10100): mcc: 0.8418, acc: 0.7860, precision: 0.8672, recall: 0.8234, f1: 0.8447, edges-pos-ontonotes_loss: 0.0151
09/16 12:52:07 PM: Update 10178: task edges-pos-ontonotes, batch 178 (10178): mcc: 0.8407, acc: 0.7822, precision: 0.8680, recall: 0.8205, f1: 0.8436, edges-pos-ontonotes_loss: 0.0159
09/16 12:52:17 PM: Update 10258: task edges-pos-ontonotes, batch 258 (10258): mcc: 0.8422, acc: 0.7836, precision: 0.8701, recall: 0.8215, f1: 0.8451, edges-pos-ontonotes_loss: 0.0161
09/16 12:52:27 PM: Update 10319: task edges-pos-ontonotes, batch 319 (10319): mcc: 0.8428, acc: 0.7839, precision: 0.8712, recall: 0.8215, f1: 0.8456, edges-pos-ontonotes_loss: 0.0162
09/16 12:52:37 PM: Update 10381: task edges-pos-ontonotes, batch 381 (10381): mcc: 0.8428, acc: 0.7834, precision: 0.8715, recall: 0.8211, f1: 0.8456, edges-pos-ontonotes_loss: 0.0163
09/16 12:52:47 PM: Update 10489: task edges-pos-ontonotes, batch 489 (10489): mcc: 0.8458, acc: 0.7878, precision: 0.8735, recall: 0.8249, f1: 0.8485, edges-pos-ontonotes_loss: 0.0156
09/16 12:52:57 PM: Update 10578: task edges-pos-ontonotes, batch 578 (10578): mcc: 0.8478, acc: 0.7908, precision: 0.8749, recall: 0.8275, f1: 0.8505, edges-pos-ontonotes_loss: 0.0151
09/16 12:53:07 PM: Update 10672: task edges-pos-ontonotes, batch 672 (10672): mcc: 0.8496, acc: 0.7935, precision: 0.8761, recall: 0.8299, f1: 0.8524, edges-pos-ontonotes_loss: 0.0147
09/16 12:53:17 PM: Update 10753: task edges-pos-ontonotes, batch 753 (10753): mcc: 0.8511, acc: 0.7954, precision: 0.8770, recall: 0.8318, f1: 0.8538, edges-pos-ontonotes_loss: 0.0145
09/16 12:53:27 PM: Update 10825: task edges-pos-ontonotes, batch 825 (10825): mcc: 0.8523, acc: 0.7966, precision: 0.8779, recall: 0.8332, f1: 0.8550, edges-pos-ontonotes_loss: 0.0144
09/16 12:53:37 PM: Update 10916: task edges-pos-ontonotes, batch 916 (10916): mcc: 0.8538, acc: 0.7983, precision: 0.8791, recall: 0.8351, f1: 0.8565, edges-pos-ontonotes_loss: 0.0143
09/16 12:53:46 PM: ***** Step 11000 / Validation 11 *****
09/16 12:53:46 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:53:46 PM: Validating...
09/16 12:53:47 PM: Evaluate: task edges-pos-ontonotes, batch 11 (157): mcc: 0.8721, acc: 0.8409, precision: 0.8937, recall: 0.8561, f1: 0.8745, edges-pos-ontonotes_loss: 0.0130
09/16 12:53:57 PM: Evaluate: task edges-pos-ontonotes, batch 106 (157): mcc: 0.8773, acc: 0.8447, precision: 0.9049, recall: 0.8554, f1: 0.8794, edges-pos-ontonotes_loss: 0.0125
09/16 12:54:05 PM: Updating LR scheduler:
09/16 12:54:05 PM: 	Best result seen so far for macro_avg: 0.871
09/16 12:54:05 PM: 	# validation passes without improvement: 3
09/16 12:54:05 PM: edges-pos-ontonotes_loss: training: 0.014134 validation: 0.013134
09/16 12:54:05 PM: macro_avg: validation: 0.870601
09/16 12:54:05 PM: micro_avg: validation: 0.000000
09/16 12:54:05 PM: edges-pos-ontonotes_mcc: training: 0.854810 validation: 0.868342
09/16 12:54:05 PM: edges-pos-ontonotes_acc: training: 0.799396 validation: 0.833053
09/16 12:54:05 PM: edges-pos-ontonotes_precision: training: 0.879704 validation: 0.897622
09/16 12:54:05 PM: edges-pos-ontonotes_recall: training: 0.836352 validation: 0.845159
09/16 12:54:05 PM: edges-pos-ontonotes_f1: training: 0.857480 validation: 0.870601
09/16 12:54:05 PM: Global learning rate: 0.0001
09/16 12:54:05 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 12:54:08 PM: Update 11007: task edges-pos-ontonotes, batch 7 (11007): mcc: 0.8346, acc: 0.7780, precision: 0.8626, recall: 0.8140, f1: 0.8376, edges-pos-ontonotes_loss: 0.0137
09/16 12:54:18 PM: Update 11079: task edges-pos-ontonotes, batch 79 (11079): mcc: 0.8524, acc: 0.7946, precision: 0.8748, recall: 0.8364, f1: 0.8551, edges-pos-ontonotes_loss: 0.0150
09/16 12:54:28 PM: Update 11148: task edges-pos-ontonotes, batch 148 (11148): mcc: 0.8539, acc: 0.7972, precision: 0.8762, recall: 0.8380, f1: 0.8567, edges-pos-ontonotes_loss: 0.0150
09/16 12:54:38 PM: Update 11220: task edges-pos-ontonotes, batch 220 (11220): mcc: 0.8548, acc: 0.7984, precision: 0.8769, recall: 0.8390, f1: 0.8575, edges-pos-ontonotes_loss: 0.0149
09/16 12:54:48 PM: Update 11295: task edges-pos-ontonotes, batch 295 (11295): mcc: 0.8551, acc: 0.7987, precision: 0.8771, recall: 0.8394, f1: 0.8578, edges-pos-ontonotes_loss: 0.0148
09/16 12:55:02 PM: Update 11320: task edges-pos-ontonotes, batch 320 (11320): mcc: 0.8554, acc: 0.7992, precision: 0.8775, recall: 0.8396, f1: 0.8582, edges-pos-ontonotes_loss: 0.0148
09/16 12:55:12 PM: Update 11388: task edges-pos-ontonotes, batch 388 (11388): mcc: 0.8555, acc: 0.7997, precision: 0.8780, recall: 0.8394, f1: 0.8583, edges-pos-ontonotes_loss: 0.0149
09/16 12:55:22 PM: Update 11444: task edges-pos-ontonotes, batch 444 (11444): mcc: 0.8557, acc: 0.7999, precision: 0.8786, recall: 0.8391, f1: 0.8584, edges-pos-ontonotes_loss: 0.0149
09/16 12:55:32 PM: Update 11488: task edges-pos-ontonotes, batch 488 (11488): mcc: 0.8560, acc: 0.8006, precision: 0.8790, recall: 0.8393, f1: 0.8587, edges-pos-ontonotes_loss: 0.0149
09/16 12:55:42 PM: Update 11536: task edges-pos-ontonotes, batch 536 (11536): mcc: 0.8565, acc: 0.8014, precision: 0.8794, recall: 0.8398, f1: 0.8591, edges-pos-ontonotes_loss: 0.0148
09/16 12:55:53 PM: Update 11586: task edges-pos-ontonotes, batch 586 (11586): mcc: 0.8567, acc: 0.8020, precision: 0.8796, recall: 0.8400, f1: 0.8594, edges-pos-ontonotes_loss: 0.0148
09/16 12:56:03 PM: Update 11640: task edges-pos-ontonotes, batch 640 (11640): mcc: 0.8570, acc: 0.8027, precision: 0.8798, recall: 0.8404, f1: 0.8596, edges-pos-ontonotes_loss: 0.0148
09/16 12:56:13 PM: Update 11698: task edges-pos-ontonotes, batch 698 (11698): mcc: 0.8573, acc: 0.8032, precision: 0.8803, recall: 0.8406, f1: 0.8600, edges-pos-ontonotes_loss: 0.0148
09/16 12:56:23 PM: Update 11747: task edges-pos-ontonotes, batch 747 (11747): mcc: 0.8576, acc: 0.8037, precision: 0.8806, recall: 0.8409, f1: 0.8603, edges-pos-ontonotes_loss: 0.0148
09/16 12:56:33 PM: Update 11815: task edges-pos-ontonotes, batch 815 (11815): mcc: 0.8580, acc: 0.8043, precision: 0.8810, recall: 0.8412, f1: 0.8606, edges-pos-ontonotes_loss: 0.0147
09/16 12:56:43 PM: Update 11870: task edges-pos-ontonotes, batch 870 (11870): mcc: 0.8583, acc: 0.8048, precision: 0.8812, recall: 0.8415, f1: 0.8609, edges-pos-ontonotes_loss: 0.0147
09/16 12:56:53 PM: Update 11934: task edges-pos-ontonotes, batch 934 (11934): mcc: 0.8583, acc: 0.8050, precision: 0.8815, recall: 0.8414, f1: 0.8610, edges-pos-ontonotes_loss: 0.0147
09/16 12:57:03 PM: Update 11987: task edges-pos-ontonotes, batch 987 (11987): mcc: 0.8584, acc: 0.8053, precision: 0.8816, recall: 0.8415, f1: 0.8611, edges-pos-ontonotes_loss: 0.0147
09/16 12:57:05 PM: ***** Step 12000 / Validation 12 *****
09/16 12:57:05 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:57:05 PM: Validating...
09/16 12:57:13 PM: Evaluate: task edges-pos-ontonotes, batch 83 (157): mcc: 0.8664, acc: 0.8395, precision: 0.8855, recall: 0.8530, f1: 0.8689, edges-pos-ontonotes_loss: 0.0138
09/16 12:57:23 PM: Evaluate: task edges-pos-ontonotes, batch 151 (157): mcc: 0.8685, acc: 0.8409, precision: 0.8881, recall: 0.8547, f1: 0.8711, edges-pos-ontonotes_loss: 0.0134
09/16 12:57:24 PM: Best result seen so far for edges-pos-ontonotes.
09/16 12:57:24 PM: Best result seen so far for macro.
09/16 12:57:24 PM: Updating LR scheduler:
09/16 12:57:24 PM: 	Best result seen so far for macro_avg: 0.871
09/16 12:57:24 PM: 	# validation passes without improvement: 0
09/16 12:57:24 PM: edges-pos-ontonotes_loss: training: 0.014680 validation: 0.013453
09/16 12:57:24 PM: macro_avg: validation: 0.870913
09/16 12:57:24 PM: micro_avg: validation: 0.000000
09/16 12:57:24 PM: edges-pos-ontonotes_mcc: training: 0.858476 validation: 0.868387
09/16 12:57:24 PM: edges-pos-ontonotes_acc: training: 0.805352 validation: 0.840651
09/16 12:57:24 PM: edges-pos-ontonotes_precision: training: 0.881545 validation: 0.887965
09/16 12:57:24 PM: edges-pos-ontonotes_recall: training: 0.841622 validation: 0.854503
09/16 12:57:24 PM: edges-pos-ontonotes_f1: training: 0.861121 validation: 0.870913
09/16 12:57:24 PM: Global learning rate: 0.0001
09/16 12:57:24 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 12:57:33 PM: Update 12064: task edges-pos-ontonotes, batch 64 (12064): mcc: 0.8619, acc: 0.8098, precision: 0.8853, recall: 0.8446, f1: 0.8645, edges-pos-ontonotes_loss: 0.0143
09/16 12:57:44 PM: Update 12139: task edges-pos-ontonotes, batch 139 (12139): mcc: 0.8628, acc: 0.8110, precision: 0.8860, recall: 0.8457, f1: 0.8654, edges-pos-ontonotes_loss: 0.0144
09/16 12:57:54 PM: Update 12212: task edges-pos-ontonotes, batch 212 (12212): mcc: 0.8640, acc: 0.8128, precision: 0.8871, recall: 0.8468, f1: 0.8665, edges-pos-ontonotes_loss: 0.0142
09/16 12:58:04 PM: Update 12260: task edges-pos-ontonotes, batch 260 (12260): mcc: 0.8630, acc: 0.8119, precision: 0.8862, recall: 0.8459, f1: 0.8656, edges-pos-ontonotes_loss: 0.0142
09/16 12:58:14 PM: Update 12343: task edges-pos-ontonotes, batch 343 (12343): mcc: 0.8638, acc: 0.8124, precision: 0.8866, recall: 0.8469, f1: 0.8663, edges-pos-ontonotes_loss: 0.0138
09/16 12:58:24 PM: Update 12404: task edges-pos-ontonotes, batch 404 (12404): mcc: 0.8653, acc: 0.8137, precision: 0.8881, recall: 0.8485, f1: 0.8678, edges-pos-ontonotes_loss: 0.0135
09/16 12:58:34 PM: Update 12478: task edges-pos-ontonotes, batch 478 (12478): mcc: 0.8661, acc: 0.8143, precision: 0.8887, recall: 0.8495, f1: 0.8686, edges-pos-ontonotes_loss: 0.0132
09/16 12:58:44 PM: Update 12553: task edges-pos-ontonotes, batch 553 (12553): mcc: 0.8673, acc: 0.8150, precision: 0.8898, recall: 0.8506, f1: 0.8697, edges-pos-ontonotes_loss: 0.0130
09/16 12:58:55 PM: Update 12618: task edges-pos-ontonotes, batch 618 (12618): mcc: 0.8689, acc: 0.8167, precision: 0.8910, recall: 0.8525, f1: 0.8713, edges-pos-ontonotes_loss: 0.0128
09/16 12:59:05 PM: Update 12716: task edges-pos-ontonotes, batch 716 (12716): mcc: 0.8714, acc: 0.8196, precision: 0.8928, recall: 0.8556, f1: 0.8738, edges-pos-ontonotes_loss: 0.0124
09/16 12:59:15 PM: Update 12815: task edges-pos-ontonotes, batch 815 (12815): mcc: 0.8737, acc: 0.8223, precision: 0.8946, recall: 0.8583, f1: 0.8761, edges-pos-ontonotes_loss: 0.0120
09/16 12:59:25 PM: Update 12919: task edges-pos-ontonotes, batch 919 (12919): mcc: 0.8754, acc: 0.8245, precision: 0.8960, recall: 0.8602, f1: 0.8778, edges-pos-ontonotes_loss: 0.0118
09/16 12:59:31 PM: ***** Step 13000 / Validation 13 *****
09/16 12:59:31 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:59:31 PM: Validating...
09/16 12:59:35 PM: Evaluate: task edges-pos-ontonotes, batch 35 (157): mcc: 0.8464, acc: 0.8190, precision: 0.8706, recall: 0.8289, f1: 0.8492, edges-pos-ontonotes_loss: 0.0149
09/16 12:59:45 PM: Evaluate: task edges-pos-ontonotes, batch 119 (157): mcc: 0.8490, acc: 0.8200, precision: 0.8708, recall: 0.8338, f1: 0.8519, edges-pos-ontonotes_loss: 0.0144
09/16 12:59:51 PM: Updating LR scheduler:
09/16 12:59:51 PM: 	Best result seen so far for macro_avg: 0.871
09/16 12:59:51 PM: 	# validation passes without improvement: 1
09/16 12:59:51 PM: edges-pos-ontonotes_loss: training: 0.011728 validation: 0.014610
09/16 12:59:51 PM: macro_avg: validation: 0.848332
09/16 12:59:51 PM: micro_avg: validation: 0.000000
09/16 12:59:51 PM: edges-pos-ontonotes_mcc: training: 0.876292 validation: 0.845467
09/16 12:59:51 PM: edges-pos-ontonotes_acc: training: 0.825626 validation: 0.813539
09/16 12:59:51 PM: edges-pos-ontonotes_precision: training: 0.896748 validation: 0.870220
09/16 12:59:51 PM: edges-pos-ontonotes_recall: training: 0.861239 validation: 0.827518
09/16 12:59:51 PM: edges-pos-ontonotes_f1: training: 0.878635 validation: 0.848332
09/16 12:59:51 PM: Global learning rate: 0.0001
09/16 12:59:51 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 12:59:55 PM: Update 13055: task edges-pos-ontonotes, batch 55 (13055): mcc: 0.8941, acc: 0.8512, precision: 0.9084, recall: 0.8842, f1: 0.8962, edges-pos-ontonotes_loss: 0.0102
09/16 01:00:05 PM: Update 13193: task edges-pos-ontonotes, batch 193 (13193): mcc: 0.8951, acc: 0.8523, precision: 0.9084, recall: 0.8861, f1: 0.8971, edges-pos-ontonotes_loss: 0.0101
09/16 01:00:15 PM: Update 13291: task edges-pos-ontonotes, batch 291 (13291): mcc: 0.8869, acc: 0.8433, precision: 0.9018, recall: 0.8769, f1: 0.8892, edges-pos-ontonotes_loss: 0.0107
09/16 01:00:25 PM: Update 13462: task edges-pos-ontonotes, batch 462 (13462): mcc: 0.8814, acc: 0.8383, precision: 0.8976, recall: 0.8703, f1: 0.8838, edges-pos-ontonotes_loss: 0.0110
09/16 01:00:38 PM: Update 13511: task edges-pos-ontonotes, batch 511 (13511): mcc: 0.8795, acc: 0.8361, precision: 0.8960, recall: 0.8682, f1: 0.8819, edges-pos-ontonotes_loss: 0.0111
09/16 01:00:48 PM: Update 13566: task edges-pos-ontonotes, batch 566 (13566): mcc: 0.8714, acc: 0.8251, precision: 0.8898, recall: 0.8586, f1: 0.8739, edges-pos-ontonotes_loss: 0.0117
09/16 01:00:58 PM: Update 13616: task edges-pos-ontonotes, batch 616 (13616): mcc: 0.8669, acc: 0.8190, precision: 0.8869, recall: 0.8526, f1: 0.8694, edges-pos-ontonotes_loss: 0.0121
09/16 01:01:08 PM: Update 13693: task edges-pos-ontonotes, batch 693 (13693): mcc: 0.8624, acc: 0.8125, precision: 0.8842, recall: 0.8467, f1: 0.8650, edges-pos-ontonotes_loss: 0.0125
09/16 01:01:19 PM: Update 13764: task edges-pos-ontonotes, batch 764 (13764): mcc: 0.8599, acc: 0.8083, precision: 0.8827, recall: 0.8433, f1: 0.8625, edges-pos-ontonotes_loss: 0.0128
09/16 01:01:30 PM: Update 13841: task edges-pos-ontonotes, batch 841 (13841): mcc: 0.8575, acc: 0.8045, precision: 0.8814, recall: 0.8398, f1: 0.8601, edges-pos-ontonotes_loss: 0.0132
09/16 01:01:40 PM: Update 13930: task edges-pos-ontonotes, batch 930 (13930): mcc: 0.8579, acc: 0.8051, precision: 0.8817, recall: 0.8404, f1: 0.8605, edges-pos-ontonotes_loss: 0.0132
09/16 01:01:48 PM: ***** Step 14000 / Validation 14 *****
09/16 01:01:48 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:01:48 PM: Validating...
09/16 01:01:50 PM: Evaluate: task edges-pos-ontonotes, batch 17 (157): mcc: 0.8692, acc: 0.8369, precision: 0.8961, recall: 0.8483, f1: 0.8715, edges-pos-ontonotes_loss: 0.0132
09/16 01:02:00 PM: Evaluate: task edges-pos-ontonotes, batch 108 (157): mcc: 0.8720, acc: 0.8399, precision: 0.8987, recall: 0.8511, f1: 0.8743, edges-pos-ontonotes_loss: 0.0128
09/16 01:02:08 PM: Updating LR scheduler:
09/16 01:02:08 PM: 	Best result seen so far for macro_avg: 0.871
09/16 01:02:08 PM: 	# validation passes without improvement: 2
09/16 01:02:08 PM: edges-pos-ontonotes_loss: training: 0.013145 validation: 0.013270
09/16 01:02:08 PM: macro_avg: validation: 0.867132
09/16 01:02:08 PM: micro_avg: validation: 0.000000
09/16 01:02:08 PM: edges-pos-ontonotes_mcc: training: 0.858219 validation: 0.864710
09/16 01:02:08 PM: edges-pos-ontonotes_acc: training: 0.805516 validation: 0.831709
09/16 01:02:08 PM: edges-pos-ontonotes_precision: training: 0.881898 validation: 0.891160
09/16 01:02:08 PM: edges-pos-ontonotes_recall: training: 0.840790 validation: 0.844365
09/16 01:02:08 PM: edges-pos-ontonotes_f1: training: 0.860853 validation: 0.867132
09/16 01:02:08 PM: Global learning rate: 0.0001
09/16 01:02:08 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 01:02:10 PM: Update 14019: task edges-pos-ontonotes, batch 19 (14019): mcc: 0.8659, acc: 0.8157, precision: 0.8845, recall: 0.8532, f1: 0.8685, edges-pos-ontonotes_loss: 0.0127
09/16 01:02:20 PM: Update 14113: task edges-pos-ontonotes, batch 113 (14113): mcc: 0.8687, acc: 0.8223, precision: 0.8869, recall: 0.8562, f1: 0.8713, edges-pos-ontonotes_loss: 0.0121
09/16 01:02:30 PM: Update 14192: task edges-pos-ontonotes, batch 192 (14192): mcc: 0.8678, acc: 0.8200, precision: 0.8877, recall: 0.8536, f1: 0.8703, edges-pos-ontonotes_loss: 0.0123
09/16 01:02:40 PM: Update 14265: task edges-pos-ontonotes, batch 265 (14265): mcc: 0.8674, acc: 0.8184, precision: 0.8878, recall: 0.8528, f1: 0.8700, edges-pos-ontonotes_loss: 0.0125
09/16 01:02:50 PM: Update 14355: task edges-pos-ontonotes, batch 355 (14355): mcc: 0.8670, acc: 0.8160, precision: 0.8881, recall: 0.8517, f1: 0.8695, edges-pos-ontonotes_loss: 0.0126
09/16 01:03:01 PM: Update 14446: task edges-pos-ontonotes, batch 446 (14446): mcc: 0.8672, acc: 0.8162, precision: 0.8883, recall: 0.8519, f1: 0.8697, edges-pos-ontonotes_loss: 0.0126
09/16 01:03:11 PM: Update 14505: task edges-pos-ontonotes, batch 505 (14505): mcc: 0.8645, acc: 0.8123, precision: 0.8859, recall: 0.8490, f1: 0.8671, edges-pos-ontonotes_loss: 0.0128
09/16 01:03:21 PM: Update 14580: task edges-pos-ontonotes, batch 580 (14580): mcc: 0.8631, acc: 0.8105, precision: 0.8847, recall: 0.8474, f1: 0.8657, edges-pos-ontonotes_loss: 0.0131
09/16 01:03:31 PM: Update 14651: task edges-pos-ontonotes, batch 651 (14651): mcc: 0.8622, acc: 0.8092, precision: 0.8839, recall: 0.8465, f1: 0.8648, edges-pos-ontonotes_loss: 0.0132
09/16 01:03:41 PM: Update 14722: task edges-pos-ontonotes, batch 722 (14722): mcc: 0.8619, acc: 0.8088, precision: 0.8835, recall: 0.8462, f1: 0.8645, edges-pos-ontonotes_loss: 0.0133
09/16 01:03:51 PM: Update 14780: task edges-pos-ontonotes, batch 780 (14780): mcc: 0.8619, acc: 0.8089, precision: 0.8836, recall: 0.8464, f1: 0.8646, edges-pos-ontonotes_loss: 0.0134
09/16 01:04:01 PM: Update 14844: task edges-pos-ontonotes, batch 844 (14844): mcc: 0.8616, acc: 0.8087, precision: 0.8833, recall: 0.8458, f1: 0.8642, edges-pos-ontonotes_loss: 0.0135
09/16 01:04:11 PM: Update 14895: task edges-pos-ontonotes, batch 895 (14895): mcc: 0.8615, acc: 0.8087, precision: 0.8834, recall: 0.8457, f1: 0.8641, edges-pos-ontonotes_loss: 0.0136
09/16 01:04:21 PM: Update 14949: task edges-pos-ontonotes, batch 949 (14949): mcc: 0.8613, acc: 0.8086, precision: 0.8832, recall: 0.8454, f1: 0.8639, edges-pos-ontonotes_loss: 0.0136
09/16 01:04:31 PM: ***** Step 15000 / Validation 15 *****
09/16 01:04:31 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:04:31 PM: Validating...
09/16 01:04:32 PM: Evaluate: task edges-pos-ontonotes, batch 7 (157): mcc: 0.8743, acc: 0.8532, precision: 0.8901, recall: 0.8637, f1: 0.8767, edges-pos-ontonotes_loss: 0.0133
09/16 01:04:42 PM: Evaluate: task edges-pos-ontonotes, batch 103 (157): mcc: 0.8720, acc: 0.8483, precision: 0.8909, recall: 0.8587, f1: 0.8745, edges-pos-ontonotes_loss: 0.0129
09/16 01:04:50 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:04:50 PM: Best result seen so far for macro.
09/16 01:04:50 PM: Updating LR scheduler:
09/16 01:04:50 PM: 	Best result seen so far for macro_avg: 0.874
09/16 01:04:50 PM: 	# validation passes without improvement: 0
09/16 01:04:50 PM: edges-pos-ontonotes_loss: training: 0.013644 validation: 0.012985
09/16 01:04:50 PM: macro_avg: validation: 0.873932
09/16 01:04:50 PM: micro_avg: validation: 0.000000
09/16 01:04:50 PM: edges-pos-ontonotes_mcc: training: 0.861359 validation: 0.871479
09/16 01:04:50 PM: edges-pos-ontonotes_acc: training: 0.808816 validation: 0.845953
09/16 01:04:50 PM: edges-pos-ontonotes_precision: training: 0.883218 validation: 0.891444
09/16 01:04:50 PM: edges-pos-ontonotes_recall: training: 0.845554 validation: 0.857096
09/16 01:04:50 PM: edges-pos-ontonotes_f1: training: 0.863976 validation: 0.873932
09/16 01:04:50 PM: Global learning rate: 0.0001
09/16 01:04:50 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 01:04:52 PM: Update 15013: task edges-pos-ontonotes, batch 13 (15013): mcc: 0.8614, acc: 0.8094, precision: 0.8839, recall: 0.8450, f1: 0.8640, edges-pos-ontonotes_loss: 0.0151
09/16 01:05:02 PM: Update 15076: task edges-pos-ontonotes, batch 76 (15076): mcc: 0.8614, acc: 0.8107, precision: 0.8854, recall: 0.8435, f1: 0.8639, edges-pos-ontonotes_loss: 0.0145
09/16 01:05:15 PM: Update 15093: task edges-pos-ontonotes, batch 93 (15093): mcc: 0.8597, acc: 0.8096, precision: 0.8834, recall: 0.8421, f1: 0.8623, edges-pos-ontonotes_loss: 0.0146
09/16 01:05:25 PM: Update 15165: task edges-pos-ontonotes, batch 165 (15165): mcc: 0.8606, acc: 0.8106, precision: 0.8841, recall: 0.8432, f1: 0.8632, edges-pos-ontonotes_loss: 0.0146
09/16 01:05:35 PM: Update 15233: task edges-pos-ontonotes, batch 233 (15233): mcc: 0.8608, acc: 0.8112, precision: 0.8843, recall: 0.8435, f1: 0.8634, edges-pos-ontonotes_loss: 0.0145
09/16 01:05:45 PM: Update 15302: task edges-pos-ontonotes, batch 302 (15302): mcc: 0.8620, acc: 0.8125, precision: 0.8851, recall: 0.8449, f1: 0.8645, edges-pos-ontonotes_loss: 0.0144
09/16 01:05:55 PM: Update 15376: task edges-pos-ontonotes, batch 376 (15376): mcc: 0.8624, acc: 0.8127, precision: 0.8855, recall: 0.8454, f1: 0.8650, edges-pos-ontonotes_loss: 0.0144
09/16 01:06:05 PM: Update 15430: task edges-pos-ontonotes, batch 430 (15430): mcc: 0.8626, acc: 0.8129, precision: 0.8858, recall: 0.8454, f1: 0.8651, edges-pos-ontonotes_loss: 0.0143
09/16 01:06:15 PM: Update 15493: task edges-pos-ontonotes, batch 493 (15493): mcc: 0.8625, acc: 0.8127, precision: 0.8857, recall: 0.8454, f1: 0.8651, edges-pos-ontonotes_loss: 0.0143
09/16 01:06:26 PM: Update 15553: task edges-pos-ontonotes, batch 553 (15553): mcc: 0.8628, acc: 0.8131, precision: 0.8859, recall: 0.8458, f1: 0.8654, edges-pos-ontonotes_loss: 0.0143
09/16 01:06:36 PM: Update 15604: task edges-pos-ontonotes, batch 604 (15604): mcc: 0.8630, acc: 0.8132, precision: 0.8859, recall: 0.8461, f1: 0.8656, edges-pos-ontonotes_loss: 0.0142
09/16 01:06:46 PM: Update 15646: task edges-pos-ontonotes, batch 646 (15646): mcc: 0.8631, acc: 0.8133, precision: 0.8860, recall: 0.8463, f1: 0.8657, edges-pos-ontonotes_loss: 0.0142
09/16 01:06:56 PM: Update 15690: task edges-pos-ontonotes, batch 690 (15690): mcc: 0.8632, acc: 0.8133, precision: 0.8860, recall: 0.8464, f1: 0.8657, edges-pos-ontonotes_loss: 0.0142
09/16 01:07:07 PM: Update 15719: task edges-pos-ontonotes, batch 719 (15719): mcc: 0.8631, acc: 0.8131, precision: 0.8860, recall: 0.8462, f1: 0.8656, edges-pos-ontonotes_loss: 0.0142
09/16 01:07:17 PM: Update 15780: task edges-pos-ontonotes, batch 780 (15780): mcc: 0.8631, acc: 0.8130, precision: 0.8859, recall: 0.8463, f1: 0.8657, edges-pos-ontonotes_loss: 0.0141
09/16 01:07:28 PM: Update 15844: task edges-pos-ontonotes, batch 844 (15844): mcc: 0.8636, acc: 0.8134, precision: 0.8864, recall: 0.8469, f1: 0.8662, edges-pos-ontonotes_loss: 0.0140
09/16 01:07:38 PM: Update 15931: task edges-pos-ontonotes, batch 931 (15931): mcc: 0.8645, acc: 0.8141, precision: 0.8870, recall: 0.8479, f1: 0.8670, edges-pos-ontonotes_loss: 0.0137
09/16 01:07:45 PM: ***** Step 16000 / Validation 16 *****
09/16 01:07:45 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:07:45 PM: Validating...
09/16 01:07:48 PM: Evaluate: task edges-pos-ontonotes, batch 22 (157): mcc: 0.8551, acc: 0.8168, precision: 0.8858, recall: 0.8310, f1: 0.8575, edges-pos-ontonotes_loss: 0.0145
09/16 01:07:58 PM: Evaluate: task edges-pos-ontonotes, batch 105 (157): mcc: 0.8629, acc: 0.8240, precision: 0.8934, recall: 0.8387, f1: 0.8652, edges-pos-ontonotes_loss: 0.0137
09/16 01:08:06 PM: Updating LR scheduler:
09/16 01:08:06 PM: 	Best result seen so far for macro_avg: 0.874
09/16 01:08:06 PM: 	# validation passes without improvement: 1
09/16 01:08:06 PM: edges-pos-ontonotes_loss: training: 0.013577 validation: 0.013690
09/16 01:08:06 PM: macro_avg: validation: 0.864744
09/16 01:08:06 PM: micro_avg: validation: 0.000000
09/16 01:08:06 PM: edges-pos-ontonotes_mcc: training: 0.865147 validation: 0.862483
09/16 01:08:06 PM: edges-pos-ontonotes_acc: training: 0.814664 validation: 0.823423
09/16 01:08:06 PM: edges-pos-ontonotes_precision: training: 0.887564 validation: 0.895104
09/16 01:08:06 PM: edges-pos-ontonotes_recall: training: 0.848651 validation: 0.836376
09/16 01:08:06 PM: edges-pos-ontonotes_f1: training: 0.867671 validation: 0.864744
09/16 01:08:06 PM: Global learning rate: 0.0001
09/16 01:08:06 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 01:08:08 PM: Update 16018: task edges-pos-ontonotes, batch 18 (16018): mcc: 0.8741, acc: 0.8217, precision: 0.8957, recall: 0.8581, f1: 0.8765, edges-pos-ontonotes_loss: 0.0114
09/16 01:08:18 PM: Update 16105: task edges-pos-ontonotes, batch 105 (16105): mcc: 0.8858, acc: 0.8356, precision: 0.9038, recall: 0.8728, f1: 0.8880, edges-pos-ontonotes_loss: 0.0105
09/16 01:08:28 PM: Update 16220: task edges-pos-ontonotes, batch 220 (16220): mcc: 0.8911, acc: 0.8423, precision: 0.9082, recall: 0.8788, f1: 0.8932, edges-pos-ontonotes_loss: 0.0100
09/16 01:08:38 PM: Update 16336: task edges-pos-ontonotes, batch 336 (16336): mcc: 0.8937, acc: 0.8459, precision: 0.9100, recall: 0.8820, f1: 0.8958, edges-pos-ontonotes_loss: 0.0098
09/16 01:08:48 PM: Update 16454: task edges-pos-ontonotes, batch 454 (16454): mcc: 0.8927, acc: 0.8451, precision: 0.9093, recall: 0.8807, f1: 0.8948, edges-pos-ontonotes_loss: 0.0101
09/16 01:08:58 PM: Update 16592: task edges-pos-ontonotes, batch 592 (16592): mcc: 0.8935, acc: 0.8469, precision: 0.9099, recall: 0.8817, f1: 0.8956, edges-pos-ontonotes_loss: 0.0100
09/16 01:09:08 PM: Update 16729: task edges-pos-ontonotes, batch 729 (16729): mcc: 0.8914, acc: 0.8454, precision: 0.9078, recall: 0.8797, f1: 0.8935, edges-pos-ontonotes_loss: 0.0103
09/16 01:09:18 PM: Update 16911: task edges-pos-ontonotes, batch 911 (16911): mcc: 0.8887, acc: 0.8433, precision: 0.9052, recall: 0.8769, f1: 0.8909, edges-pos-ontonotes_loss: 0.0105
09/16 01:09:29 PM: Update 16999: task edges-pos-ontonotes, batch 999 (16999): mcc: 0.8840, acc: 0.8377, precision: 0.9013, recall: 0.8717, f1: 0.8863, edges-pos-ontonotes_loss: 0.0107
09/16 01:09:29 PM: ***** Step 17000 / Validation 17 *****
09/16 01:09:29 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:09:29 PM: Validating...
09/16 01:09:39 PM: Evaluate: task edges-pos-ontonotes, batch 97 (157): mcc: 0.8674, acc: 0.8422, precision: 0.8886, recall: 0.8519, f1: 0.8699, edges-pos-ontonotes_loss: 0.0134
09/16 01:09:48 PM: Updating LR scheduler:
09/16 01:09:48 PM: 	Best result seen so far for macro_avg: 0.874
09/16 01:09:48 PM: 	# validation passes without improvement: 2
09/16 01:09:48 PM: edges-pos-ontonotes_loss: training: 0.010723 validation: 0.014046
09/16 01:09:48 PM: macro_avg: validation: 0.859264
09/16 01:09:48 PM: micro_avg: validation: 0.000000
09/16 01:09:48 PM: edges-pos-ontonotes_mcc: training: 0.884021 validation: 0.856607
09/16 01:09:48 PM: edges-pos-ontonotes_acc: training: 0.837655 validation: 0.826428
09/16 01:09:48 PM: edges-pos-ontonotes_precision: training: 0.901340 validation: 0.880636
09/16 01:09:48 PM: edges-pos-ontonotes_recall: training: 0.871696 validation: 0.838905
09/16 01:09:48 PM: edges-pos-ontonotes_f1: training: 0.886270 validation: 0.859264
09/16 01:09:48 PM: Global learning rate: 0.0001
09/16 01:09:48 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 01:09:49 PM: Update 17007: task edges-pos-ontonotes, batch 7 (17007): mcc: 0.8415, acc: 0.7836, precision: 0.8677, recall: 0.8223, f1: 0.8444, edges-pos-ontonotes_loss: 0.0163
09/16 01:09:59 PM: Update 17081: task edges-pos-ontonotes, batch 81 (17081): mcc: 0.8431, acc: 0.7865, precision: 0.8703, recall: 0.8228, f1: 0.8459, edges-pos-ontonotes_loss: 0.0163
09/16 01:10:09 PM: Update 17155: task edges-pos-ontonotes, batch 155 (17155): mcc: 0.8454, acc: 0.7881, precision: 0.8727, recall: 0.8250, f1: 0.8482, edges-pos-ontonotes_loss: 0.0162
09/16 01:10:19 PM: Update 17232: task edges-pos-ontonotes, batch 232 (17232): mcc: 0.8463, acc: 0.7892, precision: 0.8745, recall: 0.8250, f1: 0.8491, edges-pos-ontonotes_loss: 0.0162
09/16 01:10:29 PM: Update 17301: task edges-pos-ontonotes, batch 301 (17301): mcc: 0.8452, acc: 0.7878, precision: 0.8740, recall: 0.8234, f1: 0.8480, edges-pos-ontonotes_loss: 0.0162
09/16 01:10:39 PM: Update 17417: task edges-pos-ontonotes, batch 417 (17417): mcc: 0.8487, acc: 0.7928, precision: 0.8759, recall: 0.8283, f1: 0.8514, edges-pos-ontonotes_loss: 0.0152
09/16 01:10:49 PM: Update 17535: task edges-pos-ontonotes, batch 535 (17535): mcc: 0.8520, acc: 0.7975, precision: 0.8781, recall: 0.8324, f1: 0.8546, edges-pos-ontonotes_loss: 0.0146
09/16 01:11:06 PM: Update 17614: task edges-pos-ontonotes, batch 614 (17614): mcc: 0.8534, acc: 0.7998, precision: 0.8789, recall: 0.8344, f1: 0.8561, edges-pos-ontonotes_loss: 0.0142
09/16 01:11:16 PM: Update 17705: task edges-pos-ontonotes, batch 705 (17705): mcc: 0.8548, acc: 0.8014, precision: 0.8797, recall: 0.8363, f1: 0.8574, edges-pos-ontonotes_loss: 0.0141
09/16 01:11:26 PM: Update 17797: task edges-pos-ontonotes, batch 797 (17797): mcc: 0.8563, acc: 0.8029, precision: 0.8807, recall: 0.8382, f1: 0.8589, edges-pos-ontonotes_loss: 0.0139
09/16 01:11:36 PM: Update 17860: task edges-pos-ontonotes, batch 860 (17860): mcc: 0.8574, acc: 0.8042, precision: 0.8816, recall: 0.8395, f1: 0.8600, edges-pos-ontonotes_loss: 0.0138
09/16 01:11:46 PM: Update 17928: task edges-pos-ontonotes, batch 928 (17928): mcc: 0.8578, acc: 0.8045, precision: 0.8819, recall: 0.8399, f1: 0.8604, edges-pos-ontonotes_loss: 0.0138
09/16 01:11:57 PM: Update 17995: task edges-pos-ontonotes, batch 995 (17995): mcc: 0.8572, acc: 0.8036, precision: 0.8811, recall: 0.8396, f1: 0.8598, edges-pos-ontonotes_loss: 0.0138
09/16 01:11:57 PM: ***** Step 18000 / Validation 18 *****
09/16 01:11:57 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:11:57 PM: Validating...
09/16 01:12:07 PM: Evaluate: task edges-pos-ontonotes, batch 94 (157): mcc: 0.8759, acc: 0.8547, precision: 0.8955, recall: 0.8618, f1: 0.8783, edges-pos-ontonotes_loss: 0.0126
09/16 01:12:16 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:12:16 PM: Best result seen so far for macro.
09/16 01:12:16 PM: Updating LR scheduler:
09/16 01:12:16 PM: 	Best result seen so far for macro_avg: 0.874
09/16 01:12:16 PM: 	# validation passes without improvement: 3
09/16 01:12:16 PM: edges-pos-ontonotes_loss: training: 0.013849 validation: 0.012858
09/16 01:12:16 PM: macro_avg: validation: 0.873969
09/16 01:12:16 PM: micro_avg: validation: 0.000000
09/16 01:12:16 PM: edges-pos-ontonotes_mcc: training: 0.857220 validation: 0.871547
09/16 01:12:16 PM: edges-pos-ontonotes_acc: training: 0.803607 validation: 0.847212
09/16 01:12:16 PM: edges-pos-ontonotes_precision: training: 0.881111 validation: 0.892761
09/16 01:12:16 PM: edges-pos-ontonotes_recall: training: 0.839626 validation: 0.855953
09/16 01:12:16 PM: edges-pos-ontonotes_f1: training: 0.859869 validation: 0.873969
09/16 01:12:16 PM: Global learning rate: 0.0001
09/16 01:12:16 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 01:12:17 PM: Update 18004: task edges-pos-ontonotes, batch 4 (18004): mcc: 0.8668, acc: 0.8146, precision: 0.8907, recall: 0.8487, f1: 0.8692, edges-pos-ontonotes_loss: 0.0135
09/16 01:12:27 PM: Update 18070: task edges-pos-ontonotes, batch 70 (18070): mcc: 0.8572, acc: 0.8018, precision: 0.8783, recall: 0.8422, f1: 0.8599, edges-pos-ontonotes_loss: 0.0144
09/16 01:12:37 PM: Update 18143: task edges-pos-ontonotes, batch 143 (18143): mcc: 0.8586, acc: 0.8051, precision: 0.8798, recall: 0.8436, f1: 0.8613, edges-pos-ontonotes_loss: 0.0143
09/16 01:12:47 PM: Update 18219: task edges-pos-ontonotes, batch 219 (18219): mcc: 0.8598, acc: 0.8066, precision: 0.8807, recall: 0.8450, f1: 0.8625, edges-pos-ontonotes_loss: 0.0142
09/16 01:12:57 PM: Update 18273: task edges-pos-ontonotes, batch 273 (18273): mcc: 0.8597, acc: 0.8068, precision: 0.8809, recall: 0.8447, f1: 0.8624, edges-pos-ontonotes_loss: 0.0143
09/16 01:13:07 PM: Update 18322: task edges-pos-ontonotes, batch 322 (18322): mcc: 0.8596, acc: 0.8071, precision: 0.8809, recall: 0.8444, f1: 0.8623, edges-pos-ontonotes_loss: 0.0143
09/16 01:13:17 PM: Update 18388: task edges-pos-ontonotes, batch 388 (18388): mcc: 0.8594, acc: 0.8071, precision: 0.8807, recall: 0.8442, f1: 0.8620, edges-pos-ontonotes_loss: 0.0144
09/16 01:13:28 PM: Update 18455: task edges-pos-ontonotes, batch 455 (18455): mcc: 0.8596, acc: 0.8077, precision: 0.8811, recall: 0.8442, f1: 0.8622, edges-pos-ontonotes_loss: 0.0144
09/16 01:13:38 PM: Update 18525: task edges-pos-ontonotes, batch 525 (18525): mcc: 0.8603, acc: 0.8088, precision: 0.8818, recall: 0.8449, f1: 0.8630, edges-pos-ontonotes_loss: 0.0144
09/16 01:13:48 PM: Update 18575: task edges-pos-ontonotes, batch 575 (18575): mcc: 0.8604, acc: 0.8092, precision: 0.8818, recall: 0.8451, f1: 0.8630, edges-pos-ontonotes_loss: 0.0144
09/16 01:13:58 PM: Update 18646: task edges-pos-ontonotes, batch 646 (18646): mcc: 0.8608, acc: 0.8099, precision: 0.8824, recall: 0.8454, f1: 0.8635, edges-pos-ontonotes_loss: 0.0143
09/16 01:14:08 PM: Update 18721: task edges-pos-ontonotes, batch 721 (18721): mcc: 0.8611, acc: 0.8103, precision: 0.8827, recall: 0.8455, f1: 0.8637, edges-pos-ontonotes_loss: 0.0143
09/16 01:14:18 PM: Update 18785: task edges-pos-ontonotes, batch 785 (18785): mcc: 0.8612, acc: 0.8106, precision: 0.8829, recall: 0.8455, f1: 0.8638, edges-pos-ontonotes_loss: 0.0143
09/16 01:14:28 PM: Update 18853: task edges-pos-ontonotes, batch 853 (18853): mcc: 0.8615, acc: 0.8111, precision: 0.8832, recall: 0.8459, f1: 0.8642, edges-pos-ontonotes_loss: 0.0143
09/16 01:14:39 PM: Update 18890: task edges-pos-ontonotes, batch 890 (18890): mcc: 0.8614, acc: 0.8110, precision: 0.8831, recall: 0.8456, f1: 0.8640, edges-pos-ontonotes_loss: 0.0143
09/16 01:14:49 PM: Update 18962: task edges-pos-ontonotes, batch 962 (18962): mcc: 0.8617, acc: 0.8115, precision: 0.8835, recall: 0.8460, f1: 0.8643, edges-pos-ontonotes_loss: 0.0143
09/16 01:14:54 PM: ***** Step 19000 / Validation 19 *****
09/16 01:14:54 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:14:54 PM: Validating...
09/16 01:14:59 PM: Evaluate: task edges-pos-ontonotes, batch 48 (157): mcc: 0.8619, acc: 0.8353, precision: 0.8801, recall: 0.8497, f1: 0.8646, edges-pos-ontonotes_loss: 0.0138
09/16 01:15:09 PM: Evaluate: task edges-pos-ontonotes, batch 129 (157): mcc: 0.8674, acc: 0.8407, precision: 0.8875, recall: 0.8531, f1: 0.8700, edges-pos-ontonotes_loss: 0.0133
09/16 01:15:13 PM: Updating LR scheduler:
09/16 01:15:13 PM: 	Best result seen so far for macro_avg: 0.874
09/16 01:15:13 PM: 	# validation passes without improvement: 0
09/16 01:15:13 PM: edges-pos-ontonotes_loss: training: 0.014252 validation: 0.013216
09/16 01:15:13 PM: macro_avg: validation: 0.871924
09/16 01:15:13 PM: micro_avg: validation: 0.000000
09/16 01:15:13 PM: edges-pos-ontonotes_mcc: training: 0.861835 validation: 0.869435
09/16 01:15:13 PM: edges-pos-ontonotes_acc: training: 0.811669 validation: 0.842852
09/16 01:15:13 PM: edges-pos-ontonotes_precision: training: 0.883567 validation: 0.889679
09/16 01:15:13 PM: edges-pos-ontonotes_recall: training: 0.846133 validation: 0.854863
09/16 01:15:13 PM: edges-pos-ontonotes_f1: training: 0.864445 validation: 0.871924
09/16 01:15:13 PM: Global learning rate: 5e-05
09/16 01:15:13 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 01:15:19 PM: Update 19032: task edges-pos-ontonotes, batch 32 (19032): mcc: 0.8632, acc: 0.8129, precision: 0.8865, recall: 0.8460, f1: 0.8658, edges-pos-ontonotes_loss: 0.0139
09/16 01:15:29 PM: Update 19102: task edges-pos-ontonotes, batch 102 (19102): mcc: 0.8646, acc: 0.8147, precision: 0.8869, recall: 0.8481, f1: 0.8671, edges-pos-ontonotes_loss: 0.0141
09/16 01:15:39 PM: Update 19173: task edges-pos-ontonotes, batch 173 (19173): mcc: 0.8653, acc: 0.8152, precision: 0.8873, recall: 0.8491, f1: 0.8678, edges-pos-ontonotes_loss: 0.0140
09/16 01:15:50 PM: Update 19179: task edges-pos-ontonotes, batch 179 (19179): mcc: 0.8646, acc: 0.8146, precision: 0.8868, recall: 0.8484, f1: 0.8672, edges-pos-ontonotes_loss: 0.0141
09/16 01:16:00 PM: Update 19254: task edges-pos-ontonotes, batch 254 (19254): mcc: 0.8647, acc: 0.8148, precision: 0.8861, recall: 0.8492, f1: 0.8673, edges-pos-ontonotes_loss: 0.0137
09/16 01:16:10 PM: Update 19345: task edges-pos-ontonotes, batch 345 (19345): mcc: 0.8666, acc: 0.8163, precision: 0.8879, recall: 0.8512, f1: 0.8692, edges-pos-ontonotes_loss: 0.0132
09/16 01:16:21 PM: Update 19430: task edges-pos-ontonotes, batch 430 (19430): mcc: 0.8677, acc: 0.8167, precision: 0.8892, recall: 0.8519, f1: 0.8701, edges-pos-ontonotes_loss: 0.0129
09/16 01:16:31 PM: Update 19510: task edges-pos-ontonotes, batch 510 (19510): mcc: 0.8690, acc: 0.8177, precision: 0.8904, recall: 0.8533, f1: 0.8714, edges-pos-ontonotes_loss: 0.0126
09/16 01:16:41 PM: Update 19631: task edges-pos-ontonotes, batch 631 (19631): mcc: 0.8721, acc: 0.8212, precision: 0.8928, recall: 0.8569, f1: 0.8745, edges-pos-ontonotes_loss: 0.0121
09/16 01:16:51 PM: Update 19742: task edges-pos-ontonotes, batch 742 (19742): mcc: 0.8748, acc: 0.8244, precision: 0.8950, recall: 0.8600, f1: 0.8771, edges-pos-ontonotes_loss: 0.0118
09/16 01:17:01 PM: Update 19851: task edges-pos-ontonotes, batch 851 (19851): mcc: 0.8762, acc: 0.8259, precision: 0.8960, recall: 0.8617, f1: 0.8785, edges-pos-ontonotes_loss: 0.0116
09/16 01:17:11 PM: Update 19974: task edges-pos-ontonotes, batch 974 (19974): mcc: 0.8772, acc: 0.8272, precision: 0.8969, recall: 0.8629, f1: 0.8796, edges-pos-ontonotes_loss: 0.0115
09/16 01:17:13 PM: ***** Step 20000 / Validation 20 *****
09/16 01:17:13 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:17:13 PM: Validating...
09/16 01:17:21 PM: Evaluate: task edges-pos-ontonotes, batch 74 (157): mcc: 0.8609, acc: 0.8219, precision: 0.8972, recall: 0.8314, f1: 0.8631, edges-pos-ontonotes_loss: 0.0137
09/16 01:17:31 PM: Evaluate: task edges-pos-ontonotes, batch 145 (157): mcc: 0.8507, acc: 0.8073, precision: 0.8895, recall: 0.8193, f1: 0.8530, edges-pos-ontonotes_loss: 0.0141
09/16 01:17:33 PM: Updating LR scheduler:
09/16 01:17:33 PM: 	Best result seen so far for macro_avg: 0.874
09/16 01:17:33 PM: 	# validation passes without improvement: 1
09/16 01:17:33 PM: edges-pos-ontonotes_loss: training: 0.011457 validation: 0.014167
09/16 01:17:33 PM: macro_avg: validation: 0.851726
09/16 01:17:33 PM: micro_avg: validation: 0.000000
09/16 01:17:33 PM: edges-pos-ontonotes_mcc: training: 0.877482 validation: 0.849472
09/16 01:17:33 PM: edges-pos-ontonotes_acc: training: 0.827494 validation: 0.805814
09/16 01:17:33 PM: edges-pos-ontonotes_precision: training: 0.897094 validation: 0.888721
09/16 01:17:33 PM: edges-pos-ontonotes_recall: training: 0.863196 validation: 0.817687
09/16 01:17:33 PM: edges-pos-ontonotes_f1: training: 0.879819 validation: 0.851726
09/16 01:17:33 PM: Global learning rate: 5e-05
09/16 01:17:33 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 01:17:41 PM: Update 20106: task edges-pos-ontonotes, batch 106 (20106): mcc: 0.8956, acc: 0.8520, precision: 0.9113, recall: 0.8844, f1: 0.8976, edges-pos-ontonotes_loss: 0.0101
09/16 01:17:51 PM: Update 20266: task edges-pos-ontonotes, batch 266 (20266): mcc: 0.8818, acc: 0.8375, precision: 0.9007, recall: 0.8680, f1: 0.8841, edges-pos-ontonotes_loss: 0.0109
09/16 01:18:01 PM: Update 20418: task edges-pos-ontonotes, batch 418 (20418): mcc: 0.8776, acc: 0.8336, precision: 0.8963, recall: 0.8641, f1: 0.8799, edges-pos-ontonotes_loss: 0.0113
09/16 01:18:11 PM: Update 20487: task edges-pos-ontonotes, batch 487 (20487): mcc: 0.8684, acc: 0.8213, precision: 0.8888, recall: 0.8537, f1: 0.8709, edges-pos-ontonotes_loss: 0.0119
09/16 01:18:21 PM: Update 20565: task edges-pos-ontonotes, batch 565 (20565): mcc: 0.8620, acc: 0.8126, precision: 0.8841, recall: 0.8460, f1: 0.8646, edges-pos-ontonotes_loss: 0.0126
09/16 01:18:31 PM: Update 20647: task edges-pos-ontonotes, batch 647 (20647): mcc: 0.8588, acc: 0.8079, precision: 0.8821, recall: 0.8417, f1: 0.8614, edges-pos-ontonotes_loss: 0.0130
09/16 01:18:41 PM: Update 20718: task edges-pos-ontonotes, batch 718 (20718): mcc: 0.8564, acc: 0.8046, precision: 0.8805, recall: 0.8387, f1: 0.8591, edges-pos-ontonotes_loss: 0.0133
09/16 01:18:51 PM: Update 20790: task edges-pos-ontonotes, batch 790 (20790): mcc: 0.8554, acc: 0.8030, precision: 0.8797, recall: 0.8374, f1: 0.8580, edges-pos-ontonotes_loss: 0.0134
09/16 01:19:01 PM: Update 20903: task edges-pos-ontonotes, batch 903 (20903): mcc: 0.8564, acc: 0.8045, precision: 0.8803, recall: 0.8388, f1: 0.8591, edges-pos-ontonotes_loss: 0.0133
09/16 01:19:09 PM: ***** Step 21000 / Validation 21 *****
09/16 01:19:09 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:19:09 PM: Validating...
09/16 01:19:11 PM: Evaluate: task edges-pos-ontonotes, batch 20 (157): mcc: 0.8660, acc: 0.8348, precision: 0.8935, recall: 0.8447, f1: 0.8684, edges-pos-ontonotes_loss: 0.0133
09/16 01:19:21 PM: Evaluate: task edges-pos-ontonotes, batch 111 (157): mcc: 0.8708, acc: 0.8385, precision: 0.8981, recall: 0.8495, f1: 0.8731, edges-pos-ontonotes_loss: 0.0127
09/16 01:19:28 PM: Updating LR scheduler:
09/16 01:19:28 PM: 	Best result seen so far for macro_avg: 0.874
09/16 01:19:28 PM: 	# validation passes without improvement: 2
09/16 01:19:28 PM: edges-pos-ontonotes_loss: training: 0.013200 validation: 0.013090
09/16 01:19:28 PM: macro_avg: validation: 0.868100
09/16 01:19:28 PM: micro_avg: validation: 0.000000
09/16 01:19:28 PM: edges-pos-ontonotes_mcc: training: 0.857512 validation: 0.865693
09/16 01:19:28 PM: edges-pos-ontonotes_acc: training: 0.806089 validation: 0.833116
09/16 01:19:28 PM: edges-pos-ontonotes_precision: training: 0.880966 validation: 0.891955
09/16 01:19:28 PM: edges-pos-ontonotes_recall: training: 0.840326 validation: 0.845487
09/16 01:19:28 PM: edges-pos-ontonotes_f1: training: 0.860166 validation: 0.868100
09/16 01:19:28 PM: Global learning rate: 5e-05
09/16 01:19:28 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 01:19:32 PM: Update 21034: task edges-pos-ontonotes, batch 34 (21034): mcc: 0.8642, acc: 0.8173, precision: 0.8848, recall: 0.8495, f1: 0.8668, edges-pos-ontonotes_loss: 0.0125
09/16 01:19:42 PM: Update 21112: task edges-pos-ontonotes, batch 112 (21112): mcc: 0.8632, acc: 0.8148, precision: 0.8845, recall: 0.8478, f1: 0.8658, edges-pos-ontonotes_loss: 0.0130
09/16 01:19:52 PM: Update 21200: task edges-pos-ontonotes, batch 200 (21200): mcc: 0.8632, acc: 0.8121, precision: 0.8845, recall: 0.8478, f1: 0.8658, edges-pos-ontonotes_loss: 0.0130
09/16 01:20:02 PM: Update 21299: task edges-pos-ontonotes, batch 299 (21299): mcc: 0.8649, acc: 0.8135, precision: 0.8859, recall: 0.8498, f1: 0.8675, edges-pos-ontonotes_loss: 0.0129
09/16 01:20:22 PM: Update 21387: task edges-pos-ontonotes, batch 387 (21387): mcc: 0.8658, acc: 0.8140, precision: 0.8871, recall: 0.8504, f1: 0.8684, edges-pos-ontonotes_loss: 0.0128
09/16 01:20:32 PM: Update 21457: task edges-pos-ontonotes, batch 457 (21457): mcc: 0.8629, acc: 0.8094, precision: 0.8846, recall: 0.8472, f1: 0.8655, edges-pos-ontonotes_loss: 0.0131
09/16 01:20:42 PM: Update 21526: task edges-pos-ontonotes, batch 526 (21526): mcc: 0.8615, acc: 0.8079, precision: 0.8832, recall: 0.8459, f1: 0.8642, edges-pos-ontonotes_loss: 0.0133
09/16 01:20:53 PM: Update 21591: task edges-pos-ontonotes, batch 591 (21591): mcc: 0.8614, acc: 0.8078, precision: 0.8830, recall: 0.8458, f1: 0.8640, edges-pos-ontonotes_loss: 0.0134
09/16 01:21:03 PM: Update 21650: task edges-pos-ontonotes, batch 650 (21650): mcc: 0.8611, acc: 0.8076, precision: 0.8828, recall: 0.8456, f1: 0.8638, edges-pos-ontonotes_loss: 0.0135
09/16 01:21:13 PM: Update 21700: task edges-pos-ontonotes, batch 700 (21700): mcc: 0.8611, acc: 0.8075, precision: 0.8827, recall: 0.8455, f1: 0.8637, edges-pos-ontonotes_loss: 0.0135
09/16 01:21:23 PM: Update 21762: task edges-pos-ontonotes, batch 762 (21762): mcc: 0.8606, acc: 0.8072, precision: 0.8824, recall: 0.8449, f1: 0.8633, edges-pos-ontonotes_loss: 0.0136
09/16 01:21:33 PM: Update 21829: task edges-pos-ontonotes, batch 829 (21829): mcc: 0.8606, acc: 0.8075, precision: 0.8824, recall: 0.8449, f1: 0.8632, edges-pos-ontonotes_loss: 0.0137
09/16 01:21:43 PM: Update 21895: task edges-pos-ontonotes, batch 895 (21895): mcc: 0.8607, acc: 0.8078, precision: 0.8825, recall: 0.8451, f1: 0.8634, edges-pos-ontonotes_loss: 0.0137
09/16 01:21:53 PM: Update 21967: task edges-pos-ontonotes, batch 967 (21967): mcc: 0.8610, acc: 0.8084, precision: 0.8827, recall: 0.8453, f1: 0.8636, edges-pos-ontonotes_loss: 0.0138
09/16 01:21:57 PM: ***** Step 22000 / Validation 22 *****
09/16 01:21:57 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:21:57 PM: Validating...
09/16 01:22:03 PM: Evaluate: task edges-pos-ontonotes, batch 62 (157): mcc: 0.8694, acc: 0.8471, precision: 0.8879, recall: 0.8565, f1: 0.8719, edges-pos-ontonotes_loss: 0.0131
09/16 01:22:13 PM: Evaluate: task edges-pos-ontonotes, batch 137 (157): mcc: 0.8730, acc: 0.8481, precision: 0.8908, recall: 0.8607, f1: 0.8755, edges-pos-ontonotes_loss: 0.0127
09/16 01:22:16 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:22:16 PM: Best result seen so far for macro.
09/16 01:22:16 PM: Updating LR scheduler:
09/16 01:22:16 PM: 	Best result seen so far for macro_avg: 0.876
09/16 01:22:16 PM: 	# validation passes without improvement: 0
09/16 01:22:16 PM: edges-pos-ontonotes_loss: training: 0.013787 validation: 0.012792
09/16 01:22:16 PM: macro_avg: validation: 0.875816
09/16 01:22:16 PM: micro_avg: validation: 0.000000
09/16 01:22:16 PM: edges-pos-ontonotes_mcc: training: 0.861028 validation: 0.873355
09/16 01:22:16 PM: edges-pos-ontonotes_acc: training: 0.808542 validation: 0.848376
09/16 01:22:16 PM: edges-pos-ontonotes_precision: training: 0.882809 validation: 0.891150
09/16 01:22:16 PM: edges-pos-ontonotes_recall: training: 0.845311 validation: 0.861001
09/16 01:22:16 PM: edges-pos-ontonotes_f1: training: 0.863653 validation: 0.875816
09/16 01:22:16 PM: Global learning rate: 5e-05
09/16 01:22:16 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 01:22:23 PM: Update 22032: task edges-pos-ontonotes, batch 32 (22032): mcc: 0.8570, acc: 0.8074, precision: 0.8801, recall: 0.8401, f1: 0.8596, edges-pos-ontonotes_loss: 0.0151
09/16 01:22:33 PM: Update 22103: task edges-pos-ontonotes, batch 103 (22103): mcc: 0.8608, acc: 0.8109, precision: 0.8837, recall: 0.8441, f1: 0.8634, edges-pos-ontonotes_loss: 0.0146
09/16 01:22:43 PM: Update 22173: task edges-pos-ontonotes, batch 173 (22173): mcc: 0.8615, acc: 0.8114, precision: 0.8843, recall: 0.8447, f1: 0.8641, edges-pos-ontonotes_loss: 0.0144
09/16 01:22:54 PM: Update 22245: task edges-pos-ontonotes, batch 245 (22245): mcc: 0.8623, acc: 0.8127, precision: 0.8851, recall: 0.8455, f1: 0.8648, edges-pos-ontonotes_loss: 0.0142
09/16 01:23:04 PM: Update 22317: task edges-pos-ontonotes, batch 317 (22317): mcc: 0.8629, acc: 0.8136, precision: 0.8855, recall: 0.8463, f1: 0.8655, edges-pos-ontonotes_loss: 0.0141
09/16 01:23:14 PM: Update 22374: task edges-pos-ontonotes, batch 374 (22374): mcc: 0.8631, acc: 0.8141, precision: 0.8856, recall: 0.8466, f1: 0.8657, edges-pos-ontonotes_loss: 0.0141
09/16 01:23:24 PM: Update 22445: task edges-pos-ontonotes, batch 445 (22445): mcc: 0.8635, acc: 0.8144, precision: 0.8859, recall: 0.8471, f1: 0.8661, edges-pos-ontonotes_loss: 0.0141
09/16 01:23:34 PM: Update 22509: task edges-pos-ontonotes, batch 509 (22509): mcc: 0.8639, acc: 0.8147, precision: 0.8863, recall: 0.8474, f1: 0.8664, edges-pos-ontonotes_loss: 0.0141
09/16 01:23:44 PM: Update 22582: task edges-pos-ontonotes, batch 582 (22582): mcc: 0.8638, acc: 0.8146, precision: 0.8862, recall: 0.8475, f1: 0.8664, edges-pos-ontonotes_loss: 0.0141
09/16 01:23:55 PM: Update 22639: task edges-pos-ontonotes, batch 639 (22639): mcc: 0.8634, acc: 0.8140, precision: 0.8857, recall: 0.8472, f1: 0.8660, edges-pos-ontonotes_loss: 0.0141
09/16 01:24:05 PM: Update 22714: task edges-pos-ontonotes, batch 714 (22714): mcc: 0.8638, acc: 0.8143, precision: 0.8858, recall: 0.8477, f1: 0.8663, edges-pos-ontonotes_loss: 0.0140
09/16 01:24:15 PM: Update 22800: task edges-pos-ontonotes, batch 800 (22800): mcc: 0.8649, acc: 0.8152, precision: 0.8868, recall: 0.8489, f1: 0.8674, edges-pos-ontonotes_loss: 0.0137
09/16 01:24:25 PM: Update 22889: task edges-pos-ontonotes, batch 889 (22889): mcc: 0.8656, acc: 0.8157, precision: 0.8875, recall: 0.8497, f1: 0.8682, edges-pos-ontonotes_loss: 0.0135
09/16 01:24:35 PM: Update 22966: task edges-pos-ontonotes, batch 966 (22966): mcc: 0.8662, acc: 0.8162, precision: 0.8881, recall: 0.8502, f1: 0.8687, edges-pos-ontonotes_loss: 0.0133
09/16 01:24:38 PM: ***** Step 23000 / Validation 23 *****
09/16 01:24:38 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:24:38 PM: Validating...
09/16 01:24:46 PM: Evaluate: task edges-pos-ontonotes, batch 74 (157): mcc: 0.8679, acc: 0.8292, precision: 0.8955, recall: 0.8464, f1: 0.8703, edges-pos-ontonotes_loss: 0.0136
09/16 01:24:56 PM: Evaluate: task edges-pos-ontonotes, batch 145 (157): mcc: 0.8667, acc: 0.8286, precision: 0.8960, recall: 0.8435, f1: 0.8690, edges-pos-ontonotes_loss: 0.0133
09/16 01:24:57 PM: Updating LR scheduler:
09/16 01:24:57 PM: 	Best result seen so far for macro_avg: 0.876
09/16 01:24:57 PM: 	# validation passes without improvement: 1
09/16 01:24:57 PM: edges-pos-ontonotes_loss: training: 0.013217 validation: 0.013349
09/16 01:24:57 PM: macro_avg: validation: 0.868911
09/16 01:24:57 PM: micro_avg: validation: 0.000000
09/16 01:24:57 PM: edges-pos-ontonotes_mcc: training: 0.866702 validation: 0.866638
09/16 01:24:57 PM: edges-pos-ontonotes_acc: training: 0.816673 validation: 0.828280
09/16 01:24:57 PM: edges-pos-ontonotes_precision: training: 0.888490 validation: 0.896513
09/16 01:24:57 PM: edges-pos-ontonotes_recall: training: 0.850750 validation: 0.842958
09/16 01:24:57 PM: edges-pos-ontonotes_f1: training: 0.869211 validation: 0.868911
09/16 01:24:57 PM: Global learning rate: 5e-05
09/16 01:24:57 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 01:25:06 PM: Update 23097: task edges-pos-ontonotes, batch 97 (23097): mcc: 0.8941, acc: 0.8464, precision: 0.9114, recall: 0.8813, f1: 0.8961, edges-pos-ontonotes_loss: 0.0098
09/16 01:25:16 PM: Update 23212: task edges-pos-ontonotes, batch 212 (23212): mcc: 0.8961, acc: 0.8492, precision: 0.9122, recall: 0.8844, f1: 0.8981, edges-pos-ontonotes_loss: 0.0096
09/16 01:25:30 PM: Update 23265: task edges-pos-ontonotes, batch 265 (23265): mcc: 0.8961, acc: 0.8492, precision: 0.9124, recall: 0.8843, f1: 0.8981, edges-pos-ontonotes_loss: 0.0096
09/16 01:25:40 PM: Update 23415: task edges-pos-ontonotes, batch 415 (23415): mcc: 0.8942, acc: 0.8472, precision: 0.9109, recall: 0.8821, f1: 0.8963, edges-pos-ontonotes_loss: 0.0101
09/16 01:25:50 PM: Update 23554: task edges-pos-ontonotes, batch 554 (23554): mcc: 0.8943, acc: 0.8481, precision: 0.9104, recall: 0.8828, f1: 0.8964, edges-pos-ontonotes_loss: 0.0101
09/16 01:26:00 PM: Update 23702: task edges-pos-ontonotes, batch 702 (23702): mcc: 0.8906, acc: 0.8447, precision: 0.9072, recall: 0.8787, f1: 0.8928, edges-pos-ontonotes_loss: 0.0105
09/16 01:26:10 PM: Update 23879: task edges-pos-ontonotes, batch 879 (23879): mcc: 0.8876, acc: 0.8421, precision: 0.9048, recall: 0.8753, f1: 0.8898, edges-pos-ontonotes_loss: 0.0106
09/16 01:26:20 PM: Update 23947: task edges-pos-ontonotes, batch 947 (23947): mcc: 0.8815, acc: 0.8347, precision: 0.8998, recall: 0.8684, f1: 0.8838, edges-pos-ontonotes_loss: 0.0110
09/16 01:26:27 PM: ***** Step 24000 / Validation 24 *****
09/16 01:26:27 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:26:27 PM: Validating...
09/16 01:26:30 PM: Evaluate: task edges-pos-ontonotes, batch 34 (157): mcc: 0.8657, acc: 0.8297, precision: 0.8966, recall: 0.8411, f1: 0.8680, edges-pos-ontonotes_loss: 0.0133
09/16 01:26:40 PM: Evaluate: task edges-pos-ontonotes, batch 120 (157): mcc: 0.8657, acc: 0.8298, precision: 0.8937, recall: 0.8439, f1: 0.8681, edges-pos-ontonotes_loss: 0.0130
09/16 01:26:45 PM: Updating LR scheduler:
09/16 01:26:45 PM: 	Best result seen so far for macro_avg: 0.876
09/16 01:26:45 PM: 	# validation passes without improvement: 2
09/16 01:26:45 PM: edges-pos-ontonotes_loss: training: 0.011311 validation: 0.013237
09/16 01:26:45 PM: macro_avg: validation: 0.865046
09/16 01:26:45 PM: micro_avg: validation: 0.000000
09/16 01:26:45 PM: edges-pos-ontonotes_mcc: training: 0.877645 validation: 0.862663
09/16 01:26:45 PM: edges-pos-ontonotes_acc: training: 0.829716 validation: 0.825391
09/16 01:26:45 PM: edges-pos-ontonotes_precision: training: 0.896805 validation: 0.891672
09/16 01:26:45 PM: edges-pos-ontonotes_recall: training: 0.863793 validation: 0.839963
09/16 01:26:45 PM: edges-pos-ontonotes_f1: training: 0.879989 validation: 0.865046
09/16 01:26:45 PM: Global learning rate: 5e-05
09/16 01:26:45 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 01:26:50 PM: Update 24032: task edges-pos-ontonotes, batch 32 (24032): mcc: 0.8412, acc: 0.7828, precision: 0.8734, recall: 0.8164, f1: 0.8440, edges-pos-ontonotes_loss: 0.0162
09/16 01:27:00 PM: Update 24097: task edges-pos-ontonotes, batch 97 (24097): mcc: 0.8454, acc: 0.7886, precision: 0.8748, recall: 0.8230, f1: 0.8481, edges-pos-ontonotes_loss: 0.0159
09/16 01:27:10 PM: Update 24177: task edges-pos-ontonotes, batch 177 (24177): mcc: 0.8470, acc: 0.7906, precision: 0.8752, recall: 0.8257, f1: 0.8497, edges-pos-ontonotes_loss: 0.0157
09/16 01:27:20 PM: Update 24256: task edges-pos-ontonotes, batch 256 (24256): mcc: 0.8474, acc: 0.7911, precision: 0.8753, recall: 0.8264, f1: 0.8501, edges-pos-ontonotes_loss: 0.0154
09/16 01:27:30 PM: Update 24378: task edges-pos-ontonotes, batch 378 (24378): mcc: 0.8514, acc: 0.7973, precision: 0.8776, recall: 0.8318, f1: 0.8541, edges-pos-ontonotes_loss: 0.0144
09/16 01:27:40 PM: Update 24496: task edges-pos-ontonotes, batch 496 (24496): mcc: 0.8545, acc: 0.8017, precision: 0.8794, recall: 0.8361, f1: 0.8572, edges-pos-ontonotes_loss: 0.0139
09/16 01:27:50 PM: Update 24575: task edges-pos-ontonotes, batch 575 (24575): mcc: 0.8561, acc: 0.8038, precision: 0.8802, recall: 0.8383, f1: 0.8587, edges-pos-ontonotes_loss: 0.0137
09/16 01:28:01 PM: Update 24669: task edges-pos-ontonotes, batch 669 (24669): mcc: 0.8576, acc: 0.8052, precision: 0.8813, recall: 0.8402, f1: 0.8603, edges-pos-ontonotes_loss: 0.0136
09/16 01:28:11 PM: Update 24761: task edges-pos-ontonotes, batch 761 (24761): mcc: 0.8589, acc: 0.8066, precision: 0.8821, recall: 0.8418, f1: 0.8615, edges-pos-ontonotes_loss: 0.0135
09/16 01:28:21 PM: Update 24844: task edges-pos-ontonotes, batch 844 (24844): mcc: 0.8602, acc: 0.8080, precision: 0.8832, recall: 0.8433, f1: 0.8628, edges-pos-ontonotes_loss: 0.0134
09/16 01:28:31 PM: Update 24902: task edges-pos-ontonotes, batch 902 (24902): mcc: 0.8591, acc: 0.8064, precision: 0.8822, recall: 0.8423, f1: 0.8618, edges-pos-ontonotes_loss: 0.0135
09/16 01:28:41 PM: Update 24970: task edges-pos-ontonotes, batch 970 (24970): mcc: 0.8587, acc: 0.8058, precision: 0.8817, recall: 0.8419, f1: 0.8614, edges-pos-ontonotes_loss: 0.0135
09/16 01:28:47 PM: ***** Step 25000 / Validation 25 *****
09/16 01:28:47 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:28:47 PM: Validating...
09/16 01:28:51 PM: Evaluate: task edges-pos-ontonotes, batch 29 (157): mcc: 0.8672, acc: 0.8439, precision: 0.8871, recall: 0.8531, f1: 0.8698, edges-pos-ontonotes_loss: 0.0132
09/16 01:29:01 PM: Evaluate: task edges-pos-ontonotes, batch 114 (157): mcc: 0.8762, acc: 0.8532, precision: 0.8951, recall: 0.8626, f1: 0.8786, edges-pos-ontonotes_loss: 0.0124
09/16 01:29:08 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:29:08 PM: Best result seen so far for macro.
09/16 01:29:08 PM: Updating LR scheduler:
09/16 01:29:08 PM: 	Best result seen so far for macro_avg: 0.876
09/16 01:29:08 PM: 	# validation passes without improvement: 0
09/16 01:29:08 PM: edges-pos-ontonotes_loss: training: 0.013552 validation: 0.012682
09/16 01:29:08 PM: macro_avg: validation: 0.875938
09/16 01:29:08 PM: micro_avg: validation: 0.000000
09/16 01:29:08 PM: edges-pos-ontonotes_mcc: training: 0.858761 validation: 0.873518
09/16 01:29:08 PM: edges-pos-ontonotes_acc: training: 0.805869 validation: 0.848895
09/16 01:29:08 PM: edges-pos-ontonotes_precision: training: 0.881673 validation: 0.893054
09/16 01:29:08 PM: edges-pos-ontonotes_recall: training: 0.842046 validation: 0.859466
09/16 01:29:08 PM: edges-pos-ontonotes_f1: training: 0.861404 validation: 0.875938
09/16 01:29:08 PM: Global learning rate: 5e-05
09/16 01:29:08 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 01:29:11 PM: Update 25023: task edges-pos-ontonotes, batch 23 (25023): mcc: 0.8592, acc: 0.8061, precision: 0.8797, recall: 0.8447, f1: 0.8619, edges-pos-ontonotes_loss: 0.0139
09/16 01:29:21 PM: Update 25091: task edges-pos-ontonotes, batch 91 (25091): mcc: 0.8593, acc: 0.8069, precision: 0.8791, recall: 0.8457, f1: 0.8621, edges-pos-ontonotes_loss: 0.0141
09/16 01:29:41 PM: Update 25160: task edges-pos-ontonotes, batch 160 (25160): mcc: 0.8597, acc: 0.8071, precision: 0.8802, recall: 0.8453, f1: 0.8624, edges-pos-ontonotes_loss: 0.0142
09/16 01:29:51 PM: Update 25229: task edges-pos-ontonotes, batch 229 (25229): mcc: 0.8591, acc: 0.8073, precision: 0.8805, recall: 0.8439, f1: 0.8618, edges-pos-ontonotes_loss: 0.0143
09/16 01:30:01 PM: Update 25296: task edges-pos-ontonotes, batch 296 (25296): mcc: 0.8590, acc: 0.8075, precision: 0.8802, recall: 0.8439, f1: 0.8616, edges-pos-ontonotes_loss: 0.0144
09/16 01:30:11 PM: Update 25361: task edges-pos-ontonotes, batch 361 (25361): mcc: 0.8594, acc: 0.8079, precision: 0.8808, recall: 0.8441, f1: 0.8621, edges-pos-ontonotes_loss: 0.0144
09/16 01:30:21 PM: Update 25430: task edges-pos-ontonotes, batch 430 (25430): mcc: 0.8603, acc: 0.8094, precision: 0.8817, recall: 0.8450, f1: 0.8630, edges-pos-ontonotes_loss: 0.0143
09/16 01:30:32 PM: Update 25486: task edges-pos-ontonotes, batch 486 (25486): mcc: 0.8603, acc: 0.8096, precision: 0.8819, recall: 0.8449, f1: 0.8630, edges-pos-ontonotes_loss: 0.0143
09/16 01:30:42 PM: Update 25557: task edges-pos-ontonotes, batch 557 (25557): mcc: 0.8607, acc: 0.8103, precision: 0.8824, recall: 0.8451, f1: 0.8634, edges-pos-ontonotes_loss: 0.0143
09/16 01:30:52 PM: Update 25629: task edges-pos-ontonotes, batch 629 (25629): mcc: 0.8609, acc: 0.8107, precision: 0.8827, recall: 0.8452, f1: 0.8635, edges-pos-ontonotes_loss: 0.0143
09/16 01:31:02 PM: Update 25699: task edges-pos-ontonotes, batch 699 (25699): mcc: 0.8613, acc: 0.8112, precision: 0.8832, recall: 0.8455, f1: 0.8639, edges-pos-ontonotes_loss: 0.0143
09/16 01:31:12 PM: Update 25771: task edges-pos-ontonotes, batch 771 (25771): mcc: 0.8616, acc: 0.8118, precision: 0.8834, recall: 0.8459, f1: 0.8642, edges-pos-ontonotes_loss: 0.0143
09/16 01:31:22 PM: Update 25829: task edges-pos-ontonotes, batch 829 (25829): mcc: 0.8619, acc: 0.8122, precision: 0.8837, recall: 0.8461, f1: 0.8645, edges-pos-ontonotes_loss: 0.0142
09/16 01:31:32 PM: Update 25893: task edges-pos-ontonotes, batch 893 (25893): mcc: 0.8622, acc: 0.8125, precision: 0.8840, recall: 0.8464, f1: 0.8648, edges-pos-ontonotes_loss: 0.0142
09/16 01:31:42 PM: Update 25940: task edges-pos-ontonotes, batch 940 (25940): mcc: 0.8623, acc: 0.8125, precision: 0.8841, recall: 0.8464, f1: 0.8649, edges-pos-ontonotes_loss: 0.0142
09/16 01:31:52 PM: Update 25996: task edges-pos-ontonotes, batch 996 (25996): mcc: 0.8623, acc: 0.8126, precision: 0.8842, recall: 0.8465, f1: 0.8649, edges-pos-ontonotes_loss: 0.0142
09/16 01:31:53 PM: ***** Step 26000 / Validation 26 *****
09/16 01:31:53 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:31:53 PM: Validating...
09/16 01:32:02 PM: Evaluate: task edges-pos-ontonotes, batch 95 (157): mcc: 0.8712, acc: 0.8461, precision: 0.8877, recall: 0.8602, f1: 0.8737, edges-pos-ontonotes_loss: 0.0130
09/16 01:32:12 PM: Updating LR scheduler:
09/16 01:32:12 PM: 	Best result seen so far for macro_avg: 0.876
09/16 01:32:12 PM: 	# validation passes without improvement: 1
09/16 01:32:12 PM: edges-pos-ontonotes_loss: training: 0.014195 validation: 0.012946
09/16 01:32:12 PM: macro_avg: validation: 0.874181
09/16 01:32:12 PM: micro_avg: validation: 0.000000
09/16 01:32:12 PM: edges-pos-ontonotes_mcc: training: 0.862385 validation: 0.871689
09/16 01:32:12 PM: edges-pos-ontonotes_acc: training: 0.812662 validation: 0.845741
09/16 01:32:12 PM: edges-pos-ontonotes_precision: training: 0.884212 validation: 0.889635
09/16 01:32:12 PM: edges-pos-ontonotes_recall: training: 0.846568 validation: 0.859255
09/16 01:32:12 PM: edges-pos-ontonotes_f1: training: 0.864981 validation: 0.874181
09/16 01:32:12 PM: Global learning rate: 5e-05
09/16 01:32:12 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 01:32:13 PM: Update 26007: task edges-pos-ontonotes, batch 7 (26007): mcc: 0.8621, acc: 0.8151, precision: 0.8824, recall: 0.8479, f1: 0.8648, edges-pos-ontonotes_loss: 0.0140
09/16 01:32:23 PM: Update 26071: task edges-pos-ontonotes, batch 71 (26071): mcc: 0.8628, acc: 0.8137, precision: 0.8838, recall: 0.8478, f1: 0.8654, edges-pos-ontonotes_loss: 0.0141
09/16 01:32:33 PM: Update 26138: task edges-pos-ontonotes, batch 138 (26138): mcc: 0.8644, acc: 0.8161, precision: 0.8846, recall: 0.8500, f1: 0.8670, edges-pos-ontonotes_loss: 0.0136
09/16 01:32:43 PM: Update 26221: task edges-pos-ontonotes, batch 221 (26221): mcc: 0.8669, acc: 0.8176, precision: 0.8874, recall: 0.8523, f1: 0.8695, edges-pos-ontonotes_loss: 0.0129
09/16 01:32:53 PM: Update 26304: task edges-pos-ontonotes, batch 304 (26304): mcc: 0.8685, acc: 0.8182, precision: 0.8893, recall: 0.8535, f1: 0.8710, edges-pos-ontonotes_loss: 0.0126
09/16 01:33:03 PM: Update 26389: task edges-pos-ontonotes, batch 389 (26389): mcc: 0.8703, acc: 0.8198, precision: 0.8909, recall: 0.8553, f1: 0.8728, edges-pos-ontonotes_loss: 0.0123
09/16 01:33:13 PM: Update 26479: task edges-pos-ontonotes, batch 479 (26479): mcc: 0.8729, acc: 0.8225, precision: 0.8933, recall: 0.8581, f1: 0.8753, edges-pos-ontonotes_loss: 0.0120
09/16 01:33:23 PM: Update 26596: task edges-pos-ontonotes, batch 596 (26596): mcc: 0.8763, acc: 0.8265, precision: 0.8961, recall: 0.8619, f1: 0.8787, edges-pos-ontonotes_loss: 0.0115
09/16 01:33:33 PM: Update 26702: task edges-pos-ontonotes, batch 702 (26702): mcc: 0.8788, acc: 0.8294, precision: 0.8980, recall: 0.8649, f1: 0.8812, edges-pos-ontonotes_loss: 0.0112
09/16 01:33:43 PM: Update 26813: task edges-pos-ontonotes, batch 813 (26813): mcc: 0.8800, acc: 0.8306, precision: 0.8991, recall: 0.8660, f1: 0.8823, edges-pos-ontonotes_loss: 0.0112
09/16 01:33:53 PM: Update 26961: task edges-pos-ontonotes, batch 961 (26961): mcc: 0.8813, acc: 0.8324, precision: 0.9000, recall: 0.8677, f1: 0.8836, edges-pos-ontonotes_loss: 0.0110
09/16 01:33:56 PM: ***** Step 27000 / Validation 27 *****
09/16 01:33:56 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:33:56 PM: Validating...
09/16 01:34:03 PM: Evaluate: task edges-pos-ontonotes, batch 78 (157): mcc: 0.8656, acc: 0.8422, precision: 0.8891, recall: 0.8480, f1: 0.8681, edges-pos-ontonotes_loss: 0.0137
09/16 01:34:13 PM: Evaluate: task edges-pos-ontonotes, batch 148 (157): mcc: 0.8551, acc: 0.8262, precision: 0.8808, recall: 0.8359, f1: 0.8577, edges-pos-ontonotes_loss: 0.0141
09/16 01:34:14 PM: Updating LR scheduler:
09/16 01:34:14 PM: 	Best result seen so far for macro_avg: 0.876
09/16 01:34:14 PM: 	# validation passes without improvement: 2
09/16 01:34:14 PM: edges-pos-ontonotes_loss: training: 0.010978 validation: 0.014137
09/16 01:34:14 PM: macro_avg: validation: 0.856730
09/16 01:34:14 PM: micro_avg: validation: 0.000000
09/16 01:34:14 PM: edges-pos-ontonotes_mcc: training: 0.881730 validation: 0.854083
09/16 01:34:14 PM: edges-pos-ontonotes_acc: training: 0.833039 validation: 0.824778
09/16 01:34:14 PM: edges-pos-ontonotes_precision: training: 0.900304 validation: 0.880268
09/16 01:34:14 PM: edges-pos-ontonotes_recall: training: 0.868280 validation: 0.834418
09/16 01:34:14 PM: edges-pos-ontonotes_f1: training: 0.884002 validation: 0.856730
09/16 01:34:14 PM: Global learning rate: 5e-05
09/16 01:34:14 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 01:34:23 PM: Update 27116: task edges-pos-ontonotes, batch 116 (27116): mcc: 0.8735, acc: 0.8277, precision: 0.8933, recall: 0.8593, f1: 0.8759, edges-pos-ontonotes_loss: 0.0111
09/16 01:34:33 PM: Update 27298: task edges-pos-ontonotes, batch 298 (27298): mcc: 0.8725, acc: 0.8296, precision: 0.8918, recall: 0.8587, f1: 0.8749, edges-pos-ontonotes_loss: 0.0114
09/16 01:34:46 PM: Update 27351: task edges-pos-ontonotes, batch 351 (27351): mcc: 0.8720, acc: 0.8291, precision: 0.8915, recall: 0.8580, f1: 0.8744, edges-pos-ontonotes_loss: 0.0112
09/16 01:34:56 PM: Update 27427: task edges-pos-ontonotes, batch 427 (27427): mcc: 0.8600, acc: 0.8121, precision: 0.8820, recall: 0.8441, f1: 0.8626, edges-pos-ontonotes_loss: 0.0123
09/16 01:35:06 PM: Update 27506: task edges-pos-ontonotes, batch 506 (27506): mcc: 0.8562, acc: 0.8064, precision: 0.8794, recall: 0.8393, f1: 0.8589, edges-pos-ontonotes_loss: 0.0129
09/16 01:35:16 PM: Update 27584: task edges-pos-ontonotes, batch 584 (27584): mcc: 0.8550, acc: 0.8041, precision: 0.8789, recall: 0.8374, f1: 0.8576, edges-pos-ontonotes_loss: 0.0132
09/16 01:35:26 PM: Update 27655: task edges-pos-ontonotes, batch 655 (27655): mcc: 0.8534, acc: 0.8014, precision: 0.8782, recall: 0.8352, f1: 0.8561, edges-pos-ontonotes_loss: 0.0135
09/16 01:35:36 PM: Update 27745: task edges-pos-ontonotes, batch 745 (27745): mcc: 0.8531, acc: 0.8009, precision: 0.8779, recall: 0.8349, f1: 0.8559, edges-pos-ontonotes_loss: 0.0136
09/16 01:35:46 PM: Update 27869: task edges-pos-ontonotes, batch 869 (27869): mcc: 0.8548, acc: 0.8032, precision: 0.8790, recall: 0.8370, f1: 0.8575, edges-pos-ontonotes_loss: 0.0134
09/16 01:35:56 PM: Update 27970: task edges-pos-ontonotes, batch 970 (27970): mcc: 0.8559, acc: 0.8048, precision: 0.8794, recall: 0.8387, f1: 0.8586, edges-pos-ontonotes_loss: 0.0133
09/16 01:36:02 PM: ***** Step 28000 / Validation 28 *****
09/16 01:36:02 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:36:02 PM: Validating...
09/16 01:36:06 PM: Evaluate: task edges-pos-ontonotes, batch 44 (157): mcc: 0.8694, acc: 0.8453, precision: 0.8914, recall: 0.8532, f1: 0.8719, edges-pos-ontonotes_loss: 0.0128
09/16 01:36:17 PM: Evaluate: task edges-pos-ontonotes, batch 127 (157): mcc: 0.8686, acc: 0.8435, precision: 0.8905, recall: 0.8524, f1: 0.8711, edges-pos-ontonotes_loss: 0.0128
09/16 01:36:21 PM: Updating LR scheduler:
09/16 01:36:21 PM: 	Best result seen so far for macro_avg: 0.876
09/16 01:36:21 PM: 	# validation passes without improvement: 3
09/16 01:36:21 PM: edges-pos-ontonotes_loss: training: 0.013219 validation: 0.012991
09/16 01:36:21 PM: macro_avg: validation: 0.868575
09/16 01:36:21 PM: micro_avg: validation: 0.000000
09/16 01:36:21 PM: edges-pos-ontonotes_mcc: training: 0.856356 validation: 0.866042
09/16 01:36:21 PM: edges-pos-ontonotes_acc: training: 0.805448 validation: 0.840513
09/16 01:36:21 PM: edges-pos-ontonotes_precision: training: 0.879725 validation: 0.887385
09/16 01:36:21 PM: edges-pos-ontonotes_recall: training: 0.839299 validation: 0.850546
09/16 01:36:21 PM: edges-pos-ontonotes_f1: training: 0.859037 validation: 0.868575
09/16 01:36:21 PM: Global learning rate: 5e-05
09/16 01:36:21 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 01:36:27 PM: Update 28053: task edges-pos-ontonotes, batch 53 (28053): mcc: 0.8652, acc: 0.8153, precision: 0.8871, recall: 0.8492, f1: 0.8677, edges-pos-ontonotes_loss: 0.0132
09/16 01:36:37 PM: Update 28150: task edges-pos-ontonotes, batch 150 (28150): mcc: 0.8659, acc: 0.8140, precision: 0.8870, recall: 0.8507, f1: 0.8685, edges-pos-ontonotes_loss: 0.0129
09/16 01:36:47 PM: Update 28240: task edges-pos-ontonotes, batch 240 (28240): mcc: 0.8665, acc: 0.8142, precision: 0.8878, recall: 0.8511, f1: 0.8691, edges-pos-ontonotes_loss: 0.0128
09/16 01:36:57 PM: Update 28308: task edges-pos-ontonotes, batch 308 (28308): mcc: 0.8657, acc: 0.8135, precision: 0.8871, recall: 0.8501, f1: 0.8682, edges-pos-ontonotes_loss: 0.0128
09/16 01:37:07 PM: Update 28376: task edges-pos-ontonotes, batch 376 (28376): mcc: 0.8630, acc: 0.8097, precision: 0.8845, recall: 0.8475, f1: 0.8656, edges-pos-ontonotes_loss: 0.0131
09/16 01:37:17 PM: Update 28437: task edges-pos-ontonotes, batch 437 (28437): mcc: 0.8619, acc: 0.8087, precision: 0.8835, recall: 0.8464, f1: 0.8645, edges-pos-ontonotes_loss: 0.0133
09/16 01:37:27 PM: Update 28513: task edges-pos-ontonotes, batch 513 (28513): mcc: 0.8613, acc: 0.8080, precision: 0.8825, recall: 0.8461, f1: 0.8639, edges-pos-ontonotes_loss: 0.0135
09/16 01:37:38 PM: Update 28581: task edges-pos-ontonotes, batch 581 (28581): mcc: 0.8610, acc: 0.8078, precision: 0.8822, recall: 0.8459, f1: 0.8637, edges-pos-ontonotes_loss: 0.0135
09/16 01:37:48 PM: Update 28639: task edges-pos-ontonotes, batch 639 (28639): mcc: 0.8607, acc: 0.8077, precision: 0.8820, recall: 0.8456, f1: 0.8634, edges-pos-ontonotes_loss: 0.0136
09/16 01:37:58 PM: Update 28705: task edges-pos-ontonotes, batch 705 (28705): mcc: 0.8607, acc: 0.8082, precision: 0.8821, recall: 0.8454, f1: 0.8634, edges-pos-ontonotes_loss: 0.0137
09/16 01:38:08 PM: Update 28778: task edges-pos-ontonotes, batch 778 (28778): mcc: 0.8608, acc: 0.8088, precision: 0.8822, recall: 0.8454, f1: 0.8634, edges-pos-ontonotes_loss: 0.0137
09/16 01:38:18 PM: Update 28848: task edges-pos-ontonotes, batch 848 (28848): mcc: 0.8608, acc: 0.8090, precision: 0.8822, recall: 0.8455, f1: 0.8635, edges-pos-ontonotes_loss: 0.0138
09/16 01:38:28 PM: Update 28917: task edges-pos-ontonotes, batch 917 (28917): mcc: 0.8610, acc: 0.8095, precision: 0.8824, recall: 0.8457, f1: 0.8636, edges-pos-ontonotes_loss: 0.0138
09/16 01:38:38 PM: Update 28964: task edges-pos-ontonotes, batch 964 (28964): mcc: 0.8610, acc: 0.8097, precision: 0.8824, recall: 0.8456, f1: 0.8636, edges-pos-ontonotes_loss: 0.0138
09/16 01:38:44 PM: ***** Step 29000 / Validation 29 *****
09/16 01:38:44 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:38:44 PM: Validating...
09/16 01:38:48 PM: Evaluate: task edges-pos-ontonotes, batch 46 (157): mcc: 0.8627, acc: 0.8397, precision: 0.8832, recall: 0.8482, f1: 0.8654, edges-pos-ontonotes_loss: 0.0134
09/16 01:38:58 PM: Evaluate: task edges-pos-ontonotes, batch 126 (157): mcc: 0.8719, acc: 0.8475, precision: 0.8921, recall: 0.8572, f1: 0.8743, edges-pos-ontonotes_loss: 0.0128
09/16 01:39:03 PM: Updating LR scheduler:
09/16 01:39:03 PM: 	Best result seen so far for macro_avg: 0.876
09/16 01:39:03 PM: 	# validation passes without improvement: 0
09/16 01:39:03 PM: edges-pos-ontonotes_loss: training: 0.013831 validation: 0.012757
09/16 01:39:03 PM: macro_avg: validation: 0.875384
09/16 01:39:03 PM: micro_avg: validation: 0.000000
09/16 01:39:03 PM: edges-pos-ontonotes_mcc: training: 0.860983 validation: 0.872963
09/16 01:39:03 PM: edges-pos-ontonotes_acc: training: 0.809833 validation: 0.848270
09/16 01:39:03 PM: edges-pos-ontonotes_precision: training: 0.882451 validation: 0.893000
09/16 01:39:03 PM: edges-pos-ontonotes_recall: training: 0.845572 validation: 0.858451
09/16 01:39:03 PM: edges-pos-ontonotes_f1: training: 0.863618 validation: 0.875384
09/16 01:39:03 PM: Global learning rate: 2.5e-05
09/16 01:39:03 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 01:39:09 PM: Update 29041: task edges-pos-ontonotes, batch 41 (29041): mcc: 0.8634, acc: 0.8142, precision: 0.8869, recall: 0.8459, f1: 0.8659, edges-pos-ontonotes_loss: 0.0145
09/16 01:39:19 PM: Update 29116: task edges-pos-ontonotes, batch 116 (29116): mcc: 0.8648, acc: 0.8156, precision: 0.8877, recall: 0.8479, f1: 0.8674, edges-pos-ontonotes_loss: 0.0144
09/16 01:39:29 PM: Update 29179: task edges-pos-ontonotes, batch 179 (29179): mcc: 0.8643, acc: 0.8151, precision: 0.8873, recall: 0.8473, f1: 0.8668, edges-pos-ontonotes_loss: 0.0142
09/16 01:39:49 PM: Update 29246: task edges-pos-ontonotes, batch 246 (29246): mcc: 0.8639, acc: 0.8152, precision: 0.8868, recall: 0.8471, f1: 0.8665, edges-pos-ontonotes_loss: 0.0142
09/16 01:39:59 PM: Update 29311: task edges-pos-ontonotes, batch 311 (29311): mcc: 0.8638, acc: 0.8151, precision: 0.8865, recall: 0.8471, f1: 0.8663, edges-pos-ontonotes_loss: 0.0141
09/16 01:40:09 PM: Update 29382: task edges-pos-ontonotes, batch 382 (29382): mcc: 0.8635, acc: 0.8147, precision: 0.8860, recall: 0.8470, f1: 0.8661, edges-pos-ontonotes_loss: 0.0142
09/16 01:40:19 PM: Update 29454: task edges-pos-ontonotes, batch 454 (29454): mcc: 0.8635, acc: 0.8145, precision: 0.8860, recall: 0.8470, f1: 0.8661, edges-pos-ontonotes_loss: 0.0142
09/16 01:40:29 PM: Update 29525: task edges-pos-ontonotes, batch 525 (29525): mcc: 0.8640, acc: 0.8151, precision: 0.8864, recall: 0.8476, f1: 0.8666, edges-pos-ontonotes_loss: 0.0141
09/16 01:40:39 PM: Update 29582: task edges-pos-ontonotes, batch 582 (29582): mcc: 0.8639, acc: 0.8150, precision: 0.8861, recall: 0.8475, f1: 0.8664, edges-pos-ontonotes_loss: 0.0141
09/16 01:40:49 PM: Update 29663: task edges-pos-ontonotes, batch 663 (29663): mcc: 0.8649, acc: 0.8159, precision: 0.8869, recall: 0.8488, f1: 0.8675, edges-pos-ontonotes_loss: 0.0138
09/16 01:41:00 PM: Update 29753: task edges-pos-ontonotes, batch 753 (29753): mcc: 0.8657, acc: 0.8165, precision: 0.8876, recall: 0.8496, f1: 0.8682, edges-pos-ontonotes_loss: 0.0136
09/16 01:41:10 PM: Update 29823: task edges-pos-ontonotes, batch 823 (29823): mcc: 0.8663, acc: 0.8170, precision: 0.8882, recall: 0.8503, f1: 0.8688, edges-pos-ontonotes_loss: 0.0134
09/16 01:41:20 PM: Update 29913: task edges-pos-ontonotes, batch 913 (29913): mcc: 0.8674, acc: 0.8180, precision: 0.8891, recall: 0.8515, f1: 0.8699, edges-pos-ontonotes_loss: 0.0132
09/16 01:41:28 PM: ***** Step 30000 / Validation 30 *****
09/16 01:41:28 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:41:28 PM: Validating...
09/16 01:41:30 PM: Evaluate: task edges-pos-ontonotes, batch 24 (157): mcc: 0.8628, acc: 0.8294, precision: 0.8913, recall: 0.8405, f1: 0.8652, edges-pos-ontonotes_loss: 0.0139
09/16 01:41:40 PM: Evaluate: task edges-pos-ontonotes, batch 113 (157): mcc: 0.8687, acc: 0.8340, precision: 0.8989, recall: 0.8445, f1: 0.8709, edges-pos-ontonotes_loss: 0.0132
09/16 01:41:47 PM: Updating LR scheduler:
09/16 01:41:47 PM: 	Best result seen so far for macro_avg: 0.876
09/16 01:41:47 PM: 	# validation passes without improvement: 1
09/16 01:41:47 PM: edges-pos-ontonotes_loss: training: 0.012923 validation: 0.013199
09/16 01:41:47 PM: macro_avg: validation: 0.869502
09/16 01:41:47 PM: micro_avg: validation: 0.000000
09/16 01:41:47 PM: edges-pos-ontonotes_mcc: training: 0.868720 validation: 0.867350
09/16 01:41:47 PM: edges-pos-ontonotes_acc: training: 0.819315 validation: 0.830841
09/16 01:41:47 PM: edges-pos-ontonotes_precision: training: 0.890086 validation: 0.900282
09/16 01:41:47 PM: edges-pos-ontonotes_recall: training: 0.853093 validation: 0.840757
09/16 01:41:47 PM: edges-pos-ontonotes_f1: training: 0.871197 validation: 0.869502
09/16 01:41:47 PM: Global learning rate: 2.5e-05
09/16 01:41:47 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 01:41:50 PM: Update 30042: task edges-pos-ontonotes, batch 42 (30042): mcc: 0.8934, acc: 0.8453, precision: 0.9086, recall: 0.8827, f1: 0.8954, edges-pos-ontonotes_loss: 0.0099
09/16 01:42:00 PM: Update 30158: task edges-pos-ontonotes, batch 158 (30158): mcc: 0.8957, acc: 0.8496, precision: 0.9113, recall: 0.8845, f1: 0.8977, edges-pos-ontonotes_loss: 0.0098
09/16 01:42:10 PM: Update 30266: task edges-pos-ontonotes, batch 266 (30266): mcc: 0.8927, acc: 0.8457, precision: 0.9092, recall: 0.8807, f1: 0.8948, edges-pos-ontonotes_loss: 0.0104
09/16 01:42:20 PM: Update 30408: task edges-pos-ontonotes, batch 408 (30408): mcc: 0.8929, acc: 0.8455, precision: 0.9095, recall: 0.8809, f1: 0.8950, edges-pos-ontonotes_loss: 0.0103
09/16 01:42:30 PM: Update 30540: task edges-pos-ontonotes, batch 540 (30540): mcc: 0.8901, acc: 0.8425, precision: 0.9075, recall: 0.8773, f1: 0.8922, edges-pos-ontonotes_loss: 0.0105
09/16 01:42:40 PM: Update 30715: task edges-pos-ontonotes, batch 715 (30715): mcc: 0.8866, acc: 0.8398, precision: 0.9050, recall: 0.8731, f1: 0.8887, edges-pos-ontonotes_loss: 0.0108
09/16 01:42:50 PM: Update 30829: task edges-pos-ontonotes, batch 829 (30829): mcc: 0.8827, acc: 0.8359, precision: 0.9018, recall: 0.8687, f1: 0.8850, edges-pos-ontonotes_loss: 0.0109
09/16 01:43:00 PM: Update 30911: task edges-pos-ontonotes, batch 911 (30911): mcc: 0.8761, acc: 0.8279, precision: 0.8965, recall: 0.8611, f1: 0.8784, edges-pos-ontonotes_loss: 0.0114
09/16 01:43:11 PM: Update 30985: task edges-pos-ontonotes, batch 985 (30985): mcc: 0.8716, acc: 0.8223, precision: 0.8928, recall: 0.8560, f1: 0.8740, edges-pos-ontonotes_loss: 0.0118
09/16 01:43:13 PM: ***** Step 31000 / Validation 31 *****
09/16 01:43:13 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:43:13 PM: Validating...
09/16 01:43:21 PM: Evaluate: task edges-pos-ontonotes, batch 81 (157): mcc: 0.8727, acc: 0.8403, precision: 0.9002, recall: 0.8511, f1: 0.8750, edges-pos-ontonotes_loss: 0.0126
09/16 01:43:31 PM: Evaluate: task edges-pos-ontonotes, batch 150 (157): mcc: 0.8653, acc: 0.8307, precision: 0.8931, recall: 0.8436, f1: 0.8676, edges-pos-ontonotes_loss: 0.0130
09/16 01:43:32 PM: Updating LR scheduler:
09/16 01:43:32 PM: 	Best result seen so far for macro_avg: 0.876
09/16 01:43:32 PM: 	# validation passes without improvement: 2
09/16 01:43:32 PM: edges-pos-ontonotes_loss: training: 0.011874 validation: 0.013011
09/16 01:43:32 PM: macro_avg: validation: 0.866801
09/16 01:43:32 PM: micro_avg: validation: 0.000000
09/16 01:43:32 PM: edges-pos-ontonotes_mcc: training: 0.870780 validation: 0.864431
09/16 01:43:32 PM: edges-pos-ontonotes_acc: training: 0.821311 validation: 0.829561
09/16 01:43:32 PM: edges-pos-ontonotes_precision: training: 0.892190 validation: 0.892743
09/16 01:43:32 PM: edges-pos-ontonotes_recall: training: 0.855028 validation: 0.842323
09/16 01:43:32 PM: edges-pos-ontonotes_f1: training: 0.873214 validation: 0.866801
09/16 01:43:32 PM: Global learning rate: 2.5e-05
09/16 01:43:32 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 01:43:41 PM: Update 31062: task edges-pos-ontonotes, batch 62 (31062): mcc: 0.8489, acc: 0.7947, precision: 0.8747, recall: 0.8298, f1: 0.8517, edges-pos-ontonotes_loss: 0.0155
09/16 01:43:51 PM: Update 31129: task edges-pos-ontonotes, batch 129 (31129): mcc: 0.8466, acc: 0.7907, precision: 0.8736, recall: 0.8264, f1: 0.8494, edges-pos-ontonotes_loss: 0.0159
09/16 01:44:01 PM: Update 31229: task edges-pos-ontonotes, batch 229 (31229): mcc: 0.8497, acc: 0.7953, precision: 0.8756, recall: 0.8305, f1: 0.8525, edges-pos-ontonotes_loss: 0.0147
09/16 01:44:11 PM: Update 31339: task edges-pos-ontonotes, batch 339 (31339): mcc: 0.8543, acc: 0.8020, precision: 0.8787, recall: 0.8364, f1: 0.8570, edges-pos-ontonotes_loss: 0.0139
09/16 01:44:32 PM: Update 31454: task edges-pos-ontonotes, batch 454 (31454): mcc: 0.8569, acc: 0.8062, precision: 0.8802, recall: 0.8399, f1: 0.8596, edges-pos-ontonotes_loss: 0.0134
09/16 01:44:42 PM: Update 31544: task edges-pos-ontonotes, batch 544 (31544): mcc: 0.8584, acc: 0.8079, precision: 0.8813, recall: 0.8417, f1: 0.8611, edges-pos-ontonotes_loss: 0.0134
09/16 01:44:52 PM: Update 31628: task edges-pos-ontonotes, batch 628 (31628): mcc: 0.8596, acc: 0.8089, precision: 0.8821, recall: 0.8432, f1: 0.8622, edges-pos-ontonotes_loss: 0.0133
09/16 01:45:02 PM: Update 31726: task edges-pos-ontonotes, batch 726 (31726): mcc: 0.8608, acc: 0.8099, precision: 0.8831, recall: 0.8445, f1: 0.8634, edges-pos-ontonotes_loss: 0.0132
09/16 01:45:12 PM: Update 31790: task edges-pos-ontonotes, batch 790 (31790): mcc: 0.8601, acc: 0.8087, precision: 0.8826, recall: 0.8437, f1: 0.8627, edges-pos-ontonotes_loss: 0.0133
09/16 01:45:22 PM: Update 31850: task edges-pos-ontonotes, batch 850 (31850): mcc: 0.8592, acc: 0.8071, precision: 0.8818, recall: 0.8428, f1: 0.8619, edges-pos-ontonotes_loss: 0.0134
09/16 01:45:32 PM: Update 31915: task edges-pos-ontonotes, batch 915 (31915): mcc: 0.8592, acc: 0.8067, precision: 0.8816, recall: 0.8429, f1: 0.8618, edges-pos-ontonotes_loss: 0.0134
09/16 01:45:42 PM: Update 31983: task edges-pos-ontonotes, batch 983 (31983): mcc: 0.8591, acc: 0.8064, precision: 0.8814, recall: 0.8429, f1: 0.8617, edges-pos-ontonotes_loss: 0.0135
09/16 01:45:45 PM: ***** Step 32000 / Validation 32 *****
09/16 01:45:45 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:45:45 PM: Validating...
09/16 01:45:52 PM: Evaluate: task edges-pos-ontonotes, batch 77 (157): mcc: 0.8747, acc: 0.8533, precision: 0.8941, recall: 0.8608, f1: 0.8771, edges-pos-ontonotes_loss: 0.0126
09/16 01:46:02 PM: Evaluate: task edges-pos-ontonotes, batch 147 (157): mcc: 0.8745, acc: 0.8503, precision: 0.8923, recall: 0.8621, f1: 0.8769, edges-pos-ontonotes_loss: 0.0126
09/16 01:46:04 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:46:04 PM: Best result seen so far for macro.
09/16 01:46:04 PM: Updating LR scheduler:
09/16 01:46:04 PM: 	Best result seen so far for macro_avg: 0.877
09/16 01:46:04 PM: 	# validation passes without improvement: 0
09/16 01:46:04 PM: edges-pos-ontonotes_loss: training: 0.013479 validation: 0.012650
09/16 01:46:04 PM: macro_avg: validation: 0.876988
09/16 01:46:04 PM: micro_avg: validation: 0.000000
09/16 01:46:04 PM: edges-pos-ontonotes_mcc: training: 0.859012 validation: 0.874554
09/16 01:46:04 PM: edges-pos-ontonotes_acc: training: 0.806288 validation: 0.850376
09/16 01:46:04 PM: edges-pos-ontonotes_precision: training: 0.881283 validation: 0.892476
09/16 01:46:04 PM: edges-pos-ontonotes_recall: training: 0.842904 validation: 0.862027
09/16 01:46:04 PM: edges-pos-ontonotes_f1: training: 0.861667 validation: 0.876988
09/16 01:46:04 PM: Global learning rate: 2.5e-05
09/16 01:46:04 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 01:46:12 PM: Update 32069: task edges-pos-ontonotes, batch 69 (32069): mcc: 0.8580, acc: 0.8052, precision: 0.8793, recall: 0.8428, f1: 0.8607, edges-pos-ontonotes_loss: 0.0144
09/16 01:46:22 PM: Update 32123: task edges-pos-ontonotes, batch 123 (32123): mcc: 0.8580, acc: 0.8062, precision: 0.8795, recall: 0.8426, f1: 0.8607, edges-pos-ontonotes_loss: 0.0145
09/16 01:46:33 PM: Update 32194: task edges-pos-ontonotes, batch 194 (32194): mcc: 0.8595, acc: 0.8081, precision: 0.8813, recall: 0.8439, f1: 0.8622, edges-pos-ontonotes_loss: 0.0144
09/16 01:46:43 PM: Update 32264: task edges-pos-ontonotes, batch 264 (32264): mcc: 0.8592, acc: 0.8080, precision: 0.8810, recall: 0.8436, f1: 0.8619, edges-pos-ontonotes_loss: 0.0144
09/16 01:46:53 PM: Update 32333: task edges-pos-ontonotes, batch 333 (32333): mcc: 0.8601, acc: 0.8096, precision: 0.8819, recall: 0.8444, f1: 0.8627, edges-pos-ontonotes_loss: 0.0144
09/16 01:47:04 PM: Update 32393: task edges-pos-ontonotes, batch 393 (32393): mcc: 0.8603, acc: 0.8099, precision: 0.8820, recall: 0.8446, f1: 0.8629, edges-pos-ontonotes_loss: 0.0143
09/16 01:47:14 PM: Update 32453: task edges-pos-ontonotes, batch 453 (32453): mcc: 0.8604, acc: 0.8103, precision: 0.8824, recall: 0.8445, f1: 0.8631, edges-pos-ontonotes_loss: 0.0144
09/16 01:47:24 PM: Update 32508: task edges-pos-ontonotes, batch 508 (32508): mcc: 0.8604, acc: 0.8103, precision: 0.8825, recall: 0.8444, f1: 0.8630, edges-pos-ontonotes_loss: 0.0144
09/16 01:47:35 PM: Update 32576: task edges-pos-ontonotes, batch 576 (32576): mcc: 0.8606, acc: 0.8105, precision: 0.8825, recall: 0.8447, f1: 0.8632, edges-pos-ontonotes_loss: 0.0144
09/16 01:47:45 PM: Update 32647: task edges-pos-ontonotes, batch 647 (32647): mcc: 0.8611, acc: 0.8112, precision: 0.8830, recall: 0.8451, f1: 0.8637, edges-pos-ontonotes_loss: 0.0143
09/16 01:47:56 PM: Update 32706: task edges-pos-ontonotes, batch 706 (32706): mcc: 0.8615, acc: 0.8118, precision: 0.8836, recall: 0.8455, f1: 0.8641, edges-pos-ontonotes_loss: 0.0143
09/16 01:48:06 PM: Update 32778: task edges-pos-ontonotes, batch 778 (32778): mcc: 0.8618, acc: 0.8122, precision: 0.8839, recall: 0.8458, f1: 0.8644, edges-pos-ontonotes_loss: 0.0142
09/16 01:48:16 PM: Update 32844: task edges-pos-ontonotes, batch 844 (32844): mcc: 0.8622, acc: 0.8128, precision: 0.8841, recall: 0.8463, f1: 0.8648, edges-pos-ontonotes_loss: 0.0142
09/16 01:48:26 PM: Update 32901: task edges-pos-ontonotes, batch 901 (32901): mcc: 0.8623, acc: 0.8128, precision: 0.8842, recall: 0.8463, f1: 0.8648, edges-pos-ontonotes_loss: 0.0142
09/16 01:48:36 PM: Update 32946: task edges-pos-ontonotes, batch 946 (32946): mcc: 0.8622, acc: 0.8127, precision: 0.8841, recall: 0.8463, f1: 0.8648, edges-pos-ontonotes_loss: 0.0142
09/16 01:48:46 PM: Update 32992: task edges-pos-ontonotes, batch 992 (32992): mcc: 0.8623, acc: 0.8129, precision: 0.8843, recall: 0.8464, f1: 0.8649, edges-pos-ontonotes_loss: 0.0142
09/16 01:48:48 PM: ***** Step 33000 / Validation 33 *****
09/16 01:48:48 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:48:48 PM: Validating...
09/16 01:48:56 PM: Evaluate: task edges-pos-ontonotes, batch 70 (157): mcc: 0.8710, acc: 0.8483, precision: 0.8904, recall: 0.8572, f1: 0.8735, edges-pos-ontonotes_loss: 0.0130
09/16 01:49:06 PM: Evaluate: task edges-pos-ontonotes, batch 142 (157): mcc: 0.8723, acc: 0.8478, precision: 0.8918, recall: 0.8583, f1: 0.8747, edges-pos-ontonotes_loss: 0.0128
09/16 01:49:08 PM: Updating LR scheduler:
09/16 01:49:08 PM: 	Best result seen so far for macro_avg: 0.877
09/16 01:49:08 PM: 	# validation passes without improvement: 1
09/16 01:49:08 PM: edges-pos-ontonotes_loss: training: 0.014220 validation: 0.012796
09/16 01:49:08 PM: macro_avg: validation: 0.875491
09/16 01:49:08 PM: micro_avg: validation: 0.000000
09/16 01:49:08 PM: edges-pos-ontonotes_mcc: training: 0.862361 validation: 0.873060
09/16 01:49:08 PM: edges-pos-ontonotes_acc: training: 0.812861 validation: 0.848630
09/16 01:49:08 PM: edges-pos-ontonotes_precision: training: 0.884311 validation: 0.892558
09/16 01:49:08 PM: edges-pos-ontonotes_recall: training: 0.846429 validation: 0.859064
09/16 01:49:08 PM: edges-pos-ontonotes_f1: training: 0.864955 validation: 0.875491
09/16 01:49:08 PM: Global learning rate: 2.5e-05
09/16 01:49:08 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 01:49:22 PM: Update 33019: task edges-pos-ontonotes, batch 19 (33019): mcc: 0.8479, acc: 0.7964, precision: 0.8708, recall: 0.8317, f1: 0.8508, edges-pos-ontonotes_loss: 0.0148
09/16 01:49:32 PM: Update 33100: task edges-pos-ontonotes, batch 100 (33100): mcc: 0.8657, acc: 0.8171, precision: 0.8841, recall: 0.8531, f1: 0.8683, edges-pos-ontonotes_loss: 0.0123
09/16 01:49:43 PM: Update 33181: task edges-pos-ontonotes, batch 181 (33181): mcc: 0.8677, acc: 0.8183, precision: 0.8872, recall: 0.8539, f1: 0.8703, edges-pos-ontonotes_loss: 0.0123
09/16 01:49:53 PM: Update 33266: task edges-pos-ontonotes, batch 266 (33266): mcc: 0.8705, acc: 0.8205, precision: 0.8904, recall: 0.8562, f1: 0.8729, edges-pos-ontonotes_loss: 0.0120
09/16 01:50:03 PM: Update 33338: task edges-pos-ontonotes, batch 338 (33338): mcc: 0.8720, acc: 0.8218, precision: 0.8919, recall: 0.8575, f1: 0.8744, edges-pos-ontonotes_loss: 0.0118
09/16 01:50:13 PM: Update 33454: task edges-pos-ontonotes, batch 454 (33454): mcc: 0.8755, acc: 0.8258, precision: 0.8948, recall: 0.8616, f1: 0.8779, edges-pos-ontonotes_loss: 0.0114
09/16 01:50:23 PM: Update 33569: task edges-pos-ontonotes, batch 569 (33569): mcc: 0.8786, acc: 0.8295, precision: 0.8974, recall: 0.8651, f1: 0.8809, edges-pos-ontonotes_loss: 0.0111
09/16 01:50:33 PM: Update 33664: task edges-pos-ontonotes, batch 664 (33664): mcc: 0.8803, acc: 0.8315, precision: 0.8988, recall: 0.8669, f1: 0.8826, edges-pos-ontonotes_loss: 0.0109
09/16 01:50:43 PM: Update 33766: task edges-pos-ontonotes, batch 766 (33766): mcc: 0.8812, acc: 0.8327, precision: 0.8998, recall: 0.8678, f1: 0.8835, edges-pos-ontonotes_loss: 0.0109
09/16 01:50:53 PM: Update 33880: task edges-pos-ontonotes, batch 880 (33880): mcc: 0.8823, acc: 0.8340, precision: 0.9008, recall: 0.8689, f1: 0.8846, edges-pos-ontonotes_loss: 0.0108
09/16 01:51:03 PM: Update 33996: task edges-pos-ontonotes, batch 996 (33996): mcc: 0.8823, acc: 0.8339, precision: 0.9008, recall: 0.8689, f1: 0.8845, edges-pos-ontonotes_loss: 0.0109
09/16 01:51:03 PM: ***** Step 34000 / Validation 34 *****
09/16 01:51:03 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:51:03 PM: Validating...
09/16 01:51:13 PM: Evaluate: task edges-pos-ontonotes, batch 93 (157): mcc: 0.8689, acc: 0.8432, precision: 0.8940, recall: 0.8498, f1: 0.8713, edges-pos-ontonotes_loss: 0.0131
09/16 01:51:22 PM: Updating LR scheduler:
09/16 01:51:22 PM: 	Best result seen so far for macro_avg: 0.877
09/16 01:51:22 PM: 	# validation passes without improvement: 2
09/16 01:51:22 PM: edges-pos-ontonotes_loss: training: 0.010878 validation: 0.013627
09/16 01:51:22 PM: macro_avg: validation: 0.861090
09/16 01:51:22 PM: micro_avg: validation: 0.000000
09/16 01:51:22 PM: edges-pos-ontonotes_mcc: training: 0.882252 validation: 0.858611
09/16 01:51:22 PM: edges-pos-ontonotes_acc: training: 0.833915 validation: 0.829063
09/16 01:51:22 PM: edges-pos-ontonotes_precision: training: 0.900735 validation: 0.887225
09/16 01:51:22 PM: edges-pos-ontonotes_recall: training: 0.868868 validation: 0.836450
09/16 01:51:22 PM: edges-pos-ontonotes_f1: training: 0.884515 validation: 0.861090
09/16 01:51:22 PM: Global learning rate: 2.5e-05
09/16 01:51:22 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 01:51:23 PM: Update 34016: task edges-pos-ontonotes, batch 16 (34016): mcc: 0.8918, acc: 0.8469, precision: 0.9151, recall: 0.8735, f1: 0.8938, edges-pos-ontonotes_loss: 0.0119
09/16 01:51:33 PM: Update 34185: task edges-pos-ontonotes, batch 185 (34185): mcc: 0.8697, acc: 0.8275, precision: 0.8922, recall: 0.8529, f1: 0.8721, edges-pos-ontonotes_loss: 0.0114
09/16 01:51:43 PM: Update 34296: task edges-pos-ontonotes, batch 296 (34296): mcc: 0.8620, acc: 0.8173, precision: 0.8850, recall: 0.8450, f1: 0.8645, edges-pos-ontonotes_loss: 0.0119
09/16 01:51:53 PM: Update 34381: task edges-pos-ontonotes, batch 381 (34381): mcc: 0.8541, acc: 0.8055, precision: 0.8784, recall: 0.8362, f1: 0.8568, edges-pos-ontonotes_loss: 0.0129
09/16 01:52:03 PM: Update 34458: task edges-pos-ontonotes, batch 458 (34458): mcc: 0.8523, acc: 0.8022, precision: 0.8771, recall: 0.8340, f1: 0.8550, edges-pos-ontonotes_loss: 0.0133
09/16 01:52:13 PM: Update 34530: task edges-pos-ontonotes, batch 530 (34530): mcc: 0.8506, acc: 0.7993, precision: 0.8760, recall: 0.8318, f1: 0.8533, edges-pos-ontonotes_loss: 0.0138
09/16 01:52:25 PM: Update 34601: task edges-pos-ontonotes, batch 601 (34601): mcc: 0.8489, acc: 0.7962, precision: 0.8751, recall: 0.8296, f1: 0.8517, edges-pos-ontonotes_loss: 0.0140
09/16 01:52:35 PM: Update 34718: task edges-pos-ontonotes, batch 718 (34718): mcc: 0.8512, acc: 0.7992, precision: 0.8765, recall: 0.8325, f1: 0.8539, edges-pos-ontonotes_loss: 0.0138
09/16 01:52:45 PM: Update 34840: task edges-pos-ontonotes, batch 840 (34840): mcc: 0.8533, acc: 0.8020, precision: 0.8779, recall: 0.8352, f1: 0.8560, edges-pos-ontonotes_loss: 0.0135
09/16 01:52:55 PM: Update 34931: task edges-pos-ontonotes, batch 931 (34931): mcc: 0.8545, acc: 0.8037, precision: 0.8785, recall: 0.8369, f1: 0.8572, edges-pos-ontonotes_loss: 0.0134
09/16 01:53:03 PM: ***** Step 35000 / Validation 35 *****
09/16 01:53:03 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:53:03 PM: Validating...
09/16 01:53:05 PM: Evaluate: task edges-pos-ontonotes, batch 18 (157): mcc: 0.8662, acc: 0.8431, precision: 0.8857, recall: 0.8525, f1: 0.8688, edges-pos-ontonotes_loss: 0.0129
09/16 01:53:15 PM: Evaluate: task edges-pos-ontonotes, batch 113 (157): mcc: 0.8723, acc: 0.8492, precision: 0.8909, recall: 0.8593, f1: 0.8748, edges-pos-ontonotes_loss: 0.0124
09/16 01:53:22 PM: Updating LR scheduler:
09/16 01:53:22 PM: 	Best result seen so far for macro_avg: 0.877
09/16 01:53:22 PM: 	# validation passes without improvement: 3
09/16 01:53:22 PM: edges-pos-ontonotes_loss: training: 0.013388 validation: 0.012746
09/16 01:53:22 PM: macro_avg: validation: 0.869873
09/16 01:53:22 PM: micro_avg: validation: 0.000000
09/16 01:53:22 PM: edges-pos-ontonotes_mcc: training: 0.855611 validation: 0.867306
09/16 01:53:22 PM: edges-pos-ontonotes_acc: training: 0.804921 validation: 0.843223
09/16 01:53:22 PM: edges-pos-ontonotes_precision: training: 0.879342 validation: 0.886022
09/16 01:53:22 PM: edges-pos-ontonotes_recall: training: 0.838235 validation: 0.854302
09/16 01:53:22 PM: edges-pos-ontonotes_f1: training: 0.858297 validation: 0.869873
09/16 01:53:22 PM: Global learning rate: 2.5e-05
09/16 01:53:22 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 01:53:25 PM: Update 35040: task edges-pos-ontonotes, batch 40 (35040): mcc: 0.8645, acc: 0.8136, precision: 0.8857, recall: 0.8493, f1: 0.8671, edges-pos-ontonotes_loss: 0.0130
09/16 01:53:35 PM: Update 35127: task edges-pos-ontonotes, batch 127 (35127): mcc: 0.8660, acc: 0.8142, precision: 0.8868, recall: 0.8510, f1: 0.8686, edges-pos-ontonotes_loss: 0.0128
09/16 01:53:45 PM: Update 35223: task edges-pos-ontonotes, batch 223 (35223): mcc: 0.8664, acc: 0.8144, precision: 0.8874, recall: 0.8512, f1: 0.8689, edges-pos-ontonotes_loss: 0.0127
09/16 01:53:55 PM: Update 35278: task edges-pos-ontonotes, batch 278 (35278): mcc: 0.8611, acc: 0.8072, precision: 0.8828, recall: 0.8454, f1: 0.8637, edges-pos-ontonotes_loss: 0.0131
09/16 01:54:05 PM: Update 35352: task edges-pos-ontonotes, batch 352 (35352): mcc: 0.8595, acc: 0.8050, precision: 0.8814, recall: 0.8437, f1: 0.8621, edges-pos-ontonotes_loss: 0.0134
09/16 01:54:16 PM: Update 35429: task edges-pos-ontonotes, batch 429 (35429): mcc: 0.8593, acc: 0.8049, precision: 0.8811, recall: 0.8435, f1: 0.8619, edges-pos-ontonotes_loss: 0.0135
09/16 01:54:26 PM: Update 35497: task edges-pos-ontonotes, batch 497 (35497): mcc: 0.8587, acc: 0.8042, precision: 0.8805, recall: 0.8430, f1: 0.8613, edges-pos-ontonotes_loss: 0.0136
09/16 01:54:41 PM: Update 35540: task edges-pos-ontonotes, batch 540 (35540): mcc: 0.8589, acc: 0.8047, precision: 0.8806, recall: 0.8434, f1: 0.8616, edges-pos-ontonotes_loss: 0.0137
09/16 01:54:51 PM: Update 35603: task edges-pos-ontonotes, batch 603 (35603): mcc: 0.8590, acc: 0.8051, precision: 0.8807, recall: 0.8434, f1: 0.8616, edges-pos-ontonotes_loss: 0.0137
09/16 01:55:01 PM: Update 35673: task edges-pos-ontonotes, batch 673 (35673): mcc: 0.8594, acc: 0.8061, precision: 0.8812, recall: 0.8438, f1: 0.8621, edges-pos-ontonotes_loss: 0.0138
09/16 01:55:11 PM: Update 35742: task edges-pos-ontonotes, batch 742 (35742): mcc: 0.8595, acc: 0.8066, precision: 0.8813, recall: 0.8439, f1: 0.8622, edges-pos-ontonotes_loss: 0.0139
09/16 01:55:21 PM: Update 35815: task edges-pos-ontonotes, batch 815 (35815): mcc: 0.8598, acc: 0.8071, precision: 0.8815, recall: 0.8442, f1: 0.8624, edges-pos-ontonotes_loss: 0.0139
09/16 01:55:31 PM: Update 35868: task edges-pos-ontonotes, batch 868 (35868): mcc: 0.8596, acc: 0.8072, precision: 0.8813, recall: 0.8439, f1: 0.8622, edges-pos-ontonotes_loss: 0.0139
09/16 01:55:42 PM: Update 35939: task edges-pos-ontonotes, batch 939 (35939): mcc: 0.8597, acc: 0.8076, precision: 0.8816, recall: 0.8440, f1: 0.8624, edges-pos-ontonotes_loss: 0.0139
09/16 01:55:51 PM: ***** Step 36000 / Validation 36 *****
09/16 01:55:51 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:55:51 PM: Validating...
09/16 01:55:52 PM: Evaluate: task edges-pos-ontonotes, batch 8 (157): mcc: 0.8750, acc: 0.8529, precision: 0.8918, recall: 0.8636, f1: 0.8775, edges-pos-ontonotes_loss: 0.0128
09/16 01:56:02 PM: Evaluate: task edges-pos-ontonotes, batch 104 (157): mcc: 0.8759, acc: 0.8517, precision: 0.8934, recall: 0.8636, f1: 0.8783, edges-pos-ontonotes_loss: 0.0125
09/16 01:56:10 PM: Updating LR scheduler:
09/16 01:56:10 PM: 	Best result seen so far for macro_avg: 0.877
09/16 01:56:10 PM: 	# validation passes without improvement: 0
09/16 01:56:10 PM: edges-pos-ontonotes_loss: training: 0.014001 validation: 0.012673
09/16 01:56:10 PM: macro_avg: validation: 0.876486
09/16 01:56:10 PM: micro_avg: validation: 0.000000
09/16 01:56:10 PM: edges-pos-ontonotes_mcc: training: 0.859780 validation: 0.874044
09/16 01:56:10 PM: edges-pos-ontonotes_acc: training: 0.807888 validation: 0.848493
09/16 01:56:10 PM: edges-pos-ontonotes_precision: training: 0.881660 validation: 0.892051
09/16 01:56:10 PM: edges-pos-ontonotes_recall: training: 0.844018 validation: 0.861456
09/16 01:56:10 PM: edges-pos-ontonotes_f1: training: 0.862429 validation: 0.876486
09/16 01:56:10 PM: Global learning rate: 1.25e-05
09/16 01:56:10 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 01:56:12 PM: Update 36018: task edges-pos-ontonotes, batch 18 (36018): mcc: 0.8664, acc: 0.8196, precision: 0.8887, recall: 0.8501, f1: 0.8689, edges-pos-ontonotes_loss: 0.0138
09/16 01:56:22 PM: Update 36096: task edges-pos-ontonotes, batch 96 (36096): mcc: 0.8646, acc: 0.8166, precision: 0.8876, recall: 0.8475, f1: 0.8671, edges-pos-ontonotes_loss: 0.0139
09/16 01:56:32 PM: Update 36164: task edges-pos-ontonotes, batch 164 (36164): mcc: 0.8652, acc: 0.8167, precision: 0.8878, recall: 0.8485, f1: 0.8677, edges-pos-ontonotes_loss: 0.0139
09/16 01:56:42 PM: Update 36224: task edges-pos-ontonotes, batch 224 (36224): mcc: 0.8637, acc: 0.8147, precision: 0.8863, recall: 0.8470, f1: 0.8662, edges-pos-ontonotes_loss: 0.0140
09/16 01:56:52 PM: Update 36299: task edges-pos-ontonotes, batch 299 (36299): mcc: 0.8634, acc: 0.8142, precision: 0.8862, recall: 0.8465, f1: 0.8659, edges-pos-ontonotes_loss: 0.0142
09/16 01:57:02 PM: Update 36368: task edges-pos-ontonotes, batch 368 (36368): mcc: 0.8633, acc: 0.8144, precision: 0.8861, recall: 0.8466, f1: 0.8659, edges-pos-ontonotes_loss: 0.0141
09/16 01:57:12 PM: Update 36438: task edges-pos-ontonotes, batch 438 (36438): mcc: 0.8635, acc: 0.8145, precision: 0.8860, recall: 0.8470, f1: 0.8660, edges-pos-ontonotes_loss: 0.0141
09/16 01:57:22 PM: Update 36488: task edges-pos-ontonotes, batch 488 (36488): mcc: 0.8630, acc: 0.8139, precision: 0.8853, recall: 0.8467, f1: 0.8655, edges-pos-ontonotes_loss: 0.0141
09/16 01:57:32 PM: Update 36576: task edges-pos-ontonotes, batch 576 (36576): mcc: 0.8643, acc: 0.8156, precision: 0.8860, recall: 0.8485, f1: 0.8668, edges-pos-ontonotes_loss: 0.0138
09/16 01:57:42 PM: Update 36660: task edges-pos-ontonotes, batch 660 (36660): mcc: 0.8656, acc: 0.8167, precision: 0.8869, recall: 0.8501, f1: 0.8681, edges-pos-ontonotes_loss: 0.0135
09/16 01:57:52 PM: Update 36751: task edges-pos-ontonotes, batch 751 (36751): mcc: 0.8667, acc: 0.8178, precision: 0.8879, recall: 0.8513, f1: 0.8692, edges-pos-ontonotes_loss: 0.0132
09/16 01:58:03 PM: Update 36841: task edges-pos-ontonotes, batch 841 (36841): mcc: 0.8678, acc: 0.8189, precision: 0.8888, recall: 0.8527, f1: 0.8703, edges-pos-ontonotes_loss: 0.0130
09/16 01:58:13 PM: Update 36960: task edges-pos-ontonotes, batch 960 (36960): mcc: 0.8698, acc: 0.8210, precision: 0.8902, recall: 0.8550, f1: 0.8723, edges-pos-ontonotes_loss: 0.0126
09/16 01:58:16 PM: ***** Step 37000 / Validation 37 *****
09/16 01:58:16 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:58:16 PM: Validating...
09/16 01:58:23 PM: Evaluate: task edges-pos-ontonotes, batch 71 (157): mcc: 0.8720, acc: 0.8399, precision: 0.9026, recall: 0.8474, f1: 0.8741, edges-pos-ontonotes_loss: 0.0131
09/16 01:58:33 PM: Evaluate: task edges-pos-ontonotes, batch 144 (157): mcc: 0.8691, acc: 0.8347, precision: 0.9012, recall: 0.8431, f1: 0.8712, edges-pos-ontonotes_loss: 0.0129
09/16 01:58:35 PM: Updating LR scheduler:
09/16 01:58:35 PM: 	Best result seen so far for macro_avg: 0.877
09/16 01:58:35 PM: 	# validation passes without improvement: 1
09/16 01:58:35 PM: edges-pos-ontonotes_loss: training: 0.012540 validation: 0.012946
09/16 01:58:35 PM: macro_avg: validation: 0.870746
09/16 01:58:35 PM: micro_avg: validation: 0.000000
09/16 01:58:35 PM: edges-pos-ontonotes_mcc: training: 0.870378 validation: 0.868611
09/16 01:58:35 PM: edges-pos-ontonotes_acc: training: 0.821673 validation: 0.833720
09/16 01:58:35 PM: edges-pos-ontonotes_precision: training: 0.890682 validation: 0.901311
09/16 01:58:35 PM: edges-pos-ontonotes_recall: training: 0.855710 validation: 0.842185
09/16 01:58:35 PM: edges-pos-ontonotes_f1: training: 0.872846 validation: 0.870746
09/16 01:58:35 PM: Global learning rate: 1.25e-05
09/16 01:58:35 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 01:58:43 PM: Update 37094: task edges-pos-ontonotes, batch 94 (37094): mcc: 0.8930, acc: 0.8479, precision: 0.9096, recall: 0.8811, f1: 0.8951, edges-pos-ontonotes_loss: 0.0099
09/16 01:58:53 PM: Update 37228: task edges-pos-ontonotes, batch 228 (37228): mcc: 0.8903, acc: 0.8444, precision: 0.9073, recall: 0.8781, f1: 0.8924, edges-pos-ontonotes_loss: 0.0106
09/16 01:59:03 PM: Update 37369: task edges-pos-ontonotes, batch 369 (37369): mcc: 0.8899, acc: 0.8426, precision: 0.9074, recall: 0.8772, f1: 0.8920, edges-pos-ontonotes_loss: 0.0106
09/16 01:59:16 PM: Update 37418: task edges-pos-ontonotes, batch 418 (37418): mcc: 0.8896, acc: 0.8423, precision: 0.9072, recall: 0.8767, f1: 0.8917, edges-pos-ontonotes_loss: 0.0106
09/16 01:59:26 PM: Update 37589: task edges-pos-ontonotes, batch 589 (37589): mcc: 0.8844, acc: 0.8366, precision: 0.9038, recall: 0.8701, f1: 0.8866, edges-pos-ontonotes_loss: 0.0110
09/16 01:59:37 PM: Update 37731: task edges-pos-ontonotes, batch 731 (37731): mcc: 0.8813, acc: 0.8341, precision: 0.9013, recall: 0.8665, f1: 0.8836, edges-pos-ontonotes_loss: 0.0111
09/16 01:59:47 PM: Update 37806: task edges-pos-ontonotes, batch 806 (37806): mcc: 0.8735, acc: 0.8249, precision: 0.8953, recall: 0.8572, f1: 0.8758, edges-pos-ontonotes_loss: 0.0117
09/16 01:59:57 PM: Update 37884: task edges-pos-ontonotes, batch 884 (37884): mcc: 0.8687, acc: 0.8192, precision: 0.8913, recall: 0.8518, f1: 0.8711, edges-pos-ontonotes_loss: 0.0121
09/16 02:00:07 PM: Update 37962: task edges-pos-ontonotes, batch 962 (37962): mcc: 0.8656, acc: 0.8154, precision: 0.8888, recall: 0.8484, f1: 0.8681, edges-pos-ontonotes_loss: 0.0123
09/16 02:00:12 PM: ***** Step 38000 / Validation 38 *****
09/16 02:00:12 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:00:12 PM: Validating...
09/16 02:00:17 PM: Evaluate: task edges-pos-ontonotes, batch 56 (157): mcc: 0.8719, acc: 0.8411, precision: 0.8990, recall: 0.8506, f1: 0.8741, edges-pos-ontonotes_loss: 0.0128
09/16 02:00:27 PM: Evaluate: task edges-pos-ontonotes, batch 133 (157): mcc: 0.8670, acc: 0.8352, precision: 0.8948, recall: 0.8453, f1: 0.8693, edges-pos-ontonotes_loss: 0.0128
09/16 02:00:30 PM: Updating LR scheduler:
09/16 02:00:30 PM: 	Best result seen so far for macro_avg: 0.877
09/16 02:00:30 PM: 	# validation passes without improvement: 2
09/16 02:00:30 PM: edges-pos-ontonotes_loss: training: 0.012467 validation: 0.012952
09/16 02:00:30 PM: macro_avg: validation: 0.867558
09/16 02:00:30 PM: micro_avg: validation: 0.000000
09/16 02:00:30 PM: edges-pos-ontonotes_mcc: training: 0.864519 validation: 0.865216
09/16 02:00:30 PM: edges-pos-ontonotes_acc: training: 0.814040 validation: 0.832640
09/16 02:00:30 PM: edges-pos-ontonotes_precision: training: 0.887852 validation: 0.893910
09/16 02:00:30 PM: edges-pos-ontonotes_recall: training: 0.847167 validation: 0.842715
09/16 02:00:30 PM: edges-pos-ontonotes_f1: training: 0.867033 validation: 0.867558
09/16 02:00:30 PM: Global learning rate: 1.25e-05
09/16 02:00:30 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 02:00:37 PM: Update 38045: task edges-pos-ontonotes, batch 45 (38045): mcc: 0.8393, acc: 0.7826, precision: 0.8669, recall: 0.8189, f1: 0.8422, edges-pos-ontonotes_loss: 0.0168
09/16 02:00:47 PM: Update 38128: task edges-pos-ontonotes, batch 128 (38128): mcc: 0.8482, acc: 0.7933, precision: 0.8744, recall: 0.8288, f1: 0.8510, edges-pos-ontonotes_loss: 0.0145
09/16 02:00:57 PM: Update 38243: task edges-pos-ontonotes, batch 243 (38243): mcc: 0.8559, acc: 0.8042, precision: 0.8800, recall: 0.8381, f1: 0.8585, edges-pos-ontonotes_loss: 0.0134
09/16 02:01:09 PM: Update 38374: task edges-pos-ontonotes, batch 374 (38374): mcc: 0.8588, acc: 0.8091, precision: 0.8817, recall: 0.8421, f1: 0.8615, edges-pos-ontonotes_loss: 0.0129
09/16 02:01:19 PM: Update 38463: task edges-pos-ontonotes, batch 463 (38463): mcc: 0.8597, acc: 0.8102, precision: 0.8822, recall: 0.8434, f1: 0.8624, edges-pos-ontonotes_loss: 0.0130
09/16 02:01:29 PM: Update 38551: task edges-pos-ontonotes, batch 551 (38551): mcc: 0.8613, acc: 0.8116, precision: 0.8835, recall: 0.8452, f1: 0.8639, edges-pos-ontonotes_loss: 0.0130
09/16 02:01:39 PM: Update 38649: task edges-pos-ontonotes, batch 649 (38649): mcc: 0.8624, acc: 0.8126, precision: 0.8843, recall: 0.8464, f1: 0.8650, edges-pos-ontonotes_loss: 0.0129
09/16 02:01:49 PM: Update 38709: task edges-pos-ontonotes, batch 709 (38709): mcc: 0.8613, acc: 0.8107, precision: 0.8833, recall: 0.8453, f1: 0.8639, edges-pos-ontonotes_loss: 0.0130
09/16 02:02:00 PM: Update 38785: task edges-pos-ontonotes, batch 785 (38785): mcc: 0.8600, acc: 0.8081, precision: 0.8821, recall: 0.8439, f1: 0.8626, edges-pos-ontonotes_loss: 0.0131
09/16 02:02:10 PM: Update 38858: task edges-pos-ontonotes, batch 858 (38858): mcc: 0.8590, acc: 0.8063, precision: 0.8812, recall: 0.8430, f1: 0.8617, edges-pos-ontonotes_loss: 0.0133
09/16 02:02:20 PM: Update 38928: task edges-pos-ontonotes, batch 928 (38928): mcc: 0.8586, acc: 0.8054, precision: 0.8808, recall: 0.8426, f1: 0.8613, edges-pos-ontonotes_loss: 0.0133
09/16 02:02:31 PM: Update 39000: task edges-pos-ontonotes, batch 1000 (39000): mcc: 0.8586, acc: 0.8052, precision: 0.8807, recall: 0.8427, f1: 0.8613, edges-pos-ontonotes_loss: 0.0134
09/16 02:02:31 PM: ***** Step 39000 / Validation 39 *****
09/16 02:02:31 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:02:31 PM: Validating...
09/16 02:02:41 PM: Evaluate: task edges-pos-ontonotes, batch 100 (157): mcc: 0.8771, acc: 0.8565, precision: 0.8952, recall: 0.8643, f1: 0.8795, edges-pos-ontonotes_loss: 0.0123
09/16 02:02:50 PM: Best result seen so far for edges-pos-ontonotes.
09/16 02:02:50 PM: Best result seen so far for macro.
09/16 02:02:50 PM: Updating LR scheduler:
09/16 02:02:50 PM: 	Best result seen so far for macro_avg: 0.877
09/16 02:02:50 PM: 	# validation passes without improvement: 0
09/16 02:02:50 PM: edges-pos-ontonotes_loss: training: 0.013399 validation: 0.012581
09/16 02:02:50 PM: macro_avg: validation: 0.877201
09/16 02:02:50 PM: micro_avg: validation: 0.000000
09/16 02:02:50 PM: edges-pos-ontonotes_mcc: training: 0.858607 validation: 0.874781
09/16 02:02:50 PM: edges-pos-ontonotes_acc: training: 0.805221 validation: 0.852546
09/16 02:02:50 PM: edges-pos-ontonotes_precision: training: 0.880670 validation: 0.893112
09/16 02:02:50 PM: edges-pos-ontonotes_recall: training: 0.842716 validation: 0.861847
09/16 02:02:50 PM: edges-pos-ontonotes_f1: training: 0.861275 validation: 0.877201
09/16 02:02:50 PM: Global learning rate: 1.25e-05
09/16 02:02:50 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 02:02:51 PM: Update 39009: task edges-pos-ontonotes, batch 9 (39009): mcc: 0.8566, acc: 0.8008, precision: 0.8815, recall: 0.8381, f1: 0.8593, edges-pos-ontonotes_loss: 0.0142
09/16 02:03:01 PM: Update 39077: task edges-pos-ontonotes, batch 77 (39077): mcc: 0.8571, acc: 0.8054, precision: 0.8811, recall: 0.8394, f1: 0.8598, edges-pos-ontonotes_loss: 0.0144
09/16 02:03:12 PM: Update 39151: task edges-pos-ontonotes, batch 151 (39151): mcc: 0.8589, acc: 0.8079, precision: 0.8823, recall: 0.8418, f1: 0.8616, edges-pos-ontonotes_loss: 0.0143
09/16 02:03:22 PM: Update 39228: task edges-pos-ontonotes, batch 228 (39228): mcc: 0.8593, acc: 0.8087, precision: 0.8827, recall: 0.8420, f1: 0.8619, edges-pos-ontonotes_loss: 0.0144
09/16 02:03:32 PM: Update 39291: task edges-pos-ontonotes, batch 291 (39291): mcc: 0.8598, acc: 0.8092, precision: 0.8827, recall: 0.8431, f1: 0.8624, edges-pos-ontonotes_loss: 0.0143
09/16 02:03:46 PM: Update 39313: task edges-pos-ontonotes, batch 313 (39313): mcc: 0.8597, acc: 0.8093, precision: 0.8825, recall: 0.8431, f1: 0.8623, edges-pos-ontonotes_loss: 0.0143
09/16 02:03:56 PM: Update 39386: task edges-pos-ontonotes, batch 386 (39386): mcc: 0.8598, acc: 0.8096, precision: 0.8825, recall: 0.8433, f1: 0.8624, edges-pos-ontonotes_loss: 0.0144
09/16 02:04:06 PM: Update 39460: task edges-pos-ontonotes, batch 460 (39460): mcc: 0.8599, acc: 0.8098, precision: 0.8824, recall: 0.8434, f1: 0.8625, edges-pos-ontonotes_loss: 0.0144
09/16 02:04:16 PM: Update 39528: task edges-pos-ontonotes, batch 528 (39528): mcc: 0.8600, acc: 0.8100, precision: 0.8827, recall: 0.8436, f1: 0.8627, edges-pos-ontonotes_loss: 0.0143
09/16 02:04:26 PM: Update 39598: task edges-pos-ontonotes, batch 598 (39598): mcc: 0.8605, acc: 0.8106, precision: 0.8831, recall: 0.8441, f1: 0.8632, edges-pos-ontonotes_loss: 0.0143
09/16 02:04:36 PM: Update 39653: task edges-pos-ontonotes, batch 653 (39653): mcc: 0.8607, acc: 0.8109, precision: 0.8832, recall: 0.8443, f1: 0.8633, edges-pos-ontonotes_loss: 0.0143
09/16 02:04:46 PM: Update 39724: task edges-pos-ontonotes, batch 724 (39724): mcc: 0.8607, acc: 0.8109, precision: 0.8833, recall: 0.8443, f1: 0.8633, edges-pos-ontonotes_loss: 0.0143
09/16 02:04:56 PM: Update 39790: task edges-pos-ontonotes, batch 790 (39790): mcc: 0.8610, acc: 0.8112, precision: 0.8835, recall: 0.8445, f1: 0.8636, edges-pos-ontonotes_loss: 0.0143
09/16 02:05:06 PM: Update 39859: task edges-pos-ontonotes, batch 859 (39859): mcc: 0.8611, acc: 0.8113, precision: 0.8836, recall: 0.8447, f1: 0.8637, edges-pos-ontonotes_loss: 0.0143
09/16 02:05:16 PM: Update 39934: task edges-pos-ontonotes, batch 934 (39934): mcc: 0.8613, acc: 0.8114, precision: 0.8837, recall: 0.8449, f1: 0.8639, edges-pos-ontonotes_loss: 0.0143
09/16 02:05:26 PM: ***** Step 40000 / Validation 40 *****
09/16 02:05:26 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:05:26 PM: Validating...
09/16 02:05:26 PM: Evaluate: task edges-pos-ontonotes, batch 4 (157): mcc: 0.8900, acc: 0.8699, precision: 0.9066, recall: 0.8781, f1: 0.8921, edges-pos-ontonotes_loss: 0.0118
09/16 02:05:36 PM: Evaluate: task edges-pos-ontonotes, batch 103 (157): mcc: 0.8740, acc: 0.8509, precision: 0.8939, recall: 0.8596, f1: 0.8764, edges-pos-ontonotes_loss: 0.0126
09/16 02:05:44 PM: Updating LR scheduler:
09/16 02:05:44 PM: 	Best result seen so far for macro_avg: 0.877
09/16 02:05:44 PM: 	# validation passes without improvement: 1
09/16 02:05:44 PM: edges-pos-ontonotes_loss: training: 0.014129 validation: 0.012701
09/16 02:05:44 PM: macro_avg: validation: 0.875563
09/16 02:05:44 PM: micro_avg: validation: 0.000000
09/16 02:05:44 PM: edges-pos-ontonotes_mcc: training: 0.861647 validation: 0.873151
09/16 02:05:44 PM: edges-pos-ontonotes_acc: training: 0.812061 validation: 0.848905
09/16 02:05:44 PM: edges-pos-ontonotes_precision: training: 0.883785 validation: 0.893418
09/16 02:05:44 PM: edges-pos-ontonotes_recall: training: 0.845562 validation: 0.858408
09/16 02:05:44 PM: edges-pos-ontonotes_f1: training: 0.864251 validation: 0.875563
09/16 02:05:44 PM: Global learning rate: 1.25e-05
09/16 02:05:44 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 02:05:47 PM: Update 40015: task edges-pos-ontonotes, batch 15 (40015): mcc: 0.8747, acc: 0.8257, precision: 0.8932, recall: 0.8616, f1: 0.8771, edges-pos-ontonotes_loss: 0.0123
09/16 02:05:57 PM: Update 40093: task edges-pos-ontonotes, batch 93 (40093): mcc: 0.8723, acc: 0.8226, precision: 0.8908, recall: 0.8592, f1: 0.8747, edges-pos-ontonotes_loss: 0.0119
09/16 02:06:07 PM: Update 40186: task edges-pos-ontonotes, batch 186 (40186): mcc: 0.8737, acc: 0.8238, precision: 0.8927, recall: 0.8603, f1: 0.8762, edges-pos-ontonotes_loss: 0.0117
09/16 02:06:17 PM: Update 40263: task edges-pos-ontonotes, batch 263 (40263): mcc: 0.8750, acc: 0.8250, precision: 0.8940, recall: 0.8615, f1: 0.8774, edges-pos-ontonotes_loss: 0.0116
09/16 02:06:27 PM: Update 40380: task edges-pos-ontonotes, batch 380 (40380): mcc: 0.8790, acc: 0.8298, precision: 0.8970, recall: 0.8662, f1: 0.8814, edges-pos-ontonotes_loss: 0.0111
09/16 02:06:37 PM: Update 40497: task edges-pos-ontonotes, batch 497 (40497): mcc: 0.8818, acc: 0.8332, precision: 0.8993, recall: 0.8694, f1: 0.8841, edges-pos-ontonotes_loss: 0.0108
09/16 02:06:47 PM: Update 40602: task edges-pos-ontonotes, batch 602 (40602): mcc: 0.8828, acc: 0.8344, precision: 0.9001, recall: 0.8705, f1: 0.8851, edges-pos-ontonotes_loss: 0.0108
09/16 02:06:57 PM: Update 40742: task edges-pos-ontonotes, batch 742 (40742): mcc: 0.8838, acc: 0.8359, precision: 0.9013, recall: 0.8714, f1: 0.8861, edges-pos-ontonotes_loss: 0.0108
09/16 02:07:08 PM: Update 40878: task edges-pos-ontonotes, batch 878 (40878): mcc: 0.8847, acc: 0.8368, precision: 0.9021, recall: 0.8722, f1: 0.8869, edges-pos-ontonotes_loss: 0.0107
09/16 02:07:15 PM: ***** Step 41000 / Validation 41 *****
09/16 02:07:15 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:07:15 PM: Validating...
09/16 02:07:18 PM: Evaluate: task edges-pos-ontonotes, batch 32 (157): mcc: 0.8601, acc: 0.8332, precision: 0.8875, recall: 0.8391, f1: 0.8626, edges-pos-ontonotes_loss: 0.0137
09/16 02:07:28 PM: Evaluate: task edges-pos-ontonotes, batch 118 (157): mcc: 0.8638, acc: 0.8364, precision: 0.8905, recall: 0.8432, f1: 0.8663, edges-pos-ontonotes_loss: 0.0131
09/16 02:07:34 PM: Updating LR scheduler:
09/16 02:07:34 PM: 	Best result seen so far for macro_avg: 0.877
09/16 02:07:34 PM: 	# validation passes without improvement: 2
09/16 02:07:34 PM: edges-pos-ontonotes_loss: training: 0.010847 validation: 0.013378
09/16 02:07:34 PM: macro_avg: validation: 0.862211
09/16 02:07:34 PM: micro_avg: validation: 0.000000
09/16 02:07:34 PM: edges-pos-ontonotes_mcc: training: 0.883004 validation: 0.859778
09/16 02:07:34 PM: edges-pos-ontonotes_acc: training: 0.834737 validation: 0.829846
09/16 02:07:34 PM: edges-pos-ontonotes_precision: training: 0.900946 validation: 0.889059
09/16 02:07:34 PM: edges-pos-ontonotes_recall: training: 0.870117 validation: 0.836937
09/16 02:07:34 PM: edges-pos-ontonotes_f1: training: 0.885263 validation: 0.862211
09/16 02:07:34 PM: Global learning rate: 1.25e-05
09/16 02:07:34 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 02:07:38 PM: Update 41074: task edges-pos-ontonotes, batch 74 (41074): mcc: 0.8699, acc: 0.8252, precision: 0.8936, recall: 0.8520, f1: 0.8723, edges-pos-ontonotes_loss: 0.0116
09/16 02:07:48 PM: Update 41197: task edges-pos-ontonotes, batch 197 (41197): mcc: 0.8659, acc: 0.8213, precision: 0.8904, recall: 0.8474, f1: 0.8683, edges-pos-ontonotes_loss: 0.0118
09/16 02:07:58 PM: Update 41270: task edges-pos-ontonotes, batch 270 (41270): mcc: 0.8539, acc: 0.8052, precision: 0.8796, recall: 0.8346, f1: 0.8565, edges-pos-ontonotes_loss: 0.0131
09/16 02:08:08 PM: Update 41351: task edges-pos-ontonotes, batch 351 (41351): mcc: 0.8506, acc: 0.8004, precision: 0.8761, recall: 0.8317, f1: 0.8533, edges-pos-ontonotes_loss: 0.0137
09/16 02:08:18 PM: Update 41435: task edges-pos-ontonotes, batch 435 (41435): mcc: 0.8492, acc: 0.7978, precision: 0.8748, recall: 0.8303, f1: 0.8519, edges-pos-ontonotes_loss: 0.0141
09/16 02:08:28 PM: Update 41504: task edges-pos-ontonotes, batch 504 (41504): mcc: 0.8475, acc: 0.7951, precision: 0.8737, recall: 0.8280, f1: 0.8503, edges-pos-ontonotes_loss: 0.0145
09/16 02:08:40 PM: Update 41521: task edges-pos-ontonotes, batch 521 (41521): mcc: 0.8467, acc: 0.7938, precision: 0.8732, recall: 0.8270, f1: 0.8495, edges-pos-ontonotes_loss: 0.0146
09/16 02:08:50 PM: Update 41636: task edges-pos-ontonotes, batch 636 (41636): mcc: 0.8495, acc: 0.7974, precision: 0.8751, recall: 0.8305, f1: 0.8522, edges-pos-ontonotes_loss: 0.0141
09/16 02:09:00 PM: Update 41759: task edges-pos-ontonotes, batch 759 (41759): mcc: 0.8515, acc: 0.8002, precision: 0.8765, recall: 0.8331, f1: 0.8542, edges-pos-ontonotes_loss: 0.0138
09/16 02:09:10 PM: Update 41846: task edges-pos-ontonotes, batch 846 (41846): mcc: 0.8532, acc: 0.8025, precision: 0.8776, recall: 0.8353, f1: 0.8559, edges-pos-ontonotes_loss: 0.0136
09/16 02:09:20 PM: Update 41937: task edges-pos-ontonotes, batch 937 (41937): mcc: 0.8547, acc: 0.8042, precision: 0.8787, recall: 0.8371, f1: 0.8574, edges-pos-ontonotes_loss: 0.0136
09/16 02:09:27 PM: ***** Step 42000 / Validation 42 *****
09/16 02:09:27 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:09:27 PM: Validating...
09/16 02:09:30 PM: Evaluate: task edges-pos-ontonotes, batch 33 (157): mcc: 0.8661, acc: 0.8413, precision: 0.8884, recall: 0.8496, f1: 0.8686, edges-pos-ontonotes_loss: 0.0130
09/16 02:09:40 PM: Evaluate: task edges-pos-ontonotes, batch 119 (157): mcc: 0.8692, acc: 0.8425, precision: 0.8907, recall: 0.8535, f1: 0.8717, edges-pos-ontonotes_loss: 0.0124
09/16 02:09:46 PM: Updating LR scheduler:
09/16 02:09:46 PM: 	Best result seen so far for macro_avg: 0.877
09/16 02:09:46 PM: 	# validation passes without improvement: 3
09/16 02:09:46 PM: edges-pos-ontonotes_loss: training: 0.013564 validation: 0.012701
09/16 02:09:46 PM: macro_avg: validation: 0.867854
09/16 02:09:46 PM: micro_avg: validation: 0.000000
09/16 02:09:46 PM: edges-pos-ontonotes_mcc: training: 0.855311 validation: 0.865363
09/16 02:09:46 PM: edges-pos-ontonotes_acc: training: 0.804771 validation: 0.836376
09/16 02:09:46 PM: edges-pos-ontonotes_precision: training: 0.879186 validation: 0.888909
09/16 02:09:46 PM: edges-pos-ontonotes_recall: training: 0.837809 validation: 0.847773
09/16 02:09:46 PM: edges-pos-ontonotes_f1: training: 0.857999 validation: 0.867854
09/16 02:09:46 PM: Global learning rate: 1.25e-05
09/16 02:09:46 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 02:09:50 PM: Update 42036: task edges-pos-ontonotes, batch 36 (42036): mcc: 0.8665, acc: 0.8164, precision: 0.8872, recall: 0.8517, f1: 0.8691, edges-pos-ontonotes_loss: 0.0128
09/16 02:10:00 PM: Update 42131: task edges-pos-ontonotes, batch 131 (42131): mcc: 0.8676, acc: 0.8158, precision: 0.8880, recall: 0.8529, f1: 0.8701, edges-pos-ontonotes_loss: 0.0126
09/16 02:10:10 PM: Update 42187: task edges-pos-ontonotes, batch 187 (42187): mcc: 0.8596, acc: 0.8052, precision: 0.8820, recall: 0.8433, f1: 0.8622, edges-pos-ontonotes_loss: 0.0131
09/16 02:10:20 PM: Update 42260: task edges-pos-ontonotes, batch 260 (42260): mcc: 0.8571, acc: 0.8009, precision: 0.8798, recall: 0.8407, f1: 0.8598, edges-pos-ontonotes_loss: 0.0135
09/16 02:10:30 PM: Update 42332: task edges-pos-ontonotes, batch 332 (42332): mcc: 0.8565, acc: 0.7996, precision: 0.8789, recall: 0.8404, f1: 0.8592, edges-pos-ontonotes_loss: 0.0137
09/16 02:10:40 PM: Update 42406: task edges-pos-ontonotes, batch 406 (42406): mcc: 0.8561, acc: 0.7990, precision: 0.8784, recall: 0.8400, f1: 0.8588, edges-pos-ontonotes_loss: 0.0139
09/16 02:10:51 PM: Update 42467: task edges-pos-ontonotes, batch 467 (42467): mcc: 0.8560, acc: 0.7990, precision: 0.8782, recall: 0.8400, f1: 0.8587, edges-pos-ontonotes_loss: 0.0139
09/16 02:11:01 PM: Update 42535: task edges-pos-ontonotes, batch 535 (42535): mcc: 0.8567, acc: 0.8005, precision: 0.8793, recall: 0.8405, f1: 0.8594, edges-pos-ontonotes_loss: 0.0140
09/16 02:11:11 PM: Update 42609: task edges-pos-ontonotes, batch 609 (42609): mcc: 0.8570, acc: 0.8016, precision: 0.8795, recall: 0.8407, f1: 0.8597, edges-pos-ontonotes_loss: 0.0140
09/16 02:11:21 PM: Update 42680: task edges-pos-ontonotes, batch 680 (42680): mcc: 0.8575, acc: 0.8027, precision: 0.8799, recall: 0.8412, f1: 0.8601, edges-pos-ontonotes_loss: 0.0141
09/16 02:11:31 PM: Update 42746: task edges-pos-ontonotes, batch 746 (42746): mcc: 0.8576, acc: 0.8033, precision: 0.8800, recall: 0.8414, f1: 0.8603, edges-pos-ontonotes_loss: 0.0141
09/16 02:11:41 PM: Update 42795: task edges-pos-ontonotes, batch 795 (42795): mcc: 0.8577, acc: 0.8037, precision: 0.8801, recall: 0.8416, f1: 0.8604, edges-pos-ontonotes_loss: 0.0141
09/16 02:11:51 PM: Update 42870: task edges-pos-ontonotes, batch 870 (42870): mcc: 0.8581, acc: 0.8045, precision: 0.8805, recall: 0.8420, f1: 0.8608, edges-pos-ontonotes_loss: 0.0141
09/16 02:12:01 PM: Update 42940: task edges-pos-ontonotes, batch 940 (42940): mcc: 0.8585, acc: 0.8051, precision: 0.8808, recall: 0.8423, f1: 0.8611, edges-pos-ontonotes_loss: 0.0141
09/16 02:12:10 PM: ***** Step 43000 / Validation 43 *****
09/16 02:12:10 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:12:10 PM: Validating...
09/16 02:12:11 PM: Evaluate: task edges-pos-ontonotes, batch 19 (157): mcc: 0.8687, acc: 0.8471, precision: 0.8848, recall: 0.8581, f1: 0.8713, edges-pos-ontonotes_loss: 0.0131
09/16 02:12:21 PM: Evaluate: task edges-pos-ontonotes, batch 112 (157): mcc: 0.8755, acc: 0.8534, precision: 0.8917, recall: 0.8646, f1: 0.8780, edges-pos-ontonotes_loss: 0.0125
09/16 02:12:28 PM: Best result seen so far for edges-pos-ontonotes.
09/16 02:12:28 PM: Best result seen so far for macro.
09/16 02:12:28 PM: Updating LR scheduler:
09/16 02:12:28 PM: 	Best result seen so far for macro_avg: 0.877
09/16 02:12:28 PM: 	# validation passes without improvement: 0
09/16 02:12:28 PM: edges-pos-ontonotes_loss: training: 0.014128 validation: 0.012626
09/16 02:12:28 PM: macro_avg: validation: 0.877216
09/16 02:12:28 PM: micro_avg: validation: 0.000000
09/16 02:12:28 PM: edges-pos-ontonotes_mcc: training: 0.858681 validation: 0.874761
09/16 02:12:28 PM: edges-pos-ontonotes_acc: training: 0.805595 validation: 0.851011
09/16 02:12:28 PM: edges-pos-ontonotes_precision: training: 0.881065 validation: 0.891399
09/16 02:12:28 PM: edges-pos-ontonotes_recall: training: 0.842478 validation: 0.863477
09/16 02:12:28 PM: edges-pos-ontonotes_f1: training: 0.861339 validation: 0.877216
09/16 02:12:28 PM: Global learning rate: 6.25e-06
09/16 02:12:28 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 02:12:31 PM: Update 43023: task edges-pos-ontonotes, batch 23 (43023): mcc: 0.8611, acc: 0.8128, precision: 0.8815, recall: 0.8466, f1: 0.8637, edges-pos-ontonotes_loss: 0.0142
09/16 02:12:50 PM: Update 43086: task edges-pos-ontonotes, batch 86 (43086): mcc: 0.8626, acc: 0.8153, precision: 0.8842, recall: 0.8470, f1: 0.8652, edges-pos-ontonotes_loss: 0.0142
09/16 02:13:00 PM: Update 43155: task edges-pos-ontonotes, batch 155 (43155): mcc: 0.8618, acc: 0.8138, precision: 0.8835, recall: 0.8460, f1: 0.8644, edges-pos-ontonotes_loss: 0.0141
09/16 02:13:10 PM: Update 43226: task edges-pos-ontonotes, batch 226 (43226): mcc: 0.8622, acc: 0.8136, precision: 0.8839, recall: 0.8465, f1: 0.8648, edges-pos-ontonotes_loss: 0.0141
09/16 02:13:20 PM: Update 43296: task edges-pos-ontonotes, batch 296 (43296): mcc: 0.8622, acc: 0.8136, precision: 0.8841, recall: 0.8464, f1: 0.8648, edges-pos-ontonotes_loss: 0.0141
09/16 02:13:30 PM: Update 43364: task edges-pos-ontonotes, batch 364 (43364): mcc: 0.8625, acc: 0.8136, precision: 0.8843, recall: 0.8467, f1: 0.8651, edges-pos-ontonotes_loss: 0.0142
09/16 02:13:40 PM: Update 43426: task edges-pos-ontonotes, batch 426 (43426): mcc: 0.8623, acc: 0.8135, precision: 0.8838, recall: 0.8468, f1: 0.8649, edges-pos-ontonotes_loss: 0.0141
09/16 02:13:51 PM: Update 43511: task edges-pos-ontonotes, batch 511 (43511): mcc: 0.8638, acc: 0.8152, precision: 0.8849, recall: 0.8486, f1: 0.8663, edges-pos-ontonotes_loss: 0.0138
09/16 02:14:01 PM: Update 43602: task edges-pos-ontonotes, batch 602 (43602): mcc: 0.8653, acc: 0.8168, precision: 0.8860, recall: 0.8506, f1: 0.8679, edges-pos-ontonotes_loss: 0.0135
09/16 02:14:11 PM: Update 43687: task edges-pos-ontonotes, batch 687 (43687): mcc: 0.8663, acc: 0.8178, precision: 0.8865, recall: 0.8518, f1: 0.8688, edges-pos-ontonotes_loss: 0.0132
09/16 02:14:21 PM: Update 43778: task edges-pos-ontonotes, batch 778 (43778): mcc: 0.8681, acc: 0.8197, precision: 0.8880, recall: 0.8540, f1: 0.8707, edges-pos-ontonotes_loss: 0.0129
09/16 02:14:31 PM: Update 43896: task edges-pos-ontonotes, batch 896 (43896): mcc: 0.8701, acc: 0.8219, precision: 0.8895, recall: 0.8564, f1: 0.8726, edges-pos-ontonotes_loss: 0.0125
09/16 02:14:40 PM: ***** Step 44000 / Validation 44 *****
09/16 02:14:40 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:14:40 PM: Validating...
09/16 02:14:41 PM: Evaluate: task edges-pos-ontonotes, batch 13 (157): mcc: 0.8691, acc: 0.8407, precision: 0.8940, recall: 0.8500, f1: 0.8714, edges-pos-ontonotes_loss: 0.0130
09/16 02:14:51 PM: Evaluate: task edges-pos-ontonotes, batch 110 (157): mcc: 0.8739, acc: 0.8443, precision: 0.9001, recall: 0.8533, f1: 0.8761, edges-pos-ontonotes_loss: 0.0127
09/16 02:14:58 PM: Updating LR scheduler:
09/16 02:14:58 PM: 	Best result seen so far for macro_avg: 0.877
09/16 02:14:58 PM: 	# validation passes without improvement: 1
09/16 02:14:58 PM: edges-pos-ontonotes_loss: training: 0.012292 validation: 0.012790
09/16 02:14:58 PM: macro_avg: validation: 0.874237
09/16 02:14:58 PM: micro_avg: validation: 0.000000
09/16 02:14:58 PM: edges-pos-ontonotes_mcc: training: 0.871577 validation: 0.871960
09/16 02:14:58 PM: edges-pos-ontonotes_acc: training: 0.823519 validation: 0.842302
09/16 02:14:58 PM: edges-pos-ontonotes_precision: training: 0.890621 validation: 0.898272
09/16 02:14:58 PM: edges-pos-ontonotes_recall: training: 0.858082 validation: 0.851456
09/16 02:14:58 PM: edges-pos-ontonotes_f1: training: 0.874049 validation: 0.874237
09/16 02:14:58 PM: Global learning rate: 6.25e-06
09/16 02:14:58 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 02:15:01 PM: Update 44025: task edges-pos-ontonotes, batch 25 (44025): mcc: 0.8927, acc: 0.8467, precision: 0.9080, recall: 0.8820, f1: 0.8948, edges-pos-ontonotes_loss: 0.0099
09/16 02:15:11 PM: Update 44171: task edges-pos-ontonotes, batch 171 (44171): mcc: 0.8882, acc: 0.8431, precision: 0.9046, recall: 0.8765, f1: 0.8903, edges-pos-ontonotes_loss: 0.0107
09/16 02:15:21 PM: Update 44313: task edges-pos-ontonotes, batch 313 (44313): mcc: 0.8884, acc: 0.8424, precision: 0.9054, recall: 0.8762, f1: 0.8906, edges-pos-ontonotes_loss: 0.0107
09/16 02:15:31 PM: Update 44461: task edges-pos-ontonotes, batch 461 (44461): mcc: 0.8811, acc: 0.8330, precision: 0.8998, recall: 0.8677, f1: 0.8834, edges-pos-ontonotes_loss: 0.0112
09/16 02:15:41 PM: Update 44646: task edges-pos-ontonotes, batch 646 (44646): mcc: 0.8779, acc: 0.8301, precision: 0.8982, recall: 0.8630, f1: 0.8802, edges-pos-ontonotes_loss: 0.0114
09/16 02:15:51 PM: Update 44709: task edges-pos-ontonotes, batch 709 (44709): mcc: 0.8712, acc: 0.8224, precision: 0.8933, recall: 0.8548, f1: 0.8736, edges-pos-ontonotes_loss: 0.0118
09/16 02:16:01 PM: Update 44794: task edges-pos-ontonotes, batch 794 (44794): mcc: 0.8661, acc: 0.8166, precision: 0.8892, recall: 0.8489, f1: 0.8686, edges-pos-ontonotes_loss: 0.0122
09/16 02:16:11 PM: Update 44864: task edges-pos-ontonotes, batch 864 (44864): mcc: 0.8625, acc: 0.8123, precision: 0.8863, recall: 0.8449, f1: 0.8651, edges-pos-ontonotes_loss: 0.0125
09/16 02:16:21 PM: Update 44939: task edges-pos-ontonotes, batch 939 (44939): mcc: 0.8600, acc: 0.8090, precision: 0.8841, recall: 0.8421, f1: 0.8625, edges-pos-ontonotes_loss: 0.0129
09/16 02:16:30 PM: ***** Step 45000 / Validation 45 *****
09/16 02:16:30 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:16:30 PM: Validating...
09/16 02:16:31 PM: Evaluate: task edges-pos-ontonotes, batch 17 (157): mcc: 0.8630, acc: 0.8312, precision: 0.8902, recall: 0.8421, f1: 0.8655, edges-pos-ontonotes_loss: 0.0132
09/16 02:16:42 PM: Evaluate: task edges-pos-ontonotes, batch 111 (157): mcc: 0.8710, acc: 0.8385, precision: 0.8975, recall: 0.8503, f1: 0.8733, edges-pos-ontonotes_loss: 0.0125
09/16 02:16:48 PM: Updating LR scheduler:
09/16 02:16:48 PM: 	Best result seen so far for macro_avg: 0.877
09/16 02:16:48 PM: 	# validation passes without improvement: 2
09/16 02:16:48 PM: edges-pos-ontonotes_loss: training: 0.012996 validation: 0.012819
09/16 02:16:48 PM: macro_avg: validation: 0.868357
09/16 02:16:48 PM: micro_avg: validation: 0.000000
09/16 02:16:48 PM: edges-pos-ontonotes_mcc: training: 0.858585 validation: 0.866036
09/16 02:16:48 PM: edges-pos-ontonotes_acc: training: 0.807139 validation: 0.831804
09/16 02:16:48 PM: edges-pos-ontonotes_precision: training: 0.882930 validation: 0.894822
09/16 02:16:48 PM: edges-pos-ontonotes_recall: training: 0.840501 validation: 0.843413
09/16 02:16:48 PM: edges-pos-ontonotes_f1: training: 0.861193 validation: 0.868357
09/16 02:16:48 PM: Global learning rate: 6.25e-06
09/16 02:16:48 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 02:16:52 PM: Update 45039: task edges-pos-ontonotes, batch 39 (45039): mcc: 0.8646, acc: 0.8162, precision: 0.8846, recall: 0.8504, f1: 0.8672, edges-pos-ontonotes_loss: 0.0125
09/16 02:17:02 PM: Update 45149: task edges-pos-ontonotes, batch 149 (45149): mcc: 0.8645, acc: 0.8172, precision: 0.8856, recall: 0.8494, f1: 0.8671, edges-pos-ontonotes_loss: 0.0124
09/16 02:17:12 PM: Update 45270: task edges-pos-ontonotes, batch 270 (45270): mcc: 0.8647, acc: 0.8175, precision: 0.8857, recall: 0.8497, f1: 0.8673, edges-pos-ontonotes_loss: 0.0123
09/16 02:17:23 PM: Update 45294: task edges-pos-ontonotes, batch 294 (45294): mcc: 0.8652, acc: 0.8181, precision: 0.8862, recall: 0.8502, f1: 0.8678, edges-pos-ontonotes_loss: 0.0122
09/16 02:17:33 PM: Update 45380: task edges-pos-ontonotes, batch 380 (45380): mcc: 0.8655, acc: 0.8182, precision: 0.8862, recall: 0.8507, f1: 0.8681, edges-pos-ontonotes_loss: 0.0125
09/16 02:17:43 PM: Update 45479: task edges-pos-ontonotes, batch 479 (45479): mcc: 0.8660, acc: 0.8181, precision: 0.8867, recall: 0.8511, f1: 0.8685, edges-pos-ontonotes_loss: 0.0125
09/16 02:17:53 PM: Update 45567: task edges-pos-ontonotes, batch 567 (45567): mcc: 0.8660, acc: 0.8178, precision: 0.8867, recall: 0.8512, f1: 0.8686, edges-pos-ontonotes_loss: 0.0126
09/16 02:18:03 PM: Update 45634: task edges-pos-ontonotes, batch 634 (45634): mcc: 0.8643, acc: 0.8150, precision: 0.8853, recall: 0.8492, f1: 0.8669, edges-pos-ontonotes_loss: 0.0127
09/16 02:18:13 PM: Update 45703: task edges-pos-ontonotes, batch 703 (45703): mcc: 0.8625, acc: 0.8119, precision: 0.8840, recall: 0.8469, f1: 0.8651, edges-pos-ontonotes_loss: 0.0129
09/16 02:18:23 PM: Update 45777: task edges-pos-ontonotes, batch 777 (45777): mcc: 0.8610, acc: 0.8093, precision: 0.8828, recall: 0.8452, f1: 0.8636, edges-pos-ontonotes_loss: 0.0130
09/16 02:18:33 PM: Update 45855: task edges-pos-ontonotes, batch 855 (45855): mcc: 0.8600, acc: 0.8075, precision: 0.8819, recall: 0.8443, f1: 0.8626, edges-pos-ontonotes_loss: 0.0132
09/16 02:18:45 PM: Update 45920: task edges-pos-ontonotes, batch 920 (45920): mcc: 0.8593, acc: 0.8062, precision: 0.8811, recall: 0.8437, f1: 0.8620, edges-pos-ontonotes_loss: 0.0132
09/16 02:18:55 PM: Update 45990: task edges-pos-ontonotes, batch 990 (45990): mcc: 0.8588, acc: 0.8056, precision: 0.8809, recall: 0.8429, f1: 0.8615, edges-pos-ontonotes_loss: 0.0134
09/16 02:18:56 PM: ***** Step 46000 / Validation 46 *****
09/16 02:18:56 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:18:56 PM: Validating...
09/16 02:19:05 PM: Evaluate: task edges-pos-ontonotes, batch 91 (157): mcc: 0.8761, acc: 0.8482, precision: 0.9017, recall: 0.8561, f1: 0.8783, edges-pos-ontonotes_loss: 0.0123
09/16 02:19:15 PM: Updating LR scheduler:
09/16 02:19:15 PM: 	Best result seen so far for macro_avg: 0.877
09/16 02:19:15 PM: 	# validation passes without improvement: 3
09/16 02:19:15 PM: edges-pos-ontonotes_loss: training: 0.013374 validation: 0.012553
09/16 02:19:15 PM: macro_avg: validation: 0.875573
09/16 02:19:15 PM: micro_avg: validation: 0.000000
09/16 02:19:15 PM: edges-pos-ontonotes_mcc: training: 0.858898 validation: 0.873260
09/16 02:19:15 PM: edges-pos-ontonotes_acc: training: 0.805602 validation: 0.844799
09/16 02:19:15 PM: edges-pos-ontonotes_precision: training: 0.880999 validation: 0.897381
09/16 02:19:15 PM: edges-pos-ontonotes_recall: training: 0.842958 validation: 0.854800
09/16 02:19:15 PM: edges-pos-ontonotes_f1: training: 0.861559 validation: 0.875573
09/16 02:19:15 PM: Global learning rate: 6.25e-06
09/16 02:19:15 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 02:19:15 PM: Update 46003: task edges-pos-ontonotes, batch 3 (46003): mcc: 0.8632, acc: 0.8099, precision: 0.8884, recall: 0.8441, f1: 0.8657, edges-pos-ontonotes_loss: 0.0133
09/16 02:19:26 PM: Update 46069: task edges-pos-ontonotes, batch 69 (46069): mcc: 0.8570, acc: 0.8015, precision: 0.8814, recall: 0.8390, f1: 0.8597, edges-pos-ontonotes_loss: 0.0142
09/16 02:19:36 PM: Update 46137: task edges-pos-ontonotes, batch 137 (46137): mcc: 0.8576, acc: 0.8031, precision: 0.8813, recall: 0.8403, f1: 0.8603, edges-pos-ontonotes_loss: 0.0142
09/16 02:19:46 PM: Update 46206: task edges-pos-ontonotes, batch 206 (46206): mcc: 0.8583, acc: 0.8045, precision: 0.8819, recall: 0.8409, f1: 0.8609, edges-pos-ontonotes_loss: 0.0142
09/16 02:19:56 PM: Update 46263: task edges-pos-ontonotes, batch 263 (46263): mcc: 0.8584, acc: 0.8053, precision: 0.8820, recall: 0.8410, f1: 0.8610, edges-pos-ontonotes_loss: 0.0142
09/16 02:20:06 PM: Update 46334: task edges-pos-ontonotes, batch 334 (46334): mcc: 0.8589, acc: 0.8063, precision: 0.8822, recall: 0.8418, f1: 0.8615, edges-pos-ontonotes_loss: 0.0143
09/16 02:20:16 PM: Update 46402: task edges-pos-ontonotes, batch 402 (46402): mcc: 0.8590, acc: 0.8068, precision: 0.8821, recall: 0.8421, f1: 0.8617, edges-pos-ontonotes_loss: 0.0143
09/16 02:20:26 PM: Update 46477: task edges-pos-ontonotes, batch 477 (46477): mcc: 0.8593, acc: 0.8074, precision: 0.8824, recall: 0.8424, f1: 0.8620, edges-pos-ontonotes_loss: 0.0143
09/16 02:20:38 PM: Update 46546: task edges-pos-ontonotes, batch 546 (46546): mcc: 0.8594, acc: 0.8077, precision: 0.8826, recall: 0.8424, f1: 0.8620, edges-pos-ontonotes_loss: 0.0143
09/16 02:20:48 PM: Update 46615: task edges-pos-ontonotes, batch 615 (46615): mcc: 0.8592, acc: 0.8075, precision: 0.8824, recall: 0.8421, f1: 0.8618, edges-pos-ontonotes_loss: 0.0144
09/16 02:20:58 PM: Update 46687: task edges-pos-ontonotes, batch 687 (46687): mcc: 0.8592, acc: 0.8077, precision: 0.8823, recall: 0.8423, f1: 0.8618, edges-pos-ontonotes_loss: 0.0144
09/16 02:21:08 PM: Update 46755: task edges-pos-ontonotes, batch 755 (46755): mcc: 0.8595, acc: 0.8082, precision: 0.8825, recall: 0.8427, f1: 0.8621, edges-pos-ontonotes_loss: 0.0143
09/16 02:21:18 PM: Update 46830: task edges-pos-ontonotes, batch 830 (46830): mcc: 0.8599, acc: 0.8087, precision: 0.8829, recall: 0.8430, f1: 0.8625, edges-pos-ontonotes_loss: 0.0143
09/16 02:21:28 PM: Update 46889: task edges-pos-ontonotes, batch 889 (46889): mcc: 0.8600, acc: 0.8090, precision: 0.8828, recall: 0.8434, f1: 0.8627, edges-pos-ontonotes_loss: 0.0142
09/16 02:21:38 PM: Update 46974: task edges-pos-ontonotes, batch 974 (46974): mcc: 0.8611, acc: 0.8103, precision: 0.8834, recall: 0.8448, f1: 0.8637, edges-pos-ontonotes_loss: 0.0140
09/16 02:21:41 PM: ***** Step 47000 / Validation 47 *****
09/16 02:21:41 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:21:41 PM: Validating...
09/16 02:21:48 PM: Evaluate: task edges-pos-ontonotes, batch 74 (157): mcc: 0.8744, acc: 0.8532, precision: 0.8916, recall: 0.8625, f1: 0.8768, edges-pos-ontonotes_loss: 0.0126
09/16 02:21:58 PM: Evaluate: task edges-pos-ontonotes, batch 145 (157): mcc: 0.8734, acc: 0.8496, precision: 0.8901, recall: 0.8621, f1: 0.8759, edges-pos-ontonotes_loss: 0.0126
09/16 02:22:00 PM: Updating LR scheduler:
09/16 02:22:00 PM: 	Best result seen so far for macro_avg: 0.877
09/16 02:22:00 PM: 	# validation passes without improvement: 0
09/16 02:22:00 PM: edges-pos-ontonotes_loss: training: 0.013921 validation: 0.012641
09/16 02:22:00 PM: macro_avg: validation: 0.876321
09/16 02:22:00 PM: micro_avg: validation: 0.000000
09/16 02:22:00 PM: edges-pos-ontonotes_mcc: training: 0.861493 validation: 0.873850
09/16 02:22:00 PM: edges-pos-ontonotes_acc: training: 0.810764 validation: 0.850101
09/16 02:22:00 PM: edges-pos-ontonotes_precision: training: 0.883717 validation: 0.890589
09/16 02:22:00 PM: edges-pos-ontonotes_recall: training: 0.845332 validation: 0.862504
09/16 02:22:00 PM: edges-pos-ontonotes_f1: training: 0.864098 validation: 0.876321
09/16 02:22:00 PM: Global learning rate: 3.125e-06
09/16 02:22:00 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 02:22:08 PM: Update 47072: task edges-pos-ontonotes, batch 72 (47072): mcc: 0.8755, acc: 0.8264, precision: 0.8931, recall: 0.8633, f1: 0.8779, edges-pos-ontonotes_loss: 0.0117
09/16 02:22:18 PM: Update 47155: task edges-pos-ontonotes, batch 155 (47155): mcc: 0.8741, acc: 0.8259, precision: 0.8911, recall: 0.8625, f1: 0.8766, edges-pos-ontonotes_loss: 0.0118
09/16 02:22:30 PM: Update 47172: task edges-pos-ontonotes, batch 172 (47172): mcc: 0.8743, acc: 0.8261, precision: 0.8915, recall: 0.8626, f1: 0.8768, edges-pos-ontonotes_loss: 0.0119
09/16 02:22:40 PM: Update 47286: task edges-pos-ontonotes, batch 286 (47286): mcc: 0.8790, acc: 0.8319, precision: 0.8952, recall: 0.8680, f1: 0.8814, edges-pos-ontonotes_loss: 0.0112
09/16 02:22:50 PM: Update 47402: task edges-pos-ontonotes, batch 402 (47402): mcc: 0.8813, acc: 0.8346, precision: 0.8970, recall: 0.8707, f1: 0.8836, edges-pos-ontonotes_loss: 0.0110
09/16 02:23:00 PM: Update 47512: task edges-pos-ontonotes, batch 512 (47512): mcc: 0.8830, acc: 0.8366, precision: 0.8982, recall: 0.8729, f1: 0.8853, edges-pos-ontonotes_loss: 0.0108
09/16 02:23:10 PM: Update 47656: task edges-pos-ontonotes, batch 656 (47656): mcc: 0.8838, acc: 0.8378, precision: 0.8989, recall: 0.8737, f1: 0.8861, edges-pos-ontonotes_loss: 0.0108
09/16 02:23:21 PM: Update 47793: task edges-pos-ontonotes, batch 793 (47793): mcc: 0.8840, acc: 0.8380, precision: 0.8994, recall: 0.8736, f1: 0.8863, edges-pos-ontonotes_loss: 0.0108
09/16 02:23:31 PM: Update 47939: task edges-pos-ontonotes, batch 939 (47939): mcc: 0.8804, acc: 0.8336, precision: 0.8967, recall: 0.8693, f1: 0.8828, edges-pos-ontonotes_loss: 0.0112
09/16 02:23:34 PM: ***** Step 48000 / Validation 48 *****
09/16 02:23:34 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:23:34 PM: Validating...
09/16 02:23:41 PM: Evaluate: task edges-pos-ontonotes, batch 69 (157): mcc: 0.8750, acc: 0.8393, precision: 0.8983, recall: 0.8571, f1: 0.8772, edges-pos-ontonotes_loss: 0.0125
09/16 02:23:51 PM: Evaluate: task edges-pos-ontonotes, batch 142 (157): mcc: 0.8695, acc: 0.8344, precision: 0.8930, recall: 0.8518, f1: 0.8719, edges-pos-ontonotes_loss: 0.0127
09/16 02:23:53 PM: Updating LR scheduler:
09/16 02:23:53 PM: 	Best result seen so far for macro_avg: 0.877
09/16 02:23:53 PM: 	# validation passes without improvement: 1
09/16 02:23:53 PM: edges-pos-ontonotes_loss: training: 0.011255 validation: 0.012764
09/16 02:23:53 PM: macro_avg: validation: 0.871381
09/16 02:23:53 PM: micro_avg: validation: 0.000000
09/16 02:23:53 PM: edges-pos-ontonotes_mcc: training: 0.879746 validation: 0.868965
09/16 02:23:53 PM: edges-pos-ontonotes_acc: training: 0.832623 validation: 0.833624
09/16 02:23:53 PM: edges-pos-ontonotes_precision: training: 0.896341 validation: 0.892552
09/16 02:23:53 PM: edges-pos-ontonotes_recall: training: 0.868301 validation: 0.851191
09/16 02:23:53 PM: edges-pos-ontonotes_f1: training: 0.882098 validation: 0.871381
09/16 02:23:53 PM: Global learning rate: 3.125e-06
09/16 02:23:53 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 02:24:01 PM: Update 48111: task edges-pos-ontonotes, batch 111 (48111): mcc: 0.8580, acc: 0.8039, precision: 0.8820, recall: 0.8403, f1: 0.8607, edges-pos-ontonotes_loss: 0.0121
09/16 02:24:11 PM: Update 48174: task edges-pos-ontonotes, batch 174 (48174): mcc: 0.8453, acc: 0.7895, precision: 0.8741, recall: 0.8234, f1: 0.8480, edges-pos-ontonotes_loss: 0.0135
09/16 02:24:21 PM: Update 48261: task edges-pos-ontonotes, batch 261 (48261): mcc: 0.8442, acc: 0.7885, precision: 0.8734, recall: 0.8221, f1: 0.8470, edges-pos-ontonotes_loss: 0.0143
09/16 02:24:31 PM: Update 48339: task edges-pos-ontonotes, batch 339 (48339): mcc: 0.8444, acc: 0.7884, precision: 0.8728, recall: 0.8230, f1: 0.8472, edges-pos-ontonotes_loss: 0.0148
09/16 02:24:41 PM: Update 48417: task edges-pos-ontonotes, batch 417 (48417): mcc: 0.8446, acc: 0.7886, precision: 0.8728, recall: 0.8233, f1: 0.8473, edges-pos-ontonotes_loss: 0.0149
09/16 02:24:51 PM: Update 48504: task edges-pos-ontonotes, batch 504 (48504): mcc: 0.8455, acc: 0.7896, precision: 0.8734, recall: 0.8244, f1: 0.8482, edges-pos-ontonotes_loss: 0.0147
09/16 02:25:01 PM: Update 48627: task edges-pos-ontonotes, batch 627 (48627): mcc: 0.8486, acc: 0.7937, precision: 0.8754, recall: 0.8286, f1: 0.8513, edges-pos-ontonotes_loss: 0.0142
09/16 02:25:11 PM: Update 48733: task edges-pos-ontonotes, batch 733 (48733): mcc: 0.8507, acc: 0.7965, precision: 0.8767, recall: 0.8314, f1: 0.8535, edges-pos-ontonotes_loss: 0.0139
09/16 02:25:22 PM: Update 48814: task edges-pos-ontonotes, batch 814 (48814): mcc: 0.8522, acc: 0.7985, precision: 0.8778, recall: 0.8333, f1: 0.8549, edges-pos-ontonotes_loss: 0.0138
09/16 02:25:32 PM: Update 48905: task edges-pos-ontonotes, batch 905 (48905): mcc: 0.8540, acc: 0.8007, precision: 0.8792, recall: 0.8353, f1: 0.8567, edges-pos-ontonotes_loss: 0.0137
09/16 02:25:42 PM: Update 48999: task edges-pos-ontonotes, batch 999 (48999): mcc: 0.8553, acc: 0.8023, precision: 0.8801, recall: 0.8369, f1: 0.8579, edges-pos-ontonotes_loss: 0.0136
09/16 02:25:42 PM: ***** Step 49000 / Validation 49 *****
09/16 02:25:42 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:25:42 PM: Validating...
09/16 02:25:52 PM: Evaluate: task edges-pos-ontonotes, batch 98 (157): mcc: 0.8777, acc: 0.8506, precision: 0.9012, recall: 0.8597, f1: 0.8800, edges-pos-ontonotes_loss: 0.0122
09/16 02:26:00 PM: Updating LR scheduler:
09/16 02:26:00 PM: 	Best result seen so far for macro_avg: 0.877
09/16 02:26:00 PM: 	# validation passes without improvement: 2
09/16 02:26:00 PM: edges-pos-ontonotes_loss: training: 0.013641 validation: 0.012659
09/16 02:26:00 PM: macro_avg: validation: 0.872145
09/16 02:26:00 PM: micro_avg: validation: 0.000000
09/16 02:26:00 PM: edges-pos-ontonotes_mcc: training: 0.855272 validation: 0.869746
09/16 02:26:00 PM: edges-pos-ontonotes_acc: training: 0.802277 validation: 0.841603
09/16 02:26:00 PM: edges-pos-ontonotes_precision: training: 0.880041 validation: 0.893330
09/16 02:26:00 PM: edges-pos-ontonotes_recall: training: 0.836914 validation: 0.851942
09/16 02:26:00 PM: edges-pos-ontonotes_f1: training: 0.857936 validation: 0.872145
09/16 02:26:00 PM: Global learning rate: 3.125e-06
09/16 02:26:00 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 02:26:02 PM: Update 49014: task edges-pos-ontonotes, batch 14 (49014): mcc: 0.8707, acc: 0.8219, precision: 0.8887, recall: 0.8582, f1: 0.8732, edges-pos-ontonotes_loss: 0.0120
09/16 02:26:12 PM: Update 49078: task edges-pos-ontonotes, batch 78 (49078): mcc: 0.8586, acc: 0.8061, precision: 0.8806, recall: 0.8427, f1: 0.8612, edges-pos-ontonotes_loss: 0.0132
09/16 02:26:22 PM: Update 49159: task edges-pos-ontonotes, batch 159 (49159): mcc: 0.8532, acc: 0.7973, precision: 0.8763, recall: 0.8366, f1: 0.8560, edges-pos-ontonotes_loss: 0.0140
09/16 02:26:32 PM: Update 49229: task edges-pos-ontonotes, batch 229 (49229): mcc: 0.8521, acc: 0.7948, precision: 0.8759, recall: 0.8348, f1: 0.8548, edges-pos-ontonotes_loss: 0.0140
09/16 02:26:42 PM: Update 49299: task edges-pos-ontonotes, batch 299 (49299): mcc: 0.8519, acc: 0.7944, precision: 0.8753, recall: 0.8349, f1: 0.8546, edges-pos-ontonotes_loss: 0.0141
09/16 02:26:52 PM: Update 49370: task edges-pos-ontonotes, batch 370 (49370): mcc: 0.8520, acc: 0.7945, precision: 0.8751, recall: 0.8354, f1: 0.8548, edges-pos-ontonotes_loss: 0.0142
09/16 02:27:03 PM: Update 49380: task edges-pos-ontonotes, batch 380 (49380): mcc: 0.8521, acc: 0.7945, precision: 0.8753, recall: 0.8353, f1: 0.8548, edges-pos-ontonotes_loss: 0.0142
09/16 02:27:13 PM: Update 49447: task edges-pos-ontonotes, batch 447 (49447): mcc: 0.8528, acc: 0.7954, precision: 0.8762, recall: 0.8358, f1: 0.8555, edges-pos-ontonotes_loss: 0.0142
09/16 02:27:24 PM: Update 49515: task edges-pos-ontonotes, batch 515 (49515): mcc: 0.8528, acc: 0.7957, precision: 0.8765, recall: 0.8356, f1: 0.8555, edges-pos-ontonotes_loss: 0.0143
09/16 02:27:34 PM: Update 49582: task edges-pos-ontonotes, batch 582 (49582): mcc: 0.8532, acc: 0.7963, precision: 0.8770, recall: 0.8359, f1: 0.8559, edges-pos-ontonotes_loss: 0.0143
09/16 02:27:44 PM: Update 49653: task edges-pos-ontonotes, batch 653 (49653): mcc: 0.8537, acc: 0.7970, precision: 0.8775, recall: 0.8364, f1: 0.8565, edges-pos-ontonotes_loss: 0.0143
09/16 02:27:54 PM: Update 49709: task edges-pos-ontonotes, batch 709 (49709): mcc: 0.8540, acc: 0.7976, precision: 0.8777, recall: 0.8366, f1: 0.8567, edges-pos-ontonotes_loss: 0.0143
09/16 02:28:04 PM: Update 49783: task edges-pos-ontonotes, batch 783 (49783): mcc: 0.8546, acc: 0.7985, precision: 0.8785, recall: 0.8372, f1: 0.8573, edges-pos-ontonotes_loss: 0.0143
09/16 02:28:14 PM: Update 49851: task edges-pos-ontonotes, batch 851 (49851): mcc: 0.8549, acc: 0.7990, precision: 0.8788, recall: 0.8374, f1: 0.8576, edges-pos-ontonotes_loss: 0.0143
09/16 02:28:24 PM: Update 49927: task edges-pos-ontonotes, batch 927 (49927): mcc: 0.8551, acc: 0.7994, precision: 0.8791, recall: 0.8376, f1: 0.8578, edges-pos-ontonotes_loss: 0.0143
09/16 02:28:34 PM: Update 49995: task edges-pos-ontonotes, batch 995 (49995): mcc: 0.8553, acc: 0.7999, precision: 0.8792, recall: 0.8378, f1: 0.8580, edges-pos-ontonotes_loss: 0.0143
09/16 02:28:35 PM: ***** Step 50000 / Validation 50 *****
09/16 02:28:35 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:28:35 PM: Validating...
09/16 02:28:45 PM: Evaluate: task edges-pos-ontonotes, batch 93 (157): mcc: 0.8763, acc: 0.8493, precision: 0.8996, recall: 0.8585, f1: 0.8786, edges-pos-ontonotes_loss: 0.0124
09/16 02:28:54 PM: Updating LR scheduler:
09/16 02:28:54 PM: 	Best result seen so far for macro_avg: 0.877
09/16 02:28:54 PM: 	# validation passes without improvement: 3
09/16 02:28:54 PM: edges-pos-ontonotes_loss: training: 0.014293 validation: 0.012564
09/16 02:28:54 PM: macro_avg: validation: 0.875636
09/16 02:28:54 PM: micro_avg: validation: 0.000000
09/16 02:28:54 PM: edges-pos-ontonotes_mcc: training: 0.855327 validation: 0.873271
09/16 02:28:54 PM: edges-pos-ontonotes_acc: training: 0.799878 validation: 0.844895
09/16 02:28:54 PM: edges-pos-ontonotes_precision: training: 0.879216 validation: 0.895422
09/16 02:28:54 PM: edges-pos-ontonotes_recall: training: 0.837812 validation: 0.856704
09/16 02:28:54 PM: edges-pos-ontonotes_f1: training: 0.858014 validation: 0.875636
09/16 02:28:54 PM: Global learning rate: 3.125e-06
09/16 02:28:54 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 02:28:55 PM: Update 50003: task edges-pos-ontonotes, batch 3 (50003): mcc: 0.8603, acc: 0.8036, precision: 0.8807, recall: 0.8459, f1: 0.8630, edges-pos-ontonotes_loss: 0.0139
09/16 02:29:05 PM: Update 50056: task edges-pos-ontonotes, batch 56 (50056): mcc: 0.8588, acc: 0.8055, precision: 0.8806, recall: 0.8431, f1: 0.8614, edges-pos-ontonotes_loss: 0.0143
09/16 02:29:15 PM: Update 50123: task edges-pos-ontonotes, batch 123 (50123): mcc: 0.8585, acc: 0.8047, precision: 0.8813, recall: 0.8418, f1: 0.8611, edges-pos-ontonotes_loss: 0.0145
09/16 02:29:25 PM: Update 50197: task edges-pos-ontonotes, batch 197 (50197): mcc: 0.8588, acc: 0.8057, precision: 0.8815, recall: 0.8422, f1: 0.8614, edges-pos-ontonotes_loss: 0.0145
09/16 02:29:35 PM: Update 50270: task edges-pos-ontonotes, batch 270 (50270): mcc: 0.8591, acc: 0.8062, precision: 0.8819, recall: 0.8425, f1: 0.8617, edges-pos-ontonotes_loss: 0.0144
09/16 02:29:45 PM: Update 50322: task edges-pos-ontonotes, batch 322 (50322): mcc: 0.8584, acc: 0.8057, precision: 0.8811, recall: 0.8420, f1: 0.8611, edges-pos-ontonotes_loss: 0.0144
09/16 02:29:55 PM: Update 50415: task edges-pos-ontonotes, batch 415 (50415): mcc: 0.8615, acc: 0.8099, precision: 0.8831, recall: 0.8458, f1: 0.8641, edges-pos-ontonotes_loss: 0.0138
09/16 02:30:05 PM: Update 50499: task edges-pos-ontonotes, batch 499 (50499): mcc: 0.8630, acc: 0.8120, precision: 0.8841, recall: 0.8479, f1: 0.8656, edges-pos-ontonotes_loss: 0.0135
09/16 02:30:15 PM: Update 50577: task edges-pos-ontonotes, batch 577 (50577): mcc: 0.8639, acc: 0.8132, precision: 0.8845, recall: 0.8492, f1: 0.8665, edges-pos-ontonotes_loss: 0.0133
09/16 02:30:25 PM: Update 50664: task edges-pos-ontonotes, batch 664 (50664): mcc: 0.8658, acc: 0.8155, precision: 0.8860, recall: 0.8515, f1: 0.8684, edges-pos-ontonotes_loss: 0.0130
09/16 02:30:35 PM: Update 50782: task edges-pos-ontonotes, batch 782 (50782): mcc: 0.8681, acc: 0.8182, precision: 0.8876, recall: 0.8543, f1: 0.8706, edges-pos-ontonotes_loss: 0.0126
09/16 02:30:45 PM: Update 50898: task edges-pos-ontonotes, batch 898 (50898): mcc: 0.8703, acc: 0.8208, precision: 0.8893, recall: 0.8569, f1: 0.8728, edges-pos-ontonotes_loss: 0.0122
09/16 02:30:54 PM: ***** Step 51000 / Validation 51 *****
09/16 02:30:54 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:30:54 PM: Validating...
09/16 02:30:55 PM: Evaluate: task edges-pos-ontonotes, batch 11 (157): mcc: 0.8705, acc: 0.8451, precision: 0.8921, recall: 0.8546, f1: 0.8729, edges-pos-ontonotes_loss: 0.0129
09/16 02:31:05 PM: Evaluate: task edges-pos-ontonotes, batch 107 (157): mcc: 0.8748, acc: 0.8474, precision: 0.8992, recall: 0.8560, f1: 0.8771, edges-pos-ontonotes_loss: 0.0125
09/16 02:31:12 PM: Updating LR scheduler:
09/16 02:31:12 PM: 	Best result seen so far for macro_avg: 0.877
09/16 02:31:12 PM: 	# validation passes without improvement: 0
09/16 02:31:12 PM: edges-pos-ontonotes_loss: training: 0.012062 validation: 0.012675
09/16 02:31:12 PM: macro_avg: validation: 0.874524
09/16 02:31:12 PM: micro_avg: validation: 0.000000
09/16 02:31:12 PM: edges-pos-ontonotes_mcc: training: 0.871290 validation: 0.872206
09/16 02:31:12 PM: edges-pos-ontonotes_acc: training: 0.822053 validation: 0.844376
09/16 02:31:12 PM: edges-pos-ontonotes_precision: training: 0.889907 validation: 0.896940
09/16 02:31:12 PM: edges-pos-ontonotes_recall: training: 0.858220 validation: 0.853202
09/16 02:31:12 PM: edges-pos-ontonotes_f1: training: 0.873776 validation: 0.874524
09/16 02:31:12 PM: Global learning rate: 1.5625e-06
09/16 02:31:12 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 02:31:15 PM: Update 51037: task edges-pos-ontonotes, batch 37 (51037): mcc: 0.8927, acc: 0.8511, precision: 0.9047, recall: 0.8852, f1: 0.8948, edges-pos-ontonotes_loss: 0.0099
09/16 02:31:25 PM: Update 51176: task edges-pos-ontonotes, batch 176 (51176): mcc: 0.8878, acc: 0.8425, precision: 0.9020, recall: 0.8783, f1: 0.8900, edges-pos-ontonotes_loss: 0.0106
09/16 02:31:35 PM: Update 51327: task edges-pos-ontonotes, batch 327 (51327): mcc: 0.8813, acc: 0.8350, precision: 0.8981, recall: 0.8696, f1: 0.8836, edges-pos-ontonotes_loss: 0.0112
09/16 02:31:45 PM: Update 51518: task edges-pos-ontonotes, batch 518 (51518): mcc: 0.8728, acc: 0.8241, precision: 0.8918, recall: 0.8594, f1: 0.8753, edges-pos-ontonotes_loss: 0.0117
09/16 02:31:59 PM: Update 51571: task edges-pos-ontonotes, batch 571 (51571): mcc: 0.8703, acc: 0.8207, precision: 0.8899, recall: 0.8563, f1: 0.8728, edges-pos-ontonotes_loss: 0.0119
09/16 02:32:09 PM: Update 51649: task edges-pos-ontonotes, batch 649 (51649): mcc: 0.8641, acc: 0.8125, precision: 0.8863, recall: 0.8479, f1: 0.8667, edges-pos-ontonotes_loss: 0.0123
09/16 02:32:19 PM: Update 51722: task edges-pos-ontonotes, batch 722 (51722): mcc: 0.8604, acc: 0.8074, precision: 0.8837, recall: 0.8432, f1: 0.8630, edges-pos-ontonotes_loss: 0.0127
09/16 02:32:29 PM: Update 51803: task edges-pos-ontonotes, batch 803 (51803): mcc: 0.8574, acc: 0.8037, precision: 0.8818, recall: 0.8394, f1: 0.8601, edges-pos-ontonotes_loss: 0.0130
09/16 02:32:39 PM: Update 51881: task edges-pos-ontonotes, batch 881 (51881): mcc: 0.8558, acc: 0.8017, precision: 0.8807, recall: 0.8373, f1: 0.8585, edges-pos-ontonotes_loss: 0.0133
09/16 02:32:49 PM: Update 51965: task edges-pos-ontonotes, batch 965 (51965): mcc: 0.8554, acc: 0.8010, precision: 0.8805, recall: 0.8368, f1: 0.8581, edges-pos-ontonotes_loss: 0.0133
09/16 02:32:53 PM: ***** Step 52000 / Validation 52 *****
09/16 02:32:53 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:32:53 PM: Validating...
09/16 02:32:59 PM: Evaluate: task edges-pos-ontonotes, batch 71 (157): mcc: 0.8761, acc: 0.8414, precision: 0.8959, recall: 0.8617, f1: 0.8785, edges-pos-ontonotes_loss: 0.0124
09/16 02:33:09 PM: Evaluate: task edges-pos-ontonotes, batch 144 (157): mcc: 0.8706, acc: 0.8365, precision: 0.8906, recall: 0.8563, f1: 0.8731, edges-pos-ontonotes_loss: 0.0126
09/16 02:33:11 PM: Updating LR scheduler:
09/16 02:33:11 PM: 	Best result seen so far for macro_avg: 0.877
09/16 02:33:11 PM: 	# validation passes without improvement: 1
09/16 02:33:11 PM: edges-pos-ontonotes_loss: training: 0.013294 validation: 0.012677
09/16 02:33:11 PM: macro_avg: validation: 0.872803
09/16 02:33:11 PM: micro_avg: validation: 0.000000
09/16 02:33:11 PM: edges-pos-ontonotes_mcc: training: 0.855604 validation: 0.870324
09/16 02:33:11 PM: edges-pos-ontonotes_acc: training: 0.801264 validation: 0.835995
09/16 02:33:11 PM: edges-pos-ontonotes_precision: training: 0.880617 validation: 0.890227
09/16 02:33:11 PM: edges-pos-ontonotes_recall: training: 0.836999 validation: 0.856048
09/16 02:33:11 PM: edges-pos-ontonotes_f1: training: 0.858254 validation: 0.872803
09/16 02:33:11 PM: Global learning rate: 1.5625e-06
09/16 02:33:11 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 02:33:19 PM: Update 52088: task edges-pos-ontonotes, batch 88 (52088): mcc: 0.8611, acc: 0.8065, precision: 0.8836, recall: 0.8447, f1: 0.8637, edges-pos-ontonotes_loss: 0.0126
09/16 02:33:30 PM: Update 52214: task edges-pos-ontonotes, batch 214 (52214): mcc: 0.8637, acc: 0.8103, precision: 0.8856, recall: 0.8477, f1: 0.8662, edges-pos-ontonotes_loss: 0.0122
09/16 02:33:40 PM: Update 52309: task edges-pos-ontonotes, batch 309 (52309): mcc: 0.8650, acc: 0.8121, precision: 0.8868, recall: 0.8491, f1: 0.8675, edges-pos-ontonotes_loss: 0.0124
09/16 02:33:50 PM: Update 52390: task edges-pos-ontonotes, batch 390 (52390): mcc: 0.8651, acc: 0.8123, precision: 0.8871, recall: 0.8490, f1: 0.8677, edges-pos-ontonotes_loss: 0.0126
09/16 02:34:00 PM: Update 52484: task edges-pos-ontonotes, batch 484 (52484): mcc: 0.8660, acc: 0.8131, precision: 0.8880, recall: 0.8499, f1: 0.8685, edges-pos-ontonotes_loss: 0.0126
09/16 02:34:11 PM: Update 52550: task edges-pos-ontonotes, batch 550 (52550): mcc: 0.8642, acc: 0.8110, precision: 0.8865, recall: 0.8479, f1: 0.8668, edges-pos-ontonotes_loss: 0.0127
09/16 02:34:21 PM: Update 52622: task edges-pos-ontonotes, batch 622 (52622): mcc: 0.8624, acc: 0.8082, precision: 0.8850, recall: 0.8459, f1: 0.8650, edges-pos-ontonotes_loss: 0.0129
09/16 02:34:31 PM: Update 52698: task edges-pos-ontonotes, batch 698 (52698): mcc: 0.8609, acc: 0.8060, precision: 0.8838, recall: 0.8441, f1: 0.8635, edges-pos-ontonotes_loss: 0.0131
09/16 02:34:41 PM: Update 52765: task edges-pos-ontonotes, batch 765 (52765): mcc: 0.8597, acc: 0.8045, precision: 0.8828, recall: 0.8428, f1: 0.8623, edges-pos-ontonotes_loss: 0.0132
09/16 02:34:51 PM: Update 52838: task edges-pos-ontonotes, batch 838 (52838): mcc: 0.8586, acc: 0.8028, precision: 0.8818, recall: 0.8416, f1: 0.8612, edges-pos-ontonotes_loss: 0.0133
09/16 02:35:01 PM: Update 52892: task edges-pos-ontonotes, batch 892 (52892): mcc: 0.8584, acc: 0.8026, precision: 0.8818, recall: 0.8412, f1: 0.8610, edges-pos-ontonotes_loss: 0.0134
09/16 02:35:11 PM: Update 52963: task edges-pos-ontonotes, batch 963 (52963): mcc: 0.8580, acc: 0.8022, precision: 0.8814, recall: 0.8408, f1: 0.8606, edges-pos-ontonotes_loss: 0.0135
09/16 02:35:17 PM: ***** Step 53000 / Validation 53 *****
09/16 02:35:17 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:35:17 PM: Validating...
09/16 02:35:21 PM: Evaluate: task edges-pos-ontonotes, batch 48 (157): mcc: 0.8692, acc: 0.8410, precision: 0.8954, recall: 0.8489, f1: 0.8715, edges-pos-ontonotes_loss: 0.0127
09/16 02:35:31 PM: Evaluate: task edges-pos-ontonotes, batch 129 (157): mcc: 0.8724, acc: 0.8435, precision: 0.8958, recall: 0.8547, f1: 0.8747, edges-pos-ontonotes_loss: 0.0125
09/16 02:35:35 PM: Updating LR scheduler:
09/16 02:35:35 PM: 	Best result seen so far for macro_avg: 0.877
09/16 02:35:35 PM: 	# validation passes without improvement: 2
09/16 02:35:35 PM: Ran out of early stopping patience. Stopping training.
09/16 02:35:35 PM: edges-pos-ontonotes_loss: training: 0.013520 validation: 0.012584
09/16 02:35:35 PM: macro_avg: validation: 0.874926
09/16 02:35:35 PM: micro_avg: validation: 0.000000
09/16 02:35:35 PM: edges-pos-ontonotes_mcc: training: 0.857937 validation: 0.872570
09/16 02:35:35 PM: edges-pos-ontonotes_acc: training: 0.802231 validation: 0.843762
09/16 02:35:35 PM: edges-pos-ontonotes_precision: training: 0.881497 validation: 0.895594
09/16 02:35:35 PM: edges-pos-ontonotes_recall: training: 0.840633 validation: 0.855191
09/16 02:35:35 PM: edges-pos-ontonotes_f1: training: 0.860580 validation: 0.874926
09/16 02:35:35 PM: Global learning rate: 1.5625e-06
09/16 02:35:35 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-only/run
09/16 02:35:35 PM: Stopped training after 53 validation checks
09/16 02:35:35 PM: Trained edges-pos-ontonotes for 53000 batches or 15.345 epochs
09/16 02:35:35 PM: ***** VALIDATION RESULTS *****
09/16 02:35:35 PM: edges-pos-ontonotes_f1 (for best val pass 43): edges-pos-ontonotes_loss: 0.01263, macro_avg: 0.87722, micro_avg: 0.00000, edges-pos-ontonotes_mcc: 0.87476, edges-pos-ontonotes_acc: 0.85101, edges-pos-ontonotes_precision: 0.89140, edges-pos-ontonotes_recall: 0.86348, edges-pos-ontonotes_f1: 0.87722
09/16 02:35:35 PM: micro_avg (for best val pass 1): edges-pos-ontonotes_loss: 0.01973, macro_avg: 0.82444, micro_avg: 0.00000, edges-pos-ontonotes_mcc: 0.82293, edges-pos-ontonotes_acc: 0.74864, edges-pos-ontonotes_precision: 0.88439, edges-pos-ontonotes_recall: 0.77211, edges-pos-ontonotes_f1: 0.82444
09/16 02:35:35 PM: macro_avg (for best val pass 43): edges-pos-ontonotes_loss: 0.01263, macro_avg: 0.87722, micro_avg: 0.00000, edges-pos-ontonotes_mcc: 0.87476, edges-pos-ontonotes_acc: 0.85101, edges-pos-ontonotes_precision: 0.89140, edges-pos-ontonotes_recall: 0.86348, edges-pos-ontonotes_f1: 0.87722
09/16 02:35:35 PM: Evaluating...
09/16 02:35:35 PM: Loaded model state from ./experiments/pos-ontonotes-sts-only/run/edges-pos-ontonotes/model_state_target_train_val_43.best.th
09/16 02:35:35 PM: Evaluating on: edges-pos-ontonotes, split: val
09/16 02:36:05 PM: 	Task edges-pos-ontonotes: batch 209
09/16 02:36:35 PM: 	Task edges-pos-ontonotes: batch 354
09/16 02:36:47 PM: Task 'edges-pos-ontonotes': sorting predictions by 'idx'
09/16 02:36:47 PM: Finished evaluating on: edges-pos-ontonotes
09/16 02:36:48 PM: Task 'edges-pos-ontonotes': joining predictions with input split 'val'
09/16 02:37:00 PM: Task 'edges-pos-ontonotes': Wrote predictions to ./experiments/pos-ontonotes-sts-only/run
09/16 02:37:00 PM: Wrote all preds for split 'val' to ./experiments/pos-ontonotes-sts-only/run
09/16 02:37:00 PM: Evaluating on: edges-pos-ontonotes, split: test
09/16 02:37:30 PM: 	Task edges-pos-ontonotes: batch 202
09/16 02:37:47 PM: Task 'edges-pos-ontonotes': sorting predictions by 'idx'
09/16 02:37:47 PM: Finished evaluating on: edges-pos-ontonotes
09/16 02:37:47 PM: Task 'edges-pos-ontonotes': joining predictions with input split 'test'
09/16 02:37:56 PM: Task 'edges-pos-ontonotes': Wrote predictions to ./experiments/pos-ontonotes-sts-only/run
09/16 02:37:56 PM: Wrote all preds for split 'test' to ./experiments/pos-ontonotes-sts-only/run
09/16 02:37:56 PM: Writing results for split 'val' to ./experiments/pos-ontonotes-sts-only/results.tsv
09/16 02:37:56 PM: micro_avg: 0.000, macro_avg: 0.878, edges-pos-ontonotes_mcc: 0.876, edges-pos-ontonotes_acc: 0.853, edges-pos-ontonotes_precision: 0.893, edges-pos-ontonotes_recall: 0.864, edges-pos-ontonotes_f1: 0.878
09/16 02:37:57 PM: Done!
09/16 02:37:57 PM: Fatal error in main():
Traceback (most recent call last):
  File "main.py", line 16, in <module>
    main(sys.argv[1:])
  File "/srv/home/ericwallace/jiant/jiant/__main__.py", line 610, in main
    exit("Done exited")
  File "/home/ericwallace/miniconda3/envs/jiant/lib/python3.6/_sitebuiltins.py", line 26, in __call__
    raise SystemExit(code)
SystemExit: Done exited
