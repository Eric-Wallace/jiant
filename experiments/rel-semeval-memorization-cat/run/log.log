09/16 12:09:09 PM: Git branch: master
09/16 12:09:09 PM: Git SHA: 93c1dfd555f3458ddbb66d458dfeca984f2d8527
09/16 12:09:09 PM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/rel-semeval-memorization-cat/",
  "exp_name": "experiments/rel-semeval-memorization-cat",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/rel-semeval-memorization-cat/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/memorization",
  "pytorch_transformers_output_mode": "cat",
  "remote_log_name": "experiments/rel-semeval-memorization-cat__run",
  "run_dir": "./experiments/rel-semeval-memorization-cat/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-rel-semeval",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 12:09:09 PM: Saved config to ./experiments/rel-semeval-memorization-cat/run/params.conf
09/16 12:09:09 PM: Using random seed 1234
09/16 12:09:38 PM: Using GPU 0
09/16 12:09:38 PM: Loading tasks...
09/16 12:09:38 PM: Writing pre-preprocessed tasks to ./experiments/rel-semeval-memorization-cat/
09/16 12:09:38 PM: 	Creating task edges-rel-semeval from scratch.
09/16 12:09:38 PM: Read=6851, Skip=0, Total=6851 from ./probing_data/edges/semeval/train.0.85.json.retokenized.bert-base-uncased
09/16 12:09:38 PM: Read=1149, Skip=0, Total=1149 from ./probing_data/edges/semeval/dev.json.retokenized.bert-base-uncased
09/16 12:09:38 PM: Read=2717, Skip=0, Total=2717 from ./probing_data/edges/semeval/test.json.retokenized.bert-base-uncased
09/16 12:09:38 PM: 	Task 'edges-rel-semeval': |train|=6851 |val|=1149 |test|=2717
09/16 12:09:38 PM: 	Finished loading tasks: edges-rel-semeval.
09/16 12:09:38 PM: 	Building vocab from scratch.
09/16 12:09:38 PM: 	Counting units for task edges-rel-semeval.
09/16 12:09:38 PM: 	Task 'edges-rel-semeval': adding vocab namespace 'edges-rel-semeval_labels'
09/16 12:09:39 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:09:39 PM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 12:09:40 PM: 	Saved vocab to ./experiments/rel-semeval-memorization-cat/vocab
09/16 12:09:40 PM: Loading token dictionary from ./experiments/rel-semeval-memorization-cat/vocab.
09/16 12:09:40 PM: 	Loaded vocab from ./experiments/rel-semeval-memorization-cat/vocab
09/16 12:09:40 PM: 	Vocab namespace tokens: size 16020
09/16 12:09:40 PM: 	Vocab namespace bert_uncased: size 30524
09/16 12:09:40 PM: 	Vocab namespace edges-rel-semeval_labels: size 19
09/16 12:09:40 PM: 	Vocab namespace chars: size 59
09/16 12:09:40 PM: 	Finished building vocab.
09/16 12:09:40 PM: 	Task edges-rel-semeval (train): Indexing from scratch.
09/16 12:09:41 PM: 	Task edges-rel-semeval (train): Saved 6851 instances to ./experiments/rel-semeval-memorization-cat/preproc/edges-rel-semeval__train_data
09/16 12:09:41 PM: 	Task edges-rel-semeval (val): Indexing from scratch.
09/16 12:09:41 PM: 	Task edges-rel-semeval (val): Saved 1149 instances to ./experiments/rel-semeval-memorization-cat/preproc/edges-rel-semeval__val_data
09/16 12:09:41 PM: 	Task edges-rel-semeval (test): Indexing from scratch.
09/16 12:09:41 PM: 	Task edges-rel-semeval (test): Saved 2717 instances to ./experiments/rel-semeval-memorization-cat/preproc/edges-rel-semeval__test_data
09/16 12:09:41 PM: 	Finished indexing tasks
09/16 12:09:41 PM: 	Creating trimmed target-only version of edges-rel-semeval train.
09/16 12:09:41 PM: 	  Training on 
09/16 12:09:41 PM: 	  Evaluating on edges-rel-semeval
09/16 12:09:41 PM: 	Finished loading tasks in 3.590s
09/16 12:09:41 PM: 	 Tasks: ['edges-rel-semeval']
09/16 12:09:41 PM: Building model...
09/16 12:09:41 PM: Using BERT model (bert-base-uncased).
09/16 12:09:41 PM: LOADING A FUNETUNED MODEL from: 
09/16 12:09:41 PM: models/memorization
09/16 12:09:41 PM: loading configuration file models/memorization/config.json
09/16 12:09:41 PM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "random-memorization",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 12:09:41 PM: loading weights file models/memorization/pytorch_model.bin
09/16 12:09:45 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmph46r4lio
09/16 12:09:48 PM: copying /tmp/tmph46r4lio to cache at ./experiments/rel-semeval-memorization-cat/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:09:48 PM: creating metadata file for ./experiments/rel-semeval-memorization-cat/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:09:48 PM: removing temp file /tmp/tmph46r4lio
09/16 12:09:48 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/rel-semeval-memorization-cat/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:09:48 PM: Initializing parameters
09/16 12:09:48 PM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 12:09:48 PM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 12:09:48 PM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 12:09:48 PM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.pooler.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.pooler.dense.weight
09/16 12:09:48 PM: 	Task 'edges-rel-semeval' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-rel-semeval"
}
09/16 12:10:10 PM: Model specification:
09/16 12:10:10 PM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-rel-semeval_mdl): EdgeClassifierModule(
    (proj1): Conv1d(1536, 256, kernel_size=(1,), stride=(1,))
    (proj2): Conv1d(1536, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (span_extractor2): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Sequential(
        (0): Linear(in_features=1024, out_features=256, bias=True)
        (1): Tanh()
        (2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)
        (3): Dropout(p=0.3)
        (4): Linear(in_features=256, out_features=19, bias=True)
      )
    )
  )
)
09/16 12:10:10 PM: Model parameters:
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	edges-rel-semeval_mdl.proj1.weight: Trainable parameter, count 393216 with torch.Size([256, 1536, 1])
09/16 12:10:10 PM: 	edges-rel-semeval_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 12:10:10 PM: 	edges-rel-semeval_mdl.proj2.weight: Trainable parameter, count 393216 with torch.Size([256, 1536, 1])
09/16 12:10:10 PM: 	edges-rel-semeval_mdl.proj2.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 12:10:10 PM: 	edges-rel-semeval_mdl.classifier.classifier.0.weight: Trainable parameter, count 262144 with torch.Size([256, 1024])
09/16 12:10:10 PM: 	edges-rel-semeval_mdl.classifier.classifier.0.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 12:10:10 PM: 	edges-rel-semeval_mdl.classifier.classifier.2.weight: Trainable parameter, count 256 with torch.Size([256])
09/16 12:10:10 PM: 	edges-rel-semeval_mdl.classifier.classifier.2.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 12:10:10 PM: 	edges-rel-semeval_mdl.classifier.classifier.4.weight: Trainable parameter, count 4864 with torch.Size([19, 256])
09/16 12:10:10 PM: 	edges-rel-semeval_mdl.classifier.classifier.4.bias: Trainable parameter, count 19 with torch.Size([19])
09/16 12:10:10 PM: Total number of parameters: 110536979 (1.10537e+08)
09/16 12:10:10 PM: Number of trainable parameters: 1054739 (1.05474e+06)
09/16 12:10:10 PM: Finished building model in 28.605s
09/16 12:10:10 PM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-rel-semeval 

09/16 12:10:11 PM: patience = 9
09/16 12:10:11 PM: val_interval = 100
09/16 12:10:11 PM: max_vals = 100
09/16 12:10:11 PM: cuda_device = 0
09/16 12:10:11 PM: grad_norm = 5.0
09/16 12:10:11 PM: grad_clipping = None
09/16 12:10:11 PM: lr_decay = 0.99
09/16 12:10:11 PM: min_lr = 1e-06
09/16 12:10:11 PM: keep_all_checkpoints = 0
09/16 12:10:11 PM: val_data_limit = 5000
09/16 12:10:11 PM: max_epochs = -1
09/16 12:10:11 PM: dec_val_scale = 250
09/16 12:10:11 PM: training_data_fraction = 1
09/16 12:10:11 PM: type = adam
09/16 12:10:11 PM: parameter_groups = None
09/16 12:10:11 PM: Number of trainable parameters: 1054739
09/16 12:10:11 PM: infer_type_and_cast = True
09/16 12:10:11 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:10:11 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:10:11 PM: lr = 0.0001
09/16 12:10:11 PM: amsgrad = True
09/16 12:10:11 PM: type = reduce_on_plateau
09/16 12:10:11 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:10:11 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:10:11 PM: mode = max
09/16 12:10:11 PM: factor = 0.5
09/16 12:10:11 PM: patience = 3
09/16 12:10:11 PM: threshold = 0.0001
09/16 12:10:11 PM: threshold_mode = abs
09/16 12:10:11 PM: verbose = True
09/16 12:10:11 PM: type = adam
09/16 12:10:11 PM: parameter_groups = None
09/16 12:10:11 PM: Number of trainable parameters: 1054739
09/16 12:10:11 PM: infer_type_and_cast = True
09/16 12:10:11 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:10:11 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:10:11 PM: lr = 0.0001
09/16 12:10:11 PM: amsgrad = True
09/16 12:10:11 PM: type = reduce_on_plateau
09/16 12:10:11 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:10:11 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:10:11 PM: mode = max
09/16 12:10:11 PM: factor = 0.5
09/16 12:10:11 PM: patience = 3
09/16 12:10:11 PM: threshold = 0.0001
09/16 12:10:11 PM: threshold_mode = abs
09/16 12:10:11 PM: verbose = True
09/16 12:10:11 PM: Starting training without restoring from a checkpoint.
09/16 12:10:11 PM: Training examples per task, before any subsampling: {'edges-rel-semeval': 6851}
09/16 12:10:11 PM: Beginning training with stopping criteria based on metric: edges-rel-semeval_f1
09/16 12:10:17 PM: ***** Step 100 / Validation 1 *****
09/16 12:10:17 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:10:17 PM: Validating...
09/16 12:10:21 PM: Evaluate: task edges-rel-semeval, batch 20 (36): mcc: 0.0000, acc: 0.0000, precision: 0.0000, recall: 0.0000, f1: 0.0000, edges-rel-semeval_loss: 0.1794
09/16 12:10:22 PM: Best result seen so far for edges-rel-semeval.
09/16 12:10:22 PM: Best result seen so far for micro.
09/16 12:10:22 PM: Best result seen so far for macro.
09/16 12:10:22 PM: Updating LR scheduler:
09/16 12:10:22 PM: 	Best result seen so far for macro_avg: 0.000
09/16 12:10:22 PM: 	# validation passes without improvement: 0
09/16 12:10:22 PM: edges-rel-semeval_loss: training: 0.246206 validation: 0.179615
09/16 12:10:22 PM: macro_avg: validation: 0.000000
09/16 12:10:22 PM: micro_avg: validation: 0.000000
09/16 12:10:22 PM: edges-rel-semeval_mcc: training: 0.005014 validation: 0.000000
09/16 12:10:22 PM: edges-rel-semeval_acc: training: 0.002838 validation: 0.000000
09/16 12:10:22 PM: edges-rel-semeval_precision: training: 0.060580 validation: 0.000000
09/16 12:10:22 PM: edges-rel-semeval_recall: training: 0.022390 validation: 0.000000
09/16 12:10:22 PM: edges-rel-semeval_f1: training: 0.032696 validation: 0.000000
09/16 12:10:22 PM: Global learning rate: 0.0001
09/16 12:10:22 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:10:31 PM: Update 179: task edges-rel-semeval, batch 79 (179): mcc: 0.0884, acc: 0.0107, precision: 0.7941, recall: 0.0107, f1: 0.0211, edges-rel-semeval_loss: 0.1756
09/16 12:10:32 PM: ***** Step 200 / Validation 2 *****
09/16 12:10:32 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:10:32 PM: Validating...
09/16 12:10:35 PM: Best result seen so far for edges-rel-semeval.
09/16 12:10:35 PM: Best result seen so far for macro.
09/16 12:10:35 PM: Updating LR scheduler:
09/16 12:10:35 PM: 	Best result seen so far for macro_avg: 0.093
09/16 12:10:35 PM: 	# validation passes without improvement: 0
09/16 12:10:35 PM: edges-rel-semeval_loss: training: 0.172882 validation: 0.150638
09/16 12:10:35 PM: macro_avg: validation: 0.092639
09/16 12:10:35 PM: micro_avg: validation: 0.000000
09/16 12:10:35 PM: edges-rel-semeval_mcc: training: 0.097227 validation: 0.207054
09/16 12:10:35 PM: edges-rel-semeval_acc: training: 0.014063 validation: 0.048738
09/16 12:10:35 PM: edges-rel-semeval_precision: training: 0.737705 validation: 0.933333
09/16 12:10:35 PM: edges-rel-semeval_recall: training: 0.014062 validation: 0.048738
09/16 12:10:35 PM: edges-rel-semeval_f1: training: 0.027599 validation: 0.092639
09/16 12:10:35 PM: Global learning rate: 0.0001
09/16 12:10:35 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:10:41 PM: Update 285: task edges-rel-semeval, batch 85 (285): mcc: 0.3113, acc: 0.1252, precision: 0.8182, recall: 0.1271, f1: 0.2200, edges-rel-semeval_loss: 0.1455
09/16 12:10:42 PM: ***** Step 300 / Validation 3 *****
09/16 12:10:42 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:10:42 PM: Validating...
09/16 12:10:45 PM: Best result seen so far for edges-rel-semeval.
09/16 12:10:45 PM: Best result seen so far for macro.
09/16 12:10:45 PM: Updating LR scheduler:
09/16 12:10:45 PM: 	Best result seen so far for macro_avg: 0.265
09/16 12:10:45 PM: 	# validation passes without improvement: 0
09/16 12:10:45 PM: edges-rel-semeval_loss: training: 0.144701 validation: 0.128735
09/16 12:10:45 PM: macro_avg: validation: 0.265382
09/16 12:10:45 PM: micro_avg: validation: 0.000000
09/16 12:10:45 PM: edges-rel-semeval_mcc: training: 0.313316 validation: 0.362741
09/16 12:10:45 PM: edges-rel-semeval_acc: training: 0.129297 validation: 0.154917
09/16 12:10:45 PM: edges-rel-semeval_precision: training: 0.804642 validation: 0.895000
09/16 12:10:45 PM: edges-rel-semeval_recall: training: 0.131189 validation: 0.155788
09/16 12:10:45 PM: edges-rel-semeval_f1: training: 0.225597 validation: 0.265382
09/16 12:10:45 PM: Global learning rate: 0.0001
09/16 12:10:45 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:10:51 PM: ***** Step 400 / Validation 4 *****
09/16 12:10:51 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:10:51 PM: Validating...
09/16 12:10:51 PM: Evaluate: task edges-rel-semeval, batch 1 (36): mcc: 0.5798, acc: 0.4062, precision: 0.8667, recall: 0.4062, f1: 0.5532, edges-rel-semeval_loss: 0.1024
09/16 12:10:54 PM: Best result seen so far for edges-rel-semeval.
09/16 12:10:54 PM: Best result seen so far for macro.
09/16 12:10:54 PM: Updating LR scheduler:
09/16 12:10:54 PM: 	Best result seen so far for macro_avg: 0.400
09/16 12:10:54 PM: 	# validation passes without improvement: 0
09/16 12:10:54 PM: edges-rel-semeval_loss: training: 0.125638 validation: 0.115173
09/16 12:10:54 PM: macro_avg: validation: 0.399729
09/16 12:10:54 PM: micro_avg: validation: 0.000000
09/16 12:10:54 PM: edges-rel-semeval_mcc: training: 0.452116 validation: 0.469137
09/16 12:10:54 PM: edges-rel-semeval_acc: training: 0.252812 validation: 0.255004
09/16 12:10:54 PM: edges-rel-semeval_precision: training: 0.840979 validation: 0.902141
09/16 12:10:54 PM: edges-rel-semeval_recall: training: 0.257812 validation: 0.256745
09/16 12:10:54 PM: edges-rel-semeval_f1: training: 0.394642 validation: 0.399729
09/16 12:10:54 PM: Global learning rate: 0.0001
09/16 12:10:54 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:11:01 PM: ***** Step 500 / Validation 5 *****
09/16 12:11:01 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:11:01 PM: Validating...
09/16 12:11:01 PM: Evaluate: task edges-rel-semeval, batch 5 (36): mcc: 0.6288, acc: 0.4437, precision: 0.9012, recall: 0.4563, f1: 0.6058, edges-rel-semeval_loss: 0.0956
09/16 12:11:04 PM: Best result seen so far for edges-rel-semeval.
09/16 12:11:05 PM: Best result seen so far for macro.
09/16 12:11:05 PM: Updating LR scheduler:
09/16 12:11:05 PM: 	Best result seen so far for macro_avg: 0.493
09/16 12:11:05 PM: 	# validation passes without improvement: 0
09/16 12:11:05 PM: edges-rel-semeval_loss: training: 0.112792 validation: 0.104900
09/16 12:11:05 PM: macro_avg: validation: 0.493409
09/16 12:11:05 PM: micro_avg: validation: 0.000000
09/16 12:11:05 PM: edges-rel-semeval_mcc: training: 0.516139 validation: 0.537180
09/16 12:11:05 PM: edges-rel-semeval_acc: training: 0.322927 validation: 0.337685
09/16 12:11:05 PM: edges-rel-semeval_precision: training: 0.838990 validation: 0.885135
09/16 12:11:05 PM: edges-rel-semeval_recall: training: 0.335225 validation: 0.342037
09/16 12:11:05 PM: edges-rel-semeval_f1: training: 0.479045 validation: 0.493409
09/16 12:11:05 PM: Global learning rate: 0.0001
09/16 12:11:05 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:11:11 PM: ***** Step 600 / Validation 6 *****
09/16 12:11:11 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:11:11 PM: Validating...
09/16 12:11:11 PM: Evaluate: task edges-rel-semeval, batch 1 (36): mcc: 0.6541, acc: 0.4688, precision: 0.8889, recall: 0.5000, f1: 0.6400, edges-rel-semeval_loss: 0.0862
09/16 12:11:14 PM: Best result seen so far for edges-rel-semeval.
09/16 12:11:14 PM: Best result seen so far for macro.
09/16 12:11:14 PM: Updating LR scheduler:
09/16 12:11:14 PM: 	Best result seen so far for macro_avg: 0.547
09/16 12:11:14 PM: 	# validation passes without improvement: 0
09/16 12:11:14 PM: edges-rel-semeval_loss: training: 0.102129 validation: 0.098433
09/16 12:11:14 PM: macro_avg: validation: 0.546763
09/16 12:11:14 PM: micro_avg: validation: 0.000000
09/16 12:11:14 PM: edges-rel-semeval_mcc: training: 0.580528 validation: 0.577244
09/16 12:11:14 PM: edges-rel-semeval_acc: training: 0.401562 validation: 0.390775
09/16 12:11:14 PM: edges-rel-semeval_precision: training: 0.848061 validation: 0.878613
09/16 12:11:14 PM: edges-rel-semeval_recall: training: 0.416875 validation: 0.396867
09/16 12:11:14 PM: edges-rel-semeval_f1: training: 0.558978 validation: 0.546763
09/16 12:11:14 PM: Global learning rate: 0.0001
09/16 12:11:14 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:11:21 PM: ***** Step 700 / Validation 7 *****
09/16 12:11:21 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:11:21 PM: Validating...
09/16 12:11:21 PM: Evaluate: task edges-rel-semeval, batch 4 (36): mcc: 0.6573, acc: 0.5000, precision: 0.8590, recall: 0.5234, f1: 0.6505, edges-rel-semeval_loss: 0.0834
09/16 12:11:24 PM: Best result seen so far for edges-rel-semeval.
09/16 12:11:24 PM: Best result seen so far for macro.
09/16 12:11:24 PM: Updating LR scheduler:
09/16 12:11:24 PM: 	Best result seen so far for macro_avg: 0.583
09/16 12:11:24 PM: 	# validation passes without improvement: 0
09/16 12:11:24 PM: edges-rel-semeval_loss: training: 0.093313 validation: 0.092717
09/16 12:11:24 PM: macro_avg: validation: 0.583382
09/16 12:11:24 PM: micro_avg: validation: 0.000000
09/16 12:11:24 PM: edges-rel-semeval_mcc: training: 0.622412 validation: 0.606029
09/16 12:11:24 PM: edges-rel-semeval_acc: training: 0.453485 validation: 0.427328
09/16 12:11:24 PM: edges-rel-semeval_precision: training: 0.856898 validation: 0.877622
09/16 12:11:24 PM: edges-rel-semeval_recall: training: 0.472091 validation: 0.436902
09/16 12:11:24 PM: edges-rel-semeval_f1: training: 0.608784 validation: 0.583382
09/16 12:11:24 PM: Global learning rate: 0.0001
09/16 12:11:24 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:11:30 PM: ***** Step 800 / Validation 8 *****
09/16 12:11:30 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:11:30 PM: Validating...
09/16 12:11:31 PM: Evaluate: task edges-rel-semeval, batch 18 (36): mcc: 0.6590, acc: 0.4896, precision: 0.8951, recall: 0.5035, f1: 0.6444, edges-rel-semeval_loss: 0.0836
09/16 12:11:33 PM: Best result seen so far for edges-rel-semeval.
09/16 12:11:33 PM: Best result seen so far for macro.
09/16 12:11:33 PM: Updating LR scheduler:
09/16 12:11:33 PM: 	Best result seen so far for macro_avg: 0.603
09/16 12:11:33 PM: 	# validation passes without improvement: 0
09/16 12:11:33 PM: edges-rel-semeval_loss: training: 0.086432 validation: 0.088991
09/16 12:11:33 PM: macro_avg: validation: 0.603193
09/16 12:11:33 PM: micro_avg: validation: 0.000000
09/16 12:11:33 PM: edges-rel-semeval_mcc: training: 0.658904 validation: 0.621298
09/16 12:11:33 PM: edges-rel-semeval_acc: training: 0.498750 validation: 0.447346
09/16 12:11:33 PM: edges-rel-semeval_precision: training: 0.863707 validation: 0.874380
09/16 12:11:33 PM: edges-rel-semeval_recall: training: 0.522812 validation: 0.460400
09/16 12:11:33 PM: edges-rel-semeval_f1: training: 0.651353 validation: 0.603193
09/16 12:11:33 PM: Global learning rate: 0.0001
09/16 12:11:33 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:11:40 PM: ***** Step 900 / Validation 9 *****
09/16 12:11:40 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:11:40 PM: Validating...
09/16 12:11:42 PM: Evaluate: task edges-rel-semeval, batch 16 (36): mcc: 0.6745, acc: 0.5176, precision: 0.8940, recall: 0.5273, f1: 0.6634, edges-rel-semeval_loss: 0.0810
09/16 12:11:43 PM: Best result seen so far for edges-rel-semeval.
09/16 12:11:43 PM: Best result seen so far for macro.
09/16 12:11:43 PM: Updating LR scheduler:
09/16 12:11:43 PM: 	Best result seen so far for macro_avg: 0.627
09/16 12:11:43 PM: 	# validation passes without improvement: 0
09/16 12:11:43 PM: edges-rel-semeval_loss: training: 0.081823 validation: 0.086132
09/16 12:11:43 PM: macro_avg: validation: 0.627232
09/16 12:11:43 PM: micro_avg: validation: 0.000000
09/16 12:11:43 PM: edges-rel-semeval_mcc: training: 0.671723 validation: 0.640812
09/16 12:11:43 PM: edges-rel-semeval_acc: training: 0.521287 validation: 0.477807
09/16 12:11:43 PM: edges-rel-semeval_precision: training: 0.851022 validation: 0.874028
09/16 12:11:43 PM: edges-rel-semeval_recall: training: 0.551246 validation: 0.489121
09/16 12:11:43 PM: edges-rel-semeval_f1: training: 0.669091 validation: 0.627232
09/16 12:11:43 PM: Global learning rate: 0.0001
09/16 12:11:43 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:11:49 PM: ***** Step 1000 / Validation 10 *****
09/16 12:11:49 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:11:49 PM: Validating...
09/16 12:11:52 PM: Evaluate: task edges-rel-semeval, batch 28 (36): mcc: 0.6727, acc: 0.5279, precision: 0.8663, recall: 0.5424, f1: 0.6671, edges-rel-semeval_loss: 0.0812
09/16 12:11:52 PM: Best result seen so far for edges-rel-semeval.
09/16 12:11:52 PM: Best result seen so far for macro.
09/16 12:11:52 PM: Updating LR scheduler:
09/16 12:11:52 PM: 	Best result seen so far for macro_avg: 0.647
09/16 12:11:52 PM: 	# validation passes without improvement: 0
09/16 12:11:52 PM: edges-rel-semeval_loss: training: 0.073392 validation: 0.083888
09/16 12:11:52 PM: macro_avg: validation: 0.647281
09/16 12:11:52 PM: micro_avg: validation: 0.000000
09/16 12:11:52 PM: edges-rel-semeval_mcc: training: 0.729635 validation: 0.652829
09/16 12:11:52 PM: edges-rel-semeval_acc: training: 0.589688 validation: 0.503916
09/16 12:11:52 PM: edges-rel-semeval_precision: training: 0.888190 validation: 0.848870
09/16 12:11:52 PM: edges-rel-semeval_recall: training: 0.618125 validation: 0.523064
09/16 12:11:52 PM: edges-rel-semeval_f1: training: 0.728948 validation: 0.647281
09/16 12:11:52 PM: Global learning rate: 0.0001
09/16 12:11:52 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:11:59 PM: ***** Step 1100 / Validation 11 *****
09/16 12:11:59 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:11:59 PM: Validating...
09/16 12:12:02 PM: Evaluate: task edges-rel-semeval, batch 32 (36): mcc: 0.6906, acc: 0.5469, precision: 0.8841, recall: 0.5586, f1: 0.6846, edges-rel-semeval_loss: 0.0785
09/16 12:12:02 PM: Best result seen so far for edges-rel-semeval.
09/16 12:12:02 PM: Best result seen so far for macro.
09/16 12:12:02 PM: Updating LR scheduler:
09/16 12:12:02 PM: 	Best result seen so far for macro_avg: 0.663
09/16 12:12:02 PM: 	# validation passes without improvement: 0
09/16 12:12:02 PM: edges-rel-semeval_loss: training: 0.071914 validation: 0.081928
09/16 12:12:02 PM: macro_avg: validation: 0.663067
09/16 12:12:02 PM: micro_avg: validation: 0.000000
09/16 12:12:02 PM: edges-rel-semeval_mcc: training: 0.728987 validation: 0.670481
09/16 12:12:02 PM: edges-rel-semeval_acc: training: 0.595711 validation: 0.521323
09/16 12:12:02 PM: edges-rel-semeval_precision: training: 0.877379 validation: 0.873400
09/16 12:12:02 PM: edges-rel-semeval_recall: training: 0.625039 validation: 0.534378
09/16 12:12:02 PM: edges-rel-semeval_f1: training: 0.730018 validation: 0.663067
09/16 12:12:02 PM: Global learning rate: 0.0001
09/16 12:12:02 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:12:08 PM: ***** Step 1200 / Validation 12 *****
09/16 12:12:08 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:12:08 PM: Validating...
09/16 12:12:11 PM: Best result seen so far for edges-rel-semeval.
09/16 12:12:11 PM: Best result seen so far for macro.
09/16 12:12:11 PM: Updating LR scheduler:
09/16 12:12:11 PM: 	Best result seen so far for macro_avg: 0.663
09/16 12:12:11 PM: 	# validation passes without improvement: 0
09/16 12:12:11 PM: edges-rel-semeval_loss: training: 0.067086 validation: 0.079694
09/16 12:12:11 PM: macro_avg: validation: 0.663482
09/16 12:12:11 PM: micro_avg: validation: 0.000000
09/16 12:12:11 PM: edges-rel-semeval_mcc: training: 0.749918 validation: 0.666815
09/16 12:12:11 PM: edges-rel-semeval_acc: training: 0.623125 validation: 0.527415
09/16 12:12:11 PM: edges-rel-semeval_precision: training: 0.882997 validation: 0.850340
09/16 12:12:11 PM: edges-rel-semeval_recall: training: 0.655625 validation: 0.543951
09/16 12:12:11 PM: edges-rel-semeval_f1: training: 0.752511 validation: 0.663482
09/16 12:12:11 PM: Global learning rate: 0.0001
09/16 12:12:11 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:12:12 PM: Update 1217: task edges-rel-semeval, batch 17 (1217): mcc: 0.7419, acc: 0.6121, precision: 0.8627, recall: 0.6581, f1: 0.7466, edges-rel-semeval_loss: 0.0672
09/16 12:12:17 PM: ***** Step 1300 / Validation 13 *****
09/16 12:12:18 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:12:18 PM: Validating...
09/16 12:12:21 PM: Best result seen so far for edges-rel-semeval.
09/16 12:12:21 PM: Best result seen so far for macro.
09/16 12:12:21 PM: Updating LR scheduler:
09/16 12:12:21 PM: 	Best result seen so far for macro_avg: 0.671
09/16 12:12:21 PM: 	# validation passes without improvement: 0
09/16 12:12:21 PM: edges-rel-semeval_loss: training: 0.066009 validation: 0.078403
09/16 12:12:21 PM: macro_avg: validation: 0.670940
09/16 12:12:21 PM: micro_avg: validation: 0.000000
09/16 12:12:21 PM: edges-rel-semeval_mcc: training: 0.748885 validation: 0.676298
09/16 12:12:21 PM: edges-rel-semeval_acc: training: 0.618417 validation: 0.536118
09/16 12:12:21 PM: edges-rel-semeval_precision: training: 0.876310 validation: 0.868603
09/16 12:12:21 PM: edges-rel-semeval_recall: training: 0.659098 validation: 0.546562
09/16 12:12:21 PM: edges-rel-semeval_f1: training: 0.752340 validation: 0.670940
09/16 12:12:21 PM: Global learning rate: 0.0001
09/16 12:12:21 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:12:22 PM: Update 1314: task edges-rel-semeval, batch 14 (1314): mcc: 0.7925, acc: 0.6741, precision: 0.9256, recall: 0.6942, f1: 0.7934, edges-rel-semeval_loss: 0.0569
09/16 12:12:27 PM: ***** Step 1400 / Validation 14 *****
09/16 12:12:27 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:12:27 PM: Validating...
09/16 12:12:30 PM: Best result seen so far for edges-rel-semeval.
09/16 12:12:30 PM: Best result seen so far for macro.
09/16 12:12:30 PM: Updating LR scheduler:
09/16 12:12:30 PM: 	Best result seen so far for macro_avg: 0.679
09/16 12:12:30 PM: 	# validation passes without improvement: 0
09/16 12:12:30 PM: edges-rel-semeval_loss: training: 0.060350 validation: 0.078689
09/16 12:12:30 PM: macro_avg: validation: 0.679385
09/16 12:12:30 PM: micro_avg: validation: 0.000000
09/16 12:12:30 PM: edges-rel-semeval_mcc: training: 0.783260 validation: 0.683487
09/16 12:12:30 PM: edges-rel-semeval_acc: training: 0.665000 validation: 0.543951
09/16 12:12:30 PM: edges-rel-semeval_precision: training: 0.896882 validation: 0.868564
09/16 12:12:30 PM: edges-rel-semeval_recall: training: 0.701250 validation: 0.557876
09/16 12:12:30 PM: edges-rel-semeval_f1: training: 0.787092 validation: 0.679385
09/16 12:12:30 PM: Global learning rate: 0.0001
09/16 12:12:30 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:12:32 PM: Update 1437: task edges-rel-semeval, batch 37 (1437): mcc: 0.7835, acc: 0.6579, precision: 0.8904, recall: 0.7069, f1: 0.7881, edges-rel-semeval_loss: 0.0597
09/16 12:12:35 PM: ***** Step 1500 / Validation 15 *****
09/16 12:12:35 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:12:35 PM: Validating...
09/16 12:12:38 PM: Updating LR scheduler:
09/16 12:12:38 PM: 	Best result seen so far for macro_avg: 0.679
09/16 12:12:38 PM: 	# validation passes without improvement: 1
09/16 12:12:38 PM: edges-rel-semeval_loss: training: 0.059846 validation: 0.078649
09/16 12:12:38 PM: macro_avg: validation: 0.664868
09/16 12:12:38 PM: micro_avg: validation: 0.000000
09/16 12:12:38 PM: edges-rel-semeval_mcc: training: 0.778759 validation: 0.672282
09/16 12:12:38 PM: edges-rel-semeval_acc: training: 0.655937 validation: 0.525674
09/16 12:12:38 PM: edges-rel-semeval_precision: training: 0.887001 validation: 0.875000
09/16 12:12:38 PM: edges-rel-semeval_recall: training: 0.701563 validation: 0.536118
09/16 12:12:38 PM: edges-rel-semeval_f1: training: 0.783458 validation: 0.664868
09/16 12:12:38 PM: Global learning rate: 0.0001
09/16 12:12:38 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:12:42 PM: Update 1542: task edges-rel-semeval, batch 42 (1542): mcc: 0.8094, acc: 0.7049, precision: 0.9013, recall: 0.7430, f1: 0.8145, edges-rel-semeval_loss: 0.0528
09/16 12:12:45 PM: ***** Step 1600 / Validation 16 *****
09/16 12:12:45 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:12:45 PM: Validating...
09/16 12:12:48 PM: Best result seen so far for edges-rel-semeval.
09/16 12:12:51 PM: Best result seen so far for macro.
09/16 12:12:51 PM: Updating LR scheduler:
09/16 12:12:51 PM: 	Best result seen so far for macro_avg: 0.693
09/16 12:12:51 PM: 	# validation passes without improvement: 0
09/16 12:12:51 PM: edges-rel-semeval_loss: training: 0.053354 validation: 0.079073
09/16 12:12:51 PM: macro_avg: validation: 0.693028
09/16 12:12:51 PM: micro_avg: validation: 0.000000
09/16 12:12:51 PM: edges-rel-semeval_mcc: training: 0.811945 validation: 0.694094
09/16 12:12:51 PM: edges-rel-semeval_acc: training: 0.703248 validation: 0.562228
09/16 12:12:51 PM: edges-rel-semeval_precision: training: 0.908423 validation: 0.861578
09/16 12:12:51 PM: edges-rel-semeval_recall: training: 0.741407 validation: 0.579634
09/16 12:12:51 PM: edges-rel-semeval_f1: training: 0.816461 validation: 0.693028
09/16 12:12:51 PM: Global learning rate: 0.0001
09/16 12:12:51 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:12:52 PM: Update 1612: task edges-rel-semeval, batch 12 (1612): mcc: 0.8038, acc: 0.7083, precision: 0.8906, recall: 0.7422, f1: 0.8097, edges-rel-semeval_loss: 0.0533
09/16 12:12:57 PM: ***** Step 1700 / Validation 17 *****
09/16 12:12:57 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:12:57 PM: Validating...
09/16 12:13:00 PM: Updating LR scheduler:
09/16 12:13:00 PM: 	Best result seen so far for macro_avg: 0.693
09/16 12:13:00 PM: 	# validation passes without improvement: 1
09/16 12:13:00 PM: edges-rel-semeval_loss: training: 0.056167 validation: 0.075916
09/16 12:13:00 PM: macro_avg: validation: 0.691396
09/16 12:13:00 PM: micro_avg: validation: 0.000000
09/16 12:13:00 PM: edges-rel-semeval_mcc: training: 0.787058 validation: 0.690416
09/16 12:13:00 PM: edges-rel-semeval_acc: training: 0.673125 validation: 0.565709
09/16 12:13:00 PM: edges-rel-semeval_precision: training: 0.883301 validation: 0.847222
09/16 12:13:00 PM: edges-rel-semeval_recall: training: 0.719063 validation: 0.583986
09/16 12:13:00 PM: edges-rel-semeval_f1: training: 0.792765 validation: 0.691396
09/16 12:13:00 PM: Global learning rate: 0.0001
09/16 12:13:00 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:13:02 PM: Update 1721: task edges-rel-semeval, batch 21 (1721): mcc: 0.8123, acc: 0.7061, precision: 0.8978, recall: 0.7512, f1: 0.8180, edges-rel-semeval_loss: 0.0519
09/16 12:13:07 PM: ***** Step 1800 / Validation 18 *****
09/16 12:13:07 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:13:07 PM: Validating...
09/16 12:13:10 PM: Best result seen so far for edges-rel-semeval.
09/16 12:13:10 PM: Best result seen so far for macro.
09/16 12:13:10 PM: Updating LR scheduler:
09/16 12:13:10 PM: 	Best result seen so far for macro_avg: 0.697
09/16 12:13:10 PM: 	# validation passes without improvement: 0
09/16 12:13:10 PM: edges-rel-semeval_loss: training: 0.050651 validation: 0.076701
09/16 12:13:10 PM: macro_avg: validation: 0.696709
09/16 12:13:10 PM: micro_avg: validation: 0.000000
09/16 12:13:10 PM: edges-rel-semeval_mcc: training: 0.820287 validation: 0.692958
09/16 12:13:10 PM: edges-rel-semeval_acc: training: 0.714601 validation: 0.574413
09/16 12:13:10 PM: edges-rel-semeval_precision: training: 0.902731 validation: 0.832930
09/16 12:13:10 PM: edges-rel-semeval_recall: training: 0.760959 validation: 0.598782
09/16 12:13:10 PM: edges-rel-semeval_f1: training: 0.825804 validation: 0.696709
09/16 12:13:10 PM: Global learning rate: 0.0001
09/16 12:13:10 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:13:12 PM: Update 1837: task edges-rel-semeval, batch 37 (1837): mcc: 0.8119, acc: 0.7061, precision: 0.8914, recall: 0.7559, f1: 0.8181, edges-rel-semeval_loss: 0.0523
09/16 12:13:17 PM: ***** Step 1900 / Validation 19 *****
09/16 12:13:17 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:13:17 PM: Validating...
09/16 12:13:20 PM: Best result seen so far for edges-rel-semeval.
09/16 12:13:20 PM: Best result seen so far for macro.
09/16 12:13:20 PM: Updating LR scheduler:
09/16 12:13:20 PM: 	Best result seen so far for macro_avg: 0.697
09/16 12:13:20 PM: 	# validation passes without improvement: 0
09/16 12:13:20 PM: edges-rel-semeval_loss: training: 0.051884 validation: 0.075327
09/16 12:13:20 PM: macro_avg: validation: 0.697229
09/16 12:13:20 PM: micro_avg: validation: 0.000000
09/16 12:13:20 PM: edges-rel-semeval_mcc: training: 0.811586 validation: 0.692678
09/16 12:13:20 PM: edges-rel-semeval_acc: training: 0.703438 validation: 0.577894
09/16 12:13:20 PM: edges-rel-semeval_precision: training: 0.895422 validation: 0.827751
09/16 12:13:20 PM: edges-rel-semeval_recall: training: 0.751875 validation: 0.602263
09/16 12:13:20 PM: edges-rel-semeval_f1: training: 0.817394 validation: 0.697229
09/16 12:13:20 PM: Global learning rate: 0.0001
09/16 12:13:20 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:13:23 PM: Update 1936: task edges-rel-semeval, batch 36 (1936): mcc: 0.8075, acc: 0.6981, precision: 0.8977, recall: 0.7427, f1: 0.8129, edges-rel-semeval_loss: 0.0501
09/16 12:13:27 PM: ***** Step 2000 / Validation 20 *****
09/16 12:13:27 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:13:27 PM: Validating...
09/16 12:13:30 PM: Updating LR scheduler:
09/16 12:13:30 PM: 	Best result seen so far for macro_avg: 0.697
09/16 12:13:30 PM: 	# validation passes without improvement: 1
09/16 12:13:30 PM: edges-rel-semeval_loss: training: 0.047399 validation: 0.076008
09/16 12:13:30 PM: macro_avg: validation: 0.684458
09/16 12:13:30 PM: micro_avg: validation: 0.000000
09/16 12:13:30 PM: edges-rel-semeval_mcc: training: 0.829589 validation: 0.686139
09/16 12:13:30 PM: edges-rel-semeval_acc: training: 0.728161 validation: 0.554395
09/16 12:13:30 PM: edges-rel-semeval_precision: training: 0.909023 validation: 0.858268
09/16 12:13:30 PM: edges-rel-semeval_recall: training: 0.771996 validation: 0.569191
09/16 12:13:30 PM: edges-rel-semeval_f1: training: 0.834925 validation: 0.684458
09/16 12:13:30 PM: Global learning rate: 0.0001
09/16 12:13:30 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:13:33 PM: Update 2052: task edges-rel-semeval, batch 52 (2052): mcc: 0.8427, acc: 0.7488, precision: 0.9127, recall: 0.7921, f1: 0.8481, edges-rel-semeval_loss: 0.0459
09/16 12:13:36 PM: ***** Step 2100 / Validation 21 *****
09/16 12:13:36 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:13:36 PM: Validating...
09/16 12:13:39 PM: Updating LR scheduler:
09/16 12:13:39 PM: 	Best result seen so far for macro_avg: 0.697
09/16 12:13:39 PM: 	# validation passes without improvement: 2
09/16 12:13:39 PM: edges-rel-semeval_loss: training: 0.046902 validation: 0.075983
09/16 12:13:39 PM: macro_avg: validation: 0.690890
09/16 12:13:39 PM: micro_avg: validation: 0.000000
09/16 12:13:39 PM: edges-rel-semeval_mcc: training: 0.837185 validation: 0.688640
09/16 12:13:39 PM: edges-rel-semeval_acc: training: 0.739375 validation: 0.565709
09/16 12:13:39 PM: edges-rel-semeval_precision: training: 0.910708 validation: 0.838509
09/16 12:13:39 PM: edges-rel-semeval_recall: training: 0.784063 validation: 0.587467
09/16 12:13:39 PM: edges-rel-semeval_f1: training: 0.842653 validation: 0.690890
09/16 12:13:39 PM: Global learning rate: 0.0001
09/16 12:13:39 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:13:43 PM: Update 2161: task edges-rel-semeval, batch 61 (2161): mcc: 0.8113, acc: 0.7031, precision: 0.8894, recall: 0.7566, f1: 0.8176, edges-rel-semeval_loss: 0.0501
09/16 12:13:46 PM: ***** Step 2200 / Validation 22 *****
09/16 12:13:46 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:13:46 PM: Validating...
09/16 12:13:49 PM: Best result seen so far for edges-rel-semeval.
09/16 12:13:49 PM: Best result seen so far for macro.
09/16 12:13:49 PM: Updating LR scheduler:
09/16 12:13:49 PM: 	Best result seen so far for macro_avg: 0.704
09/16 12:13:49 PM: 	# validation passes without improvement: 0
09/16 12:13:49 PM: edges-rel-semeval_loss: training: 0.046863 validation: 0.074357
09/16 12:13:49 PM: macro_avg: validation: 0.703573
09/16 12:13:49 PM: micro_avg: validation: 0.000000
09/16 12:13:49 PM: edges-rel-semeval_mcc: training: 0.830176 validation: 0.699245
09/16 12:13:49 PM: edges-rel-semeval_acc: training: 0.728792 validation: 0.587467
09/16 12:13:49 PM: edges-rel-semeval_precision: training: 0.906977 validation: 0.834129
09/16 12:13:49 PM: edges-rel-semeval_recall: training: 0.774834 validation: 0.608355
09/16 12:13:49 PM: edges-rel-semeval_f1: training: 0.835714 validation: 0.703573
09/16 12:13:49 PM: Global learning rate: 0.0001
09/16 12:13:49 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:13:53 PM: Update 2277: task edges-rel-semeval, batch 77 (2277): mcc: 0.8318, acc: 0.7346, precision: 0.9049, recall: 0.7796, f1: 0.8376, edges-rel-semeval_loss: 0.0458
09/16 12:13:54 PM: ***** Step 2300 / Validation 23 *****
09/16 12:13:54 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:13:54 PM: Validating...
09/16 12:13:57 PM: Updating LR scheduler:
09/16 12:13:57 PM: 	Best result seen so far for macro_avg: 0.704
09/16 12:13:57 PM: 	# validation passes without improvement: 1
09/16 12:13:57 PM: edges-rel-semeval_loss: training: 0.046054 validation: 0.075722
09/16 12:13:57 PM: macro_avg: validation: 0.701772
09/16 12:13:57 PM: micro_avg: validation: 0.000000
09/16 12:13:57 PM: edges-rel-semeval_mcc: training: 0.829923 validation: 0.698333
09/16 12:13:57 PM: edges-rel-semeval_acc: training: 0.731563 validation: 0.581375
09/16 12:13:57 PM: edges-rel-semeval_precision: training: 0.899568 validation: 0.838983
09/16 12:13:57 PM: edges-rel-semeval_recall: training: 0.780937 validation: 0.603133
09/16 12:13:57 PM: edges-rel-semeval_f1: training: 0.836066 validation: 0.701772
09/16 12:13:57 PM: Global learning rate: 0.0001
09/16 12:13:57 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:14:03 PM: Update 2379: task edges-rel-semeval, batch 79 (2379): mcc: 0.8496, acc: 0.7543, precision: 0.9117, recall: 0.8055, f1: 0.8553, edges-rel-semeval_loss: 0.0435
09/16 12:14:04 PM: ***** Step 2400 / Validation 24 *****
09/16 12:14:04 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:14:04 PM: Validating...
09/16 12:14:08 PM: Updating LR scheduler:
09/16 12:14:08 PM: 	Best result seen so far for macro_avg: 0.704
09/16 12:14:08 PM: 	# validation passes without improvement: 2
09/16 12:14:08 PM: edges-rel-semeval_loss: training: 0.042171 validation: 0.076109
09/16 12:14:08 PM: macro_avg: validation: 0.694172
09/16 12:14:08 PM: micro_avg: validation: 0.000000
09/16 12:14:08 PM: edges-rel-semeval_mcc: training: 0.856607 validation: 0.693569
09/16 12:14:08 PM: edges-rel-semeval_acc: training: 0.764428 validation: 0.568320
09/16 12:14:08 PM: edges-rel-semeval_precision: training: 0.915338 validation: 0.851899
09/16 12:14:08 PM: edges-rel-semeval_recall: training: 0.814885 validation: 0.585727
09/16 12:14:08 PM: edges-rel-semeval_f1: training: 0.862195 validation: 0.694172
09/16 12:14:08 PM: Global learning rate: 0.0001
09/16 12:14:08 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:14:13 PM: Update 2476: task edges-rel-semeval, batch 76 (2476): mcc: 0.8599, acc: 0.7747, precision: 0.9191, recall: 0.8174, f1: 0.8653, edges-rel-semeval_loss: 0.0408
09/16 12:14:15 PM: ***** Step 2500 / Validation 25 *****
09/16 12:14:17 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:14:17 PM: Validating...
09/16 12:14:20 PM: Best result seen so far for edges-rel-semeval.
09/16 12:14:20 PM: Best result seen so far for macro.
09/16 12:14:20 PM: Updating LR scheduler:
09/16 12:14:20 PM: 	Best result seen so far for macro_avg: 0.708
09/16 12:14:20 PM: 	# validation passes without improvement: 0
09/16 12:14:20 PM: edges-rel-semeval_loss: training: 0.041900 validation: 0.075445
09/16 12:14:20 PM: macro_avg: validation: 0.707552
09/16 12:14:20 PM: micro_avg: validation: 0.000000
09/16 12:14:20 PM: edges-rel-semeval_mcc: training: 0.854616 validation: 0.704642
09/16 12:14:20 PM: edges-rel-semeval_acc: training: 0.767500 validation: 0.589208
09/16 12:14:20 PM: edges-rel-semeval_precision: training: 0.919872 validation: 0.847087
09/16 12:14:20 PM: edges-rel-semeval_recall: training: 0.807187 validation: 0.607485
09/16 12:14:20 PM: edges-rel-semeval_f1: training: 0.859854 validation: 0.707552
09/16 12:14:20 PM: Global learning rate: 0.0001
09/16 12:14:20 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:14:23 PM: Update 2552: task edges-rel-semeval, batch 52 (2552): mcc: 0.8421, acc: 0.7464, precision: 0.9035, recall: 0.7993, f1: 0.8482, edges-rel-semeval_loss: 0.0449
09/16 12:14:27 PM: ***** Step 2600 / Validation 26 *****
09/16 12:14:27 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:14:27 PM: Validating...
09/16 12:14:30 PM: Best result seen so far for edges-rel-semeval.
09/16 12:14:30 PM: Best result seen so far for macro.
09/16 12:14:30 PM: Updating LR scheduler:
09/16 12:14:30 PM: 	Best result seen so far for macro_avg: 0.712
09/16 12:14:30 PM: 	# validation passes without improvement: 0
09/16 12:14:30 PM: edges-rel-semeval_loss: training: 0.043038 validation: 0.074968
09/16 12:14:30 PM: macro_avg: validation: 0.712438
09/16 12:14:30 PM: micro_avg: validation: 0.000000
09/16 12:14:30 PM: edges-rel-semeval_mcc: training: 0.848099 validation: 0.706862
09/16 12:14:30 PM: edges-rel-semeval_acc: training: 0.754336 validation: 0.600522
09/16 12:14:30 PM: edges-rel-semeval_precision: training: 0.909480 validation: 0.831591
09/16 12:14:30 PM: edges-rel-semeval_recall: training: 0.804793 validation: 0.623151
09/16 12:14:30 PM: edges-rel-semeval_f1: training: 0.853940 validation: 0.712438
09/16 12:14:30 PM: Global learning rate: 0.0001
09/16 12:14:30 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:14:33 PM: Update 2649: task edges-rel-semeval, batch 49 (2649): mcc: 0.8718, acc: 0.7876, precision: 0.9244, recall: 0.8342, f1: 0.8770, edges-rel-semeval_loss: 0.0378
09/16 12:14:36 PM: ***** Step 2700 / Validation 27 *****
09/16 12:14:36 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:14:36 PM: Validating...
09/16 12:14:39 PM: Updating LR scheduler:
09/16 12:14:39 PM: 	Best result seen so far for macro_avg: 0.712
09/16 12:14:39 PM: 	# validation passes without improvement: 1
09/16 12:14:39 PM: edges-rel-semeval_loss: training: 0.038978 validation: 0.075193
09/16 12:14:39 PM: macro_avg: validation: 0.708354
09/16 12:14:39 PM: micro_avg: validation: 0.000000
09/16 12:14:39 PM: edges-rel-semeval_mcc: training: 0.868807 validation: 0.703365
09/16 12:14:39 PM: edges-rel-semeval_acc: training: 0.786875 validation: 0.587467
09/16 12:14:39 PM: edges-rel-semeval_precision: training: 0.921691 validation: 0.832941
09/16 12:14:39 PM: edges-rel-semeval_recall: training: 0.831250 validation: 0.616188
09/16 12:14:39 PM: edges-rel-semeval_f1: training: 0.874137 validation: 0.708354
09/16 12:14:39 PM: Global learning rate: 0.0001
09/16 12:14:39 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:14:43 PM: Update 2761: task edges-rel-semeval, batch 61 (2761): mcc: 0.8555, acc: 0.7618, precision: 0.9085, recall: 0.8192, f1: 0.8615, edges-rel-semeval_loss: 0.0404
09/16 12:14:46 PM: ***** Step 2800 / Validation 28 *****
09/16 12:14:46 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:14:46 PM: Validating...
09/16 12:14:49 PM: Updating LR scheduler:
09/16 12:14:49 PM: 	Best result seen so far for macro_avg: 0.712
09/16 12:14:49 PM: 	# validation passes without improvement: 2
09/16 12:14:49 PM: edges-rel-semeval_loss: training: 0.040720 validation: 0.076240
09/16 12:14:49 PM: macro_avg: validation: 0.707293
09/16 12:14:49 PM: micro_avg: validation: 0.000000
09/16 12:14:49 PM: edges-rel-semeval_mcc: training: 0.850272 validation: 0.702010
09/16 12:14:49 PM: edges-rel-semeval_acc: training: 0.754021 validation: 0.588338
09/16 12:14:49 PM: edges-rel-semeval_precision: training: 0.905163 validation: 0.830012
09/16 12:14:49 PM: edges-rel-semeval_recall: training: 0.812677 validation: 0.616188
09/16 12:14:49 PM: edges-rel-semeval_f1: training: 0.856431 validation: 0.707293
09/16 12:14:49 PM: Global learning rate: 0.0001
09/16 12:14:49 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:14:53 PM: Update 2864: task edges-rel-semeval, batch 64 (2864): mcc: 0.8863, acc: 0.8130, precision: 0.9323, recall: 0.8535, f1: 0.8912, edges-rel-semeval_loss: 0.0349
09/16 12:14:55 PM: ***** Step 2900 / Validation 29 *****
09/16 12:14:55 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:14:55 PM: Validating...
09/16 12:14:58 PM: Updating LR scheduler:
09/16 12:15:00 PM: 	Best result seen so far for macro_avg: 0.712
09/16 12:15:00 PM: 	# validation passes without improvement: 3
09/16 12:15:00 PM: edges-rel-semeval_loss: training: 0.036313 validation: 0.076834
09/16 12:15:00 PM: macro_avg: validation: 0.704453
09/16 12:15:00 PM: micro_avg: validation: 0.000000
09/16 12:15:00 PM: edges-rel-semeval_mcc: training: 0.879422 validation: 0.701095
09/16 12:15:00 PM: edges-rel-semeval_acc: training: 0.800937 validation: 0.584856
09/16 12:15:00 PM: edges-rel-semeval_precision: training: 0.924098 validation: 0.841596
09/16 12:15:00 PM: edges-rel-semeval_recall: training: 0.848437 validation: 0.605744
09/16 12:15:00 PM: edges-rel-semeval_f1: training: 0.884653 validation: 0.704453
09/16 12:15:00 PM: Global learning rate: 0.0001
09/16 12:15:00 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:15:03 PM: Update 2962: task edges-rel-semeval, batch 62 (2962): mcc: 0.8620, acc: 0.7752, precision: 0.9099, recall: 0.8296, f1: 0.8679, edges-rel-semeval_loss: 0.0383
09/16 12:15:06 PM: ***** Step 3000 / Validation 30 *****
09/16 12:15:06 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:15:06 PM: Validating...
09/16 12:15:09 PM: Updating LR scheduler:
09/16 12:15:10 PM: 	Best result seen so far for macro_avg: 0.712
09/16 12:15:10 PM: 	# validation passes without improvement: 0
09/16 12:15:10 PM: edges-rel-semeval_loss: training: 0.038789 validation: 0.076536
09/16 12:15:10 PM: macro_avg: validation: 0.704877
09/16 12:15:10 PM: micro_avg: validation: 0.000000
09/16 12:15:10 PM: edges-rel-semeval_mcc: training: 0.860578 validation: 0.700466
09/16 12:15:10 PM: edges-rel-semeval_acc: training: 0.775625 validation: 0.584856
09/16 12:15:10 PM: edges-rel-semeval_precision: training: 0.910499 validation: 0.834524
09/16 12:15:10 PM: edges-rel-semeval_recall: training: 0.826563 validation: 0.610096
09/16 12:15:10 PM: edges-rel-semeval_f1: training: 0.866503 validation: 0.704877
09/16 12:15:10 PM: Global learning rate: 5e-05
09/16 12:15:10 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:15:13 PM: Update 3033: task edges-rel-semeval, batch 33 (3033): mcc: 0.8758, acc: 0.7955, precision: 0.9278, recall: 0.8384, f1: 0.8808, edges-rel-semeval_loss: 0.0351
09/16 12:15:17 PM: ***** Step 3100 / Validation 31 *****
09/16 12:15:17 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:15:17 PM: Validating...
09/16 12:15:20 PM: Updating LR scheduler:
09/16 12:15:20 PM: 	Best result seen so far for macro_avg: 0.712
09/16 12:15:20 PM: 	# validation passes without improvement: 1
09/16 12:15:20 PM: edges-rel-semeval_loss: training: 0.034264 validation: 0.076688
09/16 12:15:20 PM: macro_avg: validation: 0.703274
09/16 12:15:20 PM: micro_avg: validation: 0.000000
09/16 12:15:20 PM: edges-rel-semeval_mcc: training: 0.882637 validation: 0.699091
09/16 12:15:20 PM: edges-rel-semeval_acc: training: 0.804163 validation: 0.582245
09/16 12:15:20 PM: edges-rel-semeval_precision: training: 0.929879 validation: 0.834928
09/16 12:15:20 PM: edges-rel-semeval_recall: training: 0.848944 validation: 0.607485
09/16 12:15:20 PM: edges-rel-semeval_f1: training: 0.887570 validation: 0.703274
09/16 12:15:20 PM: Global learning rate: 5e-05
09/16 12:15:20 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:15:23 PM: Update 3152: task edges-rel-semeval, batch 52 (3152): mcc: 0.8715, acc: 0.7837, precision: 0.9212, recall: 0.8365, f1: 0.8769, edges-rel-semeval_loss: 0.0360
09/16 12:15:26 PM: ***** Step 3200 / Validation 32 *****
09/16 12:15:26 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:15:27 PM: Validating...
09/16 12:15:30 PM: Best result seen so far for edges-rel-semeval.
09/16 12:15:30 PM: Best result seen so far for macro.
09/16 12:15:30 PM: Updating LR scheduler:
09/16 12:15:30 PM: 	Best result seen so far for macro_avg: 0.718
09/16 12:15:30 PM: 	# validation passes without improvement: 0
09/16 12:15:30 PM: edges-rel-semeval_loss: training: 0.034824 validation: 0.076603
09/16 12:15:30 PM: macro_avg: validation: 0.717718
09/16 12:15:30 PM: micro_avg: validation: 0.000000
09/16 12:15:30 PM: edges-rel-semeval_mcc: training: 0.878528 validation: 0.713368
09/16 12:15:30 PM: edges-rel-semeval_acc: training: 0.797813 validation: 0.601393
09/16 12:15:30 PM: edges-rel-semeval_precision: training: 0.926027 validation: 0.844523
09/16 12:15:30 PM: edges-rel-semeval_recall: training: 0.845000 validation: 0.624021
09/16 12:15:30 PM: edges-rel-semeval_f1: training: 0.883660 validation: 0.717718
09/16 12:15:30 PM: Global learning rate: 5e-05
09/16 12:15:30 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:15:33 PM: Update 3242: task edges-rel-semeval, batch 42 (3242): mcc: 0.8892, acc: 0.8076, precision: 0.9381, recall: 0.8532, f1: 0.8937, edges-rel-semeval_loss: 0.0328
09/16 12:15:37 PM: ***** Step 3300 / Validation 33 *****
09/16 12:15:38 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:15:38 PM: Validating...
09/16 12:15:41 PM: Updating LR scheduler:
09/16 12:15:41 PM: 	Best result seen so far for macro_avg: 0.718
09/16 12:15:41 PM: 	# validation passes without improvement: 1
09/16 12:15:41 PM: edges-rel-semeval_loss: training: 0.032281 validation: 0.075811
09/16 12:15:41 PM: macro_avg: validation: 0.709904
09/16 12:15:41 PM: micro_avg: validation: 0.000000
09/16 12:15:41 PM: edges-rel-semeval_mcc: training: 0.893262 validation: 0.705799
09/16 12:15:41 PM: edges-rel-semeval_acc: training: 0.818669 validation: 0.594430
09/16 12:15:41 PM: edges-rel-semeval_precision: training: 0.934219 validation: 0.840476
09/16 12:15:41 PM: edges-rel-semeval_recall: training: 0.864396 validation: 0.614447
09/16 12:15:41 PM: edges-rel-semeval_f1: training: 0.897952 validation: 0.709904
09/16 12:15:41 PM: Global learning rate: 5e-05
09/16 12:15:41 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:15:43 PM: Update 3342: task edges-rel-semeval, batch 42 (3342): mcc: 0.9029, acc: 0.8385, precision: 0.9466, recall: 0.8705, f1: 0.9070, edges-rel-semeval_loss: 0.0319
09/16 12:15:47 PM: ***** Step 3400 / Validation 34 *****
09/16 12:15:49 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:15:49 PM: Validating...
09/16 12:15:52 PM: Updating LR scheduler:
09/16 12:15:52 PM: 	Best result seen so far for macro_avg: 0.718
09/16 12:15:53 PM: 	# validation passes without improvement: 2
09/16 12:15:53 PM: edges-rel-semeval_loss: training: 0.033198 validation: 0.075627
09/16 12:15:53 PM: macro_avg: validation: 0.715257
09/16 12:15:53 PM: micro_avg: validation: 0.000000
09/16 12:15:53 PM: edges-rel-semeval_mcc: training: 0.890734 validation: 0.706679
09/16 12:15:53 PM: edges-rel-semeval_acc: training: 0.817813 validation: 0.604874
09/16 12:15:53 PM: edges-rel-semeval_precision: training: 0.932950 validation: 0.809681
09/16 12:15:53 PM: edges-rel-semeval_recall: training: 0.860937 validation: 0.640557
09/16 12:15:53 PM: edges-rel-semeval_f1: training: 0.895498 validation: 0.715257
09/16 12:15:53 PM: Global learning rate: 5e-05
09/16 12:15:53 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:15:53 PM: Update 3404: task edges-rel-semeval, batch 4 (3404): mcc: 0.8419, acc: 0.7656, precision: 0.8889, recall: 0.8125, f1: 0.8490, edges-rel-semeval_loss: 0.0390
09/16 12:16:00 PM: ***** Step 3500 / Validation 35 *****
09/16 12:16:00 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:16:00 PM: Validating...
09/16 12:16:03 PM: Updating LR scheduler:
09/16 12:16:03 PM: 	Best result seen so far for macro_avg: 0.718
09/16 12:16:03 PM: 	# validation passes without improvement: 3
09/16 12:16:03 PM: edges-rel-semeval_loss: training: 0.032835 validation: 0.076476
09/16 12:16:03 PM: macro_avg: validation: 0.709325
09/16 12:16:03 PM: micro_avg: validation: 0.000000
09/16 12:16:03 PM: edges-rel-semeval_mcc: training: 0.887892 validation: 0.703131
09/16 12:16:03 PM: edges-rel-semeval_acc: training: 0.809208 validation: 0.597041
09/16 12:16:03 PM: edges-rel-semeval_precision: training: 0.926730 validation: 0.824683
09/16 12:16:03 PM: edges-rel-semeval_recall: training: 0.861558 validation: 0.622280
09/16 12:16:03 PM: edges-rel-semeval_f1: training: 0.892956 validation: 0.709325
09/16 12:16:03 PM: Global learning rate: 5e-05
09/16 12:16:03 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:16:03 PM: Update 3508: task edges-rel-semeval, batch 8 (3508): mcc: 0.8753, acc: 0.7969, precision: 0.9087, recall: 0.8555, f1: 0.8813, edges-rel-semeval_loss: 0.0335
09/16 12:16:09 PM: ***** Step 3600 / Validation 36 *****
09/16 12:16:09 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:16:09 PM: Validating...
09/16 12:16:13 PM: Updating LR scheduler:
09/16 12:16:13 PM: 	Best result seen so far for macro_avg: 0.718
09/16 12:16:13 PM: 	# validation passes without improvement: 0
09/16 12:16:13 PM: edges-rel-semeval_loss: training: 0.032509 validation: 0.076316
09/16 12:16:13 PM: macro_avg: validation: 0.711626
09/16 12:16:13 PM: micro_avg: validation: 0.000000
09/16 12:16:13 PM: edges-rel-semeval_mcc: training: 0.889930 validation: 0.707787
09/16 12:16:13 PM: edges-rel-semeval_acc: training: 0.815937 validation: 0.590949
09/16 12:16:13 PM: edges-rel-semeval_precision: training: 0.931373 validation: 0.843675
09/16 12:16:13 PM: edges-rel-semeval_recall: training: 0.860937 validation: 0.615318
09/16 12:16:13 PM: edges-rel-semeval_f1: training: 0.894771 validation: 0.711626
09/16 12:16:13 PM: Global learning rate: 2.5e-05
09/16 12:16:13 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:16:13 PM: Update 3609: task edges-rel-semeval, batch 9 (3609): mcc: 0.9033, acc: 0.8368, precision: 0.9245, recall: 0.8924, f1: 0.9081, edges-rel-semeval_loss: 0.0307
09/16 12:16:23 PM: ***** Step 3700 / Validation 37 *****
09/16 12:16:23 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:16:23 PM: Validating...
09/16 12:16:24 PM: Evaluate: task edges-rel-semeval, batch 7 (36): mcc: 0.7620, acc: 0.6518, precision: 0.8743, recall: 0.6830, f1: 0.7669, edges-rel-semeval_loss: 0.0639
09/16 12:16:27 PM: Best result seen so far for edges-rel-semeval.
09/16 12:16:28 PM: Best result seen so far for macro.
09/16 12:16:28 PM: Updating LR scheduler:
09/16 12:16:28 PM: 	Best result seen so far for macro_avg: 0.720
09/16 12:16:28 PM: 	# validation passes without improvement: 0
09/16 12:16:28 PM: edges-rel-semeval_loss: training: 0.030895 validation: 0.076018
09/16 12:16:28 PM: macro_avg: validation: 0.720398
09/16 12:16:28 PM: micro_avg: validation: 0.000000
09/16 12:16:28 PM: edges-rel-semeval_mcc: training: 0.900009 validation: 0.715294
09/16 12:16:28 PM: edges-rel-semeval_acc: training: 0.829391 validation: 0.603133
09/16 12:16:28 PM: edges-rel-semeval_precision: training: 0.937712 validation: 0.840883
09/16 12:16:28 PM: edges-rel-semeval_recall: training: 0.873541 validation: 0.630113
09/16 12:16:28 PM: edges-rel-semeval_f1: training: 0.904490 validation: 0.720398
09/16 12:16:28 PM: Global learning rate: 2.5e-05
09/16 12:16:28 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:16:34 PM: Update 3764: task edges-rel-semeval, batch 64 (3764): mcc: 0.9055, acc: 0.8413, precision: 0.9396, recall: 0.8818, f1: 0.9098, edges-rel-semeval_loss: 0.0300
09/16 12:16:37 PM: ***** Step 3800 / Validation 38 *****
09/16 12:16:37 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:16:37 PM: Validating...
09/16 12:16:41 PM: Best result seen so far for edges-rel-semeval.
09/16 12:16:41 PM: Best result seen so far for macro.
09/16 12:16:41 PM: Updating LR scheduler:
09/16 12:16:41 PM: 	Best result seen so far for macro_avg: 0.726
09/16 12:16:41 PM: 	# validation passes without improvement: 0
09/16 12:16:41 PM: edges-rel-semeval_loss: training: 0.030289 validation: 0.075656
09/16 12:16:41 PM: macro_avg: validation: 0.725830
09/16 12:16:41 PM: micro_avg: validation: 0.000000
09/16 12:16:41 PM: edges-rel-semeval_mcc: training: 0.905106 validation: 0.720534
09/16 12:16:41 PM: edges-rel-semeval_acc: training: 0.841250 validation: 0.613577
09/16 12:16:41 PM: edges-rel-semeval_precision: training: 0.938206 validation: 0.843318
09/16 12:16:41 PM: edges-rel-semeval_recall: training: 0.882500 validation: 0.637076
09/16 12:16:41 PM: edges-rel-semeval_f1: training: 0.909501 validation: 0.725830
09/16 12:16:41 PM: Global learning rate: 2.5e-05
09/16 12:16:41 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:16:44 PM: Update 3825: task edges-rel-semeval, batch 25 (3825): mcc: 0.8982, acc: 0.8337, precision: 0.9380, recall: 0.8700, f1: 0.9027, edges-rel-semeval_loss: 0.0300
09/16 12:16:53 PM: ***** Step 3900 / Validation 39 *****
09/16 12:16:53 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:16:53 PM: Validating...
09/16 12:16:54 PM: Evaluate: task edges-rel-semeval, batch 13 (36): mcc: 0.7351, acc: 0.6346, precision: 0.8505, recall: 0.6562, f1: 0.7408, edges-rel-semeval_loss: 0.0712
09/16 12:16:57 PM: Updating LR scheduler:
09/16 12:16:57 PM: 	Best result seen so far for macro_avg: 0.726
09/16 12:16:57 PM: 	# validation passes without improvement: 1
09/16 12:16:57 PM: edges-rel-semeval_loss: training: 0.029791 validation: 0.075764
09/16 12:16:57 PM: macro_avg: validation: 0.716136
09/16 12:16:57 PM: micro_avg: validation: 0.000000
09/16 12:16:57 PM: edges-rel-semeval_mcc: training: 0.902530 validation: 0.710927
09/16 12:16:57 PM: edges-rel-semeval_acc: training: 0.835699 validation: 0.599652
09/16 12:16:57 PM: edges-rel-semeval_precision: training: 0.938301 validation: 0.837020
09/16 12:16:57 PM: edges-rel-semeval_recall: training: 0.877641 validation: 0.625762
09/16 12:16:57 PM: edges-rel-semeval_f1: training: 0.906958 validation: 0.716136
09/16 12:16:57 PM: Global learning rate: 2.5e-05
09/16 12:16:57 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:17:04 PM: Update 3975: task edges-rel-semeval, batch 75 (3975): mcc: 0.8966, acc: 0.8271, precision: 0.9370, recall: 0.8679, f1: 0.9011, edges-rel-semeval_loss: 0.0307
09/16 12:17:06 PM: ***** Step 4000 / Validation 40 *****
09/16 12:17:06 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:17:06 PM: Validating...
09/16 12:17:10 PM: Updating LR scheduler:
09/16 12:17:10 PM: 	Best result seen so far for macro_avg: 0.726
09/16 12:17:10 PM: 	# validation passes without improvement: 2
09/16 12:17:10 PM: edges-rel-semeval_loss: training: 0.030231 validation: 0.076440
09/16 12:17:10 PM: macro_avg: validation: 0.716448
09/16 12:17:10 PM: micro_avg: validation: 0.000000
09/16 12:17:10 PM: edges-rel-semeval_mcc: training: 0.897993 validation: 0.713318
09/16 12:17:10 PM: edges-rel-semeval_acc: training: 0.828750 validation: 0.598782
09/16 12:17:10 PM: edges-rel-semeval_precision: training: 0.936199 validation: 0.852341
09/16 12:17:10 PM: edges-rel-semeval_recall: training: 0.871250 validation: 0.617929
09/16 12:17:10 PM: edges-rel-semeval_f1: training: 0.902557 validation: 0.716448
09/16 12:17:10 PM: Global learning rate: 2.5e-05
09/16 12:17:10 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:17:14 PM: Update 4039: task edges-rel-semeval, batch 39 (4039): mcc: 0.9059, acc: 0.8389, precision: 0.9425, recall: 0.8798, f1: 0.9101, edges-rel-semeval_loss: 0.0299
09/16 12:17:21 PM: ***** Step 4100 / Validation 41 *****
09/16 12:17:21 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:17:21 PM: Validating...
09/16 12:17:24 PM: Evaluate: task edges-rel-semeval, batch 30 (36): mcc: 0.7340, acc: 0.6271, precision: 0.8664, recall: 0.6417, f1: 0.7373, edges-rel-semeval_loss: 0.0725
09/16 12:17:25 PM: Updating LR scheduler:
09/16 12:17:25 PM: 	Best result seen so far for macro_avg: 0.726
09/16 12:17:25 PM: 	# validation passes without improvement: 3
09/16 12:17:25 PM: edges-rel-semeval_loss: training: 0.029241 validation: 0.077084
09/16 12:17:25 PM: macro_avg: validation: 0.715299
09/16 12:17:25 PM: micro_avg: validation: 0.000000
09/16 12:17:25 PM: edges-rel-semeval_mcc: training: 0.904429 validation: 0.712781
09/16 12:17:25 PM: edges-rel-semeval_acc: training: 0.836329 validation: 0.598782
09/16 12:17:25 PM: edges-rel-semeval_precision: training: 0.940007 validation: 0.855758
09/16 12:17:25 PM: edges-rel-semeval_recall: training: 0.879533 validation: 0.614447
09/16 12:17:25 PM: edges-rel-semeval_f1: training: 0.908765 validation: 0.715299
09/16 12:17:25 PM: Global learning rate: 2.5e-05
09/16 12:17:25 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:17:34 PM: Update 4196: task edges-rel-semeval, batch 96 (4196): mcc: 0.9146, acc: 0.8558, precision: 0.9512, recall: 0.8877, f1: 0.9183, edges-rel-semeval_loss: 0.0279
09/16 12:17:34 PM: ***** Step 4200 / Validation 42 *****
09/16 12:17:34 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:17:34 PM: Validating...
09/16 12:17:38 PM: Updating LR scheduler:
09/16 12:17:40 PM: 	Best result seen so far for macro_avg: 0.726
09/16 12:17:40 PM: 	# validation passes without improvement: 0
09/16 12:17:40 PM: edges-rel-semeval_loss: training: 0.027858 validation: 0.076313
09/16 12:17:40 PM: macro_avg: validation: 0.719802
09/16 12:17:40 PM: micro_avg: validation: 0.000000
09/16 12:17:40 PM: edges-rel-semeval_mcc: training: 0.914787 validation: 0.713938
09/16 12:17:40 PM: edges-rel-semeval_acc: training: 0.856563 validation: 0.607485
09/16 12:17:40 PM: edges-rel-semeval_precision: training: 0.951138 validation: 0.834673
09/16 12:17:40 PM: edges-rel-semeval_recall: training: 0.888125 validation: 0.632724
09/16 12:17:40 PM: edges-rel-semeval_f1: training: 0.918552 validation: 0.719802
09/16 12:17:40 PM: Global learning rate: 1.25e-05
09/16 12:17:40 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:17:44 PM: Update 4234: task edges-rel-semeval, batch 34 (4234): mcc: 0.9044, acc: 0.8355, precision: 0.9340, recall: 0.8851, f1: 0.9089, edges-rel-semeval_loss: 0.0296
09/16 12:17:53 PM: ***** Step 4300 / Validation 43 *****
09/16 12:17:53 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:17:53 PM: Validating...
09/16 12:17:56 PM: Evaluate: task edges-rel-semeval, batch 35 (36): mcc: 0.7156, acc: 0.6045, precision: 0.8493, recall: 0.6241, f1: 0.7195, edges-rel-semeval_loss: 0.0749
09/16 12:17:59 PM: Updating LR scheduler:
09/16 12:17:59 PM: 	Best result seen so far for macro_avg: 0.726
09/16 12:17:59 PM: 	# validation passes without improvement: 1
09/16 12:17:59 PM: edges-rel-semeval_loss: training: 0.030810 validation: 0.076754
09/16 12:17:59 PM: macro_avg: validation: 0.715578
09/16 12:17:59 PM: micro_avg: validation: 0.000000
09/16 12:17:59 PM: edges-rel-semeval_mcc: training: 0.899174 validation: 0.711735
09/16 12:17:59 PM: edges-rel-semeval_acc: training: 0.828438 validation: 0.598782
09/16 12:17:59 PM: edges-rel-semeval_precision: training: 0.932248 validation: 0.846611
09/16 12:17:59 PM: edges-rel-semeval_recall: training: 0.877187 validation: 0.619669
09/16 12:17:59 PM: edges-rel-semeval_f1: training: 0.903880 validation: 0.715578
09/16 12:17:59 PM: Global learning rate: 1.25e-05
09/16 12:17:59 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:18:09 PM: Update 4359: task edges-rel-semeval, batch 59 (4359): mcc: 0.9133, acc: 0.8510, precision: 0.9546, recall: 0.8822, f1: 0.9170, edges-rel-semeval_loss: 0.0274
09/16 12:18:13 PM: ***** Step 4400 / Validation 44 *****
09/16 12:18:13 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:18:13 PM: Validating...
09/16 12:18:17 PM: Updating LR scheduler:
09/16 12:18:19 PM: 	Best result seen so far for macro_avg: 0.726
09/16 12:18:19 PM: 	# validation passes without improvement: 2
09/16 12:18:19 PM: edges-rel-semeval_loss: training: 0.027576 validation: 0.076865
09/16 12:18:19 PM: macro_avg: validation: 0.712632
09/16 12:18:19 PM: micro_avg: validation: 0.000000
09/16 12:18:19 PM: edges-rel-semeval_mcc: training: 0.914017 validation: 0.708855
09/16 12:18:19 PM: edges-rel-semeval_acc: training: 0.853043 validation: 0.595300
09/16 12:18:19 PM: edges-rel-semeval_precision: training: 0.950051 validation: 0.844869
09/16 12:18:19 PM: edges-rel-semeval_recall: training: 0.887733 validation: 0.616188
09/16 12:18:19 PM: edges-rel-semeval_f1: training: 0.917835 validation: 0.712632
09/16 12:18:19 PM: Global learning rate: 1.25e-05
09/16 12:18:19 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:18:19 PM: Update 4401: task edges-rel-semeval, batch 1 (4401): mcc: 0.9364, acc: 0.8750, precision: 0.9118, recall: 0.9688, f1: 0.9394, edges-rel-semeval_loss: 0.0218
09/16 12:18:29 PM: ***** Step 4500 / Validation 45 *****
09/16 12:18:29 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:18:29 PM: Validating...
09/16 12:18:29 PM: Evaluate: task edges-rel-semeval, batch 6 (36): mcc: 0.7768, acc: 0.6719, precision: 0.8874, recall: 0.6979, f1: 0.7813, edges-rel-semeval_loss: 0.0633
09/16 12:18:32 PM: Updating LR scheduler:
09/16 12:18:32 PM: 	Best result seen so far for macro_avg: 0.726
09/16 12:18:32 PM: 	# validation passes without improvement: 3
09/16 12:18:32 PM: edges-rel-semeval_loss: training: 0.029220 validation: 0.076440
09/16 12:18:32 PM: macro_avg: validation: 0.721946
09/16 12:18:32 PM: micro_avg: validation: 0.000000
09/16 12:18:32 PM: edges-rel-semeval_mcc: training: 0.905569 validation: 0.716639
09/16 12:18:32 PM: edges-rel-semeval_acc: training: 0.838437 validation: 0.608355
09/16 12:18:32 PM: edges-rel-semeval_precision: training: 0.942398 validation: 0.840462
09/16 12:18:32 PM: edges-rel-semeval_recall: training: 0.879375 validation: 0.632724
09/16 12:18:32 PM: edges-rel-semeval_f1: training: 0.909796 validation: 0.721946
09/16 12:18:32 PM: Global learning rate: 1.25e-05
09/16 12:18:32 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:18:39 PM: Update 4550: task edges-rel-semeval, batch 50 (4550): mcc: 0.9072, acc: 0.8415, precision: 0.9453, recall: 0.8797, f1: 0.9113, edges-rel-semeval_loss: 0.0278
09/16 12:18:44 PM: ***** Step 4600 / Validation 46 *****
09/16 12:18:44 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:18:44 PM: Validating...
09/16 12:18:48 PM: Updating LR scheduler:
09/16 12:18:48 PM: 	Best result seen so far for macro_avg: 0.726
09/16 12:18:48 PM: 	# validation passes without improvement: 0
09/16 12:18:48 PM: edges-rel-semeval_loss: training: 0.027988 validation: 0.076615
09/16 12:18:48 PM: macro_avg: validation: 0.718204
09/16 12:18:48 PM: micro_avg: validation: 0.000000
09/16 12:18:48 PM: edges-rel-semeval_mcc: training: 0.908287 validation: 0.713345
09/16 12:18:48 PM: edges-rel-semeval_acc: training: 0.842636 validation: 0.602263
09/16 12:18:48 PM: edges-rel-semeval_precision: training: 0.945535 validation: 0.841121
09/16 12:18:48 PM: edges-rel-semeval_recall: training: 0.881425 validation: 0.626632
09/16 12:18:48 PM: edges-rel-semeval_f1: training: 0.912355 validation: 0.718204
09/16 12:18:48 PM: Global learning rate: 6.25e-06
09/16 12:18:48 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:18:50 PM: Update 4618: task edges-rel-semeval, batch 18 (4618): mcc: 0.9097, acc: 0.8455, precision: 0.9478, recall: 0.8819, f1: 0.9137, edges-rel-semeval_loss: 0.0287
09/16 12:18:56 PM: ***** Step 4700 / Validation 47 *****
09/16 12:19:00 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:19:00 PM: Validating...
09/16 12:19:00 PM: Evaluate: task edges-rel-semeval, batch 1 (36): mcc: 0.7673, acc: 0.6562, precision: 0.8800, recall: 0.6875, f1: 0.7719, edges-rel-semeval_loss: 0.0666
09/16 12:19:03 PM: Updating LR scheduler:
09/16 12:19:04 PM: 	Best result seen so far for macro_avg: 0.726
09/16 12:19:04 PM: 	# validation passes without improvement: 1
09/16 12:19:04 PM: edges-rel-semeval_loss: training: 0.028604 validation: 0.076426
09/16 12:19:04 PM: macro_avg: validation: 0.720919
09/16 12:19:04 PM: micro_avg: validation: 0.000000
09/16 12:19:04 PM: edges-rel-semeval_mcc: training: 0.907501 validation: 0.716373
09/16 12:19:04 PM: edges-rel-semeval_acc: training: 0.842500 validation: 0.605744
09/16 12:19:04 PM: edges-rel-semeval_precision: training: 0.940239 validation: 0.845433
09/16 12:19:04 PM: edges-rel-semeval_recall: training: 0.885000 validation: 0.628372
09/16 12:19:04 PM: edges-rel-semeval_f1: training: 0.911784 validation: 0.720919
09/16 12:19:04 PM: Global learning rate: 6.25e-06
09/16 12:19:04 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:19:10 PM: Update 4731: task edges-rel-semeval, batch 31 (4731): mcc: 0.9109, acc: 0.8474, precision: 0.9418, recall: 0.8899, f1: 0.9151, edges-rel-semeval_loss: 0.0280
09/16 12:19:19 PM: ***** Step 4800 / Validation 48 *****
09/16 12:19:19 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:19:19 PM: Validating...
09/16 12:19:21 PM: Evaluate: task edges-rel-semeval, batch 20 (36): mcc: 0.7427, acc: 0.6438, precision: 0.8569, recall: 0.6641, f1: 0.7482, edges-rel-semeval_loss: 0.0701
09/16 12:19:24 PM: Updating LR scheduler:
09/16 12:19:25 PM: 	Best result seen so far for macro_avg: 0.726
09/16 12:19:25 PM: 	# validation passes without improvement: 2
09/16 12:19:25 PM: Ran out of early stopping patience. Stopping training.
09/16 12:19:25 PM: edges-rel-semeval_loss: training: 0.028077 validation: 0.076197
09/16 12:19:25 PM: macro_avg: validation: 0.721670
09/16 12:19:25 PM: micro_avg: validation: 0.000000
09/16 12:19:25 PM: edges-rel-semeval_mcc: training: 0.908457 validation: 0.716493
09/16 12:19:25 PM: edges-rel-semeval_acc: training: 0.843582 validation: 0.606614
09/16 12:19:25 PM: edges-rel-semeval_precision: training: 0.942540 validation: 0.841251
09/16 12:19:25 PM: edges-rel-semeval_recall: training: 0.884579 validation: 0.631854
09/16 12:19:25 PM: edges-rel-semeval_f1: training: 0.912640 validation: 0.721670
09/16 12:19:25 PM: Global learning rate: 6.25e-06
09/16 12:19:25 PM: Saving checkpoints to: ./experiments/rel-semeval-memorization-cat/run
09/16 12:19:25 PM: Stopped training after 48 validation checks
09/16 12:19:25 PM: Trained edges-rel-semeval for 4800 batches or 22.326 epochs
09/16 12:19:25 PM: ***** VALIDATION RESULTS *****
09/16 12:19:25 PM: edges-rel-semeval_f1 (for best val pass 38): edges-rel-semeval_loss: 0.07566, macro_avg: 0.72583, micro_avg: 0.00000, edges-rel-semeval_mcc: 0.72053, edges-rel-semeval_acc: 0.61358, edges-rel-semeval_precision: 0.84332, edges-rel-semeval_recall: 0.63708, edges-rel-semeval_f1: 0.72583
09/16 12:19:25 PM: micro_avg (for best val pass 1): edges-rel-semeval_loss: 0.17962, macro_avg: 0.00000, micro_avg: 0.00000, edges-rel-semeval_mcc: 0.00000, edges-rel-semeval_acc: 0.00000, edges-rel-semeval_precision: 0.00000, edges-rel-semeval_recall: 0.00000, edges-rel-semeval_f1: 0.00000
09/16 12:19:25 PM: macro_avg (for best val pass 38): edges-rel-semeval_loss: 0.07566, macro_avg: 0.72583, micro_avg: 0.00000, edges-rel-semeval_mcc: 0.72053, edges-rel-semeval_acc: 0.61358, edges-rel-semeval_precision: 0.84332, edges-rel-semeval_recall: 0.63708, edges-rel-semeval_f1: 0.72583
09/16 12:19:25 PM: Evaluating...
09/16 12:19:26 PM: Loaded model state from ./experiments/rel-semeval-memorization-cat/run/edges-rel-semeval/model_state_target_train_val_38.best.th
09/16 12:19:26 PM: Evaluating on: edges-rel-semeval, split: val
09/16 12:19:30 PM: Task 'edges-rel-semeval': sorting predictions by 'idx'
09/16 12:19:32 PM: Finished evaluating on: edges-rel-semeval
09/16 12:19:32 PM: Task 'edges-rel-semeval': joining predictions with input split 'val'
09/16 12:19:32 PM: Task 'edges-rel-semeval': Wrote predictions to ./experiments/rel-semeval-memorization-cat/run
09/16 12:19:32 PM: Wrote all preds for split 'val' to ./experiments/rel-semeval-memorization-cat/run
09/16 12:19:32 PM: Evaluating on: edges-rel-semeval, split: test
09/16 12:19:43 PM: Task 'edges-rel-semeval': sorting predictions by 'idx'
09/16 12:19:43 PM: Finished evaluating on: edges-rel-semeval
09/16 12:19:43 PM: Task 'edges-rel-semeval': joining predictions with input split 'test'
09/16 12:19:43 PM: Task 'edges-rel-semeval': Wrote predictions to ./experiments/rel-semeval-memorization-cat/run
09/16 12:19:43 PM: Wrote all preds for split 'test' to ./experiments/rel-semeval-memorization-cat/run
09/16 12:19:43 PM: Writing results for split 'val' to ./experiments/rel-semeval-memorization-cat/results.tsv
09/16 12:19:43 PM: micro_avg: 0.000, macro_avg: 0.726, edges-rel-semeval_mcc: 0.721, edges-rel-semeval_acc: 0.614, edges-rel-semeval_precision: 0.843, edges-rel-semeval_recall: 0.637, edges-rel-semeval_f1: 0.726
09/16 12:19:43 PM: Done!
09/16 12:19:43 PM: Fatal error in main():
Traceback (most recent call last):
  File "main.py", line 16, in <module>
    main(sys.argv[1:])
  File "/srv/home/ericwallace/jiant/jiant/__main__.py", line 610, in main
    exit("Done exited")
  File "/home/ericwallace/miniconda3/envs/jiant/lib/python3.6/_sitebuiltins.py", line 26, in __call__
    raise SystemExit(code)
SystemExit: Done exited
