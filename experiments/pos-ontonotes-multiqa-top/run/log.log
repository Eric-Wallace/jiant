09/16 09:39:17 AM: Git branch: master
09/16 09:39:17 AM: Git SHA: 0869c6f0712662a0adcfe16ed0072c1997d1c5da
09/16 09:39:17 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/pos-ontonotes-multiqa-top/",
  "exp_name": "experiments/pos-ontonotes-multiqa-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/pos-ontonotes-multiqa-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/multiqa",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/pos-ontonotes-multiqa-top__run",
  "run_dir": "./experiments/pos-ontonotes-multiqa-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-pos-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 09:39:17 AM: Saved config to ./experiments/pos-ontonotes-multiqa-top/run/params.conf
09/16 09:39:17 AM: Using random seed 1234
09/16 09:39:17 AM: Using GPU 0
09/16 09:39:17 AM: Loading tasks...
09/16 09:39:17 AM: Writing pre-preprocessed tasks to ./experiments/pos-ontonotes-multiqa-top/
09/16 09:39:17 AM: 	Creating task edges-pos-ontonotes from scratch.
09/16 09:39:37 AM: Read=110514, Skip=5298, Total=115812 from ./probing_data/edges/ontonotes/const/pos/train.json.retokenized.bert-base-uncased
09/16 09:39:38 AM: Read=15060, Skip=620, Total=15680 from ./probing_data/edges/ontonotes/const/pos/development.json.retokenized.bert-base-uncased
09/16 09:39:41 AM: Read=11462, Skip=755, Total=12217 from ./probing_data/edges/ontonotes/const/pos/test.json.retokenized.bert-base-uncased
09/16 09:39:53 AM: 	Task 'edges-pos-ontonotes': |train|=110514 |val|=15060 |test|=11462
09/16 09:39:53 AM: 	Finished loading tasks: edges-pos-ontonotes.
09/16 09:39:53 AM: 	Building vocab from scratch.
09/16 09:39:53 AM: 	Counting units for task edges-pos-ontonotes.
09/16 09:39:55 AM: 	Task 'edges-pos-ontonotes': adding vocab namespace 'edges-pos-ontonotes_labels'
09/16 09:39:56 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:39:56 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 09:39:56 AM: 	Saved vocab to ./experiments/pos-ontonotes-multiqa-top/vocab
09/16 09:39:56 AM: Loading token dictionary from ./experiments/pos-ontonotes-multiqa-top/vocab.
09/16 09:39:57 AM: 	Loaded vocab from ./experiments/pos-ontonotes-multiqa-top/vocab
09/16 09:39:57 AM: 	Vocab namespace bert_uncased: size 30524
09/16 09:39:57 AM: 	Vocab namespace tokens: size 24015
09/16 09:39:57 AM: 	Vocab namespace chars: size 81
09/16 09:39:57 AM: 	Vocab namespace edges-pos-ontonotes_labels: size 48
09/16 09:39:57 AM: 	Finished building vocab.
09/16 09:39:57 AM: 	Task edges-pos-ontonotes (train): Indexing from scratch.
09/16 09:40:37 AM: 	Task edges-pos-ontonotes (train): Saved 110514 instances to ./experiments/pos-ontonotes-multiqa-top/preproc/edges-pos-ontonotes__train_data
09/16 09:40:37 AM: 	Task edges-pos-ontonotes (val): Indexing from scratch.
09/16 09:40:45 AM: 	Task edges-pos-ontonotes (val): Saved 15060 instances to ./experiments/pos-ontonotes-multiqa-top/preproc/edges-pos-ontonotes__val_data
09/16 09:40:45 AM: 	Task edges-pos-ontonotes (test): Indexing from scratch.
09/16 09:40:50 AM: 	Task edges-pos-ontonotes (test): Saved 11462 instances to ./experiments/pos-ontonotes-multiqa-top/preproc/edges-pos-ontonotes__test_data
09/16 09:40:50 AM: 	Finished indexing tasks
09/16 09:40:50 AM: 	Creating trimmed target-only version of edges-pos-ontonotes train.
09/16 09:40:50 AM: 	  Training on 
09/16 09:40:50 AM: 	  Evaluating on edges-pos-ontonotes
09/16 09:40:50 AM: 	Finished loading tasks in 92.660s
09/16 09:40:50 AM: 	 Tasks: ['edges-pos-ontonotes']
09/16 09:40:50 AM: Building model...
09/16 09:40:50 AM: Using BERT model (bert-base-uncased).
09/16 09:40:50 AM: LOADING A FUNETUNED MODEL from: 
09/16 09:40:50 AM: models/multiqa
09/16 09:40:50 AM: loading configuration file models/multiqa/config.json
09/16 09:40:50 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 09:40:50 AM: loading weights file models/multiqa/pytorch_model.bin
09/16 09:40:54 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpq5w3m5ic
09/16 09:40:55 AM: copying /tmp/tmpq5w3m5ic to cache at ./experiments/pos-ontonotes-multiqa-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:40:55 AM: creating metadata file for ./experiments/pos-ontonotes-multiqa-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:40:55 AM: removing temp file /tmp/tmpq5w3m5ic
09/16 09:40:55 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/pos-ontonotes-multiqa-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:40:56 AM: Initializing parameters
09/16 09:40:56 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 09:40:56 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 09:40:56 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 09:40:56 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 09:40:56 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 09:40:56 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 09:40:56 AM: 	Task 'edges-pos-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-pos-ontonotes"
}
09/16 09:41:01 AM: Model specification:
09/16 09:41:01 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-pos-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=48, bias=True)
    )
  )
)
09/16 09:41:01 AM: Model parameters:
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	edges-pos-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 09:41:01 AM: 	edges-pos-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 09:41:01 AM: 	edges-pos-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 24576 with torch.Size([48, 512])
09/16 09:41:01 AM: 	edges-pos-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 48 with torch.Size([48])
09/16 09:41:01 AM: Total number of parameters: 109703728 (1.09704e+08)
09/16 09:41:01 AM: Number of trainable parameters: 221488 (221488)
09/16 09:41:01 AM: Finished building model in 11.586s
09/16 09:41:01 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-pos-ontonotes 

09/16 09:42:21 AM: patience = 9
09/16 09:42:21 AM: val_interval = 1000
09/16 09:42:21 AM: max_vals = 250
09/16 09:42:21 AM: cuda_device = 0
09/16 09:42:21 AM: grad_norm = 5.0
09/16 09:42:21 AM: grad_clipping = None
09/16 09:42:21 AM: lr_decay = 0.99
09/16 09:42:21 AM: min_lr = 1e-06
09/16 09:42:21 AM: keep_all_checkpoints = 0
09/16 09:42:21 AM: val_data_limit = 5000
09/16 09:42:21 AM: max_epochs = -1
09/16 09:42:21 AM: dec_val_scale = 250
09/16 09:42:21 AM: training_data_fraction = 1
09/16 09:42:21 AM: type = adam
09/16 09:42:21 AM: parameter_groups = None
09/16 09:42:21 AM: Number of trainable parameters: 221488
09/16 09:42:21 AM: infer_type_and_cast = True
09/16 09:42:21 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:42:21 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:42:21 AM: lr = 0.0001
09/16 09:42:21 AM: amsgrad = True
09/16 09:42:21 AM: type = reduce_on_plateau
09/16 09:42:21 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:42:21 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:42:21 AM: mode = max
09/16 09:42:21 AM: factor = 0.5
09/16 09:42:21 AM: patience = 3
09/16 09:42:21 AM: threshold = 0.0001
09/16 09:42:21 AM: threshold_mode = abs
09/16 09:42:21 AM: verbose = True
09/16 09:42:21 AM: type = adam
09/16 09:42:21 AM: parameter_groups = None
09/16 09:42:21 AM: Number of trainable parameters: 221488
09/16 09:42:21 AM: infer_type_and_cast = True
09/16 09:42:21 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:42:21 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:42:21 AM: lr = 0.0001
09/16 09:42:21 AM: amsgrad = True
09/16 09:42:21 AM: type = reduce_on_plateau
09/16 09:42:21 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:42:21 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:42:21 AM: mode = max
09/16 09:42:21 AM: factor = 0.5
09/16 09:42:21 AM: patience = 3
09/16 09:42:21 AM: threshold = 0.0001
09/16 09:42:21 AM: threshold_mode = abs
09/16 09:42:21 AM: verbose = True
09/16 09:42:21 AM: Starting training without restoring from a checkpoint.
09/16 09:42:21 AM: Training examples per task, before any subsampling: {'edges-pos-ontonotes': 110514}
09/16 09:42:21 AM: Beginning training with stopping criteria based on metric: edges-pos-ontonotes_f1
09/16 09:42:31 AM: Update 50: task edges-pos-ontonotes, batch 50 (50): mcc: 0.0050, acc: 0.0009, precision: 0.0229, recall: 0.1163, f1: 0.0383, edges-pos-ontonotes_loss: 0.3394
09/16 09:42:41 AM: Update 104: task edges-pos-ontonotes, batch 104 (104): mcc: 0.0035, acc: 0.0005, precision: 0.0229, recall: 0.0609, f1: 0.0333, edges-pos-ontonotes_loss: 0.2112
09/16 09:42:51 AM: Update 133: task edges-pos-ontonotes, batch 133 (133): mcc: 0.0030, acc: 0.0004, precision: 0.0229, recall: 0.0466, f1: 0.0307, edges-pos-ontonotes_loss: 0.1834
09/16 09:43:02 AM: Update 169: task edges-pos-ontonotes, batch 169 (169): mcc: 0.0039, acc: 0.0019, precision: 0.0238, recall: 0.0400, f1: 0.0298, edges-pos-ontonotes_loss: 0.1610
09/16 09:43:12 AM: Update 197: task edges-pos-ontonotes, batch 197 (197): mcc: 0.0046, acc: 0.0027, precision: 0.0246, recall: 0.0338, f1: 0.0285, edges-pos-ontonotes_loss: 0.1494
09/16 09:43:22 AM: Update 225: task edges-pos-ontonotes, batch 225 (225): mcc: 0.0052, acc: 0.0034, precision: 0.0255, recall: 0.0312, f1: 0.0280, edges-pos-ontonotes_loss: 0.1403
09/16 09:43:32 AM: Update 258: task edges-pos-ontonotes, batch 258 (258): mcc: 0.0094, acc: 0.0077, precision: 0.0296, recall: 0.0322, f1: 0.0309, edges-pos-ontonotes_loss: 0.1317
09/16 09:43:42 AM: Update 289: task edges-pos-ontonotes, batch 289 (289): mcc: 0.0139, acc: 0.0120, precision: 0.0345, recall: 0.0341, f1: 0.0343, edges-pos-ontonotes_loss: 0.1254
09/16 09:43:54 AM: Update 314: task edges-pos-ontonotes, batch 314 (314): mcc: 0.0170, acc: 0.0144, precision: 0.0384, recall: 0.0345, f1: 0.0364, edges-pos-ontonotes_loss: 0.1212
09/16 09:44:04 AM: Update 341: task edges-pos-ontonotes, batch 341 (341): mcc: 0.0182, acc: 0.0149, precision: 0.0408, recall: 0.0327, f1: 0.0363, edges-pos-ontonotes_loss: 0.1175
09/16 09:44:14 AM: Update 369: task edges-pos-ontonotes, batch 369 (369): mcc: 0.0208, acc: 0.0164, precision: 0.0447, recall: 0.0327, f1: 0.0377, edges-pos-ontonotes_loss: 0.1141
09/16 09:44:24 AM: Update 396: task edges-pos-ontonotes, batch 396 (396): mcc: 0.0237, acc: 0.0183, precision: 0.0491, recall: 0.0333, f1: 0.0397, edges-pos-ontonotes_loss: 0.1111
09/16 09:44:34 AM: Update 423: task edges-pos-ontonotes, batch 423 (423): mcc: 0.0275, acc: 0.0207, precision: 0.0548, recall: 0.0345, f1: 0.0424, edges-pos-ontonotes_loss: 0.1085
09/16 09:44:45 AM: Update 452: task edges-pos-ontonotes, batch 452 (452): mcc: 0.0315, acc: 0.0230, precision: 0.0612, recall: 0.0360, f1: 0.0453, edges-pos-ontonotes_loss: 0.1059
09/16 09:44:55 AM: Update 501: task edges-pos-ontonotes, batch 501 (501): mcc: 0.0394, acc: 0.0276, precision: 0.0743, recall: 0.0391, f1: 0.0512, edges-pos-ontonotes_loss: 0.1022
09/16 09:45:05 AM: Update 537: task edges-pos-ontonotes, batch 537 (537): mcc: 0.0454, acc: 0.0308, precision: 0.0847, recall: 0.0415, f1: 0.0557, edges-pos-ontonotes_loss: 0.0999
09/16 09:45:15 AM: Update 564: task edges-pos-ontonotes, batch 564 (564): mcc: 0.0502, acc: 0.0334, precision: 0.0930, recall: 0.0436, f1: 0.0594, edges-pos-ontonotes_loss: 0.0982
09/16 09:45:26 AM: Update 591: task edges-pos-ontonotes, batch 591 (591): mcc: 0.0548, acc: 0.0357, precision: 0.1014, recall: 0.0455, f1: 0.0628, edges-pos-ontonotes_loss: 0.0965
09/16 09:45:36 AM: Update 618: task edges-pos-ontonotes, batch 618 (618): mcc: 0.0603, acc: 0.0386, precision: 0.1112, recall: 0.0480, f1: 0.0671, edges-pos-ontonotes_loss: 0.0950
09/16 09:45:46 AM: Update 635: task edges-pos-ontonotes, batch 635 (635): mcc: 0.0641, acc: 0.0404, precision: 0.1185, recall: 0.0496, f1: 0.0699, edges-pos-ontonotes_loss: 0.0943
09/16 09:45:56 AM: Update 660: task edges-pos-ontonotes, batch 660 (660): mcc: 0.0695, acc: 0.0429, precision: 0.1289, recall: 0.0517, f1: 0.0738, edges-pos-ontonotes_loss: 0.0932
09/16 09:46:06 AM: Update 682: task edges-pos-ontonotes, batch 682 (682): mcc: 0.0747, acc: 0.0452, precision: 0.1393, recall: 0.0537, f1: 0.0775, edges-pos-ontonotes_loss: 0.0923
09/16 09:46:17 AM: Update 705: task edges-pos-ontonotes, batch 705 (705): mcc: 0.0797, acc: 0.0475, precision: 0.1495, recall: 0.0557, f1: 0.0812, edges-pos-ontonotes_loss: 0.0914
09/16 09:46:27 AM: Update 729: task edges-pos-ontonotes, batch 729 (729): mcc: 0.0849, acc: 0.0499, precision: 0.1600, recall: 0.0578, f1: 0.0850, edges-pos-ontonotes_loss: 0.0905
09/16 09:46:37 AM: Update 753: task edges-pos-ontonotes, batch 753 (753): mcc: 0.0905, acc: 0.0525, precision: 0.1709, recall: 0.0604, f1: 0.0893, edges-pos-ontonotes_loss: 0.0897
09/16 09:46:47 AM: Update 780: task edges-pos-ontonotes, batch 780 (780): mcc: 0.0960, acc: 0.0551, precision: 0.1820, recall: 0.0628, f1: 0.0934, edges-pos-ontonotes_loss: 0.0887
09/16 09:46:58 AM: Update 804: task edges-pos-ontonotes, batch 804 (804): mcc: 0.1018, acc: 0.0578, precision: 0.1936, recall: 0.0653, f1: 0.0977, edges-pos-ontonotes_loss: 0.0880
09/16 09:47:08 AM: Update 831: task edges-pos-ontonotes, batch 831 (831): mcc: 0.1079, acc: 0.0606, precision: 0.2059, recall: 0.0680, f1: 0.1023, edges-pos-ontonotes_loss: 0.0871
09/16 09:47:18 AM: Update 879: task edges-pos-ontonotes, batch 879 (879): mcc: 0.1190, acc: 0.0660, precision: 0.2276, recall: 0.0733, f1: 0.1109, edges-pos-ontonotes_loss: 0.0856
09/16 09:47:28 AM: Update 906: task edges-pos-ontonotes, batch 906 (906): mcc: 0.1263, acc: 0.0693, precision: 0.2426, recall: 0.0766, f1: 0.1164, edges-pos-ontonotes_loss: 0.0849
09/16 09:47:39 AM: Update 930: task edges-pos-ontonotes, batch 930 (930): mcc: 0.1322, acc: 0.0721, precision: 0.2545, recall: 0.0793, f1: 0.1209, edges-pos-ontonotes_loss: 0.0842
09/16 09:47:49 AM: Update 946: task edges-pos-ontonotes, batch 946 (946): mcc: 0.1361, acc: 0.0739, precision: 0.2627, recall: 0.0810, f1: 0.1238, edges-pos-ontonotes_loss: 0.0838
09/16 09:47:59 AM: Update 973: task edges-pos-ontonotes, batch 973 (973): mcc: 0.1418, acc: 0.0764, precision: 0.2744, recall: 0.0835, f1: 0.1280, edges-pos-ontonotes_loss: 0.0831
09/16 09:48:09 AM: Update 996: task edges-pos-ontonotes, batch 996 (996): mcc: 0.1473, acc: 0.0789, precision: 0.2856, recall: 0.0860, f1: 0.1321, edges-pos-ontonotes_loss: 0.0826
09/16 09:48:11 AM: ***** Step 1000 / Validation 1 *****
09/16 09:48:11 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 09:48:11 AM: Validating...
09/16 09:48:19 AM: Evaluate: task edges-pos-ontonotes, batch 28 (157): mcc: 0.3930, acc: 0.1775, precision: 0.8635, recall: 0.1831, f1: 0.3021, edges-pos-ontonotes_loss: 0.0580
09/16 09:48:29 AM: Evaluate: task edges-pos-ontonotes, batch 62 (157): mcc: 0.4069, acc: 0.1848, precision: 0.8951, recall: 0.1890, f1: 0.3121, edges-pos-ontonotes_loss: 0.0588
09/16 09:48:40 AM: Evaluate: task edges-pos-ontonotes, batch 93 (157): mcc: 0.4266, acc: 0.2013, precision: 0.9016, recall: 0.2061, f1: 0.3356, edges-pos-ontonotes_loss: 0.0573
09/16 09:48:50 AM: Evaluate: task edges-pos-ontonotes, batch 119 (157): mcc: 0.4274, acc: 0.2021, precision: 0.9003, recall: 0.2072, f1: 0.3369, edges-pos-ontonotes_loss: 0.0568
09/16 09:49:00 AM: Evaluate: task edges-pos-ontonotes, batch 144 (157): mcc: 0.4212, acc: 0.1976, precision: 0.8938, recall: 0.2028, f1: 0.3306, edges-pos-ontonotes_loss: 0.0566
09/16 09:49:05 AM: Best result seen so far for edges-pos-ontonotes.
09/16 09:49:05 AM: Best result seen so far for micro.
09/16 09:49:05 AM: Best result seen so far for macro.
09/16 09:49:05 AM: Updating LR scheduler:
09/16 09:49:05 AM: 	Best result seen so far for macro_avg: 0.327
09/16 09:49:05 AM: 	# validation passes without improvement: 0
09/16 09:49:05 AM: edges-pos-ontonotes_loss: training: 0.082498 validation: 0.056583
09/16 09:49:05 AM: macro_avg: validation: 0.327192
09/16 09:49:05 AM: micro_avg: validation: 0.000000
09/16 09:49:05 AM: edges-pos-ontonotes_mcc: training: 0.148172 validation: 0.418547
09/16 09:49:05 AM: edges-pos-ontonotes_acc: training: 0.079335 validation: 0.195276
09/16 09:49:05 AM: edges-pos-ontonotes_precision: training: 0.287531 validation: 0.893775
09/16 09:49:05 AM: edges-pos-ontonotes_recall: training: 0.086359 validation: 0.200250
09/16 09:49:05 AM: edges-pos-ontonotes_f1: training: 0.132824 validation: 0.327192
09/16 09:49:05 AM: Global learning rate: 0.0001
09/16 09:49:05 AM: Saving checkpoints to: ./experiments/pos-ontonotes-multiqa-top/run
09/16 09:49:10 AM: Update 1013: task edges-pos-ontonotes, batch 13 (1013): mcc: 0.3768, acc: 0.1674, precision: 0.8369, recall: 0.1740, f1: 0.2881, edges-pos-ontonotes_loss: 0.0584
09/16 09:49:20 AM: Update 1036: task edges-pos-ontonotes, batch 36 (1036): mcc: 0.3770, acc: 0.1686, precision: 0.8291, recall: 0.1758, f1: 0.2901, edges-pos-ontonotes_loss: 0.0584
09/16 09:49:31 AM: Update 1059: task edges-pos-ontonotes, batch 59 (1059): mcc: 0.3764, acc: 0.1684, precision: 0.8261, recall: 0.1759, f1: 0.2901, edges-pos-ontonotes_loss: 0.0582
09/16 09:49:41 AM: Update 1086: task edges-pos-ontonotes, batch 86 (1086): mcc: 0.3830, acc: 0.1739, precision: 0.8279, recall: 0.1818, f1: 0.2981, edges-pos-ontonotes_loss: 0.0578
09/16 09:49:51 AM: Update 1129: task edges-pos-ontonotes, batch 129 (1129): mcc: 0.3883, acc: 0.1782, precision: 0.8286, recall: 0.1866, f1: 0.3046, edges-pos-ontonotes_loss: 0.0572
09/16 09:50:01 AM: Update 1152: task edges-pos-ontonotes, batch 152 (1152): mcc: 0.3910, acc: 0.1807, precision: 0.8276, recall: 0.1895, f1: 0.3084, edges-pos-ontonotes_loss: 0.0570
09/16 09:50:12 AM: Update 1176: task edges-pos-ontonotes, batch 176 (1176): mcc: 0.3941, acc: 0.1832, precision: 0.8294, recall: 0.1920, f1: 0.3118, edges-pos-ontonotes_loss: 0.0568
09/16 09:50:22 AM: Update 1200: task edges-pos-ontonotes, batch 200 (1200): mcc: 0.3963, acc: 0.1854, precision: 0.8287, recall: 0.1943, f1: 0.3148, edges-pos-ontonotes_loss: 0.0566
09/16 09:50:32 AM: Update 1222: task edges-pos-ontonotes, batch 222 (1222): mcc: 0.3977, acc: 0.1868, precision: 0.8283, recall: 0.1958, f1: 0.3167, edges-pos-ontonotes_loss: 0.0565
09/16 09:50:42 AM: Update 1243: task edges-pos-ontonotes, batch 243 (1243): mcc: 0.4003, acc: 0.1891, precision: 0.8280, recall: 0.1984, f1: 0.3201, edges-pos-ontonotes_loss: 0.0563
09/16 09:50:59 AM: Update 1253: task edges-pos-ontonotes, batch 253 (1253): mcc: 0.4007, acc: 0.1896, precision: 0.8270, recall: 0.1990, f1: 0.3209, edges-pos-ontonotes_loss: 0.0563
09/16 09:51:09 AM: Update 1276: task edges-pos-ontonotes, batch 276 (1276): mcc: 0.4029, acc: 0.1915, precision: 0.8277, recall: 0.2010, f1: 0.3235, edges-pos-ontonotes_loss: 0.0562
09/16 09:51:19 AM: Update 1300: task edges-pos-ontonotes, batch 300 (1300): mcc: 0.4058, acc: 0.1942, precision: 0.8287, recall: 0.2037, f1: 0.3271, edges-pos-ontonotes_loss: 0.0559
09/16 09:51:30 AM: Update 1325: task edges-pos-ontonotes, batch 325 (1325): mcc: 0.4088, acc: 0.1968, precision: 0.8292, recall: 0.2065, f1: 0.3307, edges-pos-ontonotes_loss: 0.0556
09/16 09:51:40 AM: Update 1350: task edges-pos-ontonotes, batch 350 (1350): mcc: 0.4110, acc: 0.1989, precision: 0.8290, recall: 0.2089, f1: 0.3337, edges-pos-ontonotes_loss: 0.0555
09/16 09:51:50 AM: Update 1372: task edges-pos-ontonotes, batch 372 (1372): mcc: 0.4134, acc: 0.2012, precision: 0.8291, recall: 0.2113, f1: 0.3367, edges-pos-ontonotes_loss: 0.0553
09/16 09:52:00 AM: Update 1398: task edges-pos-ontonotes, batch 398 (1398): mcc: 0.4162, acc: 0.2037, precision: 0.8294, recall: 0.2140, f1: 0.3402, edges-pos-ontonotes_loss: 0.0551
09/16 09:52:10 AM: Update 1437: task edges-pos-ontonotes, batch 437 (1437): mcc: 0.4204, acc: 0.2077, precision: 0.8291, recall: 0.2184, f1: 0.3457, edges-pos-ontonotes_loss: 0.0548
09/16 09:52:20 AM: Update 1462: task edges-pos-ontonotes, batch 462 (1462): mcc: 0.4225, acc: 0.2098, precision: 0.8292, recall: 0.2205, f1: 0.3484, edges-pos-ontonotes_loss: 0.0546
09/16 09:52:31 AM: Update 1485: task edges-pos-ontonotes, batch 485 (1485): mcc: 0.4250, acc: 0.2122, precision: 0.8295, recall: 0.2231, f1: 0.3516, edges-pos-ontonotes_loss: 0.0545
09/16 09:52:41 AM: Update 1507: task edges-pos-ontonotes, batch 507 (1507): mcc: 0.4269, acc: 0.2140, precision: 0.8298, recall: 0.2250, f1: 0.3540, edges-pos-ontonotes_loss: 0.0543
09/16 09:52:51 AM: Update 1529: task edges-pos-ontonotes, batch 529 (1529): mcc: 0.4292, acc: 0.2163, precision: 0.8296, recall: 0.2275, f1: 0.3571, edges-pos-ontonotes_loss: 0.0542
09/16 09:53:01 AM: Update 1552: task edges-pos-ontonotes, batch 552 (1552): mcc: 0.4311, acc: 0.2180, precision: 0.8299, recall: 0.2294, f1: 0.3594, edges-pos-ontonotes_loss: 0.0540
09/16 09:53:11 AM: Update 1568: task edges-pos-ontonotes, batch 568 (1568): mcc: 0.4322, acc: 0.2193, precision: 0.8290, recall: 0.2308, f1: 0.3611, edges-pos-ontonotes_loss: 0.0539
09/16 09:53:22 AM: Update 1593: task edges-pos-ontonotes, batch 593 (1593): mcc: 0.4344, acc: 0.2214, precision: 0.8292, recall: 0.2331, f1: 0.3639, edges-pos-ontonotes_loss: 0.0537
09/16 09:53:32 AM: Update 1614: task edges-pos-ontonotes, batch 614 (1614): mcc: 0.4363, acc: 0.2234, precision: 0.8288, recall: 0.2353, f1: 0.3665, edges-pos-ontonotes_loss: 0.0535
09/16 09:53:42 AM: Update 1636: task edges-pos-ontonotes, batch 636 (1636): mcc: 0.4383, acc: 0.2253, precision: 0.8288, recall: 0.2374, f1: 0.3690, edges-pos-ontonotes_loss: 0.0534
09/16 09:53:52 AM: Update 1657: task edges-pos-ontonotes, batch 657 (1657): mcc: 0.4403, acc: 0.2274, precision: 0.8291, recall: 0.2395, f1: 0.3716, edges-pos-ontonotes_loss: 0.0533
09/16 09:54:03 AM: Update 1682: task edges-pos-ontonotes, batch 682 (1682): mcc: 0.4429, acc: 0.2298, precision: 0.8291, recall: 0.2422, f1: 0.3749, edges-pos-ontonotes_loss: 0.0531
09/16 09:54:13 AM: Update 1705: task edges-pos-ontonotes, batch 705 (1705): mcc: 0.4445, acc: 0.2315, precision: 0.8288, recall: 0.2442, f1: 0.3772, edges-pos-ontonotes_loss: 0.0529
09/16 09:54:23 AM: Update 1730: task edges-pos-ontonotes, batch 730 (1730): mcc: 0.4465, acc: 0.2336, precision: 0.8285, recall: 0.2464, f1: 0.3798, edges-pos-ontonotes_loss: 0.0528
09/16 09:54:34 AM: Update 1763: task edges-pos-ontonotes, batch 763 (1763): mcc: 0.4491, acc: 0.2362, precision: 0.8286, recall: 0.2492, f1: 0.3832, edges-pos-ontonotes_loss: 0.0526
09/16 09:54:44 AM: Update 1787: task edges-pos-ontonotes, batch 787 (1787): mcc: 0.4508, acc: 0.2379, precision: 0.8284, recall: 0.2512, f1: 0.3855, edges-pos-ontonotes_loss: 0.0524
09/16 09:54:54 AM: Update 1811: task edges-pos-ontonotes, batch 811 (1811): mcc: 0.4525, acc: 0.2397, precision: 0.8284, recall: 0.2530, f1: 0.3876, edges-pos-ontonotes_loss: 0.0523
09/16 09:55:04 AM: Update 1835: task edges-pos-ontonotes, batch 835 (1835): mcc: 0.4544, acc: 0.2417, precision: 0.8284, recall: 0.2552, f1: 0.3902, edges-pos-ontonotes_loss: 0.0521
09/16 09:55:15 AM: Update 1855: task edges-pos-ontonotes, batch 855 (1855): mcc: 0.4560, acc: 0.2433, precision: 0.8286, recall: 0.2569, f1: 0.3922, edges-pos-ontonotes_loss: 0.0520
09/16 09:55:25 AM: Update 1878: task edges-pos-ontonotes, batch 878 (1878): mcc: 0.4581, acc: 0.2453, precision: 0.8285, recall: 0.2593, f1: 0.3949, edges-pos-ontonotes_loss: 0.0518
09/16 09:55:35 AM: Update 1891: task edges-pos-ontonotes, batch 891 (1891): mcc: 0.4583, acc: 0.2457, precision: 0.8279, recall: 0.2597, f1: 0.3953, edges-pos-ontonotes_loss: 0.0518
09/16 09:55:46 AM: Update 1914: task edges-pos-ontonotes, batch 914 (1914): mcc: 0.4597, acc: 0.2472, precision: 0.8279, recall: 0.2613, f1: 0.3972, edges-pos-ontonotes_loss: 0.0517
09/16 09:55:56 AM: Update 1937: task edges-pos-ontonotes, batch 937 (1937): mcc: 0.4609, acc: 0.2484, precision: 0.8279, recall: 0.2627, f1: 0.3988, edges-pos-ontonotes_loss: 0.0516
09/16 09:56:06 AM: Update 1962: task edges-pos-ontonotes, batch 962 (1962): mcc: 0.4625, acc: 0.2500, precision: 0.8280, recall: 0.2644, f1: 0.4008, edges-pos-ontonotes_loss: 0.0514
09/16 09:56:16 AM: Update 1986: task edges-pos-ontonotes, batch 986 (1986): mcc: 0.4640, acc: 0.2516, precision: 0.8281, recall: 0.2661, f1: 0.4027, edges-pos-ontonotes_loss: 0.0513
09/16 09:56:21 AM: ***** Step 2000 / Validation 2 *****
09/16 09:56:21 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 09:56:21 AM: Validating...
09/16 09:56:26 AM: Evaluate: task edges-pos-ontonotes, batch 16 (157): mcc: 0.5619, acc: 0.3514, precision: 0.8878, recall: 0.3621, f1: 0.5144, edges-pos-ontonotes_loss: 0.0438
09/16 09:56:36 AM: Evaluate: task edges-pos-ontonotes, batch 50 (157): mcc: 0.5412, acc: 0.3235, precision: 0.9028, recall: 0.3303, f1: 0.4837, edges-pos-ontonotes_loss: 0.0465
09/16 09:56:46 AM: Evaluate: task edges-pos-ontonotes, batch 88 (157): mcc: 0.5683, acc: 0.3536, precision: 0.9065, recall: 0.3624, f1: 0.5178, edges-pos-ontonotes_loss: 0.0445
09/16 09:56:57 AM: Evaluate: task edges-pos-ontonotes, batch 119 (157): mcc: 0.5765, acc: 0.3653, precision: 0.9007, recall: 0.3753, f1: 0.5298, edges-pos-ontonotes_loss: 0.0438
09/16 09:57:07 AM: Evaluate: task edges-pos-ontonotes, batch 144 (157): mcc: 0.5763, acc: 0.3669, precision: 0.8949, recall: 0.3775, f1: 0.5310, edges-pos-ontonotes_loss: 0.0435
09/16 09:57:12 AM: Best result seen so far for edges-pos-ontonotes.
09/16 09:57:12 AM: Best result seen so far for macro.
09/16 09:57:12 AM: Updating LR scheduler:
09/16 09:57:12 AM: 	Best result seen so far for macro_avg: 0.531
09/16 09:57:12 AM: 	# validation passes without improvement: 0
09/16 09:57:12 AM: edges-pos-ontonotes_loss: training: 0.051144 validation: 0.043330
09/16 09:57:12 AM: macro_avg: validation: 0.530518
09/16 09:57:12 AM: micro_avg: validation: 0.000000
09/16 09:57:12 AM: edges-pos-ontonotes_mcc: training: 0.464805 validation: 0.575948
09/16 09:57:12 AM: edges-pos-ontonotes_acc: training: 0.252411 validation: 0.366371
09/16 09:57:12 AM: edges-pos-ontonotes_precision: training: 0.828235 validation: 0.895332
09/16 09:57:12 AM: edges-pos-ontonotes_recall: training: 0.266960 validation: 0.376933
09/16 09:57:12 AM: edges-pos-ontonotes_f1: training: 0.403774 validation: 0.530518
09/16 09:57:12 AM: Global learning rate: 0.0001
09/16 09:57:12 AM: Saving checkpoints to: ./experiments/pos-ontonotes-multiqa-top/run
09/16 09:57:17 AM: Update 2011: task edges-pos-ontonotes, batch 11 (2011): mcc: 0.5283, acc: 0.3257, precision: 0.8253, recall: 0.3454, f1: 0.4870, edges-pos-ontonotes_loss: 0.0453
09/16 09:57:27 AM: Update 2038: task edges-pos-ontonotes, batch 38 (2038): mcc: 0.5386, acc: 0.3355, precision: 0.8314, recall: 0.3561, f1: 0.4987, edges-pos-ontonotes_loss: 0.0445
09/16 09:57:38 AM: Update 2063: task edges-pos-ontonotes, batch 63 (2063): mcc: 0.5416, acc: 0.3380, precision: 0.8335, recall: 0.3593, f1: 0.5021, edges-pos-ontonotes_loss: 0.0443
09/16 09:57:48 AM: Update 2087: task edges-pos-ontonotes, batch 87 (2087): mcc: 0.5439, acc: 0.3400, precision: 0.8354, recall: 0.3614, f1: 0.5046, edges-pos-ontonotes_loss: 0.0442
09/16 09:57:58 AM: Update 2111: task edges-pos-ontonotes, batch 111 (2111): mcc: 0.5408, acc: 0.3367, precision: 0.8334, recall: 0.3582, f1: 0.5011, edges-pos-ontonotes_loss: 0.0441
09/16 09:58:08 AM: Update 2135: task edges-pos-ontonotes, batch 135 (2135): mcc: 0.5411, acc: 0.3369, precision: 0.8315, recall: 0.3594, f1: 0.5019, edges-pos-ontonotes_loss: 0.0440
09/16 09:58:19 AM: Update 2160: task edges-pos-ontonotes, batch 160 (2160): mcc: 0.5420, acc: 0.3381, precision: 0.8311, recall: 0.3608, f1: 0.5032, edges-pos-ontonotes_loss: 0.0438
09/16 09:58:29 AM: Update 2186: task edges-pos-ontonotes, batch 186 (2186): mcc: 0.5435, acc: 0.3397, precision: 0.8308, recall: 0.3630, f1: 0.5052, edges-pos-ontonotes_loss: 0.0436
09/16 09:58:39 AM: Update 2210: task edges-pos-ontonotes, batch 210 (2210): mcc: 0.5447, acc: 0.3413, precision: 0.8311, recall: 0.3643, f1: 0.5066, edges-pos-ontonotes_loss: 0.0434
09/16 09:58:50 AM: Update 2236: task edges-pos-ontonotes, batch 236 (2236): mcc: 0.5480, acc: 0.3444, precision: 0.8346, recall: 0.3672, f1: 0.5100, edges-pos-ontonotes_loss: 0.0432
09/16 09:59:00 AM: Update 2264: task edges-pos-ontonotes, batch 264 (2264): mcc: 0.5525, acc: 0.3490, precision: 0.8373, recall: 0.3719, f1: 0.5151, edges-pos-ontonotes_loss: 0.0428
09/16 09:59:10 AM: Update 2320: task edges-pos-ontonotes, batch 320 (2320): mcc: 0.5612, acc: 0.3580, precision: 0.8429, recall: 0.3811, f1: 0.5249, edges-pos-ontonotes_loss: 0.0421
09/16 09:59:20 AM: Update 2361: task edges-pos-ontonotes, batch 361 (2361): mcc: 0.5663, acc: 0.3635, precision: 0.8461, recall: 0.3864, f1: 0.5305, edges-pos-ontonotes_loss: 0.0418
09/16 09:59:30 AM: Update 2388: task edges-pos-ontonotes, batch 388 (2388): mcc: 0.5699, acc: 0.3673, precision: 0.8476, recall: 0.3905, f1: 0.5347, edges-pos-ontonotes_loss: 0.0416
09/16 09:59:40 AM: Update 2417: task edges-pos-ontonotes, batch 417 (2417): mcc: 0.5735, acc: 0.3712, precision: 0.8498, recall: 0.3943, f1: 0.5387, edges-pos-ontonotes_loss: 0.0413
09/16 09:59:51 AM: Update 2445: task edges-pos-ontonotes, batch 445 (2445): mcc: 0.5763, acc: 0.3744, precision: 0.8509, recall: 0.3977, f1: 0.5420, edges-pos-ontonotes_loss: 0.0411
09/16 10:00:01 AM: Update 2472: task edges-pos-ontonotes, batch 472 (2472): mcc: 0.5793, acc: 0.3778, precision: 0.8521, recall: 0.4012, f1: 0.5456, edges-pos-ontonotes_loss: 0.0409
09/16 10:00:11 AM: Update 2505: task edges-pos-ontonotes, batch 505 (2505): mcc: 0.5815, acc: 0.3803, precision: 0.8530, recall: 0.4039, f1: 0.5482, edges-pos-ontonotes_loss: 0.0407
09/16 10:00:21 AM: Update 2535: task edges-pos-ontonotes, batch 535 (2535): mcc: 0.5840, acc: 0.3831, precision: 0.8539, recall: 0.4069, f1: 0.5511, edges-pos-ontonotes_loss: 0.0406
09/16 10:00:31 AM: Update 2573: task edges-pos-ontonotes, batch 573 (2573): mcc: 0.5866, acc: 0.3860, precision: 0.8552, recall: 0.4097, f1: 0.5540, edges-pos-ontonotes_loss: 0.0402
09/16 10:00:42 AM: Update 2605: task edges-pos-ontonotes, batch 605 (2605): mcc: 0.5892, acc: 0.3891, precision: 0.8560, recall: 0.4129, f1: 0.5571, edges-pos-ontonotes_loss: 0.0400
09/16 10:00:52 AM: Update 2635: task edges-pos-ontonotes, batch 635 (2635): mcc: 0.5914, acc: 0.3919, precision: 0.8565, recall: 0.4158, f1: 0.5599, edges-pos-ontonotes_loss: 0.0399
09/16 10:01:02 AM: Update 2668: task edges-pos-ontonotes, batch 668 (2668): mcc: 0.5942, acc: 0.3953, precision: 0.8572, recall: 0.4194, f1: 0.5632, edges-pos-ontonotes_loss: 0.0396
09/16 10:01:12 AM: Update 2700: task edges-pos-ontonotes, batch 700 (2700): mcc: 0.5966, acc: 0.3981, precision: 0.8578, recall: 0.4224, f1: 0.5660, edges-pos-ontonotes_loss: 0.0394
09/16 10:01:23 AM: Update 2733: task edges-pos-ontonotes, batch 733 (2733): mcc: 0.5988, acc: 0.4009, precision: 0.8583, recall: 0.4253, f1: 0.5687, edges-pos-ontonotes_loss: 0.0391
09/16 10:01:33 AM: Update 2806: task edges-pos-ontonotes, batch 806 (2806): mcc: 0.6044, acc: 0.4078, precision: 0.8597, recall: 0.4324, f1: 0.5754, edges-pos-ontonotes_loss: 0.0386
09/16 10:01:43 AM: Update 2841: task edges-pos-ontonotes, batch 841 (2841): mcc: 0.6042, acc: 0.4078, precision: 0.8589, recall: 0.4325, f1: 0.5753, edges-pos-ontonotes_loss: 0.0385
09/16 10:01:53 AM: Update 2891: task edges-pos-ontonotes, batch 891 (2891): mcc: 0.6040, acc: 0.4080, precision: 0.8578, recall: 0.4328, f1: 0.5754, edges-pos-ontonotes_loss: 0.0385
09/16 10:02:03 AM: Update 2932: task edges-pos-ontonotes, batch 932 (2932): mcc: 0.6048, acc: 0.4091, precision: 0.8576, recall: 0.4340, f1: 0.5764, edges-pos-ontonotes_loss: 0.0383
09/16 10:02:14 AM: Update 2973: task edges-pos-ontonotes, batch 973 (2973): mcc: 0.6055, acc: 0.4100, precision: 0.8575, recall: 0.4351, f1: 0.5773, edges-pos-ontonotes_loss: 0.0381
09/16 10:02:21 AM: ***** Step 3000 / Validation 3 *****
09/16 10:02:21 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 10:02:21 AM: Validating...
09/16 10:02:24 AM: Evaluate: task edges-pos-ontonotes, batch 8 (157): mcc: 0.6708, acc: 0.4972, precision: 0.8575, recall: 0.5327, f1: 0.6572, edges-pos-ontonotes_loss: 0.0341
09/16 10:02:34 AM: Evaluate: task edges-pos-ontonotes, batch 42 (157): mcc: 0.6514, acc: 0.4688, precision: 0.8787, recall: 0.4904, f1: 0.6295, edges-pos-ontonotes_loss: 0.0363
09/16 10:02:44 AM: Evaluate: task edges-pos-ontonotes, batch 72 (157): mcc: 0.6700, acc: 0.4924, precision: 0.8852, recall: 0.5144, f1: 0.6507, edges-pos-ontonotes_loss: 0.0349
09/16 10:02:55 AM: Evaluate: task edges-pos-ontonotes, batch 102 (157): mcc: 0.6681, acc: 0.4909, precision: 0.8765, recall: 0.5167, f1: 0.6502, edges-pos-ontonotes_loss: 0.0351
09/16 10:03:05 AM: Evaluate: task edges-pos-ontonotes, batch 126 (157): mcc: 0.6599, acc: 0.4814, precision: 0.8682, recall: 0.5093, f1: 0.6420, edges-pos-ontonotes_loss: 0.0358
09/16 10:03:15 AM: Evaluate: task edges-pos-ontonotes, batch 150 (157): mcc: 0.6526, acc: 0.4720, precision: 0.8629, recall: 0.5014, f1: 0.6342, edges-pos-ontonotes_loss: 0.0363
09/16 10:03:17 AM: Best result seen so far for edges-pos-ontonotes.
09/16 10:03:17 AM: Best result seen so far for macro.
09/16 10:03:17 AM: Updating LR scheduler:
09/16 10:03:17 AM: 	Best result seen so far for macro_avg: 0.632
09/16 10:03:17 AM: 	# validation passes without improvement: 0
09/16 10:03:17 AM: edges-pos-ontonotes_loss: training: 0.038015 validation: 0.036428
09/16 10:03:17 AM: macro_avg: validation: 0.632305
09/16 10:03:17 AM: micro_avg: validation: 0.000000
09/16 10:03:17 AM: edges-pos-ontonotes_mcc: training: 0.605760 validation: 0.651072
09/16 10:03:17 AM: edges-pos-ontonotes_acc: training: 0.410481 validation: 0.469824
09/16 10:03:17 AM: edges-pos-ontonotes_precision: training: 0.857131 validation: 0.863111
09/16 10:03:17 AM: edges-pos-ontonotes_recall: training: 0.435672 validation: 0.498894
09/16 10:03:17 AM: edges-pos-ontonotes_f1: training: 0.577703 validation: 0.632305
09/16 10:03:17 AM: Global learning rate: 0.0001
09/16 10:03:17 AM: Saving checkpoints to: ./experiments/pos-ontonotes-multiqa-top/run
09/16 10:03:25 AM: Update 3027: task edges-pos-ontonotes, batch 27 (3027): mcc: 0.6138, acc: 0.4272, precision: 0.8428, recall: 0.4550, f1: 0.5909, edges-pos-ontonotes_loss: 0.0357
09/16 10:03:35 AM: Update 3065: task edges-pos-ontonotes, batch 65 (3065): mcc: 0.6120, acc: 0.4264, precision: 0.8375, recall: 0.4553, f1: 0.5899, edges-pos-ontonotes_loss: 0.0355
09/16 10:03:45 AM: Update 3106: task edges-pos-ontonotes, batch 106 (3106): mcc: 0.6175, acc: 0.4328, precision: 0.8411, recall: 0.4614, f1: 0.5959, edges-pos-ontonotes_loss: 0.0343
09/16 10:03:55 AM: Update 3135: task edges-pos-ontonotes, batch 135 (3135): mcc: 0.5999, acc: 0.4137, precision: 0.8269, recall: 0.4434, f1: 0.5773, edges-pos-ontonotes_loss: 0.0345
09/16 10:04:05 AM: Update 3167: task edges-pos-ontonotes, batch 167 (3167): mcc: 0.5869, acc: 0.3992, precision: 0.8145, recall: 0.4313, f1: 0.5639, edges-pos-ontonotes_loss: 0.0363
09/16 10:04:15 AM: Update 3188: task edges-pos-ontonotes, batch 188 (3188): mcc: 0.5799, acc: 0.3912, precision: 0.8102, recall: 0.4236, f1: 0.5563, edges-pos-ontonotes_loss: 0.0372
09/16 10:04:26 AM: Update 3210: task edges-pos-ontonotes, batch 210 (3210): mcc: 0.5738, acc: 0.3843, precision: 0.8068, recall: 0.4166, f1: 0.5495, edges-pos-ontonotes_loss: 0.0379
09/16 10:04:36 AM: Update 3244: task edges-pos-ontonotes, batch 244 (3244): mcc: 0.5724, acc: 0.3826, precision: 0.8055, recall: 0.4152, f1: 0.5479, edges-pos-ontonotes_loss: 0.0386
09/16 10:04:46 AM: Update 3267: task edges-pos-ontonotes, batch 267 (3267): mcc: 0.5706, acc: 0.3802, precision: 0.8054, recall: 0.4127, f1: 0.5457, edges-pos-ontonotes_loss: 0.0390
09/16 10:04:57 AM: Update 3290: task edges-pos-ontonotes, batch 290 (3290): mcc: 0.5703, acc: 0.3799, precision: 0.8054, recall: 0.4122, f1: 0.5453, edges-pos-ontonotes_loss: 0.0394
09/16 10:05:07 AM: Update 3314: task edges-pos-ontonotes, batch 314 (3314): mcc: 0.5711, acc: 0.3808, precision: 0.8054, recall: 0.4134, f1: 0.5463, edges-pos-ontonotes_loss: 0.0396
09/16 10:05:17 AM: Update 3336: task edges-pos-ontonotes, batch 336 (3336): mcc: 0.5698, acc: 0.3792, precision: 0.8057, recall: 0.4113, f1: 0.5446, edges-pos-ontonotes_loss: 0.0398
09/16 10:05:27 AM: Update 3363: task edges-pos-ontonotes, batch 363 (3363): mcc: 0.5711, acc: 0.3806, precision: 0.8068, recall: 0.4126, f1: 0.5460, edges-pos-ontonotes_loss: 0.0399
09/16 10:05:38 AM: Update 3388: task edges-pos-ontonotes, batch 388 (3388): mcc: 0.5724, acc: 0.3821, precision: 0.8069, recall: 0.4145, f1: 0.5477, edges-pos-ontonotes_loss: 0.0399
09/16 10:05:48 AM: Update 3412: task edges-pos-ontonotes, batch 412 (3412): mcc: 0.5726, acc: 0.3822, precision: 0.8072, recall: 0.4146, f1: 0.5478, edges-pos-ontonotes_loss: 0.0400
09/16 10:05:58 AM: Update 3437: task edges-pos-ontonotes, batch 437 (3437): mcc: 0.5728, acc: 0.3824, precision: 0.8069, recall: 0.4150, f1: 0.5481, edges-pos-ontonotes_loss: 0.0400
09/16 10:06:08 AM: Update 3460: task edges-pos-ontonotes, batch 460 (3460): mcc: 0.5738, acc: 0.3835, precision: 0.8079, recall: 0.4159, f1: 0.5492, edges-pos-ontonotes_loss: 0.0401
09/16 10:06:20 AM: Update 3461: task edges-pos-ontonotes, batch 461 (3461): mcc: 0.5734, acc: 0.3830, precision: 0.8079, recall: 0.4153, f1: 0.5486, edges-pos-ontonotes_loss: 0.0401
09/16 10:06:30 AM: Update 3520: task edges-pos-ontonotes, batch 520 (3520): mcc: 0.5763, acc: 0.3861, precision: 0.8111, recall: 0.4179, f1: 0.5516, edges-pos-ontonotes_loss: 0.0397
09/16 10:06:40 AM: Update 3553: task edges-pos-ontonotes, batch 553 (3553): mcc: 0.5792, acc: 0.3893, precision: 0.8129, recall: 0.4211, f1: 0.5548, edges-pos-ontonotes_loss: 0.0394
09/16 10:06:50 AM: Update 3582: task edges-pos-ontonotes, batch 582 (3582): mcc: 0.5817, acc: 0.3921, precision: 0.8144, recall: 0.4239, f1: 0.5576, edges-pos-ontonotes_loss: 0.0391
09/16 10:07:01 AM: Update 3608: task edges-pos-ontonotes, batch 608 (3608): mcc: 0.5827, acc: 0.3930, precision: 0.8154, recall: 0.4247, f1: 0.5585, edges-pos-ontonotes_loss: 0.0389
09/16 10:07:11 AM: Update 3638: task edges-pos-ontonotes, batch 638 (3638): mcc: 0.5844, acc: 0.3951, precision: 0.8163, recall: 0.4268, f1: 0.5605, edges-pos-ontonotes_loss: 0.0387
09/16 10:07:21 AM: Update 3668: task edges-pos-ontonotes, batch 668 (3668): mcc: 0.5860, acc: 0.3968, precision: 0.8173, recall: 0.4284, f1: 0.5622, edges-pos-ontonotes_loss: 0.0385
09/16 10:07:31 AM: Update 3694: task edges-pos-ontonotes, batch 694 (3694): mcc: 0.5869, acc: 0.3980, precision: 0.8178, recall: 0.4296, f1: 0.5632, edges-pos-ontonotes_loss: 0.0384
09/16 10:07:41 AM: Update 3720: task edges-pos-ontonotes, batch 720 (3720): mcc: 0.5883, acc: 0.3995, precision: 0.8186, recall: 0.4311, f1: 0.5648, edges-pos-ontonotes_loss: 0.0382
09/16 10:07:51 AM: Update 3751: task edges-pos-ontonotes, batch 751 (3751): mcc: 0.5896, acc: 0.4010, precision: 0.8192, recall: 0.4327, f1: 0.5663, edges-pos-ontonotes_loss: 0.0380
09/16 10:08:02 AM: Update 3775: task edges-pos-ontonotes, batch 775 (3775): mcc: 0.5901, acc: 0.4017, precision: 0.8194, recall: 0.4333, f1: 0.5669, edges-pos-ontonotes_loss: 0.0379
09/16 10:08:12 AM: Update 3803: task edges-pos-ontonotes, batch 803 (3803): mcc: 0.5916, acc: 0.4035, precision: 0.8195, recall: 0.4354, f1: 0.5687, edges-pos-ontonotes_loss: 0.0378
09/16 10:08:22 AM: Update 3829: task edges-pos-ontonotes, batch 829 (3829): mcc: 0.5928, acc: 0.4050, precision: 0.8196, recall: 0.4371, f1: 0.5702, edges-pos-ontonotes_loss: 0.0378
09/16 10:08:33 AM: Update 3854: task edges-pos-ontonotes, batch 854 (3854): mcc: 0.5937, acc: 0.4062, precision: 0.8197, recall: 0.4384, f1: 0.5712, edges-pos-ontonotes_loss: 0.0377
09/16 10:08:43 AM: Update 3889: task edges-pos-ontonotes, batch 889 (3889): mcc: 0.5951, acc: 0.4080, precision: 0.8196, recall: 0.4405, f1: 0.5730, edges-pos-ontonotes_loss: 0.0377
09/16 10:08:53 AM: Update 3931: task edges-pos-ontonotes, batch 931 (3931): mcc: 0.5971, acc: 0.4104, precision: 0.8202, recall: 0.4431, f1: 0.5754, edges-pos-ontonotes_loss: 0.0375
09/16 10:09:03 AM: Update 3956: task edges-pos-ontonotes, batch 956 (3956): mcc: 0.5983, acc: 0.4119, precision: 0.8202, recall: 0.4448, f1: 0.5768, edges-pos-ontonotes_loss: 0.0374
09/16 10:09:13 AM: Update 3983: task edges-pos-ontonotes, batch 983 (3983): mcc: 0.5996, acc: 0.4134, precision: 0.8206, recall: 0.4465, f1: 0.5783, edges-pos-ontonotes_loss: 0.0373
09/16 10:09:19 AM: ***** Step 4000 / Validation 4 *****
09/16 10:09:19 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 10:09:19 AM: Validating...
09/16 10:09:23 AM: Evaluate: task edges-pos-ontonotes, batch 13 (157): mcc: 0.7117, acc: 0.5511, precision: 0.8986, recall: 0.5708, f1: 0.6981, edges-pos-ontonotes_loss: 0.0300
09/16 10:09:34 AM: Evaluate: task edges-pos-ontonotes, batch 48 (157): mcc: 0.7006, acc: 0.5296, precision: 0.9103, recall: 0.5460, f1: 0.6826, edges-pos-ontonotes_loss: 0.0309
09/16 10:09:44 AM: Evaluate: task edges-pos-ontonotes, batch 81 (157): mcc: 0.7109, acc: 0.5439, precision: 0.9075, recall: 0.5638, f1: 0.6955, edges-pos-ontonotes_loss: 0.0300
09/16 10:09:54 AM: Evaluate: task edges-pos-ontonotes, batch 109 (157): mcc: 0.7056, acc: 0.5367, precision: 0.9063, recall: 0.5563, f1: 0.6894, edges-pos-ontonotes_loss: 0.0304
09/16 10:10:04 AM: Evaluate: task edges-pos-ontonotes, batch 132 (157): mcc: 0.6955, acc: 0.5242, precision: 0.9016, recall: 0.5436, f1: 0.6782, edges-pos-ontonotes_loss: 0.0311
09/16 10:10:14 AM: Best result seen so far for edges-pos-ontonotes.
09/16 10:10:14 AM: Best result seen so far for macro.
09/16 10:10:14 AM: Updating LR scheduler:
09/16 10:10:14 AM: 	Best result seen so far for macro_avg: 0.672
09/16 10:10:14 AM: 	# validation passes without improvement: 0
09/16 10:10:14 AM: edges-pos-ontonotes_loss: training: 0.037218 validation: 0.031534
09/16 10:10:14 AM: macro_avg: validation: 0.671991
09/16 10:10:14 AM: micro_avg: validation: 0.000000
09/16 10:10:14 AM: edges-pos-ontonotes_mcc: training: 0.600265 validation: 0.690100
09/16 10:10:14 AM: edges-pos-ontonotes_acc: training: 0.414272 validation: 0.516810
09/16 10:10:14 AM: edges-pos-ontonotes_precision: training: 0.820875 validation: 0.900309
09/16 10:10:14 AM: edges-pos-ontonotes_recall: training: 0.447338 validation: 0.536049
09/16 10:10:14 AM: edges-pos-ontonotes_f1: training: 0.579096 validation: 0.671991
09/16 10:10:14 AM: Global learning rate: 0.0001
09/16 10:10:14 AM: Saving checkpoints to: ./experiments/pos-ontonotes-multiqa-top/run
09/16 10:10:14 AM: Update 4001: task edges-pos-ontonotes, batch 1 (4001): mcc: 0.6309, acc: 0.4639, precision: 0.8293, recall: 0.4884, f1: 0.6148, edges-pos-ontonotes_loss: 0.0386
09/16 10:10:24 AM: Update 4027: task edges-pos-ontonotes, batch 27 (4027): mcc: 0.6392, acc: 0.4666, precision: 0.8202, recall: 0.5069, f1: 0.6266, edges-pos-ontonotes_loss: 0.0356
09/16 10:10:35 AM: Update 4053: task edges-pos-ontonotes, batch 53 (4053): mcc: 0.6400, acc: 0.4679, precision: 0.8228, recall: 0.5065, f1: 0.6271, edges-pos-ontonotes_loss: 0.0357
09/16 10:10:45 AM: Update 4076: task edges-pos-ontonotes, batch 76 (4076): mcc: 0.6285, acc: 0.4531, precision: 0.8203, recall: 0.4903, f1: 0.6137, edges-pos-ontonotes_loss: 0.0356
09/16 10:10:55 AM: Update 4091: task edges-pos-ontonotes, batch 91 (4091): mcc: 0.6203, acc: 0.4437, precision: 0.8143, recall: 0.4814, f1: 0.6051, edges-pos-ontonotes_loss: 0.0361
09/16 10:11:06 AM: Update 4125: task edges-pos-ontonotes, batch 125 (4125): mcc: 0.6145, acc: 0.4366, precision: 0.8112, recall: 0.4744, f1: 0.5986, edges-pos-ontonotes_loss: 0.0373
09/16 10:11:16 AM: Update 4163: task edges-pos-ontonotes, batch 163 (4163): mcc: 0.6100, acc: 0.4309, precision: 0.8088, recall: 0.4688, f1: 0.5936, edges-pos-ontonotes_loss: 0.0380
09/16 10:11:26 AM: Update 4186: task edges-pos-ontonotes, batch 186 (4186): mcc: 0.6085, acc: 0.4292, precision: 0.8079, recall: 0.4672, f1: 0.5920, edges-pos-ontonotes_loss: 0.0381
09/16 10:11:37 AM: Update 4209: task edges-pos-ontonotes, batch 209 (4209): mcc: 0.6088, acc: 0.4296, precision: 0.8076, recall: 0.4678, f1: 0.5925, edges-pos-ontonotes_loss: 0.0382
09/16 10:11:47 AM: Update 4238: task edges-pos-ontonotes, batch 238 (4238): mcc: 0.6089, acc: 0.4293, precision: 0.8079, recall: 0.4677, f1: 0.5925, edges-pos-ontonotes_loss: 0.0383
09/16 10:11:58 AM: Update 4262: task edges-pos-ontonotes, batch 262 (4262): mcc: 0.6093, acc: 0.4296, precision: 0.8085, recall: 0.4680, f1: 0.5928, edges-pos-ontonotes_loss: 0.0382
09/16 10:12:08 AM: Update 4285: task edges-pos-ontonotes, batch 285 (4285): mcc: 0.6091, acc: 0.4293, precision: 0.8080, recall: 0.4680, f1: 0.5927, edges-pos-ontonotes_loss: 0.0383
09/16 10:12:18 AM: Update 4305: task edges-pos-ontonotes, batch 305 (4305): mcc: 0.6073, acc: 0.4272, precision: 0.8075, recall: 0.4656, f1: 0.5906, edges-pos-ontonotes_loss: 0.0383
09/16 10:12:28 AM: Update 4327: task edges-pos-ontonotes, batch 327 (4327): mcc: 0.6073, acc: 0.4271, precision: 0.8077, recall: 0.4654, f1: 0.5905, edges-pos-ontonotes_loss: 0.0384
09/16 10:12:38 AM: Update 4351: task edges-pos-ontonotes, batch 351 (4351): mcc: 0.6063, acc: 0.4259, precision: 0.8078, recall: 0.4638, f1: 0.5893, edges-pos-ontonotes_loss: 0.0384
09/16 10:12:48 AM: Update 4373: task edges-pos-ontonotes, batch 373 (4373): mcc: 0.6061, acc: 0.4258, precision: 0.8076, recall: 0.4636, f1: 0.5891, edges-pos-ontonotes_loss: 0.0384
09/16 10:12:59 AM: Update 4395: task edges-pos-ontonotes, batch 395 (4395): mcc: 0.6061, acc: 0.4260, precision: 0.8079, recall: 0.4636, f1: 0.5891, edges-pos-ontonotes_loss: 0.0384
09/16 10:13:09 AM: Update 4411: task edges-pos-ontonotes, batch 411 (4411): mcc: 0.6053, acc: 0.4250, precision: 0.8070, recall: 0.4628, f1: 0.5883, edges-pos-ontonotes_loss: 0.0385
09/16 10:13:19 AM: Update 4436: task edges-pos-ontonotes, batch 436 (4436): mcc: 0.6052, acc: 0.4249, precision: 0.8066, recall: 0.4630, f1: 0.5883, edges-pos-ontonotes_loss: 0.0385
09/16 10:13:30 AM: Update 4466: task edges-pos-ontonotes, batch 466 (4466): mcc: 0.6052, acc: 0.4247, precision: 0.8065, recall: 0.4629, f1: 0.5882, edges-pos-ontonotes_loss: 0.0385
09/16 10:13:40 AM: Update 4506: task edges-pos-ontonotes, batch 506 (4506): mcc: 0.6058, acc: 0.4253, precision: 0.8066, recall: 0.4639, f1: 0.5890, edges-pos-ontonotes_loss: 0.0384
09/16 10:13:50 AM: Update 4527: task edges-pos-ontonotes, batch 527 (4527): mcc: 0.6052, acc: 0.4244, precision: 0.8065, recall: 0.4630, f1: 0.5883, edges-pos-ontonotes_loss: 0.0385
09/16 10:14:01 AM: Update 4549: task edges-pos-ontonotes, batch 549 (4549): mcc: 0.6049, acc: 0.4241, precision: 0.8063, recall: 0.4626, f1: 0.5879, edges-pos-ontonotes_loss: 0.0385
09/16 10:14:11 AM: Update 4571: task edges-pos-ontonotes, batch 571 (4571): mcc: 0.6050, acc: 0.4243, precision: 0.8062, recall: 0.4629, f1: 0.5881, edges-pos-ontonotes_loss: 0.0386
09/16 10:14:21 AM: Update 4595: task edges-pos-ontonotes, batch 595 (4595): mcc: 0.6058, acc: 0.4251, precision: 0.8066, recall: 0.4638, f1: 0.5889, edges-pos-ontonotes_loss: 0.0385
09/16 10:14:31 AM: Update 4618: task edges-pos-ontonotes, batch 618 (4618): mcc: 0.6064, acc: 0.4260, precision: 0.8067, recall: 0.4646, f1: 0.5897, edges-pos-ontonotes_loss: 0.0385
09/16 10:14:41 AM: Update 4639: task edges-pos-ontonotes, batch 639 (4639): mcc: 0.6068, acc: 0.4262, precision: 0.8070, recall: 0.4650, f1: 0.5900, edges-pos-ontonotes_loss: 0.0385
09/16 10:14:52 AM: Update 4661: task edges-pos-ontonotes, batch 661 (4661): mcc: 0.6070, acc: 0.4265, precision: 0.8071, recall: 0.4653, f1: 0.5903, edges-pos-ontonotes_loss: 0.0384
09/16 10:15:02 AM: Update 4683: task edges-pos-ontonotes, batch 683 (4683): mcc: 0.6073, acc: 0.4268, precision: 0.8074, recall: 0.4656, f1: 0.5906, edges-pos-ontonotes_loss: 0.0384
09/16 10:15:12 AM: Update 4705: task edges-pos-ontonotes, batch 705 (4705): mcc: 0.6079, acc: 0.4275, precision: 0.8075, recall: 0.4664, f1: 0.5913, edges-pos-ontonotes_loss: 0.0384
09/16 10:15:22 AM: Update 4720: task edges-pos-ontonotes, batch 720 (4720): mcc: 0.6075, acc: 0.4271, precision: 0.8072, recall: 0.4661, f1: 0.5909, edges-pos-ontonotes_loss: 0.0384
09/16 10:15:33 AM: Update 4744: task edges-pos-ontonotes, batch 744 (4744): mcc: 0.6081, acc: 0.4277, precision: 0.8076, recall: 0.4667, f1: 0.5915, edges-pos-ontonotes_loss: 0.0384
09/16 10:15:43 AM: Update 4766: task edges-pos-ontonotes, batch 766 (4766): mcc: 0.6080, acc: 0.4276, precision: 0.8075, recall: 0.4666, f1: 0.5914, edges-pos-ontonotes_loss: 0.0384
09/16 10:15:54 AM: Update 4797: task edges-pos-ontonotes, batch 797 (4797): mcc: 0.6092, acc: 0.4289, precision: 0.8081, recall: 0.4681, f1: 0.5928, edges-pos-ontonotes_loss: 0.0383
09/16 10:16:04 AM: Update 4831: task edges-pos-ontonotes, batch 831 (4831): mcc: 0.6098, acc: 0.4297, precision: 0.8084, recall: 0.4688, f1: 0.5935, edges-pos-ontonotes_loss: 0.0383
09/16 10:16:14 AM: Update 4856: task edges-pos-ontonotes, batch 856 (4856): mcc: 0.6104, acc: 0.4303, precision: 0.8088, recall: 0.4694, f1: 0.5941, edges-pos-ontonotes_loss: 0.0382
09/16 10:16:24 AM: Update 4878: task edges-pos-ontonotes, batch 878 (4878): mcc: 0.6105, acc: 0.4304, precision: 0.8089, recall: 0.4695, f1: 0.5942, edges-pos-ontonotes_loss: 0.0382
09/16 10:16:35 AM: Update 4903: task edges-pos-ontonotes, batch 903 (4903): mcc: 0.6111, acc: 0.4311, precision: 0.8091, recall: 0.4704, f1: 0.5949, edges-pos-ontonotes_loss: 0.0382
09/16 10:16:45 AM: Update 4928: task edges-pos-ontonotes, batch 928 (4928): mcc: 0.6116, acc: 0.4317, precision: 0.8094, recall: 0.4709, f1: 0.5955, edges-pos-ontonotes_loss: 0.0381
09/16 10:16:55 AM: Update 4950: task edges-pos-ontonotes, batch 950 (4950): mcc: 0.6119, acc: 0.4320, precision: 0.8096, recall: 0.4713, f1: 0.5957, edges-pos-ontonotes_loss: 0.0381
09/16 10:17:05 AM: Update 4972: task edges-pos-ontonotes, batch 972 (4972): mcc: 0.6124, acc: 0.4327, precision: 0.8098, recall: 0.4719, f1: 0.5963, edges-pos-ontonotes_loss: 0.0381
09/16 10:17:16 AM: Update 4991: task edges-pos-ontonotes, batch 991 (4991): mcc: 0.6126, acc: 0.4329, precision: 0.8099, recall: 0.4722, f1: 0.5966, edges-pos-ontonotes_loss: 0.0381
09/16 10:17:20 AM: ***** Step 5000 / Validation 5 *****
09/16 10:17:20 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 10:17:20 AM: Validating...
09/16 10:17:26 AM: Evaluate: task edges-pos-ontonotes, batch 20 (157): mcc: 0.7155, acc: 0.5537, precision: 0.9015, recall: 0.5749, f1: 0.7021, edges-pos-ontonotes_loss: 0.0301
09/16 10:17:36 AM: Evaluate: task edges-pos-ontonotes, batch 55 (157): mcc: 0.7149, acc: 0.5501, precision: 0.9079, recall: 0.5699, f1: 0.7003, edges-pos-ontonotes_loss: 0.0305
09/16 10:17:46 AM: Evaluate: task edges-pos-ontonotes, batch 86 (157): mcc: 0.7235, acc: 0.5626, precision: 0.9065, recall: 0.5843, f1: 0.7106, edges-pos-ontonotes_loss: 0.0296
09/16 10:17:56 AM: Evaluate: task edges-pos-ontonotes, batch 112 (157): mcc: 0.7201, acc: 0.5575, precision: 0.9071, recall: 0.5785, f1: 0.7065, edges-pos-ontonotes_loss: 0.0296
09/16 10:18:06 AM: Evaluate: task edges-pos-ontonotes, batch 136 (157): mcc: 0.7149, acc: 0.5513, precision: 0.9048, recall: 0.5719, f1: 0.7008, edges-pos-ontonotes_loss: 0.0298
09/16 10:18:15 AM: Best result seen so far for edges-pos-ontonotes.
09/16 10:18:15 AM: Best result seen so far for macro.
09/16 10:18:15 AM: Updating LR scheduler:
09/16 10:18:15 AM: 	Best result seen so far for macro_avg: 0.700
09/16 10:18:15 AM: 	# validation passes without improvement: 0
09/16 10:18:15 AM: edges-pos-ontonotes_loss: training: 0.038083 validation: 0.029791
09/16 10:18:15 AM: macro_avg: validation: 0.700216
09/16 10:18:15 AM: micro_avg: validation: 0.000000
09/16 10:18:15 AM: edges-pos-ontonotes_mcc: training: 0.612650 validation: 0.714566
09/16 10:18:15 AM: edges-pos-ontonotes_acc: training: 0.432940 validation: 0.550261
09/16 10:18:15 AM: edges-pos-ontonotes_precision: training: 0.809903 validation: 0.905705
09/16 10:18:15 AM: edges-pos-ontonotes_recall: training: 0.472254 validation: 0.570727
09/16 10:18:15 AM: edges-pos-ontonotes_f1: training: 0.596619 validation: 0.700216
09/16 10:18:15 AM: Global learning rate: 0.0001
09/16 10:18:15 AM: Saving checkpoints to: ./experiments/pos-ontonotes-multiqa-top/run
09/16 10:18:17 AM: Update 5005: task edges-pos-ontonotes, batch 5 (5005): mcc: 0.6526, acc: 0.4829, precision: 0.8198, recall: 0.5284, f1: 0.6426, edges-pos-ontonotes_loss: 0.0349
09/16 10:18:35 AM: Update 5026: task edges-pos-ontonotes, batch 26 (5026): mcc: 0.6317, acc: 0.4575, precision: 0.8172, recall: 0.4971, f1: 0.6182, edges-pos-ontonotes_loss: 0.0357
09/16 10:18:45 AM: Update 5050: task edges-pos-ontonotes, batch 50 (5050): mcc: 0.6329, acc: 0.4585, precision: 0.8178, recall: 0.4986, f1: 0.6195, edges-pos-ontonotes_loss: 0.0361
09/16 10:18:55 AM: Update 5071: task edges-pos-ontonotes, batch 71 (5071): mcc: 0.6334, acc: 0.4582, precision: 0.8189, recall: 0.4986, f1: 0.6198, edges-pos-ontonotes_loss: 0.0362
09/16 10:19:06 AM: Update 5095: task edges-pos-ontonotes, batch 95 (5095): mcc: 0.6338, acc: 0.4588, precision: 0.8183, recall: 0.4997, f1: 0.6205, edges-pos-ontonotes_loss: 0.0364
09/16 10:19:16 AM: Update 5117: task edges-pos-ontonotes, batch 117 (5117): mcc: 0.6331, acc: 0.4580, precision: 0.8189, recall: 0.4982, f1: 0.6195, edges-pos-ontonotes_loss: 0.0363
09/16 10:19:26 AM: Update 5137: task edges-pos-ontonotes, batch 137 (5137): mcc: 0.6319, acc: 0.4568, precision: 0.8171, recall: 0.4974, f1: 0.6184, edges-pos-ontonotes_loss: 0.0364
09/16 10:19:36 AM: Update 5161: task edges-pos-ontonotes, batch 161 (5161): mcc: 0.6336, acc: 0.4592, precision: 0.8171, recall: 0.5000, f1: 0.6204, edges-pos-ontonotes_loss: 0.0363
09/16 10:19:46 AM: Update 5185: task edges-pos-ontonotes, batch 185 (5185): mcc: 0.6338, acc: 0.4594, precision: 0.8174, recall: 0.5002, f1: 0.6206, edges-pos-ontonotes_loss: 0.0362
09/16 10:19:56 AM: Update 5208: task edges-pos-ontonotes, batch 208 (5208): mcc: 0.6328, acc: 0.4583, precision: 0.8163, recall: 0.4993, f1: 0.6196, edges-pos-ontonotes_loss: 0.0364
09/16 10:20:06 AM: Update 5229: task edges-pos-ontonotes, batch 229 (5229): mcc: 0.6327, acc: 0.4581, precision: 0.8162, recall: 0.4992, f1: 0.6195, edges-pos-ontonotes_loss: 0.0364
09/16 10:20:17 AM: Update 5252: task edges-pos-ontonotes, batch 252 (5252): mcc: 0.6324, acc: 0.4579, precision: 0.8159, recall: 0.4990, f1: 0.6192, edges-pos-ontonotes_loss: 0.0364
09/16 10:20:27 AM: Update 5274: task edges-pos-ontonotes, batch 274 (5274): mcc: 0.6321, acc: 0.4576, precision: 0.8158, recall: 0.4986, f1: 0.6189, edges-pos-ontonotes_loss: 0.0364
09/16 10:20:37 AM: Update 5297: task edges-pos-ontonotes, batch 297 (5297): mcc: 0.6326, acc: 0.4580, precision: 0.8162, recall: 0.4991, f1: 0.6194, edges-pos-ontonotes_loss: 0.0364
09/16 10:20:47 AM: Update 5330: task edges-pos-ontonotes, batch 330 (5330): mcc: 0.6319, acc: 0.4574, precision: 0.8156, recall: 0.4984, f1: 0.6187, edges-pos-ontonotes_loss: 0.0365
09/16 10:20:58 AM: Update 5348: task edges-pos-ontonotes, batch 348 (5348): mcc: 0.6289, acc: 0.4537, precision: 0.8137, recall: 0.4949, f1: 0.6155, edges-pos-ontonotes_loss: 0.0366
09/16 10:21:08 AM: Update 5374: task edges-pos-ontonotes, batch 374 (5374): mcc: 0.6302, acc: 0.4551, precision: 0.8147, recall: 0.4963, f1: 0.6168, edges-pos-ontonotes_loss: 0.0363
09/16 10:21:18 AM: Update 5400: task edges-pos-ontonotes, batch 400 (5400): mcc: 0.6317, acc: 0.4568, precision: 0.8154, recall: 0.4982, f1: 0.6185, edges-pos-ontonotes_loss: 0.0361
09/16 10:21:29 AM: Update 5425: task edges-pos-ontonotes, batch 425 (5425): mcc: 0.6322, acc: 0.4574, precision: 0.8159, recall: 0.4987, f1: 0.6190, edges-pos-ontonotes_loss: 0.0360
09/16 10:21:39 AM: Update 5450: task edges-pos-ontonotes, batch 450 (5450): mcc: 0.6335, acc: 0.4590, precision: 0.8166, recall: 0.5003, f1: 0.6205, edges-pos-ontonotes_loss: 0.0358
09/16 10:21:49 AM: Update 5477: task edges-pos-ontonotes, batch 477 (5477): mcc: 0.6348, acc: 0.4605, precision: 0.8171, recall: 0.5020, f1: 0.6219, edges-pos-ontonotes_loss: 0.0356
09/16 10:21:59 AM: Update 5502: task edges-pos-ontonotes, batch 502 (5502): mcc: 0.6356, acc: 0.4615, precision: 0.8176, recall: 0.5030, f1: 0.6228, edges-pos-ontonotes_loss: 0.0354
09/16 10:22:09 AM: Update 5528: task edges-pos-ontonotes, batch 528 (5528): mcc: 0.6367, acc: 0.4626, precision: 0.8183, recall: 0.5042, f1: 0.6239, edges-pos-ontonotes_loss: 0.0353
09/16 10:22:20 AM: Update 5554: task edges-pos-ontonotes, batch 554 (5554): mcc: 0.6376, acc: 0.4636, precision: 0.8188, recall: 0.5052, f1: 0.6249, edges-pos-ontonotes_loss: 0.0351
09/16 10:22:30 AM: Update 5577: task edges-pos-ontonotes, batch 577 (5577): mcc: 0.6376, acc: 0.4637, precision: 0.8185, recall: 0.5054, f1: 0.6250, edges-pos-ontonotes_loss: 0.0351
09/16 10:22:40 AM: Update 5598: task edges-pos-ontonotes, batch 598 (5598): mcc: 0.6371, acc: 0.4631, precision: 0.8180, recall: 0.5050, f1: 0.6245, edges-pos-ontonotes_loss: 0.0351
09/16 10:22:50 AM: Update 5625: task edges-pos-ontonotes, batch 625 (5625): mcc: 0.6377, acc: 0.4639, precision: 0.8184, recall: 0.5057, f1: 0.6251, edges-pos-ontonotes_loss: 0.0349
09/16 10:23:00 AM: Update 5649: task edges-pos-ontonotes, batch 649 (5649): mcc: 0.6374, acc: 0.4636, precision: 0.8182, recall: 0.5053, f1: 0.6248, edges-pos-ontonotes_loss: 0.0349
09/16 10:23:11 AM: Update 5693: task edges-pos-ontonotes, batch 693 (5693): mcc: 0.6400, acc: 0.4665, precision: 0.8197, recall: 0.5084, f1: 0.6276, edges-pos-ontonotes_loss: 0.0346
09/16 10:23:21 AM: Update 5735: task edges-pos-ontonotes, batch 735 (5735): mcc: 0.6430, acc: 0.4700, precision: 0.8215, recall: 0.5120, f1: 0.6308, edges-pos-ontonotes_loss: 0.0343
09/16 10:23:31 AM: Update 5763: task edges-pos-ontonotes, batch 763 (5763): mcc: 0.6450, acc: 0.4723, precision: 0.8227, recall: 0.5144, f1: 0.6330, edges-pos-ontonotes_loss: 0.0341
09/16 10:23:41 AM: Update 5794: task edges-pos-ontonotes, batch 794 (5794): mcc: 0.6471, acc: 0.4748, precision: 0.8238, recall: 0.5171, f1: 0.6354, edges-pos-ontonotes_loss: 0.0338
09/16 10:23:52 AM: Update 5822: task edges-pos-ontonotes, batch 822 (5822): mcc: 0.6491, acc: 0.4771, precision: 0.8250, recall: 0.5194, f1: 0.6375, edges-pos-ontonotes_loss: 0.0336
09/16 10:24:02 AM: Update 5850: task edges-pos-ontonotes, batch 850 (5850): mcc: 0.6508, acc: 0.4791, precision: 0.8261, recall: 0.5214, f1: 0.6393, edges-pos-ontonotes_loss: 0.0335
09/16 10:24:12 AM: Update 5879: task edges-pos-ontonotes, batch 879 (5879): mcc: 0.6524, acc: 0.4811, precision: 0.8270, recall: 0.5234, f1: 0.6411, edges-pos-ontonotes_loss: 0.0333
09/16 10:24:22 AM: Update 5906: task edges-pos-ontonotes, batch 906 (5906): mcc: 0.6540, acc: 0.4830, precision: 0.8279, recall: 0.5253, f1: 0.6428, edges-pos-ontonotes_loss: 0.0332
09/16 10:24:32 AM: Update 5936: task edges-pos-ontonotes, batch 936 (5936): mcc: 0.6556, acc: 0.4849, precision: 0.8288, recall: 0.5273, f1: 0.6445, edges-pos-ontonotes_loss: 0.0330
09/16 10:24:42 AM: Update 5964: task edges-pos-ontonotes, batch 964 (5964): mcc: 0.6571, acc: 0.4866, precision: 0.8298, recall: 0.5289, f1: 0.6460, edges-pos-ontonotes_loss: 0.0328
09/16 10:24:52 AM: Update 5986: task edges-pos-ontonotes, batch 986 (5986): mcc: 0.6577, acc: 0.4874, precision: 0.8302, recall: 0.5297, f1: 0.6467, edges-pos-ontonotes_loss: 0.0328
09/16 10:24:57 AM: ***** Step 6000 / Validation 6 *****
09/16 10:24:57 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 10:24:57 AM: Validating...
09/16 10:25:03 AM: Evaluate: task edges-pos-ontonotes, batch 17 (157): mcc: 0.7217, acc: 0.5609, precision: 0.9164, recall: 0.5751, f1: 0.7067, edges-pos-ontonotes_loss: 0.0287
09/16 10:25:13 AM: Evaluate: task edges-pos-ontonotes, batch 52 (157): mcc: 0.7209, acc: 0.5557, precision: 0.9237, recall: 0.5692, f1: 0.7043, edges-pos-ontonotes_loss: 0.0287
09/16 10:25:23 AM: Evaluate: task edges-pos-ontonotes, batch 84 (157): mcc: 0.7300, acc: 0.5694, precision: 0.9239, recall: 0.5834, f1: 0.7152, edges-pos-ontonotes_loss: 0.0279
09/16 10:25:33 AM: Evaluate: task edges-pos-ontonotes, batch 115 (157): mcc: 0.7209, acc: 0.5560, precision: 0.9229, recall: 0.5697, f1: 0.7045, edges-pos-ontonotes_loss: 0.0284
09/16 10:25:43 AM: Evaluate: task edges-pos-ontonotes, batch 144 (157): mcc: 0.7113, acc: 0.5431, precision: 0.9190, recall: 0.5573, f1: 0.6938, edges-pos-ontonotes_loss: 0.0290
09/16 10:25:48 AM: Updating LR scheduler:
09/16 10:25:48 AM: 	Best result seen so far for macro_avg: 0.700
09/16 10:25:48 AM: 	# validation passes without improvement: 1
09/16 10:25:48 AM: edges-pos-ontonotes_loss: training: 0.032691 validation: 0.029036
09/16 10:25:48 AM: macro_avg: validation: 0.692676
09/16 10:25:48 AM: micro_avg: validation: 0.000000
09/16 10:25:48 AM: edges-pos-ontonotes_mcc: training: 0.658362 validation: 0.710553
09/16 10:25:48 AM: edges-pos-ontonotes_acc: training: 0.488228 validation: 0.541520
09/16 10:25:48 AM: edges-pos-ontonotes_precision: training: 0.830549 validation: 0.920140
09/16 10:25:48 AM: edges-pos-ontonotes_recall: training: 0.530479 validation: 0.555383
09/16 10:25:48 AM: edges-pos-ontonotes_f1: training: 0.647435 validation: 0.692676
09/16 10:25:48 AM: Global learning rate: 0.0001
09/16 10:25:48 AM: Saving checkpoints to: ./experiments/pos-ontonotes-multiqa-top/run
09/16 10:25:54 AM: Update 6018: task edges-pos-ontonotes, batch 18 (6018): mcc: 0.7379, acc: 0.5892, precision: 0.8756, recall: 0.6293, f1: 0.7323, edges-pos-ontonotes_loss: 0.0270
09/16 10:26:04 AM: Update 6052: task edges-pos-ontonotes, batch 52 (6052): mcc: 0.7393, acc: 0.5930, precision: 0.8715, recall: 0.6348, f1: 0.7346, edges-pos-ontonotes_loss: 0.0265
09/16 10:26:14 AM: Update 6097: task edges-pos-ontonotes, batch 97 (6097): mcc: 0.7361, acc: 0.5901, precision: 0.8694, recall: 0.6308, f1: 0.7311, edges-pos-ontonotes_loss: 0.0266
09/16 10:26:24 AM: Update 6127: task edges-pos-ontonotes, batch 127 (6127): mcc: 0.7294, acc: 0.5806, precision: 0.8671, recall: 0.6213, f1: 0.7239, edges-pos-ontonotes_loss: 0.0271
09/16 10:26:34 AM: Update 6159: task edges-pos-ontonotes, batch 159 (6159): mcc: 0.7305, acc: 0.5816, precision: 0.8675, recall: 0.6229, f1: 0.7251, edges-pos-ontonotes_loss: 0.0270
09/16 10:26:44 AM: Update 6191: task edges-pos-ontonotes, batch 191 (6191): mcc: 0.7308, acc: 0.5818, precision: 0.8677, recall: 0.6232, f1: 0.7254, edges-pos-ontonotes_loss: 0.0269
09/16 10:26:54 AM: Update 6220: task edges-pos-ontonotes, batch 220 (6220): mcc: 0.7321, acc: 0.5831, precision: 0.8687, recall: 0.6246, f1: 0.7267, edges-pos-ontonotes_loss: 0.0269
09/16 10:27:05 AM: Update 6255: task edges-pos-ontonotes, batch 255 (6255): mcc: 0.7334, acc: 0.5848, precision: 0.8688, recall: 0.6267, f1: 0.7282, edges-pos-ontonotes_loss: 0.0267
09/16 10:27:15 AM: Update 6281: task edges-pos-ontonotes, batch 281 (6281): mcc: 0.7292, acc: 0.5790, precision: 0.8667, recall: 0.6212, f1: 0.7237, edges-pos-ontonotes_loss: 0.0268
09/16 10:27:25 AM: Update 6321: task edges-pos-ontonotes, batch 321 (6321): mcc: 0.7259, acc: 0.5747, precision: 0.8646, recall: 0.6172, f1: 0.7202, edges-pos-ontonotes_loss: 0.0272
09/16 10:27:35 AM: Update 6362: task edges-pos-ontonotes, batch 362 (6362): mcc: 0.7213, acc: 0.5689, precision: 0.8617, recall: 0.6116, f1: 0.7154, edges-pos-ontonotes_loss: 0.0274
09/16 10:27:45 AM: Update 6400: task edges-pos-ontonotes, batch 400 (6400): mcc: 0.7169, acc: 0.5636, precision: 0.8586, recall: 0.6066, f1: 0.7110, edges-pos-ontonotes_loss: 0.0276
09/16 10:27:55 AM: Update 6460: task edges-pos-ontonotes, batch 460 (6460): mcc: 0.7100, acc: 0.5548, precision: 0.8548, recall: 0.5979, f1: 0.7036, edges-pos-ontonotes_loss: 0.0280
09/16 10:28:05 AM: Update 6548: task edges-pos-ontonotes, batch 548 (6548): mcc: 0.7094, acc: 0.5541, precision: 0.8541, recall: 0.5973, f1: 0.7030, edges-pos-ontonotes_loss: 0.0278
09/16 10:28:16 AM: Update 6585: task edges-pos-ontonotes, batch 585 (6585): mcc: 0.7096, acc: 0.5544, precision: 0.8538, recall: 0.5979, f1: 0.7033, edges-pos-ontonotes_loss: 0.0279
09/16 10:28:26 AM: Update 6604: task edges-pos-ontonotes, batch 604 (6604): mcc: 0.7035, acc: 0.5467, precision: 0.8497, recall: 0.5906, f1: 0.6968, edges-pos-ontonotes_loss: 0.0281
09/16 10:28:36 AM: Update 6630: task edges-pos-ontonotes, batch 630 (6630): mcc: 0.6964, acc: 0.5376, precision: 0.8448, recall: 0.5824, f1: 0.6895, edges-pos-ontonotes_loss: 0.0286
09/16 10:28:46 AM: Update 6657: task edges-pos-ontonotes, batch 657 (6657): mcc: 0.6931, acc: 0.5335, precision: 0.8427, recall: 0.5785, f1: 0.6861, edges-pos-ontonotes_loss: 0.0288
09/16 10:28:57 AM: Update 6683: task edges-pos-ontonotes, batch 683 (6683): mcc: 0.6880, acc: 0.5270, precision: 0.8396, recall: 0.5722, f1: 0.6806, edges-pos-ontonotes_loss: 0.0292
09/16 10:29:07 AM: Update 6705: task edges-pos-ontonotes, batch 705 (6705): mcc: 0.6830, acc: 0.5208, precision: 0.8369, recall: 0.5660, f1: 0.6753, edges-pos-ontonotes_loss: 0.0295
09/16 10:29:18 AM: Update 6728: task edges-pos-ontonotes, batch 728 (6728): mcc: 0.6780, acc: 0.5146, precision: 0.8339, recall: 0.5599, f1: 0.6700, edges-pos-ontonotes_loss: 0.0298
09/16 10:29:28 AM: Update 6749: task edges-pos-ontonotes, batch 749 (6749): mcc: 0.6742, acc: 0.5098, precision: 0.8315, recall: 0.5552, f1: 0.6659, edges-pos-ontonotes_loss: 0.0300
09/16 10:29:38 AM: Update 6771: task edges-pos-ontonotes, batch 771 (6771): mcc: 0.6712, acc: 0.5060, precision: 0.8302, recall: 0.5514, f1: 0.6626, edges-pos-ontonotes_loss: 0.0302
09/16 10:29:49 AM: Update 6794: task edges-pos-ontonotes, batch 794 (6794): mcc: 0.6684, acc: 0.5025, precision: 0.8285, recall: 0.5479, f1: 0.6596, edges-pos-ontonotes_loss: 0.0304
09/16 10:29:59 AM: Update 6817: task edges-pos-ontonotes, batch 817 (6817): mcc: 0.6660, acc: 0.4996, precision: 0.8272, recall: 0.5449, f1: 0.6570, edges-pos-ontonotes_loss: 0.0306
09/16 10:30:09 AM: Update 6841: task edges-pos-ontonotes, batch 841 (6841): mcc: 0.6642, acc: 0.4973, precision: 0.8262, recall: 0.5427, f1: 0.6551, edges-pos-ontonotes_loss: 0.0308
09/16 10:30:19 AM: Update 6877: task edges-pos-ontonotes, batch 877 (6877): mcc: 0.6616, acc: 0.4942, precision: 0.8244, recall: 0.5397, f1: 0.6523, edges-pos-ontonotes_loss: 0.0310
09/16 10:30:29 AM: Update 6917: task edges-pos-ontonotes, batch 917 (6917): mcc: 0.6601, acc: 0.4924, precision: 0.8235, recall: 0.5379, f1: 0.6507, edges-pos-ontonotes_loss: 0.0312
09/16 10:30:40 AM: Update 6952: task edges-pos-ontonotes, batch 952 (6952): mcc: 0.6595, acc: 0.4916, precision: 0.8234, recall: 0.5370, f1: 0.6500, edges-pos-ontonotes_loss: 0.0313
09/16 10:30:50 AM: Update 6982: task edges-pos-ontonotes, batch 982 (6982): mcc: 0.6595, acc: 0.4915, precision: 0.8237, recall: 0.5368, f1: 0.6500, edges-pos-ontonotes_loss: 0.0313
09/16 10:30:57 AM: ***** Step 7000 / Validation 7 *****
09/16 10:30:57 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 10:30:57 AM: Validating...
09/16 10:31:00 AM: Evaluate: task edges-pos-ontonotes, batch 8 (157): mcc: 0.7495, acc: 0.6022, precision: 0.9062, recall: 0.6268, f1: 0.7410, edges-pos-ontonotes_loss: 0.0257
09/16 10:31:10 AM: Evaluate: task edges-pos-ontonotes, batch 42 (157): mcc: 0.7416, acc: 0.5871, precision: 0.9197, recall: 0.6046, f1: 0.7296, edges-pos-ontonotes_loss: 0.0264
09/16 10:31:20 AM: Evaluate: task edges-pos-ontonotes, batch 75 (157): mcc: 0.7492, acc: 0.5981, precision: 0.9196, recall: 0.6169, f1: 0.7385, edges-pos-ontonotes_loss: 0.0258
09/16 10:31:31 AM: Evaluate: task edges-pos-ontonotes, batch 104 (157): mcc: 0.7432, acc: 0.5893, precision: 0.9173, recall: 0.6089, f1: 0.7319, edges-pos-ontonotes_loss: 0.0262
09/16 10:31:41 AM: Evaluate: task edges-pos-ontonotes, batch 129 (157): mcc: 0.7319, acc: 0.5740, precision: 0.9130, recall: 0.5934, f1: 0.7193, edges-pos-ontonotes_loss: 0.0269
09/16 10:31:51 AM: Evaluate: task edges-pos-ontonotes, batch 154 (157): mcc: 0.7268, acc: 0.5665, precision: 0.9117, recall: 0.5863, f1: 0.7137, edges-pos-ontonotes_loss: 0.0273
09/16 10:31:52 AM: Best result seen so far for edges-pos-ontonotes.
09/16 10:31:52 AM: Best result seen so far for macro.
09/16 10:31:52 AM: Updating LR scheduler:
09/16 10:31:52 AM: 	Best result seen so far for macro_avg: 0.713
09/16 10:31:52 AM: 	# validation passes without improvement: 0
09/16 10:31:52 AM: edges-pos-ontonotes_loss: training: 0.031285 validation: 0.027400
09/16 10:31:52 AM: macro_avg: validation: 0.712839
09/16 10:31:52 AM: micro_avg: validation: 0.000000
09/16 10:31:52 AM: edges-pos-ontonotes_mcc: training: 0.659042 validation: 0.726192
09/16 10:31:52 AM: edges-pos-ontonotes_acc: training: 0.490977 validation: 0.565372
09/16 10:31:52 AM: edges-pos-ontonotes_precision: training: 0.823482 validation: 0.911911
09/16 10:31:52 AM: edges-pos-ontonotes_recall: training: 0.536234 validation: 0.585109
09/16 10:31:52 AM: edges-pos-ontonotes_f1: training: 0.649517 validation: 0.712839
09/16 10:31:52 AM: Global learning rate: 0.0001
09/16 10:31:52 AM: Saving checkpoints to: ./experiments/pos-ontonotes-multiqa-top/run
09/16 10:32:01 AM: Update 7024: task edges-pos-ontonotes, batch 24 (7024): mcc: 0.6645, acc: 0.4966, precision: 0.8299, recall: 0.5407, f1: 0.6548, edges-pos-ontonotes_loss: 0.0310
09/16 10:32:11 AM: Update 7055: task edges-pos-ontonotes, batch 55 (7055): mcc: 0.6761, acc: 0.5108, precision: 0.8388, recall: 0.5534, f1: 0.6668, edges-pos-ontonotes_loss: 0.0293
09/16 10:32:21 AM: Update 7084: task edges-pos-ontonotes, batch 84 (7084): mcc: 0.6670, acc: 0.4995, precision: 0.8350, recall: 0.5414, f1: 0.6569, edges-pos-ontonotes_loss: 0.0298
09/16 10:32:32 AM: Update 7115: task edges-pos-ontonotes, batch 115 (7115): mcc: 0.6715, acc: 0.5057, precision: 0.8343, recall: 0.5491, f1: 0.6623, edges-pos-ontonotes_loss: 0.0299
09/16 10:32:42 AM: Update 7144: task edges-pos-ontonotes, batch 144 (7144): mcc: 0.6711, acc: 0.5056, precision: 0.8337, recall: 0.5487, f1: 0.6618, edges-pos-ontonotes_loss: 0.0302
09/16 10:32:52 AM: Update 7194: task edges-pos-ontonotes, batch 194 (7194): mcc: 0.6742, acc: 0.5093, precision: 0.8351, recall: 0.5528, f1: 0.6652, edges-pos-ontonotes_loss: 0.0299
09/16 10:33:02 AM: Update 7236: task edges-pos-ontonotes, batch 236 (7236): mcc: 0.6705, acc: 0.5046, precision: 0.8329, recall: 0.5484, f1: 0.6613, edges-pos-ontonotes_loss: 0.0301
09/16 10:33:12 AM: Update 7261: task edges-pos-ontonotes, batch 261 (7261): mcc: 0.6701, acc: 0.5044, precision: 0.8308, recall: 0.5491, f1: 0.6612, edges-pos-ontonotes_loss: 0.0304
09/16 10:33:22 AM: Update 7287: task edges-pos-ontonotes, batch 287 (7287): mcc: 0.6697, acc: 0.5040, precision: 0.8297, recall: 0.5492, f1: 0.6609, edges-pos-ontonotes_loss: 0.0305
09/16 10:33:32 AM: Update 7313: task edges-pos-ontonotes, batch 313 (7313): mcc: 0.6704, acc: 0.5046, precision: 0.8304, recall: 0.5499, f1: 0.6616, edges-pos-ontonotes_loss: 0.0305
09/16 10:33:42 AM: Update 7336: task edges-pos-ontonotes, batch 336 (7336): mcc: 0.6681, acc: 0.5018, precision: 0.8291, recall: 0.5470, f1: 0.6592, edges-pos-ontonotes_loss: 0.0307
09/16 10:33:53 AM: Update 7363: task edges-pos-ontonotes, batch 363 (7363): mcc: 0.6680, acc: 0.5016, precision: 0.8286, recall: 0.5472, f1: 0.6591, edges-pos-ontonotes_loss: 0.0308
09/16 10:34:03 AM: Update 7388: task edges-pos-ontonotes, batch 388 (7388): mcc: 0.6687, acc: 0.5028, precision: 0.8278, recall: 0.5489, f1: 0.6601, edges-pos-ontonotes_loss: 0.0308
09/16 10:34:13 AM: Update 7414: task edges-pos-ontonotes, batch 414 (7414): mcc: 0.6689, acc: 0.5032, precision: 0.8270, recall: 0.5497, f1: 0.6604, edges-pos-ontonotes_loss: 0.0308
09/16 10:34:23 AM: Update 7440: task edges-pos-ontonotes, batch 440 (7440): mcc: 0.6679, acc: 0.5021, precision: 0.8260, recall: 0.5489, f1: 0.6595, edges-pos-ontonotes_loss: 0.0309
09/16 10:34:34 AM: Update 7465: task edges-pos-ontonotes, batch 465 (7465): mcc: 0.6676, acc: 0.5016, precision: 0.8257, recall: 0.5485, f1: 0.6591, edges-pos-ontonotes_loss: 0.0309
09/16 10:34:44 AM: Update 7491: task edges-pos-ontonotes, batch 491 (7491): mcc: 0.6679, acc: 0.5021, precision: 0.8254, recall: 0.5492, f1: 0.6596, edges-pos-ontonotes_loss: 0.0310
09/16 10:34:54 AM: Update 7517: task edges-pos-ontonotes, batch 517 (7517): mcc: 0.6687, acc: 0.5032, precision: 0.8255, recall: 0.5504, f1: 0.6605, edges-pos-ontonotes_loss: 0.0310
09/16 10:35:04 AM: Update 7546: task edges-pos-ontonotes, batch 546 (7546): mcc: 0.6691, acc: 0.5039, precision: 0.8257, recall: 0.5510, f1: 0.6610, edges-pos-ontonotes_loss: 0.0309
09/16 10:35:16 AM: Update 7547: task edges-pos-ontonotes, batch 547 (7547): mcc: 0.6682, acc: 0.5029, precision: 0.8252, recall: 0.5499, f1: 0.6600, edges-pos-ontonotes_loss: 0.0310
09/16 10:35:27 AM: Update 7574: task edges-pos-ontonotes, batch 574 (7574): mcc: 0.6642, acc: 0.4981, precision: 0.8227, recall: 0.5451, f1: 0.6557, edges-pos-ontonotes_loss: 0.0313
09/16 10:35:37 AM: Update 7596: task edges-pos-ontonotes, batch 596 (7596): mcc: 0.6617, acc: 0.4954, precision: 0.8207, recall: 0.5424, f1: 0.6531, edges-pos-ontonotes_loss: 0.0315
09/16 10:35:47 AM: Update 7617: task edges-pos-ontonotes, batch 617 (7617): mcc: 0.6594, acc: 0.4926, precision: 0.8193, recall: 0.5396, f1: 0.6507, edges-pos-ontonotes_loss: 0.0317
09/16 10:35:57 AM: Update 7640: task edges-pos-ontonotes, batch 640 (7640): mcc: 0.6586, acc: 0.4917, precision: 0.8186, recall: 0.5388, f1: 0.6498, edges-pos-ontonotes_loss: 0.0318
09/16 10:36:07 AM: Update 7661: task edges-pos-ontonotes, batch 661 (7661): mcc: 0.6575, acc: 0.4904, precision: 0.8178, recall: 0.5375, f1: 0.6487, edges-pos-ontonotes_loss: 0.0320
09/16 10:36:17 AM: Update 7688: task edges-pos-ontonotes, batch 688 (7688): mcc: 0.6557, acc: 0.4882, precision: 0.8169, recall: 0.5352, f1: 0.6467, edges-pos-ontonotes_loss: 0.0322
09/16 10:36:27 AM: Update 7714: task edges-pos-ontonotes, batch 714 (7714): mcc: 0.6553, acc: 0.4878, precision: 0.8165, recall: 0.5349, f1: 0.6464, edges-pos-ontonotes_loss: 0.0322
09/16 10:36:38 AM: Update 7740: task edges-pos-ontonotes, batch 740 (7740): mcc: 0.6554, acc: 0.4880, precision: 0.8163, recall: 0.5352, f1: 0.6465, edges-pos-ontonotes_loss: 0.0323
09/16 10:36:48 AM: Update 7764: task edges-pos-ontonotes, batch 764 (7764): mcc: 0.6555, acc: 0.4881, precision: 0.8165, recall: 0.5352, f1: 0.6466, edges-pos-ontonotes_loss: 0.0323
09/16 10:36:58 AM: Update 7789: task edges-pos-ontonotes, batch 789 (7789): mcc: 0.6555, acc: 0.4880, precision: 0.8163, recall: 0.5353, f1: 0.6466, edges-pos-ontonotes_loss: 0.0324
09/16 10:37:09 AM: Update 7811: task edges-pos-ontonotes, batch 811 (7811): mcc: 0.6544, acc: 0.4868, precision: 0.8156, recall: 0.5340, f1: 0.6454, edges-pos-ontonotes_loss: 0.0325
09/16 10:37:19 AM: Update 7834: task edges-pos-ontonotes, batch 834 (7834): mcc: 0.6538, acc: 0.4861, precision: 0.8152, recall: 0.5333, f1: 0.6448, edges-pos-ontonotes_loss: 0.0326
09/16 10:37:29 AM: Update 7856: task edges-pos-ontonotes, batch 856 (7856): mcc: 0.6532, acc: 0.4855, precision: 0.8148, recall: 0.5327, f1: 0.6442, edges-pos-ontonotes_loss: 0.0327
09/16 10:37:39 AM: Update 7875: task edges-pos-ontonotes, batch 875 (7875): mcc: 0.6521, acc: 0.4841, precision: 0.8140, recall: 0.5313, f1: 0.6430, edges-pos-ontonotes_loss: 0.0328
09/16 10:37:50 AM: Update 7909: task edges-pos-ontonotes, batch 909 (7909): mcc: 0.6508, acc: 0.4826, precision: 0.8131, recall: 0.5299, f1: 0.6417, edges-pos-ontonotes_loss: 0.0329
09/16 10:38:00 AM: Update 7933: task edges-pos-ontonotes, batch 933 (7933): mcc: 0.6507, acc: 0.4825, precision: 0.8129, recall: 0.5299, f1: 0.6416, edges-pos-ontonotes_loss: 0.0330
09/16 10:38:10 AM: Update 7954: task edges-pos-ontonotes, batch 954 (7954): mcc: 0.6504, acc: 0.4822, precision: 0.8127, recall: 0.5296, f1: 0.6413, edges-pos-ontonotes_loss: 0.0331
09/16 10:38:20 AM: Update 7978: task edges-pos-ontonotes, batch 978 (7978): mcc: 0.6503, acc: 0.4820, precision: 0.8126, recall: 0.5295, f1: 0.6411, edges-pos-ontonotes_loss: 0.0331
09/16 10:38:31 AM: Update 7998: task edges-pos-ontonotes, batch 998 (7998): mcc: 0.6502, acc: 0.4818, precision: 0.8126, recall: 0.5293, f1: 0.6410, edges-pos-ontonotes_loss: 0.0331
09/16 10:38:32 AM: ***** Step 8000 / Validation 8 *****
09/16 10:38:32 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 10:38:32 AM: Validating...
09/16 10:38:41 AM: Evaluate: task edges-pos-ontonotes, batch 31 (157): mcc: 0.7430, acc: 0.5907, precision: 0.9118, recall: 0.6122, f1: 0.7325, edges-pos-ontonotes_loss: 0.0265
09/16 10:38:51 AM: Evaluate: task edges-pos-ontonotes, batch 64 (157): mcc: 0.7473, acc: 0.5955, precision: 0.9168, recall: 0.6158, f1: 0.7367, edges-pos-ontonotes_loss: 0.0261
09/16 10:39:01 AM: Evaluate: task edges-pos-ontonotes, batch 94 (157): mcc: 0.7501, acc: 0.5999, precision: 0.9159, recall: 0.6209, f1: 0.7401, edges-pos-ontonotes_loss: 0.0259
09/16 10:39:11 AM: Evaluate: task edges-pos-ontonotes, batch 120 (157): mcc: 0.7452, acc: 0.5930, precision: 0.9158, recall: 0.6130, f1: 0.7344, edges-pos-ontonotes_loss: 0.0261
09/16 10:39:22 AM: Evaluate: task edges-pos-ontonotes, batch 145 (157): mcc: 0.7377, acc: 0.5827, precision: 0.9138, recall: 0.6023, f1: 0.7260, edges-pos-ontonotes_loss: 0.0265
09/16 10:39:26 AM: Best result seen so far for edges-pos-ontonotes.
09/16 10:39:26 AM: Best result seen so far for macro.
09/16 10:39:26 AM: Updating LR scheduler:
09/16 10:39:26 AM: 	Best result seen so far for macro_avg: 0.726
09/16 10:39:26 AM: 	# validation passes without improvement: 0
09/16 10:39:26 AM: edges-pos-ontonotes_loss: training: 0.033140 validation: 0.026506
09/16 10:39:26 AM: macro_avg: validation: 0.726236
09/16 10:39:26 AM: micro_avg: validation: 0.000000
09/16 10:39:26 AM: edges-pos-ontonotes_mcc: training: 0.650201 validation: 0.738060
09/16 10:39:26 AM: edges-pos-ontonotes_acc: training: 0.481843 validation: 0.582770
09/16 10:39:26 AM: edges-pos-ontonotes_precision: training: 0.812626 validation: 0.915041
09/16 10:39:26 AM: edges-pos-ontonotes_recall: training: 0.529281 validation: 0.602019
09/16 10:39:26 AM: edges-pos-ontonotes_f1: training: 0.641039 validation: 0.726236
09/16 10:39:26 AM: Global learning rate: 0.0001
09/16 10:39:26 AM: Saving checkpoints to: ./experiments/pos-ontonotes-multiqa-top/run
09/16 10:39:32 AM: Update 8013: task edges-pos-ontonotes, batch 13 (8013): mcc: 0.6513, acc: 0.4842, precision: 0.8061, recall: 0.5355, f1: 0.6435, edges-pos-ontonotes_loss: 0.0352
09/16 10:39:42 AM: Update 8036: task edges-pos-ontonotes, batch 36 (8036): mcc: 0.6479, acc: 0.4782, precision: 0.8125, recall: 0.5257, f1: 0.6384, edges-pos-ontonotes_loss: 0.0346
09/16 10:39:53 AM: Update 8057: task edges-pos-ontonotes, batch 57 (8057): mcc: 0.6473, acc: 0.4783, precision: 0.8093, recall: 0.5269, f1: 0.6382, edges-pos-ontonotes_loss: 0.0349
09/16 10:40:03 AM: Update 8083: task edges-pos-ontonotes, batch 83 (8083): mcc: 0.6464, acc: 0.4778, precision: 0.8087, recall: 0.5259, f1: 0.6373, edges-pos-ontonotes_loss: 0.0349
09/16 10:40:13 AM: Update 8115: task edges-pos-ontonotes, batch 115 (8115): mcc: 0.6447, acc: 0.4756, precision: 0.8072, recall: 0.5240, f1: 0.6355, edges-pos-ontonotes_loss: 0.0351
09/16 10:40:23 AM: Update 8137: task edges-pos-ontonotes, batch 137 (8137): mcc: 0.6434, acc: 0.4743, precision: 0.8063, recall: 0.5226, f1: 0.6342, edges-pos-ontonotes_loss: 0.0351
09/16 10:40:34 AM: Update 8159: task edges-pos-ontonotes, batch 159 (8159): mcc: 0.6454, acc: 0.4767, precision: 0.8078, recall: 0.5248, f1: 0.6363, edges-pos-ontonotes_loss: 0.0349
09/16 10:40:44 AM: Update 8174: task edges-pos-ontonotes, batch 174 (8174): mcc: 0.6425, acc: 0.4733, precision: 0.8063, recall: 0.5211, f1: 0.6331, edges-pos-ontonotes_loss: 0.0351
09/16 10:40:54 AM: Update 8195: task edges-pos-ontonotes, batch 195 (8195): mcc: 0.6427, acc: 0.4735, precision: 0.8064, recall: 0.5213, f1: 0.6333, edges-pos-ontonotes_loss: 0.0352
09/16 10:41:05 AM: Update 8232: task edges-pos-ontonotes, batch 232 (8232): mcc: 0.6424, acc: 0.4731, precision: 0.8068, recall: 0.5206, f1: 0.6328, edges-pos-ontonotes_loss: 0.0353
09/16 10:41:15 AM: Update 8269: task edges-pos-ontonotes, batch 269 (8269): mcc: 0.6438, acc: 0.4747, precision: 0.8078, recall: 0.5223, f1: 0.6344, edges-pos-ontonotes_loss: 0.0351
09/16 10:41:25 AM: Update 8308: task edges-pos-ontonotes, batch 308 (8308): mcc: 0.6453, acc: 0.4764, precision: 0.8087, recall: 0.5240, f1: 0.6360, edges-pos-ontonotes_loss: 0.0351
09/16 10:41:36 AM: Update 8338: task edges-pos-ontonotes, batch 338 (8338): mcc: 0.6453, acc: 0.4764, precision: 0.8090, recall: 0.5239, f1: 0.6360, edges-pos-ontonotes_loss: 0.0351
09/16 10:41:46 AM: Update 8363: task edges-pos-ontonotes, batch 363 (8363): mcc: 0.6460, acc: 0.4774, precision: 0.8093, recall: 0.5247, f1: 0.6367, edges-pos-ontonotes_loss: 0.0349
09/16 10:41:56 AM: Update 8387: task edges-pos-ontonotes, batch 387 (8387): mcc: 0.6471, acc: 0.4785, precision: 0.8102, recall: 0.5259, f1: 0.6378, edges-pos-ontonotes_loss: 0.0348
09/16 10:42:06 AM: Update 8410: task edges-pos-ontonotes, batch 410 (8410): mcc: 0.6471, acc: 0.4786, precision: 0.8103, recall: 0.5259, f1: 0.6379, edges-pos-ontonotes_loss: 0.0349
09/16 10:42:17 AM: Update 8436: task edges-pos-ontonotes, batch 436 (8436): mcc: 0.6480, acc: 0.4796, precision: 0.8109, recall: 0.5270, f1: 0.6388, edges-pos-ontonotes_loss: 0.0348
09/16 10:42:27 AM: Update 8459: task edges-pos-ontonotes, batch 459 (8459): mcc: 0.6486, acc: 0.4803, precision: 0.8113, recall: 0.5276, f1: 0.6394, edges-pos-ontonotes_loss: 0.0348
09/16 10:42:37 AM: Update 8481: task edges-pos-ontonotes, batch 481 (8481): mcc: 0.6493, acc: 0.4810, precision: 0.8120, recall: 0.5283, f1: 0.6401, edges-pos-ontonotes_loss: 0.0348
09/16 10:42:47 AM: Update 8497: task edges-pos-ontonotes, batch 497 (8497): mcc: 0.6487, acc: 0.4803, precision: 0.8116, recall: 0.5276, f1: 0.6394, edges-pos-ontonotes_loss: 0.0348
09/16 10:42:58 AM: Update 8518: task edges-pos-ontonotes, batch 518 (8518): mcc: 0.6484, acc: 0.4800, precision: 0.8113, recall: 0.5273, f1: 0.6391, edges-pos-ontonotes_loss: 0.0349
09/16 10:43:08 AM: Update 8552: task edges-pos-ontonotes, batch 552 (8552): mcc: 0.6490, acc: 0.4807, precision: 0.8116, recall: 0.5281, f1: 0.6399, edges-pos-ontonotes_loss: 0.0348
09/16 10:43:18 AM: Update 8587: task edges-pos-ontonotes, batch 587 (8587): mcc: 0.6494, acc: 0.4812, precision: 0.8117, recall: 0.5286, f1: 0.6402, edges-pos-ontonotes_loss: 0.0348
09/16 10:43:28 AM: Update 8608: task edges-pos-ontonotes, batch 608 (8608): mcc: 0.6495, acc: 0.4813, precision: 0.8117, recall: 0.5288, f1: 0.6404, edges-pos-ontonotes_loss: 0.0348
09/16 10:43:38 AM: Update 8631: task edges-pos-ontonotes, batch 631 (8631): mcc: 0.6501, acc: 0.4820, precision: 0.8120, recall: 0.5296, f1: 0.6410, edges-pos-ontonotes_loss: 0.0347
09/16 10:43:49 AM: Update 8652: task edges-pos-ontonotes, batch 652 (8652): mcc: 0.6503, acc: 0.4823, precision: 0.8120, recall: 0.5299, f1: 0.6413, edges-pos-ontonotes_loss: 0.0347
09/16 10:43:59 AM: Update 8675: task edges-pos-ontonotes, batch 675 (8675): mcc: 0.6508, acc: 0.4828, precision: 0.8121, recall: 0.5306, f1: 0.6418, edges-pos-ontonotes_loss: 0.0347
09/16 10:44:09 AM: Update 8698: task edges-pos-ontonotes, batch 698 (8698): mcc: 0.6514, acc: 0.4836, precision: 0.8123, recall: 0.5314, f1: 0.6425, edges-pos-ontonotes_loss: 0.0346
09/16 10:44:19 AM: Update 8722: task edges-pos-ontonotes, batch 722 (8722): mcc: 0.6519, acc: 0.4841, precision: 0.8127, recall: 0.5320, f1: 0.6430, edges-pos-ontonotes_loss: 0.0346
09/16 10:44:30 AM: Update 8747: task edges-pos-ontonotes, batch 747 (8747): mcc: 0.6522, acc: 0.4846, precision: 0.8128, recall: 0.5324, f1: 0.6434, edges-pos-ontonotes_loss: 0.0346
09/16 10:44:40 AM: Update 8768: task edges-pos-ontonotes, batch 768 (8768): mcc: 0.6522, acc: 0.4845, precision: 0.8129, recall: 0.5323, f1: 0.6433, edges-pos-ontonotes_loss: 0.0346
09/16 10:44:50 AM: Update 8790: task edges-pos-ontonotes, batch 790 (8790): mcc: 0.6521, acc: 0.4844, precision: 0.8131, recall: 0.5320, f1: 0.6432, edges-pos-ontonotes_loss: 0.0346
09/16 10:45:01 AM: Update 8805: task edges-pos-ontonotes, batch 805 (8805): mcc: 0.6513, acc: 0.4835, precision: 0.8126, recall: 0.5311, f1: 0.6424, edges-pos-ontonotes_loss: 0.0346
09/16 10:45:11 AM: Update 8829: task edges-pos-ontonotes, batch 829 (8829): mcc: 0.6515, acc: 0.4836, precision: 0.8128, recall: 0.5312, f1: 0.6425, edges-pos-ontonotes_loss: 0.0345
09/16 10:45:21 AM: Update 8854: task edges-pos-ontonotes, batch 854 (8854): mcc: 0.6521, acc: 0.4844, precision: 0.8131, recall: 0.5320, f1: 0.6432, edges-pos-ontonotes_loss: 0.0344
09/16 10:45:31 AM: Update 8887: task edges-pos-ontonotes, batch 887 (8887): mcc: 0.6517, acc: 0.4839, precision: 0.8131, recall: 0.5314, f1: 0.6428, edges-pos-ontonotes_loss: 0.0343
09/16 10:45:42 AM: Update 8927: task edges-pos-ontonotes, batch 927 (8927): mcc: 0.6530, acc: 0.4855, precision: 0.8138, recall: 0.5330, f1: 0.6442, edges-pos-ontonotes_loss: 0.0341
09/16 10:45:52 AM: Update 8950: task edges-pos-ontonotes, batch 950 (8950): mcc: 0.6528, acc: 0.4852, precision: 0.8137, recall: 0.5327, f1: 0.6439, edges-pos-ontonotes_loss: 0.0341
09/16 10:46:02 AM: Update 8974: task edges-pos-ontonotes, batch 974 (8974): mcc: 0.6532, acc: 0.4857, precision: 0.8139, recall: 0.5333, f1: 0.6444, edges-pos-ontonotes_loss: 0.0340
09/16 10:46:11 AM: ***** Step 9000 / Validation 9 *****
09/16 10:46:11 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 10:46:11 AM: Validating...
09/16 10:46:12 AM: Evaluate: task edges-pos-ontonotes, batch 3 (157): mcc: 0.7680, acc: 0.6260, precision: 0.9230, recall: 0.6455, f1: 0.7597, edges-pos-ontonotes_loss: 0.0239
09/16 10:46:22 AM: Evaluate: task edges-pos-ontonotes, batch 38 (157): mcc: 0.7401, acc: 0.5854, precision: 0.9197, recall: 0.6022, f1: 0.7278, edges-pos-ontonotes_loss: 0.0265
09/16 10:46:33 AM: Evaluate: task edges-pos-ontonotes, batch 68 (157): mcc: 0.7448, acc: 0.5912, precision: 0.9226, recall: 0.6078, f1: 0.7328, edges-pos-ontonotes_loss: 0.0262
09/16 10:46:43 AM: Evaluate: task edges-pos-ontonotes, batch 95 (157): mcc: 0.7474, acc: 0.5956, precision: 0.9213, recall: 0.6128, f1: 0.7361, edges-pos-ontonotes_loss: 0.0259
09/16 10:46:53 AM: Evaluate: task edges-pos-ontonotes, batch 118 (157): mcc: 0.7442, acc: 0.5914, precision: 0.9198, recall: 0.6087, f1: 0.7326, edges-pos-ontonotes_loss: 0.0260
09/16 10:47:03 AM: Evaluate: task edges-pos-ontonotes, batch 141 (157): mcc: 0.7389, acc: 0.5846, precision: 0.9160, recall: 0.6027, f1: 0.7270, edges-pos-ontonotes_loss: 0.0263
09/16 10:47:10 AM: Best result seen so far for edges-pos-ontonotes.
09/16 10:47:10 AM: Best result seen so far for macro.
09/16 10:47:10 AM: Updating LR scheduler:
09/16 10:47:10 AM: 	Best result seen so far for macro_avg: 0.727
09/16 10:47:10 AM: 	# validation passes without improvement: 0
09/16 10:47:10 AM: edges-pos-ontonotes_loss: training: 0.033898 validation: 0.026249
09/16 10:47:10 AM: macro_avg: validation: 0.727260
09/16 10:47:10 AM: micro_avg: validation: 0.000000
09/16 10:47:10 AM: edges-pos-ontonotes_mcc: training: 0.653576 validation: 0.739292
09/16 10:47:10 AM: edges-pos-ontonotes_acc: training: 0.486071 validation: 0.584347
09/16 10:47:10 AM: edges-pos-ontonotes_precision: training: 0.814150 validation: 0.917462
09/16 10:47:10 AM: edges-pos-ontonotes_recall: training: 0.533689 validation: 0.602379
09/16 10:47:10 AM: edges-pos-ontonotes_f1: training: 0.644740 validation: 0.727260
09/16 10:47:10 AM: Global learning rate: 0.0001
09/16 10:47:10 AM: Saving checkpoints to: ./experiments/pos-ontonotes-multiqa-top/run
09/16 10:47:13 AM: Update 9010: task edges-pos-ontonotes, batch 10 (9010): mcc: 0.7024, acc: 0.5392, precision: 0.8372, recall: 0.5978, f1: 0.6975, edges-pos-ontonotes_loss: 0.0295
09/16 10:47:24 AM: Update 9035: task edges-pos-ontonotes, batch 35 (9035): mcc: 0.6820, acc: 0.5180, precision: 0.8276, recall: 0.5708, f1: 0.6756, edges-pos-ontonotes_loss: 0.0304
09/16 10:47:34 AM: Update 9060: task edges-pos-ontonotes, batch 60 (9060): mcc: 0.6765, acc: 0.5122, precision: 0.8234, recall: 0.5648, f1: 0.6700, edges-pos-ontonotes_loss: 0.0300
09/16 10:47:44 AM: Update 9087: task edges-pos-ontonotes, batch 87 (9087): mcc: 0.6823, acc: 0.5206, precision: 0.8272, recall: 0.5716, f1: 0.6761, edges-pos-ontonotes_loss: 0.0297
09/16 10:48:04 AM: Update 9112: task edges-pos-ontonotes, batch 112 (9112): mcc: 0.6743, acc: 0.5109, precision: 0.8222, recall: 0.5619, f1: 0.6676, edges-pos-ontonotes_loss: 0.0303
09/16 10:48:15 AM: Update 9154: task edges-pos-ontonotes, batch 154 (9154): mcc: 0.6874, acc: 0.5260, precision: 0.8297, recall: 0.5782, f1: 0.6815, edges-pos-ontonotes_loss: 0.0294
09/16 10:48:25 AM: Update 9184: task edges-pos-ontonotes, batch 184 (9184): mcc: 0.6945, acc: 0.5348, precision: 0.8342, recall: 0.5868, f1: 0.6890, edges-pos-ontonotes_loss: 0.0289
09/16 10:48:35 AM: Update 9213: task edges-pos-ontonotes, batch 213 (9213): mcc: 0.7002, acc: 0.5417, precision: 0.8377, recall: 0.5937, f1: 0.6949, edges-pos-ontonotes_loss: 0.0285
09/16 10:48:45 AM: Update 9244: task edges-pos-ontonotes, batch 244 (9244): mcc: 0.7044, acc: 0.5468, precision: 0.8402, recall: 0.5991, f1: 0.6994, edges-pos-ontonotes_loss: 0.0282
09/16 10:48:56 AM: Update 9274: task edges-pos-ontonotes, batch 274 (9274): mcc: 0.7084, acc: 0.5518, precision: 0.8425, recall: 0.6041, f1: 0.7036, edges-pos-ontonotes_loss: 0.0280
09/16 10:49:06 AM: Update 9302: task edges-pos-ontonotes, batch 302 (9302): mcc: 0.7106, acc: 0.5546, precision: 0.8436, recall: 0.6070, f1: 0.7060, edges-pos-ontonotes_loss: 0.0279
09/16 10:49:16 AM: Update 9330: task edges-pos-ontonotes, batch 330 (9330): mcc: 0.7132, acc: 0.5578, precision: 0.8453, recall: 0.6101, f1: 0.7087, edges-pos-ontonotes_loss: 0.0278
09/16 10:49:26 AM: Update 9357: task edges-pos-ontonotes, batch 357 (9357): mcc: 0.7150, acc: 0.5598, precision: 0.8468, recall: 0.6119, f1: 0.7105, edges-pos-ontonotes_loss: 0.0277
09/16 10:49:37 AM: Update 9384: task edges-pos-ontonotes, batch 384 (9384): mcc: 0.7164, acc: 0.5616, precision: 0.8479, recall: 0.6136, f1: 0.7119, edges-pos-ontonotes_loss: 0.0276
09/16 10:49:47 AM: Update 9410: task edges-pos-ontonotes, batch 410 (9410): mcc: 0.7181, acc: 0.5637, precision: 0.8485, recall: 0.6159, f1: 0.7137, edges-pos-ontonotes_loss: 0.0275
09/16 10:49:57 AM: Update 9433: task edges-pos-ontonotes, batch 433 (9433): mcc: 0.7177, acc: 0.5631, precision: 0.8484, recall: 0.6153, f1: 0.7133, edges-pos-ontonotes_loss: 0.0275
09/16 10:50:07 AM: Update 9466: task edges-pos-ontonotes, batch 466 (9466): mcc: 0.7191, acc: 0.5653, precision: 0.8496, recall: 0.6169, f1: 0.7148, edges-pos-ontonotes_loss: 0.0274
09/16 10:50:17 AM: Update 9506: task edges-pos-ontonotes, batch 506 (9506): mcc: 0.7206, acc: 0.5672, precision: 0.8506, recall: 0.6187, f1: 0.7163, edges-pos-ontonotes_loss: 0.0273
09/16 10:50:27 AM: Update 9574: task edges-pos-ontonotes, batch 574 (9574): mcc: 0.7235, acc: 0.5712, precision: 0.8522, recall: 0.6223, f1: 0.7194, edges-pos-ontonotes_loss: 0.0271
09/16 10:50:38 AM: Update 9619: task edges-pos-ontonotes, batch 619 (9619): mcc: 0.7252, acc: 0.5736, precision: 0.8530, recall: 0.6246, f1: 0.7212, edges-pos-ontonotes_loss: 0.0269
09/16 10:50:48 AM: Update 9654: task edges-pos-ontonotes, batch 654 (9654): mcc: 0.7268, acc: 0.5757, precision: 0.8540, recall: 0.6266, f1: 0.7228, edges-pos-ontonotes_loss: 0.0267
09/16 10:50:58 AM: Update 9688: task edges-pos-ontonotes, batch 688 (9688): mcc: 0.7281, acc: 0.5774, precision: 0.8548, recall: 0.6281, f1: 0.7241, edges-pos-ontonotes_loss: 0.0266
09/16 10:51:08 AM: Update 9722: task edges-pos-ontonotes, batch 722 (9722): mcc: 0.7287, acc: 0.5784, precision: 0.8551, recall: 0.6290, f1: 0.7248, edges-pos-ontonotes_loss: 0.0265
09/16 10:51:18 AM: Update 9749: task edges-pos-ontonotes, batch 749 (9749): mcc: 0.7277, acc: 0.5773, precision: 0.8546, recall: 0.6277, f1: 0.7238, edges-pos-ontonotes_loss: 0.0265
09/16 10:51:29 AM: Update 9786: task edges-pos-ontonotes, batch 786 (9786): mcc: 0.7266, acc: 0.5760, precision: 0.8539, recall: 0.6264, f1: 0.7227, edges-pos-ontonotes_loss: 0.0266
09/16 10:51:39 AM: Update 9827: task edges-pos-ontonotes, batch 827 (9827): mcc: 0.7268, acc: 0.5764, precision: 0.8539, recall: 0.6267, f1: 0.7229, edges-pos-ontonotes_loss: 0.0266
09/16 10:51:49 AM: Update 9864: task edges-pos-ontonotes, batch 864 (9864): mcc: 0.7264, acc: 0.5758, precision: 0.8534, recall: 0.6263, f1: 0.7224, edges-pos-ontonotes_loss: 0.0267
09/16 10:51:59 AM: Update 9899: task edges-pos-ontonotes, batch 899 (9899): mcc: 0.7249, acc: 0.5741, precision: 0.8525, recall: 0.6246, f1: 0.7209, edges-pos-ontonotes_loss: 0.0268
09/16 10:52:09 AM: Update 9944: task edges-pos-ontonotes, batch 944 (9944): mcc: 0.7251, acc: 0.5742, precision: 0.8526, recall: 0.6247, f1: 0.7211, edges-pos-ontonotes_loss: 0.0266
09/16 10:52:19 AM: Update 9982: task edges-pos-ontonotes, batch 982 (9982): mcc: 0.7243, acc: 0.5733, precision: 0.8521, recall: 0.6239, f1: 0.7203, edges-pos-ontonotes_loss: 0.0267
09/16 10:52:24 AM: ***** Step 10000 / Validation 10 *****
09/16 10:52:24 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 10:52:24 AM: Validating...
09/16 10:52:30 AM: Evaluate: task edges-pos-ontonotes, batch 18 (157): mcc: 0.7462, acc: 0.5989, precision: 0.9018, recall: 0.6243, f1: 0.7378, edges-pos-ontonotes_loss: 0.0260
09/16 10:52:40 AM: Evaluate: task edges-pos-ontonotes, batch 50 (157): mcc: 0.7526, acc: 0.6057, precision: 0.9121, recall: 0.6277, f1: 0.7437, edges-pos-ontonotes_loss: 0.0255
09/16 10:52:50 AM: Evaluate: task edges-pos-ontonotes, batch 93 (157): mcc: 0.7570, acc: 0.6130, precision: 0.9094, recall: 0.6369, f1: 0.7492, edges-pos-ontonotes_loss: 0.0250
09/16 10:53:00 AM: Evaluate: task edges-pos-ontonotes, batch 120 (157): mcc: 0.7470, acc: 0.5986, precision: 0.9042, recall: 0.6240, f1: 0.7384, edges-pos-ontonotes_loss: 0.0256
09/16 10:53:10 AM: Evaluate: task edges-pos-ontonotes, batch 143 (157): mcc: 0.7371, acc: 0.5844, precision: 0.8980, recall: 0.6121, f1: 0.7280, edges-pos-ontonotes_loss: 0.0262
09/16 10:53:16 AM: Best result seen so far for edges-pos-ontonotes.
09/16 10:53:16 AM: Best result seen so far for macro.
09/16 10:53:16 AM: Updating LR scheduler:
09/16 10:53:16 AM: 	Best result seen so far for macro_avg: 0.728
09/16 10:53:16 AM: 	# validation passes without improvement: 0
09/16 10:53:16 AM: edges-pos-ontonotes_loss: training: 0.026628 validation: 0.026309
09/16 10:53:16 AM: macro_avg: validation: 0.727754
09/16 10:53:16 AM: micro_avg: validation: 0.000000
09/16 10:53:16 AM: edges-pos-ontonotes_mcc: training: 0.724305 validation: 0.737098
09/16 10:53:16 AM: edges-pos-ontonotes_acc: training: 0.573307 validation: 0.583839
09/16 10:53:16 AM: edges-pos-ontonotes_precision: training: 0.852007 validation: 0.899340
09/16 10:53:16 AM: edges-pos-ontonotes_recall: training: 0.623854 validation: 0.611152
09/16 10:53:16 AM: edges-pos-ontonotes_f1: training: 0.720296 validation: 0.727754
09/16 10:53:16 AM: Global learning rate: 0.0001
09/16 10:53:16 AM: Saving checkpoints to: ./experiments/pos-ontonotes-multiqa-top/run
09/16 10:53:21 AM: Update 10019: task edges-pos-ontonotes, batch 19 (10019): mcc: 0.6754, acc: 0.5131, precision: 0.8257, recall: 0.5612, f1: 0.6682, edges-pos-ontonotes_loss: 0.0291
09/16 10:53:32 AM: Update 10051: task edges-pos-ontonotes, batch 51 (10051): mcc: 0.6667, acc: 0.5049, precision: 0.8160, recall: 0.5537, f1: 0.6597, edges-pos-ontonotes_loss: 0.0289
09/16 10:53:43 AM: Update 10071: task edges-pos-ontonotes, batch 71 (10071): mcc: 0.6318, acc: 0.4624, precision: 0.7890, recall: 0.5155, f1: 0.6236, edges-pos-ontonotes_loss: 0.0316
09/16 10:53:53 AM: Update 10093: task edges-pos-ontonotes, batch 93 (10093): mcc: 0.6359, acc: 0.4665, precision: 0.7926, recall: 0.5197, f1: 0.6277, edges-pos-ontonotes_loss: 0.0325
09/16 10:54:04 AM: Update 10116: task edges-pos-ontonotes, batch 116 (10116): mcc: 0.6367, acc: 0.4665, precision: 0.7949, recall: 0.5195, f1: 0.6284, edges-pos-ontonotes_loss: 0.0330
09/16 10:54:14 AM: Update 10140: task edges-pos-ontonotes, batch 140 (10140): mcc: 0.6382, acc: 0.4682, precision: 0.7963, recall: 0.5210, f1: 0.6298, edges-pos-ontonotes_loss: 0.0334
09/16 10:54:24 AM: Update 10163: task edges-pos-ontonotes, batch 163 (10163): mcc: 0.6381, acc: 0.4679, precision: 0.7963, recall: 0.5207, f1: 0.6297, edges-pos-ontonotes_loss: 0.0336
09/16 10:54:34 AM: Update 10187: task edges-pos-ontonotes, batch 187 (10187): mcc: 0.6371, acc: 0.4667, precision: 0.7960, recall: 0.5194, f1: 0.6286, edges-pos-ontonotes_loss: 0.0339
09/16 10:54:44 AM: Update 10212: task edges-pos-ontonotes, batch 212 (10212): mcc: 0.6367, acc: 0.4662, precision: 0.7958, recall: 0.5188, f1: 0.6281, edges-pos-ontonotes_loss: 0.0340
09/16 10:54:54 AM: Update 10237: task edges-pos-ontonotes, batch 237 (10237): mcc: 0.6376, acc: 0.4672, precision: 0.7960, recall: 0.5201, f1: 0.6291, edges-pos-ontonotes_loss: 0.0342
09/16 10:55:05 AM: Update 10265: task edges-pos-ontonotes, batch 265 (10265): mcc: 0.6389, acc: 0.4686, precision: 0.7968, recall: 0.5216, f1: 0.6305, edges-pos-ontonotes_loss: 0.0342
09/16 10:55:15 AM: Update 10305: task edges-pos-ontonotes, batch 305 (10305): mcc: 0.6386, acc: 0.4679, precision: 0.7974, recall: 0.5208, f1: 0.6301, edges-pos-ontonotes_loss: 0.0344
09/16 10:55:25 AM: Update 10338: task edges-pos-ontonotes, batch 338 (10338): mcc: 0.6393, acc: 0.4689, precision: 0.7975, recall: 0.5219, f1: 0.6309, edges-pos-ontonotes_loss: 0.0344
09/16 10:55:35 AM: Update 10362: task edges-pos-ontonotes, batch 362 (10362): mcc: 0.6392, acc: 0.4688, precision: 0.7979, recall: 0.5215, f1: 0.6308, edges-pos-ontonotes_loss: 0.0345
09/16 10:55:46 AM: Update 10381: task edges-pos-ontonotes, batch 381 (10381): mcc: 0.6394, acc: 0.4689, precision: 0.7983, recall: 0.5215, f1: 0.6309, edges-pos-ontonotes_loss: 0.0346
09/16 10:55:56 AM: Update 10407: task edges-pos-ontonotes, batch 407 (10407): mcc: 0.6402, acc: 0.4698, precision: 0.7995, recall: 0.5220, f1: 0.6316, edges-pos-ontonotes_loss: 0.0344
09/16 10:56:06 AM: Update 10438: task edges-pos-ontonotes, batch 438 (10438): mcc: 0.6423, acc: 0.4722, precision: 0.8012, recall: 0.5243, f1: 0.6338, edges-pos-ontonotes_loss: 0.0340
09/16 10:56:17 AM: Update 10469: task edges-pos-ontonotes, batch 469 (10469): mcc: 0.6450, acc: 0.4755, precision: 0.8030, recall: 0.5274, f1: 0.6366, edges-pos-ontonotes_loss: 0.0337
09/16 10:56:27 AM: Update 10498: task edges-pos-ontonotes, batch 498 (10498): mcc: 0.6465, acc: 0.4773, precision: 0.8043, recall: 0.5289, f1: 0.6382, edges-pos-ontonotes_loss: 0.0335
09/16 10:56:37 AM: Update 10528: task edges-pos-ontonotes, batch 528 (10528): mcc: 0.6483, acc: 0.4795, precision: 0.8052, recall: 0.5311, f1: 0.6401, edges-pos-ontonotes_loss: 0.0332
09/16 10:56:48 AM: Update 10554: task edges-pos-ontonotes, batch 554 (10554): mcc: 0.6489, acc: 0.4802, precision: 0.8060, recall: 0.5315, f1: 0.6406, edges-pos-ontonotes_loss: 0.0331
09/16 10:56:58 AM: Update 10584: task edges-pos-ontonotes, batch 584 (10584): mcc: 0.6505, acc: 0.4823, precision: 0.8072, recall: 0.5334, f1: 0.6424, edges-pos-ontonotes_loss: 0.0328
09/16 10:57:08 AM: Update 10613: task edges-pos-ontonotes, batch 613 (10613): mcc: 0.6516, acc: 0.4836, precision: 0.8080, recall: 0.5347, f1: 0.6435, edges-pos-ontonotes_loss: 0.0327
09/16 10:57:18 AM: Update 10642: task edges-pos-ontonotes, batch 642 (10642): mcc: 0.6524, acc: 0.4843, precision: 0.8088, recall: 0.5353, f1: 0.6442, edges-pos-ontonotes_loss: 0.0325
09/16 10:57:28 AM: Update 10676: task edges-pos-ontonotes, batch 676 (10676): mcc: 0.6534, acc: 0.4857, precision: 0.8094, recall: 0.5366, f1: 0.6453, edges-pos-ontonotes_loss: 0.0323
09/16 10:57:38 AM: Update 10718: task edges-pos-ontonotes, batch 718 (10718): mcc: 0.6546, acc: 0.4871, precision: 0.8101, recall: 0.5380, f1: 0.6466, edges-pos-ontonotes_loss: 0.0321
09/16 10:57:48 AM: Update 10751: task edges-pos-ontonotes, batch 751 (10751): mcc: 0.6554, acc: 0.4882, precision: 0.8104, recall: 0.5392, f1: 0.6476, edges-pos-ontonotes_loss: 0.0320
09/16 10:57:59 AM: Update 10774: task edges-pos-ontonotes, batch 774 (10774): mcc: 0.6558, acc: 0.4886, precision: 0.8106, recall: 0.5397, f1: 0.6480, edges-pos-ontonotes_loss: 0.0320
09/16 10:58:09 AM: Update 10800: task edges-pos-ontonotes, batch 800 (10800): mcc: 0.6563, acc: 0.4893, precision: 0.8108, recall: 0.5404, f1: 0.6485, edges-pos-ontonotes_loss: 0.0320
09/16 10:58:19 AM: Update 10828: task edges-pos-ontonotes, batch 828 (10828): mcc: 0.6574, acc: 0.4907, precision: 0.8111, recall: 0.5419, f1: 0.6498, edges-pos-ontonotes_loss: 0.0319
09/16 10:58:30 AM: Update 10856: task edges-pos-ontonotes, batch 856 (10856): mcc: 0.6584, acc: 0.4919, precision: 0.8116, recall: 0.5432, f1: 0.6508, edges-pos-ontonotes_loss: 0.0318
09/16 10:58:40 AM: Update 10881: task edges-pos-ontonotes, batch 881 (10881): mcc: 0.6589, acc: 0.4925, precision: 0.8117, recall: 0.5440, f1: 0.6514, edges-pos-ontonotes_loss: 0.0318
09/16 10:58:50 AM: Update 10908: task edges-pos-ontonotes, batch 908 (10908): mcc: 0.6594, acc: 0.4932, precision: 0.8121, recall: 0.5446, f1: 0.6520, edges-pos-ontonotes_loss: 0.0318
09/16 10:59:00 AM: Update 10934: task edges-pos-ontonotes, batch 934 (10934): mcc: 0.6600, acc: 0.4939, precision: 0.8122, recall: 0.5454, f1: 0.6526, edges-pos-ontonotes_loss: 0.0317
09/16 10:59:10 AM: Update 10956: task edges-pos-ontonotes, batch 956 (10956): mcc: 0.6603, acc: 0.4944, precision: 0.8123, recall: 0.5459, f1: 0.6529, edges-pos-ontonotes_loss: 0.0317
09/16 10:59:20 AM: Update 10982: task edges-pos-ontonotes, batch 982 (10982): mcc: 0.6610, acc: 0.4952, precision: 0.8127, recall: 0.5466, f1: 0.6536, edges-pos-ontonotes_loss: 0.0316
09/16 10:59:27 AM: ***** Step 11000 / Validation 11 *****
09/16 10:59:27 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 10:59:27 AM: Validating...
09/16 10:59:31 AM: Evaluate: task edges-pos-ontonotes, batch 11 (157): mcc: 0.7720, acc: 0.6379, precision: 0.9041, recall: 0.6658, f1: 0.7669, edges-pos-ontonotes_loss: 0.0235
09/16 10:59:41 AM: Evaluate: task edges-pos-ontonotes, batch 44 (157): mcc: 0.7637, acc: 0.6207, precision: 0.9176, recall: 0.6422, f1: 0.7556, edges-pos-ontonotes_loss: 0.0242
09/16 10:59:51 AM: Evaluate: task edges-pos-ontonotes, batch 75 (157): mcc: 0.7742, acc: 0.6362, precision: 0.9182, recall: 0.6592, f1: 0.7674, edges-pos-ontonotes_loss: 0.0235
09/16 11:00:01 AM: Evaluate: task edges-pos-ontonotes, batch 110 (157): mcc: 0.7669, acc: 0.6257, precision: 0.9154, recall: 0.6490, f1: 0.7595, edges-pos-ontonotes_loss: 0.0239
09/16 11:00:11 AM: Evaluate: task edges-pos-ontonotes, batch 136 (157): mcc: 0.7562, acc: 0.6110, precision: 0.9106, recall: 0.6346, f1: 0.7480, edges-pos-ontonotes_loss: 0.0246
09/16 11:00:19 AM: Best result seen so far for edges-pos-ontonotes.
09/16 11:00:19 AM: Best result seen so far for macro.
09/16 11:00:19 AM: Updating LR scheduler:
09/16 11:00:19 AM: 	Best result seen so far for macro_avg: 0.746
09/16 11:00:19 AM: 	# validation passes without improvement: 0
09/16 11:00:19 AM: edges-pos-ontonotes_loss: training: 0.031612 validation: 0.024819
09/16 11:00:19 AM: macro_avg: validation: 0.745685
09/16 11:00:19 AM: micro_avg: validation: 0.000000
09/16 11:00:19 AM: edges-pos-ontonotes_mcc: training: 0.661626 validation: 0.754174
09/16 11:00:19 AM: edges-pos-ontonotes_acc: training: 0.496026 validation: 0.607596
09/16 11:00:19 AM: edges-pos-ontonotes_precision: training: 0.812993 validation: 0.910538
09/16 11:00:19 AM: edges-pos-ontonotes_recall: training: 0.547528 validation: 0.631375
09/16 11:00:19 AM: edges-pos-ontonotes_f1: training: 0.654362 validation: 0.745685
09/16 11:00:19 AM: Global learning rate: 0.0001
09/16 11:00:19 AM: Saving checkpoints to: ./experiments/pos-ontonotes-multiqa-top/run
09/16 11:00:21 AM: Update 11005: task edges-pos-ontonotes, batch 5 (11005): mcc: 0.7154, acc: 0.5671, precision: 0.8306, recall: 0.6249, f1: 0.7132, edges-pos-ontonotes_loss: 0.0289
09/16 11:00:31 AM: Update 11019: task edges-pos-ontonotes, batch 19 (11019): mcc: 0.6306, acc: 0.4615, precision: 0.7932, recall: 0.5107, f1: 0.6214, edges-pos-ontonotes_loss: 0.0346
09/16 11:00:41 AM: Update 11047: task edges-pos-ontonotes, batch 47 (11047): mcc: 0.6484, acc: 0.4827, precision: 0.8005, recall: 0.5346, f1: 0.6411, edges-pos-ontonotes_loss: 0.0344
09/16 11:00:52 AM: Update 11070: task edges-pos-ontonotes, batch 70 (11070): mcc: 0.6464, acc: 0.4794, precision: 0.7990, recall: 0.5323, f1: 0.6389, edges-pos-ontonotes_loss: 0.0347
09/16 11:01:02 AM: Update 11092: task edges-pos-ontonotes, batch 92 (11092): mcc: 0.6443, acc: 0.4769, precision: 0.7972, recall: 0.5301, f1: 0.6368, edges-pos-ontonotes_loss: 0.0350
09/16 11:01:12 AM: Update 11115: task edges-pos-ontonotes, batch 115 (11115): mcc: 0.6449, acc: 0.4774, precision: 0.7988, recall: 0.5301, f1: 0.6373, edges-pos-ontonotes_loss: 0.0350
09/16 11:01:22 AM: Update 11137: task edges-pos-ontonotes, batch 137 (11137): mcc: 0.6448, acc: 0.4767, precision: 0.7989, recall: 0.5298, f1: 0.6371, edges-pos-ontonotes_loss: 0.0350
09/16 11:01:32 AM: Update 11161: task edges-pos-ontonotes, batch 161 (11161): mcc: 0.6452, acc: 0.4772, precision: 0.7998, recall: 0.5298, f1: 0.6374, edges-pos-ontonotes_loss: 0.0349
09/16 11:01:42 AM: Update 11183: task edges-pos-ontonotes, batch 183 (11183): mcc: 0.6458, acc: 0.4779, precision: 0.8002, recall: 0.5306, f1: 0.6381, edges-pos-ontonotes_loss: 0.0349
09/16 11:01:53 AM: Update 11205: task edges-pos-ontonotes, batch 205 (11205): mcc: 0.6457, acc: 0.4779, precision: 0.8000, recall: 0.5305, f1: 0.6380, edges-pos-ontonotes_loss: 0.0349
09/16 11:02:03 AM: Update 11229: task edges-pos-ontonotes, batch 229 (11229): mcc: 0.6466, acc: 0.4792, precision: 0.7998, recall: 0.5321, f1: 0.6390, edges-pos-ontonotes_loss: 0.0346
09/16 11:02:13 AM: Update 11250: task edges-pos-ontonotes, batch 250 (11250): mcc: 0.6466, acc: 0.4790, precision: 0.8004, recall: 0.5317, f1: 0.6389, edges-pos-ontonotes_loss: 0.0345
09/16 11:02:23 AM: Update 11285: task edges-pos-ontonotes, batch 285 (11285): mcc: 0.6473, acc: 0.4796, precision: 0.8010, recall: 0.5325, f1: 0.6397, edges-pos-ontonotes_loss: 0.0344
09/16 11:02:46 AM: Update 11320: task edges-pos-ontonotes, batch 320 (11320): mcc: 0.6467, acc: 0.4789, precision: 0.8013, recall: 0.5313, f1: 0.6390, edges-pos-ontonotes_loss: 0.0344
09/16 11:02:57 AM: Update 11343: task edges-pos-ontonotes, batch 343 (11343): mcc: 0.6468, acc: 0.4789, precision: 0.8013, recall: 0.5313, f1: 0.6390, edges-pos-ontonotes_loss: 0.0345
09/16 11:03:07 AM: Update 11368: task edges-pos-ontonotes, batch 368 (11368): mcc: 0.6477, acc: 0.4801, precision: 0.8016, recall: 0.5327, f1: 0.6400, edges-pos-ontonotes_loss: 0.0344
09/16 11:03:17 AM: Update 11392: task edges-pos-ontonotes, batch 392 (11392): mcc: 0.6487, acc: 0.4811, precision: 0.8023, recall: 0.5338, f1: 0.6411, edges-pos-ontonotes_loss: 0.0344
09/16 11:03:27 AM: Update 11412: task edges-pos-ontonotes, batch 412 (11412): mcc: 0.6485, acc: 0.4808, precision: 0.8027, recall: 0.5332, f1: 0.6408, edges-pos-ontonotes_loss: 0.0344
09/16 11:03:38 AM: Update 11434: task edges-pos-ontonotes, batch 434 (11434): mcc: 0.6487, acc: 0.4812, precision: 0.8027, recall: 0.5336, f1: 0.6411, edges-pos-ontonotes_loss: 0.0343
09/16 11:03:48 AM: Update 11454: task edges-pos-ontonotes, batch 454 (11454): mcc: 0.6486, acc: 0.4810, precision: 0.8029, recall: 0.5333, f1: 0.6409, edges-pos-ontonotes_loss: 0.0344
09/16 11:03:58 AM: Update 11476: task edges-pos-ontonotes, batch 476 (11476): mcc: 0.6484, acc: 0.4807, precision: 0.8027, recall: 0.5330, f1: 0.6406, edges-pos-ontonotes_loss: 0.0344
09/16 11:04:08 AM: Update 11496: task edges-pos-ontonotes, batch 496 (11496): mcc: 0.6484, acc: 0.4808, precision: 0.8028, recall: 0.5330, f1: 0.6407, edges-pos-ontonotes_loss: 0.0344
09/16 11:04:18 AM: Update 11519: task edges-pos-ontonotes, batch 519 (11519): mcc: 0.6488, acc: 0.4813, precision: 0.8031, recall: 0.5334, f1: 0.6410, edges-pos-ontonotes_loss: 0.0344
09/16 11:04:28 AM: Update 11543: task edges-pos-ontonotes, batch 543 (11543): mcc: 0.6497, acc: 0.4824, precision: 0.8036, recall: 0.5345, f1: 0.6420, edges-pos-ontonotes_loss: 0.0343
09/16 11:04:39 AM: Update 11565: task edges-pos-ontonotes, batch 565 (11565): mcc: 0.6496, acc: 0.4823, precision: 0.8035, recall: 0.5344, f1: 0.6419, edges-pos-ontonotes_loss: 0.0344
09/16 11:04:49 AM: Update 11593: task edges-pos-ontonotes, batch 593 (11593): mcc: 0.6493, acc: 0.4819, precision: 0.8034, recall: 0.5340, f1: 0.6416, edges-pos-ontonotes_loss: 0.0344
09/16 11:05:00 AM: Update 11618: task edges-pos-ontonotes, batch 618 (11618): mcc: 0.6499, acc: 0.4827, precision: 0.8038, recall: 0.5348, f1: 0.6423, edges-pos-ontonotes_loss: 0.0344
09/16 11:05:10 AM: Update 11634: task edges-pos-ontonotes, batch 634 (11634): mcc: 0.6498, acc: 0.4825, precision: 0.8038, recall: 0.5346, f1: 0.6421, edges-pos-ontonotes_loss: 0.0344
09/16 11:05:20 AM: Update 11658: task edges-pos-ontonotes, batch 658 (11658): mcc: 0.6503, acc: 0.4831, precision: 0.8040, recall: 0.5353, f1: 0.6427, edges-pos-ontonotes_loss: 0.0343
09/16 11:05:30 AM: Update 11684: task edges-pos-ontonotes, batch 684 (11684): mcc: 0.6508, acc: 0.4837, precision: 0.8043, recall: 0.5358, f1: 0.6431, edges-pos-ontonotes_loss: 0.0343
09/16 11:05:40 AM: Update 11707: task edges-pos-ontonotes, batch 707 (11707): mcc: 0.6509, acc: 0.4839, precision: 0.8044, recall: 0.5359, f1: 0.6433, edges-pos-ontonotes_loss: 0.0343
09/16 11:05:51 AM: Update 11730: task edges-pos-ontonotes, batch 730 (11730): mcc: 0.6514, acc: 0.4845, precision: 0.8048, recall: 0.5365, f1: 0.6438, edges-pos-ontonotes_loss: 0.0343
09/16 11:06:01 AM: Update 11754: task edges-pos-ontonotes, batch 754 (11754): mcc: 0.6519, acc: 0.4851, precision: 0.8052, recall: 0.5370, f1: 0.6443, edges-pos-ontonotes_loss: 0.0342
09/16 11:06:11 AM: Update 11777: task edges-pos-ontonotes, batch 777 (11777): mcc: 0.6522, acc: 0.4855, precision: 0.8055, recall: 0.5374, f1: 0.6446, edges-pos-ontonotes_loss: 0.0342
09/16 11:06:21 AM: Update 11800: task edges-pos-ontonotes, batch 800 (11800): mcc: 0.6525, acc: 0.4859, precision: 0.8057, recall: 0.5377, f1: 0.6450, edges-pos-ontonotes_loss: 0.0342
09/16 11:06:32 AM: Update 11823: task edges-pos-ontonotes, batch 823 (11823): mcc: 0.6532, acc: 0.4867, precision: 0.8060, recall: 0.5385, f1: 0.6457, edges-pos-ontonotes_loss: 0.0341
09/16 11:06:42 AM: Update 11845: task edges-pos-ontonotes, batch 845 (11845): mcc: 0.6533, acc: 0.4868, precision: 0.8062, recall: 0.5386, f1: 0.6458, edges-pos-ontonotes_loss: 0.0341
09/16 11:06:52 AM: Update 11866: task edges-pos-ontonotes, batch 866 (11866): mcc: 0.6533, acc: 0.4869, precision: 0.8062, recall: 0.5387, f1: 0.6458, edges-pos-ontonotes_loss: 0.0341
09/16 11:07:02 AM: Update 11894: task edges-pos-ontonotes, batch 894 (11894): mcc: 0.6536, acc: 0.4873, precision: 0.8063, recall: 0.5390, f1: 0.6461, edges-pos-ontonotes_loss: 0.0341
09/16 11:07:13 AM: Update 11928: task edges-pos-ontonotes, batch 928 (11928): mcc: 0.6540, acc: 0.4877, precision: 0.8068, recall: 0.5394, f1: 0.6465, edges-pos-ontonotes_loss: 0.0341
09/16 11:07:23 AM: Update 11946: task edges-pos-ontonotes, batch 946 (11946): mcc: 0.6543, acc: 0.4880, precision: 0.8070, recall: 0.5396, f1: 0.6468, edges-pos-ontonotes_loss: 0.0341
09/16 11:07:33 AM: Update 11965: task edges-pos-ontonotes, batch 965 (11965): mcc: 0.6541, acc: 0.4878, precision: 0.8070, recall: 0.5394, f1: 0.6466, edges-pos-ontonotes_loss: 0.0341
09/16 11:07:43 AM: Update 11992: task edges-pos-ontonotes, batch 992 (11992): mcc: 0.6545, acc: 0.4883, precision: 0.8072, recall: 0.5399, f1: 0.6471, edges-pos-ontonotes_loss: 0.0341
09/16 11:07:47 AM: ***** Step 12000 / Validation 12 *****
09/16 11:07:47 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 11:07:47 AM: Validating...
09/16 11:07:53 AM: Evaluate: task edges-pos-ontonotes, batch 20 (157): mcc: 0.7587, acc: 0.6163, precision: 0.9086, recall: 0.6402, f1: 0.7512, edges-pos-ontonotes_loss: 0.0252
09/16 11:08:03 AM: Evaluate: task edges-pos-ontonotes, batch 55 (157): mcc: 0.7582, acc: 0.6121, precision: 0.9137, recall: 0.6358, f1: 0.7498, edges-pos-ontonotes_loss: 0.0253
09/16 11:08:14 AM: Evaluate: task edges-pos-ontonotes, batch 88 (157): mcc: 0.7649, acc: 0.6228, precision: 0.9126, recall: 0.6478, f1: 0.7577, edges-pos-ontonotes_loss: 0.0247
09/16 11:08:24 AM: Evaluate: task edges-pos-ontonotes, batch 114 (157): mcc: 0.7615, acc: 0.6182, precision: 0.9117, recall: 0.6427, f1: 0.7539, edges-pos-ontonotes_loss: 0.0248
09/16 11:08:34 AM: Evaluate: task edges-pos-ontonotes, batch 138 (157): mcc: 0.7560, acc: 0.6104, precision: 0.9101, recall: 0.6347, f1: 0.7478, edges-pos-ontonotes_loss: 0.0250
09/16 11:08:41 AM: Best result seen so far for edges-pos-ontonotes.
09/16 11:08:41 AM: Best result seen so far for macro.
09/16 11:08:41 AM: Updating LR scheduler:
09/16 11:08:41 AM: 	Best result seen so far for macro_avg: 0.749
09/16 11:08:41 AM: 	# validation passes without improvement: 0
09/16 11:08:41 AM: edges-pos-ontonotes_loss: training: 0.034062 validation: 0.024981
09/16 11:08:41 AM: macro_avg: validation: 0.748586
09/16 11:08:41 AM: micro_avg: validation: 0.000000
09/16 11:08:41 AM: edges-pos-ontonotes_mcc: training: 0.654554 validation: 0.756862
09/16 11:08:41 AM: edges-pos-ontonotes_acc: training: 0.488318 validation: 0.611109
09/16 11:08:41 AM: edges-pos-ontonotes_precision: training: 0.807176 validation: 0.911758
09/16 11:08:41 AM: edges-pos-ontonotes_recall: training: 0.540003 validation: 0.634951
09/16 11:08:41 AM: edges-pos-ontonotes_f1: training: 0.647096 validation: 0.748586
09/16 11:08:41 AM: Global learning rate: 0.0001
09/16 11:08:41 AM: Saving checkpoints to: ./experiments/pos-ontonotes-multiqa-top/run
09/16 11:08:44 AM: Update 12007: task edges-pos-ontonotes, batch 7 (12007): mcc: 0.6903, acc: 0.5336, precision: 0.8188, recall: 0.5910, f1: 0.6865, edges-pos-ontonotes_loss: 0.0320
09/16 11:08:55 AM: Update 12028: task edges-pos-ontonotes, batch 28 (12028): mcc: 0.6656, acc: 0.5031, precision: 0.8127, recall: 0.5542, f1: 0.6590, edges-pos-ontonotes_loss: 0.0331
09/16 11:09:05 AM: Update 12051: task edges-pos-ontonotes, batch 51 (12051): mcc: 0.6649, acc: 0.5015, precision: 0.8143, recall: 0.5519, f1: 0.6579, edges-pos-ontonotes_loss: 0.0338
09/16 11:09:15 AM: Update 12075: task edges-pos-ontonotes, batch 75 (12075): mcc: 0.6655, acc: 0.5025, precision: 0.8160, recall: 0.5518, f1: 0.6584, edges-pos-ontonotes_loss: 0.0338
09/16 11:09:25 AM: Update 12099: task edges-pos-ontonotes, batch 99 (12099): mcc: 0.6658, acc: 0.5031, precision: 0.8159, recall: 0.5523, f1: 0.6587, edges-pos-ontonotes_loss: 0.0337
09/16 11:09:35 AM: Update 12134: task edges-pos-ontonotes, batch 134 (12134): mcc: 0.6693, acc: 0.5073, precision: 0.8173, recall: 0.5571, f1: 0.6625, edges-pos-ontonotes_loss: 0.0333
09/16 11:09:45 AM: Update 12172: task edges-pos-ontonotes, batch 172 (12172): mcc: 0.6691, acc: 0.5070, precision: 0.8172, recall: 0.5569, f1: 0.6624, edges-pos-ontonotes_loss: 0.0332
09/16 11:09:56 AM: Update 12200: task edges-pos-ontonotes, batch 200 (12200): mcc: 0.6696, acc: 0.5074, precision: 0.8176, recall: 0.5574, f1: 0.6629, edges-pos-ontonotes_loss: 0.0332
09/16 11:10:06 AM: Update 12221: task edges-pos-ontonotes, batch 221 (12221): mcc: 0.6698, acc: 0.5079, precision: 0.8176, recall: 0.5578, f1: 0.6631, edges-pos-ontonotes_loss: 0.0332
09/16 11:10:16 AM: Update 12244: task edges-pos-ontonotes, batch 244 (12244): mcc: 0.6697, acc: 0.5080, precision: 0.8170, recall: 0.5580, f1: 0.6631, edges-pos-ontonotes_loss: 0.0332
09/16 11:10:27 AM: Update 12260: task edges-pos-ontonotes, batch 260 (12260): mcc: 0.6659, acc: 0.5030, precision: 0.8153, recall: 0.5530, f1: 0.6590, edges-pos-ontonotes_loss: 0.0333
09/16 11:10:38 AM: Update 12288: task edges-pos-ontonotes, batch 288 (12288): mcc: 0.6669, acc: 0.5039, precision: 0.8162, recall: 0.5540, f1: 0.6600, edges-pos-ontonotes_loss: 0.0330
09/16 11:10:48 AM: Update 12313: task edges-pos-ontonotes, batch 313 (12313): mcc: 0.6664, acc: 0.5031, precision: 0.8162, recall: 0.5530, f1: 0.6594, edges-pos-ontonotes_loss: 0.0329
09/16 11:10:58 AM: Update 12340: task edges-pos-ontonotes, batch 340 (12340): mcc: 0.6678, acc: 0.5047, precision: 0.8170, recall: 0.5549, f1: 0.6609, edges-pos-ontonotes_loss: 0.0326
09/16 11:11:09 AM: Update 12366: task edges-pos-ontonotes, batch 366 (12366): mcc: 0.6691, acc: 0.5060, precision: 0.8179, recall: 0.5563, f1: 0.6622, edges-pos-ontonotes_loss: 0.0324
09/16 11:11:19 AM: Update 12391: task edges-pos-ontonotes, batch 391 (12391): mcc: 0.6703, acc: 0.5073, precision: 0.8187, recall: 0.5577, f1: 0.6635, edges-pos-ontonotes_loss: 0.0322
09/16 11:11:29 AM: Update 12417: task edges-pos-ontonotes, batch 417 (12417): mcc: 0.6707, acc: 0.5078, precision: 0.8188, recall: 0.5584, f1: 0.6640, edges-pos-ontonotes_loss: 0.0319
09/16 11:11:39 AM: Update 12444: task edges-pos-ontonotes, batch 444 (12444): mcc: 0.6712, acc: 0.5083, precision: 0.8190, recall: 0.5590, f1: 0.6644, edges-pos-ontonotes_loss: 0.0318
09/16 11:11:49 AM: Update 12468: task edges-pos-ontonotes, batch 468 (12468): mcc: 0.6709, acc: 0.5078, precision: 0.8188, recall: 0.5587, f1: 0.6642, edges-pos-ontonotes_loss: 0.0317
09/16 11:11:59 AM: Update 12495: task edges-pos-ontonotes, batch 495 (12495): mcc: 0.6714, acc: 0.5085, precision: 0.8191, recall: 0.5593, f1: 0.6647, edges-pos-ontonotes_loss: 0.0316
09/16 11:12:09 AM: Update 12532: task edges-pos-ontonotes, batch 532 (12532): mcc: 0.6713, acc: 0.5084, precision: 0.8188, recall: 0.5593, f1: 0.6646, edges-pos-ontonotes_loss: 0.0315
09/16 11:12:20 AM: Update 12563: task edges-pos-ontonotes, batch 563 (12563): mcc: 0.6715, acc: 0.5088, precision: 0.8186, recall: 0.5599, f1: 0.6649, edges-pos-ontonotes_loss: 0.0314
09/16 11:12:30 AM: Update 12583: task edges-pos-ontonotes, batch 583 (12583): mcc: 0.6721, acc: 0.5094, precision: 0.8190, recall: 0.5605, f1: 0.6655, edges-pos-ontonotes_loss: 0.0313
09/16 11:12:40 AM: Update 12618: task edges-pos-ontonotes, batch 618 (12618): mcc: 0.6748, acc: 0.5125, precision: 0.8205, recall: 0.5639, f1: 0.6685, edges-pos-ontonotes_loss: 0.0311
09/16 11:12:50 AM: Update 12646: task edges-pos-ontonotes, batch 646 (12646): mcc: 0.6769, acc: 0.5149, precision: 0.8217, recall: 0.5666, f1: 0.6707, edges-pos-ontonotes_loss: 0.0309
09/16 11:13:00 AM: Update 12676: task edges-pos-ontonotes, batch 676 (12676): mcc: 0.6792, acc: 0.5176, precision: 0.8230, recall: 0.5694, f1: 0.6731, edges-pos-ontonotes_loss: 0.0306
09/16 11:13:10 AM: Update 12704: task edges-pos-ontonotes, batch 704 (12704): mcc: 0.6813, acc: 0.5202, precision: 0.8242, recall: 0.5721, f1: 0.6754, edges-pos-ontonotes_loss: 0.0304
09/16 11:13:20 AM: Update 12732: task edges-pos-ontonotes, batch 732 (12732): mcc: 0.6831, acc: 0.5223, precision: 0.8253, recall: 0.5743, f1: 0.6773, edges-pos-ontonotes_loss: 0.0302
09/16 11:13:30 AM: Update 12759: task edges-pos-ontonotes, batch 759 (12759): mcc: 0.6849, acc: 0.5243, precision: 0.8264, recall: 0.5764, f1: 0.6791, edges-pos-ontonotes_loss: 0.0301
09/16 11:13:40 AM: Update 12785: task edges-pos-ontonotes, batch 785 (12785): mcc: 0.6866, acc: 0.5263, precision: 0.8274, recall: 0.5785, f1: 0.6809, edges-pos-ontonotes_loss: 0.0299
09/16 11:13:50 AM: Update 12815: task edges-pos-ontonotes, batch 815 (12815): mcc: 0.6882, acc: 0.5283, precision: 0.8283, recall: 0.5805, f1: 0.6826, edges-pos-ontonotes_loss: 0.0298
09/16 11:14:01 AM: Update 12844: task edges-pos-ontonotes, batch 844 (12844): mcc: 0.6898, acc: 0.5305, precision: 0.8293, recall: 0.5826, f1: 0.6844, edges-pos-ontonotes_loss: 0.0296
09/16 11:14:11 AM: Update 12873: task edges-pos-ontonotes, batch 873 (12873): mcc: 0.6916, acc: 0.5326, precision: 0.8302, recall: 0.5848, f1: 0.6862, edges-pos-ontonotes_loss: 0.0294
09/16 11:14:21 AM: Update 12899: task edges-pos-ontonotes, batch 899 (12899): mcc: 0.6922, acc: 0.5334, precision: 0.8307, recall: 0.5855, f1: 0.6869, edges-pos-ontonotes_loss: 0.0294
09/16 11:14:31 AM: Update 12969: task edges-pos-ontonotes, batch 969 (12969): mcc: 0.6950, acc: 0.5370, precision: 0.8325, recall: 0.5890, f1: 0.6898, edges-pos-ontonotes_loss: 0.0290
09/16 11:14:36 AM: ***** Step 13000 / Validation 13 *****
09/16 11:14:36 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 11:14:36 AM: Validating...
09/16 11:14:41 AM: Evaluate: task edges-pos-ontonotes, batch 14 (157): mcc: 0.7595, acc: 0.6169, precision: 0.9160, recall: 0.6363, f1: 0.7510, edges-pos-ontonotes_loss: 0.0245
09/16 11:14:52 AM: Evaluate: task edges-pos-ontonotes, batch 48 (157): mcc: 0.7540, acc: 0.6043, precision: 0.9255, recall: 0.6206, f1: 0.7430, edges-pos-ontonotes_loss: 0.0248
09/16 11:15:02 AM: Evaluate: task edges-pos-ontonotes, batch 81 (157): mcc: 0.7655, acc: 0.6217, precision: 0.9252, recall: 0.6397, f1: 0.7564, edges-pos-ontonotes_loss: 0.0239
09/16 11:15:12 AM: Evaluate: task edges-pos-ontonotes, batch 108 (157): mcc: 0.7571, acc: 0.6104, precision: 0.9204, recall: 0.6293, f1: 0.7475, edges-pos-ontonotes_loss: 0.0243
09/16 11:15:22 AM: Evaluate: task edges-pos-ontonotes, batch 131 (157): mcc: 0.7487, acc: 0.5984, precision: 0.9160, recall: 0.6187, f1: 0.7385, edges-pos-ontonotes_loss: 0.0248
09/16 11:15:32 AM: Evaluate: task edges-pos-ontonotes, batch 155 (157): mcc: 0.7462, acc: 0.5942, precision: 0.9152, recall: 0.6151, f1: 0.7357, edges-pos-ontonotes_loss: 0.0250
09/16 11:15:33 AM: Updating LR scheduler:
09/16 11:15:33 AM: 	Best result seen so far for macro_avg: 0.749
09/16 11:15:33 AM: 	# validation passes without improvement: 1
09/16 11:15:33 AM: edges-pos-ontonotes_loss: training: 0.028835 validation: 0.025049
09/16 11:15:33 AM: macro_avg: validation: 0.735579
09/16 11:15:33 AM: micro_avg: validation: 0.000000
09/16 11:15:33 AM: edges-pos-ontonotes_mcc: training: 0.696356 validation: 0.746114
09/16 11:15:33 AM: edges-pos-ontonotes_acc: training: 0.538651 validation: 0.593934
09/16 11:15:33 AM: edges-pos-ontonotes_precision: training: 0.833239 validation: 0.915363
09/16 11:15:33 AM: edges-pos-ontonotes_recall: training: 0.590585 validation: 0.614824
09/16 11:15:33 AM: edges-pos-ontonotes_f1: training: 0.691235 validation: 0.735579
09/16 11:15:33 AM: Global learning rate: 0.0001
09/16 11:15:33 AM: Saving checkpoints to: ./experiments/pos-ontonotes-multiqa-top/run
09/16 11:15:42 AM: Update 13027: task edges-pos-ontonotes, batch 27 (13027): mcc: 0.7446, acc: 0.6032, precision: 0.8599, recall: 0.6527, f1: 0.7421, edges-pos-ontonotes_loss: 0.0254
09/16 11:15:53 AM: Update 13061: task edges-pos-ontonotes, batch 61 (13061): mcc: 0.7491, acc: 0.6087, precision: 0.8601, recall: 0.6602, f1: 0.7470, edges-pos-ontonotes_loss: 0.0250
09/16 11:16:03 AM: Update 13094: task edges-pos-ontonotes, batch 94 (13094): mcc: 0.7501, acc: 0.6093, precision: 0.8624, recall: 0.6602, f1: 0.7479, edges-pos-ontonotes_loss: 0.0249
09/16 11:16:13 AM: Update 13126: task edges-pos-ontonotes, batch 126 (13126): mcc: 0.7486, acc: 0.6079, precision: 0.8610, recall: 0.6587, f1: 0.7464, edges-pos-ontonotes_loss: 0.0251
09/16 11:16:23 AM: Update 13160: task edges-pos-ontonotes, batch 160 (13160): mcc: 0.7534, acc: 0.6144, precision: 0.8634, recall: 0.6651, f1: 0.7514, edges-pos-ontonotes_loss: 0.0246
09/16 11:16:34 AM: Update 13192: task edges-pos-ontonotes, batch 192 (13192): mcc: 0.7556, acc: 0.6172, precision: 0.8651, recall: 0.6677, f1: 0.7537, edges-pos-ontonotes_loss: 0.0243
09/16 11:16:44 AM: Update 13218: task edges-pos-ontonotes, batch 218 (13218): mcc: 0.7454, acc: 0.6032, precision: 0.8603, recall: 0.6536, f1: 0.7429, edges-pos-ontonotes_loss: 0.0247
09/16 11:16:54 AM: Update 13292: task edges-pos-ontonotes, batch 292 (13292): mcc: 0.7398, acc: 0.5962, precision: 0.8568, recall: 0.6467, f1: 0.7371, edges-pos-ontonotes_loss: 0.0251
09/16 11:17:04 AM: Update 13373: task edges-pos-ontonotes, batch 373 (13373): mcc: 0.7346, acc: 0.5894, precision: 0.8530, recall: 0.6407, f1: 0.7318, edges-pos-ontonotes_loss: 0.0256
09/16 11:17:14 AM: Update 13413: task edges-pos-ontonotes, batch 413 (13413): mcc: 0.7301, acc: 0.5835, precision: 0.8503, recall: 0.6351, f1: 0.7271, edges-pos-ontonotes_loss: 0.0258
09/16 11:17:24 AM: Update 13454: task edges-pos-ontonotes, batch 454 (13454): mcc: 0.7311, acc: 0.5852, precision: 0.8506, recall: 0.6366, f1: 0.7282, edges-pos-ontonotes_loss: 0.0258
09/16 11:17:34 AM: Update 13505: task edges-pos-ontonotes, batch 505 (13505): mcc: 0.7301, acc: 0.5837, precision: 0.8497, recall: 0.6354, f1: 0.7271, edges-pos-ontonotes_loss: 0.0258
09/16 11:17:48 AM: Update 13511: task edges-pos-ontonotes, batch 511 (13511): mcc: 0.7269, acc: 0.5797, precision: 0.8476, recall: 0.6316, f1: 0.7238, edges-pos-ontonotes_loss: 0.0258
09/16 11:17:58 AM: Update 13532: task edges-pos-ontonotes, batch 532 (13532): mcc: 0.7183, acc: 0.5688, precision: 0.8418, recall: 0.6214, f1: 0.7150, edges-pos-ontonotes_loss: 0.0262
09/16 11:18:09 AM: Update 13557: task edges-pos-ontonotes, batch 557 (13557): mcc: 0.7115, acc: 0.5599, precision: 0.8377, recall: 0.6129, f1: 0.7079, edges-pos-ontonotes_loss: 0.0266
09/16 11:18:19 AM: Update 13580: task edges-pos-ontonotes, batch 580 (13580): mcc: 0.7071, acc: 0.5540, precision: 0.8351, recall: 0.6072, f1: 0.7032, edges-pos-ontonotes_loss: 0.0269
09/16 11:18:29 AM: Update 13604: task edges-pos-ontonotes, batch 604 (13604): mcc: 0.7015, acc: 0.5468, precision: 0.8316, recall: 0.6004, f1: 0.6974, edges-pos-ontonotes_loss: 0.0273
09/16 11:18:39 AM: Update 13629: task edges-pos-ontonotes, batch 629 (13629): mcc: 0.6990, acc: 0.5435, precision: 0.8300, recall: 0.5974, f1: 0.6947, edges-pos-ontonotes_loss: 0.0275
09/16 11:18:50 AM: Update 13655: task edges-pos-ontonotes, batch 655 (13655): mcc: 0.6974, acc: 0.5414, precision: 0.8288, recall: 0.5956, f1: 0.6931, edges-pos-ontonotes_loss: 0.0278
09/16 11:19:00 AM: Update 13678: task edges-pos-ontonotes, batch 678 (13678): mcc: 0.6933, acc: 0.5360, precision: 0.8267, recall: 0.5903, f1: 0.6888, edges-pos-ontonotes_loss: 0.0280
09/16 11:19:11 AM: Update 13701: task edges-pos-ontonotes, batch 701 (13701): mcc: 0.6912, acc: 0.5332, precision: 0.8255, recall: 0.5876, f1: 0.6865, edges-pos-ontonotes_loss: 0.0282
09/16 11:19:21 AM: Update 13742: task edges-pos-ontonotes, batch 742 (13742): mcc: 0.6883, acc: 0.5295, precision: 0.8238, recall: 0.5840, f1: 0.6835, edges-pos-ontonotes_loss: 0.0285
09/16 11:19:31 AM: Update 13769: task edges-pos-ontonotes, batch 769 (13769): mcc: 0.6841, acc: 0.5240, precision: 0.8215, recall: 0.5785, f1: 0.6790, edges-pos-ontonotes_loss: 0.0288
09/16 11:19:41 AM: Update 13795: task edges-pos-ontonotes, batch 795 (13795): mcc: 0.6827, acc: 0.5224, precision: 0.8205, recall: 0.5770, f1: 0.6776, edges-pos-ontonotes_loss: 0.0289
09/16 11:19:51 AM: Update 13820: task edges-pos-ontonotes, batch 820 (13820): mcc: 0.6807, acc: 0.5197, precision: 0.8198, recall: 0.5741, f1: 0.6753, edges-pos-ontonotes_loss: 0.0291
09/16 11:20:04 AM: Update 13841: task edges-pos-ontonotes, batch 841 (13841): mcc: 0.6793, acc: 0.5180, precision: 0.8190, recall: 0.5724, f1: 0.6739, edges-pos-ontonotes_loss: 0.0293
09/16 11:20:14 AM: Update 13869: task edges-pos-ontonotes, batch 869 (13869): mcc: 0.6792, acc: 0.5179, precision: 0.8192, recall: 0.5722, f1: 0.6738, edges-pos-ontonotes_loss: 0.0293
09/16 11:20:24 AM: Update 13896: task edges-pos-ontonotes, batch 896 (13896): mcc: 0.6788, acc: 0.5174, precision: 0.8191, recall: 0.5715, f1: 0.6733, edges-pos-ontonotes_loss: 0.0293
09/16 11:20:34 AM: Update 13927: task edges-pos-ontonotes, batch 927 (13927): mcc: 0.6796, acc: 0.5184, precision: 0.8199, recall: 0.5723, f1: 0.6741, edges-pos-ontonotes_loss: 0.0292
09/16 11:20:44 AM: Update 13952: task edges-pos-ontonotes, batch 952 (13952): mcc: 0.6795, acc: 0.5182, precision: 0.8202, recall: 0.5719, f1: 0.6739, edges-pos-ontonotes_loss: 0.0292
09/16 11:20:55 AM: Update 13978: task edges-pos-ontonotes, batch 978 (13978): mcc: 0.6786, acc: 0.5170, precision: 0.8199, recall: 0.5706, f1: 0.6729, edges-pos-ontonotes_loss: 0.0293
09/16 11:21:03 AM: ***** Step 14000 / Validation 14 *****
09/16 11:21:03 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 11:21:03 AM: Validating...
09/16 11:21:05 AM: Evaluate: task edges-pos-ontonotes, batch 5 (157): mcc: 0.7751, acc: 0.6416, precision: 0.8988, recall: 0.6752, f1: 0.7711, edges-pos-ontonotes_loss: 0.0227
09/16 11:21:15 AM: Evaluate: task edges-pos-ontonotes, batch 38 (157): mcc: 0.7722, acc: 0.6333, precision: 0.9167, recall: 0.6569, f1: 0.7654, edges-pos-ontonotes_loss: 0.0232
09/16 11:21:25 AM: Evaluate: task edges-pos-ontonotes, batch 71 (157): mcc: 0.7761, acc: 0.6381, precision: 0.9182, recall: 0.6624, f1: 0.7696, edges-pos-ontonotes_loss: 0.0229
09/16 11:21:35 AM: Evaluate: task edges-pos-ontonotes, batch 100 (157): mcc: 0.7715, acc: 0.6320, precision: 0.9141, recall: 0.6576, f1: 0.7649, edges-pos-ontonotes_loss: 0.0233
09/16 11:21:45 AM: Evaluate: task edges-pos-ontonotes, batch 128 (157): mcc: 0.7595, acc: 0.6154, precision: 0.9086, recall: 0.6417, f1: 0.7521, edges-pos-ontonotes_loss: 0.0241
09/16 11:21:55 AM: Updating LR scheduler:
09/16 11:21:55 AM: 	Best result seen so far for macro_avg: 0.749
09/16 11:21:55 AM: 	# validation passes without improvement: 2
09/16 11:21:55 AM: edges-pos-ontonotes_loss: training: 0.029249 validation: 0.024521
09/16 11:21:55 AM: macro_avg: validation: 0.745718
09/16 11:21:55 AM: micro_avg: validation: 0.000000
09/16 11:21:55 AM: edges-pos-ontonotes_mcc: training: 0.678896 validation: 0.753816
09/16 11:21:55 AM: edges-pos-ontonotes_acc: training: 0.517407 validation: 0.606453
09/16 11:21:55 AM: edges-pos-ontonotes_precision: training: 0.819968 validation: 0.907681
09/16 11:21:55 AM: edges-pos-ontonotes_recall: training: 0.571049 validation: 0.632803
09/16 11:21:55 AM: edges-pos-ontonotes_f1: training: 0.673237 validation: 0.745718
09/16 11:21:55 AM: Global learning rate: 0.0001
09/16 11:21:55 AM: Saving checkpoints to: ./experiments/pos-ontonotes-multiqa-top/run
09/16 11:21:55 AM: Update 14003: task edges-pos-ontonotes, batch 3 (14003): mcc: 0.6566, acc: 0.4924, precision: 0.8256, recall: 0.5309, f1: 0.6462, edges-pos-ontonotes_loss: 0.0333
09/16 11:22:06 AM: Update 14038: task edges-pos-ontonotes, batch 38 (14038): mcc: 0.7117, acc: 0.5600, precision: 0.8431, recall: 0.6092, f1: 0.7073, edges-pos-ontonotes_loss: 0.0275
09/16 11:22:16 AM: Update 14070: task edges-pos-ontonotes, batch 70 (14070): mcc: 0.7101, acc: 0.5574, precision: 0.8440, recall: 0.6057, f1: 0.7053, edges-pos-ontonotes_loss: 0.0273
09/16 11:22:26 AM: Update 14101: task edges-pos-ontonotes, batch 101 (14101): mcc: 0.7106, acc: 0.5577, precision: 0.8431, recall: 0.6072, f1: 0.7060, edges-pos-ontonotes_loss: 0.0271
09/16 11:22:37 AM: Update 14127: task edges-pos-ontonotes, batch 127 (14127): mcc: 0.7037, acc: 0.5493, precision: 0.8375, recall: 0.5999, f1: 0.6990, edges-pos-ontonotes_loss: 0.0276
09/16 11:22:48 AM: Update 14154: task edges-pos-ontonotes, batch 154 (14154): mcc: 0.7001, acc: 0.5447, precision: 0.8362, recall: 0.5947, f1: 0.6951, edges-pos-ontonotes_loss: 0.0277
09/16 11:22:58 AM: Update 14180: task edges-pos-ontonotes, batch 180 (14180): mcc: 0.6969, acc: 0.5405, precision: 0.8329, recall: 0.5917, f1: 0.6919, edges-pos-ontonotes_loss: 0.0280
09/16 11:23:09 AM: Update 14204: task edges-pos-ontonotes, batch 204 (14204): mcc: 0.6931, acc: 0.5358, precision: 0.8296, recall: 0.5879, f1: 0.6881, edges-pos-ontonotes_loss: 0.0284
09/16 11:23:19 AM: Update 14235: task edges-pos-ontonotes, batch 235 (14235): mcc: 0.6947, acc: 0.5377, precision: 0.8300, recall: 0.5901, f1: 0.6898, edges-pos-ontonotes_loss: 0.0283
09/16 11:23:29 AM: Update 14260: task edges-pos-ontonotes, batch 260 (14260): mcc: 0.6923, acc: 0.5349, precision: 0.8279, recall: 0.5876, f1: 0.6873, edges-pos-ontonotes_loss: 0.0286
09/16 11:23:40 AM: Update 14287: task edges-pos-ontonotes, batch 287 (14287): mcc: 0.6915, acc: 0.5339, precision: 0.8263, recall: 0.5874, f1: 0.6867, edges-pos-ontonotes_loss: 0.0288
09/16 11:23:50 AM: Update 14310: task edges-pos-ontonotes, batch 310 (14310): mcc: 0.6916, acc: 0.5342, precision: 0.8261, recall: 0.5877, f1: 0.6868, edges-pos-ontonotes_loss: 0.0289
09/16 11:24:00 AM: Update 14335: task edges-pos-ontonotes, batch 335 (14335): mcc: 0.6901, acc: 0.5324, precision: 0.8248, recall: 0.5862, f1: 0.6853, edges-pos-ontonotes_loss: 0.0289
09/16 11:24:10 AM: Update 14381: task edges-pos-ontonotes, batch 381 (14381): mcc: 0.6903, acc: 0.5325, precision: 0.8248, recall: 0.5866, f1: 0.6856, edges-pos-ontonotes_loss: 0.0290
09/16 11:24:21 AM: Update 14426: task edges-pos-ontonotes, batch 426 (14426): mcc: 0.6894, acc: 0.5314, precision: 0.8242, recall: 0.5854, f1: 0.6846, edges-pos-ontonotes_loss: 0.0291
09/16 11:24:31 AM: Update 14451: task edges-pos-ontonotes, batch 451 (14451): mcc: 0.6878, acc: 0.5294, precision: 0.8235, recall: 0.5834, f1: 0.6829, edges-pos-ontonotes_loss: 0.0292
09/16 11:24:42 AM: Update 14468: task edges-pos-ontonotes, batch 468 (14468): mcc: 0.6858, acc: 0.5270, precision: 0.8225, recall: 0.5808, f1: 0.6808, edges-pos-ontonotes_loss: 0.0293
09/16 11:24:52 AM: Update 14492: task edges-pos-ontonotes, batch 492 (14492): mcc: 0.6836, acc: 0.5246, precision: 0.8206, recall: 0.5784, f1: 0.6786, edges-pos-ontonotes_loss: 0.0296
09/16 11:25:02 AM: Update 14515: task edges-pos-ontonotes, batch 515 (14515): mcc: 0.6816, acc: 0.5220, precision: 0.8194, recall: 0.5760, f1: 0.6765, edges-pos-ontonotes_loss: 0.0298
09/16 11:25:13 AM: Update 14540: task edges-pos-ontonotes, batch 540 (14540): mcc: 0.6801, acc: 0.5201, precision: 0.8184, recall: 0.5741, f1: 0.6748, edges-pos-ontonotes_loss: 0.0299
09/16 11:25:23 AM: Update 14565: task edges-pos-ontonotes, batch 565 (14565): mcc: 0.6785, acc: 0.5183, precision: 0.8171, recall: 0.5725, f1: 0.6733, edges-pos-ontonotes_loss: 0.0301
09/16 11:25:33 AM: Update 14588: task edges-pos-ontonotes, batch 588 (14588): mcc: 0.6777, acc: 0.5174, precision: 0.8166, recall: 0.5715, f1: 0.6724, edges-pos-ontonotes_loss: 0.0303
09/16 11:25:43 AM: Update 14613: task edges-pos-ontonotes, batch 613 (14613): mcc: 0.6763, acc: 0.5158, precision: 0.8157, recall: 0.5698, f1: 0.6709, edges-pos-ontonotes_loss: 0.0304
09/16 11:25:54 AM: Update 14635: task edges-pos-ontonotes, batch 635 (14635): mcc: 0.6757, acc: 0.5151, precision: 0.8152, recall: 0.5692, f1: 0.6704, edges-pos-ontonotes_loss: 0.0305
09/16 11:26:04 AM: Update 14657: task edges-pos-ontonotes, batch 657 (14657): mcc: 0.6743, acc: 0.5133, precision: 0.8143, recall: 0.5675, f1: 0.6689, edges-pos-ontonotes_loss: 0.0306
09/16 11:26:14 AM: Update 14679: task edges-pos-ontonotes, batch 679 (14679): mcc: 0.6733, acc: 0.5119, precision: 0.8139, recall: 0.5660, f1: 0.6677, edges-pos-ontonotes_loss: 0.0307
09/16 11:26:24 AM: Update 14703: task edges-pos-ontonotes, batch 703 (14703): mcc: 0.6732, acc: 0.5118, precision: 0.8137, recall: 0.5661, f1: 0.6677, edges-pos-ontonotes_loss: 0.0308
09/16 11:26:34 AM: Update 14735: task edges-pos-ontonotes, batch 735 (14735): mcc: 0.6726, acc: 0.5109, precision: 0.8132, recall: 0.5654, f1: 0.6670, edges-pos-ontonotes_loss: 0.0309
09/16 11:26:44 AM: Update 14769: task edges-pos-ontonotes, batch 769 (14769): mcc: 0.6714, acc: 0.5094, precision: 0.8128, recall: 0.5638, f1: 0.6658, edges-pos-ontonotes_loss: 0.0311
09/16 11:26:55 AM: Update 14785: task edges-pos-ontonotes, batch 785 (14785): mcc: 0.6705, acc: 0.5082, precision: 0.8124, recall: 0.5626, f1: 0.6648, edges-pos-ontonotes_loss: 0.0311
09/16 11:27:05 AM: Update 14810: task edges-pos-ontonotes, batch 810 (14810): mcc: 0.6704, acc: 0.5080, precision: 0.8123, recall: 0.5625, f1: 0.6647, edges-pos-ontonotes_loss: 0.0312
09/16 11:27:15 AM: Update 14833: task edges-pos-ontonotes, batch 833 (14833): mcc: 0.6696, acc: 0.5071, precision: 0.8118, recall: 0.5615, f1: 0.6638, edges-pos-ontonotes_loss: 0.0313
09/16 11:27:25 AM: Update 14854: task edges-pos-ontonotes, batch 854 (14854): mcc: 0.6687, acc: 0.5059, precision: 0.8112, recall: 0.5604, f1: 0.6629, edges-pos-ontonotes_loss: 0.0313
09/16 11:27:35 AM: Update 14880: task edges-pos-ontonotes, batch 880 (14880): mcc: 0.6688, acc: 0.5061, precision: 0.8111, recall: 0.5607, f1: 0.6630, edges-pos-ontonotes_loss: 0.0314
09/16 11:27:46 AM: Update 14904: task edges-pos-ontonotes, batch 904 (14904): mcc: 0.6686, acc: 0.5057, precision: 0.8111, recall: 0.5602, f1: 0.6627, edges-pos-ontonotes_loss: 0.0314
09/16 11:27:56 AM: Update 14926: task edges-pos-ontonotes, batch 926 (14926): mcc: 0.6682, acc: 0.5052, precision: 0.8110, recall: 0.5597, f1: 0.6623, edges-pos-ontonotes_loss: 0.0315
09/16 11:28:06 AM: Update 14949: task edges-pos-ontonotes, batch 949 (14949): mcc: 0.6677, acc: 0.5046, precision: 0.8107, recall: 0.5591, f1: 0.6618, edges-pos-ontonotes_loss: 0.0316
09/16 11:28:17 AM: Update 14972: task edges-pos-ontonotes, batch 972 (14972): mcc: 0.6677, acc: 0.5046, precision: 0.8108, recall: 0.5590, f1: 0.6618, edges-pos-ontonotes_loss: 0.0316
09/16 11:28:27 AM: Update 14997: task edges-pos-ontonotes, batch 997 (14997): mcc: 0.6678, acc: 0.5047, precision: 0.8109, recall: 0.5591, f1: 0.6619, edges-pos-ontonotes_loss: 0.0316
09/16 11:28:28 AM: ***** Step 15000 / Validation 15 *****
09/16 11:28:28 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 11:28:28 AM: Validating...
09/16 11:28:37 AM: Evaluate: task edges-pos-ontonotes, batch 30 (157): mcc: 0.7685, acc: 0.6289, precision: 0.9137, recall: 0.6530, f1: 0.7616, edges-pos-ontonotes_loss: 0.0240
09/16 11:28:47 AM: Evaluate: task edges-pos-ontonotes, batch 65 (157): mcc: 0.7729, acc: 0.6341, precision: 0.9168, recall: 0.6581, f1: 0.7662, edges-pos-ontonotes_loss: 0.0236
09/16 11:28:57 AM: Evaluate: task edges-pos-ontonotes, batch 100 (157): mcc: 0.7732, acc: 0.6354, precision: 0.9146, recall: 0.6602, f1: 0.7669, edges-pos-ontonotes_loss: 0.0235
09/16 11:29:07 AM: Evaluate: task edges-pos-ontonotes, batch 132 (157): mcc: 0.7644, acc: 0.6229, precision: 0.9128, recall: 0.6467, f1: 0.7570, edges-pos-ontonotes_loss: 0.0240
09/16 11:29:17 AM: Best result seen so far for edges-pos-ontonotes.
09/16 11:29:17 AM: Best result seen so far for macro.
09/16 11:29:17 AM: Updating LR scheduler:
09/16 11:29:17 AM: 	Best result seen so far for macro_avg: 0.756
09/16 11:29:17 AM: 	# validation passes without improvement: 0
09/16 11:29:17 AM: edges-pos-ontonotes_loss: training: 0.031643 validation: 0.024052
09/16 11:29:17 AM: macro_avg: validation: 0.756059
09/16 11:29:17 AM: micro_avg: validation: 0.000000
09/16 11:29:17 AM: edges-pos-ontonotes_mcc: training: 0.667772 validation: 0.763655
09/16 11:29:17 AM: edges-pos-ontonotes_acc: training: 0.504700 validation: 0.621078
09/16 11:29:17 AM: edges-pos-ontonotes_precision: training: 0.810900 validation: 0.913818
09/16 11:29:17 AM: edges-pos-ontonotes_recall: training: 0.559074 validation: 0.644751
09/16 11:29:17 AM: edges-pos-ontonotes_f1: training: 0.661842 validation: 0.756059
09/16 11:29:17 AM: Global learning rate: 0.0001
09/16 11:29:17 AM: Saving checkpoints to: ./experiments/pos-ontonotes-multiqa-top/run
09/16 11:29:18 AM: Update 15002: task edges-pos-ontonotes, batch 2 (15002): mcc: 0.6664, acc: 0.4979, precision: 0.8197, recall: 0.5507, f1: 0.6588, edges-pos-ontonotes_loss: 0.0344
09/16 11:29:28 AM: Update 15023: task edges-pos-ontonotes, batch 23 (15023): mcc: 0.6738, acc: 0.5112, precision: 0.8133, recall: 0.5673, f1: 0.6684, edges-pos-ontonotes_loss: 0.0334
09/16 11:29:38 AM: Update 15041: task edges-pos-ontonotes, batch 41 (15041): mcc: 0.6613, acc: 0.4965, precision: 0.8080, recall: 0.5505, f1: 0.6548, edges-pos-ontonotes_loss: 0.0337
09/16 11:29:48 AM: Update 15064: task edges-pos-ontonotes, batch 64 (15064): mcc: 0.6615, acc: 0.4973, precision: 0.8102, recall: 0.5493, f1: 0.6547, edges-pos-ontonotes_loss: 0.0337
09/16 11:29:59 AM: Update 15089: task edges-pos-ontonotes, batch 89 (15089): mcc: 0.6646, acc: 0.5003, precision: 0.8108, recall: 0.5539, f1: 0.6582, edges-pos-ontonotes_loss: 0.0335
09/16 11:30:13 AM: Update 15093: task edges-pos-ontonotes, batch 93 (15093): mcc: 0.6630, acc: 0.4984, precision: 0.8100, recall: 0.5519, f1: 0.6565, edges-pos-ontonotes_loss: 0.0336
09/16 11:30:23 AM: Update 15112: task edges-pos-ontonotes, batch 112 (15112): mcc: 0.6610, acc: 0.4961, precision: 0.8091, recall: 0.5493, f1: 0.6543, edges-pos-ontonotes_loss: 0.0337
09/16 11:30:33 AM: Update 15137: task edges-pos-ontonotes, batch 137 (15137): mcc: 0.6642, acc: 0.5002, precision: 0.8110, recall: 0.5531, f1: 0.6577, edges-pos-ontonotes_loss: 0.0333
09/16 11:30:43 AM: Update 15162: task edges-pos-ontonotes, batch 162 (15162): mcc: 0.6657, acc: 0.5019, precision: 0.8124, recall: 0.5546, f1: 0.6592, edges-pos-ontonotes_loss: 0.0332
09/16 11:30:54 AM: Update 15185: task edges-pos-ontonotes, batch 185 (15185): mcc: 0.6638, acc: 0.4999, precision: 0.8109, recall: 0.5526, f1: 0.6573, edges-pos-ontonotes_loss: 0.0334
09/16 11:31:04 AM: Update 15210: task edges-pos-ontonotes, batch 210 (15210): mcc: 0.6652, acc: 0.5018, precision: 0.8116, recall: 0.5544, f1: 0.6588, edges-pos-ontonotes_loss: 0.0333
09/16 11:31:14 AM: Update 15233: task edges-pos-ontonotes, batch 233 (15233): mcc: 0.6647, acc: 0.5016, precision: 0.8111, recall: 0.5540, f1: 0.6583, edges-pos-ontonotes_loss: 0.0333
09/16 11:31:25 AM: Update 15271: task edges-pos-ontonotes, batch 271 (15271): mcc: 0.6657, acc: 0.5024, precision: 0.8116, recall: 0.5551, f1: 0.6593, edges-pos-ontonotes_loss: 0.0332
09/16 11:31:35 AM: Update 15306: task edges-pos-ontonotes, batch 306 (15306): mcc: 0.6658, acc: 0.5027, precision: 0.8116, recall: 0.5553, f1: 0.6594, edges-pos-ontonotes_loss: 0.0332
09/16 11:31:45 AM: Update 15329: task edges-pos-ontonotes, batch 329 (15329): mcc: 0.6666, acc: 0.5036, precision: 0.8120, recall: 0.5564, f1: 0.6603, edges-pos-ontonotes_loss: 0.0331
09/16 11:31:55 AM: Update 15354: task edges-pos-ontonotes, batch 354 (15354): mcc: 0.6667, acc: 0.5037, precision: 0.8121, recall: 0.5565, f1: 0.6604, edges-pos-ontonotes_loss: 0.0331
09/16 11:32:05 AM: Update 15378: task edges-pos-ontonotes, batch 378 (15378): mcc: 0.6666, acc: 0.5037, precision: 0.8118, recall: 0.5565, f1: 0.6604, edges-pos-ontonotes_loss: 0.0332
09/16 11:32:16 AM: Update 15399: task edges-pos-ontonotes, batch 399 (15399): mcc: 0.6672, acc: 0.5043, precision: 0.8123, recall: 0.5571, f1: 0.6609, edges-pos-ontonotes_loss: 0.0332
09/16 11:32:26 AM: Update 15416: task edges-pos-ontonotes, batch 416 (15416): mcc: 0.6665, acc: 0.5035, precision: 0.8121, recall: 0.5562, f1: 0.6602, edges-pos-ontonotes_loss: 0.0332
09/16 11:32:36 AM: Update 15441: task edges-pos-ontonotes, batch 441 (15441): mcc: 0.6668, acc: 0.5039, precision: 0.8120, recall: 0.5568, f1: 0.6606, edges-pos-ontonotes_loss: 0.0331
09/16 11:32:46 AM: Update 15464: task edges-pos-ontonotes, batch 464 (15464): mcc: 0.6666, acc: 0.5035, precision: 0.8122, recall: 0.5562, f1: 0.6602, edges-pos-ontonotes_loss: 0.0332
09/16 11:32:56 AM: Update 15490: task edges-pos-ontonotes, batch 490 (15490): mcc: 0.6673, acc: 0.5044, precision: 0.8126, recall: 0.5571, f1: 0.6610, edges-pos-ontonotes_loss: 0.0331
09/16 11:33:07 AM: Update 15514: task edges-pos-ontonotes, batch 514 (15514): mcc: 0.6676, acc: 0.5048, precision: 0.8127, recall: 0.5575, f1: 0.6613, edges-pos-ontonotes_loss: 0.0331
09/16 11:33:17 AM: Update 15538: task edges-pos-ontonotes, batch 538 (15538): mcc: 0.6679, acc: 0.5052, precision: 0.8126, recall: 0.5581, f1: 0.6617, edges-pos-ontonotes_loss: 0.0331
09/16 11:33:28 AM: Update 15563: task edges-pos-ontonotes, batch 563 (15563): mcc: 0.6683, acc: 0.5056, precision: 0.8128, recall: 0.5586, f1: 0.6621, edges-pos-ontonotes_loss: 0.0330
09/16 11:33:38 AM: Update 15584: task edges-pos-ontonotes, batch 584 (15584): mcc: 0.6681, acc: 0.5054, precision: 0.8127, recall: 0.5583, f1: 0.6619, edges-pos-ontonotes_loss: 0.0331
09/16 11:33:48 AM: Update 15615: task edges-pos-ontonotes, batch 615 (15615): mcc: 0.6681, acc: 0.5055, precision: 0.8127, recall: 0.5583, f1: 0.6619, edges-pos-ontonotes_loss: 0.0331
09/16 11:33:58 AM: Update 15650: task edges-pos-ontonotes, batch 650 (15650): mcc: 0.6686, acc: 0.5062, precision: 0.8131, recall: 0.5589, f1: 0.6625, edges-pos-ontonotes_loss: 0.0330
09/16 11:34:08 AM: Update 15675: task edges-pos-ontonotes, batch 675 (15675): mcc: 0.6691, acc: 0.5068, precision: 0.8135, recall: 0.5595, f1: 0.6630, edges-pos-ontonotes_loss: 0.0330
09/16 11:34:18 AM: Update 15700: task edges-pos-ontonotes, batch 700 (15700): mcc: 0.6692, acc: 0.5069, precision: 0.8135, recall: 0.5596, f1: 0.6631, edges-pos-ontonotes_loss: 0.0330
09/16 11:34:28 AM: Update 15721: task edges-pos-ontonotes, batch 721 (15721): mcc: 0.6682, acc: 0.5057, precision: 0.8131, recall: 0.5583, f1: 0.6620, edges-pos-ontonotes_loss: 0.0330
09/16 11:34:39 AM: Update 15746: task edges-pos-ontonotes, batch 746 (15746): mcc: 0.6680, acc: 0.5054, precision: 0.8133, recall: 0.5578, f1: 0.6617, edges-pos-ontonotes_loss: 0.0329
09/16 11:34:49 AM: Update 15769: task edges-pos-ontonotes, batch 769 (15769): mcc: 0.6681, acc: 0.5054, precision: 0.8134, recall: 0.5578, f1: 0.6618, edges-pos-ontonotes_loss: 0.0329
09/16 11:34:59 AM: Update 15797: task edges-pos-ontonotes, batch 797 (15797): mcc: 0.6688, acc: 0.5062, precision: 0.8139, recall: 0.5586, f1: 0.6625, edges-pos-ontonotes_loss: 0.0327
09/16 11:35:10 AM: Update 15821: task edges-pos-ontonotes, batch 821 (15821): mcc: 0.6690, acc: 0.5064, precision: 0.8140, recall: 0.5589, f1: 0.6627, edges-pos-ontonotes_loss: 0.0327
09/16 11:35:20 AM: Update 15844: task edges-pos-ontonotes, batch 844 (15844): mcc: 0.6687, acc: 0.5060, precision: 0.8140, recall: 0.5585, f1: 0.6624, edges-pos-ontonotes_loss: 0.0326
09/16 11:35:30 AM: Update 15869: task edges-pos-ontonotes, batch 869 (15869): mcc: 0.6691, acc: 0.5065, precision: 0.8140, recall: 0.5591, f1: 0.6629, edges-pos-ontonotes_loss: 0.0325
09/16 11:35:40 AM: Update 15897: task edges-pos-ontonotes, batch 897 (15897): mcc: 0.6699, acc: 0.5074, precision: 0.8146, recall: 0.5600, f1: 0.6637, edges-pos-ontonotes_loss: 0.0324
09/16 11:35:51 AM: Update 15921: task edges-pos-ontonotes, batch 921 (15921): mcc: 0.6699, acc: 0.5073, precision: 0.8147, recall: 0.5600, f1: 0.6637, edges-pos-ontonotes_loss: 0.0323
09/16 11:36:01 AM: Update 15948: task edges-pos-ontonotes, batch 948 (15948): mcc: 0.6708, acc: 0.5084, precision: 0.8153, recall: 0.5611, f1: 0.6647, edges-pos-ontonotes_loss: 0.0322
09/16 11:36:11 AM: Update 15987: task edges-pos-ontonotes, batch 987 (15987): mcc: 0.6713, acc: 0.5090, precision: 0.8156, recall: 0.5617, f1: 0.6652, edges-pos-ontonotes_loss: 0.0321
09/16 11:36:14 AM: ***** Step 16000 / Validation 16 *****
09/16 11:36:14 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 11:36:14 AM: Validating...
09/16 11:36:21 AM: Evaluate: task edges-pos-ontonotes, batch 38 (157): mcc: 0.7597, acc: 0.6154, precision: 0.9193, recall: 0.6343, f1: 0.7507, edges-pos-ontonotes_loss: 0.0243
09/16 11:36:31 AM: Evaluate: task edges-pos-ontonotes, batch 70 (157): mcc: 0.7643, acc: 0.6208, precision: 0.9222, recall: 0.6399, f1: 0.7556, edges-pos-ontonotes_loss: 0.0240
09/16 11:36:41 AM: Evaluate: task edges-pos-ontonotes, batch 97 (157): mcc: 0.7664, acc: 0.6245, precision: 0.9203, recall: 0.6446, f1: 0.7582, edges-pos-ontonotes_loss: 0.0238
09/16 11:36:51 AM: Evaluate: task edges-pos-ontonotes, batch 122 (157): mcc: 0.7634, acc: 0.6204, precision: 0.9189, recall: 0.6408, f1: 0.7550, edges-pos-ontonotes_loss: 0.0240
09/16 11:37:02 AM: Evaluate: task edges-pos-ontonotes, batch 147 (157): mcc: 0.7589, acc: 0.6136, precision: 0.9161, recall: 0.6352, f1: 0.7503, edges-pos-ontonotes_loss: 0.0242
09/16 11:37:05 AM: Updating LR scheduler:
09/16 11:37:05 AM: 	Best result seen so far for macro_avg: 0.756
09/16 11:37:05 AM: 	# validation passes without improvement: 1
09/16 11:37:05 AM: edges-pos-ontonotes_loss: training: 0.032021 validation: 0.024171
09/16 11:37:05 AM: macro_avg: validation: 0.750796
09/16 11:37:05 AM: micro_avg: validation: 0.000000
09/16 11:37:05 AM: edges-pos-ontonotes_mcc: training: 0.671404 validation: 0.759533
09/16 11:37:05 AM: edges-pos-ontonotes_acc: training: 0.509074 validation: 0.613998
09/16 11:37:05 AM: edges-pos-ontonotes_precision: training: 0.815499 validation: 0.917283
09/16 11:37:05 AM: edges-pos-ontonotes_recall: training: 0.561824 validation: 0.635459
09/16 11:37:05 AM: edges-pos-ontonotes_f1: training: 0.665300 validation: 0.750796
09/16 11:37:05 AM: Global learning rate: 0.0001
09/16 11:37:05 AM: Saving checkpoints to: ./experiments/pos-ontonotes-multiqa-top/run
09/16 11:37:12 AM: Update 16017: task edges-pos-ontonotes, batch 17 (16017): mcc: 0.7001, acc: 0.5428, precision: 0.8274, recall: 0.6012, f1: 0.6964, edges-pos-ontonotes_loss: 0.0280
09/16 11:37:22 AM: Update 16036: task edges-pos-ontonotes, batch 36 (16036): mcc: 0.6735, acc: 0.5098, precision: 0.8168, recall: 0.5644, f1: 0.6676, edges-pos-ontonotes_loss: 0.0301
09/16 11:37:32 AM: Update 16066: task edges-pos-ontonotes, batch 66 (16066): mcc: 0.7015, acc: 0.5434, precision: 0.8332, recall: 0.5993, f1: 0.6972, edges-pos-ontonotes_loss: 0.0280
09/16 11:37:42 AM: Update 16095: task edges-pos-ontonotes, batch 95 (16095): mcc: 0.7142, acc: 0.5590, precision: 0.8416, recall: 0.6145, f1: 0.7103, edges-pos-ontonotes_loss: 0.0272
09/16 11:37:53 AM: Update 16125: task edges-pos-ontonotes, batch 125 (16125): mcc: 0.7236, acc: 0.5713, precision: 0.8462, recall: 0.6269, f1: 0.7203, edges-pos-ontonotes_loss: 0.0266
09/16 11:38:03 AM: Update 16154: task edges-pos-ontonotes, batch 154 (16154): mcc: 0.7291, acc: 0.5785, precision: 0.8494, recall: 0.6339, f1: 0.7260, edges-pos-ontonotes_loss: 0.0263
09/16 11:38:13 AM: Update 16183: task edges-pos-ontonotes, batch 183 (16183): mcc: 0.7322, acc: 0.5822, precision: 0.8513, recall: 0.6379, f1: 0.7293, edges-pos-ontonotes_loss: 0.0262
09/16 11:38:23 AM: Update 16214: task edges-pos-ontonotes, batch 214 (16214): mcc: 0.7361, acc: 0.5874, precision: 0.8527, recall: 0.6435, f1: 0.7335, edges-pos-ontonotes_loss: 0.0259
09/16 11:38:33 AM: Update 16247: task edges-pos-ontonotes, batch 247 (16247): mcc: 0.7392, acc: 0.5910, precision: 0.8548, recall: 0.6472, f1: 0.7366, edges-pos-ontonotes_loss: 0.0258
09/16 11:38:43 AM: Update 16310: task edges-pos-ontonotes, batch 310 (16310): mcc: 0.7418, acc: 0.5946, precision: 0.8558, recall: 0.6509, f1: 0.7394, edges-pos-ontonotes_loss: 0.0257
09/16 11:38:53 AM: Update 16348: task edges-pos-ontonotes, batch 348 (16348): mcc: 0.7412, acc: 0.5939, precision: 0.8561, recall: 0.6496, f1: 0.7387, edges-pos-ontonotes_loss: 0.0256
09/16 11:39:03 AM: Update 16400: task edges-pos-ontonotes, batch 400 (16400): mcc: 0.7424, acc: 0.5960, precision: 0.8569, recall: 0.6512, f1: 0.7400, edges-pos-ontonotes_loss: 0.0255
09/16 11:39:14 AM: Update 16430: task edges-pos-ontonotes, batch 430 (16430): mcc: 0.7428, acc: 0.5967, precision: 0.8570, recall: 0.6518, f1: 0.7404, edges-pos-ontonotes_loss: 0.0255
09/16 11:39:24 AM: Update 16465: task edges-pos-ontonotes, batch 465 (16465): mcc: 0.7439, acc: 0.5983, precision: 0.8577, recall: 0.6531, f1: 0.7415, edges-pos-ontonotes_loss: 0.0252
09/16 11:39:34 AM: Update 16498: task edges-pos-ontonotes, batch 498 (16498): mcc: 0.7448, acc: 0.5996, precision: 0.8581, recall: 0.6543, f1: 0.7425, edges-pos-ontonotes_loss: 0.0251
09/16 11:39:44 AM: Update 16529: task edges-pos-ontonotes, batch 529 (16529): mcc: 0.7448, acc: 0.5998, precision: 0.8581, recall: 0.6544, f1: 0.7425, edges-pos-ontonotes_loss: 0.0251
09/16 11:39:54 AM: Update 16562: task edges-pos-ontonotes, batch 562 (16562): mcc: 0.7458, acc: 0.6014, precision: 0.8583, recall: 0.6559, f1: 0.7436, edges-pos-ontonotes_loss: 0.0250
09/16 11:40:04 AM: Update 16597: task edges-pos-ontonotes, batch 597 (16597): mcc: 0.7469, acc: 0.6031, precision: 0.8592, recall: 0.6572, f1: 0.7447, edges-pos-ontonotes_loss: 0.0249
09/16 11:40:14 AM: Update 16632: task edges-pos-ontonotes, batch 632 (16632): mcc: 0.7484, acc: 0.6051, precision: 0.8600, recall: 0.6591, f1: 0.7463, edges-pos-ontonotes_loss: 0.0248
09/16 11:40:25 AM: Update 16659: task edges-pos-ontonotes, batch 659 (16659): mcc: 0.7472, acc: 0.6035, precision: 0.8596, recall: 0.6572, f1: 0.7449, edges-pos-ontonotes_loss: 0.0248
09/16 11:40:35 AM: Update 16700: task edges-pos-ontonotes, batch 700 (16700): mcc: 0.7454, acc: 0.6011, precision: 0.8586, recall: 0.6549, f1: 0.7430, edges-pos-ontonotes_loss: 0.0249
09/16 11:40:45 AM: Update 16741: task edges-pos-ontonotes, batch 741 (16741): mcc: 0.7447, acc: 0.6002, precision: 0.8581, recall: 0.6542, f1: 0.7424, edges-pos-ontonotes_loss: 0.0250
09/16 11:40:56 AM: Update 16781: task edges-pos-ontonotes, batch 781 (16781): mcc: 0.7441, acc: 0.5996, precision: 0.8576, recall: 0.6535, f1: 0.7418, edges-pos-ontonotes_loss: 0.0251
09/16 11:41:06 AM: Update 16869: task edges-pos-ontonotes, batch 869 (16869): mcc: 0.7424, acc: 0.5978, precision: 0.8563, recall: 0.6515, f1: 0.7400, edges-pos-ontonotes_loss: 0.0252
09/16 11:41:16 AM: Update 16950: task edges-pos-ontonotes, batch 950 (16950): mcc: 0.7402, acc: 0.5950, precision: 0.8548, recall: 0.6489, f1: 0.7377, edges-pos-ontonotes_loss: 0.0252
09/16 11:41:26 AM: Update 16975: task edges-pos-ontonotes, batch 975 (16975): mcc: 0.7369, acc: 0.5907, precision: 0.8530, recall: 0.6446, f1: 0.7343, edges-pos-ontonotes_loss: 0.0253
09/16 11:41:37 AM: Update 16999: task edges-pos-ontonotes, batch 999 (16999): mcc: 0.7315, acc: 0.5839, precision: 0.8495, recall: 0.6381, f1: 0.7288, edges-pos-ontonotes_loss: 0.0255
09/16 11:41:37 AM: ***** Step 17000 / Validation 17 *****
09/16 11:41:37 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 11:41:37 AM: Validating...
09/16 11:41:47 AM: Evaluate: task edges-pos-ontonotes, batch 38 (157): mcc: 0.7692, acc: 0.6304, precision: 0.9124, recall: 0.6551, f1: 0.7626, edges-pos-ontonotes_loss: 0.0234
09/16 11:41:57 AM: Evaluate: task edges-pos-ontonotes, batch 71 (157): mcc: 0.7768, acc: 0.6402, precision: 0.9170, recall: 0.6644, f1: 0.7705, edges-pos-ontonotes_loss: 0.0229
09/16 11:42:07 AM: Evaluate: task edges-pos-ontonotes, batch 101 (157): mcc: 0.7728, acc: 0.6342, precision: 0.9149, recall: 0.6592, f1: 0.7663, edges-pos-ontonotes_loss: 0.0232
09/16 11:42:17 AM: Evaluate: task edges-pos-ontonotes, batch 127 (157): mcc: 0.7640, acc: 0.6224, precision: 0.9097, recall: 0.6484, f1: 0.7571, edges-pos-ontonotes_loss: 0.0238
09/16 11:42:27 AM: Evaluate: task edges-pos-ontonotes, batch 152 (157): mcc: 0.7591, acc: 0.6145, precision: 0.9083, recall: 0.6412, f1: 0.7517, edges-pos-ontonotes_loss: 0.0241
09/16 11:42:29 AM: Updating LR scheduler:
09/16 11:42:29 AM: 	Best result seen so far for macro_avg: 0.756
09/16 11:42:29 AM: 	# validation passes without improvement: 2
09/16 11:42:29 AM: edges-pos-ontonotes_loss: training: 0.025514 validation: 0.024149
09/16 11:42:29 AM: macro_avg: validation: 0.750972
09/16 11:42:29 AM: micro_avg: validation: 0.000000
09/16 11:42:29 AM: edges-pos-ontonotes_mcc: training: 0.731533 validation: 0.758533
09/16 11:42:29 AM: edges-pos-ontonotes_acc: training: 0.583922 validation: 0.613469
09/16 11:42:29 AM: edges-pos-ontonotes_precision: training: 0.849471 validation: 0.908693
09/16 11:42:29 AM: edges-pos-ontonotes_recall: training: 0.638108 validation: 0.639904
09/16 11:42:29 AM: edges-pos-ontonotes_f1: training: 0.728773 validation: 0.750972
09/16 11:42:29 AM: Global learning rate: 0.0001
09/16 11:42:29 AM: Saving checkpoints to: ./experiments/pos-ontonotes-multiqa-top/run
09/16 11:42:38 AM: Update 17021: task edges-pos-ontonotes, batch 21 (17021): mcc: 0.6652, acc: 0.4994, precision: 0.7997, recall: 0.5627, f1: 0.6606, edges-pos-ontonotes_loss: 0.0335
09/16 11:42:48 AM: Update 17045: task edges-pos-ontonotes, batch 45 (17045): mcc: 0.6631, acc: 0.4968, precision: 0.7996, recall: 0.5593, f1: 0.6582, edges-pos-ontonotes_loss: 0.0336
09/16 11:42:58 AM: Update 17068: task edges-pos-ontonotes, batch 68 (17068): mcc: 0.6598, acc: 0.4924, precision: 0.7998, recall: 0.5538, f1: 0.6545, edges-pos-ontonotes_loss: 0.0337
09/16 11:43:08 AM: Update 17090: task edges-pos-ontonotes, batch 90 (17090): mcc: 0.6524, acc: 0.4835, precision: 0.7974, recall: 0.5432, f1: 0.6462, edges-pos-ontonotes_loss: 0.0345
09/16 11:43:18 AM: Update 17116: task edges-pos-ontonotes, batch 116 (17116): mcc: 0.6533, acc: 0.4851, precision: 0.7975, recall: 0.5447, f1: 0.6473, edges-pos-ontonotes_loss: 0.0342
09/16 11:43:28 AM: Update 17140: task edges-pos-ontonotes, batch 140 (17140): mcc: 0.6519, acc: 0.4836, precision: 0.7964, recall: 0.5432, f1: 0.6459, edges-pos-ontonotes_loss: 0.0342
09/16 11:43:39 AM: Update 17182: task edges-pos-ontonotes, batch 182 (17182): mcc: 0.6514, acc: 0.4831, precision: 0.7965, recall: 0.5423, f1: 0.6452, edges-pos-ontonotes_loss: 0.0343
09/16 11:43:49 AM: Update 17217: task edges-pos-ontonotes, batch 217 (17217): mcc: 0.6524, acc: 0.4843, precision: 0.7977, recall: 0.5430, f1: 0.6462, edges-pos-ontonotes_loss: 0.0342
09/16 11:44:00 AM: Update 17243: task edges-pos-ontonotes, batch 243 (17243): mcc: 0.6515, acc: 0.4836, precision: 0.7975, recall: 0.5417, f1: 0.6452, edges-pos-ontonotes_loss: 0.0343
09/16 11:44:10 AM: Update 17266: task edges-pos-ontonotes, batch 266 (17266): mcc: 0.6517, acc: 0.4838, precision: 0.7978, recall: 0.5418, f1: 0.6453, edges-pos-ontonotes_loss: 0.0342
09/16 11:44:20 AM: Update 17292: task edges-pos-ontonotes, batch 292 (17292): mcc: 0.6525, acc: 0.4848, precision: 0.7987, recall: 0.5426, f1: 0.6462, edges-pos-ontonotes_loss: 0.0342
09/16 11:44:34 AM: Update 17301: task edges-pos-ontonotes, batch 301 (17301): mcc: 0.6525, acc: 0.4849, precision: 0.7988, recall: 0.5425, f1: 0.6462, edges-pos-ontonotes_loss: 0.0341
09/16 11:44:44 AM: Update 17331: task edges-pos-ontonotes, batch 331 (17331): mcc: 0.6541, acc: 0.4867, precision: 0.8006, recall: 0.5439, f1: 0.6477, edges-pos-ontonotes_loss: 0.0337
09/16 11:44:54 AM: Update 17360: task edges-pos-ontonotes, batch 360 (17360): mcc: 0.6552, acc: 0.4879, precision: 0.8021, recall: 0.5446, f1: 0.6487, edges-pos-ontonotes_loss: 0.0334
09/16 11:45:04 AM: Update 17395: task edges-pos-ontonotes, batch 395 (17395): mcc: 0.6582, acc: 0.4915, precision: 0.8043, recall: 0.5480, f1: 0.6518, edges-pos-ontonotes_loss: 0.0328
09/16 11:45:15 AM: Update 17426: task edges-pos-ontonotes, batch 426 (17426): mcc: 0.6603, acc: 0.4940, precision: 0.8056, recall: 0.5504, f1: 0.6540, edges-pos-ontonotes_loss: 0.0325
09/16 11:45:25 AM: Update 17458: task edges-pos-ontonotes, batch 458 (17458): mcc: 0.6627, acc: 0.4971, precision: 0.8075, recall: 0.5531, f1: 0.6565, edges-pos-ontonotes_loss: 0.0322
09/16 11:45:35 AM: Update 17490: task edges-pos-ontonotes, batch 490 (17490): mcc: 0.6635, acc: 0.4982, precision: 0.8084, recall: 0.5539, f1: 0.6574, edges-pos-ontonotes_loss: 0.0319
09/16 11:45:45 AM: Update 17518: task edges-pos-ontonotes, batch 518 (17518): mcc: 0.6642, acc: 0.4990, precision: 0.8089, recall: 0.5545, f1: 0.6580, edges-pos-ontonotes_loss: 0.0318
09/16 11:45:55 AM: Update 17562: task edges-pos-ontonotes, batch 562 (17562): mcc: 0.6664, acc: 0.5019, precision: 0.8103, recall: 0.5573, f1: 0.6604, edges-pos-ontonotes_loss: 0.0315
09/16 11:46:06 AM: Update 17615: task edges-pos-ontonotes, batch 615 (17615): mcc: 0.6678, acc: 0.5037, precision: 0.8115, recall: 0.5588, f1: 0.6618, edges-pos-ontonotes_loss: 0.0311
09/16 11:46:16 AM: Update 17653: task edges-pos-ontonotes, batch 653 (17653): mcc: 0.6682, acc: 0.5043, precision: 0.8112, recall: 0.5596, f1: 0.6623, edges-pos-ontonotes_loss: 0.0310
09/16 11:46:26 AM: Update 17683: task edges-pos-ontonotes, batch 683 (17683): mcc: 0.6697, acc: 0.5061, precision: 0.8118, recall: 0.5616, f1: 0.6639, edges-pos-ontonotes_loss: 0.0309
09/16 11:46:36 AM: Update 17710: task edges-pos-ontonotes, batch 710 (17710): mcc: 0.6700, acc: 0.5066, precision: 0.8119, recall: 0.5621, f1: 0.6643, edges-pos-ontonotes_loss: 0.0309
09/16 11:46:46 AM: Update 17740: task edges-pos-ontonotes, batch 740 (17740): mcc: 0.6712, acc: 0.5082, precision: 0.8124, recall: 0.5637, f1: 0.6656, edges-pos-ontonotes_loss: 0.0308
09/16 11:46:57 AM: Update 17764: task edges-pos-ontonotes, batch 764 (17764): mcc: 0.6722, acc: 0.5095, precision: 0.8130, recall: 0.5649, f1: 0.6666, edges-pos-ontonotes_loss: 0.0307
09/16 11:47:07 AM: Update 17789: task edges-pos-ontonotes, batch 789 (17789): mcc: 0.6724, acc: 0.5099, precision: 0.8129, recall: 0.5654, f1: 0.6669, edges-pos-ontonotes_loss: 0.0307
09/16 11:47:17 AM: Update 17814: task edges-pos-ontonotes, batch 814 (17814): mcc: 0.6731, acc: 0.5107, precision: 0.8132, recall: 0.5663, f1: 0.6676, edges-pos-ontonotes_loss: 0.0307
09/16 11:47:27 AM: Update 17837: task edges-pos-ontonotes, batch 837 (17837): mcc: 0.6726, acc: 0.5102, precision: 0.8127, recall: 0.5658, f1: 0.6671, edges-pos-ontonotes_loss: 0.0308
09/16 11:47:38 AM: Update 17867: task edges-pos-ontonotes, batch 867 (17867): mcc: 0.6733, acc: 0.5112, precision: 0.8131, recall: 0.5667, f1: 0.6679, edges-pos-ontonotes_loss: 0.0307
09/16 11:47:48 AM: Update 17892: task edges-pos-ontonotes, batch 892 (17892): mcc: 0.6732, acc: 0.5111, precision: 0.8131, recall: 0.5666, f1: 0.6678, edges-pos-ontonotes_loss: 0.0307
09/16 11:47:58 AM: Update 17922: task edges-pos-ontonotes, batch 922 (17922): mcc: 0.6744, acc: 0.5125, precision: 0.8138, recall: 0.5680, f1: 0.6690, edges-pos-ontonotes_loss: 0.0306
09/16 11:48:08 AM: Update 17937: task edges-pos-ontonotes, batch 937 (17937): mcc: 0.6730, acc: 0.5109, precision: 0.8129, recall: 0.5663, f1: 0.6676, edges-pos-ontonotes_loss: 0.0307
09/16 11:48:18 AM: Update 17960: task edges-pos-ontonotes, batch 960 (17960): mcc: 0.6724, acc: 0.5102, precision: 0.8124, recall: 0.5656, f1: 0.6669, edges-pos-ontonotes_loss: 0.0307
09/16 11:48:28 AM: ***** Step 18000 / Validation 18 *****
09/16 11:48:28 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 11:48:28 AM: Validating...
09/16 11:48:28 AM: Evaluate: task edges-pos-ontonotes, batch 2 (157): mcc: 0.8046, acc: 0.6844, precision: 0.9113, recall: 0.7167, f1: 0.8023, edges-pos-ontonotes_loss: 0.0206
09/16 11:48:38 AM: Evaluate: task edges-pos-ontonotes, batch 44 (157): mcc: 0.7750, acc: 0.6365, precision: 0.9196, recall: 0.6595, f1: 0.7681, edges-pos-ontonotes_loss: 0.0230
09/16 11:48:49 AM: Evaluate: task edges-pos-ontonotes, batch 75 (157): mcc: 0.7850, acc: 0.6516, precision: 0.9209, recall: 0.6755, f1: 0.7793, edges-pos-ontonotes_loss: 0.0222
09/16 11:48:59 AM: Evaluate: task edges-pos-ontonotes, batch 103 (157): mcc: 0.7807, acc: 0.6457, precision: 0.9195, recall: 0.6691, f1: 0.7746, edges-pos-ontonotes_loss: 0.0225
09/16 11:49:09 AM: Evaluate: task edges-pos-ontonotes, batch 128 (157): mcc: 0.7725, acc: 0.6338, precision: 0.9176, recall: 0.6567, f1: 0.7655, edges-pos-ontonotes_loss: 0.0230
09/16 11:49:19 AM: Evaluate: task edges-pos-ontonotes, batch 154 (157): mcc: 0.7679, acc: 0.6264, precision: 0.9170, recall: 0.6495, f1: 0.7604, edges-pos-ontonotes_loss: 0.0233
09/16 11:49:20 AM: Best result seen so far for edges-pos-ontonotes.
09/16 11:49:20 AM: Best result seen so far for macro.
09/16 11:49:20 AM: Updating LR scheduler:
09/16 11:49:20 AM: 	Best result seen so far for macro_avg: 0.760
09/16 11:49:20 AM: 	# validation passes without improvement: 0
09/16 11:49:20 AM: edges-pos-ontonotes_loss: training: 0.030866 validation: 0.023389
09/16 11:49:20 AM: macro_avg: validation: 0.759697
09/16 11:49:20 AM: micro_avg: validation: 0.000000
09/16 11:49:20 AM: edges-pos-ontonotes_mcc: training: 0.671631 validation: 0.767299
09/16 11:49:20 AM: edges-pos-ontonotes_acc: training: 0.509365 validation: 0.625290
09/16 11:49:20 AM: edges-pos-ontonotes_precision: training: 0.811710 validation: 0.917329
09/16 11:49:20 AM: edges-pos-ontonotes_recall: training: 0.564884 validation: 0.648296
09/16 11:49:20 AM: edges-pos-ontonotes_f1: training: 0.666169 validation: 0.759697
09/16 11:49:20 AM: Global learning rate: 0.0001
09/16 11:49:20 AM: Saving checkpoints to: ./experiments/pos-ontonotes-multiqa-top/run
09/16 11:49:29 AM: Update 18022: task edges-pos-ontonotes, batch 22 (18022): mcc: 0.6633, acc: 0.4989, precision: 0.8033, recall: 0.5570, f1: 0.6579, edges-pos-ontonotes_loss: 0.0337
09/16 11:49:40 AM: Update 18047: task edges-pos-ontonotes, batch 47 (18047): mcc: 0.6629, acc: 0.5005, precision: 0.8037, recall: 0.5562, f1: 0.6574, edges-pos-ontonotes_loss: 0.0333
09/16 11:49:50 AM: Update 18070: task edges-pos-ontonotes, batch 70 (18070): mcc: 0.6567, acc: 0.4917, precision: 0.8013, recall: 0.5475, f1: 0.6505, edges-pos-ontonotes_loss: 0.0338
09/16 11:50:00 AM: Update 18096: task edges-pos-ontonotes, batch 96 (18096): mcc: 0.6587, acc: 0.4938, precision: 0.8029, recall: 0.5498, f1: 0.6527, edges-pos-ontonotes_loss: 0.0335
09/16 11:50:10 AM: Update 18120: task edges-pos-ontonotes, batch 120 (18120): mcc: 0.6571, acc: 0.4920, precision: 0.8020, recall: 0.5478, f1: 0.6509, edges-pos-ontonotes_loss: 0.0335
09/16 11:50:21 AM: Update 18144: task edges-pos-ontonotes, batch 144 (18144): mcc: 0.6596, acc: 0.4951, precision: 0.8037, recall: 0.5507, f1: 0.6536, edges-pos-ontonotes_loss: 0.0333
09/16 11:50:31 AM: Update 18167: task edges-pos-ontonotes, batch 167 (18167): mcc: 0.6593, acc: 0.4945, precision: 0.8037, recall: 0.5501, f1: 0.6532, edges-pos-ontonotes_loss: 0.0333
09/16 11:50:41 AM: Update 18188: task edges-pos-ontonotes, batch 188 (18188): mcc: 0.6606, acc: 0.4958, precision: 0.8050, recall: 0.5514, f1: 0.6545, edges-pos-ontonotes_loss: 0.0333
09/16 11:50:51 AM: Update 18228: task edges-pos-ontonotes, batch 228 (18228): mcc: 0.6624, acc: 0.4977, precision: 0.8061, recall: 0.5535, f1: 0.6564, edges-pos-ontonotes_loss: 0.0331
09/16 11:51:02 AM: Update 18255: task edges-pos-ontonotes, batch 255 (18255): mcc: 0.6609, acc: 0.4958, precision: 0.8051, recall: 0.5519, f1: 0.6549, edges-pos-ontonotes_loss: 0.0332
09/16 11:51:12 AM: Update 18278: task edges-pos-ontonotes, batch 278 (18278): mcc: 0.6614, acc: 0.4965, precision: 0.8054, recall: 0.5524, f1: 0.6553, edges-pos-ontonotes_loss: 0.0331
09/16 11:51:22 AM: Update 18302: task edges-pos-ontonotes, batch 302 (18302): mcc: 0.6620, acc: 0.4972, precision: 0.8060, recall: 0.5531, f1: 0.6560, edges-pos-ontonotes_loss: 0.0331
09/16 11:51:32 AM: Update 18323: task edges-pos-ontonotes, batch 323 (18323): mcc: 0.6620, acc: 0.4975, precision: 0.8058, recall: 0.5532, f1: 0.6560, edges-pos-ontonotes_loss: 0.0332
09/16 11:51:42 AM: Update 18343: task edges-pos-ontonotes, batch 343 (18343): mcc: 0.6614, acc: 0.4968, precision: 0.8057, recall: 0.5522, f1: 0.6553, edges-pos-ontonotes_loss: 0.0333
09/16 11:51:53 AM: Update 18366: task edges-pos-ontonotes, batch 366 (18366): mcc: 0.6614, acc: 0.4970, precision: 0.8056, recall: 0.5522, f1: 0.6553, edges-pos-ontonotes_loss: 0.0333
09/16 11:52:03 AM: Update 18391: task edges-pos-ontonotes, batch 391 (18391): mcc: 0.6616, acc: 0.4972, precision: 0.8059, recall: 0.5524, f1: 0.6555, edges-pos-ontonotes_loss: 0.0333
09/16 11:52:13 AM: Update 18413: task edges-pos-ontonotes, batch 413 (18413): mcc: 0.6619, acc: 0.4977, precision: 0.8064, recall: 0.5526, f1: 0.6558, edges-pos-ontonotes_loss: 0.0332
09/16 11:52:23 AM: Update 18434: task edges-pos-ontonotes, batch 434 (18434): mcc: 0.6624, acc: 0.4982, precision: 0.8067, recall: 0.5532, f1: 0.6563, edges-pos-ontonotes_loss: 0.0332
09/16 11:52:34 AM: Update 18454: task edges-pos-ontonotes, batch 454 (18454): mcc: 0.6625, acc: 0.4982, precision: 0.8068, recall: 0.5532, f1: 0.6564, edges-pos-ontonotes_loss: 0.0332
09/16 11:52:44 AM: Update 18475: task edges-pos-ontonotes, batch 475 (18475): mcc: 0.6620, acc: 0.4977, precision: 0.8065, recall: 0.5527, f1: 0.6559, edges-pos-ontonotes_loss: 0.0333
09/16 11:52:54 AM: Update 18501: task edges-pos-ontonotes, batch 501 (18501): mcc: 0.6628, acc: 0.4987, precision: 0.8071, recall: 0.5536, f1: 0.6568, edges-pos-ontonotes_loss: 0.0332
09/16 11:53:04 AM: Update 18523: task edges-pos-ontonotes, batch 523 (18523): mcc: 0.6630, acc: 0.4989, precision: 0.8072, recall: 0.5538, f1: 0.6569, edges-pos-ontonotes_loss: 0.0331
09/16 11:53:14 AM: Update 18550: task edges-pos-ontonotes, batch 550 (18550): mcc: 0.6633, acc: 0.4993, precision: 0.8073, recall: 0.5543, f1: 0.6573, edges-pos-ontonotes_loss: 0.0332
09/16 11:53:25 AM: Update 18574: task edges-pos-ontonotes, batch 574 (18574): mcc: 0.6632, acc: 0.4992, precision: 0.8074, recall: 0.5540, f1: 0.6571, edges-pos-ontonotes_loss: 0.0331
09/16 11:53:35 AM: Update 18599: task edges-pos-ontonotes, batch 599 (18599): mcc: 0.6637, acc: 0.4998, precision: 0.8076, recall: 0.5547, f1: 0.6577, edges-pos-ontonotes_loss: 0.0331
09/16 11:53:45 AM: Update 18624: task edges-pos-ontonotes, batch 624 (18624): mcc: 0.6641, acc: 0.5003, precision: 0.8078, recall: 0.5552, f1: 0.6581, edges-pos-ontonotes_loss: 0.0331
09/16 11:53:56 AM: Update 18647: task edges-pos-ontonotes, batch 647 (18647): mcc: 0.6641, acc: 0.5003, precision: 0.8079, recall: 0.5552, f1: 0.6581, edges-pos-ontonotes_loss: 0.0331
09/16 11:54:06 AM: Update 18671: task edges-pos-ontonotes, batch 671 (18671): mcc: 0.6644, acc: 0.5006, precision: 0.8080, recall: 0.5555, f1: 0.6584, edges-pos-ontonotes_loss: 0.0331
09/16 11:54:16 AM: Update 18698: task edges-pos-ontonotes, batch 698 (18698): mcc: 0.6653, acc: 0.5017, precision: 0.8085, recall: 0.5567, f1: 0.6594, edges-pos-ontonotes_loss: 0.0330
09/16 11:54:26 AM: Update 18721: task edges-pos-ontonotes, batch 721 (18721): mcc: 0.6654, acc: 0.5018, precision: 0.8086, recall: 0.5567, f1: 0.6594, edges-pos-ontonotes_loss: 0.0330
09/16 11:54:36 AM: Update 18745: task edges-pos-ontonotes, batch 745 (18745): mcc: 0.6657, acc: 0.5022, precision: 0.8087, recall: 0.5572, f1: 0.6598, edges-pos-ontonotes_loss: 0.0330
