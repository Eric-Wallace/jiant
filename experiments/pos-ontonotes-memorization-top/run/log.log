09/16 09:39:17 AM: Git branch: master
09/16 09:39:17 AM: Git SHA: 0869c6f0712662a0adcfe16ed0072c1997d1c5da
09/16 09:39:17 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/pos-ontonotes-memorization-top/",
  "exp_name": "experiments/pos-ontonotes-memorization-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/pos-ontonotes-memorization-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/memorization",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/pos-ontonotes-memorization-top__run",
  "run_dir": "./experiments/pos-ontonotes-memorization-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-pos-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 09:39:17 AM: Saved config to ./experiments/pos-ontonotes-memorization-top/run/params.conf
09/16 09:39:17 AM: Using random seed 1234
09/16 09:39:17 AM: Using GPU 0
09/16 09:39:17 AM: Loading tasks...
09/16 09:39:17 AM: Writing pre-preprocessed tasks to ./experiments/pos-ontonotes-memorization-top/
09/16 09:39:17 AM: 	Creating task edges-pos-ontonotes from scratch.
09/16 09:39:37 AM: Read=110514, Skip=5298, Total=115812 from ./probing_data/edges/ontonotes/const/pos/train.json.retokenized.bert-base-uncased
09/16 09:39:38 AM: Read=15060, Skip=620, Total=15680 from ./probing_data/edges/ontonotes/const/pos/development.json.retokenized.bert-base-uncased
09/16 09:39:42 AM: Read=11462, Skip=755, Total=12217 from ./probing_data/edges/ontonotes/const/pos/test.json.retokenized.bert-base-uncased
09/16 09:39:54 AM: 	Task 'edges-pos-ontonotes': |train|=110514 |val|=15060 |test|=11462
09/16 09:39:54 AM: 	Finished loading tasks: edges-pos-ontonotes.
09/16 09:39:54 AM: 	Building vocab from scratch.
09/16 09:39:54 AM: 	Counting units for task edges-pos-ontonotes.
09/16 09:39:56 AM: 	Task 'edges-pos-ontonotes': adding vocab namespace 'edges-pos-ontonotes_labels'
09/16 09:39:57 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:39:57 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 09:39:58 AM: 	Saved vocab to ./experiments/pos-ontonotes-memorization-top/vocab
09/16 09:39:58 AM: Loading token dictionary from ./experiments/pos-ontonotes-memorization-top/vocab.
09/16 09:39:58 AM: 	Loaded vocab from ./experiments/pos-ontonotes-memorization-top/vocab
09/16 09:39:58 AM: 	Vocab namespace bert_uncased: size 30524
09/16 09:39:58 AM: 	Vocab namespace tokens: size 24015
09/16 09:39:58 AM: 	Vocab namespace chars: size 81
09/16 09:39:58 AM: 	Vocab namespace edges-pos-ontonotes_labels: size 48
09/16 09:39:58 AM: 	Finished building vocab.
09/16 09:39:58 AM: 	Task edges-pos-ontonotes (train): Indexing from scratch.
09/16 09:40:40 AM: 	Task edges-pos-ontonotes (train): Saved 110514 instances to ./experiments/pos-ontonotes-memorization-top/preproc/edges-pos-ontonotes__train_data
09/16 09:40:40 AM: 	Task edges-pos-ontonotes (val): Indexing from scratch.
09/16 09:40:48 AM: 	Task edges-pos-ontonotes (val): Saved 15060 instances to ./experiments/pos-ontonotes-memorization-top/preproc/edges-pos-ontonotes__val_data
09/16 09:40:48 AM: 	Task edges-pos-ontonotes (test): Indexing from scratch.
09/16 09:40:52 AM: 	Task edges-pos-ontonotes (test): Saved 11462 instances to ./experiments/pos-ontonotes-memorization-top/preproc/edges-pos-ontonotes__test_data
09/16 09:40:52 AM: 	Finished indexing tasks
09/16 09:40:52 AM: 	Creating trimmed target-only version of edges-pos-ontonotes train.
09/16 09:40:52 AM: 	  Training on 
09/16 09:40:52 AM: 	  Evaluating on edges-pos-ontonotes
09/16 09:40:52 AM: 	Finished loading tasks in 94.429s
09/16 09:40:52 AM: 	 Tasks: ['edges-pos-ontonotes']
09/16 09:40:52 AM: Building model...
09/16 09:40:52 AM: Using BERT model (bert-base-uncased).
09/16 09:40:52 AM: LOADING A FUNETUNED MODEL from: 
09/16 09:40:52 AM: models/memorization
09/16 09:40:52 AM: loading configuration file models/memorization/config.json
09/16 09:40:52 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "random-memorization",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 09:40:52 AM: loading weights file models/memorization/pytorch_model.bin
09/16 09:40:56 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpz9iyaccz
09/16 09:40:57 AM: copying /tmp/tmpz9iyaccz to cache at ./experiments/pos-ontonotes-memorization-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:40:57 AM: creating metadata file for ./experiments/pos-ontonotes-memorization-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:40:57 AM: removing temp file /tmp/tmpz9iyaccz
09/16 09:40:57 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/pos-ontonotes-memorization-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:40:57 AM: Initializing parameters
09/16 09:40:57 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 09:40:57 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 09:40:57 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 09:40:57 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 09:40:57 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 09:40:57 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 09:40:57 AM: 	Task 'edges-pos-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-pos-ontonotes"
}
09/16 09:41:01 AM: Model specification:
09/16 09:41:01 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-pos-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=48, bias=True)
    )
  )
)
09/16 09:41:01 AM: Model parameters:
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:41:01 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:41:01 AM: 	edges-pos-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 09:41:01 AM: 	edges-pos-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 09:41:01 AM: 	edges-pos-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 24576 with torch.Size([48, 512])
09/16 09:41:01 AM: 	edges-pos-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 48 with torch.Size([48])
09/16 09:41:01 AM: Total number of parameters: 109703728 (1.09704e+08)
09/16 09:41:01 AM: Number of trainable parameters: 221488 (221488)
09/16 09:41:01 AM: Finished building model in 9.579s
09/16 09:41:01 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-pos-ontonotes 

09/16 09:42:19 AM: patience = 9
09/16 09:42:19 AM: val_interval = 1000
09/16 09:42:19 AM: max_vals = 250
09/16 09:42:19 AM: cuda_device = 0
09/16 09:42:19 AM: grad_norm = 5.0
09/16 09:42:19 AM: grad_clipping = None
09/16 09:42:19 AM: lr_decay = 0.99
09/16 09:42:19 AM: min_lr = 1e-06
09/16 09:42:19 AM: keep_all_checkpoints = 0
09/16 09:42:19 AM: val_data_limit = 5000
09/16 09:42:19 AM: max_epochs = -1
09/16 09:42:19 AM: dec_val_scale = 250
09/16 09:42:19 AM: training_data_fraction = 1
09/16 09:42:19 AM: type = adam
09/16 09:42:19 AM: parameter_groups = None
09/16 09:42:19 AM: Number of trainable parameters: 221488
09/16 09:42:19 AM: infer_type_and_cast = True
09/16 09:42:19 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:42:19 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:42:19 AM: lr = 0.0001
09/16 09:42:19 AM: amsgrad = True
09/16 09:42:19 AM: type = reduce_on_plateau
09/16 09:42:19 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:42:19 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:42:19 AM: mode = max
09/16 09:42:19 AM: factor = 0.5
09/16 09:42:19 AM: patience = 3
09/16 09:42:19 AM: threshold = 0.0001
09/16 09:42:19 AM: threshold_mode = abs
09/16 09:42:19 AM: verbose = True
09/16 09:42:19 AM: type = adam
09/16 09:42:19 AM: parameter_groups = None
09/16 09:42:19 AM: Number of trainable parameters: 221488
09/16 09:42:19 AM: infer_type_and_cast = True
09/16 09:42:19 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:42:19 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:42:19 AM: lr = 0.0001
09/16 09:42:19 AM: amsgrad = True
09/16 09:42:19 AM: type = reduce_on_plateau
09/16 09:42:19 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:42:19 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:42:19 AM: mode = max
09/16 09:42:19 AM: factor = 0.5
09/16 09:42:19 AM: patience = 3
09/16 09:42:19 AM: threshold = 0.0001
09/16 09:42:19 AM: threshold_mode = abs
09/16 09:42:19 AM: verbose = True
09/16 09:42:19 AM: Starting training without restoring from a checkpoint.
09/16 09:42:19 AM: Training examples per task, before any subsampling: {'edges-pos-ontonotes': 110514}
09/16 09:42:19 AM: Beginning training with stopping criteria based on metric: edges-pos-ontonotes_f1
09/16 09:42:29 AM: Update 51: task edges-pos-ontonotes, batch 51 (51): mcc: 0.0031, acc: 0.0035, precision: 0.0220, recall: 0.1314, f1: 0.0377, edges-pos-ontonotes_loss: 0.3876
09/16 09:42:39 AM: Update 118: task edges-pos-ontonotes, batch 118 (118): mcc: 0.0024, acc: 0.0021, precision: 0.0222, recall: 0.0602, f1: 0.0325, edges-pos-ontonotes_loss: 0.2223
09/16 09:42:49 AM: Update 185: task edges-pos-ontonotes, batch 185 (185): mcc: 0.0114, acc: 0.0140, precision: 0.0291, recall: 0.0520, f1: 0.0373, edges-pos-ontonotes_loss: 0.1698
09/16 09:42:59 AM: Update 250: task edges-pos-ontonotes, batch 250 (250): mcc: 0.0218, acc: 0.0243, precision: 0.0392, recall: 0.0526, f1: 0.0449, edges-pos-ontonotes_loss: 0.1443
09/16 09:43:11 AM: Update 314: task edges-pos-ontonotes, batch 314 (314): mcc: 0.0321, acc: 0.0326, precision: 0.0511, recall: 0.0551, f1: 0.0530, edges-pos-ontonotes_loss: 0.1287
09/16 09:43:22 AM: Update 362: task edges-pos-ontonotes, batch 362 (362): mcc: 0.0335, acc: 0.0312, precision: 0.0556, recall: 0.0498, f1: 0.0525, edges-pos-ontonotes_loss: 0.1208
09/16 09:43:32 AM: Update 414: task edges-pos-ontonotes, batch 414 (414): mcc: 0.0433, acc: 0.0376, precision: 0.0692, recall: 0.0535, f1: 0.0604, edges-pos-ontonotes_loss: 0.1137
09/16 09:43:42 AM: Update 464: task edges-pos-ontonotes, batch 464 (464): mcc: 0.0582, acc: 0.0481, precision: 0.0894, recall: 0.0621, f1: 0.0733, edges-pos-ontonotes_loss: 0.1078
09/16 09:43:52 AM: Update 507: task edges-pos-ontonotes, batch 507 (507): mcc: 0.0762, acc: 0.0603, precision: 0.1146, recall: 0.0730, f1: 0.0892, edges-pos-ontonotes_loss: 0.1035
09/16 09:44:02 AM: Update 555: task edges-pos-ontonotes, batch 555 (555): mcc: 0.0981, acc: 0.0750, precision: 0.1461, recall: 0.0868, f1: 0.1089, edges-pos-ontonotes_loss: 0.0992
09/16 09:44:12 AM: Update 604: task edges-pos-ontonotes, batch 604 (604): mcc: 0.1219, acc: 0.0907, precision: 0.1804, recall: 0.1018, f1: 0.1302, edges-pos-ontonotes_loss: 0.0952
09/16 09:44:22 AM: Update 634: task edges-pos-ontonotes, batch 634 (634): mcc: 0.1383, acc: 0.1013, precision: 0.2046, recall: 0.1121, f1: 0.1449, edges-pos-ontonotes_loss: 0.0930
09/16 09:44:33 AM: Update 672: task edges-pos-ontonotes, batch 672 (672): mcc: 0.1639, acc: 0.1176, precision: 0.2426, recall: 0.1284, f1: 0.1679, edges-pos-ontonotes_loss: 0.0906
09/16 09:44:43 AM: Update 709: task edges-pos-ontonotes, batch 709 (709): mcc: 0.1894, acc: 0.1340, precision: 0.2803, recall: 0.1446, f1: 0.1908, edges-pos-ontonotes_loss: 0.0885
09/16 09:44:53 AM: Update 752: task edges-pos-ontonotes, batch 752 (752): mcc: 0.2128, acc: 0.1491, precision: 0.3150, recall: 0.1596, f1: 0.2119, edges-pos-ontonotes_loss: 0.0862
09/16 09:45:03 AM: Update 797: task edges-pos-ontonotes, batch 797 (797): mcc: 0.2359, acc: 0.1644, precision: 0.3486, recall: 0.1750, f1: 0.2330, edges-pos-ontonotes_loss: 0.0839
09/16 09:45:13 AM: Update 839: task edges-pos-ontonotes, batch 839 (839): mcc: 0.2572, acc: 0.1785, precision: 0.3793, recall: 0.1892, f1: 0.2525, edges-pos-ontonotes_loss: 0.0820
09/16 09:45:23 AM: Update 884: task edges-pos-ontonotes, batch 884 (884): mcc: 0.2783, acc: 0.1929, precision: 0.4090, recall: 0.2038, f1: 0.2720, edges-pos-ontonotes_loss: 0.0799
09/16 09:45:34 AM: Update 921: task edges-pos-ontonotes, batch 921 (921): mcc: 0.2993, acc: 0.2074, precision: 0.4376, recall: 0.2186, f1: 0.2916, edges-pos-ontonotes_loss: 0.0783
09/16 09:45:44 AM: Update 948: task edges-pos-ontonotes, batch 948 (948): mcc: 0.3126, acc: 0.2165, precision: 0.4559, recall: 0.2281, f1: 0.3041, edges-pos-ontonotes_loss: 0.0773
09/16 09:45:54 AM: Update 984: task edges-pos-ontonotes, batch 984 (984): mcc: 0.3276, acc: 0.2268, precision: 0.4763, recall: 0.2388, f1: 0.3181, edges-pos-ontonotes_loss: 0.0759
09/16 09:45:58 AM: ***** Step 1000 / Validation 1 *****
09/16 09:45:58 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 09:45:58 AM: Validating...
09/16 09:46:04 AM: Evaluate: task edges-pos-ontonotes, batch 31 (157): mcc: 0.6627, acc: 0.4685, precision: 0.9282, recall: 0.4796, f1: 0.6325, edges-pos-ontonotes_loss: 0.0368
09/16 09:46:14 AM: Evaluate: task edges-pos-ontonotes, batch 82 (157): mcc: 0.6831, acc: 0.4972, precision: 0.9302, recall: 0.5081, f1: 0.6572, edges-pos-ontonotes_loss: 0.0359
09/16 09:46:24 AM: Evaluate: task edges-pos-ontonotes, batch 117 (157): mcc: 0.6913, acc: 0.5105, precision: 0.9267, recall: 0.5222, f1: 0.6680, edges-pos-ontonotes_loss: 0.0352
09/16 09:46:34 AM: Evaluate: task edges-pos-ontonotes, batch 151 (157): mcc: 0.6946, acc: 0.5153, precision: 0.9267, recall: 0.5272, f1: 0.6720, edges-pos-ontonotes_loss: 0.0350
09/16 09:46:36 AM: Best result seen so far for edges-pos-ontonotes.
09/16 09:46:36 AM: Best result seen so far for micro.
09/16 09:46:36 AM: Best result seen so far for macro.
09/16 09:46:36 AM: Updating LR scheduler:
09/16 09:46:36 AM: 	Best result seen so far for macro_avg: 0.671
09/16 09:46:36 AM: 	# validation passes without improvement: 0
09/16 09:46:36 AM: edges-pos-ontonotes_loss: training: 0.075313 validation: 0.035075
09/16 09:46:36 AM: macro_avg: validation: 0.671220
09/16 09:46:36 AM: micro_avg: validation: 0.000000
09/16 09:46:36 AM: edges-pos-ontonotes_mcc: training: 0.334563 validation: 0.693893
09/16 09:46:36 AM: edges-pos-ontonotes_acc: training: 0.231632 validation: 0.514228
09/16 09:46:36 AM: edges-pos-ontonotes_precision: training: 0.485530 validation: 0.926531
09/16 09:46:36 AM: edges-pos-ontonotes_recall: training: 0.243850 validation: 0.526218
09/16 09:46:36 AM: edges-pos-ontonotes_f1: training: 0.324650 validation: 0.671220
09/16 09:46:36 AM: Global learning rate: 0.0001
09/16 09:46:36 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 09:46:45 AM: Update 1032: task edges-pos-ontonotes, batch 32 (1032): mcc: 0.6522, acc: 0.4616, precision: 0.8934, recall: 0.4833, f1: 0.6272, edges-pos-ontonotes_loss: 0.0389
09/16 09:46:55 AM: Update 1072: task edges-pos-ontonotes, batch 72 (1072): mcc: 0.6597, acc: 0.4725, precision: 0.8939, recall: 0.4939, f1: 0.6363, edges-pos-ontonotes_loss: 0.0380
09/16 09:47:05 AM: Update 1108: task edges-pos-ontonotes, batch 108 (1108): mcc: 0.6671, acc: 0.4823, precision: 0.8957, recall: 0.5039, f1: 0.6450, edges-pos-ontonotes_loss: 0.0376
09/16 09:47:15 AM: Update 1146: task edges-pos-ontonotes, batch 146 (1146): mcc: 0.6725, acc: 0.4900, precision: 0.8960, recall: 0.5119, f1: 0.6515, edges-pos-ontonotes_loss: 0.0369
09/16 09:47:25 AM: Update 1186: task edges-pos-ontonotes, batch 186 (1186): mcc: 0.6767, acc: 0.4963, precision: 0.8951, recall: 0.5187, f1: 0.6568, edges-pos-ontonotes_loss: 0.0365
09/16 09:47:35 AM: Update 1222: task edges-pos-ontonotes, batch 222 (1222): mcc: 0.6811, acc: 0.5027, precision: 0.8953, recall: 0.5253, f1: 0.6621, edges-pos-ontonotes_loss: 0.0361
09/16 09:47:56 AM: Update 1253: task edges-pos-ontonotes, batch 253 (1253): mcc: 0.6851, acc: 0.5084, precision: 0.8952, recall: 0.5315, f1: 0.6670, edges-pos-ontonotes_loss: 0.0357
09/16 09:48:06 AM: Update 1294: task edges-pos-ontonotes, batch 294 (1294): mcc: 0.6890, acc: 0.5139, precision: 0.8955, recall: 0.5373, f1: 0.6716, edges-pos-ontonotes_loss: 0.0352
09/16 09:48:16 AM: Update 1338: task edges-pos-ontonotes, batch 338 (1338): mcc: 0.6931, acc: 0.5200, precision: 0.8956, recall: 0.5436, f1: 0.6765, edges-pos-ontonotes_loss: 0.0347
09/16 09:48:27 AM: Update 1370: task edges-pos-ontonotes, batch 370 (1370): mcc: 0.6965, acc: 0.5248, precision: 0.8958, recall: 0.5487, f1: 0.6805, edges-pos-ontonotes_loss: 0.0344
09/16 09:48:37 AM: Update 1411: task edges-pos-ontonotes, batch 411 (1411): mcc: 0.7007, acc: 0.5308, precision: 0.8961, recall: 0.5551, f1: 0.6855, edges-pos-ontonotes_loss: 0.0340
09/16 09:48:47 AM: Update 1448: task edges-pos-ontonotes, batch 448 (1448): mcc: 0.7047, acc: 0.5363, precision: 0.8965, recall: 0.5610, f1: 0.6902, edges-pos-ontonotes_loss: 0.0336
09/16 09:48:57 AM: Update 1485: task edges-pos-ontonotes, batch 485 (1485): mcc: 0.7081, acc: 0.5415, precision: 0.8966, recall: 0.5665, f1: 0.6943, edges-pos-ontonotes_loss: 0.0334
09/16 09:49:07 AM: Update 1523: task edges-pos-ontonotes, batch 523 (1523): mcc: 0.7111, acc: 0.5459, precision: 0.8967, recall: 0.5711, f1: 0.6978, edges-pos-ontonotes_loss: 0.0331
09/16 09:49:17 AM: Update 1565: task edges-pos-ontonotes, batch 565 (1565): mcc: 0.7145, acc: 0.5508, precision: 0.8970, recall: 0.5763, f1: 0.7017, edges-pos-ontonotes_loss: 0.0327
09/16 09:49:27 AM: Update 1597: task edges-pos-ontonotes, batch 597 (1597): mcc: 0.7166, acc: 0.5539, precision: 0.8970, recall: 0.5796, f1: 0.7042, edges-pos-ontonotes_loss: 0.0324
09/16 09:49:38 AM: Update 1633: task edges-pos-ontonotes, batch 633 (1633): mcc: 0.7195, acc: 0.5583, precision: 0.8968, recall: 0.5844, f1: 0.7077, edges-pos-ontonotes_loss: 0.0321
09/16 09:49:48 AM: Update 1669: task edges-pos-ontonotes, batch 669 (1669): mcc: 0.7224, acc: 0.5627, precision: 0.8969, recall: 0.5890, f1: 0.7111, edges-pos-ontonotes_loss: 0.0319
09/16 09:49:58 AM: Update 1709: task edges-pos-ontonotes, batch 709 (1709): mcc: 0.7249, acc: 0.5663, precision: 0.8969, recall: 0.5929, f1: 0.7139, edges-pos-ontonotes_loss: 0.0316
09/16 09:50:08 AM: Update 1746: task edges-pos-ontonotes, batch 746 (1746): mcc: 0.7272, acc: 0.5698, precision: 0.8968, recall: 0.5967, f1: 0.7166, edges-pos-ontonotes_loss: 0.0314
09/16 09:50:18 AM: Update 1785: task edges-pos-ontonotes, batch 785 (1785): mcc: 0.7293, acc: 0.5730, precision: 0.8968, recall: 0.6002, f1: 0.7191, edges-pos-ontonotes_loss: 0.0312
09/16 09:50:28 AM: Update 1824: task edges-pos-ontonotes, batch 824 (1824): mcc: 0.7316, acc: 0.5765, precision: 0.8969, recall: 0.6038, f1: 0.7218, edges-pos-ontonotes_loss: 0.0310
09/16 09:50:38 AM: Update 1858: task edges-pos-ontonotes, batch 858 (1858): mcc: 0.7339, acc: 0.5800, precision: 0.8970, recall: 0.6076, f1: 0.7245, edges-pos-ontonotes_loss: 0.0307
09/16 09:50:49 AM: Update 1887: task edges-pos-ontonotes, batch 887 (1887): mcc: 0.7355, acc: 0.5826, precision: 0.8967, recall: 0.6104, f1: 0.7264, edges-pos-ontonotes_loss: 0.0306
09/16 09:50:59 AM: Update 1926: task edges-pos-ontonotes, batch 926 (1926): mcc: 0.7377, acc: 0.5857, precision: 0.8967, recall: 0.6139, f1: 0.7288, edges-pos-ontonotes_loss: 0.0304
09/16 09:51:09 AM: Update 1976: task edges-pos-ontonotes, batch 976 (1976): mcc: 0.7398, acc: 0.5888, precision: 0.8967, recall: 0.6174, f1: 0.7313, edges-pos-ontonotes_loss: 0.0301
09/16 09:51:14 AM: ***** Step 2000 / Validation 2 *****
09/16 09:51:14 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 09:51:14 AM: Validating...
09/16 09:51:19 AM: Evaluate: task edges-pos-ontonotes, batch 24 (157): mcc: 0.7822, acc: 0.6523, precision: 0.9176, recall: 0.6731, f1: 0.7766, edges-pos-ontonotes_loss: 0.0250
09/16 09:51:29 AM: Evaluate: task edges-pos-ontonotes, batch 75 (157): mcc: 0.7994, acc: 0.6783, precision: 0.9208, recall: 0.7002, f1: 0.7955, edges-pos-ontonotes_loss: 0.0250
09/16 09:51:39 AM: Evaluate: task edges-pos-ontonotes, batch 113 (157): mcc: 0.8076, acc: 0.6919, precision: 0.9214, recall: 0.7138, f1: 0.8044, edges-pos-ontonotes_loss: 0.0239
09/16 09:51:49 AM: Evaluate: task edges-pos-ontonotes, batch 146 (157): mcc: 0.8124, acc: 0.6997, precision: 0.9225, recall: 0.7214, f1: 0.8097, edges-pos-ontonotes_loss: 0.0233
09/16 09:51:52 AM: Best result seen so far for edges-pos-ontonotes.
09/16 09:51:52 AM: Best result seen so far for macro.
09/16 09:51:52 AM: Updating LR scheduler:
09/16 09:51:52 AM: 	Best result seen so far for macro_avg: 0.812
09/16 09:51:52 AM: 	# validation passes without improvement: 0
09/16 09:51:52 AM: edges-pos-ontonotes_loss: training: 0.029973 validation: 0.023034
09/16 09:51:52 AM: macro_avg: validation: 0.811728
09/16 09:51:52 AM: micro_avg: validation: 0.000000
09/16 09:51:52 AM: edges-pos-ontonotes_mcc: training: 0.740868 validation: 0.814387
09/16 09:51:52 AM: edges-pos-ontonotes_acc: training: 0.590390 validation: 0.702393
09/16 09:51:52 AM: edges-pos-ontonotes_precision: training: 0.896805 validation: 0.923078
09/16 09:51:52 AM: edges-pos-ontonotes_recall: training: 0.619106 validation: 0.724351
09/16 09:51:52 AM: edges-pos-ontonotes_f1: training: 0.732520 validation: 0.811728
09/16 09:51:52 AM: Global learning rate: 0.0001
09/16 09:51:52 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 09:51:59 AM: Update 2036: task edges-pos-ontonotes, batch 36 (2036): mcc: 0.7917, acc: 0.6698, precision: 0.9003, recall: 0.7027, f1: 0.7893, edges-pos-ontonotes_loss: 0.0247
09/16 09:52:09 AM: Update 2088: task edges-pos-ontonotes, batch 88 (2088): mcc: 0.7950, acc: 0.6739, precision: 0.9024, recall: 0.7069, f1: 0.7928, edges-pos-ontonotes_loss: 0.0242
09/16 09:52:19 AM: Update 2129: task edges-pos-ontonotes, batch 129 (2129): mcc: 0.7972, acc: 0.6777, precision: 0.9010, recall: 0.7118, f1: 0.7953, edges-pos-ontonotes_loss: 0.0238
09/16 09:52:30 AM: Update 2177: task edges-pos-ontonotes, batch 177 (2177): mcc: 0.8001, acc: 0.6820, precision: 0.9013, recall: 0.7166, f1: 0.7984, edges-pos-ontonotes_loss: 0.0235
09/16 09:52:40 AM: Update 2217: task edges-pos-ontonotes, batch 217 (2217): mcc: 0.8013, acc: 0.6835, precision: 0.9023, recall: 0.7180, f1: 0.7997, edges-pos-ontonotes_loss: 0.0232
09/16 09:52:50 AM: Update 2277: task edges-pos-ontonotes, batch 277 (2277): mcc: 0.8042, acc: 0.6868, precision: 0.9048, recall: 0.7211, f1: 0.8025, edges-pos-ontonotes_loss: 0.0228
09/16 09:53:00 AM: Update 2339: task edges-pos-ontonotes, batch 339 (2339): mcc: 0.8080, acc: 0.6917, precision: 0.9073, recall: 0.7258, f1: 0.8064, edges-pos-ontonotes_loss: 0.0223
09/16 09:53:10 AM: Update 2398: task edges-pos-ontonotes, batch 398 (2398): mcc: 0.8113, acc: 0.6961, precision: 0.9092, recall: 0.7300, f1: 0.8098, edges-pos-ontonotes_loss: 0.0220
09/16 09:53:20 AM: Update 2461: task edges-pos-ontonotes, batch 461 (2461): mcc: 0.8147, acc: 0.7007, precision: 0.9111, recall: 0.7346, f1: 0.8134, edges-pos-ontonotes_loss: 0.0216
09/16 09:53:31 AM: Update 2508: task edges-pos-ontonotes, batch 508 (2508): mcc: 0.8169, acc: 0.7039, precision: 0.9121, recall: 0.7377, f1: 0.8157, edges-pos-ontonotes_loss: 0.0213
09/16 09:53:41 AM: Update 2588: task edges-pos-ontonotes, batch 588 (2588): mcc: 0.8182, acc: 0.7059, precision: 0.9127, recall: 0.7394, f1: 0.8170, edges-pos-ontonotes_loss: 0.0216
09/16 09:53:51 AM: Update 2656: task edges-pos-ontonotes, batch 656 (2656): mcc: 0.8196, acc: 0.7082, precision: 0.9133, recall: 0.7414, f1: 0.8184, edges-pos-ontonotes_loss: 0.0215
09/16 09:54:01 AM: Update 2734: task edges-pos-ontonotes, batch 734 (2734): mcc: 0.8213, acc: 0.7108, precision: 0.9140, recall: 0.7439, f1: 0.8203, edges-pos-ontonotes_loss: 0.0213
09/16 09:54:11 AM: Update 2803: task edges-pos-ontonotes, batch 803 (2803): mcc: 0.8232, acc: 0.7138, precision: 0.9146, recall: 0.7468, f1: 0.8222, edges-pos-ontonotes_loss: 0.0211
09/16 09:54:21 AM: Update 2864: task edges-pos-ontonotes, batch 864 (2864): mcc: 0.8219, acc: 0.7121, precision: 0.9132, recall: 0.7456, f1: 0.8209, edges-pos-ontonotes_loss: 0.0213
09/16 09:54:31 AM: Update 2968: task edges-pos-ontonotes, batch 968 (2968): mcc: 0.8205, acc: 0.7103, precision: 0.9120, recall: 0.7441, f1: 0.8195, edges-pos-ontonotes_loss: 0.0214
09/16 09:54:35 AM: ***** Step 3000 / Validation 3 *****
09/16 09:54:35 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 09:54:35 AM: Validating...
09/16 09:54:41 AM: Evaluate: task edges-pos-ontonotes, batch 32 (157): mcc: 0.8072, acc: 0.6884, precision: 0.9191, recall: 0.7149, f1: 0.8042, edges-pos-ontonotes_loss: 0.0210
09/16 09:54:51 AM: Evaluate: task edges-pos-ontonotes, batch 80 (157): mcc: 0.8301, acc: 0.7245, precision: 0.9222, recall: 0.7528, f1: 0.8290, edges-pos-ontonotes_loss: 0.0195
09/16 09:55:01 AM: Evaluate: task edges-pos-ontonotes, batch 117 (157): mcc: 0.8317, acc: 0.7286, precision: 0.9189, recall: 0.7583, f1: 0.8309, edges-pos-ontonotes_loss: 0.0194
09/16 09:55:12 AM: Evaluate: task edges-pos-ontonotes, batch 147 (157): mcc: 0.8319, acc: 0.7297, precision: 0.9172, recall: 0.7602, f1: 0.8314, edges-pos-ontonotes_loss: 0.0195
09/16 09:55:15 AM: Best result seen so far for edges-pos-ontonotes.
09/16 09:55:15 AM: Best result seen so far for macro.
09/16 09:55:15 AM: Updating LR scheduler:
09/16 09:55:15 AM: 	Best result seen so far for macro_avg: 0.832
09/16 09:55:15 AM: 	# validation passes without improvement: 0
09/16 09:55:15 AM: edges-pos-ontonotes_loss: training: 0.021437 validation: 0.019408
09/16 09:55:15 AM: macro_avg: validation: 0.832159
09/16 09:55:15 AM: micro_avg: validation: 0.000000
09/16 09:55:15 AM: edges-pos-ontonotes_mcc: training: 0.819995 validation: 0.832682
09/16 09:55:15 AM: edges-pos-ontonotes_acc: training: 0.709718 validation: 0.731018
09/16 09:55:15 AM: edges-pos-ontonotes_precision: training: 0.911408 validation: 0.917556
09/16 09:55:15 AM: edges-pos-ontonotes_recall: training: 0.743712 validation: 0.761305
09/16 09:55:15 AM: edges-pos-ontonotes_f1: training: 0.819065 validation: 0.832159
09/16 09:55:15 AM: Global learning rate: 0.0001
09/16 09:55:15 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 09:55:22 AM: Update 3056: task edges-pos-ontonotes, batch 56 (3056): mcc: 0.8067, acc: 0.6943, precision: 0.8966, recall: 0.7322, f1: 0.8061, edges-pos-ontonotes_loss: 0.0221
09/16 09:55:34 AM: Update 3131: task edges-pos-ontonotes, batch 131 (3131): mcc: 0.8092, acc: 0.6981, precision: 0.8941, recall: 0.7388, f1: 0.8090, edges-pos-ontonotes_loss: 0.0217
09/16 09:55:44 AM: Update 3169: task edges-pos-ontonotes, batch 169 (3169): mcc: 0.8036, acc: 0.6905, precision: 0.8871, recall: 0.7346, f1: 0.8037, edges-pos-ontonotes_loss: 0.0223
09/16 09:55:54 AM: Update 3204: task edges-pos-ontonotes, batch 204 (3204): mcc: 0.8011, acc: 0.6877, precision: 0.8845, recall: 0.7323, f1: 0.8013, edges-pos-ontonotes_loss: 0.0226
09/16 09:56:04 AM: Update 3245: task edges-pos-ontonotes, batch 245 (3245): mcc: 0.8012, acc: 0.6881, precision: 0.8842, recall: 0.7328, f1: 0.8014, edges-pos-ontonotes_loss: 0.0229
09/16 09:56:15 AM: Update 3281: task edges-pos-ontonotes, batch 281 (3281): mcc: 0.8010, acc: 0.6876, precision: 0.8841, recall: 0.7325, f1: 0.8012, edges-pos-ontonotes_loss: 0.0230
09/16 09:56:25 AM: Update 3324: task edges-pos-ontonotes, batch 324 (3324): mcc: 0.8014, acc: 0.6884, precision: 0.8840, recall: 0.7331, f1: 0.8015, edges-pos-ontonotes_loss: 0.0232
09/16 09:56:35 AM: Update 3371: task edges-pos-ontonotes, batch 371 (3371): mcc: 0.8017, acc: 0.6887, precision: 0.8849, recall: 0.7331, f1: 0.8019, edges-pos-ontonotes_loss: 0.0231
09/16 09:56:45 AM: Update 3414: task edges-pos-ontonotes, batch 414 (3414): mcc: 0.8026, acc: 0.6898, precision: 0.8855, recall: 0.7341, f1: 0.8027, edges-pos-ontonotes_loss: 0.0231
09/16 09:56:55 AM: Update 3452: task edges-pos-ontonotes, batch 452 (3452): mcc: 0.8025, acc: 0.6900, precision: 0.8854, recall: 0.7340, f1: 0.8026, edges-pos-ontonotes_loss: 0.0230
09/16 09:57:08 AM: Update 3461: task edges-pos-ontonotes, batch 461 (3461): mcc: 0.8024, acc: 0.6899, precision: 0.8853, recall: 0.7340, f1: 0.8026, edges-pos-ontonotes_loss: 0.0230
09/16 09:57:19 AM: Update 3519: task edges-pos-ontonotes, batch 519 (3519): mcc: 0.8029, acc: 0.6903, precision: 0.8867, recall: 0.7338, f1: 0.8030, edges-pos-ontonotes_loss: 0.0229
09/16 09:57:29 AM: Update 3584: task edges-pos-ontonotes, batch 584 (3584): mcc: 0.8045, acc: 0.6922, precision: 0.8882, recall: 0.7353, f1: 0.8046, edges-pos-ontonotes_loss: 0.0225
09/16 09:57:39 AM: Update 3654: task edges-pos-ontonotes, batch 654 (3654): mcc: 0.8055, acc: 0.6935, precision: 0.8890, recall: 0.7364, f1: 0.8055, edges-pos-ontonotes_loss: 0.0222
09/16 09:57:49 AM: Update 3705: task edges-pos-ontonotes, batch 705 (3705): mcc: 0.8065, acc: 0.6949, precision: 0.8897, recall: 0.7376, f1: 0.8065, edges-pos-ontonotes_loss: 0.0220
09/16 09:57:59 AM: Update 3767: task edges-pos-ontonotes, batch 767 (3767): mcc: 0.8077, acc: 0.6965, precision: 0.8906, recall: 0.7389, f1: 0.8077, edges-pos-ontonotes_loss: 0.0218
09/16 09:58:09 AM: Update 3804: task edges-pos-ontonotes, batch 804 (3804): mcc: 0.8089, acc: 0.6983, precision: 0.8912, recall: 0.7406, f1: 0.8090, edges-pos-ontonotes_loss: 0.0217
09/16 09:58:20 AM: Update 3848: task edges-pos-ontonotes, batch 848 (3848): mcc: 0.8100, acc: 0.6999, precision: 0.8917, recall: 0.7423, f1: 0.8101, edges-pos-ontonotes_loss: 0.0216
09/16 09:58:30 AM: Update 3886: task edges-pos-ontonotes, batch 886 (3886): mcc: 0.8111, acc: 0.7015, precision: 0.8921, recall: 0.7438, f1: 0.8113, edges-pos-ontonotes_loss: 0.0215
09/16 09:58:40 AM: Update 3937: task edges-pos-ontonotes, batch 937 (3937): mcc: 0.8122, acc: 0.7031, precision: 0.8926, recall: 0.7454, f1: 0.8124, edges-pos-ontonotes_loss: 0.0213
09/16 09:58:50 AM: Update 3989: task edges-pos-ontonotes, batch 989 (3989): mcc: 0.8133, acc: 0.7046, precision: 0.8932, recall: 0.7469, f1: 0.8135, edges-pos-ontonotes_loss: 0.0212
09/16 09:58:52 AM: ***** Step 4000 / Validation 4 *****
09/16 09:58:52 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 09:58:52 AM: Validating...
09/16 09:59:00 AM: Evaluate: task edges-pos-ontonotes, batch 41 (157): mcc: 0.8573, acc: 0.7688, precision: 0.9346, recall: 0.7913, f1: 0.8570, edges-pos-ontonotes_loss: 0.0163
09/16 09:59:10 AM: Evaluate: task edges-pos-ontonotes, batch 88 (157): mcc: 0.8687, acc: 0.7877, precision: 0.9361, recall: 0.8108, f1: 0.8690, edges-pos-ontonotes_loss: 0.0155
09/16 09:59:20 AM: Evaluate: task edges-pos-ontonotes, batch 122 (157): mcc: 0.8667, acc: 0.7864, precision: 0.9334, recall: 0.8095, f1: 0.8671, edges-pos-ontonotes_loss: 0.0157
09/16 09:59:30 AM: Evaluate: task edges-pos-ontonotes, batch 154 (157): mcc: 0.8654, acc: 0.7855, precision: 0.9315, recall: 0.8089, f1: 0.8658, edges-pos-ontonotes_loss: 0.0159
09/16 09:59:31 AM: Best result seen so far for edges-pos-ontonotes.
09/16 09:59:31 AM: Best result seen so far for macro.
09/16 09:59:31 AM: Updating LR scheduler:
09/16 09:59:31 AM: 	Best result seen so far for macro_avg: 0.866
09/16 09:59:31 AM: 	# validation passes without improvement: 0
09/16 09:59:31 AM: edges-pos-ontonotes_loss: training: 0.021159 validation: 0.015875
09/16 09:59:31 AM: macro_avg: validation: 0.865593
09/16 09:59:31 AM: micro_avg: validation: 0.000000
09/16 09:59:31 AM: edges-pos-ontonotes_mcc: training: 0.813374 validation: 0.865184
09/16 09:59:31 AM: edges-pos-ontonotes_acc: training: 0.704778 validation: 0.785147
09/16 09:59:31 AM: edges-pos-ontonotes_precision: training: 0.893249 validation: 0.931346
09/16 09:59:31 AM: edges-pos-ontonotes_recall: training: 0.747015 validation: 0.808512
09/16 09:59:31 AM: edges-pos-ontonotes_f1: training: 0.813613 validation: 0.865593
09/16 09:59:31 AM: Global learning rate: 0.0001
09/16 09:59:31 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 09:59:41 AM: Update 4045: task edges-pos-ontonotes, batch 45 (4045): mcc: 0.8306, acc: 0.7294, precision: 0.9002, recall: 0.7723, f1: 0.8313, edges-pos-ontonotes_loss: 0.0198
09/16 09:59:51 AM: Update 4086: task edges-pos-ontonotes, batch 86 (4086): mcc: 0.8331, acc: 0.7337, precision: 0.9013, recall: 0.7760, f1: 0.8340, edges-pos-ontonotes_loss: 0.0195
09/16 10:00:01 AM: Update 4117: task edges-pos-ontonotes, batch 117 (4117): mcc: 0.8276, acc: 0.7270, precision: 0.8968, recall: 0.7698, f1: 0.8285, edges-pos-ontonotes_loss: 0.0202
09/16 10:00:11 AM: Update 4153: task edges-pos-ontonotes, batch 153 (4153): mcc: 0.8261, acc: 0.7247, precision: 0.8965, recall: 0.7673, f1: 0.8269, edges-pos-ontonotes_loss: 0.0206
09/16 10:00:21 AM: Update 4187: task edges-pos-ontonotes, batch 187 (4187): mcc: 0.8252, acc: 0.7235, precision: 0.8958, recall: 0.7664, f1: 0.8260, edges-pos-ontonotes_loss: 0.0206
09/16 10:00:31 AM: Update 4227: task edges-pos-ontonotes, batch 227 (4227): mcc: 0.8252, acc: 0.7237, precision: 0.8955, recall: 0.7665, f1: 0.8260, edges-pos-ontonotes_loss: 0.0207
09/16 10:00:42 AM: Update 4264: task edges-pos-ontonotes, batch 264 (4264): mcc: 0.8262, acc: 0.7251, precision: 0.8959, recall: 0.7680, f1: 0.8270, edges-pos-ontonotes_loss: 0.0206
09/16 10:00:52 AM: Update 4301: task edges-pos-ontonotes, batch 301 (4301): mcc: 0.8261, acc: 0.7252, precision: 0.8951, recall: 0.7686, f1: 0.8270, edges-pos-ontonotes_loss: 0.0206
09/16 10:01:02 AM: Update 4340: task edges-pos-ontonotes, batch 340 (4340): mcc: 0.8265, acc: 0.7260, precision: 0.8954, recall: 0.7690, f1: 0.8274, edges-pos-ontonotes_loss: 0.0206
09/16 10:01:12 AM: Update 4376: task edges-pos-ontonotes, batch 376 (4376): mcc: 0.8266, acc: 0.7262, precision: 0.8957, recall: 0.7689, f1: 0.8275, edges-pos-ontonotes_loss: 0.0205
09/16 10:01:22 AM: Update 4403: task edges-pos-ontonotes, batch 403 (4403): mcc: 0.8266, acc: 0.7261, precision: 0.8956, recall: 0.7690, f1: 0.8275, edges-pos-ontonotes_loss: 0.0205
09/16 10:01:33 AM: Update 4440: task edges-pos-ontonotes, batch 440 (4440): mcc: 0.8263, acc: 0.7256, precision: 0.8954, recall: 0.7687, f1: 0.8272, edges-pos-ontonotes_loss: 0.0205
09/16 10:01:43 AM: Update 4477: task edges-pos-ontonotes, batch 477 (4477): mcc: 0.8264, acc: 0.7257, precision: 0.8954, recall: 0.7688, f1: 0.8273, edges-pos-ontonotes_loss: 0.0204
09/16 10:01:53 AM: Update 4514: task edges-pos-ontonotes, batch 514 (4514): mcc: 0.8269, acc: 0.7264, precision: 0.8958, recall: 0.7694, f1: 0.8278, edges-pos-ontonotes_loss: 0.0204
09/16 10:02:03 AM: Update 4547: task edges-pos-ontonotes, batch 547 (4547): mcc: 0.8267, acc: 0.7261, precision: 0.8957, recall: 0.7691, f1: 0.8276, edges-pos-ontonotes_loss: 0.0204
09/16 10:02:13 AM: Update 4581: task edges-pos-ontonotes, batch 581 (4581): mcc: 0.8269, acc: 0.7266, precision: 0.8958, recall: 0.7695, f1: 0.8278, edges-pos-ontonotes_loss: 0.0204
09/16 10:02:23 AM: Update 4619: task edges-pos-ontonotes, batch 619 (4619): mcc: 0.8273, acc: 0.7271, precision: 0.8961, recall: 0.7698, f1: 0.8282, edges-pos-ontonotes_loss: 0.0203
09/16 10:02:34 AM: Update 4651: task edges-pos-ontonotes, batch 651 (4651): mcc: 0.8277, acc: 0.7279, precision: 0.8964, recall: 0.7704, f1: 0.8286, edges-pos-ontonotes_loss: 0.0202
09/16 10:02:44 AM: Update 4681: task edges-pos-ontonotes, batch 681 (4681): mcc: 0.8280, acc: 0.7284, precision: 0.8967, recall: 0.7707, f1: 0.8289, edges-pos-ontonotes_loss: 0.0202
09/16 10:02:55 AM: Update 4713: task edges-pos-ontonotes, batch 713 (4713): mcc: 0.8284, acc: 0.7290, precision: 0.8969, recall: 0.7712, f1: 0.8293, edges-pos-ontonotes_loss: 0.0201
09/16 10:03:05 AM: Update 4748: task edges-pos-ontonotes, batch 748 (4748): mcc: 0.8287, acc: 0.7293, precision: 0.8971, recall: 0.7715, f1: 0.8296, edges-pos-ontonotes_loss: 0.0201
09/16 10:03:15 AM: Update 4784: task edges-pos-ontonotes, batch 784 (4784): mcc: 0.8289, acc: 0.7297, precision: 0.8972, recall: 0.7718, f1: 0.8298, edges-pos-ontonotes_loss: 0.0200
09/16 10:03:25 AM: Update 4819: task edges-pos-ontonotes, batch 819 (4819): mcc: 0.8293, acc: 0.7303, precision: 0.8974, recall: 0.7724, f1: 0.8302, edges-pos-ontonotes_loss: 0.0200
09/16 10:03:35 AM: Update 4857: task edges-pos-ontonotes, batch 857 (4857): mcc: 0.8297, acc: 0.7309, precision: 0.8976, recall: 0.7729, f1: 0.8306, edges-pos-ontonotes_loss: 0.0199
09/16 10:03:46 AM: Update 4895: task edges-pos-ontonotes, batch 895 (4895): mcc: 0.8302, acc: 0.7317, precision: 0.8980, recall: 0.7735, f1: 0.8311, edges-pos-ontonotes_loss: 0.0199
09/16 10:03:56 AM: Update 4935: task edges-pos-ontonotes, batch 935 (4935): mcc: 0.8305, acc: 0.7323, precision: 0.8981, recall: 0.7740, f1: 0.8314, edges-pos-ontonotes_loss: 0.0199
09/16 10:04:06 AM: Update 4972: task edges-pos-ontonotes, batch 972 (4972): mcc: 0.8310, acc: 0.7331, precision: 0.8984, recall: 0.7747, f1: 0.8320, edges-pos-ontonotes_loss: 0.0198
09/16 10:04:14 AM: ***** Step 5000 / Validation 5 *****
09/16 10:04:14 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 10:04:14 AM: Validating...
09/16 10:04:16 AM: Evaluate: task edges-pos-ontonotes, batch 8 (157): mcc: 0.8643, acc: 0.7919, precision: 0.9252, recall: 0.8123, f1: 0.8651, edges-pos-ontonotes_loss: 0.0152
09/16 10:04:26 AM: Evaluate: task edges-pos-ontonotes, batch 55 (157): mcc: 0.8661, acc: 0.7858, precision: 0.9306, recall: 0.8108, f1: 0.8666, edges-pos-ontonotes_loss: 0.0157
09/16 10:04:36 AM: Evaluate: task edges-pos-ontonotes, batch 98 (157): mcc: 0.8741, acc: 0.8002, precision: 0.9310, recall: 0.8252, f1: 0.8749, edges-pos-ontonotes_loss: 0.0150
09/16 10:04:47 AM: Evaluate: task edges-pos-ontonotes, batch 130 (157): mcc: 0.8754, acc: 0.8028, precision: 0.9313, recall: 0.8273, f1: 0.8763, edges-pos-ontonotes_loss: 0.0149
09/16 10:04:55 AM: Best result seen so far for edges-pos-ontonotes.
09/16 10:04:55 AM: Best result seen so far for macro.
09/16 10:04:55 AM: Updating LR scheduler:
09/16 10:04:55 AM: 	Best result seen so far for macro_avg: 0.879
09/16 10:04:55 AM: 	# validation passes without improvement: 0
09/16 10:04:55 AM: edges-pos-ontonotes_loss: training: 0.019758 validation: 0.014614
09/16 10:04:55 AM: macro_avg: validation: 0.878798
09/16 10:04:55 AM: micro_avg: validation: 0.000000
09/16 10:04:55 AM: edges-pos-ontonotes_mcc: training: 0.831307 validation: 0.877868
09/16 10:04:55 AM: edges-pos-ontonotes_acc: training: 0.733662 validation: 0.807285
09/16 10:04:55 AM: edges-pos-ontonotes_precision: training: 0.898447 validation: 0.932165
09/16 10:04:55 AM: edges-pos-ontonotes_recall: training: 0.775154 validation: 0.831212
09/16 10:04:55 AM: edges-pos-ontonotes_f1: training: 0.832259 validation: 0.878798
09/16 10:04:55 AM: Global learning rate: 0.0001
09/16 10:04:55 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 10:04:57 AM: Update 5006: task edges-pos-ontonotes, batch 6 (5006): mcc: 0.8466, acc: 0.7566, precision: 0.9096, recall: 0.7934, f1: 0.8475, edges-pos-ontonotes_loss: 0.0178
09/16 10:05:14 AM: Update 5026: task edges-pos-ontonotes, batch 26 (5026): mcc: 0.8419, acc: 0.7504, precision: 0.9051, recall: 0.7888, f1: 0.8430, edges-pos-ontonotes_loss: 0.0181
09/16 10:05:24 AM: Update 5068: task edges-pos-ontonotes, batch 68 (5068): mcc: 0.8405, acc: 0.7488, precision: 0.9043, recall: 0.7870, f1: 0.8415, edges-pos-ontonotes_loss: 0.0190
09/16 10:05:35 AM: Update 5110: task edges-pos-ontonotes, batch 110 (5110): mcc: 0.8401, acc: 0.7479, precision: 0.9034, recall: 0.7869, f1: 0.8411, edges-pos-ontonotes_loss: 0.0190
09/16 10:05:45 AM: Update 5148: task edges-pos-ontonotes, batch 148 (5148): mcc: 0.8408, acc: 0.7487, precision: 0.9035, recall: 0.7882, f1: 0.8419, edges-pos-ontonotes_loss: 0.0188
09/16 10:05:55 AM: Update 5189: task edges-pos-ontonotes, batch 189 (5189): mcc: 0.8413, acc: 0.7495, precision: 0.9037, recall: 0.7889, f1: 0.8424, edges-pos-ontonotes_loss: 0.0187
09/16 10:06:05 AM: Update 5224: task edges-pos-ontonotes, batch 224 (5224): mcc: 0.8412, acc: 0.7496, precision: 0.9031, recall: 0.7893, f1: 0.8424, edges-pos-ontonotes_loss: 0.0187
09/16 10:06:15 AM: Update 5261: task edges-pos-ontonotes, batch 261 (5261): mcc: 0.8412, acc: 0.7498, precision: 0.9026, recall: 0.7898, f1: 0.8424, edges-pos-ontonotes_loss: 0.0187
09/16 10:06:25 AM: Update 5295: task edges-pos-ontonotes, batch 295 (5295): mcc: 0.8416, acc: 0.7505, precision: 0.9030, recall: 0.7901, f1: 0.8428, edges-pos-ontonotes_loss: 0.0186
09/16 10:06:35 AM: Update 5328: task edges-pos-ontonotes, batch 328 (5328): mcc: 0.8419, acc: 0.7509, precision: 0.9032, recall: 0.7905, f1: 0.8431, edges-pos-ontonotes_loss: 0.0186
09/16 10:06:45 AM: Update 5351: task edges-pos-ontonotes, batch 351 (5351): mcc: 0.8419, acc: 0.7509, precision: 0.9028, recall: 0.7908, f1: 0.8431, edges-pos-ontonotes_loss: 0.0185
09/16 10:06:56 AM: Update 5391: task edges-pos-ontonotes, batch 391 (5391): mcc: 0.8426, acc: 0.7518, precision: 0.9033, recall: 0.7916, f1: 0.8438, edges-pos-ontonotes_loss: 0.0184
09/16 10:07:06 AM: Update 5441: task edges-pos-ontonotes, batch 441 (5441): mcc: 0.8436, acc: 0.7531, precision: 0.9038, recall: 0.7931, f1: 0.8449, edges-pos-ontonotes_loss: 0.0181
09/16 10:07:16 AM: Update 5491: task edges-pos-ontonotes, batch 491 (5491): mcc: 0.8445, acc: 0.7541, precision: 0.9045, recall: 0.7942, f1: 0.8457, edges-pos-ontonotes_loss: 0.0179
09/16 10:07:26 AM: Update 5540: task edges-pos-ontonotes, batch 540 (5540): mcc: 0.8453, acc: 0.7551, precision: 0.9051, recall: 0.7951, f1: 0.8465, edges-pos-ontonotes_loss: 0.0177
09/16 10:07:36 AM: Update 5583: task edges-pos-ontonotes, batch 583 (5583): mcc: 0.8460, acc: 0.7560, precision: 0.9054, recall: 0.7960, f1: 0.8472, edges-pos-ontonotes_loss: 0.0176
09/16 10:07:46 AM: Update 5622: task edges-pos-ontonotes, batch 622 (5622): mcc: 0.8465, acc: 0.7568, precision: 0.9056, recall: 0.7968, f1: 0.8478, edges-pos-ontonotes_loss: 0.0175
09/16 10:07:56 AM: Update 5657: task edges-pos-ontonotes, batch 657 (5657): mcc: 0.8469, acc: 0.7573, precision: 0.9058, recall: 0.7974, f1: 0.8482, edges-pos-ontonotes_loss: 0.0174
09/16 10:08:06 AM: Update 5710: task edges-pos-ontonotes, batch 710 (5710): mcc: 0.8484, acc: 0.7591, precision: 0.9069, recall: 0.7991, f1: 0.8496, edges-pos-ontonotes_loss: 0.0172
09/16 10:08:16 AM: Update 5772: task edges-pos-ontonotes, batch 772 (5772): mcc: 0.8502, acc: 0.7614, precision: 0.9082, recall: 0.8012, f1: 0.8514, edges-pos-ontonotes_loss: 0.0170
09/16 10:08:26 AM: Update 5834: task edges-pos-ontonotes, batch 834 (5834): mcc: 0.8518, acc: 0.7636, precision: 0.9093, recall: 0.8033, f1: 0.8530, edges-pos-ontonotes_loss: 0.0167
09/16 10:08:36 AM: Update 5898: task edges-pos-ontonotes, batch 898 (5898): mcc: 0.8534, acc: 0.7657, precision: 0.9103, recall: 0.8054, f1: 0.8546, edges-pos-ontonotes_loss: 0.0165
09/16 10:08:46 AM: Update 5957: task edges-pos-ontonotes, batch 957 (5957): mcc: 0.8547, acc: 0.7676, precision: 0.9113, recall: 0.8069, f1: 0.8559, edges-pos-ontonotes_loss: 0.0163
09/16 10:08:55 AM: ***** Step 6000 / Validation 6 *****
09/16 10:08:55 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 10:08:55 AM: Validating...
09/16 10:08:56 AM: Evaluate: task edges-pos-ontonotes, batch 8 (157): mcc: 0.8633, acc: 0.7907, precision: 0.9289, recall: 0.8072, f1: 0.8638, edges-pos-ontonotes_loss: 0.0155
09/16 10:09:06 AM: Evaluate: task edges-pos-ontonotes, batch 59 (157): mcc: 0.8717, acc: 0.7939, precision: 0.9358, recall: 0.8167, f1: 0.8722, edges-pos-ontonotes_loss: 0.0151
09/16 10:09:16 AM: Evaluate: task edges-pos-ontonotes, batch 98 (157): mcc: 0.8757, acc: 0.8011, precision: 0.9364, recall: 0.8234, f1: 0.8763, edges-pos-ontonotes_loss: 0.0146
09/16 10:09:27 AM: Evaluate: task edges-pos-ontonotes, batch 130 (157): mcc: 0.8742, acc: 0.7983, precision: 0.9383, recall: 0.8190, f1: 0.8746, edges-pos-ontonotes_loss: 0.0146
09/16 10:09:34 AM: Updating LR scheduler:
09/16 10:09:34 AM: 	Best result seen so far for macro_avg: 0.879
09/16 10:09:34 AM: 	# validation passes without improvement: 1
09/16 10:09:34 AM: edges-pos-ontonotes_loss: training: 0.016313 validation: 0.014436
09/16 10:09:34 AM: macro_avg: validation: 0.875461
09/16 10:09:34 AM: micro_avg: validation: 0.000000
09/16 10:09:34 AM: edges-pos-ontonotes_mcc: training: 0.855307 validation: 0.875056
09/16 10:09:34 AM: edges-pos-ontonotes_acc: training: 0.768470 validation: 0.800258
09/16 10:09:34 AM: edges-pos-ontonotes_precision: training: 0.911658 validation: 0.938629
09/16 10:09:34 AM: edges-pos-ontonotes_recall: training: 0.807714 validation: 0.820259
09/16 10:09:34 AM: edges-pos-ontonotes_f1: training: 0.856544 validation: 0.875461
09/16 10:09:34 AM: Global learning rate: 0.0001
09/16 10:09:34 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 10:09:37 AM: Update 6019: task edges-pos-ontonotes, batch 19 (6019): mcc: 0.8698, acc: 0.7876, precision: 0.9238, recall: 0.8238, f1: 0.8709, edges-pos-ontonotes_loss: 0.0164
09/16 10:09:47 AM: Update 6099: task edges-pos-ontonotes, batch 99 (6099): mcc: 0.8748, acc: 0.7959, precision: 0.9260, recall: 0.8311, f1: 0.8760, edges-pos-ontonotes_loss: 0.0154
09/16 10:09:57 AM: Update 6160: task edges-pos-ontonotes, batch 160 (6160): mcc: 0.8745, acc: 0.7955, precision: 0.9254, recall: 0.8311, f1: 0.8757, edges-pos-ontonotes_loss: 0.0152
09/16 10:10:07 AM: Update 6224: task edges-pos-ontonotes, batch 224 (6224): mcc: 0.8761, acc: 0.7976, precision: 0.9257, recall: 0.8337, f1: 0.8773, edges-pos-ontonotes_loss: 0.0148
09/16 10:10:17 AM: Update 6290: task edges-pos-ontonotes, batch 290 (6290): mcc: 0.8745, acc: 0.7958, precision: 0.9241, recall: 0.8322, f1: 0.8758, edges-pos-ontonotes_loss: 0.0150
09/16 10:10:27 AM: Update 6374: task edges-pos-ontonotes, batch 374 (6374): mcc: 0.8674, acc: 0.7855, precision: 0.9187, recall: 0.8238, f1: 0.8687, edges-pos-ontonotes_loss: 0.0159
09/16 10:10:37 AM: Update 6455: task edges-pos-ontonotes, batch 455 (6455): mcc: 0.8624, acc: 0.7783, precision: 0.9151, recall: 0.8178, f1: 0.8637, edges-pos-ontonotes_loss: 0.0163
09/16 10:10:47 AM: Update 6555: task edges-pos-ontonotes, batch 555 (6555): mcc: 0.8595, acc: 0.7741, precision: 0.9130, recall: 0.8142, f1: 0.8608, edges-pos-ontonotes_loss: 0.0165
09/16 10:10:58 AM: Update 6605: task edges-pos-ontonotes, batch 605 (6605): mcc: 0.8571, acc: 0.7708, precision: 0.9109, recall: 0.8118, f1: 0.8585, edges-pos-ontonotes_loss: 0.0168
09/16 10:11:08 AM: Update 6644: task edges-pos-ontonotes, batch 644 (6644): mcc: 0.8534, acc: 0.7653, precision: 0.9079, recall: 0.8076, f1: 0.8548, edges-pos-ontonotes_loss: 0.0171
09/16 10:11:18 AM: Update 6689: task edges-pos-ontonotes, batch 689 (6689): mcc: 0.8510, acc: 0.7618, precision: 0.9058, recall: 0.8050, f1: 0.8524, edges-pos-ontonotes_loss: 0.0172
09/16 10:11:28 AM: Update 6723: task edges-pos-ontonotes, batch 723 (6723): mcc: 0.8492, acc: 0.7592, precision: 0.9040, recall: 0.8032, f1: 0.8506, edges-pos-ontonotes_loss: 0.0173
09/16 10:11:38 AM: Update 6759: task edges-pos-ontonotes, batch 759 (6759): mcc: 0.8478, acc: 0.7575, precision: 0.9024, recall: 0.8021, f1: 0.8493, edges-pos-ontonotes_loss: 0.0174
09/16 10:11:48 AM: Update 6794: task edges-pos-ontonotes, batch 794 (6794): mcc: 0.8469, acc: 0.7562, precision: 0.9016, recall: 0.8012, f1: 0.8484, edges-pos-ontonotes_loss: 0.0175
09/16 10:11:58 AM: Update 6831: task edges-pos-ontonotes, batch 831 (6831): mcc: 0.8461, acc: 0.7552, precision: 0.9008, recall: 0.8005, f1: 0.8477, edges-pos-ontonotes_loss: 0.0176
09/16 10:12:09 AM: Update 6871: task edges-pos-ontonotes, batch 871 (6871): mcc: 0.8455, acc: 0.7544, precision: 0.9004, recall: 0.7997, f1: 0.8470, edges-pos-ontonotes_loss: 0.0176
09/16 10:12:19 AM: Update 6912: task edges-pos-ontonotes, batch 912 (6912): mcc: 0.8449, acc: 0.7536, precision: 0.8999, recall: 0.7990, f1: 0.8465, edges-pos-ontonotes_loss: 0.0177
09/16 10:12:29 AM: Update 6958: task edges-pos-ontonotes, batch 958 (6958): mcc: 0.8445, acc: 0.7528, precision: 0.8999, recall: 0.7982, f1: 0.8460, edges-pos-ontonotes_loss: 0.0177
09/16 10:12:38 AM: ***** Step 7000 / Validation 7 *****
09/16 10:12:38 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 10:12:38 AM: Validating...
09/16 10:12:39 AM: Evaluate: task edges-pos-ontonotes, batch 6 (157): mcc: 0.8837, acc: 0.8173, precision: 0.9382, recall: 0.8367, f1: 0.8846, edges-pos-ontonotes_loss: 0.0135
09/16 10:12:50 AM: Evaluate: task edges-pos-ontonotes, batch 58 (157): mcc: 0.8818, acc: 0.8103, precision: 0.9382, recall: 0.8331, f1: 0.8826, edges-pos-ontonotes_loss: 0.0138
09/16 10:13:00 AM: Evaluate: task edges-pos-ontonotes, batch 101 (157): mcc: 0.8854, acc: 0.8170, precision: 0.9365, recall: 0.8413, f1: 0.8863, edges-pos-ontonotes_loss: 0.0135
09/16 10:13:10 AM: Evaluate: task edges-pos-ontonotes, batch 133 (157): mcc: 0.8832, acc: 0.8140, precision: 0.9349, recall: 0.8388, f1: 0.8842, edges-pos-ontonotes_loss: 0.0136
09/16 10:13:17 AM: Best result seen so far for edges-pos-ontonotes.
09/16 10:13:17 AM: Best result seen so far for macro.
09/16 10:13:17 AM: Updating LR scheduler:
09/16 10:13:17 AM: 	Best result seen so far for macro_avg: 0.884
09/16 10:13:17 AM: 	# validation passes without improvement: 0
09/16 10:13:17 AM: edges-pos-ontonotes_loss: training: 0.017762 validation: 0.013530
09/16 10:13:17 AM: macro_avg: validation: 0.884452
09/16 10:13:17 AM: micro_avg: validation: 0.000000
09/16 10:13:17 AM: edges-pos-ontonotes_mcc: training: 0.844268 validation: 0.883426
09/16 10:13:17 AM: edges-pos-ontonotes_acc: training: 0.752442 validation: 0.815116
09/16 10:13:17 AM: edges-pos-ontonotes_precision: training: 0.899941 validation: 0.934087
09/16 10:13:17 AM: edges-pos-ontonotes_recall: training: 0.797723 validation: 0.839826
09/16 10:13:17 AM: edges-pos-ontonotes_f1: training: 0.845755 validation: 0.884452
09/16 10:13:17 AM: Global learning rate: 0.0001
09/16 10:13:17 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 10:13:20 AM: Update 7017: task edges-pos-ontonotes, batch 17 (7017): mcc: 0.8467, acc: 0.7544, precision: 0.9051, recall: 0.7976, f1: 0.8479, edges-pos-ontonotes_loss: 0.0170
09/16 10:13:30 AM: Update 7080: task edges-pos-ontonotes, batch 80 (7080): mcc: 0.8458, acc: 0.7530, precision: 0.9056, recall: 0.7956, f1: 0.8470, edges-pos-ontonotes_loss: 0.0164
09/16 10:13:40 AM: Update 7142: task edges-pos-ontonotes, batch 142 (7142): mcc: 0.8430, acc: 0.7493, precision: 0.9040, recall: 0.7917, f1: 0.8441, edges-pos-ontonotes_loss: 0.0169
09/16 10:13:50 AM: Update 7212: task edges-pos-ontonotes, batch 212 (7212): mcc: 0.8435, acc: 0.7499, precision: 0.9049, recall: 0.7919, f1: 0.8446, edges-pos-ontonotes_loss: 0.0168
09/16 10:14:00 AM: Update 7249: task edges-pos-ontonotes, batch 249 (7249): mcc: 0.8448, acc: 0.7519, precision: 0.9040, recall: 0.7951, f1: 0.8461, edges-pos-ontonotes_loss: 0.0168
09/16 10:14:10 AM: Update 7297: task edges-pos-ontonotes, batch 297 (7297): mcc: 0.8461, acc: 0.7538, precision: 0.9041, recall: 0.7975, f1: 0.8474, edges-pos-ontonotes_loss: 0.0168
09/16 10:14:21 AM: Update 7341: task edges-pos-ontonotes, batch 341 (7341): mcc: 0.8466, acc: 0.7544, precision: 0.9039, recall: 0.7985, f1: 0.8479, edges-pos-ontonotes_loss: 0.0169
09/16 10:14:31 AM: Update 7388: task edges-pos-ontonotes, batch 388 (7388): mcc: 0.8466, acc: 0.7544, precision: 0.9038, recall: 0.7987, f1: 0.8480, edges-pos-ontonotes_loss: 0.0169
09/16 10:14:41 AM: Update 7435: task edges-pos-ontonotes, batch 435 (7435): mcc: 0.8472, acc: 0.7554, precision: 0.9035, recall: 0.8000, f1: 0.8486, edges-pos-ontonotes_loss: 0.0170
09/16 10:14:51 AM: Update 7477: task edges-pos-ontonotes, batch 477 (7477): mcc: 0.8473, acc: 0.7555, precision: 0.9034, recall: 0.8002, f1: 0.8487, edges-pos-ontonotes_loss: 0.0170
09/16 10:15:01 AM: Update 7529: task edges-pos-ontonotes, batch 529 (7529): mcc: 0.8479, acc: 0.7565, precision: 0.9037, recall: 0.8011, f1: 0.8493, edges-pos-ontonotes_loss: 0.0169
09/16 10:15:18 AM: Update 7547: task edges-pos-ontonotes, batch 547 (7547): mcc: 0.8476, acc: 0.7561, precision: 0.9034, recall: 0.8007, f1: 0.8490, edges-pos-ontonotes_loss: 0.0169
09/16 10:15:28 AM: Update 7579: task edges-pos-ontonotes, batch 579 (7579): mcc: 0.8468, acc: 0.7553, precision: 0.9026, recall: 0.7999, f1: 0.8482, edges-pos-ontonotes_loss: 0.0170
09/16 10:15:38 AM: Update 7609: task edges-pos-ontonotes, batch 609 (7609): mcc: 0.8461, acc: 0.7546, precision: 0.9020, recall: 0.7993, f1: 0.8476, edges-pos-ontonotes_loss: 0.0171
09/16 10:15:48 AM: Update 7642: task edges-pos-ontonotes, batch 642 (7642): mcc: 0.8462, acc: 0.7548, precision: 0.9017, recall: 0.7999, f1: 0.8477, edges-pos-ontonotes_loss: 0.0172
09/16 10:15:58 AM: Update 7679: task edges-pos-ontonotes, batch 679 (7679): mcc: 0.8457, acc: 0.7543, precision: 0.9009, recall: 0.7996, f1: 0.8472, edges-pos-ontonotes_loss: 0.0173
09/16 10:16:08 AM: Update 7719: task edges-pos-ontonotes, batch 719 (7719): mcc: 0.8459, acc: 0.7546, precision: 0.9007, recall: 0.8000, f1: 0.8474, edges-pos-ontonotes_loss: 0.0173
09/16 10:16:18 AM: Update 7764: task edges-pos-ontonotes, batch 764 (7764): mcc: 0.8462, acc: 0.7551, precision: 0.9010, recall: 0.8004, f1: 0.8477, edges-pos-ontonotes_loss: 0.0174
09/16 10:16:29 AM: Update 7802: task edges-pos-ontonotes, batch 802 (7802): mcc: 0.8465, acc: 0.7555, precision: 0.9011, recall: 0.8007, f1: 0.8480, edges-pos-ontonotes_loss: 0.0174
09/16 10:16:39 AM: Update 7838: task edges-pos-ontonotes, batch 838 (7838): mcc: 0.8465, acc: 0.7556, precision: 0.9011, recall: 0.8009, f1: 0.8480, edges-pos-ontonotes_loss: 0.0174
09/16 10:16:49 AM: Update 7864: task edges-pos-ontonotes, batch 864 (7864): mcc: 0.8461, acc: 0.7551, precision: 0.9007, recall: 0.8005, f1: 0.8477, edges-pos-ontonotes_loss: 0.0174
09/16 10:17:00 AM: Update 7903: task edges-pos-ontonotes, batch 903 (7903): mcc: 0.8459, acc: 0.7548, precision: 0.9006, recall: 0.8003, f1: 0.8475, edges-pos-ontonotes_loss: 0.0175
09/16 10:17:10 AM: Update 7938: task edges-pos-ontonotes, batch 938 (7938): mcc: 0.8461, acc: 0.7551, precision: 0.9006, recall: 0.8006, f1: 0.8476, edges-pos-ontonotes_loss: 0.0175
09/16 10:17:20 AM: Update 7976: task edges-pos-ontonotes, batch 976 (7976): mcc: 0.8462, acc: 0.7554, precision: 0.9006, recall: 0.8008, f1: 0.8478, edges-pos-ontonotes_loss: 0.0175
09/16 10:17:27 AM: ***** Step 8000 / Validation 8 *****
09/16 10:17:27 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 10:17:27 AM: Validating...
09/16 10:17:30 AM: Evaluate: task edges-pos-ontonotes, batch 14 (157): mcc: 0.8753, acc: 0.8041, precision: 0.9313, recall: 0.8272, f1: 0.8761, edges-pos-ontonotes_loss: 0.0138
09/16 10:17:40 AM: Evaluate: task edges-pos-ontonotes, batch 67 (157): mcc: 0.8856, acc: 0.8170, precision: 0.9369, recall: 0.8414, f1: 0.8866, edges-pos-ontonotes_loss: 0.0133
09/16 10:17:50 AM: Evaluate: task edges-pos-ontonotes, batch 107 (157): mcc: 0.8897, acc: 0.8241, precision: 0.9383, recall: 0.8478, f1: 0.8907, edges-pos-ontonotes_loss: 0.0129
09/16 10:18:00 AM: Evaluate: task edges-pos-ontonotes, batch 138 (157): mcc: 0.8895, acc: 0.8243, precision: 0.9373, recall: 0.8483, f1: 0.8906, edges-pos-ontonotes_loss: 0.0129
09/16 10:18:06 AM: Best result seen so far for edges-pos-ontonotes.
09/16 10:18:06 AM: Best result seen so far for macro.
09/16 10:18:06 AM: Updating LR scheduler:
09/16 10:18:06 AM: 	Best result seen so far for macro_avg: 0.892
09/16 10:18:06 AM: 	# validation passes without improvement: 0
09/16 10:18:06 AM: edges-pos-ontonotes_loss: training: 0.017458 validation: 0.012789
09/16 10:18:06 AM: macro_avg: validation: 0.891699
09/16 10:18:06 AM: micro_avg: validation: 0.000000
09/16 10:18:06 AM: edges-pos-ontonotes_mcc: training: 0.846406 validation: 0.890591
09/16 10:18:06 AM: edges-pos-ontonotes_acc: training: 0.755633 validation: 0.826873
09/16 10:18:06 AM: edges-pos-ontonotes_precision: training: 0.900767 validation: 0.936961
09/16 10:18:06 AM: edges-pos-ontonotes_recall: training: 0.800951 validation: 0.850609
09/16 10:18:06 AM: edges-pos-ontonotes_f1: training: 0.847932 validation: 0.891699
09/16 10:18:06 AM: Global learning rate: 0.0001
09/16 10:18:06 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 10:18:11 AM: Update 8016: task edges-pos-ontonotes, batch 16 (8016): mcc: 0.8463, acc: 0.7568, precision: 0.8984, recall: 0.8030, f1: 0.8480, edges-pos-ontonotes_loss: 0.0180
09/16 10:18:21 AM: Update 8051: task edges-pos-ontonotes, batch 51 (8051): mcc: 0.8489, acc: 0.7593, precision: 0.9020, recall: 0.8045, f1: 0.8505, edges-pos-ontonotes_loss: 0.0175
09/16 10:18:31 AM: Update 8087: task edges-pos-ontonotes, batch 87 (8087): mcc: 0.8491, acc: 0.7606, precision: 0.9020, recall: 0.8049, f1: 0.8507, edges-pos-ontonotes_loss: 0.0175
09/16 10:18:41 AM: Update 8123: task edges-pos-ontonotes, batch 123 (8123): mcc: 0.8494, acc: 0.7609, precision: 0.9023, recall: 0.8051, f1: 0.8509, edges-pos-ontonotes_loss: 0.0173
09/16 10:18:51 AM: Update 8161: task edges-pos-ontonotes, batch 161 (8161): mcc: 0.8495, acc: 0.7612, precision: 0.9025, recall: 0.8051, f1: 0.8510, edges-pos-ontonotes_loss: 0.0173
09/16 10:19:01 AM: Update 8185: task edges-pos-ontonotes, batch 185 (8185): mcc: 0.8484, acc: 0.7603, precision: 0.9011, recall: 0.8044, f1: 0.8500, edges-pos-ontonotes_loss: 0.0174
09/16 10:19:12 AM: Update 8221: task edges-pos-ontonotes, batch 221 (8221): mcc: 0.8490, acc: 0.7613, precision: 0.9013, recall: 0.8053, f1: 0.8506, edges-pos-ontonotes_loss: 0.0174
09/16 10:19:22 AM: Update 8250: task edges-pos-ontonotes, batch 250 (8250): mcc: 0.8493, acc: 0.7618, precision: 0.9018, recall: 0.8054, f1: 0.8509, edges-pos-ontonotes_loss: 0.0174
09/16 10:19:32 AM: Update 8289: task edges-pos-ontonotes, batch 289 (8289): mcc: 0.8499, acc: 0.7627, precision: 0.9020, recall: 0.8063, f1: 0.8515, edges-pos-ontonotes_loss: 0.0173
09/16 10:19:42 AM: Update 8326: task edges-pos-ontonotes, batch 326 (8326): mcc: 0.8504, acc: 0.7634, precision: 0.9025, recall: 0.8069, f1: 0.8520, edges-pos-ontonotes_loss: 0.0174
09/16 10:19:52 AM: Update 8363: task edges-pos-ontonotes, batch 363 (8363): mcc: 0.8511, acc: 0.7645, precision: 0.9031, recall: 0.8075, f1: 0.8526, edges-pos-ontonotes_loss: 0.0173
09/16 10:20:02 AM: Update 8401: task edges-pos-ontonotes, batch 401 (8401): mcc: 0.8515, acc: 0.7651, precision: 0.9036, recall: 0.8080, f1: 0.8531, edges-pos-ontonotes_loss: 0.0173
09/16 10:20:12 AM: Update 8438: task edges-pos-ontonotes, batch 438 (8438): mcc: 0.8519, acc: 0.7655, precision: 0.9037, recall: 0.8085, f1: 0.8535, edges-pos-ontonotes_loss: 0.0173
09/16 10:20:23 AM: Update 8474: task edges-pos-ontonotes, batch 474 (8474): mcc: 0.8522, acc: 0.7661, precision: 0.9038, recall: 0.8090, f1: 0.8538, edges-pos-ontonotes_loss: 0.0172
09/16 10:20:33 AM: Update 8501: task edges-pos-ontonotes, batch 501 (8501): mcc: 0.8522, acc: 0.7660, precision: 0.9038, recall: 0.8091, f1: 0.8538, edges-pos-ontonotes_loss: 0.0172
09/16 10:20:43 AM: Update 8536: task edges-pos-ontonotes, batch 536 (8536): mcc: 0.8523, acc: 0.7663, precision: 0.9037, recall: 0.8094, f1: 0.8539, edges-pos-ontonotes_loss: 0.0172
09/16 10:20:53 AM: Update 8574: task edges-pos-ontonotes, batch 574 (8574): mcc: 0.8524, acc: 0.7664, precision: 0.9038, recall: 0.8094, f1: 0.8540, edges-pos-ontonotes_loss: 0.0172
09/16 10:21:03 AM: Update 8614: task edges-pos-ontonotes, batch 614 (8614): mcc: 0.8527, acc: 0.7668, precision: 0.9039, recall: 0.8098, f1: 0.8543, edges-pos-ontonotes_loss: 0.0172
09/16 10:21:13 AM: Update 8652: task edges-pos-ontonotes, batch 652 (8652): mcc: 0.8529, acc: 0.7672, precision: 0.9040, recall: 0.8101, f1: 0.8545, edges-pos-ontonotes_loss: 0.0172
09/16 10:21:23 AM: Update 8692: task edges-pos-ontonotes, batch 692 (8692): mcc: 0.8532, acc: 0.7676, precision: 0.9042, recall: 0.8104, f1: 0.8548, edges-pos-ontonotes_loss: 0.0172
09/16 10:21:34 AM: Update 8736: task edges-pos-ontonotes, batch 736 (8736): mcc: 0.8532, acc: 0.7678, precision: 0.9042, recall: 0.8105, f1: 0.8548, edges-pos-ontonotes_loss: 0.0172
09/16 10:21:44 AM: Update 8767: task edges-pos-ontonotes, batch 767 (8767): mcc: 0.8531, acc: 0.7677, precision: 0.9041, recall: 0.8104, f1: 0.8547, edges-pos-ontonotes_loss: 0.0172
09/16 10:21:55 AM: Update 8799: task edges-pos-ontonotes, batch 799 (8799): mcc: 0.8533, acc: 0.7679, precision: 0.9041, recall: 0.8107, f1: 0.8549, edges-pos-ontonotes_loss: 0.0172
09/16 10:22:05 AM: Update 8840: task edges-pos-ontonotes, batch 840 (8840): mcc: 0.8536, acc: 0.7684, precision: 0.9043, recall: 0.8112, f1: 0.8552, edges-pos-ontonotes_loss: 0.0171
09/16 10:22:15 AM: Update 8875: task edges-pos-ontonotes, batch 875 (8875): mcc: 0.8540, acc: 0.7690, precision: 0.9044, recall: 0.8118, f1: 0.8556, edges-pos-ontonotes_loss: 0.0170
09/16 10:22:25 AM: Update 8926: task edges-pos-ontonotes, batch 926 (8926): mcc: 0.8545, acc: 0.7696, precision: 0.9048, recall: 0.8124, f1: 0.8561, edges-pos-ontonotes_loss: 0.0169
09/16 10:22:35 AM: Update 8964: task edges-pos-ontonotes, batch 964 (8964): mcc: 0.8547, acc: 0.7699, precision: 0.9048, recall: 0.8127, f1: 0.8563, edges-pos-ontonotes_loss: 0.0168
09/16 10:22:43 AM: ***** Step 9000 / Validation 9 *****
09/16 10:22:43 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 10:22:43 AM: Validating...
09/16 10:22:45 AM: Evaluate: task edges-pos-ontonotes, batch 9 (157): mcc: 0.8770, acc: 0.8096, precision: 0.9321, recall: 0.8297, f1: 0.8779, edges-pos-ontonotes_loss: 0.0135
09/16 10:22:55 AM: Evaluate: task edges-pos-ontonotes, batch 56 (157): mcc: 0.8818, acc: 0.8100, precision: 0.9380, recall: 0.8334, f1: 0.8826, edges-pos-ontonotes_loss: 0.0137
09/16 10:23:06 AM: Evaluate: task edges-pos-ontonotes, batch 100 (157): mcc: 0.8878, acc: 0.8205, precision: 0.9388, recall: 0.8438, f1: 0.8887, edges-pos-ontonotes_loss: 0.0131
09/16 10:23:16 AM: Evaluate: task edges-pos-ontonotes, batch 132 (157): mcc: 0.8890, acc: 0.8228, precision: 0.9394, recall: 0.8455, f1: 0.8900, edges-pos-ontonotes_loss: 0.0129
09/16 10:23:23 AM: Best result seen so far for edges-pos-ontonotes.
09/16 10:23:23 AM: Best result seen so far for macro.
09/16 10:23:23 AM: Updating LR scheduler:
09/16 10:23:23 AM: 	Best result seen so far for macro_avg: 0.892
09/16 10:23:23 AM: 	# validation passes without improvement: 0
09/16 10:23:23 AM: edges-pos-ontonotes_loss: training: 0.016727 validation: 0.012708
09/16 10:23:23 AM: macro_avg: validation: 0.892097
09/16 10:23:23 AM: micro_avg: validation: 0.000000
09/16 10:23:23 AM: edges-pos-ontonotes_mcc: training: 0.855047 validation: 0.891102
09/16 10:23:23 AM: edges-pos-ontonotes_acc: training: 0.770321 validation: 0.827000
09/16 10:23:23 AM: edges-pos-ontonotes_precision: training: 0.905118 validation: 0.939530
09/16 10:23:23 AM: edges-pos-ontonotes_recall: training: 0.813116 validation: 0.849223
09/16 10:23:23 AM: edges-pos-ontonotes_f1: training: 0.856654 validation: 0.892097
09/16 10:23:23 AM: Global learning rate: 0.0001
09/16 10:23:23 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 10:23:26 AM: Update 9013: task edges-pos-ontonotes, batch 13 (9013): mcc: 0.8729, acc: 0.7939, precision: 0.9207, recall: 0.8322, f1: 0.8742, edges-pos-ontonotes_loss: 0.0140
09/16 10:23:36 AM: Update 9061: task edges-pos-ontonotes, batch 61 (9061): mcc: 0.8664, acc: 0.7872, precision: 0.9111, recall: 0.8290, f1: 0.8681, edges-pos-ontonotes_loss: 0.0147
09/16 10:23:46 AM: Update 9106: task edges-pos-ontonotes, batch 106 (9106): mcc: 0.8670, acc: 0.7877, precision: 0.9112, recall: 0.8299, f1: 0.8687, edges-pos-ontonotes_loss: 0.0145
09/16 10:24:01 AM: Update 9112: task edges-pos-ontonotes, batch 112 (9112): mcc: 0.8667, acc: 0.7871, precision: 0.9118, recall: 0.8290, f1: 0.8684, edges-pos-ontonotes_loss: 0.0145
09/16 10:24:11 AM: Update 9175: task edges-pos-ontonotes, batch 175 (9175): mcc: 0.8727, acc: 0.7945, precision: 0.9170, recall: 0.8354, f1: 0.8743, edges-pos-ontonotes_loss: 0.0141
09/16 10:24:21 AM: Update 9237: task edges-pos-ontonotes, batch 237 (9237): mcc: 0.8768, acc: 0.7996, precision: 0.9201, recall: 0.8402, f1: 0.8783, edges-pos-ontonotes_loss: 0.0137
09/16 10:24:31 AM: Update 9294: task edges-pos-ontonotes, batch 294 (9294): mcc: 0.8792, acc: 0.8028, precision: 0.9220, recall: 0.8429, f1: 0.8807, edges-pos-ontonotes_loss: 0.0136
09/16 10:24:41 AM: Update 9351: task edges-pos-ontonotes, batch 351 (9351): mcc: 0.8815, acc: 0.8061, precision: 0.9236, recall: 0.8457, f1: 0.8830, edges-pos-ontonotes_loss: 0.0134
09/16 10:24:51 AM: Update 9403: task edges-pos-ontonotes, batch 403 (9403): mcc: 0.8831, acc: 0.8084, precision: 0.9249, recall: 0.8476, f1: 0.8845, edges-pos-ontonotes_loss: 0.0132
09/16 10:25:01 AM: Update 9446: task edges-pos-ontonotes, batch 446 (9446): mcc: 0.8836, acc: 0.8094, precision: 0.9251, recall: 0.8485, f1: 0.8851, edges-pos-ontonotes_loss: 0.0132
09/16 10:25:11 AM: Update 9511: task edges-pos-ontonotes, batch 511 (9511): mcc: 0.8838, acc: 0.8097, precision: 0.9254, recall: 0.8485, f1: 0.8852, edges-pos-ontonotes_loss: 0.0133
09/16 10:25:21 AM: Update 9586: task edges-pos-ontonotes, batch 586 (9586): mcc: 0.8839, acc: 0.8099, precision: 0.9257, recall: 0.8483, f1: 0.8853, edges-pos-ontonotes_loss: 0.0134
09/16 10:25:31 AM: Update 9667: task edges-pos-ontonotes, batch 667 (9667): mcc: 0.8842, acc: 0.8104, precision: 0.9260, recall: 0.8486, f1: 0.8856, edges-pos-ontonotes_loss: 0.0134
09/16 10:25:41 AM: Update 9735: task edges-pos-ontonotes, batch 735 (9735): mcc: 0.8844, acc: 0.8108, precision: 0.9261, recall: 0.8489, f1: 0.8858, edges-pos-ontonotes_loss: 0.0134
09/16 10:25:51 AM: Update 9814: task edges-pos-ontonotes, batch 814 (9814): mcc: 0.8818, acc: 0.8072, precision: 0.9240, recall: 0.8460, f1: 0.8833, edges-pos-ontonotes_loss: 0.0138
09/16 10:26:01 AM: Update 9911: task edges-pos-ontonotes, batch 911 (9911): mcc: 0.8795, acc: 0.8039, precision: 0.9224, recall: 0.8432, f1: 0.8810, edges-pos-ontonotes_loss: 0.0143
09/16 10:26:11 AM: ***** Step 10000 / Validation 10 *****
09/16 10:26:11 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 10:26:11 AM: Validating...
09/16 10:26:12 AM: Evaluate: task edges-pos-ontonotes, batch 3 (157): mcc: 0.8832, acc: 0.8162, precision: 0.9332, recall: 0.8402, f1: 0.8843, edges-pos-ontonotes_loss: 0.0131
09/16 10:26:22 AM: Evaluate: task edges-pos-ontonotes, batch 53 (157): mcc: 0.8835, acc: 0.8126, precision: 0.9366, recall: 0.8377, f1: 0.8844, edges-pos-ontonotes_loss: 0.0136
09/16 10:26:32 AM: Evaluate: task edges-pos-ontonotes, batch 99 (157): mcc: 0.8868, acc: 0.8200, precision: 0.9352, recall: 0.8450, f1: 0.8878, edges-pos-ontonotes_loss: 0.0132
09/16 10:26:42 AM: Evaluate: task edges-pos-ontonotes, batch 129 (157): mcc: 0.8839, acc: 0.8156, precision: 0.9334, recall: 0.8414, f1: 0.8850, edges-pos-ontonotes_loss: 0.0133
09/16 10:26:51 AM: Updating LR scheduler:
09/16 10:26:51 AM: 	Best result seen so far for macro_avg: 0.892
09/16 10:26:51 AM: 	# validation passes without improvement: 1
09/16 10:26:51 AM: edges-pos-ontonotes_loss: training: 0.014442 validation: 0.013191
09/16 10:26:51 AM: macro_avg: validation: 0.885978
09/16 10:26:51 AM: micro_avg: validation: 0.000000
09/16 10:26:51 AM: edges-pos-ontonotes_mcc: training: 0.877771 validation: 0.884823
09/16 10:26:51 AM: edges-pos-ontonotes_acc: training: 0.801459 validation: 0.817846
09/16 10:26:51 AM: edges-pos-ontonotes_precision: training: 0.921133 validation: 0.932524
09/16 10:26:51 AM: edges-pos-ontonotes_recall: training: 0.841059 validation: 0.843857
09/16 10:26:51 AM: edges-pos-ontonotes_f1: training: 0.879277 validation: 0.885978
09/16 10:26:51 AM: Global learning rate: 0.0001
09/16 10:26:51 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 10:26:52 AM: Update 10007: task edges-pos-ontonotes, batch 7 (10007): mcc: 0.8639, acc: 0.7858, precision: 0.9135, recall: 0.8220, f1: 0.8654, edges-pos-ontonotes_loss: 0.0167
09/16 10:27:02 AM: Update 10052: task edges-pos-ontonotes, batch 52 (10052): mcc: 0.8456, acc: 0.7565, precision: 0.8940, recall: 0.8056, f1: 0.8475, edges-pos-ontonotes_loss: 0.0173
09/16 10:27:13 AM: Update 10088: task edges-pos-ontonotes, batch 88 (10088): mcc: 0.8434, acc: 0.7523, precision: 0.8907, recall: 0.8044, f1: 0.8453, edges-pos-ontonotes_loss: 0.0178
09/16 10:27:23 AM: Update 10131: task edges-pos-ontonotes, batch 131 (10131): mcc: 0.8431, acc: 0.7511, precision: 0.8906, recall: 0.8040, f1: 0.8451, edges-pos-ontonotes_loss: 0.0180
09/16 10:27:33 AM: Update 10174: task edges-pos-ontonotes, batch 174 (10174): mcc: 0.8435, acc: 0.7519, precision: 0.8914, recall: 0.8040, f1: 0.8454, edges-pos-ontonotes_loss: 0.0180
09/16 10:27:43 AM: Update 10213: task edges-pos-ontonotes, batch 213 (10213): mcc: 0.8439, acc: 0.7525, precision: 0.8920, recall: 0.8043, f1: 0.8459, edges-pos-ontonotes_loss: 0.0181
09/16 10:27:53 AM: Update 10255: task edges-pos-ontonotes, batch 255 (10255): mcc: 0.8437, acc: 0.7522, precision: 0.8920, recall: 0.8038, f1: 0.8456, edges-pos-ontonotes_loss: 0.0182
09/16 10:28:03 AM: Update 10297: task edges-pos-ontonotes, batch 297 (10297): mcc: 0.8445, acc: 0.7534, precision: 0.8928, recall: 0.8046, f1: 0.8464, edges-pos-ontonotes_loss: 0.0181
09/16 10:28:13 AM: Update 10338: task edges-pos-ontonotes, batch 338 (10338): mcc: 0.8448, acc: 0.7538, precision: 0.8931, recall: 0.8049, f1: 0.8467, edges-pos-ontonotes_loss: 0.0182
09/16 10:28:24 AM: Update 10377: task edges-pos-ontonotes, batch 377 (10377): mcc: 0.8446, acc: 0.7536, precision: 0.8930, recall: 0.8045, f1: 0.8465, edges-pos-ontonotes_loss: 0.0182
09/16 10:28:34 AM: Update 10420: task edges-pos-ontonotes, batch 420 (10420): mcc: 0.8447, acc: 0.7536, precision: 0.8939, recall: 0.8039, f1: 0.8465, edges-pos-ontonotes_loss: 0.0181
09/16 10:28:44 AM: Update 10480: task edges-pos-ontonotes, batch 480 (10480): mcc: 0.8452, acc: 0.7543, precision: 0.8948, recall: 0.8040, f1: 0.8470, edges-pos-ontonotes_loss: 0.0179
09/16 10:28:54 AM: Update 10543: task edges-pos-ontonotes, batch 543 (10543): mcc: 0.8450, acc: 0.7540, precision: 0.8951, recall: 0.8034, f1: 0.8468, edges-pos-ontonotes_loss: 0.0178
09/16 10:29:04 AM: Update 10602: task edges-pos-ontonotes, batch 602 (10602): mcc: 0.8454, acc: 0.7545, precision: 0.8956, recall: 0.8038, f1: 0.8472, edges-pos-ontonotes_loss: 0.0176
09/16 10:29:14 AM: Update 10660: task edges-pos-ontonotes, batch 660 (10660): mcc: 0.8459, acc: 0.7552, precision: 0.8962, recall: 0.8042, f1: 0.8477, edges-pos-ontonotes_loss: 0.0175
09/16 10:29:24 AM: Update 10703: task edges-pos-ontonotes, batch 703 (10703): mcc: 0.8464, acc: 0.7560, precision: 0.8967, recall: 0.8047, f1: 0.8482, edges-pos-ontonotes_loss: 0.0174
09/16 10:29:34 AM: Update 10751: task edges-pos-ontonotes, batch 751 (10751): mcc: 0.8468, acc: 0.7565, precision: 0.8971, recall: 0.8051, f1: 0.8486, edges-pos-ontonotes_loss: 0.0173
09/16 10:29:44 AM: Update 10794: task edges-pos-ontonotes, batch 794 (10794): mcc: 0.8477, acc: 0.7576, precision: 0.8978, recall: 0.8060, f1: 0.8494, edges-pos-ontonotes_loss: 0.0172
09/16 10:29:54 AM: Update 10841: task edges-pos-ontonotes, batch 841 (10841): mcc: 0.8480, acc: 0.7580, precision: 0.8982, recall: 0.8063, f1: 0.8498, edges-pos-ontonotes_loss: 0.0172
09/16 10:30:05 AM: Update 10887: task edges-pos-ontonotes, batch 887 (10887): mcc: 0.8486, acc: 0.7588, precision: 0.8986, recall: 0.8070, f1: 0.8503, edges-pos-ontonotes_loss: 0.0171
09/16 10:30:15 AM: Update 10935: task edges-pos-ontonotes, batch 935 (10935): mcc: 0.8492, acc: 0.7597, precision: 0.8991, recall: 0.8077, f1: 0.8510, edges-pos-ontonotes_loss: 0.0170
09/16 10:30:25 AM: Update 10987: task edges-pos-ontonotes, batch 987 (10987): mcc: 0.8497, acc: 0.7603, precision: 0.8995, recall: 0.8081, f1: 0.8514, edges-pos-ontonotes_loss: 0.0170
09/16 10:30:27 AM: ***** Step 11000 / Validation 11 *****
09/16 10:30:27 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 10:30:27 AM: Validating...
09/16 10:30:35 AM: Evaluate: task edges-pos-ontonotes, batch 42 (157): mcc: 0.8871, acc: 0.8209, precision: 0.9334, recall: 0.8473, f1: 0.8883, edges-pos-ontonotes_loss: 0.0128
09/16 10:30:45 AM: Evaluate: task edges-pos-ontonotes, batch 90 (157): mcc: 0.8967, acc: 0.8357, precision: 0.9361, recall: 0.8628, f1: 0.8980, edges-pos-ontonotes_loss: 0.0121
09/16 10:30:55 AM: Evaluate: task edges-pos-ontonotes, batch 125 (157): mcc: 0.8945, acc: 0.8333, precision: 0.9327, recall: 0.8619, f1: 0.8959, edges-pos-ontonotes_loss: 0.0122
09/16 10:31:05 AM: Best result seen so far for edges-pos-ontonotes.
09/16 10:31:05 AM: Best result seen so far for macro.
09/16 10:31:05 AM: Updating LR scheduler:
09/16 10:31:05 AM: 	Best result seen so far for macro_avg: 0.896
09/16 10:31:05 AM: 	# validation passes without improvement: 0
09/16 10:31:05 AM: edges-pos-ontonotes_loss: training: 0.016981 validation: 0.012238
09/16 10:31:05 AM: macro_avg: validation: 0.895918
09/16 10:31:05 AM: micro_avg: validation: 0.000000
09/16 10:31:05 AM: edges-pos-ontonotes_mcc: training: 0.849738 validation: 0.894439
09/16 10:31:05 AM: edges-pos-ontonotes_acc: training: 0.760401 validation: 0.834228
09/16 10:31:05 AM: edges-pos-ontonotes_precision: training: 0.899620 validation: 0.930708
09/16 10:31:05 AM: edges-pos-ontonotes_recall: training: 0.808190 validation: 0.863636
09/16 10:31:05 AM: edges-pos-ontonotes_f1: training: 0.851458 validation: 0.895918
09/16 10:31:05 AM: Global learning rate: 0.0001
09/16 10:31:05 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 10:31:05 AM: Update 11003: task edges-pos-ontonotes, batch 3 (11003): mcc: 0.8428, acc: 0.7581, precision: 0.8745, recall: 0.8184, f1: 0.8455, edges-pos-ontonotes_loss: 0.0187
09/16 10:31:16 AM: Update 11027: task edges-pos-ontonotes, batch 27 (11027): mcc: 0.8475, acc: 0.7577, precision: 0.8964, recall: 0.8069, f1: 0.8493, edges-pos-ontonotes_loss: 0.0181
09/16 10:31:26 AM: Update 11064: task edges-pos-ontonotes, batch 64 (11064): mcc: 0.8477, acc: 0.7583, precision: 0.8957, recall: 0.8080, f1: 0.8496, edges-pos-ontonotes_loss: 0.0179
09/16 10:31:36 AM: Update 11101: task edges-pos-ontonotes, batch 101 (11101): mcc: 0.8499, acc: 0.7614, precision: 0.8973, recall: 0.8105, f1: 0.8517, edges-pos-ontonotes_loss: 0.0178
09/16 10:31:46 AM: Update 11134: task edges-pos-ontonotes, batch 134 (11134): mcc: 0.8505, acc: 0.7625, precision: 0.8983, recall: 0.8108, f1: 0.8523, edges-pos-ontonotes_loss: 0.0176
09/16 10:31:56 AM: Update 11170: task edges-pos-ontonotes, batch 170 (11170): mcc: 0.8502, acc: 0.7624, precision: 0.8979, recall: 0.8106, f1: 0.8520, edges-pos-ontonotes_loss: 0.0175
09/16 10:32:06 AM: Update 11203: task edges-pos-ontonotes, batch 203 (11203): mcc: 0.8505, acc: 0.7631, precision: 0.8977, recall: 0.8114, f1: 0.8524, edges-pos-ontonotes_loss: 0.0175
09/16 10:32:16 AM: Update 11242: task edges-pos-ontonotes, batch 242 (11242): mcc: 0.8506, acc: 0.7631, precision: 0.8977, recall: 0.8115, f1: 0.8524, edges-pos-ontonotes_loss: 0.0176
09/16 10:32:26 AM: Update 11277: task edges-pos-ontonotes, batch 277 (11277): mcc: 0.8508, acc: 0.7635, precision: 0.8978, recall: 0.8119, f1: 0.8527, edges-pos-ontonotes_loss: 0.0175
09/16 10:32:36 AM: Update 11314: task edges-pos-ontonotes, batch 314 (11314): mcc: 0.8509, acc: 0.7636, precision: 0.8981, recall: 0.8117, f1: 0.8527, edges-pos-ontonotes_loss: 0.0174
09/16 10:32:51 AM: Update 11320: task edges-pos-ontonotes, batch 320 (11320): mcc: 0.8507, acc: 0.7635, precision: 0.8980, recall: 0.8116, f1: 0.8526, edges-pos-ontonotes_loss: 0.0174
09/16 10:33:02 AM: Update 11359: task edges-pos-ontonotes, batch 359 (11359): mcc: 0.8509, acc: 0.7636, precision: 0.8984, recall: 0.8115, f1: 0.8527, edges-pos-ontonotes_loss: 0.0174
09/16 10:33:12 AM: Update 11397: task edges-pos-ontonotes, batch 397 (11397): mcc: 0.8510, acc: 0.7638, precision: 0.8987, recall: 0.8115, f1: 0.8528, edges-pos-ontonotes_loss: 0.0174
09/16 10:33:22 AM: Update 11429: task edges-pos-ontonotes, batch 429 (11429): mcc: 0.8514, acc: 0.7643, precision: 0.8990, recall: 0.8118, f1: 0.8532, edges-pos-ontonotes_loss: 0.0173
09/16 10:33:32 AM: Update 11456: task edges-pos-ontonotes, batch 456 (11456): mcc: 0.8517, acc: 0.7648, precision: 0.8993, recall: 0.8122, f1: 0.8535, edges-pos-ontonotes_loss: 0.0173
09/16 10:33:42 AM: Update 11489: task edges-pos-ontonotes, batch 489 (11489): mcc: 0.8518, acc: 0.7649, precision: 0.8993, recall: 0.8123, f1: 0.8536, edges-pos-ontonotes_loss: 0.0172
09/16 10:33:52 AM: Update 11528: task edges-pos-ontonotes, batch 528 (11528): mcc: 0.8518, acc: 0.7651, precision: 0.8994, recall: 0.8123, f1: 0.8536, edges-pos-ontonotes_loss: 0.0172
09/16 10:34:02 AM: Update 11561: task edges-pos-ontonotes, batch 561 (11561): mcc: 0.8519, acc: 0.7651, precision: 0.8996, recall: 0.8122, f1: 0.8537, edges-pos-ontonotes_loss: 0.0172
09/16 10:34:13 AM: Update 11592: task edges-pos-ontonotes, batch 592 (11592): mcc: 0.8522, acc: 0.7657, precision: 0.8998, recall: 0.8126, f1: 0.8540, edges-pos-ontonotes_loss: 0.0171
09/16 10:34:23 AM: Update 11628: task edges-pos-ontonotes, batch 628 (11628): mcc: 0.8525, acc: 0.7662, precision: 0.9001, recall: 0.8130, f1: 0.8543, edges-pos-ontonotes_loss: 0.0171
09/16 10:34:34 AM: Update 11653: task edges-pos-ontonotes, batch 653 (11653): mcc: 0.8526, acc: 0.7663, precision: 0.9003, recall: 0.8130, f1: 0.8544, edges-pos-ontonotes_loss: 0.0170
09/16 10:34:44 AM: Update 11691: task edges-pos-ontonotes, batch 691 (11691): mcc: 0.8527, acc: 0.7665, precision: 0.9004, recall: 0.8131, f1: 0.8545, edges-pos-ontonotes_loss: 0.0171
09/16 10:34:54 AM: Update 11729: task edges-pos-ontonotes, batch 729 (11729): mcc: 0.8531, acc: 0.7671, precision: 0.9007, recall: 0.8135, f1: 0.8549, edges-pos-ontonotes_loss: 0.0170
09/16 10:35:04 AM: Update 11769: task edges-pos-ontonotes, batch 769 (11769): mcc: 0.8535, acc: 0.7677, precision: 0.9010, recall: 0.8139, f1: 0.8553, edges-pos-ontonotes_loss: 0.0170
09/16 10:35:14 AM: Update 11805: task edges-pos-ontonotes, batch 805 (11805): mcc: 0.8539, acc: 0.7682, precision: 0.9014, recall: 0.8143, f1: 0.8556, edges-pos-ontonotes_loss: 0.0169
09/16 10:35:25 AM: Update 11844: task edges-pos-ontonotes, batch 844 (11844): mcc: 0.8541, acc: 0.7686, precision: 0.9016, recall: 0.8145, f1: 0.8559, edges-pos-ontonotes_loss: 0.0169
09/16 10:35:35 AM: Update 11876: task edges-pos-ontonotes, batch 876 (11876): mcc: 0.8544, acc: 0.7690, precision: 0.9018, recall: 0.8149, f1: 0.8561, edges-pos-ontonotes_loss: 0.0169
09/16 10:35:45 AM: Update 11914: task edges-pos-ontonotes, batch 914 (11914): mcc: 0.8547, acc: 0.7696, precision: 0.9021, recall: 0.8153, f1: 0.8565, edges-pos-ontonotes_loss: 0.0169
09/16 10:35:58 AM: Update 11946: task edges-pos-ontonotes, batch 946 (11946): mcc: 0.8551, acc: 0.7701, precision: 0.9023, recall: 0.8157, f1: 0.8568, edges-pos-ontonotes_loss: 0.0168
09/16 10:36:08 AM: Update 11976: task edges-pos-ontonotes, batch 976 (11976): mcc: 0.8551, acc: 0.7702, precision: 0.9023, recall: 0.8158, f1: 0.8569, edges-pos-ontonotes_loss: 0.0168
09/16 10:36:15 AM: ***** Step 12000 / Validation 12 *****
09/16 10:36:15 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 10:36:15 AM: Validating...
09/16 10:36:18 AM: Evaluate: task edges-pos-ontonotes, batch 12 (157): mcc: 0.8829, acc: 0.8186, precision: 0.9313, recall: 0.8414, f1: 0.8841, edges-pos-ontonotes_loss: 0.0131
09/16 10:36:28 AM: Evaluate: task edges-pos-ontonotes, batch 61 (157): mcc: 0.8902, acc: 0.8244, precision: 0.9379, recall: 0.8491, f1: 0.8913, edges-pos-ontonotes_loss: 0.0129
09/16 10:36:38 AM: Evaluate: task edges-pos-ontonotes, batch 102 (157): mcc: 0.8942, acc: 0.8324, precision: 0.9366, recall: 0.8578, f1: 0.8954, edges-pos-ontonotes_loss: 0.0124
09/16 10:36:48 AM: Evaluate: task edges-pos-ontonotes, batch 134 (157): mcc: 0.8956, acc: 0.8351, precision: 0.9370, recall: 0.8600, f1: 0.8968, edges-pos-ontonotes_loss: 0.0122
09/16 10:36:55 AM: Best result seen so far for edges-pos-ontonotes.
09/16 10:36:55 AM: Best result seen so far for macro.
09/16 10:36:55 AM: Updating LR scheduler:
09/16 10:36:55 AM: 	Best result seen so far for macro_avg: 0.899
09/16 10:36:55 AM: 	# validation passes without improvement: 0
09/16 10:36:55 AM: edges-pos-ontonotes_loss: training: 0.016816 validation: 0.012052
09/16 10:36:55 AM: macro_avg: validation: 0.898707
09/16 10:36:55 AM: micro_avg: validation: 0.000000
09/16 10:36:55 AM: edges-pos-ontonotes_mcc: training: 0.855387 validation: 0.897441
09/16 10:36:55 AM: edges-pos-ontonotes_acc: training: 0.770580 validation: 0.838841
09/16 10:36:55 AM: edges-pos-ontonotes_precision: training: 0.902514 validation: 0.937446
09/16 10:36:55 AM: edges-pos-ontonotes_recall: training: 0.816118 validation: 0.863043
09/16 10:36:55 AM: edges-pos-ontonotes_f1: training: 0.857145 validation: 0.898707
09/16 10:36:55 AM: Global learning rate: 0.0001
09/16 10:36:55 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 10:36:58 AM: Update 12012: task edges-pos-ontonotes, batch 12 (12012): mcc: 0.8618, acc: 0.7806, precision: 0.9041, recall: 0.8268, f1: 0.8637, edges-pos-ontonotes_loss: 0.0162
09/16 10:37:08 AM: Update 12050: task edges-pos-ontonotes, batch 50 (12050): mcc: 0.8598, acc: 0.7776, precision: 0.9057, recall: 0.8214, f1: 0.8615, edges-pos-ontonotes_loss: 0.0172
09/16 10:37:19 AM: Update 12087: task edges-pos-ontonotes, batch 87 (12087): mcc: 0.8589, acc: 0.7766, precision: 0.9042, recall: 0.8211, f1: 0.8607, edges-pos-ontonotes_loss: 0.0170
09/16 10:37:29 AM: Update 12124: task edges-pos-ontonotes, batch 124 (12124): mcc: 0.8584, acc: 0.7755, precision: 0.9041, recall: 0.8203, f1: 0.8602, edges-pos-ontonotes_loss: 0.0170
09/16 10:37:39 AM: Update 12160: task edges-pos-ontonotes, batch 160 (12160): mcc: 0.8587, acc: 0.7763, precision: 0.9039, recall: 0.8211, f1: 0.8605, edges-pos-ontonotes_loss: 0.0169
09/16 10:37:49 AM: Update 12200: task edges-pos-ontonotes, batch 200 (12200): mcc: 0.8587, acc: 0.7763, precision: 0.9042, recall: 0.8208, f1: 0.8605, edges-pos-ontonotes_loss: 0.0169
09/16 10:37:59 AM: Update 12238: task edges-pos-ontonotes, batch 238 (12238): mcc: 0.8586, acc: 0.7764, precision: 0.9041, recall: 0.8207, f1: 0.8604, edges-pos-ontonotes_loss: 0.0167
09/16 10:38:10 AM: Update 12260: task edges-pos-ontonotes, batch 260 (12260): mcc: 0.8583, acc: 0.7763, precision: 0.9035, recall: 0.8207, f1: 0.8601, edges-pos-ontonotes_loss: 0.0167
09/16 10:38:20 AM: Update 12305: task edges-pos-ontonotes, batch 305 (12305): mcc: 0.8589, acc: 0.7770, precision: 0.9041, recall: 0.8212, f1: 0.8607, edges-pos-ontonotes_loss: 0.0164
09/16 10:38:30 AM: Update 12353: task edges-pos-ontonotes, batch 353 (12353): mcc: 0.8602, acc: 0.7787, precision: 0.9054, recall: 0.8226, f1: 0.8620, edges-pos-ontonotes_loss: 0.0161
09/16 10:38:40 AM: Update 12402: task edges-pos-ontonotes, batch 402 (12402): mcc: 0.8615, acc: 0.7802, precision: 0.9065, recall: 0.8240, f1: 0.8632, edges-pos-ontonotes_loss: 0.0158
09/16 10:38:50 AM: Update 12445: task edges-pos-ontonotes, batch 445 (12445): mcc: 0.8623, acc: 0.7813, precision: 0.9070, recall: 0.8250, f1: 0.8640, edges-pos-ontonotes_loss: 0.0156
09/16 10:39:01 AM: Update 12487: task edges-pos-ontonotes, batch 487 (12487): mcc: 0.8628, acc: 0.7821, precision: 0.9072, recall: 0.8257, f1: 0.8645, edges-pos-ontonotes_loss: 0.0155
09/16 10:39:11 AM: Update 12530: task edges-pos-ontonotes, batch 530 (12530): mcc: 0.8632, acc: 0.7827, precision: 0.9074, recall: 0.8263, f1: 0.8649, edges-pos-ontonotes_loss: 0.0154
09/16 10:39:23 AM: Update 12572: task edges-pos-ontonotes, batch 572 (12572): mcc: 0.8638, acc: 0.7836, precision: 0.9078, recall: 0.8271, f1: 0.8656, edges-pos-ontonotes_loss: 0.0153
09/16 10:39:33 AM: Update 12627: task edges-pos-ontonotes, batch 627 (12627): mcc: 0.8656, acc: 0.7857, precision: 0.9092, recall: 0.8291, f1: 0.8673, edges-pos-ontonotes_loss: 0.0151
09/16 10:39:43 AM: Update 12684: task edges-pos-ontonotes, batch 684 (12684): mcc: 0.8672, acc: 0.7878, precision: 0.9105, recall: 0.8309, f1: 0.8689, edges-pos-ontonotes_loss: 0.0148
09/16 10:39:53 AM: Update 12742: task edges-pos-ontonotes, batch 742 (12742): mcc: 0.8689, acc: 0.7901, precision: 0.9118, recall: 0.8329, f1: 0.8706, edges-pos-ontonotes_loss: 0.0146
09/16 10:40:03 AM: Update 12796: task edges-pos-ontonotes, batch 796 (12796): mcc: 0.8703, acc: 0.7919, precision: 0.9129, recall: 0.8345, f1: 0.8719, edges-pos-ontonotes_loss: 0.0144
09/16 10:40:13 AM: Update 12862: task edges-pos-ontonotes, batch 862 (12862): mcc: 0.8717, acc: 0.7939, precision: 0.9140, recall: 0.8362, f1: 0.8734, edges-pos-ontonotes_loss: 0.0143
09/16 10:40:23 AM: Update 12915: task edges-pos-ontonotes, batch 915 (12915): mcc: 0.8725, acc: 0.7950, precision: 0.9146, recall: 0.8371, f1: 0.8741, edges-pos-ontonotes_loss: 0.0142
09/16 10:40:33 AM: Update 12989: task edges-pos-ontonotes, batch 989 (12989): mcc: 0.8732, acc: 0.7961, precision: 0.9153, recall: 0.8379, f1: 0.8749, edges-pos-ontonotes_loss: 0.0141
09/16 10:40:35 AM: ***** Step 13000 / Validation 13 *****
09/16 10:40:35 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 10:40:35 AM: Validating...
09/16 10:40:43 AM: Evaluate: task edges-pos-ontonotes, batch 42 (157): mcc: 0.8828, acc: 0.8109, precision: 0.9426, recall: 0.8311, f1: 0.8833, edges-pos-ontonotes_loss: 0.0133
09/16 10:40:53 AM: Evaluate: task edges-pos-ontonotes, batch 90 (157): mcc: 0.8917, acc: 0.8259, precision: 0.9434, recall: 0.8468, f1: 0.8925, edges-pos-ontonotes_loss: 0.0126
09/16 10:41:04 AM: Evaluate: task edges-pos-ontonotes, batch 124 (157): mcc: 0.8901, acc: 0.8239, precision: 0.9431, recall: 0.8441, f1: 0.8909, edges-pos-ontonotes_loss: 0.0126
09/16 10:41:14 AM: Evaluate: task edges-pos-ontonotes, batch 154 (157): mcc: 0.8911, acc: 0.8266, precision: 0.9423, recall: 0.8467, f1: 0.8920, edges-pos-ontonotes_loss: 0.0125
09/16 10:41:14 AM: Updating LR scheduler:
09/16 10:41:14 AM: 	Best result seen so far for macro_avg: 0.899
09/16 10:41:14 AM: 	# validation passes without improvement: 1
09/16 10:41:14 AM: edges-pos-ontonotes_loss: training: 0.014079 validation: 0.012480
09/16 10:41:14 AM: macro_avg: validation: 0.891903
09/16 10:41:14 AM: micro_avg: validation: 0.000000
09/16 10:41:14 AM: edges-pos-ontonotes_mcc: training: 0.873352 validation: 0.891057
09/16 10:41:14 AM: edges-pos-ontonotes_acc: training: 0.796223 validation: 0.826545
09/16 10:41:14 AM: edges-pos-ontonotes_precision: training: 0.915336 validation: 0.942330
09/16 10:41:14 AM: edges-pos-ontonotes_recall: training: 0.838085 validation: 0.846598
09/16 10:41:14 AM: edges-pos-ontonotes_f1: training: 0.875009 validation: 0.891903
09/16 10:41:14 AM: Global learning rate: 0.0001
09/16 10:41:14 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 10:41:24 AM: Update 13072: task edges-pos-ontonotes, batch 72 (13072): mcc: 0.8890, acc: 0.8181, precision: 0.9284, recall: 0.8554, f1: 0.8904, edges-pos-ontonotes_loss: 0.0131
09/16 10:41:34 AM: Update 13138: task edges-pos-ontonotes, batch 138 (13138): mcc: 0.8899, acc: 0.8194, precision: 0.9291, recall: 0.8565, f1: 0.8913, edges-pos-ontonotes_loss: 0.0133
09/16 10:41:44 AM: Update 13200: task edges-pos-ontonotes, batch 200 (13200): mcc: 0.8887, acc: 0.8183, precision: 0.9275, recall: 0.8557, f1: 0.8902, edges-pos-ontonotes_loss: 0.0131
09/16 10:41:54 AM: Update 13295: task edges-pos-ontonotes, batch 295 (13295): mcc: 0.8796, acc: 0.8050, precision: 0.9207, recall: 0.8450, f1: 0.8812, edges-pos-ontonotes_loss: 0.0144
09/16 10:42:04 AM: Update 13383: task edges-pos-ontonotes, batch 383 (13383): mcc: 0.8738, acc: 0.7963, precision: 0.9163, recall: 0.8380, f1: 0.8754, edges-pos-ontonotes_loss: 0.0150
09/16 10:42:14 AM: Update 13476: task edges-pos-ontonotes, batch 476 (13476): mcc: 0.8703, acc: 0.7914, precision: 0.9137, recall: 0.8338, f1: 0.8719, edges-pos-ontonotes_loss: 0.0153
09/16 10:42:30 AM: Update 13511: task edges-pos-ontonotes, batch 511 (13511): mcc: 0.8694, acc: 0.7902, precision: 0.9129, recall: 0.8328, f1: 0.8710, edges-pos-ontonotes_loss: 0.0154
09/16 10:42:40 AM: Update 13549: task edges-pos-ontonotes, batch 549 (13549): mcc: 0.8660, acc: 0.7851, precision: 0.9099, recall: 0.8293, f1: 0.8677, edges-pos-ontonotes_loss: 0.0156
09/16 10:42:50 AM: Update 13587: task edges-pos-ontonotes, batch 587 (13587): mcc: 0.8635, acc: 0.7815, precision: 0.9078, recall: 0.8265, f1: 0.8653, edges-pos-ontonotes_loss: 0.0158
09/16 10:43:01 AM: Update 13629: task edges-pos-ontonotes, batch 629 (13629): mcc: 0.8618, acc: 0.7790, precision: 0.9060, recall: 0.8251, f1: 0.8636, edges-pos-ontonotes_loss: 0.0159
09/16 10:43:11 AM: Update 13675: task edges-pos-ontonotes, batch 675 (13675): mcc: 0.8606, acc: 0.7773, precision: 0.9048, recall: 0.8238, f1: 0.8624, edges-pos-ontonotes_loss: 0.0160
09/16 10:43:22 AM: Update 13717: task edges-pos-ontonotes, batch 717 (13717): mcc: 0.8598, acc: 0.7761, precision: 0.9040, recall: 0.8229, f1: 0.8616, edges-pos-ontonotes_loss: 0.0161
09/16 10:43:32 AM: Update 13754: task edges-pos-ontonotes, batch 754 (13754): mcc: 0.8589, acc: 0.7750, precision: 0.9030, recall: 0.8223, f1: 0.8608, edges-pos-ontonotes_loss: 0.0162
09/16 10:43:42 AM: Update 13791: task edges-pos-ontonotes, batch 791 (13791): mcc: 0.8584, acc: 0.7743, precision: 0.9024, recall: 0.8219, f1: 0.8603, edges-pos-ontonotes_loss: 0.0163
09/16 10:43:52 AM: Update 13828: task edges-pos-ontonotes, batch 828 (13828): mcc: 0.8577, acc: 0.7733, precision: 0.9018, recall: 0.8212, f1: 0.8596, edges-pos-ontonotes_loss: 0.0163
09/16 10:44:02 AM: Update 13871: task edges-pos-ontonotes, batch 871 (13871): mcc: 0.8571, acc: 0.7724, precision: 0.9015, recall: 0.8202, f1: 0.8590, edges-pos-ontonotes_loss: 0.0164
09/16 10:44:12 AM: Update 13939: task edges-pos-ontonotes, batch 939 (13939): mcc: 0.8570, acc: 0.7721, precision: 0.9020, recall: 0.8196, f1: 0.8588, edges-pos-ontonotes_loss: 0.0164
09/16 10:44:22 AM: Update 13984: task edges-pos-ontonotes, batch 984 (13984): mcc: 0.8567, acc: 0.7716, precision: 0.9020, recall: 0.8190, f1: 0.8585, edges-pos-ontonotes_loss: 0.0164
09/16 10:44:25 AM: ***** Step 14000 / Validation 14 *****
09/16 10:44:25 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 10:44:25 AM: Validating...
09/16 10:44:32 AM: Evaluate: task edges-pos-ontonotes, batch 39 (157): mcc: 0.8898, acc: 0.8232, precision: 0.9389, recall: 0.8473, f1: 0.8908, edges-pos-ontonotes_loss: 0.0125
09/16 10:44:43 AM: Evaluate: task edges-pos-ontonotes, batch 88 (157): mcc: 0.8987, acc: 0.8386, precision: 0.9399, recall: 0.8632, f1: 0.8999, edges-pos-ontonotes_loss: 0.0119
09/16 10:44:53 AM: Evaluate: task edges-pos-ontonotes, batch 123 (157): mcc: 0.8975, acc: 0.8375, precision: 0.9376, recall: 0.8630, f1: 0.8987, edges-pos-ontonotes_loss: 0.0120
09/16 10:45:03 AM: Evaluate: task edges-pos-ontonotes, batch 156 (157): mcc: 0.8972, acc: 0.8380, precision: 0.9355, recall: 0.8644, f1: 0.8985, edges-pos-ontonotes_loss: 0.0120
09/16 10:45:03 AM: Updating LR scheduler:
09/16 10:45:03 AM: 	Best result seen so far for macro_avg: 0.899
09/16 10:45:03 AM: 	# validation passes without improvement: 2
09/16 10:45:03 AM: edges-pos-ontonotes_loss: training: 0.016353 validation: 0.011943
09/16 10:45:03 AM: macro_avg: validation: 0.898551
09/16 10:45:03 AM: micro_avg: validation: 0.000000
09/16 10:45:03 AM: edges-pos-ontonotes_mcc: training: 0.856622 validation: 0.897210
09/16 10:45:03 AM: edges-pos-ontonotes_acc: training: 0.771441 validation: 0.837984
09/16 10:45:03 AM: edges-pos-ontonotes_precision: training: 0.902136 validation: 0.935539
09/16 10:45:03 AM: edges-pos-ontonotes_recall: training: 0.818779 validation: 0.864377
09/16 10:45:03 AM: edges-pos-ontonotes_f1: training: 0.858439 validation: 0.898551
09/16 10:45:03 AM: Global learning rate: 0.0001
09/16 10:45:03 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 10:45:13 AM: Update 14071: task edges-pos-ontonotes, batch 71 (14071): mcc: 0.8543, acc: 0.7660, precision: 0.9047, recall: 0.8120, f1: 0.8559, edges-pos-ontonotes_loss: 0.0162
09/16 10:45:23 AM: Update 14129: task edges-pos-ontonotes, batch 129 (14129): mcc: 0.8536, acc: 0.7644, precision: 0.9040, recall: 0.8114, f1: 0.8552, edges-pos-ontonotes_loss: 0.0160
09/16 10:45:33 AM: Update 14172: task edges-pos-ontonotes, batch 172 (14172): mcc: 0.8559, acc: 0.7682, precision: 0.9050, recall: 0.8149, f1: 0.8576, edges-pos-ontonotes_loss: 0.0158
09/16 10:45:43 AM: Update 14223: task edges-pos-ontonotes, batch 223 (14223): mcc: 0.8571, acc: 0.7704, precision: 0.9046, recall: 0.8175, f1: 0.8588, edges-pos-ontonotes_loss: 0.0159
09/16 10:45:53 AM: Update 14277: task edges-pos-ontonotes, batch 277 (14277): mcc: 0.8573, acc: 0.7709, precision: 0.9044, recall: 0.8180, f1: 0.8590, edges-pos-ontonotes_loss: 0.0159
09/16 10:46:03 AM: Update 14324: task edges-pos-ontonotes, batch 324 (14324): mcc: 0.8574, acc: 0.7709, precision: 0.9047, recall: 0.8180, f1: 0.8592, edges-pos-ontonotes_loss: 0.0159
09/16 10:46:13 AM: Update 14371: task edges-pos-ontonotes, batch 371 (14371): mcc: 0.8579, acc: 0.7715, precision: 0.9049, recall: 0.8186, f1: 0.8596, edges-pos-ontonotes_loss: 0.0158
09/16 10:46:23 AM: Update 14414: task edges-pos-ontonotes, batch 414 (14414): mcc: 0.8586, acc: 0.7724, precision: 0.9055, recall: 0.8193, f1: 0.8603, edges-pos-ontonotes_loss: 0.0158
09/16 10:46:34 AM: Update 14456: task edges-pos-ontonotes, batch 456 (14456): mcc: 0.8588, acc: 0.7730, precision: 0.9055, recall: 0.8198, f1: 0.8605, edges-pos-ontonotes_loss: 0.0158
09/16 10:46:44 AM: Update 14481: task edges-pos-ontonotes, batch 481 (14481): mcc: 0.8579, acc: 0.7718, precision: 0.9050, recall: 0.8185, f1: 0.8596, edges-pos-ontonotes_loss: 0.0158
09/16 10:46:54 AM: Update 14524: task edges-pos-ontonotes, batch 524 (14524): mcc: 0.8569, acc: 0.7707, precision: 0.9039, recall: 0.8177, f1: 0.8586, edges-pos-ontonotes_loss: 0.0160
09/16 10:47:05 AM: Update 14566: task edges-pos-ontonotes, batch 566 (14566): mcc: 0.8566, acc: 0.7703, precision: 0.9032, recall: 0.8177, f1: 0.8583, edges-pos-ontonotes_loss: 0.0162
09/16 10:47:15 AM: Update 14607: task edges-pos-ontonotes, batch 607 (14607): mcc: 0.8564, acc: 0.7703, precision: 0.9029, recall: 0.8176, f1: 0.8581, edges-pos-ontonotes_loss: 0.0162
09/16 10:47:25 AM: Update 14647: task edges-pos-ontonotes, batch 647 (14647): mcc: 0.8563, acc: 0.7703, precision: 0.9026, recall: 0.8178, f1: 0.8581, edges-pos-ontonotes_loss: 0.0163
09/16 10:47:35 AM: Update 14679: task edges-pos-ontonotes, batch 679 (14679): mcc: 0.8562, acc: 0.7703, precision: 0.9025, recall: 0.8177, f1: 0.8580, edges-pos-ontonotes_loss: 0.0163
09/16 10:47:45 AM: Update 14717: task edges-pos-ontonotes, batch 717 (14717): mcc: 0.8564, acc: 0.7705, precision: 0.9025, recall: 0.8180, f1: 0.8582, edges-pos-ontonotes_loss: 0.0163
09/16 10:47:55 AM: Update 14757: task edges-pos-ontonotes, batch 757 (14757): mcc: 0.8565, acc: 0.7707, precision: 0.9026, recall: 0.8182, f1: 0.8583, edges-pos-ontonotes_loss: 0.0163
09/16 10:48:05 AM: Update 14780: task edges-pos-ontonotes, batch 780 (14780): mcc: 0.8566, acc: 0.7709, precision: 0.9024, recall: 0.8184, f1: 0.8584, edges-pos-ontonotes_loss: 0.0163
09/16 10:48:15 AM: Update 14817: task edges-pos-ontonotes, batch 817 (14817): mcc: 0.8566, acc: 0.7707, precision: 0.9026, recall: 0.8183, f1: 0.8583, edges-pos-ontonotes_loss: 0.0163
09/16 10:48:25 AM: Update 14850: task edges-pos-ontonotes, batch 850 (14850): mcc: 0.8564, acc: 0.7707, precision: 0.9024, recall: 0.8182, f1: 0.8582, edges-pos-ontonotes_loss: 0.0163
09/16 10:48:35 AM: Update 14891: task edges-pos-ontonotes, batch 891 (14891): mcc: 0.8564, acc: 0.7707, precision: 0.9024, recall: 0.8181, f1: 0.8582, edges-pos-ontonotes_loss: 0.0163
09/16 10:48:46 AM: Update 14923: task edges-pos-ontonotes, batch 923 (14923): mcc: 0.8565, acc: 0.7709, precision: 0.9025, recall: 0.8182, f1: 0.8583, edges-pos-ontonotes_loss: 0.0163
09/16 10:48:56 AM: Update 14955: task edges-pos-ontonotes, batch 955 (14955): mcc: 0.8566, acc: 0.7710, precision: 0.9025, recall: 0.8184, f1: 0.8584, edges-pos-ontonotes_loss: 0.0163
09/16 10:49:06 AM: Update 14996: task edges-pos-ontonotes, batch 996 (14996): mcc: 0.8568, acc: 0.7714, precision: 0.9027, recall: 0.8186, f1: 0.8586, edges-pos-ontonotes_loss: 0.0163
09/16 10:49:07 AM: ***** Step 15000 / Validation 15 *****
09/16 10:49:07 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 10:49:07 AM: Validating...
09/16 10:49:16 AM: Evaluate: task edges-pos-ontonotes, batch 45 (157): mcc: 0.8896, acc: 0.8230, precision: 0.9387, recall: 0.8471, f1: 0.8905, edges-pos-ontonotes_loss: 0.0126
09/16 10:49:26 AM: Evaluate: task edges-pos-ontonotes, batch 92 (157): mcc: 0.8985, acc: 0.8376, precision: 0.9404, recall: 0.8623, f1: 0.8996, edges-pos-ontonotes_loss: 0.0119
09/16 10:49:37 AM: Evaluate: task edges-pos-ontonotes, batch 125 (157): mcc: 0.8988, acc: 0.8393, precision: 0.9400, recall: 0.8633, f1: 0.9000, edges-pos-ontonotes_loss: 0.0118
09/16 10:49:46 AM: Best result seen so far for edges-pos-ontonotes.
09/16 10:49:46 AM: Best result seen so far for macro.
09/16 10:49:46 AM: Updating LR scheduler:
09/16 10:49:46 AM: 	Best result seen so far for macro_avg: 0.902
09/16 10:49:46 AM: 	# validation passes without improvement: 0
09/16 10:49:46 AM: edges-pos-ontonotes_loss: training: 0.016269 validation: 0.011648
09/16 10:49:46 AM: macro_avg: validation: 0.901554
09/16 10:49:46 AM: micro_avg: validation: 0.000000
09/16 10:49:46 AM: edges-pos-ontonotes_mcc: training: 0.856844 validation: 0.900316
09/16 10:49:46 AM: edges-pos-ontonotes_acc: training: 0.771427 validation: 0.842704
09/16 10:49:46 AM: edges-pos-ontonotes_precision: training: 0.902727 validation: 0.939635
09/16 10:49:46 AM: edges-pos-ontonotes_recall: training: 0.818653 validation: 0.866440
09/16 10:49:46 AM: edges-pos-ontonotes_f1: training: 0.858637 validation: 0.901554
09/16 10:49:46 AM: Global learning rate: 0.0001
09/16 10:49:46 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 10:49:47 AM: Update 15001: task edges-pos-ontonotes, batch 1 (15001): mcc: 0.8680, acc: 0.7917, precision: 0.9024, recall: 0.8400, f1: 0.8701, edges-pos-ontonotes_loss: 0.0160
09/16 10:49:57 AM: Update 15032: task edges-pos-ontonotes, batch 32 (15032): mcc: 0.8597, acc: 0.7775, precision: 0.9022, recall: 0.8245, f1: 0.8616, edges-pos-ontonotes_loss: 0.0165
09/16 10:50:07 AM: Update 15066: task edges-pos-ontonotes, batch 66 (15066): mcc: 0.8599, acc: 0.7776, precision: 0.9041, recall: 0.8231, f1: 0.8617, edges-pos-ontonotes_loss: 0.0168
09/16 10:50:28 AM: Update 15093: task edges-pos-ontonotes, batch 93 (15093): mcc: 0.8598, acc: 0.7768, precision: 0.9039, recall: 0.8230, f1: 0.8616, edges-pos-ontonotes_loss: 0.0165
09/16 10:50:38 AM: Update 15125: task edges-pos-ontonotes, batch 125 (15125): mcc: 0.8602, acc: 0.7774, precision: 0.9044, recall: 0.8234, f1: 0.8620, edges-pos-ontonotes_loss: 0.0166
09/16 10:50:48 AM: Update 15165: task edges-pos-ontonotes, batch 165 (15165): mcc: 0.8608, acc: 0.7783, precision: 0.9055, recall: 0.8235, f1: 0.8626, edges-pos-ontonotes_loss: 0.0164
09/16 10:50:58 AM: Update 15201: task edges-pos-ontonotes, batch 201 (15201): mcc: 0.8610, acc: 0.7788, precision: 0.9056, recall: 0.8237, f1: 0.8627, edges-pos-ontonotes_loss: 0.0163
09/16 10:51:08 AM: Update 15236: task edges-pos-ontonotes, batch 236 (15236): mcc: 0.8612, acc: 0.7792, precision: 0.9057, recall: 0.8240, f1: 0.8630, edges-pos-ontonotes_loss: 0.0163
09/16 10:51:18 AM: Update 15274: task edges-pos-ontonotes, batch 274 (15274): mcc: 0.8619, acc: 0.7803, precision: 0.9058, recall: 0.8253, f1: 0.8637, edges-pos-ontonotes_loss: 0.0161
09/16 10:51:29 AM: Update 15308: task edges-pos-ontonotes, batch 308 (15308): mcc: 0.8619, acc: 0.7804, precision: 0.9059, recall: 0.8252, f1: 0.8637, edges-pos-ontonotes_loss: 0.0161
09/16 10:51:39 AM: Update 15343: task edges-pos-ontonotes, batch 343 (15343): mcc: 0.8621, acc: 0.7809, precision: 0.9062, recall: 0.8254, f1: 0.8639, edges-pos-ontonotes_loss: 0.0160
09/16 10:51:49 AM: Update 15375: task edges-pos-ontonotes, batch 375 (15375): mcc: 0.8622, acc: 0.7810, precision: 0.9063, recall: 0.8255, f1: 0.8640, edges-pos-ontonotes_loss: 0.0161
09/16 10:51:59 AM: Update 15406: task edges-pos-ontonotes, batch 406 (15406): mcc: 0.8622, acc: 0.7811, precision: 0.9064, recall: 0.8254, f1: 0.8640, edges-pos-ontonotes_loss: 0.0161
09/16 10:52:09 AM: Update 15444: task edges-pos-ontonotes, batch 444 (15444): mcc: 0.8623, acc: 0.7812, precision: 0.9065, recall: 0.8254, f1: 0.8640, edges-pos-ontonotes_loss: 0.0161
09/16 10:52:19 AM: Update 15479: task edges-pos-ontonotes, batch 479 (15479): mcc: 0.8623, acc: 0.7813, precision: 0.9065, recall: 0.8254, f1: 0.8640, edges-pos-ontonotes_loss: 0.0161
09/16 10:52:29 AM: Update 15514: task edges-pos-ontonotes, batch 514 (15514): mcc: 0.8623, acc: 0.7814, precision: 0.9064, recall: 0.8256, f1: 0.8641, edges-pos-ontonotes_loss: 0.0161
09/16 10:52:39 AM: Update 15549: task edges-pos-ontonotes, batch 549 (15549): mcc: 0.8623, acc: 0.7814, precision: 0.9064, recall: 0.8255, f1: 0.8641, edges-pos-ontonotes_loss: 0.0161
09/16 10:52:49 AM: Update 15577: task edges-pos-ontonotes, batch 577 (15577): mcc: 0.8625, acc: 0.7817, precision: 0.9066, recall: 0.8257, f1: 0.8642, edges-pos-ontonotes_loss: 0.0161
09/16 10:53:00 AM: Update 15611: task edges-pos-ontonotes, batch 611 (15611): mcc: 0.8625, acc: 0.7817, precision: 0.9065, recall: 0.8257, f1: 0.8642, edges-pos-ontonotes_loss: 0.0160
09/16 10:53:10 AM: Update 15647: task edges-pos-ontonotes, batch 647 (15647): mcc: 0.8627, acc: 0.7821, precision: 0.9066, recall: 0.8261, f1: 0.8645, edges-pos-ontonotes_loss: 0.0160
09/16 10:53:20 AM: Update 15686: task edges-pos-ontonotes, batch 686 (15686): mcc: 0.8627, acc: 0.7822, precision: 0.9067, recall: 0.8261, f1: 0.8645, edges-pos-ontonotes_loss: 0.0161
09/16 10:53:33 AM: Update 15719: task edges-pos-ontonotes, batch 719 (15719): mcc: 0.8624, acc: 0.7818, precision: 0.9063, recall: 0.8258, f1: 0.8642, edges-pos-ontonotes_loss: 0.0161
09/16 10:53:43 AM: Update 15756: task edges-pos-ontonotes, batch 756 (15756): mcc: 0.8624, acc: 0.7819, precision: 0.9063, recall: 0.8258, f1: 0.8642, edges-pos-ontonotes_loss: 0.0161
09/16 10:53:53 AM: Update 15796: task edges-pos-ontonotes, batch 796 (15796): mcc: 0.8627, acc: 0.7823, precision: 0.9066, recall: 0.8262, f1: 0.8645, edges-pos-ontonotes_loss: 0.0160
09/16 10:54:04 AM: Update 15842: task edges-pos-ontonotes, batch 842 (15842): mcc: 0.8632, acc: 0.7829, precision: 0.9068, recall: 0.8268, f1: 0.8650, edges-pos-ontonotes_loss: 0.0159
09/16 10:54:14 AM: Update 15886: task edges-pos-ontonotes, batch 886 (15886): mcc: 0.8633, acc: 0.7832, precision: 0.9070, recall: 0.8270, f1: 0.8651, edges-pos-ontonotes_loss: 0.0158
09/16 10:54:24 AM: Update 15938: task edges-pos-ontonotes, batch 938 (15938): mcc: 0.8639, acc: 0.7839, precision: 0.9073, recall: 0.8277, f1: 0.8657, edges-pos-ontonotes_loss: 0.0156
09/16 10:54:34 AM: Update 15987: task edges-pos-ontonotes, batch 987 (15987): mcc: 0.8643, acc: 0.7845, precision: 0.9077, recall: 0.8282, f1: 0.8661, edges-pos-ontonotes_loss: 0.0155
09/16 10:54:37 AM: ***** Step 16000 / Validation 16 *****
09/16 10:54:37 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 10:54:37 AM: Validating...
09/16 10:54:44 AM: Evaluate: task edges-pos-ontonotes, batch 32 (157): mcc: 0.8862, acc: 0.8185, precision: 0.9333, recall: 0.8457, f1: 0.8873, edges-pos-ontonotes_loss: 0.0129
09/16 10:54:54 AM: Evaluate: task edges-pos-ontonotes, batch 78 (157): mcc: 0.8963, acc: 0.8347, precision: 0.9375, recall: 0.8609, f1: 0.8976, edges-pos-ontonotes_loss: 0.0122
09/16 10:55:04 AM: Evaluate: task edges-pos-ontonotes, batch 114 (157): mcc: 0.8974, acc: 0.8380, precision: 0.9372, recall: 0.8633, f1: 0.8987, edges-pos-ontonotes_loss: 0.0120
09/16 10:55:15 AM: Evaluate: task edges-pos-ontonotes, batch 147 (157): mcc: 0.8992, acc: 0.8412, precision: 0.9368, recall: 0.8669, f1: 0.9005, edges-pos-ontonotes_loss: 0.0118
09/16 10:55:17 AM: Updating LR scheduler:
09/16 10:55:17 AM: 	Best result seen so far for macro_avg: 0.902
09/16 10:55:17 AM: 	# validation passes without improvement: 1
09/16 10:55:17 AM: edges-pos-ontonotes_loss: training: 0.015505 validation: 0.011690
09/16 10:55:17 AM: macro_avg: validation: 0.901428
09/16 10:55:17 AM: micro_avg: validation: 0.000000
09/16 10:55:17 AM: edges-pos-ontonotes_mcc: training: 0.864313 validation: 0.900099
09/16 10:55:17 AM: edges-pos-ontonotes_acc: training: 0.784428 validation: 0.843000
09/16 10:55:17 AM: edges-pos-ontonotes_precision: training: 0.907660 validation: 0.937292
09/16 10:55:17 AM: edges-pos-ontonotes_recall: training: 0.828152 validation: 0.868207
09/16 10:55:17 AM: edges-pos-ontonotes_f1: training: 0.866085 validation: 0.901428
09/16 10:55:17 AM: Global learning rate: 0.0001
09/16 10:55:17 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 10:55:25 AM: Update 16031: task edges-pos-ontonotes, batch 31 (16031): mcc: 0.8698, acc: 0.7908, precision: 0.9085, recall: 0.8378, f1: 0.8717, edges-pos-ontonotes_loss: 0.0137
09/16 10:55:35 AM: Update 16080: task edges-pos-ontonotes, batch 80 (16080): mcc: 0.8831, acc: 0.8083, precision: 0.9214, recall: 0.8508, f1: 0.8847, edges-pos-ontonotes_loss: 0.0128
09/16 10:55:45 AM: Update 16138: task edges-pos-ontonotes, batch 138 (16138): mcc: 0.8880, acc: 0.8146, precision: 0.9252, recall: 0.8565, f1: 0.8895, edges-pos-ontonotes_loss: 0.0125
09/16 10:55:55 AM: Update 16200: task edges-pos-ontonotes, batch 200 (16200): mcc: 0.8908, acc: 0.8188, precision: 0.9274, recall: 0.8598, f1: 0.8923, edges-pos-ontonotes_loss: 0.0123
09/16 10:56:05 AM: Update 16265: task edges-pos-ontonotes, batch 265 (16265): mcc: 0.8924, acc: 0.8211, precision: 0.9283, recall: 0.8619, f1: 0.8939, edges-pos-ontonotes_loss: 0.0123
09/16 10:56:15 AM: Update 16319: task edges-pos-ontonotes, batch 319 (16319): mcc: 0.8934, acc: 0.8226, precision: 0.9291, recall: 0.8631, f1: 0.8949, edges-pos-ontonotes_loss: 0.0122
09/16 10:56:25 AM: Update 16374: task edges-pos-ontonotes, batch 374 (16374): mcc: 0.8933, acc: 0.8228, precision: 0.9290, recall: 0.8631, f1: 0.8948, edges-pos-ontonotes_loss: 0.0123
09/16 10:56:35 AM: Update 16437: task edges-pos-ontonotes, batch 437 (16437): mcc: 0.8929, acc: 0.8227, precision: 0.9289, recall: 0.8623, f1: 0.8944, edges-pos-ontonotes_loss: 0.0124
09/16 10:56:45 AM: Update 16511: task edges-pos-ontonotes, batch 511 (16511): mcc: 0.8929, acc: 0.8228, precision: 0.9291, recall: 0.8621, f1: 0.8944, edges-pos-ontonotes_loss: 0.0124
09/16 10:56:55 AM: Update 16584: task edges-pos-ontonotes, batch 584 (16584): mcc: 0.8930, acc: 0.8231, precision: 0.9291, recall: 0.8623, f1: 0.8945, edges-pos-ontonotes_loss: 0.0124
09/16 10:57:06 AM: Update 16658: task edges-pos-ontonotes, batch 658 (16658): mcc: 0.8934, acc: 0.8239, precision: 0.9294, recall: 0.8629, f1: 0.8949, edges-pos-ontonotes_loss: 0.0124
09/16 10:57:16 AM: Update 16751: task edges-pos-ontonotes, batch 751 (16751): mcc: 0.8896, acc: 0.8183, precision: 0.9266, recall: 0.8583, f1: 0.8911, edges-pos-ontonotes_loss: 0.0130
09/16 10:57:26 AM: Update 16839: task edges-pos-ontonotes, batch 839 (16839): mcc: 0.8871, acc: 0.8148, precision: 0.9250, recall: 0.8551, f1: 0.8887, edges-pos-ontonotes_loss: 0.0134
09/16 10:57:36 AM: Update 16931: task edges-pos-ontonotes, batch 931 (16931): mcc: 0.8847, acc: 0.8113, precision: 0.9232, recall: 0.8521, f1: 0.8862, edges-pos-ontonotes_loss: 0.0137
09/16 10:57:46 AM: Update 16980: task edges-pos-ontonotes, batch 980 (16980): mcc: 0.8832, acc: 0.8093, precision: 0.9220, recall: 0.8504, f1: 0.8848, edges-pos-ontonotes_loss: 0.0138
09/16 10:57:52 AM: ***** Step 17000 / Validation 17 *****
09/16 10:57:52 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 10:57:52 AM: Validating...
09/16 10:57:57 AM: Evaluate: task edges-pos-ontonotes, batch 24 (157): mcc: 0.8787, acc: 0.8075, precision: 0.9317, recall: 0.8332, f1: 0.8797, edges-pos-ontonotes_loss: 0.0135
09/16 10:58:07 AM: Evaluate: task edges-pos-ontonotes, batch 74 (157): mcc: 0.8948, acc: 0.8321, precision: 0.9399, recall: 0.8558, f1: 0.8959, edges-pos-ontonotes_loss: 0.0123
09/16 10:58:17 AM: Evaluate: task edges-pos-ontonotes, batch 113 (157): mcc: 0.8930, acc: 0.8302, precision: 0.9380, recall: 0.8543, f1: 0.8942, edges-pos-ontonotes_loss: 0.0123
09/16 10:58:27 AM: Evaluate: task edges-pos-ontonotes, batch 142 (157): mcc: 0.8925, acc: 0.8294, precision: 0.9361, recall: 0.8549, f1: 0.8937, edges-pos-ontonotes_loss: 0.0123
09/16 10:58:32 AM: Updating LR scheduler:
09/16 10:58:32 AM: 	Best result seen so far for macro_avg: 0.902
09/16 10:58:32 AM: 	# validation passes without improvement: 2
09/16 10:58:32 AM: edges-pos-ontonotes_loss: training: 0.013897 validation: 0.012173
09/16 10:58:32 AM: macro_avg: validation: 0.894939
09/16 10:58:32 AM: micro_avg: validation: 0.000000
09/16 10:58:32 AM: edges-pos-ontonotes_mcc: training: 0.881765 validation: 0.893717
09/16 10:58:32 AM: edges-pos-ontonotes_acc: training: 0.807244 validation: 0.831772
09/16 10:58:32 AM: edges-pos-ontonotes_precision: training: 0.920851 validation: 0.936404
09/16 10:58:32 AM: edges-pos-ontonotes_recall: training: 0.848844 validation: 0.856990
09/16 10:58:32 AM: edges-pos-ontonotes_f1: training: 0.883383 validation: 0.894939
09/16 10:58:32 AM: Global learning rate: 0.0001
09/16 10:58:32 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 10:58:37 AM: Update 17021: task edges-pos-ontonotes, batch 21 (17021): mcc: 0.8541, acc: 0.7667, precision: 0.8963, recall: 0.8193, f1: 0.8561, edges-pos-ontonotes_loss: 0.0173
09/16 10:58:47 AM: Update 17062: task edges-pos-ontonotes, batch 62 (17062): mcc: 0.8527, acc: 0.7652, precision: 0.8958, recall: 0.8173, f1: 0.8547, edges-pos-ontonotes_loss: 0.0173
09/16 10:58:58 AM: Update 17095: task edges-pos-ontonotes, batch 95 (17095): mcc: 0.8515, acc: 0.7630, precision: 0.8939, recall: 0.8166, f1: 0.8535, edges-pos-ontonotes_loss: 0.0177
09/16 10:59:08 AM: Update 17131: task edges-pos-ontonotes, batch 131 (17131): mcc: 0.8517, acc: 0.7636, precision: 0.8941, recall: 0.8170, f1: 0.8538, edges-pos-ontonotes_loss: 0.0175
09/16 10:59:18 AM: Update 17167: task edges-pos-ontonotes, batch 167 (17167): mcc: 0.8525, acc: 0.7647, precision: 0.8948, recall: 0.8178, f1: 0.8546, edges-pos-ontonotes_loss: 0.0174
09/16 10:59:28 AM: Update 17209: task edges-pos-ontonotes, batch 209 (17209): mcc: 0.8530, acc: 0.7656, precision: 0.8952, recall: 0.8184, f1: 0.8551, edges-pos-ontonotes_loss: 0.0174
09/16 10:59:38 AM: Update 17251: task edges-pos-ontonotes, batch 251 (17251): mcc: 0.8528, acc: 0.7655, precision: 0.8950, recall: 0.8181, f1: 0.8548, edges-pos-ontonotes_loss: 0.0174
09/16 10:59:48 AM: Update 17288: task edges-pos-ontonotes, batch 288 (17288): mcc: 0.8525, acc: 0.7652, precision: 0.8951, recall: 0.8176, f1: 0.8546, edges-pos-ontonotes_loss: 0.0175
09/16 11:00:04 AM: Update 17301: task edges-pos-ontonotes, batch 301 (17301): mcc: 0.8522, acc: 0.7647, precision: 0.8949, recall: 0.8171, f1: 0.8542, edges-pos-ontonotes_loss: 0.0175
09/16 11:00:14 AM: Update 17354: task edges-pos-ontonotes, batch 354 (17354): mcc: 0.8522, acc: 0.7645, precision: 0.8957, recall: 0.8163, f1: 0.8542, edges-pos-ontonotes_loss: 0.0174
09/16 11:00:24 AM: Update 17410: task edges-pos-ontonotes, batch 410 (17410): mcc: 0.8524, acc: 0.7647, precision: 0.8965, recall: 0.8160, f1: 0.8543, edges-pos-ontonotes_loss: 0.0172
09/16 11:00:35 AM: Update 17475: task edges-pos-ontonotes, batch 475 (17475): mcc: 0.8527, acc: 0.7649, precision: 0.8970, recall: 0.8160, f1: 0.8546, edges-pos-ontonotes_loss: 0.0170
09/16 11:00:45 AM: Update 17537: task edges-pos-ontonotes, batch 537 (17537): mcc: 0.8528, acc: 0.7650, precision: 0.8975, recall: 0.8158, f1: 0.8547, edges-pos-ontonotes_loss: 0.0168
09/16 11:00:55 AM: Update 17594: task edges-pos-ontonotes, batch 594 (17594): mcc: 0.8530, acc: 0.7653, precision: 0.8981, recall: 0.8158, f1: 0.8549, edges-pos-ontonotes_loss: 0.0167
09/16 11:01:05 AM: Update 17630: task edges-pos-ontonotes, batch 630 (17630): mcc: 0.8536, acc: 0.7661, precision: 0.8985, recall: 0.8164, f1: 0.8555, edges-pos-ontonotes_loss: 0.0166
09/16 11:01:15 AM: Update 17678: task edges-pos-ontonotes, batch 678 (17678): mcc: 0.8538, acc: 0.7664, precision: 0.8988, recall: 0.8166, f1: 0.8557, edges-pos-ontonotes_loss: 0.0166
09/16 11:01:25 AM: Update 17728: task edges-pos-ontonotes, batch 728 (17728): mcc: 0.8543, acc: 0.7671, precision: 0.8991, recall: 0.8172, f1: 0.8562, edges-pos-ontonotes_loss: 0.0165
09/16 11:01:36 AM: Update 17779: task edges-pos-ontonotes, batch 779 (17779): mcc: 0.8548, acc: 0.7679, precision: 0.8997, recall: 0.8177, f1: 0.8567, edges-pos-ontonotes_loss: 0.0164
09/16 11:01:46 AM: Update 17818: task edges-pos-ontonotes, batch 818 (17818): mcc: 0.8553, acc: 0.7684, precision: 0.9000, recall: 0.8182, f1: 0.8571, edges-pos-ontonotes_loss: 0.0164
09/16 11:01:56 AM: Update 17856: task edges-pos-ontonotes, batch 856 (17856): mcc: 0.8558, acc: 0.7691, precision: 0.9003, recall: 0.8188, f1: 0.8576, edges-pos-ontonotes_loss: 0.0164
09/16 11:02:06 AM: Update 17899: task edges-pos-ontonotes, batch 899 (17899): mcc: 0.8561, acc: 0.7696, precision: 0.9006, recall: 0.8192, f1: 0.8580, edges-pos-ontonotes_loss: 0.0163
09/16 11:02:16 AM: Update 17935: task edges-pos-ontonotes, batch 935 (17935): mcc: 0.8561, acc: 0.7696, precision: 0.9007, recall: 0.8191, f1: 0.8580, edges-pos-ontonotes_loss: 0.0163
09/16 11:02:26 AM: Update 17969: task edges-pos-ontonotes, batch 969 (17969): mcc: 0.8560, acc: 0.7696, precision: 0.9006, recall: 0.8190, f1: 0.8579, edges-pos-ontonotes_loss: 0.0163
09/16 11:02:34 AM: ***** Step 18000 / Validation 18 *****
09/16 11:02:34 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 11:02:34 AM: Validating...
09/16 11:02:36 AM: Evaluate: task edges-pos-ontonotes, batch 10 (157): mcc: 0.8860, acc: 0.8259, precision: 0.9298, recall: 0.8484, f1: 0.8873, edges-pos-ontonotes_loss: 0.0124
09/16 11:02:46 AM: Evaluate: task edges-pos-ontonotes, batch 60 (157): mcc: 0.8979, acc: 0.8366, precision: 0.9424, recall: 0.8593, f1: 0.8989, edges-pos-ontonotes_loss: 0.0118
09/16 11:02:56 AM: Evaluate: task edges-pos-ontonotes, batch 101 (157): mcc: 0.9011, acc: 0.8419, precision: 0.9422, recall: 0.8655, f1: 0.9022, edges-pos-ontonotes_loss: 0.0115
09/16 11:03:07 AM: Evaluate: task edges-pos-ontonotes, batch 132 (157): mcc: 0.9004, acc: 0.8412, precision: 0.9413, recall: 0.8651, f1: 0.9016, edges-pos-ontonotes_loss: 0.0115
09/16 11:03:15 AM: Best result seen so far for edges-pos-ontonotes.
09/16 11:03:15 AM: Best result seen so far for macro.
09/16 11:03:15 AM: Updating LR scheduler:
09/16 11:03:15 AM: 	Best result seen so far for macro_avg: 0.902
09/16 11:03:15 AM: 	# validation passes without improvement: 3
09/16 11:03:15 AM: edges-pos-ontonotes_loss: training: 0.016337 validation: 0.011440
09/16 11:03:15 AM: macro_avg: validation: 0.901647
09/16 11:03:15 AM: micro_avg: validation: 0.000000
09/16 11:03:15 AM: edges-pos-ontonotes_mcc: training: 0.855900 validation: 0.900435
09/16 11:03:15 AM: edges-pos-ontonotes_acc: training: 0.769448 validation: 0.842270
09/16 11:03:15 AM: edges-pos-ontonotes_precision: training: 0.900466 validation: 0.940310
09/16 11:03:15 AM: edges-pos-ontonotes_recall: training: 0.818955 validation: 0.866038
09/16 11:03:15 AM: edges-pos-ontonotes_f1: training: 0.857778 validation: 0.901647
09/16 11:03:15 AM: Global learning rate: 0.0001
09/16 11:03:15 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 11:03:17 AM: Update 18007: task edges-pos-ontonotes, batch 7 (18007): mcc: 0.8577, acc: 0.7747, precision: 0.8998, recall: 0.8229, f1: 0.8596, edges-pos-ontonotes_loss: 0.0160
09/16 11:03:27 AM: Update 18047: task edges-pos-ontonotes, batch 47 (18047): mcc: 0.8568, acc: 0.7717, precision: 0.9003, recall: 0.8208, f1: 0.8587, edges-pos-ontonotes_loss: 0.0162
09/16 11:03:37 AM: Update 18083: task edges-pos-ontonotes, batch 83 (18083): mcc: 0.8553, acc: 0.7705, precision: 0.8982, recall: 0.8199, f1: 0.8573, edges-pos-ontonotes_loss: 0.0168
09/16 11:03:47 AM: Update 18120: task edges-pos-ontonotes, batch 120 (18120): mcc: 0.8566, acc: 0.7722, precision: 0.8995, recall: 0.8212, f1: 0.8586, edges-pos-ontonotes_loss: 0.0167
09/16 11:03:57 AM: Update 18159: task edges-pos-ontonotes, batch 159 (18159): mcc: 0.8580, acc: 0.7742, precision: 0.9007, recall: 0.8227, f1: 0.8599, edges-pos-ontonotes_loss: 0.0165
09/16 11:04:07 AM: Update 18199: task edges-pos-ontonotes, batch 199 (18199): mcc: 0.8587, acc: 0.7751, precision: 0.9017, recall: 0.8230, f1: 0.8606, edges-pos-ontonotes_loss: 0.0163
09/16 11:04:20 AM: Update 18240: task edges-pos-ontonotes, batch 240 (18240): mcc: 0.8580, acc: 0.7742, precision: 0.9015, recall: 0.8220, f1: 0.8599, edges-pos-ontonotes_loss: 0.0165
09/16 11:04:30 AM: Update 18272: task edges-pos-ontonotes, batch 272 (18272): mcc: 0.8581, acc: 0.7742, precision: 0.9015, recall: 0.8221, f1: 0.8599, edges-pos-ontonotes_loss: 0.0165
09/16 11:04:40 AM: Update 18305: task edges-pos-ontonotes, batch 305 (18305): mcc: 0.8577, acc: 0.7736, precision: 0.9014, recall: 0.8215, f1: 0.8596, edges-pos-ontonotes_loss: 0.0164
09/16 11:04:50 AM: Update 18341: task edges-pos-ontonotes, batch 341 (18341): mcc: 0.8578, acc: 0.7738, precision: 0.9015, recall: 0.8216, f1: 0.8597, edges-pos-ontonotes_loss: 0.0165
09/16 11:05:00 AM: Update 18377: task edges-pos-ontonotes, batch 377 (18377): mcc: 0.8581, acc: 0.7742, precision: 0.9018, recall: 0.8218, f1: 0.8599, edges-pos-ontonotes_loss: 0.0164
09/16 11:05:10 AM: Update 18414: task edges-pos-ontonotes, batch 414 (18414): mcc: 0.8582, acc: 0.7744, precision: 0.9020, recall: 0.8218, f1: 0.8601, edges-pos-ontonotes_loss: 0.0164
09/16 11:05:21 AM: Update 18451: task edges-pos-ontonotes, batch 451 (18451): mcc: 0.8584, acc: 0.7749, precision: 0.9020, recall: 0.8221, f1: 0.8602, edges-pos-ontonotes_loss: 0.0164
09/16 11:05:31 AM: Update 18486: task edges-pos-ontonotes, batch 486 (18486): mcc: 0.8586, acc: 0.7753, precision: 0.9024, recall: 0.8223, f1: 0.8605, edges-pos-ontonotes_loss: 0.0163
09/16 11:05:41 AM: Update 18525: task edges-pos-ontonotes, batch 525 (18525): mcc: 0.8587, acc: 0.7754, precision: 0.9025, recall: 0.8223, f1: 0.8606, edges-pos-ontonotes_loss: 0.0163
09/16 11:05:52 AM: Update 18553: task edges-pos-ontonotes, batch 553 (18553): mcc: 0.8588, acc: 0.7755, precision: 0.9026, recall: 0.8224, f1: 0.8606, edges-pos-ontonotes_loss: 0.0163
09/16 11:06:02 AM: Update 18589: task edges-pos-ontonotes, batch 589 (18589): mcc: 0.8590, acc: 0.7759, precision: 0.9027, recall: 0.8227, f1: 0.8608, edges-pos-ontonotes_loss: 0.0162
09/16 11:06:12 AM: Update 18622: task edges-pos-ontonotes, batch 622 (18622): mcc: 0.8593, acc: 0.7764, precision: 0.9029, recall: 0.8231, f1: 0.8611, edges-pos-ontonotes_loss: 0.0162
09/16 11:06:22 AM: Update 18655: task edges-pos-ontonotes, batch 655 (18655): mcc: 0.8596, acc: 0.7768, precision: 0.9032, recall: 0.8233, f1: 0.8614, edges-pos-ontonotes_loss: 0.0162
09/16 11:06:32 AM: Update 18699: task edges-pos-ontonotes, batch 699 (18699): mcc: 0.8598, acc: 0.7772, precision: 0.9034, recall: 0.8236, f1: 0.8617, edges-pos-ontonotes_loss: 0.0162
09/16 11:06:42 AM: Update 18734: task edges-pos-ontonotes, batch 734 (18734): mcc: 0.8600, acc: 0.7775, precision: 0.9036, recall: 0.8239, f1: 0.8619, edges-pos-ontonotes_loss: 0.0162
09/16 11:06:53 AM: Update 18767: task edges-pos-ontonotes, batch 767 (18767): mcc: 0.8602, acc: 0.7778, precision: 0.9037, recall: 0.8241, f1: 0.8621, edges-pos-ontonotes_loss: 0.0161
09/16 11:07:03 AM: Update 18801: task edges-pos-ontonotes, batch 801 (18801): mcc: 0.8603, acc: 0.7780, precision: 0.9038, recall: 0.8242, f1: 0.8622, edges-pos-ontonotes_loss: 0.0162
09/16 11:07:13 AM: Update 18836: task edges-pos-ontonotes, batch 836 (18836): mcc: 0.8606, acc: 0.7784, precision: 0.9040, recall: 0.8245, f1: 0.8624, edges-pos-ontonotes_loss: 0.0161
09/16 11:07:24 AM: Update 18866: task edges-pos-ontonotes, batch 866 (18866): mcc: 0.8607, acc: 0.7785, precision: 0.9040, recall: 0.8247, f1: 0.8625, edges-pos-ontonotes_loss: 0.0161
09/16 11:07:34 AM: Update 18898: task edges-pos-ontonotes, batch 898 (18898): mcc: 0.8608, acc: 0.7787, precision: 0.9042, recall: 0.8248, f1: 0.8627, edges-pos-ontonotes_loss: 0.0161
09/16 11:07:45 AM: Update 18938: task edges-pos-ontonotes, batch 938 (18938): mcc: 0.8611, acc: 0.7791, precision: 0.9044, recall: 0.8251, f1: 0.8629, edges-pos-ontonotes_loss: 0.0161
09/16 11:07:55 AM: Update 18975: task edges-pos-ontonotes, batch 975 (18975): mcc: 0.8611, acc: 0.7792, precision: 0.9044, recall: 0.8251, f1: 0.8630, edges-pos-ontonotes_loss: 0.0161
09/16 11:08:00 AM: ***** Step 19000 / Validation 19 *****
09/16 11:08:00 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 11:08:00 AM: Validating...
09/16 11:08:05 AM: Evaluate: task edges-pos-ontonotes, batch 22 (157): mcc: 0.8830, acc: 0.8152, precision: 0.9303, recall: 0.8424, f1: 0.8842, edges-pos-ontonotes_loss: 0.0129
09/16 11:08:15 AM: Evaluate: task edges-pos-ontonotes, batch 74 (157): mcc: 0.8977, acc: 0.8367, precision: 0.9381, recall: 0.8629, f1: 0.8989, edges-pos-ontonotes_loss: 0.0121
09/16 11:08:25 AM: Evaluate: task edges-pos-ontonotes, batch 113 (157): mcc: 0.8994, acc: 0.8409, precision: 0.9380, recall: 0.8662, f1: 0.9007, edges-pos-ontonotes_loss: 0.0118
09/16 11:08:35 AM: Evaluate: task edges-pos-ontonotes, batch 144 (157): mcc: 0.9009, acc: 0.8439, precision: 0.9376, recall: 0.8695, f1: 0.9023, edges-pos-ontonotes_loss: 0.0116
09/16 11:08:39 AM: Best result seen so far for edges-pos-ontonotes.
09/16 11:08:39 AM: Best result seen so far for macro.
09/16 11:08:39 AM: Updating LR scheduler:
09/16 11:08:39 AM: 	Best result seen so far for macro_avg: 0.904
09/16 11:08:39 AM: 	# validation passes without improvement: 0
09/16 11:08:39 AM: edges-pos-ontonotes_loss: training: 0.016086 validation: 0.011493
09/16 11:08:39 AM: macro_avg: validation: 0.903714
09/16 11:08:39 AM: micro_avg: validation: 0.000000
09/16 11:08:39 AM: edges-pos-ontonotes_mcc: training: 0.861200 validation: 0.902374
09/16 11:08:39 AM: edges-pos-ontonotes_acc: training: 0.779378 validation: 0.846524
09/16 11:08:39 AM: edges-pos-ontonotes_precision: training: 0.904491 validation: 0.938097
09/16 11:08:39 AM: edges-pos-ontonotes_recall: training: 0.825214 validation: 0.871763
09/16 11:08:39 AM: edges-pos-ontonotes_f1: training: 0.863036 validation: 0.903714
09/16 11:08:39 AM: Global learning rate: 0.0001
09/16 11:08:39 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 11:08:46 AM: Update 19021: task edges-pos-ontonotes, batch 21 (19021): mcc: 0.8655, acc: 0.7861, precision: 0.9084, recall: 0.8297, f1: 0.8673, edges-pos-ontonotes_loss: 0.0156
09/16 11:08:56 AM: Update 19060: task edges-pos-ontonotes, batch 60 (19060): mcc: 0.8655, acc: 0.7862, precision: 0.9082, recall: 0.8299, f1: 0.8673, edges-pos-ontonotes_loss: 0.0162
09/16 11:09:06 AM: Update 19098: task edges-pos-ontonotes, batch 98 (19098): mcc: 0.8653, acc: 0.7859, precision: 0.9090, recall: 0.8288, f1: 0.8671, edges-pos-ontonotes_loss: 0.0163
09/16 11:09:16 AM: Update 19137: task edges-pos-ontonotes, batch 137 (19137): mcc: 0.8652, acc: 0.7857, precision: 0.9085, recall: 0.8290, f1: 0.8669, edges-pos-ontonotes_loss: 0.0162
09/16 11:09:26 AM: Update 19173: task edges-pos-ontonotes, batch 173 (19173): mcc: 0.8648, acc: 0.7855, precision: 0.9079, recall: 0.8289, f1: 0.8666, edges-pos-ontonotes_loss: 0.0161
09/16 11:09:40 AM: Update 19179: task edges-pos-ontonotes, batch 179 (19179): mcc: 0.8641, acc: 0.7846, precision: 0.9073, recall: 0.8280, f1: 0.8658, edges-pos-ontonotes_loss: 0.0162
09/16 11:09:50 AM: Update 19216: task edges-pos-ontonotes, batch 216 (19216): mcc: 0.8644, acc: 0.7851, precision: 0.9069, recall: 0.8290, f1: 0.8662, edges-pos-ontonotes_loss: 0.0159
09/16 11:10:00 AM: Update 19258: task edges-pos-ontonotes, batch 258 (19258): mcc: 0.8650, acc: 0.7858, precision: 0.9073, recall: 0.8297, f1: 0.8668, edges-pos-ontonotes_loss: 0.0156
09/16 11:10:10 AM: Update 19305: task edges-pos-ontonotes, batch 305 (19305): mcc: 0.8663, acc: 0.7874, precision: 0.9083, recall: 0.8313, f1: 0.8681, edges-pos-ontonotes_loss: 0.0152
09/16 11:10:20 AM: Update 19351: task edges-pos-ontonotes, batch 351 (19351): mcc: 0.8676, acc: 0.7891, precision: 0.9093, recall: 0.8328, f1: 0.8694, edges-pos-ontonotes_loss: 0.0150
09/16 11:10:30 AM: Update 19392: task edges-pos-ontonotes, batch 392 (19392): mcc: 0.8676, acc: 0.7893, precision: 0.9091, recall: 0.8330, f1: 0.8694, edges-pos-ontonotes_loss: 0.0149
09/16 11:10:40 AM: Update 19438: task edges-pos-ontonotes, batch 438 (19438): mcc: 0.8686, acc: 0.7907, precision: 0.9099, recall: 0.8342, f1: 0.8704, edges-pos-ontonotes_loss: 0.0147
09/16 11:10:51 AM: Update 19484: task edges-pos-ontonotes, batch 484 (19484): mcc: 0.8695, acc: 0.7918, precision: 0.9105, recall: 0.8352, f1: 0.8713, edges-pos-ontonotes_loss: 0.0145
09/16 11:11:01 AM: Update 19530: task edges-pos-ontonotes, batch 530 (19530): mcc: 0.8707, acc: 0.7934, precision: 0.9115, recall: 0.8366, f1: 0.8724, edges-pos-ontonotes_loss: 0.0143
09/16 11:11:11 AM: Update 19594: task edges-pos-ontonotes, batch 594 (19594): mcc: 0.8726, acc: 0.7957, precision: 0.9129, recall: 0.8388, f1: 0.8743, edges-pos-ontonotes_loss: 0.0141
09/16 11:11:21 AM: Update 19648: task edges-pos-ontonotes, batch 648 (19648): mcc: 0.8740, acc: 0.7976, precision: 0.9140, recall: 0.8405, f1: 0.8757, edges-pos-ontonotes_loss: 0.0139
09/16 11:11:31 AM: Update 19707: task edges-pos-ontonotes, batch 707 (19707): mcc: 0.8759, acc: 0.8002, precision: 0.9155, recall: 0.8428, f1: 0.8776, edges-pos-ontonotes_loss: 0.0137
09/16 11:11:41 AM: Update 19768: task edges-pos-ontonotes, batch 768 (19768): mcc: 0.8772, acc: 0.8019, precision: 0.9164, recall: 0.8444, f1: 0.8789, edges-pos-ontonotes_loss: 0.0135
09/16 11:11:51 AM: Update 19817: task edges-pos-ontonotes, batch 817 (19817): mcc: 0.8780, acc: 0.8030, precision: 0.9169, recall: 0.8454, f1: 0.8797, edges-pos-ontonotes_loss: 0.0135
09/16 11:12:01 AM: Update 19894: task edges-pos-ontonotes, batch 894 (19894): mcc: 0.8788, acc: 0.8041, precision: 0.9176, recall: 0.8462, f1: 0.8805, edges-pos-ontonotes_loss: 0.0134
09/16 11:12:11 AM: Update 19970: task edges-pos-ontonotes, batch 970 (19970): mcc: 0.8795, acc: 0.8051, precision: 0.9182, recall: 0.8469, f1: 0.8811, edges-pos-ontonotes_loss: 0.0133
09/16 11:12:14 AM: ***** Step 20000 / Validation 20 *****
09/16 11:12:14 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 11:12:14 AM: Validating...
09/16 11:12:21 AM: Evaluate: task edges-pos-ontonotes, batch 34 (157): mcc: 0.8880, acc: 0.8213, precision: 0.9378, recall: 0.8449, f1: 0.8889, edges-pos-ontonotes_loss: 0.0128
09/16 11:12:32 AM: Evaluate: task edges-pos-ontonotes, batch 84 (157): mcc: 0.8972, acc: 0.8364, precision: 0.9413, recall: 0.8591, f1: 0.8983, edges-pos-ontonotes_loss: 0.0121
09/16 11:12:42 AM: Evaluate: task edges-pos-ontonotes, batch 119 (157): mcc: 0.8962, acc: 0.8357, precision: 0.9404, recall: 0.8579, f1: 0.8973, edges-pos-ontonotes_loss: 0.0121
09/16 11:12:52 AM: Evaluate: task edges-pos-ontonotes, batch 153 (157): mcc: 0.8971, acc: 0.8377, precision: 0.9396, recall: 0.8604, f1: 0.8983, edges-pos-ontonotes_loss: 0.0119
09/16 11:12:53 AM: Updating LR scheduler:
09/16 11:12:53 AM: 	Best result seen so far for macro_avg: 0.904
09/16 11:12:53 AM: 	# validation passes without improvement: 1
09/16 11:12:53 AM: edges-pos-ontonotes_loss: training: 0.013298 validation: 0.011951
09/16 11:12:53 AM: macro_avg: validation: 0.898055
09/16 11:12:53 AM: micro_avg: validation: 0.000000
09/16 11:12:53 AM: edges-pos-ontonotes_mcc: training: 0.879767 validation: 0.896890
09/16 11:12:53 AM: edges-pos-ontonotes_acc: training: 0.805599 validation: 0.837572
09/16 11:12:53 AM: edges-pos-ontonotes_precision: training: 0.918493 validation: 0.939438
09/16 11:12:53 AM: edges-pos-ontonotes_recall: training: 0.847261 validation: 0.860165
09/16 11:12:53 AM: edges-pos-ontonotes_f1: training: 0.881440 validation: 0.898055
09/16 11:12:53 AM: Global learning rate: 0.0001
09/16 11:12:53 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 11:13:02 AM: Update 20055: task edges-pos-ontonotes, batch 55 (20055): mcc: 0.8992, acc: 0.8347, precision: 0.9312, recall: 0.8721, f1: 0.9007, edges-pos-ontonotes_loss: 0.0121
09/16 11:13:12 AM: Update 20113: task edges-pos-ontonotes, batch 113 (20113): mcc: 0.8974, acc: 0.8316, precision: 0.9307, recall: 0.8692, f1: 0.8989, edges-pos-ontonotes_loss: 0.0122
09/16 11:13:22 AM: Update 20194: task edges-pos-ontonotes, batch 194 (20194): mcc: 0.8844, acc: 0.8132, precision: 0.9205, recall: 0.8541, f1: 0.8860, edges-pos-ontonotes_loss: 0.0138
09/16 11:13:32 AM: Update 20285: task edges-pos-ontonotes, batch 285 (20285): mcc: 0.8771, acc: 0.8021, precision: 0.9162, recall: 0.8443, f1: 0.8788, edges-pos-ontonotes_loss: 0.0147
09/16 11:13:42 AM: Update 20371: task edges-pos-ontonotes, batch 371 (20371): mcc: 0.8734, acc: 0.7967, precision: 0.9138, recall: 0.8397, f1: 0.8751, edges-pos-ontonotes_loss: 0.0151
09/16 11:13:53 AM: Update 20431: task edges-pos-ontonotes, batch 431 (20431): mcc: 0.8706, acc: 0.7927, precision: 0.9111, recall: 0.8368, f1: 0.8724, edges-pos-ontonotes_loss: 0.0153
09/16 11:14:03 AM: Update 20470: task edges-pos-ontonotes, batch 470 (20470): mcc: 0.8673, acc: 0.7877, precision: 0.9080, recall: 0.8334, f1: 0.8691, edges-pos-ontonotes_loss: 0.0155
09/16 11:14:13 AM: Update 20510: task edges-pos-ontonotes, batch 510 (20510): mcc: 0.8658, acc: 0.7855, precision: 0.9069, recall: 0.8317, f1: 0.8677, edges-pos-ontonotes_loss: 0.0156
09/16 11:14:23 AM: Update 20549: task edges-pos-ontonotes, batch 549 (20549): mcc: 0.8643, acc: 0.7832, precision: 0.9057, recall: 0.8299, f1: 0.8662, edges-pos-ontonotes_loss: 0.0158
09/16 11:14:33 AM: Update 20588: task edges-pos-ontonotes, batch 588 (20588): mcc: 0.8632, acc: 0.7815, precision: 0.9044, recall: 0.8291, f1: 0.8651, edges-pos-ontonotes_loss: 0.0159
09/16 11:14:44 AM: Update 20635: task edges-pos-ontonotes, batch 635 (20635): mcc: 0.8622, acc: 0.7799, precision: 0.9035, recall: 0.8280, f1: 0.8641, edges-pos-ontonotes_loss: 0.0160
09/16 11:14:54 AM: Update 20673: task edges-pos-ontonotes, batch 673 (20673): mcc: 0.8617, acc: 0.7793, precision: 0.9029, recall: 0.8277, f1: 0.8636, edges-pos-ontonotes_loss: 0.0160
09/16 11:15:04 AM: Update 20710: task edges-pos-ontonotes, batch 710 (20710): mcc: 0.8608, acc: 0.7779, precision: 0.9023, recall: 0.8266, f1: 0.8628, edges-pos-ontonotes_loss: 0.0161
09/16 11:15:14 AM: Update 20744: task edges-pos-ontonotes, batch 744 (20744): mcc: 0.8607, acc: 0.7777, precision: 0.9022, recall: 0.8264, f1: 0.8626, edges-pos-ontonotes_loss: 0.0161
09/16 11:15:24 AM: Update 20780: task edges-pos-ontonotes, batch 780 (20780): mcc: 0.8601, acc: 0.7768, precision: 0.9019, recall: 0.8256, f1: 0.8620, edges-pos-ontonotes_loss: 0.0162
09/16 11:15:34 AM: Update 20837: task edges-pos-ontonotes, batch 837 (20837): mcc: 0.8598, acc: 0.7762, precision: 0.9020, recall: 0.8248, f1: 0.8617, edges-pos-ontonotes_loss: 0.0162
09/16 11:15:44 AM: Update 20897: task edges-pos-ontonotes, batch 897 (20897): mcc: 0.8596, acc: 0.7758, precision: 0.9022, recall: 0.8242, f1: 0.8615, edges-pos-ontonotes_loss: 0.0161
09/16 11:15:54 AM: Update 20953: task edges-pos-ontonotes, batch 953 (20953): mcc: 0.8596, acc: 0.7759, precision: 0.9026, recall: 0.8240, f1: 0.8615, edges-pos-ontonotes_loss: 0.0161
09/16 11:16:02 AM: ***** Step 21000 / Validation 21 *****
09/16 11:16:02 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 11:16:02 AM: Validating...
09/16 11:16:05 AM: Evaluate: task edges-pos-ontonotes, batch 10 (157): mcc: 0.8866, acc: 0.8265, precision: 0.9294, recall: 0.8500, f1: 0.8879, edges-pos-ontonotes_loss: 0.0126
09/16 11:16:15 AM: Evaluate: task edges-pos-ontonotes, batch 62 (157): mcc: 0.8999, acc: 0.8405, precision: 0.9414, recall: 0.8640, f1: 0.9011, edges-pos-ontonotes_loss: 0.0117
09/16 11:16:25 AM: Evaluate: task edges-pos-ontonotes, batch 103 (157): mcc: 0.9016, acc: 0.8441, precision: 0.9395, recall: 0.8690, f1: 0.9029, edges-pos-ontonotes_loss: 0.0115
09/16 11:16:35 AM: Evaluate: task edges-pos-ontonotes, batch 133 (157): mcc: 0.9002, acc: 0.8422, precision: 0.9374, recall: 0.8683, f1: 0.9015, edges-pos-ontonotes_loss: 0.0116
09/16 11:16:42 AM: Updating LR scheduler:
09/16 11:16:42 AM: 	Best result seen so far for macro_avg: 0.904
09/16 11:16:42 AM: 	# validation passes without improvement: 2
09/16 11:16:42 AM: edges-pos-ontonotes_loss: training: 0.016012 validation: 0.011530
09/16 11:16:42 AM: macro_avg: validation: 0.902137
09/16 11:16:42 AM: micro_avg: validation: 0.000000
09/16 11:16:42 AM: edges-pos-ontonotes_mcc: training: 0.859605 validation: 0.900764
09/16 11:16:42 AM: edges-pos-ontonotes_acc: training: 0.775746 validation: 0.843900
09/16 11:16:42 AM: edges-pos-ontonotes_precision: training: 0.902790 validation: 0.936498
09/16 11:16:42 AM: edges-pos-ontonotes_recall: training: 0.823780 validation: 0.870208
09/16 11:16:42 AM: edges-pos-ontonotes_f1: training: 0.861477 validation: 0.902137
09/16 11:16:42 AM: Global learning rate: 0.0001
09/16 11:16:42 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 11:16:45 AM: Update 21014: task edges-pos-ontonotes, batch 14 (21014): mcc: 0.8594, acc: 0.7707, precision: 0.9071, recall: 0.8193, f1: 0.8610, edges-pos-ontonotes_loss: 0.0152
09/16 11:16:56 AM: Update 21069: task edges-pos-ontonotes, batch 69 (21069): mcc: 0.8569, acc: 0.7708, precision: 0.9050, recall: 0.8167, f1: 0.8586, edges-pos-ontonotes_loss: 0.0154
09/16 11:17:06 AM: Update 21106: task edges-pos-ontonotes, batch 106 (21106): mcc: 0.8599, acc: 0.7752, precision: 0.9055, recall: 0.8219, f1: 0.8617, edges-pos-ontonotes_loss: 0.0155
09/16 11:17:16 AM: Update 21148: task edges-pos-ontonotes, batch 148 (21148): mcc: 0.8604, acc: 0.7762, precision: 0.9052, recall: 0.8232, f1: 0.8622, edges-pos-ontonotes_loss: 0.0156
09/16 11:17:26 AM: Update 21190: task edges-pos-ontonotes, batch 190 (21190): mcc: 0.8618, acc: 0.7775, precision: 0.9060, recall: 0.8249, f1: 0.8636, edges-pos-ontonotes_loss: 0.0156
09/16 11:17:36 AM: Update 21240: task edges-pos-ontonotes, batch 240 (21240): mcc: 0.8619, acc: 0.7778, precision: 0.9056, recall: 0.8255, f1: 0.8637, edges-pos-ontonotes_loss: 0.0156
09/16 11:17:46 AM: Update 21293: task edges-pos-ontonotes, batch 293 (21293): mcc: 0.8623, acc: 0.7783, precision: 0.9065, recall: 0.8255, f1: 0.8641, edges-pos-ontonotes_loss: 0.0155
09/16 11:17:56 AM: Update 21342: task edges-pos-ontonotes, batch 342 (21342): mcc: 0.8625, acc: 0.7785, precision: 0.9068, recall: 0.8256, f1: 0.8643, edges-pos-ontonotes_loss: 0.0155
09/16 11:18:19 AM: Update 21387: task edges-pos-ontonotes, batch 387 (21387): mcc: 0.8625, acc: 0.7786, precision: 0.9068, recall: 0.8256, f1: 0.8643, edges-pos-ontonotes_loss: 0.0154
09/16 11:18:29 AM: Update 21423: task edges-pos-ontonotes, batch 423 (21423): mcc: 0.8618, acc: 0.7779, precision: 0.9060, recall: 0.8250, f1: 0.8636, edges-pos-ontonotes_loss: 0.0155
09/16 11:18:39 AM: Update 21462: task edges-pos-ontonotes, batch 462 (21462): mcc: 0.8613, acc: 0.7773, precision: 0.9052, recall: 0.8247, f1: 0.8631, edges-pos-ontonotes_loss: 0.0156
09/16 11:18:49 AM: Update 21497: task edges-pos-ontonotes, batch 497 (21497): mcc: 0.8609, acc: 0.7769, precision: 0.9046, recall: 0.8246, f1: 0.8627, edges-pos-ontonotes_loss: 0.0157
09/16 11:18:59 AM: Update 21531: task edges-pos-ontonotes, batch 531 (21531): mcc: 0.8607, acc: 0.7768, precision: 0.9042, recall: 0.8245, f1: 0.8625, edges-pos-ontonotes_loss: 0.0157
09/16 11:19:10 AM: Update 21573: task edges-pos-ontonotes, batch 573 (21573): mcc: 0.8606, acc: 0.7768, precision: 0.9040, recall: 0.8245, f1: 0.8624, edges-pos-ontonotes_loss: 0.0158
09/16 11:19:20 AM: Update 21610: task edges-pos-ontonotes, batch 610 (21610): mcc: 0.8605, acc: 0.7768, precision: 0.9038, recall: 0.8244, f1: 0.8623, edges-pos-ontonotes_loss: 0.0159
09/16 11:19:30 AM: Update 21647: task edges-pos-ontonotes, batch 647 (21647): mcc: 0.8604, acc: 0.7768, precision: 0.9036, recall: 0.8245, f1: 0.8623, edges-pos-ontonotes_loss: 0.0159
09/16 11:19:40 AM: Update 21685: task edges-pos-ontonotes, batch 685 (21685): mcc: 0.8607, acc: 0.7771, precision: 0.9037, recall: 0.8249, f1: 0.8625, edges-pos-ontonotes_loss: 0.0159
09/16 11:19:51 AM: Update 21712: task edges-pos-ontonotes, batch 712 (21712): mcc: 0.8604, acc: 0.7769, precision: 0.9035, recall: 0.8247, f1: 0.8623, edges-pos-ontonotes_loss: 0.0159
09/16 11:20:01 AM: Update 21741: task edges-pos-ontonotes, batch 741 (21741): mcc: 0.8604, acc: 0.7768, precision: 0.9035, recall: 0.8245, f1: 0.8622, edges-pos-ontonotes_loss: 0.0159
09/16 11:20:11 AM: Update 21777: task edges-pos-ontonotes, batch 777 (21777): mcc: 0.8604, acc: 0.7769, precision: 0.9035, recall: 0.8245, f1: 0.8622, edges-pos-ontonotes_loss: 0.0159
09/16 11:20:21 AM: Update 21807: task edges-pos-ontonotes, batch 807 (21807): mcc: 0.8604, acc: 0.7769, precision: 0.9034, recall: 0.8247, f1: 0.8623, edges-pos-ontonotes_loss: 0.0159
09/16 11:20:31 AM: Update 21841: task edges-pos-ontonotes, batch 841 (21841): mcc: 0.8603, acc: 0.7768, precision: 0.9034, recall: 0.8246, f1: 0.8622, edges-pos-ontonotes_loss: 0.0159
09/16 11:20:42 AM: Update 21870: task edges-pos-ontonotes, batch 870 (21870): mcc: 0.8605, acc: 0.7770, precision: 0.9035, recall: 0.8247, f1: 0.8623, edges-pos-ontonotes_loss: 0.0159
09/16 11:20:52 AM: Update 21901: task edges-pos-ontonotes, batch 901 (21901): mcc: 0.8607, acc: 0.7774, precision: 0.9037, recall: 0.8249, f1: 0.8625, edges-pos-ontonotes_loss: 0.0159
09/16 11:21:02 AM: Update 21939: task edges-pos-ontonotes, batch 939 (21939): mcc: 0.8608, acc: 0.7776, precision: 0.9038, recall: 0.8252, f1: 0.8627, edges-pos-ontonotes_loss: 0.0159
09/16 11:21:13 AM: Update 21979: task edges-pos-ontonotes, batch 979 (21979): mcc: 0.8609, acc: 0.7778, precision: 0.9039, recall: 0.8252, f1: 0.8628, edges-pos-ontonotes_loss: 0.0159
09/16 11:21:18 AM: ***** Step 22000 / Validation 22 *****
09/16 11:21:18 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 11:21:18 AM: Validating...
09/16 11:21:23 AM: Evaluate: task edges-pos-ontonotes, batch 25 (157): mcc: 0.8873, acc: 0.8209, precision: 0.9348, recall: 0.8464, f1: 0.8884, edges-pos-ontonotes_loss: 0.0126
09/16 11:21:33 AM: Evaluate: task edges-pos-ontonotes, batch 76 (157): mcc: 0.9002, acc: 0.8400, precision: 0.9411, recall: 0.8648, f1: 0.9013, edges-pos-ontonotes_loss: 0.0117
09/16 11:21:43 AM: Evaluate: task edges-pos-ontonotes, batch 110 (157): mcc: 0.9012, acc: 0.8428, precision: 0.9409, recall: 0.8668, f1: 0.9024, edges-pos-ontonotes_loss: 0.0115
09/16 11:21:53 AM: Evaluate: task edges-pos-ontonotes, batch 142 (157): mcc: 0.9019, acc: 0.8448, precision: 0.9400, recall: 0.8691, f1: 0.9032, edges-pos-ontonotes_loss: 0.0114
09/16 11:21:57 AM: Best result seen so far for edges-pos-ontonotes.
09/16 11:21:57 AM: Best result seen so far for macro.
09/16 11:21:57 AM: Updating LR scheduler:
09/16 11:21:57 AM: 	Best result seen so far for macro_avg: 0.905
09/16 11:21:57 AM: 	# validation passes without improvement: 0
09/16 11:21:57 AM: edges-pos-ontonotes_loss: training: 0.015895 validation: 0.011281
09/16 11:21:57 AM: macro_avg: validation: 0.904516
09/16 11:21:57 AM: micro_avg: validation: 0.000000
09/16 11:21:57 AM: edges-pos-ontonotes_mcc: training: 0.860931 validation: 0.903248
09/16 11:21:57 AM: edges-pos-ontonotes_acc: training: 0.777878 validation: 0.847318
09/16 11:21:57 AM: edges-pos-ontonotes_precision: training: 0.903991 validation: 0.940380
09/16 11:21:57 AM: edges-pos-ontonotes_recall: training: 0.825168 validation: 0.871287
09/16 11:21:57 AM: edges-pos-ontonotes_f1: training: 0.862783 validation: 0.904516
09/16 11:21:57 AM: Global learning rate: 0.0001
09/16 11:21:57 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 11:22:04 AM: Update 22013: task edges-pos-ontonotes, batch 13 (22013): mcc: 0.8609, acc: 0.7773, precision: 0.9031, recall: 0.8260, f1: 0.8628, edges-pos-ontonotes_loss: 0.0159
09/16 11:22:14 AM: Update 22047: task edges-pos-ontonotes, batch 47 (22047): mcc: 0.8607, acc: 0.7794, precision: 0.9026, recall: 0.8260, f1: 0.8626, edges-pos-ontonotes_loss: 0.0164
09/16 11:22:24 AM: Update 22087: task edges-pos-ontonotes, batch 87 (22087): mcc: 0.8622, acc: 0.7807, precision: 0.9052, recall: 0.8265, f1: 0.8641, edges-pos-ontonotes_loss: 0.0163
09/16 11:22:34 AM: Update 22117: task edges-pos-ontonotes, batch 117 (22117): mcc: 0.8624, acc: 0.7812, precision: 0.9056, recall: 0.8265, f1: 0.8642, edges-pos-ontonotes_loss: 0.0161
09/16 11:22:45 AM: Update 22153: task edges-pos-ontonotes, batch 153 (22153): mcc: 0.8636, acc: 0.7831, precision: 0.9065, recall: 0.8279, f1: 0.8654, edges-pos-ontonotes_loss: 0.0158
09/16 11:22:55 AM: Update 22190: task edges-pos-ontonotes, batch 190 (22190): mcc: 0.8638, acc: 0.7836, precision: 0.9064, recall: 0.8284, f1: 0.8657, edges-pos-ontonotes_loss: 0.0158
09/16 11:23:05 AM: Update 22228: task edges-pos-ontonotes, batch 228 (22228): mcc: 0.8647, acc: 0.7848, precision: 0.9070, recall: 0.8296, f1: 0.8666, edges-pos-ontonotes_loss: 0.0156
09/16 11:23:15 AM: Update 22262: task edges-pos-ontonotes, batch 262 (22262): mcc: 0.8652, acc: 0.7855, precision: 0.9073, recall: 0.8302, f1: 0.8670, edges-pos-ontonotes_loss: 0.0156
09/16 11:23:25 AM: Update 22297: task edges-pos-ontonotes, batch 297 (22297): mcc: 0.8649, acc: 0.7851, precision: 0.9071, recall: 0.8298, f1: 0.8667, edges-pos-ontonotes_loss: 0.0156
09/16 11:23:35 AM: Update 22326: task edges-pos-ontonotes, batch 326 (22326): mcc: 0.8649, acc: 0.7851, precision: 0.9072, recall: 0.8298, f1: 0.8667, edges-pos-ontonotes_loss: 0.0156
09/16 11:23:45 AM: Update 22361: task edges-pos-ontonotes, batch 361 (22361): mcc: 0.8651, acc: 0.7855, precision: 0.9072, recall: 0.8300, f1: 0.8669, edges-pos-ontonotes_loss: 0.0156
09/16 11:23:56 AM: Update 22398: task edges-pos-ontonotes, batch 398 (22398): mcc: 0.8650, acc: 0.7854, precision: 0.9071, recall: 0.8299, f1: 0.8668, edges-pos-ontonotes_loss: 0.0156
09/16 11:24:06 AM: Update 22435: task edges-pos-ontonotes, batch 435 (22435): mcc: 0.8648, acc: 0.7851, precision: 0.9070, recall: 0.8297, f1: 0.8667, edges-pos-ontonotes_loss: 0.0156
09/16 11:24:16 AM: Update 22473: task edges-pos-ontonotes, batch 473 (22473): mcc: 0.8650, acc: 0.7853, precision: 0.9072, recall: 0.8299, f1: 0.8668, edges-pos-ontonotes_loss: 0.0157
09/16 11:24:26 AM: Update 22516: task edges-pos-ontonotes, batch 516 (22516): mcc: 0.8651, acc: 0.7855, precision: 0.9073, recall: 0.8299, f1: 0.8669, edges-pos-ontonotes_loss: 0.0157
09/16 11:24:36 AM: Update 22555: task edges-pos-ontonotes, batch 555 (22555): mcc: 0.8652, acc: 0.7857, precision: 0.9075, recall: 0.8300, f1: 0.8670, edges-pos-ontonotes_loss: 0.0157
09/16 11:24:46 AM: Update 22591: task edges-pos-ontonotes, batch 591 (22591): mcc: 0.8652, acc: 0.7858, precision: 0.9074, recall: 0.8300, f1: 0.8670, edges-pos-ontonotes_loss: 0.0157
09/16 11:24:56 AM: Update 22623: task edges-pos-ontonotes, batch 623 (22623): mcc: 0.8654, acc: 0.7861, precision: 0.9075, recall: 0.8302, f1: 0.8672, edges-pos-ontonotes_loss: 0.0157
09/16 11:25:07 AM: Update 22640: task edges-pos-ontonotes, batch 640 (22640): mcc: 0.8650, acc: 0.7856, precision: 0.9071, recall: 0.8299, f1: 0.8668, edges-pos-ontonotes_loss: 0.0157
09/16 11:25:17 AM: Update 22677: task edges-pos-ontonotes, batch 677 (22677): mcc: 0.8650, acc: 0.7858, precision: 0.9070, recall: 0.8301, f1: 0.8668, edges-pos-ontonotes_loss: 0.0157
09/16 11:25:27 AM: Update 22720: task edges-pos-ontonotes, batch 720 (22720): mcc: 0.8654, acc: 0.7863, precision: 0.9073, recall: 0.8305, f1: 0.8672, edges-pos-ontonotes_loss: 0.0155
09/16 11:25:37 AM: Update 22766: task edges-pos-ontonotes, batch 766 (22766): mcc: 0.8659, acc: 0.7869, precision: 0.9077, recall: 0.8310, f1: 0.8677, edges-pos-ontonotes_loss: 0.0154
09/16 11:25:47 AM: Update 22804: task edges-pos-ontonotes, batch 804 (22804): mcc: 0.8661, acc: 0.7872, precision: 0.9078, recall: 0.8314, f1: 0.8679, edges-pos-ontonotes_loss: 0.0153
09/16 11:25:57 AM: Update 22846: task edges-pos-ontonotes, batch 846 (22846): mcc: 0.8665, acc: 0.7877, precision: 0.9081, recall: 0.8319, f1: 0.8683, edges-pos-ontonotes_loss: 0.0152
09/16 11:26:07 AM: Update 22894: task edges-pos-ontonotes, batch 894 (22894): mcc: 0.8669, acc: 0.7883, precision: 0.9083, recall: 0.8325, f1: 0.8687, edges-pos-ontonotes_loss: 0.0151
09/16 11:26:17 AM: Update 22943: task edges-pos-ontonotes, batch 943 (22943): mcc: 0.8673, acc: 0.7888, precision: 0.9085, recall: 0.8329, f1: 0.8691, edges-pos-ontonotes_loss: 0.0150
09/16 11:26:27 AM: Update 22989: task edges-pos-ontonotes, batch 989 (22989): mcc: 0.8680, acc: 0.7898, precision: 0.9091, recall: 0.8338, f1: 0.8698, edges-pos-ontonotes_loss: 0.0149
09/16 11:26:29 AM: ***** Step 23000 / Validation 23 *****
09/16 11:26:29 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 11:26:29 AM: Validating...
09/16 11:26:37 AM: Evaluate: task edges-pos-ontonotes, batch 44 (157): mcc: 0.8918, acc: 0.8260, precision: 0.9387, recall: 0.8512, f1: 0.8928, edges-pos-ontonotes_loss: 0.0124
09/16 11:26:48 AM: Evaluate: task edges-pos-ontonotes, batch 92 (157): mcc: 0.9000, acc: 0.8402, precision: 0.9406, recall: 0.8649, f1: 0.9012, edges-pos-ontonotes_loss: 0.0117
09/16 11:26:58 AM: Evaluate: task edges-pos-ontonotes, batch 127 (157): mcc: 0.9001, acc: 0.8414, precision: 0.9404, recall: 0.8652, f1: 0.9013, edges-pos-ontonotes_loss: 0.0116
09/16 11:27:07 AM: Updating LR scheduler:
09/16 11:27:07 AM: 	Best result seen so far for macro_avg: 0.905
09/16 11:27:07 AM: 	# validation passes without improvement: 1
09/16 11:27:07 AM: edges-pos-ontonotes_loss: training: 0.014852 validation: 0.011386
09/16 11:27:07 AM: macro_avg: validation: 0.903142
09/16 11:27:07 AM: micro_avg: validation: 0.000000
09/16 11:27:07 AM: edges-pos-ontonotes_mcc: training: 0.868215 validation: 0.901895
09/16 11:27:07 AM: edges-pos-ontonotes_acc: training: 0.790038 validation: 0.845328
09/16 11:27:07 AM: edges-pos-ontonotes_precision: training: 0.909292 validation: 0.940224
09/16 11:27:07 AM: edges-pos-ontonotes_recall: training: 0.833990 validation: 0.868874
09/16 11:27:07 AM: edges-pos-ontonotes_f1: training: 0.870015 validation: 0.903142
09/16 11:27:07 AM: Global learning rate: 0.0001
09/16 11:27:07 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 11:27:08 AM: Update 23006: task edges-pos-ontonotes, batch 6 (23006): mcc: 0.8966, acc: 0.8295, precision: 0.9362, recall: 0.8626, f1: 0.8979, edges-pos-ontonotes_loss: 0.0118
09/16 11:27:18 AM: Update 23072: task edges-pos-ontonotes, batch 72 (23072): mcc: 0.8975, acc: 0.8302, precision: 0.9309, recall: 0.8693, f1: 0.8991, edges-pos-ontonotes_loss: 0.0120
09/16 11:27:28 AM: Update 23140: task edges-pos-ontonotes, batch 140 (23140): mcc: 0.8981, acc: 0.8306, precision: 0.9315, recall: 0.8698, f1: 0.8996, edges-pos-ontonotes_loss: 0.0118
09/16 11:27:38 AM: Update 23203: task edges-pos-ontonotes, batch 203 (23203): mcc: 0.9001, acc: 0.8333, precision: 0.9332, recall: 0.8720, f1: 0.9015, edges-pos-ontonotes_loss: 0.0115
09/16 11:27:59 AM: Update 23265: task edges-pos-ontonotes, batch 265 (23265): mcc: 0.9007, acc: 0.8342, precision: 0.9331, recall: 0.8732, f1: 0.9022, edges-pos-ontonotes_loss: 0.0115
09/16 11:28:09 AM: Update 23329: task edges-pos-ontonotes, batch 329 (23329): mcc: 0.8997, acc: 0.8331, precision: 0.9326, recall: 0.8717, f1: 0.9012, edges-pos-ontonotes_loss: 0.0119
09/16 11:28:19 AM: Update 23409: task edges-pos-ontonotes, batch 409 (23409): mcc: 0.8989, acc: 0.8323, precision: 0.9322, recall: 0.8707, f1: 0.9004, edges-pos-ontonotes_loss: 0.0119
09/16 11:28:29 AM: Update 23485: task edges-pos-ontonotes, batch 485 (23485): mcc: 0.8987, acc: 0.8322, precision: 0.9320, recall: 0.8704, f1: 0.9002, edges-pos-ontonotes_loss: 0.0119
09/16 11:28:39 AM: Update 23557: task edges-pos-ontonotes, batch 557 (23557): mcc: 0.8983, acc: 0.8318, precision: 0.9318, recall: 0.8699, f1: 0.8998, edges-pos-ontonotes_loss: 0.0120
09/16 11:28:49 AM: Update 23631: task edges-pos-ontonotes, batch 631 (23631): mcc: 0.8952, acc: 0.8275, precision: 0.9293, recall: 0.8664, f1: 0.8967, edges-pos-ontonotes_loss: 0.0125
09/16 11:28:59 AM: Update 23726: task edges-pos-ontonotes, batch 726 (23726): mcc: 0.8915, acc: 0.8221, precision: 0.9269, recall: 0.8617, f1: 0.8931, edges-pos-ontonotes_loss: 0.0130
09/16 11:29:09 AM: Update 23819: task edges-pos-ontonotes, batch 819 (23819): mcc: 0.8889, acc: 0.8185, precision: 0.9250, recall: 0.8586, f1: 0.8905, edges-pos-ontonotes_loss: 0.0134
09/16 11:29:20 AM: Update 23891: task edges-pos-ontonotes, batch 891 (23891): mcc: 0.8869, acc: 0.8156, precision: 0.9233, recall: 0.8562, f1: 0.8885, edges-pos-ontonotes_loss: 0.0135
09/16 11:29:31 AM: Update 23926: task edges-pos-ontonotes, batch 926 (23926): mcc: 0.8842, acc: 0.8117, precision: 0.9212, recall: 0.8532, f1: 0.8859, edges-pos-ontonotes_loss: 0.0137
09/16 11:29:41 AM: Update 23964: task edges-pos-ontonotes, batch 964 (23964): mcc: 0.8820, acc: 0.8085, precision: 0.9192, recall: 0.8509, f1: 0.8837, edges-pos-ontonotes_loss: 0.0138
09/16 11:29:48 AM: ***** Step 24000 / Validation 24 *****
09/16 11:29:48 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 11:29:48 AM: Validating...
09/16 11:29:51 AM: Evaluate: task edges-pos-ontonotes, batch 12 (157): mcc: 0.8879, acc: 0.8245, precision: 0.9280, recall: 0.8538, f1: 0.8894, edges-pos-ontonotes_loss: 0.0126
09/16 11:30:01 AM: Evaluate: task edges-pos-ontonotes, batch 65 (157): mcc: 0.8974, acc: 0.8363, precision: 0.9377, recall: 0.8627, f1: 0.8987, edges-pos-ontonotes_loss: 0.0121
09/16 11:30:11 AM: Evaluate: task edges-pos-ontonotes, batch 106 (157): mcc: 0.8981, acc: 0.8383, precision: 0.9358, recall: 0.8659, f1: 0.8995, edges-pos-ontonotes_loss: 0.0118
09/16 11:30:21 AM: Evaluate: task edges-pos-ontonotes, batch 138 (157): mcc: 0.8966, acc: 0.8367, precision: 0.9322, recall: 0.8664, f1: 0.8981, edges-pos-ontonotes_loss: 0.0118
09/16 11:30:27 AM: Updating LR scheduler:
09/16 11:30:27 AM: 	Best result seen so far for macro_avg: 0.905
09/16 11:30:27 AM: 	# validation passes without improvement: 2
09/16 11:30:27 AM: edges-pos-ontonotes_loss: training: 0.013995 validation: 0.011732
09/16 11:30:27 AM: macro_avg: validation: 0.899325
09/16 11:30:27 AM: micro_avg: validation: 0.000000
09/16 11:30:27 AM: edges-pos-ontonotes_mcc: training: 0.880519 validation: 0.897837
09/16 11:30:27 AM: edges-pos-ontonotes_acc: training: 0.806344 validation: 0.839095
09/16 11:30:27 AM: edges-pos-ontonotes_precision: training: 0.917839 validation: 0.932084
09/16 11:30:27 AM: edges-pos-ontonotes_recall: training: 0.849290 validation: 0.868789
09/16 11:30:27 AM: edges-pos-ontonotes_f1: training: 0.882235 validation: 0.899325
09/16 11:30:27 AM: Global learning rate: 0.0001
09/16 11:30:27 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 11:30:31 AM: Update 24019: task edges-pos-ontonotes, batch 19 (24019): mcc: 0.8508, acc: 0.7639, precision: 0.8920, recall: 0.8172, f1: 0.8530, edges-pos-ontonotes_loss: 0.0176
09/16 11:30:41 AM: Update 24056: task edges-pos-ontonotes, batch 56 (24056): mcc: 0.8558, acc: 0.7709, precision: 0.8956, recall: 0.8232, f1: 0.8579, edges-pos-ontonotes_loss: 0.0170
09/16 11:30:52 AM: Update 24097: task edges-pos-ontonotes, batch 97 (24097): mcc: 0.8569, acc: 0.7722, precision: 0.8977, recall: 0.8233, f1: 0.8589, edges-pos-ontonotes_loss: 0.0168
09/16 11:31:02 AM: Update 24142: task edges-pos-ontonotes, batch 142 (24142): mcc: 0.8566, acc: 0.7717, precision: 0.8982, recall: 0.8224, f1: 0.8586, edges-pos-ontonotes_loss: 0.0168
09/16 11:31:12 AM: Update 24187: task edges-pos-ontonotes, batch 187 (24187): mcc: 0.8561, acc: 0.7710, precision: 0.8977, recall: 0.8218, f1: 0.8581, edges-pos-ontonotes_loss: 0.0169
09/16 11:31:22 AM: Update 24222: task edges-pos-ontonotes, batch 222 (24222): mcc: 0.8555, acc: 0.7702, precision: 0.8972, recall: 0.8211, f1: 0.8575, edges-pos-ontonotes_loss: 0.0169
09/16 11:31:33 AM: Update 24292: task edges-pos-ontonotes, batch 292 (24292): mcc: 0.8556, acc: 0.7702, precision: 0.8985, recall: 0.8201, f1: 0.8575, edges-pos-ontonotes_loss: 0.0167
09/16 11:31:43 AM: Update 24357: task edges-pos-ontonotes, batch 357 (24357): mcc: 0.8565, acc: 0.7713, precision: 0.8999, recall: 0.8206, f1: 0.8584, edges-pos-ontonotes_loss: 0.0164
09/16 11:31:53 AM: Update 24410: task edges-pos-ontonotes, batch 410 (24410): mcc: 0.8561, acc: 0.7706, precision: 0.9001, recall: 0.8197, f1: 0.8580, edges-pos-ontonotes_loss: 0.0163
09/16 11:32:03 AM: Update 24476: task edges-pos-ontonotes, batch 476 (24476): mcc: 0.8565, acc: 0.7711, precision: 0.9007, recall: 0.8199, f1: 0.8584, edges-pos-ontonotes_loss: 0.0161
09/16 11:32:15 AM: Update 24534: task edges-pos-ontonotes, batch 534 (24534): mcc: 0.8570, acc: 0.7716, precision: 0.9013, recall: 0.8203, f1: 0.8589, edges-pos-ontonotes_loss: 0.0160
09/16 11:32:25 AM: Update 24579: task edges-pos-ontonotes, batch 579 (24579): mcc: 0.8574, acc: 0.7722, precision: 0.9014, recall: 0.8208, f1: 0.8592, edges-pos-ontonotes_loss: 0.0160
09/16 11:32:35 AM: Update 24625: task edges-pos-ontonotes, batch 625 (24625): mcc: 0.8583, acc: 0.7735, precision: 0.9021, recall: 0.8219, f1: 0.8602, edges-pos-ontonotes_loss: 0.0160
09/16 11:32:45 AM: Update 24689: task edges-pos-ontonotes, batch 689 (24689): mcc: 0.8589, acc: 0.7741, precision: 0.9027, recall: 0.8225, f1: 0.8607, edges-pos-ontonotes_loss: 0.0159
09/16 11:32:55 AM: Update 24737: task edges-pos-ontonotes, batch 737 (24737): mcc: 0.8594, acc: 0.7748, precision: 0.9029, recall: 0.8232, f1: 0.8612, edges-pos-ontonotes_loss: 0.0158
09/16 11:33:05 AM: Update 24789: task edges-pos-ontonotes, batch 789 (24789): mcc: 0.8597, acc: 0.7754, precision: 0.9033, recall: 0.8236, f1: 0.8616, edges-pos-ontonotes_loss: 0.0158
09/16 11:33:16 AM: Update 24840: task edges-pos-ontonotes, batch 840 (24840): mcc: 0.8602, acc: 0.7761, precision: 0.9035, recall: 0.8243, f1: 0.8621, edges-pos-ontonotes_loss: 0.0157
09/16 11:33:26 AM: Update 24870: task edges-pos-ontonotes, batch 870 (24870): mcc: 0.8600, acc: 0.7758, precision: 0.9034, recall: 0.8239, f1: 0.8618, edges-pos-ontonotes_loss: 0.0158
09/16 11:33:36 AM: Update 24912: task edges-pos-ontonotes, batch 912 (24912): mcc: 0.8600, acc: 0.7759, precision: 0.9034, recall: 0.8240, f1: 0.8619, edges-pos-ontonotes_loss: 0.0158
09/16 11:33:46 AM: Update 24945: task edges-pos-ontonotes, batch 945 (24945): mcc: 0.8601, acc: 0.7761, precision: 0.9033, recall: 0.8243, f1: 0.8620, edges-pos-ontonotes_loss: 0.0158
09/16 11:33:57 AM: Update 24988: task edges-pos-ontonotes, batch 988 (24988): mcc: 0.8600, acc: 0.7761, precision: 0.9032, recall: 0.8243, f1: 0.8619, edges-pos-ontonotes_loss: 0.0158
09/16 11:33:59 AM: ***** Step 25000 / Validation 25 *****
09/16 11:33:59 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 11:33:59 AM: Validating...
09/16 11:34:07 AM: Evaluate: task edges-pos-ontonotes, batch 39 (157): mcc: 0.8937, acc: 0.8300, precision: 0.9403, recall: 0.8534, f1: 0.8947, edges-pos-ontonotes_loss: 0.0119
09/16 11:34:17 AM: Evaluate: task edges-pos-ontonotes, batch 88 (157): mcc: 0.9024, acc: 0.8435, precision: 0.9439, recall: 0.8663, f1: 0.9035, edges-pos-ontonotes_loss: 0.0112
09/16 11:34:27 AM: Evaluate: task edges-pos-ontonotes, batch 123 (157): mcc: 0.9025, acc: 0.8443, precision: 0.9427, recall: 0.8676, f1: 0.9036, edges-pos-ontonotes_loss: 0.0112
09/16 11:34:37 AM: Evaluate: task edges-pos-ontonotes, batch 156 (157): mcc: 0.9026, acc: 0.8453, precision: 0.9414, recall: 0.8691, f1: 0.9038, edges-pos-ontonotes_loss: 0.0112
09/16 11:34:37 AM: Updating LR scheduler:
09/16 11:34:37 AM: 	Best result seen so far for macro_avg: 0.905
09/16 11:34:37 AM: 	# validation passes without improvement: 3
09/16 11:34:37 AM: edges-pos-ontonotes_loss: training: 0.015816 validation: 0.011155
09/16 11:34:37 AM: macro_avg: validation: 0.903817
09/16 11:34:37 AM: micro_avg: validation: 0.000000
09/16 11:34:37 AM: edges-pos-ontonotes_mcc: training: 0.860104 validation: 0.902606
09/16 11:34:37 AM: edges-pos-ontonotes_acc: training: 0.776136 validation: 0.845286
09/16 11:34:37 AM: edges-pos-ontonotes_precision: training: 0.903215 validation: 0.941465
09/16 11:34:37 AM: edges-pos-ontonotes_recall: training: 0.824328 validation: 0.869065
09/16 11:34:37 AM: edges-pos-ontonotes_f1: training: 0.861970 validation: 0.903817
09/16 11:34:37 AM: Global learning rate: 0.0001
09/16 11:34:37 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 11:34:47 AM: Update 25038: task edges-pos-ontonotes, batch 38 (25038): mcc: 0.8599, acc: 0.7762, precision: 0.9012, recall: 0.8259, f1: 0.8619, edges-pos-ontonotes_loss: 0.0165
09/16 11:34:57 AM: Update 25073: task edges-pos-ontonotes, batch 73 (25073): mcc: 0.8614, acc: 0.7793, precision: 0.9026, recall: 0.8274, f1: 0.8634, edges-pos-ontonotes_loss: 0.0162
09/16 11:35:07 AM: Update 25115: task edges-pos-ontonotes, batch 115 (25115): mcc: 0.8617, acc: 0.7796, precision: 0.9030, recall: 0.8275, f1: 0.8636, edges-pos-ontonotes_loss: 0.0162
09/16 11:35:17 AM: Update 25157: task edges-pos-ontonotes, batch 157 (25157): mcc: 0.8620, acc: 0.7804, precision: 0.9031, recall: 0.8280, f1: 0.8639, edges-pos-ontonotes_loss: 0.0163
09/16 11:35:30 AM: Update 25160: task edges-pos-ontonotes, batch 160 (25160): mcc: 0.8617, acc: 0.7800, precision: 0.9026, recall: 0.8278, f1: 0.8636, edges-pos-ontonotes_loss: 0.0163
09/16 11:35:41 AM: Update 25197: task edges-pos-ontonotes, batch 197 (25197): mcc: 0.8615, acc: 0.7793, precision: 0.9029, recall: 0.8272, f1: 0.8634, edges-pos-ontonotes_loss: 0.0162
09/16 11:35:51 AM: Update 25228: task edges-pos-ontonotes, batch 228 (25228): mcc: 0.8611, acc: 0.7787, precision: 0.9030, recall: 0.8264, f1: 0.8630, edges-pos-ontonotes_loss: 0.0162
09/16 11:36:01 AM: Update 25263: task edges-pos-ontonotes, batch 263 (25263): mcc: 0.8613, acc: 0.7789, precision: 0.9029, recall: 0.8268, f1: 0.8632, edges-pos-ontonotes_loss: 0.0161
09/16 11:36:12 AM: Update 25300: task edges-pos-ontonotes, batch 300 (25300): mcc: 0.8610, acc: 0.7785, precision: 0.9029, recall: 0.8264, f1: 0.8629, edges-pos-ontonotes_loss: 0.0161
09/16 11:36:22 AM: Update 25339: task edges-pos-ontonotes, batch 339 (25339): mcc: 0.8614, acc: 0.7790, precision: 0.9034, recall: 0.8266, f1: 0.8633, edges-pos-ontonotes_loss: 0.0161
09/16 11:36:32 AM: Update 25377: task edges-pos-ontonotes, batch 377 (25377): mcc: 0.8616, acc: 0.7793, precision: 0.9036, recall: 0.8267, f1: 0.8635, edges-pos-ontonotes_loss: 0.0160
09/16 11:36:42 AM: Update 25408: task edges-pos-ontonotes, batch 408 (25408): mcc: 0.8621, acc: 0.7801, precision: 0.9041, recall: 0.8272, f1: 0.8639, edges-pos-ontonotes_loss: 0.0160
09/16 11:36:52 AM: Update 25447: task edges-pos-ontonotes, batch 447 (25447): mcc: 0.8626, acc: 0.7809, precision: 0.9046, recall: 0.8279, f1: 0.8645, edges-pos-ontonotes_loss: 0.0159
09/16 11:37:03 AM: Update 25476: task edges-pos-ontonotes, batch 476 (25476): mcc: 0.8626, acc: 0.7810, precision: 0.9046, recall: 0.8278, f1: 0.8645, edges-pos-ontonotes_loss: 0.0159
09/16 11:37:13 AM: Update 25506: task edges-pos-ontonotes, batch 506 (25506): mcc: 0.8629, acc: 0.7813, precision: 0.9049, recall: 0.8280, f1: 0.8647, edges-pos-ontonotes_loss: 0.0158
09/16 11:37:23 AM: Update 25543: task edges-pos-ontonotes, batch 543 (25543): mcc: 0.8631, acc: 0.7817, precision: 0.9052, recall: 0.8282, f1: 0.8650, edges-pos-ontonotes_loss: 0.0159
09/16 11:37:33 AM: Update 25583: task edges-pos-ontonotes, batch 583 (25583): mcc: 0.8633, acc: 0.7821, precision: 0.9054, recall: 0.8284, f1: 0.8652, edges-pos-ontonotes_loss: 0.0158
09/16 11:37:43 AM: Update 25621: task edges-pos-ontonotes, batch 621 (25621): mcc: 0.8634, acc: 0.7822, precision: 0.9055, recall: 0.8284, f1: 0.8652, edges-pos-ontonotes_loss: 0.0159
09/16 11:37:53 AM: Update 25655: task edges-pos-ontonotes, batch 655 (25655): mcc: 0.8635, acc: 0.7825, precision: 0.9055, recall: 0.8287, f1: 0.8654, edges-pos-ontonotes_loss: 0.0158
09/16 11:38:03 AM: Update 25690: task edges-pos-ontonotes, batch 690 (25690): mcc: 0.8638, acc: 0.7830, precision: 0.9057, recall: 0.8290, f1: 0.8656, edges-pos-ontonotes_loss: 0.0158
09/16 11:38:14 AM: Update 25728: task edges-pos-ontonotes, batch 728 (25728): mcc: 0.8639, acc: 0.7832, precision: 0.9058, recall: 0.8291, f1: 0.8658, edges-pos-ontonotes_loss: 0.0158
09/16 11:38:24 AM: Update 25769: task edges-pos-ontonotes, batch 769 (25769): mcc: 0.8641, acc: 0.7836, precision: 0.9059, recall: 0.8294, f1: 0.8660, edges-pos-ontonotes_loss: 0.0157
09/16 11:38:34 AM: Update 25797: task edges-pos-ontonotes, batch 797 (25797): mcc: 0.8642, acc: 0.7838, precision: 0.9061, recall: 0.8294, f1: 0.8661, edges-pos-ontonotes_loss: 0.0157
09/16 11:38:44 AM: Update 25838: task edges-pos-ontonotes, batch 838 (25838): mcc: 0.8642, acc: 0.7838, precision: 0.9060, recall: 0.8294, f1: 0.8660, edges-pos-ontonotes_loss: 0.0158
09/16 11:38:54 AM: Update 25874: task edges-pos-ontonotes, batch 874 (25874): mcc: 0.8642, acc: 0.7838, precision: 0.9060, recall: 0.8294, f1: 0.8660, edges-pos-ontonotes_loss: 0.0157
09/16 11:39:04 AM: Update 25910: task edges-pos-ontonotes, batch 910 (25910): mcc: 0.8643, acc: 0.7842, precision: 0.9061, recall: 0.8296, f1: 0.8662, edges-pos-ontonotes_loss: 0.0158
09/16 11:39:14 AM: Update 25944: task edges-pos-ontonotes, batch 944 (25944): mcc: 0.8645, acc: 0.7845, precision: 0.9063, recall: 0.8298, f1: 0.8664, edges-pos-ontonotes_loss: 0.0157
09/16 11:39:25 AM: Update 25983: task edges-pos-ontonotes, batch 983 (25983): mcc: 0.8646, acc: 0.7847, precision: 0.9064, recall: 0.8299, f1: 0.8665, edges-pos-ontonotes_loss: 0.0157
09/16 11:39:30 AM: ***** Step 26000 / Validation 26 *****
09/16 11:39:30 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 11:39:30 AM: Validating...
09/16 11:39:35 AM: Evaluate: task edges-pos-ontonotes, batch 21 (157): mcc: 0.8856, acc: 0.8190, precision: 0.9325, recall: 0.8452, f1: 0.8867, edges-pos-ontonotes_loss: 0.0126
09/16 11:39:45 AM: Evaluate: task edges-pos-ontonotes, batch 72 (157): mcc: 0.8994, acc: 0.8393, precision: 0.9400, recall: 0.8643, f1: 0.9006, edges-pos-ontonotes_loss: 0.0119
09/16 11:39:55 AM: Evaluate: task edges-pos-ontonotes, batch 112 (157): mcc: 0.9012, acc: 0.8438, precision: 0.9396, recall: 0.8681, f1: 0.9024, edges-pos-ontonotes_loss: 0.0116
09/16 11:40:05 AM: Evaluate: task edges-pos-ontonotes, batch 145 (157): mcc: 0.9028, acc: 0.8470, precision: 0.9395, recall: 0.8713, f1: 0.9041, edges-pos-ontonotes_loss: 0.0114
09/16 11:40:08 AM: Best result seen so far for edges-pos-ontonotes.
09/16 11:40:08 AM: Best result seen so far for macro.
09/16 11:40:08 AM: Updating LR scheduler:
09/16 11:40:08 AM: 	Best result seen so far for macro_avg: 0.905
09/16 11:40:08 AM: 	# validation passes without improvement: 0
09/16 11:40:08 AM: edges-pos-ontonotes_loss: training: 0.015732 validation: 0.011262
09/16 11:40:08 AM: macro_avg: validation: 0.905454
09/16 11:40:08 AM: micro_avg: validation: 0.000000
09/16 11:40:08 AM: edges-pos-ontonotes_mcc: training: 0.864717 validation: 0.904152
09/16 11:40:08 AM: edges-pos-ontonotes_acc: training: 0.784823 validation: 0.849424
09/16 11:40:08 AM: edges-pos-ontonotes_precision: training: 0.906468 validation: 0.939958
09/16 11:40:08 AM: edges-pos-ontonotes_recall: training: 0.830009 validation: 0.873393
09/16 11:40:08 AM: edges-pos-ontonotes_f1: training: 0.866556 validation: 0.905454
09/16 11:40:08 AM: Global learning rate: 0.0001
09/16 11:40:08 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 11:40:15 AM: Update 26027: task edges-pos-ontonotes, batch 27 (26027): mcc: 0.8636, acc: 0.7856, precision: 0.9045, recall: 0.8297, f1: 0.8655, edges-pos-ontonotes_loss: 0.0157
09/16 11:40:25 AM: Update 26066: task edges-pos-ontonotes, batch 66 (26066): mcc: 0.8652, acc: 0.7871, precision: 0.9056, recall: 0.8317, f1: 0.8671, edges-pos-ontonotes_loss: 0.0157
09/16 11:40:36 AM: Update 26099: task edges-pos-ontonotes, batch 99 (26099): mcc: 0.8628, acc: 0.7842, precision: 0.9040, recall: 0.8286, f1: 0.8647, edges-pos-ontonotes_loss: 0.0160
09/16 11:40:46 AM: Update 26146: task edges-pos-ontonotes, batch 146 (26146): mcc: 0.8652, acc: 0.7870, precision: 0.9065, recall: 0.8309, f1: 0.8671, edges-pos-ontonotes_loss: 0.0153
09/16 11:40:56 AM: Update 26195: task edges-pos-ontonotes, batch 195 (26195): mcc: 0.8671, acc: 0.7895, precision: 0.9075, recall: 0.8336, f1: 0.8689, edges-pos-ontonotes_loss: 0.0149
09/16 11:41:06 AM: Update 26238: task edges-pos-ontonotes, batch 238 (26238): mcc: 0.8679, acc: 0.7908, precision: 0.9077, recall: 0.8350, f1: 0.8698, edges-pos-ontonotes_loss: 0.0146
09/16 11:41:16 AM: Update 26286: task edges-pos-ontonotes, batch 286 (26286): mcc: 0.8693, acc: 0.7924, precision: 0.9090, recall: 0.8362, f1: 0.8711, edges-pos-ontonotes_loss: 0.0143
09/16 11:41:26 AM: Update 26326: task edges-pos-ontonotes, batch 326 (26326): mcc: 0.8698, acc: 0.7931, precision: 0.9094, recall: 0.8368, f1: 0.8716, edges-pos-ontonotes_loss: 0.0142
09/16 11:41:37 AM: Update 26379: task edges-pos-ontonotes, batch 379 (26379): mcc: 0.8708, acc: 0.7943, precision: 0.9101, recall: 0.8380, f1: 0.8726, edges-pos-ontonotes_loss: 0.0141
09/16 11:41:47 AM: Update 26421: task edges-pos-ontonotes, batch 421 (26421): mcc: 0.8715, acc: 0.7952, precision: 0.9106, recall: 0.8390, f1: 0.8733, edges-pos-ontonotes_loss: 0.0140
09/16 11:41:57 AM: Update 26485: task edges-pos-ontonotes, batch 485 (26485): mcc: 0.8740, acc: 0.7985, precision: 0.9126, recall: 0.8418, f1: 0.8758, edges-pos-ontonotes_loss: 0.0137
09/16 11:42:07 AM: Update 26549: task edges-pos-ontonotes, batch 549 (26549): mcc: 0.8762, acc: 0.8015, precision: 0.9144, recall: 0.8444, f1: 0.8780, edges-pos-ontonotes_loss: 0.0135
09/16 11:42:17 AM: Update 26615: task edges-pos-ontonotes, batch 615 (26615): mcc: 0.8783, acc: 0.8042, precision: 0.9160, recall: 0.8469, f1: 0.8801, edges-pos-ontonotes_loss: 0.0133
09/16 11:42:27 AM: Update 26678: task edges-pos-ontonotes, batch 678 (26678): mcc: 0.8801, acc: 0.8066, precision: 0.9173, recall: 0.8489, f1: 0.8818, edges-pos-ontonotes_loss: 0.0131
09/16 11:42:37 AM: Update 26731: task edges-pos-ontonotes, batch 731 (26731): mcc: 0.8812, acc: 0.8082, precision: 0.9181, recall: 0.8504, f1: 0.8830, edges-pos-ontonotes_loss: 0.0129
09/16 11:42:47 AM: Update 26801: task edges-pos-ontonotes, batch 801 (26801): mcc: 0.8820, acc: 0.8093, precision: 0.9189, recall: 0.8512, f1: 0.8837, edges-pos-ontonotes_loss: 0.0129
09/16 11:42:57 AM: Update 26875: task edges-pos-ontonotes, batch 875 (26875): mcc: 0.8828, acc: 0.8104, precision: 0.9195, recall: 0.8521, f1: 0.8845, edges-pos-ontonotes_loss: 0.0129
09/16 11:43:07 AM: Update 26958: task edges-pos-ontonotes, batch 958 (26958): mcc: 0.8836, acc: 0.8116, precision: 0.9201, recall: 0.8530, f1: 0.8853, edges-pos-ontonotes_loss: 0.0128
09/16 11:43:12 AM: ***** Step 27000 / Validation 27 *****
09/16 11:43:12 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 11:43:12 AM: Validating...
09/16 11:43:18 AM: Evaluate: task edges-pos-ontonotes, batch 24 (157): mcc: 0.8840, acc: 0.8158, precision: 0.9341, recall: 0.8410, f1: 0.8851, edges-pos-ontonotes_loss: 0.0130
09/16 11:43:28 AM: Evaluate: task edges-pos-ontonotes, batch 73 (157): mcc: 0.8994, acc: 0.8393, precision: 0.9414, recall: 0.8630, f1: 0.9005, edges-pos-ontonotes_loss: 0.0119
09/16 11:43:38 AM: Evaluate: task edges-pos-ontonotes, batch 112 (157): mcc: 0.8983, acc: 0.8386, precision: 0.9409, recall: 0.8615, f1: 0.8994, edges-pos-ontonotes_loss: 0.0118
09/16 11:43:48 AM: Evaluate: task edges-pos-ontonotes, batch 144 (157): mcc: 0.8978, acc: 0.8383, precision: 0.9394, recall: 0.8620, f1: 0.8990, edges-pos-ontonotes_loss: 0.0117
09/16 11:43:51 AM: Updating LR scheduler:
09/16 11:43:51 AM: 	Best result seen so far for macro_avg: 0.905
09/16 11:43:51 AM: 	# validation passes without improvement: 1
09/16 11:43:51 AM: edges-pos-ontonotes_loss: training: 0.012788 validation: 0.011666
09/16 11:43:51 AM: macro_avg: validation: 0.900084
09/16 11:43:51 AM: micro_avg: validation: 0.000000
09/16 11:43:51 AM: edges-pos-ontonotes_mcc: training: 0.884049 validation: 0.898879
09/16 11:43:51 AM: edges-pos-ontonotes_acc: training: 0.812255 validation: 0.840408
09/16 11:43:51 AM: edges-pos-ontonotes_precision: training: 0.920526 validation: 0.939620
09/16 11:43:51 AM: edges-pos-ontonotes_recall: training: 0.853466 validation: 0.863742
09/16 11:43:51 AM: edges-pos-ontonotes_f1: training: 0.885729 validation: 0.900084
09/16 11:43:51 AM: Global learning rate: 0.0001
09/16 11:43:51 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 11:43:59 AM: Update 27038: task edges-pos-ontonotes, batch 38 (27038): mcc: 0.9003, acc: 0.8372, precision: 0.9310, recall: 0.8746, f1: 0.9019, edges-pos-ontonotes_loss: 0.0113
09/16 11:44:09 AM: Update 27117: task edges-pos-ontonotes, batch 117 (27117): mcc: 0.8738, acc: 0.7977, precision: 0.9134, recall: 0.8408, f1: 0.8756, edges-pos-ontonotes_loss: 0.0150
09/16 11:44:19 AM: Update 27204: task edges-pos-ontonotes, batch 204 (27204): mcc: 0.8666, acc: 0.7874, precision: 0.9078, recall: 0.8323, f1: 0.8684, edges-pos-ontonotes_loss: 0.0156
09/16 11:44:29 AM: Update 27309: task edges-pos-ontonotes, batch 309 (27309): mcc: 0.8653, acc: 0.7854, precision: 0.9071, recall: 0.8305, f1: 0.8671, edges-pos-ontonotes_loss: 0.0158
09/16 11:44:45 AM: Update 27351: task edges-pos-ontonotes, batch 351 (27351): mcc: 0.8651, acc: 0.7851, precision: 0.9070, recall: 0.8303, f1: 0.8670, edges-pos-ontonotes_loss: 0.0156
09/16 11:44:55 AM: Update 27392: task edges-pos-ontonotes, batch 392 (27392): mcc: 0.8625, acc: 0.7814, precision: 0.9033, recall: 0.8287, f1: 0.8644, edges-pos-ontonotes_loss: 0.0158
09/16 11:45:06 AM: Update 27437: task edges-pos-ontonotes, batch 437 (27437): mcc: 0.8615, acc: 0.7795, precision: 0.9022, recall: 0.8278, f1: 0.8634, edges-pos-ontonotes_loss: 0.0159
09/16 11:45:16 AM: Update 27480: task edges-pos-ontonotes, batch 480 (27480): mcc: 0.8604, acc: 0.7778, precision: 0.9012, recall: 0.8267, f1: 0.8623, edges-pos-ontonotes_loss: 0.0160
09/16 11:45:26 AM: Update 27523: task edges-pos-ontonotes, batch 523 (27523): mcc: 0.8597, acc: 0.7766, precision: 0.9006, recall: 0.8260, f1: 0.8617, edges-pos-ontonotes_loss: 0.0161
09/16 11:45:36 AM: Update 27560: task edges-pos-ontonotes, batch 560 (27560): mcc: 0.8596, acc: 0.7764, precision: 0.9005, recall: 0.8259, f1: 0.8616, edges-pos-ontonotes_loss: 0.0161
09/16 11:45:46 AM: Update 27599: task edges-pos-ontonotes, batch 599 (27599): mcc: 0.8595, acc: 0.7762, precision: 0.9003, recall: 0.8259, f1: 0.8615, edges-pos-ontonotes_loss: 0.0161
09/16 11:45:56 AM: Update 27641: task edges-pos-ontonotes, batch 641 (27641): mcc: 0.8594, acc: 0.7761, precision: 0.9003, recall: 0.8256, f1: 0.8614, edges-pos-ontonotes_loss: 0.0162
09/16 11:46:08 AM: Update 27681: task edges-pos-ontonotes, batch 681 (27681): mcc: 0.8591, acc: 0.7757, precision: 0.8999, recall: 0.8255, f1: 0.8611, edges-pos-ontonotes_loss: 0.0162
09/16 11:46:18 AM: Update 27739: task edges-pos-ontonotes, batch 739 (27739): mcc: 0.8586, acc: 0.7748, precision: 0.9002, recall: 0.8243, f1: 0.8606, edges-pos-ontonotes_loss: 0.0162
09/16 11:46:28 AM: Update 27802: task edges-pos-ontonotes, batch 802 (27802): mcc: 0.8587, acc: 0.7748, precision: 0.9007, recall: 0.8240, f1: 0.8606, edges-pos-ontonotes_loss: 0.0161
09/16 11:46:38 AM: Update 27873: task edges-pos-ontonotes, batch 873 (27873): mcc: 0.8591, acc: 0.7753, precision: 0.9012, recall: 0.8242, f1: 0.8610, edges-pos-ontonotes_loss: 0.0160
09/16 11:46:49 AM: Update 27935: task edges-pos-ontonotes, batch 935 (27935): mcc: 0.8591, acc: 0.7753, precision: 0.9015, recall: 0.8241, f1: 0.8610, edges-pos-ontonotes_loss: 0.0160
09/16 11:47:01 AM: Update 27994: task edges-pos-ontonotes, batch 994 (27994): mcc: 0.8594, acc: 0.7756, precision: 0.9018, recall: 0.8243, f1: 0.8613, edges-pos-ontonotes_loss: 0.0159
09/16 11:47:03 AM: ***** Step 28000 / Validation 28 *****
09/16 11:47:03 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 11:47:03 AM: Validating...
09/16 11:47:11 AM: Evaluate: task edges-pos-ontonotes, batch 34 (157): mcc: 0.8931, acc: 0.8276, precision: 0.9424, recall: 0.8504, f1: 0.8940, edges-pos-ontonotes_loss: 0.0118
09/16 11:47:21 AM: Evaluate: task edges-pos-ontonotes, batch 80 (157): mcc: 0.9023, acc: 0.8432, precision: 0.9444, recall: 0.8658, f1: 0.9034, edges-pos-ontonotes_loss: 0.0113
09/16 11:47:31 AM: Evaluate: task edges-pos-ontonotes, batch 116 (157): mcc: 0.9007, acc: 0.8415, precision: 0.9422, recall: 0.8649, f1: 0.9019, edges-pos-ontonotes_loss: 0.0114
09/16 11:47:41 AM: Evaluate: task edges-pos-ontonotes, batch 148 (157): mcc: 0.9008, acc: 0.8421, precision: 0.9405, recall: 0.8667, f1: 0.9021, edges-pos-ontonotes_loss: 0.0113
09/16 11:47:44 AM: Updating LR scheduler:
09/16 11:47:44 AM: 	Best result seen so far for macro_avg: 0.905
09/16 11:47:44 AM: 	# validation passes without improvement: 2
09/16 11:47:44 AM: edges-pos-ontonotes_loss: training: 0.015879 validation: 0.011293
09/16 11:47:44 AM: macro_avg: validation: 0.902390
09/16 11:47:44 AM: micro_avg: validation: 0.000000
09/16 11:47:44 AM: edges-pos-ontonotes_mcc: training: 0.859556 validation: 0.901173
09/16 11:47:44 AM: edges-pos-ontonotes_acc: training: 0.775882 validation: 0.842884
09/16 11:47:44 AM: edges-pos-ontonotes_precision: training: 0.901857 validation: 0.940578
09/16 11:47:44 AM: edges-pos-ontonotes_recall: training: 0.824548 validation: 0.867181
09/16 11:47:44 AM: edges-pos-ontonotes_f1: training: 0.861471 validation: 0.902390
09/16 11:47:44 AM: Global learning rate: 0.0001
09/16 11:47:44 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 11:47:51 AM: Update 28034: task edges-pos-ontonotes, batch 34 (28034): mcc: 0.8641, acc: 0.7794, precision: 0.9069, recall: 0.8283, f1: 0.8659, edges-pos-ontonotes_loss: 0.0149
09/16 11:48:02 AM: Update 28079: task edges-pos-ontonotes, batch 79 (28079): mcc: 0.8639, acc: 0.7801, precision: 0.9067, recall: 0.8282, f1: 0.8657, edges-pos-ontonotes_loss: 0.0151
09/16 11:48:12 AM: Update 28132: task edges-pos-ontonotes, batch 132 (28132): mcc: 0.8643, acc: 0.7811, precision: 0.9072, recall: 0.8286, f1: 0.8661, edges-pos-ontonotes_loss: 0.0152
09/16 11:48:22 AM: Update 28183: task edges-pos-ontonotes, batch 183 (28183): mcc: 0.8645, acc: 0.7814, precision: 0.9072, recall: 0.8290, f1: 0.8663, edges-pos-ontonotes_loss: 0.0152
09/16 11:48:32 AM: Update 28232: task edges-pos-ontonotes, batch 232 (28232): mcc: 0.8643, acc: 0.7812, precision: 0.9071, recall: 0.8286, f1: 0.8661, edges-pos-ontonotes_loss: 0.0152
09/16 11:48:42 AM: Update 28276: task edges-pos-ontonotes, batch 276 (28276): mcc: 0.8646, acc: 0.7818, precision: 0.9071, recall: 0.8292, f1: 0.8664, edges-pos-ontonotes_loss: 0.0151
09/16 11:48:52 AM: Update 28308: task edges-pos-ontonotes, batch 308 (28308): mcc: 0.8642, acc: 0.7812, precision: 0.9066, recall: 0.8289, f1: 0.8660, edges-pos-ontonotes_loss: 0.0151
09/16 11:49:02 AM: Update 28347: task edges-pos-ontonotes, batch 347 (28347): mcc: 0.8636, acc: 0.7807, precision: 0.9059, recall: 0.8285, f1: 0.8655, edges-pos-ontonotes_loss: 0.0152
09/16 11:49:12 AM: Update 28388: task edges-pos-ontonotes, batch 388 (28388): mcc: 0.8632, acc: 0.7802, precision: 0.9053, recall: 0.8282, f1: 0.8650, edges-pos-ontonotes_loss: 0.0153
09/16 11:49:22 AM: Update 28425: task edges-pos-ontonotes, batch 425 (28425): mcc: 0.8626, acc: 0.7796, precision: 0.9046, recall: 0.8277, f1: 0.8644, edges-pos-ontonotes_loss: 0.0155
09/16 11:49:32 AM: Update 28461: task edges-pos-ontonotes, batch 461 (28461): mcc: 0.8626, acc: 0.7799, precision: 0.9045, recall: 0.8279, f1: 0.8645, edges-pos-ontonotes_loss: 0.0155
09/16 11:49:42 AM: Update 28507: task edges-pos-ontonotes, batch 507 (28507): mcc: 0.8626, acc: 0.7800, precision: 0.9044, recall: 0.8280, f1: 0.8645, edges-pos-ontonotes_loss: 0.0157
09/16 11:49:53 AM: Update 28543: task edges-pos-ontonotes, batch 543 (28543): mcc: 0.8627, acc: 0.7802, precision: 0.9043, recall: 0.8282, f1: 0.8646, edges-pos-ontonotes_loss: 0.0156
09/16 11:50:03 AM: Update 28585: task edges-pos-ontonotes, batch 585 (28585): mcc: 0.8627, acc: 0.7802, precision: 0.9042, recall: 0.8283, f1: 0.8646, edges-pos-ontonotes_loss: 0.0157
09/16 11:50:14 AM: Update 28620: task edges-pos-ontonotes, batch 620 (28620): mcc: 0.8626, acc: 0.7802, precision: 0.9039, recall: 0.8283, f1: 0.8645, edges-pos-ontonotes_loss: 0.0157
09/16 11:50:24 AM: Update 28651: task edges-pos-ontonotes, batch 651 (28651): mcc: 0.8623, acc: 0.7797, precision: 0.9037, recall: 0.8280, f1: 0.8642, edges-pos-ontonotes_loss: 0.0157
09/16 11:50:35 AM: Update 28690: task edges-pos-ontonotes, batch 690 (28690): mcc: 0.8625, acc: 0.7801, precision: 0.9039, recall: 0.8282, f1: 0.8644, edges-pos-ontonotes_loss: 0.0157
09/16 11:50:45 AM: Update 28731: task edges-pos-ontonotes, batch 731 (28731): mcc: 0.8626, acc: 0.7802, precision: 0.9041, recall: 0.8282, f1: 0.8645, edges-pos-ontonotes_loss: 0.0157
09/16 11:50:55 AM: Update 28768: task edges-pos-ontonotes, batch 768 (28768): mcc: 0.8626, acc: 0.7802, precision: 0.9042, recall: 0.8281, f1: 0.8644, edges-pos-ontonotes_loss: 0.0157
09/16 11:51:05 AM: Update 28805: task edges-pos-ontonotes, batch 805 (28805): mcc: 0.8626, acc: 0.7804, precision: 0.9042, recall: 0.8282, f1: 0.8645, edges-pos-ontonotes_loss: 0.0157
09/16 11:51:15 AM: Update 28843: task edges-pos-ontonotes, batch 843 (28843): mcc: 0.8628, acc: 0.7807, precision: 0.9043, recall: 0.8283, f1: 0.8647, edges-pos-ontonotes_loss: 0.0156
09/16 11:51:25 AM: Update 28884: task edges-pos-ontonotes, batch 884 (28884): mcc: 0.8630, acc: 0.7810, precision: 0.9045, recall: 0.8285, f1: 0.8649, edges-pos-ontonotes_loss: 0.0157
09/16 11:51:36 AM: Update 28918: task edges-pos-ontonotes, batch 918 (28918): mcc: 0.8631, acc: 0.7813, precision: 0.9045, recall: 0.8288, f1: 0.8650, edges-pos-ontonotes_loss: 0.0156
09/16 11:51:46 AM: Update 28936: task edges-pos-ontonotes, batch 936 (28936): mcc: 0.8632, acc: 0.7814, precision: 0.9045, recall: 0.8289, f1: 0.8651, edges-pos-ontonotes_loss: 0.0156
09/16 11:51:56 AM: Update 28975: task edges-pos-ontonotes, batch 975 (28975): mcc: 0.8633, acc: 0.7817, precision: 0.9047, recall: 0.8290, f1: 0.8652, edges-pos-ontonotes_loss: 0.0156
09/16 11:52:04 AM: ***** Step 29000 / Validation 29 *****
09/16 11:52:04 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 11:52:04 AM: Validating...
09/16 11:52:07 AM: Evaluate: task edges-pos-ontonotes, batch 13 (157): mcc: 0.8913, acc: 0.8312, precision: 0.9337, recall: 0.8550, f1: 0.8926, edges-pos-ontonotes_loss: 0.0120
09/16 11:52:17 AM: Evaluate: task edges-pos-ontonotes, batch 54 (157): mcc: 0.8990, acc: 0.8386, precision: 0.9410, recall: 0.8627, f1: 0.9002, edges-pos-ontonotes_loss: 0.0117
09/16 11:52:27 AM: Evaluate: task edges-pos-ontonotes, batch 96 (157): mcc: 0.9031, acc: 0.8457, precision: 0.9408, recall: 0.8706, f1: 0.9043, edges-pos-ontonotes_loss: 0.0114
09/16 11:52:37 AM: Evaluate: task edges-pos-ontonotes, batch 129 (157): mcc: 0.9046, acc: 0.8488, precision: 0.9402, recall: 0.8740, f1: 0.9059, edges-pos-ontonotes_loss: 0.0112
09/16 11:52:56 AM: Evaluate: task edges-pos-ontonotes, batch 154 (157): mcc: 0.9060, acc: 0.8519, precision: 0.9401, recall: 0.8768, f1: 0.9073, edges-pos-ontonotes_loss: 0.0111
09/16 11:52:57 AM: Best result seen so far for edges-pos-ontonotes.
09/16 11:52:57 AM: Best result seen so far for macro.
09/16 11:52:57 AM: Updating LR scheduler:
09/16 11:52:57 AM: 	Best result seen so far for macro_avg: 0.907
09/16 11:52:57 AM: 	# validation passes without improvement: 0
09/16 11:52:57 AM: edges-pos-ontonotes_loss: training: 0.015613 validation: 0.011050
09/16 11:52:57 AM: macro_avg: validation: 0.907332
09/16 11:52:57 AM: micro_avg: validation: 0.000000
09/16 11:52:57 AM: edges-pos-ontonotes_mcc: training: 0.863449 validation: 0.906003
09/16 11:52:57 AM: edges-pos-ontonotes_acc: training: 0.781922 validation: 0.852016
09/16 11:52:57 AM: edges-pos-ontonotes_precision: training: 0.904789 validation: 0.940091
09/16 11:52:57 AM: edges-pos-ontonotes_recall: training: 0.829171 validation: 0.876779
09/16 11:52:57 AM: edges-pos-ontonotes_f1: training: 0.865331 validation: 0.907332
09/16 11:52:57 AM: Global learning rate: 0.0001
09/16 11:52:57 AM: Saving checkpoints to: ./experiments/pos-ontonotes-memorization-top/run
09/16 11:53:06 AM: Update 29038: task edges-pos-ontonotes, batch 38 (29038): mcc: 0.8664, acc: 0.7877, precision: 0.9079, recall: 0.8318, f1: 0.8682, edges-pos-ontonotes_loss: 0.0164
09/16 11:53:16 AM: Update 29077: task edges-pos-ontonotes, batch 77 (29077): mcc: 0.8677, acc: 0.7902, precision: 0.9081, recall: 0.8341, f1: 0.8695, edges-pos-ontonotes_loss: 0.0159
09/16 11:53:27 AM: Update 29118: task edges-pos-ontonotes, batch 118 (29118): mcc: 0.8683, acc: 0.7906, precision: 0.9089, recall: 0.8346, f1: 0.8702, edges-pos-ontonotes_loss: 0.0159
09/16 11:53:37 AM: Update 29160: task edges-pos-ontonotes, batch 160 (29160): mcc: 0.8689, acc: 0.7911, precision: 0.9093, recall: 0.8352, f1: 0.8707, edges-pos-ontonotes_loss: 0.0156
09/16 11:53:47 AM: Update 29198: task edges-pos-ontonotes, batch 198 (29198): mcc: 0.8685, acc: 0.7906, precision: 0.9091, recall: 0.8347, f1: 0.8703, edges-pos-ontonotes_loss: 0.0155
09/16 11:53:57 AM: Update 29231: task edges-pos-ontonotes, batch 231 (29231): mcc: 0.8690, acc: 0.7914, precision: 0.9096, recall: 0.8352, f1: 0.8708, edges-pos-ontonotes_loss: 0.0154
09/16 11:54:07 AM: Update 29255: task edges-pos-ontonotes, batch 255 (29255): mcc: 0.8689, acc: 0.7913, precision: 0.9095, recall: 0.8351, f1: 0.8707, edges-pos-ontonotes_loss: 0.0154
09/16 11:54:17 AM: Update 29291: task edges-pos-ontonotes, batch 291 (29291): mcc: 0.8687, acc: 0.7912, precision: 0.9093, recall: 0.8349, f1: 0.8705, edges-pos-ontonotes_loss: 0.0154
09/16 11:54:28 AM: Update 29328: task edges-pos-ontonotes, batch 328 (29328): mcc: 0.8685, acc: 0.7910, precision: 0.9091, recall: 0.8347, f1: 0.8703, edges-pos-ontonotes_loss: 0.0154
