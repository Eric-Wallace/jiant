09/16 05:59:29 AM: Git branch: master
09/16 05:59:29 AM: Git SHA: 03401462a9f5f9b569ed41ceca48ecd81700406f
09/16 05:59:29 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/ner-ontonotes-None-top/",
  "exp_name": "experiments/ner-ontonotes-None-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/ner-ontonotes-None-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/None",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/ner-ontonotes-None-top__run",
  "run_dir": "./experiments/ner-ontonotes-None-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-ner-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 05:59:29 AM: Saved config to ./experiments/ner-ontonotes-None-top/run/params.conf
09/16 05:59:29 AM: Using random seed 1234
09/16 05:59:53 AM: Git branch: master
09/16 05:59:53 AM: Git SHA: 03401462a9f5f9b569ed41ceca48ecd81700406f
09/16 05:59:54 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/ner-ontonotes-None-top/",
  "exp_name": "experiments/ner-ontonotes-None-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/ner-ontonotes-None-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/None",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/ner-ontonotes-None-top__run",
  "run_dir": "./experiments/ner-ontonotes-None-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-ner-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 05:59:54 AM: Saved config to ./experiments/ner-ontonotes-None-top/run/params.conf
09/16 05:59:54 AM: Using random seed 1234
09/16 06:00:33 AM: Using GPU 0
09/16 06:00:33 AM: Loading tasks...
09/16 06:00:33 AM: Writing pre-preprocessed tasks to ./experiments/ner-ontonotes-None-top/
09/16 06:00:33 AM: 	Creating task edges-ner-ontonotes from scratch.
09/16 06:00:33 AM: Using GPU 0
09/16 06:00:33 AM: Loading tasks...
09/16 06:00:33 AM: Writing pre-preprocessed tasks to ./experiments/ner-ontonotes-None-top/
09/16 06:00:33 AM: 	Creating task edges-ner-ontonotes from scratch.
09/16 06:00:35 AM: Read=49706, Skip=66106, Total=115812 from ./probing_data/edges/ontonotes/ner/train.json.retokenized.bert-base-uncased
09/16 06:00:36 AM: Read=49706, Skip=66106, Total=115812 from ./probing_data/edges/ontonotes/ner/train.json.retokenized.bert-base-uncased
09/16 06:00:36 AM: Read=7610, Skip=8070, Total=15680 from ./probing_data/edges/ontonotes/ner/development.json.retokenized.bert-base-uncased
09/16 06:00:36 AM: Read=5099, Skip=7118, Total=12217 from ./probing_data/edges/ontonotes/ner/test.json.retokenized.bert-base-uncased
09/16 06:00:36 AM: Read=7610, Skip=8070, Total=15680 from ./probing_data/edges/ontonotes/ner/development.json.retokenized.bert-base-uncased
09/16 06:00:37 AM: Read=5099, Skip=7118, Total=12217 from ./probing_data/edges/ontonotes/ner/test.json.retokenized.bert-base-uncased
09/16 06:00:37 AM: 	Task 'edges-ner-ontonotes': |train|=49706 |val|=7610 |test|=5099
09/16 06:00:37 AM: 	Finished loading tasks: edges-ner-ontonotes.
09/16 06:00:37 AM: 	Building vocab from scratch.
09/16 06:00:37 AM: 	Counting units for task edges-ner-ontonotes.
09/16 06:00:37 AM: 	Task 'edges-ner-ontonotes': |train|=49706 |val|=7610 |test|=5099
09/16 06:00:37 AM: 	Finished loading tasks: edges-ner-ontonotes.
09/16 06:00:37 AM: 	Building vocab from scratch.
09/16 06:00:37 AM: 	Counting units for task edges-ner-ontonotes.
09/16 06:00:39 AM: 	Task 'edges-ner-ontonotes': adding vocab namespace 'edges-ner-ontonotes_labels'
09/16 06:00:40 AM: 	Task 'edges-ner-ontonotes': adding vocab namespace 'edges-ner-ontonotes_labels'
09/16 06:00:40 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpi31l1kus
09/16 06:00:41 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmphrjni9e6
09/16 06:00:42 AM: copying /tmp/tmpi31l1kus to cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:42 AM: creating metadata file for /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:42 AM: removing temp file /tmp/tmpi31l1kus
09/16 06:00:42 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:42 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 06:00:42 AM: 	Saved vocab to ./experiments/ner-ontonotes-None-top/vocab
09/16 06:00:42 AM: Loading token dictionary from ./experiments/ner-ontonotes-None-top/vocab.
09/16 06:00:42 AM: 	Loaded vocab from ./experiments/ner-ontonotes-None-top/vocab
09/16 06:00:42 AM: 	Vocab namespace edges-ner-ontonotes_labels: size 18
09/16 06:00:42 AM: 	Vocab namespace tokens: size 22840
09/16 06:00:42 AM: 	Vocab namespace bert_uncased: size 30524
09/16 06:00:42 AM: 	Vocab namespace chars: size 77
09/16 06:00:42 AM: 	Finished building vocab.
09/16 06:00:42 AM: 	Task edges-ner-ontonotes (train): Indexing from scratch.
09/16 06:00:43 AM: copying /tmp/tmphrjni9e6 to cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:43 AM: creating metadata file for /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:43 AM: removing temp file /tmp/tmphrjni9e6
09/16 06:00:43 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:43 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 06:00:43 AM: vocabulary serialization directory ./experiments/ner-ontonotes-None-top/vocab is not empty
09/16 06:00:43 AM: 	Saved vocab to ./experiments/ner-ontonotes-None-top/vocab
09/16 06:00:43 AM: Loading token dictionary from ./experiments/ner-ontonotes-None-top/vocab.
09/16 06:00:43 AM: 	Loaded vocab from ./experiments/ner-ontonotes-None-top/vocab
09/16 06:00:43 AM: 	Vocab namespace edges-ner-ontonotes_labels: size 18
09/16 06:00:43 AM: 	Vocab namespace tokens: size 22840
09/16 06:00:43 AM: 	Vocab namespace bert_uncased: size 30524
09/16 06:00:43 AM: 	Vocab namespace chars: size 77
09/16 06:00:43 AM: 	Finished building vocab.
09/16 06:00:43 AM: 	Task 'edges-ner-ontonotes', split 'train': Found preprocessed copy in ./experiments/ner-ontonotes-None-top/preproc/edges-ner-ontonotes__train_data
09/16 06:00:43 AM: 	Task edges-ner-ontonotes (val): Indexing from scratch.
09/16 06:00:46 AM: 	Task edges-ner-ontonotes (val): Saved 7610 instances to ./experiments/ner-ontonotes-None-top/preproc/edges-ner-ontonotes__val_data
09/16 06:00:46 AM: 	Task edges-ner-ontonotes (test): Indexing from scratch.
09/16 06:00:47 AM: 	Task edges-ner-ontonotes (test): Saved 5099 instances to ./experiments/ner-ontonotes-None-top/preproc/edges-ner-ontonotes__test_data
09/16 06:00:47 AM: 	Finished indexing tasks
09/16 06:00:47 AM: 	Creating trimmed target-only version of edges-ner-ontonotes train.
09/16 06:00:47 AM: 	  Training on 
09/16 06:00:47 AM: 	  Evaluating on edges-ner-ontonotes
09/16 06:00:47 AM: 	Finished loading tasks in 13.656s
09/16 06:00:47 AM: 	 Tasks: ['edges-ner-ontonotes']
09/16 06:00:47 AM: Building model...
09/16 06:00:47 AM: Using BERT model (bert-base-uncased).
09/16 06:00:47 AM: LOADING A PRETRAINED MODEL
09/16 06:00:48 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpq84wuhr3
09/16 06:00:49 AM: copying /tmp/tmpq84wuhr3 to cache at ./experiments/ner-ontonotes-None-top/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/16 06:00:49 AM: creating metadata file for ./experiments/ner-ontonotes-None-top/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/16 06:00:49 AM: removing temp file /tmp/tmpq84wuhr3
09/16 06:00:49 AM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./experiments/ner-ontonotes-None-top/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/16 06:00:49 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 06:00:50 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpmdacmos8
09/16 06:00:57 AM: 	Task edges-ner-ontonotes (train): Saved 49706 instances to ./experiments/ner-ontonotes-None-top/preproc/edges-ner-ontonotes__train_data
09/16 06:00:57 AM: 	Task 'edges-ner-ontonotes', split 'val': Found preprocessed copy in ./experiments/ner-ontonotes-None-top/preproc/edges-ner-ontonotes__val_data
09/16 06:00:57 AM: 	Task 'edges-ner-ontonotes', split 'test': Found preprocessed copy in ./experiments/ner-ontonotes-None-top/preproc/edges-ner-ontonotes__test_data
09/16 06:00:57 AM: 	Finished indexing tasks
09/16 06:00:57 AM: 	Creating trimmed target-only version of edges-ner-ontonotes train.
09/16 06:00:57 AM: 	  Training on 
09/16 06:00:57 AM: 	  Evaluating on edges-ner-ontonotes
09/16 06:00:57 AM: 	Finished loading tasks in 24.137s
09/16 06:00:57 AM: 	 Tasks: ['edges-ner-ontonotes']
09/16 06:00:57 AM: Building model...
09/16 06:00:57 AM: Using BERT model (bert-base-uncased).
09/16 06:00:57 AM: LOADING A PRETRAINED MODEL
09/16 06:00:58 AM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./experiments/ner-ontonotes-None-top/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/16 06:01:01 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 06:01:02 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpi0a6vz1i
09/16 06:07:44 AM: copying /tmp/tmpmdacmos8 to cache at ./experiments/ner-ontonotes-None-top/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/16 06:07:45 AM: creating metadata file for ./experiments/ner-ontonotes-None-top/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/16 06:07:45 AM: removing temp file /tmp/tmpmdacmos8
09/16 06:07:45 AM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./experiments/ner-ontonotes-None-top/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/16 06:07:50 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpejxfidal
09/16 06:07:56 AM: copying /tmp/tmpejxfidal to cache at ./experiments/ner-ontonotes-None-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:07:56 AM: creating metadata file for ./experiments/ner-ontonotes-None-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:07:56 AM: removing temp file /tmp/tmpejxfidal
09/16 06:07:56 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/ner-ontonotes-None-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:07:56 AM: Initializing parameters
09/16 06:07:56 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 06:07:56 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 06:07:56 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 06:07:56 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 06:07:56 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 06:07:56 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 06:07:56 AM: 	Task 'edges-ner-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-ner-ontonotes"
}
09/16 06:08:20 AM: Model specification:
09/16 06:08:20 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-ner-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=18, bias=True)
    )
  )
)
09/16 06:08:20 AM: Model parameters:
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:08:20 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:08:20 AM: 	edges-ner-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 06:08:20 AM: 	edges-ner-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 06:08:20 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 9216 with torch.Size([18, 512])
09/16 06:08:20 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 18 with torch.Size([18])
09/16 06:08:20 AM: Total number of parameters: 109688338 (1.09688e+08)
09/16 06:08:20 AM: Number of trainable parameters: 206098 (206098)
09/16 06:08:20 AM: Finished building model in 453.016s
09/16 06:08:20 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-ner-ontonotes 

09/16 06:08:24 AM: patience = 9
09/16 06:08:24 AM: val_interval = 1000
09/16 06:08:24 AM: max_vals = 250
09/16 06:08:24 AM: cuda_device = 0
09/16 06:08:24 AM: grad_norm = 5.0
09/16 06:08:24 AM: grad_clipping = None
09/16 06:08:24 AM: lr_decay = 0.99
09/16 06:08:24 AM: min_lr = 1e-06
09/16 06:08:24 AM: keep_all_checkpoints = 0
09/16 06:08:24 AM: val_data_limit = 5000
09/16 06:08:24 AM: max_epochs = -1
09/16 06:08:24 AM: dec_val_scale = 250
09/16 06:08:24 AM: training_data_fraction = 1
09/16 06:08:24 AM: type = adam
09/16 06:08:24 AM: parameter_groups = None
09/16 06:08:24 AM: Number of trainable parameters: 206098
09/16 06:08:24 AM: infer_type_and_cast = True
09/16 06:08:24 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:08:24 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:08:24 AM: lr = 0.0001
09/16 06:08:24 AM: amsgrad = True
09/16 06:08:24 AM: type = reduce_on_plateau
09/16 06:08:24 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:08:24 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:08:24 AM: mode = max
09/16 06:08:24 AM: factor = 0.5
09/16 06:08:24 AM: patience = 3
09/16 06:08:24 AM: threshold = 0.0001
09/16 06:08:24 AM: threshold_mode = abs
09/16 06:08:24 AM: verbose = True
09/16 06:08:24 AM: type = adam
09/16 06:08:24 AM: parameter_groups = None
09/16 06:08:24 AM: Number of trainable parameters: 206098
09/16 06:08:24 AM: infer_type_and_cast = True
09/16 06:08:24 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:08:24 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:08:24 AM: lr = 0.0001
09/16 06:08:24 AM: amsgrad = True
09/16 06:08:24 AM: type = reduce_on_plateau
09/16 06:08:24 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:08:24 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:08:24 AM: mode = max
09/16 06:08:24 AM: factor = 0.5
09/16 06:08:24 AM: patience = 3
09/16 06:08:24 AM: threshold = 0.0001
09/16 06:08:24 AM: threshold_mode = abs
09/16 06:08:24 AM: verbose = True
09/16 06:08:24 AM: Starting training without restoring from a checkpoint.
09/16 06:08:24 AM: Training examples per task, before any subsampling: {'edges-ner-ontonotes': 49706}
09/16 06:08:24 AM: Beginning training with stopping criteria based on metric: edges-ner-ontonotes_f1
09/16 06:08:34 AM: Update 53: task edges-ner-ontonotes, batch 53 (53): mcc: 0.0019, acc: 0.0084, precision: 0.0570, recall: 0.0804, f1: 0.0667, edges-ner-ontonotes_loss: 0.4270
09/16 06:08:44 AM: Update 205: task edges-ner-ontonotes, batch 205 (205): mcc: 0.1295, acc: 0.0914, precision: 0.2374, recall: 0.1108, f1: 0.1511, edges-ner-ontonotes_loss: 0.2212
09/16 06:08:54 AM: Update 314: task edges-ner-ontonotes, batch 314 (314): mcc: 0.3060, acc: 0.2137, precision: 0.4829, recall: 0.2278, f1: 0.3095, edges-ner-ontonotes_loss: 0.1802
09/16 06:09:04 AM: Update 448: task edges-ner-ontonotes, batch 448 (448): mcc: 0.4739, acc: 0.3520, precision: 0.6720, recall: 0.3638, f1: 0.4721, edges-ner-ontonotes_loss: 0.1507
09/16 06:09:14 AM: Update 582: task edges-ner-ontonotes, batch 582 (582): mcc: 0.5696, acc: 0.4448, precision: 0.7567, recall: 0.4558, f1: 0.5689, edges-ner-ontonotes_loss: 0.1309
09/16 06:09:24 AM: Update 690: task edges-ner-ontonotes, batch 690 (690): mcc: 0.6248, acc: 0.5028, precision: 0.7996, recall: 0.5136, f1: 0.6254, edges-ner-ontonotes_loss: 0.1190
09/16 06:09:27 AM: copying /tmp/tmpi0a6vz1i to cache at ./experiments/ner-ontonotes-None-top/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/16 06:09:28 AM: creating metadata file for ./experiments/ner-ontonotes-None-top/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/16 06:09:29 AM: removing temp file /tmp/tmpi0a6vz1i
09/16 06:09:29 AM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./experiments/ner-ontonotes-None-top/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/16 06:09:34 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/ner-ontonotes-None-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:09:34 AM: Initializing parameters
09/16 06:09:34 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 06:09:34 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 06:09:34 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 06:09:34 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 06:09:34 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 06:09:34 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 06:09:34 AM: 	Task 'edges-ner-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-ner-ontonotes"
}
09/16 06:09:34 AM: Update 816: task edges-ner-ontonotes, batch 816 (816): mcc: 0.6712, acc: 0.5551, precision: 0.8309, recall: 0.5658, f1: 0.6732, edges-ner-ontonotes_loss: 0.1079
09/16 06:09:46 AM: Update 940: task edges-ner-ontonotes, batch 940 (940): mcc: 0.7053, acc: 0.5955, precision: 0.8517, recall: 0.6064, f1: 0.7084, edges-ner-ontonotes_loss: 0.0991
09/16 06:09:55 AM: ***** Step 1000 / Validation 1 *****
09/16 06:09:56 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:09:56 AM: Validating...
09/16 06:09:59 AM: Evaluate: task edges-ner-ontonotes, batch 31 (157): mcc: 0.7989, acc: 0.7345, precision: 0.8832, recall: 0.7411, f1: 0.8059, edges-ner-ontonotes_loss: 0.0638
09/16 06:10:03 AM: Model specification:
09/16 06:10:03 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-ner-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=18, bias=True)
    )
  )
)
09/16 06:10:03 AM: Model parameters:
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:10:03 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:10:03 AM: 	edges-ner-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 06:10:03 AM: 	edges-ner-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 06:10:03 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 9216 with torch.Size([18, 512])
09/16 06:10:03 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 18 with torch.Size([18])
09/16 06:10:03 AM: Total number of parameters: 109688338 (1.09688e+08)
09/16 06:10:03 AM: Number of trainable parameters: 206098 (206098)
09/16 06:10:03 AM: Finished building model in 545.508s
09/16 06:10:03 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-ner-ontonotes 

09/16 06:10:09 AM: patience = 9
09/16 06:10:09 AM: val_interval = 1000
09/16 06:10:09 AM: max_vals = 250
09/16 06:10:09 AM: cuda_device = 0
09/16 06:10:09 AM: grad_norm = 5.0
09/16 06:10:09 AM: grad_clipping = None
09/16 06:10:09 AM: lr_decay = 0.99
09/16 06:10:09 AM: min_lr = 1e-06
09/16 06:10:09 AM: keep_all_checkpoints = 0
09/16 06:10:09 AM: val_data_limit = 5000
09/16 06:10:09 AM: max_epochs = -1
09/16 06:10:09 AM: dec_val_scale = 250
09/16 06:10:09 AM: training_data_fraction = 1
09/16 06:10:09 AM: type = adam
09/16 06:10:09 AM: parameter_groups = None
09/16 06:10:09 AM: Number of trainable parameters: 206098
09/16 06:10:09 AM: infer_type_and_cast = True
09/16 06:10:09 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:10:09 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:10:09 AM: lr = 0.0001
09/16 06:10:09 AM: amsgrad = True
09/16 06:10:09 AM: type = reduce_on_plateau
09/16 06:10:09 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:10:09 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:10:09 AM: mode = max
09/16 06:10:09 AM: factor = 0.5
09/16 06:10:09 AM: patience = 3
09/16 06:10:09 AM: threshold = 0.0001
09/16 06:10:09 AM: threshold_mode = abs
09/16 06:10:09 AM: verbose = True
09/16 06:10:09 AM: type = adam
09/16 06:10:09 AM: parameter_groups = None
09/16 06:10:09 AM: Number of trainable parameters: 206098
09/16 06:10:09 AM: infer_type_and_cast = True
09/16 06:10:09 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:10:09 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:10:09 AM: lr = 0.0001
09/16 06:10:09 AM: amsgrad = True
09/16 06:10:09 AM: type = reduce_on_plateau
09/16 06:10:09 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:10:09 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:10:09 AM: mode = max
09/16 06:10:09 AM: factor = 0.5
09/16 06:10:09 AM: patience = 3
09/16 06:10:09 AM: threshold = 0.0001
09/16 06:10:09 AM: threshold_mode = abs
09/16 06:10:09 AM: verbose = True
09/16 06:10:09 AM: Starting training without restoring from a checkpoint.
09/16 06:10:09 AM: Training examples per task, before any subsampling: {'edges-ner-ontonotes': 49706}
09/16 06:10:09 AM: Beginning training with stopping criteria based on metric: edges-ner-ontonotes_f1
09/16 06:10:12 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.8476, acc: 0.7940, precision: 0.9119, recall: 0.8025, f1: 0.8537, edges-ner-ontonotes_loss: 0.0534
09/16 06:10:23 AM: Update 27: task edges-ner-ontonotes, batch 27 (27): mcc: 0.0022, acc: 0.0142, precision: 0.0568, recall: 0.1393, f1: 0.0807, edges-ner-ontonotes_loss: 0.5488
09/16 06:10:24 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.8713, acc: 0.8197, precision: 0.9282, recall: 0.8306, f1: 0.8767, edges-ner-ontonotes_loss: 0.0469
09/16 06:10:31 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:10:31 AM: Best result seen so far for micro.
09/16 06:10:31 AM: Best result seen so far for macro.
09/16 06:10:31 AM: Updating LR scheduler:
09/16 06:10:31 AM: 	Best result seen so far for macro_avg: 0.885
09/16 06:10:31 AM: 	# validation passes without improvement: 0
09/16 06:10:31 AM: edges-ner-ontonotes_loss: training: 0.095616 validation: 0.043732
09/16 06:10:31 AM: macro_avg: validation: 0.884549
09/16 06:10:31 AM: micro_avg: validation: 0.000000
09/16 06:10:31 AM: edges-ner-ontonotes_mcc: training: 0.718612 validation: 0.879534
09/16 06:10:31 AM: edges-ner-ontonotes_acc: training: 0.611615 validation: 0.829769
09/16 06:10:31 AM: edges-ner-ontonotes_precision: training: 0.859115 validation: 0.934363
09/16 06:10:31 AM: edges-ner-ontonotes_recall: training: 0.622772 validation: 0.839779
09/16 06:10:31 AM: edges-ner-ontonotes_f1: training: 0.722097 validation: 0.884549
09/16 06:10:31 AM: Global learning rate: 0.0001
09/16 06:10:31 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:10:34 AM: Update 102: task edges-ner-ontonotes, batch 102 (102): mcc: 0.0082, acc: 0.0106, precision: 0.0643, recall: 0.0502, f1: 0.0564, edges-ner-ontonotes_loss: 0.3070
09/16 06:10:34 AM: Update 1023: task edges-ner-ontonotes, batch 23 (1023): mcc: 0.8941, acc: 0.8411, precision: 0.9487, recall: 0.8531, f1: 0.8984, edges-ner-ontonotes_loss: 0.0385
09/16 06:10:44 AM: Update 188: task edges-ner-ontonotes, batch 188 (188): mcc: 0.0991, acc: 0.0715, precision: 0.1926, recall: 0.0927, f1: 0.1251, edges-ner-ontonotes_loss: 0.2305
09/16 06:10:44 AM: Update 1099: task edges-ner-ontonotes, batch 99 (1099): mcc: 0.8865, acc: 0.8357, precision: 0.9390, recall: 0.8482, f1: 0.8913, edges-ner-ontonotes_loss: 0.0395
09/16 06:10:54 AM: Update 273: task edges-ner-ontonotes, batch 273 (273): mcc: 0.2453, acc: 0.1700, precision: 0.4023, recall: 0.1853, f1: 0.2537, edges-ner-ontonotes_loss: 0.1930
09/16 06:10:54 AM: Update 1176: task edges-ner-ontonotes, batch 176 (1176): mcc: 0.8932, acc: 0.8434, precision: 0.9441, recall: 0.8556, f1: 0.8977, edges-ner-ontonotes_loss: 0.0379
09/16 06:11:04 AM: Update 315: task edges-ner-ontonotes, batch 315 (315): mcc: 0.3101, acc: 0.2167, precision: 0.4879, recall: 0.2308, f1: 0.3133, edges-ner-ontonotes_loss: 0.1800
09/16 06:11:05 AM: Update 1253: task edges-ner-ontonotes, batch 253 (1253): mcc: 0.8924, acc: 0.8423, precision: 0.9427, recall: 0.8555, f1: 0.8970, edges-ner-ontonotes_loss: 0.0374
09/16 06:11:14 AM: Update 394: task edges-ner-ontonotes, batch 394 (394): mcc: 0.4178, acc: 0.3025, precision: 0.6149, recall: 0.3148, f1: 0.4164, edges-ner-ontonotes_loss: 0.1611
09/16 06:11:15 AM: Update 1322: task edges-ner-ontonotes, batch 322 (1322): mcc: 0.8844, acc: 0.8309, precision: 0.9386, recall: 0.8447, f1: 0.8892, edges-ner-ontonotes_loss: 0.0405
09/16 06:11:24 AM: Update 471: task edges-ner-ontonotes, batch 471 (471): mcc: 0.4932, acc: 0.3697, precision: 0.6906, recall: 0.3813, f1: 0.4913, edges-ner-ontonotes_loss: 0.1466
09/16 06:11:26 AM: Update 1403: task edges-ner-ontonotes, batch 403 (1403): mcc: 0.8792, acc: 0.8233, precision: 0.9370, recall: 0.8368, f1: 0.8841, edges-ner-ontonotes_loss: 0.0425
09/16 06:11:36 AM: Update 546: task edges-ner-ontonotes, batch 546 (546): mcc: 0.5500, acc: 0.4248, precision: 0.7408, recall: 0.4359, f1: 0.5489, edges-ner-ontonotes_loss: 0.1354
09/16 06:11:36 AM: Update 1474: task edges-ner-ontonotes, batch 474 (1474): mcc: 0.8777, acc: 0.8214, precision: 0.9362, recall: 0.8348, f1: 0.8826, edges-ner-ontonotes_loss: 0.0428
09/16 06:11:48 AM: Update 621: task edges-ner-ontonotes, batch 621 (621): mcc: 0.5904, acc: 0.4666, precision: 0.7730, recall: 0.4775, f1: 0.5903, edges-ner-ontonotes_loss: 0.1262
09/16 06:11:48 AM: Update 1550: task edges-ner-ontonotes, batch 550 (1550): mcc: 0.8753, acc: 0.8180, precision: 0.9350, recall: 0.8316, f1: 0.8803, edges-ner-ontonotes_loss: 0.0435
09/16 06:11:59 AM: Update 1616: task edges-ner-ontonotes, batch 616 (1616): mcc: 0.8742, acc: 0.8168, precision: 0.9341, recall: 0.8304, f1: 0.8792, edges-ner-ontonotes_loss: 0.0436
09/16 06:11:59 AM: Update 684: task edges-ner-ontonotes, batch 684 (684): mcc: 0.6227, acc: 0.5005, precision: 0.7982, recall: 0.5112, f1: 0.6233, edges-ner-ontonotes_loss: 0.1196
09/16 06:12:09 AM: Update 765: task edges-ner-ontonotes, batch 765 (765): mcc: 0.6547, acc: 0.5361, precision: 0.8205, recall: 0.5467, f1: 0.6562, edges-ner-ontonotes_loss: 0.1121
09/16 06:12:09 AM: Update 1695: task edges-ner-ontonotes, batch 695 (1695): mcc: 0.8738, acc: 0.8160, precision: 0.9340, recall: 0.8297, f1: 0.8788, edges-ner-ontonotes_loss: 0.0434
09/16 06:12:19 AM: Update 1775: task edges-ner-ontonotes, batch 775 (1775): mcc: 0.8729, acc: 0.8152, precision: 0.9330, recall: 0.8290, f1: 0.8780, edges-ner-ontonotes_loss: 0.0435
09/16 06:12:19 AM: Update 843: task edges-ner-ontonotes, batch 843 (843): mcc: 0.6791, acc: 0.5644, precision: 0.8358, recall: 0.5751, f1: 0.6814, edges-ner-ontonotes_loss: 0.1058
09/16 06:12:29 AM: Update 1855: task edges-ner-ontonotes, batch 855 (1855): mcc: 0.8738, acc: 0.8160, precision: 0.9338, recall: 0.8300, f1: 0.8788, edges-ner-ontonotes_loss: 0.0429
09/16 06:12:29 AM: Update 920: task edges-ner-ontonotes, batch 920 (920): mcc: 0.7010, acc: 0.5902, precision: 0.8493, recall: 0.6011, f1: 0.7039, edges-ner-ontonotes_loss: 0.1003
09/16 06:12:39 AM: Update 1912: task edges-ner-ontonotes, batch 912 (1912): mcc: 0.8747, acc: 0.8173, precision: 0.9340, recall: 0.8313, f1: 0.8797, edges-ner-ontonotes_loss: 0.0425
09/16 06:12:39 AM: Update 974: task edges-ner-ontonotes, batch 974 (974): mcc: 0.7131, acc: 0.6049, precision: 0.8560, recall: 0.6160, f1: 0.7164, edges-ner-ontonotes_loss: 0.0971
09/16 06:12:43 AM: ***** Step 1000 / Validation 1 *****
09/16 06:12:44 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:12:44 AM: Validating...
09/16 06:12:49 AM: Update 1984: task edges-ner-ontonotes, batch 984 (1984): mcc: 0.8765, acc: 0.8198, precision: 0.9345, recall: 0.8342, f1: 0.8815, edges-ner-ontonotes_loss: 0.0418
09/16 06:12:49 AM: Evaluate: task edges-ner-ontonotes, batch 38 (157): mcc: 0.8122, acc: 0.7517, precision: 0.8895, recall: 0.7590, f1: 0.8191, edges-ner-ontonotes_loss: 0.0608
09/16 06:12:53 AM: ***** Step 2000 / Validation 2 *****
09/16 06:12:53 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:12:53 AM: Validating...
09/16 06:13:00 AM: Evaluate: task edges-ner-ontonotes, batch 57 (157): mcc: 0.8868, acc: 0.8425, precision: 0.9363, recall: 0.8512, f1: 0.8918, edges-ner-ontonotes_loss: 0.0355
09/16 06:13:02 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.8476, acc: 0.7940, precision: 0.9119, recall: 0.8025, f1: 0.8537, edges-ner-ontonotes_loss: 0.0534
09/16 06:13:11 AM: Evaluate: task edges-ner-ontonotes, batch 101 (157): mcc: 0.8945, acc: 0.8497, precision: 0.9421, recall: 0.8600, f1: 0.8992, edges-ner-ontonotes_loss: 0.0333
09/16 06:13:12 AM: Evaluate: task edges-ner-ontonotes, batch 109 (157): mcc: 0.8673, acc: 0.8139, precision: 0.9264, recall: 0.8248, f1: 0.8727, edges-ner-ontonotes_loss: 0.0477
09/16 06:13:23 AM: Evaluate: task edges-ner-ontonotes, batch 128 (157): mcc: 0.9061, acc: 0.8650, precision: 0.9499, recall: 0.8738, f1: 0.9103, edges-ner-ontonotes_loss: 0.0309
09/16 06:13:23 AM: Evaluate: task edges-ner-ontonotes, batch 152 (157): mcc: 0.8796, acc: 0.8300, precision: 0.9343, recall: 0.8399, f1: 0.8846, edges-ner-ontonotes_loss: 0.0440
09/16 06:13:24 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:13:24 AM: Best result seen so far for micro.
09/16 06:13:24 AM: Best result seen so far for macro.
09/16 06:13:24 AM: Updating LR scheduler:
09/16 06:13:24 AM: 	Best result seen so far for macro_avg: 0.885
09/16 06:13:24 AM: 	# validation passes without improvement: 0
09/16 06:13:24 AM: edges-ner-ontonotes_loss: training: 0.095616 validation: 0.043732
09/16 06:13:24 AM: macro_avg: validation: 0.884549
09/16 06:13:24 AM: micro_avg: validation: 0.000000
09/16 06:13:24 AM: edges-ner-ontonotes_mcc: training: 0.718612 validation: 0.879534
09/16 06:13:24 AM: edges-ner-ontonotes_acc: training: 0.611615 validation: 0.829769
09/16 06:13:24 AM: edges-ner-ontonotes_precision: training: 0.859115 validation: 0.934363
09/16 06:13:24 AM: edges-ner-ontonotes_recall: training: 0.622772 validation: 0.839779
09/16 06:13:24 AM: edges-ner-ontonotes_f1: training: 0.722097 validation: 0.884549
09/16 06:13:24 AM: Global learning rate: 0.0001
09/16 06:13:24 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:13:28 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:13:31 AM: Best result seen so far for macro.
09/16 06:13:31 AM: Updating LR scheduler:
09/16 06:13:31 AM: 	Best result seen so far for macro_avg: 0.913
09/16 06:13:31 AM: 	# validation passes without improvement: 0
09/16 06:13:31 AM: edges-ner-ontonotes_loss: training: 0.041668 validation: 0.029771
09/16 06:13:31 AM: macro_avg: validation: 0.913246
09/16 06:13:31 AM: micro_avg: validation: 0.000000
09/16 06:13:31 AM: edges-ner-ontonotes_mcc: training: 0.877021 validation: 0.909219
09/16 06:13:31 AM: edges-ner-ontonotes_acc: training: 0.820467 validation: 0.868365
09/16 06:13:31 AM: edges-ner-ontonotes_precision: training: 0.934767 validation: 0.952338
09/16 06:13:31 AM: edges-ner-ontonotes_recall: training: 0.834856 validation: 0.877237
09/16 06:13:31 AM: edges-ner-ontonotes_f1: training: 0.881991 validation: 0.913246
09/16 06:13:31 AM: Global learning rate: 0.0001
09/16 06:13:31 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:13:33 AM: Update 2016: task edges-ner-ontonotes, batch 16 (2016): mcc: 0.9010, acc: 0.8571, precision: 0.9424, recall: 0.8715, f1: 0.9055, edges-ner-ontonotes_loss: 0.0309
09/16 06:13:33 AM: Update 1067: task edges-ner-ontonotes, batch 67 (1067): mcc: 0.8914, acc: 0.8404, precision: 0.9435, recall: 0.8529, f1: 0.8959, edges-ner-ontonotes_loss: 0.0384
09/16 06:13:43 AM: Update 2090: task edges-ner-ontonotes, batch 90 (2090): mcc: 0.9059, acc: 0.8629, precision: 0.9463, recall: 0.8767, f1: 0.9102, edges-ner-ontonotes_loss: 0.0305
09/16 06:13:43 AM: Update 1142: task edges-ner-ontonotes, batch 142 (1142): mcc: 0.8906, acc: 0.8407, precision: 0.9415, recall: 0.8533, f1: 0.8953, edges-ner-ontonotes_loss: 0.0387
09/16 06:13:53 AM: Update 2163: task edges-ner-ontonotes, batch 163 (2163): mcc: 0.9051, acc: 0.8616, precision: 0.9462, recall: 0.8755, f1: 0.9095, edges-ner-ontonotes_loss: 0.0308
09/16 06:13:53 AM: Update 1213: task edges-ner-ontonotes, batch 213 (1213): mcc: 0.8944, acc: 0.8448, precision: 0.9443, recall: 0.8576, f1: 0.8989, edges-ner-ontonotes_loss: 0.0376
09/16 06:14:03 AM: Update 2226: task edges-ner-ontonotes, batch 226 (2226): mcc: 0.9071, acc: 0.8644, precision: 0.9472, recall: 0.8781, f1: 0.9113, edges-ner-ontonotes_loss: 0.0303
09/16 06:14:03 AM: Update 1269: task edges-ner-ontonotes, batch 269 (1269): mcc: 0.8893, acc: 0.8380, precision: 0.9412, recall: 0.8512, f1: 0.8939, edges-ner-ontonotes_loss: 0.0384
09/16 06:14:15 AM: Update 2296: task edges-ner-ontonotes, batch 296 (2296): mcc: 0.9107, acc: 0.8692, precision: 0.9487, recall: 0.8834, f1: 0.9149, edges-ner-ontonotes_loss: 0.0291
09/16 06:14:15 AM: Update 1338: task edges-ner-ontonotes, batch 338 (1338): mcc: 0.8827, acc: 0.8285, precision: 0.9379, recall: 0.8422, f1: 0.8875, edges-ner-ontonotes_loss: 0.0411
09/16 06:14:25 AM: Update 1413: task edges-ner-ontonotes, batch 413 (1413): mcc: 0.8789, acc: 0.8229, precision: 0.9369, recall: 0.8364, f1: 0.8838, edges-ner-ontonotes_loss: 0.0425
09/16 06:14:25 AM: Update 2371: task edges-ner-ontonotes, batch 371 (2371): mcc: 0.9127, acc: 0.8724, precision: 0.9496, recall: 0.8863, f1: 0.9168, edges-ner-ontonotes_loss: 0.0284
09/16 06:14:35 AM: Update 1486: task edges-ner-ontonotes, batch 486 (1486): mcc: 0.8774, acc: 0.8209, precision: 0.9359, recall: 0.8344, f1: 0.8823, edges-ner-ontonotes_loss: 0.0428
09/16 06:14:35 AM: Update 2442: task edges-ner-ontonotes, batch 442 (2442): mcc: 0.9150, acc: 0.8754, precision: 0.9501, recall: 0.8900, f1: 0.9190, edges-ner-ontonotes_loss: 0.0278
09/16 06:14:45 AM: Update 2496: task edges-ner-ontonotes, batch 496 (2496): mcc: 0.9165, acc: 0.8773, precision: 0.9509, recall: 0.8921, f1: 0.9205, edges-ner-ontonotes_loss: 0.0274
09/16 06:14:45 AM: Update 1557: task edges-ner-ontonotes, batch 557 (1557): mcc: 0.8755, acc: 0.8182, precision: 0.9352, recall: 0.8317, f1: 0.8804, edges-ner-ontonotes_loss: 0.0435
09/16 06:14:55 AM: Update 2575: task edges-ner-ontonotes, batch 575 (2575): mcc: 0.9166, acc: 0.8774, precision: 0.9507, recall: 0.8925, f1: 0.9206, edges-ner-ontonotes_loss: 0.0274
09/16 06:14:56 AM: Update 1638: task edges-ner-ontonotes, batch 638 (1638): mcc: 0.8738, acc: 0.8162, precision: 0.9338, recall: 0.8298, f1: 0.8787, edges-ner-ontonotes_loss: 0.0437
09/16 06:15:05 AM: Update 2654: task edges-ner-ontonotes, batch 654 (2654): mcc: 0.9170, acc: 0.8776, precision: 0.9504, recall: 0.8935, f1: 0.9210, edges-ner-ontonotes_loss: 0.0271
09/16 06:15:06 AM: Update 1721: task edges-ner-ontonotes, batch 721 (1721): mcc: 0.8734, acc: 0.8155, precision: 0.9336, recall: 0.8293, f1: 0.8784, edges-ner-ontonotes_loss: 0.0434
09/16 06:15:15 AM: Update 2729: task edges-ner-ontonotes, batch 729 (2729): mcc: 0.9179, acc: 0.8788, precision: 0.9506, recall: 0.8948, f1: 0.9218, edges-ner-ontonotes_loss: 0.0269
09/16 06:15:16 AM: Update 1800: task edges-ner-ontonotes, batch 800 (1800): mcc: 0.8731, acc: 0.8153, precision: 0.9332, recall: 0.8292, f1: 0.8781, edges-ner-ontonotes_loss: 0.0433
09/16 06:15:27 AM: Update 1870: task edges-ner-ontonotes, batch 870 (1870): mcc: 0.8739, acc: 0.8161, precision: 0.9337, recall: 0.8301, f1: 0.8789, edges-ner-ontonotes_loss: 0.0428
09/16 06:15:28 AM: Update 2809: task edges-ner-ontonotes, batch 809 (2809): mcc: 0.9194, acc: 0.8808, precision: 0.9514, recall: 0.8968, f1: 0.9233, edges-ner-ontonotes_loss: 0.0264
09/16 06:15:37 AM: Update 1947: task edges-ner-ontonotes, batch 947 (1947): mcc: 0.8756, acc: 0.8184, precision: 0.9343, recall: 0.8326, f1: 0.8805, edges-ner-ontonotes_loss: 0.0421
09/16 06:15:38 AM: Update 2876: task edges-ner-ontonotes, batch 876 (2876): mcc: 0.9169, acc: 0.8773, precision: 0.9499, recall: 0.8937, f1: 0.9209, edges-ner-ontonotes_loss: 0.0275
09/16 06:15:44 AM: ***** Step 2000 / Validation 2 *****
09/16 06:15:44 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:15:44 AM: Validating...
09/16 06:15:47 AM: Evaluate: task edges-ner-ontonotes, batch 17 (157): mcc: 0.8409, acc: 0.7793, precision: 0.9115, recall: 0.7908, f1: 0.8469, edges-ner-ontonotes_loss: 0.0434
09/16 06:15:48 AM: Update 2941: task edges-ner-ontonotes, batch 941 (2941): mcc: 0.9148, acc: 0.8745, precision: 0.9487, recall: 0.8910, f1: 0.9189, edges-ner-ontonotes_loss: 0.0282
09/16 06:15:57 AM: Evaluate: task edges-ner-ontonotes, batch 75 (157): mcc: 0.8894, acc: 0.8445, precision: 0.9393, recall: 0.8532, f1: 0.8942, edges-ner-ontonotes_loss: 0.0352
09/16 06:15:58 AM: ***** Step 3000 / Validation 3 *****
09/16 06:15:58 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:15:58 AM: Validating...
09/16 06:15:58 AM: Evaluate: task edges-ner-ontonotes, batch 1 (157): mcc: 0.7828, acc: 0.6721, precision: 0.9130, recall: 0.6885, f1: 0.7850, edges-ner-ontonotes_loss: 0.0490
09/16 06:16:08 AM: Evaluate: task edges-ner-ontonotes, batch 55 (157): mcc: 0.8922, acc: 0.8478, precision: 0.9340, recall: 0.8631, f1: 0.8972, edges-ner-ontonotes_loss: 0.0335
09/16 06:16:09 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9016, acc: 0.8595, precision: 0.9459, recall: 0.8693, f1: 0.9060, edges-ner-ontonotes_loss: 0.0318
09/16 06:16:18 AM: Evaluate: task edges-ner-ontonotes, batch 102 (157): mcc: 0.9054, acc: 0.8635, precision: 0.9452, recall: 0.8768, f1: 0.9097, edges-ner-ontonotes_loss: 0.0303
09/16 06:16:19 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:16:19 AM: Best result seen so far for macro.
09/16 06:16:19 AM: Updating LR scheduler:
09/16 06:16:19 AM: 	Best result seen so far for macro_avg: 0.913
09/16 06:16:19 AM: 	# validation passes without improvement: 0
09/16 06:16:19 AM: edges-ner-ontonotes_loss: training: 0.041668 validation: 0.029771
09/16 06:16:19 AM: macro_avg: validation: 0.913246
09/16 06:16:19 AM: micro_avg: validation: 0.000000
09/16 06:16:19 AM: edges-ner-ontonotes_mcc: training: 0.877021 validation: 0.909219
09/16 06:16:19 AM: edges-ner-ontonotes_acc: training: 0.820467 validation: 0.868365
09/16 06:16:19 AM: edges-ner-ontonotes_precision: training: 0.934767 validation: 0.952338
09/16 06:16:19 AM: edges-ner-ontonotes_recall: training: 0.834856 validation: 0.877237
09/16 06:16:19 AM: edges-ner-ontonotes_f1: training: 0.881991 validation: 0.913246
09/16 06:16:19 AM: Global learning rate: 0.0001
09/16 06:16:19 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:16:21 AM: Update 2001: task edges-ner-ontonotes, batch 1 (2001): mcc: 0.9450, acc: 0.9153, precision: 0.9818, recall: 0.9153, f1: 0.9474, edges-ner-ontonotes_loss: 0.0229
09/16 06:16:28 AM: Evaluate: task edges-ner-ontonotes, batch 156 (157): mcc: 0.9203, acc: 0.8833, precision: 0.9553, recall: 0.8949, f1: 0.9241, edges-ner-ontonotes_loss: 0.0262
09/16 06:16:28 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:16:28 AM: Best result seen so far for macro.
09/16 06:16:28 AM: Updating LR scheduler:
09/16 06:16:28 AM: 	Best result seen so far for macro_avg: 0.924
09/16 06:16:28 AM: 	# validation passes without improvement: 0
09/16 06:16:28 AM: edges-ner-ontonotes_loss: training: 0.028876 validation: 0.026224
09/16 06:16:28 AM: macro_avg: validation: 0.924125
09/16 06:16:28 AM: micro_avg: validation: 0.000000
09/16 06:16:28 AM: edges-ner-ontonotes_mcc: training: 0.913398 validation: 0.920364
09/16 06:16:28 AM: edges-ner-ontonotes_acc: training: 0.872691 validation: 0.883303
09/16 06:16:28 AM: edges-ner-ontonotes_precision: training: 0.947822 validation: 0.955318
09/16 06:16:28 AM: edges-ner-ontonotes_recall: training: 0.889178 validation: 0.894904
09/16 06:16:28 AM: edges-ner-ontonotes_f1: training: 0.917564 validation: 0.924125
09/16 06:16:28 AM: Global learning rate: 0.0001
09/16 06:16:28 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:16:31 AM: Update 2061: task edges-ner-ontonotes, batch 61 (2061): mcc: 0.9041, acc: 0.8605, precision: 0.9452, recall: 0.8747, f1: 0.9086, edges-ner-ontonotes_loss: 0.0307
09/16 06:16:38 AM: Update 3080: task edges-ner-ontonotes, batch 80 (3080): mcc: 0.8833, acc: 0.8352, precision: 0.9268, recall: 0.8537, f1: 0.8888, edges-ner-ontonotes_loss: 0.0399
09/16 06:16:41 AM: Update 2139: task edges-ner-ontonotes, batch 139 (2139): mcc: 0.9054, acc: 0.8618, precision: 0.9471, recall: 0.8752, f1: 0.9097, edges-ner-ontonotes_loss: 0.0308
09/16 06:16:49 AM: Update 3147: task edges-ner-ontonotes, batch 147 (3147): mcc: 0.8846, acc: 0.8360, precision: 0.9288, recall: 0.8541, f1: 0.8899, edges-ner-ontonotes_loss: 0.0396
09/16 06:16:51 AM: Update 2200: task edges-ner-ontonotes, batch 200 (2200): mcc: 0.9050, acc: 0.8618, precision: 0.9459, recall: 0.8755, f1: 0.9094, edges-ner-ontonotes_loss: 0.0309
09/16 06:16:59 AM: Update 3229: task edges-ner-ontonotes, batch 229 (3229): mcc: 0.8860, acc: 0.8377, precision: 0.9292, recall: 0.8564, f1: 0.8913, edges-ner-ontonotes_loss: 0.0382
09/16 06:17:01 AM: Update 2277: task edges-ner-ontonotes, batch 277 (2277): mcc: 0.9102, acc: 0.8685, precision: 0.9484, recall: 0.8828, f1: 0.9144, edges-ner-ontonotes_loss: 0.0294
09/16 06:17:09 AM: Update 3312: task edges-ner-ontonotes, batch 312 (3312): mcc: 0.8885, acc: 0.8405, precision: 0.9306, recall: 0.8596, f1: 0.8937, edges-ner-ontonotes_loss: 0.0367
09/16 06:17:11 AM: Update 2353: task edges-ner-ontonotes, batch 353 (2353): mcc: 0.9129, acc: 0.8724, precision: 0.9498, recall: 0.8864, f1: 0.9170, edges-ner-ontonotes_loss: 0.0283
09/16 06:17:19 AM: Update 3391: task edges-ner-ontonotes, batch 391 (3391): mcc: 0.8915, acc: 0.8450, precision: 0.9327, recall: 0.8631, f1: 0.8966, edges-ner-ontonotes_loss: 0.0358
09/16 06:17:21 AM: Update 2431: task edges-ner-ontonotes, batch 431 (2431): mcc: 0.9147, acc: 0.8750, precision: 0.9501, recall: 0.8893, f1: 0.9187, edges-ner-ontonotes_loss: 0.0279
09/16 06:17:29 AM: Update 3451: task edges-ner-ontonotes, batch 451 (3451): mcc: 0.8937, acc: 0.8481, precision: 0.9338, recall: 0.8661, f1: 0.8987, edges-ner-ontonotes_loss: 0.0351
09/16 06:17:32 AM: Update 2496: task edges-ner-ontonotes, batch 496 (2496): mcc: 0.9165, acc: 0.8773, precision: 0.9509, recall: 0.8921, f1: 0.9205, edges-ner-ontonotes_loss: 0.0274
09/16 06:17:39 AM: Update 3535: task edges-ner-ontonotes, batch 535 (3535): mcc: 0.8967, acc: 0.8527, precision: 0.9351, recall: 0.8704, f1: 0.9016, edges-ner-ontonotes_loss: 0.0342
09/16 06:17:42 AM: Update 2567: task edges-ner-ontonotes, batch 567 (2567): mcc: 0.9166, acc: 0.8773, precision: 0.9507, recall: 0.8923, f1: 0.9206, edges-ner-ontonotes_loss: 0.0274
09/16 06:17:49 AM: Update 3607: task edges-ner-ontonotes, batch 607 (3607): mcc: 0.8996, acc: 0.8564, precision: 0.9369, recall: 0.8741, f1: 0.9044, edges-ner-ontonotes_loss: 0.0333
09/16 06:17:52 AM: Update 2638: task edges-ner-ontonotes, batch 638 (2638): mcc: 0.9174, acc: 0.8782, precision: 0.9508, recall: 0.8936, f1: 0.9214, edges-ner-ontonotes_loss: 0.0271
09/16 06:17:59 AM: Update 3689: task edges-ner-ontonotes, batch 689 (3689): mcc: 0.9026, acc: 0.8602, precision: 0.9387, recall: 0.8779, f1: 0.9073, edges-ner-ontonotes_loss: 0.0325
09/16 06:18:06 AM: Update 2712: task edges-ner-ontonotes, batch 712 (2712): mcc: 0.9178, acc: 0.8786, precision: 0.9506, recall: 0.8947, f1: 0.9218, edges-ner-ontonotes_loss: 0.0269
09/16 06:18:10 AM: Update 3745: task edges-ner-ontonotes, batch 745 (3745): mcc: 0.9046, acc: 0.8630, precision: 0.9400, recall: 0.8804, f1: 0.9092, edges-ner-ontonotes_loss: 0.0319
09/16 06:18:16 AM: Update 2791: task edges-ner-ontonotes, batch 791 (2791): mcc: 0.9190, acc: 0.8803, precision: 0.9512, recall: 0.8963, f1: 0.9230, edges-ner-ontonotes_loss: 0.0265
09/16 06:18:20 AM: Update 3816: task edges-ner-ontonotes, batch 816 (3816): mcc: 0.9077, acc: 0.8670, precision: 0.9416, recall: 0.8846, f1: 0.9122, edges-ner-ontonotes_loss: 0.0312
09/16 06:18:26 AM: Update 2840: task edges-ner-ontonotes, batch 840 (2840): mcc: 0.9178, acc: 0.8787, precision: 0.9504, recall: 0.8949, f1: 0.9218, edges-ner-ontonotes_loss: 0.0271
09/16 06:18:30 AM: Update 3895: task edges-ner-ontonotes, batch 895 (3895): mcc: 0.9101, acc: 0.8703, precision: 0.9429, recall: 0.8878, f1: 0.9145, edges-ner-ontonotes_loss: 0.0304
09/16 06:18:37 AM: Update 2909: task edges-ner-ontonotes, batch 909 (2909): mcc: 0.9157, acc: 0.8757, precision: 0.9492, recall: 0.8921, f1: 0.9198, edges-ner-ontonotes_loss: 0.0279
09/16 06:18:40 AM: Update 3969: task edges-ner-ontonotes, batch 969 (3969): mcc: 0.9121, acc: 0.8727, precision: 0.9439, recall: 0.8906, f1: 0.9165, edges-ner-ontonotes_loss: 0.0296
09/16 06:18:44 AM: ***** Step 4000 / Validation 4 *****
09/16 06:18:44 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:18:44 AM: Validating...
09/16 06:18:47 AM: Update 2979: task edges-ner-ontonotes, batch 979 (2979): mcc: 0.9138, acc: 0.8733, precision: 0.9480, recall: 0.8898, f1: 0.9180, edges-ner-ontonotes_loss: 0.0287
09/16 06:18:50 AM: Evaluate: task edges-ner-ontonotes, batch 40 (157): mcc: 0.8858, acc: 0.8475, precision: 0.9219, recall: 0.8630, f1: 0.8915, edges-ner-ontonotes_loss: 0.0350
09/16 06:18:51 AM: ***** Step 3000 / Validation 3 *****
09/16 06:18:51 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:18:51 AM: Validating...
09/16 06:18:57 AM: Evaluate: task edges-ner-ontonotes, batch 35 (157): mcc: 0.8782, acc: 0.8312, precision: 0.9220, recall: 0.8488, f1: 0.8839, edges-ner-ontonotes_loss: 0.0369
09/16 06:19:00 AM: Evaluate: task edges-ner-ontonotes, batch 92 (157): mcc: 0.9152, acc: 0.8800, precision: 0.9471, recall: 0.8932, f1: 0.9193, edges-ner-ontonotes_loss: 0.0280
09/16 06:19:09 AM: Evaluate: task edges-ner-ontonotes, batch 80 (157): mcc: 0.9021, acc: 0.8596, precision: 0.9432, recall: 0.8727, f1: 0.9066, edges-ner-ontonotes_loss: 0.0317
09/16 06:19:10 AM: Evaluate: task edges-ner-ontonotes, batch 135 (157): mcc: 0.9276, acc: 0.8973, precision: 0.9541, recall: 0.9095, f1: 0.9313, edges-ner-ontonotes_loss: 0.0244
09/16 06:19:15 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:19:15 AM: Best result seen so far for macro.
09/16 06:19:15 AM: Updating LR scheduler:
09/16 06:19:15 AM: 	Best result seen so far for macro_avg: 0.933
09/16 06:19:15 AM: 	# validation passes without improvement: 0
09/16 06:19:15 AM: edges-ner-ontonotes_loss: training: 0.029300 validation: 0.023586
09/16 06:19:15 AM: macro_avg: validation: 0.933085
09/16 06:19:15 AM: micro_avg: validation: 0.000000
09/16 06:19:15 AM: edges-ner-ontonotes_mcc: training: 0.913109 validation: 0.929508
09/16 06:19:15 AM: edges-ner-ontonotes_acc: training: 0.873952 validation: 0.899075
09/16 06:19:15 AM: edges-ner-ontonotes_precision: training: 0.944525 validation: 0.954625
09/16 06:19:15 AM: edges-ner-ontonotes_recall: training: 0.891790 validation: 0.912496
09/16 06:19:15 AM: edges-ner-ontonotes_f1: training: 0.917400 validation: 0.933085
09/16 06:19:15 AM: Global learning rate: 0.0001
09/16 06:19:15 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:19:20 AM: Evaluate: task edges-ner-ontonotes, batch 124 (157): mcc: 0.9146, acc: 0.8762, precision: 0.9515, recall: 0.8879, f1: 0.9186, edges-ner-ontonotes_loss: 0.0281
09/16 06:19:20 AM: Update 4027: task edges-ner-ontonotes, batch 27 (4027): mcc: 0.9390, acc: 0.9096, precision: 0.9569, recall: 0.9279, f1: 0.9422, edges-ner-ontonotes_loss: 0.0202
09/16 06:19:25 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:19:25 AM: Best result seen so far for macro.
09/16 06:19:26 AM: Updating LR scheduler:
09/16 06:19:26 AM: 	Best result seen so far for macro_avg: 0.924
09/16 06:19:26 AM: 	# validation passes without improvement: 0
09/16 06:19:26 AM: edges-ner-ontonotes_loss: training: 0.028876 validation: 0.026224
09/16 06:19:26 AM: macro_avg: validation: 0.924125
09/16 06:19:26 AM: micro_avg: validation: 0.000000
09/16 06:19:26 AM: edges-ner-ontonotes_mcc: training: 0.913398 validation: 0.920364
09/16 06:19:26 AM: edges-ner-ontonotes_acc: training: 0.872691 validation: 0.883303
09/16 06:19:26 AM: edges-ner-ontonotes_precision: training: 0.947822 validation: 0.955318
09/16 06:19:26 AM: edges-ner-ontonotes_recall: training: 0.889178 validation: 0.894904
09/16 06:19:26 AM: edges-ner-ontonotes_f1: training: 0.917564 validation: 0.924125
09/16 06:19:26 AM: Global learning rate: 0.0001
09/16 06:19:26 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:19:30 AM: Update 3038: task edges-ner-ontonotes, batch 38 (3038): mcc: 0.8885, acc: 0.8450, precision: 0.9286, recall: 0.8615, f1: 0.8938, edges-ner-ontonotes_loss: 0.0382
09/16 06:19:30 AM: Update 4074: task edges-ner-ontonotes, batch 74 (4074): mcc: 0.9376, acc: 0.9063, precision: 0.9580, recall: 0.9243, f1: 0.9409, edges-ner-ontonotes_loss: 0.0195
09/16 06:19:41 AM: Update 4152: task edges-ner-ontonotes, batch 152 (4152): mcc: 0.9360, acc: 0.9042, precision: 0.9566, recall: 0.9227, f1: 0.9393, edges-ner-ontonotes_loss: 0.0208
09/16 06:19:42 AM: Update 3113: task edges-ner-ontonotes, batch 113 (3113): mcc: 0.8825, acc: 0.8343, precision: 0.9265, recall: 0.8525, f1: 0.8879, edges-ner-ontonotes_loss: 0.0403
09/16 06:19:51 AM: Update 4239: task edges-ner-ontonotes, batch 239 (4239): mcc: 0.9344, acc: 0.9021, precision: 0.9549, recall: 0.9214, f1: 0.9379, edges-ner-ontonotes_loss: 0.0213
09/16 06:19:54 AM: Update 3190: task edges-ner-ontonotes, batch 190 (3190): mcc: 0.8857, acc: 0.8374, precision: 0.9291, recall: 0.8560, f1: 0.8910, edges-ner-ontonotes_loss: 0.0386
09/16 06:20:01 AM: Update 4319: task edges-ner-ontonotes, batch 319 (4319): mcc: 0.9343, acc: 0.9020, precision: 0.9545, recall: 0.9215, f1: 0.9377, edges-ner-ontonotes_loss: 0.0212
09/16 06:20:04 AM: Update 3272: task edges-ner-ontonotes, batch 272 (3272): mcc: 0.8884, acc: 0.8404, precision: 0.9311, recall: 0.8589, f1: 0.8936, edges-ner-ontonotes_loss: 0.0373
09/16 06:20:11 AM: Update 4378: task edges-ner-ontonotes, batch 378 (4378): mcc: 0.9320, acc: 0.8988, precision: 0.9531, recall: 0.9186, f1: 0.9355, edges-ner-ontonotes_loss: 0.0220
09/16 06:20:14 AM: Update 3361: task edges-ner-ontonotes, batch 361 (3361): mcc: 0.8908, acc: 0.8439, precision: 0.9324, recall: 0.8622, f1: 0.8959, edges-ner-ontonotes_loss: 0.0361
09/16 06:20:21 AM: Update 4458: task edges-ner-ontonotes, batch 458 (4458): mcc: 0.9276, acc: 0.8928, precision: 0.9509, recall: 0.9126, f1: 0.9313, edges-ner-ontonotes_loss: 0.0239
09/16 06:20:25 AM: Update 3426: task edges-ner-ontonotes, batch 426 (3426): mcc: 0.8918, acc: 0.8458, precision: 0.9326, recall: 0.8638, f1: 0.8969, edges-ner-ontonotes_loss: 0.0355
09/16 06:20:31 AM: Update 4545: task edges-ner-ontonotes, batch 545 (4545): mcc: 0.9233, acc: 0.8871, precision: 0.9487, recall: 0.9067, f1: 0.9272, edges-ner-ontonotes_loss: 0.0264
09/16 06:20:35 AM: Update 3511: task edges-ner-ontonotes, batch 511 (3511): mcc: 0.8956, acc: 0.8513, precision: 0.9346, recall: 0.8690, f1: 0.9006, edges-ner-ontonotes_loss: 0.0345
09/16 06:20:43 AM: Update 4617: task edges-ner-ontonotes, batch 617 (4617): mcc: 0.9203, acc: 0.8835, precision: 0.9468, recall: 0.9030, f1: 0.9244, edges-ner-ontonotes_loss: 0.0276
09/16 06:20:45 AM: Update 3590: task edges-ner-ontonotes, batch 590 (3590): mcc: 0.8990, acc: 0.8557, precision: 0.9366, recall: 0.8734, f1: 0.9039, edges-ner-ontonotes_loss: 0.0335
09/16 06:20:54 AM: Update 4675: task edges-ner-ontonotes, batch 675 (4675): mcc: 0.9181, acc: 0.8808, precision: 0.9454, recall: 0.9002, f1: 0.9223, edges-ner-ontonotes_loss: 0.0284
09/16 06:20:55 AM: Update 3675: task edges-ner-ontonotes, batch 675 (3675): mcc: 0.9021, acc: 0.8597, precision: 0.9383, recall: 0.8774, f1: 0.9068, edges-ner-ontonotes_loss: 0.0326
09/16 06:21:04 AM: Update 4766: task edges-ner-ontonotes, batch 766 (4766): mcc: 0.9170, acc: 0.8795, precision: 0.9446, recall: 0.8990, f1: 0.9212, edges-ner-ontonotes_loss: 0.0288
09/16 06:21:07 AM: Update 3739: task edges-ner-ontonotes, batch 739 (3739): mcc: 0.9042, acc: 0.8625, precision: 0.9397, recall: 0.8800, f1: 0.9089, edges-ner-ontonotes_loss: 0.0320
09/16 06:21:14 AM: Update 4855: task edges-ner-ontonotes, batch 855 (4855): mcc: 0.9157, acc: 0.8779, precision: 0.9436, recall: 0.8975, f1: 0.9200, edges-ner-ontonotes_loss: 0.0291
09/16 06:21:17 AM: Update 3807: task edges-ner-ontonotes, batch 807 (3807): mcc: 0.9073, acc: 0.8666, precision: 0.9414, recall: 0.8841, f1: 0.9119, edges-ner-ontonotes_loss: 0.0312
09/16 06:21:24 AM: Update 4935: task edges-ner-ontonotes, batch 935 (4935): mcc: 0.9154, acc: 0.8775, precision: 0.9435, recall: 0.8970, f1: 0.9196, edges-ner-ontonotes_loss: 0.0291
09/16 06:21:27 AM: Update 3890: task edges-ner-ontonotes, batch 890 (3890): mcc: 0.9100, acc: 0.8702, precision: 0.9428, recall: 0.8877, f1: 0.9144, edges-ner-ontonotes_loss: 0.0304
09/16 06:21:35 AM: Update 4989: task edges-ner-ontonotes, batch 989 (4989): mcc: 0.9150, acc: 0.8769, precision: 0.9431, recall: 0.8966, f1: 0.9193, edges-ner-ontonotes_loss: 0.0292
09/16 06:21:36 AM: ***** Step 5000 / Validation 5 *****
09/16 06:21:36 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:21:36 AM: Validating...
09/16 06:21:38 AM: Update 3978: task edges-ner-ontonotes, batch 978 (3978): mcc: 0.9124, acc: 0.8730, precision: 0.9441, recall: 0.8908, f1: 0.9167, edges-ner-ontonotes_loss: 0.0295
09/16 06:21:42 AM: ***** Step 4000 / Validation 4 *****
09/16 06:21:42 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:21:42 AM: Validating...
09/16 06:21:45 AM: Evaluate: task edges-ner-ontonotes, batch 51 (157): mcc: 0.9123, acc: 0.8766, precision: 0.9432, recall: 0.8915, f1: 0.9167, edges-ner-ontonotes_loss: 0.0285
09/16 06:21:48 AM: Evaluate: task edges-ner-ontonotes, batch 33 (157): mcc: 0.8812, acc: 0.8409, precision: 0.9196, recall: 0.8567, f1: 0.8870, edges-ner-ontonotes_loss: 0.0362
09/16 06:21:55 AM: Evaluate: task edges-ner-ontonotes, batch 97 (157): mcc: 0.9253, acc: 0.8917, precision: 0.9558, recall: 0.9036, f1: 0.9290, edges-ner-ontonotes_loss: 0.0253
09/16 06:21:58 AM: Evaluate: task edges-ner-ontonotes, batch 78 (157): mcc: 0.9093, acc: 0.8737, precision: 0.9413, recall: 0.8878, f1: 0.9138, edges-ner-ontonotes_loss: 0.0297
09/16 06:22:05 AM: Evaluate: task edges-ner-ontonotes, batch 140 (157): mcc: 0.9331, acc: 0.9025, precision: 0.9600, recall: 0.9140, f1: 0.9364, edges-ner-ontonotes_loss: 0.0226
09/16 06:22:08 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:22:08 AM: Best result seen so far for macro.
09/16 06:22:08 AM: Updating LR scheduler:
09/16 06:22:08 AM: 	Best result seen so far for macro_avg: 0.937
09/16 06:22:08 AM: 	# validation passes without improvement: 0
09/16 06:22:08 AM: edges-ner-ontonotes_loss: training: 0.029206 validation: 0.022330
09/16 06:22:08 AM: macro_avg: validation: 0.936631
09/16 06:22:08 AM: micro_avg: validation: 0.000000
09/16 06:22:08 AM: edges-ner-ontonotes_mcc: training: 0.915036 validation: 0.933303
09/16 06:22:08 AM: edges-ner-ontonotes_acc: training: 0.876965 validation: 0.902335
09/16 06:22:08 AM: edges-ner-ontonotes_precision: training: 0.943104 validation: 0.959812
09/16 06:22:08 AM: edges-ner-ontonotes_recall: training: 0.896725 validation: 0.914544
09/16 06:22:08 AM: edges-ner-ontonotes_f1: training: 0.919330 validation: 0.936631
09/16 06:22:08 AM: Global learning rate: 0.0001
09/16 06:22:08 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:22:10 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9195, acc: 0.8866, precision: 0.9484, recall: 0.8999, f1: 0.9235, edges-ner-ontonotes_loss: 0.0265
09/16 06:22:15 AM: Update 5047: task edges-ner-ontonotes, batch 47 (5047): mcc: 0.9140, acc: 0.8814, precision: 0.9362, recall: 0.9014, f1: 0.9185, edges-ner-ontonotes_loss: 0.0287
09/16 06:22:18 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:22:18 AM: Best result seen so far for macro.
09/16 06:22:18 AM: Updating LR scheduler:
09/16 06:22:18 AM: 	Best result seen so far for macro_avg: 0.933
09/16 06:22:18 AM: 	# validation passes without improvement: 0
09/16 06:22:18 AM: edges-ner-ontonotes_loss: training: 0.029300 validation: 0.023586
09/16 06:22:18 AM: macro_avg: validation: 0.933085
09/16 06:22:18 AM: micro_avg: validation: 0.000000
09/16 06:22:18 AM: edges-ner-ontonotes_mcc: training: 0.913109 validation: 0.929508
09/16 06:22:18 AM: edges-ner-ontonotes_acc: training: 0.873952 validation: 0.899075
09/16 06:22:18 AM: edges-ner-ontonotes_precision: training: 0.944525 validation: 0.954625
09/16 06:22:18 AM: edges-ner-ontonotes_recall: training: 0.891790 validation: 0.912496
09/16 06:22:18 AM: edges-ner-ontonotes_f1: training: 0.917400 validation: 0.933085
09/16 06:22:18 AM: Global learning rate: 0.0001
09/16 06:22:18 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:22:21 AM: Update 4013: task edges-ner-ontonotes, batch 13 (4013): mcc: 0.9352, acc: 0.9064, precision: 0.9559, recall: 0.9219, f1: 0.9386, edges-ner-ontonotes_loss: 0.0217
09/16 06:22:25 AM: Update 5110: task edges-ner-ontonotes, batch 110 (5110): mcc: 0.9188, acc: 0.8851, precision: 0.9430, recall: 0.9038, f1: 0.9230, edges-ner-ontonotes_loss: 0.0268
09/16 06:22:31 AM: Update 4058: task edges-ner-ontonotes, batch 58 (4058): mcc: 0.9381, acc: 0.9071, precision: 0.9574, recall: 0.9259, f1: 0.9414, edges-ner-ontonotes_loss: 0.0195
09/16 06:22:35 AM: Update 5203: task edges-ner-ontonotes, batch 203 (5203): mcc: 0.9212, acc: 0.8876, precision: 0.9460, recall: 0.9054, f1: 0.9253, edges-ner-ontonotes_loss: 0.0259
09/16 06:22:43 AM: Update 4132: task edges-ner-ontonotes, batch 132 (4132): mcc: 0.9361, acc: 0.9037, precision: 0.9563, recall: 0.9232, f1: 0.9395, edges-ner-ontonotes_loss: 0.0208
09/16 06:22:45 AM: Update 5280: task edges-ner-ontonotes, batch 280 (5280): mcc: 0.9245, acc: 0.8914, precision: 0.9489, recall: 0.9087, f1: 0.9284, edges-ner-ontonotes_loss: 0.0250
09/16 06:22:53 AM: Update 4209: task edges-ner-ontonotes, batch 209 (4209): mcc: 0.9347, acc: 0.9029, precision: 0.9548, recall: 0.9219, f1: 0.9381, edges-ner-ontonotes_loss: 0.0212
09/16 06:22:55 AM: Update 5338: task edges-ner-ontonotes, batch 338 (5338): mcc: 0.9272, acc: 0.8942, precision: 0.9505, recall: 0.9122, f1: 0.9309, edges-ner-ontonotes_loss: 0.0241
09/16 06:23:03 AM: Update 4280: task edges-ner-ontonotes, batch 280 (4280): mcc: 0.9345, acc: 0.9021, precision: 0.9549, recall: 0.9215, f1: 0.9379, edges-ner-ontonotes_loss: 0.0212
09/16 06:23:05 AM: Update 5413: task edges-ner-ontonotes, batch 413 (5413): mcc: 0.9291, acc: 0.8966, precision: 0.9511, recall: 0.9151, f1: 0.9327, edges-ner-ontonotes_loss: 0.0233
09/16 06:23:13 AM: Update 4361: task edges-ner-ontonotes, batch 361 (4361): mcc: 0.9335, acc: 0.9009, precision: 0.9541, recall: 0.9206, f1: 0.9370, edges-ner-ontonotes_loss: 0.0214
09/16 06:23:17 AM: Update 5489: task edges-ner-ontonotes, batch 489 (5489): mcc: 0.9306, acc: 0.8984, precision: 0.9521, recall: 0.9170, f1: 0.9342, edges-ner-ontonotes_loss: 0.0229
09/16 06:23:23 AM: Update 4426: task edges-ner-ontonotes, batch 426 (4426): mcc: 0.9294, acc: 0.8951, precision: 0.9519, recall: 0.9149, f1: 0.9330, edges-ner-ontonotes_loss: 0.0232
09/16 06:23:28 AM: Update 5566: task edges-ner-ontonotes, batch 566 (5566): mcc: 0.9320, acc: 0.9004, precision: 0.9528, recall: 0.9189, f1: 0.9356, edges-ner-ontonotes_loss: 0.0225
09/16 06:23:33 AM: Update 4498: task edges-ner-ontonotes, batch 498 (4498): mcc: 0.9257, acc: 0.8906, precision: 0.9499, recall: 0.9099, f1: 0.9295, edges-ner-ontonotes_loss: 0.0249
09/16 06:23:39 AM: Update 5609: task edges-ner-ontonotes, batch 609 (5609): mcc: 0.9330, acc: 0.9016, precision: 0.9536, recall: 0.9200, f1: 0.9365, edges-ner-ontonotes_loss: 0.0222
09/16 06:23:44 AM: Update 4593: task edges-ner-ontonotes, batch 593 (4593): mcc: 0.9210, acc: 0.8845, precision: 0.9470, recall: 0.9040, f1: 0.9250, edges-ner-ontonotes_loss: 0.0274
09/16 06:23:51 AM: Update 5684: task edges-ner-ontonotes, batch 684 (5684): mcc: 0.9335, acc: 0.9022, precision: 0.9536, recall: 0.9209, f1: 0.9370, edges-ner-ontonotes_loss: 0.0220
09/16 06:23:55 AM: Update 4663: task edges-ner-ontonotes, batch 663 (4663): mcc: 0.9183, acc: 0.8811, precision: 0.9456, recall: 0.9005, f1: 0.9225, edges-ner-ontonotes_loss: 0.0283
09/16 06:24:01 AM: Update 5767: task edges-ner-ontonotes, batch 767 (5767): mcc: 0.9340, acc: 0.9027, precision: 0.9537, recall: 0.9217, f1: 0.9374, edges-ner-ontonotes_loss: 0.0217
09/16 06:24:05 AM: Update 4728: task edges-ner-ontonotes, batch 728 (4728): mcc: 0.9173, acc: 0.8798, precision: 0.9448, recall: 0.8993, f1: 0.9215, edges-ner-ontonotes_loss: 0.0287
09/16 06:24:11 AM: Update 5848: task edges-ner-ontonotes, batch 848 (5848): mcc: 0.9344, acc: 0.9031, precision: 0.9539, recall: 0.9222, f1: 0.9378, edges-ner-ontonotes_loss: 0.0216
09/16 06:24:15 AM: Update 4834: task edges-ner-ontonotes, batch 834 (4834): mcc: 0.9162, acc: 0.8785, precision: 0.9441, recall: 0.8979, f1: 0.9204, edges-ner-ontonotes_loss: 0.0290
09/16 06:24:25 AM: Update 5920: task edges-ner-ontonotes, batch 920 (5920): mcc: 0.9345, acc: 0.9034, precision: 0.9536, recall: 0.9228, f1: 0.9380, edges-ner-ontonotes_loss: 0.0217
09/16 06:24:25 AM: Update 4914: task edges-ner-ontonotes, batch 914 (4914): mcc: 0.9154, acc: 0.8776, precision: 0.9435, recall: 0.8971, f1: 0.9197, edges-ner-ontonotes_loss: 0.0291
09/16 06:24:35 AM: Update 5984: task edges-ner-ontonotes, batch 984 (5984): mcc: 0.9323, acc: 0.9005, precision: 0.9524, recall: 0.9198, f1: 0.9358, edges-ner-ontonotes_loss: 0.0226
09/16 06:24:36 AM: ***** Step 6000 / Validation 6 *****
09/16 06:24:36 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:24:36 AM: Update 4982: task edges-ner-ontonotes, batch 982 (4982): mcc: 0.9149, acc: 0.8769, precision: 0.9430, recall: 0.8965, f1: 0.9192, edges-ner-ontonotes_loss: 0.0292
09/16 06:24:37 AM: Validating...
09/16 06:24:40 AM: ***** Step 5000 / Validation 5 *****
09/16 06:24:40 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:24:40 AM: Validating...
09/16 06:24:45 AM: Evaluate: task edges-ner-ontonotes, batch 45 (157): mcc: 0.9010, acc: 0.8664, precision: 0.9294, recall: 0.8838, f1: 0.9060, edges-ner-ontonotes_loss: 0.0307
09/16 06:24:47 AM: Evaluate: task edges-ner-ontonotes, batch 38 (157): mcc: 0.9054, acc: 0.8679, precision: 0.9372, recall: 0.8846, f1: 0.9101, edges-ner-ontonotes_loss: 0.0305
09/16 06:24:55 AM: Evaluate: task edges-ner-ontonotes, batch 90 (157): mcc: 0.9217, acc: 0.8881, precision: 0.9511, recall: 0.9015, f1: 0.9256, edges-ner-ontonotes_loss: 0.0262
09/16 06:24:57 AM: Evaluate: task edges-ner-ontonotes, batch 81 (157): mcc: 0.9221, acc: 0.8881, precision: 0.9525, recall: 0.9008, f1: 0.9260, edges-ner-ontonotes_loss: 0.0263
09/16 06:25:05 AM: Evaluate: task edges-ner-ontonotes, batch 115 (157): mcc: 0.9251, acc: 0.8929, precision: 0.9525, recall: 0.9064, f1: 0.9289, edges-ner-ontonotes_loss: 0.0247
09/16 06:25:07 AM: Evaluate: task edges-ner-ontonotes, batch 129 (157): mcc: 0.9301, acc: 0.8983, precision: 0.9585, recall: 0.9098, f1: 0.9335, edges-ner-ontonotes_loss: 0.0235
09/16 06:25:13 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:25:14 AM: Updating LR scheduler:
09/16 06:25:14 AM: 	Best result seen so far for macro_avg: 0.937
09/16 06:25:14 AM: 	# validation passes without improvement: 1
09/16 06:25:14 AM: edges-ner-ontonotes_loss: training: 0.022841 validation: 0.022142
09/16 06:25:14 AM: macro_avg: validation: 0.936206
09/16 06:25:14 AM: Best result seen so far for macro.
09/16 06:25:14 AM: micro_avg: validation: 0.000000
09/16 06:25:14 AM: Updating LR scheduler:
09/16 06:25:14 AM: edges-ner-ontonotes_mcc: training: 0.931816 validation: 0.932800
09/16 06:25:14 AM: edges-ner-ontonotes_acc: training: 0.899812 validation: 0.902715
09/16 06:25:14 AM: 	Best result seen so far for macro_avg: 0.937
09/16 06:25:14 AM: edges-ner-ontonotes_precision: training: 0.952336 validation: 0.957508
09/16 06:25:14 AM: 	# validation passes without improvement: 0
09/16 06:25:14 AM: edges-ner-ontonotes_recall: training: 0.919018 validation: 0.915833
09/16 06:25:14 AM: edges-ner-ontonotes_f1: training: 0.935380 validation: 0.936206
09/16 06:25:14 AM: edges-ner-ontonotes_loss: training: 0.029206 validation: 0.022330
09/16 06:25:14 AM: macro_avg: validation: 0.936631
09/16 06:25:14 AM: micro_avg: validation: 0.000000
09/16 06:25:14 AM: edges-ner-ontonotes_mcc: training: 0.915036 validation: 0.933303
09/16 06:25:14 AM: edges-ner-ontonotes_acc: training: 0.876965 validation: 0.902335
09/16 06:25:14 AM: edges-ner-ontonotes_precision: training: 0.943104 validation: 0.959812
09/16 06:25:14 AM: edges-ner-ontonotes_recall: training: 0.896725 validation: 0.914544
09/16 06:25:14 AM: edges-ner-ontonotes_f1: training: 0.919330 validation: 0.936631
09/16 06:25:14 AM: Global learning rate: 0.0001
09/16 06:25:14 AM: Global learning rate: 0.0001
09/16 06:25:14 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:25:14 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:25:15 AM: Update 6009: task edges-ner-ontonotes, batch 9 (6009): mcc: 0.9097, acc: 0.8591, precision: 0.9389, recall: 0.8909, f1: 0.9142, edges-ner-ontonotes_loss: 0.0332
09/16 06:25:17 AM: Update 5025: task edges-ner-ontonotes, batch 25 (5025): mcc: 0.9108, acc: 0.8793, precision: 0.9322, recall: 0.8995, f1: 0.9155, edges-ner-ontonotes_loss: 0.0293
09/16 06:25:25 AM: Update 6082: task edges-ner-ontonotes, batch 82 (6082): mcc: 0.9025, acc: 0.8585, precision: 0.9341, recall: 0.8822, f1: 0.9074, edges-ner-ontonotes_loss: 0.0339
09/16 06:25:27 AM: Update 5097: task edges-ner-ontonotes, batch 97 (5097): mcc: 0.9177, acc: 0.8839, precision: 0.9413, recall: 0.9033, f1: 0.9219, edges-ner-ontonotes_loss: 0.0270
09/16 06:25:35 AM: Update 6151: task edges-ner-ontonotes, batch 151 (6151): mcc: 0.9015, acc: 0.8597, precision: 0.9328, recall: 0.8816, f1: 0.9065, edges-ner-ontonotes_loss: 0.0347
09/16 06:25:37 AM: Update 5172: task edges-ner-ontonotes, batch 172 (5172): mcc: 0.9206, acc: 0.8871, precision: 0.9452, recall: 0.9050, f1: 0.9247, edges-ner-ontonotes_loss: 0.0262
09/16 06:25:48 AM: Update 5261: task edges-ner-ontonotes, batch 261 (5261): mcc: 0.9232, acc: 0.8901, precision: 0.9479, recall: 0.9074, f1: 0.9272, edges-ner-ontonotes_loss: 0.0254
09/16 06:25:48 AM: Update 6225: task edges-ner-ontonotes, batch 225 (6225): mcc: 0.9008, acc: 0.8589, precision: 0.9324, recall: 0.8806, f1: 0.9058, edges-ner-ontonotes_loss: 0.0350
09/16 06:25:58 AM: Update 5325: task edges-ner-ontonotes, batch 325 (5325): mcc: 0.9266, acc: 0.8936, precision: 0.9502, recall: 0.9115, f1: 0.9304, edges-ner-ontonotes_loss: 0.0243
09/16 06:25:58 AM: Update 6312: task edges-ner-ontonotes, batch 312 (6312): mcc: 0.9031, acc: 0.8621, precision: 0.9341, recall: 0.8833, f1: 0.9080, edges-ner-ontonotes_loss: 0.0336
09/16 06:26:08 AM: Update 5403: task edges-ner-ontonotes, batch 403 (5403): mcc: 0.9290, acc: 0.8965, precision: 0.9510, recall: 0.9150, f1: 0.9326, edges-ner-ontonotes_loss: 0.0234
09/16 06:26:08 AM: Update 6392: task edges-ner-ontonotes, batch 392 (6392): mcc: 0.9022, acc: 0.8608, precision: 0.9331, recall: 0.8825, f1: 0.9071, edges-ner-ontonotes_loss: 0.0334
09/16 06:26:18 AM: Update 5479: task edges-ner-ontonotes, batch 479 (5479): mcc: 0.9302, acc: 0.8980, precision: 0.9519, recall: 0.9165, f1: 0.9339, edges-ner-ontonotes_loss: 0.0230
09/16 06:26:18 AM: Update 6471: task edges-ner-ontonotes, batch 471 (6471): mcc: 0.9035, acc: 0.8626, precision: 0.9338, recall: 0.8844, f1: 0.9084, edges-ner-ontonotes_loss: 0.0327
09/16 06:26:28 AM: Update 5563: task edges-ner-ontonotes, batch 563 (5563): mcc: 0.9320, acc: 0.9003, precision: 0.9528, recall: 0.9189, f1: 0.9355, edges-ner-ontonotes_loss: 0.0225
09/16 06:26:29 AM: Update 6538: task edges-ner-ontonotes, batch 538 (6538): mcc: 0.9048, acc: 0.8644, precision: 0.9347, recall: 0.8858, f1: 0.9096, edges-ner-ontonotes_loss: 0.0320
09/16 06:26:38 AM: Update 5613: task edges-ner-ontonotes, batch 613 (5613): mcc: 0.9329, acc: 0.9015, precision: 0.9535, recall: 0.9199, f1: 0.9364, edges-ner-ontonotes_loss: 0.0222
09/16 06:26:40 AM: Update 6623: task edges-ner-ontonotes, batch 623 (6623): mcc: 0.9087, acc: 0.8693, precision: 0.9373, recall: 0.8905, f1: 0.9133, edges-ner-ontonotes_loss: 0.0309
09/16 06:26:48 AM: Update 5688: task edges-ner-ontonotes, batch 688 (5688): mcc: 0.9334, acc: 0.9022, precision: 0.9536, recall: 0.9208, f1: 0.9369, edges-ner-ontonotes_loss: 0.0220
09/16 06:26:52 AM: Update 6694: task edges-ner-ontonotes, batch 694 (6694): mcc: 0.9102, acc: 0.8716, precision: 0.9383, recall: 0.8924, f1: 0.9148, edges-ner-ontonotes_loss: 0.0303
09/16 06:26:58 AM: Update 5768: task edges-ner-ontonotes, batch 768 (5768): mcc: 0.9340, acc: 0.9027, precision: 0.9537, recall: 0.9217, f1: 0.9374, edges-ner-ontonotes_loss: 0.0217
09/16 06:27:03 AM: Update 6769: task edges-ner-ontonotes, batch 769 (6769): mcc: 0.9124, acc: 0.8744, precision: 0.9398, recall: 0.8950, f1: 0.9168, edges-ner-ontonotes_loss: 0.0296
09/16 06:27:08 AM: Update 5847: task edges-ner-ontonotes, batch 847 (5847): mcc: 0.9344, acc: 0.9031, precision: 0.9539, recall: 0.9222, f1: 0.9378, edges-ner-ontonotes_loss: 0.0216
09/16 06:27:14 AM: Update 6839: task edges-ner-ontonotes, batch 839 (6839): mcc: 0.9134, acc: 0.8761, precision: 0.9400, recall: 0.8967, f1: 0.9179, edges-ner-ontonotes_loss: 0.0292
09/16 06:27:20 AM: Update 5921: task edges-ner-ontonotes, batch 921 (5921): mcc: 0.9344, acc: 0.9033, precision: 0.9536, recall: 0.9227, f1: 0.9379, edges-ner-ontonotes_loss: 0.0217
09/16 06:27:26 AM: Update 6893: task edges-ner-ontonotes, batch 893 (6893): mcc: 0.9152, acc: 0.8784, precision: 0.9414, recall: 0.8987, f1: 0.9196, edges-ner-ontonotes_loss: 0.0286
09/16 06:27:30 AM: Update 5995: task edges-ner-ontonotes, batch 995 (5995): mcc: 0.9320, acc: 0.9000, precision: 0.9524, recall: 0.9193, f1: 0.9355, edges-ner-ontonotes_loss: 0.0228
09/16 06:27:31 AM: ***** Step 6000 / Validation 6 *****
09/16 06:27:31 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:27:31 AM: Validating...
09/16 06:27:37 AM: Update 6958: task edges-ner-ontonotes, batch 958 (6958): mcc: 0.9172, acc: 0.8809, precision: 0.9427, recall: 0.9012, f1: 0.9215, edges-ner-ontonotes_loss: 0.0280
09/16 06:27:40 AM: Evaluate: task edges-ner-ontonotes, batch 58 (157): mcc: 0.9125, acc: 0.8801, precision: 0.9391, recall: 0.8959, f1: 0.9170, edges-ner-ontonotes_loss: 0.0281
09/16 06:27:46 AM: ***** Step 7000 / Validation 7 *****
09/16 06:27:46 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:27:46 AM: Validating...
09/16 06:27:48 AM: Evaluate: task edges-ner-ontonotes, batch 14 (157): mcc: 0.8666, acc: 0.8173, precision: 0.9111, recall: 0.8377, f1: 0.8729, edges-ner-ontonotes_loss: 0.0365
09/16 06:27:50 AM: Evaluate: task edges-ner-ontonotes, batch 111 (157): mcc: 0.9234, acc: 0.8908, precision: 0.9510, recall: 0.9047, f1: 0.9273, edges-ner-ontonotes_loss: 0.0250
09/16 06:28:00 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.9195, acc: 0.8904, precision: 0.9421, recall: 0.9061, f1: 0.9237, edges-ner-ontonotes_loss: 0.0269
09/16 06:28:01 AM: Evaluate: task edges-ner-ontonotes, batch 152 (157): mcc: 0.9323, acc: 0.9018, precision: 0.9575, recall: 0.9149, f1: 0.9357, edges-ner-ontonotes_loss: 0.0223
09/16 06:28:02 AM: Updating LR scheduler:
09/16 06:28:02 AM: 	Best result seen so far for macro_avg: 0.937
09/16 06:28:02 AM: 	# validation passes without improvement: 1
09/16 06:28:02 AM: edges-ner-ontonotes_loss: training: 0.022841 validation: 0.022142
09/16 06:28:02 AM: macro_avg: validation: 0.936206
09/16 06:28:02 AM: micro_avg: validation: 0.000000
09/16 06:28:02 AM: edges-ner-ontonotes_mcc: training: 0.931816 validation: 0.932800
09/16 06:28:02 AM: edges-ner-ontonotes_acc: training: 0.899812 validation: 0.902715
09/16 06:28:02 AM: edges-ner-ontonotes_precision: training: 0.952336 validation: 0.957508
09/16 06:28:02 AM: edges-ner-ontonotes_recall: training: 0.919018 validation: 0.915833
09/16 06:28:02 AM: edges-ner-ontonotes_f1: training: 0.935380 validation: 0.936206
09/16 06:28:02 AM: Global learning rate: 0.0001
09/16 06:28:02 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:28:11 AM: Update 6042: task edges-ner-ontonotes, batch 42 (6042): mcc: 0.9062, acc: 0.8650, precision: 0.9345, recall: 0.8886, f1: 0.9110, edges-ner-ontonotes_loss: 0.0340
09/16 06:28:11 AM: Evaluate: task edges-ner-ontonotes, batch 114 (157): mcc: 0.9282, acc: 0.8993, precision: 0.9504, recall: 0.9142, f1: 0.9320, edges-ner-ontonotes_loss: 0.0239
09/16 06:28:19 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:28:19 AM: Best result seen so far for macro.
09/16 06:28:19 AM: Updating LR scheduler:
09/16 06:28:19 AM: 	Best result seen so far for macro_avg: 0.940
09/16 06:28:19 AM: 	# validation passes without improvement: 0
09/16 06:28:19 AM: edges-ner-ontonotes_loss: training: 0.027581 validation: 0.021121
09/16 06:28:19 AM: macro_avg: validation: 0.939903
09/16 06:28:19 AM: micro_avg: validation: 0.000000
09/16 06:28:19 AM: edges-ner-ontonotes_mcc: training: 0.918621 validation: 0.936564
09/16 06:28:19 AM: edges-ner-ontonotes_acc: training: 0.882661 validation: 0.909994
09/16 06:28:19 AM: edges-ner-ontonotes_precision: training: 0.943741 validation: 0.955286
09/16 06:28:19 AM: edges-ner-ontonotes_recall: training: 0.902772 validation: 0.925008
09/16 06:28:19 AM: edges-ner-ontonotes_f1: training: 0.922802 validation: 0.939903
09/16 06:28:19 AM: Global learning rate: 0.0001
09/16 06:28:19 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:28:21 AM: Update 6103: task edges-ner-ontonotes, batch 103 (6103): mcc: 0.9014, acc: 0.8587, precision: 0.9314, recall: 0.8827, f1: 0.9064, edges-ner-ontonotes_loss: 0.0338
09/16 06:28:21 AM: Update 7015: task edges-ner-ontonotes, batch 15 (7015): mcc: 0.9492, acc: 0.9242, precision: 0.9550, recall: 0.9490, f1: 0.9520, edges-ner-ontonotes_loss: 0.0166
09/16 06:28:31 AM: Update 6174: task edges-ner-ontonotes, batch 174 (6174): mcc: 0.9008, acc: 0.8585, precision: 0.9330, recall: 0.8800, f1: 0.9058, edges-ner-ontonotes_loss: 0.0349
09/16 06:28:31 AM: Update 7090: task edges-ner-ontonotes, batch 90 (7090): mcc: 0.9431, acc: 0.9144, precision: 0.9573, recall: 0.9353, f1: 0.9462, edges-ner-ontonotes_loss: 0.0184
09/16 06:28:41 AM: Update 6236: task edges-ner-ontonotes, batch 236 (6236): mcc: 0.9011, acc: 0.8593, precision: 0.9326, recall: 0.8810, f1: 0.9061, edges-ner-ontonotes_loss: 0.0348
09/16 06:28:42 AM: Update 7164: task edges-ner-ontonotes, batch 164 (7164): mcc: 0.9443, acc: 0.9159, precision: 0.9591, recall: 0.9358, f1: 0.9473, edges-ner-ontonotes_loss: 0.0183
09/16 06:28:51 AM: Update 6340: task edges-ner-ontonotes, batch 340 (6340): mcc: 0.9037, acc: 0.8628, precision: 0.9345, recall: 0.8839, f1: 0.9085, edges-ner-ontonotes_loss: 0.0335
09/16 06:28:56 AM: Update 7239: task edges-ner-ontonotes, batch 239 (7239): mcc: 0.9418, acc: 0.9128, precision: 0.9576, recall: 0.9327, f1: 0.9449, edges-ner-ontonotes_loss: 0.0191
09/16 06:29:01 AM: Update 6418: task edges-ner-ontonotes, batch 418 (6418): mcc: 0.9028, acc: 0.8617, precision: 0.9336, recall: 0.8832, f1: 0.9077, edges-ner-ontonotes_loss: 0.0332
09/16 06:29:06 AM: Update 7318: task edges-ner-ontonotes, batch 318 (7318): mcc: 0.9422, acc: 0.9136, precision: 0.9580, recall: 0.9328, f1: 0.9452, edges-ner-ontonotes_loss: 0.0190
09/16 06:29:12 AM: Update 6499: task edges-ner-ontonotes, batch 499 (6499): mcc: 0.9041, acc: 0.8634, precision: 0.9343, recall: 0.8849, f1: 0.9089, edges-ner-ontonotes_loss: 0.0325
09/16 06:29:16 AM: Update 7391: task edges-ner-ontonotes, batch 391 (7391): mcc: 0.9427, acc: 0.9139, precision: 0.9585, recall: 0.9333, f1: 0.9457, edges-ner-ontonotes_loss: 0.0187
09/16 06:29:22 AM: Update 6548: task edges-ner-ontonotes, batch 548 (6548): mcc: 0.9052, acc: 0.8648, precision: 0.9350, recall: 0.8863, f1: 0.9100, edges-ner-ontonotes_loss: 0.0318
09/16 06:29:26 AM: Update 7476: task edges-ner-ontonotes, batch 476 (7476): mcc: 0.9416, acc: 0.9123, precision: 0.9575, recall: 0.9323, f1: 0.9447, edges-ner-ontonotes_loss: 0.0193
09/16 06:29:32 AM: Update 6630: task edges-ner-ontonotes, batch 630 (6630): mcc: 0.9091, acc: 0.8698, precision: 0.9376, recall: 0.8910, f1: 0.9137, edges-ner-ontonotes_loss: 0.0307
09/16 06:29:36 AM: Update 7532: task edges-ner-ontonotes, batch 532 (7532): mcc: 0.9375, acc: 0.9068, precision: 0.9551, recall: 0.9270, f1: 0.9408, edges-ner-ontonotes_loss: 0.0213
09/16 06:29:42 AM: Update 6702: task edges-ner-ontonotes, batch 702 (6702): mcc: 0.9104, acc: 0.8719, precision: 0.9383, recall: 0.8927, f1: 0.9150, edges-ner-ontonotes_loss: 0.0302
09/16 06:29:46 AM: Update 7602: task edges-ner-ontonotes, batch 602 (7602): mcc: 0.9340, acc: 0.9025, precision: 0.9529, recall: 0.9225, f1: 0.9375, edges-ner-ontonotes_loss: 0.0225
09/16 06:29:52 AM: Update 6779: task edges-ner-ontonotes, batch 779 (6779): mcc: 0.9126, acc: 0.8746, precision: 0.9399, recall: 0.8952, f1: 0.9170, edges-ner-ontonotes_loss: 0.0296
09/16 06:29:57 AM: Update 7678: task edges-ner-ontonotes, batch 678 (7678): mcc: 0.9309, acc: 0.8986, precision: 0.9508, recall: 0.9188, f1: 0.9345, edges-ner-ontonotes_loss: 0.0240
09/16 06:30:03 AM: Update 6849: task edges-ner-ontonotes, batch 849 (6849): mcc: 0.9137, acc: 0.8764, precision: 0.9403, recall: 0.8969, f1: 0.9181, edges-ner-ontonotes_loss: 0.0291
09/16 06:30:07 AM: Update 7757: task edges-ner-ontonotes, batch 757 (7757): mcc: 0.9284, acc: 0.8951, precision: 0.9493, recall: 0.9155, f1: 0.9321, edges-ner-ontonotes_loss: 0.0249
09/16 06:30:13 AM: Update 6921: task edges-ner-ontonotes, batch 921 (6921): mcc: 0.9160, acc: 0.8795, precision: 0.9420, recall: 0.8997, f1: 0.9203, edges-ner-ontonotes_loss: 0.0284
09/16 06:30:17 AM: Update 7812: task edges-ner-ontonotes, batch 812 (7812): mcc: 0.9269, acc: 0.8933, precision: 0.9483, recall: 0.9138, f1: 0.9307, edges-ner-ontonotes_loss: 0.0255
09/16 06:30:23 AM: Update 6997: task edges-ner-ontonotes, batch 997 (6997): mcc: 0.9185, acc: 0.8825, precision: 0.9437, recall: 0.9027, f1: 0.9227, edges-ner-ontonotes_loss: 0.0276
09/16 06:30:23 AM: ***** Step 7000 / Validation 7 *****
09/16 06:30:23 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:30:23 AM: Validating...
09/16 06:30:27 AM: Update 7885: task edges-ner-ontonotes, batch 885 (7885): mcc: 0.9257, acc: 0.8919, precision: 0.9474, recall: 0.9124, f1: 0.9296, edges-ner-ontonotes_loss: 0.0259
09/16 06:30:33 AM: Evaluate: task edges-ner-ontonotes, batch 62 (157): mcc: 0.9189, acc: 0.8890, precision: 0.9404, recall: 0.9065, f1: 0.9231, edges-ner-ontonotes_loss: 0.0269
09/16 06:30:37 AM: Update 7946: task edges-ner-ontonotes, batch 946 (7946): mcc: 0.9252, acc: 0.8912, precision: 0.9470, recall: 0.9119, f1: 0.9291, edges-ner-ontonotes_loss: 0.0260
09/16 06:30:43 AM: Evaluate: task edges-ner-ontonotes, batch 116 (157): mcc: 0.9287, acc: 0.9000, precision: 0.9506, recall: 0.9149, f1: 0.9324, edges-ner-ontonotes_loss: 0.0237
09/16 06:30:46 AM: ***** Step 8000 / Validation 8 *****
09/16 06:30:46 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:30:46 AM: Validating...
09/16 06:30:47 AM: Evaluate: task edges-ner-ontonotes, batch 6 (157): mcc: 0.8493, acc: 0.7800, precision: 0.8962, recall: 0.8200, f1: 0.8564, edges-ner-ontonotes_loss: 0.0390
09/16 06:30:51 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:30:51 AM: Best result seen so far for macro.
09/16 06:30:51 AM: Updating LR scheduler:
09/16 06:30:51 AM: 	Best result seen so far for macro_avg: 0.940
09/16 06:30:51 AM: 	# validation passes without improvement: 0
09/16 06:30:51 AM: edges-ner-ontonotes_loss: training: 0.027581 validation: 0.021121
09/16 06:30:51 AM: macro_avg: validation: 0.939903
09/16 06:30:51 AM: micro_avg: validation: 0.000000
09/16 06:30:51 AM: edges-ner-ontonotes_mcc: training: 0.918621 validation: 0.936564
09/16 06:30:51 AM: edges-ner-ontonotes_acc: training: 0.882661 validation: 0.909994
09/16 06:30:51 AM: edges-ner-ontonotes_precision: training: 0.943741 validation: 0.955286
09/16 06:30:51 AM: edges-ner-ontonotes_recall: training: 0.902772 validation: 0.925008
09/16 06:30:51 AM: edges-ner-ontonotes_f1: training: 0.922802 validation: 0.939903
09/16 06:30:51 AM: Global learning rate: 0.0001
09/16 06:30:51 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:30:53 AM: Update 7001: task edges-ner-ontonotes, batch 1 (7001): mcc: 0.9658, acc: 0.9496, precision: 0.9643, recall: 0.9712, f1: 0.9677, edges-ner-ontonotes_loss: 0.0127
09/16 06:30:57 AM: Evaluate: task edges-ner-ontonotes, batch 65 (157): mcc: 0.9214, acc: 0.8892, precision: 0.9453, recall: 0.9065, f1: 0.9255, edges-ner-ontonotes_loss: 0.0260
09/16 06:31:03 AM: Update 7059: task edges-ner-ontonotes, batch 59 (7059): mcc: 0.9412, acc: 0.9131, precision: 0.9523, recall: 0.9366, f1: 0.9444, edges-ner-ontonotes_loss: 0.0187
09/16 06:31:07 AM: Evaluate: task edges-ner-ontonotes, batch 116 (157): mcc: 0.9304, acc: 0.8999, precision: 0.9548, recall: 0.9140, f1: 0.9339, edges-ner-ontonotes_loss: 0.0229
09/16 06:31:13 AM: Update 7115: task edges-ner-ontonotes, batch 115 (7115): mcc: 0.9423, acc: 0.9131, precision: 0.9573, recall: 0.9338, f1: 0.9454, edges-ner-ontonotes_loss: 0.0187
09/16 06:31:14 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:31:14 AM: Best result seen so far for macro.
09/16 06:31:14 AM: Updating LR scheduler:
09/16 06:31:14 AM: 	Best result seen so far for macro_avg: 0.941
09/16 06:31:14 AM: 	# validation passes without improvement: 0
09/16 06:31:14 AM: edges-ner-ontonotes_loss: training: 0.026188 validation: 0.020795
09/16 06:31:14 AM: macro_avg: validation: 0.941045
09/16 06:31:14 AM: micro_avg: validation: 0.000000
09/16 06:31:14 AM: edges-ner-ontonotes_mcc: training: 0.924636 validation: 0.937852
09/16 06:31:14 AM: edges-ner-ontonotes_acc: training: 0.890556 validation: 0.909842
09/16 06:31:14 AM: edges-ner-ontonotes_precision: training: 0.946723 validation: 0.959934
09/16 06:31:14 AM: edges-ner-ontonotes_recall: training: 0.911087 validation: 0.922884
09/16 06:31:14 AM: edges-ner-ontonotes_f1: training: 0.928563 validation: 0.941045
09/16 06:31:14 AM: Global learning rate: 0.0001
09/16 06:31:14 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:31:17 AM: Update 8018: task edges-ner-ontonotes, batch 18 (8018): mcc: 0.9200, acc: 0.8861, precision: 0.9463, recall: 0.9029, f1: 0.9241, edges-ner-ontonotes_loss: 0.0280
09/16 06:31:24 AM: Update 7164: task edges-ner-ontonotes, batch 164 (7164): mcc: 0.9443, acc: 0.9159, precision: 0.9591, recall: 0.9358, f1: 0.9473, edges-ner-ontonotes_loss: 0.0183
09/16 06:31:27 AM: Update 8094: task edges-ner-ontonotes, batch 94 (8094): mcc: 0.9131, acc: 0.8764, precision: 0.9407, recall: 0.8955, f1: 0.9175, edges-ner-ontonotes_loss: 0.0281
09/16 06:31:34 AM: Update 7242: task edges-ner-ontonotes, batch 242 (7242): mcc: 0.9418, acc: 0.9127, precision: 0.9576, recall: 0.9325, f1: 0.9449, edges-ner-ontonotes_loss: 0.0191
09/16 06:31:37 AM: Update 8167: task edges-ner-ontonotes, batch 167 (8167): mcc: 0.9196, acc: 0.8839, precision: 0.9433, recall: 0.9050, f1: 0.9238, edges-ner-ontonotes_loss: 0.0261
09/16 06:31:44 AM: Update 7315: task edges-ner-ontonotes, batch 315 (7315): mcc: 0.9423, acc: 0.9138, precision: 0.9580, recall: 0.9331, f1: 0.9454, edges-ner-ontonotes_loss: 0.0190
09/16 06:31:47 AM: Update 8242: task edges-ner-ontonotes, batch 242 (8242): mcc: 0.9241, acc: 0.8899, precision: 0.9463, recall: 0.9105, f1: 0.9280, edges-ner-ontonotes_loss: 0.0250
09/16 06:31:54 AM: Update 7385: task edges-ner-ontonotes, batch 385 (7385): mcc: 0.9426, acc: 0.9138, precision: 0.9582, recall: 0.9333, f1: 0.9456, edges-ner-ontonotes_loss: 0.0187
09/16 06:31:58 AM: Update 8311: task edges-ner-ontonotes, batch 311 (8311): mcc: 0.9247, acc: 0.8913, precision: 0.9463, recall: 0.9116, f1: 0.9287, edges-ner-ontonotes_loss: 0.0247
09/16 06:32:04 AM: Update 7457: task edges-ner-ontonotes, batch 457 (7457): mcc: 0.9415, acc: 0.9124, precision: 0.9574, recall: 0.9322, f1: 0.9447, edges-ner-ontonotes_loss: 0.0192
09/16 06:32:08 AM: Update 8382: task edges-ner-ontonotes, batch 382 (8382): mcc: 0.9259, acc: 0.8930, precision: 0.9469, recall: 0.9133, f1: 0.9298, edges-ner-ontonotes_loss: 0.0243
09/16 06:32:14 AM: Update 7523: task edges-ner-ontonotes, batch 523 (7523): mcc: 0.9382, acc: 0.9077, precision: 0.9555, recall: 0.9278, f1: 0.9414, edges-ner-ontonotes_loss: 0.0208
09/16 06:32:18 AM: Update 8443: task edges-ner-ontonotes, batch 443 (8443): mcc: 0.9273, acc: 0.8951, precision: 0.9475, recall: 0.9153, f1: 0.9311, edges-ner-ontonotes_loss: 0.0241
09/16 06:32:25 AM: Update 7606: task edges-ner-ontonotes, batch 606 (7606): mcc: 0.9337, acc: 0.9022, precision: 0.9526, recall: 0.9222, f1: 0.9372, edges-ner-ontonotes_loss: 0.0226
09/16 06:32:31 AM: Update 8517: task edges-ner-ontonotes, batch 517 (8517): mcc: 0.9301, acc: 0.8987, precision: 0.9492, recall: 0.9188, f1: 0.9338, edges-ner-ontonotes_loss: 0.0233
09/16 06:32:35 AM: Update 7680: task edges-ner-ontonotes, batch 680 (7680): mcc: 0.9308, acc: 0.8985, precision: 0.9507, recall: 0.9187, f1: 0.9344, edges-ner-ontonotes_loss: 0.0240
09/16 06:32:41 AM: Update 8594: task edges-ner-ontonotes, batch 594 (8594): mcc: 0.9318, acc: 0.9010, precision: 0.9503, recall: 0.9211, f1: 0.9355, edges-ner-ontonotes_loss: 0.0227
09/16 06:32:46 AM: Update 7762: task edges-ner-ontonotes, batch 762 (7762): mcc: 0.9282, acc: 0.8948, precision: 0.9492, recall: 0.9153, f1: 0.9319, edges-ner-ontonotes_loss: 0.0250
09/16 06:32:53 AM: Update 8683: task edges-ner-ontonotes, batch 683 (8683): mcc: 0.9337, acc: 0.9033, precision: 0.9513, recall: 0.9235, f1: 0.9372, edges-ner-ontonotes_loss: 0.0220
09/16 06:32:58 AM: Update 7826: task edges-ner-ontonotes, batch 826 (7826): mcc: 0.9265, acc: 0.8928, precision: 0.9481, recall: 0.9133, f1: 0.9304, edges-ner-ontonotes_loss: 0.0257
09/16 06:33:05 AM: Update 8742: task edges-ner-ontonotes, batch 742 (8742): mcc: 0.9346, acc: 0.9044, precision: 0.9522, recall: 0.9244, f1: 0.9381, edges-ner-ontonotes_loss: 0.0217
09/16 06:33:08 AM: Update 7914: task edges-ner-ontonotes, batch 914 (7914): mcc: 0.9255, acc: 0.8916, precision: 0.9472, recall: 0.9122, f1: 0.9294, edges-ner-ontonotes_loss: 0.0259
09/16 06:33:15 AM: Update 8821: task edges-ner-ontonotes, batch 821 (8821): mcc: 0.9356, acc: 0.9057, precision: 0.9530, recall: 0.9254, f1: 0.9390, edges-ner-ontonotes_loss: 0.0214
09/16 06:33:18 AM: Update 7995: task edges-ner-ontonotes, batch 995 (7995): mcc: 0.9247, acc: 0.8906, precision: 0.9467, recall: 0.9112, f1: 0.9286, edges-ner-ontonotes_loss: 0.0262
09/16 06:33:18 AM: ***** Step 8000 / Validation 8 *****
09/16 06:33:18 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:33:18 AM: Validating...
09/16 06:33:25 AM: Update 8889: task edges-ner-ontonotes, batch 889 (8889): mcc: 0.9361, acc: 0.9062, precision: 0.9535, recall: 0.9259, f1: 0.9395, edges-ner-ontonotes_loss: 0.0213
09/16 06:33:28 AM: Evaluate: task edges-ner-ontonotes, batch 58 (157): mcc: 0.9235, acc: 0.8938, precision: 0.9451, recall: 0.9105, f1: 0.9275, edges-ner-ontonotes_loss: 0.0253
09/16 06:33:35 AM: Update 8944: task edges-ner-ontonotes, batch 944 (8944): mcc: 0.9362, acc: 0.9064, precision: 0.9536, recall: 0.9261, f1: 0.9396, edges-ner-ontonotes_loss: 0.0211
09/16 06:33:38 AM: Evaluate: task edges-ner-ontonotes, batch 112 (157): mcc: 0.9295, acc: 0.8990, precision: 0.9536, recall: 0.9134, f1: 0.9331, edges-ner-ontonotes_loss: 0.0232
09/16 06:33:45 AM: Update 9000: task edges-ner-ontonotes, batch 1000 (9000): mcc: 0.9367, acc: 0.9069, precision: 0.9539, recall: 0.9266, f1: 0.9400, edges-ner-ontonotes_loss: 0.0210
09/16 06:33:45 AM: ***** Step 9000 / Validation 9 *****
09/16 06:33:45 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:33:45 AM: Validating...
09/16 06:33:47 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:33:47 AM: Best result seen so far for macro.
09/16 06:33:47 AM: Updating LR scheduler:
09/16 06:33:47 AM: 	Best result seen so far for macro_avg: 0.941
09/16 06:33:47 AM: 	# validation passes without improvement: 0
09/16 06:33:47 AM: edges-ner-ontonotes_loss: training: 0.026188 validation: 0.020795
09/16 06:33:47 AM: macro_avg: validation: 0.941045
09/16 06:33:47 AM: micro_avg: validation: 0.000000
09/16 06:33:47 AM: edges-ner-ontonotes_mcc: training: 0.924636 validation: 0.937852
09/16 06:33:47 AM: edges-ner-ontonotes_acc: training: 0.890556 validation: 0.909842
09/16 06:33:47 AM: edges-ner-ontonotes_precision: training: 0.946723 validation: 0.959934
09/16 06:33:47 AM: edges-ner-ontonotes_recall: training: 0.911087 validation: 0.922884
09/16 06:33:47 AM: edges-ner-ontonotes_f1: training: 0.928563 validation: 0.941045
09/16 06:33:47 AM: Global learning rate: 0.0001
09/16 06:33:47 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:33:49 AM: Update 8001: task edges-ner-ontonotes, batch 1 (8001): mcc: 0.9009, acc: 0.8500, precision: 0.9298, recall: 0.8833, f1: 0.9060, edges-ner-ontonotes_loss: 0.0287
09/16 06:33:55 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.9192, acc: 0.8897, precision: 0.9433, recall: 0.9043, f1: 0.9234, edges-ner-ontonotes_loss: 0.0274
09/16 06:33:59 AM: Update 8069: task edges-ner-ontonotes, batch 69 (8069): mcc: 0.9164, acc: 0.8785, precision: 0.9446, recall: 0.8977, f1: 0.9206, edges-ner-ontonotes_loss: 0.0278
09/16 06:34:05 AM: Evaluate: task edges-ner-ontonotes, batch 117 (157): mcc: 0.9309, acc: 0.9023, precision: 0.9541, recall: 0.9157, f1: 0.9345, edges-ner-ontonotes_loss: 0.0236
09/16 06:34:09 AM: Update 8113: task edges-ner-ontonotes, batch 113 (8113): mcc: 0.9167, acc: 0.8809, precision: 0.9418, recall: 0.9010, f1: 0.9209, edges-ner-ontonotes_loss: 0.0271
09/16 06:34:13 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:34:13 AM: Best result seen so far for macro.
09/16 06:34:14 AM: Updating LR scheduler:
09/16 06:34:14 AM: 	Best result seen so far for macro_avg: 0.942
09/16 06:34:14 AM: 	# validation passes without improvement: 0
09/16 06:34:14 AM: edges-ner-ontonotes_loss: training: 0.020978 validation: 0.020785
09/16 06:34:14 AM: macro_avg: validation: 0.942107
09/16 06:34:14 AM: micro_avg: validation: 0.000000
09/16 06:34:14 AM: edges-ner-ontonotes_mcc: training: 0.936679 validation: 0.938921
09/16 06:34:14 AM: edges-ner-ontonotes_acc: training: 0.906921 validation: 0.912572
09/16 06:34:14 AM: edges-ner-ontonotes_precision: training: 0.953859 validation: 0.958709
09/16 06:34:14 AM: edges-ner-ontonotes_recall: training: 0.926620 validation: 0.926069
09/16 06:34:14 AM: edges-ner-ontonotes_f1: training: 0.940042 validation: 0.942107
09/16 06:34:14 AM: Global learning rate: 0.0001
09/16 06:34:14 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:34:15 AM: Update 9012: task edges-ner-ontonotes, batch 12 (9012): mcc: 0.9449, acc: 0.9151, precision: 0.9610, recall: 0.9350, f1: 0.9478, edges-ner-ontonotes_loss: 0.0207
09/16 06:34:19 AM: Update 8189: task edges-ner-ontonotes, batch 189 (8189): mcc: 0.9217, acc: 0.8867, precision: 0.9445, recall: 0.9077, f1: 0.9258, edges-ner-ontonotes_loss: 0.0256
09/16 06:34:26 AM: Update 9058: task edges-ner-ontonotes, batch 58 (9058): mcc: 0.9212, acc: 0.8848, precision: 0.9470, recall: 0.9043, f1: 0.9252, edges-ner-ontonotes_loss: 0.0270
09/16 06:34:29 AM: Update 8268: task edges-ner-ontonotes, batch 268 (8268): mcc: 0.9248, acc: 0.8910, precision: 0.9466, recall: 0.9115, f1: 0.9287, edges-ner-ontonotes_loss: 0.0247
09/16 06:34:36 AM: Update 9133: task edges-ner-ontonotes, batch 133 (9133): mcc: 0.9136, acc: 0.8765, precision: 0.9402, recall: 0.8969, f1: 0.9180, edges-ner-ontonotes_loss: 0.0304
09/16 06:34:39 AM: Update 8341: task edges-ner-ontonotes, batch 341 (8341): mcc: 0.9249, acc: 0.8918, precision: 0.9463, recall: 0.9120, f1: 0.9289, edges-ner-ontonotes_loss: 0.0247
09/16 06:34:46 AM: Update 9206: task edges-ner-ontonotes, batch 206 (9206): mcc: 0.9103, acc: 0.8718, precision: 0.9384, recall: 0.8925, f1: 0.9149, edges-ner-ontonotes_loss: 0.0313
09/16 06:34:51 AM: Update 8407: task edges-ner-ontonotes, batch 407 (8407): mcc: 0.9260, acc: 0.8933, precision: 0.9470, recall: 0.9134, f1: 0.9299, edges-ner-ontonotes_loss: 0.0244
09/16 06:34:56 AM: Update 9298: task edges-ner-ontonotes, batch 298 (9298): mcc: 0.9080, acc: 0.8694, precision: 0.9365, recall: 0.8900, f1: 0.9127, edges-ner-ontonotes_loss: 0.0325
09/16 06:35:02 AM: Update 8490: task edges-ner-ontonotes, batch 490 (8490): mcc: 0.9291, acc: 0.8972, precision: 0.9486, recall: 0.9176, f1: 0.9328, edges-ner-ontonotes_loss: 0.0236
09/16 06:35:09 AM: Update 9359: task edges-ner-ontonotes, batch 359 (9359): mcc: 0.9080, acc: 0.8700, precision: 0.9361, recall: 0.8904, f1: 0.9127, edges-ner-ontonotes_loss: 0.0325
09/16 06:35:12 AM: Update 8575: task edges-ner-ontonotes, batch 575 (8575): mcc: 0.9316, acc: 0.9006, precision: 0.9501, recall: 0.9207, f1: 0.9352, edges-ner-ontonotes_loss: 0.0228
09/16 06:35:20 AM: Update 9439: task edges-ner-ontonotes, batch 439 (9439): mcc: 0.9083, acc: 0.8704, precision: 0.9361, recall: 0.8910, f1: 0.9130, edges-ner-ontonotes_loss: 0.0321
09/16 06:35:22 AM: Update 8653: task edges-ner-ontonotes, batch 653 (8653): mcc: 0.9333, acc: 0.9028, precision: 0.9511, recall: 0.9230, f1: 0.9368, edges-ner-ontonotes_loss: 0.0222
09/16 06:35:31 AM: Update 9523: task edges-ner-ontonotes, batch 523 (9523): mcc: 0.9098, acc: 0.8724, precision: 0.9371, recall: 0.8929, f1: 0.9145, edges-ner-ontonotes_loss: 0.0313
09/16 06:35:32 AM: Update 8720: task edges-ner-ontonotes, batch 720 (8720): mcc: 0.9343, acc: 0.9041, precision: 0.9519, recall: 0.9242, f1: 0.9378, edges-ner-ontonotes_loss: 0.0218
09/16 06:35:41 AM: Update 9605: task edges-ner-ontonotes, batch 605 (9605): mcc: 0.9105, acc: 0.8728, precision: 0.9375, recall: 0.8936, f1: 0.9151, edges-ner-ontonotes_loss: 0.0308
09/16 06:35:42 AM: Update 8792: task edges-ner-ontonotes, batch 792 (8792): mcc: 0.9352, acc: 0.9053, precision: 0.9527, recall: 0.9251, f1: 0.9387, edges-ner-ontonotes_loss: 0.0216
09/16 06:35:51 AM: Update 9669: task edges-ner-ontonotes, batch 669 (9669): mcc: 0.9117, acc: 0.8742, precision: 0.9383, recall: 0.8951, f1: 0.9162, edges-ner-ontonotes_loss: 0.0303
09/16 06:35:54 AM: Update 8879: task edges-ner-ontonotes, batch 879 (8879): mcc: 0.9359, acc: 0.9060, precision: 0.9532, recall: 0.9257, f1: 0.9393, edges-ner-ontonotes_loss: 0.0214
09/16 06:36:01 AM: Update 9743: task edges-ner-ontonotes, batch 743 (9743): mcc: 0.9138, acc: 0.8768, precision: 0.9395, recall: 0.8978, f1: 0.9182, edges-ner-ontonotes_loss: 0.0295
09/16 06:36:04 AM: Update 8951: task edges-ner-ontonotes, batch 951 (8951): mcc: 0.9362, acc: 0.9064, precision: 0.9536, recall: 0.9261, f1: 0.9396, edges-ner-ontonotes_loss: 0.0211
09/16 06:36:10 AM: ***** Step 9000 / Validation 9 *****
09/16 06:36:10 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:36:10 AM: Validating...
09/16 06:36:11 AM: Update 9814: task edges-ner-ontonotes, batch 814 (9814): mcc: 0.9153, acc: 0.8792, precision: 0.9402, recall: 0.9001, f1: 0.9197, edges-ner-ontonotes_loss: 0.0290
09/16 06:36:14 AM: Evaluate: task edges-ner-ontonotes, batch 21 (157): mcc: 0.8840, acc: 0.8416, precision: 0.9221, recall: 0.8594, f1: 0.8896, edges-ner-ontonotes_loss: 0.0313
09/16 06:36:22 AM: Update 9873: task edges-ner-ontonotes, batch 873 (9873): mcc: 0.9169, acc: 0.8811, precision: 0.9414, recall: 0.9019, f1: 0.9212, edges-ner-ontonotes_loss: 0.0285
09/16 06:36:24 AM: Evaluate: task edges-ner-ontonotes, batch 80 (157): mcc: 0.9230, acc: 0.8920, precision: 0.9496, recall: 0.9053, f1: 0.9269, edges-ner-ontonotes_loss: 0.0269
09/16 06:36:32 AM: Update 9930: task edges-ner-ontonotes, batch 930 (9930): mcc: 0.9180, acc: 0.8827, precision: 0.9422, recall: 0.9031, f1: 0.9223, edges-ner-ontonotes_loss: 0.0281
09/16 06:36:34 AM: Evaluate: task edges-ner-ontonotes, batch 133 (157): mcc: 0.9363, acc: 0.9094, precision: 0.9580, recall: 0.9219, f1: 0.9396, edges-ner-ontonotes_loss: 0.0220
09/16 06:36:38 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:36:38 AM: Best result seen so far for macro.
09/16 06:36:38 AM: Updating LR scheduler:
09/16 06:36:38 AM: 	Best result seen so far for macro_avg: 0.942
09/16 06:36:38 AM: 	# validation passes without improvement: 0
09/16 06:36:38 AM: edges-ner-ontonotes_loss: training: 0.020978 validation: 0.020785
09/16 06:36:38 AM: macro_avg: validation: 0.942107
09/16 06:36:38 AM: micro_avg: validation: 0.000000
09/16 06:36:38 AM: edges-ner-ontonotes_mcc: training: 0.936679 validation: 0.938921
09/16 06:36:38 AM: edges-ner-ontonotes_acc: training: 0.906921 validation: 0.912572
09/16 06:36:38 AM: edges-ner-ontonotes_precision: training: 0.953859 validation: 0.958709
09/16 06:36:38 AM: edges-ner-ontonotes_recall: training: 0.926620 validation: 0.926069
09/16 06:36:38 AM: edges-ner-ontonotes_f1: training: 0.940042 validation: 0.942107
09/16 06:36:38 AM: Global learning rate: 0.0001
09/16 06:36:38 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:36:43 AM: Update 9976: task edges-ner-ontonotes, batch 976 (9976): mcc: 0.9189, acc: 0.8837, precision: 0.9428, recall: 0.9042, f1: 0.9231, edges-ner-ontonotes_loss: 0.0278
09/16 06:36:47 AM: ***** Step 10000 / Validation 10 *****
09/16 06:36:47 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:36:47 AM: Validating...
09/16 06:36:47 AM: Update 9033: task edges-ner-ontonotes, batch 33 (9033): mcc: 0.9392, acc: 0.9088, precision: 0.9574, recall: 0.9278, f1: 0.9424, edges-ner-ontonotes_loss: 0.0200
09/16 06:36:55 AM: Evaluate: task edges-ner-ontonotes, batch 50 (157): mcc: 0.9127, acc: 0.8814, precision: 0.9373, recall: 0.8980, f1: 0.9172, edges-ner-ontonotes_loss: 0.0280
09/16 06:36:57 AM: Update 9089: task edges-ner-ontonotes, batch 89 (9089): mcc: 0.9139, acc: 0.8780, precision: 0.9397, recall: 0.8980, f1: 0.9184, edges-ner-ontonotes_loss: 0.0300
09/16 06:37:05 AM: Evaluate: task edges-ner-ontonotes, batch 106 (157): mcc: 0.9294, acc: 0.9015, precision: 0.9510, recall: 0.9158, f1: 0.9330, edges-ner-ontonotes_loss: 0.0232
09/16 06:37:07 AM: Update 9145: task edges-ner-ontonotes, batch 145 (9145): mcc: 0.9132, acc: 0.8764, precision: 0.9396, recall: 0.8967, f1: 0.9177, edges-ner-ontonotes_loss: 0.0304
09/16 06:37:15 AM: Evaluate: task edges-ner-ontonotes, batch 155 (157): mcc: 0.9390, acc: 0.9137, precision: 0.9568, recall: 0.9280, f1: 0.9422, edges-ner-ontonotes_loss: 0.0202
09/16 06:37:15 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:37:15 AM: Best result seen so far for macro.
09/16 06:37:15 AM: Updating LR scheduler:
09/16 06:37:15 AM: 	Best result seen so far for macro_avg: 0.942
09/16 06:37:15 AM: 	# validation passes without improvement: 0
09/16 06:37:15 AM: edges-ner-ontonotes_loss: training: 0.027529 validation: 0.020106
09/16 06:37:15 AM: macro_avg: validation: 0.942422
09/16 06:37:15 AM: micro_avg: validation: 0.000000
09/16 06:37:15 AM: edges-ner-ontonotes_mcc: training: 0.919611 validation: 0.939210
09/16 06:37:15 AM: edges-ner-ontonotes_acc: training: 0.884609 validation: 0.914089
09/16 06:37:15 AM: edges-ner-ontonotes_precision: training: 0.943268 validation: 0.956933
09/16 06:37:15 AM: edges-ner-ontonotes_recall: training: 0.905076 validation: 0.928344
09/16 06:37:15 AM: edges-ner-ontonotes_f1: training: 0.923777 validation: 0.942422
09/16 06:37:15 AM: Global learning rate: 0.0001
09/16 06:37:15 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:37:17 AM: Update 9213: task edges-ner-ontonotes, batch 213 (9213): mcc: 0.9108, acc: 0.8724, precision: 0.9388, recall: 0.8929, f1: 0.9153, edges-ner-ontonotes_loss: 0.0311
09/16 06:37:25 AM: Update 10051: task edges-ner-ontonotes, batch 51 (10051): mcc: 0.9500, acc: 0.9224, precision: 0.9650, recall: 0.9406, f1: 0.9526, edges-ner-ontonotes_loss: 0.0169
09/16 06:37:27 AM: Update 9293: task edges-ner-ontonotes, batch 293 (9293): mcc: 0.9082, acc: 0.8696, precision: 0.9366, recall: 0.8904, f1: 0.9129, edges-ner-ontonotes_loss: 0.0324
09/16 06:37:35 AM: Update 10128: task edges-ner-ontonotes, batch 128 (10128): mcc: 0.9453, acc: 0.9168, precision: 0.9608, recall: 0.9360, f1: 0.9482, edges-ner-ontonotes_loss: 0.0183
09/16 06:37:37 AM: Update 9356: task edges-ner-ontonotes, batch 356 (9356): mcc: 0.9080, acc: 0.8701, precision: 0.9361, recall: 0.8904, f1: 0.9127, edges-ner-ontonotes_loss: 0.0325
09/16 06:37:47 AM: Update 10207: task edges-ner-ontonotes, batch 207 (10207): mcc: 0.9458, acc: 0.9181, precision: 0.9608, recall: 0.9369, f1: 0.9487, edges-ner-ontonotes_loss: 0.0180
09/16 06:37:47 AM: Update 9436: task edges-ner-ontonotes, batch 436 (9436): mcc: 0.9085, acc: 0.8706, precision: 0.9362, recall: 0.8912, f1: 0.9131, edges-ner-ontonotes_loss: 0.0320
09/16 06:37:58 AM: Update 9522: task edges-ner-ontonotes, batch 522 (9522): mcc: 0.9099, acc: 0.8724, precision: 0.9371, recall: 0.8929, f1: 0.9145, edges-ner-ontonotes_loss: 0.0313
09/16 06:37:59 AM: Update 10276: task edges-ner-ontonotes, batch 276 (10276): mcc: 0.9463, acc: 0.9191, precision: 0.9608, recall: 0.9378, f1: 0.9491, edges-ner-ontonotes_loss: 0.0178
09/16 06:38:08 AM: Update 9611: task edges-ner-ontonotes, batch 611 (9611): mcc: 0.9106, acc: 0.8729, precision: 0.9375, recall: 0.8938, f1: 0.9151, edges-ner-ontonotes_loss: 0.0308
09/16 06:38:09 AM: Update 10352: task edges-ner-ontonotes, batch 352 (10352): mcc: 0.9445, acc: 0.9168, precision: 0.9591, recall: 0.9361, f1: 0.9475, edges-ner-ontonotes_loss: 0.0181
09/16 06:38:18 AM: Update 9670: task edges-ner-ontonotes, batch 670 (9670): mcc: 0.9117, acc: 0.8743, precision: 0.9382, recall: 0.8952, f1: 0.9162, edges-ner-ontonotes_loss: 0.0303
09/16 06:38:19 AM: Update 10433: task edges-ner-ontonotes, batch 433 (10433): mcc: 0.9446, acc: 0.9170, precision: 0.9590, recall: 0.9364, f1: 0.9476, edges-ner-ontonotes_loss: 0.0179
09/16 06:38:28 AM: Update 9741: task edges-ner-ontonotes, batch 741 (9741): mcc: 0.9137, acc: 0.8767, precision: 0.9395, recall: 0.8977, f1: 0.9181, edges-ner-ontonotes_loss: 0.0295
09/16 06:38:29 AM: Update 10503: task edges-ner-ontonotes, batch 503 (10503): mcc: 0.9443, acc: 0.9167, precision: 0.9588, recall: 0.9361, f1: 0.9473, edges-ner-ontonotes_loss: 0.0182
09/16 06:38:38 AM: Update 9814: task edges-ner-ontonotes, batch 814 (9814): mcc: 0.9153, acc: 0.8792, precision: 0.9402, recall: 0.9001, f1: 0.9197, edges-ner-ontonotes_loss: 0.0290
09/16 06:38:39 AM: Update 10578: task edges-ner-ontonotes, batch 578 (10578): mcc: 0.9442, acc: 0.9165, precision: 0.9586, recall: 0.9361, f1: 0.9472, edges-ner-ontonotes_loss: 0.0183
09/16 06:38:48 AM: Update 9900: task edges-ner-ontonotes, batch 900 (9900): mcc: 0.9176, acc: 0.8820, precision: 0.9419, recall: 0.9027, f1: 0.9219, edges-ner-ontonotes_loss: 0.0282
09/16 06:38:49 AM: Update 10631: task edges-ner-ontonotes, batch 631 (10631): mcc: 0.9420, acc: 0.9134, precision: 0.9575, recall: 0.9331, f1: 0.9451, edges-ner-ontonotes_loss: 0.0192
09/16 06:38:59 AM: Update 10710: task edges-ner-ontonotes, batch 710 (10710): mcc: 0.9377, acc: 0.9080, precision: 0.9547, recall: 0.9277, f1: 0.9410, edges-ner-ontonotes_loss: 0.0209
09/16 06:39:00 AM: Update 9963: task edges-ner-ontonotes, batch 963 (9963): mcc: 0.9184, acc: 0.8831, precision: 0.9424, recall: 0.9036, f1: 0.9226, edges-ner-ontonotes_loss: 0.0279
09/16 06:39:05 AM: ***** Step 10000 / Validation 10 *****
09/16 06:39:05 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:39:05 AM: Validating...
09/16 06:39:10 AM: Update 10779: task edges-ner-ontonotes, batch 779 (10779): mcc: 0.9358, acc: 0.9054, precision: 0.9536, recall: 0.9252, f1: 0.9392, edges-ner-ontonotes_loss: 0.0219
09/16 06:39:10 AM: Evaluate: task edges-ner-ontonotes, batch 36 (157): mcc: 0.9031, acc: 0.8692, precision: 0.9301, recall: 0.8872, f1: 0.9081, edges-ner-ontonotes_loss: 0.0302
09/16 06:39:20 AM: Update 10834: task edges-ner-ontonotes, batch 834 (10834): mcc: 0.9338, acc: 0.9030, precision: 0.9522, recall: 0.9229, f1: 0.9373, edges-ner-ontonotes_loss: 0.0226
09/16 06:39:20 AM: Evaluate: task edges-ner-ontonotes, batch 91 (157): mcc: 0.9280, acc: 0.8985, precision: 0.9525, recall: 0.9117, f1: 0.9317, edges-ner-ontonotes_loss: 0.0242
09/16 06:39:30 AM: Update 10889: task edges-ner-ontonotes, batch 889 (10889): mcc: 0.9324, acc: 0.9012, precision: 0.9514, recall: 0.9210, f1: 0.9360, edges-ner-ontonotes_loss: 0.0234
09/16 06:39:30 AM: Evaluate: task edges-ner-ontonotes, batch 142 (157): mcc: 0.9384, acc: 0.9133, precision: 0.9572, recall: 0.9265, f1: 0.9416, edges-ner-ontonotes_loss: 0.0206
09/16 06:39:32 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:39:32 AM: Best result seen so far for macro.
09/16 06:39:32 AM: Updating LR scheduler:
09/16 06:39:32 AM: 	Best result seen so far for macro_avg: 0.942
09/16 06:39:32 AM: 	# validation passes without improvement: 0
09/16 06:39:32 AM: edges-ner-ontonotes_loss: training: 0.027529 validation: 0.020106
09/16 06:39:32 AM: macro_avg: validation: 0.942422
09/16 06:39:32 AM: micro_avg: validation: 0.000000
09/16 06:39:32 AM: edges-ner-ontonotes_mcc: training: 0.919611 validation: 0.939210
09/16 06:39:32 AM: edges-ner-ontonotes_acc: training: 0.884609 validation: 0.914089
09/16 06:39:32 AM: edges-ner-ontonotes_precision: training: 0.943268 validation: 0.956933
09/16 06:39:32 AM: edges-ner-ontonotes_recall: training: 0.905076 validation: 0.928344
09/16 06:39:32 AM: edges-ner-ontonotes_f1: training: 0.923777 validation: 0.942422
09/16 06:39:32 AM: Global learning rate: 0.0001
09/16 06:39:32 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:39:40 AM: Update 10949: task edges-ner-ontonotes, batch 949 (10949): mcc: 0.9309, acc: 0.8992, precision: 0.9502, recall: 0.9193, f1: 0.9345, edges-ner-ontonotes_loss: 0.0239
09/16 06:39:40 AM: Update 10045: task edges-ner-ontonotes, batch 45 (10045): mcc: 0.9497, acc: 0.9219, precision: 0.9643, recall: 0.9407, f1: 0.9524, edges-ner-ontonotes_loss: 0.0168
09/16 06:39:46 AM: ***** Step 11000 / Validation 11 *****
09/16 06:39:46 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:39:46 AM: Validating...
09/16 06:39:50 AM: Evaluate: task edges-ner-ontonotes, batch 24 (157): mcc: 0.8843, acc: 0.8469, precision: 0.9090, recall: 0.8726, f1: 0.8904, edges-ner-ontonotes_loss: 0.0341
09/16 06:39:50 AM: Update 10116: task edges-ner-ontonotes, batch 116 (10116): mcc: 0.9453, acc: 0.9171, precision: 0.9610, recall: 0.9359, f1: 0.9482, edges-ner-ontonotes_loss: 0.0185
09/16 06:40:00 AM: Evaluate: task edges-ner-ontonotes, batch 83 (157): mcc: 0.9288, acc: 0.8995, precision: 0.9502, recall: 0.9154, f1: 0.9325, edges-ner-ontonotes_loss: 0.0243
09/16 06:40:00 AM: Update 10172: task edges-ner-ontonotes, batch 172 (10172): mcc: 0.9449, acc: 0.9168, precision: 0.9604, recall: 0.9356, f1: 0.9479, edges-ner-ontonotes_loss: 0.0182
09/16 06:40:10 AM: Evaluate: task edges-ner-ontonotes, batch 133 (157): mcc: 0.9371, acc: 0.9095, precision: 0.9569, recall: 0.9244, f1: 0.9404, edges-ner-ontonotes_loss: 0.0211
09/16 06:40:10 AM: Update 10223: task edges-ner-ontonotes, batch 223 (10223): mcc: 0.9461, acc: 0.9184, precision: 0.9608, recall: 0.9374, f1: 0.9490, edges-ner-ontonotes_loss: 0.0180
09/16 06:40:14 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:40:15 AM: Best result seen so far for macro.
09/16 06:40:15 AM: Updating LR scheduler:
09/16 06:40:15 AM: 	Best result seen so far for macro_avg: 0.943
09/16 06:40:15 AM: 	# validation passes without improvement: 0
09/16 06:40:15 AM: edges-ner-ontonotes_loss: training: 0.024090 validation: 0.020174
09/16 06:40:15 AM: macro_avg: validation: 0.943297
09/16 06:40:15 AM: micro_avg: validation: 0.000000
09/16 06:40:15 AM: edges-ner-ontonotes_mcc: training: 0.930275 validation: 0.940154
09/16 06:40:15 AM: edges-ner-ontonotes_acc: training: 0.898378 validation: 0.913709
09/16 06:40:15 AM: edges-ner-ontonotes_precision: training: 0.949847 validation: 0.958660
09/16 06:40:15 AM: edges-ner-ontonotes_recall: training: 0.918569 validation: 0.928420
09/16 06:40:15 AM: edges-ner-ontonotes_f1: training: 0.933946 validation: 0.943297
09/16 06:40:15 AM: Global learning rate: 0.0001
09/16 06:40:15 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:40:20 AM: Update 11054: task edges-ner-ontonotes, batch 54 (11054): mcc: 0.9151, acc: 0.8792, precision: 0.9418, recall: 0.8980, f1: 0.9194, edges-ner-ontonotes_loss: 0.0277
09/16 06:40:21 AM: Update 10276: task edges-ner-ontonotes, batch 276 (10276): mcc: 0.9463, acc: 0.9191, precision: 0.9608, recall: 0.9378, f1: 0.9491, edges-ner-ontonotes_loss: 0.0178
09/16 06:40:30 AM: Update 11136: task edges-ner-ontonotes, batch 136 (11136): mcc: 0.9154, acc: 0.8783, precision: 0.9402, recall: 0.9003, f1: 0.9198, edges-ner-ontonotes_loss: 0.0272
09/16 06:40:31 AM: Update 10354: task edges-ner-ontonotes, batch 354 (10354): mcc: 0.9446, acc: 0.9170, precision: 0.9592, recall: 0.9363, f1: 0.9476, edges-ner-ontonotes_loss: 0.0180
09/16 06:40:41 AM: Update 10438: task edges-ner-ontonotes, batch 438 (10438): mcc: 0.9446, acc: 0.9171, precision: 0.9589, recall: 0.9365, f1: 0.9476, edges-ner-ontonotes_loss: 0.0179
09/16 06:40:42 AM: Update 11206: task edges-ner-ontonotes, batch 206 (11206): mcc: 0.9150, acc: 0.8785, precision: 0.9387, recall: 0.9008, f1: 0.9194, edges-ner-ontonotes_loss: 0.0276
09/16 06:40:51 AM: Update 10511: task edges-ner-ontonotes, batch 511 (10511): mcc: 0.9443, acc: 0.9166, precision: 0.9587, recall: 0.9362, f1: 0.9473, edges-ner-ontonotes_loss: 0.0182
09/16 06:40:52 AM: Update 11279: task edges-ner-ontonotes, batch 279 (11279): mcc: 0.9194, acc: 0.8845, precision: 0.9418, recall: 0.9061, f1: 0.9236, edges-ner-ontonotes_loss: 0.0263
09/16 06:41:01 AM: Update 10581: task edges-ner-ontonotes, batch 581 (10581): mcc: 0.9442, acc: 0.9165, precision: 0.9586, recall: 0.9361, f1: 0.9472, edges-ner-ontonotes_loss: 0.0183
09/16 06:41:02 AM: Update 11351: task edges-ner-ontonotes, batch 351 (11351): mcc: 0.9222, acc: 0.8882, precision: 0.9438, recall: 0.9094, f1: 0.9263, edges-ner-ontonotes_loss: 0.0255
09/16 06:41:11 AM: Update 10639: task edges-ner-ontonotes, batch 639 (10639): mcc: 0.9416, acc: 0.9128, precision: 0.9572, recall: 0.9325, f1: 0.9447, edges-ner-ontonotes_loss: 0.0194
09/16 06:41:12 AM: Update 11427: task edges-ner-ontonotes, batch 427 (11427): mcc: 0.9233, acc: 0.8899, precision: 0.9445, recall: 0.9107, f1: 0.9273, edges-ner-ontonotes_loss: 0.0250
09/16 06:41:21 AM: Update 10714: task edges-ner-ontonotes, batch 714 (10714): mcc: 0.9376, acc: 0.9078, precision: 0.9546, recall: 0.9276, f1: 0.9409, edges-ner-ontonotes_loss: 0.0209
09/16 06:41:22 AM: Update 11508: task edges-ner-ontonotes, batch 508 (11508): mcc: 0.9250, acc: 0.8922, precision: 0.9453, recall: 0.9132, f1: 0.9290, edges-ner-ontonotes_loss: 0.0246
09/16 06:41:33 AM: Update 11563: task edges-ner-ontonotes, batch 563 (11563): mcc: 0.9273, acc: 0.8948, precision: 0.9471, recall: 0.9156, f1: 0.9311, edges-ner-ontonotes_loss: 0.0240
09/16 06:41:33 AM: Update 10797: task edges-ner-ontonotes, batch 797 (10797): mcc: 0.9351, acc: 0.9046, precision: 0.9532, recall: 0.9243, f1: 0.9385, edges-ner-ontonotes_loss: 0.0222
09/16 06:41:43 AM: Update 10867: task edges-ner-ontonotes, batch 867 (10867): mcc: 0.9329, acc: 0.9020, precision: 0.9515, recall: 0.9218, f1: 0.9364, edges-ner-ontonotes_loss: 0.0231
09/16 06:41:43 AM: Update 11634: task edges-ner-ontonotes, batch 634 (11634): mcc: 0.9297, acc: 0.8979, precision: 0.9488, recall: 0.9185, f1: 0.9334, edges-ner-ontonotes_loss: 0.0233
09/16 06:41:55 AM: Update 11714: task edges-ner-ontonotes, batch 714 (11714): mcc: 0.9318, acc: 0.9005, precision: 0.9501, recall: 0.9212, f1: 0.9354, edges-ner-ontonotes_loss: 0.0226
09/16 06:41:55 AM: Update 10928: task edges-ner-ontonotes, batch 928 (10928): mcc: 0.9313, acc: 0.8997, precision: 0.9505, recall: 0.9198, f1: 0.9349, edges-ner-ontonotes_loss: 0.0237
09/16 06:42:04 AM: ***** Step 11000 / Validation 11 *****
09/16 06:42:04 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:42:04 AM: Validating...
09/16 06:42:05 AM: Evaluate: task edges-ner-ontonotes, batch 7 (157): mcc: 0.8642, acc: 0.8039, precision: 0.8991, recall: 0.8448, f1: 0.8711, edges-ner-ontonotes_loss: 0.0355
09/16 06:42:05 AM: Update 11791: task edges-ner-ontonotes, batch 791 (11791): mcc: 0.9335, acc: 0.9027, precision: 0.9512, recall: 0.9232, f1: 0.9370, edges-ner-ontonotes_loss: 0.0221
09/16 06:42:15 AM: Evaluate: task edges-ner-ontonotes, batch 74 (157): mcc: 0.9225, acc: 0.8912, precision: 0.9449, recall: 0.9088, f1: 0.9265, edges-ner-ontonotes_loss: 0.0259
09/16 06:42:18 AM: Update 11836: task edges-ner-ontonotes, batch 836 (11836): mcc: 0.9344, acc: 0.9039, precision: 0.9520, recall: 0.9242, f1: 0.9379, edges-ner-ontonotes_loss: 0.0217
09/16 06:42:25 AM: Evaluate: task edges-ner-ontonotes, batch 126 (157): mcc: 0.9349, acc: 0.9068, precision: 0.9552, recall: 0.9220, f1: 0.9383, edges-ner-ontonotes_loss: 0.0217
09/16 06:42:29 AM: Update 11896: task edges-ner-ontonotes, batch 896 (11896): mcc: 0.9351, acc: 0.9047, precision: 0.9525, recall: 0.9250, f1: 0.9386, edges-ner-ontonotes_loss: 0.0215
09/16 06:42:30 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:42:30 AM: Best result seen so far for macro.
09/16 06:42:30 AM: Updating LR scheduler:
09/16 06:42:30 AM: 	Best result seen so far for macro_avg: 0.943
09/16 06:42:30 AM: 	# validation passes without improvement: 0
09/16 06:42:30 AM: edges-ner-ontonotes_loss: training: 0.024090 validation: 0.020174
09/16 06:42:30 AM: macro_avg: validation: 0.943297
09/16 06:42:30 AM: micro_avg: validation: 0.000000
09/16 06:42:30 AM: edges-ner-ontonotes_mcc: training: 0.930275 validation: 0.940154
09/16 06:42:30 AM: edges-ner-ontonotes_acc: training: 0.898378 validation: 0.913709
09/16 06:42:30 AM: edges-ner-ontonotes_precision: training: 0.949847 validation: 0.958660
09/16 06:42:30 AM: edges-ner-ontonotes_recall: training: 0.918569 validation: 0.928420
09/16 06:42:30 AM: edges-ner-ontonotes_f1: training: 0.933946 validation: 0.943297
09/16 06:42:30 AM: Global learning rate: 0.0001
09/16 06:42:30 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:42:35 AM: Update 11040: task edges-ner-ontonotes, batch 40 (11040): mcc: 0.9160, acc: 0.8799, precision: 0.9432, recall: 0.8984, f1: 0.9203, edges-ner-ontonotes_loss: 0.0283
09/16 06:42:41 AM: Update 11973: task edges-ner-ontonotes, batch 973 (11973): mcc: 0.9359, acc: 0.9057, precision: 0.9530, recall: 0.9260, f1: 0.9393, edges-ner-ontonotes_loss: 0.0213
09/16 06:42:44 AM: ***** Step 12000 / Validation 12 *****
09/16 06:42:44 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:42:44 AM: Validating...
09/16 06:42:45 AM: Update 11119: task edges-ner-ontonotes, batch 119 (11119): mcc: 0.9151, acc: 0.8780, precision: 0.9400, recall: 0.8999, f1: 0.9195, edges-ner-ontonotes_loss: 0.0272
09/16 06:42:51 AM: Evaluate: task edges-ner-ontonotes, batch 47 (157): mcc: 0.9094, acc: 0.8805, precision: 0.9343, recall: 0.8949, f1: 0.9141, edges-ner-ontonotes_loss: 0.0304
09/16 06:42:56 AM: Update 11182: task edges-ner-ontonotes, batch 182 (11182): mcc: 0.9160, acc: 0.8800, precision: 0.9404, recall: 0.9010, f1: 0.9203, edges-ner-ontonotes_loss: 0.0274
09/16 06:43:01 AM: Evaluate: task edges-ner-ontonotes, batch 105 (157): mcc: 0.9305, acc: 0.9042, precision: 0.9513, recall: 0.9176, f1: 0.9342, edges-ner-ontonotes_loss: 0.0240
09/16 06:43:06 AM: Update 11225: task edges-ner-ontonotes, batch 225 (11225): mcc: 0.9155, acc: 0.8792, precision: 0.9395, recall: 0.9011, f1: 0.9199, edges-ner-ontonotes_loss: 0.0273
09/16 06:43:11 AM: Evaluate: task edges-ner-ontonotes, batch 156 (157): mcc: 0.9418, acc: 0.9183, precision: 0.9582, recall: 0.9319, f1: 0.9449, edges-ner-ontonotes_loss: 0.0202
09/16 06:43:11 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:43:11 AM: Best result seen so far for macro.
09/16 06:43:11 AM: Updating LR scheduler:
09/16 06:43:11 AM: 	Best result seen so far for macro_avg: 0.945
09/16 06:43:11 AM: 	# validation passes without improvement: 0
09/16 06:43:11 AM: edges-ner-ontonotes_loss: training: 0.021232 validation: 0.020097
09/16 06:43:11 AM: macro_avg: validation: 0.944876
09/16 06:43:11 AM: micro_avg: validation: 0.000000
09/16 06:43:11 AM: edges-ner-ontonotes_mcc: training: 0.936116 validation: 0.941783
09/16 06:43:11 AM: edges-ner-ontonotes_acc: training: 0.905969 validation: 0.918335
09/16 06:43:11 AM: edges-ner-ontonotes_precision: training: 0.953135 validation: 0.958210
09/16 06:43:11 AM: edges-ner-ontonotes_recall: training: 0.926276 validation: 0.931908
09/16 06:43:11 AM: edges-ner-ontonotes_f1: training: 0.939514 validation: 0.944876
09/16 06:43:11 AM: Global learning rate: 0.0001
09/16 06:43:11 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:43:16 AM: Update 11291: task edges-ner-ontonotes, batch 291 (11291): mcc: 0.9206, acc: 0.8860, precision: 0.9427, recall: 0.9075, f1: 0.9248, edges-ner-ontonotes_loss: 0.0260
09/16 06:43:21 AM: Update 12073: task edges-ner-ontonotes, batch 73 (12073): mcc: 0.9460, acc: 0.9193, precision: 0.9586, recall: 0.9395, f1: 0.9489, edges-ner-ontonotes_loss: 0.0177
09/16 06:43:26 AM: Update 11360: task edges-ner-ontonotes, batch 360 (11360): mcc: 0.9224, acc: 0.8883, precision: 0.9440, recall: 0.9095, f1: 0.9264, edges-ner-ontonotes_loss: 0.0254
09/16 06:43:33 AM: Update 12145: task edges-ner-ontonotes, batch 145 (12145): mcc: 0.9475, acc: 0.9205, precision: 0.9604, recall: 0.9405, f1: 0.9504, edges-ner-ontonotes_loss: 0.0178
09/16 06:43:37 AM: Update 11439: task edges-ner-ontonotes, batch 439 (11439): mcc: 0.9234, acc: 0.8901, precision: 0.9444, recall: 0.9110, f1: 0.9274, edges-ner-ontonotes_loss: 0.0249
09/16 06:43:43 AM: Update 12225: task edges-ner-ontonotes, batch 225 (12225): mcc: 0.9331, acc: 0.9022, precision: 0.9512, recall: 0.9225, f1: 0.9367, edges-ner-ontonotes_loss: 0.0236
09/16 06:43:50 AM: Update 11519: task edges-ner-ontonotes, batch 519 (11519): mcc: 0.9252, acc: 0.8924, precision: 0.9455, recall: 0.9133, f1: 0.9291, edges-ner-ontonotes_loss: 0.0245
09/16 06:43:53 AM: Update 12302: task edges-ner-ontonotes, batch 302 (12302): mcc: 0.9275, acc: 0.8953, precision: 0.9474, recall: 0.9158, f1: 0.9313, edges-ner-ontonotes_loss: 0.0259
09/16 06:44:00 AM: Update 11589: task edges-ner-ontonotes, batch 589 (11589): mcc: 0.9286, acc: 0.8965, precision: 0.9480, recall: 0.9172, f1: 0.9323, edges-ner-ontonotes_loss: 0.0236
09/16 06:44:03 AM: Update 12386: task edges-ner-ontonotes, batch 386 (12386): mcc: 0.9238, acc: 0.8905, precision: 0.9452, recall: 0.9110, f1: 0.9278, edges-ner-ontonotes_loss: 0.0275
09/16 06:44:11 AM: Update 11660: task edges-ner-ontonotes, batch 660 (11660): mcc: 0.9304, acc: 0.8988, precision: 0.9491, recall: 0.9196, f1: 0.9341, edges-ner-ontonotes_loss: 0.0231
09/16 06:44:15 AM: Update 12449: task edges-ner-ontonotes, batch 449 (12449): mcc: 0.9212, acc: 0.8876, precision: 0.9430, recall: 0.9084, f1: 0.9253, edges-ner-ontonotes_loss: 0.0279
09/16 06:44:21 AM: Update 11751: task edges-ner-ontonotes, batch 751 (11751): mcc: 0.9325, acc: 0.9015, precision: 0.9505, recall: 0.9221, f1: 0.9361, edges-ner-ontonotes_loss: 0.0223
09/16 06:44:27 AM: Update 12542: task edges-ner-ontonotes, batch 542 (12542): mcc: 0.9201, acc: 0.8858, precision: 0.9421, recall: 0.9071, f1: 0.9243, edges-ner-ontonotes_loss: 0.0279
09/16 06:44:34 AM: Update 11831: task edges-ner-ontonotes, batch 831 (11831): mcc: 0.9343, acc: 0.9037, precision: 0.9518, recall: 0.9241, f1: 0.9378, edges-ner-ontonotes_loss: 0.0218
09/16 06:44:38 AM: Update 12642: task edges-ner-ontonotes, batch 642 (12642): mcc: 0.9193, acc: 0.8848, precision: 0.9417, recall: 0.9061, f1: 0.9235, edges-ner-ontonotes_loss: 0.0279
09/16 06:44:45 AM: Update 11879: task edges-ner-ontonotes, batch 879 (11879): mcc: 0.9348, acc: 0.9043, precision: 0.9522, recall: 0.9247, f1: 0.9383, edges-ner-ontonotes_loss: 0.0216
09/16 06:44:48 AM: Update 12726: task edges-ner-ontonotes, batch 726 (12726): mcc: 0.9192, acc: 0.8849, precision: 0.9415, recall: 0.9059, f1: 0.9234, edges-ner-ontonotes_loss: 0.0279
09/16 06:44:55 AM: Update 11964: task edges-ner-ontonotes, batch 964 (11964): mcc: 0.9358, acc: 0.9057, precision: 0.9529, recall: 0.9260, f1: 0.9393, edges-ner-ontonotes_loss: 0.0213
09/16 06:44:58 AM: Update 12781: task edges-ner-ontonotes, batch 781 (12781): mcc: 0.9193, acc: 0.8848, precision: 0.9414, recall: 0.9064, f1: 0.9236, edges-ner-ontonotes_loss: 0.0278
09/16 06:45:00 AM: ***** Step 12000 / Validation 12 *****
09/16 06:45:00 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:45:00 AM: Validating...
09/16 06:45:05 AM: Evaluate: task edges-ner-ontonotes, batch 35 (157): mcc: 0.9025, acc: 0.8709, precision: 0.9297, recall: 0.8863, f1: 0.9075, edges-ner-ontonotes_loss: 0.0322
09/16 06:45:08 AM: Update 12842: task edges-ner-ontonotes, batch 842 (12842): mcc: 0.9203, acc: 0.8859, precision: 0.9421, recall: 0.9075, f1: 0.9244, edges-ner-ontonotes_loss: 0.0273
09/16 06:45:15 AM: Evaluate: task edges-ner-ontonotes, batch 92 (157): mcc: 0.9298, acc: 0.9020, precision: 0.9526, recall: 0.9150, f1: 0.9334, edges-ner-ontonotes_loss: 0.0248
09/16 06:45:19 AM: Update 12895: task edges-ner-ontonotes, batch 895 (12895): mcc: 0.9209, acc: 0.8868, precision: 0.9423, recall: 0.9083, f1: 0.9250, edges-ner-ontonotes_loss: 0.0271
09/16 06:45:25 AM: Evaluate: task edges-ner-ontonotes, batch 140 (157): mcc: 0.9407, acc: 0.9173, precision: 0.9581, recall: 0.9300, f1: 0.9438, edges-ner-ontonotes_loss: 0.0208
09/16 06:45:28 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:45:28 AM: Best result seen so far for macro.
09/16 06:45:28 AM: Updating LR scheduler:
09/16 06:45:28 AM: 	Best result seen so far for macro_avg: 0.945
09/16 06:45:28 AM: 	# validation passes without improvement: 0
09/16 06:45:28 AM: edges-ner-ontonotes_loss: training: 0.021232 validation: 0.020097
09/16 06:45:28 AM: macro_avg: validation: 0.944876
09/16 06:45:28 AM: micro_avg: validation: 0.000000
09/16 06:45:28 AM: edges-ner-ontonotes_mcc: training: 0.936116 validation: 0.941783
09/16 06:45:28 AM: edges-ner-ontonotes_acc: training: 0.905969 validation: 0.918335
09/16 06:45:28 AM: edges-ner-ontonotes_precision: training: 0.953135 validation: 0.958210
09/16 06:45:28 AM: edges-ner-ontonotes_recall: training: 0.926276 validation: 0.931908
09/16 06:45:28 AM: edges-ner-ontonotes_f1: training: 0.939514 validation: 0.944876
09/16 06:45:28 AM: Global learning rate: 0.0001
09/16 06:45:28 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:45:29 AM: Update 12954: task edges-ner-ontonotes, batch 954 (12954): mcc: 0.9218, acc: 0.8880, precision: 0.9432, recall: 0.9093, f1: 0.9259, edges-ner-ontonotes_loss: 0.0268
09/16 06:45:34 AM: ***** Step 13000 / Validation 13 *****
09/16 06:45:34 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:45:34 AM: Validating...
09/16 06:45:35 AM: Update 12029: task edges-ner-ontonotes, batch 29 (12029): mcc: 0.9361, acc: 0.9070, precision: 0.9503, recall: 0.9290, f1: 0.9395, edges-ner-ontonotes_loss: 0.0198
09/16 06:45:39 AM: Evaluate: task edges-ner-ontonotes, batch 34 (157): mcc: 0.9041, acc: 0.8699, precision: 0.9292, recall: 0.8897, f1: 0.9090, edges-ner-ontonotes_loss: 0.0296
09/16 06:45:45 AM: Update 12084: task edges-ner-ontonotes, batch 84 (12084): mcc: 0.9462, acc: 0.9198, precision: 0.9578, recall: 0.9405, f1: 0.9491, edges-ner-ontonotes_loss: 0.0178
09/16 06:45:49 AM: Evaluate: task edges-ner-ontonotes, batch 88 (157): mcc: 0.9316, acc: 0.9033, precision: 0.9543, recall: 0.9168, f1: 0.9352, edges-ner-ontonotes_loss: 0.0232
09/16 06:45:55 AM: Update 12139: task edges-ner-ontonotes, batch 139 (12139): mcc: 0.9476, acc: 0.9207, precision: 0.9601, recall: 0.9409, f1: 0.9504, edges-ner-ontonotes_loss: 0.0177
09/16 06:45:59 AM: Evaluate: task edges-ner-ontonotes, batch 142 (157): mcc: 0.9402, acc: 0.9150, precision: 0.9599, recall: 0.9273, f1: 0.9433, edges-ner-ontonotes_loss: 0.0200
09/16 06:46:02 AM: Updating LR scheduler:
09/16 06:46:02 AM: 	Best result seen so far for macro_avg: 0.945
09/16 06:46:02 AM: 	# validation passes without improvement: 1
09/16 06:46:02 AM: edges-ner-ontonotes_loss: training: 0.026504 validation: 0.019615
09/16 06:46:02 AM: macro_avg: validation: 0.944151
09/16 06:46:02 AM: micro_avg: validation: 0.000000
09/16 06:46:02 AM: edges-ner-ontonotes_mcc: training: 0.922512 validation: 0.941069
09/16 06:46:02 AM: edges-ner-ontonotes_acc: training: 0.888794 validation: 0.916136
09/16 06:46:02 AM: edges-ner-ontonotes_precision: training: 0.943537 validation: 0.960100
09/16 06:46:02 AM: edges-ner-ontonotes_recall: training: 0.910226 validation: 0.928723
09/16 06:46:02 AM: edges-ner-ontonotes_f1: training: 0.926582 validation: 0.944151
09/16 06:46:02 AM: Global learning rate: 0.0001
09/16 06:46:02 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:46:05 AM: Update 12191: task edges-ner-ontonotes, batch 191 (12191): mcc: 0.9368, acc: 0.9067, precision: 0.9536, recall: 0.9271, f1: 0.9402, edges-ner-ontonotes_loss: 0.0220
09/16 06:46:09 AM: Update 13059: task edges-ner-ontonotes, batch 59 (13059): mcc: 0.9306, acc: 0.8989, precision: 0.9479, recall: 0.9212, f1: 0.9343, edges-ner-ontonotes_loss: 0.0226
09/16 06:46:16 AM: Update 12279: task edges-ner-ontonotes, batch 279 (12279): mcc: 0.9290, acc: 0.8973, precision: 0.9483, recall: 0.9177, f1: 0.9328, edges-ner-ontonotes_loss: 0.0255
09/16 06:46:19 AM: Update 13113: task edges-ner-ontonotes, batch 113 (13113): mcc: 0.9358, acc: 0.9053, precision: 0.9519, recall: 0.9270, f1: 0.9393, edges-ner-ontonotes_loss: 0.0210
09/16 06:46:26 AM: Update 12360: task edges-ner-ontonotes, batch 360 (12360): mcc: 0.9247, acc: 0.8918, precision: 0.9457, recall: 0.9121, f1: 0.9286, edges-ner-ontonotes_loss: 0.0273
09/16 06:46:31 AM: Update 13192: task edges-ner-ontonotes, batch 192 (13192): mcc: 0.9417, acc: 0.9128, precision: 0.9559, recall: 0.9340, f1: 0.9448, edges-ner-ontonotes_loss: 0.0192
09/16 06:46:37 AM: Update 12437: task edges-ner-ontonotes, batch 437 (12437): mcc: 0.9217, acc: 0.8881, precision: 0.9435, recall: 0.9088, f1: 0.9258, edges-ner-ontonotes_loss: 0.0278
09/16 06:46:42 AM: Update 13277: task edges-ner-ontonotes, batch 277 (13277): mcc: 0.9431, acc: 0.9151, precision: 0.9567, recall: 0.9358, f1: 0.9461, edges-ner-ontonotes_loss: 0.0188
09/16 06:46:49 AM: Update 12490: task edges-ner-ontonotes, batch 490 (12490): mcc: 0.9202, acc: 0.8862, precision: 0.9422, recall: 0.9071, f1: 0.9244, edges-ner-ontonotes_loss: 0.0281
09/16 06:46:52 AM: Update 13356: task edges-ner-ontonotes, batch 356 (13356): mcc: 0.9441, acc: 0.9164, precision: 0.9577, recall: 0.9367, f1: 0.9471, edges-ner-ontonotes_loss: 0.0183
09/16 06:46:59 AM: Update 12587: task edges-ner-ontonotes, batch 587 (12587): mcc: 0.9194, acc: 0.8849, precision: 0.9416, recall: 0.9063, f1: 0.9236, edges-ner-ontonotes_loss: 0.0279
09/16 06:47:02 AM: Update 13408: task edges-ner-ontonotes, batch 408 (13408): mcc: 0.9448, acc: 0.9174, precision: 0.9585, recall: 0.9373, f1: 0.9478, edges-ner-ontonotes_loss: 0.0182
09/16 06:47:09 AM: Update 12671: task edges-ner-ontonotes, batch 671 (12671): mcc: 0.9192, acc: 0.8847, precision: 0.9415, recall: 0.9059, f1: 0.9234, edges-ner-ontonotes_loss: 0.0279
09/16 06:47:12 AM: Update 13489: task edges-ner-ontonotes, batch 489 (13489): mcc: 0.9441, acc: 0.9167, precision: 0.9580, recall: 0.9365, f1: 0.9471, edges-ner-ontonotes_loss: 0.0183
09/16 06:47:19 AM: Update 12753: task edges-ner-ontonotes, batch 753 (12753): mcc: 0.9191, acc: 0.8847, precision: 0.9415, recall: 0.9059, f1: 0.9234, edges-ner-ontonotes_loss: 0.0279
09/16 06:47:22 AM: Update 13573: task edges-ner-ontonotes, batch 573 (13573): mcc: 0.9443, acc: 0.9168, precision: 0.9582, recall: 0.9367, f1: 0.9473, edges-ner-ontonotes_loss: 0.0181
09/16 06:47:29 AM: Update 12810: task edges-ner-ontonotes, batch 810 (12810): mcc: 0.9196, acc: 0.8851, precision: 0.9415, recall: 0.9067, f1: 0.9238, edges-ner-ontonotes_loss: 0.0276
09/16 06:47:34 AM: Update 13645: task edges-ner-ontonotes, batch 645 (13645): mcc: 0.9445, acc: 0.9170, precision: 0.9585, recall: 0.9368, f1: 0.9475, edges-ner-ontonotes_loss: 0.0180
09/16 06:47:39 AM: Update 12888: task edges-ner-ontonotes, batch 888 (12888): mcc: 0.9209, acc: 0.8869, precision: 0.9424, recall: 0.9083, f1: 0.9251, edges-ner-ontonotes_loss: 0.0271
09/16 06:47:45 AM: Update 13702: task edges-ner-ontonotes, batch 702 (13702): mcc: 0.9443, acc: 0.9166, precision: 0.9585, recall: 0.9363, f1: 0.9473, edges-ner-ontonotes_loss: 0.0180
09/16 06:47:49 AM: Update 12968: task edges-ner-ontonotes, batch 968 (12968): mcc: 0.9222, acc: 0.8884, precision: 0.9435, recall: 0.9097, f1: 0.9263, edges-ner-ontonotes_loss: 0.0267
09/16 06:47:53 AM: ***** Step 13000 / Validation 13 *****
09/16 06:47:53 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:47:53 AM: Validating...
09/16 06:47:57 AM: Update 13776: task edges-ner-ontonotes, batch 776 (13776): mcc: 0.9412, acc: 0.9126, precision: 0.9565, recall: 0.9325, f1: 0.9444, edges-ner-ontonotes_loss: 0.0195
09/16 06:47:59 AM: Evaluate: task edges-ner-ontonotes, batch 41 (157): mcc: 0.9099, acc: 0.8784, precision: 0.9315, recall: 0.8983, f1: 0.9146, edges-ner-ontonotes_loss: 0.0282
09/16 06:48:08 AM: Update 13831: task edges-ner-ontonotes, batch 831 (13831): mcc: 0.9396, acc: 0.9106, precision: 0.9557, recall: 0.9303, f1: 0.9428, edges-ner-ontonotes_loss: 0.0204
09/16 06:48:09 AM: Evaluate: task edges-ner-ontonotes, batch 95 (157): mcc: 0.9327, acc: 0.9048, precision: 0.9557, recall: 0.9175, f1: 0.9362, edges-ner-ontonotes_loss: 0.0228
09/16 06:48:18 AM: Update 13888: task edges-ner-ontonotes, batch 888 (13888): mcc: 0.9379, acc: 0.9082, precision: 0.9546, recall: 0.9281, f1: 0.9412, edges-ner-ontonotes_loss: 0.0211
09/16 06:48:19 AM: Evaluate: task edges-ner-ontonotes, batch 145 (157): mcc: 0.9401, acc: 0.9148, precision: 0.9598, recall: 0.9272, f1: 0.9432, edges-ner-ontonotes_loss: 0.0200
09/16 06:48:22 AM: Updating LR scheduler:
09/16 06:48:22 AM: 	Best result seen so far for macro_avg: 0.945
09/16 06:48:22 AM: 	# validation passes without improvement: 1
09/16 06:48:22 AM: edges-ner-ontonotes_loss: training: 0.026504 validation: 0.019615
09/16 06:48:22 AM: macro_avg: validation: 0.944151
09/16 06:48:22 AM: micro_avg: validation: 0.000000
09/16 06:48:22 AM: edges-ner-ontonotes_mcc: training: 0.922512 validation: 0.941069
09/16 06:48:22 AM: edges-ner-ontonotes_acc: training: 0.888794 validation: 0.916136
09/16 06:48:22 AM: edges-ner-ontonotes_precision: training: 0.943537 validation: 0.960100
09/16 06:48:22 AM: edges-ner-ontonotes_recall: training: 0.910226 validation: 0.928723
09/16 06:48:22 AM: edges-ner-ontonotes_f1: training: 0.926582 validation: 0.944151
09/16 06:48:22 AM: Global learning rate: 0.0001
09/16 06:48:22 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:48:28 AM: Update 13966: task edges-ner-ontonotes, batch 966 (13966): mcc: 0.9355, acc: 0.9052, precision: 0.9530, recall: 0.9253, f1: 0.9389, edges-ner-ontonotes_loss: 0.0221
09/16 06:48:29 AM: Update 13037: task edges-ner-ontonotes, batch 37 (13037): mcc: 0.9320, acc: 0.9021, precision: 0.9488, recall: 0.9229, f1: 0.9357, edges-ner-ontonotes_loss: 0.0231
09/16 06:48:32 AM: ***** Step 14000 / Validation 14 *****
09/16 06:48:32 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:48:32 AM: Validating...
09/16 06:48:38 AM: Evaluate: task edges-ner-ontonotes, batch 46 (157): mcc: 0.9120, acc: 0.8840, precision: 0.9317, recall: 0.9020, f1: 0.9167, edges-ner-ontonotes_loss: 0.0287
09/16 06:48:39 AM: Update 13081: task edges-ner-ontonotes, batch 81 (13081): mcc: 0.9302, acc: 0.8978, precision: 0.9482, recall: 0.9202, f1: 0.9339, edges-ner-ontonotes_loss: 0.0227
09/16 06:48:48 AM: Evaluate: task edges-ner-ontonotes, batch 100 (157): mcc: 0.9258, acc: 0.8961, precision: 0.9495, recall: 0.9105, f1: 0.9296, edges-ner-ontonotes_loss: 0.0245
09/16 06:48:50 AM: Update 13138: task edges-ner-ontonotes, batch 138 (13138): mcc: 0.9396, acc: 0.9106, precision: 0.9540, recall: 0.9319, f1: 0.9428, edges-ner-ontonotes_loss: 0.0201
09/16 06:48:58 AM: Evaluate: task edges-ner-ontonotes, batch 151 (157): mcc: 0.9383, acc: 0.9123, precision: 0.9586, recall: 0.9250, f1: 0.9415, edges-ner-ontonotes_loss: 0.0207
09/16 06:48:59 AM: Updating LR scheduler:
09/16 06:48:59 AM: 	Best result seen so far for macro_avg: 0.945
09/16 06:48:59 AM: 	# validation passes without improvement: 2
09/16 06:48:59 AM: edges-ner-ontonotes_loss: training: 0.022458 validation: 0.020473
09/16 06:48:59 AM: macro_avg: validation: 0.942147
09/16 06:48:59 AM: micro_avg: validation: 0.000000
09/16 06:48:59 AM: edges-ner-ontonotes_mcc: training: 0.934735 validation: 0.938963
09/16 06:48:59 AM: edges-ner-ontonotes_acc: training: 0.904282 validation: 0.913330
09/16 06:48:59 AM: edges-ner-ontonotes_precision: training: 0.952569 validation: 0.958713
09/16 06:48:59 AM: edges-ner-ontonotes_recall: training: 0.924244 validation: 0.926145
09/16 06:48:59 AM: edges-ner-ontonotes_f1: training: 0.938193 validation: 0.942147
09/16 06:48:59 AM: Global learning rate: 0.0001
09/16 06:48:59 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:49:00 AM: Update 13196: task edges-ner-ontonotes, batch 196 (13196): mcc: 0.9416, acc: 0.9126, precision: 0.9558, recall: 0.9339, f1: 0.9447, edges-ner-ontonotes_loss: 0.0192
09/16 06:49:08 AM: Update 14048: task edges-ner-ontonotes, batch 48 (14048): mcc: 0.9168, acc: 0.8805, precision: 0.9399, recall: 0.9030, f1: 0.9211, edges-ner-ontonotes_loss: 0.0279
09/16 06:49:10 AM: Update 13282: task edges-ner-ontonotes, batch 282 (13282): mcc: 0.9430, acc: 0.9150, precision: 0.9568, recall: 0.9356, f1: 0.9461, edges-ner-ontonotes_loss: 0.0188
09/16 06:49:18 AM: Update 14128: task edges-ner-ontonotes, batch 128 (14128): mcc: 0.9147, acc: 0.8784, precision: 0.9386, recall: 0.9004, f1: 0.9191, edges-ner-ontonotes_loss: 0.0278
09/16 06:49:20 AM: Update 13355: task edges-ner-ontonotes, batch 355 (13355): mcc: 0.9440, acc: 0.9162, precision: 0.9576, recall: 0.9366, f1: 0.9470, edges-ner-ontonotes_loss: 0.0184
09/16 06:49:28 AM: Update 14217: task edges-ner-ontonotes, batch 217 (14217): mcc: 0.9178, acc: 0.8819, precision: 0.9409, recall: 0.9040, f1: 0.9221, edges-ner-ontonotes_loss: 0.0270
09/16 06:49:30 AM: Update 13419: task edges-ner-ontonotes, batch 419 (13419): mcc: 0.9447, acc: 0.9174, precision: 0.9584, recall: 0.9372, f1: 0.9477, edges-ner-ontonotes_loss: 0.0183
09/16 06:49:38 AM: Update 14309: task edges-ner-ontonotes, batch 309 (14309): mcc: 0.9170, acc: 0.8813, precision: 0.9396, recall: 0.9037, f1: 0.9213, edges-ner-ontonotes_loss: 0.0273
09/16 06:49:43 AM: Update 13503: task edges-ner-ontonotes, batch 503 (13503): mcc: 0.9441, acc: 0.9167, precision: 0.9580, recall: 0.9365, f1: 0.9471, edges-ner-ontonotes_loss: 0.0183
09/16 06:49:48 AM: Update 14368: task edges-ner-ontonotes, batch 368 (14368): mcc: 0.9179, acc: 0.8828, precision: 0.9396, recall: 0.9054, f1: 0.9222, edges-ner-ontonotes_loss: 0.0268
09/16 06:49:54 AM: Update 13585: task edges-ner-ontonotes, batch 585 (13585): mcc: 0.9443, acc: 0.9169, precision: 0.9582, recall: 0.9368, f1: 0.9473, edges-ner-ontonotes_loss: 0.0181
09/16 06:50:01 AM: Update 14448: task edges-ner-ontonotes, batch 448 (14448): mcc: 0.9210, acc: 0.8870, precision: 0.9423, recall: 0.9086, f1: 0.9252, edges-ner-ontonotes_loss: 0.0261
09/16 06:50:05 AM: Update 13661: task edges-ner-ontonotes, batch 661 (13661): mcc: 0.9445, acc: 0.9170, precision: 0.9586, recall: 0.9367, f1: 0.9475, edges-ner-ontonotes_loss: 0.0180
09/16 06:50:12 AM: Update 14524: task edges-ner-ontonotes, batch 524 (14524): mcc: 0.9224, acc: 0.8889, precision: 0.9430, recall: 0.9106, f1: 0.9265, edges-ner-ontonotes_loss: 0.0255
09/16 06:50:15 AM: Update 13710: task edges-ner-ontonotes, batch 710 (13710): mcc: 0.9440, acc: 0.9162, precision: 0.9583, recall: 0.9359, f1: 0.9470, edges-ner-ontonotes_loss: 0.0182
09/16 06:50:22 AM: Update 14603: task edges-ner-ontonotes, batch 603 (14603): mcc: 0.9256, acc: 0.8930, precision: 0.9458, recall: 0.9139, f1: 0.9295, edges-ner-ontonotes_loss: 0.0246
09/16 06:50:25 AM: Update 13784: task edges-ner-ontonotes, batch 784 (13784): mcc: 0.9411, acc: 0.9123, precision: 0.9564, recall: 0.9323, f1: 0.9442, edges-ner-ontonotes_loss: 0.0196
09/16 06:50:32 AM: Update 14655: task edges-ner-ontonotes, batch 655 (14655): mcc: 0.9264, acc: 0.8942, precision: 0.9462, recall: 0.9150, f1: 0.9303, edges-ner-ontonotes_loss: 0.0243
09/16 06:50:35 AM: Update 13868: task edges-ner-ontonotes, batch 868 (13868): mcc: 0.9384, acc: 0.9090, precision: 0.9549, recall: 0.9289, f1: 0.9417, edges-ner-ontonotes_loss: 0.0208
09/16 06:50:42 AM: Update 14724: task edges-ner-ontonotes, batch 724 (14724): mcc: 0.9291, acc: 0.8975, precision: 0.9481, recall: 0.9181, f1: 0.9329, edges-ner-ontonotes_loss: 0.0236
09/16 06:50:45 AM: Update 13938: task edges-ner-ontonotes, batch 938 (13938): mcc: 0.9362, acc: 0.9062, precision: 0.9533, recall: 0.9262, f1: 0.9396, edges-ner-ontonotes_loss: 0.0218
09/16 06:50:52 AM: Update 14797: task edges-ner-ontonotes, batch 797 (14797): mcc: 0.9313, acc: 0.9004, precision: 0.9497, recall: 0.9207, f1: 0.9349, edges-ner-ontonotes_loss: 0.0230
09/16 06:50:54 AM: ***** Step 14000 / Validation 14 *****
09/16 06:50:54 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:50:54 AM: Validating...
09/16 06:50:55 AM: Evaluate: task edges-ner-ontonotes, batch 11 (157): mcc: 0.8552, acc: 0.8077, precision: 0.8889, recall: 0.8379, f1: 0.8626, edges-ner-ontonotes_loss: 0.0367
09/16 06:51:02 AM: Update 14857: task edges-ner-ontonotes, batch 857 (14857): mcc: 0.9327, acc: 0.9022, precision: 0.9505, recall: 0.9225, f1: 0.9363, edges-ner-ontonotes_loss: 0.0225
09/16 06:51:06 AM: Evaluate: task edges-ner-ontonotes, batch 71 (157): mcc: 0.9202, acc: 0.8893, precision: 0.9442, recall: 0.9052, f1: 0.9243, edges-ner-ontonotes_loss: 0.0267
09/16 06:51:13 AM: Update 14913: task edges-ner-ontonotes, batch 913 (14913): mcc: 0.9342, acc: 0.9042, precision: 0.9517, recall: 0.9241, f1: 0.9377, edges-ner-ontonotes_loss: 0.0221
09/16 06:51:16 AM: Evaluate: task edges-ner-ontonotes, batch 122 (157): mcc: 0.9333, acc: 0.9060, precision: 0.9547, recall: 0.9195, f1: 0.9368, edges-ner-ontonotes_loss: 0.0225
09/16 06:51:21 AM: Updating LR scheduler:
09/16 06:51:21 AM: 	Best result seen so far for macro_avg: 0.945
09/16 06:51:21 AM: 	# validation passes without improvement: 2
09/16 06:51:21 AM: edges-ner-ontonotes_loss: training: 0.022458 validation: 0.020473
09/16 06:51:21 AM: macro_avg: validation: 0.942147
09/16 06:51:21 AM: micro_avg: validation: 0.000000
09/16 06:51:21 AM: edges-ner-ontonotes_mcc: training: 0.934735 validation: 0.938963
09/16 06:51:21 AM: edges-ner-ontonotes_acc: training: 0.904282 validation: 0.913330
09/16 06:51:21 AM: edges-ner-ontonotes_precision: training: 0.952569 validation: 0.958713
09/16 06:51:21 AM: edges-ner-ontonotes_recall: training: 0.924244 validation: 0.926145
09/16 06:51:21 AM: edges-ner-ontonotes_f1: training: 0.938193 validation: 0.942147
09/16 06:51:21 AM: Global learning rate: 0.0001
09/16 06:51:21 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:51:24 AM: Update 14976: task edges-ner-ontonotes, batch 976 (14976): mcc: 0.9347, acc: 0.9049, precision: 0.9519, recall: 0.9248, f1: 0.9382, edges-ner-ontonotes_loss: 0.0218
09/16 06:51:26 AM: Update 14017: task edges-ner-ontonotes, batch 17 (14017): mcc: 0.9138, acc: 0.8763, precision: 0.9399, recall: 0.8975, f1: 0.9182, edges-ner-ontonotes_loss: 0.0270
09/16 06:51:29 AM: ***** Step 15000 / Validation 15 *****
09/16 06:51:29 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:51:29 AM: Validating...
09/16 06:51:36 AM: Evaluate: task edges-ner-ontonotes, batch 42 (157): mcc: 0.9101, acc: 0.8818, precision: 0.9332, recall: 0.8971, f1: 0.9148, edges-ner-ontonotes_loss: 0.0306
09/16 06:51:36 AM: Update 14092: task edges-ner-ontonotes, batch 92 (14092): mcc: 0.9135, acc: 0.8771, precision: 0.9360, recall: 0.9007, f1: 0.9180, edges-ner-ontonotes_loss: 0.0280
09/16 06:51:46 AM: Evaluate: task edges-ner-ontonotes, batch 99 (157): mcc: 0.9294, acc: 0.9030, precision: 0.9508, recall: 0.9161, f1: 0.9331, edges-ner-ontonotes_loss: 0.0242
09/16 06:51:46 AM: Update 14154: task edges-ner-ontonotes, batch 154 (14154): mcc: 0.9162, acc: 0.8801, precision: 0.9399, recall: 0.9020, f1: 0.9206, edges-ner-ontonotes_loss: 0.0274
09/16 06:51:56 AM: Evaluate: task edges-ner-ontonotes, batch 152 (157): mcc: 0.9424, acc: 0.9190, precision: 0.9588, recall: 0.9324, f1: 0.9454, edges-ner-ontonotes_loss: 0.0200
09/16 06:51:56 AM: Update 14216: task edges-ner-ontonotes, batch 216 (14216): mcc: 0.9178, acc: 0.8818, precision: 0.9410, recall: 0.9039, f1: 0.9221, edges-ner-ontonotes_loss: 0.0270
09/16 06:51:56 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:51:56 AM: Best result seen so far for macro.
09/16 06:51:56 AM: Updating LR scheduler:
09/16 06:51:56 AM: 	Best result seen so far for macro_avg: 0.946
09/16 06:51:56 AM: 	# validation passes without improvement: 0
09/16 06:51:56 AM: edges-ner-ontonotes_loss: training: 0.021768 validation: 0.019740
09/16 06:51:56 AM: macro_avg: validation: 0.946014
09/16 06:51:56 AM: micro_avg: validation: 0.000000
09/16 06:51:56 AM: edges-ner-ontonotes_mcc: training: 0.934912 validation: 0.942979
09/16 06:51:56 AM: edges-ner-ontonotes_acc: training: 0.905136 validation: 0.919851
09/16 06:51:56 AM: edges-ner-ontonotes_precision: training: 0.952049 validation: 0.958947
09/16 06:51:56 AM: edges-ner-ontonotes_recall: training: 0.925087 validation: 0.933424
09/16 06:51:56 AM: edges-ner-ontonotes_f1: training: 0.938374 validation: 0.946014
09/16 06:51:56 AM: Global learning rate: 0.0001
09/16 06:51:56 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:52:06 AM: Update 15073: task edges-ner-ontonotes, batch 73 (15073): mcc: 0.9467, acc: 0.9222, precision: 0.9591, recall: 0.9403, f1: 0.9496, edges-ner-ontonotes_loss: 0.0180
09/16 06:52:06 AM: Update 14297: task edges-ner-ontonotes, batch 297 (14297): mcc: 0.9176, acc: 0.8822, precision: 0.9399, recall: 0.9046, f1: 0.9219, edges-ner-ontonotes_loss: 0.0271
09/16 06:52:16 AM: Update 15153: task edges-ner-ontonotes, batch 153 (15153): mcc: 0.9457, acc: 0.9193, precision: 0.9593, recall: 0.9381, f1: 0.9486, edges-ner-ontonotes_loss: 0.0177
09/16 06:52:16 AM: Update 14348: task edges-ner-ontonotes, batch 348 (14348): mcc: 0.9174, acc: 0.8822, precision: 0.9391, recall: 0.9049, f1: 0.9217, edges-ner-ontonotes_loss: 0.0271
09/16 06:52:26 AM: Update 15227: task edges-ner-ontonotes, batch 227 (15227): mcc: 0.9467, acc: 0.9202, precision: 0.9599, recall: 0.9396, f1: 0.9496, edges-ner-ontonotes_loss: 0.0175
09/16 06:52:26 AM: Update 14425: task edges-ner-ontonotes, batch 425 (14425): mcc: 0.9196, acc: 0.8852, precision: 0.9409, recall: 0.9074, f1: 0.9238, edges-ner-ontonotes_loss: 0.0264
09/16 06:52:39 AM: Update 14510: task edges-ner-ontonotes, batch 510 (14510): mcc: 0.9221, acc: 0.8884, precision: 0.9427, recall: 0.9102, f1: 0.9262, edges-ner-ontonotes_loss: 0.0256
09/16 06:52:39 AM: Update 15276: task edges-ner-ontonotes, batch 276 (15276): mcc: 0.9436, acc: 0.9164, precision: 0.9578, recall: 0.9357, f1: 0.9466, edges-ner-ontonotes_loss: 0.0185
09/16 06:52:49 AM: Update 15346: task edges-ner-ontonotes, batch 346 (15346): mcc: 0.9369, acc: 0.9080, precision: 0.9535, recall: 0.9274, f1: 0.9403, edges-ner-ontonotes_loss: 0.0217
09/16 06:52:49 AM: Update 14586: task edges-ner-ontonotes, batch 586 (14586): mcc: 0.9248, acc: 0.8919, precision: 0.9452, recall: 0.9129, f1: 0.9288, edges-ner-ontonotes_loss: 0.0248
09/16 06:52:59 AM: Update 14639: task edges-ner-ontonotes, batch 639 (14639): mcc: 0.9261, acc: 0.8936, precision: 0.9461, recall: 0.9144, f1: 0.9300, edges-ner-ontonotes_loss: 0.0244
09/16 06:52:59 AM: Update 15430: task edges-ner-ontonotes, batch 430 (15430): mcc: 0.9330, acc: 0.9028, precision: 0.9509, recall: 0.9226, f1: 0.9366, edges-ner-ontonotes_loss: 0.0233
09/16 06:53:09 AM: Update 14711: task edges-ner-ontonotes, batch 711 (14711): mcc: 0.9287, acc: 0.8971, precision: 0.9478, recall: 0.9177, f1: 0.9325, edges-ner-ontonotes_loss: 0.0237
09/16 06:53:09 AM: Update 15507: task edges-ner-ontonotes, batch 507 (15507): mcc: 0.9293, acc: 0.8983, precision: 0.9482, recall: 0.9184, f1: 0.9331, edges-ner-ontonotes_loss: 0.0249
09/16 06:53:19 AM: Update 14787: task edges-ner-ontonotes, batch 787 (14787): mcc: 0.9310, acc: 0.9000, precision: 0.9494, recall: 0.9204, f1: 0.9346, edges-ner-ontonotes_loss: 0.0231
09/16 06:53:19 AM: Update 15569: task edges-ner-ontonotes, batch 569 (15569): mcc: 0.9273, acc: 0.8956, precision: 0.9470, recall: 0.9158, f1: 0.9311, edges-ner-ontonotes_loss: 0.0258
09/16 06:53:29 AM: Update 14865: task edges-ner-ontonotes, batch 865 (14865): mcc: 0.9330, acc: 0.9026, precision: 0.9507, recall: 0.9227, f1: 0.9365, edges-ner-ontonotes_loss: 0.0224
09/16 06:53:29 AM: Update 15648: task edges-ner-ontonotes, batch 648 (15648): mcc: 0.9261, acc: 0.8938, precision: 0.9460, recall: 0.9144, f1: 0.9299, edges-ner-ontonotes_loss: 0.0262
09/16 06:53:39 AM: Update 14943: task edges-ner-ontonotes, batch 943 (14943): mcc: 0.9346, acc: 0.9046, precision: 0.9519, recall: 0.9246, f1: 0.9381, edges-ner-ontonotes_loss: 0.0219
09/16 06:53:40 AM: Update 15731: task edges-ner-ontonotes, batch 731 (15731): mcc: 0.9251, acc: 0.8922, precision: 0.9456, recall: 0.9131, f1: 0.9290, edges-ner-ontonotes_loss: 0.0262
09/16 06:53:48 AM: ***** Step 15000 / Validation 15 *****
09/16 06:53:48 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:53:48 AM: Validating...
09/16 06:53:49 AM: Evaluate: task edges-ner-ontonotes, batch 6 (157): mcc: 0.8379, acc: 0.7850, precision: 0.9008, recall: 0.7950, f1: 0.8446, edges-ner-ontonotes_loss: 0.0444
09/16 06:53:50 AM: Update 15814: task edges-ner-ontonotes, batch 814 (15814): mcc: 0.9249, acc: 0.8918, precision: 0.9454, recall: 0.9129, f1: 0.9288, edges-ner-ontonotes_loss: 0.0262
09/16 06:53:59 AM: Evaluate: task edges-ner-ontonotes, batch 69 (157): mcc: 0.9233, acc: 0.8948, precision: 0.9468, recall: 0.9086, f1: 0.9273, edges-ner-ontonotes_loss: 0.0269
09/16 06:54:02 AM: Update 15874: task edges-ner-ontonotes, batch 874 (15874): mcc: 0.9242, acc: 0.8910, precision: 0.9447, recall: 0.9124, f1: 0.9282, edges-ner-ontonotes_loss: 0.0262
09/16 06:54:09 AM: Evaluate: task edges-ner-ontonotes, batch 120 (157): mcc: 0.9364, acc: 0.9118, precision: 0.9552, recall: 0.9248, f1: 0.9398, edges-ner-ontonotes_loss: 0.0222
09/16 06:54:12 AM: Update 15939: task edges-ner-ontonotes, batch 939 (15939): mcc: 0.9246, acc: 0.8914, precision: 0.9450, recall: 0.9128, f1: 0.9286, edges-ner-ontonotes_loss: 0.0261
09/16 06:54:15 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:54:15 AM: Best result seen so far for macro.
09/16 06:54:15 AM: Updating LR scheduler:
09/16 06:54:15 AM: 	Best result seen so far for macro_avg: 0.946
09/16 06:54:15 AM: 	# validation passes without improvement: 0
09/16 06:54:15 AM: edges-ner-ontonotes_loss: training: 0.021768 validation: 0.019740
09/16 06:54:15 AM: macro_avg: validation: 0.946014
09/16 06:54:15 AM: micro_avg: validation: 0.000000
09/16 06:54:15 AM: edges-ner-ontonotes_mcc: training: 0.934912 validation: 0.942979
09/16 06:54:15 AM: edges-ner-ontonotes_acc: training: 0.905136 validation: 0.919851
09/16 06:54:15 AM: edges-ner-ontonotes_precision: training: 0.952049 validation: 0.958947
09/16 06:54:15 AM: edges-ner-ontonotes_recall: training: 0.925087 validation: 0.933424
09/16 06:54:15 AM: edges-ner-ontonotes_f1: training: 0.938374 validation: 0.946014
09/16 06:54:15 AM: Global learning rate: 0.0001
09/16 06:54:15 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:54:19 AM: Update 15025: task edges-ner-ontonotes, batch 25 (15025): mcc: 0.9453, acc: 0.9214, precision: 0.9571, recall: 0.9397, f1: 0.9483, edges-ner-ontonotes_loss: 0.0181
09/16 06:54:22 AM: ***** Step 16000 / Validation 16 *****
09/16 06:54:22 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:54:22 AM: Validating...
09/16 06:54:23 AM: Evaluate: task edges-ner-ontonotes, batch 7 (157): mcc: 0.8513, acc: 0.7931, precision: 0.8967, recall: 0.8233, f1: 0.8584, edges-ner-ontonotes_loss: 0.0368
09/16 06:54:29 AM: Update 15087: task edges-ner-ontonotes, batch 87 (15087): mcc: 0.9465, acc: 0.9216, precision: 0.9598, recall: 0.9392, f1: 0.9493, edges-ner-ontonotes_loss: 0.0179
09/16 06:54:33 AM: Evaluate: task edges-ner-ontonotes, batch 66 (157): mcc: 0.9249, acc: 0.8972, precision: 0.9463, recall: 0.9121, f1: 0.9288, edges-ner-ontonotes_loss: 0.0253
09/16 06:54:39 AM: Update 15140: task edges-ner-ontonotes, batch 140 (15140): mcc: 0.9455, acc: 0.9190, precision: 0.9588, recall: 0.9383, f1: 0.9484, edges-ner-ontonotes_loss: 0.0177
09/16 06:54:43 AM: Evaluate: task edges-ner-ontonotes, batch 116 (157): mcc: 0.9356, acc: 0.9095, precision: 0.9547, recall: 0.9237, f1: 0.9390, edges-ner-ontonotes_loss: 0.0216
09/16 06:54:49 AM: Update 15196: task edges-ner-ontonotes, batch 196 (15196): mcc: 0.9467, acc: 0.9199, precision: 0.9602, recall: 0.9391, f1: 0.9495, edges-ner-ontonotes_loss: 0.0174
09/16 06:54:50 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:54:50 AM: Best result seen so far for macro.
09/16 06:54:50 AM: Updating LR scheduler:
09/16 06:54:50 AM: 	Best result seen so far for macro_avg: 0.946
09/16 06:54:50 AM: 	# validation passes without improvement: 0
09/16 06:54:50 AM: edges-ner-ontonotes_loss: training: 0.025648 validation: 0.019283
09/16 06:54:50 AM: macro_avg: validation: 0.946243
09/16 06:54:50 AM: micro_avg: validation: 0.000000
09/16 06:54:50 AM: edges-ner-ontonotes_mcc: training: 0.925712 validation: 0.943235
09/16 06:54:50 AM: edges-ner-ontonotes_acc: training: 0.892766 validation: 0.919700
09/16 06:54:50 AM: edges-ner-ontonotes_precision: training: 0.945711 validation: 0.959900
09/16 06:54:50 AM: edges-ner-ontonotes_recall: training: 0.914082 validation: 0.932969
09/16 06:54:50 AM: edges-ner-ontonotes_f1: training: 0.929627 validation: 0.946243
09/16 06:54:50 AM: Global learning rate: 0.0001
09/16 06:54:50 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:54:53 AM: Update 16020: task edges-ner-ontonotes, batch 20 (16020): mcc: 0.9378, acc: 0.9095, precision: 0.9543, recall: 0.9282, f1: 0.9411, edges-ner-ontonotes_loss: 0.0202
09/16 06:55:01 AM: Update 15257: task edges-ner-ontonotes, batch 257 (15257): mcc: 0.9468, acc: 0.9204, precision: 0.9598, recall: 0.9397, f1: 0.9496, edges-ner-ontonotes_loss: 0.0175
09/16 06:55:03 AM: Update 16101: task edges-ner-ontonotes, batch 101 (16101): mcc: 0.9304, acc: 0.9003, precision: 0.9478, recall: 0.9208, f1: 0.9341, edges-ner-ontonotes_loss: 0.0229
09/16 06:55:11 AM: Update 15321: task edges-ner-ontonotes, batch 321 (15321): mcc: 0.9395, acc: 0.9115, precision: 0.9552, recall: 0.9306, f1: 0.9428, edges-ner-ontonotes_loss: 0.0204
09/16 06:55:13 AM: Update 16175: task edges-ner-ontonotes, batch 175 (16175): mcc: 0.9326, acc: 0.9028, precision: 0.9492, recall: 0.9236, f1: 0.9362, edges-ner-ontonotes_loss: 0.0225
09/16 06:55:21 AM: Update 15409: task edges-ner-ontonotes, batch 409 (15409): mcc: 0.9340, acc: 0.9041, precision: 0.9516, recall: 0.9238, f1: 0.9375, edges-ner-ontonotes_loss: 0.0229
09/16 06:55:23 AM: Update 16229: task edges-ner-ontonotes, batch 229 (16229): mcc: 0.9364, acc: 0.9076, precision: 0.9518, recall: 0.9281, f1: 0.9398, edges-ner-ontonotes_loss: 0.0212
09/16 06:55:31 AM: Update 15485: task edges-ner-ontonotes, batch 485 (15485): mcc: 0.9303, acc: 0.8995, precision: 0.9490, recall: 0.9194, f1: 0.9340, edges-ner-ontonotes_loss: 0.0245
09/16 06:55:33 AM: Update 16307: task edges-ner-ontonotes, batch 307 (16307): mcc: 0.9388, acc: 0.9103, precision: 0.9536, recall: 0.9309, f1: 0.9421, edges-ner-ontonotes_loss: 0.0203
09/16 06:55:41 AM: Update 15558: task edges-ner-ontonotes, batch 558 (15558): mcc: 0.9277, acc: 0.8962, precision: 0.9472, recall: 0.9163, f1: 0.9315, edges-ner-ontonotes_loss: 0.0257
09/16 06:55:43 AM: Update 16388: task edges-ner-ontonotes, batch 388 (16388): mcc: 0.9415, acc: 0.9137, precision: 0.9555, recall: 0.9340, f1: 0.9446, edges-ner-ontonotes_loss: 0.0194
09/16 06:55:51 AM: Update 15623: task edges-ner-ontonotes, batch 623 (15623): mcc: 0.9263, acc: 0.8941, precision: 0.9461, recall: 0.9147, f1: 0.9301, edges-ner-ontonotes_loss: 0.0260
09/16 06:55:54 AM: Update 16460: task edges-ner-ontonotes, batch 460 (16460): mcc: 0.9432, acc: 0.9159, precision: 0.9570, recall: 0.9358, f1: 0.9463, edges-ner-ontonotes_loss: 0.0189
09/16 06:56:01 AM: Update 15711: task edges-ner-ontonotes, batch 711 (15711): mcc: 0.9256, acc: 0.8928, precision: 0.9458, recall: 0.9137, f1: 0.9295, edges-ner-ontonotes_loss: 0.0261
09/16 06:56:04 AM: Update 16503: task edges-ner-ontonotes, batch 503 (16503): mcc: 0.9440, acc: 0.9167, precision: 0.9577, recall: 0.9365, f1: 0.9470, edges-ner-ontonotes_loss: 0.0187
09/16 06:56:11 AM: Update 15799: task edges-ner-ontonotes, batch 799 (15799): mcc: 0.9249, acc: 0.8920, precision: 0.9454, recall: 0.9129, f1: 0.9289, edges-ner-ontonotes_loss: 0.0262
09/16 06:56:14 AM: Update 16582: task edges-ner-ontonotes, batch 582 (16582): mcc: 0.9445, acc: 0.9174, precision: 0.9580, recall: 0.9372, f1: 0.9475, edges-ner-ontonotes_loss: 0.0185
09/16 06:56:23 AM: Update 15874: task edges-ner-ontonotes, batch 874 (15874): mcc: 0.9242, acc: 0.8910, precision: 0.9447, recall: 0.9124, f1: 0.9282, edges-ner-ontonotes_loss: 0.0262
09/16 06:56:24 AM: Update 16663: task edges-ner-ontonotes, batch 663 (16663): mcc: 0.9449, acc: 0.9177, precision: 0.9583, recall: 0.9377, f1: 0.9479, edges-ner-ontonotes_loss: 0.0185
09/16 06:56:33 AM: Update 15947: task edges-ner-ontonotes, batch 947 (15947): mcc: 0.9248, acc: 0.8917, precision: 0.9450, recall: 0.9131, f1: 0.9288, edges-ner-ontonotes_loss: 0.0260
09/16 06:56:34 AM: Update 16736: task edges-ner-ontonotes, batch 736 (16736): mcc: 0.9451, acc: 0.9181, precision: 0.9585, recall: 0.9378, f1: 0.9481, edges-ner-ontonotes_loss: 0.0184
09/16 06:56:40 AM: ***** Step 16000 / Validation 16 *****
09/16 06:56:40 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:56:40 AM: Validating...
09/16 06:56:43 AM: Evaluate: task edges-ner-ontonotes, batch 18 (157): mcc: 0.8885, acc: 0.8462, precision: 0.9201, recall: 0.8696, f1: 0.8941, edges-ner-ontonotes_loss: 0.0296
09/16 06:56:44 AM: Update 16803: task edges-ner-ontonotes, batch 803 (16803): mcc: 0.9453, acc: 0.9183, precision: 0.9586, recall: 0.9381, f1: 0.9482, edges-ner-ontonotes_loss: 0.0183
09/16 06:56:53 AM: Evaluate: task edges-ner-ontonotes, batch 78 (157): mcc: 0.9297, acc: 0.9027, precision: 0.9510, recall: 0.9163, f1: 0.9333, edges-ner-ontonotes_loss: 0.0243
09/16 06:56:54 AM: Update 16846: task edges-ner-ontonotes, batch 846 (16846): mcc: 0.9437, acc: 0.9163, precision: 0.9575, recall: 0.9363, f1: 0.9468, edges-ner-ontonotes_loss: 0.0187
09/16 06:57:03 AM: Evaluate: task edges-ner-ontonotes, batch 128 (157): mcc: 0.9384, acc: 0.9134, precision: 0.9569, recall: 0.9269, f1: 0.9416, edges-ner-ontonotes_loss: 0.0208
09/16 06:57:04 AM: Update 16908: task edges-ner-ontonotes, batch 908 (16908): mcc: 0.9414, acc: 0.9132, precision: 0.9561, recall: 0.9333, f1: 0.9445, edges-ner-ontonotes_loss: 0.0198
09/16 06:57:09 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:57:09 AM: Best result seen so far for macro.
09/16 06:57:09 AM: Updating LR scheduler:
09/16 06:57:09 AM: 	Best result seen so far for macro_avg: 0.946
09/16 06:57:09 AM: 	# validation passes without improvement: 0
09/16 06:57:09 AM: edges-ner-ontonotes_loss: training: 0.025648 validation: 0.019283
09/16 06:57:09 AM: macro_avg: validation: 0.946243
09/16 06:57:09 AM: micro_avg: validation: 0.000000
09/16 06:57:09 AM: edges-ner-ontonotes_mcc: training: 0.925712 validation: 0.943235
09/16 06:57:09 AM: edges-ner-ontonotes_acc: training: 0.892766 validation: 0.919700
09/16 06:57:09 AM: edges-ner-ontonotes_precision: training: 0.945711 validation: 0.959900
09/16 06:57:09 AM: edges-ner-ontonotes_recall: training: 0.914082 validation: 0.932969
09/16 06:57:09 AM: edges-ner-ontonotes_f1: training: 0.929627 validation: 0.946243
09/16 06:57:09 AM: Global learning rate: 0.0001
09/16 06:57:09 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:57:14 AM: Update 16035: task edges-ner-ontonotes, batch 35 (16035): mcc: 0.9374, acc: 0.9096, precision: 0.9552, recall: 0.9267, f1: 0.9408, edges-ner-ontonotes_loss: 0.0204
09/16 06:57:14 AM: Update 16970: task edges-ner-ontonotes, batch 970 (16970): mcc: 0.9397, acc: 0.9110, precision: 0.9549, recall: 0.9312, f1: 0.9429, edges-ner-ontonotes_loss: 0.0205
09/16 06:57:18 AM: ***** Step 17000 / Validation 17 *****
09/16 06:57:18 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:57:18 AM: Validating...
09/16 06:57:24 AM: Evaluate: task edges-ner-ontonotes, batch 40 (157): mcc: 0.9091, acc: 0.8816, precision: 0.9285, recall: 0.8998, f1: 0.9139, edges-ner-ontonotes_loss: 0.0304
09/16 06:57:24 AM: Update 16096: task edges-ner-ontonotes, batch 96 (16096): mcc: 0.9319, acc: 0.9027, precision: 0.9488, recall: 0.9227, f1: 0.9356, edges-ner-ontonotes_loss: 0.0225
09/16 06:57:34 AM: Evaluate: task edges-ner-ontonotes, batch 95 (157): mcc: 0.9296, acc: 0.9005, precision: 0.9536, recall: 0.9136, f1: 0.9332, edges-ner-ontonotes_loss: 0.0246
09/16 06:57:34 AM: Update 16151: task edges-ner-ontonotes, batch 151 (16151): mcc: 0.9319, acc: 0.9022, precision: 0.9493, recall: 0.9221, f1: 0.9355, edges-ner-ontonotes_loss: 0.0227
09/16 06:57:44 AM: Update 16190: task edges-ner-ontonotes, batch 190 (16190): mcc: 0.9333, acc: 0.9038, precision: 0.9493, recall: 0.9248, f1: 0.9369, edges-ner-ontonotes_loss: 0.0222
09/16 06:57:44 AM: Evaluate: task edges-ner-ontonotes, batch 152 (157): mcc: 0.9384, acc: 0.9121, precision: 0.9588, recall: 0.9251, f1: 0.9416, edges-ner-ontonotes_loss: 0.0210
09/16 06:57:45 AM: Updating LR scheduler:
09/16 06:57:45 AM: 	Best result seen so far for macro_avg: 0.946
09/16 06:57:45 AM: 	# validation passes without improvement: 1
09/16 06:57:45 AM: edges-ner-ontonotes_loss: training: 0.020943 validation: 0.020811
09/16 06:57:45 AM: macro_avg: validation: 0.942025
09/16 06:57:45 AM: micro_avg: validation: 0.000000
09/16 06:57:45 AM: edges-ner-ontonotes_mcc: training: 0.938774 validation: 0.938836
09/16 06:57:45 AM: edges-ner-ontonotes_acc: training: 0.909814 validation: 0.912951
09/16 06:57:45 AM: edges-ner-ontonotes_precision: training: 0.954334 validation: 0.958703
09/16 06:57:45 AM: edges-ner-ontonotes_recall: training: 0.930076 validation: 0.925918
09/16 06:57:45 AM: edges-ner-ontonotes_f1: training: 0.942049 validation: 0.942025
09/16 06:57:45 AM: Global learning rate: 0.0001
09/16 06:57:45 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 06:57:54 AM: Update 17070: task edges-ner-ontonotes, batch 70 (17070): mcc: 0.9131, acc: 0.8731, precision: 0.9391, recall: 0.8970, f1: 0.9175, edges-ner-ontonotes_loss: 0.0314
09/16 06:57:54 AM: Update 16266: task edges-ner-ontonotes, batch 266 (16266): mcc: 0.9377, acc: 0.9088, precision: 0.9529, recall: 0.9295, f1: 0.9411, edges-ner-ontonotes_loss: 0.0208
09/16 06:58:04 AM: Update 16359: task edges-ner-ontonotes, batch 359 (16359): mcc: 0.9403, acc: 0.9122, precision: 0.9546, recall: 0.9327, f1: 0.9435, edges-ner-ontonotes_loss: 0.0198
09/16 06:58:04 AM: Update 17125: task edges-ner-ontonotes, batch 125 (17125): mcc: 0.9111, acc: 0.8740, precision: 0.9358, recall: 0.8965, f1: 0.9158, edges-ner-ontonotes_loss: 0.0313
09/16 06:58:15 AM: Update 16432: task edges-ner-ontonotes, batch 432 (16432): mcc: 0.9426, acc: 0.9150, precision: 0.9565, recall: 0.9352, f1: 0.9457, edges-ner-ontonotes_loss: 0.0191
09/16 06:58:15 AM: Update 17205: task edges-ner-ontonotes, batch 205 (17205): mcc: 0.9138, acc: 0.8775, precision: 0.9372, recall: 0.9001, f1: 0.9183, edges-ner-ontonotes_loss: 0.0299
09/16 06:58:25 AM: Update 17287: task edges-ner-ontonotes, batch 287 (17287): mcc: 0.9149, acc: 0.8789, precision: 0.9378, recall: 0.9016, f1: 0.9193, edges-ner-ontonotes_loss: 0.0291
09/16 06:58:26 AM: Update 16500: task edges-ner-ontonotes, batch 500 (16500): mcc: 0.9440, acc: 0.9168, precision: 0.9576, recall: 0.9366, f1: 0.9470, edges-ner-ontonotes_loss: 0.0187
09/16 06:58:35 AM: Update 17371: task edges-ner-ontonotes, batch 371 (17371): mcc: 0.9156, acc: 0.8796, precision: 0.9387, recall: 0.9021, f1: 0.9200, edges-ner-ontonotes_loss: 0.0285
09/16 06:58:36 AM: Update 16575: task edges-ner-ontonotes, batch 575 (16575): mcc: 0.9443, acc: 0.9171, precision: 0.9579, recall: 0.9369, f1: 0.9473, edges-ner-ontonotes_loss: 0.0185
09/16 06:58:45 AM: Update 17433: task edges-ner-ontonotes, batch 433 (17433): mcc: 0.9167, acc: 0.8811, precision: 0.9396, recall: 0.9032, f1: 0.9211, edges-ner-ontonotes_loss: 0.0282
09/16 06:58:47 AM: Update 16655: task edges-ner-ontonotes, batch 655 (16655): mcc: 0.9450, acc: 0.9178, precision: 0.9584, recall: 0.9377, f1: 0.9479, edges-ner-ontonotes_loss: 0.0184
09/16 06:58:55 AM: Update 17520: task edges-ner-ontonotes, batch 520 (17520): mcc: 0.9198, acc: 0.8851, precision: 0.9414, recall: 0.9073, f1: 0.9240, edges-ner-ontonotes_loss: 0.0272
09/16 06:59:01 AM: Update 16726: task edges-ner-ontonotes, batch 726 (16726): mcc: 0.9450, acc: 0.9179, precision: 0.9584, recall: 0.9378, f1: 0.9480, edges-ner-ontonotes_loss: 0.0184
09/16 06:59:05 AM: Update 17591: task edges-ner-ontonotes, batch 591 (17591): mcc: 0.9221, acc: 0.8882, precision: 0.9429, recall: 0.9100, f1: 0.9262, edges-ner-ontonotes_loss: 0.0265
09/16 06:59:11 AM: Update 16798: task edges-ner-ontonotes, batch 798 (16798): mcc: 0.9453, acc: 0.9183, precision: 0.9585, recall: 0.9381, f1: 0.9482, edges-ner-ontonotes_loss: 0.0183
09/16 06:59:15 AM: Update 17673: task edges-ner-ontonotes, batch 673 (17673): mcc: 0.9242, acc: 0.8912, precision: 0.9445, recall: 0.9124, f1: 0.9282, edges-ner-ontonotes_loss: 0.0258
09/16 06:59:21 AM: Update 16849: task edges-ner-ontonotes, batch 849 (16849): mcc: 0.9436, acc: 0.9161, precision: 0.9574, recall: 0.9361, f1: 0.9466, edges-ner-ontonotes_loss: 0.0188
09/16 06:59:26 AM: Update 17743: task edges-ner-ontonotes, batch 743 (17743): mcc: 0.9253, acc: 0.8926, precision: 0.9453, recall: 0.9137, f1: 0.9292, edges-ner-ontonotes_loss: 0.0254
09/16 06:59:31 AM: Update 16926: task edges-ner-ontonotes, batch 926 (16926): mcc: 0.9411, acc: 0.9128, precision: 0.9559, recall: 0.9328, f1: 0.9442, edges-ner-ontonotes_loss: 0.0199
09/16 06:59:36 AM: Update 17816: task edges-ner-ontonotes, batch 816 (17816): mcc: 0.9277, acc: 0.8957, precision: 0.9470, recall: 0.9164, f1: 0.9315, edges-ner-ontonotes_loss: 0.0246
09/16 06:59:41 AM: Update 16995: task edges-ner-ontonotes, batch 995 (16995): mcc: 0.9388, acc: 0.9099, precision: 0.9543, recall: 0.9302, f1: 0.9421, edges-ner-ontonotes_loss: 0.0209
09/16 06:59:42 AM: ***** Step 17000 / Validation 17 *****
09/16 06:59:42 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:59:42 AM: Validating...
09/16 06:59:46 AM: Update 17882: task edges-ner-ontonotes, batch 882 (17882): mcc: 0.9297, acc: 0.8983, precision: 0.9485, recall: 0.9188, f1: 0.9334, edges-ner-ontonotes_loss: 0.0240
09/16 06:59:51 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.9233, acc: 0.8960, precision: 0.9433, recall: 0.9119, f1: 0.9273, edges-ner-ontonotes_loss: 0.0263
09/16 06:59:58 AM: Update 17938: task edges-ner-ontonotes, batch 938 (17938): mcc: 0.9310, acc: 0.9000, precision: 0.9492, recall: 0.9205, f1: 0.9346, edges-ner-ontonotes_loss: 0.0236
09/16 07:00:02 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9310, acc: 0.9026, precision: 0.9532, recall: 0.9166, f1: 0.9345, edges-ner-ontonotes_loss: 0.0235
09/16 07:00:08 AM: Update 17996: task edges-ner-ontonotes, batch 996 (17996): mcc: 0.9325, acc: 0.9019, precision: 0.9502, recall: 0.9223, f1: 0.9361, edges-ner-ontonotes_loss: 0.0231
09/16 07:00:08 AM: ***** Step 18000 / Validation 18 *****
09/16 07:00:08 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:00:08 AM: Validating...
09/16 07:00:10 AM: Updating LR scheduler:
09/16 07:00:10 AM: 	Best result seen so far for macro_avg: 0.946
09/16 07:00:10 AM: 	# validation passes without improvement: 1
09/16 07:00:10 AM: edges-ner-ontonotes_loss: training: 0.020943 validation: 0.020811
09/16 07:00:10 AM: macro_avg: validation: 0.942025
09/16 07:00:10 AM: micro_avg: validation: 0.000000
09/16 07:00:10 AM: edges-ner-ontonotes_mcc: training: 0.938774 validation: 0.938836
09/16 07:00:10 AM: edges-ner-ontonotes_acc: training: 0.909814 validation: 0.912951
09/16 07:00:10 AM: edges-ner-ontonotes_precision: training: 0.954334 validation: 0.958703
09/16 07:00:10 AM: edges-ner-ontonotes_recall: training: 0.930076 validation: 0.925918
09/16 07:00:10 AM: edges-ner-ontonotes_f1: training: 0.942049 validation: 0.942025
09/16 07:00:10 AM: Global learning rate: 0.0001
09/16 07:00:10 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:00:12 AM: Update 17007: task edges-ner-ontonotes, batch 7 (17007): mcc: 0.9138, acc: 0.8729, precision: 0.9466, recall: 0.8911, f1: 0.9180, edges-ner-ontonotes_loss: 0.0351
09/16 07:00:18 AM: Evaluate: task edges-ner-ontonotes, batch 59 (157): mcc: 0.9250, acc: 0.8980, precision: 0.9457, recall: 0.9128, f1: 0.9290, edges-ner-ontonotes_loss: 0.0261
09/16 07:00:22 AM: Update 17072: task edges-ner-ontonotes, batch 72 (17072): mcc: 0.9124, acc: 0.8720, precision: 0.9390, recall: 0.8958, f1: 0.9169, edges-ner-ontonotes_loss: 0.0316
09/16 07:00:28 AM: Evaluate: task edges-ner-ontonotes, batch 111 (157): mcc: 0.9341, acc: 0.9067, precision: 0.9551, recall: 0.9206, f1: 0.9375, edges-ner-ontonotes_loss: 0.0226
09/16 07:00:32 AM: Update 17117: task edges-ner-ontonotes, batch 117 (17117): mcc: 0.9104, acc: 0.8723, precision: 0.9360, recall: 0.8950, f1: 0.9150, edges-ner-ontonotes_loss: 0.0315
09/16 07:00:36 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:00:36 AM: Best result seen so far for macro.
09/16 07:00:36 AM: Updating LR scheduler:
09/16 07:00:36 AM: 	Best result seen so far for macro_avg: 0.946
09/16 07:00:36 AM: 	# validation passes without improvement: 0
09/16 07:00:36 AM: edges-ner-ontonotes_loss: training: 0.023066 validation: 0.019503
09/16 07:00:36 AM: macro_avg: validation: 0.946356
09/16 07:00:36 AM: micro_avg: validation: 0.000000
09/16 07:00:36 AM: edges-ner-ontonotes_mcc: training: 0.932554 validation: 0.943369
09/16 07:00:36 AM: edges-ner-ontonotes_acc: training: 0.902011 validation: 0.919245
09/16 07:00:36 AM: edges-ner-ontonotes_precision: training: 0.950330 validation: 0.960775
09/16 07:00:36 AM: edges-ner-ontonotes_recall: training: 0.922359 validation: 0.932363
09/16 07:00:36 AM: edges-ner-ontonotes_f1: training: 0.936135 validation: 0.946356
09/16 07:00:36 AM: Global learning rate: 0.0001
09/16 07:00:36 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:00:38 AM: Update 18017: task edges-ner-ontonotes, batch 17 (18017): mcc: 0.9454, acc: 0.9166, precision: 0.9581, recall: 0.9388, f1: 0.9484, edges-ner-ontonotes_loss: 0.0186
09/16 07:00:42 AM: Update 17200: task edges-ner-ontonotes, batch 200 (17200): mcc: 0.9138, acc: 0.8776, precision: 0.9373, recall: 0.9000, f1: 0.9183, edges-ner-ontonotes_loss: 0.0299
09/16 07:00:50 AM: Update 18071: task edges-ner-ontonotes, batch 71 (18071): mcc: 0.9454, acc: 0.9180, precision: 0.9587, recall: 0.9383, f1: 0.9483, edges-ner-ontonotes_loss: 0.0180
09/16 07:00:52 AM: Update 17294: task edges-ner-ontonotes, batch 294 (17294): mcc: 0.9149, acc: 0.8788, precision: 0.9379, recall: 0.9015, f1: 0.9193, edges-ner-ontonotes_loss: 0.0290
09/16 07:01:00 AM: Update 18147: task edges-ner-ontonotes, batch 147 (18147): mcc: 0.9476, acc: 0.9208, precision: 0.9594, recall: 0.9417, f1: 0.9505, edges-ner-ontonotes_loss: 0.0175
09/16 07:01:02 AM: Update 17375: task edges-ner-ontonotes, batch 375 (17375): mcc: 0.9157, acc: 0.8797, precision: 0.9388, recall: 0.9021, f1: 0.9201, edges-ner-ontonotes_loss: 0.0286
09/16 07:01:10 AM: Update 18231: task edges-ner-ontonotes, batch 231 (18231): mcc: 0.9469, acc: 0.9201, precision: 0.9588, recall: 0.9410, f1: 0.9498, edges-ner-ontonotes_loss: 0.0174
09/16 07:01:12 AM: Update 17435: task edges-ner-ontonotes, batch 435 (17435): mcc: 0.9169, acc: 0.8813, precision: 0.9397, recall: 0.9035, f1: 0.9212, edges-ner-ontonotes_loss: 0.0281
09/16 07:01:20 AM: Update 18306: task edges-ner-ontonotes, batch 306 (18306): mcc: 0.9467, acc: 0.9201, precision: 0.9585, recall: 0.9408, f1: 0.9496, edges-ner-ontonotes_loss: 0.0174
09/16 07:01:22 AM: Update 17507: task edges-ner-ontonotes, batch 507 (17507): mcc: 0.9192, acc: 0.8842, precision: 0.9410, recall: 0.9065, f1: 0.9234, edges-ner-ontonotes_loss: 0.0273
09/16 07:01:31 AM: Update 18369: task edges-ner-ontonotes, batch 369 (18369): mcc: 0.9467, acc: 0.9201, precision: 0.9583, recall: 0.9410, f1: 0.9496, edges-ner-ontonotes_loss: 0.0175
09/16 07:01:33 AM: Update 17586: task edges-ner-ontonotes, batch 586 (17586): mcc: 0.9219, acc: 0.8879, precision: 0.9428, recall: 0.9097, f1: 0.9260, edges-ner-ontonotes_loss: 0.0266
09/16 07:01:41 AM: Update 18438: task edges-ner-ontonotes, batch 438 (18438): mcc: 0.9402, acc: 0.9120, precision: 0.9542, recall: 0.9328, f1: 0.9434, edges-ner-ontonotes_loss: 0.0201
09/16 07:01:43 AM: Update 17660: task edges-ner-ontonotes, batch 660 (17660): mcc: 0.9239, acc: 0.8907, precision: 0.9444, recall: 0.9120, f1: 0.9279, edges-ner-ontonotes_loss: 0.0259
09/16 07:01:52 AM: Update 18513: task edges-ner-ontonotes, batch 513 (18513): mcc: 0.9369, acc: 0.9079, precision: 0.9524, recall: 0.9285, f1: 0.9403, edges-ner-ontonotes_loss: 0.0216
09/16 07:01:53 AM: Update 17736: task edges-ner-ontonotes, batch 736 (17736): mcc: 0.9253, acc: 0.8927, precision: 0.9454, recall: 0.9137, f1: 0.9293, edges-ner-ontonotes_loss: 0.0254
09/16 07:02:02 AM: Update 18601: task edges-ner-ontonotes, batch 601 (18601): mcc: 0.9336, acc: 0.9035, precision: 0.9504, recall: 0.9242, f1: 0.9371, edges-ner-ontonotes_loss: 0.0231
09/16 07:02:03 AM: Update 17792: task edges-ner-ontonotes, batch 792 (17792): mcc: 0.9272, acc: 0.8951, precision: 0.9467, recall: 0.9158, f1: 0.9310, edges-ner-ontonotes_loss: 0.0248
09/16 07:02:13 AM: Update 17870: task edges-ner-ontonotes, batch 870 (17870): mcc: 0.9293, acc: 0.8978, precision: 0.9482, recall: 0.9183, f1: 0.9330, edges-ner-ontonotes_loss: 0.0241
09/16 07:02:14 AM: Update 18673: task edges-ner-ontonotes, batch 673 (18673): mcc: 0.9318, acc: 0.9010, precision: 0.9494, recall: 0.9219, f1: 0.9354, edges-ner-ontonotes_loss: 0.0240
09/16 07:02:23 AM: Update 17948: task edges-ner-ontonotes, batch 948 (17948): mcc: 0.9313, acc: 0.9004, precision: 0.9495, recall: 0.9209, f1: 0.9350, edges-ner-ontonotes_loss: 0.0234
09/16 07:02:25 AM: Update 18754: task edges-ner-ontonotes, batch 754 (18754): mcc: 0.9298, acc: 0.8986, precision: 0.9478, recall: 0.9197, f1: 0.9336, edges-ner-ontonotes_loss: 0.0246
09/16 07:02:30 AM: ***** Step 18000 / Validation 18 *****
09/16 07:02:30 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:02:30 AM: Validating...
09/16 07:02:33 AM: Evaluate: task edges-ner-ontonotes, batch 23 (157): mcc: 0.8771, acc: 0.8395, precision: 0.9103, recall: 0.8580, f1: 0.8834, edges-ner-ontonotes_loss: 0.0386
09/16 07:02:35 AM: Update 18827: task edges-ner-ontonotes, batch 827 (18827): mcc: 0.9295, acc: 0.8979, precision: 0.9478, recall: 0.9191, f1: 0.9332, edges-ner-ontonotes_loss: 0.0246
09/16 07:02:43 AM: Evaluate: task edges-ner-ontonotes, batch 87 (157): mcc: 0.9325, acc: 0.9048, precision: 0.9545, recall: 0.9182, f1: 0.9360, edges-ner-ontonotes_loss: 0.0240
09/16 07:02:45 AM: Update 18894: task edges-ner-ontonotes, batch 894 (18894): mcc: 0.9294, acc: 0.8977, precision: 0.9478, recall: 0.9188, f1: 0.9331, edges-ner-ontonotes_loss: 0.0245
09/16 07:02:54 AM: Evaluate: task edges-ner-ontonotes, batch 140 (157): mcc: 0.9425, acc: 0.9183, precision: 0.9607, recall: 0.9308, f1: 0.9455, edges-ner-ontonotes_loss: 0.0202
09/16 07:02:55 AM: Update 18958: task edges-ner-ontonotes, batch 958 (18958): mcc: 0.9289, acc: 0.8971, precision: 0.9476, recall: 0.9182, f1: 0.9326, edges-ner-ontonotes_loss: 0.0247
09/16 07:02:57 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:02:57 AM: Best result seen so far for macro.
09/16 07:02:57 AM: Updating LR scheduler:
09/16 07:02:57 AM: 	Best result seen so far for macro_avg: 0.946
09/16 07:02:57 AM: 	# validation passes without improvement: 0
09/16 07:02:57 AM: edges-ner-ontonotes_loss: training: 0.023066 validation: 0.019503
09/16 07:02:57 AM: macro_avg: validation: 0.946356
09/16 07:02:57 AM: micro_avg: validation: 0.000000
09/16 07:02:57 AM: edges-ner-ontonotes_mcc: training: 0.932554 validation: 0.943369
09/16 07:02:57 AM: edges-ner-ontonotes_acc: training: 0.902011 validation: 0.919245
09/16 07:02:57 AM: edges-ner-ontonotes_precision: training: 0.950330 validation: 0.960775
09/16 07:02:57 AM: edges-ner-ontonotes_recall: training: 0.922359 validation: 0.932363
09/16 07:02:57 AM: edges-ner-ontonotes_f1: training: 0.936135 validation: 0.946356
09/16 07:02:57 AM: Global learning rate: 0.0001
09/16 07:02:57 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:03:03 AM: ***** Step 19000 / Validation 19 *****
09/16 07:03:03 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:03:03 AM: Validating...
09/16 07:03:04 AM: Update 18051: task edges-ner-ontonotes, batch 51 (18051): mcc: 0.9476, acc: 0.9215, precision: 0.9603, recall: 0.9407, f1: 0.9504, edges-ner-ontonotes_loss: 0.0173
09/16 07:03:05 AM: Evaluate: task edges-ner-ontonotes, batch 13 (157): mcc: 0.8774, acc: 0.8311, precision: 0.9110, recall: 0.8578, f1: 0.8836, edges-ner-ontonotes_loss: 0.0336
09/16 07:03:14 AM: Update 18093: task edges-ner-ontonotes, batch 93 (18093): mcc: 0.9461, acc: 0.9182, precision: 0.9587, recall: 0.9395, f1: 0.9490, edges-ner-ontonotes_loss: 0.0178
09/16 07:03:17 AM: Evaluate: task edges-ner-ontonotes, batch 72 (157): mcc: 0.9281, acc: 0.8997, precision: 0.9497, recall: 0.9147, f1: 0.9319, edges-ner-ontonotes_loss: 0.0244
09/16 07:03:24 AM: Update 18149: task edges-ner-ontonotes, batch 149 (18149): mcc: 0.9477, acc: 0.9209, precision: 0.9596, recall: 0.9417, f1: 0.9506, edges-ner-ontonotes_loss: 0.0174
09/16 07:03:27 AM: Evaluate: task edges-ner-ontonotes, batch 122 (157): mcc: 0.9382, acc: 0.9125, precision: 0.9578, recall: 0.9257, f1: 0.9415, edges-ner-ontonotes_loss: 0.0208
09/16 07:03:33 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:03:34 AM: Best result seen so far for macro.
09/16 07:03:34 AM: Updating LR scheduler:
09/16 07:03:34 AM: 	Best result seen so far for macro_avg: 0.947
09/16 07:03:34 AM: 	# validation passes without improvement: 0
09/16 07:03:34 AM: edges-ner-ontonotes_loss: training: 0.024627 validation: 0.019011
09/16 07:03:34 AM: macro_avg: validation: 0.946639
09/16 07:03:34 AM: micro_avg: validation: 0.000000
09/16 07:03:34 AM: edges-ner-ontonotes_mcc: training: 0.928727 validation: 0.943678
09/16 07:03:34 AM: edges-ner-ontonotes_acc: training: 0.896895 validation: 0.919624
09/16 07:03:34 AM: edges-ner-ontonotes_precision: training: 0.947456 validation: 0.961520
09/16 07:03:34 AM: edges-ner-ontonotes_recall: training: 0.918012 validation: 0.932211
09/16 07:03:34 AM: edges-ner-ontonotes_f1: training: 0.932502 validation: 0.946639
09/16 07:03:34 AM: Global learning rate: 0.0001
09/16 07:03:34 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:03:34 AM: Update 18211: task edges-ner-ontonotes, batch 211 (18211): mcc: 0.9469, acc: 0.9199, precision: 0.9592, recall: 0.9406, f1: 0.9498, edges-ner-ontonotes_loss: 0.0175
09/16 07:03:37 AM: Update 19022: task edges-ner-ontonotes, batch 22 (19022): mcc: 0.9328, acc: 0.9017, precision: 0.9492, recall: 0.9240, f1: 0.9364, edges-ner-ontonotes_loss: 0.0204
09/16 07:03:44 AM: Update 18292: task edges-ner-ontonotes, batch 292 (18292): mcc: 0.9469, acc: 0.9204, precision: 0.9586, recall: 0.9412, f1: 0.9498, edges-ner-ontonotes_loss: 0.0173
09/16 07:03:49 AM: Update 19097: task edges-ner-ontonotes, batch 97 (19097): mcc: 0.9343, acc: 0.9039, precision: 0.9516, recall: 0.9243, f1: 0.9378, edges-ner-ontonotes_loss: 0.0217
09/16 07:03:54 AM: Update 18366: task edges-ner-ontonotes, batch 366 (18366): mcc: 0.9467, acc: 0.9201, precision: 0.9582, recall: 0.9411, f1: 0.9496, edges-ner-ontonotes_loss: 0.0176
09/16 07:04:00 AM: Update 19180: task edges-ner-ontonotes, batch 180 (19180): mcc: 0.9317, acc: 0.9013, precision: 0.9477, recall: 0.9233, f1: 0.9353, edges-ner-ontonotes_loss: 0.0221
09/16 07:04:06 AM: Update 18426: task edges-ner-ontonotes, batch 426 (18426): mcc: 0.9409, acc: 0.9130, precision: 0.9547, recall: 0.9337, f1: 0.9440, edges-ner-ontonotes_loss: 0.0198
09/16 07:04:11 AM: Update 19264: task edges-ner-ontonotes, batch 264 (19264): mcc: 0.9341, acc: 0.9041, precision: 0.9503, recall: 0.9254, f1: 0.9376, edges-ner-ontonotes_loss: 0.0214
09/16 07:04:18 AM: Update 18507: task edges-ner-ontonotes, batch 507 (18507): mcc: 0.9371, acc: 0.9082, precision: 0.9525, recall: 0.9288, f1: 0.9405, edges-ner-ontonotes_loss: 0.0216
09/16 07:04:21 AM: Update 19314: task edges-ner-ontonotes, batch 314 (19314): mcc: 0.9351, acc: 0.9056, precision: 0.9507, recall: 0.9268, f1: 0.9386, edges-ner-ontonotes_loss: 0.0212
09/16 07:04:28 AM: Update 18583: task edges-ner-ontonotes, batch 583 (18583): mcc: 0.9340, acc: 0.9040, precision: 0.9508, recall: 0.9247, f1: 0.9376, edges-ner-ontonotes_loss: 0.0229
09/16 07:04:31 AM: Update 19399: task edges-ner-ontonotes, batch 399 (19399): mcc: 0.9384, acc: 0.9096, precision: 0.9533, recall: 0.9305, f1: 0.9417, edges-ner-ontonotes_loss: 0.0202
09/16 07:04:40 AM: Update 18658: task edges-ner-ontonotes, batch 658 (18658): mcc: 0.9322, acc: 0.9016, precision: 0.9496, recall: 0.9224, f1: 0.9358, edges-ner-ontonotes_loss: 0.0238
09/16 07:04:41 AM: Update 19475: task edges-ner-ontonotes, batch 475 (19475): mcc: 0.9408, acc: 0.9127, precision: 0.9551, recall: 0.9331, f1: 0.9440, edges-ner-ontonotes_loss: 0.0195
09/16 07:04:52 AM: Update 18718: task edges-ner-ontonotes, batch 718 (18718): mcc: 0.9307, acc: 0.8997, precision: 0.9486, recall: 0.9206, f1: 0.9344, edges-ner-ontonotes_loss: 0.0243
09/16 07:04:52 AM: Update 19559: task edges-ner-ontonotes, batch 559 (19559): mcc: 0.9423, acc: 0.9146, precision: 0.9562, recall: 0.9348, f1: 0.9454, edges-ner-ontonotes_loss: 0.0188
09/16 07:05:02 AM: Update 18807: task edges-ner-ontonotes, batch 807 (18807): mcc: 0.9296, acc: 0.8981, precision: 0.9478, recall: 0.9193, f1: 0.9334, edges-ner-ontonotes_loss: 0.0246
09/16 07:05:02 AM: Update 19623: task edges-ner-ontonotes, batch 623 (19623): mcc: 0.9428, acc: 0.9151, precision: 0.9564, recall: 0.9356, f1: 0.9459, edges-ner-ontonotes_loss: 0.0187
09/16 07:05:12 AM: Update 18892: task edges-ner-ontonotes, batch 892 (18892): mcc: 0.9294, acc: 0.8977, precision: 0.9479, recall: 0.9189, f1: 0.9332, edges-ner-ontonotes_loss: 0.0245
09/16 07:05:12 AM: Update 19704: task edges-ner-ontonotes, batch 704 (19704): mcc: 0.9434, acc: 0.9161, precision: 0.9568, recall: 0.9364, f1: 0.9465, edges-ner-ontonotes_loss: 0.0185
09/16 07:05:22 AM: Update 18976: task edges-ner-ontonotes, batch 976 (18976): mcc: 0.9288, acc: 0.8970, precision: 0.9475, recall: 0.9181, f1: 0.9326, edges-ner-ontonotes_loss: 0.0246
09/16 07:05:22 AM: Update 19784: task edges-ner-ontonotes, batch 784 (19784): mcc: 0.9437, acc: 0.9162, precision: 0.9569, recall: 0.9368, f1: 0.9467, edges-ner-ontonotes_loss: 0.0184
09/16 07:05:28 AM: ***** Step 19000 / Validation 19 *****
09/16 07:05:28 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:05:28 AM: Validating...
09/16 07:05:32 AM: Evaluate: task edges-ner-ontonotes, batch 23 (157): mcc: 0.8867, acc: 0.8509, precision: 0.9125, recall: 0.8736, f1: 0.8926, edges-ner-ontonotes_loss: 0.0341
09/16 07:05:32 AM: Update 19858: task edges-ner-ontonotes, batch 858 (19858): mcc: 0.9442, acc: 0.9169, precision: 0.9575, recall: 0.9372, f1: 0.9472, edges-ner-ontonotes_loss: 0.0182
09/16 07:05:42 AM: Evaluate: task edges-ner-ontonotes, batch 80 (157): mcc: 0.9322, acc: 0.9053, precision: 0.9533, recall: 0.9189, f1: 0.9358, edges-ner-ontonotes_loss: 0.0233
09/16 07:05:42 AM: Update 19915: task edges-ner-ontonotes, batch 915 (19915): mcc: 0.9443, acc: 0.9168, precision: 0.9575, recall: 0.9372, f1: 0.9473, edges-ner-ontonotes_loss: 0.0182
09/16 07:05:52 AM: Evaluate: task edges-ner-ontonotes, batch 134 (157): mcc: 0.9417, acc: 0.9170, precision: 0.9605, recall: 0.9295, f1: 0.9447, edges-ner-ontonotes_loss: 0.0198
09/16 07:05:53 AM: Update 19956: task edges-ner-ontonotes, batch 956 (19956): mcc: 0.9430, acc: 0.9151, precision: 0.9567, recall: 0.9357, f1: 0.9461, edges-ner-ontonotes_loss: 0.0188
09/16 07:05:56 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:05:56 AM: Best result seen so far for macro.
09/16 07:05:56 AM: Updating LR scheduler:
09/16 07:05:56 AM: 	Best result seen so far for macro_avg: 0.947
09/16 07:05:56 AM: 	# validation passes without improvement: 0
09/16 07:05:56 AM: edges-ner-ontonotes_loss: training: 0.024627 validation: 0.019011
09/16 07:05:56 AM: macro_avg: validation: 0.946639
09/16 07:05:56 AM: micro_avg: validation: 0.000000
09/16 07:05:56 AM: edges-ner-ontonotes_mcc: training: 0.928727 validation: 0.943678
09/16 07:05:56 AM: edges-ner-ontonotes_acc: training: 0.896895 validation: 0.919624
09/16 07:05:56 AM: edges-ner-ontonotes_precision: training: 0.947456 validation: 0.961520
09/16 07:05:56 AM: edges-ner-ontonotes_recall: training: 0.918012 validation: 0.932211
09/16 07:05:56 AM: edges-ner-ontonotes_f1: training: 0.932502 validation: 0.946639
09/16 07:05:56 AM: Global learning rate: 0.0001
09/16 07:05:56 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:05:59 AM: ***** Step 20000 / Validation 20 *****
09/16 07:05:59 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:05:59 AM: Validating...
09/16 07:06:02 AM: Update 19041: task edges-ner-ontonotes, batch 41 (19041): mcc: 0.9371, acc: 0.9074, precision: 0.9532, recall: 0.9281, f1: 0.9405, edges-ner-ontonotes_loss: 0.0207
09/16 07:06:03 AM: Evaluate: task edges-ner-ontonotes, batch 23 (157): mcc: 0.8834, acc: 0.8480, precision: 0.9076, recall: 0.8722, f1: 0.8895, edges-ner-ontonotes_loss: 0.0363
09/16 07:06:12 AM: Update 19099: task edges-ner-ontonotes, batch 99 (19099): mcc: 0.9333, acc: 0.9029, precision: 0.9508, recall: 0.9233, f1: 0.9368, edges-ner-ontonotes_loss: 0.0220
09/16 07:06:13 AM: Evaluate: task edges-ner-ontonotes, batch 79 (157): mcc: 0.9281, acc: 0.9005, precision: 0.9487, recall: 0.9156, f1: 0.9318, edges-ner-ontonotes_loss: 0.0249
09/16 07:06:22 AM: Update 19152: task edges-ner-ontonotes, batch 152 (19152): mcc: 0.9327, acc: 0.9023, precision: 0.9494, recall: 0.9236, f1: 0.9363, edges-ner-ontonotes_loss: 0.0219
09/16 07:06:23 AM: Evaluate: task edges-ner-ontonotes, batch 128 (157): mcc: 0.9379, acc: 0.9125, precision: 0.9568, recall: 0.9260, f1: 0.9411, edges-ner-ontonotes_loss: 0.0213
09/16 07:06:28 AM: Updating LR scheduler:
09/16 07:06:28 AM: 	Best result seen so far for macro_avg: 0.947
09/16 07:06:28 AM: 	# validation passes without improvement: 1
09/16 07:06:28 AM: edges-ner-ontonotes_loss: training: 0.019504 validation: 0.019657
09/16 07:06:28 AM: macro_avg: validation: 0.945205
09/16 07:06:28 AM: micro_avg: validation: 0.000000
09/16 07:06:28 AM: edges-ner-ontonotes_mcc: training: 0.941375 validation: 0.942151
09/16 07:06:28 AM: edges-ner-ontonotes_acc: training: 0.913037 validation: 0.918107
09/16 07:06:28 AM: edges-ner-ontonotes_precision: training: 0.955582 validation: 0.959531
09/16 07:06:28 AM: edges-ner-ontonotes_recall: training: 0.933725 validation: 0.931301
09/16 07:06:28 AM: edges-ner-ontonotes_f1: training: 0.944527 validation: 0.945205
09/16 07:06:28 AM: Global learning rate: 0.0001
09/16 07:06:28 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:06:32 AM: Update 19219: task edges-ner-ontonotes, batch 219 (19219): mcc: 0.9336, acc: 0.9034, precision: 0.9497, recall: 0.9250, f1: 0.9372, edges-ner-ontonotes_loss: 0.0215
09/16 07:06:33 AM: Update 20038: task edges-ner-ontonotes, batch 38 (20038): mcc: 0.9118, acc: 0.8756, precision: 0.9353, recall: 0.8983, f1: 0.9164, edges-ner-ontonotes_loss: 0.0317
09/16 07:06:42 AM: Update 19294: task edges-ner-ontonotes, batch 294 (19294): mcc: 0.9343, acc: 0.9050, precision: 0.9502, recall: 0.9258, f1: 0.9378, edges-ner-ontonotes_loss: 0.0214
09/16 07:06:43 AM: Update 20111: task edges-ner-ontonotes, batch 111 (20111): mcc: 0.9160, acc: 0.8800, precision: 0.9392, recall: 0.9023, f1: 0.9204, edges-ner-ontonotes_loss: 0.0290
09/16 07:06:52 AM: Update 19336: task edges-ner-ontonotes, batch 336 (19336): mcc: 0.9365, acc: 0.9075, precision: 0.9516, recall: 0.9285, f1: 0.9399, edges-ner-ontonotes_loss: 0.0209
09/16 07:06:53 AM: Update 20192: task edges-ner-ontonotes, batch 192 (20192): mcc: 0.9137, acc: 0.8781, precision: 0.9373, recall: 0.8999, f1: 0.9182, edges-ner-ontonotes_loss: 0.0296
09/16 07:07:02 AM: Update 19417: task edges-ner-ontonotes, batch 417 (19417): mcc: 0.9389, acc: 0.9104, precision: 0.9535, recall: 0.9312, f1: 0.9422, edges-ner-ontonotes_loss: 0.0200
09/16 07:07:03 AM: Update 20246: task edges-ner-ontonotes, batch 246 (20246): mcc: 0.9122, acc: 0.8758, precision: 0.9365, recall: 0.8977, f1: 0.9167, edges-ner-ontonotes_loss: 0.0306
09/16 07:07:13 AM: Update 19493: task edges-ner-ontonotes, batch 493 (19493): mcc: 0.9410, acc: 0.9131, precision: 0.9552, recall: 0.9333, f1: 0.9442, edges-ner-ontonotes_loss: 0.0193
09/16 07:07:13 AM: Update 20328: task edges-ner-ontonotes, batch 328 (20328): mcc: 0.9134, acc: 0.8764, precision: 0.9370, recall: 0.8995, f1: 0.9179, edges-ner-ontonotes_loss: 0.0293
09/16 07:07:23 AM: Update 19573: task edges-ner-ontonotes, batch 573 (19573): mcc: 0.9425, acc: 0.9149, precision: 0.9564, recall: 0.9351, f1: 0.9456, edges-ner-ontonotes_loss: 0.0188
09/16 07:07:23 AM: Update 20411: task edges-ner-ontonotes, batch 411 (20411): mcc: 0.9149, acc: 0.8785, precision: 0.9379, recall: 0.9014, f1: 0.9193, edges-ner-ontonotes_loss: 0.0289
09/16 07:07:33 AM: Update 19638: task edges-ner-ontonotes, batch 638 (19638): mcc: 0.9430, acc: 0.9153, precision: 0.9565, recall: 0.9358, f1: 0.9460, edges-ner-ontonotes_loss: 0.0186
09/16 07:07:33 AM: Update 20500: task edges-ner-ontonotes, batch 500 (20500): mcc: 0.9158, acc: 0.8797, precision: 0.9385, recall: 0.9026, f1: 0.9202, edges-ner-ontonotes_loss: 0.0282
09/16 07:07:43 AM: Update 19722: task edges-ner-ontonotes, batch 722 (19722): mcc: 0.9436, acc: 0.9163, precision: 0.9570, recall: 0.9366, f1: 0.9467, edges-ner-ontonotes_loss: 0.0185
09/16 07:07:43 AM: Update 20553: task edges-ner-ontonotes, batch 553 (20553): mcc: 0.9167, acc: 0.8809, precision: 0.9391, recall: 0.9036, f1: 0.9210, edges-ner-ontonotes_loss: 0.0280
09/16 07:07:53 AM: Update 19796: task edges-ner-ontonotes, batch 796 (19796): mcc: 0.9437, acc: 0.9163, precision: 0.9569, recall: 0.9368, f1: 0.9467, edges-ner-ontonotes_loss: 0.0184
09/16 07:07:53 AM: Update 20629: task edges-ner-ontonotes, batch 629 (20629): mcc: 0.9188, acc: 0.8840, precision: 0.9404, recall: 0.9063, f1: 0.9231, edges-ner-ontonotes_loss: 0.0272
09/16 07:08:03 AM: Update 19866: task edges-ner-ontonotes, batch 866 (19866): mcc: 0.9442, acc: 0.9167, precision: 0.9574, recall: 0.9371, f1: 0.9472, edges-ner-ontonotes_loss: 0.0182
09/16 07:08:03 AM: Update 20697: task edges-ner-ontonotes, batch 697 (20697): mcc: 0.9207, acc: 0.8867, precision: 0.9419, recall: 0.9084, f1: 0.9249, edges-ner-ontonotes_loss: 0.0266
09/16 07:08:13 AM: Update 20775: task edges-ner-ontonotes, batch 775 (20775): mcc: 0.9221, acc: 0.8884, precision: 0.9430, recall: 0.9099, f1: 0.9262, edges-ner-ontonotes_loss: 0.0262
09/16 07:08:14 AM: Update 19925: task edges-ner-ontonotes, batch 925 (19925): mcc: 0.9443, acc: 0.9169, precision: 0.9576, recall: 0.9373, f1: 0.9473, edges-ner-ontonotes_loss: 0.0182
09/16 07:08:24 AM: Update 20852: task edges-ner-ontonotes, batch 852 (20852): mcc: 0.9237, acc: 0.8904, precision: 0.9443, recall: 0.9118, f1: 0.9278, edges-ner-ontonotes_loss: 0.0256
09/16 07:08:24 AM: ***** Step 20000 / Validation 20 *****
09/16 07:08:24 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:08:24 AM: Validating...
09/16 07:08:24 AM: Evaluate: task edges-ner-ontonotes, batch 2 (157): mcc: 0.8411, acc: 0.7462, precision: 0.8770, recall: 0.8231, f1: 0.8492, edges-ner-ontonotes_loss: 0.0397
09/16 07:08:34 AM: Update 20894: task edges-ner-ontonotes, batch 894 (20894): mcc: 0.9250, acc: 0.8922, precision: 0.9449, recall: 0.9137, f1: 0.9290, edges-ner-ontonotes_loss: 0.0252
09/16 07:08:34 AM: Evaluate: task edges-ner-ontonotes, batch 67 (157): mcc: 0.9229, acc: 0.8940, precision: 0.9432, recall: 0.9112, f1: 0.9270, edges-ner-ontonotes_loss: 0.0261
09/16 07:08:44 AM: Update 20948: task edges-ner-ontonotes, batch 948 (20948): mcc: 0.9267, acc: 0.8941, precision: 0.9459, recall: 0.9157, f1: 0.9306, edges-ner-ontonotes_loss: 0.0247
09/16 07:08:45 AM: Evaluate: task edges-ner-ontonotes, batch 117 (157): mcc: 0.9355, acc: 0.9096, precision: 0.9546, recall: 0.9237, f1: 0.9389, edges-ner-ontonotes_loss: 0.0220
09/16 07:08:52 AM: Updating LR scheduler:
09/16 07:08:52 AM: 	Best result seen so far for macro_avg: 0.947
09/16 07:08:52 AM: 	# validation passes without improvement: 1
09/16 07:08:52 AM: edges-ner-ontonotes_loss: training: 0.019504 validation: 0.019657
09/16 07:08:52 AM: macro_avg: validation: 0.945205
09/16 07:08:52 AM: micro_avg: validation: 0.000000
09/16 07:08:52 AM: edges-ner-ontonotes_mcc: training: 0.941375 validation: 0.942151
09/16 07:08:52 AM: edges-ner-ontonotes_acc: training: 0.913037 validation: 0.918107
09/16 07:08:52 AM: edges-ner-ontonotes_precision: training: 0.955582 validation: 0.959531
09/16 07:08:52 AM: edges-ner-ontonotes_recall: training: 0.933725 validation: 0.931301
09/16 07:08:52 AM: edges-ner-ontonotes_f1: training: 0.944527 validation: 0.945205
09/16 07:08:52 AM: Global learning rate: 0.0001
09/16 07:08:52 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:08:52 AM: ***** Step 21000 / Validation 21 *****
09/16 07:08:52 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:08:52 AM: Validating...
09/16 07:08:54 AM: Evaluate: task edges-ner-ontonotes, batch 9 (157): mcc: 0.8579, acc: 0.8078, precision: 0.9098, recall: 0.8231, f1: 0.8643, edges-ner-ontonotes_loss: 0.0391
09/16 07:08:55 AM: Update 20018: task edges-ner-ontonotes, batch 18 (20018): mcc: 0.9081, acc: 0.8658, precision: 0.9321, recall: 0.8944, f1: 0.9128, edges-ner-ontonotes_loss: 0.0343
09/16 07:09:04 AM: Evaluate: task edges-ner-ontonotes, batch 69 (157): mcc: 0.9258, acc: 0.8967, precision: 0.9493, recall: 0.9107, f1: 0.9296, edges-ner-ontonotes_loss: 0.0258
09/16 07:09:05 AM: Update 20075: task edges-ner-ontonotes, batch 75 (20075): mcc: 0.9120, acc: 0.8755, precision: 0.9361, recall: 0.8979, f1: 0.9166, edges-ner-ontonotes_loss: 0.0304
09/16 07:09:14 AM: Evaluate: task edges-ner-ontonotes, batch 119 (157): mcc: 0.9370, acc: 0.9116, precision: 0.9566, recall: 0.9246, f1: 0.9403, edges-ner-ontonotes_loss: 0.0217
09/16 07:09:15 AM: Update 20130: task edges-ner-ontonotes, batch 130 (20130): mcc: 0.9145, acc: 0.8792, precision: 0.9377, recall: 0.9010, f1: 0.9190, edges-ner-ontonotes_loss: 0.0292
09/16 07:09:21 AM: Updating LR scheduler:
09/16 07:09:21 AM: 	Best result seen so far for macro_avg: 0.947
09/16 07:09:21 AM: 	# validation passes without improvement: 2
09/16 07:09:21 AM: edges-ner-ontonotes_loss: training: 0.024256 validation: 0.019342
09/16 07:09:21 AM: macro_avg: validation: 0.946579
09/16 07:09:21 AM: micro_avg: validation: 0.000000
09/16 07:09:21 AM: edges-ner-ontonotes_mcc: training: 0.927985 validation: 0.943594
09/16 07:09:21 AM: edges-ner-ontonotes_acc: training: 0.895959 validation: 0.920913
09/16 07:09:21 AM: edges-ner-ontonotes_precision: training: 0.946728 validation: 0.960431
09/16 07:09:21 AM: edges-ner-ontonotes_recall: training: 0.917336 validation: 0.933121
09/16 07:09:21 AM: edges-ner-ontonotes_f1: training: 0.931800 validation: 0.946579
09/16 07:09:21 AM: Global learning rate: 0.0001
09/16 07:09:21 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:09:24 AM: Update 21021: task edges-ner-ontonotes, batch 21 (21021): mcc: 0.9424, acc: 0.9149, precision: 0.9575, recall: 0.9337, f1: 0.9455, edges-ner-ontonotes_loss: 0.0185
09/16 07:09:25 AM: Update 20192: task edges-ner-ontonotes, batch 192 (20192): mcc: 0.9137, acc: 0.8781, precision: 0.9373, recall: 0.8999, f1: 0.9182, edges-ner-ontonotes_loss: 0.0296
09/16 07:09:35 AM: Update 20248: task edges-ner-ontonotes, batch 248 (20248): mcc: 0.9123, acc: 0.8760, precision: 0.9365, recall: 0.8980, f1: 0.9168, edges-ner-ontonotes_loss: 0.0306
09/16 07:09:35 AM: Update 21104: task edges-ner-ontonotes, batch 104 (21104): mcc: 0.9495, acc: 0.9238, precision: 0.9607, recall: 0.9439, f1: 0.9522, edges-ner-ontonotes_loss: 0.0164
09/16 07:09:45 AM: Update 20337: task edges-ner-ontonotes, batch 337 (20337): mcc: 0.9140, acc: 0.8772, precision: 0.9375, recall: 0.9002, f1: 0.9185, edges-ner-ontonotes_loss: 0.0292
09/16 07:09:47 AM: Update 21168: task edges-ner-ontonotes, batch 168 (21168): mcc: 0.9487, acc: 0.9224, precision: 0.9605, recall: 0.9427, f1: 0.9515, edges-ner-ontonotes_loss: 0.0167
09/16 07:09:55 AM: Update 20428: task edges-ner-ontonotes, batch 428 (20428): mcc: 0.9150, acc: 0.8788, precision: 0.9380, recall: 0.9016, f1: 0.9194, edges-ner-ontonotes_loss: 0.0287
09/16 07:09:58 AM: Update 21248: task edges-ner-ontonotes, batch 248 (21248): mcc: 0.9478, acc: 0.9211, precision: 0.9595, recall: 0.9418, f1: 0.9506, edges-ner-ontonotes_loss: 0.0168
09/16 07:10:05 AM: Update 20512: task edges-ner-ontonotes, batch 512 (20512): mcc: 0.9159, acc: 0.8799, precision: 0.9386, recall: 0.9027, f1: 0.9203, edges-ner-ontonotes_loss: 0.0282
09/16 07:10:09 AM: Update 21328: task edges-ner-ontonotes, batch 328 (21328): mcc: 0.9480, acc: 0.9216, precision: 0.9600, recall: 0.9418, f1: 0.9508, edges-ner-ontonotes_loss: 0.0167
09/16 07:10:15 AM: Update 20566: task edges-ner-ontonotes, batch 566 (20566): mcc: 0.9168, acc: 0.8811, precision: 0.9389, recall: 0.9040, f1: 0.9211, edges-ner-ontonotes_loss: 0.0279
09/16 07:10:19 AM: Update 21413: task edges-ner-ontonotes, batch 413 (21413): mcc: 0.9472, acc: 0.9202, precision: 0.9596, recall: 0.9407, f1: 0.9501, edges-ner-ontonotes_loss: 0.0172
09/16 07:10:25 AM: Update 20640: task edges-ner-ontonotes, batch 640 (20640): mcc: 0.9195, acc: 0.8849, precision: 0.9411, recall: 0.9070, f1: 0.9237, edges-ner-ontonotes_loss: 0.0270
09/16 07:10:31 AM: Update 21481: task edges-ner-ontonotes, batch 481 (21481): mcc: 0.9473, acc: 0.9205, precision: 0.9599, recall: 0.9407, f1: 0.9502, edges-ner-ontonotes_loss: 0.0172
09/16 07:10:35 AM: Update 20722: task edges-ner-ontonotes, batch 722 (20722): mcc: 0.9212, acc: 0.8874, precision: 0.9423, recall: 0.9091, f1: 0.9254, edges-ner-ontonotes_loss: 0.0265
09/16 07:10:41 AM: Update 21551: task edges-ner-ontonotes, batch 551 (21551): mcc: 0.9425, acc: 0.9143, precision: 0.9564, recall: 0.9351, f1: 0.9456, edges-ner-ontonotes_loss: 0.0191
09/16 07:10:46 AM: Update 20797: task edges-ner-ontonotes, batch 797 (20797): mcc: 0.9227, acc: 0.8891, precision: 0.9435, recall: 0.9106, f1: 0.9267, edges-ner-ontonotes_loss: 0.0260
09/16 07:10:51 AM: Update 21631: task edges-ner-ontonotes, batch 631 (21631): mcc: 0.9391, acc: 0.9103, precision: 0.9543, recall: 0.9308, f1: 0.9424, edges-ner-ontonotes_loss: 0.0208
09/16 07:10:56 AM: Update 20855: task edges-ner-ontonotes, batch 855 (20855): mcc: 0.9238, acc: 0.8905, precision: 0.9442, recall: 0.9119, f1: 0.9278, edges-ner-ontonotes_loss: 0.0256
09/16 07:11:01 AM: Update 21711: task edges-ner-ontonotes, batch 711 (21711): mcc: 0.9363, acc: 0.9068, precision: 0.9523, recall: 0.9275, f1: 0.9397, edges-ner-ontonotes_loss: 0.0221
09/16 07:11:06 AM: Update 20927: task edges-ner-ontonotes, batch 927 (20927): mcc: 0.9260, acc: 0.8933, precision: 0.9455, recall: 0.9148, f1: 0.9299, edges-ner-ontonotes_loss: 0.0249
09/16 07:11:11 AM: Update 21784: task edges-ner-ontonotes, batch 784 (21784): mcc: 0.9344, acc: 0.9044, precision: 0.9513, recall: 0.9249, f1: 0.9379, edges-ner-ontonotes_loss: 0.0228
09/16 07:11:15 AM: ***** Step 21000 / Validation 21 *****
09/16 07:11:15 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:11:15 AM: Validating...
09/16 07:11:16 AM: Evaluate: task edges-ner-ontonotes, batch 6 (157): mcc: 0.8379, acc: 0.7800, precision: 0.9008, recall: 0.7950, f1: 0.8446, edges-ner-ontonotes_loss: 0.0437
09/16 07:11:21 AM: Update 21838: task edges-ner-ontonotes, batch 838 (21838): mcc: 0.9337, acc: 0.9033, precision: 0.9505, recall: 0.9243, f1: 0.9372, edges-ner-ontonotes_loss: 0.0230
09/16 07:11:26 AM: Evaluate: task edges-ner-ontonotes, batch 69 (157): mcc: 0.9258, acc: 0.8967, precision: 0.9493, recall: 0.9107, f1: 0.9296, edges-ner-ontonotes_loss: 0.0258
09/16 07:11:31 AM: Update 21902: task edges-ner-ontonotes, batch 902 (21902): mcc: 0.9327, acc: 0.9019, precision: 0.9499, recall: 0.9230, f1: 0.9363, edges-ner-ontonotes_loss: 0.0234
09/16 07:11:36 AM: Evaluate: task edges-ner-ontonotes, batch 124 (157): mcc: 0.9382, acc: 0.9134, precision: 0.9573, recall: 0.9260, f1: 0.9414, edges-ner-ontonotes_loss: 0.0214
09/16 07:11:41 AM: Update 21962: task edges-ner-ontonotes, batch 962 (21962): mcc: 0.9323, acc: 0.9015, precision: 0.9495, recall: 0.9227, f1: 0.9359, edges-ner-ontonotes_loss: 0.0236
09/16 07:11:42 AM: Updating LR scheduler:
09/16 07:11:42 AM: 	Best result seen so far for macro_avg: 0.947
09/16 07:11:42 AM: 	# validation passes without improvement: 2
09/16 07:11:42 AM: edges-ner-ontonotes_loss: training: 0.024256 validation: 0.019342
09/16 07:11:42 AM: macro_avg: validation: 0.946579
09/16 07:11:42 AM: micro_avg: validation: 0.000000
09/16 07:11:42 AM: edges-ner-ontonotes_mcc: training: 0.927985 validation: 0.943594
09/16 07:11:42 AM: edges-ner-ontonotes_acc: training: 0.895959 validation: 0.920913
09/16 07:11:42 AM: edges-ner-ontonotes_precision: training: 0.946728 validation: 0.960431
09/16 07:11:42 AM: edges-ner-ontonotes_recall: training: 0.917336 validation: 0.933121
09/16 07:11:42 AM: edges-ner-ontonotes_f1: training: 0.931800 validation: 0.946579
09/16 07:11:42 AM: Global learning rate: 0.0001
09/16 07:11:42 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:11:46 AM: ***** Step 22000 / Validation 22 *****
09/16 07:11:46 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:11:46 AM: Validating...
09/16 07:11:47 AM: Update 21037: task edges-ner-ontonotes, batch 37 (21037): mcc: 0.9476, acc: 0.9220, precision: 0.9599, recall: 0.9412, f1: 0.9505, edges-ner-ontonotes_loss: 0.0165
09/16 07:11:51 AM: Evaluate: task edges-ner-ontonotes, batch 32 (157): mcc: 0.9077, acc: 0.8766, precision: 0.9308, recall: 0.8949, f1: 0.9125, edges-ner-ontonotes_loss: 0.0287
09/16 07:11:57 AM: Update 21094: task edges-ner-ontonotes, batch 94 (21094): mcc: 0.9497, acc: 0.9238, precision: 0.9610, recall: 0.9440, f1: 0.9524, edges-ner-ontonotes_loss: 0.0160
09/16 07:12:01 AM: Evaluate: task edges-ner-ontonotes, batch 87 (157): mcc: 0.9341, acc: 0.9076, precision: 0.9547, recall: 0.9210, f1: 0.9376, edges-ner-ontonotes_loss: 0.0225
09/16 07:12:07 AM: Update 21153: task edges-ner-ontonotes, batch 153 (21153): mcc: 0.9484, acc: 0.9221, precision: 0.9598, recall: 0.9427, f1: 0.9512, edges-ner-ontonotes_loss: 0.0168
09/16 07:12:12 AM: Evaluate: task edges-ner-ontonotes, batch 145 (157): mcc: 0.9423, acc: 0.9181, precision: 0.9608, recall: 0.9303, f1: 0.9453, edges-ner-ontonotes_loss: 0.0194
09/16 07:12:15 AM: Updating LR scheduler:
09/16 07:12:15 AM: 	Best result seen so far for macro_avg: 0.947
09/16 07:12:15 AM: 	# validation passes without improvement: 3
09/16 07:12:15 AM: edges-ner-ontonotes_loss: training: 0.023631 validation: 0.018937
09/16 07:12:15 AM: macro_avg: validation: 0.946485
09/16 07:12:15 AM: micro_avg: validation: 0.000000
09/16 07:12:15 AM: edges-ner-ontonotes_mcc: training: 0.932112 validation: 0.943515
09/16 07:12:15 AM: edges-ner-ontonotes_acc: training: 0.901259 validation: 0.919624
09/16 07:12:15 AM: edges-ner-ontonotes_precision: training: 0.949377 validation: 0.961364
09/16 07:12:15 AM: edges-ner-ontonotes_recall: training: 0.922465 validation: 0.932059
09/16 07:12:15 AM: edges-ner-ontonotes_f1: training: 0.935727 validation: 0.946485
09/16 07:12:15 AM: Global learning rate: 0.0001
09/16 07:12:15 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:12:17 AM: Update 21198: task edges-ner-ontonotes, batch 198 (21198): mcc: 0.9477, acc: 0.9212, precision: 0.9594, recall: 0.9418, f1: 0.9505, edges-ner-ontonotes_loss: 0.0169
09/16 07:12:23 AM: Update 22066: task edges-ner-ontonotes, batch 66 (22066): mcc: 0.9260, acc: 0.8930, precision: 0.9482, recall: 0.9121, f1: 0.9298, edges-ner-ontonotes_loss: 0.0244
09/16 07:12:27 AM: Update 21280: task edges-ner-ontonotes, batch 280 (21280): mcc: 0.9482, acc: 0.9216, precision: 0.9603, recall: 0.9419, f1: 0.9510, edges-ner-ontonotes_loss: 0.0167
09/16 07:12:34 AM: Update 22118: task edges-ner-ontonotes, batch 118 (22118): mcc: 0.9266, acc: 0.8932, precision: 0.9481, recall: 0.9134, f1: 0.9304, edges-ner-ontonotes_loss: 0.0242
09/16 07:12:37 AM: Update 21366: task edges-ner-ontonotes, batch 366 (21366): mcc: 0.9472, acc: 0.9204, precision: 0.9590, recall: 0.9412, f1: 0.9500, edges-ner-ontonotes_loss: 0.0172
09/16 07:12:45 AM: Update 22195: task edges-ner-ontonotes, batch 195 (22195): mcc: 0.9291, acc: 0.8971, precision: 0.9472, recall: 0.9189, f1: 0.9328, edges-ner-ontonotes_loss: 0.0235
09/16 07:12:47 AM: Update 21437: task edges-ner-ontonotes, batch 437 (21437): mcc: 0.9475, acc: 0.9204, precision: 0.9599, recall: 0.9410, f1: 0.9503, edges-ner-ontonotes_loss: 0.0171
09/16 07:12:55 AM: Update 22273: task edges-ner-ontonotes, batch 273 (22273): mcc: 0.9306, acc: 0.8993, precision: 0.9488, recall: 0.9202, f1: 0.9343, edges-ner-ontonotes_loss: 0.0228
09/16 07:12:57 AM: Update 21493: task edges-ner-ontonotes, batch 493 (21493): mcc: 0.9459, acc: 0.9189, precision: 0.9586, recall: 0.9392, f1: 0.9488, edges-ner-ontonotes_loss: 0.0178
09/16 07:13:05 AM: Update 22354: task edges-ner-ontonotes, batch 354 (22354): mcc: 0.9319, acc: 0.9016, precision: 0.9492, recall: 0.9222, f1: 0.9355, edges-ner-ontonotes_loss: 0.0226
09/16 07:13:08 AM: Update 21568: task edges-ner-ontonotes, batch 568 (21568): mcc: 0.9415, acc: 0.9131, precision: 0.9557, recall: 0.9339, f1: 0.9447, edges-ner-ontonotes_loss: 0.0197
09/16 07:13:15 AM: Update 22422: task edges-ner-ontonotes, batch 422 (22422): mcc: 0.9334, acc: 0.9035, precision: 0.9503, recall: 0.9239, f1: 0.9370, edges-ner-ontonotes_loss: 0.0221
09/16 07:13:19 AM: Update 21645: task edges-ner-ontonotes, batch 645 (21645): mcc: 0.9387, acc: 0.9097, precision: 0.9540, recall: 0.9302, f1: 0.9419, edges-ner-ontonotes_loss: 0.0210
09/16 07:13:25 AM: Update 22496: task edges-ner-ontonotes, batch 496 (22496): mcc: 0.9359, acc: 0.9066, precision: 0.9517, recall: 0.9273, f1: 0.9393, edges-ner-ontonotes_loss: 0.0213
09/16 07:13:31 AM: Update 21720: task edges-ner-ontonotes, batch 720 (21720): mcc: 0.9359, acc: 0.9062, precision: 0.9520, recall: 0.9269, f1: 0.9393, edges-ner-ontonotes_loss: 0.0221
09/16 07:13:35 AM: Update 22576: task edges-ner-ontonotes, batch 576 (22576): mcc: 0.9380, acc: 0.9092, precision: 0.9531, recall: 0.9297, f1: 0.9413, edges-ner-ontonotes_loss: 0.0206
09/16 07:13:42 AM: Update 21785: task edges-ner-ontonotes, batch 785 (21785): mcc: 0.9343, acc: 0.9043, precision: 0.9513, recall: 0.9248, f1: 0.9378, edges-ner-ontonotes_loss: 0.0228
09/16 07:13:45 AM: Update 22660: task edges-ner-ontonotes, batch 660 (22660): mcc: 0.9399, acc: 0.9115, precision: 0.9544, recall: 0.9322, f1: 0.9431, edges-ner-ontonotes_loss: 0.0199
09/16 07:13:53 AM: Update 21869: task edges-ner-ontonotes, batch 869 (21869): mcc: 0.9332, acc: 0.9027, precision: 0.9502, recall: 0.9237, f1: 0.9368, edges-ner-ontonotes_loss: 0.0232
09/16 07:13:56 AM: Update 22724: task edges-ner-ontonotes, batch 724 (22724): mcc: 0.9412, acc: 0.9132, precision: 0.9553, recall: 0.9336, f1: 0.9443, edges-ner-ontonotes_loss: 0.0195
09/16 07:14:03 AM: Update 21966: task edges-ner-ontonotes, batch 966 (21966): mcc: 0.9323, acc: 0.9015, precision: 0.9495, recall: 0.9227, f1: 0.9359, edges-ner-ontonotes_loss: 0.0236
09/16 07:14:06 AM: Update 22802: task edges-ner-ontonotes, batch 802 (22802): mcc: 0.9420, acc: 0.9144, precision: 0.9559, recall: 0.9346, f1: 0.9451, edges-ner-ontonotes_loss: 0.0192
09/16 07:14:07 AM: ***** Step 22000 / Validation 22 *****
09/16 07:14:07 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:14:07 AM: Validating...
09/16 07:14:13 AM: Evaluate: task edges-ner-ontonotes, batch 39 (157): mcc: 0.9143, acc: 0.8849, precision: 0.9347, recall: 0.9035, f1: 0.9189, edges-ner-ontonotes_loss: 0.0274
09/16 07:14:16 AM: Update 22861: task edges-ner-ontonotes, batch 861 (22861): mcc: 0.9426, acc: 0.9151, precision: 0.9564, recall: 0.9351, f1: 0.9457, edges-ner-ontonotes_loss: 0.0190
09/16 07:14:23 AM: Evaluate: task edges-ner-ontonotes, batch 95 (157): mcc: 0.9351, acc: 0.9084, precision: 0.9565, recall: 0.9211, f1: 0.9385, edges-ner-ontonotes_loss: 0.0222
09/16 07:14:27 AM: Update 22918: task edges-ner-ontonotes, batch 918 (22918): mcc: 0.9428, acc: 0.9154, precision: 0.9566, recall: 0.9353, f1: 0.9459, edges-ner-ontonotes_loss: 0.0189
09/16 07:14:34 AM: Evaluate: task edges-ner-ontonotes, batch 145 (157): mcc: 0.9423, acc: 0.9181, precision: 0.9608, recall: 0.9303, f1: 0.9453, edges-ner-ontonotes_loss: 0.0194
09/16 07:14:36 AM: Updating LR scheduler:
09/16 07:14:36 AM: 	Best result seen so far for macro_avg: 0.947
09/16 07:14:36 AM: 	# validation passes without improvement: 3
09/16 07:14:36 AM: edges-ner-ontonotes_loss: training: 0.023631 validation: 0.018937
09/16 07:14:36 AM: macro_avg: validation: 0.946485
09/16 07:14:36 AM: micro_avg: validation: 0.000000
09/16 07:14:36 AM: edges-ner-ontonotes_mcc: training: 0.932112 validation: 0.943515
09/16 07:14:36 AM: edges-ner-ontonotes_acc: training: 0.901259 validation: 0.919624
09/16 07:14:36 AM: edges-ner-ontonotes_precision: training: 0.949377 validation: 0.961364
09/16 07:14:36 AM: edges-ner-ontonotes_recall: training: 0.922465 validation: 0.932059
09/16 07:14:36 AM: edges-ner-ontonotes_f1: training: 0.935727 validation: 0.946485
09/16 07:14:36 AM: Global learning rate: 0.0001
09/16 07:14:36 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:14:37 AM: Update 22976: task edges-ner-ontonotes, batch 976 (22976): mcc: 0.9433, acc: 0.9160, precision: 0.9571, recall: 0.9358, f1: 0.9463, edges-ner-ontonotes_loss: 0.0187
09/16 07:14:39 AM: ***** Step 23000 / Validation 23 *****
09/16 07:14:39 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:14:39 AM: Validating...
09/16 07:14:44 AM: Update 22027: task edges-ner-ontonotes, batch 27 (22027): mcc: 0.9182, acc: 0.8852, precision: 0.9401, recall: 0.9054, f1: 0.9224, edges-ner-ontonotes_loss: 0.0255
09/16 07:14:47 AM: Evaluate: task edges-ner-ontonotes, batch 54 (157): mcc: 0.9219, acc: 0.8971, precision: 0.9383, recall: 0.9142, f1: 0.9261, edges-ner-ontonotes_loss: 0.0275
09/16 07:14:54 AM: Update 22090: task edges-ner-ontonotes, batch 90 (22090): mcc: 0.9273, acc: 0.8938, precision: 0.9484, recall: 0.9144, f1: 0.9311, edges-ner-ontonotes_loss: 0.0243
09/16 07:14:57 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9361, acc: 0.9124, precision: 0.9523, recall: 0.9270, f1: 0.9395, edges-ner-ontonotes_loss: 0.0226
09/16 07:15:04 AM: Update 22130: task edges-ner-ontonotes, batch 130 (22130): mcc: 0.9266, acc: 0.8931, precision: 0.9482, recall: 0.9132, f1: 0.9304, edges-ner-ontonotes_loss: 0.0242
09/16 07:15:05 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:15:05 AM: Best result seen so far for macro.
09/16 07:15:05 AM: Updating LR scheduler:
09/16 07:15:05 AM: 	Best result seen so far for macro_avg: 0.948
09/16 07:15:05 AM: 	# validation passes without improvement: 0
09/16 07:15:05 AM: edges-ner-ontonotes_loss: training: 0.018720 validation: 0.019430
09/16 07:15:05 AM: macro_avg: validation: 0.947735
09/16 07:15:05 AM: micro_avg: validation: 0.000000
09/16 07:15:05 AM: edges-ner-ontonotes_mcc: training: 0.943583 validation: 0.944756
09/16 07:15:05 AM: edges-ner-ontonotes_acc: training: 0.916511 validation: 0.923870
09/16 07:15:05 AM: edges-ner-ontonotes_precision: training: 0.957318 validation: 0.957940
09/16 07:15:05 AM: edges-ner-ontonotes_recall: training: 0.936159 validation: 0.937746
09/16 07:15:05 AM: edges-ner-ontonotes_f1: training: 0.946620 validation: 0.947735
09/16 07:15:05 AM: Global learning rate: 0.0001
09/16 07:15:05 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:15:07 AM: Update 23021: task edges-ner-ontonotes, batch 21 (23021): mcc: 0.9522, acc: 0.9306, precision: 0.9599, recall: 0.9498, f1: 0.9548, edges-ner-ontonotes_loss: 0.0167
09/16 07:15:14 AM: Update 22210: task edges-ner-ontonotes, batch 210 (22210): mcc: 0.9296, acc: 0.8978, precision: 0.9477, recall: 0.9194, f1: 0.9333, edges-ner-ontonotes_loss: 0.0232
09/16 07:15:18 AM: Update 23072: task edges-ner-ontonotes, batch 72 (23072): mcc: 0.9237, acc: 0.8904, precision: 0.9436, recall: 0.9124, f1: 0.9277, edges-ner-ontonotes_loss: 0.0264
09/16 07:15:24 AM: Update 22285: task edges-ner-ontonotes, batch 285 (22285): mcc: 0.9315, acc: 0.9005, precision: 0.9496, recall: 0.9211, f1: 0.9351, edges-ner-ontonotes_loss: 0.0227
09/16 07:15:28 AM: Update 23152: task edges-ner-ontonotes, batch 152 (23152): mcc: 0.9191, acc: 0.8854, precision: 0.9413, recall: 0.9061, f1: 0.9234, edges-ner-ontonotes_loss: 0.0282
09/16 07:15:34 AM: Update 22357: task edges-ner-ontonotes, batch 357 (22357): mcc: 0.9316, acc: 0.9013, precision: 0.9490, recall: 0.9219, f1: 0.9352, edges-ner-ontonotes_loss: 0.0227
09/16 07:15:38 AM: Update 23223: task edges-ner-ontonotes, batch 223 (23223): mcc: 0.9166, acc: 0.8828, precision: 0.9399, recall: 0.9027, f1: 0.9209, edges-ner-ontonotes_loss: 0.0291
09/16 07:15:44 AM: Update 22418: task edges-ner-ontonotes, batch 418 (22418): mcc: 0.9333, acc: 0.9035, precision: 0.9503, recall: 0.9239, f1: 0.9369, edges-ner-ontonotes_loss: 0.0221
09/16 07:15:48 AM: Update 23302: task edges-ner-ontonotes, batch 302 (23302): mcc: 0.9173, acc: 0.8835, precision: 0.9405, recall: 0.9035, f1: 0.9216, edges-ner-ontonotes_loss: 0.0291
09/16 07:15:54 AM: Update 22488: task edges-ner-ontonotes, batch 488 (22488): mcc: 0.9358, acc: 0.9064, precision: 0.9516, recall: 0.9271, f1: 0.9392, edges-ner-ontonotes_loss: 0.0214
09/16 07:15:58 AM: Update 23359: task edges-ner-ontonotes, batch 359 (23359): mcc: 0.9158, acc: 0.8814, precision: 0.9388, recall: 0.9023, f1: 0.9202, edges-ner-ontonotes_loss: 0.0295
09/16 07:16:05 AM: Update 22570: task edges-ner-ontonotes, batch 570 (22570): mcc: 0.9376, acc: 0.9088, precision: 0.9529, recall: 0.9293, f1: 0.9410, edges-ner-ontonotes_loss: 0.0207
09/16 07:16:08 AM: Update 23438: task edges-ner-ontonotes, batch 438 (23438): mcc: 0.9171, acc: 0.8826, precision: 0.9395, recall: 0.9040, f1: 0.9214, edges-ner-ontonotes_loss: 0.0286
09/16 07:16:15 AM: Update 22650: task edges-ner-ontonotes, batch 650 (22650): mcc: 0.9397, acc: 0.9113, precision: 0.9543, recall: 0.9319, f1: 0.9430, edges-ner-ontonotes_loss: 0.0200
09/16 07:16:18 AM: Update 23522: task edges-ner-ontonotes, batch 522 (23522): mcc: 0.9168, acc: 0.8823, precision: 0.9391, recall: 0.9039, f1: 0.9212, edges-ner-ontonotes_loss: 0.0284
09/16 07:16:27 AM: Update 22724: task edges-ner-ontonotes, batch 724 (22724): mcc: 0.9412, acc: 0.9132, precision: 0.9553, recall: 0.9336, f1: 0.9443, edges-ner-ontonotes_loss: 0.0195
09/16 07:16:28 AM: Update 23615: task edges-ner-ontonotes, batch 615 (23615): mcc: 0.9174, acc: 0.8825, precision: 0.9397, recall: 0.9043, f1: 0.9217, edges-ner-ontonotes_loss: 0.0279
09/16 07:16:37 AM: Update 22806: task edges-ner-ontonotes, batch 806 (22806): mcc: 0.9420, acc: 0.9144, precision: 0.9558, recall: 0.9346, f1: 0.9451, edges-ner-ontonotes_loss: 0.0192
09/16 07:16:38 AM: Update 23674: task edges-ner-ontonotes, batch 674 (23674): mcc: 0.9182, acc: 0.8836, precision: 0.9402, recall: 0.9055, f1: 0.9225, edges-ner-ontonotes_loss: 0.0277
09/16 07:16:47 AM: Update 22879: task edges-ner-ontonotes, batch 879 (22879): mcc: 0.9427, acc: 0.9153, precision: 0.9565, recall: 0.9354, f1: 0.9458, edges-ner-ontonotes_loss: 0.0189
09/16 07:16:49 AM: Update 23747: task edges-ner-ontonotes, batch 747 (23747): mcc: 0.9204, acc: 0.8862, precision: 0.9416, recall: 0.9082, f1: 0.9246, edges-ner-ontonotes_loss: 0.0269
09/16 07:16:57 AM: Update 22950: task edges-ner-ontonotes, batch 950 (22950): mcc: 0.9430, acc: 0.9157, precision: 0.9568, recall: 0.9356, f1: 0.9461, edges-ner-ontonotes_loss: 0.0188
09/16 07:16:59 AM: Update 23821: task edges-ner-ontonotes, batch 821 (23821): mcc: 0.9217, acc: 0.8878, precision: 0.9426, recall: 0.9096, f1: 0.9258, edges-ner-ontonotes_loss: 0.0264
09/16 07:17:04 AM: ***** Step 23000 / Validation 23 *****
09/16 07:17:05 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:17:05 AM: Validating...
09/16 07:17:07 AM: Evaluate: task edges-ner-ontonotes, batch 14 (157): mcc: 0.8692, acc: 0.8297, precision: 0.9055, recall: 0.8479, f1: 0.8757, edges-ner-ontonotes_loss: 0.0361
09/16 07:17:09 AM: Update 23898: task edges-ner-ontonotes, batch 898 (23898): mcc: 0.9225, acc: 0.8890, precision: 0.9430, recall: 0.9108, f1: 0.9266, edges-ner-ontonotes_loss: 0.0260
09/16 07:17:17 AM: Evaluate: task edges-ner-ontonotes, batch 72 (157): mcc: 0.9249, acc: 0.8982, precision: 0.9441, recall: 0.9142, f1: 0.9289, edges-ner-ontonotes_loss: 0.0268
09/16 07:17:19 AM: Update 23957: task edges-ner-ontonotes, batch 957 (23957): mcc: 0.9234, acc: 0.8902, precision: 0.9435, recall: 0.9119, f1: 0.9274, edges-ner-ontonotes_loss: 0.0256
09/16 07:17:27 AM: Evaluate: task edges-ner-ontonotes, batch 127 (157): mcc: 0.9400, acc: 0.9176, precision: 0.9550, recall: 0.9317, f1: 0.9432, edges-ner-ontonotes_loss: 0.0214
09/16 07:17:29 AM: Update 23994: task edges-ner-ontonotes, batch 994 (23994): mcc: 0.9243, acc: 0.8913, precision: 0.9442, recall: 0.9129, f1: 0.9283, edges-ner-ontonotes_loss: 0.0254
09/16 07:17:30 AM: ***** Step 24000 / Validation 24 *****
09/16 07:17:30 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:17:30 AM: Validating...
09/16 07:17:34 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:17:34 AM: Best result seen so far for macro.
09/16 07:17:34 AM: Updating LR scheduler:
09/16 07:17:34 AM: 	Best result seen so far for macro_avg: 0.948
09/16 07:17:34 AM: 	# validation passes without improvement: 0
09/16 07:17:34 AM: edges-ner-ontonotes_loss: training: 0.018720 validation: 0.019430
09/16 07:17:34 AM: macro_avg: validation: 0.947735
09/16 07:17:34 AM: micro_avg: validation: 0.000000
09/16 07:17:34 AM: edges-ner-ontonotes_mcc: training: 0.943583 validation: 0.944756
09/16 07:17:34 AM: edges-ner-ontonotes_acc: training: 0.916511 validation: 0.923870
09/16 07:17:34 AM: edges-ner-ontonotes_precision: training: 0.957318 validation: 0.957940
09/16 07:17:34 AM: edges-ner-ontonotes_recall: training: 0.936159 validation: 0.937746
09/16 07:17:34 AM: edges-ner-ontonotes_f1: training: 0.946620 validation: 0.947735
09/16 07:17:34 AM: Global learning rate: 0.0001
09/16 07:17:34 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:17:38 AM: Update 23024: task edges-ner-ontonotes, batch 24 (23024): mcc: 0.9519, acc: 0.9288, precision: 0.9598, recall: 0.9494, f1: 0.9546, edges-ner-ontonotes_loss: 0.0167
09/16 07:17:39 AM: Evaluate: task edges-ner-ontonotes, batch 54 (157): mcc: 0.9246, acc: 0.8979, precision: 0.9429, recall: 0.9148, f1: 0.9286, edges-ner-ontonotes_loss: 0.0257
09/16 07:17:48 AM: Update 23066: task edges-ner-ontonotes, batch 66 (23066): mcc: 0.9264, acc: 0.8940, precision: 0.9448, recall: 0.9162, f1: 0.9303, edges-ner-ontonotes_loss: 0.0252
09/16 07:17:49 AM: Evaluate: task edges-ner-ontonotes, batch 112 (157): mcc: 0.9349, acc: 0.9097, precision: 0.9524, recall: 0.9246, f1: 0.9383, edges-ner-ontonotes_loss: 0.0218
09/16 07:17:58 AM: Updating LR scheduler:
09/16 07:17:58 AM: 	Best result seen so far for macro_avg: 0.948
09/16 07:17:58 AM: 	# validation passes without improvement: 1
09/16 07:17:58 AM: edges-ner-ontonotes_loss: training: 0.025291 validation: 0.018991
09/16 07:17:58 AM: macro_avg: validation: 0.947340
09/16 07:17:58 AM: micro_avg: validation: 0.000000
09/16 07:17:58 AM: edges-ner-ontonotes_mcc: training: 0.924600 validation: 0.944352
09/16 07:17:58 AM: edges-ner-ontonotes_acc: training: 0.891639 validation: 0.922429
09/16 07:17:58 AM: edges-ner-ontonotes_precision: training: 0.944389 validation: 0.958479
09/16 07:17:58 AM: edges-ner-ontonotes_recall: training: 0.913296 validation: 0.936457
09/16 07:17:58 AM: edges-ner-ontonotes_f1: training: 0.928582 validation: 0.947340
09/16 07:17:58 AM: Global learning rate: 0.0001
09/16 07:17:58 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:17:58 AM: Update 23122: task edges-ner-ontonotes, batch 122 (23122): mcc: 0.9189, acc: 0.8851, precision: 0.9414, recall: 0.9055, f1: 0.9231, edges-ner-ontonotes_loss: 0.0285
09/16 07:17:59 AM: Update 24010: task edges-ner-ontonotes, batch 10 (24010): mcc: 0.9525, acc: 0.9317, precision: 0.9576, recall: 0.9528, f1: 0.9552, edges-ner-ontonotes_loss: 0.0165
09/16 07:18:08 AM: Update 23194: task edges-ner-ontonotes, batch 194 (23194): mcc: 0.9172, acc: 0.8833, precision: 0.9402, recall: 0.9035, f1: 0.9215, edges-ner-ontonotes_loss: 0.0289
09/16 07:18:09 AM: Update 24080: task edges-ner-ontonotes, batch 80 (24080): mcc: 0.9506, acc: 0.9253, precision: 0.9596, recall: 0.9472, f1: 0.9533, edges-ner-ontonotes_loss: 0.0163
09/16 07:18:18 AM: Update 23267: task edges-ner-ontonotes, batch 267 (23267): mcc: 0.9172, acc: 0.8834, precision: 0.9403, recall: 0.9034, f1: 0.9215, edges-ner-ontonotes_loss: 0.0289
09/16 07:18:19 AM: Update 24155: task edges-ner-ontonotes, batch 155 (24155): mcc: 0.9514, acc: 0.9265, precision: 0.9618, recall: 0.9464, f1: 0.9541, edges-ner-ontonotes_loss: 0.0161
09/16 07:18:28 AM: Update 23339: task edges-ner-ontonotes, batch 339 (23339): mcc: 0.9159, acc: 0.8815, precision: 0.9391, recall: 0.9022, f1: 0.9203, edges-ner-ontonotes_loss: 0.0295
09/16 07:18:29 AM: Update 24235: task edges-ner-ontonotes, batch 235 (24235): mcc: 0.9511, acc: 0.9254, precision: 0.9616, recall: 0.9461, f1: 0.9538, edges-ner-ontonotes_loss: 0.0162
09/16 07:18:38 AM: Update 23403: task edges-ner-ontonotes, batch 403 (23403): mcc: 0.9159, acc: 0.8814, precision: 0.9386, recall: 0.9027, f1: 0.9203, edges-ner-ontonotes_loss: 0.0291
09/16 07:18:40 AM: Update 24294: task edges-ner-ontonotes, batch 294 (24294): mcc: 0.9506, acc: 0.9245, precision: 0.9614, recall: 0.9453, f1: 0.9533, edges-ner-ontonotes_loss: 0.0163
09/16 07:18:48 AM: Update 23484: task edges-ner-ontonotes, batch 484 (23484): mcc: 0.9171, acc: 0.8826, precision: 0.9395, recall: 0.9042, f1: 0.9215, edges-ner-ontonotes_loss: 0.0284
09/16 07:18:50 AM: Update 24370: task edges-ner-ontonotes, batch 370 (24370): mcc: 0.9503, acc: 0.9243, precision: 0.9615, recall: 0.9447, f1: 0.9530, edges-ner-ontonotes_loss: 0.0164
09/16 07:18:58 AM: Update 23566: task edges-ner-ontonotes, batch 566 (23566): mcc: 0.9172, acc: 0.8826, precision: 0.9396, recall: 0.9042, f1: 0.9216, edges-ner-ontonotes_loss: 0.0281
09/16 07:19:00 AM: Update 24452: task edges-ner-ontonotes, batch 452 (24452): mcc: 0.9498, acc: 0.9239, precision: 0.9610, recall: 0.9442, f1: 0.9525, edges-ner-ontonotes_loss: 0.0165
09/16 07:19:08 AM: Update 23645: task edges-ner-ontonotes, batch 645 (23645): mcc: 0.9177, acc: 0.8831, precision: 0.9400, recall: 0.9048, f1: 0.9220, edges-ner-ontonotes_loss: 0.0279
09/16 07:19:10 AM: Update 24529: task edges-ner-ontonotes, batch 529 (24529): mcc: 0.9497, acc: 0.9236, precision: 0.9610, recall: 0.9439, f1: 0.9524, edges-ner-ontonotes_loss: 0.0166
09/16 07:19:19 AM: Update 23705: task edges-ner-ontonotes, batch 705 (23705): mcc: 0.9192, acc: 0.8847, precision: 0.9408, recall: 0.9067, f1: 0.9235, edges-ner-ontonotes_loss: 0.0273
09/16 07:19:20 AM: Update 24599: task edges-ner-ontonotes, batch 599 (24599): mcc: 0.9485, acc: 0.9221, precision: 0.9602, recall: 0.9426, f1: 0.9513, edges-ner-ontonotes_loss: 0.0169
09/16 07:19:30 AM: Update 24673: task edges-ner-ontonotes, batch 673 (24673): mcc: 0.9445, acc: 0.9170, precision: 0.9576, recall: 0.9376, f1: 0.9475, edges-ner-ontonotes_loss: 0.0186
09/16 07:19:30 AM: Update 23781: task edges-ner-ontonotes, batch 781 (23781): mcc: 0.9211, acc: 0.8870, precision: 0.9421, recall: 0.9090, f1: 0.9253, edges-ner-ontonotes_loss: 0.0266
09/16 07:19:40 AM: Update 23860: task edges-ner-ontonotes, batch 860 (23860): mcc: 0.9222, acc: 0.8885, precision: 0.9428, recall: 0.9103, f1: 0.9263, edges-ner-ontonotes_loss: 0.0262
09/16 07:19:40 AM: Update 24748: task edges-ner-ontonotes, batch 748 (24748): mcc: 0.9416, acc: 0.9132, precision: 0.9558, recall: 0.9340, f1: 0.9448, edges-ner-ontonotes_loss: 0.0200
09/16 07:19:50 AM: Update 23931: task edges-ner-ontonotes, batch 931 (23931): mcc: 0.9230, acc: 0.8898, precision: 0.9433, recall: 0.9114, f1: 0.9271, edges-ner-ontonotes_loss: 0.0258
09/16 07:19:50 AM: Update 24819: task edges-ner-ontonotes, batch 819 (24819): mcc: 0.9395, acc: 0.9104, precision: 0.9545, recall: 0.9312, f1: 0.9427, edges-ner-ontonotes_loss: 0.0209
09/16 07:20:00 AM: Update 23985: task edges-ner-ontonotes, batch 985 (23985): mcc: 0.9241, acc: 0.8910, precision: 0.9440, recall: 0.9127, f1: 0.9281, edges-ner-ontonotes_loss: 0.0254
09/16 07:20:01 AM: Update 24897: task edges-ner-ontonotes, batch 897 (24897): mcc: 0.9376, acc: 0.9081, precision: 0.9534, recall: 0.9289, f1: 0.9410, edges-ner-ontonotes_loss: 0.0217
09/16 07:20:02 AM: ***** Step 24000 / Validation 24 *****
09/16 07:20:03 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:20:03 AM: Validating...
09/16 07:20:10 AM: Evaluate: task edges-ner-ontonotes, batch 52 (157): mcc: 0.9224, acc: 0.8951, precision: 0.9415, recall: 0.9121, f1: 0.9266, edges-ner-ontonotes_loss: 0.0263
09/16 07:20:13 AM: Update 24959: task edges-ner-ontonotes, batch 959 (24959): mcc: 0.9367, acc: 0.9069, precision: 0.9528, recall: 0.9278, f1: 0.9401, edges-ner-ontonotes_loss: 0.0220
09/16 07:20:20 AM: Evaluate: task edges-ner-ontonotes, batch 112 (157): mcc: 0.9349, acc: 0.9097, precision: 0.9524, recall: 0.9246, f1: 0.9383, edges-ner-ontonotes_loss: 0.0218
09/16 07:20:21 AM: ***** Step 25000 / Validation 25 *****
09/16 07:20:21 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:20:21 AM: Validating...
09/16 07:20:24 AM: Evaluate: task edges-ner-ontonotes, batch 17 (157): mcc: 0.8935, acc: 0.8522, precision: 0.9249, recall: 0.8743, f1: 0.8989, edges-ner-ontonotes_loss: 0.0298
09/16 07:20:30 AM: Updating LR scheduler:
09/16 07:20:30 AM: 	Best result seen so far for macro_avg: 0.948
09/16 07:20:30 AM: 	# validation passes without improvement: 1
09/16 07:20:30 AM: edges-ner-ontonotes_loss: training: 0.025291 validation: 0.018991
09/16 07:20:30 AM: macro_avg: validation: 0.947340
09/16 07:20:30 AM: micro_avg: validation: 0.000000
09/16 07:20:30 AM: edges-ner-ontonotes_mcc: training: 0.924600 validation: 0.944352
09/16 07:20:30 AM: edges-ner-ontonotes_acc: training: 0.891639 validation: 0.922429
09/16 07:20:30 AM: edges-ner-ontonotes_precision: training: 0.944389 validation: 0.958479
09/16 07:20:30 AM: edges-ner-ontonotes_recall: training: 0.913296 validation: 0.936457
09/16 07:20:30 AM: edges-ner-ontonotes_f1: training: 0.928582 validation: 0.947340
09/16 07:20:30 AM: Global learning rate: 0.0001
09/16 07:20:30 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:20:32 AM: Update 24001: task edges-ner-ontonotes, batch 1 (24001): mcc: 0.9647, acc: 0.9500, precision: 0.9667, recall: 0.9667, f1: 0.9667, edges-ner-ontonotes_loss: 0.0109
09/16 07:20:34 AM: Evaluate: task edges-ner-ontonotes, batch 70 (157): mcc: 0.9262, acc: 0.8987, precision: 0.9457, recall: 0.9150, f1: 0.9301, edges-ner-ontonotes_loss: 0.0249
09/16 07:20:42 AM: Update 24059: task edges-ner-ontonotes, batch 59 (24059): mcc: 0.9502, acc: 0.9253, precision: 0.9576, recall: 0.9483, f1: 0.9529, edges-ner-ontonotes_loss: 0.0164
09/16 07:20:44 AM: Evaluate: task edges-ner-ontonotes, batch 119 (157): mcc: 0.9373, acc: 0.9129, precision: 0.9551, recall: 0.9265, f1: 0.9406, edges-ner-ontonotes_loss: 0.0213
09/16 07:20:51 AM: Updating LR scheduler:
09/16 07:20:51 AM: 	Best result seen so far for macro_avg: 0.948
09/16 07:20:51 AM: 	# validation passes without improvement: 2
09/16 07:20:51 AM: edges-ner-ontonotes_loss: training: 0.022245 validation: 0.019114
09/16 07:20:51 AM: macro_avg: validation: 0.946907
09/16 07:20:51 AM: micro_avg: validation: 0.000000
09/16 07:20:51 AM: edges-ner-ontonotes_mcc: training: 0.936196 validation: 0.943922
09/16 07:20:51 AM: edges-ner-ontonotes_acc: training: 0.906173 validation: 0.921292
09/16 07:20:51 AM: edges-ner-ontonotes_precision: training: 0.952409 validation: 0.959664
09/16 07:20:51 AM: edges-ner-ontonotes_recall: training: 0.927137 validation: 0.934486
09/16 07:20:51 AM: edges-ner-ontonotes_f1: training: 0.939603 validation: 0.946907
09/16 07:20:51 AM: Global learning rate: 0.0001
09/16 07:20:51 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:20:52 AM: Update 24113: task edges-ner-ontonotes, batch 113 (24113): mcc: 0.9520, acc: 0.9268, precision: 0.9624, recall: 0.9469, f1: 0.9546, edges-ner-ontonotes_loss: 0.0157
09/16 07:20:54 AM: Update 25023: task edges-ner-ontonotes, batch 23 (25023): mcc: 0.9234, acc: 0.8905, precision: 0.9420, recall: 0.9133, f1: 0.9275, edges-ner-ontonotes_loss: 0.0245
09/16 07:21:02 AM: Update 24193: task edges-ner-ontonotes, batch 193 (24193): mcc: 0.9508, acc: 0.9255, precision: 0.9613, recall: 0.9457, f1: 0.9534, edges-ner-ontonotes_loss: 0.0164
09/16 07:21:04 AM: Update 25107: task edges-ner-ontonotes, batch 107 (25107): mcc: 0.9205, acc: 0.8849, precision: 0.9432, recall: 0.9069, f1: 0.9247, edges-ner-ontonotes_loss: 0.0258
09/16 07:21:12 AM: Update 24271: task edges-ner-ontonotes, batch 271 (24271): mcc: 0.9507, acc: 0.9248, precision: 0.9613, recall: 0.9456, f1: 0.9534, edges-ner-ontonotes_loss: 0.0162
09/16 07:21:14 AM: Update 25195: task edges-ner-ontonotes, batch 195 (25195): mcc: 0.9220, acc: 0.8877, precision: 0.9440, recall: 0.9089, f1: 0.9261, edges-ner-ontonotes_loss: 0.0253
09/16 07:21:22 AM: Update 24331: task edges-ner-ontonotes, batch 331 (24331): mcc: 0.9497, acc: 0.9232, precision: 0.9611, recall: 0.9438, f1: 0.9524, edges-ner-ontonotes_loss: 0.0164
09/16 07:21:24 AM: Update 25249: task edges-ner-ontonotes, batch 249 (25249): mcc: 0.9230, acc: 0.8889, precision: 0.9437, recall: 0.9110, f1: 0.9270, edges-ner-ontonotes_loss: 0.0250
09/16 07:21:32 AM: Update 24402: task edges-ner-ontonotes, batch 402 (24402): mcc: 0.9503, acc: 0.9244, precision: 0.9613, recall: 0.9448, f1: 0.9530, edges-ner-ontonotes_loss: 0.0164
09/16 07:21:34 AM: Update 25321: task edges-ner-ontonotes, batch 321 (25321): mcc: 0.9261, acc: 0.8932, precision: 0.9456, recall: 0.9148, f1: 0.9300, edges-ner-ontonotes_loss: 0.0242
09/16 07:21:42 AM: Update 24481: task edges-ner-ontonotes, batch 481 (24481): mcc: 0.9497, acc: 0.9237, precision: 0.9608, recall: 0.9442, f1: 0.9524, edges-ner-ontonotes_loss: 0.0166
09/16 07:21:45 AM: Update 25397: task edges-ner-ontonotes, batch 397 (25397): mcc: 0.9288, acc: 0.8972, precision: 0.9474, recall: 0.9181, f1: 0.9325, edges-ner-ontonotes_loss: 0.0235
09/16 07:21:52 AM: Update 24553: task edges-ner-ontonotes, batch 553 (24553): mcc: 0.9496, acc: 0.9236, precision: 0.9610, recall: 0.9438, f1: 0.9523, edges-ner-ontonotes_loss: 0.0166
09/16 07:21:55 AM: Update 25470: task edges-ner-ontonotes, batch 470 (25470): mcc: 0.9305, acc: 0.8993, precision: 0.9484, recall: 0.9203, f1: 0.9342, edges-ner-ontonotes_loss: 0.0230
09/16 07:22:02 AM: Update 24622: task edges-ner-ontonotes, batch 622 (24622): mcc: 0.9473, acc: 0.9207, precision: 0.9594, recall: 0.9411, f1: 0.9502, edges-ner-ontonotes_loss: 0.0175
09/16 07:22:07 AM: Update 25530: task edges-ner-ontonotes, batch 530 (25530): mcc: 0.9311, acc: 0.9004, precision: 0.9485, recall: 0.9215, f1: 0.9348, edges-ner-ontonotes_loss: 0.0228
09/16 07:22:12 AM: Update 24709: task edges-ner-ontonotes, batch 709 (24709): mcc: 0.9432, acc: 0.9152, precision: 0.9569, recall: 0.9359, f1: 0.9463, edges-ner-ontonotes_loss: 0.0193
09/16 07:22:18 AM: Update 25603: task edges-ner-ontonotes, batch 603 (25603): mcc: 0.9338, acc: 0.9041, precision: 0.9504, recall: 0.9247, f1: 0.9373, edges-ner-ontonotes_loss: 0.0222
09/16 07:22:22 AM: Update 24779: task edges-ner-ontonotes, batch 779 (24779): mcc: 0.9412, acc: 0.9126, precision: 0.9555, recall: 0.9334, f1: 0.9444, edges-ner-ontonotes_loss: 0.0202
09/16 07:22:28 AM: Update 25677: task edges-ner-ontonotes, batch 677 (25677): mcc: 0.9360, acc: 0.9069, precision: 0.9520, recall: 0.9272, f1: 0.9395, edges-ner-ontonotes_loss: 0.0215
09/16 07:22:33 AM: Update 24855: task edges-ner-ontonotes, batch 855 (24855): mcc: 0.9387, acc: 0.9095, precision: 0.9541, recall: 0.9302, f1: 0.9420, edges-ner-ontonotes_loss: 0.0212
09/16 07:22:38 AM: Update 25751: task edges-ner-ontonotes, batch 751 (25751): mcc: 0.9373, acc: 0.9085, precision: 0.9528, recall: 0.9289, f1: 0.9407, edges-ner-ontonotes_loss: 0.0210
09/16 07:22:43 AM: Update 24911: task edges-ner-ontonotes, batch 911 (24911): mcc: 0.9372, acc: 0.9076, precision: 0.9531, recall: 0.9284, f1: 0.9406, edges-ner-ontonotes_loss: 0.0218
09/16 07:22:48 AM: Update 25833: task edges-ner-ontonotes, batch 833 (25833): mcc: 0.9394, acc: 0.9111, precision: 0.9541, recall: 0.9314, f1: 0.9426, edges-ner-ontonotes_loss: 0.0204
09/16 07:22:53 AM: Update 24999: task edges-ner-ontonotes, batch 999 (24999): mcc: 0.9362, acc: 0.9062, precision: 0.9524, recall: 0.9271, f1: 0.9396, edges-ner-ontonotes_loss: 0.0222
09/16 07:22:53 AM: ***** Step 25000 / Validation 25 *****
09/16 07:22:53 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:22:53 AM: Validating...
09/16 07:22:58 AM: Update 25888: task edges-ner-ontonotes, batch 888 (25888): mcc: 0.9399, acc: 0.9115, precision: 0.9545, recall: 0.9319, f1: 0.9431, edges-ner-ontonotes_loss: 0.0202
09/16 07:23:03 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.9289, acc: 0.9041, precision: 0.9451, recall: 0.9207, f1: 0.9327, edges-ner-ontonotes_loss: 0.0241
09/16 07:23:08 AM: Update 25952: task edges-ner-ontonotes, batch 952 (25952): mcc: 0.9401, acc: 0.9119, precision: 0.9546, recall: 0.9324, f1: 0.9433, edges-ner-ontonotes_loss: 0.0200
09/16 07:23:14 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9359, acc: 0.9112, precision: 0.9540, recall: 0.9251, f1: 0.9393, edges-ner-ontonotes_loss: 0.0216
09/16 07:23:16 AM: ***** Step 26000 / Validation 26 *****
09/16 07:23:16 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:23:16 AM: Validating...
09/16 07:23:19 AM: Evaluate: task edges-ner-ontonotes, batch 15 (157): mcc: 0.8756, acc: 0.8335, precision: 0.9084, recall: 0.8570, f1: 0.8819, edges-ner-ontonotes_loss: 0.0353
09/16 07:23:25 AM: Updating LR scheduler:
09/16 07:23:25 AM: 	Best result seen so far for macro_avg: 0.948
09/16 07:23:25 AM: 	# validation passes without improvement: 2
09/16 07:23:25 AM: edges-ner-ontonotes_loss: training: 0.022245 validation: 0.019114
09/16 07:23:25 AM: macro_avg: validation: 0.946907
09/16 07:23:25 AM: micro_avg: validation: 0.000000
09/16 07:23:25 AM: edges-ner-ontonotes_mcc: training: 0.936196 validation: 0.943922
09/16 07:23:25 AM: edges-ner-ontonotes_acc: training: 0.906173 validation: 0.921292
09/16 07:23:25 AM: edges-ner-ontonotes_precision: training: 0.952409 validation: 0.959664
09/16 07:23:25 AM: edges-ner-ontonotes_recall: training: 0.927137 validation: 0.934486
09/16 07:23:25 AM: edges-ner-ontonotes_f1: training: 0.939603 validation: 0.946907
09/16 07:23:25 AM: Global learning rate: 0.0001
09/16 07:23:25 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:23:27 AM: Update 25001: task edges-ner-ontonotes, batch 1 (25001): mcc: 0.9037, acc: 0.8788, precision: 0.9091, recall: 0.9091, f1: 0.9091, edges-ner-ontonotes_loss: 0.0309
09/16 07:23:29 AM: Evaluate: task edges-ner-ontonotes, batch 72 (157): mcc: 0.9252, acc: 0.8971, precision: 0.9438, recall: 0.9149, f1: 0.9292, edges-ner-ontonotes_loss: 0.0265
09/16 07:23:37 AM: Update 25062: task edges-ner-ontonotes, batch 62 (25062): mcc: 0.9222, acc: 0.8876, precision: 0.9435, recall: 0.9096, f1: 0.9262, edges-ner-ontonotes_loss: 0.0246
09/16 07:23:39 AM: Evaluate: task edges-ner-ontonotes, batch 127 (157): mcc: 0.9402, acc: 0.9171, precision: 0.9541, recall: 0.9330, f1: 0.9434, edges-ner-ontonotes_loss: 0.0212
09/16 07:23:44 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:23:44 AM: Best result seen so far for macro.
09/16 07:23:44 AM: Updating LR scheduler:
09/16 07:23:44 AM: 	Best result seen so far for macro_avg: 0.948
09/16 07:23:44 AM: 	# validation passes without improvement: 0
09/16 07:23:44 AM: edges-ner-ontonotes_loss: training: 0.019904 validation: 0.019278
09/16 07:23:44 AM: macro_avg: validation: 0.948065
09/16 07:23:44 AM: micro_avg: validation: 0.000000
09/16 07:23:44 AM: edges-ner-ontonotes_mcc: training: 0.940579 validation: 0.945088
09/16 07:23:44 AM: edges-ner-ontonotes_acc: training: 0.912538 validation: 0.923188
09/16 07:23:44 AM: edges-ner-ontonotes_precision: training: 0.954897 validation: 0.957113
09/16 07:23:44 AM: edges-ner-ontonotes_recall: training: 0.932908 validation: 0.939187
09/16 07:23:44 AM: edges-ner-ontonotes_f1: training: 0.943775 validation: 0.948065
09/16 07:23:44 AM: Global learning rate: 0.0001
09/16 07:23:44 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:23:48 AM: Update 25130: task edges-ner-ontonotes, batch 130 (25130): mcc: 0.9214, acc: 0.8862, precision: 0.9439, recall: 0.9078, f1: 0.9255, edges-ner-ontonotes_loss: 0.0253
09/16 07:23:49 AM: Update 26036: task edges-ner-ontonotes, batch 36 (26036): mcc: 0.9510, acc: 0.9246, precision: 0.9623, recall: 0.9451, f1: 0.9536, edges-ner-ontonotes_loss: 0.0146
09/16 07:23:59 AM: Update 26127: task edges-ner-ontonotes, batch 127 (26127): mcc: 0.9495, acc: 0.9234, precision: 0.9610, recall: 0.9435, f1: 0.9522, edges-ner-ontonotes_loss: 0.0164
09/16 07:24:00 AM: Update 25210: task edges-ner-ontonotes, batch 210 (25210): mcc: 0.9212, acc: 0.8866, precision: 0.9431, recall: 0.9083, f1: 0.9253, edges-ner-ontonotes_loss: 0.0254
09/16 07:24:09 AM: Update 26179: task edges-ner-ontonotes, batch 179 (26179): mcc: 0.9430, acc: 0.9147, precision: 0.9569, recall: 0.9354, f1: 0.9460, edges-ner-ontonotes_loss: 0.0193
09/16 07:24:10 AM: Update 25286: task edges-ner-ontonotes, batch 286 (25286): mcc: 0.9253, acc: 0.8918, precision: 0.9456, recall: 0.9135, f1: 0.9293, edges-ner-ontonotes_loss: 0.0245
09/16 07:24:19 AM: Update 26251: task edges-ner-ontonotes, batch 251 (26251): mcc: 0.9361, acc: 0.9058, precision: 0.9518, recall: 0.9275, f1: 0.9395, edges-ner-ontonotes_loss: 0.0225
09/16 07:24:20 AM: Update 25361: task edges-ner-ontonotes, batch 361 (25361): mcc: 0.9277, acc: 0.8956, precision: 0.9469, recall: 0.9167, f1: 0.9315, edges-ner-ontonotes_loss: 0.0238
09/16 07:24:29 AM: Update 26327: task edges-ner-ontonotes, batch 327 (26327): mcc: 0.9303, acc: 0.8983, precision: 0.9490, recall: 0.9196, f1: 0.9340, edges-ner-ontonotes_loss: 0.0244
09/16 07:24:30 AM: Update 25442: task edges-ner-ontonotes, batch 442 (25442): mcc: 0.9303, acc: 0.8991, precision: 0.9483, recall: 0.9202, f1: 0.9340, edges-ner-ontonotes_loss: 0.0231
09/16 07:24:39 AM: Update 26399: task edges-ner-ontonotes, batch 399 (26399): mcc: 0.9284, acc: 0.8958, precision: 0.9478, recall: 0.9171, f1: 0.9322, edges-ner-ontonotes_loss: 0.0254
09/16 07:24:40 AM: Update 25517: task edges-ner-ontonotes, batch 517 (25517): mcc: 0.9307, acc: 0.8998, precision: 0.9484, recall: 0.9208, f1: 0.9344, edges-ner-ontonotes_loss: 0.0229
09/16 07:24:49 AM: Update 26468: task edges-ner-ontonotes, batch 468 (26468): mcc: 0.9264, acc: 0.8933, precision: 0.9465, recall: 0.9146, f1: 0.9302, edges-ner-ontonotes_loss: 0.0262
09/16 07:24:50 AM: Update 25576: task edges-ner-ontonotes, batch 576 (25576): mcc: 0.9328, acc: 0.9027, precision: 0.9497, recall: 0.9234, f1: 0.9364, edges-ner-ontonotes_loss: 0.0224
09/16 07:24:59 AM: Update 26550: task edges-ner-ontonotes, batch 550 (26550): mcc: 0.9254, acc: 0.8919, precision: 0.9456, recall: 0.9136, f1: 0.9293, edges-ner-ontonotes_loss: 0.0263
09/16 07:25:00 AM: Update 25654: task edges-ner-ontonotes, batch 654 (25654): mcc: 0.9356, acc: 0.9064, precision: 0.9518, recall: 0.9266, f1: 0.9390, edges-ner-ontonotes_loss: 0.0217
09/16 07:25:10 AM: Update 26633: task edges-ner-ontonotes, batch 633 (26633): mcc: 0.9245, acc: 0.8908, precision: 0.9449, recall: 0.9127, f1: 0.9285, edges-ner-ontonotes_loss: 0.0262
09/16 07:25:10 AM: Update 25733: task edges-ner-ontonotes, batch 733 (25733): mcc: 0.9370, acc: 0.9082, precision: 0.9525, recall: 0.9287, f1: 0.9404, edges-ner-ontonotes_loss: 0.0211
09/16 07:25:20 AM: Update 26712: task edges-ner-ontonotes, batch 712 (26712): mcc: 0.9243, acc: 0.8905, precision: 0.9444, recall: 0.9126, f1: 0.9283, edges-ner-ontonotes_loss: 0.0261
09/16 07:25:20 AM: Update 25810: task edges-ner-ontonotes, batch 810 (25810): mcc: 0.9387, acc: 0.9103, precision: 0.9536, recall: 0.9307, f1: 0.9420, edges-ner-ontonotes_loss: 0.0206
09/16 07:25:30 AM: Update 26774: task edges-ner-ontonotes, batch 774 (26774): mcc: 0.9243, acc: 0.8906, precision: 0.9444, recall: 0.9128, f1: 0.9283, edges-ner-ontonotes_loss: 0.0260
09/16 07:25:30 AM: Update 25880: task edges-ner-ontonotes, batch 880 (25880): mcc: 0.9399, acc: 0.9116, precision: 0.9545, recall: 0.9319, f1: 0.9431, edges-ner-ontonotes_loss: 0.0202
09/16 07:25:41 AM: Update 25951: task edges-ner-ontonotes, batch 951 (25951): mcc: 0.9401, acc: 0.9119, precision: 0.9545, recall: 0.9323, f1: 0.9433, edges-ner-ontonotes_loss: 0.0200
09/16 07:25:41 AM: Update 26844: task edges-ner-ontonotes, batch 844 (26844): mcc: 0.9254, acc: 0.8921, precision: 0.9449, recall: 0.9143, f1: 0.9294, edges-ner-ontonotes_loss: 0.0255
09/16 07:25:46 AM: ***** Step 26000 / Validation 26 *****
09/16 07:25:47 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:25:47 AM: Validating...
09/16 07:25:51 AM: Evaluate: task edges-ner-ontonotes, batch 27 (157): mcc: 0.8877, acc: 0.8553, precision: 0.9129, recall: 0.8751, f1: 0.8936, edges-ner-ontonotes_loss: 0.0364
09/16 07:25:52 AM: Update 26916: task edges-ner-ontonotes, batch 916 (26916): mcc: 0.9259, acc: 0.8925, precision: 0.9451, recall: 0.9149, f1: 0.9298, edges-ner-ontonotes_loss: 0.0253
09/16 07:26:01 AM: Evaluate: task edges-ner-ontonotes, batch 82 (157): mcc: 0.9312, acc: 0.9050, precision: 0.9482, recall: 0.9219, f1: 0.9349, edges-ner-ontonotes_loss: 0.0248
09/16 07:26:03 AM: Update 26979: task edges-ner-ontonotes, batch 979 (26979): mcc: 0.9269, acc: 0.8941, precision: 0.9458, recall: 0.9163, f1: 0.9308, edges-ner-ontonotes_loss: 0.0248
09/16 07:26:08 AM: ***** Step 27000 / Validation 27 *****
09/16 07:26:09 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:26:09 AM: Validating...
09/16 07:26:11 AM: Evaluate: task edges-ner-ontonotes, batch 134 (157): mcc: 0.9428, acc: 0.9206, precision: 0.9564, recall: 0.9355, f1: 0.9459, edges-ner-ontonotes_loss: 0.0205
09/16 07:26:14 AM: Evaluate: task edges-ner-ontonotes, batch 32 (157): mcc: 0.9066, acc: 0.8776, precision: 0.9303, recall: 0.8935, f1: 0.9115, edges-ner-ontonotes_loss: 0.0291
09/16 07:26:15 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:26:15 AM: Best result seen so far for macro.
09/16 07:26:15 AM: Updating LR scheduler:
09/16 07:26:15 AM: 	Best result seen so far for macro_avg: 0.948
09/16 07:26:15 AM: 	# validation passes without improvement: 0
09/16 07:26:15 AM: edges-ner-ontonotes_loss: training: 0.019904 validation: 0.019278
09/16 07:26:15 AM: macro_avg: validation: 0.948065
09/16 07:26:15 AM: micro_avg: validation: 0.000000
09/16 07:26:15 AM: edges-ner-ontonotes_mcc: training: 0.940579 validation: 0.945088
09/16 07:26:15 AM: edges-ner-ontonotes_acc: training: 0.912538 validation: 0.923188
09/16 07:26:15 AM: edges-ner-ontonotes_precision: training: 0.954897 validation: 0.957113
09/16 07:26:15 AM: edges-ner-ontonotes_recall: training: 0.932908 validation: 0.939187
09/16 07:26:15 AM: edges-ner-ontonotes_f1: training: 0.943775 validation: 0.948065
09/16 07:26:15 AM: Global learning rate: 0.0001
09/16 07:26:15 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:26:21 AM: Update 26027: task edges-ner-ontonotes, batch 27 (26027): mcc: 0.9502, acc: 0.9226, precision: 0.9613, recall: 0.9447, f1: 0.9529, edges-ner-ontonotes_loss: 0.0144
09/16 07:26:26 AM: Evaluate: task edges-ner-ontonotes, batch 87 (157): mcc: 0.9350, acc: 0.9085, precision: 0.9554, recall: 0.9220, f1: 0.9384, edges-ner-ontonotes_loss: 0.0224
09/16 07:26:31 AM: Update 26091: task edges-ner-ontonotes, batch 91 (26091): mcc: 0.9485, acc: 0.9221, precision: 0.9609, recall: 0.9418, f1: 0.9513, edges-ner-ontonotes_loss: 0.0166
09/16 07:26:37 AM: Evaluate: task edges-ner-ontonotes, batch 139 (157): mcc: 0.9430, acc: 0.9200, precision: 0.9592, recall: 0.9331, f1: 0.9460, edges-ner-ontonotes_loss: 0.0193
09/16 07:26:41 AM: Updating LR scheduler:
09/16 07:26:41 AM: 	Best result seen so far for macro_avg: 0.948
09/16 07:26:41 AM: 	# validation passes without improvement: 1
09/16 07:26:41 AM: edges-ner-ontonotes_loss: training: 0.024731 validation: 0.018757
09/16 07:26:41 AM: macro_avg: validation: 0.947296
09/16 07:26:41 AM: micro_avg: validation: 0.000000
09/16 07:26:41 AM: edges-ner-ontonotes_mcc: training: 0.927333 validation: 0.944331
09/16 07:26:41 AM: edges-ner-ontonotes_acc: training: 0.894539 validation: 0.921823
09/16 07:26:41 AM: edges-ner-ontonotes_precision: training: 0.946135 validation: 0.959981
09/16 07:26:41 AM: edges-ner-ontonotes_recall: training: 0.916699 validation: 0.934941
09/16 07:26:41 AM: edges-ner-ontonotes_f1: training: 0.931184 validation: 0.947296
09/16 07:26:41 AM: Global learning rate: 0.0001
09/16 07:26:41 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:26:43 AM: Update 26149: task edges-ner-ontonotes, batch 149 (26149): mcc: 0.9501, acc: 0.9239, precision: 0.9617, recall: 0.9441, f1: 0.9528, edges-ner-ontonotes_loss: 0.0163
09/16 07:26:48 AM: Update 27057: task edges-ner-ontonotes, batch 57 (27057): mcc: 0.9307, acc: 0.9002, precision: 0.9474, recall: 0.9218, f1: 0.9344, edges-ner-ontonotes_loss: 0.0233
09/16 07:26:53 AM: Update 26228: task edges-ner-ontonotes, batch 228 (26228): mcc: 0.9375, acc: 0.9077, precision: 0.9527, recall: 0.9293, f1: 0.9409, edges-ner-ontonotes_loss: 0.0218
09/16 07:26:59 AM: Update 27113: task edges-ner-ontonotes, batch 113 (27113): mcc: 0.9380, acc: 0.9076, precision: 0.9524, recall: 0.9305, f1: 0.9413, edges-ner-ontonotes_loss: 0.0202
09/16 07:27:03 AM: Update 26307: task edges-ner-ontonotes, batch 307 (26307): mcc: 0.9318, acc: 0.9000, precision: 0.9495, recall: 0.9218, f1: 0.9355, edges-ner-ontonotes_loss: 0.0240
09/16 07:27:10 AM: Update 27185: task edges-ner-ontonotes, batch 185 (27185): mcc: 0.9427, acc: 0.9151, precision: 0.9557, recall: 0.9361, f1: 0.9458, edges-ner-ontonotes_loss: 0.0191
09/16 07:27:13 AM: Update 26377: task edges-ner-ontonotes, batch 377 (26377): mcc: 0.9289, acc: 0.8963, precision: 0.9481, recall: 0.9177, f1: 0.9326, edges-ner-ontonotes_loss: 0.0249
09/16 07:27:20 AM: Update 27267: task edges-ner-ontonotes, batch 267 (27267): mcc: 0.9457, acc: 0.9194, precision: 0.9578, recall: 0.9396, f1: 0.9486, edges-ner-ontonotes_loss: 0.0180
09/16 07:27:28 AM: Update 26453: task edges-ner-ontonotes, batch 453 (26453): mcc: 0.9270, acc: 0.8939, precision: 0.9471, recall: 0.9151, f1: 0.9308, edges-ner-ontonotes_loss: 0.0260
09/16 07:27:30 AM: Update 27348: task edges-ner-ontonotes, batch 348 (27348): mcc: 0.9473, acc: 0.9213, precision: 0.9596, recall: 0.9410, f1: 0.9502, edges-ner-ontonotes_loss: 0.0173
09/16 07:27:38 AM: Update 26544: task edges-ner-ontonotes, batch 544 (26544): mcc: 0.9254, acc: 0.8919, precision: 0.9458, recall: 0.9134, f1: 0.9293, edges-ner-ontonotes_loss: 0.0263
09/16 07:27:40 AM: Update 27411: task edges-ner-ontonotes, batch 411 (27411): mcc: 0.9478, acc: 0.9221, precision: 0.9597, recall: 0.9418, f1: 0.9507, edges-ner-ontonotes_loss: 0.0173
09/16 07:27:48 AM: Update 26627: task edges-ner-ontonotes, batch 627 (26627): mcc: 0.9246, acc: 0.8909, precision: 0.9449, recall: 0.9129, f1: 0.9286, edges-ner-ontonotes_loss: 0.0262
09/16 07:27:50 AM: Update 27486: task edges-ner-ontonotes, batch 486 (27486): mcc: 0.9488, acc: 0.9231, precision: 0.9607, recall: 0.9427, f1: 0.9516, edges-ner-ontonotes_loss: 0.0169
09/16 07:27:58 AM: Update 26711: task edges-ner-ontonotes, batch 711 (26711): mcc: 0.9243, acc: 0.8906, precision: 0.9445, recall: 0.9127, f1: 0.9283, edges-ner-ontonotes_loss: 0.0261
09/16 07:28:00 AM: Update 27561: task edges-ner-ontonotes, batch 561 (27561): mcc: 0.9487, acc: 0.9227, precision: 0.9603, recall: 0.9428, f1: 0.9514, edges-ner-ontonotes_loss: 0.0169
09/16 07:28:08 AM: Update 26770: task edges-ner-ontonotes, batch 770 (26770): mcc: 0.9244, acc: 0.8907, precision: 0.9444, recall: 0.9129, f1: 0.9284, edges-ner-ontonotes_loss: 0.0260
09/16 07:28:10 AM: Update 27644: task edges-ner-ontonotes, batch 644 (27644): mcc: 0.9485, acc: 0.9224, precision: 0.9603, recall: 0.9424, f1: 0.9513, edges-ner-ontonotes_loss: 0.0169
09/16 07:28:18 AM: Update 26845: task edges-ner-ontonotes, batch 845 (26845): mcc: 0.9255, acc: 0.8921, precision: 0.9450, recall: 0.9143, f1: 0.9294, edges-ner-ontonotes_loss: 0.0255
09/16 07:28:21 AM: Update 27705: task edges-ner-ontonotes, batch 705 (27705): mcc: 0.9482, acc: 0.9221, precision: 0.9601, recall: 0.9420, f1: 0.9510, edges-ner-ontonotes_loss: 0.0171
09/16 07:28:29 AM: Update 26925: task edges-ner-ontonotes, batch 925 (26925): mcc: 0.9260, acc: 0.8927, precision: 0.9453, recall: 0.9151, f1: 0.9299, edges-ner-ontonotes_loss: 0.0252
09/16 07:28:31 AM: Update 27778: task edges-ner-ontonotes, batch 778 (27778): mcc: 0.9451, acc: 0.9184, precision: 0.9581, recall: 0.9383, f1: 0.9481, edges-ner-ontonotes_loss: 0.0182
09/16 07:28:39 AM: Update 27000: task edges-ner-ontonotes, batch 1000 (27000): mcc: 0.9273, acc: 0.8945, precision: 0.9461, recall: 0.9167, f1: 0.9312, edges-ner-ontonotes_loss: 0.0247
09/16 07:28:39 AM: ***** Step 27000 / Validation 27 *****
09/16 07:28:39 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:28:39 AM: Validating...
09/16 07:28:41 AM: Update 27852: task edges-ner-ontonotes, batch 852 (27852): mcc: 0.9422, acc: 0.9146, precision: 0.9560, recall: 0.9348, f1: 0.9453, edges-ner-ontonotes_loss: 0.0196
09/16 07:28:49 AM: Evaluate: task edges-ner-ontonotes, batch 64 (157): mcc: 0.9285, acc: 0.9022, precision: 0.9472, recall: 0.9179, f1: 0.9323, edges-ner-ontonotes_loss: 0.0238
09/16 07:28:51 AM: Update 27908: task edges-ner-ontonotes, batch 908 (27908): mcc: 0.9405, acc: 0.9126, precision: 0.9551, recall: 0.9327, f1: 0.9437, edges-ner-ontonotes_loss: 0.0203
09/16 07:28:59 AM: Evaluate: task edges-ner-ontonotes, batch 116 (157): mcc: 0.9370, acc: 0.9112, precision: 0.9554, recall: 0.9257, f1: 0.9403, edges-ner-ontonotes_loss: 0.0210
09/16 07:29:01 AM: Update 27964: task edges-ner-ontonotes, batch 964 (27964): mcc: 0.9391, acc: 0.9108, precision: 0.9542, recall: 0.9309, f1: 0.9424, edges-ner-ontonotes_loss: 0.0210
09/16 07:29:06 AM: Updating LR scheduler:
09/16 07:29:06 AM: 	Best result seen so far for macro_avg: 0.948
09/16 07:29:06 AM: 	# validation passes without improvement: 1
09/16 07:29:06 AM: edges-ner-ontonotes_loss: training: 0.024731 validation: 0.018757
09/16 07:29:06 AM: macro_avg: validation: 0.947296
09/16 07:29:06 AM: micro_avg: validation: 0.000000
09/16 07:29:06 AM: edges-ner-ontonotes_mcc: training: 0.927333 validation: 0.944331
09/16 07:29:06 AM: edges-ner-ontonotes_acc: training: 0.894539 validation: 0.921823
09/16 07:29:06 AM: edges-ner-ontonotes_precision: training: 0.946135 validation: 0.959981
09/16 07:29:06 AM: edges-ner-ontonotes_recall: training: 0.916699 validation: 0.934941
09/16 07:29:06 AM: edges-ner-ontonotes_f1: training: 0.931184 validation: 0.947296
09/16 07:29:06 AM: Global learning rate: 0.0001
09/16 07:29:06 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:29:07 AM: ***** Step 28000 / Validation 28 *****
09/16 07:29:07 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:29:07 AM: Validating...
09/16 07:29:09 AM: Update 27002: task edges-ner-ontonotes, batch 2 (27002): mcc: 0.9456, acc: 0.9032, precision: 0.9665, recall: 0.9309, f1: 0.9484, edges-ner-ontonotes_loss: 0.0155
09/16 07:29:11 AM: Evaluate: task edges-ner-ontonotes, batch 34 (157): mcc: 0.9094, acc: 0.8798, precision: 0.9319, recall: 0.8970, f1: 0.9141, edges-ner-ontonotes_loss: 0.0297
09/16 07:29:19 AM: Update 27058: task edges-ner-ontonotes, batch 58 (27058): mcc: 0.9311, acc: 0.9007, precision: 0.9477, recall: 0.9222, f1: 0.9348, edges-ner-ontonotes_loss: 0.0231
09/16 07:29:21 AM: Evaluate: task edges-ner-ontonotes, batch 89 (157): mcc: 0.9347, acc: 0.9088, precision: 0.9548, recall: 0.9220, f1: 0.9381, edges-ner-ontonotes_loss: 0.0230
09/16 07:29:29 AM: Update 27100: task edges-ner-ontonotes, batch 100 (27100): mcc: 0.9359, acc: 0.9051, precision: 0.9509, recall: 0.9281, f1: 0.9394, edges-ner-ontonotes_loss: 0.0210
09/16 07:29:31 AM: Evaluate: task edges-ner-ontonotes, batch 144 (157): mcc: 0.9439, acc: 0.9212, precision: 0.9600, recall: 0.9341, f1: 0.9469, edges-ner-ontonotes_loss: 0.0197
09/16 07:29:34 AM: Updating LR scheduler:
09/16 07:29:34 AM: 	Best result seen so far for macro_avg: 0.948
09/16 07:29:34 AM: 	# validation passes without improvement: 2
09/16 07:29:34 AM: edges-ner-ontonotes_loss: training: 0.021349 validation: 0.019227
09/16 07:29:34 AM: macro_avg: validation: 0.947797
09/16 07:29:34 AM: micro_avg: validation: 0.000000
09/16 07:29:34 AM: edges-ner-ontonotes_mcc: training: 0.938318 validation: 0.944861
09/16 07:29:34 AM: edges-ner-ontonotes_acc: training: 0.909649 validation: 0.922429
09/16 07:29:34 AM: edges-ner-ontonotes_precision: training: 0.953605 validation: 0.960452
09/16 07:29:34 AM: edges-ner-ontonotes_recall: training: 0.929940 validation: 0.935472
09/16 07:29:34 AM: edges-ner-ontonotes_f1: training: 0.941624 validation: 0.947797
09/16 07:29:34 AM: Global learning rate: 0.0001
09/16 07:29:34 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:29:39 AM: Update 27177: task edges-ner-ontonotes, batch 177 (27177): mcc: 0.9423, acc: 0.9147, precision: 0.9550, recall: 0.9360, f1: 0.9454, edges-ner-ontonotes_loss: 0.0191
09/16 07:29:41 AM: Update 28037: task edges-ner-ontonotes, batch 37 (28037): mcc: 0.9133, acc: 0.8764, precision: 0.9381, recall: 0.8984, f1: 0.9178, edges-ner-ontonotes_loss: 0.0277
09/16 07:29:49 AM: Update 27253: task edges-ner-ontonotes, batch 253 (27253): mcc: 0.9452, acc: 0.9185, precision: 0.9576, recall: 0.9388, f1: 0.9481, edges-ner-ontonotes_loss: 0.0181
09/16 07:29:52 AM: Update 28117: task edges-ner-ontonotes, batch 117 (28117): mcc: 0.9192, acc: 0.8849, precision: 0.9404, recall: 0.9072, f1: 0.9235, edges-ner-ontonotes_loss: 0.0267
09/16 07:30:00 AM: Update 27333: task edges-ner-ontonotes, batch 333 (27333): mcc: 0.9469, acc: 0.9208, precision: 0.9591, recall: 0.9407, f1: 0.9498, edges-ner-ontonotes_loss: 0.0175
09/16 07:30:02 AM: Update 28203: task edges-ner-ontonotes, batch 203 (28203): mcc: 0.9190, acc: 0.8836, precision: 0.9395, recall: 0.9075, f1: 0.9232, edges-ner-ontonotes_loss: 0.0270
09/16 07:30:11 AM: Update 27393: task edges-ner-ontonotes, batch 393 (27393): mcc: 0.9480, acc: 0.9224, precision: 0.9598, recall: 0.9420, f1: 0.9508, edges-ner-ontonotes_loss: 0.0172
09/16 07:30:12 AM: Update 28296: task edges-ner-ontonotes, batch 296 (28296): mcc: 0.9215, acc: 0.8872, precision: 0.9417, recall: 0.9102, f1: 0.9257, edges-ner-ontonotes_loss: 0.0260
09/16 07:30:21 AM: Update 27475: task edges-ner-ontonotes, batch 475 (27475): mcc: 0.9488, acc: 0.9231, precision: 0.9607, recall: 0.9425, f1: 0.9515, edges-ner-ontonotes_loss: 0.0169
09/16 07:30:22 AM: Update 28356: task edges-ner-ontonotes, batch 356 (28356): mcc: 0.9226, acc: 0.8883, precision: 0.9424, recall: 0.9115, f1: 0.9267, edges-ner-ontonotes_loss: 0.0257
09/16 07:30:31 AM: Update 27551: task edges-ner-ontonotes, batch 551 (27551): mcc: 0.9488, acc: 0.9229, precision: 0.9604, recall: 0.9429, f1: 0.9516, edges-ner-ontonotes_loss: 0.0168
09/16 07:30:32 AM: Update 28428: task edges-ner-ontonotes, batch 428 (28428): mcc: 0.9249, acc: 0.8913, precision: 0.9444, recall: 0.9138, f1: 0.9289, edges-ner-ontonotes_loss: 0.0249
09/16 07:30:41 AM: Update 27619: task edges-ner-ontonotes, batch 619 (27619): mcc: 0.9483, acc: 0.9223, precision: 0.9600, recall: 0.9425, f1: 0.9511, edges-ner-ontonotes_loss: 0.0170
09/16 07:30:42 AM: Update 28503: task edges-ner-ontonotes, batch 503 (28503): mcc: 0.9267, acc: 0.8940, precision: 0.9455, recall: 0.9163, f1: 0.9306, edges-ner-ontonotes_loss: 0.0245
09/16 07:30:51 AM: Update 27692: task edges-ner-ontonotes, batch 692 (27692): mcc: 0.9482, acc: 0.9222, precision: 0.9601, recall: 0.9422, f1: 0.9510, edges-ner-ontonotes_loss: 0.0171
09/16 07:30:52 AM: Update 28583: task edges-ner-ontonotes, batch 583 (28583): mcc: 0.9279, acc: 0.8959, precision: 0.9460, recall: 0.9179, f1: 0.9317, edges-ner-ontonotes_loss: 0.0239
09/16 07:31:01 AM: Update 27746: task edges-ner-ontonotes, batch 746 (27746): mcc: 0.9462, acc: 0.9197, precision: 0.9589, recall: 0.9396, f1: 0.9491, edges-ner-ontonotes_loss: 0.0177
09/16 07:31:02 AM: Update 28647: task edges-ner-ontonotes, batch 647 (28647): mcc: 0.9292, acc: 0.8976, precision: 0.9469, recall: 0.9193, f1: 0.9329, edges-ner-ontonotes_loss: 0.0236
09/16 07:31:11 AM: Update 27817: task edges-ner-ontonotes, batch 817 (27817): mcc: 0.9435, acc: 0.9162, precision: 0.9570, recall: 0.9363, f1: 0.9465, edges-ner-ontonotes_loss: 0.0189
09/16 07:31:12 AM: Update 28718: task edges-ner-ontonotes, batch 718 (28718): mcc: 0.9323, acc: 0.9016, precision: 0.9491, recall: 0.9230, f1: 0.9359, edges-ner-ontonotes_loss: 0.0227
09/16 07:31:21 AM: Update 27893: task edges-ner-ontonotes, batch 893 (27893): mcc: 0.9409, acc: 0.9130, precision: 0.9552, recall: 0.9332, f1: 0.9441, edges-ner-ontonotes_loss: 0.0201
09/16 07:31:22 AM: Update 28794: task edges-ner-ontonotes, batch 794 (28794): mcc: 0.9341, acc: 0.9040, precision: 0.9501, recall: 0.9255, f1: 0.9376, edges-ner-ontonotes_loss: 0.0221
09/16 07:31:31 AM: Update 27969: task edges-ner-ontonotes, batch 969 (27969): mcc: 0.9390, acc: 0.9106, precision: 0.9541, recall: 0.9307, f1: 0.9423, edges-ner-ontonotes_loss: 0.0210
09/16 07:31:33 AM: Update 28872: task edges-ner-ontonotes, batch 872 (28872): mcc: 0.9359, acc: 0.9065, precision: 0.9514, recall: 0.9275, f1: 0.9393, edges-ner-ontonotes_loss: 0.0214
09/16 07:31:36 AM: ***** Step 28000 / Validation 28 *****
09/16 07:31:36 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:31:36 AM: Validating...
09/16 07:31:42 AM: Evaluate: task edges-ner-ontonotes, batch 38 (157): mcc: 0.9129, acc: 0.8846, precision: 0.9339, recall: 0.9017, f1: 0.9175, edges-ner-ontonotes_loss: 0.0289
09/16 07:31:43 AM: Update 28939: task edges-ner-ontonotes, batch 939 (28939): mcc: 0.9370, acc: 0.9078, precision: 0.9521, recall: 0.9289, f1: 0.9403, edges-ner-ontonotes_loss: 0.0211
09/16 07:31:52 AM: Evaluate: task edges-ner-ontonotes, batch 100 (157): mcc: 0.9312, acc: 0.9042, precision: 0.9519, recall: 0.9184, f1: 0.9348, edges-ner-ontonotes_loss: 0.0233
09/16 07:31:53 AM: Update 28975: task edges-ner-ontonotes, batch 975 (28975): mcc: 0.9376, acc: 0.9085, precision: 0.9526, recall: 0.9296, f1: 0.9409, edges-ner-ontonotes_loss: 0.0209
09/16 07:31:57 AM: ***** Step 29000 / Validation 29 *****
09/16 07:31:57 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:31:57 AM: Validating...
09/16 07:32:02 AM: Evaluate: task edges-ner-ontonotes, batch 148 (157): mcc: 0.9441, acc: 0.9213, precision: 0.9602, recall: 0.9343, f1: 0.9471, edges-ner-ontonotes_loss: 0.0196
09/16 07:32:03 AM: Evaluate: task edges-ner-ontonotes, batch 35 (157): mcc: 0.9056, acc: 0.8740, precision: 0.9293, recall: 0.8925, f1: 0.9105, edges-ner-ontonotes_loss: 0.0317
09/16 07:32:06 AM: Updating LR scheduler:
09/16 07:32:06 AM: 	Best result seen so far for macro_avg: 0.948
09/16 07:32:06 AM: 	# validation passes without improvement: 2
09/16 07:32:06 AM: edges-ner-ontonotes_loss: training: 0.021349 validation: 0.019227
09/16 07:32:06 AM: macro_avg: validation: 0.947797
09/16 07:32:06 AM: micro_avg: validation: 0.000000
09/16 07:32:06 AM: edges-ner-ontonotes_mcc: training: 0.938318 validation: 0.944861
09/16 07:32:06 AM: edges-ner-ontonotes_acc: training: 0.909649 validation: 0.922429
09/16 07:32:06 AM: edges-ner-ontonotes_precision: training: 0.953605 validation: 0.960452
09/16 07:32:06 AM: edges-ner-ontonotes_recall: training: 0.929940 validation: 0.935472
09/16 07:32:06 AM: edges-ner-ontonotes_f1: training: 0.941624 validation: 0.947797
09/16 07:32:06 AM: Global learning rate: 0.0001
09/16 07:32:06 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:32:14 AM: Evaluate: task edges-ner-ontonotes, batch 94 (157): mcc: 0.9325, acc: 0.9052, precision: 0.9524, recall: 0.9202, f1: 0.9360, edges-ner-ontonotes_loss: 0.0240
09/16 07:32:14 AM: Update 28034: task edges-ner-ontonotes, batch 34 (28034): mcc: 0.9129, acc: 0.8760, precision: 0.9378, recall: 0.8979, f1: 0.9174, edges-ner-ontonotes_loss: 0.0279
09/16 07:32:25 AM: Update 28092: task edges-ner-ontonotes, batch 92 (28092): mcc: 0.9167, acc: 0.8818, precision: 0.9372, recall: 0.9055, f1: 0.9211, edges-ner-ontonotes_loss: 0.0276
09/16 07:32:25 AM: Evaluate: task edges-ner-ontonotes, batch 148 (157): mcc: 0.9429, acc: 0.9199, precision: 0.9577, recall: 0.9345, f1: 0.9460, edges-ner-ontonotes_loss: 0.0199
09/16 07:32:28 AM: Updating LR scheduler:
09/16 07:32:28 AM: 	Best result seen so far for macro_avg: 0.948
09/16 07:32:28 AM: 	# validation passes without improvement: 3
09/16 07:32:28 AM: edges-ner-ontonotes_loss: training: 0.020789 validation: 0.019490
09/16 07:32:28 AM: macro_avg: validation: 0.946823
09/16 07:32:28 AM: micro_avg: validation: 0.000000
09/16 07:32:28 AM: edges-ner-ontonotes_mcc: training: 0.937793 validation: 0.943810
09/16 07:32:28 AM: edges-ner-ontonotes_acc: training: 0.908692 validation: 0.921065
09/16 07:32:28 AM: edges-ner-ontonotes_precision: training: 0.952794 validation: 0.958295
09/16 07:32:28 AM: edges-ner-ontonotes_recall: training: 0.929753 validation: 0.935623
09/16 07:32:28 AM: edges-ner-ontonotes_f1: training: 0.941133 validation: 0.946823
09/16 07:32:28 AM: Global learning rate: 0.0001
09/16 07:32:28 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:32:37 AM: Update 29069: task edges-ner-ontonotes, batch 69 (29069): mcc: 0.9465, acc: 0.9183, precision: 0.9592, recall: 0.9398, f1: 0.9494, edges-ner-ontonotes_loss: 0.0190
09/16 07:32:37 AM: Update 28172: task edges-ner-ontonotes, batch 172 (28172): mcc: 0.9179, acc: 0.8826, precision: 0.9383, recall: 0.9068, f1: 0.9223, edges-ner-ontonotes_loss: 0.0273
09/16 07:32:47 AM: Update 28253: task edges-ner-ontonotes, batch 253 (28253): mcc: 0.9209, acc: 0.8863, precision: 0.9412, recall: 0.9095, f1: 0.9251, edges-ner-ontonotes_loss: 0.0265
09/16 07:32:47 AM: Update 29149: task edges-ner-ontonotes, batch 149 (29149): mcc: 0.9471, acc: 0.9205, precision: 0.9596, recall: 0.9406, f1: 0.9500, edges-ner-ontonotes_loss: 0.0180
09/16 07:32:57 AM: Update 29231: task edges-ner-ontonotes, batch 231 (29231): mcc: 0.9483, acc: 0.9220, precision: 0.9611, recall: 0.9413, f1: 0.9511, edges-ner-ontonotes_loss: 0.0175
09/16 07:32:58 AM: Update 28322: task edges-ner-ontonotes, batch 322 (28322): mcc: 0.9211, acc: 0.8869, precision: 0.9410, recall: 0.9101, f1: 0.9253, edges-ner-ontonotes_loss: 0.0260
09/16 07:33:07 AM: Update 29285: task edges-ner-ontonotes, batch 285 (29285): mcc: 0.9456, acc: 0.9186, precision: 0.9590, recall: 0.9382, f1: 0.9485, edges-ner-ontonotes_loss: 0.0181
09/16 07:33:08 AM: Update 28401: task edges-ner-ontonotes, batch 401 (28401): mcc: 0.9240, acc: 0.8901, precision: 0.9437, recall: 0.9129, f1: 0.9280, edges-ner-ontonotes_loss: 0.0252
09/16 07:33:17 AM: Update 29359: task edges-ner-ontonotes, batch 359 (29359): mcc: 0.9390, acc: 0.9099, precision: 0.9542, recall: 0.9305, f1: 0.9422, edges-ner-ontonotes_loss: 0.0210
09/16 07:33:18 AM: Update 28478: task edges-ner-ontonotes, batch 478 (28478): mcc: 0.9270, acc: 0.8940, precision: 0.9459, recall: 0.9163, f1: 0.9308, edges-ner-ontonotes_loss: 0.0244
09/16 07:33:27 AM: Update 29437: task edges-ner-ontonotes, batch 437 (29437): mcc: 0.9347, acc: 0.9048, precision: 0.9512, recall: 0.9256, f1: 0.9382, edges-ner-ontonotes_loss: 0.0230
09/16 07:33:28 AM: Update 28553: task edges-ner-ontonotes, batch 553 (28553): mcc: 0.9268, acc: 0.8943, precision: 0.9454, recall: 0.9165, f1: 0.9307, edges-ner-ontonotes_loss: 0.0243
09/16 07:33:37 AM: Update 29510: task edges-ner-ontonotes, batch 510 (29510): mcc: 0.9324, acc: 0.9019, precision: 0.9497, recall: 0.9228, f1: 0.9360, edges-ner-ontonotes_loss: 0.0237
09/16 07:33:38 AM: Update 28626: task edges-ner-ontonotes, batch 626 (28626): mcc: 0.9286, acc: 0.8969, precision: 0.9465, recall: 0.9188, f1: 0.9324, edges-ner-ontonotes_loss: 0.0237
09/16 07:33:47 AM: Update 29575: task edges-ner-ontonotes, batch 575 (29575): mcc: 0.9306, acc: 0.8996, precision: 0.9485, recall: 0.9204, f1: 0.9343, edges-ner-ontonotes_loss: 0.0245
09/16 07:33:48 AM: Update 28683: task edges-ner-ontonotes, batch 683 (28683): mcc: 0.9310, acc: 0.9000, precision: 0.9482, recall: 0.9215, f1: 0.9347, edges-ner-ontonotes_loss: 0.0231
09/16 07:33:57 AM: Update 29658: task edges-ner-ontonotes, batch 658 (29658): mcc: 0.9295, acc: 0.8982, precision: 0.9477, recall: 0.9193, f1: 0.9333, edges-ner-ontonotes_loss: 0.0248
09/16 07:33:58 AM: Update 28763: task edges-ner-ontonotes, batch 763 (28763): mcc: 0.9331, acc: 0.9029, precision: 0.9496, recall: 0.9242, f1: 0.9367, edges-ner-ontonotes_loss: 0.0224
09/16 07:34:07 AM: Update 29741: task edges-ner-ontonotes, batch 741 (29741): mcc: 0.9287, acc: 0.8972, precision: 0.9471, recall: 0.9184, f1: 0.9325, edges-ner-ontonotes_loss: 0.0249
09/16 07:34:08 AM: Update 28841: task edges-ner-ontonotes, batch 841 (28841): mcc: 0.9350, acc: 0.9052, precision: 0.9508, recall: 0.9265, f1: 0.9385, edges-ner-ontonotes_loss: 0.0217
09/16 07:34:17 AM: Update 29825: task edges-ner-ontonotes, batch 825 (29825): mcc: 0.9284, acc: 0.8967, precision: 0.9468, recall: 0.9181, f1: 0.9322, edges-ner-ontonotes_loss: 0.0250
09/16 07:34:18 AM: Update 28920: task edges-ner-ontonotes, batch 920 (28920): mcc: 0.9368, acc: 0.9077, precision: 0.9521, recall: 0.9287, f1: 0.9402, edges-ner-ontonotes_loss: 0.0212
09/16 07:34:29 AM: Update 29894: task edges-ner-ontonotes, batch 894 (29894): mcc: 0.9286, acc: 0.8970, precision: 0.9469, recall: 0.9183, f1: 0.9324, edges-ner-ontonotes_loss: 0.0249
09/16 07:34:29 AM: Update 28980: task edges-ner-ontonotes, batch 980 (28980): mcc: 0.9377, acc: 0.9086, precision: 0.9526, recall: 0.9297, f1: 0.9410, edges-ner-ontonotes_loss: 0.0208
09/16 07:34:33 AM: ***** Step 29000 / Validation 29 *****
09/16 07:34:33 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:34:33 AM: Validating...
09/16 07:34:40 AM: Update 29955: task edges-ner-ontonotes, batch 955 (29955): mcc: 0.9289, acc: 0.8973, precision: 0.9471, recall: 0.9187, f1: 0.9327, edges-ner-ontonotes_loss: 0.0247
09/16 07:34:40 AM: Evaluate: task edges-ner-ontonotes, batch 46 (157): mcc: 0.9121, acc: 0.8823, precision: 0.9347, recall: 0.8994, f1: 0.9167, edges-ner-ontonotes_loss: 0.0296
09/16 07:34:50 AM: ***** Step 30000 / Validation 30 *****
09/16 07:34:50 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:34:50 AM: Validating...
09/16 07:34:51 AM: Evaluate: task edges-ner-ontonotes, batch 9 (157): mcc: 0.8646, acc: 0.8180, precision: 0.9048, recall: 0.8401, f1: 0.8713, edges-ner-ontonotes_loss: 0.0352
09/16 07:34:51 AM: Evaluate: task edges-ner-ontonotes, batch 102 (157): mcc: 0.9303, acc: 0.9033, precision: 0.9493, recall: 0.9191, f1: 0.9340, edges-ner-ontonotes_loss: 0.0239
09/16 07:35:02 AM: Evaluate: task edges-ner-ontonotes, batch 144 (157): mcc: 0.9429, acc: 0.9200, precision: 0.9578, recall: 0.9344, f1: 0.9459, edges-ner-ontonotes_loss: 0.0200
09/16 07:35:02 AM: Evaluate: task edges-ner-ontonotes, batch 59 (157): mcc: 0.9289, acc: 0.9036, precision: 0.9487, recall: 0.9170, f1: 0.9326, edges-ner-ontonotes_loss: 0.0234
09/16 07:35:04 AM: Updating LR scheduler:
09/16 07:35:04 AM: 	Best result seen so far for macro_avg: 0.948
09/16 07:35:04 AM: 	# validation passes without improvement: 3
09/16 07:35:04 AM: edges-ner-ontonotes_loss: training: 0.020789 validation: 0.019490
09/16 07:35:04 AM: macro_avg: validation: 0.946823
09/16 07:35:04 AM: micro_avg: validation: 0.000000
09/16 07:35:04 AM: edges-ner-ontonotes_mcc: training: 0.937793 validation: 0.943810
09/16 07:35:04 AM: edges-ner-ontonotes_acc: training: 0.908692 validation: 0.921065
09/16 07:35:04 AM: edges-ner-ontonotes_precision: training: 0.952794 validation: 0.958295
09/16 07:35:04 AM: edges-ner-ontonotes_recall: training: 0.929753 validation: 0.935623
09/16 07:35:04 AM: edges-ner-ontonotes_f1: training: 0.941133 validation: 0.946823
09/16 07:35:04 AM: Global learning rate: 0.0001
09/16 07:35:04 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:35:12 AM: Update 29041: task edges-ner-ontonotes, batch 41 (29041): mcc: 0.9403, acc: 0.9072, precision: 0.9545, recall: 0.9328, f1: 0.9435, edges-ner-ontonotes_loss: 0.0207
09/16 07:35:12 AM: Evaluate: task edges-ner-ontonotes, batch 111 (157): mcc: 0.9346, acc: 0.9084, precision: 0.9542, recall: 0.9224, f1: 0.9380, edges-ner-ontonotes_loss: 0.0213
09/16 07:35:21 AM: Updating LR scheduler:
09/16 07:35:21 AM: 	Best result seen so far for macro_avg: 0.948
09/16 07:35:21 AM: 	# validation passes without improvement: 0
09/16 07:35:21 AM: edges-ner-ontonotes_loss: training: 0.024522 validation: 0.018759
09/16 07:35:21 AM: macro_avg: validation: 0.946567
09/16 07:35:21 AM: micro_avg: validation: 0.000000
09/16 07:35:21 AM: edges-ner-ontonotes_mcc: training: 0.929079 validation: 0.943586
09/16 07:35:21 AM: edges-ner-ontonotes_acc: training: 0.897526 validation: 0.920231
09/16 07:35:21 AM: edges-ner-ontonotes_precision: training: 0.947083 validation: 0.960647
09/16 07:35:21 AM: edges-ner-ontonotes_recall: training: 0.919037 validation: 0.932894
09/16 07:35:21 AM: edges-ner-ontonotes_f1: training: 0.932849 validation: 0.946567
09/16 07:35:21 AM: Global learning rate: 5e-05
09/16 07:35:21 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:35:22 AM: Update 30008: task edges-ner-ontonotes, batch 8 (30008): mcc: 0.9180, acc: 0.8861, precision: 0.9353, recall: 0.9099, f1: 0.9224, edges-ner-ontonotes_loss: 0.0266
09/16 07:35:22 AM: Update 29099: task edges-ner-ontonotes, batch 99 (29099): mcc: 0.9468, acc: 0.9192, precision: 0.9593, recall: 0.9404, f1: 0.9497, edges-ner-ontonotes_loss: 0.0184
09/16 07:35:32 AM: Update 30085: task edges-ner-ontonotes, batch 85 (30085): mcc: 0.9361, acc: 0.9058, precision: 0.9524, recall: 0.9269, f1: 0.9395, edges-ner-ontonotes_loss: 0.0211
09/16 07:35:32 AM: Update 29175: task edges-ner-ontonotes, batch 175 (29175): mcc: 0.9471, acc: 0.9201, precision: 0.9596, recall: 0.9405, f1: 0.9500, edges-ner-ontonotes_loss: 0.0179
09/16 07:35:42 AM: Update 29245: task edges-ner-ontonotes, batch 245 (29245): mcc: 0.9488, acc: 0.9228, precision: 0.9613, recall: 0.9420, f1: 0.9516, edges-ner-ontonotes_loss: 0.0173
09/16 07:35:42 AM: Update 30160: task edges-ner-ontonotes, batch 160 (30160): mcc: 0.9351, acc: 0.9064, precision: 0.9515, recall: 0.9260, f1: 0.9386, edges-ner-ontonotes_loss: 0.0210
09/16 07:35:52 AM: Update 30216: task edges-ner-ontonotes, batch 216 (30216): mcc: 0.9363, acc: 0.9076, precision: 0.9517, recall: 0.9280, f1: 0.9397, edges-ner-ontonotes_loss: 0.0205
09/16 07:35:52 AM: Update 29308: task edges-ner-ontonotes, batch 308 (29308): mcc: 0.9435, acc: 0.9157, precision: 0.9572, recall: 0.9361, f1: 0.9465, edges-ner-ontonotes_loss: 0.0190
09/16 07:36:02 AM: Update 30293: task edges-ner-ontonotes, batch 293 (30293): mcc: 0.9403, acc: 0.9133, precision: 0.9536, recall: 0.9335, f1: 0.9435, edges-ner-ontonotes_loss: 0.0195
09/16 07:36:02 AM: Update 29381: task edges-ner-ontonotes, batch 381 (29381): mcc: 0.9373, acc: 0.9079, precision: 0.9529, recall: 0.9287, f1: 0.9407, edges-ner-ontonotes_loss: 0.0217
09/16 07:36:12 AM: Update 30367: task edges-ner-ontonotes, batch 367 (30367): mcc: 0.9426, acc: 0.9162, precision: 0.9556, recall: 0.9361, f1: 0.9457, edges-ner-ontonotes_loss: 0.0188
09/16 07:36:12 AM: Update 29456: task edges-ner-ontonotes, batch 456 (29456): mcc: 0.9336, acc: 0.9033, precision: 0.9504, recall: 0.9243, f1: 0.9372, edges-ner-ontonotes_loss: 0.0234
09/16 07:36:22 AM: Update 30439: task edges-ner-ontonotes, batch 439 (30439): mcc: 0.9439, acc: 0.9175, precision: 0.9566, recall: 0.9375, f1: 0.9470, edges-ner-ontonotes_loss: 0.0184
09/16 07:36:22 AM: Update 29526: task edges-ner-ontonotes, batch 526 (29526): mcc: 0.9319, acc: 0.9011, precision: 0.9493, recall: 0.9221, f1: 0.9355, edges-ner-ontonotes_loss: 0.0240
09/16 07:36:32 AM: Update 30509: task edges-ner-ontonotes, batch 509 (30509): mcc: 0.9452, acc: 0.9188, precision: 0.9578, recall: 0.9387, f1: 0.9481, edges-ner-ontonotes_loss: 0.0180
09/16 07:36:32 AM: Update 29584: task edges-ner-ontonotes, batch 584 (29584): mcc: 0.9304, acc: 0.8994, precision: 0.9484, recall: 0.9202, f1: 0.9341, edges-ner-ontonotes_loss: 0.0246
09/16 07:36:42 AM: Update 30588: task edges-ner-ontonotes, batch 588 (30588): mcc: 0.9452, acc: 0.9189, precision: 0.9580, recall: 0.9386, f1: 0.9482, edges-ner-ontonotes_loss: 0.0179
09/16 07:36:42 AM: Update 29669: task edges-ner-ontonotes, batch 669 (29669): mcc: 0.9292, acc: 0.8978, precision: 0.9474, recall: 0.9190, f1: 0.9330, edges-ner-ontonotes_loss: 0.0249
09/16 07:36:52 AM: Update 30664: task edges-ner-ontonotes, batch 664 (30664): mcc: 0.9456, acc: 0.9193, precision: 0.9581, recall: 0.9392, f1: 0.9486, edges-ner-ontonotes_loss: 0.0178
09/16 07:36:52 AM: Update 29747: task edges-ner-ontonotes, batch 747 (29747): mcc: 0.9287, acc: 0.8972, precision: 0.9470, recall: 0.9184, f1: 0.9325, edges-ner-ontonotes_loss: 0.0249
09/16 07:37:02 AM: Update 30741: task edges-ner-ontonotes, batch 741 (30741): mcc: 0.9460, acc: 0.9197, precision: 0.9586, recall: 0.9395, f1: 0.9489, edges-ner-ontonotes_loss: 0.0178
09/16 07:37:02 AM: Update 29830: task edges-ner-ontonotes, batch 830 (29830): mcc: 0.9283, acc: 0.8967, precision: 0.9467, recall: 0.9180, f1: 0.9321, edges-ner-ontonotes_loss: 0.0250
09/16 07:37:12 AM: Update 29890: task edges-ner-ontonotes, batch 890 (29890): mcc: 0.9286, acc: 0.8970, precision: 0.9468, recall: 0.9183, f1: 0.9324, edges-ner-ontonotes_loss: 0.0249
09/16 07:37:14 AM: Update 30817: task edges-ner-ontonotes, batch 817 (30817): mcc: 0.9462, acc: 0.9199, precision: 0.9587, recall: 0.9397, f1: 0.9491, edges-ner-ontonotes_loss: 0.0178
09/16 07:37:22 AM: Update 29964: task edges-ner-ontonotes, batch 964 (29964): mcc: 0.9290, acc: 0.8974, precision: 0.9472, recall: 0.9188, f1: 0.9328, edges-ner-ontonotes_loss: 0.0246
09/16 07:37:24 AM: Update 30881: task edges-ner-ontonotes, batch 881 (30881): mcc: 0.9439, acc: 0.9171, precision: 0.9572, recall: 0.9370, f1: 0.9470, edges-ner-ontonotes_loss: 0.0187
09/16 07:37:27 AM: ***** Step 30000 / Validation 30 *****
09/16 07:37:27 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:37:27 AM: Validating...
09/16 07:37:32 AM: Evaluate: task edges-ner-ontonotes, batch 39 (157): mcc: 0.9137, acc: 0.8857, precision: 0.9364, recall: 0.9008, f1: 0.9183, edges-ner-ontonotes_loss: 0.0274
09/16 07:37:34 AM: Update 30957: task edges-ner-ontonotes, batch 957 (30957): mcc: 0.9416, acc: 0.9140, precision: 0.9558, recall: 0.9339, f1: 0.9447, edges-ner-ontonotes_loss: 0.0198
09/16 07:37:41 AM: ***** Step 31000 / Validation 31 *****
09/16 07:37:41 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:37:41 AM: Validating...
09/16 07:37:44 AM: Evaluate: task edges-ner-ontonotes, batch 16 (157): mcc: 0.8835, acc: 0.8432, precision: 0.9159, recall: 0.8643, f1: 0.8893, edges-ner-ontonotes_loss: 0.0309
09/16 07:37:44 AM: Evaluate: task edges-ner-ontonotes, batch 94 (157): mcc: 0.9346, acc: 0.9081, precision: 0.9566, recall: 0.9200, f1: 0.9380, edges-ner-ontonotes_loss: 0.0221
09/16 07:37:54 AM: Evaluate: task edges-ner-ontonotes, batch 63 (157): mcc: 0.9288, acc: 0.9049, precision: 0.9468, recall: 0.9189, f1: 0.9326, edges-ner-ontonotes_loss: 0.0243
09/16 07:37:54 AM: Evaluate: task edges-ner-ontonotes, batch 135 (157): mcc: 0.9414, acc: 0.9173, precision: 0.9593, recall: 0.9301, f1: 0.9445, edges-ner-ontonotes_loss: 0.0196
09/16 07:37:59 AM: Updating LR scheduler:
09/16 07:37:59 AM: 	Best result seen so far for macro_avg: 0.948
09/16 07:37:59 AM: 	# validation passes without improvement: 0
09/16 07:37:59 AM: edges-ner-ontonotes_loss: training: 0.024522 validation: 0.018759
09/16 07:37:59 AM: macro_avg: validation: 0.946567
09/16 07:37:59 AM: micro_avg: validation: 0.000000
09/16 07:37:59 AM: edges-ner-ontonotes_mcc: training: 0.929079 validation: 0.943586
09/16 07:37:59 AM: edges-ner-ontonotes_acc: training: 0.897526 validation: 0.920231
09/16 07:37:59 AM: edges-ner-ontonotes_precision: training: 0.947083 validation: 0.960647
09/16 07:37:59 AM: edges-ner-ontonotes_recall: training: 0.919037 validation: 0.932894
09/16 07:37:59 AM: edges-ner-ontonotes_f1: training: 0.932849 validation: 0.946567
09/16 07:37:59 AM: Global learning rate: 5e-05
09/16 07:37:59 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:38:04 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9369, acc: 0.9125, precision: 0.9560, recall: 0.9248, f1: 0.9402, edges-ner-ontonotes_loss: 0.0220
09/16 07:38:05 AM: Update 30020: task edges-ner-ontonotes, batch 20 (30020): mcc: 0.9315, acc: 0.9015, precision: 0.9498, recall: 0.9209, f1: 0.9351, edges-ner-ontonotes_loss: 0.0224
09/16 07:38:12 AM: Updating LR scheduler:
09/16 07:38:12 AM: 	Best result seen so far for macro_avg: 0.948
09/16 07:38:12 AM: 	# validation passes without improvement: 1
09/16 07:38:12 AM: edges-ner-ontonotes_loss: training: 0.020073 validation: 0.019325
09/16 07:38:12 AM: macro_avg: validation: 0.947737
09/16 07:38:12 AM: micro_avg: validation: 0.000000
09/16 07:38:12 AM: edges-ner-ontonotes_mcc: training: 0.940871 validation: 0.944818
09/16 07:38:12 AM: edges-ner-ontonotes_acc: training: 0.913241 validation: 0.922960
09/16 07:38:12 AM: edges-ner-ontonotes_precision: training: 0.955354 validation: 0.961529
09/16 07:38:12 AM: edges-ner-ontonotes_recall: training: 0.933005 validation: 0.934334
09/16 07:38:12 AM: edges-ner-ontonotes_f1: training: 0.944047 validation: 0.947737
09/16 07:38:12 AM: Global learning rate: 5e-05
09/16 07:38:12 AM: Saving checkpoints to: ./experiments/ner-ontonotes-None-top/run
09/16 07:38:14 AM: Update 31021: task edges-ner-ontonotes, batch 21 (31021): mcc: 0.8976, acc: 0.8496, precision: 0.9298, recall: 0.8771, f1: 0.9027, edges-ner-ontonotes_loss: 0.0381
09/16 07:38:15 AM: Update 30084: task edges-ner-ontonotes, batch 84 (30084): mcc: 0.9366, acc: 0.9062, precision: 0.9530, recall: 0.9272, f1: 0.9399, edges-ner-ontonotes_loss: 0.0210
09/16 07:38:24 AM: Update 31093: task edges-ner-ontonotes, batch 93 (31093): mcc: 0.9137, acc: 0.8763, precision: 0.9389, recall: 0.8984, f1: 0.9182, edges-ner-ontonotes_loss: 0.0306
09/16 07:38:25 AM: Update 30160: task edges-ner-ontonotes, batch 160 (30160): mcc: 0.9351, acc: 0.9064, precision: 0.9515, recall: 0.9260, f1: 0.9386, edges-ner-ontonotes_loss: 0.0210
09/16 07:38:35 AM: Update 31148: task edges-ner-ontonotes, batch 148 (31148): mcc: 0.9145, acc: 0.8788, precision: 0.9376, recall: 0.9010, f1: 0.9189, edges-ner-ontonotes_loss: 0.0300
09/16 07:38:35 AM: Update 30211: task edges-ner-ontonotes, batch 211 (30211): mcc: 0.9362, acc: 0.9073, precision: 0.9516, recall: 0.9279, f1: 0.9396, edges-ner-ontonotes_loss: 0.0205
09/16 07:38:45 AM: Update 31237: task edges-ner-ontonotes, batch 237 (31237): mcc: 0.9161, acc: 0.8806, precision: 0.9386, recall: 0.9031, f1: 0.9205, edges-ner-ontonotes_loss: 0.0284
09/16 07:38:45 AM: Update 30287: task edges-ner-ontonotes, batch 287 (30287): mcc: 0.9399, acc: 0.9127, precision: 0.9534, recall: 0.9331, f1: 0.9431, edges-ner-ontonotes_loss: 0.0196
