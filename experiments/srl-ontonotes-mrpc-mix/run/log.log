09/16 10:55:44 AM: Git branch: master
09/16 10:55:44 AM: Git SHA: 092d4f2e0b7152db74aa328af35fdb8b3f73d06a
09/16 10:55:44 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/srl-ontonotes-mrpc-mix/",
  "exp_name": "experiments/srl-ontonotes-mrpc-mix",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/srl-ontonotes-mrpc-mix/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/mrpc",
  "pytorch_transformers_output_mode": "mix",
  "remote_log_name": "experiments/srl-ontonotes-mrpc-mix__run",
  "run_dir": "./experiments/srl-ontonotes-mrpc-mix/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-srl-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 10:55:44 AM: Saved config to ./experiments/srl-ontonotes-mrpc-mix/run/params.conf
09/16 10:55:44 AM: Using random seed 1234
09/16 10:55:45 AM: Using GPU 0
09/16 10:55:45 AM: Loading tasks...
09/16 10:55:45 AM: Writing pre-preprocessed tasks to ./experiments/srl-ontonotes-mrpc-mix/
09/16 10:55:45 AM: 	Creating task edges-srl-ontonotes from scratch.
09/16 10:55:51 AM: Read=231480, Skip=21590, Total=253070 from ./probing_data/edges/ontonotes/srl/train.json.retokenized.bert-base-uncased
09/16 10:55:51 AM: Read=32486, Skip=2811, Total=35297 from ./probing_data/edges/ontonotes/srl/development.json.retokenized.bert-base-uncased
09/16 10:55:52 AM: Read=23800, Skip=2915, Total=26715 from ./probing_data/edges/ontonotes/srl/test.json.retokenized.bert-base-uncased
09/16 10:55:56 AM: 	Task 'edges-srl-ontonotes': |train|=231480 |val|=32486 |test|=23800
09/16 10:55:56 AM: 	Finished loading tasks: edges-srl-ontonotes.
09/16 10:55:56 AM: 	Building vocab from scratch.
09/16 10:55:56 AM: 	Counting units for task edges-srl-ontonotes.
09/16 10:56:04 AM: 	Task 'edges-srl-ontonotes': adding vocab namespace 'edges-srl-ontonotes_labels'
09/16 10:56:05 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 10:56:05 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 10:56:05 AM: 	Saved vocab to ./experiments/srl-ontonotes-mrpc-mix/vocab
09/16 10:56:05 AM: Loading token dictionary from ./experiments/srl-ontonotes-mrpc-mix/vocab.
09/16 10:56:05 AM: 	Loaded vocab from ./experiments/srl-ontonotes-mrpc-mix/vocab
09/16 10:56:05 AM: 	Vocab namespace bert_uncased: size 30524
09/16 10:56:05 AM: 	Vocab namespace tokens: size 23662
09/16 10:56:05 AM: 	Vocab namespace edges-srl-ontonotes_labels: size 66
09/16 10:56:05 AM: 	Vocab namespace chars: size 76
09/16 10:56:05 AM: 	Finished building vocab.
09/16 10:56:05 AM: 	Task edges-srl-ontonotes (train): Indexing from scratch.
09/16 10:56:37 AM: 	Task edges-srl-ontonotes (train): Saved 231480 instances to ./experiments/srl-ontonotes-mrpc-mix/preproc/edges-srl-ontonotes__train_data
09/16 10:56:37 AM: 	Task edges-srl-ontonotes (val): Indexing from scratch.
09/16 10:56:42 AM: 	Task edges-srl-ontonotes (val): Saved 32486 instances to ./experiments/srl-ontonotes-mrpc-mix/preproc/edges-srl-ontonotes__val_data
09/16 10:56:42 AM: 	Task edges-srl-ontonotes (test): Indexing from scratch.
09/16 10:56:45 AM: 	Task edges-srl-ontonotes (test): Saved 23800 instances to ./experiments/srl-ontonotes-mrpc-mix/preproc/edges-srl-ontonotes__test_data
09/16 10:56:45 AM: 	Finished indexing tasks
09/16 10:56:45 AM: 	Creating trimmed target-only version of edges-srl-ontonotes train.
09/16 10:56:45 AM: 	  Training on 
09/16 10:56:45 AM: 	  Evaluating on edges-srl-ontonotes
09/16 10:56:45 AM: 	Finished loading tasks in 59.995s
09/16 10:56:45 AM: 	 Tasks: ['edges-srl-ontonotes']
09/16 10:56:45 AM: Building model...
09/16 10:56:45 AM: Using BERT model (bert-base-uncased).
09/16 10:56:45 AM: LOADING A FUNETUNED MODEL from: 
09/16 10:56:45 AM: models/mrpc
09/16 10:56:45 AM: loading configuration file models/mrpc/config.json
09/16 10:56:45 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "mrpc",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 10:56:45 AM: loading weights file models/mrpc/pytorch_model.bin
09/16 10:56:48 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp70kkyic5
09/16 10:56:50 AM: copying /tmp/tmp70kkyic5 to cache at ./experiments/srl-ontonotes-mrpc-mix/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 10:56:50 AM: creating metadata file for ./experiments/srl-ontonotes-mrpc-mix/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 10:56:50 AM: removing temp file /tmp/tmp70kkyic5
09/16 10:56:50 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/srl-ontonotes-mrpc-mix/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 10:56:50 AM: NOTE: pytorch_transformers_output_mode='mix', so scalar mixing weights will be fine-tuned even if BERT model is frozen.
09/16 10:56:50 AM: Initializing parameters
09/16 10:56:50 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 10:56:50 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 10:56:50 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 10:56:50 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 10:56:50 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 10:56:50 AM:    _text_field_embedder.scalar_mix.gamma
09/16 10:56:50 AM:    _text_field_embedder.scalar_mix.scalar_parameters.0
09/16 10:56:50 AM:    _text_field_embedder.scalar_mix.scalar_parameters.1
09/16 10:56:50 AM:    _text_field_embedder.scalar_mix.scalar_parameters.10
09/16 10:56:50 AM:    _text_field_embedder.scalar_mix.scalar_parameters.11
09/16 10:56:50 AM:    _text_field_embedder.scalar_mix.scalar_parameters.12
09/16 10:56:50 AM:    _text_field_embedder.scalar_mix.scalar_parameters.2
09/16 10:56:50 AM:    _text_field_embedder.scalar_mix.scalar_parameters.3
09/16 10:56:50 AM:    _text_field_embedder.scalar_mix.scalar_parameters.4
09/16 10:56:50 AM:    _text_field_embedder.scalar_mix.scalar_parameters.5
09/16 10:56:50 AM:    _text_field_embedder.scalar_mix.scalar_parameters.6
09/16 10:56:50 AM:    _text_field_embedder.scalar_mix.scalar_parameters.7
09/16 10:56:50 AM:    _text_field_embedder.scalar_mix.scalar_parameters.8
09/16 10:56:50 AM:    _text_field_embedder.scalar_mix.scalar_parameters.9
09/16 10:56:50 AM: 	Task 'edges-srl-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-srl-ontonotes"
}
09/16 10:56:54 AM: Model specification:
09/16 10:56:54 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
      (scalar_mix): ScalarMix(
        (scalar_parameters): ParameterList(
            (0): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (1): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (2): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (3): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (4): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (5): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (6): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (7): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (8): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (9): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (10): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (11): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (12): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-srl-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (proj2): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (span_extractor2): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Sequential(
        (0): Linear(in_features=1024, out_features=256, bias=True)
        (1): Tanh()
        (2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)
        (3): Dropout(p=0.3)
        (4): Linear(in_features=256, out_features=66, bias=True)
      )
    )
  )
)
09/16 10:56:54 AM: Model parameters:
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.scalar_mix.gamma: Trainable parameter, count 1 with torch.Size([1])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.0: Trainable parameter, count 1 with torch.Size([1])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.1: Trainable parameter, count 1 with torch.Size([1])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.2: Trainable parameter, count 1 with torch.Size([1])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.3: Trainable parameter, count 1 with torch.Size([1])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.4: Trainable parameter, count 1 with torch.Size([1])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.5: Trainable parameter, count 1 with torch.Size([1])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.6: Trainable parameter, count 1 with torch.Size([1])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.7: Trainable parameter, count 1 with torch.Size([1])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.8: Trainable parameter, count 1 with torch.Size([1])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.9: Trainable parameter, count 1 with torch.Size([1])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.10: Trainable parameter, count 1 with torch.Size([1])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.11: Trainable parameter, count 1 with torch.Size([1])
09/16 10:56:54 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.12: Trainable parameter, count 1 with torch.Size([1])
09/16 10:56:54 AM: 	edges-srl-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 10:56:54 AM: 	edges-srl-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 10:56:54 AM: 	edges-srl-ontonotes_mdl.proj2.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 10:56:54 AM: 	edges-srl-ontonotes_mdl.proj2.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 10:56:54 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.0.weight: Trainable parameter, count 262144 with torch.Size([256, 1024])
09/16 10:56:54 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.0.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 10:56:54 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.2.weight: Trainable parameter, count 256 with torch.Size([256])
09/16 10:56:54 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.2.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 10:56:54 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.4.weight: Trainable parameter, count 16896 with torch.Size([66, 256])
09/16 10:56:54 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.4.bias: Trainable parameter, count 66 with torch.Size([66])
09/16 10:56:54 AM: Total number of parameters: 110155856 (1.10156e+08)
09/16 10:56:54 AM: Number of trainable parameters: 673616 (673616)
09/16 10:56:54 AM: Finished building model in 8.685s
09/16 10:56:54 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-srl-ontonotes 

09/16 10:57:08 AM: patience = 9
09/16 10:57:08 AM: val_interval = 1000
09/16 10:57:08 AM: max_vals = 250
09/16 10:57:08 AM: cuda_device = 0
09/16 10:57:08 AM: grad_norm = 5.0
09/16 10:57:08 AM: grad_clipping = None
09/16 10:57:08 AM: lr_decay = 0.99
09/16 10:57:08 AM: min_lr = 1e-06
09/16 10:57:08 AM: keep_all_checkpoints = 0
09/16 10:57:08 AM: val_data_limit = 5000
09/16 10:57:08 AM: max_epochs = -1
09/16 10:57:08 AM: dec_val_scale = 250
09/16 10:57:08 AM: training_data_fraction = 1
09/16 10:57:08 AM: type = adam
09/16 10:57:08 AM: parameter_groups = None
09/16 10:57:08 AM: Number of trainable parameters: 673616
09/16 10:57:08 AM: infer_type_and_cast = True
09/16 10:57:08 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 10:57:08 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 10:57:08 AM: lr = 0.0001
09/16 10:57:08 AM: amsgrad = True
09/16 10:57:08 AM: type = reduce_on_plateau
09/16 10:57:08 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 10:57:08 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 10:57:08 AM: mode = max
09/16 10:57:08 AM: factor = 0.5
09/16 10:57:08 AM: patience = 3
09/16 10:57:08 AM: threshold = 0.0001
09/16 10:57:08 AM: threshold_mode = abs
09/16 10:57:08 AM: verbose = True
09/16 10:57:08 AM: type = adam
09/16 10:57:08 AM: parameter_groups = None
09/16 10:57:08 AM: Number of trainable parameters: 673616
09/16 10:57:08 AM: infer_type_and_cast = True
09/16 10:57:08 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 10:57:08 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 10:57:08 AM: lr = 0.0001
09/16 10:57:08 AM: amsgrad = True
09/16 10:57:08 AM: type = reduce_on_plateau
09/16 10:57:08 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 10:57:08 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 10:57:08 AM: mode = max
09/16 10:57:08 AM: factor = 0.5
09/16 10:57:08 AM: patience = 3
09/16 10:57:08 AM: threshold = 0.0001
09/16 10:57:08 AM: threshold_mode = abs
09/16 10:57:08 AM: verbose = True
09/16 10:57:08 AM: Starting training without restoring from a checkpoint.
09/16 10:57:08 AM: Training examples per task, before any subsampling: {'edges-srl-ontonotes': 231480}
09/16 10:57:08 AM: Beginning training with stopping criteria based on metric: edges-srl-ontonotes_f1
09/16 10:57:18 AM: Update 106: task edges-srl-ontonotes, batch 106 (106): mcc: 0.0672, acc: 0.0478, precision: 0.0618, recall: 0.1226, f1: 0.0821, edges-srl-ontonotes_loss: 0.2207
09/16 10:57:28 AM: Update 234: task edges-srl-ontonotes, batch 234 (234): mcc: 0.0765, acc: 0.0533, precision: 0.0934, recall: 0.0866, f1: 0.0899, edges-srl-ontonotes_loss: 0.1397
09/16 10:57:38 AM: Update 351: task edges-srl-ontonotes, batch 351 (351): mcc: 0.1559, acc: 0.1181, precision: 0.1961, recall: 0.1417, f1: 0.1645, edges-srl-ontonotes_loss: 0.1095
09/16 10:57:48 AM: Update 476: task edges-srl-ontonotes, batch 476 (476): mcc: 0.2537, acc: 0.1939, precision: 0.3219, recall: 0.2146, f1: 0.2576, edges-srl-ontonotes_loss: 0.0909
09/16 10:57:58 AM: Update 606: task edges-srl-ontonotes, batch 606 (606): mcc: 0.3459, acc: 0.2674, precision: 0.4343, recall: 0.2883, f1: 0.3466, edges-srl-ontonotes_loss: 0.0782
09/16 10:58:08 AM: Update 695: task edges-srl-ontonotes, batch 695 (695): mcc: 0.3909, acc: 0.3039, precision: 0.4886, recall: 0.3248, f1: 0.3902, edges-srl-ontonotes_loss: 0.0720
09/16 10:58:18 AM: Update 820: task edges-srl-ontonotes, batch 820 (820): mcc: 0.4428, acc: 0.3478, precision: 0.5476, recall: 0.3691, f1: 0.4410, edges-srl-ontonotes_loss: 0.0651
09/16 10:58:29 AM: Update 940: task edges-srl-ontonotes, batch 940 (940): mcc: 0.4824, acc: 0.3826, precision: 0.5910, recall: 0.4043, f1: 0.4801, edges-srl-ontonotes_loss: 0.0599
09/16 10:58:34 AM: ***** Step 1000 / Validation 1 *****
09/16 10:58:34 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:58:34 AM: Validating...
09/16 10:58:39 AM: Evaluate: task edges-srl-ontonotes, batch 63 (157): mcc: 0.7637, acc: 0.6480, precision: 0.8933, recall: 0.6580, f1: 0.7578, edges-srl-ontonotes_loss: 0.0224
09/16 10:58:47 AM: Best result seen so far for edges-srl-ontonotes.
09/16 10:58:47 AM: Best result seen so far for micro.
09/16 10:58:47 AM: Best result seen so far for macro.
09/16 10:58:47 AM: Updating LR scheduler:
09/16 10:58:47 AM: 	Best result seen so far for macro_avg: 0.779
09/16 10:58:47 AM: 	# validation passes without improvement: 0
09/16 10:58:47 AM: edges-srl-ontonotes_loss: training: 0.057768 validation: 0.021029
09/16 10:58:47 AM: macro_avg: validation: 0.778982
09/16 10:58:47 AM: micro_avg: validation: 0.000000
09/16 10:58:47 AM: edges-srl-ontonotes_mcc: training: 0.497875 validation: 0.783500
09/16 10:58:47 AM: edges-srl-ontonotes_acc: training: 0.396283 validation: 0.674852
09/16 10:58:47 AM: edges-srl-ontonotes_precision: training: 0.607467 validation: 0.901366
09/16 10:58:47 AM: edges-srl-ontonotes_recall: training: 0.418285 validation: 0.685859
09/16 10:58:47 AM: edges-srl-ontonotes_f1: training: 0.495431 validation: 0.778982
09/16 10:58:47 AM: Global learning rate: 0.0001
09/16 10:58:47 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 10:58:49 AM: Update 1022: task edges-srl-ontonotes, batch 22 (1022): mcc: 0.7405, acc: 0.6269, precision: 0.8545, recall: 0.6475, f1: 0.7368, edges-srl-ontonotes_loss: 0.0242
09/16 10:58:59 AM: Update 1140: task edges-srl-ontonotes, batch 140 (1140): mcc: 0.7566, acc: 0.6433, precision: 0.8627, recall: 0.6692, f1: 0.7537, edges-srl-ontonotes_loss: 0.0233
09/16 10:59:09 AM: Update 1253: task edges-srl-ontonotes, batch 253 (1253): mcc: 0.7591, acc: 0.6489, precision: 0.8602, recall: 0.6755, f1: 0.7568, edges-srl-ontonotes_loss: 0.0226
09/16 10:59:19 AM: Update 1377: task edges-srl-ontonotes, batch 377 (1377): mcc: 0.7578, acc: 0.6490, precision: 0.8551, recall: 0.6773, f1: 0.7559, edges-srl-ontonotes_loss: 0.0223
09/16 10:59:29 AM: Update 1490: task edges-srl-ontonotes, batch 490 (1490): mcc: 0.7640, acc: 0.6576, precision: 0.8577, recall: 0.6862, f1: 0.7624, edges-srl-ontonotes_loss: 0.0216
09/16 10:59:39 AM: Update 1600: task edges-srl-ontonotes, batch 600 (1600): mcc: 0.7669, acc: 0.6618, precision: 0.8577, recall: 0.6913, f1: 0.7655, edges-srl-ontonotes_loss: 0.0212
09/16 10:59:49 AM: Update 1718: task edges-srl-ontonotes, batch 718 (1718): mcc: 0.7662, acc: 0.6612, precision: 0.8559, recall: 0.6914, f1: 0.7649, edges-srl-ontonotes_loss: 0.0211
09/16 10:59:59 AM: Update 1826: task edges-srl-ontonotes, batch 826 (1826): mcc: 0.7647, acc: 0.6599, precision: 0.8537, recall: 0.6906, f1: 0.7635, edges-srl-ontonotes_loss: 0.0211
09/16 11:00:09 AM: Update 1914: task edges-srl-ontonotes, batch 914 (1914): mcc: 0.7656, acc: 0.6611, precision: 0.8537, recall: 0.6922, f1: 0.7645, edges-srl-ontonotes_loss: 0.0210
09/16 11:00:17 AM: ***** Step 2000 / Validation 2 *****
09/16 11:00:17 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:00:17 AM: Validating...
09/16 11:00:19 AM: Evaluate: task edges-srl-ontonotes, batch 36 (157): mcc: 0.8154, acc: 0.7335, precision: 0.8959, recall: 0.7467, f1: 0.8145, edges-srl-ontonotes_loss: 0.0167
09/16 11:00:28 AM: Best result seen so far for edges-srl-ontonotes.
09/16 11:00:28 AM: Best result seen so far for macro.
09/16 11:00:28 AM: Updating LR scheduler:
09/16 11:00:28 AM: 	Best result seen so far for macro_avg: 0.824
09/16 11:00:28 AM: 	# validation passes without improvement: 0
09/16 11:00:28 AM: edges-srl-ontonotes_loss: training: 0.020799 validation: 0.015843
09/16 11:00:28 AM: macro_avg: validation: 0.823933
09/16 11:00:28 AM: micro_avg: validation: 0.000000
09/16 11:00:28 AM: edges-srl-ontonotes_mcc: training: 0.767101 validation: 0.824687
09/16 11:00:28 AM: edges-srl-ontonotes_acc: training: 0.662985 validation: 0.743053
09/16 11:00:28 AM: edges-srl-ontonotes_precision: training: 0.854000 validation: 0.902557
09/16 11:00:28 AM: edges-srl-ontonotes_recall: training: 0.694672 validation: 0.757909
09/16 11:00:28 AM: edges-srl-ontonotes_f1: training: 0.766140 validation: 0.823933
09/16 11:00:28 AM: Global learning rate: 0.0001
09/16 11:00:28 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:00:29 AM: Update 2011: task edges-srl-ontonotes, batch 11 (2011): mcc: 0.7823, acc: 0.6895, precision: 0.8605, recall: 0.7166, f1: 0.7820, edges-srl-ontonotes_loss: 0.0192
09/16 11:00:39 AM: Update 2133: task edges-srl-ontonotes, batch 133 (2133): mcc: 0.7745, acc: 0.6768, precision: 0.8524, recall: 0.7093, f1: 0.7743, edges-srl-ontonotes_loss: 0.0195
09/16 11:00:49 AM: Update 2241: task edges-srl-ontonotes, batch 241 (2241): mcc: 0.7787, acc: 0.6815, precision: 0.8540, recall: 0.7155, f1: 0.7787, edges-srl-ontonotes_loss: 0.0192
09/16 11:00:59 AM: Update 2351: task edges-srl-ontonotes, batch 351 (2351): mcc: 0.7862, acc: 0.6917, precision: 0.8575, recall: 0.7262, f1: 0.7864, edges-srl-ontonotes_loss: 0.0186
09/16 11:01:09 AM: Update 2462: task edges-srl-ontonotes, batch 462 (2462): mcc: 0.7903, acc: 0.6981, precision: 0.8598, recall: 0.7318, f1: 0.7907, edges-srl-ontonotes_loss: 0.0183
09/16 11:01:19 AM: Update 2567: task edges-srl-ontonotes, batch 567 (2567): mcc: 0.7942, acc: 0.7031, precision: 0.8620, recall: 0.7369, f1: 0.7946, edges-srl-ontonotes_loss: 0.0180
09/16 11:01:30 AM: Update 2682: task edges-srl-ontonotes, batch 682 (2682): mcc: 0.7950, acc: 0.7053, precision: 0.8615, recall: 0.7390, f1: 0.7955, edges-srl-ontonotes_loss: 0.0178
09/16 11:01:40 AM: Update 2795: task edges-srl-ontonotes, batch 795 (2795): mcc: 0.7968, acc: 0.7081, precision: 0.8620, recall: 0.7419, f1: 0.7974, edges-srl-ontonotes_loss: 0.0176
09/16 11:01:50 AM: Update 2877: task edges-srl-ontonotes, batch 877 (2877): mcc: 0.7993, acc: 0.7114, precision: 0.8634, recall: 0.7452, f1: 0.7999, edges-srl-ontonotes_loss: 0.0175
09/16 11:02:00 AM: Update 2994: task edges-srl-ontonotes, batch 994 (2994): mcc: 0.8007, acc: 0.7134, precision: 0.8641, recall: 0.7470, f1: 0.8013, edges-srl-ontonotes_loss: 0.0173
09/16 11:02:00 AM: ***** Step 3000 / Validation 3 *****
09/16 11:02:00 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:02:00 AM: Validating...
09/16 11:02:10 AM: Evaluate: task edges-srl-ontonotes, batch 121 (157): mcc: 0.8303, acc: 0.7578, precision: 0.8914, recall: 0.7779, f1: 0.8308, edges-srl-ontonotes_loss: 0.0147
09/16 11:02:13 AM: Best result seen so far for edges-srl-ontonotes.
09/16 11:02:13 AM: Best result seen so far for macro.
09/16 11:02:13 AM: Updating LR scheduler:
09/16 11:02:13 AM: 	Best result seen so far for macro_avg: 0.832
09/16 11:02:13 AM: 	# validation passes without improvement: 0
09/16 11:02:13 AM: edges-srl-ontonotes_loss: training: 0.017331 validation: 0.014728
09/16 11:02:13 AM: macro_avg: validation: 0.832150
09/16 11:02:13 AM: micro_avg: validation: 0.000000
09/16 11:02:13 AM: edges-srl-ontonotes_mcc: training: 0.800891 validation: 0.831608
09/16 11:02:13 AM: edges-srl-ontonotes_acc: training: 0.713698 validation: 0.760680
09/16 11:02:13 AM: edges-srl-ontonotes_precision: training: 0.864260 validation: 0.890968
09/16 11:02:13 AM: edges-srl-ontonotes_recall: training: 0.747321 validation: 0.780617
09/16 11:02:13 AM: edges-srl-ontonotes_f1: training: 0.801548 validation: 0.832150
09/16 11:02:13 AM: Global learning rate: 0.0001
09/16 11:02:13 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:02:20 AM: Update 3081: task edges-srl-ontonotes, batch 81 (3081): mcc: 0.8242, acc: 0.7470, precision: 0.8770, recall: 0.7792, f1: 0.8252, edges-srl-ontonotes_loss: 0.0154
09/16 11:02:30 AM: Update 3187: task edges-srl-ontonotes, batch 187 (3187): mcc: 0.8159, acc: 0.7366, precision: 0.8714, recall: 0.7688, f1: 0.8169, edges-srl-ontonotes_loss: 0.0160
09/16 11:02:40 AM: Update 3304: task edges-srl-ontonotes, batch 304 (3304): mcc: 0.8139, acc: 0.7328, precision: 0.8704, recall: 0.7659, f1: 0.8148, edges-srl-ontonotes_loss: 0.0161
09/16 11:02:50 AM: Update 3414: task edges-srl-ontonotes, batch 414 (3414): mcc: 0.8126, acc: 0.7309, precision: 0.8698, recall: 0.7640, f1: 0.8135, edges-srl-ontonotes_loss: 0.0162
09/16 11:03:00 AM: Update 3518: task edges-srl-ontonotes, batch 518 (3518): mcc: 0.8128, acc: 0.7314, precision: 0.8700, recall: 0.7643, f1: 0.8137, edges-srl-ontonotes_loss: 0.0162
09/16 11:03:10 AM: Update 3634: task edges-srl-ontonotes, batch 634 (3634): mcc: 0.8116, acc: 0.7290, precision: 0.8696, recall: 0.7625, f1: 0.8125, edges-srl-ontonotes_loss: 0.0162
09/16 11:03:20 AM: Update 3750: task edges-srl-ontonotes, batch 750 (3750): mcc: 0.8131, acc: 0.7309, precision: 0.8710, recall: 0.7639, f1: 0.8140, edges-srl-ontonotes_loss: 0.0161
09/16 11:03:30 AM: Update 3861: task edges-srl-ontonotes, batch 861 (3861): mcc: 0.8131, acc: 0.7313, precision: 0.8707, recall: 0.7643, f1: 0.8140, edges-srl-ontonotes_loss: 0.0160
09/16 11:03:40 AM: Update 3977: task edges-srl-ontonotes, batch 977 (3977): mcc: 0.8129, acc: 0.7314, precision: 0.8702, recall: 0.7643, f1: 0.8138, edges-srl-ontonotes_loss: 0.0160
09/16 11:03:42 AM: ***** Step 4000 / Validation 4 *****
09/16 11:03:42 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:03:42 AM: Validating...
09/16 11:03:50 AM: Evaluate: task edges-srl-ontonotes, batch 90 (157): mcc: 0.8241, acc: 0.7485, precision: 0.8964, recall: 0.7620, f1: 0.8238, edges-srl-ontonotes_loss: 0.0148
09/16 11:03:57 AM: Best result seen so far for edges-srl-ontonotes.
09/16 11:03:57 AM: Best result seen so far for macro.
09/16 11:03:57 AM: Updating LR scheduler:
09/16 11:03:57 AM: 	Best result seen so far for macro_avg: 0.834
09/16 11:03:57 AM: 	# validation passes without improvement: 0
09/16 11:03:57 AM: edges-srl-ontonotes_loss: training: 0.016010 validation: 0.014186
09/16 11:03:57 AM: macro_avg: validation: 0.833725
09/16 11:03:57 AM: micro_avg: validation: 0.000000
09/16 11:03:57 AM: edges-srl-ontonotes_mcc: training: 0.812872 validation: 0.833461
09/16 11:03:57 AM: edges-srl-ontonotes_acc: training: 0.731482 validation: 0.765299
09/16 11:03:57 AM: edges-srl-ontonotes_precision: training: 0.870260 validation: 0.896616
09/16 11:03:57 AM: edges-srl-ontonotes_recall: training: 0.764193 validation: 0.779078
09/16 11:03:57 AM: edges-srl-ontonotes_f1: training: 0.813785 validation: 0.833725
09/16 11:03:57 AM: Global learning rate: 0.0001
09/16 11:03:57 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:04:00 AM: Update 4038: task edges-srl-ontonotes, batch 38 (4038): mcc: 0.8095, acc: 0.7283, precision: 0.8672, recall: 0.7606, f1: 0.8104, edges-srl-ontonotes_loss: 0.0159
09/16 11:04:10 AM: Update 4141: task edges-srl-ontonotes, batch 141 (4141): mcc: 0.8143, acc: 0.7371, precision: 0.8677, recall: 0.7692, f1: 0.8155, edges-srl-ontonotes_loss: 0.0157
09/16 11:04:20 AM: Update 4248: task edges-srl-ontonotes, batch 248 (4248): mcc: 0.8197, acc: 0.7451, precision: 0.8723, recall: 0.7751, f1: 0.8208, edges-srl-ontonotes_loss: 0.0155
09/16 11:04:30 AM: Update 4360: task edges-srl-ontonotes, batch 360 (4360): mcc: 0.8241, acc: 0.7506, precision: 0.8753, recall: 0.7805, f1: 0.8252, edges-srl-ontonotes_loss: 0.0151
09/16 11:04:40 AM: Update 4461: task edges-srl-ontonotes, batch 461 (4461): mcc: 0.8245, acc: 0.7508, precision: 0.8761, recall: 0.7806, f1: 0.8256, edges-srl-ontonotes_loss: 0.0151
09/16 11:04:50 AM: Update 4570: task edges-srl-ontonotes, batch 570 (4570): mcc: 0.8266, acc: 0.7541, precision: 0.8774, recall: 0.7834, f1: 0.8277, edges-srl-ontonotes_loss: 0.0149
09/16 11:05:00 AM: Update 4688: task edges-srl-ontonotes, batch 688 (4688): mcc: 0.8277, acc: 0.7557, precision: 0.8780, recall: 0.7849, f1: 0.8288, edges-srl-ontonotes_loss: 0.0148
09/16 11:05:10 AM: Update 4785: task edges-srl-ontonotes, batch 785 (4785): mcc: 0.8238, acc: 0.7509, precision: 0.8747, recall: 0.7805, f1: 0.8249, edges-srl-ontonotes_loss: 0.0151
09/16 11:05:20 AM: Update 4892: task edges-srl-ontonotes, batch 892 (4892): mcc: 0.8216, acc: 0.7478, precision: 0.8735, recall: 0.7776, f1: 0.8228, edges-srl-ontonotes_loss: 0.0152
09/16 11:05:30 AM: Update 4994: task edges-srl-ontonotes, batch 994 (4994): mcc: 0.8211, acc: 0.7467, precision: 0.8735, recall: 0.7766, f1: 0.8222, edges-srl-ontonotes_loss: 0.0152
09/16 11:05:31 AM: ***** Step 5000 / Validation 5 *****
09/16 11:05:31 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:05:31 AM: Validating...
09/16 11:05:40 AM: Evaluate: task edges-srl-ontonotes, batch 124 (157): mcc: 0.8413, acc: 0.7766, precision: 0.8959, recall: 0.7943, f1: 0.8420, edges-srl-ontonotes_loss: 0.0135
09/16 11:05:43 AM: Best result seen so far for edges-srl-ontonotes.
09/16 11:05:43 AM: Best result seen so far for macro.
09/16 11:05:43 AM: Updating LR scheduler:
09/16 11:05:43 AM: 	Best result seen so far for macro_avg: 0.843
09/16 11:05:43 AM: 	# validation passes without improvement: 0
09/16 11:05:43 AM: edges-srl-ontonotes_loss: training: 0.015257 validation: 0.013461
09/16 11:05:43 AM: macro_avg: validation: 0.843140
09/16 11:05:43 AM: micro_avg: validation: 0.000000
09/16 11:05:43 AM: edges-srl-ontonotes_mcc: training: 0.820880 validation: 0.842403
09/16 11:05:43 AM: edges-srl-ontonotes_acc: training: 0.746420 validation: 0.778462
09/16 11:05:43 AM: edges-srl-ontonotes_precision: training: 0.873346 validation: 0.896393
09/16 11:05:43 AM: edges-srl-ontonotes_recall: training: 0.776344 validation: 0.795859
09/16 11:05:43 AM: edges-srl-ontonotes_f1: training: 0.821993 validation: 0.843140
09/16 11:05:43 AM: Global learning rate: 0.0001
09/16 11:05:43 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:05:51 AM: Update 5058: task edges-srl-ontonotes, batch 58 (5058): mcc: 0.8245, acc: 0.7530, precision: 0.8741, recall: 0.7825, f1: 0.8258, edges-srl-ontonotes_loss: 0.0149
09/16 11:06:01 AM: Update 5185: task edges-srl-ontonotes, batch 185 (5185): mcc: 0.8428, acc: 0.7734, precision: 0.8888, recall: 0.8035, f1: 0.8440, edges-srl-ontonotes_loss: 0.0136
09/16 11:06:11 AM: Update 5309: task edges-srl-ontonotes, batch 309 (5309): mcc: 0.8486, acc: 0.7818, precision: 0.8920, recall: 0.8115, f1: 0.8499, edges-srl-ontonotes_loss: 0.0132
09/16 11:06:21 AM: Update 5432: task edges-srl-ontonotes, batch 432 (5432): mcc: 0.8579, acc: 0.7947, precision: 0.8991, recall: 0.8224, f1: 0.8591, edges-srl-ontonotes_loss: 0.0126
09/16 11:06:31 AM: Update 5586: task edges-srl-ontonotes, batch 586 (5586): mcc: 0.8669, acc: 0.8071, precision: 0.9058, recall: 0.8334, f1: 0.8681, edges-srl-ontonotes_loss: 0.0119
09/16 11:06:41 AM: Update 5703: task edges-srl-ontonotes, batch 703 (5703): mcc: 0.8704, acc: 0.8116, precision: 0.9085, recall: 0.8375, f1: 0.8715, edges-srl-ontonotes_loss: 0.0117
09/16 11:06:51 AM: Update 5830: task edges-srl-ontonotes, batch 830 (5830): mcc: 0.8736, acc: 0.8157, precision: 0.9109, recall: 0.8414, f1: 0.8747, edges-srl-ontonotes_loss: 0.0114
09/16 11:07:02 AM: Update 5948: task edges-srl-ontonotes, batch 948 (5948): mcc: 0.8764, acc: 0.8194, precision: 0.9131, recall: 0.8445, f1: 0.8775, edges-srl-ontonotes_loss: 0.0112
09/16 11:07:06 AM: ***** Step 6000 / Validation 6 *****
09/16 11:07:06 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:07:06 AM: Validating...
09/16 11:07:12 AM: Evaluate: task edges-srl-ontonotes, batch 75 (157): mcc: 0.8527, acc: 0.7969, precision: 0.9069, recall: 0.8056, f1: 0.8533, edges-srl-ontonotes_loss: 0.0130
09/16 11:07:19 AM: Best result seen so far for edges-srl-ontonotes.
09/16 11:07:19 AM: Best result seen so far for macro.
09/16 11:07:19 AM: Updating LR scheduler:
09/16 11:07:19 AM: 	Best result seen so far for macro_avg: 0.861
09/16 11:07:19 AM: 	# validation passes without improvement: 0
09/16 11:07:19 AM: edges-srl-ontonotes_loss: training: 0.011202 validation: 0.012451
09/16 11:07:19 AM: macro_avg: validation: 0.861080
09/16 11:07:19 AM: micro_avg: validation: 0.000000
09/16 11:07:19 AM: edges-srl-ontonotes_mcc: training: 0.877109 validation: 0.860298
09/16 11:07:19 AM: edges-srl-ontonotes_acc: training: 0.820477 validation: 0.806404
09/16 11:07:19 AM: edges-srl-ontonotes_precision: training: 0.913440 validation: 0.909200
09/16 11:07:19 AM: edges-srl-ontonotes_recall: training: 0.845648 validation: 0.817797
09/16 11:07:19 AM: edges-srl-ontonotes_f1: training: 0.878238 validation: 0.861080
09/16 11:07:19 AM: Global learning rate: 0.0001
09/16 11:07:19 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:07:22 AM: Update 6037: task edges-srl-ontonotes, batch 37 (6037): mcc: 0.8917, acc: 0.8434, precision: 0.9173, recall: 0.8699, f1: 0.8930, edges-srl-ontonotes_loss: 0.0101
09/16 11:07:32 AM: Update 6188: task edges-srl-ontonotes, batch 188 (6188): mcc: 0.8913, acc: 0.8430, precision: 0.9219, recall: 0.8648, f1: 0.8924, edges-srl-ontonotes_loss: 0.0101
09/16 11:07:42 AM: Update 6321: task edges-srl-ontonotes, batch 321 (6321): mcc: 0.8908, acc: 0.8431, precision: 0.9202, recall: 0.8655, f1: 0.8920, edges-srl-ontonotes_loss: 0.0101
09/16 11:07:52 AM: Update 6462: task edges-srl-ontonotes, batch 462 (6462): mcc: 0.8901, acc: 0.8423, precision: 0.9189, recall: 0.8653, f1: 0.8913, edges-srl-ontonotes_loss: 0.0101
09/16 11:08:02 AM: Update 6585: task edges-srl-ontonotes, batch 585 (6585): mcc: 0.8903, acc: 0.8431, precision: 0.9191, recall: 0.8656, f1: 0.8915, edges-srl-ontonotes_loss: 0.0102
09/16 11:08:12 AM: Update 6708: task edges-srl-ontonotes, batch 708 (6708): mcc: 0.8840, acc: 0.8342, precision: 0.9148, recall: 0.8575, f1: 0.8852, edges-srl-ontonotes_loss: 0.0106
09/16 11:08:22 AM: Update 6817: task edges-srl-ontonotes, batch 817 (6817): mcc: 0.8812, acc: 0.8303, precision: 0.9127, recall: 0.8541, f1: 0.8824, edges-srl-ontonotes_loss: 0.0108
09/16 11:08:33 AM: Update 6917: task edges-srl-ontonotes, batch 917 (6917): mcc: 0.8778, acc: 0.8259, precision: 0.9103, recall: 0.8498, f1: 0.8790, edges-srl-ontonotes_loss: 0.0111
09/16 11:08:41 AM: ***** Step 7000 / Validation 7 *****
09/16 11:08:41 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:08:41 AM: Validating...
09/16 11:08:43 AM: Evaluate: task edges-srl-ontonotes, batch 28 (157): mcc: 0.8708, acc: 0.8225, precision: 0.9171, recall: 0.8305, f1: 0.8716, edges-srl-ontonotes_loss: 0.0115
09/16 11:08:53 AM: Evaluate: task edges-srl-ontonotes, batch 131 (157): mcc: 0.8727, acc: 0.8267, precision: 0.9141, recall: 0.8367, f1: 0.8737, edges-srl-ontonotes_loss: 0.0111
09/16 11:08:55 AM: Best result seen so far for edges-srl-ontonotes.
09/16 11:08:55 AM: Best result seen so far for macro.
09/16 11:08:55 AM: Updating LR scheduler:
09/16 11:08:55 AM: 	Best result seen so far for macro_avg: 0.869
09/16 11:08:55 AM: 	# validation passes without improvement: 0
09/16 11:08:55 AM: edges-srl-ontonotes_loss: training: 0.011383 validation: 0.011548
09/16 11:08:55 AM: macro_avg: validation: 0.868708
09/16 11:08:55 AM: micro_avg: validation: 0.000000
09/16 11:08:55 AM: edges-srl-ontonotes_mcc: training: 0.873484 validation: 0.867703
09/16 11:08:55 AM: edges-srl-ontonotes_acc: training: 0.820484 validation: 0.820876
09/16 11:08:55 AM: edges-srl-ontonotes_precision: training: 0.907079 validation: 0.910049
09/16 11:08:55 AM: edges-srl-ontonotes_recall: training: 0.844683 validation: 0.830960
09/16 11:08:55 AM: edges-srl-ontonotes_f1: training: 0.874770 validation: 0.868708
09/16 11:08:55 AM: Global learning rate: 0.0001
09/16 11:08:55 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:09:03 AM: Update 7097: task edges-srl-ontonotes, batch 97 (7097): mcc: 0.8432, acc: 0.7814, precision: 0.8851, recall: 0.8076, f1: 0.8446, edges-srl-ontonotes_loss: 0.0135
09/16 11:09:13 AM: Update 7215: task edges-srl-ontonotes, batch 215 (7215): mcc: 0.8397, acc: 0.7774, precision: 0.8820, recall: 0.8039, f1: 0.8411, edges-srl-ontonotes_loss: 0.0138
09/16 11:09:23 AM: Update 7334: task edges-srl-ontonotes, batch 334 (7334): mcc: 0.8458, acc: 0.7855, precision: 0.8876, recall: 0.8103, f1: 0.8472, edges-srl-ontonotes_loss: 0.0134
09/16 11:09:33 AM: Update 7448: task edges-srl-ontonotes, batch 448 (7448): mcc: 0.8507, acc: 0.7908, precision: 0.8916, recall: 0.8159, f1: 0.8520, edges-srl-ontonotes_loss: 0.0130
09/16 11:09:43 AM: Update 7560: task edges-srl-ontonotes, batch 560 (7560): mcc: 0.8550, acc: 0.7963, precision: 0.8947, recall: 0.8210, f1: 0.8563, edges-srl-ontonotes_loss: 0.0127
09/16 11:09:53 AM: Update 7697: task edges-srl-ontonotes, batch 697 (7697): mcc: 0.8577, acc: 0.7997, precision: 0.8960, recall: 0.8249, f1: 0.8590, edges-srl-ontonotes_loss: 0.0124
09/16 11:10:03 AM: Update 7823: task edges-srl-ontonotes, batch 823 (7823): mcc: 0.8596, acc: 0.8026, precision: 0.8976, recall: 0.8272, f1: 0.8609, edges-srl-ontonotes_loss: 0.0123
09/16 11:10:13 AM: Update 7934: task edges-srl-ontonotes, batch 934 (7934): mcc: 0.8606, acc: 0.8038, precision: 0.8983, recall: 0.8283, f1: 0.8619, edges-srl-ontonotes_loss: 0.0122
09/16 11:10:18 AM: ***** Step 8000 / Validation 8 *****
09/16 11:10:18 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:10:18 AM: Validating...
09/16 11:10:23 AM: Evaluate: task edges-srl-ontonotes, batch 59 (157): mcc: 0.8651, acc: 0.8171, precision: 0.9078, recall: 0.8280, f1: 0.8661, edges-srl-ontonotes_loss: 0.0115
09/16 11:10:31 AM: Best result seen so far for edges-srl-ontonotes.
09/16 11:10:31 AM: Best result seen so far for macro.
09/16 11:10:31 AM: Updating LR scheduler:
09/16 11:10:31 AM: 	Best result seen so far for macro_avg: 0.878
09/16 11:10:31 AM: 	# validation passes without improvement: 0
09/16 11:10:31 AM: edges-srl-ontonotes_loss: training: 0.012226 validation: 0.010625
09/16 11:10:31 AM: macro_avg: validation: 0.877529
09/16 11:10:31 AM: micro_avg: validation: 0.000000
09/16 11:10:31 AM: edges-srl-ontonotes_mcc: training: 0.860585 validation: 0.876478
09/16 11:10:31 AM: edges-srl-ontonotes_acc: training: 0.804044 validation: 0.833346
09/16 11:10:31 AM: edges-srl-ontonotes_precision: training: 0.898284 validation: 0.914954
09/16 11:10:31 AM: edges-srl-ontonotes_recall: training: 0.828340 validation: 0.843045
09/16 11:10:31 AM: edges-srl-ontonotes_f1: training: 0.861895 validation: 0.877529
09/16 11:10:31 AM: Global learning rate: 0.0001
09/16 11:10:31 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:10:33 AM: Update 8031: task edges-srl-ontonotes, batch 31 (8031): mcc: 0.8375, acc: 0.7754, precision: 0.8767, recall: 0.8044, f1: 0.8390, edges-srl-ontonotes_loss: 0.0131
09/16 11:10:43 AM: Update 8157: task edges-srl-ontonotes, batch 157 (8157): mcc: 0.8522, acc: 0.7963, precision: 0.8892, recall: 0.8208, f1: 0.8536, edges-srl-ontonotes_loss: 0.0124
09/16 11:10:53 AM: Update 8240: task edges-srl-ontonotes, batch 240 (8240): mcc: 0.8498, acc: 0.7919, precision: 0.8876, recall: 0.8178, f1: 0.8513, edges-srl-ontonotes_loss: 0.0127
09/16 11:11:03 AM: Update 8376: task edges-srl-ontonotes, batch 376 (8376): mcc: 0.8465, acc: 0.7873, precision: 0.8859, recall: 0.8131, f1: 0.8479, edges-srl-ontonotes_loss: 0.0130
09/16 11:11:13 AM: Update 8497: task edges-srl-ontonotes, batch 497 (8497): mcc: 0.8461, acc: 0.7866, precision: 0.8857, recall: 0.8125, f1: 0.8475, edges-srl-ontonotes_loss: 0.0130
09/16 11:11:23 AM: Update 8602: task edges-srl-ontonotes, batch 602 (8602): mcc: 0.8454, acc: 0.7853, precision: 0.8858, recall: 0.8111, f1: 0.8468, edges-srl-ontonotes_loss: 0.0130
09/16 11:11:33 AM: Update 8721: task edges-srl-ontonotes, batch 721 (8721): mcc: 0.8464, acc: 0.7861, precision: 0.8873, recall: 0.8117, f1: 0.8478, edges-srl-ontonotes_loss: 0.0130
09/16 11:11:43 AM: Update 8832: task edges-srl-ontonotes, batch 832 (8832): mcc: 0.8470, acc: 0.7870, precision: 0.8872, recall: 0.8129, f1: 0.8484, edges-srl-ontonotes_loss: 0.0129
09/16 11:11:53 AM: Update 8942: task edges-srl-ontonotes, batch 942 (8942): mcc: 0.8434, acc: 0.7828, precision: 0.8843, recall: 0.8088, f1: 0.8448, edges-srl-ontonotes_loss: 0.0132
09/16 11:11:58 AM: ***** Step 9000 / Validation 9 *****
09/16 11:11:58 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:11:58 AM: Validating...
09/16 11:12:03 AM: Evaluate: task edges-srl-ontonotes, batch 66 (157): mcc: 0.8631, acc: 0.8125, precision: 0.9104, recall: 0.8219, f1: 0.8639, edges-srl-ontonotes_loss: 0.0115
09/16 11:12:10 AM: Updating LR scheduler:
09/16 11:12:10 AM: 	Best result seen so far for macro_avg: 0.878
09/16 11:12:10 AM: 	# validation passes without improvement: 1
09/16 11:12:10 AM: edges-srl-ontonotes_loss: training: 0.013259 validation: 0.010564
09/16 11:12:10 AM: macro_avg: validation: 0.876237
09/16 11:12:10 AM: micro_avg: validation: 0.000000
09/16 11:12:10 AM: edges-srl-ontonotes_mcc: training: 0.842064 validation: 0.875350
09/16 11:12:10 AM: edges-srl-ontonotes_acc: training: 0.781160 validation: 0.829651
09/16 11:12:10 AM: edges-srl-ontonotes_precision: training: 0.883309 validation: 0.917896
09/16 11:12:10 AM: edges-srl-ontonotes_recall: training: 0.807087 validation: 0.838196
09/16 11:12:10 AM: edges-srl-ontonotes_f1: training: 0.843480 validation: 0.876237
09/16 11:12:10 AM: Global learning rate: 0.0001
09/16 11:12:10 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:12:13 AM: Update 9035: task edges-srl-ontonotes, batch 35 (9035): mcc: 0.8351, acc: 0.7740, precision: 0.8764, recall: 0.8002, f1: 0.8366, edges-srl-ontonotes_loss: 0.0143
09/16 11:12:24 AM: Update 9125: task edges-srl-ontonotes, batch 125 (9125): mcc: 0.8332, acc: 0.7719, precision: 0.8748, recall: 0.7982, f1: 0.8347, edges-srl-ontonotes_loss: 0.0141
09/16 11:12:34 AM: Update 9249: task edges-srl-ontonotes, batch 249 (9249): mcc: 0.8315, acc: 0.7680, precision: 0.8746, recall: 0.7951, f1: 0.8330, edges-srl-ontonotes_loss: 0.0142
09/16 11:12:44 AM: Update 9366: task edges-srl-ontonotes, batch 366 (9366): mcc: 0.8323, acc: 0.7686, precision: 0.8752, recall: 0.7961, f1: 0.8338, edges-srl-ontonotes_loss: 0.0140
09/16 11:12:54 AM: Update 9472: task edges-srl-ontonotes, batch 472 (9472): mcc: 0.8337, acc: 0.7701, precision: 0.8774, recall: 0.7967, f1: 0.8351, edges-srl-ontonotes_loss: 0.0139
09/16 11:13:04 AM: Update 9582: task edges-srl-ontonotes, batch 582 (9582): mcc: 0.8390, acc: 0.7766, precision: 0.8815, recall: 0.8029, f1: 0.8404, edges-srl-ontonotes_loss: 0.0135
09/16 11:13:14 AM: Update 9692: task edges-srl-ontonotes, batch 692 (9692): mcc: 0.8410, acc: 0.7794, precision: 0.8833, recall: 0.8052, f1: 0.8424, edges-srl-ontonotes_loss: 0.0134
09/16 11:13:24 AM: Update 9790: task edges-srl-ontonotes, batch 790 (9790): mcc: 0.8420, acc: 0.7809, precision: 0.8839, recall: 0.8064, f1: 0.8434, edges-srl-ontonotes_loss: 0.0133
09/16 11:13:34 AM: Update 9917: task edges-srl-ontonotes, batch 917 (9917): mcc: 0.8438, acc: 0.7832, precision: 0.8854, recall: 0.8085, f1: 0.8452, edges-srl-ontonotes_loss: 0.0131
09/16 11:13:42 AM: ***** Step 10000 / Validation 10 *****
09/16 11:13:42 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:13:42 AM: Validating...
09/16 11:13:44 AM: Evaluate: task edges-srl-ontonotes, batch 38 (157): mcc: 0.8682, acc: 0.8242, precision: 0.9097, recall: 0.8323, f1: 0.8693, edges-srl-ontonotes_loss: 0.0110
09/16 11:13:54 AM: Best result seen so far for edges-srl-ontonotes.
09/16 11:13:54 AM: Best result seen so far for macro.
09/16 11:13:54 AM: Updating LR scheduler:
09/16 11:13:54 AM: 	Best result seen so far for macro_avg: 0.878
09/16 11:13:54 AM: 	# validation passes without improvement: 2
09/16 11:13:54 AM: edges-srl-ontonotes_loss: training: 0.013079 validation: 0.010504
09/16 11:13:54 AM: macro_avg: validation: 0.877612
09/16 11:13:54 AM: micro_avg: validation: 0.000000
09/16 11:13:54 AM: edges-srl-ontonotes_mcc: training: 0.844509 validation: 0.876460
09/16 11:13:54 AM: edges-srl-ontonotes_acc: training: 0.784001 validation: 0.835809
09/16 11:13:54 AM: edges-srl-ontonotes_precision: training: 0.886108 validation: 0.912429
09/16 11:13:54 AM: edges-srl-ontonotes_recall: training: 0.809136 validation: 0.845354
09/16 11:13:54 AM: edges-srl-ontonotes_f1: training: 0.845874 validation: 0.877612
09/16 11:13:54 AM: Global learning rate: 0.0001
09/16 11:13:54 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:13:55 AM: Update 10011: task edges-srl-ontonotes, batch 11 (10011): mcc: 0.8641, acc: 0.8112, precision: 0.8969, recall: 0.8364, f1: 0.8656, edges-srl-ontonotes_loss: 0.0113
09/16 11:14:05 AM: Update 10089: task edges-srl-ontonotes, batch 89 (10089): mcc: 0.8599, acc: 0.8073, precision: 0.8982, recall: 0.8272, f1: 0.8612, edges-srl-ontonotes_loss: 0.0122
09/16 11:14:15 AM: Update 10202: task edges-srl-ontonotes, batch 202 (10202): mcc: 0.8604, acc: 0.8053, precision: 0.8994, recall: 0.8270, f1: 0.8617, edges-srl-ontonotes_loss: 0.0120
09/16 11:14:25 AM: Update 10318: task edges-srl-ontonotes, batch 318 (10318): mcc: 0.8612, acc: 0.8062, precision: 0.8994, recall: 0.8284, f1: 0.8625, edges-srl-ontonotes_loss: 0.0120
09/16 11:14:35 AM: Update 10422: task edges-srl-ontonotes, batch 422 (10422): mcc: 0.8606, acc: 0.8053, precision: 0.8987, recall: 0.8280, f1: 0.8619, edges-srl-ontonotes_loss: 0.0120
09/16 11:14:45 AM: Update 10537: task edges-srl-ontonotes, batch 537 (10537): mcc: 0.8578, acc: 0.8022, precision: 0.8971, recall: 0.8242, f1: 0.8591, edges-srl-ontonotes_loss: 0.0122
09/16 11:14:55 AM: Update 10656: task edges-srl-ontonotes, batch 656 (10656): mcc: 0.8561, acc: 0.7997, precision: 0.8962, recall: 0.8218, f1: 0.8574, edges-srl-ontonotes_loss: 0.0123
09/16 11:15:05 AM: Update 10769: task edges-srl-ontonotes, batch 769 (10769): mcc: 0.8548, acc: 0.7979, precision: 0.8951, recall: 0.8203, f1: 0.8561, edges-srl-ontonotes_loss: 0.0124
09/16 11:15:15 AM: Update 10889: task edges-srl-ontonotes, batch 889 (10889): mcc: 0.8547, acc: 0.7976, precision: 0.8953, recall: 0.8200, f1: 0.8560, edges-srl-ontonotes_loss: 0.0124
09/16 11:15:24 AM: ***** Step 11000 / Validation 11 *****
09/16 11:15:24 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:15:24 AM: Validating...
09/16 11:15:25 AM: Evaluate: task edges-srl-ontonotes, batch 14 (157): mcc: 0.8631, acc: 0.8191, precision: 0.9062, recall: 0.8257, f1: 0.8641, edges-srl-ontonotes_loss: 0.0111
09/16 11:15:35 AM: Evaluate: task edges-srl-ontonotes, batch 147 (157): mcc: 0.8718, acc: 0.8284, precision: 0.9132, recall: 0.8359, f1: 0.8728, edges-srl-ontonotes_loss: 0.0108
09/16 11:15:36 AM: Updating LR scheduler:
09/16 11:15:36 AM: 	Best result seen so far for macro_avg: 0.878
09/16 11:15:36 AM: 	# validation passes without improvement: 3
09/16 11:15:36 AM: edges-srl-ontonotes_loss: training: 0.012395 validation: 0.010940
09/16 11:15:36 AM: macro_avg: validation: 0.871684
09/16 11:15:36 AM: micro_avg: validation: 0.000000
09/16 11:15:36 AM: edges-srl-ontonotes_mcc: training: 0.854354 validation: 0.870685
09/16 11:15:36 AM: edges-srl-ontonotes_acc: training: 0.796948 validation: 0.827111
09/16 11:15:36 AM: edges-srl-ontonotes_precision: training: 0.895107 validation: 0.912242
09/16 11:15:36 AM: edges-srl-ontonotes_recall: training: 0.819469 validation: 0.834578
09/16 11:15:36 AM: edges-srl-ontonotes_f1: training: 0.855619 validation: 0.871684
09/16 11:15:36 AM: Global learning rate: 0.0001
09/16 11:15:36 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:15:45 AM: Update 11109: task edges-srl-ontonotes, batch 109 (11109): mcc: 0.8504, acc: 0.7911, precision: 0.8906, recall: 0.8160, f1: 0.8517, edges-srl-ontonotes_loss: 0.0126
09/16 11:15:55 AM: Update 11228: task edges-srl-ontonotes, batch 228 (11228): mcc: 0.8490, acc: 0.7901, precision: 0.8903, recall: 0.8137, f1: 0.8503, edges-srl-ontonotes_loss: 0.0127
09/16 11:16:06 AM: Update 11316: task edges-srl-ontonotes, batch 316 (11316): mcc: 0.8484, acc: 0.7896, precision: 0.8898, recall: 0.8131, f1: 0.8498, edges-srl-ontonotes_loss: 0.0126
09/16 11:16:16 AM: Update 11427: task edges-srl-ontonotes, batch 427 (11427): mcc: 0.8494, acc: 0.7919, precision: 0.8897, recall: 0.8150, f1: 0.8507, edges-srl-ontonotes_loss: 0.0126
09/16 11:16:26 AM: Update 11547: task edges-srl-ontonotes, batch 547 (11547): mcc: 0.8518, acc: 0.7955, precision: 0.8916, recall: 0.8178, f1: 0.8531, edges-srl-ontonotes_loss: 0.0124
09/16 11:16:36 AM: Update 11647: task edges-srl-ontonotes, batch 647 (11647): mcc: 0.8527, acc: 0.7967, precision: 0.8924, recall: 0.8190, f1: 0.8541, edges-srl-ontonotes_loss: 0.0124
09/16 11:16:46 AM: Update 11752: task edges-srl-ontonotes, batch 752 (11752): mcc: 0.8542, acc: 0.7984, precision: 0.8937, recall: 0.8205, f1: 0.8555, edges-srl-ontonotes_loss: 0.0123
09/16 11:16:56 AM: Update 11867: task edges-srl-ontonotes, batch 867 (11867): mcc: 0.8562, acc: 0.8008, precision: 0.8954, recall: 0.8228, f1: 0.8575, edges-srl-ontonotes_loss: 0.0121
09/16 11:17:06 AM: Update 11976: task edges-srl-ontonotes, batch 976 (11976): mcc: 0.8548, acc: 0.7986, precision: 0.8945, recall: 0.8209, f1: 0.8561, edges-srl-ontonotes_loss: 0.0122
09/16 11:17:08 AM: ***** Step 12000 / Validation 12 *****
09/16 11:17:08 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:17:08 AM: Validating...
09/16 11:17:16 AM: Evaluate: task edges-srl-ontonotes, batch 102 (157): mcc: 0.8694, acc: 0.8223, precision: 0.9161, recall: 0.8286, f1: 0.8701, edges-srl-ontonotes_loss: 0.0108
09/16 11:17:20 AM: Updating LR scheduler:
09/16 11:17:20 AM: 	Best result seen so far for macro_avg: 0.878
09/16 11:17:20 AM: 	# validation passes without improvement: 0
09/16 11:17:20 AM: edges-srl-ontonotes_loss: training: 0.012267 validation: 0.010662
09/16 11:17:20 AM: macro_avg: validation: 0.875247
09/16 11:17:20 AM: micro_avg: validation: 0.000000
09/16 11:17:20 AM: edges-srl-ontonotes_mcc: training: 0.854261 validation: 0.874367
09/16 11:17:20 AM: edges-srl-ontonotes_acc: training: 0.797892 validation: 0.829959
09/16 11:17:20 AM: edges-srl-ontonotes_precision: training: 0.893972 validation: 0.917384
09/16 11:17:20 AM: edges-srl-ontonotes_recall: training: 0.820339 validation: 0.836810
09/16 11:17:20 AM: edges-srl-ontonotes_f1: training: 0.855574 validation: 0.875247
09/16 11:17:20 AM: Global learning rate: 5e-05
09/16 11:17:20 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:17:26 AM: Update 12060: task edges-srl-ontonotes, batch 60 (12060): mcc: 0.8374, acc: 0.7710, precision: 0.8865, recall: 0.7955, f1: 0.8385, edges-srl-ontonotes_loss: 0.0138
09/16 11:17:36 AM: Update 12164: task edges-srl-ontonotes, batch 164 (12164): mcc: 0.8383, acc: 0.7751, precision: 0.8860, recall: 0.7975, f1: 0.8394, edges-srl-ontonotes_loss: 0.0134
09/16 11:17:47 AM: Update 12255: task edges-srl-ontonotes, batch 255 (12255): mcc: 0.8375, acc: 0.7743, precision: 0.8851, recall: 0.7969, f1: 0.8387, edges-srl-ontonotes_loss: 0.0135
09/16 11:17:58 AM: Update 12388: task edges-srl-ontonotes, batch 388 (12388): mcc: 0.8478, acc: 0.7890, precision: 0.8908, recall: 0.8110, f1: 0.8490, edges-srl-ontonotes_loss: 0.0127
09/16 11:18:08 AM: Update 12521: task edges-srl-ontonotes, batch 521 (12521): mcc: 0.8550, acc: 0.7982, precision: 0.8953, recall: 0.8205, f1: 0.8563, edges-srl-ontonotes_loss: 0.0121
09/16 11:18:18 AM: Update 12638: task edges-srl-ontonotes, batch 638 (12638): mcc: 0.8620, acc: 0.8073, precision: 0.9004, recall: 0.8290, f1: 0.8632, edges-srl-ontonotes_loss: 0.0116
09/16 11:18:28 AM: Update 12773: task edges-srl-ontonotes, batch 773 (12773): mcc: 0.8705, acc: 0.8182, precision: 0.9065, recall: 0.8396, f1: 0.8718, edges-srl-ontonotes_loss: 0.0110
09/16 11:18:38 AM: Update 12895: task edges-srl-ontonotes, batch 895 (12895): mcc: 0.8761, acc: 0.8255, precision: 0.9106, recall: 0.8463, f1: 0.8773, edges-srl-ontonotes_loss: 0.0106
09/16 11:18:44 AM: ***** Step 13000 / Validation 13 *****
09/16 11:18:44 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:18:44 AM: Validating...
09/16 11:18:48 AM: Evaluate: task edges-srl-ontonotes, batch 41 (157): mcc: 0.8707, acc: 0.8255, precision: 0.9159, recall: 0.8313, f1: 0.8715, edges-srl-ontonotes_loss: 0.0110
09/16 11:18:56 AM: Best result seen so far for edges-srl-ontonotes.
09/16 11:18:56 AM: Best result seen so far for macro.
09/16 11:18:56 AM: Updating LR scheduler:
09/16 11:18:56 AM: 	Best result seen so far for macro_avg: 0.881
09/16 11:18:56 AM: 	# validation passes without improvement: 0
09/16 11:18:56 AM: edges-srl-ontonotes_loss: training: 0.010416 validation: 0.010385
09/16 11:18:56 AM: macro_avg: validation: 0.881478
09/16 11:18:56 AM: micro_avg: validation: 0.000000
09/16 11:18:56 AM: edges-srl-ontonotes_mcc: training: 0.879602 validation: 0.880414
09/16 11:18:56 AM: edges-srl-ontonotes_acc: training: 0.830296 validation: 0.840197
09/16 11:18:56 AM: edges-srl-ontonotes_precision: training: 0.913376 validation: 0.917201
09/16 11:18:56 AM: edges-srl-ontonotes_recall: training: 0.850454 validation: 0.848434
09/16 11:18:56 AM: edges-srl-ontonotes_f1: training: 0.880793 validation: 0.881478
09/16 11:18:56 AM: Global learning rate: 5e-05
09/16 11:18:56 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:18:58 AM: Update 13017: task edges-srl-ontonotes, batch 17 (13017): mcc: 0.8954, acc: 0.8495, precision: 0.9237, recall: 0.8710, f1: 0.8966, edges-srl-ontonotes_loss: 0.0091
09/16 11:19:08 AM: Update 13148: task edges-srl-ontonotes, batch 148 (13148): mcc: 0.9075, acc: 0.8670, precision: 0.9336, recall: 0.8848, f1: 0.9085, edges-srl-ontonotes_loss: 0.0084
09/16 11:19:18 AM: Update 13272: task edges-srl-ontonotes, batch 272 (13272): mcc: 0.9076, acc: 0.8670, precision: 0.9341, recall: 0.8844, f1: 0.9086, edges-srl-ontonotes_loss: 0.0085
09/16 11:19:28 AM: Update 13414: task edges-srl-ontonotes, batch 414 (13414): mcc: 0.9085, acc: 0.8687, precision: 0.9347, recall: 0.8856, f1: 0.9095, edges-srl-ontonotes_loss: 0.0085
09/16 11:19:38 AM: Update 13511: task edges-srl-ontonotes, batch 511 (13511): mcc: 0.9078, acc: 0.8683, precision: 0.9338, recall: 0.8851, f1: 0.9088, edges-srl-ontonotes_loss: 0.0085
09/16 11:19:48 AM: Update 13646: task edges-srl-ontonotes, batch 646 (13646): mcc: 0.9066, acc: 0.8672, precision: 0.9320, recall: 0.8846, f1: 0.9077, edges-srl-ontonotes_loss: 0.0086
09/16 11:19:58 AM: Update 13789: task edges-srl-ontonotes, batch 789 (13789): mcc: 0.9060, acc: 0.8669, precision: 0.9309, recall: 0.8844, f1: 0.9071, edges-srl-ontonotes_loss: 0.0086
09/16 11:20:08 AM: Update 13902: task edges-srl-ontonotes, batch 902 (13902): mcc: 0.9029, acc: 0.8628, precision: 0.9283, recall: 0.8809, f1: 0.9040, edges-srl-ontonotes_loss: 0.0089
09/16 11:20:17 AM: ***** Step 14000 / Validation 14 *****
09/16 11:20:17 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:20:17 AM: Validating...
09/16 11:20:18 AM: Evaluate: task edges-srl-ontonotes, batch 12 (157): mcc: 0.8999, acc: 0.8616, precision: 0.9307, recall: 0.8729, f1: 0.9009, edges-srl-ontonotes_loss: 0.0086
09/16 11:20:28 AM: Evaluate: task edges-srl-ontonotes, batch 137 (157): mcc: 0.8893, acc: 0.8522, precision: 0.9226, recall: 0.8603, f1: 0.8903, edges-srl-ontonotes_loss: 0.0097
09/16 11:20:29 AM: Best result seen so far for edges-srl-ontonotes.
09/16 11:20:29 AM: Best result seen so far for macro.
09/16 11:20:29 AM: Updating LR scheduler:
09/16 11:20:29 AM: 	Best result seen so far for macro_avg: 0.886
09/16 11:20:29 AM: 	# validation passes without improvement: 0
09/16 11:20:29 AM: edges-srl-ontonotes_loss: training: 0.009086 validation: 0.010016
09/16 11:20:29 AM: macro_avg: validation: 0.886391
09/16 11:20:29 AM: micro_avg: validation: 0.000000
09/16 11:20:29 AM: edges-srl-ontonotes_mcc: training: 0.900003 validation: 0.885288
09/16 11:20:29 AM: edges-srl-ontonotes_acc: training: 0.859108 validation: 0.847587
09/16 11:20:29 AM: edges-srl-ontonotes_precision: training: 0.926138 validation: 0.919223
09/16 11:20:29 AM: edges-srl-ontonotes_recall: training: 0.877464 validation: 0.855823
09/16 11:20:29 AM: edges-srl-ontonotes_f1: training: 0.901144 validation: 0.886391
09/16 11:20:29 AM: Global learning rate: 5e-05
09/16 11:20:29 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:20:38 AM: Update 14110: task edges-srl-ontonotes, batch 110 (14110): mcc: 0.8820, acc: 0.8361, precision: 0.9136, recall: 0.8547, f1: 0.8832, edges-srl-ontonotes_loss: 0.0104
09/16 11:20:48 AM: Update 14206: task edges-srl-ontonotes, batch 206 (14206): mcc: 0.8687, acc: 0.8192, precision: 0.9036, recall: 0.8389, f1: 0.8700, edges-srl-ontonotes_loss: 0.0113
09/16 11:20:58 AM: Update 14324: task edges-srl-ontonotes, batch 324 (14324): mcc: 0.8644, acc: 0.8135, precision: 0.8995, recall: 0.8344, f1: 0.8657, edges-srl-ontonotes_loss: 0.0116
09/16 11:21:08 AM: Update 14441: task edges-srl-ontonotes, batch 441 (14441): mcc: 0.8613, acc: 0.8094, precision: 0.8971, recall: 0.8307, f1: 0.8626, edges-srl-ontonotes_loss: 0.0118
09/16 11:21:18 AM: Update 14535: task edges-srl-ontonotes, batch 535 (14535): mcc: 0.8622, acc: 0.8104, precision: 0.8981, recall: 0.8315, f1: 0.8635, edges-srl-ontonotes_loss: 0.0118
09/16 11:21:28 AM: Update 14662: task edges-srl-ontonotes, batch 662 (14662): mcc: 0.8669, acc: 0.8166, precision: 0.9018, recall: 0.8370, f1: 0.8682, edges-srl-ontonotes_loss: 0.0114
09/16 11:21:38 AM: Update 14787: task edges-srl-ontonotes, batch 787 (14787): mcc: 0.8692, acc: 0.8192, precision: 0.9037, recall: 0.8397, f1: 0.8705, edges-srl-ontonotes_loss: 0.0113
09/16 11:21:48 AM: Update 14901: task edges-srl-ontonotes, batch 901 (14901): mcc: 0.8706, acc: 0.8210, precision: 0.9045, recall: 0.8416, f1: 0.8719, edges-srl-ontonotes_loss: 0.0112
09/16 11:21:56 AM: ***** Step 15000 / Validation 15 *****
09/16 11:21:56 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:21:56 AM: Validating...
09/16 11:21:58 AM: Evaluate: task edges-srl-ontonotes, batch 25 (157): mcc: 0.8960, acc: 0.8573, precision: 0.9300, recall: 0.8663, f1: 0.8970, edges-srl-ontonotes_loss: 0.0093
09/16 11:22:08 AM: Evaluate: task edges-srl-ontonotes, batch 147 (157): mcc: 0.8924, acc: 0.8563, precision: 0.9240, recall: 0.8648, f1: 0.8934, edges-srl-ontonotes_loss: 0.0093
09/16 11:22:09 AM: Best result seen so far for edges-srl-ontonotes.
09/16 11:22:09 AM: Best result seen so far for macro.
09/16 11:22:09 AM: Updating LR scheduler:
09/16 11:22:09 AM: 	Best result seen so far for macro_avg: 0.892
09/16 11:22:09 AM: 	# validation passes without improvement: 0
09/16 11:22:09 AM: edges-srl-ontonotes_loss: training: 0.011076 validation: 0.009527
09/16 11:22:09 AM: macro_avg: validation: 0.891566
09/16 11:22:09 AM: micro_avg: validation: 0.000000
09/16 11:22:09 AM: edges-srl-ontonotes_mcc: training: 0.872186 validation: 0.890457
09/16 11:22:09 AM: edges-srl-ontonotes_acc: training: 0.823091 validation: 0.854515
09/16 11:22:09 AM: edges-srl-ontonotes_precision: training: 0.905556 validation: 0.922109
09/16 11:22:09 AM: edges-srl-ontonotes_recall: training: 0.843635 validation: 0.862982
09/16 11:22:09 AM: edges-srl-ontonotes_f1: training: 0.873500 validation: 0.891566
09/16 11:22:09 AM: Global learning rate: 5e-05
09/16 11:22:09 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:22:19 AM: Update 15118: task edges-srl-ontonotes, batch 118 (15118): mcc: 0.8829, acc: 0.8367, precision: 0.9141, recall: 0.8560, f1: 0.8841, edges-srl-ontonotes_loss: 0.0101
09/16 11:22:29 AM: Update 15231: task edges-srl-ontonotes, batch 231 (15231): mcc: 0.8751, acc: 0.8267, precision: 0.9065, recall: 0.8483, f1: 0.8764, edges-srl-ontonotes_loss: 0.0108
09/16 11:22:39 AM: Update 15363: task edges-srl-ontonotes, batch 363 (15363): mcc: 0.8735, acc: 0.8251, precision: 0.9054, recall: 0.8463, f1: 0.8749, edges-srl-ontonotes_loss: 0.0109
09/16 11:22:49 AM: Update 15457: task edges-srl-ontonotes, batch 457 (15457): mcc: 0.8734, acc: 0.8245, precision: 0.9051, recall: 0.8465, f1: 0.8748, edges-srl-ontonotes_loss: 0.0109
09/16 11:22:59 AM: Update 15575: task edges-srl-ontonotes, batch 575 (15575): mcc: 0.8694, acc: 0.8193, precision: 0.9025, recall: 0.8413, f1: 0.8708, edges-srl-ontonotes_loss: 0.0112
09/16 11:23:09 AM: Update 15705: task edges-srl-ontonotes, batch 705 (15705): mcc: 0.8680, acc: 0.8170, precision: 0.9017, recall: 0.8392, f1: 0.8693, edges-srl-ontonotes_loss: 0.0113
09/16 11:23:19 AM: Update 15814: task edges-srl-ontonotes, batch 814 (15814): mcc: 0.8668, acc: 0.8154, precision: 0.9007, recall: 0.8379, f1: 0.8682, edges-srl-ontonotes_loss: 0.0113
09/16 11:23:29 AM: Update 15934: task edges-srl-ontonotes, batch 934 (15934): mcc: 0.8664, acc: 0.8152, precision: 0.9002, recall: 0.8377, f1: 0.8678, edges-srl-ontonotes_loss: 0.0114
09/16 11:23:35 AM: ***** Step 16000 / Validation 16 *****
09/16 11:23:35 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:23:35 AM: Validating...
09/16 11:23:39 AM: Evaluate: task edges-srl-ontonotes, batch 57 (157): mcc: 0.8796, acc: 0.8395, precision: 0.9166, recall: 0.8475, f1: 0.8807, edges-srl-ontonotes_loss: 0.0101
09/16 11:23:47 AM: Updating LR scheduler:
09/16 11:23:47 AM: 	Best result seen so far for macro_avg: 0.892
09/16 11:23:47 AM: 	# validation passes without improvement: 1
09/16 11:23:47 AM: edges-srl-ontonotes_loss: training: 0.011376 validation: 0.009322
09/16 11:23:47 AM: macro_avg: validation: 0.891488
09/16 11:23:47 AM: micro_avg: validation: 0.000000
09/16 11:23:47 AM: edges-srl-ontonotes_mcc: training: 0.866113 validation: 0.890389
09/16 11:23:47 AM: edges-srl-ontonotes_acc: training: 0.814553 validation: 0.854823
09/16 11:23:47 AM: edges-srl-ontonotes_precision: training: 0.900005 validation: 0.922380
09/16 11:23:47 AM: edges-srl-ontonotes_recall: training: 0.837251 validation: 0.862597
09/16 11:23:47 AM: edges-srl-ontonotes_f1: training: 0.867495 validation: 0.891488
09/16 11:23:47 AM: Global learning rate: 5e-05
09/16 11:23:47 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:23:49 AM: Update 16025: task edges-srl-ontonotes, batch 25 (16025): mcc: 0.8665, acc: 0.8172, precision: 0.8949, recall: 0.8428, f1: 0.8681, edges-srl-ontonotes_loss: 0.0113
09/16 11:23:59 AM: Update 16128: task edges-srl-ontonotes, batch 128 (16128): mcc: 0.8539, acc: 0.8005, precision: 0.8881, recall: 0.8251, f1: 0.8554, edges-srl-ontonotes_loss: 0.0123
09/16 11:24:09 AM: Update 16249: task edges-srl-ontonotes, batch 249 (16249): mcc: 0.8451, acc: 0.7885, precision: 0.8829, recall: 0.8133, f1: 0.8467, edges-srl-ontonotes_loss: 0.0128
09/16 11:24:19 AM: Update 16356: task edges-srl-ontonotes, batch 356 (16356): mcc: 0.8443, acc: 0.7866, precision: 0.8829, recall: 0.8117, f1: 0.8458, edges-srl-ontonotes_loss: 0.0129
09/16 11:24:29 AM: Update 16435: task edges-srl-ontonotes, batch 435 (16435): mcc: 0.8436, acc: 0.7862, precision: 0.8820, recall: 0.8113, f1: 0.8452, edges-srl-ontonotes_loss: 0.0129
09/16 11:24:39 AM: Update 16548: task edges-srl-ontonotes, batch 548 (16548): mcc: 0.8436, acc: 0.7863, precision: 0.8828, recall: 0.8106, f1: 0.8451, edges-srl-ontonotes_loss: 0.0129
09/16 11:24:49 AM: Update 16660: task edges-srl-ontonotes, batch 660 (16660): mcc: 0.8445, acc: 0.7870, precision: 0.8842, recall: 0.8109, f1: 0.8460, edges-srl-ontonotes_loss: 0.0128
09/16 11:24:59 AM: Update 16756: task edges-srl-ontonotes, batch 756 (16756): mcc: 0.8469, acc: 0.7900, precision: 0.8860, recall: 0.8138, f1: 0.8484, edges-srl-ontonotes_loss: 0.0126
09/16 11:25:09 AM: Update 16862: task edges-srl-ontonotes, batch 862 (16862): mcc: 0.8501, acc: 0.7938, precision: 0.8889, recall: 0.8171, f1: 0.8515, edges-srl-ontonotes_loss: 0.0124
09/16 11:25:19 AM: Update 16974: task edges-srl-ontonotes, batch 974 (16974): mcc: 0.8527, acc: 0.7970, precision: 0.8911, recall: 0.8201, f1: 0.8541, edges-srl-ontonotes_loss: 0.0123
09/16 11:25:23 AM: ***** Step 17000 / Validation 17 *****
09/16 11:25:23 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:25:23 AM: Validating...
09/16 11:25:29 AM: Evaluate: task edges-srl-ontonotes, batch 83 (157): mcc: 0.8834, acc: 0.8421, precision: 0.9217, recall: 0.8500, f1: 0.8844, edges-srl-ontonotes_loss: 0.0098
09/16 11:25:35 AM: Updating LR scheduler:
09/16 11:25:35 AM: 	Best result seen so far for macro_avg: 0.892
09/16 11:25:35 AM: 	# validation passes without improvement: 2
09/16 11:25:35 AM: edges-srl-ontonotes_loss: training: 0.012245 validation: 0.009453
09/16 11:25:35 AM: macro_avg: validation: 0.890148
09/16 11:25:35 AM: micro_avg: validation: 0.000000
09/16 11:25:35 AM: edges-srl-ontonotes_mcc: training: 0.852875 validation: 0.889126
09/16 11:25:35 AM: edges-srl-ontonotes_acc: training: 0.797209 validation: 0.851590
09/16 11:25:35 AM: edges-srl-ontonotes_precision: training: 0.891264 validation: 0.923752
09/16 11:25:35 AM: edges-srl-ontonotes_recall: training: 0.820217 validation: 0.858902
09/16 11:25:35 AM: edges-srl-ontonotes_f1: training: 0.854266 validation: 0.890148
09/16 11:25:35 AM: Global learning rate: 5e-05
09/16 11:25:35 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:25:39 AM: Update 17047: task edges-srl-ontonotes, batch 47 (17047): mcc: 0.8653, acc: 0.8193, precision: 0.8989, recall: 0.8367, f1: 0.8667, edges-srl-ontonotes_loss: 0.0117
09/16 11:25:49 AM: Update 17157: task edges-srl-ontonotes, batch 157 (17157): mcc: 0.8689, acc: 0.8197, precision: 0.9027, recall: 0.8400, f1: 0.8702, edges-srl-ontonotes_loss: 0.0112
09/16 11:26:00 AM: Update 17277: task edges-srl-ontonotes, batch 277 (17277): mcc: 0.8692, acc: 0.8188, precision: 0.9042, recall: 0.8393, f1: 0.8705, edges-srl-ontonotes_loss: 0.0112
09/16 11:26:10 AM: Update 17389: task edges-srl-ontonotes, batch 389 (17389): mcc: 0.8694, acc: 0.8191, precision: 0.9041, recall: 0.8397, f1: 0.8707, edges-srl-ontonotes_loss: 0.0112
09/16 11:26:20 AM: Update 17503: task edges-srl-ontonotes, batch 503 (17503): mcc: 0.8712, acc: 0.8209, precision: 0.9056, recall: 0.8417, f1: 0.8725, edges-srl-ontonotes_loss: 0.0110
09/16 11:26:30 AM: Update 17617: task edges-srl-ontonotes, batch 617 (17617): mcc: 0.8723, acc: 0.8222, precision: 0.9063, recall: 0.8431, f1: 0.8736, edges-srl-ontonotes_loss: 0.0110
09/16 11:26:40 AM: Update 17697: task edges-srl-ontonotes, batch 697 (17697): mcc: 0.8712, acc: 0.8209, precision: 0.9053, recall: 0.8419, f1: 0.8725, edges-srl-ontonotes_loss: 0.0111
09/16 11:26:50 AM: Update 17810: task edges-srl-ontonotes, batch 810 (17810): mcc: 0.8695, acc: 0.8186, precision: 0.9043, recall: 0.8397, f1: 0.8708, edges-srl-ontonotes_loss: 0.0112
09/16 11:27:00 AM: Update 17921: task edges-srl-ontonotes, batch 921 (17921): mcc: 0.8684, acc: 0.8174, precision: 0.9034, recall: 0.8384, f1: 0.8697, edges-srl-ontonotes_loss: 0.0112
09/16 11:27:08 AM: ***** Step 18000 / Validation 18 *****
09/16 11:27:08 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:27:08 AM: Validating...
09/16 11:27:10 AM: Evaluate: task edges-srl-ontonotes, batch 22 (157): mcc: 0.8824, acc: 0.8410, precision: 0.9190, recall: 0.8505, f1: 0.8834, edges-srl-ontonotes_loss: 0.0093
09/16 11:27:20 AM: Evaluate: task edges-srl-ontonotes, batch 148 (157): mcc: 0.8886, acc: 0.8508, precision: 0.9226, recall: 0.8591, f1: 0.8897, edges-srl-ontonotes_loss: 0.0094
09/16 11:27:21 AM: Updating LR scheduler:
09/16 11:27:21 AM: 	Best result seen so far for macro_avg: 0.892
09/16 11:27:21 AM: 	# validation passes without improvement: 3
09/16 11:27:21 AM: edges-srl-ontonotes_loss: training: 0.011290 validation: 0.009612
09/16 11:27:21 AM: macro_avg: validation: 0.887932
09/16 11:27:21 AM: micro_avg: validation: 0.000000
09/16 11:27:21 AM: edges-srl-ontonotes_mcc: training: 0.867435 validation: 0.886857
09/16 11:27:21 AM: edges-srl-ontonotes_acc: training: 0.816097 validation: 0.848972
09/16 11:27:21 AM: edges-srl-ontonotes_precision: training: 0.902727 validation: 0.920939
09/16 11:27:21 AM: edges-srl-ontonotes_recall: training: 0.837226 validation: 0.857209
09/16 11:27:21 AM: edges-srl-ontonotes_f1: training: 0.868744 validation: 0.887932
09/16 11:27:21 AM: Global learning rate: 5e-05
09/16 11:27:21 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:27:30 AM: Update 18109: task edges-srl-ontonotes, batch 109 (18109): mcc: 0.8681, acc: 0.8153, precision: 0.9052, recall: 0.8362, f1: 0.8693, edges-srl-ontonotes_loss: 0.0114
09/16 11:27:40 AM: Update 18221: task edges-srl-ontonotes, batch 221 (18221): mcc: 0.8676, acc: 0.8146, precision: 0.9042, recall: 0.8362, f1: 0.8689, edges-srl-ontonotes_loss: 0.0114
09/16 11:27:50 AM: Update 18332: task edges-srl-ontonotes, batch 332 (18332): mcc: 0.8669, acc: 0.8137, precision: 0.9032, recall: 0.8359, f1: 0.8682, edges-srl-ontonotes_loss: 0.0114
09/16 11:28:00 AM: Update 18442: task edges-srl-ontonotes, batch 442 (18442): mcc: 0.8636, acc: 0.8095, precision: 0.9008, recall: 0.8318, f1: 0.8649, edges-srl-ontonotes_loss: 0.0116
09/16 11:28:10 AM: Update 18560: task edges-srl-ontonotes, batch 560 (18560): mcc: 0.8638, acc: 0.8097, precision: 0.9012, recall: 0.8317, f1: 0.8651, edges-srl-ontonotes_loss: 0.0115
09/16 11:28:20 AM: Update 18648: task edges-srl-ontonotes, batch 648 (18648): mcc: 0.8645, acc: 0.8108, precision: 0.9016, recall: 0.8328, f1: 0.8658, edges-srl-ontonotes_loss: 0.0115
09/16 11:28:30 AM: Update 18767: task edges-srl-ontonotes, batch 767 (18767): mcc: 0.8644, acc: 0.8115, precision: 0.9009, recall: 0.8331, f1: 0.8657, edges-srl-ontonotes_loss: 0.0115
09/16 11:28:41 AM: Update 18875: task edges-srl-ontonotes, batch 875 (18875): mcc: 0.8648, acc: 0.8122, precision: 0.9012, recall: 0.8337, f1: 0.8661, edges-srl-ontonotes_loss: 0.0114
09/16 11:28:51 AM: Update 18992: task edges-srl-ontonotes, batch 992 (18992): mcc: 0.8656, acc: 0.8133, precision: 0.9021, recall: 0.8344, f1: 0.8669, edges-srl-ontonotes_loss: 0.0114
09/16 11:28:51 AM: ***** Step 19000 / Validation 19 *****
09/16 11:28:51 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:28:51 AM: Validating...
09/16 11:29:01 AM: Evaluate: task edges-srl-ontonotes, batch 118 (157): mcc: 0.8847, acc: 0.8465, precision: 0.9193, recall: 0.8547, f1: 0.8858, edges-srl-ontonotes_loss: 0.0097
09/16 11:29:04 AM: Updating LR scheduler:
09/16 11:29:04 AM: 	Best result seen so far for macro_avg: 0.892
09/16 11:29:04 AM: 	# validation passes without improvement: 0
09/16 11:29:04 AM: edges-srl-ontonotes_loss: training: 0.011368 validation: 0.009687
09/16 11:29:04 AM: macro_avg: validation: 0.886772
09/16 11:29:04 AM: micro_avg: validation: 0.000000
09/16 11:29:04 AM: edges-srl-ontonotes_mcc: training: 0.865748 validation: 0.885668
09/16 11:29:04 AM: edges-srl-ontonotes_acc: training: 0.813433 validation: 0.848049
09/16 11:29:04 AM: edges-srl-ontonotes_precision: training: 0.902149 validation: 0.919421
09/16 11:29:04 AM: edges-srl-ontonotes_recall: training: 0.834556 validation: 0.856362
09/16 11:29:04 AM: edges-srl-ontonotes_f1: training: 0.867037 validation: 0.886772
09/16 11:29:04 AM: Global learning rate: 2.5e-05
09/16 11:29:04 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:29:11 AM: Update 19079: task edges-srl-ontonotes, batch 79 (19079): mcc: 0.8676, acc: 0.8159, precision: 0.8998, recall: 0.8403, f1: 0.8690, edges-srl-ontonotes_loss: 0.0110
09/16 11:29:22 AM: Update 19188: task edges-srl-ontonotes, batch 188 (19188): mcc: 0.8681, acc: 0.8153, precision: 0.9031, recall: 0.8380, f1: 0.8694, edges-srl-ontonotes_loss: 0.0109
09/16 11:29:32 AM: Update 19297: task edges-srl-ontonotes, batch 297 (19297): mcc: 0.8575, acc: 0.8022, precision: 0.8953, recall: 0.8252, f1: 0.8588, edges-srl-ontonotes_loss: 0.0117
09/16 11:29:42 AM: Update 19398: task edges-srl-ontonotes, batch 398 (19398): mcc: 0.8537, acc: 0.7969, precision: 0.8931, recall: 0.8201, f1: 0.8551, edges-srl-ontonotes_loss: 0.0120
09/16 11:29:53 AM: Update 19501: task edges-srl-ontonotes, batch 501 (19501): mcc: 0.8522, acc: 0.7953, precision: 0.8925, recall: 0.8178, f1: 0.8535, edges-srl-ontonotes_loss: 0.0122
09/16 11:30:03 AM: Update 19620: task edges-srl-ontonotes, batch 620 (19620): mcc: 0.8589, acc: 0.8043, precision: 0.8974, recall: 0.8260, f1: 0.8602, edges-srl-ontonotes_loss: 0.0117
09/16 11:30:13 AM: Update 19734: task edges-srl-ontonotes, batch 734 (19734): mcc: 0.8625, acc: 0.8091, precision: 0.8995, recall: 0.8308, f1: 0.8638, edges-srl-ontonotes_loss: 0.0115
09/16 11:30:23 AM: Update 19833: task edges-srl-ontonotes, batch 833 (19833): mcc: 0.8653, acc: 0.8131, precision: 0.9011, recall: 0.8347, f1: 0.8667, edges-srl-ontonotes_loss: 0.0113
09/16 11:30:33 AM: Update 19974: task edges-srl-ontonotes, batch 974 (19974): mcc: 0.8716, acc: 0.8213, precision: 0.9054, recall: 0.8427, f1: 0.8729, edges-srl-ontonotes_loss: 0.0108
09/16 11:30:35 AM: ***** Step 20000 / Validation 20 *****
09/16 11:30:35 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:30:35 AM: Validating...
09/16 11:30:43 AM: Evaluate: task edges-srl-ontonotes, batch 85 (157): mcc: 0.8817, acc: 0.8392, precision: 0.9221, recall: 0.8463, f1: 0.8826, edges-srl-ontonotes_loss: 0.0099
09/16 11:30:50 AM: Updating LR scheduler:
09/16 11:30:50 AM: 	Best result seen so far for macro_avg: 0.892
09/16 11:30:50 AM: 	# validation passes without improvement: 1
09/16 11:30:50 AM: edges-srl-ontonotes_loss: training: 0.010742 validation: 0.009527
09/16 11:30:50 AM: macro_avg: validation: 0.888587
09/16 11:30:50 AM: micro_avg: validation: 0.000000
09/16 11:30:50 AM: edges-srl-ontonotes_mcc: training: 0.872768 validation: 0.887610
09/16 11:30:50 AM: edges-srl-ontonotes_acc: training: 0.822859 validation: 0.849588
09/16 11:30:50 AM: edges-srl-ontonotes_precision: training: 0.906189 validation: 0.923959
09/16 11:30:50 AM: edges-srl-ontonotes_recall: training: 0.844152 validation: 0.855823
09/16 11:30:50 AM: edges-srl-ontonotes_f1: training: 0.874071 validation: 0.888587
09/16 11:30:50 AM: Global learning rate: 2.5e-05
09/16 11:30:50 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:30:53 AM: Update 20036: task edges-srl-ontonotes, batch 36 (20036): mcc: 0.9105, acc: 0.8694, precision: 0.9331, recall: 0.8910, f1: 0.9116, edges-srl-ontonotes_loss: 0.0079
09/16 11:31:03 AM: Update 20170: task edges-srl-ontonotes, batch 170 (20170): mcc: 0.9136, acc: 0.8768, precision: 0.9372, recall: 0.8931, f1: 0.9147, edges-srl-ontonotes_loss: 0.0077
09/16 11:31:13 AM: Update 20306: task edges-srl-ontonotes, batch 306 (20306): mcc: 0.9130, acc: 0.8756, precision: 0.9375, recall: 0.8916, f1: 0.9140, edges-srl-ontonotes_loss: 0.0078
09/16 11:31:24 AM: Update 20440: task edges-srl-ontonotes, batch 440 (20440): mcc: 0.9126, acc: 0.8757, precision: 0.9370, recall: 0.8914, f1: 0.9136, edges-srl-ontonotes_loss: 0.0079
09/16 11:31:34 AM: Update 20594: task edges-srl-ontonotes, batch 594 (20594): mcc: 0.9123, acc: 0.8752, precision: 0.9363, recall: 0.8915, f1: 0.9134, edges-srl-ontonotes_loss: 0.0079
09/16 11:31:44 AM: Update 20740: task edges-srl-ontonotes, batch 740 (20740): mcc: 0.9114, acc: 0.8743, precision: 0.9354, recall: 0.8906, f1: 0.9125, edges-srl-ontonotes_loss: 0.0079
09/16 11:31:54 AM: Update 20811: task edges-srl-ontonotes, batch 811 (20811): mcc: 0.9109, acc: 0.8739, precision: 0.9347, recall: 0.8903, f1: 0.9119, edges-srl-ontonotes_loss: 0.0080
09/16 11:32:04 AM: Update 20946: task edges-srl-ontonotes, batch 946 (20946): mcc: 0.9096, acc: 0.8725, precision: 0.9333, recall: 0.8891, f1: 0.9107, edges-srl-ontonotes_loss: 0.0081
09/16 11:32:08 AM: ***** Step 21000 / Validation 21 *****
09/16 11:32:08 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:32:08 AM: Validating...
09/16 11:32:14 AM: Evaluate: task edges-srl-ontonotes, batch 83 (157): mcc: 0.8859, acc: 0.8440, precision: 0.9259, recall: 0.8507, f1: 0.8867, edges-srl-ontonotes_loss: 0.0098
09/16 11:32:20 AM: Updating LR scheduler:
09/16 11:32:20 AM: 	Best result seen so far for macro_avg: 0.892
09/16 11:32:20 AM: 	# validation passes without improvement: 2
09/16 11:32:20 AM: edges-srl-ontonotes_loss: training: 0.008089 validation: 0.009414
09/16 11:32:20 AM: macro_avg: validation: 0.891481
09/16 11:32:20 AM: micro_avg: validation: 0.000000
09/16 11:32:20 AM: edges-srl-ontonotes_mcc: training: 0.909852 validation: 0.890529
09/16 11:32:20 AM: edges-srl-ontonotes_acc: training: 0.872854 validation: 0.852975
09/16 11:32:20 AM: edges-srl-ontonotes_precision: training: 0.933367 validation: 0.926449
09/16 11:32:20 AM: edges-srl-ontonotes_recall: training: 0.889523 validation: 0.859056
09/16 11:32:20 AM: edges-srl-ontonotes_f1: training: 0.910917 validation: 0.891481
09/16 11:32:20 AM: Global learning rate: 2.5e-05
09/16 11:32:20 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:32:25 AM: Update 21066: task edges-srl-ontonotes, batch 66 (21066): mcc: 0.9105, acc: 0.8752, precision: 0.9320, recall: 0.8920, f1: 0.9116, edges-srl-ontonotes_loss: 0.0083
09/16 11:32:35 AM: Update 21187: task edges-srl-ontonotes, batch 187 (21187): mcc: 0.8916, acc: 0.8497, precision: 0.9186, recall: 0.8686, f1: 0.8929, edges-srl-ontonotes_loss: 0.0095
09/16 11:32:45 AM: Update 21309: task edges-srl-ontonotes, batch 309 (21309): mcc: 0.8868, acc: 0.8436, precision: 0.9140, recall: 0.8636, f1: 0.8881, edges-srl-ontonotes_loss: 0.0099
09/16 11:32:55 AM: Update 21417: task edges-srl-ontonotes, batch 417 (21417): mcc: 0.8824, acc: 0.8372, precision: 0.9116, recall: 0.8574, f1: 0.8837, edges-srl-ontonotes_loss: 0.0102
09/16 11:33:05 AM: Update 21543: task edges-srl-ontonotes, batch 543 (21543): mcc: 0.8779, acc: 0.8313, precision: 0.9083, recall: 0.8520, f1: 0.8792, edges-srl-ontonotes_loss: 0.0105
09/16 11:33:15 AM: Update 21657: task edges-srl-ontonotes, batch 657 (21657): mcc: 0.8753, acc: 0.8280, precision: 0.9065, recall: 0.8487, f1: 0.8766, edges-srl-ontonotes_loss: 0.0108
09/16 11:33:25 AM: Update 21741: task edges-srl-ontonotes, batch 741 (21741): mcc: 0.8734, acc: 0.8256, precision: 0.9052, recall: 0.8463, f1: 0.8747, edges-srl-ontonotes_loss: 0.0109
09/16 11:33:35 AM: Update 21875: task edges-srl-ontonotes, batch 875 (21875): mcc: 0.8754, acc: 0.8279, precision: 0.9069, recall: 0.8485, f1: 0.8767, edges-srl-ontonotes_loss: 0.0108
09/16 11:33:44 AM: ***** Step 22000 / Validation 22 *****
09/16 11:33:44 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:33:44 AM: Validating...
09/16 11:33:45 AM: Evaluate: task edges-srl-ontonotes, batch 16 (157): mcc: 0.9014, acc: 0.8657, precision: 0.9330, recall: 0.8737, f1: 0.9024, edges-srl-ontonotes_loss: 0.0084
09/16 11:33:55 AM: Evaluate: task edges-srl-ontonotes, batch 148 (157): mcc: 0.8961, acc: 0.8625, precision: 0.9265, recall: 0.8697, f1: 0.8972, edges-srl-ontonotes_loss: 0.0090
09/16 11:33:56 AM: Best result seen so far for edges-srl-ontonotes.
09/16 11:33:56 AM: Best result seen so far for macro.
09/16 11:33:56 AM: Updating LR scheduler:
09/16 11:33:56 AM: 	Best result seen so far for macro_avg: 0.895
09/16 11:33:56 AM: 	# validation passes without improvement: 0
09/16 11:33:56 AM: edges-srl-ontonotes_loss: training: 0.010659 validation: 0.009174
09/16 11:33:56 AM: macro_avg: validation: 0.894933
09/16 11:33:56 AM: micro_avg: validation: 0.000000
09/16 11:33:56 AM: edges-srl-ontonotes_mcc: training: 0.876758 validation: 0.893831
09/16 11:33:56 AM: edges-srl-ontonotes_acc: training: 0.829580 validation: 0.860211
09/16 11:33:56 AM: edges-srl-ontonotes_precision: training: 0.908117 validation: 0.924219
09/16 11:33:56 AM: edges-srl-ontonotes_recall: training: 0.849959 validation: 0.867447
09/16 11:33:56 AM: edges-srl-ontonotes_f1: training: 0.878076 validation: 0.894933
09/16 11:33:56 AM: Global learning rate: 2.5e-05
09/16 11:33:56 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:34:05 AM: Update 22116: task edges-srl-ontonotes, batch 116 (22116): mcc: 0.8849, acc: 0.8410, precision: 0.9143, recall: 0.8598, f1: 0.8862, edges-srl-ontonotes_loss: 0.0101
09/16 11:34:15 AM: Update 22255: task edges-srl-ontonotes, batch 255 (22255): mcc: 0.8866, acc: 0.8421, precision: 0.9161, recall: 0.8612, f1: 0.8878, edges-srl-ontonotes_loss: 0.0099
09/16 11:34:25 AM: Update 22376: task edges-srl-ontonotes, batch 376 (22376): mcc: 0.8866, acc: 0.8414, precision: 0.9164, recall: 0.8611, f1: 0.8879, edges-srl-ontonotes_loss: 0.0099
09/16 11:34:35 AM: Update 22513: task edges-srl-ontonotes, batch 513 (22513): mcc: 0.8839, acc: 0.8379, precision: 0.9140, recall: 0.8581, f1: 0.8852, edges-srl-ontonotes_loss: 0.0101
09/16 11:34:45 AM: Update 22648: task edges-srl-ontonotes, batch 648 (22648): mcc: 0.8827, acc: 0.8369, precision: 0.9129, recall: 0.8569, f1: 0.8840, edges-srl-ontonotes_loss: 0.0102
09/16 11:34:55 AM: Update 22743: task edges-srl-ontonotes, batch 743 (22743): mcc: 0.8805, acc: 0.8343, precision: 0.9112, recall: 0.8543, f1: 0.8818, edges-srl-ontonotes_loss: 0.0104
09/16 11:35:05 AM: Update 22878: task edges-srl-ontonotes, batch 878 (22878): mcc: 0.8779, acc: 0.8307, precision: 0.9093, recall: 0.8510, f1: 0.8792, edges-srl-ontonotes_loss: 0.0105
09/16 11:35:15 AM: Update 22993: task edges-srl-ontonotes, batch 993 (22993): mcc: 0.8765, acc: 0.8290, precision: 0.9080, recall: 0.8496, f1: 0.8778, edges-srl-ontonotes_loss: 0.0106
09/16 11:35:16 AM: ***** Step 23000 / Validation 23 *****
09/16 11:35:16 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:35:16 AM: Validating...
09/16 11:35:25 AM: Evaluate: task edges-srl-ontonotes, batch 128 (157): mcc: 0.8999, acc: 0.8667, precision: 0.9314, recall: 0.8722, f1: 0.9008, edges-srl-ontonotes_loss: 0.0086
09/16 11:35:28 AM: Best result seen so far for edges-srl-ontonotes.
09/16 11:35:28 AM: Best result seen so far for macro.
09/16 11:35:28 AM: Updating LR scheduler:
09/16 11:35:28 AM: 	Best result seen so far for macro_avg: 0.897
09/16 11:35:28 AM: 	# validation passes without improvement: 0
09/16 11:35:28 AM: edges-srl-ontonotes_loss: training: 0.010641 validation: 0.008949
09/16 11:35:28 AM: macro_avg: validation: 0.896623
09/16 11:35:28 AM: micro_avg: validation: 0.000000
09/16 11:35:28 AM: edges-srl-ontonotes_mcc: training: 0.876455 validation: 0.895603
09/16 11:35:28 AM: edges-srl-ontonotes_acc: training: 0.828847 validation: 0.861981
09/16 11:35:28 AM: edges-srl-ontonotes_precision: training: 0.908054 validation: 0.927654
09/16 11:35:28 AM: edges-srl-ontonotes_recall: training: 0.849441 validation: 0.867601
09/16 11:35:28 AM: edges-srl-ontonotes_f1: training: 0.877770 validation: 0.896623
09/16 11:35:28 AM: Global learning rate: 2.5e-05
09/16 11:35:28 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:35:35 AM: Update 23097: task edges-srl-ontonotes, batch 97 (23097): mcc: 0.8722, acc: 0.8212, precision: 0.9036, recall: 0.8454, f1: 0.8735, edges-srl-ontonotes_loss: 0.0108
09/16 11:35:45 AM: Update 23210: task edges-srl-ontonotes, batch 210 (23210): mcc: 0.8703, acc: 0.8206, precision: 0.9024, recall: 0.8430, f1: 0.8717, edges-srl-ontonotes_loss: 0.0109
09/16 11:35:55 AM: Update 23313: task edges-srl-ontonotes, batch 313 (23313): mcc: 0.8674, acc: 0.8156, precision: 0.9006, recall: 0.8392, f1: 0.8688, edges-srl-ontonotes_loss: 0.0111
09/16 11:36:06 AM: Update 23439: task edges-srl-ontonotes, batch 439 (23439): mcc: 0.8598, acc: 0.8064, precision: 0.8946, recall: 0.8304, f1: 0.8613, edges-srl-ontonotes_loss: 0.0116
09/16 11:36:16 AM: Update 23566: task edges-srl-ontonotes, batch 566 (23566): mcc: 0.8563, acc: 0.8022, precision: 0.8920, recall: 0.8260, f1: 0.8577, edges-srl-ontonotes_loss: 0.0118
09/16 11:36:26 AM: Update 23677: task edges-srl-ontonotes, batch 677 (23677): mcc: 0.8550, acc: 0.8003, precision: 0.8910, recall: 0.8244, f1: 0.8565, edges-srl-ontonotes_loss: 0.0119
09/16 11:36:36 AM: Update 23807: task edges-srl-ontonotes, batch 807 (23807): mcc: 0.8537, acc: 0.7987, precision: 0.8902, recall: 0.8227, f1: 0.8551, edges-srl-ontonotes_loss: 0.0120
09/16 11:36:48 AM: Update 23930: task edges-srl-ontonotes, batch 930 (23930): mcc: 0.8533, acc: 0.7984, precision: 0.8901, recall: 0.8222, f1: 0.8548, edges-srl-ontonotes_loss: 0.0121
09/16 11:36:53 AM: ***** Step 24000 / Validation 24 *****
09/16 11:36:53 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:36:53 AM: Validating...
09/16 11:36:58 AM: Evaluate: task edges-srl-ontonotes, batch 60 (157): mcc: 0.8841, acc: 0.8457, precision: 0.9196, recall: 0.8532, f1: 0.8852, edges-srl-ontonotes_loss: 0.0097
09/16 11:37:05 AM: Updating LR scheduler:
09/16 11:37:05 AM: 	Best result seen so far for macro_avg: 0.897
09/16 11:37:05 AM: 	# validation passes without improvement: 1
09/16 11:37:05 AM: edges-srl-ontonotes_loss: training: 0.011927 validation: 0.009035
09/16 11:37:05 AM: macro_avg: validation: 0.894762
09/16 11:37:05 AM: micro_avg: validation: 0.000000
09/16 11:37:05 AM: edges-srl-ontonotes_mcc: training: 0.855227 validation: 0.893685
09/16 11:37:05 AM: edges-srl-ontonotes_acc: training: 0.800605 validation: 0.858440
09/16 11:37:05 AM: edges-srl-ontonotes_precision: training: 0.891747 validation: 0.924903
09/16 11:37:05 AM: edges-srl-ontonotes_recall: training: 0.824234 validation: 0.866523
09/16 11:37:05 AM: edges-srl-ontonotes_f1: training: 0.856662 validation: 0.894762
09/16 11:37:05 AM: Global learning rate: 2.5e-05
09/16 11:37:05 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:37:08 AM: Update 24033: task edges-srl-ontonotes, batch 33 (24033): mcc: 0.8784, acc: 0.8293, precision: 0.9095, recall: 0.8519, f1: 0.8797, edges-srl-ontonotes_loss: 0.0104
09/16 11:37:18 AM: Update 24156: task edges-srl-ontonotes, batch 156 (24156): mcc: 0.8733, acc: 0.8245, precision: 0.9069, recall: 0.8444, f1: 0.8745, edges-srl-ontonotes_loss: 0.0108
09/16 11:37:28 AM: Update 24268: task edges-srl-ontonotes, batch 268 (24268): mcc: 0.8730, acc: 0.8247, precision: 0.9054, recall: 0.8453, f1: 0.8743, edges-srl-ontonotes_loss: 0.0107
09/16 11:37:38 AM: Update 24400: task edges-srl-ontonotes, batch 400 (24400): mcc: 0.8740, acc: 0.8257, precision: 0.9067, recall: 0.8461, f1: 0.8753, edges-srl-ontonotes_loss: 0.0107
09/16 11:37:48 AM: Update 24520: task edges-srl-ontonotes, batch 520 (24520): mcc: 0.8733, acc: 0.8242, precision: 0.9068, recall: 0.8446, f1: 0.8746, edges-srl-ontonotes_loss: 0.0107
09/16 11:37:58 AM: Update 24627: task edges-srl-ontonotes, batch 627 (24627): mcc: 0.8738, acc: 0.8252, precision: 0.9073, recall: 0.8451, f1: 0.8751, edges-srl-ontonotes_loss: 0.0107
09/16 11:38:08 AM: Update 24742: task edges-srl-ontonotes, batch 742 (24742): mcc: 0.8745, acc: 0.8260, precision: 0.9077, recall: 0.8461, f1: 0.8758, edges-srl-ontonotes_loss: 0.0106
09/16 11:38:18 AM: Update 24858: task edges-srl-ontonotes, batch 858 (24858): mcc: 0.8757, acc: 0.8273, precision: 0.9088, recall: 0.8473, f1: 0.8770, edges-srl-ontonotes_loss: 0.0106
09/16 11:38:28 AM: Update 24948: task edges-srl-ontonotes, batch 948 (24948): mcc: 0.8745, acc: 0.8257, precision: 0.9081, recall: 0.8457, f1: 0.8758, edges-srl-ontonotes_loss: 0.0107
09/16 11:38:32 AM: ***** Step 25000 / Validation 25 *****
09/16 11:38:32 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:38:32 AM: Validating...
09/16 11:38:38 AM: Evaluate: task edges-srl-ontonotes, batch 80 (157): mcc: 0.8867, acc: 0.8461, precision: 0.9249, recall: 0.8532, f1: 0.8876, edges-srl-ontonotes_loss: 0.0095
09/16 11:38:44 AM: Updating LR scheduler:
09/16 11:38:44 AM: 	Best result seen so far for macro_avg: 0.897
09/16 11:38:44 AM: 	# validation passes without improvement: 2
09/16 11:38:44 AM: edges-srl-ontonotes_loss: training: 0.010723 validation: 0.009139
09/16 11:38:44 AM: macro_avg: validation: 0.892335
09/16 11:38:44 AM: micro_avg: validation: 0.000000
09/16 11:38:44 AM: edges-srl-ontonotes_mcc: training: 0.873621 validation: 0.891323
09/16 11:38:44 AM: edges-srl-ontonotes_acc: training: 0.824452 validation: 0.854669
09/16 11:38:44 AM: edges-srl-ontonotes_precision: training: 0.907361 validation: 0.925347
09/16 11:38:44 AM: edges-srl-ontonotes_recall: training: 0.844682 validation: 0.861596
09/16 11:38:44 AM: edges-srl-ontonotes_f1: training: 0.874900 validation: 0.892335
09/16 11:38:44 AM: Global learning rate: 2.5e-05
09/16 11:38:44 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:38:48 AM: Update 25049: task edges-srl-ontonotes, batch 49 (25049): mcc: 0.8627, acc: 0.8125, precision: 0.8967, recall: 0.8338, f1: 0.8641, edges-srl-ontonotes_loss: 0.0113
09/16 11:38:58 AM: Update 25168: task edges-srl-ontonotes, batch 168 (25168): mcc: 0.8661, acc: 0.8157, precision: 0.9011, recall: 0.8362, f1: 0.8674, edges-srl-ontonotes_loss: 0.0112
09/16 11:39:08 AM: Update 25278: task edges-srl-ontonotes, batch 278 (25278): mcc: 0.8655, acc: 0.8144, precision: 0.8998, recall: 0.8363, f1: 0.8669, edges-srl-ontonotes_loss: 0.0113
09/16 11:39:18 AM: Update 25407: task edges-srl-ontonotes, batch 407 (25407): mcc: 0.8662, acc: 0.8150, precision: 0.9010, recall: 0.8364, f1: 0.8675, edges-srl-ontonotes_loss: 0.0112
09/16 11:39:29 AM: Update 25511: task edges-srl-ontonotes, batch 511 (25511): mcc: 0.8662, acc: 0.8147, precision: 0.9015, recall: 0.8359, f1: 0.8675, edges-srl-ontonotes_loss: 0.0112
09/16 11:39:39 AM: Update 25630: task edges-srl-ontonotes, batch 630 (25630): mcc: 0.8658, acc: 0.8140, precision: 0.9010, recall: 0.8358, f1: 0.8672, edges-srl-ontonotes_loss: 0.0113
09/16 11:39:49 AM: Update 25748: task edges-srl-ontonotes, batch 748 (25748): mcc: 0.8655, acc: 0.8136, precision: 0.9008, recall: 0.8353, f1: 0.8668, edges-srl-ontonotes_loss: 0.0113
09/16 11:39:59 AM: Update 25825: task edges-srl-ontonotes, batch 825 (25825): mcc: 0.8653, acc: 0.8133, precision: 0.9005, recall: 0.8352, f1: 0.8666, edges-srl-ontonotes_loss: 0.0113
09/16 11:40:09 AM: Update 25940: task edges-srl-ontonotes, batch 940 (25940): mcc: 0.8659, acc: 0.8140, precision: 0.9011, recall: 0.8358, f1: 0.8672, edges-srl-ontonotes_loss: 0.0112
09/16 11:40:14 AM: ***** Step 26000 / Validation 26 *****
09/16 11:40:14 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:40:14 AM: Validating...
09/16 11:40:19 AM: Evaluate: task edges-srl-ontonotes, batch 58 (157): mcc: 0.8797, acc: 0.8397, precision: 0.9179, recall: 0.8465, f1: 0.8807, edges-srl-ontonotes_loss: 0.0101
09/16 11:40:27 AM: Updating LR scheduler:
09/16 11:40:27 AM: 	Best result seen so far for macro_avg: 0.897
09/16 11:40:27 AM: 	# validation passes without improvement: 3
09/16 11:40:27 AM: edges-srl-ontonotes_loss: training: 0.011194 validation: 0.009324
09/16 11:40:27 AM: macro_avg: validation: 0.892376
09/16 11:40:27 AM: micro_avg: validation: 0.000000
09/16 11:40:27 AM: edges-srl-ontonotes_mcc: training: 0.866356 validation: 0.891338
09/16 11:40:27 AM: edges-srl-ontonotes_acc: training: 0.814756 validation: 0.855053
09/16 11:40:27 AM: edges-srl-ontonotes_precision: training: 0.901204 validation: 0.924639
09/16 11:40:27 AM: edges-srl-ontonotes_recall: training: 0.836594 validation: 0.862289
09/16 11:40:27 AM: edges-srl-ontonotes_f1: training: 0.867698 validation: 0.892376
09/16 11:40:27 AM: Global learning rate: 2.5e-05
09/16 11:40:27 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:40:29 AM: Update 26021: task edges-srl-ontonotes, batch 21 (26021): mcc: 0.8719, acc: 0.8235, precision: 0.9032, recall: 0.8453, f1: 0.8733, edges-srl-ontonotes_loss: 0.0113
09/16 11:40:39 AM: Update 26127: task edges-srl-ontonotes, batch 127 (26127): mcc: 0.8733, acc: 0.8261, precision: 0.9060, recall: 0.8454, f1: 0.8747, edges-srl-ontonotes_loss: 0.0110
09/16 11:40:49 AM: Update 26249: task edges-srl-ontonotes, batch 249 (26249): mcc: 0.8736, acc: 0.8242, precision: 0.9065, recall: 0.8454, f1: 0.8749, edges-srl-ontonotes_loss: 0.0108
09/16 11:40:59 AM: Update 26381: task edges-srl-ontonotes, batch 381 (26381): mcc: 0.8736, acc: 0.8245, precision: 0.9067, recall: 0.8452, f1: 0.8749, edges-srl-ontonotes_loss: 0.0107
09/16 11:41:09 AM: Update 26483: task edges-srl-ontonotes, batch 483 (26483): mcc: 0.8687, acc: 0.8177, precision: 0.9031, recall: 0.8393, f1: 0.8700, edges-srl-ontonotes_loss: 0.0111
09/16 11:41:19 AM: Update 26599: task edges-srl-ontonotes, batch 599 (26599): mcc: 0.8641, acc: 0.8113, precision: 0.8999, recall: 0.8334, f1: 0.8654, edges-srl-ontonotes_loss: 0.0114
09/16 11:41:29 AM: Update 26716: task edges-srl-ontonotes, batch 716 (26716): mcc: 0.8624, acc: 0.8087, precision: 0.8992, recall: 0.8309, f1: 0.8637, edges-srl-ontonotes_loss: 0.0115
09/16 11:41:39 AM: Update 26836: task edges-srl-ontonotes, batch 836 (26836): mcc: 0.8635, acc: 0.8105, precision: 0.9000, recall: 0.8323, f1: 0.8648, edges-srl-ontonotes_loss: 0.0114
09/16 11:41:49 AM: Update 26983: task edges-srl-ontonotes, batch 983 (26983): mcc: 0.8681, acc: 0.8164, precision: 0.9034, recall: 0.8378, f1: 0.8694, edges-srl-ontonotes_loss: 0.0111
09/16 11:41:50 AM: ***** Step 27000 / Validation 27 *****
09/16 11:41:50 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:41:50 AM: Validating...
09/16 11:41:59 AM: Evaluate: task edges-srl-ontonotes, batch 119 (157): mcc: 0.8929, acc: 0.8557, precision: 0.9286, recall: 0.8616, f1: 0.8938, edges-srl-ontonotes_loss: 0.0091
09/16 11:42:02 AM: Updating LR scheduler:
09/16 11:42:02 AM: 	Best result seen so far for macro_avg: 0.897
09/16 11:42:02 AM: 	# validation passes without improvement: 0
09/16 11:42:02 AM: edges-srl-ontonotes_loss: training: 0.011030 validation: 0.009205
09/16 11:42:02 AM: macro_avg: validation: 0.893505
09/16 11:42:02 AM: micro_avg: validation: 0.000000
09/16 11:42:02 AM: edges-srl-ontonotes_mcc: training: 0.868599 validation: 0.892520
09/16 11:42:02 AM: edges-srl-ontonotes_acc: training: 0.817134 validation: 0.856593
09/16 11:42:02 AM: edges-srl-ontonotes_precision: training: 0.903699 validation: 0.926799
09/16 11:42:02 AM: edges-srl-ontonotes_recall: training: 0.838535 validation: 0.862520
09/16 11:42:02 AM: edges-srl-ontonotes_f1: training: 0.869899 validation: 0.893505
09/16 11:42:02 AM: Global learning rate: 1.25e-05
09/16 11:42:02 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:42:09 AM: Update 27060: task edges-srl-ontonotes, batch 60 (27060): mcc: 0.8898, acc: 0.8460, precision: 0.9197, recall: 0.8639, f1: 0.8909, edges-srl-ontonotes_loss: 0.0095
09/16 11:42:19 AM: Update 27222: task edges-srl-ontonotes, batch 222 (27222): mcc: 0.9072, acc: 0.8676, precision: 0.9318, recall: 0.8859, f1: 0.9083, edges-srl-ontonotes_loss: 0.0082
09/16 11:42:30 AM: Update 27373: task edges-srl-ontonotes, batch 373 (27373): mcc: 0.9104, acc: 0.8718, precision: 0.9342, recall: 0.8898, f1: 0.9115, edges-srl-ontonotes_loss: 0.0079
09/16 11:42:40 AM: Update 27510: task edges-srl-ontonotes, batch 510 (27510): mcc: 0.9114, acc: 0.8730, precision: 0.9357, recall: 0.8902, f1: 0.9124, edges-srl-ontonotes_loss: 0.0079
09/16 11:42:50 AM: Update 27648: task edges-srl-ontonotes, batch 648 (27648): mcc: 0.9123, acc: 0.8745, precision: 0.9367, recall: 0.8911, f1: 0.9133, edges-srl-ontonotes_loss: 0.0078
09/16 11:43:00 AM: Update 27776: task edges-srl-ontonotes, batch 776 (27776): mcc: 0.9122, acc: 0.8746, precision: 0.9365, recall: 0.8912, f1: 0.9133, edges-srl-ontonotes_loss: 0.0078
09/16 11:43:10 AM: Update 27924: task edges-srl-ontonotes, batch 924 (27924): mcc: 0.9130, acc: 0.8756, precision: 0.9370, recall: 0.8921, f1: 0.9140, edges-srl-ontonotes_loss: 0.0078
09/16 11:43:17 AM: ***** Step 28000 / Validation 28 *****
09/16 11:43:17 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:43:17 AM: Validating...
09/16 11:43:20 AM: Evaluate: task edges-srl-ontonotes, batch 30 (157): mcc: 0.8928, acc: 0.8509, precision: 0.9331, recall: 0.8572, f1: 0.8936, edges-srl-ontonotes_loss: 0.0091
09/16 11:43:29 AM: Updating LR scheduler:
09/16 11:43:29 AM: 	Best result seen so far for macro_avg: 0.897
09/16 11:43:29 AM: 	# validation passes without improvement: 1
09/16 11:43:29 AM: edges-srl-ontonotes_loss: training: 0.007809 validation: 0.009204
09/16 11:43:29 AM: macro_avg: validation: 0.893831
09/16 11:43:29 AM: micro_avg: validation: 0.000000
09/16 11:43:29 AM: edges-srl-ontonotes_mcc: training: 0.912817 validation: 0.892835
09/16 11:43:29 AM: edges-srl-ontonotes_acc: training: 0.875536 validation: 0.857209
09/16 11:43:29 AM: edges-srl-ontonotes_precision: training: 0.936871 validation: 0.926700
09/16 11:43:29 AM: edges-srl-ontonotes_recall: training: 0.891885 validation: 0.863213
09/16 11:43:29 AM: edges-srl-ontonotes_f1: training: 0.913825 validation: 0.893831
09/16 11:43:29 AM: Global learning rate: 1.25e-05
09/16 11:43:29 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:43:30 AM: Update 28004: task edges-srl-ontonotes, batch 4 (28004): mcc: 0.8878, acc: 0.8478, precision: 0.9201, recall: 0.8597, f1: 0.8889, edges-srl-ontonotes_loss: 0.0090
09/16 11:43:40 AM: Update 28164: task edges-srl-ontonotes, batch 164 (28164): mcc: 0.9065, acc: 0.8687, precision: 0.9284, recall: 0.8878, f1: 0.9076, edges-srl-ontonotes_loss: 0.0086
09/16 11:43:50 AM: Update 28313: task edges-srl-ontonotes, batch 313 (28313): mcc: 0.9076, acc: 0.8704, precision: 0.9286, recall: 0.8899, f1: 0.9088, edges-srl-ontonotes_loss: 0.0085
09/16 11:44:00 AM: Update 28433: task edges-srl-ontonotes, batch 433 (28433): mcc: 0.9010, acc: 0.8616, precision: 0.9250, recall: 0.8805, f1: 0.9022, edges-srl-ontonotes_loss: 0.0090
09/16 11:44:10 AM: Update 28560: task edges-srl-ontonotes, batch 560 (28560): mcc: 0.8968, acc: 0.8556, precision: 0.9220, recall: 0.8753, f1: 0.8980, edges-srl-ontonotes_loss: 0.0093
09/16 11:44:20 AM: Update 28674: task edges-srl-ontonotes, batch 674 (28674): mcc: 0.8934, acc: 0.8514, precision: 0.9194, recall: 0.8711, f1: 0.8946, edges-srl-ontonotes_loss: 0.0095
09/16 11:44:30 AM: Update 28799: task edges-srl-ontonotes, batch 799 (28799): mcc: 0.8878, acc: 0.8442, precision: 0.9152, recall: 0.8645, f1: 0.8891, edges-srl-ontonotes_loss: 0.0099
09/16 11:44:40 AM: Update 28931: task edges-srl-ontonotes, batch 931 (28931): mcc: 0.8851, acc: 0.8406, precision: 0.9133, recall: 0.8611, f1: 0.8864, edges-srl-ontonotes_loss: 0.0101
09/16 11:44:47 AM: ***** Step 29000 / Validation 29 *****
09/16 11:44:47 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:44:47 AM: Validating...
09/16 11:44:50 AM: Evaluate: task edges-srl-ontonotes, batch 43 (157): mcc: 0.8868, acc: 0.8479, precision: 0.9240, recall: 0.8543, f1: 0.8878, edges-srl-ontonotes_loss: 0.0098
09/16 11:44:59 AM: Updating LR scheduler:
09/16 11:44:59 AM: 	Best result seen so far for macro_avg: 0.897
09/16 11:44:59 AM: 	# validation passes without improvement: 2
09/16 11:44:59 AM: edges-srl-ontonotes_loss: training: 0.010146 validation: 0.009080
09/16 11:44:59 AM: macro_avg: validation: 0.895490
09/16 11:44:59 AM: micro_avg: validation: 0.000000
09/16 11:44:59 AM: edges-srl-ontonotes_mcc: training: 0.884314 validation: 0.894446
09/16 11:44:59 AM: edges-srl-ontonotes_acc: training: 0.839377 validation: 0.859826
09/16 11:44:59 AM: edges-srl-ontonotes_precision: training: 0.912867 validation: 0.926286
09/16 11:44:59 AM: edges-srl-ontonotes_recall: training: 0.859942 validation: 0.866677
09/16 11:44:59 AM: edges-srl-ontonotes_f1: training: 0.885615 validation: 0.895490
09/16 11:44:59 AM: Global learning rate: 1.25e-05
09/16 11:44:59 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:45:00 AM: Update 29016: task edges-srl-ontonotes, batch 16 (29016): mcc: 0.8802, acc: 0.8330, precision: 0.9155, recall: 0.8497, f1: 0.8814, edges-srl-ontonotes_loss: 0.0100
09/16 11:45:10 AM: Update 29144: task edges-srl-ontonotes, batch 144 (29144): mcc: 0.8813, acc: 0.8357, precision: 0.9117, recall: 0.8553, f1: 0.8826, edges-srl-ontonotes_loss: 0.0102
09/16 11:45:20 AM: Update 29283: task edges-srl-ontonotes, batch 283 (29283): mcc: 0.8859, acc: 0.8402, precision: 0.9166, recall: 0.8594, f1: 0.8871, edges-srl-ontonotes_loss: 0.0099
09/16 11:45:30 AM: Update 29376: task edges-srl-ontonotes, batch 376 (29376): mcc: 0.8866, acc: 0.8410, precision: 0.9172, recall: 0.8603, f1: 0.8878, edges-srl-ontonotes_loss: 0.0099
09/16 11:45:40 AM: Update 29499: task edges-srl-ontonotes, batch 499 (29499): mcc: 0.8877, acc: 0.8430, precision: 0.9178, recall: 0.8617, f1: 0.8889, edges-srl-ontonotes_loss: 0.0098
09/16 11:45:50 AM: Update 29613: task edges-srl-ontonotes, batch 613 (29613): mcc: 0.8876, acc: 0.8427, precision: 0.9180, recall: 0.8614, f1: 0.8888, edges-srl-ontonotes_loss: 0.0098
09/16 11:46:00 AM: Update 29732: task edges-srl-ontonotes, batch 732 (29732): mcc: 0.8854, acc: 0.8397, precision: 0.9161, recall: 0.8590, f1: 0.8866, edges-srl-ontonotes_loss: 0.0100
09/16 11:46:10 AM: Update 29861: task edges-srl-ontonotes, batch 861 (29861): mcc: 0.8852, acc: 0.8399, precision: 0.9154, recall: 0.8592, f1: 0.8864, edges-srl-ontonotes_loss: 0.0100
09/16 11:46:21 AM: Update 29977: task edges-srl-ontonotes, batch 977 (29977): mcc: 0.8839, acc: 0.8384, precision: 0.9142, recall: 0.8578, f1: 0.8851, edges-srl-ontonotes_loss: 0.0100
09/16 11:46:22 AM: ***** Step 30000 / Validation 30 *****
09/16 11:46:22 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:46:22 AM: Validating...
09/16 11:46:31 AM: Evaluate: task edges-srl-ontonotes, batch 100 (157): mcc: 0.8977, acc: 0.8601, precision: 0.9325, recall: 0.8670, f1: 0.8986, edges-srl-ontonotes_loss: 0.0088
09/16 11:46:35 AM: Best result seen so far for edges-srl-ontonotes.
09/16 11:46:35 AM: Best result seen so far for macro.
09/16 11:46:35 AM: Updating LR scheduler:
09/16 11:46:35 AM: 	Best result seen so far for macro_avg: 0.898
09/16 11:46:35 AM: 	# validation passes without improvement: 0
09/16 11:46:35 AM: edges-srl-ontonotes_loss: training: 0.010059 validation: 0.008874
09/16 11:46:35 AM: macro_avg: validation: 0.897909
09/16 11:46:35 AM: micro_avg: validation: 0.000000
09/16 11:46:35 AM: edges-srl-ontonotes_mcc: training: 0.883666 validation: 0.896891
09/16 11:46:35 AM: edges-srl-ontonotes_acc: training: 0.838107 validation: 0.862520
09/16 11:46:35 AM: edges-srl-ontonotes_precision: training: 0.914050 validation: 0.928472
09/16 11:46:35 AM: edges-srl-ontonotes_recall: training: 0.857583 validation: 0.869294
09/16 11:46:35 AM: edges-srl-ontonotes_f1: training: 0.884917 validation: 0.897909
09/16 11:46:35 AM: Global learning rate: 1.25e-05
09/16 11:46:35 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:46:41 AM: Update 30066: task edges-srl-ontonotes, batch 66 (30066): mcc: 0.8678, acc: 0.8178, precision: 0.8986, recall: 0.8417, f1: 0.8692, edges-srl-ontonotes_loss: 0.0110
09/16 11:46:51 AM: Update 30188: task edges-srl-ontonotes, batch 188 (30188): mcc: 0.8620, acc: 0.8097, precision: 0.8963, recall: 0.8330, f1: 0.8635, edges-srl-ontonotes_loss: 0.0114
09/16 11:47:01 AM: Update 30270: task edges-srl-ontonotes, batch 270 (30270): mcc: 0.8633, acc: 0.8119, precision: 0.8974, recall: 0.8343, f1: 0.8647, edges-srl-ontonotes_loss: 0.0114
09/16 11:47:11 AM: Update 30388: task edges-srl-ontonotes, batch 388 (30388): mcc: 0.8667, acc: 0.8160, precision: 0.9003, recall: 0.8381, f1: 0.8681, edges-srl-ontonotes_loss: 0.0112
09/16 11:47:21 AM: Update 30512: task edges-srl-ontonotes, batch 512 (30512): mcc: 0.8671, acc: 0.8161, precision: 0.9009, recall: 0.8382, f1: 0.8684, edges-srl-ontonotes_loss: 0.0111
09/16 11:47:31 AM: Update 30628: task edges-srl-ontonotes, batch 628 (30628): mcc: 0.8643, acc: 0.8128, precision: 0.8983, recall: 0.8355, f1: 0.8657, edges-srl-ontonotes_loss: 0.0113
09/16 11:47:41 AM: Update 30751: task edges-srl-ontonotes, batch 751 (30751): mcc: 0.8613, acc: 0.8087, precision: 0.8957, recall: 0.8321, f1: 0.8627, edges-srl-ontonotes_loss: 0.0115
09/16 11:47:51 AM: Update 30866: task edges-srl-ontonotes, batch 866 (30866): mcc: 0.8598, acc: 0.8066, precision: 0.8947, recall: 0.8302, f1: 0.8612, edges-srl-ontonotes_loss: 0.0116
09/16 11:48:01 AM: Update 30983: task edges-srl-ontonotes, batch 983 (30983): mcc: 0.8584, acc: 0.8044, precision: 0.8939, recall: 0.8282, f1: 0.8598, edges-srl-ontonotes_loss: 0.0117
09/16 11:48:03 AM: ***** Step 31000 / Validation 31 *****
09/16 11:48:03 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:48:03 AM: Validating...
09/16 11:48:11 AM: Evaluate: task edges-srl-ontonotes, batch 100 (157): mcc: 0.8963, acc: 0.8586, precision: 0.9303, recall: 0.8663, f1: 0.8972, edges-srl-ontonotes_loss: 0.0088
09/16 11:48:16 AM: Updating LR scheduler:
09/16 11:48:16 AM: 	Best result seen so far for macro_avg: 0.898
09/16 11:48:16 AM: 	# validation passes without improvement: 1
09/16 11:48:16 AM: edges-srl-ontonotes_loss: training: 0.011725 validation: 0.008877
09/16 11:48:16 AM: macro_avg: validation: 0.897711
09/16 11:48:16 AM: micro_avg: validation: 0.000000
09/16 11:48:16 AM: edges-srl-ontonotes_mcc: training: 0.858180 validation: 0.896677
09/16 11:48:16 AM: edges-srl-ontonotes_acc: training: 0.804233 validation: 0.861750
09/16 11:48:16 AM: edges-srl-ontonotes_precision: training: 0.893515 validation: 0.927873
09/16 11:48:16 AM: edges-srl-ontonotes_recall: training: 0.828203 validation: 0.869448
09/16 11:48:16 AM: edges-srl-ontonotes_f1: training: 0.859620 validation: 0.897711
09/16 11:48:16 AM: Global learning rate: 1.25e-05
09/16 11:48:16 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:48:21 AM: Update 31060: task edges-srl-ontonotes, batch 60 (31060): mcc: 0.8559, acc: 0.8039, precision: 0.8918, recall: 0.8255, f1: 0.8574, edges-srl-ontonotes_loss: 0.0122
09/16 11:48:34 AM: Update 31176: task edges-srl-ontonotes, batch 176 (31176): mcc: 0.8541, acc: 0.8004, precision: 0.8905, recall: 0.8232, f1: 0.8555, edges-srl-ontonotes_loss: 0.0121
09/16 11:48:44 AM: Update 31286: task edges-srl-ontonotes, batch 286 (31286): mcc: 0.8618, acc: 0.8094, precision: 0.8965, recall: 0.8322, f1: 0.8632, edges-srl-ontonotes_loss: 0.0114
09/16 11:48:54 AM: Update 31396: task edges-srl-ontonotes, batch 396 (31396): mcc: 0.8657, acc: 0.8145, precision: 0.9001, recall: 0.8364, f1: 0.8671, edges-srl-ontonotes_loss: 0.0111
09/16 11:49:04 AM: Update 31499: task edges-srl-ontonotes, batch 499 (31499): mcc: 0.8689, acc: 0.8188, precision: 0.9025, recall: 0.8402, f1: 0.8703, edges-srl-ontonotes_loss: 0.0109
09/16 11:49:14 AM: Update 31612: task edges-srl-ontonotes, batch 612 (31612): mcc: 0.8688, acc: 0.8184, precision: 0.9026, recall: 0.8400, f1: 0.8702, edges-srl-ontonotes_loss: 0.0109
09/16 11:49:24 AM: Update 31727: task edges-srl-ontonotes, batch 727 (31727): mcc: 0.8704, acc: 0.8205, precision: 0.9039, recall: 0.8417, f1: 0.8717, edges-srl-ontonotes_loss: 0.0108
09/16 11:49:34 AM: Update 31831: task edges-srl-ontonotes, batch 831 (31831): mcc: 0.8712, acc: 0.8216, precision: 0.9046, recall: 0.8426, f1: 0.8725, edges-srl-ontonotes_loss: 0.0107
09/16 11:49:44 AM: Update 31945: task edges-srl-ontonotes, batch 945 (31945): mcc: 0.8719, acc: 0.8225, precision: 0.9048, recall: 0.8437, f1: 0.8732, edges-srl-ontonotes_loss: 0.0107
09/16 11:49:49 AM: ***** Step 32000 / Validation 32 *****
09/16 11:49:49 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:49:49 AM: Validating...
09/16 11:49:54 AM: Evaluate: task edges-srl-ontonotes, batch 64 (157): mcc: 0.8847, acc: 0.8460, precision: 0.9212, recall: 0.8528, f1: 0.8857, edges-srl-ontonotes_loss: 0.0097
09/16 11:50:02 AM: Updating LR scheduler:
09/16 11:50:02 AM: 	Best result seen so far for macro_avg: 0.898
09/16 11:50:02 AM: 	# validation passes without improvement: 2
09/16 11:50:02 AM: edges-srl-ontonotes_loss: training: 0.010663 validation: 0.008952
09/16 11:50:02 AM: macro_avg: validation: 0.895347
09/16 11:50:02 AM: micro_avg: validation: 0.000000
09/16 11:50:02 AM: edges-srl-ontonotes_mcc: training: 0.872458 validation: 0.894334
09/16 11:50:02 AM: edges-srl-ontonotes_acc: training: 0.823204 validation: 0.859287
09/16 11:50:02 AM: edges-srl-ontonotes_precision: training: 0.905260 validation: 0.927123
09/16 11:50:02 AM: edges-srl-ontonotes_recall: training: 0.844432 validation: 0.865676
09/16 11:50:02 AM: edges-srl-ontonotes_f1: training: 0.873788 validation: 0.895347
09/16 11:50:02 AM: Global learning rate: 1.25e-05
09/16 11:50:02 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:50:04 AM: Update 32024: task edges-srl-ontonotes, batch 24 (32024): mcc: 0.8829, acc: 0.8371, precision: 0.9134, recall: 0.8568, f1: 0.8842, edges-srl-ontonotes_loss: 0.0102
09/16 11:50:14 AM: Update 32127: task edges-srl-ontonotes, batch 127 (32127): mcc: 0.8794, acc: 0.8330, precision: 0.9102, recall: 0.8531, f1: 0.8807, edges-srl-ontonotes_loss: 0.0103
09/16 11:50:24 AM: Update 32255: task edges-srl-ontonotes, batch 255 (32255): mcc: 0.8717, acc: 0.8230, precision: 0.9050, recall: 0.8433, f1: 0.8730, edges-srl-ontonotes_loss: 0.0108
09/16 11:50:34 AM: Update 32384: task edges-srl-ontonotes, batch 384 (32384): mcc: 0.8709, acc: 0.8219, precision: 0.9043, recall: 0.8424, f1: 0.8722, edges-srl-ontonotes_loss: 0.0109
09/16 11:50:44 AM: Update 32482: task edges-srl-ontonotes, batch 482 (32482): mcc: 0.8703, acc: 0.8207, precision: 0.9042, recall: 0.8413, f1: 0.8716, edges-srl-ontonotes_loss: 0.0110
09/16 11:50:54 AM: Update 32616: task edges-srl-ontonotes, batch 616 (32616): mcc: 0.8695, acc: 0.8198, precision: 0.9036, recall: 0.8404, f1: 0.8708, edges-srl-ontonotes_loss: 0.0110
09/16 11:51:04 AM: Update 32740: task edges-srl-ontonotes, batch 740 (32740): mcc: 0.8684, acc: 0.8182, precision: 0.9025, recall: 0.8392, f1: 0.8697, edges-srl-ontonotes_loss: 0.0111
09/16 11:51:15 AM: Update 32861: task edges-srl-ontonotes, batch 861 (32861): mcc: 0.8679, acc: 0.8173, precision: 0.9023, recall: 0.8384, f1: 0.8692, edges-srl-ontonotes_loss: 0.0111
09/16 11:51:25 AM: Update 32990: task edges-srl-ontonotes, batch 990 (32990): mcc: 0.8679, acc: 0.8169, precision: 0.9023, recall: 0.8385, f1: 0.8692, edges-srl-ontonotes_loss: 0.0111
09/16 11:51:25 AM: ***** Step 33000 / Validation 33 *****
09/16 11:51:25 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:51:25 AM: Validating...
09/16 11:51:35 AM: Evaluate: task edges-srl-ontonotes, batch 123 (157): mcc: 0.8946, acc: 0.8596, precision: 0.9270, recall: 0.8663, f1: 0.8956, edges-srl-ontonotes_loss: 0.0089
09/16 11:51:37 AM: Updating LR scheduler:
09/16 11:51:37 AM: 	Best result seen so far for macro_avg: 0.898
09/16 11:51:37 AM: 	# validation passes without improvement: 3
09/16 11:51:37 AM: edges-srl-ontonotes_loss: training: 0.011092 validation: 0.009058
09/16 11:51:37 AM: macro_avg: validation: 0.895361
09/16 11:51:37 AM: micro_avg: validation: 0.000000
09/16 11:51:37 AM: edges-srl-ontonotes_mcc: training: 0.867838 validation: 0.894331
09/16 11:51:37 AM: edges-srl-ontonotes_acc: training: 0.816862 validation: 0.859364
09/16 11:51:37 AM: edges-srl-ontonotes_precision: training: 0.902182 validation: 0.926624
09/16 11:51:37 AM: edges-srl-ontonotes_recall: training: 0.838503 validation: 0.866138
09/16 11:51:37 AM: edges-srl-ontonotes_f1: training: 0.869177 validation: 0.895361
09/16 11:51:37 AM: Global learning rate: 1.25e-05
09/16 11:51:37 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:51:45 AM: Update 33084: task edges-srl-ontonotes, batch 84 (33084): mcc: 0.8598, acc: 0.8069, precision: 0.8942, recall: 0.8307, f1: 0.8613, edges-srl-ontonotes_loss: 0.0116
09/16 11:51:55 AM: Update 33213: task edges-srl-ontonotes, batch 213 (33213): mcc: 0.8673, acc: 0.8162, precision: 0.9006, recall: 0.8390, f1: 0.8687, edges-srl-ontonotes_loss: 0.0111
09/16 11:52:05 AM: Update 33341: task edges-srl-ontonotes, batch 341 (33341): mcc: 0.8691, acc: 0.8188, precision: 0.9022, recall: 0.8410, f1: 0.8705, edges-srl-ontonotes_loss: 0.0110
09/16 11:52:15 AM: Update 33435: task edges-srl-ontonotes, batch 435 (33435): mcc: 0.8709, acc: 0.8210, precision: 0.9037, recall: 0.8430, f1: 0.8723, edges-srl-ontonotes_loss: 0.0109
09/16 11:52:25 AM: Update 33565: task edges-srl-ontonotes, batch 565 (33565): mcc: 0.8705, acc: 0.8207, precision: 0.9033, recall: 0.8425, f1: 0.8718, edges-srl-ontonotes_loss: 0.0109
09/16 11:52:35 AM: Update 33681: task edges-srl-ontonotes, batch 681 (33681): mcc: 0.8720, acc: 0.8224, precision: 0.9050, recall: 0.8438, f1: 0.8733, edges-srl-ontonotes_loss: 0.0108
09/16 11:52:45 AM: Update 33796: task edges-srl-ontonotes, batch 796 (33796): mcc: 0.8680, acc: 0.8172, precision: 0.9024, recall: 0.8386, f1: 0.8693, edges-srl-ontonotes_loss: 0.0111
09/16 11:52:55 AM: Update 33911: task edges-srl-ontonotes, batch 911 (33911): mcc: 0.8659, acc: 0.8144, precision: 0.9008, recall: 0.8361, f1: 0.8672, edges-srl-ontonotes_loss: 0.0112
09/16 11:53:04 AM: ***** Step 34000 / Validation 34 *****
09/16 11:53:04 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:53:04 AM: Validating...
09/16 11:53:05 AM: Evaluate: task edges-srl-ontonotes, batch 16 (157): mcc: 0.8909, acc: 0.8540, precision: 0.9241, recall: 0.8620, f1: 0.8920, edges-srl-ontonotes_loss: 0.0086
09/16 11:53:15 AM: Evaluate: task edges-srl-ontonotes, batch 149 (157): mcc: 0.8969, acc: 0.8626, precision: 0.9277, recall: 0.8701, f1: 0.8980, edges-srl-ontonotes_loss: 0.0089
09/16 11:53:16 AM: Updating LR scheduler:
09/16 11:53:16 AM: 	Best result seen so far for macro_avg: 0.898
09/16 11:53:16 AM: 	# validation passes without improvement: 0
09/16 11:53:16 AM: edges-srl-ontonotes_loss: training: 0.011310 validation: 0.009043
09/16 11:53:16 AM: macro_avg: validation: 0.895784
09/16 11:53:16 AM: micro_avg: validation: 0.000000
09/16 11:53:16 AM: edges-srl-ontonotes_mcc: training: 0.864916 validation: 0.894715
09/16 11:53:16 AM: edges-srl-ontonotes_acc: training: 0.813006 validation: 0.860365
09/16 11:53:16 AM: edges-srl-ontonotes_precision: training: 0.900372 validation: 0.925686
09/16 11:53:16 AM: edges-srl-ontonotes_recall: training: 0.834628 validation: 0.867755
09/16 11:53:16 AM: edges-srl-ontonotes_f1: training: 0.866255 validation: 0.895784
09/16 11:53:16 AM: Global learning rate: 6.25e-06
09/16 11:53:16 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:53:25 AM: Update 34135: task edges-srl-ontonotes, batch 135 (34135): mcc: 0.8925, acc: 0.8517, precision: 0.9195, recall: 0.8694, f1: 0.8937, edges-srl-ontonotes_loss: 0.0094
09/16 11:53:35 AM: Update 34280: task edges-srl-ontonotes, batch 280 (34280): mcc: 0.8903, acc: 0.8476, precision: 0.9180, recall: 0.8666, f1: 0.8915, edges-srl-ontonotes_loss: 0.0094
09/16 11:53:45 AM: Update 34395: task edges-srl-ontonotes, batch 395 (34395): mcc: 0.8953, acc: 0.8542, precision: 0.9223, recall: 0.8721, f1: 0.8965, edges-srl-ontonotes_loss: 0.0090
09/16 11:53:55 AM: Update 34559: task edges-srl-ontonotes, batch 559 (34559): mcc: 0.9018, acc: 0.8623, precision: 0.9270, recall: 0.8801, f1: 0.9029, edges-srl-ontonotes_loss: 0.0085
09/16 11:54:05 AM: Update 34707: task edges-srl-ontonotes, batch 707 (34707): mcc: 0.9040, acc: 0.8649, precision: 0.9292, recall: 0.8822, f1: 0.9051, edges-srl-ontonotes_loss: 0.0083
09/16 11:54:15 AM: Update 34865: task edges-srl-ontonotes, batch 865 (34865): mcc: 0.9062, acc: 0.8675, precision: 0.9313, recall: 0.8844, f1: 0.9073, edges-srl-ontonotes_loss: 0.0082
09/16 11:54:25 AM: ***** Step 35000 / Validation 35 *****
09/16 11:54:25 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:54:25 AM: Validating...
09/16 11:54:25 AM: Evaluate: task edges-srl-ontonotes, batch 4 (157): mcc: 0.9041, acc: 0.8771, precision: 0.9228, recall: 0.8886, f1: 0.9054, edges-srl-ontonotes_loss: 0.0073
09/16 11:54:35 AM: Evaluate: task edges-srl-ontonotes, batch 135 (157): mcc: 0.8970, acc: 0.8612, precision: 0.9301, recall: 0.8680, f1: 0.8980, edges-srl-ontonotes_loss: 0.0088
09/16 11:54:37 AM: Updating LR scheduler:
09/16 11:54:37 AM: 	Best result seen so far for macro_avg: 0.898
09/16 11:54:37 AM: 	# validation passes without improvement: 1
09/16 11:54:37 AM: edges-srl-ontonotes_loss: training: 0.008109 validation: 0.009029
09/16 11:54:37 AM: macro_avg: validation: 0.895324
09/16 11:54:37 AM: micro_avg: validation: 0.000000
09/16 11:54:37 AM: edges-srl-ontonotes_mcc: training: 0.907673 validation: 0.894331
09/16 11:54:37 AM: edges-srl-ontonotes_acc: training: 0.869465 validation: 0.858671
09/16 11:54:37 AM: edges-srl-ontonotes_precision: training: 0.932568 validation: 0.927693
09/16 11:54:37 AM: edges-srl-ontonotes_recall: training: 0.886090 validation: 0.865137
09/16 11:54:37 AM: edges-srl-ontonotes_f1: training: 0.908735 validation: 0.895324
09/16 11:54:37 AM: Global learning rate: 6.25e-06
09/16 11:54:37 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:54:45 AM: Update 35123: task edges-srl-ontonotes, batch 123 (35123): mcc: 0.9112, acc: 0.8736, precision: 0.9348, recall: 0.8907, f1: 0.9122, edges-srl-ontonotes_loss: 0.0079
09/16 11:54:55 AM: Update 35255: task edges-srl-ontonotes, batch 255 (35255): mcc: 0.9140, acc: 0.8769, precision: 0.9377, recall: 0.8934, f1: 0.9150, edges-srl-ontonotes_loss: 0.0078
09/16 11:55:05 AM: Update 35423: task edges-srl-ontonotes, batch 423 (35423): mcc: 0.9119, acc: 0.8753, precision: 0.9340, recall: 0.8929, f1: 0.9130, edges-srl-ontonotes_loss: 0.0080
09/16 11:55:16 AM: Update 35558: task edges-srl-ontonotes, batch 558 (35558): mcc: 0.9113, acc: 0.8746, precision: 0.9328, recall: 0.8928, f1: 0.9124, edges-srl-ontonotes_loss: 0.0081
09/16 11:55:26 AM: Update 35687: task edges-srl-ontonotes, batch 687 (35687): mcc: 0.9054, acc: 0.8664, precision: 0.9293, recall: 0.8849, f1: 0.9066, edges-srl-ontonotes_loss: 0.0085
09/16 11:55:36 AM: Update 35817: task edges-srl-ontonotes, batch 817 (35817): mcc: 0.9022, acc: 0.8626, precision: 0.9269, recall: 0.8809, f1: 0.9033, edges-srl-ontonotes_loss: 0.0087
09/16 11:55:46 AM: Update 35935: task edges-srl-ontonotes, batch 935 (35935): mcc: 0.8984, acc: 0.8576, precision: 0.9239, recall: 0.8764, f1: 0.8995, edges-srl-ontonotes_loss: 0.0090
09/16 11:55:51 AM: ***** Step 36000 / Validation 36 *****
09/16 11:55:51 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:55:51 AM: Validating...
09/16 11:55:56 AM: Evaluate: task edges-srl-ontonotes, batch 68 (157): mcc: 0.8893, acc: 0.8516, precision: 0.9245, recall: 0.8586, f1: 0.8903, edges-srl-ontonotes_loss: 0.0095
09/16 11:56:03 AM: Updating LR scheduler:
09/16 11:56:03 AM: 	Best result seen so far for macro_avg: 0.898
09/16 11:56:03 AM: 	# validation passes without improvement: 2
09/16 11:56:03 AM: edges-srl-ontonotes_loss: training: 0.009161 validation: 0.008956
09/16 11:56:03 AM: macro_avg: validation: 0.897068
09/16 11:56:03 AM: micro_avg: validation: 0.000000
09/16 11:56:03 AM: edges-srl-ontonotes_mcc: training: 0.896380 validation: 0.896065
09/16 11:56:03 AM: edges-srl-ontonotes_acc: training: 0.854934 validation: 0.861289
09/16 11:56:03 AM: edges-srl-ontonotes_precision: training: 0.922419 validation: 0.928430
09/16 11:56:03 AM: edges-srl-ontonotes_recall: training: 0.874040 validation: 0.867755
09/16 11:56:03 AM: edges-srl-ontonotes_f1: training: 0.897578 validation: 0.897068
09/16 11:56:03 AM: Global learning rate: 6.25e-06
09/16 11:56:03 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:56:06 AM: Update 36035: task edges-srl-ontonotes, batch 35 (36035): mcc: 0.8627, acc: 0.8099, precision: 0.8982, recall: 0.8325, f1: 0.8641, edges-srl-ontonotes_loss: 0.0114
09/16 11:56:16 AM: Update 36161: task edges-srl-ontonotes, batch 161 (36161): mcc: 0.8622, acc: 0.8120, precision: 0.8956, recall: 0.8338, f1: 0.8636, edges-srl-ontonotes_loss: 0.0116
09/16 11:56:26 AM: Update 36284: task edges-srl-ontonotes, batch 284 (36284): mcc: 0.8673, acc: 0.8175, precision: 0.9010, recall: 0.8386, f1: 0.8687, edges-srl-ontonotes_loss: 0.0112
09/16 11:56:36 AM: Update 36428: task edges-srl-ontonotes, batch 428 (36428): mcc: 0.8748, acc: 0.8270, precision: 0.9073, recall: 0.8471, f1: 0.8762, edges-srl-ontonotes_loss: 0.0107
09/16 11:56:47 AM: Update 36544: task edges-srl-ontonotes, batch 544 (36544): mcc: 0.8777, acc: 0.8305, precision: 0.9093, recall: 0.8506, f1: 0.8790, edges-srl-ontonotes_loss: 0.0105
09/16 11:56:57 AM: Update 36682: task edges-srl-ontonotes, batch 682 (36682): mcc: 0.8798, acc: 0.8334, precision: 0.9107, recall: 0.8533, f1: 0.8811, edges-srl-ontonotes_loss: 0.0103
09/16 11:57:07 AM: Update 36823: task edges-srl-ontonotes, batch 823 (36823): mcc: 0.8814, acc: 0.8354, precision: 0.9120, recall: 0.8553, f1: 0.8827, edges-srl-ontonotes_loss: 0.0102
09/16 11:57:17 AM: Update 36951: task edges-srl-ontonotes, batch 951 (36951): mcc: 0.8818, acc: 0.8362, precision: 0.9123, recall: 0.8557, f1: 0.8831, edges-srl-ontonotes_loss: 0.0102
09/16 11:57:21 AM: ***** Step 37000 / Validation 37 *****
09/16 11:57:21 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:57:21 AM: Validating...
09/16 11:57:27 AM: Evaluate: task edges-srl-ontonotes, batch 88 (157): mcc: 0.8961, acc: 0.8589, precision: 0.9293, recall: 0.8669, f1: 0.8970, edges-srl-ontonotes_loss: 0.0089
09/16 11:57:33 AM: Best result seen so far for edges-srl-ontonotes.
09/16 11:57:33 AM: Best result seen so far for macro.
09/16 11:57:33 AM: Updating LR scheduler:
09/16 11:57:33 AM: 	Best result seen so far for macro_avg: 0.898
09/16 11:57:33 AM: 	# validation passes without improvement: 0
09/16 11:57:33 AM: edges-srl-ontonotes_loss: training: 0.010173 validation: 0.008823
09/16 11:57:33 AM: macro_avg: validation: 0.898285
09/16 11:57:33 AM: micro_avg: validation: 0.000000
09/16 11:57:33 AM: edges-srl-ontonotes_mcc: training: 0.881851 validation: 0.897229
09/16 11:57:33 AM: edges-srl-ontonotes_acc: training: 0.836233 validation: 0.863598
09/16 11:57:33 AM: edges-srl-ontonotes_precision: training: 0.912286 validation: 0.927523
09/16 11:57:33 AM: edges-srl-ontonotes_recall: training: 0.855773 validation: 0.870834
09/16 11:57:33 AM: edges-srl-ontonotes_f1: training: 0.883127 validation: 0.898285
09/16 11:57:33 AM: Global learning rate: 6.25e-06
09/16 11:57:33 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:57:38 AM: Update 37064: task edges-srl-ontonotes, batch 64 (37064): mcc: 0.8828, acc: 0.8378, precision: 0.9137, recall: 0.8562, f1: 0.8840, edges-srl-ontonotes_loss: 0.0102
09/16 11:57:48 AM: Update 37193: task edges-srl-ontonotes, batch 193 (37193): mcc: 0.8796, acc: 0.8333, precision: 0.9109, recall: 0.8528, f1: 0.8809, edges-srl-ontonotes_loss: 0.0103
09/16 11:57:58 AM: Update 37331: task edges-srl-ontonotes, batch 331 (37331): mcc: 0.8763, acc: 0.8280, precision: 0.9074, recall: 0.8498, f1: 0.8776, edges-srl-ontonotes_loss: 0.0106
09/16 11:58:08 AM: Update 37470: task edges-srl-ontonotes, batch 470 (37470): mcc: 0.8720, acc: 0.8224, precision: 0.9038, recall: 0.8450, f1: 0.8734, edges-srl-ontonotes_loss: 0.0109
09/16 11:58:18 AM: Update 37590: task edges-srl-ontonotes, batch 590 (37590): mcc: 0.8717, acc: 0.8219, precision: 0.9038, recall: 0.8443, f1: 0.8730, edges-srl-ontonotes_loss: 0.0109
09/16 11:58:28 AM: Update 37720: task edges-srl-ontonotes, batch 720 (37720): mcc: 0.8715, acc: 0.8215, precision: 0.9039, recall: 0.8438, f1: 0.8728, edges-srl-ontonotes_loss: 0.0109
09/16 11:58:38 AM: Update 37817: task edges-srl-ontonotes, batch 817 (37817): mcc: 0.8703, acc: 0.8203, precision: 0.9028, recall: 0.8427, f1: 0.8717, edges-srl-ontonotes_loss: 0.0109
09/16 11:58:48 AM: Update 37933: task edges-srl-ontonotes, batch 933 (37933): mcc: 0.8683, acc: 0.8180, precision: 0.9013, recall: 0.8403, f1: 0.8697, edges-srl-ontonotes_loss: 0.0111
09/16 11:58:54 AM: ***** Step 38000 / Validation 38 *****
09/16 11:58:54 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 11:58:54 AM: Validating...
09/16 11:58:58 AM: Evaluate: task edges-srl-ontonotes, batch 52 (157): mcc: 0.8902, acc: 0.8517, precision: 0.9267, recall: 0.8582, f1: 0.8911, edges-srl-ontonotes_loss: 0.0095
09/16 11:59:06 AM: Best result seen so far for edges-srl-ontonotes.
09/16 11:59:06 AM: Best result seen so far for macro.
09/16 11:59:06 AM: Updating LR scheduler:
09/16 11:59:06 AM: 	Best result seen so far for macro_avg: 0.899
09/16 11:59:06 AM: 	# validation passes without improvement: 0
09/16 11:59:06 AM: edges-srl-ontonotes_loss: training: 0.011155 validation: 0.008804
09/16 11:59:06 AM: macro_avg: validation: 0.899269
09/16 11:59:06 AM: micro_avg: validation: 0.000000
09/16 11:59:06 AM: edges-srl-ontonotes_mcc: training: 0.866878 validation: 0.898269
09/16 11:59:06 AM: edges-srl-ontonotes_acc: training: 0.816187 validation: 0.863521
09/16 11:59:06 AM: edges-srl-ontonotes_precision: training: 0.900128 validation: 0.929799
09/16 11:59:06 AM: edges-srl-ontonotes_recall: training: 0.838594 validation: 0.870680
09/16 11:59:06 AM: edges-srl-ontonotes_f1: training: 0.868272 validation: 0.899269
09/16 11:59:06 AM: Global learning rate: 6.25e-06
09/16 11:59:06 AM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 11:59:08 AM: Update 38022: task edges-srl-ontonotes, batch 22 (38022): mcc: 0.8501, acc: 0.7970, precision: 0.8861, recall: 0.8199, f1: 0.8517, edges-srl-ontonotes_loss: 0.0123
09/16 11:59:18 AM: Update 38121: task edges-srl-ontonotes, batch 121 (38121): mcc: 0.8452, acc: 0.7900, precision: 0.8841, recall: 0.8123, f1: 0.8466, edges-srl-ontonotes_loss: 0.0127
09/16 11:59:28 AM: Update 38237: task edges-srl-ontonotes, batch 237 (38237): mcc: 0.8504, acc: 0.7954, precision: 0.8878, recall: 0.8187, f1: 0.8518, edges-srl-ontonotes_loss: 0.0124
09/16 11:59:38 AM: Update 38355: task edges-srl-ontonotes, batch 355 (38355): mcc: 0.8514, acc: 0.7957, precision: 0.8895, recall: 0.8191, f1: 0.8528, edges-srl-ontonotes_loss: 0.0123
09/16 11:59:48 AM: Update 38472: task edges-srl-ontonotes, batch 472 (38472): mcc: 0.8544, acc: 0.7997, precision: 0.8924, recall: 0.8220, f1: 0.8558, edges-srl-ontonotes_loss: 0.0120
09/16 11:59:58 AM: Update 38594: task edges-srl-ontonotes, batch 594 (38594): mcc: 0.8597, acc: 0.8063, precision: 0.8964, recall: 0.8284, f1: 0.8611, edges-srl-ontonotes_loss: 0.0116
09/16 12:00:08 PM: Update 38708: task edges-srl-ontonotes, batch 708 (38708): mcc: 0.8629, acc: 0.8102, precision: 0.8987, recall: 0.8324, f1: 0.8643, edges-srl-ontonotes_loss: 0.0114
09/16 12:00:18 PM: Update 38797: task edges-srl-ontonotes, batch 797 (38797): mcc: 0.8643, acc: 0.8120, precision: 0.8996, recall: 0.8342, f1: 0.8657, edges-srl-ontonotes_loss: 0.0113
09/16 12:00:28 PM: Update 38922: task edges-srl-ontonotes, batch 922 (38922): mcc: 0.8655, acc: 0.8135, precision: 0.9007, recall: 0.8354, f1: 0.8668, edges-srl-ontonotes_loss: 0.0112
09/16 12:00:34 PM: ***** Step 39000 / Validation 39 *****
09/16 12:00:34 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 12:00:34 PM: Validating...
09/16 12:00:38 PM: Evaluate: task edges-srl-ontonotes, batch 51 (157): mcc: 0.8887, acc: 0.8528, precision: 0.9225, recall: 0.8592, f1: 0.8897, edges-srl-ontonotes_loss: 0.0095
09/16 12:00:46 PM: Updating LR scheduler:
09/16 12:00:46 PM: 	Best result seen so far for macro_avg: 0.899
09/16 12:00:46 PM: 	# validation passes without improvement: 1
09/16 12:00:46 PM: edges-srl-ontonotes_loss: training: 0.011094 validation: 0.008826
09/16 12:00:46 PM: macro_avg: validation: 0.898270
09/16 12:00:46 PM: micro_avg: validation: 0.000000
09/16 12:00:46 PM: edges-srl-ontonotes_mcc: training: 0.866765 validation: 0.897194
09/16 12:00:46 PM: edges-srl-ontonotes_acc: training: 0.815123 validation: 0.863906
09/16 12:00:46 PM: edges-srl-ontonotes_precision: training: 0.901612 validation: 0.926881
09/16 12:00:46 PM: edges-srl-ontonotes_recall: training: 0.836992 validation: 0.871372
09/16 12:00:46 PM: edges-srl-ontonotes_f1: training: 0.868101 validation: 0.898270
09/16 12:00:46 PM: Global learning rate: 6.25e-06
09/16 12:00:46 PM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 12:00:48 PM: Update 39023: task edges-srl-ontonotes, batch 23 (39023): mcc: 0.8788, acc: 0.8285, precision: 0.9071, recall: 0.8548, f1: 0.8802, edges-srl-ontonotes_loss: 0.0103
09/16 12:00:58 PM: Update 39133: task edges-srl-ontonotes, batch 133 (39133): mcc: 0.8787, acc: 0.8311, precision: 0.9084, recall: 0.8535, f1: 0.8801, edges-srl-ontonotes_loss: 0.0104
09/16 12:01:08 PM: Update 39263: task edges-srl-ontonotes, batch 263 (39263): mcc: 0.8816, acc: 0.8334, precision: 0.9120, recall: 0.8556, f1: 0.8829, edges-srl-ontonotes_loss: 0.0102
09/16 12:01:18 PM: Update 39382: task edges-srl-ontonotes, batch 382 (39382): mcc: 0.8791, acc: 0.8305, precision: 0.9107, recall: 0.8520, f1: 0.8804, edges-srl-ontonotes_loss: 0.0103
09/16 12:01:28 PM: Update 39512: task edges-srl-ontonotes, batch 512 (39512): mcc: 0.8766, acc: 0.8278, precision: 0.9089, recall: 0.8489, f1: 0.8779, edges-srl-ontonotes_loss: 0.0105
09/16 12:01:38 PM: Update 39640: task edges-srl-ontonotes, batch 640 (39640): mcc: 0.8747, acc: 0.8253, precision: 0.9081, recall: 0.8460, f1: 0.8760, edges-srl-ontonotes_loss: 0.0106
09/16 12:01:48 PM: Update 39736: task edges-srl-ontonotes, batch 736 (39736): mcc: 0.8734, acc: 0.8236, precision: 0.9069, recall: 0.8447, f1: 0.8747, edges-srl-ontonotes_loss: 0.0107
09/16 12:01:58 PM: Update 39867: task edges-srl-ontonotes, batch 867 (39867): mcc: 0.8726, acc: 0.8225, precision: 0.9063, recall: 0.8436, f1: 0.8739, edges-srl-ontonotes_loss: 0.0108
09/16 12:02:08 PM: Update 39988: task edges-srl-ontonotes, batch 988 (39988): mcc: 0.8718, acc: 0.8217, precision: 0.9054, recall: 0.8431, f1: 0.8731, edges-srl-ontonotes_loss: 0.0109
09/16 12:02:09 PM: ***** Step 40000 / Validation 40 *****
09/16 12:02:09 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 12:02:09 PM: Validating...
09/16 12:02:19 PM: Evaluate: task edges-srl-ontonotes, batch 121 (157): mcc: 0.8967, acc: 0.8625, precision: 0.9285, recall: 0.8689, f1: 0.8977, edges-srl-ontonotes_loss: 0.0088
09/16 12:02:21 PM: Updating LR scheduler:
09/16 12:02:21 PM: 	Best result seen so far for macro_avg: 0.899
09/16 12:02:21 PM: 	# validation passes without improvement: 2
09/16 12:02:21 PM: edges-srl-ontonotes_loss: training: 0.010874 validation: 0.008888
09/16 12:02:21 PM: macro_avg: validation: 0.897166
09/16 12:02:21 PM: micro_avg: validation: 0.000000
09/16 12:02:21 PM: edges-srl-ontonotes_mcc: training: 0.871455 validation: 0.896133
09/16 12:02:21 PM: edges-srl-ontonotes_acc: training: 0.821251 validation: 0.862289
09/16 12:02:21 PM: edges-srl-ontonotes_precision: training: 0.905187 validation: 0.927585
09/16 12:02:21 PM: edges-srl-ontonotes_recall: training: 0.842585 validation: 0.868678
09/16 12:02:21 PM: edges-srl-ontonotes_f1: training: 0.872765 validation: 0.897166
09/16 12:02:21 PM: Global learning rate: 6.25e-06
09/16 12:02:21 PM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 12:02:29 PM: Update 40094: task edges-srl-ontonotes, batch 94 (40094): mcc: 0.8630, acc: 0.8125, precision: 0.8970, recall: 0.8341, f1: 0.8645, edges-srl-ontonotes_loss: 0.0115
09/16 12:02:39 PM: Update 40226: task edges-srl-ontonotes, batch 226 (40226): mcc: 0.8641, acc: 0.8123, precision: 0.8996, recall: 0.8339, f1: 0.8655, edges-srl-ontonotes_loss: 0.0113
09/16 12:02:49 PM: Update 40344: task edges-srl-ontonotes, batch 344 (40344): mcc: 0.8662, acc: 0.8151, precision: 0.9009, recall: 0.8366, f1: 0.8675, edges-srl-ontonotes_loss: 0.0112
09/16 12:02:59 PM: Update 40475: task edges-srl-ontonotes, batch 475 (40475): mcc: 0.8670, acc: 0.8167, precision: 0.9007, recall: 0.8384, f1: 0.8684, edges-srl-ontonotes_loss: 0.0111
09/16 12:03:09 PM: Update 40604: task edges-srl-ontonotes, batch 604 (40604): mcc: 0.8689, acc: 0.8194, precision: 0.9021, recall: 0.8405, f1: 0.8702, edges-srl-ontonotes_loss: 0.0110
09/16 12:03:19 PM: Update 40726: task edges-srl-ontonotes, batch 726 (40726): mcc: 0.8704, acc: 0.8208, precision: 0.9035, recall: 0.8422, f1: 0.8718, edges-srl-ontonotes_loss: 0.0109
09/16 12:03:29 PM: Update 40854: task edges-srl-ontonotes, batch 854 (40854): mcc: 0.8716, acc: 0.8223, precision: 0.9045, recall: 0.8435, f1: 0.8729, edges-srl-ontonotes_loss: 0.0108
09/16 12:03:39 PM: Update 40943: task edges-srl-ontonotes, batch 943 (40943): mcc: 0.8710, acc: 0.8216, precision: 0.9041, recall: 0.8428, f1: 0.8724, edges-srl-ontonotes_loss: 0.0108
09/16 12:03:44 PM: ***** Step 41000 / Validation 41 *****
09/16 12:03:44 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 12:03:44 PM: Validating...
09/16 12:03:49 PM: Evaluate: task edges-srl-ontonotes, batch 65 (157): mcc: 0.8864, acc: 0.8489, precision: 0.9202, recall: 0.8570, f1: 0.8875, edges-srl-ontonotes_loss: 0.0096
09/16 12:03:56 PM: Updating LR scheduler:
09/16 12:03:56 PM: 	Best result seen so far for macro_avg: 0.899
09/16 12:03:56 PM: 	# validation passes without improvement: 3
09/16 12:03:56 PM: edges-srl-ontonotes_loss: training: 0.010909 validation: 0.008924
09/16 12:03:56 PM: macro_avg: validation: 0.896300
09/16 12:03:56 PM: micro_avg: validation: 0.000000
09/16 12:03:56 PM: edges-srl-ontonotes_mcc: training: 0.870043 validation: 0.895251
09/16 12:03:56 PM: edges-srl-ontonotes_acc: training: 0.820052 validation: 0.861058
09/16 12:03:56 PM: edges-srl-ontonotes_precision: training: 0.903429 validation: 0.926611
09/16 12:03:56 PM: edges-srl-ontonotes_recall: training: 0.841539 validation: 0.867909
09/16 12:03:56 PM: edges-srl-ontonotes_f1: training: 0.871386 validation: 0.896300
09/16 12:03:56 PM: Global learning rate: 6.25e-06
09/16 12:03:56 PM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 12:03:59 PM: Update 41035: task edges-srl-ontonotes, batch 35 (41035): mcc: 0.8545, acc: 0.7979, precision: 0.8903, recall: 0.8242, f1: 0.8560, edges-srl-ontonotes_loss: 0.0124
09/16 12:04:09 PM: Update 41148: task edges-srl-ontonotes, batch 148 (41148): mcc: 0.8491, acc: 0.7913, precision: 0.8886, recall: 0.8156, f1: 0.8505, edges-srl-ontonotes_loss: 0.0125
09/16 12:04:19 PM: Update 41256: task edges-srl-ontonotes, batch 256 (41256): mcc: 0.8531, acc: 0.7964, precision: 0.8923, recall: 0.8197, f1: 0.8544, edges-srl-ontonotes_loss: 0.0122
09/16 12:04:29 PM: Update 41400: task edges-srl-ontonotes, batch 400 (41400): mcc: 0.8681, acc: 0.8159, precision: 0.9041, recall: 0.8372, f1: 0.8694, edges-srl-ontonotes_loss: 0.0111
09/16 12:04:39 PM: Update 41539: task edges-srl-ontonotes, batch 539 (41539): mcc: 0.8751, acc: 0.8254, precision: 0.9088, recall: 0.8460, f1: 0.8763, edges-srl-ontonotes_loss: 0.0105
09/16 12:04:49 PM: Update 41686: task edges-srl-ontonotes, batch 686 (41686): mcc: 0.8835, acc: 0.8364, precision: 0.9144, recall: 0.8569, f1: 0.8847, edges-srl-ontonotes_loss: 0.0099
09/16 12:04:59 PM: Update 41840: task edges-srl-ontonotes, batch 840 (41840): mcc: 0.8897, acc: 0.8450, precision: 0.9187, recall: 0.8648, f1: 0.8909, edges-srl-ontonotes_loss: 0.0094
09/16 12:05:09 PM: Update 41949: task edges-srl-ontonotes, batch 949 (41949): mcc: 0.8925, acc: 0.8488, precision: 0.9209, recall: 0.8680, f1: 0.8937, edges-srl-ontonotes_loss: 0.0092
09/16 12:05:13 PM: ***** Step 42000 / Validation 42 *****
09/16 12:05:13 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 12:05:13 PM: Validating...
09/16 12:05:19 PM: Evaluate: task edges-srl-ontonotes, batch 89 (157): mcc: 0.8924, acc: 0.8531, precision: 0.9298, recall: 0.8595, f1: 0.8932, edges-srl-ontonotes_loss: 0.0091
09/16 12:05:24 PM: Updating LR scheduler:
09/16 12:05:24 PM: 	Best result seen so far for macro_avg: 0.899
09/16 12:05:24 PM: 	# validation passes without improvement: 0
09/16 12:05:24 PM: edges-srl-ontonotes_loss: training: 0.009151 validation: 0.008930
09/16 12:05:24 PM: macro_avg: validation: 0.896510
09/16 12:05:24 PM: micro_avg: validation: 0.000000
09/16 12:05:24 PM: edges-srl-ontonotes_mcc: training: 0.893610 validation: 0.895539
09/16 12:05:24 PM: edges-srl-ontonotes_acc: training: 0.850437 validation: 0.860365
09/16 12:05:24 PM: edges-srl-ontonotes_precision: training: 0.921787 validation: 0.929002
09/16 12:05:24 PM: edges-srl-ontonotes_recall: training: 0.869321 validation: 0.866215
09/16 12:05:24 PM: edges-srl-ontonotes_f1: training: 0.894786 validation: 0.896510
09/16 12:05:24 PM: Global learning rate: 3.125e-06
09/16 12:05:24 PM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 12:05:29 PM: Update 42074: task edges-srl-ontonotes, batch 74 (42074): mcc: 0.9169, acc: 0.8799, precision: 0.9415, recall: 0.8953, f1: 0.9178, edges-srl-ontonotes_loss: 0.0075
09/16 12:05:39 PM: Update 42215: task edges-srl-ontonotes, batch 215 (42215): mcc: 0.9169, acc: 0.8821, precision: 0.9410, recall: 0.8959, f1: 0.9179, edges-srl-ontonotes_loss: 0.0075
09/16 12:05:49 PM: Update 42372: task edges-srl-ontonotes, batch 372 (42372): mcc: 0.9174, acc: 0.8828, precision: 0.9407, recall: 0.8970, f1: 0.9183, edges-srl-ontonotes_loss: 0.0075
09/16 12:05:59 PM: Update 42495: task edges-srl-ontonotes, batch 495 (42495): mcc: 0.9154, acc: 0.8799, precision: 0.9388, recall: 0.8950, f1: 0.9164, edges-srl-ontonotes_loss: 0.0076
09/16 12:06:09 PM: Update 42654: task edges-srl-ontonotes, batch 654 (42654): mcc: 0.9135, acc: 0.8780, precision: 0.9361, recall: 0.8940, f1: 0.9145, edges-srl-ontonotes_loss: 0.0078
09/16 12:06:20 PM: Update 42804: task edges-srl-ontonotes, batch 804 (42804): mcc: 0.9129, acc: 0.8774, precision: 0.9349, recall: 0.8939, f1: 0.9139, edges-srl-ontonotes_loss: 0.0079
09/16 12:06:30 PM: Update 42934: task edges-srl-ontonotes, batch 934 (42934): mcc: 0.9087, acc: 0.8719, precision: 0.9320, recall: 0.8885, f1: 0.9098, edges-srl-ontonotes_loss: 0.0082
09/16 12:06:35 PM: ***** Step 43000 / Validation 43 *****
09/16 12:06:35 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 12:06:35 PM: Validating...
09/16 12:06:40 PM: Evaluate: task edges-srl-ontonotes, batch 72 (157): mcc: 0.8905, acc: 0.8521, precision: 0.9273, recall: 0.8582, f1: 0.8914, edges-srl-ontonotes_loss: 0.0093
09/16 12:06:46 PM: Updating LR scheduler:
09/16 12:06:46 PM: 	Best result seen so far for macro_avg: 0.899
09/16 12:06:46 PM: 	# validation passes without improvement: 1
09/16 12:06:46 PM: edges-srl-ontonotes_loss: training: 0.008258 validation: 0.008902
09/16 12:06:46 PM: macro_avg: validation: 0.897041
09/16 12:06:46 PM: micro_avg: validation: 0.000000
09/16 12:06:46 PM: edges-srl-ontonotes_mcc: training: 0.907430 validation: 0.896073
09/16 12:06:46 PM: edges-srl-ontonotes_acc: training: 0.870147 validation: 0.861135
09/16 12:06:46 PM: edges-srl-ontonotes_precision: training: 0.930988 validation: 0.929432
09/16 12:06:46 PM: edges-srl-ontonotes_recall: training: 0.887132 validation: 0.866831
09/16 12:06:46 PM: edges-srl-ontonotes_f1: training: 0.908531 validation: 0.897041
09/16 12:06:46 PM: Global learning rate: 3.125e-06
09/16 12:06:46 PM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 12:06:50 PM: Update 43046: task edges-srl-ontonotes, batch 46 (43046): mcc: 0.8799, acc: 0.8349, precision: 0.9095, recall: 0.8548, f1: 0.8813, edges-srl-ontonotes_loss: 0.0100
09/16 12:07:00 PM: Update 43122: task edges-srl-ontonotes, batch 122 (43122): mcc: 0.8747, acc: 0.8273, precision: 0.9046, recall: 0.8494, f1: 0.8761, edges-srl-ontonotes_loss: 0.0104
09/16 12:07:10 PM: Update 43252: task edges-srl-ontonotes, batch 252 (43252): mcc: 0.8672, acc: 0.8173, precision: 0.8994, recall: 0.8399, f1: 0.8686, edges-srl-ontonotes_loss: 0.0111
09/16 12:07:20 PM: Update 43385: task edges-srl-ontonotes, batch 385 (43385): mcc: 0.8679, acc: 0.8177, precision: 0.9009, recall: 0.8398, f1: 0.8693, edges-srl-ontonotes_loss: 0.0111
09/16 12:07:30 PM: Update 43504: task edges-srl-ontonotes, batch 504 (43504): mcc: 0.8679, acc: 0.8180, precision: 0.9009, recall: 0.8398, f1: 0.8693, edges-srl-ontonotes_loss: 0.0111
09/16 12:07:40 PM: Update 43649: task edges-srl-ontonotes, batch 649 (43649): mcc: 0.8735, acc: 0.8251, precision: 0.9060, recall: 0.8458, f1: 0.8749, edges-srl-ontonotes_loss: 0.0107
09/16 12:07:51 PM: Update 43790: task edges-srl-ontonotes, batch 790 (43790): mcc: 0.8756, acc: 0.8279, precision: 0.9074, recall: 0.8484, f1: 0.8769, edges-srl-ontonotes_loss: 0.0106
09/16 12:08:01 PM: Update 43928: task edges-srl-ontonotes, batch 928 (43928): mcc: 0.8779, acc: 0.8309, precision: 0.9089, recall: 0.8514, f1: 0.8792, edges-srl-ontonotes_loss: 0.0104
09/16 12:08:06 PM: ***** Step 44000 / Validation 44 *****
09/16 12:08:06 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 12:08:06 PM: Validating...
09/16 12:08:11 PM: Evaluate: task edges-srl-ontonotes, batch 68 (157): mcc: 0.8909, acc: 0.8544, precision: 0.9241, recall: 0.8619, f1: 0.8919, edges-srl-ontonotes_loss: 0.0093
09/16 12:08:18 PM: Updating LR scheduler:
09/16 12:08:18 PM: 	Best result seen so far for macro_avg: 0.899
09/16 12:08:18 PM: 	# validation passes without improvement: 2
09/16 12:08:18 PM: edges-srl-ontonotes_loss: training: 0.010387 validation: 0.008808
09/16 12:08:18 PM: macro_avg: validation: 0.898223
09/16 12:08:18 PM: micro_avg: validation: 0.000000
09/16 12:08:18 PM: edges-srl-ontonotes_mcc: training: 0.878364 validation: 0.897137
09/16 12:08:18 PM: edges-srl-ontonotes_acc: training: 0.831496 validation: 0.864291
09/16 12:08:18 PM: edges-srl-ontonotes_precision: training: 0.909339 validation: 0.926520
09/16 12:08:18 PM: edges-srl-ontonotes_recall: training: 0.851880 validation: 0.871603
09/16 12:08:18 PM: edges-srl-ontonotes_f1: training: 0.879672 validation: 0.898223
09/16 12:08:18 PM: Global learning rate: 3.125e-06
09/16 12:08:18 PM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 12:08:21 PM: Update 44047: task edges-srl-ontonotes, batch 47 (44047): mcc: 0.8981, acc: 0.8568, precision: 0.9277, recall: 0.8722, f1: 0.8991, edges-srl-ontonotes_loss: 0.0089
09/16 12:08:31 PM: Update 44154: task edges-srl-ontonotes, batch 154 (44154): mcc: 0.8915, acc: 0.8506, precision: 0.9182, recall: 0.8688, f1: 0.8928, edges-srl-ontonotes_loss: 0.0094
09/16 12:08:41 PM: Update 44294: task edges-srl-ontonotes, batch 294 (44294): mcc: 0.8863, acc: 0.8415, precision: 0.9146, recall: 0.8621, f1: 0.8875, edges-srl-ontonotes_loss: 0.0097
09/16 12:08:51 PM: Update 44420: task edges-srl-ontonotes, batch 420 (44420): mcc: 0.8847, acc: 0.8395, precision: 0.9142, recall: 0.8594, f1: 0.8860, edges-srl-ontonotes_loss: 0.0099
09/16 12:09:01 PM: Update 44557: task edges-srl-ontonotes, batch 557 (44557): mcc: 0.8806, acc: 0.8342, precision: 0.9110, recall: 0.8546, f1: 0.8819, edges-srl-ontonotes_loss: 0.0102
09/16 12:09:11 PM: Update 44696: task edges-srl-ontonotes, batch 696 (44696): mcc: 0.8780, acc: 0.8306, precision: 0.9092, recall: 0.8513, f1: 0.8793, edges-srl-ontonotes_loss: 0.0104
09/16 12:09:21 PM: Update 44819: task edges-srl-ontonotes, batch 819 (44819): mcc: 0.8779, acc: 0.8304, precision: 0.9093, recall: 0.8511, f1: 0.8792, edges-srl-ontonotes_loss: 0.0104
09/16 12:09:31 PM: Update 44951: task edges-srl-ontonotes, batch 951 (44951): mcc: 0.8767, acc: 0.8288, precision: 0.9085, recall: 0.8495, f1: 0.8780, edges-srl-ontonotes_loss: 0.0105
09/16 12:09:35 PM: ***** Step 45000 / Validation 45 *****
09/16 12:09:35 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 12:09:35 PM: Validating...
09/16 12:09:41 PM: Evaluate: task edges-srl-ontonotes, batch 83 (157): mcc: 0.8953, acc: 0.8580, precision: 0.9290, recall: 0.8657, f1: 0.8962, edges-srl-ontonotes_loss: 0.0091
09/16 12:09:47 PM: Updating LR scheduler:
09/16 12:09:47 PM: 	Best result seen so far for macro_avg: 0.899
09/16 12:09:47 PM: 	# validation passes without improvement: 3
09/16 12:09:47 PM: edges-srl-ontonotes_loss: training: 0.010521 validation: 0.008781
09/16 12:09:47 PM: macro_avg: validation: 0.899233
09/16 12:09:47 PM: micro_avg: validation: 0.000000
09/16 12:09:47 PM: edges-srl-ontonotes_mcc: training: 0.876113 validation: 0.898206
09/16 12:09:47 PM: edges-srl-ontonotes_acc: training: 0.827916 validation: 0.864291
09/16 12:09:47 PM: edges-srl-ontonotes_precision: training: 0.907752 validation: 0.928935
09/16 12:09:47 PM: edges-srl-ontonotes_recall: training: 0.849070 validation: 0.871372
09/16 12:09:47 PM: edges-srl-ontonotes_f1: training: 0.877431 validation: 0.899233
09/16 12:09:47 PM: Global learning rate: 3.125e-06
09/16 12:09:47 PM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 12:09:53 PM: Update 45042: task edges-srl-ontonotes, batch 42 (45042): mcc: 0.8684, acc: 0.8143, precision: 0.9027, recall: 0.8392, f1: 0.8698, edges-srl-ontonotes_loss: 0.0108
09/16 12:10:03 PM: Update 45169: task edges-srl-ontonotes, batch 169 (45169): mcc: 0.8563, acc: 0.8017, precision: 0.8923, recall: 0.8258, f1: 0.8578, edges-srl-ontonotes_loss: 0.0118
09/16 12:10:13 PM: Update 45283: task edges-srl-ontonotes, batch 283 (45283): mcc: 0.8545, acc: 0.7994, precision: 0.8917, recall: 0.8229, f1: 0.8559, edges-srl-ontonotes_loss: 0.0121
09/16 12:10:23 PM: Update 45394: task edges-srl-ontonotes, batch 394 (45394): mcc: 0.8537, acc: 0.7988, precision: 0.8900, recall: 0.8229, f1: 0.8551, edges-srl-ontonotes_loss: 0.0121
09/16 12:10:33 PM: Update 45523: task edges-srl-ontonotes, batch 523 (45523): mcc: 0.8526, acc: 0.7976, precision: 0.8894, recall: 0.8215, f1: 0.8541, edges-srl-ontonotes_loss: 0.0122
09/16 12:10:43 PM: Update 45648: task edges-srl-ontonotes, batch 648 (45648): mcc: 0.8536, acc: 0.7990, precision: 0.8900, recall: 0.8228, f1: 0.8551, edges-srl-ontonotes_loss: 0.0121
09/16 12:10:53 PM: Update 45761: task edges-srl-ontonotes, batch 761 (45761): mcc: 0.8571, acc: 0.8032, precision: 0.8932, recall: 0.8265, f1: 0.8586, edges-srl-ontonotes_loss: 0.0119
09/16 12:11:03 PM: Update 45885: task edges-srl-ontonotes, batch 885 (45885): mcc: 0.8606, acc: 0.8078, precision: 0.8958, recall: 0.8306, f1: 0.8620, edges-srl-ontonotes_loss: 0.0116
09/16 12:11:13 PM: Update 45997: task edges-srl-ontonotes, batch 997 (45997): mcc: 0.8627, acc: 0.8103, precision: 0.8976, recall: 0.8329, f1: 0.8640, edges-srl-ontonotes_loss: 0.0114
09/16 12:11:13 PM: ***** Step 46000 / Validation 46 *****
09/16 12:11:13 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 12:11:13 PM: Validating...
09/16 12:11:23 PM: Evaluate: task edges-srl-ontonotes, batch 131 (157): mcc: 0.9018, acc: 0.8687, precision: 0.9318, recall: 0.8756, f1: 0.9028, edges-srl-ontonotes_loss: 0.0085
09/16 12:11:25 PM: Updating LR scheduler:
09/16 12:11:25 PM: 	Best result seen so far for macro_avg: 0.899
09/16 12:11:25 PM: 	# validation passes without improvement: 0
09/16 12:11:25 PM: edges-srl-ontonotes_loss: training: 0.011444 validation: 0.008794
09/16 12:11:25 PM: macro_avg: validation: 0.898888
09/16 12:11:25 PM: micro_avg: validation: 0.000000
09/16 12:11:25 PM: edges-srl-ontonotes_mcc: training: 0.862767 validation: 0.897852
09/16 12:11:25 PM: edges-srl-ontonotes_acc: training: 0.810426 validation: 0.864291
09/16 12:11:25 PM: edges-srl-ontonotes_precision: training: 0.897756 validation: 0.928460
09/16 12:11:25 PM: edges-srl-ontonotes_recall: training: 0.832979 validation: 0.871142
09/16 12:11:25 PM: edges-srl-ontonotes_f1: training: 0.864155 validation: 0.898888
09/16 12:11:25 PM: Global learning rate: 1.5625e-06
09/16 12:11:25 PM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 12:11:33 PM: Update 46103: task edges-srl-ontonotes, batch 103 (46103): mcc: 0.8753, acc: 0.8251, precision: 0.9086, recall: 0.8467, f1: 0.8766, edges-srl-ontonotes_loss: 0.0105
09/16 12:11:43 PM: Update 46231: task edges-srl-ontonotes, batch 231 (46231): mcc: 0.8777, acc: 0.8297, precision: 0.9093, recall: 0.8507, f1: 0.8790, edges-srl-ontonotes_loss: 0.0103
09/16 12:11:53 PM: Update 46310: task edges-srl-ontonotes, batch 310 (46310): mcc: 0.8770, acc: 0.8289, precision: 0.9086, recall: 0.8500, f1: 0.8783, edges-srl-ontonotes_loss: 0.0104
09/16 12:12:03 PM: Update 46424: task edges-srl-ontonotes, batch 424 (46424): mcc: 0.8787, acc: 0.8312, precision: 0.9098, recall: 0.8522, f1: 0.8800, edges-srl-ontonotes_loss: 0.0103
09/16 12:12:13 PM: Update 46543: task edges-srl-ontonotes, batch 543 (46543): mcc: 0.8799, acc: 0.8325, precision: 0.9106, recall: 0.8536, f1: 0.8812, edges-srl-ontonotes_loss: 0.0102
09/16 12:12:23 PM: Update 46661: task edges-srl-ontonotes, batch 661 (46661): mcc: 0.8788, acc: 0.8311, precision: 0.9105, recall: 0.8516, f1: 0.8801, edges-srl-ontonotes_loss: 0.0103
09/16 12:12:33 PM: Update 46790: task edges-srl-ontonotes, batch 790 (46790): mcc: 0.8773, acc: 0.8293, precision: 0.9092, recall: 0.8499, f1: 0.8786, edges-srl-ontonotes_loss: 0.0104
09/16 12:12:43 PM: Update 46918: task edges-srl-ontonotes, batch 918 (46918): mcc: 0.8756, acc: 0.8271, precision: 0.9081, recall: 0.8477, f1: 0.8769, edges-srl-ontonotes_loss: 0.0105
09/16 12:12:51 PM: ***** Step 47000 / Validation 47 *****
09/16 12:12:51 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 12:12:51 PM: Validating...
09/16 12:12:53 PM: Evaluate: task edges-srl-ontonotes, batch 38 (157): mcc: 0.8931, acc: 0.8551, precision: 0.9309, recall: 0.8598, f1: 0.8939, edges-srl-ontonotes_loss: 0.0092
09/16 12:13:02 PM: Updating LR scheduler:
09/16 12:13:02 PM: 	Best result seen so far for macro_avg: 0.899
09/16 12:13:02 PM: 	# validation passes without improvement: 1
09/16 12:13:02 PM: edges-srl-ontonotes_loss: training: 0.010581 validation: 0.008808
09/16 12:13:02 PM: macro_avg: validation: 0.898403
09/16 12:13:02 PM: micro_avg: validation: 0.000000
09/16 12:13:02 PM: edges-srl-ontonotes_mcc: training: 0.874998 validation: 0.897362
09/16 12:13:02 PM: edges-srl-ontonotes_acc: training: 0.826209 validation: 0.863983
09/16 12:13:02 PM: edges-srl-ontonotes_precision: training: 0.907765 validation: 0.928038
09/16 12:13:02 PM: edges-srl-ontonotes_recall: training: 0.846928 validation: 0.870603
09/16 12:13:02 PM: edges-srl-ontonotes_f1: training: 0.876292 validation: 0.898403
09/16 12:13:02 PM: Global learning rate: 1.5625e-06
09/16 12:13:02 PM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 12:13:03 PM: Update 47014: task edges-srl-ontonotes, batch 14 (47014): mcc: 0.8617, acc: 0.8054, precision: 0.9028, recall: 0.8264, f1: 0.8629, edges-srl-ontonotes_loss: 0.0114
09/16 12:13:14 PM: Update 47145: task edges-srl-ontonotes, batch 145 (47145): mcc: 0.8635, acc: 0.8109, precision: 0.9002, recall: 0.8320, f1: 0.8648, edges-srl-ontonotes_loss: 0.0114
09/16 12:13:24 PM: Update 47242: task edges-srl-ontonotes, batch 242 (47242): mcc: 0.8657, acc: 0.8140, precision: 0.9013, recall: 0.8354, f1: 0.8671, edges-srl-ontonotes_loss: 0.0113
09/16 12:13:34 PM: Update 47371: task edges-srl-ontonotes, batch 371 (47371): mcc: 0.8656, acc: 0.8138, precision: 0.9005, recall: 0.8358, f1: 0.8669, edges-srl-ontonotes_loss: 0.0112
09/16 12:13:44 PM: Update 47505: task edges-srl-ontonotes, batch 505 (47505): mcc: 0.8655, acc: 0.8135, precision: 0.9010, recall: 0.8352, f1: 0.8668, edges-srl-ontonotes_loss: 0.0113
09/16 12:13:54 PM: Update 47624: task edges-srl-ontonotes, batch 624 (47624): mcc: 0.8664, acc: 0.8143, precision: 0.9013, recall: 0.8366, f1: 0.8677, edges-srl-ontonotes_loss: 0.0112
09/16 12:14:04 PM: Update 47755: task edges-srl-ontonotes, batch 755 (47755): mcc: 0.8674, acc: 0.8162, precision: 0.9016, recall: 0.8383, f1: 0.8688, edges-srl-ontonotes_loss: 0.0111
09/16 12:14:14 PM: Update 47873: task edges-srl-ontonotes, batch 873 (47873): mcc: 0.8683, acc: 0.8171, precision: 0.9023, recall: 0.8393, f1: 0.8697, edges-srl-ontonotes_loss: 0.0110
09/16 12:14:24 PM: ***** Step 48000 / Validation 48 *****
09/16 12:14:24 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 12:14:24 PM: Validating...
09/16 12:14:24 PM: Evaluate: task edges-srl-ontonotes, batch 5 (157): mcc: 0.8961, acc: 0.8702, precision: 0.9189, recall: 0.8770, f1: 0.8974, edges-srl-ontonotes_loss: 0.0081
09/16 12:14:34 PM: Evaluate: task edges-srl-ontonotes, batch 139 (157): mcc: 0.8991, acc: 0.8655, precision: 0.9294, recall: 0.8726, f1: 0.9001, edges-srl-ontonotes_loss: 0.0086
09/16 12:14:35 PM: Updating LR scheduler:
09/16 12:14:35 PM: 	Best result seen so far for macro_avg: 0.899
09/16 12:14:35 PM: 	# validation passes without improvement: 2
09/16 12:14:35 PM: Ran out of early stopping patience. Stopping training.
09/16 12:14:35 PM: edges-srl-ontonotes_loss: training: 0.010956 validation: 0.008826
09/16 12:14:35 PM: macro_avg: validation: 0.897776
09/16 12:14:35 PM: micro_avg: validation: 0.000000
09/16 12:14:35 PM: edges-srl-ontonotes_mcc: training: 0.869251 validation: 0.896723
09/16 12:14:35 PM: edges-srl-ontonotes_acc: training: 0.818224 validation: 0.863059
09/16 12:14:35 PM: edges-srl-ontonotes_precision: training: 0.903141 validation: 0.927312
09/16 12:14:35 PM: edges-srl-ontonotes_recall: training: 0.840299 validation: 0.870064
09/16 12:14:35 PM: edges-srl-ontonotes_f1: training: 0.870588 validation: 0.897776
09/16 12:14:35 PM: Global learning rate: 1.5625e-06
09/16 12:14:35 PM: Saving checkpoints to: ./experiments/srl-ontonotes-mrpc-mix/run
09/16 12:14:35 PM: Stopped training after 48 validation checks
09/16 12:14:35 PM: Trained edges-srl-ontonotes for 48000 batches or 6.635 epochs
09/16 12:14:35 PM: ***** VALIDATION RESULTS *****
09/16 12:14:35 PM: edges-srl-ontonotes_f1 (for best val pass 38): edges-srl-ontonotes_loss: 0.00880, macro_avg: 0.89927, micro_avg: 0.00000, edges-srl-ontonotes_mcc: 0.89827, edges-srl-ontonotes_acc: 0.86352, edges-srl-ontonotes_precision: 0.92980, edges-srl-ontonotes_recall: 0.87068, edges-srl-ontonotes_f1: 0.89927
09/16 12:14:35 PM: micro_avg (for best val pass 1): edges-srl-ontonotes_loss: 0.02103, macro_avg: 0.77898, micro_avg: 0.00000, edges-srl-ontonotes_mcc: 0.78350, edges-srl-ontonotes_acc: 0.67485, edges-srl-ontonotes_precision: 0.90137, edges-srl-ontonotes_recall: 0.68586, edges-srl-ontonotes_f1: 0.77898
09/16 12:14:35 PM: macro_avg (for best val pass 38): edges-srl-ontonotes_loss: 0.00880, macro_avg: 0.89927, micro_avg: 0.00000, edges-srl-ontonotes_mcc: 0.89827, edges-srl-ontonotes_acc: 0.86352, edges-srl-ontonotes_precision: 0.92980, edges-srl-ontonotes_recall: 0.87068, edges-srl-ontonotes_f1: 0.89927
09/16 12:14:35 PM: Evaluating...
09/16 12:14:35 PM: Loaded model state from ./experiments/srl-ontonotes-mrpc-mix/run/edges-srl-ontonotes/model_state_target_train_val_38.best.th
09/16 12:14:35 PM: Evaluating on: edges-srl-ontonotes, split: val
09/16 12:15:05 PM: 	Task edges-srl-ontonotes: batch 358
09/16 12:15:35 PM: 	Task edges-srl-ontonotes: batch 670
09/16 12:16:05 PM: Task 'edges-srl-ontonotes': sorting predictions by 'idx'
09/16 12:16:05 PM: Finished evaluating on: edges-srl-ontonotes
09/16 12:16:05 PM: Task 'edges-srl-ontonotes': joining predictions with input split 'val'
09/16 12:16:10 PM: Task 'edges-srl-ontonotes': Wrote predictions to ./experiments/srl-ontonotes-mrpc-mix/run
09/16 12:16:10 PM: Wrote all preds for split 'val' to ./experiments/srl-ontonotes-mrpc-mix/run
09/16 12:16:10 PM: Evaluating on: edges-srl-ontonotes, split: test
09/16 12:16:40 PM: 	Task edges-srl-ontonotes: batch 348
09/16 12:17:10 PM: 	Task edges-srl-ontonotes: batch 706
09/16 12:17:13 PM: Task 'edges-srl-ontonotes': sorting predictions by 'idx'
09/16 12:17:13 PM: Finished evaluating on: edges-srl-ontonotes
09/16 12:17:13 PM: Task 'edges-srl-ontonotes': joining predictions with input split 'test'
09/16 12:17:17 PM: Task 'edges-srl-ontonotes': Wrote predictions to ./experiments/srl-ontonotes-mrpc-mix/run
09/16 12:17:17 PM: Wrote all preds for split 'test' to ./experiments/srl-ontonotes-mrpc-mix/run
09/16 12:17:17 PM: Writing results for split 'val' to ./experiments/srl-ontonotes-mrpc-mix/results.tsv
09/16 12:17:17 PM: micro_avg: 0.000, macro_avg: 0.897, edges-srl-ontonotes_mcc: 0.896, edges-srl-ontonotes_acc: 0.862, edges-srl-ontonotes_precision: 0.927, edges-srl-ontonotes_recall: 0.869, edges-srl-ontonotes_f1: 0.897
09/16 12:17:17 PM: Done!
09/16 12:17:17 PM: Fatal error in main():
Traceback (most recent call last):
  File "main.py", line 16, in <module>
    main(sys.argv[1:])
  File "/srv/home/ericwallace/jiant/jiant/__main__.py", line 610, in main
    exit("Done exited")
  File "/home/ericwallace/miniconda3/envs/jiant/lib/python3.6/_sitebuiltins.py", line 26, in __call__
    raise SystemExit(code)
SystemExit: Done exited
