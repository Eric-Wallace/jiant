09/07 09:16:38 PM: Git branch: master
09/07 09:16:38 PM: Git SHA: 117419dc9116809c203f878fb83f7aaddafbbcb0
09/07 09:16:39 PM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "/scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/",
  "exp_name": "experiments/srl-ontonotes-RANDOM-cat",
  "input_module": "bert-base-uncased",
  "local_log_path": "/scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run/log.log",
  "lr_patience": 5,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 20,
  "pretrain_tasks": "",
  "pretrained_dir": "RANDOM",
  "pytorch_transformers_output_mode": "cat",
  "remote_log_name": "experiments/srl-ontonotes-RANDOM-cat__run",
  "run_dir": "/scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-srl-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/07 09:16:39 PM: Saved config to /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run/params.conf
09/07 09:16:39 PM: Using random seed 1234
09/07 09:16:40 PM: Using GPU 0
09/07 09:16:40 PM: Loading tasks...
09/07 09:16:40 PM: Writing pre-preprocessed tasks to /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/
09/07 09:16:40 PM: 	Creating task edges-srl-ontonotes from scratch.
09/07 09:16:44 PM: Read=231480, Skip=21590, Total=253070 from /scratch0/new/jiant/probing_data/edges/ontonotes/srl/train.json.retokenized.bert-base-uncased
09/07 09:16:45 PM: Read=32486, Skip=2811, Total=35297 from /scratch0/new/jiant/probing_data/edges/ontonotes/srl/development.json.retokenized.bert-base-uncased
09/07 09:16:45 PM: Read=23800, Skip=2915, Total=26715 from /scratch0/new/jiant/probing_data/edges/ontonotes/srl/test.json.retokenized.bert-base-uncased
09/07 09:16:48 PM: 	Task 'edges-srl-ontonotes': |train|=231480 |val|=32486 |test|=23800
09/07 09:16:48 PM: 	Finished loading tasks: edges-srl-ontonotes.
09/07 09:16:48 PM: 	Building vocab from scratch.
09/07 09:16:48 PM: 	Counting units for task edges-srl-ontonotes.
09/07 09:16:55 PM: 	Task 'edges-srl-ontonotes': adding vocab namespace 'edges-srl-ontonotes_labels'
09/07 09:16:56 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to /tmp/tmphk9ogyyc
09/07 09:16:56 PM: copying /tmp/tmphk9ogyyc to cache at /cliphomes/ewallac2/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:16:56 PM: creating metadata file for /cliphomes/ewallac2/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:16:56 PM: removing temp file /tmp/tmphk9ogyyc
09/07 09:16:56 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /cliphomes/ewallac2/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:16:56 PM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/07 09:16:56 PM: 	Saved vocab to /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/vocab
09/07 09:16:56 PM: Loading token dictionary from /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/vocab.
09/07 09:16:56 PM: 	Loaded vocab from /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/vocab
09/07 09:16:56 PM: 	Vocab namespace tokens: size 23662
09/07 09:16:56 PM: 	Vocab namespace chars: size 76
09/07 09:16:56 PM: 	Vocab namespace edges-srl-ontonotes_labels: size 66
09/07 09:16:56 PM: 	Vocab namespace bert_uncased: size 30524
09/07 09:16:56 PM: 	Finished building vocab.
09/07 09:16:56 PM: 	Task edges-srl-ontonotes (train): Indexing from scratch.
09/07 09:17:44 PM: 	Task edges-srl-ontonotes (train): Saved 231480 instances to /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/preproc/edges-srl-ontonotes__train_data
09/07 09:17:44 PM: 	Task edges-srl-ontonotes (val): Indexing from scratch.
09/07 09:17:51 PM: 	Task edges-srl-ontonotes (val): Saved 32486 instances to /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/preproc/edges-srl-ontonotes__val_data
09/07 09:17:51 PM: 	Task edges-srl-ontonotes (test): Indexing from scratch.
09/07 09:17:56 PM: 	Task edges-srl-ontonotes (test): Saved 23800 instances to /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/preproc/edges-srl-ontonotes__test_data
09/07 09:17:56 PM: 	Finished indexing tasks
09/07 09:17:56 PM: 	Creating trimmed target-only version of edges-srl-ontonotes train.
09/07 09:17:56 PM: 	  Training on 
09/07 09:17:56 PM: 	  Evaluating on edges-srl-ontonotes
09/07 09:17:56 PM: 	Finished loading tasks in 75.947s
09/07 09:17:56 PM: 	 Tasks: ['edges-srl-ontonotes']
09/07 09:17:56 PM: Building model...
09/07 09:17:56 PM: Using BERT model (bert-base-uncased).
09/07 09:17:56 PM: LOADING A RANDOMLY WEIGHTS BERT
09/07 09:17:58 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache, downloading to /tmp/tmpjcd_k82y
09/07 09:17:58 PM: copying /tmp/tmpjcd_k82y to cache at /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/07 09:17:58 PM: creating metadata file for /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/07 09:17:58 PM: removing temp file /tmp/tmpjcd_k82y
09/07 09:17:58 PM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/07 09:17:58 PM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/07 09:17:58 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache, downloading to /tmp/tmpa7gznfdi
09/07 09:18:20 PM: copying /tmp/tmpa7gznfdi to cache at /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/07 09:18:20 PM: creating metadata file for /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/07 09:18:20 PM: removing temp file /tmp/tmpa7gznfdi
09/07 09:18:20 PM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/07 09:18:23 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to /tmp/tmp3ess285r
09/07 09:18:23 PM: copying /tmp/tmp3ess285r to cache at /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:18:23 PM: creating metadata file for /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:18:23 PM: removing temp file /tmp/tmp3ess285r
09/07 09:18:23 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:18:23 PM: Initializing parameters
09/07 09:18:23 PM: Done initializing parameters; the following parameters are using their default initialization from their code
09/07 09:18:23 PM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/07 09:18:23 PM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/07 09:18:23 PM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/07 09:18:23 PM:    _text_field_embedder.model.pooler.dense.bias
09/07 09:18:23 PM:    _text_field_embedder.model.pooler.dense.weight
09/07 09:18:23 PM: 	Task 'edges-srl-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-srl-ontonotes"
}
09/07 09:18:28 PM: Model specification:
09/07 09:18:28 PM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): BertLayerNorm()
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-srl-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(1536, 256, kernel_size=(1,), stride=(1,))
    (proj2): Conv1d(1536, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (span_extractor2): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Sequential(
        (0): Linear(in_features=1024, out_features=256, bias=True)
        (1): Tanh()
        (2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)
        (3): Dropout(p=0.3)
        (4): Linear(in_features=256, out_features=66, bias=True)
      )
    )
  )
)
09/07 09:18:28 PM: Model parameters:
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:28 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:28 PM: 	edges-srl-ontonotes_mdl.proj1.weight: Trainable parameter, count 393216 with torch.Size([256, 1536, 1])
09/07 09:18:28 PM: 	edges-srl-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:28 PM: 	edges-srl-ontonotes_mdl.proj2.weight: Trainable parameter, count 393216 with torch.Size([256, 1536, 1])
09/07 09:18:28 PM: 	edges-srl-ontonotes_mdl.proj2.bias: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:28 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.0.weight: Trainable parameter, count 262144 with torch.Size([256, 1024])
09/07 09:18:28 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.0.bias: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:28 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.2.weight: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:28 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.2.bias: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:28 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.4.weight: Trainable parameter, count 16896 with torch.Size([66, 256])
09/07 09:18:28 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.4.bias: Trainable parameter, count 66 with torch.Size([66])
09/07 09:18:28 PM: Total number of parameters: 110549058 (1.10549e+08)
09/07 09:18:28 PM: Number of trainable parameters: 1066818 (1.06682e+06)
09/07 09:18:28 PM: Finished building model in 31.945s
09/07 09:18:28 PM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-srl-ontonotes 

09/07 09:18:44 PM: patience = 20
09/07 09:18:44 PM: val_interval = 1000
09/07 09:18:44 PM: max_vals = 250
09/07 09:18:44 PM: cuda_device = 0
09/07 09:18:44 PM: grad_norm = 5.0
09/07 09:18:44 PM: grad_clipping = None
09/07 09:18:44 PM: lr_decay = 0.99
09/07 09:18:44 PM: min_lr = 1e-06
09/07 09:18:44 PM: keep_all_checkpoints = 0
09/07 09:18:44 PM: val_data_limit = 5000
09/07 09:18:44 PM: max_epochs = -1
09/07 09:18:44 PM: dec_val_scale = 250
09/07 09:18:44 PM: training_data_fraction = 1
09/07 09:18:44 PM: type = adam
09/07 09:18:44 PM: parameter_groups = None
09/07 09:18:44 PM: Number of trainable parameters: 1066818
09/07 09:18:44 PM: infer_type_and_cast = True
09/07 09:18:44 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/07 09:18:44 PM: CURRENTLY DEFINED PARAMETERS: 
09/07 09:18:44 PM: lr = 0.0001
09/07 09:18:44 PM: amsgrad = True
09/07 09:18:44 PM: type = reduce_on_plateau
09/07 09:18:44 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/07 09:18:44 PM: CURRENTLY DEFINED PARAMETERS: 
09/07 09:18:44 PM: mode = max
09/07 09:18:44 PM: factor = 0.5
09/07 09:18:44 PM: patience = 5
09/07 09:18:44 PM: threshold = 0.0001
09/07 09:18:44 PM: threshold_mode = abs
09/07 09:18:44 PM: verbose = True
09/07 09:18:44 PM: type = adam
09/07 09:18:44 PM: parameter_groups = None
09/07 09:18:44 PM: Number of trainable parameters: 1066818
09/07 09:18:44 PM: infer_type_and_cast = True
09/07 09:18:44 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/07 09:18:44 PM: CURRENTLY DEFINED PARAMETERS: 
09/07 09:18:44 PM: lr = 0.0001
09/07 09:18:44 PM: amsgrad = True
09/07 09:18:44 PM: type = reduce_on_plateau
09/07 09:18:44 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/07 09:18:44 PM: CURRENTLY DEFINED PARAMETERS: 
09/07 09:18:44 PM: mode = max
09/07 09:18:44 PM: factor = 0.5
09/07 09:18:44 PM: patience = 5
09/07 09:18:44 PM: threshold = 0.0001
09/07 09:18:44 PM: threshold_mode = abs
09/07 09:18:44 PM: verbose = True
09/07 09:18:44 PM: Starting training without restoring from a checkpoint.
09/07 09:18:44 PM: Training examples per task, before any subsampling: {'edges-srl-ontonotes': 231480}
09/07 09:18:44 PM: Beginning training with stopping criteria based on metric: edges-srl-ontonotes_f1
09/07 09:18:54 PM: Update 110: task edges-srl-ontonotes, batch 110 (110): mcc: 0.0329, acc: 0.0214, precision: 0.0429, recall: 0.0581, f1: 0.0493, edges-srl-ontonotes_loss: 0.1987
09/07 09:19:04 PM: Update 230: task edges-srl-ontonotes, batch 230 (230): mcc: 0.0494, acc: 0.0329, precision: 0.0747, recall: 0.0501, f1: 0.0600, edges-srl-ontonotes_loss: 0.1324
09/07 09:19:14 PM: Update 337: task edges-srl-ontonotes, batch 337 (337): mcc: 0.1133, acc: 0.0781, precision: 0.1685, recall: 0.0899, f1: 0.1173, edges-srl-ontonotes_loss: 0.1071
09/07 09:19:24 PM: Update 455: task edges-srl-ontonotes, batch 455 (455): mcc: 0.1906, acc: 0.1304, precision: 0.2837, recall: 0.1397, f1: 0.1872, edges-srl-ontonotes_loss: 0.0908
09/07 09:19:34 PM: Update 578: task edges-srl-ontonotes, batch 578 (578): mcc: 0.2655, acc: 0.1826, precision: 0.3893, recall: 0.1917, f1: 0.2569, edges-srl-ontonotes_loss: 0.0795
09/07 09:19:44 PM: Update 665: task edges-srl-ontonotes, batch 665 (665): mcc: 0.3006, acc: 0.2068, precision: 0.4382, recall: 0.2162, f1: 0.2895, edges-srl-ontonotes_loss: 0.0740
09/07 09:19:54 PM: Update 786: task edges-srl-ontonotes, batch 786 (786): mcc: 0.3333, acc: 0.2289, precision: 0.4829, recall: 0.2396, f1: 0.3203, edges-srl-ontonotes_loss: 0.0681
09/07 09:20:04 PM: Update 903: task edges-srl-ontonotes, batch 903 (903): mcc: 0.3609, acc: 0.2489, precision: 0.5174, recall: 0.2612, f1: 0.3471, edges-srl-ontonotes_loss: 0.0637
09/07 09:20:13 PM: ***** Step 1000 / Validation 1 *****
09/07 09:20:13 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:20:13 PM: Validating...
09/07 09:20:14 PM: Evaluate: task edges-srl-ontonotes, batch 8 (157): mcc: 0.5601, acc: 0.3938, precision: 0.7842, recall: 0.4065, f1: 0.5354, edges-srl-ontonotes_loss: 0.0326
09/07 09:20:24 PM: Evaluate: task edges-srl-ontonotes, batch 116 (157): mcc: 0.6065, acc: 0.4590, precision: 0.7916, recall: 0.4714, f1: 0.5909, edges-srl-ontonotes_loss: 0.0303
09/07 09:20:28 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:20:28 PM: Best result seen so far for micro.
09/07 09:20:28 PM: Best result seen so far for macro.
09/07 09:20:28 PM: Updating LR scheduler:
09/07 09:20:28 PM: 	Best result seen so far for macro_avg: 0.582
09/07 09:20:28 PM: 	# validation passes without improvement: 0
09/07 09:20:28 PM: edges-srl-ontonotes_loss: training: 0.060752 validation: 0.030529
09/07 09:20:28 PM: macro_avg: validation: 0.582121
09/07 09:20:28 PM: micro_avg: validation: 0.000000
09/07 09:20:28 PM: edges-srl-ontonotes_mcc: training: 0.378612 validation: 0.598363
09/07 09:20:28 PM: edges-srl-ontonotes_acc: training: 0.262254 validation: 0.450235
09/07 09:20:28 PM: edges-srl-ontonotes_precision: training: 0.538193 validation: 0.786173
09/07 09:20:28 PM: edges-srl-ontonotes_recall: training: 0.275576 validation: 0.462166
09/07 09:20:28 PM: edges-srl-ontonotes_f1: training: 0.364509 validation: 0.582121
09/07 09:20:28 PM: Global learning rate: 0.0001
09/07 09:20:28 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 09:20:34 PM: Update 1071: task edges-srl-ontonotes, batch 71 (1071): mcc: 0.5390, acc: 0.3914, precision: 0.7081, recall: 0.4182, f1: 0.5258, edges-srl-ontonotes_loss: 0.0336
09/07 09:20:44 PM: Update 1187: task edges-srl-ontonotes, batch 187 (1187): mcc: 0.5431, acc: 0.3960, precision: 0.7112, recall: 0.4227, f1: 0.5302, edges-srl-ontonotes_loss: 0.0332
09/07 09:20:54 PM: Update 1288: task edges-srl-ontonotes, batch 288 (1288): mcc: 0.5496, acc: 0.4045, precision: 0.7131, recall: 0.4315, f1: 0.5376, edges-srl-ontonotes_loss: 0.0327
09/07 09:21:05 PM: Update 1402: task edges-srl-ontonotes, batch 402 (1402): mcc: 0.5504, acc: 0.4058, precision: 0.7115, recall: 0.4338, f1: 0.5390, edges-srl-ontonotes_loss: 0.0323
09/07 09:21:15 PM: Update 1511: task edges-srl-ontonotes, batch 511 (1511): mcc: 0.5560, acc: 0.4129, precision: 0.7133, recall: 0.4414, f1: 0.5453, edges-srl-ontonotes_loss: 0.0319
09/07 09:21:25 PM: Update 1612: task edges-srl-ontonotes, batch 612 (1612): mcc: 0.5577, acc: 0.4154, precision: 0.7132, recall: 0.4441, f1: 0.5473, edges-srl-ontonotes_loss: 0.0317
09/07 09:21:35 PM: Update 1723: task edges-srl-ontonotes, batch 723 (1723): mcc: 0.5557, acc: 0.4138, precision: 0.7117, recall: 0.4419, f1: 0.5453, edges-srl-ontonotes_loss: 0.0318
09/07 09:21:45 PM: Update 1829: task edges-srl-ontonotes, batch 829 (1829): mcc: 0.5538, acc: 0.4113, precision: 0.7105, recall: 0.4397, f1: 0.5432, edges-srl-ontonotes_loss: 0.0318
09/07 09:21:55 PM: Update 1907: task edges-srl-ontonotes, batch 907 (1907): mcc: 0.5535, acc: 0.4107, precision: 0.7101, recall: 0.4395, f1: 0.5429, edges-srl-ontonotes_loss: 0.0318
09/07 09:22:04 PM: ***** Step 2000 / Validation 2 *****
09/07 09:22:04 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:22:04 PM: Validating...
09/07 09:22:05 PM: Evaluate: task edges-srl-ontonotes, batch 14 (157): mcc: 0.6132, acc: 0.4556, precision: 0.8230, recall: 0.4631, f1: 0.5927, edges-srl-ontonotes_loss: 0.0271
09/07 09:22:15 PM: Evaluate: task edges-srl-ontonotes, batch 122 (157): mcc: 0.6300, acc: 0.4889, precision: 0.8121, recall: 0.4951, f1: 0.6152, edges-srl-ontonotes_loss: 0.0265
09/07 09:22:18 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:22:18 PM: Best result seen so far for macro.
09/07 09:22:18 PM: Updating LR scheduler:
09/07 09:22:18 PM: 	Best result seen so far for macro_avg: 0.608
09/07 09:22:18 PM: 	# validation passes without improvement: 0
09/07 09:22:18 PM: edges-srl-ontonotes_loss: training: 0.031708 validation: 0.026812
09/07 09:22:18 PM: macro_avg: validation: 0.608337
09/07 09:22:18 PM: micro_avg: validation: 0.000000
09/07 09:22:18 PM: edges-srl-ontonotes_mcc: training: 0.553262 validation: 0.623715
09/07 09:22:18 PM: edges-srl-ontonotes_acc: training: 0.410336 validation: 0.481872
09/07 09:22:18 PM: edges-srl-ontonotes_precision: training: 0.709809 validation: 0.808630
09/07 09:22:18 PM: edges-srl-ontonotes_recall: training: 0.439278 validation: 0.487568
09/07 09:22:18 PM: edges-srl-ontonotes_f1: training: 0.542697 validation: 0.608337
09/07 09:22:18 PM: Global learning rate: 0.0001
09/07 09:22:18 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 09:22:25 PM: Update 2075: task edges-srl-ontonotes, batch 75 (2075): mcc: 0.5588, acc: 0.4214, precision: 0.7067, recall: 0.4500, f1: 0.5499, edges-srl-ontonotes_loss: 0.0308
09/07 09:22:35 PM: Update 2187: task edges-srl-ontonotes, batch 187 (2187): mcc: 0.5683, acc: 0.4302, precision: 0.7154, recall: 0.4596, f1: 0.5597, edges-srl-ontonotes_loss: 0.0306
09/07 09:22:45 PM: Update 2278: task edges-srl-ontonotes, batch 278 (2278): mcc: 0.5659, acc: 0.4282, precision: 0.7085, recall: 0.4602, f1: 0.5579, edges-srl-ontonotes_loss: 0.0306
09/07 09:22:55 PM: Update 2380: task edges-srl-ontonotes, batch 380 (2380): mcc: 0.5693, acc: 0.4327, precision: 0.7079, recall: 0.4661, f1: 0.5621, edges-srl-ontonotes_loss: 0.0301
09/07 09:23:05 PM: Update 2488: task edges-srl-ontonotes, batch 488 (2488): mcc: 0.5726, acc: 0.4369, precision: 0.7099, recall: 0.4702, f1: 0.5657, edges-srl-ontonotes_loss: 0.0298
09/07 09:23:15 PM: Update 2585: task edges-srl-ontonotes, batch 585 (2585): mcc: 0.5740, acc: 0.4380, precision: 0.7100, recall: 0.4724, f1: 0.5673, edges-srl-ontonotes_loss: 0.0297
09/07 09:23:25 PM: Update 2695: task edges-srl-ontonotes, batch 695 (2695): mcc: 0.5774, acc: 0.4417, precision: 0.7124, recall: 0.4762, f1: 0.5708, edges-srl-ontonotes_loss: 0.0295
09/07 09:23:35 PM: Update 2804: task edges-srl-ontonotes, batch 804 (2804): mcc: 0.5796, acc: 0.4450, precision: 0.7128, recall: 0.4796, f1: 0.5734, edges-srl-ontonotes_loss: 0.0293
09/07 09:23:45 PM: Update 2881: task edges-srl-ontonotes, batch 881 (2881): mcc: 0.5827, acc: 0.4486, precision: 0.7149, recall: 0.4832, f1: 0.5766, edges-srl-ontonotes_loss: 0.0292
09/07 09:23:55 PM: Update 2988: task edges-srl-ontonotes, batch 988 (2988): mcc: 0.5849, acc: 0.4518, precision: 0.7160, recall: 0.4860, f1: 0.5790, edges-srl-ontonotes_loss: 0.0290
09/07 09:23:57 PM: ***** Step 3000 / Validation 3 *****
09/07 09:23:57 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:23:57 PM: Validating...
09/07 09:24:06 PM: Evaluate: task edges-srl-ontonotes, batch 97 (157): mcc: 0.6238, acc: 0.4999, precision: 0.7828, recall: 0.5041, f1: 0.6133, edges-srl-ontonotes_loss: 0.0268
09/07 09:24:11 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:24:11 PM: Best result seen so far for macro.
09/07 09:24:11 PM: Updating LR scheduler:
09/07 09:24:11 PM: 	Best result seen so far for macro_avg: 0.612
09/07 09:24:11 PM: 	# validation passes without improvement: 0
09/07 09:24:11 PM: edges-srl-ontonotes_loss: training: 0.028996 validation: 0.026604
09/07 09:24:11 PM: macro_avg: validation: 0.612446
09/07 09:24:11 PM: micro_avg: validation: 0.000000
09/07 09:24:11 PM: edges-srl-ontonotes_mcc: training: 0.585525 validation: 0.623359
09/07 09:24:11 PM: edges-srl-ontonotes_acc: training: 0.452507 validation: 0.498422
09/07 09:24:11 PM: edges-srl-ontonotes_precision: training: 0.716726 validation: 0.784538
09/07 09:24:11 PM: edges-srl-ontonotes_recall: training: 0.486603 validation: 0.502271
09/07 09:24:11 PM: edges-srl-ontonotes_f1: training: 0.579660 validation: 0.612446
09/07 09:24:11 PM: Global learning rate: 0.0001
09/07 09:24:11 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 09:24:16 PM: Update 3047: task edges-srl-ontonotes, batch 47 (3047): mcc: 0.6259, acc: 0.5061, precision: 0.7420, recall: 0.5359, f1: 0.6224, edges-srl-ontonotes_loss: 0.0268
09/07 09:24:26 PM: Update 3143: task edges-srl-ontonotes, batch 143 (3143): mcc: 0.6261, acc: 0.5017, precision: 0.7462, recall: 0.5333, f1: 0.6220, edges-srl-ontonotes_loss: 0.0270
09/07 09:24:36 PM: Update 3254: task edges-srl-ontonotes, batch 254 (3254): mcc: 0.6104, acc: 0.4849, precision: 0.7312, recall: 0.5177, f1: 0.6062, edges-srl-ontonotes_loss: 0.0277
09/07 09:24:46 PM: Update 3364: task edges-srl-ontonotes, batch 364 (3364): mcc: 0.6039, acc: 0.4771, precision: 0.7266, recall: 0.5101, f1: 0.5994, edges-srl-ontonotes_loss: 0.0279
09/07 09:24:56 PM: Update 3458: task edges-srl-ontonotes, batch 458 (3458): mcc: 0.6041, acc: 0.4778, precision: 0.7261, recall: 0.5108, f1: 0.5997, edges-srl-ontonotes_loss: 0.0279
09/07 09:25:06 PM: Update 3571: task edges-srl-ontonotes, batch 571 (3571): mcc: 0.6034, acc: 0.4767, precision: 0.7255, recall: 0.5100, f1: 0.5990, edges-srl-ontonotes_loss: 0.0279
09/07 09:25:16 PM: Update 3676: task edges-srl-ontonotes, batch 676 (3676): mcc: 0.6029, acc: 0.4763, precision: 0.7261, recall: 0.5088, f1: 0.5983, edges-srl-ontonotes_loss: 0.0279
09/07 09:25:26 PM: Update 3774: task edges-srl-ontonotes, batch 774 (3774): mcc: 0.6030, acc: 0.4766, precision: 0.7258, recall: 0.5092, f1: 0.5985, edges-srl-ontonotes_loss: 0.0279
09/07 09:25:36 PM: Update 3883: task edges-srl-ontonotes, batch 883 (3883): mcc: 0.6036, acc: 0.4774, precision: 0.7262, recall: 0.5099, f1: 0.5991, edges-srl-ontonotes_loss: 0.0278
09/07 09:25:46 PM: Update 3989: task edges-srl-ontonotes, batch 989 (3989): mcc: 0.6031, acc: 0.4774, precision: 0.7252, recall: 0.5097, f1: 0.5986, edges-srl-ontonotes_loss: 0.0278
09/07 09:25:47 PM: ***** Step 4000 / Validation 4 *****
09/07 09:25:47 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:25:47 PM: Validating...
09/07 09:25:56 PM: Evaluate: task edges-srl-ontonotes, batch 78 (157): mcc: 0.6250, acc: 0.4902, precision: 0.8006, recall: 0.4946, f1: 0.6115, edges-srl-ontonotes_loss: 0.0269
09/07 09:26:04 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:26:04 PM: Best result seen so far for macro.
09/07 09:26:04 PM: Updating LR scheduler:
09/07 09:26:04 PM: 	Best result seen so far for macro_avg: 0.620
09/07 09:26:04 PM: 	# validation passes without improvement: 0
09/07 09:26:04 PM: edges-srl-ontonotes_loss: training: 0.027813 validation: 0.026224
09/07 09:26:04 PM: macro_avg: validation: 0.620471
09/07 09:26:04 PM: micro_avg: validation: 0.000000
09/07 09:26:04 PM: edges-srl-ontonotes_mcc: training: 0.602789 validation: 0.633481
09/07 09:26:04 PM: edges-srl-ontonotes_acc: training: 0.477053 validation: 0.500654
09/07 09:26:04 PM: edges-srl-ontonotes_precision: training: 0.724902 validation: 0.806452
09/07 09:26:04 PM: edges-srl-ontonotes_recall: training: 0.509470 validation: 0.504195
09/07 09:26:04 PM: edges-srl-ontonotes_f1: training: 0.598387 validation: 0.620471
09/07 09:26:04 PM: Global learning rate: 0.0001
09/07 09:26:04 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 09:26:06 PM: Update 4029: task edges-srl-ontonotes, batch 29 (4029): mcc: 0.5993, acc: 0.4718, precision: 0.7258, recall: 0.5030, f1: 0.5942, edges-srl-ontonotes_loss: 0.0278
09/07 09:26:16 PM: Update 4125: task edges-srl-ontonotes, batch 125 (4125): mcc: 0.6070, acc: 0.4869, precision: 0.7272, recall: 0.5149, f1: 0.6029, edges-srl-ontonotes_loss: 0.0275
09/07 09:26:26 PM: Update 4232: task edges-srl-ontonotes, batch 232 (4232): mcc: 0.6091, acc: 0.4887, precision: 0.7272, recall: 0.5183, f1: 0.6052, edges-srl-ontonotes_loss: 0.0273
09/07 09:26:36 PM: Update 4341: task edges-srl-ontonotes, batch 341 (4341): mcc: 0.6128, acc: 0.4926, precision: 0.7292, recall: 0.5232, f1: 0.6093, edges-srl-ontonotes_loss: 0.0271
09/07 09:26:46 PM: Update 4440: task edges-srl-ontonotes, batch 440 (4440): mcc: 0.6158, acc: 0.4965, precision: 0.7304, recall: 0.5274, f1: 0.6125, edges-srl-ontonotes_loss: 0.0270
09/07 09:26:56 PM: Update 4549: task edges-srl-ontonotes, batch 549 (4549): mcc: 0.6172, acc: 0.4980, precision: 0.7305, recall: 0.5297, f1: 0.6141, edges-srl-ontonotes_loss: 0.0268
09/07 09:27:06 PM: Update 4658: task edges-srl-ontonotes, batch 658 (4658): mcc: 0.6186, acc: 0.4998, precision: 0.7312, recall: 0.5316, f1: 0.6156, edges-srl-ontonotes_loss: 0.0267
09/07 09:27:17 PM: Update 4745: task edges-srl-ontonotes, batch 745 (4745): mcc: 0.6159, acc: 0.4970, precision: 0.7294, recall: 0.5282, f1: 0.6127, edges-srl-ontonotes_loss: 0.0269
09/07 09:27:27 PM: Update 4843: task edges-srl-ontonotes, batch 843 (4843): mcc: 0.6122, acc: 0.4928, precision: 0.7279, recall: 0.5232, f1: 0.6088, edges-srl-ontonotes_loss: 0.0271
09/07 09:27:37 PM: Update 4938: task edges-srl-ontonotes, batch 938 (4938): mcc: 0.6115, acc: 0.4921, precision: 0.7280, recall: 0.5220, f1: 0.6080, edges-srl-ontonotes_loss: 0.0272
09/07 09:27:43 PM: ***** Step 5000 / Validation 5 *****
09/07 09:27:43 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:27:43 PM: Validating...
09/07 09:27:47 PM: Evaluate: task edges-srl-ontonotes, batch 41 (157): mcc: 0.6287, acc: 0.4968, precision: 0.8025, recall: 0.4991, f1: 0.6155, edges-srl-ontonotes_loss: 0.0266
09/07 09:27:57 PM: Evaluate: task edges-srl-ontonotes, batch 148 (157): mcc: 0.6332, acc: 0.5088, precision: 0.7949, recall: 0.5112, f1: 0.6222, edges-srl-ontonotes_loss: 0.0261
09/07 09:27:58 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:27:58 PM: Best result seen so far for macro.
09/07 09:27:58 PM: Updating LR scheduler:
09/07 09:27:58 PM: 	Best result seen so far for macro_avg: 0.622
09/07 09:27:58 PM: 	# validation passes without improvement: 0
09/07 09:27:58 PM: edges-srl-ontonotes_loss: training: 0.027238 validation: 0.026253
09/07 09:27:58 PM: macro_avg: validation: 0.621895
09/07 09:27:58 PM: micro_avg: validation: 0.000000
09/07 09:27:58 PM: edges-srl-ontonotes_mcc: training: 0.612140 validation: 0.632901
09/07 09:27:58 PM: edges-srl-ontonotes_acc: training: 0.492706 validation: 0.508506
09/07 09:27:58 PM: edges-srl-ontonotes_precision: training: 0.729200 validation: 0.794896
09/07 09:27:58 PM: edges-srl-ontonotes_recall: training: 0.522067 validation: 0.510738
09/07 09:27:58 PM: edges-srl-ontonotes_f1: training: 0.608489 validation: 0.621895
09/07 09:27:58 PM: Global learning rate: 0.0001
09/07 09:27:58 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 09:28:07 PM: Update 5069: task edges-srl-ontonotes, batch 69 (5069): mcc: 0.6401, acc: 0.5249, precision: 0.7522, recall: 0.5525, f1: 0.6371, edges-srl-ontonotes_loss: 0.0260
09/07 09:28:17 PM: Update 5191: task edges-srl-ontonotes, batch 191 (5191): mcc: 0.6637, acc: 0.5512, precision: 0.7699, recall: 0.5797, f1: 0.6614, edges-srl-ontonotes_loss: 0.0244
09/07 09:28:27 PM: Update 5310: task edges-srl-ontonotes, batch 310 (5310): mcc: 0.6746, acc: 0.5640, precision: 0.7765, recall: 0.5934, f1: 0.6727, edges-srl-ontonotes_loss: 0.0238
09/07 09:28:37 PM: Update 5425: task edges-srl-ontonotes, batch 425 (5425): mcc: 0.6912, acc: 0.5840, precision: 0.7877, recall: 0.6136, f1: 0.6898, edges-srl-ontonotes_loss: 0.0229
09/07 09:28:47 PM: Update 5556: task edges-srl-ontonotes, batch 556 (5556): mcc: 0.7076, acc: 0.6039, precision: 0.7980, recall: 0.6343, f1: 0.7068, edges-srl-ontonotes_loss: 0.0220
09/07 09:28:57 PM: Update 5674: task edges-srl-ontonotes, batch 674 (5674): mcc: 0.7153, acc: 0.6147, precision: 0.8021, recall: 0.6448, f1: 0.7149, edges-srl-ontonotes_loss: 0.0215
09/07 09:29:07 PM: Update 5805: task edges-srl-ontonotes, batch 805 (5805): mcc: 0.7211, acc: 0.6225, precision: 0.8053, recall: 0.6525, f1: 0.7209, edges-srl-ontonotes_loss: 0.0211
09/07 09:29:17 PM: Update 5936: task edges-srl-ontonotes, batch 936 (5936): mcc: 0.7271, acc: 0.6307, precision: 0.8086, recall: 0.6605, f1: 0.7271, edges-srl-ontonotes_loss: 0.0207
09/07 09:29:25 PM: ***** Step 6000 / Validation 6 *****
09/07 09:29:25 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:29:25 PM: Validating...
09/07 09:29:27 PM: Evaluate: task edges-srl-ontonotes, batch 25 (157): mcc: 0.6643, acc: 0.5382, precision: 0.8253, recall: 0.5411, f1: 0.6536, edges-srl-ontonotes_loss: 0.0245
09/07 09:29:37 PM: Evaluate: task edges-srl-ontonotes, batch 133 (157): mcc: 0.6746, acc: 0.5669, precision: 0.8089, recall: 0.5693, f1: 0.6682, edges-srl-ontonotes_loss: 0.0242
09/07 09:29:39 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:29:39 PM: Best result seen so far for macro.
09/07 09:29:39 PM: Updating LR scheduler:
09/07 09:29:39 PM: 	Best result seen so far for macro_avg: 0.657
09/07 09:29:39 PM: 	# validation passes without improvement: 0
09/07 09:29:39 PM: edges-srl-ontonotes_loss: training: 0.020621 validation: 0.024864
09/07 09:29:39 PM: macro_avg: validation: 0.657097
09/07 09:29:39 PM: micro_avg: validation: 0.000000
09/07 09:29:39 PM: edges-srl-ontonotes_mcc: training: 0.729375 validation: 0.663930
09/07 09:29:39 PM: edges-srl-ontonotes_acc: training: 0.633761 validation: 0.554615
09/07 09:29:39 PM: edges-srl-ontonotes_precision: training: 0.809908 validation: 0.801529
09/07 09:29:39 PM: edges-srl-ontonotes_recall: training: 0.663460 validation: 0.556770
09/07 09:29:39 PM: edges-srl-ontonotes_f1: training: 0.729406 validation: 0.657097
09/07 09:29:39 PM: Global learning rate: 0.0001
09/07 09:29:39 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 09:29:47 PM: Update 6104: task edges-srl-ontonotes, batch 104 (6104): mcc: 0.7693, acc: 0.6905, precision: 0.8347, recall: 0.7149, f1: 0.7702, edges-srl-ontonotes_loss: 0.0183
09/07 09:29:57 PM: Update 6233: task edges-srl-ontonotes, batch 233 (6233): mcc: 0.7747, acc: 0.6943, precision: 0.8384, recall: 0.7216, f1: 0.7757, edges-srl-ontonotes_loss: 0.0179
09/07 09:30:07 PM: Update 6351: task edges-srl-ontonotes, batch 351 (6351): mcc: 0.7797, acc: 0.7026, precision: 0.8426, recall: 0.7273, f1: 0.7807, edges-srl-ontonotes_loss: 0.0178
09/07 09:30:17 PM: Update 6486: task edges-srl-ontonotes, batch 486 (6486): mcc: 0.7864, acc: 0.7122, precision: 0.8478, recall: 0.7351, f1: 0.7874, edges-srl-ontonotes_loss: 0.0174
09/07 09:30:27 PM: Update 6597: task edges-srl-ontonotes, batch 597 (6597): mcc: 0.7849, acc: 0.7103, precision: 0.8469, recall: 0.7329, f1: 0.7858, edges-srl-ontonotes_loss: 0.0176
09/07 09:30:37 PM: Update 6711: task edges-srl-ontonotes, batch 711 (6711): mcc: 0.7681, acc: 0.6898, precision: 0.8343, recall: 0.7132, f1: 0.7690, edges-srl-ontonotes_loss: 0.0186
09/07 09:30:47 PM: Update 6822: task edges-srl-ontonotes, batch 822 (6822): mcc: 0.7587, acc: 0.6775, precision: 0.8274, recall: 0.7018, f1: 0.7595, edges-srl-ontonotes_loss: 0.0192
09/07 09:30:57 PM: Update 6918: task edges-srl-ontonotes, batch 918 (6918): mcc: 0.7495, acc: 0.6661, precision: 0.8207, recall: 0.6908, f1: 0.7502, edges-srl-ontonotes_loss: 0.0197
09/07 09:31:05 PM: ***** Step 7000 / Validation 7 *****
09/07 09:31:05 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:31:05 PM: Validating...
09/07 09:31:07 PM: Evaluate: task edges-srl-ontonotes, batch 26 (157): mcc: 0.6742, acc: 0.5452, precision: 0.8403, recall: 0.5470, f1: 0.6626, edges-srl-ontonotes_loss: 0.0234
09/07 09:31:18 PM: Evaluate: task edges-srl-ontonotes, batch 115 (157): mcc: 0.6830, acc: 0.5703, precision: 0.8256, recall: 0.5715, f1: 0.6754, edges-srl-ontonotes_loss: 0.0231
09/07 09:31:21 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:31:21 PM: Best result seen so far for macro.
09/07 09:31:21 PM: Updating LR scheduler:
09/07 09:31:21 PM: 	Best result seen so far for macro_avg: 0.667
09/07 09:31:21 PM: 	# validation passes without improvement: 0
09/07 09:31:21 PM: edges-srl-ontonotes_loss: training: 0.020255 validation: 0.023565
09/07 09:31:21 PM: macro_avg: validation: 0.667093
09/07 09:31:21 PM: micro_avg: validation: 0.000000
09/07 09:31:21 PM: edges-srl-ontonotes_mcc: training: 0.739798 validation: 0.675083
09/07 09:31:21 PM: edges-srl-ontonotes_acc: training: 0.653610 validation: 0.561081
09/07 09:31:21 PM: edges-srl-ontonotes_precision: training: 0.814051 validation: 0.820029
09/07 09:31:21 PM: edges-srl-ontonotes_recall: training: 0.678800 validation: 0.562235
09/07 09:31:21 PM: edges-srl-ontonotes_f1: training: 0.740299 validation: 0.667093
09/07 09:31:21 PM: Global learning rate: 0.0001
09/07 09:31:21 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 09:31:28 PM: Update 7068: task edges-srl-ontonotes, batch 68 (7068): mcc: 0.6481, acc: 0.5400, precision: 0.7501, recall: 0.5679, f1: 0.6464, edges-srl-ontonotes_loss: 0.0254
09/07 09:31:38 PM: Update 7178: task edges-srl-ontonotes, batch 178 (7178): mcc: 0.6502, acc: 0.5439, precision: 0.7509, recall: 0.5709, f1: 0.6487, edges-srl-ontonotes_loss: 0.0252
09/07 09:31:48 PM: Update 7275: task edges-srl-ontonotes, batch 275 (7275): mcc: 0.6528, acc: 0.5459, precision: 0.7570, recall: 0.5707, f1: 0.6508, edges-srl-ontonotes_loss: 0.0252
09/07 09:31:58 PM: Update 7398: task edges-srl-ontonotes, batch 398 (7398): mcc: 0.6694, acc: 0.5651, precision: 0.7695, recall: 0.5899, f1: 0.6678, edges-srl-ontonotes_loss: 0.0242
09/07 09:32:08 PM: Update 7515: task edges-srl-ontonotes, batch 515 (7515): mcc: 0.6788, acc: 0.5754, precision: 0.7775, recall: 0.5999, f1: 0.6773, edges-srl-ontonotes_loss: 0.0237
09/07 09:32:18 PM: Update 7618: task edges-srl-ontonotes, batch 618 (7618): mcc: 0.6848, acc: 0.5825, precision: 0.7815, recall: 0.6073, f1: 0.6834, edges-srl-ontonotes_loss: 0.0233
09/07 09:32:28 PM: Update 7737: task edges-srl-ontonotes, batch 737 (7737): mcc: 0.6916, acc: 0.5907, precision: 0.7860, recall: 0.6157, f1: 0.6905, edges-srl-ontonotes_loss: 0.0229
09/07 09:32:38 PM: Update 7855: task edges-srl-ontonotes, batch 855 (7855): mcc: 0.6970, acc: 0.5974, precision: 0.7897, recall: 0.6224, f1: 0.6961, edges-srl-ontonotes_loss: 0.0225
09/07 09:32:48 PM: Update 7959: task edges-srl-ontonotes, batch 959 (7959): mcc: 0.6942, acc: 0.5941, precision: 0.7869, recall: 0.6196, f1: 0.6933, edges-srl-ontonotes_loss: 0.0227
09/07 09:32:51 PM: ***** Step 8000 / Validation 8 *****
09/07 09:32:51 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:32:51 PM: Validating...
09/07 09:32:58 PM: Evaluate: task edges-srl-ontonotes, batch 72 (157): mcc: 0.7090, acc: 0.6026, precision: 0.8408, recall: 0.6039, f1: 0.7030, edges-srl-ontonotes_loss: 0.0216
09/07 09:33:06 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:33:06 PM: Best result seen so far for macro.
09/07 09:33:06 PM: Updating LR scheduler:
09/07 09:33:06 PM: 	Best result seen so far for macro_avg: 0.701
09/07 09:33:06 PM: 	# validation passes without improvement: 0
09/07 09:33:06 PM: edges-srl-ontonotes_loss: training: 0.022751 validation: 0.021413
09/07 09:33:06 PM: macro_avg: validation: 0.701470
09/07 09:33:06 PM: micro_avg: validation: 0.000000
09/07 09:33:06 PM: edges-srl-ontonotes_mcc: training: 0.693469 validation: 0.707503
09/07 09:33:06 PM: edges-srl-ontonotes_acc: training: 0.593399 validation: 0.601724
09/07 09:33:06 PM: edges-srl-ontonotes_precision: training: 0.786098 validation: 0.839357
09/07 09:33:06 PM: edges-srl-ontonotes_recall: training: 0.618927 validation: 0.602494
09/07 09:33:06 PM: edges-srl-ontonotes_f1: training: 0.692568 validation: 0.701470
09/07 09:33:06 PM: Global learning rate: 0.0001
09/07 09:33:06 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 09:33:08 PM: Update 8026: task edges-srl-ontonotes, batch 26 (8026): mcc: 0.6509, acc: 0.5411, precision: 0.7497, recall: 0.5731, f1: 0.6496, edges-srl-ontonotes_loss: 0.0245
09/07 09:33:18 PM: Update 8144: task edges-srl-ontonotes, batch 144 (8144): mcc: 0.6644, acc: 0.5587, precision: 0.7608, recall: 0.5879, f1: 0.6633, edges-srl-ontonotes_loss: 0.0242
09/07 09:33:28 PM: Update 8222: task edges-srl-ontonotes, batch 222 (8222): mcc: 0.6617, acc: 0.5565, precision: 0.7584, recall: 0.5850, f1: 0.6605, edges-srl-ontonotes_loss: 0.0244
09/07 09:33:38 PM: Update 8340: task edges-srl-ontonotes, batch 340 (8340): mcc: 0.6567, acc: 0.5503, precision: 0.7554, recall: 0.5787, f1: 0.6554, edges-srl-ontonotes_loss: 0.0246
09/07 09:33:48 PM: Update 8451: task edges-srl-ontonotes, batch 451 (8451): mcc: 0.6539, acc: 0.5464, precision: 0.7535, recall: 0.5753, f1: 0.6524, edges-srl-ontonotes_loss: 0.0249
09/07 09:33:58 PM: Update 8550: task edges-srl-ontonotes, batch 550 (8550): mcc: 0.6496, acc: 0.5418, precision: 0.7497, recall: 0.5708, f1: 0.6481, edges-srl-ontonotes_loss: 0.0251
09/07 09:34:08 PM: Update 8659: task edges-srl-ontonotes, batch 659 (8659): mcc: 0.6481, acc: 0.5399, precision: 0.7482, recall: 0.5693, f1: 0.6466, edges-srl-ontonotes_loss: 0.0251
09/07 09:34:18 PM: Update 8773: task edges-srl-ontonotes, batch 773 (8773): mcc: 0.6491, acc: 0.5414, precision: 0.7486, recall: 0.5707, f1: 0.6477, edges-srl-ontonotes_loss: 0.0250
09/07 09:34:28 PM: Update 8871: task edges-srl-ontonotes, batch 871 (8871): mcc: 0.6462, acc: 0.5383, precision: 0.7464, recall: 0.5674, f1: 0.6447, edges-srl-ontonotes_loss: 0.0251
09/07 09:34:38 PM: Update 8976: task edges-srl-ontonotes, batch 976 (8976): mcc: 0.6416, acc: 0.5326, precision: 0.7434, recall: 0.5617, f1: 0.6399, edges-srl-ontonotes_loss: 0.0254
09/07 09:34:40 PM: ***** Step 9000 / Validation 9 *****
09/07 09:34:40 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:34:40 PM: Validating...
09/07 09:34:48 PM: Evaluate: task edges-srl-ontonotes, batch 84 (157): mcc: 0.7056, acc: 0.6049, precision: 0.8291, recall: 0.6068, f1: 0.7007, edges-srl-ontonotes_loss: 0.0218
09/07 09:34:55 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:34:55 PM: Best result seen so far for macro.
09/07 09:34:55 PM: Updating LR scheduler:
09/07 09:34:55 PM: 	Best result seen so far for macro_avg: 0.703
09/07 09:34:55 PM: 	# validation passes without improvement: 0
09/07 09:34:55 PM: edges-srl-ontonotes_loss: training: 0.025421 validation: 0.021409
09/07 09:34:55 PM: macro_avg: validation: 0.702698
09/07 09:34:55 PM: micro_avg: validation: 0.000000
09/07 09:34:55 PM: edges-srl-ontonotes_mcc: training: 0.640702 validation: 0.707596
09/07 09:34:55 PM: edges-srl-ontonotes_acc: training: 0.531407 validation: 0.606574
09/07 09:34:55 PM: edges-srl-ontonotes_precision: training: 0.742957 validation: 0.831405
09/07 09:34:55 PM: edges-srl-ontonotes_recall: training: 0.560558 validation: 0.608498
09/07 09:34:55 PM: edges-srl-ontonotes_f1: training: 0.638996 validation: 0.702698
09/07 09:34:55 PM: Global learning rate: 0.0001
09/07 09:34:55 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 09:34:58 PM: Update 9034: task edges-srl-ontonotes, batch 34 (9034): mcc: 0.6178, acc: 0.4995, precision: 0.7297, recall: 0.5314, f1: 0.6149, edges-srl-ontonotes_loss: 0.0267
09/07 09:35:10 PM: Update 9125: task edges-srl-ontonotes, batch 125 (9125): mcc: 0.6183, acc: 0.5038, precision: 0.7304, recall: 0.5317, f1: 0.6154, edges-srl-ontonotes_loss: 0.0266
09/07 09:35:20 PM: Update 9233: task edges-srl-ontonotes, batch 233 (9233): mcc: 0.6151, acc: 0.4997, precision: 0.7290, recall: 0.5273, f1: 0.6120, edges-srl-ontonotes_loss: 0.0268
09/07 09:35:30 PM: Update 9344: task edges-srl-ontonotes, batch 344 (9344): mcc: 0.6196, acc: 0.5041, precision: 0.7333, recall: 0.5317, f1: 0.6164, edges-srl-ontonotes_loss: 0.0266
09/07 09:35:40 PM: Update 9439: task edges-srl-ontonotes, batch 439 (9439): mcc: 0.6202, acc: 0.5051, precision: 0.7339, recall: 0.5323, f1: 0.6170, edges-srl-ontonotes_loss: 0.0267
09/07 09:35:50 PM: Update 9544: task edges-srl-ontonotes, batch 544 (9544): mcc: 0.6228, acc: 0.5081, precision: 0.7345, recall: 0.5362, f1: 0.6199, edges-srl-ontonotes_loss: 0.0264
09/07 09:36:00 PM: Update 9649: task edges-srl-ontonotes, batch 649 (9649): mcc: 0.6255, acc: 0.5118, precision: 0.7357, recall: 0.5399, f1: 0.6228, edges-srl-ontonotes_loss: 0.0262
09/07 09:36:11 PM: Update 9751: task edges-srl-ontonotes, batch 751 (9751): mcc: 0.6254, acc: 0.5117, precision: 0.7350, recall: 0.5403, f1: 0.6228, edges-srl-ontonotes_loss: 0.0261
09/07 09:36:21 PM: Update 9861: task edges-srl-ontonotes, batch 861 (9861): mcc: 0.6269, acc: 0.5138, precision: 0.7351, recall: 0.5428, f1: 0.6245, edges-srl-ontonotes_loss: 0.0260
09/07 09:36:31 PM: Update 9967: task edges-srl-ontonotes, batch 967 (9967): mcc: 0.6285, acc: 0.5155, precision: 0.7363, recall: 0.5446, f1: 0.6261, edges-srl-ontonotes_loss: 0.0259
09/07 09:36:34 PM: ***** Step 10000 / Validation 10 *****
09/07 09:36:34 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:36:34 PM: Validating...
09/07 09:36:41 PM: Evaluate: task edges-srl-ontonotes, batch 74 (157): mcc: 0.6912, acc: 0.5837, precision: 0.8266, recall: 0.5844, f1: 0.6847, edges-srl-ontonotes_loss: 0.0225
09/07 09:36:49 PM: Updating LR scheduler:
09/07 09:36:49 PM: 	Best result seen so far for macro_avg: 0.703
09/07 09:36:49 PM: 	# validation passes without improvement: 1
09/07 09:36:49 PM: edges-srl-ontonotes_loss: training: 0.025853 validation: 0.022118
09/07 09:36:49 PM: macro_avg: validation: 0.683844
09/07 09:36:49 PM: micro_avg: validation: 0.000000
09/07 09:36:49 PM: edges-srl-ontonotes_mcc: training: 0.628596 validation: 0.690708
09/07 09:36:49 PM: edges-srl-ontonotes_acc: training: 0.515661 validation: 0.581633
09/07 09:36:49 PM: edges-srl-ontonotes_precision: training: 0.735981 validation: 0.828387
09/07 09:36:49 PM: edges-srl-ontonotes_recall: training: 0.545022 validation: 0.582249
09/07 09:36:49 PM: edges-srl-ontonotes_f1: training: 0.626268 validation: 0.683844
09/07 09:36:49 PM: Global learning rate: 0.0001
09/07 09:36:49 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 09:36:51 PM: Update 10022: task edges-srl-ontonotes, batch 22 (10022): mcc: 0.6510, acc: 0.5377, precision: 0.7485, recall: 0.5741, f1: 0.6498, edges-srl-ontonotes_loss: 0.0243
09/07 09:37:01 PM: Update 10096: task edges-srl-ontonotes, batch 96 (10096): mcc: 0.6570, acc: 0.5477, precision: 0.7526, recall: 0.5814, f1: 0.6561, edges-srl-ontonotes_loss: 0.0242
09/07 09:37:11 PM: Update 10203: task edges-srl-ontonotes, batch 203 (10203): mcc: 0.6545, acc: 0.5466, precision: 0.7517, recall: 0.5778, f1: 0.6533, edges-srl-ontonotes_loss: 0.0243
09/07 09:37:21 PM: Update 10312: task edges-srl-ontonotes, batch 312 (10312): mcc: 0.6572, acc: 0.5489, precision: 0.7551, recall: 0.5798, f1: 0.6560, edges-srl-ontonotes_loss: 0.0242
09/07 09:37:31 PM: Update 10410: task edges-srl-ontonotes, batch 410 (10410): mcc: 0.6559, acc: 0.5484, precision: 0.7532, recall: 0.5790, f1: 0.6547, edges-srl-ontonotes_loss: 0.0243
09/07 09:37:41 PM: Update 10518: task edges-srl-ontonotes, batch 518 (10518): mcc: 0.6507, acc: 0.5428, precision: 0.7487, recall: 0.5735, f1: 0.6495, edges-srl-ontonotes_loss: 0.0246
09/07 09:37:51 PM: Update 10626: task edges-srl-ontonotes, batch 626 (10626): mcc: 0.6490, acc: 0.5413, precision: 0.7474, recall: 0.5715, f1: 0.6477, edges-srl-ontonotes_loss: 0.0247
09/07 09:38:02 PM: Update 10720: task edges-srl-ontonotes, batch 720 (10720): mcc: 0.6474, acc: 0.5396, precision: 0.7460, recall: 0.5699, f1: 0.6462, edges-srl-ontonotes_loss: 0.0248
09/07 09:38:12 PM: Update 10830: task edges-srl-ontonotes, batch 830 (10830): mcc: 0.6458, acc: 0.5375, precision: 0.7452, recall: 0.5676, f1: 0.6444, edges-srl-ontonotes_loss: 0.0249
09/07 09:38:22 PM: Update 10938: task edges-srl-ontonotes, batch 938 (10938): mcc: 0.6453, acc: 0.5368, precision: 0.7454, recall: 0.5666, f1: 0.6438, edges-srl-ontonotes_loss: 0.0249
09/07 09:38:27 PM: ***** Step 11000 / Validation 11 *****
09/07 09:38:27 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:38:27 PM: Validating...
09/07 09:38:32 PM: Evaluate: task edges-srl-ontonotes, batch 46 (157): mcc: 0.6740, acc: 0.5596, precision: 0.8197, recall: 0.5606, f1: 0.6658, edges-srl-ontonotes_loss: 0.0242
09/07 09:38:42 PM: Evaluate: task edges-srl-ontonotes, batch 152 (157): mcc: 0.6829, acc: 0.5743, precision: 0.8201, recall: 0.5752, f1: 0.6762, edges-srl-ontonotes_loss: 0.0231
09/07 09:38:42 PM: Updating LR scheduler:
09/07 09:38:42 PM: 	Best result seen so far for macro_avg: 0.703
09/07 09:38:42 PM: 	# validation passes without improvement: 2
09/07 09:38:42 PM: edges-srl-ontonotes_loss: training: 0.024935 validation: 0.023141
09/07 09:38:42 PM: macro_avg: validation: 0.675837
09/07 09:38:42 PM: micro_avg: validation: 0.000000
09/07 09:38:42 PM: edges-srl-ontonotes_mcc: training: 0.644441 validation: 0.682623
09/07 09:38:42 PM: edges-srl-ontonotes_acc: training: 0.535721 validation: 0.574013
09/07 09:38:42 PM: edges-srl-ontonotes_precision: training: 0.744871 validation: 0.819848
09/07 09:38:42 PM: edges-srl-ontonotes_recall: training: 0.565562 validation: 0.574859
09/07 09:38:42 PM: edges-srl-ontonotes_f1: training: 0.642949 validation: 0.675837
09/07 09:38:42 PM: Global learning rate: 0.0001
09/07 09:38:42 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 09:38:52 PM: Update 11093: task edges-srl-ontonotes, batch 93 (11093): mcc: 0.6370, acc: 0.5275, precision: 0.7406, recall: 0.5560, f1: 0.6352, edges-srl-ontonotes_loss: 0.0253
09/07 09:39:02 PM: Update 11203: task edges-srl-ontonotes, batch 203 (11203): mcc: 0.6426, acc: 0.5314, precision: 0.7477, recall: 0.5601, f1: 0.6405, edges-srl-ontonotes_loss: 0.0252
09/07 09:39:12 PM: Update 11311: task edges-srl-ontonotes, batch 311 (11311): mcc: 0.6392, acc: 0.5282, precision: 0.7448, recall: 0.5566, f1: 0.6371, edges-srl-ontonotes_loss: 0.0253
09/07 09:39:22 PM: Update 11387: task edges-srl-ontonotes, batch 387 (11387): mcc: 0.6398, acc: 0.5293, precision: 0.7442, recall: 0.5580, f1: 0.6378, edges-srl-ontonotes_loss: 0.0252
09/07 09:39:32 PM: Update 11497: task edges-srl-ontonotes, batch 497 (11497): mcc: 0.6436, acc: 0.5342, precision: 0.7456, recall: 0.5634, f1: 0.6419, edges-srl-ontonotes_loss: 0.0249
09/07 09:39:42 PM: Update 11608: task edges-srl-ontonotes, batch 608 (11608): mcc: 0.6457, acc: 0.5372, precision: 0.7464, recall: 0.5667, f1: 0.6442, edges-srl-ontonotes_loss: 0.0248
09/07 09:39:52 PM: Update 11704: task edges-srl-ontonotes, batch 704 (11704): mcc: 0.6463, acc: 0.5381, precision: 0.7464, recall: 0.5676, f1: 0.6448, edges-srl-ontonotes_loss: 0.0248
09/07 09:40:02 PM: Update 11813: task edges-srl-ontonotes, batch 813 (11813): mcc: 0.6470, acc: 0.5393, precision: 0.7463, recall: 0.5688, f1: 0.6456, edges-srl-ontonotes_loss: 0.0247
09/07 09:40:12 PM: Update 11921: task edges-srl-ontonotes, batch 921 (11921): mcc: 0.6485, acc: 0.5416, precision: 0.7473, recall: 0.5707, f1: 0.6472, edges-srl-ontonotes_loss: 0.0246
09/07 09:40:21 PM: ***** Step 12000 / Validation 12 *****
09/07 09:40:21 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:40:21 PM: Validating...
09/07 09:40:22 PM: Evaluate: task edges-srl-ontonotes, batch 9 (157): mcc: 0.6640, acc: 0.5482, precision: 0.8141, recall: 0.5482, f1: 0.6552, edges-srl-ontonotes_loss: 0.0234
09/07 09:40:32 PM: Evaluate: task edges-srl-ontonotes, batch 117 (157): mcc: 0.6809, acc: 0.5818, precision: 0.8043, recall: 0.5831, f1: 0.6761, edges-srl-ontonotes_loss: 0.0232
09/07 09:40:36 PM: Updating LR scheduler:
09/07 09:40:36 PM: 	Best result seen so far for macro_avg: 0.703
09/07 09:40:36 PM: 	# validation passes without improvement: 3
09/07 09:40:36 PM: edges-srl-ontonotes_loss: training: 0.024783 validation: 0.023337
09/07 09:40:36 PM: macro_avg: validation: 0.673435
09/07 09:40:36 PM: micro_avg: validation: 0.000000
09/07 09:40:36 PM: edges-srl-ontonotes_mcc: training: 0.646318 validation: 0.678428
09/07 09:40:36 PM: edges-srl-ontonotes_acc: training: 0.538606 validation: 0.578246
09/07 09:40:36 PM: edges-srl-ontonotes_precision: training: 0.746450 validation: 0.803608
09/07 09:40:36 PM: edges-srl-ontonotes_recall: training: 0.567597 validation: 0.579555
09/07 09:40:36 PM: edges-srl-ontonotes_f1: training: 0.644852 validation: 0.673435
09/07 09:40:36 PM: Global learning rate: 0.0001
09/07 09:40:36 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 09:40:42 PM: Update 12060: task edges-srl-ontonotes, batch 60 (12060): mcc: 0.6122, acc: 0.4979, precision: 0.7288, recall: 0.5224, f1: 0.6086, edges-srl-ontonotes_loss: 0.0268
09/07 09:40:52 PM: Update 12157: task edges-srl-ontonotes, batch 157 (12157): mcc: 0.6198, acc: 0.5027, precision: 0.7355, recall: 0.5305, f1: 0.6164, edges-srl-ontonotes_loss: 0.0262
09/07 09:41:02 PM: Update 12254: task edges-srl-ontonotes, batch 254 (12254): mcc: 0.6283, acc: 0.5149, precision: 0.7392, recall: 0.5421, f1: 0.6255, edges-srl-ontonotes_loss: 0.0259
09/07 09:41:13 PM: Update 12334: task edges-srl-ontonotes, batch 334 (12334): mcc: 0.6409, acc: 0.5297, precision: 0.7481, recall: 0.5570, f1: 0.6386, edges-srl-ontonotes_loss: 0.0251
09/07 09:41:23 PM: Update 12458: task edges-srl-ontonotes, batch 458 (12458): mcc: 0.6626, acc: 0.5548, precision: 0.7642, recall: 0.5822, f1: 0.6609, edges-srl-ontonotes_loss: 0.0239
09/07 09:41:33 PM: Update 12568: task edges-srl-ontonotes, batch 568 (12568): mcc: 0.6750, acc: 0.5697, precision: 0.7723, recall: 0.5974, f1: 0.6737, edges-srl-ontonotes_loss: 0.0233
09/07 09:41:43 PM: Update 12702: task edges-srl-ontonotes, batch 702 (12702): mcc: 0.6960, acc: 0.5951, precision: 0.7871, recall: 0.6227, f1: 0.6953, edges-srl-ontonotes_loss: 0.0221
09/07 09:41:53 PM: Update 12836: task edges-srl-ontonotes, batch 836 (12836): mcc: 0.7115, acc: 0.6140, precision: 0.7974, recall: 0.6418, f1: 0.7112, edges-srl-ontonotes_loss: 0.0212
09/07 09:42:03 PM: Update 12953: task edges-srl-ontonotes, batch 953 (12953): mcc: 0.7200, acc: 0.6249, precision: 0.8031, recall: 0.6523, f1: 0.7199, edges-srl-ontonotes_loss: 0.0207
09/07 09:42:07 PM: ***** Step 13000 / Validation 13 *****
09/07 09:42:07 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:42:07 PM: Validating...
09/07 09:42:13 PM: Evaluate: task edges-srl-ontonotes, batch 71 (157): mcc: 0.6971, acc: 0.5989, precision: 0.8162, recall: 0.6019, f1: 0.6929, edges-srl-ontonotes_loss: 0.0229
09/07 09:42:21 PM: Updating LR scheduler:
09/07 09:42:21 PM: 	Best result seen so far for macro_avg: 0.703
09/07 09:42:21 PM: 	# validation passes without improvement: 4
09/07 09:42:21 PM: edges-srl-ontonotes_loss: training: 0.020537 validation: 0.022561
09/07 09:42:21 PM: macro_avg: validation: 0.695103
09/07 09:42:21 PM: micro_avg: validation: 0.000000
09/07 09:42:21 PM: edges-srl-ontonotes_mcc: training: 0.723157 validation: 0.698934
09/07 09:42:21 PM: edges-srl-ontonotes_acc: training: 0.629051 validation: 0.602571
09/07 09:42:21 PM: edges-srl-ontonotes_precision: training: 0.805031 validation: 0.815141
09/07 09:42:21 PM: edges-srl-ontonotes_recall: training: 0.656337 validation: 0.605881
09/07 09:42:21 PM: edges-srl-ontonotes_f1: training: 0.723119 validation: 0.695103
09/07 09:42:21 PM: Global learning rate: 0.0001
09/07 09:42:21 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 09:42:23 PM: Update 13025: task edges-srl-ontonotes, batch 25 (13025): mcc: 0.7604, acc: 0.6778, precision: 0.8309, recall: 0.7020, f1: 0.7610, edges-srl-ontonotes_loss: 0.0181
09/07 09:42:33 PM: Update 13155: task edges-srl-ontonotes, batch 155 (13155): mcc: 0.7730, acc: 0.6946, precision: 0.8323, recall: 0.7239, f1: 0.7743, edges-srl-ontonotes_loss: 0.0172
09/07 09:42:43 PM: Update 13272: task edges-srl-ontonotes, batch 272 (13272): mcc: 0.7786, acc: 0.7010, precision: 0.8370, recall: 0.7301, f1: 0.7799, edges-srl-ontonotes_loss: 0.0170
09/07 09:42:53 PM: Update 13404: task edges-srl-ontonotes, batch 404 (13404): mcc: 0.7846, acc: 0.7095, precision: 0.8406, recall: 0.7380, f1: 0.7859, edges-srl-ontonotes_loss: 0.0167
09/07 09:43:04 PM: Update 13507: task edges-srl-ontonotes, batch 507 (13507): mcc: 0.7861, acc: 0.7115, precision: 0.8413, recall: 0.7401, f1: 0.7875, edges-srl-ontonotes_loss: 0.0166
09/07 09:43:14 PM: Update 13637: task edges-srl-ontonotes, batch 637 (13637): mcc: 0.7919, acc: 0.7202, precision: 0.8467, recall: 0.7462, f1: 0.7933, edges-srl-ontonotes_loss: 0.0164
09/07 09:43:24 PM: Update 13770: task edges-srl-ontonotes, batch 770 (13770): mcc: 0.7960, acc: 0.7263, precision: 0.8499, recall: 0.7509, f1: 0.7974, edges-srl-ontonotes_loss: 0.0162
09/07 09:43:34 PM: Update 13875: task edges-srl-ontonotes, batch 875 (13875): mcc: 0.7915, acc: 0.7209, precision: 0.8466, recall: 0.7455, f1: 0.7928, edges-srl-ontonotes_loss: 0.0165
09/07 09:43:44 PM: Update 13986: task edges-srl-ontonotes, batch 986 (13986): mcc: 0.7805, acc: 0.7071, precision: 0.8387, recall: 0.7322, f1: 0.7818, edges-srl-ontonotes_loss: 0.0172
09/07 09:43:45 PM: ***** Step 14000 / Validation 14 *****
09/07 09:43:45 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:43:45 PM: Validating...
09/07 09:43:54 PM: Evaluate: task edges-srl-ontonotes, batch 96 (157): mcc: 0.7149, acc: 0.6268, precision: 0.8208, recall: 0.6290, f1: 0.7122, edges-srl-ontonotes_loss: 0.0212
09/07 09:44:00 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:44:00 PM: Best result seen so far for macro.
09/07 09:44:00 PM: Updating LR scheduler:
09/07 09:44:00 PM: 	Best result seen so far for macro_avg: 0.706
09/07 09:44:00 PM: 	# validation passes without improvement: 0
09/07 09:44:00 PM: edges-srl-ontonotes_loss: training: 0.017250 validation: 0.021490
09/07 09:44:00 PM: macro_avg: validation: 0.706278
09/07 09:44:00 PM: micro_avg: validation: 0.000000
09/07 09:44:00 PM: edges-srl-ontonotes_mcc: training: 0.779504 validation: 0.708968
09/07 09:44:00 PM: edges-srl-ontonotes_acc: training: 0.705888 validation: 0.620660
09/07 09:44:00 PM: edges-srl-ontonotes_precision: training: 0.837888 validation: 0.815835
09/07 09:44:00 PM: edges-srl-ontonotes_recall: training: 0.730957 validation: 0.622662
09/07 09:44:00 PM: edges-srl-ontonotes_f1: training: 0.780778 validation: 0.706278
09/07 09:44:00 PM: Global learning rate: 0.0001
09/07 09:44:00 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 09:44:04 PM: Update 14050: task edges-srl-ontonotes, batch 50 (14050): mcc: 0.7168, acc: 0.6247, precision: 0.7868, recall: 0.6601, f1: 0.7179, edges-srl-ontonotes_loss: 0.0207
09/07 09:44:14 PM: Update 14144: task edges-srl-ontonotes, batch 144 (14144): mcc: 0.7079, acc: 0.6157, precision: 0.7814, recall: 0.6486, f1: 0.7088, edges-srl-ontonotes_loss: 0.0215
09/07 09:44:24 PM: Update 14252: task edges-srl-ontonotes, batch 252 (14252): mcc: 0.6864, acc: 0.5889, precision: 0.7692, recall: 0.6201, f1: 0.6866, edges-srl-ontonotes_loss: 0.0227
09/07 09:44:34 PM: Update 14365: task edges-srl-ontonotes, batch 365 (14365): mcc: 0.6784, acc: 0.5797, precision: 0.7640, recall: 0.6101, f1: 0.6784, edges-srl-ontonotes_loss: 0.0232
09/07 09:44:44 PM: Update 14474: task edges-srl-ontonotes, batch 474 (14474): mcc: 0.6757, acc: 0.5756, precision: 0.7638, recall: 0.6054, f1: 0.6755, edges-srl-ontonotes_loss: 0.0234
09/07 09:44:55 PM: Update 14564: task edges-srl-ontonotes, batch 564 (14564): mcc: 0.6820, acc: 0.5835, precision: 0.7695, recall: 0.6121, f1: 0.6818, edges-srl-ontonotes_loss: 0.0230
09/07 09:45:05 PM: Update 14684: task edges-srl-ontonotes, batch 684 (14684): mcc: 0.6915, acc: 0.5948, precision: 0.7774, recall: 0.6224, f1: 0.6914, edges-srl-ontonotes_loss: 0.0225
09/07 09:45:15 PM: Update 14802: task edges-srl-ontonotes, batch 802 (14802): mcc: 0.6955, acc: 0.5994, precision: 0.7806, recall: 0.6270, f1: 0.6954, edges-srl-ontonotes_loss: 0.0222
09/07 09:45:25 PM: Update 14907: task edges-srl-ontonotes, batch 907 (14907): mcc: 0.6996, acc: 0.6042, precision: 0.7841, recall: 0.6314, f1: 0.6995, edges-srl-ontonotes_loss: 0.0220
09/07 09:45:33 PM: ***** Step 15000 / Validation 15 *****
09/07 09:45:33 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:45:33 PM: Validating...
09/07 09:45:35 PM: Evaluate: task edges-srl-ontonotes, batch 24 (157): mcc: 0.7202, acc: 0.6141, precision: 0.8495, recall: 0.6166, f1: 0.7145, edges-srl-ontonotes_loss: 0.0205
09/07 09:45:45 PM: Evaluate: task edges-srl-ontonotes, batch 132 (157): mcc: 0.7357, acc: 0.6454, precision: 0.8442, recall: 0.6471, f1: 0.7326, edges-srl-ontonotes_loss: 0.0194
09/07 09:45:47 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:45:47 PM: Best result seen so far for macro.
09/07 09:45:47 PM: Updating LR scheduler:
09/07 09:45:47 PM: 	Best result seen so far for macro_avg: 0.720
09/07 09:45:47 PM: 	# validation passes without improvement: 0
09/07 09:45:47 PM: edges-srl-ontonotes_loss: training: 0.021711 validation: 0.020223
09/07 09:45:47 PM: macro_avg: validation: 0.719645
09/07 09:45:47 PM: micro_avg: validation: 0.000000
09/07 09:45:47 PM: edges-srl-ontonotes_mcc: training: 0.703348 validation: 0.723270
09/07 09:45:47 PM: edges-srl-ontonotes_acc: training: 0.609057 validation: 0.629513
09/07 09:45:47 PM: edges-srl-ontonotes_precision: training: 0.786735 validation: 0.836905
09/07 09:45:47 PM: edges-srl-ontonotes_recall: training: 0.635946 validation: 0.631206
09/07 09:45:47 PM: edges-srl-ontonotes_f1: training: 0.703350 validation: 0.719645
09/07 09:45:47 PM: Global learning rate: 0.0001
09/07 09:45:47 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 09:45:55 PM: Update 15090: task edges-srl-ontonotes, batch 90 (15090): mcc: 0.7402, acc: 0.6565, precision: 0.8117, recall: 0.6815, f1: 0.7409, edges-srl-ontonotes_loss: 0.0195
09/07 09:46:05 PM: Update 15193: task edges-srl-ontonotes, batch 193 (15193): mcc: 0.7189, acc: 0.6289, precision: 0.7966, recall: 0.6556, f1: 0.7193, edges-srl-ontonotes_loss: 0.0209
09/07 09:46:15 PM: Update 15310: task edges-srl-ontonotes, batch 310 (15310): mcc: 0.7053, acc: 0.6127, precision: 0.7858, recall: 0.6402, f1: 0.7056, edges-srl-ontonotes_loss: 0.0216
09/07 09:46:25 PM: Update 15427: task edges-srl-ontonotes, batch 427 (15427): mcc: 0.7004, acc: 0.6060, precision: 0.7833, recall: 0.6335, f1: 0.7005, edges-srl-ontonotes_loss: 0.0219
09/07 09:46:35 PM: Update 15504: task edges-srl-ontonotes, batch 504 (15504): mcc: 0.6958, acc: 0.5998, precision: 0.7798, recall: 0.6281, f1: 0.6958, edges-srl-ontonotes_loss: 0.0222
09/07 09:46:45 PM: Update 15615: task edges-srl-ontonotes, batch 615 (15615): mcc: 0.6876, acc: 0.5899, precision: 0.7739, recall: 0.6183, f1: 0.6874, edges-srl-ontonotes_loss: 0.0227
09/07 09:46:55 PM: Update 15733: task edges-srl-ontonotes, batch 733 (15733): mcc: 0.6854, acc: 0.5872, precision: 0.7725, recall: 0.6155, f1: 0.6851, edges-srl-ontonotes_loss: 0.0228
09/07 09:47:05 PM: Update 15832: task edges-srl-ontonotes, batch 832 (15832): mcc: 0.6821, acc: 0.5829, precision: 0.7701, recall: 0.6117, f1: 0.6818, edges-srl-ontonotes_loss: 0.0230
09/07 09:47:15 PM: Update 15944: task edges-srl-ontonotes, batch 944 (15944): mcc: 0.6791, acc: 0.5792, precision: 0.7676, recall: 0.6083, f1: 0.6787, edges-srl-ontonotes_loss: 0.0231
09/07 09:47:20 PM: ***** Step 16000 / Validation 16 *****
09/07 09:47:20 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:47:20 PM: Validating...
09/07 09:47:25 PM: Evaluate: task edges-srl-ontonotes, batch 54 (157): mcc: 0.7203, acc: 0.6271, precision: 0.8324, recall: 0.6295, f1: 0.7169, edges-srl-ontonotes_loss: 0.0210
09/07 09:47:35 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:47:35 PM: Best result seen so far for macro.
09/07 09:47:35 PM: Updating LR scheduler:
09/07 09:47:35 PM: 	Best result seen so far for macro_avg: 0.727
09/07 09:47:35 PM: 	# validation passes without improvement: 0
09/07 09:47:35 PM: edges-srl-ontonotes_loss: training: 0.023096 validation: 0.020081
09/07 09:47:35 PM: macro_avg: validation: 0.727249
09/07 09:47:35 PM: micro_avg: validation: 0.000000
09/07 09:47:35 PM: edges-srl-ontonotes_mcc: training: 0.678170 validation: 0.730105
09/07 09:47:35 PM: edges-srl-ontonotes_acc: training: 0.578095 validation: 0.641367
09/07 09:47:35 PM: edges-srl-ontonotes_precision: training: 0.766811 validation: 0.837193
09/07 09:47:35 PM: edges-srl-ontonotes_recall: training: 0.607365 validation: 0.642830
09/07 09:47:35 PM: edges-srl-ontonotes_f1: training: 0.677838 validation: 0.727249
09/07 09:47:35 PM: Global learning rate: 0.0001
09/07 09:47:35 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 09:47:35 PM: Update 16002: task edges-srl-ontonotes, batch 2 (16002): mcc: 0.6944, acc: 0.5742, precision: 0.8214, recall: 0.5935, f1: 0.6891, edges-srl-ontonotes_loss: 0.0222
09/07 09:47:45 PM: Update 16100: task edges-srl-ontonotes, batch 100 (16100): mcc: 0.6600, acc: 0.5584, precision: 0.7510, recall: 0.5878, f1: 0.6595, edges-srl-ontonotes_loss: 0.0239
09/07 09:47:55 PM: Update 16206: task edges-srl-ontonotes, batch 206 (16206): mcc: 0.6371, acc: 0.5293, precision: 0.7356, recall: 0.5600, f1: 0.6359, edges-srl-ontonotes_loss: 0.0253
09/07 09:48:05 PM: Update 16313: task edges-srl-ontonotes, batch 313 (16313): mcc: 0.6366, acc: 0.5283, precision: 0.7376, recall: 0.5576, f1: 0.6351, edges-srl-ontonotes_loss: 0.0253
09/07 09:48:15 PM: Update 16387: task edges-srl-ontonotes, batch 387 (16387): mcc: 0.6350, acc: 0.5263, precision: 0.7374, recall: 0.5551, f1: 0.6334, edges-srl-ontonotes_loss: 0.0255
09/07 09:48:25 PM: Update 16499: task edges-srl-ontonotes, batch 499 (16499): mcc: 0.6357, acc: 0.5263, precision: 0.7390, recall: 0.5549, f1: 0.6339, edges-srl-ontonotes_loss: 0.0255
09/07 09:48:36 PM: Update 16609: task edges-srl-ontonotes, batch 609 (16609): mcc: 0.6359, acc: 0.5257, precision: 0.7409, recall: 0.5538, f1: 0.6338, edges-srl-ontonotes_loss: 0.0255
09/07 09:48:46 PM: Update 16700: task edges-srl-ontonotes, batch 700 (16700): mcc: 0.6351, acc: 0.5249, precision: 0.7395, recall: 0.5535, f1: 0.6331, edges-srl-ontonotes_loss: 0.0255
09/07 09:48:56 PM: Update 16801: task edges-srl-ontonotes, batch 801 (16801): mcc: 0.6381, acc: 0.5282, precision: 0.7413, recall: 0.5574, f1: 0.6363, edges-srl-ontonotes_loss: 0.0253
09/07 09:49:06 PM: Update 16907: task edges-srl-ontonotes, batch 907 (16907): mcc: 0.6388, acc: 0.5289, precision: 0.7409, recall: 0.5588, f1: 0.6371, edges-srl-ontonotes_loss: 0.0252
09/07 09:49:16 PM: Update 16998: task edges-srl-ontonotes, batch 998 (16998): mcc: 0.6392, acc: 0.5297, precision: 0.7402, recall: 0.5601, f1: 0.6377, edges-srl-ontonotes_loss: 0.0251
09/07 09:49:16 PM: ***** Step 17000 / Validation 17 *****
09/07 09:49:16 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:49:16 PM: Validating...
09/07 09:49:26 PM: Evaluate: task edges-srl-ontonotes, batch 105 (157): mcc: 0.7177, acc: 0.6237, precision: 0.8314, recall: 0.6259, f1: 0.7141, edges-srl-ontonotes_loss: 0.0208
09/07 09:49:31 PM: Updating LR scheduler:
09/07 09:49:31 PM: 	Best result seen so far for macro_avg: 0.727
09/07 09:49:31 PM: 	# validation passes without improvement: 1
09/07 09:49:31 PM: edges-srl-ontonotes_loss: training: 0.025111 validation: 0.020906
09/07 09:49:31 PM: macro_avg: validation: 0.710274
09/07 09:49:31 PM: micro_avg: validation: 0.000000
09/07 09:49:31 PM: edges-srl-ontonotes_mcc: training: 0.639191 validation: 0.714071
09/07 09:49:31 PM: edges-srl-ontonotes_acc: training: 0.529687 validation: 0.618967
09/07 09:49:31 PM: edges-srl-ontonotes_precision: training: 0.740160 validation: 0.829444
09/07 09:49:31 PM: edges-srl-ontonotes_recall: training: 0.560095 validation: 0.621045
09/07 09:49:31 PM: edges-srl-ontonotes_f1: training: 0.637659 validation: 0.710274
09/07 09:49:31 PM: Global learning rate: 0.0001
09/07 09:49:31 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 09:49:36 PM: Update 17055: task edges-srl-ontonotes, batch 55 (17055): mcc: 0.6492, acc: 0.5468, precision: 0.7365, recall: 0.5806, f1: 0.6493, edges-srl-ontonotes_loss: 0.0240
09/07 09:49:46 PM: Update 17162: task edges-srl-ontonotes, batch 162 (17162): mcc: 0.6601, acc: 0.5576, precision: 0.7495, recall: 0.5893, f1: 0.6598, edges-srl-ontonotes_loss: 0.0237
09/07 09:49:56 PM: Update 17269: task edges-srl-ontonotes, batch 269 (17269): mcc: 0.6584, acc: 0.5567, precision: 0.7475, recall: 0.5879, f1: 0.6582, edges-srl-ontonotes_loss: 0.0239
09/07 09:50:06 PM: Update 17364: task edges-srl-ontonotes, batch 364 (17364): mcc: 0.6605, acc: 0.5584, precision: 0.7497, recall: 0.5900, f1: 0.6603, edges-srl-ontonotes_loss: 0.0238
09/07 09:50:16 PM: Update 17474: task edges-srl-ontonotes, batch 474 (17474): mcc: 0.6652, acc: 0.5637, precision: 0.7545, recall: 0.5943, f1: 0.6649, edges-srl-ontonotes_loss: 0.0236
09/07 09:50:26 PM: Update 17577: task edges-srl-ontonotes, batch 577 (17577): mcc: 0.6675, acc: 0.5662, precision: 0.7569, recall: 0.5965, f1: 0.6672, edges-srl-ontonotes_loss: 0.0235
09/07 09:50:36 PM: Update 17652: task edges-srl-ontonotes, batch 652 (17652): mcc: 0.6672, acc: 0.5658, precision: 0.7569, recall: 0.5959, f1: 0.6668, edges-srl-ontonotes_loss: 0.0236
09/07 09:50:46 PM: Update 17763: task edges-srl-ontonotes, batch 763 (17763): mcc: 0.6659, acc: 0.5640, precision: 0.7561, recall: 0.5943, f1: 0.6655, edges-srl-ontonotes_loss: 0.0237
09/07 09:50:56 PM: Update 17871: task edges-srl-ontonotes, batch 871 (17871): mcc: 0.6645, acc: 0.5622, precision: 0.7553, recall: 0.5924, f1: 0.6640, edges-srl-ontonotes_loss: 0.0238
09/07 09:51:06 PM: Update 17965: task edges-srl-ontonotes, batch 965 (17965): mcc: 0.6628, acc: 0.5602, precision: 0.7543, recall: 0.5903, f1: 0.6623, edges-srl-ontonotes_loss: 0.0238
09/07 09:51:09 PM: ***** Step 18000 / Validation 18 *****
09/07 09:51:09 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:51:09 PM: Validating...
09/07 09:51:16 PM: Evaluate: task edges-srl-ontonotes, batch 75 (157): mcc: 0.7010, acc: 0.6052, precision: 0.8173, recall: 0.6079, f1: 0.6972, edges-srl-ontonotes_loss: 0.0217
09/07 09:51:24 PM: Updating LR scheduler:
09/07 09:51:24 PM: 	Best result seen so far for macro_avg: 0.727
09/07 09:51:24 PM: 	# validation passes without improvement: 2
09/07 09:51:24 PM: edges-srl-ontonotes_loss: training: 0.023839 validation: 0.021290
09/07 09:51:24 PM: macro_avg: validation: 0.701147
09/07 09:51:24 PM: micro_avg: validation: 0.000000
09/07 09:51:24 PM: edges-srl-ontonotes_mcc: training: 0.662626 validation: 0.705052
09/07 09:51:24 PM: edges-srl-ontonotes_acc: training: 0.559950 validation: 0.609422
09/07 09:51:24 PM: edges-srl-ontonotes_precision: training: 0.754278 validation: 0.821595
09/07 09:51:24 PM: edges-srl-ontonotes_recall: training: 0.589961 validation: 0.611500
09/07 09:51:24 PM: edges-srl-ontonotes_f1: training: 0.662076 validation: 0.701147
09/07 09:51:24 PM: Global learning rate: 0.0001
09/07 09:51:24 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 09:51:26 PM: Update 18023: task edges-srl-ontonotes, batch 23 (18023): mcc: 0.6328, acc: 0.5217, precision: 0.7375, recall: 0.5511, f1: 0.6308, edges-srl-ontonotes_loss: 0.0250
09/07 09:51:36 PM: Update 18129: task edges-srl-ontonotes, batch 129 (18129): mcc: 0.6541, acc: 0.5448, precision: 0.7545, recall: 0.5749, f1: 0.6526, edges-srl-ontonotes_loss: 0.0240
09/07 09:51:46 PM: Update 18237: task edges-srl-ontonotes, batch 237 (18237): mcc: 0.6582, acc: 0.5491, precision: 0.7583, recall: 0.5791, f1: 0.6567, edges-srl-ontonotes_loss: 0.0239
09/07 09:51:56 PM: Update 18339: task edges-srl-ontonotes, batch 339 (18339): mcc: 0.6570, acc: 0.5482, precision: 0.7566, recall: 0.5783, f1: 0.6555, edges-srl-ontonotes_loss: 0.0240
09/07 09:52:06 PM: Update 18447: task edges-srl-ontonotes, batch 447 (18447): mcc: 0.6550, acc: 0.5455, precision: 0.7548, recall: 0.5762, f1: 0.6535, edges-srl-ontonotes_loss: 0.0242
09/07 09:52:17 PM: Update 18554: task edges-srl-ontonotes, batch 554 (18554): mcc: 0.6571, acc: 0.5481, precision: 0.7560, recall: 0.5790, f1: 0.6558, edges-srl-ontonotes_loss: 0.0241
09/07 09:52:27 PM: Update 18631: task edges-srl-ontonotes, batch 631 (18631): mcc: 0.6591, acc: 0.5504, precision: 0.7574, recall: 0.5813, f1: 0.6578, edges-srl-ontonotes_loss: 0.0240
09/07 09:52:37 PM: Update 18741: task edges-srl-ontonotes, batch 741 (18741): mcc: 0.6594, acc: 0.5515, precision: 0.7564, recall: 0.5826, f1: 0.6583, edges-srl-ontonotes_loss: 0.0240
09/07 09:52:47 PM: Update 18850: task edges-srl-ontonotes, batch 850 (18850): mcc: 0.6608, acc: 0.5538, precision: 0.7567, recall: 0.5848, f1: 0.6598, edges-srl-ontonotes_loss: 0.0239
09/07 09:52:57 PM: Update 18944: task edges-srl-ontonotes, batch 944 (18944): mcc: 0.6612, acc: 0.5546, precision: 0.7571, recall: 0.5852, f1: 0.6601, edges-srl-ontonotes_loss: 0.0239
09/07 09:53:02 PM: ***** Step 19000 / Validation 19 *****
09/07 09:53:02 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:53:02 PM: Validating...
09/07 09:53:07 PM: Evaluate: task edges-srl-ontonotes, batch 54 (157): mcc: 0.6996, acc: 0.6050, precision: 0.8146, recall: 0.6074, f1: 0.6959, edges-srl-ontonotes_loss: 0.0222
09/07 09:53:17 PM: Updating LR scheduler:
09/07 09:53:17 PM: 	Best result seen so far for macro_avg: 0.727
09/07 09:53:17 PM: 	# validation passes without improvement: 3
09/07 09:53:17 PM: edges-srl-ontonotes_loss: training: 0.023851 validation: 0.021529
09/07 09:53:17 PM: macro_avg: validation: 0.703150
09/07 09:53:17 PM: micro_avg: validation: 0.000000
09/07 09:53:17 PM: edges-srl-ontonotes_mcc: training: 0.661767 validation: 0.706203
09/07 09:53:17 PM: edges-srl-ontonotes_acc: training: 0.555382 validation: 0.616196
09/07 09:53:17 PM: edges-srl-ontonotes_precision: training: 0.757490 validation: 0.816111
09/07 09:53:17 PM: edges-srl-ontonotes_recall: training: 0.585913 validation: 0.617658
09/07 09:53:17 PM: edges-srl-ontonotes_f1: training: 0.660745 validation: 0.703150
09/07 09:53:17 PM: Global learning rate: 0.0001
09/07 09:53:17 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 09:53:17 PM: Update 19003: task edges-srl-ontonotes, batch 3 (19003): mcc: 0.7141, acc: 0.6104, precision: 0.7874, recall: 0.6546, f1: 0.7149, edges-srl-ontonotes_loss: 0.0216
09/07 09:53:27 PM: Update 19113: task edges-srl-ontonotes, batch 113 (19113): mcc: 0.6688, acc: 0.5674, precision: 0.7566, recall: 0.5989, f1: 0.6686, edges-srl-ontonotes_loss: 0.0233
09/07 09:53:37 PM: Update 19206: task edges-srl-ontonotes, batch 206 (19206): mcc: 0.6640, acc: 0.5609, precision: 0.7541, recall: 0.5925, f1: 0.6636, edges-srl-ontonotes_loss: 0.0236
09/07 09:53:47 PM: Update 19301: task edges-srl-ontonotes, batch 301 (19301): mcc: 0.6527, acc: 0.5465, precision: 0.7484, recall: 0.5772, f1: 0.6518, edges-srl-ontonotes_loss: 0.0243
09/07 09:53:57 PM: Update 19395: task edges-srl-ontonotes, batch 395 (19395): mcc: 0.6503, acc: 0.5424, precision: 0.7493, recall: 0.5723, f1: 0.6490, edges-srl-ontonotes_loss: 0.0246
09/07 09:54:07 PM: Update 19491: task edges-srl-ontonotes, batch 491 (19491): mcc: 0.6518, acc: 0.5437, precision: 0.7522, recall: 0.5727, f1: 0.6503, edges-srl-ontonotes_loss: 0.0245
09/07 09:54:17 PM: Update 19568: task edges-srl-ontonotes, batch 568 (19568): mcc: 0.6594, acc: 0.5526, precision: 0.7581, recall: 0.5813, f1: 0.6580, edges-srl-ontonotes_loss: 0.0241
09/07 09:54:27 PM: Update 19685: task edges-srl-ontonotes, batch 685 (19685): mcc: 0.6709, acc: 0.5659, precision: 0.7668, recall: 0.5946, f1: 0.6698, edges-srl-ontonotes_loss: 0.0234
09/07 09:54:37 PM: Update 19807: task edges-srl-ontonotes, batch 807 (19807): mcc: 0.6819, acc: 0.5791, precision: 0.7748, recall: 0.6075, f1: 0.6811, edges-srl-ontonotes_loss: 0.0228
09/07 09:54:47 PM: Update 19922: task edges-srl-ontonotes, batch 922 (19922): mcc: 0.6952, acc: 0.5951, precision: 0.7841, recall: 0.6236, f1: 0.6947, edges-srl-ontonotes_loss: 0.0221
09/07 09:54:53 PM: ***** Step 20000 / Validation 20 *****
09/07 09:54:53 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:54:53 PM: Validating...
09/07 09:54:57 PM: Evaluate: task edges-srl-ontonotes, batch 44 (157): mcc: 0.7080, acc: 0.6167, precision: 0.8177, recall: 0.6196, f1: 0.7050, edges-srl-ontonotes_loss: 0.0222
09/07 09:55:07 PM: Evaluate: task edges-srl-ontonotes, batch 152 (157): mcc: 0.7125, acc: 0.6239, precision: 0.8183, recall: 0.6268, f1: 0.7099, edges-srl-ontonotes_loss: 0.0213
09/07 09:55:08 PM: Updating LR scheduler:
09/07 09:55:08 PM: 	Best result seen so far for macro_avg: 0.727
09/07 09:55:08 PM: 	# validation passes without improvement: 4
09/07 09:55:08 PM: edges-srl-ontonotes_loss: training: 0.021587 validation: 0.021361
09/07 09:55:08 PM: macro_avg: validation: 0.710383
09/07 09:55:08 PM: micro_avg: validation: 0.000000
09/07 09:55:08 PM: edges-srl-ontonotes_mcc: training: 0.703993 validation: 0.712936
09/07 09:55:08 PM: edges-srl-ontonotes_acc: training: 0.605898 validation: 0.624663
09/07 09:55:08 PM: edges-srl-ontonotes_precision: training: 0.790510 validation: 0.818474
09/07 09:55:08 PM: edges-srl-ontonotes_recall: training: 0.634013 validation: 0.627511
09/07 09:55:08 PM: edges-srl-ontonotes_f1: training: 0.703665 validation: 0.710383
09/07 09:55:08 PM: Global learning rate: 0.0001
09/07 09:55:08 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 09:55:18 PM: Update 20125: task edges-srl-ontonotes, batch 125 (20125): mcc: 0.8004, acc: 0.7266, precision: 0.8538, recall: 0.7557, f1: 0.8017, edges-srl-ontonotes_loss: 0.0156
09/07 09:55:28 PM: Update 20239: task edges-srl-ontonotes, batch 239 (20239): mcc: 0.7927, acc: 0.7189, precision: 0.8483, recall: 0.7463, f1: 0.7940, edges-srl-ontonotes_loss: 0.0161
09/07 09:55:38 PM: Update 20364: task edges-srl-ontonotes, batch 364 (20364): mcc: 0.7904, acc: 0.7163, precision: 0.8455, recall: 0.7445, f1: 0.7918, edges-srl-ontonotes_loss: 0.0161
09/07 09:55:48 PM: Update 20478: task edges-srl-ontonotes, batch 478 (20478): mcc: 0.7913, acc: 0.7174, precision: 0.8458, recall: 0.7459, f1: 0.7927, edges-srl-ontonotes_loss: 0.0161
09/07 09:55:58 PM: Update 20611: task edges-srl-ontonotes, batch 611 (20611): mcc: 0.7926, acc: 0.7199, precision: 0.8463, recall: 0.7479, f1: 0.7941, edges-srl-ontonotes_loss: 0.0160
09/07 09:56:08 PM: Update 20739: task edges-srl-ontonotes, batch 739 (20739): mcc: 0.7954, acc: 0.7237, precision: 0.8485, recall: 0.7511, f1: 0.7968, edges-srl-ontonotes_loss: 0.0159
09/07 09:56:18 PM: Update 20833: task edges-srl-ontonotes, batch 833 (20833): mcc: 0.7974, acc: 0.7270, precision: 0.8498, recall: 0.7536, f1: 0.7988, edges-srl-ontonotes_loss: 0.0158
09/07 09:56:28 PM: Update 20963: task edges-srl-ontonotes, batch 963 (20963): mcc: 0.8000, acc: 0.7311, precision: 0.8520, recall: 0.7566, f1: 0.8015, edges-srl-ontonotes_loss: 0.0157
09/07 09:56:31 PM: ***** Step 21000 / Validation 21 *****
09/07 09:56:31 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:56:31 PM: Validating...
09/07 09:56:38 PM: Evaluate: task edges-srl-ontonotes, batch 79 (157): mcc: 0.7235, acc: 0.6331, precision: 0.8302, recall: 0.6368, f1: 0.7208, edges-srl-ontonotes_loss: 0.0211
09/07 09:56:45 PM: Updating LR scheduler:
09/07 09:56:45 PM: 	Best result seen so far for macro_avg: 0.727
09/07 09:56:45 PM: 	# validation passes without improvement: 5
09/07 09:56:45 PM: edges-srl-ontonotes_loss: training: 0.015623 validation: 0.020892
09/07 09:56:45 PM: macro_avg: validation: 0.718657
09/07 09:56:45 PM: micro_avg: validation: 0.000000
09/07 09:56:45 PM: edges-srl-ontonotes_mcc: training: 0.801019 validation: 0.721454
09/07 09:56:45 PM: edges-srl-ontonotes_acc: training: 0.732538 validation: 0.631514
09/07 09:56:45 PM: edges-srl-ontonotes_precision: training: 0.852740 validation: 0.828525
09/07 09:56:45 PM: edges-srl-ontonotes_recall: training: 0.757745 validation: 0.634516
09/07 09:56:45 PM: edges-srl-ontonotes_f1: training: 0.802441 validation: 0.718657
09/07 09:56:45 PM: Global learning rate: 0.0001
09/07 09:56:45 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 09:56:48 PM: Update 21036: task edges-srl-ontonotes, batch 36 (21036): mcc: 0.8278, acc: 0.7698, precision: 0.8738, recall: 0.7889, f1: 0.8292, edges-srl-ontonotes_loss: 0.0145
09/07 09:56:58 PM: Update 21138: task edges-srl-ontonotes, batch 138 (21138): mcc: 0.7782, acc: 0.7055, precision: 0.8379, recall: 0.7285, f1: 0.7794, edges-srl-ontonotes_loss: 0.0175
09/07 09:57:08 PM: Update 21253: task edges-srl-ontonotes, batch 253 (21253): mcc: 0.7488, acc: 0.6686, precision: 0.8153, recall: 0.6942, f1: 0.7499, edges-srl-ontonotes_loss: 0.0191
09/07 09:57:18 PM: Update 21358: task edges-srl-ontonotes, batch 358 (21358): mcc: 0.7345, acc: 0.6510, precision: 0.8036, recall: 0.6780, f1: 0.7355, edges-srl-ontonotes_loss: 0.0198
09/07 09:57:28 PM: Update 21448: task edges-srl-ontonotes, batch 448 (21448): mcc: 0.7226, acc: 0.6368, precision: 0.7943, recall: 0.6644, f1: 0.7235, edges-srl-ontonotes_loss: 0.0206
09/07 09:57:38 PM: Update 21556: task edges-srl-ontonotes, batch 556 (21556): mcc: 0.7122, acc: 0.6237, precision: 0.7874, recall: 0.6514, f1: 0.7130, edges-srl-ontonotes_loss: 0.0211
09/07 09:57:48 PM: Update 21666: task edges-srl-ontonotes, batch 666 (21666): mcc: 0.7065, acc: 0.6162, precision: 0.7837, recall: 0.6441, f1: 0.7070, edges-srl-ontonotes_loss: 0.0215
09/07 09:57:58 PM: Update 21743: task edges-srl-ontonotes, batch 743 (21743): mcc: 0.7044, acc: 0.6129, precision: 0.7837, recall: 0.6403, f1: 0.7048, edges-srl-ontonotes_loss: 0.0216
09/07 09:58:08 PM: Update 21861: task edges-srl-ontonotes, batch 861 (21861): mcc: 0.7076, acc: 0.6171, precision: 0.7864, recall: 0.6439, f1: 0.7081, edges-srl-ontonotes_loss: 0.0214
09/07 09:58:18 PM: Update 21980: task edges-srl-ontonotes, batch 980 (21980): mcc: 0.7119, acc: 0.6218, precision: 0.7902, recall: 0.6485, f1: 0.7124, edges-srl-ontonotes_loss: 0.0212
09/07 09:58:20 PM: ***** Step 22000 / Validation 22 *****
09/07 09:58:20 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:58:20 PM: Validating...
09/07 09:58:28 PM: Evaluate: task edges-srl-ontonotes, batch 89 (157): mcc: 0.7360, acc: 0.6413, precision: 0.8473, recall: 0.6452, f1: 0.7326, edges-srl-ontonotes_loss: 0.0194
09/07 09:58:35 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:58:35 PM: Best result seen so far for macro.
09/07 09:58:35 PM: Updating LR scheduler:
09/07 09:58:35 PM: 	Best result seen so far for macro_avg: 0.728
09/07 09:58:35 PM: 	# validation passes without improvement: 0
09/07 09:58:35 PM: edges-srl-ontonotes_loss: training: 0.021143 validation: 0.019611
09/07 09:58:35 PM: macro_avg: validation: 0.727855
09/07 09:58:35 PM: micro_avg: validation: 0.000000
09/07 09:58:35 PM: edges-srl-ontonotes_mcc: training: 0.712083 validation: 0.731712
09/07 09:58:35 PM: edges-srl-ontonotes_acc: training: 0.621833 validation: 0.634747
09/07 09:58:35 PM: edges-srl-ontonotes_precision: training: 0.790424 validation: 0.846798
09/07 09:58:35 PM: edges-srl-ontonotes_recall: training: 0.648558 validation: 0.638211
09/07 09:58:35 PM: edges-srl-ontonotes_f1: training: 0.712498 validation: 0.727855
09/07 09:58:35 PM: Global learning rate: 0.0001
09/07 09:58:35 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 09:58:38 PM: Update 22041: task edges-srl-ontonotes, batch 41 (22041): mcc: 0.7268, acc: 0.6340, precision: 0.8063, recall: 0.6619, f1: 0.7270, edges-srl-ontonotes_loss: 0.0201
09/07 09:58:48 PM: Update 22147: task edges-srl-ontonotes, batch 147 (22147): mcc: 0.7397, acc: 0.6548, precision: 0.8133, recall: 0.6792, f1: 0.7402, edges-srl-ontonotes_loss: 0.0194
09/07 09:58:58 PM: Update 22264: task edges-srl-ontonotes, batch 264 (22264): mcc: 0.7443, acc: 0.6592, precision: 0.8167, recall: 0.6846, f1: 0.7449, edges-srl-ontonotes_loss: 0.0189
09/07 09:59:08 PM: Update 22367: task edges-srl-ontonotes, batch 367 (22367): mcc: 0.7456, acc: 0.6609, precision: 0.8173, recall: 0.6865, f1: 0.7462, edges-srl-ontonotes_loss: 0.0189
09/07 09:59:18 PM: Update 22486: task edges-srl-ontonotes, batch 486 (22486): mcc: 0.7323, acc: 0.6446, precision: 0.8074, recall: 0.6708, f1: 0.7328, edges-srl-ontonotes_loss: 0.0198
09/07 09:59:28 PM: Update 22600: task edges-srl-ontonotes, batch 600 (22600): mcc: 0.7251, acc: 0.6366, precision: 0.8012, recall: 0.6630, f1: 0.7256, edges-srl-ontonotes_loss: 0.0203
09/07 09:59:38 PM: Update 22682: task edges-srl-ontonotes, batch 682 (22682): mcc: 0.7228, acc: 0.6333, precision: 0.7993, recall: 0.6605, f1: 0.7233, edges-srl-ontonotes_loss: 0.0204
09/07 09:59:48 PM: Update 22795: task edges-srl-ontonotes, batch 795 (22795): mcc: 0.7153, acc: 0.6237, precision: 0.7940, recall: 0.6513, f1: 0.7156, edges-srl-ontonotes_loss: 0.0209
09/07 09:59:58 PM: Update 22911: task edges-srl-ontonotes, batch 911 (22911): mcc: 0.7099, acc: 0.6169, precision: 0.7901, recall: 0.6448, f1: 0.7101, edges-srl-ontonotes_loss: 0.0212
09/07 10:00:07 PM: ***** Step 23000 / Validation 23 *****
09/07 10:00:07 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:00:07 PM: Validating...
09/07 10:00:08 PM: Evaluate: task edges-srl-ontonotes, batch 11 (157): mcc: 0.7279, acc: 0.6264, precision: 0.8484, recall: 0.6305, f1: 0.7234, edges-srl-ontonotes_loss: 0.0198
09/07 10:00:18 PM: Evaluate: task edges-srl-ontonotes, batch 119 (157): mcc: 0.7512, acc: 0.6674, precision: 0.8496, recall: 0.6700, f1: 0.7492, edges-srl-ontonotes_loss: 0.0187
09/07 10:00:22 PM: Best result seen so far for edges-srl-ontonotes.
09/07 10:00:22 PM: Best result seen so far for macro.
09/07 10:00:22 PM: Updating LR scheduler:
09/07 10:00:22 PM: 	Best result seen so far for macro_avg: 0.741
09/07 10:00:22 PM: 	# validation passes without improvement: 0
09/07 10:00:22 PM: edges-srl-ontonotes_loss: training: 0.021370 validation: 0.019142
09/07 10:00:22 PM: macro_avg: validation: 0.741244
09/07 10:00:22 PM: micro_avg: validation: 0.000000
09/07 10:00:22 PM: edges-srl-ontonotes_mcc: training: 0.707583 validation: 0.743608
09/07 10:00:22 PM: edges-srl-ontonotes_acc: training: 0.613813 validation: 0.657301
09/07 10:00:22 PM: edges-srl-ontonotes_precision: training: 0.788358 validation: 0.845683
09/07 10:00:22 PM: edges-srl-ontonotes_recall: training: 0.642189 validation: 0.659764
09/07 10:00:22 PM: edges-srl-ontonotes_f1: training: 0.707806 validation: 0.741244
09/07 10:00:22 PM: Global learning rate: 0.0001
09/07 10:00:22 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 10:00:29 PM: Update 23071: task edges-srl-ontonotes, batch 71 (23071): mcc: 0.6707, acc: 0.5703, precision: 0.7565, recall: 0.6025, f1: 0.6708, edges-srl-ontonotes_loss: 0.0229
09/07 10:00:39 PM: Update 23184: task edges-srl-ontonotes, batch 184 (23184): mcc: 0.6721, acc: 0.5702, precision: 0.7602, recall: 0.6019, f1: 0.6718, edges-srl-ontonotes_loss: 0.0230
09/07 10:00:49 PM: Update 23292: task edges-srl-ontonotes, batch 292 (23292): mcc: 0.6721, acc: 0.5715, precision: 0.7598, recall: 0.6023, f1: 0.6719, edges-srl-ontonotes_loss: 0.0230
09/07 10:00:59 PM: Update 23383: task edges-srl-ontonotes, batch 383 (23383): mcc: 0.6637, acc: 0.5614, precision: 0.7545, recall: 0.5917, f1: 0.6632, edges-srl-ontonotes_loss: 0.0235
09/07 10:01:09 PM: Update 23489: task edges-srl-ontonotes, batch 489 (23489): mcc: 0.6574, acc: 0.5539, precision: 0.7502, recall: 0.5841, f1: 0.6568, edges-srl-ontonotes_loss: 0.0239
09/07 10:01:19 PM: Update 23595: task edges-srl-ontonotes, batch 595 (23595): mcc: 0.6547, acc: 0.5504, precision: 0.7489, recall: 0.5804, f1: 0.6540, edges-srl-ontonotes_loss: 0.0241
09/07 10:01:29 PM: Update 23689: task edges-srl-ontonotes, batch 689 (23689): mcc: 0.6533, acc: 0.5486, precision: 0.7483, recall: 0.5783, f1: 0.6524, edges-srl-ontonotes_loss: 0.0242
09/07 10:01:39 PM: Update 23796: task edges-srl-ontonotes, batch 796 (23796): mcc: 0.6517, acc: 0.5468, precision: 0.7479, recall: 0.5760, f1: 0.6507, edges-srl-ontonotes_loss: 0.0244
09/07 10:01:49 PM: Update 23905: task edges-srl-ontonotes, batch 905 (23905): mcc: 0.6514, acc: 0.5461, precision: 0.7484, recall: 0.5750, f1: 0.6503, edges-srl-ontonotes_loss: 0.0244
09/07 10:01:59 PM: Update 23980: task edges-srl-ontonotes, batch 980 (23980): mcc: 0.6519, acc: 0.5464, precision: 0.7488, recall: 0.5754, f1: 0.6508, edges-srl-ontonotes_loss: 0.0244
09/07 10:02:01 PM: ***** Step 24000 / Validation 24 *****
09/07 10:02:01 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:02:01 PM: Validating...
09/07 10:02:09 PM: Evaluate: task edges-srl-ontonotes, batch 90 (157): mcc: 0.7283, acc: 0.6412, precision: 0.8321, recall: 0.6437, f1: 0.7258, edges-srl-ontonotes_loss: 0.0200
09/07 10:02:15 PM: Updating LR scheduler:
09/07 10:02:15 PM: 	Best result seen so far for macro_avg: 0.741
09/07 10:02:15 PM: 	# validation passes without improvement: 1
09/07 10:02:15 PM: edges-srl-ontonotes_loss: training: 0.024400 validation: 0.019846
09/07 10:02:15 PM: macro_avg: validation: 0.727202
09/07 10:02:15 PM: micro_avg: validation: 0.000000
09/07 10:02:15 PM: edges-srl-ontonotes_mcc: training: 0.652029 validation: 0.729853
09/07 10:02:15 PM: edges-srl-ontonotes_acc: training: 0.546415 validation: 0.641598
09/07 10:02:15 PM: edges-srl-ontonotes_precision: training: 0.748992 validation: 0.835247
09/07 10:02:15 PM: edges-srl-ontonotes_recall: training: 0.575560 validation: 0.643907
09/07 10:02:15 PM: edges-srl-ontonotes_f1: training: 0.650922 validation: 0.727202
09/07 10:02:15 PM: Global learning rate: 0.0001
09/07 10:02:15 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 10:02:19 PM: Update 24039: task edges-srl-ontonotes, batch 39 (24039): mcc: 0.6786, acc: 0.5796, precision: 0.7586, recall: 0.6147, f1: 0.6791, edges-srl-ontonotes_loss: 0.0228
09/07 10:02:29 PM: Update 24143: task edges-srl-ontonotes, batch 143 (24143): mcc: 0.6580, acc: 0.5570, precision: 0.7472, recall: 0.5875, f1: 0.6578, edges-srl-ontonotes_loss: 0.0236
09/07 10:02:40 PM: Update 24243: task edges-srl-ontonotes, batch 243 (24243): mcc: 0.6621, acc: 0.5623, precision: 0.7500, recall: 0.5924, f1: 0.6620, edges-srl-ontonotes_loss: 0.0235
09/07 10:02:50 PM: Update 24352: task edges-srl-ontonotes, batch 352 (24352): mcc: 0.6627, acc: 0.5628, precision: 0.7507, recall: 0.5929, f1: 0.6626, edges-srl-ontonotes_loss: 0.0234
09/07 10:03:00 PM: Update 24459: task edges-srl-ontonotes, batch 459 (24459): mcc: 0.6629, acc: 0.5622, precision: 0.7514, recall: 0.5928, f1: 0.6628, edges-srl-ontonotes_loss: 0.0234
09/07 10:03:10 PM: Update 24556: task edges-srl-ontonotes, batch 556 (24556): mcc: 0.6641, acc: 0.5630, precision: 0.7527, recall: 0.5939, f1: 0.6639, edges-srl-ontonotes_loss: 0.0233
09/07 10:03:20 PM: Update 24664: task edges-srl-ontonotes, batch 664 (24664): mcc: 0.6666, acc: 0.5660, precision: 0.7546, recall: 0.5967, f1: 0.6664, edges-srl-ontonotes_loss: 0.0232
09/07 10:03:30 PM: Update 24771: task edges-srl-ontonotes, batch 771 (24771): mcc: 0.6686, acc: 0.5680, precision: 0.7566, recall: 0.5987, f1: 0.6685, edges-srl-ontonotes_loss: 0.0232
09/07 10:03:43 PM: Update 24869: task edges-srl-ontonotes, batch 869 (24869): mcc: 0.6721, acc: 0.5718, precision: 0.7594, recall: 0.6026, f1: 0.6720, edges-srl-ontonotes_loss: 0.0230
09/07 10:03:53 PM: Update 24975: task edges-srl-ontonotes, batch 975 (24975): mcc: 0.6713, acc: 0.5707, precision: 0.7587, recall: 0.6017, f1: 0.6711, edges-srl-ontonotes_loss: 0.0231
09/07 10:03:55 PM: ***** Step 25000 / Validation 25 *****
09/07 10:03:55 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:03:55 PM: Validating...
09/07 10:04:03 PM: Evaluate: task edges-srl-ontonotes, batch 84 (157): mcc: 0.7238, acc: 0.6363, precision: 0.8279, recall: 0.6392, f1: 0.7214, edges-srl-ontonotes_loss: 0.0209
09/07 10:04:10 PM: Updating LR scheduler:
09/07 10:04:10 PM: 	Best result seen so far for macro_avg: 0.741
09/07 10:04:10 PM: 	# validation passes without improvement: 2
09/07 10:04:10 PM: edges-srl-ontonotes_loss: training: 0.023128 validation: 0.020370
09/07 10:04:10 PM: macro_avg: validation: 0.726484
09/07 10:04:10 PM: micro_avg: validation: 0.000000
09/07 10:04:10 PM: edges-srl-ontonotes_mcc: training: 0.671060 validation: 0.728964
09/07 10:04:10 PM: edges-srl-ontonotes_acc: training: 0.570547 validation: 0.640982
09/07 10:04:10 PM: edges-srl-ontonotes_precision: training: 0.758627 validation: 0.832968
09/07 10:04:10 PM: edges-srl-ontonotes_recall: training: 0.601367 validation: 0.644138
09/07 10:04:10 PM: edges-srl-ontonotes_f1: training: 0.670905 validation: 0.726484
09/07 10:04:10 PM: Global learning rate: 0.0001
09/07 10:04:10 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 10:04:13 PM: Update 25033: task edges-srl-ontonotes, batch 33 (25033): mcc: 0.6751, acc: 0.5680, precision: 0.7724, recall: 0.5976, f1: 0.6738, edges-srl-ontonotes_loss: 0.0231
09/07 10:04:23 PM: Update 25145: task edges-srl-ontonotes, batch 145 (25145): mcc: 0.6695, acc: 0.5666, precision: 0.7586, recall: 0.5986, f1: 0.6692, edges-srl-ontonotes_loss: 0.0234
09/07 10:04:33 PM: Update 25241: task edges-srl-ontonotes, batch 241 (25241): mcc: 0.6670, acc: 0.5627, precision: 0.7580, recall: 0.5948, f1: 0.6665, edges-srl-ontonotes_loss: 0.0235
09/07 10:04:43 PM: Update 25352: task edges-srl-ontonotes, batch 352 (25352): mcc: 0.6661, acc: 0.5611, precision: 0.7583, recall: 0.5928, f1: 0.6654, edges-srl-ontonotes_loss: 0.0235
09/07 10:04:53 PM: Update 25460: task edges-srl-ontonotes, batch 460 (25460): mcc: 0.6667, acc: 0.5625, precision: 0.7587, recall: 0.5936, f1: 0.6661, edges-srl-ontonotes_loss: 0.0235
09/07 10:05:03 PM: Update 25555: task edges-srl-ontonotes, batch 555 (25555): mcc: 0.6655, acc: 0.5619, precision: 0.7575, recall: 0.5925, f1: 0.6649, edges-srl-ontonotes_loss: 0.0236
09/07 10:05:13 PM: Update 25665: task edges-srl-ontonotes, batch 665 (25665): mcc: 0.6661, acc: 0.5627, precision: 0.7583, recall: 0.5929, f1: 0.6655, edges-srl-ontonotes_loss: 0.0236
09/07 10:05:23 PM: Update 25775: task edges-srl-ontonotes, batch 775 (25775): mcc: 0.6672, acc: 0.5642, precision: 0.7592, recall: 0.5941, f1: 0.6666, edges-srl-ontonotes_loss: 0.0235
09/07 10:05:33 PM: Update 25850: task edges-srl-ontonotes, batch 850 (25850): mcc: 0.6677, acc: 0.5646, precision: 0.7596, recall: 0.5947, f1: 0.6671, edges-srl-ontonotes_loss: 0.0235
09/07 10:05:43 PM: Update 25958: task edges-srl-ontonotes, batch 958 (25958): mcc: 0.6692, acc: 0.5662, precision: 0.7605, recall: 0.5965, f1: 0.6686, edges-srl-ontonotes_loss: 0.0234
09/07 10:05:47 PM: ***** Step 26000 / Validation 26 *****
09/07 10:05:47 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:05:47 PM: Validating...
09/07 10:05:53 PM: Evaluate: task edges-srl-ontonotes, batch 66 (157): mcc: 0.7118, acc: 0.6280, precision: 0.8123, recall: 0.6303, f1: 0.7098, edges-srl-ontonotes_loss: 0.0215
09/07 10:06:02 PM: Updating LR scheduler:
09/07 10:06:02 PM: 	Best result seen so far for macro_avg: 0.741
09/07 10:06:02 PM: 	# validation passes without improvement: 3
09/07 10:06:02 PM: edges-srl-ontonotes_loss: training: 0.023344 validation: 0.020794
09/07 10:06:02 PM: macro_avg: validation: 0.718254
09/07 10:06:02 PM: micro_avg: validation: 0.000000
09/07 10:06:02 PM: edges-srl-ontonotes_mcc: training: 0.670076 validation: 0.720036
09/07 10:06:02 PM: edges-srl-ontonotes_acc: training: 0.567412 validation: 0.637056
09/07 10:06:02 PM: edges-srl-ontonotes_precision: training: 0.760892 validation: 0.818594
09/07 10:06:02 PM: edges-srl-ontonotes_recall: training: 0.597811 validation: 0.639828
09/07 10:06:02 PM: edges-srl-ontonotes_f1: training: 0.669565 validation: 0.718254
09/07 10:06:02 PM: Global learning rate: 0.0001
09/07 10:06:02 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 10:06:03 PM: Update 26016: task edges-srl-ontonotes, batch 16 (26016): mcc: 0.6926, acc: 0.6012, precision: 0.7772, recall: 0.6245, f1: 0.6925, edges-srl-ontonotes_loss: 0.0222
09/07 10:06:14 PM: Update 26121: task edges-srl-ontonotes, batch 121 (26121): mcc: 0.6811, acc: 0.5846, precision: 0.7642, recall: 0.6147, f1: 0.6814, edges-srl-ontonotes_loss: 0.0228
09/07 10:06:24 PM: Update 26228: task edges-srl-ontonotes, batch 228 (26228): mcc: 0.6816, acc: 0.5856, precision: 0.7646, recall: 0.6152, f1: 0.6818, edges-srl-ontonotes_loss: 0.0227
09/07 10:06:34 PM: Update 26338: task edges-srl-ontonotes, batch 338 (26338): mcc: 0.6817, acc: 0.5849, precision: 0.7657, recall: 0.6144, f1: 0.6818, edges-srl-ontonotes_loss: 0.0227
09/07 10:06:45 PM: Update 26434: task edges-srl-ontonotes, batch 434 (26434): mcc: 0.6803, acc: 0.5833, precision: 0.7645, recall: 0.6130, f1: 0.6804, edges-srl-ontonotes_loss: 0.0228
09/07 10:06:55 PM: Update 26529: task edges-srl-ontonotes, batch 529 (26529): mcc: 0.6727, acc: 0.5728, precision: 0.7605, recall: 0.6027, f1: 0.6725, edges-srl-ontonotes_loss: 0.0232
09/07 10:07:05 PM: Update 26625: task edges-srl-ontonotes, batch 625 (26625): mcc: 0.6691, acc: 0.5676, precision: 0.7592, recall: 0.5973, f1: 0.6686, edges-srl-ontonotes_loss: 0.0234
09/07 10:07:15 PM: Update 26724: task edges-srl-ontonotes, batch 724 (26724): mcc: 0.6687, acc: 0.5665, precision: 0.7597, recall: 0.5963, f1: 0.6682, edges-srl-ontonotes_loss: 0.0235
09/07 10:07:25 PM: Update 26823: task edges-srl-ontonotes, batch 823 (26823): mcc: 0.6738, acc: 0.5720, precision: 0.7643, recall: 0.6017, f1: 0.6733, edges-srl-ontonotes_loss: 0.0232
09/07 10:07:35 PM: Update 26945: task edges-srl-ontonotes, batch 945 (26945): mcc: 0.6833, acc: 0.5828, precision: 0.7714, recall: 0.6128, f1: 0.6830, edges-srl-ontonotes_loss: 0.0227
09/07 10:07:39 PM: ***** Step 27000 / Validation 27 *****
09/07 10:07:39 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:07:39 PM: Validating...
09/07 10:07:45 PM: Evaluate: task edges-srl-ontonotes, batch 60 (157): mcc: 0.7198, acc: 0.6344, precision: 0.8181, recall: 0.6398, f1: 0.7180, edges-srl-ontonotes_loss: 0.0212
09/07 10:07:54 PM: Updating LR scheduler:
09/07 10:07:54 PM: 	Best result seen so far for macro_avg: 0.741
09/07 10:07:54 PM: 	# validation passes without improvement: 4
09/07 10:07:54 PM: edges-srl-ontonotes_loss: training: 0.022437 validation: 0.020590
09/07 10:07:54 PM: macro_avg: validation: 0.726040
09/07 10:07:54 PM: micro_avg: validation: 0.000000
09/07 10:07:54 PM: edges-srl-ontonotes_mcc: training: 0.686546 validation: 0.727288
09/07 10:07:54 PM: edges-srl-ontonotes_acc: training: 0.586626 validation: 0.646371
09/07 10:07:54 PM: edges-srl-ontonotes_precision: training: 0.773952 validation: 0.820528
09/07 10:07:54 PM: edges-srl-ontonotes_recall: training: 0.616445 validation: 0.651066
09/07 10:07:54 PM: edges-srl-ontonotes_f1: training: 0.686277 validation: 0.726040
09/07 10:07:54 PM: Global learning rate: 0.0001
09/07 10:07:54 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 10:07:55 PM: Update 27012: task edges-srl-ontonotes, batch 12 (27012): mcc: 0.7569, acc: 0.6791, precision: 0.8115, recall: 0.7124, f1: 0.7587, edges-srl-ontonotes_loss: 0.0189
09/07 10:08:05 PM: Update 27100: task edges-srl-ontonotes, batch 100 (27100): mcc: 0.7633, acc: 0.6827, precision: 0.8231, recall: 0.7140, f1: 0.7647, edges-srl-ontonotes_loss: 0.0179
09/07 10:08:15 PM: Update 27230: task edges-srl-ontonotes, batch 230 (27230): mcc: 0.7818, acc: 0.7047, precision: 0.8390, recall: 0.7342, f1: 0.7831, edges-srl-ontonotes_loss: 0.0167
09/07 10:08:25 PM: Update 27362: task edges-srl-ontonotes, batch 362 (27362): mcc: 0.7908, acc: 0.7162, precision: 0.8456, recall: 0.7451, f1: 0.7922, edges-srl-ontonotes_loss: 0.0161
09/07 10:08:35 PM: Update 27474: task edges-srl-ontonotes, batch 474 (27474): mcc: 0.7883, acc: 0.7140, precision: 0.8435, recall: 0.7422, f1: 0.7897, edges-srl-ontonotes_loss: 0.0162
09/07 10:08:45 PM: Update 27602: task edges-srl-ontonotes, batch 602 (27602): mcc: 0.7900, acc: 0.7161, precision: 0.8452, recall: 0.7440, f1: 0.7913, edges-srl-ontonotes_loss: 0.0160
09/07 10:08:55 PM: Update 27720: task edges-srl-ontonotes, batch 720 (27720): mcc: 0.7918, acc: 0.7184, precision: 0.8468, recall: 0.7459, f1: 0.7931, edges-srl-ontonotes_loss: 0.0159
09/07 10:09:05 PM: Update 27853: task edges-srl-ontonotes, batch 853 (27853): mcc: 0.7941, acc: 0.7214, precision: 0.8483, recall: 0.7488, f1: 0.7955, edges-srl-ontonotes_loss: 0.0158
09/07 10:09:15 PM: Update 27985: task edges-srl-ontonotes, batch 985 (27985): mcc: 0.7970, acc: 0.7258, precision: 0.8503, recall: 0.7524, f1: 0.7984, edges-srl-ontonotes_loss: 0.0156
09/07 10:09:19 PM: ***** Step 28000 / Validation 28 *****
09/07 10:09:19 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:09:19 PM: Validating...
09/07 10:09:25 PM: Evaluate: task edges-srl-ontonotes, batch 65 (157): mcc: 0.7197, acc: 0.6363, precision: 0.8180, recall: 0.6396, f1: 0.7179, edges-srl-ontonotes_loss: 0.0209
09/07 10:09:34 PM: Updating LR scheduler:
09/07 10:09:34 PM: 	Best result seen so far for macro_avg: 0.741
09/07 10:09:34 PM: 	# validation passes without improvement: 5
09/07 10:09:34 PM: edges-srl-ontonotes_loss: training: 0.015615 validation: 0.020542
09/07 10:09:34 PM: macro_avg: validation: 0.722492
09/07 10:09:34 PM: micro_avg: validation: 0.000000
09/07 10:09:34 PM: edges-srl-ontonotes_mcc: training: 0.797138 validation: 0.723933
09/07 10:09:34 PM: edges-srl-ontonotes_acc: training: 0.726012 validation: 0.642753
09/07 10:09:34 PM: edges-srl-ontonotes_precision: training: 0.850227 validation: 0.819184
09/07 10:09:34 PM: edges-srl-ontonotes_recall: training: 0.752757 validation: 0.646217
09/07 10:09:34 PM: edges-srl-ontonotes_f1: training: 0.798529 validation: 0.722492
09/07 10:09:34 PM: Global learning rate: 0.0001
09/07 10:09:34 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-cat/run
09/07 10:09:35 PM: Update 28020: task edges-srl-ontonotes, batch 20 (28020): mcc: 0.8017, acc: 0.7364, precision: 0.8552, recall: 0.7568, f1: 0.8030, edges-srl-ontonotes_loss: 0.0160
09/07 10:09:45 PM: Update 28153: task edges-srl-ontonotes, batch 153 (28153): mcc: 0.8240, acc: 0.7663, precision: 0.8678, recall: 0.7873, f1: 0.8256, edges-srl-ontonotes_loss: 0.0145
09/07 10:09:55 PM: Update 28288: task edges-srl-ontonotes, batch 288 (28288): mcc: 0.8259, acc: 0.7683, precision: 0.8704, recall: 0.7884, f1: 0.8274, edges-srl-ontonotes_loss: 0.0142
09/07 10:10:06 PM: Update 28384: task edges-srl-ontonotes, batch 384 (28384): mcc: 0.8040, acc: 0.7399, precision: 0.8545, recall: 0.7617, f1: 0.8054, edges-srl-ontonotes_loss: 0.0156
09/07 10:10:16 PM: Update 28499: task edges-srl-ontonotes, batch 499 (28499): mcc: 0.7857, acc: 0.7168, precision: 0.8404, recall: 0.7402, f1: 0.7871, edges-srl-ontonotes_loss: 0.0167
09/07 10:10:26 PM: Update 28611: task edges-srl-ontonotes, batch 611 (28611): mcc: 0.7752, acc: 0.7030, precision: 0.8327, recall: 0.7276, f1: 0.7766, edges-srl-ontonotes_loss: 0.0174
09/07 10:10:36 PM: Update 28706: task edges-srl-ontonotes, batch 706 (28706): mcc: 0.7628, acc: 0.6871, precision: 0.8240, recall: 0.7123, f1: 0.7641, edges-srl-ontonotes_loss: 0.0181
09/07 10:10:46 PM: Update 28810: task edges-srl-ontonotes, batch 810 (28810): mcc: 0.7522, acc: 0.6730, precision: 0.8165, recall: 0.6992, f1: 0.7533, edges-srl-ontonotes_loss: 0.0188
09/07 10:10:56 PM: Update 28922: task edges-srl-ontonotes, batch 922 (28922): mcc: 0.7447, acc: 0.6634, precision: 0.8115, recall: 0.6900, f1: 0.7458, edges-srl-ontonotes_loss: 0.0192
09/07 10:11:05 PM: ***** Step 29000 / Validation 29 *****
09/07 10:11:05 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:11:05 PM: Validating...
09/07 10:11:06 PM: Evaluate: task edges-srl-ontonotes, batch 4 (157): mcc: 0.7463, acc: 0.6600, precision: 0.8442, recall: 0.6657, f1: 0.7444, edges-srl-ontonotes_loss: 0.0187
