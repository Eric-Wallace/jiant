09/07 09:16:38 PM: Git branch: master
09/07 09:16:38 PM: Git SHA: 117419dc9116809c203f878fb83f7aaddafbbcb0
09/07 09:16:39 PM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "/scratch0/new/jiant/experiments/srl-ontonotes-None-cat/",
  "exp_name": "experiments/srl-ontonotes-None-cat",
  "input_module": "bert-base-uncased",
  "local_log_path": "/scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run/log.log",
  "lr_patience": 5,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 20,
  "pretrain_tasks": "",
  "pretrained_dir": "None",
  "pytorch_transformers_output_mode": "cat",
  "remote_log_name": "experiments/srl-ontonotes-None-cat__run",
  "run_dir": "/scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-srl-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/07 09:16:39 PM: Saved config to /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run/params.conf
09/07 09:16:39 PM: Using random seed 1234
09/07 09:16:40 PM: Using GPU 0
09/07 09:16:40 PM: Loading tasks...
09/07 09:16:40 PM: Writing pre-preprocessed tasks to /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/
09/07 09:16:40 PM: 	Creating task edges-srl-ontonotes from scratch.
09/07 09:16:44 PM: Read=231480, Skip=21590, Total=253070 from /scratch0/new/jiant/probing_data/edges/ontonotes/srl/train.json.retokenized.bert-base-uncased
09/07 09:16:45 PM: Read=32486, Skip=2811, Total=35297 from /scratch0/new/jiant/probing_data/edges/ontonotes/srl/development.json.retokenized.bert-base-uncased
09/07 09:16:45 PM: Read=23800, Skip=2915, Total=26715 from /scratch0/new/jiant/probing_data/edges/ontonotes/srl/test.json.retokenized.bert-base-uncased
09/07 09:16:48 PM: 	Task 'edges-srl-ontonotes': |train|=231480 |val|=32486 |test|=23800
09/07 09:16:48 PM: 	Finished loading tasks: edges-srl-ontonotes.
09/07 09:16:48 PM: 	Building vocab from scratch.
09/07 09:16:48 PM: 	Counting units for task edges-srl-ontonotes.
09/07 09:16:55 PM: 	Task 'edges-srl-ontonotes': adding vocab namespace 'edges-srl-ontonotes_labels'
09/07 09:16:55 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to /tmp/tmp5yii0oow
09/07 09:16:56 PM: copying /tmp/tmp5yii0oow to cache at /cliphomes/ewallac2/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:16:56 PM: creating metadata file for /cliphomes/ewallac2/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:16:56 PM: removing temp file /tmp/tmp5yii0oow
09/07 09:16:56 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /cliphomes/ewallac2/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:16:56 PM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/07 09:16:56 PM: 	Saved vocab to /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/vocab
09/07 09:16:56 PM: Loading token dictionary from /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/vocab.
09/07 09:16:56 PM: 	Loaded vocab from /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/vocab
09/07 09:16:56 PM: 	Vocab namespace tokens: size 23662
09/07 09:16:56 PM: 	Vocab namespace chars: size 76
09/07 09:16:56 PM: 	Vocab namespace edges-srl-ontonotes_labels: size 66
09/07 09:16:56 PM: 	Vocab namespace bert_uncased: size 30524
09/07 09:16:56 PM: 	Finished building vocab.
09/07 09:16:56 PM: 	Task edges-srl-ontonotes (train): Indexing from scratch.
09/07 09:17:44 PM: 	Task edges-srl-ontonotes (train): Saved 231480 instances to /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/preproc/edges-srl-ontonotes__train_data
09/07 09:17:44 PM: 	Task edges-srl-ontonotes (val): Indexing from scratch.
09/07 09:17:51 PM: 	Task edges-srl-ontonotes (val): Saved 32486 instances to /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/preproc/edges-srl-ontonotes__val_data
09/07 09:17:51 PM: 	Task edges-srl-ontonotes (test): Indexing from scratch.
09/07 09:17:56 PM: 	Task edges-srl-ontonotes (test): Saved 23800 instances to /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/preproc/edges-srl-ontonotes__test_data
09/07 09:17:56 PM: 	Finished indexing tasks
09/07 09:17:56 PM: 	Creating trimmed target-only version of edges-srl-ontonotes train.
09/07 09:17:56 PM: 	  Training on 
09/07 09:17:56 PM: 	  Evaluating on edges-srl-ontonotes
09/07 09:17:56 PM: 	Finished loading tasks in 76.502s
09/07 09:17:56 PM: 	 Tasks: ['edges-srl-ontonotes']
09/07 09:17:56 PM: Building model...
09/07 09:17:56 PM: Using BERT model (bert-base-uncased).
09/07 09:17:56 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache, downloading to /tmp/tmpqi4q50ps
09/07 09:17:56 PM: copying /tmp/tmpqi4q50ps to cache at /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/07 09:17:56 PM: creating metadata file for /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/07 09:17:56 PM: removing temp file /tmp/tmpqi4q50ps
09/07 09:17:56 PM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/07 09:17:56 PM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/07 09:17:56 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache, downloading to /tmp/tmptmnrnyoa
09/07 09:18:23 PM: copying /tmp/tmptmnrnyoa to cache at /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/07 09:18:24 PM: creating metadata file for /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/07 09:18:24 PM: removing temp file /tmp/tmptmnrnyoa
09/07 09:18:24 PM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/07 09:18:28 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to /tmp/tmpe3bzhnwx
09/07 09:18:28 PM: copying /tmp/tmpe3bzhnwx to cache at /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:18:28 PM: creating metadata file for /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:18:28 PM: removing temp file /tmp/tmpe3bzhnwx
09/07 09:18:28 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:18:28 PM: Initializing parameters
09/07 09:18:28 PM: Done initializing parameters; the following parameters are using their default initialization from their code
09/07 09:18:28 PM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/07 09:18:28 PM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/07 09:18:28 PM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.pooler.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.pooler.dense.weight
09/07 09:18:28 PM: 	Task 'edges-srl-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-srl-ontonotes"
}
09/07 09:18:32 PM: Model specification:
09/07 09:18:32 PM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): BertLayerNorm()
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-srl-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(1536, 256, kernel_size=(1,), stride=(1,))
    (proj2): Conv1d(1536, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (span_extractor2): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Sequential(
        (0): Linear(in_features=1024, out_features=256, bias=True)
        (1): Tanh()
        (2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)
        (3): Dropout(p=0.3)
        (4): Linear(in_features=256, out_features=66, bias=True)
      )
    )
  )
)
09/07 09:18:32 PM: Model parameters:
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:32 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:32 PM: 	edges-srl-ontonotes_mdl.proj1.weight: Trainable parameter, count 393216 with torch.Size([256, 1536, 1])
09/07 09:18:32 PM: 	edges-srl-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:32 PM: 	edges-srl-ontonotes_mdl.proj2.weight: Trainable parameter, count 393216 with torch.Size([256, 1536, 1])
09/07 09:18:32 PM: 	edges-srl-ontonotes_mdl.proj2.bias: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:32 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.0.weight: Trainable parameter, count 262144 with torch.Size([256, 1024])
09/07 09:18:32 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.0.bias: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:32 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.2.weight: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:32 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.2.bias: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:32 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.4.weight: Trainable parameter, count 16896 with torch.Size([66, 256])
09/07 09:18:32 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.4.bias: Trainable parameter, count 66 with torch.Size([66])
09/07 09:18:32 PM: Total number of parameters: 110549058 (1.10549e+08)
09/07 09:18:32 PM: Number of trainable parameters: 1066818 (1.06682e+06)
09/07 09:18:32 PM: Finished building model in 35.887s
09/07 09:18:32 PM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-srl-ontonotes 

09/07 09:18:48 PM: patience = 20
09/07 09:18:48 PM: val_interval = 1000
09/07 09:18:48 PM: max_vals = 250
09/07 09:18:48 PM: cuda_device = 0
09/07 09:18:48 PM: grad_norm = 5.0
09/07 09:18:48 PM: grad_clipping = None
09/07 09:18:48 PM: lr_decay = 0.99
09/07 09:18:48 PM: min_lr = 1e-06
09/07 09:18:48 PM: keep_all_checkpoints = 0
09/07 09:18:48 PM: val_data_limit = 5000
09/07 09:18:48 PM: max_epochs = -1
09/07 09:18:48 PM: dec_val_scale = 250
09/07 09:18:48 PM: training_data_fraction = 1
09/07 09:18:48 PM: type = adam
09/07 09:18:48 PM: parameter_groups = None
09/07 09:18:48 PM: Number of trainable parameters: 1066818
09/07 09:18:48 PM: infer_type_and_cast = True
09/07 09:18:48 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/07 09:18:48 PM: CURRENTLY DEFINED PARAMETERS: 
09/07 09:18:48 PM: lr = 0.0001
09/07 09:18:48 PM: amsgrad = True
09/07 09:18:48 PM: type = reduce_on_plateau
09/07 09:18:48 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/07 09:18:48 PM: CURRENTLY DEFINED PARAMETERS: 
09/07 09:18:48 PM: mode = max
09/07 09:18:48 PM: factor = 0.5
09/07 09:18:48 PM: patience = 5
09/07 09:18:48 PM: threshold = 0.0001
09/07 09:18:48 PM: threshold_mode = abs
09/07 09:18:48 PM: verbose = True
09/07 09:18:48 PM: type = adam
09/07 09:18:48 PM: parameter_groups = None
09/07 09:18:48 PM: Number of trainable parameters: 1066818
09/07 09:18:48 PM: infer_type_and_cast = True
09/07 09:18:48 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/07 09:18:48 PM: CURRENTLY DEFINED PARAMETERS: 
09/07 09:18:48 PM: lr = 0.0001
09/07 09:18:48 PM: amsgrad = True
09/07 09:18:48 PM: type = reduce_on_plateau
09/07 09:18:48 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/07 09:18:48 PM: CURRENTLY DEFINED PARAMETERS: 
09/07 09:18:48 PM: mode = max
09/07 09:18:48 PM: factor = 0.5
09/07 09:18:48 PM: patience = 5
09/07 09:18:48 PM: threshold = 0.0001
09/07 09:18:48 PM: threshold_mode = abs
09/07 09:18:48 PM: verbose = True
09/07 09:18:48 PM: Starting training without restoring from a checkpoint.
09/07 09:18:48 PM: Training examples per task, before any subsampling: {'edges-srl-ontonotes': 231480}
09/07 09:18:48 PM: Beginning training with stopping criteria based on metric: edges-srl-ontonotes_f1
09/07 09:18:58 PM: Update 110: task edges-srl-ontonotes, batch 110 (110): mcc: 0.0361, acc: 0.0303, precision: 0.0409, recall: 0.0769, f1: 0.0534, edges-srl-ontonotes_loss: 0.2122
09/07 09:19:08 PM: Update 229: task edges-srl-ontonotes, batch 229 (229): mcc: 0.0847, acc: 0.0742, precision: 0.1000, recall: 0.0968, f1: 0.0984, edges-srl-ontonotes_loss: 0.1379
09/07 09:19:18 PM: Update 334: task edges-srl-ontonotes, batch 334 (334): mcc: 0.1686, acc: 0.1425, precision: 0.2031, recall: 0.1590, f1: 0.1783, edges-srl-ontonotes_loss: 0.1097
09/07 09:19:28 PM: Update 449: task edges-srl-ontonotes, batch 449 (449): mcc: 0.2547, acc: 0.2091, precision: 0.3124, recall: 0.2234, f1: 0.2605, edges-srl-ontonotes_loss: 0.0916
09/07 09:19:38 PM: Update 567: task edges-srl-ontonotes, batch 567 (567): mcc: 0.3315, acc: 0.2691, precision: 0.4075, recall: 0.2835, f1: 0.3344, edges-srl-ontonotes_loss: 0.0794
09/07 09:19:48 PM: Update 652: task edges-srl-ontonotes, batch 652 (652): mcc: 0.3745, acc: 0.3024, precision: 0.4600, recall: 0.3177, f1: 0.3759, edges-srl-ontonotes_loss: 0.0730
09/07 09:19:58 PM: Update 772: task edges-srl-ontonotes, batch 772 (772): mcc: 0.4194, acc: 0.3377, precision: 0.5135, recall: 0.3544, f1: 0.4194, edges-srl-ontonotes_loss: 0.0661
09/07 09:20:08 PM: Update 889: task edges-srl-ontonotes, batch 889 (889): mcc: 0.4555, acc: 0.3670, precision: 0.5549, recall: 0.3851, f1: 0.4546, edges-srl-ontonotes_loss: 0.0610
09/07 09:20:18 PM: Update 997: task edges-srl-ontonotes, batch 997 (997): mcc: 0.4822, acc: 0.3894, precision: 0.5843, recall: 0.4086, f1: 0.4809, edges-srl-ontonotes_loss: 0.0571
09/07 09:20:19 PM: ***** Step 1000 / Validation 1 *****
09/07 09:20:19 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:20:19 PM: Validating...
09/07 09:20:28 PM: Evaluate: task edges-srl-ontonotes, batch 106 (157): mcc: 0.7512, acc: 0.6382, precision: 0.8768, recall: 0.6490, f1: 0.7459, edges-srl-ontonotes_loss: 0.0224
09/07 09:20:33 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:20:33 PM: Best result seen so far for micro.
09/07 09:20:33 PM: Best result seen so far for macro.
09/07 09:20:33 PM: Updating LR scheduler:
09/07 09:20:33 PM: 	Best result seen so far for macro_avg: 0.745
09/07 09:20:33 PM: 	# validation passes without improvement: 0
09/07 09:20:33 PM: edges-srl-ontonotes_loss: training: 0.057017 validation: 0.022432
09/07 09:20:33 PM: macro_avg: validation: 0.744571
09/07 09:20:33 PM: micro_avg: validation: 0.000000
09/07 09:20:33 PM: edges-srl-ontonotes_mcc: training: 0.482880 validation: 0.749849
09/07 09:20:33 PM: edges-srl-ontonotes_acc: training: 0.390048 validation: 0.635594
09/07 09:20:33 PM: edges-srl-ontonotes_precision: training: 0.585145 validation: 0.875130
09/07 09:20:33 PM: edges-srl-ontonotes_recall: training: 0.409209 validation: 0.647910
09/07 09:20:33 PM: edges-srl-ontonotes_f1: training: 0.481612 validation: 0.744571
09/07 09:20:33 PM: Global learning rate: 0.0001
09/07 09:20:33 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 09:20:38 PM: Update 1062: task edges-srl-ontonotes, batch 62 (1062): mcc: 0.7072, acc: 0.5860, precision: 0.8286, recall: 0.6100, f1: 0.7027, edges-srl-ontonotes_loss: 0.0254
09/07 09:20:48 PM: Update 1178: task edges-srl-ontonotes, batch 178 (1178): mcc: 0.7121, acc: 0.5927, precision: 0.8256, recall: 0.6205, f1: 0.7085, edges-srl-ontonotes_loss: 0.0248
09/07 09:20:58 PM: Update 1279: task edges-srl-ontonotes, batch 279 (1279): mcc: 0.7184, acc: 0.6013, precision: 0.8275, recall: 0.6301, f1: 0.7154, edges-srl-ontonotes_loss: 0.0242
09/07 09:21:09 PM: Update 1391: task edges-srl-ontonotes, batch 391 (1391): mcc: 0.7210, acc: 0.6055, precision: 0.8257, recall: 0.6359, f1: 0.7185, edges-srl-ontonotes_loss: 0.0238
09/07 09:21:19 PM: Update 1500: task edges-srl-ontonotes, batch 500 (1500): mcc: 0.7285, acc: 0.6153, precision: 0.8295, recall: 0.6460, f1: 0.7263, edges-srl-ontonotes_loss: 0.0231
09/07 09:21:29 PM: Update 1601: task edges-srl-ontonotes, batch 601 (1601): mcc: 0.7305, acc: 0.6180, precision: 0.8294, recall: 0.6496, f1: 0.7286, edges-srl-ontonotes_loss: 0.0228
09/07 09:21:39 PM: Update 1712: task edges-srl-ontonotes, batch 712 (1712): mcc: 0.7301, acc: 0.6175, precision: 0.8282, recall: 0.6499, f1: 0.7283, edges-srl-ontonotes_loss: 0.0228
09/07 09:21:49 PM: Update 1818: task edges-srl-ontonotes, batch 818 (1818): mcc: 0.7301, acc: 0.6179, precision: 0.8278, recall: 0.6503, f1: 0.7284, edges-srl-ontonotes_loss: 0.0227
09/07 09:21:59 PM: Update 1892: task edges-srl-ontonotes, batch 892 (1892): mcc: 0.7306, acc: 0.6186, precision: 0.8275, recall: 0.6514, f1: 0.7290, edges-srl-ontonotes_loss: 0.0227
09/07 09:22:09 PM: Update 2000: task edges-srl-ontonotes, batch 1000 (2000): mcc: 0.7324, acc: 0.6210, precision: 0.8279, recall: 0.6542, f1: 0.7308, edges-srl-ontonotes_loss: 0.0225
09/07 09:22:09 PM: ***** Step 2000 / Validation 2 *****
09/07 09:22:09 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:22:09 PM: Validating...
09/07 09:22:19 PM: Evaluate: task edges-srl-ontonotes, batch 108 (157): mcc: 0.7910, acc: 0.7020, precision: 0.8787, recall: 0.7171, f1: 0.7897, edges-srl-ontonotes_loss: 0.0176
09/07 09:22:23 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:22:23 PM: Best result seen so far for macro.
09/07 09:22:23 PM: Updating LR scheduler:
09/07 09:22:23 PM: 	Best result seen so far for macro_avg: 0.792
09/07 09:22:23 PM: 	# validation passes without improvement: 0
09/07 09:22:23 PM: edges-srl-ontonotes_loss: training: 0.022480 validation: 0.017472
09/07 09:22:23 PM: macro_avg: validation: 0.792373
09/07 09:22:23 PM: micro_avg: validation: 0.000000
09/07 09:22:23 PM: edges-srl-ontonotes_mcc: training: 0.732383 validation: 0.793672
09/07 09:22:23 PM: edges-srl-ontonotes_acc: training: 0.621039 validation: 0.705488
09/07 09:22:23 PM: edges-srl-ontonotes_precision: training: 0.827877 validation: 0.881327
09/07 09:22:23 PM: edges-srl-ontonotes_recall: training: 0.654174 validation: 0.719729
09/07 09:22:23 PM: edges-srl-ontonotes_f1: training: 0.730846 validation: 0.792373
09/07 09:22:23 PM: Global learning rate: 0.0001
09/07 09:22:23 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 09:22:29 PM: Update 2062: task edges-srl-ontonotes, batch 62 (2062): mcc: 0.7564, acc: 0.6521, precision: 0.8442, recall: 0.6835, f1: 0.7554, edges-srl-ontonotes_loss: 0.0207
09/07 09:22:39 PM: Update 2174: task edges-srl-ontonotes, batch 174 (2174): mcc: 0.7481, acc: 0.6449, precision: 0.8333, recall: 0.6776, f1: 0.7474, edges-srl-ontonotes_loss: 0.0210
09/07 09:22:49 PM: Update 2267: task edges-srl-ontonotes, batch 267 (2267): mcc: 0.7533, acc: 0.6518, precision: 0.8355, recall: 0.6852, f1: 0.7529, edges-srl-ontonotes_loss: 0.0206
09/07 09:22:59 PM: Update 2370: task edges-srl-ontonotes, batch 370 (2370): mcc: 0.7626, acc: 0.6636, precision: 0.8415, recall: 0.6969, f1: 0.7624, edges-srl-ontonotes_loss: 0.0200
09/07 09:23:09 PM: Update 2477: task edges-srl-ontonotes, batch 477 (2477): mcc: 0.7658, acc: 0.6686, precision: 0.8426, recall: 0.7017, f1: 0.7658, edges-srl-ontonotes_loss: 0.0197
09/07 09:23:19 PM: Update 2574: task edges-srl-ontonotes, batch 574 (2574): mcc: 0.7690, acc: 0.6731, precision: 0.8444, recall: 0.7062, f1: 0.7691, edges-srl-ontonotes_loss: 0.0195
09/07 09:23:29 PM: Update 2685: task edges-srl-ontonotes, batch 685 (2685): mcc: 0.7709, acc: 0.6760, precision: 0.8450, recall: 0.7091, f1: 0.7711, edges-srl-ontonotes_loss: 0.0192
09/07 09:23:39 PM: Update 2794: task edges-srl-ontonotes, batch 794 (2794): mcc: 0.7738, acc: 0.6800, precision: 0.8465, recall: 0.7130, f1: 0.7740, edges-srl-ontonotes_loss: 0.0190
09/07 09:23:49 PM: Update 2871: task edges-srl-ontonotes, batch 871 (2871): mcc: 0.7767, acc: 0.6838, precision: 0.8486, recall: 0.7166, f1: 0.7770, edges-srl-ontonotes_loss: 0.0188
09/07 09:23:59 PM: Update 2979: task edges-srl-ontonotes, batch 979 (2979): mcc: 0.7799, acc: 0.6880, precision: 0.8506, recall: 0.7206, f1: 0.7802, edges-srl-ontonotes_loss: 0.0186
09/07 09:24:01 PM: ***** Step 3000 / Validation 3 *****
09/07 09:24:01 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:24:01 PM: Validating...
09/07 09:24:09 PM: Evaluate: task edges-srl-ontonotes, batch 86 (157): mcc: 0.8014, acc: 0.7239, precision: 0.8694, recall: 0.7438, f1: 0.8017, edges-srl-ontonotes_loss: 0.0167
09/07 09:24:16 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:24:16 PM: Best result seen so far for macro.
09/07 09:24:16 PM: Updating LR scheduler:
09/07 09:24:16 PM: 	Best result seen so far for macro_avg: 0.812
09/07 09:24:16 PM: 	# validation passes without improvement: 0
09/07 09:24:16 PM: edges-srl-ontonotes_loss: training: 0.018608 validation: 0.015922
09/07 09:24:16 PM: macro_avg: validation: 0.812254
09/07 09:24:16 PM: micro_avg: validation: 0.000000
09/07 09:24:16 PM: edges-srl-ontonotes_mcc: training: 0.780326 validation: 0.811887
09/07 09:24:16 PM: edges-srl-ontonotes_acc: training: 0.688622 validation: 0.738049
09/07 09:24:16 PM: edges-srl-ontonotes_precision: training: 0.850940 validation: 0.877367
09/07 09:24:16 PM: edges-srl-ontonotes_recall: training: 0.721132 validation: 0.756139
09/07 09:24:16 PM: edges-srl-ontonotes_f1: training: 0.780677 validation: 0.812254
09/07 09:24:16 PM: Global learning rate: 0.0001
09/07 09:24:16 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 09:24:19 PM: Update 3036: task edges-srl-ontonotes, batch 36 (3036): mcc: 0.8076, acc: 0.7307, precision: 0.8642, recall: 0.7598, f1: 0.8086, edges-srl-ontonotes_loss: 0.0164
09/07 09:24:30 PM: Update 3132: task edges-srl-ontonotes, batch 132 (3132): mcc: 0.8075, acc: 0.7288, precision: 0.8682, recall: 0.7560, f1: 0.8082, edges-srl-ontonotes_loss: 0.0165
09/07 09:24:40 PM: Update 3242: task edges-srl-ontonotes, batch 242 (3242): mcc: 0.7992, acc: 0.7190, precision: 0.8606, recall: 0.7474, f1: 0.8000, edges-srl-ontonotes_loss: 0.0171
09/07 09:24:50 PM: Update 3352: task edges-srl-ontonotes, batch 352 (3352): mcc: 0.7958, acc: 0.7140, precision: 0.8581, recall: 0.7434, f1: 0.7966, edges-srl-ontonotes_loss: 0.0172
09/07 09:25:00 PM: Update 3446: task edges-srl-ontonotes, batch 446 (3446): mcc: 0.7954, acc: 0.7132, precision: 0.8582, recall: 0.7425, f1: 0.7962, edges-srl-ontonotes_loss: 0.0172
09/07 09:25:10 PM: Update 3561: task edges-srl-ontonotes, batch 561 (3561): mcc: 0.7958, acc: 0.7132, precision: 0.8580, recall: 0.7434, f1: 0.7966, edges-srl-ontonotes_loss: 0.0172
09/07 09:25:20 PM: Update 3668: task edges-srl-ontonotes, batch 668 (3668): mcc: 0.7956, acc: 0.7128, precision: 0.8578, recall: 0.7433, f1: 0.7964, edges-srl-ontonotes_loss: 0.0172
09/07 09:25:30 PM: Update 3767: task edges-srl-ontonotes, batch 767 (3767): mcc: 0.7969, acc: 0.7143, precision: 0.8585, recall: 0.7449, f1: 0.7977, edges-srl-ontonotes_loss: 0.0171
09/07 09:25:40 PM: Update 3877: task edges-srl-ontonotes, batch 877 (3877): mcc: 0.7968, acc: 0.7141, precision: 0.8585, recall: 0.7449, f1: 0.7977, edges-srl-ontonotes_loss: 0.0170
09/07 09:25:50 PM: Update 3985: task edges-srl-ontonotes, batch 985 (3985): mcc: 0.7969, acc: 0.7142, precision: 0.8584, recall: 0.7451, f1: 0.7978, edges-srl-ontonotes_loss: 0.0170
09/07 09:25:51 PM: ***** Step 4000 / Validation 4 *****
09/07 09:25:51 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:25:51 PM: Validating...
09/07 09:26:02 PM: Evaluate: task edges-srl-ontonotes, batch 91 (157): mcc: 0.8120, acc: 0.7396, precision: 0.8775, recall: 0.7564, f1: 0.8124, edges-srl-ontonotes_loss: 0.0159
09/07 09:26:08 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:26:08 PM: Best result seen so far for macro.
09/07 09:26:08 PM: Updating LR scheduler:
09/07 09:26:08 PM: 	Best result seen so far for macro_avg: 0.822
09/07 09:26:08 PM: 	# validation passes without improvement: 0
09/07 09:26:08 PM: edges-srl-ontonotes_loss: training: 0.017025 validation: 0.015343
09/07 09:26:08 PM: macro_avg: validation: 0.821552
09/07 09:26:08 PM: micro_avg: validation: 0.000000
09/07 09:26:08 PM: edges-srl-ontonotes_mcc: training: 0.796687 validation: 0.821091
09/07 09:26:08 PM: edges-srl-ontonotes_acc: training: 0.713999 validation: 0.751982
09/07 09:26:08 PM: edges-srl-ontonotes_precision: training: 0.858153 validation: 0.883651
09/07 09:26:08 PM: edges-srl-ontonotes_recall: training: 0.744909 validation: 0.767608
09/07 09:26:08 PM: edges-srl-ontonotes_f1: training: 0.797531 validation: 0.821552
09/07 09:26:08 PM: Global learning rate: 0.0001
09/07 09:26:08 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 09:26:12 PM: Update 4041: task edges-srl-ontonotes, batch 41 (4041): mcc: 0.8020, acc: 0.7199, precision: 0.8592, recall: 0.7538, f1: 0.8030, edges-srl-ontonotes_loss: 0.0169
09/07 09:26:22 PM: Update 4136: task edges-srl-ontonotes, batch 136 (4136): mcc: 0.8018, acc: 0.7236, precision: 0.8576, recall: 0.7549, f1: 0.8030, edges-srl-ontonotes_loss: 0.0167
09/07 09:26:32 PM: Update 4243: task edges-srl-ontonotes, batch 243 (4243): mcc: 0.8045, acc: 0.7267, precision: 0.8593, recall: 0.7584, f1: 0.8057, edges-srl-ontonotes_loss: 0.0164
09/07 09:26:42 PM: Update 4354: task edges-srl-ontonotes, batch 354 (4354): mcc: 0.8088, acc: 0.7328, precision: 0.8623, recall: 0.7636, f1: 0.8100, edges-srl-ontonotes_loss: 0.0161
09/07 09:26:52 PM: Update 4452: task edges-srl-ontonotes, batch 452 (4452): mcc: 0.8097, acc: 0.7337, precision: 0.8632, recall: 0.7645, f1: 0.8109, edges-srl-ontonotes_loss: 0.0160
09/07 09:27:02 PM: Update 4563: task edges-srl-ontonotes, batch 563 (4563): mcc: 0.8110, acc: 0.7356, precision: 0.8641, recall: 0.7661, f1: 0.8122, edges-srl-ontonotes_loss: 0.0158
09/07 09:27:12 PM: Update 4672: task edges-srl-ontonotes, batch 672 (4672): mcc: 0.8111, acc: 0.7359, precision: 0.8644, recall: 0.7661, f1: 0.8123, edges-srl-ontonotes_loss: 0.0158
09/07 09:27:22 PM: Update 4759: task edges-srl-ontonotes, batch 759 (4759): mcc: 0.8085, acc: 0.7329, precision: 0.8628, recall: 0.7627, f1: 0.8097, edges-srl-ontonotes_loss: 0.0160
09/07 09:27:32 PM: Update 4859: task edges-srl-ontonotes, batch 859 (4859): mcc: 0.8074, acc: 0.7315, precision: 0.8622, recall: 0.7611, f1: 0.8085, edges-srl-ontonotes_loss: 0.0161
09/07 09:27:42 PM: Update 4956: task edges-srl-ontonotes, batch 956 (4956): mcc: 0.8066, acc: 0.7303, precision: 0.8618, recall: 0.7600, f1: 0.8078, edges-srl-ontonotes_loss: 0.0161
09/07 09:27:47 PM: ***** Step 5000 / Validation 5 *****
09/07 09:27:47 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:27:47 PM: Validating...
09/07 09:27:52 PM: Evaluate: task edges-srl-ontonotes, batch 61 (157): mcc: 0.8095, acc: 0.7359, precision: 0.8734, recall: 0.7552, f1: 0.8100, edges-srl-ontonotes_loss: 0.0159
09/07 09:28:01 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:28:01 PM: Best result seen so far for macro.
09/07 09:28:01 PM: Updating LR scheduler:
09/07 09:28:01 PM: 	Best result seen so far for macro_avg: 0.824
09/07 09:28:01 PM: 	# validation passes without improvement: 0
09/07 09:28:01 PM: edges-srl-ontonotes_loss: training: 0.016134 validation: 0.014844
09/07 09:28:01 PM: macro_avg: validation: 0.824494
09/07 09:28:01 PM: micro_avg: validation: 0.000000
09/07 09:28:01 PM: edges-srl-ontonotes_mcc: training: 0.806489 validation: 0.823804
09/07 09:28:01 PM: edges-srl-ontonotes_acc: training: 0.729983 validation: 0.756062
09/07 09:28:01 PM: edges-srl-ontonotes_precision: training: 0.861841 validation: 0.882441
09/07 09:28:01 PM: edges-srl-ontonotes_recall: training: 0.759810 validation: 0.773689
09/07 09:28:01 PM: edges-srl-ontonotes_f1: training: 0.807615 validation: 0.824494
09/07 09:28:01 PM: Global learning rate: 0.0001
09/07 09:28:01 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 09:28:05 PM: Update 5009: task edges-srl-ontonotes, batch 9 (5009): mcc: 0.7941, acc: 0.7211, precision: 0.8462, recall: 0.7507, f1: 0.7956, edges-srl-ontonotes_loss: 0.0174
09/07 09:28:15 PM: Update 5128: task edges-srl-ontonotes, batch 128 (5128): mcc: 0.8227, acc: 0.7493, precision: 0.8720, recall: 0.7810, f1: 0.8240, edges-srl-ontonotes_loss: 0.0146
09/07 09:28:25 PM: Update 5250: task edges-srl-ontonotes, batch 250 (5250): mcc: 0.8272, acc: 0.7556, precision: 0.8747, recall: 0.7869, f1: 0.8285, edges-srl-ontonotes_loss: 0.0144
09/07 09:28:35 PM: Update 5359: task edges-srl-ontonotes, batch 359 (5359): mcc: 0.8355, acc: 0.7663, precision: 0.8817, recall: 0.7962, f1: 0.8368, edges-srl-ontonotes_loss: 0.0139
09/07 09:28:45 PM: Update 5492: task edges-srl-ontonotes, batch 492 (5492): mcc: 0.8449, acc: 0.7780, precision: 0.8886, recall: 0.8075, f1: 0.8462, edges-srl-ontonotes_loss: 0.0133
09/07 09:28:55 PM: Update 5628: task edges-srl-ontonotes, batch 628 (5628): mcc: 0.8532, acc: 0.7893, precision: 0.8948, recall: 0.8175, f1: 0.8544, edges-srl-ontonotes_loss: 0.0127
09/07 09:29:05 PM: Update 5742: task edges-srl-ontonotes, batch 742 (5742): mcc: 0.8563, acc: 0.7935, precision: 0.8972, recall: 0.8213, f1: 0.8576, edges-srl-ontonotes_loss: 0.0125
09/07 09:29:15 PM: Update 5876: task edges-srl-ontonotes, batch 876 (5876): mcc: 0.8604, acc: 0.7992, precision: 0.9001, recall: 0.8263, f1: 0.8616, edges-srl-ontonotes_loss: 0.0122
09/07 09:29:25 PM: Update 5968: task edges-srl-ontonotes, batch 968 (5968): mcc: 0.8621, acc: 0.8017, precision: 0.9013, recall: 0.8284, f1: 0.8633, edges-srl-ontonotes_loss: 0.0121
09/07 09:29:28 PM: ***** Step 6000 / Validation 6 *****
09/07 09:29:28 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:29:28 PM: Validating...
09/07 09:29:35 PM: Evaluate: task edges-srl-ontonotes, batch 83 (157): mcc: 0.8355, acc: 0.7773, precision: 0.8914, recall: 0.7875, f1: 0.8362, edges-srl-ontonotes_loss: 0.0141
09/07 09:29:42 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:29:42 PM: Best result seen so far for macro.
09/07 09:29:42 PM: Updating LR scheduler:
09/07 09:29:42 PM: 	Best result seen so far for macro_avg: 0.844
09/07 09:29:42 PM: 	# validation passes without improvement: 0
09/07 09:29:42 PM: edges-srl-ontonotes_loss: training: 0.012101 validation: 0.013609
09/07 09:29:42 PM: macro_avg: validation: 0.844084
09/07 09:29:42 PM: micro_avg: validation: 0.000000
09/07 09:29:42 PM: edges-srl-ontonotes_mcc: training: 0.862858 validation: 0.843360
09/07 09:29:42 PM: edges-srl-ontonotes_acc: training: 0.802745 validation: 0.786545
09/07 09:29:42 PM: edges-srl-ontonotes_precision: training: 0.901689 validation: 0.897356
09/07 09:29:42 PM: edges-srl-ontonotes_recall: training: 0.829496 validation: 0.796782
09/07 09:29:42 PM: edges-srl-ontonotes_f1: training: 0.864087 validation: 0.844084
09/07 09:29:42 PM: Global learning rate: 0.0001
09/07 09:29:42 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 09:29:45 PM: Update 6041: task edges-srl-ontonotes, batch 41 (6041): mcc: 0.8833, acc: 0.8338, precision: 0.9181, recall: 0.8530, f1: 0.8844, edges-srl-ontonotes_loss: 0.0107
09/07 09:29:55 PM: Update 6174: task edges-srl-ontonotes, batch 174 (6174): mcc: 0.8800, acc: 0.8286, precision: 0.9140, recall: 0.8506, f1: 0.8812, edges-srl-ontonotes_loss: 0.0109
09/07 09:30:05 PM: Update 6291: task edges-srl-ontonotes, batch 291 (6291): mcc: 0.8812, acc: 0.8305, precision: 0.9138, recall: 0.8530, f1: 0.8824, edges-srl-ontonotes_loss: 0.0108
09/07 09:30:15 PM: Update 6425: task edges-srl-ontonotes, batch 425 (6425): mcc: 0.8811, acc: 0.8310, precision: 0.9131, recall: 0.8536, f1: 0.8824, edges-srl-ontonotes_loss: 0.0108
09/07 09:30:25 PM: Update 6562: task edges-srl-ontonotes, batch 562 (6562): mcc: 0.8820, acc: 0.8328, precision: 0.9129, recall: 0.8556, f1: 0.8833, edges-srl-ontonotes_loss: 0.0107
09/07 09:30:36 PM: Update 6661: task edges-srl-ontonotes, batch 661 (6661): mcc: 0.8753, acc: 0.8238, precision: 0.9076, recall: 0.8477, f1: 0.8766, edges-srl-ontonotes_loss: 0.0112
09/07 09:30:46 PM: Update 6777: task edges-srl-ontonotes, batch 777 (6777): mcc: 0.8709, acc: 0.8180, precision: 0.9042, recall: 0.8424, f1: 0.8722, edges-srl-ontonotes_loss: 0.0116
09/07 09:30:56 PM: Update 6885: task edges-srl-ontonotes, batch 885 (6885): mcc: 0.8675, acc: 0.8136, precision: 0.9019, recall: 0.8381, f1: 0.8688, edges-srl-ontonotes_loss: 0.0118
09/07 09:31:06 PM: Update 6980: task edges-srl-ontonotes, batch 980 (6980): mcc: 0.8618, acc: 0.8058, precision: 0.8976, recall: 0.8312, f1: 0.8631, edges-srl-ontonotes_loss: 0.0122
09/07 09:31:08 PM: ***** Step 7000 / Validation 7 *****
09/07 09:31:08 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:31:08 PM: Validating...
09/07 09:31:16 PM: Evaluate: task edges-srl-ontonotes, batch 89 (157): mcc: 0.8515, acc: 0.7968, precision: 0.8980, recall: 0.8114, f1: 0.8525, edges-srl-ontonotes_loss: 0.0129
09/07 09:31:24 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:31:24 PM: Best result seen so far for macro.
09/07 09:31:24 PM: Updating LR scheduler:
09/07 09:31:24 PM: 	Best result seen so far for macro_avg: 0.855
09/07 09:31:24 PM: 	# validation passes without improvement: 0
09/07 09:31:24 PM: edges-srl-ontonotes_loss: training: 0.012267 validation: 0.012675
09/07 09:31:24 PM: macro_avg: validation: 0.854845
09/07 09:31:24 PM: micro_avg: validation: 0.000000
09/07 09:31:24 PM: edges-srl-ontonotes_mcc: training: 0.860867 validation: 0.853835
09/07 09:31:24 PM: edges-srl-ontonotes_acc: training: 0.804582 validation: 0.800939
09/07 09:31:24 PM: edges-srl-ontonotes_precision: training: 0.896947 validation: 0.900068
09/07 09:31:24 PM: edges-srl-ontonotes_recall: training: 0.830118 validation: 0.813948
09/07 09:31:24 PM: edges-srl-ontonotes_f1: training: 0.862239 validation: 0.854845
09/07 09:31:24 PM: Global learning rate: 0.0001
09/07 09:31:24 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 09:31:26 PM: Update 7019: task edges-srl-ontonotes, batch 19 (7019): mcc: 0.8141, acc: 0.7392, precision: 0.8641, recall: 0.7720, f1: 0.8154, edges-srl-ontonotes_loss: 0.0155
09/07 09:31:36 PM: Update 7133: task edges-srl-ontonotes, batch 133 (7133): mcc: 0.8250, acc: 0.7541, precision: 0.8718, recall: 0.7855, f1: 0.8264, edges-srl-ontonotes_loss: 0.0148
09/07 09:31:46 PM: Update 7238: task edges-srl-ontonotes, batch 238 (7238): mcc: 0.8247, acc: 0.7541, precision: 0.8716, recall: 0.7852, f1: 0.8261, edges-srl-ontonotes_loss: 0.0148
09/07 09:31:56 PM: Update 7346: task edges-srl-ontonotes, batch 346 (7346): mcc: 0.8296, acc: 0.7615, precision: 0.8759, recall: 0.7904, f1: 0.8309, edges-srl-ontonotes_loss: 0.0144
09/07 09:32:06 PM: Update 7463: task edges-srl-ontonotes, batch 463 (7463): mcc: 0.8346, acc: 0.7684, precision: 0.8788, recall: 0.7971, f1: 0.8360, edges-srl-ontonotes_loss: 0.0140
09/07 09:32:16 PM: Update 7566: task edges-srl-ontonotes, batch 566 (7566): mcc: 0.8391, acc: 0.7744, precision: 0.8823, recall: 0.8024, f1: 0.8404, edges-srl-ontonotes_loss: 0.0137
09/07 09:32:26 PM: Update 7683: task edges-srl-ontonotes, batch 683 (7683): mcc: 0.8424, acc: 0.7787, precision: 0.8842, recall: 0.8068, f1: 0.8438, edges-srl-ontonotes_loss: 0.0134
09/07 09:32:36 PM: Update 7800: task edges-srl-ontonotes, batch 800 (7800): mcc: 0.8449, acc: 0.7822, precision: 0.8858, recall: 0.8103, f1: 0.8463, edges-srl-ontonotes_loss: 0.0132
09/07 09:32:46 PM: Update 7905: task edges-srl-ontonotes, batch 905 (7905): mcc: 0.8462, acc: 0.7837, precision: 0.8869, recall: 0.8117, f1: 0.8476, edges-srl-ontonotes_loss: 0.0131
09/07 09:32:54 PM: ***** Step 8000 / Validation 8 *****
09/07 09:32:54 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:32:54 PM: Validating...
09/07 09:32:56 PM: Evaluate: task edges-srl-ontonotes, batch 21 (157): mcc: 0.8782, acc: 0.8344, precision: 0.9135, recall: 0.8477, f1: 0.8794, edges-srl-ontonotes_loss: 0.0109
09/07 09:33:06 PM: Evaluate: task edges-srl-ontonotes, batch 129 (157): mcc: 0.8703, acc: 0.8275, precision: 0.9057, recall: 0.8400, f1: 0.8716, edges-srl-ontonotes_loss: 0.0111
09/07 09:33:09 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:33:09 PM: Best result seen so far for macro.
09/07 09:33:09 PM: Updating LR scheduler:
09/07 09:33:09 PM: 	Best result seen so far for macro_avg: 0.867
09/07 09:33:09 PM: 	# validation passes without improvement: 0
09/07 09:33:09 PM: edges-srl-ontonotes_loss: training: 0.013166 validation: 0.011573
09/07 09:33:09 PM: macro_avg: validation: 0.867110
09/07 09:33:09 PM: micro_avg: validation: 0.000000
09/07 09:33:09 PM: edges-srl-ontonotes_mcc: training: 0.846062 validation: 0.865885
09/07 09:33:09 PM: edges-srl-ontonotes_acc: training: 0.783717 validation: 0.820953
09/07 09:33:09 PM: edges-srl-ontonotes_precision: training: 0.886490 validation: 0.903816
09/07 09:33:09 PM: edges-srl-ontonotes_recall: training: 0.811720 validation: 0.833269
09/07 09:33:09 PM: edges-srl-ontonotes_f1: training: 0.847459 validation: 0.867110
09/07 09:33:09 PM: Global learning rate: 0.0001
09/07 09:33:09 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 09:33:16 PM: Update 8089: task edges-srl-ontonotes, batch 89 (8089): mcc: 0.8455, acc: 0.7850, precision: 0.8832, recall: 0.8136, f1: 0.8470, edges-srl-ontonotes_loss: 0.0133
09/07 09:33:28 PM: Update 8186: task edges-srl-ontonotes, batch 186 (8186): mcc: 0.8404, acc: 0.7793, precision: 0.8791, recall: 0.8079, f1: 0.8420, edges-srl-ontonotes_loss: 0.0135
09/07 09:33:38 PM: Update 8301: task edges-srl-ontonotes, batch 301 (8301): mcc: 0.8355, acc: 0.7723, precision: 0.8762, recall: 0.8012, f1: 0.8370, edges-srl-ontonotes_loss: 0.0139
09/07 09:33:48 PM: Update 8417: task edges-srl-ontonotes, batch 417 (8417): mcc: 0.8322, acc: 0.7667, precision: 0.8750, recall: 0.7961, f1: 0.8336, edges-srl-ontonotes_loss: 0.0142
09/07 09:33:58 PM: Update 8517: task edges-srl-ontonotes, batch 517 (8517): mcc: 0.8313, acc: 0.7652, precision: 0.8748, recall: 0.7946, f1: 0.8327, edges-srl-ontonotes_loss: 0.0142
09/07 09:34:08 PM: Update 8627: task edges-srl-ontonotes, batch 627 (8627): mcc: 0.8303, acc: 0.7643, precision: 0.8742, recall: 0.7933, f1: 0.8318, edges-srl-ontonotes_loss: 0.0142
09/07 09:34:18 PM: Update 8738: task edges-srl-ontonotes, batch 738 (8738): mcc: 0.8309, acc: 0.7654, precision: 0.8742, recall: 0.7944, f1: 0.8324, edges-srl-ontonotes_loss: 0.0141
09/07 09:34:28 PM: Update 8839: task edges-srl-ontonotes, batch 839 (8839): mcc: 0.8305, acc: 0.7648, precision: 0.8736, recall: 0.7941, f1: 0.8320, edges-srl-ontonotes_loss: 0.0141
09/07 09:34:38 PM: Update 8944: task edges-srl-ontonotes, batch 944 (8944): mcc: 0.8265, acc: 0.7600, precision: 0.8708, recall: 0.7892, f1: 0.8280, edges-srl-ontonotes_loss: 0.0144
09/07 09:34:43 PM: ***** Step 9000 / Validation 9 *****
09/07 09:34:43 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:34:43 PM: Validating...
09/07 09:34:48 PM: Evaluate: task edges-srl-ontonotes, batch 54 (157): mcc: 0.8513, acc: 0.8004, precision: 0.8959, recall: 0.8130, f1: 0.8524, edges-srl-ontonotes_loss: 0.0124
09/07 09:34:58 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:34:58 PM: Best result seen so far for macro.
09/07 09:34:58 PM: Updating LR scheduler:
09/07 09:34:58 PM: 	Best result seen so far for macro_avg: 0.868
09/07 09:34:58 PM: 	# validation passes without improvement: 0
09/07 09:34:58 PM: edges-srl-ontonotes_loss: training: 0.014455 validation: 0.011352
09/07 09:34:58 PM: macro_avg: validation: 0.867918
09/07 09:34:58 PM: micro_avg: validation: 0.000000
09/07 09:34:58 PM: edges-srl-ontonotes_mcc: training: 0.824909 validation: 0.866869
09/07 09:34:58 PM: edges-srl-ontonotes_acc: training: 0.757931 validation: 0.819029
09/07 09:34:58 PM: edges-srl-ontonotes_precision: training: 0.869559 validation: 0.908502
09/07 09:34:58 PM: edges-srl-ontonotes_recall: training: 0.787320 validation: 0.830806
09/07 09:34:58 PM: edges-srl-ontonotes_f1: training: 0.826399 validation: 0.867918
09/07 09:34:58 PM: Global learning rate: 0.0001
09/07 09:34:58 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 09:34:58 PM: Update 9004: task edges-srl-ontonotes, batch 4 (9004): mcc: 0.8091, acc: 0.7383, precision: 0.8515, recall: 0.7741, f1: 0.8110, edges-srl-ontonotes_loss: 0.0160
09/07 09:35:08 PM: Update 9114: task edges-srl-ontonotes, batch 114 (9114): mcc: 0.8127, acc: 0.7424, precision: 0.8616, recall: 0.7716, f1: 0.8141, edges-srl-ontonotes_loss: 0.0152
09/07 09:35:18 PM: Update 9189: task edges-srl-ontonotes, batch 189 (9189): mcc: 0.8093, acc: 0.7375, precision: 0.8577, recall: 0.7687, f1: 0.8108, edges-srl-ontonotes_loss: 0.0155
09/07 09:35:28 PM: Update 9299: task edges-srl-ontonotes, batch 299 (9299): mcc: 0.8103, acc: 0.7389, precision: 0.8591, recall: 0.7694, f1: 0.8118, edges-srl-ontonotes_loss: 0.0154
09/07 09:35:38 PM: Update 9408: task edges-srl-ontonotes, batch 408 (9408): mcc: 0.8099, acc: 0.7393, precision: 0.8589, recall: 0.7689, f1: 0.8114, edges-srl-ontonotes_loss: 0.0154
09/07 09:35:48 PM: Update 9499: task edges-srl-ontonotes, batch 499 (9499): mcc: 0.8123, acc: 0.7422, precision: 0.8606, recall: 0.7717, f1: 0.8137, edges-srl-ontonotes_loss: 0.0152
09/07 09:35:58 PM: Update 9604: task edges-srl-ontonotes, batch 604 (9604): mcc: 0.8168, acc: 0.7480, precision: 0.8641, recall: 0.7771, f1: 0.8183, edges-srl-ontonotes_loss: 0.0149
09/07 09:36:08 PM: Update 9710: task edges-srl-ontonotes, batch 710 (9710): mcc: 0.8185, acc: 0.7500, precision: 0.8650, recall: 0.7795, f1: 0.8200, edges-srl-ontonotes_loss: 0.0148
09/07 09:36:18 PM: Update 9806: task edges-srl-ontonotes, batch 806 (9806): mcc: 0.8204, acc: 0.7524, precision: 0.8663, recall: 0.7818, f1: 0.8219, edges-srl-ontonotes_loss: 0.0147
09/07 09:36:29 PM: Update 9916: task edges-srl-ontonotes, batch 916 (9916): mcc: 0.8227, acc: 0.7553, precision: 0.8682, recall: 0.7845, f1: 0.8242, edges-srl-ontonotes_loss: 0.0145
09/07 09:36:37 PM: ***** Step 10000 / Validation 10 *****
09/07 09:36:37 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:36:37 PM: Validating...
09/07 09:36:39 PM: Evaluate: task edges-srl-ontonotes, batch 20 (157): mcc: 0.8667, acc: 0.8181, precision: 0.9144, recall: 0.8251, f1: 0.8674, edges-srl-ontonotes_loss: 0.0109
09/07 09:36:49 PM: Evaluate: task edges-srl-ontonotes, batch 127 (157): mcc: 0.8621, acc: 0.8155, precision: 0.9043, recall: 0.8256, f1: 0.8632, edges-srl-ontonotes_loss: 0.0115
09/07 09:36:52 PM: Updating LR scheduler:
09/07 09:36:52 PM: 	Best result seen so far for macro_avg: 0.868
09/07 09:36:52 PM: 	# validation passes without improvement: 1
09/07 09:36:52 PM: edges-srl-ontonotes_loss: training: 0.014430 validation: 0.011687
09/07 09:36:52 PM: macro_avg: validation: 0.860967
09/07 09:36:52 PM: micro_avg: validation: 0.000000
09/07 09:36:52 PM: edges-srl-ontonotes_mcc: training: 0.823533 validation: 0.859924
09/07 09:36:52 PM: edges-srl-ontonotes_acc: training: 0.756272 validation: 0.812178
09/07 09:36:52 PM: edges-srl-ontonotes_precision: training: 0.868797 validation: 0.903775
09/07 09:36:52 PM: edges-srl-ontonotes_recall: training: 0.785425 validation: 0.822031
09/07 09:36:52 PM: edges-srl-ontonotes_f1: training: 0.825010 validation: 0.860967
09/07 09:36:52 PM: Global learning rate: 0.0001
09/07 09:36:52 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 09:37:01 PM: Update 10064: task edges-srl-ontonotes, batch 64 (10064): mcc: 0.8416, acc: 0.7804, precision: 0.8856, recall: 0.8041, f1: 0.8429, edges-srl-ontonotes_loss: 0.0136
09/07 09:37:11 PM: Update 10169: task edges-srl-ontonotes, batch 169 (10169): mcc: 0.8469, acc: 0.7878, precision: 0.8872, recall: 0.8127, f1: 0.8483, edges-srl-ontonotes_loss: 0.0131
09/07 09:37:21 PM: Update 10277: task edges-srl-ontonotes, batch 277 (10277): mcc: 0.8465, acc: 0.7863, precision: 0.8878, recall: 0.8112, f1: 0.8478, edges-srl-ontonotes_loss: 0.0131
09/07 09:37:31 PM: Update 10377: task edges-srl-ontonotes, batch 377 (10377): mcc: 0.8455, acc: 0.7858, precision: 0.8861, recall: 0.8110, f1: 0.8469, edges-srl-ontonotes_loss: 0.0131
09/07 09:37:41 PM: Update 10485: task edges-srl-ontonotes, batch 485 (10485): mcc: 0.8425, acc: 0.7816, precision: 0.8842, recall: 0.8071, f1: 0.8439, edges-srl-ontonotes_loss: 0.0133
09/07 09:37:51 PM: Update 10592: task edges-srl-ontonotes, batch 592 (10592): mcc: 0.8400, acc: 0.7776, precision: 0.8825, recall: 0.8039, f1: 0.8414, edges-srl-ontonotes_loss: 0.0134
09/07 09:38:01 PM: Update 10690: task edges-srl-ontonotes, batch 690 (10690): mcc: 0.8393, acc: 0.7766, precision: 0.8822, recall: 0.8029, f1: 0.8407, edges-srl-ontonotes_loss: 0.0135
09/07 09:38:11 PM: Update 10799: task edges-srl-ontonotes, batch 799 (10799): mcc: 0.8380, acc: 0.7744, precision: 0.8811, recall: 0.8014, f1: 0.8393, edges-srl-ontonotes_loss: 0.0135
09/07 09:38:21 PM: Update 10909: task edges-srl-ontonotes, batch 909 (10909): mcc: 0.8378, acc: 0.7745, precision: 0.8811, recall: 0.8011, f1: 0.8392, edges-srl-ontonotes_loss: 0.0136
09/07 09:38:30 PM: ***** Step 11000 / Validation 11 *****
09/07 09:38:30 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:38:30 PM: Validating...
09/07 09:38:31 PM: Evaluate: task edges-srl-ontonotes, batch 17 (157): mcc: 0.8520, acc: 0.8014, precision: 0.8921, recall: 0.8179, f1: 0.8534, edges-srl-ontonotes_loss: 0.0122
09/07 09:38:41 PM: Evaluate: task edges-srl-ontonotes, batch 125 (157): mcc: 0.8546, acc: 0.8096, precision: 0.8939, recall: 0.8211, f1: 0.8560, edges-srl-ontonotes_loss: 0.0121
09/07 09:38:44 PM: Updating LR scheduler:
09/07 09:38:44 PM: 	Best result seen so far for macro_avg: 0.868
09/07 09:38:44 PM: 	# validation passes without improvement: 2
09/07 09:38:44 PM: edges-srl-ontonotes_loss: training: 0.013561 validation: 0.012151
09/07 09:38:44 PM: macro_avg: validation: 0.854813
09/07 09:38:44 PM: micro_avg: validation: 0.000000
09/07 09:38:44 PM: edges-srl-ontonotes_mcc: training: 0.837737 validation: 0.853510
09/07 09:38:44 PM: edges-srl-ontonotes_acc: training: 0.774257 validation: 0.807097
09/07 09:38:44 PM: edges-srl-ontonotes_precision: training: 0.881176 validation: 0.893685
09/07 09:38:44 PM: edges-srl-ontonotes_recall: training: 0.800876 validation: 0.819183
09/07 09:38:44 PM: edges-srl-ontonotes_f1: training: 0.839109 validation: 0.854813
09/07 09:38:44 PM: Global learning rate: 0.0001
09/07 09:38:44 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 09:38:52 PM: Update 11067: task edges-srl-ontonotes, batch 67 (11067): mcc: 0.8313, acc: 0.7643, precision: 0.8774, recall: 0.7921, f1: 0.8326, edges-srl-ontonotes_loss: 0.0137
09/07 09:39:02 PM: Update 11178: task edges-srl-ontonotes, batch 178 (11178): mcc: 0.8303, acc: 0.7648, precision: 0.8758, recall: 0.7918, f1: 0.8317, edges-srl-ontonotes_loss: 0.0139
09/07 09:39:12 PM: Update 11288: task edges-srl-ontonotes, batch 288 (11288): mcc: 0.8327, acc: 0.7691, precision: 0.8769, recall: 0.7952, f1: 0.8341, edges-srl-ontonotes_loss: 0.0137
09/07 09:39:22 PM: Update 11361: task edges-srl-ontonotes, batch 361 (11361): mcc: 0.8321, acc: 0.7685, precision: 0.8759, recall: 0.7952, f1: 0.8336, edges-srl-ontonotes_loss: 0.0138
09/07 09:39:32 PM: Update 11471: task edges-srl-ontonotes, batch 471 (11471): mcc: 0.8346, acc: 0.7719, precision: 0.8773, recall: 0.7985, f1: 0.8361, edges-srl-ontonotes_loss: 0.0136
09/07 09:39:42 PM: Update 11581: task edges-srl-ontonotes, batch 581 (11581): mcc: 0.8367, acc: 0.7745, precision: 0.8788, recall: 0.8012, f1: 0.8382, edges-srl-ontonotes_loss: 0.0135
09/07 09:39:52 PM: Update 11678: task edges-srl-ontonotes, batch 678 (11678): mcc: 0.8379, acc: 0.7756, precision: 0.8802, recall: 0.8022, f1: 0.8393, edges-srl-ontonotes_loss: 0.0134
09/07 09:40:02 PM: Update 11787: task edges-srl-ontonotes, batch 787 (11787): mcc: 0.8388, acc: 0.7765, precision: 0.8808, recall: 0.8033, f1: 0.8402, edges-srl-ontonotes_loss: 0.0134
09/07 09:40:12 PM: Update 11897: task edges-srl-ontonotes, batch 897 (11897): mcc: 0.8400, acc: 0.7782, precision: 0.8815, recall: 0.8048, f1: 0.8414, edges-srl-ontonotes_loss: 0.0133
09/07 09:40:22 PM: Update 11986: task edges-srl-ontonotes, batch 986 (11986): mcc: 0.8386, acc: 0.7763, precision: 0.8807, recall: 0.8030, f1: 0.8401, edges-srl-ontonotes_loss: 0.0134
09/07 09:40:23 PM: ***** Step 12000 / Validation 12 *****
09/07 09:40:23 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:40:23 PM: Validating...
09/07 09:40:32 PM: Evaluate: task edges-srl-ontonotes, batch 96 (157): mcc: 0.8551, acc: 0.8057, precision: 0.8995, recall: 0.8168, f1: 0.8561, edges-srl-ontonotes_loss: 0.0122
09/07 09:40:38 PM: Updating LR scheduler:
09/07 09:40:38 PM: 	Best result seen so far for macro_avg: 0.868
09/07 09:40:38 PM: 	# validation passes without improvement: 3
09/07 09:40:38 PM: edges-srl-ontonotes_loss: training: 0.013391 validation: 0.011939
09/07 09:40:38 PM: macro_avg: validation: 0.858673
09/07 09:40:38 PM: micro_avg: validation: 0.000000
09/07 09:40:38 PM: edges-srl-ontonotes_mcc: training: 0.838445 validation: 0.857541
09/07 09:40:38 PM: edges-srl-ontonotes_acc: training: 0.776103 validation: 0.809791
09/07 09:40:38 PM: edges-srl-ontonotes_precision: training: 0.880544 validation: 0.900211
09/07 09:40:38 PM: edges-srl-ontonotes_recall: training: 0.802791 validation: 0.820799
09/07 09:40:38 PM: edges-srl-ontonotes_f1: training: 0.839872 validation: 0.858673
09/07 09:40:38 PM: Global learning rate: 0.0001
09/07 09:40:38 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 09:40:42 PM: Update 12041: task edges-srl-ontonotes, batch 41 (12041): mcc: 0.8194, acc: 0.7549, precision: 0.8684, recall: 0.7780, f1: 0.8207, edges-srl-ontonotes_loss: 0.0148
09/07 09:40:52 PM: Update 12138: task edges-srl-ontonotes, batch 138 (12138): mcc: 0.8187, acc: 0.7500, precision: 0.8688, recall: 0.7764, f1: 0.8200, edges-srl-ontonotes_loss: 0.0148
09/07 09:41:02 PM: Update 12238: task edges-srl-ontonotes, batch 238 (12238): mcc: 0.8247, acc: 0.7581, precision: 0.8727, recall: 0.7841, f1: 0.8260, edges-srl-ontonotes_loss: 0.0143
09/07 09:41:12 PM: Update 12315: task edges-srl-ontonotes, batch 315 (12315): mcc: 0.8297, acc: 0.7644, precision: 0.8756, recall: 0.7908, f1: 0.8311, edges-srl-ontonotes_loss: 0.0140
09/07 09:41:22 PM: Update 12439: task edges-srl-ontonotes, batch 439 (12439): mcc: 0.8396, acc: 0.7769, precision: 0.8824, recall: 0.8033, f1: 0.8410, edges-srl-ontonotes_loss: 0.0132
09/07 09:41:32 PM: Update 12559: task edges-srl-ontonotes, batch 559 (12559): mcc: 0.8469, acc: 0.7860, precision: 0.8876, recall: 0.8122, f1: 0.8483, edges-srl-ontonotes_loss: 0.0128
09/07 09:41:42 PM: Update 12679: task edges-srl-ontonotes, batch 679 (12679): mcc: 0.8552, acc: 0.7968, precision: 0.8936, recall: 0.8225, f1: 0.8566, edges-srl-ontonotes_loss: 0.0122
09/07 09:41:52 PM: Update 12813: task edges-srl-ontonotes, batch 813 (12813): mcc: 0.8639, acc: 0.8083, precision: 0.9002, recall: 0.8330, f1: 0.8653, edges-srl-ontonotes_loss: 0.0116
09/07 09:42:02 PM: Update 12931: task edges-srl-ontonotes, batch 931 (12931): mcc: 0.8686, acc: 0.8144, precision: 0.9035, recall: 0.8387, f1: 0.8699, edges-srl-ontonotes_loss: 0.0113
09/07 09:42:08 PM: ***** Step 13000 / Validation 13 *****
09/07 09:42:08 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:42:08 PM: Validating...
09/07 09:42:12 PM: Evaluate: task edges-srl-ontonotes, batch 53 (157): mcc: 0.8543, acc: 0.8029, precision: 0.8988, recall: 0.8160, f1: 0.8554, edges-srl-ontonotes_loss: 0.0126
09/07 09:42:22 PM: Updating LR scheduler:
09/07 09:42:22 PM: 	Best result seen so far for macro_avg: 0.868
09/07 09:42:22 PM: 	# validation passes without improvement: 4
09/07 09:42:22 PM: edges-srl-ontonotes_loss: training: 0.011101 validation: 0.011771
09/07 09:42:22 PM: macro_avg: validation: 0.865604
09/07 09:42:22 PM: micro_avg: validation: 0.000000
09/07 09:42:22 PM: edges-srl-ontonotes_mcc: training: 0.870700 validation: 0.864553
09/07 09:42:22 PM: edges-srl-ontonotes_acc: training: 0.817194 validation: 0.816103
09/07 09:42:22 PM: edges-srl-ontonotes_precision: training: 0.904991 validation: 0.906838
09/07 09:42:22 PM: edges-srl-ontonotes_recall: training: 0.841331 validation: 0.827958
09/07 09:42:22 PM: edges-srl-ontonotes_f1: training: 0.872001 validation: 0.865604
09/07 09:42:22 PM: Global learning rate: 0.0001
09/07 09:42:22 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 09:42:23 PM: Update 13004: task edges-srl-ontonotes, batch 4 (13004): mcc: 0.8834, acc: 0.8366, precision: 0.9094, recall: 0.8615, f1: 0.8848, edges-srl-ontonotes_loss: 0.0099
09/07 09:42:33 PM: Update 13133: task edges-srl-ontonotes, batch 133 (13133): mcc: 0.8993, acc: 0.8543, precision: 0.9280, recall: 0.8744, f1: 0.9004, edges-srl-ontonotes_loss: 0.0090
09/07 09:42:43 PM: Update 13226: task edges-srl-ontonotes, batch 226 (13226): mcc: 0.8990, acc: 0.8547, precision: 0.9268, recall: 0.8749, f1: 0.9001, edges-srl-ontonotes_loss: 0.0091
09/07 09:42:53 PM: Update 13359: task edges-srl-ontonotes, batch 359 (13359): mcc: 0.9007, acc: 0.8568, precision: 0.9275, recall: 0.8774, f1: 0.9018, edges-srl-ontonotes_loss: 0.0090
09/07 09:43:03 PM: Update 13490: task edges-srl-ontonotes, batch 490 (13490): mcc: 0.9002, acc: 0.8569, precision: 0.9263, recall: 0.8776, f1: 0.9013, edges-srl-ontonotes_loss: 0.0090
09/07 09:43:13 PM: Update 13611: task edges-srl-ontonotes, batch 611 (13611): mcc: 0.8994, acc: 0.8566, precision: 0.9255, recall: 0.8769, f1: 0.9005, edges-srl-ontonotes_loss: 0.0091
09/07 09:43:23 PM: Update 13745: task edges-srl-ontonotes, batch 745 (13745): mcc: 0.8986, acc: 0.8561, precision: 0.9245, recall: 0.8763, f1: 0.8998, edges-srl-ontonotes_loss: 0.0092
09/07 09:43:33 PM: Update 13855: task edges-srl-ontonotes, batch 855 (13855): mcc: 0.8971, acc: 0.8546, precision: 0.9231, recall: 0.8747, f1: 0.8983, edges-srl-ontonotes_loss: 0.0093
09/07 09:43:43 PM: Update 13968: task edges-srl-ontonotes, batch 968 (13968): mcc: 0.8919, acc: 0.8478, precision: 0.9193, recall: 0.8685, f1: 0.8932, edges-srl-ontonotes_loss: 0.0096
09/07 09:43:46 PM: ***** Step 14000 / Validation 14 *****
09/07 09:43:46 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:43:46 PM: Validating...
09/07 09:43:53 PM: Evaluate: task edges-srl-ontonotes, batch 76 (157): mcc: 0.8670, acc: 0.8232, precision: 0.9057, recall: 0.8337, f1: 0.8682, edges-srl-ontonotes_loss: 0.0116
09/07 09:44:01 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:44:01 PM: Best result seen so far for macro.
09/07 09:44:01 PM: Updating LR scheduler:
09/07 09:44:01 PM: 	Best result seen so far for macro_avg: 0.873
09/07 09:44:01 PM: 	# validation passes without improvement: 0
09/07 09:44:01 PM: edges-srl-ontonotes_loss: training: 0.009696 validation: 0.011136
09/07 09:44:01 PM: macro_avg: validation: 0.873105
09/07 09:44:01 PM: micro_avg: validation: 0.000000
09/07 09:44:01 PM: edges-srl-ontonotes_mcc: training: 0.890871 validation: 0.871916
09/07 09:44:01 PM: edges-srl-ontonotes_acc: training: 0.846426 validation: 0.829728
09/07 09:44:01 PM: edges-srl-ontonotes_precision: training: 0.918442 validation: 0.908607
09/07 09:44:01 PM: edges-srl-ontonotes_recall: training: 0.867236 validation: 0.840274
09/07 09:44:01 PM: edges-srl-ontonotes_f1: training: 0.892105 validation: 0.873105
09/07 09:44:01 PM: Global learning rate: 0.0001
09/07 09:44:01 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 09:44:03 PM: Update 14029: task edges-srl-ontonotes, batch 29 (14029): mcc: 0.8662, acc: 0.8111, precision: 0.8991, recall: 0.8383, f1: 0.8677, edges-srl-ontonotes_loss: 0.0113
09/07 09:44:14 PM: Update 14133: task edges-srl-ontonotes, batch 133 (14133): mcc: 0.8656, acc: 0.8124, precision: 0.8986, recall: 0.8376, f1: 0.8670, edges-srl-ontonotes_loss: 0.0115
09/07 09:44:24 PM: Update 14237: task edges-srl-ontonotes, batch 237 (14237): mcc: 0.8535, acc: 0.7958, precision: 0.8906, recall: 0.8219, f1: 0.8549, edges-srl-ontonotes_loss: 0.0124
09/07 09:44:34 PM: Update 14347: task edges-srl-ontonotes, batch 347 (14347): mcc: 0.8476, acc: 0.7889, precision: 0.8858, recall: 0.8153, f1: 0.8491, edges-srl-ontonotes_loss: 0.0128
09/07 09:44:44 PM: Update 14456: task edges-srl-ontonotes, batch 456 (14456): mcc: 0.8468, acc: 0.7875, precision: 0.8851, recall: 0.8143, f1: 0.8482, edges-srl-ontonotes_loss: 0.0129
09/07 09:44:54 PM: Update 14543: task edges-srl-ontonotes, batch 543 (14543): mcc: 0.8488, acc: 0.7900, precision: 0.8867, recall: 0.8167, f1: 0.8502, edges-srl-ontonotes_loss: 0.0127
09/07 09:45:04 PM: Update 14663: task edges-srl-ontonotes, batch 663 (14663): mcc: 0.8526, acc: 0.7949, precision: 0.8896, recall: 0.8213, f1: 0.8541, edges-srl-ontonotes_loss: 0.0124
09/07 09:45:14 PM: Update 14781: task edges-srl-ontonotes, batch 781 (14781): mcc: 0.8549, acc: 0.7980, precision: 0.8913, recall: 0.8240, f1: 0.8563, edges-srl-ontonotes_loss: 0.0123
09/07 09:45:24 PM: Update 14883: task edges-srl-ontonotes, batch 883 (14883): mcc: 0.8562, acc: 0.7994, precision: 0.8923, recall: 0.8256, f1: 0.8577, edges-srl-ontonotes_loss: 0.0122
09/07 09:45:34 PM: ***** Step 15000 / Validation 15 *****
09/07 09:45:34 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:45:34 PM: Validating...
09/07 09:45:34 PM: Evaluate: task edges-srl-ontonotes, batch 3 (157): mcc: 0.8856, acc: 0.8491, precision: 0.9190, recall: 0.8566, f1: 0.8867, edges-srl-ontonotes_loss: 0.0097
09/07 09:45:44 PM: Evaluate: task edges-srl-ontonotes, batch 113 (157): mcc: 0.8823, acc: 0.8434, precision: 0.9163, recall: 0.8528, f1: 0.8834, edges-srl-ontonotes_loss: 0.0101
09/07 09:45:49 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:45:49 PM: Best result seen so far for macro.
09/07 09:45:49 PM: Updating LR scheduler:
09/07 09:45:49 PM: 	Best result seen so far for macro_avg: 0.883
09/07 09:45:49 PM: 	# validation passes without improvement: 0
09/07 09:45:49 PM: edges-srl-ontonotes_loss: training: 0.012015 validation: 0.010302
09/07 09:45:49 PM: macro_avg: validation: 0.882592
09/07 09:45:49 PM: micro_avg: validation: 0.000000
09/07 09:45:49 PM: edges-srl-ontonotes_mcc: training: 0.858189 validation: 0.881422
09/07 09:45:49 PM: edges-srl-ontonotes_acc: training: 0.802204 validation: 0.842737
09/07 09:45:49 PM: edges-srl-ontonotes_precision: training: 0.893800 validation: 0.915048
09/07 09:45:49 PM: edges-srl-ontonotes_recall: training: 0.827954 validation: 0.852359
09/07 09:45:49 PM: edges-srl-ontonotes_f1: training: 0.859618 validation: 0.882592
09/07 09:45:49 PM: Global learning rate: 0.0001
09/07 09:45:49 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 09:45:54 PM: Update 15068: task edges-srl-ontonotes, batch 68 (15068): mcc: 0.8769, acc: 0.8268, precision: 0.9088, recall: 0.8496, f1: 0.8782, edges-srl-ontonotes_loss: 0.0108
09/07 09:46:04 PM: Update 15169: task edges-srl-ontonotes, batch 169 (15169): mcc: 0.8676, acc: 0.8142, precision: 0.8995, recall: 0.8405, f1: 0.8690, edges-srl-ontonotes_loss: 0.0114
09/07 09:46:14 PM: Update 15287: task edges-srl-ontonotes, batch 287 (15287): mcc: 0.8628, acc: 0.8086, precision: 0.8953, recall: 0.8354, f1: 0.8643, edges-srl-ontonotes_loss: 0.0116
09/07 09:46:24 PM: Update 15404: task edges-srl-ontonotes, batch 404 (15404): mcc: 0.8617, acc: 0.8069, precision: 0.8949, recall: 0.8336, f1: 0.8632, edges-srl-ontonotes_loss: 0.0117
09/07 09:46:35 PM: Update 15485: task edges-srl-ontonotes, batch 485 (15485): mcc: 0.8598, acc: 0.8044, precision: 0.8932, recall: 0.8315, f1: 0.8613, edges-srl-ontonotes_loss: 0.0119
09/07 09:46:45 PM: Update 15597: task edges-srl-ontonotes, batch 597 (15597): mcc: 0.8564, acc: 0.7996, precision: 0.8911, recall: 0.8270, f1: 0.8579, edges-srl-ontonotes_loss: 0.0121
09/07 09:46:55 PM: Update 15716: task edges-srl-ontonotes, batch 716 (15716): mcc: 0.8543, acc: 0.7970, precision: 0.8896, recall: 0.8245, f1: 0.8558, edges-srl-ontonotes_loss: 0.0122
09/07 09:47:05 PM: Update 15815: task edges-srl-ontonotes, batch 815 (15815): mcc: 0.8535, acc: 0.7958, precision: 0.8887, recall: 0.8237, f1: 0.8550, edges-srl-ontonotes_loss: 0.0123
09/07 09:47:15 PM: Update 15926: task edges-srl-ontonotes, batch 926 (15926): mcc: 0.8527, acc: 0.7951, precision: 0.8879, recall: 0.8229, f1: 0.8542, edges-srl-ontonotes_loss: 0.0123
09/07 09:47:21 PM: ***** Step 16000 / Validation 16 *****
09/07 09:47:21 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:47:21 PM: Validating...
09/07 09:47:25 PM: Evaluate: task edges-srl-ontonotes, batch 35 (157): mcc: 0.8782, acc: 0.8417, precision: 0.9075, recall: 0.8533, f1: 0.8796, edges-srl-ontonotes_loss: 0.0105
09/07 09:47:35 PM: Evaluate: task edges-srl-ontonotes, batch 142 (157): mcc: 0.8843, acc: 0.8472, precision: 0.9133, recall: 0.8595, f1: 0.8856, edges-srl-ontonotes_loss: 0.0098
09/07 09:47:36 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:47:36 PM: Best result seen so far for macro.
09/07 09:47:36 PM: Updating LR scheduler:
09/07 09:47:36 PM: 	Best result seen so far for macro_avg: 0.883
09/07 09:47:36 PM: 	# validation passes without improvement: 0
09/07 09:47:36 PM: edges-srl-ontonotes_loss: training: 0.012320 validation: 0.010113
09/07 09:47:36 PM: macro_avg: validation: 0.883042
09/07 09:47:36 PM: micro_avg: validation: 0.000000
09/07 09:47:36 PM: edges-srl-ontonotes_mcc: training: 0.852204 validation: 0.881740
09/07 09:47:36 PM: edges-srl-ontonotes_acc: training: 0.794679 validation: 0.844354
09/07 09:47:36 PM: edges-srl-ontonotes_precision: training: 0.887376 validation: 0.911437
09/07 09:47:36 PM: edges-srl-ontonotes_recall: training: 0.822554 validation: 0.856362
09/07 09:47:36 PM: edges-srl-ontonotes_f1: training: 0.853737 validation: 0.883042
09/07 09:47:36 PM: Global learning rate: 0.0001
09/07 09:47:36 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 09:47:45 PM: Update 16084: task edges-srl-ontonotes, batch 84 (16084): mcc: 0.8485, acc: 0.7886, precision: 0.8862, recall: 0.8166, f1: 0.8500, edges-srl-ontonotes_loss: 0.0125
09/07 09:47:55 PM: Update 16192: task edges-srl-ontonotes, batch 192 (16192): mcc: 0.8271, acc: 0.7635, precision: 0.8689, recall: 0.7919, f1: 0.8287, edges-srl-ontonotes_loss: 0.0140
09/07 09:48:05 PM: Update 16301: task edges-srl-ontonotes, batch 301 (16301): mcc: 0.8262, acc: 0.7618, precision: 0.8681, recall: 0.7910, f1: 0.8278, edges-srl-ontonotes_loss: 0.0140
09/07 09:48:15 PM: Update 16394: task edges-srl-ontonotes, batch 394 (16394): mcc: 0.8252, acc: 0.7605, precision: 0.8685, recall: 0.7889, f1: 0.8268, edges-srl-ontonotes_loss: 0.0141
09/07 09:48:25 PM: Update 16506: task edges-srl-ontonotes, batch 506 (16506): mcc: 0.8256, acc: 0.7607, precision: 0.8687, recall: 0.7895, f1: 0.8272, edges-srl-ontonotes_loss: 0.0141
09/07 09:48:35 PM: Update 16615: task edges-srl-ontonotes, batch 615 (16615): mcc: 0.8257, acc: 0.7611, precision: 0.8687, recall: 0.7896, f1: 0.8273, edges-srl-ontonotes_loss: 0.0141
09/07 09:48:45 PM: Update 16687: task edges-srl-ontonotes, batch 687 (16687): mcc: 0.8259, acc: 0.7610, precision: 0.8693, recall: 0.7893, f1: 0.8274, edges-srl-ontonotes_loss: 0.0141
09/07 09:48:55 PM: Update 16791: task edges-srl-ontonotes, batch 791 (16791): mcc: 0.8296, acc: 0.7657, precision: 0.8720, recall: 0.7940, f1: 0.8312, edges-srl-ontonotes_loss: 0.0138
09/07 09:49:05 PM: Update 16900: task edges-srl-ontonotes, batch 900 (16900): mcc: 0.8323, acc: 0.7691, precision: 0.8742, recall: 0.7970, f1: 0.8338, edges-srl-ontonotes_loss: 0.0136
09/07 09:49:16 PM: Update 16997: task edges-srl-ontonotes, batch 997 (16997): mcc: 0.8334, acc: 0.7706, precision: 0.8743, recall: 0.7990, f1: 0.8350, edges-srl-ontonotes_loss: 0.0136
09/07 09:49:16 PM: ***** Step 17000 / Validation 17 *****
09/07 09:49:16 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:49:16 PM: Validating...
09/07 09:49:26 PM: Evaluate: task edges-srl-ontonotes, batch 104 (157): mcc: 0.8800, acc: 0.8386, precision: 0.9162, recall: 0.8486, f1: 0.8811, edges-srl-ontonotes_loss: 0.0102
09/07 09:49:31 PM: Updating LR scheduler:
09/07 09:49:31 PM: 	Best result seen so far for macro_avg: 0.883
09/07 09:49:31 PM: 	# validation passes without improvement: 1
09/07 09:49:31 PM: edges-srl-ontonotes_loss: training: 0.013572 validation: 0.010241
09/07 09:49:31 PM: macro_avg: validation: 0.881712
09/07 09:49:31 PM: micro_avg: validation: 0.000000
09/07 09:49:31 PM: edges-srl-ontonotes_mcc: training: 0.833461 validation: 0.880590
09/07 09:49:31 PM: edges-srl-ontonotes_acc: training: 0.770666 validation: 0.841044
09/07 09:49:31 PM: edges-srl-ontonotes_precision: training: 0.874401 validation: 0.915824
09/07 09:49:31 PM: edges-srl-ontonotes_recall: training: 0.799019 validation: 0.850050
09/07 09:49:31 PM: edges-srl-ontonotes_f1: training: 0.835012 validation: 0.881712
09/07 09:49:31 PM: Global learning rate: 0.0001
09/07 09:49:31 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 09:49:36 PM: Update 17055: task edges-srl-ontonotes, batch 55 (17055): mcc: 0.8470, acc: 0.7896, precision: 0.8852, recall: 0.8147, f1: 0.8485, edges-srl-ontonotes_loss: 0.0127
09/07 09:49:46 PM: Update 17163: task edges-srl-ontonotes, batch 163 (17163): mcc: 0.8537, acc: 0.7985, precision: 0.8910, recall: 0.8220, f1: 0.8551, edges-srl-ontonotes_loss: 0.0122
09/07 09:49:56 PM: Update 17271: task edges-srl-ontonotes, batch 271 (17271): mcc: 0.8506, acc: 0.7940, precision: 0.8875, recall: 0.8193, f1: 0.8521, edges-srl-ontonotes_loss: 0.0124
09/07 09:50:06 PM: Update 17366: task edges-srl-ontonotes, batch 366 (17366): mcc: 0.8507, acc: 0.7944, precision: 0.8877, recall: 0.8195, f1: 0.8522, edges-srl-ontonotes_loss: 0.0123
09/07 09:50:16 PM: Update 17478: task edges-srl-ontonotes, batch 478 (17478): mcc: 0.8526, acc: 0.7960, precision: 0.8896, recall: 0.8213, f1: 0.8541, edges-srl-ontonotes_loss: 0.0122
09/07 09:50:26 PM: Update 17583: task edges-srl-ontonotes, batch 583 (17583): mcc: 0.8546, acc: 0.7990, precision: 0.8911, recall: 0.8237, f1: 0.8561, edges-srl-ontonotes_loss: 0.0121
09/07 09:50:36 PM: Update 17659: task edges-srl-ontonotes, batch 659 (17659): mcc: 0.8541, acc: 0.7982, precision: 0.8907, recall: 0.8231, f1: 0.8556, edges-srl-ontonotes_loss: 0.0121
09/07 09:50:46 PM: Update 17771: task edges-srl-ontonotes, batch 771 (17771): mcc: 0.8524, acc: 0.7958, precision: 0.8895, recall: 0.8208, f1: 0.8538, edges-srl-ontonotes_loss: 0.0123
09/07 09:50:56 PM: Update 17879: task edges-srl-ontonotes, batch 879 (17879): mcc: 0.8517, acc: 0.7947, precision: 0.8896, recall: 0.8196, f1: 0.8532, edges-srl-ontonotes_loss: 0.0123
09/07 09:51:06 PM: Update 17976: task edges-srl-ontonotes, batch 976 (17976): mcc: 0.8511, acc: 0.7938, precision: 0.8890, recall: 0.8189, f1: 0.8525, edges-srl-ontonotes_loss: 0.0124
09/07 09:51:08 PM: ***** Step 18000 / Validation 18 *****
09/07 09:51:08 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:51:08 PM: Validating...
09/07 09:51:16 PM: Evaluate: task edges-srl-ontonotes, batch 86 (157): mcc: 0.8696, acc: 0.8277, precision: 0.9068, recall: 0.8375, f1: 0.8708, edges-srl-ontonotes_loss: 0.0110
09/07 09:51:23 PM: Updating LR scheduler:
09/07 09:51:23 PM: 	Best result seen so far for macro_avg: 0.883
09/07 09:51:23 PM: 	# validation passes without improvement: 2
09/07 09:51:23 PM: edges-srl-ontonotes_loss: training: 0.012402 validation: 0.010664
09/07 09:51:23 PM: macro_avg: validation: 0.874156
09/07 09:51:23 PM: micro_avg: validation: 0.000000
09/07 09:51:23 PM: edges-srl-ontonotes_mcc: training: 0.850714 validation: 0.872932
09/07 09:51:23 PM: edges-srl-ontonotes_acc: training: 0.793335 validation: 0.831807
09/07 09:51:23 PM: edges-srl-ontonotes_precision: training: 0.888803 validation: 0.908367
09/07 09:51:23 PM: edges-srl-ontonotes_recall: training: 0.818396 validation: 0.842429
09/07 09:51:23 PM: edges-srl-ontonotes_f1: training: 0.852148 validation: 0.874156
09/07 09:51:23 PM: Global learning rate: 0.0001
09/07 09:51:23 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 09:51:26 PM: Update 18036: task edges-srl-ontonotes, batch 36 (18036): mcc: 0.8460, acc: 0.7882, precision: 0.8846, recall: 0.8133, f1: 0.8474, edges-srl-ontonotes_loss: 0.0132
09/07 09:51:36 PM: Update 18144: task edges-srl-ontonotes, batch 144 (18144): mcc: 0.8510, acc: 0.7929, precision: 0.8888, recall: 0.8189, f1: 0.8525, edges-srl-ontonotes_loss: 0.0125
09/07 09:51:47 PM: Update 18249: task edges-srl-ontonotes, batch 249 (18249): mcc: 0.8531, acc: 0.7944, precision: 0.8919, recall: 0.8200, f1: 0.8545, edges-srl-ontonotes_loss: 0.0125
09/07 09:51:57 PM: Update 18361: task edges-srl-ontonotes, batch 361 (18361): mcc: 0.8512, acc: 0.7927, precision: 0.8900, recall: 0.8182, f1: 0.8526, edges-srl-ontonotes_loss: 0.0125
09/07 09:52:07 PM: Update 18469: task edges-srl-ontonotes, batch 469 (18469): mcc: 0.8490, acc: 0.7902, precision: 0.8882, recall: 0.8157, f1: 0.8504, edges-srl-ontonotes_loss: 0.0126
09/07 09:52:19 PM: Update 18562: task edges-srl-ontonotes, batch 562 (18562): mcc: 0.8492, acc: 0.7904, precision: 0.8886, recall: 0.8157, f1: 0.8506, edges-srl-ontonotes_loss: 0.0126
09/07 09:52:29 PM: Update 18670: task edges-srl-ontonotes, batch 670 (18670): mcc: 0.8503, acc: 0.7922, precision: 0.8888, recall: 0.8177, f1: 0.8517, edges-srl-ontonotes_loss: 0.0125
09/07 09:52:39 PM: Update 18779: task edges-srl-ontonotes, batch 779 (18779): mcc: 0.8510, acc: 0.7929, precision: 0.8893, recall: 0.8186, f1: 0.8525, edges-srl-ontonotes_loss: 0.0125
09/07 09:52:49 PM: Update 18876: task edges-srl-ontonotes, batch 876 (18876): mcc: 0.8510, acc: 0.7932, precision: 0.8890, recall: 0.8187, f1: 0.8524, edges-srl-ontonotes_loss: 0.0124
09/07 09:52:59 PM: Update 18983: task edges-srl-ontonotes, batch 983 (18983): mcc: 0.8519, acc: 0.7943, precision: 0.8902, recall: 0.8194, f1: 0.8534, edges-srl-ontonotes_loss: 0.0124
09/07 09:53:01 PM: ***** Step 19000 / Validation 19 *****
09/07 09:53:01 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:53:01 PM: Validating...
09/07 09:53:10 PM: Evaluate: task edges-srl-ontonotes, batch 91 (157): mcc: 0.8712, acc: 0.8309, precision: 0.9046, recall: 0.8427, f1: 0.8726, edges-srl-ontonotes_loss: 0.0109
09/07 09:53:16 PM: Updating LR scheduler:
09/07 09:53:16 PM: 	Best result seen so far for macro_avg: 0.883
09/07 09:53:16 PM: 	# validation passes without improvement: 3
09/07 09:53:16 PM: edges-srl-ontonotes_loss: training: 0.012361 validation: 0.010692
09/07 09:53:16 PM: macro_avg: validation: 0.875682
09/07 09:53:16 PM: micro_avg: validation: 0.000000
09/07 09:53:16 PM: edges-srl-ontonotes_mcc: training: 0.852090 validation: 0.874365
09/07 09:53:16 PM: edges-srl-ontonotes_acc: training: 0.794531 validation: 0.835348
09/07 09:53:16 PM: edges-srl-ontonotes_precision: training: 0.890248 validation: 0.906760
09/07 09:53:16 PM: edges-srl-ontonotes_recall: training: 0.819668 validation: 0.846663
09/07 09:53:16 PM: edges-srl-ontonotes_f1: training: 0.853502 validation: 0.875682
09/07 09:53:16 PM: Global learning rate: 0.0001
09/07 09:53:16 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 09:53:20 PM: Update 19043: task edges-srl-ontonotes, batch 43 (19043): mcc: 0.8646, acc: 0.8134, precision: 0.9001, recall: 0.8342, f1: 0.8659, edges-srl-ontonotes_loss: 0.0116
09/07 09:53:30 PM: Update 19149: task edges-srl-ontonotes, batch 149 (19149): mcc: 0.8580, acc: 0.8015, precision: 0.8944, recall: 0.8271, f1: 0.8594, edges-srl-ontonotes_loss: 0.0118
09/07 09:53:40 PM: Update 19238: task edges-srl-ontonotes, batch 238 (19238): mcc: 0.8526, acc: 0.7947, precision: 0.8912, recall: 0.8198, f1: 0.8540, edges-srl-ontonotes_loss: 0.0122
09/07 09:53:50 PM: Update 19337: task edges-srl-ontonotes, batch 337 (19337): mcc: 0.8472, acc: 0.7874, precision: 0.8872, recall: 0.8131, f1: 0.8486, edges-srl-ontonotes_loss: 0.0126
09/07 09:54:00 PM: Update 19432: task edges-srl-ontonotes, batch 432 (19432): mcc: 0.8454, acc: 0.7849, precision: 0.8855, recall: 0.8113, f1: 0.8468, edges-srl-ontonotes_loss: 0.0128
09/07 09:54:10 PM: Update 19524: task edges-srl-ontonotes, batch 524 (19524): mcc: 0.8460, acc: 0.7858, precision: 0.8857, recall: 0.8123, f1: 0.8474, edges-srl-ontonotes_loss: 0.0127
09/07 09:54:20 PM: Update 19643: task edges-srl-ontonotes, batch 643 (19643): mcc: 0.8519, acc: 0.7932, precision: 0.8899, recall: 0.8196, f1: 0.8533, edges-srl-ontonotes_loss: 0.0122
09/07 09:54:30 PM: Update 19765: task edges-srl-ontonotes, batch 765 (19765): mcc: 0.8559, acc: 0.7986, precision: 0.8928, recall: 0.8246, f1: 0.8573, edges-srl-ontonotes_loss: 0.0119
09/07 09:54:40 PM: Update 19855: task edges-srl-ontonotes, batch 855 (19855): mcc: 0.8603, acc: 0.8041, precision: 0.8961, recall: 0.8299, f1: 0.8617, edges-srl-ontonotes_loss: 0.0116
09/07 09:54:50 PM: Update 19989: task edges-srl-ontonotes, batch 989 (19989): mcc: 0.8673, acc: 0.8131, precision: 0.9014, recall: 0.8381, f1: 0.8686, edges-srl-ontonotes_loss: 0.0112
09/07 09:54:51 PM: ***** Step 20000 / Validation 20 *****
09/07 09:54:51 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:54:51 PM: Validating...
09/07 09:55:00 PM: Evaluate: task edges-srl-ontonotes, batch 100 (157): mcc: 0.8719, acc: 0.8279, precision: 0.9095, recall: 0.8394, f1: 0.8731, edges-srl-ontonotes_loss: 0.0108
09/07 09:55:05 PM: Updating LR scheduler:
09/07 09:55:05 PM: 	Best result seen so far for macro_avg: 0.883
09/07 09:55:05 PM: 	# validation passes without improvement: 4
09/07 09:55:05 PM: edges-srl-ontonotes_loss: training: 0.011124 validation: 0.010705
09/07 09:55:05 PM: macro_avg: validation: 0.876669
09/07 09:55:05 PM: micro_avg: validation: 0.000000
09/07 09:55:05 PM: edges-srl-ontonotes_mcc: training: 0.867904 validation: 0.875509
09/07 09:55:05 PM: edges-srl-ontonotes_acc: training: 0.813943 validation: 0.833731
09/07 09:55:05 PM: edges-srl-ontonotes_precision: training: 0.901994 validation: 0.911645
09/07 09:55:05 PM: edges-srl-ontonotes_recall: training: 0.838805 validation: 0.844277
09/07 09:55:05 PM: edges-srl-ontonotes_f1: training: 0.869252 validation: 0.876669
09/07 09:55:05 PM: Global learning rate: 0.0001
09/07 09:55:05 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 09:55:10 PM: Update 20062: task edges-srl-ontonotes, batch 62 (20062): mcc: 0.9108, acc: 0.8679, precision: 0.9333, recall: 0.8913, f1: 0.9118, edges-srl-ontonotes_loss: 0.0077
09/07 09:55:20 PM: Update 20180: task edges-srl-ontonotes, batch 180 (20180): mcc: 0.9122, acc: 0.8729, precision: 0.9355, recall: 0.8920, f1: 0.9132, edges-srl-ontonotes_loss: 0.0077
09/07 09:55:30 PM: Update 20309: task edges-srl-ontonotes, batch 309 (20309): mcc: 0.9115, acc: 0.8713, precision: 0.9349, recall: 0.8913, f1: 0.9125, edges-srl-ontonotes_loss: 0.0079
09/07 09:55:40 PM: Update 20439: task edges-srl-ontonotes, batch 439 (20439): mcc: 0.9116, acc: 0.8716, precision: 0.9354, recall: 0.8911, f1: 0.9127, edges-srl-ontonotes_loss: 0.0079
09/07 09:55:50 PM: Update 20558: task edges-srl-ontonotes, batch 558 (20558): mcc: 0.9117, acc: 0.8722, precision: 0.9353, recall: 0.8913, f1: 0.9128, edges-srl-ontonotes_loss: 0.0079
09/07 09:56:00 PM: Update 20689: task edges-srl-ontonotes, batch 689 (20689): mcc: 0.9112, acc: 0.8721, precision: 0.9338, recall: 0.8917, f1: 0.9122, edges-srl-ontonotes_loss: 0.0079
09/07 09:56:10 PM: Update 20781: task edges-srl-ontonotes, batch 781 (20781): mcc: 0.9100, acc: 0.8708, precision: 0.9328, recall: 0.8904, f1: 0.9111, edges-srl-ontonotes_loss: 0.0081
09/07 09:56:20 PM: Update 20913: task edges-srl-ontonotes, batch 913 (20913): mcc: 0.9086, acc: 0.8698, precision: 0.9312, recall: 0.8891, f1: 0.9097, edges-srl-ontonotes_loss: 0.0082
09/07 09:56:27 PM: ***** Step 21000 / Validation 21 *****
09/07 09:56:27 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:56:27 PM: Validating...
09/07 09:56:30 PM: Evaluate: task edges-srl-ontonotes, batch 38 (157): mcc: 0.8744, acc: 0.8326, precision: 0.9139, recall: 0.8401, f1: 0.8754, edges-srl-ontonotes_loss: 0.0109
09/07 09:56:40 PM: Evaluate: task edges-srl-ontonotes, batch 146 (157): mcc: 0.8821, acc: 0.8437, precision: 0.9169, recall: 0.8519, f1: 0.8832, edges-srl-ontonotes_loss: 0.0101
09/07 09:56:41 PM: Updating LR scheduler:
09/07 09:56:41 PM: 	Best result seen so far for macro_avg: 0.883
09/07 09:56:41 PM: 	# validation passes without improvement: 5
09/07 09:56:41 PM: edges-srl-ontonotes_loss: training: 0.008224 validation: 0.010406
09/07 09:56:41 PM: macro_avg: validation: 0.881453
09/07 09:56:41 PM: micro_avg: validation: 0.000000
09/07 09:56:41 PM: edges-srl-ontonotes_mcc: training: 0.908421 validation: 0.880334
09/07 09:56:41 PM: edges-srl-ontonotes_acc: training: 0.869949 validation: 0.841275
09/07 09:56:41 PM: edges-srl-ontonotes_precision: training: 0.930985 validation: 0.915713
09/07 09:56:41 PM: edges-srl-ontonotes_recall: training: 0.889044 validation: 0.849665
09/07 09:56:41 PM: edges-srl-ontonotes_f1: training: 0.909531 validation: 0.881453
09/07 09:56:41 PM: Global learning rate: 0.0001
09/07 09:56:41 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 09:56:50 PM: Update 21099: task edges-srl-ontonotes, batch 99 (21099): mcc: 0.8939, acc: 0.8532, precision: 0.9163, recall: 0.8751, f1: 0.8952, edges-srl-ontonotes_loss: 0.0093
09/07 09:57:00 PM: Update 21213: task edges-srl-ontonotes, batch 213 (21213): mcc: 0.8844, acc: 0.8390, precision: 0.9106, recall: 0.8622, f1: 0.8857, edges-srl-ontonotes_loss: 0.0101
09/07 09:57:10 PM: Update 21321: task edges-srl-ontonotes, batch 321 (21321): mcc: 0.8797, acc: 0.8325, precision: 0.9074, recall: 0.8562, f1: 0.8811, edges-srl-ontonotes_loss: 0.0104
09/07 09:57:20 PM: Update 21415: task edges-srl-ontonotes, batch 415 (21415): mcc: 0.8750, acc: 0.8265, precision: 0.9044, recall: 0.8501, f1: 0.8764, edges-srl-ontonotes_loss: 0.0108
09/07 09:57:31 PM: Update 21523: task edges-srl-ontonotes, batch 523 (21523): mcc: 0.8696, acc: 0.8198, precision: 0.9002, recall: 0.8439, f1: 0.8711, edges-srl-ontonotes_loss: 0.0112
09/07 09:57:41 PM: Update 21638: task edges-srl-ontonotes, batch 638 (21638): mcc: 0.8662, acc: 0.8158, precision: 0.8974, recall: 0.8399, f1: 0.8677, edges-srl-ontonotes_loss: 0.0114
09/07 09:57:53 PM: Update 21739: task edges-srl-ontonotes, batch 739 (21739): mcc: 0.8642, acc: 0.8130, precision: 0.8965, recall: 0.8370, f1: 0.8657, edges-srl-ontonotes_loss: 0.0115
09/07 09:58:03 PM: Update 21859: task edges-srl-ontonotes, batch 859 (21859): mcc: 0.8658, acc: 0.8150, precision: 0.8976, recall: 0.8390, f1: 0.8673, edges-srl-ontonotes_loss: 0.0114
09/07 09:58:13 PM: Update 21982: task edges-srl-ontonotes, batch 982 (21982): mcc: 0.8675, acc: 0.8172, precision: 0.8988, recall: 0.8409, f1: 0.8689, edges-srl-ontonotes_loss: 0.0113
09/07 09:58:14 PM: ***** Step 22000 / Validation 22 *****
09/07 09:58:14 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:58:14 PM: Validating...
09/07 09:58:23 PM: Evaluate: task edges-srl-ontonotes, batch 92 (157): mcc: 0.8907, acc: 0.8537, precision: 0.9225, recall: 0.8630, f1: 0.8918, edges-srl-ontonotes_loss: 0.0095
09/07 09:58:29 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:58:29 PM: Best result seen so far for macro.
09/07 09:58:29 PM: Updating LR scheduler:
09/07 09:58:29 PM: 	Best result seen so far for macro_avg: 0.891
09/07 09:58:29 PM: 	# validation passes without improvement: 0
09/07 09:58:29 PM: edges-srl-ontonotes_loss: training: 0.011265 validation: 0.009658
09/07 09:58:29 PM: macro_avg: validation: 0.890806
09/07 09:58:29 PM: micro_avg: validation: 0.000000
09/07 09:58:29 PM: edges-srl-ontonotes_mcc: training: 0.867430 validation: 0.889675
09/07 09:58:29 PM: edges-srl-ontonotes_acc: training: 0.817150 validation: 0.853052
09/07 09:58:29 PM: edges-srl-ontonotes_precision: training: 0.898835 validation: 0.921009
09/07 09:58:29 PM: edges-srl-ontonotes_recall: training: 0.840863 validation: 0.862520
09/07 09:58:29 PM: edges-srl-ontonotes_f1: training: 0.868883 validation: 0.890806
09/07 09:58:29 PM: Global learning rate: 0.0001
09/07 09:58:29 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 09:58:33 PM: Update 22045: task edges-srl-ontonotes, batch 45 (22045): mcc: 0.8738, acc: 0.8243, precision: 0.9026, recall: 0.8496, f1: 0.8753, edges-srl-ontonotes_loss: 0.0109
09/07 09:58:43 PM: Update 22153: task edges-srl-ontonotes, batch 153 (22153): mcc: 0.8772, acc: 0.8283, precision: 0.9055, recall: 0.8532, f1: 0.8786, edges-srl-ontonotes_loss: 0.0104
09/07 09:58:53 PM: Update 22273: task edges-srl-ontonotes, batch 273 (22273): mcc: 0.8806, acc: 0.8325, precision: 0.9082, recall: 0.8573, f1: 0.8820, edges-srl-ontonotes_loss: 0.0102
09/07 09:59:03 PM: Update 22380: task edges-srl-ontonotes, batch 380 (22380): mcc: 0.8799, acc: 0.8318, precision: 0.9082, recall: 0.8559, f1: 0.8813, edges-srl-ontonotes_loss: 0.0102
09/07 09:59:13 PM: Update 22500: task edges-srl-ontonotes, batch 500 (22500): mcc: 0.8759, acc: 0.8271, precision: 0.9041, recall: 0.8520, f1: 0.8773, edges-srl-ontonotes_loss: 0.0105
09/07 09:59:23 PM: Update 22616: task edges-srl-ontonotes, batch 616 (22616): mcc: 0.8747, acc: 0.8263, precision: 0.9035, recall: 0.8504, f1: 0.8762, edges-srl-ontonotes_loss: 0.0107
09/07 09:59:33 PM: Update 22697: task edges-srl-ontonotes, batch 697 (22697): mcc: 0.8737, acc: 0.8249, precision: 0.9024, recall: 0.8494, f1: 0.8751, edges-srl-ontonotes_loss: 0.0107
09/07 09:59:43 PM: Update 22810: task edges-srl-ontonotes, batch 810 (22810): mcc: 0.8702, acc: 0.8205, precision: 0.9000, recall: 0.8451, f1: 0.8717, edges-srl-ontonotes_loss: 0.0110
09/07 09:59:53 PM: Update 22930: task edges-srl-ontonotes, batch 930 (22930): mcc: 0.8679, acc: 0.8171, precision: 0.8984, recall: 0.8422, f1: 0.8694, edges-srl-ontonotes_loss: 0.0112
09/07 10:00:00 PM: ***** Step 23000 / Validation 23 *****
09/07 10:00:00 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:00:00 PM: Validating...
09/07 10:00:03 PM: Evaluate: task edges-srl-ontonotes, batch 29 (157): mcc: 0.8943, acc: 0.8615, precision: 0.9216, recall: 0.8708, f1: 0.8955, edges-srl-ontonotes_loss: 0.0093
09/07 10:00:13 PM: Evaluate: task edges-srl-ontonotes, batch 137 (157): mcc: 0.8954, acc: 0.8627, precision: 0.9221, recall: 0.8725, f1: 0.8966, edges-srl-ontonotes_loss: 0.0091
09/07 10:00:15 PM: Best result seen so far for edges-srl-ontonotes.
09/07 10:00:15 PM: Best result seen so far for macro.
09/07 10:00:15 PM: Updating LR scheduler:
09/07 10:00:15 PM: 	Best result seen so far for macro_avg: 0.893
09/07 10:00:15 PM: 	# validation passes without improvement: 0
09/07 10:00:15 PM: edges-srl-ontonotes_loss: training: 0.011225 validation: 0.009388
09/07 10:00:15 PM: macro_avg: validation: 0.893482
09/07 10:00:15 PM: micro_avg: validation: 0.000000
09/07 10:00:15 PM: edges-srl-ontonotes_mcc: training: 0.866974 validation: 0.892273
09/07 10:00:15 PM: edges-srl-ontonotes_acc: training: 0.815582 validation: 0.858594
09/07 10:00:15 PM: edges-srl-ontonotes_precision: training: 0.897739 validation: 0.920003
09/07 10:00:15 PM: edges-srl-ontonotes_recall: training: 0.841022 validation: 0.868447
09/07 10:00:15 PM: edges-srl-ontonotes_f1: training: 0.868455 validation: 0.893482
09/07 10:00:15 PM: Global learning rate: 0.0001
09/07 10:00:15 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 10:00:23 PM: Update 23091: task edges-srl-ontonotes, batch 91 (23091): mcc: 0.8581, acc: 0.8022, precision: 0.8908, recall: 0.8305, f1: 0.8596, edges-srl-ontonotes_loss: 0.0116
09/07 10:00:33 PM: Update 23204: task edges-srl-ontonotes, batch 204 (23204): mcc: 0.8590, acc: 0.8039, precision: 0.8920, recall: 0.8313, f1: 0.8606, edges-srl-ontonotes_loss: 0.0116
09/07 10:00:43 PM: Update 23304: task edges-srl-ontonotes, batch 304 (23304): mcc: 0.8580, acc: 0.8041, precision: 0.8907, recall: 0.8305, f1: 0.8596, edges-srl-ontonotes_loss: 0.0117
09/07 10:00:53 PM: Update 23412: task edges-srl-ontonotes, batch 412 (23412): mcc: 0.8488, acc: 0.7922, precision: 0.8842, recall: 0.8190, f1: 0.8504, edges-srl-ontonotes_loss: 0.0123
09/07 10:01:03 PM: Update 23521: task edges-srl-ontonotes, batch 521 (23521): mcc: 0.8454, acc: 0.7877, precision: 0.8820, recall: 0.8145, f1: 0.8469, edges-srl-ontonotes_loss: 0.0126
09/07 10:01:14 PM: Update 23617: task edges-srl-ontonotes, batch 617 (23617): mcc: 0.8443, acc: 0.7863, precision: 0.8815, recall: 0.8129, f1: 0.8458, edges-srl-ontonotes_loss: 0.0127
09/07 10:01:24 PM: Update 23726: task edges-srl-ontonotes, batch 726 (23726): mcc: 0.8431, acc: 0.7847, precision: 0.8809, recall: 0.8113, f1: 0.8447, edges-srl-ontonotes_loss: 0.0128
09/07 10:01:34 PM: Update 23836: task edges-srl-ontonotes, batch 836 (23836): mcc: 0.8428, acc: 0.7842, precision: 0.8809, recall: 0.8107, f1: 0.8443, edges-srl-ontonotes_loss: 0.0129
09/07 10:01:45 PM: Update 23930: task edges-srl-ontonotes, batch 930 (23930): mcc: 0.8421, acc: 0.7832, precision: 0.8806, recall: 0.8097, f1: 0.8437, edges-srl-ontonotes_loss: 0.0129
09/07 10:01:52 PM: ***** Step 24000 / Validation 24 *****
09/07 10:01:52 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:01:52 PM: Validating...
09/07 10:01:55 PM: Evaluate: task edges-srl-ontonotes, batch 36 (157): mcc: 0.8845, acc: 0.8456, precision: 0.9176, recall: 0.8559, f1: 0.8857, edges-srl-ontonotes_loss: 0.0099
09/07 10:02:05 PM: Evaluate: task edges-srl-ontonotes, batch 144 (157): mcc: 0.8898, acc: 0.8526, precision: 0.9206, recall: 0.8631, f1: 0.8909, edges-srl-ontonotes_loss: 0.0093
09/07 10:02:06 PM: Updating LR scheduler:
09/07 10:02:06 PM: 	Best result seen so far for macro_avg: 0.893
09/07 10:02:06 PM: 	# validation passes without improvement: 1
09/07 10:02:06 PM: edges-srl-ontonotes_loss: training: 0.012816 validation: 0.009595
09/07 10:02:06 PM: macro_avg: validation: 0.888827
09/07 10:02:06 PM: micro_avg: validation: 0.000000
09/07 10:02:06 PM: edges-srl-ontonotes_mcc: training: 0.843102 validation: 0.887663
09/07 10:02:06 PM: edges-srl-ontonotes_acc: training: 0.784067 validation: 0.850281
09/07 10:02:06 PM: edges-srl-ontonotes_precision: training: 0.881608 validation: 0.918886
09/07 10:02:06 PM: edges-srl-ontonotes_recall: training: 0.810622 validation: 0.860673
09/07 10:02:06 PM: edges-srl-ontonotes_f1: training: 0.844626 validation: 0.888827
09/07 10:02:06 PM: Global learning rate: 0.0001
09/07 10:02:06 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 10:02:15 PM: Update 24094: task edges-srl-ontonotes, batch 94 (24094): mcc: 0.8623, acc: 0.8070, precision: 0.8967, recall: 0.8331, f1: 0.8637, edges-srl-ontonotes_loss: 0.0116
09/07 10:02:25 PM: Update 24198: task edges-srl-ontonotes, batch 198 (24198): mcc: 0.8623, acc: 0.8082, precision: 0.8956, recall: 0.8341, f1: 0.8637, edges-srl-ontonotes_loss: 0.0114
09/07 10:02:35 PM: Update 24292: task edges-srl-ontonotes, batch 292 (24292): mcc: 0.8618, acc: 0.8076, precision: 0.8958, recall: 0.8330, f1: 0.8632, edges-srl-ontonotes_loss: 0.0115
09/07 10:02:45 PM: Update 24403: task edges-srl-ontonotes, batch 403 (24403): mcc: 0.8628, acc: 0.8092, precision: 0.8962, recall: 0.8345, f1: 0.8642, edges-srl-ontonotes_loss: 0.0114
09/07 10:02:55 PM: Update 24509: task edges-srl-ontonotes, batch 509 (24509): mcc: 0.8628, acc: 0.8088, precision: 0.8967, recall: 0.8340, f1: 0.8642, edges-srl-ontonotes_loss: 0.0115
09/07 10:03:05 PM: Update 24604: task edges-srl-ontonotes, batch 604 (24604): mcc: 0.8630, acc: 0.8090, precision: 0.8972, recall: 0.8339, f1: 0.8644, edges-srl-ontonotes_loss: 0.0114
09/07 10:03:15 PM: Update 24712: task edges-srl-ontonotes, batch 712 (24712): mcc: 0.8631, acc: 0.8094, precision: 0.8969, recall: 0.8345, f1: 0.8646, edges-srl-ontonotes_loss: 0.0114
09/07 10:03:26 PM: Update 24820: task edges-srl-ontonotes, batch 820 (24820): mcc: 0.8638, acc: 0.8104, precision: 0.8973, recall: 0.8354, f1: 0.8652, edges-srl-ontonotes_loss: 0.0114
09/07 10:03:36 PM: Update 24894: task edges-srl-ontonotes, batch 894 (24894): mcc: 0.8640, acc: 0.8110, precision: 0.8972, recall: 0.8359, f1: 0.8655, edges-srl-ontonotes_loss: 0.0114
09/07 10:03:46 PM: Update 24999: task edges-srl-ontonotes, batch 999 (24999): mcc: 0.8626, acc: 0.8092, precision: 0.8963, recall: 0.8340, f1: 0.8640, edges-srl-ontonotes_loss: 0.0115
09/07 10:03:46 PM: ***** Step 25000 / Validation 25 *****
09/07 10:03:46 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:03:46 PM: Validating...
09/07 10:03:56 PM: Evaluate: task edges-srl-ontonotes, batch 107 (157): mcc: 0.8820, acc: 0.8436, precision: 0.9153, recall: 0.8532, f1: 0.8832, edges-srl-ontonotes_loss: 0.0100
09/07 10:04:00 PM: Updating LR scheduler:
09/07 10:04:00 PM: 	Best result seen so far for macro_avg: 0.893
09/07 10:04:00 PM: 	# validation passes without improvement: 2
09/07 10:04:00 PM: edges-srl-ontonotes_loss: training: 0.011472 validation: 0.009989
09/07 10:04:00 PM: macro_avg: validation: 0.883712
09/07 10:04:00 PM: micro_avg: validation: 0.000000
09/07 10:04:00 PM: edges-srl-ontonotes_mcc: training: 0.862602 validation: 0.882534
09/07 10:04:00 PM: edges-srl-ontonotes_acc: training: 0.809156 validation: 0.845124
09/07 10:04:00 PM: edges-srl-ontonotes_precision: training: 0.896281 validation: 0.915505
09/07 10:04:00 PM: edges-srl-ontonotes_recall: training: 0.834043 validation: 0.854053
09/07 10:04:00 PM: edges-srl-ontonotes_f1: training: 0.864043 validation: 0.883712
09/07 10:04:00 PM: Global learning rate: 0.0001
09/07 10:04:00 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 10:04:06 PM: Update 25058: task edges-srl-ontonotes, batch 58 (25058): mcc: 0.8531, acc: 0.7983, precision: 0.8881, recall: 0.8236, f1: 0.8547, edges-srl-ontonotes_loss: 0.0121
09/07 10:04:16 PM: Update 25169: task edges-srl-ontonotes, batch 169 (25169): mcc: 0.8546, acc: 0.7979, precision: 0.8914, recall: 0.8234, f1: 0.8560, edges-srl-ontonotes_loss: 0.0120
09/07 10:04:26 PM: Update 25266: task edges-srl-ontonotes, batch 266 (25266): mcc: 0.8543, acc: 0.7968, precision: 0.8917, recall: 0.8225, f1: 0.8557, edges-srl-ontonotes_loss: 0.0120
09/07 10:04:36 PM: Update 25376: task edges-srl-ontonotes, batch 376 (25376): mcc: 0.8556, acc: 0.7983, precision: 0.8927, recall: 0.8241, f1: 0.8570, edges-srl-ontonotes_loss: 0.0120
09/07 10:04:46 PM: Update 25485: task edges-srl-ontonotes, batch 485 (25485): mcc: 0.8564, acc: 0.7996, precision: 0.8931, recall: 0.8253, f1: 0.8578, edges-srl-ontonotes_loss: 0.0120
09/07 10:04:56 PM: Update 25581: task edges-srl-ontonotes, batch 581 (25581): mcc: 0.8559, acc: 0.7991, precision: 0.8925, recall: 0.8247, f1: 0.8573, edges-srl-ontonotes_loss: 0.0120
09/07 10:05:06 PM: Update 25692: task edges-srl-ontonotes, batch 692 (25692): mcc: 0.8560, acc: 0.7994, precision: 0.8927, recall: 0.8248, f1: 0.8574, edges-srl-ontonotes_loss: 0.0120
09/07 10:05:16 PM: Update 25798: task edges-srl-ontonotes, batch 798 (25798): mcc: 0.8562, acc: 0.7996, precision: 0.8926, recall: 0.8252, f1: 0.8576, edges-srl-ontonotes_loss: 0.0120
09/07 10:05:26 PM: Update 25891: task edges-srl-ontonotes, batch 891 (25891): mcc: 0.8563, acc: 0.7999, precision: 0.8925, recall: 0.8255, f1: 0.8577, edges-srl-ontonotes_loss: 0.0120
09/07 10:05:36 PM: Update 25997: task edges-srl-ontonotes, batch 997 (25997): mcc: 0.8574, acc: 0.8014, precision: 0.8933, recall: 0.8269, f1: 0.8588, edges-srl-ontonotes_loss: 0.0119
09/07 10:05:37 PM: ***** Step 26000 / Validation 26 *****
09/07 10:05:37 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:05:37 PM: Validating...
09/07 10:05:46 PM: Evaluate: task edges-srl-ontonotes, batch 105 (157): mcc: 0.8807, acc: 0.8431, precision: 0.9110, recall: 0.8547, f1: 0.8820, edges-srl-ontonotes_loss: 0.0101
09/07 10:05:51 PM: Updating LR scheduler:
09/07 10:05:51 PM: 	Best result seen so far for macro_avg: 0.893
09/07 10:05:51 PM: 	# validation passes without improvement: 3
09/07 10:05:51 PM: edges-srl-ontonotes_loss: training: 0.011854 validation: 0.010045
09/07 10:05:51 PM: macro_avg: validation: 0.883608
09/07 10:05:51 PM: micro_avg: validation: 0.000000
09/07 10:05:51 PM: edges-srl-ontonotes_mcc: training: 0.857460 validation: 0.882302
09/07 10:05:51 PM: edges-srl-ontonotes_acc: training: 0.801417 validation: 0.846432
09/07 10:05:51 PM: edges-srl-ontonotes_precision: training: 0.893362 validation: 0.911599
09/07 10:05:51 PM: edges-srl-ontonotes_recall: training: 0.826977 validation: 0.857286
09/07 10:05:51 PM: edges-srl-ontonotes_f1: training: 0.858889 validation: 0.883608
09/07 10:05:51 PM: Global learning rate: 0.0001
09/07 10:05:51 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 10:05:56 PM: Update 26055: task edges-srl-ontonotes, batch 55 (26055): mcc: 0.8608, acc: 0.8147, precision: 0.8934, recall: 0.8334, f1: 0.8623, edges-srl-ontonotes_loss: 0.0122
09/07 10:06:06 PM: Update 26133: task edges-srl-ontonotes, batch 133 (26133): mcc: 0.8620, acc: 0.8118, precision: 0.8949, recall: 0.8342, f1: 0.8635, edges-srl-ontonotes_loss: 0.0118
09/07 10:06:16 PM: Update 26240: task edges-srl-ontonotes, batch 240 (26240): mcc: 0.8638, acc: 0.8119, precision: 0.8970, recall: 0.8356, f1: 0.8653, edges-srl-ontonotes_loss: 0.0115
09/07 10:06:27 PM: Update 26351: task edges-srl-ontonotes, batch 351 (26351): mcc: 0.8649, acc: 0.8128, precision: 0.8988, recall: 0.8361, f1: 0.8663, edges-srl-ontonotes_loss: 0.0114
09/07 10:06:37 PM: Update 26441: task edges-srl-ontonotes, batch 441 (26441): mcc: 0.8635, acc: 0.8111, precision: 0.8977, recall: 0.8344, f1: 0.8649, edges-srl-ontonotes_loss: 0.0114
09/07 10:06:47 PM: Update 26539: task edges-srl-ontonotes, batch 539 (26539): mcc: 0.8585, acc: 0.8036, precision: 0.8939, recall: 0.8284, f1: 0.8599, edges-srl-ontonotes_loss: 0.0118
09/07 10:06:57 PM: Update 26635: task edges-srl-ontonotes, batch 635 (26635): mcc: 0.8561, acc: 0.8003, precision: 0.8926, recall: 0.8252, f1: 0.8575, edges-srl-ontonotes_loss: 0.0119
09/07 10:07:07 PM: Update 26735: task edges-srl-ontonotes, batch 735 (26735): mcc: 0.8555, acc: 0.7989, precision: 0.8919, recall: 0.8245, f1: 0.8569, edges-srl-ontonotes_loss: 0.0120
09/07 10:07:17 PM: Update 26837: task edges-srl-ontonotes, batch 837 (26837): mcc: 0.8579, acc: 0.8019, precision: 0.8937, recall: 0.8274, f1: 0.8593, edges-srl-ontonotes_loss: 0.0118
09/07 10:07:27 PM: Update 26959: task edges-srl-ontonotes, batch 959 (26959): mcc: 0.8622, acc: 0.8070, precision: 0.8970, recall: 0.8327, f1: 0.8636, edges-srl-ontonotes_loss: 0.0115
09/07 10:07:30 PM: ***** Step 27000 / Validation 27 *****
09/07 10:07:30 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:07:30 PM: Validating...
09/07 10:07:37 PM: Evaluate: task edges-srl-ontonotes, batch 74 (157): mcc: 0.8777, acc: 0.8383, precision: 0.9086, recall: 0.8513, f1: 0.8790, edges-srl-ontonotes_loss: 0.0105
09/07 10:07:45 PM: Updating LR scheduler:
09/07 10:07:45 PM: 	Best result seen so far for macro_avg: 0.893
09/07 10:07:45 PM: 	# validation passes without improvement: 4
09/07 10:07:45 PM: edges-srl-ontonotes_loss: training: 0.011380 validation: 0.009996
09/07 10:07:45 PM: macro_avg: validation: 0.885456
09/07 10:07:45 PM: micro_avg: validation: 0.000000
09/07 10:07:45 PM: edges-srl-ontonotes_mcc: training: 0.863516 validation: 0.884131
09/07 10:07:45 PM: edges-srl-ontonotes_acc: training: 0.808656 validation: 0.848049
09/07 10:07:45 PM: edges-srl-ontonotes_precision: training: 0.897963 validation: 0.911969
09/07 10:07:45 PM: edges-srl-ontonotes_recall: training: 0.834211 validation: 0.860442
09/07 10:07:45 PM: edges-srl-ontonotes_f1: training: 0.864914 validation: 0.885456
09/07 10:07:45 PM: Global learning rate: 0.0001
09/07 10:07:45 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 10:07:47 PM: Update 27027: task edges-srl-ontonotes, batch 27 (27027): mcc: 0.8898, acc: 0.8413, precision: 0.9122, recall: 0.8712, f1: 0.8912, edges-srl-ontonotes_loss: 0.0095
09/07 10:07:57 PM: Update 27118: task edges-srl-ontonotes, batch 118 (27118): mcc: 0.8996, acc: 0.8542, precision: 0.9242, recall: 0.8785, f1: 0.9008, edges-srl-ontonotes_loss: 0.0087
09/07 10:08:07 PM: Update 27249: task edges-srl-ontonotes, batch 249 (27249): mcc: 0.9080, acc: 0.8662, precision: 0.9307, recall: 0.8885, f1: 0.9091, edges-srl-ontonotes_loss: 0.0080
09/07 10:08:17 PM: Update 27373: task edges-srl-ontonotes, batch 373 (27373): mcc: 0.9120, acc: 0.8720, precision: 0.9337, recall: 0.8933, f1: 0.9131, edges-srl-ontonotes_loss: 0.0077
09/07 10:08:27 PM: Update 27500: task edges-srl-ontonotes, batch 500 (27500): mcc: 0.9114, acc: 0.8715, precision: 0.9337, recall: 0.8923, f1: 0.9125, edges-srl-ontonotes_loss: 0.0077
09/07 10:08:37 PM: Update 27633: task edges-srl-ontonotes, batch 633 (27633): mcc: 0.9129, acc: 0.8735, precision: 0.9349, recall: 0.8938, f1: 0.9139, edges-srl-ontonotes_loss: 0.0077
09/07 10:08:47 PM: Update 27750: task edges-srl-ontonotes, batch 750 (27750): mcc: 0.9127, acc: 0.8740, precision: 0.9346, recall: 0.8939, f1: 0.9138, edges-srl-ontonotes_loss: 0.0077
09/07 10:08:57 PM: Update 27884: task edges-srl-ontonotes, batch 884 (27884): mcc: 0.9138, acc: 0.8757, precision: 0.9353, recall: 0.8953, f1: 0.9149, edges-srl-ontonotes_loss: 0.0076
09/07 10:09:07 PM: Update 28000: task edges-srl-ontonotes, batch 1000 (28000): mcc: 0.9136, acc: 0.8756, precision: 0.9349, recall: 0.8953, f1: 0.9147, edges-srl-ontonotes_loss: 0.0077
09/07 10:09:07 PM: ***** Step 28000 / Validation 28 *****
09/07 10:09:07 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:09:07 PM: Validating...
09/07 10:09:17 PM: Evaluate: task edges-srl-ontonotes, batch 108 (157): mcc: 0.8866, acc: 0.8502, precision: 0.9165, recall: 0.8609, f1: 0.8878, edges-srl-ontonotes_loss: 0.0099
09/07 10:09:24 PM: Updating LR scheduler:
09/07 10:09:24 PM: 	Best result seen so far for macro_avg: 0.893
09/07 10:09:24 PM: 	# validation passes without improvement: 5
09/07 10:09:24 PM: edges-srl-ontonotes_loss: training: 0.007657 validation: 0.009971
09/07 10:09:24 PM: macro_avg: validation: 0.887284
09/07 10:09:24 PM: micro_avg: validation: 0.000000
09/07 10:09:24 PM: edges-srl-ontonotes_mcc: training: 0.913595 validation: 0.886049
09/07 10:09:24 PM: edges-srl-ontonotes_acc: training: 0.875572 validation: 0.850974
09/07 10:09:24 PM: edges-srl-ontonotes_precision: training: 0.934898 validation: 0.915854
09/07 10:09:24 PM: edges-srl-ontonotes_recall: training: 0.895277 validation: 0.860442
09/07 10:09:24 PM: edges-srl-ontonotes_f1: training: 0.914658 validation: 0.887284
09/07 10:09:24 PM: Global learning rate: 0.0001
09/07 10:09:24 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-cat/run
09/07 10:09:28 PM: Update 28050: task edges-srl-ontonotes, batch 50 (28050): mcc: 0.9042, acc: 0.8676, precision: 0.9242, recall: 0.8875, f1: 0.9055, edges-srl-ontonotes_loss: 0.0089
09/07 10:09:38 PM: Update 28183: task edges-srl-ontonotes, batch 183 (28183): mcc: 0.9059, acc: 0.8697, precision: 0.9259, recall: 0.8891, f1: 0.9071, edges-srl-ontonotes_loss: 0.0086
09/07 10:09:48 PM: Update 28312: task edges-srl-ontonotes, batch 312 (28312): mcc: 0.9078, acc: 0.8725, precision: 0.9277, recall: 0.8910, f1: 0.9090, edges-srl-ontonotes_loss: 0.0084
09/07 10:09:58 PM: Update 28417: task edges-srl-ontonotes, batch 417 (28417): mcc: 0.8994, acc: 0.8606, precision: 0.9219, recall: 0.8803, f1: 0.9006, edges-srl-ontonotes_loss: 0.0089
09/07 10:10:08 PM: Update 28533: task edges-srl-ontonotes, batch 533 (28533): mcc: 0.8944, acc: 0.8537, precision: 0.9184, recall: 0.8740, f1: 0.8956, edges-srl-ontonotes_loss: 0.0093
09/07 10:10:18 PM: Update 28630: task edges-srl-ontonotes, batch 630 (28630): mcc: 0.8917, acc: 0.8501, precision: 0.9167, recall: 0.8706, f1: 0.8930, edges-srl-ontonotes_loss: 0.0095
09/07 10:10:28 PM: Update 28738: task edges-srl-ontonotes, batch 738 (28738): mcc: 0.8863, acc: 0.8424, precision: 0.9126, recall: 0.8639, f1: 0.8876, edges-srl-ontonotes_loss: 0.0099
09/07 10:10:38 PM: Update 28844: task edges-srl-ontonotes, batch 844 (28844): mcc: 0.8826, acc: 0.8375, precision: 0.9099, recall: 0.8596, f1: 0.8840, edges-srl-ontonotes_loss: 0.0101
09/07 10:10:49 PM: Update 28951: task edges-srl-ontonotes, batch 951 (28951): mcc: 0.8800, acc: 0.8341, precision: 0.9080, recall: 0.8563, f1: 0.8814, edges-srl-ontonotes_loss: 0.0103
09/07 10:10:54 PM: ***** Step 29000 / Validation 29 *****
09/07 10:10:54 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:10:54 PM: Validating...
09/07 10:10:59 PM: Evaluate: task edges-srl-ontonotes, batch 53 (157): mcc: 0.8837, acc: 0.8456, precision: 0.9172, recall: 0.8548, f1: 0.8849, edges-srl-ontonotes_loss: 0.0104
