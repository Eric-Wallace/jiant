09/16 09:13:23 AM: Git branch: master
09/16 09:13:23 AM: Git SHA: 3ca0f74688379229ab3eec908a215358ad18b3f4
09/16 09:13:23 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/ner-ontonotes-coref-top/",
  "exp_name": "experiments/ner-ontonotes-coref-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/ner-ontonotes-coref-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/coref",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/ner-ontonotes-coref-top__run",
  "run_dir": "./experiments/ner-ontonotes-coref-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-ner-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 09:13:23 AM: Saved config to ./experiments/ner-ontonotes-coref-top/run/params.conf
09/16 09:13:23 AM: Using random seed 1234
09/16 09:13:58 AM: Using GPU 0
09/16 09:13:58 AM: Loading tasks...
09/16 09:13:58 AM: Writing pre-preprocessed tasks to ./experiments/ner-ontonotes-coref-top/
09/16 09:13:58 AM: 	Creating task edges-ner-ontonotes from scratch.
09/16 09:13:59 AM: Read=49706, Skip=66106, Total=115812 from ./probing_data/edges/ontonotes/ner/train.json.retokenized.bert-base-uncased
09/16 09:14:00 AM: Read=7610, Skip=8070, Total=15680 from ./probing_data/edges/ontonotes/ner/development.json.retokenized.bert-base-uncased
09/16 09:14:00 AM: Read=5099, Skip=7118, Total=12217 from ./probing_data/edges/ontonotes/ner/test.json.retokenized.bert-base-uncased
09/16 09:14:00 AM: 	Task 'edges-ner-ontonotes': |train|=49706 |val|=7610 |test|=5099
09/16 09:14:00 AM: 	Finished loading tasks: edges-ner-ontonotes.
09/16 09:14:00 AM: 	Building vocab from scratch.
09/16 09:14:00 AM: 	Counting units for task edges-ner-ontonotes.
09/16 09:14:02 AM: 	Task 'edges-ner-ontonotes': adding vocab namespace 'edges-ner-ontonotes_labels'
09/16 09:14:03 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:14:04 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 09:14:04 AM: 	Saved vocab to ./experiments/ner-ontonotes-coref-top/vocab
09/16 09:14:04 AM: Loading token dictionary from ./experiments/ner-ontonotes-coref-top/vocab.
09/16 09:14:04 AM: 	Loaded vocab from ./experiments/ner-ontonotes-coref-top/vocab
09/16 09:14:04 AM: 	Vocab namespace edges-ner-ontonotes_labels: size 18
09/16 09:14:04 AM: 	Vocab namespace tokens: size 22840
09/16 09:14:04 AM: 	Vocab namespace bert_uncased: size 30524
09/16 09:14:04 AM: 	Vocab namespace chars: size 77
09/16 09:14:04 AM: 	Finished building vocab.
09/16 09:14:04 AM: 	Task edges-ner-ontonotes (train): Indexing from scratch.
09/16 09:14:18 AM: 	Task edges-ner-ontonotes (train): Saved 49706 instances to ./experiments/ner-ontonotes-coref-top/preproc/edges-ner-ontonotes__train_data
09/16 09:14:18 AM: 	Task edges-ner-ontonotes (val): Indexing from scratch.
09/16 09:14:20 AM: 	Task edges-ner-ontonotes (val): Saved 7610 instances to ./experiments/ner-ontonotes-coref-top/preproc/edges-ner-ontonotes__val_data
09/16 09:14:20 AM: 	Task edges-ner-ontonotes (test): Indexing from scratch.
09/16 09:14:21 AM: 	Task edges-ner-ontonotes (test): Saved 5099 instances to ./experiments/ner-ontonotes-coref-top/preproc/edges-ner-ontonotes__test_data
09/16 09:14:21 AM: 	Finished indexing tasks
09/16 09:14:21 AM: 	Creating trimmed target-only version of edges-ner-ontonotes train.
09/16 09:14:21 AM: 	  Training on 
09/16 09:14:21 AM: 	  Evaluating on edges-ner-ontonotes
09/16 09:14:21 AM: 	Finished loading tasks in 23.827s
09/16 09:14:21 AM: 	 Tasks: ['edges-ner-ontonotes']
09/16 09:14:21 AM: Building model...
09/16 09:14:21 AM: Using BERT model (bert-base-uncased).
09/16 09:14:21 AM: LOADING A FUNETUNED MODEL from: 
09/16 09:14:21 AM: models/coref
09/16 09:14:21 AM: loading configuration file models/coref/config.json
09/16 09:14:21 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 09:14:21 AM: loading weights file models/coref/pytorch_model.bin
09/16 09:14:26 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmprsosdy_2
09/16 09:14:29 AM: copying /tmp/tmprsosdy_2 to cache at ./experiments/ner-ontonotes-coref-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:14:29 AM: creating metadata file for ./experiments/ner-ontonotes-coref-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:14:29 AM: removing temp file /tmp/tmprsosdy_2
09/16 09:14:29 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/ner-ontonotes-coref-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:14:30 AM: Initializing parameters
09/16 09:14:30 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 09:14:30 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 09:14:30 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 09:14:30 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 09:14:30 AM: 	Task 'edges-ner-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-ner-ontonotes"
}
09/16 09:14:54 AM: Model specification:
09/16 09:14:54 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-ner-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=18, bias=True)
    )
  )
)
09/16 09:14:54 AM: Model parameters:
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:54 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:54 AM: 	edges-ner-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 09:14:54 AM: 	edges-ner-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 09:14:54 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 9216 with torch.Size([18, 512])
09/16 09:14:54 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 18 with torch.Size([18])
09/16 09:14:54 AM: Total number of parameters: 109688338 (1.09688e+08)
09/16 09:14:54 AM: Number of trainable parameters: 206098 (206098)
09/16 09:14:54 AM: Finished building model in 32.685s
09/16 09:14:54 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-ner-ontonotes 

09/16 09:14:58 AM: patience = 9
09/16 09:14:59 AM: val_interval = 1000
09/16 09:14:59 AM: max_vals = 250
09/16 09:14:59 AM: cuda_device = 0
09/16 09:14:59 AM: grad_norm = 5.0
09/16 09:14:59 AM: grad_clipping = None
09/16 09:14:59 AM: lr_decay = 0.99
09/16 09:14:59 AM: min_lr = 1e-06
09/16 09:14:59 AM: keep_all_checkpoints = 0
09/16 09:14:59 AM: val_data_limit = 5000
09/16 09:14:59 AM: max_epochs = -1
09/16 09:14:59 AM: dec_val_scale = 250
09/16 09:14:59 AM: training_data_fraction = 1
09/16 09:14:59 AM: type = adam
09/16 09:14:59 AM: parameter_groups = None
09/16 09:14:59 AM: Number of trainable parameters: 206098
09/16 09:14:59 AM: infer_type_and_cast = True
09/16 09:14:59 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:14:59 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:14:59 AM: lr = 0.0001
09/16 09:14:59 AM: amsgrad = True
09/16 09:14:59 AM: type = reduce_on_plateau
09/16 09:14:59 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:14:59 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:14:59 AM: mode = max
09/16 09:14:59 AM: factor = 0.5
09/16 09:14:59 AM: patience = 3
09/16 09:14:59 AM: threshold = 0.0001
09/16 09:14:59 AM: threshold_mode = abs
09/16 09:14:59 AM: verbose = True
09/16 09:14:59 AM: type = adam
09/16 09:14:59 AM: parameter_groups = None
09/16 09:14:59 AM: Number of trainable parameters: 206098
09/16 09:14:59 AM: infer_type_and_cast = True
09/16 09:14:59 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:14:59 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:14:59 AM: lr = 0.0001
09/16 09:14:59 AM: amsgrad = True
09/16 09:14:59 AM: type = reduce_on_plateau
09/16 09:14:59 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:14:59 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:14:59 AM: mode = max
09/16 09:14:59 AM: factor = 0.5
09/16 09:14:59 AM: patience = 3
09/16 09:14:59 AM: threshold = 0.0001
09/16 09:14:59 AM: threshold_mode = abs
09/16 09:14:59 AM: verbose = True
09/16 09:14:59 AM: Starting training without restoring from a checkpoint.
09/16 09:14:59 AM: Training examples per task, before any subsampling: {'edges-ner-ontonotes': 49706}
09/16 09:14:59 AM: Beginning training with stopping criteria based on metric: edges-ner-ontonotes_f1
09/16 09:15:09 AM: Update 78: task edges-ner-ontonotes, batch 78 (78): mcc: 0.0409, acc: 0.0312, precision: 0.0943, recall: 0.0940, f1: 0.0942, edges-ner-ontonotes_loss: 0.3294
09/16 09:15:19 AM: Update 228: task edges-ner-ontonotes, batch 228 (228): mcc: 0.2806, acc: 0.2082, precision: 0.4151, recall: 0.2314, f1: 0.2972, edges-ner-ontonotes_loss: 0.1986
09/16 09:15:29 AM: Update 330: task edges-ner-ontonotes, batch 330 (330): mcc: 0.4075, acc: 0.3046, precision: 0.5760, recall: 0.3231, f1: 0.4140, edges-ner-ontonotes_loss: 0.1679
09/16 09:15:39 AM: Update 463: task edges-ner-ontonotes, batch 463 (463): mcc: 0.5249, acc: 0.4078, precision: 0.6997, recall: 0.4241, f1: 0.5281, edges-ner-ontonotes_loss: 0.1429
09/16 09:15:49 AM: Update 589: task edges-ner-ontonotes, batch 589 (589): mcc: 0.5919, acc: 0.4739, precision: 0.7590, recall: 0.4894, f1: 0.5951, edges-ner-ontonotes_loss: 0.1273
09/16 09:15:59 AM: Update 694: task edges-ner-ontonotes, batch 694 (694): mcc: 0.6297, acc: 0.5123, precision: 0.7909, recall: 0.5275, f1: 0.6329, edges-ner-ontonotes_loss: 0.1179
09/16 09:16:09 AM: Update 820: task edges-ner-ontonotes, batch 820 (820): mcc: 0.6654, acc: 0.5504, precision: 0.8183, recall: 0.5655, f1: 0.6688, edges-ner-ontonotes_loss: 0.1086
09/16 09:16:21 AM: Update 940: task edges-ner-ontonotes, batch 940 (940): mcc: 0.6926, acc: 0.5815, precision: 0.8370, recall: 0.5964, f1: 0.6965, edges-ner-ontonotes_loss: 0.1012
09/16 09:16:25 AM: ***** Step 1000 / Validation 1 *****
09/16 09:16:25 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:16:25 AM: Validating...
09/16 09:16:31 AM: Evaluate: task edges-ner-ontonotes, batch 52 (157): mcc: 0.8024, acc: 0.7315, precision: 0.8872, recall: 0.7438, f1: 0.8092, edges-ner-ontonotes_loss: 0.0665
09/16 09:16:45 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.8400, acc: 0.7735, precision: 0.9169, recall: 0.7844, f1: 0.8455, edges-ner-ontonotes_loss: 0.0564
09/16 09:16:50 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:16:51 AM: Best result seen so far for micro.
09/16 09:16:51 AM: Best result seen so far for macro.
09/16 09:16:51 AM: Updating LR scheduler:
09/16 09:16:51 AM: 	Best result seen so far for macro_avg: 0.851
09/16 09:16:51 AM: 	# validation passes without improvement: 0
09/16 09:16:51 AM: edges-ner-ontonotes_loss: training: 0.098294 validation: 0.053492
09/16 09:16:51 AM: macro_avg: validation: 0.851192
09/16 09:16:51 AM: micro_avg: validation: 0.000000
09/16 09:16:51 AM: edges-ner-ontonotes_mcc: training: 0.703482 validation: 0.845948
09/16 09:16:51 AM: edges-ner-ontonotes_acc: training: 0.594243 validation: 0.779951
09/16 09:16:51 AM: edges-ner-ontonotes_precision: training: 0.843952 validation: 0.922301
09/16 09:16:51 AM: edges-ner-ontonotes_recall: training: 0.609168 validation: 0.790264
09/16 09:16:51 AM: edges-ner-ontonotes_f1: training: 0.707593 validation: 0.851192
09/16 09:16:51 AM: Global learning rate: 0.0001
09/16 09:16:51 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:16:55 AM: Update 1048: task edges-ner-ontonotes, batch 48 (1048): mcc: 0.8578, acc: 0.7837, precision: 0.9355, recall: 0.7998, f1: 0.8624, edges-ner-ontonotes_loss: 0.0478
09/16 09:17:05 AM: Update 1170: task edges-ner-ontonotes, batch 170 (1170): mcc: 0.8602, acc: 0.7910, precision: 0.9326, recall: 0.8067, f1: 0.8651, edges-ner-ontonotes_loss: 0.0471
09/16 09:17:15 AM: Update 1269: task edges-ner-ontonotes, batch 269 (1269): mcc: 0.8571, acc: 0.7874, precision: 0.9305, recall: 0.8029, f1: 0.8620, edges-ner-ontonotes_loss: 0.0477
09/16 09:17:25 AM: Update 1400: task edges-ner-ontonotes, batch 400 (1400): mcc: 0.8467, acc: 0.7742, precision: 0.9234, recall: 0.7906, f1: 0.8519, edges-ner-ontonotes_loss: 0.0514
09/16 09:17:35 AM: Update 1530: task edges-ner-ontonotes, batch 530 (1530): mcc: 0.8430, acc: 0.7700, precision: 0.9204, recall: 0.7868, f1: 0.8483, edges-ner-ontonotes_loss: 0.0522
09/16 09:17:45 AM: Update 1654: task edges-ner-ontonotes, batch 654 (1654): mcc: 0.8434, acc: 0.7704, precision: 0.9198, recall: 0.7879, f1: 0.8487, edges-ner-ontonotes_loss: 0.0515
09/16 09:17:55 AM: Update 1802: task edges-ner-ontonotes, batch 802 (1802): mcc: 0.8446, acc: 0.7722, precision: 0.9200, recall: 0.7898, f1: 0.8500, edges-ner-ontonotes_loss: 0.0505
09/16 09:18:05 AM: Update 1913: task edges-ner-ontonotes, batch 913 (1913): mcc: 0.8470, acc: 0.7753, precision: 0.9209, recall: 0.7934, f1: 0.8524, edges-ner-ontonotes_loss: 0.0496
09/16 09:18:12 AM: ***** Step 2000 / Validation 2 *****
09/16 09:18:12 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:18:12 AM: Validating...
09/16 09:18:16 AM: Evaluate: task edges-ner-ontonotes, batch 35 (157): mcc: 0.8453, acc: 0.7854, precision: 0.9111, recall: 0.7990, f1: 0.8514, edges-ner-ontonotes_loss: 0.0476
09/16 09:18:26 AM: Evaluate: task edges-ner-ontonotes, batch 115 (157): mcc: 0.8852, acc: 0.8335, precision: 0.9404, recall: 0.8446, f1: 0.8899, edges-ner-ontonotes_loss: 0.0385
09/16 09:18:30 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:18:30 AM: Best result seen so far for macro.
09/16 09:18:30 AM: Updating LR scheduler:
09/16 09:18:30 AM: 	Best result seen so far for macro_avg: 0.892
09/16 09:18:30 AM: 	# validation passes without improvement: 0
09/16 09:18:30 AM: edges-ner-ontonotes_loss: training: 0.048810 validation: 0.037391
09/16 09:18:30 AM: macro_avg: validation: 0.891929
09/16 09:18:30 AM: micro_avg: validation: 0.000000
09/16 09:18:30 AM: edges-ner-ontonotes_mcc: training: 0.849210 validation: 0.887434
09/16 09:18:30 AM: edges-ner-ontonotes_acc: training: 0.778812 validation: 0.833258
09/16 09:18:30 AM: edges-ner-ontonotes_precision: training: 0.920769 validation: 0.943796
09/16 09:18:30 AM: edges-ner-ontonotes_recall: training: 0.797435 validation: 0.845466
09/16 09:18:30 AM: edges-ner-ontonotes_f1: training: 0.854675 validation: 0.891929
09/16 09:18:30 AM: Global learning rate: 0.0001
09/16 09:18:30 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:18:36 AM: Update 2068: task edges-ner-ontonotes, batch 68 (2068): mcc: 0.8822, acc: 0.8244, precision: 0.9344, recall: 0.8447, f1: 0.8873, edges-ner-ontonotes_loss: 0.0369
09/16 09:18:46 AM: Update 2183: task edges-ner-ontonotes, batch 183 (2183): mcc: 0.8807, acc: 0.8248, precision: 0.9314, recall: 0.8447, f1: 0.8859, edges-ner-ontonotes_loss: 0.0372
09/16 09:18:57 AM: Update 2307: task edges-ner-ontonotes, batch 307 (2307): mcc: 0.8861, acc: 0.8305, precision: 0.9353, recall: 0.8508, f1: 0.8910, edges-ner-ontonotes_loss: 0.0361
09/16 09:19:07 AM: Update 2436: task edges-ner-ontonotes, batch 436 (2436): mcc: 0.8888, acc: 0.8345, precision: 0.9366, recall: 0.8546, f1: 0.8937, edges-ner-ontonotes_loss: 0.0351
09/16 09:19:17 AM: Update 2534: task edges-ner-ontonotes, batch 534 (2534): mcc: 0.8904, acc: 0.8365, precision: 0.9378, recall: 0.8565, f1: 0.8953, edges-ner-ontonotes_loss: 0.0348
09/16 09:19:27 AM: Update 2663: task edges-ner-ontonotes, batch 663 (2663): mcc: 0.8919, acc: 0.8379, precision: 0.9382, recall: 0.8587, f1: 0.8967, edges-ner-ontonotes_loss: 0.0345
09/16 09:19:37 AM: Update 2788: task edges-ner-ontonotes, batch 788 (2788): mcc: 0.8932, acc: 0.8395, precision: 0.9386, recall: 0.8609, f1: 0.8980, edges-ner-ontonotes_loss: 0.0341
09/16 09:19:47 AM: Update 2884: task edges-ner-ontonotes, batch 884 (2884): mcc: 0.8901, acc: 0.8356, precision: 0.9361, recall: 0.8575, f1: 0.8951, edges-ner-ontonotes_loss: 0.0352
09/16 09:19:56 AM: ***** Step 3000 / Validation 3 *****
09/16 09:19:56 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:19:56 AM: Validating...
09/16 09:19:57 AM: Evaluate: task edges-ner-ontonotes, batch 11 (157): mcc: 0.7987, acc: 0.7274, precision: 0.8704, recall: 0.7518, f1: 0.8068, edges-ner-ontonotes_loss: 0.0546
09/16 09:20:07 AM: Evaluate: task edges-ner-ontonotes, batch 100 (157): mcc: 0.8842, acc: 0.8372, precision: 0.9303, recall: 0.8519, f1: 0.8894, edges-ner-ontonotes_loss: 0.0366
09/16 09:20:14 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:20:14 AM: Best result seen so far for macro.
09/16 09:20:14 AM: Updating LR scheduler:
09/16 09:20:14 AM: 	Best result seen so far for macro_avg: 0.903
09/16 09:20:14 AM: 	# validation passes without improvement: 0
09/16 09:20:14 AM: edges-ner-ontonotes_loss: training: 0.036421 validation: 0.032772
09/16 09:20:14 AM: macro_avg: validation: 0.902938
09/16 09:20:14 AM: micro_avg: validation: 0.000000
09/16 09:20:14 AM: edges-ner-ontonotes_mcc: training: 0.886751 validation: 0.898405
09/16 09:20:14 AM: edges-ner-ontonotes_acc: training: 0.831389 validation: 0.852138
09/16 09:20:14 AM: edges-ner-ontonotes_precision: training: 0.933705 validation: 0.943329
09/16 09:20:14 AM: edges-ner-ontonotes_recall: training: 0.853527 validation: 0.865863
09/16 09:20:14 AM: edges-ner-ontonotes_f1: training: 0.891817 validation: 0.902938
09/16 09:20:14 AM: Global learning rate: 0.0001
09/16 09:20:14 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:20:17 AM: Update 3031: task edges-ner-ontonotes, batch 31 (3031): mcc: 0.8665, acc: 0.8037, precision: 0.9245, recall: 0.8252, f1: 0.8720, edges-ner-ontonotes_loss: 0.0444
09/16 09:20:27 AM: Update 3146: task edges-ner-ontonotes, batch 146 (3146): mcc: 0.8637, acc: 0.8039, precision: 0.9169, recall: 0.8272, f1: 0.8697, edges-ner-ontonotes_loss: 0.0438
09/16 09:20:37 AM: Update 3298: task edges-ner-ontonotes, batch 298 (3298): mcc: 0.8713, acc: 0.8133, precision: 0.9209, recall: 0.8371, f1: 0.8770, edges-ner-ontonotes_loss: 0.0412
09/16 09:20:47 AM: Update 3426: task edges-ner-ontonotes, batch 426 (3426): mcc: 0.8745, acc: 0.8171, precision: 0.9229, recall: 0.8413, f1: 0.8802, edges-ner-ontonotes_loss: 0.0398
09/16 09:20:57 AM: Update 3551: task edges-ner-ontonotes, batch 551 (3551): mcc: 0.8783, acc: 0.8225, precision: 0.9246, recall: 0.8465, f1: 0.8838, edges-ner-ontonotes_loss: 0.0386
09/16 09:21:07 AM: Update 3680: task edges-ner-ontonotes, batch 680 (3680): mcc: 0.8823, acc: 0.8280, precision: 0.9271, recall: 0.8516, f1: 0.8877, edges-ner-ontonotes_loss: 0.0375
09/16 09:21:17 AM: Update 3779: task edges-ner-ontonotes, batch 779 (3779): mcc: 0.8853, acc: 0.8320, precision: 0.9284, recall: 0.8559, f1: 0.8907, edges-ner-ontonotes_loss: 0.0368
09/16 09:21:27 AM: Update 3905: task edges-ner-ontonotes, batch 905 (3905): mcc: 0.8891, acc: 0.8365, precision: 0.9308, recall: 0.8605, f1: 0.8943, edges-ner-ontonotes_loss: 0.0356
09/16 09:21:35 AM: ***** Step 4000 / Validation 4 *****
09/16 09:21:35 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:21:35 AM: Validating...
09/16 09:21:37 AM: Evaluate: task edges-ner-ontonotes, batch 28 (157): mcc: 0.8476, acc: 0.7905, precision: 0.8969, recall: 0.8163, f1: 0.8547, edges-ner-ontonotes_loss: 0.0484
09/16 09:21:48 AM: Evaluate: task edges-ner-ontonotes, batch 112 (157): mcc: 0.9014, acc: 0.8608, precision: 0.9374, recall: 0.8770, f1: 0.9062, edges-ner-ontonotes_loss: 0.0337
09/16 09:21:54 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:21:54 AM: Best result seen so far for macro.
09/16 09:21:54 AM: Updating LR scheduler:
09/16 09:21:54 AM: 	Best result seen so far for macro_avg: 0.913
09/16 09:21:54 AM: 	# validation passes without improvement: 0
09/16 09:21:54 AM: edges-ner-ontonotes_loss: training: 0.034857 validation: 0.030596
09/16 09:21:54 AM: macro_avg: validation: 0.913273
09/16 09:21:54 AM: micro_avg: validation: 0.000000
09/16 09:21:54 AM: edges-ner-ontonotes_mcc: training: 0.891454 validation: 0.908857
09/16 09:21:54 AM: edges-ner-ontonotes_acc: training: 0.839336 validation: 0.868972
09/16 09:21:54 AM: edges-ner-ontonotes_precision: training: 0.932216 validation: 0.943273
09/16 09:21:54 AM: edges-ner-ontonotes_recall: training: 0.863540 validation: 0.885123
09/16 09:21:54 AM: edges-ner-ontonotes_f1: training: 0.896564 validation: 0.913273
09/16 09:21:54 AM: Global learning rate: 0.0001
09/16 09:21:54 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:21:58 AM: Update 4048: task edges-ner-ontonotes, batch 48 (4048): mcc: 0.9160, acc: 0.8713, precision: 0.9461, recall: 0.8956, f1: 0.9202, edges-ner-ontonotes_loss: 0.0268
09/16 09:22:08 AM: Update 4148: task edges-ner-ontonotes, batch 148 (4148): mcc: 0.9113, acc: 0.8649, precision: 0.9445, recall: 0.8885, f1: 0.9156, edges-ner-ontonotes_loss: 0.0281
09/16 09:22:18 AM: Update 4273: task edges-ner-ontonotes, batch 273 (4273): mcc: 0.9119, acc: 0.8660, precision: 0.9447, recall: 0.8894, f1: 0.9162, edges-ner-ontonotes_loss: 0.0280
09/16 09:22:28 AM: Update 4384: task edges-ner-ontonotes, batch 384 (4384): mcc: 0.9081, acc: 0.8609, precision: 0.9413, recall: 0.8855, f1: 0.9126, edges-ner-ontonotes_loss: 0.0291
09/16 09:22:38 AM: Update 4511: task edges-ner-ontonotes, batch 511 (4511): mcc: 0.9003, acc: 0.8505, precision: 0.9368, recall: 0.8755, f1: 0.9051, edges-ner-ontonotes_loss: 0.0326
09/16 09:22:48 AM: Update 4636: task edges-ner-ontonotes, batch 636 (4636): mcc: 0.8948, acc: 0.8443, precision: 0.9329, recall: 0.8691, f1: 0.8999, edges-ner-ontonotes_loss: 0.0347
09/16 09:22:58 AM: Update 4761: task edges-ner-ontonotes, batch 761 (4761): mcc: 0.8931, acc: 0.8425, precision: 0.9314, recall: 0.8673, f1: 0.8982, edges-ner-ontonotes_loss: 0.0352
09/16 09:23:08 AM: Update 4909: task edges-ner-ontonotes, batch 909 (4909): mcc: 0.8927, acc: 0.8422, precision: 0.9309, recall: 0.8671, f1: 0.8979, edges-ner-ontonotes_loss: 0.0352
09/16 09:23:17 AM: ***** Step 5000 / Validation 5 *****
09/16 09:23:17 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:23:17 AM: Validating...
09/16 09:23:18 AM: Evaluate: task edges-ner-ontonotes, batch 14 (157): mcc: 0.8435, acc: 0.7798, precision: 0.8989, recall: 0.8070, f1: 0.8505, edges-ner-ontonotes_loss: 0.0435
09/16 09:23:28 AM: Evaluate: task edges-ner-ontonotes, batch 101 (157): mcc: 0.9038, acc: 0.8636, precision: 0.9410, recall: 0.8779, f1: 0.9083, edges-ner-ontonotes_loss: 0.0318
09/16 09:23:35 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:23:35 AM: Best result seen so far for macro.
09/16 09:23:35 AM: Updating LR scheduler:
09/16 09:23:35 AM: 	Best result seen so far for macro_avg: 0.920
09/16 09:23:35 AM: 	# validation passes without improvement: 0
09/16 09:23:35 AM: edges-ner-ontonotes_loss: training: 0.035225 validation: 0.028352
09/16 09:23:35 AM: macro_avg: validation: 0.919612
09/16 09:23:35 AM: micro_avg: validation: 0.000000
09/16 09:23:35 AM: edges-ner-ontonotes_mcc: training: 0.892344 validation: 0.915540
09/16 09:23:35 AM: edges-ner-ontonotes_acc: training: 0.841819 validation: 0.877161
09/16 09:23:35 AM: edges-ner-ontonotes_precision: training: 0.930448 validation: 0.949306
09/16 09:23:35 AM: edges-ner-ontonotes_recall: training: 0.866849 validation: 0.891720
09/16 09:23:35 AM: edges-ner-ontonotes_f1: training: 0.897523 validation: 0.919612
09/16 09:23:35 AM: Global learning rate: 0.0001
09/16 09:23:35 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:23:38 AM: Update 5032: task edges-ner-ontonotes, batch 32 (5032): mcc: 0.8909, acc: 0.8435, precision: 0.9287, recall: 0.8659, f1: 0.8962, edges-ner-ontonotes_loss: 0.0351
09/16 09:23:48 AM: Update 5159: task edges-ner-ontonotes, batch 159 (5159): mcc: 0.8976, acc: 0.8518, precision: 0.9318, recall: 0.8753, f1: 0.9027, edges-ner-ontonotes_loss: 0.0330
09/16 09:23:58 AM: Update 5293: task edges-ner-ontonotes, batch 293 (5293): mcc: 0.9004, acc: 0.8541, precision: 0.9338, recall: 0.8784, f1: 0.9053, edges-ner-ontonotes_loss: 0.0315
09/16 09:24:08 AM: Update 5400: task edges-ner-ontonotes, batch 400 (5400): mcc: 0.9045, acc: 0.8586, precision: 0.9363, recall: 0.8838, f1: 0.9093, edges-ner-ontonotes_loss: 0.0302
09/16 09:24:18 AM: Update 5522: task edges-ner-ontonotes, batch 522 (5522): mcc: 0.9077, acc: 0.8628, precision: 0.9385, recall: 0.8875, f1: 0.9123, edges-ner-ontonotes_loss: 0.0294
09/16 09:24:28 AM: Update 5617: task edges-ner-ontonotes, batch 617 (5617): mcc: 0.9089, acc: 0.8642, precision: 0.9396, recall: 0.8887, f1: 0.9134, edges-ner-ontonotes_loss: 0.0289
09/16 09:24:38 AM: Update 5735: task edges-ner-ontonotes, batch 735 (5735): mcc: 0.9098, acc: 0.8652, precision: 0.9400, recall: 0.8900, f1: 0.9143, edges-ner-ontonotes_loss: 0.0286
09/16 09:24:48 AM: Update 5865: task edges-ner-ontonotes, batch 865 (5865): mcc: 0.9103, acc: 0.8657, precision: 0.9403, recall: 0.8906, f1: 0.9148, edges-ner-ontonotes_loss: 0.0285
09/16 09:24:59 AM: Update 5972: task edges-ner-ontonotes, batch 972 (5972): mcc: 0.9087, acc: 0.8638, precision: 0.9393, recall: 0.8887, f1: 0.9133, edges-ner-ontonotes_loss: 0.0291
09/16 09:25:01 AM: ***** Step 6000 / Validation 6 *****
09/16 09:25:01 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:25:01 AM: Validating...
09/16 09:25:09 AM: Evaluate: task edges-ner-ontonotes, batch 70 (157): mcc: 0.8966, acc: 0.8555, precision: 0.9310, recall: 0.8741, f1: 0.9017, edges-ner-ontonotes_loss: 0.0345
09/16 09:25:19 AM: Evaluate: task edges-ner-ontonotes, batch 149 (157): mcc: 0.9170, acc: 0.8795, precision: 0.9477, recall: 0.8959, f1: 0.9211, edges-ner-ontonotes_loss: 0.0279
09/16 09:25:20 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:25:20 AM: Best result seen so far for macro.
09/16 09:25:20 AM: Updating LR scheduler:
09/16 09:25:20 AM: 	Best result seen so far for macro_avg: 0.921
09/16 09:25:20 AM: 	# validation passes without improvement: 0
09/16 09:25:20 AM: edges-ner-ontonotes_loss: training: 0.029474 validation: 0.027644
09/16 09:25:20 AM: macro_avg: validation: 0.921333
09/16 09:25:20 AM: micro_avg: validation: 0.000000
09/16 09:25:20 AM: edges-ner-ontonotes_mcc: training: 0.907773 validation: 0.917234
09/16 09:25:20 AM: edges-ner-ontonotes_acc: training: 0.862509 validation: 0.879588
09/16 09:25:20 AM: edges-ner-ontonotes_precision: training: 0.938732 validation: 0.947584
09/16 09:25:20 AM: edges-ner-ontonotes_recall: training: 0.887457 validation: 0.896497
09/16 09:25:20 AM: edges-ner-ontonotes_f1: training: 0.912374 validation: 0.921333
09/16 09:25:20 AM: Global learning rate: 0.0001
09/16 09:25:20 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:25:29 AM: Update 6115: task edges-ner-ontonotes, batch 115 (6115): mcc: 0.8770, acc: 0.8247, precision: 0.9160, recall: 0.8523, f1: 0.8830, edges-ner-ontonotes_loss: 0.0406
09/16 09:25:39 AM: Update 6225: task edges-ner-ontonotes, batch 225 (6225): mcc: 0.8779, acc: 0.8249, precision: 0.9183, recall: 0.8516, f1: 0.8837, edges-ner-ontonotes_loss: 0.0410
09/16 09:25:49 AM: Update 6378: task edges-ner-ontonotes, batch 378 (6378): mcc: 0.8824, acc: 0.8308, precision: 0.9215, recall: 0.8571, f1: 0.8881, edges-ner-ontonotes_loss: 0.0384
09/16 09:25:59 AM: Update 6525: task edges-ner-ontonotes, batch 525 (6525): mcc: 0.8858, acc: 0.8355, precision: 0.9233, recall: 0.8615, f1: 0.8913, edges-ner-ontonotes_loss: 0.0371
09/16 09:26:09 AM: Update 6635: task edges-ner-ontonotes, batch 635 (6635): mcc: 0.8894, acc: 0.8403, precision: 0.9257, recall: 0.8660, f1: 0.8948, edges-ner-ontonotes_loss: 0.0358
09/16 09:26:19 AM: Update 6766: task edges-ner-ontonotes, batch 766 (6766): mcc: 0.8924, acc: 0.8443, precision: 0.9274, recall: 0.8698, f1: 0.8977, edges-ner-ontonotes_loss: 0.0350
09/16 09:26:29 AM: Update 6865: task edges-ner-ontonotes, batch 865 (6865): mcc: 0.8941, acc: 0.8469, precision: 0.9284, recall: 0.8720, f1: 0.8993, edges-ner-ontonotes_loss: 0.0343
09/16 09:26:39 AM: Update 6992: task edges-ner-ontonotes, batch 992 (6992): mcc: 0.8975, acc: 0.8511, precision: 0.9306, recall: 0.8761, f1: 0.9026, edges-ner-ontonotes_loss: 0.0332
09/16 09:26:40 AM: ***** Step 7000 / Validation 7 *****
09/16 09:26:40 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:26:40 AM: Validating...
09/16 09:26:49 AM: Evaluate: task edges-ner-ontonotes, batch 82 (157): mcc: 0.9047, acc: 0.8649, precision: 0.9378, recall: 0.8825, f1: 0.9094, edges-ner-ontonotes_loss: 0.0335
09/16 09:26:59 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:26:59 AM: Best result seen so far for macro.
09/16 09:26:59 AM: Updating LR scheduler:
09/16 09:26:59 AM: 	Best result seen so far for macro_avg: 0.925
09/16 09:26:59 AM: 	# validation passes without improvement: 0
09/16 09:26:59 AM: edges-ner-ontonotes_loss: training: 0.033159 validation: 0.027437
09/16 09:26:59 AM: macro_avg: validation: 0.924582
09/16 09:26:59 AM: micro_avg: validation: 0.000000
09/16 09:26:59 AM: edges-ner-ontonotes_mcc: training: 0.897822 validation: 0.920564
09/16 09:26:59 AM: edges-ner-ontonotes_acc: training: 0.851446 validation: 0.884592
09/16 09:26:59 AM: edges-ner-ontonotes_precision: training: 0.930880 validation: 0.947620
09/16 09:26:59 AM: edges-ner-ontonotes_recall: training: 0.876550 validation: 0.902639
09/16 09:26:59 AM: edges-ner-ontonotes_f1: training: 0.902899 validation: 0.924582
09/16 09:26:59 AM: Global learning rate: 0.0001
09/16 09:26:59 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:26:59 AM: Update 7006: task edges-ner-ontonotes, batch 6 (7006): mcc: 0.9346, acc: 0.9004, precision: 0.9499, recall: 0.9267, f1: 0.9382, edges-ner-ontonotes_loss: 0.0221
09/16 09:27:09 AM: Update 7128: task edges-ner-ontonotes, batch 128 (7128): mcc: 0.9209, acc: 0.8796, precision: 0.9459, recall: 0.9050, f1: 0.9250, edges-ner-ontonotes_loss: 0.0249
09/16 09:27:19 AM: Update 7236: task edges-ner-ontonotes, batch 236 (7236): mcc: 0.9185, acc: 0.8773, precision: 0.9446, recall: 0.9018, f1: 0.9227, edges-ner-ontonotes_loss: 0.0256
09/16 09:27:29 AM: Update 7360: task edges-ner-ontonotes, batch 360 (7360): mcc: 0.9196, acc: 0.8781, precision: 0.9456, recall: 0.9029, f1: 0.9237, edges-ner-ontonotes_loss: 0.0252
09/16 09:27:41 AM: Update 7477: task edges-ner-ontonotes, batch 477 (7477): mcc: 0.9183, acc: 0.8766, precision: 0.9445, recall: 0.9015, f1: 0.9225, edges-ner-ontonotes_loss: 0.0258
09/16 09:27:51 AM: Update 7603: task edges-ner-ontonotes, batch 603 (7603): mcc: 0.9101, acc: 0.8660, precision: 0.9392, recall: 0.8913, f1: 0.9146, edges-ner-ontonotes_loss: 0.0290
09/16 09:28:01 AM: Update 7728: task edges-ner-ontonotes, batch 728 (7728): mcc: 0.9057, acc: 0.8605, precision: 0.9362, recall: 0.8862, f1: 0.9105, edges-ner-ontonotes_loss: 0.0309
09/16 09:28:11 AM: Update 7850: task edges-ner-ontonotes, batch 850 (7850): mcc: 0.9038, acc: 0.8580, precision: 0.9350, recall: 0.8837, f1: 0.9086, edges-ner-ontonotes_loss: 0.0318
09/16 09:28:21 AM: Update 7999: task edges-ner-ontonotes, batch 999 (7999): mcc: 0.9030, acc: 0.8571, precision: 0.9343, recall: 0.8828, f1: 0.9078, edges-ner-ontonotes_loss: 0.0320
09/16 09:28:21 AM: ***** Step 8000 / Validation 8 *****
09/16 09:28:21 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:28:21 AM: Validating...
09/16 09:28:31 AM: Evaluate: task edges-ner-ontonotes, batch 90 (157): mcc: 0.9133, acc: 0.8755, precision: 0.9472, recall: 0.8895, f1: 0.9175, edges-ner-ontonotes_loss: 0.0297
09/16 09:28:40 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:28:40 AM: Best result seen so far for macro.
09/16 09:28:40 AM: Updating LR scheduler:
09/16 09:28:40 AM: 	Best result seen so far for macro_avg: 0.925
09/16 09:28:40 AM: 	# validation passes without improvement: 0
09/16 09:28:40 AM: edges-ner-ontonotes_loss: training: 0.031981 validation: 0.026289
09/16 09:28:40 AM: macro_avg: validation: 0.925330
09/16 09:28:40 AM: micro_avg: validation: 0.000000
09/16 09:28:40 AM: edges-ner-ontonotes_mcc: training: 0.902943 validation: 0.921543
09/16 09:28:40 AM: edges-ner-ontonotes_acc: training: 0.857052 validation: 0.885729
09/16 09:28:40 AM: edges-ner-ontonotes_precision: training: 0.934252 validation: 0.954018
09/16 09:28:40 AM: edges-ner-ontonotes_recall: training: 0.882804 validation: 0.898317
09/16 09:28:40 AM: edges-ner-ontonotes_f1: training: 0.907800 validation: 0.925330
09/16 09:28:40 AM: Global learning rate: 0.0001
09/16 09:28:40 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:28:41 AM: Update 8015: task edges-ner-ontonotes, batch 15 (8015): mcc: 0.9016, acc: 0.8619, precision: 0.9330, recall: 0.8815, f1: 0.9065, edges-ner-ontonotes_loss: 0.0302
09/16 09:28:51 AM: Update 8129: task edges-ner-ontonotes, batch 129 (8129): mcc: 0.9025, acc: 0.8559, precision: 0.9347, recall: 0.8816, f1: 0.9074, edges-ner-ontonotes_loss: 0.0315
09/16 09:29:01 AM: Update 8265: task edges-ner-ontonotes, batch 265 (8265): mcc: 0.9066, acc: 0.8621, precision: 0.9362, recall: 0.8877, f1: 0.9113, edges-ner-ontonotes_loss: 0.0304
09/16 09:29:11 AM: Update 8393: task edges-ner-ontonotes, batch 393 (8393): mcc: 0.9069, acc: 0.8629, precision: 0.9360, recall: 0.8885, f1: 0.9116, edges-ner-ontonotes_loss: 0.0301
09/16 09:29:22 AM: Update 8498: task edges-ner-ontonotes, batch 498 (8498): mcc: 0.9096, acc: 0.8661, precision: 0.9374, recall: 0.8921, f1: 0.9142, edges-ner-ontonotes_loss: 0.0292
09/16 09:29:32 AM: Update 8619: task edges-ner-ontonotes, batch 619 (8619): mcc: 0.9129, acc: 0.8701, precision: 0.9396, recall: 0.8961, f1: 0.9174, edges-ner-ontonotes_loss: 0.0282
09/16 09:29:42 AM: Update 8722: task edges-ner-ontonotes, batch 722 (8722): mcc: 0.9142, acc: 0.8718, precision: 0.9404, recall: 0.8978, f1: 0.9186, edges-ner-ontonotes_loss: 0.0275
09/16 09:29:52 AM: Update 8845: task edges-ner-ontonotes, batch 845 (8845): mcc: 0.9156, acc: 0.8736, precision: 0.9412, recall: 0.8996, f1: 0.9199, edges-ner-ontonotes_loss: 0.0272
09/16 09:30:02 AM: Update 8973: task edges-ner-ontonotes, batch 973 (8973): mcc: 0.9159, acc: 0.8739, precision: 0.9413, recall: 0.9000, f1: 0.9202, edges-ner-ontonotes_loss: 0.0269
09/16 09:30:04 AM: ***** Step 9000 / Validation 9 *****
09/16 09:30:04 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:30:04 AM: Validating...
09/16 09:30:12 AM: Evaluate: task edges-ner-ontonotes, batch 65 (157): mcc: 0.9006, acc: 0.8618, precision: 0.9324, recall: 0.8802, f1: 0.9056, edges-ner-ontonotes_loss: 0.0348
09/16 09:30:22 AM: Evaluate: task edges-ner-ontonotes, batch 143 (157): mcc: 0.9238, acc: 0.8899, precision: 0.9510, recall: 0.9054, f1: 0.9276, edges-ner-ontonotes_loss: 0.0270
09/16 09:30:23 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:30:23 AM: Best result seen so far for macro.
09/16 09:30:23 AM: Updating LR scheduler:
09/16 09:30:23 AM: 	Best result seen so far for macro_avg: 0.928
09/16 09:30:23 AM: 	# validation passes without improvement: 0
09/16 09:30:23 AM: edges-ner-ontonotes_loss: training: 0.026840 validation: 0.026513
09/16 09:30:23 AM: macro_avg: validation: 0.927620
09/16 09:30:23 AM: micro_avg: validation: 0.000000
09/16 09:30:23 AM: edges-ner-ontonotes_mcc: training: 0.916067 validation: 0.923790
09/16 09:30:23 AM: edges-ner-ontonotes_acc: training: 0.874171 validation: 0.889597
09/16 09:30:23 AM: edges-ner-ontonotes_precision: training: 0.941366 validation: 0.951159
09/16 09:30:23 AM: edges-ner-ontonotes_recall: training: 0.900320 validation: 0.905217
09/16 09:30:23 AM: edges-ner-ontonotes_f1: training: 0.920386 validation: 0.927620
09/16 09:30:23 AM: Global learning rate: 0.0001
09/16 09:30:23 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:30:32 AM: Update 9076: task edges-ner-ontonotes, batch 76 (9076): mcc: 0.8915, acc: 0.8422, precision: 0.9234, recall: 0.8720, f1: 0.8970, edges-ner-ontonotes_loss: 0.0360
09/16 09:30:42 AM: Update 9209: task edges-ner-ontonotes, batch 209 (9209): mcc: 0.8888, acc: 0.8396, precision: 0.9221, recall: 0.8682, f1: 0.8944, edges-ner-ontonotes_loss: 0.0376
09/16 09:30:53 AM: Update 9337: task edges-ner-ontonotes, batch 337 (9337): mcc: 0.8871, acc: 0.8388, precision: 0.9215, recall: 0.8657, f1: 0.8928, edges-ner-ontonotes_loss: 0.0387
09/16 09:31:03 AM: Update 9479: task edges-ner-ontonotes, batch 479 (9479): mcc: 0.8902, acc: 0.8424, precision: 0.9234, recall: 0.8695, f1: 0.8957, edges-ner-ontonotes_loss: 0.0370
09/16 09:31:13 AM: Update 9626: task edges-ner-ontonotes, batch 626 (9626): mcc: 0.8919, acc: 0.8454, precision: 0.9248, recall: 0.8714, f1: 0.8973, edges-ner-ontonotes_loss: 0.0360
09/16 09:31:23 AM: Update 9730: task edges-ner-ontonotes, batch 730 (9730): mcc: 0.8938, acc: 0.8472, precision: 0.9263, recall: 0.8735, f1: 0.8991, edges-ner-ontonotes_loss: 0.0352
09/16 09:31:33 AM: Update 9863: task edges-ner-ontonotes, batch 863 (9863): mcc: 0.8966, acc: 0.8508, precision: 0.9282, recall: 0.8768, f1: 0.9018, edges-ner-ontonotes_loss: 0.0343
09/16 09:31:43 AM: Update 9964: task edges-ner-ontonotes, batch 964 (9964): mcc: 0.8983, acc: 0.8528, precision: 0.9292, recall: 0.8790, f1: 0.9034, edges-ner-ontonotes_loss: 0.0337
09/16 09:31:46 AM: ***** Step 10000 / Validation 10 *****
09/16 09:31:46 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:31:46 AM: Validating...
09/16 09:31:53 AM: Evaluate: task edges-ner-ontonotes, batch 67 (157): mcc: 0.9040, acc: 0.8674, precision: 0.9323, recall: 0.8867, f1: 0.9089, edges-ner-ontonotes_loss: 0.0330
09/16 09:32:03 AM: Evaluate: task edges-ner-ontonotes, batch 144 (157): mcc: 0.9243, acc: 0.8917, precision: 0.9475, recall: 0.9097, f1: 0.9282, edges-ner-ontonotes_loss: 0.0262
09/16 09:32:04 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:32:04 AM: Best result seen so far for macro.
09/16 09:32:04 AM: Updating LR scheduler:
09/16 09:32:04 AM: 	Best result seen so far for macro_avg: 0.928
09/16 09:32:04 AM: 	# validation passes without improvement: 0
09/16 09:32:04 AM: edges-ner-ontonotes_loss: training: 0.033274 validation: 0.025931
09/16 09:32:04 AM: macro_avg: validation: 0.928146
09/16 09:32:04 AM: micro_avg: validation: 0.000000
09/16 09:32:04 AM: edges-ner-ontonotes_mcc: training: 0.899423 validation: 0.924216
09/16 09:32:04 AM: edges-ner-ontonotes_acc: training: 0.854111 validation: 0.891189
09/16 09:32:04 AM: edges-ner-ontonotes_precision: training: 0.930081 validation: 0.947119
09/16 09:32:04 AM: edges-ner-ontonotes_recall: training: 0.880283 validation: 0.909918
09/16 09:32:04 AM: edges-ner-ontonotes_f1: training: 0.904497 validation: 0.928146
09/16 09:32:04 AM: Global learning rate: 0.0001
09/16 09:32:04 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:32:13 AM: Update 10100: task edges-ner-ontonotes, batch 100 (10100): mcc: 0.9229, acc: 0.8820, precision: 0.9465, recall: 0.9080, f1: 0.9269, edges-ner-ontonotes_loss: 0.0253
09/16 09:32:23 AM: Update 10223: task edges-ner-ontonotes, batch 223 (10223): mcc: 0.9235, acc: 0.8838, precision: 0.9464, recall: 0.9093, f1: 0.9275, edges-ner-ontonotes_loss: 0.0244
09/16 09:32:33 AM: Update 10327: task edges-ner-ontonotes, batch 327 (10327): mcc: 0.9226, acc: 0.8826, precision: 0.9457, recall: 0.9084, f1: 0.9266, edges-ner-ontonotes_loss: 0.0244
09/16 09:32:43 AM: Update 10453: task edges-ner-ontonotes, batch 453 (10453): mcc: 0.9228, acc: 0.8828, precision: 0.9457, recall: 0.9085, f1: 0.9268, edges-ner-ontonotes_loss: 0.0245
09/16 09:32:53 AM: Update 10581: task edges-ner-ontonotes, batch 581 (10581): mcc: 0.9228, acc: 0.8828, precision: 0.9458, recall: 0.9086, f1: 0.9269, edges-ner-ontonotes_loss: 0.0245
09/16 09:33:03 AM: Update 10688: task edges-ner-ontonotes, batch 688 (10688): mcc: 0.9173, acc: 0.8753, precision: 0.9422, recall: 0.9017, f1: 0.9215, edges-ner-ontonotes_loss: 0.0266
09/16 09:33:13 AM: Update 10820: task edges-ner-ontonotes, batch 820 (10820): mcc: 0.9128, acc: 0.8699, precision: 0.9390, recall: 0.8965, f1: 0.9172, edges-ner-ontonotes_loss: 0.0285
09/16 09:33:23 AM: Update 10926: task edges-ner-ontonotes, batch 926 (10926): mcc: 0.9098, acc: 0.8665, precision: 0.9369, recall: 0.8930, f1: 0.9144, edges-ner-ontonotes_loss: 0.0298
09/16 09:33:28 AM: ***** Step 11000 / Validation 11 *****
09/16 09:33:28 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:33:28 AM: Validating...
09/16 09:33:34 AM: Evaluate: task edges-ner-ontonotes, batch 50 (157): mcc: 0.8998, acc: 0.8639, precision: 0.9290, recall: 0.8820, f1: 0.9049, edges-ner-ontonotes_loss: 0.0324
09/16 09:33:44 AM: Evaluate: task edges-ner-ontonotes, batch 124 (157): mcc: 0.9201, acc: 0.8857, precision: 0.9522, recall: 0.8975, f1: 0.9240, edges-ner-ontonotes_loss: 0.0272
09/16 09:33:47 AM: Updating LR scheduler:
09/16 09:33:47 AM: 	Best result seen so far for macro_avg: 0.928
09/16 09:33:47 AM: 	# validation passes without improvement: 1
09/16 09:33:47 AM: edges-ner-ontonotes_loss: training: 0.030059 validation: 0.025563
09/16 09:33:47 AM: macro_avg: validation: 0.927069
09/16 09:33:47 AM: micro_avg: validation: 0.000000
09/16 09:33:47 AM: edges-ner-ontonotes_mcc: training: 0.909148 validation: 0.923352
09/16 09:33:47 AM: edges-ner-ontonotes_acc: training: 0.865554 validation: 0.888687
09/16 09:33:47 AM: edges-ner-ontonotes_precision: training: 0.936385 validation: 0.954980
09/16 09:33:47 AM: edges-ner-ontonotes_recall: training: 0.892267 validation: 0.900743
09/16 09:33:47 AM: edges-ner-ontonotes_f1: training: 0.913794 validation: 0.927069
09/16 09:33:47 AM: Global learning rate: 0.0001
09/16 09:33:47 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:33:54 AM: Update 11095: task edges-ner-ontonotes, batch 95 (11095): mcc: 0.9013, acc: 0.8539, precision: 0.9336, recall: 0.8804, f1: 0.9062, edges-ner-ontonotes_loss: 0.0315
09/16 09:34:04 AM: Update 11214: task edges-ner-ontonotes, batch 214 (11214): mcc: 0.8984, acc: 0.8501, precision: 0.9293, recall: 0.8791, f1: 0.9035, edges-ner-ontonotes_loss: 0.0317
09/16 09:34:14 AM: Update 11345: task edges-ner-ontonotes, batch 345 (11345): mcc: 0.9026, acc: 0.8565, precision: 0.9320, recall: 0.8844, f1: 0.9076, edges-ner-ontonotes_loss: 0.0307
09/16 09:34:24 AM: Update 11475: task edges-ner-ontonotes, batch 475 (11475): mcc: 0.9055, acc: 0.8611, precision: 0.9340, recall: 0.8878, f1: 0.9103, edges-ner-ontonotes_loss: 0.0301
09/16 09:34:34 AM: Update 11579: task edges-ner-ontonotes, batch 579 (11579): mcc: 0.9085, acc: 0.8651, precision: 0.9360, recall: 0.8914, f1: 0.9132, edges-ner-ontonotes_loss: 0.0293
09/16 09:34:44 AM: Update 11702: task edges-ner-ontonotes, batch 702 (11702): mcc: 0.9119, acc: 0.8693, precision: 0.9384, recall: 0.8954, f1: 0.9164, edges-ner-ontonotes_loss: 0.0283
09/16 09:34:54 AM: Update 11825: task edges-ner-ontonotes, batch 825 (11825): mcc: 0.9151, acc: 0.8735, precision: 0.9407, recall: 0.8991, f1: 0.9194, edges-ner-ontonotes_loss: 0.0273
09/16 09:35:04 AM: Update 11936: task edges-ner-ontonotes, batch 936 (11936): mcc: 0.9164, acc: 0.8752, precision: 0.9417, recall: 0.9007, f1: 0.9207, edges-ner-ontonotes_loss: 0.0269
09/16 09:35:09 AM: ***** Step 12000 / Validation 12 *****
09/16 09:35:09 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:35:09 AM: Validating...
09/16 09:35:14 AM: Evaluate: task edges-ner-ontonotes, batch 48 (157): mcc: 0.8917, acc: 0.8539, precision: 0.9175, recall: 0.8781, f1: 0.8973, edges-ner-ontonotes_loss: 0.0375
09/16 09:35:24 AM: Evaluate: task edges-ner-ontonotes, batch 122 (157): mcc: 0.9215, acc: 0.8893, precision: 0.9430, recall: 0.9089, f1: 0.9257, edges-ner-ontonotes_loss: 0.0284
09/16 09:35:28 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:35:28 AM: Best result seen so far for macro.
09/16 09:35:28 AM: Updating LR scheduler:
09/16 09:35:28 AM: 	Best result seen so far for macro_avg: 0.931
09/16 09:35:28 AM: 	# validation passes without improvement: 0
09/16 09:35:28 AM: edges-ner-ontonotes_loss: training: 0.026820 validation: 0.025783
09/16 09:35:28 AM: macro_avg: validation: 0.931201
09/16 09:35:28 AM: micro_avg: validation: 0.000000
09/16 09:35:28 AM: edges-ner-ontonotes_mcc: training: 0.916623 validation: 0.927368
09/16 09:35:28 AM: edges-ner-ontonotes_acc: training: 0.875491 validation: 0.896497
09/16 09:35:28 AM: edges-ner-ontonotes_precision: training: 0.941618 validation: 0.946931
09/16 09:35:28 AM: edges-ner-ontonotes_recall: training: 0.901110 validation: 0.915984
09/16 09:35:28 AM: edges-ner-ontonotes_f1: training: 0.920919 validation: 0.931201
09/16 09:35:28 AM: Global learning rate: 0.0001
09/16 09:35:28 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:35:34 AM: Update 12074: task edges-ner-ontonotes, batch 74 (12074): mcc: 0.9284, acc: 0.8904, precision: 0.9504, recall: 0.9145, f1: 0.9321, edges-ner-ontonotes_loss: 0.0232
09/16 09:35:44 AM: Update 12178: task edges-ner-ontonotes, batch 178 (12178): mcc: 0.9186, acc: 0.8774, precision: 0.9434, recall: 0.9030, f1: 0.9228, edges-ner-ontonotes_loss: 0.0271
09/16 09:35:54 AM: Update 12301: task edges-ner-ontonotes, batch 301 (12301): mcc: 0.9052, acc: 0.8607, precision: 0.9346, recall: 0.8866, f1: 0.9100, edges-ner-ontonotes_loss: 0.0319
09/16 09:36:04 AM: Update 12436: task edges-ner-ontonotes, batch 436 (12436): mcc: 0.9002, acc: 0.8551, precision: 0.9308, recall: 0.8811, f1: 0.9053, edges-ner-ontonotes_loss: 0.0339
09/16 09:36:14 AM: Update 12556: task edges-ner-ontonotes, batch 556 (12556): mcc: 0.9001, acc: 0.8550, precision: 0.9307, recall: 0.8810, f1: 0.9052, edges-ner-ontonotes_loss: 0.0336
09/16 09:36:24 AM: Update 12706: task edges-ner-ontonotes, batch 706 (12706): mcc: 0.9000, acc: 0.8549, precision: 0.9301, recall: 0.8813, f1: 0.9051, edges-ner-ontonotes_loss: 0.0332
09/16 09:36:34 AM: Update 12816: task edges-ner-ontonotes, batch 816 (12816): mcc: 0.9000, acc: 0.8548, precision: 0.9301, recall: 0.8814, f1: 0.9051, edges-ner-ontonotes_loss: 0.0330
09/16 09:36:44 AM: Update 12940: task edges-ner-ontonotes, batch 940 (12940): mcc: 0.9012, acc: 0.8563, precision: 0.9309, recall: 0.8827, f1: 0.9062, edges-ner-ontonotes_loss: 0.0325
09/16 09:36:49 AM: ***** Step 13000 / Validation 13 *****
09/16 09:36:50 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:36:50 AM: Validating...
09/16 09:36:54 AM: Evaluate: task edges-ner-ontonotes, batch 49 (157): mcc: 0.8991, acc: 0.8633, precision: 0.9252, recall: 0.8844, f1: 0.9043, edges-ner-ontonotes_loss: 0.0323
09/16 09:37:06 AM: Evaluate: task edges-ner-ontonotes, batch 125 (157): mcc: 0.9240, acc: 0.8924, precision: 0.9482, recall: 0.9085, f1: 0.9279, edges-ner-ontonotes_loss: 0.0261
09/16 09:37:10 AM: Updating LR scheduler:
09/16 09:37:10 AM: 	Best result seen so far for macro_avg: 0.931
09/16 09:37:10 AM: 	# validation passes without improvement: 1
09/16 09:37:10 AM: edges-ner-ontonotes_loss: training: 0.032200 validation: 0.024492
09/16 09:37:10 AM: macro_avg: validation: 0.930965
09/16 09:37:10 AM: micro_avg: validation: 0.000000
09/16 09:37:10 AM: edges-ner-ontonotes_mcc: training: 0.902273 validation: 0.927214
09/16 09:37:10 AM: edges-ner-ontonotes_acc: training: 0.857634 validation: 0.895663
09/16 09:37:10 AM: edges-ner-ontonotes_precision: training: 0.931668 validation: 0.950608
09/16 09:37:10 AM: edges-ner-ontonotes_recall: training: 0.884044 validation: 0.912117
09/16 09:37:10 AM: edges-ner-ontonotes_f1: training: 0.907231 validation: 0.930965
09/16 09:37:10 AM: Global learning rate: 0.0001
09/16 09:37:10 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:37:17 AM: Update 13075: task edges-ner-ontonotes, batch 75 (13075): mcc: 0.9128, acc: 0.8701, precision: 0.9360, recall: 0.8994, f1: 0.9174, edges-ner-ontonotes_loss: 0.0289
09/16 09:37:28 AM: Update 13197: task edges-ner-ontonotes, batch 197 (13197): mcc: 0.9209, acc: 0.8801, precision: 0.9433, recall: 0.9074, f1: 0.9250, edges-ner-ontonotes_loss: 0.0254
09/16 09:37:38 AM: Update 13321: task edges-ner-ontonotes, batch 321 (13321): mcc: 0.9235, acc: 0.8836, precision: 0.9450, recall: 0.9107, f1: 0.9275, edges-ner-ontonotes_loss: 0.0242
09/16 09:37:48 AM: Update 13426: task edges-ner-ontonotes, batch 426 (13426): mcc: 0.9235, acc: 0.8840, precision: 0.9449, recall: 0.9108, f1: 0.9275, edges-ner-ontonotes_loss: 0.0241
09/16 09:37:58 AM: Update 13554: task edges-ner-ontonotes, batch 554 (13554): mcc: 0.9244, acc: 0.8855, precision: 0.9461, recall: 0.9113, f1: 0.9284, edges-ner-ontonotes_loss: 0.0239
09/16 09:38:08 AM: Update 13674: task edges-ner-ontonotes, batch 674 (13674): mcc: 0.9252, acc: 0.8864, precision: 0.9469, recall: 0.9119, f1: 0.9291, edges-ner-ontonotes_loss: 0.0238
09/16 09:38:18 AM: Update 13782: task edges-ner-ontonotes, batch 782 (13782): mcc: 0.9211, acc: 0.8810, precision: 0.9443, recall: 0.9069, f1: 0.9252, edges-ner-ontonotes_loss: 0.0254
09/16 09:38:28 AM: Update 13909: task edges-ner-ontonotes, batch 909 (13909): mcc: 0.9170, acc: 0.8760, precision: 0.9414, recall: 0.9020, f1: 0.9213, edges-ner-ontonotes_loss: 0.0272
09/16 09:38:35 AM: ***** Step 14000 / Validation 14 *****
09/16 09:38:35 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:38:35 AM: Validating...
09/16 09:38:38 AM: Evaluate: task edges-ner-ontonotes, batch 30 (157): mcc: 0.8794, acc: 0.8385, precision: 0.9052, recall: 0.8670, f1: 0.8857, edges-ner-ontonotes_loss: 0.0389
09/16 09:38:48 AM: Evaluate: task edges-ner-ontonotes, batch 112 (157): mcc: 0.9166, acc: 0.8835, precision: 0.9437, recall: 0.8992, f1: 0.9209, edges-ner-ontonotes_loss: 0.0280
09/16 09:38:54 AM: Updating LR scheduler:
09/16 09:38:54 AM: 	Best result seen so far for macro_avg: 0.931
09/16 09:38:54 AM: 	# validation passes without improvement: 2
09/16 09:38:54 AM: edges-ner-ontonotes_loss: training: 0.028265 validation: 0.025391
09/16 09:38:54 AM: macro_avg: validation: 0.928073
09/16 09:38:54 AM: micro_avg: validation: 0.000000
09/16 09:38:54 AM: edges-ner-ontonotes_mcc: training: 0.914426 validation: 0.924226
09/16 09:38:54 AM: edges-ner-ontonotes_acc: training: 0.872742 validation: 0.891720
09/16 09:38:54 AM: edges-ner-ontonotes_precision: training: 0.939830 validation: 0.950191
09/16 09:38:54 AM: edges-ner-ontonotes_recall: training: 0.898753 validation: 0.906961
09/16 09:38:54 AM: edges-ner-ontonotes_f1: training: 0.918833 validation: 0.928073
09/16 09:38:54 AM: Global learning rate: 0.0001
09/16 09:38:54 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:38:58 AM: Update 14005: task edges-ner-ontonotes, batch 5 (14005): mcc: 0.9076, acc: 0.8669, precision: 0.9437, recall: 0.8824, f1: 0.9120, edges-ner-ontonotes_loss: 0.0317
09/16 09:39:08 AM: Update 14157: task edges-ner-ontonotes, batch 157 (14157): mcc: 0.9018, acc: 0.8576, precision: 0.9294, recall: 0.8853, f1: 0.9068, edges-ner-ontonotes_loss: 0.0320
09/16 09:39:18 AM: Update 14307: task edges-ner-ontonotes, batch 307 (14307): mcc: 0.9019, acc: 0.8577, precision: 0.9306, recall: 0.8844, f1: 0.9069, edges-ner-ontonotes_loss: 0.0318
09/16 09:39:28 AM: Update 14416: task edges-ner-ontonotes, batch 416 (14416): mcc: 0.9021, acc: 0.8580, precision: 0.9303, recall: 0.8851, f1: 0.9071, edges-ner-ontonotes_loss: 0.0316
09/16 09:39:39 AM: Update 14550: task edges-ner-ontonotes, batch 550 (14550): mcc: 0.9060, acc: 0.8631, precision: 0.9335, recall: 0.8892, f1: 0.9108, edges-ner-ontonotes_loss: 0.0304
09/16 09:39:49 AM: Update 14651: task edges-ner-ontonotes, batch 651 (14651): mcc: 0.9078, acc: 0.8653, precision: 0.9347, recall: 0.8915, f1: 0.9126, edges-ner-ontonotes_loss: 0.0299
09/16 09:39:59 AM: Update 14770: task edges-ner-ontonotes, batch 770 (14770): mcc: 0.9115, acc: 0.8702, precision: 0.9373, recall: 0.8958, f1: 0.9161, edges-ner-ontonotes_loss: 0.0287
09/16 09:40:09 AM: Update 14897: task edges-ner-ontonotes, batch 897 (14897): mcc: 0.9149, acc: 0.8743, precision: 0.9399, recall: 0.8996, f1: 0.9193, edges-ner-ontonotes_loss: 0.0278
09/16 09:40:18 AM: ***** Step 15000 / Validation 15 *****
09/16 09:40:20 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:40:20 AM: Validating...
09/16 09:40:20 AM: Evaluate: task edges-ner-ontonotes, batch 1 (157): mcc: 0.7883, acc: 0.7049, precision: 0.8654, recall: 0.7377, f1: 0.7965, edges-ner-ontonotes_loss: 0.0592
09/16 09:40:30 AM: Evaluate: task edges-ner-ontonotes, batch 88 (157): mcc: 0.9156, acc: 0.8813, precision: 0.9409, recall: 0.8999, f1: 0.9199, edges-ner-ontonotes_loss: 0.0308
09/16 09:40:39 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:40:39 AM: Best result seen so far for macro.
09/16 09:40:39 AM: Updating LR scheduler:
09/16 09:40:39 AM: 	Best result seen so far for macro_avg: 0.933
09/16 09:40:39 AM: 	# validation passes without improvement: 0
09/16 09:40:39 AM: edges-ner-ontonotes_loss: training: 0.027415 validation: 0.025024
09/16 09:40:39 AM: macro_avg: validation: 0.933323
09/16 09:40:39 AM: micro_avg: validation: 0.000000
09/16 09:40:39 AM: edges-ner-ontonotes_mcc: training: 0.916186 validation: 0.929625
09/16 09:40:39 AM: edges-ner-ontonotes_acc: training: 0.875761 validation: 0.899227
09/16 09:40:39 AM: edges-ner-ontonotes_precision: training: 0.940583 validation: 0.949619
09/16 09:40:39 AM: edges-ner-ontonotes_recall: training: 0.901300 validation: 0.917577
09/16 09:40:39 AM: edges-ner-ontonotes_f1: training: 0.920523 validation: 0.933323
09/16 09:40:39 AM: Global learning rate: 0.0001
09/16 09:40:39 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:40:40 AM: Update 15013: task edges-ner-ontonotes, batch 13 (15013): mcc: 0.9349, acc: 0.8970, precision: 0.9567, recall: 0.9206, f1: 0.9383, edges-ner-ontonotes_loss: 0.0217
09/16 09:40:50 AM: Update 15135: task edges-ner-ontonotes, batch 135 (15135): mcc: 0.9240, acc: 0.8849, precision: 0.9444, recall: 0.9123, f1: 0.9280, edges-ner-ontonotes_loss: 0.0237
09/16 09:41:01 AM: Update 15257: task edges-ner-ontonotes, batch 257 (15257): mcc: 0.9251, acc: 0.8861, precision: 0.9460, recall: 0.9127, f1: 0.9290, edges-ner-ontonotes_loss: 0.0234
09/16 09:41:11 AM: Update 15379: task edges-ner-ontonotes, batch 379 (15379): mcc: 0.9133, acc: 0.8714, precision: 0.9385, recall: 0.8980, f1: 0.9178, edges-ner-ontonotes_loss: 0.0283
09/16 09:41:21 AM: Update 15519: task edges-ner-ontonotes, batch 519 (15519): mcc: 0.9075, acc: 0.8644, precision: 0.9346, recall: 0.8909, f1: 0.9122, edges-ner-ontonotes_loss: 0.0313
09/16 09:41:32 AM: Update 15647: task edges-ner-ontonotes, batch 647 (15647): mcc: 0.9051, acc: 0.8617, precision: 0.9327, recall: 0.8883, f1: 0.9100, edges-ner-ontonotes_loss: 0.0320
09/16 09:41:42 AM: Update 15797: task edges-ner-ontonotes, batch 797 (15797): mcc: 0.9052, acc: 0.8618, precision: 0.9329, recall: 0.8882, f1: 0.9100, edges-ner-ontonotes_loss: 0.0318
09/16 09:41:52 AM: Update 15914: task edges-ner-ontonotes, batch 914 (15914): mcc: 0.9047, acc: 0.8612, precision: 0.9326, recall: 0.8876, f1: 0.9096, edges-ner-ontonotes_loss: 0.0317
09/16 09:41:58 AM: ***** Step 16000 / Validation 16 *****
09/16 09:41:58 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:41:58 AM: Validating...
09/16 09:42:02 AM: Evaluate: task edges-ner-ontonotes, batch 35 (157): mcc: 0.8929, acc: 0.8576, precision: 0.9233, recall: 0.8748, f1: 0.8984, edges-ner-ontonotes_loss: 0.0352
09/16 09:42:12 AM: Evaluate: task edges-ner-ontonotes, batch 114 (157): mcc: 0.9232, acc: 0.8913, precision: 0.9486, recall: 0.9065, f1: 0.9271, edges-ner-ontonotes_loss: 0.0266
09/16 09:42:17 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:42:17 AM: Best result seen so far for macro.
09/16 09:42:17 AM: Updating LR scheduler:
09/16 09:42:17 AM: 	Best result seen so far for macro_avg: 0.934
09/16 09:42:17 AM: 	# validation passes without improvement: 0
09/16 09:42:17 AM: edges-ner-ontonotes_loss: training: 0.031195 validation: 0.024072
09/16 09:42:17 AM: macro_avg: validation: 0.933509
09/16 09:42:17 AM: micro_avg: validation: 0.000000
09/16 09:42:17 AM: edges-ner-ontonotes_mcc: training: 0.905660 validation: 0.929894
09/16 09:42:17 AM: edges-ner-ontonotes_acc: training: 0.862404 validation: 0.899151
09/16 09:42:17 AM: edges-ner-ontonotes_precision: training: 0.933196 validation: 0.952783
09/16 09:42:17 AM: edges-ner-ontonotes_recall: training: 0.888862 validation: 0.914998
09/16 09:42:17 AM: edges-ner-ontonotes_f1: training: 0.910490 validation: 0.933509
09/16 09:42:17 AM: Global learning rate: 0.0001
09/16 09:42:17 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:42:22 AM: Update 16054: task edges-ner-ontonotes, batch 54 (16054): mcc: 0.9106, acc: 0.8694, precision: 0.9351, recall: 0.8962, f1: 0.9152, edges-ner-ontonotes_loss: 0.0278
09/16 09:42:34 AM: Update 16179: task edges-ner-ontonotes, batch 179 (16179): mcc: 0.9099, acc: 0.8689, precision: 0.9349, recall: 0.8951, f1: 0.9146, edges-ner-ontonotes_loss: 0.0286
09/16 09:42:44 AM: Update 16283: task edges-ner-ontonotes, batch 283 (16283): mcc: 0.9147, acc: 0.8739, precision: 0.9387, recall: 0.9004, f1: 0.9191, edges-ner-ontonotes_loss: 0.0268
09/16 09:42:54 AM: Update 16414: task edges-ner-ontonotes, batch 414 (16414): mcc: 0.9190, acc: 0.8793, precision: 0.9419, recall: 0.9053, f1: 0.9232, edges-ner-ontonotes_loss: 0.0254
09/16 09:43:04 AM: Update 16502: task edges-ner-ontonotes, batch 502 (16502): mcc: 0.9214, acc: 0.8819, precision: 0.9437, recall: 0.9079, f1: 0.9255, edges-ner-ontonotes_loss: 0.0248
09/16 09:43:14 AM: Update 16632: task edges-ner-ontonotes, batch 632 (16632): mcc: 0.9227, acc: 0.8836, precision: 0.9449, recall: 0.9092, f1: 0.9267, edges-ner-ontonotes_loss: 0.0244
09/16 09:43:24 AM: Update 16754: task edges-ner-ontonotes, batch 754 (16754): mcc: 0.9232, acc: 0.8837, precision: 0.9455, recall: 0.9095, f1: 0.9272, edges-ner-ontonotes_loss: 0.0242
09/16 09:43:34 AM: Update 16860: task edges-ner-ontonotes, batch 860 (16860): mcc: 0.9217, acc: 0.8819, precision: 0.9445, recall: 0.9077, f1: 0.9258, edges-ner-ontonotes_loss: 0.0248
09/16 09:43:44 AM: Update 16984: task edges-ner-ontonotes, batch 984 (16984): mcc: 0.9177, acc: 0.8767, precision: 0.9418, recall: 0.9029, f1: 0.9219, edges-ner-ontonotes_loss: 0.0265
09/16 09:43:46 AM: ***** Step 17000 / Validation 17 *****
09/16 09:43:46 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:43:46 AM: Validating...
09/16 09:43:55 AM: Evaluate: task edges-ner-ontonotes, batch 82 (157): mcc: 0.9147, acc: 0.8822, precision: 0.9393, recall: 0.8998, f1: 0.9191, edges-ner-ontonotes_loss: 0.0304
09/16 09:44:04 AM: Updating LR scheduler:
09/16 09:44:04 AM: 	Best result seen so far for macro_avg: 0.934
09/16 09:44:04 AM: 	# validation passes without improvement: 1
09/16 09:44:04 AM: edges-ner-ontonotes_loss: training: 0.026787 validation: 0.025028
09/16 09:44:04 AM: macro_avg: validation: 0.931612
09/16 09:44:04 AM: micro_avg: validation: 0.000000
09/16 09:44:04 AM: edges-ner-ontonotes_mcc: training: 0.917164 validation: 0.927874
09/16 09:44:04 AM: edges-ner-ontonotes_acc: training: 0.876141 validation: 0.897179
09/16 09:44:04 AM: edges-ner-ontonotes_precision: training: 0.941436 validation: 0.950312
09/16 09:44:04 AM: edges-ner-ontonotes_recall: training: 0.902294 validation: 0.913634
09/16 09:44:04 AM: edges-ner-ontonotes_f1: training: 0.921450 validation: 0.931612
09/16 09:44:04 AM: Global learning rate: 0.0001
09/16 09:44:04 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:44:05 AM: Update 17007: task edges-ner-ontonotes, batch 7 (17007): mcc: 0.8861, acc: 0.8408, precision: 0.9237, recall: 0.8617, f1: 0.8916, edges-ner-ontonotes_loss: 0.0435
09/16 09:44:15 AM: Update 17121: task edges-ner-ontonotes, batch 121 (17121): mcc: 0.8925, acc: 0.8455, precision: 0.9254, recall: 0.8719, f1: 0.8979, edges-ner-ontonotes_loss: 0.0368
09/16 09:44:25 AM: Update 17272: task edges-ner-ontonotes, batch 272 (17272): mcc: 0.8959, acc: 0.8496, precision: 0.9272, recall: 0.8765, f1: 0.9011, edges-ner-ontonotes_loss: 0.0342
09/16 09:44:35 AM: Update 17424: task edges-ner-ontonotes, batch 424 (17424): mcc: 0.8992, acc: 0.8538, precision: 0.9294, recall: 0.8805, f1: 0.9043, edges-ner-ontonotes_loss: 0.0328
09/16 09:44:45 AM: Update 17531: task edges-ner-ontonotes, batch 531 (17531): mcc: 0.9004, acc: 0.8550, precision: 0.9299, recall: 0.8822, f1: 0.9054, edges-ner-ontonotes_loss: 0.0324
09/16 09:44:55 AM: Update 17660: task edges-ner-ontonotes, batch 660 (17660): mcc: 0.9040, acc: 0.8597, precision: 0.9321, recall: 0.8868, f1: 0.9089, edges-ner-ontonotes_loss: 0.0313
09/16 09:45:05 AM: Update 17773: task edges-ner-ontonotes, batch 773 (17773): mcc: 0.9070, acc: 0.8640, precision: 0.9342, recall: 0.8904, f1: 0.9118, edges-ner-ontonotes_loss: 0.0305
09/16 09:45:15 AM: Update 17895: task edges-ner-ontonotes, batch 895 (17895): mcc: 0.9102, acc: 0.8676, precision: 0.9362, recall: 0.8944, f1: 0.9148, edges-ner-ontonotes_loss: 0.0294
09/16 09:45:23 AM: ***** Step 18000 / Validation 18 *****
09/16 09:45:23 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:45:23 AM: Validating...
09/16 09:45:25 AM: Evaluate: task edges-ner-ontonotes, batch 18 (157): mcc: 0.8668, acc: 0.8085, precision: 0.9110, recall: 0.8381, f1: 0.8731, edges-ner-ontonotes_loss: 0.0406
09/16 09:45:35 AM: Evaluate: task edges-ner-ontonotes, batch 99 (157): mcc: 0.9158, acc: 0.8810, precision: 0.9428, recall: 0.8984, f1: 0.9201, edges-ner-ontonotes_loss: 0.0301
09/16 09:45:43 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:45:43 AM: Best result seen so far for macro.
09/16 09:45:43 AM: Updating LR scheduler:
09/16 09:45:43 AM: 	Best result seen so far for macro_avg: 0.934
09/16 09:45:43 AM: 	# validation passes without improvement: 0
09/16 09:45:43 AM: edges-ner-ontonotes_loss: training: 0.028637 validation: 0.024890
09/16 09:45:43 AM: macro_avg: validation: 0.933668
09/16 09:45:43 AM: micro_avg: validation: 0.000000
09/16 09:45:43 AM: edges-ner-ontonotes_mcc: training: 0.912685 validation: 0.930018
09/16 09:45:43 AM: edges-ner-ontonotes_acc: training: 0.870766 validation: 0.899227
09/16 09:45:43 AM: edges-ner-ontonotes_precision: training: 0.937758 validation: 0.951149
09/16 09:45:43 AM: edges-ner-ontonotes_recall: training: 0.897519 validation: 0.916818
09/16 09:45:43 AM: edges-ner-ontonotes_f1: training: 0.917197 validation: 0.933668
09/16 09:45:43 AM: Global learning rate: 0.0001
09/16 09:45:43 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:45:45 AM: Update 18010: task edges-ner-ontonotes, batch 10 (18010): mcc: 0.9188, acc: 0.8803, precision: 0.9371, recall: 0.9096, f1: 0.9232, edges-ner-ontonotes_loss: 0.0224
09/16 09:45:55 AM: Update 18110: task edges-ner-ontonotes, batch 110 (18110): mcc: 0.9257, acc: 0.8885, precision: 0.9455, recall: 0.9143, f1: 0.9297, edges-ner-ontonotes_loss: 0.0233
09/16 09:46:05 AM: Update 18233: task edges-ner-ontonotes, batch 233 (18233): mcc: 0.9261, acc: 0.8869, precision: 0.9469, recall: 0.9136, f1: 0.9300, edges-ner-ontonotes_loss: 0.0231
09/16 09:46:15 AM: Update 18356: task edges-ner-ontonotes, batch 356 (18356): mcc: 0.9261, acc: 0.8878, precision: 0.9466, recall: 0.9138, f1: 0.9299, edges-ner-ontonotes_loss: 0.0233
09/16 09:46:25 AM: Update 18463: task edges-ner-ontonotes, batch 463 (18463): mcc: 0.9176, acc: 0.8768, precision: 0.9411, recall: 0.9034, f1: 0.9219, edges-ner-ontonotes_loss: 0.0265
09/16 09:46:36 AM: Update 18591: task edges-ner-ontonotes, batch 591 (18591): mcc: 0.9125, acc: 0.8702, precision: 0.9377, recall: 0.8971, f1: 0.9170, edges-ner-ontonotes_loss: 0.0288
09/16 09:46:46 AM: Update 18701: task edges-ner-ontonotes, batch 701 (18701): mcc: 0.9096, acc: 0.8670, precision: 0.9359, recall: 0.8937, f1: 0.9143, edges-ner-ontonotes_loss: 0.0301
09/16 09:46:56 AM: Update 18850: task edges-ner-ontonotes, batch 850 (18850): mcc: 0.9091, acc: 0.8663, precision: 0.9355, recall: 0.8931, f1: 0.9138, edges-ner-ontonotes_loss: 0.0302
09/16 09:47:06 AM: Update 18986: task edges-ner-ontonotes, batch 986 (18986): mcc: 0.9085, acc: 0.8656, precision: 0.9347, recall: 0.8926, f1: 0.9132, edges-ner-ontonotes_loss: 0.0302
09/16 09:47:07 AM: ***** Step 19000 / Validation 19 *****
09/16 09:47:07 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:47:07 AM: Validating...
09/16 09:47:16 AM: Evaluate: task edges-ner-ontonotes, batch 81 (157): mcc: 0.9193, acc: 0.8856, precision: 0.9435, recall: 0.9042, f1: 0.9235, edges-ner-ontonotes_loss: 0.0283
09/16 09:47:26 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:47:26 AM: Best result seen so far for macro.
09/16 09:47:26 AM: Updating LR scheduler:
09/16 09:47:26 AM: 	Best result seen so far for macro_avg: 0.935
09/16 09:47:26 AM: 	# validation passes without improvement: 0
09/16 09:47:26 AM: edges-ner-ontonotes_loss: training: 0.030245 validation: 0.023806
09/16 09:47:26 AM: macro_avg: validation: 0.934720
09/16 09:47:26 AM: micro_avg: validation: 0.000000
09/16 09:47:26 AM: edges-ner-ontonotes_mcc: training: 0.908198 validation: 0.931171
09/16 09:47:26 AM: edges-ner-ontonotes_acc: training: 0.865169 validation: 0.900212
09/16 09:47:26 AM: edges-ner-ontonotes_precision: training: 0.934594 validation: 0.953828
09/16 09:47:26 AM: edges-ner-ontonotes_recall: training: 0.892233 validation: 0.916363
09/16 09:47:26 AM: edges-ner-ontonotes_f1: training: 0.912922 validation: 0.934720
09/16 09:47:26 AM: Global learning rate: 0.0001
09/16 09:47:26 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:47:26 AM: Update 19008: task edges-ner-ontonotes, batch 8 (19008): mcc: 0.9182, acc: 0.8780, precision: 0.9349, recall: 0.9106, f1: 0.9226, edges-ner-ontonotes_loss: 0.0278
09/16 09:47:36 AM: Update 19134: task edges-ner-ontonotes, batch 134 (19134): mcc: 0.9143, acc: 0.8749, precision: 0.9388, recall: 0.8996, f1: 0.9188, edges-ner-ontonotes_loss: 0.0276
09/16 09:47:46 AM: Update 19257: task edges-ner-ontonotes, batch 257 (19257): mcc: 0.9152, acc: 0.8751, precision: 0.9397, recall: 0.9003, f1: 0.9196, edges-ner-ontonotes_loss: 0.0272
09/16 09:47:56 AM: Update 19357: task edges-ner-ontonotes, batch 357 (19357): mcc: 0.9179, acc: 0.8782, precision: 0.9410, recall: 0.9040, f1: 0.9221, edges-ner-ontonotes_loss: 0.0266
09/16 09:48:06 AM: Update 19478: task edges-ner-ontonotes, batch 478 (19478): mcc: 0.9210, acc: 0.8818, precision: 0.9432, recall: 0.9077, f1: 0.9251, edges-ner-ontonotes_loss: 0.0254
09/16 09:48:16 AM: Update 19608: task edges-ner-ontonotes, batch 608 (19608): mcc: 0.9232, acc: 0.8846, precision: 0.9450, recall: 0.9101, f1: 0.9272, edges-ner-ontonotes_loss: 0.0247
09/16 09:48:26 AM: Update 19716: task edges-ner-ontonotes, batch 716 (19716): mcc: 0.9237, acc: 0.8850, precision: 0.9456, recall: 0.9105, f1: 0.9277, edges-ner-ontonotes_loss: 0.0245
09/16 09:48:37 AM: Update 19838: task edges-ner-ontonotes, batch 838 (19838): mcc: 0.9243, acc: 0.8859, precision: 0.9462, recall: 0.9110, f1: 0.9283, edges-ner-ontonotes_loss: 0.0242
09/16 09:48:47 AM: Update 19938: task edges-ner-ontonotes, batch 938 (19938): mcc: 0.9237, acc: 0.8849, precision: 0.9456, recall: 0.9104, f1: 0.9277, edges-ner-ontonotes_loss: 0.0243
09/16 09:48:51 AM: ***** Step 20000 / Validation 20 *****
09/16 09:48:51 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:48:51 AM: Validating...
09/16 09:48:57 AM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.9068, acc: 0.8753, precision: 0.9278, recall: 0.8961, f1: 0.9117, edges-ner-ontonotes_loss: 0.0318
09/16 09:49:07 AM: Evaluate: task edges-ner-ontonotes, batch 130 (157): mcc: 0.9257, acc: 0.8960, precision: 0.9486, recall: 0.9113, f1: 0.9296, edges-ner-ontonotes_loss: 0.0259
09/16 09:49:10 AM: Updating LR scheduler:
09/16 09:49:10 AM: 	Best result seen so far for macro_avg: 0.935
09/16 09:49:10 AM: 	# validation passes without improvement: 1
09/16 09:49:10 AM: edges-ner-ontonotes_loss: training: 0.025395 validation: 0.024435
09/16 09:49:10 AM: macro_avg: validation: 0.932586
09/16 09:49:10 AM: micro_avg: validation: 0.000000
09/16 09:49:10 AM: edges-ner-ontonotes_mcc: training: 0.921484 validation: 0.928901
09/16 09:49:10 AM: edges-ner-ontonotes_acc: training: 0.882111 validation: 0.899378
09/16 09:49:10 AM: edges-ner-ontonotes_precision: training: 0.944065 validation: 0.951191
09/16 09:49:10 AM: edges-ner-ontonotes_recall: training: 0.907793 validation: 0.914695
09/16 09:49:10 AM: edges-ner-ontonotes_f1: training: 0.925574 validation: 0.932586
09/16 09:49:10 AM: Global learning rate: 0.0001
09/16 09:49:10 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:49:17 AM: Update 20086: task edges-ner-ontonotes, batch 86 (20086): mcc: 0.8915, acc: 0.8458, precision: 0.9219, recall: 0.8734, f1: 0.8970, edges-ner-ontonotes_loss: 0.0362
09/16 09:49:27 AM: Update 20209: task edges-ner-ontonotes, batch 209 (20209): mcc: 0.8915, acc: 0.8468, precision: 0.9221, recall: 0.8733, f1: 0.8971, edges-ner-ontonotes_loss: 0.0361
09/16 09:49:37 AM: Update 20327: task edges-ner-ontonotes, batch 327 (20327): mcc: 0.8938, acc: 0.8484, precision: 0.9237, recall: 0.8761, f1: 0.8993, edges-ner-ontonotes_loss: 0.0348
09/16 09:49:47 AM: Update 20475: task edges-ner-ontonotes, batch 475 (20475): mcc: 0.8969, acc: 0.8521, precision: 0.9265, recall: 0.8789, f1: 0.9021, edges-ner-ontonotes_loss: 0.0335
09/16 09:49:57 AM: Update 20589: task edges-ner-ontonotes, batch 589 (20589): mcc: 0.8995, acc: 0.8554, precision: 0.9285, recall: 0.8818, f1: 0.9046, edges-ner-ontonotes_loss: 0.0328
09/16 09:50:07 AM: Update 20722: task edges-ner-ontonotes, batch 722 (20722): mcc: 0.9024, acc: 0.8592, precision: 0.9303, recall: 0.8856, f1: 0.9074, edges-ner-ontonotes_loss: 0.0318
09/16 09:50:17 AM: Update 20848: task edges-ner-ontonotes, batch 848 (20848): mcc: 0.9043, acc: 0.8617, precision: 0.9314, recall: 0.8880, f1: 0.9092, edges-ner-ontonotes_loss: 0.0312
09/16 09:50:27 AM: Update 20945: task edges-ner-ontonotes, batch 945 (20945): mcc: 0.9068, acc: 0.8646, precision: 0.9333, recall: 0.8909, f1: 0.9116, edges-ner-ontonotes_loss: 0.0303
09/16 09:50:32 AM: ***** Step 21000 / Validation 21 *****
09/16 09:50:32 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:50:33 AM: Validating...
09/16 09:50:37 AM: Evaluate: task edges-ner-ontonotes, batch 44 (157): mcc: 0.9012, acc: 0.8649, precision: 0.9275, recall: 0.8861, f1: 0.9063, edges-ner-ontonotes_loss: 0.0343
09/16 09:50:47 AM: Evaluate: task edges-ner-ontonotes, batch 121 (157): mcc: 0.9247, acc: 0.8932, precision: 0.9488, recall: 0.9092, f1: 0.9286, edges-ner-ontonotes_loss: 0.0269
09/16 09:50:51 AM: Updating LR scheduler:
09/16 09:50:52 AM: 	Best result seen so far for macro_avg: 0.935
09/16 09:50:52 AM: 	# validation passes without improvement: 2
09/16 09:50:52 AM: edges-ner-ontonotes_loss: training: 0.029840 validation: 0.024392
09/16 09:50:52 AM: macro_avg: validation: 0.933895
09/16 09:50:52 AM: micro_avg: validation: 0.000000
09/16 09:50:52 AM: edges-ner-ontonotes_mcc: training: 0.908306 validation: 0.930288
09/16 09:50:52 AM: edges-ner-ontonotes_acc: training: 0.866335 validation: 0.899833
09/16 09:50:52 AM: edges-ner-ontonotes_precision: training: 0.934176 validation: 0.952603
09/16 09:50:52 AM: edges-ner-ontonotes_recall: training: 0.892836 validation: 0.915908
09/16 09:50:52 AM: edges-ner-ontonotes_f1: training: 0.913039 validation: 0.933895
09/16 09:50:52 AM: Global learning rate: 0.0001
09/16 09:50:52 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:50:57 AM: Update 21071: task edges-ner-ontonotes, batch 71 (21071): mcc: 0.9277, acc: 0.8884, precision: 0.9513, recall: 0.9124, f1: 0.9314, edges-ner-ontonotes_loss: 0.0225
09/16 09:51:08 AM: Update 21173: task edges-ner-ontonotes, batch 173 (21173): mcc: 0.9269, acc: 0.8882, precision: 0.9478, recall: 0.9143, f1: 0.9307, edges-ner-ontonotes_loss: 0.0223
09/16 09:51:18 AM: Update 21294: task edges-ner-ontonotes, batch 294 (21294): mcc: 0.9275, acc: 0.8893, precision: 0.9483, recall: 0.9149, f1: 0.9313, edges-ner-ontonotes_loss: 0.0223
09/16 09:51:28 AM: Update 21419: task edges-ner-ontonotes, batch 419 (21419): mcc: 0.9277, acc: 0.8895, precision: 0.9486, recall: 0.9149, f1: 0.9315, edges-ner-ontonotes_loss: 0.0226
09/16 09:51:38 AM: Update 21526: task edges-ner-ontonotes, batch 526 (21526): mcc: 0.9239, acc: 0.8851, precision: 0.9455, recall: 0.9109, f1: 0.9279, edges-ner-ontonotes_loss: 0.0242
09/16 09:51:48 AM: Update 21659: task edges-ner-ontonotes, batch 659 (21659): mcc: 0.9181, acc: 0.8777, precision: 0.9416, recall: 0.9039, f1: 0.9224, edges-ner-ontonotes_loss: 0.0268
09/16 09:51:59 AM: Update 21785: task edges-ner-ontonotes, batch 785 (21785): mcc: 0.9142, acc: 0.8729, precision: 0.9387, recall: 0.8994, f1: 0.9186, edges-ner-ontonotes_loss: 0.0285
09/16 09:52:10 AM: Update 21932: task edges-ner-ontonotes, batch 932 (21932): mcc: 0.9127, acc: 0.8713, precision: 0.9375, recall: 0.8978, f1: 0.9172, edges-ner-ontonotes_loss: 0.0290
09/16 09:52:14 AM: ***** Step 22000 / Validation 22 *****
09/16 09:52:14 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:52:14 AM: Validating...
09/16 09:52:20 AM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.9107, acc: 0.8785, precision: 0.9387, recall: 0.8929, f1: 0.9152, edges-ner-ontonotes_loss: 0.0297
09/16 09:52:30 AM: Evaluate: task edges-ner-ontonotes, batch 130 (157): mcc: 0.9281, acc: 0.8974, precision: 0.9561, recall: 0.9085, f1: 0.9317, edges-ner-ontonotes_loss: 0.0248
09/16 09:52:33 AM: Updating LR scheduler:
09/16 09:52:33 AM: 	Best result seen so far for macro_avg: 0.935
09/16 09:52:33 AM: 	# validation passes without improvement: 3
09/16 09:52:33 AM: edges-ner-ontonotes_loss: training: 0.029051 validation: 0.023640
09/16 09:52:33 AM: macro_avg: validation: 0.933592
09/16 09:52:33 AM: micro_avg: validation: 0.000000
09/16 09:52:33 AM: edges-ner-ontonotes_mcc: training: 0.912228 validation: 0.930111
09/16 09:52:33 AM: edges-ner-ontonotes_acc: training: 0.870751 validation: 0.899302
09/16 09:52:33 AM: edges-ner-ontonotes_precision: training: 0.937056 validation: 0.957440
09/16 09:52:33 AM: edges-ner-ontonotes_recall: training: 0.897349 validation: 0.910904
09/16 09:52:33 AM: edges-ner-ontonotes_f1: training: 0.916773 validation: 0.933592
09/16 09:52:33 AM: Global learning rate: 0.0001
09/16 09:52:33 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:52:40 AM: Update 22095: task edges-ner-ontonotes, batch 95 (22095): mcc: 0.9112, acc: 0.8697, precision: 0.9385, recall: 0.8940, f1: 0.9157, edges-ner-ontonotes_loss: 0.0289
09/16 09:52:50 AM: Update 22194: task edges-ner-ontonotes, batch 194 (22194): mcc: 0.9112, acc: 0.8690, precision: 0.9367, recall: 0.8957, f1: 0.9157, edges-ner-ontonotes_loss: 0.0289
09/16 09:53:00 AM: Update 22317: task edges-ner-ontonotes, batch 317 (22317): mcc: 0.9110, acc: 0.8692, precision: 0.9350, recall: 0.8970, f1: 0.9156, edges-ner-ontonotes_loss: 0.0284
09/16 09:53:10 AM: Update 22423: task edges-ner-ontonotes, batch 423 (22423): mcc: 0.9124, acc: 0.8706, precision: 0.9363, recall: 0.8983, f1: 0.9170, edges-ner-ontonotes_loss: 0.0280
09/16 09:53:20 AM: Update 22544: task edges-ner-ontonotes, batch 544 (22544): mcc: 0.9165, acc: 0.8755, precision: 0.9393, recall: 0.9031, f1: 0.9208, edges-ner-ontonotes_loss: 0.0269
09/16 09:53:30 AM: Update 22671: task edges-ner-ontonotes, batch 671 (22671): mcc: 0.9197, acc: 0.8797, precision: 0.9416, recall: 0.9068, f1: 0.9239, edges-ner-ontonotes_loss: 0.0257
09/16 09:53:40 AM: Update 22775: task edges-ner-ontonotes, batch 775 (22775): mcc: 0.9214, acc: 0.8821, precision: 0.9431, recall: 0.9086, f1: 0.9255, edges-ner-ontonotes_loss: 0.0252
09/16 09:53:50 AM: Update 22897: task edges-ner-ontonotes, batch 897 (22897): mcc: 0.9225, acc: 0.8833, precision: 0.9438, recall: 0.9100, f1: 0.9266, edges-ner-ontonotes_loss: 0.0248
09/16 09:53:58 AM: ***** Step 23000 / Validation 23 *****
09/16 09:53:58 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:53:58 AM: Validating...
09/16 09:54:00 AM: Evaluate: task edges-ner-ontonotes, batch 17 (157): mcc: 0.8621, acc: 0.8023, precision: 0.8952, recall: 0.8445, f1: 0.8691, edges-ner-ontonotes_loss: 0.0400
09/16 09:54:10 AM: Evaluate: task edges-ner-ontonotes, batch 104 (157): mcc: 0.9185, acc: 0.8859, precision: 0.9397, recall: 0.9065, f1: 0.9228, edges-ner-ontonotes_loss: 0.0291
09/16 09:54:17 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:54:17 AM: Best result seen so far for macro.
09/16 09:54:17 AM: Updating LR scheduler:
09/16 09:54:17 AM: 	Best result seen so far for macro_avg: 0.936
09/16 09:54:17 AM: 	# validation passes without improvement: 0
09/16 09:54:17 AM: edges-ner-ontonotes_loss: training: 0.024564 validation: 0.024325
09/16 09:54:17 AM: macro_avg: validation: 0.935606
09/16 09:54:17 AM: micro_avg: validation: 0.000000
09/16 09:54:17 AM: edges-ner-ontonotes_mcc: training: 0.923245 validation: 0.931988
09/16 09:54:17 AM: edges-ner-ontonotes_acc: training: 0.884268 validation: 0.903549
09/16 09:54:17 AM: edges-ner-ontonotes_precision: training: 0.944581 validation: 0.949485
09/16 09:54:17 AM: edges-ner-ontonotes_recall: training: 0.910576 validation: 0.922126
09/16 09:54:17 AM: edges-ner-ontonotes_f1: training: 0.927267 validation: 0.935606
09/16 09:54:17 AM: Global learning rate: 0.0001
09/16 09:54:17 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:54:22 AM: Update 23037: task edges-ner-ontonotes, batch 37 (23037): mcc: 0.9268, acc: 0.8882, precision: 0.9452, recall: 0.9167, f1: 0.9307, edges-ner-ontonotes_loss: 0.0223
09/16 09:54:32 AM: Update 23167: task edges-ner-ontonotes, batch 167 (23167): mcc: 0.8979, acc: 0.8517, precision: 0.9286, recall: 0.8790, f1: 0.9031, edges-ner-ontonotes_loss: 0.0346
09/16 09:54:42 AM: Update 23292: task edges-ner-ontonotes, batch 292 (23292): mcc: 0.8970, acc: 0.8509, precision: 0.9279, recall: 0.8779, f1: 0.9022, edges-ner-ontonotes_loss: 0.0352
09/16 09:54:52 AM: Update 23398: task edges-ner-ontonotes, batch 398 (23398): mcc: 0.8969, acc: 0.8505, precision: 0.9268, recall: 0.8787, f1: 0.9021, edges-ner-ontonotes_loss: 0.0350
09/16 09:55:02 AM: Update 23546: task edges-ner-ontonotes, batch 546 (23546): mcc: 0.8992, acc: 0.8534, precision: 0.9287, recall: 0.8812, f1: 0.9043, edges-ner-ontonotes_loss: 0.0335
09/16 09:55:12 AM: Update 23668: task edges-ner-ontonotes, batch 668 (23668): mcc: 0.9007, acc: 0.8553, precision: 0.9298, recall: 0.8829, f1: 0.9057, edges-ner-ontonotes_loss: 0.0328
09/16 09:55:22 AM: Update 23798: task edges-ner-ontonotes, batch 798 (23798): mcc: 0.9038, acc: 0.8590, precision: 0.9319, recall: 0.8866, f1: 0.9087, edges-ner-ontonotes_loss: 0.0318
09/16 09:55:32 AM: Update 23922: task edges-ner-ontonotes, batch 922 (23922): mcc: 0.9053, acc: 0.8614, precision: 0.9327, recall: 0.8886, f1: 0.9101, edges-ner-ontonotes_loss: 0.0313
09/16 09:55:40 AM: ***** Step 24000 / Validation 24 *****
09/16 09:55:40 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:55:40 AM: Validating...
09/16 09:55:42 AM: Evaluate: task edges-ner-ontonotes, batch 18 (157): mcc: 0.8742, acc: 0.8174, precision: 0.9180, recall: 0.8453, f1: 0.8801, edges-ner-ontonotes_loss: 0.0378
09/16 09:55:52 AM: Evaluate: task edges-ner-ontonotes, batch 104 (157): mcc: 0.9208, acc: 0.8884, precision: 0.9454, recall: 0.9053, f1: 0.9249, edges-ner-ontonotes_loss: 0.0280
09/16 09:55:59 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:55:59 AM: Best result seen so far for macro.
09/16 09:55:59 AM: Updating LR scheduler:
09/16 09:55:59 AM: 	Best result seen so far for macro_avg: 0.936
09/16 09:55:59 AM: 	# validation passes without improvement: 0
09/16 09:55:59 AM: edges-ner-ontonotes_loss: training: 0.030806 validation: 0.024007
09/16 09:55:59 AM: macro_avg: validation: 0.935729
09/16 09:55:59 AM: micro_avg: validation: 0.000000
09/16 09:55:59 AM: edges-ner-ontonotes_mcc: training: 0.906878 validation: 0.932165
09/16 09:55:59 AM: edges-ner-ontonotes_acc: training: 0.863394 validation: 0.902639
09/16 09:55:59 AM: edges-ner-ontonotes_precision: training: 0.933654 validation: 0.951839
09/16 09:55:59 AM: edges-ner-ontonotes_recall: training: 0.890685 validation: 0.920155
09/16 09:55:59 AM: edges-ner-ontonotes_f1: training: 0.911663 validation: 0.935729
09/16 09:55:59 AM: Global learning rate: 0.0001
09/16 09:55:59 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:56:02 AM: Update 24037: task edges-ner-ontonotes, batch 37 (24037): mcc: 0.9285, acc: 0.8901, precision: 0.9499, recall: 0.9152, f1: 0.9322, edges-ner-ontonotes_loss: 0.0222
09/16 09:56:12 AM: Update 24158: task edges-ner-ontonotes, batch 158 (24158): mcc: 0.9283, acc: 0.8898, precision: 0.9491, recall: 0.9156, f1: 0.9321, edges-ner-ontonotes_loss: 0.0224
09/16 09:56:24 AM: Update 24280: task edges-ner-ontonotes, batch 280 (24280): mcc: 0.9298, acc: 0.8923, precision: 0.9493, recall: 0.9182, f1: 0.9335, edges-ner-ontonotes_loss: 0.0219
09/16 09:56:34 AM: Update 24399: task edges-ner-ontonotes, batch 399 (24399): mcc: 0.9298, acc: 0.8927, precision: 0.9490, recall: 0.9185, f1: 0.9335, edges-ner-ontonotes_loss: 0.0218
09/16 09:56:46 AM: Update 24519: task edges-ner-ontonotes, batch 519 (24519): mcc: 0.9296, acc: 0.8923, precision: 0.9493, recall: 0.9179, f1: 0.9333, edges-ner-ontonotes_loss: 0.0221
09/16 09:56:56 AM: Update 24635: task edges-ner-ontonotes, batch 635 (24635): mcc: 0.9268, acc: 0.8885, precision: 0.9475, recall: 0.9144, f1: 0.9306, edges-ner-ontonotes_loss: 0.0234
09/16 09:57:06 AM: Update 24767: task edges-ner-ontonotes, batch 767 (24767): mcc: 0.9211, acc: 0.8811, precision: 0.9437, recall: 0.9074, f1: 0.9252, edges-ner-ontonotes_loss: 0.0259
09/16 09:57:16 AM: Update 24896: task edges-ner-ontonotes, batch 896 (24896): mcc: 0.9172, acc: 0.8765, precision: 0.9409, recall: 0.9028, f1: 0.9215, edges-ner-ontonotes_loss: 0.0274
09/16 09:57:25 AM: ***** Step 25000 / Validation 25 *****
09/16 09:57:25 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:57:25 AM: Validating...
09/16 09:57:26 AM: Evaluate: task edges-ner-ontonotes, batch 14 (157): mcc: 0.8619, acc: 0.8048, precision: 0.9032, recall: 0.8365, f1: 0.8686, edges-ner-ontonotes_loss: 0.0381
09/16 09:57:39 AM: Evaluate: task edges-ner-ontonotes, batch 98 (157): mcc: 0.9220, acc: 0.8904, precision: 0.9499, recall: 0.9030, f1: 0.9259, edges-ner-ontonotes_loss: 0.0267
09/16 09:57:46 AM: Updating LR scheduler:
09/16 09:57:46 AM: 	Best result seen so far for macro_avg: 0.936
09/16 09:57:46 AM: 	# validation passes without improvement: 1
09/16 09:57:46 AM: edges-ner-ontonotes_loss: training: 0.027919 validation: 0.023541
09/16 09:57:46 AM: macro_avg: validation: 0.933877
09/16 09:57:46 AM: micro_avg: validation: 0.000000
09/16 09:57:46 AM: edges-ner-ontonotes_mcc: training: 0.915880 validation: 0.930389
09/16 09:57:46 AM: edges-ner-ontonotes_acc: training: 0.874917 validation: 0.899606
09/16 09:57:46 AM: edges-ner-ontonotes_precision: training: 0.939900 validation: 0.956951
09/16 09:57:46 AM: edges-ner-ontonotes_recall: training: 0.901394 validation: 0.911890
09/16 09:57:46 AM: edges-ner-ontonotes_f1: training: 0.920244 validation: 0.933877
09/16 09:57:46 AM: Global learning rate: 0.0001
09/16 09:57:46 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:57:49 AM: Update 25030: task edges-ner-ontonotes, batch 30 (25030): mcc: 0.9052, acc: 0.8601, precision: 0.9375, recall: 0.8839, f1: 0.9099, edges-ner-ontonotes_loss: 0.0301
09/16 09:57:59 AM: Update 25183: task edges-ner-ontonotes, batch 183 (25183): mcc: 0.9055, acc: 0.8613, precision: 0.9348, recall: 0.8871, f1: 0.9103, edges-ner-ontonotes_loss: 0.0298
09/16 09:58:09 AM: Update 25280: task edges-ner-ontonotes, batch 280 (25280): mcc: 0.9048, acc: 0.8600, precision: 0.9328, recall: 0.8877, f1: 0.9097, edges-ner-ontonotes_loss: 0.0298
09/16 09:58:19 AM: Update 25414: task edges-ner-ontonotes, batch 414 (25414): mcc: 0.9087, acc: 0.8656, precision: 0.9348, recall: 0.8929, f1: 0.9134, edges-ner-ontonotes_loss: 0.0286
09/16 09:58:29 AM: Update 25523: task edges-ner-ontonotes, batch 523 (25523): mcc: 0.9101, acc: 0.8679, precision: 0.9350, recall: 0.8954, f1: 0.9148, edges-ner-ontonotes_loss: 0.0284
09/16 09:58:39 AM: Update 25643: task edges-ner-ontonotes, batch 643 (25643): mcc: 0.9134, acc: 0.8718, precision: 0.9371, recall: 0.8994, f1: 0.9179, edges-ner-ontonotes_loss: 0.0274
09/16 09:58:49 AM: Update 25771: task edges-ner-ontonotes, batch 771 (25771): mcc: 0.9168, acc: 0.8761, precision: 0.9395, recall: 0.9036, f1: 0.9212, edges-ner-ontonotes_loss: 0.0264
09/16 09:58:59 AM: Update 25873: task edges-ner-ontonotes, batch 873 (25873): mcc: 0.9193, acc: 0.8793, precision: 0.9413, recall: 0.9064, f1: 0.9235, edges-ner-ontonotes_loss: 0.0257
09/16 09:59:09 AM: Update 25998: task edges-ner-ontonotes, batch 998 (25998): mcc: 0.9204, acc: 0.8805, precision: 0.9420, recall: 0.9077, f1: 0.9245, edges-ner-ontonotes_loss: 0.0254
09/16 09:59:10 AM: ***** Step 26000 / Validation 26 *****
09/16 09:59:10 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:59:10 AM: Validating...
09/16 09:59:19 AM: Evaluate: task edges-ner-ontonotes, batch 89 (157): mcc: 0.9178, acc: 0.8855, precision: 0.9371, recall: 0.9076, f1: 0.9221, edges-ner-ontonotes_loss: 0.0302
09/16 09:59:28 AM: Updating LR scheduler:
09/16 09:59:28 AM: 	Best result seen so far for macro_avg: 0.936
09/16 09:59:28 AM: 	# validation passes without improvement: 2
09/16 09:59:28 AM: edges-ner-ontonotes_loss: training: 0.025390 validation: 0.024342
09/16 09:59:28 AM: macro_avg: validation: 0.935693
09/16 09:59:28 AM: micro_avg: validation: 0.000000
09/16 09:59:28 AM: edges-ner-ontonotes_mcc: training: 0.920518 validation: 0.932044
09/16 09:59:28 AM: edges-ner-ontonotes_acc: training: 0.880743 validation: 0.904155
09/16 09:59:28 AM: edges-ner-ontonotes_precision: training: 0.942100 validation: 0.947663
09/16 09:59:28 AM: edges-ner-ontonotes_recall: training: 0.907904 validation: 0.924022
09/16 09:59:28 AM: edges-ner-ontonotes_f1: training: 0.924686 validation: 0.935693
09/16 09:59:28 AM: Global learning rate: 0.0001
09/16 09:59:28 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 09:59:30 AM: Update 26012: task edges-ner-ontonotes, batch 12 (26012): mcc: 0.9348, acc: 0.8980, precision: 0.9509, recall: 0.9261, f1: 0.9383, edges-ner-ontonotes_loss: 0.0215
09/16 09:59:40 AM: Update 26133: task edges-ner-ontonotes, batch 133 (26133): mcc: 0.9302, acc: 0.8929, precision: 0.9488, recall: 0.9194, f1: 0.9339, edges-ner-ontonotes_loss: 0.0223
09/16 09:59:50 AM: Update 26228: task edges-ner-ontonotes, batch 228 (26228): mcc: 0.9152, acc: 0.8732, precision: 0.9392, recall: 0.9008, f1: 0.9196, edges-ner-ontonotes_loss: 0.0284
09/16 10:00:00 AM: Update 26357: task edges-ner-ontonotes, batch 357 (26357): mcc: 0.9090, acc: 0.8663, precision: 0.9351, recall: 0.8932, f1: 0.9137, edges-ner-ontonotes_loss: 0.0309
09/16 10:00:10 AM: Update 26470: task edges-ner-ontonotes, batch 470 (26470): mcc: 0.9060, acc: 0.8627, precision: 0.9328, recall: 0.8898, f1: 0.9108, edges-ner-ontonotes_loss: 0.0320
09/16 10:00:20 AM: Update 26621: task edges-ner-ontonotes, batch 621 (26621): mcc: 0.9047, acc: 0.8610, precision: 0.9320, recall: 0.8882, f1: 0.9096, edges-ner-ontonotes_loss: 0.0318
09/16 10:00:31 AM: Update 26766: task edges-ner-ontonotes, batch 766 (26766): mcc: 0.9058, acc: 0.8626, precision: 0.9324, recall: 0.8898, f1: 0.9106, edges-ner-ontonotes_loss: 0.0312
09/16 10:00:41 AM: Update 26898: task edges-ner-ontonotes, batch 898 (26898): mcc: 0.9071, acc: 0.8645, precision: 0.9334, recall: 0.8913, f1: 0.9119, edges-ner-ontonotes_loss: 0.0307
09/16 10:00:49 AM: ***** Step 27000 / Validation 27 *****
09/16 10:00:49 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:00:49 AM: Validating...
09/16 10:00:51 AM: Evaluate: task edges-ner-ontonotes, batch 24 (157): mcc: 0.8690, acc: 0.8293, precision: 0.8970, recall: 0.8557, f1: 0.8759, edges-ner-ontonotes_loss: 0.0406
09/16 10:01:01 AM: Evaluate: task edges-ner-ontonotes, batch 110 (157): mcc: 0.9253, acc: 0.8951, precision: 0.9472, recall: 0.9119, f1: 0.9292, edges-ner-ontonotes_loss: 0.0260
09/16 10:01:08 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:01:08 AM: Best result seen so far for macro.
09/16 10:01:08 AM: Updating LR scheduler:
09/16 10:01:08 AM: 	Best result seen so far for macro_avg: 0.937
09/16 10:01:08 AM: 	# validation passes without improvement: 0
09/16 10:01:08 AM: edges-ner-ontonotes_loss: training: 0.030167 validation: 0.023210
09/16 10:01:08 AM: macro_avg: validation: 0.937305
09/16 10:01:08 AM: micro_avg: validation: 0.000000
09/16 10:01:08 AM: edges-ner-ontonotes_mcc: training: 0.908348 validation: 0.933821
09/16 10:01:08 AM: edges-ner-ontonotes_acc: training: 0.865757 validation: 0.905369
09/16 10:01:08 AM: edges-ner-ontonotes_precision: training: 0.934472 validation: 0.952911
09/16 10:01:08 AM: edges-ner-ontonotes_recall: training: 0.892629 validation: 0.922202
09/16 10:01:08 AM: edges-ner-ontonotes_f1: training: 0.913071 validation: 0.937305
09/16 10:01:08 AM: Global learning rate: 0.0001
09/16 10:01:08 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 10:01:11 AM: Update 27041: task edges-ner-ontonotes, batch 41 (27041): mcc: 0.9050, acc: 0.8656, precision: 0.9301, recall: 0.8906, f1: 0.9099, edges-ner-ontonotes_loss: 0.0310
09/16 10:01:21 AM: Update 27140: task edges-ner-ontonotes, batch 140 (27140): mcc: 0.9183, acc: 0.8805, precision: 0.9403, recall: 0.9057, f1: 0.9226, edges-ner-ontonotes_loss: 0.0263
09/16 10:01:32 AM: Update 27258: task edges-ner-ontonotes, batch 258 (27258): mcc: 0.9245, acc: 0.8877, precision: 0.9459, recall: 0.9116, f1: 0.9284, edges-ner-ontonotes_loss: 0.0240
09/16 10:01:42 AM: Update 27380: task edges-ner-ontonotes, batch 380 (27380): mcc: 0.9275, acc: 0.8909, precision: 0.9482, recall: 0.9149, f1: 0.9313, edges-ner-ontonotes_loss: 0.0231
09/16 10:01:52 AM: Update 27483: task edges-ner-ontonotes, batch 483 (27483): mcc: 0.9281, acc: 0.8913, precision: 0.9489, recall: 0.9155, f1: 0.9319, edges-ner-ontonotes_loss: 0.0228
09/16 10:02:02 AM: Update 27606: task edges-ner-ontonotes, batch 606 (27606): mcc: 0.9275, acc: 0.8903, precision: 0.9478, recall: 0.9153, f1: 0.9313, edges-ner-ontonotes_loss: 0.0228
09/16 10:02:12 AM: Update 27709: task edges-ner-ontonotes, batch 709 (27709): mcc: 0.9270, acc: 0.8894, precision: 0.9475, recall: 0.9148, f1: 0.9308, edges-ner-ontonotes_loss: 0.0228
09/16 10:02:22 AM: Update 27836: task edges-ner-ontonotes, batch 836 (27836): mcc: 0.9223, acc: 0.8836, precision: 0.9441, recall: 0.9092, f1: 0.9263, edges-ner-ontonotes_loss: 0.0251
09/16 10:02:32 AM: Update 27969: task edges-ner-ontonotes, batch 969 (27969): mcc: 0.9185, acc: 0.8789, precision: 0.9414, recall: 0.9049, f1: 0.9228, edges-ner-ontonotes_loss: 0.0268
09/16 10:02:34 AM: ***** Step 28000 / Validation 28 *****
09/16 10:02:34 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:02:34 AM: Validating...
09/16 10:02:42 AM: Evaluate: task edges-ner-ontonotes, batch 70 (157): mcc: 0.9117, acc: 0.8762, precision: 0.9377, recall: 0.8958, f1: 0.9163, edges-ner-ontonotes_loss: 0.0300
09/16 10:02:52 AM: Evaluate: task edges-ner-ontonotes, batch 146 (157): mcc: 0.9300, acc: 0.8991, precision: 0.9540, recall: 0.9140, f1: 0.9336, edges-ner-ontonotes_loss: 0.0241
09/16 10:02:53 AM: Updating LR scheduler:
09/16 10:02:53 AM: 	Best result seen so far for macro_avg: 0.937
09/16 10:02:53 AM: 	# validation passes without improvement: 1
09/16 10:02:53 AM: edges-ner-ontonotes_loss: training: 0.027168 validation: 0.023690
09/16 10:02:53 AM: macro_avg: validation: 0.934200
09/16 10:02:53 AM: micro_avg: validation: 0.000000
09/16 10:02:53 AM: edges-ner-ontonotes_mcc: training: 0.917889 validation: 0.930643
09/16 10:02:53 AM: edges-ner-ontonotes_acc: training: 0.878039 validation: 0.899833
09/16 10:02:53 AM: edges-ner-ontonotes_precision: training: 0.940963 validation: 0.954143
09/16 10:02:53 AM: edges-ner-ontonotes_recall: training: 0.904104 validation: 0.915074
09/16 10:02:53 AM: edges-ner-ontonotes_f1: training: 0.922165 validation: 0.934200
09/16 10:02:53 AM: Global learning rate: 0.0001
09/16 10:02:53 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 10:03:02 AM: Update 28092: task edges-ner-ontonotes, batch 92 (28092): mcc: 0.8986, acc: 0.8559, precision: 0.9268, recall: 0.8818, f1: 0.9038, edges-ner-ontonotes_loss: 0.0319
09/16 10:03:12 AM: Update 28246: task edges-ner-ontonotes, batch 246 (28246): mcc: 0.9027, acc: 0.8600, precision: 0.9311, recall: 0.8854, f1: 0.9077, edges-ner-ontonotes_loss: 0.0308
09/16 10:03:22 AM: Update 28363: task edges-ner-ontonotes, batch 363 (28363): mcc: 0.9048, acc: 0.8618, precision: 0.9320, recall: 0.8884, f1: 0.9097, edges-ner-ontonotes_loss: 0.0303
09/16 10:03:32 AM: Update 28487: task edges-ner-ontonotes, batch 487 (28487): mcc: 0.9079, acc: 0.8657, precision: 0.9336, recall: 0.8926, f1: 0.9127, edges-ner-ontonotes_loss: 0.0295
09/16 10:03:42 AM: Update 28616: task edges-ner-ontonotes, batch 616 (28616): mcc: 0.9098, acc: 0.8681, precision: 0.9352, recall: 0.8947, f1: 0.9145, edges-ner-ontonotes_loss: 0.0289
09/16 10:03:52 AM: Update 28721: task edges-ner-ontonotes, batch 721 (28721): mcc: 0.9130, acc: 0.8717, precision: 0.9372, recall: 0.8986, f1: 0.9175, edges-ner-ontonotes_loss: 0.0279
09/16 10:04:02 AM: Update 28854: task edges-ner-ontonotes, batch 854 (28854): mcc: 0.9162, acc: 0.8759, precision: 0.9394, recall: 0.9026, f1: 0.9206, edges-ner-ontonotes_loss: 0.0268
09/16 10:04:12 AM: Update 28950: task edges-ner-ontonotes, batch 950 (28950): mcc: 0.9182, acc: 0.8784, precision: 0.9407, recall: 0.9049, f1: 0.9224, edges-ner-ontonotes_loss: 0.0263
09/16 10:04:16 AM: ***** Step 29000 / Validation 29 *****
09/16 10:04:17 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:04:17 AM: Validating...
09/16 10:04:23 AM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.9088, acc: 0.8745, precision: 0.9305, recall: 0.8972, f1: 0.9136, edges-ner-ontonotes_loss: 0.0334
09/16 10:04:33 AM: Evaluate: task edges-ner-ontonotes, batch 131 (157): mcc: 0.9288, acc: 0.8988, precision: 0.9473, recall: 0.9184, f1: 0.9326, edges-ner-ontonotes_loss: 0.0260
09/16 10:04:36 AM: Updating LR scheduler:
09/16 10:04:36 AM: 	Best result seen so far for macro_avg: 0.937
09/16 10:04:36 AM: 	# validation passes without improvement: 2
09/16 10:04:36 AM: edges-ner-ontonotes_loss: training: 0.026097 validation: 0.024252
09/16 10:04:36 AM: macro_avg: validation: 0.936193
09/16 10:04:36 AM: micro_avg: validation: 0.000000
09/16 10:04:36 AM: edges-ner-ontonotes_mcc: training: 0.918748 validation: 0.932595
09/16 10:04:36 AM: edges-ner-ontonotes_acc: training: 0.878965 validation: 0.903397
09/16 10:04:36 AM: edges-ner-ontonotes_precision: training: 0.941192 validation: 0.949330
09/16 10:04:36 AM: edges-ner-ontonotes_recall: training: 0.905485 validation: 0.923415
09/16 10:04:36 AM: edges-ner-ontonotes_f1: training: 0.922993 validation: 0.936193
09/16 10:04:36 AM: Global learning rate: 0.0001
09/16 10:04:36 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 10:04:43 AM: Update 29086: task edges-ner-ontonotes, batch 86 (29086): mcc: 0.9285, acc: 0.8896, precision: 0.9464, recall: 0.9186, f1: 0.9323, edges-ner-ontonotes_loss: 0.0231
09/16 10:04:53 AM: Update 29208: task edges-ner-ontonotes, batch 208 (29208): mcc: 0.9275, acc: 0.8893, precision: 0.9461, recall: 0.9172, f1: 0.9314, edges-ner-ontonotes_loss: 0.0229
09/16 10:05:03 AM: Update 29315: task edges-ner-ontonotes, batch 315 (29315): mcc: 0.9218, acc: 0.8827, precision: 0.9425, recall: 0.9099, f1: 0.9259, edges-ner-ontonotes_loss: 0.0251
09/16 10:05:13 AM: Update 29449: task edges-ner-ontonotes, batch 449 (29449): mcc: 0.9130, acc: 0.8717, precision: 0.9370, recall: 0.8989, f1: 0.9176, edges-ner-ontonotes_loss: 0.0291
09/16 10:05:24 AM: Update 29565: task edges-ner-ontonotes, batch 565 (29565): mcc: 0.9097, acc: 0.8677, precision: 0.9346, recall: 0.8950, f1: 0.9144, edges-ner-ontonotes_loss: 0.0305
09/16 10:05:34 AM: Update 29710: task edges-ner-ontonotes, batch 710 (29710): mcc: 0.9086, acc: 0.8661, precision: 0.9340, recall: 0.8935, f1: 0.9133, edges-ner-ontonotes_loss: 0.0308
09/16 10:05:44 AM: Update 29866: task edges-ner-ontonotes, batch 866 (29866): mcc: 0.9087, acc: 0.8667, precision: 0.9340, recall: 0.8936, f1: 0.9134, edges-ner-ontonotes_loss: 0.0305
09/16 10:05:54 AM: Update 29968: task edges-ner-ontonotes, batch 968 (29968): mcc: 0.9092, acc: 0.8674, precision: 0.9346, recall: 0.8941, f1: 0.9139, edges-ner-ontonotes_loss: 0.0303
09/16 10:05:56 AM: ***** Step 30000 / Validation 30 *****
09/16 10:05:56 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:05:56 AM: Validating...
09/16 10:06:04 AM: Evaluate: task edges-ner-ontonotes, batch 71 (157): mcc: 0.9153, acc: 0.8812, precision: 0.9423, recall: 0.8981, f1: 0.9197, edges-ner-ontonotes_loss: 0.0291
09/16 10:06:14 AM: Evaluate: task edges-ner-ontonotes, batch 148 (157): mcc: 0.9331, acc: 0.9037, precision: 0.9557, recall: 0.9181, f1: 0.9366, edges-ner-ontonotes_loss: 0.0233
09/16 10:06:15 AM: Updating LR scheduler:
09/16 10:06:15 AM: 	Best result seen so far for macro_avg: 0.937
09/16 10:06:15 AM: 	# validation passes without improvement: 3
09/16 10:06:15 AM: edges-ner-ontonotes_loss: training: 0.030169 validation: 0.023054
09/16 10:06:15 AM: macro_avg: validation: 0.937133
09/16 10:06:15 AM: micro_avg: validation: 0.000000
09/16 10:06:15 AM: edges-ner-ontonotes_mcc: training: 0.909402 validation: 0.933717
09/16 10:06:15 AM: edges-ner-ontonotes_acc: training: 0.867686 validation: 0.904610
09/16 10:06:15 AM: edges-ner-ontonotes_precision: training: 0.934780 validation: 0.956059
09/16 10:06:15 AM: edges-ner-ontonotes_recall: training: 0.894293 validation: 0.918941
09/16 10:06:15 AM: edges-ner-ontonotes_f1: training: 0.914088 validation: 0.937133
09/16 10:06:15 AM: Global learning rate: 0.0001
09/16 10:06:15 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 10:06:24 AM: Update 30117: task edges-ner-ontonotes, batch 117 (30117): mcc: 0.9178, acc: 0.8777, precision: 0.9390, recall: 0.9058, f1: 0.9221, edges-ner-ontonotes_loss: 0.0274
09/16 10:06:34 AM: Update 30213: task edges-ner-ontonotes, batch 213 (30213): mcc: 0.9176, acc: 0.8780, precision: 0.9392, recall: 0.9053, f1: 0.9219, edges-ner-ontonotes_loss: 0.0268
09/16 10:06:44 AM: Update 30337: task edges-ner-ontonotes, batch 337 (30337): mcc: 0.9224, acc: 0.8837, precision: 0.9425, recall: 0.9110, f1: 0.9265, edges-ner-ontonotes_loss: 0.0250
09/16 10:06:54 AM: Update 30459: task edges-ner-ontonotes, batch 459 (30459): mcc: 0.9257, acc: 0.8877, precision: 0.9450, recall: 0.9148, f1: 0.9296, edges-ner-ontonotes_loss: 0.0239
09/16 10:07:04 AM: Update 30565: task edges-ner-ontonotes, batch 565 (30565): mcc: 0.9260, acc: 0.8880, precision: 0.9452, recall: 0.9150, f1: 0.9299, edges-ner-ontonotes_loss: 0.0238
09/16 10:07:14 AM: Update 30684: task edges-ner-ontonotes, batch 684 (30684): mcc: 0.9269, acc: 0.8893, precision: 0.9463, recall: 0.9156, f1: 0.9307, edges-ner-ontonotes_loss: 0.0234
09/16 10:07:24 AM: Update 30813: task edges-ner-ontonotes, batch 813 (30813): mcc: 0.9270, acc: 0.8891, precision: 0.9467, recall: 0.9156, f1: 0.9309, edges-ner-ontonotes_loss: 0.0233
09/16 10:07:34 AM: Update 30918: task edges-ner-ontonotes, batch 918 (30918): mcc: 0.9229, acc: 0.8839, precision: 0.9441, recall: 0.9103, f1: 0.9269, edges-ner-ontonotes_loss: 0.0251
09/16 10:07:40 AM: ***** Step 31000 / Validation 31 *****
09/16 10:07:40 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:07:40 AM: Validating...
09/16 10:07:44 AM: Evaluate: task edges-ner-ontonotes, batch 39 (157): mcc: 0.9019, acc: 0.8658, precision: 0.9235, recall: 0.8912, f1: 0.9071, edges-ner-ontonotes_loss: 0.0338
09/16 10:07:54 AM: Evaluate: task edges-ner-ontonotes, batch 114 (157): mcc: 0.9258, acc: 0.8953, precision: 0.9481, recall: 0.9119, f1: 0.9296, edges-ner-ontonotes_loss: 0.0260
09/16 10:08:00 AM: Updating LR scheduler:
09/16 10:08:00 AM: 	Best result seen so far for macro_avg: 0.937
09/16 10:08:00 AM: 	# validation passes without improvement: 0
09/16 10:08:00 AM: edges-ner-ontonotes_loss: training: 0.025906 validation: 0.023359
09/16 10:08:00 AM: macro_avg: validation: 0.935990
09/16 10:08:00 AM: micro_avg: validation: 0.000000
09/16 10:08:00 AM: edges-ner-ontonotes_mcc: training: 0.920919 validation: 0.932472
09/16 10:08:00 AM: edges-ner-ontonotes_acc: training: 0.881290 validation: 0.902942
09/16 10:08:00 AM: edges-ner-ontonotes_precision: training: 0.942953 validation: 0.953437
09/16 10:08:00 AM: edges-ner-ontonotes_recall: training: 0.907821 validation: 0.919169
09/16 10:08:00 AM: edges-ner-ontonotes_f1: training: 0.925054 validation: 0.935990
09/16 10:08:00 AM: Global learning rate: 5e-05
09/16 10:08:00 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 10:08:04 AM: Update 31063: task edges-ner-ontonotes, batch 63 (31063): mcc: 0.8901, acc: 0.8440, precision: 0.9196, recall: 0.8731, f1: 0.8957, edges-ner-ontonotes_loss: 0.0363
09/16 10:08:14 AM: Update 31174: task edges-ner-ontonotes, batch 174 (31174): mcc: 0.8937, acc: 0.8493, precision: 0.9238, recall: 0.8757, f1: 0.8991, edges-ner-ontonotes_loss: 0.0353
09/16 10:08:24 AM: Update 31322: task edges-ner-ontonotes, batch 322 (31322): mcc: 0.8987, acc: 0.8538, precision: 0.9265, recall: 0.8823, f1: 0.9039, edges-ner-ontonotes_loss: 0.0330
09/16 10:08:35 AM: Update 31438: task edges-ner-ontonotes, batch 438 (31438): mcc: 0.9012, acc: 0.8565, precision: 0.9286, recall: 0.8851, f1: 0.9063, edges-ner-ontonotes_loss: 0.0319
09/16 10:08:45 AM: Update 31568: task edges-ner-ontonotes, batch 568 (31568): mcc: 0.9054, acc: 0.8619, precision: 0.9319, recall: 0.8896, f1: 0.9103, edges-ner-ontonotes_loss: 0.0306
09/16 10:08:55 AM: Update 31697: task edges-ner-ontonotes, batch 697 (31697): mcc: 0.9079, acc: 0.8657, precision: 0.9336, recall: 0.8927, f1: 0.9127, edges-ner-ontonotes_loss: 0.0299
09/16 10:09:05 AM: Update 31789: task edges-ner-ontonotes, batch 789 (31789): mcc: 0.9101, acc: 0.8681, precision: 0.9352, recall: 0.8953, f1: 0.9148, edges-ner-ontonotes_loss: 0.0293
09/16 10:09:15 AM: Update 31918: task edges-ner-ontonotes, batch 918 (31918): mcc: 0.9133, acc: 0.8723, precision: 0.9373, recall: 0.8991, f1: 0.9178, edges-ner-ontonotes_loss: 0.0282
09/16 10:09:21 AM: ***** Step 32000 / Validation 32 *****
09/16 10:09:21 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:09:21 AM: Validating...
09/16 10:09:25 AM: Evaluate: task edges-ner-ontonotes, batch 37 (157): mcc: 0.8949, acc: 0.8554, precision: 0.9250, recall: 0.8767, f1: 0.9002, edges-ner-ontonotes_loss: 0.0365
09/16 10:09:35 AM: Evaluate: task edges-ner-ontonotes, batch 115 (157): mcc: 0.9241, acc: 0.8924, precision: 0.9478, recall: 0.9090, f1: 0.9280, edges-ner-ontonotes_loss: 0.0270
09/16 10:09:40 AM: Updating LR scheduler:
09/16 10:09:40 AM: 	Best result seen so far for macro_avg: 0.937
09/16 10:09:40 AM: 	# validation passes without improvement: 1
09/16 10:09:40 AM: edges-ner-ontonotes_loss: training: 0.027571 validation: 0.023887
09/16 10:09:40 AM: macro_avg: validation: 0.935700
09/16 10:09:40 AM: micro_avg: validation: 0.000000
09/16 10:09:40 AM: edges-ner-ontonotes_mcc: training: 0.915243 validation: 0.932159
09/16 10:09:40 AM: edges-ner-ontonotes_acc: training: 0.874778 validation: 0.902487
09/16 10:09:40 AM: edges-ner-ontonotes_precision: training: 0.938647 validation: 0.952838
09/16 10:09:40 AM: edges-ner-ontonotes_recall: training: 0.901424 validation: 0.919169
09/16 10:09:40 AM: edges-ner-ontonotes_f1: training: 0.919659 validation: 0.935700
09/16 10:09:40 AM: Global learning rate: 5e-05
09/16 10:09:40 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 10:09:47 AM: Update 32060: task edges-ner-ontonotes, batch 60 (32060): mcc: 0.9322, acc: 0.8967, precision: 0.9511, recall: 0.9209, f1: 0.9358, edges-ner-ontonotes_loss: 0.0208
09/16 10:09:57 AM: Update 32181: task edges-ner-ontonotes, batch 181 (32181): mcc: 0.9298, acc: 0.8921, precision: 0.9499, recall: 0.9175, f1: 0.9335, edges-ner-ontonotes_loss: 0.0221
09/16 10:10:07 AM: Update 32307: task edges-ner-ontonotes, batch 307 (32307): mcc: 0.9300, acc: 0.8923, precision: 0.9497, recall: 0.9181, f1: 0.9337, edges-ner-ontonotes_loss: 0.0221
09/16 10:10:17 AM: Update 32416: task edges-ner-ontonotes, batch 416 (32416): mcc: 0.9262, acc: 0.8880, precision: 0.9474, recall: 0.9134, f1: 0.9301, edges-ner-ontonotes_loss: 0.0236
09/16 10:10:27 AM: Update 32547: task edges-ner-ontonotes, batch 547 (32547): mcc: 0.9198, acc: 0.8801, precision: 0.9428, recall: 0.9058, f1: 0.9239, edges-ner-ontonotes_loss: 0.0269
09/16 10:10:37 AM: Update 32676: task edges-ner-ontonotes, batch 676 (32676): mcc: 0.9160, acc: 0.8755, precision: 0.9402, recall: 0.9014, f1: 0.9204, edges-ner-ontonotes_loss: 0.0286
09/16 10:10:47 AM: Update 32806: task edges-ner-ontonotes, batch 806 (32806): mcc: 0.9146, acc: 0.8735, precision: 0.9389, recall: 0.8999, f1: 0.9190, edges-ner-ontonotes_loss: 0.0287
09/16 10:10:57 AM: Update 32965: task edges-ner-ontonotes, batch 965 (32965): mcc: 0.9135, acc: 0.8725, precision: 0.9382, recall: 0.8987, f1: 0.9180, edges-ner-ontonotes_loss: 0.0290
09/16 10:11:01 AM: ***** Step 33000 / Validation 33 *****
09/16 10:11:01 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:11:01 AM: Validating...
09/16 10:11:07 AM: Evaluate: task edges-ner-ontonotes, batch 57 (157): mcc: 0.9193, acc: 0.8876, precision: 0.9418, recall: 0.9060, f1: 0.9236, edges-ner-ontonotes_loss: 0.0282
09/16 10:11:18 AM: Evaluate: task edges-ner-ontonotes, batch 134 (157): mcc: 0.9323, acc: 0.9025, precision: 0.9573, recall: 0.9151, f1: 0.9357, edges-ner-ontonotes_loss: 0.0239
09/16 10:11:20 AM: Updating LR scheduler:
09/16 10:11:20 AM: 	Best result seen so far for macro_avg: 0.937
09/16 10:11:20 AM: 	# validation passes without improvement: 2
09/16 10:11:20 AM: edges-ner-ontonotes_loss: training: 0.029011 validation: 0.023063
09/16 10:11:20 AM: macro_avg: validation: 0.936521
09/16 10:11:20 AM: micro_avg: validation: 0.000000
09/16 10:11:20 AM: edges-ner-ontonotes_mcc: training: 0.913517 validation: 0.933131
09/16 10:11:20 AM: edges-ner-ontonotes_acc: training: 0.872417 validation: 0.903170
09/16 10:11:20 AM: edges-ner-ontonotes_precision: training: 0.938284 validation: 0.957752
09/16 10:11:20 AM: edges-ner-ontonotes_recall: training: 0.898559 validation: 0.916212
09/16 10:11:20 AM: edges-ner-ontonotes_f1: training: 0.917992 validation: 0.936521
09/16 10:11:20 AM: Global learning rate: 5e-05
09/16 10:11:20 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 10:11:28 AM: Update 33095: task edges-ner-ontonotes, batch 95 (33095): mcc: 0.9177, acc: 0.8797, precision: 0.9425, recall: 0.9022, f1: 0.9219, edges-ner-ontonotes_loss: 0.0272
09/16 10:11:38 AM: Update 33224: task edges-ner-ontonotes, batch 224 (33224): mcc: 0.9183, acc: 0.8803, precision: 0.9408, recall: 0.9050, f1: 0.9225, edges-ner-ontonotes_loss: 0.0266
09/16 10:11:48 AM: Update 33320: task edges-ner-ontonotes, batch 320 (33320): mcc: 0.9185, acc: 0.8806, precision: 0.9412, recall: 0.9051, f1: 0.9228, edges-ner-ontonotes_loss: 0.0262
09/16 10:11:58 AM: Update 33448: task edges-ner-ontonotes, batch 448 (33448): mcc: 0.9226, acc: 0.8852, precision: 0.9441, recall: 0.9098, f1: 0.9266, edges-ner-ontonotes_loss: 0.0248
09/16 10:12:08 AM: Update 33570: task edges-ner-ontonotes, batch 570 (33570): mcc: 0.9257, acc: 0.8892, precision: 0.9460, recall: 0.9139, f1: 0.9297, edges-ner-ontonotes_loss: 0.0239
09/16 10:12:18 AM: Update 33670: task edges-ner-ontonotes, batch 670 (33670): mcc: 0.9267, acc: 0.8900, precision: 0.9471, recall: 0.9146, f1: 0.9306, edges-ner-ontonotes_loss: 0.0235
09/16 10:12:28 AM: Update 33791: task edges-ner-ontonotes, batch 791 (33791): mcc: 0.9271, acc: 0.8901, precision: 0.9472, recall: 0.9151, f1: 0.9309, edges-ner-ontonotes_loss: 0.0233
09/16 10:12:38 AM: Update 33914: task edges-ner-ontonotes, batch 914 (33914): mcc: 0.9277, acc: 0.8908, precision: 0.9480, recall: 0.9157, f1: 0.9315, edges-ner-ontonotes_loss: 0.0231
09/16 10:12:47 AM: ***** Step 34000 / Validation 34 *****
09/16 10:12:47 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:12:47 AM: Validating...
09/16 10:12:48 AM: Evaluate: task edges-ner-ontonotes, batch 18 (157): mcc: 0.8781, acc: 0.8273, precision: 0.9065, recall: 0.8633, f1: 0.8844, edges-ner-ontonotes_loss: 0.0348
09/16 10:12:58 AM: Evaluate: task edges-ner-ontonotes, batch 105 (157): mcc: 0.9215, acc: 0.8895, precision: 0.9464, recall: 0.9055, f1: 0.9255, edges-ner-ontonotes_loss: 0.0272
09/16 10:13:05 AM: Updating LR scheduler:
09/16 10:13:05 AM: 	Best result seen so far for macro_avg: 0.937
09/16 10:13:05 AM: 	# validation passes without improvement: 3
09/16 10:13:05 AM: edges-ner-ontonotes_loss: training: 0.024069 validation: 0.023449
09/16 10:13:05 AM: macro_avg: validation: 0.935877
09/16 10:13:05 AM: micro_avg: validation: 0.000000
09/16 10:13:05 AM: edges-ner-ontonotes_mcc: training: 0.925434 validation: 0.932411
09/16 10:13:05 AM: edges-ner-ontonotes_acc: training: 0.887672 validation: 0.903094
09/16 10:13:05 AM: edges-ner-ontonotes_precision: training: 0.946406 validation: 0.955663
09/16 10:13:05 AM: edges-ner-ontonotes_recall: training: 0.912884 validation: 0.916894
09/16 10:13:05 AM: edges-ner-ontonotes_f1: training: 0.929343 validation: 0.935877
09/16 10:13:05 AM: Global learning rate: 5e-05
09/16 10:13:05 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 10:13:08 AM: Update 34035: task edges-ner-ontonotes, batch 35 (34035): mcc: 0.8907, acc: 0.8353, precision: 0.9291, recall: 0.8651, f1: 0.8960, edges-ner-ontonotes_loss: 0.0366
09/16 10:13:18 AM: Update 34166: task edges-ner-ontonotes, batch 166 (34166): mcc: 0.8936, acc: 0.8469, precision: 0.9249, recall: 0.8744, f1: 0.8990, edges-ner-ontonotes_loss: 0.0371
09/16 10:13:28 AM: Update 34275: task edges-ner-ontonotes, batch 275 (34275): mcc: 0.8966, acc: 0.8512, precision: 0.9266, recall: 0.8783, f1: 0.9018, edges-ner-ontonotes_loss: 0.0358
09/16 10:13:38 AM: Update 34427: task edges-ner-ontonotes, batch 427 (34427): mcc: 0.8995, acc: 0.8547, precision: 0.9283, recall: 0.8822, f1: 0.9046, edges-ner-ontonotes_loss: 0.0339
09/16 10:13:49 AM: Update 34546: task edges-ner-ontonotes, batch 546 (34546): mcc: 0.9020, acc: 0.8581, precision: 0.9304, recall: 0.8848, f1: 0.9070, edges-ner-ontonotes_loss: 0.0328
09/16 10:13:59 AM: Update 34671: task edges-ner-ontonotes, batch 671 (34671): mcc: 0.9042, acc: 0.8608, precision: 0.9316, recall: 0.8878, f1: 0.9092, edges-ner-ontonotes_loss: 0.0319
09/16 10:14:09 AM: Update 34798: task edges-ner-ontonotes, batch 798 (34798): mcc: 0.9068, acc: 0.8641, precision: 0.9334, recall: 0.8908, f1: 0.9116, edges-ner-ontonotes_loss: 0.0310
09/16 10:14:19 AM: Update 34909: task edges-ner-ontonotes, batch 909 (34909): mcc: 0.9085, acc: 0.8663, precision: 0.9345, recall: 0.8929, f1: 0.9132, edges-ner-ontonotes_loss: 0.0304
09/16 10:14:26 AM: ***** Step 35000 / Validation 35 *****
09/16 10:14:26 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:14:26 AM: Validating...
09/16 10:14:29 AM: Evaluate: task edges-ner-ontonotes, batch 27 (157): mcc: 0.8726, acc: 0.8270, precision: 0.9062, recall: 0.8535, f1: 0.8791, edges-ner-ontonotes_loss: 0.0413
09/16 10:14:39 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9246, acc: 0.8923, precision: 0.9487, recall: 0.9091, f1: 0.9285, edges-ner-ontonotes_loss: 0.0266
09/16 10:14:44 AM: Updating LR scheduler:
09/16 10:14:44 AM: 	Best result seen so far for macro_avg: 0.937
09/16 10:14:44 AM: 	# validation passes without improvement: 0
09/16 10:14:44 AM: edges-ner-ontonotes_loss: training: 0.029437 validation: 0.023491
09/16 10:14:44 AM: macro_avg: validation: 0.936504
09/16 10:14:44 AM: micro_avg: validation: 0.000000
09/16 10:14:44 AM: edges-ner-ontonotes_mcc: training: 0.911133 validation: 0.933011
09/16 10:14:44 AM: edges-ner-ontonotes_acc: training: 0.869568 validation: 0.903245
09/16 10:14:44 AM: edges-ner-ontonotes_precision: training: 0.936270 validation: 0.953770
09/16 10:14:44 AM: edges-ner-ontonotes_recall: training: 0.896073 validation: 0.919851
09/16 10:14:44 AM: edges-ner-ontonotes_f1: training: 0.915730 validation: 0.936504
09/16 10:14:44 AM: Global learning rate: 2.5e-05
09/16 10:14:44 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 10:14:49 AM: Update 35060: task edges-ner-ontonotes, batch 60 (35060): mcc: 0.9298, acc: 0.8911, precision: 0.9497, recall: 0.9179, f1: 0.9335, edges-ner-ontonotes_loss: 0.0223
09/16 10:15:00 AM: Update 35172: task edges-ner-ontonotes, batch 172 (35172): mcc: 0.9338, acc: 0.8981, precision: 0.9510, recall: 0.9239, f1: 0.9373, edges-ner-ontonotes_loss: 0.0207
09/16 10:15:10 AM: Update 35285: task edges-ner-ontonotes, batch 285 (35285): mcc: 0.9319, acc: 0.8952, precision: 0.9505, recall: 0.9209, f1: 0.9355, edges-ner-ontonotes_loss: 0.0213
09/16 10:15:20 AM: Update 35412: task edges-ner-ontonotes, batch 412 (35412): mcc: 0.9323, acc: 0.8958, precision: 0.9507, recall: 0.9215, f1: 0.9359, edges-ner-ontonotes_loss: 0.0212
09/16 10:15:30 AM: Update 35524: task edges-ner-ontonotes, batch 524 (35524): mcc: 0.9288, acc: 0.8911, precision: 0.9485, recall: 0.9171, f1: 0.9325, edges-ner-ontonotes_loss: 0.0227
09/16 10:15:41 AM: Update 35648: task edges-ner-ontonotes, batch 648 (35648): mcc: 0.9216, acc: 0.8824, precision: 0.9438, recall: 0.9082, f1: 0.9257, edges-ner-ontonotes_loss: 0.0255
09/16 10:15:51 AM: Update 35784: task edges-ner-ontonotes, batch 784 (35784): mcc: 0.9175, acc: 0.8773, precision: 0.9413, recall: 0.9031, f1: 0.9218, edges-ner-ontonotes_loss: 0.0274
09/16 10:16:01 AM: Update 35898: task edges-ner-ontonotes, batch 898 (35898): mcc: 0.9159, acc: 0.8756, precision: 0.9398, recall: 0.9016, f1: 0.9203, edges-ner-ontonotes_loss: 0.0280
09/16 10:16:07 AM: ***** Step 36000 / Validation 36 *****
09/16 10:16:07 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:16:07 AM: Validating...
09/16 10:16:11 AM: Evaluate: task edges-ner-ontonotes, batch 42 (157): mcc: 0.9050, acc: 0.8704, precision: 0.9276, recall: 0.8931, f1: 0.9100, edges-ner-ontonotes_loss: 0.0314
09/16 10:16:22 AM: Evaluate: task edges-ner-ontonotes, batch 119 (157): mcc: 0.9274, acc: 0.8967, precision: 0.9532, recall: 0.9100, f1: 0.9311, edges-ner-ontonotes_loss: 0.0250
09/16 10:16:26 AM: Updating LR scheduler:
09/16 10:16:26 AM: 	Best result seen so far for macro_avg: 0.937
09/16 10:16:26 AM: 	# validation passes without improvement: 1
09/16 10:16:26 AM: edges-ner-ontonotes_loss: training: 0.027967 validation: 0.022850
09/16 10:16:26 AM: macro_avg: validation: 0.936472
09/16 10:16:26 AM: micro_avg: validation: 0.000000
09/16 10:16:26 AM: edges-ner-ontonotes_mcc: training: 0.915655 validation: 0.933101
09/16 10:16:26 AM: edges-ner-ontonotes_acc: training: 0.875360 validation: 0.903397
09/16 10:16:26 AM: edges-ner-ontonotes_precision: training: 0.939762 validation: 0.958479
09/16 10:16:26 AM: edges-ner-ontonotes_recall: training: 0.901108 validation: 0.915453
09/16 10:16:26 AM: edges-ner-ontonotes_f1: training: 0.920029 validation: 0.936472
09/16 10:16:26 AM: Global learning rate: 2.5e-05
09/16 10:16:26 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 10:16:32 AM: Update 36083: task edges-ner-ontonotes, batch 83 (36083): mcc: 0.9083, acc: 0.8673, precision: 0.9334, recall: 0.8935, f1: 0.9130, edges-ner-ontonotes_loss: 0.0302
09/16 10:16:42 AM: Update 36184: task edges-ner-ontonotes, batch 184 (36184): mcc: 0.9129, acc: 0.8731, precision: 0.9382, recall: 0.8974, f1: 0.9174, edges-ner-ontonotes_loss: 0.0287
09/16 10:16:52 AM: Update 36311: task edges-ner-ontonotes, batch 311 (36311): mcc: 0.9151, acc: 0.8753, precision: 0.9400, recall: 0.8998, f1: 0.9195, edges-ner-ontonotes_loss: 0.0276
09/16 10:17:02 AM: Update 36421: task edges-ner-ontonotes, batch 421 (36421): mcc: 0.9154, acc: 0.8761, precision: 0.9397, recall: 0.9008, f1: 0.9198, edges-ner-ontonotes_loss: 0.0275
09/16 10:17:12 AM: Update 36541: task edges-ner-ontonotes, batch 541 (36541): mcc: 0.9200, acc: 0.8819, precision: 0.9426, recall: 0.9064, f1: 0.9242, edges-ner-ontonotes_loss: 0.0260
09/16 10:17:22 AM: Update 36669: task edges-ner-ontonotes, batch 669 (36669): mcc: 0.9226, acc: 0.8851, precision: 0.9444, recall: 0.9095, f1: 0.9266, edges-ner-ontonotes_loss: 0.0250
09/16 10:17:32 AM: Update 36772: task edges-ner-ontonotes, batch 772 (36772): mcc: 0.9240, acc: 0.8867, precision: 0.9452, recall: 0.9113, f1: 0.9280, edges-ner-ontonotes_loss: 0.0246
09/16 10:17:42 AM: Update 36896: task edges-ner-ontonotes, batch 896 (36896): mcc: 0.9244, acc: 0.8870, precision: 0.9459, recall: 0.9115, f1: 0.9283, edges-ner-ontonotes_loss: 0.0244
09/16 10:17:50 AM: ***** Step 37000 / Validation 37 *****
09/16 10:17:50 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:17:50 AM: Validating...
09/16 10:17:52 AM: Evaluate: task edges-ner-ontonotes, batch 17 (157): mcc: 0.8672, acc: 0.8081, precision: 0.9062, recall: 0.8436, f1: 0.8738, edges-ner-ontonotes_loss: 0.0387
09/16 10:18:02 AM: Evaluate: task edges-ner-ontonotes, batch 106 (157): mcc: 0.9220, acc: 0.8897, precision: 0.9458, recall: 0.9070, f1: 0.9260, edges-ner-ontonotes_loss: 0.0278
09/16 10:18:09 AM: Updating LR scheduler:
09/16 10:18:09 AM: 	Best result seen so far for macro_avg: 0.937
09/16 10:18:10 AM: 	# validation passes without improvement: 2
09/16 10:18:10 AM: Ran out of early stopping patience. Stopping training.
09/16 10:18:10 AM: edges-ner-ontonotes_loss: training: 0.024178 validation: 0.023576
09/16 10:18:10 AM: macro_avg: validation: 0.937278
09/16 10:18:10 AM: micro_avg: validation: 0.000000
09/16 10:18:10 AM: edges-ner-ontonotes_mcc: training: 0.924991 validation: 0.933816
09/16 10:18:10 AM: edges-ner-ontonotes_acc: training: 0.887593 validation: 0.904459
09/16 10:18:10 AM: edges-ner-ontonotes_precision: training: 0.946141 validation: 0.953910
09/16 10:18:10 AM: edges-ner-ontonotes_recall: training: 0.912315 validation: 0.921216
09/16 10:18:10 AM: edges-ner-ontonotes_f1: training: 0.928920 validation: 0.937278
09/16 10:18:10 AM: Global learning rate: 2.5e-05
09/16 10:18:10 AM: Saving checkpoints to: ./experiments/ner-ontonotes-coref-top/run
09/16 10:18:10 AM: Stopped training after 37 validation checks
09/16 10:18:10 AM: Trained edges-ner-ontonotes for 37000 batches or 23.810 epochs
09/16 10:18:10 AM: ***** VALIDATION RESULTS *****
09/16 10:18:10 AM: edges-ner-ontonotes_f1 (for best val pass 27): edges-ner-ontonotes_loss: 0.02321, macro_avg: 0.93730, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.93382, edges-ner-ontonotes_acc: 0.90537, edges-ner-ontonotes_precision: 0.95291, edges-ner-ontonotes_recall: 0.92220, edges-ner-ontonotes_f1: 0.93730
09/16 10:18:10 AM: micro_avg (for best val pass 1): edges-ner-ontonotes_loss: 0.05349, macro_avg: 0.85119, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.84595, edges-ner-ontonotes_acc: 0.77995, edges-ner-ontonotes_precision: 0.92230, edges-ner-ontonotes_recall: 0.79026, edges-ner-ontonotes_f1: 0.85119
09/16 10:18:10 AM: macro_avg (for best val pass 27): edges-ner-ontonotes_loss: 0.02321, macro_avg: 0.93730, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.93382, edges-ner-ontonotes_acc: 0.90537, edges-ner-ontonotes_precision: 0.95291, edges-ner-ontonotes_recall: 0.92220, edges-ner-ontonotes_f1: 0.93730
09/16 10:18:10 AM: Evaluating...
09/16 10:18:10 AM: Loaded model state from ./experiments/ner-ontonotes-coref-top/run/edges-ner-ontonotes/model_state_target_train_val_27.best.th
09/16 10:18:10 AM: Evaluating on: edges-ner-ontonotes, split: val
09/16 10:18:40 AM: 	Task edges-ner-ontonotes: batch 236
09/16 10:18:40 AM: Task 'edges-ner-ontonotes': sorting predictions by 'idx'
09/16 10:18:41 AM: Finished evaluating on: edges-ner-ontonotes
09/16 10:18:41 AM: Task 'edges-ner-ontonotes': joining predictions with input split 'val'
09/16 10:18:42 AM: Task 'edges-ner-ontonotes': Wrote predictions to ./experiments/ner-ontonotes-coref-top/run
09/16 10:18:42 AM: Wrote all preds for split 'val' to ./experiments/ner-ontonotes-coref-top/run
09/16 10:18:42 AM: Evaluating on: edges-ner-ontonotes, split: test
09/16 10:19:01 AM: Task 'edges-ner-ontonotes': sorting predictions by 'idx'
09/16 10:19:01 AM: Finished evaluating on: edges-ner-ontonotes
09/16 10:19:01 AM: Task 'edges-ner-ontonotes': joining predictions with input split 'test'
09/16 10:19:01 AM: Task 'edges-ner-ontonotes': Wrote predictions to ./experiments/ner-ontonotes-coref-top/run
09/16 10:19:01 AM: Wrote all preds for split 'test' to ./experiments/ner-ontonotes-coref-top/run
09/16 10:19:01 AM: Writing results for split 'val' to ./experiments/ner-ontonotes-coref-top/results.tsv
09/16 10:19:01 AM: micro_avg: 0.000, macro_avg: 0.933, edges-ner-ontonotes_mcc: 0.929, edges-ner-ontonotes_acc: 0.901, edges-ner-ontonotes_precision: 0.950, edges-ner-ontonotes_recall: 0.917, edges-ner-ontonotes_f1: 0.933
09/16 10:19:01 AM: Done!
