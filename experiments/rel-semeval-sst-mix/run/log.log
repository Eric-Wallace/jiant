09/16 12:09:09 PM: Git branch: master
09/16 12:09:09 PM: Git SHA: 93c1dfd555f3458ddbb66d458dfeca984f2d8527
09/16 12:09:10 PM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/rel-semeval-sst-mix/",
  "exp_name": "experiments/rel-semeval-sst-mix",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/rel-semeval-sst-mix/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/sst",
  "pytorch_transformers_output_mode": "mix",
  "remote_log_name": "experiments/rel-semeval-sst-mix__run",
  "run_dir": "./experiments/rel-semeval-sst-mix/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-rel-semeval",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 12:09:10 PM: Saved config to ./experiments/rel-semeval-sst-mix/run/params.conf
09/16 12:09:10 PM: Using random seed 1234
09/16 12:09:38 PM: Using GPU 0
09/16 12:09:38 PM: Loading tasks...
09/16 12:09:38 PM: Writing pre-preprocessed tasks to ./experiments/rel-semeval-sst-mix/
09/16 12:09:38 PM: 	Creating task edges-rel-semeval from scratch.
09/16 12:09:38 PM: Read=6851, Skip=0, Total=6851 from ./probing_data/edges/semeval/train.0.85.json.retokenized.bert-base-uncased
09/16 12:09:38 PM: Read=1149, Skip=0, Total=1149 from ./probing_data/edges/semeval/dev.json.retokenized.bert-base-uncased
09/16 12:09:38 PM: Read=2717, Skip=0, Total=2717 from ./probing_data/edges/semeval/test.json.retokenized.bert-base-uncased
09/16 12:09:38 PM: 	Task 'edges-rel-semeval': |train|=6851 |val|=1149 |test|=2717
09/16 12:09:38 PM: 	Finished loading tasks: edges-rel-semeval.
09/16 12:09:38 PM: 	Building vocab from scratch.
09/16 12:09:38 PM: 	Counting units for task edges-rel-semeval.
09/16 12:09:38 PM: 	Task 'edges-rel-semeval': adding vocab namespace 'edges-rel-semeval_labels'
09/16 12:09:39 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:09:39 PM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 12:09:40 PM: 	Saved vocab to ./experiments/rel-semeval-sst-mix/vocab
09/16 12:09:40 PM: Loading token dictionary from ./experiments/rel-semeval-sst-mix/vocab.
09/16 12:09:40 PM: 	Loaded vocab from ./experiments/rel-semeval-sst-mix/vocab
09/16 12:09:40 PM: 	Vocab namespace tokens: size 16020
09/16 12:09:40 PM: 	Vocab namespace bert_uncased: size 30524
09/16 12:09:40 PM: 	Vocab namespace edges-rel-semeval_labels: size 19
09/16 12:09:40 PM: 	Vocab namespace chars: size 59
09/16 12:09:40 PM: 	Finished building vocab.
09/16 12:09:40 PM: 	Task edges-rel-semeval (train): Indexing from scratch.
09/16 12:09:41 PM: 	Task edges-rel-semeval (train): Saved 6851 instances to ./experiments/rel-semeval-sst-mix/preproc/edges-rel-semeval__train_data
09/16 12:09:41 PM: 	Task edges-rel-semeval (val): Indexing from scratch.
09/16 12:09:41 PM: 	Task edges-rel-semeval (val): Saved 1149 instances to ./experiments/rel-semeval-sst-mix/preproc/edges-rel-semeval__val_data
09/16 12:09:41 PM: 	Task edges-rel-semeval (test): Indexing from scratch.
09/16 12:09:41 PM: 	Task edges-rel-semeval (test): Saved 2717 instances to ./experiments/rel-semeval-sst-mix/preproc/edges-rel-semeval__test_data
09/16 12:09:41 PM: 	Finished indexing tasks
09/16 12:09:41 PM: 	Creating trimmed target-only version of edges-rel-semeval train.
09/16 12:09:41 PM: 	  Training on 
09/16 12:09:41 PM: 	  Evaluating on edges-rel-semeval
09/16 12:09:41 PM: 	Finished loading tasks in 3.758s
09/16 12:09:41 PM: 	 Tasks: ['edges-rel-semeval']
09/16 12:09:41 PM: Building model...
09/16 12:09:41 PM: Using BERT model (bert-base-uncased).
09/16 12:09:41 PM: LOADING A FUNETUNED MODEL from: 
09/16 12:09:41 PM: models/sst
09/16 12:09:41 PM: loading configuration file models/sst/config.json
09/16 12:09:41 PM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "sst-2",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 12:09:41 PM: loading weights file models/sst/pytorch_model.bin
09/16 12:09:46 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpovbvok_x
09/16 12:09:48 PM: copying /tmp/tmpovbvok_x to cache at ./experiments/rel-semeval-sst-mix/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:09:48 PM: creating metadata file for ./experiments/rel-semeval-sst-mix/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:09:48 PM: removing temp file /tmp/tmpovbvok_x
09/16 12:09:48 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/rel-semeval-sst-mix/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:09:48 PM: NOTE: pytorch_transformers_output_mode='mix', so scalar mixing weights will be fine-tuned even if BERT model is frozen.
09/16 12:09:48 PM: Initializing parameters
09/16 12:09:48 PM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 12:09:48 PM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 12:09:48 PM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 12:09:48 PM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.model.pooler.dense.bias
09/16 12:09:48 PM:    _text_field_embedder.model.pooler.dense.weight
09/16 12:09:48 PM:    _text_field_embedder.scalar_mix.gamma
09/16 12:09:48 PM:    _text_field_embedder.scalar_mix.scalar_parameters.0
09/16 12:09:48 PM:    _text_field_embedder.scalar_mix.scalar_parameters.1
09/16 12:09:48 PM:    _text_field_embedder.scalar_mix.scalar_parameters.10
09/16 12:09:48 PM:    _text_field_embedder.scalar_mix.scalar_parameters.11
09/16 12:09:48 PM:    _text_field_embedder.scalar_mix.scalar_parameters.12
09/16 12:09:48 PM:    _text_field_embedder.scalar_mix.scalar_parameters.2
09/16 12:09:48 PM:    _text_field_embedder.scalar_mix.scalar_parameters.3
09/16 12:09:48 PM:    _text_field_embedder.scalar_mix.scalar_parameters.4
09/16 12:09:48 PM:    _text_field_embedder.scalar_mix.scalar_parameters.5
09/16 12:09:48 PM:    _text_field_embedder.scalar_mix.scalar_parameters.6
09/16 12:09:48 PM:    _text_field_embedder.scalar_mix.scalar_parameters.7
09/16 12:09:48 PM:    _text_field_embedder.scalar_mix.scalar_parameters.8
09/16 12:09:48 PM:    _text_field_embedder.scalar_mix.scalar_parameters.9
09/16 12:09:48 PM: 	Task 'edges-rel-semeval' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-rel-semeval"
}
09/16 12:10:10 PM: Model specification:
09/16 12:10:10 PM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
      (scalar_mix): ScalarMix(
        (scalar_parameters): ParameterList(
            (0): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (1): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (2): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (3): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (4): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (5): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (6): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (7): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (8): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (9): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (10): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (11): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (12): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-rel-semeval_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (proj2): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (span_extractor2): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Sequential(
        (0): Linear(in_features=1024, out_features=256, bias=True)
        (1): Tanh()
        (2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)
        (3): Dropout(p=0.3)
        (4): Linear(in_features=256, out_features=19, bias=True)
      )
    )
  )
)
09/16 12:10:10 PM: Model parameters:
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.scalar_mix.gamma: Trainable parameter, count 1 with torch.Size([1])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.0: Trainable parameter, count 1 with torch.Size([1])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.1: Trainable parameter, count 1 with torch.Size([1])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.2: Trainable parameter, count 1 with torch.Size([1])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.3: Trainable parameter, count 1 with torch.Size([1])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.4: Trainable parameter, count 1 with torch.Size([1])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.5: Trainable parameter, count 1 with torch.Size([1])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.6: Trainable parameter, count 1 with torch.Size([1])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.7: Trainable parameter, count 1 with torch.Size([1])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.8: Trainable parameter, count 1 with torch.Size([1])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.9: Trainable parameter, count 1 with torch.Size([1])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.10: Trainable parameter, count 1 with torch.Size([1])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.11: Trainable parameter, count 1 with torch.Size([1])
09/16 12:10:10 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.12: Trainable parameter, count 1 with torch.Size([1])
09/16 12:10:10 PM: 	edges-rel-semeval_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 12:10:10 PM: 	edges-rel-semeval_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 12:10:10 PM: 	edges-rel-semeval_mdl.proj2.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 12:10:10 PM: 	edges-rel-semeval_mdl.proj2.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 12:10:10 PM: 	edges-rel-semeval_mdl.classifier.classifier.0.weight: Trainable parameter, count 262144 with torch.Size([256, 1024])
09/16 12:10:10 PM: 	edges-rel-semeval_mdl.classifier.classifier.0.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 12:10:10 PM: 	edges-rel-semeval_mdl.classifier.classifier.2.weight: Trainable parameter, count 256 with torch.Size([256])
09/16 12:10:10 PM: 	edges-rel-semeval_mdl.classifier.classifier.2.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 12:10:10 PM: 	edges-rel-semeval_mdl.classifier.classifier.4.weight: Trainable parameter, count 4864 with torch.Size([19, 256])
09/16 12:10:10 PM: 	edges-rel-semeval_mdl.classifier.classifier.4.bias: Trainable parameter, count 19 with torch.Size([19])
09/16 12:10:10 PM: Total number of parameters: 110143777 (1.10144e+08)
09/16 12:10:10 PM: Number of trainable parameters: 661537 (661537)
09/16 12:10:10 PM: Finished building model in 28.785s
09/16 12:10:10 PM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-rel-semeval 

09/16 12:10:11 PM: patience = 9
09/16 12:10:11 PM: val_interval = 100
09/16 12:10:11 PM: max_vals = 100
09/16 12:10:11 PM: cuda_device = 0
09/16 12:10:11 PM: grad_norm = 5.0
09/16 12:10:11 PM: grad_clipping = None
09/16 12:10:11 PM: lr_decay = 0.99
09/16 12:10:11 PM: min_lr = 1e-06
09/16 12:10:11 PM: keep_all_checkpoints = 0
09/16 12:10:11 PM: val_data_limit = 5000
09/16 12:10:11 PM: max_epochs = -1
09/16 12:10:11 PM: dec_val_scale = 250
09/16 12:10:11 PM: training_data_fraction = 1
09/16 12:10:11 PM: type = adam
09/16 12:10:11 PM: parameter_groups = None
09/16 12:10:11 PM: Number of trainable parameters: 661537
09/16 12:10:11 PM: infer_type_and_cast = True
09/16 12:10:11 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:10:11 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:10:11 PM: lr = 0.0001
09/16 12:10:11 PM: amsgrad = True
09/16 12:10:11 PM: type = reduce_on_plateau
09/16 12:10:11 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:10:11 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:10:11 PM: mode = max
09/16 12:10:11 PM: factor = 0.5
09/16 12:10:11 PM: patience = 3
09/16 12:10:11 PM: threshold = 0.0001
09/16 12:10:11 PM: threshold_mode = abs
09/16 12:10:11 PM: verbose = True
09/16 12:10:11 PM: type = adam
09/16 12:10:11 PM: parameter_groups = None
09/16 12:10:11 PM: Number of trainable parameters: 661537
09/16 12:10:11 PM: infer_type_and_cast = True
09/16 12:10:11 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:10:11 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:10:11 PM: lr = 0.0001
09/16 12:10:11 PM: amsgrad = True
09/16 12:10:11 PM: type = reduce_on_plateau
09/16 12:10:11 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:10:11 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:10:11 PM: mode = max
09/16 12:10:11 PM: factor = 0.5
09/16 12:10:11 PM: patience = 3
09/16 12:10:11 PM: threshold = 0.0001
09/16 12:10:11 PM: threshold_mode = abs
09/16 12:10:11 PM: verbose = True
09/16 12:10:11 PM: Starting training without restoring from a checkpoint.
09/16 12:10:11 PM: Training examples per task, before any subsampling: {'edges-rel-semeval': 6851}
09/16 12:10:11 PM: Beginning training with stopping criteria based on metric: edges-rel-semeval_f1
09/16 12:10:21 PM: Update 8: task edges-rel-semeval, batch 8 (8): mcc: 0.0087, acc: 0.0044, precision: 0.0556, recall: 0.3172, f1: 0.0946, edges-rel-semeval_loss: 0.6227
09/16 12:10:27 PM: ***** Step 100 / Validation 1 *****
09/16 12:10:27 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:10:27 PM: Validating...
09/16 12:10:32 PM: Evaluate: task edges-rel-semeval, batch 19 (36): mcc: 0.0000, acc: 0.0000, precision: 0.0000, recall: 0.0000, f1: 0.0000, edges-rel-semeval_loss: 0.1764
09/16 12:10:33 PM: Best result seen so far for edges-rel-semeval.
09/16 12:10:33 PM: Best result seen so far for micro.
09/16 12:10:33 PM: Best result seen so far for macro.
09/16 12:10:33 PM: Updating LR scheduler:
09/16 12:10:33 PM: 	Best result seen so far for macro_avg: 0.000
09/16 12:10:33 PM: 	# validation passes without improvement: 0
09/16 12:10:33 PM: edges-rel-semeval_loss: training: 0.257856 validation: 0.176192
09/16 12:10:33 PM: macro_avg: validation: 0.000000
09/16 12:10:33 PM: micro_avg: validation: 0.000000
09/16 12:10:33 PM: edges-rel-semeval_mcc: training: 0.005325 validation: 0.000000
09/16 12:10:33 PM: edges-rel-semeval_acc: training: 0.003784 validation: 0.000000
09/16 12:10:33 PM: edges-rel-semeval_precision: training: 0.059861 validation: 0.000000
09/16 12:10:33 PM: edges-rel-semeval_recall: training: 0.029959 validation: 0.000000
09/16 12:10:33 PM: edges-rel-semeval_f1: training: 0.039933 validation: 0.000000
09/16 12:10:33 PM: Global learning rate: 0.0001
09/16 12:10:33 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:10:43 PM: Update 122: task edges-rel-semeval, batch 22 (122): mcc: 0.0519, acc: 0.0028, precision: 1.0000, recall: 0.0028, f1: 0.0057, edges-rel-semeval_loss: 0.1818
09/16 12:10:48 PM: ***** Step 200 / Validation 2 *****
09/16 12:10:49 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:10:49 PM: Validating...
09/16 12:10:52 PM: Best result seen so far for edges-rel-semeval.
09/16 12:10:52 PM: Best result seen so far for macro.
09/16 12:10:52 PM: Updating LR scheduler:
09/16 12:10:52 PM: 	Best result seen so far for macro_avg: 0.135
09/16 12:10:52 PM: 	# validation passes without improvement: 0
09/16 12:10:52 PM: edges-rel-semeval_loss: training: 0.169138 validation: 0.146877
09/16 12:10:52 PM: macro_avg: validation: 0.135157
09/16 12:10:52 PM: micro_avg: validation: 0.000000
09/16 12:10:52 PM: edges-rel-semeval_mcc: training: 0.146935 validation: 0.247668
09/16 12:10:52 PM: edges-rel-semeval_acc: training: 0.028125 validation: 0.073107
09/16 12:10:52 PM: edges-rel-semeval_precision: training: 0.819820 validation: 0.893617
09/16 12:10:52 PM: edges-rel-semeval_recall: training: 0.028438 validation: 0.073107
09/16 12:10:52 PM: edges-rel-semeval_f1: training: 0.054968 validation: 0.135157
09/16 12:10:52 PM: Global learning rate: 0.0001
09/16 12:10:52 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:10:53 PM: Update 205: task edges-rel-semeval, batch 5 (205): mcc: 0.2777, acc: 0.0875, precision: 0.9333, recall: 0.0875, f1: 0.1600, edges-rel-semeval_loss: 0.1496
09/16 12:11:00 PM: ***** Step 300 / Validation 3 *****
09/16 12:11:00 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:11:00 PM: Validating...
09/16 12:11:03 PM: Evaluate: task edges-rel-semeval, batch 29 (36): mcc: 0.3903, acc: 0.1746, precision: 0.9157, recall: 0.1756, f1: 0.2948, edges-rel-semeval_loss: 0.1236
09/16 12:11:03 PM: Best result seen so far for edges-rel-semeval.
09/16 12:11:05 PM: Best result seen so far for macro.
09/16 12:11:05 PM: Updating LR scheduler:
09/16 12:11:05 PM: 	Best result seen so far for macro_avg: 0.276
09/16 12:11:05 PM: 	# validation passes without improvement: 0
09/16 12:11:05 PM: edges-rel-semeval_loss: training: 0.143883 validation: 0.125750
09/16 12:11:05 PM: macro_avg: validation: 0.275811
09/16 12:11:05 PM: micro_avg: validation: 0.000000
09/16 12:11:05 PM: edges-rel-semeval_mcc: training: 0.313886 validation: 0.372766
09/16 12:11:05 PM: edges-rel-semeval_acc: training: 0.126774 validation: 0.161880
09/16 12:11:05 PM: edges-rel-semeval_precision: training: 0.808967 validation: 0.903382
09/16 12:11:05 PM: edges-rel-semeval_recall: training: 0.130874 validation: 0.162750
09/16 12:11:05 PM: edges-rel-semeval_f1: training: 0.225299 validation: 0.275811
09/16 12:11:05 PM: Global learning rate: 0.0001
09/16 12:11:05 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:11:11 PM: ***** Step 400 / Validation 4 *****
09/16 12:11:11 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:11:11 PM: Validating...
09/16 12:11:13 PM: Evaluate: task edges-rel-semeval, batch 18 (36): mcc: 0.5244, acc: 0.3125, precision: 0.8981, recall: 0.3212, f1: 0.4731, edges-rel-semeval_loss: 0.1079
09/16 12:11:14 PM: Best result seen so far for edges-rel-semeval.
09/16 12:11:14 PM: Best result seen so far for macro.
09/16 12:11:14 PM: Updating LR scheduler:
09/16 12:11:14 PM: 	Best result seen so far for macro_avg: 0.415
09/16 12:11:14 PM: 	# validation passes without improvement: 0
09/16 12:11:14 PM: edges-rel-semeval_loss: training: 0.124723 validation: 0.112129
09/16 12:11:14 PM: macro_avg: validation: 0.415119
09/16 12:11:14 PM: micro_avg: validation: 0.000000
09/16 12:11:14 PM: edges-rel-semeval_mcc: training: 0.451122 validation: 0.474391
09/16 12:11:14 PM: edges-rel-semeval_acc: training: 0.246875 validation: 0.268059
09/16 12:11:14 PM: edges-rel-semeval_precision: training: 0.855626 validation: 0.871866
09/16 12:11:14 PM: edges-rel-semeval_recall: training: 0.251875 validation: 0.272411
09/16 12:11:14 PM: edges-rel-semeval_f1: training: 0.389184 validation: 0.415119
09/16 12:11:14 PM: Global learning rate: 0.0001
09/16 12:11:14 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:11:22 PM: ***** Step 500 / Validation 5 *****
09/16 12:11:22 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:11:22 PM: Validating...
09/16 12:11:23 PM: Evaluate: task edges-rel-semeval, batch 5 (36): mcc: 0.6351, acc: 0.4625, precision: 0.8837, recall: 0.4750, f1: 0.6179, edges-rel-semeval_loss: 0.0956
09/16 12:11:25 PM: Best result seen so far for edges-rel-semeval.
09/16 12:11:25 PM: Best result seen so far for macro.
09/16 12:11:25 PM: Updating LR scheduler:
09/16 12:11:25 PM: 	Best result seen so far for macro_avg: 0.526
09/16 12:11:25 PM: 	# validation passes without improvement: 0
09/16 12:11:25 PM: edges-rel-semeval_loss: training: 0.114636 validation: 0.103238
09/16 12:11:25 PM: macro_avg: validation: 0.526124
09/16 12:11:25 PM: micro_avg: validation: 0.000000
09/16 12:11:25 PM: edges-rel-semeval_mcc: training: 0.511129 validation: 0.559537
09/16 12:11:25 PM: edges-rel-semeval_acc: training: 0.317881 validation: 0.370757
09/16 12:11:25 PM: edges-rel-semeval_precision: training: 0.839645 validation: 0.871227
09/16 12:11:25 PM: edges-rel-semeval_recall: training: 0.328603 validation: 0.376849
09/16 12:11:25 PM: edges-rel-semeval_f1: training: 0.472348 validation: 0.526124
09/16 12:11:25 PM: Global learning rate: 0.0001
09/16 12:11:25 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:11:31 PM: ***** Step 600 / Validation 6 *****
09/16 12:11:31 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:11:31 PM: Validating...
09/16 12:11:33 PM: Evaluate: task edges-rel-semeval, batch 19 (36): mcc: 0.6345, acc: 0.4507, precision: 0.9145, recall: 0.4572, f1: 0.6096, edges-rel-semeval_loss: 0.0930
09/16 12:11:34 PM: Best result seen so far for edges-rel-semeval.
09/16 12:11:34 PM: Best result seen so far for macro.
09/16 12:11:34 PM: Updating LR scheduler:
09/16 12:11:34 PM: 	Best result seen so far for macro_avg: 0.570
09/16 12:11:34 PM: 	# validation passes without improvement: 0
09/16 12:11:34 PM: edges-rel-semeval_loss: training: 0.104394 validation: 0.096142
09/16 12:11:34 PM: macro_avg: validation: 0.569918
09/16 12:11:34 PM: micro_avg: validation: 0.000000
09/16 12:11:34 PM: edges-rel-semeval_mcc: training: 0.564639 validation: 0.595188
09/16 12:11:34 PM: edges-rel-semeval_acc: training: 0.381875 validation: 0.416014
09/16 12:11:34 PM: edges-rel-semeval_precision: training: 0.838689 validation: 0.877034
09/16 12:11:34 PM: edges-rel-semeval_recall: training: 0.399687 validation: 0.422106
09/16 12:11:34 PM: edges-rel-semeval_f1: training: 0.541376 validation: 0.569918
09/16 12:11:34 PM: Global learning rate: 0.0001
09/16 12:11:34 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:11:41 PM: ***** Step 700 / Validation 7 *****
09/16 12:11:41 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:11:41 PM: Validating...
09/16 12:11:43 PM: Evaluate: task edges-rel-semeval, batch 21 (36): mcc: 0.6475, acc: 0.4747, precision: 0.9003, recall: 0.4836, f1: 0.6292, edges-rel-semeval_loss: 0.0881
09/16 12:11:44 PM: Best result seen so far for edges-rel-semeval.
09/16 12:11:45 PM: Best result seen so far for macro.
09/16 12:11:45 PM: Updating LR scheduler:
09/16 12:11:45 PM: 	Best result seen so far for macro_avg: 0.592
09/16 12:11:45 PM: 	# validation passes without improvement: 0
09/16 12:11:45 PM: edges-rel-semeval_loss: training: 0.097133 validation: 0.091647
09/16 12:11:45 PM: macro_avg: validation: 0.591533
09/16 12:11:45 PM: micro_avg: validation: 0.000000
09/16 12:11:45 PM: edges-rel-semeval_mcc: training: 0.601817 validation: 0.609641
09/16 12:11:45 PM: edges-rel-semeval_acc: training: 0.426049 validation: 0.442124
09/16 12:11:45 PM: edges-rel-semeval_precision: training: 0.846337 validation: 0.863105
09/16 12:11:45 PM: edges-rel-semeval_recall: training: 0.448124 validation: 0.449956
09/16 12:11:45 PM: edges-rel-semeval_f1: training: 0.585979 validation: 0.591533
09/16 12:11:45 PM: Global learning rate: 0.0001
09/16 12:11:45 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:11:51 PM: ***** Step 800 / Validation 8 *****
09/16 12:11:51 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:11:51 PM: Validating...
09/16 12:11:53 PM: Evaluate: task edges-rel-semeval, batch 25 (36): mcc: 0.6913, acc: 0.5387, precision: 0.8931, recall: 0.5537, f1: 0.6836, edges-rel-semeval_loss: 0.0832
09/16 12:11:54 PM: Best result seen so far for edges-rel-semeval.
09/16 12:11:54 PM: Best result seen so far for macro.
09/16 12:11:54 PM: Updating LR scheduler:
09/16 12:11:54 PM: 	Best result seen so far for macro_avg: 0.653
09/16 12:11:54 PM: 	# validation passes without improvement: 0
09/16 12:11:54 PM: edges-rel-semeval_loss: training: 0.092012 validation: 0.086729
09/16 12:11:54 PM: macro_avg: validation: 0.652838
09/16 12:11:54 PM: micro_avg: validation: 0.000000
09/16 12:11:54 PM: edges-rel-semeval_mcc: training: 0.624552 validation: 0.662292
09/16 12:11:54 PM: edges-rel-semeval_acc: training: 0.458750 validation: 0.506527
09/16 12:11:54 PM: edges-rel-semeval_precision: training: 0.849474 validation: 0.875549
09/16 12:11:54 PM: edges-rel-semeval_recall: training: 0.479688 validation: 0.520453
09/16 12:11:54 PM: edges-rel-semeval_f1: training: 0.613142 validation: 0.652838
09/16 12:11:54 PM: Global learning rate: 0.0001
09/16 12:11:54 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:12:01 PM: ***** Step 900 / Validation 9 *****
09/16 12:12:01 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:12:01 PM: Validating...
09/16 12:12:03 PM: Evaluate: task edges-rel-semeval, batch 23 (36): mcc: 0.6959, acc: 0.5557, precision: 0.8887, recall: 0.5639, f1: 0.6899, edges-rel-semeval_loss: 0.0800
09/16 12:12:04 PM: Best result seen so far for edges-rel-semeval.
09/16 12:12:07 PM: Best result seen so far for macro.
09/16 12:12:07 PM: Updating LR scheduler:
09/16 12:12:07 PM: 	Best result seen so far for macro_avg: 0.660
09/16 12:12:07 PM: 	# validation passes without improvement: 0
09/16 12:12:07 PM: edges-rel-semeval_loss: training: 0.086947 validation: 0.083832
09/16 12:12:07 PM: macro_avg: validation: 0.659827
09/16 12:12:07 PM: micro_avg: validation: 0.000000
09/16 12:12:07 PM: edges-rel-semeval_mcc: training: 0.641462 validation: 0.666995
09/16 12:12:07 PM: edges-rel-semeval_acc: training: 0.486597 validation: 0.523934
09/16 12:12:07 PM: edges-rel-semeval_precision: training: 0.842544 validation: 0.869132
09/16 12:12:07 PM: edges-rel-semeval_recall: training: 0.509618 validation: 0.531767
09/16 12:12:07 PM: edges-rel-semeval_f1: training: 0.635095 validation: 0.659827
09/16 12:12:07 PM: Global learning rate: 0.0001
09/16 12:12:07 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:12:13 PM: ***** Step 1000 / Validation 10 *****
09/16 12:12:13 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:12:13 PM: Validating...
09/16 12:12:13 PM: Evaluate: task edges-rel-semeval, batch 2 (36): mcc: 0.7040, acc: 0.5781, precision: 0.8039, recall: 0.6406, f1: 0.7130, edges-rel-semeval_loss: 0.0753
09/16 12:12:16 PM: Best result seen so far for edges-rel-semeval.
09/16 12:12:18 PM: Best result seen so far for macro.
09/16 12:12:18 PM: Updating LR scheduler:
09/16 12:12:18 PM: 	Best result seen so far for macro_avg: 0.679
09/16 12:12:18 PM: 	# validation passes without improvement: 0
09/16 12:12:18 PM: edges-rel-semeval_loss: training: 0.080949 validation: 0.081035
09/16 12:12:18 PM: macro_avg: validation: 0.679065
09/16 12:12:18 PM: micro_avg: validation: 0.000000
09/16 12:12:18 PM: edges-rel-semeval_mcc: training: 0.680117 validation: 0.683755
09/16 12:12:18 PM: edges-rel-semeval_acc: training: 0.528438 validation: 0.542211
09/16 12:12:18 PM: edges-rel-semeval_precision: training: 0.863592 validation: 0.871760
09/16 12:12:18 PM: edges-rel-semeval_recall: training: 0.555938 validation: 0.556136
09/16 12:12:18 PM: edges-rel-semeval_f1: training: 0.676426 validation: 0.679065
09/16 12:12:18 PM: Global learning rate: 0.0001
09/16 12:12:18 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:12:24 PM: Update 1076: task edges-rel-semeval, batch 76 (1076): mcc: 0.6733, acc: 0.5281, precision: 0.8396, recall: 0.5618, f1: 0.6731, edges-rel-semeval_loss: 0.0803
09/16 12:12:25 PM: ***** Step 1100 / Validation 11 *****
09/16 12:12:25 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:12:25 PM: Validating...
09/16 12:12:28 PM: Best result seen so far for edges-rel-semeval.
09/16 12:12:29 PM: Best result seen so far for macro.
09/16 12:12:29 PM: Updating LR scheduler:
09/16 12:12:29 PM: 	Best result seen so far for macro_avg: 0.689
09/16 12:12:29 PM: 	# validation passes without improvement: 0
09/16 12:12:29 PM: edges-rel-semeval_loss: training: 0.078925 validation: 0.079319
09/16 12:12:29 PM: macro_avg: validation: 0.688749
09/16 12:12:29 PM: micro_avg: validation: 0.000000
09/16 12:12:29 PM: edges-rel-semeval_mcc: training: 0.681185 validation: 0.691736
09/16 12:12:29 PM: edges-rel-semeval_acc: training: 0.538947 validation: 0.554395
09/16 12:12:29 PM: edges-rel-semeval_precision: training: 0.844289 validation: 0.869854
09/16 12:12:29 PM: edges-rel-semeval_recall: training: 0.571113 validation: 0.570061
09/16 12:12:29 PM: edges-rel-semeval_f1: training: 0.681339 validation: 0.688749
09/16 12:12:29 PM: Global learning rate: 0.0001
09/16 12:12:29 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:12:34 PM: Update 1172: task edges-rel-semeval, batch 72 (1172): mcc: 0.7038, acc: 0.5564, precision: 0.8589, recall: 0.5972, f1: 0.7046, edges-rel-semeval_loss: 0.0765
09/16 12:12:35 PM: ***** Step 1200 / Validation 12 *****
09/16 12:12:35 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:12:35 PM: Validating...
09/16 12:12:38 PM: Updating LR scheduler:
09/16 12:12:38 PM: 	Best result seen so far for macro_avg: 0.689
09/16 12:12:38 PM: 	# validation passes without improvement: 1
09/16 12:12:38 PM: edges-rel-semeval_loss: training: 0.076164 validation: 0.077408
09/16 12:12:38 PM: macro_avg: validation: 0.686933
09/16 12:12:38 PM: micro_avg: validation: 0.000000
09/16 12:12:38 PM: edges-rel-semeval_mcc: training: 0.708024 validation: 0.693072
09/16 12:12:38 PM: edges-rel-semeval_acc: training: 0.563750 validation: 0.550044
09/16 12:12:38 PM: edges-rel-semeval_precision: training: 0.863820 validation: 0.887052
09/16 12:12:38 PM: edges-rel-semeval_recall: training: 0.600625 validation: 0.560487
09/16 12:12:38 PM: edges-rel-semeval_f1: training: 0.708571 validation: 0.686933
09/16 12:12:38 PM: Global learning rate: 0.0001
09/16 12:12:38 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:12:44 PM: Update 1280: task edges-rel-semeval, batch 80 (1280): mcc: 0.7057, acc: 0.5656, precision: 0.8579, recall: 0.6012, f1: 0.7069, edges-rel-semeval_loss: 0.0747
09/16 12:12:46 PM: ***** Step 1300 / Validation 13 *****
09/16 12:12:46 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:12:46 PM: Validating...
09/16 12:12:49 PM: Best result seen so far for edges-rel-semeval.
09/16 12:12:51 PM: Best result seen so far for macro.
09/16 12:12:51 PM: Updating LR scheduler:
09/16 12:12:51 PM: 	Best result seen so far for macro_avg: 0.695
09/16 12:12:51 PM: 	# validation passes without improvement: 0
09/16 12:12:51 PM: edges-rel-semeval_loss: training: 0.073597 validation: 0.075719
09/16 12:12:51 PM: macro_avg: validation: 0.695109
09/16 12:12:51 PM: micro_avg: validation: 0.000000
09/16 12:12:51 PM: edges-rel-semeval_mcc: training: 0.709921 validation: 0.696314
09/16 12:12:51 PM: edges-rel-semeval_acc: training: 0.570482 validation: 0.557876
09/16 12:12:51 PM: edges-rel-semeval_precision: training: 0.858033 validation: 0.864166
09/16 12:12:51 PM: edges-rel-semeval_recall: training: 0.608010 validation: 0.581375
09/16 12:12:51 PM: edges-rel-semeval_f1: training: 0.711702 validation: 0.695109
09/16 12:12:51 PM: Global learning rate: 0.0001
09/16 12:12:51 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:12:54 PM: Update 1343: task edges-rel-semeval, batch 43 (1343): mcc: 0.7300, acc: 0.6054, precision: 0.8625, recall: 0.6381, f1: 0.7335, edges-rel-semeval_loss: 0.0710
09/16 12:12:59 PM: ***** Step 1400 / Validation 14 *****
09/16 12:12:59 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:13:00 PM: Validating...
09/16 12:13:03 PM: Updating LR scheduler:
09/16 12:13:03 PM: 	Best result seen so far for macro_avg: 0.695
09/16 12:13:03 PM: 	# validation passes without improvement: 1
09/16 12:13:03 PM: edges-rel-semeval_loss: training: 0.070506 validation: 0.075251
09/16 12:13:03 PM: macro_avg: validation: 0.692509
09/16 12:13:03 PM: micro_avg: validation: 0.000000
09/16 12:13:03 PM: edges-rel-semeval_mcc: training: 0.730557 validation: 0.694960
09/16 12:13:03 PM: edges-rel-semeval_acc: training: 0.599688 validation: 0.560487
09/16 12:13:03 PM: edges-rel-semeval_precision: training: 0.864407 validation: 0.869737
09/16 12:13:03 PM: edges-rel-semeval_recall: training: 0.637500 validation: 0.575283
09/16 12:13:03 PM: edges-rel-semeval_f1: training: 0.733813 validation: 0.692509
09/16 12:13:03 PM: Global learning rate: 0.0001
09/16 12:13:03 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:13:05 PM: Update 1434: task edges-rel-semeval, batch 34 (1434): mcc: 0.7450, acc: 0.6222, precision: 0.8833, recall: 0.6471, f1: 0.7469, edges-rel-semeval_loss: 0.0694
09/16 12:13:10 PM: ***** Step 1500 / Validation 15 *****
09/16 12:13:10 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:13:13 PM: Validating...
09/16 12:13:16 PM: Best result seen so far for edges-rel-semeval.
09/16 12:13:16 PM: Best result seen so far for macro.
09/16 12:13:16 PM: Updating LR scheduler:
09/16 12:13:16 PM: 	Best result seen so far for macro_avg: 0.699
09/16 12:13:16 PM: 	# validation passes without improvement: 0
09/16 12:13:16 PM: edges-rel-semeval_loss: training: 0.070310 validation: 0.073226
09/16 12:13:16 PM: macro_avg: validation: 0.699272
09/16 12:13:16 PM: micro_avg: validation: 0.000000
09/16 12:13:16 PM: edges-rel-semeval_mcc: training: 0.731738 validation: 0.700754
09/16 12:13:16 PM: edges-rel-semeval_acc: training: 0.605313 validation: 0.562228
09/16 12:13:16 PM: edges-rel-semeval_precision: training: 0.868601 validation: 0.869340
09/16 12:13:16 PM: edges-rel-semeval_recall: training: 0.636250 validation: 0.584856
09/16 12:13:16 PM: edges-rel-semeval_f1: training: 0.734488 validation: 0.699272
09/16 12:13:16 PM: Global learning rate: 0.0001
09/16 12:13:16 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:13:16 PM: Update 1504: task edges-rel-semeval, batch 4 (1504): mcc: 0.6727, acc: 0.5156, precision: 0.8372, recall: 0.5625, f1: 0.6729, edges-rel-semeval_loss: 0.0754
09/16 12:13:24 PM: ***** Step 1600 / Validation 16 *****
09/16 12:13:24 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:13:24 PM: Validating...
09/16 12:13:26 PM: Evaluate: task edges-rel-semeval, batch 30 (36): mcc: 0.7345, acc: 0.6010, precision: 0.9011, recall: 0.6167, f1: 0.7322, edges-rel-semeval_loss: 0.0694
09/16 12:13:27 PM: Best result seen so far for edges-rel-semeval.
09/16 12:13:27 PM: Best result seen so far for macro.
09/16 12:13:27 PM: Updating LR scheduler:
09/16 12:13:27 PM: 	Best result seen so far for macro_avg: 0.708
09/16 12:13:27 PM: 	# validation passes without improvement: 0
09/16 12:13:27 PM: edges-rel-semeval_loss: training: 0.064849 validation: 0.073283
09/16 12:13:27 PM: macro_avg: validation: 0.708159
09/16 12:13:27 PM: micro_avg: validation: 0.000000
09/16 12:13:27 PM: edges-rel-semeval_mcc: training: 0.754149 validation: 0.711337
09/16 12:13:27 PM: edges-rel-semeval_acc: training: 0.628508 validation: 0.572672
09/16 12:13:27 PM: edges-rel-semeval_precision: training: 0.879217 validation: 0.887287
09/16 12:13:27 PM: edges-rel-semeval_recall: training: 0.665721 validation: 0.589208
09/16 12:13:27 PM: edges-rel-semeval_f1: training: 0.757717 validation: 0.708159
09/16 12:13:27 PM: Global learning rate: 0.0001
09/16 12:13:27 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:13:33 PM: ***** Step 1700 / Validation 17 *****
09/16 12:13:33 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:13:33 PM: Validating...
09/16 12:13:36 PM: Best result seen so far for edges-rel-semeval.
09/16 12:13:36 PM: Best result seen so far for macro.
09/16 12:13:36 PM: Updating LR scheduler:
09/16 12:13:36 PM: 	Best result seen so far for macro_avg: 0.712
09/16 12:13:36 PM: 	# validation passes without improvement: 0
09/16 12:13:36 PM: edges-rel-semeval_loss: training: 0.066587 validation: 0.072280
09/16 12:13:36 PM: macro_avg: validation: 0.711744
09/16 12:13:36 PM: micro_avg: validation: 0.000000
09/16 12:13:36 PM: edges-rel-semeval_mcc: training: 0.747543 validation: 0.709622
09/16 12:13:36 PM: edges-rel-semeval_acc: training: 0.620625 validation: 0.580505
09/16 12:13:36 PM: edges-rel-semeval_precision: training: 0.867948 validation: 0.855746
09/16 12:13:36 PM: edges-rel-semeval_recall: training: 0.663437 validation: 0.609225
09/16 12:13:36 PM: edges-rel-semeval_f1: training: 0.752037 validation: 0.711744
09/16 12:13:36 PM: Global learning rate: 0.0001
09/16 12:13:36 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:13:36 PM: Update 1705: task edges-rel-semeval, batch 5 (1705): mcc: 0.7859, acc: 0.6813, precision: 0.8667, recall: 0.7312, f1: 0.7932, edges-rel-semeval_loss: 0.0609
09/16 12:13:43 PM: ***** Step 1800 / Validation 18 *****
09/16 12:13:43 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:13:43 PM: Validating...
09/16 12:13:46 PM: Evaluate: task edges-rel-semeval, batch 35 (36): mcc: 0.7099, acc: 0.5839, precision: 0.8615, recall: 0.6054, f1: 0.7111, edges-rel-semeval_loss: 0.0712
09/16 12:13:47 PM: Updating LR scheduler:
09/16 12:13:47 PM: 	Best result seen so far for macro_avg: 0.712
09/16 12:13:47 PM: 	# validation passes without improvement: 1
09/16 12:13:47 PM: edges-rel-semeval_loss: training: 0.062704 validation: 0.072567
09/16 12:13:47 PM: macro_avg: validation: 0.705339
09/16 12:13:47 PM: micro_avg: validation: 0.000000
09/16 12:13:47 PM: edges-rel-semeval_mcc: training: 0.755932 validation: 0.704576
09/16 12:13:47 PM: edges-rel-semeval_acc: training: 0.631977 validation: 0.577023
09/16 12:13:47 PM: edges-rel-semeval_precision: training: 0.864583 validation: 0.859825
09/16 12:13:47 PM: edges-rel-semeval_recall: training: 0.680542 validation: 0.597911
09/16 12:13:47 PM: edges-rel-semeval_f1: training: 0.761602 validation: 0.705339
09/16 12:13:47 PM: Global learning rate: 0.0001
09/16 12:13:47 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:13:53 PM: ***** Step 1900 / Validation 19 *****
09/16 12:13:53 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:13:53 PM: Validating...
09/16 12:13:56 PM: Best result seen so far for edges-rel-semeval.
09/16 12:13:57 PM: Best result seen so far for macro.
09/16 12:13:57 PM: Updating LR scheduler:
09/16 12:13:57 PM: 	Best result seen so far for macro_avg: 0.714
09/16 12:13:57 PM: 	# validation passes without improvement: 0
09/16 12:13:57 PM: edges-rel-semeval_loss: training: 0.062090 validation: 0.071240
09/16 12:13:57 PM: macro_avg: validation: 0.714286
09/16 12:13:57 PM: micro_avg: validation: 0.000000
09/16 12:13:57 PM: edges-rel-semeval_mcc: training: 0.759767 validation: 0.714291
09/16 12:13:57 PM: edges-rel-semeval_acc: training: 0.642500 validation: 0.586597
09/16 12:13:57 PM: edges-rel-semeval_precision: training: 0.863815 validation: 0.872020
09/16 12:13:57 PM: edges-rel-semeval_recall: training: 0.687813 validation: 0.604874
09/16 12:13:57 PM: edges-rel-semeval_f1: training: 0.765832 validation: 0.714286
09/16 12:13:57 PM: Global learning rate: 0.0001
09/16 12:13:57 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:13:57 PM: Update 1901: task edges-rel-semeval, batch 1 (1901): mcc: 0.7037, acc: 0.5625, precision: 0.8636, recall: 0.5938, f1: 0.7037, edges-rel-semeval_loss: 0.0736
09/16 12:14:05 PM: ***** Step 2000 / Validation 20 *****
09/16 12:14:05 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:14:05 PM: Validating...
09/16 12:14:07 PM: Evaluate: task edges-rel-semeval, batch 28 (36): mcc: 0.7386, acc: 0.6183, precision: 0.8912, recall: 0.6306, f1: 0.7386, edges-rel-semeval_loss: 0.0683
09/16 12:14:09 PM: Best result seen so far for edges-rel-semeval.
09/16 12:14:09 PM: Best result seen so far for macro.
09/16 12:14:09 PM: Updating LR scheduler:
09/16 12:14:09 PM: 	Best result seen so far for macro_avg: 0.718
09/16 12:14:09 PM: 	# validation passes without improvement: 0
09/16 12:14:09 PM: edges-rel-semeval_loss: training: 0.059433 validation: 0.071142
09/16 12:14:09 PM: macro_avg: validation: 0.718477
09/16 12:14:09 PM: micro_avg: validation: 0.000000
09/16 12:14:09 PM: edges-rel-semeval_mcc: training: 0.773087 validation: 0.719049
09/16 12:14:09 PM: edges-rel-semeval_acc: training: 0.657837 validation: 0.591819
09/16 12:14:09 PM: edges-rel-semeval_precision: training: 0.878020 validation: 0.879093
09/16 12:14:09 PM: edges-rel-semeval_recall: training: 0.699149 validation: 0.607485
09/16 12:14:09 PM: edges-rel-semeval_f1: training: 0.778441 validation: 0.718477
09/16 12:14:09 PM: Global learning rate: 0.0001
09/16 12:14:09 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:14:15 PM: ***** Step 2100 / Validation 21 *****
09/16 12:14:17 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:14:17 PM: Validating...
09/16 12:14:18 PM: Evaluate: task edges-rel-semeval, batch 16 (36): mcc: 0.7414, acc: 0.6289, precision: 0.8638, recall: 0.6562, f1: 0.7458, edges-rel-semeval_loss: 0.0662
09/16 12:14:20 PM: Best result seen so far for edges-rel-semeval.
09/16 12:14:20 PM: Best result seen so far for macro.
09/16 12:14:20 PM: Updating LR scheduler:
09/16 12:14:20 PM: 	Best result seen so far for macro_avg: 0.725
09/16 12:14:20 PM: 	# validation passes without improvement: 0
09/16 12:14:20 PM: edges-rel-semeval_loss: training: 0.059049 validation: 0.069724
09/16 12:14:20 PM: macro_avg: validation: 0.724812
09/16 12:14:20 PM: micro_avg: validation: 0.000000
09/16 12:14:20 PM: edges-rel-semeval_mcc: training: 0.775349 validation: 0.721125
09/16 12:14:20 PM: edges-rel-semeval_acc: training: 0.659375 validation: 0.604003
09/16 12:14:20 PM: edges-rel-semeval_precision: training: 0.877583 validation: 0.854610
09/16 12:14:20 PM: edges-rel-semeval_recall: training: 0.703438 validation: 0.629243
09/16 12:14:20 PM: edges-rel-semeval_f1: training: 0.780919 validation: 0.724812
09/16 12:14:20 PM: Global learning rate: 0.0001
09/16 12:14:20 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:14:27 PM: ***** Step 2200 / Validation 22 *****
09/16 12:14:27 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:14:27 PM: Validating...
09/16 12:14:28 PM: Evaluate: task edges-rel-semeval, batch 17 (36): mcc: 0.7483, acc: 0.6397, precision: 0.8717, recall: 0.6618, f1: 0.7524, edges-rel-semeval_loss: 0.0644
09/16 12:14:30 PM: Best result seen so far for edges-rel-semeval.
09/16 12:14:30 PM: Best result seen so far for macro.
09/16 12:14:30 PM: Updating LR scheduler:
09/16 12:14:30 PM: 	Best result seen so far for macro_avg: 0.727
09/16 12:14:30 PM: 	# validation passes without improvement: 0
09/16 12:14:30 PM: edges-rel-semeval_loss: training: 0.059128 validation: 0.068955
09/16 12:14:30 PM: macro_avg: validation: 0.727364
09/16 12:14:30 PM: micro_avg: validation: 0.000000
09/16 12:14:30 PM: edges-rel-semeval_mcc: training: 0.773114 validation: 0.724400
09/16 12:14:30 PM: edges-rel-semeval_acc: training: 0.654368 validation: 0.608355
09/16 12:14:30 PM: edges-rel-semeval_precision: training: 0.870140 validation: 0.861740
09/16 12:14:30 PM: edges-rel-semeval_recall: training: 0.705771 validation: 0.629243
09/16 12:14:30 PM: edges-rel-semeval_f1: training: 0.779384 validation: 0.727364
09/16 12:14:30 PM: Global learning rate: 0.0001
09/16 12:14:30 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:14:36 PM: ***** Step 2300 / Validation 23 *****
09/16 12:14:36 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:14:36 PM: Validating...
09/16 12:14:38 PM: Evaluate: task edges-rel-semeval, batch 26 (36): mcc: 0.7359, acc: 0.6178, precision: 0.8736, recall: 0.6394, f1: 0.7384, edges-rel-semeval_loss: 0.0663
09/16 12:14:39 PM: Updating LR scheduler:
09/16 12:14:39 PM: 	Best result seen so far for macro_avg: 0.727
09/16 12:14:39 PM: 	# validation passes without improvement: 1
09/16 12:14:39 PM: edges-rel-semeval_loss: training: 0.058491 validation: 0.070004
09/16 12:14:39 PM: macro_avg: validation: 0.714868
09/16 12:14:39 PM: micro_avg: validation: 0.000000
09/16 12:14:39 PM: edges-rel-semeval_mcc: training: 0.782454 validation: 0.713211
09/16 12:14:39 PM: edges-rel-semeval_acc: training: 0.668438 validation: 0.589208
09/16 12:14:39 PM: edges-rel-semeval_precision: training: 0.878939 validation: 0.861350
09/16 12:14:39 PM: edges-rel-semeval_recall: training: 0.714688 validation: 0.610966
09/16 12:14:39 PM: edges-rel-semeval_f1: training: 0.788349 validation: 0.714868
09/16 12:14:39 PM: Global learning rate: 0.0001
09/16 12:14:39 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:14:47 PM: ***** Step 2400 / Validation 24 *****
09/16 12:14:47 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:14:47 PM: Validating...
09/16 12:14:48 PM: Evaluate: task edges-rel-semeval, batch 18 (36): mcc: 0.7510, acc: 0.6337, precision: 0.8779, recall: 0.6615, f1: 0.7545, edges-rel-semeval_loss: 0.0641
09/16 12:14:50 PM: Updating LR scheduler:
09/16 12:14:50 PM: 	Best result seen so far for macro_avg: 0.727
09/16 12:14:50 PM: 	# validation passes without improvement: 2
09/16 12:14:50 PM: edges-rel-semeval_loss: training: 0.054422 validation: 0.069493
09/16 12:14:50 PM: macro_avg: validation: 0.721691
09/16 12:14:50 PM: micro_avg: validation: 0.000000
09/16 12:14:50 PM: edges-rel-semeval_mcc: training: 0.792662 validation: 0.718464
09/16 12:14:50 PM: edges-rel-semeval_acc: training: 0.678020 validation: 0.599652
09/16 12:14:50 PM: edges-rel-semeval_precision: training: 0.878639 validation: 0.855609
09/16 12:14:50 PM: edges-rel-semeval_recall: training: 0.732892 validation: 0.624021
09/16 12:14:50 PM: edges-rel-semeval_f1: training: 0.799175 validation: 0.721691
09/16 12:14:50 PM: Global learning rate: 0.0001
09/16 12:14:50 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:14:56 PM: ***** Step 2500 / Validation 25 *****
09/16 12:14:56 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:14:56 PM: Validating...
09/16 12:14:58 PM: Evaluate: task edges-rel-semeval, batch 24 (36): mcc: 0.7528, acc: 0.6432, precision: 0.8752, recall: 0.6667, f1: 0.7568, edges-rel-semeval_loss: 0.0648
09/16 12:15:01 PM: Best result seen so far for edges-rel-semeval.
09/16 12:15:01 PM: Best result seen so far for macro.
09/16 12:15:01 PM: Updating LR scheduler:
09/16 12:15:01 PM: 	Best result seen so far for macro_avg: 0.737
09/16 12:15:01 PM: 	# validation passes without improvement: 0
09/16 12:15:01 PM: edges-rel-semeval_loss: training: 0.054709 validation: 0.068641
09/16 12:15:01 PM: macro_avg: validation: 0.737469
09/16 12:15:01 PM: micro_avg: validation: 0.000000
09/16 12:15:01 PM: edges-rel-semeval_mcc: training: 0.791500 validation: 0.733003
09/16 12:15:01 PM: edges-rel-semeval_acc: training: 0.680312 validation: 0.618799
09/16 12:15:01 PM: edges-rel-semeval_precision: training: 0.880710 validation: 0.857968
09/16 12:15:01 PM: edges-rel-semeval_recall: training: 0.729062 validation: 0.646649
09/16 12:15:01 PM: edges-rel-semeval_f1: training: 0.797743 validation: 0.737469
09/16 12:15:01 PM: Global learning rate: 0.0001
09/16 12:15:01 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:15:07 PM: ***** Step 2600 / Validation 26 *****
09/16 12:15:07 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:15:07 PM: Validating...
09/16 12:15:10 PM: Evaluate: task edges-rel-semeval, batch 25 (36): mcc: 0.7464, acc: 0.6375, precision: 0.8636, recall: 0.6650, f1: 0.7514, edges-rel-semeval_loss: 0.0651
09/16 12:15:11 PM: Updating LR scheduler:
09/16 12:15:11 PM: 	Best result seen so far for macro_avg: 0.737
09/16 12:15:11 PM: 	# validation passes without improvement: 1
09/16 12:15:11 PM: edges-rel-semeval_loss: training: 0.056161 validation: 0.069572
09/16 12:15:11 PM: macro_avg: validation: 0.727363
09/16 12:15:11 PM: micro_avg: validation: 0.000000
09/16 12:15:11 PM: edges-rel-semeval_mcc: training: 0.784674 validation: 0.721871
09/16 12:15:11 PM: edges-rel-semeval_acc: training: 0.674235 validation: 0.607485
09/16 12:15:11 PM: edges-rel-semeval_precision: training: 0.874714 validation: 0.842890
09/16 12:15:11 PM: edges-rel-semeval_recall: training: 0.722170 validation: 0.639687
09/16 12:15:11 PM: edges-rel-semeval_f1: training: 0.791156 validation: 0.727363
09/16 12:15:11 PM: Global learning rate: 0.0001
09/16 12:15:11 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:15:18 PM: ***** Step 2700 / Validation 27 *****
09/16 12:15:18 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:15:18 PM: Validating...
09/16 12:15:20 PM: Evaluate: task edges-rel-semeval, batch 29 (36): mcc: 0.7487, acc: 0.6379, precision: 0.8701, recall: 0.6638, f1: 0.7531, edges-rel-semeval_loss: 0.0652
09/16 12:15:21 PM: Updating LR scheduler:
09/16 12:15:21 PM: 	Best result seen so far for macro_avg: 0.737
09/16 12:15:21 PM: 	# validation passes without improvement: 2
09/16 12:15:21 PM: edges-rel-semeval_loss: training: 0.050641 validation: 0.068959
09/16 12:15:21 PM: macro_avg: validation: 0.725549
09/16 12:15:21 PM: micro_avg: validation: 0.000000
09/16 12:15:21 PM: edges-rel-semeval_mcc: training: 0.808184 validation: 0.721203
09/16 12:15:21 PM: edges-rel-semeval_acc: training: 0.706250 validation: 0.602263
09/16 12:15:21 PM: edges-rel-semeval_precision: training: 0.888479 validation: 0.850292
09/16 12:15:21 PM: edges-rel-semeval_recall: training: 0.751875 validation: 0.632724
09/16 12:15:21 PM: edges-rel-semeval_f1: training: 0.814489 validation: 0.725549
09/16 12:15:21 PM: Global learning rate: 0.0001
09/16 12:15:21 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:15:29 PM: ***** Step 2800 / Validation 28 *****
09/16 12:15:29 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:15:29 PM: Validating...
09/16 12:15:30 PM: Evaluate: task edges-rel-semeval, batch 21 (36): mcc: 0.7506, acc: 0.6414, precision: 0.8612, recall: 0.6741, f1: 0.7563, edges-rel-semeval_loss: 0.0639
09/16 12:15:32 PM: Updating LR scheduler:
09/16 12:15:32 PM: 	Best result seen so far for macro_avg: 0.737
09/16 12:15:32 PM: 	# validation passes without improvement: 3
09/16 12:15:32 PM: edges-rel-semeval_loss: training: 0.053764 validation: 0.068768
09/16 12:15:32 PM: macro_avg: validation: 0.730562
09/16 12:15:32 PM: micro_avg: validation: 0.000000
09/16 12:15:32 PM: edges-rel-semeval_mcc: training: 0.792183 validation: 0.723647
09/16 12:15:32 PM: edges-rel-semeval_acc: training: 0.680227 validation: 0.608355
09/16 12:15:32 PM: edges-rel-semeval_precision: training: 0.879121 validation: 0.833705
09/16 12:15:32 PM: edges-rel-semeval_recall: training: 0.731630 validation: 0.650131
09/16 12:15:32 PM: edges-rel-semeval_f1: training: 0.798623 validation: 0.730562
09/16 12:15:32 PM: Global learning rate: 0.0001
09/16 12:15:32 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:15:38 PM: ***** Step 2900 / Validation 29 *****
09/16 12:15:38 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:15:38 PM: Validating...
09/16 12:15:40 PM: Evaluate: task edges-rel-semeval, batch 24 (36): mcc: 0.7429, acc: 0.6302, precision: 0.8622, recall: 0.6602, f1: 0.7478, edges-rel-semeval_loss: 0.0637
09/16 12:15:41 PM: Updating LR scheduler:
09/16 12:15:42 PM: 	Best result seen so far for macro_avg: 0.737
09/16 12:15:42 PM: 	# validation passes without improvement: 0
09/16 12:15:42 PM: edges-rel-semeval_loss: training: 0.049614 validation: 0.068685
09/16 12:15:42 PM: macro_avg: validation: 0.727003
09/16 12:15:42 PM: micro_avg: validation: 0.000000
09/16 12:15:42 PM: edges-rel-semeval_mcc: training: 0.820472 validation: 0.721419
09/16 12:15:42 PM: edges-rel-semeval_acc: training: 0.716250 validation: 0.604874
09/16 12:15:42 PM: edges-rel-semeval_precision: training: 0.895985 validation: 0.841924
09/16 12:15:42 PM: edges-rel-semeval_recall: training: 0.767187 validation: 0.639687
09/16 12:15:42 PM: edges-rel-semeval_f1: training: 0.826599 validation: 0.727003
09/16 12:15:42 PM: Global learning rate: 5e-05
09/16 12:15:42 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:15:49 PM: ***** Step 3000 / Validation 30 *****
09/16 12:15:49 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:15:49 PM: Validating...
09/16 12:15:51 PM: Evaluate: task edges-rel-semeval, batch 21 (36): mcc: 0.7543, acc: 0.6429, precision: 0.8784, recall: 0.6667, f1: 0.7580, edges-rel-semeval_loss: 0.0625
09/16 12:15:52 PM: Updating LR scheduler:
09/16 12:15:53 PM: 	Best result seen so far for macro_avg: 0.737
09/16 12:15:53 PM: 	# validation passes without improvement: 1
09/16 12:15:53 PM: edges-rel-semeval_loss: training: 0.051891 validation: 0.068048
09/16 12:15:53 PM: macro_avg: validation: 0.729716
09/16 12:15:53 PM: micro_avg: validation: 0.000000
09/16 12:15:53 PM: edges-rel-semeval_mcc: training: 0.803703 validation: 0.725238
09/16 12:15:53 PM: edges-rel-semeval_acc: training: 0.695937 validation: 0.605744
09/16 12:15:53 PM: edges-rel-semeval_precision: training: 0.884004 validation: 0.852326
09/16 12:15:53 PM: edges-rel-semeval_recall: training: 0.747813 validation: 0.637946
09/16 12:15:53 PM: edges-rel-semeval_f1: training: 0.810225 validation: 0.729716
09/16 12:15:53 PM: Global learning rate: 5e-05
09/16 12:15:53 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:16:01 PM: Update 3099: task edges-rel-semeval, batch 99 (3099): mcc: 0.8089, acc: 0.7040, precision: 0.8843, recall: 0.7569, f1: 0.8157, edges-rel-semeval_loss: 0.0484
09/16 12:16:01 PM: ***** Step 3100 / Validation 31 *****
09/16 12:16:01 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:16:01 PM: Validating...
09/16 12:16:04 PM: Best result seen so far for edges-rel-semeval.
09/16 12:16:04 PM: Best result seen so far for macro.
09/16 12:16:04 PM: Updating LR scheduler:
09/16 12:16:04 PM: 	Best result seen so far for macro_avg: 0.739
09/16 12:16:04 PM: 	# validation passes without improvement: 0
09/16 12:16:04 PM: edges-rel-semeval_loss: training: 0.048358 validation: 0.067944
09/16 12:16:04 PM: macro_avg: validation: 0.738581
09/16 12:16:04 PM: micro_avg: validation: 0.000000
09/16 12:16:04 PM: edges-rel-semeval_mcc: training: 0.809196 validation: 0.731324
09/16 12:16:04 PM: edges-rel-semeval_acc: training: 0.704510 validation: 0.618799
09/16 12:16:04 PM: edges-rel-semeval_precision: training: 0.883781 validation: 0.836084
09/16 12:16:04 PM: edges-rel-semeval_recall: training: 0.757805 validation: 0.661445
09/16 12:16:04 PM: edges-rel-semeval_f1: training: 0.815959 validation: 0.738581
09/16 12:16:04 PM: Global learning rate: 5e-05
09/16 12:16:04 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:16:11 PM: Update 3198: task edges-rel-semeval, batch 98 (3198): mcc: 0.8249, acc: 0.7274, precision: 0.9003, recall: 0.7714, f1: 0.8308, edges-rel-semeval_loss: 0.0487
09/16 12:16:11 PM: ***** Step 3200 / Validation 32 *****
09/16 12:16:11 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:16:11 PM: Validating...
09/16 12:16:16 PM: Updating LR scheduler:
09/16 12:16:16 PM: 	Best result seen so far for macro_avg: 0.739
09/16 12:16:16 PM: 	# validation passes without improvement: 1
09/16 12:16:16 PM: edges-rel-semeval_loss: training: 0.048833 validation: 0.067968
09/16 12:16:16 PM: macro_avg: validation: 0.733792
09/16 12:16:16 PM: micro_avg: validation: 0.000000
09/16 12:16:16 PM: edges-rel-semeval_mcc: training: 0.823120 validation: 0.727645
09/16 12:16:16 PM: edges-rel-semeval_acc: training: 0.725000 validation: 0.612707
09/16 12:16:16 PM: edges-rel-semeval_precision: training: 0.898868 validation: 0.842165
09/16 12:16:16 PM: edges-rel-semeval_recall: training: 0.769375 validation: 0.650131
09/16 12:16:16 PM: edges-rel-semeval_f1: training: 0.829096 validation: 0.733792
09/16 12:16:16 PM: Global learning rate: 5e-05
09/16 12:16:16 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:16:21 PM: Update 3235: task edges-rel-semeval, batch 35 (3235): mcc: 0.8177, acc: 0.7204, precision: 0.8904, recall: 0.7672, f1: 0.8242, edges-rel-semeval_loss: 0.0476
09/16 12:16:28 PM: ***** Step 3300 / Validation 33 *****
09/16 12:16:28 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:16:28 PM: Validating...
09/16 12:16:31 PM: Evaluate: task edges-rel-semeval, batch 27 (36): mcc: 0.7574, acc: 0.6574, precision: 0.8511, recall: 0.6944, f1: 0.7648, edges-rel-semeval_loss: 0.0631
09/16 12:16:32 PM: Best result seen so far for edges-rel-semeval.
09/16 12:16:32 PM: Best result seen so far for macro.
09/16 12:16:32 PM: Updating LR scheduler:
09/16 12:16:32 PM: 	Best result seen so far for macro_avg: 0.741
09/16 12:16:32 PM: 	# validation passes without improvement: 0
09/16 12:16:32 PM: edges-rel-semeval_loss: training: 0.046990 validation: 0.067145
09/16 12:16:32 PM: macro_avg: validation: 0.741279
09/16 12:16:32 PM: micro_avg: validation: 0.000000
09/16 12:16:32 PM: edges-rel-semeval_mcc: training: 0.827828 validation: 0.733822
09/16 12:16:32 PM: edges-rel-semeval_acc: training: 0.727215 validation: 0.624891
09/16 12:16:32 PM: edges-rel-semeval_precision: training: 0.897240 validation: 0.836066
09/16 12:16:32 PM: edges-rel-semeval_recall: training: 0.779249 validation: 0.665796
09/16 12:16:32 PM: edges-rel-semeval_f1: training: 0.834093 validation: 0.741279
09/16 12:16:32 PM: Global learning rate: 5e-05
09/16 12:16:32 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:16:41 PM: Update 3373: task edges-rel-semeval, batch 73 (3373): mcc: 0.8273, acc: 0.7226, precision: 0.9001, recall: 0.7757, f1: 0.8333, edges-rel-semeval_loss: 0.0466
09/16 12:16:43 PM: ***** Step 3400 / Validation 34 *****
09/16 12:16:43 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:16:43 PM: Validating...
09/16 12:16:47 PM: Updating LR scheduler:
09/16 12:16:47 PM: 	Best result seen so far for macro_avg: 0.741
09/16 12:16:47 PM: 	# validation passes without improvement: 1
09/16 12:16:47 PM: edges-rel-semeval_loss: training: 0.047371 validation: 0.068925
09/16 12:16:47 PM: macro_avg: validation: 0.732839
09/16 12:16:47 PM: micro_avg: validation: 0.000000
09/16 12:16:47 PM: edges-rel-semeval_mcc: training: 0.823150 validation: 0.727386
09/16 12:16:47 PM: edges-rel-semeval_acc: training: 0.718750 validation: 0.613577
09/16 12:16:47 PM: edges-rel-semeval_precision: training: 0.895042 validation: 0.847032
09/16 12:16:47 PM: edges-rel-semeval_recall: training: 0.772812 validation: 0.645779
09/16 12:16:47 PM: edges-rel-semeval_f1: training: 0.829448 validation: 0.732839
09/16 12:16:47 PM: Global learning rate: 5e-05
09/16 12:16:48 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:16:51 PM: Update 3432: task edges-rel-semeval, batch 32 (3432): mcc: 0.8176, acc: 0.7168, precision: 0.8865, recall: 0.7705, f1: 0.8245, edges-rel-semeval_loss: 0.0490
09/16 12:17:00 PM: ***** Step 3500 / Validation 35 *****
09/16 12:17:00 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:17:00 PM: Validating...
09/16 12:17:01 PM: Evaluate: task edges-rel-semeval, batch 10 (36): mcc: 0.7693, acc: 0.6656, precision: 0.8654, recall: 0.7031, f1: 0.7759, edges-rel-semeval_loss: 0.0638
09/16 12:17:04 PM: Best result seen so far for edges-rel-semeval.
09/16 12:17:04 PM: Best result seen so far for macro.
09/16 12:17:04 PM: Updating LR scheduler:
09/16 12:17:04 PM: 	Best result seen so far for macro_avg: 0.745
09/16 12:17:04 PM: 	# validation passes without improvement: 0
09/16 12:17:04 PM: edges-rel-semeval_loss: training: 0.046643 validation: 0.068021
09/16 12:17:04 PM: macro_avg: validation: 0.744639
09/16 12:17:04 PM: micro_avg: validation: 0.000000
09/16 12:17:04 PM: edges-rel-semeval_mcc: training: 0.827652 validation: 0.738091
09/16 12:17:04 PM: edges-rel-semeval_acc: training: 0.727531 validation: 0.629243
09/16 12:17:04 PM: edges-rel-semeval_precision: training: 0.902574 validation: 0.846069
09/16 12:17:04 PM: edges-rel-semeval_recall: training: 0.774204 validation: 0.664926
09/16 12:17:04 PM: edges-rel-semeval_f1: training: 0.833475 validation: 0.744639
09/16 12:17:04 PM: Global learning rate: 5e-05
09/16 12:17:04 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:17:11 PM: Update 3565: task edges-rel-semeval, batch 65 (3565): mcc: 0.8283, acc: 0.7274, precision: 0.8976, recall: 0.7798, f1: 0.8346, edges-rel-semeval_loss: 0.0464
09/16 12:17:15 PM: ***** Step 3600 / Validation 36 *****
09/16 12:17:15 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:17:15 PM: Validating...
09/16 12:17:19 PM: Updating LR scheduler:
09/16 12:17:19 PM: 	Best result seen so far for macro_avg: 0.745
09/16 12:17:19 PM: 	# validation passes without improvement: 1
09/16 12:17:19 PM: edges-rel-semeval_loss: training: 0.047574 validation: 0.068314
09/16 12:17:19 PM: macro_avg: validation: 0.737624
09/16 12:17:19 PM: micro_avg: validation: 0.000000
09/16 12:17:19 PM: edges-rel-semeval_mcc: training: 0.821162 validation: 0.732804
09/16 12:17:19 PM: edges-rel-semeval_acc: training: 0.717187 validation: 0.613577
09/16 12:17:19 PM: edges-rel-semeval_precision: training: 0.891736 validation: 0.855339
09/16 12:17:19 PM: edges-rel-semeval_recall: training: 0.772187 validation: 0.648390
09/16 12:17:19 PM: edges-rel-semeval_f1: training: 0.827667 validation: 0.737624
09/16 12:17:19 PM: Global learning rate: 5e-05
09/16 12:17:19 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:17:22 PM: Update 3633: task edges-rel-semeval, batch 33 (3633): mcc: 0.8297, acc: 0.7235, precision: 0.9096, recall: 0.7718, f1: 0.8350, edges-rel-semeval_loss: 0.0445
09/16 12:17:29 PM: ***** Step 3700 / Validation 37 *****
09/16 12:17:29 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:17:29 PM: Validating...
09/16 12:17:32 PM: Evaluate: task edges-rel-semeval, batch 25 (36): mcc: 0.7589, acc: 0.6500, precision: 0.8730, recall: 0.6787, f1: 0.7637, edges-rel-semeval_loss: 0.0638
09/16 12:17:33 PM: Updating LR scheduler:
09/16 12:17:33 PM: 	Best result seen so far for macro_avg: 0.745
09/16 12:17:33 PM: 	# validation passes without improvement: 2
09/16 12:17:33 PM: edges-rel-semeval_loss: training: 0.045546 validation: 0.068419
09/16 12:17:33 PM: macro_avg: validation: 0.738659
09/16 12:17:33 PM: micro_avg: validation: 0.000000
09/16 12:17:33 PM: edges-rel-semeval_mcc: training: 0.827342 validation: 0.733336
09/16 12:17:33 PM: edges-rel-semeval_acc: training: 0.725323 validation: 0.619669
09/16 12:17:33 PM: edges-rel-semeval_precision: training: 0.896264 validation: 0.852105
09/16 12:17:33 PM: edges-rel-semeval_recall: training: 0.779249 validation: 0.651871
09/16 12:17:33 PM: edges-rel-semeval_f1: training: 0.833671 validation: 0.738659
09/16 12:17:33 PM: Global learning rate: 5e-05
09/16 12:17:33 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:17:42 PM: Update 3784: task edges-rel-semeval, batch 84 (3784): mcc: 0.8342, acc: 0.7381, precision: 0.9015, recall: 0.7868, f1: 0.8403, edges-rel-semeval_loss: 0.0454
09/16 12:17:43 PM: ***** Step 3800 / Validation 38 *****
09/16 12:17:46 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:17:46 PM: Validating...
09/16 12:17:50 PM: Updating LR scheduler:
09/16 12:17:51 PM: 	Best result seen so far for macro_avg: 0.745
09/16 12:17:51 PM: 	# validation passes without improvement: 3
09/16 12:17:51 PM: edges-rel-semeval_loss: training: 0.045213 validation: 0.068470
09/16 12:17:51 PM: macro_avg: validation: 0.737893
09/16 12:17:51 PM: micro_avg: validation: 0.000000
09/16 12:17:51 PM: edges-rel-semeval_mcc: training: 0.834236 validation: 0.734360
09/16 12:17:51 PM: edges-rel-semeval_acc: training: 0.736875 validation: 0.618799
09/16 12:17:51 PM: edges-rel-semeval_precision: training: 0.901252 validation: 0.865340
09/16 12:17:51 PM: edges-rel-semeval_recall: training: 0.787188 validation: 0.643168
09/16 12:17:51 PM: edges-rel-semeval_f1: training: 0.840367 validation: 0.737893
09/16 12:17:51 PM: Global learning rate: 5e-05
09/16 12:17:51 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:17:52 PM: Update 3811: task edges-rel-semeval, batch 11 (3811): mcc: 0.8174, acc: 0.7244, precision: 0.8963, recall: 0.7614, f1: 0.8233, edges-rel-semeval_loss: 0.0452
09/16 12:18:02 PM: Update 3893: task edges-rel-semeval, batch 93 (3893): mcc: 0.8289, acc: 0.7309, precision: 0.9019, recall: 0.7771, f1: 0.8349, edges-rel-semeval_loss: 0.0447
09/16 12:18:03 PM: ***** Step 3900 / Validation 39 *****
09/16 12:18:03 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:18:03 PM: Validating...
09/16 12:18:06 PM: Best result seen so far for edges-rel-semeval.
09/16 12:18:06 PM: Best result seen so far for macro.
09/16 12:18:06 PM: Updating LR scheduler:
09/16 12:18:06 PM: 	Best result seen so far for macro_avg: 0.746
09/16 12:18:06 PM: 	# validation passes without improvement: 0
09/16 12:18:06 PM: edges-rel-semeval_loss: training: 0.044620 validation: 0.067893
09/16 12:18:06 PM: macro_avg: validation: 0.745946
09/16 12:18:06 PM: micro_avg: validation: 0.000000
09/16 12:18:06 PM: edges-rel-semeval_mcc: training: 0.829592 validation: 0.740568
09/16 12:18:06 PM: edges-rel-semeval_acc: training: 0.731946 validation: 0.624021
09/16 12:18:06 PM: edges-rel-semeval_precision: training: 0.902930 validation: 0.856659
09/16 12:18:06 PM: edges-rel-semeval_recall: training: 0.777357 validation: 0.660574
09/16 12:18:06 PM: edges-rel-semeval_f1: training: 0.835452 validation: 0.745946
09/16 12:18:06 PM: Global learning rate: 5e-05
09/16 12:18:06 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:18:12 PM: Update 3945: task edges-rel-semeval, batch 45 (3945): mcc: 0.8446, acc: 0.7514, precision: 0.9033, recall: 0.8042, f1: 0.8508, edges-rel-semeval_loss: 0.0441
09/16 12:18:17 PM: ***** Step 4000 / Validation 40 *****
09/16 12:18:19 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:18:19 PM: Validating...
09/16 12:18:22 PM: Evaluate: task edges-rel-semeval, batch 23 (36): mcc: 0.7564, acc: 0.6413, precision: 0.8788, recall: 0.6698, f1: 0.7602, edges-rel-semeval_loss: 0.0636
09/16 12:18:23 PM: Updating LR scheduler:
09/16 12:18:23 PM: 	Best result seen so far for macro_avg: 0.746
09/16 12:18:23 PM: 	# validation passes without improvement: 1
09/16 12:18:23 PM: edges-rel-semeval_loss: training: 0.044435 validation: 0.068281
09/16 12:18:23 PM: macro_avg: validation: 0.733000
09/16 12:18:23 PM: micro_avg: validation: 0.000000
09/16 12:18:23 PM: edges-rel-semeval_mcc: training: 0.837140 validation: 0.729409
09/16 12:18:23 PM: edges-rel-semeval_acc: training: 0.743125 validation: 0.606614
09/16 12:18:23 PM: edges-rel-semeval_precision: training: 0.903249 validation: 0.861340
09/16 12:18:23 PM: edges-rel-semeval_recall: training: 0.790625 validation: 0.637946
09/16 12:18:23 PM: edges-rel-semeval_f1: training: 0.843193 validation: 0.733000
09/16 12:18:23 PM: Global learning rate: 5e-05
09/16 12:18:23 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:18:32 PM: Update 4080: task edges-rel-semeval, batch 80 (4080): mcc: 0.8257, acc: 0.7215, precision: 0.9000, recall: 0.7730, f1: 0.8317, edges-rel-semeval_loss: 0.0459
09/16 12:18:37 PM: ***** Step 4100 / Validation 41 *****
09/16 12:18:37 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:18:37 PM: Validating...
09/16 12:18:41 PM: Updating LR scheduler:
09/16 12:18:41 PM: 	Best result seen so far for macro_avg: 0.746
09/16 12:18:41 PM: 	# validation passes without improvement: 2
09/16 12:18:41 PM: edges-rel-semeval_loss: training: 0.045518 validation: 0.067790
09/16 12:18:41 PM: macro_avg: validation: 0.742941
09/16 12:18:41 PM: micro_avg: validation: 0.000000
09/16 12:18:41 PM: edges-rel-semeval_mcc: training: 0.826372 validation: 0.736173
09/16 12:18:41 PM: edges-rel-semeval_acc: training: 0.723116 validation: 0.628372
09/16 12:18:41 PM: edges-rel-semeval_precision: training: 0.897847 validation: 0.843094
09/16 12:18:41 PM: edges-rel-semeval_recall: training: 0.776096 validation: 0.664056
09/16 12:18:41 PM: edges-rel-semeval_f1: training: 0.832544 validation: 0.742941
09/16 12:18:41 PM: Global learning rate: 5e-05
09/16 12:18:41 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:18:42 PM: Update 4108: task edges-rel-semeval, batch 8 (4108): mcc: 0.8501, acc: 0.7500, precision: 0.9009, recall: 0.8164, f1: 0.8566, edges-rel-semeval_loss: 0.0413
09/16 12:18:50 PM: ***** Step 4200 / Validation 42 *****
09/16 12:18:50 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:18:50 PM: Validating...
09/16 12:18:52 PM: Evaluate: task edges-rel-semeval, batch 24 (36): mcc: 0.7623, acc: 0.6576, precision: 0.8711, recall: 0.6862, f1: 0.7677, edges-rel-semeval_loss: 0.0626
09/16 12:18:53 PM: Updating LR scheduler:
09/16 12:18:53 PM: 	Best result seen so far for macro_avg: 0.746
09/16 12:18:53 PM: 	# validation passes without improvement: 3
09/16 12:18:53 PM: edges-rel-semeval_loss: training: 0.042637 validation: 0.067814
09/16 12:18:53 PM: macro_avg: validation: 0.740813
09/16 12:18:53 PM: micro_avg: validation: 0.000000
09/16 12:18:53 PM: edges-rel-semeval_mcc: training: 0.847304 validation: 0.734743
09/16 12:18:53 PM: edges-rel-semeval_acc: training: 0.753750 validation: 0.625762
09/16 12:18:53 PM: edges-rel-semeval_precision: training: 0.909734 validation: 0.847534
09/16 12:18:53 PM: edges-rel-semeval_recall: training: 0.803125 validation: 0.657963
09/16 12:18:53 PM: edges-rel-semeval_f1: training: 0.853112 validation: 0.740813
09/16 12:18:53 PM: Global learning rate: 5e-05
09/16 12:18:53 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:19:02 PM: Update 4285: task edges-rel-semeval, batch 85 (4285): mcc: 0.8261, acc: 0.7272, precision: 0.8924, recall: 0.7805, f1: 0.8327, edges-rel-semeval_loss: 0.0460
09/16 12:19:06 PM: ***** Step 4300 / Validation 43 *****
09/16 12:19:06 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:19:06 PM: Validating...
09/16 12:19:10 PM: Updating LR scheduler:
09/16 12:19:11 PM: 	Best result seen so far for macro_avg: 0.746
09/16 12:19:11 PM: 	# validation passes without improvement: 0
09/16 12:19:11 PM: edges-rel-semeval_loss: training: 0.046108 validation: 0.068193
09/16 12:19:11 PM: macro_avg: validation: 0.739619
09/16 12:19:11 PM: micro_avg: validation: 0.000000
09/16 12:19:11 PM: edges-rel-semeval_mcc: training: 0.826135 validation: 0.733096
09/16 12:19:11 PM: edges-rel-semeval_acc: training: 0.725938 validation: 0.621410
09/16 12:19:11 PM: edges-rel-semeval_precision: training: 0.889876 validation: 0.842984
09/16 12:19:11 PM: edges-rel-semeval_recall: training: 0.782812 validation: 0.658834
09/16 12:19:11 PM: edges-rel-semeval_f1: training: 0.832918 validation: 0.739619
09/16 12:19:11 PM: Global learning rate: 2.5e-05
09/16 12:19:11 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:19:14 PM: Update 4303: task edges-rel-semeval, batch 3 (4303): mcc: 0.8938, acc: 0.8209, precision: 0.9500, recall: 0.8507, f1: 0.8976, edges-rel-semeval_loss: 0.0319
09/16 12:19:24 PM: Update 4388: task edges-rel-semeval, batch 88 (4388): mcc: 0.8482, acc: 0.7582, precision: 0.9164, recall: 0.7987, f1: 0.8535, edges-rel-semeval_loss: 0.0422
09/16 12:19:27 PM: ***** Step 4400 / Validation 44 *****
09/16 12:19:27 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:19:27 PM: Validating...
09/16 12:19:31 PM: Updating LR scheduler:
09/16 12:19:32 PM: 	Best result seen so far for macro_avg: 0.746
09/16 12:19:32 PM: 	# validation passes without improvement: 1
09/16 12:19:32 PM: edges-rel-semeval_loss: training: 0.041993 validation: 0.067968
09/16 12:19:32 PM: macro_avg: validation: 0.738659
09/16 12:19:32 PM: micro_avg: validation: 0.000000
09/16 12:19:32 PM: edges-rel-semeval_mcc: training: 0.849619 validation: 0.733336
09/16 12:19:32 PM: edges-rel-semeval_acc: training: 0.759697 validation: 0.618799
09/16 12:19:32 PM: edges-rel-semeval_precision: training: 0.913917 validation: 0.852105
09/16 12:19:32 PM: edges-rel-semeval_recall: training: 0.803532 validation: 0.651871
09/16 12:19:32 PM: edges-rel-semeval_f1: training: 0.855177 validation: 0.738659
09/16 12:19:32 PM: Global learning rate: 2.5e-05
09/16 12:19:32 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:19:35 PM: Update 4428: task edges-rel-semeval, batch 28 (4428): mcc: 0.8297, acc: 0.7288, precision: 0.8976, recall: 0.7824, f1: 0.8360, edges-rel-semeval_loss: 0.0452
09/16 12:19:45 PM: ***** Step 4500 / Validation 45 *****
09/16 12:19:45 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:19:45 PM: Validating...
09/16 12:19:47 PM: Evaluate: task edges-rel-semeval, batch 17 (36): mcc: 0.7586, acc: 0.6544, precision: 0.8618, recall: 0.6875, f1: 0.7648, edges-rel-semeval_loss: 0.0624
09/16 12:19:50 PM: Updating LR scheduler:
09/16 12:19:50 PM: 	Best result seen so far for macro_avg: 0.746
09/16 12:19:50 PM: 	# validation passes without improvement: 2
09/16 12:19:50 PM: edges-rel-semeval_loss: training: 0.043702 validation: 0.067533
09/16 12:19:50 PM: macro_avg: validation: 0.742913
09/16 12:19:50 PM: micro_avg: validation: 0.000000
09/16 12:19:50 PM: edges-rel-semeval_mcc: training: 0.841665 validation: 0.736642
09/16 12:19:50 PM: edges-rel-semeval_acc: training: 0.745938 validation: 0.625762
09/16 12:19:50 PM: edges-rel-semeval_precision: training: 0.902611 validation: 0.847269
09/16 12:19:50 PM: edges-rel-semeval_recall: training: 0.799375 validation: 0.661445
09/16 12:19:50 PM: edges-rel-semeval_f1: training: 0.847862 validation: 0.742913
09/16 12:19:50 PM: Global learning rate: 2.5e-05
09/16 12:19:50 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:19:57 PM: Update 4553: task edges-rel-semeval, batch 53 (4553): mcc: 0.8409, acc: 0.7409, precision: 0.9109, recall: 0.7906, f1: 0.8465, edges-rel-semeval_loss: 0.0423
09/16 12:20:01 PM: ***** Step 4600 / Validation 46 *****
09/16 12:20:01 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:20:01 PM: Validating...
09/16 12:20:06 PM: Updating LR scheduler:
09/16 12:20:07 PM: 	Best result seen so far for macro_avg: 0.746
09/16 12:20:07 PM: 	# validation passes without improvement: 3
09/16 12:20:07 PM: edges-rel-semeval_loss: training: 0.041547 validation: 0.067469
09/16 12:20:07 PM: macro_avg: validation: 0.741136
09/16 12:20:07 PM: micro_avg: validation: 0.000000
09/16 12:20:07 PM: edges-rel-semeval_mcc: training: 0.850233 validation: 0.733965
09/16 12:20:07 PM: edges-rel-semeval_acc: training: 0.755282 validation: 0.624021
09/16 12:20:07 PM: edges-rel-semeval_precision: training: 0.917962 validation: 0.838462
09/16 12:20:07 PM: edges-rel-semeval_recall: training: 0.801009 validation: 0.664056
09/16 12:20:07 PM: edges-rel-semeval_f1: training: 0.855507 validation: 0.741136
09/16 12:20:07 PM: Global learning rate: 2.5e-05
09/16 12:20:07 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:20:07 PM: Update 4601: task edges-rel-semeval, batch 1 (4601): mcc: 0.8681, acc: 0.7812, precision: 0.8750, recall: 0.8750, f1: 0.8750, edges-rel-semeval_loss: 0.0447
09/16 12:20:17 PM: Update 4697: task edges-rel-semeval, batch 97 (4697): mcc: 0.8366, acc: 0.7445, precision: 0.8971, recall: 0.7951, f1: 0.8430, edges-rel-semeval_loss: 0.0433
09/16 12:20:18 PM: ***** Step 4700 / Validation 47 *****
09/16 12:20:18 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:20:18 PM: Validating...
09/16 12:20:21 PM: Updating LR scheduler:
09/16 12:20:21 PM: 	Best result seen so far for macro_avg: 0.746
09/16 12:20:21 PM: 	# validation passes without improvement: 0
09/16 12:20:21 PM: edges-rel-semeval_loss: training: 0.043267 validation: 0.067804
09/16 12:20:21 PM: macro_avg: validation: 0.740413
09/16 12:20:21 PM: micro_avg: validation: 0.000000
09/16 12:20:21 PM: edges-rel-semeval_mcc: training: 0.836519 validation: 0.734782
09/16 12:20:21 PM: edges-rel-semeval_acc: training: 0.743750 validation: 0.625762
09/16 12:20:21 PM: edges-rel-semeval_precision: training: 0.898197 validation: 0.850847
09/16 12:20:21 PM: edges-rel-semeval_recall: training: 0.794062 validation: 0.655352
09/16 12:20:21 PM: edges-rel-semeval_f1: training: 0.842926 validation: 0.740413
09/16 12:20:21 PM: Global learning rate: 1.25e-05
09/16 12:20:21 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:20:28 PM: Update 4746: task edges-rel-semeval, batch 46 (4746): mcc: 0.8497, acc: 0.7623, precision: 0.9167, recall: 0.8011, f1: 0.8550, edges-rel-semeval_loss: 0.0417
09/16 12:20:35 PM: ***** Step 4800 / Validation 48 *****
09/16 12:20:35 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:20:35 PM: Validating...
09/16 12:20:38 PM: Evaluate: task edges-rel-semeval, batch 30 (36): mcc: 0.7591, acc: 0.6562, precision: 0.8627, recall: 0.6875, f1: 0.7652, edges-rel-semeval_loss: 0.0629
09/16 12:20:39 PM: Updating LR scheduler:
09/16 12:20:39 PM: 	Best result seen so far for macro_avg: 0.746
09/16 12:20:39 PM: 	# validation passes without improvement: 1
09/16 12:20:39 PM: edges-rel-semeval_loss: training: 0.041954 validation: 0.067366
09/16 12:20:39 PM: macro_avg: validation: 0.742550
09/16 12:20:39 PM: micro_avg: validation: 0.000000
09/16 12:20:39 PM: edges-rel-semeval_mcc: training: 0.843896 validation: 0.736195
09/16 12:20:39 PM: edges-rel-semeval_acc: training: 0.751813 validation: 0.628372
09/16 12:20:39 PM: edges-rel-semeval_precision: training: 0.910863 validation: 0.846325
09/16 12:20:39 PM: edges-rel-semeval_recall: training: 0.795963 validation: 0.661445
09/16 12:20:39 PM: edges-rel-semeval_f1: training: 0.849546 validation: 0.742550
09/16 12:20:39 PM: Global learning rate: 1.25e-05
09/16 12:20:39 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:20:48 PM: Update 4894: task edges-rel-semeval, batch 94 (4894): mcc: 0.8501, acc: 0.7593, precision: 0.9079, recall: 0.8098, f1: 0.8561, edges-rel-semeval_loss: 0.0417
09/16 12:20:50 PM: ***** Step 4900 / Validation 49 *****
09/16 12:20:50 PM: edges-rel-semeval: trained on 100 batches, 0.465 epochs
09/16 12:20:50 PM: Validating...
09/16 12:20:53 PM: Updating LR scheduler:
09/16 12:20:54 PM: 	Best result seen so far for macro_avg: 0.746
09/16 12:20:54 PM: 	# validation passes without improvement: 2
09/16 12:20:54 PM: Ran out of early stopping patience. Stopping training.
09/16 12:20:54 PM: edges-rel-semeval_loss: training: 0.041566 validation: 0.067937
09/16 12:20:54 PM: macro_avg: validation: 0.740451
09/16 12:20:54 PM: micro_avg: validation: 0.000000
09/16 12:20:54 PM: edges-rel-semeval_mcc: training: 0.851834 validation: 0.734294
09/16 12:20:54 PM: edges-rel-semeval_acc: training: 0.762813 validation: 0.625762
09/16 12:20:54 PM: edges-rel-semeval_precision: training: 0.908456 validation: 0.846585
09/16 12:20:54 PM: edges-rel-semeval_recall: training: 0.812500 validation: 0.657963
09/16 12:20:54 PM: edges-rel-semeval_f1: training: 0.857803 validation: 0.740451
09/16 12:20:54 PM: Global learning rate: 1.25e-05
09/16 12:20:54 PM: Saving checkpoints to: ./experiments/rel-semeval-sst-mix/run
09/16 12:20:54 PM: Stopped training after 49 validation checks
09/16 12:20:54 PM: Trained edges-rel-semeval for 4900 batches or 22.791 epochs
09/16 12:20:54 PM: ***** VALIDATION RESULTS *****
09/16 12:20:54 PM: edges-rel-semeval_f1 (for best val pass 39): edges-rel-semeval_loss: 0.06789, macro_avg: 0.74595, micro_avg: 0.00000, edges-rel-semeval_mcc: 0.74057, edges-rel-semeval_acc: 0.62402, edges-rel-semeval_precision: 0.85666, edges-rel-semeval_recall: 0.66057, edges-rel-semeval_f1: 0.74595
09/16 12:20:54 PM: micro_avg (for best val pass 1): edges-rel-semeval_loss: 0.17619, macro_avg: 0.00000, micro_avg: 0.00000, edges-rel-semeval_mcc: 0.00000, edges-rel-semeval_acc: 0.00000, edges-rel-semeval_precision: 0.00000, edges-rel-semeval_recall: 0.00000, edges-rel-semeval_f1: 0.00000
09/16 12:20:54 PM: macro_avg (for best val pass 39): edges-rel-semeval_loss: 0.06789, macro_avg: 0.74595, micro_avg: 0.00000, edges-rel-semeval_mcc: 0.74057, edges-rel-semeval_acc: 0.62402, edges-rel-semeval_precision: 0.85666, edges-rel-semeval_recall: 0.66057, edges-rel-semeval_f1: 0.74595
09/16 12:20:54 PM: Evaluating...
09/16 12:20:54 PM: Loaded model state from ./experiments/rel-semeval-sst-mix/run/edges-rel-semeval/model_state_target_train_val_39.best.th
09/16 12:20:54 PM: Evaluating on: edges-rel-semeval, split: val
09/16 12:20:58 PM: Task 'edges-rel-semeval': sorting predictions by 'idx'
09/16 12:20:58 PM: Finished evaluating on: edges-rel-semeval
09/16 12:20:58 PM: Task 'edges-rel-semeval': joining predictions with input split 'val'
09/16 12:20:58 PM: Task 'edges-rel-semeval': Wrote predictions to ./experiments/rel-semeval-sst-mix/run
09/16 12:20:58 PM: Wrote all preds for split 'val' to ./experiments/rel-semeval-sst-mix/run
09/16 12:20:58 PM: Evaluating on: edges-rel-semeval, split: test
09/16 12:21:07 PM: Task 'edges-rel-semeval': sorting predictions by 'idx'
09/16 12:21:07 PM: Finished evaluating on: edges-rel-semeval
09/16 12:21:07 PM: Task 'edges-rel-semeval': joining predictions with input split 'test'
09/16 12:21:07 PM: Task 'edges-rel-semeval': Wrote predictions to ./experiments/rel-semeval-sst-mix/run
09/16 12:21:07 PM: Wrote all preds for split 'test' to ./experiments/rel-semeval-sst-mix/run
09/16 12:21:07 PM: Writing results for split 'val' to ./experiments/rel-semeval-sst-mix/results.tsv
09/16 12:21:07 PM: micro_avg: 0.000, macro_avg: 0.746, edges-rel-semeval_mcc: 0.741, edges-rel-semeval_acc: 0.624, edges-rel-semeval_precision: 0.857, edges-rel-semeval_recall: 0.661, edges-rel-semeval_f1: 0.746
09/16 12:21:07 PM: Done!
09/16 12:21:07 PM: Fatal error in main():
Traceback (most recent call last):
  File "main.py", line 16, in <module>
    main(sys.argv[1:])
  File "/srv/home/ericwallace/jiant/jiant/__main__.py", line 610, in main
    exit("Done exited")
  File "/home/ericwallace/miniconda3/envs/jiant/lib/python3.6/_sitebuiltins.py", line 26, in __call__
    raise SystemExit(code)
SystemExit: Done exited
