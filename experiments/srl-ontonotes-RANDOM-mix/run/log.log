09/07 09:16:38 PM: Git branch: master
09/07 09:16:38 PM: Git SHA: 117419dc9116809c203f878fb83f7aaddafbbcb0
09/07 09:16:39 PM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "/scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/",
  "exp_name": "experiments/srl-ontonotes-RANDOM-mix",
  "input_module": "bert-base-uncased",
  "local_log_path": "/scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run/log.log",
  "lr_patience": 5,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 20,
  "pretrain_tasks": "",
  "pretrained_dir": "RANDOM",
  "pytorch_transformers_output_mode": "mix",
  "remote_log_name": "experiments/srl-ontonotes-RANDOM-mix__run",
  "run_dir": "/scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-srl-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/07 09:16:39 PM: Saved config to /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run/params.conf
09/07 09:16:39 PM: Using random seed 1234
09/07 09:16:40 PM: Using GPU 0
09/07 09:16:40 PM: Loading tasks...
09/07 09:16:40 PM: Writing pre-preprocessed tasks to /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/
09/07 09:16:40 PM: 	Creating task edges-srl-ontonotes from scratch.
09/07 09:16:44 PM: Read=231480, Skip=21590, Total=253070 from /scratch0/new/jiant/probing_data/edges/ontonotes/srl/train.json.retokenized.bert-base-uncased
09/07 09:16:45 PM: Read=32486, Skip=2811, Total=35297 from /scratch0/new/jiant/probing_data/edges/ontonotes/srl/development.json.retokenized.bert-base-uncased
09/07 09:16:45 PM: Read=23800, Skip=2915, Total=26715 from /scratch0/new/jiant/probing_data/edges/ontonotes/srl/test.json.retokenized.bert-base-uncased
09/07 09:16:48 PM: 	Task 'edges-srl-ontonotes': |train|=231480 |val|=32486 |test|=23800
09/07 09:16:48 PM: 	Finished loading tasks: edges-srl-ontonotes.
09/07 09:16:48 PM: 	Building vocab from scratch.
09/07 09:16:48 PM: 	Counting units for task edges-srl-ontonotes.
09/07 09:16:56 PM: 	Task 'edges-srl-ontonotes': adding vocab namespace 'edges-srl-ontonotes_labels'
09/07 09:16:56 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /cliphomes/ewallac2/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:16:56 PM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/07 09:16:56 PM: 	Saved vocab to /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/vocab
09/07 09:16:56 PM: Loading token dictionary from /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/vocab.
09/07 09:16:56 PM: 	Loaded vocab from /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/vocab
09/07 09:16:56 PM: 	Vocab namespace tokens: size 23662
09/07 09:16:56 PM: 	Vocab namespace chars: size 76
09/07 09:16:56 PM: 	Vocab namespace edges-srl-ontonotes_labels: size 66
09/07 09:16:56 PM: 	Vocab namespace bert_uncased: size 30524
09/07 09:16:56 PM: 	Finished building vocab.
09/07 09:16:56 PM: 	Task edges-srl-ontonotes (train): Indexing from scratch.
09/07 09:17:44 PM: 	Task edges-srl-ontonotes (train): Saved 231480 instances to /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/preproc/edges-srl-ontonotes__train_data
09/07 09:17:44 PM: 	Task edges-srl-ontonotes (val): Indexing from scratch.
09/07 09:17:51 PM: 	Task edges-srl-ontonotes (val): Saved 32486 instances to /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/preproc/edges-srl-ontonotes__val_data
09/07 09:17:51 PM: 	Task edges-srl-ontonotes (test): Indexing from scratch.
09/07 09:17:56 PM: 	Task edges-srl-ontonotes (test): Saved 23800 instances to /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/preproc/edges-srl-ontonotes__test_data
09/07 09:17:56 PM: 	Finished indexing tasks
09/07 09:17:56 PM: 	Creating trimmed target-only version of edges-srl-ontonotes train.
09/07 09:17:56 PM: 	  Training on 
09/07 09:17:56 PM: 	  Evaluating on edges-srl-ontonotes
09/07 09:17:56 PM: 	Finished loading tasks in 75.702s
09/07 09:17:56 PM: 	 Tasks: ['edges-srl-ontonotes']
09/07 09:17:56 PM: Building model...
09/07 09:17:56 PM: Using BERT model (bert-base-uncased).
09/07 09:17:56 PM: LOADING A RANDOMLY WEIGHTS BERT
09/07 09:17:58 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache, downloading to /tmp/tmpi74rodlw
09/07 09:17:58 PM: copying /tmp/tmpi74rodlw to cache at /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/07 09:17:58 PM: creating metadata file for /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/07 09:17:58 PM: removing temp file /tmp/tmpi74rodlw
09/07 09:17:58 PM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/07 09:17:58 PM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/07 09:17:58 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache, downloading to /tmp/tmp9bio2i9t
09/07 09:18:25 PM: copying /tmp/tmp9bio2i9t to cache at /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/07 09:18:25 PM: creating metadata file for /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/07 09:18:25 PM: removing temp file /tmp/tmp9bio2i9t
09/07 09:18:25 PM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/07 09:18:29 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to /tmp/tmp90c0z1vq
09/07 09:18:29 PM: copying /tmp/tmp90c0z1vq to cache at /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:18:29 PM: creating metadata file for /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:18:29 PM: removing temp file /tmp/tmp90c0z1vq
09/07 09:18:29 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:18:29 PM: NOTE: pytorch_transformers_output_mode='mix', so scalar mixing weights will be fine-tuned even if BERT model is frozen.
09/07 09:18:29 PM: Initializing parameters
09/07 09:18:29 PM: Done initializing parameters; the following parameters are using their default initialization from their code
09/07 09:18:29 PM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/07 09:18:29 PM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/07 09:18:29 PM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.model.pooler.dense.bias
09/07 09:18:29 PM:    _text_field_embedder.model.pooler.dense.weight
09/07 09:18:29 PM:    _text_field_embedder.scalar_mix.gamma
09/07 09:18:29 PM:    _text_field_embedder.scalar_mix.scalar_parameters.0
09/07 09:18:29 PM:    _text_field_embedder.scalar_mix.scalar_parameters.1
09/07 09:18:29 PM:    _text_field_embedder.scalar_mix.scalar_parameters.10
09/07 09:18:29 PM:    _text_field_embedder.scalar_mix.scalar_parameters.11
09/07 09:18:29 PM:    _text_field_embedder.scalar_mix.scalar_parameters.12
09/07 09:18:29 PM:    _text_field_embedder.scalar_mix.scalar_parameters.2
09/07 09:18:29 PM:    _text_field_embedder.scalar_mix.scalar_parameters.3
09/07 09:18:29 PM:    _text_field_embedder.scalar_mix.scalar_parameters.4
09/07 09:18:29 PM:    _text_field_embedder.scalar_mix.scalar_parameters.5
09/07 09:18:29 PM:    _text_field_embedder.scalar_mix.scalar_parameters.6
09/07 09:18:29 PM:    _text_field_embedder.scalar_mix.scalar_parameters.7
09/07 09:18:29 PM:    _text_field_embedder.scalar_mix.scalar_parameters.8
09/07 09:18:29 PM:    _text_field_embedder.scalar_mix.scalar_parameters.9
09/07 09:18:29 PM: 	Task 'edges-srl-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-srl-ontonotes"
}
09/07 09:18:33 PM: Model specification:
09/07 09:18:33 PM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): BertLayerNorm()
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
      (scalar_mix): ScalarMix(
        (scalar_parameters): ParameterList(
            (0): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (1): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (2): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (3): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (4): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (5): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (6): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (7): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (8): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (9): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (10): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (11): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (12): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-srl-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (proj2): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (span_extractor2): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Sequential(
        (0): Linear(in_features=1024, out_features=256, bias=True)
        (1): Tanh()
        (2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)
        (3): Dropout(p=0.3)
        (4): Linear(in_features=256, out_features=66, bias=True)
      )
    )
  )
)
09/07 09:18:33 PM: Model parameters:
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.scalar_mix.gamma: Trainable parameter, count 1 with torch.Size([1])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.0: Trainable parameter, count 1 with torch.Size([1])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.1: Trainable parameter, count 1 with torch.Size([1])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.2: Trainable parameter, count 1 with torch.Size([1])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.3: Trainable parameter, count 1 with torch.Size([1])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.4: Trainable parameter, count 1 with torch.Size([1])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.5: Trainable parameter, count 1 with torch.Size([1])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.6: Trainable parameter, count 1 with torch.Size([1])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.7: Trainable parameter, count 1 with torch.Size([1])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.8: Trainable parameter, count 1 with torch.Size([1])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.9: Trainable parameter, count 1 with torch.Size([1])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.10: Trainable parameter, count 1 with torch.Size([1])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.11: Trainable parameter, count 1 with torch.Size([1])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.12: Trainable parameter, count 1 with torch.Size([1])
09/07 09:18:33 PM: 	edges-srl-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/07 09:18:33 PM: 	edges-srl-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:33 PM: 	edges-srl-ontonotes_mdl.proj2.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/07 09:18:33 PM: 	edges-srl-ontonotes_mdl.proj2.bias: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:33 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.0.weight: Trainable parameter, count 262144 with torch.Size([256, 1024])
09/07 09:18:33 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.0.bias: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:33 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.2.weight: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:33 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.2.bias: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:33 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.4.weight: Trainable parameter, count 16896 with torch.Size([66, 256])
09/07 09:18:33 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.4.bias: Trainable parameter, count 66 with torch.Size([66])
09/07 09:18:33 PM: Total number of parameters: 110155856 (1.10156e+08)
09/07 09:18:33 PM: Number of trainable parameters: 673616 (673616)
09/07 09:18:33 PM: Finished building model in 37.459s
09/07 09:18:33 PM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-srl-ontonotes 

09/07 09:18:50 PM: patience = 20
09/07 09:18:50 PM: val_interval = 1000
09/07 09:18:50 PM: max_vals = 250
09/07 09:18:50 PM: cuda_device = 0
09/07 09:18:50 PM: grad_norm = 5.0
09/07 09:18:50 PM: grad_clipping = None
09/07 09:18:50 PM: lr_decay = 0.99
09/07 09:18:50 PM: min_lr = 1e-06
09/07 09:18:50 PM: keep_all_checkpoints = 0
09/07 09:18:50 PM: val_data_limit = 5000
09/07 09:18:50 PM: max_epochs = -1
09/07 09:18:50 PM: dec_val_scale = 250
09/07 09:18:50 PM: training_data_fraction = 1
09/07 09:18:50 PM: type = adam
09/07 09:18:50 PM: parameter_groups = None
09/07 09:18:50 PM: Number of trainable parameters: 673616
09/07 09:18:50 PM: infer_type_and_cast = True
09/07 09:18:50 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/07 09:18:50 PM: CURRENTLY DEFINED PARAMETERS: 
09/07 09:18:50 PM: lr = 0.0001
09/07 09:18:50 PM: amsgrad = True
09/07 09:18:50 PM: type = reduce_on_plateau
09/07 09:18:50 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/07 09:18:50 PM: CURRENTLY DEFINED PARAMETERS: 
09/07 09:18:50 PM: mode = max
09/07 09:18:50 PM: factor = 0.5
09/07 09:18:50 PM: patience = 5
09/07 09:18:50 PM: threshold = 0.0001
09/07 09:18:50 PM: threshold_mode = abs
09/07 09:18:50 PM: verbose = True
09/07 09:18:50 PM: type = adam
09/07 09:18:50 PM: parameter_groups = None
09/07 09:18:50 PM: Number of trainable parameters: 673616
09/07 09:18:50 PM: infer_type_and_cast = True
09/07 09:18:50 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/07 09:18:50 PM: CURRENTLY DEFINED PARAMETERS: 
09/07 09:18:50 PM: lr = 0.0001
09/07 09:18:50 PM: amsgrad = True
09/07 09:18:50 PM: type = reduce_on_plateau
09/07 09:18:50 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/07 09:18:50 PM: CURRENTLY DEFINED PARAMETERS: 
09/07 09:18:50 PM: mode = max
09/07 09:18:50 PM: factor = 0.5
09/07 09:18:50 PM: patience = 5
09/07 09:18:50 PM: threshold = 0.0001
09/07 09:18:50 PM: threshold_mode = abs
09/07 09:18:50 PM: verbose = True
09/07 09:18:50 PM: Starting training without restoring from a checkpoint.
09/07 09:18:50 PM: Training examples per task, before any subsampling: {'edges-srl-ontonotes': 231480}
09/07 09:18:50 PM: Beginning training with stopping criteria based on metric: edges-srl-ontonotes_f1
09/07 09:19:00 PM: Update 105: task edges-srl-ontonotes, batch 105 (105): mcc: 0.0214, acc: 0.0162, precision: 0.0317, recall: 0.0509, f1: 0.0391, edges-srl-ontonotes_loss: 0.2184
09/07 09:19:10 PM: Update 206: task edges-srl-ontonotes, batch 206 (206): mcc: 0.0220, acc: 0.0148, precision: 0.0392, recall: 0.0321, f1: 0.0353, edges-srl-ontonotes_loss: 0.1508
09/07 09:19:20 PM: Update 307: task edges-srl-ontonotes, batch 307 (307): mcc: 0.0281, acc: 0.0178, precision: 0.0521, recall: 0.0294, f1: 0.0376, edges-srl-ontonotes_loss: 0.1210
09/07 09:19:30 PM: Update 392: task edges-srl-ontonotes, batch 392 (392): mcc: 0.0458, acc: 0.0289, precision: 0.0815, recall: 0.0380, f1: 0.0518, edges-srl-ontonotes_loss: 0.1061
09/07 09:19:40 PM: Update 506: task edges-srl-ontonotes, batch 506 (506): mcc: 0.0938, acc: 0.0585, precision: 0.1596, recall: 0.0658, f1: 0.0932, edges-srl-ontonotes_loss: 0.0927
09/07 09:19:50 PM: Update 620: task edges-srl-ontonotes, batch 620 (620): mcc: 0.1503, acc: 0.0932, precision: 0.2507, recall: 0.1000, f1: 0.1430, edges-srl-ontonotes_loss: 0.0835
09/07 09:20:00 PM: Update 696: task edges-srl-ontonotes, batch 696 (696): mcc: 0.1709, acc: 0.1046, precision: 0.2860, recall: 0.1115, f1: 0.1604, edges-srl-ontonotes_loss: 0.0792
09/07 09:20:10 PM: Update 810: task edges-srl-ontonotes, batch 810 (810): mcc: 0.2022, acc: 0.1225, precision: 0.3362, recall: 0.1306, f1: 0.1881, edges-srl-ontonotes_loss: 0.0739
09/07 09:20:20 PM: Update 923: task edges-srl-ontonotes, batch 923 (923): mcc: 0.2308, acc: 0.1396, precision: 0.3796, recall: 0.1490, f1: 0.2140, edges-srl-ontonotes_loss: 0.0696
09/07 09:20:28 PM: ***** Step 1000 / Validation 1 *****
09/07 09:20:28 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:20:28 PM: Validating...
09/07 09:20:30 PM: Evaluate: task edges-srl-ontonotes, batch 21 (157): mcc: 0.4979, acc: 0.3068, precision: 0.8031, recall: 0.3140, f1: 0.4514, edges-srl-ontonotes_loss: 0.0362
09/07 09:20:40 PM: Evaluate: task edges-srl-ontonotes, batch 129 (157): mcc: 0.5163, acc: 0.3353, precision: 0.7909, recall: 0.3428, f1: 0.4783, edges-srl-ontonotes_loss: 0.0349
09/07 09:20:43 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:20:43 PM: Best result seen so far for micro.
09/07 09:20:43 PM: Best result seen so far for macro.
09/07 09:20:43 PM: Updating LR scheduler:
09/07 09:20:43 PM: 	Best result seen so far for macro_avg: 0.465
09/07 09:20:43 PM: 	# validation passes without improvement: 0
09/07 09:20:43 PM: edges-srl-ontonotes_loss: training: 0.067256 validation: 0.035230
09/07 09:20:43 PM: macro_avg: validation: 0.465033
09/07 09:20:43 PM: micro_avg: validation: 0.000000
09/07 09:20:43 PM: edges-srl-ontonotes_mcc: training: 0.246003 validation: 0.504264
09/07 09:20:43 PM: edges-srl-ontonotes_acc: training: 0.149209 validation: 0.322916
09/07 09:20:43 PM: edges-srl-ontonotes_precision: training: 0.402011 validation: 0.781921
09/07 09:20:43 PM: edges-srl-ontonotes_recall: training: 0.159137 validation: 0.330921
09/07 09:20:43 PM: edges-srl-ontonotes_f1: training: 0.228014 validation: 0.465033
09/07 09:20:43 PM: Global learning rate: 0.0001
09/07 09:20:43 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 09:20:50 PM: Update 1081: task edges-srl-ontonotes, batch 81 (1081): mcc: 0.4392, acc: 0.2772, precision: 0.6613, recall: 0.2989, f1: 0.4117, edges-srl-ontonotes_loss: 0.0386
09/07 09:21:00 PM: Update 1190: task edges-srl-ontonotes, batch 190 (1190): mcc: 0.4472, acc: 0.2859, precision: 0.6634, recall: 0.3087, f1: 0.4214, edges-srl-ontonotes_loss: 0.0380
09/07 09:21:10 PM: Update 1285: task edges-srl-ontonotes, batch 285 (1285): mcc: 0.4536, acc: 0.2939, precision: 0.6640, recall: 0.3174, f1: 0.4294, edges-srl-ontonotes_loss: 0.0376
09/07 09:21:20 PM: Update 1393: task edges-srl-ontonotes, batch 393 (1393): mcc: 0.4550, acc: 0.2965, precision: 0.6615, recall: 0.3205, f1: 0.4318, edges-srl-ontonotes_loss: 0.0372
09/07 09:21:30 PM: Update 1497: task edges-srl-ontonotes, batch 497 (1497): mcc: 0.4612, acc: 0.3020, precision: 0.6646, recall: 0.3276, f1: 0.4389, edges-srl-ontonotes_loss: 0.0368
09/07 09:21:40 PM: Update 1593: task edges-srl-ontonotes, batch 593 (1593): mcc: 0.4644, acc: 0.3061, precision: 0.6646, recall: 0.3321, f1: 0.4429, edges-srl-ontonotes_loss: 0.0365
09/07 09:21:50 PM: Update 1698: task edges-srl-ontonotes, batch 698 (1698): mcc: 0.4633, acc: 0.3050, precision: 0.6645, recall: 0.3306, f1: 0.4415, edges-srl-ontonotes_loss: 0.0364
09/07 09:22:01 PM: Update 1799: task edges-srl-ontonotes, batch 799 (1799): mcc: 0.4616, acc: 0.3036, precision: 0.6631, recall: 0.3289, f1: 0.4397, edges-srl-ontonotes_loss: 0.0364
09/07 09:22:11 PM: Update 1879: task edges-srl-ontonotes, batch 879 (1879): mcc: 0.4605, acc: 0.3026, precision: 0.6618, recall: 0.3280, f1: 0.4386, edges-srl-ontonotes_loss: 0.0364
09/07 09:22:21 PM: Update 1980: task edges-srl-ontonotes, batch 980 (1980): mcc: 0.4609, acc: 0.3027, precision: 0.6621, recall: 0.3284, f1: 0.4391, edges-srl-ontonotes_loss: 0.0363
09/07 09:22:23 PM: ***** Step 2000 / Validation 2 *****
09/07 09:22:23 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:22:23 PM: Validating...
09/07 09:22:31 PM: Evaluate: task edges-srl-ontonotes, batch 87 (157): mcc: 0.5606, acc: 0.4004, precision: 0.7807, recall: 0.4090, f1: 0.5368, edges-srl-ontonotes_loss: 0.0311
09/07 09:22:38 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:22:38 PM: Best result seen so far for macro.
09/07 09:22:38 PM: Updating LR scheduler:
09/07 09:22:38 PM: 	Best result seen so far for macro_avg: 0.531
09/07 09:22:38 PM: 	# validation passes without improvement: 0
09/07 09:22:38 PM: edges-srl-ontonotes_loss: training: 0.036278 validation: 0.030722
09/07 09:22:38 PM: macro_avg: validation: 0.531407
09/07 09:22:38 PM: micro_avg: validation: 0.000000
09/07 09:22:38 PM: edges-srl-ontonotes_mcc: training: 0.461060 validation: 0.555835
09/07 09:22:38 PM: edges-srl-ontonotes_acc: training: 0.303006 validation: 0.395197
09/07 09:22:38 PM: edges-srl-ontonotes_precision: training: 0.662248 validation: 0.778289
09/07 09:22:38 PM: edges-srl-ontonotes_recall: training: 0.328616 validation: 0.403433
09/07 09:22:38 PM: edges-srl-ontonotes_f1: training: 0.439264 validation: 0.531407
09/07 09:22:38 PM: Global learning rate: 0.0001
09/07 09:22:38 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 09:22:41 PM: Update 2036: task edges-srl-ontonotes, batch 36 (2036): mcc: 0.4749, acc: 0.3166, precision: 0.6613, recall: 0.3491, f1: 0.4569, edges-srl-ontonotes_loss: 0.0353
09/07 09:22:51 PM: Update 2143: task edges-srl-ontonotes, batch 143 (2143): mcc: 0.4760, acc: 0.3175, precision: 0.6675, recall: 0.3473, f1: 0.4568, edges-srl-ontonotes_loss: 0.0351
09/07 09:23:01 PM: Update 2232: task edges-srl-ontonotes, batch 232 (2232): mcc: 0.4749, acc: 0.3172, precision: 0.6653, recall: 0.3468, f1: 0.4559, edges-srl-ontonotes_loss: 0.0349
09/07 09:23:11 PM: Update 2331: task edges-srl-ontonotes, batch 331 (2331): mcc: 0.4785, acc: 0.3215, precision: 0.6638, recall: 0.3528, f1: 0.4608, edges-srl-ontonotes_loss: 0.0344
09/07 09:23:21 PM: Update 2430: task edges-srl-ontonotes, batch 430 (2430): mcc: 0.4828, acc: 0.3268, precision: 0.6642, recall: 0.3590, f1: 0.4661, edges-srl-ontonotes_loss: 0.0340
09/07 09:23:31 PM: Update 2523: task edges-srl-ontonotes, batch 523 (2523): mcc: 0.4865, acc: 0.3302, precision: 0.6658, recall: 0.3636, f1: 0.4703, edges-srl-ontonotes_loss: 0.0338
09/07 09:23:42 PM: Update 2626: task edges-srl-ontonotes, batch 626 (2626): mcc: 0.4874, acc: 0.3312, precision: 0.6640, recall: 0.3659, f1: 0.4718, edges-srl-ontonotes_loss: 0.0337
09/07 09:23:52 PM: Update 2729: task edges-srl-ontonotes, batch 729 (2729): mcc: 0.4894, acc: 0.3336, precision: 0.6642, recall: 0.3688, f1: 0.4743, edges-srl-ontonotes_loss: 0.0335
09/07 09:24:03 PM: Update 2818: task edges-srl-ontonotes, batch 818 (2818): mcc: 0.4918, acc: 0.3365, precision: 0.6651, recall: 0.3719, f1: 0.4770, edges-srl-ontonotes_loss: 0.0333
09/07 09:24:13 PM: Update 2921: task edges-srl-ontonotes, batch 921 (2921): mcc: 0.4950, acc: 0.3403, precision: 0.6672, recall: 0.3755, f1: 0.4805, edges-srl-ontonotes_loss: 0.0332
09/07 09:24:21 PM: ***** Step 3000 / Validation 3 *****
09/07 09:24:21 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:24:21 PM: Validating...
09/07 09:24:23 PM: Evaluate: task edges-srl-ontonotes, batch 25 (157): mcc: 0.5583, acc: 0.4083, precision: 0.7656, recall: 0.4139, f1: 0.5373, edges-srl-ontonotes_loss: 0.0299
09/07 09:24:33 PM: Evaluate: task edges-srl-ontonotes, batch 132 (157): mcc: 0.5733, acc: 0.4279, precision: 0.7658, recall: 0.4361, f1: 0.5557, edges-srl-ontonotes_loss: 0.0295
09/07 09:24:36 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:24:36 PM: Best result seen so far for macro.
09/07 09:24:36 PM: Updating LR scheduler:
09/07 09:24:36 PM: 	Best result seen so far for macro_avg: 0.550
09/07 09:24:36 PM: 	# validation passes without improvement: 0
09/07 09:24:36 PM: edges-srl-ontonotes_loss: training: 0.033043 validation: 0.029722
09/07 09:24:36 PM: macro_avg: validation: 0.550118
09/07 09:24:36 PM: micro_avg: validation: 0.000000
09/07 09:24:36 PM: edges-srl-ontonotes_mcc: training: 0.497081 validation: 0.567794
09/07 09:24:36 PM: edges-srl-ontonotes_acc: training: 0.342471 validation: 0.422831
09/07 09:24:36 PM: edges-srl-ontonotes_precision: training: 0.668847 validation: 0.760494
09/07 09:24:36 PM: edges-srl-ontonotes_recall: training: 0.377632 validation: 0.430914
09/07 09:24:36 PM: edges-srl-ontonotes_f1: training: 0.482720 validation: 0.550118
09/07 09:24:36 PM: Global learning rate: 0.0001
09/07 09:24:36 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 09:24:43 PM: Update 3079: task edges-srl-ontonotes, batch 79 (3079): mcc: 0.5287, acc: 0.3778, precision: 0.6863, recall: 0.4156, f1: 0.5177, edges-srl-ontonotes_loss: 0.0311
09/07 09:24:53 PM: Update 3170: task edges-srl-ontonotes, batch 170 (3170): mcc: 0.5236, acc: 0.3705, precision: 0.6851, recall: 0.4085, f1: 0.5118, edges-srl-ontonotes_loss: 0.0314
09/07 09:25:03 PM: Update 3275: task edges-srl-ontonotes, batch 275 (3275): mcc: 0.5172, acc: 0.3658, precision: 0.6787, recall: 0.4024, f1: 0.5052, edges-srl-ontonotes_loss: 0.0319
09/07 09:25:13 PM: Update 3380: task edges-srl-ontonotes, batch 380 (3380): mcc: 0.5147, acc: 0.3640, precision: 0.6774, recall: 0.3994, f1: 0.5025, edges-srl-ontonotes_loss: 0.0320
09/07 09:25:23 PM: Update 3471: task edges-srl-ontonotes, batch 471 (3471): mcc: 0.5143, acc: 0.3639, precision: 0.6771, recall: 0.3990, f1: 0.5021, edges-srl-ontonotes_loss: 0.0320
09/07 09:25:33 PM: Update 3581: task edges-srl-ontonotes, batch 581 (3581): mcc: 0.5140, acc: 0.3641, precision: 0.6778, recall: 0.3981, f1: 0.5016, edges-srl-ontonotes_loss: 0.0320
09/07 09:25:43 PM: Update 3681: task edges-srl-ontonotes, batch 681 (3681): mcc: 0.5113, acc: 0.3612, precision: 0.6761, recall: 0.3950, f1: 0.4987, edges-srl-ontonotes_loss: 0.0321
09/07 09:25:53 PM: Update 3773: task edges-srl-ontonotes, batch 773 (3773): mcc: 0.5114, acc: 0.3612, precision: 0.6761, recall: 0.3951, f1: 0.4987, edges-srl-ontonotes_loss: 0.0320
09/07 09:26:04 PM: Update 3877: task edges-srl-ontonotes, batch 877 (3877): mcc: 0.5120, acc: 0.3620, precision: 0.6768, recall: 0.3956, f1: 0.4993, edges-srl-ontonotes_loss: 0.0320
09/07 09:26:14 PM: Update 3980: task edges-srl-ontonotes, batch 980 (3980): mcc: 0.5128, acc: 0.3634, precision: 0.6772, recall: 0.3965, f1: 0.5002, edges-srl-ontonotes_loss: 0.0320
09/07 09:26:16 PM: ***** Step 4000 / Validation 4 *****
09/07 09:26:16 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:26:16 PM: Validating...
09/07 09:26:24 PM: Evaluate: task edges-srl-ontonotes, batch 67 (157): mcc: 0.5659, acc: 0.4108, precision: 0.7856, recall: 0.4141, f1: 0.5423, edges-srl-ontonotes_loss: 0.0301
09/07 09:26:32 PM: Updating LR scheduler:
09/07 09:26:32 PM: 	Best result seen so far for macro_avg: 0.550
09/07 09:26:32 PM: 	# validation passes without improvement: 1
09/07 09:26:32 PM: edges-srl-ontonotes_loss: training: 0.031972 validation: 0.029372
09/07 09:26:32 PM: macro_avg: validation: 0.549184
09/07 09:26:32 PM: micro_avg: validation: 0.000000
09/07 09:26:32 PM: edges-srl-ontonotes_mcc: training: 0.512670 validation: 0.571247
09/07 09:26:32 PM: edges-srl-ontonotes_acc: training: 0.363346 validation: 0.418444
09/07 09:26:32 PM: edges-srl-ontonotes_precision: training: 0.677231 validation: 0.784560
09/07 09:26:32 PM: edges-srl-ontonotes_recall: training: 0.396364 validation: 0.422446
09/07 09:26:32 PM: edges-srl-ontonotes_f1: training: 0.500058 validation: 0.549184
09/07 09:26:32 PM: Global learning rate: 0.0001
09/07 09:26:32 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 09:26:34 PM: Update 4017: task edges-srl-ontonotes, batch 17 (4017): mcc: 0.5169, acc: 0.3770, precision: 0.6825, recall: 0.3997, f1: 0.5042, edges-srl-ontonotes_loss: 0.0324
09/07 09:26:44 PM: Update 4109: task edges-srl-ontonotes, batch 109 (4109): mcc: 0.5226, acc: 0.3775, precision: 0.6869, recall: 0.4057, f1: 0.5102, edges-srl-ontonotes_loss: 0.0314
09/07 09:26:54 PM: Update 4211: task edges-srl-ontonotes, batch 211 (4211): mcc: 0.5261, acc: 0.3813, precision: 0.6847, recall: 0.4125, f1: 0.5149, edges-srl-ontonotes_loss: 0.0311
09/07 09:27:04 PM: Update 4314: task edges-srl-ontonotes, batch 314 (4314): mcc: 0.5268, acc: 0.3820, precision: 0.6849, recall: 0.4136, f1: 0.5157, edges-srl-ontonotes_loss: 0.0310
09/07 09:27:14 PM: Update 4410: task edges-srl-ontonotes, batch 410 (4410): mcc: 0.5301, acc: 0.3859, precision: 0.6856, recall: 0.4182, f1: 0.5195, edges-srl-ontonotes_loss: 0.0308
09/07 09:27:24 PM: Update 4515: task edges-srl-ontonotes, batch 515 (4515): mcc: 0.5306, acc: 0.3869, precision: 0.6849, recall: 0.4195, f1: 0.5203, edges-srl-ontonotes_loss: 0.0308
09/07 09:27:34 PM: Update 4616: task edges-srl-ontonotes, batch 616 (4616): mcc: 0.5313, acc: 0.3877, precision: 0.6854, recall: 0.4201, f1: 0.5210, edges-srl-ontonotes_loss: 0.0307
09/07 09:27:44 PM: Update 4705: task edges-srl-ontonotes, batch 705 (4705): mcc: 0.5320, acc: 0.3885, precision: 0.6854, recall: 0.4212, f1: 0.5218, edges-srl-ontonotes_loss: 0.0308
09/07 09:27:54 PM: Update 4796: task edges-srl-ontonotes, batch 796 (4796): mcc: 0.5276, acc: 0.3840, precision: 0.6830, recall: 0.4159, f1: 0.5170, edges-srl-ontonotes_loss: 0.0311
09/07 09:28:04 PM: Update 4891: task edges-srl-ontonotes, batch 891 (4891): mcc: 0.5254, acc: 0.3813, precision: 0.6822, recall: 0.4130, f1: 0.5145, edges-srl-ontonotes_loss: 0.0312
09/07 09:28:14 PM: Update 4981: task edges-srl-ontonotes, batch 981 (4981): mcc: 0.5245, acc: 0.3804, precision: 0.6823, recall: 0.4115, f1: 0.5134, edges-srl-ontonotes_loss: 0.0313
09/07 09:28:16 PM: ***** Step 5000 / Validation 5 *****
09/07 09:28:16 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:28:16 PM: Validating...
09/07 09:28:24 PM: Evaluate: task edges-srl-ontonotes, batch 84 (157): mcc: 0.5708, acc: 0.4309, precision: 0.7583, recall: 0.4368, f1: 0.5543, edges-srl-ontonotes_loss: 0.0298
09/07 09:28:31 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:28:31 PM: Best result seen so far for macro.
09/07 09:28:31 PM: Updating LR scheduler:
09/07 09:28:31 PM: 	Best result seen so far for macro_avg: 0.562
09/07 09:28:31 PM: 	# validation passes without improvement: 0
09/07 09:28:31 PM: edges-srl-ontonotes_loss: training: 0.031276 validation: 0.029120
09/07 09:28:31 PM: macro_avg: validation: 0.562079
09/07 09:28:31 PM: micro_avg: validation: 0.000000
09/07 09:28:31 PM: edges-srl-ontonotes_mcc: training: 0.524544 validation: 0.578660
09/07 09:28:31 PM: edges-srl-ontonotes_acc: training: 0.380474 validation: 0.439073
09/07 09:28:31 PM: edges-srl-ontonotes_precision: training: 0.682522 validation: 0.766866
09/07 09:28:31 PM: edges-srl-ontonotes_recall: training: 0.411463 validation: 0.443615
09/07 09:28:31 PM: edges-srl-ontonotes_f1: training: 0.513412 validation: 0.562079
09/07 09:28:31 PM: Global learning rate: 0.0001
09/07 09:28:31 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 09:28:35 PM: Update 5009: task edges-srl-ontonotes, batch 9 (5009): mcc: 0.5100, acc: 0.3620, precision: 0.6683, recall: 0.3976, f1: 0.4986, edges-srl-ontonotes_loss: 0.0336
09/07 09:28:45 PM: Update 5120: task edges-srl-ontonotes, batch 120 (5120): mcc: 0.5737, acc: 0.4376, precision: 0.7242, recall: 0.4624, f1: 0.5644, edges-srl-ontonotes_loss: 0.0293
09/07 09:28:55 PM: Update 5237: task edges-srl-ontonotes, batch 237 (5237): mcc: 0.5858, acc: 0.4503, precision: 0.7306, recall: 0.4777, f1: 0.5777, edges-srl-ontonotes_loss: 0.0286
09/07 09:29:05 PM: Update 5336: task edges-srl-ontonotes, batch 336 (5336): mcc: 0.5916, acc: 0.4572, precision: 0.7343, recall: 0.4846, f1: 0.5838, edges-srl-ontonotes_loss: 0.0282
09/07 09:29:15 PM: Update 5459: task edges-srl-ontonotes, batch 459 (5459): mcc: 0.6096, acc: 0.4773, precision: 0.7468, recall: 0.5054, f1: 0.6028, edges-srl-ontonotes_loss: 0.0272
09/07 09:29:25 PM: Update 5585: task edges-srl-ontonotes, batch 585 (5585): mcc: 0.6251, acc: 0.4957, precision: 0.7565, recall: 0.5243, f1: 0.6193, edges-srl-ontonotes_loss: 0.0264
09/07 09:29:35 PM: Update 5693: task edges-srl-ontonotes, batch 693 (5693): mcc: 0.6325, acc: 0.5043, precision: 0.7600, recall: 0.5340, f1: 0.6273, edges-srl-ontonotes_loss: 0.0260
09/07 09:29:45 PM: Update 5814: task edges-srl-ontonotes, batch 814 (5814): mcc: 0.6392, acc: 0.5123, precision: 0.7638, recall: 0.5424, f1: 0.6343, edges-srl-ontonotes_loss: 0.0256
09/07 09:29:55 PM: Update 5936: task edges-srl-ontonotes, batch 936 (5936): mcc: 0.6455, acc: 0.5199, precision: 0.7669, recall: 0.5508, f1: 0.6411, edges-srl-ontonotes_loss: 0.0253
09/07 09:30:03 PM: ***** Step 6000 / Validation 6 *****
09/07 09:30:03 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:30:03 PM: Validating...
09/07 09:30:05 PM: Evaluate: task edges-srl-ontonotes, batch 21 (157): mcc: 0.6204, acc: 0.4718, precision: 0.8171, recall: 0.4773, f1: 0.6026, edges-srl-ontonotes_loss: 0.0264
09/07 09:30:15 PM: Evaluate: task edges-srl-ontonotes, batch 129 (157): mcc: 0.6416, acc: 0.5105, precision: 0.8093, recall: 0.5153, f1: 0.6296, edges-srl-ontonotes_loss: 0.0261
09/07 09:30:18 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:30:18 PM: Best result seen so far for macro.
09/07 09:30:18 PM: Updating LR scheduler:
09/07 09:30:18 PM: 	Best result seen so far for macro_avg: 0.616
09/07 09:30:18 PM: 	# validation passes without improvement: 0
09/07 09:30:18 PM: edges-srl-ontonotes_loss: training: 0.025123 validation: 0.026889
09/07 09:30:18 PM: macro_avg: validation: 0.616296
09/07 09:30:18 PM: micro_avg: validation: 0.000000
09/07 09:30:18 PM: edges-srl-ontonotes_mcc: training: 0.648466 validation: 0.629289
09/07 09:30:18 PM: edges-srl-ontonotes_acc: training: 0.523338 validation: 0.495728
09/07 09:30:18 PM: edges-srl-ontonotes_precision: training: 0.769240 validation: 0.801998
09/07 09:30:18 PM: edges-srl-ontonotes_recall: training: 0.554109 validation: 0.500423
09/07 09:30:18 PM: edges-srl-ontonotes_f1: training: 0.644188 validation: 0.616296
09/07 09:30:18 PM: Global learning rate: 0.0001
09/07 09:30:18 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 09:30:25 PM: Update 6092: task edges-srl-ontonotes, batch 92 (6092): mcc: 0.6957, acc: 0.5856, precision: 0.7945, recall: 0.6163, f1: 0.6941, edges-srl-ontonotes_loss: 0.0227
09/07 09:30:35 PM: Update 6215: task edges-srl-ontonotes, batch 215 (6215): mcc: 0.7019, acc: 0.5908, precision: 0.8000, recall: 0.6228, f1: 0.7004, edges-srl-ontonotes_loss: 0.0223
09/07 09:30:45 PM: Update 6323: task edges-srl-ontonotes, batch 323 (6323): mcc: 0.7088, acc: 0.6004, precision: 0.8047, recall: 0.6310, f1: 0.7074, edges-srl-ontonotes_loss: 0.0221
09/07 09:30:55 PM: Update 6443: task edges-srl-ontonotes, batch 443 (6443): mcc: 0.7170, acc: 0.6112, precision: 0.8120, recall: 0.6397, f1: 0.7156, edges-srl-ontonotes_loss: 0.0217
09/07 09:31:05 PM: Update 6566: task edges-srl-ontonotes, batch 566 (6566): mcc: 0.7261, acc: 0.6236, precision: 0.8187, recall: 0.6505, f1: 0.7250, edges-srl-ontonotes_loss: 0.0212
09/07 09:31:16 PM: Update 6656: task edges-srl-ontonotes, batch 656 (6656): mcc: 0.7134, acc: 0.6087, precision: 0.8093, recall: 0.6355, f1: 0.7120, edges-srl-ontonotes_loss: 0.0220
09/07 09:31:26 PM: Update 6766: task edges-srl-ontonotes, batch 766 (6766): mcc: 0.7024, acc: 0.5955, precision: 0.8013, recall: 0.6227, f1: 0.7008, edges-srl-ontonotes_loss: 0.0226
09/07 09:31:36 PM: Update 6867: task edges-srl-ontonotes, batch 867 (6867): mcc: 0.6945, acc: 0.5862, precision: 0.7957, recall: 0.6131, f1: 0.6926, edges-srl-ontonotes_loss: 0.0231
09/07 09:31:46 PM: Update 6955: task edges-srl-ontonotes, batch 955 (6955): mcc: 0.6852, acc: 0.5751, precision: 0.7894, recall: 0.6019, f1: 0.6830, edges-srl-ontonotes_loss: 0.0236
09/07 09:31:50 PM: ***** Step 7000 / Validation 7 *****
09/07 09:31:50 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:31:50 PM: Validating...
09/07 09:31:56 PM: Evaluate: task edges-srl-ontonotes, batch 58 (157): mcc: 0.6395, acc: 0.5032, precision: 0.8213, recall: 0.5042, f1: 0.6248, edges-srl-ontonotes_loss: 0.0266
09/07 09:32:06 PM: Evaluate: task edges-srl-ontonotes, batch 145 (157): mcc: 0.6495, acc: 0.5225, precision: 0.8158, recall: 0.5236, f1: 0.6378, edges-srl-ontonotes_loss: 0.0258
09/07 09:32:07 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:32:07 PM: Best result seen so far for macro.
09/07 09:32:07 PM: Updating LR scheduler:
09/07 09:32:07 PM: 	Best result seen so far for macro_avg: 0.635
09/07 09:32:07 PM: 	# validation passes without improvement: 0
09/07 09:32:07 PM: edges-srl-ontonotes_loss: training: 0.023926 validation: 0.025983
09/07 09:32:07 PM: macro_avg: validation: 0.635275
09/07 09:32:07 PM: micro_avg: validation: 0.000000
09/07 09:32:07 PM: edges-srl-ontonotes_mcc: training: 0.679718 validation: 0.647116
09/07 09:32:07 PM: edges-srl-ontonotes_acc: training: 0.568526 validation: 0.519744
09/07 09:32:07 PM: edges-srl-ontonotes_precision: training: 0.785919 validation: 0.814200
09/07 09:32:07 PM: edges-srl-ontonotes_recall: training: 0.595041 validation: 0.520822
09/07 09:32:07 PM: edges-srl-ontonotes_f1: training: 0.677288 validation: 0.635275
09/07 09:32:07 PM: Global learning rate: 0.0001
09/07 09:32:07 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 09:32:16 PM: Update 7094: task edges-srl-ontonotes, batch 94 (7094): mcc: 0.5946, acc: 0.4693, precision: 0.7278, recall: 0.4939, f1: 0.5885, edges-srl-ontonotes_loss: 0.0284
09/07 09:32:26 PM: Update 7198: task edges-srl-ontonotes, batch 198 (7198): mcc: 0.5903, acc: 0.4632, precision: 0.7257, recall: 0.4883, f1: 0.5838, edges-srl-ontonotes_loss: 0.0287
09/07 09:32:36 PM: Update 7296: task edges-srl-ontonotes, batch 296 (7296): mcc: 0.6015, acc: 0.4739, precision: 0.7390, recall: 0.4975, f1: 0.5947, edges-srl-ontonotes_loss: 0.0284
09/07 09:32:46 PM: Update 7411: task edges-srl-ontonotes, batch 411 (7411): mcc: 0.6128, acc: 0.4867, precision: 0.7468, recall: 0.5106, f1: 0.6065, edges-srl-ontonotes_loss: 0.0277
09/07 09:32:56 PM: Update 7524: task edges-srl-ontonotes, batch 524 (7524): mcc: 0.6204, acc: 0.4956, precision: 0.7526, recall: 0.5192, f1: 0.6145, edges-srl-ontonotes_loss: 0.0273
09/07 09:33:06 PM: Update 7623: task edges-srl-ontonotes, batch 623 (7623): mcc: 0.6266, acc: 0.5027, precision: 0.7567, recall: 0.5265, f1: 0.6210, edges-srl-ontonotes_loss: 0.0270
09/07 09:33:16 PM: Update 7738: task edges-srl-ontonotes, batch 738 (7738): mcc: 0.6349, acc: 0.5121, precision: 0.7624, recall: 0.5363, f1: 0.6297, edges-srl-ontonotes_loss: 0.0266
09/07 09:33:26 PM: Update 7851: task edges-srl-ontonotes, batch 851 (7851): mcc: 0.6406, acc: 0.5190, precision: 0.7662, recall: 0.5431, f1: 0.6356, edges-srl-ontonotes_loss: 0.0262
09/07 09:33:36 PM: Update 7951: task edges-srl-ontonotes, batch 951 (7951): mcc: 0.6376, acc: 0.5159, precision: 0.7631, recall: 0.5403, f1: 0.6327, edges-srl-ontonotes_loss: 0.0263
09/07 09:33:41 PM: ***** Step 8000 / Validation 8 *****
09/07 09:33:41 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:33:41 PM: Validating...
09/07 09:33:46 PM: Evaluate: task edges-srl-ontonotes, batch 60 (157): mcc: 0.6661, acc: 0.5493, precision: 0.8155, recall: 0.5507, f1: 0.6574, edges-srl-ontonotes_loss: 0.0245
09/07 09:33:55 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:33:55 PM: Best result seen so far for macro.
09/07 09:33:55 PM: Updating LR scheduler:
09/07 09:33:55 PM: 	Best result seen so far for macro_avg: 0.668
09/07 09:33:55 PM: 	# validation passes without improvement: 0
09/07 09:33:55 PM: edges-srl-ontonotes_loss: training: 0.026382 validation: 0.023879
09/07 09:33:55 PM: macro_avg: validation: 0.667513
09/07 09:33:55 PM: micro_avg: validation: 0.000000
09/07 09:33:55 PM: edges-srl-ontonotes_mcc: training: 0.636682 validation: 0.674287
09/07 09:33:55 PM: edges-srl-ontonotes_acc: training: 0.514825 validation: 0.565314
09/07 09:33:55 PM: edges-srl-ontonotes_precision: training: 0.762264 validation: 0.811481
09/07 09:33:55 PM: edges-srl-ontonotes_recall: training: 0.539346 validation: 0.566931
09/07 09:33:55 PM: edges-srl-ontonotes_f1: training: 0.631716 validation: 0.667513
09/07 09:33:55 PM: Global learning rate: 0.0001
09/07 09:33:55 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 09:33:56 PM: Update 8011: task edges-srl-ontonotes, batch 11 (8011): mcc: 0.5963, acc: 0.4727, precision: 0.7237, recall: 0.4994, f1: 0.5910, edges-srl-ontonotes_loss: 0.0282
09/07 09:34:06 PM: Update 8125: task edges-srl-ontonotes, batch 125 (8125): mcc: 0.6030, acc: 0.4820, precision: 0.7286, recall: 0.5072, f1: 0.5981, edges-srl-ontonotes_loss: 0.0277
09/07 09:34:16 PM: Update 8203: task edges-srl-ontonotes, batch 203 (8203): mcc: 0.5978, acc: 0.4763, precision: 0.7254, recall: 0.5008, f1: 0.5925, edges-srl-ontonotes_loss: 0.0281
09/07 09:34:26 PM: Update 8314: task edges-srl-ontonotes, batch 314 (8314): mcc: 0.5923, acc: 0.4697, precision: 0.7214, recall: 0.4946, f1: 0.5868, edges-srl-ontonotes_loss: 0.0284
09/07 09:34:37 PM: Update 8424: task edges-srl-ontonotes, batch 424 (8424): mcc: 0.5889, acc: 0.4655, precision: 0.7192, recall: 0.4904, f1: 0.5831, edges-srl-ontonotes_loss: 0.0286
09/07 09:34:47 PM: Update 8518: task edges-srl-ontonotes, batch 518 (8518): mcc: 0.5863, acc: 0.4620, precision: 0.7179, recall: 0.4870, f1: 0.5803, edges-srl-ontonotes_loss: 0.0287
09/07 09:34:57 PM: Update 8622: task edges-srl-ontonotes, batch 622 (8622): mcc: 0.5836, acc: 0.4584, precision: 0.7157, recall: 0.4841, f1: 0.5775, edges-srl-ontonotes_loss: 0.0288
09/07 09:35:07 PM: Update 8728: task edges-srl-ontonotes, batch 728 (8728): mcc: 0.5825, acc: 0.4579, precision: 0.7142, recall: 0.4835, f1: 0.5766, edges-srl-ontonotes_loss: 0.0288
09/07 09:35:17 PM: Update 8825: task edges-srl-ontonotes, batch 825 (8825): mcc: 0.5830, acc: 0.4585, precision: 0.7146, recall: 0.4839, f1: 0.5770, edges-srl-ontonotes_loss: 0.0287
09/07 09:35:27 PM: Update 8927: task edges-srl-ontonotes, batch 927 (8927): mcc: 0.5783, acc: 0.4531, precision: 0.7120, recall: 0.4781, f1: 0.5720, edges-srl-ontonotes_loss: 0.0290
09/07 09:35:34 PM: ***** Step 9000 / Validation 9 *****
09/07 09:35:34 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:35:34 PM: Validating...
09/07 09:35:37 PM: Evaluate: task edges-srl-ontonotes, batch 28 (157): mcc: 0.6571, acc: 0.5292, precision: 0.8240, recall: 0.5304, f1: 0.6454, edges-srl-ontonotes_loss: 0.0244
09/07 09:35:47 PM: Evaluate: task edges-srl-ontonotes, batch 135 (157): mcc: 0.6746, acc: 0.5613, precision: 0.8158, recall: 0.5643, f1: 0.6672, edges-srl-ontonotes_loss: 0.0238
09/07 09:35:49 PM: Updating LR scheduler:
09/07 09:35:49 PM: 	Best result seen so far for macro_avg: 0.668
09/07 09:35:49 PM: 	# validation passes without improvement: 1
09/07 09:35:49 PM: edges-srl-ontonotes_loss: training: 0.029134 validation: 0.024129
09/07 09:35:49 PM: macro_avg: validation: 0.661220
09/07 09:35:49 PM: micro_avg: validation: 0.000000
09/07 09:35:49 PM: edges-srl-ontonotes_mcc: training: 0.575539 validation: 0.668932
09/07 09:35:49 PM: edges-srl-ontonotes_acc: training: 0.449613 validation: 0.554384
09/07 09:35:49 PM: edges-srl-ontonotes_precision: training: 0.710808 validation: 0.812108
09/07 09:35:49 PM: edges-srl-ontonotes_recall: training: 0.474316 validation: 0.557617
09/07 09:35:49 PM: edges-srl-ontonotes_f1: training: 0.568966 validation: 0.661220
09/07 09:35:49 PM: Global learning rate: 0.0001
09/07 09:35:49 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 09:35:57 PM: Update 9084: task edges-srl-ontonotes, batch 84 (9084): mcc: 0.5620, acc: 0.4344, precision: 0.7059, recall: 0.4556, f1: 0.5538, edges-srl-ontonotes_loss: 0.0299
09/07 09:36:07 PM: Update 9155: task edges-srl-ontonotes, batch 155 (9155): mcc: 0.5581, acc: 0.4277, precision: 0.7046, recall: 0.4503, f1: 0.5495, edges-srl-ontonotes_loss: 0.0301
09/07 09:36:17 PM: Update 9262: task edges-srl-ontonotes, batch 262 (9262): mcc: 0.5534, acc: 0.4228, precision: 0.7011, recall: 0.4450, f1: 0.5444, edges-srl-ontonotes_loss: 0.0303
09/07 09:36:27 PM: Update 9367: task edges-srl-ontonotes, batch 367 (9367): mcc: 0.5559, acc: 0.4257, precision: 0.7026, recall: 0.4481, f1: 0.5472, edges-srl-ontonotes_loss: 0.0302
09/07 09:36:37 PM: Update 9457: task edges-srl-ontonotes, batch 457 (9457): mcc: 0.5562, acc: 0.4256, precision: 0.7036, recall: 0.4479, f1: 0.5474, edges-srl-ontonotes_loss: 0.0302
09/07 09:36:47 PM: Update 9559: task edges-srl-ontonotes, batch 559 (9559): mcc: 0.5592, acc: 0.4292, precision: 0.7044, recall: 0.4522, f1: 0.5508, edges-srl-ontonotes_loss: 0.0298
09/07 09:36:57 PM: Update 9660: task edges-srl-ontonotes, batch 660 (9660): mcc: 0.5610, acc: 0.4313, precision: 0.7040, recall: 0.4554, f1: 0.5530, edges-srl-ontonotes_loss: 0.0297
09/07 09:37:07 PM: Update 9751: task edges-srl-ontonotes, batch 751 (9751): mcc: 0.5616, acc: 0.4321, precision: 0.7038, recall: 0.4565, f1: 0.5538, edges-srl-ontonotes_loss: 0.0296
09/07 09:37:17 PM: Update 9857: task edges-srl-ontonotes, batch 857 (9857): mcc: 0.5634, acc: 0.4340, precision: 0.7046, recall: 0.4589, f1: 0.5558, edges-srl-ontonotes_loss: 0.0294
09/07 09:37:27 PM: Update 9961: task edges-srl-ontonotes, batch 961 (9961): mcc: 0.5640, acc: 0.4342, precision: 0.7044, recall: 0.4598, f1: 0.5564, edges-srl-ontonotes_loss: 0.0294
09/07 09:37:31 PM: ***** Step 10000 / Validation 10 *****
09/07 09:37:31 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:37:31 PM: Validating...
09/07 09:37:37 PM: Evaluate: task edges-srl-ontonotes, batch 67 (157): mcc: 0.6444, acc: 0.5225, precision: 0.8036, recall: 0.5234, f1: 0.6339, edges-srl-ontonotes_loss: 0.0254
09/07 09:37:46 PM: Updating LR scheduler:
09/07 09:37:46 PM: 	Best result seen so far for macro_avg: 0.668
09/07 09:37:46 PM: 	# validation passes without improvement: 2
09/07 09:37:46 PM: edges-srl-ontonotes_loss: training: 0.029343 validation: 0.024785
09/07 09:37:46 PM: macro_avg: validation: 0.643331
09/07 09:37:46 PM: micro_avg: validation: 0.000000
09/07 09:37:46 PM: edges-srl-ontonotes_mcc: training: 0.564118 validation: 0.653373
09/07 09:37:46 PM: edges-srl-ontonotes_acc: training: 0.434495 validation: 0.532215
09/07 09:37:46 PM: edges-srl-ontonotes_precision: training: 0.704290 validation: 0.810409
09/07 09:37:46 PM: edges-srl-ontonotes_recall: training: 0.460178 validation: 0.533369
09/07 09:37:46 PM: edges-srl-ontonotes_f1: training: 0.556647 validation: 0.643331
09/07 09:37:46 PM: Global learning rate: 0.0001
09/07 09:37:46 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 09:37:48 PM: Update 10017: task edges-srl-ontonotes, batch 17 (10017): mcc: 0.5782, acc: 0.4458, precision: 0.7185, recall: 0.4735, f1: 0.5708, edges-srl-ontonotes_loss: 0.0281
09/07 09:37:58 PM: Update 10090: task edges-srl-ontonotes, batch 90 (10090): mcc: 0.5911, acc: 0.4633, precision: 0.7257, recall: 0.4895, f1: 0.5846, edges-srl-ontonotes_loss: 0.0278
09/07 09:38:08 PM: Update 10191: task edges-srl-ontonotes, batch 191 (10191): mcc: 0.5883, acc: 0.4620, precision: 0.7204, recall: 0.4886, f1: 0.5823, edges-srl-ontonotes_loss: 0.0279
09/07 09:38:18 PM: Update 10294: task edges-srl-ontonotes, batch 294 (10294): mcc: 0.5903, acc: 0.4640, precision: 0.7224, recall: 0.4905, f1: 0.5843, edges-srl-ontonotes_loss: 0.0279
09/07 09:38:28 PM: Update 10385: task edges-srl-ontonotes, batch 385 (10385): mcc: 0.5911, acc: 0.4645, precision: 0.7224, recall: 0.4919, f1: 0.5853, edges-srl-ontonotes_loss: 0.0278
09/07 09:38:38 PM: Update 10489: task edges-srl-ontonotes, batch 489 (10489): mcc: 0.5865, acc: 0.4597, precision: 0.7181, recall: 0.4873, f1: 0.5806, edges-srl-ontonotes_loss: 0.0280
09/07 09:38:48 PM: Update 10592: task edges-srl-ontonotes, batch 592 (10592): mcc: 0.5831, acc: 0.4555, precision: 0.7162, recall: 0.4830, f1: 0.5769, edges-srl-ontonotes_loss: 0.0283
09/07 09:38:59 PM: Update 10690: task edges-srl-ontonotes, batch 690 (10690): mcc: 0.5826, acc: 0.4550, precision: 0.7163, recall: 0.4821, f1: 0.5763, edges-srl-ontonotes_loss: 0.0283
09/07 09:39:09 PM: Update 10794: task edges-srl-ontonotes, batch 794 (10794): mcc: 0.5810, acc: 0.4532, precision: 0.7150, recall: 0.4803, f1: 0.5746, edges-srl-ontonotes_loss: 0.0284
09/07 09:39:19 PM: Update 10898: task edges-srl-ontonotes, batch 898 (10898): mcc: 0.5810, acc: 0.4528, precision: 0.7158, recall: 0.4799, f1: 0.5745, edges-srl-ontonotes_loss: 0.0284
09/07 09:39:29 PM: ***** Step 11000 / Validation 11 *****
09/07 09:39:29 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:39:29 PM: Validating...
09/07 09:39:29 PM: Evaluate: task edges-srl-ontonotes, batch 2 (157): mcc: 0.5973, acc: 0.4432, precision: 0.8061, recall: 0.4489, f1: 0.5766, edges-srl-ontonotes_loss: 0.0272
09/07 09:39:39 PM: Evaluate: task edges-srl-ontonotes, batch 109 (157): mcc: 0.6524, acc: 0.5356, precision: 0.8018, recall: 0.5375, f1: 0.6436, edges-srl-ontonotes_loss: 0.0252
09/07 09:39:43 PM: Updating LR scheduler:
09/07 09:39:43 PM: 	Best result seen so far for macro_avg: 0.668
09/07 09:39:43 PM: 	# validation passes without improvement: 3
09/07 09:39:43 PM: edges-srl-ontonotes_loss: training: 0.028491 validation: 0.024995
09/07 09:39:43 PM: macro_avg: validation: 0.645486
09/07 09:39:43 PM: micro_avg: validation: 0.000000
09/07 09:39:43 PM: edges-srl-ontonotes_mcc: training: 0.579266 validation: 0.654419
09/07 09:39:43 PM: edges-srl-ontonotes_acc: training: 0.451049 validation: 0.536756
09/07 09:39:43 PM: edges-srl-ontonotes_precision: training: 0.714558 validation: 0.804945
09/07 09:39:43 PM: edges-srl-ontonotes_recall: training: 0.477838 validation: 0.538758
09/07 09:39:43 PM: edges-srl-ontonotes_f1: training: 0.572701 validation: 0.645486
09/07 09:39:43 PM: Global learning rate: 0.0001
09/07 09:39:43 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 09:39:49 PM: Update 11047: task edges-srl-ontonotes, batch 47 (11047): mcc: 0.5750, acc: 0.4403, precision: 0.7186, recall: 0.4682, f1: 0.5670, edges-srl-ontonotes_loss: 0.0289
09/07 09:39:59 PM: Update 11150: task edges-srl-ontonotes, batch 150 (11150): mcc: 0.5787, acc: 0.4480, precision: 0.7200, recall: 0.4732, f1: 0.5711, edges-srl-ontonotes_loss: 0.0287
09/07 09:40:09 PM: Update 11253: task edges-srl-ontonotes, batch 253 (11253): mcc: 0.5763, acc: 0.4461, precision: 0.7174, recall: 0.4711, f1: 0.5687, edges-srl-ontonotes_loss: 0.0286
09/07 09:40:19 PM: Update 11323: task edges-srl-ontonotes, batch 323 (11323): mcc: 0.5761, acc: 0.4464, precision: 0.7170, recall: 0.4710, f1: 0.5685, edges-srl-ontonotes_loss: 0.0286
09/07 09:40:29 PM: Update 11427: task edges-srl-ontonotes, batch 427 (11427): mcc: 0.5789, acc: 0.4504, precision: 0.7184, recall: 0.4746, f1: 0.5716, edges-srl-ontonotes_loss: 0.0285
09/07 09:40:39 PM: Update 11531: task edges-srl-ontonotes, batch 531 (11531): mcc: 0.5834, acc: 0.4561, precision: 0.7199, recall: 0.4809, f1: 0.5766, edges-srl-ontonotes_loss: 0.0283
09/07 09:40:50 PM: Update 11629: task edges-srl-ontonotes, batch 629 (11629): mcc: 0.5841, acc: 0.4575, precision: 0.7190, recall: 0.4827, f1: 0.5776, edges-srl-ontonotes_loss: 0.0282
09/07 09:41:00 PM: Update 11731: task edges-srl-ontonotes, batch 731 (11731): mcc: 0.5850, acc: 0.4585, precision: 0.7189, recall: 0.4842, f1: 0.5787, edges-srl-ontonotes_loss: 0.0282
09/07 09:41:10 PM: Update 11833: task edges-srl-ontonotes, batch 833 (11833): mcc: 0.5867, acc: 0.4603, precision: 0.7199, recall: 0.4863, f1: 0.5805, edges-srl-ontonotes_loss: 0.0281
09/07 09:41:20 PM: Update 11936: task edges-srl-ontonotes, batch 936 (11936): mcc: 0.5876, acc: 0.4616, precision: 0.7200, recall: 0.4877, f1: 0.5815, edges-srl-ontonotes_loss: 0.0280
09/07 09:41:28 PM: ***** Step 12000 / Validation 12 *****
09/07 09:41:28 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:41:28 PM: Validating...
09/07 09:41:30 PM: Evaluate: task edges-srl-ontonotes, batch 22 (157): mcc: 0.6430, acc: 0.5197, precision: 0.8028, recall: 0.5218, f1: 0.6325, edges-srl-ontonotes_loss: 0.0250
09/07 09:41:40 PM: Evaluate: task edges-srl-ontonotes, batch 129 (157): mcc: 0.6526, acc: 0.5426, precision: 0.7908, recall: 0.5455, f1: 0.6456, edges-srl-ontonotes_loss: 0.0254
09/07 09:41:43 PM: Updating LR scheduler:
09/07 09:41:43 PM: 	Best result seen so far for macro_avg: 0.668
09/07 09:41:43 PM: 	# validation passes without improvement: 4
09/07 09:41:43 PM: edges-srl-ontonotes_loss: training: 0.028186 validation: 0.025640
09/07 09:41:43 PM: macro_avg: validation: 0.640636
09/07 09:41:43 PM: micro_avg: validation: 0.000000
09/07 09:41:43 PM: edges-srl-ontonotes_mcc: training: 0.584735 validation: 0.647812
09/07 09:41:43 PM: edges-srl-ontonotes_acc: training: 0.458250 validation: 0.536833
09/07 09:41:43 PM: edges-srl-ontonotes_precision: training: 0.718563 validation: 0.787559
09/07 09:41:43 PM: edges-srl-ontonotes_recall: training: 0.484036 validation: 0.539912
09/07 09:41:43 PM: edges-srl-ontonotes_f1: training: 0.578431 validation: 0.640636
09/07 09:41:43 PM: Global learning rate: 0.0001
09/07 09:41:43 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 09:41:50 PM: Update 12067: task edges-srl-ontonotes, batch 67 (12067): mcc: 0.5461, acc: 0.4105, precision: 0.7053, recall: 0.4310, f1: 0.5350, edges-srl-ontonotes_loss: 0.0309
09/07 09:42:00 PM: Update 12162: task edges-srl-ontonotes, batch 162 (12162): mcc: 0.5523, acc: 0.4179, precision: 0.7066, recall: 0.4398, f1: 0.5421, edges-srl-ontonotes_loss: 0.0301
09/07 09:42:13 PM: Update 12255: task edges-srl-ontonotes, batch 255 (12255): mcc: 0.5548, acc: 0.4226, precision: 0.7050, recall: 0.4447, f1: 0.5454, edges-srl-ontonotes_loss: 0.0300
09/07 09:42:23 PM: Update 12367: task edges-srl-ontonotes, batch 367 (12367): mcc: 0.5806, acc: 0.4517, precision: 0.7228, recall: 0.4745, f1: 0.5729, edges-srl-ontonotes_loss: 0.0287
09/07 09:42:33 PM: Update 12482: task edges-srl-ontonotes, batch 482 (12482): mcc: 0.6007, acc: 0.4744, precision: 0.7364, recall: 0.4979, f1: 0.5941, edges-srl-ontonotes_loss: 0.0276
09/07 09:42:43 PM: Update 12584: task edges-srl-ontonotes, batch 584 (12584): mcc: 0.6153, acc: 0.4911, precision: 0.7463, recall: 0.5151, f1: 0.6095, edges-srl-ontonotes_loss: 0.0269
09/07 09:42:53 PM: Update 12710: task edges-srl-ontonotes, batch 710 (12710): mcc: 0.6354, acc: 0.5146, precision: 0.7589, recall: 0.5396, f1: 0.6307, edges-srl-ontonotes_loss: 0.0259
09/07 09:43:03 PM: Update 12834: task edges-srl-ontonotes, batch 834 (12834): mcc: 0.6497, acc: 0.5324, precision: 0.7675, recall: 0.5574, f1: 0.6458, edges-srl-ontonotes_loss: 0.0250
09/07 09:43:13 PM: Update 12943: task edges-srl-ontonotes, batch 943 (12943): mcc: 0.6584, acc: 0.5434, precision: 0.7727, recall: 0.5684, f1: 0.6550, edges-srl-ontonotes_loss: 0.0246
09/07 09:43:18 PM: ***** Step 13000 / Validation 13 *****
09/07 09:43:18 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:43:18 PM: Validating...
09/07 09:43:23 PM: Evaluate: task edges-srl-ontonotes, batch 59 (157): mcc: 0.6646, acc: 0.5625, precision: 0.7901, recall: 0.5661, f1: 0.6596, edges-srl-ontonotes_loss: 0.0253
09/07 09:43:33 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:43:33 PM: Best result seen so far for macro.
09/07 09:43:33 PM: Updating LR scheduler:
09/07 09:43:33 PM: 	Best result seen so far for macro_avg: 0.671
09/07 09:43:33 PM: 	# validation passes without improvement: 0
09/07 09:43:33 PM: edges-srl-ontonotes_loss: training: 0.024297 validation: 0.024568
09/07 09:43:33 PM: macro_avg: validation: 0.670901
09/07 09:43:33 PM: micro_avg: validation: 0.000000
09/07 09:43:33 PM: edges-srl-ontonotes_mcc: training: 0.662769 validation: 0.674901
09/07 09:43:33 PM: edges-srl-ontonotes_acc: training: 0.548815 validation: 0.578246
09/07 09:43:33 PM: edges-srl-ontonotes_precision: training: 0.775385 validation: 0.793111
09/07 09:43:33 PM: edges-srl-ontonotes_recall: training: 0.573877 validation: 0.581326
09/07 09:43:33 PM: edges-srl-ontonotes_f1: training: 0.659584 validation: 0.670901
09/07 09:43:33 PM: Global learning rate: 0.0001
09/07 09:43:33 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 09:43:34 PM: Update 13010: task edges-srl-ontonotes, batch 10 (13010): mcc: 0.7110, acc: 0.6114, precision: 0.8102, recall: 0.6307, f1: 0.7093, edges-srl-ontonotes_loss: 0.0215
09/07 09:43:44 PM: Update 13132: task edges-srl-ontonotes, batch 132 (13132): mcc: 0.7185, acc: 0.6214, precision: 0.8041, recall: 0.6488, f1: 0.7181, edges-srl-ontonotes_loss: 0.0208
09/07 09:43:54 PM: Update 13241: task edges-srl-ontonotes, batch 241 (13241): mcc: 0.7243, acc: 0.6285, precision: 0.8077, recall: 0.6561, f1: 0.7241, edges-srl-ontonotes_loss: 0.0204
09/07 09:44:04 PM: Update 13363: task edges-srl-ontonotes, batch 363 (13363): mcc: 0.7302, acc: 0.6361, precision: 0.8118, recall: 0.6633, f1: 0.7301, edges-srl-ontonotes_loss: 0.0202
09/07 09:44:14 PM: Update 13486: task edges-srl-ontonotes, batch 486 (13486): mcc: 0.7355, acc: 0.6425, precision: 0.8158, recall: 0.6695, f1: 0.7354, edges-srl-ontonotes_loss: 0.0199
09/07 09:44:24 PM: Update 13577: task edges-srl-ontonotes, batch 577 (13577): mcc: 0.7401, acc: 0.6488, precision: 0.8197, recall: 0.6746, f1: 0.7401, edges-srl-ontonotes_loss: 0.0198
09/07 09:44:34 PM: Update 13703: task edges-srl-ontonotes, batch 703 (13703): mcc: 0.7473, acc: 0.6581, precision: 0.8254, recall: 0.6828, f1: 0.7474, edges-srl-ontonotes_loss: 0.0195
09/07 09:44:44 PM: Update 13820: task edges-srl-ontonotes, batch 820 (13820): mcc: 0.7518, acc: 0.6642, precision: 0.8286, recall: 0.6883, f1: 0.7520, edges-srl-ontonotes_loss: 0.0192
09/07 09:44:54 PM: Update 13923: task edges-srl-ontonotes, batch 923 (13923): mcc: 0.7413, acc: 0.6508, precision: 0.8213, recall: 0.6755, f1: 0.7413, edges-srl-ontonotes_loss: 0.0199
09/07 09:45:02 PM: ***** Step 14000 / Validation 14 *****
09/07 09:45:02 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:45:02 PM: Validating...
09/07 09:45:04 PM: Evaluate: task edges-srl-ontonotes, batch 29 (157): mcc: 0.6764, acc: 0.5654, precision: 0.8088, recall: 0.5723, f1: 0.6703, edges-srl-ontonotes_loss: 0.0236
09/07 09:45:14 PM: Evaluate: task edges-srl-ontonotes, batch 136 (157): mcc: 0.6945, acc: 0.6015, precision: 0.8044, recall: 0.6064, f1: 0.6915, edges-srl-ontonotes_loss: 0.0231
09/07 09:45:16 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:45:16 PM: Best result seen so far for macro.
09/07 09:45:16 PM: Updating LR scheduler:
09/07 09:45:16 PM: 	Best result seen so far for macro_avg: 0.684
09/07 09:45:16 PM: 	# validation passes without improvement: 0
09/07 09:45:16 PM: edges-srl-ontonotes_loss: training: 0.020284 validation: 0.023609
09/07 09:45:16 PM: macro_avg: validation: 0.683877
09/07 09:45:16 PM: micro_avg: validation: 0.000000
09/07 09:45:16 PM: edges-srl-ontonotes_mcc: training: 0.735312 validation: 0.687137
09/07 09:45:16 PM: edges-srl-ontonotes_acc: training: 0.643493 validation: 0.592641
09/07 09:45:16 PM: edges-srl-ontonotes_precision: training: 0.817228 validation: 0.799464
09/07 09:45:16 PM: edges-srl-ontonotes_recall: training: 0.668055 validation: 0.597491
09/07 09:45:16 PM: edges-srl-ontonotes_f1: training: 0.735150 validation: 0.683877
09/07 09:45:16 PM: Global learning rate: 0.0001
09/07 09:45:16 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 09:45:24 PM: Update 14090: task edges-srl-ontonotes, batch 90 (14090): mcc: 0.6701, acc: 0.5647, precision: 0.7695, recall: 0.5910, f1: 0.6685, edges-srl-ontonotes_loss: 0.0234
09/07 09:45:34 PM: Update 14177: task edges-srl-ontonotes, batch 177 (14177): mcc: 0.6494, acc: 0.5403, precision: 0.7564, recall: 0.5652, f1: 0.6470, edges-srl-ontonotes_loss: 0.0250
09/07 09:45:44 PM: Update 14283: task edges-srl-ontonotes, batch 283 (14283): mcc: 0.6357, acc: 0.5232, precision: 0.7477, recall: 0.5484, f1: 0.6327, edges-srl-ontonotes_loss: 0.0257
09/07 09:45:54 PM: Update 14389: task edges-srl-ontonotes, batch 389 (14389): mcc: 0.6303, acc: 0.5164, precision: 0.7447, recall: 0.5414, f1: 0.6270, edges-srl-ontonotes_loss: 0.0260
09/07 09:46:07 PM: Update 14493: task edges-srl-ontonotes, batch 493 (14493): mcc: 0.6296, acc: 0.5154, precision: 0.7466, recall: 0.5388, f1: 0.6259, edges-srl-ontonotes_loss: 0.0262
09/07 09:46:17 PM: Update 14607: task edges-srl-ontonotes, batch 607 (14607): mcc: 0.6389, acc: 0.5253, precision: 0.7546, recall: 0.5487, f1: 0.6354, edges-srl-ontonotes_loss: 0.0257
09/07 09:46:27 PM: Update 14720: task edges-srl-ontonotes, batch 720 (14720): mcc: 0.6456, acc: 0.5332, precision: 0.7595, recall: 0.5565, f1: 0.6423, edges-srl-ontonotes_loss: 0.0254
09/07 09:46:37 PM: Update 14820: task edges-srl-ontonotes, batch 820 (14820): mcc: 0.6492, acc: 0.5375, precision: 0.7621, recall: 0.5606, f1: 0.6460, edges-srl-ontonotes_loss: 0.0252
09/07 09:46:47 PM: Update 14932: task edges-srl-ontonotes, batch 932 (14932): mcc: 0.6554, acc: 0.5446, precision: 0.7669, recall: 0.5677, f1: 0.6524, edges-srl-ontonotes_loss: 0.0249
09/07 09:46:54 PM: ***** Step 15000 / Validation 15 *****
09/07 09:46:54 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:46:54 PM: Validating...
09/07 09:46:58 PM: Evaluate: task edges-srl-ontonotes, batch 43 (157): mcc: 0.6820, acc: 0.5713, precision: 0.8188, recall: 0.5747, f1: 0.6753, edges-srl-ontonotes_loss: 0.0232
09/07 09:47:08 PM: Evaluate: task edges-srl-ontonotes, batch 150 (157): mcc: 0.7030, acc: 0.6045, precision: 0.8214, recall: 0.6082, f1: 0.6989, edges-srl-ontonotes_loss: 0.0219
09/07 09:47:08 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:47:08 PM: Best result seen so far for macro.
09/07 09:47:08 PM: Updating LR scheduler:
09/07 09:47:08 PM: 	Best result seen so far for macro_avg: 0.697
09/07 09:47:08 PM: 	# validation passes without improvement: 0
09/07 09:47:08 PM: edges-srl-ontonotes_loss: training: 0.024694 validation: 0.022087
09/07 09:47:08 PM: macro_avg: validation: 0.697310
09/07 09:47:08 PM: micro_avg: validation: 0.000000
09/07 09:47:08 PM: edges-srl-ontonotes_mcc: training: 0.659245 validation: 0.701444
09/07 09:47:08 PM: edges-srl-ontonotes_acc: training: 0.549194 validation: 0.602956
09/07 09:47:08 PM: edges-srl-ontonotes_precision: training: 0.769485 validation: 0.819827
09/07 09:47:08 PM: edges-srl-ontonotes_recall: training: 0.572288 validation: 0.606651
09/07 09:47:08 PM: edges-srl-ontonotes_f1: training: 0.656395 validation: 0.697310
09/07 09:47:08 PM: Global learning rate: 0.0001
09/07 09:47:08 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 09:47:18 PM: Update 15103: task edges-srl-ontonotes, batch 103 (15103): mcc: 0.7039, acc: 0.6037, precision: 0.7980, recall: 0.6278, f1: 0.7027, edges-srl-ontonotes_loss: 0.0222
09/07 09:47:28 PM: Update 15201: task edges-srl-ontonotes, batch 201 (15201): mcc: 0.6760, acc: 0.5703, precision: 0.7784, recall: 0.5944, f1: 0.6741, edges-srl-ontonotes_loss: 0.0238
09/07 09:47:38 PM: Update 15313: task edges-srl-ontonotes, batch 313 (15313): mcc: 0.6593, acc: 0.5506, precision: 0.7654, recall: 0.5755, f1: 0.6570, edges-srl-ontonotes_loss: 0.0247
09/07 09:47:48 PM: Update 15426: task edges-srl-ontonotes, batch 426 (15426): mcc: 0.6548, acc: 0.5442, precision: 0.7638, recall: 0.5689, f1: 0.6521, edges-srl-ontonotes_loss: 0.0250
09/07 09:47:58 PM: Update 15505: task edges-srl-ontonotes, batch 505 (15505): mcc: 0.6505, acc: 0.5393, precision: 0.7608, recall: 0.5638, f1: 0.6477, edges-srl-ontonotes_loss: 0.0252
09/07 09:48:08 PM: Update 15612: task edges-srl-ontonotes, batch 612 (15612): mcc: 0.6430, acc: 0.5304, precision: 0.7552, recall: 0.5552, f1: 0.6399, edges-srl-ontonotes_loss: 0.0257
09/07 09:48:18 PM: Update 15725: task edges-srl-ontonotes, batch 725 (15725): mcc: 0.6396, acc: 0.5266, precision: 0.7529, recall: 0.5511, f1: 0.6364, edges-srl-ontonotes_loss: 0.0259
09/07 09:48:28 PM: Update 15820: task edges-srl-ontonotes, batch 820 (15820): mcc: 0.6347, acc: 0.5211, precision: 0.7488, recall: 0.5457, f1: 0.6314, edges-srl-ontonotes_loss: 0.0261
09/07 09:48:38 PM: Update 15927: task edges-srl-ontonotes, batch 927 (15927): mcc: 0.6312, acc: 0.5174, precision: 0.7463, recall: 0.5417, f1: 0.6278, edges-srl-ontonotes_loss: 0.0262
09/07 09:48:45 PM: ***** Step 16000 / Validation 16 *****
09/07 09:48:45 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:48:45 PM: Validating...
09/07 09:48:48 PM: Evaluate: task edges-srl-ontonotes, batch 32 (157): mcc: 0.6984, acc: 0.6005, precision: 0.8117, recall: 0.6075, f1: 0.6949, edges-srl-ontonotes_loss: 0.0224
09/07 09:48:58 PM: Evaluate: task edges-srl-ontonotes, batch 139 (157): mcc: 0.7156, acc: 0.6294, precision: 0.8152, recall: 0.6347, f1: 0.7137, edges-srl-ontonotes_loss: 0.0218
09/07 09:49:00 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:49:00 PM: Best result seen so far for macro.
09/07 09:49:00 PM: Updating LR scheduler:
09/07 09:49:00 PM: 	Best result seen so far for macro_avg: 0.710
09/07 09:49:00 PM: 	# validation passes without improvement: 0
09/07 09:49:00 PM: edges-srl-ontonotes_loss: training: 0.026307 validation: 0.022044
09/07 09:49:00 PM: macro_avg: validation: 0.709787
09/07 09:49:00 PM: micro_avg: validation: 0.000000
09/07 09:49:00 PM: edges-srl-ontonotes_mcc: training: 0.629026 validation: 0.711827
09/07 09:49:00 PM: edges-srl-ontonotes_acc: training: 0.514915 validation: 0.624586
09/07 09:49:00 PM: edges-srl-ontonotes_precision: training: 0.744673 validation: 0.813140
09/07 09:49:00 PM: edges-srl-ontonotes_recall: training: 0.539268 validation: 0.629744
09/07 09:49:00 PM: edges-srl-ontonotes_f1: training: 0.625540 validation: 0.709787
09/07 09:49:00 PM: Global learning rate: 0.0001
09/07 09:49:00 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 09:49:08 PM: Update 16077: task edges-srl-ontonotes, batch 77 (16077): mcc: 0.6264, acc: 0.5116, precision: 0.7450, recall: 0.5345, f1: 0.6225, edges-srl-ontonotes_loss: 0.0265
09/07 09:49:18 PM: Update 16180: task edges-srl-ontonotes, batch 180 (16180): mcc: 0.5922, acc: 0.4709, precision: 0.7213, recall: 0.4945, f1: 0.5867, edges-srl-ontonotes_loss: 0.0282
09/07 09:49:28 PM: Update 16284: task edges-srl-ontonotes, batch 284 (16284): mcc: 0.5881, acc: 0.4662, precision: 0.7180, recall: 0.4900, f1: 0.5825, edges-srl-ontonotes_loss: 0.0284
09/07 09:49:40 PM: Update 16371: task edges-srl-ontonotes, batch 371 (16371): mcc: 0.5886, acc: 0.4657, precision: 0.7198, recall: 0.4895, f1: 0.5827, edges-srl-ontonotes_loss: 0.0284
09/07 09:49:50 PM: Update 16476: task edges-srl-ontonotes, batch 476 (16476): mcc: 0.5875, acc: 0.4647, precision: 0.7191, recall: 0.4882, f1: 0.5815, edges-srl-ontonotes_loss: 0.0285
09/07 09:50:00 PM: Update 16581: task edges-srl-ontonotes, batch 581 (16581): mcc: 0.5876, acc: 0.4650, precision: 0.7199, recall: 0.4877, f1: 0.5815, edges-srl-ontonotes_loss: 0.0285
09/07 09:50:11 PM: Update 16684: task edges-srl-ontonotes, batch 684 (16684): mcc: 0.5869, acc: 0.4646, precision: 0.7195, recall: 0.4870, f1: 0.5808, edges-srl-ontonotes_loss: 0.0285
09/07 09:50:21 PM: Update 16783: task edges-srl-ontonotes, batch 783 (16783): mcc: 0.5893, acc: 0.4669, precision: 0.7202, recall: 0.4903, f1: 0.5835, edges-srl-ontonotes_loss: 0.0283
09/07 09:50:31 PM: Update 16886: task edges-srl-ontonotes, batch 886 (16886): mcc: 0.5910, acc: 0.4688, precision: 0.7207, recall: 0.4929, f1: 0.5854, edges-srl-ontonotes_loss: 0.0281
09/07 09:50:41 PM: Update 16986: task edges-srl-ontonotes, batch 986 (16986): mcc: 0.5925, acc: 0.4706, precision: 0.7210, recall: 0.4951, f1: 0.5871, edges-srl-ontonotes_loss: 0.0280
09/07 09:50:44 PM: ***** Step 17000 / Validation 17 *****
09/07 09:50:44 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:50:44 PM: Validating...
09/07 09:50:51 PM: Evaluate: task edges-srl-ontonotes, batch 80 (157): mcc: 0.6943, acc: 0.5959, precision: 0.8118, recall: 0.6005, f1: 0.6904, edges-srl-ontonotes_loss: 0.0230
09/07 09:50:58 PM: Updating LR scheduler:
09/07 09:50:58 PM: 	Best result seen so far for macro_avg: 0.710
09/07 09:50:58 PM: 	# validation passes without improvement: 1
09/07 09:50:58 PM: edges-srl-ontonotes_loss: training: 0.028018 validation: 0.022619
09/07 09:50:58 PM: macro_avg: validation: 0.693386
09/07 09:50:58 PM: micro_avg: validation: 0.000000
09/07 09:50:58 PM: edges-srl-ontonotes_mcc: training: 0.592170 validation: 0.697416
09/07 09:50:58 PM: edges-srl-ontonotes_acc: training: 0.469995 validation: 0.598106
09/07 09:50:58 PM: edges-srl-ontonotes_precision: training: 0.720894 validation: 0.815165
09/07 09:50:58 PM: edges-srl-ontonotes_recall: training: 0.494655 validation: 0.603264
09/07 09:50:58 PM: edges-srl-ontonotes_f1: training: 0.586720 validation: 0.693386
09/07 09:50:58 PM: Global learning rate: 0.0001
09/07 09:50:58 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 09:51:01 PM: Update 17028: task edges-srl-ontonotes, batch 28 (17028): mcc: 0.6032, acc: 0.4825, precision: 0.7252, recall: 0.5100, f1: 0.5989, edges-srl-ontonotes_loss: 0.0269
09/07 09:51:11 PM: Update 17132: task edges-srl-ontonotes, batch 132 (17132): mcc: 0.6036, acc: 0.4825, precision: 0.7267, recall: 0.5095, f1: 0.5990, edges-srl-ontonotes_loss: 0.0270
09/07 09:51:21 PM: Update 17236: task edges-srl-ontonotes, batch 236 (17236): mcc: 0.6058, acc: 0.4869, precision: 0.7259, recall: 0.5138, f1: 0.6017, edges-srl-ontonotes_loss: 0.0268
09/07 09:51:31 PM: Update 17324: task edges-srl-ontonotes, batch 324 (17324): mcc: 0.6049, acc: 0.4851, precision: 0.7256, recall: 0.5125, f1: 0.6007, edges-srl-ontonotes_loss: 0.0269
09/07 09:51:41 PM: Update 17430: task edges-srl-ontonotes, batch 430 (17430): mcc: 0.6075, acc: 0.4885, precision: 0.7273, recall: 0.5157, f1: 0.6035, edges-srl-ontonotes_loss: 0.0267
09/07 09:51:51 PM: Update 17533: task edges-srl-ontonotes, batch 533 (17533): mcc: 0.6112, acc: 0.4926, precision: 0.7305, recall: 0.5195, f1: 0.6072, edges-srl-ontonotes_loss: 0.0266
09/07 09:52:03 PM: Update 17623: task edges-srl-ontonotes, batch 623 (17623): mcc: 0.6135, acc: 0.4948, precision: 0.7321, recall: 0.5221, f1: 0.6096, edges-srl-ontonotes_loss: 0.0265
09/07 09:52:13 PM: Update 17726: task edges-srl-ontonotes, batch 726 (17726): mcc: 0.6114, acc: 0.4923, precision: 0.7314, recall: 0.5193, f1: 0.6073, edges-srl-ontonotes_loss: 0.0267
09/07 09:52:23 PM: Update 17831: task edges-srl-ontonotes, batch 831 (17831): mcc: 0.6117, acc: 0.4922, precision: 0.7320, recall: 0.5193, f1: 0.6076, edges-srl-ontonotes_loss: 0.0267
09/07 09:52:33 PM: Update 17934: task edges-srl-ontonotes, batch 934 (17934): mcc: 0.6107, acc: 0.4913, precision: 0.7315, recall: 0.5180, f1: 0.6065, edges-srl-ontonotes_loss: 0.0267
09/07 09:52:41 PM: ***** Step 18000 / Validation 18 *****
09/07 09:52:41 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:52:41 PM: Validating...
09/07 09:52:43 PM: Evaluate: task edges-srl-ontonotes, batch 30 (157): mcc: 0.6764, acc: 0.5610, precision: 0.8199, recall: 0.5646, f1: 0.6687, edges-srl-ontonotes_loss: 0.0230
09/07 09:52:53 PM: Evaluate: task edges-srl-ontonotes, batch 137 (157): mcc: 0.6934, acc: 0.5921, precision: 0.8157, recall: 0.5960, f1: 0.6887, edges-srl-ontonotes_loss: 0.0225
09/07 09:52:55 PM: Updating LR scheduler:
09/07 09:52:55 PM: 	Best result seen so far for macro_avg: 0.710
09/07 09:52:55 PM: 	# validation passes without improvement: 2
09/07 09:52:55 PM: edges-srl-ontonotes_loss: training: 0.026817 validation: 0.022820
09/07 09:52:55 PM: macro_avg: validation: 0.684046
09/07 09:52:55 PM: micro_avg: validation: 0.000000
09/07 09:52:55 PM: edges-srl-ontonotes_mcc: training: 0.609195 validation: 0.688824
09/07 09:52:55 PM: edges-srl-ontonotes_acc: training: 0.489653 validation: 0.586868
09/07 09:52:55 PM: edges-srl-ontonotes_precision: training: 0.730453 validation: 0.812255
09/07 09:52:55 PM: edges-srl-ontonotes_recall: training: 0.516204 validation: 0.590794
09/07 09:52:55 PM: edges-srl-ontonotes_f1: training: 0.604918 validation: 0.684046
09/07 09:52:55 PM: Global learning rate: 0.0001
09/07 09:52:55 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 09:53:03 PM: Update 18085: task edges-srl-ontonotes, batch 85 (18085): mcc: 0.6073, acc: 0.4812, precision: 0.7360, recall: 0.5091, f1: 0.6019, edges-srl-ontonotes_loss: 0.0271
09/07 09:53:14 PM: Update 18190: task edges-srl-ontonotes, batch 190 (18190): mcc: 0.6100, acc: 0.4863, precision: 0.7375, recall: 0.5124, f1: 0.6047, edges-srl-ontonotes_loss: 0.0271
09/07 09:53:24 PM: Update 18285: task edges-srl-ontonotes, batch 285 (18285): mcc: 0.6094, acc: 0.4869, precision: 0.7351, recall: 0.5132, f1: 0.6044, edges-srl-ontonotes_loss: 0.0271
09/07 09:53:34 PM: Update 18391: task edges-srl-ontonotes, batch 391 (18391): mcc: 0.6060, acc: 0.4845, precision: 0.7315, recall: 0.5101, f1: 0.6010, edges-srl-ontonotes_loss: 0.0272
09/07 09:53:44 PM: Update 18497: task edges-srl-ontonotes, batch 497 (18497): mcc: 0.6073, acc: 0.4856, precision: 0.7331, recall: 0.5111, f1: 0.6023, edges-srl-ontonotes_loss: 0.0271
09/07 09:53:54 PM: Update 18566: task edges-srl-ontonotes, batch 566 (18566): mcc: 0.6071, acc: 0.4858, precision: 0.7327, recall: 0.5111, f1: 0.6021, edges-srl-ontonotes_loss: 0.0271
09/07 09:54:04 PM: Update 18671: task edges-srl-ontonotes, batch 671 (18671): mcc: 0.6095, acc: 0.4893, precision: 0.7335, recall: 0.5144, f1: 0.6048, edges-srl-ontonotes_loss: 0.0269
09/07 09:54:14 PM: Update 18775: task edges-srl-ontonotes, batch 775 (18775): mcc: 0.6103, acc: 0.4901, precision: 0.7338, recall: 0.5156, f1: 0.6057, edges-srl-ontonotes_loss: 0.0269
09/07 09:54:25 PM: Update 18875: task edges-srl-ontonotes, batch 875 (18875): mcc: 0.6117, acc: 0.4919, precision: 0.7342, recall: 0.5177, f1: 0.6072, edges-srl-ontonotes_loss: 0.0268
09/07 09:54:35 PM: Update 18976: task edges-srl-ontonotes, batch 976 (18976): mcc: 0.6129, acc: 0.4934, precision: 0.7350, recall: 0.5192, f1: 0.6085, edges-srl-ontonotes_loss: 0.0268
09/07 09:54:37 PM: ***** Step 19000 / Validation 19 *****
09/07 09:54:37 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:54:37 PM: Validating...
09/07 09:54:45 PM: Evaluate: task edges-srl-ontonotes, batch 84 (157): mcc: 0.6814, acc: 0.5901, precision: 0.7903, recall: 0.5946, f1: 0.6786, edges-srl-ontonotes_loss: 0.0237
09/07 09:54:52 PM: Updating LR scheduler:
09/07 09:54:52 PM: 	Best result seen so far for macro_avg: 0.710
09/07 09:54:52 PM: 	# validation passes without improvement: 3
09/07 09:54:52 PM: edges-srl-ontonotes_loss: training: 0.026733 validation: 0.023142
09/07 09:54:52 PM: macro_avg: validation: 0.687579
09/07 09:54:52 PM: micro_avg: validation: 0.000000
09/07 09:54:52 PM: edges-srl-ontonotes_mcc: training: 0.613158 validation: 0.690258
09/07 09:54:52 PM: edges-srl-ontonotes_acc: training: 0.493783 validation: 0.598645
09/07 09:54:52 PM: edges-srl-ontonotes_precision: training: 0.735053 validation: 0.797946
09/07 09:54:52 PM: edges-srl-ontonotes_recall: training: 0.519530 validation: 0.604034
09/07 09:54:52 PM: edges-srl-ontonotes_f1: training: 0.608780 validation: 0.687579
09/07 09:54:52 PM: Global learning rate: 0.0001
09/07 09:54:52 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 09:54:55 PM: Update 19036: task edges-srl-ontonotes, batch 36 (19036): mcc: 0.6354, acc: 0.5189, precision: 0.7515, recall: 0.5451, f1: 0.6318, edges-srl-ontonotes_loss: 0.0255
09/07 09:55:05 PM: Update 19139: task edges-srl-ontonotes, batch 139 (19139): mcc: 0.6251, acc: 0.5109, precision: 0.7395, recall: 0.5365, f1: 0.6218, edges-srl-ontonotes_loss: 0.0261
09/07 09:55:15 PM: Update 19227: task edges-srl-ontonotes, batch 227 (19227): mcc: 0.6144, acc: 0.4984, precision: 0.7324, recall: 0.5236, f1: 0.6106, edges-srl-ontonotes_loss: 0.0267
09/07 09:55:25 PM: Update 19320: task edges-srl-ontonotes, batch 320 (19320): mcc: 0.6035, acc: 0.4839, precision: 0.7301, recall: 0.5069, f1: 0.5983, edges-srl-ontonotes_loss: 0.0274
09/07 09:55:35 PM: Update 19414: task edges-srl-ontonotes, batch 414 (19414): mcc: 0.6009, acc: 0.4795, precision: 0.7303, recall: 0.5024, f1: 0.5953, edges-srl-ontonotes_loss: 0.0275
09/07 09:55:45 PM: Update 19501: task edges-srl-ontonotes, batch 501 (19501): mcc: 0.5984, acc: 0.4767, precision: 0.7287, recall: 0.4995, f1: 0.5927, edges-srl-ontonotes_loss: 0.0277
09/07 09:55:55 PM: Update 19613: task edges-srl-ontonotes, batch 613 (19613): mcc: 0.6130, acc: 0.4938, precision: 0.7390, recall: 0.5165, f1: 0.6080, edges-srl-ontonotes_loss: 0.0269
09/07 09:56:05 PM: Update 19727: task edges-srl-ontonotes, batch 727 (19727): mcc: 0.6241, acc: 0.5069, precision: 0.7463, recall: 0.5298, f1: 0.6197, edges-srl-ontonotes_loss: 0.0263
09/07 09:56:16 PM: Update 19814: task edges-srl-ontonotes, batch 814 (19814): mcc: 0.6313, acc: 0.5152, precision: 0.7514, recall: 0.5381, f1: 0.6271, edges-srl-ontonotes_loss: 0.0259
09/07 09:56:26 PM: Update 19940: task edges-srl-ontonotes, batch 940 (19940): mcc: 0.6465, acc: 0.5330, precision: 0.7616, recall: 0.5564, f1: 0.6431, edges-srl-ontonotes_loss: 0.0251
09/07 09:56:31 PM: ***** Step 20000 / Validation 20 *****
09/07 09:56:31 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:56:31 PM: Validating...
09/07 09:56:36 PM: Evaluate: task edges-srl-ontonotes, batch 58 (157): mcc: 0.6912, acc: 0.6073, precision: 0.7856, recall: 0.6154, f1: 0.6901, edges-srl-ontonotes_loss: 0.0233
09/07 09:56:45 PM: Updating LR scheduler:
09/07 09:56:45 PM: 	Best result seen so far for macro_avg: 0.710
09/07 09:56:45 PM: 	# validation passes without improvement: 4
09/07 09:56:45 PM: edges-srl-ontonotes_loss: training: 0.024676 validation: 0.022752
09/07 09:56:45 PM: macro_avg: validation: 0.699619
09/07 09:56:45 PM: micro_avg: validation: 0.000000
09/07 09:56:45 PM: edges-srl-ontonotes_mcc: training: 0.653944 validation: 0.700123
09/07 09:56:45 PM: edges-srl-ontonotes_acc: training: 0.541642 validation: 0.620583
09/07 09:56:45 PM: edges-srl-ontonotes_precision: training: 0.766807 validation: 0.788625
09/07 09:56:45 PM: edges-srl-ontonotes_recall: training: 0.565225 validation: 0.628666
09/07 09:56:45 PM: edges-srl-ontonotes_f1: training: 0.650763 validation: 0.699619
09/07 09:56:45 PM: Global learning rate: 0.0001
09/07 09:56:45 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 09:56:46 PM: Update 20011: task edges-srl-ontonotes, batch 11 (20011): mcc: 0.7511, acc: 0.6725, precision: 0.8201, recall: 0.6943, f1: 0.7520, edges-srl-ontonotes_loss: 0.0192
09/07 09:56:56 PM: Update 20127: task edges-srl-ontonotes, batch 127 (20127): mcc: 0.7571, acc: 0.6710, precision: 0.8329, recall: 0.6943, f1: 0.7573, edges-srl-ontonotes_loss: 0.0185
09/07 09:57:06 PM: Update 20251: task edges-srl-ontonotes, batch 251 (20251): mcc: 0.7486, acc: 0.6608, precision: 0.8262, recall: 0.6844, f1: 0.7487, edges-srl-ontonotes_loss: 0.0189
09/07 09:57:16 PM: Update 20374: task edges-srl-ontonotes, batch 374 (20374): mcc: 0.7472, acc: 0.6587, precision: 0.8235, recall: 0.6842, f1: 0.7474, edges-srl-ontonotes_loss: 0.0189
09/07 09:57:26 PM: Update 20485: task edges-srl-ontonotes, batch 485 (20485): mcc: 0.7480, acc: 0.6601, precision: 0.8239, recall: 0.6854, f1: 0.7482, edges-srl-ontonotes_loss: 0.0189
09/07 09:57:36 PM: Update 20612: task edges-srl-ontonotes, batch 612 (20612): mcc: 0.7508, acc: 0.6632, precision: 0.8257, recall: 0.6890, f1: 0.7512, edges-srl-ontonotes_loss: 0.0188
09/07 09:57:46 PM: Update 20736: task edges-srl-ontonotes, batch 736 (20736): mcc: 0.7537, acc: 0.6669, precision: 0.8275, recall: 0.6927, f1: 0.7541, edges-srl-ontonotes_loss: 0.0186
09/07 09:57:56 PM: Update 20825: task edges-srl-ontonotes, batch 825 (20825): mcc: 0.7565, acc: 0.6708, precision: 0.8293, recall: 0.6961, f1: 0.7569, edges-srl-ontonotes_loss: 0.0185
09/07 09:58:06 PM: Update 20950: task edges-srl-ontonotes, batch 950 (20950): mcc: 0.7605, acc: 0.6763, precision: 0.8324, recall: 0.7008, f1: 0.7610, edges-srl-ontonotes_loss: 0.0184
09/07 09:58:10 PM: ***** Step 21000 / Validation 21 *****
09/07 09:58:10 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:58:10 PM: Validating...
09/07 09:58:16 PM: Evaluate: task edges-srl-ontonotes, batch 67 (157): mcc: 0.7004, acc: 0.6050, precision: 0.8138, recall: 0.6095, f1: 0.6970, edges-srl-ontonotes_loss: 0.0226
09/07 09:58:25 PM: Updating LR scheduler:
09/07 09:58:25 PM: 	Best result seen so far for macro_avg: 0.710
09/07 09:58:25 PM: 	# validation passes without improvement: 5
09/07 09:58:25 PM: edges-srl-ontonotes_loss: training: 0.018251 validation: 0.022368
09/07 09:58:25 PM: macro_avg: validation: 0.698557
09/07 09:58:25 PM: micro_avg: validation: 0.000000
09/07 09:58:25 PM: edges-srl-ontonotes_mcc: training: 0.762339 validation: 0.701588
09/07 09:58:25 PM: edges-srl-ontonotes_acc: training: 0.678763 validation: 0.608806
09/07 09:58:25 PM: edges-srl-ontonotes_precision: training: 0.833827 validation: 0.811532
09/07 09:58:25 PM: edges-srl-ontonotes_recall: training: 0.702968 validation: 0.613194
09/07 09:58:25 PM: edges-srl-ontonotes_f1: training: 0.762826 validation: 0.698557
09/07 09:58:25 PM: Global learning rate: 0.0001
09/07 09:58:25 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 09:58:27 PM: Update 21021: task edges-srl-ontonotes, batch 21 (21021): mcc: 0.7967, acc: 0.7245, precision: 0.8609, recall: 0.7425, f1: 0.7973, edges-srl-ontonotes_loss: 0.0170
09/07 09:58:37 PM: Update 21123: task edges-srl-ontonotes, batch 123 (21123): mcc: 0.7506, acc: 0.6646, precision: 0.8317, recall: 0.6835, f1: 0.7503, edges-srl-ontonotes_loss: 0.0194
09/07 09:58:47 PM: Update 21232: task edges-srl-ontonotes, batch 232 (21232): mcc: 0.7183, acc: 0.6249, precision: 0.8065, recall: 0.6464, f1: 0.7176, edges-srl-ontonotes_loss: 0.0212
09/07 09:58:57 PM: Update 21335: task edges-srl-ontonotes, batch 335 (21335): mcc: 0.7049, acc: 0.6093, precision: 0.7946, recall: 0.6323, f1: 0.7042, edges-srl-ontonotes_loss: 0.0219
09/07 09:59:07 PM: Update 21422: task edges-srl-ontonotes, batch 422 (21422): mcc: 0.6917, acc: 0.5941, precision: 0.7846, recall: 0.6170, f1: 0.6908, edges-srl-ontonotes_loss: 0.0227
09/07 09:59:17 PM: Update 21522: task edges-srl-ontonotes, batch 522 (21522): mcc: 0.6803, acc: 0.5797, precision: 0.7774, recall: 0.6026, f1: 0.6790, edges-srl-ontonotes_loss: 0.0233
09/07 09:59:27 PM: Update 21631: task edges-srl-ontonotes, batch 631 (21631): mcc: 0.6744, acc: 0.5724, precision: 0.7732, recall: 0.5957, f1: 0.6729, edges-srl-ontonotes_loss: 0.0236
09/07 09:59:37 PM: Update 21734: task edges-srl-ontonotes, batch 734 (21734): mcc: 0.6707, acc: 0.5668, precision: 0.7721, recall: 0.5901, f1: 0.6690, edges-srl-ontonotes_loss: 0.0239
09/07 09:59:47 PM: Update 21836: task edges-srl-ontonotes, batch 836 (21836): mcc: 0.6734, acc: 0.5699, precision: 0.7744, recall: 0.5930, f1: 0.6717, edges-srl-ontonotes_loss: 0.0238
09/07 09:59:57 PM: Update 21954: task edges-srl-ontonotes, batch 954 (21954): mcc: 0.6772, acc: 0.5744, precision: 0.7773, recall: 0.5974, f1: 0.6756, edges-srl-ontonotes_loss: 0.0236
09/07 10:00:01 PM: ***** Step 22000 / Validation 22 *****
09/07 10:00:01 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:00:01 PM: Validating...
09/07 10:00:07 PM: Evaluate: task edges-srl-ontonotes, batch 64 (157): mcc: 0.7142, acc: 0.6166, precision: 0.8228, recall: 0.6264, f1: 0.7113, edges-srl-ontonotes_loss: 0.0213
09/07 10:00:16 PM: Best result seen so far for edges-srl-ontonotes.
09/07 10:00:16 PM: Best result seen so far for macro.
09/07 10:00:16 PM: Updating LR scheduler:
09/07 10:00:16 PM: 	Best result seen so far for macro_avg: 0.718
09/07 10:00:16 PM: 	# validation passes without improvement: 0
09/07 10:00:16 PM: edges-srl-ontonotes_loss: training: 0.023515 validation: 0.020958
09/07 10:00:16 PM: macro_avg: validation: 0.717893
09/07 10:00:16 PM: micro_avg: validation: 0.000000
09/07 10:00:16 PM: edges-srl-ontonotes_mcc: training: 0.678193 validation: 0.720130
09/07 10:00:16 PM: edges-srl-ontonotes_acc: training: 0.575457 validation: 0.627588
09/07 10:00:16 PM: edges-srl-ontonotes_precision: training: 0.778177 validation: 0.822611
09/07 10:00:16 PM: edges-srl-ontonotes_recall: training: 0.598394 validation: 0.636826
09/07 10:00:16 PM: edges-srl-ontonotes_f1: training: 0.676545 validation: 0.717893
09/07 10:00:16 PM: Global learning rate: 0.0001
09/07 10:00:16 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 10:00:17 PM: Update 22015: task edges-srl-ontonotes, batch 15 (22015): mcc: 0.7116, acc: 0.6098, precision: 0.8153, recall: 0.6277, f1: 0.7093, edges-srl-ontonotes_loss: 0.0217
09/07 10:00:27 PM: Update 22094: task edges-srl-ontonotes, batch 94 (22094): mcc: 0.7053, acc: 0.6078, precision: 0.8000, recall: 0.6287, f1: 0.7041, edges-srl-ontonotes_loss: 0.0222
09/07 10:00:37 PM: Update 22198: task edges-srl-ontonotes, batch 198 (22198): mcc: 0.7119, acc: 0.6145, precision: 0.8044, recall: 0.6368, f1: 0.7108, edges-srl-ontonotes_loss: 0.0217
09/07 10:00:47 PM: Update 22310: task edges-srl-ontonotes, batch 310 (22310): mcc: 0.7161, acc: 0.6200, precision: 0.8065, recall: 0.6427, f1: 0.7153, edges-srl-ontonotes_loss: 0.0214
09/07 10:00:57 PM: Update 22410: task edges-srl-ontonotes, batch 410 (22410): mcc: 0.7104, acc: 0.6125, precision: 0.8031, recall: 0.6352, f1: 0.7093, edges-srl-ontonotes_loss: 0.0218
09/07 10:01:07 PM: Update 22524: task edges-srl-ontonotes, batch 524 (22524): mcc: 0.6981, acc: 0.5977, precision: 0.7939, recall: 0.6209, f1: 0.6968, edges-srl-ontonotes_loss: 0.0225
09/07 10:01:17 PM: Update 22634: task edges-srl-ontonotes, batch 634 (22634): mcc: 0.6911, acc: 0.5897, precision: 0.7888, recall: 0.6127, f1: 0.6897, edges-srl-ontonotes_loss: 0.0229
09/07 10:01:27 PM: Update 22728: task edges-srl-ontonotes, batch 728 (22728): mcc: 0.6861, acc: 0.5837, precision: 0.7850, recall: 0.6069, f1: 0.6846, edges-srl-ontonotes_loss: 0.0232
09/07 10:01:37 PM: Update 22839: task edges-srl-ontonotes, batch 839 (22839): mcc: 0.6785, acc: 0.5744, precision: 0.7796, recall: 0.5977, f1: 0.6767, edges-srl-ontonotes_loss: 0.0236
09/07 10:01:47 PM: Update 22951: task edges-srl-ontonotes, batch 951 (22951): mcc: 0.6747, acc: 0.5697, precision: 0.7769, recall: 0.5934, f1: 0.6729, edges-srl-ontonotes_loss: 0.0239
09/07 10:01:55 PM: ***** Step 23000 / Validation 23 *****
09/07 10:01:55 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:01:55 PM: Validating...
09/07 10:01:58 PM: Evaluate: task edges-srl-ontonotes, batch 25 (157): mcc: 0.7198, acc: 0.6190, precision: 0.8310, recall: 0.6298, f1: 0.7165, edges-srl-ontonotes_loss: 0.0206
09/07 10:02:08 PM: Evaluate: task edges-srl-ontonotes, batch 132 (157): mcc: 0.7393, acc: 0.6578, precision: 0.8257, recall: 0.6681, f1: 0.7386, edges-srl-ontonotes_loss: 0.0199
09/07 10:02:10 PM: Best result seen so far for edges-srl-ontonotes.
09/07 10:02:10 PM: Best result seen so far for macro.
09/07 10:02:10 PM: Updating LR scheduler:
09/07 10:02:10 PM: 	Best result seen so far for macro_avg: 0.729
09/07 10:02:10 PM: 	# validation passes without improvement: 0
09/07 10:02:10 PM: edges-srl-ontonotes_loss: training: 0.023946 validation: 0.020471
09/07 10:02:10 PM: macro_avg: validation: 0.729168
09/07 10:02:10 PM: micro_avg: validation: 0.000000
09/07 10:02:10 PM: edges-srl-ontonotes_mcc: training: 0.672841 validation: 0.729994
09/07 10:02:10 PM: edges-srl-ontonotes_acc: training: 0.567326 validation: 0.646986
09/07 10:02:10 PM: edges-srl-ontonotes_precision: training: 0.775465 validation: 0.819037
09/07 10:02:10 PM: edges-srl-ontonotes_recall: training: 0.591187 validation: 0.657070
09/07 10:02:10 PM: edges-srl-ontonotes_f1: training: 0.670902 validation: 0.729168
09/07 10:02:10 PM: Global learning rate: 0.0001
09/07 10:02:10 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 10:02:18 PM: Update 23082: task edges-srl-ontonotes, batch 82 (23082): mcc: 0.6262, acc: 0.5081, precision: 0.7424, recall: 0.5361, f1: 0.6226, edges-srl-ontonotes_loss: 0.0262
09/07 10:02:28 PM: Update 23191: task edges-srl-ontonotes, batch 191 (23191): mcc: 0.6272, acc: 0.5111, precision: 0.7408, recall: 0.5390, f1: 0.6240, edges-srl-ontonotes_loss: 0.0261
09/07 10:02:38 PM: Update 23300: task edges-srl-ontonotes, batch 300 (23300): mcc: 0.6312, acc: 0.5168, precision: 0.7441, recall: 0.5433, f1: 0.6280, edges-srl-ontonotes_loss: 0.0258
09/07 10:02:48 PM: Update 23389: task edges-srl-ontonotes, batch 389 (23389): mcc: 0.6240, acc: 0.5086, precision: 0.7392, recall: 0.5347, f1: 0.6205, edges-srl-ontonotes_loss: 0.0263
09/07 10:02:58 PM: Update 23495: task edges-srl-ontonotes, batch 495 (23495): mcc: 0.6205, acc: 0.5043, precision: 0.7381, recall: 0.5297, f1: 0.6168, edges-srl-ontonotes_loss: 0.0266
09/07 10:03:08 PM: Update 23598: task edges-srl-ontonotes, batch 598 (23598): mcc: 0.6188, acc: 0.5017, precision: 0.7377, recall: 0.5271, f1: 0.6149, edges-srl-ontonotes_loss: 0.0267
09/07 10:03:18 PM: Update 23688: task edges-srl-ontonotes, batch 688 (23688): mcc: 0.6171, acc: 0.5002, precision: 0.7361, recall: 0.5254, f1: 0.6131, edges-srl-ontonotes_loss: 0.0268
09/07 10:03:28 PM: Update 23793: task edges-srl-ontonotes, batch 793 (23793): mcc: 0.6161, acc: 0.4988, precision: 0.7357, recall: 0.5240, f1: 0.6120, edges-srl-ontonotes_loss: 0.0269
09/07 10:03:38 PM: Update 23899: task edges-srl-ontonotes, batch 899 (23899): mcc: 0.6159, acc: 0.4982, precision: 0.7365, recall: 0.5231, f1: 0.6118, edges-srl-ontonotes_loss: 0.0270
09/07 10:03:48 PM: Update 23970: task edges-srl-ontonotes, batch 970 (23970): mcc: 0.6162, acc: 0.4983, precision: 0.7372, recall: 0.5230, f1: 0.6119, edges-srl-ontonotes_loss: 0.0269
09/07 10:03:51 PM: ***** Step 24000 / Validation 24 *****
09/07 10:03:51 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:03:51 PM: Validating...
09/07 10:03:58 PM: Evaluate: task edges-srl-ontonotes, batch 78 (157): mcc: 0.7149, acc: 0.6316, precision: 0.8057, recall: 0.6410, f1: 0.7140, edges-srl-ontonotes_loss: 0.0216
09/07 10:04:06 PM: Updating LR scheduler:
09/07 10:04:06 PM: 	Best result seen so far for macro_avg: 0.729
09/07 10:04:06 PM: 	# validation passes without improvement: 1
09/07 10:04:06 PM: edges-srl-ontonotes_loss: training: 0.026894 validation: 0.021211
09/07 10:04:06 PM: macro_avg: validation: 0.721151
09/07 10:04:06 PM: micro_avg: validation: 0.000000
09/07 10:04:06 PM: edges-srl-ontonotes_mcc: training: 0.616734 validation: 0.721739
09/07 10:04:06 PM: edges-srl-ontonotes_acc: training: 0.498872 validation: 0.640520
09/07 10:04:06 PM: edges-srl-ontonotes_precision: training: 0.737396 validation: 0.809214
09/07 10:04:06 PM: edges-srl-ontonotes_recall: training: 0.523840 validation: 0.650373
09/07 10:04:06 PM: edges-srl-ontonotes_f1: training: 0.612538 validation: 0.721151
09/07 10:04:06 PM: Global learning rate: 0.0001
09/07 10:04:06 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 10:04:08 PM: Update 24026: task edges-srl-ontonotes, batch 26 (24026): mcc: 0.6449, acc: 0.5233, precision: 0.7551, recall: 0.5586, f1: 0.6421, edges-srl-ontonotes_loss: 0.0250
09/07 10:04:18 PM: Update 24128: task edges-srl-ontonotes, batch 128 (24128): mcc: 0.6280, acc: 0.5108, precision: 0.7405, recall: 0.5406, f1: 0.6250, edges-srl-ontonotes_loss: 0.0258
09/07 10:04:28 PM: Update 24228: task edges-srl-ontonotes, batch 228 (24228): mcc: 0.6289, acc: 0.5121, precision: 0.7404, recall: 0.5422, f1: 0.6260, edges-srl-ontonotes_loss: 0.0256
09/07 10:04:38 PM: Update 24321: task edges-srl-ontonotes, batch 321 (24321): mcc: 0.6295, acc: 0.5141, precision: 0.7401, recall: 0.5434, f1: 0.6267, edges-srl-ontonotes_loss: 0.0257
09/07 10:04:48 PM: Update 24427: task edges-srl-ontonotes, batch 427 (24427): mcc: 0.6285, acc: 0.5130, precision: 0.7390, recall: 0.5426, f1: 0.6258, edges-srl-ontonotes_loss: 0.0257
09/07 10:04:59 PM: Update 24528: task edges-srl-ontonotes, batch 528 (24528): mcc: 0.6286, acc: 0.5136, precision: 0.7383, recall: 0.5432, f1: 0.6259, edges-srl-ontonotes_loss: 0.0257
09/07 10:05:09 PM: Update 24620: task edges-srl-ontonotes, batch 620 (24620): mcc: 0.6290, acc: 0.5137, precision: 0.7395, recall: 0.5431, f1: 0.6262, edges-srl-ontonotes_loss: 0.0257
09/07 10:05:19 PM: Update 24723: task edges-srl-ontonotes, batch 723 (24723): mcc: 0.6307, acc: 0.5152, precision: 0.7414, recall: 0.5444, f1: 0.6279, edges-srl-ontonotes_loss: 0.0256
09/07 10:05:29 PM: Update 24827: task edges-srl-ontonotes, batch 827 (24827): mcc: 0.6327, acc: 0.5178, precision: 0.7427, recall: 0.5469, f1: 0.6300, edges-srl-ontonotes_loss: 0.0255
09/07 10:05:39 PM: Update 24917: task edges-srl-ontonotes, batch 917 (24917): mcc: 0.6335, acc: 0.5183, precision: 0.7435, recall: 0.5477, f1: 0.6308, edges-srl-ontonotes_loss: 0.0255
09/07 10:05:47 PM: ***** Step 25000 / Validation 25 *****
09/07 10:05:47 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:05:47 PM: Validating...
09/07 10:05:49 PM: Evaluate: task edges-srl-ontonotes, batch 22 (157): mcc: 0.7003, acc: 0.5995, precision: 0.8119, recall: 0.6106, f1: 0.6970, edges-srl-ontonotes_loss: 0.0216
09/07 10:05:59 PM: Evaluate: task edges-srl-ontonotes, batch 129 (157): mcc: 0.7190, acc: 0.6334, precision: 0.8111, recall: 0.6439, f1: 0.7179, edges-srl-ontonotes_loss: 0.0213
09/07 10:06:01 PM: Updating LR scheduler:
09/07 10:06:01 PM: 	Best result seen so far for macro_avg: 0.729
09/07 10:06:01 PM: 	# validation passes without improvement: 2
09/07 10:06:01 PM: edges-srl-ontonotes_loss: training: 0.025580 validation: 0.021766
09/07 10:06:01 PM: macro_avg: validation: 0.710510
09/07 10:06:01 PM: micro_avg: validation: 0.000000
09/07 10:06:01 PM: edges-srl-ontonotes_mcc: training: 0.632682 validation: 0.711723
09/07 10:06:01 PM: edges-srl-ontonotes_acc: training: 0.517438 validation: 0.624894
09/07 10:06:01 PM: edges-srl-ontonotes_precision: training: 0.743137 validation: 0.805819
09/07 10:06:01 PM: edges-srl-ontonotes_recall: training: 0.546634 validation: 0.635363
09/07 10:06:01 PM: edges-srl-ontonotes_f1: training: 0.629916 validation: 0.710510
09/07 10:06:01 PM: Global learning rate: 0.0001
09/07 10:06:01 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 10:06:09 PM: Update 25077: task edges-srl-ontonotes, batch 77 (25077): mcc: 0.6304, acc: 0.5136, precision: 0.7414, recall: 0.5439, f1: 0.6275, edges-srl-ontonotes_loss: 0.0257
09/07 10:06:22 PM: Update 25182: task edges-srl-ontonotes, batch 182 (25182): mcc: 0.6296, acc: 0.5137, precision: 0.7421, recall: 0.5421, f1: 0.6265, edges-srl-ontonotes_loss: 0.0259
09/07 10:06:32 PM: Update 25288: task edges-srl-ontonotes, batch 288 (25288): mcc: 0.6274, acc: 0.5115, precision: 0.7396, recall: 0.5401, f1: 0.6243, edges-srl-ontonotes_loss: 0.0260
09/07 10:06:42 PM: Update 25393: task edges-srl-ontonotes, batch 393 (25393): mcc: 0.6277, acc: 0.5122, precision: 0.7422, recall: 0.5389, f1: 0.6244, edges-srl-ontonotes_loss: 0.0260
09/07 10:06:53 PM: Update 25495: task edges-srl-ontonotes, batch 495 (25495): mcc: 0.6260, acc: 0.5101, precision: 0.7418, recall: 0.5362, f1: 0.6224, edges-srl-ontonotes_loss: 0.0261
09/07 10:07:03 PM: Update 25599: task edges-srl-ontonotes, batch 599 (25599): mcc: 0.6240, acc: 0.5082, precision: 0.7408, recall: 0.5336, f1: 0.6204, edges-srl-ontonotes_loss: 0.0262
09/07 10:07:13 PM: Update 25707: task edges-srl-ontonotes, batch 707 (25707): mcc: 0.6254, acc: 0.5094, precision: 0.7417, recall: 0.5353, f1: 0.6218, edges-srl-ontonotes_loss: 0.0261
09/07 10:07:24 PM: Update 25808: task edges-srl-ontonotes, batch 808 (25808): mcc: 0.6258, acc: 0.5103, precision: 0.7419, recall: 0.5359, f1: 0.6223, edges-srl-ontonotes_loss: 0.0261
09/07 10:07:34 PM: Update 25911: task edges-srl-ontonotes, batch 911 (25911): mcc: 0.6272, acc: 0.5120, precision: 0.7426, recall: 0.5377, f1: 0.6237, edges-srl-ontonotes_loss: 0.0260
09/07 10:07:43 PM: ***** Step 26000 / Validation 26 *****
09/07 10:07:43 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:07:43 PM: Validating...
09/07 10:07:44 PM: Evaluate: task edges-srl-ontonotes, batch 15 (157): mcc: 0.6764, acc: 0.5794, precision: 0.7847, recall: 0.5903, f1: 0.6738, edges-srl-ontonotes_loss: 0.0228
09/07 10:07:54 PM: Evaluate: task edges-srl-ontonotes, batch 123 (157): mcc: 0.7095, acc: 0.6318, precision: 0.7983, recall: 0.6375, f1: 0.7089, edges-srl-ontonotes_loss: 0.0218
09/07 10:07:57 PM: Updating LR scheduler:
09/07 10:07:57 PM: 	Best result seen so far for macro_avg: 0.729
09/07 10:07:57 PM: 	# validation passes without improvement: 3
09/07 10:07:57 PM: edges-srl-ontonotes_loss: training: 0.025929 validation: 0.022085
09/07 10:07:57 PM: macro_avg: validation: 0.703700
09/07 10:07:57 PM: micro_avg: validation: 0.000000
09/07 10:07:57 PM: edges-srl-ontonotes_mcc: training: 0.628691 validation: 0.704283
09/07 10:07:57 PM: edges-srl-ontonotes_acc: training: 0.513984 validation: 0.626434
09/07 10:07:57 PM: edges-srl-ontonotes_precision: training: 0.743214 validation: 0.793183
09/07 10:07:57 PM: edges-srl-ontonotes_recall: training: 0.539777 validation: 0.632361
09/07 10:07:57 PM: edges-srl-ontonotes_f1: training: 0.625366 validation: 0.703700
09/07 10:07:57 PM: Global learning rate: 0.0001
09/07 10:07:57 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 10:08:04 PM: Update 26070: task edges-srl-ontonotes, batch 70 (26070): mcc: 0.6470, acc: 0.5349, precision: 0.7545, recall: 0.5627, f1: 0.6446, edges-srl-ontonotes_loss: 0.0251
09/07 10:08:14 PM: Update 26145: task edges-srl-ontonotes, batch 145 (26145): mcc: 0.6450, acc: 0.5350, precision: 0.7504, recall: 0.5623, f1: 0.6429, edges-srl-ontonotes_loss: 0.0250
09/07 10:08:24 PM: Update 26249: task edges-srl-ontonotes, batch 249 (26249): mcc: 0.6408, acc: 0.5304, precision: 0.7471, recall: 0.5575, f1: 0.6386, edges-srl-ontonotes_loss: 0.0252
09/07 10:08:34 PM: Update 26356: task edges-srl-ontonotes, batch 356 (26356): mcc: 0.6422, acc: 0.5329, precision: 0.7483, recall: 0.5590, f1: 0.6399, edges-srl-ontonotes_loss: 0.0250
09/07 10:08:44 PM: Update 26444: task edges-srl-ontonotes, batch 444 (26444): mcc: 0.6384, acc: 0.5286, precision: 0.7451, recall: 0.5549, f1: 0.6361, edges-srl-ontonotes_loss: 0.0252
09/07 10:08:55 PM: Update 26538: task edges-srl-ontonotes, batch 538 (26538): mcc: 0.6290, acc: 0.5166, precision: 0.7404, recall: 0.5424, f1: 0.6261, edges-srl-ontonotes_loss: 0.0258
09/07 10:09:05 PM: Update 26630: task edges-srl-ontonotes, batch 630 (26630): mcc: 0.6254, acc: 0.5114, precision: 0.7399, recall: 0.5366, f1: 0.6221, edges-srl-ontonotes_loss: 0.0261
09/07 10:09:15 PM: Update 26727: task edges-srl-ontonotes, batch 727 (26727): mcc: 0.6242, acc: 0.5099, precision: 0.7401, recall: 0.5344, f1: 0.6207, edges-srl-ontonotes_loss: 0.0261
09/07 10:09:25 PM: Update 26821: task edges-srl-ontonotes, batch 821 (26821): mcc: 0.6285, acc: 0.5146, precision: 0.7438, recall: 0.5390, f1: 0.6251, edges-srl-ontonotes_loss: 0.0259
09/07 10:09:35 PM: Update 26937: task edges-srl-ontonotes, batch 937 (26937): mcc: 0.6381, acc: 0.5256, precision: 0.7510, recall: 0.5500, f1: 0.6350, edges-srl-ontonotes_loss: 0.0254
09/07 10:09:40 PM: ***** Step 27000 / Validation 27 *****
09/07 10:09:40 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:09:40 PM: Validating...
09/07 10:09:45 PM: Evaluate: task edges-srl-ontonotes, batch 51 (157): mcc: 0.6997, acc: 0.6138, precision: 0.7902, recall: 0.6267, f1: 0.6990, edges-srl-ontonotes_loss: 0.0223
09/07 10:09:55 PM: Updating LR scheduler:
09/07 10:09:55 PM: 	Best result seen so far for macro_avg: 0.729
09/07 10:09:55 PM: 	# validation passes without improvement: 4
09/07 10:09:55 PM: edges-srl-ontonotes_loss: training: 0.025168 validation: 0.021684
09/07 10:09:55 PM: macro_avg: validation: 0.713393
09/07 10:09:55 PM: micro_avg: validation: 0.000000
09/07 10:09:55 PM: edges-srl-ontonotes_mcc: training: 0.642227 validation: 0.713453
09/07 10:09:55 PM: edges-srl-ontonotes_acc: training: 0.530178 validation: 0.634208
09/07 10:09:55 PM: edges-srl-ontonotes_precision: training: 0.754110 validation: 0.796507
09/07 10:09:55 PM: edges-srl-ontonotes_recall: training: 0.554719 validation: 0.645986
09/07 10:09:55 PM: edges-srl-ontonotes_f1: training: 0.639227 validation: 0.713393
09/07 10:09:55 PM: Global learning rate: 0.0001
09/07 10:09:55 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-mix/run
09/07 10:09:55 PM: Update 27001: task edges-srl-ontonotes, batch 1 (27001): mcc: 0.7544, acc: 0.6829, precision: 0.8261, recall: 0.6951, f1: 0.7550, edges-srl-ontonotes_loss: 0.0163
09/07 10:10:05 PM: Update 27107: task edges-srl-ontonotes, batch 107 (27107): mcc: 0.7381, acc: 0.6456, precision: 0.8211, recall: 0.6698, f1: 0.7378, edges-srl-ontonotes_loss: 0.0199
09/07 10:10:15 PM: Update 27232: task edges-srl-ontonotes, batch 232 (27232): mcc: 0.7473, acc: 0.6577, precision: 0.8233, recall: 0.6845, f1: 0.7475, edges-srl-ontonotes_loss: 0.0191
09/07 10:10:25 PM: Update 27360: task edges-srl-ontonotes, batch 360 (27360): mcc: 0.7581, acc: 0.6708, precision: 0.8308, recall: 0.6979, f1: 0.7586, edges-srl-ontonotes_loss: 0.0185
09/07 10:10:35 PM: Update 27447: task edges-srl-ontonotes, batch 447 (27447): mcc: 0.7554, acc: 0.6676, precision: 0.8285, recall: 0.6948, f1: 0.7558, edges-srl-ontonotes_loss: 0.0186
09/07 10:10:45 PM: Update 27571: task edges-srl-ontonotes, batch 571 (27571): mcc: 0.7575, acc: 0.6699, precision: 0.8300, recall: 0.6975, f1: 0.7580, edges-srl-ontonotes_loss: 0.0184
09/07 10:10:55 PM: Update 27686: task edges-srl-ontonotes, batch 686 (27686): mcc: 0.7595, acc: 0.6726, precision: 0.8310, recall: 0.7003, f1: 0.7601, edges-srl-ontonotes_loss: 0.0183
09/07 10:11:05 PM: Update 27809: task edges-srl-ontonotes, batch 809 (27809): mcc: 0.7616, acc: 0.6757, precision: 0.8323, recall: 0.7030, f1: 0.7622, edges-srl-ontonotes_loss: 0.0181
