09/07 09:16:38 PM: Git branch: master
09/07 09:16:38 PM: Git SHA: 117419dc9116809c203f878fb83f7aaddafbbcb0
09/07 09:16:39 PM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "/scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/",
  "exp_name": "experiments/srl-ontonotes-RANDOM-only",
  "input_module": "bert-base-uncased",
  "local_log_path": "/scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run/log.log",
  "lr_patience": 5,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 20,
  "pretrain_tasks": "",
  "pretrained_dir": "RANDOM",
  "pytorch_transformers_output_mode": "only",
  "remote_log_name": "experiments/srl-ontonotes-RANDOM-only__run",
  "run_dir": "/scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-srl-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/07 09:16:39 PM: Saved config to /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run/params.conf
09/07 09:16:39 PM: Using random seed 1234
09/07 09:16:40 PM: Using GPU 0
09/07 09:16:40 PM: Loading tasks...
09/07 09:16:40 PM: Writing pre-preprocessed tasks to /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/
09/07 09:16:40 PM: 	Creating task edges-srl-ontonotes from scratch.
09/07 09:16:45 PM: Read=231480, Skip=21590, Total=253070 from /scratch0/new/jiant/probing_data/edges/ontonotes/srl/train.json.retokenized.bert-base-uncased
09/07 09:16:45 PM: Read=32486, Skip=2811, Total=35297 from /scratch0/new/jiant/probing_data/edges/ontonotes/srl/development.json.retokenized.bert-base-uncased
09/07 09:16:46 PM: Read=23800, Skip=2915, Total=26715 from /scratch0/new/jiant/probing_data/edges/ontonotes/srl/test.json.retokenized.bert-base-uncased
09/07 09:16:48 PM: 	Task 'edges-srl-ontonotes': |train|=231480 |val|=32486 |test|=23800
09/07 09:16:48 PM: 	Finished loading tasks: edges-srl-ontonotes.
09/07 09:16:48 PM: 	Building vocab from scratch.
09/07 09:16:48 PM: 	Counting units for task edges-srl-ontonotes.
09/07 09:16:56 PM: 	Task 'edges-srl-ontonotes': adding vocab namespace 'edges-srl-ontonotes_labels'
09/07 09:16:56 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /cliphomes/ewallac2/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:16:56 PM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/07 09:16:57 PM: 	Saved vocab to /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/vocab
09/07 09:16:57 PM: Loading token dictionary from /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/vocab.
09/07 09:16:57 PM: 	Loaded vocab from /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/vocab
09/07 09:16:57 PM: 	Vocab namespace tokens: size 23662
09/07 09:16:57 PM: 	Vocab namespace chars: size 76
09/07 09:16:57 PM: 	Vocab namespace edges-srl-ontonotes_labels: size 66
09/07 09:16:57 PM: 	Vocab namespace bert_uncased: size 30524
09/07 09:16:57 PM: 	Finished building vocab.
09/07 09:16:57 PM: 	Task edges-srl-ontonotes (train): Indexing from scratch.
09/07 09:17:42 PM: 	Task edges-srl-ontonotes (train): Saved 231480 instances to /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/preproc/edges-srl-ontonotes__train_data
09/07 09:17:42 PM: 	Task edges-srl-ontonotes (val): Indexing from scratch.
09/07 09:17:49 PM: 	Task edges-srl-ontonotes (val): Saved 32486 instances to /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/preproc/edges-srl-ontonotes__val_data
09/07 09:17:49 PM: 	Task edges-srl-ontonotes (test): Indexing from scratch.
09/07 09:17:54 PM: 	Task edges-srl-ontonotes (test): Saved 23800 instances to /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/preproc/edges-srl-ontonotes__test_data
09/07 09:17:54 PM: 	Finished indexing tasks
09/07 09:17:54 PM: 	Creating trimmed target-only version of edges-srl-ontonotes train.
09/07 09:17:54 PM: 	  Training on 
09/07 09:17:54 PM: 	  Evaluating on edges-srl-ontonotes
09/07 09:17:54 PM: 	Finished loading tasks in 73.812s
09/07 09:17:54 PM: 	 Tasks: ['edges-srl-ontonotes']
09/07 09:17:54 PM: Building model...
09/07 09:17:54 PM: Using BERT model (bert-base-uncased).
09/07 09:17:54 PM: LOADING A RANDOMLY WEIGHTS BERT
09/07 09:17:56 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache, downloading to /tmp/tmp8h9tl9fk
09/07 09:17:56 PM: copying /tmp/tmp8h9tl9fk to cache at /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/07 09:17:56 PM: creating metadata file for /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/07 09:17:56 PM: removing temp file /tmp/tmp8h9tl9fk
09/07 09:17:56 PM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/07 09:17:56 PM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/07 09:17:56 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache, downloading to /tmp/tmp3xluy8vn
09/07 09:18:23 PM: copying /tmp/tmp3xluy8vn to cache at /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/07 09:18:23 PM: creating metadata file for /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/07 09:18:23 PM: removing temp file /tmp/tmp3xluy8vn
09/07 09:18:23 PM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/07 09:18:27 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to /tmp/tmpa0h3h5uq
09/07 09:18:27 PM: copying /tmp/tmpa0h3h5uq to cache at /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:18:27 PM: creating metadata file for /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:18:27 PM: removing temp file /tmp/tmpa0h3h5uq
09/07 09:18:27 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:18:27 PM: Initializing parameters
09/07 09:18:27 PM: Done initializing parameters; the following parameters are using their default initialization from their code
09/07 09:18:27 PM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/07 09:18:27 PM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/07 09:18:27 PM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/07 09:18:27 PM:    _text_field_embedder.model.pooler.dense.bias
09/07 09:18:27 PM:    _text_field_embedder.model.pooler.dense.weight
09/07 09:18:27 PM: 	Task 'edges-srl-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-srl-ontonotes"
}
09/07 09:18:31 PM: Model specification:
09/07 09:18:31 PM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): BertLayerNorm()
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-srl-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (proj2): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (span_extractor2): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Sequential(
        (0): Linear(in_features=1024, out_features=256, bias=True)
        (1): Tanh()
        (2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)
        (3): Dropout(p=0.3)
        (4): Linear(in_features=256, out_features=66, bias=True)
      )
    )
  )
)
09/07 09:18:31 PM: Model parameters:
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:31 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:31 PM: 	edges-srl-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/07 09:18:31 PM: 	edges-srl-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:31 PM: 	edges-srl-ontonotes_mdl.proj2.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/07 09:18:31 PM: 	edges-srl-ontonotes_mdl.proj2.bias: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:31 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.0.weight: Trainable parameter, count 262144 with torch.Size([256, 1024])
09/07 09:18:31 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.0.bias: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:31 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.2.weight: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:31 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.2.bias: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:31 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.4.weight: Trainable parameter, count 16896 with torch.Size([66, 256])
09/07 09:18:31 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.4.bias: Trainable parameter, count 66 with torch.Size([66])
09/07 09:18:31 PM: Total number of parameters: 110155842 (1.10156e+08)
09/07 09:18:31 PM: Number of trainable parameters: 673602 (673602)
09/07 09:18:31 PM: Finished building model in 37.866s
09/07 09:18:31 PM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-srl-ontonotes 

09/07 09:18:48 PM: patience = 20
09/07 09:18:48 PM: val_interval = 1000
09/07 09:18:48 PM: max_vals = 250
09/07 09:18:48 PM: cuda_device = 0
09/07 09:18:48 PM: grad_norm = 5.0
09/07 09:18:48 PM: grad_clipping = None
09/07 09:18:48 PM: lr_decay = 0.99
09/07 09:18:48 PM: min_lr = 1e-06
09/07 09:18:48 PM: keep_all_checkpoints = 0
09/07 09:18:48 PM: val_data_limit = 5000
09/07 09:18:48 PM: max_epochs = -1
09/07 09:18:48 PM: dec_val_scale = 250
09/07 09:18:48 PM: training_data_fraction = 1
09/07 09:18:48 PM: type = adam
09/07 09:18:48 PM: parameter_groups = None
09/07 09:18:48 PM: Number of trainable parameters: 673602
09/07 09:18:48 PM: infer_type_and_cast = True
09/07 09:18:48 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/07 09:18:48 PM: CURRENTLY DEFINED PARAMETERS: 
09/07 09:18:48 PM: lr = 0.0001
09/07 09:18:48 PM: amsgrad = True
09/07 09:18:48 PM: type = reduce_on_plateau
09/07 09:18:48 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/07 09:18:48 PM: CURRENTLY DEFINED PARAMETERS: 
09/07 09:18:48 PM: mode = max
09/07 09:18:48 PM: factor = 0.5
09/07 09:18:48 PM: patience = 5
09/07 09:18:48 PM: threshold = 0.0001
09/07 09:18:48 PM: threshold_mode = abs
09/07 09:18:48 PM: verbose = True
09/07 09:18:48 PM: type = adam
09/07 09:18:48 PM: parameter_groups = None
09/07 09:18:48 PM: Number of trainable parameters: 673602
09/07 09:18:48 PM: infer_type_and_cast = True
09/07 09:18:48 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/07 09:18:48 PM: CURRENTLY DEFINED PARAMETERS: 
09/07 09:18:48 PM: lr = 0.0001
09/07 09:18:48 PM: amsgrad = True
09/07 09:18:48 PM: type = reduce_on_plateau
09/07 09:18:48 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/07 09:18:48 PM: CURRENTLY DEFINED PARAMETERS: 
09/07 09:18:48 PM: mode = max
09/07 09:18:48 PM: factor = 0.5
09/07 09:18:48 PM: patience = 5
09/07 09:18:48 PM: threshold = 0.0001
09/07 09:18:48 PM: threshold_mode = abs
09/07 09:18:48 PM: verbose = True
09/07 09:18:48 PM: Starting training without restoring from a checkpoint.
09/07 09:18:48 PM: Training examples per task, before any subsampling: {'edges-srl-ontonotes': 231480}
09/07 09:18:48 PM: Beginning training with stopping criteria based on metric: edges-srl-ontonotes_f1
09/07 09:18:58 PM: Update 179: task edges-srl-ontonotes, batch 179 (179): mcc: 0.0365, acc: 0.0412, precision: 0.0285, recall: 0.1878, f1: 0.0496, edges-srl-ontonotes_loss: 0.2818
09/07 09:19:08 PM: Update 358: task edges-srl-ontonotes, batch 358 (358): mcc: 0.0513, acc: 0.0711, precision: 0.0407, recall: 0.1525, f1: 0.0642, edges-srl-ontonotes_loss: 0.1827
09/07 09:19:18 PM: Update 564: task edges-srl-ontonotes, batch 564 (564): mcc: 0.0910, acc: 0.1277, precision: 0.0696, recall: 0.1838, f1: 0.1010, edges-srl-ontonotes_loss: 0.1366
09/07 09:19:28 PM: Update 713: task edges-srl-ontonotes, batch 713 (713): mcc: 0.1147, acc: 0.1531, precision: 0.0899, recall: 0.2013, f1: 0.1243, edges-srl-ontonotes_loss: 0.1192
09/07 09:19:38 PM: Update 921: task edges-srl-ontonotes, batch 921 (921): mcc: 0.1407, acc: 0.1743, precision: 0.1160, recall: 0.2161, f1: 0.1510, edges-srl-ontonotes_loss: 0.1024
09/07 09:19:43 PM: ***** Step 1000 / Validation 1 *****
09/07 09:19:43 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:19:43 PM: Validating...
09/07 09:19:48 PM: Evaluate: task edges-srl-ontonotes, batch 85 (157): mcc: 0.4831, acc: 0.3152, precision: 0.7441, recall: 0.3198, f1: 0.4473, edges-srl-ontonotes_loss: 0.0361
09/07 09:19:52 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:19:52 PM: Best result seen so far for micro.
09/07 09:19:52 PM: Best result seen so far for macro.
09/07 09:19:52 PM: Updating LR scheduler:
09/07 09:19:52 PM: 	Best result seen so far for macro_avg: 0.438
09/07 09:19:52 PM: 	# validation passes without improvement: 0
09/07 09:19:52 PM: edges-srl-ontonotes_loss: training: 0.097548 validation: 0.035897
09/07 09:19:52 PM: macro_avg: validation: 0.438269
09/07 09:19:52 PM: micro_avg: validation: 0.000000
09/07 09:19:52 PM: edges-srl-ontonotes_mcc: training: 0.150510 validation: 0.472572
09/07 09:19:52 PM: edges-srl-ontonotes_acc: training: 0.182014 validation: 0.309291
09/07 09:19:52 PM: edges-srl-ontonotes_precision: training: 0.126225 validation: 0.726220
09/07 09:19:52 PM: edges-srl-ontonotes_recall: training: 0.222170 validation: 0.313833
09/07 09:19:52 PM: edges-srl-ontonotes_f1: training: 0.160986 validation: 0.438269
09/07 09:19:52 PM: Global learning rate: 0.0001
09/07 09:19:52 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:19:58 PM: Update 1130: task edges-srl-ontonotes, batch 130 (1130): mcc: 0.4137, acc: 0.2760, precision: 0.5926, recall: 0.2973, f1: 0.3960, edges-srl-ontonotes_loss: 0.0405
09/07 09:20:08 PM: Update 1321: task edges-srl-ontonotes, batch 321 (1321): mcc: 0.4256, acc: 0.2800, precision: 0.6113, recall: 0.3045, f1: 0.4065, edges-srl-ontonotes_loss: 0.0388
09/07 09:20:18 PM: Update 1534: task edges-srl-ontonotes, batch 534 (1534): mcc: 0.4356, acc: 0.2848, precision: 0.6194, recall: 0.3145, f1: 0.4172, edges-srl-ontonotes_loss: 0.0376
09/07 09:20:28 PM: Update 1722: task edges-srl-ontonotes, batch 722 (1722): mcc: 0.4398, acc: 0.2868, precision: 0.6266, recall: 0.3168, f1: 0.4208, edges-srl-ontonotes_loss: 0.0372
09/07 09:20:39 PM: Update 1879: task edges-srl-ontonotes, batch 879 (1879): mcc: 0.4413, acc: 0.2871, precision: 0.6302, recall: 0.3171, f1: 0.4219, edges-srl-ontonotes_loss: 0.0370
09/07 09:20:45 PM: ***** Step 2000 / Validation 2 *****
09/07 09:20:45 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:20:45 PM: Validating...
09/07 09:20:49 PM: Evaluate: task edges-srl-ontonotes, batch 88 (157): mcc: 0.5481, acc: 0.3890, precision: 0.7697, recall: 0.3968, f1: 0.5237, edges-srl-ontonotes_loss: 0.0307
09/07 09:20:52 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:20:52 PM: Best result seen so far for macro.
09/07 09:20:52 PM: Updating LR scheduler:
09/07 09:20:52 PM: 	Best result seen so far for macro_avg: 0.522
09/07 09:20:52 PM: 	# validation passes without improvement: 0
09/07 09:20:52 PM: edges-srl-ontonotes_loss: training: 0.036733 validation: 0.030470
09/07 09:20:52 PM: macro_avg: validation: 0.521823
09/07 09:20:52 PM: micro_avg: validation: 0.000000
09/07 09:20:52 PM: edges-srl-ontonotes_mcc: training: 0.445068 validation: 0.545898
09/07 09:20:52 PM: edges-srl-ontonotes_acc: training: 0.290389 validation: 0.388269
09/07 09:20:52 PM: edges-srl-ontonotes_precision: training: 0.633936 validation: 0.765827
09/07 09:20:52 PM: edges-srl-ontonotes_recall: training: 0.320516 validation: 0.395736
09/07 09:20:52 PM: edges-srl-ontonotes_f1: training: 0.425766 validation: 0.521823
09/07 09:20:52 PM: Global learning rate: 0.0001
09/07 09:20:52 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:20:59 PM: Update 2144: task edges-srl-ontonotes, batch 144 (2144): mcc: 0.4734, acc: 0.3151, precision: 0.6637, recall: 0.3454, f1: 0.4544, edges-srl-ontonotes_loss: 0.0347
09/07 09:21:09 PM: Update 2321: task edges-srl-ontonotes, batch 321 (2321): mcc: 0.4777, acc: 0.3205, precision: 0.6548, recall: 0.3567, f1: 0.4618, edges-srl-ontonotes_loss: 0.0340
09/07 09:21:19 PM: Update 2506: task edges-srl-ontonotes, batch 506 (2506): mcc: 0.4849, acc: 0.3286, precision: 0.6545, recall: 0.3676, f1: 0.4708, edges-srl-ontonotes_loss: 0.0333
09/07 09:21:29 PM: Update 2713: task edges-srl-ontonotes, batch 713 (2713): mcc: 0.4907, acc: 0.3339, precision: 0.6562, recall: 0.3754, f1: 0.4776, edges-srl-ontonotes_loss: 0.0329
09/07 09:21:39 PM: Update 2856: task edges-srl-ontonotes, batch 856 (2856): mcc: 0.4952, acc: 0.3390, precision: 0.6585, recall: 0.3809, f1: 0.4826, edges-srl-ontonotes_loss: 0.0326
09/07 09:21:46 PM: ***** Step 3000 / Validation 3 *****
09/07 09:21:46 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:21:46 PM: Validating...
09/07 09:21:49 PM: Evaluate: task edges-srl-ontonotes, batch 65 (157): mcc: 0.5428, acc: 0.3964, precision: 0.7411, recall: 0.4047, f1: 0.5235, edges-srl-ontonotes_loss: 0.0303
09/07 09:21:53 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:21:53 PM: Best result seen so far for macro.
09/07 09:21:53 PM: Updating LR scheduler:
09/07 09:21:53 PM: 	Best result seen so far for macro_avg: 0.534
09/07 09:21:53 PM: 	# validation passes without improvement: 0
09/07 09:21:53 PM: edges-srl-ontonotes_loss: training: 0.032340 validation: 0.029517
09/07 09:21:53 PM: macro_avg: validation: 0.534333
09/07 09:21:53 PM: micro_avg: validation: 0.000000
09/07 09:21:53 PM: edges-srl-ontonotes_mcc: training: 0.499768 validation: 0.552067
09/07 09:21:53 PM: edges-srl-ontonotes_acc: training: 0.343863 validation: 0.407667
09/07 09:21:53 PM: edges-srl-ontonotes_precision: training: 0.661507 validation: 0.743854
09/07 09:21:53 PM: edges-srl-ontonotes_recall: training: 0.386047 validation: 0.416904
09/07 09:21:53 PM: edges-srl-ontonotes_f1: training: 0.487560 validation: 0.534333
09/07 09:21:53 PM: Global learning rate: 0.0001
09/07 09:21:53 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:21:59 PM: Update 3120: task edges-srl-ontonotes, batch 120 (3120): mcc: 0.5429, acc: 0.3910, precision: 0.6892, recall: 0.4362, f1: 0.5342, edges-srl-ontonotes_loss: 0.0299
09/07 09:22:09 PM: Update 3305: task edges-srl-ontonotes, batch 305 (3305): mcc: 0.5254, acc: 0.3735, precision: 0.6728, recall: 0.4189, f1: 0.5163, edges-srl-ontonotes_loss: 0.0309
09/07 09:22:19 PM: Update 3489: task edges-srl-ontonotes, batch 489 (3489): mcc: 0.5233, acc: 0.3704, precision: 0.6724, recall: 0.4159, f1: 0.5139, edges-srl-ontonotes_loss: 0.0310
09/07 09:22:29 PM: Update 3698: task edges-srl-ontonotes, batch 698 (3698): mcc: 0.5230, acc: 0.3708, precision: 0.6722, recall: 0.4155, f1: 0.5136, edges-srl-ontonotes_loss: 0.0310
09/07 09:22:39 PM: Update 3884: task edges-srl-ontonotes, batch 884 (3884): mcc: 0.5245, acc: 0.3729, precision: 0.6732, recall: 0.4172, f1: 0.5151, edges-srl-ontonotes_loss: 0.0309
09/07 09:22:45 PM: ***** Step 4000 / Validation 4 *****
09/07 09:22:45 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:22:45 PM: Validating...
09/07 09:22:49 PM: Evaluate: task edges-srl-ontonotes, batch 59 (157): mcc: 0.5517, acc: 0.4135, precision: 0.7350, recall: 0.4216, f1: 0.5358, edges-srl-ontonotes_loss: 0.0299
09/07 09:22:53 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:22:53 PM: Best result seen so far for macro.
09/07 09:22:53 PM: Updating LR scheduler:
09/07 09:22:53 PM: 	Best result seen so far for macro_avg: 0.553
09/07 09:22:53 PM: 	# validation passes without improvement: 0
09/07 09:22:53 PM: edges-srl-ontonotes_loss: training: 0.030861 validation: 0.028945
09/07 09:22:53 PM: macro_avg: validation: 0.552550
09/07 09:22:53 PM: micro_avg: validation: 0.000000
09/07 09:22:53 PM: edges-srl-ontonotes_mcc: training: 0.525431 validation: 0.566599
09/07 09:22:53 PM: edges-srl-ontonotes_acc: training: 0.374188 validation: 0.429990
09/07 09:22:53 PM: edges-srl-ontonotes_precision: training: 0.673703 validation: 0.741605
09/07 09:22:53 PM: edges-srl-ontonotes_recall: training: 0.418392 validation: 0.440305
09/07 09:22:53 PM: edges-srl-ontonotes_f1: training: 0.516204 validation: 0.552550
09/07 09:22:53 PM: Global learning rate: 0.0001
09/07 09:22:53 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:22:59 PM: Update 4095: task edges-srl-ontonotes, batch 95 (4095): mcc: 0.5371, acc: 0.3878, precision: 0.6833, recall: 0.4307, f1: 0.5284, edges-srl-ontonotes_loss: 0.0303
09/07 09:23:09 PM: Update 4301: task edges-srl-ontonotes, batch 301 (4301): mcc: 0.5371, acc: 0.3905, precision: 0.6780, recall: 0.4341, f1: 0.5293, edges-srl-ontonotes_loss: 0.0301
09/07 09:23:19 PM: Update 4489: task edges-srl-ontonotes, batch 489 (4489): mcc: 0.5438, acc: 0.3985, precision: 0.6810, recall: 0.4429, f1: 0.5367, edges-srl-ontonotes_loss: 0.0297
09/07 09:23:29 PM: Update 4695: task edges-srl-ontonotes, batch 695 (4695): mcc: 0.5457, acc: 0.4016, precision: 0.6812, recall: 0.4458, f1: 0.5389, edges-srl-ontonotes_loss: 0.0295
09/07 09:23:39 PM: Update 4883: task edges-srl-ontonotes, batch 883 (4883): mcc: 0.5414, acc: 0.3965, precision: 0.6804, recall: 0.4394, f1: 0.5340, edges-srl-ontonotes_loss: 0.0300
09/07 09:23:45 PM: ***** Step 5000 / Validation 5 *****
09/07 09:23:45 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:23:45 PM: Validating...
09/07 09:23:49 PM: Evaluate: task edges-srl-ontonotes, batch 100 (157): mcc: 0.5615, acc: 0.4285, precision: 0.7214, recall: 0.4449, f1: 0.5504, edges-srl-ontonotes_loss: 0.0291
09/07 09:23:52 PM: Updating LR scheduler:
09/07 09:23:52 PM: 	Best result seen so far for macro_avg: 0.553
09/07 09:23:52 PM: 	# validation passes without improvement: 1
09/07 09:23:52 PM: edges-srl-ontonotes_loss: training: 0.030030 validation: 0.028982
09/07 09:23:52 PM: macro_avg: validation: 0.548104
09/07 09:23:52 PM: micro_avg: validation: 0.000000
09/07 09:23:52 PM: edges-srl-ontonotes_mcc: training: 0.541618 validation: 0.559201
09/07 09:23:52 PM: edges-srl-ontonotes_acc: training: 0.396580 validation: 0.425756
09/07 09:23:52 PM: edges-srl-ontonotes_precision: training: 0.681363 validation: 0.718801
09/07 09:23:52 PM: edges-srl-ontonotes_recall: training: 0.439184 validation: 0.442922
09/07 09:23:52 PM: edges-srl-ontonotes_f1: training: 0.534103 validation: 0.548104
09/07 09:23:52 PM: Global learning rate: 0.0001
09/07 09:23:52 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:23:59 PM: Update 5096: task edges-srl-ontonotes, batch 96 (5096): mcc: 0.5813, acc: 0.4458, precision: 0.7150, recall: 0.4809, f1: 0.5751, edges-srl-ontonotes_loss: 0.0284
09/07 09:24:09 PM: Update 5301: task edges-srl-ontonotes, batch 301 (5301): mcc: 0.5970, acc: 0.4596, precision: 0.7283, recall: 0.4974, f1: 0.5911, edges-srl-ontonotes_loss: 0.0271
09/07 09:24:19 PM: Update 5485: task edges-srl-ontonotes, batch 485 (5485): mcc: 0.6176, acc: 0.4850, precision: 0.7419, recall: 0.5221, f1: 0.6129, edges-srl-ontonotes_loss: 0.0260
09/07 09:24:29 PM: Update 5670: task edges-srl-ontonotes, batch 670 (5670): mcc: 0.6317, acc: 0.5018, precision: 0.7508, recall: 0.5393, f1: 0.6277, edges-srl-ontonotes_loss: 0.0252
09/07 09:24:39 PM: Update 5873: task edges-srl-ontonotes, batch 873 (5873): mcc: 0.6402, acc: 0.5127, precision: 0.7539, recall: 0.5514, f1: 0.6369, edges-srl-ontonotes_loss: 0.0246
09/07 09:24:48 PM: ***** Step 6000 / Validation 6 *****
09/07 09:24:48 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:24:48 PM: Validating...
09/07 09:24:49 PM: Evaluate: task edges-srl-ontonotes, batch 22 (157): mcc: 0.6021, acc: 0.4628, precision: 0.7789, recall: 0.4723, f1: 0.5881, edges-srl-ontonotes_loss: 0.0270
09/07 09:24:55 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:24:55 PM: Best result seen so far for macro.
09/07 09:24:55 PM: Updating LR scheduler:
09/07 09:24:55 PM: 	Best result seen so far for macro_avg: 0.592
09/07 09:24:55 PM: 	# validation passes without improvement: 0
09/07 09:24:55 PM: edges-srl-ontonotes_loss: training: 0.024395 validation: 0.027522
09/07 09:24:55 PM: macro_avg: validation: 0.592364
09/07 09:24:55 PM: micro_avg: validation: 0.000000
09/07 09:24:55 PM: edges-srl-ontonotes_mcc: training: 0.645286 validation: 0.601538
09/07 09:24:55 PM: edges-srl-ontonotes_acc: training: 0.518740 validation: 0.472173
09/07 09:24:55 PM: edges-srl-ontonotes_precision: training: 0.756756 validation: 0.752341
09/07 09:24:55 PM: edges-srl-ontonotes_recall: training: 0.557965 validation: 0.488492
09/07 09:24:55 PM: edges-srl-ontonotes_f1: training: 0.642331 validation: 0.592364
09/07 09:24:55 PM: Global learning rate: 0.0001
09/07 09:24:55 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:24:59 PM: Update 6081: task edges-srl-ontonotes, batch 81 (6081): mcc: 0.6840, acc: 0.5683, precision: 0.7784, recall: 0.6084, f1: 0.6830, edges-srl-ontonotes_loss: 0.0221
09/07 09:25:09 PM: Update 6263: task edges-srl-ontonotes, batch 263 (6263): mcc: 0.6925, acc: 0.5790, precision: 0.7818, recall: 0.6206, f1: 0.6919, edges-srl-ontonotes_loss: 0.0218
09/07 09:25:19 PM: Update 6466: task edges-srl-ontonotes, batch 466 (6466): mcc: 0.7165, acc: 0.6110, precision: 0.8022, recall: 0.6467, f1: 0.7161, edges-srl-ontonotes_loss: 0.0210
09/07 09:25:29 PM: Update 6650: task edges-srl-ontonotes, batch 650 (6650): mcc: 0.7129, acc: 0.6080, precision: 0.7998, recall: 0.6423, f1: 0.7124, edges-srl-ontonotes_loss: 0.0214
09/07 09:25:39 PM: Update 6858: task edges-srl-ontonotes, batch 858 (6858): mcc: 0.6947, acc: 0.5858, precision: 0.7851, recall: 0.6219, f1: 0.6940, edges-srl-ontonotes_loss: 0.0225
09/07 09:25:47 PM: ***** Step 7000 / Validation 7 *****
09/07 09:25:47 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:25:47 PM: Validating...
09/07 09:25:49 PM: Evaluate: task edges-srl-ontonotes, batch 42 (157): mcc: 0.6100, acc: 0.4850, precision: 0.7611, recall: 0.4963, f1: 0.6008, edges-srl-ontonotes_loss: 0.0271
09/07 09:25:56 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:25:56 PM: Best result seen so far for macro.
09/07 09:25:56 PM: Updating LR scheduler:
09/07 09:25:56 PM: 	Best result seen so far for macro_avg: 0.617
09/07 09:25:56 PM: 	# validation passes without improvement: 0
09/07 09:25:56 PM: edges-srl-ontonotes_loss: training: 0.023342 validation: 0.026022
09/07 09:25:56 PM: macro_avg: validation: 0.616574
09/07 09:25:56 PM: micro_avg: validation: 0.000000
09/07 09:25:56 PM: edges-srl-ontonotes_mcc: training: 0.679425 validation: 0.624190
09/07 09:25:56 PM: edges-srl-ontonotes_acc: training: 0.567392 validation: 0.501732
09/07 09:25:56 PM: edges-srl-ontonotes_precision: training: 0.773815 validation: 0.766415
09/07 09:25:56 PM: edges-srl-ontonotes_recall: training: 0.603983 validation: 0.515742
09/07 09:25:56 PM: edges-srl-ontonotes_f1: training: 0.678432 validation: 0.616574
09/07 09:25:56 PM: Global learning rate: 0.0001
09/07 09:25:56 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:25:59 PM: Update 7062: task edges-srl-ontonotes, batch 62 (7062): mcc: 0.5949, acc: 0.4669, precision: 0.7125, recall: 0.5053, f1: 0.5912, edges-srl-ontonotes_loss: 0.0280
09/07 09:26:10 PM: Update 7247: task edges-srl-ontonotes, batch 247 (7247): mcc: 0.5959, acc: 0.4659, precision: 0.7170, recall: 0.5037, f1: 0.5917, edges-srl-ontonotes_loss: 0.0279
09/07 09:26:20 PM: Update 7450: task edges-srl-ontonotes, batch 450 (7450): mcc: 0.6155, acc: 0.4893, precision: 0.7339, recall: 0.5242, f1: 0.6116, edges-srl-ontonotes_loss: 0.0269
09/07 09:26:30 PM: Update 7631: task edges-srl-ontonotes, batch 631 (7631): mcc: 0.6286, acc: 0.5054, precision: 0.7430, recall: 0.5398, f1: 0.6253, edges-srl-ontonotes_loss: 0.0261
09/07 09:26:40 PM: Update 7835: task edges-srl-ontonotes, batch 835 (7835): mcc: 0.6381, acc: 0.5171, precision: 0.7493, recall: 0.5513, f1: 0.6352, edges-srl-ontonotes_loss: 0.0255
09/07 09:26:49 PM: ***** Step 8000 / Validation 8 *****
09/07 09:26:49 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:26:49 PM: Validating...
09/07 09:26:50 PM: Evaluate: task edges-srl-ontonotes, batch 23 (157): mcc: 0.6494, acc: 0.5303, precision: 0.7927, recall: 0.5389, f1: 0.6416, edges-srl-ontonotes_loss: 0.0243
09/07 09:26:56 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:26:56 PM: Best result seen so far for macro.
09/07 09:26:56 PM: Updating LR scheduler:
09/07 09:26:56 PM: 	Best result seen so far for macro_avg: 0.647
09/07 09:26:56 PM: 	# validation passes without improvement: 0
09/07 09:26:56 PM: edges-srl-ontonotes_loss: training: 0.025645 validation: 0.024423
09/07 09:26:56 PM: macro_avg: validation: 0.647141
09/07 09:26:56 PM: micro_avg: validation: 0.000000
09/07 09:26:56 PM: edges-srl-ontonotes_mcc: training: 0.634981 validation: 0.653154
09/07 09:26:56 PM: edges-srl-ontonotes_acc: training: 0.513214 validation: 0.537680
09/07 09:26:56 PM: edges-srl-ontonotes_precision: training: 0.746343 validation: 0.785495
09/07 09:26:56 PM: edges-srl-ontonotes_recall: training: 0.548160 validation: 0.550227
09/07 09:26:56 PM: edges-srl-ontonotes_f1: training: 0.632081 validation: 0.647141
09/07 09:26:56 PM: Global learning rate: 0.0001
09/07 09:26:56 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:27:00 PM: Update 8085: task edges-srl-ontonotes, batch 85 (8085): mcc: 0.6012, acc: 0.4692, precision: 0.7140, recall: 0.5146, f1: 0.5982, edges-srl-ontonotes_loss: 0.0270
09/07 09:27:10 PM: Update 8233: task edges-srl-ontonotes, batch 233 (8233): mcc: 0.5951, acc: 0.4648, precision: 0.7078, recall: 0.5090, f1: 0.5921, edges-srl-ontonotes_loss: 0.0274
09/07 09:27:20 PM: Update 8444: task edges-srl-ontonotes, batch 444 (8444): mcc: 0.5892, acc: 0.4580, precision: 0.7047, recall: 0.5013, f1: 0.5858, edges-srl-ontonotes_loss: 0.0279
09/07 09:27:30 PM: Update 8632: task edges-srl-ontonotes, batch 632 (8632): mcc: 0.5846, acc: 0.4520, precision: 0.7023, recall: 0.4953, f1: 0.5809, edges-srl-ontonotes_loss: 0.0279
09/07 09:27:40 PM: Update 8820: task edges-srl-ontonotes, batch 820 (8820): mcc: 0.5833, acc: 0.4502, precision: 0.7003, recall: 0.4945, f1: 0.5797, edges-srl-ontonotes_loss: 0.0278
09/07 09:27:49 PM: ***** Step 9000 / Validation 9 *****
09/07 09:27:49 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:27:49 PM: Validating...
09/07 09:27:50 PM: Evaluate: task edges-srl-ontonotes, batch 25 (157): mcc: 0.6337, acc: 0.5068, precision: 0.7913, recall: 0.5143, f1: 0.6234, edges-srl-ontonotes_loss: 0.0247
09/07 09:27:56 PM: Updating LR scheduler:
09/07 09:27:56 PM: 	Best result seen so far for macro_avg: 0.647
09/07 09:27:56 PM: 	# validation passes without improvement: 1
09/07 09:27:56 PM: edges-srl-ontonotes_loss: training: 0.028284 validation: 0.024379
09/07 09:27:56 PM: macro_avg: validation: 0.640202
09/07 09:27:56 PM: micro_avg: validation: 0.000000
09/07 09:27:56 PM: edges-srl-ontonotes_mcc: training: 0.574559 validation: 0.647969
09/07 09:27:56 PM: edges-srl-ontonotes_acc: training: 0.440617 validation: 0.527211
09/07 09:27:56 PM: edges-srl-ontonotes_precision: training: 0.694924 validation: 0.791364
09/07 09:27:56 PM: edges-srl-ontonotes_recall: training: 0.483775 validation: 0.537526
09/07 09:27:56 PM: edges-srl-ontonotes_f1: training: 0.570437 validation: 0.640202
09/07 09:27:56 PM: Global learning rate: 0.0001
09/07 09:27:56 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:28:00 PM: Update 9085: task edges-srl-ontonotes, batch 85 (9085): mcc: 0.5569, acc: 0.4198, precision: 0.6915, recall: 0.4572, f1: 0.5504, edges-srl-ontonotes_loss: 0.0292
09/07 09:28:10 PM: Update 9232: task edges-srl-ontonotes, batch 232 (9232): mcc: 0.5500, acc: 0.4114, precision: 0.6846, recall: 0.4506, f1: 0.5435, edges-srl-ontonotes_loss: 0.0295
09/07 09:28:21 PM: Update 9438: task edges-srl-ontonotes, batch 438 (9438): mcc: 0.5570, acc: 0.4185, precision: 0.6922, recall: 0.4567, f1: 0.5503, edges-srl-ontonotes_loss: 0.0293
09/07 09:28:31 PM: Update 9641: task edges-srl-ontonotes, batch 641 (9641): mcc: 0.5603, acc: 0.4219, precision: 0.6908, recall: 0.4631, f1: 0.5545, edges-srl-ontonotes_loss: 0.0289
09/07 09:28:41 PM: Update 9824: task edges-srl-ontonotes, batch 824 (9824): mcc: 0.5602, acc: 0.4222, precision: 0.6888, recall: 0.4643, f1: 0.5547, edges-srl-ontonotes_loss: 0.0288
09/07 09:28:50 PM: ***** Step 10000 / Validation 10 *****
09/07 09:28:50 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:28:50 PM: Validating...
09/07 09:28:51 PM: Evaluate: task edges-srl-ontonotes, batch 29 (157): mcc: 0.6168, acc: 0.4941, precision: 0.7668, recall: 0.5034, f1: 0.6078, edges-srl-ontonotes_loss: 0.0253
09/07 09:28:57 PM: Updating LR scheduler:
09/07 09:28:57 PM: 	Best result seen so far for macro_avg: 0.647
09/07 09:28:57 PM: 	# validation passes without improvement: 2
09/07 09:28:57 PM: edges-srl-ontonotes_loss: training: 0.028584 validation: 0.025288
09/07 09:28:57 PM: macro_avg: validation: 0.612866
09/07 09:28:57 PM: micro_avg: validation: 0.000000
09/07 09:28:57 PM: edges-srl-ontonotes_mcc: training: 0.562275 validation: 0.620257
09/07 09:28:57 PM: edges-srl-ontonotes_acc: training: 0.424655 validation: 0.503041
09/07 09:28:57 PM: edges-srl-ontonotes_precision: training: 0.689373 validation: 0.761078
09/07 09:28:57 PM: edges-srl-ontonotes_recall: training: 0.467339 validation: 0.512971
09/07 09:28:57 PM: edges-srl-ontonotes_f1: training: 0.557046 validation: 0.612866
09/07 09:28:57 PM: Global learning rate: 0.0001
09/07 09:28:57 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:29:03 PM: Update 10064: task edges-srl-ontonotes, batch 64 (10064): mcc: 0.5749, acc: 0.4411, precision: 0.6970, recall: 0.4829, f1: 0.5705, edges-srl-ontonotes_loss: 0.0276
09/07 09:29:13 PM: Update 10265: task edges-srl-ontonotes, batch 265 (10265): mcc: 0.5853, acc: 0.4550, precision: 0.7042, recall: 0.4951, f1: 0.5814, edges-srl-ontonotes_loss: 0.0272
09/07 09:29:23 PM: Update 10447: task edges-srl-ontonotes, batch 447 (10447): mcc: 0.5824, acc: 0.4512, precision: 0.7017, recall: 0.4920, f1: 0.5784, edges-srl-ontonotes_loss: 0.0273
09/07 09:29:33 PM: Update 10651: task edges-srl-ontonotes, batch 651 (10651): mcc: 0.5771, acc: 0.4453, precision: 0.6978, recall: 0.4861, f1: 0.5730, edges-srl-ontonotes_loss: 0.0277
09/07 09:29:43 PM: Update 10837: task edges-srl-ontonotes, batch 837 (10837): mcc: 0.5763, acc: 0.4442, precision: 0.6977, recall: 0.4846, f1: 0.5720, edges-srl-ontonotes_loss: 0.0278
09/07 09:29:51 PM: ***** Step 11000 / Validation 11 *****
09/07 09:29:51 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:29:51 PM: Validating...
09/07 09:29:53 PM: Evaluate: task edges-srl-ontonotes, batch 46 (157): mcc: 0.6052, acc: 0.4792, precision: 0.7647, recall: 0.4862, f1: 0.5945, edges-srl-ontonotes_loss: 0.0270
09/07 09:29:58 PM: Updating LR scheduler:
09/07 09:29:58 PM: 	Best result seen so far for macro_avg: 0.647
09/07 09:29:58 PM: 	# validation passes without improvement: 3
09/07 09:29:58 PM: edges-srl-ontonotes_loss: training: 0.027859 validation: 0.025644
09/07 09:29:58 PM: macro_avg: validation: 0.613432
09/07 09:29:58 PM: micro_avg: validation: 0.000000
09/07 09:29:58 PM: edges-srl-ontonotes_mcc: training: 0.575224 validation: 0.622040
09/07 09:29:58 PM: edges-srl-ontonotes_acc: training: 0.443060 validation: 0.501655
09/07 09:29:58 PM: edges-srl-ontonotes_precision: training: 0.697564 validation: 0.770090
09/07 09:29:58 PM: edges-srl-ontonotes_recall: training: 0.483006 validation: 0.509737
09/07 09:29:58 PM: edges-srl-ontonotes_f1: training: 0.570788 validation: 0.613432
09/07 09:29:58 PM: Global learning rate: 0.0001
09/07 09:29:58 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:30:03 PM: Update 11083: task edges-srl-ontonotes, batch 83 (11083): mcc: 0.5641, acc: 0.4287, precision: 0.6885, recall: 0.4709, f1: 0.5593, edges-srl-ontonotes_loss: 0.0284
09/07 09:30:13 PM: Update 11290: task edges-srl-ontonotes, batch 290 (11290): mcc: 0.5717, acc: 0.4392, precision: 0.6964, recall: 0.4779, f1: 0.5669, edges-srl-ontonotes_loss: 0.0281
09/07 09:30:23 PM: Update 11435: task edges-srl-ontonotes, batch 435 (11435): mcc: 0.5748, acc: 0.4422, precision: 0.6991, recall: 0.4812, f1: 0.5700, edges-srl-ontonotes_loss: 0.0279
09/07 09:30:34 PM: Update 11629: task edges-srl-ontonotes, batch 629 (11629): mcc: 0.5785, acc: 0.4475, precision: 0.7004, recall: 0.4864, f1: 0.5741, edges-srl-ontonotes_loss: 0.0277
09/07 09:30:44 PM: Update 11833: task edges-srl-ontonotes, batch 833 (11833): mcc: 0.5804, acc: 0.4505, precision: 0.7005, recall: 0.4896, f1: 0.5763, edges-srl-ontonotes_loss: 0.0276
09/07 09:30:53 PM: ***** Step 12000 / Validation 12 *****
09/07 09:30:53 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:30:53 PM: Validating...
09/07 09:30:54 PM: Evaluate: task edges-srl-ontonotes, batch 18 (157): mcc: 0.6115, acc: 0.4899, precision: 0.7655, recall: 0.4958, f1: 0.6018, edges-srl-ontonotes_loss: 0.0253
09/07 09:31:00 PM: Updating LR scheduler:
09/07 09:31:00 PM: 	Best result seen so far for macro_avg: 0.647
09/07 09:31:00 PM: 	# validation passes without improvement: 4
09/07 09:31:00 PM: edges-srl-ontonotes_loss: training: 0.027638 validation: 0.025892
09/07 09:31:00 PM: macro_avg: validation: 0.613336
09/07 09:31:00 PM: micro_avg: validation: 0.000000
09/07 09:31:00 PM: edges-srl-ontonotes_mcc: training: 0.579748 validation: 0.618461
09/07 09:31:00 PM: edges-srl-ontonotes_acc: training: 0.449232 validation: 0.511277
09/07 09:31:00 PM: edges-srl-ontonotes_precision: training: 0.700812 validation: 0.745184
09/07 09:31:00 PM: edges-srl-ontonotes_recall: training: 0.488228 validation: 0.521130
09/07 09:31:00 PM: edges-srl-ontonotes_f1: training: 0.575516 validation: 0.613336
09/07 09:31:00 PM: Global learning rate: 0.0001
09/07 09:31:00 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:31:04 PM: Update 12077: task edges-srl-ontonotes, batch 77 (12077): mcc: 0.5583, acc: 0.4177, precision: 0.7017, recall: 0.4525, f1: 0.5502, edges-srl-ontonotes_loss: 0.0297
09/07 09:31:16 PM: Update 12255: task edges-srl-ontonotes, batch 255 (12255): mcc: 0.5699, acc: 0.4346, precision: 0.7041, recall: 0.4697, f1: 0.5635, edges-srl-ontonotes_loss: 0.0287
09/07 09:31:26 PM: Update 12459: task edges-srl-ontonotes, batch 459 (12459): mcc: 0.5964, acc: 0.4662, precision: 0.7222, recall: 0.5007, f1: 0.5914, edges-srl-ontonotes_loss: 0.0270
09/07 09:31:36 PM: Update 12642: task edges-srl-ontonotes, batch 642 (12642): mcc: 0.6162, acc: 0.4905, precision: 0.7351, recall: 0.5246, f1: 0.6122, edges-srl-ontonotes_loss: 0.0259
09/07 09:31:46 PM: Update 12843: task edges-srl-ontonotes, batch 843 (12843): mcc: 0.6374, acc: 0.5159, precision: 0.7479, recall: 0.5512, f1: 0.6346, edges-srl-ontonotes_loss: 0.0247
09/07 09:31:54 PM: ***** Step 13000 / Validation 13 *****
09/07 09:31:54 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:31:54 PM: Validating...
09/07 09:31:56 PM: Evaluate: task edges-srl-ontonotes, batch 26 (157): mcc: 0.6352, acc: 0.5175, precision: 0.7770, recall: 0.5266, f1: 0.6277, edges-srl-ontonotes_loss: 0.0251
09/07 09:32:02 PM: Updating LR scheduler:
09/07 09:32:02 PM: 	Best result seen so far for macro_avg: 0.647
09/07 09:32:02 PM: 	# validation passes without improvement: 5
09/07 09:32:02 PM: edges-srl-ontonotes_loss: training: 0.024110 validation: 0.025778
09/07 09:32:02 PM: macro_avg: validation: 0.627992
09/07 09:32:02 PM: micro_avg: validation: 0.000000
09/07 09:32:02 PM: edges-srl-ontonotes_mcc: training: 0.647998 validation: 0.632839
09/07 09:32:02 PM: edges-srl-ontonotes_acc: training: 0.529137 validation: 0.525210
09/07 09:32:02 PM: edges-srl-ontonotes_precision: training: 0.753936 validation: 0.757668
09/07 09:32:02 PM: edges-srl-ontonotes_recall: training: 0.564754 validation: 0.536217
09/07 09:32:02 PM: edges-srl-ontonotes_f1: training: 0.645774 validation: 0.627992
09/07 09:32:02 PM: Global learning rate: 0.0001
09/07 09:32:02 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:32:06 PM: Update 13080: task edges-srl-ontonotes, batch 80 (13080): mcc: 0.7004, acc: 0.5966, precision: 0.7787, recall: 0.6372, f1: 0.7009, edges-srl-ontonotes_loss: 0.0213
09/07 09:32:16 PM: Update 13262: task edges-srl-ontonotes, batch 262 (13262): mcc: 0.7088, acc: 0.6063, precision: 0.7841, recall: 0.6479, f1: 0.7095, edges-srl-ontonotes_loss: 0.0207
09/07 09:32:26 PM: Update 13464: task edges-srl-ontonotes, batch 464 (13464): mcc: 0.7187, acc: 0.6206, precision: 0.7921, recall: 0.6592, f1: 0.7195, edges-srl-ontonotes_loss: 0.0202
09/07 09:32:36 PM: Update 13606: task edges-srl-ontonotes, batch 606 (13606): mcc: 0.7281, acc: 0.6335, precision: 0.7999, recall: 0.6696, f1: 0.7290, edges-srl-ontonotes_loss: 0.0199
09/07 09:32:46 PM: Update 13809: task edges-srl-ontonotes, batch 809 (13809): mcc: 0.7418, acc: 0.6523, precision: 0.8113, recall: 0.6848, f1: 0.7427, edges-srl-ontonotes_loss: 0.0193
09/07 09:32:56 PM: Update 13994: task edges-srl-ontonotes, batch 994 (13994): mcc: 0.7265, acc: 0.6339, precision: 0.7997, recall: 0.6668, f1: 0.7273, edges-srl-ontonotes_loss: 0.0203
09/07 09:32:56 PM: ***** Step 14000 / Validation 14 *****
09/07 09:32:56 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:32:56 PM: Validating...
09/07 09:33:03 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:33:03 PM: Best result seen so far for macro.
09/07 09:33:03 PM: Updating LR scheduler:
09/07 09:33:03 PM: 	Best result seen so far for macro_avg: 0.662
09/07 09:33:03 PM: 	# validation passes without improvement: 0
09/07 09:33:03 PM: edges-srl-ontonotes_loss: training: 0.020354 validation: 0.024440
09/07 09:33:03 PM: macro_avg: validation: 0.662242
09/07 09:33:03 PM: micro_avg: validation: 0.000000
09/07 09:33:03 PM: edges-srl-ontonotes_mcc: training: 0.726178 validation: 0.664715
09/07 09:33:03 PM: edges-srl-ontonotes_acc: training: 0.633489 validation: 0.567855
09/07 09:33:03 PM: edges-srl-ontonotes_precision: training: 0.799541 validation: 0.771903
09/07 09:33:03 PM: edges-srl-ontonotes_recall: training: 0.666368 validation: 0.579863
09/07 09:33:03 PM: edges-srl-ontonotes_f1: training: 0.726905 validation: 0.662242
09/07 09:33:03 PM: Global learning rate: 0.0001
09/07 09:33:03 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:33:06 PM: Update 14054: task edges-srl-ontonotes, batch 54 (14054): mcc: 0.6582, acc: 0.5500, precision: 0.7457, recall: 0.5890, f1: 0.6581, edges-srl-ontonotes_loss: 0.0238
09/07 09:33:16 PM: Update 14236: task edges-srl-ontonotes, batch 236 (14236): mcc: 0.6383, acc: 0.5265, precision: 0.7323, recall: 0.5646, f1: 0.6376, edges-srl-ontonotes_loss: 0.0254
09/07 09:33:26 PM: Update 14440: task edges-srl-ontonotes, batch 440 (14440): mcc: 0.6253, acc: 0.5109, precision: 0.7254, recall: 0.5473, f1: 0.6239, edges-srl-ontonotes_loss: 0.0260
09/07 09:33:36 PM: Update 14573: task edges-srl-ontonotes, batch 573 (14573): mcc: 0.6305, acc: 0.5159, precision: 0.7324, recall: 0.5510, f1: 0.6289, edges-srl-ontonotes_loss: 0.0258
09/07 09:33:46 PM: Update 14765: task edges-srl-ontonotes, batch 765 (14765): mcc: 0.6409, acc: 0.5283, precision: 0.7420, recall: 0.5616, f1: 0.6394, edges-srl-ontonotes_loss: 0.0252
09/07 09:33:56 PM: Update 14944: task edges-srl-ontonotes, batch 944 (14944): mcc: 0.6479, acc: 0.5366, precision: 0.7478, recall: 0.5693, f1: 0.6465, edges-srl-ontonotes_loss: 0.0248
09/07 09:33:59 PM: ***** Step 15000 / Validation 15 *****
09/07 09:33:59 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:33:59 PM: Validating...
09/07 09:34:06 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:34:06 PM: Best result seen so far for macro.
09/07 09:34:06 PM: Updating LR scheduler:
09/07 09:34:06 PM: 	Best result seen so far for macro_avg: 0.671
09/07 09:34:06 PM: 	# validation passes without improvement: 0
09/07 09:34:06 PM: edges-srl-ontonotes_loss: training: 0.024605 validation: 0.023327
09/07 09:34:06 PM: macro_avg: validation: 0.670712
09/07 09:34:06 PM: micro_avg: validation: 0.000000
09/07 09:34:06 PM: edges-srl-ontonotes_mcc: training: 0.650288 validation: 0.674325
09/07 09:34:06 PM: edges-srl-ontonotes_acc: training: 0.539337 validation: 0.574167
09/07 09:34:06 PM: edges-srl-ontonotes_precision: training: 0.749681 validation: 0.789737
09/07 09:34:06 PM: edges-srl-ontonotes_recall: training: 0.571991 validation: 0.582865
09/07 09:34:06 PM: edges-srl-ontonotes_f1: training: 0.648892 validation: 0.670712
09/07 09:34:06 PM: Global learning rate: 0.0001
09/07 09:34:06 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:34:06 PM: Update 15004: task edges-srl-ontonotes, batch 4 (15004): mcc: 0.7186, acc: 0.6200, precision: 0.8109, recall: 0.6433, f1: 0.7175, edges-srl-ontonotes_loss: 0.0211
09/07 09:34:16 PM: Update 15190: task edges-srl-ontonotes, batch 190 (15190): mcc: 0.6644, acc: 0.5558, precision: 0.7604, recall: 0.5883, f1: 0.6634, edges-srl-ontonotes_loss: 0.0238
09/07 09:34:26 PM: Update 15398: task edges-srl-ontonotes, batch 398 (15398): mcc: 0.6398, acc: 0.5270, precision: 0.7406, recall: 0.5609, f1: 0.6383, edges-srl-ontonotes_loss: 0.0250
09/07 09:34:36 PM: Update 15551: task edges-srl-ontonotes, batch 551 (15551): mcc: 0.6311, acc: 0.5171, precision: 0.7331, recall: 0.5516, f1: 0.6295, edges-srl-ontonotes_loss: 0.0255
09/07 09:34:47 PM: Update 15745: task edges-srl-ontonotes, batch 745 (15745): mcc: 0.6245, acc: 0.5085, precision: 0.7292, recall: 0.5432, f1: 0.6226, edges-srl-ontonotes_loss: 0.0259
09/07 09:34:57 PM: Update 15954: task edges-srl-ontonotes, batch 954 (15954): mcc: 0.6169, acc: 0.4989, precision: 0.7234, recall: 0.5346, f1: 0.6148, edges-srl-ontonotes_loss: 0.0261
09/07 09:34:59 PM: ***** Step 16000 / Validation 16 *****
09/07 09:34:59 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:34:59 PM: Validating...
09/07 09:35:06 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:35:06 PM: Best result seen so far for macro.
09/07 09:35:06 PM: Updating LR scheduler:
09/07 09:35:06 PM: 	Best result seen so far for macro_avg: 0.675
09/07 09:35:06 PM: 	# validation passes without improvement: 0
09/07 09:35:06 PM: edges-srl-ontonotes_loss: training: 0.026121 validation: 0.023097
09/07 09:35:06 PM: macro_avg: validation: 0.675117
09/07 09:35:06 PM: micro_avg: validation: 0.000000
09/07 09:35:06 PM: edges-srl-ontonotes_mcc: training: 0.615033 validation: 0.678047
09/07 09:35:06 PM: edges-srl-ontonotes_acc: training: 0.496671 validation: 0.580941
09/07 09:35:06 PM: edges-srl-ontonotes_precision: training: 0.721728 validation: 0.788203
09/07 09:35:06 PM: edges-srl-ontonotes_recall: training: 0.532524 validation: 0.590409
09/07 09:35:06 PM: edges-srl-ontonotes_f1: training: 0.612855 validation: 0.675117
09/07 09:35:06 PM: Global learning rate: 0.0001
09/07 09:35:06 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:35:07 PM: Update 16017: task edges-srl-ontonotes, batch 17 (16017): mcc: 0.6134, acc: 0.4981, precision: 0.7163, recall: 0.5339, f1: 0.6118, edges-srl-ontonotes_loss: 0.0261
09/07 09:35:17 PM: Update 16202: task edges-srl-ontonotes, batch 202 (16202): mcc: 0.5747, acc: 0.4480, precision: 0.6975, recall: 0.4822, f1: 0.5702, edges-srl-ontonotes_loss: 0.0280
09/07 09:35:28 PM: Update 16371: task edges-srl-ontonotes, batch 371 (16371): mcc: 0.5735, acc: 0.4457, precision: 0.6967, recall: 0.4807, f1: 0.5689, edges-srl-ontonotes_loss: 0.0282
09/07 09:35:38 PM: Update 16578: task edges-srl-ontonotes, batch 578 (16578): mcc: 0.5737, acc: 0.4461, precision: 0.6983, recall: 0.4799, f1: 0.5689, edges-srl-ontonotes_loss: 0.0283
09/07 09:35:48 PM: Update 16761: task edges-srl-ontonotes, batch 761 (16761): mcc: 0.5728, acc: 0.4451, precision: 0.6972, recall: 0.4792, f1: 0.5680, edges-srl-ontonotes_loss: 0.0282
09/07 09:35:58 PM: Update 16965: task edges-srl-ontonotes, batch 965 (16965): mcc: 0.5741, acc: 0.4466, precision: 0.6964, recall: 0.4820, f1: 0.5697, edges-srl-ontonotes_loss: 0.0280
09/07 09:36:01 PM: ***** Step 17000 / Validation 17 *****
09/07 09:36:01 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:36:01 PM: Validating...
09/07 09:36:08 PM: Updating LR scheduler:
09/07 09:36:08 PM: 	Best result seen so far for macro_avg: 0.675
09/07 09:36:08 PM: 	# validation passes without improvement: 1
09/07 09:36:08 PM: edges-srl-ontonotes_loss: training: 0.027956 validation: 0.023865
09/07 09:36:08 PM: macro_avg: validation: 0.647388
09/07 09:36:08 PM: micro_avg: validation: 0.000000
09/07 09:36:08 PM: edges-srl-ontonotes_mcc: training: 0.574300 validation: 0.653133
09/07 09:36:08 PM: edges-srl-ontonotes_acc: training: 0.446645 validation: 0.545070
09/07 09:36:08 PM: edges-srl-ontonotes_precision: training: 0.696256 validation: 0.783722
09/07 09:36:08 PM: edges-srl-ontonotes_recall: training: 0.482398 validation: 0.551459
09/07 09:36:08 PM: edges-srl-ontonotes_f1: training: 0.569926 validation: 0.647388
09/07 09:36:08 PM: Global learning rate: 0.0001
09/07 09:36:08 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:36:08 PM: Update 17001: task edges-srl-ontonotes, batch 1 (17001): mcc: 0.5628, acc: 0.4368, precision: 0.7018, recall: 0.4598, f1: 0.5556, edges-srl-ontonotes_loss: 0.0302
09/07 09:36:18 PM: Update 17208: task edges-srl-ontonotes, batch 208 (17208): mcc: 0.5900, acc: 0.4667, precision: 0.6999, recall: 0.5061, f1: 0.5874, edges-srl-ontonotes_loss: 0.0267
09/07 09:36:28 PM: Update 17392: task edges-srl-ontonotes, batch 392 (17392): mcc: 0.5929, acc: 0.4712, precision: 0.7026, recall: 0.5090, f1: 0.5903, edges-srl-ontonotes_loss: 0.0267
09/07 09:36:38 PM: Update 17592: task edges-srl-ontonotes, batch 592 (17592): mcc: 0.5983, acc: 0.4766, precision: 0.7088, recall: 0.5136, f1: 0.5956, edges-srl-ontonotes_loss: 0.0264
09/07 09:36:48 PM: Update 17737: task edges-srl-ontonotes, batch 737 (17737): mcc: 0.5936, acc: 0.4716, precision: 0.7054, recall: 0.5082, f1: 0.5908, edges-srl-ontonotes_loss: 0.0267
09/07 09:36:59 PM: Update 17936: task edges-srl-ontonotes, batch 936 (17936): mcc: 0.5920, acc: 0.4692, precision: 0.7053, recall: 0.5055, f1: 0.5889, edges-srl-ontonotes_loss: 0.0268
09/07 09:37:02 PM: ***** Step 18000 / Validation 18 *****
09/07 09:37:02 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:37:02 PM: Validating...
09/07 09:37:09 PM: Evaluate: task edges-srl-ontonotes, batch 153 (157): mcc: 0.6466, acc: 0.5411, precision: 0.7785, recall: 0.5443, f1: 0.6407, edges-srl-ontonotes_loss: 0.0243
09/07 09:37:09 PM: Updating LR scheduler:
09/07 09:37:09 PM: 	Best result seen so far for macro_avg: 0.675
09/07 09:37:09 PM: 	# validation passes without improvement: 2
09/07 09:37:09 PM: edges-srl-ontonotes_loss: training: 0.026884 validation: 0.024327
09/07 09:37:09 PM: macro_avg: validation: 0.639819
09/07 09:37:09 PM: micro_avg: validation: 0.000000
09/07 09:37:09 PM: edges-srl-ontonotes_mcc: training: 0.590881 validation: 0.645726
09/07 09:37:09 PM: edges-srl-ontonotes_acc: training: 0.468077 validation: 0.540297
09/07 09:37:09 PM: edges-srl-ontonotes_precision: training: 0.704588 validation: 0.777411
09/07 09:37:09 PM: edges-srl-ontonotes_recall: training: 0.504175 validation: 0.543607
09/07 09:37:09 PM: edges-srl-ontonotes_f1: training: 0.587767 validation: 0.639819
09/07 09:37:09 PM: Global learning rate: 0.0001
09/07 09:37:09 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:37:19 PM: Update 18205: task edges-srl-ontonotes, batch 205 (18205): mcc: 0.5873, acc: 0.4606, precision: 0.7072, recall: 0.4962, f1: 0.5832, edges-srl-ontonotes_loss: 0.0273
09/07 09:37:29 PM: Update 18394: task edges-srl-ontonotes, batch 394 (18394): mcc: 0.5877, acc: 0.4622, precision: 0.7059, recall: 0.4979, f1: 0.5840, edges-srl-ontonotes_loss: 0.0273
09/07 09:37:40 PM: Update 18562: task edges-srl-ontonotes, batch 562 (18562): mcc: 0.5879, acc: 0.4632, precision: 0.7061, recall: 0.4980, f1: 0.5841, edges-srl-ontonotes_loss: 0.0272
09/07 09:37:50 PM: Update 18766: task edges-srl-ontonotes, batch 766 (18766): mcc: 0.5904, acc: 0.4667, precision: 0.7070, recall: 0.5017, f1: 0.5869, edges-srl-ontonotes_loss: 0.0270
09/07 09:38:00 PM: Update 18948: task edges-srl-ontonotes, batch 948 (18948): mcc: 0.5934, acc: 0.4702, precision: 0.7091, recall: 0.5051, f1: 0.5899, edges-srl-ontonotes_loss: 0.0269
09/07 09:38:03 PM: ***** Step 19000 / Validation 19 *****
09/07 09:38:03 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:38:03 PM: Validating...
09/07 09:38:10 PM: Updating LR scheduler:
09/07 09:38:10 PM: 	Best result seen so far for macro_avg: 0.675
09/07 09:38:10 PM: 	# validation passes without improvement: 3
09/07 09:38:10 PM: edges-srl-ontonotes_loss: training: 0.026889 validation: 0.024621
09/07 09:38:10 PM: macro_avg: validation: 0.638527
09/07 09:38:10 PM: micro_avg: validation: 0.000000
09/07 09:38:10 PM: edges-srl-ontonotes_mcc: training: 0.593800 validation: 0.642845
09/07 09:38:10 PM: edges-srl-ontonotes_acc: training: 0.470707 validation: 0.544685
09/07 09:38:10 PM: edges-srl-ontonotes_precision: training: 0.709507 validation: 0.763993
09/07 09:38:10 PM: edges-srl-ontonotes_recall: training: 0.505509 validation: 0.548457
09/07 09:38:10 PM: edges-srl-ontonotes_f1: training: 0.590383 validation: 0.638527
09/07 09:38:10 PM: Global learning rate: 0.0001
09/07 09:38:10 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:38:10 PM: Update 19007: task edges-srl-ontonotes, batch 7 (19007): mcc: 0.5840, acc: 0.4680, precision: 0.6887, recall: 0.5043, f1: 0.5823, edges-srl-ontonotes_loss: 0.0251
09/07 09:38:20 PM: Update 19190: task edges-srl-ontonotes, batch 190 (19190): mcc: 0.5961, acc: 0.4758, precision: 0.7056, recall: 0.5123, f1: 0.5936, edges-srl-ontonotes_loss: 0.0265
09/07 09:38:30 PM: Update 19399: task edges-srl-ontonotes, batch 399 (19399): mcc: 0.5823, acc: 0.4582, precision: 0.7015, recall: 0.4920, f1: 0.5784, edges-srl-ontonotes_loss: 0.0275
09/07 09:38:40 PM: Update 19546: task edges-srl-ontonotes, batch 546 (19546): mcc: 0.5889, acc: 0.4645, precision: 0.7086, recall: 0.4979, f1: 0.5849, edges-srl-ontonotes_loss: 0.0272
09/07 09:38:50 PM: Update 19746: task edges-srl-ontonotes, batch 746 (19746): mcc: 0.6052, acc: 0.4829, precision: 0.7207, recall: 0.5165, f1: 0.6018, edges-srl-ontonotes_loss: 0.0263
09/07 09:39:00 PM: Update 19928: task edges-srl-ontonotes, batch 928 (19928): mcc: 0.6220, acc: 0.5023, precision: 0.7328, recall: 0.5361, f1: 0.6192, edges-srl-ontonotes_loss: 0.0254
09/07 09:39:04 PM: ***** Step 20000 / Validation 20 *****
09/07 09:39:04 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:39:04 PM: Validating...
09/07 09:39:10 PM: Evaluate: task edges-srl-ontonotes, batch 141 (157): mcc: 0.6519, acc: 0.5514, precision: 0.7662, recall: 0.5621, f1: 0.6485, edges-srl-ontonotes_loss: 0.0244
09/07 09:39:11 PM: Updating LR scheduler:
09/07 09:39:11 PM: 	Best result seen so far for macro_avg: 0.675
09/07 09:39:11 PM: 	# validation passes without improvement: 4
09/07 09:39:11 PM: edges-srl-ontonotes_loss: training: 0.024994 validation: 0.024680
09/07 09:39:11 PM: macro_avg: validation: 0.642361
09/07 09:39:11 PM: micro_avg: validation: 0.000000
09/07 09:39:11 PM: edges-srl-ontonotes_mcc: training: 0.629569 validation: 0.645911
09/07 09:39:11 PM: edges-srl-ontonotes_acc: training: 0.511347 validation: 0.544916
09/07 09:39:11 PM: edges-srl-ontonotes_precision: training: 0.738475 validation: 0.761638
09/07 09:39:11 PM: edges-srl-ontonotes_recall: training: 0.544809 validation: 0.555385
09/07 09:39:11 PM: edges-srl-ontonotes_f1: training: 0.627028 validation: 0.642361
09/07 09:39:11 PM: Global learning rate: 0.0001
09/07 09:39:11 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:39:20 PM: Update 20167: task edges-srl-ontonotes, batch 167 (20167): mcc: 0.7177, acc: 0.6192, precision: 0.7934, recall: 0.6561, f1: 0.7183, edges-srl-ontonotes_loss: 0.0198
09/07 09:39:30 PM: Update 20368: task edges-srl-ontonotes, batch 368 (20368): mcc: 0.7167, acc: 0.6204, precision: 0.7914, recall: 0.6560, f1: 0.7174, edges-srl-ontonotes_loss: 0.0199
09/07 09:39:40 PM: Update 20550: task edges-srl-ontonotes, batch 550 (20550): mcc: 0.7206, acc: 0.6259, precision: 0.7932, recall: 0.6617, f1: 0.7215, edges-srl-ontonotes_loss: 0.0198
09/07 09:39:50 PM: Update 20751: task edges-srl-ontonotes, batch 751 (20751): mcc: 0.7267, acc: 0.6340, precision: 0.7966, recall: 0.6697, f1: 0.7277, edges-srl-ontonotes_loss: 0.0196
09/07 09:40:00 PM: Update 20895: task edges-srl-ontonotes, batch 895 (20895): mcc: 0.7359, acc: 0.6465, precision: 0.8040, recall: 0.6802, f1: 0.7369, edges-srl-ontonotes_loss: 0.0192
09/07 09:40:05 PM: ***** Step 21000 / Validation 21 *****
09/07 09:40:05 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:40:05 PM: Validating...
09/07 09:40:10 PM: Evaluate: task edges-srl-ontonotes, batch 105 (157): mcc: 0.6755, acc: 0.5874, precision: 0.7756, recall: 0.5957, f1: 0.6739, edges-srl-ontonotes_loss: 0.0238
09/07 09:40:12 PM: Updating LR scheduler:
09/07 09:40:12 PM: 	Best result seen so far for macro_avg: 0.675
09/07 09:40:12 PM: 	# validation passes without improvement: 5
09/07 09:40:12 PM: edges-srl-ontonotes_loss: training: 0.019018 validation: 0.024471
09/07 09:40:12 PM: macro_avg: validation: 0.663194
09/07 09:40:12 PM: micro_avg: validation: 0.000000
09/07 09:40:12 PM: edges-srl-ontonotes_mcc: training: 0.741471 validation: 0.665194
09/07 09:40:12 PM: edges-srl-ontonotes_acc: training: 0.654092 validation: 0.575552
09/07 09:40:12 PM: edges-srl-ontonotes_precision: training: 0.808492 validation: 0.768669
09/07 09:40:12 PM: edges-srl-ontonotes_recall: training: 0.686578 validation: 0.583173
09/07 09:40:12 PM: edges-srl-ontonotes_f1: training: 0.742564 validation: 0.663194
09/07 09:40:12 PM: Global learning rate: 0.0001
09/07 09:40:12 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:40:20 PM: Update 21138: task edges-srl-ontonotes, batch 138 (21138): mcc: 0.7327, acc: 0.6474, precision: 0.8055, recall: 0.6731, f1: 0.7334, edges-srl-ontonotes_loss: 0.0202
09/07 09:40:30 PM: Update 21344: task edges-srl-ontonotes, batch 344 (21344): mcc: 0.6909, acc: 0.5963, precision: 0.7709, recall: 0.6267, f1: 0.6914, edges-srl-ontonotes_loss: 0.0224
09/07 09:40:40 PM: Update 21526: task edges-srl-ontonotes, batch 526 (21526): mcc: 0.6651, acc: 0.5643, precision: 0.7520, recall: 0.5961, f1: 0.6651, edges-srl-ontonotes_loss: 0.0238
09/07 09:40:50 PM: Update 21722: task edges-srl-ontonotes, batch 722 (21722): mcc: 0.6537, acc: 0.5496, precision: 0.7452, recall: 0.5815, f1: 0.6532, edges-srl-ontonotes_loss: 0.0244
09/07 09:41:00 PM: Update 21868: task edges-srl-ontonotes, batch 868 (21868): mcc: 0.6567, acc: 0.5523, precision: 0.7492, recall: 0.5835, f1: 0.6560, edges-srl-ontonotes_loss: 0.0243
09/07 09:41:07 PM: ***** Step 22000 / Validation 22 *****
09/07 09:41:07 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:41:07 PM: Validating...
09/07 09:41:10 PM: Evaluate: task edges-srl-ontonotes, batch 73 (157): mcc: 0.6875, acc: 0.5873, precision: 0.8025, recall: 0.5958, f1: 0.6839, edges-srl-ontonotes_loss: 0.0227
09/07 09:41:14 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:41:14 PM: Best result seen so far for macro.
09/07 09:41:14 PM: Updating LR scheduler:
09/07 09:41:14 PM: 	Best result seen so far for macro_avg: 0.677
09/07 09:41:14 PM: 	# validation passes without improvement: 0
09/07 09:41:14 PM: edges-srl-ontonotes_loss: training: 0.024048 validation: 0.022746
09/07 09:41:14 PM: macro_avg: validation: 0.677415
09/07 09:41:14 PM: micro_avg: validation: 0.000000
09/07 09:41:14 PM: edges-srl-ontonotes_mcc: training: 0.660421 validation: 0.680856
09/07 09:41:14 PM: edges-srl-ontonotes_acc: training: 0.556380 validation: 0.582172
09/07 09:41:14 PM: edges-srl-ontonotes_precision: training: 0.753121 validation: 0.794776
09/07 09:41:14 PM: edges-srl-ontonotes_recall: training: 0.587003 validation: 0.590255
09/07 09:41:14 PM: edges-srl-ontonotes_f1: training: 0.659766 validation: 0.677415
09/07 09:41:14 PM: Global learning rate: 0.0001
09/07 09:41:14 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:41:20 PM: Update 22104: task edges-srl-ontonotes, batch 104 (22104): mcc: 0.6903, acc: 0.5866, precision: 0.7861, recall: 0.6134, f1: 0.6891, edges-srl-ontonotes_loss: 0.0222
09/07 09:41:30 PM: Update 22306: task edges-srl-ontonotes, batch 306 (22306): mcc: 0.6948, acc: 0.5938, precision: 0.7838, recall: 0.6230, f1: 0.6942, edges-srl-ontonotes_loss: 0.0218
09/07 09:41:40 PM: Update 22490: task edges-srl-ontonotes, batch 490 (22490): mcc: 0.6771, acc: 0.5730, precision: 0.7692, recall: 0.6035, f1: 0.6764, edges-srl-ontonotes_loss: 0.0228
09/07 09:41:52 PM: Update 22678: task edges-srl-ontonotes, batch 678 (22678): mcc: 0.6656, acc: 0.5592, precision: 0.7597, recall: 0.5909, f1: 0.6648, edges-srl-ontonotes_loss: 0.0235
09/07 09:42:03 PM: Update 22891: task edges-srl-ontonotes, batch 891 (22891): mcc: 0.6530, acc: 0.5437, precision: 0.7508, recall: 0.5758, f1: 0.6518, edges-srl-ontonotes_loss: 0.0242
09/07 09:42:09 PM: ***** Step 23000 / Validation 23 *****
09/07 09:42:09 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:42:09 PM: Validating...
09/07 09:42:13 PM: Evaluate: task edges-srl-ontonotes, batch 84 (157): mcc: 0.6899, acc: 0.5962, precision: 0.7957, recall: 0.6052, f1: 0.6875, edges-srl-ontonotes_loss: 0.0223
09/07 09:42:16 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:42:16 PM: Best result seen so far for macro.
09/07 09:42:16 PM: Updating LR scheduler:
09/07 09:42:16 PM: 	Best result seen so far for macro_avg: 0.685
09/07 09:42:16 PM: 	# validation passes without improvement: 0
09/07 09:42:16 PM: edges-srl-ontonotes_loss: training: 0.024401 validation: 0.022195
09/07 09:42:16 PM: macro_avg: validation: 0.685247
09/07 09:42:16 PM: micro_avg: validation: 0.000000
09/07 09:42:16 PM: edges-srl-ontonotes_mcc: training: 0.648710 validation: 0.687711
09/07 09:42:16 PM: edges-srl-ontonotes_acc: training: 0.538606 validation: 0.594565
09/07 09:42:16 PM: edges-srl-ontonotes_precision: training: 0.747366 validation: 0.793817
09/07 09:42:16 PM: edges-srl-ontonotes_recall: training: 0.571046 validation: 0.602802
09/07 09:42:16 PM: edges-srl-ontonotes_f1: training: 0.647415 validation: 0.685247
09/07 09:42:16 PM: Global learning rate: 0.0001
09/07 09:42:16 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:42:23 PM: Update 23144: task edges-srl-ontonotes, batch 144 (23144): mcc: 0.5968, acc: 0.4773, precision: 0.7039, recall: 0.5147, f1: 0.5946, edges-srl-ontonotes_loss: 0.0263
09/07 09:42:33 PM: Update 23332: task edges-srl-ontonotes, batch 332 (23332): mcc: 0.5942, acc: 0.4742, precision: 0.7029, recall: 0.5111, f1: 0.5919, edges-srl-ontonotes_loss: 0.0265
09/07 09:42:43 PM: Update 23538: task edges-srl-ontonotes, batch 538 (23538): mcc: 0.5852, acc: 0.4641, precision: 0.6993, recall: 0.4985, f1: 0.5821, edges-srl-ontonotes_loss: 0.0272
09/07 09:42:53 PM: Update 23722: task edges-srl-ontonotes, batch 722 (23722): mcc: 0.5854, acc: 0.4637, precision: 0.7012, recall: 0.4975, f1: 0.5820, edges-srl-ontonotes_loss: 0.0273
09/07 09:43:05 PM: Update 23930: task edges-srl-ontonotes, batch 930 (23930): mcc: 0.5841, acc: 0.4617, precision: 0.7017, recall: 0.4949, f1: 0.5804, edges-srl-ontonotes_loss: 0.0274
09/07 09:43:09 PM: ***** Step 24000 / Validation 24 *****
09/07 09:43:09 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:43:09 PM: Validating...
09/07 09:43:15 PM: Evaluate: task edges-srl-ontonotes, batch 148 (157): mcc: 0.6705, acc: 0.5706, precision: 0.7887, recall: 0.5772, f1: 0.6666, edges-srl-ontonotes_loss: 0.0228
09/07 09:43:16 PM: Updating LR scheduler:
09/07 09:43:16 PM: 	Best result seen so far for macro_avg: 0.685
09/07 09:43:16 PM: 	# validation passes without improvement: 1
09/07 09:43:16 PM: edges-srl-ontonotes_loss: training: 0.027374 validation: 0.022961
09/07 09:43:16 PM: macro_avg: validation: 0.664621
09/07 09:43:16 PM: micro_avg: validation: 0.000000
09/07 09:43:16 PM: edges-srl-ontonotes_mcc: training: 0.584120 validation: 0.668606
09/07 09:43:16 PM: edges-srl-ontonotes_acc: training: 0.461333 validation: 0.568701
09/07 09:43:16 PM: edges-srl-ontonotes_precision: training: 0.701555 validation: 0.786880
09/07 09:43:16 PM: edges-srl-ontonotes_recall: training: 0.495004 validation: 0.575244
09/07 09:43:16 PM: edges-srl-ontonotes_f1: training: 0.580452 validation: 0.664621
09/07 09:43:16 PM: Global learning rate: 0.0001
09/07 09:43:16 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:43:26 PM: Update 24195: task edges-srl-ontonotes, batch 195 (24195): mcc: 0.5928, acc: 0.4711, precision: 0.7019, recall: 0.5094, f1: 0.5903, edges-srl-ontonotes_loss: 0.0264
09/07 09:43:36 PM: Update 24377: task edges-srl-ontonotes, batch 377 (24377): mcc: 0.5941, acc: 0.4721, precision: 0.7035, recall: 0.5104, f1: 0.5916, edges-srl-ontonotes_loss: 0.0264
09/07 09:43:46 PM: Update 24562: task edges-srl-ontonotes, batch 562 (24562): mcc: 0.5966, acc: 0.4753, precision: 0.7058, recall: 0.5130, f1: 0.5941, edges-srl-ontonotes_loss: 0.0263
09/07 09:43:56 PM: Update 24766: task edges-srl-ontonotes, batch 766 (24766): mcc: 0.5997, acc: 0.4795, precision: 0.7084, recall: 0.5162, f1: 0.5972, edges-srl-ontonotes_loss: 0.0262
09/07 09:44:06 PM: Update 24913: task edges-srl-ontonotes, batch 913 (24913): mcc: 0.6023, acc: 0.4827, precision: 0.7107, recall: 0.5190, f1: 0.5999, edges-srl-ontonotes_loss: 0.0262
09/07 09:44:10 PM: ***** Step 25000 / Validation 25 *****
09/07 09:44:10 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:44:10 PM: Validating...
09/07 09:44:16 PM: Evaluate: task edges-srl-ontonotes, batch 127 (157): mcc: 0.6818, acc: 0.5865, precision: 0.7936, recall: 0.5929, f1: 0.6787, edges-srl-ontonotes_loss: 0.0229
09/07 09:44:17 PM: Updating LR scheduler:
09/07 09:44:17 PM: 	Best result seen so far for macro_avg: 0.685
09/07 09:44:17 PM: 	# validation passes without improvement: 2
09/07 09:44:17 PM: edges-srl-ontonotes_loss: training: 0.026221 validation: 0.023386
09/07 09:44:17 PM: macro_avg: validation: 0.665752
09/07 09:44:17 PM: micro_avg: validation: 0.000000
09/07 09:44:17 PM: edges-srl-ontonotes_mcc: training: 0.600961 validation: 0.669190
09/07 09:44:17 PM: edges-srl-ontonotes_acc: training: 0.481226 validation: 0.572242
09/07 09:44:17 PM: edges-srl-ontonotes_precision: training: 0.709875 validation: 0.783474
09/07 09:44:17 PM: edges-srl-ontonotes_recall: training: 0.517366 validation: 0.578785
09/07 09:44:17 PM: edges-srl-ontonotes_f1: training: 0.598521 validation: 0.665752
09/07 09:44:17 PM: Global learning rate: 0.0001
09/07 09:44:17 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:44:26 PM: Update 25180: task edges-srl-ontonotes, batch 180 (25180): mcc: 0.5864, acc: 0.4664, precision: 0.6995, recall: 0.5003, f1: 0.5834, edges-srl-ontonotes_loss: 0.0268
09/07 09:44:36 PM: Update 25365: task edges-srl-ontonotes, batch 365 (25365): mcc: 0.5913, acc: 0.4712, precision: 0.7049, recall: 0.5047, f1: 0.5882, edges-srl-ontonotes_loss: 0.0267
09/07 09:44:46 PM: Update 25553: task edges-srl-ontonotes, batch 553 (25553): mcc: 0.5923, acc: 0.4727, precision: 0.7052, recall: 0.5062, f1: 0.5893, edges-srl-ontonotes_loss: 0.0267
09/07 09:44:56 PM: Update 25762: task edges-srl-ontonotes, batch 762 (25762): mcc: 0.5916, acc: 0.4722, precision: 0.7045, recall: 0.5055, f1: 0.5887, edges-srl-ontonotes_loss: 0.0267
09/07 09:45:06 PM: Update 25908: task edges-srl-ontonotes, batch 908 (25908): mcc: 0.5932, acc: 0.4741, precision: 0.7057, recall: 0.5072, f1: 0.5902, edges-srl-ontonotes_loss: 0.0267
09/07 09:45:10 PM: ***** Step 26000 / Validation 26 *****
09/07 09:45:10 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:45:10 PM: Validating...
09/07 09:45:16 PM: Evaluate: task edges-srl-ontonotes, batch 124 (157): mcc: 0.6681, acc: 0.5738, precision: 0.7791, recall: 0.5802, f1: 0.6651, edges-srl-ontonotes_loss: 0.0235
09/07 09:45:17 PM: Updating LR scheduler:
09/07 09:45:17 PM: 	Best result seen so far for macro_avg: 0.685
09/07 09:45:17 PM: 	# validation passes without improvement: 3
09/07 09:45:17 PM: edges-srl-ontonotes_loss: training: 0.026612 validation: 0.023848
09/07 09:45:17 PM: macro_avg: validation: 0.654780
09/07 09:45:17 PM: micro_avg: validation: 0.000000
09/07 09:45:17 PM: edges-srl-ontonotes_mcc: training: 0.594817 validation: 0.657862
09/07 09:45:17 PM: edges-srl-ontonotes_acc: training: 0.475797 validation: 0.562543
09/07 09:45:17 PM: edges-srl-ontonotes_precision: training: 0.707171 validation: 0.769871
09/07 09:45:17 PM: edges-srl-ontonotes_recall: training: 0.508935 validation: 0.569625
09/07 09:45:17 PM: edges-srl-ontonotes_f1: training: 0.591896 validation: 0.654780
09/07 09:45:17 PM: Global learning rate: 0.0001
09/07 09:45:17 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:45:26 PM: Update 26153: task edges-srl-ontonotes, batch 153 (26153): mcc: 0.6060, acc: 0.4896, precision: 0.7135, recall: 0.5233, f1: 0.6038, edges-srl-ontonotes_loss: 0.0261
09/07 09:45:36 PM: Update 26358: task edges-srl-ontonotes, batch 358 (26358): mcc: 0.6101, acc: 0.4940, precision: 0.7163, recall: 0.5282, f1: 0.6081, edges-srl-ontonotes_loss: 0.0259
09/07 09:45:46 PM: Update 26544: task edges-srl-ontonotes, batch 544 (26544): mcc: 0.6013, acc: 0.4838, precision: 0.7121, recall: 0.5163, f1: 0.5986, edges-srl-ontonotes_loss: 0.0265
09/07 09:45:57 PM: Update 26747: task edges-srl-ontonotes, batch 747 (26747): mcc: 0.5979, acc: 0.4784, precision: 0.7119, recall: 0.5108, f1: 0.5948, edges-srl-ontonotes_loss: 0.0267
09/07 09:46:07 PM: Update 26951: task edges-srl-ontonotes, batch 951 (26951): mcc: 0.6097, acc: 0.4919, precision: 0.7215, recall: 0.5236, f1: 0.6068, edges-srl-ontonotes_loss: 0.0260
09/07 09:46:09 PM: ***** Step 27000 / Validation 27 *****
09/07 09:46:09 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:46:09 PM: Validating...
09/07 09:46:16 PM: Updating LR scheduler:
09/07 09:46:16 PM: 	Best result seen so far for macro_avg: 0.685
09/07 09:46:16 PM: 	# validation passes without improvement: 4
09/07 09:46:16 PM: edges-srl-ontonotes_loss: training: 0.025822 validation: 0.023885
09/07 09:46:16 PM: macro_avg: validation: 0.655929
09/07 09:46:16 PM: micro_avg: validation: 0.000000
09/07 09:46:16 PM: edges-srl-ontonotes_mcc: training: 0.612609 validation: 0.659056
09/07 09:46:16 PM: edges-srl-ontonotes_acc: training: 0.495095 validation: 0.562235
09/07 09:46:16 PM: edges-srl-ontonotes_precision: training: 0.723759 validation: 0.771360
09/07 09:46:16 PM: edges-srl-ontonotes_recall: training: 0.526868 validation: 0.570549
09/07 09:46:16 PM: edges-srl-ontonotes_f1: training: 0.609815 validation: 0.655929
09/07 09:46:16 PM: Global learning rate: 0.0001
09/07 09:46:16 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:46:17 PM: Update 27012: task edges-srl-ontonotes, batch 12 (27012): mcc: 0.6735, acc: 0.5610, precision: 0.7541, recall: 0.6095, f1: 0.6741, edges-srl-ontonotes_loss: 0.0227
09/07 09:46:27 PM: Update 27158: task edges-srl-ontonotes, batch 158 (27158): mcc: 0.6944, acc: 0.5906, precision: 0.7806, recall: 0.6249, f1: 0.6941, edges-srl-ontonotes_loss: 0.0211
09/07 09:46:37 PM: Update 27362: task edges-srl-ontonotes, batch 362 (27362): mcc: 0.7141, acc: 0.6146, precision: 0.7941, recall: 0.6491, f1: 0.7143, edges-srl-ontonotes_loss: 0.0200
09/07 09:46:47 PM: Update 27542: task edges-srl-ontonotes, batch 542 (27542): mcc: 0.7155, acc: 0.6187, precision: 0.7931, recall: 0.6525, f1: 0.7160, edges-srl-ontonotes_loss: 0.0200
09/07 09:46:57 PM: Update 27724: task edges-srl-ontonotes, batch 724 (27724): mcc: 0.7200, acc: 0.6253, precision: 0.7944, recall: 0.6596, f1: 0.7207, edges-srl-ontonotes_loss: 0.0197
09/07 09:47:07 PM: Update 27929: task edges-srl-ontonotes, batch 929 (27929): mcc: 0.7269, acc: 0.6345, precision: 0.7989, recall: 0.6683, f1: 0.7278, edges-srl-ontonotes_loss: 0.0194
09/07 09:47:13 PM: ***** Step 28000 / Validation 28 *****
09/07 09:47:13 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:47:13 PM: Validating...
09/07 09:47:17 PM: Evaluate: task edges-srl-ontonotes, batch 79 (157): mcc: 0.6788, acc: 0.5896, precision: 0.7742, recall: 0.6025, f1: 0.6776, edges-srl-ontonotes_loss: 0.0239
09/07 09:47:20 PM: Updating LR scheduler:
09/07 09:47:20 PM: 	Best result seen so far for macro_avg: 0.685
09/07 09:47:20 PM: 	# validation passes without improvement: 5
09/07 09:47:20 PM: edges-srl-ontonotes_loss: training: 0.019360 validation: 0.023788
09/07 09:47:20 PM: macro_avg: validation: 0.672930
09/07 09:47:20 PM: micro_avg: validation: 0.000000
09/07 09:47:20 PM: edges-srl-ontonotes_mcc: training: 0.728307 validation: 0.673962
09/07 09:47:20 PM: edges-srl-ontonotes_acc: training: 0.636620 validation: 0.585867
09/07 09:47:20 PM: edges-srl-ontonotes_precision: training: 0.799515 validation: 0.769025
09/07 09:47:20 PM: edges-srl-ontonotes_recall: training: 0.670253 validation: 0.598183
09/07 09:47:20 PM: edges-srl-ontonotes_f1: training: 0.729200 validation: 0.672930
09/07 09:47:20 PM: Global learning rate: 0.0001
09/07 09:47:20 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:47:27 PM: Update 28130: task edges-srl-ontonotes, batch 130 (28130): mcc: 0.7895, acc: 0.7190, precision: 0.8494, recall: 0.7393, f1: 0.7905, edges-srl-ontonotes_loss: 0.0172
09/07 09:47:37 PM: Update 28312: task edges-srl-ontonotes, batch 312 (28312): mcc: 0.7924, acc: 0.7255, precision: 0.8476, recall: 0.7463, f1: 0.7937, edges-srl-ontonotes_loss: 0.0168
09/07 09:47:47 PM: Update 28517: task edges-srl-ontonotes, batch 517 (28517): mcc: 0.7441, acc: 0.6637, precision: 0.8113, recall: 0.6890, f1: 0.7452, edges-srl-ontonotes_loss: 0.0196
09/07 09:47:57 PM: Update 28699: task edges-srl-ontonotes, batch 699 (28699): mcc: 0.7215, acc: 0.6352, precision: 0.7947, recall: 0.6620, f1: 0.7223, edges-srl-ontonotes_loss: 0.0208
09/07 09:48:07 PM: Update 28900: task edges-srl-ontonotes, batch 900 (28900): mcc: 0.7003, acc: 0.6087, precision: 0.7794, recall: 0.6365, f1: 0.7007, edges-srl-ontonotes_loss: 0.0219
09/07 09:48:15 PM: ***** Step 29000 / Validation 29 *****
09/07 09:48:15 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:48:15 PM: Validating...
09/07 09:48:17 PM: Evaluate: task edges-srl-ontonotes, batch 46 (157): mcc: 0.6671, acc: 0.5710, precision: 0.7803, recall: 0.5775, f1: 0.6638, edges-srl-ontonotes_loss: 0.0239
09/07 09:48:22 PM: Updating LR scheduler:
09/07 09:48:22 PM: 	Best result seen so far for macro_avg: 0.685
09/07 09:48:22 PM: 	# validation passes without improvement: 0
09/07 09:48:22 PM: edges-srl-ontonotes_loss: training: 0.022231 validation: 0.023029
09/07 09:48:22 PM: macro_avg: validation: 0.674739
09/07 09:48:22 PM: micro_avg: validation: 0.000000
09/07 09:48:22 PM: edges-srl-ontonotes_mcc: training: 0.694026 validation: 0.676854
09/07 09:48:22 PM: edges-srl-ontonotes_acc: training: 0.600285 validation: 0.588022
09/07 09:48:22 PM: edges-srl-ontonotes_precision: training: 0.775785 validation: 0.780700
09/07 09:48:22 PM: edges-srl-ontonotes_recall: training: 0.628275 validation: 0.594104
09/07 09:48:22 PM: edges-srl-ontonotes_f1: training: 0.694281 validation: 0.674739
09/07 09:48:22 PM: Global learning rate: 5e-05
09/07 09:48:22 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:48:27 PM: Update 29099: task edges-srl-ontonotes, batch 99 (29099): mcc: 0.6824, acc: 0.5842, precision: 0.7765, recall: 0.6072, f1: 0.6815, edges-srl-ontonotes_loss: 0.0228
09/07 09:48:37 PM: Update 29295: task edges-srl-ontonotes, batch 295 (29295): mcc: 0.6886, acc: 0.5901, precision: 0.7805, recall: 0.6148, f1: 0.6878, edges-srl-ontonotes_loss: 0.0224
09/07 09:48:47 PM: Update 29474: task edges-srl-ontonotes, batch 474 (29474): mcc: 0.6936, acc: 0.5960, precision: 0.7832, recall: 0.6215, f1: 0.6930, edges-srl-ontonotes_loss: 0.0221
09/07 09:48:57 PM: Update 29659: task edges-srl-ontonotes, batch 659 (29659): mcc: 0.6899, acc: 0.5903, precision: 0.7808, recall: 0.6169, f1: 0.6892, edges-srl-ontonotes_loss: 0.0222
09/07 09:49:07 PM: Update 29866: task edges-srl-ontonotes, batch 866 (29866): mcc: 0.6777, acc: 0.5752, precision: 0.7704, recall: 0.6037, f1: 0.6769, edges-srl-ontonotes_loss: 0.0229
09/07 09:49:16 PM: ***** Step 30000 / Validation 30 *****
09/07 09:49:16 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:49:16 PM: Validating...
09/07 09:49:17 PM: Evaluate: task edges-srl-ontonotes, batch 14 (157): mcc: 0.6794, acc: 0.5776, precision: 0.8007, recall: 0.5834, f1: 0.6750, edges-srl-ontonotes_loss: 0.0221
09/07 09:49:24 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:49:24 PM: Best result seen so far for macro.
09/07 09:49:24 PM: Updating LR scheduler:
09/07 09:49:24 PM: 	Best result seen so far for macro_avg: 0.689
09/07 09:49:24 PM: 	# validation passes without improvement: 0
09/07 09:49:24 PM: edges-srl-ontonotes_loss: training: 0.023205 validation: 0.021995
09/07 09:49:24 PM: macro_avg: validation: 0.688937
09/07 09:49:24 PM: micro_avg: validation: 0.000000
09/07 09:49:24 PM: edges-srl-ontonotes_mcc: training: 0.671386 validation: 0.690963
09/07 09:49:24 PM: edges-srl-ontonotes_acc: training: 0.567698 validation: 0.601031
09/07 09:49:24 PM: edges-srl-ontonotes_precision: training: 0.764836 validation: 0.793359
09/07 09:49:24 PM: edges-srl-ontonotes_recall: training: 0.596978 validation: 0.608806
09/07 09:49:24 PM: edges-srl-ontonotes_f1: training: 0.670562 validation: 0.688937
09/07 09:49:24 PM: Global learning rate: 5e-05
09/07 09:49:24 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:49:27 PM: Update 30076: task edges-srl-ontonotes, batch 76 (30076): mcc: 0.6183, acc: 0.5036, precision: 0.7219, recall: 0.5380, f1: 0.6165, edges-srl-ontonotes_loss: 0.0258
09/07 09:49:37 PM: Update 30264: task edges-srl-ontonotes, batch 264 (30264): mcc: 0.6124, acc: 0.4981, precision: 0.7179, recall: 0.5309, f1: 0.6104, edges-srl-ontonotes_loss: 0.0262
09/07 09:49:47 PM: Update 30476: task edges-srl-ontonotes, batch 476 (30476): mcc: 0.6096, acc: 0.4936, precision: 0.7158, recall: 0.5277, f1: 0.6075, edges-srl-ontonotes_loss: 0.0260
09/07 09:49:57 PM: Update 30661: task edges-srl-ontonotes, batch 661 (30661): mcc: 0.6043, acc: 0.4876, precision: 0.7109, recall: 0.5223, f1: 0.6022, edges-srl-ontonotes_loss: 0.0263
09/07 09:50:08 PM: Update 30863: task edges-srl-ontonotes, batch 863 (30863): mcc: 0.5977, acc: 0.4802, precision: 0.7079, recall: 0.5134, f1: 0.5951, edges-srl-ontonotes_loss: 0.0267
09/07 09:50:15 PM: ***** Step 31000 / Validation 31 *****
09/07 09:50:15 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:50:15 PM: Validating...
09/07 09:50:18 PM: Evaluate: task edges-srl-ontonotes, batch 74 (157): mcc: 0.6837, acc: 0.5854, precision: 0.7989, recall: 0.5920, f1: 0.6800, edges-srl-ontonotes_loss: 0.0224
09/07 09:50:22 PM: Updating LR scheduler:
09/07 09:50:22 PM: 	Best result seen so far for macro_avg: 0.689
09/07 09:50:22 PM: 	# validation passes without improvement: 1
09/07 09:50:22 PM: edges-srl-ontonotes_loss: training: 0.026820 validation: 0.022156
09/07 09:50:22 PM: macro_avg: validation: 0.682785
09/07 09:50:22 PM: micro_avg: validation: 0.000000
09/07 09:50:22 PM: edges-srl-ontonotes_mcc: training: 0.595174 validation: 0.685981
09/07 09:50:22 PM: edges-srl-ontonotes_acc: training: 0.476897 validation: 0.589793
09/07 09:50:22 PM: edges-srl-ontonotes_precision: training: 0.706730 validation: 0.797859
09/07 09:50:22 PM: edges-srl-ontonotes_recall: training: 0.509864 validation: 0.596721
09/07 09:50:22 PM: edges-srl-ontonotes_f1: training: 0.592369 validation: 0.682785
09/07 09:50:22 PM: Global learning rate: 5e-05
09/07 09:50:22 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:50:28 PM: Update 31131: task edges-srl-ontonotes, batch 131 (31131): mcc: 0.5883, acc: 0.4664, precision: 0.7036, recall: 0.5005, f1: 0.5849, edges-srl-ontonotes_loss: 0.0273
09/07 09:50:38 PM: Update 31277: task edges-srl-ontonotes, batch 277 (31277): mcc: 0.5913, acc: 0.4685, precision: 0.7039, recall: 0.5054, f1: 0.5883, edges-srl-ontonotes_loss: 0.0269
09/07 09:50:48 PM: Update 31481: task edges-srl-ontonotes, batch 481 (31481): mcc: 0.5935, acc: 0.4723, precision: 0.7045, recall: 0.5087, f1: 0.5908, edges-srl-ontonotes_loss: 0.0266
09/07 09:50:58 PM: Update 31665: task edges-srl-ontonotes, batch 665 (31665): mcc: 0.5945, acc: 0.4736, precision: 0.7038, recall: 0.5108, f1: 0.5920, edges-srl-ontonotes_loss: 0.0265
09/07 09:51:08 PM: Update 31849: task edges-srl-ontonotes, batch 849 (31849): mcc: 0.5996, acc: 0.4796, precision: 0.7076, recall: 0.5168, f1: 0.5974, edges-srl-ontonotes_loss: 0.0262
09/07 09:51:16 PM: ***** Step 32000 / Validation 32 *****
09/07 09:51:16 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:51:16 PM: Validating...
09/07 09:51:18 PM: Evaluate: task edges-srl-ontonotes, batch 58 (157): mcc: 0.6678, acc: 0.5711, precision: 0.7837, recall: 0.5763, f1: 0.6641, edges-srl-ontonotes_loss: 0.0233
09/07 09:51:23 PM: Updating LR scheduler:
09/07 09:51:23 PM: 	Best result seen so far for macro_avg: 0.689
09/07 09:51:23 PM: 	# validation passes without improvement: 2
09/07 09:51:23 PM: edges-srl-ontonotes_loss: training: 0.026126 validation: 0.022665
09/07 09:51:23 PM: macro_avg: validation: 0.672108
09/07 09:51:23 PM: micro_avg: validation: 0.000000
09/07 09:51:23 PM: edges-srl-ontonotes_mcc: training: 0.602471 validation: 0.674617
09/07 09:51:23 PM: edges-srl-ontonotes_acc: training: 0.483150 validation: 0.583943
09/07 09:51:23 PM: edges-srl-ontonotes_precision: training: 0.709634 validation: 0.781668
09/07 09:51:23 PM: edges-srl-ontonotes_recall: training: 0.520120 validation: 0.589485
09/07 09:51:23 PM: edges-srl-ontonotes_f1: training: 0.600274 validation: 0.672108
09/07 09:51:23 PM: Global learning rate: 5e-05
09/07 09:51:23 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:51:28 PM: Update 32114: task edges-srl-ontonotes, batch 114 (32114): mcc: 0.6283, acc: 0.5160, precision: 0.7311, recall: 0.5483, f1: 0.6266, edges-srl-ontonotes_loss: 0.0251
09/07 09:51:38 PM: Update 32258: task edges-srl-ontonotes, batch 258 (32258): mcc: 0.6097, acc: 0.4947, precision: 0.7152, recall: 0.5284, f1: 0.6077, edges-srl-ontonotes_loss: 0.0261
09/07 09:51:48 PM: Update 32443: task edges-srl-ontonotes, batch 443 (32443): mcc: 0.6047, acc: 0.4887, precision: 0.7117, recall: 0.5223, f1: 0.6025, edges-srl-ontonotes_loss: 0.0263
09/07 09:51:58 PM: Update 32652: task edges-srl-ontonotes, batch 652 (32652): mcc: 0.6037, acc: 0.4874, precision: 0.7118, recall: 0.5206, f1: 0.6014, edges-srl-ontonotes_loss: 0.0264
09/07 09:52:08 PM: Update 32836: task edges-srl-ontonotes, batch 836 (32836): mcc: 0.6022, acc: 0.4857, precision: 0.7108, recall: 0.5188, f1: 0.5998, edges-srl-ontonotes_loss: 0.0264
09/07 09:52:16 PM: ***** Step 33000 / Validation 33 *****
09/07 09:52:16 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:52:16 PM: Validating...
09/07 09:52:18 PM: Evaluate: task edges-srl-ontonotes, batch 48 (157): mcc: 0.6599, acc: 0.5625, precision: 0.7756, recall: 0.5687, f1: 0.6563, edges-srl-ontonotes_loss: 0.0242
09/07 09:52:23 PM: Updating LR scheduler:
09/07 09:52:23 PM: 	Best result seen so far for macro_avg: 0.689
09/07 09:52:23 PM: 	# validation passes without improvement: 3
09/07 09:52:23 PM: edges-srl-ontonotes_loss: training: 0.026377 validation: 0.023068
09/07 09:52:23 PM: macro_avg: validation: 0.666696
09/07 09:52:23 PM: micro_avg: validation: 0.000000
09/07 09:52:23 PM: edges-srl-ontonotes_mcc: training: 0.602041 validation: 0.669270
09/07 09:52:23 PM: edges-srl-ontonotes_acc: training: 0.484811 validation: 0.578093
09/07 09:52:23 PM: edges-srl-ontonotes_precision: training: 0.711039 validation: 0.777049
09/07 09:52:23 PM: edges-srl-ontonotes_recall: training: 0.518338 validation: 0.583789
09/07 09:52:23 PM: edges-srl-ontonotes_f1: training: 0.599586 validation: 0.666696
09/07 09:52:23 PM: Global learning rate: 5e-05
09/07 09:52:23 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:52:29 PM: Update 33084: task edges-srl-ontonotes, batch 84 (33084): mcc: 0.5893, acc: 0.4731, precision: 0.6996, recall: 0.5052, f1: 0.5867, edges-srl-ontonotes_loss: 0.0269
09/07 09:52:39 PM: Update 33288: task edges-srl-ontonotes, batch 288 (33288): mcc: 0.6068, acc: 0.4907, precision: 0.7124, recall: 0.5254, f1: 0.6048, edges-srl-ontonotes_loss: 0.0260
09/07 09:52:49 PM: Update 33434: task edges-srl-ontonotes, batch 434 (33434): mcc: 0.6098, acc: 0.4936, precision: 0.7153, recall: 0.5283, f1: 0.6078, edges-srl-ontonotes_loss: 0.0259
09/07 09:52:59 PM: Update 33640: task edges-srl-ontonotes, batch 640 (33640): mcc: 0.6110, acc: 0.4950, precision: 0.7164, recall: 0.5296, f1: 0.6090, edges-srl-ontonotes_loss: 0.0258
09/07 09:53:09 PM: Update 33827: task edges-srl-ontonotes, batch 827 (33827): mcc: 0.6055, acc: 0.4882, precision: 0.7143, recall: 0.5218, f1: 0.6030, edges-srl-ontonotes_loss: 0.0262
09/07 09:53:18 PM: ***** Step 34000 / Validation 34 *****
09/07 09:53:18 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:53:18 PM: Validating...
09/07 09:53:19 PM: Evaluate: task edges-srl-ontonotes, batch 16 (157): mcc: 0.6612, acc: 0.5569, precision: 0.7887, recall: 0.5613, f1: 0.6559, edges-srl-ontonotes_loss: 0.0230
09/07 09:53:25 PM: Updating LR scheduler:
09/07 09:53:25 PM: 	Best result seen so far for macro_avg: 0.689
09/07 09:53:25 PM: 	# validation passes without improvement: 4
09/07 09:53:25 PM: edges-srl-ontonotes_loss: training: 0.026298 validation: 0.023270
09/07 09:53:25 PM: macro_avg: validation: 0.661231
09/07 09:53:25 PM: micro_avg: validation: 0.000000
09/07 09:53:25 PM: edges-srl-ontonotes_mcc: training: 0.604098 validation: 0.663993
09/07 09:53:25 PM: edges-srl-ontonotes_acc: training: 0.485970 validation: 0.572088
09/07 09:53:25 PM: edges-srl-ontonotes_precision: training: 0.715011 validation: 0.773402
09/07 09:53:25 PM: edges-srl-ontonotes_recall: training: 0.518888 validation: 0.577477
09/07 09:53:25 PM: edges-srl-ontonotes_f1: training: 0.601363 validation: 0.661231
09/07 09:53:25 PM: Global learning rate: 5e-05
09/07 09:53:25 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:53:29 PM: Update 34076: task edges-srl-ontonotes, batch 76 (34076): mcc: 0.6629, acc: 0.5500, precision: 0.7656, recall: 0.5816, f1: 0.6610, edges-srl-ontonotes_loss: 0.0227
09/07 09:53:39 PM: Update 34281: task edges-srl-ontonotes, batch 281 (34281): mcc: 0.6707, acc: 0.5607, precision: 0.7693, recall: 0.5923, f1: 0.6693, edges-srl-ontonotes_loss: 0.0225
09/07 09:53:49 PM: Update 34428: task edges-srl-ontonotes, batch 428 (34428): mcc: 0.6834, acc: 0.5769, precision: 0.7758, recall: 0.6095, f1: 0.6826, edges-srl-ontonotes_loss: 0.0217
09/07 09:53:59 PM: Update 34619: task edges-srl-ontonotes, batch 619 (34619): mcc: 0.6979, acc: 0.5950, precision: 0.7837, recall: 0.6287, f1: 0.6977, edges-srl-ontonotes_loss: 0.0209
09/07 09:54:09 PM: Update 34820: task edges-srl-ontonotes, batch 820 (34820): mcc: 0.7044, acc: 0.6048, precision: 0.7870, recall: 0.6376, f1: 0.7045, edges-srl-ontonotes_loss: 0.0206
09/07 09:54:19 PM: ***** Step 35000 / Validation 35 *****
09/07 09:54:19 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:54:19 PM: Validating...
09/07 09:54:19 PM: Evaluate: task edges-srl-ontonotes, batch 4 (157): mcc: 0.6904, acc: 0.5800, precision: 0.8150, recall: 0.5914, f1: 0.6854, edges-srl-ontonotes_loss: 0.0220
09/07 09:54:26 PM: Updating LR scheduler:
09/07 09:54:26 PM: 	Best result seen so far for macro_avg: 0.689
09/07 09:54:26 PM: 	# validation passes without improvement: 5
09/07 09:54:26 PM: edges-srl-ontonotes_loss: training: 0.020268 validation: 0.023064
09/07 09:54:26 PM: macro_avg: validation: 0.678917
09/07 09:54:26 PM: micro_avg: validation: 0.000000
09/07 09:54:26 PM: edges-srl-ontonotes_mcc: training: 0.711159 validation: 0.680174
09/07 09:54:26 PM: edges-srl-ontonotes_acc: training: 0.613757 validation: 0.593026
09/07 09:54:26 PM: edges-srl-ontonotes_precision: training: 0.791003 validation: 0.776775
09/07 09:54:26 PM: edges-srl-ontonotes_recall: training: 0.646417 validation: 0.602956
09/07 09:54:26 PM: edges-srl-ontonotes_f1: training: 0.711438 validation: 0.678917
09/07 09:54:26 PM: Global learning rate: 5e-05
09/07 09:54:26 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:54:29 PM: Update 35066: task edges-srl-ontonotes, batch 66 (35066): mcc: 0.7466, acc: 0.6620, precision: 0.8107, recall: 0.6941, f1: 0.7479, edges-srl-ontonotes_loss: 0.0185
09/07 09:54:41 PM: Update 35245: task edges-srl-ontonotes, batch 245 (35245): mcc: 0.7522, acc: 0.6702, precision: 0.8150, recall: 0.7006, f1: 0.7535, edges-srl-ontonotes_loss: 0.0182
09/07 09:54:51 PM: Update 35445: task edges-srl-ontonotes, batch 445 (35445): mcc: 0.7717, acc: 0.6951, precision: 0.8318, recall: 0.7219, f1: 0.7730, edges-srl-ontonotes_loss: 0.0175
09/07 09:55:01 PM: Update 35630: task edges-srl-ontonotes, batch 630 (35630): mcc: 0.7637, acc: 0.6865, precision: 0.8262, recall: 0.7120, f1: 0.7649, edges-srl-ontonotes_loss: 0.0181
09/07 09:55:11 PM: Update 35837: task edges-srl-ontonotes, batch 837 (35837): mcc: 0.7420, acc: 0.6594, precision: 0.8096, recall: 0.6867, f1: 0.7431, edges-srl-ontonotes_loss: 0.0193
09/07 09:55:20 PM: ***** Step 36000 / Validation 36 *****
09/07 09:55:20 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:55:20 PM: Validating...
09/07 09:55:21 PM: Evaluate: task edges-srl-ontonotes, batch 22 (157): mcc: 0.6972, acc: 0.5941, precision: 0.8147, recall: 0.6032, f1: 0.6932, edges-srl-ontonotes_loss: 0.0218
09/07 09:55:27 PM: Updating LR scheduler:
09/07 09:55:27 PM: 	Best result seen so far for macro_avg: 0.689
09/07 09:55:27 PM: 	# validation passes without improvement: 0
09/07 09:55:27 PM: edges-srl-ontonotes_loss: training: 0.020206 validation: 0.022554
09/07 09:55:27 PM: macro_avg: validation: 0.686400
09/07 09:55:27 PM: micro_avg: validation: 0.000000
09/07 09:55:27 PM: edges-srl-ontonotes_mcc: training: 0.725888 validation: 0.687825
09/07 09:55:27 PM: edges-srl-ontonotes_acc: training: 0.639102 validation: 0.599569
09/07 09:55:27 PM: edges-srl-ontonotes_precision: training: 0.798131 validation: 0.785381
09/07 09:55:27 PM: edges-srl-ontonotes_recall: training: 0.667033 validation: 0.609576
09/07 09:55:27 PM: edges-srl-ontonotes_f1: training: 0.726717 validation: 0.686400
09/07 09:55:27 PM: Global learning rate: 2.5e-05
09/07 09:55:27 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:55:31 PM: Update 36081: task edges-srl-ontonotes, batch 81 (36081): mcc: 0.6243, acc: 0.5167, precision: 0.7179, recall: 0.5514, f1: 0.6238, edges-srl-ontonotes_loss: 0.0258
09/07 09:55:41 PM: Update 36258: task edges-srl-ontonotes, batch 258 (36258): mcc: 0.6353, acc: 0.5267, precision: 0.7332, recall: 0.5587, f1: 0.6341, edges-srl-ontonotes_loss: 0.0253
09/07 09:55:51 PM: Update 36456: task edges-srl-ontonotes, batch 456 (36456): mcc: 0.6596, acc: 0.5561, precision: 0.7540, recall: 0.5849, f1: 0.6588, edges-srl-ontonotes_loss: 0.0239
09/07 09:56:01 PM: Update 36604: task edges-srl-ontonotes, batch 604 (36604): mcc: 0.6691, acc: 0.5675, precision: 0.7612, recall: 0.5959, f1: 0.6685, edges-srl-ontonotes_loss: 0.0234
09/07 09:56:11 PM: Update 36806: task edges-srl-ontonotes, batch 806 (36806): mcc: 0.6786, acc: 0.5788, precision: 0.7689, recall: 0.6064, f1: 0.6781, edges-srl-ontonotes_loss: 0.0229
09/07 09:56:21 PM: Update 36993: task edges-srl-ontonotes, batch 993 (36993): mcc: 0.6737, acc: 0.5726, precision: 0.7649, recall: 0.6011, f1: 0.6732, edges-srl-ontonotes_loss: 0.0231
09/07 09:56:22 PM: ***** Step 37000 / Validation 37 *****
09/07 09:56:22 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:56:22 PM: Validating...
09/07 09:56:29 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:56:29 PM: Best result seen so far for macro.
09/07 09:56:29 PM: Updating LR scheduler:
09/07 09:56:29 PM: 	Best result seen so far for macro_avg: 0.693
09/07 09:56:29 PM: 	# validation passes without improvement: 0
09/07 09:56:29 PM: edges-srl-ontonotes_loss: training: 0.023121 validation: 0.021914
09/07 09:56:29 PM: macro_avg: validation: 0.692887
09/07 09:56:29 PM: micro_avg: validation: 0.000000
09/07 09:56:29 PM: edges-srl-ontonotes_mcc: training: 0.673604 validation: 0.695007
09/07 09:56:29 PM: edges-srl-ontonotes_acc: training: 0.572386 validation: 0.604034
09/07 09:56:29 PM: edges-srl-ontonotes_precision: training: 0.764772 validation: 0.797953
09/07 09:56:29 PM: edges-srl-ontonotes_recall: training: 0.600933 validation: 0.612270
09/07 09:56:29 PM: edges-srl-ontonotes_f1: training: 0.673025 validation: 0.692887
09/07 09:56:29 PM: Global learning rate: 2.5e-05
09/07 09:56:29 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:56:31 PM: Update 37054: task edges-srl-ontonotes, batch 54 (37054): mcc: 0.6371, acc: 0.5293, precision: 0.7363, recall: 0.5595, f1: 0.6358, edges-srl-ontonotes_loss: 0.0252
09/07 09:56:41 PM: Update 37241: task edges-srl-ontonotes, batch 241 (37241): mcc: 0.6336, acc: 0.5225, precision: 0.7317, recall: 0.5569, f1: 0.6325, edges-srl-ontonotes_loss: 0.0251
09/07 09:56:51 PM: Update 37452: task edges-srl-ontonotes, batch 452 (37452): mcc: 0.6273, acc: 0.5159, precision: 0.7270, recall: 0.5496, f1: 0.6260, edges-srl-ontonotes_loss: 0.0255
09/07 09:57:01 PM: Update 37602: task edges-srl-ontonotes, batch 602 (37602): mcc: 0.6222, acc: 0.5093, precision: 0.7226, recall: 0.5441, f1: 0.6208, edges-srl-ontonotes_loss: 0.0257
09/07 09:57:12 PM: Update 37796: task edges-srl-ontonotes, batch 796 (37796): mcc: 0.6179, acc: 0.5043, precision: 0.7188, recall: 0.5396, f1: 0.6164, edges-srl-ontonotes_loss: 0.0257
09/07 09:57:21 PM: ***** Step 38000 / Validation 38 *****
09/07 09:57:21 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:57:21 PM: Validating...
09/07 09:57:22 PM: Evaluate: task edges-srl-ontonotes, batch 5 (157): mcc: 0.6780, acc: 0.5604, precision: 0.8103, recall: 0.5740, f1: 0.6720, edges-srl-ontonotes_loss: 0.0224
09/07 09:57:28 PM: Updating LR scheduler:
09/07 09:57:28 PM: 	Best result seen so far for macro_avg: 0.693
09/07 09:57:28 PM: 	# validation passes without improvement: 1
09/07 09:57:28 PM: edges-srl-ontonotes_loss: training: 0.026064 validation: 0.021909
09/07 09:57:28 PM: macro_avg: validation: 0.692318
09/07 09:57:28 PM: micro_avg: validation: 0.000000
09/07 09:57:28 PM: edges-srl-ontonotes_mcc: training: 0.611072 validation: 0.694474
09/07 09:57:28 PM: edges-srl-ontonotes_acc: training: 0.496441 validation: 0.600878
09/07 09:57:28 PM: edges-srl-ontonotes_precision: training: 0.714343 validation: 0.797751
09/07 09:57:28 PM: edges-srl-ontonotes_recall: training: 0.531309 validation: 0.611500
09/07 09:57:28 PM: edges-srl-ontonotes_f1: training: 0.609379 validation: 0.692318
09/07 09:57:28 PM: Global learning rate: 2.5e-05
09/07 09:57:28 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:57:32 PM: Update 38066: task edges-srl-ontonotes, batch 66 (38066): mcc: 0.5830, acc: 0.4668, precision: 0.6910, recall: 0.5008, f1: 0.5807, edges-srl-ontonotes_loss: 0.0276
09/07 09:57:42 PM: Update 38252: task edges-srl-ontonotes, batch 252 (38252): mcc: 0.5847, acc: 0.4642, precision: 0.6992, recall: 0.4977, f1: 0.5815, edges-srl-ontonotes_loss: 0.0276
09/07 09:57:52 PM: Update 38438: task edges-srl-ontonotes, batch 438 (38438): mcc: 0.5861, acc: 0.4667, precision: 0.7003, recall: 0.4992, f1: 0.5829, edges-srl-ontonotes_loss: 0.0275
09/07 09:58:02 PM: Update 38643: task edges-srl-ontonotes, batch 643 (38643): mcc: 0.5926, acc: 0.4731, precision: 0.7037, recall: 0.5077, f1: 0.5899, edges-srl-ontonotes_loss: 0.0269
09/07 09:58:12 PM: Update 38791: task edges-srl-ontonotes, batch 791 (38791): mcc: 0.5932, acc: 0.4743, precision: 0.7024, recall: 0.5097, f1: 0.5908, edges-srl-ontonotes_loss: 0.0268
09/07 09:58:22 PM: Update 38997: task edges-srl-ontonotes, batch 997 (38997): mcc: 0.5958, acc: 0.4772, precision: 0.7040, recall: 0.5130, f1: 0.5935, edges-srl-ontonotes_loss: 0.0266
09/07 09:58:22 PM: ***** Step 39000 / Validation 39 *****
09/07 09:58:22 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:58:22 PM: Validating...
09/07 09:58:29 PM: Updating LR scheduler:
09/07 09:58:29 PM: 	Best result seen so far for macro_avg: 0.693
09/07 09:58:29 PM: 	# validation passes without improvement: 2
09/07 09:58:29 PM: edges-srl-ontonotes_loss: training: 0.026552 validation: 0.022266
09/07 09:58:29 PM: macro_avg: validation: 0.682137
09/07 09:58:29 PM: micro_avg: validation: 0.000000
09/07 09:58:29 PM: edges-srl-ontonotes_mcc: training: 0.595986 validation: 0.683966
09/07 09:58:29 PM: edges-srl-ontonotes_acc: training: 0.477382 validation: 0.594412
09/07 09:58:29 PM: edges-srl-ontonotes_precision: training: 0.704162 validation: 0.785127
09/07 09:58:29 PM: edges-srl-ontonotes_recall: training: 0.513145 validation: 0.603033
09/07 09:58:29 PM: edges-srl-ontonotes_f1: training: 0.593666 validation: 0.682137
09/07 09:58:29 PM: Global learning rate: 2.5e-05
09/07 09:58:29 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:58:32 PM: Update 39048: task edges-srl-ontonotes, batch 48 (39048): mcc: 0.5996, acc: 0.4813, precision: 0.7066, recall: 0.5175, f1: 0.5974, edges-srl-ontonotes_loss: 0.0260
09/07 09:58:42 PM: Update 39251: task edges-srl-ontonotes, batch 251 (39251): mcc: 0.6175, acc: 0.5022, precision: 0.7203, recall: 0.5378, f1: 0.6158, edges-srl-ontonotes_loss: 0.0253
09/07 09:58:52 PM: Update 39435: task edges-srl-ontonotes, batch 435 (39435): mcc: 0.6143, acc: 0.4989, precision: 0.7175, recall: 0.5345, f1: 0.6126, edges-srl-ontonotes_loss: 0.0255
09/07 09:59:02 PM: Update 39642: task edges-srl-ontonotes, batch 642 (39642): mcc: 0.6092, acc: 0.4937, precision: 0.7131, recall: 0.5290, f1: 0.6074, edges-srl-ontonotes_loss: 0.0259
09/07 09:59:12 PM: Update 39791: task edges-srl-ontonotes, batch 791 (39791): mcc: 0.6066, acc: 0.4910, precision: 0.7113, recall: 0.5260, f1: 0.6048, edges-srl-ontonotes_loss: 0.0260
09/07 09:59:23 PM: Update 39987: task edges-srl-ontonotes, batch 987 (39987): mcc: 0.6057, acc: 0.4897, precision: 0.7115, recall: 0.5243, f1: 0.6037, edges-srl-ontonotes_loss: 0.0261
09/07 09:59:23 PM: ***** Step 40000 / Validation 40 *****
09/07 09:59:23 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:59:23 PM: Validating...
09/07 09:59:30 PM: Updating LR scheduler:
09/07 09:59:30 PM: 	Best result seen so far for macro_avg: 0.693
09/07 09:59:30 PM: 	# validation passes without improvement: 3
09/07 09:59:30 PM: edges-srl-ontonotes_loss: training: 0.026097 validation: 0.022462
09/07 09:59:30 PM: macro_avg: validation: 0.677580
09/07 09:59:30 PM: micro_avg: validation: 0.000000
09/07 09:59:30 PM: edges-srl-ontonotes_mcc: training: 0.605227 validation: 0.679918
09/07 09:59:30 PM: edges-srl-ontonotes_acc: training: 0.489199 validation: 0.589947
09/07 09:59:30 PM: edges-srl-ontonotes_precision: training: 0.711070 validation: 0.785388
09/07 09:59:30 PM: edges-srl-ontonotes_recall: training: 0.523754 validation: 0.595797
09/07 09:59:30 PM: edges-srl-ontonotes_f1: training: 0.603205 validation: 0.677580
09/07 09:59:30 PM: Global learning rate: 2.5e-05
09/07 09:59:30 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 09:59:33 PM: Update 40050: task edges-srl-ontonotes, batch 50 (40050): mcc: 0.6016, acc: 0.4858, precision: 0.7086, recall: 0.5194, f1: 0.5995, edges-srl-ontonotes_loss: 0.0265
09/07 09:59:43 PM: Update 40255: task edges-srl-ontonotes, batch 255 (40255): mcc: 0.5992, acc: 0.4805, precision: 0.7091, recall: 0.5149, f1: 0.5966, edges-srl-ontonotes_loss: 0.0264
09/07 09:59:53 PM: Update 40438: task edges-srl-ontonotes, batch 438 (40438): mcc: 0.6048, acc: 0.4860, precision: 0.7124, recall: 0.5221, f1: 0.6026, edges-srl-ontonotes_loss: 0.0261
09/07 10:00:03 PM: Update 40621: task edges-srl-ontonotes, batch 621 (40621): mcc: 0.6068, acc: 0.4897, precision: 0.7128, recall: 0.5251, f1: 0.6047, edges-srl-ontonotes_loss: 0.0259
09/07 10:00:13 PM: Update 40825: task edges-srl-ontonotes, batch 825 (40825): mcc: 0.6076, acc: 0.4910, precision: 0.7133, recall: 0.5261, f1: 0.6055, edges-srl-ontonotes_loss: 0.0259
09/07 10:00:23 PM: Update 40968: task edges-srl-ontonotes, batch 968 (40968): mcc: 0.6070, acc: 0.4905, precision: 0.7130, recall: 0.5253, f1: 0.6049, edges-srl-ontonotes_loss: 0.0259
09/07 10:00:24 PM: ***** Step 41000 / Validation 41 *****
09/07 10:00:24 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:00:24 PM: Validating...
09/07 10:00:32 PM: Updating LR scheduler:
09/07 10:00:32 PM: 	Best result seen so far for macro_avg: 0.693
09/07 10:00:32 PM: 	# validation passes without improvement: 4
09/07 10:00:32 PM: edges-srl-ontonotes_loss: training: 0.025949 validation: 0.022663
09/07 10:00:32 PM: macro_avg: validation: 0.669646
09/07 10:00:32 PM: micro_avg: validation: 0.000000
09/07 10:00:32 PM: edges-srl-ontonotes_mcc: training: 0.606181 validation: 0.671912
09/07 10:00:32 PM: edges-srl-ontonotes_acc: training: 0.489524 validation: 0.582788
09/07 10:00:32 PM: edges-srl-ontonotes_precision: training: 0.712451 validation: 0.777179
09/07 10:00:32 PM: edges-srl-ontonotes_recall: training: 0.524350 validation: 0.588253
09/07 10:00:32 PM: edges-srl-ontonotes_f1: training: 0.604096 validation: 0.669646
09/07 10:00:32 PM: Global learning rate: 2.5e-05
09/07 10:00:32 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 10:00:33 PM: Update 41027: task edges-srl-ontonotes, batch 27 (41027): mcc: 0.5825, acc: 0.4616, precision: 0.7026, recall: 0.4916, f1: 0.5785, edges-srl-ontonotes_loss: 0.0276
09/07 10:00:43 PM: Update 41233: task edges-srl-ontonotes, batch 233 (41233): mcc: 0.5905, acc: 0.4689, precision: 0.7113, recall: 0.4987, f1: 0.5863, edges-srl-ontonotes_loss: 0.0271
09/07 10:00:53 PM: Update 41416: task edges-srl-ontonotes, batch 416 (41416): mcc: 0.6262, acc: 0.5110, precision: 0.7374, recall: 0.5398, f1: 0.6233, edges-srl-ontonotes_loss: 0.0251
09/07 10:01:03 PM: Update 41599: task edges-srl-ontonotes, batch 599 (41599): mcc: 0.6442, acc: 0.5310, precision: 0.7515, recall: 0.5601, f1: 0.6418, edges-srl-ontonotes_loss: 0.0240
09/07 10:01:13 PM: Update 41802: task edges-srl-ontonotes, batch 802 (41802): mcc: 0.6641, acc: 0.5550, precision: 0.7629, recall: 0.5857, f1: 0.6627, edges-srl-ontonotes_loss: 0.0229
09/07 10:01:23 PM: Update 41945: task edges-srl-ontonotes, batch 945 (41945): mcc: 0.6750, acc: 0.5684, precision: 0.7700, recall: 0.5992, f1: 0.6739, edges-srl-ontonotes_loss: 0.0223
09/07 10:01:26 PM: ***** Step 42000 / Validation 42 *****
09/07 10:01:26 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:01:26 PM: Validating...
09/07 10:01:33 PM: Updating LR scheduler:
09/07 10:01:33 PM: 	Best result seen so far for macro_avg: 0.693
09/07 10:01:33 PM: 	# validation passes without improvement: 5
09/07 10:01:33 PM: edges-srl-ontonotes_loss: training: 0.022142 validation: 0.022626
09/07 10:01:33 PM: macro_avg: validation: 0.680502
09/07 10:01:33 PM: micro_avg: validation: 0.000000
09/07 10:01:33 PM: edges-srl-ontonotes_mcc: training: 0.677645 validation: 0.682456
09/07 10:01:33 PM: edges-srl-ontonotes_acc: training: 0.571924 validation: 0.594027
09/07 10:01:33 PM: edges-srl-ontonotes_precision: training: 0.771390 validation: 0.784716
09/07 10:01:33 PM: edges-srl-ontonotes_recall: training: 0.602778 validation: 0.600724
09/07 10:01:33 PM: edges-srl-ontonotes_f1: training: 0.676740 validation: 0.680502
09/07 10:01:33 PM: Global learning rate: 2.5e-05
09/07 10:01:33 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 10:01:33 PM: Update 42004: task edges-srl-ontonotes, batch 4 (42004): mcc: 0.7211, acc: 0.6197, precision: 0.7939, recall: 0.6620, f1: 0.7220, edges-srl-ontonotes_loss: 0.0197
09/07 10:01:43 PM: Update 42183: task edges-srl-ontonotes, batch 183 (42183): mcc: 0.7276, acc: 0.6334, precision: 0.7988, recall: 0.6696, f1: 0.7285, edges-srl-ontonotes_loss: 0.0190
09/07 10:01:53 PM: Update 42385: task edges-srl-ontonotes, batch 385 (42385): mcc: 0.7374, acc: 0.6485, precision: 0.8059, recall: 0.6813, f1: 0.7384, edges-srl-ontonotes_loss: 0.0186
09/07 10:02:03 PM: Update 42566: task edges-srl-ontonotes, batch 566 (42566): mcc: 0.7455, acc: 0.6592, precision: 0.8135, recall: 0.6897, f1: 0.7465, edges-srl-ontonotes_loss: 0.0184
09/07 10:02:13 PM: Update 42769: task edges-srl-ontonotes, batch 769 (42769): mcc: 0.7570, acc: 0.6743, precision: 0.8230, recall: 0.7025, f1: 0.7580, edges-srl-ontonotes_loss: 0.0180
09/07 10:02:23 PM: Update 42913: task edges-srl-ontonotes, batch 913 (42913): mcc: 0.7488, acc: 0.6648, precision: 0.8169, recall: 0.6927, f1: 0.7497, edges-srl-ontonotes_loss: 0.0185
09/07 10:02:28 PM: ***** Step 43000 / Validation 43 *****
09/07 10:02:28 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:02:28 PM: Validating...
09/07 10:02:33 PM: Evaluate: task edges-srl-ontonotes, batch 126 (157): mcc: 0.7062, acc: 0.6245, precision: 0.7952, recall: 0.6341, f1: 0.7056, edges-srl-ontonotes_loss: 0.0215
09/07 10:02:35 PM: Updating LR scheduler:
09/07 10:02:35 PM: 	Best result seen so far for macro_avg: 0.693
09/07 10:02:35 PM: 	# validation passes without improvement: 0
09/07 10:02:35 PM: edges-srl-ontonotes_loss: training: 0.018865 validation: 0.022308
09/07 10:02:35 PM: macro_avg: validation: 0.689076
09/07 10:02:35 PM: micro_avg: validation: 0.000000
09/07 10:02:35 PM: edges-srl-ontonotes_mcc: training: 0.742930 validation: 0.689966
09/07 10:02:35 PM: edges-srl-ontonotes_acc: training: 0.657738 validation: 0.606035
09/07 10:02:35 PM: edges-srl-ontonotes_precision: training: 0.812494 validation: 0.782749
09/07 10:02:35 PM: edges-srl-ontonotes_recall: training: 0.685813 validation: 0.615426
09/07 10:02:35 PM: edges-srl-ontonotes_f1: training: 0.743798 validation: 0.689076
09/07 10:02:35 PM: Global learning rate: 1.25e-05
09/07 10:02:35 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 10:02:43 PM: Update 43154: task edges-srl-ontonotes, batch 154 (43154): mcc: 0.6625, acc: 0.5642, precision: 0.7500, recall: 0.5932, f1: 0.6624, edges-srl-ontonotes_loss: 0.0237
09/07 10:02:53 PM: Update 43357: task edges-srl-ontonotes, batch 357 (43357): mcc: 0.6430, acc: 0.5389, precision: 0.7366, recall: 0.5695, f1: 0.6424, edges-srl-ontonotes_loss: 0.0247
09/07 10:03:03 PM: Update 43533: task edges-srl-ontonotes, batch 533 (43533): mcc: 0.6459, acc: 0.5422, precision: 0.7402, recall: 0.5718, f1: 0.6452, edges-srl-ontonotes_loss: 0.0247
09/07 10:03:13 PM: Update 43731: task edges-srl-ontonotes, batch 731 (43731): mcc: 0.6597, acc: 0.5580, precision: 0.7517, recall: 0.5868, f1: 0.6591, edges-srl-ontonotes_loss: 0.0239
09/07 10:03:23 PM: Update 43874: task edges-srl-ontonotes, batch 874 (43874): mcc: 0.6647, acc: 0.5642, precision: 0.7560, recall: 0.5923, f1: 0.6642, edges-srl-ontonotes_loss: 0.0236
09/07 10:03:30 PM: ***** Step 44000 / Validation 44 *****
09/07 10:03:30 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:03:30 PM: Validating...
09/07 10:03:34 PM: Evaluate: task edges-srl-ontonotes, batch 83 (157): mcc: 0.6973, acc: 0.6080, precision: 0.8001, recall: 0.6146, f1: 0.6952, edges-srl-ontonotes_loss: 0.0220
09/07 10:03:37 PM: Updating LR scheduler:
09/07 10:03:37 PM: 	Best result seen so far for macro_avg: 0.693
09/07 10:03:37 PM: 	# validation passes without improvement: 1
09/07 10:03:37 PM: edges-srl-ontonotes_loss: training: 0.023333 validation: 0.021976
09/07 10:03:37 PM: macro_avg: validation: 0.691010
09/07 10:03:37 PM: micro_avg: validation: 0.000000
09/07 10:03:37 PM: edges-srl-ontonotes_mcc: training: 0.669830 validation: 0.692868
09/07 10:03:37 PM: edges-srl-ontonotes_acc: training: 0.570002 validation: 0.605188
09/07 10:03:37 PM: edges-srl-ontonotes_precision: training: 0.760152 validation: 0.793768
09/07 10:03:37 PM: edges-srl-ontonotes_recall: training: 0.597970 validation: 0.611808
09/07 10:03:37 PM: edges-srl-ontonotes_f1: training: 0.669377 validation: 0.691010
09/07 10:03:37 PM: Global learning rate: 1.25e-05
09/07 10:03:37 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 10:03:44 PM: Update 44117: task edges-srl-ontonotes, batch 117 (44117): mcc: 0.7073, acc: 0.6121, precision: 0.7914, recall: 0.6392, f1: 0.7072, edges-srl-ontonotes_loss: 0.0213
09/07 10:03:54 PM: Update 44323: task edges-srl-ontonotes, batch 323 (44323): mcc: 0.6654, acc: 0.5622, precision: 0.7582, recall: 0.5917, f1: 0.6646, edges-srl-ontonotes_loss: 0.0235
09/07 10:04:04 PM: Update 44510: task edges-srl-ontonotes, batch 510 (44510): mcc: 0.6510, acc: 0.5441, precision: 0.7467, recall: 0.5755, f1: 0.6500, edges-srl-ontonotes_loss: 0.0242
09/07 10:04:14 PM: Update 44721: task edges-srl-ontonotes, batch 721 (44721): mcc: 0.6420, acc: 0.5336, precision: 0.7391, recall: 0.5658, f1: 0.6410, edges-srl-ontonotes_loss: 0.0247
09/07 10:04:24 PM: Update 44909: task edges-srl-ontonotes, batch 909 (44909): mcc: 0.6341, acc: 0.5239, precision: 0.7326, recall: 0.5571, f1: 0.6329, edges-srl-ontonotes_loss: 0.0250
09/07 10:04:28 PM: ***** Step 45000 / Validation 45 *****
09/07 10:04:28 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:04:28 PM: Validating...
09/07 10:04:34 PM: Evaluate: task edges-srl-ontonotes, batch 123 (157): mcc: 0.7106, acc: 0.6250, precision: 0.8046, recall: 0.6344, f1: 0.7094, edges-srl-ontonotes_loss: 0.0212
09/07 10:04:35 PM: Best result seen so far for edges-srl-ontonotes.
09/07 10:04:35 PM: Best result seen so far for macro.
09/07 10:04:35 PM: Updating LR scheduler:
09/07 10:04:35 PM: 	Best result seen so far for macro_avg: 0.695
09/07 10:04:35 PM: 	# validation passes without improvement: 0
09/07 10:04:35 PM: edges-srl-ontonotes_loss: training: 0.025054 validation: 0.021840
09/07 10:04:35 PM: macro_avg: validation: 0.695487
09/07 10:04:35 PM: micro_avg: validation: 0.000000
09/07 10:04:35 PM: edges-srl-ontonotes_mcc: training: 0.632143 validation: 0.696841
09/07 10:04:35 PM: edges-srl-ontonotes_acc: training: 0.521696 validation: 0.608960
09/07 10:04:35 PM: edges-srl-ontonotes_precision: training: 0.730549 validation: 0.793216
09/07 10:04:35 PM: edges-srl-ontonotes_recall: training: 0.555295 validation: 0.619198
09/07 10:04:35 PM: edges-srl-ontonotes_f1: training: 0.630979 validation: 0.695487
09/07 10:04:35 PM: Global learning rate: 1.25e-05
09/07 10:04:35 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 10:04:44 PM: Update 45117: task edges-srl-ontonotes, batch 117 (45117): mcc: 0.5943, acc: 0.4776, precision: 0.7006, recall: 0.5129, f1: 0.5922, edges-srl-ontonotes_loss: 0.0269
09/07 10:04:54 PM: Update 45321: task edges-srl-ontonotes, batch 321 (45321): mcc: 0.5892, acc: 0.4728, precision: 0.6972, recall: 0.5069, f1: 0.5870, edges-srl-ontonotes_loss: 0.0272
09/07 10:05:04 PM: Update 45507: task edges-srl-ontonotes, batch 507 (45507): mcc: 0.5862, acc: 0.4688, precision: 0.6958, recall: 0.5028, f1: 0.5837, edges-srl-ontonotes_loss: 0.0275
09/07 10:05:14 PM: Update 45690: task edges-srl-ontonotes, batch 690 (45690): mcc: 0.5887, acc: 0.4707, precision: 0.6998, recall: 0.5040, f1: 0.5859, edges-srl-ontonotes_loss: 0.0273
09/07 10:05:24 PM: Update 45894: task edges-srl-ontonotes, batch 894 (45894): mcc: 0.5926, acc: 0.4747, precision: 0.7017, recall: 0.5091, f1: 0.5901, edges-srl-ontonotes_loss: 0.0270
09/07 10:05:32 PM: ***** Step 46000 / Validation 46 *****
09/07 10:05:32 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:05:32 PM: Validating...
09/07 10:05:34 PM: Evaluate: task edges-srl-ontonotes, batch 42 (157): mcc: 0.6845, acc: 0.5909, precision: 0.7896, recall: 0.6006, f1: 0.6822, edges-srl-ontonotes_loss: 0.0229
09/07 10:05:39 PM: Updating LR scheduler:
09/07 10:05:39 PM: 	Best result seen so far for macro_avg: 0.695
09/07 10:05:39 PM: 	# validation passes without improvement: 1
09/07 10:05:39 PM: edges-srl-ontonotes_loss: training: 0.026876 validation: 0.021972
09/07 10:05:39 PM: macro_avg: validation: 0.690608
09/07 10:05:39 PM: micro_avg: validation: 0.000000
09/07 10:05:39 PM: edges-srl-ontonotes_mcc: training: 0.594399 validation: 0.692078
09/07 10:05:39 PM: edges-srl-ontonotes_acc: training: 0.476555 validation: 0.603341
09/07 10:05:39 PM: edges-srl-ontonotes_precision: training: 0.702804 validation: 0.789755
09/07 10:05:39 PM: edges-srl-ontonotes_recall: training: 0.511454 validation: 0.613579
09/07 10:05:39 PM: edges-srl-ontonotes_f1: training: 0.592052 validation: 0.690608
09/07 10:05:39 PM: Global learning rate: 1.25e-05
09/07 10:05:39 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 10:05:44 PM: Update 46100: task edges-srl-ontonotes, batch 100 (46100): mcc: 0.6085, acc: 0.4897, precision: 0.7084, recall: 0.5314, f1: 0.6073, edges-srl-ontonotes_loss: 0.0260
09/07 10:05:54 PM: Update 46294: task edges-srl-ontonotes, batch 294 (46294): mcc: 0.6083, acc: 0.4902, precision: 0.7088, recall: 0.5308, f1: 0.6070, edges-srl-ontonotes_loss: 0.0257
09/07 10:06:04 PM: Update 46498: task edges-srl-ontonotes, batch 498 (46498): mcc: 0.6137, acc: 0.4981, precision: 0.7127, recall: 0.5371, f1: 0.6126, edges-srl-ontonotes_loss: 0.0255
09/07 10:06:14 PM: Update 46681: task edges-srl-ontonotes, batch 681 (46681): mcc: 0.6146, acc: 0.4993, precision: 0.7145, recall: 0.5372, f1: 0.6133, edges-srl-ontonotes_loss: 0.0255
09/07 10:06:24 PM: Update 46889: task edges-srl-ontonotes, batch 889 (46889): mcc: 0.6095, acc: 0.4935, precision: 0.7104, recall: 0.5317, f1: 0.6082, edges-srl-ontonotes_loss: 0.0258
09/07 10:06:31 PM: ***** Step 47000 / Validation 47 *****
09/07 10:06:31 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:06:31 PM: Validating...
09/07 10:06:34 PM: Evaluate: task edges-srl-ontonotes, batch 79 (157): mcc: 0.6864, acc: 0.5963, precision: 0.7906, recall: 0.6031, f1: 0.6842, edges-srl-ontonotes_loss: 0.0224
09/07 10:06:38 PM: Updating LR scheduler:
09/07 10:06:38 PM: 	Best result seen so far for macro_avg: 0.695
09/07 10:06:38 PM: 	# validation passes without improvement: 2
09/07 10:06:38 PM: edges-srl-ontonotes_loss: training: 0.025864 validation: 0.022169
09/07 10:06:38 PM: macro_avg: validation: 0.684811
09/07 10:06:38 PM: micro_avg: validation: 0.000000
09/07 10:06:38 PM: edges-srl-ontonotes_mcc: training: 0.608552 validation: 0.686725
09/07 10:06:38 PM: edges-srl-ontonotes_acc: training: 0.492386 validation: 0.597952
09/07 10:06:38 PM: edges-srl-ontonotes_precision: training: 0.710003 validation: 0.788429
09/07 10:06:38 PM: edges-srl-ontonotes_recall: training: 0.530273 validation: 0.605265
09/07 10:06:38 PM: edges-srl-ontonotes_f1: training: 0.607115 validation: 0.684811
09/07 10:06:38 PM: Global learning rate: 1.25e-05
09/07 10:06:38 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 10:06:44 PM: Update 47135: task edges-srl-ontonotes, batch 135 (47135): mcc: 0.6044, acc: 0.4889, precision: 0.7123, recall: 0.5214, f1: 0.6021, edges-srl-ontonotes_loss: 0.0263
09/07 10:06:55 PM: Update 47284: task edges-srl-ontonotes, batch 284 (47284): mcc: 0.6026, acc: 0.4866, precision: 0.7093, recall: 0.5205, f1: 0.6004, edges-srl-ontonotes_loss: 0.0264
09/07 10:07:05 PM: Update 47492: task edges-srl-ontonotes, batch 492 (47492): mcc: 0.6003, acc: 0.4844, precision: 0.7062, recall: 0.5190, f1: 0.5983, edges-srl-ontonotes_loss: 0.0265
09/07 10:07:15 PM: Update 47677: task edges-srl-ontonotes, batch 677 (47677): mcc: 0.6034, acc: 0.4876, precision: 0.7088, recall: 0.5224, f1: 0.6015, edges-srl-ontonotes_loss: 0.0263
09/07 10:07:25 PM: Update 47862: task edges-srl-ontonotes, batch 862 (47862): mcc: 0.6048, acc: 0.4895, precision: 0.7090, recall: 0.5246, f1: 0.6030, edges-srl-ontonotes_loss: 0.0262
09/07 10:07:31 PM: ***** Step 48000 / Validation 48 *****
09/07 10:07:31 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:07:31 PM: Validating...
09/07 10:07:35 PM: Evaluate: task edges-srl-ontonotes, batch 73 (157): mcc: 0.6861, acc: 0.5984, precision: 0.7872, recall: 0.6051, f1: 0.6842, edges-srl-ontonotes_loss: 0.0225
09/07 10:07:38 PM: Updating LR scheduler:
09/07 10:07:38 PM: 	Best result seen so far for macro_avg: 0.695
09/07 10:07:38 PM: 	# validation passes without improvement: 3
09/07 10:07:38 PM: edges-srl-ontonotes_loss: training: 0.026146 validation: 0.022306
09/07 10:07:38 PM: macro_avg: validation: 0.682664
09/07 10:07:38 PM: micro_avg: validation: 0.000000
09/07 10:07:38 PM: edges-srl-ontonotes_mcc: training: 0.605826 validation: 0.684336
09/07 10:07:38 PM: edges-srl-ontonotes_acc: training: 0.490842 validation: 0.597414
09/07 10:07:38 PM: edges-srl-ontonotes_precision: training: 0.709893 validation: 0.784181
09/07 10:07:38 PM: edges-srl-ontonotes_recall: training: 0.525669 validation: 0.604418
09/07 10:07:38 PM: edges-srl-ontonotes_f1: training: 0.604047 validation: 0.682664
09/07 10:07:38 PM: Global learning rate: 1.25e-05
09/07 10:07:38 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 10:07:45 PM: Update 48130: task edges-srl-ontonotes, batch 130 (48130): mcc: 0.6125, acc: 0.4944, precision: 0.7154, recall: 0.5330, f1: 0.6109, edges-srl-ontonotes_loss: 0.0256
09/07 10:07:55 PM: Update 48279: task edges-srl-ontonotes, batch 279 (48279): mcc: 0.6055, acc: 0.4883, precision: 0.7126, recall: 0.5231, f1: 0.6033, edges-srl-ontonotes_loss: 0.0262
09/07 10:08:06 PM: Update 48485: task edges-srl-ontonotes, batch 485 (48485): mcc: 0.5961, acc: 0.4775, precision: 0.7080, recall: 0.5105, f1: 0.5933, edges-srl-ontonotes_loss: 0.0266
09/07 10:08:16 PM: Update 48691: task edges-srl-ontonotes, batch 691 (48691): mcc: 0.6213, acc: 0.5061, precision: 0.7277, recall: 0.5389, f1: 0.6192, edges-srl-ontonotes_loss: 0.0252
09/07 10:08:26 PM: Update 48875: task edges-srl-ontonotes, batch 875 (48875): mcc: 0.6376, acc: 0.5253, precision: 0.7398, recall: 0.5576, f1: 0.6359, edges-srl-ontonotes_loss: 0.0244
09/07 10:08:32 PM: ***** Step 49000 / Validation 49 *****
09/07 10:08:32 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:08:32 PM: Validating...
09/07 10:08:36 PM: Evaluate: task edges-srl-ontonotes, batch 86 (157): mcc: 0.6874, acc: 0.5990, precision: 0.7866, recall: 0.6079, f1: 0.6858, edges-srl-ontonotes_loss: 0.0224
09/07 10:08:39 PM: Updating LR scheduler:
09/07 10:08:39 PM: 	Best result seen so far for macro_avg: 0.695
09/07 10:08:39 PM: 	# validation passes without improvement: 4
09/07 10:08:39 PM: edges-srl-ontonotes_loss: training: 0.023745 validation: 0.022226
09/07 10:08:39 PM: macro_avg: validation: 0.684423
09/07 10:08:39 PM: micro_avg: validation: 0.000000
09/07 10:08:39 PM: edges-srl-ontonotes_mcc: training: 0.648519 validation: 0.686082
09/07 10:08:39 PM: edges-srl-ontonotes_acc: training: 0.538070 validation: 0.598337
09/07 10:08:39 PM: edges-srl-ontonotes_precision: training: 0.747915 validation: 0.785714
09/07 10:08:39 PM: edges-srl-ontonotes_recall: training: 0.570286 validation: 0.606266
09/07 10:08:39 PM: edges-srl-ontonotes_f1: training: 0.647133 validation: 0.684423
09/07 10:08:39 PM: Global learning rate: 1.25e-05
09/07 10:08:39 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 10:08:47 PM: Update 49111: task edges-srl-ontonotes, batch 111 (49111): mcc: 0.7250, acc: 0.6326, precision: 0.7957, recall: 0.6675, f1: 0.7260, edges-srl-ontonotes_loss: 0.0191
09/07 10:08:57 PM: Update 49313: task edges-srl-ontonotes, batch 313 (49313): mcc: 0.7260, acc: 0.6343, precision: 0.7989, recall: 0.6666, f1: 0.7268, edges-srl-ontonotes_loss: 0.0193
09/07 10:09:07 PM: Update 49497: task edges-srl-ontonotes, batch 497 (49497): mcc: 0.7305, acc: 0.6397, precision: 0.8030, recall: 0.6713, f1: 0.7312, edges-srl-ontonotes_loss: 0.0190
09/07 10:09:17 PM: Update 49698: task edges-srl-ontonotes, batch 698 (49698): mcc: 0.7345, acc: 0.6452, precision: 0.8058, recall: 0.6761, f1: 0.7353, edges-srl-ontonotes_loss: 0.0189
09/07 10:09:27 PM: Update 49882: task edges-srl-ontonotes, batch 882 (49882): mcc: 0.7432, acc: 0.6564, precision: 0.8133, recall: 0.6857, f1: 0.7440, edges-srl-ontonotes_loss: 0.0186
09/07 10:09:33 PM: ***** Step 50000 / Validation 50 *****
09/07 10:09:33 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:09:33 PM: Validating...
09/07 10:09:37 PM: Evaluate: task edges-srl-ontonotes, batch 92 (157): mcc: 0.6950, acc: 0.6085, precision: 0.7924, recall: 0.6166, f1: 0.6935, edges-srl-ontonotes_loss: 0.0219
09/07 10:09:40 PM: Updating LR scheduler:
09/07 10:09:40 PM: 	Best result seen so far for macro_avg: 0.695
09/07 10:09:40 PM: 	# validation passes without improvement: 5
09/07 10:09:40 PM: edges-srl-ontonotes_loss: training: 0.018325 validation: 0.022273
09/07 10:09:40 PM: macro_avg: validation: 0.684920
09/07 10:09:40 PM: micro_avg: validation: 0.000000
09/07 10:09:40 PM: edges-srl-ontonotes_mcc: training: 0.749314 validation: 0.686614
09/07 10:09:40 PM: edges-srl-ontonotes_acc: training: 0.664210 validation: 0.599415
09/07 10:09:40 PM: edges-srl-ontonotes_precision: training: 0.818143 validation: 0.786506
09/07 10:09:40 PM: edges-srl-ontonotes_recall: training: 0.692624 validation: 0.606574
09/07 10:09:40 PM: edges-srl-ontonotes_f1: training: 0.750169 validation: 0.684920
09/07 10:09:40 PM: Global learning rate: 1.25e-05
09/07 10:09:40 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 10:09:47 PM: Update 50126: task edges-srl-ontonotes, batch 126 (50126): mcc: 0.7276, acc: 0.6398, precision: 0.8049, recall: 0.6645, f1: 0.7280, edges-srl-ontonotes_loss: 0.0201
09/07 10:09:57 PM: Update 50331: task edges-srl-ontonotes, batch 331 (50331): mcc: 0.6959, acc: 0.6016, precision: 0.7805, recall: 0.6277, f1: 0.6958, edges-srl-ontonotes_loss: 0.0217
09/07 10:10:07 PM: Update 50472: task edges-srl-ontonotes, batch 472 (50472): mcc: 0.6766, acc: 0.5779, precision: 0.7659, recall: 0.6053, f1: 0.6762, edges-srl-ontonotes_loss: 0.0228
09/07 10:10:17 PM: Update 50671: task edges-srl-ontonotes, batch 671 (50671): mcc: 0.6630, acc: 0.5609, precision: 0.7552, recall: 0.5899, f1: 0.6624, edges-srl-ontonotes_loss: 0.0236
09/07 10:10:27 PM: Update 50839: task edges-srl-ontonotes, batch 839 (50839): mcc: 0.6652, acc: 0.5633, precision: 0.7579, recall: 0.5917, f1: 0.6645, edges-srl-ontonotes_loss: 0.0235
09/07 10:10:36 PM: ***** Step 51000 / Validation 51 *****
09/07 10:10:36 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:10:36 PM: Validating...
09/07 10:10:37 PM: Evaluate: task edges-srl-ontonotes, batch 36 (157): mcc: 0.6888, acc: 0.5933, precision: 0.7996, recall: 0.6003, f1: 0.6858, edges-srl-ontonotes_loss: 0.0224
09/07 10:10:43 PM: Updating LR scheduler:
09/07 10:10:43 PM: 	Best result seen so far for macro_avg: 0.695
09/07 10:10:43 PM: 	# validation passes without improvement: 0
09/07 10:10:43 PM: edges-srl-ontonotes_loss: training: 0.023198 validation: 0.021939
09/07 10:10:43 PM: macro_avg: validation: 0.690237
09/07 10:10:43 PM: micro_avg: validation: 0.000000
09/07 10:10:43 PM: edges-srl-ontonotes_mcc: training: 0.670850 validation: 0.692121
09/07 10:10:43 PM: edges-srl-ontonotes_acc: training: 0.569493 validation: 0.604803
09/07 10:10:43 PM: edges-srl-ontonotes_precision: training: 0.762853 validation: 0.793283
09/07 10:10:43 PM: edges-srl-ontonotes_recall: training: 0.597612 validation: 0.610884
09/07 10:10:43 PM: edges-srl-ontonotes_f1: training: 0.670197 validation: 0.690237
09/07 10:10:43 PM: Global learning rate: 6.25e-06
09/07 10:10:43 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-RANDOM-only/run
09/07 10:10:47 PM: Update 51069: task edges-srl-ontonotes, batch 69 (51069): mcc: 0.6950, acc: 0.6020, precision: 0.7798, recall: 0.6267, f1: 0.6949, edges-srl-ontonotes_loss: 0.0218
09/07 10:10:57 PM: Update 51270: task edges-srl-ontonotes, batch 270 (51270): mcc: 0.6973, acc: 0.6052, precision: 0.7830, recall: 0.6283, f1: 0.6971, edges-srl-ontonotes_loss: 0.0216
