09/16 06:46:18 AM: Git branch: master
09/16 06:46:18 AM: Git SHA: fb3796f035a61c062bc75b422b0939a7eeec20ff
09/16 06:46:18 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/pos-ontonotes-5-way-multiqa-top/",
  "exp_name": "experiments/pos-ontonotes-5-way-multiqa-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/pos-ontonotes-5-way-multiqa-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/5-way-multiqa",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/pos-ontonotes-5-way-multiqa-top__run",
  "run_dir": "./experiments/pos-ontonotes-5-way-multiqa-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-pos-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 06:46:18 AM: Saved config to ./experiments/pos-ontonotes-5-way-multiqa-top/run/params.conf
09/16 06:46:18 AM: Using random seed 1234
09/16 06:46:19 AM: Using GPU 0
09/16 06:46:19 AM: Loading tasks...
09/16 06:46:19 AM: Writing pre-preprocessed tasks to ./experiments/pos-ontonotes-5-way-multiqa-top/
09/16 06:46:19 AM: 	Creating task edges-pos-ontonotes from scratch.
09/16 06:46:35 AM: Read=110514, Skip=5298, Total=115812 from ./probing_data/edges/ontonotes/const/pos/train.json.retokenized.bert-base-uncased
09/16 06:46:35 AM: Read=15060, Skip=620, Total=15680 from ./probing_data/edges/ontonotes/const/pos/development.json.retokenized.bert-base-uncased
09/16 06:46:38 AM: Read=11462, Skip=755, Total=12217 from ./probing_data/edges/ontonotes/const/pos/test.json.retokenized.bert-base-uncased
09/16 06:46:48 AM: 	Task 'edges-pos-ontonotes': |train|=110514 |val|=15060 |test|=11462
09/16 06:46:48 AM: 	Finished loading tasks: edges-pos-ontonotes.
09/16 06:46:48 AM: 	Building vocab from scratch.
09/16 06:46:48 AM: 	Counting units for task edges-pos-ontonotes.
09/16 06:46:50 AM: 	Task 'edges-pos-ontonotes': adding vocab namespace 'edges-pos-ontonotes_labels'
09/16 06:46:51 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:46:51 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 06:46:51 AM: 	Saved vocab to ./experiments/pos-ontonotes-5-way-multiqa-top/vocab
09/16 06:46:51 AM: Loading token dictionary from ./experiments/pos-ontonotes-5-way-multiqa-top/vocab.
09/16 06:46:51 AM: 	Loaded vocab from ./experiments/pos-ontonotes-5-way-multiqa-top/vocab
09/16 06:46:51 AM: 	Vocab namespace bert_uncased: size 30524
09/16 06:46:51 AM: 	Vocab namespace tokens: size 24015
09/16 06:46:51 AM: 	Vocab namespace edges-pos-ontonotes_labels: size 48
09/16 06:46:51 AM: 	Vocab namespace chars: size 81
09/16 06:46:51 AM: 	Finished building vocab.
09/16 06:46:51 AM: 	Task edges-pos-ontonotes (train): Indexing from scratch.
09/16 06:47:20 AM: 	Task edges-pos-ontonotes (train): Saved 110514 instances to ./experiments/pos-ontonotes-5-way-multiqa-top/preproc/edges-pos-ontonotes__train_data
09/16 06:47:20 AM: 	Task edges-pos-ontonotes (val): Indexing from scratch.
09/16 06:47:24 AM: 	Task edges-pos-ontonotes (val): Saved 15060 instances to ./experiments/pos-ontonotes-5-way-multiqa-top/preproc/edges-pos-ontonotes__val_data
09/16 06:47:24 AM: 	Task edges-pos-ontonotes (test): Indexing from scratch.
09/16 06:47:27 AM: 	Task edges-pos-ontonotes (test): Saved 11462 instances to ./experiments/pos-ontonotes-5-way-multiqa-top/preproc/edges-pos-ontonotes__test_data
09/16 06:47:27 AM: 	Finished indexing tasks
09/16 06:47:27 AM: 	Creating trimmed target-only version of edges-pos-ontonotes train.
09/16 06:47:27 AM: 	  Training on 
09/16 06:47:27 AM: 	  Evaluating on edges-pos-ontonotes
09/16 06:47:27 AM: 	Finished loading tasks in 68.485s
09/16 06:47:27 AM: 	 Tasks: ['edges-pos-ontonotes']
09/16 06:47:27 AM: Building model...
09/16 06:47:27 AM: Using BERT model (bert-base-uncased).
09/16 06:47:27 AM: LOADING A FUNETUNED MODEL from: 
09/16 06:47:27 AM: models/5-way-multiqa
09/16 06:47:27 AM: loading configuration file models/5-way-multiqa/config.json
09/16 06:47:27 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 06:47:27 AM: loading weights file models/5-way-multiqa/pytorch_model.bin
09/16 06:47:30 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp7siqzroj
09/16 06:47:32 AM: copying /tmp/tmp7siqzroj to cache at ./experiments/pos-ontonotes-5-way-multiqa-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:47:32 AM: creating metadata file for ./experiments/pos-ontonotes-5-way-multiqa-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:47:32 AM: removing temp file /tmp/tmp7siqzroj
09/16 06:47:32 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/pos-ontonotes-5-way-multiqa-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:47:32 AM: Initializing parameters
09/16 06:47:32 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 06:47:32 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 06:47:32 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 06:47:32 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 06:47:32 AM: 	Task 'edges-pos-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-pos-ontonotes"
}
09/16 06:47:36 AM: Model specification:
09/16 06:47:36 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-pos-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=48, bias=True)
    )
  )
)
09/16 06:47:36 AM: Model parameters:
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	edges-pos-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 06:47:36 AM: 	edges-pos-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 06:47:36 AM: 	edges-pos-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 24576 with torch.Size([48, 512])
09/16 06:47:36 AM: 	edges-pos-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 48 with torch.Size([48])
09/16 06:47:36 AM: Total number of parameters: 109703728 (1.09704e+08)
09/16 06:47:36 AM: Number of trainable parameters: 221488 (221488)
09/16 06:47:36 AM: Finished building model in 8.994s
09/16 06:47:36 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-pos-ontonotes 

09/16 06:48:37 AM: patience = 9
09/16 06:48:37 AM: val_interval = 1000
09/16 06:48:37 AM: max_vals = 250
09/16 06:48:37 AM: cuda_device = 0
09/16 06:48:37 AM: grad_norm = 5.0
09/16 06:48:37 AM: grad_clipping = None
09/16 06:48:37 AM: lr_decay = 0.99
09/16 06:48:37 AM: min_lr = 1e-06
09/16 06:48:37 AM: keep_all_checkpoints = 0
09/16 06:48:37 AM: val_data_limit = 5000
09/16 06:48:37 AM: max_epochs = -1
09/16 06:48:37 AM: dec_val_scale = 250
09/16 06:48:37 AM: training_data_fraction = 1
09/16 06:48:37 AM: type = adam
09/16 06:48:37 AM: parameter_groups = None
09/16 06:48:37 AM: Number of trainable parameters: 221488
09/16 06:48:37 AM: infer_type_and_cast = True
09/16 06:48:37 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:48:37 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:48:37 AM: lr = 0.0001
09/16 06:48:37 AM: amsgrad = True
09/16 06:48:37 AM: type = reduce_on_plateau
09/16 06:48:37 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:48:37 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:48:37 AM: mode = max
09/16 06:48:37 AM: factor = 0.5
09/16 06:48:37 AM: patience = 3
09/16 06:48:37 AM: threshold = 0.0001
09/16 06:48:37 AM: threshold_mode = abs
09/16 06:48:37 AM: verbose = True
09/16 06:48:37 AM: type = adam
09/16 06:48:37 AM: parameter_groups = None
09/16 06:48:37 AM: Number of trainable parameters: 221488
09/16 06:48:37 AM: infer_type_and_cast = True
09/16 06:48:37 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:48:37 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:48:37 AM: lr = 0.0001
09/16 06:48:37 AM: amsgrad = True
09/16 06:48:37 AM: type = reduce_on_plateau
09/16 06:48:37 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:48:37 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:48:37 AM: mode = max
09/16 06:48:37 AM: factor = 0.5
09/16 06:48:37 AM: patience = 3
09/16 06:48:37 AM: threshold = 0.0001
09/16 06:48:37 AM: threshold_mode = abs
09/16 06:48:37 AM: verbose = True
09/16 06:48:37 AM: Starting training without restoring from a checkpoint.
09/16 06:48:37 AM: Training examples per task, before any subsampling: {'edges-pos-ontonotes': 110514}
09/16 06:48:37 AM: Beginning training with stopping criteria based on metric: edges-pos-ontonotes_f1
09/16 06:48:47 AM: Update 81: task edges-pos-ontonotes, batch 81 (81): mcc: 0.0040, acc: 0.0006, precision: 0.0229, recall: 0.0791, f1: 0.0355, edges-pos-ontonotes_loss: 0.2465
09/16 06:48:57 AM: Update 172: task edges-pos-ontonotes, batch 172 (172): mcc: 0.0040, acc: 0.0020, precision: 0.0239, recall: 0.0386, f1: 0.0295, edges-pos-ontonotes_loss: 0.1597
09/16 06:49:07 AM: Update 266: task edges-pos-ontonotes, batch 266 (266): mcc: 0.0105, acc: 0.0088, precision: 0.0309, recall: 0.0327, f1: 0.0317, edges-pos-ontonotes_loss: 0.1300
09/16 06:49:17 AM: Update 334: task edges-pos-ontonotes, batch 334 (334): mcc: 0.0176, acc: 0.0145, precision: 0.0399, recall: 0.0328, f1: 0.0360, edges-pos-ontonotes_loss: 0.1184
09/16 06:49:27 AM: Update 412: task edges-pos-ontonotes, batch 412 (412): mcc: 0.0259, acc: 0.0197, precision: 0.0524, recall: 0.0341, f1: 0.0413, edges-pos-ontonotes_loss: 0.1096
09/16 06:49:37 AM: Update 486: task edges-pos-ontonotes, batch 486 (486): mcc: 0.0370, acc: 0.0263, precision: 0.0702, recall: 0.0382, f1: 0.0495, edges-pos-ontonotes_loss: 0.1032
09/16 06:49:47 AM: Update 555: task edges-pos-ontonotes, batch 555 (555): mcc: 0.0488, acc: 0.0326, precision: 0.0906, recall: 0.0429, f1: 0.0583, edges-pos-ontonotes_loss: 0.0987
09/16 06:49:59 AM: Update 627: task edges-pos-ontonotes, batch 627 (627): mcc: 0.0622, acc: 0.0395, precision: 0.1147, recall: 0.0489, f1: 0.0685, edges-pos-ontonotes_loss: 0.0946
09/16 06:50:09 AM: Update 678: task edges-pos-ontonotes, batch 678 (678): mcc: 0.0737, acc: 0.0448, precision: 0.1375, recall: 0.0533, f1: 0.0769, edges-pos-ontonotes_loss: 0.0925
09/16 06:50:19 AM: Update 733: task edges-pos-ontonotes, batch 733 (733): mcc: 0.0859, acc: 0.0503, precision: 0.1620, recall: 0.0583, f1: 0.0857, edges-pos-ontonotes_loss: 0.0904
09/16 06:50:29 AM: Update 797: task edges-pos-ontonotes, batch 797 (797): mcc: 0.1000, acc: 0.0570, precision: 0.1900, recall: 0.0646, f1: 0.0964, edges-pos-ontonotes_loss: 0.0882
09/16 06:50:39 AM: Update 861: task edges-pos-ontonotes, batch 861 (861): mcc: 0.1145, acc: 0.0639, precision: 0.2186, recall: 0.0712, f1: 0.1074, edges-pos-ontonotes_loss: 0.0862
09/16 06:50:49 AM: Update 914: task edges-pos-ontonotes, batch 914 (914): mcc: 0.1283, acc: 0.0703, precision: 0.2467, recall: 0.0775, f1: 0.1179, edges-pos-ontonotes_loss: 0.0847
09/16 06:50:59 AM: Update 960: task edges-pos-ontonotes, batch 960 (960): mcc: 0.1392, acc: 0.0753, precision: 0.2687, recall: 0.0824, f1: 0.1261, edges-pos-ontonotes_loss: 0.0835
09/16 06:51:07 AM: ***** Step 1000 / Validation 1 *****
09/16 06:51:07 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 06:51:07 AM: Validating...
09/16 06:51:10 AM: Evaluate: task edges-pos-ontonotes, batch 17 (157): mcc: 0.4020, acc: 0.1863, precision: 0.8600, recall: 0.1924, f1: 0.3144, edges-pos-ontonotes_loss: 0.0573
09/16 06:51:20 AM: Evaluate: task edges-pos-ontonotes, batch 86 (157): mcc: 0.4224, acc: 0.1975, precision: 0.9018, recall: 0.2020, f1: 0.3301, edges-pos-ontonotes_loss: 0.0576
09/16 06:51:30 AM: Evaluate: task edges-pos-ontonotes, batch 132 (157): mcc: 0.4241, acc: 0.1999, precision: 0.8960, recall: 0.2051, f1: 0.3338, edges-pos-ontonotes_loss: 0.0566
09/16 06:51:35 AM: Best result seen so far for edges-pos-ontonotes.
09/16 06:51:35 AM: Best result seen so far for micro.
09/16 06:51:35 AM: Best result seen so far for macro.
09/16 06:51:35 AM: Updating LR scheduler:
09/16 06:51:35 AM: 	Best result seen so far for macro_avg: 0.327
09/16 06:51:35 AM: 	# validation passes without improvement: 0
09/16 06:51:35 AM: edges-pos-ontonotes_loss: training: 0.082498 validation: 0.056583
09/16 06:51:35 AM: macro_avg: validation: 0.327192
09/16 06:51:35 AM: micro_avg: validation: 0.000000
09/16 06:51:35 AM: edges-pos-ontonotes_mcc: training: 0.148172 validation: 0.418547
09/16 06:51:35 AM: edges-pos-ontonotes_acc: training: 0.079335 validation: 0.195276
09/16 06:51:35 AM: edges-pos-ontonotes_precision: training: 0.287531 validation: 0.893775
09/16 06:51:35 AM: edges-pos-ontonotes_recall: training: 0.086359 validation: 0.200250
09/16 06:51:35 AM: edges-pos-ontonotes_f1: training: 0.132824 validation: 0.327192
09/16 06:51:35 AM: Global learning rate: 0.0001
09/16 06:51:35 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 06:51:40 AM: Update 1026: task edges-pos-ontonotes, batch 26 (1026): mcc: 0.3667, acc: 0.1600, precision: 0.8294, recall: 0.1664, f1: 0.2771, edges-pos-ontonotes_loss: 0.0591
09/16 06:51:50 AM: Update 1080: task edges-pos-ontonotes, batch 80 (1080): mcc: 0.3813, acc: 0.1724, precision: 0.8271, recall: 0.1803, f1: 0.2960, edges-pos-ontonotes_loss: 0.0579
09/16 06:52:00 AM: Update 1136: task edges-pos-ontonotes, batch 136 (1136): mcc: 0.3890, acc: 0.1790, precision: 0.8270, recall: 0.1877, f1: 0.3059, edges-pos-ontonotes_loss: 0.0572
09/16 06:52:10 AM: Update 1189: task edges-pos-ontonotes, batch 189 (1189): mcc: 0.3946, acc: 0.1841, precision: 0.8279, recall: 0.1928, f1: 0.3128, edges-pos-ontonotes_loss: 0.0568
09/16 06:52:21 AM: Update 1245: task edges-pos-ontonotes, batch 245 (1245): mcc: 0.4001, acc: 0.1890, precision: 0.8274, recall: 0.1983, f1: 0.3200, edges-pos-ontonotes_loss: 0.0563
09/16 06:52:32 AM: Update 1253: task edges-pos-ontonotes, batch 253 (1253): mcc: 0.4007, acc: 0.1896, precision: 0.8270, recall: 0.1990, f1: 0.3209, edges-pos-ontonotes_loss: 0.0563
09/16 06:52:42 AM: Update 1311: task edges-pos-ontonotes, batch 311 (1311): mcc: 0.4071, acc: 0.1953, precision: 0.8287, recall: 0.2050, f1: 0.3287, edges-pos-ontonotes_loss: 0.0558
09/16 06:52:53 AM: Update 1369: task edges-pos-ontonotes, batch 369 (1369): mcc: 0.4130, acc: 0.2008, precision: 0.8289, recall: 0.2109, f1: 0.3362, edges-pos-ontonotes_loss: 0.0553
09/16 06:53:03 AM: Update 1427: task edges-pos-ontonotes, batch 427 (1427): mcc: 0.4194, acc: 0.2067, precision: 0.8297, recall: 0.2172, f1: 0.3443, edges-pos-ontonotes_loss: 0.0549
09/16 06:53:13 AM: Update 1480: task edges-pos-ontonotes, batch 480 (1480): mcc: 0.4244, acc: 0.2116, precision: 0.8293, recall: 0.2225, f1: 0.3508, edges-pos-ontonotes_loss: 0.0545
09/16 06:53:23 AM: Update 1534: task edges-pos-ontonotes, batch 534 (1534): mcc: 0.4297, acc: 0.2168, precision: 0.8297, recall: 0.2280, f1: 0.3577, edges-pos-ontonotes_loss: 0.0541
09/16 06:53:33 AM: Update 1585: task edges-pos-ontonotes, batch 585 (1585): mcc: 0.4336, acc: 0.2207, precision: 0.8291, recall: 0.2323, f1: 0.3629, edges-pos-ontonotes_loss: 0.0538
09/16 06:53:43 AM: Update 1639: task edges-pos-ontonotes, batch 639 (1639): mcc: 0.4384, acc: 0.2256, precision: 0.8287, recall: 0.2376, f1: 0.3693, edges-pos-ontonotes_loss: 0.0534
09/16 06:53:53 AM: Update 1694: task edges-pos-ontonotes, batch 694 (1694): mcc: 0.4438, acc: 0.2308, precision: 0.8289, recall: 0.2433, f1: 0.3762, edges-pos-ontonotes_loss: 0.0530
09/16 06:54:03 AM: Update 1748: task edges-pos-ontonotes, batch 748 (1748): mcc: 0.4477, acc: 0.2348, precision: 0.8286, recall: 0.2477, f1: 0.3814, edges-pos-ontonotes_loss: 0.0527
09/16 06:54:13 AM: Update 1807: task edges-pos-ontonotes, batch 807 (1807): mcc: 0.4521, acc: 0.2393, precision: 0.8284, recall: 0.2527, f1: 0.3872, edges-pos-ontonotes_loss: 0.0523
09/16 06:54:23 AM: Update 1861: task edges-pos-ontonotes, batch 861 (1861): mcc: 0.4567, acc: 0.2439, precision: 0.8287, recall: 0.2576, f1: 0.3930, edges-pos-ontonotes_loss: 0.0520
09/16 06:54:33 AM: Update 1902: task edges-pos-ontonotes, batch 902 (1902): mcc: 0.4588, acc: 0.2463, precision: 0.8278, recall: 0.2603, f1: 0.3961, edges-pos-ontonotes_loss: 0.0517
09/16 06:54:43 AM: Update 1971: task edges-pos-ontonotes, batch 971 (1971): mcc: 0.4630, acc: 0.2506, precision: 0.8280, recall: 0.2650, f1: 0.4015, edges-pos-ontonotes_loss: 0.0513
09/16 06:54:47 AM: ***** Step 2000 / Validation 2 *****
09/16 06:54:47 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 06:54:47 AM: Validating...
09/16 06:54:54 AM: Evaluate: task edges-pos-ontonotes, batch 43 (157): mcc: 0.5332, acc: 0.3156, precision: 0.8978, recall: 0.3225, f1: 0.4746, edges-pos-ontonotes_loss: 0.0464
09/16 06:55:04 AM: Evaluate: task edges-pos-ontonotes, batch 103 (157): mcc: 0.5750, acc: 0.3624, precision: 0.9039, recall: 0.3721, f1: 0.5271, edges-pos-ontonotes_loss: 0.0440
09/16 06:55:14 AM: Evaluate: task edges-pos-ontonotes, batch 149 (157): mcc: 0.5769, acc: 0.3676, precision: 0.8947, recall: 0.3784, f1: 0.5319, edges-pos-ontonotes_loss: 0.0434
09/16 06:55:15 AM: Best result seen so far for edges-pos-ontonotes.
09/16 06:55:15 AM: Best result seen so far for macro.
09/16 06:55:15 AM: Updating LR scheduler:
09/16 06:55:15 AM: 	Best result seen so far for macro_avg: 0.531
09/16 06:55:15 AM: 	# validation passes without improvement: 0
09/16 06:55:15 AM: edges-pos-ontonotes_loss: training: 0.051144 validation: 0.043330
09/16 06:55:15 AM: macro_avg: validation: 0.530518
09/16 06:55:15 AM: micro_avg: validation: 0.000000
09/16 06:55:15 AM: edges-pos-ontonotes_mcc: training: 0.464805 validation: 0.575948
09/16 06:55:15 AM: edges-pos-ontonotes_acc: training: 0.252411 validation: 0.366371
09/16 06:55:15 AM: edges-pos-ontonotes_precision: training: 0.828235 validation: 0.895332
09/16 06:55:15 AM: edges-pos-ontonotes_recall: training: 0.266960 validation: 0.376933
09/16 06:55:15 AM: edges-pos-ontonotes_f1: training: 0.403774 validation: 0.530518
09/16 06:55:15 AM: Global learning rate: 0.0001
09/16 06:55:15 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 06:55:24 AM: Update 2062: task edges-pos-ontonotes, batch 62 (2062): mcc: 0.5415, acc: 0.3378, precision: 0.8343, recall: 0.3588, f1: 0.5018, edges-pos-ontonotes_loss: 0.0443
09/16 06:55:34 AM: Update 2127: task edges-pos-ontonotes, batch 127 (2127): mcc: 0.5413, acc: 0.3371, precision: 0.8320, recall: 0.3595, f1: 0.5020, edges-pos-ontonotes_loss: 0.0440
09/16 06:55:45 AM: Update 2192: task edges-pos-ontonotes, batch 192 (2192): mcc: 0.5425, acc: 0.3387, precision: 0.8301, recall: 0.3619, f1: 0.5040, edges-pos-ontonotes_loss: 0.0437
09/16 06:55:55 AM: Update 2286: task edges-pos-ontonotes, batch 286 (2286): mcc: 0.5559, acc: 0.3526, precision: 0.8392, recall: 0.3756, f1: 0.5189, edges-pos-ontonotes_loss: 0.0426
09/16 06:56:05 AM: Update 2378: task edges-pos-ontonotes, batch 378 (2378): mcc: 0.5690, acc: 0.3664, precision: 0.8471, recall: 0.3895, f1: 0.5337, edges-pos-ontonotes_loss: 0.0417
09/16 06:56:15 AM: Update 2468: task edges-pos-ontonotes, batch 468 (2468): mcc: 0.5787, acc: 0.3772, precision: 0.8519, recall: 0.4006, f1: 0.5449, edges-pos-ontonotes_loss: 0.0409
09/16 06:56:25 AM: Update 2555: task edges-pos-ontonotes, batch 555 (2555): mcc: 0.5856, acc: 0.3848, precision: 0.8546, recall: 0.4086, f1: 0.5529, edges-pos-ontonotes_loss: 0.0404
09/16 06:56:35 AM: Update 2660: task edges-pos-ontonotes, batch 660 (2660): mcc: 0.5936, acc: 0.3945, precision: 0.8571, recall: 0.4186, f1: 0.5624, edges-pos-ontonotes_loss: 0.0397
09/16 06:56:45 AM: Update 2770: task edges-pos-ontonotes, batch 770 (2770): mcc: 0.6018, acc: 0.4046, precision: 0.8590, recall: 0.4292, f1: 0.5723, edges-pos-ontonotes_loss: 0.0388
09/16 06:56:55 AM: Update 2871: task edges-pos-ontonotes, batch 871 (2871): mcc: 0.6036, acc: 0.4074, precision: 0.8580, recall: 0.4322, f1: 0.5748, edges-pos-ontonotes_loss: 0.0386
09/16 06:57:05 AM: ***** Step 3000 / Validation 3 *****
09/16 06:57:05 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 06:57:05 AM: Validating...
09/16 06:57:05 AM: Evaluate: task edges-pos-ontonotes, batch 2 (157): mcc: 0.6833, acc: 0.5083, precision: 0.8440, recall: 0.5615, f1: 0.6743, edges-pos-ontonotes_loss: 0.0321
09/16 06:57:16 AM: Evaluate: task edges-pos-ontonotes, batch 73 (157): mcc: 0.6704, acc: 0.4930, precision: 0.8847, recall: 0.5153, f1: 0.6513, edges-pos-ontonotes_loss: 0.0349
09/16 06:57:26 AM: Evaluate: task edges-pos-ontonotes, batch 125 (157): mcc: 0.6605, acc: 0.4821, precision: 0.8687, recall: 0.5099, f1: 0.6426, edges-pos-ontonotes_loss: 0.0358
09/16 06:57:32 AM: Best result seen so far for edges-pos-ontonotes.
09/16 06:57:32 AM: Best result seen so far for macro.
09/16 06:57:32 AM: Updating LR scheduler:
09/16 06:57:32 AM: 	Best result seen so far for macro_avg: 0.632
09/16 06:57:32 AM: 	# validation passes without improvement: 0
09/16 06:57:32 AM: edges-pos-ontonotes_loss: training: 0.038015 validation: 0.036428
09/16 06:57:32 AM: macro_avg: validation: 0.632305
09/16 06:57:32 AM: micro_avg: validation: 0.000000
09/16 06:57:32 AM: edges-pos-ontonotes_mcc: training: 0.605760 validation: 0.651072
09/16 06:57:32 AM: edges-pos-ontonotes_acc: training: 0.410481 validation: 0.469824
09/16 06:57:32 AM: edges-pos-ontonotes_precision: training: 0.857131 validation: 0.863111
09/16 06:57:32 AM: edges-pos-ontonotes_recall: training: 0.435672 validation: 0.498894
09/16 06:57:32 AM: edges-pos-ontonotes_f1: training: 0.577703 validation: 0.632305
09/16 06:57:32 AM: Global learning rate: 0.0001
09/16 06:57:32 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 06:57:36 AM: Update 3043: task edges-pos-ontonotes, batch 43 (3043): mcc: 0.6183, acc: 0.4328, precision: 0.8435, recall: 0.4612, f1: 0.5963, edges-pos-ontonotes_loss: 0.0354
09/16 06:57:46 AM: Update 3136: task edges-pos-ontonotes, batch 136 (3136): mcc: 0.5990, acc: 0.4126, precision: 0.8258, recall: 0.4427, f1: 0.5764, edges-pos-ontonotes_loss: 0.0346
09/16 06:57:56 AM: Update 3191: task edges-pos-ontonotes, batch 191 (3191): mcc: 0.5780, acc: 0.3889, precision: 0.8096, recall: 0.4211, f1: 0.5540, edges-pos-ontonotes_loss: 0.0373
09/16 06:58:06 AM: Update 3250: task edges-pos-ontonotes, batch 250 (3250): mcc: 0.5716, acc: 0.3817, precision: 0.8052, recall: 0.4142, f1: 0.5470, edges-pos-ontonotes_loss: 0.0387
09/16 06:58:16 AM: Update 3313: task edges-pos-ontonotes, batch 313 (3313): mcc: 0.5712, acc: 0.3809, precision: 0.8055, recall: 0.4134, f1: 0.5464, edges-pos-ontonotes_loss: 0.0396
09/16 06:58:26 AM: Update 3376: task edges-pos-ontonotes, batch 376 (3376): mcc: 0.5715, acc: 0.3811, precision: 0.8067, recall: 0.4133, f1: 0.5466, edges-pos-ontonotes_loss: 0.0399
09/16 06:58:36 AM: Update 3439: task edges-pos-ontonotes, batch 439 (3439): mcc: 0.5723, acc: 0.3819, precision: 0.8068, recall: 0.4144, f1: 0.5475, edges-pos-ontonotes_loss: 0.0401
09/16 06:58:49 AM: Update 3461: task edges-pos-ontonotes, batch 461 (3461): mcc: 0.5734, acc: 0.3830, precision: 0.8079, recall: 0.4153, f1: 0.5486, edges-pos-ontonotes_loss: 0.0401
09/16 06:58:59 AM: Update 3560: task edges-pos-ontonotes, batch 560 (3560): mcc: 0.5795, acc: 0.3897, precision: 0.8130, recall: 0.4214, f1: 0.5551, edges-pos-ontonotes_loss: 0.0393
09/16 06:59:10 AM: Update 3657: task edges-pos-ontonotes, batch 657 (3657): mcc: 0.5855, acc: 0.3963, precision: 0.8170, recall: 0.4279, f1: 0.5616, edges-pos-ontonotes_loss: 0.0385
09/16 06:59:20 AM: Update 3739: task edges-pos-ontonotes, batch 739 (3739): mcc: 0.5890, acc: 0.4003, precision: 0.8189, recall: 0.4319, f1: 0.5656, edges-pos-ontonotes_loss: 0.0381
09/16 06:59:30 AM: Update 3806: task edges-pos-ontonotes, batch 806 (3806): mcc: 0.5916, acc: 0.4035, precision: 0.8196, recall: 0.4354, f1: 0.5687, edges-pos-ontonotes_loss: 0.0378
09/16 06:59:40 AM: Update 3874: task edges-pos-ontonotes, batch 874 (3874): mcc: 0.5946, acc: 0.4073, precision: 0.8196, recall: 0.4398, f1: 0.5724, edges-pos-ontonotes_loss: 0.0377
09/16 06:59:50 AM: Update 3949: task edges-pos-ontonotes, batch 949 (3949): mcc: 0.5979, acc: 0.4113, precision: 0.8203, recall: 0.4442, f1: 0.5763, edges-pos-ontonotes_loss: 0.0374
09/16 06:59:57 AM: ***** Step 4000 / Validation 4 *****
09/16 06:59:57 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 06:59:57 AM: Validating...
09/16 07:00:00 AM: Evaluate: task edges-pos-ontonotes, batch 25 (157): mcc: 0.7008, acc: 0.5341, precision: 0.9022, recall: 0.5513, f1: 0.6844, edges-pos-ontonotes_loss: 0.0310
09/16 07:00:10 AM: Evaluate: task edges-pos-ontonotes, batch 91 (157): mcc: 0.7114, acc: 0.5444, precision: 0.9073, recall: 0.5647, f1: 0.6961, edges-pos-ontonotes_loss: 0.0300
09/16 07:00:20 AM: Evaluate: task edges-pos-ontonotes, batch 137 (157): mcc: 0.6943, acc: 0.5227, precision: 0.9011, recall: 0.5421, f1: 0.6769, edges-pos-ontonotes_loss: 0.0312
09/16 07:00:25 AM: Best result seen so far for edges-pos-ontonotes.
09/16 07:00:25 AM: Best result seen so far for macro.
09/16 07:00:25 AM: Updating LR scheduler:
09/16 07:00:25 AM: 	Best result seen so far for macro_avg: 0.672
09/16 07:00:25 AM: 	# validation passes without improvement: 0
09/16 07:00:25 AM: edges-pos-ontonotes_loss: training: 0.037218 validation: 0.031534
09/16 07:00:25 AM: macro_avg: validation: 0.671991
09/16 07:00:25 AM: micro_avg: validation: 0.000000
09/16 07:00:25 AM: edges-pos-ontonotes_mcc: training: 0.600265 validation: 0.690100
09/16 07:00:25 AM: edges-pos-ontonotes_acc: training: 0.414272 validation: 0.516810
09/16 07:00:25 AM: edges-pos-ontonotes_precision: training: 0.820875 validation: 0.900309
09/16 07:00:25 AM: edges-pos-ontonotes_recall: training: 0.447338 validation: 0.536049
09/16 07:00:25 AM: edges-pos-ontonotes_f1: training: 0.579096 validation: 0.671991
09/16 07:00:25 AM: Global learning rate: 0.0001
09/16 07:00:25 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 07:00:31 AM: Update 4044: task edges-pos-ontonotes, batch 44 (4044): mcc: 0.6376, acc: 0.4648, precision: 0.8209, recall: 0.5040, f1: 0.6245, edges-pos-ontonotes_loss: 0.0361
09/16 07:00:41 AM: Update 4095: task edges-pos-ontonotes, batch 95 (4095): mcc: 0.6192, acc: 0.4420, precision: 0.8138, recall: 0.4799, f1: 0.6038, edges-pos-ontonotes_loss: 0.0363
09/16 07:00:51 AM: Update 4154: task edges-pos-ontonotes, batch 154 (4154): mcc: 0.6132, acc: 0.4347, precision: 0.8104, recall: 0.4728, f1: 0.5972, edges-pos-ontonotes_loss: 0.0377
09/16 07:01:01 AM: Update 4210: task edges-pos-ontonotes, batch 210 (4210): mcc: 0.6091, acc: 0.4299, precision: 0.8077, recall: 0.4681, f1: 0.5927, edges-pos-ontonotes_loss: 0.0382
09/16 07:01:11 AM: Update 4271: task edges-pos-ontonotes, batch 271 (4271): mcc: 0.6089, acc: 0.4291, precision: 0.8085, recall: 0.4675, f1: 0.5924, edges-pos-ontonotes_loss: 0.0383
09/16 07:01:21 AM: Update 4327: task edges-pos-ontonotes, batch 327 (4327): mcc: 0.6073, acc: 0.4271, precision: 0.8077, recall: 0.4654, f1: 0.5905, edges-pos-ontonotes_loss: 0.0384
09/16 07:01:31 AM: Update 4384: task edges-pos-ontonotes, batch 384 (4384): mcc: 0.6063, acc: 0.4260, precision: 0.8079, recall: 0.4638, f1: 0.5893, edges-pos-ontonotes_loss: 0.0384
09/16 07:01:41 AM: Update 4427: task edges-pos-ontonotes, batch 427 (4427): mcc: 0.6049, acc: 0.4245, precision: 0.8065, recall: 0.4625, f1: 0.5879, edges-pos-ontonotes_loss: 0.0385
09/16 07:01:52 AM: Update 4486: task edges-pos-ontonotes, batch 486 (4486): mcc: 0.6054, acc: 0.4248, precision: 0.8067, recall: 0.4632, f1: 0.5885, edges-pos-ontonotes_loss: 0.0385
09/16 07:02:02 AM: Update 4536: task edges-pos-ontonotes, batch 536 (4536): mcc: 0.6053, acc: 0.4245, precision: 0.8065, recall: 0.4631, f1: 0.5883, edges-pos-ontonotes_loss: 0.0385
09/16 07:02:12 AM: Update 4587: task edges-pos-ontonotes, batch 587 (4587): mcc: 0.6055, acc: 0.4248, precision: 0.8064, recall: 0.4635, f1: 0.5886, edges-pos-ontonotes_loss: 0.0385
09/16 07:02:22 AM: Update 4642: task edges-pos-ontonotes, batch 642 (4642): mcc: 0.6068, acc: 0.4264, precision: 0.8070, recall: 0.4652, f1: 0.5902, edges-pos-ontonotes_loss: 0.0385
09/16 07:02:32 AM: Update 4694: task edges-pos-ontonotes, batch 694 (4694): mcc: 0.6076, acc: 0.4272, precision: 0.8074, recall: 0.4661, f1: 0.5910, edges-pos-ontonotes_loss: 0.0384
09/16 07:02:42 AM: Update 4740: task edges-pos-ontonotes, batch 740 (4740): mcc: 0.6080, acc: 0.4276, precision: 0.8075, recall: 0.4666, f1: 0.5914, edges-pos-ontonotes_loss: 0.0384
09/16 07:02:52 AM: Update 4793: task edges-pos-ontonotes, batch 793 (4793): mcc: 0.6090, acc: 0.4287, precision: 0.8080, recall: 0.4678, f1: 0.5926, edges-pos-ontonotes_loss: 0.0383
09/16 07:03:02 AM: Update 4849: task edges-pos-ontonotes, batch 849 (4849): mcc: 0.6102, acc: 0.4300, precision: 0.8087, recall: 0.4692, f1: 0.5939, edges-pos-ontonotes_loss: 0.0382
09/16 07:03:12 AM: Update 4904: task edges-pos-ontonotes, batch 904 (4904): mcc: 0.6112, acc: 0.4311, precision: 0.8092, recall: 0.4704, f1: 0.5950, edges-pos-ontonotes_loss: 0.0382
09/16 07:03:22 AM: Update 4963: task edges-pos-ontonotes, batch 963 (4963): mcc: 0.6123, acc: 0.4326, precision: 0.8098, recall: 0.4719, f1: 0.5963, edges-pos-ontonotes_loss: 0.0381
09/16 07:03:30 AM: ***** Step 5000 / Validation 5 *****
09/16 07:03:30 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:03:30 AM: Validating...
09/16 07:03:32 AM: Evaluate: task edges-pos-ontonotes, batch 17 (157): mcc: 0.7188, acc: 0.5603, precision: 0.8975, recall: 0.5828, f1: 0.7067, edges-pos-ontonotes_loss: 0.0298
09/16 07:03:43 AM: Evaluate: task edges-pos-ontonotes, batch 87 (157): mcc: 0.7234, acc: 0.5625, precision: 0.9068, recall: 0.5841, f1: 0.7105, edges-pos-ontonotes_loss: 0.0296
09/16 07:03:53 AM: Evaluate: task edges-pos-ontonotes, batch 133 (157): mcc: 0.7150, acc: 0.5515, precision: 0.9046, recall: 0.5721, f1: 0.7009, edges-pos-ontonotes_loss: 0.0298
09/16 07:03:57 AM: Best result seen so far for edges-pos-ontonotes.
09/16 07:03:57 AM: Best result seen so far for macro.
09/16 07:03:57 AM: Updating LR scheduler:
09/16 07:03:57 AM: 	Best result seen so far for macro_avg: 0.700
09/16 07:03:57 AM: 	# validation passes without improvement: 0
09/16 07:03:57 AM: edges-pos-ontonotes_loss: training: 0.038083 validation: 0.029791
09/16 07:03:57 AM: macro_avg: validation: 0.700216
09/16 07:03:57 AM: micro_avg: validation: 0.000000
09/16 07:03:57 AM: edges-pos-ontonotes_mcc: training: 0.612650 validation: 0.714566
09/16 07:03:57 AM: edges-pos-ontonotes_acc: training: 0.432940 validation: 0.550261
09/16 07:03:57 AM: edges-pos-ontonotes_precision: training: 0.809903 validation: 0.905705
09/16 07:03:57 AM: edges-pos-ontonotes_recall: training: 0.472254 validation: 0.570727
09/16 07:03:57 AM: edges-pos-ontonotes_f1: training: 0.596619 validation: 0.700216
09/16 07:03:57 AM: Global learning rate: 0.0001
09/16 07:03:57 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 07:04:12 AM: Update 5026: task edges-pos-ontonotes, batch 26 (5026): mcc: 0.6317, acc: 0.4575, precision: 0.8172, recall: 0.4971, f1: 0.6182, edges-pos-ontonotes_loss: 0.0357
09/16 07:04:22 AM: Update 5086: task edges-pos-ontonotes, batch 86 (5086): mcc: 0.6355, acc: 0.4607, precision: 0.8195, recall: 0.5015, f1: 0.6222, edges-pos-ontonotes_loss: 0.0362
09/16 07:04:32 AM: Update 5140: task edges-pos-ontonotes, batch 140 (5140): mcc: 0.6319, acc: 0.4569, precision: 0.8169, recall: 0.4976, f1: 0.6184, edges-pos-ontonotes_loss: 0.0364
09/16 07:04:42 AM: Update 5199: task edges-pos-ontonotes, batch 199 (5199): mcc: 0.6329, acc: 0.4583, precision: 0.8170, recall: 0.4991, f1: 0.6197, edges-pos-ontonotes_loss: 0.0363
09/16 07:04:52 AM: Update 5254: task edges-pos-ontonotes, batch 254 (5254): mcc: 0.6325, acc: 0.4580, precision: 0.8160, recall: 0.4991, f1: 0.6193, edges-pos-ontonotes_loss: 0.0364
09/16 07:05:02 AM: Update 5307: task edges-pos-ontonotes, batch 307 (5307): mcc: 0.6323, acc: 0.4578, precision: 0.8160, recall: 0.4989, f1: 0.6192, edges-pos-ontonotes_loss: 0.0364
09/16 07:05:12 AM: Update 5344: task edges-pos-ontonotes, batch 344 (5344): mcc: 0.6291, acc: 0.4539, precision: 0.8141, recall: 0.4950, f1: 0.6157, edges-pos-ontonotes_loss: 0.0366
09/16 07:05:22 AM: Update 5414: task edges-pos-ontonotes, batch 414 (5414): mcc: 0.6320, acc: 0.4571, precision: 0.8157, recall: 0.4985, f1: 0.6188, edges-pos-ontonotes_loss: 0.0360
09/16 07:05:32 AM: Update 5486: task edges-pos-ontonotes, batch 486 (5486): mcc: 0.6348, acc: 0.4605, precision: 0.8172, recall: 0.5019, f1: 0.6219, edges-pos-ontonotes_loss: 0.0355
09/16 07:05:42 AM: Update 5561: task edges-pos-ontonotes, batch 561 (5561): mcc: 0.6377, acc: 0.4637, precision: 0.8189, recall: 0.5053, f1: 0.6250, edges-pos-ontonotes_loss: 0.0351
09/16 07:05:52 AM: Update 5620: task edges-pos-ontonotes, batch 620 (5620): mcc: 0.6373, acc: 0.4634, precision: 0.8182, recall: 0.5052, f1: 0.6247, edges-pos-ontonotes_loss: 0.0350
09/16 07:06:02 AM: Update 5687: task edges-pos-ontonotes, batch 687 (5687): mcc: 0.6396, acc: 0.4661, precision: 0.8196, recall: 0.5080, f1: 0.6272, edges-pos-ontonotes_loss: 0.0346
09/16 07:06:12 AM: Update 5780: task edges-pos-ontonotes, batch 780 (5780): mcc: 0.6462, acc: 0.4738, precision: 0.8233, recall: 0.5160, f1: 0.6344, edges-pos-ontonotes_loss: 0.0339
09/16 07:06:22 AM: Update 5875: task edges-pos-ontonotes, batch 875 (5875): mcc: 0.6523, acc: 0.4809, precision: 0.8270, recall: 0.5232, f1: 0.6409, edges-pos-ontonotes_loss: 0.0333
09/16 07:06:34 AM: Update 5965: task edges-pos-ontonotes, batch 965 (5965): mcc: 0.6568, acc: 0.4863, precision: 0.8297, recall: 0.5286, f1: 0.6458, edges-pos-ontonotes_loss: 0.0329
09/16 07:06:37 AM: ***** Step 6000 / Validation 6 *****
09/16 07:06:37 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:06:37 AM: Validating...
09/16 07:06:44 AM: Evaluate: task edges-pos-ontonotes, batch 47 (157): mcc: 0.7183, acc: 0.5528, precision: 0.9221, recall: 0.5662, f1: 0.7016, edges-pos-ontonotes_loss: 0.0290
09/16 07:06:54 AM: Evaluate: task edges-pos-ontonotes, batch 107 (157): mcc: 0.7243, acc: 0.5608, precision: 0.9235, recall: 0.5746, f1: 0.7085, edges-pos-ontonotes_loss: 0.0282
09/16 07:07:04 AM: Evaluate: task edges-pos-ontonotes, batch 153 (157): mcc: 0.7116, acc: 0.5431, precision: 0.9200, recall: 0.5571, f1: 0.6940, edges-pos-ontonotes_loss: 0.0289
09/16 07:07:05 AM: Updating LR scheduler:
09/16 07:07:05 AM: 	Best result seen so far for macro_avg: 0.700
09/16 07:07:05 AM: 	# validation passes without improvement: 1
09/16 07:07:05 AM: edges-pos-ontonotes_loss: training: 0.032691 validation: 0.029036
09/16 07:07:05 AM: macro_avg: validation: 0.692676
09/16 07:07:05 AM: micro_avg: validation: 0.000000
09/16 07:07:05 AM: edges-pos-ontonotes_mcc: training: 0.658362 validation: 0.710553
09/16 07:07:05 AM: edges-pos-ontonotes_acc: training: 0.488228 validation: 0.541520
09/16 07:07:05 AM: edges-pos-ontonotes_precision: training: 0.830549 validation: 0.920140
09/16 07:07:05 AM: edges-pos-ontonotes_recall: training: 0.530479 validation: 0.555383
09/16 07:07:05 AM: edges-pos-ontonotes_f1: training: 0.647435 validation: 0.692676
09/16 07:07:05 AM: Global learning rate: 0.0001
09/16 07:07:05 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 07:07:14 AM: Update 6107: task edges-pos-ontonotes, batch 107 (6107): mcc: 0.7326, acc: 0.5854, precision: 0.8668, recall: 0.6270, f1: 0.7276, edges-pos-ontonotes_loss: 0.0268
09/16 07:07:24 AM: Update 6208: task edges-pos-ontonotes, batch 208 (6208): mcc: 0.7325, acc: 0.5839, precision: 0.8684, recall: 0.6256, f1: 0.7273, edges-pos-ontonotes_loss: 0.0269
09/16 07:07:34 AM: Update 6310: task edges-pos-ontonotes, batch 310 (6310): mcc: 0.7270, acc: 0.5762, precision: 0.8652, recall: 0.6187, f1: 0.7215, edges-pos-ontonotes_loss: 0.0271
09/16 07:07:44 AM: Update 6439: task edges-pos-ontonotes, batch 439 (6439): mcc: 0.7132, acc: 0.5587, precision: 0.8567, recall: 0.6017, f1: 0.7069, edges-pos-ontonotes_loss: 0.0278
09/16 07:07:54 AM: Update 6579: task edges-pos-ontonotes, batch 579 (6579): mcc: 0.7093, acc: 0.5539, precision: 0.8537, recall: 0.5974, f1: 0.7029, edges-pos-ontonotes_loss: 0.0279
09/16 07:08:04 AM: Update 6635: task edges-pos-ontonotes, batch 635 (6635): mcc: 0.6956, acc: 0.5366, precision: 0.8441, recall: 0.5815, f1: 0.6886, edges-pos-ontonotes_loss: 0.0286
09/16 07:08:14 AM: Update 6697: task edges-pos-ontonotes, batch 697 (6697): mcc: 0.6849, acc: 0.5231, precision: 0.8378, recall: 0.5684, f1: 0.6773, edges-pos-ontonotes_loss: 0.0294
09/16 07:08:24 AM: Update 6750: task edges-pos-ontonotes, batch 750 (6750): mcc: 0.6738, acc: 0.5092, precision: 0.8314, recall: 0.5547, f1: 0.6654, edges-pos-ontonotes_loss: 0.0300
09/16 07:08:35 AM: Update 6809: task edges-pos-ontonotes, batch 809 (6809): mcc: 0.6676, acc: 0.5016, precision: 0.8279, recall: 0.5471, f1: 0.6588, edges-pos-ontonotes_loss: 0.0305
09/16 07:08:45 AM: Update 6870: task edges-pos-ontonotes, batch 870 (6870): mcc: 0.6627, acc: 0.4956, precision: 0.8250, recall: 0.5410, f1: 0.6535, edges-pos-ontonotes_loss: 0.0309
09/16 07:08:55 AM: Update 6922: task edges-pos-ontonotes, batch 922 (6922): mcc: 0.6592, acc: 0.4912, precision: 0.8231, recall: 0.5367, f1: 0.6497, edges-pos-ontonotes_loss: 0.0313
09/16 07:09:03 AM: ***** Step 7000 / Validation 7 *****
09/16 07:09:03 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:09:03 AM: Validating...
09/16 07:09:05 AM: Evaluate: task edges-pos-ontonotes, batch 9 (157): mcc: 0.7498, acc: 0.6038, precision: 0.9050, recall: 0.6280, f1: 0.7415, edges-pos-ontonotes_loss: 0.0258
09/16 07:09:15 AM: Evaluate: task edges-pos-ontonotes, batch 79 (157): mcc: 0.7490, acc: 0.5977, precision: 0.9195, recall: 0.6166, f1: 0.7382, edges-pos-ontonotes_loss: 0.0259
09/16 07:09:25 AM: Evaluate: task edges-pos-ontonotes, batch 129 (157): mcc: 0.7319, acc: 0.5740, precision: 0.9130, recall: 0.5934, f1: 0.7193, edges-pos-ontonotes_loss: 0.0269
09/16 07:09:31 AM: Best result seen so far for edges-pos-ontonotes.
09/16 07:09:31 AM: Best result seen so far for macro.
09/16 07:09:31 AM: Updating LR scheduler:
09/16 07:09:31 AM: 	Best result seen so far for macro_avg: 0.713
09/16 07:09:31 AM: 	# validation passes without improvement: 0
09/16 07:09:31 AM: edges-pos-ontonotes_loss: training: 0.031285 validation: 0.027400
09/16 07:09:31 AM: macro_avg: validation: 0.712839
09/16 07:09:31 AM: micro_avg: validation: 0.000000
09/16 07:09:31 AM: edges-pos-ontonotes_mcc: training: 0.659042 validation: 0.726192
09/16 07:09:31 AM: edges-pos-ontonotes_acc: training: 0.490977 validation: 0.565372
09/16 07:09:31 AM: edges-pos-ontonotes_precision: training: 0.823482 validation: 0.911911
09/16 07:09:31 AM: edges-pos-ontonotes_recall: training: 0.536234 validation: 0.585109
09/16 07:09:31 AM: edges-pos-ontonotes_f1: training: 0.649517 validation: 0.712839
09/16 07:09:31 AM: Global learning rate: 0.0001
09/16 07:09:31 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 07:09:35 AM: Update 7038: task edges-pos-ontonotes, batch 38 (7038): mcc: 0.6718, acc: 0.5051, precision: 0.8341, recall: 0.5497, f1: 0.6627, edges-pos-ontonotes_loss: 0.0305
09/16 07:09:45 AM: Update 7133: task edges-pos-ontonotes, batch 133 (7133): mcc: 0.6720, acc: 0.5067, precision: 0.8341, recall: 0.5500, f1: 0.6629, edges-pos-ontonotes_loss: 0.0300
09/16 07:09:56 AM: Update 7227: task edges-pos-ontonotes, batch 227 (7227): mcc: 0.6751, acc: 0.5104, precision: 0.8355, recall: 0.5541, f1: 0.6663, edges-pos-ontonotes_loss: 0.0299
09/16 07:10:06 AM: Update 7287: task edges-pos-ontonotes, batch 287 (7287): mcc: 0.6697, acc: 0.5040, precision: 0.8297, recall: 0.5492, f1: 0.6609, edges-pos-ontonotes_loss: 0.0305
09/16 07:10:16 AM: Update 7356: task edges-pos-ontonotes, batch 356 (7356): mcc: 0.6681, acc: 0.5018, precision: 0.8290, recall: 0.5472, f1: 0.6593, edges-pos-ontonotes_loss: 0.0307
09/16 07:10:26 AM: Update 7431: task edges-pos-ontonotes, batch 431 (7431): mcc: 0.6680, acc: 0.5021, precision: 0.8263, recall: 0.5488, f1: 0.6595, edges-pos-ontonotes_loss: 0.0309
09/16 07:10:36 AM: Update 7503: task edges-pos-ontonotes, batch 503 (7503): mcc: 0.6684, acc: 0.5027, precision: 0.8255, recall: 0.5500, f1: 0.6602, edges-pos-ontonotes_loss: 0.0310
09/16 07:10:52 AM: Update 7547: task edges-pos-ontonotes, batch 547 (7547): mcc: 0.6682, acc: 0.5029, precision: 0.8252, recall: 0.5499, f1: 0.6600, edges-pos-ontonotes_loss: 0.0310
09/16 07:11:02 AM: Update 7599: task edges-pos-ontonotes, batch 599 (7599): mcc: 0.6612, acc: 0.4948, precision: 0.8203, recall: 0.5418, f1: 0.6526, edges-pos-ontonotes_loss: 0.0315
09/16 07:11:12 AM: Update 7657: task edges-pos-ontonotes, batch 657 (7657): mcc: 0.6577, acc: 0.4906, precision: 0.8181, recall: 0.5377, f1: 0.6489, edges-pos-ontonotes_loss: 0.0319
09/16 07:11:23 AM: Update 7715: task edges-pos-ontonotes, batch 715 (7715): mcc: 0.6554, acc: 0.4879, precision: 0.8165, recall: 0.5350, f1: 0.6464, edges-pos-ontonotes_loss: 0.0322
09/16 07:11:33 AM: Update 7782: task edges-pos-ontonotes, batch 782 (7782): mcc: 0.6554, acc: 0.4880, precision: 0.8163, recall: 0.5352, f1: 0.6465, edges-pos-ontonotes_loss: 0.0324
09/16 07:11:43 AM: Update 7838: task edges-pos-ontonotes, batch 838 (7838): mcc: 0.6534, acc: 0.4856, precision: 0.8150, recall: 0.5328, f1: 0.6443, edges-pos-ontonotes_loss: 0.0326
09/16 07:11:53 AM: Update 7880: task edges-pos-ontonotes, batch 880 (7880): mcc: 0.6519, acc: 0.4839, precision: 0.8138, recall: 0.5312, f1: 0.6428, edges-pos-ontonotes_loss: 0.0328
09/16 07:12:03 AM: Update 7935: task edges-pos-ontonotes, batch 935 (7935): mcc: 0.6507, acc: 0.4826, precision: 0.8129, recall: 0.5300, f1: 0.6416, edges-pos-ontonotes_loss: 0.0330
09/16 07:12:13 AM: Update 7988: task edges-pos-ontonotes, batch 988 (7988): mcc: 0.6501, acc: 0.4817, precision: 0.8125, recall: 0.5292, f1: 0.6409, edges-pos-ontonotes_loss: 0.0331
09/16 07:12:15 AM: ***** Step 8000 / Validation 8 *****
09/16 07:12:15 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:12:15 AM: Validating...
09/16 07:12:23 AM: Evaluate: task edges-pos-ontonotes, batch 57 (157): mcc: 0.7458, acc: 0.5937, precision: 0.9157, recall: 0.6141, f1: 0.7352, edges-pos-ontonotes_loss: 0.0263
09/16 07:12:33 AM: Evaluate: task edges-pos-ontonotes, batch 113 (157): mcc: 0.7463, acc: 0.5945, precision: 0.9159, recall: 0.6147, f1: 0.7357, edges-pos-ontonotes_loss: 0.0261
09/16 07:12:43 AM: Best result seen so far for edges-pos-ontonotes.
09/16 07:12:43 AM: Best result seen so far for macro.
09/16 07:12:43 AM: Updating LR scheduler:
09/16 07:12:43 AM: 	Best result seen so far for macro_avg: 0.726
09/16 07:12:43 AM: 	# validation passes without improvement: 0
09/16 07:12:43 AM: edges-pos-ontonotes_loss: training: 0.033140 validation: 0.026506
09/16 07:12:43 AM: macro_avg: validation: 0.726236
09/16 07:12:43 AM: micro_avg: validation: 0.000000
09/16 07:12:43 AM: edges-pos-ontonotes_mcc: training: 0.650201 validation: 0.738060
09/16 07:12:43 AM: edges-pos-ontonotes_acc: training: 0.481843 validation: 0.582770
09/16 07:12:43 AM: edges-pos-ontonotes_precision: training: 0.812626 validation: 0.915041
09/16 07:12:43 AM: edges-pos-ontonotes_recall: training: 0.529281 validation: 0.602019
09/16 07:12:43 AM: edges-pos-ontonotes_f1: training: 0.641039 validation: 0.726236
09/16 07:12:43 AM: Global learning rate: 0.0001
09/16 07:12:43 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 07:12:43 AM: Update 8003: task edges-pos-ontonotes, batch 3 (8003): mcc: 0.6394, acc: 0.4700, precision: 0.8026, recall: 0.5186, f1: 0.6301, edges-pos-ontonotes_loss: 0.0372
09/16 07:12:53 AM: Update 8061: task edges-pos-ontonotes, batch 61 (8061): mcc: 0.6467, acc: 0.4777, precision: 0.8088, recall: 0.5261, f1: 0.6375, edges-pos-ontonotes_loss: 0.0349
09/16 07:13:03 AM: Update 8114: task edges-pos-ontonotes, batch 114 (8114): mcc: 0.6459, acc: 0.4771, precision: 0.8079, recall: 0.5255, f1: 0.6368, edges-pos-ontonotes_loss: 0.0351
09/16 07:13:14 AM: Update 8170: task edges-pos-ontonotes, batch 170 (8170): mcc: 0.6443, acc: 0.4754, precision: 0.8070, recall: 0.5235, f1: 0.6351, edges-pos-ontonotes_loss: 0.0350
09/16 07:13:24 AM: Update 8211: task edges-pos-ontonotes, batch 211 (8211): mcc: 0.6427, acc: 0.4733, precision: 0.8071, recall: 0.5209, f1: 0.6332, edges-pos-ontonotes_loss: 0.0352
09/16 07:13:34 AM: Update 8267: task edges-pos-ontonotes, batch 267 (8267): mcc: 0.6442, acc: 0.4751, precision: 0.8079, recall: 0.5227, f1: 0.6348, edges-pos-ontonotes_loss: 0.0351
09/16 07:13:44 AM: Update 8324: task edges-pos-ontonotes, batch 324 (8324): mcc: 0.6453, acc: 0.4765, precision: 0.8086, recall: 0.5242, f1: 0.6360, edges-pos-ontonotes_loss: 0.0351
09/16 07:13:54 AM: Update 8384: task edges-pos-ontonotes, batch 384 (8384): mcc: 0.6468, acc: 0.4783, precision: 0.8100, recall: 0.5257, f1: 0.6376, edges-pos-ontonotes_loss: 0.0348
09/16 07:14:04 AM: Update 8440: task edges-pos-ontonotes, batch 440 (8440): mcc: 0.6479, acc: 0.4795, precision: 0.8109, recall: 0.5267, f1: 0.6386, edges-pos-ontonotes_loss: 0.0348
09/16 07:14:15 AM: Update 8487: task edges-pos-ontonotes, batch 487 (8487): mcc: 0.6486, acc: 0.4802, precision: 0.8116, recall: 0.5274, f1: 0.6393, edges-pos-ontonotes_loss: 0.0348
09/16 07:14:25 AM: Update 8540: task edges-pos-ontonotes, batch 540 (8540): mcc: 0.6488, acc: 0.4804, precision: 0.8116, recall: 0.5278, f1: 0.6396, edges-pos-ontonotes_loss: 0.0348
09/16 07:14:35 AM: Update 8598: task edges-pos-ontonotes, batch 598 (8598): mcc: 0.6494, acc: 0.4813, precision: 0.8116, recall: 0.5287, f1: 0.6403, edges-pos-ontonotes_loss: 0.0348
09/16 07:14:45 AM: Update 8652: task edges-pos-ontonotes, batch 652 (8652): mcc: 0.6503, acc: 0.4823, precision: 0.8120, recall: 0.5299, f1: 0.6413, edges-pos-ontonotes_loss: 0.0347
09/16 07:14:55 AM: Update 8711: task edges-pos-ontonotes, batch 711 (8711): mcc: 0.6517, acc: 0.4839, precision: 0.8124, recall: 0.5318, f1: 0.6428, edges-pos-ontonotes_loss: 0.0346
09/16 07:15:05 AM: Update 8768: task edges-pos-ontonotes, batch 768 (8768): mcc: 0.6522, acc: 0.4845, precision: 0.8129, recall: 0.5323, f1: 0.6433, edges-pos-ontonotes_loss: 0.0346
09/16 07:15:15 AM: Update 8812: task edges-pos-ontonotes, batch 812 (8812): mcc: 0.6513, acc: 0.4834, precision: 0.8126, recall: 0.5310, f1: 0.6423, edges-pos-ontonotes_loss: 0.0345
09/16 07:15:25 AM: Update 8874: task edges-pos-ontonotes, batch 874 (8874): mcc: 0.6516, acc: 0.4838, precision: 0.8130, recall: 0.5313, f1: 0.6427, edges-pos-ontonotes_loss: 0.0344
09/16 07:15:36 AM: Update 8945: task edges-pos-ontonotes, batch 945 (8945): mcc: 0.6530, acc: 0.4854, precision: 0.8139, recall: 0.5330, f1: 0.6442, edges-pos-ontonotes_loss: 0.0341
09/16 07:15:44 AM: ***** Step 9000 / Validation 9 *****
09/16 07:15:44 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:15:44 AM: Validating...
09/16 07:15:46 AM: Evaluate: task edges-pos-ontonotes, batch 9 (157): mcc: 0.7577, acc: 0.6154, precision: 0.9160, recall: 0.6333, f1: 0.7488, edges-pos-ontonotes_loss: 0.0249
09/16 07:15:56 AM: Evaluate: task edges-pos-ontonotes, batch 78 (157): mcc: 0.7480, acc: 0.5963, precision: 0.9224, recall: 0.6131, f1: 0.7366, edges-pos-ontonotes_loss: 0.0259
09/16 07:16:06 AM: Evaluate: task edges-pos-ontonotes, batch 128 (157): mcc: 0.7411, acc: 0.5877, precision: 0.9174, recall: 0.6054, f1: 0.7294, edges-pos-ontonotes_loss: 0.0261
09/16 07:16:12 AM: Best result seen so far for edges-pos-ontonotes.
09/16 07:16:12 AM: Best result seen so far for macro.
09/16 07:16:12 AM: Updating LR scheduler:
09/16 07:16:12 AM: 	Best result seen so far for macro_avg: 0.727
09/16 07:16:12 AM: 	# validation passes without improvement: 0
09/16 07:16:12 AM: edges-pos-ontonotes_loss: training: 0.033898 validation: 0.026249
09/16 07:16:12 AM: macro_avg: validation: 0.727260
09/16 07:16:12 AM: micro_avg: validation: 0.000000
09/16 07:16:12 AM: edges-pos-ontonotes_mcc: training: 0.653576 validation: 0.739292
09/16 07:16:12 AM: edges-pos-ontonotes_acc: training: 0.486071 validation: 0.584347
09/16 07:16:12 AM: edges-pos-ontonotes_precision: training: 0.814150 validation: 0.917462
09/16 07:16:12 AM: edges-pos-ontonotes_recall: training: 0.533689 validation: 0.602379
09/16 07:16:12 AM: edges-pos-ontonotes_f1: training: 0.644740 validation: 0.727260
09/16 07:16:12 AM: Global learning rate: 0.0001
09/16 07:16:12 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 07:16:16 AM: Update 9028: task edges-pos-ontonotes, batch 28 (9028): mcc: 0.6756, acc: 0.5101, precision: 0.8237, recall: 0.5629, f1: 0.6688, edges-pos-ontonotes_loss: 0.0309
09/16 07:16:26 AM: Update 9102: task edges-pos-ontonotes, batch 102 (9102): mcc: 0.6755, acc: 0.5123, precision: 0.8221, recall: 0.5639, f1: 0.6689, edges-pos-ontonotes_loss: 0.0301
09/16 07:16:37 AM: Update 9112: task edges-pos-ontonotes, batch 112 (9112): mcc: 0.6743, acc: 0.5109, precision: 0.8222, recall: 0.5619, f1: 0.6676, edges-pos-ontonotes_loss: 0.0303
09/16 07:16:47 AM: Update 9191: task edges-pos-ontonotes, batch 191 (9191): mcc: 0.6959, acc: 0.5366, precision: 0.8351, recall: 0.5886, f1: 0.6905, edges-pos-ontonotes_loss: 0.0288
09/16 07:16:57 AM: Update 9287: task edges-pos-ontonotes, batch 287 (9287): mcc: 0.7091, acc: 0.5526, precision: 0.8428, recall: 0.6050, f1: 0.7043, edges-pos-ontonotes_loss: 0.0280
09/16 07:17:07 AM: Update 9377: task edges-pos-ontonotes, batch 377 (9377): mcc: 0.7163, acc: 0.5615, precision: 0.8476, recall: 0.6136, f1: 0.7118, edges-pos-ontonotes_loss: 0.0276
09/16 07:17:17 AM: Update 9455: task edges-pos-ontonotes, batch 455 (9455): mcc: 0.7186, acc: 0.5645, precision: 0.8491, recall: 0.6163, f1: 0.7142, edges-pos-ontonotes_loss: 0.0274
09/16 07:17:27 AM: Update 9559: task edges-pos-ontonotes, batch 559 (9559): mcc: 0.7233, acc: 0.5709, precision: 0.8521, recall: 0.6221, f1: 0.7192, edges-pos-ontonotes_loss: 0.0271
09/16 07:17:37 AM: Update 9679: task edges-pos-ontonotes, batch 679 (9679): mcc: 0.7279, acc: 0.5772, precision: 0.8546, recall: 0.6280, f1: 0.7240, edges-pos-ontonotes_loss: 0.0266
09/16 07:17:47 AM: Update 9772: task edges-pos-ontonotes, batch 772 (9772): mcc: 0.7268, acc: 0.5762, precision: 0.8541, recall: 0.6266, f1: 0.7229, edges-pos-ontonotes_loss: 0.0266
09/16 07:17:57 AM: Update 9910: task edges-pos-ontonotes, batch 910 (9910): mcc: 0.7251, acc: 0.5743, precision: 0.8526, recall: 0.6247, f1: 0.7211, edges-pos-ontonotes_loss: 0.0267
09/16 07:18:04 AM: ***** Step 10000 / Validation 10 *****
09/16 07:18:04 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:18:04 AM: Validating...
09/16 07:18:07 AM: Evaluate: task edges-pos-ontonotes, batch 25 (157): mcc: 0.7483, acc: 0.6013, precision: 0.9053, recall: 0.6254, f1: 0.7397, edges-pos-ontonotes_loss: 0.0259
09/16 07:18:18 AM: Evaluate: task edges-pos-ontonotes, batch 91 (157): mcc: 0.7594, acc: 0.6161, precision: 0.9112, recall: 0.6395, f1: 0.7515, edges-pos-ontonotes_loss: 0.0248
09/16 07:18:28 AM: Evaluate: task edges-pos-ontonotes, batch 136 (157): mcc: 0.7392, acc: 0.5874, precision: 0.8994, recall: 0.6145, f1: 0.7302, edges-pos-ontonotes_loss: 0.0261
09/16 07:18:32 AM: Best result seen so far for edges-pos-ontonotes.
09/16 07:18:32 AM: Best result seen so far for macro.
09/16 07:18:32 AM: Updating LR scheduler:
09/16 07:18:32 AM: 	Best result seen so far for macro_avg: 0.728
09/16 07:18:32 AM: 	# validation passes without improvement: 0
09/16 07:18:32 AM: edges-pos-ontonotes_loss: training: 0.026628 validation: 0.026309
09/16 07:18:32 AM: macro_avg: validation: 0.727754
09/16 07:18:32 AM: micro_avg: validation: 0.000000
09/16 07:18:32 AM: edges-pos-ontonotes_mcc: training: 0.724305 validation: 0.737098
09/16 07:18:32 AM: edges-pos-ontonotes_acc: training: 0.573307 validation: 0.583839
09/16 07:18:32 AM: edges-pos-ontonotes_precision: training: 0.852007 validation: 0.899340
09/16 07:18:32 AM: edges-pos-ontonotes_recall: training: 0.623854 validation: 0.611152
09/16 07:18:32 AM: edges-pos-ontonotes_f1: training: 0.720296 validation: 0.727754
09/16 07:18:32 AM: Global learning rate: 0.0001
09/16 07:18:32 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 07:18:40 AM: Update 10051: task edges-pos-ontonotes, batch 51 (10051): mcc: 0.6667, acc: 0.5049, precision: 0.8160, recall: 0.5537, f1: 0.6597, edges-pos-ontonotes_loss: 0.0289
09/16 07:18:50 AM: Update 10102: task edges-pos-ontonotes, batch 102 (10102): mcc: 0.6367, acc: 0.4669, precision: 0.7931, recall: 0.5207, f1: 0.6287, edges-pos-ontonotes_loss: 0.0327
09/16 07:19:00 AM: Update 10163: task edges-pos-ontonotes, batch 163 (10163): mcc: 0.6381, acc: 0.4679, precision: 0.7963, recall: 0.5207, f1: 0.6297, edges-pos-ontonotes_loss: 0.0336
09/16 07:19:10 AM: Update 10224: task edges-pos-ontonotes, batch 224 (10224): mcc: 0.6374, acc: 0.4671, precision: 0.7962, recall: 0.5197, f1: 0.6289, edges-pos-ontonotes_loss: 0.0341
09/16 07:19:20 AM: Update 10284: task edges-pos-ontonotes, batch 284 (10284): mcc: 0.6385, acc: 0.4679, precision: 0.7971, recall: 0.5209, f1: 0.6301, edges-pos-ontonotes_loss: 0.0343
09/16 07:19:30 AM: Update 10344: task edges-pos-ontonotes, batch 344 (10344): mcc: 0.6393, acc: 0.4689, precision: 0.7978, recall: 0.5217, f1: 0.6309, edges-pos-ontonotes_loss: 0.0344
09/16 07:19:40 AM: Update 10382: task edges-pos-ontonotes, batch 382 (10382): mcc: 0.6386, acc: 0.4679, precision: 0.7982, recall: 0.5203, f1: 0.6300, edges-pos-ontonotes_loss: 0.0346
09/16 07:19:50 AM: Update 10452: task edges-pos-ontonotes, batch 452 (10452): mcc: 0.6439, acc: 0.4741, precision: 0.8021, recall: 0.5261, f1: 0.6354, edges-pos-ontonotes_loss: 0.0338
09/16 07:20:00 AM: Update 10515: task edges-pos-ontonotes, batch 515 (10515): mcc: 0.6477, acc: 0.4787, precision: 0.8050, recall: 0.5304, f1: 0.6394, edges-pos-ontonotes_loss: 0.0333
09/16 07:20:11 AM: Update 10581: task edges-pos-ontonotes, batch 581 (10581): mcc: 0.6504, acc: 0.4821, precision: 0.8071, recall: 0.5332, f1: 0.6422, edges-pos-ontonotes_loss: 0.0329
09/16 07:20:21 AM: Update 10647: task edges-pos-ontonotes, batch 647 (10647): mcc: 0.6525, acc: 0.4845, precision: 0.8089, recall: 0.5355, f1: 0.6444, edges-pos-ontonotes_loss: 0.0325
09/16 07:20:31 AM: Update 10703: task edges-pos-ontonotes, batch 703 (10703): mcc: 0.6540, acc: 0.4865, precision: 0.8100, recall: 0.5372, f1: 0.6460, edges-pos-ontonotes_loss: 0.0321
09/16 07:20:41 AM: Update 10756: task edges-pos-ontonotes, batch 756 (10756): mcc: 0.6553, acc: 0.4881, precision: 0.8104, recall: 0.5391, f1: 0.6475, edges-pos-ontonotes_loss: 0.0320
09/16 07:20:51 AM: Update 10809: task edges-pos-ontonotes, batch 809 (10809): mcc: 0.6566, acc: 0.4897, precision: 0.8109, recall: 0.5408, f1: 0.6489, edges-pos-ontonotes_loss: 0.0320
09/16 07:21:01 AM: Update 10868: task edges-pos-ontonotes, batch 868 (10868): mcc: 0.6586, acc: 0.4921, precision: 0.8117, recall: 0.5435, f1: 0.6510, edges-pos-ontonotes_loss: 0.0318
09/16 07:21:12 AM: Update 10920: task edges-pos-ontonotes, batch 920 (10920): mcc: 0.6599, acc: 0.4938, precision: 0.8122, recall: 0.5453, f1: 0.6525, edges-pos-ontonotes_loss: 0.0317
09/16 07:21:22 AM: Update 10972: task edges-pos-ontonotes, batch 972 (10972): mcc: 0.6607, acc: 0.4949, precision: 0.8126, recall: 0.5464, f1: 0.6534, edges-pos-ontonotes_loss: 0.0316
09/16 07:21:27 AM: ***** Step 11000 / Validation 11 *****
09/16 07:21:27 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:21:27 AM: Validating...
09/16 07:21:32 AM: Evaluate: task edges-pos-ontonotes, batch 29 (157): mcc: 0.7646, acc: 0.6242, precision: 0.9133, recall: 0.6467, f1: 0.7572, edges-pos-ontonotes_loss: 0.0241
09/16 07:21:42 AM: Evaluate: task edges-pos-ontonotes, batch 85 (157): mcc: 0.7735, acc: 0.6354, precision: 0.9169, recall: 0.6589, f1: 0.7668, edges-pos-ontonotes_loss: 0.0235
09/16 07:21:52 AM: Evaluate: task edges-pos-ontonotes, batch 126 (157): mcc: 0.7613, acc: 0.6186, precision: 0.9120, recall: 0.6422, f1: 0.7537, edges-pos-ontonotes_loss: 0.0243
09/16 07:22:00 AM: Best result seen so far for edges-pos-ontonotes.
09/16 07:22:00 AM: Best result seen so far for macro.
09/16 07:22:00 AM: Updating LR scheduler:
09/16 07:22:00 AM: 	Best result seen so far for macro_avg: 0.746
09/16 07:22:00 AM: 	# validation passes without improvement: 0
09/16 07:22:00 AM: edges-pos-ontonotes_loss: training: 0.031612 validation: 0.024819
09/16 07:22:00 AM: macro_avg: validation: 0.745685
09/16 07:22:00 AM: micro_avg: validation: 0.000000
09/16 07:22:00 AM: edges-pos-ontonotes_mcc: training: 0.661626 validation: 0.754174
09/16 07:22:00 AM: edges-pos-ontonotes_acc: training: 0.496026 validation: 0.607596
09/16 07:22:00 AM: edges-pos-ontonotes_precision: training: 0.812993 validation: 0.910538
09/16 07:22:00 AM: edges-pos-ontonotes_recall: training: 0.547528 validation: 0.631375
09/16 07:22:00 AM: edges-pos-ontonotes_f1: training: 0.654362 validation: 0.745685
09/16 07:22:00 AM: Global learning rate: 0.0001
09/16 07:22:00 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 07:22:03 AM: Update 11007: task edges-pos-ontonotes, batch 7 (11007): mcc: 0.6425, acc: 0.4787, precision: 0.7976, recall: 0.5270, f1: 0.6347, edges-pos-ontonotes_loss: 0.0321
09/16 07:22:13 AM: Update 11052: task edges-pos-ontonotes, batch 52 (11052): mcc: 0.6458, acc: 0.4792, precision: 0.7983, recall: 0.5319, f1: 0.6384, edges-pos-ontonotes_loss: 0.0346
09/16 07:22:23 AM: Update 11096: task edges-pos-ontonotes, batch 96 (11096): mcc: 0.6448, acc: 0.4773, precision: 0.7978, recall: 0.5305, f1: 0.6373, edges-pos-ontonotes_loss: 0.0350
09/16 07:22:33 AM: Update 11138: task edges-pos-ontonotes, batch 138 (11138): mcc: 0.6449, acc: 0.4769, precision: 0.7988, recall: 0.5300, f1: 0.6372, edges-pos-ontonotes_loss: 0.0350
09/16 07:22:43 AM: Update 11181: task edges-pos-ontonotes, batch 181 (11181): mcc: 0.6459, acc: 0.4780, precision: 0.8004, recall: 0.5306, f1: 0.6381, edges-pos-ontonotes_loss: 0.0349
09/16 07:22:53 AM: Update 11226: task edges-pos-ontonotes, batch 226 (11226): mcc: 0.6467, acc: 0.4794, precision: 0.7998, recall: 0.5323, f1: 0.6392, edges-pos-ontonotes_loss: 0.0346
09/16 07:23:03 AM: Update 11270: task edges-pos-ontonotes, batch 270 (11270): mcc: 0.6464, acc: 0.4787, precision: 0.8004, recall: 0.5314, f1: 0.6387, edges-pos-ontonotes_loss: 0.0345
09/16 07:23:14 AM: Update 11317: task edges-pos-ontonotes, batch 317 (11317): mcc: 0.6472, acc: 0.4795, precision: 0.8017, recall: 0.5318, f1: 0.6395, edges-pos-ontonotes_loss: 0.0344
09/16 07:23:25 AM: Update 11320: task edges-pos-ontonotes, batch 320 (11320): mcc: 0.6467, acc: 0.4789, precision: 0.8013, recall: 0.5313, f1: 0.6390, edges-pos-ontonotes_loss: 0.0344
09/16 07:23:35 AM: Update 11364: task edges-pos-ontonotes, batch 364 (11364): mcc: 0.6476, acc: 0.4800, precision: 0.8015, recall: 0.5327, f1: 0.6400, edges-pos-ontonotes_loss: 0.0344
09/16 07:23:45 AM: Update 11407: task edges-pos-ontonotes, batch 407 (11407): mcc: 0.6485, acc: 0.4809, precision: 0.8024, recall: 0.5334, f1: 0.6408, edges-pos-ontonotes_loss: 0.0343
09/16 07:23:55 AM: Update 11447: task edges-pos-ontonotes, batch 447 (11447): mcc: 0.6484, acc: 0.4808, precision: 0.8027, recall: 0.5331, f1: 0.6407, edges-pos-ontonotes_loss: 0.0344
09/16 07:24:05 AM: Update 11489: task edges-pos-ontonotes, batch 489 (11489): mcc: 0.6483, acc: 0.4807, precision: 0.8027, recall: 0.5329, f1: 0.6405, edges-pos-ontonotes_loss: 0.0344
09/16 07:24:15 AM: Update 11533: task edges-pos-ontonotes, batch 533 (11533): mcc: 0.6492, acc: 0.4818, precision: 0.8033, recall: 0.5339, f1: 0.6415, edges-pos-ontonotes_loss: 0.0344
09/16 07:24:25 AM: Update 11575: task edges-pos-ontonotes, batch 575 (11575): mcc: 0.6493, acc: 0.4820, precision: 0.8033, recall: 0.5341, f1: 0.6416, edges-pos-ontonotes_loss: 0.0344
09/16 07:24:35 AM: Update 11615: task edges-pos-ontonotes, batch 615 (11615): mcc: 0.6499, acc: 0.4827, precision: 0.8038, recall: 0.5348, f1: 0.6422, edges-pos-ontonotes_loss: 0.0344
09/16 07:24:46 AM: Update 11652: task edges-pos-ontonotes, batch 652 (11652): mcc: 0.6502, acc: 0.4829, precision: 0.8039, recall: 0.5352, f1: 0.6426, edges-pos-ontonotes_loss: 0.0343
09/16 07:24:56 AM: Update 11710: task edges-pos-ontonotes, batch 710 (11710): mcc: 0.6510, acc: 0.4840, precision: 0.8045, recall: 0.5360, f1: 0.6434, edges-pos-ontonotes_loss: 0.0343
09/16 07:25:06 AM: Update 11768: task edges-pos-ontonotes, batch 768 (11768): mcc: 0.6522, acc: 0.4855, precision: 0.8054, recall: 0.5373, f1: 0.6446, edges-pos-ontonotes_loss: 0.0342
09/16 07:25:16 AM: Update 11825: task edges-pos-ontonotes, batch 825 (11825): mcc: 0.6531, acc: 0.4867, precision: 0.8060, recall: 0.5384, f1: 0.6456, edges-pos-ontonotes_loss: 0.0341
09/16 07:25:26 AM: Update 11876: task edges-pos-ontonotes, batch 876 (11876): mcc: 0.6534, acc: 0.4870, precision: 0.8063, recall: 0.5387, f1: 0.6459, edges-pos-ontonotes_loss: 0.0342
09/16 07:25:36 AM: Update 11929: task edges-pos-ontonotes, batch 929 (11929): mcc: 0.6540, acc: 0.4877, precision: 0.8068, recall: 0.5394, f1: 0.6465, edges-pos-ontonotes_loss: 0.0341
09/16 07:25:46 AM: Update 11970: task edges-pos-ontonotes, batch 970 (11970): mcc: 0.6542, acc: 0.4879, precision: 0.8071, recall: 0.5396, f1: 0.6467, edges-pos-ontonotes_loss: 0.0341
09/16 07:25:51 AM: ***** Step 12000 / Validation 12 *****
09/16 07:25:51 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:25:51 AM: Validating...
09/16 07:25:56 AM: Evaluate: task edges-pos-ontonotes, batch 30 (157): mcc: 0.7583, acc: 0.6137, precision: 0.9111, recall: 0.6378, f1: 0.7503, edges-pos-ontonotes_loss: 0.0252
09/16 07:26:06 AM: Evaluate: task edges-pos-ontonotes, batch 95 (157): mcc: 0.7638, acc: 0.6213, precision: 0.9123, recall: 0.6460, f1: 0.7564, edges-pos-ontonotes_loss: 0.0247
09/16 07:26:16 AM: Evaluate: task edges-pos-ontonotes, batch 142 (157): mcc: 0.7555, acc: 0.6098, precision: 0.9096, recall: 0.6342, f1: 0.7473, edges-pos-ontonotes_loss: 0.0250
09/16 07:26:19 AM: Best result seen so far for edges-pos-ontonotes.
09/16 07:26:19 AM: Best result seen so far for macro.
09/16 07:26:19 AM: Updating LR scheduler:
09/16 07:26:19 AM: 	Best result seen so far for macro_avg: 0.749
09/16 07:26:19 AM: 	# validation passes without improvement: 0
09/16 07:26:19 AM: edges-pos-ontonotes_loss: training: 0.034062 validation: 0.024981
09/16 07:26:19 AM: macro_avg: validation: 0.748586
09/16 07:26:19 AM: micro_avg: validation: 0.000000
09/16 07:26:19 AM: edges-pos-ontonotes_mcc: training: 0.654554 validation: 0.756862
09/16 07:26:19 AM: edges-pos-ontonotes_acc: training: 0.488318 validation: 0.611109
09/16 07:26:19 AM: edges-pos-ontonotes_precision: training: 0.807176 validation: 0.911758
09/16 07:26:19 AM: edges-pos-ontonotes_recall: training: 0.540003 validation: 0.634951
09/16 07:26:19 AM: edges-pos-ontonotes_f1: training: 0.647096 validation: 0.748586
09/16 07:26:19 AM: Global learning rate: 0.0001
09/16 07:26:19 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 07:26:26 AM: Update 12038: task edges-pos-ontonotes, batch 38 (12038): mcc: 0.6678, acc: 0.5054, precision: 0.8150, recall: 0.5562, f1: 0.6612, edges-pos-ontonotes_loss: 0.0329
09/16 07:26:36 AM: Update 12095: task edges-pos-ontonotes, batch 95 (12095): mcc: 0.6681, acc: 0.5057, precision: 0.8170, recall: 0.5553, f1: 0.6612, edges-pos-ontonotes_loss: 0.0336
09/16 07:26:46 AM: Update 12152: task edges-pos-ontonotes, batch 152 (12152): mcc: 0.6686, acc: 0.5062, precision: 0.8171, recall: 0.5561, f1: 0.6618, edges-pos-ontonotes_loss: 0.0333
09/16 07:26:56 AM: Update 12212: task edges-pos-ontonotes, batch 212 (12212): mcc: 0.6701, acc: 0.5081, precision: 0.8179, recall: 0.5580, f1: 0.6634, edges-pos-ontonotes_loss: 0.0331
09/16 07:27:07 AM: Update 12259: task edges-pos-ontonotes, batch 259 (12259): mcc: 0.6678, acc: 0.5053, precision: 0.8161, recall: 0.5554, f1: 0.6610, edges-pos-ontonotes_loss: 0.0333
09/16 07:27:17 AM: Update 12321: task edges-pos-ontonotes, batch 321 (12321): mcc: 0.6665, acc: 0.5032, precision: 0.8163, recall: 0.5532, f1: 0.6595, edges-pos-ontonotes_loss: 0.0328
09/16 07:27:28 AM: Update 12397: task edges-pos-ontonotes, batch 397 (12397): mcc: 0.6709, acc: 0.5080, precision: 0.8189, recall: 0.5585, f1: 0.6641, edges-pos-ontonotes_loss: 0.0321
09/16 07:27:38 AM: Update 12467: task edges-pos-ontonotes, batch 467 (12467): mcc: 0.6714, acc: 0.5085, precision: 0.8190, recall: 0.5594, f1: 0.6648, edges-pos-ontonotes_loss: 0.0317
09/16 07:27:48 AM: Update 12530: task edges-pos-ontonotes, batch 530 (12530): mcc: 0.6713, acc: 0.5084, precision: 0.8189, recall: 0.5593, f1: 0.6646, edges-pos-ontonotes_loss: 0.0315
09/16 07:27:58 AM: Update 12590: task edges-pos-ontonotes, batch 590 (12590): mcc: 0.6726, acc: 0.5099, precision: 0.8193, recall: 0.5611, f1: 0.6660, edges-pos-ontonotes_loss: 0.0313
09/16 07:28:08 AM: Update 12687: task edges-pos-ontonotes, batch 687 (12687): mcc: 0.6801, acc: 0.5187, precision: 0.8235, recall: 0.5705, f1: 0.6741, edges-pos-ontonotes_loss: 0.0305
09/16 07:28:18 AM: Update 12772: task edges-pos-ontonotes, batch 772 (12772): mcc: 0.6857, acc: 0.5253, precision: 0.8270, recall: 0.5774, f1: 0.6800, edges-pos-ontonotes_loss: 0.0300
09/16 07:28:28 AM: Update 12866: task edges-pos-ontonotes, batch 866 (12866): mcc: 0.6911, acc: 0.5320, precision: 0.8300, recall: 0.5842, f1: 0.6857, edges-pos-ontonotes_loss: 0.0295
09/16 07:28:38 AM: Update 12959: task edges-pos-ontonotes, batch 959 (12959): mcc: 0.6945, acc: 0.5363, precision: 0.8322, recall: 0.5883, f1: 0.6893, edges-pos-ontonotes_loss: 0.0290
09/16 07:28:42 AM: ***** Step 13000 / Validation 13 *****
09/16 07:28:42 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:28:42 AM: Validating...
09/16 07:28:48 AM: Evaluate: task edges-pos-ontonotes, batch 43 (157): mcc: 0.7531, acc: 0.6032, precision: 0.9238, recall: 0.6203, f1: 0.7423, edges-pos-ontonotes_loss: 0.0249
09/16 07:28:58 AM: Evaluate: task edges-pos-ontonotes, batch 104 (157): mcc: 0.7593, acc: 0.6134, precision: 0.9213, recall: 0.6322, f1: 0.7499, edges-pos-ontonotes_loss: 0.0242
09/16 07:29:08 AM: Evaluate: task edges-pos-ontonotes, batch 150 (157): mcc: 0.7467, acc: 0.5951, precision: 0.9145, recall: 0.6164, f1: 0.7364, edges-pos-ontonotes_loss: 0.0250
09/16 07:29:10 AM: Updating LR scheduler:
09/16 07:29:10 AM: 	Best result seen so far for macro_avg: 0.749
09/16 07:29:10 AM: 	# validation passes without improvement: 1
09/16 07:29:10 AM: edges-pos-ontonotes_loss: training: 0.028835 validation: 0.025049
09/16 07:29:10 AM: macro_avg: validation: 0.735579
09/16 07:29:10 AM: micro_avg: validation: 0.000000
09/16 07:29:10 AM: edges-pos-ontonotes_mcc: training: 0.696356 validation: 0.746114
09/16 07:29:10 AM: edges-pos-ontonotes_acc: training: 0.538651 validation: 0.593934
09/16 07:29:10 AM: edges-pos-ontonotes_precision: training: 0.833239 validation: 0.915363
09/16 07:29:10 AM: edges-pos-ontonotes_recall: training: 0.590585 validation: 0.614824
09/16 07:29:10 AM: edges-pos-ontonotes_f1: training: 0.691235 validation: 0.735579
09/16 07:29:10 AM: Global learning rate: 0.0001
09/16 07:29:10 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 07:29:19 AM: Update 13094: task edges-pos-ontonotes, batch 94 (13094): mcc: 0.7501, acc: 0.6093, precision: 0.8624, recall: 0.6602, f1: 0.7479, edges-pos-ontonotes_loss: 0.0249
09/16 07:29:29 AM: Update 13198: task edges-pos-ontonotes, batch 198 (13198): mcc: 0.7521, acc: 0.6127, precision: 0.8630, recall: 0.6631, f1: 0.7500, edges-pos-ontonotes_loss: 0.0244
09/16 07:29:39 AM: Update 13337: task edges-pos-ontonotes, batch 337 (13337): mcc: 0.7378, acc: 0.5935, precision: 0.8551, recall: 0.6446, f1: 0.7351, edges-pos-ontonotes_loss: 0.0254
09/16 07:29:49 AM: Update 13472: task edges-pos-ontonotes, batch 472 (13472): mcc: 0.7298, acc: 0.5833, precision: 0.8500, recall: 0.6346, f1: 0.7267, edges-pos-ontonotes_loss: 0.0259
09/16 07:30:01 AM: Update 13511: task edges-pos-ontonotes, batch 511 (13511): mcc: 0.7269, acc: 0.5797, precision: 0.8476, recall: 0.6316, f1: 0.7238, edges-pos-ontonotes_loss: 0.0258
09/16 07:30:11 AM: Update 13572: task edges-pos-ontonotes, batch 572 (13572): mcc: 0.7095, acc: 0.5570, precision: 0.8365, recall: 0.6102, f1: 0.7057, edges-pos-ontonotes_loss: 0.0268
09/16 07:30:22 AM: Update 13634: task edges-pos-ontonotes, batch 634 (13634): mcc: 0.6986, acc: 0.5431, precision: 0.8295, recall: 0.5971, f1: 0.6944, edges-pos-ontonotes_loss: 0.0276
09/16 07:30:32 AM: Update 13697: task edges-pos-ontonotes, batch 697 (13697): mcc: 0.6913, acc: 0.5334, precision: 0.8256, recall: 0.5877, f1: 0.6866, edges-pos-ontonotes_loss: 0.0282
09/16 07:30:42 AM: Update 13757: task edges-pos-ontonotes, batch 757 (13757): mcc: 0.6853, acc: 0.5257, precision: 0.8221, recall: 0.5803, f1: 0.6803, edges-pos-ontonotes_loss: 0.0287
09/16 07:30:52 AM: Update 13820: task edges-pos-ontonotes, batch 820 (13820): mcc: 0.6807, acc: 0.5197, precision: 0.8198, recall: 0.5741, f1: 0.6753, edges-pos-ontonotes_loss: 0.0291
09/16 07:31:02 AM: Update 13883: task edges-pos-ontonotes, batch 883 (13883): mcc: 0.6786, acc: 0.5171, precision: 0.8189, recall: 0.5713, f1: 0.6730, edges-pos-ontonotes_loss: 0.0293
09/16 07:31:12 AM: Update 13974: task edges-pos-ontonotes, batch 974 (13974): mcc: 0.6789, acc: 0.5174, precision: 0.8201, recall: 0.5710, f1: 0.6732, edges-pos-ontonotes_loss: 0.0292
09/16 07:31:15 AM: ***** Step 14000 / Validation 14 *****
09/16 07:31:15 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:31:15 AM: Validating...
09/16 07:31:22 AM: Evaluate: task edges-pos-ontonotes, batch 49 (157): mcc: 0.7706, acc: 0.6299, precision: 0.9189, recall: 0.6526, f1: 0.7632, edges-pos-ontonotes_loss: 0.0234
09/16 07:31:32 AM: Evaluate: task edges-pos-ontonotes, batch 109 (157): mcc: 0.7673, acc: 0.6260, precision: 0.9126, recall: 0.6517, f1: 0.7604, edges-pos-ontonotes_loss: 0.0235
09/16 07:31:42 AM: Evaluate: task edges-pos-ontonotes, batch 155 (157): mcc: 0.7541, acc: 0.6069, precision: 0.9076, recall: 0.6333, f1: 0.7460, edges-pos-ontonotes_loss: 0.0245
09/16 07:31:43 AM: Updating LR scheduler:
09/16 07:31:43 AM: 	Best result seen so far for macro_avg: 0.749
09/16 07:31:43 AM: 	# validation passes without improvement: 2
09/16 07:31:43 AM: edges-pos-ontonotes_loss: training: 0.029249 validation: 0.024521
09/16 07:31:43 AM: macro_avg: validation: 0.745718
09/16 07:31:43 AM: micro_avg: validation: 0.000000
09/16 07:31:43 AM: edges-pos-ontonotes_mcc: training: 0.678896 validation: 0.753816
09/16 07:31:43 AM: edges-pos-ontonotes_acc: training: 0.517407 validation: 0.606453
09/16 07:31:43 AM: edges-pos-ontonotes_precision: training: 0.819968 validation: 0.907681
09/16 07:31:43 AM: edges-pos-ontonotes_recall: training: 0.571049 validation: 0.632803
09/16 07:31:43 AM: edges-pos-ontonotes_f1: training: 0.673237 validation: 0.745718
09/16 07:31:43 AM: Global learning rate: 0.0001
09/16 07:31:43 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 07:31:52 AM: Update 14104: task edges-pos-ontonotes, batch 104 (14104): mcc: 0.7103, acc: 0.5575, precision: 0.8433, recall: 0.6067, f1: 0.7057, edges-pos-ontonotes_loss: 0.0270
09/16 07:32:03 AM: Update 14171: task edges-pos-ontonotes, batch 171 (14171): mcc: 0.6962, acc: 0.5397, precision: 0.8326, recall: 0.5909, f1: 0.6912, edges-pos-ontonotes_loss: 0.0280
09/16 07:32:13 AM: Update 14249: task edges-pos-ontonotes, batch 249 (14249): mcc: 0.6935, acc: 0.5362, precision: 0.8294, recall: 0.5886, f1: 0.6886, edges-pos-ontonotes_loss: 0.0285
09/16 07:32:23 AM: Update 14318: task edges-pos-ontonotes, batch 318 (14318): mcc: 0.6908, acc: 0.5333, precision: 0.8253, recall: 0.5871, f1: 0.6861, edges-pos-ontonotes_loss: 0.0289
09/16 07:32:33 AM: Update 14389: task edges-pos-ontonotes, batch 389 (14389): mcc: 0.6894, acc: 0.5313, precision: 0.8242, recall: 0.5855, f1: 0.6846, edges-pos-ontonotes_loss: 0.0290
09/16 07:32:43 AM: Update 14456: task edges-pos-ontonotes, batch 456 (14456): mcc: 0.6872, acc: 0.5287, precision: 0.8232, recall: 0.5826, f1: 0.6823, edges-pos-ontonotes_loss: 0.0293
09/16 07:32:53 AM: Update 14505: task edges-pos-ontonotes, batch 505 (14505): mcc: 0.6830, acc: 0.5237, precision: 0.8202, recall: 0.5777, f1: 0.6779, edges-pos-ontonotes_loss: 0.0296
09/16 07:33:03 AM: Update 14566: task edges-pos-ontonotes, batch 566 (14566): mcc: 0.6786, acc: 0.5184, precision: 0.8171, recall: 0.5726, f1: 0.6733, edges-pos-ontonotes_loss: 0.0301
09/16 07:33:13 AM: Update 14627: task edges-pos-ontonotes, batch 627 (14627): mcc: 0.6762, acc: 0.5157, precision: 0.8155, recall: 0.5698, f1: 0.6708, edges-pos-ontonotes_loss: 0.0304
09/16 07:33:23 AM: Update 14679: task edges-pos-ontonotes, batch 679 (14679): mcc: 0.6733, acc: 0.5119, precision: 0.8139, recall: 0.5660, f1: 0.6677, edges-pos-ontonotes_loss: 0.0307
09/16 07:33:33 AM: Update 14737: task edges-pos-ontonotes, batch 737 (14737): mcc: 0.6724, acc: 0.5106, precision: 0.8133, recall: 0.5650, f1: 0.6668, edges-pos-ontonotes_loss: 0.0309
09/16 07:33:44 AM: Update 14780: task edges-pos-ontonotes, batch 780 (14780): mcc: 0.6709, acc: 0.5087, precision: 0.8125, recall: 0.5630, f1: 0.6652, edges-pos-ontonotes_loss: 0.0311
09/16 07:33:54 AM: Update 14834: task edges-pos-ontonotes, batch 834 (14834): mcc: 0.6694, acc: 0.5068, precision: 0.8117, recall: 0.5613, f1: 0.6636, edges-pos-ontonotes_loss: 0.0313
09/16 07:34:04 AM: Update 14891: task edges-pos-ontonotes, batch 891 (14891): mcc: 0.6688, acc: 0.5060, precision: 0.8112, recall: 0.5605, f1: 0.6630, edges-pos-ontonotes_loss: 0.0314
09/16 07:34:14 AM: Update 14940: task edges-pos-ontonotes, batch 940 (14940): mcc: 0.6678, acc: 0.5047, precision: 0.8109, recall: 0.5592, f1: 0.6619, edges-pos-ontonotes_loss: 0.0316
09/16 07:34:24 AM: Update 14996: task edges-pos-ontonotes, batch 996 (14996): mcc: 0.6678, acc: 0.5048, precision: 0.8109, recall: 0.5592, f1: 0.6619, edges-pos-ontonotes_loss: 0.0316
09/16 07:34:25 AM: ***** Step 15000 / Validation 15 *****
09/16 07:34:25 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:34:25 AM: Validating...
09/16 07:34:34 AM: Evaluate: task edges-pos-ontonotes, batch 66 (157): mcc: 0.7735, acc: 0.6348, precision: 0.9172, recall: 0.6587, f1: 0.7668, edges-pos-ontonotes_loss: 0.0236
09/16 07:34:44 AM: Evaluate: task edges-pos-ontonotes, batch 118 (157): mcc: 0.7695, acc: 0.6302, precision: 0.9144, recall: 0.6541, f1: 0.7627, edges-pos-ontonotes_loss: 0.0237
09/16 07:34:52 AM: Best result seen so far for edges-pos-ontonotes.
09/16 07:34:52 AM: Best result seen so far for macro.
09/16 07:34:52 AM: Updating LR scheduler:
09/16 07:34:52 AM: 	Best result seen so far for macro_avg: 0.756
09/16 07:34:52 AM: 	# validation passes without improvement: 0
09/16 07:34:52 AM: edges-pos-ontonotes_loss: training: 0.031643 validation: 0.024052
09/16 07:34:52 AM: macro_avg: validation: 0.756059
09/16 07:34:52 AM: micro_avg: validation: 0.000000
09/16 07:34:52 AM: edges-pos-ontonotes_mcc: training: 0.667772 validation: 0.763655
09/16 07:34:52 AM: edges-pos-ontonotes_acc: training: 0.504700 validation: 0.621078
09/16 07:34:52 AM: edges-pos-ontonotes_precision: training: 0.810900 validation: 0.913818
09/16 07:34:52 AM: edges-pos-ontonotes_recall: training: 0.559074 validation: 0.644751
09/16 07:34:52 AM: edges-pos-ontonotes_f1: training: 0.661842 validation: 0.756059
09/16 07:34:52 AM: Global learning rate: 0.0001
09/16 07:34:52 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 07:34:54 AM: Update 15009: task edges-pos-ontonotes, batch 9 (15009): mcc: 0.6795, acc: 0.5162, precision: 0.8190, recall: 0.5727, f1: 0.6740, edges-pos-ontonotes_loss: 0.0330
09/16 07:35:04 AM: Update 15058: task edges-pos-ontonotes, batch 58 (15058): mcc: 0.6612, acc: 0.4968, precision: 0.8106, recall: 0.5485, f1: 0.6543, edges-pos-ontonotes_loss: 0.0339
09/16 07:35:20 AM: Update 15093: task edges-pos-ontonotes, batch 93 (15093): mcc: 0.6630, acc: 0.4984, precision: 0.8100, recall: 0.5519, f1: 0.6565, edges-pos-ontonotes_loss: 0.0336
09/16 07:35:31 AM: Update 15150: task edges-pos-ontonotes, batch 150 (15150): mcc: 0.6648, acc: 0.5010, precision: 0.8112, recall: 0.5540, f1: 0.6584, edges-pos-ontonotes_loss: 0.0333
09/16 07:35:41 AM: Update 15205: task edges-pos-ontonotes, batch 205 (15205): mcc: 0.6653, acc: 0.5018, precision: 0.8116, recall: 0.5544, f1: 0.6588, edges-pos-ontonotes_loss: 0.0333
09/16 07:35:51 AM: Update 15253: task edges-pos-ontonotes, batch 253 (15253): mcc: 0.6655, acc: 0.5025, precision: 0.8114, recall: 0.5549, f1: 0.6591, edges-pos-ontonotes_loss: 0.0332
09/16 07:36:01 AM: Update 15295: task edges-pos-ontonotes, batch 295 (15295): mcc: 0.6657, acc: 0.5026, precision: 0.8116, recall: 0.5552, f1: 0.6594, edges-pos-ontonotes_loss: 0.0332
09/16 07:36:11 AM: Update 15337: task edges-pos-ontonotes, batch 337 (15337): mcc: 0.6664, acc: 0.5034, precision: 0.8118, recall: 0.5562, f1: 0.6601, edges-pos-ontonotes_loss: 0.0331
09/16 07:36:22 AM: Update 15376: task edges-pos-ontonotes, batch 376 (15376): mcc: 0.6665, acc: 0.5035, precision: 0.8118, recall: 0.5564, f1: 0.6602, edges-pos-ontonotes_loss: 0.0332
09/16 07:36:32 AM: Update 15408: task edges-pos-ontonotes, batch 408 (15408): mcc: 0.6667, acc: 0.5038, precision: 0.8121, recall: 0.5565, f1: 0.6605, edges-pos-ontonotes_loss: 0.0332
09/16 07:36:42 AM: Update 15451: task edges-pos-ontonotes, batch 451 (15451): mcc: 0.6664, acc: 0.5033, precision: 0.8122, recall: 0.5559, f1: 0.6600, edges-pos-ontonotes_loss: 0.0332
09/16 07:36:52 AM: Update 15494: task edges-pos-ontonotes, batch 494 (15494): mcc: 0.6675, acc: 0.5045, precision: 0.8126, recall: 0.5574, f1: 0.6612, edges-pos-ontonotes_loss: 0.0331
09/16 07:37:02 AM: Update 15536: task edges-pos-ontonotes, batch 536 (15536): mcc: 0.6679, acc: 0.5052, precision: 0.8126, recall: 0.5582, f1: 0.6618, edges-pos-ontonotes_loss: 0.0331
09/16 07:37:12 AM: Update 15575: task edges-pos-ontonotes, batch 575 (15575): mcc: 0.6683, acc: 0.5056, precision: 0.8129, recall: 0.5585, f1: 0.6621, edges-pos-ontonotes_loss: 0.0330
09/16 07:37:22 AM: Update 15614: task edges-pos-ontonotes, batch 614 (15614): mcc: 0.6680, acc: 0.5055, precision: 0.8127, recall: 0.5583, f1: 0.6619, edges-pos-ontonotes_loss: 0.0331
09/16 07:37:32 AM: Update 15661: task edges-pos-ontonotes, batch 661 (15661): mcc: 0.6689, acc: 0.5065, precision: 0.8133, recall: 0.5592, f1: 0.6627, edges-pos-ontonotes_loss: 0.0330
09/16 07:37:42 AM: Update 15711: task edges-pos-ontonotes, batch 711 (15711): mcc: 0.6694, acc: 0.5071, precision: 0.8135, recall: 0.5598, f1: 0.6633, edges-pos-ontonotes_loss: 0.0330
09/16 07:37:52 AM: Update 15747: task edges-pos-ontonotes, batch 747 (15747): mcc: 0.6681, acc: 0.5055, precision: 0.8134, recall: 0.5579, f1: 0.6618, edges-pos-ontonotes_loss: 0.0329
09/16 07:38:02 AM: Update 15797: task edges-pos-ontonotes, batch 797 (15797): mcc: 0.6688, acc: 0.5062, precision: 0.8139, recall: 0.5586, f1: 0.6625, edges-pos-ontonotes_loss: 0.0327
09/16 07:38:12 AM: Update 15846: task edges-pos-ontonotes, batch 846 (15846): mcc: 0.6687, acc: 0.5060, precision: 0.8140, recall: 0.5585, f1: 0.6624, edges-pos-ontonotes_loss: 0.0326
09/16 07:38:23 AM: Update 15902: task edges-pos-ontonotes, batch 902 (15902): mcc: 0.6698, acc: 0.5072, precision: 0.8145, recall: 0.5599, f1: 0.6636, edges-pos-ontonotes_loss: 0.0324
09/16 07:38:33 AM: Update 15953: task edges-pos-ontonotes, batch 953 (15953): mcc: 0.6706, acc: 0.5081, precision: 0.8151, recall: 0.5608, f1: 0.6644, edges-pos-ontonotes_loss: 0.0322
09/16 07:38:41 AM: ***** Step 16000 / Validation 16 *****
09/16 07:38:41 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:38:41 AM: Validating...
09/16 07:38:43 AM: Evaluate: task edges-pos-ontonotes, batch 10 (157): mcc: 0.7714, acc: 0.6382, precision: 0.9099, recall: 0.6605, f1: 0.7654, edges-pos-ontonotes_loss: 0.0235
09/16 07:38:53 AM: Evaluate: task edges-pos-ontonotes, batch 69 (157): mcc: 0.7642, acc: 0.6205, precision: 0.9225, recall: 0.6395, f1: 0.7554, edges-pos-ontonotes_loss: 0.0240
09/16 07:39:03 AM: Evaluate: task edges-pos-ontonotes, batch 116 (157): mcc: 0.7638, acc: 0.6209, precision: 0.9194, recall: 0.6410, f1: 0.7553, edges-pos-ontonotes_loss: 0.0239
09/16 07:39:13 AM: Evaluate: task edges-pos-ontonotes, batch 157 (157): mcc: 0.7595, acc: 0.6140, precision: 0.9173, recall: 0.6355, f1: 0.7508, edges-pos-ontonotes_loss: 0.0242
09/16 07:39:13 AM: Updating LR scheduler:
09/16 07:39:13 AM: 	Best result seen so far for macro_avg: 0.756
09/16 07:39:13 AM: 	# validation passes without improvement: 1
09/16 07:39:13 AM: edges-pos-ontonotes_loss: training: 0.032021 validation: 0.024171
09/16 07:39:13 AM: macro_avg: validation: 0.750796
09/16 07:39:13 AM: micro_avg: validation: 0.000000
09/16 07:39:13 AM: edges-pos-ontonotes_mcc: training: 0.671404 validation: 0.759533
09/16 07:39:13 AM: edges-pos-ontonotes_acc: training: 0.509074 validation: 0.613998
09/16 07:39:13 AM: edges-pos-ontonotes_precision: training: 0.815499 validation: 0.917283
09/16 07:39:13 AM: edges-pos-ontonotes_recall: training: 0.561824 validation: 0.635459
09/16 07:39:13 AM: edges-pos-ontonotes_f1: training: 0.665300 validation: 0.750796
09/16 07:39:13 AM: Global learning rate: 0.0001
09/16 07:39:13 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 07:39:23 AM: Update 16047: task edges-pos-ontonotes, batch 47 (16047): mcc: 0.6863, acc: 0.5249, precision: 0.8243, recall: 0.5803, f1: 0.6811, edges-pos-ontonotes_loss: 0.0289
09/16 07:39:33 AM: Update 16111: task edges-pos-ontonotes, batch 111 (16111): mcc: 0.7191, acc: 0.5654, precision: 0.8438, recall: 0.6211, f1: 0.7155, edges-pos-ontonotes_loss: 0.0269
09/16 07:39:43 AM: Update 16172: task edges-pos-ontonotes, batch 172 (16172): mcc: 0.7313, acc: 0.5810, precision: 0.8506, recall: 0.6368, f1: 0.7283, edges-pos-ontonotes_loss: 0.0262
09/16 07:39:54 AM: Update 16240: task edges-pos-ontonotes, batch 240 (16240): mcc: 0.7388, acc: 0.5907, precision: 0.8542, recall: 0.6470, f1: 0.7363, edges-pos-ontonotes_loss: 0.0258
09/16 07:40:04 AM: Update 16300: task edges-pos-ontonotes, batch 300 (16300): mcc: 0.7419, acc: 0.5947, precision: 0.8558, recall: 0.6510, f1: 0.7395, edges-pos-ontonotes_loss: 0.0257
09/16 07:40:14 AM: Update 16359: task edges-pos-ontonotes, batch 359 (16359): mcc: 0.7417, acc: 0.5947, precision: 0.8565, recall: 0.6503, f1: 0.7393, edges-pos-ontonotes_loss: 0.0256
09/16 07:40:24 AM: Update 16434: task edges-pos-ontonotes, batch 434 (16434): mcc: 0.7431, acc: 0.5971, precision: 0.8571, recall: 0.6522, f1: 0.7407, edges-pos-ontonotes_loss: 0.0254
09/16 07:40:34 AM: Update 16509: task edges-pos-ontonotes, batch 509 (16509): mcc: 0.7443, acc: 0.5991, precision: 0.8578, recall: 0.6537, f1: 0.7420, edges-pos-ontonotes_loss: 0.0251
09/16 07:40:44 AM: Update 16580: task edges-pos-ontonotes, batch 580 (16580): mcc: 0.7464, acc: 0.6023, precision: 0.8587, recall: 0.6566, f1: 0.7442, edges-pos-ontonotes_loss: 0.0249
09/16 07:40:54 AM: Update 16655: task edges-pos-ontonotes, batch 655 (16655): mcc: 0.7489, acc: 0.6057, precision: 0.8603, recall: 0.6597, f1: 0.7467, edges-pos-ontonotes_loss: 0.0247
09/16 07:41:05 AM: Update 16723: task edges-pos-ontonotes, batch 723 (16723): mcc: 0.7450, acc: 0.6007, precision: 0.8584, recall: 0.6545, f1: 0.7427, edges-pos-ontonotes_loss: 0.0249
09/16 07:41:15 AM: Update 16825: task edges-pos-ontonotes, batch 825 (16825): mcc: 0.7435, acc: 0.5990, precision: 0.8571, recall: 0.6529, f1: 0.7412, edges-pos-ontonotes_loss: 0.0251
09/16 07:41:25 AM: Update 16954: task edges-pos-ontonotes, batch 954 (16954): mcc: 0.7402, acc: 0.5951, precision: 0.8548, recall: 0.6490, f1: 0.7378, edges-pos-ontonotes_loss: 0.0252
09/16 07:41:34 AM: ***** Step 17000 / Validation 17 *****
09/16 07:41:34 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:41:34 AM: Validating...
09/16 07:41:35 AM: Evaluate: task edges-pos-ontonotes, batch 4 (157): mcc: 0.7836, acc: 0.6483, precision: 0.9043, recall: 0.6855, f1: 0.7799, edges-pos-ontonotes_loss: 0.0220
09/16 07:41:45 AM: Evaluate: task edges-pos-ontonotes, batch 72 (157): mcc: 0.7773, acc: 0.6410, precision: 0.9168, recall: 0.6654, f1: 0.7711, edges-pos-ontonotes_loss: 0.0229
09/16 07:41:55 AM: Evaluate: task edges-pos-ontonotes, batch 123 (157): mcc: 0.7658, acc: 0.6250, precision: 0.9108, recall: 0.6506, f1: 0.7590, edges-pos-ontonotes_loss: 0.0237
09/16 07:42:02 AM: Updating LR scheduler:
09/16 07:42:02 AM: 	Best result seen so far for macro_avg: 0.756
09/16 07:42:02 AM: 	# validation passes without improvement: 2
09/16 07:42:02 AM: edges-pos-ontonotes_loss: training: 0.025514 validation: 0.024149
09/16 07:42:02 AM: macro_avg: validation: 0.750972
09/16 07:42:02 AM: micro_avg: validation: 0.000000
09/16 07:42:02 AM: edges-pos-ontonotes_mcc: training: 0.731533 validation: 0.758533
09/16 07:42:02 AM: edges-pos-ontonotes_acc: training: 0.583922 validation: 0.613469
09/16 07:42:02 AM: edges-pos-ontonotes_precision: training: 0.849471 validation: 0.908693
09/16 07:42:02 AM: edges-pos-ontonotes_recall: training: 0.638108 validation: 0.639904
09/16 07:42:02 AM: edges-pos-ontonotes_f1: training: 0.728773 validation: 0.750972
09/16 07:42:02 AM: Global learning rate: 0.0001
09/16 07:42:02 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 07:42:05 AM: Update 17016: task edges-pos-ontonotes, batch 16 (17016): mcc: 0.6555, acc: 0.4882, precision: 0.7961, recall: 0.5493, f1: 0.6500, edges-pos-ontonotes_loss: 0.0343
09/16 07:42:15 AM: Update 17070: task edges-pos-ontonotes, batch 70 (17070): mcc: 0.6583, acc: 0.4908, precision: 0.7992, recall: 0.5517, f1: 0.6528, edges-pos-ontonotes_loss: 0.0337
09/16 07:42:25 AM: Update 17117: task edges-pos-ontonotes, batch 117 (17117): mcc: 0.6526, acc: 0.4842, precision: 0.7977, recall: 0.5434, f1: 0.6465, edges-pos-ontonotes_loss: 0.0343
09/16 07:42:35 AM: Update 17164: task edges-pos-ontonotes, batch 164 (17164): mcc: 0.6497, acc: 0.4810, precision: 0.7960, recall: 0.5398, f1: 0.6433, edges-pos-ontonotes_loss: 0.0344
09/16 07:42:46 AM: Update 17218: task edges-pos-ontonotes, batch 218 (17218): mcc: 0.6525, acc: 0.4845, precision: 0.7976, recall: 0.5432, f1: 0.6463, edges-pos-ontonotes_loss: 0.0342
09/16 07:42:56 AM: Update 17267: task edges-pos-ontonotes, batch 267 (17267): mcc: 0.6516, acc: 0.4838, precision: 0.7978, recall: 0.5417, f1: 0.6453, edges-pos-ontonotes_loss: 0.0342
09/16 07:43:11 AM: Update 17301: task edges-pos-ontonotes, batch 301 (17301): mcc: 0.6525, acc: 0.4849, precision: 0.7988, recall: 0.5425, f1: 0.6462, edges-pos-ontonotes_loss: 0.0341
09/16 07:43:21 AM: Update 17376: task edges-pos-ontonotes, batch 376 (17376): mcc: 0.6570, acc: 0.4901, precision: 0.8033, recall: 0.5467, f1: 0.6506, edges-pos-ontonotes_loss: 0.0331
09/16 07:43:31 AM: Update 17465: task edges-pos-ontonotes, batch 465 (17465): mcc: 0.6625, acc: 0.4969, precision: 0.8075, recall: 0.5528, f1: 0.6563, edges-pos-ontonotes_loss: 0.0321
09/16 07:43:41 AM: Update 17554: task edges-pos-ontonotes, batch 554 (17554): mcc: 0.6660, acc: 0.5013, precision: 0.8101, recall: 0.5567, f1: 0.6599, edges-pos-ontonotes_loss: 0.0315
09/16 07:43:52 AM: Update 17630: task edges-pos-ontonotes, batch 630 (17630): mcc: 0.6679, acc: 0.5038, precision: 0.8115, recall: 0.5589, f1: 0.6619, edges-pos-ontonotes_loss: 0.0311
09/16 07:44:02 AM: Update 17707: task edges-pos-ontonotes, batch 707 (17707): mcc: 0.6700, acc: 0.5065, precision: 0.8119, recall: 0.5620, f1: 0.6642, edges-pos-ontonotes_loss: 0.0309
09/16 07:44:12 AM: Update 17783: task edges-pos-ontonotes, batch 783 (17783): mcc: 0.6723, acc: 0.5098, precision: 0.8129, recall: 0.5652, f1: 0.6668, edges-pos-ontonotes_loss: 0.0307
09/16 07:44:22 AM: Update 17845: task edges-pos-ontonotes, batch 845 (17845): mcc: 0.6727, acc: 0.5104, precision: 0.8128, recall: 0.5659, f1: 0.6673, edges-pos-ontonotes_loss: 0.0308
09/16 07:44:32 AM: Update 17925: task edges-pos-ontonotes, batch 925 (17925): mcc: 0.6745, acc: 0.5127, precision: 0.8138, recall: 0.5682, f1: 0.6692, edges-pos-ontonotes_loss: 0.0306
09/16 07:44:42 AM: Update 17965: task edges-pos-ontonotes, batch 965 (17965): mcc: 0.6721, acc: 0.5099, precision: 0.8123, recall: 0.5652, f1: 0.6666, edges-pos-ontonotes_loss: 0.0308
09/16 07:44:48 AM: ***** Step 18000 / Validation 18 *****
09/16 07:44:48 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:44:48 AM: Validating...
09/16 07:44:52 AM: Evaluate: task edges-pos-ontonotes, batch 32 (157): mcc: 0.7750, acc: 0.6379, precision: 0.9170, recall: 0.6615, f1: 0.7685, edges-pos-ontonotes_loss: 0.0229
09/16 07:45:02 AM: Evaluate: task edges-pos-ontonotes, batch 97 (157): mcc: 0.7813, acc: 0.6465, precision: 0.9193, recall: 0.6703, f1: 0.7753, edges-pos-ontonotes_loss: 0.0225
09/16 07:45:12 AM: Evaluate: task edges-pos-ontonotes, batch 143 (157): mcc: 0.7670, acc: 0.6256, precision: 0.9160, recall: 0.6489, f1: 0.7596, edges-pos-ontonotes_loss: 0.0233
09/16 07:45:15 AM: Best result seen so far for edges-pos-ontonotes.
09/16 07:45:15 AM: Best result seen so far for macro.
09/16 07:45:15 AM: Updating LR scheduler:
09/16 07:45:15 AM: 	Best result seen so far for macro_avg: 0.760
09/16 07:45:15 AM: 	# validation passes without improvement: 0
09/16 07:45:15 AM: edges-pos-ontonotes_loss: training: 0.030866 validation: 0.023389
09/16 07:45:15 AM: macro_avg: validation: 0.759697
09/16 07:45:15 AM: micro_avg: validation: 0.000000
09/16 07:45:15 AM: edges-pos-ontonotes_mcc: training: 0.671631 validation: 0.767299
09/16 07:45:15 AM: edges-pos-ontonotes_acc: training: 0.509365 validation: 0.625290
09/16 07:45:15 AM: edges-pos-ontonotes_precision: training: 0.811710 validation: 0.917329
09/16 07:45:15 AM: edges-pos-ontonotes_recall: training: 0.564884 validation: 0.648296
09/16 07:45:15 AM: edges-pos-ontonotes_f1: training: 0.666169 validation: 0.759697
09/16 07:45:15 AM: Global learning rate: 0.0001
09/16 07:45:15 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 07:45:22 AM: Update 18043: task edges-pos-ontonotes, batch 43 (18043): mcc: 0.6634, acc: 0.5007, precision: 0.8044, recall: 0.5564, f1: 0.6578, edges-pos-ontonotes_loss: 0.0332
09/16 07:45:32 AM: Update 18099: task edges-pos-ontonotes, batch 99 (18099): mcc: 0.6596, acc: 0.4948, precision: 0.8031, recall: 0.5511, f1: 0.6536, edges-pos-ontonotes_loss: 0.0335
09/16 07:45:43 AM: Update 18157: task edges-pos-ontonotes, batch 157 (18157): mcc: 0.6589, acc: 0.4940, precision: 0.8035, recall: 0.5497, f1: 0.6528, edges-pos-ontonotes_loss: 0.0333
09/16 07:45:53 AM: Update 18221: task edges-pos-ontonotes, batch 221 (18221): mcc: 0.6627, acc: 0.4982, precision: 0.8058, recall: 0.5543, f1: 0.6568, edges-pos-ontonotes_loss: 0.0331
09/16 07:46:03 AM: Update 18265: task edges-pos-ontonotes, batch 265 (18265): mcc: 0.6611, acc: 0.4960, precision: 0.8054, recall: 0.5520, f1: 0.6551, edges-pos-ontonotes_loss: 0.0331
09/16 07:46:13 AM: Update 18318: task edges-pos-ontonotes, batch 318 (18318): mcc: 0.6621, acc: 0.4975, precision: 0.8059, recall: 0.5532, f1: 0.6560, edges-pos-ontonotes_loss: 0.0332
09/16 07:46:23 AM: Update 18370: task edges-pos-ontonotes, batch 370 (18370): mcc: 0.6615, acc: 0.4972, precision: 0.8057, recall: 0.5525, f1: 0.6555, edges-pos-ontonotes_loss: 0.0333
09/16 07:46:33 AM: Update 18427: task edges-pos-ontonotes, batch 427 (18427): mcc: 0.6620, acc: 0.4977, precision: 0.8064, recall: 0.5527, f1: 0.6559, edges-pos-ontonotes_loss: 0.0332
09/16 07:46:43 AM: Update 18479: task edges-pos-ontonotes, batch 479 (18479): mcc: 0.6622, acc: 0.4979, precision: 0.8066, recall: 0.5529, f1: 0.6561, edges-pos-ontonotes_loss: 0.0332
09/16 07:46:54 AM: Update 18538: task edges-pos-ontonotes, batch 538 (18538): mcc: 0.6635, acc: 0.4995, precision: 0.8075, recall: 0.5545, f1: 0.6575, edges-pos-ontonotes_loss: 0.0331
09/16 07:47:04 AM: Update 18581: task edges-pos-ontonotes, batch 581 (18581): mcc: 0.6634, acc: 0.4993, precision: 0.8074, recall: 0.5543, f1: 0.6573, edges-pos-ontonotes_loss: 0.0331
09/16 07:47:14 AM: Update 18638: task edges-pos-ontonotes, batch 638 (18638): mcc: 0.6639, acc: 0.5001, precision: 0.8077, recall: 0.5550, f1: 0.6579, edges-pos-ontonotes_loss: 0.0331
09/16 07:47:24 AM: Update 18700: task edges-pos-ontonotes, batch 700 (18700): mcc: 0.6653, acc: 0.5017, precision: 0.8085, recall: 0.5566, f1: 0.6593, edges-pos-ontonotes_loss: 0.0330
09/16 07:47:34 AM: Update 18756: task edges-pos-ontonotes, batch 756 (18756): mcc: 0.6658, acc: 0.5024, precision: 0.8089, recall: 0.5573, f1: 0.6599, edges-pos-ontonotes_loss: 0.0330
09/16 07:47:44 AM: Update 18809: task edges-pos-ontonotes, batch 809 (18809): mcc: 0.6664, acc: 0.5030, precision: 0.8094, recall: 0.5578, f1: 0.6605, edges-pos-ontonotes_loss: 0.0330
09/16 07:47:54 AM: Update 18861: task edges-pos-ontonotes, batch 861 (18861): mcc: 0.6664, acc: 0.5030, precision: 0.8097, recall: 0.5576, f1: 0.6604, edges-pos-ontonotes_loss: 0.0330
09/16 07:48:04 AM: Update 18905: task edges-pos-ontonotes, batch 905 (18905): mcc: 0.6664, acc: 0.5031, precision: 0.8097, recall: 0.5576, f1: 0.6604, edges-pos-ontonotes_loss: 0.0330
09/16 07:48:14 AM: Update 18962: task edges-pos-ontonotes, batch 962 (18962): mcc: 0.6670, acc: 0.5039, precision: 0.8100, recall: 0.5583, f1: 0.6610, edges-pos-ontonotes_loss: 0.0329
09/16 07:48:21 AM: ***** Step 19000 / Validation 19 *****
09/16 07:48:21 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:48:21 AM: Validating...
09/16 07:48:24 AM: Evaluate: task edges-pos-ontonotes, batch 20 (157): mcc: 0.7691, acc: 0.6317, precision: 0.9118, recall: 0.6554, f1: 0.7626, edges-pos-ontonotes_loss: 0.0239
09/16 07:48:34 AM: Evaluate: task edges-pos-ontonotes, batch 88 (157): mcc: 0.7765, acc: 0.6402, precision: 0.9154, recall: 0.6651, f1: 0.7704, edges-pos-ontonotes_loss: 0.0234
09/16 07:48:44 AM: Evaluate: task edges-pos-ontonotes, batch 134 (157): mcc: 0.7676, acc: 0.6278, precision: 0.9128, recall: 0.6520, f1: 0.7607, edges-pos-ontonotes_loss: 0.0238
09/16 07:48:49 AM: Best result seen so far for edges-pos-ontonotes.
09/16 07:48:49 AM: Best result seen so far for macro.
09/16 07:48:49 AM: Updating LR scheduler:
09/16 07:48:49 AM: 	Best result seen so far for macro_avg: 0.761
09/16 07:48:49 AM: 	# validation passes without improvement: 0
09/16 07:48:49 AM: edges-pos-ontonotes_loss: training: 0.032911 validation: 0.023739
09/16 07:48:49 AM: macro_avg: validation: 0.760896
09/16 07:48:49 AM: micro_avg: validation: 0.000000
09/16 07:48:49 AM: edges-pos-ontonotes_mcc: training: 0.667363 validation: 0.768000
09/16 07:48:49 AM: edges-pos-ontonotes_acc: training: 0.504443 validation: 0.627702
09/16 07:48:49 AM: edges-pos-ontonotes_precision: training: 0.810452 validation: 0.914650
09/16 07:48:49 AM: edges-pos-ontonotes_recall: training: 0.558715 validation: 0.651396
09/16 07:48:49 AM: edges-pos-ontonotes_f1: training: 0.661441 validation: 0.760896
09/16 07:48:49 AM: Global learning rate: 0.0001
09/16 07:48:49 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 07:48:55 AM: Update 19026: task edges-pos-ontonotes, batch 26 (19026): mcc: 0.6618, acc: 0.4993, precision: 0.8069, recall: 0.5520, f1: 0.6555, edges-pos-ontonotes_loss: 0.0334
09/16 07:49:05 AM: Update 19085: task edges-pos-ontonotes, batch 85 (19085): mcc: 0.6732, acc: 0.5120, precision: 0.8155, recall: 0.5648, f1: 0.6674, edges-pos-ontonotes_loss: 0.0330
09/16 07:49:15 AM: Update 19143: task edges-pos-ontonotes, batch 143 (19143): mcc: 0.6756, acc: 0.5153, precision: 0.8158, recall: 0.5685, f1: 0.6701, edges-pos-ontonotes_loss: 0.0327
09/16 07:49:33 AM: Update 19179: task edges-pos-ontonotes, batch 179 (19179): mcc: 0.6744, acc: 0.5136, precision: 0.8155, recall: 0.5668, f1: 0.6688, edges-pos-ontonotes_loss: 0.0326
09/16 07:49:43 AM: Update 19224: task edges-pos-ontonotes, batch 224 (19224): mcc: 0.6707, acc: 0.5087, precision: 0.8134, recall: 0.5621, f1: 0.6648, edges-pos-ontonotes_loss: 0.0324
09/16 07:49:53 AM: Update 19292: task edges-pos-ontonotes, batch 292 (19292): mcc: 0.6733, acc: 0.5114, precision: 0.8154, recall: 0.5650, f1: 0.6675, edges-pos-ontonotes_loss: 0.0317
09/16 07:50:03 AM: Update 19363: task edges-pos-ontonotes, batch 363 (19363): mcc: 0.6763, acc: 0.5150, precision: 0.8174, recall: 0.5686, f1: 0.6707, edges-pos-ontonotes_loss: 0.0311
09/16 07:50:13 AM: Update 19431: task edges-pos-ontonotes, batch 431 (19431): mcc: 0.6776, acc: 0.5165, precision: 0.8186, recall: 0.5699, f1: 0.6720, edges-pos-ontonotes_loss: 0.0308
09/16 07:50:23 AM: Update 19493: task edges-pos-ontonotes, batch 493 (19493): mcc: 0.6784, acc: 0.5174, precision: 0.8191, recall: 0.5708, f1: 0.6728, edges-pos-ontonotes_loss: 0.0305
09/16 07:50:33 AM: Update 19592: task edges-pos-ontonotes, batch 592 (19592): mcc: 0.6872, acc: 0.5279, precision: 0.8241, recall: 0.5820, f1: 0.6822, edges-pos-ontonotes_loss: 0.0295
09/16 07:50:43 AM: Update 19677: task edges-pos-ontonotes, batch 677 (19677): mcc: 0.6937, acc: 0.5356, precision: 0.8282, recall: 0.5898, f1: 0.6890, edges-pos-ontonotes_loss: 0.0290
09/16 07:50:53 AM: Update 19769: task edges-pos-ontonotes, batch 769 (19769): mcc: 0.6998, acc: 0.5430, precision: 0.8316, recall: 0.5975, f1: 0.6954, edges-pos-ontonotes_loss: 0.0284
09/16 07:51:03 AM: Update 19853: task edges-pos-ontonotes, batch 853 (19853): mcc: 0.7033, acc: 0.5476, precision: 0.8337, recall: 0.6019, f1: 0.6991, edges-pos-ontonotes_loss: 0.0281
09/16 07:51:14 AM: Update 19964: task edges-pos-ontonotes, batch 964 (19964): mcc: 0.7079, acc: 0.5535, precision: 0.8364, recall: 0.6076, f1: 0.7039, edges-pos-ontonotes_loss: 0.0275
09/16 07:51:16 AM: ***** Step 20000 / Validation 20 *****
09/16 07:51:16 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:51:16 AM: Validating...
09/16 07:51:24 AM: Evaluate: task edges-pos-ontonotes, batch 52 (157): mcc: 0.7684, acc: 0.6245, precision: 0.9273, recall: 0.6431, f1: 0.7595, edges-pos-ontonotes_loss: 0.0235
09/16 07:51:34 AM: Evaluate: task edges-pos-ontonotes, batch 111 (157): mcc: 0.7668, acc: 0.6239, precision: 0.9218, recall: 0.6443, f1: 0.7585, edges-pos-ontonotes_loss: 0.0235
09/16 07:51:44 AM: Updating LR scheduler:
09/16 07:51:44 AM: 	Best result seen so far for macro_avg: 0.761
09/16 07:51:44 AM: 	# validation passes without improvement: 1
09/16 07:51:44 AM: edges-pos-ontonotes_loss: training: 0.027297 validation: 0.024162
09/16 07:51:44 AM: macro_avg: validation: 0.748375
09/16 07:51:44 AM: micro_avg: validation: 0.000000
09/16 07:51:44 AM: edges-pos-ontonotes_mcc: training: 0.709058 validation: 0.757334
09/16 07:51:44 AM: edges-pos-ontonotes_acc: training: 0.555084 validation: 0.609956
09/16 07:51:44 AM: edges-pos-ontonotes_precision: training: 0.837140 validation: 0.916571
09/16 07:51:44 AM: edges-pos-ontonotes_recall: training: 0.609085 validation: 0.632338
09/16 07:51:44 AM: edges-pos-ontonotes_f1: training: 0.705132 validation: 0.748375
09/16 07:51:44 AM: Global learning rate: 0.0001
09/16 07:51:44 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 07:51:44 AM: Update 20002: task edges-pos-ontonotes, batch 2 (20002): mcc: 0.8508, acc: 0.7576, precision: 0.9249, recall: 0.7879, f1: 0.8509, edges-pos-ontonotes_loss: 0.0167
09/16 07:51:54 AM: Update 20104: task edges-pos-ontonotes, batch 104 (20104): mcc: 0.7655, acc: 0.6295, precision: 0.8667, recall: 0.6836, f1: 0.7643, edges-pos-ontonotes_loss: 0.0236
09/16 07:52:04 AM: Update 20221: task edges-pos-ontonotes, batch 221 (20221): mcc: 0.7406, acc: 0.5965, precision: 0.8533, recall: 0.6508, f1: 0.7384, edges-pos-ontonotes_loss: 0.0245
09/16 07:52:14 AM: Update 20361: task edges-pos-ontonotes, batch 361 (20361): mcc: 0.7360, acc: 0.5905, precision: 0.8493, recall: 0.6460, f1: 0.7338, edges-pos-ontonotes_loss: 0.0248
09/16 07:52:24 AM: Update 20440: task edges-pos-ontonotes, batch 440 (20440): mcc: 0.7197, acc: 0.5697, precision: 0.8401, recall: 0.6249, f1: 0.7167, edges-pos-ontonotes_loss: 0.0255
09/16 07:52:34 AM: Update 20508: task edges-pos-ontonotes, batch 508 (20508): mcc: 0.7069, acc: 0.5532, precision: 0.8311, recall: 0.6099, f1: 0.7035, edges-pos-ontonotes_loss: 0.0265
09/16 07:52:44 AM: Update 20569: task edges-pos-ontonotes, batch 569 (20569): mcc: 0.6958, acc: 0.5390, precision: 0.8248, recall: 0.5959, f1: 0.6919, edges-pos-ontonotes_loss: 0.0274
09/16 07:52:54 AM: Update 20635: task edges-pos-ontonotes, batch 635 (20635): mcc: 0.6904, acc: 0.5321, precision: 0.8217, recall: 0.5891, f1: 0.6862, edges-pos-ontonotes_loss: 0.0279
09/16 07:53:05 AM: Update 20695: task edges-pos-ontonotes, batch 695 (20695): mcc: 0.6853, acc: 0.5258, precision: 0.8180, recall: 0.5831, f1: 0.6809, edges-pos-ontonotes_loss: 0.0285
09/16 07:53:15 AM: Update 20746: task edges-pos-ontonotes, batch 746 (20746): mcc: 0.6810, acc: 0.5201, precision: 0.8156, recall: 0.5776, f1: 0.6763, edges-pos-ontonotes_loss: 0.0289
09/16 07:53:25 AM: Update 20822: task edges-pos-ontonotes, batch 822 (20822): mcc: 0.6813, acc: 0.5203, precision: 0.8165, recall: 0.5776, f1: 0.6766, edges-pos-ontonotes_loss: 0.0289
09/16 07:53:35 AM: Update 20910: task edges-pos-ontonotes, batch 910 (20910): mcc: 0.6821, acc: 0.5213, precision: 0.8179, recall: 0.5779, f1: 0.6773, edges-pos-ontonotes_loss: 0.0288
09/16 07:53:44 AM: ***** Step 21000 / Validation 21 *****
09/16 07:53:44 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:53:44 AM: Validating...
09/16 07:53:45 AM: Evaluate: task edges-pos-ontonotes, batch 2 (157): mcc: 0.7904, acc: 0.6643, precision: 0.8835, recall: 0.7140, f1: 0.7898, edges-pos-ontonotes_loss: 0.0210
09/16 07:53:55 AM: Evaluate: task edges-pos-ontonotes, batch 72 (157): mcc: 0.7881, acc: 0.6564, precision: 0.9192, recall: 0.6819, f1: 0.7830, edges-pos-ontonotes_loss: 0.0218
09/16 07:54:05 AM: Evaluate: task edges-pos-ontonotes, batch 124 (157): mcc: 0.7734, acc: 0.6365, precision: 0.9100, recall: 0.6638, f1: 0.7677, edges-pos-ontonotes_loss: 0.0229
09/16 07:54:12 AM: Updating LR scheduler:
09/16 07:54:12 AM: 	Best result seen so far for macro_avg: 0.761
09/16 07:54:12 AM: 	# validation passes without improvement: 2
09/16 07:54:12 AM: edges-pos-ontonotes_loss: training: 0.028710 validation: 0.023457
09/16 07:54:12 AM: macro_avg: validation: 0.758254
09/16 07:54:12 AM: micro_avg: validation: 0.000000
09/16 07:54:12 AM: edges-pos-ontonotes_mcc: training: 0.683817 validation: 0.764775
09/16 07:54:12 AM: edges-pos-ontonotes_acc: training: 0.523477 validation: 0.623258
09/16 07:54:12 AM: edges-pos-ontonotes_precision: training: 0.819280 validation: 0.907625
09/16 07:54:12 AM: edges-pos-ontonotes_recall: training: 0.579731 validation: 0.651100
09/16 07:54:12 AM: edges-pos-ontonotes_f1: training: 0.678997 validation: 0.758254
09/16 07:54:12 AM: Global learning rate: 0.0001
09/16 07:54:12 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 07:54:15 AM: Update 21026: task edges-pos-ontonotes, batch 26 (21026): mcc: 0.6867, acc: 0.5260, precision: 0.8235, recall: 0.5815, f1: 0.6817, edges-pos-ontonotes_loss: 0.0282
09/16 07:54:25 AM: Update 21096: task edges-pos-ontonotes, batch 96 (21096): mcc: 0.6915, acc: 0.5342, precision: 0.8239, recall: 0.5892, f1: 0.6871, edges-pos-ontonotes_loss: 0.0284
09/16 07:54:35 AM: Update 21156: task edges-pos-ontonotes, batch 156 (21156): mcc: 0.6823, acc: 0.5224, precision: 0.8174, recall: 0.5785, f1: 0.6775, edges-pos-ontonotes_loss: 0.0295
09/16 07:54:45 AM: Update 21232: task edges-pos-ontonotes, batch 232 (21232): mcc: 0.6868, acc: 0.5281, precision: 0.8198, recall: 0.5843, f1: 0.6823, edges-pos-ontonotes_loss: 0.0294
09/16 07:54:55 AM: Update 21309: task edges-pos-ontonotes, batch 309 (21309): mcc: 0.6879, acc: 0.5294, precision: 0.8206, recall: 0.5857, f1: 0.6835, edges-pos-ontonotes_loss: 0.0290
09/16 07:55:06 AM: Update 21383: task edges-pos-ontonotes, batch 383 (21383): mcc: 0.6900, acc: 0.5322, precision: 0.8211, recall: 0.5887, f1: 0.6858, edges-pos-ontonotes_loss: 0.0291
09/16 07:55:16 AM: Update 21387: task edges-pos-ontonotes, batch 387 (21387): mcc: 0.6890, acc: 0.5310, precision: 0.8208, recall: 0.5873, f1: 0.6847, edges-pos-ontonotes_loss: 0.0291
09/16 07:55:26 AM: Update 21442: task edges-pos-ontonotes, batch 442 (21442): mcc: 0.6838, acc: 0.5247, precision: 0.8171, recall: 0.5813, f1: 0.6793, edges-pos-ontonotes_loss: 0.0297
09/16 07:55:36 AM: Update 21496: task edges-pos-ontonotes, batch 496 (21496): mcc: 0.6791, acc: 0.5192, precision: 0.8138, recall: 0.5758, f1: 0.6744, edges-pos-ontonotes_loss: 0.0301
09/16 07:55:46 AM: Update 21553: task edges-pos-ontonotes, batch 553 (21553): mcc: 0.6769, acc: 0.5164, precision: 0.8125, recall: 0.5730, f1: 0.6721, edges-pos-ontonotes_loss: 0.0304
09/16 07:55:57 AM: Update 21619: task edges-pos-ontonotes, batch 619 (21619): mcc: 0.6767, acc: 0.5161, precision: 0.8125, recall: 0.5727, f1: 0.6719, edges-pos-ontonotes_loss: 0.0306
09/16 07:56:07 AM: Update 21676: task edges-pos-ontonotes, batch 676 (21676): mcc: 0.6759, acc: 0.5150, precision: 0.8122, recall: 0.5716, f1: 0.6710, edges-pos-ontonotes_loss: 0.0308
09/16 07:56:17 AM: Update 21721: task edges-pos-ontonotes, batch 721 (21721): mcc: 0.6747, acc: 0.5135, precision: 0.8114, recall: 0.5702, f1: 0.6698, edges-pos-ontonotes_loss: 0.0309
09/16 07:56:27 AM: Update 21770: task edges-pos-ontonotes, batch 770 (21770): mcc: 0.6734, acc: 0.5119, precision: 0.8109, recall: 0.5684, f1: 0.6683, edges-pos-ontonotes_loss: 0.0311
09/16 07:56:37 AM: Update 21824: task edges-pos-ontonotes, batch 824 (21824): mcc: 0.6732, acc: 0.5117, precision: 0.8109, recall: 0.5680, f1: 0.6681, edges-pos-ontonotes_loss: 0.0312
09/16 07:56:47 AM: Update 21872: task edges-pos-ontonotes, batch 872 (21872): mcc: 0.6724, acc: 0.5107, precision: 0.8107, recall: 0.5669, f1: 0.6672, edges-pos-ontonotes_loss: 0.0314
09/16 07:56:57 AM: Update 21927: task edges-pos-ontonotes, batch 927 (21927): mcc: 0.6721, acc: 0.5104, precision: 0.8105, recall: 0.5666, f1: 0.6669, edges-pos-ontonotes_loss: 0.0314
09/16 07:57:07 AM: Update 21986: task edges-pos-ontonotes, batch 986 (21986): mcc: 0.6725, acc: 0.5109, precision: 0.8108, recall: 0.5669, f1: 0.6673, edges-pos-ontonotes_loss: 0.0315
09/16 07:57:09 AM: ***** Step 22000 / Validation 22 *****
09/16 07:57:09 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:57:09 AM: Validating...
09/16 07:57:17 AM: Evaluate: task edges-pos-ontonotes, batch 56 (157): mcc: 0.7737, acc: 0.6341, precision: 0.9221, recall: 0.6555, f1: 0.7663, edges-pos-ontonotes_loss: 0.0232
09/16 07:57:28 AM: Evaluate: task edges-pos-ontonotes, batch 113 (157): mcc: 0.7737, acc: 0.6346, precision: 0.9204, recall: 0.6568, f1: 0.7666, edges-pos-ontonotes_loss: 0.0230
09/16 07:57:37 AM: Updating LR scheduler:
09/16 07:57:37 AM: 	Best result seen so far for macro_avg: 0.761
09/16 07:57:37 AM: 	# validation passes without improvement: 3
09/16 07:57:37 AM: edges-pos-ontonotes_loss: training: 0.031507 validation: 0.023341
09/16 07:57:37 AM: macro_avg: validation: 0.759072
09/16 07:57:37 AM: micro_avg: validation: 0.000000
09/16 07:57:37 AM: edges-pos-ontonotes_mcc: training: 0.672678 validation: 0.767137
09/16 07:57:37 AM: edges-pos-ontonotes_acc: training: 0.511152 validation: 0.624591
09/16 07:57:37 AM: edges-pos-ontonotes_precision: training: 0.810931 validation: 0.920233
09/16 07:57:37 AM: edges-pos-ontonotes_recall: training: 0.567176 validation: 0.645946
09/16 07:57:37 AM: edges-pos-ontonotes_f1: training: 0.667496 validation: 0.759072
09/16 07:57:37 AM: Global learning rate: 0.0001
09/16 07:57:37 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 07:57:38 AM: Update 22001: task edges-pos-ontonotes, batch 1 (22001): mcc: 0.6891, acc: 0.5369, precision: 0.8071, recall: 0.5977, f1: 0.6868, edges-pos-ontonotes_loss: 0.0319
09/16 07:57:48 AM: Update 22032: task edges-pos-ontonotes, batch 32 (22032): mcc: 0.6579, acc: 0.4934, precision: 0.8087, recall: 0.5444, f1: 0.6507, edges-pos-ontonotes_loss: 0.0346
09/16 07:57:58 AM: Update 22081: task edges-pos-ontonotes, batch 81 (22081): mcc: 0.6684, acc: 0.5064, precision: 0.8113, recall: 0.5599, f1: 0.6625, edges-pos-ontonotes_loss: 0.0331
09/16 07:58:08 AM: Update 22124: task edges-pos-ontonotes, batch 124 (22124): mcc: 0.6705, acc: 0.5076, precision: 0.8132, recall: 0.5619, f1: 0.6646, edges-pos-ontonotes_loss: 0.0329
09/16 07:58:18 AM: Update 22168: task edges-pos-ontonotes, batch 168 (22168): mcc: 0.6708, acc: 0.5083, precision: 0.8122, recall: 0.5631, f1: 0.6651, edges-pos-ontonotes_loss: 0.0329
09/16 07:58:28 AM: Update 22218: task edges-pos-ontonotes, batch 218 (22218): mcc: 0.6736, acc: 0.5118, precision: 0.8139, recall: 0.5666, f1: 0.6681, edges-pos-ontonotes_loss: 0.0325
09/16 07:58:38 AM: Update 22266: task edges-pos-ontonotes, batch 266 (22266): mcc: 0.6741, acc: 0.5122, precision: 0.8143, recall: 0.5671, f1: 0.6686, edges-pos-ontonotes_loss: 0.0324
09/16 07:58:48 AM: Update 22321: task edges-pos-ontonotes, batch 321 (22321): mcc: 0.6746, acc: 0.5126, precision: 0.8147, recall: 0.5677, f1: 0.6691, edges-pos-ontonotes_loss: 0.0324
09/16 07:58:59 AM: Update 22360: task edges-pos-ontonotes, batch 360 (22360): mcc: 0.6742, acc: 0.5123, precision: 0.8143, recall: 0.5673, f1: 0.6687, edges-pos-ontonotes_loss: 0.0324
09/16 07:59:09 AM: Update 22410: task edges-pos-ontonotes, batch 410 (22410): mcc: 0.6744, acc: 0.5125, precision: 0.8144, recall: 0.5676, f1: 0.6690, edges-pos-ontonotes_loss: 0.0324
09/16 07:59:19 AM: Update 22457: task edges-pos-ontonotes, batch 457 (22457): mcc: 0.6749, acc: 0.5132, precision: 0.8145, recall: 0.5684, f1: 0.6695, edges-pos-ontonotes_loss: 0.0324
09/16 07:59:29 AM: Update 22503: task edges-pos-ontonotes, batch 503 (22503): mcc: 0.6753, acc: 0.5138, precision: 0.8147, recall: 0.5689, f1: 0.6700, edges-pos-ontonotes_loss: 0.0324
09/16 07:59:39 AM: Update 22550: task edges-pos-ontonotes, batch 550 (22550): mcc: 0.6764, acc: 0.5152, precision: 0.8153, recall: 0.5702, f1: 0.6711, edges-pos-ontonotes_loss: 0.0323
09/16 07:59:49 AM: Update 22595: task edges-pos-ontonotes, batch 595 (22595): mcc: 0.6758, acc: 0.5146, precision: 0.8149, recall: 0.5695, f1: 0.6705, edges-pos-ontonotes_loss: 0.0323
09/16 08:00:01 AM: Update 22639: task edges-pos-ontonotes, batch 639 (22639): mcc: 0.6751, acc: 0.5138, precision: 0.8146, recall: 0.5685, f1: 0.6697, edges-pos-ontonotes_loss: 0.0324
09/16 08:00:11 AM: Update 22684: task edges-pos-ontonotes, batch 684 (22684): mcc: 0.6734, acc: 0.5117, precision: 0.8139, recall: 0.5662, f1: 0.6678, edges-pos-ontonotes_loss: 0.0323
09/16 08:00:21 AM: Update 22741: task edges-pos-ontonotes, batch 741 (22741): mcc: 0.6744, acc: 0.5129, precision: 0.8145, recall: 0.5675, f1: 0.6689, edges-pos-ontonotes_loss: 0.0320
09/16 08:00:31 AM: Update 22803: task edges-pos-ontonotes, batch 803 (22803): mcc: 0.6757, acc: 0.5143, precision: 0.8153, recall: 0.5690, f1: 0.6703, edges-pos-ontonotes_loss: 0.0318
09/16 08:00:42 AM: Update 22865: task edges-pos-ontonotes, batch 865 (22865): mcc: 0.6765, acc: 0.5154, precision: 0.8158, recall: 0.5701, f1: 0.6712, edges-pos-ontonotes_loss: 0.0315
09/16 08:00:52 AM: Update 22935: task edges-pos-ontonotes, batch 935 (22935): mcc: 0.6778, acc: 0.5169, precision: 0.8166, recall: 0.5716, f1: 0.6725, edges-pos-ontonotes_loss: 0.0312
09/16 08:01:02 AM: Update 22998: task edges-pos-ontonotes, batch 998 (22998): mcc: 0.6796, acc: 0.5190, precision: 0.8176, recall: 0.5739, f1: 0.6744, edges-pos-ontonotes_loss: 0.0310
09/16 08:01:02 AM: ***** Step 23000 / Validation 23 *****
09/16 08:01:02 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:01:02 AM: Validating...
09/16 08:01:12 AM: Evaluate: task edges-pos-ontonotes, batch 64 (157): mcc: 0.7681, acc: 0.6222, precision: 0.9331, recall: 0.6385, f1: 0.7582, edges-pos-ontonotes_loss: 0.0233
09/16 08:01:22 AM: Evaluate: task edges-pos-ontonotes, batch 113 (157): mcc: 0.7661, acc: 0.6201, precision: 0.9317, recall: 0.6362, f1: 0.7561, edges-pos-ontonotes_loss: 0.0233
09/16 08:01:32 AM: Updating LR scheduler:
09/16 08:01:32 AM: 	Best result seen so far for macro_avg: 0.761
09/16 08:01:32 AM: 	# validation passes without improvement: 0
09/16 08:01:32 AM: edges-pos-ontonotes_loss: training: 0.030973 validation: 0.023631
09/16 08:01:32 AM: macro_avg: validation: 0.749420
09/16 08:01:32 AM: micro_avg: validation: 0.000000
09/16 08:01:32 AM: edges-pos-ontonotes_mcc: training: 0.679648 validation: 0.760224
09/16 08:01:32 AM: edges-pos-ontonotes_acc: training: 0.519073 validation: 0.610972
09/16 08:01:32 AM: edges-pos-ontonotes_precision: training: 0.817720 validation: 0.930790
09/16 08:01:32 AM: edges-pos-ontonotes_recall: training: 0.573904 validation: 0.627205
09/16 08:01:32 AM: edges-pos-ontonotes_f1: training: 0.674454 validation: 0.749420
09/16 08:01:32 AM: Global learning rate: 5e-05
09/16 08:01:32 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 08:01:32 AM: Update 23004: task edges-pos-ontonotes, batch 4 (23004): mcc: 0.7571, acc: 0.6102, precision: 0.8733, recall: 0.6637, f1: 0.7542, edges-pos-ontonotes_loss: 0.0240
09/16 08:01:42 AM: Update 23096: task edges-pos-ontonotes, batch 96 (23096): mcc: 0.7543, acc: 0.6110, precision: 0.8604, recall: 0.6691, f1: 0.7528, edges-pos-ontonotes_loss: 0.0248
09/16 08:01:52 AM: Update 23187: task edges-pos-ontonotes, batch 187 (23187): mcc: 0.7574, acc: 0.6155, precision: 0.8623, recall: 0.6730, f1: 0.7560, edges-pos-ontonotes_loss: 0.0246
09/16 08:02:11 AM: Update 23265: task edges-pos-ontonotes, batch 265 (23265): mcc: 0.7562, acc: 0.6137, precision: 0.8617, recall: 0.6713, f1: 0.7547, edges-pos-ontonotes_loss: 0.0247
09/16 08:02:22 AM: Update 23355: task edges-pos-ontonotes, batch 355 (23355): mcc: 0.7577, acc: 0.6162, precision: 0.8636, recall: 0.6725, f1: 0.7561, edges-pos-ontonotes_loss: 0.0245
09/16 08:02:32 AM: Update 23459: task edges-pos-ontonotes, batch 459 (23459): mcc: 0.7594, acc: 0.6189, precision: 0.8650, recall: 0.6743, f1: 0.7578, edges-pos-ontonotes_loss: 0.0243
09/16 08:02:42 AM: Update 23565: task edges-pos-ontonotes, batch 565 (23565): mcc: 0.7594, acc: 0.6195, precision: 0.8650, recall: 0.6743, f1: 0.7578, edges-pos-ontonotes_loss: 0.0241
09/16 08:02:52 AM: Update 23673: task edges-pos-ontonotes, batch 673 (23673): mcc: 0.7540, acc: 0.6125, precision: 0.8623, recall: 0.6671, f1: 0.7522, edges-pos-ontonotes_loss: 0.0246
09/16 08:03:02 AM: Update 23795: task edges-pos-ontonotes, batch 795 (23795): mcc: 0.7498, acc: 0.6073, precision: 0.8594, recall: 0.6619, f1: 0.7478, edges-pos-ontonotes_loss: 0.0248
09/16 08:03:12 AM: Update 23892: task edges-pos-ontonotes, batch 892 (23892): mcc: 0.7442, acc: 0.6001, precision: 0.8559, recall: 0.6549, f1: 0.7421, edges-pos-ontonotes_loss: 0.0249
09/16 08:03:22 AM: Update 23952: task edges-pos-ontonotes, batch 952 (23952): mcc: 0.7343, acc: 0.5874, precision: 0.8495, recall: 0.6428, f1: 0.7318, edges-pos-ontonotes_loss: 0.0255
09/16 08:03:30 AM: ***** Step 24000 / Validation 24 *****
09/16 08:03:30 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:03:30 AM: Validating...
09/16 08:03:33 AM: Evaluate: task edges-pos-ontonotes, batch 15 (157): mcc: 0.7789, acc: 0.6503, precision: 0.9020, recall: 0.6792, f1: 0.7749, edges-pos-ontonotes_loss: 0.0224
09/16 08:03:43 AM: Evaluate: task edges-pos-ontonotes, batch 82 (157): mcc: 0.7851, acc: 0.6546, precision: 0.9143, recall: 0.6805, f1: 0.7803, edges-pos-ontonotes_loss: 0.0221
09/16 08:03:53 AM: Evaluate: task edges-pos-ontonotes, batch 129 (157): mcc: 0.7726, acc: 0.6370, precision: 0.9073, recall: 0.6644, f1: 0.7671, edges-pos-ontonotes_loss: 0.0229
09/16 08:03:59 AM: Best result seen so far for edges-pos-ontonotes.
09/16 08:03:59 AM: Best result seen so far for macro.
09/16 08:03:59 AM: Updating LR scheduler:
09/16 08:03:59 AM: 	Best result seen so far for macro_avg: 0.764
09/16 08:03:59 AM: 	# validation passes without improvement: 0
09/16 08:03:59 AM: edges-pos-ontonotes_loss: training: 0.025871 validation: 0.023078
09/16 08:03:59 AM: macro_avg: validation: 0.764382
09/16 08:03:59 AM: micro_avg: validation: 0.000000
09/16 08:03:59 AM: edges-pos-ontonotes_mcc: training: 0.728080 validation: 0.770187
09/16 08:03:59 AM: edges-pos-ontonotes_acc: training: 0.579454 validation: 0.632634
09/16 08:03:59 AM: edges-pos-ontonotes_precision: training: 0.845643 validation: 0.907705
09/16 08:03:59 AM: edges-pos-ontonotes_recall: training: 0.635105 validation: 0.660148
09/16 08:03:59 AM: edges-pos-ontonotes_f1: training: 0.725406 validation: 0.764382
09/16 08:03:59 AM: Global learning rate: 5e-05
09/16 08:03:59 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 08:04:03 AM: Update 24023: task edges-pos-ontonotes, batch 23 (24023): mcc: 0.6471, acc: 0.4809, precision: 0.7868, recall: 0.5420, f1: 0.6419, edges-pos-ontonotes_loss: 0.0343
09/16 08:04:13 AM: Update 24078: task edges-pos-ontonotes, batch 78 (24078): mcc: 0.6520, acc: 0.4846, precision: 0.7959, recall: 0.5435, f1: 0.6460, edges-pos-ontonotes_loss: 0.0338
09/16 08:04:23 AM: Update 24141: task edges-pos-ontonotes, batch 141 (24141): mcc: 0.6565, acc: 0.4895, precision: 0.7991, recall: 0.5488, f1: 0.6507, edges-pos-ontonotes_loss: 0.0333
09/16 08:04:34 AM: Update 24205: task edges-pos-ontonotes, batch 205 (24205): mcc: 0.6585, acc: 0.4921, precision: 0.8005, recall: 0.5511, f1: 0.6528, edges-pos-ontonotes_loss: 0.0333
09/16 08:04:44 AM: Update 24277: task edges-pos-ontonotes, batch 277 (24277): mcc: 0.6633, acc: 0.4978, precision: 0.8056, recall: 0.5554, f1: 0.6575, edges-pos-ontonotes_loss: 0.0321
09/16 08:04:54 AM: Update 24373: task edges-pos-ontonotes, batch 373 (24373): mcc: 0.6697, acc: 0.5057, precision: 0.8105, recall: 0.5624, f1: 0.6641, edges-pos-ontonotes_loss: 0.0310
09/16 08:05:04 AM: Update 24464: task edges-pos-ontonotes, batch 464 (24464): mcc: 0.6737, acc: 0.5110, precision: 0.8136, recall: 0.5669, f1: 0.6682, edges-pos-ontonotes_loss: 0.0303
09/16 08:05:14 AM: Update 24536: task edges-pos-ontonotes, batch 536 (24536): mcc: 0.6756, acc: 0.5135, precision: 0.8150, recall: 0.5690, f1: 0.6702, edges-pos-ontonotes_loss: 0.0301
09/16 08:05:24 AM: Update 24592: task edges-pos-ontonotes, batch 592 (24592): mcc: 0.6772, acc: 0.5158, precision: 0.8151, recall: 0.5717, f1: 0.6721, edges-pos-ontonotes_loss: 0.0301
09/16 08:05:34 AM: Update 24655: task edges-pos-ontonotes, batch 655 (24655): mcc: 0.6788, acc: 0.5180, precision: 0.8161, recall: 0.5736, f1: 0.6737, edges-pos-ontonotes_loss: 0.0300
09/16 08:05:44 AM: Update 24721: task edges-pos-ontonotes, batch 721 (24721): mcc: 0.6808, acc: 0.5208, precision: 0.8169, recall: 0.5765, f1: 0.6759, edges-pos-ontonotes_loss: 0.0298
09/16 08:05:55 AM: Update 24780: task edges-pos-ontonotes, batch 780 (24780): mcc: 0.6815, acc: 0.5216, precision: 0.8171, recall: 0.5774, f1: 0.6766, edges-pos-ontonotes_loss: 0.0298
09/16 08:06:05 AM: Update 24836: task edges-pos-ontonotes, batch 836 (24836): mcc: 0.6821, acc: 0.5223, precision: 0.8174, recall: 0.5783, f1: 0.6774, edges-pos-ontonotes_loss: 0.0298
09/16 08:06:15 AM: Update 24874: task edges-pos-ontonotes, batch 874 (24874): mcc: 0.6804, acc: 0.5203, precision: 0.8165, recall: 0.5760, f1: 0.6755, edges-pos-ontonotes_loss: 0.0299
09/16 08:06:25 AM: Update 24924: task edges-pos-ontonotes, batch 924 (24924): mcc: 0.6795, acc: 0.5191, precision: 0.8158, recall: 0.5750, f1: 0.6746, edges-pos-ontonotes_loss: 0.0300
09/16 08:06:35 AM: Update 24971: task edges-pos-ontonotes, batch 971 (24971): mcc: 0.6786, acc: 0.5181, precision: 0.8152, recall: 0.5739, f1: 0.6736, edges-pos-ontonotes_loss: 0.0302
09/16 08:06:41 AM: ***** Step 25000 / Validation 25 *****
09/16 08:06:41 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:06:41 AM: Validating...
09/16 08:06:46 AM: Evaluate: task edges-pos-ontonotes, batch 23 (157): mcc: 0.7749, acc: 0.6384, precision: 0.9218, recall: 0.6578, f1: 0.7678, edges-pos-ontonotes_loss: 0.0228
09/16 08:06:56 AM: Evaluate: task edges-pos-ontonotes, batch 81 (157): mcc: 0.7852, acc: 0.6506, precision: 0.9272, recall: 0.6711, f1: 0.7786, edges-pos-ontonotes_loss: 0.0219
09/16 08:07:06 AM: Evaluate: task edges-pos-ontonotes, batch 123 (157): mcc: 0.7763, acc: 0.6379, precision: 0.9251, recall: 0.6577, f1: 0.7688, edges-pos-ontonotes_loss: 0.0225
09/16 08:07:14 AM: Updating LR scheduler:
09/16 08:07:14 AM: 	Best result seen so far for macro_avg: 0.764
09/16 08:07:14 AM: 	# validation passes without improvement: 1
09/16 08:07:14 AM: edges-pos-ontonotes_loss: training: 0.030238 validation: 0.022945
09/16 08:07:14 AM: macro_avg: validation: 0.760859
09/16 08:07:14 AM: micro_avg: validation: 0.000000
09/16 08:07:14 AM: edges-pos-ontonotes_mcc: training: 0.678217 validation: 0.769211
09/16 08:07:14 AM: edges-pos-ontonotes_acc: training: 0.517563 validation: 0.626993
09/16 08:07:14 AM: edges-pos-ontonotes_precision: training: 0.814963 validation: 0.924097
09/16 08:07:14 AM: edges-pos-ontonotes_recall: training: 0.573502 validation: 0.646634
09/16 08:07:14 AM: edges-pos-ontonotes_f1: training: 0.673237 validation: 0.760859
09/16 08:07:14 AM: Global learning rate: 5e-05
09/16 08:07:14 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 08:07:16 AM: Update 25004: task edges-pos-ontonotes, batch 4 (25004): mcc: 0.6395, acc: 0.4677, precision: 0.8097, recall: 0.5141, f1: 0.6289, edges-pos-ontonotes_loss: 0.0364
09/16 08:07:26 AM: Update 25050: task edges-pos-ontonotes, batch 50 (25050): mcc: 0.6655, acc: 0.5038, precision: 0.8051, recall: 0.5594, f1: 0.6602, edges-pos-ontonotes_loss: 0.0330
09/16 08:07:36 AM: Update 25093: task edges-pos-ontonotes, batch 93 (25093): mcc: 0.6608, acc: 0.4972, precision: 0.8045, recall: 0.5521, f1: 0.6548, edges-pos-ontonotes_loss: 0.0334
09/16 08:07:46 AM: Update 25145: task edges-pos-ontonotes, batch 145 (25145): mcc: 0.6658, acc: 0.5032, precision: 0.8068, recall: 0.5587, f1: 0.6602, edges-pos-ontonotes_loss: 0.0330
09/16 08:07:59 AM: Update 25160: task edges-pos-ontonotes, batch 160 (25160): mcc: 0.6653, acc: 0.5023, precision: 0.8065, recall: 0.5580, f1: 0.6597, edges-pos-ontonotes_loss: 0.0330
09/16 08:08:09 AM: Update 25207: task edges-pos-ontonotes, batch 207 (25207): mcc: 0.6666, acc: 0.5039, precision: 0.8072, recall: 0.5598, f1: 0.6611, edges-pos-ontonotes_loss: 0.0328
09/16 08:08:20 AM: Update 25247: task edges-pos-ontonotes, batch 247 (25247): mcc: 0.6660, acc: 0.5029, precision: 0.8073, recall: 0.5586, f1: 0.6603, edges-pos-ontonotes_loss: 0.0329
09/16 08:08:30 AM: Update 25292: task edges-pos-ontonotes, batch 292 (25292): mcc: 0.6673, acc: 0.5047, precision: 0.8081, recall: 0.5603, f1: 0.6618, edges-pos-ontonotes_loss: 0.0329
09/16 08:08:40 AM: Update 25337: task edges-pos-ontonotes, batch 337 (25337): mcc: 0.6682, acc: 0.5057, precision: 0.8089, recall: 0.5612, f1: 0.6627, edges-pos-ontonotes_loss: 0.0329
09/16 08:08:50 AM: Update 25385: task edges-pos-ontonotes, batch 385 (25385): mcc: 0.6684, acc: 0.5059, precision: 0.8088, recall: 0.5615, f1: 0.6628, edges-pos-ontonotes_loss: 0.0329
09/16 08:09:00 AM: Update 25428: task edges-pos-ontonotes, batch 428 (25428): mcc: 0.6689, acc: 0.5064, precision: 0.8094, recall: 0.5619, f1: 0.6633, edges-pos-ontonotes_loss: 0.0329
09/16 08:09:11 AM: Update 25473: task edges-pos-ontonotes, batch 473 (25473): mcc: 0.6686, acc: 0.5061, precision: 0.8091, recall: 0.5616, f1: 0.6630, edges-pos-ontonotes_loss: 0.0328
09/16 08:09:21 AM: Update 25527: task edges-pos-ontonotes, batch 527 (25527): mcc: 0.6689, acc: 0.5062, precision: 0.8097, recall: 0.5617, f1: 0.6633, edges-pos-ontonotes_loss: 0.0328
09/16 08:09:31 AM: Update 25586: task edges-pos-ontonotes, batch 586 (25586): mcc: 0.6697, acc: 0.5072, precision: 0.8103, recall: 0.5627, f1: 0.6642, edges-pos-ontonotes_loss: 0.0327
09/16 08:09:41 AM: Update 25642: task edges-pos-ontonotes, batch 642 (25642): mcc: 0.6702, acc: 0.5078, precision: 0.8107, recall: 0.5632, f1: 0.6647, edges-pos-ontonotes_loss: 0.0327
09/16 08:09:52 AM: Update 25695: task edges-pos-ontonotes, batch 695 (25695): mcc: 0.6706, acc: 0.5082, precision: 0.8111, recall: 0.5635, f1: 0.6650, edges-pos-ontonotes_loss: 0.0327
09/16 08:10:02 AM: Update 25752: task edges-pos-ontonotes, batch 752 (25752): mcc: 0.6711, acc: 0.5090, precision: 0.8113, recall: 0.5643, f1: 0.6657, edges-pos-ontonotes_loss: 0.0327
09/16 08:10:12 AM: Update 25796: task edges-pos-ontonotes, batch 796 (25796): mcc: 0.6711, acc: 0.5089, precision: 0.8116, recall: 0.5641, f1: 0.6656, edges-pos-ontonotes_loss: 0.0326
09/16 08:10:22 AM: Update 25853: task edges-pos-ontonotes, batch 853 (25853): mcc: 0.6715, acc: 0.5095, precision: 0.8118, recall: 0.5646, f1: 0.6660, edges-pos-ontonotes_loss: 0.0326
09/16 08:10:32 AM: Update 25904: task edges-pos-ontonotes, batch 904 (25904): mcc: 0.6718, acc: 0.5098, precision: 0.8121, recall: 0.5650, f1: 0.6664, edges-pos-ontonotes_loss: 0.0326
09/16 08:10:42 AM: Update 25959: task edges-pos-ontonotes, batch 959 (25959): mcc: 0.6719, acc: 0.5099, precision: 0.8123, recall: 0.5650, f1: 0.6664, edges-pos-ontonotes_loss: 0.0326
09/16 08:10:50 AM: ***** Step 26000 / Validation 26 *****
09/16 08:10:50 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:10:50 AM: Validating...
09/16 08:10:52 AM: Evaluate: task edges-pos-ontonotes, batch 16 (157): mcc: 0.7727, acc: 0.6394, precision: 0.9072, recall: 0.6648, f1: 0.7673, edges-pos-ontonotes_loss: 0.0230
09/16 08:11:03 AM: Evaluate: task edges-pos-ontonotes, batch 74 (157): mcc: 0.7796, acc: 0.6445, precision: 0.9177, recall: 0.6687, f1: 0.7736, edges-pos-ontonotes_loss: 0.0228
09/16 08:11:13 AM: Evaluate: task edges-pos-ontonotes, batch 116 (157): mcc: 0.7746, acc: 0.6375, precision: 0.9161, recall: 0.6614, f1: 0.7682, edges-pos-ontonotes_loss: 0.0230
09/16 08:11:23 AM: Evaluate: task edges-pos-ontonotes, batch 157 (157): mcc: 0.7698, acc: 0.6296, precision: 0.9164, recall: 0.6531, f1: 0.7627, edges-pos-ontonotes_loss: 0.0232
09/16 08:11:23 AM: Updating LR scheduler:
09/16 08:11:23 AM: 	Best result seen so far for macro_avg: 0.764
09/16 08:11:23 AM: 	# validation passes without improvement: 2
09/16 08:11:23 AM: edges-pos-ontonotes_loss: training: 0.032587 validation: 0.023217
09/16 08:11:23 AM: macro_avg: validation: 0.762671
09/16 08:11:23 AM: micro_avg: validation: 0.000000
09/16 08:11:23 AM: edges-pos-ontonotes_mcc: training: 0.672439 validation: 0.769780
09/16 08:11:23 AM: edges-pos-ontonotes_acc: training: 0.510581 validation: 0.629597
09/16 08:11:23 AM: edges-pos-ontonotes_precision: training: 0.812555 validation: 0.916377
09/16 08:11:23 AM: edges-pos-ontonotes_recall: training: 0.565622 validation: 0.653121
09/16 08:11:23 AM: edges-pos-ontonotes_f1: training: 0.666966 validation: 0.762671
09/16 08:11:23 AM: Global learning rate: 5e-05
09/16 08:11:23 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 08:11:33 AM: Update 26042: task edges-pos-ontonotes, batch 42 (26042): mcc: 0.6762, acc: 0.5155, precision: 0.8117, recall: 0.5724, f1: 0.6714, edges-pos-ontonotes_loss: 0.0319
09/16 08:11:43 AM: Update 26090: task edges-pos-ontonotes, batch 90 (26090): mcc: 0.6811, acc: 0.5220, precision: 0.8144, recall: 0.5787, f1: 0.6766, edges-pos-ontonotes_loss: 0.0317
09/16 08:11:53 AM: Update 26132: task edges-pos-ontonotes, batch 132 (26132): mcc: 0.6761, acc: 0.5150, precision: 0.8150, recall: 0.5700, f1: 0.6709, edges-pos-ontonotes_loss: 0.0313
09/16 08:12:03 AM: Update 26182: task edges-pos-ontonotes, batch 182 (26182): mcc: 0.6790, acc: 0.5178, precision: 0.8188, recall: 0.5720, f1: 0.6735, edges-pos-ontonotes_loss: 0.0305
09/16 08:12:13 AM: Update 26230: task edges-pos-ontonotes, batch 230 (26230): mcc: 0.6792, acc: 0.5180, precision: 0.8186, recall: 0.5726, f1: 0.6739, edges-pos-ontonotes_loss: 0.0302
09/16 08:12:23 AM: Update 26281: task edges-pos-ontonotes, batch 281 (26281): mcc: 0.6808, acc: 0.5201, precision: 0.8196, recall: 0.5745, f1: 0.6755, edges-pos-ontonotes_loss: 0.0297
09/16 08:12:34 AM: Update 26329: task edges-pos-ontonotes, batch 329 (26329): mcc: 0.6809, acc: 0.5201, precision: 0.8196, recall: 0.5746, f1: 0.6756, edges-pos-ontonotes_loss: 0.0298
09/16 08:12:44 AM: Update 26382: task edges-pos-ontonotes, batch 382 (26382): mcc: 0.6831, acc: 0.5228, precision: 0.8208, recall: 0.5774, f1: 0.6779, edges-pos-ontonotes_loss: 0.0295
09/16 08:12:54 AM: Update 26429: task edges-pos-ontonotes, batch 429 (26429): mcc: 0.6847, acc: 0.5247, precision: 0.8216, recall: 0.5795, f1: 0.6796, edges-pos-ontonotes_loss: 0.0294
09/16 08:13:04 AM: Update 26493: task edges-pos-ontonotes, batch 493 (26493): mcc: 0.6915, acc: 0.5328, precision: 0.8256, recall: 0.5880, f1: 0.6868, edges-pos-ontonotes_loss: 0.0288
09/16 08:13:14 AM: Update 26558: task edges-pos-ontonotes, batch 558 (26558): mcc: 0.6966, acc: 0.5389, precision: 0.8286, recall: 0.5944, f1: 0.6922, edges-pos-ontonotes_loss: 0.0283
09/16 08:13:24 AM: Update 26623: task edges-pos-ontonotes, batch 623 (26623): mcc: 0.7016, acc: 0.5451, precision: 0.8314, recall: 0.6008, f1: 0.6975, edges-pos-ontonotes_loss: 0.0280
09/16 08:13:34 AM: Update 26687: task edges-pos-ontonotes, batch 687 (26687): mcc: 0.7058, acc: 0.5501, precision: 0.8339, recall: 0.6059, f1: 0.7019, edges-pos-ontonotes_loss: 0.0277
09/16 08:13:44 AM: Update 26743: task edges-pos-ontonotes, batch 743 (26743): mcc: 0.7085, acc: 0.5535, precision: 0.8357, recall: 0.6092, f1: 0.7047, edges-pos-ontonotes_loss: 0.0274
09/16 08:13:54 AM: Update 26813: task edges-pos-ontonotes, batch 813 (26813): mcc: 0.7116, acc: 0.5575, precision: 0.8377, recall: 0.6130, f1: 0.7079, edges-pos-ontonotes_loss: 0.0272
09/16 08:14:04 AM: Update 26874: task edges-pos-ontonotes, batch 874 (26874): mcc: 0.7139, acc: 0.5606, precision: 0.8390, recall: 0.6160, f1: 0.7104, edges-pos-ontonotes_loss: 0.0269
09/16 08:14:14 AM: Update 26946: task edges-pos-ontonotes, batch 946 (26946): mcc: 0.7165, acc: 0.5640, precision: 0.8405, recall: 0.6193, f1: 0.7131, edges-pos-ontonotes_loss: 0.0266
09/16 08:14:21 AM: ***** Step 27000 / Validation 27 *****
09/16 08:14:21 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:14:21 AM: Validating...
09/16 08:14:24 AM: Evaluate: task edges-pos-ontonotes, batch 18 (157): mcc: 0.7663, acc: 0.6256, precision: 0.9230, recall: 0.6426, f1: 0.7577, edges-pos-ontonotes_loss: 0.0234
09/16 08:14:35 AM: Evaluate: task edges-pos-ontonotes, batch 76 (157): mcc: 0.7805, acc: 0.6428, precision: 0.9301, recall: 0.6611, f1: 0.7728, edges-pos-ontonotes_loss: 0.0223
09/16 08:14:45 AM: Evaluate: task edges-pos-ontonotes, batch 118 (157): mcc: 0.7690, acc: 0.6268, precision: 0.9248, recall: 0.6457, f1: 0.7605, edges-pos-ontonotes_loss: 0.0230
09/16 08:14:54 AM: Updating LR scheduler:
09/16 08:14:54 AM: 	Best result seen so far for macro_avg: 0.764
09/16 08:14:54 AM: 	# validation passes without improvement: 3
09/16 08:14:54 AM: edges-pos-ontonotes_loss: training: 0.026381 validation: 0.023488
09/16 08:14:54 AM: macro_avg: validation: 0.752496
09/16 08:14:54 AM: micro_avg: validation: 0.000000
09/16 08:14:54 AM: edges-pos-ontonotes_mcc: training: 0.718531 validation: 0.761629
09/16 08:14:54 AM: edges-pos-ontonotes_acc: training: 0.566647 validation: 0.615533
09/16 08:14:54 AM: edges-pos-ontonotes_precision: training: 0.841794 validation: 0.921819
09/16 08:14:54 AM: edges-pos-ontonotes_recall: training: 0.621691 validation: 0.635724
09/16 08:14:54 AM: edges-pos-ontonotes_f1: training: 0.715191 validation: 0.752496
09/16 08:14:54 AM: Global learning rate: 5e-05
09/16 08:14:54 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 08:14:55 AM: Update 27003: task edges-pos-ontonotes, batch 3 (27003): mcc: 0.7727, acc: 0.6516, precision: 0.8737, recall: 0.6906, f1: 0.7714, edges-pos-ontonotes_loss: 0.0241
09/16 08:15:05 AM: Update 27053: task edges-pos-ontonotes, batch 53 (27053): mcc: 0.7393, acc: 0.5965, precision: 0.8564, recall: 0.6461, f1: 0.7365, edges-pos-ontonotes_loss: 0.0244
09/16 08:15:15 AM: Update 27127: task edges-pos-ontonotes, batch 127 (27127): mcc: 0.7219, acc: 0.5736, precision: 0.8455, recall: 0.6247, f1: 0.7185, edges-pos-ontonotes_loss: 0.0254
09/16 08:15:25 AM: Update 27202: task edges-pos-ontonotes, batch 202 (27202): mcc: 0.7196, acc: 0.5701, precision: 0.8426, recall: 0.6229, f1: 0.7163, edges-pos-ontonotes_loss: 0.0259
09/16 08:15:35 AM: Update 27281: task edges-pos-ontonotes, batch 281 (27281): mcc: 0.7232, acc: 0.5751, precision: 0.8434, recall: 0.6284, f1: 0.7202, edges-pos-ontonotes_loss: 0.0257
09/16 08:15:54 AM: Update 27351: task edges-pos-ontonotes, batch 351 (27351): mcc: 0.7200, acc: 0.5717, precision: 0.8415, recall: 0.6245, f1: 0.7169, edges-pos-ontonotes_loss: 0.0256
09/16 08:16:05 AM: Update 27392: task edges-pos-ontonotes, batch 392 (27392): mcc: 0.7031, acc: 0.5496, precision: 0.8303, recall: 0.6041, f1: 0.6994, edges-pos-ontonotes_loss: 0.0265
09/16 08:16:15 AM: Update 27439: task edges-pos-ontonotes, batch 439 (27439): mcc: 0.6945, acc: 0.5384, precision: 0.8243, recall: 0.5940, f1: 0.6904, edges-pos-ontonotes_loss: 0.0273
09/16 08:16:25 AM: Update 27486: task edges-pos-ontonotes, batch 486 (27486): mcc: 0.6900, acc: 0.5328, precision: 0.8210, recall: 0.5888, f1: 0.6858, edges-pos-ontonotes_loss: 0.0279
09/16 08:16:35 AM: Update 27534: task edges-pos-ontonotes, batch 534 (27534): mcc: 0.6863, acc: 0.5279, precision: 0.8184, recall: 0.5846, f1: 0.6820, edges-pos-ontonotes_loss: 0.0283
09/16 08:16:45 AM: Update 27596: task edges-pos-ontonotes, batch 596 (27596): mcc: 0.6835, acc: 0.5243, precision: 0.8164, recall: 0.5813, f1: 0.6791, edges-pos-ontonotes_loss: 0.0288
09/16 08:16:55 AM: Update 27653: task edges-pos-ontonotes, batch 653 (27653): mcc: 0.6784, acc: 0.5178, precision: 0.8137, recall: 0.5747, f1: 0.6736, edges-pos-ontonotes_loss: 0.0293
09/16 08:17:05 AM: Update 27720: task edges-pos-ontonotes, batch 720 (27720): mcc: 0.6779, acc: 0.5173, precision: 0.8137, recall: 0.5739, f1: 0.6731, edges-pos-ontonotes_loss: 0.0294
09/16 08:17:15 AM: Update 27815: task edges-pos-ontonotes, batch 815 (27815): mcc: 0.6795, acc: 0.5191, precision: 0.8157, recall: 0.5751, f1: 0.6746, edges-pos-ontonotes_loss: 0.0292
09/16 08:17:25 AM: Update 27911: task edges-pos-ontonotes, batch 911 (27911): mcc: 0.6818, acc: 0.5219, precision: 0.8178, recall: 0.5775, f1: 0.6769, edges-pos-ontonotes_loss: 0.0290
09/16 08:17:37 AM: Update 27994: task edges-pos-ontonotes, batch 994 (27994): mcc: 0.6829, acc: 0.5233, precision: 0.8187, recall: 0.5786, f1: 0.6780, edges-pos-ontonotes_loss: 0.0289
09/16 08:17:38 AM: ***** Step 28000 / Validation 28 *****
09/16 08:17:38 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:17:38 AM: Validating...
09/16 08:17:47 AM: Evaluate: task edges-pos-ontonotes, batch 61 (157): mcc: 0.7880, acc: 0.6548, precision: 0.9252, recall: 0.6772, f1: 0.7820, edges-pos-ontonotes_loss: 0.0217
09/16 08:17:57 AM: Evaluate: task edges-pos-ontonotes, batch 116 (157): mcc: 0.7782, acc: 0.6420, precision: 0.9182, recall: 0.6660, f1: 0.7720, edges-pos-ontonotes_loss: 0.0223
09/16 08:18:05 AM: Updating LR scheduler:
09/16 08:18:05 AM: 	Best result seen so far for macro_avg: 0.764
09/16 08:18:05 AM: 	# validation passes without improvement: 0
09/16 08:18:05 AM: edges-pos-ontonotes_loss: training: 0.028938 validation: 0.022976
09/16 08:18:05 AM: macro_avg: validation: 0.761767
09/16 08:18:05 AM: micro_avg: validation: 0.000000
09/16 08:18:05 AM: edges-pos-ontonotes_mcc: training: 0.682452 validation: 0.768887
09/16 08:18:05 AM: edges-pos-ontonotes_acc: training: 0.522682 validation: 0.627607
09/16 08:18:05 AM: edges-pos-ontonotes_precision: training: 0.818460 validation: 0.915601
09/16 08:18:05 AM: edges-pos-ontonotes_recall: training: 0.578045 validation: 0.652190
09/16 08:18:05 AM: edges-pos-ontonotes_f1: training: 0.677558 validation: 0.761767
09/16 08:18:05 AM: Global learning rate: 2.5e-05
09/16 08:18:05 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 08:18:07 AM: Update 28012: task edges-pos-ontonotes, batch 12 (28012): mcc: 0.6942, acc: 0.5396, precision: 0.8204, recall: 0.5964, f1: 0.6907, edges-pos-ontonotes_loss: 0.0289
09/16 08:18:17 AM: Update 28081: task edges-pos-ontonotes, batch 81 (28081): mcc: 0.6948, acc: 0.5387, precision: 0.8226, recall: 0.5958, f1: 0.6911, edges-pos-ontonotes_loss: 0.0293
09/16 08:18:27 AM: Update 28162: task edges-pos-ontonotes, batch 162 (28162): mcc: 0.6979, acc: 0.5429, precision: 0.8230, recall: 0.6007, f1: 0.6945, edges-pos-ontonotes_loss: 0.0289
09/16 08:18:37 AM: Update 28232: task edges-pos-ontonotes, batch 232 (28232): mcc: 0.6955, acc: 0.5397, precision: 0.8220, recall: 0.5974, f1: 0.6919, edges-pos-ontonotes_loss: 0.0291
09/16 08:18:48 AM: Update 28301: task edges-pos-ontonotes, batch 301 (28301): mcc: 0.6942, acc: 0.5376, precision: 0.8219, recall: 0.5953, f1: 0.6905, edges-pos-ontonotes_loss: 0.0291
09/16 08:18:58 AM: Update 28343: task edges-pos-ontonotes, batch 343 (28343): mcc: 0.6863, acc: 0.5276, precision: 0.8177, recall: 0.5851, f1: 0.6821, edges-pos-ontonotes_loss: 0.0297
09/16 08:19:08 AM: Update 28403: task edges-pos-ontonotes, batch 403 (28403): mcc: 0.6829, acc: 0.5236, precision: 0.8151, recall: 0.5812, f1: 0.6786, edges-pos-ontonotes_loss: 0.0302
09/16 08:19:18 AM: Update 28455: task edges-pos-ontonotes, batch 455 (28455): mcc: 0.6791, acc: 0.5187, precision: 0.8132, recall: 0.5762, f1: 0.6745, edges-pos-ontonotes_loss: 0.0305
09/16 08:19:28 AM: Update 28518: task edges-pos-ontonotes, batch 518 (28518): mcc: 0.6782, acc: 0.5174, precision: 0.8126, recall: 0.5751, f1: 0.6735, edges-pos-ontonotes_loss: 0.0308
09/16 08:19:38 AM: Update 28574: task edges-pos-ontonotes, batch 574 (28574): mcc: 0.6762, acc: 0.5148, precision: 0.8115, recall: 0.5727, f1: 0.6715, edges-pos-ontonotes_loss: 0.0310
09/16 08:19:48 AM: Update 28621: task edges-pos-ontonotes, batch 621 (28621): mcc: 0.6750, acc: 0.5134, precision: 0.8108, recall: 0.5712, f1: 0.6702, edges-pos-ontonotes_loss: 0.0311
09/16 08:19:58 AM: Update 28673: task edges-pos-ontonotes, batch 673 (28673): mcc: 0.6734, acc: 0.5115, precision: 0.8096, recall: 0.5694, f1: 0.6686, edges-pos-ontonotes_loss: 0.0314
09/16 08:20:08 AM: Update 28730: task edges-pos-ontonotes, batch 730 (28730): mcc: 0.6735, acc: 0.5116, precision: 0.8096, recall: 0.5694, f1: 0.6686, edges-pos-ontonotes_loss: 0.0314
09/16 08:20:18 AM: Update 28786: task edges-pos-ontonotes, batch 786 (28786): mcc: 0.6733, acc: 0.5113, precision: 0.8098, recall: 0.5690, f1: 0.6683, edges-pos-ontonotes_loss: 0.0315
09/16 08:20:28 AM: Update 28842: task edges-pos-ontonotes, batch 842 (28842): mcc: 0.6732, acc: 0.5113, precision: 0.8098, recall: 0.5689, f1: 0.6683, edges-pos-ontonotes_loss: 0.0316
09/16 08:20:39 AM: Update 28898: task edges-pos-ontonotes, batch 898 (28898): mcc: 0.6730, acc: 0.5111, precision: 0.8098, recall: 0.5685, f1: 0.6681, edges-pos-ontonotes_loss: 0.0317
09/16 08:20:49 AM: Update 28937: task edges-pos-ontonotes, batch 937 (28937): mcc: 0.6719, acc: 0.5096, precision: 0.8093, recall: 0.5670, f1: 0.6668, edges-pos-ontonotes_loss: 0.0318
09/16 08:20:59 AM: Update 28991: task edges-pos-ontonotes, batch 991 (28991): mcc: 0.6715, acc: 0.5093, precision: 0.8092, recall: 0.5665, f1: 0.6665, edges-pos-ontonotes_loss: 0.0318
09/16 08:21:01 AM: ***** Step 29000 / Validation 29 *****
09/16 08:21:01 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:21:01 AM: Validating...
09/16 08:21:09 AM: Evaluate: task edges-pos-ontonotes, batch 58 (157): mcc: 0.7819, acc: 0.6465, precision: 0.9222, recall: 0.6692, f1: 0.7756, edges-pos-ontonotes_loss: 0.0224
09/16 08:21:19 AM: Evaluate: task edges-pos-ontonotes, batch 113 (157): mcc: 0.7794, acc: 0.6437, precision: 0.9202, recall: 0.6666, f1: 0.7731, edges-pos-ontonotes_loss: 0.0224
09/16 08:21:36 AM: Evaluate: task edges-pos-ontonotes, batch 154 (157): mcc: 0.7728, acc: 0.6336, precision: 0.9189, recall: 0.6564, f1: 0.7658, edges-pos-ontonotes_loss: 0.0228
09/16 08:21:37 AM: Best result seen so far for edges-pos-ontonotes.
09/16 08:21:37 AM: Best result seen so far for macro.
09/16 08:21:37 AM: Updating LR scheduler:
09/16 08:21:37 AM: 	Best result seen so far for macro_avg: 0.765
09/16 08:21:37 AM: 	# validation passes without improvement: 0
09/16 08:21:37 AM: edges-pos-ontonotes_loss: training: 0.031843 validation: 0.022875
09/16 08:21:37 AM: macro_avg: validation: 0.765190
09/16 08:21:37 AM: micro_avg: validation: 0.000000
09/16 08:21:37 AM: edges-pos-ontonotes_mcc: training: 0.671430 validation: 0.772366
09/16 08:21:37 AM: edges-pos-ontonotes_acc: training: 0.509104 validation: 0.632666
09/16 08:21:37 AM: edges-pos-ontonotes_precision: training: 0.809104 validation: 0.919277
09/16 08:21:37 AM: edges-pos-ontonotes_recall: training: 0.566410 validation: 0.655344
09/16 08:21:37 AM: edges-pos-ontonotes_f1: training: 0.666347 validation: 0.765190
09/16 08:21:37 AM: Global learning rate: 2.5e-05
09/16 08:21:37 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 08:21:46 AM: Update 29059: task edges-pos-ontonotes, batch 59 (29059): mcc: 0.6833, acc: 0.5243, precision: 0.8160, recall: 0.5812, f1: 0.6788, edges-pos-ontonotes_loss: 0.0321
09/16 08:21:56 AM: Update 29117: task edges-pos-ontonotes, batch 117 (29117): mcc: 0.6804, acc: 0.5206, precision: 0.8160, recall: 0.5764, f1: 0.6756, edges-pos-ontonotes_loss: 0.0323
09/16 08:22:06 AM: Update 29173: task edges-pos-ontonotes, batch 173 (29173): mcc: 0.6776, acc: 0.5166, precision: 0.8146, recall: 0.5727, f1: 0.6726, edges-pos-ontonotes_loss: 0.0322
09/16 08:22:16 AM: Update 29230: task edges-pos-ontonotes, batch 230 (29230): mcc: 0.6776, acc: 0.5167, precision: 0.8148, recall: 0.5726, f1: 0.6726, edges-pos-ontonotes_loss: 0.0321
09/16 08:22:26 AM: Update 29271: task edges-pos-ontonotes, batch 271 (29271): mcc: 0.6761, acc: 0.5150, precision: 0.8143, recall: 0.5705, f1: 0.6709, edges-pos-ontonotes_loss: 0.0322
09/16 08:22:36 AM: Update 29321: task edges-pos-ontonotes, batch 321 (29321): mcc: 0.6740, acc: 0.5124, precision: 0.8129, recall: 0.5679, f1: 0.6687, edges-pos-ontonotes_loss: 0.0324
09/16 08:22:47 AM: Update 29380: task edges-pos-ontonotes, batch 380 (29380): mcc: 0.6746, acc: 0.5133, precision: 0.8133, recall: 0.5686, f1: 0.6693, edges-pos-ontonotes_loss: 0.0325
09/16 08:22:57 AM: Update 29435: task edges-pos-ontonotes, batch 435 (29435): mcc: 0.6747, acc: 0.5136, precision: 0.8133, recall: 0.5689, f1: 0.6695, edges-pos-ontonotes_loss: 0.0325
09/16 08:23:07 AM: Update 29495: task edges-pos-ontonotes, batch 495 (29495): mcc: 0.6755, acc: 0.5146, precision: 0.8138, recall: 0.5699, f1: 0.6703, edges-pos-ontonotes_loss: 0.0324
09/16 08:23:17 AM: Update 29550: task edges-pos-ontonotes, batch 550 (29550): mcc: 0.6759, acc: 0.5149, precision: 0.8139, recall: 0.5703, f1: 0.6707, edges-pos-ontonotes_loss: 0.0324
09/16 08:23:27 AM: Update 29599: task edges-pos-ontonotes, batch 599 (29599): mcc: 0.6745, acc: 0.5131, precision: 0.8135, recall: 0.5684, f1: 0.6692, edges-pos-ontonotes_loss: 0.0322
09/16 08:23:37 AM: Update 29663: task edges-pos-ontonotes, batch 663 (29663): mcc: 0.6751, acc: 0.5135, precision: 0.8146, recall: 0.5685, f1: 0.6696, edges-pos-ontonotes_loss: 0.0320
09/16 08:23:48 AM: Update 29740: task edges-pos-ontonotes, batch 740 (29740): mcc: 0.6768, acc: 0.5155, precision: 0.8158, recall: 0.5705, f1: 0.6714, edges-pos-ontonotes_loss: 0.0315
09/16 08:23:58 AM: Update 29807: task edges-pos-ontonotes, batch 807 (29807): mcc: 0.6773, acc: 0.5161, precision: 0.8165, recall: 0.5709, f1: 0.6719, edges-pos-ontonotes_loss: 0.0312
09/16 08:24:08 AM: Update 29872: task edges-pos-ontonotes, batch 872 (29872): mcc: 0.6783, acc: 0.5173, precision: 0.8172, recall: 0.5720, f1: 0.6730, edges-pos-ontonotes_loss: 0.0311
09/16 08:24:18 AM: Update 29966: task edges-pos-ontonotes, batch 966 (29966): mcc: 0.6830, acc: 0.5228, precision: 0.8201, recall: 0.5777, f1: 0.6779, edges-pos-ontonotes_loss: 0.0305
09/16 08:24:22 AM: ***** Step 30000 / Validation 30 *****
09/16 08:24:22 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:24:22 AM: Validating...
09/16 08:24:28 AM: Evaluate: task edges-pos-ontonotes, batch 46 (157): mcc: 0.7676, acc: 0.6223, precision: 0.9323, recall: 0.6382, f1: 0.7577, edges-pos-ontonotes_loss: 0.0231
09/16 08:24:38 AM: Evaluate: task edges-pos-ontonotes, batch 106 (157): mcc: 0.7728, acc: 0.6302, precision: 0.9320, recall: 0.6470, f1: 0.7638, edges-pos-ontonotes_loss: 0.0225
09/16 08:24:48 AM: Evaluate: task edges-pos-ontonotes, batch 152 (157): mcc: 0.7633, acc: 0.6159, precision: 0.9311, recall: 0.6319, f1: 0.7529, edges-pos-ontonotes_loss: 0.0232
09/16 08:24:49 AM: Updating LR scheduler:
09/16 08:24:49 AM: 	Best result seen so far for macro_avg: 0.765
09/16 08:24:49 AM: 	# validation passes without improvement: 1
09/16 08:24:49 AM: edges-pos-ontonotes_loss: training: 0.030270 validation: 0.023219
09/16 08:24:49 AM: macro_avg: validation: 0.752254
09/16 08:24:49 AM: micro_avg: validation: 0.000000
09/16 08:24:49 AM: edges-pos-ontonotes_mcc: training: 0.684710 validation: 0.762784
09/16 08:24:49 AM: edges-pos-ontonotes_acc: training: 0.524930 validation: 0.614940
09/16 08:24:49 AM: edges-pos-ontonotes_precision: training: 0.821199 validation: 0.931624
09/16 08:24:49 AM: edges-pos-ontonotes_recall: training: 0.579836 validation: 0.630803
09/16 08:24:49 AM: edges-pos-ontonotes_f1: training: 0.679727 validation: 0.752254
09/16 08:24:49 AM: Global learning rate: 2.5e-05
09/16 08:24:49 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 08:24:58 AM: Update 30085: task edges-pos-ontonotes, batch 85 (30085): mcc: 0.7609, acc: 0.6202, precision: 0.8650, recall: 0.6770, f1: 0.7595, edges-pos-ontonotes_loss: 0.0245
09/16 08:25:09 AM: Update 30176: task edges-pos-ontonotes, batch 176 (30176): mcc: 0.7604, acc: 0.6189, precision: 0.8645, recall: 0.6764, f1: 0.7590, edges-pos-ontonotes_loss: 0.0245
09/16 08:25:19 AM: Update 30266: task edges-pos-ontonotes, batch 266 (30266): mcc: 0.7579, acc: 0.6167, precision: 0.8638, recall: 0.6726, f1: 0.7563, edges-pos-ontonotes_loss: 0.0243
09/16 08:25:29 AM: Update 30375: task edges-pos-ontonotes, batch 375 (30375): mcc: 0.7595, acc: 0.6194, precision: 0.8654, recall: 0.6742, f1: 0.7579, edges-pos-ontonotes_loss: 0.0240
09/16 08:25:39 AM: Update 30494: task edges-pos-ontonotes, batch 494 (30494): mcc: 0.7628, acc: 0.6244, precision: 0.8672, recall: 0.6786, f1: 0.7614, edges-pos-ontonotes_loss: 0.0236
09/16 08:25:49 AM: Update 30609: task edges-pos-ontonotes, batch 609 (30609): mcc: 0.7550, acc: 0.6140, precision: 0.8635, recall: 0.6678, f1: 0.7532, edges-pos-ontonotes_loss: 0.0241
09/16 08:25:59 AM: Update 30742: task edges-pos-ontonotes, batch 742 (30742): mcc: 0.7494, acc: 0.6067, precision: 0.8601, recall: 0.6608, f1: 0.7474, edges-pos-ontonotes_loss: 0.0244
09/16 08:26:09 AM: Update 30835: task edges-pos-ontonotes, batch 835 (30835): mcc: 0.7424, acc: 0.5979, precision: 0.8558, recall: 0.6520, f1: 0.7401, edges-pos-ontonotes_loss: 0.0247
09/16 08:26:19 AM: Update 30902: task edges-pos-ontonotes, batch 902 (30902): mcc: 0.7319, acc: 0.5846, precision: 0.8488, recall: 0.6393, f1: 0.7293, edges-pos-ontonotes_loss: 0.0253
09/16 08:26:29 AM: Update 30962: task edges-pos-ontonotes, batch 962 (30962): mcc: 0.7232, acc: 0.5736, precision: 0.8432, recall: 0.6286, f1: 0.7202, edges-pos-ontonotes_loss: 0.0258
09/16 08:26:35 AM: ***** Step 31000 / Validation 31 *****
09/16 08:26:35 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:26:35 AM: Validating...
09/16 08:26:39 AM: Evaluate: task edges-pos-ontonotes, batch 27 (157): mcc: 0.7808, acc: 0.6489, precision: 0.9129, recall: 0.6743, f1: 0.7757, edges-pos-ontonotes_loss: 0.0224
09/16 08:26:49 AM: Evaluate: task edges-pos-ontonotes, batch 93 (157): mcc: 0.7874, acc: 0.6570, precision: 0.9182, recall: 0.6816, f1: 0.7824, edges-pos-ontonotes_loss: 0.0218
09/16 08:26:59 AM: Evaluate: task edges-pos-ontonotes, batch 140 (157): mcc: 0.7741, acc: 0.6377, precision: 0.9121, recall: 0.6635, f1: 0.7682, edges-pos-ontonotes_loss: 0.0226
09/16 08:27:03 AM: Best result seen so far for edges-pos-ontonotes.
09/16 08:27:03 AM: Best result seen so far for macro.
09/16 08:27:03 AM: Updating LR scheduler:
09/16 08:27:03 AM: 	Best result seen so far for macro_avg: 0.768
09/16 08:27:03 AM: 	# validation passes without improvement: 0
09/16 08:27:03 AM: edges-pos-ontonotes_loss: training: 0.026100 validation: 0.022684
09/16 08:27:03 AM: macro_avg: validation: 0.768404
09/16 08:27:03 AM: micro_avg: validation: 0.000000
09/16 08:27:03 AM: edges-pos-ontonotes_mcc: training: 0.719180 validation: 0.774502
09/16 08:27:03 AM: edges-pos-ontonotes_acc: training: 0.568339 validation: 0.637608
09/16 08:27:03 AM: edges-pos-ontonotes_precision: training: 0.840773 validation: 0.913829
09/16 08:27:03 AM: edges-pos-ontonotes_recall: training: 0.623568 validation: 0.662910
09/16 08:27:03 AM: edges-pos-ontonotes_f1: training: 0.716061 validation: 0.768404
09/16 08:27:03 AM: Global learning rate: 2.5e-05
09/16 08:27:03 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 08:27:10 AM: Update 31039: task edges-pos-ontonotes, batch 39 (31039): mcc: 0.6656, acc: 0.5022, precision: 0.8029, recall: 0.5611, f1: 0.6606, edges-pos-ontonotes_loss: 0.0331
09/16 08:27:20 AM: Update 31098: task edges-pos-ontonotes, batch 98 (31098): mcc: 0.6633, acc: 0.4985, precision: 0.8030, recall: 0.5572, f1: 0.6579, edges-pos-ontonotes_loss: 0.0334
09/16 08:27:30 AM: Update 31149: task edges-pos-ontonotes, batch 149 (31149): mcc: 0.6632, acc: 0.4981, precision: 0.8032, recall: 0.5570, f1: 0.6578, edges-pos-ontonotes_loss: 0.0332
09/16 08:27:40 AM: Update 31251: task edges-pos-ontonotes, batch 251 (31251): mcc: 0.6767, acc: 0.5149, precision: 0.8139, recall: 0.5718, f1: 0.6717, edges-pos-ontonotes_loss: 0.0308
09/16 08:27:50 AM: Update 31339: task edges-pos-ontonotes, batch 339 (31339): mcc: 0.6779, acc: 0.5161, precision: 0.8167, recall: 0.5717, f1: 0.6726, edges-pos-ontonotes_loss: 0.0302
09/16 08:28:00 AM: Update 31435: task edges-pos-ontonotes, batch 435 (31435): mcc: 0.6828, acc: 0.5224, precision: 0.8202, recall: 0.5775, f1: 0.6778, edges-pos-ontonotes_loss: 0.0295
09/16 08:28:12 AM: Update 31454: task edges-pos-ontonotes, batch 454 (31454): mcc: 0.6831, acc: 0.5228, precision: 0.8206, recall: 0.5776, f1: 0.6780, edges-pos-ontonotes_loss: 0.0295
09/16 08:28:22 AM: Update 31526: task edges-pos-ontonotes, batch 526 (31526): mcc: 0.6850, acc: 0.5254, precision: 0.8204, recall: 0.5809, f1: 0.6802, edges-pos-ontonotes_loss: 0.0294
09/16 08:28:32 AM: Update 31596: task edges-pos-ontonotes, batch 596 (31596): mcc: 0.6852, acc: 0.5257, precision: 0.8203, recall: 0.5814, f1: 0.6805, edges-pos-ontonotes_loss: 0.0294
09/16 08:28:42 AM: Update 31673: task edges-pos-ontonotes, batch 673 (31673): mcc: 0.6869, acc: 0.5279, precision: 0.8209, recall: 0.5837, f1: 0.6823, edges-pos-ontonotes_loss: 0.0293
09/16 08:28:52 AM: Update 31746: task edges-pos-ontonotes, batch 746 (31746): mcc: 0.6876, acc: 0.5288, precision: 0.8210, recall: 0.5847, f1: 0.6830, edges-pos-ontonotes_loss: 0.0293
09/16 08:29:02 AM: Update 31796: task edges-pos-ontonotes, batch 796 (31796): mcc: 0.6859, acc: 0.5269, precision: 0.8197, recall: 0.5829, f1: 0.6813, edges-pos-ontonotes_loss: 0.0295
09/16 08:29:12 AM: Update 31854: task edges-pos-ontonotes, batch 854 (31854): mcc: 0.6834, acc: 0.5239, precision: 0.8180, recall: 0.5801, f1: 0.6788, edges-pos-ontonotes_loss: 0.0297
09/16 08:29:22 AM: Update 31911: task edges-pos-ontonotes, batch 911 (31911): mcc: 0.6820, acc: 0.5221, precision: 0.8167, recall: 0.5785, f1: 0.6773, edges-pos-ontonotes_loss: 0.0299
09/16 08:29:32 AM: Update 31970: task edges-pos-ontonotes, batch 970 (31970): mcc: 0.6809, acc: 0.5208, precision: 0.8158, recall: 0.5773, f1: 0.6761, edges-pos-ontonotes_loss: 0.0301
09/16 08:29:39 AM: ***** Step 32000 / Validation 32 *****
09/16 08:29:39 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:29:39 AM: Validating...
09/16 08:29:43 AM: Evaluate: task edges-pos-ontonotes, batch 28 (157): mcc: 0.7800, acc: 0.6460, precision: 0.9186, recall: 0.6687, f1: 0.7739, edges-pos-ontonotes_loss: 0.0223
09/16 08:29:53 AM: Evaluate: task edges-pos-ontonotes, batch 94 (157): mcc: 0.7864, acc: 0.6543, precision: 0.9212, recall: 0.6775, f1: 0.7808, edges-pos-ontonotes_loss: 0.0218
09/16 08:30:03 AM: Evaluate: task edges-pos-ontonotes, batch 141 (157): mcc: 0.7734, acc: 0.6353, precision: 0.9167, recall: 0.6590, f1: 0.7668, edges-pos-ontonotes_loss: 0.0226
09/16 08:30:06 AM: Updating LR scheduler:
09/16 08:30:06 AM: 	Best result seen so far for macro_avg: 0.768
09/16 08:30:06 AM: 	# validation passes without improvement: 1
09/16 08:30:06 AM: edges-pos-ontonotes_loss: training: 0.030203 validation: 0.022666
09/16 08:30:06 AM: macro_avg: validation: 0.766519
09/16 08:30:06 AM: micro_avg: validation: 0.000000
09/16 08:30:06 AM: edges-pos-ontonotes_mcc: training: 0.679664 validation: 0.773401
09/16 08:30:06 AM: edges-pos-ontonotes_acc: training: 0.519312 validation: 0.634592
09/16 08:30:06 AM: edges-pos-ontonotes_precision: training: 0.815224 validation: 0.918252
09/16 08:30:06 AM: edges-pos-ontonotes_recall: training: 0.575727 validation: 0.657820
09/16 08:30:06 AM: edges-pos-ontonotes_f1: training: 0.674857 validation: 0.766519
09/16 08:30:06 AM: Global learning rate: 2.5e-05
09/16 08:30:06 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 08:30:13 AM: Update 32043: task edges-pos-ontonotes, batch 43 (32043): mcc: 0.6722, acc: 0.5129, precision: 0.8057, recall: 0.5703, f1: 0.6678, edges-pos-ontonotes_loss: 0.0321
09/16 08:30:23 AM: Update 32091: task edges-pos-ontonotes, batch 91 (32091): mcc: 0.6659, acc: 0.5048, precision: 0.8031, recall: 0.5614, f1: 0.6609, edges-pos-ontonotes_loss: 0.0326
09/16 08:30:33 AM: Update 32147: task edges-pos-ontonotes, batch 147 (32147): mcc: 0.6681, acc: 0.5064, precision: 0.8061, recall: 0.5630, f1: 0.6630, edges-pos-ontonotes_loss: 0.0326
09/16 08:30:43 AM: Update 32202: task edges-pos-ontonotes, batch 202 (32202): mcc: 0.6685, acc: 0.5068, precision: 0.8065, recall: 0.5634, f1: 0.6633, edges-pos-ontonotes_loss: 0.0326
09/16 08:30:53 AM: Update 32257: task edges-pos-ontonotes, batch 257 (32257): mcc: 0.6687, acc: 0.5069, precision: 0.8072, recall: 0.5632, f1: 0.6635, edges-pos-ontonotes_loss: 0.0327
09/16 08:31:03 AM: Update 32315: task edges-pos-ontonotes, batch 315 (32315): mcc: 0.6698, acc: 0.5081, precision: 0.8078, recall: 0.5647, f1: 0.6647, edges-pos-ontonotes_loss: 0.0326
09/16 08:31:13 AM: Update 32365: task edges-pos-ontonotes, batch 365 (32365): mcc: 0.6694, acc: 0.5075, precision: 0.8079, recall: 0.5639, f1: 0.6642, edges-pos-ontonotes_loss: 0.0327
09/16 08:31:23 AM: Update 32404: task edges-pos-ontonotes, batch 404 (32404): mcc: 0.6684, acc: 0.5063, precision: 0.8075, recall: 0.5626, f1: 0.6631, edges-pos-ontonotes_loss: 0.0328
09/16 08:31:33 AM: Update 32465: task edges-pos-ontonotes, batch 465 (32465): mcc: 0.6697, acc: 0.5081, precision: 0.8081, recall: 0.5643, f1: 0.6645, edges-pos-ontonotes_loss: 0.0327
09/16 08:31:43 AM: Update 32516: task edges-pos-ontonotes, batch 516 (32516): mcc: 0.6695, acc: 0.5078, precision: 0.8082, recall: 0.5639, f1: 0.6643, edges-pos-ontonotes_loss: 0.0328
09/16 08:31:53 AM: Update 32569: task edges-pos-ontonotes, batch 569 (32569): mcc: 0.6699, acc: 0.5082, precision: 0.8086, recall: 0.5642, f1: 0.6646, edges-pos-ontonotes_loss: 0.0328
09/16 08:32:04 AM: Update 32628: task edges-pos-ontonotes, batch 628 (32628): mcc: 0.6706, acc: 0.5091, precision: 0.8091, recall: 0.5651, f1: 0.6654, edges-pos-ontonotes_loss: 0.0327
09/16 08:32:14 AM: Update 32685: task edges-pos-ontonotes, batch 685 (32685): mcc: 0.6714, acc: 0.5099, precision: 0.8098, recall: 0.5659, f1: 0.6662, edges-pos-ontonotes_loss: 0.0326
09/16 08:32:24 AM: Update 32730: task edges-pos-ontonotes, batch 730 (32730): mcc: 0.6715, acc: 0.5101, precision: 0.8101, recall: 0.5659, f1: 0.6663, edges-pos-ontonotes_loss: 0.0326
09/16 08:32:34 AM: Update 32789: task edges-pos-ontonotes, batch 789 (32789): mcc: 0.6723, acc: 0.5109, precision: 0.8105, recall: 0.5669, f1: 0.6671, edges-pos-ontonotes_loss: 0.0325
09/16 08:32:44 AM: Update 32847: task edges-pos-ontonotes, batch 847 (32847): mcc: 0.6727, acc: 0.5115, precision: 0.8108, recall: 0.5674, f1: 0.6676, edges-pos-ontonotes_loss: 0.0325
09/16 08:32:54 AM: Update 32905: task edges-pos-ontonotes, batch 905 (32905): mcc: 0.6731, acc: 0.5121, precision: 0.8110, recall: 0.5679, f1: 0.6680, edges-pos-ontonotes_loss: 0.0325
09/16 08:33:05 AM: Update 32959: task edges-pos-ontonotes, batch 959 (32959): mcc: 0.6734, acc: 0.5124, precision: 0.8112, recall: 0.5682, f1: 0.6683, edges-pos-ontonotes_loss: 0.0325
09/16 08:33:13 AM: ***** Step 33000 / Validation 33 *****
09/16 08:33:13 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:33:13 AM: Validating...
09/16 08:33:15 AM: Evaluate: task edges-pos-ontonotes, batch 12 (157): mcc: 0.7825, acc: 0.6546, precision: 0.9094, recall: 0.6798, f1: 0.7780, edges-pos-ontonotes_loss: 0.0224
09/16 08:33:25 AM: Evaluate: task edges-pos-ontonotes, batch 81 (157): mcc: 0.7857, acc: 0.6529, precision: 0.9210, recall: 0.6765, f1: 0.7801, edges-pos-ontonotes_loss: 0.0222
09/16 08:33:35 AM: Evaluate: task edges-pos-ontonotes, batch 129 (157): mcc: 0.7747, acc: 0.6375, precision: 0.9175, recall: 0.6605, f1: 0.7681, edges-pos-ontonotes_loss: 0.0228
09/16 08:33:41 AM: Updating LR scheduler:
09/16 08:33:41 AM: 	Best result seen so far for macro_avg: 0.768
09/16 08:33:41 AM: 	# validation passes without improvement: 2
09/16 08:33:41 AM: edges-pos-ontonotes_loss: training: 0.032506 validation: 0.022885
09/16 08:33:41 AM: macro_avg: validation: 0.766161
09/16 08:33:41 AM: micro_avg: validation: 0.000000
09/16 08:33:41 AM: edges-pos-ontonotes_mcc: training: 0.673215 validation: 0.773188
09/16 08:33:41 AM: edges-pos-ontonotes_acc: training: 0.512156 validation: 0.634253
09/16 08:33:41 AM: edges-pos-ontonotes_precision: training: 0.811177 validation: 0.919043
09/16 08:33:41 AM: edges-pos-ontonotes_recall: training: 0.567895 validation: 0.656889
09/16 08:33:41 AM: edges-pos-ontonotes_f1: training: 0.668077 validation: 0.766161
09/16 08:33:41 AM: Global learning rate: 2.5e-05
09/16 08:33:41 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 08:33:54 AM: Update 33019: task edges-pos-ontonotes, batch 19 (33019): mcc: 0.6509, acc: 0.4851, precision: 0.7992, recall: 0.5396, f1: 0.6442, edges-pos-ontonotes_loss: 0.0332
09/16 08:34:05 AM: Update 33082: task edges-pos-ontonotes, batch 82 (33082): mcc: 0.6709, acc: 0.5069, precision: 0.8132, recall: 0.5625, f1: 0.6650, edges-pos-ontonotes_loss: 0.0298
09/16 08:34:15 AM: Update 33137: task edges-pos-ontonotes, batch 137 (33137): mcc: 0.6740, acc: 0.5108, precision: 0.8172, recall: 0.5649, f1: 0.6680, edges-pos-ontonotes_loss: 0.0295
09/16 08:34:25 AM: Update 33193: task edges-pos-ontonotes, batch 193 (33193): mcc: 0.6781, acc: 0.5156, precision: 0.8191, recall: 0.5703, f1: 0.6724, edges-pos-ontonotes_loss: 0.0292
09/16 08:34:35 AM: Update 33263: task edges-pos-ontonotes, batch 263 (33263): mcc: 0.6809, acc: 0.5194, precision: 0.8206, recall: 0.5740, f1: 0.6755, edges-pos-ontonotes_loss: 0.0289
09/16 08:34:45 AM: Update 33313: task edges-pos-ontonotes, batch 313 (33313): mcc: 0.6801, acc: 0.5184, precision: 0.8206, recall: 0.5725, f1: 0.6745, edges-pos-ontonotes_loss: 0.0290
09/16 08:34:55 AM: Update 33373: task edges-pos-ontonotes, batch 373 (33373): mcc: 0.6877, acc: 0.5276, precision: 0.8249, recall: 0.5822, f1: 0.6826, edges-pos-ontonotes_loss: 0.0285
09/16 08:35:06 AM: Update 33446: task edges-pos-ontonotes, batch 446 (33446): mcc: 0.6962, acc: 0.5379, precision: 0.8295, recall: 0.5931, f1: 0.6916, edges-pos-ontonotes_loss: 0.0279
09/16 08:35:16 AM: Update 33513: task edges-pos-ontonotes, batch 513 (33513): mcc: 0.7025, acc: 0.5454, precision: 0.8333, recall: 0.6009, f1: 0.6982, edges-pos-ontonotes_loss: 0.0276
09/16 08:35:26 AM: Update 33569: task edges-pos-ontonotes, batch 569 (33569): mcc: 0.7070, acc: 0.5512, precision: 0.8357, recall: 0.6068, f1: 0.7030, edges-pos-ontonotes_loss: 0.0272
09/16 08:35:36 AM: Update 33626: task edges-pos-ontonotes, batch 626 (33626): mcc: 0.7111, acc: 0.5564, precision: 0.8381, recall: 0.6119, f1: 0.7073, edges-pos-ontonotes_loss: 0.0269
09/16 08:35:46 AM: Update 33671: task edges-pos-ontonotes, batch 671 (33671): mcc: 0.7127, acc: 0.5583, precision: 0.8391, recall: 0.6137, f1: 0.7089, edges-pos-ontonotes_loss: 0.0268
09/16 08:35:56 AM: Update 33741: task edges-pos-ontonotes, batch 741 (33741): mcc: 0.7160, acc: 0.5629, precision: 0.8411, recall: 0.6179, f1: 0.7125, edges-pos-ontonotes_loss: 0.0265
09/16 08:36:06 AM: Update 33814: task edges-pos-ontonotes, batch 814 (33814): mcc: 0.7186, acc: 0.5661, precision: 0.8428, recall: 0.6210, f1: 0.7151, edges-pos-ontonotes_loss: 0.0262
09/16 08:36:16 AM: Update 33888: task edges-pos-ontonotes, batch 888 (33888): mcc: 0.7219, acc: 0.5705, precision: 0.8448, recall: 0.6251, f1: 0.7186, edges-pos-ontonotes_loss: 0.0259
09/16 08:36:26 AM: Update 33958: task edges-pos-ontonotes, batch 958 (33958): mcc: 0.7242, acc: 0.5735, precision: 0.8462, recall: 0.6280, f1: 0.7210, edges-pos-ontonotes_loss: 0.0257
09/16 08:36:31 AM: ***** Step 34000 / Validation 34 *****
09/16 08:36:31 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:36:31 AM: Validating...
09/16 08:36:36 AM: Evaluate: task edges-pos-ontonotes, batch 23 (157): mcc: 0.7754, acc: 0.6394, precision: 0.9196, recall: 0.6602, f1: 0.7686, edges-pos-ontonotes_loss: 0.0228
09/16 08:36:47 AM: Evaluate: task edges-pos-ontonotes, batch 77 (157): mcc: 0.7879, acc: 0.6563, precision: 0.9233, recall: 0.6785, f1: 0.7822, edges-pos-ontonotes_loss: 0.0219
09/16 08:36:57 AM: Evaluate: task edges-pos-ontonotes, batch 119 (157): mcc: 0.7763, acc: 0.6399, precision: 0.9181, recall: 0.6628, f1: 0.7698, edges-pos-ontonotes_loss: 0.0226
09/16 08:37:06 AM: Updating LR scheduler:
09/16 08:37:06 AM: 	Best result seen so far for macro_avg: 0.768
09/16 08:37:06 AM: 	# validation passes without improvement: 3
09/16 08:37:06 AM: edges-pos-ontonotes_loss: training: 0.025789 validation: 0.023096
09/16 08:37:06 AM: macro_avg: validation: 0.761890
09/16 08:37:06 AM: micro_avg: validation: 0.000000
09/16 08:37:06 AM: edges-pos-ontonotes_mcc: training: 0.723710 validation: 0.769049
09/16 08:37:06 AM: edges-pos-ontonotes_acc: training: 0.572903 validation: 0.628443
09/16 08:37:06 AM: edges-pos-ontonotes_precision: training: 0.845930 validation: 0.916019
09/16 08:37:06 AM: edges-pos-ontonotes_recall: training: 0.627405 validation: 0.652158
09/16 08:37:06 AM: edges-pos-ontonotes_f1: training: 0.720461 validation: 0.761890
09/16 08:37:06 AM: Global learning rate: 2.5e-05
09/16 08:37:06 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 08:37:07 AM: Update 34006: task edges-pos-ontonotes, batch 6 (34006): mcc: 0.7679, acc: 0.6369, precision: 0.8544, recall: 0.6980, f1: 0.7683, edges-pos-ontonotes_loss: 0.0254
09/16 08:37:17 AM: Update 34090: task edges-pos-ontonotes, batch 90 (34090): mcc: 0.7202, acc: 0.5695, precision: 0.8422, recall: 0.6242, f1: 0.7170, edges-pos-ontonotes_loss: 0.0253
09/16 08:37:27 AM: Update 34165: task edges-pos-ontonotes, batch 165 (34165): mcc: 0.7153, acc: 0.5637, precision: 0.8396, recall: 0.6178, f1: 0.7118, edges-pos-ontonotes_loss: 0.0255
09/16 08:37:37 AM: Update 34260: task edges-pos-ontonotes, batch 260 (34260): mcc: 0.7201, acc: 0.5705, precision: 0.8413, recall: 0.6247, f1: 0.7170, edges-pos-ontonotes_loss: 0.0255
09/16 08:37:47 AM: Update 34301: task edges-pos-ontonotes, batch 301 (34301): mcc: 0.7012, acc: 0.5464, precision: 0.8291, recall: 0.6019, f1: 0.6974, edges-pos-ontonotes_loss: 0.0265
09/16 08:37:57 AM: Update 34350: task edges-pos-ontonotes, batch 350 (34350): mcc: 0.6924, acc: 0.5352, precision: 0.8230, recall: 0.5914, f1: 0.6882, edges-pos-ontonotes_loss: 0.0273
09/16 08:38:07 AM: Update 34394: task edges-pos-ontonotes, batch 394 (34394): mcc: 0.6865, acc: 0.5281, precision: 0.8184, recall: 0.5849, f1: 0.6822, edges-pos-ontonotes_loss: 0.0280
09/16 08:38:18 AM: Update 34435: task edges-pos-ontonotes, batch 435 (34435): mcc: 0.6826, acc: 0.5231, precision: 0.8155, recall: 0.5806, f1: 0.6782, edges-pos-ontonotes_loss: 0.0285
09/16 08:38:28 AM: Update 34476: task edges-pos-ontonotes, batch 476 (34476): mcc: 0.6812, acc: 0.5212, precision: 0.8141, recall: 0.5791, f1: 0.6768, edges-pos-ontonotes_loss: 0.0289
09/16 08:38:38 AM: Update 34513: task edges-pos-ontonotes, batch 513 (34513): mcc: 0.6773, acc: 0.5162, precision: 0.8123, recall: 0.5739, f1: 0.6726, edges-pos-ontonotes_loss: 0.0293
09/16 08:38:48 AM: Update 34558: task edges-pos-ontonotes, batch 558 (34558): mcc: 0.6743, acc: 0.5126, precision: 0.8104, recall: 0.5702, f1: 0.6694, edges-pos-ontonotes_loss: 0.0296
09/16 08:38:59 AM: Update 34600: task edges-pos-ontonotes, batch 600 (34600): mcc: 0.6735, acc: 0.5116, precision: 0.8099, recall: 0.5692, f1: 0.6686, edges-pos-ontonotes_loss: 0.0298
09/16 08:39:09 AM: Update 34654: task edges-pos-ontonotes, batch 654 (34654): mcc: 0.6746, acc: 0.5129, precision: 0.8114, recall: 0.5700, f1: 0.6696, edges-pos-ontonotes_loss: 0.0297
09/16 08:39:19 AM: Update 34711: task edges-pos-ontonotes, batch 711 (34711): mcc: 0.6752, acc: 0.5138, precision: 0.8123, recall: 0.5704, f1: 0.6702, edges-pos-ontonotes_loss: 0.0296
09/16 08:39:29 AM: Update 34765: task edges-pos-ontonotes, batch 765 (34765): mcc: 0.6764, acc: 0.5153, precision: 0.8135, recall: 0.5716, f1: 0.6714, edges-pos-ontonotes_loss: 0.0295
09/16 08:39:39 AM: Update 34833: task edges-pos-ontonotes, batch 833 (34833): mcc: 0.6788, acc: 0.5183, precision: 0.8153, recall: 0.5742, f1: 0.6739, edges-pos-ontonotes_loss: 0.0293
09/16 08:39:50 AM: Update 34901: task edges-pos-ontonotes, batch 901 (34901): mcc: 0.6802, acc: 0.5200, precision: 0.8165, recall: 0.5757, f1: 0.6753, edges-pos-ontonotes_loss: 0.0291
09/16 08:40:00 AM: Update 34943: task edges-pos-ontonotes, batch 943 (34943): mcc: 0.6809, acc: 0.5209, precision: 0.8165, recall: 0.5768, f1: 0.6760, edges-pos-ontonotes_loss: 0.0291
09/16 08:40:10 AM: Update 34992: task edges-pos-ontonotes, batch 992 (34992): mcc: 0.6813, acc: 0.5213, precision: 0.8168, recall: 0.5773, f1: 0.6765, edges-pos-ontonotes_loss: 0.0291
09/16 08:40:12 AM: ***** Step 35000 / Validation 35 *****
09/16 08:40:12 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:40:12 AM: Validating...
09/16 08:40:20 AM: Evaluate: task edges-pos-ontonotes, batch 44 (157): mcc: 0.7794, acc: 0.6425, precision: 0.9252, recall: 0.6628, f1: 0.7724, edges-pos-ontonotes_loss: 0.0222
09/16 08:40:30 AM: Evaluate: task edges-pos-ontonotes, batch 95 (157): mcc: 0.7834, acc: 0.6484, precision: 0.9247, recall: 0.6698, f1: 0.7769, edges-pos-ontonotes_loss: 0.0218
09/16 08:40:40 AM: Evaluate: task edges-pos-ontonotes, batch 141 (157): mcc: 0.7694, acc: 0.6285, precision: 0.9197, recall: 0.6501, f1: 0.7618, edges-pos-ontonotes_loss: 0.0227
09/16 08:40:43 AM: Updating LR scheduler:
09/16 08:40:43 AM: 	Best result seen so far for macro_avg: 0.768
09/16 08:40:43 AM: 	# validation passes without improvement: 0
09/16 08:40:43 AM: edges-pos-ontonotes_loss: training: 0.029160 validation: 0.022729
09/16 08:40:43 AM: macro_avg: validation: 0.761640
09/16 08:40:43 AM: micro_avg: validation: 0.000000
09/16 08:40:43 AM: edges-pos-ontonotes_mcc: training: 0.680889 validation: 0.769538
09/16 08:40:43 AM: edges-pos-ontonotes_acc: training: 0.520725 validation: 0.627840
09/16 08:40:43 AM: edges-pos-ontonotes_precision: training: 0.816751 validation: 0.921431
09/16 08:40:43 AM: edges-pos-ontonotes_recall: training: 0.576669 validation: 0.649079
09/16 08:40:43 AM: edges-pos-ontonotes_f1: training: 0.676028 validation: 0.761640
09/16 08:40:43 AM: Global learning rate: 1.25e-05
09/16 08:40:43 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 08:40:50 AM: Update 35054: task edges-pos-ontonotes, batch 54 (35054): mcc: 0.7031, acc: 0.5497, precision: 0.8275, recall: 0.6062, f1: 0.6997, edges-pos-ontonotes_loss: 0.0287
09/16 08:41:00 AM: Update 35121: task edges-pos-ontonotes, batch 121 (35121): mcc: 0.6942, acc: 0.5390, precision: 0.8221, recall: 0.5951, f1: 0.6905, edges-pos-ontonotes_loss: 0.0293
09/16 08:41:10 AM: Update 35199: task edges-pos-ontonotes, batch 199 (35199): mcc: 0.6975, acc: 0.5432, precision: 0.8238, recall: 0.5995, f1: 0.6940, edges-pos-ontonotes_loss: 0.0288
09/16 08:41:24 AM: Update 35227: task edges-pos-ontonotes, batch 227 (35227): mcc: 0.6954, acc: 0.5407, precision: 0.8226, recall: 0.5968, f1: 0.6918, edges-pos-ontonotes_loss: 0.0290
09/16 08:41:35 AM: Update 35280: task edges-pos-ontonotes, batch 280 (35280): mcc: 0.6847, acc: 0.5271, precision: 0.8162, recall: 0.5835, f1: 0.6805, edges-pos-ontonotes_loss: 0.0299
09/16 08:41:45 AM: Update 35336: task edges-pos-ontonotes, batch 336 (35336): mcc: 0.6818, acc: 0.5232, precision: 0.8140, recall: 0.5802, f1: 0.6775, edges-pos-ontonotes_loss: 0.0304
09/16 08:41:55 AM: Update 35383: task edges-pos-ontonotes, batch 383 (35383): mcc: 0.6787, acc: 0.5192, precision: 0.8129, recall: 0.5759, f1: 0.6742, edges-pos-ontonotes_loss: 0.0307
09/16 08:42:05 AM: Update 35434: task edges-pos-ontonotes, batch 434 (35434): mcc: 0.6786, acc: 0.5187, precision: 0.8129, recall: 0.5755, f1: 0.6739, edges-pos-ontonotes_loss: 0.0308
09/16 08:42:15 AM: Update 35487: task edges-pos-ontonotes, batch 487 (35487): mcc: 0.6769, acc: 0.5166, precision: 0.8119, recall: 0.5736, f1: 0.6722, edges-pos-ontonotes_loss: 0.0310
09/16 08:42:27 AM: Update 35540: task edges-pos-ontonotes, batch 540 (35540): mcc: 0.6753, acc: 0.5147, precision: 0.8110, recall: 0.5715, f1: 0.6705, edges-pos-ontonotes_loss: 0.0312
09/16 08:42:37 AM: Update 35586: task edges-pos-ontonotes, batch 586 (35586): mcc: 0.6739, acc: 0.5131, precision: 0.8098, recall: 0.5700, f1: 0.6691, edges-pos-ontonotes_loss: 0.0314
09/16 08:42:47 AM: Update 35639: task edges-pos-ontonotes, batch 639 (35639): mcc: 0.6733, acc: 0.5123, precision: 0.8096, recall: 0.5691, f1: 0.6684, edges-pos-ontonotes_loss: 0.0316
09/16 08:42:57 AM: Update 35696: task edges-pos-ontonotes, batch 696 (35696): mcc: 0.6734, acc: 0.5124, precision: 0.8097, recall: 0.5692, f1: 0.6685, edges-pos-ontonotes_loss: 0.0317
09/16 08:43:07 AM: Update 35750: task edges-pos-ontonotes, batch 750 (35750): mcc: 0.6725, acc: 0.5113, precision: 0.8094, recall: 0.5679, f1: 0.6675, edges-pos-ontonotes_loss: 0.0318
09/16 08:43:17 AM: Update 35806: task edges-pos-ontonotes, batch 806 (35806): mcc: 0.6728, acc: 0.5117, precision: 0.8098, recall: 0.5682, f1: 0.6678, edges-pos-ontonotes_loss: 0.0318
09/16 08:43:28 AM: Update 35853: task edges-pos-ontonotes, batch 853 (35853): mcc: 0.6727, acc: 0.5115, precision: 0.8099, recall: 0.5680, f1: 0.6677, edges-pos-ontonotes_loss: 0.0318
09/16 08:43:38 AM: Update 35906: task edges-pos-ontonotes, batch 906 (35906): mcc: 0.6723, acc: 0.5110, precision: 0.8099, recall: 0.5673, f1: 0.6673, edges-pos-ontonotes_loss: 0.0319
09/16 08:43:48 AM: Update 35960: task edges-pos-ontonotes, batch 960 (35960): mcc: 0.6723, acc: 0.5109, precision: 0.8098, recall: 0.5673, f1: 0.6672, edges-pos-ontonotes_loss: 0.0319
09/16 08:43:56 AM: ***** Step 36000 / Validation 36 *****
09/16 08:43:56 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:43:56 AM: Validating...
09/16 08:43:58 AM: Evaluate: task edges-pos-ontonotes, batch 16 (157): mcc: 0.7797, acc: 0.6483, precision: 0.9112, recall: 0.6736, f1: 0.7746, edges-pos-ontonotes_loss: 0.0223
09/16 08:44:08 AM: Evaluate: task edges-pos-ontonotes, batch 85 (157): mcc: 0.7868, acc: 0.6543, precision: 0.9224, recall: 0.6774, f1: 0.7812, edges-pos-ontonotes_loss: 0.0219
09/16 08:44:18 AM: Evaluate: task edges-pos-ontonotes, batch 132 (157): mcc: 0.7733, acc: 0.6347, precision: 0.9191, recall: 0.6571, f1: 0.7663, edges-pos-ontonotes_loss: 0.0226
09/16 08:44:23 AM: Updating LR scheduler:
09/16 08:44:23 AM: 	Best result seen so far for macro_avg: 0.768
09/16 08:44:23 AM: 	# validation passes without improvement: 1
09/16 08:44:23 AM: edges-pos-ontonotes_loss: training: 0.032014 validation: 0.022731
09/16 08:44:23 AM: macro_avg: validation: 0.765458
09/16 08:44:23 AM: micro_avg: validation: 0.000000
09/16 08:44:23 AM: edges-pos-ontonotes_mcc: training: 0.672118 validation: 0.772724
09/16 08:44:23 AM: edges-pos-ontonotes_acc: training: 0.510734 validation: 0.633015
09/16 08:44:23 AM: edges-pos-ontonotes_precision: training: 0.809897 validation: 0.920236
09/16 08:44:23 AM: edges-pos-ontonotes_recall: training: 0.566986 validation: 0.655248
09/16 08:44:23 AM: edges-pos-ontonotes_f1: training: 0.667014 validation: 0.765458
09/16 08:44:23 AM: Global learning rate: 1.25e-05
09/16 08:44:23 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 08:44:28 AM: Update 36033: task edges-pos-ontonotes, batch 33 (36033): mcc: 0.6930, acc: 0.5359, precision: 0.8242, recall: 0.5915, f1: 0.6888, edges-pos-ontonotes_loss: 0.0311
09/16 08:44:39 AM: Update 36091: task edges-pos-ontonotes, batch 91 (36091): mcc: 0.6857, acc: 0.5263, precision: 0.8183, recall: 0.5836, f1: 0.6813, edges-pos-ontonotes_loss: 0.0314
09/16 08:44:49 AM: Update 36143: task edges-pos-ontonotes, batch 143 (36143): mcc: 0.6808, acc: 0.5215, precision: 0.8159, recall: 0.5772, f1: 0.6761, edges-pos-ontonotes_loss: 0.0318
09/16 08:44:59 AM: Update 36188: task edges-pos-ontonotes, batch 188 (36188): mcc: 0.6790, acc: 0.5192, precision: 0.8150, recall: 0.5748, f1: 0.6741, edges-pos-ontonotes_loss: 0.0320
09/16 08:45:09 AM: Update 36247: task edges-pos-ontonotes, batch 247 (36247): mcc: 0.6770, acc: 0.5166, precision: 0.8140, recall: 0.5722, f1: 0.6720, edges-pos-ontonotes_loss: 0.0321
09/16 08:45:19 AM: Update 36306: task edges-pos-ontonotes, batch 306 (36306): mcc: 0.6776, acc: 0.5174, precision: 0.8142, recall: 0.5731, f1: 0.6727, edges-pos-ontonotes_loss: 0.0321
09/16 08:45:29 AM: Update 36360: task edges-pos-ontonotes, batch 360 (36360): mcc: 0.6775, acc: 0.5171, precision: 0.8143, recall: 0.5728, f1: 0.6726, edges-pos-ontonotes_loss: 0.0321
09/16 08:45:39 AM: Update 36413: task edges-pos-ontonotes, batch 413 (36413): mcc: 0.6770, acc: 0.5166, precision: 0.8139, recall: 0.5723, f1: 0.6720, edges-pos-ontonotes_loss: 0.0322
09/16 08:45:49 AM: Update 36466: task edges-pos-ontonotes, batch 466 (36466): mcc: 0.6769, acc: 0.5166, precision: 0.8138, recall: 0.5722, f1: 0.6719, edges-pos-ontonotes_loss: 0.0322
09/16 08:46:00 AM: Update 36509: task edges-pos-ontonotes, batch 509 (36509): mcc: 0.6743, acc: 0.5134, precision: 0.8124, recall: 0.5689, f1: 0.6692, edges-pos-ontonotes_loss: 0.0322
09/16 08:46:10 AM: Update 36578: task edges-pos-ontonotes, batch 578 (36578): mcc: 0.6758, acc: 0.5148, precision: 0.8140, recall: 0.5701, f1: 0.6706, edges-pos-ontonotes_loss: 0.0318
09/16 08:46:20 AM: Update 36642: task edges-pos-ontonotes, batch 642 (36642): mcc: 0.6759, acc: 0.5148, precision: 0.8145, recall: 0.5700, f1: 0.6707, edges-pos-ontonotes_loss: 0.0315
09/16 08:46:30 AM: Update 36719: task edges-pos-ontonotes, batch 719 (36719): mcc: 0.6789, acc: 0.5184, precision: 0.8162, recall: 0.5737, f1: 0.6738, edges-pos-ontonotes_loss: 0.0310
09/16 08:46:40 AM: Update 36783: task edges-pos-ontonotes, batch 783 (36783): mcc: 0.6786, acc: 0.5178, precision: 0.8167, recall: 0.5728, f1: 0.6734, edges-pos-ontonotes_loss: 0.0309
09/16 08:46:50 AM: Update 36864: task edges-pos-ontonotes, batch 864 (36864): mcc: 0.6828, acc: 0.5228, precision: 0.8192, recall: 0.5781, f1: 0.6778, edges-pos-ontonotes_loss: 0.0303
09/16 08:47:00 AM: Update 36957: task edges-pos-ontonotes, batch 957 (36957): mcc: 0.6880, acc: 0.5290, precision: 0.8224, recall: 0.5845, f1: 0.6833, edges-pos-ontonotes_loss: 0.0298
09/16 08:47:05 AM: ***** Step 37000 / Validation 37 *****
09/16 08:47:05 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:47:05 AM: Validating...
09/16 08:47:10 AM: Evaluate: task edges-pos-ontonotes, batch 39 (157): mcc: 0.7727, acc: 0.6304, precision: 0.9323, recall: 0.6467, f1: 0.7636, edges-pos-ontonotes_loss: 0.0226
09/16 08:47:20 AM: Evaluate: task edges-pos-ontonotes, batch 101 (157): mcc: 0.7761, acc: 0.6347, precision: 0.9328, recall: 0.6519, f1: 0.7674, edges-pos-ontonotes_loss: 0.0223
09/16 08:47:30 AM: Evaluate: task edges-pos-ontonotes, batch 145 (157): mcc: 0.7636, acc: 0.6166, precision: 0.9303, recall: 0.6330, f1: 0.7534, edges-pos-ontonotes_loss: 0.0231
09/16 08:47:33 AM: Updating LR scheduler:
09/16 08:47:33 AM: 	Best result seen so far for macro_avg: 0.768
09/16 08:47:33 AM: 	# validation passes without improvement: 2
09/16 08:47:33 AM: edges-pos-ontonotes_loss: training: 0.029543 validation: 0.023083
09/16 08:47:33 AM: macro_avg: validation: 0.753567
09/16 08:47:33 AM: micro_avg: validation: 0.000000
09/16 08:47:33 AM: edges-pos-ontonotes_mcc: training: 0.690012 validation: 0.763903
09/16 08:47:33 AM: edges-pos-ontonotes_acc: training: 0.531457 validation: 0.616506
09/16 08:47:33 AM: edges-pos-ontonotes_precision: training: 0.823646 validation: 0.931524
09/16 08:47:33 AM: edges-pos-ontonotes_recall: training: 0.586930 validation: 0.632697
09/16 08:47:33 AM: edges-pos-ontonotes_f1: training: 0.685425 validation: 0.753567
09/16 08:47:33 AM: Global learning rate: 1.25e-05
09/16 08:47:33 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 08:47:40 AM: Update 37042: task edges-pos-ontonotes, batch 42 (37042): mcc: 0.7448, acc: 0.5984, precision: 0.8572, recall: 0.6551, f1: 0.7427, edges-pos-ontonotes_loss: 0.0258
09/16 08:47:50 AM: Update 37095: task edges-pos-ontonotes, batch 95 (37095): mcc: 0.7581, acc: 0.6159, precision: 0.8619, recall: 0.6745, f1: 0.7567, edges-pos-ontonotes_loss: 0.0246
09/16 08:48:02 AM: Update 37105: task edges-pos-ontonotes, batch 105 (37105): mcc: 0.7532, acc: 0.6096, precision: 0.8602, recall: 0.6673, f1: 0.7515, edges-pos-ontonotes_loss: 0.0248
09/16 08:48:12 AM: Update 37172: task edges-pos-ontonotes, batch 172 (37172): mcc: 0.7544, acc: 0.6119, precision: 0.8617, recall: 0.6682, f1: 0.7527, edges-pos-ontonotes_loss: 0.0240
09/16 08:48:22 AM: Update 37235: task edges-pos-ontonotes, batch 235 (37235): mcc: 0.7599, acc: 0.6196, precision: 0.8656, recall: 0.6746, f1: 0.7583, edges-pos-ontonotes_loss: 0.0235
09/16 08:48:32 AM: Update 37295: task edges-pos-ontonotes, batch 295 (37295): mcc: 0.7600, acc: 0.6202, precision: 0.8654, recall: 0.6750, f1: 0.7584, edges-pos-ontonotes_loss: 0.0236
09/16 08:48:42 AM: Update 37363: task edges-pos-ontonotes, batch 363 (37363): mcc: 0.7609, acc: 0.6214, precision: 0.8665, recall: 0.6758, f1: 0.7593, edges-pos-ontonotes_loss: 0.0234
09/16 08:48:52 AM: Update 37418: task edges-pos-ontonotes, batch 418 (37418): mcc: 0.7588, acc: 0.6187, precision: 0.8655, recall: 0.6728, f1: 0.7571, edges-pos-ontonotes_loss: 0.0236
09/16 08:49:03 AM: Update 37508: task edges-pos-ontonotes, batch 508 (37508): mcc: 0.7543, acc: 0.6130, precision: 0.8636, recall: 0.6665, f1: 0.7524, edges-pos-ontonotes_loss: 0.0239
09/16 08:49:13 AM: Update 37588: task edges-pos-ontonotes, batch 588 (37588): mcc: 0.7518, acc: 0.6097, precision: 0.8625, recall: 0.6631, f1: 0.7497, edges-pos-ontonotes_loss: 0.0241
09/16 08:49:23 AM: Update 37665: task edges-pos-ontonotes, batch 665 (37665): mcc: 0.7484, acc: 0.6054, precision: 0.8605, recall: 0.6586, f1: 0.7461, edges-pos-ontonotes_loss: 0.0243
09/16 08:49:35 AM: Update 37731: task edges-pos-ontonotes, batch 731 (37731): mcc: 0.7441, acc: 0.5997, precision: 0.8586, recall: 0.6526, f1: 0.7416, edges-pos-ontonotes_loss: 0.0245
09/16 08:49:45 AM: Update 37775: task edges-pos-ontonotes, batch 775 (37775): mcc: 0.7321, acc: 0.5842, precision: 0.8517, recall: 0.6374, f1: 0.7292, edges-pos-ontonotes_loss: 0.0251
09/16 08:49:55 AM: Update 37820: task edges-pos-ontonotes, batch 820 (37820): mcc: 0.7256, acc: 0.5760, precision: 0.8467, recall: 0.6300, f1: 0.7225, edges-pos-ontonotes_loss: 0.0255
09/16 08:50:05 AM: Update 37863: task edges-pos-ontonotes, batch 863 (37863): mcc: 0.7204, acc: 0.5693, precision: 0.8430, recall: 0.6239, f1: 0.7171, edges-pos-ontonotes_loss: 0.0259
09/16 08:50:15 AM: Update 37915: task edges-pos-ontonotes, batch 915 (37915): mcc: 0.7160, acc: 0.5638, precision: 0.8399, recall: 0.6188, f1: 0.7126, edges-pos-ontonotes_loss: 0.0263
09/16 08:50:25 AM: Update 37963: task edges-pos-ontonotes, batch 963 (37963): mcc: 0.7114, acc: 0.5580, precision: 0.8368, recall: 0.6133, f1: 0.7078, edges-pos-ontonotes_loss: 0.0266
09/16 08:50:33 AM: ***** Step 38000 / Validation 38 *****
09/16 08:50:33 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:50:33 AM: Validating...
09/16 08:50:35 AM: Evaluate: task edges-pos-ontonotes, batch 13 (157): mcc: 0.7840, acc: 0.6562, precision: 0.9104, recall: 0.6817, f1: 0.7796, edges-pos-ontonotes_loss: 0.0220
09/16 08:50:45 AM: Evaluate: task edges-pos-ontonotes, batch 70 (157): mcc: 0.7902, acc: 0.6599, precision: 0.9223, recall: 0.6832, f1: 0.7849, edges-pos-ontonotes_loss: 0.0216
09/16 08:50:55 AM: Evaluate: task edges-pos-ontonotes, batch 110 (157): mcc: 0.7835, acc: 0.6506, precision: 0.9200, recall: 0.6736, f1: 0.7777, edges-pos-ontonotes_loss: 0.0220
09/16 08:51:05 AM: Evaluate: task edges-pos-ontonotes, batch 142 (157): mcc: 0.7745, acc: 0.6375, precision: 0.9155, recall: 0.6617, f1: 0.7682, edges-pos-ontonotes_loss: 0.0226
09/16 08:51:10 AM: Best result seen so far for edges-pos-ontonotes.
09/16 08:51:10 AM: Best result seen so far for macro.
09/16 08:51:10 AM: Updating LR scheduler:
09/16 08:51:10 AM: 	Best result seen so far for macro_avg: 0.769
09/16 08:51:10 AM: 	# validation passes without improvement: 0
09/16 08:51:10 AM: edges-pos-ontonotes_loss: training: 0.026809 validation: 0.022605
09/16 08:51:10 AM: macro_avg: validation: 0.768525
09/16 08:51:10 AM: micro_avg: validation: 0.000000
09/16 08:51:10 AM: edges-pos-ontonotes_mcc: training: 0.708935 validation: 0.775033
09/16 08:51:10 AM: edges-pos-ontonotes_acc: training: 0.554853 validation: 0.637481
09/16 08:51:10 AM: edges-pos-ontonotes_precision: training: 0.835169 validation: 0.917207
09/16 08:51:10 AM: edges-pos-ontonotes_recall: training: 0.610343 validation: 0.661323
09/16 08:51:10 AM: edges-pos-ontonotes_f1: training: 0.705272 validation: 0.768525
09/16 08:51:10 AM: Global learning rate: 1.25e-05
09/16 08:51:10 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 08:51:16 AM: Update 38019: task edges-pos-ontonotes, batch 19 (38019): mcc: 0.6555, acc: 0.4890, precision: 0.7949, recall: 0.5501, f1: 0.6502, edges-pos-ontonotes_loss: 0.0340
09/16 08:51:26 AM: Update 38059: task edges-pos-ontonotes, batch 59 (38059): mcc: 0.6556, acc: 0.4900, precision: 0.7981, recall: 0.5480, f1: 0.6498, edges-pos-ontonotes_loss: 0.0339
09/16 08:51:36 AM: Update 38108: task edges-pos-ontonotes, batch 108 (38108): mcc: 0.6613, acc: 0.4964, precision: 0.8064, recall: 0.5516, f1: 0.6551, edges-pos-ontonotes_loss: 0.0316
09/16 08:51:46 AM: Update 38166: task edges-pos-ontonotes, batch 166 (38166): mcc: 0.6723, acc: 0.5097, precision: 0.8148, recall: 0.5637, f1: 0.6664, edges-pos-ontonotes_loss: 0.0301
09/16 08:51:56 AM: Update 38217: task edges-pos-ontonotes, batch 217 (38217): mcc: 0.6762, acc: 0.5144, precision: 0.8165, recall: 0.5690, f1: 0.6706, edges-pos-ontonotes_loss: 0.0300
09/16 08:52:06 AM: Update 38287: task edges-pos-ontonotes, batch 287 (38287): mcc: 0.6817, acc: 0.5215, precision: 0.8210, recall: 0.5750, f1: 0.6763, edges-pos-ontonotes_loss: 0.0291
09/16 08:52:16 AM: Update 38349: task edges-pos-ontonotes, batch 349 (38349): mcc: 0.6847, acc: 0.5251, precision: 0.8228, recall: 0.5786, f1: 0.6795, edges-pos-ontonotes_loss: 0.0288
09/16 08:52:27 AM: Update 38396: task edges-pos-ontonotes, batch 396 (38396): mcc: 0.6854, acc: 0.5262, precision: 0.8230, recall: 0.5796, f1: 0.6802, edges-pos-ontonotes_loss: 0.0288
09/16 08:52:37 AM: Update 38449: task edges-pos-ontonotes, batch 449 (38449): mcc: 0.6872, acc: 0.5286, precision: 0.8233, recall: 0.5824, f1: 0.6822, edges-pos-ontonotes_loss: 0.0289
09/16 08:52:47 AM: Update 38504: task edges-pos-ontonotes, batch 504 (38504): mcc: 0.6874, acc: 0.5289, precision: 0.8225, recall: 0.5834, f1: 0.6826, edges-pos-ontonotes_loss: 0.0289
09/16 08:52:57 AM: Update 38553: task edges-pos-ontonotes, batch 553 (38553): mcc: 0.6882, acc: 0.5298, precision: 0.8230, recall: 0.5844, f1: 0.6835, edges-pos-ontonotes_loss: 0.0290
09/16 08:53:07 AM: Update 38614: task edges-pos-ontonotes, batch 614 (38614): mcc: 0.6898, acc: 0.5320, precision: 0.8230, recall: 0.5870, f1: 0.6852, edges-pos-ontonotes_loss: 0.0289
09/16 08:53:17 AM: Update 38667: task edges-pos-ontonotes, batch 667 (38667): mcc: 0.6896, acc: 0.5318, precision: 0.8231, recall: 0.5867, f1: 0.6851, edges-pos-ontonotes_loss: 0.0289
09/16 08:53:27 AM: Update 38704: task edges-pos-ontonotes, batch 704 (38704): mcc: 0.6874, acc: 0.5291, precision: 0.8217, recall: 0.5839, f1: 0.6827, edges-pos-ontonotes_loss: 0.0290
09/16 08:53:37 AM: Update 38750: task edges-pos-ontonotes, batch 750 (38750): mcc: 0.6859, acc: 0.5274, precision: 0.8202, recall: 0.5825, f1: 0.6812, edges-pos-ontonotes_loss: 0.0293
09/16 08:53:48 AM: Update 38793: task edges-pos-ontonotes, batch 793 (38793): mcc: 0.6842, acc: 0.5252, precision: 0.8189, recall: 0.5806, f1: 0.6794, edges-pos-ontonotes_loss: 0.0295
09/16 08:53:58 AM: Update 38839: task edges-pos-ontonotes, batch 839 (38839): mcc: 0.6825, acc: 0.5229, precision: 0.8179, recall: 0.5786, f1: 0.6777, edges-pos-ontonotes_loss: 0.0297
09/16 08:54:08 AM: Update 38882: task edges-pos-ontonotes, batch 882 (38882): mcc: 0.6819, acc: 0.5222, precision: 0.8174, recall: 0.5779, f1: 0.6771, edges-pos-ontonotes_loss: 0.0298
09/16 08:54:18 AM: Update 38928: task edges-pos-ontonotes, batch 928 (38928): mcc: 0.6809, acc: 0.5208, precision: 0.8165, recall: 0.5768, f1: 0.6761, edges-pos-ontonotes_loss: 0.0300
09/16 08:54:28 AM: Update 38977: task edges-pos-ontonotes, batch 977 (38977): mcc: 0.6808, acc: 0.5206, precision: 0.8162, recall: 0.5768, f1: 0.6759, edges-pos-ontonotes_loss: 0.0301
09/16 08:54:35 AM: ***** Step 39000 / Validation 39 *****
09/16 08:54:35 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:54:35 AM: Validating...
09/16 08:54:38 AM: Evaluate: task edges-pos-ontonotes, batch 16 (157): mcc: 0.7801, acc: 0.6491, precision: 0.9126, recall: 0.6732, f1: 0.7749, edges-pos-ontonotes_loss: 0.0220
09/16 08:54:55 AM: Evaluate: task edges-pos-ontonotes, batch 68 (157): mcc: 0.7876, acc: 0.6545, precision: 0.9257, recall: 0.6763, f1: 0.7816, edges-pos-ontonotes_loss: 0.0217
09/16 08:55:05 AM: Evaluate: task edges-pos-ontonotes, batch 117 (157): mcc: 0.7809, acc: 0.6460, precision: 0.9211, recall: 0.6682, f1: 0.7746, edges-pos-ontonotes_loss: 0.0221
09/16 08:55:14 AM: Updating LR scheduler:
09/16 08:55:14 AM: 	Best result seen so far for macro_avg: 0.769
09/16 08:55:14 AM: 	# validation passes without improvement: 1
09/16 08:55:14 AM: edges-pos-ontonotes_loss: training: 0.030104 validation: 0.022616
09/16 08:55:14 AM: macro_avg: validation: 0.766319
09/16 08:55:14 AM: micro_avg: validation: 0.000000
09/16 08:55:14 AM: edges-pos-ontonotes_mcc: training: 0.679845 validation: 0.773375
09/16 08:55:14 AM: edges-pos-ontonotes_acc: training: 0.519597 validation: 0.634369
09/16 08:55:14 AM: edges-pos-ontonotes_precision: training: 0.815627 validation: 0.919415
09/16 08:55:14 AM: edges-pos-ontonotes_recall: training: 0.575738 validation: 0.656931
09/16 08:55:14 AM: edges-pos-ontonotes_f1: training: 0.675002 validation: 0.766319
09/16 08:55:14 AM: Global learning rate: 1.25e-05
09/16 08:55:14 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 08:55:16 AM: Update 39007: task edges-pos-ontonotes, batch 7 (39007): mcc: 0.6499, acc: 0.4842, precision: 0.7971, recall: 0.5393, f1: 0.6433, edges-pos-ontonotes_loss: 0.0339
09/16 08:55:26 AM: Update 39060: task edges-pos-ontonotes, batch 60 (39060): mcc: 0.6637, acc: 0.5002, precision: 0.8032, recall: 0.5578, f1: 0.6584, edges-pos-ontonotes_loss: 0.0331
09/16 08:55:36 AM: Update 39117: task edges-pos-ontonotes, batch 117 (39117): mcc: 0.6678, acc: 0.5055, precision: 0.8064, recall: 0.5624, f1: 0.6626, edges-pos-ontonotes_loss: 0.0328
09/16 08:55:46 AM: Update 39177: task edges-pos-ontonotes, batch 177 (39177): mcc: 0.6710, acc: 0.5093, precision: 0.8085, recall: 0.5661, f1: 0.6659, edges-pos-ontonotes_loss: 0.0324
09/16 08:55:56 AM: Update 39235: task edges-pos-ontonotes, batch 235 (39235): mcc: 0.6716, acc: 0.5104, precision: 0.8083, recall: 0.5673, f1: 0.6667, edges-pos-ontonotes_loss: 0.0325
09/16 08:56:06 AM: Update 39285: task edges-pos-ontonotes, batch 285 (39285): mcc: 0.6711, acc: 0.5096, precision: 0.8089, recall: 0.5660, f1: 0.6660, edges-pos-ontonotes_loss: 0.0326
09/16 08:56:16 AM: Update 39322: task edges-pos-ontonotes, batch 322 (39322): mcc: 0.6685, acc: 0.5062, precision: 0.8078, recall: 0.5624, f1: 0.6631, edges-pos-ontonotes_loss: 0.0328
09/16 08:56:26 AM: Update 39382: task edges-pos-ontonotes, batch 382 (39382): mcc: 0.6703, acc: 0.5084, precision: 0.8090, recall: 0.5647, f1: 0.6651, edges-pos-ontonotes_loss: 0.0326
09/16 08:56:36 AM: Update 39442: task edges-pos-ontonotes, batch 442 (39442): mcc: 0.6707, acc: 0.5088, precision: 0.8096, recall: 0.5648, f1: 0.6654, edges-pos-ontonotes_loss: 0.0326
09/16 08:56:47 AM: Update 39497: task edges-pos-ontonotes, batch 497 (39497): mcc: 0.6714, acc: 0.5095, precision: 0.8103, recall: 0.5654, f1: 0.6661, edges-pos-ontonotes_loss: 0.0326
09/16 08:56:57 AM: Update 39554: task edges-pos-ontonotes, batch 554 (39554): mcc: 0.6722, acc: 0.5103, precision: 0.8107, recall: 0.5665, f1: 0.6670, edges-pos-ontonotes_loss: 0.0325
09/16 08:57:07 AM: Update 39608: task edges-pos-ontonotes, batch 608 (39608): mcc: 0.6723, acc: 0.5105, precision: 0.8108, recall: 0.5667, f1: 0.6671, edges-pos-ontonotes_loss: 0.0325
09/16 08:57:17 AM: Update 39650: task edges-pos-ontonotes, batch 650 (39650): mcc: 0.6720, acc: 0.5101, precision: 0.8108, recall: 0.5662, f1: 0.6668, edges-pos-ontonotes_loss: 0.0326
09/16 08:57:27 AM: Update 39707: task edges-pos-ontonotes, batch 707 (39707): mcc: 0.6725, acc: 0.5107, precision: 0.8109, recall: 0.5669, f1: 0.6673, edges-pos-ontonotes_loss: 0.0325
09/16 08:57:37 AM: Update 39760: task edges-pos-ontonotes, batch 760 (39760): mcc: 0.6726, acc: 0.5110, precision: 0.8111, recall: 0.5669, f1: 0.6674, edges-pos-ontonotes_loss: 0.0325
09/16 08:57:47 AM: Update 39815: task edges-pos-ontonotes, batch 815 (39815): mcc: 0.6728, acc: 0.5112, precision: 0.8112, recall: 0.5672, f1: 0.6676, edges-pos-ontonotes_loss: 0.0325
09/16 08:57:57 AM: Update 39868: task edges-pos-ontonotes, batch 868 (39868): mcc: 0.6730, acc: 0.5115, precision: 0.8112, recall: 0.5675, f1: 0.6678, edges-pos-ontonotes_loss: 0.0325
09/16 08:58:07 AM: Update 39926: task edges-pos-ontonotes, batch 926 (39926): mcc: 0.6734, acc: 0.5121, precision: 0.8114, recall: 0.5681, f1: 0.6683, edges-pos-ontonotes_loss: 0.0325
09/16 08:58:17 AM: Update 39981: task edges-pos-ontonotes, batch 981 (39981): mcc: 0.6736, acc: 0.5123, precision: 0.8115, recall: 0.5684, f1: 0.6685, edges-pos-ontonotes_loss: 0.0323
09/16 08:58:20 AM: ***** Step 40000 / Validation 40 *****
09/16 08:58:20 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:58:20 AM: Validating...
09/16 08:58:27 AM: Evaluate: task edges-pos-ontonotes, batch 48 (157): mcc: 0.7761, acc: 0.6362, precision: 0.9294, recall: 0.6544, f1: 0.7680, edges-pos-ontonotes_loss: 0.0227
09/16 08:58:37 AM: Evaluate: task edges-pos-ontonotes, batch 107 (157): mcc: 0.7797, acc: 0.6417, precision: 0.9288, recall: 0.6607, f1: 0.7721, edges-pos-ontonotes_loss: 0.0222
09/16 08:58:47 AM: Evaluate: task edges-pos-ontonotes, batch 152 (157): mcc: 0.7705, acc: 0.6280, precision: 0.9269, recall: 0.6468, f1: 0.7619, edges-pos-ontonotes_loss: 0.0228
09/16 08:58:48 AM: Updating LR scheduler:
09/16 08:58:48 AM: 	Best result seen so far for macro_avg: 0.769
09/16 08:58:48 AM: 	# validation passes without improvement: 2
09/16 08:58:48 AM: edges-pos-ontonotes_loss: training: 0.032267 validation: 0.022812
09/16 08:58:48 AM: macro_avg: validation: 0.761346
09/16 08:58:48 AM: micro_avg: validation: 0.000000
09/16 08:58:48 AM: edges-pos-ontonotes_mcc: training: 0.673695 validation: 0.770100
09/16 08:58:48 AM: edges-pos-ontonotes_acc: training: 0.512375 validation: 0.627142
09/16 08:58:48 AM: edges-pos-ontonotes_precision: training: 0.811607 validation: 0.927558
09/16 08:58:48 AM: edges-pos-ontonotes_recall: training: 0.568384 validation: 0.645650
09/16 08:58:48 AM: edges-pos-ontonotes_f1: training: 0.668562 validation: 0.761346
09/16 08:58:48 AM: Global learning rate: 1.25e-05
09/16 08:58:48 AM: Saving checkpoints to: ./experiments/pos-ontonotes-5-way-multiqa-top/run
09/16 08:58:57 AM: Update 40049: task edges-pos-ontonotes, batch 49 (40049): mcc: 0.6629, acc: 0.4970, precision: 0.8164, recall: 0.5472, f1: 0.6552, edges-pos-ontonotes_loss: 0.0306
09/16 08:59:07 AM: Update 40117: task edges-pos-ontonotes, batch 117 (40117): mcc: 0.6781, acc: 0.5150, precision: 0.8219, recall: 0.5683, f1: 0.6720, edges-pos-ontonotes_loss: 0.0292
09/16 08:59:17 AM: Update 40189: task edges-pos-ontonotes, batch 189 (40189): mcc: 0.6830, acc: 0.5215, precision: 0.8241, recall: 0.5749, f1: 0.6773, edges-pos-ontonotes_loss: 0.0286
09/16 08:59:28 AM: Update 40252: task edges-pos-ontonotes, batch 252 (40252): mcc: 0.6852, acc: 0.5245, precision: 0.8249, recall: 0.5780, f1: 0.6797, edges-pos-ontonotes_loss: 0.0287
09/16 08:59:38 AM: Update 40325: task edges-pos-ontonotes, batch 325 (40325): mcc: 0.6964, acc: 0.5378, precision: 0.8313, recall: 0.5920, f1: 0.6915, edges-pos-ontonotes_loss: 0.0279
09/16 08:59:48 AM: Update 40417: task edges-pos-ontonotes, batch 417 (40417): mcc: 0.7083, acc: 0.5527, precision: 0.8375, recall: 0.6075, f1: 0.7042, edges-pos-ontonotes_loss: 0.0271
09/16 08:59:59 AM: Update 40501: task edges-pos-ontonotes, batch 501 (40501): mcc: 0.7152, acc: 0.5611, precision: 0.8413, recall: 0.6164, f1: 0.7115, edges-pos-ontonotes_loss: 0.0267
09/16 09:00:09 AM: Update 40565: task edges-pos-ontonotes, batch 565 (40565): mcc: 0.7190, acc: 0.5660, precision: 0.8433, recall: 0.6214, f1: 0.7155, edges-pos-ontonotes_loss: 0.0265
09/16 09:00:19 AM: Update 40653: task edges-pos-ontonotes, batch 653 (40653): mcc: 0.7234, acc: 0.5718, precision: 0.8458, recall: 0.6269, f1: 0.7201, edges-pos-ontonotes_loss: 0.0260
