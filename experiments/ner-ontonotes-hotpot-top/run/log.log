09/16 09:43:38 AM: Git branch: master
09/16 09:43:38 AM: Git SHA: 3df92c4ffc379a5a4d4b935b653f2ef463350c4f
09/16 09:43:38 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/ner-ontonotes-hotpot-top/",
  "exp_name": "experiments/ner-ontonotes-hotpot-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/ner-ontonotes-hotpot-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/hotpot",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/ner-ontonotes-hotpot-top__run",
  "run_dir": "./experiments/ner-ontonotes-hotpot-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-ner-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 09:43:38 AM: Saved config to ./experiments/ner-ontonotes-hotpot-top/run/params.conf
09/16 09:43:38 AM: Using random seed 1234
09/16 09:43:39 AM: Using GPU 0
09/16 09:43:39 AM: Loading tasks...
09/16 09:43:39 AM: Writing pre-preprocessed tasks to ./experiments/ner-ontonotes-hotpot-top/
09/16 09:43:39 AM: 	Creating task edges-ner-ontonotes from scratch.
09/16 09:43:40 AM: Read=49706, Skip=66106, Total=115812 from ./probing_data/edges/ontonotes/ner/train.json.retokenized.bert-base-uncased
09/16 09:43:41 AM: Read=7610, Skip=8070, Total=15680 from ./probing_data/edges/ontonotes/ner/development.json.retokenized.bert-base-uncased
09/16 09:43:41 AM: Read=5099, Skip=7118, Total=12217 from ./probing_data/edges/ontonotes/ner/test.json.retokenized.bert-base-uncased
09/16 09:43:41 AM: 	Task 'edges-ner-ontonotes': |train|=49706 |val|=7610 |test|=5099
09/16 09:43:41 AM: 	Finished loading tasks: edges-ner-ontonotes.
09/16 09:43:41 AM: 	Building vocab from scratch.
09/16 09:43:41 AM: 	Counting units for task edges-ner-ontonotes.
09/16 09:43:44 AM: 	Task 'edges-ner-ontonotes': adding vocab namespace 'edges-ner-ontonotes_labels'
09/16 09:43:45 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:43:45 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 09:43:45 AM: 	Saved vocab to ./experiments/ner-ontonotes-hotpot-top/vocab
09/16 09:43:45 AM: Loading token dictionary from ./experiments/ner-ontonotes-hotpot-top/vocab.
09/16 09:43:45 AM: 	Loaded vocab from ./experiments/ner-ontonotes-hotpot-top/vocab
09/16 09:43:45 AM: 	Vocab namespace chars: size 77
09/16 09:43:45 AM: 	Vocab namespace tokens: size 22840
09/16 09:43:45 AM: 	Vocab namespace bert_uncased: size 30524
09/16 09:43:45 AM: 	Vocab namespace edges-ner-ontonotes_labels: size 18
09/16 09:43:45 AM: 	Finished building vocab.
09/16 09:43:45 AM: 	Task edges-ner-ontonotes (train): Indexing from scratch.
09/16 09:43:58 AM: 	Task edges-ner-ontonotes (train): Saved 49706 instances to ./experiments/ner-ontonotes-hotpot-top/preproc/edges-ner-ontonotes__train_data
09/16 09:43:58 AM: 	Task edges-ner-ontonotes (val): Indexing from scratch.
09/16 09:44:00 AM: 	Task edges-ner-ontonotes (val): Saved 7610 instances to ./experiments/ner-ontonotes-hotpot-top/preproc/edges-ner-ontonotes__val_data
09/16 09:44:00 AM: 	Task edges-ner-ontonotes (test): Indexing from scratch.
09/16 09:44:01 AM: 	Task edges-ner-ontonotes (test): Saved 5099 instances to ./experiments/ner-ontonotes-hotpot-top/preproc/edges-ner-ontonotes__test_data
09/16 09:44:01 AM: 	Finished indexing tasks
09/16 09:44:01 AM: 	Creating trimmed target-only version of edges-ner-ontonotes train.
09/16 09:44:01 AM: 	  Training on 
09/16 09:44:01 AM: 	  Evaluating on edges-ner-ontonotes
09/16 09:44:01 AM: 	Finished loading tasks in 22.139s
09/16 09:44:01 AM: 	 Tasks: ['edges-ner-ontonotes']
09/16 09:44:01 AM: Building model...
09/16 09:44:01 AM: Using BERT model (bert-base-uncased).
09/16 09:44:01 AM: LOADING A FUNETUNED MODEL from: 
09/16 09:44:01 AM: models/hotpot
09/16 09:44:01 AM: loading configuration file models/hotpot/config.json
09/16 09:44:01 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 09:44:01 AM: loading weights file models/hotpot/pytorch_model.bin
09/16 09:44:07 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmprat2ei9x
09/16 09:44:09 AM: copying /tmp/tmprat2ei9x to cache at ./experiments/ner-ontonotes-hotpot-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:44:09 AM: creating metadata file for ./experiments/ner-ontonotes-hotpot-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:44:09 AM: removing temp file /tmp/tmprat2ei9x
09/16 09:44:09 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/ner-ontonotes-hotpot-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:44:09 AM: Initializing parameters
09/16 09:44:09 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 09:44:09 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 09:44:09 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 09:44:09 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 09:44:09 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 09:44:09 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 09:44:09 AM: 	Task 'edges-ner-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-ner-ontonotes"
}
09/16 09:44:16 AM: Model specification:
09/16 09:44:16 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-ner-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=18, bias=True)
    )
  )
)
09/16 09:44:16 AM: Model parameters:
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:44:16 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:44:16 AM: 	edges-ner-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 09:44:16 AM: 	edges-ner-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 09:44:16 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 9216 with torch.Size([18, 512])
09/16 09:44:16 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 18 with torch.Size([18])
09/16 09:44:16 AM: Total number of parameters: 109688338 (1.09688e+08)
09/16 09:44:16 AM: Number of trainable parameters: 206098 (206098)
09/16 09:44:16 AM: Finished building model in 15.214s
09/16 09:44:16 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-ner-ontonotes 

09/16 09:44:20 AM: patience = 9
09/16 09:44:20 AM: val_interval = 1000
09/16 09:44:20 AM: max_vals = 250
09/16 09:44:20 AM: cuda_device = 0
09/16 09:44:20 AM: grad_norm = 5.0
09/16 09:44:20 AM: grad_clipping = None
09/16 09:44:20 AM: lr_decay = 0.99
09/16 09:44:20 AM: min_lr = 1e-06
09/16 09:44:20 AM: keep_all_checkpoints = 0
09/16 09:44:20 AM: val_data_limit = 5000
09/16 09:44:20 AM: max_epochs = -1
09/16 09:44:20 AM: dec_val_scale = 250
09/16 09:44:20 AM: training_data_fraction = 1
09/16 09:44:20 AM: type = adam
09/16 09:44:20 AM: parameter_groups = None
09/16 09:44:20 AM: Number of trainable parameters: 206098
09/16 09:44:20 AM: infer_type_and_cast = True
09/16 09:44:20 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:44:20 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:44:20 AM: lr = 0.0001
09/16 09:44:20 AM: amsgrad = True
09/16 09:44:20 AM: type = reduce_on_plateau
09/16 09:44:20 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:44:20 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:44:20 AM: mode = max
09/16 09:44:20 AM: factor = 0.5
09/16 09:44:20 AM: patience = 3
09/16 09:44:20 AM: threshold = 0.0001
09/16 09:44:20 AM: threshold_mode = abs
09/16 09:44:20 AM: verbose = True
09/16 09:44:20 AM: type = adam
09/16 09:44:20 AM: parameter_groups = None
09/16 09:44:20 AM: Number of trainable parameters: 206098
09/16 09:44:20 AM: infer_type_and_cast = True
09/16 09:44:20 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:44:20 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:44:20 AM: lr = 0.0001
09/16 09:44:20 AM: amsgrad = True
09/16 09:44:20 AM: type = reduce_on_plateau
09/16 09:44:20 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:44:20 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:44:20 AM: mode = max
09/16 09:44:20 AM: factor = 0.5
09/16 09:44:20 AM: patience = 3
09/16 09:44:20 AM: threshold = 0.0001
09/16 09:44:20 AM: threshold_mode = abs
09/16 09:44:20 AM: verbose = True
09/16 09:44:20 AM: Starting training without restoring from a checkpoint.
09/16 09:44:20 AM: Training examples per task, before any subsampling: {'edges-ner-ontonotes': 49706}
09/16 09:44:20 AM: Beginning training with stopping criteria based on metric: edges-ner-ontonotes_f1
09/16 09:44:30 AM: Update 99: task edges-ner-ontonotes, batch 99 (99): mcc: -0.0034, acc: 0.0029, precision: 0.0517, recall: 0.0370, f1: 0.0432, edges-ner-ontonotes_loss: 0.2591
09/16 09:44:40 AM: Update 207: task edges-ner-ontonotes, batch 207 (207): mcc: 0.0387, acc: 0.0270, precision: 0.1170, recall: 0.0430, f1: 0.0629, edges-ner-ontonotes_loss: 0.2092
09/16 09:44:52 AM: Update 314: task edges-ner-ontonotes, batch 314 (314): mcc: 0.0940, acc: 0.0538, precision: 0.2249, recall: 0.0644, f1: 0.1001, edges-ner-ontonotes_loss: 0.1898
09/16 09:45:02 AM: Update 420: task edges-ner-ontonotes, batch 420 (420): mcc: 0.1480, acc: 0.0785, precision: 0.3394, recall: 0.0860, f1: 0.1372, edges-ner-ontonotes_loss: 0.1776
09/16 09:45:12 AM: Update 520: task edges-ner-ontonotes, batch 520 (520): mcc: 0.2008, acc: 0.1048, precision: 0.4432, recall: 0.1107, f1: 0.1772, edges-ner-ontonotes_loss: 0.1689
09/16 09:45:22 AM: Update 618: task edges-ner-ontonotes, batch 618 (618): mcc: 0.2440, acc: 0.1285, precision: 0.5200, recall: 0.1336, f1: 0.2126, edges-ner-ontonotes_loss: 0.1619
09/16 09:45:32 AM: Update 699: task edges-ner-ontonotes, batch 699 (699): mcc: 0.2773, acc: 0.1478, precision: 0.5716, recall: 0.1535, f1: 0.2421, edges-ner-ontonotes_loss: 0.1574
09/16 09:45:42 AM: Update 797: task edges-ner-ontonotes, batch 797 (797): mcc: 0.3123, acc: 0.1700, precision: 0.6202, recall: 0.1764, f1: 0.2747, edges-ner-ontonotes_loss: 0.1520
09/16 09:45:52 AM: Update 899: task edges-ner-ontonotes, batch 899 (899): mcc: 0.3492, acc: 0.1963, precision: 0.6628, recall: 0.2035, f1: 0.3113, edges-ner-ontonotes_loss: 0.1468
09/16 09:46:02 AM: Update 980: task edges-ner-ontonotes, batch 980 (980): mcc: 0.3729, acc: 0.2143, precision: 0.6874, recall: 0.2221, f1: 0.3357, edges-ner-ontonotes_loss: 0.1434
09/16 09:46:04 AM: ***** Step 1000 / Validation 1 *****
09/16 09:46:04 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:46:04 AM: Validating...
09/16 09:46:13 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.5425, acc: 0.3756, precision: 0.8022, recall: 0.3891, f1: 0.5241, edges-ner-ontonotes_loss: 0.1177
09/16 09:46:23 AM: Evaluate: task edges-ner-ontonotes, batch 124 (157): mcc: 0.5754, acc: 0.4113, precision: 0.8224, recall: 0.4247, f1: 0.5602, edges-ner-ontonotes_loss: 0.1100
09/16 09:46:27 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:46:27 AM: Best result seen so far for micro.
09/16 09:46:27 AM: Best result seen so far for macro.
09/16 09:46:27 AM: Updating LR scheduler:
09/16 09:46:27 AM: 	Best result seen so far for macro_avg: 0.571
09/16 09:46:27 AM: 	# validation passes without improvement: 0
09/16 09:46:27 AM: edges-ner-ontonotes_loss: training: 0.142597 validation: 0.107455
09/16 09:46:27 AM: macro_avg: validation: 0.570733
09/16 09:46:27 AM: micro_avg: validation: 0.000000
09/16 09:46:27 AM: edges-ner-ontonotes_mcc: training: 0.378349 validation: 0.584989
09/16 09:46:27 AM: edges-ner-ontonotes_acc: training: 0.218556 validation: 0.421216
09/16 09:46:27 AM: edges-ner-ontonotes_precision: training: 0.692613 validation: 0.827879
09/16 09:46:27 AM: edges-ner-ontonotes_recall: training: 0.226533 validation: 0.435472
09/16 09:46:27 AM: edges-ner-ontonotes_f1: training: 0.341403 validation: 0.570733
09/16 09:46:27 AM: Global learning rate: 0.0001
09/16 09:46:27 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:46:33 AM: Update 1052: task edges-ner-ontonotes, batch 52 (1052): mcc: 0.5867, acc: 0.4165, precision: 0.8357, recall: 0.4336, f1: 0.5709, edges-ner-ontonotes_loss: 0.0999
09/16 09:46:43 AM: Update 1156: task edges-ner-ontonotes, batch 156 (1156): mcc: 0.5957, acc: 0.4300, precision: 0.8363, recall: 0.4461, f1: 0.5819, edges-ner-ontonotes_loss: 0.0998
09/16 09:46:54 AM: Update 1253: task edges-ner-ontonotes, batch 253 (1253): mcc: 0.6001, acc: 0.4370, precision: 0.8339, recall: 0.4541, f1: 0.5880, edges-ner-ontonotes_loss: 0.0990
09/16 09:47:04 AM: Update 1349: task edges-ner-ontonotes, batch 349 (1349): mcc: 0.5808, acc: 0.4155, precision: 0.8218, recall: 0.4328, f1: 0.5670, edges-ner-ontonotes_loss: 0.1037
09/16 09:47:14 AM: Update 1458: task edges-ner-ontonotes, batch 458 (1458): mcc: 0.5750, acc: 0.4104, precision: 0.8167, recall: 0.4273, f1: 0.5611, edges-ner-ontonotes_loss: 0.1049
09/16 09:47:25 AM: Update 1557: task edges-ner-ontonotes, batch 557 (1557): mcc: 0.5735, acc: 0.4093, precision: 0.8148, recall: 0.4263, f1: 0.5598, edges-ner-ontonotes_loss: 0.1055
09/16 09:47:35 AM: Update 1675: task edges-ner-ontonotes, batch 675 (1675): mcc: 0.5806, acc: 0.4175, precision: 0.8197, recall: 0.4339, f1: 0.5674, edges-ner-ontonotes_loss: 0.1044
09/16 09:47:45 AM: Update 1795: task edges-ner-ontonotes, batch 795 (1795): mcc: 0.5860, acc: 0.4242, precision: 0.8216, recall: 0.4406, f1: 0.5736, edges-ner-ontonotes_loss: 0.1032
09/16 09:47:55 AM: Update 1885: task edges-ner-ontonotes, batch 885 (1885): mcc: 0.5906, acc: 0.4300, precision: 0.8225, recall: 0.4467, f1: 0.5790, edges-ner-ontonotes_loss: 0.1023
09/16 09:48:05 AM: Update 1998: task edges-ner-ontonotes, batch 998 (1998): mcc: 0.5976, acc: 0.4391, precision: 0.8229, recall: 0.4568, f1: 0.5875, edges-ner-ontonotes_loss: 0.1011
09/16 09:48:05 AM: ***** Step 2000 / Validation 2 *****
09/16 09:48:05 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:48:05 AM: Validating...
09/16 09:48:15 AM: Evaluate: task edges-ner-ontonotes, batch 79 (157): mcc: 0.7025, acc: 0.5700, precision: 0.8759, recall: 0.5841, f1: 0.7008, edges-ner-ontonotes_loss: 0.0854
09/16 09:48:25 AM: Evaluate: task edges-ner-ontonotes, batch 147 (157): mcc: 0.6933, acc: 0.5584, precision: 0.8689, recall: 0.5743, f1: 0.6915, edges-ner-ontonotes_loss: 0.0839
09/16 09:48:26 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:48:26 AM: Best result seen so far for macro.
09/16 09:48:26 AM: Updating LR scheduler:
09/16 09:48:26 AM: 	Best result seen so far for macro_avg: 0.691
09/16 09:48:26 AM: 	# validation passes without improvement: 0
09/16 09:48:26 AM: edges-ner-ontonotes_loss: training: 0.101024 validation: 0.083766
09/16 09:48:26 AM: macro_avg: validation: 0.690675
09/16 09:48:26 AM: micro_avg: validation: 0.000000
09/16 09:48:26 AM: edges-ner-ontonotes_mcc: training: 0.597975 validation: 0.692297
09/16 09:48:26 AM: edges-ner-ontonotes_acc: training: 0.439566 validation: 0.556794
09/16 09:48:26 AM: edges-ner-ontonotes_precision: training: 0.823145 validation: 0.867561
09/16 09:48:26 AM: edges-ner-ontonotes_recall: training: 0.457243 validation: 0.573703
09/16 09:48:26 AM: edges-ner-ontonotes_f1: training: 0.587911 validation: 0.690675
09/16 09:48:26 AM: Global learning rate: 0.0001
09/16 09:48:26 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:48:35 AM: Update 2101: task edges-ner-ontonotes, batch 101 (2101): mcc: 0.6688, acc: 0.5290, precision: 0.8433, recall: 0.5532, f1: 0.6681, edges-ner-ontonotes_loss: 0.0863
09/16 09:48:45 AM: Update 2187: task edges-ner-ontonotes, batch 187 (2187): mcc: 0.6655, acc: 0.5243, precision: 0.8417, recall: 0.5489, f1: 0.6645, edges-ner-ontonotes_loss: 0.0867
09/16 09:48:55 AM: Update 2299: task edges-ner-ontonotes, batch 299 (2299): mcc: 0.6765, acc: 0.5387, precision: 0.8435, recall: 0.5654, f1: 0.6770, edges-ner-ontonotes_loss: 0.0851
09/16 09:49:05 AM: Update 2412: task edges-ner-ontonotes, batch 412 (2412): mcc: 0.6819, acc: 0.5470, precision: 0.8428, recall: 0.5746, f1: 0.6833, edges-ner-ontonotes_loss: 0.0837
09/16 09:49:15 AM: Update 2502: task edges-ner-ontonotes, batch 502 (2502): mcc: 0.6848, acc: 0.5507, precision: 0.8435, recall: 0.5788, f1: 0.6865, edges-ner-ontonotes_loss: 0.0829
09/16 09:49:25 AM: Update 2613: task edges-ner-ontonotes, batch 613 (2613): mcc: 0.6868, acc: 0.5532, precision: 0.8438, recall: 0.5819, f1: 0.6888, edges-ner-ontonotes_loss: 0.0826
09/16 09:49:35 AM: Update 2726: task edges-ner-ontonotes, batch 726 (2726): mcc: 0.6894, acc: 0.5572, precision: 0.8446, recall: 0.5855, f1: 0.6916, edges-ner-ontonotes_loss: 0.0821
09/16 09:49:45 AM: Update 2818: task edges-ner-ontonotes, batch 818 (2818): mcc: 0.6889, acc: 0.5573, precision: 0.8427, recall: 0.5860, f1: 0.6913, edges-ner-ontonotes_loss: 0.0818
09/16 09:49:55 AM: Update 2929: task edges-ner-ontonotes, batch 929 (2929): mcc: 0.6820, acc: 0.5490, precision: 0.8382, recall: 0.5781, f1: 0.6842, edges-ner-ontonotes_loss: 0.0836
09/16 09:50:01 AM: ***** Step 3000 / Validation 3 *****
09/16 09:50:01 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:50:01 AM: Validating...
09/16 09:50:05 AM: Evaluate: task edges-ner-ontonotes, batch 39 (157): mcc: 0.7049, acc: 0.5871, precision: 0.8591, recall: 0.6002, f1: 0.7067, edges-ner-ontonotes_loss: 0.0827
09/16 09:50:15 AM: Evaluate: task edges-ner-ontonotes, batch 112 (157): mcc: 0.7401, acc: 0.6218, precision: 0.8871, recall: 0.6372, f1: 0.7416, edges-ner-ontonotes_loss: 0.0756
09/16 09:50:22 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:50:22 AM: Best result seen so far for macro.
09/16 09:50:22 AM: Updating LR scheduler:
09/16 09:50:22 AM: 	Best result seen so far for macro_avg: 0.730
09/16 09:50:22 AM: 	# validation passes without improvement: 0
09/16 09:50:22 AM: edges-ner-ontonotes_loss: training: 0.084542 validation: 0.075907
09/16 09:50:22 AM: macro_avg: validation: 0.730152
09/16 09:50:22 AM: micro_avg: validation: 0.000000
09/16 09:50:22 AM: edges-ner-ontonotes_mcc: training: 0.678842 validation: 0.728755
09/16 09:50:22 AM: edges-ner-ontonotes_acc: training: 0.545262 validation: 0.608204
09/16 09:50:22 AM: edges-ner-ontonotes_precision: training: 0.836099 validation: 0.879568
09/16 09:50:22 AM: edges-ner-ontonotes_recall: training: 0.574479 validation: 0.624128
09/16 09:50:22 AM: edges-ner-ontonotes_f1: training: 0.681028 validation: 0.730152
09/16 09:50:22 AM: Global learning rate: 0.0001
09/16 09:50:22 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:50:25 AM: Update 3045: task edges-ner-ontonotes, batch 45 (3045): mcc: 0.6370, acc: 0.4962, precision: 0.8134, recall: 0.5234, f1: 0.6369, edges-ner-ontonotes_loss: 0.0969
09/16 09:50:35 AM: Update 3157: task edges-ner-ontonotes, batch 157 (3157): mcc: 0.6481, acc: 0.5081, precision: 0.8213, recall: 0.5356, f1: 0.6483, edges-ner-ontonotes_loss: 0.0938
09/16 09:50:45 AM: Update 3316: task edges-ner-ontonotes, batch 316 (3316): mcc: 0.6629, acc: 0.5263, precision: 0.8314, recall: 0.5521, f1: 0.6635, edges-ner-ontonotes_loss: 0.0897
09/16 09:50:55 AM: Update 3440: task edges-ner-ontonotes, batch 440 (3440): mcc: 0.6662, acc: 0.5310, precision: 0.8317, recall: 0.5572, f1: 0.6674, edges-ner-ontonotes_loss: 0.0885
09/16 09:51:05 AM: Update 3570: task edges-ner-ontonotes, batch 570 (3570): mcc: 0.6743, acc: 0.5419, precision: 0.8340, recall: 0.5686, f1: 0.6762, edges-ner-ontonotes_loss: 0.0868
09/16 09:51:15 AM: Update 3703: task edges-ner-ontonotes, batch 703 (3703): mcc: 0.6821, acc: 0.5516, precision: 0.8377, recall: 0.5786, f1: 0.6845, edges-ner-ontonotes_loss: 0.0853
09/16 09:51:25 AM: Update 3803: task edges-ner-ontonotes, batch 803 (3803): mcc: 0.6850, acc: 0.5555, precision: 0.8381, recall: 0.5831, f1: 0.6877, edges-ner-ontonotes_loss: 0.0843
09/16 09:51:36 AM: Update 3937: task edges-ner-ontonotes, batch 937 (3937): mcc: 0.6924, acc: 0.5645, precision: 0.8408, recall: 0.5932, f1: 0.6956, edges-ner-ontonotes_loss: 0.0827
09/16 09:51:40 AM: ***** Step 4000 / Validation 4 *****
09/16 09:51:40 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:51:40 AM: Validating...
09/16 09:51:46 AM: Evaluate: task edges-ner-ontonotes, batch 52 (157): mcc: 0.7221, acc: 0.6157, precision: 0.8567, recall: 0.6305, f1: 0.7264, edges-ner-ontonotes_loss: 0.0817
09/16 09:51:56 AM: Evaluate: task edges-ner-ontonotes, batch 126 (157): mcc: 0.7543, acc: 0.6499, precision: 0.8828, recall: 0.6642, f1: 0.7580, edges-ner-ontonotes_loss: 0.0721
09/16 09:51:59 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:51:59 AM: Best result seen so far for macro.
09/16 09:51:59 AM: Updating LR scheduler:
09/16 09:51:59 AM: 	Best result seen so far for macro_avg: 0.761
09/16 09:51:59 AM: 	# validation passes without improvement: 0
09/16 09:51:59 AM: edges-ner-ontonotes_loss: training: 0.081945 validation: 0.070566
09/16 09:51:59 AM: macro_avg: validation: 0.761322
09/16 09:51:59 AM: micro_avg: validation: 0.000000
09/16 09:51:59 AM: edges-ner-ontonotes_mcc: training: 0.696081 validation: 0.757259
09/16 09:51:59 AM: edges-ner-ontonotes_acc: training: 0.568810 validation: 0.653700
09/16 09:51:59 AM: edges-ner-ontonotes_precision: training: 0.842785 validation: 0.882777
09/16 09:51:59 AM: edges-ner-ontonotes_recall: training: 0.597791 validation: 0.669245
09/16 09:51:59 AM: edges-ner-ontonotes_f1: training: 0.699456 validation: 0.761322
09/16 09:51:59 AM: Global learning rate: 0.0001
09/16 09:51:59 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:52:06 AM: Update 4053: task edges-ner-ontonotes, batch 53 (4053): mcc: 0.7260, acc: 0.6072, precision: 0.8514, recall: 0.6411, f1: 0.7314, edges-ner-ontonotes_loss: 0.0728
09/16 09:52:16 AM: Update 4182: task edges-ner-ontonotes, batch 182 (4182): mcc: 0.7299, acc: 0.6125, precision: 0.8531, recall: 0.6464, f1: 0.7355, edges-ner-ontonotes_loss: 0.0725
09/16 09:52:26 AM: Update 4311: task edges-ner-ontonotes, batch 311 (4311): mcc: 0.7281, acc: 0.6108, precision: 0.8512, recall: 0.6448, f1: 0.7338, edges-ner-ontonotes_loss: 0.0730
09/16 09:52:36 AM: Update 4426: task edges-ner-ontonotes, batch 426 (4426): mcc: 0.7185, acc: 0.5989, precision: 0.8453, recall: 0.6333, f1: 0.7241, edges-ner-ontonotes_loss: 0.0758
09/16 09:52:46 AM: Update 4555: task edges-ner-ontonotes, batch 555 (4555): mcc: 0.7037, acc: 0.5803, precision: 0.8361, recall: 0.6156, f1: 0.7091, edges-ner-ontonotes_loss: 0.0801
09/16 09:52:56 AM: Update 4670: task edges-ner-ontonotes, batch 670 (4670): mcc: 0.6965, acc: 0.5716, precision: 0.8319, recall: 0.6068, f1: 0.7017, edges-ner-ontonotes_loss: 0.0818
09/16 09:53:06 AM: Update 4831: task edges-ner-ontonotes, batch 831 (4831): mcc: 0.6969, acc: 0.5720, precision: 0.8335, recall: 0.6062, f1: 0.7019, edges-ner-ontonotes_loss: 0.0819
09/16 09:53:16 AM: Update 4980: task edges-ner-ontonotes, batch 980 (4980): mcc: 0.6967, acc: 0.5718, precision: 0.8337, recall: 0.6057, f1: 0.7017, edges-ner-ontonotes_loss: 0.0816
09/16 09:53:20 AM: ***** Step 5000 / Validation 5 *****
09/16 09:53:20 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:53:20 AM: Validating...
09/16 09:53:26 AM: Evaluate: task edges-ner-ontonotes, batch 57 (157): mcc: 0.7663, acc: 0.6683, precision: 0.8831, recall: 0.6844, f1: 0.7712, edges-ner-ontonotes_loss: 0.0678
09/16 09:53:36 AM: Evaluate: task edges-ner-ontonotes, batch 133 (157): mcc: 0.7750, acc: 0.6728, precision: 0.8977, recall: 0.6875, f1: 0.7786, edges-ner-ontonotes_loss: 0.0654
09/16 09:53:39 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:53:39 AM: Best result seen so far for macro.
09/16 09:53:39 AM: Updating LR scheduler:
09/16 09:53:39 AM: 	Best result seen so far for macro_avg: 0.773
09/16 09:53:39 AM: 	# validation passes without improvement: 0
09/16 09:53:39 AM: edges-ner-ontonotes_loss: training: 0.081616 validation: 0.065791
09/16 09:53:39 AM: macro_avg: validation: 0.773388
09/16 09:53:39 AM: micro_avg: validation: 0.000000
09/16 09:53:39 AM: edges-ner-ontonotes_mcc: training: 0.696545 validation: 0.769733
09/16 09:53:39 AM: edges-ner-ontonotes_acc: training: 0.571627 validation: 0.665150
09/16 09:53:39 AM: edges-ner-ontonotes_precision: training: 0.833758 validation: 0.894129
09/16 09:53:39 AM: edges-ner-ontonotes_recall: training: 0.605406 validation: 0.681377
09/16 09:53:39 AM: edges-ner-ontonotes_f1: training: 0.701466 validation: 0.773388
09/16 09:53:39 AM: Global learning rate: 0.0001
09/16 09:53:39 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:53:46 AM: Update 5085: task edges-ner-ontonotes, batch 85 (5085): mcc: 0.7014, acc: 0.5835, precision: 0.8327, recall: 0.6144, f1: 0.7071, edges-ner-ontonotes_loss: 0.0785
09/16 09:53:56 AM: Update 5217: task edges-ner-ontonotes, batch 217 (5217): mcc: 0.7089, acc: 0.5902, precision: 0.8372, recall: 0.6235, f1: 0.7147, edges-ner-ontonotes_loss: 0.0770
09/16 09:54:06 AM: Update 5336: task edges-ner-ontonotes, batch 336 (5336): mcc: 0.7179, acc: 0.6010, precision: 0.8429, recall: 0.6341, f1: 0.7238, edges-ner-ontonotes_loss: 0.0752
09/16 09:54:16 AM: Update 5464: task edges-ner-ontonotes, batch 464 (5464): mcc: 0.7261, acc: 0.6111, precision: 0.8481, recall: 0.6440, f1: 0.7321, edges-ner-ontonotes_loss: 0.0735
09/16 09:54:26 AM: Update 5590: task edges-ner-ontonotes, batch 590 (5590): mcc: 0.7311, acc: 0.6167, precision: 0.8515, recall: 0.6497, f1: 0.7371, edges-ner-ontonotes_loss: 0.0723
09/16 09:54:36 AM: Update 5685: task edges-ner-ontonotes, batch 685 (5685): mcc: 0.7314, acc: 0.6172, precision: 0.8510, recall: 0.6506, f1: 0.7374, edges-ner-ontonotes_loss: 0.0721
09/16 09:54:46 AM: Update 5815: task edges-ner-ontonotes, batch 815 (5815): mcc: 0.7339, acc: 0.6200, precision: 0.8527, recall: 0.6536, f1: 0.7400, edges-ner-ontonotes_loss: 0.0715
09/16 09:54:56 AM: Update 5924: task edges-ner-ontonotes, batch 924 (5924): mcc: 0.7322, acc: 0.6183, precision: 0.8510, recall: 0.6519, f1: 0.7383, edges-ner-ontonotes_loss: 0.0717
09/16 09:55:02 AM: ***** Step 6000 / Validation 6 *****
09/16 09:55:02 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:55:02 AM: Validating...
09/16 09:55:06 AM: Evaluate: task edges-ner-ontonotes, batch 43 (157): mcc: 0.7489, acc: 0.6498, precision: 0.8701, recall: 0.6651, f1: 0.7539, edges-ner-ontonotes_loss: 0.0716
09/16 09:55:16 AM: Evaluate: task edges-ner-ontonotes, batch 119 (157): mcc: 0.7828, acc: 0.6811, precision: 0.9009, recall: 0.6981, f1: 0.7867, edges-ner-ontonotes_loss: 0.0644
09/16 09:55:21 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:55:21 AM: Best result seen so far for macro.
09/16 09:55:21 AM: Updating LR scheduler:
09/16 09:55:21 AM: 	Best result seen so far for macro_avg: 0.785
09/16 09:55:21 AM: 	# validation passes without improvement: 0
09/16 09:55:21 AM: edges-ner-ontonotes_loss: training: 0.073081 validation: 0.063775
09/16 09:55:21 AM: macro_avg: validation: 0.784635
09/16 09:55:21 AM: micro_avg: validation: 0.000000
09/16 09:55:21 AM: edges-ner-ontonotes_mcc: training: 0.727293 validation: 0.780960
09/16 09:55:21 AM: edges-ner-ontonotes_acc: training: 0.612453 validation: 0.676903
09/16 09:55:21 AM: edges-ner-ontonotes_precision: training: 0.847419 validation: 0.901407
09/16 09:55:21 AM: edges-ner-ontonotes_recall: training: 0.646523 validation: 0.694647
09/16 09:55:21 AM: edges-ner-ontonotes_f1: training: 0.733463 validation: 0.784635
09/16 09:55:21 AM: Global learning rate: 0.0001
09/16 09:55:21 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:55:27 AM: Update 6076: task edges-ner-ontonotes, batch 76 (6076): mcc: 0.6699, acc: 0.5398, precision: 0.8071, recall: 0.5814, f1: 0.6759, edges-ner-ontonotes_loss: 0.0889
09/16 09:55:37 AM: Update 6210: task edges-ner-ontonotes, batch 210 (6210): mcc: 0.6722, acc: 0.5425, precision: 0.8111, recall: 0.5821, f1: 0.6778, edges-ner-ontonotes_loss: 0.0886
09/16 09:55:47 AM: Update 6339: task edges-ner-ontonotes, batch 339 (6339): mcc: 0.6826, acc: 0.5553, precision: 0.8204, recall: 0.5924, f1: 0.6880, edges-ner-ontonotes_loss: 0.0854
09/16 09:55:57 AM: Update 6493: task edges-ner-ontonotes, batch 493 (6493): mcc: 0.6878, acc: 0.5621, precision: 0.8244, recall: 0.5980, f1: 0.6932, edges-ner-ontonotes_loss: 0.0835
09/16 09:56:07 AM: Update 6604: task edges-ner-ontonotes, batch 604 (6604): mcc: 0.6918, acc: 0.5681, precision: 0.8262, recall: 0.6033, f1: 0.6973, edges-ner-ontonotes_loss: 0.0824
09/16 09:56:17 AM: Update 6738: task edges-ner-ontonotes, batch 738 (6738): mcc: 0.7002, acc: 0.5788, precision: 0.8317, recall: 0.6131, f1: 0.7059, edges-ner-ontonotes_loss: 0.0806
09/16 09:56:27 AM: Update 6851: task edges-ner-ontonotes, batch 851 (6851): mcc: 0.7037, acc: 0.5830, precision: 0.8339, recall: 0.6174, f1: 0.7095, edges-ner-ontonotes_loss: 0.0797
09/16 09:56:37 AM: Update 6982: task edges-ner-ontonotes, batch 982 (6982): mcc: 0.7108, acc: 0.5920, precision: 0.8374, recall: 0.6265, f1: 0.7168, edges-ner-ontonotes_loss: 0.0781
09/16 09:56:39 AM: ***** Step 7000 / Validation 7 *****
09/16 09:56:39 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:56:39 AM: Validating...
09/16 09:56:47 AM: Evaluate: task edges-ner-ontonotes, batch 77 (157): mcc: 0.7590, acc: 0.6636, precision: 0.8700, recall: 0.6825, f1: 0.7649, edges-ner-ontonotes_loss: 0.0719
09/16 09:56:57 AM: Evaluate: task edges-ner-ontonotes, batch 155 (157): mcc: 0.7822, acc: 0.6893, precision: 0.8866, recall: 0.7088, f1: 0.7878, edges-ner-ontonotes_loss: 0.0636
09/16 09:56:57 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:56:57 AM: Best result seen so far for macro.
09/16 09:56:57 AM: Updating LR scheduler:
09/16 09:56:57 AM: 	Best result seen so far for macro_avg: 0.788
09/16 09:56:57 AM: 	# validation passes without improvement: 0
09/16 09:56:57 AM: edges-ner-ontonotes_loss: training: 0.077849 validation: 0.063425
09/16 09:56:57 AM: macro_avg: validation: 0.787644
09/16 09:56:57 AM: micro_avg: validation: 0.000000
09/16 09:56:57 AM: edges-ner-ontonotes_mcc: training: 0.711654 validation: 0.782021
09/16 09:56:57 AM: edges-ner-ontonotes_acc: training: 0.592896 validation: 0.688960
09/16 09:56:57 AM: edges-ner-ontonotes_precision: training: 0.838291 validation: 0.886538
09/16 09:56:57 AM: edges-ner-ontonotes_recall: training: 0.627249 validation: 0.708599
09/16 09:56:57 AM: edges-ner-ontonotes_f1: training: 0.717575 validation: 0.787644
09/16 09:56:57 AM: Global learning rate: 0.0001
09/16 09:56:57 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:57:07 AM: Update 7126: task edges-ner-ontonotes, batch 126 (7126): mcc: 0.7565, acc: 0.6507, precision: 0.8572, recall: 0.6887, f1: 0.7638, edges-ner-ontonotes_loss: 0.0660
09/16 09:57:17 AM: Update 7237: task edges-ner-ontonotes, batch 237 (7237): mcc: 0.7493, acc: 0.6416, precision: 0.8537, recall: 0.6792, f1: 0.7565, edges-ner-ontonotes_loss: 0.0674
09/16 09:57:28 AM: Update 7365: task edges-ner-ontonotes, batch 365 (7365): mcc: 0.7502, acc: 0.6424, precision: 0.8557, recall: 0.6792, f1: 0.7573, edges-ner-ontonotes_loss: 0.0670
09/16 09:57:38 AM: Update 7477: task edges-ner-ontonotes, batch 477 (7477): mcc: 0.7474, acc: 0.6396, precision: 0.8524, recall: 0.6770, f1: 0.7546, edges-ner-ontonotes_loss: 0.0679
09/16 09:57:48 AM: Update 7605: task edges-ner-ontonotes, batch 605 (7605): mcc: 0.7318, acc: 0.6197, precision: 0.8426, recall: 0.6581, f1: 0.7390, edges-ner-ontonotes_loss: 0.0722
09/16 09:57:58 AM: Update 7734: task edges-ner-ontonotes, batch 734 (7734): mcc: 0.7232, acc: 0.6088, precision: 0.8380, recall: 0.6471, f1: 0.7303, edges-ner-ontonotes_loss: 0.0750
09/16 09:58:08 AM: Update 7853: task edges-ner-ontonotes, batch 853 (7853): mcc: 0.7207, acc: 0.6055, precision: 0.8367, recall: 0.6438, f1: 0.7277, edges-ner-ontonotes_loss: 0.0758
09/16 09:58:17 AM: ***** Step 8000 / Validation 8 *****
09/16 09:58:17 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:58:17 AM: Validating...
09/16 09:58:18 AM: Evaluate: task edges-ner-ontonotes, batch 6 (157): mcc: 0.6716, acc: 0.5500, precision: 0.8364, recall: 0.5625, f1: 0.6726, edges-ner-ontonotes_loss: 0.0856
09/16 09:58:28 AM: Evaluate: task edges-ner-ontonotes, batch 96 (157): mcc: 0.7884, acc: 0.6849, precision: 0.9058, recall: 0.7038, f1: 0.7921, edges-ner-ontonotes_loss: 0.0613
09/16 09:58:36 AM: Updating LR scheduler:
09/16 09:58:36 AM: 	Best result seen so far for macro_avg: 0.788
09/16 09:58:36 AM: 	# validation passes without improvement: 1
09/16 09:58:36 AM: edges-ner-ontonotes_loss: training: 0.075845 validation: 0.062495
09/16 09:58:36 AM: macro_avg: validation: 0.777615
09/16 09:58:36 AM: micro_avg: validation: 0.000000
09/16 09:58:36 AM: edges-ner-ontonotes_mcc: training: 0.720294 validation: 0.774385
09/16 09:58:36 AM: edges-ner-ontonotes_acc: training: 0.604600 validation: 0.666060
09/16 09:58:36 AM: edges-ner-ontonotes_precision: training: 0.837620 validation: 0.900339
09/16 09:58:36 AM: edges-ner-ontonotes_recall: training: 0.642461 validation: 0.684334
09/16 09:58:36 AM: edges-ner-ontonotes_f1: training: 0.727174 validation: 0.777615
09/16 09:58:36 AM: Global learning rate: 0.0001
09/16 09:58:36 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:58:38 AM: Update 8030: task edges-ner-ontonotes, batch 30 (8030): mcc: 0.7239, acc: 0.5981, precision: 0.8481, recall: 0.6401, f1: 0.7296, edges-ner-ontonotes_loss: 0.0719
09/16 09:58:48 AM: Update 8144: task edges-ner-ontonotes, batch 144 (8144): mcc: 0.7149, acc: 0.5973, precision: 0.8381, recall: 0.6329, f1: 0.7212, edges-ner-ontonotes_loss: 0.0757
09/16 09:58:58 AM: Update 8277: task edges-ner-ontonotes, batch 277 (8277): mcc: 0.7232, acc: 0.6061, precision: 0.8412, recall: 0.6446, f1: 0.7299, edges-ner-ontonotes_loss: 0.0742
09/16 09:59:10 AM: Update 8407: task edges-ner-ontonotes, batch 407 (8407): mcc: 0.7237, acc: 0.6084, precision: 0.8407, recall: 0.6459, f1: 0.7305, edges-ner-ontonotes_loss: 0.0739
09/16 09:59:20 AM: Update 8533: task edges-ner-ontonotes, batch 533 (8533): mcc: 0.7319, acc: 0.6176, precision: 0.8460, recall: 0.6555, f1: 0.7387, edges-ner-ontonotes_loss: 0.0720
09/16 09:59:30 AM: Update 8657: task edges-ner-ontonotes, batch 657 (8657): mcc: 0.7396, acc: 0.6270, precision: 0.8512, recall: 0.6645, f1: 0.7463, edges-ner-ontonotes_loss: 0.0704
09/16 09:59:40 AM: Update 8767: task edges-ner-ontonotes, batch 767 (8767): mcc: 0.7416, acc: 0.6295, precision: 0.8521, recall: 0.6672, f1: 0.7484, edges-ner-ontonotes_loss: 0.0697
09/16 09:59:50 AM: Update 8900: task edges-ner-ontonotes, batch 900 (8900): mcc: 0.7440, acc: 0.6329, precision: 0.8529, recall: 0.6707, f1: 0.7509, edges-ner-ontonotes_loss: 0.0692
09/16 09:59:58 AM: ***** Step 9000 / Validation 9 *****
09/16 09:59:58 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:59:58 AM: Validating...
09/16 10:00:00 AM: Evaluate: task edges-ner-ontonotes, batch 22 (157): mcc: 0.7075, acc: 0.6037, precision: 0.8387, recall: 0.6200, f1: 0.7129, edges-ner-ontonotes_loss: 0.0788
09/16 10:00:10 AM: Evaluate: task edges-ner-ontonotes, batch 105 (157): mcc: 0.7841, acc: 0.6883, precision: 0.8931, recall: 0.7067, f1: 0.7890, edges-ner-ontonotes_loss: 0.0639
09/16 10:00:17 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:00:17 AM: Best result seen so far for macro.
09/16 10:00:17 AM: Updating LR scheduler:
09/16 10:00:17 AM: 	Best result seen so far for macro_avg: 0.797
09/16 10:00:17 AM: 	# validation passes without improvement: 0
09/16 10:00:17 AM: edges-ner-ontonotes_loss: training: 0.068959 validation: 0.059757
09/16 10:00:17 AM: macro_avg: validation: 0.797410
09/16 10:00:17 AM: micro_avg: validation: 0.000000
09/16 10:00:17 AM: edges-ner-ontonotes_mcc: training: 0.744814 validation: 0.792898
09/16 10:00:17 AM: edges-ner-ontonotes_acc: training: 0.633766 validation: 0.696012
09/16 10:00:17 AM: edges-ner-ontonotes_precision: training: 0.853069 validation: 0.902308
09/16 10:00:17 AM: edges-ner-ontonotes_recall: training: 0.671966 validation: 0.714362
09/16 10:00:17 AM: edges-ner-ontonotes_f1: training: 0.751764 validation: 0.797410
09/16 10:00:17 AM: Global learning rate: 0.0001
09/16 10:00:17 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:00:22 AM: Update 9033: task edges-ner-ontonotes, batch 33 (9033): mcc: 0.7138, acc: 0.5997, precision: 0.8268, recall: 0.6400, f1: 0.7215, edges-ner-ontonotes_loss: 0.0728
09/16 10:00:32 AM: Update 9163: task edges-ner-ontonotes, batch 163 (9163): mcc: 0.6862, acc: 0.5641, precision: 0.8109, recall: 0.6059, f1: 0.6936, edges-ner-ontonotes_loss: 0.0836
09/16 10:00:42 AM: Update 9302: task edges-ner-ontonotes, batch 302 (9302): mcc: 0.6805, acc: 0.5573, precision: 0.8065, recall: 0.5996, f1: 0.6878, edges-ner-ontonotes_loss: 0.0856
09/16 10:00:52 AM: Update 9430: task edges-ner-ontonotes, batch 430 (9430): mcc: 0.6875, acc: 0.5646, precision: 0.8145, recall: 0.6051, f1: 0.6944, edges-ner-ontonotes_loss: 0.0833
09/16 10:01:02 AM: Update 9593: task edges-ner-ontonotes, batch 593 (9593): mcc: 0.6966, acc: 0.5750, precision: 0.8227, recall: 0.6140, f1: 0.7032, edges-ner-ontonotes_loss: 0.0808
09/16 10:01:12 AM: Update 9709: task edges-ner-ontonotes, batch 709 (9709): mcc: 0.7001, acc: 0.5795, precision: 0.8254, recall: 0.6179, f1: 0.7068, edges-ner-ontonotes_loss: 0.0800
09/16 10:01:22 AM: Update 9846: task edges-ner-ontonotes, batch 846 (9846): mcc: 0.7075, acc: 0.5890, precision: 0.8300, recall: 0.6268, f1: 0.7142, edges-ner-ontonotes_loss: 0.0785
09/16 10:01:32 AM: Update 9963: task edges-ner-ontonotes, batch 963 (9963): mcc: 0.7102, acc: 0.5920, precision: 0.8317, recall: 0.6300, f1: 0.7170, edges-ner-ontonotes_loss: 0.0778
09/16 10:01:35 AM: ***** Step 10000 / Validation 10 *****
09/16 10:01:35 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:01:35 AM: Validating...
09/16 10:01:42 AM: Evaluate: task edges-ner-ontonotes, batch 67 (157): mcc: 0.7657, acc: 0.6713, precision: 0.8797, recall: 0.6862, f1: 0.7710, edges-ner-ontonotes_loss: 0.0676
09/16 10:01:52 AM: Evaluate: task edges-ner-ontonotes, batch 145 (157): mcc: 0.7942, acc: 0.7014, precision: 0.9027, recall: 0.7163, f1: 0.7988, edges-ner-ontonotes_loss: 0.0600
09/16 10:01:54 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:01:54 AM: Best result seen so far for macro.
09/16 10:01:54 AM: Updating LR scheduler:
09/16 10:01:54 AM: 	Best result seen so far for macro_avg: 0.799
09/16 10:01:54 AM: 	# validation passes without improvement: 0
09/16 10:01:54 AM: edges-ner-ontonotes_loss: training: 0.077357 validation: 0.059601
09/16 10:01:54 AM: macro_avg: validation: 0.798868
09/16 10:01:54 AM: micro_avg: validation: 0.000000
09/16 10:01:54 AM: edges-ner-ontonotes_mcc: training: 0.711572 validation: 0.794189
09/16 10:01:54 AM: edges-ner-ontonotes_acc: training: 0.593520 validation: 0.701244
09/16 10:01:54 AM: edges-ner-ontonotes_precision: training: 0.832602 validation: 0.901697
09/16 10:01:54 AM: edges-ner-ontonotes_recall: training: 0.631623 validation: 0.717091
09/16 10:01:54 AM: edges-ner-ontonotes_f1: training: 0.718319 validation: 0.798868
09/16 10:01:54 AM: Global learning rate: 0.0001
09/16 10:01:54 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:02:03 AM: Update 10114: task edges-ner-ontonotes, batch 114 (10114): mcc: 0.7607, acc: 0.6573, precision: 0.8585, recall: 0.6950, f1: 0.7681, edges-ner-ontonotes_loss: 0.0652
09/16 10:02:13 AM: Update 10244: task edges-ner-ontonotes, batch 244 (10244): mcc: 0.7628, acc: 0.6587, precision: 0.8610, recall: 0.6966, f1: 0.7701, edges-ner-ontonotes_loss: 0.0642
09/16 10:02:23 AM: Update 10351: task edges-ner-ontonotes, batch 351 (10351): mcc: 0.7580, acc: 0.6524, precision: 0.8583, recall: 0.6905, f1: 0.7653, edges-ner-ontonotes_loss: 0.0646
09/16 10:02:33 AM: Update 10478: task edges-ner-ontonotes, batch 478 (10478): mcc: 0.7578, acc: 0.6526, precision: 0.8573, recall: 0.6910, f1: 0.7652, edges-ner-ontonotes_loss: 0.0645
09/16 10:02:43 AM: Update 10590: task edges-ner-ontonotes, batch 590 (10590): mcc: 0.7554, acc: 0.6499, precision: 0.8545, recall: 0.6891, f1: 0.7629, edges-ner-ontonotes_loss: 0.0650
09/16 10:02:53 AM: Update 10725: task edges-ner-ontonotes, batch 725 (10725): mcc: 0.7435, acc: 0.6343, precision: 0.8468, recall: 0.6748, f1: 0.7511, edges-ner-ontonotes_loss: 0.0689
09/16 10:03:03 AM: Update 10852: task edges-ner-ontonotes, batch 852 (10852): mcc: 0.7364, acc: 0.6252, precision: 0.8430, recall: 0.6658, f1: 0.7440, edges-ner-ontonotes_loss: 0.0713
09/16 10:03:13 AM: Update 10967: task edges-ner-ontonotes, batch 967 (10967): mcc: 0.7333, acc: 0.6206, precision: 0.8419, recall: 0.6613, f1: 0.7407, edges-ner-ontonotes_loss: 0.0723
09/16 10:03:15 AM: ***** Step 11000 / Validation 11 *****
09/16 10:03:15 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:03:15 AM: Validating...
09/16 10:03:23 AM: Evaluate: task edges-ner-ontonotes, batch 74 (157): mcc: 0.7919, acc: 0.6918, precision: 0.8984, recall: 0.7158, f1: 0.7968, edges-ner-ontonotes_loss: 0.0610
09/16 10:03:33 AM: Evaluate: task edges-ner-ontonotes, batch 152 (157): mcc: 0.7919, acc: 0.6866, precision: 0.9067, recall: 0.7090, f1: 0.7958, edges-ner-ontonotes_loss: 0.0586
09/16 10:03:33 AM: Updating LR scheduler:
09/16 10:03:33 AM: 	Best result seen so far for macro_avg: 0.799
09/16 10:03:33 AM: 	# validation passes without improvement: 1
09/16 10:03:33 AM: edges-ner-ontonotes_loss: training: 0.072387 validation: 0.058440
09/16 10:03:33 AM: macro_avg: validation: 0.795421
09/16 10:03:33 AM: micro_avg: validation: 0.000000
09/16 10:03:33 AM: edges-ner-ontonotes_mcc: training: 0.733144 validation: 0.791530
09/16 10:03:33 AM: edges-ner-ontonotes_acc: training: 0.620425 validation: 0.686154
09/16 10:03:33 AM: edges-ner-ontonotes_precision: training: 0.841928 validation: 0.906489
09/16 10:03:33 AM: edges-ner-ontonotes_recall: training: 0.661006 validation: 0.708599
09/16 10:03:33 AM: edges-ner-ontonotes_f1: training: 0.740577 validation: 0.795421
09/16 10:03:33 AM: Global learning rate: 0.0001
09/16 10:03:33 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:03:43 AM: Update 11144: task edges-ner-ontonotes, batch 144 (11144): mcc: 0.7306, acc: 0.6156, precision: 0.8468, recall: 0.6526, f1: 0.7372, edges-ner-ontonotes_loss: 0.0725
09/16 10:03:53 AM: Update 11262: task edges-ner-ontonotes, batch 262 (11262): mcc: 0.7255, acc: 0.6107, precision: 0.8412, recall: 0.6486, f1: 0.7324, edges-ner-ontonotes_loss: 0.0733
09/16 10:04:03 AM: Update 11392: task edges-ner-ontonotes, batch 392 (11392): mcc: 0.7294, acc: 0.6160, precision: 0.8448, recall: 0.6522, f1: 0.7361, edges-ner-ontonotes_loss: 0.0721
09/16 10:04:15 AM: Update 11519: task edges-ner-ontonotes, batch 519 (11519): mcc: 0.7310, acc: 0.6190, precision: 0.8442, recall: 0.6554, f1: 0.7379, edges-ner-ontonotes_loss: 0.0718
09/16 10:04:25 AM: Update 11647: task edges-ner-ontonotes, batch 647 (11647): mcc: 0.7366, acc: 0.6257, precision: 0.8471, recall: 0.6628, f1: 0.7437, edges-ner-ontonotes_loss: 0.0705
09/16 10:04:35 AM: Update 11779: task edges-ner-ontonotes, batch 779 (11779): mcc: 0.7431, acc: 0.6334, precision: 0.8509, recall: 0.6708, f1: 0.7502, edges-ner-ontonotes_loss: 0.0690
09/16 10:04:45 AM: Update 11890: task edges-ner-ontonotes, batch 890 (11890): mcc: 0.7459, acc: 0.6370, precision: 0.8520, recall: 0.6748, f1: 0.7531, edges-ner-ontonotes_loss: 0.0683
09/16 10:04:54 AM: ***** Step 12000 / Validation 12 *****
09/16 10:04:54 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:04:54 AM: Validating...
09/16 10:04:55 AM: Evaluate: task edges-ner-ontonotes, batch 13 (157): mcc: 0.6916, acc: 0.5881, precision: 0.8142, recall: 0.6124, f1: 0.6990, edges-ner-ontonotes_loss: 0.0836
09/16 10:05:05 AM: Evaluate: task edges-ner-ontonotes, batch 100 (157): mcc: 0.7871, acc: 0.6978, precision: 0.8850, recall: 0.7188, f1: 0.7933, edges-ner-ontonotes_loss: 0.0630
09/16 10:05:12 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:05:12 AM: Best result seen so far for macro.
09/16 10:05:12 AM: Updating LR scheduler:
09/16 10:05:12 AM: 	Best result seen so far for macro_avg: 0.808
09/16 10:05:12 AM: 	# validation passes without improvement: 0
09/16 10:05:12 AM: edges-ner-ontonotes_loss: training: 0.067924 validation: 0.057551
09/16 10:05:12 AM: macro_avg: validation: 0.807960
09/16 10:05:12 AM: micro_avg: validation: 0.000000
09/16 10:05:12 AM: edges-ner-ontonotes_mcc: training: 0.747980 validation: 0.802353
09/16 10:05:12 AM: edges-ner-ontonotes_acc: training: 0.639706 validation: 0.713224
09/16 10:05:12 AM: edges-ner-ontonotes_precision: training: 0.852811 validation: 0.898154
09/16 10:05:12 AM: edges-ner-ontonotes_recall: training: 0.677652 validation: 0.734228
09/16 10:05:12 AM: edges-ner-ontonotes_f1: training: 0.755208 validation: 0.807960
09/16 10:05:12 AM: Global learning rate: 0.0001
09/16 10:05:12 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:05:15 AM: Update 12035: task edges-ner-ontonotes, batch 35 (12035): mcc: 0.7648, acc: 0.6641, precision: 0.8610, recall: 0.7001, f1: 0.7723, edges-ner-ontonotes_loss: 0.0638
09/16 10:05:25 AM: Update 12145: task edges-ner-ontonotes, batch 145 (12145): mcc: 0.7550, acc: 0.6490, precision: 0.8537, recall: 0.6891, f1: 0.7626, edges-ner-ontonotes_loss: 0.0664
09/16 10:05:35 AM: Update 12277: task edges-ner-ontonotes, batch 277 (12277): mcc: 0.7220, acc: 0.6051, precision: 0.8330, recall: 0.6491, f1: 0.7297, edges-ner-ontonotes_loss: 0.0758
09/16 10:05:45 AM: Update 12411: task edges-ner-ontonotes, batch 411 (12411): mcc: 0.7124, acc: 0.5940, precision: 0.8268, recall: 0.6378, f1: 0.7201, edges-ner-ontonotes_loss: 0.0788
09/16 10:05:55 AM: Update 12531: task edges-ner-ontonotes, batch 531 (12531): mcc: 0.7118, acc: 0.5934, precision: 0.8263, recall: 0.6371, f1: 0.7195, edges-ner-ontonotes_loss: 0.0787
09/16 10:06:06 AM: Update 12683: task edges-ner-ontonotes, batch 683 (12683): mcc: 0.7140, acc: 0.5960, precision: 0.8287, recall: 0.6389, f1: 0.7215, edges-ner-ontonotes_loss: 0.0776
09/16 10:06:16 AM: Update 12808: task edges-ner-ontonotes, batch 808 (12808): mcc: 0.7145, acc: 0.5967, precision: 0.8292, recall: 0.6394, f1: 0.7220, edges-ner-ontonotes_loss: 0.0770
09/16 10:06:26 AM: Update 12938: task edges-ner-ontonotes, batch 938 (12938): mcc: 0.7181, acc: 0.6015, precision: 0.8318, recall: 0.6435, f1: 0.7256, edges-ner-ontonotes_loss: 0.0760
09/16 10:06:30 AM: ***** Step 13000 / Validation 13 *****
09/16 10:06:30 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:06:30 AM: Validating...
09/16 10:06:36 AM: Evaluate: task edges-ner-ontonotes, batch 54 (157): mcc: 0.7866, acc: 0.7016, precision: 0.8783, recall: 0.7235, f1: 0.7934, edges-ner-ontonotes_loss: 0.0611
09/16 10:06:46 AM: Evaluate: task edges-ner-ontonotes, batch 132 (157): mcc: 0.8041, acc: 0.7152, precision: 0.8976, recall: 0.7377, f1: 0.8098, edges-ner-ontonotes_loss: 0.0563
09/16 10:06:49 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:06:49 AM: Best result seen so far for macro.
09/16 10:06:49 AM: Updating LR scheduler:
09/16 10:06:49 AM: 	Best result seen so far for macro_avg: 0.808
09/16 10:06:49 AM: 	# validation passes without improvement: 1
09/16 10:06:49 AM: edges-ner-ontonotes_loss: training: 0.075424 validation: 0.056094
09/16 10:06:49 AM: macro_avg: validation: 0.808018
09/16 10:06:49 AM: micro_avg: validation: 0.000000
09/16 10:06:49 AM: edges-ner-ontonotes_mcc: training: 0.720389 validation: 0.802284
09/16 10:06:49 AM: edges-ner-ontonotes_acc: training: 0.604339 validation: 0.712087
09/16 10:06:49 AM: edges-ner-ontonotes_precision: training: 0.833629 validation: 0.896938
09/16 10:06:49 AM: edges-ner-ontonotes_recall: training: 0.645856 validation: 0.735138
09/16 10:06:49 AM: edges-ner-ontonotes_f1: training: 0.727826 validation: 0.808018
09/16 10:06:49 AM: Global learning rate: 0.0001
09/16 10:06:49 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:06:56 AM: Update 13078: task edges-ner-ontonotes, batch 78 (13078): mcc: 0.7310, acc: 0.6191, precision: 0.8389, recall: 0.6599, f1: 0.7387, edges-ner-ontonotes_loss: 0.0714
09/16 10:07:06 AM: Update 13203: task edges-ner-ontonotes, batch 203 (13203): mcc: 0.7508, acc: 0.6417, precision: 0.8512, recall: 0.6839, f1: 0.7584, edges-ner-ontonotes_loss: 0.0665
09/16 10:07:16 AM: Update 13334: task edges-ner-ontonotes, batch 334 (13334): mcc: 0.7588, acc: 0.6524, precision: 0.8562, recall: 0.6936, f1: 0.7664, edges-ner-ontonotes_loss: 0.0645
09/16 10:07:26 AM: Update 13449: task edges-ner-ontonotes, batch 449 (13449): mcc: 0.7595, acc: 0.6533, precision: 0.8561, recall: 0.6950, f1: 0.7672, edges-ner-ontonotes_loss: 0.0642
09/16 10:07:36 AM: Update 13582: task edges-ner-ontonotes, batch 582 (13582): mcc: 0.7611, acc: 0.6551, precision: 0.8573, recall: 0.6968, f1: 0.7687, edges-ner-ontonotes_loss: 0.0639
09/16 10:07:46 AM: Update 13701: task edges-ner-ontonotes, batch 701 (13701): mcc: 0.7608, acc: 0.6545, precision: 0.8568, recall: 0.6967, f1: 0.7685, edges-ner-ontonotes_loss: 0.0639
09/16 10:07:56 AM: Update 13837: task edges-ner-ontonotes, batch 837 (13837): mcc: 0.7495, acc: 0.6408, precision: 0.8487, recall: 0.6838, f1: 0.7573, edges-ner-ontonotes_loss: 0.0675
09/16 10:08:06 AM: Update 13971: task edges-ner-ontonotes, batch 971 (13971): mcc: 0.7418, acc: 0.6311, precision: 0.8438, recall: 0.6745, f1: 0.7497, edges-ner-ontonotes_loss: 0.0698
09/16 10:08:08 AM: ***** Step 14000 / Validation 14 *****
09/16 10:08:08 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:08:08 AM: Validating...
09/16 10:08:16 AM: Evaluate: task edges-ner-ontonotes, batch 75 (157): mcc: 0.7889, acc: 0.6849, precision: 0.9058, recall: 0.7047, f1: 0.7927, edges-ner-ontonotes_loss: 0.0603
09/16 10:08:26 AM: Evaluate: task edges-ner-ontonotes, batch 155 (157): mcc: 0.7932, acc: 0.6852, precision: 0.9157, recall: 0.7041, f1: 0.7961, edges-ner-ontonotes_loss: 0.0570
09/16 10:08:26 AM: Updating LR scheduler:
09/16 10:08:26 AM: 	Best result seen so far for macro_avg: 0.808
09/16 10:08:26 AM: 	# validation passes without improvement: 2
09/16 10:08:26 AM: edges-ner-ontonotes_loss: training: 0.070237 validation: 0.056899
09/16 10:08:26 AM: macro_avg: validation: 0.795884
09/16 10:08:26 AM: micro_avg: validation: 0.000000
09/16 10:08:26 AM: edges-ner-ontonotes_mcc: training: 0.740831 validation: 0.793054
09/16 10:08:26 AM: edges-ner-ontonotes_acc: training: 0.629861 validation: 0.685017
09/16 10:08:26 AM: edges-ner-ontonotes_precision: training: 0.843104 validation: 0.915655
09/16 10:08:26 AM: edges-ner-ontonotes_recall: training: 0.673336 validation: 0.703822
09/16 10:08:26 AM: edges-ner-ontonotes_f1: training: 0.748717 validation: 0.795884
09/16 10:08:26 AM: Global learning rate: 0.0001
09/16 10:08:26 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:08:36 AM: Update 14135: task edges-ner-ontonotes, batch 135 (14135): mcc: 0.7229, acc: 0.6061, precision: 0.8403, recall: 0.6447, f1: 0.7296, edges-ner-ontonotes_loss: 0.0739
09/16 10:08:46 AM: Update 14293: task edges-ner-ontonotes, batch 293 (14293): mcc: 0.7267, acc: 0.6097, precision: 0.8412, recall: 0.6506, f1: 0.7337, edges-ner-ontonotes_loss: 0.0730
09/16 10:08:56 AM: Update 14407: task edges-ner-ontonotes, batch 407 (14407): mcc: 0.7254, acc: 0.6101, precision: 0.8390, recall: 0.6500, f1: 0.7326, edges-ner-ontonotes_loss: 0.0732
09/16 10:09:06 AM: Update 14541: task edges-ner-ontonotes, batch 541 (14541): mcc: 0.7296, acc: 0.6158, precision: 0.8409, recall: 0.6558, f1: 0.7369, edges-ner-ontonotes_loss: 0.0721
09/16 10:09:16 AM: Update 14653: task edges-ner-ontonotes, batch 653 (14653): mcc: 0.7315, acc: 0.6187, precision: 0.8418, recall: 0.6583, f1: 0.7388, edges-ner-ontonotes_loss: 0.0716
09/16 10:09:26 AM: Update 14781: task edges-ner-ontonotes, batch 781 (14781): mcc: 0.7389, acc: 0.6279, precision: 0.8460, recall: 0.6677, f1: 0.7463, edges-ner-ontonotes_loss: 0.0701
09/16 10:09:36 AM: Update 14913: task edges-ner-ontonotes, batch 913 (14913): mcc: 0.7446, acc: 0.6347, precision: 0.8492, recall: 0.6749, f1: 0.7521, edges-ner-ontonotes_loss: 0.0688
09/16 10:09:44 AM: ***** Step 15000 / Validation 15 *****
09/16 10:09:44 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:09:44 AM: Validating...
09/16 10:09:46 AM: Evaluate: task edges-ner-ontonotes, batch 19 (157): mcc: 0.7168, acc: 0.6175, precision: 0.8304, recall: 0.6422, f1: 0.7243, edges-ner-ontonotes_loss: 0.0760
09/16 10:09:57 AM: Evaluate: task edges-ner-ontonotes, batch 107 (157): mcc: 0.7933, acc: 0.7030, precision: 0.8881, recall: 0.7269, f1: 0.7995, edges-ner-ontonotes_loss: 0.0606
09/16 10:10:03 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:10:03 AM: Best result seen so far for macro.
09/16 10:10:03 AM: Updating LR scheduler:
09/16 10:10:03 AM: 	Best result seen so far for macro_avg: 0.809
09/16 10:10:03 AM: 	# validation passes without improvement: 0
09/16 10:10:03 AM: edges-ner-ontonotes_loss: training: 0.068426 validation: 0.056547
09/16 10:10:03 AM: macro_avg: validation: 0.809232
09/16 10:10:03 AM: micro_avg: validation: 0.000000
09/16 10:10:03 AM: edges-ner-ontonotes_mcc: training: 0.745776 validation: 0.803542
09/16 10:10:03 AM: edges-ner-ontonotes_acc: training: 0.636328 validation: 0.712997
09/16 10:10:03 AM: edges-ner-ontonotes_precision: training: 0.849705 validation: 0.898012
09/16 10:10:03 AM: edges-ner-ontonotes_recall: training: 0.676413 validation: 0.736427
09/16 10:10:03 AM: edges-ner-ontonotes_f1: training: 0.753221 validation: 0.809232
09/16 10:10:03 AM: Global learning rate: 0.0001
09/16 10:10:03 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:10:07 AM: Update 15045: task edges-ner-ontonotes, batch 45 (15045): mcc: 0.7687, acc: 0.6685, precision: 0.8641, recall: 0.7042, f1: 0.7760, edges-ner-ontonotes_loss: 0.0622
09/16 10:10:17 AM: Update 15175: task edges-ner-ontonotes, batch 175 (15175): mcc: 0.7624, acc: 0.6578, precision: 0.8576, recall: 0.6987, f1: 0.7700, edges-ner-ontonotes_loss: 0.0636
09/16 10:10:27 AM: Update 15279: task edges-ner-ontonotes, batch 279 (15279): mcc: 0.7528, acc: 0.6448, precision: 0.8506, recall: 0.6878, f1: 0.7606, edges-ner-ontonotes_loss: 0.0655
09/16 10:10:37 AM: Update 15421: task edges-ner-ontonotes, batch 421 (15421): mcc: 0.7375, acc: 0.6256, precision: 0.8405, recall: 0.6697, f1: 0.7455, edges-ner-ontonotes_loss: 0.0712
09/16 10:10:47 AM: Update 15560: task edges-ner-ontonotes, batch 560 (15560): mcc: 0.7274, acc: 0.6131, precision: 0.8339, recall: 0.6577, f1: 0.7354, edges-ner-ontonotes_loss: 0.0746
09/16 10:10:57 AM: Update 15708: task edges-ner-ontonotes, batch 708 (15708): mcc: 0.7271, acc: 0.6128, precision: 0.8351, recall: 0.6562, f1: 0.7349, edges-ner-ontonotes_loss: 0.0744
09/16 10:11:07 AM: Update 15868: task edges-ner-ontonotes, batch 868 (15868): mcc: 0.7278, acc: 0.6130, precision: 0.8373, recall: 0.6556, f1: 0.7354, edges-ner-ontonotes_loss: 0.0739
09/16 10:11:17 AM: Update 15990: task edges-ner-ontonotes, batch 990 (15990): mcc: 0.7293, acc: 0.6148, precision: 0.8386, recall: 0.6571, f1: 0.7368, edges-ner-ontonotes_loss: 0.0734
09/16 10:11:18 AM: ***** Step 16000 / Validation 16 *****
09/16 10:11:18 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:11:18 AM: Validating...
09/16 10:11:27 AM: Evaluate: task edges-ner-ontonotes, batch 86 (157): mcc: 0.8077, acc: 0.7194, precision: 0.9042, recall: 0.7384, f1: 0.8129, edges-ner-ontonotes_loss: 0.0571
09/16 10:11:36 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:11:36 AM: Best result seen so far for macro.
09/16 10:11:36 AM: Updating LR scheduler:
09/16 10:11:36 AM: 	Best result seen so far for macro_avg: 0.812
09/16 10:11:36 AM: 	# validation passes without improvement: 0
09/16 10:11:36 AM: edges-ner-ontonotes_loss: training: 0.073313 validation: 0.054713
09/16 10:11:36 AM: macro_avg: validation: 0.812105
09/16 10:11:36 AM: micro_avg: validation: 0.000000
09/16 10:11:36 AM: edges-ner-ontonotes_mcc: training: 0.729174 validation: 0.807112
09/16 10:11:36 AM: edges-ner-ontonotes_acc: training: 0.614619 validation: 0.713907
09/16 10:11:36 AM: edges-ner-ontonotes_precision: training: 0.838556 validation: 0.906381
09/16 10:11:36 AM: edges-ner-ontonotes_recall: training: 0.656933 validation: 0.735593
09/16 10:11:36 AM: edges-ner-ontonotes_f1: training: 0.736716 validation: 0.812105
09/16 10:11:36 AM: Global learning rate: 0.0001
09/16 10:11:36 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:11:37 AM: Update 16013: task edges-ner-ontonotes, batch 13 (16013): mcc: 0.7498, acc: 0.6460, precision: 0.8584, recall: 0.6761, f1: 0.7564, edges-ner-ontonotes_loss: 0.0665
09/16 10:11:47 AM: Update 16143: task edges-ner-ontonotes, batch 143 (16143): mcc: 0.7439, acc: 0.6375, precision: 0.8470, recall: 0.6755, f1: 0.7516, edges-ner-ontonotes_loss: 0.0690
09/16 10:11:57 AM: Update 16256: task edges-ner-ontonotes, batch 256 (16256): mcc: 0.7477, acc: 0.6404, precision: 0.8497, recall: 0.6797, f1: 0.7553, edges-ner-ontonotes_loss: 0.0678
09/16 10:12:07 AM: Update 16395: task edges-ner-ontonotes, batch 395 (16395): mcc: 0.7576, acc: 0.6528, precision: 0.8542, recall: 0.6933, f1: 0.7654, edges-ner-ontonotes_loss: 0.0653
09/16 10:12:17 AM: Update 16500: task edges-ner-ontonotes, batch 500 (16500): mcc: 0.7596, acc: 0.6550, precision: 0.8555, recall: 0.6956, f1: 0.7673, edges-ner-ontonotes_loss: 0.0647
09/16 10:12:27 AM: Update 16633: task edges-ner-ontonotes, batch 633 (16633): mcc: 0.7614, acc: 0.6567, precision: 0.8564, recall: 0.6980, f1: 0.7691, edges-ner-ontonotes_loss: 0.0642
09/16 10:12:38 AM: Update 16760: task edges-ner-ontonotes, batch 760 (16760): mcc: 0.7609, acc: 0.6556, precision: 0.8561, recall: 0.6975, f1: 0.7687, edges-ner-ontonotes_loss: 0.0641
09/16 10:12:48 AM: Update 16877: task edges-ner-ontonotes, batch 877 (16877): mcc: 0.7544, acc: 0.6476, precision: 0.8516, recall: 0.6897, f1: 0.7622, edges-ner-ontonotes_loss: 0.0657
09/16 10:12:57 AM: ***** Step 17000 / Validation 17 *****
09/16 10:12:57 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:12:57 AM: Validating...
09/16 10:12:58 AM: Evaluate: task edges-ner-ontonotes, batch 10 (157): mcc: 0.7117, acc: 0.5963, precision: 0.8442, recall: 0.6227, f1: 0.7167, edges-ner-ontonotes_loss: 0.0737
09/16 10:13:08 AM: Evaluate: task edges-ner-ontonotes, batch 99 (157): mcc: 0.8018, acc: 0.7027, precision: 0.9101, recall: 0.7232, f1: 0.8060, edges-ner-ontonotes_loss: 0.0578
09/16 10:13:15 AM: Updating LR scheduler:
09/16 10:13:15 AM: 	Best result seen so far for macro_avg: 0.812
09/16 10:13:15 AM: 	# validation passes without improvement: 1
09/16 10:13:15 AM: edges-ner-ontonotes_loss: training: 0.067885 validation: 0.055416
09/16 10:13:15 AM: macro_avg: validation: 0.806379
09/16 10:13:15 AM: micro_avg: validation: 0.000000
09/16 10:13:15 AM: edges-ner-ontonotes_mcc: training: 0.747629 validation: 0.802690
09/16 10:13:15 AM: edges-ner-ontonotes_acc: training: 0.639209 validation: 0.700864
09/16 10:13:15 AM: edges-ner-ontonotes_precision: training: 0.847663 validation: 0.915006
09/16 10:13:15 AM: edges-ner-ontonotes_recall: training: 0.681340 validation: 0.720807
09/16 10:13:15 AM: edges-ner-ontonotes_f1: training: 0.755455 validation: 0.806379
09/16 10:13:15 AM: Global learning rate: 0.0001
09/16 10:13:15 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:13:18 AM: Update 17035: task edges-ner-ontonotes, batch 35 (17035): mcc: 0.6905, acc: 0.5661, precision: 0.8035, recall: 0.6191, f1: 0.6993, edges-ner-ontonotes_loss: 0.0827
09/16 10:13:28 AM: Update 17163: task edges-ner-ontonotes, batch 163 (17163): mcc: 0.7087, acc: 0.5876, precision: 0.8211, recall: 0.6361, f1: 0.7168, edges-ner-ontonotes_loss: 0.0793
09/16 10:13:38 AM: Update 17323: task edges-ner-ontonotes, batch 323 (17323): mcc: 0.7178, acc: 0.5990, precision: 0.8301, recall: 0.6442, f1: 0.7254, edges-ner-ontonotes_loss: 0.0756
09/16 10:13:48 AM: Update 17454: task edges-ner-ontonotes, batch 454 (17454): mcc: 0.7191, acc: 0.6005, precision: 0.8315, recall: 0.6454, f1: 0.7267, edges-ner-ontonotes_loss: 0.0751
09/16 10:13:58 AM: Update 17589: task edges-ner-ontonotes, batch 589 (17589): mcc: 0.7261, acc: 0.6103, precision: 0.8362, recall: 0.6536, f1: 0.7337, edges-ner-ontonotes_loss: 0.0736
09/16 10:14:08 AM: Update 17725: task edges-ner-ontonotes, batch 725 (17725): mcc: 0.7296, acc: 0.6151, precision: 0.8374, recall: 0.6587, f1: 0.7374, edges-ner-ontonotes_loss: 0.0725
09/16 10:14:18 AM: Update 17848: task edges-ner-ontonotes, batch 848 (17848): mcc: 0.7355, acc: 0.6219, precision: 0.8417, recall: 0.6653, f1: 0.7432, edges-ner-ontonotes_loss: 0.0712
09/16 10:14:28 AM: Update 17979: task edges-ner-ontonotes, batch 979 (17979): mcc: 0.7417, acc: 0.6293, precision: 0.8457, recall: 0.6727, f1: 0.7493, edges-ner-ontonotes_loss: 0.0699
09/16 10:14:30 AM: ***** Step 18000 / Validation 18 *****
09/16 10:14:30 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:14:30 AM: Validating...
09/16 10:14:38 AM: Evaluate: task edges-ner-ontonotes, batch 73 (157): mcc: 0.7747, acc: 0.6807, precision: 0.8752, recall: 0.7054, f1: 0.7812, edges-ner-ontonotes_loss: 0.0658
09/16 10:14:48 AM: Evaluate: task edges-ner-ontonotes, batch 153 (157): mcc: 0.8083, acc: 0.7188, precision: 0.9007, recall: 0.7424, f1: 0.8139, edges-ner-ontonotes_loss: 0.0555
09/16 10:14:49 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:14:49 AM: Best result seen so far for macro.
09/16 10:14:49 AM: Updating LR scheduler:
09/16 10:14:49 AM: 	Best result seen so far for macro_avg: 0.813
09/16 10:14:49 AM: 	# validation passes without improvement: 0
09/16 10:14:49 AM: edges-ner-ontonotes_loss: training: 0.069592 validation: 0.055446
09/16 10:14:49 AM: macro_avg: validation: 0.813321
09/16 10:14:49 AM: micro_avg: validation: 0.000000
09/16 10:14:49 AM: edges-ner-ontonotes_mcc: training: 0.742748 validation: 0.807647
09/16 10:14:49 AM: edges-ner-ontonotes_acc: training: 0.630669 validation: 0.718153
09/16 10:14:49 AM: edges-ner-ontonotes_precision: training: 0.846167 validation: 0.900313
09/16 10:14:49 AM: edges-ner-ontonotes_recall: training: 0.674108 validation: 0.741659
09/16 10:14:49 AM: edges-ner-ontonotes_f1: training: 0.750401 validation: 0.813321
09/16 10:14:49 AM: Global learning rate: 0.0001
09/16 10:14:49 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:14:58 AM: Update 18098: task edges-ner-ontonotes, batch 98 (18098): mcc: 0.7650, acc: 0.6622, precision: 0.8563, recall: 0.7043, f1: 0.7729, edges-ner-ontonotes_loss: 0.0625
09/16 10:15:08 AM: Update 18228: task edges-ner-ontonotes, batch 228 (18228): mcc: 0.7662, acc: 0.6627, precision: 0.8574, recall: 0.7055, f1: 0.7741, edges-ner-ontonotes_loss: 0.0625
09/16 10:15:18 AM: Update 18356: task edges-ner-ontonotes, batch 356 (18356): mcc: 0.7644, acc: 0.6610, precision: 0.8556, recall: 0.7040, f1: 0.7725, edges-ner-ontonotes_loss: 0.0630
09/16 10:15:28 AM: Update 18468: task edges-ner-ontonotes, batch 468 (18468): mcc: 0.7457, acc: 0.6377, precision: 0.8437, recall: 0.6813, f1: 0.7538, edges-ner-ontonotes_loss: 0.0678
09/16 10:15:38 AM: Update 18610: task edges-ner-ontonotes, batch 610 (18610): mcc: 0.7368, acc: 0.6259, precision: 0.8384, recall: 0.6702, f1: 0.7449, edges-ner-ontonotes_loss: 0.0710
09/16 10:15:48 AM: Update 18730: task edges-ner-ontonotes, batch 730 (18730): mcc: 0.7326, acc: 0.6204, precision: 0.8356, recall: 0.6653, f1: 0.7408, edges-ner-ontonotes_loss: 0.0724
09/16 10:15:58 AM: Update 18893: task edges-ner-ontonotes, batch 893 (18893): mcc: 0.7329, acc: 0.6207, precision: 0.8365, recall: 0.6652, f1: 0.7411, edges-ner-ontonotes_loss: 0.0722
09/16 10:16:07 AM: ***** Step 19000 / Validation 19 *****
09/16 10:16:07 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:16:07 AM: Validating...
09/16 10:16:08 AM: Evaluate: task edges-ner-ontonotes, batch 18 (157): mcc: 0.7405, acc: 0.6367, precision: 0.8507, recall: 0.6664, f1: 0.7474, edges-ner-ontonotes_loss: 0.0678
09/16 10:16:18 AM: Evaluate: task edges-ner-ontonotes, batch 108 (157): mcc: 0.8099, acc: 0.7180, precision: 0.9029, recall: 0.7433, f1: 0.8154, edges-ner-ontonotes_loss: 0.0552
09/16 10:16:25 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:16:25 AM: Best result seen so far for macro.
09/16 10:16:25 AM: Updating LR scheduler:
09/16 10:16:25 AM: 	Best result seen so far for macro_avg: 0.817
09/16 10:16:25 AM: 	# validation passes without improvement: 0
09/16 10:16:25 AM: edges-ner-ontonotes_loss: training: 0.072153 validation: 0.053567
09/16 10:16:25 AM: macro_avg: validation: 0.817457
09/16 10:16:25 AM: micro_avg: validation: 0.000000
09/16 10:16:25 AM: edges-ner-ontonotes_mcc: training: 0.733002 validation: 0.812415
09/16 10:16:25 AM: edges-ner-ontonotes_acc: training: 0.620576 validation: 0.718229
09/16 10:16:25 AM: edges-ner-ontonotes_precision: training: 0.836979 validation: 0.908804
09/16 10:16:25 AM: edges-ner-ontonotes_recall: training: 0.664855 validation: 0.742796
09/16 10:16:25 AM: edges-ner-ontonotes_f1: training: 0.741054 validation: 0.817457
09/16 10:16:25 AM: Global learning rate: 0.0001
09/16 10:16:25 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:16:29 AM: Update 19048: task edges-ner-ontonotes, batch 48 (19048): mcc: 0.7424, acc: 0.6347, precision: 0.8443, recall: 0.6751, f1: 0.7503, edges-ner-ontonotes_loss: 0.0685
09/16 10:16:39 AM: Update 19178: task edges-ner-ontonotes, batch 178 (19178): mcc: 0.7418, acc: 0.6353, precision: 0.8421, recall: 0.6758, f1: 0.7499, edges-ner-ontonotes_loss: 0.0686
09/16 10:16:49 AM: Update 19299: task edges-ner-ontonotes, batch 299 (19299): mcc: 0.7424, acc: 0.6351, precision: 0.8431, recall: 0.6761, f1: 0.7504, edges-ner-ontonotes_loss: 0.0684
09/16 10:16:59 AM: Update 19427: task edges-ner-ontonotes, batch 427 (19427): mcc: 0.7512, acc: 0.6455, precision: 0.8485, recall: 0.6869, f1: 0.7592, edges-ner-ontonotes_loss: 0.0664
09/16 10:17:09 AM: Update 19558: task edges-ner-ontonotes, batch 558 (19558): mcc: 0.7580, acc: 0.6536, precision: 0.8527, recall: 0.6952, f1: 0.7659, edges-ner-ontonotes_loss: 0.0648
09/16 10:17:19 AM: Update 19675: task edges-ner-ontonotes, batch 675 (19675): mcc: 0.7594, acc: 0.6547, precision: 0.8532, recall: 0.6973, f1: 0.7674, edges-ner-ontonotes_loss: 0.0644
09/16 10:17:29 AM: Update 19807: task edges-ner-ontonotes, batch 807 (19807): mcc: 0.7606, acc: 0.6559, precision: 0.8540, recall: 0.6987, f1: 0.7686, edges-ner-ontonotes_loss: 0.0640
09/16 10:17:41 AM: Update 19925: task edges-ner-ontonotes, batch 925 (19925): mcc: 0.7615, acc: 0.6570, precision: 0.8545, recall: 0.6998, f1: 0.7694, edges-ner-ontonotes_loss: 0.0638
09/16 10:17:46 AM: ***** Step 20000 / Validation 20 *****
09/16 10:17:46 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:17:46 AM: Validating...
09/16 10:17:51 AM: Evaluate: task edges-ner-ontonotes, batch 46 (157): mcc: 0.7848, acc: 0.6834, precision: 0.8871, recall: 0.7130, f1: 0.7906, edges-ner-ontonotes_loss: 0.0608
09/16 10:18:01 AM: Evaluate: task edges-ner-ontonotes, batch 122 (157): mcc: 0.8102, acc: 0.7114, precision: 0.9157, recall: 0.7332, f1: 0.8144, edges-ner-ontonotes_loss: 0.0551
09/16 10:18:05 AM: Updating LR scheduler:
09/16 10:18:05 AM: 	Best result seen so far for macro_avg: 0.817
09/16 10:18:05 AM: 	# validation passes without improvement: 1
09/16 10:18:05 AM: edges-ner-ontonotes_loss: training: 0.065466 validation: 0.053943
09/16 10:18:05 AM: macro_avg: validation: 0.813841
09/16 10:18:05 AM: micro_avg: validation: 0.000000
09/16 10:18:05 AM: edges-ner-ontonotes_mcc: training: 0.756043 validation: 0.809780
09/16 10:18:05 AM: edges-ner-ontonotes_acc: training: 0.650235 validation: 0.710267
09/16 10:18:05 AM: edges-ner-ontonotes_precision: training: 0.850809 validation: 0.916121
09/16 10:18:05 AM: edges-ner-ontonotes_recall: training: 0.693376 validation: 0.732105
09/16 10:18:05 AM: edges-ner-ontonotes_f1: training: 0.764067 validation: 0.813841
09/16 10:18:05 AM: Global learning rate: 0.0001
09/16 10:18:05 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:18:11 AM: Update 20083: task edges-ner-ontonotes, batch 83 (20083): mcc: 0.7006, acc: 0.5815, precision: 0.8161, recall: 0.6263, f1: 0.7087, edges-ner-ontonotes_loss: 0.0812
09/16 10:18:21 AM: Update 20213: task edges-ner-ontonotes, batch 213 (20213): mcc: 0.6967, acc: 0.5773, precision: 0.8119, recall: 0.6229, f1: 0.7049, edges-ner-ontonotes_loss: 0.0811
09/16 10:18:31 AM: Update 20346: task edges-ner-ontonotes, batch 346 (20346): mcc: 0.7080, acc: 0.5900, precision: 0.8207, recall: 0.6351, f1: 0.7161, edges-ner-ontonotes_loss: 0.0778
09/16 10:18:41 AM: Update 20508: task edges-ner-ontonotes, batch 508 (20508): mcc: 0.7153, acc: 0.5978, precision: 0.8271, recall: 0.6424, f1: 0.7232, edges-ner-ontonotes_loss: 0.0757
09/16 10:18:51 AM: Update 20612: task edges-ner-ontonotes, batch 612 (20612): mcc: 0.7190, acc: 0.6031, precision: 0.8291, recall: 0.6472, f1: 0.7269, edges-ner-ontonotes_loss: 0.0747
09/16 10:19:01 AM: Update 20746: task edges-ner-ontonotes, batch 746 (20746): mcc: 0.7244, acc: 0.6095, precision: 0.8328, recall: 0.6533, f1: 0.7322, edges-ner-ontonotes_loss: 0.0735
09/16 10:19:11 AM: Update 20859: task edges-ner-ontonotes, batch 859 (20859): mcc: 0.7264, acc: 0.6125, precision: 0.8340, recall: 0.6559, f1: 0.7343, edges-ner-ontonotes_loss: 0.0730
09/16 10:19:21 AM: Update 20989: task edges-ner-ontonotes, batch 989 (20989): mcc: 0.7343, acc: 0.6219, precision: 0.8391, recall: 0.6654, f1: 0.7422, edges-ner-ontonotes_loss: 0.0712
09/16 10:19:22 AM: ***** Step 21000 / Validation 21 *****
09/16 10:19:22 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:19:22 AM: Validating...
09/16 10:19:31 AM: Evaluate: task edges-ner-ontonotes, batch 84 (157): mcc: 0.7921, acc: 0.7027, precision: 0.8837, recall: 0.7286, f1: 0.7987, edges-ner-ontonotes_loss: 0.0617
09/16 10:19:40 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:19:40 AM: Best result seen so far for macro.
09/16 10:19:40 AM: Updating LR scheduler:
09/16 10:19:40 AM: 	Best result seen so far for macro_avg: 0.818
09/16 10:19:40 AM: 	# validation passes without improvement: 0
09/16 10:19:40 AM: edges-ner-ontonotes_loss: training: 0.071033 validation: 0.055110
09/16 10:19:40 AM: macro_avg: validation: 0.817734
09/16 10:19:40 AM: micro_avg: validation: 0.000000
09/16 10:19:40 AM: edges-ner-ontonotes_mcc: training: 0.735044 validation: 0.811765
09/16 10:19:40 AM: edges-ner-ontonotes_acc: training: 0.622599 validation: 0.724977
09/16 10:19:40 AM: edges-ner-ontonotes_precision: training: 0.839652 validation: 0.899463
09/16 10:19:40 AM: edges-ner-ontonotes_recall: training: 0.666171 validation: 0.749621
09/16 10:19:40 AM: edges-ner-ontonotes_f1: training: 0.742919 validation: 0.817734
09/16 10:19:40 AM: Global learning rate: 0.0001
09/16 10:19:40 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:19:41 AM: Update 21010: task edges-ner-ontonotes, batch 10 (21010): mcc: 0.7584, acc: 0.6543, precision: 0.8438, recall: 0.7035, f1: 0.7673, edges-ner-ontonotes_loss: 0.0631
09/16 10:19:51 AM: Update 21136: task edges-ner-ontonotes, batch 136 (21136): mcc: 0.7720, acc: 0.6711, precision: 0.8597, recall: 0.7137, f1: 0.7799, edges-ner-ontonotes_loss: 0.0603
09/16 10:20:01 AM: Update 21244: task edges-ner-ontonotes, batch 244 (21244): mcc: 0.7711, acc: 0.6693, precision: 0.8599, recall: 0.7121, f1: 0.7790, edges-ner-ontonotes_loss: 0.0613
09/16 10:20:11 AM: Update 21377: task edges-ner-ontonotes, batch 377 (21377): mcc: 0.7679, acc: 0.6660, precision: 0.8562, recall: 0.7096, f1: 0.7761, edges-ner-ontonotes_loss: 0.0618
09/16 10:20:21 AM: Update 21491: task edges-ner-ontonotes, batch 491 (21491): mcc: 0.7646, acc: 0.6618, precision: 0.8540, recall: 0.7056, f1: 0.7728, edges-ner-ontonotes_loss: 0.0625
09/16 10:20:31 AM: Update 21629: task edges-ner-ontonotes, batch 629 (21629): mcc: 0.7515, acc: 0.6451, precision: 0.8452, recall: 0.6903, f1: 0.7599, edges-ner-ontonotes_loss: 0.0671
09/16 10:20:41 AM: Update 21763: task edges-ner-ontonotes, batch 763 (21763): mcc: 0.7431, acc: 0.6336, precision: 0.8402, recall: 0.6797, f1: 0.7515, edges-ner-ontonotes_loss: 0.0697
09/16 10:20:51 AM: Update 21898: task edges-ner-ontonotes, batch 898 (21898): mcc: 0.7408, acc: 0.6305, precision: 0.8396, recall: 0.6762, f1: 0.7491, edges-ner-ontonotes_loss: 0.0704
09/16 10:20:58 AM: ***** Step 22000 / Validation 22 *****
09/16 10:20:58 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:20:58 AM: Validating...
09/16 10:21:01 AM: Evaluate: task edges-ner-ontonotes, batch 35 (157): mcc: 0.7898, acc: 0.6968, precision: 0.8843, recall: 0.7241, f1: 0.7962, edges-ner-ontonotes_loss: 0.0602
09/16 10:21:12 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.8134, acc: 0.7208, precision: 0.9128, recall: 0.7413, f1: 0.8181, edges-ner-ontonotes_loss: 0.0543
09/16 10:21:17 AM: Updating LR scheduler:
09/16 10:21:17 AM: 	Best result seen so far for macro_avg: 0.818
09/16 10:21:17 AM: 	# validation passes without improvement: 1
09/16 10:21:17 AM: edges-ner-ontonotes_loss: training: 0.070487 validation: 0.053509
09/16 10:21:17 AM: macro_avg: validation: 0.814970
09/16 10:21:17 AM: micro_avg: validation: 0.000000
09/16 10:21:17 AM: edges-ner-ontonotes_mcc: training: 0.740136 validation: 0.810563
09/16 10:21:17 AM: edges-ner-ontonotes_acc: training: 0.629741 validation: 0.714816
09/16 10:21:17 AM: edges-ner-ontonotes_precision: training: 0.839467 validation: 0.913551
09/16 10:21:17 AM: edges-ner-ontonotes_recall: training: 0.675176 validation: 0.735593
09/16 10:21:17 AM: edges-ner-ontonotes_f1: training: 0.748411 validation: 0.814970
09/16 10:21:17 AM: Global learning rate: 0.0001
09/16 10:21:17 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:21:22 AM: Update 22077: task edges-ner-ontonotes, batch 77 (22077): mcc: 0.7480, acc: 0.6362, precision: 0.8546, recall: 0.6763, f1: 0.7551, edges-ner-ontonotes_loss: 0.0680
09/16 10:21:32 AM: Update 22191: task edges-ner-ontonotes, batch 191 (22191): mcc: 0.7472, acc: 0.6383, precision: 0.8484, recall: 0.6800, f1: 0.7549, edges-ner-ontonotes_loss: 0.0676
09/16 10:21:42 AM: Update 22326: task edges-ner-ontonotes, batch 326 (22326): mcc: 0.7483, acc: 0.6387, precision: 0.8482, recall: 0.6820, f1: 0.7561, edges-ner-ontonotes_loss: 0.0675
09/16 10:21:52 AM: Update 22438: task edges-ner-ontonotes, batch 438 (22438): mcc: 0.7470, acc: 0.6374, precision: 0.8463, recall: 0.6814, f1: 0.7549, edges-ner-ontonotes_loss: 0.0676
09/16 10:22:02 AM: Update 22565: task edges-ner-ontonotes, batch 565 (22565): mcc: 0.7536, acc: 0.6455, precision: 0.8500, recall: 0.6897, f1: 0.7615, edges-ner-ontonotes_loss: 0.0662
09/16 10:22:12 AM: Update 22696: task edges-ner-ontonotes, batch 696 (22696): mcc: 0.7583, acc: 0.6517, precision: 0.8530, recall: 0.6955, f1: 0.7662, edges-ner-ontonotes_loss: 0.0649
09/16 10:22:22 AM: Update 22801: task edges-ner-ontonotes, batch 801 (22801): mcc: 0.7613, acc: 0.6549, precision: 0.8547, recall: 0.6992, f1: 0.7692, edges-ner-ontonotes_loss: 0.0642
09/16 10:22:32 AM: Update 22923: task edges-ner-ontonotes, batch 923 (22923): mcc: 0.7626, acc: 0.6565, precision: 0.8557, recall: 0.7008, f1: 0.7705, edges-ner-ontonotes_loss: 0.0639
09/16 10:22:38 AM: ***** Step 23000 / Validation 23 *****
09/16 10:22:38 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:22:38 AM: Validating...
09/16 10:22:42 AM: Evaluate: task edges-ner-ontonotes, batch 39 (157): mcc: 0.7695, acc: 0.6765, precision: 0.8658, recall: 0.7042, f1: 0.7767, edges-ner-ontonotes_loss: 0.0667
09/16 10:22:52 AM: Evaluate: task edges-ner-ontonotes, batch 116 (157): mcc: 0.8061, acc: 0.7155, precision: 0.8995, recall: 0.7397, f1: 0.8118, edges-ner-ontonotes_loss: 0.0568
09/16 10:22:57 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:22:57 AM: Best result seen so far for macro.
09/16 10:22:57 AM: Updating LR scheduler:
09/16 10:22:57 AM: 	Best result seen so far for macro_avg: 0.822
09/16 10:22:57 AM: 	# validation passes without improvement: 0
09/16 10:22:57 AM: edges-ner-ontonotes_loss: training: 0.063900 validation: 0.053629
09/16 10:22:57 AM: macro_avg: validation: 0.821709
09/16 10:22:57 AM: micro_avg: validation: 0.000000
09/16 10:22:57 AM: edges-ner-ontonotes_mcc: training: 0.762820 validation: 0.816306
09/16 10:22:57 AM: edges-ner-ontonotes_acc: training: 0.656883 validation: 0.727783
09/16 10:22:57 AM: edges-ner-ontonotes_precision: training: 0.855580 validation: 0.907358
09/16 10:22:57 AM: edges-ner-ontonotes_recall: training: 0.701192 validation: 0.750834
09/16 10:22:57 AM: edges-ner-ontonotes_f1: training: 0.770730 validation: 0.821709
09/16 10:22:57 AM: Global learning rate: 0.0001
09/16 10:22:57 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:23:02 AM: Update 23044: task edges-ner-ontonotes, batch 44 (23044): mcc: 0.7274, acc: 0.6210, precision: 0.8191, recall: 0.6701, f1: 0.7372, edges-ner-ontonotes_loss: 0.0681
09/16 10:23:12 AM: Update 23180: task edges-ner-ontonotes, batch 180 (23180): mcc: 0.7051, acc: 0.5890, precision: 0.8096, recall: 0.6392, f1: 0.7144, edges-ner-ontonotes_loss: 0.0808
09/16 10:23:22 AM: Update 23320: task edges-ner-ontonotes, batch 320 (23320): mcc: 0.7015, acc: 0.5843, precision: 0.8097, recall: 0.6329, f1: 0.7105, edges-ner-ontonotes_loss: 0.0814
09/16 10:23:32 AM: Update 23439: task edges-ner-ontonotes, batch 439 (23439): mcc: 0.7068, acc: 0.5905, precision: 0.8151, recall: 0.6377, f1: 0.7156, edges-ner-ontonotes_loss: 0.0793
09/16 10:23:42 AM: Update 23606: task edges-ner-ontonotes, batch 606 (23606): mcc: 0.7146, acc: 0.5992, precision: 0.8221, recall: 0.6453, f1: 0.7231, edges-ner-ontonotes_loss: 0.0768
09/16 10:23:52 AM: Update 23723: task edges-ner-ontonotes, batch 723 (23723): mcc: 0.7189, acc: 0.6040, precision: 0.8265, recall: 0.6491, f1: 0.7271, edges-ner-ontonotes_loss: 0.0757
09/16 10:24:02 AM: Update 23859: task edges-ner-ontonotes, batch 859 (23859): mcc: 0.7238, acc: 0.6102, precision: 0.8295, recall: 0.6550, f1: 0.7320, edges-ner-ontonotes_loss: 0.0744
09/16 10:24:13 AM: Update 23967: task edges-ner-ontonotes, batch 967 (23967): mcc: 0.7258, acc: 0.6131, precision: 0.8308, recall: 0.6575, f1: 0.7341, edges-ner-ontonotes_loss: 0.0737
09/16 10:24:15 AM: ***** Step 24000 / Validation 24 *****
09/16 10:24:15 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:24:16 AM: Validating...
09/16 10:24:23 AM: Evaluate: task edges-ner-ontonotes, batch 68 (157): mcc: 0.7920, acc: 0.7005, precision: 0.8920, recall: 0.7215, f1: 0.7977, edges-ner-ontonotes_loss: 0.0604
09/16 10:24:33 AM: Evaluate: task edges-ner-ontonotes, batch 147 (157): mcc: 0.8176, acc: 0.7276, precision: 0.9126, recall: 0.7485, f1: 0.8225, edges-ner-ontonotes_loss: 0.0535
09/16 10:24:34 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:24:34 AM: Best result seen so far for macro.
09/16 10:24:34 AM: Updating LR scheduler:
09/16 10:24:34 AM: 	Best result seen so far for macro_avg: 0.823
09/16 10:24:34 AM: 	# validation passes without improvement: 0
09/16 10:24:34 AM: edges-ner-ontonotes_loss: training: 0.073330 validation: 0.053114
09/16 10:24:34 AM: macro_avg: validation: 0.823113
09/16 10:24:34 AM: micro_avg: validation: 0.000000
09/16 10:24:34 AM: edges-ner-ontonotes_mcc: training: 0.727233 validation: 0.818151
09/16 10:24:34 AM: edges-ner-ontonotes_acc: training: 0.614828 validation: 0.728465
09/16 10:24:34 AM: edges-ner-ontonotes_precision: training: 0.831849 validation: 0.912582
09/16 10:24:34 AM: edges-ner-ontonotes_recall: training: 0.659121 validation: 0.749621
09/16 10:24:34 AM: edges-ner-ontonotes_f1: training: 0.735480 validation: 0.823113
09/16 10:24:34 AM: Global learning rate: 0.0001
09/16 10:24:34 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:24:43 AM: Update 24111: task edges-ner-ontonotes, batch 111 (24111): mcc: 0.7699, acc: 0.6670, precision: 0.8589, recall: 0.7107, f1: 0.7778, edges-ner-ontonotes_loss: 0.0606
09/16 10:24:53 AM: Update 24249: task edges-ner-ontonotes, batch 249 (24249): mcc: 0.7755, acc: 0.6737, precision: 0.8628, recall: 0.7172, f1: 0.7833, edges-ner-ontonotes_loss: 0.0600
09/16 10:25:03 AM: Update 24354: task edges-ner-ontonotes, batch 354 (24354): mcc: 0.7700, acc: 0.6667, precision: 0.8588, recall: 0.7111, f1: 0.7780, edges-ner-ontonotes_loss: 0.0611
09/16 10:25:13 AM: Update 24486: task edges-ner-ontonotes, batch 486 (24486): mcc: 0.7716, acc: 0.6686, precision: 0.8594, recall: 0.7134, f1: 0.7796, edges-ner-ontonotes_loss: 0.0610
09/16 10:25:23 AM: Update 24603: task edges-ner-ontonotes, batch 603 (24603): mcc: 0.7684, acc: 0.6652, precision: 0.8564, recall: 0.7103, f1: 0.7765, edges-ner-ontonotes_loss: 0.0618
09/16 10:25:33 AM: Update 24741: task edges-ner-ontonotes, batch 741 (24741): mcc: 0.7560, acc: 0.6499, precision: 0.8480, recall: 0.6956, f1: 0.7643, edges-ner-ontonotes_loss: 0.0660
09/16 10:25:43 AM: Update 24879: task edges-ner-ontonotes, batch 879 (24879): mcc: 0.7484, acc: 0.6399, precision: 0.8437, recall: 0.6861, f1: 0.7568, edges-ner-ontonotes_loss: 0.0684
09/16 10:25:53 AM: ***** Step 25000 / Validation 25 *****
09/16 10:25:53 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:25:53 AM: Validating...
09/16 10:25:53 AM: Evaluate: task edges-ner-ontonotes, batch 4 (157): mcc: 0.6660, acc: 0.5580, precision: 0.8103, recall: 0.5725, f1: 0.6709, edges-ner-ontonotes_loss: 0.0861
09/16 10:26:03 AM: Evaluate: task edges-ner-ontonotes, batch 91 (157): mcc: 0.8161, acc: 0.7227, precision: 0.9130, recall: 0.7457, f1: 0.8209, edges-ner-ontonotes_loss: 0.0543
09/16 10:26:12 AM: Updating LR scheduler:
09/16 10:26:12 AM: 	Best result seen so far for macro_avg: 0.823
09/16 10:26:12 AM: 	# validation passes without improvement: 1
09/16 10:26:12 AM: edges-ner-ontonotes_loss: training: 0.068919 validation: 0.052839
09/16 10:26:12 AM: macro_avg: validation: 0.817785
09/16 10:26:12 AM: micro_avg: validation: 0.000000
09/16 10:26:12 AM: edges-ner-ontonotes_mcc: training: 0.745947 validation: 0.813378
09/16 10:26:12 AM: edges-ner-ontonotes_acc: training: 0.636759 validation: 0.717698
09/16 10:26:12 AM: edges-ner-ontonotes_precision: training: 0.842616 validation: 0.915133
09/16 10:26:12 AM: edges-ner-ontonotes_recall: training: 0.682661 validation: 0.739157
09/16 10:26:12 AM: edges-ner-ontonotes_f1: training: 0.754251 validation: 0.817785
09/16 10:26:12 AM: Global learning rate: 0.0001
09/16 10:26:12 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:26:13 AM: Update 25024: task edges-ner-ontonotes, batch 24 (25024): mcc: 0.7270, acc: 0.6132, precision: 0.8385, recall: 0.6532, f1: 0.7343, edges-ner-ontonotes_loss: 0.0714
09/16 10:26:23 AM: Update 25187: task edges-ner-ontonotes, batch 187 (25187): mcc: 0.7376, acc: 0.6243, precision: 0.8419, recall: 0.6687, f1: 0.7454, edges-ner-ontonotes_loss: 0.0694
09/16 10:26:33 AM: Update 25295: task edges-ner-ontonotes, batch 295 (25295): mcc: 0.7337, acc: 0.6210, precision: 0.8370, recall: 0.6660, f1: 0.7418, edges-ner-ontonotes_loss: 0.0701
09/16 10:26:43 AM: Update 25437: task edges-ner-ontonotes, batch 437 (25437): mcc: 0.7415, acc: 0.6310, precision: 0.8411, recall: 0.6762, f1: 0.7497, edges-ner-ontonotes_loss: 0.0687
09/16 10:26:53 AM: Update 25547: task edges-ner-ontonotes, batch 547 (25547): mcc: 0.7440, acc: 0.6347, precision: 0.8428, recall: 0.6792, f1: 0.7522, edges-ner-ontonotes_loss: 0.0683
09/16 10:27:03 AM: Update 25674: task edges-ner-ontonotes, batch 674 (25674): mcc: 0.7510, acc: 0.6433, precision: 0.8470, recall: 0.6878, f1: 0.7591, edges-ner-ontonotes_loss: 0.0667
09/16 10:27:13 AM: Update 25807: task edges-ner-ontonotes, batch 807 (25807): mcc: 0.7563, acc: 0.6503, precision: 0.8499, recall: 0.6947, f1: 0.7645, edges-ner-ontonotes_loss: 0.0654
09/16 10:27:23 AM: Update 25924: task edges-ner-ontonotes, batch 924 (25924): mcc: 0.7583, acc: 0.6526, precision: 0.8515, recall: 0.6968, f1: 0.7664, edges-ner-ontonotes_loss: 0.0649
09/16 10:27:29 AM: ***** Step 26000 / Validation 26 *****
09/16 10:27:29 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:27:29 AM: Validating...
09/16 10:27:34 AM: Evaluate: task edges-ner-ontonotes, batch 44 (157): mcc: 0.7686, acc: 0.6727, precision: 0.8609, recall: 0.7068, f1: 0.7763, edges-ner-ontonotes_loss: 0.0660
09/16 10:27:44 AM: Evaluate: task edges-ner-ontonotes, batch 120 (157): mcc: 0.8080, acc: 0.7174, precision: 0.8983, recall: 0.7439, f1: 0.8138, edges-ner-ontonotes_loss: 0.0563
09/16 10:27:48 AM: Updating LR scheduler:
09/16 10:27:48 AM: 	Best result seen so far for macro_avg: 0.823
09/16 10:27:48 AM: 	# validation passes without improvement: 2
09/16 10:27:48 AM: edges-ner-ontonotes_loss: training: 0.064620 validation: 0.053598
09/16 10:27:48 AM: macro_avg: validation: 0.821099
09/16 10:27:48 AM: micro_avg: validation: 0.000000
09/16 10:27:48 AM: edges-ner-ontonotes_mcc: training: 0.759855 validation: 0.815435
09/16 10:27:48 AM: edges-ner-ontonotes_acc: training: 0.654440 validation: 0.726570
09/16 10:27:48 AM: edges-ner-ontonotes_precision: training: 0.852563 validation: 0.904332
09/16 10:27:48 AM: edges-ner-ontonotes_recall: training: 0.698565 validation: 0.751896
09/16 10:27:48 AM: edges-ner-ontonotes_f1: training: 0.767919 validation: 0.821099
09/16 10:27:48 AM: Global learning rate: 0.0001
09/16 10:27:48 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:27:54 AM: Update 26069: task edges-ner-ontonotes, batch 69 (26069): mcc: 0.7678, acc: 0.6630, precision: 0.8523, recall: 0.7128, f1: 0.7763, edges-ner-ontonotes_loss: 0.0609
09/16 10:28:04 AM: Update 26175: task edges-ner-ontonotes, batch 175 (26175): mcc: 0.7487, acc: 0.6420, precision: 0.8389, recall: 0.6907, f1: 0.7576, edges-ner-ontonotes_loss: 0.0659
09/16 10:28:14 AM: Update 26314: task edges-ner-ontonotes, batch 314 (26314): mcc: 0.7304, acc: 0.6186, precision: 0.8278, recall: 0.6680, f1: 0.7393, edges-ner-ontonotes_loss: 0.0730
09/16 10:28:24 AM: Update 26450: task edges-ner-ontonotes, batch 450 (26450): mcc: 0.7223, acc: 0.6081, precision: 0.8240, recall: 0.6570, f1: 0.7311, edges-ner-ontonotes_loss: 0.0754
09/16 10:28:34 AM: Update 26588: task edges-ner-ontonotes, batch 588 (26588): mcc: 0.7239, acc: 0.6092, precision: 0.8266, recall: 0.6577, f1: 0.7325, edges-ner-ontonotes_loss: 0.0745
09/16 10:28:44 AM: Update 26750: task edges-ner-ontonotes, batch 750 (26750): mcc: 0.7271, acc: 0.6126, precision: 0.8303, recall: 0.6602, f1: 0.7355, edges-ner-ontonotes_loss: 0.0736
09/16 10:28:54 AM: Update 26863: task edges-ner-ontonotes, batch 863 (26863): mcc: 0.7289, acc: 0.6150, precision: 0.8322, recall: 0.6617, f1: 0.7373, edges-ner-ontonotes_loss: 0.0731
09/16 10:29:04 AM: Update 27000: task edges-ner-ontonotes, batch 1000 (27000): mcc: 0.7320, acc: 0.6194, precision: 0.8343, recall: 0.6654, f1: 0.7403, edges-ner-ontonotes_loss: 0.0721
09/16 10:29:04 AM: ***** Step 27000 / Validation 27 *****
09/16 10:29:04 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:29:04 AM: Validating...
09/16 10:29:14 AM: Evaluate: task edges-ner-ontonotes, batch 93 (157): mcc: 0.8195, acc: 0.7317, precision: 0.9128, recall: 0.7517, f1: 0.8245, edges-ner-ontonotes_loss: 0.0533
09/16 10:29:22 AM: Updating LR scheduler:
09/16 10:29:22 AM: 	Best result seen so far for macro_avg: 0.823
09/16 10:29:22 AM: 	# validation passes without improvement: 3
09/16 10:29:22 AM: edges-ner-ontonotes_loss: training: 0.072068 validation: 0.051764
09/16 10:29:22 AM: macro_avg: validation: 0.819909
09/16 10:29:22 AM: micro_avg: validation: 0.000000
09/16 10:29:22 AM: edges-ner-ontonotes_mcc: training: 0.731992 validation: 0.815096
09/16 10:29:22 AM: edges-ner-ontonotes_acc: training: 0.619444 validation: 0.723916
09/16 10:29:22 AM: edges-ner-ontonotes_precision: training: 0.834278 validation: 0.912369
09/16 10:29:22 AM: edges-ner-ontonotes_recall: training: 0.665355 validation: 0.744465
09/16 10:29:22 AM: edges-ner-ontonotes_f1: training: 0.740303 validation: 0.819909
09/16 10:29:22 AM: Global learning rate: 0.0001
09/16 10:29:22 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:29:24 AM: Update 27021: task edges-ner-ontonotes, batch 21 (27021): mcc: 0.7385, acc: 0.6303, precision: 0.8432, recall: 0.6692, f1: 0.7462, edges-ner-ontonotes_loss: 0.0712
09/16 10:29:34 AM: Update 27132: task edges-ner-ontonotes, batch 132 (27132): mcc: 0.7597, acc: 0.6541, precision: 0.8521, recall: 0.6986, f1: 0.7678, edges-ner-ontonotes_loss: 0.0654
09/16 10:29:44 AM: Update 27259: task edges-ner-ontonotes, batch 259 (27259): mcc: 0.7663, acc: 0.6620, precision: 0.8567, recall: 0.7064, f1: 0.7743, edges-ner-ontonotes_loss: 0.0625
09/16 10:29:55 AM: Update 27392: task edges-ner-ontonotes, batch 392 (27392): mcc: 0.7720, acc: 0.6691, precision: 0.8609, recall: 0.7127, f1: 0.7798, edges-ner-ontonotes_loss: 0.0611
09/16 10:30:05 AM: Update 27522: task edges-ner-ontonotes, batch 522 (27522): mcc: 0.7709, acc: 0.6673, precision: 0.8593, recall: 0.7122, f1: 0.7789, edges-ner-ontonotes_loss: 0.0611
09/16 10:30:15 AM: Update 27651: task edges-ner-ontonotes, batch 651 (27651): mcc: 0.7710, acc: 0.6674, precision: 0.8587, recall: 0.7129, f1: 0.7790, edges-ner-ontonotes_loss: 0.0611
09/16 10:30:26 AM: Update 27756: task edges-ner-ontonotes, batch 756 (27756): mcc: 0.7642, acc: 0.6590, precision: 0.8539, recall: 0.7050, f1: 0.7723, edges-ner-ontonotes_loss: 0.0625
09/16 10:30:36 AM: Update 27905: task edges-ner-ontonotes, batch 905 (27905): mcc: 0.7543, acc: 0.6467, precision: 0.8474, recall: 0.6932, f1: 0.7626, edges-ner-ontonotes_loss: 0.0661
09/16 10:30:43 AM: ***** Step 28000 / Validation 28 *****
09/16 10:30:43 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:30:43 AM: Validating...
09/16 10:30:46 AM: Evaluate: task edges-ner-ontonotes, batch 32 (157): mcc: 0.7771, acc: 0.6834, precision: 0.8702, recall: 0.7137, f1: 0.7842, edges-ner-ontonotes_loss: 0.0632
09/16 10:30:56 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.8171, acc: 0.7261, precision: 0.9091, recall: 0.7508, f1: 0.8224, edges-ner-ontonotes_loss: 0.0541
09/16 10:31:01 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:31:01 AM: Best result seen so far for macro.
09/16 10:31:01 AM: Updating LR scheduler:
09/16 10:31:01 AM: 	Best result seen so far for macro_avg: 0.824
09/16 10:31:01 AM: 	# validation passes without improvement: 0
09/16 10:31:01 AM: edges-ner-ontonotes_loss: training: 0.067520 validation: 0.052139
09/16 10:31:01 AM: macro_avg: validation: 0.824156
09/16 10:31:01 AM: micro_avg: validation: 0.000000
09/16 10:31:01 AM: edges-ner-ontonotes_mcc: training: 0.750206 validation: 0.819150
09/16 10:31:01 AM: edges-ner-ontonotes_acc: training: 0.641507 validation: 0.726645
09/16 10:31:01 AM: edges-ner-ontonotes_precision: training: 0.844944 validation: 0.912675
09/16 10:31:01 AM: edges-ner-ontonotes_recall: training: 0.688137 validation: 0.751289
09/16 10:31:01 AM: edges-ner-ontonotes_f1: training: 0.758521 validation: 0.824156
09/16 10:31:01 AM: Global learning rate: 0.0001
09/16 10:31:01 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:31:06 AM: Update 28046: task edges-ner-ontonotes, batch 46 (28046): mcc: 0.7245, acc: 0.6059, precision: 0.8256, recall: 0.6596, f1: 0.7333, edges-ner-ontonotes_loss: 0.0751
09/16 10:31:16 AM: Update 28207: task edges-ner-ontonotes, batch 207 (28207): mcc: 0.7339, acc: 0.6178, precision: 0.8407, recall: 0.6633, f1: 0.7416, edges-ner-ontonotes_loss: 0.0719
09/16 10:31:26 AM: Update 28335: task edges-ner-ontonotes, batch 335 (28335): mcc: 0.7372, acc: 0.6221, precision: 0.8414, recall: 0.6684, f1: 0.7450, edges-ner-ontonotes_loss: 0.0706
09/16 10:31:36 AM: Update 28469: task edges-ner-ontonotes, batch 469 (28469): mcc: 0.7405, acc: 0.6286, precision: 0.8413, recall: 0.6744, f1: 0.7486, edges-ner-ontonotes_loss: 0.0699
09/16 10:31:46 AM: Update 28601: task edges-ner-ontonotes, batch 601 (28601): mcc: 0.7409, acc: 0.6302, precision: 0.8412, recall: 0.6751, f1: 0.7491, edges-ner-ontonotes_loss: 0.0693
09/16 10:31:56 AM: Update 28713: task edges-ner-ontonotes, batch 713 (28713): mcc: 0.7441, acc: 0.6346, precision: 0.8426, recall: 0.6794, f1: 0.7522, edges-ner-ontonotes_loss: 0.0684
09/16 10:32:06 AM: Update 28849: task edges-ner-ontonotes, batch 849 (28849): mcc: 0.7513, acc: 0.6434, precision: 0.8469, recall: 0.6884, f1: 0.7595, edges-ner-ontonotes_loss: 0.0668
09/16 10:32:16 AM: Update 28952: task edges-ner-ontonotes, batch 952 (28952): mcc: 0.7544, acc: 0.6469, precision: 0.8488, recall: 0.6921, f1: 0.7625, edges-ner-ontonotes_loss: 0.0662
09/16 10:32:20 AM: ***** Step 29000 / Validation 29 *****
09/16 10:32:20 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:32:20 AM: Validating...
09/16 10:32:26 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.7918, acc: 0.7012, precision: 0.8772, recall: 0.7335, f1: 0.7990, edges-ner-ontonotes_loss: 0.0607
09/16 10:32:36 AM: Evaluate: task edges-ner-ontonotes, batch 141 (157): mcc: 0.8148, acc: 0.7264, precision: 0.9007, recall: 0.7539, f1: 0.8208, edges-ner-ontonotes_loss: 0.0537
09/16 10:32:38 AM: Updating LR scheduler:
09/16 10:32:38 AM: 	Best result seen so far for macro_avg: 0.824
09/16 10:32:38 AM: 	# validation passes without improvement: 1
09/16 10:32:38 AM: edges-ner-ontonotes_loss: training: 0.065832 validation: 0.053173
09/16 10:32:38 AM: macro_avg: validation: 0.820855
09/16 10:32:38 AM: micro_avg: validation: 0.000000
09/16 10:32:38 AM: edges-ner-ontonotes_mcc: training: 0.755822 validation: 0.814801
09/16 10:32:38 AM: edges-ner-ontonotes_acc: training: 0.648877 validation: 0.725963
09/16 10:32:38 AM: edges-ner-ontonotes_precision: training: 0.849622 validation: 0.900045
09/16 10:32:38 AM: edges-ner-ontonotes_recall: training: 0.693998 validation: 0.754474
09/16 10:32:38 AM: edges-ner-ontonotes_f1: training: 0.763965 validation: 0.820855
09/16 10:32:38 AM: Global learning rate: 0.0001
09/16 10:32:38 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:32:46 AM: Update 29108: task edges-ner-ontonotes, batch 108 (29108): mcc: 0.7651, acc: 0.6572, precision: 0.8518, recall: 0.7086, f1: 0.7736, edges-ner-ontonotes_loss: 0.0620
09/16 10:32:56 AM: Update 29236: task edges-ner-ontonotes, batch 236 (29236): mcc: 0.7722, acc: 0.6683, precision: 0.8577, recall: 0.7158, f1: 0.7804, edges-ner-ontonotes_loss: 0.0612
09/16 10:33:06 AM: Update 29355: task edges-ner-ontonotes, batch 355 (29355): mcc: 0.7518, acc: 0.6434, precision: 0.8445, recall: 0.6913, f1: 0.7603, edges-ner-ontonotes_loss: 0.0671
09/16 10:33:16 AM: Update 29488: task edges-ner-ontonotes, batch 488 (29488): mcc: 0.7393, acc: 0.6277, precision: 0.8368, recall: 0.6759, f1: 0.7478, edges-ner-ontonotes_loss: 0.0711
09/16 10:33:26 AM: Update 29607: task edges-ner-ontonotes, batch 607 (29607): mcc: 0.7347, acc: 0.6223, precision: 0.8336, recall: 0.6706, f1: 0.7433, edges-ner-ontonotes_loss: 0.0724
09/16 10:33:36 AM: Update 29769: task edges-ner-ontonotes, batch 769 (29769): mcc: 0.7356, acc: 0.6225, precision: 0.8354, recall: 0.6706, f1: 0.7440, edges-ner-ontonotes_loss: 0.0720
09/16 10:33:46 AM: Update 29896: task edges-ner-ontonotes, batch 896 (29896): mcc: 0.7353, acc: 0.6228, precision: 0.8355, recall: 0.6701, f1: 0.7437, edges-ner-ontonotes_loss: 0.0718
09/16 10:33:54 AM: ***** Step 30000 / Validation 30 *****
09/16 10:33:54 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:33:54 AM: Validating...
09/16 10:33:57 AM: Evaluate: task edges-ner-ontonotes, batch 23 (157): mcc: 0.7487, acc: 0.6534, precision: 0.8528, recall: 0.6790, f1: 0.7560, edges-ner-ontonotes_loss: 0.0689
09/16 10:34:07 AM: Evaluate: task edges-ner-ontonotes, batch 110 (157): mcc: 0.8192, acc: 0.7264, precision: 0.9173, recall: 0.7474, f1: 0.8237, edges-ner-ontonotes_loss: 0.0534
09/16 10:34:13 AM: Updating LR scheduler:
09/16 10:34:13 AM: 	Best result seen so far for macro_avg: 0.824
09/16 10:34:13 AM: 	# validation passes without improvement: 2
09/16 10:34:13 AM: edges-ner-ontonotes_loss: training: 0.071291 validation: 0.051802
09/16 10:34:13 AM: macro_avg: validation: 0.820745
09/16 10:34:13 AM: micro_avg: validation: 0.000000
09/16 10:34:13 AM: edges-ner-ontonotes_mcc: training: 0.736688 validation: 0.816552
09/16 10:34:13 AM: edges-ner-ontonotes_acc: training: 0.624684 validation: 0.720200
09/16 10:34:13 AM: edges-ner-ontonotes_precision: training: 0.836343 validation: 0.918828
09/16 10:34:13 AM: edges-ner-ontonotes_recall: training: 0.671795 validation: 0.741583
09/16 10:34:13 AM: edges-ner-ontonotes_f1: training: 0.745092 validation: 0.820745
09/16 10:34:13 AM: Global learning rate: 0.0001
09/16 10:34:13 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:34:17 AM: Update 30049: task edges-ner-ontonotes, batch 49 (30049): mcc: 0.7524, acc: 0.6418, precision: 0.8491, recall: 0.6885, f1: 0.7604, edges-ner-ontonotes_loss: 0.0645
09/16 10:34:27 AM: Update 30178: task edges-ner-ontonotes, batch 178 (30178): mcc: 0.7517, acc: 0.6449, precision: 0.8464, recall: 0.6895, f1: 0.7599, edges-ner-ontonotes_loss: 0.0673
09/16 10:34:37 AM: Update 30276: task edges-ner-ontonotes, batch 276 (30276): mcc: 0.7560, acc: 0.6485, precision: 0.8495, recall: 0.6943, f1: 0.7641, edges-ner-ontonotes_loss: 0.0655
09/16 10:34:47 AM: Update 30398: task edges-ner-ontonotes, batch 398 (30398): mcc: 0.7634, acc: 0.6586, precision: 0.8538, recall: 0.7038, f1: 0.7716, edges-ner-ontonotes_loss: 0.0634
09/16 10:34:57 AM: Update 30506: task edges-ner-ontonotes, batch 506 (30506): mcc: 0.7658, acc: 0.6617, precision: 0.8555, recall: 0.7065, f1: 0.7739, edges-ner-ontonotes_loss: 0.0629
09/16 10:35:07 AM: Update 30631: task edges-ner-ontonotes, batch 631 (30631): mcc: 0.7662, acc: 0.6619, precision: 0.8551, recall: 0.7075, f1: 0.7743, edges-ner-ontonotes_loss: 0.0627
09/16 10:35:17 AM: Update 30750: task edges-ner-ontonotes, batch 750 (30750): mcc: 0.7683, acc: 0.6644, precision: 0.8560, recall: 0.7104, f1: 0.7764, edges-ner-ontonotes_loss: 0.0622
09/16 10:35:27 AM: Update 30843: task edges-ner-ontonotes, batch 843 (30843): mcc: 0.7637, acc: 0.6591, precision: 0.8526, recall: 0.7052, f1: 0.7720, edges-ner-ontonotes_loss: 0.0631
09/16 10:35:37 AM: Update 30968: task edges-ner-ontonotes, batch 968 (30968): mcc: 0.7563, acc: 0.6496, precision: 0.8481, recall: 0.6962, f1: 0.7647, edges-ner-ontonotes_loss: 0.0655
09/16 10:35:39 AM: ***** Step 31000 / Validation 31 *****
09/16 10:35:39 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:35:39 AM: Validating...
09/16 10:35:47 AM: Evaluate: task edges-ner-ontonotes, batch 70 (157): mcc: 0.8056, acc: 0.7121, precision: 0.8984, recall: 0.7397, f1: 0.8114, edges-ner-ontonotes_loss: 0.0565
09/16 10:35:57 AM: Evaluate: task edges-ner-ontonotes, batch 145 (157): mcc: 0.8198, acc: 0.7262, precision: 0.9166, recall: 0.7492, f1: 0.8245, edges-ner-ontonotes_loss: 0.0520
09/16 10:35:58 AM: Updating LR scheduler:
09/16 10:35:58 AM: 	Best result seen so far for macro_avg: 0.824
09/16 10:35:58 AM: 	# validation passes without improvement: 3
09/16 10:35:58 AM: edges-ner-ontonotes_loss: training: 0.065834 validation: 0.051620
09/16 10:35:58 AM: macro_avg: validation: 0.823672
09/16 10:35:58 AM: micro_avg: validation: 0.000000
09/16 10:35:58 AM: edges-ner-ontonotes_mcc: training: 0.755741 validation: 0.819022
09/16 10:35:58 AM: edges-ner-ontonotes_acc: training: 0.648652 validation: 0.724826
09/16 10:35:58 AM: edges-ner-ontonotes_precision: training: 0.847835 validation: 0.915994
09/16 10:35:58 AM: edges-ner-ontonotes_recall: training: 0.695381 validation: 0.748256
09/16 10:35:58 AM: edges-ner-ontonotes_f1: training: 0.764077 validation: 0.823672
09/16 10:35:58 AM: Global learning rate: 0.0001
09/16 10:35:58 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:36:07 AM: Update 31112: task edges-ner-ontonotes, batch 112 (31112): mcc: 0.7100, acc: 0.5938, precision: 0.8171, recall: 0.6415, f1: 0.7187, edges-ner-ontonotes_loss: 0.0808
09/16 10:36:17 AM: Update 31230: task edges-ner-ontonotes, batch 230 (31230): mcc: 0.7186, acc: 0.6026, precision: 0.8243, recall: 0.6504, f1: 0.7271, edges-ner-ontonotes_loss: 0.0762
09/16 10:36:27 AM: Update 31379: task edges-ner-ontonotes, batch 379 (31379): mcc: 0.7286, acc: 0.6124, precision: 0.8337, recall: 0.6599, f1: 0.7367, edges-ner-ontonotes_loss: 0.0735
09/16 10:36:37 AM: Update 31488: task edges-ner-ontonotes, batch 488 (31488): mcc: 0.7302, acc: 0.6148, precision: 0.8347, recall: 0.6619, f1: 0.7383, edges-ner-ontonotes_loss: 0.0726
09/16 10:36:47 AM: Update 31618: task edges-ner-ontonotes, batch 618 (31618): mcc: 0.7368, acc: 0.6245, precision: 0.8390, recall: 0.6697, f1: 0.7449, edges-ner-ontonotes_loss: 0.0709
09/16 10:36:57 AM: Update 31745: task edges-ner-ontonotes, batch 745 (31745): mcc: 0.7389, acc: 0.6279, precision: 0.8393, recall: 0.6732, f1: 0.7471, edges-ner-ontonotes_loss: 0.0703
09/16 10:37:07 AM: Update 31839: task edges-ner-ontonotes, batch 839 (31839): mcc: 0.7419, acc: 0.6312, precision: 0.8411, recall: 0.6769, f1: 0.7501, edges-ner-ontonotes_loss: 0.0695
09/16 10:37:17 AM: Update 31962: task edges-ner-ontonotes, batch 962 (31962): mcc: 0.7478, acc: 0.6386, precision: 0.8448, recall: 0.6840, f1: 0.7559, edges-ner-ontonotes_loss: 0.0680
09/16 10:37:20 AM: ***** Step 32000 / Validation 32 *****
09/16 10:37:20 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:37:20 AM: Validating...
09/16 10:37:27 AM: Evaluate: task edges-ner-ontonotes, batch 65 (157): mcc: 0.7834, acc: 0.6910, precision: 0.8815, recall: 0.7152, f1: 0.7897, edges-ner-ontonotes_loss: 0.0628
09/16 10:37:37 AM: Evaluate: task edges-ner-ontonotes, batch 141 (157): mcc: 0.8151, acc: 0.7270, precision: 0.9072, recall: 0.7488, f1: 0.8204, edges-ner-ontonotes_loss: 0.0539
09/16 10:37:39 AM: Updating LR scheduler:
09/16 10:37:39 AM: 	Best result seen so far for macro_avg: 0.824
09/16 10:37:39 AM: 	# validation passes without improvement: 0
09/16 10:37:39 AM: edges-ner-ontonotes_loss: training: 0.067621 validation: 0.053514
09/16 10:37:39 AM: macro_avg: validation: 0.819673
09/16 10:37:39 AM: micro_avg: validation: 0.000000
09/16 10:37:39 AM: edges-ner-ontonotes_mcc: training: 0.749037 validation: 0.814276
09/16 10:37:39 AM: edges-ner-ontonotes_acc: training: 0.640275 validation: 0.725736
09/16 10:37:39 AM: edges-ner-ontonotes_precision: training: 0.845410 validation: 0.906385
09/16 10:37:39 AM: edges-ner-ontonotes_recall: training: 0.685697 validation: 0.748104
09/16 10:37:39 AM: edges-ner-ontonotes_f1: training: 0.757223 validation: 0.819673
09/16 10:37:39 AM: Global learning rate: 5e-05
09/16 10:37:39 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:37:48 AM: Update 32074: task edges-ner-ontonotes, batch 74 (32074): mcc: 0.7788, acc: 0.6807, precision: 0.8606, recall: 0.7251, f1: 0.7870, edges-ner-ontonotes_loss: 0.0590
09/16 10:37:58 AM: Update 32193: task edges-ner-ontonotes, batch 193 (32193): mcc: 0.7711, acc: 0.6698, precision: 0.8555, recall: 0.7158, f1: 0.7794, edges-ner-ontonotes_loss: 0.0610
09/16 10:38:08 AM: Update 32323: task edges-ner-ontonotes, batch 323 (32323): mcc: 0.7737, acc: 0.6724, precision: 0.8571, recall: 0.7190, f1: 0.7820, edges-ner-ontonotes_loss: 0.0607
09/16 10:38:18 AM: Update 32431: task edges-ner-ontonotes, batch 431 (32431): mcc: 0.7608, acc: 0.6563, precision: 0.8492, recall: 0.7032, f1: 0.7693, edges-ner-ontonotes_loss: 0.0640
09/16 10:38:28 AM: Update 32561: task edges-ner-ontonotes, batch 561 (32561): mcc: 0.7491, acc: 0.6418, precision: 0.8408, recall: 0.6898, f1: 0.7578, edges-ner-ontonotes_loss: 0.0682
09/16 10:38:38 AM: Update 32677: task edges-ner-ontonotes, batch 677 (32677): mcc: 0.7420, acc: 0.6325, precision: 0.8369, recall: 0.6807, f1: 0.7507, edges-ner-ontonotes_loss: 0.0704
09/16 10:38:48 AM: Update 32828: task edges-ner-ontonotes, batch 828 (32828): mcc: 0.7412, acc: 0.6307, precision: 0.8372, recall: 0.6790, f1: 0.7498, edges-ner-ontonotes_loss: 0.0703
09/16 10:38:58 AM: Update 32976: task edges-ner-ontonotes, batch 976 (32976): mcc: 0.7410, acc: 0.6301, precision: 0.8376, recall: 0.6781, f1: 0.7495, edges-ner-ontonotes_loss: 0.0703
09/16 10:39:02 AM: ***** Step 33000 / Validation 33 *****
09/16 10:39:02 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:39:02 AM: Validating...
09/16 10:39:08 AM: Evaluate: task edges-ner-ontonotes, batch 60 (157): mcc: 0.8230, acc: 0.7364, precision: 0.9084, recall: 0.7617, f1: 0.8286, edges-ner-ontonotes_loss: 0.0527
09/16 10:39:18 AM: Evaluate: task edges-ner-ontonotes, batch 135 (157): mcc: 0.8249, acc: 0.7346, precision: 0.9203, recall: 0.7549, f1: 0.8294, edges-ner-ontonotes_loss: 0.0506
09/16 10:39:21 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:39:21 AM: Best result seen so far for macro.
09/16 10:39:21 AM: Updating LR scheduler:
09/16 10:39:21 AM: 	Best result seen so far for macro_avg: 0.826
09/16 10:39:21 AM: 	# validation passes without improvement: 0
09/16 10:39:21 AM: edges-ner-ontonotes_loss: training: 0.070239 validation: 0.050628
09/16 10:39:21 AM: macro_avg: validation: 0.826031
09/16 10:39:21 AM: micro_avg: validation: 0.000000
09/16 10:39:21 AM: edges-ner-ontonotes_mcc: training: 0.740837 validation: 0.821397
09/16 10:39:21 AM: edges-ner-ontonotes_acc: training: 0.629744 validation: 0.729906
09/16 10:39:21 AM: edges-ner-ontonotes_precision: training: 0.837989 validation: 0.917400
09/16 10:39:21 AM: edges-ner-ontonotes_recall: training: 0.677645 validation: 0.751213
09/16 10:39:21 AM: edges-ner-ontonotes_f1: training: 0.749336 validation: 0.826031
09/16 10:39:21 AM: Global learning rate: 5e-05
09/16 10:39:21 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:39:28 AM: Update 33094: task edges-ner-ontonotes, batch 94 (33094): mcc: 0.7505, acc: 0.6451, precision: 0.8442, recall: 0.6893, f1: 0.7589, edges-ner-ontonotes_loss: 0.0679
09/16 10:39:39 AM: Update 33224: task edges-ner-ontonotes, batch 224 (33224): mcc: 0.7543, acc: 0.6497, precision: 0.8495, recall: 0.6915, f1: 0.7624, edges-ner-ontonotes_loss: 0.0665
09/16 10:39:49 AM: Update 33322: task edges-ner-ontonotes, batch 322 (33322): mcc: 0.7517, acc: 0.6467, precision: 0.8469, recall: 0.6892, f1: 0.7599, edges-ner-ontonotes_loss: 0.0665
09/16 10:39:59 AM: Update 33446: task edges-ner-ontonotes, batch 446 (33446): mcc: 0.7570, acc: 0.6531, precision: 0.8497, recall: 0.6960, f1: 0.7652, edges-ner-ontonotes_loss: 0.0647
09/16 10:40:09 AM: Update 33570: task edges-ner-ontonotes, batch 570 (33570): mcc: 0.7634, acc: 0.6612, precision: 0.8529, recall: 0.7045, f1: 0.7716, edges-ner-ontonotes_loss: 0.0632
09/16 10:40:19 AM: Update 33678: task edges-ner-ontonotes, batch 678 (33678): mcc: 0.7647, acc: 0.6625, precision: 0.8539, recall: 0.7059, f1: 0.7729, edges-ner-ontonotes_loss: 0.0629
09/16 10:40:29 AM: Update 33797: task edges-ner-ontonotes, batch 797 (33797): mcc: 0.7660, acc: 0.6635, precision: 0.8544, recall: 0.7079, f1: 0.7743, edges-ner-ontonotes_loss: 0.0625
09/16 10:40:39 AM: Update 33920: task edges-ner-ontonotes, batch 920 (33920): mcc: 0.7666, acc: 0.6639, precision: 0.8540, recall: 0.7092, f1: 0.7749, edges-ner-ontonotes_loss: 0.0623
09/16 10:40:47 AM: ***** Step 34000 / Validation 34 *****
09/16 10:40:47 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:40:47 AM: Validating...
09/16 10:40:49 AM: Evaluate: task edges-ner-ontonotes, batch 17 (157): mcc: 0.7547, acc: 0.6526, precision: 0.8636, recall: 0.6804, f1: 0.7611, edges-ner-ontonotes_loss: 0.0637
09/16 10:40:59 AM: Evaluate: task edges-ner-ontonotes, batch 102 (157): mcc: 0.8185, acc: 0.7270, precision: 0.9107, recall: 0.7519, f1: 0.8237, edges-ner-ontonotes_loss: 0.0534
09/16 10:41:06 AM: Updating LR scheduler:
09/16 10:41:06 AM: 	Best result seen so far for macro_avg: 0.826
09/16 10:41:06 AM: 	# validation passes without improvement: 1
09/16 10:41:06 AM: edges-ner-ontonotes_loss: training: 0.063934 validation: 0.051062
09/16 10:41:06 AM: macro_avg: validation: 0.823691
09/16 10:41:06 AM: micro_avg: validation: 0.000000
09/16 10:41:06 AM: edges-ner-ontonotes_mcc: training: 0.760077 validation: 0.818897
09/16 10:41:06 AM: edges-ner-ontonotes_acc: training: 0.655915 validation: 0.725887
09/16 10:41:06 AM: edges-ner-ontonotes_precision: training: 0.849359 validation: 0.914569
09/16 10:41:06 AM: edges-ner-ontonotes_recall: training: 0.701701 validation: 0.749242
09/16 10:41:06 AM: edges-ner-ontonotes_f1: training: 0.768502 validation: 0.823691
09/16 10:41:06 AM: Global learning rate: 5e-05
09/16 10:41:06 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:41:09 AM: Update 34031: task edges-ner-ontonotes, batch 31 (34031): mcc: 0.6858, acc: 0.5604, precision: 0.8055, recall: 0.6094, f1: 0.6938, edges-ner-ontonotes_loss: 0.0805
09/16 10:41:19 AM: Update 34166: task edges-ner-ontonotes, batch 166 (34166): mcc: 0.7026, acc: 0.5848, precision: 0.8140, recall: 0.6312, f1: 0.7111, edges-ner-ontonotes_loss: 0.0808
09/16 10:41:29 AM: Update 34277: task edges-ner-ontonotes, batch 277 (34277): mcc: 0.7088, acc: 0.5900, precision: 0.8194, recall: 0.6374, f1: 0.7171, edges-ner-ontonotes_loss: 0.0788
09/16 10:41:39 AM: Update 34428: task edges-ner-ontonotes, batch 428 (34428): mcc: 0.7191, acc: 0.6028, precision: 0.8270, recall: 0.6491, f1: 0.7273, edges-ner-ontonotes_loss: 0.0755
09/16 10:41:49 AM: Update 34550: task edges-ner-ontonotes, batch 550 (34550): mcc: 0.7226, acc: 0.6076, precision: 0.8294, recall: 0.6532, f1: 0.7308, edges-ner-ontonotes_loss: 0.0741
09/16 10:41:59 AM: Update 34679: task edges-ner-ontonotes, batch 679 (34679): mcc: 0.7280, acc: 0.6146, precision: 0.8319, recall: 0.6605, f1: 0.7363, edges-ner-ontonotes_loss: 0.0730
09/16 10:42:09 AM: Update 34806: task edges-ner-ontonotes, batch 806 (34806): mcc: 0.7324, acc: 0.6206, precision: 0.8348, recall: 0.6657, f1: 0.7407, edges-ner-ontonotes_loss: 0.0720
09/16 10:42:19 AM: Update 34916: task edges-ner-ontonotes, batch 916 (34916): mcc: 0.7364, acc: 0.6256, precision: 0.8370, recall: 0.6707, f1: 0.7447, edges-ner-ontonotes_loss: 0.0708
09/16 10:42:26 AM: ***** Step 35000 / Validation 35 *****
09/16 10:42:26 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:42:26 AM: Validating...
09/16 10:42:29 AM: Evaluate: task edges-ner-ontonotes, batch 34 (157): mcc: 0.7736, acc: 0.6814, precision: 0.8696, recall: 0.7081, f1: 0.7806, edges-ner-ontonotes_loss: 0.0653
09/16 10:42:40 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.8126, acc: 0.7231, precision: 0.9081, recall: 0.7437, f1: 0.8177, edges-ner-ontonotes_loss: 0.0553
09/16 10:42:45 AM: Updating LR scheduler:
09/16 10:42:45 AM: 	Best result seen so far for macro_avg: 0.826
09/16 10:42:45 AM: 	# validation passes without improvement: 2
09/16 10:42:45 AM: edges-ner-ontonotes_loss: training: 0.069834 validation: 0.052127
09/16 10:42:45 AM: macro_avg: validation: 0.825071
09/16 10:42:45 AM: micro_avg: validation: 0.000000
09/16 10:42:45 AM: edges-ner-ontonotes_mcc: training: 0.740597 validation: 0.820118
09/16 10:42:45 AM: edges-ner-ontonotes_acc: training: 0.630566 validation: 0.731498
09/16 10:42:45 AM: edges-ner-ontonotes_precision: training: 0.840081 validation: 0.913688
09/16 10:42:45 AM: edges-ner-ontonotes_recall: training: 0.675463 validation: 0.752123
09/16 10:42:45 AM: edges-ner-ontonotes_f1: training: 0.748832 validation: 0.825071
09/16 10:42:45 AM: Global learning rate: 5e-05
09/16 10:42:45 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:42:50 AM: Update 35056: task edges-ner-ontonotes, batch 56 (35056): mcc: 0.7785, acc: 0.6772, precision: 0.8649, recall: 0.7208, f1: 0.7863, edges-ner-ontonotes_loss: 0.0598
09/16 10:43:01 AM: Update 35172: task edges-ner-ontonotes, batch 172 (35172): mcc: 0.7840, acc: 0.6832, precision: 0.8675, recall: 0.7282, f1: 0.7918, edges-ner-ontonotes_loss: 0.0583
09/16 10:43:11 AM: Update 35285: task edges-ner-ontonotes, batch 285 (35285): mcc: 0.7739, acc: 0.6702, precision: 0.8616, recall: 0.7155, f1: 0.7818, edges-ner-ontonotes_loss: 0.0599
09/16 10:43:21 AM: Update 35396: task edges-ner-ontonotes, batch 396 (35396): mcc: 0.7771, acc: 0.6742, precision: 0.8628, recall: 0.7203, f1: 0.7851, edges-ner-ontonotes_loss: 0.0597
09/16 10:43:32 AM: Update 35490: task edges-ner-ontonotes, batch 490 (35490): mcc: 0.7728, acc: 0.6693, precision: 0.8587, recall: 0.7161, f1: 0.7809, edges-ner-ontonotes_loss: 0.0605
09/16 10:43:42 AM: Update 35616: task edges-ner-ontonotes, batch 616 (35616): mcc: 0.7607, acc: 0.6544, precision: 0.8508, recall: 0.7015, f1: 0.7690, edges-ner-ontonotes_loss: 0.0647
09/16 10:43:52 AM: Update 35745: task edges-ner-ontonotes, batch 745 (35745): mcc: 0.7519, acc: 0.6435, precision: 0.8451, recall: 0.6909, f1: 0.7603, edges-ner-ontonotes_loss: 0.0676
09/16 10:44:02 AM: Update 35863: task edges-ner-ontonotes, batch 863 (35863): mcc: 0.7480, acc: 0.6387, precision: 0.8427, recall: 0.6861, f1: 0.7564, edges-ner-ontonotes_loss: 0.0689
09/16 10:44:10 AM: ***** Step 36000 / Validation 36 *****
09/16 10:44:10 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:44:10 AM: Validating...
09/16 10:44:12 AM: Evaluate: task edges-ner-ontonotes, batch 14 (157): mcc: 0.7556, acc: 0.6549, precision: 0.8592, recall: 0.6856, f1: 0.7626, edges-ner-ontonotes_loss: 0.0651
09/16 10:44:22 AM: Evaluate: task edges-ner-ontonotes, batch 100 (157): mcc: 0.8157, acc: 0.7226, precision: 0.9139, recall: 0.7442, f1: 0.8204, edges-ner-ontonotes_loss: 0.0534
09/16 10:44:30 AM: Updating LR scheduler:
09/16 10:44:30 AM: 	Best result seen so far for macro_avg: 0.826
09/16 10:44:30 AM: 	# validation passes without improvement: 3
09/16 10:44:30 AM: edges-ner-ontonotes_loss: training: 0.068790 validation: 0.051077
09/16 10:44:30 AM: macro_avg: validation: 0.820915
09/16 10:44:30 AM: micro_avg: validation: 0.000000
09/16 10:44:30 AM: edges-ner-ontonotes_mcc: training: 0.747222 validation: 0.816647
09/16 10:44:30 AM: edges-ner-ontonotes_acc: training: 0.637653 validation: 0.721717
09/16 10:44:30 AM: edges-ner-ontonotes_precision: training: 0.842557 validation: 0.918207
09/16 10:44:30 AM: edges-ner-ontonotes_recall: training: 0.684941 validation: 0.742266
09/16 10:44:30 AM: edges-ner-ontonotes_f1: training: 0.755617 validation: 0.820915
09/16 10:44:30 AM: Global learning rate: 5e-05
09/16 10:44:30 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:44:32 AM: Update 36036: task edges-ner-ontonotes, batch 36 (36036): mcc: 0.7544, acc: 0.6419, precision: 0.8489, recall: 0.6922, f1: 0.7626, edges-ner-ontonotes_loss: 0.0670
09/16 10:44:42 AM: Update 36132: task edges-ner-ontonotes, batch 132 (36132): mcc: 0.7384, acc: 0.6267, precision: 0.8405, recall: 0.6712, f1: 0.7464, edges-ner-ontonotes_loss: 0.0691
09/16 10:44:52 AM: Update 36256: task edges-ner-ontonotes, batch 256 (36256): mcc: 0.7460, acc: 0.6385, precision: 0.8429, recall: 0.6825, f1: 0.7543, edges-ner-ontonotes_loss: 0.0675
09/16 10:45:02 AM: Update 36380: task edges-ner-ontonotes, batch 380 (36380): mcc: 0.7505, acc: 0.6431, precision: 0.8471, recall: 0.6867, f1: 0.7585, edges-ner-ontonotes_loss: 0.0668
09/16 10:45:12 AM: Update 36482: task edges-ner-ontonotes, batch 482 (36482): mcc: 0.7518, acc: 0.6451, precision: 0.8478, recall: 0.6885, f1: 0.7599, edges-ner-ontonotes_loss: 0.0662
09/16 10:45:22 AM: Update 36597: task edges-ner-ontonotes, batch 597 (36597): mcc: 0.7579, acc: 0.6521, precision: 0.8521, recall: 0.6955, f1: 0.7658, edges-ner-ontonotes_loss: 0.0649
09/16 10:45:32 AM: Update 36720: task edges-ner-ontonotes, batch 720 (36720): mcc: 0.7627, acc: 0.6578, precision: 0.8546, recall: 0.7019, f1: 0.7707, edges-ner-ontonotes_loss: 0.0636
09/16 10:45:42 AM: Update 36817: task edges-ner-ontonotes, batch 817 (36817): mcc: 0.7639, acc: 0.6593, precision: 0.8551, recall: 0.7036, f1: 0.7720, edges-ner-ontonotes_loss: 0.0633
09/16 10:45:52 AM: Update 36936: task edges-ner-ontonotes, batch 936 (36936): mcc: 0.7645, acc: 0.6600, precision: 0.8552, recall: 0.7044, f1: 0.7725, edges-ner-ontonotes_loss: 0.0631
09/16 10:45:58 AM: ***** Step 37000 / Validation 37 *****
09/16 10:45:58 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:45:58 AM: Validating...
09/16 10:46:03 AM: Evaluate: task edges-ner-ontonotes, batch 47 (157): mcc: 0.7787, acc: 0.6842, precision: 0.8691, recall: 0.7175, f1: 0.7861, edges-ner-ontonotes_loss: 0.0635
09/16 10:46:13 AM: Evaluate: task edges-ner-ontonotes, batch 121 (157): mcc: 0.8126, acc: 0.7237, precision: 0.8997, recall: 0.7509, f1: 0.8186, edges-ner-ontonotes_loss: 0.0544
09/16 10:46:17 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:46:17 AM: Best result seen so far for macro.
09/16 10:46:17 AM: Updating LR scheduler:
09/16 10:46:17 AM: 	Best result seen so far for macro_avg: 0.826
09/16 10:46:17 AM: 	# validation passes without improvement: 0
09/16 10:46:17 AM: edges-ner-ontonotes_loss: training: 0.062937 validation: 0.051769
09/16 10:46:17 AM: macro_avg: validation: 0.826114
09/16 10:46:17 AM: micro_avg: validation: 0.000000
09/16 10:46:17 AM: edges-ner-ontonotes_mcc: training: 0.765305 validation: 0.820283
09/16 10:46:17 AM: edges-ner-ontonotes_acc: training: 0.660843 validation: 0.732863
09/16 10:46:17 AM: edges-ner-ontonotes_precision: training: 0.855751 validation: 0.904921
09/16 10:46:17 AM: edges-ner-ontonotes_recall: training: 0.705411 validation: 0.759933
09/16 10:46:17 AM: edges-ner-ontonotes_f1: training: 0.773342 validation: 0.826114
09/16 10:46:17 AM: Global learning rate: 2.5e-05
09/16 10:46:17 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:46:23 AM: Update 37042: task edges-ner-ontonotes, batch 42 (37042): mcc: 0.7427, acc: 0.6337, precision: 0.8359, recall: 0.6828, f1: 0.7516, edges-ner-ontonotes_loss: 0.0616
09/16 10:46:33 AM: Update 37167: task edges-ner-ontonotes, batch 167 (37167): mcc: 0.7121, acc: 0.5941, precision: 0.8202, recall: 0.6425, f1: 0.7206, edges-ner-ontonotes_loss: 0.0768
09/16 10:46:43 AM: Update 37295: task edges-ner-ontonotes, batch 295 (37295): mcc: 0.7089, acc: 0.5911, precision: 0.8150, recall: 0.6413, f1: 0.7178, edges-ner-ontonotes_loss: 0.0786
09/16 10:46:53 AM: Update 37398: task edges-ner-ontonotes, batch 398 (37398): mcc: 0.7121, acc: 0.5945, precision: 0.8177, recall: 0.6447, f1: 0.7210, edges-ner-ontonotes_loss: 0.0780
09/16 10:47:03 AM: Update 37542: task edges-ner-ontonotes, batch 542 (37542): mcc: 0.7183, acc: 0.6020, precision: 0.8226, recall: 0.6513, f1: 0.7270, edges-ner-ontonotes_loss: 0.0756
09/16 10:47:13 AM: Update 37658: task edges-ner-ontonotes, batch 658 (37658): mcc: 0.7214, acc: 0.6055, precision: 0.8257, recall: 0.6541, f1: 0.7299, edges-ner-ontonotes_loss: 0.0746
09/16 10:47:23 AM: Update 37783: task edges-ner-ontonotes, batch 783 (37783): mcc: 0.7261, acc: 0.6118, precision: 0.8293, recall: 0.6592, f1: 0.7345, edges-ner-ontonotes_loss: 0.0734
09/16 10:47:33 AM: Update 37905: task edges-ner-ontonotes, batch 905 (37905): mcc: 0.7301, acc: 0.6169, precision: 0.8321, recall: 0.6640, f1: 0.7386, edges-ner-ontonotes_loss: 0.0726
09/16 10:47:43 AM: Update 38000: task edges-ner-ontonotes, batch 1000 (38000): mcc: 0.7323, acc: 0.6193, precision: 0.8331, recall: 0.6669, f1: 0.7408, edges-ner-ontonotes_loss: 0.0720
09/16 10:47:43 AM: ***** Step 38000 / Validation 38 *****
09/16 10:47:43 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:47:43 AM: Validating...
09/16 10:47:53 AM: Evaluate: task edges-ner-ontonotes, batch 89 (157): mcc: 0.8150, acc: 0.7270, precision: 0.9047, recall: 0.7509, f1: 0.8206, edges-ner-ontonotes_loss: 0.0553
09/16 10:48:02 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:48:02 AM: Best result seen so far for macro.
09/16 10:48:02 AM: Updating LR scheduler:
09/16 10:48:02 AM: 	Best result seen so far for macro_avg: 0.830
09/16 10:48:02 AM: 	# validation passes without improvement: 0
09/16 10:48:02 AM: edges-ner-ontonotes_loss: training: 0.071966 validation: 0.050899
09/16 10:48:02 AM: macro_avg: validation: 0.830131
09/16 10:48:02 AM: micro_avg: validation: 0.000000
09/16 10:48:02 AM: edges-ner-ontonotes_mcc: training: 0.732328 validation: 0.825013
09/16 10:48:02 AM: edges-ner-ontonotes_acc: training: 0.619306 validation: 0.737489
09/16 10:48:02 AM: edges-ner-ontonotes_precision: training: 0.833090 validation: 0.914507
09/16 10:48:02 AM: edges-ner-ontonotes_recall: training: 0.666934 validation: 0.760009
09/16 10:48:02 AM: edges-ner-ontonotes_f1: training: 0.740809 validation: 0.830131
09/16 10:48:02 AM: Global learning rate: 2.5e-05
09/16 10:48:02 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:48:03 AM: Update 38015: task edges-ner-ontonotes, batch 15 (38015): mcc: 0.7919, acc: 0.6935, precision: 0.8664, recall: 0.7434, f1: 0.8002, edges-ner-ontonotes_loss: 0.0591
09/16 10:48:13 AM: Update 38135: task edges-ner-ontonotes, batch 135 (38135): mcc: 0.7856, acc: 0.6872, precision: 0.8672, recall: 0.7314, f1: 0.7935, edges-ner-ontonotes_loss: 0.0577
09/16 10:48:23 AM: Update 38252: task edges-ner-ontonotes, batch 252 (38252): mcc: 0.7819, acc: 0.6817, precision: 0.8654, recall: 0.7263, f1: 0.7898, edges-ner-ontonotes_loss: 0.0586
09/16 10:48:33 AM: Update 38346: task edges-ner-ontonotes, batch 346 (38346): mcc: 0.7816, acc: 0.6809, precision: 0.8651, recall: 0.7261, f1: 0.7896, edges-ner-ontonotes_loss: 0.0586
09/16 10:48:43 AM: Update 38468: task edges-ner-ontonotes, batch 468 (38468): mcc: 0.7815, acc: 0.6804, precision: 0.8655, recall: 0.7255, f1: 0.7893, edges-ner-ontonotes_loss: 0.0589
09/16 10:48:54 AM: Update 38583: task edges-ner-ontonotes, batch 583 (38583): mcc: 0.7784, acc: 0.6768, precision: 0.8631, recall: 0.7222, f1: 0.7864, edges-ner-ontonotes_loss: 0.0595
09/16 10:49:04 AM: Update 38685: task edges-ner-ontonotes, batch 685 (38685): mcc: 0.7668, acc: 0.6623, precision: 0.8556, recall: 0.7081, f1: 0.7749, edges-ner-ontonotes_loss: 0.0628
09/16 10:49:14 AM: Update 38812: task edges-ner-ontonotes, batch 812 (38812): mcc: 0.7589, acc: 0.6526, precision: 0.8500, recall: 0.6991, f1: 0.7672, edges-ner-ontonotes_loss: 0.0656
09/16 10:49:24 AM: Update 38917: task edges-ner-ontonotes, batch 917 (38917): mcc: 0.7535, acc: 0.6456, precision: 0.8463, recall: 0.6927, f1: 0.7619, edges-ner-ontonotes_loss: 0.0671
09/16 10:49:30 AM: ***** Step 39000 / Validation 39 *****
09/16 10:49:30 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:49:30 AM: Validating...
09/16 10:49:34 AM: Evaluate: task edges-ner-ontonotes, batch 39 (157): mcc: 0.7989, acc: 0.7050, precision: 0.8880, recall: 0.7368, f1: 0.8054, edges-ner-ontonotes_loss: 0.0565
09/16 10:49:44 AM: Evaluate: task edges-ner-ontonotes, batch 114 (157): mcc: 0.8194, acc: 0.7272, precision: 0.9156, recall: 0.7491, f1: 0.8241, edges-ner-ontonotes_loss: 0.0515
09/16 10:49:49 AM: Updating LR scheduler:
09/16 10:49:49 AM: 	Best result seen so far for macro_avg: 0.830
09/16 10:49:49 AM: 	# validation passes without improvement: 1
09/16 10:49:49 AM: edges-ner-ontonotes_loss: training: 0.067350 validation: 0.050457
09/16 10:49:49 AM: macro_avg: validation: 0.822851
09/16 10:49:49 AM: micro_avg: validation: 0.000000
09/16 10:49:49 AM: edges-ner-ontonotes_mcc: training: 0.752369 validation: 0.818305
09/16 10:49:49 AM: edges-ner-ontonotes_acc: training: 0.644244 validation: 0.724598
09/16 10:49:49 AM: edges-ner-ontonotes_precision: training: 0.845630 validation: 0.916581
09/16 10:49:49 AM: edges-ner-ontonotes_recall: training: 0.691346 validation: 0.746512
09/16 10:49:49 AM: edges-ner-ontonotes_f1: training: 0.760744 validation: 0.822851
09/16 10:49:49 AM: Global learning rate: 2.5e-05
09/16 10:49:49 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:49:54 AM: Update 39069: task edges-ner-ontonotes, batch 69 (39069): mcc: 0.7412, acc: 0.6303, precision: 0.8413, recall: 0.6755, f1: 0.7493, edges-ner-ontonotes_loss: 0.0692
09/16 10:50:04 AM: Update 39210: task edges-ner-ontonotes, batch 210 (39210): mcc: 0.7404, acc: 0.6276, precision: 0.8398, recall: 0.6754, f1: 0.7487, edges-ner-ontonotes_loss: 0.0692
09/16 10:50:14 AM: Update 39309: task edges-ner-ontonotes, batch 309 (39309): mcc: 0.7418, acc: 0.6293, precision: 0.8420, recall: 0.6759, f1: 0.7499, edges-ner-ontonotes_loss: 0.0686
09/16 10:50:24 AM: Update 39429: task edges-ner-ontonotes, batch 429 (39429): mcc: 0.7441, acc: 0.6337, precision: 0.8431, recall: 0.6790, f1: 0.7522, edges-ner-ontonotes_loss: 0.0685
09/16 10:50:34 AM: Update 39527: task edges-ner-ontonotes, batch 527 (39527): mcc: 0.7462, acc: 0.6366, precision: 0.8444, recall: 0.6816, f1: 0.7543, edges-ner-ontonotes_loss: 0.0678
09/16 10:50:45 AM: Update 39645: task edges-ner-ontonotes, batch 645 (39645): mcc: 0.7532, acc: 0.6455, precision: 0.8488, recall: 0.6901, f1: 0.7613, edges-ner-ontonotes_loss: 0.0662
09/16 10:50:55 AM: Update 39761: task edges-ner-ontonotes, batch 761 (39761): mcc: 0.7576, acc: 0.6508, precision: 0.8509, recall: 0.6961, f1: 0.7657, edges-ner-ontonotes_loss: 0.0649
09/16 10:51:05 AM: Update 39861: task edges-ner-ontonotes, batch 861 (39861): mcc: 0.7597, acc: 0.6534, precision: 0.8523, recall: 0.6984, f1: 0.7677, edges-ner-ontonotes_loss: 0.0645
09/16 10:51:15 AM: Update 39984: task edges-ner-ontonotes, batch 984 (39984): mcc: 0.7621, acc: 0.6564, precision: 0.8538, recall: 0.7015, f1: 0.7702, edges-ner-ontonotes_loss: 0.0640
09/16 10:51:16 AM: ***** Step 40000 / Validation 40 *****
09/16 10:51:16 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:51:16 AM: Validating...
09/16 10:51:25 AM: Evaluate: task edges-ner-ontonotes, batch 75 (157): mcc: 0.7978, acc: 0.7040, precision: 0.8901, recall: 0.7331, f1: 0.8040, edges-ner-ontonotes_loss: 0.0598
09/16 10:51:35 AM: Evaluate: task edges-ner-ontonotes, batch 152 (157): mcc: 0.8226, acc: 0.7346, precision: 0.9090, recall: 0.7604, f1: 0.8281, edges-ner-ontonotes_loss: 0.0516
09/16 10:51:36 AM: Updating LR scheduler:
09/16 10:51:36 AM: 	Best result seen so far for macro_avg: 0.830
09/16 10:51:36 AM: 	# validation passes without improvement: 2
09/16 10:51:36 AM: edges-ner-ontonotes_loss: training: 0.063922 validation: 0.051429
09/16 10:51:36 AM: macro_avg: validation: 0.828019
09/16 10:51:36 AM: micro_avg: validation: 0.000000
09/16 10:51:36 AM: edges-ner-ontonotes_mcc: training: 0.762176 validation: 0.822508
09/16 10:51:36 AM: edges-ner-ontonotes_acc: training: 0.656529 validation: 0.734304
09/16 10:51:36 AM: edges-ner-ontonotes_precision: training: 0.853786 validation: 0.909289
09/16 10:51:36 AM: edges-ner-ontonotes_recall: training: 0.701594 validation: 0.760085
09/16 10:51:36 AM: edges-ner-ontonotes_f1: training: 0.770244 validation: 0.828019
09/16 10:51:36 AM: Global learning rate: 2.5e-05
09/16 10:51:36 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:51:45 AM: Update 40112: task edges-ner-ontonotes, batch 112 (40112): mcc: 0.7713, acc: 0.6688, precision: 0.8562, recall: 0.7157, f1: 0.7796, edges-ner-ontonotes_loss: 0.0608
09/16 10:51:55 AM: Update 40205: task edges-ner-ontonotes, batch 205 (40205): mcc: 0.7482, acc: 0.6417, precision: 0.8395, recall: 0.6893, f1: 0.7570, edges-ner-ontonotes_loss: 0.0668
09/16 10:52:05 AM: Update 40326: task edges-ner-ontonotes, batch 326 (40326): mcc: 0.7338, acc: 0.6230, precision: 0.8300, recall: 0.6720, f1: 0.7427, edges-ner-ontonotes_loss: 0.0716
09/16 10:52:15 AM: Update 40451: task edges-ner-ontonotes, batch 451 (40451): mcc: 0.7252, acc: 0.6117, precision: 0.8258, recall: 0.6606, f1: 0.7341, edges-ner-ontonotes_loss: 0.0745
09/16 10:52:25 AM: Update 40560: task edges-ner-ontonotes, batch 560 (40560): mcc: 0.7272, acc: 0.6137, precision: 0.8278, recall: 0.6625, f1: 0.7360, edges-ner-ontonotes_loss: 0.0739
09/16 10:52:35 AM: Update 40700: task edges-ner-ontonotes, batch 700 (40700): mcc: 0.7288, acc: 0.6150, precision: 0.8297, recall: 0.6636, f1: 0.7374, edges-ner-ontonotes_loss: 0.0731
09/16 10:52:45 AM: Update 40808: task edges-ner-ontonotes, batch 808 (40808): mcc: 0.7308, acc: 0.6176, precision: 0.8315, recall: 0.6656, f1: 0.7393, edges-ner-ontonotes_loss: 0.0722
09/16 10:52:55 AM: Update 40931: task edges-ner-ontonotes, batch 931 (40931): mcc: 0.7336, acc: 0.6214, precision: 0.8340, recall: 0.6685, f1: 0.7421, edges-ner-ontonotes_loss: 0.0715
09/16 10:53:01 AM: ***** Step 41000 / Validation 41 *****
09/16 10:53:01 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:53:01 AM: Validating...
09/16 10:53:05 AM: Evaluate: task edges-ner-ontonotes, batch 44 (157): mcc: 0.7988, acc: 0.7082, precision: 0.8850, recall: 0.7392, f1: 0.8055, edges-ner-ontonotes_loss: 0.0569
09/16 10:53:15 AM: Evaluate: task edges-ner-ontonotes, batch 119 (157): mcc: 0.8217, acc: 0.7319, precision: 0.9132, recall: 0.7553, f1: 0.8268, edges-ner-ontonotes_loss: 0.0511
09/16 10:53:20 AM: Updating LR scheduler:
09/16 10:53:20 AM: 	Best result seen so far for macro_avg: 0.830
09/16 10:53:20 AM: 	# validation passes without improvement: 3
09/16 10:53:20 AM: edges-ner-ontonotes_loss: training: 0.071215 validation: 0.049849
09/16 10:53:20 AM: macro_avg: validation: 0.827578
09/16 10:53:20 AM: micro_avg: validation: 0.000000
09/16 10:53:20 AM: edges-ner-ontonotes_mcc: training: 0.735355 validation: 0.822686
09/16 10:53:20 AM: edges-ner-ontonotes_acc: training: 0.623315 validation: 0.732636
09/16 10:53:20 AM: edges-ner-ontonotes_precision: training: 0.835206 validation: 0.915586
09/16 10:53:20 AM: edges-ner-ontonotes_recall: training: 0.670427 validation: 0.755005
09/16 10:53:20 AM: edges-ner-ontonotes_f1: training: 0.743800 validation: 0.827578
09/16 10:53:20 AM: Global learning rate: 2.5e-05
09/16 10:53:20 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:53:25 AM: Update 41070: task edges-ner-ontonotes, batch 70 (41070): mcc: 0.7492, acc: 0.6415, precision: 0.8484, recall: 0.6834, f1: 0.7570, edges-ner-ontonotes_loss: 0.0667
09/16 10:53:36 AM: Update 41166: task edges-ner-ontonotes, batch 166 (41166): mcc: 0.7635, acc: 0.6571, precision: 0.8583, recall: 0.7001, f1: 0.7711, edges-ner-ontonotes_loss: 0.0634
09/16 10:53:46 AM: Update 41285: task edges-ner-ontonotes, batch 285 (41285): mcc: 0.7735, acc: 0.6689, precision: 0.8633, recall: 0.7133, f1: 0.7812, edges-ner-ontonotes_loss: 0.0610
09/16 10:53:56 AM: Update 41396: task edges-ner-ontonotes, batch 396 (41396): mcc: 0.7757, acc: 0.6727, precision: 0.8632, recall: 0.7173, f1: 0.7835, edges-ner-ontonotes_loss: 0.0608
09/16 10:54:06 AM: Update 41514: task edges-ner-ontonotes, batch 514 (41514): mcc: 0.7744, acc: 0.6714, precision: 0.8621, recall: 0.7160, f1: 0.7823, edges-ner-ontonotes_loss: 0.0609
09/16 10:54:16 AM: Update 41635: task edges-ner-ontonotes, batch 635 (41635): mcc: 0.7737, acc: 0.6706, precision: 0.8606, recall: 0.7159, f1: 0.7816, edges-ner-ontonotes_loss: 0.0609
09/16 10:54:26 AM: Update 41725: task edges-ner-ontonotes, batch 725 (41725): mcc: 0.7688, acc: 0.6644, precision: 0.8574, recall: 0.7102, f1: 0.7769, edges-ner-ontonotes_loss: 0.0617
09/16 10:54:36 AM: Update 41848: task edges-ner-ontonotes, batch 848 (41848): mcc: 0.7590, acc: 0.6523, precision: 0.8508, recall: 0.6985, f1: 0.7672, edges-ner-ontonotes_loss: 0.0646
09/16 10:54:47 AM: Update 41977: task edges-ner-ontonotes, batch 977 (41977): mcc: 0.7534, acc: 0.6455, precision: 0.8467, recall: 0.6923, f1: 0.7618, edges-ner-ontonotes_loss: 0.0667
09/16 10:54:48 AM: ***** Step 42000 / Validation 42 *****
09/16 10:54:48 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:54:48 AM: Validating...
09/16 10:54:57 AM: Evaluate: task edges-ner-ontonotes, batch 73 (157): mcc: 0.8126, acc: 0.7221, precision: 0.9029, recall: 0.7482, f1: 0.8183, edges-ner-ontonotes_loss: 0.0554
09/16 10:55:07 AM: Evaluate: task edges-ner-ontonotes, batch 151 (157): mcc: 0.8236, acc: 0.7331, precision: 0.9169, recall: 0.7554, f1: 0.8284, edges-ner-ontonotes_loss: 0.0505
09/16 10:55:07 AM: Updating LR scheduler:
09/16 10:55:07 AM: 	Best result seen so far for macro_avg: 0.830
09/16 10:55:07 AM: 	# validation passes without improvement: 0
09/16 10:55:07 AM: edges-ner-ontonotes_loss: training: 0.066984 validation: 0.050272
09/16 10:55:07 AM: macro_avg: validation: 0.827919
09/16 10:55:07 AM: micro_avg: validation: 0.000000
09/16 10:55:07 AM: edges-ner-ontonotes_mcc: training: 0.752781 validation: 0.823146
09/16 10:55:07 AM: edges-ner-ontonotes_acc: training: 0.644699 validation: 0.732257
09/16 10:55:07 AM: edges-ner-ontonotes_precision: training: 0.846356 validation: 0.916981
09/16 10:55:07 AM: edges-ner-ontonotes_recall: training: 0.691450 validation: 0.754625
09/16 10:55:07 AM: edges-ner-ontonotes_f1: training: 0.761101 validation: 0.827919
09/16 10:55:07 AM: Global learning rate: 1.25e-05
09/16 10:55:07 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:55:17 AM: Update 42102: task edges-ner-ontonotes, batch 102 (42102): mcc: 0.7374, acc: 0.6242, precision: 0.8394, recall: 0.6704, f1: 0.7454, edges-ner-ontonotes_loss: 0.0714
09/16 10:55:27 AM: Update 42244: task edges-ner-ontonotes, batch 244 (42244): mcc: 0.7358, acc: 0.6219, precision: 0.8370, recall: 0.6696, f1: 0.7440, edges-ner-ontonotes_loss: 0.0708
09/16 10:55:37 AM: Update 42356: task edges-ner-ontonotes, batch 356 (42356): mcc: 0.7398, acc: 0.6266, precision: 0.8411, recall: 0.6732, f1: 0.7479, edges-ner-ontonotes_loss: 0.0696
09/16 10:55:47 AM: Update 42481: task edges-ner-ontonotes, batch 481 (42481): mcc: 0.7435, acc: 0.6315, precision: 0.8432, recall: 0.6779, f1: 0.7516, edges-ner-ontonotes_loss: 0.0690
09/16 10:55:57 AM: Update 42600: task edges-ner-ontonotes, batch 600 (42600): mcc: 0.7449, acc: 0.6347, precision: 0.8431, recall: 0.6805, f1: 0.7531, edges-ner-ontonotes_loss: 0.0688
09/16 10:56:07 AM: Update 42704: task edges-ner-ontonotes, batch 704 (42704): mcc: 0.7479, acc: 0.6381, precision: 0.8447, recall: 0.6843, f1: 0.7561, edges-ner-ontonotes_loss: 0.0678
09/16 10:56:17 AM: Update 42824: task edges-ner-ontonotes, batch 824 (42824): mcc: 0.7525, acc: 0.6437, precision: 0.8476, recall: 0.6899, f1: 0.7606, edges-ner-ontonotes_loss: 0.0666
09/16 10:56:27 AM: Update 42940: task edges-ner-ontonotes, batch 940 (42940): mcc: 0.7573, acc: 0.6495, precision: 0.8508, recall: 0.6955, f1: 0.7653, edges-ner-ontonotes_loss: 0.0654
09/16 10:56:35 AM: ***** Step 43000 / Validation 43 *****
09/16 10:56:35 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:56:35 AM: Validating...
09/16 10:56:37 AM: Evaluate: task edges-ner-ontonotes, batch 22 (157): mcc: 0.7422, acc: 0.6385, precision: 0.8477, recall: 0.6719, f1: 0.7496, edges-ner-ontonotes_loss: 0.0686
09/16 10:56:47 AM: Evaluate: task edges-ner-ontonotes, batch 107 (157): mcc: 0.8158, acc: 0.7281, precision: 0.9054, recall: 0.7515, f1: 0.8213, edges-ner-ontonotes_loss: 0.0552
09/16 10:56:54 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:56:54 AM: Best result seen so far for macro.
09/16 10:56:54 AM: Updating LR scheduler:
09/16 10:56:54 AM: 	Best result seen so far for macro_avg: 0.830
09/16 10:56:54 AM: 	# validation passes without improvement: 0
09/16 10:56:54 AM: edges-ner-ontonotes_loss: training: 0.065109 validation: 0.051184
09/16 10:56:54 AM: macro_avg: validation: 0.830379
09/16 10:56:54 AM: micro_avg: validation: 0.000000
09/16 10:56:54 AM: edges-ner-ontonotes_mcc: training: 0.757435 validation: 0.825276
09/16 10:56:54 AM: edges-ner-ontonotes_acc: training: 0.650093 validation: 0.737792
09/16 10:56:54 AM: edges-ner-ontonotes_precision: training: 0.850581 validation: 0.914781
09/16 10:56:54 AM: edges-ner-ontonotes_recall: training: 0.696010 validation: 0.760237
09/16 10:56:54 AM: edges-ner-ontonotes_f1: training: 0.765571 validation: 0.830379
09/16 10:56:54 AM: Global learning rate: 1.25e-05
09/16 10:56:54 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:56:57 AM: Update 43040: task edges-ner-ontonotes, batch 40 (43040): mcc: 0.7646, acc: 0.6536, precision: 0.8566, recall: 0.7034, f1: 0.7725, edges-ner-ontonotes_loss: 0.0616
09/16 10:57:07 AM: Update 43162: task edges-ner-ontonotes, batch 162 (43162): mcc: 0.7676, acc: 0.6610, precision: 0.8549, recall: 0.7102, f1: 0.7759, edges-ner-ontonotes_loss: 0.0618
09/16 10:57:18 AM: Update 43265: task edges-ner-ontonotes, batch 265 (43265): mcc: 0.7696, acc: 0.6646, precision: 0.8558, recall: 0.7129, f1: 0.7779, edges-ner-ontonotes_loss: 0.0614
09/16 10:57:28 AM: Update 43381: task edges-ner-ontonotes, batch 381 (43381): mcc: 0.7479, acc: 0.6377, precision: 0.8419, recall: 0.6866, f1: 0.7564, edges-ner-ontonotes_loss: 0.0674
09/16 10:57:38 AM: Update 43508: task edges-ner-ontonotes, batch 508 (43508): mcc: 0.7414, acc: 0.6298, precision: 0.8389, recall: 0.6779, f1: 0.7499, edges-ner-ontonotes_loss: 0.0701
09/16 10:57:48 AM: Update 43610: task edges-ner-ontonotes, batch 610 (43610): mcc: 0.7368, acc: 0.6246, precision: 0.8353, recall: 0.6728, f1: 0.7453, edges-ner-ontonotes_loss: 0.0713
09/16 10:57:58 AM: Update 43750: task edges-ner-ontonotes, batch 750 (43750): mcc: 0.7364, acc: 0.6242, precision: 0.8353, recall: 0.6723, f1: 0.7450, edges-ner-ontonotes_loss: 0.0711
09/16 10:58:09 AM: Update 43882: task edges-ner-ontonotes, batch 882 (43882): mcc: 0.7374, acc: 0.6250, precision: 0.8367, recall: 0.6728, f1: 0.7458, edges-ner-ontonotes_loss: 0.0709
09/16 10:58:19 AM: ***** Step 44000 / Validation 44 *****
09/16 10:58:19 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:58:19 AM: Validating...
09/16 10:58:19 AM: Evaluate: task edges-ner-ontonotes, batch 2 (157): mcc: 0.7010, acc: 0.5846, precision: 0.8404, recall: 0.6077, f1: 0.7054, edges-ner-ontonotes_loss: 0.0773
09/16 10:58:29 AM: Evaluate: task edges-ner-ontonotes, batch 91 (157): mcc: 0.8230, acc: 0.7345, precision: 0.9137, recall: 0.7571, f1: 0.8281, edges-ner-ontonotes_loss: 0.0525
09/16 10:58:38 AM: Updating LR scheduler:
09/16 10:58:38 AM: 	Best result seen so far for macro_avg: 0.830
09/16 10:58:38 AM: 	# validation passes without improvement: 1
09/16 10:58:38 AM: edges-ner-ontonotes_loss: training: 0.070395 validation: 0.049640
09/16 10:58:38 AM: macro_avg: validation: 0.829165
09/16 10:58:38 AM: micro_avg: validation: 0.000000
09/16 10:58:38 AM: edges-ner-ontonotes_mcc: training: 0.738988 validation: 0.824520
09/16 10:58:38 AM: edges-ner-ontonotes_acc: training: 0.627057 validation: 0.734683
09/16 10:58:38 AM: edges-ner-ontonotes_precision: training: 0.837856 validation: 0.918919
09/16 10:58:38 AM: edges-ner-ontonotes_recall: training: 0.674531 validation: 0.755384
09/16 10:58:38 AM: edges-ner-ontonotes_f1: training: 0.747374 validation: 0.829165
09/16 10:58:38 AM: Global learning rate: 1.25e-05
09/16 10:58:38 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:58:39 AM: Update 44015: task edges-ner-ontonotes, batch 15 (44015): mcc: 0.7673, acc: 0.6584, precision: 0.8474, recall: 0.7163, f1: 0.7763, edges-ner-ontonotes_loss: 0.0611
09/16 10:58:49 AM: Update 44138: task edges-ner-ontonotes, batch 138 (44138): mcc: 0.7523, acc: 0.6463, precision: 0.8475, recall: 0.6896, f1: 0.7605, edges-ner-ontonotes_loss: 0.0655
09/16 10:58:59 AM: Update 44234: task edges-ner-ontonotes, batch 234 (44234): mcc: 0.7539, acc: 0.6473, precision: 0.8493, recall: 0.6909, f1: 0.7620, edges-ner-ontonotes_loss: 0.0654
09/16 10:59:09 AM: Update 44354: task edges-ner-ontonotes, batch 354 (44354): mcc: 0.7627, acc: 0.6581, precision: 0.8535, recall: 0.7028, f1: 0.7708, edges-ner-ontonotes_loss: 0.0633
09/16 10:59:19 AM: Update 44474: task edges-ner-ontonotes, batch 474 (44474): mcc: 0.7685, acc: 0.6659, precision: 0.8566, recall: 0.7103, f1: 0.7767, edges-ner-ontonotes_loss: 0.0620
09/16 10:59:29 AM: Update 44574: task edges-ner-ontonotes, batch 574 (44574): mcc: 0.7679, acc: 0.6653, precision: 0.8562, recall: 0.7096, f1: 0.7761, edges-ner-ontonotes_loss: 0.0619
09/16 10:59:39 AM: Update 44693: task edges-ner-ontonotes, batch 693 (44693): mcc: 0.7690, acc: 0.6666, precision: 0.8568, recall: 0.7111, f1: 0.7771, edges-ner-ontonotes_loss: 0.0616
09/16 10:59:49 AM: Update 44811: task edges-ner-ontonotes, batch 811 (44811): mcc: 0.7693, acc: 0.6665, precision: 0.8571, recall: 0.7113, f1: 0.7774, edges-ner-ontonotes_loss: 0.0614
09/16 10:59:59 AM: Update 44900: task edges-ner-ontonotes, batch 900 (44900): mcc: 0.7616, acc: 0.6567, precision: 0.8522, recall: 0.7019, f1: 0.7698, edges-ner-ontonotes_loss: 0.0633
09/16 11:00:08 AM: ***** Step 45000 / Validation 45 *****
09/16 11:00:08 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 11:00:08 AM: Validating...
09/16 11:00:09 AM: Evaluate: task edges-ner-ontonotes, batch 18 (157): mcc: 0.7607, acc: 0.6610, precision: 0.8605, recall: 0.6933, f1: 0.7679, edges-ner-ontonotes_loss: 0.0620
09/16 11:00:20 AM: Evaluate: task edges-ner-ontonotes, batch 103 (157): mcc: 0.8219, acc: 0.7317, precision: 0.9130, recall: 0.7559, f1: 0.8270, edges-ner-ontonotes_loss: 0.0524
09/16 11:00:27 AM: Updating LR scheduler:
09/16 11:00:27 AM: 	Best result seen so far for macro_avg: 0.830
09/16 11:00:27 AM: 	# validation passes without improvement: 2
09/16 11:00:27 AM: edges-ner-ontonotes_loss: training: 0.065125 validation: 0.049957
09/16 11:00:27 AM: macro_avg: validation: 0.828899
09/16 11:00:27 AM: micro_avg: validation: 0.000000
09/16 11:00:27 AM: edges-ner-ontonotes_mcc: training: 0.756119 validation: 0.824116
09/16 11:00:27 AM: edges-ner-ontonotes_acc: training: 0.649855 validation: 0.733091
09/16 11:00:27 AM: edges-ner-ontonotes_precision: training: 0.848818 validation: 0.917372
09/16 11:00:27 AM: edges-ner-ontonotes_recall: training: 0.695206 validation: 0.755990
09/16 11:00:27 AM: edges-ner-ontonotes_f1: training: 0.764371 validation: 0.828899
09/16 11:00:27 AM: Global learning rate: 1.25e-05
09/16 11:00:27 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 11:00:30 AM: Update 45035: task edges-ner-ontonotes, batch 35 (45035): mcc: 0.7165, acc: 0.5953, precision: 0.8177, recall: 0.6524, f1: 0.7257, edges-ner-ontonotes_loss: 0.0794
09/16 11:00:40 AM: Update 45142: task edges-ner-ontonotes, batch 142 (45142): mcc: 0.7178, acc: 0.6024, precision: 0.8194, recall: 0.6531, f1: 0.7268, edges-ner-ontonotes_loss: 0.0787
09/16 11:00:50 AM: Update 45292: task edges-ner-ontonotes, batch 292 (45292): mcc: 0.7292, acc: 0.6148, precision: 0.8293, recall: 0.6646, f1: 0.7379, edges-ner-ontonotes_loss: 0.0738
09/16 11:01:00 AM: Update 45429: task edges-ner-ontonotes, batch 429 (45429): mcc: 0.7325, acc: 0.6185, precision: 0.8332, recall: 0.6671, f1: 0.7409, edges-ner-ontonotes_loss: 0.0723
09/16 11:01:10 AM: Update 45523: task edges-ner-ontonotes, batch 523 (45523): mcc: 0.7336, acc: 0.6198, precision: 0.8344, recall: 0.6682, f1: 0.7421, edges-ner-ontonotes_loss: 0.0718
09/16 11:01:20 AM: Update 45646: task edges-ner-ontonotes, batch 646 (45646): mcc: 0.7377, acc: 0.6255, precision: 0.8372, recall: 0.6728, f1: 0.7460, edges-ner-ontonotes_loss: 0.0707
09/16 11:01:30 AM: Update 45751: task edges-ner-ontonotes, batch 751 (45751): mcc: 0.7412, acc: 0.6302, precision: 0.8399, recall: 0.6767, f1: 0.7495, edges-ner-ontonotes_loss: 0.0700
09/16 11:01:40 AM: Update 45867: task edges-ner-ontonotes, batch 867 (45867): mcc: 0.7471, acc: 0.6377, precision: 0.8438, recall: 0.6837, f1: 0.7554, edges-ner-ontonotes_loss: 0.0686
09/16 11:01:50 AM: Update 45984: task edges-ner-ontonotes, batch 984 (45984): mcc: 0.7517, acc: 0.6434, precision: 0.8464, recall: 0.6896, f1: 0.7600, edges-ner-ontonotes_loss: 0.0673
09/16 11:01:52 AM: ***** Step 46000 / Validation 46 *****
09/16 11:01:52 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 11:01:52 AM: Validating...
09/16 11:02:01 AM: Evaluate: task edges-ner-ontonotes, batch 76 (157): mcc: 0.8021, acc: 0.7098, precision: 0.8979, recall: 0.7340, f1: 0.8077, edges-ner-ontonotes_loss: 0.0591
09/16 11:02:11 AM: Evaluate: task edges-ner-ontonotes, batch 153 (157): mcc: 0.8246, acc: 0.7361, precision: 0.9155, recall: 0.7584, f1: 0.8296, edges-ner-ontonotes_loss: 0.0514
09/16 11:02:11 AM: Updating LR scheduler:
09/16 11:02:11 AM: 	Best result seen so far for macro_avg: 0.830
09/16 11:02:11 AM: 	# validation passes without improvement: 3
09/16 11:02:11 AM: edges-ner-ontonotes_loss: training: 0.067245 validation: 0.051282
09/16 11:02:11 AM: macro_avg: validation: 0.829108
09/16 11:02:11 AM: micro_avg: validation: 0.000000
09/16 11:02:11 AM: edges-ner-ontonotes_mcc: training: 0.752134 validation: 0.824127
09/16 11:02:11 AM: edges-ner-ontonotes_acc: training: 0.643822 validation: 0.735441
09/16 11:02:11 AM: edges-ner-ontonotes_precision: training: 0.846931 validation: 0.915437
09/16 11:02:11 AM: edges-ner-ontonotes_recall: training: 0.689825 validation: 0.757658
09/16 11:02:11 AM: edges-ner-ontonotes_f1: training: 0.760347 validation: 0.829108
09/16 11:02:11 AM: Global learning rate: 1.25e-05
09/16 11:02:11 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 11:02:21 AM: Update 46089: task edges-ner-ontonotes, batch 89 (46089): mcc: 0.7831, acc: 0.6834, precision: 0.8642, recall: 0.7295, f1: 0.7911, edges-ner-ontonotes_loss: 0.0580
09/16 11:02:31 AM: Update 46207: task edges-ner-ontonotes, batch 207 (46207): mcc: 0.7768, acc: 0.6759, precision: 0.8636, recall: 0.7189, f1: 0.7846, edges-ner-ontonotes_loss: 0.0599
09/16 11:02:41 AM: Update 46329: task edges-ner-ontonotes, batch 329 (46329): mcc: 0.7776, acc: 0.6763, precision: 0.8638, recall: 0.7202, f1: 0.7855, edges-ner-ontonotes_loss: 0.0600
09/16 11:02:51 AM: Update 46427: task edges-ner-ontonotes, batch 427 (46427): mcc: 0.7631, acc: 0.6578, precision: 0.8531, recall: 0.7039, f1: 0.7713, edges-ner-ontonotes_loss: 0.0632
09/16 11:03:01 AM: Update 46550: task edges-ner-ontonotes, batch 550 (46550): mcc: 0.7527, acc: 0.6445, precision: 0.8467, recall: 0.6910, f1: 0.7610, edges-ner-ontonotes_loss: 0.0667
09/16 11:03:11 AM: Update 46680: task edges-ner-ontonotes, batch 680 (46680): mcc: 0.7450, acc: 0.6351, precision: 0.8421, recall: 0.6815, f1: 0.7533, edges-ner-ontonotes_loss: 0.0696
09/16 11:03:21 AM: Update 46800: task edges-ner-ontonotes, batch 800 (46800): mcc: 0.7441, acc: 0.6337, precision: 0.8418, recall: 0.6802, f1: 0.7524, edges-ner-ontonotes_loss: 0.0696
09/16 11:03:31 AM: Update 46947: task edges-ner-ontonotes, batch 947 (46947): mcc: 0.7439, acc: 0.6328, precision: 0.8419, recall: 0.6797, f1: 0.7521, edges-ner-ontonotes_loss: 0.0696
09/16 11:03:37 AM: ***** Step 47000 / Validation 47 *****
09/16 11:03:37 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 11:03:37 AM: Validating...
09/16 11:03:41 AM: Evaluate: task edges-ner-ontonotes, batch 40 (157): mcc: 0.8019, acc: 0.7074, precision: 0.8909, recall: 0.7396, f1: 0.8082, edges-ner-ontonotes_loss: 0.0561
09/16 11:03:51 AM: Evaluate: task edges-ner-ontonotes, batch 115 (157): mcc: 0.8215, acc: 0.7285, precision: 0.9178, recall: 0.7511, f1: 0.8261, edges-ner-ontonotes_loss: 0.0512
09/16 11:03:56 AM: Updating LR scheduler:
09/16 11:03:56 AM: 	Best result seen so far for macro_avg: 0.830
09/16 11:03:56 AM: 	# validation passes without improvement: 0
09/16 11:03:56 AM: edges-ner-ontonotes_loss: training: 0.069607 validation: 0.050033
09/16 11:03:56 AM: macro_avg: validation: 0.825024
09/16 11:03:56 AM: micro_avg: validation: 0.000000
09/16 11:03:56 AM: edges-ner-ontonotes_mcc: training: 0.743006 validation: 0.820606
09/16 11:03:56 AM: edges-ner-ontonotes_acc: training: 0.631873 validation: 0.726418
09/16 11:03:56 AM: edges-ner-ontonotes_precision: training: 0.841411 validation: 0.919002
09/16 11:03:56 AM: edges-ner-ontonotes_recall: training: 0.678543 validation: 0.748483
09/16 11:03:56 AM: edges-ner-ontonotes_f1: training: 0.751251 validation: 0.825024
09/16 11:03:56 AM: Global learning rate: 6.25e-06
09/16 11:03:56 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 11:04:01 AM: Update 47063: task edges-ner-ontonotes, batch 63 (47063): mcc: 0.7611, acc: 0.6567, precision: 0.8540, recall: 0.6995, f1: 0.7691, edges-ner-ontonotes_loss: 0.0641
09/16 11:04:11 AM: Update 47185: task edges-ner-ontonotes, batch 185 (47185): mcc: 0.7528, acc: 0.6468, precision: 0.8488, recall: 0.6895, f1: 0.7609, edges-ner-ontonotes_loss: 0.0661
09/16 11:04:24 AM: Update 47307: task edges-ner-ontonotes, batch 307 (47307): mcc: 0.7522, acc: 0.6462, precision: 0.8467, recall: 0.6901, f1: 0.7604, edges-ner-ontonotes_loss: 0.0662
09/16 11:04:34 AM: Update 47428: task edges-ner-ontonotes, batch 428 (47428): mcc: 0.7592, acc: 0.6535, precision: 0.8515, recall: 0.6984, f1: 0.7674, edges-ner-ontonotes_loss: 0.0644
09/16 11:04:44 AM: Update 47544: task edges-ner-ontonotes, batch 544 (47544): mcc: 0.7636, acc: 0.6591, precision: 0.8533, recall: 0.7046, f1: 0.7718, edges-ner-ontonotes_loss: 0.0633
09/16 11:04:54 AM: Update 47645: task edges-ner-ontonotes, batch 645 (47645): mcc: 0.7654, acc: 0.6615, precision: 0.8543, recall: 0.7068, f1: 0.7736, edges-ner-ontonotes_loss: 0.0627
09/16 11:05:04 AM: Update 47762: task edges-ner-ontonotes, batch 762 (47762): mcc: 0.7669, acc: 0.6632, precision: 0.8550, recall: 0.7088, f1: 0.7751, edges-ner-ontonotes_loss: 0.0624
09/16 11:05:14 AM: Update 47884: task edges-ner-ontonotes, batch 884 (47884): mcc: 0.7676, acc: 0.6640, precision: 0.8556, recall: 0.7097, f1: 0.7758, edges-ner-ontonotes_loss: 0.0620
09/16 11:05:24 AM: Update 47980: task edges-ner-ontonotes, batch 980 (47980): mcc: 0.7641, acc: 0.6596, precision: 0.8531, recall: 0.7056, f1: 0.7724, edges-ner-ontonotes_loss: 0.0631
09/16 11:05:26 AM: ***** Step 48000 / Validation 48 *****
09/16 11:05:26 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 11:05:26 AM: Validating...
09/16 11:05:34 AM: Evaluate: task edges-ner-ontonotes, batch 72 (157): mcc: 0.8064, acc: 0.7129, precision: 0.9028, recall: 0.7375, f1: 0.8118, edges-ner-ontonotes_loss: 0.0567
09/16 11:05:44 AM: Evaluate: task edges-ner-ontonotes, batch 149 (157): mcc: 0.8265, acc: 0.7369, precision: 0.9186, recall: 0.7591, f1: 0.8312, edges-ner-ontonotes_loss: 0.0502
09/16 11:05:45 AM: Best result seen so far for edges-ner-ontonotes.
09/16 11:05:45 AM: Best result seen so far for macro.
09/16 11:05:45 AM: Updating LR scheduler:
09/16 11:05:45 AM: 	Best result seen so far for macro_avg: 0.831
09/16 11:05:45 AM: 	# validation passes without improvement: 0
09/16 11:05:45 AM: edges-ner-ontonotes_loss: training: 0.063317 validation: 0.049924
09/16 11:05:45 AM: macro_avg: validation: 0.830827
09/16 11:05:45 AM: micro_avg: validation: 0.000000
09/16 11:05:45 AM: edges-ner-ontonotes_mcc: training: 0.762715 validation: 0.826093
09/16 11:05:45 AM: edges-ner-ontonotes_acc: training: 0.657893 validation: 0.735972
09/16 11:05:45 AM: edges-ner-ontonotes_precision: training: 0.852332 validation: 0.918857
09/16 11:05:45 AM: edges-ner-ontonotes_recall: training: 0.703789 validation: 0.758189
09/16 11:05:45 AM: edges-ner-ontonotes_f1: training: 0.770971 validation: 0.830827
09/16 11:05:45 AM: Global learning rate: 6.25e-06
09/16 11:05:45 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 11:05:54 AM: Update 48114: task edges-ner-ontonotes, batch 114 (48114): mcc: 0.7006, acc: 0.5812, precision: 0.8128, recall: 0.6288, f1: 0.7091, edges-ner-ontonotes_loss: 0.0827
09/16 11:06:07 AM: Update 48237: task edges-ner-ontonotes, batch 237 (48237): mcc: 0.7046, acc: 0.5865, precision: 0.8114, recall: 0.6370, f1: 0.7137, edges-ner-ontonotes_loss: 0.0812
09/16 11:06:17 AM: Update 48375: task edges-ner-ontonotes, batch 375 (48375): mcc: 0.7163, acc: 0.5995, precision: 0.8204, recall: 0.6498, f1: 0.7252, edges-ner-ontonotes_loss: 0.0769
09/16 11:06:27 AM: Update 48523: task edges-ner-ontonotes, batch 523 (48523): mcc: 0.7238, acc: 0.6079, precision: 0.8259, recall: 0.6580, f1: 0.7325, edges-ner-ontonotes_loss: 0.0745
09/16 11:06:37 AM: Update 48618: task edges-ner-ontonotes, batch 618 (48618): mcc: 0.7266, acc: 0.6114, precision: 0.8285, recall: 0.6608, f1: 0.7352, edges-ner-ontonotes_loss: 0.0735
09/16 11:06:47 AM: Update 48744: task edges-ner-ontonotes, batch 744 (48744): mcc: 0.7319, acc: 0.6182, precision: 0.8328, recall: 0.6665, f1: 0.7404, edges-ner-ontonotes_loss: 0.0723
09/16 11:06:59 AM: Update 48863: task edges-ner-ontonotes, batch 863 (48863): mcc: 0.7336, acc: 0.6205, precision: 0.8335, recall: 0.6689, f1: 0.7422, edges-ner-ontonotes_loss: 0.0717
09/16 11:07:09 AM: Update 48980: task edges-ner-ontonotes, batch 980 (48980): mcc: 0.7394, acc: 0.6274, precision: 0.8380, recall: 0.6750, f1: 0.7478, edges-ner-ontonotes_loss: 0.0703
09/16 11:07:10 AM: ***** Step 49000 / Validation 49 *****
09/16 11:07:10 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 11:07:10 AM: Validating...
09/16 11:07:19 AM: Evaluate: task edges-ner-ontonotes, batch 73 (157): mcc: 0.8038, acc: 0.7141, precision: 0.8943, recall: 0.7400, f1: 0.8099, edges-ner-ontonotes_loss: 0.0583
09/16 11:07:29 AM: Evaluate: task edges-ner-ontonotes, batch 150 (157): mcc: 0.8280, acc: 0.7421, precision: 0.9143, recall: 0.7654, f1: 0.8333, edges-ner-ontonotes_loss: 0.0507
09/16 11:07:30 AM: Best result seen so far for edges-ner-ontonotes.
09/16 11:07:30 AM: Best result seen so far for macro.
09/16 11:07:30 AM: Updating LR scheduler:
09/16 11:07:30 AM: 	Best result seen so far for macro_avg: 0.833
09/16 11:07:30 AM: 	# validation passes without improvement: 0
09/16 11:07:30 AM: edges-ner-ontonotes_loss: training: 0.070061 validation: 0.050368
09/16 11:07:30 AM: macro_avg: validation: 0.833106
09/16 11:07:30 AM: micro_avg: validation: 0.000000
09/16 11:07:30 AM: edges-ner-ontonotes_mcc: training: 0.740632 validation: 0.827886
09/16 11:07:30 AM: edges-ner-ontonotes_acc: training: 0.629007 validation: 0.741735
09/16 11:07:30 AM: edges-ner-ontonotes_precision: training: 0.838920 validation: 0.914830
09/16 11:07:30 AM: edges-ner-ontonotes_recall: training: 0.676500 validation: 0.764786
09/16 11:07:30 AM: edges-ner-ontonotes_f1: training: 0.749006 validation: 0.833106
09/16 11:07:30 AM: Global learning rate: 6.25e-06
09/16 11:07:30 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 11:07:39 AM: Update 49110: task edges-ner-ontonotes, batch 110 (49110): mcc: 0.7881, acc: 0.6907, precision: 0.8658, recall: 0.7371, f1: 0.7963, edges-ner-ontonotes_loss: 0.0569
09/16 11:07:49 AM: Update 49202: task edges-ner-ontonotes, batch 202 (49202): mcc: 0.7823, acc: 0.6815, precision: 0.8637, recall: 0.7285, f1: 0.7903, edges-ner-ontonotes_loss: 0.0585
09/16 11:07:59 AM: Update 49321: task edges-ner-ontonotes, batch 321 (49321): mcc: 0.7753, acc: 0.6730, precision: 0.8594, recall: 0.7199, f1: 0.7835, edges-ner-ontonotes_loss: 0.0602
09/16 11:08:09 AM: Update 49441: task edges-ner-ontonotes, batch 441 (49441): mcc: 0.7759, acc: 0.6731, precision: 0.8605, recall: 0.7199, f1: 0.7840, edges-ner-ontonotes_loss: 0.0600
09/16 11:08:19 AM: Update 49548: task edges-ner-ontonotes, batch 548 (49548): mcc: 0.7656, acc: 0.6607, precision: 0.8529, recall: 0.7084, f1: 0.7740, edges-ner-ontonotes_loss: 0.0630
09/16 11:08:29 AM: Update 49669: task edges-ner-ontonotes, batch 669 (49669): mcc: 0.7548, acc: 0.6474, precision: 0.8462, recall: 0.6952, f1: 0.7633, edges-ner-ontonotes_loss: 0.0662
09/16 11:08:41 AM: Update 49793: task edges-ner-ontonotes, batch 793 (49793): mcc: 0.7494, acc: 0.6407, precision: 0.8432, recall: 0.6883, f1: 0.7579, edges-ner-ontonotes_loss: 0.0682
09/16 11:08:51 AM: Update 49942: task edges-ner-ontonotes, batch 942 (49942): mcc: 0.7490, acc: 0.6396, precision: 0.8432, recall: 0.6875, f1: 0.7574, edges-ner-ontonotes_loss: 0.0683
09/16 11:08:55 AM: ***** Step 50000 / Validation 50 *****
09/16 11:08:55 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 11:08:55 AM: Validating...
09/16 11:09:01 AM: Evaluate: task edges-ner-ontonotes, batch 55 (157): mcc: 0.8155, acc: 0.7250, precision: 0.9029, recall: 0.7532, f1: 0.8213, edges-ner-ontonotes_loss: 0.0537
09/16 11:09:11 AM: Evaluate: task edges-ner-ontonotes, batch 130 (157): mcc: 0.8227, acc: 0.7306, precision: 0.9190, recall: 0.7521, f1: 0.8272, edges-ner-ontonotes_loss: 0.0506
09/16 11:09:14 AM: Updating LR scheduler:
09/16 11:09:14 AM: 	Best result seen so far for macro_avg: 0.833
09/16 11:09:14 AM: 	# validation passes without improvement: 1
09/16 11:09:14 AM: edges-ner-ontonotes_loss: training: 0.068422 validation: 0.050000
09/16 11:09:14 AM: macro_avg: validation: 0.826129
09/16 11:09:14 AM: micro_avg: validation: 0.000000
09/16 11:09:14 AM: edges-ner-ontonotes_mcc: training: 0.748357 validation: 0.821491
09/16 11:09:14 AM: edges-ner-ontonotes_acc: training: 0.638689 validation: 0.728996
09/16 11:09:14 AM: edges-ner-ontonotes_precision: training: 0.843252 validation: 0.917415
09/16 11:09:14 AM: edges-ner-ontonotes_recall: training: 0.686338 validation: 0.751365
09/16 11:09:14 AM: edges-ner-ontonotes_f1: training: 0.756747 validation: 0.826129
09/16 11:09:14 AM: Global learning rate: 6.25e-06
09/16 11:09:14 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 11:09:21 AM: Update 50096: task edges-ner-ontonotes, batch 96 (50096): mcc: 0.7324, acc: 0.6145, precision: 0.8335, recall: 0.6666, f1: 0.7408, edges-ner-ontonotes_loss: 0.0708
09/16 11:09:31 AM: Update 50186: task edges-ner-ontonotes, batch 186 (50186): mcc: 0.7343, acc: 0.6187, precision: 0.8354, recall: 0.6684, f1: 0.7426, edges-ner-ontonotes_loss: 0.0695
09/16 11:09:41 AM: Update 50313: task edges-ner-ontonotes, batch 313 (50313): mcc: 0.7454, acc: 0.6336, precision: 0.8431, recall: 0.6812, f1: 0.7536, edges-ner-ontonotes_loss: 0.0677
09/16 11:09:51 AM: Update 50419: task edges-ner-ontonotes, batch 419 (50419): mcc: 0.7464, acc: 0.6357, precision: 0.8441, recall: 0.6822, f1: 0.7546, edges-ner-ontonotes_loss: 0.0675
09/16 11:10:01 AM: Update 50536: task edges-ner-ontonotes, batch 536 (50536): mcc: 0.7534, acc: 0.6443, precision: 0.8490, recall: 0.6903, f1: 0.7614, edges-ner-ontonotes_loss: 0.0657
09/16 11:10:11 AM: Update 50654: task edges-ner-ontonotes, batch 654 (50654): mcc: 0.7598, acc: 0.6528, precision: 0.8526, recall: 0.6985, f1: 0.7679, edges-ner-ontonotes_loss: 0.0644
09/16 11:10:21 AM: Update 50753: task edges-ner-ontonotes, batch 753 (50753): mcc: 0.7623, acc: 0.6559, precision: 0.8541, recall: 0.7015, f1: 0.7703, edges-ner-ontonotes_loss: 0.0638
09/16 11:10:31 AM: Update 50876: task edges-ner-ontonotes, batch 876 (50876): mcc: 0.7646, acc: 0.6589, precision: 0.8555, recall: 0.7044, f1: 0.7726, edges-ner-ontonotes_loss: 0.0631
09/16 11:10:41 AM: Update 50992: task edges-ner-ontonotes, batch 992 (50992): mcc: 0.7657, acc: 0.6602, precision: 0.8563, recall: 0.7057, f1: 0.7737, edges-ner-ontonotes_loss: 0.0629
09/16 11:10:42 AM: ***** Step 51000 / Validation 51 *****
09/16 11:10:42 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 11:10:42 AM: Validating...
09/16 11:10:51 AM: Evaluate: task edges-ner-ontonotes, batch 82 (157): mcc: 0.8094, acc: 0.7194, precision: 0.9005, recall: 0.7445, f1: 0.8151, edges-ner-ontonotes_loss: 0.0575
09/16 11:11:01 AM: Updating LR scheduler:
09/16 11:11:01 AM: 	Best result seen so far for macro_avg: 0.833
09/16 11:11:01 AM: 	# validation passes without improvement: 2
09/16 11:11:01 AM: edges-ner-ontonotes_loss: training: 0.062930 validation: 0.051221
09/16 11:11:01 AM: macro_avg: validation: 0.830172
09/16 11:11:01 AM: micro_avg: validation: 0.000000
09/16 11:11:01 AM: edges-ner-ontonotes_mcc: training: 0.765626 validation: 0.824856
09/16 11:11:01 AM: edges-ner-ontonotes_acc: training: 0.660159 validation: 0.737564
09/16 11:11:01 AM: edges-ner-ontonotes_precision: training: 0.856154 validation: 0.912419
09/16 11:11:01 AM: edges-ner-ontonotes_recall: training: 0.705631 validation: 0.761526
09/16 11:11:01 AM: edges-ner-ontonotes_f1: training: 0.773639 validation: 0.830172
09/16 11:11:01 AM: Global learning rate: 6.25e-06
09/16 11:11:01 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 11:11:01 AM: Update 51004: task edges-ner-ontonotes, batch 4 (51004): mcc: 0.7173, acc: 0.6046, precision: 0.8358, recall: 0.6388, f1: 0.7241, edges-ner-ontonotes_loss: 0.0757
09/16 11:11:11 AM: Update 51097: task edges-ner-ontonotes, batch 97 (51097): mcc: 0.7163, acc: 0.6007, precision: 0.8199, recall: 0.6502, f1: 0.7253, edges-ner-ontonotes_loss: 0.0749
09/16 11:11:21 AM: Update 51226: task edges-ner-ontonotes, batch 226 (51226): mcc: 0.7122, acc: 0.5969, precision: 0.8187, recall: 0.6440, f1: 0.7209, edges-ner-ontonotes_loss: 0.0782
09/16 11:11:31 AM: Update 51347: task edges-ner-ontonotes, batch 347 (51347): mcc: 0.7073, acc: 0.5907, precision: 0.8148, recall: 0.6387, f1: 0.7161, edges-ner-ontonotes_loss: 0.0791
09/16 11:11:41 AM: Update 51458: task edges-ner-ontonotes, batch 458 (51458): mcc: 0.7137, acc: 0.5978, precision: 0.8196, recall: 0.6459, f1: 0.7224, edges-ner-ontonotes_loss: 0.0771
09/16 11:11:51 AM: Update 51604: task edges-ner-ontonotes, batch 604 (51604): mcc: 0.7194, acc: 0.6041, precision: 0.8240, recall: 0.6521, f1: 0.7280, edges-ner-ontonotes_loss: 0.0753
09/16 11:12:01 AM: Update 51707: task edges-ner-ontonotes, batch 707 (51707): mcc: 0.7218, acc: 0.6065, precision: 0.8264, recall: 0.6542, f1: 0.7303, edges-ner-ontonotes_loss: 0.0746
09/16 11:12:11 AM: Update 51829: task edges-ner-ontonotes, batch 829 (51829): mcc: 0.7259, acc: 0.6117, precision: 0.8290, recall: 0.6592, f1: 0.7344, edges-ner-ontonotes_loss: 0.0735
09/16 11:12:21 AM: Update 51957: task edges-ner-ontonotes, batch 957 (51957): mcc: 0.7301, acc: 0.6172, precision: 0.8322, recall: 0.6639, f1: 0.7386, edges-ner-ontonotes_loss: 0.0724
09/16 11:12:27 AM: ***** Step 52000 / Validation 52 *****
09/16 11:12:27 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 11:12:27 AM: Validating...
09/16 11:12:32 AM: Evaluate: task edges-ner-ontonotes, batch 43 (157): mcc: 0.7997, acc: 0.7114, precision: 0.8845, recall: 0.7413, f1: 0.8066, edges-ner-ontonotes_loss: 0.0572
09/16 11:12:42 AM: Evaluate: task edges-ner-ontonotes, batch 118 (157): mcc: 0.8240, acc: 0.7360, precision: 0.9135, recall: 0.7591, f1: 0.8292, edges-ner-ontonotes_loss: 0.0511
09/16 11:12:46 AM: Updating LR scheduler:
09/16 11:12:46 AM: 	Best result seen so far for macro_avg: 0.833
09/16 11:12:46 AM: 	# validation passes without improvement: 3
09/16 11:12:46 AM: edges-ner-ontonotes_loss: training: 0.071986 validation: 0.049519
09/16 11:12:46 AM: macro_avg: validation: 0.830846
09/16 11:12:46 AM: micro_avg: validation: 0.000000
09/16 11:12:46 AM: edges-ner-ontonotes_mcc: training: 0.731433 validation: 0.825891
09/16 11:12:46 AM: edges-ner-ontonotes_acc: training: 0.618688 validation: 0.737413
09/16 11:12:46 AM: edges-ner-ontonotes_precision: training: 0.833317 validation: 0.916575
09/16 11:12:46 AM: edges-ner-ontonotes_recall: training: 0.665186 validation: 0.759782
09/16 11:12:46 AM: edges-ner-ontonotes_f1: training: 0.739820 validation: 0.830846
09/16 11:12:46 AM: Global learning rate: 6.25e-06
09/16 11:12:46 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 11:12:52 AM: Update 52062: task edges-ner-ontonotes, batch 62 (52062): mcc: 0.7802, acc: 0.6780, precision: 0.8702, recall: 0.7192, f1: 0.7875, edges-ner-ontonotes_loss: 0.0585
09/16 11:13:02 AM: Update 52182: task edges-ner-ontonotes, batch 182 (52182): mcc: 0.7848, acc: 0.6843, precision: 0.8687, recall: 0.7286, f1: 0.7925, edges-ner-ontonotes_loss: 0.0577
09/16 11:13:12 AM: Update 52288: task edges-ner-ontonotes, batch 288 (52288): mcc: 0.7805, acc: 0.6802, precision: 0.8634, recall: 0.7257, f1: 0.7886, edges-ner-ontonotes_loss: 0.0588
09/16 11:13:22 AM: Update 52408: task edges-ner-ontonotes, batch 408 (52408): mcc: 0.7778, acc: 0.6764, precision: 0.8619, recall: 0.7222, f1: 0.7859, edges-ner-ontonotes_loss: 0.0595
09/16 11:13:33 AM: Update 52522: task edges-ner-ontonotes, batch 522 (52522): mcc: 0.7765, acc: 0.6742, precision: 0.8620, recall: 0.7197, f1: 0.7844, edges-ner-ontonotes_loss: 0.0599
09/16 11:13:43 AM: Update 52629: task edges-ner-ontonotes, batch 629 (52629): mcc: 0.7706, acc: 0.6673, precision: 0.8578, recall: 0.7130, f1: 0.7787, edges-ner-ontonotes_loss: 0.0616
09/16 11:13:53 AM: Update 52755: task edges-ner-ontonotes, batch 755 (52755): mcc: 0.7604, acc: 0.6538, precision: 0.8517, recall: 0.7002, f1: 0.7686, edges-ner-ontonotes_loss: 0.0649
09/16 11:14:03 AM: Update 52878: task edges-ner-ontonotes, batch 878 (52878): mcc: 0.7538, acc: 0.6462, precision: 0.8470, recall: 0.6927, f1: 0.7621, edges-ner-ontonotes_loss: 0.0672
09/16 11:14:13 AM: Update 52989: task edges-ner-ontonotes, batch 989 (52989): mcc: 0.7514, acc: 0.6431, precision: 0.8459, recall: 0.6893, f1: 0.7596, edges-ner-ontonotes_loss: 0.0677
09/16 11:14:13 AM: ***** Step 53000 / Validation 53 *****
09/16 11:14:13 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 11:14:13 AM: Validating...
09/16 11:14:23 AM: Evaluate: task edges-ner-ontonotes, batch 77 (157): mcc: 0.8171, acc: 0.7251, precision: 0.9105, recall: 0.7495, f1: 0.8222, edges-ner-ontonotes_loss: 0.0538
09/16 11:14:33 AM: Evaluate: task edges-ner-ontonotes, batch 153 (157): mcc: 0.8220, acc: 0.7298, precision: 0.9184, recall: 0.7514, f1: 0.8266, edges-ner-ontonotes_loss: 0.0502
09/16 11:14:33 AM: Updating LR scheduler:
09/16 11:14:33 AM: 	Best result seen so far for macro_avg: 0.833
09/16 11:14:33 AM: 	# validation passes without improvement: 0
09/16 11:14:33 AM: edges-ner-ontonotes_loss: training: 0.067682 validation: 0.049995
09/16 11:14:33 AM: macro_avg: validation: 0.826346
09/16 11:14:33 AM: micro_avg: validation: 0.000000
09/16 11:14:33 AM: edges-ner-ontonotes_mcc: training: 0.751316 validation: 0.821796
09/16 11:14:33 AM: edges-ner-ontonotes_acc: training: 0.643079 validation: 0.729224
09/16 11:14:33 AM: edges-ner-ontonotes_precision: training: 0.845965 validation: 0.918405
09/16 11:14:33 AM: edges-ner-ontonotes_recall: training: 0.689214 validation: 0.751062
09/16 11:14:33 AM: edges-ner-ontonotes_f1: training: 0.759587 validation: 0.826346
09/16 11:14:33 AM: Global learning rate: 3.125e-06
09/16 11:14:33 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 11:14:43 AM: Update 53135: task edges-ner-ontonotes, batch 135 (53135): mcc: 0.7391, acc: 0.6273, precision: 0.8370, recall: 0.6754, f1: 0.7476, edges-ner-ontonotes_loss: 0.0694
09/16 11:14:53 AM: Update 53248: task edges-ner-ontonotes, batch 248 (53248): mcc: 0.7394, acc: 0.6270, precision: 0.8407, recall: 0.6728, f1: 0.7475, edges-ner-ontonotes_loss: 0.0692
09/16 11:15:03 AM: Update 53372: task edges-ner-ontonotes, batch 372 (53372): mcc: 0.7432, acc: 0.6318, precision: 0.8426, recall: 0.6779, f1: 0.7513, edges-ner-ontonotes_loss: 0.0686
09/16 11:15:13 AM: Update 53494: task edges-ner-ontonotes, batch 494 (53494): mcc: 0.7469, acc: 0.6365, precision: 0.8452, recall: 0.6822, f1: 0.7550, edges-ner-ontonotes_loss: 0.0681
09/16 11:15:23 AM: Update 53588: task edges-ner-ontonotes, batch 588 (53588): mcc: 0.7497, acc: 0.6395, precision: 0.8476, recall: 0.6850, f1: 0.7576, edges-ner-ontonotes_loss: 0.0675
09/16 11:15:33 AM: Update 53707: task edges-ner-ontonotes, batch 707 (53707): mcc: 0.7551, acc: 0.6464, precision: 0.8511, recall: 0.6914, f1: 0.7630, edges-ner-ontonotes_loss: 0.0661
09/16 11:15:43 AM: Update 53825: task edges-ner-ontonotes, batch 825 (53825): mcc: 0.7597, acc: 0.6525, precision: 0.8537, recall: 0.6974, f1: 0.7677, edges-ner-ontonotes_loss: 0.0649
09/16 11:15:53 AM: Update 53930: task edges-ner-ontonotes, batch 930 (53930): mcc: 0.7603, acc: 0.6535, precision: 0.8533, recall: 0.6987, f1: 0.7683, edges-ner-ontonotes_loss: 0.0646
09/16 11:15:59 AM: ***** Step 54000 / Validation 54 *****
09/16 11:15:59 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 11:15:59 AM: Validating...
09/16 11:16:03 AM: Evaluate: task edges-ner-ontonotes, batch 41 (157): mcc: 0.7860, acc: 0.6938, precision: 0.8754, recall: 0.7250, f1: 0.7931, edges-ner-ontonotes_loss: 0.0611
09/16 11:16:13 AM: Evaluate: task edges-ner-ontonotes, batch 116 (157): mcc: 0.8181, acc: 0.7282, precision: 0.9089, recall: 0.7528, f1: 0.8235, edges-ner-ontonotes_loss: 0.0534
09/16 11:16:18 AM: Updating LR scheduler:
09/16 11:16:18 AM: 	Best result seen so far for macro_avg: 0.833
09/16 11:16:18 AM: 	# validation passes without improvement: 1
09/16 11:16:18 AM: edges-ner-ontonotes_loss: training: 0.064294 validation: 0.050603
09/16 11:16:18 AM: macro_avg: validation: 0.830926
09/16 11:16:18 AM: micro_avg: validation: 0.000000
09/16 11:16:18 AM: edges-ner-ontonotes_mcc: training: 0.761527 validation: 0.825798
09/16 11:16:18 AM: edges-ner-ontonotes_acc: training: 0.654958 validation: 0.737868
09/16 11:16:18 AM: edges-ner-ontonotes_precision: training: 0.854329 validation: 0.914791
09/16 11:16:18 AM: edges-ner-ontonotes_recall: training: 0.699990 validation: 0.761146
09/16 11:16:18 AM: edges-ner-ontonotes_f1: training: 0.769497 validation: 0.830926
09/16 11:16:18 AM: Global learning rate: 3.125e-06
09/16 11:16:18 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 11:16:23 AM: Update 54060: task edges-ner-ontonotes, batch 60 (54060): mcc: 0.7766, acc: 0.6802, precision: 0.8577, recall: 0.7237, f1: 0.7850, edges-ner-ontonotes_loss: 0.0597
09/16 11:16:33 AM: Update 54157: task edges-ner-ontonotes, batch 157 (54157): mcc: 0.7742, acc: 0.6739, precision: 0.8593, recall: 0.7180, f1: 0.7823, edges-ner-ontonotes_loss: 0.0606
09/16 11:16:43 AM: Update 54275: task edges-ner-ontonotes, batch 275 (54275): mcc: 0.7384, acc: 0.6291, precision: 0.8359, recall: 0.6751, f1: 0.7470, edges-ner-ontonotes_loss: 0.0705
09/16 11:16:53 AM: Update 54405: task edges-ner-ontonotes, batch 405 (54405): mcc: 0.7294, acc: 0.6167, precision: 0.8303, recall: 0.6641, f1: 0.7380, edges-ner-ontonotes_loss: 0.0739
09/16 11:17:03 AM: Update 54512: task edges-ner-ontonotes, batch 512 (54512): mcc: 0.7273, acc: 0.6135, precision: 0.8295, recall: 0.6612, f1: 0.7359, edges-ner-ontonotes_loss: 0.0738
09/16 11:17:13 AM: Update 54659: task edges-ner-ontonotes, batch 659 (54659): mcc: 0.7305, acc: 0.6167, precision: 0.8318, recall: 0.6648, f1: 0.7390, edges-ner-ontonotes_loss: 0.0727
09/16 11:17:24 AM: Update 54774: task edges-ner-ontonotes, batch 774 (54774): mcc: 0.7311, acc: 0.6176, precision: 0.8329, recall: 0.6649, f1: 0.7395, edges-ner-ontonotes_loss: 0.0726
09/16 11:17:34 AM: Update 54899: task edges-ner-ontonotes, batch 899 (54899): mcc: 0.7352, acc: 0.6223, precision: 0.8359, recall: 0.6696, f1: 0.7435, edges-ner-ontonotes_loss: 0.0716
09/16 11:17:43 AM: ***** Step 55000 / Validation 55 *****
09/16 11:17:43 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 11:17:43 AM: Validating...
09/16 11:17:44 AM: Evaluate: task edges-ner-ontonotes, batch 13 (157): mcc: 0.7443, acc: 0.6391, precision: 0.8521, recall: 0.6719, f1: 0.7514, edges-ner-ontonotes_loss: 0.0675
09/16 11:17:54 AM: Evaluate: task edges-ner-ontonotes, batch 99 (157): mcc: 0.8223, acc: 0.7344, precision: 0.9117, recall: 0.7576, f1: 0.8275, edges-ner-ontonotes_loss: 0.0525
09/16 11:18:02 AM: Updating LR scheduler:
09/16 11:18:02 AM: 	Best result seen so far for macro_avg: 0.833
09/16 11:18:02 AM: 	# validation passes without improvement: 2
09/16 11:18:02 AM: edges-ner-ontonotes_loss: training: 0.071156 validation: 0.049473
09/16 11:18:02 AM: macro_avg: validation: 0.830267
09/16 11:18:02 AM: micro_avg: validation: 0.000000
09/16 11:18:02 AM: edges-ner-ontonotes_mcc: training: 0.736886 validation: 0.825460
09/16 11:18:02 AM: edges-ner-ontonotes_acc: training: 0.624575 validation: 0.735896
09/16 11:18:02 AM: edges-ner-ontonotes_precision: training: 0.837536 validation: 0.917822
09/16 11:18:02 AM: edges-ner-ontonotes_recall: training: 0.671137 validation: 0.757962
09/16 11:18:02 AM: edges-ner-ontonotes_f1: training: 0.745160 validation: 0.830267
09/16 11:18:02 AM: Global learning rate: 3.125e-06
09/16 11:18:02 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 11:18:05 AM: Update 55032: task edges-ner-ontonotes, batch 32 (55032): mcc: 0.7635, acc: 0.6588, precision: 0.8538, recall: 0.7038, f1: 0.7716, edges-ner-ontonotes_loss: 0.0634
09/16 11:18:15 AM: Update 55131: task edges-ner-ontonotes, batch 131 (55131): mcc: 0.7577, acc: 0.6509, precision: 0.8516, recall: 0.6956, f1: 0.7658, edges-ner-ontonotes_loss: 0.0636
09/16 11:18:25 AM: Update 55250: task edges-ner-ontonotes, batch 250 (55250): mcc: 0.7699, acc: 0.6662, precision: 0.8602, recall: 0.7098, f1: 0.7778, edges-ner-ontonotes_loss: 0.0617
09/16 11:18:35 AM: Update 55373: task edges-ner-ontonotes, batch 373 (55373): mcc: 0.7753, acc: 0.6719, precision: 0.8631, recall: 0.7168, f1: 0.7831, edges-ner-ontonotes_loss: 0.0602
09/16 11:18:45 AM: Update 55473: task edges-ner-ontonotes, batch 473 (55473): mcc: 0.7739, acc: 0.6707, precision: 0.8612, recall: 0.7158, f1: 0.7818, edges-ner-ontonotes_loss: 0.0603
09/16 11:18:55 AM: Update 55595: task edges-ner-ontonotes, batch 595 (55595): mcc: 0.7760, acc: 0.6731, precision: 0.8619, recall: 0.7189, f1: 0.7840, edges-ner-ontonotes_loss: 0.0603
09/16 11:19:05 AM: Update 55712: task edges-ner-ontonotes, batch 712 (55712): mcc: 0.7728, acc: 0.6691, precision: 0.8593, recall: 0.7155, f1: 0.7808, edges-ner-ontonotes_loss: 0.0608
09/16 11:19:15 AM: Update 55812: task edges-ner-ontonotes, batch 812 (55812): mcc: 0.7624, acc: 0.6565, precision: 0.8527, recall: 0.7030, f1: 0.7706, edges-ner-ontonotes_loss: 0.0639
09/16 11:19:25 AM: Update 55935: task edges-ner-ontonotes, batch 935 (55935): mcc: 0.7555, acc: 0.6477, precision: 0.8480, recall: 0.6947, f1: 0.7638, edges-ner-ontonotes_loss: 0.0661
09/16 11:19:30 AM: ***** Step 56000 / Validation 56 *****
09/16 11:19:30 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 11:19:30 AM: Validating...
09/16 11:19:35 AM: Evaluate: task edges-ner-ontonotes, batch 47 (157): mcc: 0.8002, acc: 0.7085, precision: 0.8894, recall: 0.7379, f1: 0.8066, edges-ner-ontonotes_loss: 0.0576
09/16 11:19:45 AM: Evaluate: task edges-ner-ontonotes, batch 122 (157): mcc: 0.8251, acc: 0.7343, precision: 0.9181, recall: 0.7570, f1: 0.8298, edges-ner-ontonotes_loss: 0.0512
09/16 11:19:49 AM: Updating LR scheduler:
09/16 11:19:49 AM: 	Best result seen so far for macro_avg: 0.833
09/16 11:19:49 AM: 	# validation passes without improvement: 3
09/16 11:19:49 AM: edges-ner-ontonotes_loss: training: 0.066876 validation: 0.049723
09/16 11:19:49 AM: macro_avg: validation: 0.831581
09/16 11:19:49 AM: micro_avg: validation: 0.000000
09/16 11:19:49 AM: edges-ner-ontonotes_mcc: training: 0.752845 validation: 0.826913
09/16 11:19:49 AM: edges-ner-ontonotes_acc: training: 0.644578 validation: 0.736579
09/16 11:19:49 AM: edges-ner-ontonotes_precision: training: 0.846572 validation: 0.919923
09/16 11:19:49 AM: edges-ner-ontonotes_recall: training: 0.691377 validation: 0.758720
09/16 11:19:49 AM: edges-ner-ontonotes_f1: training: 0.761144 validation: 0.831581
09/16 11:19:49 AM: Global learning rate: 3.125e-06
09/16 11:19:49 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 11:19:55 AM: Update 56055: task edges-ner-ontonotes, batch 55 (56055): mcc: 0.7310, acc: 0.6172, precision: 0.8333, recall: 0.6645, f1: 0.7394, edges-ner-ontonotes_loss: 0.0715
09/16 11:20:05 AM: Update 56200: task edges-ner-ontonotes, batch 200 (56200): mcc: 0.7362, acc: 0.6222, precision: 0.8373, recall: 0.6702, f1: 0.7444, edges-ner-ontonotes_loss: 0.0710
09/16 11:20:16 AM: Update 56330: task edges-ner-ontonotes, batch 330 (56330): mcc: 0.7372, acc: 0.6237, precision: 0.8385, recall: 0.6710, f1: 0.7454, edges-ner-ontonotes_loss: 0.0704
09/16 11:20:27 AM: Update 56452: task edges-ner-ontonotes, batch 452 (56452): mcc: 0.7383, acc: 0.6257, precision: 0.8392, recall: 0.6722, f1: 0.7465, edges-ner-ontonotes_loss: 0.0696
09/16 11:20:37 AM: Update 56577: task edges-ner-ontonotes, batch 577 (56577): mcc: 0.7422, acc: 0.6304, precision: 0.8411, recall: 0.6774, f1: 0.7504, edges-ner-ontonotes_loss: 0.0690
09/16 11:20:47 AM: Update 56682: task edges-ner-ontonotes, batch 682 (56682): mcc: 0.7454, acc: 0.6346, precision: 0.8437, recall: 0.6808, f1: 0.7535, edges-ner-ontonotes_loss: 0.0681
09/16 11:20:57 AM: Update 56797: task edges-ner-ontonotes, batch 797 (56797): mcc: 0.7514, acc: 0.6418, precision: 0.8476, recall: 0.6879, f1: 0.7595, edges-ner-ontonotes_loss: 0.0670
09/16 11:21:07 AM: Update 56918: task edges-ner-ontonotes, batch 918 (56918): mcc: 0.7552, acc: 0.6470, precision: 0.8500, recall: 0.6925, f1: 0.7632, edges-ner-ontonotes_loss: 0.0659
09/16 11:21:16 AM: ***** Step 57000 / Validation 57 *****
09/16 11:21:16 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 11:21:16 AM: Validating...
09/16 11:21:17 AM: Evaluate: task edges-ner-ontonotes, batch 5 (157): mcc: 0.6967, acc: 0.5940, precision: 0.8182, recall: 0.6179, f1: 0.7041, edges-ner-ontonotes_loss: 0.0819
09/16 11:21:27 AM: Evaluate: task edges-ner-ontonotes, batch 94 (157): mcc: 0.8187, acc: 0.7308, precision: 0.9072, recall: 0.7551, f1: 0.8242, edges-ner-ontonotes_loss: 0.0546
09/16 11:21:35 AM: Updating LR scheduler:
09/16 11:21:35 AM: 	Best result seen so far for macro_avg: 0.833
09/16 11:21:35 AM: 	# validation passes without improvement: 0
09/16 11:21:35 AM: edges-ner-ontonotes_loss: training: 0.065322 validation: 0.050428
09/16 11:21:35 AM: macro_avg: validation: 0.831830
09/16 11:21:35 AM: micro_avg: validation: 0.000000
09/16 11:21:35 AM: edges-ner-ontonotes_mcc: training: 0.757196 validation: 0.826734
09/16 11:21:35 AM: edges-ner-ontonotes_acc: training: 0.649489 validation: 0.739157
09/16 11:21:35 AM: edges-ner-ontonotes_precision: training: 0.850790 validation: 0.915558
09/16 11:21:35 AM: edges-ner-ontonotes_recall: training: 0.695413 validation: 0.762132
09/16 11:21:35 AM: edges-ner-ontonotes_f1: training: 0.765294 validation: 0.831830
09/16 11:21:35 AM: Global learning rate: 1.5625e-06
09/16 11:21:35 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 11:21:37 AM: Update 57020: task edges-ner-ontonotes, batch 20 (57020): mcc: 0.7785, acc: 0.6787, precision: 0.8610, recall: 0.7241, f1: 0.7866, edges-ner-ontonotes_loss: 0.0575
09/16 11:21:47 AM: Update 57140: task edges-ner-ontonotes, batch 140 (57140): mcc: 0.7758, acc: 0.6739, precision: 0.8615, recall: 0.7190, f1: 0.7838, edges-ner-ontonotes_loss: 0.0596
09/16 11:21:57 AM: Update 57259: task edges-ner-ontonotes, batch 259 (57259): mcc: 0.7745, acc: 0.6712, precision: 0.8609, recall: 0.7172, f1: 0.7825, edges-ner-ontonotes_loss: 0.0600
09/16 11:22:07 AM: Update 57366: task edges-ner-ontonotes, batch 366 (57366): mcc: 0.7506, acc: 0.6425, precision: 0.8444, recall: 0.6893, f1: 0.7590, edges-ner-ontonotes_loss: 0.0666
09/16 11:22:17 AM: Update 57493: task edges-ner-ontonotes, batch 493 (57493): mcc: 0.7383, acc: 0.6275, precision: 0.8353, recall: 0.6755, f1: 0.7470, edges-ner-ontonotes_loss: 0.0710
09/16 11:22:27 AM: Update 57590: task edges-ner-ontonotes, batch 590 (57590): mcc: 0.7337, acc: 0.6215, precision: 0.8337, recall: 0.6688, f1: 0.7422, edges-ner-ontonotes_loss: 0.0723
09/16 11:22:37 AM: Update 57740: task edges-ner-ontonotes, batch 740 (57740): mcc: 0.7345, acc: 0.6222, precision: 0.8340, recall: 0.6699, f1: 0.7430, edges-ner-ontonotes_loss: 0.0719
09/16 11:22:47 AM: Update 57882: task edges-ner-ontonotes, batch 882 (57882): mcc: 0.7358, acc: 0.6235, precision: 0.8353, recall: 0.6711, f1: 0.7443, edges-ner-ontonotes_loss: 0.0715
09/16 11:22:57 AM: Update 57985: task edges-ner-ontonotes, batch 985 (57985): mcc: 0.7366, acc: 0.6249, precision: 0.8362, recall: 0.6718, f1: 0.7450, edges-ner-ontonotes_loss: 0.0711
09/16 11:22:59 AM: ***** Step 58000 / Validation 58 *****
09/16 11:22:59 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 11:22:59 AM: Validating...
09/16 11:23:07 AM: Evaluate: task edges-ner-ontonotes, batch 77 (157): mcc: 0.8180, acc: 0.7275, precision: 0.9101, recall: 0.7514, f1: 0.8232, edges-ner-ontonotes_loss: 0.0539
09/16 11:23:17 AM: Evaluate: task edges-ner-ontonotes, batch 154 (157): mcc: 0.8259, acc: 0.7353, precision: 0.9197, recall: 0.7572, f1: 0.8306, edges-ner-ontonotes_loss: 0.0497
09/16 11:23:18 AM: Updating LR scheduler:
09/16 11:23:18 AM: 	Best result seen so far for macro_avg: 0.833
09/16 11:23:18 AM: 	# validation passes without improvement: 1
09/16 11:23:18 AM: edges-ner-ontonotes_loss: training: 0.071079 validation: 0.049476
09/16 11:23:18 AM: macro_avg: validation: 0.830790
09/16 11:23:18 AM: micro_avg: validation: 0.000000
09/16 11:23:18 AM: edges-ner-ontonotes_mcc: training: 0.736589 validation: 0.826157
09/16 11:23:18 AM: edges-ner-ontonotes_acc: training: 0.624959 validation: 0.735517
09/16 11:23:18 AM: edges-ner-ontonotes_precision: training: 0.836021 validation: 0.919882
09/16 11:23:18 AM: edges-ner-ontonotes_recall: training: 0.671893 validation: 0.757431
09/16 11:23:18 AM: edges-ner-ontonotes_f1: training: 0.745025 validation: 0.830790
09/16 11:23:18 AM: Global learning rate: 1.5625e-06
09/16 11:23:18 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 11:23:27 AM: Update 58116: task edges-ner-ontonotes, batch 116 (58116): mcc: 0.7487, acc: 0.6398, precision: 0.8464, recall: 0.6843, f1: 0.7568, edges-ner-ontonotes_loss: 0.0671
09/16 11:23:38 AM: Update 58212: task edges-ner-ontonotes, batch 212 (58212): mcc: 0.7502, acc: 0.6405, precision: 0.8494, recall: 0.6843, f1: 0.7580, edges-ner-ontonotes_loss: 0.0665
09/16 11:23:48 AM: Update 58334: task edges-ner-ontonotes, batch 334 (58334): mcc: 0.7578, acc: 0.6493, precision: 0.8548, recall: 0.6931, f1: 0.7655, edges-ner-ontonotes_loss: 0.0638
09/16 11:23:58 AM: Update 58453: task edges-ner-ontonotes, batch 453 (58453): mcc: 0.7633, acc: 0.6559, precision: 0.8578, recall: 0.7002, f1: 0.7710, edges-ner-ontonotes_loss: 0.0630
09/16 11:24:08 AM: Update 58555: task edges-ner-ontonotes, batch 555 (58555): mcc: 0.7654, acc: 0.6587, precision: 0.8587, recall: 0.7030, f1: 0.7731, edges-ner-ontonotes_loss: 0.0626
09/16 11:24:18 AM: Update 58674: task edges-ner-ontonotes, batch 674 (58674): mcc: 0.7668, acc: 0.6603, precision: 0.8592, recall: 0.7051, f1: 0.7746, edges-ner-ontonotes_loss: 0.0621
09/16 11:24:28 AM: Update 58792: task edges-ner-ontonotes, batch 792 (58792): mcc: 0.7679, acc: 0.6615, precision: 0.8594, recall: 0.7068, f1: 0.7756, edges-ner-ontonotes_loss: 0.0621
09/16 11:24:38 AM: Update 58893: task edges-ner-ontonotes, batch 893 (58893): mcc: 0.7628, acc: 0.6552, precision: 0.8553, recall: 0.7013, f1: 0.7707, edges-ner-ontonotes_loss: 0.0636
09/16 11:24:47 AM: ***** Step 59000 / Validation 59 *****
09/16 11:24:47 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 11:24:47 AM: Validating...
09/16 11:24:48 AM: Evaluate: task edges-ner-ontonotes, batch 11 (157): mcc: 0.7284, acc: 0.6184, precision: 0.8385, recall: 0.6557, f1: 0.7359, edges-ner-ontonotes_loss: 0.0723
09/16 11:24:58 AM: Evaluate: task edges-ner-ontonotes, batch 98 (157): mcc: 0.8255, acc: 0.7395, precision: 0.9129, recall: 0.7622, f1: 0.8308, edges-ner-ontonotes_loss: 0.0524
09/16 11:25:06 AM: Updating LR scheduler:
09/16 11:25:06 AM: 	Best result seen so far for macro_avg: 0.833
09/16 11:25:06 AM: 	# validation passes without improvement: 2
09/16 11:25:06 AM: Ran out of early stopping patience. Stopping training.
09/16 11:25:06 AM: edges-ner-ontonotes_loss: training: 0.065514 validation: 0.049580
09/16 11:25:06 AM: macro_avg: validation: 0.832677
09/16 11:25:06 AM: micro_avg: validation: 0.000000
09/16 11:25:06 AM: edges-ner-ontonotes_mcc: training: 0.756680 validation: 0.827798
09/16 11:25:06 AM: edges-ner-ontonotes_acc: training: 0.648343 validation: 0.739308
09/16 11:25:06 AM: edges-ner-ontonotes_precision: training: 0.850405 validation: 0.918274
09/16 11:25:06 AM: edges-ner-ontonotes_recall: training: 0.694836 validation: 0.761677
09/16 11:25:06 AM: edges-ner-ontonotes_f1: training: 0.764790 validation: 0.832677
09/16 11:25:06 AM: Global learning rate: 1.5625e-06
09/16 11:25:06 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 11:25:06 AM: Stopped training after 59 validation checks
09/16 11:25:06 AM: Trained edges-ner-ontonotes for 59000 batches or 37.967 epochs
09/16 11:25:06 AM: ***** VALIDATION RESULTS *****
09/16 11:25:06 AM: edges-ner-ontonotes_f1 (for best val pass 49): edges-ner-ontonotes_loss: 0.05037, macro_avg: 0.83311, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.82789, edges-ner-ontonotes_acc: 0.74173, edges-ner-ontonotes_precision: 0.91483, edges-ner-ontonotes_recall: 0.76479, edges-ner-ontonotes_f1: 0.83311
09/16 11:25:06 AM: micro_avg (for best val pass 1): edges-ner-ontonotes_loss: 0.10745, macro_avg: 0.57073, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.58499, edges-ner-ontonotes_acc: 0.42122, edges-ner-ontonotes_precision: 0.82788, edges-ner-ontonotes_recall: 0.43547, edges-ner-ontonotes_f1: 0.57073
09/16 11:25:06 AM: macro_avg (for best val pass 49): edges-ner-ontonotes_loss: 0.05037, macro_avg: 0.83311, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.82789, edges-ner-ontonotes_acc: 0.74173, edges-ner-ontonotes_precision: 0.91483, edges-ner-ontonotes_recall: 0.76479, edges-ner-ontonotes_f1: 0.83311
09/16 11:25:06 AM: Evaluating...
09/16 11:25:06 AM: Loaded model state from ./experiments/ner-ontonotes-hotpot-top/run/edges-ner-ontonotes/model_state_target_train_val_49.best.th
09/16 11:25:06 AM: Evaluating on: edges-ner-ontonotes, split: val
09/16 11:25:36 AM: 	Task edges-ner-ontonotes: batch 227
09/16 11:25:38 AM: Task 'edges-ner-ontonotes': sorting predictions by 'idx'
09/16 11:25:38 AM: Finished evaluating on: edges-ner-ontonotes
09/16 11:25:38 AM: Task 'edges-ner-ontonotes': joining predictions with input split 'val'
09/16 11:25:38 AM: Task 'edges-ner-ontonotes': Wrote predictions to ./experiments/ner-ontonotes-hotpot-top/run
09/16 11:25:38 AM: Wrote all preds for split 'val' to ./experiments/ner-ontonotes-hotpot-top/run
09/16 11:25:38 AM: Evaluating on: edges-ner-ontonotes, split: test
09/16 11:25:58 AM: Task 'edges-ner-ontonotes': sorting predictions by 'idx'
09/16 11:25:58 AM: Finished evaluating on: edges-ner-ontonotes
09/16 11:25:58 AM: Task 'edges-ner-ontonotes': joining predictions with input split 'test'
09/16 11:25:59 AM: Task 'edges-ner-ontonotes': Wrote predictions to ./experiments/ner-ontonotes-hotpot-top/run
09/16 11:25:59 AM: Wrote all preds for split 'test' to ./experiments/ner-ontonotes-hotpot-top/run
09/16 11:25:59 AM: Writing results for split 'val' to ./experiments/ner-ontonotes-hotpot-top/results.tsv
09/16 11:25:59 AM: micro_avg: 0.000, macro_avg: 0.827, edges-ner-ontonotes_mcc: 0.821, edges-ner-ontonotes_acc: 0.733, edges-ner-ontonotes_precision: 0.912, edges-ner-ontonotes_recall: 0.756, edges-ner-ontonotes_f1: 0.827
09/16 11:25:59 AM: Done!
09/16 11:25:59 AM: Fatal error in main():
Traceback (most recent call last):
  File "main.py", line 16, in <module>
    main(sys.argv[1:])
  File "/srv/home/ericwallace/jiant/jiant/__main__.py", line 610, in main
    exit("Done exited")
  File "/home/ericwallace/miniconda3/envs/jiant/lib/python3.6/_sitebuiltins.py", line 26, in __call__
    raise SystemExit(code)
SystemExit: Done exited
