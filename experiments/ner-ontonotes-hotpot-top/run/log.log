09/16 09:13:23 AM: Git branch: master
09/16 09:13:23 AM: Git SHA: 3ca0f74688379229ab3eec908a215358ad18b3f4
09/16 09:13:23 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/ner-ontonotes-hotpot-top/",
  "exp_name": "experiments/ner-ontonotes-hotpot-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/ner-ontonotes-hotpot-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/hotpot",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/ner-ontonotes-hotpot-top__run",
  "run_dir": "./experiments/ner-ontonotes-hotpot-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-ner-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 09:13:23 AM: Saved config to ./experiments/ner-ontonotes-hotpot-top/run/params.conf
09/16 09:13:23 AM: Using random seed 1234
09/16 09:13:58 AM: Using GPU 0
09/16 09:13:58 AM: Loading tasks...
09/16 09:13:58 AM: Writing pre-preprocessed tasks to ./experiments/ner-ontonotes-hotpot-top/
09/16 09:13:58 AM: 	Creating task edges-ner-ontonotes from scratch.
09/16 09:13:59 AM: Read=49706, Skip=66106, Total=115812 from ./probing_data/edges/ontonotes/ner/train.json.retokenized.bert-base-uncased
09/16 09:13:59 AM: Read=7610, Skip=8070, Total=15680 from ./probing_data/edges/ontonotes/ner/development.json.retokenized.bert-base-uncased
09/16 09:13:59 AM: Read=5099, Skip=7118, Total=12217 from ./probing_data/edges/ontonotes/ner/test.json.retokenized.bert-base-uncased
09/16 09:14:00 AM: 	Task 'edges-ner-ontonotes': |train|=49706 |val|=7610 |test|=5099
09/16 09:14:00 AM: 	Finished loading tasks: edges-ner-ontonotes.
09/16 09:14:00 AM: 	Building vocab from scratch.
09/16 09:14:00 AM: 	Counting units for task edges-ner-ontonotes.
09/16 09:14:02 AM: 	Task 'edges-ner-ontonotes': adding vocab namespace 'edges-ner-ontonotes_labels'
09/16 09:14:03 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:14:03 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 09:14:04 AM: 	Saved vocab to ./experiments/ner-ontonotes-hotpot-top/vocab
09/16 09:14:04 AM: Loading token dictionary from ./experiments/ner-ontonotes-hotpot-top/vocab.
09/16 09:14:04 AM: 	Loaded vocab from ./experiments/ner-ontonotes-hotpot-top/vocab
09/16 09:14:04 AM: 	Vocab namespace edges-ner-ontonotes_labels: size 18
09/16 09:14:04 AM: 	Vocab namespace tokens: size 22840
09/16 09:14:04 AM: 	Vocab namespace bert_uncased: size 30524
09/16 09:14:04 AM: 	Vocab namespace chars: size 77
09/16 09:14:04 AM: 	Finished building vocab.
09/16 09:14:04 AM: 	Task edges-ner-ontonotes (train): Indexing from scratch.
09/16 09:14:14 AM: 	Task edges-ner-ontonotes (train): Saved 49706 instances to ./experiments/ner-ontonotes-hotpot-top/preproc/edges-ner-ontonotes__train_data
09/16 09:14:14 AM: 	Task edges-ner-ontonotes (val): Indexing from scratch.
09/16 09:14:16 AM: 	Task edges-ner-ontonotes (val): Saved 7610 instances to ./experiments/ner-ontonotes-hotpot-top/preproc/edges-ner-ontonotes__val_data
09/16 09:14:16 AM: 	Task edges-ner-ontonotes (test): Indexing from scratch.
09/16 09:14:17 AM: 	Task edges-ner-ontonotes (test): Saved 5099 instances to ./experiments/ner-ontonotes-hotpot-top/preproc/edges-ner-ontonotes__test_data
09/16 09:14:17 AM: 	Finished indexing tasks
09/16 09:14:17 AM: 	Creating trimmed target-only version of edges-ner-ontonotes train.
09/16 09:14:17 AM: 	  Training on 
09/16 09:14:17 AM: 	  Evaluating on edges-ner-ontonotes
09/16 09:14:17 AM: 	Finished loading tasks in 19.016s
09/16 09:14:17 AM: 	 Tasks: ['edges-ner-ontonotes']
09/16 09:14:17 AM: Building model...
09/16 09:14:17 AM: Using BERT model (bert-base-uncased).
09/16 09:14:17 AM: LOADING A FUNETUNED MODEL from: 
09/16 09:14:17 AM: models/hotpot
09/16 09:14:17 AM: loading configuration file models/hotpot/config.json
09/16 09:14:17 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 09:14:17 AM: loading weights file models/hotpot/pytorch_model.bin
09/16 09:14:22 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpgpcjysuf
09/16 09:14:29 AM: copying /tmp/tmpgpcjysuf to cache at ./experiments/ner-ontonotes-hotpot-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:14:29 AM: creating metadata file for ./experiments/ner-ontonotes-hotpot-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:14:29 AM: removing temp file /tmp/tmpgpcjysuf
09/16 09:14:29 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/ner-ontonotes-hotpot-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:14:30 AM: Initializing parameters
09/16 09:14:30 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 09:14:30 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 09:14:30 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 09:14:30 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 09:14:30 AM: 	Task 'edges-ner-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-ner-ontonotes"
}
09/16 09:14:53 AM: Model specification:
09/16 09:14:53 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-ner-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=18, bias=True)
    )
  )
)
09/16 09:14:53 AM: Model parameters:
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	edges-ner-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 09:14:53 AM: 	edges-ner-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 09:14:53 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 9216 with torch.Size([18, 512])
09/16 09:14:53 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 18 with torch.Size([18])
09/16 09:14:53 AM: Total number of parameters: 109688338 (1.09688e+08)
09/16 09:14:53 AM: Number of trainable parameters: 206098 (206098)
09/16 09:14:53 AM: Finished building model in 36.442s
09/16 09:14:53 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-ner-ontonotes 

09/16 09:14:56 AM: patience = 9
09/16 09:14:56 AM: val_interval = 1000
09/16 09:14:56 AM: max_vals = 250
09/16 09:14:56 AM: cuda_device = 0
09/16 09:14:56 AM: grad_norm = 5.0
09/16 09:14:56 AM: grad_clipping = None
09/16 09:14:56 AM: lr_decay = 0.99
09/16 09:14:56 AM: min_lr = 1e-06
09/16 09:14:56 AM: keep_all_checkpoints = 0
09/16 09:14:56 AM: val_data_limit = 5000
09/16 09:14:56 AM: max_epochs = -1
09/16 09:14:56 AM: dec_val_scale = 250
09/16 09:14:56 AM: training_data_fraction = 1
09/16 09:14:56 AM: type = adam
09/16 09:14:56 AM: parameter_groups = None
09/16 09:14:56 AM: Number of trainable parameters: 206098
09/16 09:14:56 AM: infer_type_and_cast = True
09/16 09:14:56 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:14:56 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:14:56 AM: lr = 0.0001
09/16 09:14:56 AM: amsgrad = True
09/16 09:14:56 AM: type = reduce_on_plateau
09/16 09:14:56 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:14:56 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:14:56 AM: mode = max
09/16 09:14:56 AM: factor = 0.5
09/16 09:14:56 AM: patience = 3
09/16 09:14:56 AM: threshold = 0.0001
09/16 09:14:56 AM: threshold_mode = abs
09/16 09:14:56 AM: verbose = True
09/16 09:14:56 AM: type = adam
09/16 09:14:56 AM: parameter_groups = None
09/16 09:14:56 AM: Number of trainable parameters: 206098
09/16 09:14:56 AM: infer_type_and_cast = True
09/16 09:14:56 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:14:56 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:14:56 AM: lr = 0.0001
09/16 09:14:56 AM: amsgrad = True
09/16 09:14:56 AM: type = reduce_on_plateau
09/16 09:14:56 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:14:56 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:14:56 AM: mode = max
09/16 09:14:56 AM: factor = 0.5
09/16 09:14:56 AM: patience = 3
09/16 09:14:56 AM: threshold = 0.0001
09/16 09:14:56 AM: threshold_mode = abs
09/16 09:14:56 AM: verbose = True
09/16 09:14:56 AM: Starting training without restoring from a checkpoint.
09/16 09:14:56 AM: Training examples per task, before any subsampling: {'edges-ner-ontonotes': 49706}
09/16 09:14:56 AM: Beginning training with stopping criteria based on metric: edges-ner-ontonotes_f1
09/16 09:15:06 AM: Update 41: task edges-ner-ontonotes, batch 41 (41): mcc: -0.0089, acc: 0.0017, precision: 0.0490, recall: 0.0769, f1: 0.0598, edges-ner-ontonotes_loss: 0.3774
09/16 09:15:16 AM: Update 201: task edges-ner-ontonotes, batch 201 (201): mcc: 0.0366, acc: 0.0260, precision: 0.1130, recall: 0.0424, f1: 0.0617, edges-ner-ontonotes_loss: 0.2108
09/16 09:15:26 AM: Update 318: task edges-ner-ontonotes, batch 318 (318): mcc: 0.0959, acc: 0.0546, precision: 0.2292, recall: 0.0650, f1: 0.1012, edges-ner-ontonotes_loss: 0.1893
09/16 09:15:36 AM: Update 458: task edges-ner-ontonotes, batch 458 (458): mcc: 0.1703, acc: 0.0895, precision: 0.3834, recall: 0.0963, f1: 0.1540, edges-ner-ontonotes_loss: 0.1739
09/16 09:15:46 AM: Update 596: task edges-ner-ontonotes, batch 596 (596): mcc: 0.2355, acc: 0.1235, precision: 0.5060, recall: 0.1288, f1: 0.2053, edges-ner-ontonotes_loss: 0.1632
09/16 09:15:56 AM: Update 709: task edges-ner-ontonotes, batch 709 (709): mcc: 0.2813, acc: 0.1502, precision: 0.5779, recall: 0.1560, f1: 0.2456, edges-ner-ontonotes_loss: 0.1568
09/16 09:16:06 AM: Update 853: task edges-ner-ontonotes, batch 853 (853): mcc: 0.3324, acc: 0.1840, precision: 0.6447, recall: 0.1906, f1: 0.2942, edges-ner-ontonotes_loss: 0.1491
09/16 09:16:16 AM: Update 968: task edges-ner-ontonotes, batch 968 (968): mcc: 0.3699, acc: 0.2121, precision: 0.6843, recall: 0.2197, f1: 0.3326, edges-ner-ontonotes_loss: 0.1438
09/16 09:16:19 AM: ***** Step 1000 / Validation 1 *****
09/16 09:16:19 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:16:19 AM: Validating...
09/16 09:16:33 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.5425, acc: 0.3756, precision: 0.8022, recall: 0.3891, f1: 0.5241, edges-ner-ontonotes_loss: 0.1177
09/16 09:16:45 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.5691, acc: 0.4060, precision: 0.8139, recall: 0.4204, f1: 0.5544, edges-ner-ontonotes_loss: 0.1111
09/16 09:16:50 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:16:51 AM: Best result seen so far for micro.
09/16 09:16:51 AM: Best result seen so far for macro.
09/16 09:16:51 AM: Updating LR scheduler:
09/16 09:16:51 AM: 	Best result seen so far for macro_avg: 0.571
09/16 09:16:51 AM: 	# validation passes without improvement: 0
09/16 09:16:51 AM: edges-ner-ontonotes_loss: training: 0.142597 validation: 0.107455
09/16 09:16:51 AM: macro_avg: validation: 0.570733
09/16 09:16:51 AM: micro_avg: validation: 0.000000
09/16 09:16:51 AM: edges-ner-ontonotes_mcc: training: 0.378349 validation: 0.584989
09/16 09:16:51 AM: edges-ner-ontonotes_acc: training: 0.218556 validation: 0.421216
09/16 09:16:51 AM: edges-ner-ontonotes_precision: training: 0.692613 validation: 0.827879
09/16 09:16:51 AM: edges-ner-ontonotes_recall: training: 0.226533 validation: 0.435472
09/16 09:16:51 AM: edges-ner-ontonotes_f1: training: 0.341403 validation: 0.570733
09/16 09:16:51 AM: Global learning rate: 0.0001
09/16 09:16:51 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:16:55 AM: Update 1049: task edges-ner-ontonotes, batch 49 (1049): mcc: 0.5834, acc: 0.4128, precision: 0.8345, recall: 0.4294, f1: 0.5670, edges-ner-ontonotes_loss: 0.1003
09/16 09:17:05 AM: Update 1187: task edges-ner-ontonotes, batch 187 (1187): mcc: 0.5980, acc: 0.4327, precision: 0.8356, recall: 0.4499, f1: 0.5849, edges-ner-ontonotes_loss: 0.0999
09/16 09:17:15 AM: Update 1296: task edges-ner-ontonotes, batch 296 (1296): mcc: 0.5890, acc: 0.4246, precision: 0.8269, recall: 0.4419, f1: 0.5760, edges-ner-ontonotes_loss: 0.1015
09/16 09:17:25 AM: Update 1436: task edges-ner-ontonotes, batch 436 (1436): mcc: 0.5756, acc: 0.4110, precision: 0.8173, recall: 0.4280, f1: 0.5618, edges-ner-ontonotes_loss: 0.1048
09/16 09:17:35 AM: Update 1562: task edges-ner-ontonotes, batch 562 (1562): mcc: 0.5738, acc: 0.4096, precision: 0.8152, recall: 0.4265, f1: 0.5600, edges-ner-ontonotes_loss: 0.1055
09/16 09:17:45 AM: Update 1732: task edges-ner-ontonotes, batch 732 (1732): mcc: 0.5838, acc: 0.4214, precision: 0.8209, recall: 0.4377, f1: 0.5709, edges-ner-ontonotes_loss: 0.1038
09/16 09:17:55 AM: Update 1870: task edges-ner-ontonotes, batch 870 (1870): mcc: 0.5896, acc: 0.4286, precision: 0.8225, recall: 0.4453, f1: 0.5778, edges-ner-ontonotes_loss: 0.1025
09/16 09:18:05 AM: ***** Step 2000 / Validation 2 *****
09/16 09:18:05 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:18:05 AM: Validating...
09/16 09:18:05 AM: Evaluate: task edges-ner-ontonotes, batch 9 (157): mcc: 0.5826, acc: 0.4507, precision: 0.7826, recall: 0.4592, f1: 0.5788, edges-ner-ontonotes_loss: 0.1114
09/16 09:18:15 AM: Evaluate: task edges-ner-ontonotes, batch 101 (157): mcc: 0.7020, acc: 0.5682, precision: 0.8759, recall: 0.5833, f1: 0.7003, edges-ner-ontonotes_loss: 0.0845
09/16 09:18:22 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:18:22 AM: Best result seen so far for macro.
09/16 09:18:22 AM: Updating LR scheduler:
09/16 09:18:22 AM: 	Best result seen so far for macro_avg: 0.691
09/16 09:18:22 AM: 	# validation passes without improvement: 0
09/16 09:18:22 AM: edges-ner-ontonotes_loss: training: 0.101024 validation: 0.083766
09/16 09:18:22 AM: macro_avg: validation: 0.690675
09/16 09:18:22 AM: micro_avg: validation: 0.000000
09/16 09:18:22 AM: edges-ner-ontonotes_mcc: training: 0.597975 validation: 0.692297
09/16 09:18:22 AM: edges-ner-ontonotes_acc: training: 0.439566 validation: 0.556794
09/16 09:18:22 AM: edges-ner-ontonotes_precision: training: 0.823145 validation: 0.867561
09/16 09:18:22 AM: edges-ner-ontonotes_recall: training: 0.457243 validation: 0.573703
09/16 09:18:22 AM: edges-ner-ontonotes_f1: training: 0.587911 validation: 0.690675
09/16 09:18:22 AM: Global learning rate: 0.0001
09/16 09:18:22 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:18:25 AM: Update 2039: task edges-ner-ontonotes, batch 39 (2039): mcc: 0.6648, acc: 0.5213, precision: 0.8396, recall: 0.5494, f1: 0.6642, edges-ner-ontonotes_loss: 0.0869
09/16 09:18:35 AM: Update 2173: task edges-ner-ontonotes, batch 173 (2173): mcc: 0.6694, acc: 0.5291, precision: 0.8433, recall: 0.5541, f1: 0.6688, edges-ner-ontonotes_loss: 0.0862
09/16 09:18:46 AM: Update 2284: task edges-ner-ontonotes, batch 284 (2284): mcc: 0.6755, acc: 0.5375, precision: 0.8433, recall: 0.5640, f1: 0.6759, edges-ner-ontonotes_loss: 0.0852
09/16 09:18:56 AM: Update 2416: task edges-ner-ontonotes, batch 416 (2416): mcc: 0.6821, acc: 0.5472, precision: 0.8429, recall: 0.5748, f1: 0.6835, edges-ner-ontonotes_loss: 0.0836
09/16 09:19:06 AM: Update 2524: task edges-ner-ontonotes, batch 524 (2524): mcc: 0.6853, acc: 0.5513, precision: 0.8438, recall: 0.5793, f1: 0.6870, edges-ner-ontonotes_loss: 0.0828
09/16 09:19:16 AM: Update 2664: task edges-ner-ontonotes, batch 664 (2664): mcc: 0.6879, acc: 0.5552, precision: 0.8441, recall: 0.5834, f1: 0.6900, edges-ner-ontonotes_loss: 0.0823
09/16 09:19:26 AM: Update 2800: task edges-ner-ontonotes, batch 800 (2800): mcc: 0.6912, acc: 0.5598, precision: 0.8446, recall: 0.5885, f1: 0.6936, edges-ner-ontonotes_loss: 0.0815
09/16 09:19:36 AM: Update 2907: task edges-ner-ontonotes, batch 907 (2907): mcc: 0.6825, acc: 0.5497, precision: 0.8384, recall: 0.5788, f1: 0.6848, edges-ner-ontonotes_loss: 0.0834
09/16 09:19:42 AM: ***** Step 3000 / Validation 3 *****
09/16 09:19:42 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:19:42 AM: Validating...
09/16 09:19:46 AM: Evaluate: task edges-ner-ontonotes, batch 39 (157): mcc: 0.7049, acc: 0.5871, precision: 0.8591, recall: 0.6002, f1: 0.7067, edges-ner-ontonotes_loss: 0.0827
09/16 09:19:56 AM: Evaluate: task edges-ner-ontonotes, batch 117 (157): mcc: 0.7359, acc: 0.6182, precision: 0.8831, recall: 0.6333, f1: 0.7376, edges-ner-ontonotes_loss: 0.0755
09/16 09:20:01 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:20:01 AM: Best result seen so far for macro.
09/16 09:20:01 AM: Updating LR scheduler:
09/16 09:20:01 AM: 	Best result seen so far for macro_avg: 0.730
09/16 09:20:01 AM: 	# validation passes without improvement: 0
09/16 09:20:01 AM: edges-ner-ontonotes_loss: training: 0.084542 validation: 0.075907
09/16 09:20:01 AM: macro_avg: validation: 0.730152
09/16 09:20:01 AM: micro_avg: validation: 0.000000
09/16 09:20:01 AM: edges-ner-ontonotes_mcc: training: 0.678842 validation: 0.728755
09/16 09:20:01 AM: edges-ner-ontonotes_acc: training: 0.545262 validation: 0.608204
09/16 09:20:01 AM: edges-ner-ontonotes_precision: training: 0.836099 validation: 0.879568
09/16 09:20:01 AM: edges-ner-ontonotes_recall: training: 0.574479 validation: 0.624128
09/16 09:20:01 AM: edges-ner-ontonotes_f1: training: 0.681028 validation: 0.730152
09/16 09:20:01 AM: Global learning rate: 0.0001
09/16 09:20:01 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:20:06 AM: Update 3081: task edges-ner-ontonotes, batch 81 (3081): mcc: 0.6440, acc: 0.5032, precision: 0.8191, recall: 0.5305, f1: 0.6440, edges-ner-ontonotes_loss: 0.0959
09/16 09:20:16 AM: Update 3208: task edges-ner-ontonotes, batch 208 (3208): mcc: 0.6497, acc: 0.5120, precision: 0.8215, recall: 0.5379, f1: 0.6501, edges-ner-ontonotes_loss: 0.0928
09/16 09:20:26 AM: Update 3374: task edges-ner-ontonotes, batch 374 (3374): mcc: 0.6647, acc: 0.5274, precision: 0.8321, recall: 0.5544, f1: 0.6654, edges-ner-ontonotes_loss: 0.0893
09/16 09:20:36 AM: Update 3497: task edges-ner-ontonotes, batch 497 (3497): mcc: 0.6707, acc: 0.5368, precision: 0.8335, recall: 0.5631, f1: 0.6721, edges-ner-ontonotes_loss: 0.0876
09/16 09:20:46 AM: Update 3630: task edges-ner-ontonotes, batch 630 (3630): mcc: 0.6780, acc: 0.5466, precision: 0.8359, recall: 0.5733, f1: 0.6801, edges-ner-ontonotes_loss: 0.0861
09/16 09:20:56 AM: Update 3739: task edges-ner-ontonotes, batch 739 (3739): mcc: 0.6821, acc: 0.5517, precision: 0.8375, recall: 0.5787, f1: 0.6844, edges-ner-ontonotes_loss: 0.0850
09/16 09:21:06 AM: Update 3869: task edges-ner-ontonotes, batch 869 (3869): mcc: 0.6887, acc: 0.5600, precision: 0.8394, recall: 0.5881, f1: 0.6916, edges-ner-ontonotes_loss: 0.0835
09/16 09:21:16 AM: ***** Step 4000 / Validation 4 *****
09/16 09:21:16 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:21:16 AM: Validating...
09/16 09:21:16 AM: Evaluate: task edges-ner-ontonotes, batch 5 (157): mcc: 0.6027, acc: 0.5015, precision: 0.7457, recall: 0.5164, f1: 0.6102, edges-ner-ontonotes_loss: 0.1105
09/16 09:21:26 AM: Evaluate: task edges-ner-ontonotes, batch 97 (157): mcc: 0.7528, acc: 0.6512, precision: 0.8786, recall: 0.6650, f1: 0.7570, edges-ner-ontonotes_loss: 0.0747
09/16 09:21:34 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:21:34 AM: Best result seen so far for macro.
09/16 09:21:34 AM: Updating LR scheduler:
09/16 09:21:34 AM: 	Best result seen so far for macro_avg: 0.761
09/16 09:21:34 AM: 	# validation passes without improvement: 0
09/16 09:21:34 AM: edges-ner-ontonotes_loss: training: 0.081945 validation: 0.070566
09/16 09:21:34 AM: macro_avg: validation: 0.761322
09/16 09:21:34 AM: micro_avg: validation: 0.000000
09/16 09:21:34 AM: edges-ner-ontonotes_mcc: training: 0.696081 validation: 0.757259
09/16 09:21:34 AM: edges-ner-ontonotes_acc: training: 0.568810 validation: 0.653700
09/16 09:21:34 AM: edges-ner-ontonotes_precision: training: 0.842785 validation: 0.882777
09/16 09:21:34 AM: edges-ner-ontonotes_recall: training: 0.597791 validation: 0.669245
09/16 09:21:34 AM: edges-ner-ontonotes_f1: training: 0.699456 validation: 0.761322
09/16 09:21:34 AM: Global learning rate: 0.0001
09/16 09:21:34 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:21:36 AM: Update 4026: task edges-ner-ontonotes, batch 26 (4026): mcc: 0.7370, acc: 0.6203, precision: 0.8535, recall: 0.6581, f1: 0.7432, edges-ner-ontonotes_loss: 0.0719
09/16 09:21:46 AM: Update 4128: task edges-ner-ontonotes, batch 128 (4128): mcc: 0.7293, acc: 0.6116, precision: 0.8534, recall: 0.6452, f1: 0.7348, edges-ner-ontonotes_loss: 0.0730
09/16 09:21:56 AM: Update 4256: task edges-ner-ontonotes, batch 256 (4256): mcc: 0.7297, acc: 0.6130, precision: 0.8522, recall: 0.6469, f1: 0.7354, edges-ner-ontonotes_loss: 0.0730
09/16 09:22:07 AM: Update 4374: task edges-ner-ontonotes, batch 374 (4374): mcc: 0.7234, acc: 0.6055, precision: 0.8482, recall: 0.6394, f1: 0.7291, edges-ner-ontonotes_loss: 0.0739
09/16 09:22:17 AM: Update 4512: task edges-ner-ontonotes, batch 512 (4512): mcc: 0.7074, acc: 0.5847, precision: 0.8385, recall: 0.6198, f1: 0.7128, edges-ner-ontonotes_loss: 0.0788
09/16 09:22:27 AM: Update 4650: task edges-ner-ontonotes, batch 650 (4650): mcc: 0.6971, acc: 0.5725, precision: 0.8320, recall: 0.6078, f1: 0.7024, edges-ner-ontonotes_loss: 0.0816
09/16 09:22:37 AM: Update 4792: task edges-ner-ontonotes, batch 792 (4792): mcc: 0.6969, acc: 0.5720, precision: 0.8332, recall: 0.6064, f1: 0.7019, edges-ner-ontonotes_loss: 0.0818
09/16 09:22:47 AM: Update 4953: task edges-ner-ontonotes, batch 953 (4953): mcc: 0.6972, acc: 0.5724, precision: 0.8340, recall: 0.6063, f1: 0.7022, edges-ner-ontonotes_loss: 0.0816
09/16 09:22:52 AM: ***** Step 5000 / Validation 5 *****
09/16 09:22:53 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:22:53 AM: Validating...
09/16 09:22:57 AM: Evaluate: task edges-ner-ontonotes, batch 40 (157): mcc: 0.7452, acc: 0.6455, precision: 0.8655, recall: 0.6625, f1: 0.7505, edges-ner-ontonotes_loss: 0.0717
09/16 09:23:07 AM: Evaluate: task edges-ner-ontonotes, batch 117 (157): mcc: 0.7759, acc: 0.6752, precision: 0.8963, recall: 0.6901, f1: 0.7798, edges-ner-ontonotes_loss: 0.0653
09/16 09:23:12 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:23:12 AM: Best result seen so far for macro.
09/16 09:23:12 AM: Updating LR scheduler:
09/16 09:23:12 AM: 	Best result seen so far for macro_avg: 0.773
09/16 09:23:12 AM: 	# validation passes without improvement: 0
09/16 09:23:12 AM: edges-ner-ontonotes_loss: training: 0.081616 validation: 0.065791
09/16 09:23:12 AM: macro_avg: validation: 0.773388
09/16 09:23:12 AM: micro_avg: validation: 0.000000
09/16 09:23:12 AM: edges-ner-ontonotes_mcc: training: 0.696545 validation: 0.769733
09/16 09:23:12 AM: edges-ner-ontonotes_acc: training: 0.571627 validation: 0.665150
09/16 09:23:12 AM: edges-ner-ontonotes_precision: training: 0.833758 validation: 0.894129
09/16 09:23:12 AM: edges-ner-ontonotes_recall: training: 0.605406 validation: 0.681377
09/16 09:23:12 AM: edges-ner-ontonotes_f1: training: 0.701466 validation: 0.773388
09/16 09:23:12 AM: Global learning rate: 0.0001
09/16 09:23:12 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:23:17 AM: Update 5070: task edges-ner-ontonotes, batch 70 (5070): mcc: 0.7080, acc: 0.5891, precision: 0.8390, recall: 0.6205, f1: 0.7134, edges-ner-ontonotes_loss: 0.0773
09/16 09:23:27 AM: Update 5205: task edges-ner-ontonotes, batch 205 (5205): mcc: 0.7066, acc: 0.5879, precision: 0.8350, recall: 0.6214, f1: 0.7125, edges-ner-ontonotes_loss: 0.0773
09/16 09:23:37 AM: Update 5327: task edges-ner-ontonotes, batch 327 (5327): mcc: 0.7168, acc: 0.5997, precision: 0.8426, recall: 0.6326, f1: 0.7226, edges-ner-ontonotes_loss: 0.0754
09/16 09:23:47 AM: Update 5461: task edges-ner-ontonotes, batch 461 (5461): mcc: 0.7264, acc: 0.6116, precision: 0.8480, recall: 0.6446, f1: 0.7324, edges-ner-ontonotes_loss: 0.0734
09/16 09:23:57 AM: Update 5589: task edges-ner-ontonotes, batch 589 (5589): mcc: 0.7312, acc: 0.6168, precision: 0.8515, recall: 0.6499, f1: 0.7372, edges-ner-ontonotes_loss: 0.0723
09/16 09:24:07 AM: Update 5685: task edges-ner-ontonotes, batch 685 (5685): mcc: 0.7314, acc: 0.6172, precision: 0.8510, recall: 0.6506, f1: 0.7374, edges-ner-ontonotes_loss: 0.0721
09/16 09:24:17 AM: Update 5826: task edges-ner-ontonotes, batch 826 (5826): mcc: 0.7344, acc: 0.6206, precision: 0.8528, recall: 0.6542, f1: 0.7404, edges-ner-ontonotes_loss: 0.0715
09/16 09:24:27 AM: Update 5943: task edges-ner-ontonotes, batch 943 (5943): mcc: 0.7311, acc: 0.6172, precision: 0.8501, recall: 0.6509, f1: 0.7373, edges-ner-ontonotes_loss: 0.0720
09/16 09:24:32 AM: ***** Step 6000 / Validation 6 *****
09/16 09:24:32 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:24:32 AM: Validating...
09/16 09:24:37 AM: Evaluate: task edges-ner-ontonotes, batch 57 (157): mcc: 0.7700, acc: 0.6722, precision: 0.8866, recall: 0.6878, f1: 0.7747, edges-ner-ontonotes_loss: 0.0682
09/16 09:24:47 AM: Evaluate: task edges-ner-ontonotes, batch 134 (157): mcc: 0.7838, acc: 0.6807, precision: 0.9048, recall: 0.6967, f1: 0.7872, edges-ner-ontonotes_loss: 0.0638
09/16 09:24:50 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:24:50 AM: Best result seen so far for macro.
09/16 09:24:50 AM: Updating LR scheduler:
09/16 09:24:50 AM: 	Best result seen so far for macro_avg: 0.785
09/16 09:24:50 AM: 	# validation passes without improvement: 0
09/16 09:24:50 AM: edges-ner-ontonotes_loss: training: 0.073081 validation: 0.063775
09/16 09:24:50 AM: macro_avg: validation: 0.784635
09/16 09:24:50 AM: micro_avg: validation: 0.000000
09/16 09:24:50 AM: edges-ner-ontonotes_mcc: training: 0.727293 validation: 0.780960
09/16 09:24:50 AM: edges-ner-ontonotes_acc: training: 0.612453 validation: 0.676903
09/16 09:24:50 AM: edges-ner-ontonotes_precision: training: 0.847419 validation: 0.901407
09/16 09:24:50 AM: edges-ner-ontonotes_recall: training: 0.646523 validation: 0.694647
09/16 09:24:50 AM: edges-ner-ontonotes_f1: training: 0.733463 validation: 0.784635
09/16 09:24:50 AM: Global learning rate: 0.0001
09/16 09:24:50 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:24:57 AM: Update 6102: task edges-ner-ontonotes, batch 102 (6102): mcc: 0.6717, acc: 0.5414, precision: 0.8107, recall: 0.5817, f1: 0.6773, edges-ner-ontonotes_loss: 0.0883
09/16 09:25:08 AM: Update 6225: task edges-ner-ontonotes, batch 225 (6225): mcc: 0.6712, acc: 0.5414, precision: 0.8102, recall: 0.5812, f1: 0.6768, edges-ner-ontonotes_loss: 0.0890
09/16 09:25:18 AM: Update 6390: task edges-ner-ontonotes, batch 390 (6390): mcc: 0.6837, acc: 0.5567, precision: 0.8215, recall: 0.5934, f1: 0.6890, edges-ner-ontonotes_loss: 0.0848
09/16 09:25:29 AM: Update 6538: task edges-ner-ontonotes, batch 538 (6538): mcc: 0.6880, acc: 0.5626, precision: 0.8247, recall: 0.5981, f1: 0.6934, edges-ner-ontonotes_loss: 0.0831
09/16 09:25:39 AM: Update 6672: task edges-ner-ontonotes, batch 672 (6672): mcc: 0.6963, acc: 0.5740, precision: 0.8291, recall: 0.6086, f1: 0.7019, edges-ner-ontonotes_loss: 0.0815
09/16 09:25:49 AM: Update 6812: task edges-ner-ontonotes, batch 812 (6812): mcc: 0.7034, acc: 0.5825, precision: 0.8333, recall: 0.6172, f1: 0.7092, edges-ner-ontonotes_loss: 0.0799
09/16 09:25:59 AM: Update 6917: task edges-ner-ontonotes, batch 917 (6917): mcc: 0.7073, acc: 0.5874, precision: 0.8357, recall: 0.6219, f1: 0.7131, edges-ner-ontonotes_loss: 0.0788
09/16 09:26:06 AM: ***** Step 7000 / Validation 7 *****
09/16 09:26:06 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:26:06 AM: Validating...
09/16 09:26:09 AM: Evaluate: task edges-ner-ontonotes, batch 35 (157): mcc: 0.7275, acc: 0.6324, precision: 0.8429, recall: 0.6505, f1: 0.7343, edges-ner-ontonotes_loss: 0.0784
09/16 09:26:21 AM: Evaluate: task edges-ner-ontonotes, batch 114 (157): mcc: 0.7742, acc: 0.6815, precision: 0.8799, recall: 0.7006, f1: 0.7801, edges-ner-ontonotes_loss: 0.0665
09/16 09:26:26 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:26:27 AM: Best result seen so far for macro.
09/16 09:26:27 AM: Updating LR scheduler:
09/16 09:26:27 AM: 	Best result seen so far for macro_avg: 0.788
09/16 09:26:27 AM: 	# validation passes without improvement: 0
09/16 09:26:27 AM: edges-ner-ontonotes_loss: training: 0.077849 validation: 0.063425
09/16 09:26:27 AM: macro_avg: validation: 0.787644
09/16 09:26:27 AM: micro_avg: validation: 0.000000
09/16 09:26:27 AM: edges-ner-ontonotes_mcc: training: 0.711654 validation: 0.782021
09/16 09:26:27 AM: edges-ner-ontonotes_acc: training: 0.592896 validation: 0.688960
09/16 09:26:27 AM: edges-ner-ontonotes_precision: training: 0.838291 validation: 0.886538
09/16 09:26:27 AM: edges-ner-ontonotes_recall: training: 0.627249 validation: 0.708599
09/16 09:26:27 AM: edges-ner-ontonotes_f1: training: 0.717575 validation: 0.787644
09/16 09:26:27 AM: Global learning rate: 0.0001
09/16 09:26:27 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:26:31 AM: Update 7053: task edges-ner-ontonotes, batch 53 (7053): mcc: 0.7589, acc: 0.6564, precision: 0.8559, recall: 0.6940, f1: 0.7665, edges-ner-ontonotes_loss: 0.0657
09/16 09:26:41 AM: Update 7164: task edges-ner-ontonotes, batch 164 (7164): mcc: 0.7538, acc: 0.6466, precision: 0.8561, recall: 0.6850, f1: 0.7611, edges-ner-ontonotes_loss: 0.0666
09/16 09:26:51 AM: Update 7295: task edges-ner-ontonotes, batch 295 (7295): mcc: 0.7517, acc: 0.6441, precision: 0.8569, recall: 0.6807, f1: 0.7587, edges-ner-ontonotes_loss: 0.0669
09/16 09:27:01 AM: Update 7426: task edges-ner-ontonotes, batch 426 (7426): mcc: 0.7495, acc: 0.6420, precision: 0.8541, recall: 0.6793, f1: 0.7567, edges-ner-ontonotes_loss: 0.0672
09/16 09:27:12 AM: Update 7540: task edges-ner-ontonotes, batch 540 (7540): mcc: 0.7383, acc: 0.6282, precision: 0.8459, recall: 0.6665, f1: 0.7456, edges-ner-ontonotes_loss: 0.0704
09/16 09:27:22 AM: Update 7670: task edges-ner-ontonotes, batch 670 (7670): mcc: 0.7272, acc: 0.6134, precision: 0.8409, recall: 0.6517, f1: 0.7343, edges-ner-ontonotes_loss: 0.0738
09/16 09:27:32 AM: Update 7787: task edges-ner-ontonotes, batch 787 (7787): mcc: 0.7217, acc: 0.6070, precision: 0.8370, recall: 0.6454, f1: 0.7288, edges-ner-ontonotes_loss: 0.0755
09/16 09:27:42 AM: Update 7952: task edges-ner-ontonotes, batch 952 (7952): mcc: 0.7204, acc: 0.6049, precision: 0.8375, recall: 0.6427, f1: 0.7273, edges-ner-ontonotes_loss: 0.0759
09/16 09:27:45 AM: ***** Step 8000 / Validation 8 *****
09/16 09:27:45 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:27:45 AM: Validating...
09/16 09:27:52 AM: Evaluate: task edges-ner-ontonotes, batch 66 (157): mcc: 0.7811, acc: 0.6786, precision: 0.8952, recall: 0.6999, f1: 0.7856, edges-ner-ontonotes_loss: 0.0630
09/16 09:28:02 AM: Evaluate: task edges-ner-ontonotes, batch 142 (157): mcc: 0.7793, acc: 0.6722, precision: 0.9039, recall: 0.6898, f1: 0.7825, edges-ner-ontonotes_loss: 0.0619
09/16 09:28:04 AM: Updating LR scheduler:
09/16 09:28:04 AM: 	Best result seen so far for macro_avg: 0.788
09/16 09:28:04 AM: 	# validation passes without improvement: 1
09/16 09:28:04 AM: edges-ner-ontonotes_loss: training: 0.075845 validation: 0.062495
09/16 09:28:04 AM: macro_avg: validation: 0.777615
09/16 09:28:04 AM: micro_avg: validation: 0.000000
09/16 09:28:04 AM: edges-ner-ontonotes_mcc: training: 0.720294 validation: 0.774385
09/16 09:28:04 AM: edges-ner-ontonotes_acc: training: 0.604600 validation: 0.666060
09/16 09:28:04 AM: edges-ner-ontonotes_precision: training: 0.837620 validation: 0.900339
09/16 09:28:04 AM: edges-ner-ontonotes_recall: training: 0.642461 validation: 0.684334
09/16 09:28:04 AM: edges-ner-ontonotes_f1: training: 0.727174 validation: 0.777615
09/16 09:28:04 AM: Global learning rate: 0.0001
09/16 09:28:04 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:28:12 AM: Update 8094: task edges-ner-ontonotes, batch 94 (8094): mcc: 0.7081, acc: 0.5897, precision: 0.8319, recall: 0.6263, f1: 0.7146, edges-ner-ontonotes_loss: 0.0765
09/16 09:28:23 AM: Update 8228: task edges-ner-ontonotes, batch 228 (8228): mcc: 0.7258, acc: 0.6085, precision: 0.8449, recall: 0.6459, f1: 0.7321, edges-ner-ontonotes_loss: 0.0738
09/16 09:28:33 AM: Update 8364: task edges-ner-ontonotes, batch 364 (8364): mcc: 0.7250, acc: 0.6095, precision: 0.8413, recall: 0.6476, f1: 0.7318, edges-ner-ontonotes_loss: 0.0737
09/16 09:28:43 AM: Update 8478: task edges-ner-ontonotes, batch 478 (8478): mcc: 0.7282, acc: 0.6133, precision: 0.8437, recall: 0.6511, f1: 0.7350, edges-ner-ontonotes_loss: 0.0728
09/16 09:28:53 AM: Update 8609: task edges-ner-ontonotes, batch 609 (8609): mcc: 0.7376, acc: 0.6245, precision: 0.8500, recall: 0.6621, f1: 0.7444, edges-ner-ontonotes_loss: 0.0708
09/16 09:29:03 AM: Update 8723: task edges-ner-ontonotes, batch 723 (8723): mcc: 0.7403, acc: 0.6283, precision: 0.8514, recall: 0.6656, f1: 0.7471, edges-ner-ontonotes_loss: 0.0701
09/16 09:29:13 AM: Update 8858: task edges-ner-ontonotes, batch 858 (8858): mcc: 0.7431, acc: 0.6317, precision: 0.8525, recall: 0.6695, f1: 0.7500, edges-ner-ontonotes_loss: 0.0693
09/16 09:29:23 AM: Update 8993: task edges-ner-ontonotes, batch 993 (8993): mcc: 0.7449, acc: 0.6338, precision: 0.8530, recall: 0.6721, f1: 0.7518, edges-ner-ontonotes_loss: 0.0689
09/16 09:29:24 AM: ***** Step 9000 / Validation 9 *****
09/16 09:29:24 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:29:24 AM: Validating...
09/16 09:29:33 AM: Evaluate: task edges-ner-ontonotes, batch 82 (157): mcc: 0.7743, acc: 0.6741, precision: 0.8895, recall: 0.6929, f1: 0.7790, edges-ner-ontonotes_loss: 0.0668
09/16 09:29:43 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:29:43 AM: Best result seen so far for macro.
09/16 09:29:43 AM: Updating LR scheduler:
09/16 09:29:43 AM: 	Best result seen so far for macro_avg: 0.797
09/16 09:29:43 AM: 	# validation passes without improvement: 0
09/16 09:29:43 AM: edges-ner-ontonotes_loss: training: 0.068959 validation: 0.059757
09/16 09:29:43 AM: macro_avg: validation: 0.797410
09/16 09:29:43 AM: micro_avg: validation: 0.000000
09/16 09:29:43 AM: edges-ner-ontonotes_mcc: training: 0.744814 validation: 0.792898
09/16 09:29:43 AM: edges-ner-ontonotes_acc: training: 0.633766 validation: 0.696012
09/16 09:29:43 AM: edges-ner-ontonotes_precision: training: 0.853069 validation: 0.902308
09/16 09:29:43 AM: edges-ner-ontonotes_recall: training: 0.671966 validation: 0.714362
09/16 09:29:43 AM: edges-ner-ontonotes_f1: training: 0.751764 validation: 0.797410
09/16 09:29:43 AM: Global learning rate: 0.0001
09/16 09:29:43 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:29:44 AM: Update 9006: task edges-ner-ontonotes, batch 6 (9006): mcc: 0.7184, acc: 0.6130, precision: 0.8184, recall: 0.6550, f1: 0.7276, edges-ner-ontonotes_loss: 0.0756
09/16 09:29:54 AM: Update 9114: task edges-ner-ontonotes, batch 114 (9114): mcc: 0.6812, acc: 0.5600, precision: 0.8044, recall: 0.6025, f1: 0.6889, edges-ner-ontonotes_loss: 0.0833
09/16 09:30:04 AM: Update 9256: task edges-ner-ontonotes, batch 256 (9256): mcc: 0.6818, acc: 0.5589, precision: 0.8078, recall: 0.6009, f1: 0.6891, edges-ner-ontonotes_loss: 0.0852
09/16 09:30:14 AM: Update 9389: task edges-ner-ontonotes, batch 389 (9389): mcc: 0.6854, acc: 0.5623, precision: 0.8123, recall: 0.6032, f1: 0.6924, edges-ner-ontonotes_loss: 0.0840
09/16 09:30:24 AM: Update 9548: task edges-ner-ontonotes, batch 548 (9548): mcc: 0.6951, acc: 0.5735, precision: 0.8211, recall: 0.6128, f1: 0.7018, edges-ner-ontonotes_loss: 0.0813
09/16 09:30:34 AM: Update 9672: task edges-ner-ontonotes, batch 672 (9672): mcc: 0.6982, acc: 0.5770, precision: 0.8238, recall: 0.6160, f1: 0.7049, edges-ner-ontonotes_loss: 0.0804
09/16 09:30:44 AM: Update 9803: task edges-ner-ontonotes, batch 803 (9803): mcc: 0.7050, acc: 0.5861, precision: 0.8283, recall: 0.6239, f1: 0.7117, edges-ner-ontonotes_loss: 0.0789
09/16 09:30:54 AM: Update 9941: task edges-ner-ontonotes, batch 941 (9941): mcc: 0.7105, acc: 0.5922, precision: 0.8321, recall: 0.6302, f1: 0.7172, edges-ner-ontonotes_loss: 0.0778
09/16 09:31:00 AM: ***** Step 10000 / Validation 10 *****
09/16 09:31:00 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:31:00 AM: Validating...
09/16 09:31:04 AM: Evaluate: task edges-ner-ontonotes, batch 45 (157): mcc: 0.7406, acc: 0.6488, precision: 0.8553, recall: 0.6629, f1: 0.7469, edges-ner-ontonotes_loss: 0.0719
09/16 09:31:15 AM: Evaluate: task edges-ner-ontonotes, batch 121 (157): mcc: 0.7898, acc: 0.6972, precision: 0.8988, recall: 0.7119, f1: 0.7945, edges-ner-ontonotes_loss: 0.0614
09/16 09:31:19 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:31:19 AM: Best result seen so far for macro.
09/16 09:31:19 AM: Updating LR scheduler:
09/16 09:31:19 AM: 	Best result seen so far for macro_avg: 0.799
09/16 09:31:19 AM: 	# validation passes without improvement: 0
09/16 09:31:19 AM: edges-ner-ontonotes_loss: training: 0.077357 validation: 0.059601
09/16 09:31:19 AM: macro_avg: validation: 0.798868
09/16 09:31:19 AM: micro_avg: validation: 0.000000
09/16 09:31:19 AM: edges-ner-ontonotes_mcc: training: 0.711572 validation: 0.794189
09/16 09:31:19 AM: edges-ner-ontonotes_acc: training: 0.593520 validation: 0.701244
09/16 09:31:19 AM: edges-ner-ontonotes_precision: training: 0.832602 validation: 0.901697
09/16 09:31:19 AM: edges-ner-ontonotes_recall: training: 0.631623 validation: 0.717091
09/16 09:31:19 AM: edges-ner-ontonotes_f1: training: 0.718319 validation: 0.798868
09/16 09:31:19 AM: Global learning rate: 0.0001
09/16 09:31:19 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:31:25 AM: Update 10072: task edges-ner-ontonotes, batch 72 (10072): mcc: 0.7654, acc: 0.6615, precision: 0.8642, recall: 0.6983, f1: 0.7725, edges-ner-ontonotes_loss: 0.0635
09/16 09:31:35 AM: Update 10199: task edges-ner-ontonotes, batch 199 (10199): mcc: 0.7626, acc: 0.6582, precision: 0.8611, recall: 0.6961, f1: 0.7699, edges-ner-ontonotes_loss: 0.0640
09/16 09:31:45 AM: Update 10302: task edges-ner-ontonotes, batch 302 (10302): mcc: 0.7591, acc: 0.6539, precision: 0.8586, recall: 0.6921, f1: 0.7664, edges-ner-ontonotes_loss: 0.0645
09/16 09:31:55 AM: Update 10437: task edges-ner-ontonotes, batch 437 (10437): mcc: 0.7577, acc: 0.6524, precision: 0.8573, recall: 0.6908, f1: 0.7651, edges-ner-ontonotes_loss: 0.0645
09/16 09:32:05 AM: Update 10573: task edges-ner-ontonotes, batch 573 (10573): mcc: 0.7576, acc: 0.6523, precision: 0.8562, recall: 0.6916, f1: 0.7651, edges-ner-ontonotes_loss: 0.0647
09/16 09:32:15 AM: Update 10685: task edges-ner-ontonotes, batch 685 (10685): mcc: 0.7457, acc: 0.6373, precision: 0.8483, recall: 0.6775, f1: 0.7534, edges-ner-ontonotes_loss: 0.0681
09/16 09:32:25 AM: Update 10826: task edges-ner-ontonotes, batch 826 (10826): mcc: 0.7380, acc: 0.6272, precision: 0.8440, recall: 0.6677, f1: 0.7455, edges-ner-ontonotes_loss: 0.0708
09/16 09:32:35 AM: Update 10940: task edges-ner-ontonotes, batch 940 (10940): mcc: 0.7336, acc: 0.6211, precision: 0.8417, recall: 0.6620, f1: 0.7411, edges-ner-ontonotes_loss: 0.0722
09/16 09:32:39 AM: ***** Step 11000 / Validation 11 *****
09/16 09:32:39 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:32:40 AM: Validating...
09/16 09:32:45 AM: Evaluate: task edges-ner-ontonotes, batch 36 (157): mcc: 0.7739, acc: 0.6718, precision: 0.8768, recall: 0.7026, f1: 0.7801, edges-ner-ontonotes_loss: 0.0640
09/16 09:32:55 AM: Evaluate: task edges-ner-ontonotes, batch 117 (157): mcc: 0.7971, acc: 0.6958, precision: 0.9066, recall: 0.7180, f1: 0.8014, edges-ner-ontonotes_loss: 0.0582
09/16 09:33:00 AM: Updating LR scheduler:
09/16 09:33:00 AM: 	Best result seen so far for macro_avg: 0.799
09/16 09:33:00 AM: 	# validation passes without improvement: 1
09/16 09:33:00 AM: edges-ner-ontonotes_loss: training: 0.072387 validation: 0.058440
09/16 09:33:00 AM: macro_avg: validation: 0.795421
09/16 09:33:00 AM: micro_avg: validation: 0.000000
09/16 09:33:00 AM: edges-ner-ontonotes_mcc: training: 0.733144 validation: 0.791530
09/16 09:33:00 AM: edges-ner-ontonotes_acc: training: 0.620425 validation: 0.686154
09/16 09:33:00 AM: edges-ner-ontonotes_precision: training: 0.841928 validation: 0.906489
09/16 09:33:00 AM: edges-ner-ontonotes_recall: training: 0.661006 validation: 0.708599
09/16 09:33:00 AM: edges-ner-ontonotes_f1: training: 0.740577 validation: 0.795421
09/16 09:33:00 AM: Global learning rate: 0.0001
09/16 09:33:00 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:33:05 AM: Update 11091: task edges-ner-ontonotes, batch 91 (11091): mcc: 0.7343, acc: 0.6190, precision: 0.8533, recall: 0.6538, f1: 0.7403, edges-ner-ontonotes_loss: 0.0712
09/16 09:33:15 AM: Update 11221: task edges-ner-ontonotes, batch 221 (11221): mcc: 0.7244, acc: 0.6080, precision: 0.8416, recall: 0.6463, f1: 0.7312, edges-ner-ontonotes_loss: 0.0733
09/16 09:33:25 AM: Update 11351: task edges-ner-ontonotes, batch 351 (11351): mcc: 0.7292, acc: 0.6153, precision: 0.8446, recall: 0.6521, f1: 0.7360, edges-ner-ontonotes_loss: 0.0724
09/16 09:33:35 AM: Update 11489: task edges-ner-ontonotes, batch 489 (11489): mcc: 0.7309, acc: 0.6188, precision: 0.8444, recall: 0.6552, f1: 0.7378, edges-ner-ontonotes_loss: 0.0718
09/16 09:33:45 AM: Update 11597: task edges-ner-ontonotes, batch 597 (11597): mcc: 0.7346, acc: 0.6230, precision: 0.8466, recall: 0.6597, f1: 0.7416, edges-ner-ontonotes_loss: 0.0710
09/16 09:33:55 AM: Update 11729: task edges-ner-ontonotes, batch 729 (11729): mcc: 0.7405, acc: 0.6302, precision: 0.8497, recall: 0.6673, f1: 0.7475, edges-ner-ontonotes_loss: 0.0696
09/16 09:34:06 AM: Update 11848: task edges-ner-ontonotes, batch 848 (11848): mcc: 0.7450, acc: 0.6358, precision: 0.8515, recall: 0.6736, f1: 0.7522, edges-ner-ontonotes_loss: 0.0686
09/16 09:34:16 AM: Update 11981: task edges-ner-ontonotes, batch 981 (11981): mcc: 0.7477, acc: 0.6393, precision: 0.8530, recall: 0.6771, f1: 0.7549, edges-ner-ontonotes_loss: 0.0680
09/16 09:34:17 AM: ***** Step 12000 / Validation 12 *****
09/16 09:34:17 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:34:17 AM: Validating...
09/16 09:34:26 AM: Evaluate: task edges-ner-ontonotes, batch 80 (157): mcc: 0.7826, acc: 0.6915, precision: 0.8829, recall: 0.7127, f1: 0.7887, edges-ner-ontonotes_loss: 0.0651
09/16 09:34:36 AM: Evaluate: task edges-ner-ontonotes, batch 156 (157): mcc: 0.8023, acc: 0.7132, precision: 0.8981, recall: 0.7342, f1: 0.8079, edges-ner-ontonotes_loss: 0.0577
09/16 09:34:36 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:34:36 AM: Best result seen so far for macro.
09/16 09:34:36 AM: Updating LR scheduler:
09/16 09:34:36 AM: 	Best result seen so far for macro_avg: 0.808
09/16 09:34:36 AM: 	# validation passes without improvement: 0
09/16 09:34:36 AM: edges-ner-ontonotes_loss: training: 0.067924 validation: 0.057551
09/16 09:34:36 AM: macro_avg: validation: 0.807960
09/16 09:34:36 AM: micro_avg: validation: 0.000000
09/16 09:34:36 AM: edges-ner-ontonotes_mcc: training: 0.747980 validation: 0.802353
09/16 09:34:36 AM: edges-ner-ontonotes_acc: training: 0.639706 validation: 0.713224
09/16 09:34:36 AM: edges-ner-ontonotes_precision: training: 0.852811 validation: 0.898154
09/16 09:34:36 AM: edges-ner-ontonotes_recall: training: 0.677652 validation: 0.734228
09/16 09:34:36 AM: edges-ner-ontonotes_f1: training: 0.755208 validation: 0.807960
09/16 09:34:36 AM: Global learning rate: 0.0001
09/16 09:34:36 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:34:46 AM: Update 12127: task edges-ner-ontonotes, batch 127 (12127): mcc: 0.7575, acc: 0.6521, precision: 0.8567, recall: 0.6909, f1: 0.7649, edges-ner-ontonotes_loss: 0.0655
09/16 09:34:56 AM: Update 12242: task edges-ner-ontonotes, batch 242 (12242): mcc: 0.7284, acc: 0.6133, precision: 0.8375, recall: 0.6566, f1: 0.7361, edges-ner-ontonotes_loss: 0.0743
09/16 09:35:06 AM: Update 12379: task edges-ner-ontonotes, batch 379 (12379): mcc: 0.7141, acc: 0.5957, precision: 0.8279, recall: 0.6398, f1: 0.7218, edges-ner-ontonotes_loss: 0.0782
09/16 09:35:16 AM: Update 12497: task edges-ner-ontonotes, batch 497 (12497): mcc: 0.7117, acc: 0.5934, precision: 0.8260, recall: 0.6372, f1: 0.7194, edges-ner-ontonotes_loss: 0.0789
09/16 09:35:26 AM: Update 12667: task edges-ner-ontonotes, batch 667 (12667): mcc: 0.7138, acc: 0.5959, precision: 0.8286, recall: 0.6387, f1: 0.7213, edges-ner-ontonotes_loss: 0.0777
09/16 09:35:36 AM: Update 12794: task edges-ner-ontonotes, batch 794 (12794): mcc: 0.7146, acc: 0.5968, precision: 0.8293, recall: 0.6395, f1: 0.7222, edges-ner-ontonotes_loss: 0.0770
09/16 09:35:46 AM: Update 12922: task edges-ner-ontonotes, batch 922 (12922): mcc: 0.7176, acc: 0.6009, precision: 0.8313, recall: 0.6429, f1: 0.7251, edges-ner-ontonotes_loss: 0.0761
09/16 09:35:52 AM: ***** Step 13000 / Validation 13 *****
09/16 09:35:52 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:35:52 AM: Validating...
09/16 09:35:56 AM: Evaluate: task edges-ner-ontonotes, batch 44 (157): mcc: 0.7744, acc: 0.6877, precision: 0.8708, recall: 0.7086, f1: 0.7813, edges-ner-ontonotes_loss: 0.0631
09/16 09:36:06 AM: Evaluate: task edges-ner-ontonotes, batch 120 (157): mcc: 0.8027, acc: 0.7146, precision: 0.8948, recall: 0.7377, f1: 0.8087, edges-ner-ontonotes_loss: 0.0566
09/16 09:36:10 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:36:10 AM: Best result seen so far for macro.
09/16 09:36:10 AM: Updating LR scheduler:
09/16 09:36:10 AM: 	Best result seen so far for macro_avg: 0.808
09/16 09:36:10 AM: 	# validation passes without improvement: 1
09/16 09:36:10 AM: edges-ner-ontonotes_loss: training: 0.075424 validation: 0.056094
09/16 09:36:10 AM: macro_avg: validation: 0.808018
09/16 09:36:10 AM: micro_avg: validation: 0.000000
09/16 09:36:10 AM: edges-ner-ontonotes_mcc: training: 0.720389 validation: 0.802284
09/16 09:36:10 AM: edges-ner-ontonotes_acc: training: 0.604339 validation: 0.712087
09/16 09:36:10 AM: edges-ner-ontonotes_precision: training: 0.833629 validation: 0.896938
09/16 09:36:10 AM: edges-ner-ontonotes_recall: training: 0.645856 validation: 0.735138
09/16 09:36:10 AM: edges-ner-ontonotes_f1: training: 0.727826 validation: 0.808018
09/16 09:36:10 AM: Global learning rate: 0.0001
09/16 09:36:10 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:36:17 AM: Update 13075: task edges-ner-ontonotes, batch 75 (13075): mcc: 0.7361, acc: 0.6257, precision: 0.8405, recall: 0.6674, f1: 0.7440, edges-ner-ontonotes_loss: 0.0709
09/16 09:36:27 AM: Update 13206: task edges-ner-ontonotes, batch 206 (13206): mcc: 0.7512, acc: 0.6423, precision: 0.8512, recall: 0.6845, f1: 0.7588, edges-ner-ontonotes_loss: 0.0664
09/16 09:36:37 AM: Update 13337: task edges-ner-ontonotes, batch 337 (13337): mcc: 0.7590, acc: 0.6526, precision: 0.8564, recall: 0.6938, f1: 0.7666, edges-ner-ontonotes_loss: 0.0645
09/16 09:36:47 AM: Update 13446: task edges-ner-ontonotes, batch 446 (13446): mcc: 0.7592, acc: 0.6529, precision: 0.8559, recall: 0.6946, f1: 0.7669, edges-ner-ontonotes_loss: 0.0643
09/16 09:36:57 AM: Update 13581: task edges-ner-ontonotes, batch 581 (13581): mcc: 0.7611, acc: 0.6551, precision: 0.8574, recall: 0.6967, f1: 0.7687, edges-ner-ontonotes_loss: 0.0639
09/16 09:37:08 AM: Update 13701: task edges-ner-ontonotes, batch 701 (13701): mcc: 0.7608, acc: 0.6545, precision: 0.8568, recall: 0.6967, f1: 0.7685, edges-ner-ontonotes_loss: 0.0639
09/16 09:37:18 AM: Update 13839: task edges-ner-ontonotes, batch 839 (13839): mcc: 0.7494, acc: 0.6407, precision: 0.8486, recall: 0.6837, f1: 0.7573, edges-ner-ontonotes_loss: 0.0675
09/16 09:37:28 AM: Update 13969: task edges-ner-ontonotes, batch 969 (13969): mcc: 0.7419, acc: 0.6312, precision: 0.8438, recall: 0.6746, f1: 0.7498, edges-ner-ontonotes_loss: 0.0698
09/16 09:37:30 AM: ***** Step 14000 / Validation 14 *****
09/16 09:37:30 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:37:30 AM: Validating...
09/16 09:37:38 AM: Evaluate: task edges-ner-ontonotes, batch 74 (157): mcc: 0.7888, acc: 0.6849, precision: 0.9053, recall: 0.7049, f1: 0.7926, edges-ner-ontonotes_loss: 0.0604
09/16 09:37:48 AM: Evaluate: task edges-ner-ontonotes, batch 154 (157): mcc: 0.7927, acc: 0.6847, precision: 0.9154, recall: 0.7035, f1: 0.7956, edges-ner-ontonotes_loss: 0.0571
09/16 09:37:48 AM: Updating LR scheduler:
09/16 09:37:48 AM: 	Best result seen so far for macro_avg: 0.808
09/16 09:37:48 AM: 	# validation passes without improvement: 2
09/16 09:37:48 AM: edges-ner-ontonotes_loss: training: 0.070237 validation: 0.056899
09/16 09:37:48 AM: macro_avg: validation: 0.795884
09/16 09:37:48 AM: micro_avg: validation: 0.000000
09/16 09:37:48 AM: edges-ner-ontonotes_mcc: training: 0.740831 validation: 0.793054
09/16 09:37:48 AM: edges-ner-ontonotes_acc: training: 0.629861 validation: 0.685017
09/16 09:37:48 AM: edges-ner-ontonotes_precision: training: 0.843104 validation: 0.915655
09/16 09:37:48 AM: edges-ner-ontonotes_recall: training: 0.673336 validation: 0.703822
09/16 09:37:48 AM: edges-ner-ontonotes_f1: training: 0.748717 validation: 0.795884
09/16 09:37:48 AM: Global learning rate: 0.0001
09/16 09:37:48 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:37:58 AM: Update 14128: task edges-ner-ontonotes, batch 128 (14128): mcc: 0.7232, acc: 0.6068, precision: 0.8413, recall: 0.6445, f1: 0.7298, edges-ner-ontonotes_loss: 0.0737
09/16 09:38:08 AM: Update 14283: task edges-ner-ontonotes, batch 283 (14283): mcc: 0.7261, acc: 0.6091, precision: 0.8404, recall: 0.6501, f1: 0.7331, edges-ner-ontonotes_loss: 0.0731
09/16 09:38:18 AM: Update 14401: task edges-ner-ontonotes, batch 401 (14401): mcc: 0.7251, acc: 0.6097, precision: 0.8388, recall: 0.6498, f1: 0.7323, edges-ner-ontonotes_loss: 0.0733
09/16 09:38:28 AM: Update 14540: task edges-ner-ontonotes, batch 540 (14540): mcc: 0.7298, acc: 0.6161, precision: 0.8410, recall: 0.6561, f1: 0.7371, edges-ner-ontonotes_loss: 0.0721
09/16 09:38:38 AM: Update 14646: task edges-ner-ontonotes, batch 646 (14646): mcc: 0.7307, acc: 0.6177, precision: 0.8412, recall: 0.6574, f1: 0.7380, edges-ner-ontonotes_loss: 0.0718
09/16 09:38:48 AM: Update 14777: task edges-ner-ontonotes, batch 777 (14777): mcc: 0.7387, acc: 0.6275, precision: 0.8460, recall: 0.6672, f1: 0.7461, edges-ner-ontonotes_loss: 0.0701
09/16 09:38:58 AM: Update 14914: task edges-ner-ontonotes, batch 914 (14914): mcc: 0.7446, acc: 0.6346, precision: 0.8491, recall: 0.6749, f1: 0.7520, edges-ner-ontonotes_loss: 0.0688
09/16 09:39:06 AM: ***** Step 15000 / Validation 15 *****
09/16 09:39:07 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:39:07 AM: Validating...
09/16 09:39:09 AM: Evaluate: task edges-ner-ontonotes, batch 6 (157): mcc: 0.6919, acc: 0.5850, precision: 0.8209, recall: 0.6075, f1: 0.6983, edges-ner-ontonotes_loss: 0.0873
09/16 09:39:19 AM: Evaluate: task edges-ner-ontonotes, batch 99 (157): mcc: 0.7883, acc: 0.6971, precision: 0.8850, recall: 0.7208, f1: 0.7945, edges-ner-ontonotes_loss: 0.0620
09/16 09:39:26 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:39:26 AM: Best result seen so far for macro.
09/16 09:39:26 AM: Updating LR scheduler:
09/16 09:39:26 AM: 	Best result seen so far for macro_avg: 0.809
09/16 09:39:26 AM: 	# validation passes without improvement: 0
09/16 09:39:26 AM: edges-ner-ontonotes_loss: training: 0.068426 validation: 0.056547
09/16 09:39:26 AM: macro_avg: validation: 0.809232
09/16 09:39:26 AM: micro_avg: validation: 0.000000
09/16 09:39:26 AM: edges-ner-ontonotes_mcc: training: 0.745776 validation: 0.803542
09/16 09:39:26 AM: edges-ner-ontonotes_acc: training: 0.636328 validation: 0.712997
09/16 09:39:26 AM: edges-ner-ontonotes_precision: training: 0.849705 validation: 0.898012
09/16 09:39:26 AM: edges-ner-ontonotes_recall: training: 0.676413 validation: 0.736427
09/16 09:39:26 AM: edges-ner-ontonotes_f1: training: 0.753221 validation: 0.809232
09/16 09:39:26 AM: Global learning rate: 0.0001
09/16 09:39:26 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:39:29 AM: Update 15031: task edges-ner-ontonotes, batch 31 (15031): mcc: 0.7748, acc: 0.6756, precision: 0.8700, recall: 0.7099, f1: 0.7818, edges-ner-ontonotes_loss: 0.0600
09/16 09:39:39 AM: Update 15162: task edges-ner-ontonotes, batch 162 (15162): mcc: 0.7620, acc: 0.6578, precision: 0.8561, recall: 0.6993, f1: 0.7698, edges-ner-ontonotes_loss: 0.0636
09/16 09:39:49 AM: Update 15265: task edges-ner-ontonotes, batch 265 (15265): mcc: 0.7553, acc: 0.6485, precision: 0.8526, recall: 0.6906, f1: 0.7631, edges-ner-ontonotes_loss: 0.0645
09/16 09:39:59 AM: Update 15407: task edges-ner-ontonotes, batch 407 (15407): mcc: 0.7381, acc: 0.6263, precision: 0.8405, recall: 0.6708, f1: 0.7461, edges-ner-ontonotes_loss: 0.0709
09/16 09:40:09 AM: Update 15544: task edges-ner-ontonotes, batch 544 (15544): mcc: 0.7277, acc: 0.6138, precision: 0.8340, recall: 0.6582, f1: 0.7358, edges-ner-ontonotes_loss: 0.0744
09/16 09:40:19 AM: Update 15690: task edges-ner-ontonotes, batch 690 (15690): mcc: 0.7270, acc: 0.6128, precision: 0.8351, recall: 0.6561, f1: 0.7348, edges-ner-ontonotes_loss: 0.0744
09/16 09:40:29 AM: Update 15852: task edges-ner-ontonotes, batch 852 (15852): mcc: 0.7278, acc: 0.6129, precision: 0.8372, recall: 0.6556, f1: 0.7354, edges-ner-ontonotes_loss: 0.0740
09/16 09:40:39 AM: Update 15974: task edges-ner-ontonotes, batch 974 (15974): mcc: 0.7288, acc: 0.6144, precision: 0.8380, recall: 0.6568, f1: 0.7364, edges-ner-ontonotes_loss: 0.0735
09/16 09:40:41 AM: ***** Step 16000 / Validation 16 *****
09/16 09:40:41 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:40:41 AM: Validating...
09/16 09:40:49 AM: Evaluate: task edges-ner-ontonotes, batch 73 (157): mcc: 0.7982, acc: 0.7080, precision: 0.8970, recall: 0.7280, f1: 0.8037, edges-ner-ontonotes_loss: 0.0595
09/16 09:40:59 AM: Evaluate: task edges-ner-ontonotes, batch 153 (157): mcc: 0.8072, acc: 0.7139, precision: 0.9064, recall: 0.7357, f1: 0.8122, edges-ner-ontonotes_loss: 0.0550
09/16 09:41:00 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:41:00 AM: Best result seen so far for macro.
09/16 09:41:00 AM: Updating LR scheduler:
09/16 09:41:00 AM: 	Best result seen so far for macro_avg: 0.812
09/16 09:41:00 AM: 	# validation passes without improvement: 0
09/16 09:41:00 AM: edges-ner-ontonotes_loss: training: 0.073313 validation: 0.054713
09/16 09:41:00 AM: macro_avg: validation: 0.812105
09/16 09:41:00 AM: micro_avg: validation: 0.000000
09/16 09:41:00 AM: edges-ner-ontonotes_mcc: training: 0.729174 validation: 0.807112
09/16 09:41:00 AM: edges-ner-ontonotes_acc: training: 0.614619 validation: 0.713907
09/16 09:41:00 AM: edges-ner-ontonotes_precision: training: 0.838556 validation: 0.906381
09/16 09:41:00 AM: edges-ner-ontonotes_recall: training: 0.656933 validation: 0.735593
09/16 09:41:00 AM: edges-ner-ontonotes_f1: training: 0.736716 validation: 0.812105
09/16 09:41:00 AM: Global learning rate: 0.0001
09/16 09:41:00 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:41:09 AM: Update 16126: task edges-ner-ontonotes, batch 126 (16126): mcc: 0.7422, acc: 0.6350, precision: 0.8470, recall: 0.6724, f1: 0.7497, edges-ner-ontonotes_loss: 0.0696
09/16 09:41:19 AM: Update 16239: task edges-ner-ontonotes, batch 239 (16239): mcc: 0.7477, acc: 0.6406, precision: 0.8499, recall: 0.6796, f1: 0.7553, edges-ner-ontonotes_loss: 0.0677
09/16 09:41:29 AM: Update 16384: task edges-ner-ontonotes, batch 384 (16384): mcc: 0.7570, acc: 0.6520, precision: 0.8538, recall: 0.6925, f1: 0.7647, edges-ner-ontonotes_loss: 0.0655
09/16 09:41:41 AM: Update 16500: task edges-ner-ontonotes, batch 500 (16500): mcc: 0.7596, acc: 0.6550, precision: 0.8555, recall: 0.6956, f1: 0.7673, edges-ner-ontonotes_loss: 0.0647
09/16 09:41:51 AM: Update 16634: task edges-ner-ontonotes, batch 634 (16634): mcc: 0.7615, acc: 0.6569, precision: 0.8564, recall: 0.6981, f1: 0.7692, edges-ner-ontonotes_loss: 0.0642
09/16 09:42:01 AM: Update 16766: task edges-ner-ontonotes, batch 766 (16766): mcc: 0.7608, acc: 0.6554, precision: 0.8559, recall: 0.6974, f1: 0.7685, edges-ner-ontonotes_loss: 0.0641
09/16 09:42:11 AM: Update 16883: task edges-ner-ontonotes, batch 883 (16883): mcc: 0.7539, acc: 0.6471, precision: 0.8514, recall: 0.6892, f1: 0.7618, edges-ner-ontonotes_loss: 0.0658
09/16 09:42:20 AM: ***** Step 17000 / Validation 17 *****
09/16 09:42:20 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:42:20 AM: Validating...
09/16 09:42:21 AM: Evaluate: task edges-ner-ontonotes, batch 17 (157): mcc: 0.7433, acc: 0.6372, precision: 0.8691, recall: 0.6564, f1: 0.7479, edges-ner-ontonotes_loss: 0.0667
09/16 09:42:31 AM: Evaluate: task edges-ner-ontonotes, batch 105 (157): mcc: 0.8040, acc: 0.7052, precision: 0.9120, recall: 0.7255, f1: 0.8082, edges-ner-ontonotes_loss: 0.0570
09/16 09:42:38 AM: Updating LR scheduler:
09/16 09:42:38 AM: 	Best result seen so far for macro_avg: 0.812
09/16 09:42:38 AM: 	# validation passes without improvement: 1
09/16 09:42:38 AM: edges-ner-ontonotes_loss: training: 0.067885 validation: 0.055416
09/16 09:42:38 AM: macro_avg: validation: 0.806379
09/16 09:42:38 AM: micro_avg: validation: 0.000000
09/16 09:42:38 AM: edges-ner-ontonotes_mcc: training: 0.747629 validation: 0.802690
09/16 09:42:38 AM: edges-ner-ontonotes_acc: training: 0.639209 validation: 0.700864
09/16 09:42:38 AM: edges-ner-ontonotes_precision: training: 0.847663 validation: 0.915006
09/16 09:42:38 AM: edges-ner-ontonotes_recall: training: 0.681340 validation: 0.720807
09/16 09:42:38 AM: edges-ner-ontonotes_f1: training: 0.755455 validation: 0.806379
09/16 09:42:38 AM: Global learning rate: 0.0001
09/16 09:42:38 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:42:41 AM: Update 17049: task edges-ner-ontonotes, batch 49 (17049): mcc: 0.6876, acc: 0.5626, precision: 0.8069, recall: 0.6114, f1: 0.6957, edges-ner-ontonotes_loss: 0.0851
09/16 09:42:51 AM: Update 17176: task edges-ner-ontonotes, batch 176 (17176): mcc: 0.7101, acc: 0.5894, precision: 0.8225, recall: 0.6371, f1: 0.7181, edges-ner-ontonotes_loss: 0.0788
09/16 09:43:01 AM: Update 17343: task edges-ner-ontonotes, batch 343 (17343): mcc: 0.7170, acc: 0.5981, precision: 0.8301, recall: 0.6430, f1: 0.7246, edges-ner-ontonotes_loss: 0.0757
09/16 09:43:11 AM: Update 17470: task edges-ner-ontonotes, batch 470 (17470): mcc: 0.7194, acc: 0.6010, precision: 0.8318, recall: 0.6456, f1: 0.7270, edges-ner-ontonotes_loss: 0.0749
09/16 09:43:21 AM: Update 17607: task edges-ner-ontonotes, batch 607 (17607): mcc: 0.7264, acc: 0.6107, precision: 0.8360, recall: 0.6542, f1: 0.7340, edges-ner-ontonotes_loss: 0.0735
09/16 09:43:32 AM: Update 17743: task edges-ner-ontonotes, batch 743 (17743): mcc: 0.7296, acc: 0.6149, precision: 0.8376, recall: 0.6585, f1: 0.7373, edges-ner-ontonotes_loss: 0.0724
09/16 09:43:42 AM: Update 17874: task edges-ner-ontonotes, batch 874 (17874): mcc: 0.7363, acc: 0.6229, precision: 0.8421, recall: 0.6664, f1: 0.7440, edges-ner-ontonotes_loss: 0.0710
09/16 09:43:52 AM: ***** Step 18000 / Validation 18 *****
09/16 09:43:52 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:43:52 AM: Validating...
09/16 09:43:52 AM: Evaluate: task edges-ner-ontonotes, batch 3 (157): mcc: 0.6139, acc: 0.5196, precision: 0.7466, recall: 0.5343, f1: 0.6229, edges-ner-ontonotes_loss: 0.1018
09/16 09:44:02 AM: Evaluate: task edges-ner-ontonotes, batch 86 (157): mcc: 0.7880, acc: 0.6975, precision: 0.8837, recall: 0.7215, f1: 0.7944, edges-ner-ontonotes_loss: 0.0622
09/16 09:44:11 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:44:11 AM: Best result seen so far for macro.
09/16 09:44:11 AM: Updating LR scheduler:
09/16 09:44:11 AM: 	Best result seen so far for macro_avg: 0.813
09/16 09:44:11 AM: 	# validation passes without improvement: 0
09/16 09:44:11 AM: edges-ner-ontonotes_loss: training: 0.069592 validation: 0.055446
09/16 09:44:11 AM: macro_avg: validation: 0.813321
09/16 09:44:11 AM: micro_avg: validation: 0.000000
09/16 09:44:11 AM: edges-ner-ontonotes_mcc: training: 0.742748 validation: 0.807647
09/16 09:44:11 AM: edges-ner-ontonotes_acc: training: 0.630669 validation: 0.718153
09/16 09:44:11 AM: edges-ner-ontonotes_precision: training: 0.846167 validation: 0.900313
09/16 09:44:11 AM: edges-ner-ontonotes_recall: training: 0.674108 validation: 0.741659
09/16 09:44:11 AM: edges-ner-ontonotes_f1: training: 0.750401 validation: 0.813321
09/16 09:44:11 AM: Global learning rate: 0.0001
09/16 09:44:11 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:44:13 AM: Update 18001: task edges-ner-ontonotes, batch 1 (18001): mcc: 0.7285, acc: 0.6026, precision: 0.8254, recall: 0.6667, f1: 0.7376, edges-ner-ontonotes_loss: 0.0670
09/16 09:44:23 AM: Update 18109: task edges-ner-ontonotes, batch 109 (18109): mcc: 0.7652, acc: 0.6629, precision: 0.8563, recall: 0.7048, f1: 0.7732, edges-ner-ontonotes_loss: 0.0625
09/16 09:44:34 AM: Update 18243: task edges-ner-ontonotes, batch 243 (18243): mcc: 0.7663, acc: 0.6632, precision: 0.8575, recall: 0.7057, f1: 0.7742, edges-ner-ontonotes_loss: 0.0625
09/16 09:44:44 AM: Update 18369: task edges-ner-ontonotes, batch 369 (18369): mcc: 0.7626, acc: 0.6589, precision: 0.8540, recall: 0.7021, f1: 0.7706, edges-ner-ontonotes_loss: 0.0632
09/16 09:44:54 AM: Update 18496: task edges-ner-ontonotes, batch 496 (18496): mcc: 0.7427, acc: 0.6336, precision: 0.8422, recall: 0.6774, f1: 0.7508, edges-ner-ontonotes_loss: 0.0689
09/16 09:45:04 AM: Update 18638: task edges-ner-ontonotes, batch 638 (18638): mcc: 0.7353, acc: 0.6241, precision: 0.8371, recall: 0.6687, f1: 0.7435, edges-ner-ontonotes_loss: 0.0715
09/16 09:45:14 AM: Update 18759: task edges-ner-ontonotes, batch 759 (18759): mcc: 0.7323, acc: 0.6201, precision: 0.8352, recall: 0.6652, f1: 0.7406, edges-ner-ontonotes_loss: 0.0724
09/16 09:45:24 AM: Update 18926: task edges-ner-ontonotes, batch 926 (18926): mcc: 0.7335, acc: 0.6214, precision: 0.8369, recall: 0.6657, f1: 0.7416, edges-ner-ontonotes_loss: 0.0721
09/16 09:45:31 AM: ***** Step 19000 / Validation 19 *****
09/16 09:45:31 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:45:31 AM: Validating...
09/16 09:45:35 AM: Evaluate: task edges-ner-ontonotes, batch 34 (157): mcc: 0.7747, acc: 0.6783, precision: 0.8724, recall: 0.7076, f1: 0.7814, edges-ner-ontonotes_loss: 0.0635
09/16 09:45:45 AM: Evaluate: task edges-ner-ontonotes, batch 114 (157): mcc: 0.8108, acc: 0.7178, precision: 0.9062, recall: 0.7422, f1: 0.8160, edges-ner-ontonotes_loss: 0.0550
09/16 09:45:50 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:45:50 AM: Best result seen so far for macro.
09/16 09:45:50 AM: Updating LR scheduler:
09/16 09:45:50 AM: 	Best result seen so far for macro_avg: 0.817
09/16 09:45:50 AM: 	# validation passes without improvement: 0
09/16 09:45:50 AM: edges-ner-ontonotes_loss: training: 0.072153 validation: 0.053567
09/16 09:45:50 AM: macro_avg: validation: 0.817457
09/16 09:45:50 AM: micro_avg: validation: 0.000000
09/16 09:45:50 AM: edges-ner-ontonotes_mcc: training: 0.733002 validation: 0.812415
09/16 09:45:50 AM: edges-ner-ontonotes_acc: training: 0.620576 validation: 0.718229
09/16 09:45:50 AM: edges-ner-ontonotes_precision: training: 0.836979 validation: 0.908804
09/16 09:45:50 AM: edges-ner-ontonotes_recall: training: 0.664855 validation: 0.742796
09/16 09:45:50 AM: edges-ner-ontonotes_f1: training: 0.741054 validation: 0.817457
09/16 09:45:50 AM: Global learning rate: 0.0001
09/16 09:45:50 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:45:55 AM: Update 19066: task edges-ner-ontonotes, batch 66 (19066): mcc: 0.7466, acc: 0.6411, precision: 0.8455, recall: 0.6814, f1: 0.7546, edges-ner-ontonotes_loss: 0.0679
09/16 09:46:05 AM: Update 19196: task edges-ner-ontonotes, batch 196 (19196): mcc: 0.7414, acc: 0.6346, precision: 0.8421, recall: 0.6752, f1: 0.7495, edges-ner-ontonotes_loss: 0.0685
09/16 09:46:15 AM: Update 19305: task edges-ner-ontonotes, batch 305 (19305): mcc: 0.7417, acc: 0.6340, precision: 0.8429, recall: 0.6750, f1: 0.7497, edges-ner-ontonotes_loss: 0.0684
09/16 09:46:25 AM: Update 19435: task edges-ner-ontonotes, batch 435 (19435): mcc: 0.7511, acc: 0.6456, precision: 0.8484, recall: 0.6868, f1: 0.7591, edges-ner-ontonotes_loss: 0.0664
09/16 09:46:35 AM: Update 19569: task edges-ner-ontonotes, batch 569 (19569): mcc: 0.7584, acc: 0.6541, precision: 0.8530, recall: 0.6956, f1: 0.7663, edges-ner-ontonotes_loss: 0.0647
09/16 09:46:45 AM: Update 19686: task edges-ner-ontonotes, batch 686 (19686): mcc: 0.7599, acc: 0.6554, precision: 0.8535, recall: 0.6978, f1: 0.7679, edges-ner-ontonotes_loss: 0.0643
09/16 09:46:55 AM: Update 19814: task edges-ner-ontonotes, batch 814 (19814): mcc: 0.7609, acc: 0.6563, precision: 0.8540, recall: 0.6991, f1: 0.7688, edges-ner-ontonotes_loss: 0.0640
09/16 09:47:05 AM: Update 19925: task edges-ner-ontonotes, batch 925 (19925): mcc: 0.7615, acc: 0.6570, precision: 0.8545, recall: 0.6998, f1: 0.7694, edges-ner-ontonotes_loss: 0.0638
09/16 09:47:10 AM: ***** Step 20000 / Validation 20 *****
09/16 09:47:10 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:47:10 AM: Validating...
09/16 09:47:15 AM: Evaluate: task edges-ner-ontonotes, batch 50 (157): mcc: 0.7896, acc: 0.6894, precision: 0.8913, recall: 0.7178, f1: 0.7952, edges-ner-ontonotes_loss: 0.0600
09/16 09:47:25 AM: Evaluate: task edges-ner-ontonotes, batch 127 (157): mcc: 0.8108, acc: 0.7117, precision: 0.9171, recall: 0.7330, f1: 0.8148, edges-ner-ontonotes_loss: 0.0548
09/16 09:47:29 AM: Updating LR scheduler:
09/16 09:47:31 AM: 	Best result seen so far for macro_avg: 0.817
09/16 09:47:31 AM: 	# validation passes without improvement: 1
09/16 09:47:31 AM: edges-ner-ontonotes_loss: training: 0.065466 validation: 0.053943
09/16 09:47:31 AM: macro_avg: validation: 0.813841
09/16 09:47:31 AM: micro_avg: validation: 0.000000
09/16 09:47:31 AM: edges-ner-ontonotes_mcc: training: 0.756043 validation: 0.809780
09/16 09:47:31 AM: edges-ner-ontonotes_acc: training: 0.650235 validation: 0.710267
09/16 09:47:31 AM: edges-ner-ontonotes_precision: training: 0.850809 validation: 0.916121
09/16 09:47:31 AM: edges-ner-ontonotes_recall: training: 0.693376 validation: 0.732105
09/16 09:47:31 AM: edges-ner-ontonotes_f1: training: 0.764067 validation: 0.813841
09/16 09:47:31 AM: Global learning rate: 0.0001
09/16 09:47:31 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:47:35 AM: Update 20061: task edges-ner-ontonotes, batch 61 (20061): mcc: 0.7010, acc: 0.5814, precision: 0.8163, recall: 0.6267, f1: 0.7090, edges-ner-ontonotes_loss: 0.0820
09/16 09:47:45 AM: Update 20189: task edges-ner-ontonotes, batch 189 (20189): mcc: 0.6970, acc: 0.5778, precision: 0.8128, recall: 0.6228, f1: 0.7052, edges-ner-ontonotes_loss: 0.0807
09/16 09:47:56 AM: Update 20312: task edges-ner-ontonotes, batch 312 (20312): mcc: 0.7048, acc: 0.5861, precision: 0.8186, recall: 0.6314, f1: 0.7129, edges-ner-ontonotes_loss: 0.0787
09/16 09:48:06 AM: Update 20477: task edges-ner-ontonotes, batch 477 (20477): mcc: 0.7139, acc: 0.5965, precision: 0.8261, recall: 0.6409, f1: 0.7218, edges-ner-ontonotes_loss: 0.0761
09/16 09:48:16 AM: Update 20597: task edges-ner-ontonotes, batch 597 (20597): mcc: 0.7182, acc: 0.6021, precision: 0.8285, recall: 0.6463, f1: 0.7261, edges-ner-ontonotes_loss: 0.0749
09/16 09:48:26 AM: Update 20737: task edges-ner-ontonotes, batch 737 (20737): mcc: 0.7241, acc: 0.6093, precision: 0.8329, recall: 0.6529, f1: 0.7320, edges-ner-ontonotes_loss: 0.0735
09/16 09:48:36 AM: Update 20855: task edges-ner-ontonotes, batch 855 (20855): mcc: 0.7267, acc: 0.6129, precision: 0.8341, recall: 0.6564, f1: 0.7346, edges-ner-ontonotes_loss: 0.0730
09/16 09:48:46 AM: Update 20983: task edges-ner-ontonotes, batch 983 (20983): mcc: 0.7341, acc: 0.6216, precision: 0.8390, recall: 0.6651, f1: 0.7420, edges-ner-ontonotes_loss: 0.0712
09/16 09:48:47 AM: ***** Step 21000 / Validation 21 *****
09/16 09:48:47 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:48:47 AM: Validating...
09/16 09:48:56 AM: Evaluate: task edges-ner-ontonotes, batch 81 (157): mcc: 0.7910, acc: 0.7015, precision: 0.8829, recall: 0.7273, f1: 0.7976, edges-ner-ontonotes_loss: 0.0622
09/16 09:49:06 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:49:06 AM: Best result seen so far for macro.
09/16 09:49:06 AM: Updating LR scheduler:
09/16 09:49:06 AM: 	Best result seen so far for macro_avg: 0.818
09/16 09:49:06 AM: 	# validation passes without improvement: 0
09/16 09:49:06 AM: edges-ner-ontonotes_loss: training: 0.071033 validation: 0.055110
09/16 09:49:06 AM: macro_avg: validation: 0.817734
09/16 09:49:06 AM: micro_avg: validation: 0.000000
09/16 09:49:06 AM: edges-ner-ontonotes_mcc: training: 0.735044 validation: 0.811765
09/16 09:49:06 AM: edges-ner-ontonotes_acc: training: 0.622599 validation: 0.724977
09/16 09:49:06 AM: edges-ner-ontonotes_precision: training: 0.839652 validation: 0.899463
09/16 09:49:06 AM: edges-ner-ontonotes_recall: training: 0.666171 validation: 0.749621
09/16 09:49:06 AM: edges-ner-ontonotes_f1: training: 0.742919 validation: 0.817734
09/16 09:49:06 AM: Global learning rate: 0.0001
09/16 09:49:06 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:49:07 AM: Update 21001: task edges-ner-ontonotes, batch 1 (21001): mcc: 0.8212, acc: 0.7200, precision: 0.8953, recall: 0.7700, f1: 0.8280, edges-ner-ontonotes_loss: 0.0556
09/16 09:49:17 AM: Update 21130: task edges-ner-ontonotes, batch 130 (21130): mcc: 0.7712, acc: 0.6698, precision: 0.8596, recall: 0.7124, f1: 0.7791, edges-ner-ontonotes_loss: 0.0605
09/16 09:49:27 AM: Update 21243: task edges-ner-ontonotes, batch 243 (21243): mcc: 0.7711, acc: 0.6693, precision: 0.8599, recall: 0.7121, f1: 0.7790, edges-ner-ontonotes_loss: 0.0613
09/16 09:49:37 AM: Update 21381: task edges-ner-ontonotes, batch 381 (21381): mcc: 0.7681, acc: 0.6661, precision: 0.8565, recall: 0.7096, f1: 0.7762, edges-ner-ontonotes_loss: 0.0618
09/16 09:49:47 AM: Update 21499: task edges-ner-ontonotes, batch 499 (21499): mcc: 0.7640, acc: 0.6611, precision: 0.8535, recall: 0.7051, f1: 0.7722, edges-ner-ontonotes_loss: 0.0628
09/16 09:49:57 AM: Update 21639: task edges-ner-ontonotes, batch 639 (21639): mcc: 0.7507, acc: 0.6440, precision: 0.8449, recall: 0.6891, f1: 0.7591, edges-ner-ontonotes_loss: 0.0674
09/16 09:50:07 AM: Update 21778: task edges-ner-ontonotes, batch 778 (21778): mcc: 0.7424, acc: 0.6327, precision: 0.8400, recall: 0.6787, f1: 0.7507, edges-ner-ontonotes_loss: 0.0700
09/16 09:50:17 AM: Update 21922: task edges-ner-ontonotes, batch 922 (21922): mcc: 0.7408, acc: 0.6306, precision: 0.8397, recall: 0.6762, f1: 0.7491, edges-ner-ontonotes_loss: 0.0703
09/16 09:50:22 AM: ***** Step 22000 / Validation 22 *****
09/16 09:50:22 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:50:22 AM: Validating...
09/16 09:50:28 AM: Evaluate: task edges-ner-ontonotes, batch 49 (157): mcc: 0.7974, acc: 0.7038, precision: 0.8939, recall: 0.7291, f1: 0.8032, edges-ner-ontonotes_loss: 0.0584
09/16 09:50:39 AM: Evaluate: task edges-ner-ontonotes, batch 125 (157): mcc: 0.8113, acc: 0.7163, precision: 0.9146, recall: 0.7361, f1: 0.8157, edges-ner-ontonotes_loss: 0.0543
09/16 09:50:42 AM: Updating LR scheduler:
09/16 09:50:44 AM: 	Best result seen so far for macro_avg: 0.818
09/16 09:50:44 AM: 	# validation passes without improvement: 1
09/16 09:50:44 AM: edges-ner-ontonotes_loss: training: 0.070487 validation: 0.053509
09/16 09:50:44 AM: macro_avg: validation: 0.814970
09/16 09:50:44 AM: micro_avg: validation: 0.000000
09/16 09:50:44 AM: edges-ner-ontonotes_mcc: training: 0.740136 validation: 0.810563
09/16 09:50:44 AM: edges-ner-ontonotes_acc: training: 0.629741 validation: 0.714816
09/16 09:50:44 AM: edges-ner-ontonotes_precision: training: 0.839467 validation: 0.913551
09/16 09:50:44 AM: edges-ner-ontonotes_recall: training: 0.675176 validation: 0.735593
09/16 09:50:44 AM: edges-ner-ontonotes_f1: training: 0.748411 validation: 0.814970
09/16 09:50:44 AM: Global learning rate: 0.0001
09/16 09:50:44 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:50:49 AM: Update 22071: task edges-ner-ontonotes, batch 71 (22071): mcc: 0.7507, acc: 0.6382, precision: 0.8570, recall: 0.6789, f1: 0.7576, edges-ner-ontonotes_loss: 0.0675
09/16 09:50:59 AM: Update 22180: task edges-ner-ontonotes, batch 180 (22180): mcc: 0.7457, acc: 0.6358, precision: 0.8471, recall: 0.6784, f1: 0.7534, edges-ner-ontonotes_loss: 0.0678
09/16 09:51:09 AM: Update 22314: task edges-ner-ontonotes, batch 314 (22314): mcc: 0.7476, acc: 0.6382, precision: 0.8471, recall: 0.6818, f1: 0.7555, edges-ner-ontonotes_loss: 0.0677
09/16 09:51:19 AM: Update 22432: task edges-ner-ontonotes, batch 432 (22432): mcc: 0.7466, acc: 0.6367, precision: 0.8461, recall: 0.6808, f1: 0.7545, edges-ner-ontonotes_loss: 0.0677
09/16 09:51:29 AM: Update 22562: task edges-ner-ontonotes, batch 562 (22562): mcc: 0.7533, acc: 0.6451, precision: 0.8499, recall: 0.6894, f1: 0.7613, edges-ner-ontonotes_loss: 0.0662
09/16 09:51:39 AM: Update 22691: task edges-ner-ontonotes, batch 691 (22691): mcc: 0.7583, acc: 0.6517, precision: 0.8529, recall: 0.6955, f1: 0.7662, edges-ner-ontonotes_loss: 0.0649
09/16 09:51:49 AM: Update 22793: task edges-ner-ontonotes, batch 793 (22793): mcc: 0.7609, acc: 0.6544, precision: 0.8545, recall: 0.6988, f1: 0.7688, edges-ner-ontonotes_loss: 0.0643
09/16 09:51:59 AM: Update 22925: task edges-ner-ontonotes, batch 925 (22925): mcc: 0.7627, acc: 0.6565, precision: 0.8558, recall: 0.7008, f1: 0.7706, edges-ner-ontonotes_loss: 0.0639
09/16 09:52:05 AM: ***** Step 23000 / Validation 23 *****
09/16 09:52:05 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:52:05 AM: Validating...
09/16 09:52:09 AM: Evaluate: task edges-ner-ontonotes, batch 45 (157): mcc: 0.7681, acc: 0.6733, precision: 0.8674, recall: 0.7005, f1: 0.7750, edges-ner-ontonotes_loss: 0.0664
09/16 09:52:19 AM: Evaluate: task edges-ner-ontonotes, batch 120 (157): mcc: 0.8089, acc: 0.7191, precision: 0.9017, recall: 0.7427, f1: 0.8145, edges-ner-ontonotes_loss: 0.0562
09/16 09:52:24 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:52:24 AM: Best result seen so far for macro.
09/16 09:52:24 AM: Updating LR scheduler:
09/16 09:52:24 AM: 	Best result seen so far for macro_avg: 0.822
09/16 09:52:24 AM: 	# validation passes without improvement: 0
09/16 09:52:24 AM: edges-ner-ontonotes_loss: training: 0.063900 validation: 0.053629
09/16 09:52:24 AM: macro_avg: validation: 0.821709
09/16 09:52:24 AM: micro_avg: validation: 0.000000
09/16 09:52:24 AM: edges-ner-ontonotes_mcc: training: 0.762820 validation: 0.816306
09/16 09:52:24 AM: edges-ner-ontonotes_acc: training: 0.656883 validation: 0.727783
09/16 09:52:24 AM: edges-ner-ontonotes_precision: training: 0.855580 validation: 0.907358
09/16 09:52:24 AM: edges-ner-ontonotes_recall: training: 0.701192 validation: 0.750834
09/16 09:52:24 AM: edges-ner-ontonotes_f1: training: 0.770730 validation: 0.821709
09/16 09:52:24 AM: Global learning rate: 0.0001
09/16 09:52:24 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:52:29 AM: Update 23051: task edges-ner-ontonotes, batch 51 (23051): mcc: 0.7232, acc: 0.6137, precision: 0.8186, recall: 0.6631, f1: 0.7327, edges-ner-ontonotes_loss: 0.0720
09/16 09:52:39 AM: Update 23194: task edges-ner-ontonotes, batch 194 (23194): mcc: 0.7014, acc: 0.5855, precision: 0.8068, recall: 0.6351, f1: 0.7107, edges-ner-ontonotes_loss: 0.0815
09/16 09:52:50 AM: Update 23336: task edges-ner-ontonotes, batch 336 (23336): mcc: 0.6991, acc: 0.5817, precision: 0.8085, recall: 0.6298, f1: 0.7081, edges-ner-ontonotes_loss: 0.0817
09/16 09:53:00 AM: Update 23461: task edges-ner-ontonotes, batch 461 (23461): mcc: 0.7082, acc: 0.5918, precision: 0.8162, recall: 0.6391, f1: 0.7169, edges-ner-ontonotes_loss: 0.0789
09/16 09:53:10 AM: Update 23624: task edges-ner-ontonotes, batch 624 (23624): mcc: 0.7147, acc: 0.5990, precision: 0.8226, recall: 0.6451, f1: 0.7231, edges-ner-ontonotes_loss: 0.0768
09/16 09:53:20 AM: Update 23738: task edges-ner-ontonotes, batch 738 (23738): mcc: 0.7196, acc: 0.6049, precision: 0.8271, recall: 0.6498, f1: 0.7278, edges-ner-ontonotes_loss: 0.0754
09/16 09:53:30 AM: Update 23881: task edges-ner-ontonotes, batch 881 (23881): mcc: 0.7243, acc: 0.6111, precision: 0.8298, recall: 0.6558, f1: 0.7326, edges-ner-ontonotes_loss: 0.0742
09/16 09:53:40 AM: Update 23986: task edges-ner-ontonotes, batch 986 (23986): mcc: 0.7266, acc: 0.6140, precision: 0.8314, recall: 0.6583, f1: 0.7348, edges-ner-ontonotes_loss: 0.0735
09/16 09:53:41 AM: ***** Step 24000 / Validation 24 *****
09/16 09:53:41 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:53:41 AM: Validating...
09/16 09:53:50 AM: Evaluate: task edges-ner-ontonotes, batch 80 (157): mcc: 0.8012, acc: 0.7109, precision: 0.8987, recall: 0.7317, f1: 0.8067, edges-ner-ontonotes_loss: 0.0589
09/16 09:54:00 AM: Evaluate: task edges-ner-ontonotes, batch 155 (157): mcc: 0.8185, acc: 0.7291, precision: 0.9127, recall: 0.7501, f1: 0.8235, edges-ner-ontonotes_loss: 0.0532
09/16 09:54:00 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:54:00 AM: Best result seen so far for macro.
09/16 09:54:00 AM: Updating LR scheduler:
09/16 09:54:00 AM: 	Best result seen so far for macro_avg: 0.823
09/16 09:54:00 AM: 	# validation passes without improvement: 0
09/16 09:54:00 AM: edges-ner-ontonotes_loss: training: 0.073330 validation: 0.053114
09/16 09:54:00 AM: macro_avg: validation: 0.823113
09/16 09:54:00 AM: micro_avg: validation: 0.000000
09/16 09:54:00 AM: edges-ner-ontonotes_mcc: training: 0.727233 validation: 0.818151
09/16 09:54:00 AM: edges-ner-ontonotes_acc: training: 0.614828 validation: 0.728465
09/16 09:54:00 AM: edges-ner-ontonotes_precision: training: 0.831849 validation: 0.912582
09/16 09:54:00 AM: edges-ner-ontonotes_recall: training: 0.659121 validation: 0.749621
09/16 09:54:00 AM: edges-ner-ontonotes_f1: training: 0.735480 validation: 0.823113
09/16 09:54:00 AM: Global learning rate: 0.0001
09/16 09:54:00 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:54:10 AM: Update 24123: task edges-ner-ontonotes, batch 123 (24123): mcc: 0.7717, acc: 0.6686, precision: 0.8604, recall: 0.7126, f1: 0.7796, edges-ner-ontonotes_loss: 0.0603
09/16 09:54:20 AM: Update 24260: task edges-ner-ontonotes, batch 260 (24260): mcc: 0.7754, acc: 0.6733, precision: 0.8627, recall: 0.7173, f1: 0.7833, edges-ner-ontonotes_loss: 0.0600
09/16 09:54:30 AM: Update 24363: task edges-ner-ontonotes, batch 363 (24363): mcc: 0.7699, acc: 0.6664, precision: 0.8580, recall: 0.7115, f1: 0.7779, edges-ner-ontonotes_loss: 0.0611
09/16 09:54:40 AM: Update 24495: task edges-ner-ontonotes, batch 495 (24495): mcc: 0.7714, acc: 0.6682, precision: 0.8591, recall: 0.7133, f1: 0.7794, edges-ner-ontonotes_loss: 0.0611
09/16 09:54:50 AM: Update 24617: task edges-ner-ontonotes, batch 617 (24617): mcc: 0.7678, acc: 0.6644, precision: 0.8559, recall: 0.7097, f1: 0.7760, edges-ner-ontonotes_loss: 0.0621
09/16 09:55:00 AM: Update 24751: task edges-ner-ontonotes, batch 751 (24751): mcc: 0.7555, acc: 0.6491, precision: 0.8479, recall: 0.6948, f1: 0.7638, edges-ner-ontonotes_loss: 0.0662
09/16 09:55:10 AM: Update 24888: task edges-ner-ontonotes, batch 888 (24888): mcc: 0.7481, acc: 0.6395, precision: 0.8434, recall: 0.6858, f1: 0.7565, edges-ner-ontonotes_loss: 0.0684
09/16 09:55:19 AM: ***** Step 25000 / Validation 25 *****
09/16 09:55:19 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:55:19 AM: Validating...
09/16 09:55:20 AM: Evaluate: task edges-ner-ontonotes, batch 14 (157): mcc: 0.7438, acc: 0.6390, precision: 0.8592, recall: 0.6652, f1: 0.7498, edges-ner-ontonotes_loss: 0.0670
09/16 09:55:30 AM: Evaluate: task edges-ner-ontonotes, batch 100 (157): mcc: 0.8118, acc: 0.7178, precision: 0.9105, recall: 0.7403, f1: 0.8166, edges-ner-ontonotes_loss: 0.0548
09/16 09:55:37 AM: Updating LR scheduler:
09/16 09:55:37 AM: 	Best result seen so far for macro_avg: 0.823
09/16 09:55:37 AM: 	# validation passes without improvement: 1
09/16 09:55:37 AM: edges-ner-ontonotes_loss: training: 0.068919 validation: 0.052839
09/16 09:55:37 AM: macro_avg: validation: 0.817785
09/16 09:55:37 AM: micro_avg: validation: 0.000000
09/16 09:55:37 AM: edges-ner-ontonotes_mcc: training: 0.745947 validation: 0.813378
09/16 09:55:37 AM: edges-ner-ontonotes_acc: training: 0.636759 validation: 0.717698
09/16 09:55:37 AM: edges-ner-ontonotes_precision: training: 0.842616 validation: 0.915133
09/16 09:55:37 AM: edges-ner-ontonotes_recall: training: 0.682661 validation: 0.739157
09/16 09:55:37 AM: edges-ner-ontonotes_f1: training: 0.754251 validation: 0.817785
09/16 09:55:37 AM: Global learning rate: 0.0001
09/16 09:55:37 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:55:40 AM: Update 25042: task edges-ner-ontonotes, batch 42 (25042): mcc: 0.7282, acc: 0.6179, precision: 0.8395, recall: 0.6545, f1: 0.7355, edges-ner-ontonotes_loss: 0.0717
09/16 09:55:50 AM: Update 25208: task edges-ner-ontonotes, batch 208 (25208): mcc: 0.7378, acc: 0.6246, precision: 0.8412, recall: 0.6697, f1: 0.7457, edges-ner-ontonotes_loss: 0.0694
09/16 09:56:00 AM: Update 25315: task edges-ner-ontonotes, batch 315 (25315): mcc: 0.7346, acc: 0.6226, precision: 0.8368, recall: 0.6678, f1: 0.7428, edges-ner-ontonotes_loss: 0.0701
09/16 09:56:10 AM: Update 25459: task edges-ner-ontonotes, batch 459 (25459): mcc: 0.7423, acc: 0.6321, precision: 0.8415, recall: 0.6773, f1: 0.7505, edges-ner-ontonotes_loss: 0.0685
09/16 09:56:20 AM: Update 25563: task edges-ner-ontonotes, batch 563 (25563): mcc: 0.7452, acc: 0.6361, precision: 0.8437, recall: 0.6804, f1: 0.7533, edges-ner-ontonotes_loss: 0.0681
09/16 09:56:30 AM: Update 25700: task edges-ner-ontonotes, batch 700 (25700): mcc: 0.7522, acc: 0.6448, precision: 0.8475, recall: 0.6893, f1: 0.7603, edges-ner-ontonotes_loss: 0.0664
09/16 09:56:41 AM: Update 25830: task edges-ner-ontonotes, batch 830 (25830): mcc: 0.7570, acc: 0.6509, precision: 0.8503, recall: 0.6955, f1: 0.7652, edges-ner-ontonotes_loss: 0.0652
09/16 09:56:51 AM: Update 25944: task edges-ner-ontonotes, batch 944 (25944): mcc: 0.7586, acc: 0.6530, precision: 0.8516, recall: 0.6972, f1: 0.7667, edges-ner-ontonotes_loss: 0.0649
09/16 09:56:55 AM: ***** Step 26000 / Validation 26 *****
09/16 09:56:55 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:56:55 AM: Validating...
09/16 09:57:01 AM: Evaluate: task edges-ner-ontonotes, batch 57 (157): mcc: 0.7862, acc: 0.6932, precision: 0.8783, recall: 0.7228, f1: 0.7930, edges-ner-ontonotes_loss: 0.0626
09/16 09:57:11 AM: Evaluate: task edges-ner-ontonotes, batch 133 (157): mcc: 0.8139, acc: 0.7250, precision: 0.9031, recall: 0.7503, f1: 0.8196, edges-ner-ontonotes_loss: 0.0547
09/16 09:57:13 AM: Updating LR scheduler:
09/16 09:57:13 AM: 	Best result seen so far for macro_avg: 0.823
09/16 09:57:13 AM: 	# validation passes without improvement: 2
09/16 09:57:13 AM: edges-ner-ontonotes_loss: training: 0.064620 validation: 0.053598
09/16 09:57:13 AM: macro_avg: validation: 0.821099
09/16 09:57:13 AM: micro_avg: validation: 0.000000
09/16 09:57:13 AM: edges-ner-ontonotes_mcc: training: 0.759855 validation: 0.815435
09/16 09:57:13 AM: edges-ner-ontonotes_acc: training: 0.654440 validation: 0.726570
09/16 09:57:13 AM: edges-ner-ontonotes_precision: training: 0.852563 validation: 0.904332
09/16 09:57:13 AM: edges-ner-ontonotes_recall: training: 0.698565 validation: 0.751896
09/16 09:57:13 AM: edges-ner-ontonotes_f1: training: 0.767919 validation: 0.821099
09/16 09:57:13 AM: Global learning rate: 0.0001
09/16 09:57:13 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:57:21 AM: Update 26093: task edges-ner-ontonotes, batch 93 (26093): mcc: 0.7703, acc: 0.6658, precision: 0.8542, recall: 0.7156, f1: 0.7788, edges-ner-ontonotes_loss: 0.0602
09/16 09:57:32 AM: Update 26193: task edges-ner-ontonotes, batch 193 (26193): mcc: 0.7443, acc: 0.6362, precision: 0.8368, recall: 0.6847, f1: 0.7531, edges-ner-ontonotes_loss: 0.0676
09/16 09:57:42 AM: Update 26331: task edges-ner-ontonotes, batch 331 (26331): mcc: 0.7279, acc: 0.6152, precision: 0.8272, recall: 0.6642, f1: 0.7368, edges-ner-ontonotes_loss: 0.0734
09/16 09:57:52 AM: Update 26453: task edges-ner-ontonotes, batch 453 (26453): mcc: 0.7219, acc: 0.6077, precision: 0.8235, recall: 0.6568, f1: 0.7307, edges-ner-ontonotes_loss: 0.0754
09/16 09:58:02 AM: Update 26615: task edges-ner-ontonotes, batch 615 (26615): mcc: 0.7242, acc: 0.6093, precision: 0.8274, recall: 0.6575, f1: 0.7328, edges-ner-ontonotes_loss: 0.0744
09/16 09:58:14 AM: Update 26766: task edges-ner-ontonotes, batch 766 (26766): mcc: 0.7269, acc: 0.6125, precision: 0.8304, recall: 0.6598, f1: 0.7353, edges-ner-ontonotes_loss: 0.0736
09/16 09:58:24 AM: Update 26895: task edges-ner-ontonotes, batch 895 (26895): mcc: 0.7300, acc: 0.6164, precision: 0.8331, recall: 0.6629, f1: 0.7383, edges-ner-ontonotes_loss: 0.0728
09/16 09:58:31 AM: ***** Step 27000 / Validation 27 *****
09/16 09:58:31 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:58:31 AM: Validating...
09/16 09:58:34 AM: Evaluate: task edges-ner-ontonotes, batch 23 (157): mcc: 0.7476, acc: 0.6548, precision: 0.8479, recall: 0.6811, f1: 0.7554, edges-ner-ontonotes_loss: 0.0684
09/16 09:58:47 AM: Evaluate: task edges-ner-ontonotes, batch 112 (157): mcc: 0.8187, acc: 0.7301, precision: 0.9117, recall: 0.7514, f1: 0.8238, edges-ner-ontonotes_loss: 0.0528
09/16 09:58:52 AM: Updating LR scheduler:
09/16 09:58:52 AM: 	Best result seen so far for macro_avg: 0.823
09/16 09:58:52 AM: 	# validation passes without improvement: 3
09/16 09:58:52 AM: edges-ner-ontonotes_loss: training: 0.072068 validation: 0.051764
09/16 09:58:52 AM: macro_avg: validation: 0.819909
09/16 09:58:52 AM: micro_avg: validation: 0.000000
09/16 09:58:52 AM: edges-ner-ontonotes_mcc: training: 0.731992 validation: 0.815096
09/16 09:58:52 AM: edges-ner-ontonotes_acc: training: 0.619444 validation: 0.723916
09/16 09:58:52 AM: edges-ner-ontonotes_precision: training: 0.834278 validation: 0.912369
09/16 09:58:52 AM: edges-ner-ontonotes_recall: training: 0.665355 validation: 0.744465
09/16 09:58:52 AM: edges-ner-ontonotes_f1: training: 0.740303 validation: 0.819909
09/16 09:58:52 AM: Global learning rate: 0.0001
09/16 09:58:52 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 09:58:57 AM: Update 27053: task edges-ner-ontonotes, batch 53 (27053): mcc: 0.7464, acc: 0.6393, precision: 0.8457, recall: 0.6808, f1: 0.7543, edges-ner-ontonotes_loss: 0.0690
09/16 09:59:07 AM: Update 27158: task edges-ner-ontonotes, batch 158 (27158): mcc: 0.7616, acc: 0.6569, precision: 0.8536, recall: 0.7007, f1: 0.7696, edges-ner-ontonotes_loss: 0.0645
09/16 09:59:17 AM: Update 27286: task edges-ner-ontonotes, batch 286 (27286): mcc: 0.7682, acc: 0.6643, precision: 0.8584, recall: 0.7082, f1: 0.7761, edges-ner-ontonotes_loss: 0.0620
09/16 09:59:27 AM: Update 27401: task edges-ner-ontonotes, batch 401 (27401): mcc: 0.7704, acc: 0.6667, precision: 0.8605, recall: 0.7103, f1: 0.7782, edges-ner-ontonotes_loss: 0.0613
09/16 09:59:37 AM: Update 27536: task edges-ner-ontonotes, batch 536 (27536): mcc: 0.7712, acc: 0.6676, precision: 0.8597, recall: 0.7124, f1: 0.7792, edges-ner-ontonotes_loss: 0.0611
09/16 09:59:47 AM: Update 27668: task edges-ner-ontonotes, batch 668 (27668): mcc: 0.7712, acc: 0.6677, precision: 0.8587, recall: 0.7133, f1: 0.7793, edges-ner-ontonotes_loss: 0.0610
09/16 09:59:57 AM: Update 27766: task edges-ner-ontonotes, batch 766 (27766): mcc: 0.7631, acc: 0.6577, precision: 0.8533, recall: 0.7037, f1: 0.7713, edges-ner-ontonotes_loss: 0.0627
09/16 10:00:07 AM: Update 27912: task edges-ner-ontonotes, batch 912 (27912): mcc: 0.7539, acc: 0.6462, precision: 0.8472, recall: 0.6926, f1: 0.7622, edges-ner-ontonotes_loss: 0.0662
09/16 10:00:13 AM: ***** Step 28000 / Validation 28 *****
09/16 10:00:13 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:00:13 AM: Validating...
09/16 10:00:17 AM: Evaluate: task edges-ner-ontonotes, batch 39 (157): mcc: 0.7847, acc: 0.6904, precision: 0.8751, recall: 0.7229, f1: 0.7917, edges-ner-ontonotes_loss: 0.0611
09/16 10:00:27 AM: Evaluate: task edges-ner-ontonotes, batch 116 (157): mcc: 0.8169, acc: 0.7253, precision: 0.9089, recall: 0.7506, f1: 0.8222, edges-ner-ontonotes_loss: 0.0539
09/16 10:00:32 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:00:32 AM: Best result seen so far for macro.
09/16 10:00:32 AM: Updating LR scheduler:
09/16 10:00:32 AM: 	Best result seen so far for macro_avg: 0.824
09/16 10:00:32 AM: 	# validation passes without improvement: 0
09/16 10:00:32 AM: edges-ner-ontonotes_loss: training: 0.067520 validation: 0.052139
09/16 10:00:32 AM: macro_avg: validation: 0.824156
09/16 10:00:32 AM: micro_avg: validation: 0.000000
09/16 10:00:32 AM: edges-ner-ontonotes_mcc: training: 0.750206 validation: 0.819150
09/16 10:00:32 AM: edges-ner-ontonotes_acc: training: 0.641507 validation: 0.726645
09/16 10:00:32 AM: edges-ner-ontonotes_precision: training: 0.844944 validation: 0.912675
09/16 10:00:32 AM: edges-ner-ontonotes_recall: training: 0.688137 validation: 0.751289
09/16 10:00:32 AM: edges-ner-ontonotes_f1: training: 0.758521 validation: 0.824156
09/16 10:00:32 AM: Global learning rate: 0.0001
09/16 10:00:32 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:00:37 AM: Update 28050: task edges-ner-ontonotes, batch 50 (28050): mcc: 0.7190, acc: 0.6014, precision: 0.8203, recall: 0.6544, f1: 0.7280, edges-ner-ontonotes_loss: 0.0762
09/16 10:00:47 AM: Update 28220: task edges-ner-ontonotes, batch 220 (28220): mcc: 0.7345, acc: 0.6180, precision: 0.8418, recall: 0.6634, f1: 0.7420, edges-ner-ontonotes_loss: 0.0718
09/16 10:00:57 AM: Update 28344: task edges-ner-ontonotes, batch 344 (28344): mcc: 0.7372, acc: 0.6226, precision: 0.8414, recall: 0.6685, f1: 0.7451, edges-ner-ontonotes_loss: 0.0706
09/16 10:01:07 AM: Update 28484: task edges-ner-ontonotes, batch 484 (28484): mcc: 0.7410, acc: 0.6292, precision: 0.8413, recall: 0.6751, f1: 0.7491, edges-ner-ontonotes_loss: 0.0698
09/16 10:01:17 AM: Update 28622: task edges-ner-ontonotes, batch 622 (28622): mcc: 0.7412, acc: 0.6307, precision: 0.8410, recall: 0.6758, f1: 0.7494, edges-ner-ontonotes_loss: 0.0693
09/16 10:01:27 AM: Update 28739: task edges-ner-ontonotes, batch 739 (28739): mcc: 0.7453, acc: 0.6362, precision: 0.8433, recall: 0.6809, f1: 0.7534, edges-ner-ontonotes_loss: 0.0681
09/16 10:01:37 AM: Update 28874: task edges-ner-ontonotes, batch 874 (28874): mcc: 0.7527, acc: 0.6451, precision: 0.8479, recall: 0.6900, f1: 0.7608, edges-ner-ontonotes_loss: 0.0665
09/16 10:01:47 AM: Update 28970: task edges-ner-ontonotes, batch 970 (28970): mcc: 0.7550, acc: 0.6477, precision: 0.8491, recall: 0.6929, f1: 0.7631, edges-ner-ontonotes_loss: 0.0660
09/16 10:01:50 AM: ***** Step 29000 / Validation 29 *****
09/16 10:01:50 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:01:50 AM: Validating...
09/16 10:01:58 AM: Evaluate: task edges-ner-ontonotes, batch 72 (157): mcc: 0.7825, acc: 0.6883, precision: 0.8754, recall: 0.7189, f1: 0.7894, edges-ner-ontonotes_loss: 0.0633
09/16 10:02:08 AM: Evaluate: task edges-ner-ontonotes, batch 154 (157): mcc: 0.8146, acc: 0.7259, precision: 0.8995, recall: 0.7545, f1: 0.8207, edges-ner-ontonotes_loss: 0.0534
09/16 10:02:08 AM: Updating LR scheduler:
09/16 10:02:08 AM: 	Best result seen so far for macro_avg: 0.824
09/16 10:02:08 AM: 	# validation passes without improvement: 1
09/16 10:02:08 AM: edges-ner-ontonotes_loss: training: 0.065832 validation: 0.053173
09/16 10:02:08 AM: macro_avg: validation: 0.820855
09/16 10:02:08 AM: micro_avg: validation: 0.000000
09/16 10:02:08 AM: edges-ner-ontonotes_mcc: training: 0.755822 validation: 0.814801
09/16 10:02:08 AM: edges-ner-ontonotes_acc: training: 0.648877 validation: 0.725963
09/16 10:02:08 AM: edges-ner-ontonotes_precision: training: 0.849622 validation: 0.900045
09/16 10:02:08 AM: edges-ner-ontonotes_recall: training: 0.693998 validation: 0.754474
09/16 10:02:08 AM: edges-ner-ontonotes_f1: training: 0.763965 validation: 0.820855
09/16 10:02:08 AM: Global learning rate: 0.0001
09/16 10:02:08 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:02:18 AM: Update 29129: task edges-ner-ontonotes, batch 129 (29129): mcc: 0.7695, acc: 0.6634, precision: 0.8561, recall: 0.7125, f1: 0.7777, edges-ner-ontonotes_loss: 0.0617
09/16 10:02:28 AM: Update 29258: task edges-ner-ontonotes, batch 258 (29258): mcc: 0.7731, acc: 0.6697, precision: 0.8591, recall: 0.7163, f1: 0.7812, edges-ner-ontonotes_loss: 0.0611
09/16 10:02:38 AM: Update 29379: task edges-ner-ontonotes, batch 379 (29379): mcc: 0.7480, acc: 0.6387, precision: 0.8421, recall: 0.6867, f1: 0.7565, edges-ner-ontonotes_loss: 0.0681
09/16 10:02:48 AM: Update 29517: task edges-ner-ontonotes, batch 517 (29517): mcc: 0.7377, acc: 0.6258, precision: 0.8356, recall: 0.6743, f1: 0.7463, edges-ner-ontonotes_loss: 0.0718
09/16 10:02:58 AM: Update 29646: task edges-ner-ontonotes, batch 646 (29646): mcc: 0.7348, acc: 0.6223, precision: 0.8338, recall: 0.6707, f1: 0.7434, edges-ner-ontonotes_loss: 0.0724
09/16 10:03:08 AM: Update 29812: task edges-ner-ontonotes, batch 812 (29812): mcc: 0.7358, acc: 0.6231, precision: 0.8354, recall: 0.6710, f1: 0.7442, edges-ner-ontonotes_loss: 0.0719
09/16 10:03:18 AM: Update 29928: task edges-ner-ontonotes, batch 928 (29928): mcc: 0.7357, acc: 0.6233, precision: 0.8356, recall: 0.6707, f1: 0.7441, edges-ner-ontonotes_loss: 0.0717
09/16 10:03:23 AM: ***** Step 30000 / Validation 30 *****
09/16 10:03:23 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:03:25 AM: Validating...
09/16 10:03:28 AM: Evaluate: task edges-ner-ontonotes, batch 34 (157): mcc: 0.7823, acc: 0.6891, precision: 0.8829, recall: 0.7122, f1: 0.7884, edges-ner-ontonotes_loss: 0.0607
09/16 10:03:38 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.8156, acc: 0.7205, precision: 0.9176, recall: 0.7409, f1: 0.8199, edges-ner-ontonotes_loss: 0.0535
09/16 10:03:43 AM: Updating LR scheduler:
09/16 10:03:43 AM: 	Best result seen so far for macro_avg: 0.824
09/16 10:03:43 AM: 	# validation passes without improvement: 2
09/16 10:03:43 AM: edges-ner-ontonotes_loss: training: 0.071291 validation: 0.051802
09/16 10:03:43 AM: macro_avg: validation: 0.820745
09/16 10:03:43 AM: micro_avg: validation: 0.000000
09/16 10:03:43 AM: edges-ner-ontonotes_mcc: training: 0.736688 validation: 0.816552
09/16 10:03:43 AM: edges-ner-ontonotes_acc: training: 0.624684 validation: 0.720200
09/16 10:03:43 AM: edges-ner-ontonotes_precision: training: 0.836343 validation: 0.918828
09/16 10:03:43 AM: edges-ner-ontonotes_recall: training: 0.671795 validation: 0.741583
09/16 10:03:43 AM: edges-ner-ontonotes_f1: training: 0.745092 validation: 0.820745
09/16 10:03:43 AM: Global learning rate: 0.0001
09/16 10:03:43 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:03:48 AM: Update 30070: task edges-ner-ontonotes, batch 70 (30070): mcc: 0.7531, acc: 0.6454, precision: 0.8440, recall: 0.6940, f1: 0.7617, edges-ner-ontonotes_loss: 0.0666
09/16 10:03:59 AM: Update 30191: task edges-ner-ontonotes, batch 191 (30191): mcc: 0.7492, acc: 0.6417, precision: 0.8445, recall: 0.6867, f1: 0.7575, edges-ner-ontonotes_loss: 0.0679
09/16 10:04:09 AM: Update 30324: task edges-ner-ontonotes, batch 324 (30324): mcc: 0.7600, acc: 0.6536, precision: 0.8524, recall: 0.6989, f1: 0.7681, edges-ner-ontonotes_loss: 0.0646
09/16 10:04:19 AM: Update 30452: task edges-ner-ontonotes, batch 452 (30452): mcc: 0.7658, acc: 0.6621, precision: 0.8550, recall: 0.7069, f1: 0.7739, edges-ner-ontonotes_loss: 0.0631
09/16 10:04:29 AM: Update 30568: task edges-ner-ontonotes, batch 568 (30568): mcc: 0.7655, acc: 0.6613, precision: 0.8551, recall: 0.7063, f1: 0.7736, edges-ner-ontonotes_loss: 0.0629
09/16 10:04:39 AM: Update 30702: task edges-ner-ontonotes, batch 702 (30702): mcc: 0.7676, acc: 0.6635, precision: 0.8559, recall: 0.7093, f1: 0.7758, edges-ner-ontonotes_loss: 0.0623
09/16 10:04:50 AM: Update 30817: task edges-ner-ontonotes, batch 817 (30817): mcc: 0.7680, acc: 0.6641, precision: 0.8558, recall: 0.7101, f1: 0.7762, edges-ner-ontonotes_loss: 0.0622
09/16 10:05:00 AM: Update 30948: task edges-ner-ontonotes, batch 948 (30948): mcc: 0.7573, acc: 0.6508, precision: 0.8486, recall: 0.6974, f1: 0.7656, edges-ner-ontonotes_loss: 0.0653
09/16 10:05:03 AM: ***** Step 31000 / Validation 31 *****
09/16 10:05:03 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:05:03 AM: Validating...
09/16 10:05:10 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.8123, acc: 0.7228, precision: 0.8991, recall: 0.7508, f1: 0.8183, edges-ner-ontonotes_loss: 0.0553
09/16 10:05:20 AM: Evaluate: task edges-ner-ontonotes, batch 138 (157): mcc: 0.8215, acc: 0.7283, precision: 0.9173, recall: 0.7514, f1: 0.8261, edges-ner-ontonotes_loss: 0.0517
09/16 10:05:22 AM: Updating LR scheduler:
09/16 10:05:22 AM: 	Best result seen so far for macro_avg: 0.824
09/16 10:05:22 AM: 	# validation passes without improvement: 3
09/16 10:05:22 AM: edges-ner-ontonotes_loss: training: 0.065834 validation: 0.051620
09/16 10:05:22 AM: macro_avg: validation: 0.823672
09/16 10:05:22 AM: micro_avg: validation: 0.000000
09/16 10:05:22 AM: edges-ner-ontonotes_mcc: training: 0.755741 validation: 0.819022
09/16 10:05:22 AM: edges-ner-ontonotes_acc: training: 0.648652 validation: 0.724826
09/16 10:05:22 AM: edges-ner-ontonotes_precision: training: 0.847835 validation: 0.915994
09/16 10:05:22 AM: edges-ner-ontonotes_recall: training: 0.695381 validation: 0.748256
09/16 10:05:22 AM: edges-ner-ontonotes_f1: training: 0.764077 validation: 0.823672
09/16 10:05:22 AM: Global learning rate: 0.0001
09/16 10:05:22 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:05:30 AM: Update 31107: task edges-ner-ontonotes, batch 107 (31107): mcc: 0.7108, acc: 0.5948, precision: 0.8182, recall: 0.6420, f1: 0.7195, edges-ner-ontonotes_loss: 0.0808
09/16 10:05:40 AM: Update 31238: task edges-ner-ontonotes, batch 238 (31238): mcc: 0.7182, acc: 0.6022, precision: 0.8240, recall: 0.6500, f1: 0.7267, edges-ner-ontonotes_loss: 0.0762
09/16 10:05:50 AM: Update 31402: task edges-ner-ontonotes, batch 402 (31402): mcc: 0.7294, acc: 0.6137, precision: 0.8345, recall: 0.6606, f1: 0.7374, edges-ner-ontonotes_loss: 0.0733
09/16 10:06:00 AM: Update 31520: task edges-ner-ontonotes, batch 520 (31520): mcc: 0.7324, acc: 0.6178, precision: 0.8361, recall: 0.6645, f1: 0.7405, edges-ner-ontonotes_loss: 0.0721
09/16 10:06:10 AM: Update 31661: task edges-ner-ontonotes, batch 661 (31661): mcc: 0.7383, acc: 0.6270, precision: 0.8394, recall: 0.6721, f1: 0.7465, edges-ner-ontonotes_loss: 0.0707
09/16 10:06:20 AM: Update 31770: task edges-ner-ontonotes, batch 770 (31770): mcc: 0.7388, acc: 0.6276, precision: 0.8390, recall: 0.6733, f1: 0.7470, edges-ner-ontonotes_loss: 0.0702
09/16 10:06:30 AM: Update 31901: task edges-ner-ontonotes, batch 901 (31901): mcc: 0.7454, acc: 0.6355, precision: 0.8433, recall: 0.6811, f1: 0.7536, edges-ner-ontonotes_loss: 0.0686
09/16 10:06:38 AM: ***** Step 32000 / Validation 32 *****
09/16 10:06:38 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:06:38 AM: Validating...
09/16 10:06:40 AM: Evaluate: task edges-ner-ontonotes, batch 22 (157): mcc: 0.7272, acc: 0.6252, precision: 0.8433, recall: 0.6496, f1: 0.7339, edges-ner-ontonotes_loss: 0.0731
09/16 10:06:50 AM: Evaluate: task edges-ner-ontonotes, batch 110 (157): mcc: 0.8069, acc: 0.7202, precision: 0.8972, recall: 0.7430, f1: 0.8128, edges-ner-ontonotes_loss: 0.0571
09/16 10:06:57 AM: Updating LR scheduler:
09/16 10:06:57 AM: 	Best result seen so far for macro_avg: 0.824
09/16 10:06:57 AM: 	# validation passes without improvement: 0
09/16 10:06:57 AM: edges-ner-ontonotes_loss: training: 0.067621 validation: 0.053514
09/16 10:06:57 AM: macro_avg: validation: 0.819673
09/16 10:06:57 AM: micro_avg: validation: 0.000000
09/16 10:06:57 AM: edges-ner-ontonotes_mcc: training: 0.749037 validation: 0.814276
09/16 10:06:57 AM: edges-ner-ontonotes_acc: training: 0.640275 validation: 0.725736
09/16 10:06:57 AM: edges-ner-ontonotes_precision: training: 0.845410 validation: 0.906385
09/16 10:06:57 AM: edges-ner-ontonotes_recall: training: 0.685697 validation: 0.748104
09/16 10:06:57 AM: edges-ner-ontonotes_f1: training: 0.757223 validation: 0.819673
09/16 10:06:57 AM: Global learning rate: 5e-05
09/16 10:06:57 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:07:00 AM: Update 32048: task edges-ner-ontonotes, batch 48 (32048): mcc: 0.7844, acc: 0.6887, precision: 0.8654, recall: 0.7308, f1: 0.7925, edges-ner-ontonotes_loss: 0.0582
09/16 10:07:10 AM: Update 32157: task edges-ner-ontonotes, batch 157 (32157): mcc: 0.7708, acc: 0.6690, precision: 0.8559, recall: 0.7149, f1: 0.7791, edges-ner-ontonotes_loss: 0.0610
09/16 10:07:21 AM: Update 32290: task edges-ner-ontonotes, batch 290 (32290): mcc: 0.7731, acc: 0.6720, precision: 0.8561, recall: 0.7189, f1: 0.7815, edges-ner-ontonotes_loss: 0.0608
09/16 10:07:31 AM: Update 32405: task edges-ner-ontonotes, batch 405 (32405): mcc: 0.7636, acc: 0.6600, precision: 0.8510, recall: 0.7066, f1: 0.7721, edges-ner-ontonotes_loss: 0.0627
09/16 10:07:41 AM: Update 32546: task edges-ner-ontonotes, batch 546 (32546): mcc: 0.7506, acc: 0.6436, precision: 0.8419, recall: 0.6913, f1: 0.7592, edges-ner-ontonotes_loss: 0.0678
09/16 10:07:52 AM: Update 32677: task edges-ner-ontonotes, batch 677 (32677): mcc: 0.7420, acc: 0.6325, precision: 0.8369, recall: 0.6807, f1: 0.7507, edges-ner-ontonotes_loss: 0.0704
09/16 10:08:02 AM: Update 32841: task edges-ner-ontonotes, batch 841 (32841): mcc: 0.7415, acc: 0.6310, precision: 0.8376, recall: 0.6791, f1: 0.7501, edges-ner-ontonotes_loss: 0.0702
09/16 10:08:13 AM: Update 32990: task edges-ner-ontonotes, batch 990 (32990): mcc: 0.7412, acc: 0.6303, precision: 0.8380, recall: 0.6782, f1: 0.7497, edges-ner-ontonotes_loss: 0.0702
09/16 10:08:13 AM: ***** Step 33000 / Validation 33 *****
09/16 10:08:13 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:08:15 AM: Validating...
09/16 10:08:23 AM: Evaluate: task edges-ner-ontonotes, batch 72 (157): mcc: 0.8150, acc: 0.7249, precision: 0.9064, recall: 0.7493, f1: 0.8204, edges-ner-ontonotes_loss: 0.0546
09/16 10:08:33 AM: Evaluate: task edges-ner-ontonotes, batch 153 (157): mcc: 0.8216, acc: 0.7303, precision: 0.9173, recall: 0.7516, f1: 0.8262, edges-ner-ontonotes_loss: 0.0508
09/16 10:08:33 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:08:33 AM: Best result seen so far for macro.
09/16 10:08:33 AM: Updating LR scheduler:
09/16 10:08:33 AM: 	Best result seen so far for macro_avg: 0.826
09/16 10:08:33 AM: 	# validation passes without improvement: 0
09/16 10:08:33 AM: edges-ner-ontonotes_loss: training: 0.070239 validation: 0.050628
09/16 10:08:33 AM: macro_avg: validation: 0.826031
09/16 10:08:33 AM: micro_avg: validation: 0.000000
09/16 10:08:33 AM: edges-ner-ontonotes_mcc: training: 0.740837 validation: 0.821397
09/16 10:08:33 AM: edges-ner-ontonotes_acc: training: 0.629744 validation: 0.729906
09/16 10:08:33 AM: edges-ner-ontonotes_precision: training: 0.837989 validation: 0.917400
09/16 10:08:33 AM: edges-ner-ontonotes_recall: training: 0.677645 validation: 0.751213
09/16 10:08:33 AM: edges-ner-ontonotes_f1: training: 0.749336 validation: 0.826031
09/16 10:08:33 AM: Global learning rate: 5e-05
09/16 10:08:33 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:08:43 AM: Update 33127: task edges-ner-ontonotes, batch 127 (33127): mcc: 0.7491, acc: 0.6422, precision: 0.8444, recall: 0.6867, f1: 0.7574, edges-ner-ontonotes_loss: 0.0678
09/16 10:08:53 AM: Update 33260: task edges-ner-ontonotes, batch 260 (33260): mcc: 0.7547, acc: 0.6501, precision: 0.8498, recall: 0.6919, f1: 0.7628, edges-ner-ontonotes_loss: 0.0663
09/16 10:09:03 AM: Update 33361: task edges-ner-ontonotes, batch 361 (33361): mcc: 0.7522, acc: 0.6466, precision: 0.8468, recall: 0.6902, f1: 0.7605, edges-ner-ontonotes_loss: 0.0662
09/16 10:09:13 AM: Update 33497: task edges-ner-ontonotes, batch 497 (33497): mcc: 0.7605, acc: 0.6577, precision: 0.8514, recall: 0.7008, f1: 0.7688, edges-ner-ontonotes_loss: 0.0639
09/16 10:09:23 AM: Update 33616: task edges-ner-ontonotes, batch 616 (33616): mcc: 0.7641, acc: 0.6621, precision: 0.8532, recall: 0.7055, f1: 0.7723, edges-ner-ontonotes_loss: 0.0629
09/16 10:09:33 AM: Update 33748: task edges-ner-ontonotes, batch 748 (33748): mcc: 0.7662, acc: 0.6637, precision: 0.8548, recall: 0.7078, f1: 0.7744, edges-ner-ontonotes_loss: 0.0626
09/16 10:09:44 AM: Update 33881: task edges-ner-ontonotes, batch 881 (33881): mcc: 0.7668, acc: 0.6640, precision: 0.8547, recall: 0.7090, f1: 0.7750, edges-ner-ontonotes_loss: 0.0623
09/16 10:09:54 AM: Update 33987: task edges-ner-ontonotes, batch 987 (33987): mcc: 0.7612, acc: 0.6575, precision: 0.8500, recall: 0.7032, f1: 0.7697, edges-ner-ontonotes_loss: 0.0636
09/16 10:09:55 AM: ***** Step 34000 / Validation 34 *****
09/16 10:09:56 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:09:56 AM: Validating...
09/16 10:10:04 AM: Evaluate: task edges-ner-ontonotes, batch 73 (157): mcc: 0.8094, acc: 0.7160, precision: 0.9001, recall: 0.7448, f1: 0.8151, edges-ner-ontonotes_loss: 0.0557
09/16 10:10:14 AM: Evaluate: task edges-ner-ontonotes, batch 153 (157): mcc: 0.8189, acc: 0.7260, precision: 0.9147, recall: 0.7492, f1: 0.8237, edges-ner-ontonotes_loss: 0.0512
09/16 10:10:14 AM: Updating LR scheduler:
09/16 10:10:14 AM: 	Best result seen so far for macro_avg: 0.826
09/16 10:10:14 AM: 	# validation passes without improvement: 1
09/16 10:10:14 AM: edges-ner-ontonotes_loss: training: 0.063934 validation: 0.051062
09/16 10:10:14 AM: macro_avg: validation: 0.823691
09/16 10:10:14 AM: micro_avg: validation: 0.000000
09/16 10:10:14 AM: edges-ner-ontonotes_mcc: training: 0.760077 validation: 0.818897
09/16 10:10:14 AM: edges-ner-ontonotes_acc: training: 0.655915 validation: 0.725887
09/16 10:10:14 AM: edges-ner-ontonotes_precision: training: 0.849359 validation: 0.914569
09/16 10:10:14 AM: edges-ner-ontonotes_recall: training: 0.701701 validation: 0.749242
09/16 10:10:14 AM: edges-ner-ontonotes_f1: training: 0.768502 validation: 0.823691
09/16 10:10:14 AM: Global learning rate: 5e-05
09/16 10:10:14 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:10:24 AM: Update 34129: task edges-ner-ontonotes, batch 129 (34129): mcc: 0.7035, acc: 0.5858, precision: 0.8146, recall: 0.6323, f1: 0.7120, edges-ner-ontonotes_loss: 0.0806
09/16 10:10:34 AM: Update 34238: task edges-ner-ontonotes, batch 238 (34238): mcc: 0.7066, acc: 0.5878, precision: 0.8179, recall: 0.6349, f1: 0.7149, edges-ner-ontonotes_loss: 0.0798
09/16 10:10:44 AM: Update 34403: task edges-ner-ontonotes, batch 403 (34403): mcc: 0.7175, acc: 0.6009, precision: 0.8258, recall: 0.6473, f1: 0.7257, edges-ner-ontonotes_loss: 0.0759
09/16 10:10:55 AM: Update 34546: task edges-ner-ontonotes, batch 546 (34546): mcc: 0.7230, acc: 0.6078, precision: 0.8301, recall: 0.6532, f1: 0.7311, edges-ner-ontonotes_loss: 0.0741
09/16 10:11:05 AM: Update 34679: task edges-ner-ontonotes, batch 679 (34679): mcc: 0.7280, acc: 0.6146, precision: 0.8319, recall: 0.6605, f1: 0.7363, edges-ner-ontonotes_loss: 0.0730
09/16 10:11:15 AM: Update 34812: task edges-ner-ontonotes, batch 812 (34812): mcc: 0.7328, acc: 0.6210, precision: 0.8350, recall: 0.6662, f1: 0.7411, edges-ner-ontonotes_loss: 0.0719
09/16 10:11:25 AM: Update 34928: task edges-ner-ontonotes, batch 928 (34928): mcc: 0.7371, acc: 0.6264, precision: 0.8375, recall: 0.6715, f1: 0.7454, edges-ner-ontonotes_loss: 0.0706
09/16 10:11:30 AM: ***** Step 35000 / Validation 35 *****
09/16 10:11:30 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:11:30 AM: Validating...
09/16 10:11:35 AM: Evaluate: task edges-ner-ontonotes, batch 44 (157): mcc: 0.7768, acc: 0.6852, precision: 0.8701, recall: 0.7134, f1: 0.7840, edges-ner-ontonotes_loss: 0.0633
09/16 10:11:45 AM: Evaluate: task edges-ner-ontonotes, batch 118 (157): mcc: 0.8139, acc: 0.7244, precision: 0.9091, recall: 0.7451, f1: 0.8190, edges-ner-ontonotes_loss: 0.0546
09/16 10:11:49 AM: Updating LR scheduler:
09/16 10:11:49 AM: 	Best result seen so far for macro_avg: 0.826
09/16 10:11:49 AM: 	# validation passes without improvement: 2
09/16 10:11:49 AM: edges-ner-ontonotes_loss: training: 0.069834 validation: 0.052127
09/16 10:11:49 AM: macro_avg: validation: 0.825071
09/16 10:11:49 AM: micro_avg: validation: 0.000000
09/16 10:11:49 AM: edges-ner-ontonotes_mcc: training: 0.740597 validation: 0.820118
09/16 10:11:49 AM: edges-ner-ontonotes_acc: training: 0.630566 validation: 0.731498
09/16 10:11:49 AM: edges-ner-ontonotes_precision: training: 0.840081 validation: 0.913688
09/16 10:11:49 AM: edges-ner-ontonotes_recall: training: 0.675463 validation: 0.752123
09/16 10:11:49 AM: edges-ner-ontonotes_f1: training: 0.748832 validation: 0.825071
09/16 10:11:49 AM: Global learning rate: 5e-05
09/16 10:11:49 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:11:55 AM: Update 35070: task edges-ner-ontonotes, batch 70 (35070): mcc: 0.7816, acc: 0.6797, precision: 0.8681, recall: 0.7235, f1: 0.7893, edges-ner-ontonotes_loss: 0.0597
09/16 10:12:06 AM: Update 35172: task edges-ner-ontonotes, batch 172 (35172): mcc: 0.7840, acc: 0.6832, precision: 0.8675, recall: 0.7282, f1: 0.7918, edges-ner-ontonotes_loss: 0.0583
09/16 10:12:16 AM: Update 35293: task edges-ner-ontonotes, batch 293 (35293): mcc: 0.7741, acc: 0.6705, precision: 0.8618, recall: 0.7157, f1: 0.7820, edges-ner-ontonotes_loss: 0.0598
09/16 10:12:26 AM: Update 35426: task edges-ner-ontonotes, batch 426 (35426): mcc: 0.7778, acc: 0.6752, precision: 0.8626, recall: 0.7215, f1: 0.7858, edges-ner-ontonotes_loss: 0.0596
09/16 10:12:36 AM: Update 35548: task edges-ner-ontonotes, batch 548 (35548): mcc: 0.7668, acc: 0.6619, precision: 0.8544, recall: 0.7092, f1: 0.7751, edges-ner-ontonotes_loss: 0.0628
09/16 10:12:46 AM: Update 35679: task edges-ner-ontonotes, batch 679 (35679): mcc: 0.7551, acc: 0.6477, precision: 0.8470, recall: 0.6950, f1: 0.7635, edges-ner-ontonotes_loss: 0.0662
09/16 10:12:56 AM: Update 35806: task edges-ner-ontonotes, batch 806 (35806): mcc: 0.7494, acc: 0.6406, precision: 0.8434, recall: 0.6880, f1: 0.7578, edges-ner-ontonotes_loss: 0.0685
09/16 10:13:06 AM: Update 35976: task edges-ner-ontonotes, batch 976 (35976): mcc: 0.7474, acc: 0.6380, precision: 0.8426, recall: 0.6853, f1: 0.7558, edges-ner-ontonotes_loss: 0.0688
09/16 10:13:07 AM: ***** Step 36000 / Validation 36 *****
09/16 10:13:07 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:13:07 AM: Validating...
09/16 10:13:16 AM: Evaluate: task edges-ner-ontonotes, batch 78 (157): mcc: 0.8149, acc: 0.7220, precision: 0.9111, recall: 0.7452, f1: 0.8198, edges-ner-ontonotes_loss: 0.0543
09/16 10:13:26 AM: Evaluate: task edges-ner-ontonotes, batch 156 (157): mcc: 0.8166, acc: 0.7217, precision: 0.9181, recall: 0.7422, f1: 0.8209, edges-ner-ontonotes_loss: 0.0512
09/16 10:13:26 AM: Updating LR scheduler:
09/16 10:13:26 AM: 	Best result seen so far for macro_avg: 0.826
09/16 10:13:26 AM: 	# validation passes without improvement: 3
09/16 10:13:26 AM: edges-ner-ontonotes_loss: training: 0.068790 validation: 0.051077
09/16 10:13:26 AM: macro_avg: validation: 0.820915
09/16 10:13:26 AM: micro_avg: validation: 0.000000
09/16 10:13:26 AM: edges-ner-ontonotes_mcc: training: 0.747222 validation: 0.816647
09/16 10:13:26 AM: edges-ner-ontonotes_acc: training: 0.637653 validation: 0.721717
09/16 10:13:26 AM: edges-ner-ontonotes_precision: training: 0.842557 validation: 0.918207
09/16 10:13:26 AM: edges-ner-ontonotes_recall: training: 0.684941 validation: 0.742266
09/16 10:13:26 AM: edges-ner-ontonotes_f1: training: 0.755617 validation: 0.820915
09/16 10:13:26 AM: Global learning rate: 5e-05
09/16 10:13:26 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:13:36 AM: Update 36115: task edges-ner-ontonotes, batch 115 (36115): mcc: 0.7382, acc: 0.6267, precision: 0.8406, recall: 0.6709, f1: 0.7462, edges-ner-ontonotes_loss: 0.0692
09/16 10:13:46 AM: Update 36254: task edges-ner-ontonotes, batch 254 (36254): mcc: 0.7462, acc: 0.6387, precision: 0.8432, recall: 0.6827, f1: 0.7545, edges-ner-ontonotes_loss: 0.0674
09/16 10:13:56 AM: Update 36389: task edges-ner-ontonotes, batch 389 (36389): mcc: 0.7492, acc: 0.6420, precision: 0.8460, recall: 0.6855, f1: 0.7574, edges-ner-ontonotes_loss: 0.0670
09/16 10:14:06 AM: Update 36505: task edges-ner-ontonotes, batch 505 (36505): mcc: 0.7522, acc: 0.6457, precision: 0.8481, recall: 0.6891, f1: 0.7603, edges-ner-ontonotes_loss: 0.0661
09/16 10:14:16 AM: Update 36637: task edges-ner-ontonotes, batch 637 (36637): mcc: 0.7600, acc: 0.6544, precision: 0.8532, recall: 0.6982, f1: 0.7680, edges-ner-ontonotes_loss: 0.0644
09/16 10:14:26 AM: Update 36744: task edges-ner-ontonotes, batch 744 (36744): mcc: 0.7626, acc: 0.6574, precision: 0.8545, recall: 0.7017, f1: 0.7706, edges-ner-ontonotes_loss: 0.0636
09/16 10:14:36 AM: Update 36877: task edges-ner-ontonotes, batch 877 (36877): mcc: 0.7641, acc: 0.6594, precision: 0.8549, recall: 0.7040, f1: 0.7722, edges-ner-ontonotes_loss: 0.0633
09/16 10:14:46 AM: ***** Step 37000 / Validation 37 *****
09/16 10:14:46 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:14:46 AM: Validating...
09/16 10:14:46 AM: Evaluate: task edges-ner-ontonotes, batch 6 (157): mcc: 0.6959, acc: 0.5925, precision: 0.8200, recall: 0.6150, f1: 0.7029, edges-ner-ontonotes_loss: 0.0807
09/16 10:14:56 AM: Evaluate: task edges-ner-ontonotes, batch 96 (157): mcc: 0.8105, acc: 0.7235, precision: 0.8951, recall: 0.7512, f1: 0.8169, edges-ner-ontonotes_loss: 0.0567
09/16 10:15:04 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:15:04 AM: Best result seen so far for macro.
09/16 10:15:04 AM: Updating LR scheduler:
09/16 10:15:04 AM: 	Best result seen so far for macro_avg: 0.826
09/16 10:15:04 AM: 	# validation passes without improvement: 0
09/16 10:15:04 AM: edges-ner-ontonotes_loss: training: 0.062937 validation: 0.051769
09/16 10:15:04 AM: macro_avg: validation: 0.826114
09/16 10:15:04 AM: micro_avg: validation: 0.000000
09/16 10:15:04 AM: edges-ner-ontonotes_mcc: training: 0.765305 validation: 0.820283
09/16 10:15:04 AM: edges-ner-ontonotes_acc: training: 0.660843 validation: 0.732863
09/16 10:15:04 AM: edges-ner-ontonotes_precision: training: 0.855751 validation: 0.904921
09/16 10:15:04 AM: edges-ner-ontonotes_recall: training: 0.705411 validation: 0.759933
09/16 10:15:04 AM: edges-ner-ontonotes_f1: training: 0.773342 validation: 0.826114
09/16 10:15:04 AM: Global learning rate: 2.5e-05
09/16 10:15:04 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:15:06 AM: Update 37024: task edges-ner-ontonotes, batch 24 (37024): mcc: 0.7727, acc: 0.6665, precision: 0.8629, recall: 0.7123, f1: 0.7804, edges-ner-ontonotes_loss: 0.0594
09/16 10:15:16 AM: Update 37136: task edges-ner-ontonotes, batch 136 (37136): mcc: 0.7110, acc: 0.5944, precision: 0.8175, recall: 0.6429, f1: 0.7198, edges-ner-ontonotes_loss: 0.0765
09/16 10:15:26 AM: Update 37277: task edges-ner-ontonotes, batch 277 (37277): mcc: 0.7089, acc: 0.5911, precision: 0.8148, recall: 0.6415, f1: 0.7178, edges-ner-ontonotes_loss: 0.0784
09/16 10:15:36 AM: Update 37396: task edges-ner-ontonotes, batch 396 (37396): mcc: 0.7120, acc: 0.5943, precision: 0.8177, recall: 0.6446, f1: 0.7209, edges-ner-ontonotes_loss: 0.0780
09/16 10:15:47 AM: Update 37558: task edges-ner-ontonotes, batch 558 (37558): mcc: 0.7186, acc: 0.6024, precision: 0.8229, recall: 0.6516, f1: 0.7273, edges-ner-ontonotes_loss: 0.0755
09/16 10:15:57 AM: Update 37682: task edges-ner-ontonotes, batch 682 (37682): mcc: 0.7214, acc: 0.6058, precision: 0.8260, recall: 0.6538, f1: 0.7299, edges-ner-ontonotes_loss: 0.0745
09/16 10:16:07 AM: Update 37816: task edges-ner-ontonotes, batch 816 (37816): mcc: 0.7275, acc: 0.6134, precision: 0.8301, recall: 0.6610, f1: 0.7359, edges-ner-ontonotes_loss: 0.0731
09/16 10:16:17 AM: Update 37947: task edges-ner-ontonotes, batch 947 (37947): mcc: 0.7315, acc: 0.6184, precision: 0.8327, recall: 0.6657, f1: 0.7399, edges-ner-ontonotes_loss: 0.0723
09/16 10:16:23 AM: ***** Step 38000 / Validation 38 *****
09/16 10:16:23 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:16:23 AM: Validating...
09/16 10:16:27 AM: Evaluate: task edges-ner-ontonotes, batch 39 (157): mcc: 0.7865, acc: 0.6975, precision: 0.8733, recall: 0.7277, f1: 0.7939, edges-ner-ontonotes_loss: 0.0612
09/16 10:16:37 AM: Evaluate: task edges-ner-ontonotes, batch 117 (157): mcc: 0.8186, acc: 0.7297, precision: 0.9096, recall: 0.7530, f1: 0.8239, edges-ner-ontonotes_loss: 0.0532
09/16 10:16:41 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:16:41 AM: Best result seen so far for macro.
09/16 10:16:41 AM: Updating LR scheduler:
09/16 10:16:41 AM: 	Best result seen so far for macro_avg: 0.830
09/16 10:16:41 AM: 	# validation passes without improvement: 0
09/16 10:16:41 AM: edges-ner-ontonotes_loss: training: 0.071966 validation: 0.050899
09/16 10:16:41 AM: macro_avg: validation: 0.830131
09/16 10:16:41 AM: micro_avg: validation: 0.000000
09/16 10:16:41 AM: edges-ner-ontonotes_mcc: training: 0.732328 validation: 0.825013
09/16 10:16:41 AM: edges-ner-ontonotes_acc: training: 0.619306 validation: 0.737489
09/16 10:16:41 AM: edges-ner-ontonotes_precision: training: 0.833090 validation: 0.914507
09/16 10:16:41 AM: edges-ner-ontonotes_recall: training: 0.666934 validation: 0.760009
09/16 10:16:41 AM: edges-ner-ontonotes_f1: training: 0.740809 validation: 0.830131
09/16 10:16:41 AM: Global learning rate: 2.5e-05
09/16 10:16:41 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:16:47 AM: Update 38074: task edges-ner-ontonotes, batch 74 (38074): mcc: 0.7910, acc: 0.6937, precision: 0.8721, recall: 0.7366, f1: 0.7987, edges-ner-ontonotes_loss: 0.0570
09/16 10:16:57 AM: Update 38203: task edges-ner-ontonotes, batch 203 (38203): mcc: 0.7816, acc: 0.6813, precision: 0.8649, recall: 0.7262, f1: 0.7895, edges-ner-ontonotes_loss: 0.0584
09/16 10:17:07 AM: Update 38310: task edges-ner-ontonotes, batch 310 (38310): mcc: 0.7818, acc: 0.6811, precision: 0.8656, recall: 0.7261, f1: 0.7897, edges-ner-ontonotes_loss: 0.0585
09/16 10:17:17 AM: Update 38446: task edges-ner-ontonotes, batch 446 (38446): mcc: 0.7811, acc: 0.6800, precision: 0.8652, recall: 0.7252, f1: 0.7890, edges-ner-ontonotes_loss: 0.0590
09/16 10:17:27 AM: Update 38576: task edges-ner-ontonotes, batch 576 (38576): mcc: 0.7781, acc: 0.6764, precision: 0.8629, recall: 0.7218, f1: 0.7861, edges-ner-ontonotes_loss: 0.0596
09/16 10:17:37 AM: Update 38693: task edges-ner-ontonotes, batch 693 (38693): mcc: 0.7664, acc: 0.6619, precision: 0.8553, recall: 0.7078, f1: 0.7746, edges-ner-ontonotes_loss: 0.0628
09/16 10:17:47 AM: Update 38839: task edges-ner-ontonotes, batch 839 (38839): mcc: 0.7579, acc: 0.6512, precision: 0.8495, recall: 0.6978, f1: 0.7662, edges-ner-ontonotes_loss: 0.0659
09/16 10:17:57 AM: Update 38968: task edges-ner-ontonotes, batch 968 (38968): mcc: 0.7530, acc: 0.6451, precision: 0.8459, recall: 0.6922, f1: 0.7613, edges-ner-ontonotes_loss: 0.0673
09/16 10:17:59 AM: ***** Step 39000 / Validation 39 *****
09/16 10:17:59 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:17:59 AM: Validating...
09/16 10:18:07 AM: Evaluate: task edges-ner-ontonotes, batch 72 (157): mcc: 0.8113, acc: 0.7185, precision: 0.9057, recall: 0.7435, f1: 0.8166, edges-ner-ontonotes_loss: 0.0546
09/16 10:18:17 AM: Evaluate: task edges-ner-ontonotes, batch 152 (157): mcc: 0.8186, acc: 0.7253, precision: 0.9165, recall: 0.7471, f1: 0.8232, edges-ner-ontonotes_loss: 0.0506
09/16 10:18:18 AM: Updating LR scheduler:
09/16 10:18:18 AM: 	Best result seen so far for macro_avg: 0.830
09/16 10:18:18 AM: 	# validation passes without improvement: 1
09/16 10:18:18 AM: edges-ner-ontonotes_loss: training: 0.067350 validation: 0.050457
09/16 10:18:18 AM: macro_avg: validation: 0.822851
09/16 10:18:18 AM: micro_avg: validation: 0.000000
09/16 10:18:18 AM: edges-ner-ontonotes_mcc: training: 0.752369 validation: 0.818305
09/16 10:18:18 AM: edges-ner-ontonotes_acc: training: 0.644244 validation: 0.724598
09/16 10:18:18 AM: edges-ner-ontonotes_precision: training: 0.845630 validation: 0.916581
09/16 10:18:18 AM: edges-ner-ontonotes_recall: training: 0.691346 validation: 0.746512
09/16 10:18:18 AM: edges-ner-ontonotes_f1: training: 0.760744 validation: 0.822851
09/16 10:18:18 AM: Global learning rate: 2.5e-05
09/16 10:18:18 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:18:27 AM: Update 39159: task edges-ner-ontonotes, batch 159 (39159): mcc: 0.7374, acc: 0.6240, precision: 0.8362, recall: 0.6732, f1: 0.7459, edges-ner-ontonotes_loss: 0.0698
09/16 10:18:38 AM: Update 39282: task edges-ner-ontonotes, batch 282 (39282): mcc: 0.7409, acc: 0.6284, precision: 0.8415, recall: 0.6748, f1: 0.7490, edges-ner-ontonotes_loss: 0.0688
09/16 10:18:48 AM: Update 39415: task edges-ner-ontonotes, batch 415 (39415): mcc: 0.7435, acc: 0.6329, precision: 0.8428, recall: 0.6782, f1: 0.7516, edges-ner-ontonotes_loss: 0.0686
09/16 10:18:58 AM: Update 39529: task edges-ner-ontonotes, batch 529 (39529): mcc: 0.7452, acc: 0.6354, precision: 0.8435, recall: 0.6805, f1: 0.7533, edges-ner-ontonotes_loss: 0.0678
09/16 10:19:08 AM: Update 39662: task edges-ner-ontonotes, batch 662 (39662): mcc: 0.7541, acc: 0.6466, precision: 0.8490, recall: 0.6916, f1: 0.7622, edges-ner-ontonotes_loss: 0.0660
09/16 10:19:18 AM: Update 39791: task edges-ner-ontonotes, batch 791 (39791): mcc: 0.7591, acc: 0.6526, precision: 0.8518, recall: 0.6979, f1: 0.7672, edges-ner-ontonotes_loss: 0.0646
09/16 10:19:28 AM: Update 39909: task edges-ner-ontonotes, batch 909 (39909): mcc: 0.7613, acc: 0.6553, precision: 0.8531, recall: 0.7006, f1: 0.7694, edges-ner-ontonotes_loss: 0.0642
09/16 10:19:35 AM: ***** Step 40000 / Validation 40 *****
09/16 10:19:35 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:19:35 AM: Validating...
09/16 10:19:38 AM: Evaluate: task edges-ner-ontonotes, batch 35 (157): mcc: 0.7752, acc: 0.6792, precision: 0.8651, recall: 0.7149, f1: 0.7828, edges-ner-ontonotes_loss: 0.0647
09/16 10:19:48 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.8127, acc: 0.7226, precision: 0.9019, recall: 0.7492, f1: 0.8185, edges-ner-ontonotes_loss: 0.0548
09/16 10:19:53 AM: Updating LR scheduler:
09/16 10:19:53 AM: 	Best result seen so far for macro_avg: 0.830
09/16 10:19:53 AM: 	# validation passes without improvement: 2
09/16 10:19:53 AM: edges-ner-ontonotes_loss: training: 0.063922 validation: 0.051429
09/16 10:19:53 AM: macro_avg: validation: 0.828019
09/16 10:19:53 AM: micro_avg: validation: 0.000000
09/16 10:19:53 AM: edges-ner-ontonotes_mcc: training: 0.762176 validation: 0.822508
09/16 10:19:53 AM: edges-ner-ontonotes_acc: training: 0.656529 validation: 0.734304
09/16 10:19:53 AM: edges-ner-ontonotes_precision: training: 0.853786 validation: 0.909289
09/16 10:19:53 AM: edges-ner-ontonotes_recall: training: 0.701594 validation: 0.760085
09/16 10:19:53 AM: edges-ner-ontonotes_f1: training: 0.770244 validation: 0.828019
09/16 10:19:53 AM: Global learning rate: 2.5e-05
09/16 10:19:53 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:19:58 AM: Update 40064: task edges-ner-ontonotes, batch 64 (40064): mcc: 0.7659, acc: 0.6629, precision: 0.8518, recall: 0.7099, f1: 0.7744, edges-ner-ontonotes_loss: 0.0614
09/16 10:20:08 AM: Update 40171: task edges-ner-ontonotes, batch 171 (40171): mcc: 0.7534, acc: 0.6489, precision: 0.8425, recall: 0.6958, f1: 0.7622, edges-ner-ontonotes_loss: 0.0649
09/16 10:20:18 AM: Update 40310: task edges-ner-ontonotes, batch 310 (40310): mcc: 0.7344, acc: 0.6238, precision: 0.8308, recall: 0.6725, f1: 0.7433, edges-ner-ontonotes_loss: 0.0713
09/16 10:20:28 AM: Update 40452: task edges-ner-ontonotes, batch 452 (40452): mcc: 0.7254, acc: 0.6119, precision: 0.8259, recall: 0.6609, f1: 0.7342, edges-ner-ontonotes_loss: 0.0745
09/16 10:20:38 AM: Update 40579: task edges-ner-ontonotes, batch 579 (40579): mcc: 0.7271, acc: 0.6135, precision: 0.8279, recall: 0.6623, f1: 0.7359, edges-ner-ontonotes_loss: 0.0739
09/16 10:20:48 AM: Update 40744: task edges-ner-ontonotes, batch 744 (40744): mcc: 0.7297, acc: 0.6161, precision: 0.8306, recall: 0.6645, f1: 0.7383, edges-ner-ontonotes_loss: 0.0727
09/16 10:20:58 AM: Update 40865: task edges-ner-ontonotes, batch 865 (40865): mcc: 0.7323, acc: 0.6196, precision: 0.8328, recall: 0.6672, f1: 0.7408, edges-ner-ontonotes_loss: 0.0719
09/16 10:21:08 AM: ***** Step 41000 / Validation 41 *****
09/16 10:21:08 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:21:08 AM: Validating...
09/16 10:21:08 AM: Evaluate: task edges-ner-ontonotes, batch 2 (157): mcc: 0.6969, acc: 0.5846, precision: 0.8316, recall: 0.6077, f1: 0.7022, edges-ner-ontonotes_loss: 0.0786
09/16 10:21:18 AM: Evaluate: task edges-ner-ontonotes, batch 95 (157): mcc: 0.8254, acc: 0.7380, precision: 0.9138, recall: 0.7614, f1: 0.8306, edges-ner-ontonotes_loss: 0.0518
09/16 10:21:26 AM: Updating LR scheduler:
09/16 10:21:26 AM: 	Best result seen so far for macro_avg: 0.830
09/16 10:21:27 AM: 	# validation passes without improvement: 3
09/16 10:21:27 AM: edges-ner-ontonotes_loss: training: 0.071215 validation: 0.049849
09/16 10:21:27 AM: macro_avg: validation: 0.827578
09/16 10:21:27 AM: micro_avg: validation: 0.000000
09/16 10:21:27 AM: edges-ner-ontonotes_mcc: training: 0.735355 validation: 0.822686
09/16 10:21:27 AM: edges-ner-ontonotes_acc: training: 0.623315 validation: 0.732636
09/16 10:21:27 AM: edges-ner-ontonotes_precision: training: 0.835206 validation: 0.915586
09/16 10:21:27 AM: edges-ner-ontonotes_recall: training: 0.670427 validation: 0.755005
09/16 10:21:27 AM: edges-ner-ontonotes_f1: training: 0.743800 validation: 0.827578
09/16 10:21:27 AM: Global learning rate: 2.5e-05
09/16 10:21:27 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:21:28 AM: Update 41017: task edges-ner-ontonotes, batch 17 (41017): mcc: 0.7626, acc: 0.6592, precision: 0.8628, recall: 0.6948, f1: 0.7697, edges-ner-ontonotes_loss: 0.0632
09/16 10:21:39 AM: Update 41121: task edges-ner-ontonotes, batch 121 (41121): mcc: 0.7550, acc: 0.6469, precision: 0.8534, recall: 0.6893, f1: 0.7626, edges-ner-ontonotes_loss: 0.0655
09/16 10:21:49 AM: Update 41253: task edges-ner-ontonotes, batch 253 (41253): mcc: 0.7712, acc: 0.6658, precision: 0.8615, recall: 0.7108, f1: 0.7789, edges-ner-ontonotes_loss: 0.0617
09/16 10:21:59 AM: Update 41381: task edges-ner-ontonotes, batch 381 (41381): mcc: 0.7756, acc: 0.6725, precision: 0.8638, recall: 0.7166, f1: 0.7834, edges-ner-ontonotes_loss: 0.0608
09/16 10:22:09 AM: Update 41501: task edges-ner-ontonotes, batch 501 (41501): mcc: 0.7753, acc: 0.6722, precision: 0.8631, recall: 0.7167, f1: 0.7831, edges-ner-ontonotes_loss: 0.0608
09/16 10:22:19 AM: Update 41633: task edges-ner-ontonotes, batch 633 (41633): mcc: 0.7736, acc: 0.6705, precision: 0.8605, recall: 0.7159, f1: 0.7815, edges-ner-ontonotes_loss: 0.0609
09/16 10:22:29 AM: Update 41742: task edges-ner-ontonotes, batch 742 (41742): mcc: 0.7674, acc: 0.6625, precision: 0.8567, recall: 0.7083, f1: 0.7755, edges-ner-ontonotes_loss: 0.0621
09/16 10:22:39 AM: Update 41880: task edges-ner-ontonotes, batch 880 (41880): mcc: 0.7566, acc: 0.6492, precision: 0.8492, recall: 0.6956, f1: 0.7648, edges-ner-ontonotes_loss: 0.0651
09/16 10:22:47 AM: ***** Step 42000 / Validation 42 *****
09/16 10:22:47 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:22:47 AM: Validating...
09/16 10:22:49 AM: Evaluate: task edges-ner-ontonotes, batch 18 (157): mcc: 0.7606, acc: 0.6637, precision: 0.8613, recall: 0.6924, f1: 0.7677, edges-ner-ontonotes_loss: 0.0628
09/16 10:22:59 AM: Evaluate: task edges-ner-ontonotes, batch 105 (157): mcc: 0.8239, acc: 0.7358, precision: 0.9133, recall: 0.7591, f1: 0.8291, edges-ner-ontonotes_loss: 0.0524
09/16 10:23:06 AM: Updating LR scheduler:
09/16 10:23:06 AM: 	Best result seen so far for macro_avg: 0.830
09/16 10:23:06 AM: 	# validation passes without improvement: 0
09/16 10:23:06 AM: edges-ner-ontonotes_loss: training: 0.066984 validation: 0.050272
09/16 10:23:06 AM: macro_avg: validation: 0.827919
09/16 10:23:06 AM: micro_avg: validation: 0.000000
09/16 10:23:06 AM: edges-ner-ontonotes_mcc: training: 0.752781 validation: 0.823146
09/16 10:23:06 AM: edges-ner-ontonotes_acc: training: 0.644699 validation: 0.732257
09/16 10:23:06 AM: edges-ner-ontonotes_precision: training: 0.846356 validation: 0.916981
09/16 10:23:06 AM: edges-ner-ontonotes_recall: training: 0.691450 validation: 0.754625
09/16 10:23:06 AM: edges-ner-ontonotes_f1: training: 0.761101 validation: 0.827919
09/16 10:23:06 AM: Global learning rate: 1.25e-05
09/16 10:23:06 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:23:09 AM: Update 42021: task edges-ner-ontonotes, batch 21 (42021): mcc: 0.7115, acc: 0.5936, precision: 0.8230, recall: 0.6393, f1: 0.7196, edges-ner-ontonotes_loss: 0.0775
09/16 10:23:19 AM: Update 42187: task edges-ner-ontonotes, batch 187 (42187): mcc: 0.7355, acc: 0.6219, precision: 0.8383, recall: 0.6681, f1: 0.7436, edges-ner-ontonotes_loss: 0.0708
09/16 10:23:29 AM: Update 42327: task edges-ner-ontonotes, batch 327 (42327): mcc: 0.7362, acc: 0.6215, precision: 0.8376, recall: 0.6699, f1: 0.7444, edges-ner-ontonotes_loss: 0.0703
09/16 10:23:40 AM: Update 42473: task edges-ner-ontonotes, batch 473 (42473): mcc: 0.7427, acc: 0.6306, precision: 0.8425, recall: 0.6772, f1: 0.7508, edges-ner-ontonotes_loss: 0.0691
09/16 10:23:50 AM: Update 42606: task edges-ner-ontonotes, batch 606 (42606): mcc: 0.7451, acc: 0.6349, precision: 0.8433, recall: 0.6807, f1: 0.7533, edges-ner-ontonotes_loss: 0.0688
09/16 10:24:00 AM: Update 42729: task edges-ner-ontonotes, batch 729 (42729): mcc: 0.7489, acc: 0.6395, precision: 0.8451, recall: 0.6857, f1: 0.7571, edges-ner-ontonotes_loss: 0.0675
09/16 10:24:10 AM: Update 42864: task edges-ner-ontonotes, batch 864 (42864): mcc: 0.7545, acc: 0.6463, precision: 0.8488, recall: 0.6924, f1: 0.7627, edges-ner-ontonotes_loss: 0.0661
09/16 10:24:20 AM: Update 42964: task edges-ner-ontonotes, batch 964 (42964): mcc: 0.7568, acc: 0.6492, precision: 0.8506, recall: 0.6949, f1: 0.7649, edges-ner-ontonotes_loss: 0.0654
09/16 10:24:22 AM: ***** Step 43000 / Validation 43 *****
09/16 10:24:22 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:24:22 AM: Validating...
09/16 10:24:30 AM: Evaluate: task edges-ner-ontonotes, batch 69 (157): mcc: 0.7966, acc: 0.7034, precision: 0.8926, recall: 0.7289, f1: 0.8025, edges-ner-ontonotes_loss: 0.0594
09/16 10:24:40 AM: Evaluate: task edges-ner-ontonotes, batch 148 (157): mcc: 0.8252, acc: 0.7377, precision: 0.9147, recall: 0.7602, f1: 0.8303, edges-ner-ontonotes_loss: 0.0515
09/16 10:24:41 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:24:41 AM: Best result seen so far for macro.
09/16 10:24:41 AM: Updating LR scheduler:
09/16 10:24:41 AM: 	Best result seen so far for macro_avg: 0.830
09/16 10:24:41 AM: 	# validation passes without improvement: 0
09/16 10:24:41 AM: edges-ner-ontonotes_loss: training: 0.065109 validation: 0.051184
09/16 10:24:41 AM: macro_avg: validation: 0.830379
09/16 10:24:41 AM: micro_avg: validation: 0.000000
09/16 10:24:41 AM: edges-ner-ontonotes_mcc: training: 0.757435 validation: 0.825276
09/16 10:24:41 AM: edges-ner-ontonotes_acc: training: 0.650093 validation: 0.737792
09/16 10:24:41 AM: edges-ner-ontonotes_precision: training: 0.850581 validation: 0.914781
09/16 10:24:41 AM: edges-ner-ontonotes_recall: training: 0.696010 validation: 0.760237
09/16 10:24:41 AM: edges-ner-ontonotes_f1: training: 0.765571 validation: 0.830379
09/16 10:24:41 AM: Global learning rate: 1.25e-05
09/16 10:24:41 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:24:50 AM: Update 43121: task edges-ner-ontonotes, batch 121 (43121): mcc: 0.7656, acc: 0.6590, precision: 0.8529, recall: 0.7083, f1: 0.7739, edges-ner-ontonotes_loss: 0.0621
09/16 10:25:00 AM: Update 43259: task edges-ner-ontonotes, batch 259 (43259): mcc: 0.7722, acc: 0.6680, precision: 0.8579, recall: 0.7157, f1: 0.7804, edges-ner-ontonotes_loss: 0.0611
09/16 10:25:10 AM: Update 43379: task edges-ner-ontonotes, batch 379 (43379): mcc: 0.7480, acc: 0.6380, precision: 0.8423, recall: 0.6866, f1: 0.7565, edges-ner-ontonotes_loss: 0.0674
09/16 10:25:20 AM: Update 43530: task edges-ner-ontonotes, batch 530 (43530): mcc: 0.7401, acc: 0.6284, precision: 0.8378, recall: 0.6765, f1: 0.7486, edges-ner-ontonotes_loss: 0.0707
09/16 10:25:30 AM: Update 43654: task edges-ner-ontonotes, batch 654 (43654): mcc: 0.7364, acc: 0.6243, precision: 0.8350, recall: 0.6724, f1: 0.7449, edges-ner-ontonotes_loss: 0.0714
09/16 10:25:40 AM: Update 43825: task edges-ner-ontonotes, batch 825 (43825): mcc: 0.7376, acc: 0.6251, precision: 0.8366, recall: 0.6731, f1: 0.7460, edges-ner-ontonotes_loss: 0.0709
09/16 10:25:50 AM: Update 43948: task edges-ner-ontonotes, batch 948 (43948): mcc: 0.7379, acc: 0.6256, precision: 0.8374, recall: 0.6729, f1: 0.7462, edges-ner-ontonotes_loss: 0.0706
09/16 10:25:54 AM: ***** Step 44000 / Validation 44 *****
09/16 10:25:54 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:25:54 AM: Validating...
09/16 10:26:00 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.8198, acc: 0.7333, precision: 0.9058, recall: 0.7583, f1: 0.8255, edges-ner-ontonotes_loss: 0.0530
09/16 10:26:10 AM: Evaluate: task edges-ner-ontonotes, batch 140 (157): mcc: 0.8274, acc: 0.7384, precision: 0.9212, recall: 0.7584, f1: 0.8319, edges-ner-ontonotes_loss: 0.0496
09/16 10:26:12 AM: Updating LR scheduler:
09/16 10:26:12 AM: 	Best result seen so far for macro_avg: 0.830
09/16 10:26:12 AM: 	# validation passes without improvement: 1
09/16 10:26:12 AM: edges-ner-ontonotes_loss: training: 0.070395 validation: 0.049640
09/16 10:26:12 AM: macro_avg: validation: 0.829165
09/16 10:26:12 AM: micro_avg: validation: 0.000000
09/16 10:26:12 AM: edges-ner-ontonotes_mcc: training: 0.738988 validation: 0.824520
09/16 10:26:12 AM: edges-ner-ontonotes_acc: training: 0.627057 validation: 0.734683
09/16 10:26:12 AM: edges-ner-ontonotes_precision: training: 0.837856 validation: 0.918919
09/16 10:26:12 AM: edges-ner-ontonotes_recall: training: 0.674531 validation: 0.755384
09/16 10:26:12 AM: edges-ner-ontonotes_f1: training: 0.747374 validation: 0.829165
09/16 10:26:12 AM: Global learning rate: 1.25e-05
09/16 10:26:12 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:26:20 AM: Update 44116: task edges-ner-ontonotes, batch 116 (44116): mcc: 0.7586, acc: 0.6527, precision: 0.8526, recall: 0.6964, f1: 0.7666, edges-ner-ontonotes_loss: 0.0642
09/16 10:26:30 AM: Update 44231: task edges-ner-ontonotes, batch 231 (44231): mcc: 0.7532, acc: 0.6467, precision: 0.8484, recall: 0.6905, f1: 0.7614, edges-ner-ontonotes_loss: 0.0655
09/16 10:26:41 AM: Update 44369: task edges-ner-ontonotes, batch 369 (44369): mcc: 0.7629, acc: 0.6583, precision: 0.8535, recall: 0.7030, f1: 0.7710, edges-ner-ontonotes_loss: 0.0632
09/16 10:26:51 AM: Update 44497: task edges-ner-ontonotes, batch 497 (44497): mcc: 0.7688, acc: 0.6660, precision: 0.8576, recall: 0.7101, f1: 0.7769, edges-ner-ontonotes_loss: 0.0619
09/16 10:27:01 AM: Update 44618: task edges-ner-ontonotes, batch 618 (44618): mcc: 0.7685, acc: 0.6661, precision: 0.8562, recall: 0.7107, f1: 0.7767, edges-ner-ontonotes_loss: 0.0619
09/16 10:27:11 AM: Update 44749: task edges-ner-ontonotes, batch 749 (44749): mcc: 0.7687, acc: 0.6661, precision: 0.8565, recall: 0.7107, f1: 0.7768, edges-ner-ontonotes_loss: 0.0617
09/16 10:27:21 AM: Update 44860: task edges-ner-ontonotes, batch 860 (44860): mcc: 0.7645, acc: 0.6607, precision: 0.8538, recall: 0.7058, f1: 0.7728, edges-ner-ontonotes_loss: 0.0626
09/16 10:27:31 AM: Update 44992: task edges-ner-ontonotes, batch 992 (44992): mcc: 0.7565, acc: 0.6504, precision: 0.8491, recall: 0.6957, f1: 0.7648, edges-ner-ontonotes_loss: 0.0650
09/16 10:27:31 AM: ***** Step 45000 / Validation 45 *****
09/16 10:27:31 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:27:31 AM: Validating...
09/16 10:27:41 AM: Evaluate: task edges-ner-ontonotes, batch 89 (157): mcc: 0.8227, acc: 0.7327, precision: 0.9126, recall: 0.7576, f1: 0.8279, edges-ner-ontonotes_loss: 0.0523
09/16 10:27:49 AM: Updating LR scheduler:
09/16 10:27:49 AM: 	Best result seen so far for macro_avg: 0.830
09/16 10:27:49 AM: 	# validation passes without improvement: 2
09/16 10:27:49 AM: edges-ner-ontonotes_loss: training: 0.065125 validation: 0.049957
09/16 10:27:49 AM: macro_avg: validation: 0.828899
09/16 10:27:49 AM: micro_avg: validation: 0.000000
09/16 10:27:49 AM: edges-ner-ontonotes_mcc: training: 0.756119 validation: 0.824116
09/16 10:27:49 AM: edges-ner-ontonotes_acc: training: 0.649855 validation: 0.733091
09/16 10:27:49 AM: edges-ner-ontonotes_precision: training: 0.848818 validation: 0.917372
09/16 10:27:49 AM: edges-ner-ontonotes_recall: training: 0.695206 validation: 0.755990
09/16 10:27:49 AM: edges-ner-ontonotes_f1: training: 0.764371 validation: 0.828899
09/16 10:27:49 AM: Global learning rate: 1.25e-05
09/16 10:27:49 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:27:51 AM: Update 45018: task edges-ner-ontonotes, batch 18 (45018): mcc: 0.7157, acc: 0.5997, precision: 0.8134, recall: 0.6545, f1: 0.7254, edges-ner-ontonotes_loss: 0.0792
09/16 10:28:01 AM: Update 45145: task edges-ner-ontonotes, batch 145 (45145): mcc: 0.7189, acc: 0.6039, precision: 0.8207, recall: 0.6540, f1: 0.7279, edges-ner-ontonotes_loss: 0.0785
09/16 10:28:11 AM: Update 45317: task edges-ner-ontonotes, batch 317 (45317): mcc: 0.7290, acc: 0.6144, precision: 0.8297, recall: 0.6641, f1: 0.7377, edges-ner-ontonotes_loss: 0.0735
09/16 10:28:21 AM: Update 45447: task edges-ner-ontonotes, batch 447 (45447): mcc: 0.7308, acc: 0.6164, precision: 0.8321, recall: 0.6651, f1: 0.7393, edges-ner-ontonotes_loss: 0.0724
09/16 10:28:31 AM: Update 45577: task edges-ner-ontonotes, batch 577 (45577): mcc: 0.7344, acc: 0.6213, precision: 0.8353, recall: 0.6687, f1: 0.7427, edges-ner-ontonotes_loss: 0.0715
09/16 10:28:41 AM: Update 45715: task edges-ner-ontonotes, batch 715 (45715): mcc: 0.7409, acc: 0.6299, precision: 0.8396, recall: 0.6764, f1: 0.7492, edges-ner-ontonotes_loss: 0.0701
09/16 10:28:51 AM: Update 45824: task edges-ner-ontonotes, batch 824 (45824): mcc: 0.7447, acc: 0.6346, precision: 0.8422, recall: 0.6808, f1: 0.7530, edges-ner-ontonotes_loss: 0.0690
09/16 10:29:01 AM: Update 45957: task edges-ner-ontonotes, batch 957 (45957): mcc: 0.7509, acc: 0.6424, precision: 0.8459, recall: 0.6885, f1: 0.7591, edges-ner-ontonotes_loss: 0.0676
09/16 10:29:04 AM: ***** Step 46000 / Validation 46 *****
09/16 10:29:04 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:29:04 AM: Validating...
09/16 10:29:11 AM: Evaluate: task edges-ner-ontonotes, batch 64 (157): mcc: 0.7988, acc: 0.7069, precision: 0.8921, recall: 0.7332, f1: 0.8049, edges-ner-ontonotes_loss: 0.0589
09/16 10:29:21 AM: Evaluate: task edges-ner-ontonotes, batch 143 (157): mcc: 0.8254, acc: 0.7374, precision: 0.9166, recall: 0.7588, f1: 0.8303, edges-ner-ontonotes_loss: 0.0515
09/16 10:29:23 AM: Updating LR scheduler:
09/16 10:29:23 AM: 	Best result seen so far for macro_avg: 0.830
09/16 10:29:23 AM: 	# validation passes without improvement: 3
09/16 10:29:23 AM: edges-ner-ontonotes_loss: training: 0.067245 validation: 0.051282
09/16 10:29:23 AM: macro_avg: validation: 0.829108
09/16 10:29:23 AM: micro_avg: validation: 0.000000
09/16 10:29:23 AM: edges-ner-ontonotes_mcc: training: 0.752134 validation: 0.824127
09/16 10:29:23 AM: edges-ner-ontonotes_acc: training: 0.643822 validation: 0.735441
09/16 10:29:23 AM: edges-ner-ontonotes_precision: training: 0.846931 validation: 0.915437
09/16 10:29:23 AM: edges-ner-ontonotes_recall: training: 0.689825 validation: 0.757658
09/16 10:29:23 AM: edges-ner-ontonotes_f1: training: 0.760347 validation: 0.829108
09/16 10:29:23 AM: Global learning rate: 1.25e-05
09/16 10:29:23 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:29:31 AM: Update 46090: task edges-ner-ontonotes, batch 90 (46090): mcc: 0.7826, acc: 0.6833, precision: 0.8637, recall: 0.7292, f1: 0.7908, edges-ner-ontonotes_loss: 0.0580
09/16 10:29:41 AM: Update 46229: task edges-ner-ontonotes, batch 229 (46229): mcc: 0.7781, acc: 0.6772, precision: 0.8650, recall: 0.7199, f1: 0.7858, edges-ner-ontonotes_loss: 0.0599
09/16 10:29:51 AM: Update 46363: task edges-ner-ontonotes, batch 363 (46363): mcc: 0.7767, acc: 0.6746, precision: 0.8631, recall: 0.7193, f1: 0.7846, edges-ner-ontonotes_loss: 0.0601
09/16 10:30:01 AM: Update 46478: task edges-ner-ontonotes, batch 478 (46478): mcc: 0.7576, acc: 0.6508, precision: 0.8501, recall: 0.6967, f1: 0.7658, edges-ner-ontonotes_loss: 0.0650
09/16 10:30:11 AM: Update 46620: task edges-ner-ontonotes, batch 620 (46620): mcc: 0.7474, acc: 0.6380, precision: 0.8437, recall: 0.6843, f1: 0.7557, edges-ner-ontonotes_loss: 0.0688
09/16 10:30:21 AM: Update 46754: task edges-ner-ontonotes, batch 754 (46754): mcc: 0.7440, acc: 0.6337, precision: 0.8415, recall: 0.6802, f1: 0.7523, edges-ner-ontonotes_loss: 0.0697
09/16 10:30:31 AM: Update 46926: task edges-ner-ontonotes, batch 926 (46926): mcc: 0.7441, acc: 0.6332, precision: 0.8420, recall: 0.6800, f1: 0.7523, edges-ner-ontonotes_loss: 0.0696
09/16 10:30:38 AM: ***** Step 47000 / Validation 47 *****
09/16 10:30:38 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:30:38 AM: Validating...
09/16 10:30:42 AM: Evaluate: task edges-ner-ontonotes, batch 37 (157): mcc: 0.8017, acc: 0.7079, precision: 0.8920, recall: 0.7384, f1: 0.8080, edges-ner-ontonotes_loss: 0.0564
09/16 10:30:52 AM: Evaluate: task edges-ner-ontonotes, batch 118 (157): mcc: 0.8220, acc: 0.7290, precision: 0.9181, recall: 0.7517, f1: 0.8266, edges-ner-ontonotes_loss: 0.0509
09/16 10:30:56 AM: Updating LR scheduler:
09/16 10:30:56 AM: 	Best result seen so far for macro_avg: 0.830
09/16 10:30:56 AM: 	# validation passes without improvement: 0
09/16 10:30:56 AM: edges-ner-ontonotes_loss: training: 0.069607 validation: 0.050033
09/16 10:30:56 AM: macro_avg: validation: 0.825024
09/16 10:30:56 AM: micro_avg: validation: 0.000000
09/16 10:30:56 AM: edges-ner-ontonotes_mcc: training: 0.743006 validation: 0.820606
09/16 10:30:56 AM: edges-ner-ontonotes_acc: training: 0.631873 validation: 0.726418
09/16 10:30:56 AM: edges-ner-ontonotes_precision: training: 0.841411 validation: 0.919002
09/16 10:30:56 AM: edges-ner-ontonotes_recall: training: 0.678543 validation: 0.748483
09/16 10:30:56 AM: edges-ner-ontonotes_f1: training: 0.751251 validation: 0.825024
09/16 10:30:56 AM: Global learning rate: 6.25e-06
09/16 10:30:56 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:31:02 AM: Update 47078: task edges-ner-ontonotes, batch 78 (47078): mcc: 0.7618, acc: 0.6581, precision: 0.8553, recall: 0.6996, f1: 0.7697, edges-ner-ontonotes_loss: 0.0638
09/16 10:31:12 AM: Update 47212: task edges-ner-ontonotes, batch 212 (47212): mcc: 0.7536, acc: 0.6476, precision: 0.8494, recall: 0.6903, f1: 0.7616, edges-ner-ontonotes_loss: 0.0659
09/16 10:31:22 AM: Update 47323: task edges-ner-ontonotes, batch 323 (47323): mcc: 0.7520, acc: 0.6456, precision: 0.8470, recall: 0.6895, f1: 0.7602, edges-ner-ontonotes_loss: 0.0659
09/16 10:31:32 AM: Update 47457: task edges-ner-ontonotes, batch 457 (47457): mcc: 0.7612, acc: 0.6561, precision: 0.8524, recall: 0.7011, f1: 0.7694, edges-ner-ontonotes_loss: 0.0640
09/16 10:31:42 AM: Update 47587: task edges-ner-ontonotes, batch 587 (47587): mcc: 0.7657, acc: 0.6618, precision: 0.8545, recall: 0.7072, f1: 0.7739, edges-ner-ontonotes_loss: 0.0628
09/16 10:31:52 AM: Update 47705: task edges-ner-ontonotes, batch 705 (47705): mcc: 0.7661, acc: 0.6623, precision: 0.8547, recall: 0.7078, f1: 0.7743, edges-ner-ontonotes_loss: 0.0626
09/16 10:32:02 AM: Update 47844: task edges-ner-ontonotes, batch 844 (47844): mcc: 0.7672, acc: 0.6634, precision: 0.8553, recall: 0.7091, f1: 0.7753, edges-ner-ontonotes_loss: 0.0622
09/16 10:32:12 AM: Update 47958: task edges-ner-ontonotes, batch 958 (47958): mcc: 0.7655, acc: 0.6613, precision: 0.8541, recall: 0.7071, f1: 0.7737, edges-ner-ontonotes_loss: 0.0626
09/16 10:32:15 AM: ***** Step 48000 / Validation 48 *****
09/16 10:32:15 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:32:15 AM: Validating...
09/16 10:32:22 AM: Evaluate: task edges-ner-ontonotes, batch 64 (157): mcc: 0.8087, acc: 0.7173, precision: 0.9007, recall: 0.7431, f1: 0.8144, edges-ner-ontonotes_loss: 0.0555
09/16 10:32:32 AM: Evaluate: task edges-ner-ontonotes, batch 143 (157): mcc: 0.8282, acc: 0.7388, precision: 0.9206, recall: 0.7603, f1: 0.8328, edges-ner-ontonotes_loss: 0.0500
09/16 10:32:33 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:32:33 AM: Best result seen so far for macro.
09/16 10:32:33 AM: Updating LR scheduler:
09/16 10:32:33 AM: 	Best result seen so far for macro_avg: 0.831
09/16 10:32:33 AM: 	# validation passes without improvement: 0
09/16 10:32:33 AM: edges-ner-ontonotes_loss: training: 0.063317 validation: 0.049924
09/16 10:32:33 AM: macro_avg: validation: 0.830827
09/16 10:32:33 AM: micro_avg: validation: 0.000000
09/16 10:32:33 AM: edges-ner-ontonotes_mcc: training: 0.762715 validation: 0.826093
09/16 10:32:33 AM: edges-ner-ontonotes_acc: training: 0.657893 validation: 0.735972
09/16 10:32:33 AM: edges-ner-ontonotes_precision: training: 0.852332 validation: 0.918857
09/16 10:32:33 AM: edges-ner-ontonotes_recall: training: 0.703789 validation: 0.758189
09/16 10:32:33 AM: edges-ner-ontonotes_f1: training: 0.770971 validation: 0.830827
09/16 10:32:33 AM: Global learning rate: 6.25e-06
09/16 10:32:33 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:32:42 AM: Update 48118: task edges-ner-ontonotes, batch 118 (48118): mcc: 0.7002, acc: 0.5811, precision: 0.8106, recall: 0.6301, f1: 0.7090, edges-ner-ontonotes_loss: 0.0826
09/16 10:32:52 AM: Update 48238: task edges-ner-ontonotes, batch 238 (48238): mcc: 0.7046, acc: 0.5862, precision: 0.8116, recall: 0.6367, f1: 0.7136, edges-ner-ontonotes_loss: 0.0812
09/16 10:33:02 AM: Update 48402: task edges-ner-ontonotes, batch 402 (48402): mcc: 0.7189, acc: 0.6028, precision: 0.8222, recall: 0.6527, f1: 0.7277, edges-ner-ontonotes_loss: 0.0760
09/16 10:33:13 AM: Update 48550: task edges-ner-ontonotes, batch 550 (48550): mcc: 0.7239, acc: 0.6080, precision: 0.8265, recall: 0.6578, f1: 0.7326, edges-ner-ontonotes_loss: 0.0744
09/16 10:33:23 AM: Update 48690: task edges-ner-ontonotes, batch 690 (48690): mcc: 0.7300, acc: 0.6157, precision: 0.8314, recall: 0.6644, f1: 0.7386, edges-ner-ontonotes_loss: 0.0727
09/16 10:33:33 AM: Update 48830: task edges-ner-ontonotes, batch 830 (48830): mcc: 0.7341, acc: 0.6209, precision: 0.8339, recall: 0.6693, f1: 0.7426, edges-ner-ontonotes_loss: 0.0717
09/16 10:33:43 AM: Update 48945: task edges-ner-ontonotes, batch 945 (48945): mcc: 0.7377, acc: 0.6252, precision: 0.8369, recall: 0.6731, f1: 0.7461, edges-ner-ontonotes_loss: 0.0707
09/16 10:33:47 AM: ***** Step 49000 / Validation 49 *****
09/16 10:33:47 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:33:47 AM: Validating...
09/16 10:33:53 AM: Evaluate: task edges-ner-ontonotes, batch 57 (157): mcc: 0.8062, acc: 0.7198, precision: 0.8913, recall: 0.7469, f1: 0.8128, edges-ner-ontonotes_loss: 0.0571
09/16 10:34:06 AM: Evaluate: task edges-ner-ontonotes, batch 137 (157): mcc: 0.8289, acc: 0.7432, precision: 0.9156, recall: 0.7659, f1: 0.8341, edges-ner-ontonotes_loss: 0.0508
09/16 10:34:08 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:34:08 AM: Best result seen so far for macro.
09/16 10:34:08 AM: Updating LR scheduler:
09/16 10:34:08 AM: 	Best result seen so far for macro_avg: 0.833
09/16 10:34:08 AM: 	# validation passes without improvement: 0
09/16 10:34:08 AM: edges-ner-ontonotes_loss: training: 0.070061 validation: 0.050368
09/16 10:34:08 AM: macro_avg: validation: 0.833106
09/16 10:34:08 AM: micro_avg: validation: 0.000000
09/16 10:34:08 AM: edges-ner-ontonotes_mcc: training: 0.740632 validation: 0.827886
09/16 10:34:08 AM: edges-ner-ontonotes_acc: training: 0.629007 validation: 0.741735
09/16 10:34:08 AM: edges-ner-ontonotes_precision: training: 0.838920 validation: 0.914830
09/16 10:34:08 AM: edges-ner-ontonotes_recall: training: 0.676500 validation: 0.764786
09/16 10:34:08 AM: edges-ner-ontonotes_f1: training: 0.749006 validation: 0.833106
09/16 10:34:08 AM: Global learning rate: 6.25e-06
09/16 10:34:08 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:34:16 AM: Update 49105: task edges-ner-ontonotes, batch 105 (49105): mcc: 0.7885, acc: 0.6917, precision: 0.8659, recall: 0.7377, f1: 0.7967, edges-ner-ontonotes_loss: 0.0567
09/16 10:34:26 AM: Update 49213: task edges-ner-ontonotes, batch 213 (49213): mcc: 0.7797, acc: 0.6787, precision: 0.8620, recall: 0.7255, f1: 0.7878, edges-ner-ontonotes_loss: 0.0592
09/16 10:34:36 AM: Update 49353: task edges-ner-ontonotes, batch 353 (49353): mcc: 0.7754, acc: 0.6728, precision: 0.8598, recall: 0.7196, f1: 0.7835, edges-ner-ontonotes_loss: 0.0601
09/16 10:34:46 AM: Update 49488: task edges-ner-ontonotes, batch 488 (49488): mcc: 0.7759, acc: 0.6729, precision: 0.8604, recall: 0.7200, f1: 0.7840, edges-ner-ontonotes_loss: 0.0602
09/16 10:34:56 AM: Update 49614: task edges-ner-ontonotes, batch 614 (49614): mcc: 0.7596, acc: 0.6536, precision: 0.8490, recall: 0.7011, f1: 0.7680, edges-ner-ontonotes_loss: 0.0651
09/16 10:35:06 AM: Update 49753: task edges-ner-ontonotes, batch 753 (49753): mcc: 0.7504, acc: 0.6418, precision: 0.8437, recall: 0.6895, f1: 0.7588, edges-ner-ontonotes_loss: 0.0677
09/16 10:35:16 AM: Update 49896: task edges-ner-ontonotes, batch 896 (49896): mcc: 0.7490, acc: 0.6399, precision: 0.8431, recall: 0.6876, f1: 0.7574, edges-ner-ontonotes_loss: 0.0683
09/16 10:35:22 AM: ***** Step 50000 / Validation 50 *****
09/16 10:35:25 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:35:25 AM: Validating...
09/16 10:35:26 AM: Evaluate: task edges-ner-ontonotes, batch 14 (157): mcc: 0.7501, acc: 0.6470, precision: 0.8545, recall: 0.6799, f1: 0.7573, edges-ner-ontonotes_loss: 0.0650
09/16 10:35:36 AM: Evaluate: task edges-ner-ontonotes, batch 99 (157): mcc: 0.8216, acc: 0.7308, precision: 0.9141, recall: 0.7544, f1: 0.8266, edges-ner-ontonotes_loss: 0.0525
09/16 10:35:44 AM: Updating LR scheduler:
09/16 10:35:44 AM: 	Best result seen so far for macro_avg: 0.833
09/16 10:35:44 AM: 	# validation passes without improvement: 1
09/16 10:35:44 AM: edges-ner-ontonotes_loss: training: 0.068422 validation: 0.050000
09/16 10:35:44 AM: macro_avg: validation: 0.826129
09/16 10:35:44 AM: micro_avg: validation: 0.000000
09/16 10:35:44 AM: edges-ner-ontonotes_mcc: training: 0.748357 validation: 0.821491
09/16 10:35:44 AM: edges-ner-ontonotes_acc: training: 0.638689 validation: 0.728996
09/16 10:35:44 AM: edges-ner-ontonotes_precision: training: 0.843252 validation: 0.917415
09/16 10:35:44 AM: edges-ner-ontonotes_recall: training: 0.686338 validation: 0.751365
09/16 10:35:44 AM: edges-ner-ontonotes_f1: training: 0.756747 validation: 0.826129
09/16 10:35:44 AM: Global learning rate: 6.25e-06
09/16 10:35:44 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:35:46 AM: Update 50041: task edges-ner-ontonotes, batch 41 (50041): mcc: 0.7297, acc: 0.6112, precision: 0.8309, recall: 0.6642, f1: 0.7383, edges-ner-ontonotes_loss: 0.0725
09/16 10:35:56 AM: Update 50158: task edges-ner-ontonotes, batch 158 (50158): mcc: 0.7333, acc: 0.6174, precision: 0.8342, recall: 0.6677, f1: 0.7417, edges-ner-ontonotes_loss: 0.0699
09/16 10:36:06 AM: Update 50293: task edges-ner-ontonotes, batch 293 (50293): mcc: 0.7429, acc: 0.6304, precision: 0.8409, recall: 0.6787, f1: 0.7512, edges-ner-ontonotes_loss: 0.0681
09/16 10:36:17 AM: Update 50419: task edges-ner-ontonotes, batch 419 (50419): mcc: 0.7464, acc: 0.6357, precision: 0.8441, recall: 0.6822, f1: 0.7546, edges-ner-ontonotes_loss: 0.0675
09/16 10:36:27 AM: Update 50548: task edges-ner-ontonotes, batch 548 (50548): mcc: 0.7546, acc: 0.6459, precision: 0.8499, recall: 0.6915, f1: 0.7626, edges-ner-ontonotes_loss: 0.0655
09/16 10:36:37 AM: Update 50681: task edges-ner-ontonotes, batch 681 (50681): mcc: 0.7608, acc: 0.6540, precision: 0.8532, recall: 0.6997, f1: 0.7689, edges-ner-ontonotes_loss: 0.0641
09/16 10:36:47 AM: Update 50798: task edges-ner-ontonotes, batch 798 (50798): mcc: 0.7629, acc: 0.6568, precision: 0.8542, recall: 0.7025, f1: 0.7709, edges-ner-ontonotes_loss: 0.0636
09/16 10:36:57 AM: Update 50933: task edges-ner-ontonotes, batch 933 (50933): mcc: 0.7652, acc: 0.6596, precision: 0.8560, recall: 0.7050, f1: 0.7732, edges-ner-ontonotes_loss: 0.0628
09/16 10:37:02 AM: ***** Step 51000 / Validation 51 *****
09/16 10:37:02 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:37:02 AM: Validating...
09/16 10:37:07 AM: Evaluate: task edges-ner-ontonotes, batch 52 (157): mcc: 0.7898, acc: 0.6969, precision: 0.8815, recall: 0.7265, f1: 0.7965, edges-ner-ontonotes_loss: 0.0612
09/16 10:37:18 AM: Evaluate: task edges-ner-ontonotes, batch 131 (157): mcc: 0.8220, acc: 0.7339, precision: 0.9109, recall: 0.7577, f1: 0.8273, edges-ner-ontonotes_loss: 0.0526
09/16 10:37:21 AM: Updating LR scheduler:
09/16 10:37:21 AM: 	Best result seen so far for macro_avg: 0.833
09/16 10:37:21 AM: 	# validation passes without improvement: 2
09/16 10:37:21 AM: edges-ner-ontonotes_loss: training: 0.062930 validation: 0.051221
09/16 10:37:21 AM: macro_avg: validation: 0.830172
09/16 10:37:21 AM: micro_avg: validation: 0.000000
09/16 10:37:21 AM: edges-ner-ontonotes_mcc: training: 0.765626 validation: 0.824856
09/16 10:37:21 AM: edges-ner-ontonotes_acc: training: 0.660159 validation: 0.737564
09/16 10:37:21 AM: edges-ner-ontonotes_precision: training: 0.856154 validation: 0.912419
09/16 10:37:21 AM: edges-ner-ontonotes_recall: training: 0.705631 validation: 0.761526
09/16 10:37:21 AM: edges-ner-ontonotes_f1: training: 0.773639 validation: 0.830172
09/16 10:37:21 AM: Global learning rate: 6.25e-06
09/16 10:37:21 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:37:28 AM: Update 51075: task edges-ner-ontonotes, batch 75 (51075): mcc: 0.7252, acc: 0.6114, precision: 0.8236, recall: 0.6625, f1: 0.7343, edges-ner-ontonotes_loss: 0.0719
09/16 10:37:38 AM: Update 51220: task edges-ner-ontonotes, batch 220 (51220): mcc: 0.7118, acc: 0.5962, precision: 0.8184, recall: 0.6436, f1: 0.7206, edges-ner-ontonotes_loss: 0.0783
09/16 10:37:49 AM: Update 51349: task edges-ner-ontonotes, batch 349 (51349): mcc: 0.7069, acc: 0.5902, precision: 0.8145, recall: 0.6383, f1: 0.7157, edges-ner-ontonotes_loss: 0.0793
09/16 10:37:59 AM: Update 51507: task edges-ner-ontonotes, batch 507 (51507): mcc: 0.7160, acc: 0.6003, precision: 0.8215, recall: 0.6483, f1: 0.7247, edges-ner-ontonotes_loss: 0.0764
09/16 10:38:10 AM: Update 51662: task edges-ner-ontonotes, batch 662 (51662): mcc: 0.7211, acc: 0.6057, precision: 0.8256, recall: 0.6537, f1: 0.7296, edges-ner-ontonotes_loss: 0.0748
09/16 10:38:20 AM: Update 51800: task edges-ner-ontonotes, batch 800 (51800): mcc: 0.7249, acc: 0.6105, precision: 0.8286, recall: 0.6578, f1: 0.7334, edges-ner-ontonotes_loss: 0.0738
09/16 10:38:30 AM: Update 51939: task edges-ner-ontonotes, batch 939 (51939): mcc: 0.7297, acc: 0.6166, precision: 0.8320, recall: 0.6633, f1: 0.7382, edges-ner-ontonotes_loss: 0.0724
09/16 10:38:36 AM: ***** Step 52000 / Validation 52 *****
09/16 10:38:36 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:38:36 AM: Validating...
09/16 10:38:40 AM: Evaluate: task edges-ner-ontonotes, batch 44 (157): mcc: 0.8008, acc: 0.7120, precision: 0.8864, recall: 0.7416, f1: 0.8076, edges-ner-ontonotes_loss: 0.0570
09/16 10:38:50 AM: Evaluate: task edges-ner-ontonotes, batch 121 (157): mcc: 0.8236, acc: 0.7350, precision: 0.9142, recall: 0.7577, f1: 0.8286, edges-ner-ontonotes_loss: 0.0510
09/16 10:38:54 AM: Updating LR scheduler:
09/16 10:38:54 AM: 	Best result seen so far for macro_avg: 0.833
09/16 10:38:54 AM: 	# validation passes without improvement: 3
09/16 10:38:54 AM: edges-ner-ontonotes_loss: training: 0.071986 validation: 0.049519
09/16 10:38:54 AM: macro_avg: validation: 0.830846
09/16 10:38:54 AM: micro_avg: validation: 0.000000
09/16 10:38:54 AM: edges-ner-ontonotes_mcc: training: 0.731433 validation: 0.825891
09/16 10:38:54 AM: edges-ner-ontonotes_acc: training: 0.618688 validation: 0.737413
09/16 10:38:54 AM: edges-ner-ontonotes_precision: training: 0.833317 validation: 0.916575
09/16 10:38:54 AM: edges-ner-ontonotes_recall: training: 0.665186 validation: 0.759782
09/16 10:38:54 AM: edges-ner-ontonotes_f1: training: 0.739820 validation: 0.830846
09/16 10:38:54 AM: Global learning rate: 6.25e-06
09/16 10:38:54 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:39:00 AM: Update 52080: task edges-ner-ontonotes, batch 80 (52080): mcc: 0.7834, acc: 0.6822, precision: 0.8714, recall: 0.7238, f1: 0.7908, edges-ner-ontonotes_loss: 0.0577
09/16 10:39:10 AM: Update 52213: task edges-ner-ontonotes, batch 213 (52213): mcc: 0.7817, acc: 0.6805, precision: 0.8658, recall: 0.7257, f1: 0.7896, edges-ner-ontonotes_loss: 0.0586
09/16 10:39:20 AM: Update 52330: task edges-ner-ontonotes, batch 330 (52330): mcc: 0.7797, acc: 0.6792, precision: 0.8622, recall: 0.7252, f1: 0.7878, edges-ner-ontonotes_loss: 0.0590
09/16 10:39:30 AM: Update 52464: task edges-ner-ontonotes, batch 464 (52464): mcc: 0.7766, acc: 0.6745, precision: 0.8610, recall: 0.7207, f1: 0.7846, edges-ner-ontonotes_loss: 0.0599
09/16 10:39:41 AM: Update 52601: task edges-ner-ontonotes, batch 601 (52601): mcc: 0.7746, acc: 0.6718, precision: 0.8603, recall: 0.7179, f1: 0.7826, edges-ner-ontonotes_loss: 0.0603
09/16 10:39:51 AM: Update 52742: task edges-ner-ontonotes, batch 742 (52742): mcc: 0.7610, acc: 0.6545, precision: 0.8521, recall: 0.7009, f1: 0.7691, edges-ner-ontonotes_loss: 0.0647
09/16 10:40:01 AM: Update 52884: task edges-ner-ontonotes, batch 884 (52884): mcc: 0.7536, acc: 0.6459, precision: 0.8469, recall: 0.6923, f1: 0.7619, edges-ner-ontonotes_loss: 0.0672
09/16 10:40:10 AM: ***** Step 53000 / Validation 53 *****
09/16 10:40:10 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:40:10 AM: Validating...
09/16 10:40:11 AM: Evaluate: task edges-ner-ontonotes, batch 14 (157): mcc: 0.7480, acc: 0.6459, precision: 0.8529, recall: 0.6776, f1: 0.7552, edges-ner-ontonotes_loss: 0.0651
09/16 10:40:21 AM: Evaluate: task edges-ner-ontonotes, batch 100 (157): mcc: 0.8194, acc: 0.7271, precision: 0.9141, recall: 0.7504, f1: 0.8242, edges-ner-ontonotes_loss: 0.0529
09/16 10:40:29 AM: Updating LR scheduler:
09/16 10:40:29 AM: 	Best result seen so far for macro_avg: 0.833
09/16 10:40:29 AM: 	# validation passes without improvement: 0
09/16 10:40:29 AM: edges-ner-ontonotes_loss: training: 0.067682 validation: 0.049995
09/16 10:40:29 AM: macro_avg: validation: 0.826346
09/16 10:40:29 AM: micro_avg: validation: 0.000000
09/16 10:40:29 AM: edges-ner-ontonotes_mcc: training: 0.751316 validation: 0.821796
09/16 10:40:29 AM: edges-ner-ontonotes_acc: training: 0.643079 validation: 0.729224
09/16 10:40:29 AM: edges-ner-ontonotes_precision: training: 0.845965 validation: 0.918405
09/16 10:40:29 AM: edges-ner-ontonotes_recall: training: 0.689214 validation: 0.751062
09/16 10:40:29 AM: edges-ner-ontonotes_f1: training: 0.759587 validation: 0.826346
09/16 10:40:29 AM: Global learning rate: 3.125e-06
09/16 10:40:29 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:40:31 AM: Update 53043: task edges-ner-ontonotes, batch 43 (53043): mcc: 0.7490, acc: 0.6346, precision: 0.8414, recall: 0.6890, f1: 0.7576, edges-ner-ontonotes_loss: 0.0673
09/16 10:40:41 AM: Update 53215: task edges-ner-ontonotes, batch 215 (53215): mcc: 0.7399, acc: 0.6272, precision: 0.8394, recall: 0.6749, f1: 0.7482, edges-ner-ontonotes_loss: 0.0695
09/16 10:40:51 AM: Update 53336: task edges-ner-ontonotes, batch 336 (53336): mcc: 0.7422, acc: 0.6312, precision: 0.8421, recall: 0.6766, f1: 0.7503, edges-ner-ontonotes_loss: 0.0689
09/16 10:41:01 AM: Update 53473: task edges-ner-ontonotes, batch 473 (53473): mcc: 0.7465, acc: 0.6359, precision: 0.8449, recall: 0.6818, f1: 0.7546, edges-ner-ontonotes_loss: 0.0681
09/16 10:41:11 AM: Update 53590: task edges-ner-ontonotes, batch 590 (53590): mcc: 0.7493, acc: 0.6392, precision: 0.8473, recall: 0.6846, f1: 0.7573, edges-ner-ontonotes_loss: 0.0675
09/16 10:41:22 AM: Update 53723: task edges-ner-ontonotes, batch 723 (53723): mcc: 0.7555, acc: 0.6469, precision: 0.8513, recall: 0.6920, f1: 0.7634, edges-ner-ontonotes_loss: 0.0660
09/16 10:41:32 AM: Update 53845: task edges-ner-ontonotes, batch 845 (53845): mcc: 0.7596, acc: 0.6526, precision: 0.8533, recall: 0.6976, f1: 0.7676, edges-ner-ontonotes_loss: 0.0649
09/16 10:41:42 AM: Update 53980: task edges-ner-ontonotes, batch 980 (53980): mcc: 0.7612, acc: 0.6545, precision: 0.8541, recall: 0.6995, f1: 0.7691, edges-ner-ontonotes_loss: 0.0644
09/16 10:41:43 AM: ***** Step 54000 / Validation 54 *****
09/16 10:41:43 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:41:43 AM: Validating...
09/16 10:41:52 AM: Evaluate: task edges-ner-ontonotes, batch 77 (157): mcc: 0.8056, acc: 0.7141, precision: 0.8983, recall: 0.7399, f1: 0.8114, edges-ner-ontonotes_loss: 0.0577
09/16 10:42:02 AM: Evaluate: task edges-ner-ontonotes, batch 154 (157): mcc: 0.8257, acc: 0.7378, precision: 0.9146, recall: 0.7611, f1: 0.8308, edges-ner-ontonotes_loss: 0.0508
09/16 10:42:02 AM: Updating LR scheduler:
09/16 10:42:02 AM: 	Best result seen so far for macro_avg: 0.833
09/16 10:42:02 AM: 	# validation passes without improvement: 1
09/16 10:42:02 AM: edges-ner-ontonotes_loss: training: 0.064294 validation: 0.050603
09/16 10:42:02 AM: macro_avg: validation: 0.830926
09/16 10:42:02 AM: micro_avg: validation: 0.000000
09/16 10:42:02 AM: edges-ner-ontonotes_mcc: training: 0.761527 validation: 0.825798
09/16 10:42:02 AM: edges-ner-ontonotes_acc: training: 0.654958 validation: 0.737868
09/16 10:42:02 AM: edges-ner-ontonotes_precision: training: 0.854329 validation: 0.914791
09/16 10:42:02 AM: edges-ner-ontonotes_recall: training: 0.699990 validation: 0.761146
09/16 10:42:02 AM: edges-ner-ontonotes_f1: training: 0.769497 validation: 0.830926
09/16 10:42:02 AM: Global learning rate: 3.125e-06
09/16 10:42:02 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:42:12 AM: Update 54127: task edges-ner-ontonotes, batch 127 (54127): mcc: 0.7770, acc: 0.6780, precision: 0.8594, recall: 0.7229, f1: 0.7853, edges-ner-ontonotes_loss: 0.0604
09/16 10:42:22 AM: Update 54237: task edges-ner-ontonotes, batch 237 (54237): mcc: 0.7444, acc: 0.6366, precision: 0.8393, recall: 0.6828, f1: 0.7530, edges-ner-ontonotes_loss: 0.0680
09/16 10:42:32 AM: Update 54380: task edges-ner-ontonotes, batch 380 (54380): mcc: 0.7302, acc: 0.6179, precision: 0.8307, recall: 0.6652, f1: 0.7388, edges-ner-ontonotes_loss: 0.0736
09/16 10:42:42 AM: Update 54500: task edges-ner-ontonotes, batch 500 (54500): mcc: 0.7272, acc: 0.6135, precision: 0.8294, recall: 0.6610, f1: 0.7357, edges-ner-ontonotes_loss: 0.0740
09/16 10:42:52 AM: Update 54669: task edges-ner-ontonotes, batch 669 (54669): mcc: 0.7303, acc: 0.6164, precision: 0.8316, recall: 0.6646, f1: 0.7388, edges-ner-ontonotes_loss: 0.0728
09/16 10:43:02 AM: Update 54799: task edges-ner-ontonotes, batch 799 (54799): mcc: 0.7311, acc: 0.6176, precision: 0.8330, recall: 0.6648, f1: 0.7395, edges-ner-ontonotes_loss: 0.0725
09/16 10:43:12 AM: Update 54938: task edges-ner-ontonotes, batch 938 (54938): mcc: 0.7360, acc: 0.6235, precision: 0.8367, recall: 0.6703, f1: 0.7444, edges-ner-ontonotes_loss: 0.0714
09/16 10:43:17 AM: ***** Step 55000 / Validation 55 *****
09/16 10:43:17 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:43:17 AM: Validating...
09/16 10:43:22 AM: Evaluate: task edges-ner-ontonotes, batch 55 (157): mcc: 0.8132, acc: 0.7250, precision: 0.8995, recall: 0.7522, f1: 0.8193, edges-ner-ontonotes_loss: 0.0542
09/16 10:43:32 AM: Evaluate: task edges-ner-ontonotes, batch 135 (157): mcc: 0.8272, acc: 0.7381, precision: 0.9200, recall: 0.7591, f1: 0.8318, edges-ner-ontonotes_loss: 0.0498
09/16 10:43:35 AM: Updating LR scheduler:
09/16 10:43:35 AM: 	Best result seen so far for macro_avg: 0.833
09/16 10:43:35 AM: 	# validation passes without improvement: 2
09/16 10:43:35 AM: edges-ner-ontonotes_loss: training: 0.071156 validation: 0.049473
09/16 10:43:35 AM: macro_avg: validation: 0.830267
09/16 10:43:35 AM: micro_avg: validation: 0.000000
09/16 10:43:35 AM: edges-ner-ontonotes_mcc: training: 0.736886 validation: 0.825460
09/16 10:43:35 AM: edges-ner-ontonotes_acc: training: 0.624575 validation: 0.735896
09/16 10:43:35 AM: edges-ner-ontonotes_precision: training: 0.837536 validation: 0.917822
09/16 10:43:35 AM: edges-ner-ontonotes_recall: training: 0.671137 validation: 0.757962
09/16 10:43:35 AM: edges-ner-ontonotes_f1: training: 0.745160 validation: 0.830267
09/16 10:43:35 AM: Global learning rate: 3.125e-06
09/16 10:43:35 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:43:43 AM: Update 55087: task edges-ner-ontonotes, batch 87 (55087): mcc: 0.7546, acc: 0.6464, precision: 0.8485, recall: 0.6928, f1: 0.7628, edges-ner-ontonotes_loss: 0.0655
09/16 10:43:53 AM: Update 55223: task edges-ner-ontonotes, batch 223 (55223): mcc: 0.7675, acc: 0.6633, precision: 0.8588, recall: 0.7067, f1: 0.7754, edges-ner-ontonotes_loss: 0.0622
09/16 10:44:03 AM: Update 55361: task edges-ner-ontonotes, batch 361 (55361): mcc: 0.7761, acc: 0.6728, precision: 0.8637, recall: 0.7176, f1: 0.7839, edges-ner-ontonotes_loss: 0.0601
09/16 10:44:13 AM: Update 55475: task edges-ner-ontonotes, batch 475 (55475): mcc: 0.7742, acc: 0.6711, precision: 0.8615, recall: 0.7162, f1: 0.7822, edges-ner-ontonotes_loss: 0.0603
09/16 10:44:23 AM: Update 55614: task edges-ner-ontonotes, batch 614 (55614): mcc: 0.7746, acc: 0.6715, precision: 0.8608, recall: 0.7175, f1: 0.7826, edges-ner-ontonotes_loss: 0.0605
09/16 10:44:33 AM: Update 55726: task edges-ner-ontonotes, batch 726 (55726): mcc: 0.7697, acc: 0.6655, precision: 0.8569, recall: 0.7121, f1: 0.7778, edges-ner-ontonotes_loss: 0.0614
09/16 10:44:43 AM: Update 55868: task edges-ner-ontonotes, batch 868 (55868): mcc: 0.7588, acc: 0.6520, precision: 0.8500, recall: 0.6989, f1: 0.7671, edges-ner-ontonotes_loss: 0.0650
09/16 10:44:52 AM: ***** Step 56000 / Validation 56 *****
09/16 10:44:52 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:44:52 AM: Validating...
09/16 10:44:53 AM: Evaluate: task edges-ner-ontonotes, batch 8 (157): mcc: 0.7287, acc: 0.6293, precision: 0.8411, recall: 0.6540, f1: 0.7358, edges-ner-ontonotes_loss: 0.0730
09/16 10:45:03 AM: Evaluate: task edges-ner-ontonotes, batch 99 (157): mcc: 0.8228, acc: 0.7339, precision: 0.9127, recall: 0.7576, f1: 0.8279, edges-ner-ontonotes_loss: 0.0530
09/16 10:45:10 AM: Updating LR scheduler:
09/16 10:45:10 AM: 	Best result seen so far for macro_avg: 0.833
09/16 10:45:10 AM: 	# validation passes without improvement: 3
09/16 10:45:10 AM: edges-ner-ontonotes_loss: training: 0.066876 validation: 0.049723
09/16 10:45:10 AM: macro_avg: validation: 0.831581
09/16 10:45:10 AM: micro_avg: validation: 0.000000
09/16 10:45:10 AM: edges-ner-ontonotes_mcc: training: 0.752845 validation: 0.826913
09/16 10:45:10 AM: edges-ner-ontonotes_acc: training: 0.644578 validation: 0.736579
09/16 10:45:10 AM: edges-ner-ontonotes_precision: training: 0.846572 validation: 0.919923
09/16 10:45:10 AM: edges-ner-ontonotes_recall: training: 0.691377 validation: 0.758720
09/16 10:45:10 AM: edges-ner-ontonotes_f1: training: 0.761144 validation: 0.831581
09/16 10:45:10 AM: Global learning rate: 3.125e-06
09/16 10:45:10 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:45:13 AM: Update 56017: task edges-ner-ontonotes, batch 17 (56017): mcc: 0.6852, acc: 0.5676, precision: 0.7992, recall: 0.6134, f1: 0.6941, edges-ner-ontonotes_loss: 0.0817
09/16 10:45:24 AM: Update 56187: task edges-ner-ontonotes, batch 187 (56187): mcc: 0.7377, acc: 0.6233, precision: 0.8395, recall: 0.6709, f1: 0.7458, edges-ner-ontonotes_loss: 0.0706
09/16 10:45:34 AM: Update 56330: task edges-ner-ontonotes, batch 330 (56330): mcc: 0.7372, acc: 0.6237, precision: 0.8385, recall: 0.6710, f1: 0.7454, edges-ner-ontonotes_loss: 0.0704
09/16 10:45:45 AM: Update 56467: task edges-ner-ontonotes, batch 467 (56467): mcc: 0.7398, acc: 0.6276, precision: 0.8400, recall: 0.6742, f1: 0.7480, edges-ner-ontonotes_loss: 0.0695
09/16 10:45:55 AM: Update 56612: task edges-ner-ontonotes, batch 612 (56612): mcc: 0.7439, acc: 0.6325, precision: 0.8421, recall: 0.6795, f1: 0.7521, edges-ner-ontonotes_loss: 0.0687
09/16 10:46:05 AM: Update 56736: task edges-ner-ontonotes, batch 736 (56736): mcc: 0.7487, acc: 0.6386, precision: 0.8458, recall: 0.6847, f1: 0.7568, edges-ner-ontonotes_loss: 0.0674
09/16 10:46:15 AM: Update 56868: task edges-ner-ontonotes, batch 868 (56868): mcc: 0.7535, acc: 0.6450, precision: 0.8490, recall: 0.6905, f1: 0.7615, edges-ner-ontonotes_loss: 0.0664
09/16 10:46:25 AM: Update 56979: task edges-ner-ontonotes, batch 979 (56979): mcc: 0.7569, acc: 0.6491, precision: 0.8506, recall: 0.6951, f1: 0.7650, edges-ner-ontonotes_loss: 0.0654
09/16 10:46:26 AM: ***** Step 57000 / Validation 57 *****
09/16 10:46:26 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:46:26 AM: Validating...
09/16 10:46:35 AM: Evaluate: task edges-ner-ontonotes, batch 81 (157): mcc: 0.8119, acc: 0.7220, precision: 0.9025, recall: 0.7472, f1: 0.8175, edges-ner-ontonotes_loss: 0.0564
09/16 10:46:44 AM: Updating LR scheduler:
09/16 10:46:44 AM: 	Best result seen so far for macro_avg: 0.833
09/16 10:46:44 AM: 	# validation passes without improvement: 0
09/16 10:46:44 AM: edges-ner-ontonotes_loss: training: 0.065322 validation: 0.050428
09/16 10:46:44 AM: macro_avg: validation: 0.831830
09/16 10:46:44 AM: micro_avg: validation: 0.000000
09/16 10:46:44 AM: edges-ner-ontonotes_mcc: training: 0.757196 validation: 0.826734
09/16 10:46:44 AM: edges-ner-ontonotes_acc: training: 0.649489 validation: 0.739157
09/16 10:46:44 AM: edges-ner-ontonotes_precision: training: 0.850790 validation: 0.915558
09/16 10:46:44 AM: edges-ner-ontonotes_recall: training: 0.695413 validation: 0.762132
09/16 10:46:44 AM: edges-ner-ontonotes_f1: training: 0.765294 validation: 0.831830
09/16 10:46:44 AM: Global learning rate: 1.5625e-06
09/16 10:46:44 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:46:45 AM: Update 57009: task edges-ner-ontonotes, batch 9 (57009): mcc: 0.7508, acc: 0.6513, precision: 0.8369, recall: 0.6961, f1: 0.7600, edges-ner-ontonotes_loss: 0.0608
09/16 10:46:55 AM: Update 57147: task edges-ner-ontonotes, batch 147 (57147): mcc: 0.7753, acc: 0.6728, precision: 0.8612, recall: 0.7183, f1: 0.7833, edges-ner-ontonotes_loss: 0.0596
09/16 10:47:05 AM: Update 57269: task edges-ner-ontonotes, batch 269 (57269): mcc: 0.7721, acc: 0.6690, precision: 0.8587, recall: 0.7149, f1: 0.7802, edges-ner-ontonotes_loss: 0.0604
09/16 10:47:15 AM: Update 57411: task edges-ner-ontonotes, batch 411 (57411): mcc: 0.7450, acc: 0.6356, precision: 0.8403, recall: 0.6828, f1: 0.7535, edges-ner-ontonotes_loss: 0.0685
09/16 10:47:25 AM: Update 57553: task edges-ner-ontonotes, batch 553 (57553): mcc: 0.7346, acc: 0.6225, precision: 0.8335, recall: 0.6705, f1: 0.7432, edges-ner-ontonotes_loss: 0.0721
09/16 10:47:35 AM: Update 57694: task edges-ner-ontonotes, batch 694 (57694): mcc: 0.7345, acc: 0.6225, precision: 0.8340, recall: 0.6699, f1: 0.7430, edges-ner-ontonotes_loss: 0.0720
09/16 10:47:45 AM: Update 57859: task edges-ner-ontonotes, batch 859 (57859): mcc: 0.7356, acc: 0.6232, precision: 0.8351, recall: 0.6710, f1: 0.7441, edges-ner-ontonotes_loss: 0.0715
09/16 10:47:55 AM: Update 57988: task edges-ner-ontonotes, batch 988 (57988): mcc: 0.7368, acc: 0.6252, precision: 0.8363, recall: 0.6720, f1: 0.7452, edges-ner-ontonotes_loss: 0.0711
09/16 10:47:56 AM: ***** Step 58000 / Validation 58 *****
09/16 10:47:56 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:47:56 AM: Validating...
09/16 10:48:05 AM: Evaluate: task edges-ner-ontonotes, batch 84 (157): mcc: 0.8229, acc: 0.7332, precision: 0.9146, recall: 0.7563, f1: 0.8279, edges-ner-ontonotes_loss: 0.0527
09/16 10:48:15 AM: Updating LR scheduler:
09/16 10:48:15 AM: 	Best result seen so far for macro_avg: 0.833
09/16 10:48:15 AM: 	# validation passes without improvement: 1
09/16 10:48:15 AM: edges-ner-ontonotes_loss: training: 0.071079 validation: 0.049476
09/16 10:48:15 AM: macro_avg: validation: 0.830790
09/16 10:48:15 AM: micro_avg: validation: 0.000000
09/16 10:48:15 AM: edges-ner-ontonotes_mcc: training: 0.736589 validation: 0.826157
09/16 10:48:15 AM: edges-ner-ontonotes_acc: training: 0.624959 validation: 0.735517
09/16 10:48:15 AM: edges-ner-ontonotes_precision: training: 0.836021 validation: 0.919882
09/16 10:48:15 AM: edges-ner-ontonotes_recall: training: 0.671893 validation: 0.757431
09/16 10:48:15 AM: edges-ner-ontonotes_f1: training: 0.745025 validation: 0.830790
09/16 10:48:15 AM: Global learning rate: 1.5625e-06
09/16 10:48:15 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:48:15 AM: Update 58011: task edges-ner-ontonotes, batch 11 (58011): mcc: 0.7663, acc: 0.6617, precision: 0.8647, recall: 0.6995, f1: 0.7734, edges-ner-ontonotes_loss: 0.0635
09/16 10:48:25 AM: Update 58151: task edges-ner-ontonotes, batch 151 (58151): mcc: 0.7539, acc: 0.6457, precision: 0.8500, recall: 0.6903, f1: 0.7619, edges-ner-ontonotes_loss: 0.0661
09/16 10:48:36 AM: Update 58260: task edges-ner-ontonotes, batch 260 (58260): mcc: 0.7539, acc: 0.6450, precision: 0.8524, recall: 0.6883, f1: 0.7616, edges-ner-ontonotes_loss: 0.0653
09/16 10:48:46 AM: Update 58395: task edges-ner-ontonotes, batch 395 (58395): mcc: 0.7612, acc: 0.6532, precision: 0.8564, recall: 0.6978, f1: 0.7690, edges-ner-ontonotes_loss: 0.0631
09/16 10:48:56 AM: Update 58512: task edges-ner-ontonotes, batch 512 (58512): mcc: 0.7654, acc: 0.6587, precision: 0.8590, recall: 0.7028, f1: 0.7731, edges-ner-ontonotes_loss: 0.0626
09/16 10:49:06 AM: Update 58645: task edges-ner-ontonotes, batch 645 (58645): mcc: 0.7658, acc: 0.6589, precision: 0.8589, recall: 0.7037, f1: 0.7736, edges-ner-ontonotes_loss: 0.0623
09/16 10:49:16 AM: Update 58779: task edges-ner-ontonotes, batch 779 (58779): mcc: 0.7674, acc: 0.6609, precision: 0.8591, recall: 0.7062, f1: 0.7752, edges-ner-ontonotes_loss: 0.0622
09/16 10:49:26 AM: Update 58900: task edges-ner-ontonotes, batch 900 (58900): mcc: 0.7623, acc: 0.6548, precision: 0.8549, recall: 0.7009, f1: 0.7703, edges-ner-ontonotes_loss: 0.0638
09/16 10:49:33 AM: ***** Step 59000 / Validation 59 *****
09/16 10:49:33 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:49:33 AM: Validating...
09/16 10:49:36 AM: Evaluate: task edges-ner-ontonotes, batch 31 (157): mcc: 0.7851, acc: 0.6898, precision: 0.8781, recall: 0.7210, f1: 0.7918, edges-ner-ontonotes_loss: 0.0618
09/16 10:49:46 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.8233, acc: 0.7348, precision: 0.9141, recall: 0.7573, f1: 0.8284, edges-ner-ontonotes_loss: 0.0519
09/16 10:49:51 AM: Updating LR scheduler:
09/16 10:49:53 AM: 	Best result seen so far for macro_avg: 0.833
09/16 10:49:53 AM: 	# validation passes without improvement: 2
09/16 10:49:53 AM: Ran out of early stopping patience. Stopping training.
09/16 10:49:53 AM: edges-ner-ontonotes_loss: training: 0.065514 validation: 0.049580
09/16 10:49:53 AM: macro_avg: validation: 0.832677
09/16 10:49:53 AM: micro_avg: validation: 0.000000
09/16 10:49:53 AM: edges-ner-ontonotes_mcc: training: 0.756680 validation: 0.827798
09/16 10:49:53 AM: edges-ner-ontonotes_acc: training: 0.648343 validation: 0.739308
09/16 10:49:53 AM: edges-ner-ontonotes_precision: training: 0.850405 validation: 0.918274
09/16 10:49:53 AM: edges-ner-ontonotes_recall: training: 0.694836 validation: 0.761677
09/16 10:49:53 AM: edges-ner-ontonotes_f1: training: 0.764790 validation: 0.832677
09/16 10:49:53 AM: Global learning rate: 1.5625e-06
09/16 10:49:53 AM: Saving checkpoints to: ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:49:53 AM: Stopped training after 59 validation checks
09/16 10:49:53 AM: Trained edges-ner-ontonotes for 59000 batches or 37.967 epochs
09/16 10:49:53 AM: ***** VALIDATION RESULTS *****
09/16 10:49:53 AM: edges-ner-ontonotes_f1 (for best val pass 49): edges-ner-ontonotes_loss: 0.05037, macro_avg: 0.83311, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.82789, edges-ner-ontonotes_acc: 0.74173, edges-ner-ontonotes_precision: 0.91483, edges-ner-ontonotes_recall: 0.76479, edges-ner-ontonotes_f1: 0.83311
09/16 10:49:53 AM: micro_avg (for best val pass 1): edges-ner-ontonotes_loss: 0.10745, macro_avg: 0.57073, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.58499, edges-ner-ontonotes_acc: 0.42122, edges-ner-ontonotes_precision: 0.82788, edges-ner-ontonotes_recall: 0.43547, edges-ner-ontonotes_f1: 0.57073
09/16 10:49:53 AM: macro_avg (for best val pass 49): edges-ner-ontonotes_loss: 0.05037, macro_avg: 0.83311, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.82789, edges-ner-ontonotes_acc: 0.74173, edges-ner-ontonotes_precision: 0.91483, edges-ner-ontonotes_recall: 0.76479, edges-ner-ontonotes_f1: 0.83311
09/16 10:49:53 AM: Evaluating...
09/16 10:49:53 AM: Loaded model state from ./experiments/ner-ontonotes-hotpot-top/run/edges-ner-ontonotes/model_state_target_train_val_49.best.th
09/16 10:49:53 AM: Evaluating on: edges-ner-ontonotes, split: val
09/16 10:50:22 AM: Task 'edges-ner-ontonotes': sorting predictions by 'idx'
09/16 10:50:22 AM: Finished evaluating on: edges-ner-ontonotes
09/16 10:50:22 AM: Task 'edges-ner-ontonotes': joining predictions with input split 'val'
09/16 10:50:22 AM: Task 'edges-ner-ontonotes': Wrote predictions to ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:50:22 AM: Wrote all preds for split 'val' to ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:50:22 AM: Evaluating on: edges-ner-ontonotes, split: test
09/16 10:50:41 AM: Task 'edges-ner-ontonotes': sorting predictions by 'idx'
09/16 10:50:41 AM: Finished evaluating on: edges-ner-ontonotes
09/16 10:50:41 AM: Task 'edges-ner-ontonotes': joining predictions with input split 'test'
09/16 10:50:41 AM: Task 'edges-ner-ontonotes': Wrote predictions to ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:50:41 AM: Wrote all preds for split 'test' to ./experiments/ner-ontonotes-hotpot-top/run
09/16 10:50:41 AM: Writing results for split 'val' to ./experiments/ner-ontonotes-hotpot-top/results.tsv
09/16 10:50:41 AM: micro_avg: 0.000, macro_avg: 0.827, edges-ner-ontonotes_mcc: 0.821, edges-ner-ontonotes_acc: 0.733, edges-ner-ontonotes_precision: 0.912, edges-ner-ontonotes_recall: 0.756, edges-ner-ontonotes_f1: 0.827
09/16 10:50:41 AM: Done!
