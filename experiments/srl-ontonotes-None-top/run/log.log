09/07 09:16:38 PM: Git branch: master
09/07 09:16:38 PM: Git SHA: 117419dc9116809c203f878fb83f7aaddafbbcb0
09/07 09:16:39 PM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "/scratch0/new/jiant/experiments/srl-ontonotes-None-top/",
  "exp_name": "experiments/srl-ontonotes-None-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "/scratch0/new/jiant/experiments/srl-ontonotes-None-top/run/log.log",
  "lr_patience": 5,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 20,
  "pretrain_tasks": "",
  "pretrained_dir": "None",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/srl-ontonotes-None-top__run",
  "run_dir": "/scratch0/new/jiant/experiments/srl-ontonotes-None-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-srl-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/07 09:16:39 PM: Saved config to /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run/params.conf
09/07 09:16:39 PM: Using random seed 1234
09/07 09:16:40 PM: Using GPU 0
09/07 09:16:40 PM: Loading tasks...
09/07 09:16:40 PM: Writing pre-preprocessed tasks to /scratch0/new/jiant/experiments/srl-ontonotes-None-top/
09/07 09:16:40 PM: 	Creating task edges-srl-ontonotes from scratch.
09/07 09:16:45 PM: Read=231480, Skip=21590, Total=253070 from /scratch0/new/jiant/probing_data/edges/ontonotes/srl/train.json.retokenized.bert-base-uncased
09/07 09:16:45 PM: Read=32486, Skip=2811, Total=35297 from /scratch0/new/jiant/probing_data/edges/ontonotes/srl/development.json.retokenized.bert-base-uncased
09/07 09:16:46 PM: Read=23800, Skip=2915, Total=26715 from /scratch0/new/jiant/probing_data/edges/ontonotes/srl/test.json.retokenized.bert-base-uncased
09/07 09:16:48 PM: 	Task 'edges-srl-ontonotes': |train|=231480 |val|=32486 |test|=23800
09/07 09:16:48 PM: 	Finished loading tasks: edges-srl-ontonotes.
09/07 09:16:48 PM: 	Building vocab from scratch.
09/07 09:16:48 PM: 	Counting units for task edges-srl-ontonotes.
09/07 09:16:56 PM: 	Task 'edges-srl-ontonotes': adding vocab namespace 'edges-srl-ontonotes_labels'
09/07 09:16:56 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /cliphomes/ewallac2/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:16:56 PM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/07 09:16:57 PM: 	Saved vocab to /scratch0/new/jiant/experiments/srl-ontonotes-None-top/vocab
09/07 09:16:57 PM: Loading token dictionary from /scratch0/new/jiant/experiments/srl-ontonotes-None-top/vocab.
09/07 09:16:57 PM: 	Loaded vocab from /scratch0/new/jiant/experiments/srl-ontonotes-None-top/vocab
09/07 09:16:57 PM: 	Vocab namespace tokens: size 23662
09/07 09:16:57 PM: 	Vocab namespace chars: size 76
09/07 09:16:57 PM: 	Vocab namespace edges-srl-ontonotes_labels: size 66
09/07 09:16:57 PM: 	Vocab namespace bert_uncased: size 30524
09/07 09:16:57 PM: 	Finished building vocab.
09/07 09:16:57 PM: 	Task edges-srl-ontonotes (train): Indexing from scratch.
09/07 09:17:43 PM: 	Task edges-srl-ontonotes (train): Saved 231480 instances to /scratch0/new/jiant/experiments/srl-ontonotes-None-top/preproc/edges-srl-ontonotes__train_data
09/07 09:17:43 PM: 	Task edges-srl-ontonotes (val): Indexing from scratch.
09/07 09:17:49 PM: 	Task edges-srl-ontonotes (val): Saved 32486 instances to /scratch0/new/jiant/experiments/srl-ontonotes-None-top/preproc/edges-srl-ontonotes__val_data
09/07 09:17:49 PM: 	Task edges-srl-ontonotes (test): Indexing from scratch.
09/07 09:17:54 PM: 	Task edges-srl-ontonotes (test): Saved 23800 instances to /scratch0/new/jiant/experiments/srl-ontonotes-None-top/preproc/edges-srl-ontonotes__test_data
09/07 09:17:54 PM: 	Finished indexing tasks
09/07 09:17:54 PM: 	Creating trimmed target-only version of edges-srl-ontonotes train.
09/07 09:17:54 PM: 	  Training on 
09/07 09:17:54 PM: 	  Evaluating on edges-srl-ontonotes
09/07 09:17:54 PM: 	Finished loading tasks in 74.234s
09/07 09:17:54 PM: 	 Tasks: ['edges-srl-ontonotes']
09/07 09:17:54 PM: Building model...
09/07 09:17:54 PM: Using BERT model (bert-base-uncased).
09/07 09:17:54 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache, downloading to /tmp/tmpyek0c9wp
09/07 09:17:54 PM: copying /tmp/tmpyek0c9wp to cache at /scratch0/new/jiant/experiments/srl-ontonotes-None-top/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/07 09:17:54 PM: creating metadata file for /scratch0/new/jiant/experiments/srl-ontonotes-None-top/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/07 09:17:54 PM: removing temp file /tmp/tmpyek0c9wp
09/07 09:17:54 PM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /scratch0/new/jiant/experiments/srl-ontonotes-None-top/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/07 09:17:54 PM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/07 09:17:54 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache, downloading to /tmp/tmp9svjykvm
09/07 09:18:13 PM: copying /tmp/tmp9svjykvm to cache at /scratch0/new/jiant/experiments/srl-ontonotes-None-top/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/07 09:18:13 PM: creating metadata file for /scratch0/new/jiant/experiments/srl-ontonotes-None-top/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/07 09:18:13 PM: removing temp file /tmp/tmp9svjykvm
09/07 09:18:13 PM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /scratch0/new/jiant/experiments/srl-ontonotes-None-top/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/07 09:18:17 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to /tmp/tmpghjnbvo9
09/07 09:18:17 PM: copying /tmp/tmpghjnbvo9 to cache at /scratch0/new/jiant/experiments/srl-ontonotes-None-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:18:17 PM: creating metadata file for /scratch0/new/jiant/experiments/srl-ontonotes-None-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:18:17 PM: removing temp file /tmp/tmpghjnbvo9
09/07 09:18:17 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /scratch0/new/jiant/experiments/srl-ontonotes-None-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:18:17 PM: Initializing parameters
09/07 09:18:17 PM: Done initializing parameters; the following parameters are using their default initialization from their code
09/07 09:18:17 PM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/07 09:18:17 PM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/07 09:18:17 PM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/07 09:18:17 PM:    _text_field_embedder.model.pooler.dense.bias
09/07 09:18:17 PM:    _text_field_embedder.model.pooler.dense.weight
09/07 09:18:17 PM: 	Task 'edges-srl-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-srl-ontonotes"
}
09/07 09:18:22 PM: Model specification:
09/07 09:18:22 PM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): BertLayerNorm()
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-srl-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (proj2): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (span_extractor2): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Sequential(
        (0): Linear(in_features=1024, out_features=256, bias=True)
        (1): Tanh()
        (2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)
        (3): Dropout(p=0.3)
        (4): Linear(in_features=256, out_features=66, bias=True)
      )
    )
  )
)
09/07 09:18:22 PM: Model parameters:
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:22 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:22 PM: 	edges-srl-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/07 09:18:22 PM: 	edges-srl-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:22 PM: 	edges-srl-ontonotes_mdl.proj2.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/07 09:18:22 PM: 	edges-srl-ontonotes_mdl.proj2.bias: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:22 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.0.weight: Trainable parameter, count 262144 with torch.Size([256, 1024])
09/07 09:18:22 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.0.bias: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:22 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.2.weight: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:22 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.2.bias: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:22 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.4.weight: Trainable parameter, count 16896 with torch.Size([66, 256])
09/07 09:18:22 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.4.bias: Trainable parameter, count 66 with torch.Size([66])
09/07 09:18:22 PM: Total number of parameters: 110155842 (1.10156e+08)
09/07 09:18:22 PM: Number of trainable parameters: 673602 (673602)
09/07 09:18:22 PM: Finished building model in 27.673s
09/07 09:18:22 PM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-srl-ontonotes 

09/07 09:18:39 PM: patience = 20
09/07 09:18:39 PM: val_interval = 1000
09/07 09:18:39 PM: max_vals = 250
09/07 09:18:39 PM: cuda_device = 0
09/07 09:18:39 PM: grad_norm = 5.0
09/07 09:18:39 PM: grad_clipping = None
09/07 09:18:39 PM: lr_decay = 0.99
09/07 09:18:39 PM: min_lr = 1e-06
09/07 09:18:39 PM: keep_all_checkpoints = 0
09/07 09:18:39 PM: val_data_limit = 5000
09/07 09:18:39 PM: max_epochs = -1
09/07 09:18:39 PM: dec_val_scale = 250
09/07 09:18:39 PM: training_data_fraction = 1
09/07 09:18:39 PM: type = adam
09/07 09:18:39 PM: parameter_groups = None
09/07 09:18:39 PM: Number of trainable parameters: 673602
09/07 09:18:39 PM: infer_type_and_cast = True
09/07 09:18:39 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/07 09:18:39 PM: CURRENTLY DEFINED PARAMETERS: 
09/07 09:18:39 PM: lr = 0.0001
09/07 09:18:39 PM: amsgrad = True
09/07 09:18:39 PM: type = reduce_on_plateau
09/07 09:18:39 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/07 09:18:39 PM: CURRENTLY DEFINED PARAMETERS: 
09/07 09:18:39 PM: mode = max
09/07 09:18:39 PM: factor = 0.5
09/07 09:18:39 PM: patience = 5
09/07 09:18:39 PM: threshold = 0.0001
09/07 09:18:39 PM: threshold_mode = abs
09/07 09:18:39 PM: verbose = True
09/07 09:18:39 PM: type = adam
09/07 09:18:39 PM: parameter_groups = None
09/07 09:18:39 PM: Number of trainable parameters: 673602
09/07 09:18:39 PM: infer_type_and_cast = True
09/07 09:18:39 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/07 09:18:39 PM: CURRENTLY DEFINED PARAMETERS: 
09/07 09:18:39 PM: lr = 0.0001
09/07 09:18:39 PM: amsgrad = True
09/07 09:18:39 PM: type = reduce_on_plateau
09/07 09:18:39 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/07 09:18:39 PM: CURRENTLY DEFINED PARAMETERS: 
09/07 09:18:39 PM: mode = max
09/07 09:18:39 PM: factor = 0.5
09/07 09:18:39 PM: patience = 5
09/07 09:18:39 PM: threshold = 0.0001
09/07 09:18:39 PM: threshold_mode = abs
09/07 09:18:39 PM: verbose = True
09/07 09:18:39 PM: Starting training without restoring from a checkpoint.
09/07 09:18:39 PM: Training examples per task, before any subsampling: {'edges-srl-ontonotes': 231480}
09/07 09:18:39 PM: Beginning training with stopping criteria based on metric: edges-srl-ontonotes_f1
09/07 09:18:49 PM: Update 111: task edges-srl-ontonotes, batch 111 (111): mcc: 0.0686, acc: 0.0498, precision: 0.0665, recall: 0.1139, f1: 0.0840, edges-srl-ontonotes_loss: 0.2097
09/07 09:18:59 PM: Update 233: task edges-srl-ontonotes, batch 233 (233): mcc: 0.0590, acc: 0.0354, precision: 0.0793, recall: 0.0653, f1: 0.0716, edges-srl-ontonotes_loss: 0.1384
09/07 09:19:09 PM: Update 341: task edges-srl-ontonotes, batch 341 (341): mcc: 0.0898, acc: 0.0580, precision: 0.1288, recall: 0.0785, f1: 0.0975, edges-srl-ontonotes_loss: 0.1116
09/07 09:19:19 PM: Update 461: task edges-srl-ontonotes, batch 461 (461): mcc: 0.1670, acc: 0.1137, precision: 0.2387, recall: 0.1302, f1: 0.1685, edges-srl-ontonotes_loss: 0.0940
09/07 09:19:29 PM: Update 584: task edges-srl-ontonotes, batch 584 (584): mcc: 0.2493, acc: 0.1724, precision: 0.3510, recall: 0.1889, f1: 0.2457, edges-srl-ontonotes_loss: 0.0820
09/07 09:19:39 PM: Update 667: task edges-srl-ontonotes, batch 667 (667): mcc: 0.2950, acc: 0.2056, precision: 0.4110, recall: 0.2230, f1: 0.2891, edges-srl-ontonotes_loss: 0.0761
09/07 09:19:49 PM: Update 790: task edges-srl-ontonotes, batch 790 (790): mcc: 0.3482, acc: 0.2459, precision: 0.4776, recall: 0.2644, f1: 0.3404, edges-srl-ontonotes_loss: 0.0692
09/07 09:19:59 PM: Update 910: task edges-srl-ontonotes, batch 910 (910): mcc: 0.3916, acc: 0.2808, precision: 0.5283, recall: 0.3003, f1: 0.3830, edges-srl-ontonotes_loss: 0.0640
09/07 09:20:07 PM: ***** Step 1000 / Validation 1 *****
09/07 09:20:07 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:20:07 PM: Validating...
09/07 09:20:09 PM: Evaluate: task edges-srl-ontonotes, batch 18 (157): mcc: 0.6971, acc: 0.5581, precision: 0.8500, recall: 0.5775, f1: 0.6878, edges-srl-ontonotes_loss: 0.0264
09/07 09:20:19 PM: Evaluate: task edges-srl-ontonotes, batch 130 (157): mcc: 0.7159, acc: 0.5807, precision: 0.8709, recall: 0.5941, f1: 0.7064, edges-srl-ontonotes_loss: 0.0251
09/07 09:20:21 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:20:21 PM: Best result seen so far for micro.
09/07 09:20:21 PM: Best result seen so far for macro.
09/07 09:20:21 PM: Updating LR scheduler:
09/07 09:20:21 PM: 	Best result seen so far for macro_avg: 0.703
09/07 09:20:21 PM: 	# validation passes without improvement: 0
09/07 09:20:21 PM: edges-srl-ontonotes_loss: training: 0.060873 validation: 0.025393
09/07 09:20:21 PM: macro_avg: validation: 0.702866
09/07 09:20:21 PM: micro_avg: validation: 0.000000
09/07 09:20:21 PM: edges-srl-ontonotes_mcc: training: 0.416269 validation: 0.712412
09/07 09:20:21 PM: edges-srl-ontonotes_acc: training: 0.301403 validation: 0.576784
09/07 09:20:21 PM: edges-srl-ontonotes_precision: training: 0.556030 validation: 0.867247
09/07 09:20:21 PM: edges-srl-ontonotes_recall: training: 0.321511 validation: 0.590871
09/07 09:20:21 PM: edges-srl-ontonotes_f1: training: 0.407433 validation: 0.702866
09/07 09:20:21 PM: Global learning rate: 0.0001
09/07 09:20:21 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 09:20:29 PM: Update 1090: task edges-srl-ontonotes, batch 90 (1090): mcc: 0.6615, acc: 0.5211, precision: 0.8006, recall: 0.5534, f1: 0.6545, edges-srl-ontonotes_loss: 0.0284
09/07 09:20:39 PM: Update 1207: task edges-srl-ontonotes, batch 207 (1207): mcc: 0.6699, acc: 0.5334, precision: 0.8025, recall: 0.5660, f1: 0.6638, edges-srl-ontonotes_loss: 0.0276
09/07 09:20:49 PM: Update 1309: task edges-srl-ontonotes, batch 309 (1309): mcc: 0.6737, acc: 0.5386, precision: 0.8016, recall: 0.5731, f1: 0.6684, edges-srl-ontonotes_loss: 0.0270
09/07 09:20:59 PM: Update 1425: task edges-srl-ontonotes, batch 425 (1425): mcc: 0.6806, acc: 0.5482, precision: 0.8042, recall: 0.5828, f1: 0.6758, edges-srl-ontonotes_loss: 0.0265
09/07 09:21:09 PM: Update 1538: task edges-srl-ontonotes, batch 538 (1538): mcc: 0.6876, acc: 0.5575, precision: 0.8073, recall: 0.5924, f1: 0.6834, edges-srl-ontonotes_loss: 0.0259
09/07 09:21:19 PM: Update 1638: task edges-srl-ontonotes, batch 638 (1638): mcc: 0.6871, acc: 0.5563, precision: 0.8054, recall: 0.5929, f1: 0.6830, edges-srl-ontonotes_loss: 0.0258
09/07 09:21:29 PM: Update 1750: task edges-srl-ontonotes, batch 750 (1750): mcc: 0.6880, acc: 0.5572, precision: 0.8050, recall: 0.5948, f1: 0.6841, edges-srl-ontonotes_loss: 0.0256
09/07 09:21:39 PM: Update 1859: task edges-srl-ontonotes, batch 859 (1859): mcc: 0.6887, acc: 0.5585, precision: 0.8043, recall: 0.5965, f1: 0.6850, edges-srl-ontonotes_loss: 0.0255
09/07 09:21:49 PM: Update 1936: task edges-srl-ontonotes, batch 936 (1936): mcc: 0.6895, acc: 0.5597, precision: 0.8039, recall: 0.5982, f1: 0.6860, edges-srl-ontonotes_loss: 0.0254
09/07 09:21:55 PM: ***** Step 2000 / Validation 2 *****
09/07 09:21:55 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:21:55 PM: Validating...
09/07 09:21:59 PM: Evaluate: task edges-srl-ontonotes, batch 46 (157): mcc: 0.7424, acc: 0.6285, precision: 0.8480, recall: 0.6558, f1: 0.7396, edges-srl-ontonotes_loss: 0.0212
09/07 09:22:09 PM: Evaluate: task edges-srl-ontonotes, batch 155 (157): mcc: 0.7597, acc: 0.6486, precision: 0.8668, recall: 0.6714, f1: 0.7567, edges-srl-ontonotes_loss: 0.0198
09/07 09:22:09 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:22:09 PM: Best result seen so far for macro.
09/07 09:22:09 PM: Updating LR scheduler:
09/07 09:22:09 PM: 	Best result seen so far for macro_avg: 0.756
09/07 09:22:09 PM: 	# validation passes without improvement: 0
09/07 09:22:09 PM: edges-srl-ontonotes_loss: training: 0.025262 validation: 0.019813
09/07 09:22:09 PM: macro_avg: validation: 0.756487
09/07 09:22:09 PM: micro_avg: validation: 0.000000
09/07 09:22:09 PM: edges-srl-ontonotes_mcc: training: 0.691132 validation: 0.759581
09/07 09:22:09 PM: edges-srl-ontonotes_acc: training: 0.561534 validation: 0.648449
09/07 09:22:09 PM: edges-srl-ontonotes_precision: training: 0.804224 validation: 0.866932
09/07 09:22:09 PM: edges-srl-ontonotes_recall: training: 0.600746 validation: 0.671003
09/07 09:22:09 PM: edges-srl-ontonotes_f1: training: 0.687751 validation: 0.756487
09/07 09:22:09 PM: Global learning rate: 0.0001
09/07 09:22:10 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 09:22:19 PM: Update 2112: task edges-srl-ontonotes, batch 112 (2112): mcc: 0.7000, acc: 0.5724, precision: 0.8023, recall: 0.6175, f1: 0.6979, edges-srl-ontonotes_loss: 0.0239
09/07 09:22:30 PM: Update 2209: task edges-srl-ontonotes, batch 209 (2209): mcc: 0.7045, acc: 0.5803, precision: 0.8035, recall: 0.6246, f1: 0.7028, edges-srl-ontonotes_loss: 0.0236
09/07 09:22:40 PM: Update 2315: task edges-srl-ontonotes, batch 315 (2315): mcc: 0.7134, acc: 0.5912, precision: 0.8084, recall: 0.6363, f1: 0.7121, edges-srl-ontonotes_loss: 0.0231
09/07 09:22:50 PM: Update 2421: task edges-srl-ontonotes, batch 421 (2421): mcc: 0.7196, acc: 0.6001, precision: 0.8107, recall: 0.6454, f1: 0.7187, edges-srl-ontonotes_loss: 0.0226
09/07 09:23:00 PM: Update 2520: task edges-srl-ontonotes, batch 520 (2520): mcc: 0.7239, acc: 0.6059, precision: 0.8130, recall: 0.6512, f1: 0.7231, edges-srl-ontonotes_loss: 0.0223
09/07 09:23:10 PM: Update 2631: task edges-srl-ontonotes, batch 631 (2631): mcc: 0.7267, acc: 0.6100, precision: 0.8135, recall: 0.6557, f1: 0.7262, edges-srl-ontonotes_loss: 0.0221
09/07 09:23:20 PM: Update 2741: task edges-srl-ontonotes, batch 741 (2741): mcc: 0.7288, acc: 0.6133, precision: 0.8143, recall: 0.6588, f1: 0.7284, edges-srl-ontonotes_loss: 0.0219
09/07 09:23:30 PM: Update 2819: task edges-srl-ontonotes, batch 819 (2819): mcc: 0.7308, acc: 0.6163, precision: 0.8156, recall: 0.6614, f1: 0.7304, edges-srl-ontonotes_loss: 0.0217
09/07 09:23:40 PM: Update 2930: task edges-srl-ontonotes, batch 930 (2930): mcc: 0.7327, acc: 0.6189, precision: 0.8164, recall: 0.6641, f1: 0.7324, edges-srl-ontonotes_loss: 0.0216
09/07 09:23:46 PM: ***** Step 3000 / Validation 3 *****
09/07 09:23:46 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:23:46 PM: Validating...
09/07 09:23:50 PM: Evaluate: task edges-srl-ontonotes, batch 40 (157): mcc: 0.7585, acc: 0.6558, precision: 0.8435, recall: 0.6878, f1: 0.7578, edges-srl-ontonotes_loss: 0.0194
09/07 09:24:00 PM: Evaluate: task edges-srl-ontonotes, batch 150 (157): mcc: 0.7701, acc: 0.6712, precision: 0.8533, recall: 0.7006, f1: 0.7695, edges-srl-ontonotes_loss: 0.0185
09/07 09:24:01 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:24:01 PM: Best result seen so far for macro.
09/07 09:24:01 PM: Updating LR scheduler:
09/07 09:24:01 PM: 	Best result seen so far for macro_avg: 0.769
09/07 09:24:01 PM: 	# validation passes without improvement: 0
09/07 09:24:01 PM: edges-srl-ontonotes_loss: training: 0.021459 validation: 0.018615
09/07 09:24:01 PM: macro_avg: validation: 0.768815
09/07 09:24:01 PM: micro_avg: validation: 0.000000
09/07 09:24:01 PM: edges-srl-ontonotes_mcc: training: 0.734269 validation: 0.769460
09/07 09:24:01 PM: edges-srl-ontonotes_acc: training: 0.620879 validation: 0.670387
09/07 09:24:01 PM: edges-srl-ontonotes_precision: training: 0.817211 validation: 0.852828
09/07 09:24:01 PM: edges-srl-ontonotes_recall: training: 0.666198 validation: 0.699869
09/07 09:24:01 PM: edges-srl-ontonotes_f1: training: 0.734018 validation: 0.768815
09/07 09:24:01 PM: Global learning rate: 0.0001
09/07 09:24:01 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 09:24:10 PM: Update 3105: task edges-srl-ontonotes, batch 105 (3105): mcc: 0.7622, acc: 0.6607, precision: 0.8310, recall: 0.7052, f1: 0.7630, edges-srl-ontonotes_loss: 0.0194
09/07 09:24:20 PM: Update 3201: task edges-srl-ontonotes, batch 201 (3201): mcc: 0.7523, acc: 0.6483, precision: 0.8237, recall: 0.6933, f1: 0.7529, edges-srl-ontonotes_loss: 0.0201
09/07 09:24:30 PM: Update 3317: task edges-srl-ontonotes, batch 317 (3317): mcc: 0.7506, acc: 0.6460, precision: 0.8223, recall: 0.6914, f1: 0.7512, edges-srl-ontonotes_loss: 0.0202
09/07 09:24:40 PM: Update 3426: task edges-srl-ontonotes, batch 426 (3426): mcc: 0.7493, acc: 0.6441, precision: 0.8220, recall: 0.6892, f1: 0.7498, edges-srl-ontonotes_loss: 0.0202
09/07 09:24:50 PM: Update 3529: task edges-srl-ontonotes, batch 529 (3529): mcc: 0.7485, acc: 0.6430, precision: 0.8218, recall: 0.6880, f1: 0.7489, edges-srl-ontonotes_loss: 0.0202
09/07 09:25:00 PM: Update 3639: task edges-srl-ontonotes, batch 639 (3639): mcc: 0.7465, acc: 0.6403, precision: 0.8208, recall: 0.6852, f1: 0.7469, edges-srl-ontonotes_loss: 0.0203
09/07 09:25:10 PM: Update 3752: task edges-srl-ontonotes, batch 752 (3752): mcc: 0.7475, acc: 0.6413, precision: 0.8216, recall: 0.6864, f1: 0.7480, edges-srl-ontonotes_loss: 0.0202
09/07 09:25:20 PM: Update 3853: task edges-srl-ontonotes, batch 853 (3853): mcc: 0.7466, acc: 0.6401, precision: 0.8205, recall: 0.6857, f1: 0.7471, edges-srl-ontonotes_loss: 0.0202
09/07 09:25:30 PM: Update 3966: task edges-srl-ontonotes, batch 966 (3966): mcc: 0.7463, acc: 0.6397, precision: 0.8198, recall: 0.6858, f1: 0.7468, edges-srl-ontonotes_loss: 0.0202
09/07 09:25:34 PM: ***** Step 4000 / Validation 4 *****
09/07 09:25:34 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:25:34 PM: Validating...
09/07 09:25:40 PM: Evaluate: task edges-srl-ontonotes, batch 75 (157): mcc: 0.7645, acc: 0.6643, precision: 0.8572, recall: 0.6875, f1: 0.7630, edges-srl-ontonotes_loss: 0.0189
09/07 09:25:50 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:25:50 PM: Best result seen so far for macro.
09/07 09:25:50 PM: Updating LR scheduler:
09/07 09:25:50 PM: 	Best result seen so far for macro_avg: 0.774
09/07 09:25:50 PM: 	# validation passes without improvement: 0
09/07 09:25:50 PM: edges-srl-ontonotes_loss: training: 0.020167 validation: 0.018135
09/07 09:25:50 PM: macro_avg: validation: 0.773842
09/07 09:25:50 PM: micro_avg: validation: 0.000000
09/07 09:25:50 PM: edges-srl-ontonotes_mcc: training: 0.746224 validation: 0.775113
09/07 09:25:50 PM: edges-srl-ontonotes_acc: training: 0.639766 validation: 0.676545
09/07 09:25:50 PM: edges-srl-ontonotes_precision: training: 0.819906 validation: 0.864362
09/07 09:25:50 PM: edges-srl-ontonotes_recall: training: 0.685501 validation: 0.700485
09/07 09:25:50 PM: edges-srl-ontonotes_f1: training: 0.746704 validation: 0.773842
09/07 09:25:50 PM: Global learning rate: 0.0001
09/07 09:25:50 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 09:25:50 PM: Update 4009: task edges-srl-ontonotes, batch 9 (4009): mcc: 0.7356, acc: 0.6236, precision: 0.8264, recall: 0.6611, f1: 0.7346, edges-srl-ontonotes_loss: 0.0210
09/07 09:26:00 PM: Update 4108: task edges-srl-ontonotes, batch 108 (4108): mcc: 0.7450, acc: 0.6376, precision: 0.8167, recall: 0.6860, f1: 0.7457, edges-srl-ontonotes_loss: 0.0204
09/07 09:26:10 PM: Update 4218: task edges-srl-ontonotes, batch 218 (4218): mcc: 0.7527, acc: 0.6490, precision: 0.8212, recall: 0.6961, f1: 0.7535, edges-srl-ontonotes_loss: 0.0199
09/07 09:26:21 PM: Update 4329: task edges-srl-ontonotes, batch 329 (4329): mcc: 0.7559, acc: 0.6531, precision: 0.8246, recall: 0.6992, f1: 0.7567, edges-srl-ontonotes_loss: 0.0196
09/07 09:26:31 PM: Update 4432: task edges-srl-ontonotes, batch 432 (4432): mcc: 0.7553, acc: 0.6535, precision: 0.8239, recall: 0.6987, f1: 0.7562, edges-srl-ontonotes_loss: 0.0195
09/07 09:26:41 PM: Update 4543: task edges-srl-ontonotes, batch 543 (4543): mcc: 0.7581, acc: 0.6576, precision: 0.8259, recall: 0.7020, f1: 0.7589, edges-srl-ontonotes_loss: 0.0193
09/07 09:26:51 PM: Update 4654: task edges-srl-ontonotes, batch 654 (4654): mcc: 0.7591, acc: 0.6590, precision: 0.8264, recall: 0.7035, f1: 0.7600, edges-srl-ontonotes_loss: 0.0192
09/07 09:27:01 PM: Update 4743: task edges-srl-ontonotes, batch 743 (4743): mcc: 0.7573, acc: 0.6576, precision: 0.8252, recall: 0.7011, f1: 0.7581, edges-srl-ontonotes_loss: 0.0194
09/07 09:27:11 PM: Update 4843: task edges-srl-ontonotes, batch 843 (4843): mcc: 0.7551, acc: 0.6551, precision: 0.8239, recall: 0.6984, f1: 0.7559, edges-srl-ontonotes_loss: 0.0195
09/07 09:27:21 PM: Update 4940: task edges-srl-ontonotes, batch 940 (4940): mcc: 0.7537, acc: 0.6530, precision: 0.8232, recall: 0.6964, f1: 0.7545, edges-srl-ontonotes_loss: 0.0196
09/07 09:27:27 PM: ***** Step 5000 / Validation 5 *****
09/07 09:27:27 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:27:27 PM: Validating...
09/07 09:27:31 PM: Evaluate: task edges-srl-ontonotes, batch 47 (157): mcc: 0.7632, acc: 0.6699, precision: 0.8355, recall: 0.7031, f1: 0.7636, edges-srl-ontonotes_loss: 0.0191
09/07 09:27:41 PM: Evaluate: task edges-srl-ontonotes, batch 156 (157): mcc: 0.7722, acc: 0.6784, precision: 0.8482, recall: 0.7087, f1: 0.7722, edges-srl-ontonotes_loss: 0.0182
09/07 09:27:41 PM: Updating LR scheduler:
09/07 09:27:41 PM: 	Best result seen so far for macro_avg: 0.774
09/07 09:27:41 PM: 	# validation passes without improvement: 1
09/07 09:27:41 PM: edges-srl-ontonotes_loss: training: 0.019579 validation: 0.018203
09/07 09:27:41 PM: macro_avg: validation: 0.772153
09/07 09:27:41 PM: micro_avg: validation: 0.000000
09/07 09:27:41 PM: edges-srl-ontonotes_mcc: training: 0.753712 validation: 0.772162
09/07 09:27:41 PM: edges-srl-ontonotes_acc: training: 0.652926 validation: 0.678239
09/07 09:27:41 PM: edges-srl-ontonotes_precision: training: 0.823494 validation: 0.848167
09/07 09:27:41 PM: edges-srl-ontonotes_recall: training: 0.696069 validation: 0.708644
09/07 09:27:41 PM: edges-srl-ontonotes_f1: training: 0.754439 validation: 0.772153
09/07 09:27:41 PM: Global learning rate: 0.0001
09/07 09:27:41 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 09:27:51 PM: Update 5082: task edges-srl-ontonotes, batch 82 (5082): mcc: 0.7505, acc: 0.6482, precision: 0.8231, recall: 0.6907, f1: 0.7511, edges-srl-ontonotes_loss: 0.0196
09/07 09:28:01 PM: Update 5207: task edges-srl-ontonotes, batch 207 (5207): mcc: 0.7640, acc: 0.6629, precision: 0.8312, recall: 0.7082, f1: 0.7648, edges-srl-ontonotes_loss: 0.0188
09/07 09:28:12 PM: Update 5322: task edges-srl-ontonotes, batch 322 (5322): mcc: 0.7701, acc: 0.6711, precision: 0.8350, recall: 0.7161, f1: 0.7710, edges-srl-ontonotes_loss: 0.0184
09/07 09:28:22 PM: Update 5454: task edges-srl-ontonotes, batch 454 (5454): mcc: 0.7797, acc: 0.6830, precision: 0.8424, recall: 0.7274, f1: 0.7807, edges-srl-ontonotes_loss: 0.0177
09/07 09:28:32 PM: Update 5592: task edges-srl-ontonotes, batch 592 (5592): mcc: 0.7881, acc: 0.6935, precision: 0.8478, recall: 0.7382, f1: 0.7892, edges-srl-ontonotes_loss: 0.0171
09/07 09:28:42 PM: Update 5709: task edges-srl-ontonotes, batch 709 (5709): mcc: 0.7918, acc: 0.6982, precision: 0.8507, recall: 0.7424, f1: 0.7929, edges-srl-ontonotes_loss: 0.0169
09/07 09:28:52 PM: Update 5842: task edges-srl-ontonotes, batch 842 (5842): mcc: 0.7962, acc: 0.7037, precision: 0.8535, recall: 0.7481, f1: 0.7973, edges-srl-ontonotes_loss: 0.0166
09/07 09:29:03 PM: Update 5948: task edges-srl-ontonotes, batch 948 (5948): mcc: 0.7989, acc: 0.7073, precision: 0.8555, recall: 0.7514, f1: 0.8001, edges-srl-ontonotes_loss: 0.0165
09/07 09:29:07 PM: ***** Step 6000 / Validation 6 *****
09/07 09:29:07 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:29:07 PM: Validating...
09/07 09:29:13 PM: Evaluate: task edges-srl-ontonotes, batch 67 (157): mcc: 0.8004, acc: 0.7154, precision: 0.8787, recall: 0.7340, f1: 0.7999, edges-srl-ontonotes_loss: 0.0168
09/07 09:29:21 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:29:21 PM: Best result seen so far for macro.
09/07 09:29:21 PM: Updating LR scheduler:
09/07 09:29:21 PM: 	Best result seen so far for macro_avg: 0.808
09/07 09:29:21 PM: 	# validation passes without improvement: 0
09/07 09:29:21 PM: edges-srl-ontonotes_loss: training: 0.016432 validation: 0.016013
09/07 09:29:21 PM: macro_avg: validation: 0.807988
09/07 09:29:21 PM: micro_avg: validation: 0.000000
09/07 09:29:21 PM: edges-srl-ontonotes_mcc: training: 0.799783 validation: 0.807845
09/07 09:29:21 PM: edges-srl-ontonotes_acc: training: 0.708379 validation: 0.728273
09/07 09:29:21 PM: edges-srl-ontonotes_precision: training: 0.855846 validation: 0.876983
09/07 09:29:21 PM: edges-srl-ontonotes_recall: training: 0.752673 validation: 0.749057
09/07 09:29:21 PM: edges-srl-ontonotes_f1: training: 0.800951 validation: 0.807988
09/07 09:29:21 PM: Global learning rate: 0.0001
09/07 09:29:21 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 09:29:23 PM: Update 6024: task edges-srl-ontonotes, batch 24 (6024): mcc: 0.8281, acc: 0.7381, precision: 0.8725, recall: 0.7907, f1: 0.8296, edges-srl-ontonotes_loss: 0.0148
09/07 09:29:33 PM: Update 6158: task edges-srl-ontonotes, batch 158 (6158): mcc: 0.8168, acc: 0.7314, precision: 0.8647, recall: 0.7765, f1: 0.8182, edges-srl-ontonotes_loss: 0.0153
09/07 09:29:43 PM: Update 6277: task edges-srl-ontonotes, batch 277 (6277): mcc: 0.8211, acc: 0.7380, precision: 0.8688, recall: 0.7808, f1: 0.8224, edges-srl-ontonotes_loss: 0.0150
09/07 09:29:53 PM: Update 6411: task edges-srl-ontonotes, batch 411 (6411): mcc: 0.8234, acc: 0.7418, precision: 0.8716, recall: 0.7827, f1: 0.8248, edges-srl-ontonotes_loss: 0.0148
09/07 09:30:03 PM: Update 6549: task edges-srl-ontonotes, batch 549 (6549): mcc: 0.8279, acc: 0.7483, precision: 0.8748, recall: 0.7881, f1: 0.8292, edges-srl-ontonotes_loss: 0.0144
09/07 09:30:13 PM: Update 6650: task edges-srl-ontonotes, batch 650 (6650): mcc: 0.8216, acc: 0.7403, precision: 0.8705, recall: 0.7802, f1: 0.8229, edges-srl-ontonotes_loss: 0.0149
09/07 09:30:23 PM: Update 6768: task edges-srl-ontonotes, batch 768 (6768): mcc: 0.8172, acc: 0.7356, precision: 0.8667, recall: 0.7754, f1: 0.8185, edges-srl-ontonotes_loss: 0.0152
09/07 09:30:33 PM: Update 6879: task edges-srl-ontonotes, batch 879 (6879): mcc: 0.8141, acc: 0.7320, precision: 0.8643, recall: 0.7718, f1: 0.8154, edges-srl-ontonotes_loss: 0.0154
09/07 09:30:43 PM: Update 6975: task edges-srl-ontonotes, batch 975 (6975): mcc: 0.8092, acc: 0.7260, precision: 0.8605, recall: 0.7660, f1: 0.8105, edges-srl-ontonotes_loss: 0.0158
09/07 09:30:46 PM: ***** Step 7000 / Validation 7 *****
09/07 09:30:46 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:30:46 PM: Validating...
09/07 09:30:53 PM: Evaluate: task edges-srl-ontonotes, batch 86 (157): mcc: 0.8112, acc: 0.7418, precision: 0.8709, recall: 0.7606, f1: 0.8120, edges-srl-ontonotes_loss: 0.0157
09/07 09:31:02 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:31:02 PM: Best result seen so far for macro.
09/07 09:31:02 PM: Updating LR scheduler:
09/07 09:31:02 PM: 	Best result seen so far for macro_avg: 0.821
09/07 09:31:02 PM: 	# validation passes without improvement: 0
09/07 09:31:02 PM: edges-srl-ontonotes_loss: training: 0.015849 validation: 0.015221
09/07 09:31:02 PM: macro_avg: validation: 0.820928
09/07 09:31:02 PM: micro_avg: validation: 0.000000
09/07 09:31:02 PM: edges-srl-ontonotes_mcc: training: 0.808155 validation: 0.819970
09/07 09:31:02 PM: edges-srl-ontonotes_acc: training: 0.724762 validation: 0.752598
09/07 09:31:02 PM: edges-srl-ontonotes_precision: training: 0.859752 validation: 0.875196
09/07 09:31:02 PM: edges-srl-ontonotes_recall: training: 0.764780 validation: 0.772997
09/07 09:31:02 PM: edges-srl-ontonotes_f1: training: 0.809490 validation: 0.820928
09/07 09:31:02 PM: Global learning rate: 0.0001
09/07 09:31:02 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 09:31:03 PM: Update 7019: task edges-srl-ontonotes, batch 19 (7019): mcc: 0.7661, acc: 0.6729, precision: 0.8209, recall: 0.7212, f1: 0.7678, edges-srl-ontonotes_loss: 0.0186
09/07 09:31:13 PM: Update 7135: task edges-srl-ontonotes, batch 135 (7135): mcc: 0.7753, acc: 0.6891, precision: 0.8310, recall: 0.7292, f1: 0.7768, edges-srl-ontonotes_loss: 0.0180
09/07 09:31:23 PM: Update 7243: task edges-srl-ontonotes, batch 243 (7243): mcc: 0.7759, acc: 0.6881, precision: 0.8335, recall: 0.7281, f1: 0.7773, edges-srl-ontonotes_loss: 0.0180
09/07 09:31:34 PM: Update 7354: task edges-srl-ontonotes, batch 354 (7354): mcc: 0.7811, acc: 0.6938, precision: 0.8381, recall: 0.7338, f1: 0.7825, edges-srl-ontonotes_loss: 0.0177
09/07 09:31:44 PM: Update 7475: task edges-srl-ontonotes, batch 475 (7475): mcc: 0.7872, acc: 0.7005, precision: 0.8436, recall: 0.7402, f1: 0.7885, edges-srl-ontonotes_loss: 0.0173
09/07 09:31:54 PM: Update 7582: task edges-srl-ontonotes, batch 582 (7582): mcc: 0.7913, acc: 0.7054, precision: 0.8466, recall: 0.7452, f1: 0.7926, edges-srl-ontonotes_loss: 0.0170
09/07 09:32:04 PM: Update 7704: task edges-srl-ontonotes, batch 704 (7704): mcc: 0.7944, acc: 0.7090, precision: 0.8491, recall: 0.7486, f1: 0.7957, edges-srl-ontonotes_loss: 0.0168
09/07 09:32:14 PM: Update 7825: task edges-srl-ontonotes, batch 825 (7825): mcc: 0.7974, acc: 0.7128, precision: 0.8516, recall: 0.7520, f1: 0.7987, edges-srl-ontonotes_loss: 0.0166
09/07 09:32:24 PM: Update 7932: task edges-srl-ontonotes, batch 932 (7932): mcc: 0.7974, acc: 0.7130, precision: 0.8516, recall: 0.7521, f1: 0.7988, edges-srl-ontonotes_loss: 0.0166
09/07 09:32:30 PM: ***** Step 8000 / Validation 8 *****
09/07 09:32:30 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:32:30 PM: Validating...
09/07 09:32:34 PM: Evaluate: task edges-srl-ontonotes, batch 47 (157): mcc: 0.8177, acc: 0.7537, precision: 0.8705, recall: 0.7729, f1: 0.8188, edges-srl-ontonotes_loss: 0.0153
09/07 09:32:44 PM: Evaluate: task edges-srl-ontonotes, batch 156 (157): mcc: 0.8333, acc: 0.7704, precision: 0.8834, recall: 0.7906, f1: 0.8344, edges-srl-ontonotes_loss: 0.0141
09/07 09:32:44 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:32:44 PM: Best result seen so far for macro.
09/07 09:32:44 PM: Updating LR scheduler:
09/07 09:32:44 PM: 	Best result seen so far for macro_avg: 0.834
09/07 09:32:44 PM: 	# validation passes without improvement: 0
09/07 09:32:44 PM: edges-srl-ontonotes_loss: training: 0.016598 validation: 0.014078
09/07 09:32:44 PM: macro_avg: validation: 0.834383
09/07 09:32:44 PM: micro_avg: validation: 0.000000
09/07 09:32:44 PM: edges-srl-ontonotes_mcc: training: 0.797548 validation: 0.833298
09/07 09:32:44 PM: edges-srl-ontonotes_acc: training: 0.713115 validation: 0.770303
09/07 09:32:44 PM: edges-srl-ontonotes_precision: training: 0.851726 validation: 0.883365
09/07 09:32:44 PM: edges-srl-ontonotes_recall: training: 0.752183 validation: 0.790547
09/07 09:32:44 PM: edges-srl-ontonotes_f1: training: 0.798865 validation: 0.834383
09/07 09:32:44 PM: Global learning rate: 0.0001
09/07 09:32:44 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 09:32:54 PM: Update 8121: task edges-srl-ontonotes, batch 121 (8121): mcc: 0.7919, acc: 0.7095, precision: 0.8462, recall: 0.7466, f1: 0.7933, edges-srl-ontonotes_loss: 0.0169
09/07 09:33:04 PM: Update 8204: task edges-srl-ontonotes, batch 204 (8204): mcc: 0.7876, acc: 0.7047, precision: 0.8432, recall: 0.7413, f1: 0.7890, edges-srl-ontonotes_loss: 0.0173
09/07 09:33:14 PM: Update 8325: task edges-srl-ontonotes, batch 325 (8325): mcc: 0.7822, acc: 0.6976, precision: 0.8395, recall: 0.7346, f1: 0.7835, edges-srl-ontonotes_loss: 0.0176
09/07 09:33:24 PM: Update 8442: task edges-srl-ontonotes, batch 442 (8442): mcc: 0.7798, acc: 0.6938, precision: 0.8376, recall: 0.7318, f1: 0.7811, edges-srl-ontonotes_loss: 0.0178
09/07 09:33:34 PM: Update 8541: task edges-srl-ontonotes, batch 541 (8541): mcc: 0.7793, acc: 0.6928, precision: 0.8376, recall: 0.7308, f1: 0.7806, edges-srl-ontonotes_loss: 0.0178
09/07 09:33:44 PM: Update 8652: task edges-srl-ontonotes, batch 652 (8652): mcc: 0.7780, acc: 0.6913, precision: 0.8361, recall: 0.7297, f1: 0.7793, edges-srl-ontonotes_loss: 0.0178
09/07 09:33:54 PM: Update 8768: task edges-srl-ontonotes, batch 768 (8768): mcc: 0.7780, acc: 0.6913, precision: 0.8365, recall: 0.7295, f1: 0.7793, edges-srl-ontonotes_loss: 0.0177
09/07 09:34:04 PM: Update 8867: task edges-srl-ontonotes, batch 867 (8867): mcc: 0.7766, acc: 0.6897, precision: 0.8352, recall: 0.7279, f1: 0.7778, edges-srl-ontonotes_loss: 0.0178
09/07 09:34:14 PM: Update 8975: task edges-srl-ontonotes, batch 975 (8975): mcc: 0.7728, acc: 0.6848, precision: 0.8323, recall: 0.7235, f1: 0.7741, edges-srl-ontonotes_loss: 0.0180
09/07 09:34:17 PM: ***** Step 9000 / Validation 9 *****
09/07 09:34:17 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:34:17 PM: Validating...
09/07 09:34:24 PM: Evaluate: task edges-srl-ontonotes, batch 86 (157): mcc: 0.8207, acc: 0.7537, precision: 0.8760, recall: 0.7737, f1: 0.8217, edges-srl-ontonotes_loss: 0.0144
09/07 09:34:31 PM: Updating LR scheduler:
09/07 09:34:31 PM: 	Best result seen so far for macro_avg: 0.834
09/07 09:34:31 PM: 	# validation passes without improvement: 1
09/07 09:34:31 PM: edges-srl-ontonotes_loss: training: 0.018068 validation: 0.013981
09/07 09:34:31 PM: macro_avg: validation: 0.831565
09/07 09:34:31 PM: micro_avg: validation: 0.000000
09/07 09:34:31 PM: edges-srl-ontonotes_mcc: training: 0.772253 validation: 0.830478
09/07 09:34:31 PM: edges-srl-ontonotes_acc: training: 0.684035 validation: 0.766454
09/07 09:34:31 PM: edges-srl-ontonotes_precision: training: 0.831881 validation: 0.881182
09/07 09:34:31 PM: edges-srl-ontonotes_recall: training: 0.722832 validation: 0.787237
09/07 09:34:31 PM: edges-srl-ontonotes_f1: training: 0.773532 validation: 0.831565
09/07 09:34:31 PM: Global learning rate: 0.0001
09/07 09:34:31 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 09:34:34 PM: Update 9039: task edges-srl-ontonotes, batch 39 (9039): mcc: 0.7687, acc: 0.6795, precision: 0.8311, recall: 0.7169, f1: 0.7698, edges-srl-ontonotes_loss: 0.0189
09/07 09:34:45 PM: Update 9125: task edges-srl-ontonotes, batch 125 (9125): mcc: 0.7676, acc: 0.6772, precision: 0.8294, recall: 0.7164, f1: 0.7688, edges-srl-ontonotes_loss: 0.0186
09/07 09:34:55 PM: Update 9234: task edges-srl-ontonotes, batch 234 (9234): mcc: 0.7630, acc: 0.6708, precision: 0.8250, recall: 0.7118, f1: 0.7642, edges-srl-ontonotes_loss: 0.0189
09/07 09:35:05 PM: Update 9346: task edges-srl-ontonotes, batch 346 (9346): mcc: 0.7639, acc: 0.6721, precision: 0.8256, recall: 0.7129, f1: 0.7651, edges-srl-ontonotes_loss: 0.0188
09/07 09:35:15 PM: Update 9443: task edges-srl-ontonotes, batch 443 (9443): mcc: 0.7626, acc: 0.6712, precision: 0.8252, recall: 0.7109, f1: 0.7638, edges-srl-ontonotes_loss: 0.0188
09/07 09:35:25 PM: Update 9550: task edges-srl-ontonotes, batch 550 (9550): mcc: 0.7673, acc: 0.6774, precision: 0.8285, recall: 0.7166, f1: 0.7685, edges-srl-ontonotes_loss: 0.0184
09/07 09:35:35 PM: Update 9656: task edges-srl-ontonotes, batch 656 (9656): mcc: 0.7701, acc: 0.6814, precision: 0.8301, recall: 0.7204, f1: 0.7714, edges-srl-ontonotes_loss: 0.0182
09/07 09:35:45 PM: Update 9752: task edges-srl-ontonotes, batch 752 (9752): mcc: 0.7714, acc: 0.6837, precision: 0.8312, recall: 0.7219, f1: 0.7727, edges-srl-ontonotes_loss: 0.0182
09/07 09:35:55 PM: Update 9864: task edges-srl-ontonotes, batch 864 (9864): mcc: 0.7739, acc: 0.6869, precision: 0.8329, recall: 0.7250, f1: 0.7752, edges-srl-ontonotes_loss: 0.0180
09/07 09:36:05 PM: Update 9972: task edges-srl-ontonotes, batch 972 (9972): mcc: 0.7753, acc: 0.6885, precision: 0.8342, recall: 0.7265, f1: 0.7766, edges-srl-ontonotes_loss: 0.0179
09/07 09:36:08 PM: ***** Step 10000 / Validation 10 *****
09/07 09:36:08 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:36:08 PM: Validating...
09/07 09:36:15 PM: Evaluate: task edges-srl-ontonotes, batch 82 (157): mcc: 0.8193, acc: 0.7566, precision: 0.8665, recall: 0.7796, f1: 0.8208, edges-srl-ontonotes_loss: 0.0147
09/07 09:36:22 PM: Updating LR scheduler:
09/07 09:36:22 PM: 	Best result seen so far for macro_avg: 0.834
09/07 09:36:22 PM: 	# validation passes without improvement: 2
09/07 09:36:22 PM: edges-srl-ontonotes_loss: training: 0.017824 validation: 0.014118
09/07 09:36:22 PM: macro_avg: validation: 0.831178
09/07 09:36:22 PM: micro_avg: validation: 0.000000
09/07 09:36:22 PM: edges-srl-ontonotes_mcc: training: 0.775856 validation: 0.829632
09/07 09:36:22 PM: edges-srl-ontonotes_acc: training: 0.689257 validation: 0.769918
09/07 09:36:22 PM: edges-srl-ontonotes_precision: training: 0.834596 validation: 0.871810
09/07 09:36:22 PM: edges-srl-ontonotes_recall: training: 0.727106 validation: 0.794165
09/07 09:36:22 PM: edges-srl-ontonotes_f1: training: 0.777152 validation: 0.831178
09/07 09:36:22 PM: Global learning rate: 0.0001
09/07 09:36:22 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 09:36:25 PM: Update 10034: task edges-srl-ontonotes, batch 34 (10034): mcc: 0.7900, acc: 0.7070, precision: 0.8464, recall: 0.7429, f1: 0.7913, edges-srl-ontonotes_loss: 0.0169
09/07 09:36:36 PM: Update 10113: task edges-srl-ontonotes, batch 113 (10113): mcc: 0.8004, acc: 0.7237, precision: 0.8506, recall: 0.7584, f1: 0.8019, edges-srl-ontonotes_loss: 0.0164
09/07 09:36:46 PM: Update 10220: task edges-srl-ontonotes, batch 220 (10220): mcc: 0.7978, acc: 0.7189, precision: 0.8502, recall: 0.7540, f1: 0.7993, edges-srl-ontonotes_loss: 0.0165
09/07 09:36:56 PM: Update 10330: task edges-srl-ontonotes, batch 330 (10330): mcc: 0.7977, acc: 0.7183, precision: 0.8504, recall: 0.7536, f1: 0.7991, edges-srl-ontonotes_loss: 0.0165
09/07 09:37:06 PM: Update 10428: task edges-srl-ontonotes, batch 428 (10428): mcc: 0.7964, acc: 0.7176, precision: 0.8493, recall: 0.7523, f1: 0.7979, edges-srl-ontonotes_loss: 0.0165
09/07 09:37:16 PM: Update 10539: task edges-srl-ontonotes, batch 539 (10539): mcc: 0.7954, acc: 0.7162, precision: 0.8489, recall: 0.7506, f1: 0.7967, edges-srl-ontonotes_loss: 0.0166
09/07 09:37:26 PM: Update 10650: task edges-srl-ontonotes, batch 650 (10650): mcc: 0.7933, acc: 0.7134, precision: 0.8481, recall: 0.7475, f1: 0.7946, edges-srl-ontonotes_loss: 0.0167
09/07 09:37:36 PM: Update 10750: task edges-srl-ontonotes, batch 750 (10750): mcc: 0.7914, acc: 0.7110, precision: 0.8468, recall: 0.7451, f1: 0.7927, edges-srl-ontonotes_loss: 0.0168
09/07 09:37:46 PM: Update 10861: task edges-srl-ontonotes, batch 861 (10861): mcc: 0.7908, acc: 0.7100, precision: 0.8470, recall: 0.7438, f1: 0.7920, edges-srl-ontonotes_loss: 0.0169
09/07 09:37:56 PM: Update 10971: task edges-srl-ontonotes, batch 971 (10971): mcc: 0.7903, acc: 0.7093, precision: 0.8469, recall: 0.7431, f1: 0.7916, edges-srl-ontonotes_loss: 0.0169
09/07 09:37:58 PM: ***** Step 11000 / Validation 11 *****
09/07 09:37:58 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:37:58 PM: Validating...
09/07 09:38:06 PM: Evaluate: task edges-srl-ontonotes, batch 82 (157): mcc: 0.8088, acc: 0.7396, precision: 0.8705, recall: 0.7565, f1: 0.8095, edges-srl-ontonotes_loss: 0.0153
09/07 09:38:13 PM: Updating LR scheduler:
09/07 09:38:13 PM: 	Best result seen so far for macro_avg: 0.834
09/07 09:38:13 PM: 	# validation passes without improvement: 3
09/07 09:38:13 PM: edges-srl-ontonotes_loss: training: 0.016885 validation: 0.014605
09/07 09:38:13 PM: macro_avg: validation: 0.820565
09/07 09:38:13 PM: micro_avg: validation: 0.000000
09/07 09:38:13 PM: edges-srl-ontonotes_mcc: training: 0.790429 validation: 0.819547
09/07 09:38:13 PM: edges-srl-ontonotes_acc: training: 0.709284 validation: 0.754522
09/07 09:38:13 PM: edges-srl-ontonotes_precision: training: 0.847125 validation: 0.873880
09/07 09:38:13 PM: edges-srl-ontonotes_recall: training: 0.743041 validation: 0.773382
09/07 09:38:13 PM: edges-srl-ontonotes_f1: training: 0.791677 validation: 0.820565
09/07 09:38:13 PM: Global learning rate: 0.0001
09/07 09:38:13 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 09:38:16 PM: Update 11022: task edges-srl-ontonotes, batch 22 (11022): mcc: 0.7708, acc: 0.6893, precision: 0.8244, recall: 0.7267, f1: 0.7725, edges-srl-ontonotes_loss: 0.0180
09/07 09:38:26 PM: Update 11135: task edges-srl-ontonotes, batch 135 (11135): mcc: 0.7826, acc: 0.6998, precision: 0.8387, recall: 0.7359, f1: 0.7840, edges-srl-ontonotes_loss: 0.0173
09/07 09:38:36 PM: Update 11246: task edges-srl-ontonotes, batch 246 (11246): mcc: 0.7820, acc: 0.6997, precision: 0.8402, recall: 0.7336, f1: 0.7833, edges-srl-ontonotes_loss: 0.0173
09/07 09:38:46 PM: Update 11322: task edges-srl-ontonotes, batch 322 (11322): mcc: 0.7816, acc: 0.6994, precision: 0.8395, recall: 0.7334, f1: 0.7829, edges-srl-ontonotes_loss: 0.0172
09/07 09:38:56 PM: Update 11434: task edges-srl-ontonotes, batch 434 (11434): mcc: 0.7834, acc: 0.7026, precision: 0.8405, recall: 0.7359, f1: 0.7848, edges-srl-ontonotes_loss: 0.0171
09/07 09:39:06 PM: Update 11545: task edges-srl-ontonotes, batch 545 (11545): mcc: 0.7870, acc: 0.7073, precision: 0.8432, recall: 0.7402, f1: 0.7883, edges-srl-ontonotes_loss: 0.0170
09/07 09:39:16 PM: Update 11644: task edges-srl-ontonotes, batch 644 (11644): mcc: 0.7879, acc: 0.7083, precision: 0.8439, recall: 0.7413, f1: 0.7893, edges-srl-ontonotes_loss: 0.0169
09/07 09:39:26 PM: Update 11754: task edges-srl-ontonotes, batch 754 (11754): mcc: 0.7895, acc: 0.7102, precision: 0.8450, recall: 0.7432, f1: 0.7908, edges-srl-ontonotes_loss: 0.0168
09/07 09:39:36 PM: Update 11864: task edges-srl-ontonotes, batch 864 (11864): mcc: 0.7913, acc: 0.7126, precision: 0.8463, recall: 0.7454, f1: 0.7927, edges-srl-ontonotes_loss: 0.0167
09/07 09:39:46 PM: Update 11959: task edges-srl-ontonotes, batch 959 (11959): mcc: 0.7905, acc: 0.7116, precision: 0.8458, recall: 0.7443, f1: 0.7918, edges-srl-ontonotes_loss: 0.0167
09/07 09:39:50 PM: ***** Step 12000 / Validation 12 *****
09/07 09:39:50 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:39:50 PM: Validating...
09/07 09:39:56 PM: Evaluate: task edges-srl-ontonotes, batch 68 (157): mcc: 0.8079, acc: 0.7413, precision: 0.8699, recall: 0.7552, f1: 0.8085, edges-srl-ontonotes_loss: 0.0155
09/07 09:40:05 PM: Updating LR scheduler:
09/07 09:40:05 PM: 	Best result seen so far for macro_avg: 0.834
09/07 09:40:05 PM: 	# validation passes without improvement: 4
09/07 09:40:05 PM: edges-srl-ontonotes_loss: training: 0.016808 validation: 0.014584
09/07 09:40:05 PM: macro_avg: validation: 0.821698
09/07 09:40:05 PM: micro_avg: validation: 0.000000
09/07 09:40:05 PM: edges-srl-ontonotes_mcc: training: 0.789228 validation: 0.820892
09/07 09:40:05 PM: edges-srl-ontonotes_acc: training: 0.710017 validation: 0.757909
09/07 09:40:05 PM: edges-srl-ontonotes_precision: training: 0.844872 validation: 0.878339
09/07 09:40:05 PM: edges-srl-ontonotes_recall: training: 0.742810 validation: 0.771919
09/07 09:40:05 PM: edges-srl-ontonotes_f1: training: 0.790561 validation: 0.821698
09/07 09:40:05 PM: Global learning rate: 0.0001
09/07 09:40:05 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 09:40:07 PM: Update 12019: task edges-srl-ontonotes, batch 19 (12019): mcc: 0.7571, acc: 0.6641, precision: 0.8253, recall: 0.7007, f1: 0.7579, edges-srl-ontonotes_loss: 0.0191
09/07 09:40:17 PM: Update 12118: task edges-srl-ontonotes, batch 118 (12118): mcc: 0.7676, acc: 0.6830, precision: 0.8337, recall: 0.7128, f1: 0.7685, edges-srl-ontonotes_loss: 0.0183
09/07 09:40:27 PM: Update 12217: task edges-srl-ontonotes, batch 217 (12217): mcc: 0.7733, acc: 0.6884, precision: 0.8374, recall: 0.7199, f1: 0.7743, edges-srl-ontonotes_loss: 0.0179
09/07 09:40:37 PM: Update 12291: task edges-srl-ontonotes, batch 291 (12291): mcc: 0.7778, acc: 0.6941, precision: 0.8401, recall: 0.7259, f1: 0.7788, edges-srl-ontonotes_loss: 0.0177
09/07 09:40:47 PM: Update 12416: task edges-srl-ontonotes, batch 416 (12416): mcc: 0.7851, acc: 0.7024, precision: 0.8444, recall: 0.7356, f1: 0.7862, edges-srl-ontonotes_loss: 0.0172
09/07 09:40:57 PM: Update 12535: task edges-srl-ontonotes, batch 535 (12535): mcc: 0.7922, acc: 0.7107, precision: 0.8495, recall: 0.7442, f1: 0.7934, edges-srl-ontonotes_loss: 0.0167
09/07 09:41:07 PM: Update 12654: task edges-srl-ontonotes, batch 654 (12654): mcc: 0.7985, acc: 0.7183, precision: 0.8536, recall: 0.7522, f1: 0.7997, edges-srl-ontonotes_loss: 0.0162
09/07 09:41:17 PM: Update 12789: task edges-srl-ontonotes, batch 789 (12789): mcc: 0.8071, acc: 0.7289, precision: 0.8594, recall: 0.7632, f1: 0.8085, edges-srl-ontonotes_loss: 0.0156
09/07 09:41:27 PM: Update 12906: task edges-srl-ontonotes, batch 906 (12906): mcc: 0.8123, acc: 0.7356, precision: 0.8630, recall: 0.7697, f1: 0.8137, edges-srl-ontonotes_loss: 0.0153
09/07 09:41:34 PM: ***** Step 13000 / Validation 13 *****
09/07 09:41:34 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:41:34 PM: Validating...
09/07 09:41:37 PM: Evaluate: task edges-srl-ontonotes, batch 32 (157): mcc: 0.8316, acc: 0.7695, precision: 0.8820, recall: 0.7886, f1: 0.8327, edges-srl-ontonotes_loss: 0.0141
09/07 09:41:47 PM: Evaluate: task edges-srl-ontonotes, batch 141 (157): mcc: 0.8358, acc: 0.7781, precision: 0.8817, recall: 0.7967, f1: 0.8370, edges-srl-ontonotes_loss: 0.0138
09/07 09:41:48 PM: Updating LR scheduler:
09/07 09:41:48 PM: 	Best result seen so far for macro_avg: 0.834
09/07 09:41:48 PM: 	# validation passes without improvement: 5
09/07 09:41:48 PM: edges-srl-ontonotes_loss: training: 0.015061 validation: 0.013994
09/07 09:41:48 PM: macro_avg: validation: 0.834297
09/07 09:41:48 PM: micro_avg: validation: 0.000000
09/07 09:41:48 PM: edges-srl-ontonotes_mcc: training: 0.815866 validation: 0.832988
09/07 09:41:48 PM: edges-srl-ontonotes_acc: training: 0.740336 validation: 0.774074
09/07 09:41:48 PM: edges-srl-ontonotes_precision: training: 0.865723 validation: 0.878984
09/07 09:41:48 PM: edges-srl-ontonotes_recall: training: 0.773824 validation: 0.793934
09/07 09:41:48 PM: edges-srl-ontonotes_f1: training: 0.817198 validation: 0.834297
09/07 09:41:48 PM: Global learning rate: 0.0001
09/07 09:41:48 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 09:41:57 PM: Update 13110: task edges-srl-ontonotes, batch 110 (13110): mcc: 0.8413, acc: 0.7722, precision: 0.8826, recall: 0.8063, f1: 0.8427, edges-srl-ontonotes_loss: 0.0133
09/07 09:42:07 PM: Update 13196: task edges-srl-ontonotes, batch 196 (13196): mcc: 0.8447, acc: 0.7781, precision: 0.8855, recall: 0.8100, f1: 0.8461, edges-srl-ontonotes_loss: 0.0130
09/07 09:42:17 PM: Update 13331: task edges-srl-ontonotes, batch 331 (13331): mcc: 0.8456, acc: 0.7795, precision: 0.8850, recall: 0.8123, f1: 0.8471, edges-srl-ontonotes_loss: 0.0130
09/07 09:42:27 PM: Update 13463: task edges-srl-ontonotes, batch 463 (13463): mcc: 0.8486, acc: 0.7837, precision: 0.8881, recall: 0.8151, f1: 0.8500, edges-srl-ontonotes_loss: 0.0129
09/07 09:42:37 PM: Update 13582: task edges-srl-ontonotes, batch 582 (13582): mcc: 0.8484, acc: 0.7840, precision: 0.8873, recall: 0.8154, f1: 0.8498, edges-srl-ontonotes_loss: 0.0129
09/07 09:42:47 PM: Update 13716: task edges-srl-ontonotes, batch 716 (13716): mcc: 0.8500, acc: 0.7860, precision: 0.8883, recall: 0.8174, f1: 0.8514, edges-srl-ontonotes_loss: 0.0127
09/07 09:42:57 PM: Update 13831: task edges-srl-ontonotes, batch 831 (13831): mcc: 0.8499, acc: 0.7863, precision: 0.8880, recall: 0.8176, f1: 0.8513, edges-srl-ontonotes_loss: 0.0127
09/07 09:43:07 PM: Update 13944: task edges-srl-ontonotes, batch 944 (13944): mcc: 0.8451, acc: 0.7801, precision: 0.8846, recall: 0.8117, f1: 0.8466, edges-srl-ontonotes_loss: 0.0131
09/07 09:43:12 PM: ***** Step 14000 / Validation 14 *****
09/07 09:43:12 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:43:12 PM: Validating...
09/07 09:43:17 PM: Evaluate: task edges-srl-ontonotes, batch 55 (157): mcc: 0.8243, acc: 0.7636, precision: 0.8800, recall: 0.7768, f1: 0.8252, edges-srl-ontonotes_loss: 0.0146
09/07 09:43:27 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:43:27 PM: Best result seen so far for macro.
09/07 09:43:27 PM: Updating LR scheduler:
09/07 09:43:27 PM: 	Best result seen so far for macro_avg: 0.840
09/07 09:43:27 PM: 	# validation passes without improvement: 0
09/07 09:43:27 PM: edges-srl-ontonotes_loss: training: 0.013194 validation: 0.013468
09/07 09:43:27 PM: macro_avg: validation: 0.840054
09/07 09:43:27 PM: micro_avg: validation: 0.000000
09/07 09:43:27 PM: edges-srl-ontonotes_mcc: training: 0.843262 validation: 0.839038
09/07 09:43:27 PM: edges-srl-ontonotes_acc: training: 0.777720 validation: 0.782619
09/07 09:43:27 PM: edges-srl-ontonotes_precision: training: 0.883303 validation: 0.888965
09/07 09:43:27 PM: edges-srl-ontonotes_recall: training: 0.809360 validation: 0.796244
09/07 09:43:27 PM: edges-srl-ontonotes_f1: training: 0.844716 validation: 0.840054
09/07 09:43:27 PM: Global learning rate: 0.0001
09/07 09:43:27 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 09:43:27 PM: Update 14008: task edges-srl-ontonotes, batch 8 (14008): mcc: 0.7992, acc: 0.7300, precision: 0.8449, recall: 0.7614, f1: 0.8010, edges-srl-ontonotes_loss: 0.0158
09/07 09:43:37 PM: Update 14123: task edges-srl-ontonotes, batch 123 (14123): mcc: 0.8211, acc: 0.7506, precision: 0.8685, recall: 0.7812, f1: 0.8225, edges-srl-ontonotes_loss: 0.0148
09/07 09:43:47 PM: Update 14215: task edges-srl-ontonotes, batch 215 (14215): mcc: 0.8070, acc: 0.7336, precision: 0.8571, recall: 0.7651, f1: 0.8085, edges-srl-ontonotes_loss: 0.0157
09/07 09:43:58 PM: Update 14328: task edges-srl-ontonotes, batch 328 (14328): mcc: 0.8021, acc: 0.7274, precision: 0.8520, recall: 0.7603, f1: 0.8036, edges-srl-ontonotes_loss: 0.0160
09/07 09:44:08 PM: Update 14440: task edges-srl-ontonotes, batch 440 (14440): mcc: 0.7999, acc: 0.7254, precision: 0.8498, recall: 0.7583, f1: 0.8014, edges-srl-ontonotes_loss: 0.0161
09/07 09:44:18 PM: Update 14523: task edges-srl-ontonotes, batch 523 (14523): mcc: 0.8011, acc: 0.7267, precision: 0.8515, recall: 0.7591, f1: 0.8026, edges-srl-ontonotes_loss: 0.0161
09/07 09:44:28 PM: Update 14646: task edges-srl-ontonotes, batch 646 (14646): mcc: 0.8052, acc: 0.7321, precision: 0.8548, recall: 0.7638, f1: 0.8067, edges-srl-ontonotes_loss: 0.0158
09/07 09:44:38 PM: Update 14766: task edges-srl-ontonotes, batch 766 (14766): mcc: 0.8079, acc: 0.7349, precision: 0.8574, recall: 0.7664, f1: 0.8093, edges-srl-ontonotes_loss: 0.0156
09/07 09:44:48 PM: Update 14871: task edges-srl-ontonotes, batch 871 (14871): mcc: 0.8099, acc: 0.7373, precision: 0.8593, recall: 0.7684, f1: 0.8113, edges-srl-ontonotes_loss: 0.0155
09/07 09:44:58 PM: Update 14992: task edges-srl-ontonotes, batch 992 (14992): mcc: 0.8124, acc: 0.7405, precision: 0.8611, recall: 0.7716, f1: 0.8139, edges-srl-ontonotes_loss: 0.0153
09/07 09:44:58 PM: ***** Step 15000 / Validation 15 *****
09/07 09:44:58 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:44:58 PM: Validating...
09/07 09:45:08 PM: Evaluate: task edges-srl-ontonotes, batch 103 (157): mcc: 0.8477, acc: 0.7936, precision: 0.8936, recall: 0.8084, f1: 0.8489, edges-srl-ontonotes_loss: 0.0125
09/07 09:45:13 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:45:13 PM: Best result seen so far for macro.
09/07 09:45:13 PM: Updating LR scheduler:
09/07 09:45:13 PM: 	Best result seen so far for macro_avg: 0.848
09/07 09:45:13 PM: 	# validation passes without improvement: 0
09/07 09:45:13 PM: edges-srl-ontonotes_loss: training: 0.015287 validation: 0.012726
09/07 09:45:13 PM: macro_avg: validation: 0.848309
09/07 09:45:13 PM: micro_avg: validation: 0.000000
09/07 09:45:13 PM: edges-srl-ontonotes_mcc: training: 0.812605 validation: 0.847066
09/07 09:45:13 PM: edges-srl-ontonotes_acc: training: 0.740751 validation: 0.793626
09/07 09:45:13 PM: edges-srl-ontonotes_precision: training: 0.861273 validation: 0.890487
09/07 09:45:13 PM: edges-srl-ontonotes_recall: training: 0.771733 validation: 0.809945
09/07 09:45:13 PM: edges-srl-ontonotes_f1: training: 0.814048 validation: 0.848309
09/07 09:45:13 PM: Global learning rate: 0.0001
09/07 09:45:13 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 09:45:18 PM: Update 15060: task edges-srl-ontonotes, batch 60 (15060): mcc: 0.8260, acc: 0.7578, precision: 0.8744, recall: 0.7850, f1: 0.8273, edges-srl-ontonotes_loss: 0.0143
09/07 09:45:28 PM: Update 15166: task edges-srl-ontonotes, batch 166 (15166): mcc: 0.8226, acc: 0.7550, precision: 0.8684, recall: 0.7841, f1: 0.8241, edges-srl-ontonotes_loss: 0.0146
09/07 09:45:38 PM: Update 15288: task edges-srl-ontonotes, batch 288 (15288): mcc: 0.8169, acc: 0.7467, precision: 0.8638, recall: 0.7775, f1: 0.8184, edges-srl-ontonotes_loss: 0.0149
09/07 09:45:48 PM: Update 15408: task edges-srl-ontonotes, batch 408 (15408): mcc: 0.8157, acc: 0.7451, precision: 0.8635, recall: 0.7755, f1: 0.8172, edges-srl-ontonotes_loss: 0.0151
09/07 09:45:58 PM: Update 15491: task edges-srl-ontonotes, batch 491 (15491): mcc: 0.8133, acc: 0.7418, precision: 0.8617, recall: 0.7726, f1: 0.8147, edges-srl-ontonotes_loss: 0.0153
09/07 09:46:08 PM: Update 15605: task edges-srl-ontonotes, batch 605 (15605): mcc: 0.8101, acc: 0.7379, precision: 0.8587, recall: 0.7693, f1: 0.8116, edges-srl-ontonotes_loss: 0.0155
09/07 09:46:18 PM: Update 15727: task edges-srl-ontonotes, batch 727 (15727): mcc: 0.8081, acc: 0.7353, precision: 0.8572, recall: 0.7669, f1: 0.8095, edges-srl-ontonotes_loss: 0.0157
09/07 09:46:28 PM: Update 15829: task edges-srl-ontonotes, batch 829 (15829): mcc: 0.8065, acc: 0.7331, precision: 0.8560, recall: 0.7650, f1: 0.8080, edges-srl-ontonotes_loss: 0.0157
09/07 09:46:38 PM: Update 15944: task edges-srl-ontonotes, batch 944 (15944): mcc: 0.8056, acc: 0.7322, precision: 0.8552, recall: 0.7640, f1: 0.8071, edges-srl-ontonotes_loss: 0.0158
09/07 09:46:43 PM: ***** Step 16000 / Validation 16 *****
09/07 09:46:43 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:46:43 PM: Validating...
09/07 09:46:48 PM: Evaluate: task edges-srl-ontonotes, batch 55 (157): mcc: 0.8316, acc: 0.7755, precision: 0.8799, recall: 0.7905, f1: 0.8328, edges-srl-ontonotes_loss: 0.0137
09/07 09:46:58 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:46:58 PM: Best result seen so far for macro.
09/07 09:46:58 PM: Updating LR scheduler:
09/07 09:46:58 PM: 	Best result seen so far for macro_avg: 0.851
09/07 09:46:58 PM: 	# validation passes without improvement: 0
09/07 09:46:58 PM: edges-srl-ontonotes_loss: training: 0.015776 validation: 0.012490
09/07 09:46:58 PM: macro_avg: validation: 0.850822
09/07 09:46:58 PM: micro_avg: validation: 0.000000
09/07 09:46:58 PM: edges-srl-ontonotes_mcc: training: 0.805266 validation: 0.849602
09/07 09:46:58 PM: edges-srl-ontonotes_acc: training: 0.731760 validation: 0.797552
09/07 09:46:58 PM: edges-srl-ontonotes_precision: training: 0.855051 validation: 0.892770
09/07 09:46:58 PM: edges-srl-ontonotes_recall: training: 0.763605 validation: 0.812640
09/07 09:46:58 PM: edges-srl-ontonotes_f1: training: 0.806745 validation: 0.850822
09/07 09:46:58 PM: Global learning rate: 0.0001
09/07 09:46:58 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 09:46:58 PM: Update 16007: task edges-srl-ontonotes, batch 7 (16007): mcc: 0.8226, acc: 0.7405, precision: 0.8868, recall: 0.7677, f1: 0.8230, edges-srl-ontonotes_loss: 0.0144
09/07 09:47:08 PM: Update 16108: task edges-srl-ontonotes, batch 108 (16108): mcc: 0.7893, acc: 0.7134, precision: 0.8442, recall: 0.7436, f1: 0.7907, edges-srl-ontonotes_loss: 0.0169
09/07 09:47:18 PM: Update 16217: task edges-srl-ontonotes, batch 217 (16217): mcc: 0.7828, acc: 0.7050, precision: 0.8388, recall: 0.7362, f1: 0.7841, edges-srl-ontonotes_loss: 0.0173
09/07 09:47:29 PM: Update 16326: task edges-srl-ontonotes, batch 326 (16326): mcc: 0.7817, acc: 0.7027, precision: 0.8373, recall: 0.7355, f1: 0.7831, edges-srl-ontonotes_loss: 0.0174
09/07 09:47:39 PM: Update 16426: task edges-srl-ontonotes, batch 426 (16426): mcc: 0.7800, acc: 0.6999, precision: 0.8364, recall: 0.7332, f1: 0.7814, edges-srl-ontonotes_loss: 0.0175
09/07 09:47:49 PM: Update 16538: task edges-srl-ontonotes, batch 538 (16538): mcc: 0.7795, acc: 0.7001, precision: 0.8365, recall: 0.7323, f1: 0.7809, edges-srl-ontonotes_loss: 0.0175
09/07 09:47:59 PM: Update 16649: task edges-srl-ontonotes, batch 649 (16649): mcc: 0.7798, acc: 0.7000, precision: 0.8370, recall: 0.7322, f1: 0.7811, edges-srl-ontonotes_loss: 0.0174
09/07 09:48:09 PM: Update 16725: task edges-srl-ontonotes, batch 725 (16725): mcc: 0.7818, acc: 0.7022, precision: 0.8386, recall: 0.7346, f1: 0.7832, edges-srl-ontonotes_loss: 0.0173
09/07 09:48:19 PM: Update 16830: task edges-srl-ontonotes, batch 830 (16830): mcc: 0.7848, acc: 0.7060, precision: 0.8408, recall: 0.7383, f1: 0.7862, edges-srl-ontonotes_loss: 0.0171
09/07 09:48:29 PM: Update 16940: task edges-srl-ontonotes, batch 940 (16940): mcc: 0.7878, acc: 0.7100, precision: 0.8430, recall: 0.7419, f1: 0.7892, edges-srl-ontonotes_loss: 0.0169
09/07 09:48:36 PM: ***** Step 17000 / Validation 17 *****
09/07 09:48:36 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:48:36 PM: Validating...
09/07 09:48:39 PM: Evaluate: task edges-srl-ontonotes, batch 35 (157): mcc: 0.8373, acc: 0.7846, precision: 0.8843, recall: 0.7972, f1: 0.8385, edges-srl-ontonotes_loss: 0.0134
09/07 09:48:49 PM: Evaluate: task edges-srl-ontonotes, batch 145 (157): mcc: 0.8458, acc: 0.7954, precision: 0.8902, recall: 0.8078, f1: 0.8470, edges-srl-ontonotes_loss: 0.0126
09/07 09:48:50 PM: Updating LR scheduler:
09/07 09:48:50 PM: 	Best result seen so far for macro_avg: 0.851
09/07 09:48:50 PM: 	# validation passes without improvement: 1
09/07 09:48:50 PM: edges-srl-ontonotes_loss: training: 0.016797 validation: 0.012795
09/07 09:48:50 PM: macro_avg: validation: 0.846117
09/07 09:48:50 PM: micro_avg: validation: 0.000000
09/07 09:48:50 PM: edges-srl-ontonotes_mcc: training: 0.788616 validation: 0.844905
09/07 09:48:50 PM: edges-srl-ontonotes_acc: training: 0.711097 validation: 0.793934
09/07 09:48:50 PM: edges-srl-ontonotes_precision: training: 0.843656 validation: 0.889568
09/07 09:48:50 PM: edges-srl-ontonotes_recall: training: 0.742753 validation: 0.806712
09/07 09:48:50 PM: edges-srl-ontonotes_f1: training: 0.789995 validation: 0.846117
09/07 09:48:50 PM: Global learning rate: 0.0001
09/07 09:48:50 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 09:48:59 PM: Update 17100: task edges-srl-ontonotes, batch 100 (17100): mcc: 0.8131, acc: 0.7424, precision: 0.8614, recall: 0.7725, f1: 0.8146, edges-srl-ontonotes_loss: 0.0152
09/07 09:49:09 PM: Update 17211: task edges-srl-ontonotes, batch 211 (17211): mcc: 0.8112, acc: 0.7421, precision: 0.8588, recall: 0.7713, f1: 0.8127, edges-srl-ontonotes_loss: 0.0153
09/07 09:49:19 PM: Update 17310: task edges-srl-ontonotes, batch 310 (17310): mcc: 0.8092, acc: 0.7395, precision: 0.8577, recall: 0.7686, f1: 0.8107, edges-srl-ontonotes_loss: 0.0154
09/07 09:49:29 PM: Update 17421: task edges-srl-ontonotes, batch 421 (17421): mcc: 0.8112, acc: 0.7413, precision: 0.8596, recall: 0.7706, f1: 0.8126, edges-srl-ontonotes_loss: 0.0152
09/07 09:49:39 PM: Update 17531: task edges-srl-ontonotes, batch 531 (17531): mcc: 0.8141, acc: 0.7447, precision: 0.8627, recall: 0.7732, f1: 0.8155, edges-srl-ontonotes_loss: 0.0151
09/07 09:49:51 PM: Update 17623: task edges-srl-ontonotes, batch 623 (17623): mcc: 0.8151, acc: 0.7462, precision: 0.8636, recall: 0.7743, f1: 0.8165, edges-srl-ontonotes_loss: 0.0151
09/07 09:50:01 PM: Update 17734: task edges-srl-ontonotes, batch 734 (17734): mcc: 0.8128, acc: 0.7435, precision: 0.8619, recall: 0.7715, f1: 0.8142, edges-srl-ontonotes_loss: 0.0153
09/07 09:50:11 PM: Update 17847: task edges-srl-ontonotes, batch 847 (17847): mcc: 0.8118, acc: 0.7424, precision: 0.8614, recall: 0.7701, f1: 0.8132, edges-srl-ontonotes_loss: 0.0154
09/07 09:50:21 PM: Update 17943: task edges-srl-ontonotes, batch 943 (17943): mcc: 0.8102, acc: 0.7402, precision: 0.8607, recall: 0.7678, f1: 0.8116, edges-srl-ontonotes_loss: 0.0154
09/07 09:50:26 PM: ***** Step 18000 / Validation 18 *****
09/07 09:50:26 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:50:26 PM: Validating...
09/07 09:50:31 PM: Evaluate: task edges-srl-ontonotes, batch 57 (157): mcc: 0.8250, acc: 0.7646, precision: 0.8793, recall: 0.7786, f1: 0.8259, edges-srl-ontonotes_loss: 0.0140
09/07 09:50:40 PM: Updating LR scheduler:
09/07 09:50:40 PM: 	Best result seen so far for macro_avg: 0.851
09/07 09:50:40 PM: 	# validation passes without improvement: 2
09/07 09:50:40 PM: edges-srl-ontonotes_loss: training: 0.015466 validation: 0.012980
09/07 09:50:40 PM: macro_avg: validation: 0.842746
09/07 09:50:40 PM: micro_avg: validation: 0.000000
09/07 09:50:40 PM: edges-srl-ontonotes_mcc: training: 0.809575 validation: 0.841729
09/07 09:50:40 PM: edges-srl-ontonotes_acc: training: 0.739206 validation: 0.785390
09/07 09:50:40 PM: edges-srl-ontonotes_precision: training: 0.860325 validation: 0.890967
09/07 09:50:40 PM: edges-srl-ontonotes_recall: training: 0.766918 validation: 0.799477
09/07 09:50:40 PM: edges-srl-ontonotes_f1: training: 0.810941 validation: 0.842746
09/07 09:50:40 PM: Global learning rate: 0.0001
09/07 09:50:40 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 09:50:41 PM: Update 18009: task edges-srl-ontonotes, batch 9 (18009): mcc: 0.7878, acc: 0.7056, precision: 0.8465, recall: 0.7387, f1: 0.7890, edges-srl-ontonotes_loss: 0.0171
09/07 09:50:51 PM: Update 18121: task edges-srl-ontonotes, batch 121 (18121): mcc: 0.8065, acc: 0.7325, precision: 0.8593, recall: 0.7621, f1: 0.8078, edges-srl-ontonotes_loss: 0.0157
09/07 09:51:01 PM: Update 18234: task edges-srl-ontonotes, batch 234 (18234): mcc: 0.8064, acc: 0.7326, precision: 0.8597, recall: 0.7616, f1: 0.8077, edges-srl-ontonotes_loss: 0.0156
09/07 09:51:11 PM: Update 18337: task edges-srl-ontonotes, batch 337 (18337): mcc: 0.8050, acc: 0.7311, precision: 0.8582, recall: 0.7604, f1: 0.8063, edges-srl-ontonotes_loss: 0.0157
09/07 09:51:21 PM: Update 18448: task edges-srl-ontonotes, batch 448 (18448): mcc: 0.8012, acc: 0.7269, precision: 0.8549, recall: 0.7562, f1: 0.8025, edges-srl-ontonotes_loss: 0.0159
09/07 09:51:31 PM: Update 18558: task edges-srl-ontonotes, batch 558 (18558): mcc: 0.8011, acc: 0.7267, precision: 0.8546, recall: 0.7562, f1: 0.8024, edges-srl-ontonotes_loss: 0.0159
09/07 09:51:41 PM: Update 18636: task edges-srl-ontonotes, batch 636 (18636): mcc: 0.8022, acc: 0.7287, precision: 0.8551, recall: 0.7579, f1: 0.8036, edges-srl-ontonotes_loss: 0.0158
09/07 09:51:51 PM: Update 18747: task edges-srl-ontonotes, batch 747 (18747): mcc: 0.8037, acc: 0.7312, precision: 0.8563, recall: 0.7596, f1: 0.8050, edges-srl-ontonotes_loss: 0.0158
09/07 09:52:01 PM: Update 18858: task edges-srl-ontonotes, batch 858 (18858): mcc: 0.8050, acc: 0.7331, precision: 0.8571, recall: 0.7613, f1: 0.8064, edges-srl-ontonotes_loss: 0.0157
09/07 09:52:11 PM: Update 18955: task edges-srl-ontonotes, batch 955 (18955): mcc: 0.8060, acc: 0.7344, precision: 0.8580, recall: 0.7624, f1: 0.8073, edges-srl-ontonotes_loss: 0.0156
09/07 09:52:15 PM: ***** Step 19000 / Validation 19 *****
09/07 09:52:15 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:52:15 PM: Validating...
09/07 09:52:21 PM: Evaluate: task edges-srl-ontonotes, batch 67 (157): mcc: 0.8272, acc: 0.7676, precision: 0.8813, recall: 0.7811, f1: 0.8281, edges-srl-ontonotes_loss: 0.0139
09/07 09:52:30 PM: Updating LR scheduler:
09/07 09:52:30 PM: 	Best result seen so far for macro_avg: 0.851
09/07 09:52:30 PM: 	# validation passes without improvement: 3
09/07 09:52:30 PM: edges-srl-ontonotes_loss: training: 0.015606 validation: 0.013065
09/07 09:52:30 PM: macro_avg: validation: 0.841201
09/07 09:52:30 PM: micro_avg: validation: 0.000000
09/07 09:52:30 PM: edges-srl-ontonotes_mcc: training: 0.806380 validation: 0.840095
09/07 09:52:30 PM: edges-srl-ontonotes_acc: training: 0.735067 validation: 0.785775
09/07 09:52:30 PM: edges-srl-ontonotes_precision: training: 0.858328 validation: 0.888090
09/07 09:52:30 PM: edges-srl-ontonotes_recall: training: 0.762743 validation: 0.799015
09/07 09:52:30 PM: edges-srl-ontonotes_f1: training: 0.807717 validation: 0.841201
09/07 09:52:30 PM: Global learning rate: 0.0001
09/07 09:52:30 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 09:52:31 PM: Update 19020: task edges-srl-ontonotes, batch 20 (19020): mcc: 0.8134, acc: 0.7486, precision: 0.8546, recall: 0.7794, f1: 0.8153, edges-srl-ontonotes_loss: 0.0147
09/07 09:52:41 PM: Update 19132: task edges-srl-ontonotes, batch 132 (19132): mcc: 0.8124, acc: 0.7433, precision: 0.8620, recall: 0.7707, f1: 0.8138, edges-srl-ontonotes_loss: 0.0149
09/07 09:52:52 PM: Update 19226: task edges-srl-ontonotes, batch 226 (19226): mcc: 0.8056, acc: 0.7343, precision: 0.8573, recall: 0.7622, f1: 0.8070, edges-srl-ontonotes_loss: 0.0155
09/07 09:53:02 PM: Update 19324: task edges-srl-ontonotes, batch 324 (19324): mcc: 0.7986, acc: 0.7244, precision: 0.8540, recall: 0.7521, f1: 0.7998, edges-srl-ontonotes_loss: 0.0160
09/07 09:53:12 PM: Update 19423: task edges-srl-ontonotes, batch 423 (19423): mcc: 0.7969, acc: 0.7221, precision: 0.8532, recall: 0.7496, f1: 0.7981, edges-srl-ontonotes_loss: 0.0161
09/07 09:53:22 PM: Update 19513: task edges-srl-ontonotes, batch 513 (19513): mcc: 0.7966, acc: 0.7216, precision: 0.8534, recall: 0.7488, f1: 0.7977, edges-srl-ontonotes_loss: 0.0161
09/07 09:53:32 PM: Update 19634: task edges-srl-ontonotes, batch 634 (19634): mcc: 0.8019, acc: 0.7279, precision: 0.8569, recall: 0.7558, f1: 0.8031, edges-srl-ontonotes_loss: 0.0158
09/07 09:53:42 PM: Update 19757: task edges-srl-ontonotes, batch 757 (19757): mcc: 0.8054, acc: 0.7324, precision: 0.8590, recall: 0.7603, f1: 0.8066, edges-srl-ontonotes_loss: 0.0155
09/07 09:53:52 PM: Update 19850: task edges-srl-ontonotes, batch 850 (19850): mcc: 0.8087, acc: 0.7366, precision: 0.8607, recall: 0.7649, f1: 0.8100, edges-srl-ontonotes_loss: 0.0153
09/07 09:54:02 PM: Update 19986: task edges-srl-ontonotes, batch 986 (19986): mcc: 0.8153, acc: 0.7447, precision: 0.8651, recall: 0.7732, f1: 0.8166, edges-srl-ontonotes_loss: 0.0149
09/07 09:54:03 PM: ***** Step 20000 / Validation 20 *****
09/07 09:54:03 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:54:03 PM: Validating...
09/07 09:54:12 PM: Evaluate: task edges-srl-ontonotes, batch 99 (157): mcc: 0.8378, acc: 0.7806, precision: 0.8875, recall: 0.7952, f1: 0.8388, edges-srl-ontonotes_loss: 0.0131
09/07 09:54:17 PM: Updating LR scheduler:
09/07 09:54:17 PM: 	Best result seen so far for macro_avg: 0.851
09/07 09:54:17 PM: 	# validation passes without improvement: 4
09/07 09:54:17 PM: edges-srl-ontonotes_loss: training: 0.014813 validation: 0.012935
09/07 09:54:17 PM: macro_avg: validation: 0.844342
09/07 09:54:17 PM: micro_avg: validation: 0.000000
09/07 09:54:17 PM: edges-srl-ontonotes_mcc: training: 0.815971 validation: 0.843139
09/07 09:54:17 PM: edges-srl-ontonotes_acc: training: 0.745630 validation: 0.790624
09/07 09:54:17 PM: edges-srl-ontonotes_precision: training: 0.865583 validation: 0.888454
09/07 09:54:17 PM: edges-srl-ontonotes_recall: training: 0.774146 validation: 0.804403
09/07 09:54:17 PM: edges-srl-ontonotes_f1: training: 0.817316 validation: 0.844342
09/07 09:54:17 PM: Global learning rate: 0.0001
09/07 09:54:17 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 09:54:22 PM: Update 20061: task edges-srl-ontonotes, batch 61 (20061): mcc: 0.8592, acc: 0.7997, precision: 0.8969, recall: 0.8269, f1: 0.8605, edges-srl-ontonotes_loss: 0.0117
09/07 09:54:32 PM: Update 20182: task edges-srl-ontonotes, batch 182 (20182): mcc: 0.8614, acc: 0.8033, precision: 0.8984, recall: 0.8298, f1: 0.8628, edges-srl-ontonotes_loss: 0.0116
09/07 09:54:42 PM: Update 20314: task edges-srl-ontonotes, batch 314 (20314): mcc: 0.8600, acc: 0.8007, precision: 0.8972, recall: 0.8283, f1: 0.8614, edges-srl-ontonotes_loss: 0.0118
09/07 09:54:53 PM: Update 20440: task edges-srl-ontonotes, batch 440 (20440): mcc: 0.8614, acc: 0.8033, precision: 0.8978, recall: 0.8303, f1: 0.8627, edges-srl-ontonotes_loss: 0.0117
09/07 09:55:03 PM: Update 20576: task edges-srl-ontonotes, batch 576 (20576): mcc: 0.8620, acc: 0.8040, precision: 0.8980, recall: 0.8314, f1: 0.8634, edges-srl-ontonotes_loss: 0.0116
09/07 09:55:13 PM: Update 20709: task edges-srl-ontonotes, batch 709 (20709): mcc: 0.8623, acc: 0.8045, precision: 0.8981, recall: 0.8318, f1: 0.8637, edges-srl-ontonotes_loss: 0.0116
09/07 09:55:23 PM: Update 20803: task edges-srl-ontonotes, batch 803 (20803): mcc: 0.8616, acc: 0.8040, precision: 0.8971, recall: 0.8313, f1: 0.8630, edges-srl-ontonotes_loss: 0.0117
09/07 09:55:33 PM: Update 20938: task edges-srl-ontonotes, batch 938 (20938): mcc: 0.8616, acc: 0.8043, precision: 0.8971, recall: 0.8313, f1: 0.8630, edges-srl-ontonotes_loss: 0.0117
09/07 09:55:37 PM: ***** Step 21000 / Validation 21 *****
09/07 09:55:37 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:55:37 PM: Validating...
09/07 09:55:43 PM: Evaluate: task edges-srl-ontonotes, batch 62 (157): mcc: 0.8365, acc: 0.7827, precision: 0.8856, recall: 0.7944, f1: 0.8376, edges-srl-ontonotes_loss: 0.0134
09/07 09:55:51 PM: Updating LR scheduler:
09/07 09:55:51 PM: 	Best result seen so far for macro_avg: 0.851
09/07 09:55:51 PM: 	# validation passes without improvement: 5
09/07 09:55:51 PM: edges-srl-ontonotes_loss: training: 0.011639 validation: 0.012625
09/07 09:55:51 PM: macro_avg: validation: 0.849010
09/07 09:55:51 PM: micro_avg: validation: 0.000000
09/07 09:55:51 PM: edges-srl-ontonotes_mcc: training: 0.862386 validation: 0.847786
09/07 09:55:51 PM: edges-srl-ontonotes_acc: training: 0.805676 validation: 0.797706
09/07 09:55:51 PM: edges-srl-ontonotes_precision: training: 0.897773 validation: 0.891382
09/07 09:55:51 PM: edges-srl-ontonotes_recall: training: 0.832237 validation: 0.810484
09/07 09:55:51 PM: edges-srl-ontonotes_f1: training: 0.863764 validation: 0.849010
09/07 09:55:51 PM: Global learning rate: 0.0001
09/07 09:55:51 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 09:55:53 PM: Update 21019: task edges-srl-ontonotes, batch 19 (21019): mcc: 0.8666, acc: 0.8196, precision: 0.8952, recall: 0.8427, f1: 0.8682, edges-srl-ontonotes_loss: 0.0116
09/07 09:56:03 PM: Update 21128: task edges-srl-ontonotes, batch 128 (21128): mcc: 0.8534, acc: 0.7959, precision: 0.8891, recall: 0.8233, f1: 0.8549, edges-srl-ontonotes_loss: 0.0122
09/07 09:56:13 PM: Update 21245: task edges-srl-ontonotes, batch 245 (21245): mcc: 0.8412, acc: 0.7807, precision: 0.8798, recall: 0.8087, f1: 0.8427, edges-srl-ontonotes_loss: 0.0130
09/07 09:56:23 PM: Update 21354: task edges-srl-ontonotes, batch 354 (21354): mcc: 0.8358, acc: 0.7735, precision: 0.8761, recall: 0.8018, f1: 0.8373, edges-srl-ontonotes_loss: 0.0135
09/07 09:56:33 PM: Update 21449: task edges-srl-ontonotes, batch 449 (21449): mcc: 0.8299, acc: 0.7663, precision: 0.8719, recall: 0.7946, f1: 0.8314, edges-srl-ontonotes_loss: 0.0140
09/07 09:56:43 PM: Update 21560: task edges-srl-ontonotes, batch 560 (21560): mcc: 0.8266, acc: 0.7616, precision: 0.8700, recall: 0.7901, f1: 0.8281, edges-srl-ontonotes_loss: 0.0142
09/07 09:56:53 PM: Update 21673: task edges-srl-ontonotes, batch 673 (21673): mcc: 0.8235, acc: 0.7573, precision: 0.8678, recall: 0.7862, f1: 0.8250, edges-srl-ontonotes_loss: 0.0144
09/07 09:57:03 PM: Update 21754: task edges-srl-ontonotes, batch 754 (21754): mcc: 0.8218, acc: 0.7553, precision: 0.8667, recall: 0.7840, f1: 0.8233, edges-srl-ontonotes_loss: 0.0145
09/07 09:57:13 PM: Update 21879: task edges-srl-ontonotes, batch 879 (21879): mcc: 0.8236, acc: 0.7578, precision: 0.8680, recall: 0.7863, f1: 0.8251, edges-srl-ontonotes_loss: 0.0144
09/07 09:57:23 PM: ***** Step 22000 / Validation 22 *****
09/07 09:57:23 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:57:23 PM: Validating...
09/07 09:57:23 PM: Evaluate: task edges-srl-ontonotes, batch 2 (157): mcc: 0.8709, acc: 0.8239, precision: 0.9182, recall: 0.8295, f1: 0.8716, edges-srl-ontonotes_loss: 0.0101
09/07 09:57:33 PM: Evaluate: task edges-srl-ontonotes, batch 113 (157): mcc: 0.8571, acc: 0.8105, precision: 0.8950, recall: 0.8247, f1: 0.8584, edges-srl-ontonotes_loss: 0.0117
09/07 09:57:37 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:57:37 PM: Best result seen so far for macro.
09/07 09:57:37 PM: Updating LR scheduler:
09/07 09:57:37 PM: 	Best result seen so far for macro_avg: 0.858
09/07 09:57:37 PM: 	# validation passes without improvement: 0
09/07 09:57:37 PM: edges-srl-ontonotes_loss: training: 0.014297 validation: 0.011999
09/07 09:57:37 PM: macro_avg: validation: 0.857509
09/07 09:57:37 PM: micro_avg: validation: 0.000000
09/07 09:57:37 PM: edges-srl-ontonotes_mcc: training: 0.825349 validation: 0.856131
09/07 09:57:37 PM: edges-srl-ontonotes_acc: training: 0.759646 validation: 0.809714
09/07 09:57:37 PM: edges-srl-ontonotes_precision: training: 0.869686 validation: 0.893731
09/07 09:57:37 PM: edges-srl-ontonotes_recall: training: 0.788033 validation: 0.824109
09/07 09:57:37 PM: edges-srl-ontonotes_f1: training: 0.826848 validation: 0.857509
09/07 09:57:37 PM: Global learning rate: 0.0001
09/07 09:57:37 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 09:57:43 PM: Update 22057: task edges-srl-ontonotes, batch 57 (22057): mcc: 0.8311, acc: 0.7690, precision: 0.8712, recall: 0.7975, f1: 0.8328, edges-srl-ontonotes_loss: 0.0142
09/07 09:57:53 PM: Update 22179: task edges-srl-ontonotes, batch 179 (22179): mcc: 0.8377, acc: 0.7760, precision: 0.8780, recall: 0.8036, f1: 0.8392, edges-srl-ontonotes_loss: 0.0133
09/07 09:58:04 PM: Update 22299: task edges-srl-ontonotes, batch 299 (22299): mcc: 0.8395, acc: 0.7774, precision: 0.8807, recall: 0.8045, f1: 0.8409, edges-srl-ontonotes_loss: 0.0133
09/07 09:58:14 PM: Update 22406: task edges-srl-ontonotes, batch 406 (22406): mcc: 0.8369, acc: 0.7743, precision: 0.8777, recall: 0.8025, f1: 0.8385, edges-srl-ontonotes_loss: 0.0135
09/07 09:58:24 PM: Update 22527: task edges-srl-ontonotes, batch 527 (22527): mcc: 0.8325, acc: 0.7693, precision: 0.8749, recall: 0.7968, f1: 0.8340, edges-srl-ontonotes_loss: 0.0138
09/07 09:58:34 PM: Update 22645: task edges-srl-ontonotes, batch 645 (22645): mcc: 0.8314, acc: 0.7682, precision: 0.8743, recall: 0.7953, f1: 0.8329, edges-srl-ontonotes_loss: 0.0139
09/07 09:58:44 PM: Update 22727: task edges-srl-ontonotes, batch 727 (22727): mcc: 0.8297, acc: 0.7660, precision: 0.8729, recall: 0.7933, f1: 0.8312, edges-srl-ontonotes_loss: 0.0140
09/07 09:58:54 PM: Update 22845: task edges-srl-ontonotes, batch 845 (22845): mcc: 0.8263, acc: 0.7618, precision: 0.8703, recall: 0.7893, f1: 0.8278, edges-srl-ontonotes_loss: 0.0143
09/07 09:59:04 PM: Update 22966: task edges-srl-ontonotes, batch 966 (22966): mcc: 0.8245, acc: 0.7591, precision: 0.8692, recall: 0.7868, f1: 0.8260, edges-srl-ontonotes_loss: 0.0144
09/07 09:59:08 PM: ***** Step 23000 / Validation 23 *****
09/07 09:59:08 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:59:08 PM: Validating...
09/07 09:59:14 PM: Evaluate: task edges-srl-ontonotes, batch 64 (157): mcc: 0.8438, acc: 0.7929, precision: 0.8907, recall: 0.8035, f1: 0.8449, edges-srl-ontonotes_loss: 0.0126
09/07 09:59:22 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:59:22 PM: Best result seen so far for macro.
09/07 09:59:22 PM: Updating LR scheduler:
09/07 09:59:22 PM: 	Best result seen so far for macro_avg: 0.861
09/07 09:59:22 PM: 	# validation passes without improvement: 0
09/07 09:59:22 PM: edges-srl-ontonotes_loss: training: 0.014500 validation: 0.011691
09/07 09:59:22 PM: macro_avg: validation: 0.860518
09/07 09:59:22 PM: micro_avg: validation: 0.000000
09/07 09:59:22 PM: edges-srl-ontonotes_mcc: training: 0.823506 validation: 0.859329
09/07 09:59:22 PM: edges-srl-ontonotes_acc: training: 0.757813 validation: 0.812486
09/07 09:59:22 PM: edges-srl-ontonotes_precision: training: 0.868399 validation: 0.900202
09/07 09:59:22 PM: edges-srl-ontonotes_recall: training: 0.785737 validation: 0.824186
09/07 09:59:22 PM: edges-srl-ontonotes_f1: training: 0.825002 validation: 0.860518
09/07 09:59:22 PM: Global learning rate: 0.0001
09/07 09:59:22 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 09:59:24 PM: Update 23016: task edges-srl-ontonotes, batch 16 (23016): mcc: 0.8194, acc: 0.7471, precision: 0.8670, recall: 0.7793, f1: 0.8208, edges-srl-ontonotes_loss: 0.0146
09/07 09:59:34 PM: Update 23133: task edges-srl-ontonotes, batch 133 (23133): mcc: 0.8117, acc: 0.7418, precision: 0.8606, recall: 0.7707, f1: 0.8132, edges-srl-ontonotes_loss: 0.0151
09/07 09:59:44 PM: Update 23246: task edges-srl-ontonotes, batch 246 (23246): mcc: 0.8107, acc: 0.7416, precision: 0.8583, recall: 0.7709, f1: 0.8122, edges-srl-ontonotes_loss: 0.0151
09/07 09:59:54 PM: Update 23344: task edges-srl-ontonotes, batch 344 (23344): mcc: 0.8054, acc: 0.7362, precision: 0.8528, recall: 0.7659, f1: 0.8070, edges-srl-ontonotes_loss: 0.0155
09/07 10:00:04 PM: Update 23457: task edges-srl-ontonotes, batch 457 (23457): mcc: 0.8007, acc: 0.7301, precision: 0.8495, recall: 0.7601, f1: 0.8023, edges-srl-ontonotes_loss: 0.0158
09/07 10:00:14 PM: Update 23569: task edges-srl-ontonotes, batch 569 (23569): mcc: 0.7991, acc: 0.7273, precision: 0.8487, recall: 0.7577, f1: 0.8006, edges-srl-ontonotes_loss: 0.0159
09/07 10:00:24 PM: Update 23663: task edges-srl-ontonotes, batch 663 (23663): mcc: 0.7985, acc: 0.7264, precision: 0.8492, recall: 0.7562, f1: 0.8000, edges-srl-ontonotes_loss: 0.0160
09/07 10:00:34 PM: Update 23773: task edges-srl-ontonotes, batch 773 (23773): mcc: 0.7971, acc: 0.7247, precision: 0.8484, recall: 0.7544, f1: 0.7986, edges-srl-ontonotes_loss: 0.0161
09/07 10:00:44 PM: Update 23886: task edges-srl-ontonotes, batch 886 (23886): mcc: 0.7969, acc: 0.7243, precision: 0.8485, recall: 0.7539, f1: 0.7984, edges-srl-ontonotes_loss: 0.0161
09/07 10:00:54 PM: Update 23963: task edges-srl-ontonotes, batch 963 (23963): mcc: 0.7972, acc: 0.7246, precision: 0.8487, recall: 0.7542, f1: 0.7987, edges-srl-ontonotes_loss: 0.0161
09/07 10:00:57 PM: ***** Step 24000 / Validation 24 *****
09/07 10:00:57 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:00:57 PM: Validating...
09/07 10:01:04 PM: Evaluate: task edges-srl-ontonotes, batch 75 (157): mcc: 0.8443, acc: 0.7928, precision: 0.8902, recall: 0.8050, f1: 0.8455, edges-srl-ontonotes_loss: 0.0125
09/07 10:01:12 PM: Updating LR scheduler:
09/07 10:01:12 PM: 	Best result seen so far for macro_avg: 0.861
09/07 10:01:12 PM: 	# validation passes without improvement: 1
09/07 10:01:12 PM: edges-srl-ontonotes_loss: training: 0.015998 validation: 0.011850
09/07 10:01:12 PM: macro_avg: validation: 0.857258
09/07 10:01:12 PM: micro_avg: validation: 0.000000
09/07 10:01:12 PM: edges-srl-ontonotes_mcc: training: 0.797966 validation: 0.856068
09/07 10:01:12 PM: edges-srl-ontonotes_acc: training: 0.725578 validation: 0.808021
09/07 10:01:12 PM: edges-srl-ontonotes_precision: training: 0.849272 validation: 0.897935
09/07 10:01:12 PM: edges-srl-ontonotes_recall: training: 0.755157 validation: 0.820106
09/07 10:01:12 PM: edges-srl-ontonotes_f1: training: 0.799454 validation: 0.857258
09/07 10:01:12 PM: Global learning rate: 0.0001
09/07 10:01:12 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 10:01:14 PM: Update 24027: task edges-srl-ontonotes, batch 27 (24027): mcc: 0.8201, acc: 0.7545, precision: 0.8714, recall: 0.7766, f1: 0.8213, edges-srl-ontonotes_loss: 0.0143
09/07 10:01:24 PM: Update 24134: task edges-srl-ontonotes, batch 134 (24134): mcc: 0.8121, acc: 0.7413, precision: 0.8607, recall: 0.7712, f1: 0.8135, edges-srl-ontonotes_loss: 0.0151
09/07 10:01:34 PM: Update 24240: task edges-srl-ontonotes, batch 240 (24240): mcc: 0.8152, acc: 0.7474, precision: 0.8629, recall: 0.7750, f1: 0.8166, edges-srl-ontonotes_loss: 0.0147
09/07 10:01:44 PM: Update 24339: task edges-srl-ontonotes, batch 339 (24339): mcc: 0.8160, acc: 0.7487, precision: 0.8641, recall: 0.7755, f1: 0.8174, edges-srl-ontonotes_loss: 0.0147
09/07 10:01:54 PM: Update 24448: task edges-srl-ontonotes, batch 448 (24448): mcc: 0.8161, acc: 0.7490, precision: 0.8636, recall: 0.7762, f1: 0.8176, edges-srl-ontonotes_loss: 0.0147
09/07 10:02:05 PM: Update 24556: task edges-srl-ontonotes, batch 556 (24556): mcc: 0.8173, acc: 0.7505, precision: 0.8645, recall: 0.7776, f1: 0.8188, edges-srl-ontonotes_loss: 0.0146
09/07 10:02:15 PM: Update 24668: task edges-srl-ontonotes, batch 668 (24668): mcc: 0.8176, acc: 0.7509, precision: 0.8646, recall: 0.7782, f1: 0.8191, edges-srl-ontonotes_loss: 0.0146
09/07 10:02:26 PM: Update 24777: task edges-srl-ontonotes, batch 777 (24777): mcc: 0.8185, acc: 0.7521, precision: 0.8654, recall: 0.7791, f1: 0.8200, edges-srl-ontonotes_loss: 0.0146
09/07 10:02:37 PM: Update 24869: task edges-srl-ontonotes, batch 869 (24869): mcc: 0.8205, acc: 0.7545, precision: 0.8669, recall: 0.7815, f1: 0.8220, edges-srl-ontonotes_loss: 0.0145
09/07 10:02:47 PM: Update 24978: task edges-srl-ontonotes, batch 978 (24978): mcc: 0.8195, acc: 0.7532, precision: 0.8664, recall: 0.7800, f1: 0.8209, edges-srl-ontonotes_loss: 0.0146
09/07 10:02:49 PM: ***** Step 25000 / Validation 25 *****
09/07 10:02:49 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:02:49 PM: Validating...
09/07 10:02:57 PM: Evaluate: task edges-srl-ontonotes, batch 89 (157): mcc: 0.8449, acc: 0.7932, precision: 0.8901, recall: 0.8062, f1: 0.8461, edges-srl-ontonotes_loss: 0.0123
09/07 10:03:03 PM: Updating LR scheduler:
09/07 10:03:03 PM: 	Best result seen so far for macro_avg: 0.861
09/07 10:03:03 PM: 	# validation passes without improvement: 2
09/07 10:03:03 PM: edges-srl-ontonotes_loss: training: 0.014588 validation: 0.012065
09/07 10:03:03 PM: macro_avg: validation: 0.854005
09/07 10:03:03 PM: micro_avg: validation: 0.000000
09/07 10:03:03 PM: edges-srl-ontonotes_mcc: training: 0.819092 validation: 0.852762
09/07 10:03:03 PM: edges-srl-ontonotes_acc: training: 0.752762 validation: 0.804172
09/07 10:03:03 PM: edges-srl-ontonotes_precision: training: 0.866051 validation: 0.894488
09/07 10:03:03 PM: edges-srl-ontonotes_recall: training: 0.779575 validation: 0.817027
09/07 10:03:03 PM: edges-srl-ontonotes_f1: training: 0.820541 validation: 0.854005
09/07 10:03:03 PM: Global learning rate: 0.0001
09/07 10:03:03 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 10:03:07 PM: Update 25041: task edges-srl-ontonotes, batch 41 (25041): mcc: 0.8157, acc: 0.7492, precision: 0.8646, recall: 0.7746, f1: 0.8171, edges-srl-ontonotes_loss: 0.0148
09/07 10:03:17 PM: Update 25153: task edges-srl-ontonotes, batch 153 (25153): mcc: 0.8117, acc: 0.7419, precision: 0.8619, recall: 0.7694, f1: 0.8130, edges-srl-ontonotes_loss: 0.0152
09/07 10:03:27 PM: Update 25252: task edges-srl-ontonotes, batch 252 (25252): mcc: 0.8127, acc: 0.7432, precision: 0.8629, recall: 0.7705, f1: 0.8141, edges-srl-ontonotes_loss: 0.0151
09/07 10:03:37 PM: Update 25365: task edges-srl-ontonotes, batch 365 (25365): mcc: 0.8132, acc: 0.7441, precision: 0.8636, recall: 0.7708, f1: 0.8145, edges-srl-ontonotes_loss: 0.0150
09/07 10:03:47 PM: Update 25476: task edges-srl-ontonotes, batch 476 (25476): mcc: 0.8140, acc: 0.7454, precision: 0.8643, recall: 0.7717, f1: 0.8154, edges-srl-ontonotes_loss: 0.0150
09/07 10:03:57 PM: Update 25574: task edges-srl-ontonotes, batch 574 (25574): mcc: 0.8132, acc: 0.7443, precision: 0.8639, recall: 0.7704, f1: 0.8145, edges-srl-ontonotes_loss: 0.0151
09/07 10:04:07 PM: Update 25687: task edges-srl-ontonotes, batch 687 (25687): mcc: 0.8129, acc: 0.7444, precision: 0.8633, recall: 0.7705, f1: 0.8143, edges-srl-ontonotes_loss: 0.0151
09/07 10:04:17 PM: Update 25798: task edges-srl-ontonotes, batch 798 (25798): mcc: 0.8123, acc: 0.7435, precision: 0.8629, recall: 0.7698, f1: 0.8137, edges-srl-ontonotes_loss: 0.0151
09/07 10:04:27 PM: Update 25895: task edges-srl-ontonotes, batch 895 (25895): mcc: 0.8130, acc: 0.7445, precision: 0.8635, recall: 0.7705, f1: 0.8143, edges-srl-ontonotes_loss: 0.0151
09/07 10:04:37 PM: ***** Step 26000 / Validation 26 *****
09/07 10:04:37 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:04:37 PM: Validating...
09/07 10:04:37 PM: Evaluate: task edges-srl-ontonotes, batch 5 (157): mcc: 0.8586, acc: 0.8178, precision: 0.8983, recall: 0.8246, f1: 0.8599, edges-srl-ontonotes_loss: 0.0117
09/07 10:04:47 PM: Evaluate: task edges-srl-ontonotes, batch 114 (157): mcc: 0.8466, acc: 0.7959, precision: 0.8902, recall: 0.8093, f1: 0.8478, edges-srl-ontonotes_loss: 0.0124
09/07 10:04:51 PM: Updating LR scheduler:
09/07 10:04:51 PM: 	Best result seen so far for macro_avg: 0.861
09/07 10:04:51 PM: 	# validation passes without improvement: 3
09/07 10:04:51 PM: edges-srl-ontonotes_loss: training: 0.014974 validation: 0.012282
09/07 10:04:51 PM: macro_avg: validation: 0.851007
09/07 10:04:51 PM: micro_avg: validation: 0.000000
09/07 10:04:51 PM: edges-srl-ontonotes_mcc: training: 0.813845 validation: 0.849699
09/07 10:04:51 PM: edges-srl-ontonotes_acc: training: 0.745950 validation: 0.800631
09/07 10:04:51 PM: edges-srl-ontonotes_precision: training: 0.863754 validation: 0.890957
09/07 10:04:51 PM: edges-srl-ontonotes_recall: training: 0.771817 validation: 0.814487
09/07 10:04:51 PM: edges-srl-ontonotes_f1: training: 0.815202 validation: 0.851007
09/07 10:04:51 PM: Global learning rate: 0.0001
09/07 10:04:51 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 10:04:58 PM: Update 26066: task edges-srl-ontonotes, batch 66 (26066): mcc: 0.8149, acc: 0.7471, precision: 0.8636, recall: 0.7739, f1: 0.8163, edges-srl-ontonotes_loss: 0.0151
09/07 10:05:08 PM: Update 26145: task edges-srl-ontonotes, batch 145 (26145): mcc: 0.8182, acc: 0.7529, precision: 0.8659, recall: 0.7780, f1: 0.8196, edges-srl-ontonotes_loss: 0.0147
09/07 10:05:18 PM: Update 26255: task edges-srl-ontonotes, batch 255 (26255): mcc: 0.8207, acc: 0.7550, precision: 0.8685, recall: 0.7803, f1: 0.8221, edges-srl-ontonotes_loss: 0.0145
09/07 10:05:28 PM: Update 26368: task edges-srl-ontonotes, batch 368 (26368): mcc: 0.8226, acc: 0.7575, precision: 0.8700, recall: 0.7825, f1: 0.8239, edges-srl-ontonotes_loss: 0.0143
09/07 10:05:38 PM: Update 26458: task edges-srl-ontonotes, batch 458 (26458): mcc: 0.8200, acc: 0.7544, precision: 0.8680, recall: 0.7795, f1: 0.8214, edges-srl-ontonotes_loss: 0.0145
09/07 10:05:48 PM: Update 26557: task edges-srl-ontonotes, batch 557 (26557): mcc: 0.8153, acc: 0.7483, precision: 0.8651, recall: 0.7733, f1: 0.8166, edges-srl-ontonotes_loss: 0.0149
09/07 10:05:58 PM: Update 26656: task edges-srl-ontonotes, batch 656 (26656): mcc: 0.8136, acc: 0.7458, precision: 0.8643, recall: 0.7709, f1: 0.8150, edges-srl-ontonotes_loss: 0.0150
09/07 10:06:08 PM: Update 26747: task edges-srl-ontonotes, batch 747 (26747): mcc: 0.8125, acc: 0.7444, precision: 0.8637, recall: 0.7693, f1: 0.8138, edges-srl-ontonotes_loss: 0.0151
09/07 10:06:18 PM: Update 26868: task edges-srl-ontonotes, batch 868 (26868): mcc: 0.8147, acc: 0.7473, precision: 0.8644, recall: 0.7728, f1: 0.8161, edges-srl-ontonotes_loss: 0.0149
09/07 10:06:28 PM: Update 26991: task edges-srl-ontonotes, batch 991 (26991): mcc: 0.8176, acc: 0.7507, precision: 0.8666, recall: 0.7762, f1: 0.8189, edges-srl-ontonotes_loss: 0.0147
09/07 10:06:29 PM: ***** Step 27000 / Validation 27 *****
09/07 10:06:29 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:06:29 PM: Validating...
09/07 10:06:38 PM: Evaluate: task edges-srl-ontonotes, batch 101 (157): mcc: 0.8470, acc: 0.7949, precision: 0.8908, recall: 0.8095, f1: 0.8482, edges-srl-ontonotes_loss: 0.0124
09/07 10:06:43 PM: Updating LR scheduler:
09/07 10:06:43 PM: 	Best result seen so far for macro_avg: 0.861
09/07 10:06:43 PM: 	# validation passes without improvement: 4
09/07 10:06:43 PM: edges-srl-ontonotes_loss: training: 0.014642 validation: 0.012204
09/07 10:06:43 PM: macro_avg: validation: 0.853804
09/07 10:06:43 PM: micro_avg: validation: 0.000000
09/07 10:06:43 PM: edges-srl-ontonotes_mcc: training: 0.817772 validation: 0.852475
09/07 10:06:43 PM: edges-srl-ontonotes_acc: training: 0.750999 validation: 0.803556
09/07 10:06:43 PM: edges-srl-ontonotes_precision: training: 0.866708 validation: 0.892395
09/07 10:06:43 PM: edges-srl-ontonotes_recall: training: 0.776505 validation: 0.818413
09/07 10:06:43 PM: edges-srl-ontonotes_f1: training: 0.819131 validation: 0.853804
09/07 10:06:43 PM: Global learning rate: 0.0001
09/07 10:06:43 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 10:06:48 PM: Update 27058: task edges-srl-ontonotes, batch 58 (27058): mcc: 0.8317, acc: 0.7703, precision: 0.8734, recall: 0.7966, f1: 0.8332, edges-srl-ontonotes_loss: 0.0132
09/07 10:06:58 PM: Update 27152: task edges-srl-ontonotes, batch 152 (27152): mcc: 0.8467, acc: 0.7876, precision: 0.8842, recall: 0.8150, f1: 0.8482, edges-srl-ontonotes_loss: 0.0123
09/07 10:07:08 PM: Update 27283: task edges-srl-ontonotes, batch 283 (27283): mcc: 0.8560, acc: 0.7988, precision: 0.8922, recall: 0.8253, f1: 0.8575, edges-srl-ontonotes_loss: 0.0118
09/07 10:07:18 PM: Update 27402: task edges-srl-ontonotes, batch 402 (27402): mcc: 0.8602, acc: 0.8041, precision: 0.8955, recall: 0.8302, f1: 0.8616, edges-srl-ontonotes_loss: 0.0115
09/07 10:07:28 PM: Update 27532: task edges-srl-ontonotes, batch 532 (27532): mcc: 0.8624, acc: 0.8065, precision: 0.8977, recall: 0.8324, f1: 0.8638, edges-srl-ontonotes_loss: 0.0114
09/07 10:07:38 PM: Update 27666: task edges-srl-ontonotes, batch 666 (27666): mcc: 0.8639, acc: 0.8086, precision: 0.8987, recall: 0.8343, f1: 0.8653, edges-srl-ontonotes_loss: 0.0113
09/07 10:07:48 PM: Update 27783: task edges-srl-ontonotes, batch 783 (27783): mcc: 0.8647, acc: 0.8098, precision: 0.8992, recall: 0.8353, f1: 0.8661, edges-srl-ontonotes_loss: 0.0113
09/07 10:07:58 PM: Update 27919: task edges-srl-ontonotes, batch 919 (27919): mcc: 0.8661, acc: 0.8117, precision: 0.9000, recall: 0.8372, f1: 0.8675, edges-srl-ontonotes_loss: 0.0112
09/07 10:08:06 PM: ***** Step 28000 / Validation 28 *****
09/07 10:08:06 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:08:06 PM: Validating...
09/07 10:08:08 PM: Evaluate: task edges-srl-ontonotes, batch 30 (157): mcc: 0.8571, acc: 0.8052, precision: 0.9057, recall: 0.8149, f1: 0.8579, edges-srl-ontonotes_loss: 0.0118
09/07 10:08:20 PM: Evaluate: task edges-srl-ontonotes, batch 136 (157): mcc: 0.8577, acc: 0.8103, precision: 0.9004, recall: 0.8209, f1: 0.8588, edges-srl-ontonotes_loss: 0.0117
09/07 10:08:22 PM: Updating LR scheduler:
09/07 10:08:22 PM: 	Best result seen so far for macro_avg: 0.861
09/07 10:08:22 PM: 	# validation passes without improvement: 5
09/07 10:08:22 PM: edges-srl-ontonotes_loss: training: 0.011227 validation: 0.011913
09/07 10:08:22 PM: macro_avg: validation: 0.856763
09/07 10:08:22 PM: micro_avg: validation: 0.000000
09/07 10:08:22 PM: edges-srl-ontonotes_mcc: training: 0.866274 validation: 0.855632
09/07 10:08:22 PM: edges-srl-ontonotes_acc: training: 0.812165 validation: 0.807790
09/07 10:08:22 PM: edges-srl-ontonotes_precision: training: 0.899947 validation: 0.898884
09/07 10:08:22 PM: edges-srl-ontonotes_recall: training: 0.837612 validation: 0.818413
09/07 10:08:22 PM: edges-srl-ontonotes_f1: training: 0.867661 validation: 0.856763
09/07 10:08:22 PM: Global learning rate: 0.0001
09/07 10:08:22 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 10:08:30 PM: Update 28107: task edges-srl-ontonotes, batch 107 (28107): mcc: 0.8677, acc: 0.8152, precision: 0.8989, recall: 0.8413, f1: 0.8691, edges-srl-ontonotes_loss: 0.0114
09/07 10:08:40 PM: Update 28242: task edges-srl-ontonotes, batch 242 (28242): mcc: 0.8710, acc: 0.8198, precision: 0.9028, recall: 0.8439, f1: 0.8724, edges-srl-ontonotes_loss: 0.0111
09/07 10:08:50 PM: Update 28348: task edges-srl-ontonotes, batch 348 (28348): mcc: 0.8674, acc: 0.8156, precision: 0.9003, recall: 0.8395, f1: 0.8688, edges-srl-ontonotes_loss: 0.0115
09/07 10:09:00 PM: Update 28461: task edges-srl-ontonotes, batch 461 (28461): mcc: 0.8601, acc: 0.8061, precision: 0.8949, recall: 0.8306, f1: 0.8616, edges-srl-ontonotes_loss: 0.0120
09/07 10:09:10 PM: Update 28577: task edges-srl-ontonotes, batch 577 (28577): mcc: 0.8557, acc: 0.7998, precision: 0.8921, recall: 0.8248, f1: 0.8571, edges-srl-ontonotes_loss: 0.0122
09/07 10:09:20 PM: Update 28674: task edges-srl-ontonotes, batch 674 (28674): mcc: 0.8512, acc: 0.7945, precision: 0.8882, recall: 0.8198, f1: 0.8526, edges-srl-ontonotes_loss: 0.0125
09/07 10:09:30 PM: Update 28781: task edges-srl-ontonotes, batch 781 (28781): mcc: 0.8455, acc: 0.7876, precision: 0.8834, recall: 0.8135, f1: 0.8470, edges-srl-ontonotes_loss: 0.0129
09/07 10:09:40 PM: Update 28894: task edges-srl-ontonotes, batch 894 (28894): mcc: 0.8423, acc: 0.7839, precision: 0.8810, recall: 0.8097, f1: 0.8438, edges-srl-ontonotes_loss: 0.0131
09/07 10:09:50 PM: Update 28995: task edges-srl-ontonotes, batch 995 (28995): mcc: 0.8401, acc: 0.7810, precision: 0.8796, recall: 0.8068, f1: 0.8416, edges-srl-ontonotes_loss: 0.0132
09/07 10:09:51 PM: ***** Step 29000 / Validation 29 *****
09/07 10:09:51 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:09:51 PM: Validating...
09/07 10:10:00 PM: Evaluate: task edges-srl-ontonotes, batch 104 (157): mcc: 0.8580, acc: 0.8139, precision: 0.8951, recall: 0.8264, f1: 0.8594, edges-srl-ontonotes_loss: 0.0116
09/07 10:10:05 PM: Best result seen so far for edges-srl-ontonotes.
09/07 10:10:05 PM: Best result seen so far for macro.
09/07 10:10:05 PM: Updating LR scheduler:
09/07 10:10:05 PM: 	Best result seen so far for macro_avg: 0.861
09/07 10:10:05 PM: 	# validation passes without improvement: 0
09/07 10:10:05 PM: edges-srl-ontonotes_loss: training: 0.013250 validation: 0.011703
09/07 10:10:05 PM: macro_avg: validation: 0.861171
09/07 10:10:05 PM: micro_avg: validation: 0.000000
09/07 10:10:05 PM: edges-srl-ontonotes_mcc: training: 0.839923 validation: 0.859746
09/07 10:10:05 PM: edges-srl-ontonotes_acc: training: 0.780851 validation: 0.817027
09/07 10:10:05 PM: edges-srl-ontonotes_precision: training: 0.879411 validation: 0.894912
09/07 10:10:05 PM: edges-srl-ontonotes_recall: training: 0.806629 validation: 0.829882
09/07 10:10:05 PM: edges-srl-ontonotes_f1: training: 0.841449 validation: 0.861171
09/07 10:10:05 PM: Global learning rate: 0.0001
09/07 10:10:05 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-top/run
09/07 10:10:10 PM: Update 29060: task edges-srl-ontonotes, batch 60 (29060): mcc: 0.8343, acc: 0.7746, precision: 0.8775, recall: 0.7978, f1: 0.8357, edges-srl-ontonotes_loss: 0.0135
09/07 10:10:20 PM: Update 29181: task edges-srl-ontonotes, batch 181 (29181): mcc: 0.8412, acc: 0.7809, precision: 0.8833, recall: 0.8055, f1: 0.8426, edges-srl-ontonotes_loss: 0.0131
09/07 10:10:33 PM: Update 29298: task edges-srl-ontonotes, batch 298 (29298): mcc: 0.8435, acc: 0.7834, precision: 0.8840, recall: 0.8091, f1: 0.8449, edges-srl-ontonotes_loss: 0.0130
09/07 10:10:43 PM: Update 29415: task edges-srl-ontonotes, batch 415 (29415): mcc: 0.8457, acc: 0.7859, precision: 0.8851, recall: 0.8123, f1: 0.8471, edges-srl-ontonotes_loss: 0.0128
09/07 10:10:53 PM: Update 29535: task edges-srl-ontonotes, batch 535 (29535): mcc: 0.8464, acc: 0.7875, precision: 0.8854, recall: 0.8133, f1: 0.8478, edges-srl-ontonotes_loss: 0.0128
09/07 10:11:03 PM: Update 29640: task edges-srl-ontonotes, batch 640 (29640): mcc: 0.8447, acc: 0.7854, precision: 0.8839, recall: 0.8114, f1: 0.8461, edges-srl-ontonotes_loss: 0.0129
