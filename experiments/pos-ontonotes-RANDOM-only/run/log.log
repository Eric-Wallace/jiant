09/17 12:19:09 AM: Git branch: master
09/17 12:19:09 AM: Git SHA: 4086cd8f278243816795989a620c769378a6ab56
09/17 12:19:10 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/pos-ontonotes-RANDOM-only/",
  "exp_name": "experiments/pos-ontonotes-RANDOM-only",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/pos-ontonotes-RANDOM-only/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/RANDOM",
  "pytorch_transformers_output_mode": "only",
  "remote_log_name": "experiments/pos-ontonotes-RANDOM-only__run",
  "run_dir": "./experiments/pos-ontonotes-RANDOM-only/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-pos-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/17 12:19:10 AM: Saved config to ./experiments/pos-ontonotes-RANDOM-only/run/params.conf
09/17 12:19:10 AM: Using random seed 1234
09/17 12:19:10 AM: Using GPU 0
09/17 12:19:10 AM: Loading tasks...
09/17 12:19:10 AM: Writing pre-preprocessed tasks to ./experiments/pos-ontonotes-RANDOM-only/
09/17 12:19:10 AM: 	Creating task edges-pos-ontonotes from scratch.
09/17 12:19:30 AM: Read=110514, Skip=5298, Total=115812 from ./probing_data/edges/ontonotes/const/pos/train.json.retokenized.bert-base-uncased
09/17 12:19:31 AM: Read=15060, Skip=620, Total=15680 from ./probing_data/edges/ontonotes/const/pos/development.json.retokenized.bert-base-uncased
09/17 12:19:35 AM: Read=11462, Skip=755, Total=12217 from ./probing_data/edges/ontonotes/const/pos/test.json.retokenized.bert-base-uncased
09/17 12:19:48 AM: 	Task 'edges-pos-ontonotes': |train|=110514 |val|=15060 |test|=11462
09/17 12:19:48 AM: 	Finished loading tasks: edges-pos-ontonotes.
09/17 12:19:48 AM: 	Building vocab from scratch.
09/17 12:19:48 AM: 	Counting units for task edges-pos-ontonotes.
09/17 12:19:50 AM: 	Task 'edges-pos-ontonotes': adding vocab namespace 'edges-pos-ontonotes_labels'
09/17 12:19:52 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/17 12:19:52 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/17 12:19:52 AM: 	Saved vocab to ./experiments/pos-ontonotes-RANDOM-only/vocab
09/17 12:19:52 AM: Loading token dictionary from ./experiments/pos-ontonotes-RANDOM-only/vocab.
09/17 12:19:52 AM: 	Loaded vocab from ./experiments/pos-ontonotes-RANDOM-only/vocab
09/17 12:19:52 AM: 	Vocab namespace bert_uncased: size 30524
09/17 12:19:52 AM: 	Vocab namespace tokens: size 24015
09/17 12:19:52 AM: 	Vocab namespace edges-pos-ontonotes_labels: size 48
09/17 12:19:52 AM: 	Vocab namespace chars: size 81
09/17 12:19:52 AM: 	Finished building vocab.
09/17 12:19:52 AM: 	Task edges-pos-ontonotes (train): Indexing from scratch.
09/17 12:20:32 AM: 	Task edges-pos-ontonotes (train): Saved 110514 instances to ./experiments/pos-ontonotes-RANDOM-only/preproc/edges-pos-ontonotes__train_data
09/17 12:20:32 AM: 	Task edges-pos-ontonotes (val): Indexing from scratch.
09/17 12:20:38 AM: 	Task edges-pos-ontonotes (val): Saved 15060 instances to ./experiments/pos-ontonotes-RANDOM-only/preproc/edges-pos-ontonotes__val_data
09/17 12:20:38 AM: 	Task edges-pos-ontonotes (test): Indexing from scratch.
09/17 12:20:41 AM: 	Task edges-pos-ontonotes (test): Saved 11462 instances to ./experiments/pos-ontonotes-RANDOM-only/preproc/edges-pos-ontonotes__test_data
09/17 12:20:41 AM: 	Finished indexing tasks
09/17 12:20:41 AM: 	Creating trimmed target-only version of edges-pos-ontonotes train.
09/17 12:20:41 AM: 	  Training on 
09/17 12:20:41 AM: 	  Evaluating on edges-pos-ontonotes
09/17 12:20:41 AM: 	Finished loading tasks in 90.465s
09/17 12:20:41 AM: 	 Tasks: ['edges-pos-ontonotes']
09/17 12:20:41 AM: Building model...
09/17 12:20:41 AM: Using BERT model (bert-base-uncased).
09/17 12:20:41 AM: LOADING A RANDOMLY WEIGHTS BERT
09/17 12:20:48 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpei63r_4a
09/17 12:20:50 AM: copying /tmp/tmpei63r_4a to cache at ./experiments/pos-ontonotes-RANDOM-only/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/17 12:20:50 AM: creating metadata file for ./experiments/pos-ontonotes-RANDOM-only/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/17 12:20:50 AM: removing temp file /tmp/tmpei63r_4a
09/17 12:20:50 AM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./experiments/pos-ontonotes-RANDOM-only/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/17 12:20:50 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/17 12:20:51 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmplc571ci5
09/17 12:23:25 AM: copying /tmp/tmplc571ci5 to cache at ./experiments/pos-ontonotes-RANDOM-only/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/17 12:23:26 AM: creating metadata file for ./experiments/pos-ontonotes-RANDOM-only/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/17 12:23:26 AM: removing temp file /tmp/tmplc571ci5
09/17 12:23:26 AM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./experiments/pos-ontonotes-RANDOM-only/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/17 12:23:30 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp6gzfuavq
09/17 12:23:31 AM: copying /tmp/tmp6gzfuavq to cache at ./experiments/pos-ontonotes-RANDOM-only/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/17 12:23:31 AM: creating metadata file for ./experiments/pos-ontonotes-RANDOM-only/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/17 12:23:31 AM: removing temp file /tmp/tmp6gzfuavq
09/17 12:23:31 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/pos-ontonotes-RANDOM-only/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/17 12:23:31 AM: Initializing parameters
09/17 12:23:31 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/17 12:23:31 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/17 12:23:31 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/17 12:23:31 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/17 12:23:31 AM:    _text_field_embedder.model.pooler.dense.bias
09/17 12:23:31 AM:    _text_field_embedder.model.pooler.dense.weight
09/17 12:23:31 AM: 	Task 'edges-pos-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-pos-ontonotes"
}
09/17 12:23:36 AM: Model specification:
09/17 12:23:36 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-pos-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=48, bias=True)
    )
  )
)
09/17 12:23:36 AM: Model parameters:
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:36 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:36 AM: 	edges-pos-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/17 12:23:36 AM: 	edges-pos-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/17 12:23:36 AM: 	edges-pos-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 24576 with torch.Size([48, 512])
09/17 12:23:36 AM: 	edges-pos-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 48 with torch.Size([48])
09/17 12:23:36 AM: Total number of parameters: 109703728 (1.09704e+08)
09/17 12:23:36 AM: Number of trainable parameters: 221488 (221488)
09/17 12:23:36 AM: Finished building model in 175.483s
09/17 12:23:36 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-pos-ontonotes 

09/17 12:24:51 AM: patience = 9
09/17 12:24:51 AM: val_interval = 1000
09/17 12:24:51 AM: max_vals = 250
09/17 12:24:51 AM: cuda_device = 0
09/17 12:24:51 AM: grad_norm = 5.0
09/17 12:24:51 AM: grad_clipping = None
09/17 12:24:51 AM: lr_decay = 0.99
09/17 12:24:51 AM: min_lr = 1e-06
09/17 12:24:51 AM: keep_all_checkpoints = 0
09/17 12:24:51 AM: val_data_limit = 5000
09/17 12:24:51 AM: max_epochs = -1
09/17 12:24:51 AM: dec_val_scale = 250
09/17 12:24:51 AM: training_data_fraction = 1
09/17 12:24:51 AM: type = adam
09/17 12:24:51 AM: parameter_groups = None
09/17 12:24:51 AM: Number of trainable parameters: 221488
09/17 12:24:51 AM: infer_type_and_cast = True
09/17 12:24:51 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/17 12:24:51 AM: CURRENTLY DEFINED PARAMETERS: 
09/17 12:24:51 AM: lr = 0.0001
09/17 12:24:51 AM: amsgrad = True
09/17 12:24:51 AM: type = reduce_on_plateau
09/17 12:24:51 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/17 12:24:51 AM: CURRENTLY DEFINED PARAMETERS: 
09/17 12:24:51 AM: mode = max
09/17 12:24:51 AM: factor = 0.5
09/17 12:24:51 AM: patience = 3
09/17 12:24:51 AM: threshold = 0.0001
09/17 12:24:51 AM: threshold_mode = abs
09/17 12:24:51 AM: verbose = True
09/17 12:24:51 AM: type = adam
09/17 12:24:51 AM: parameter_groups = None
09/17 12:24:51 AM: Number of trainable parameters: 221488
09/17 12:24:51 AM: infer_type_and_cast = True
09/17 12:24:51 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/17 12:24:51 AM: CURRENTLY DEFINED PARAMETERS: 
09/17 12:24:51 AM: lr = 0.0001
09/17 12:24:51 AM: amsgrad = True
09/17 12:24:51 AM: type = reduce_on_plateau
09/17 12:24:51 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/17 12:24:51 AM: CURRENTLY DEFINED PARAMETERS: 
09/17 12:24:51 AM: mode = max
09/17 12:24:51 AM: factor = 0.5
09/17 12:24:51 AM: patience = 3
09/17 12:24:51 AM: threshold = 0.0001
09/17 12:24:51 AM: threshold_mode = abs
09/17 12:24:51 AM: verbose = True
09/17 12:24:51 AM: Starting training without restoring from a checkpoint.
09/17 12:24:51 AM: Training examples per task, before any subsampling: {'edges-pos-ontonotes': 110514}
09/17 12:24:51 AM: Beginning training with stopping criteria based on metric: edges-pos-ontonotes_f1
09/17 12:25:01 AM: Update 62: task edges-pos-ontonotes, batch 62 (62): mcc: 0.0798, acc: 0.1059, precision: 0.0362, recall: 0.6171, f1: 0.0684, edges-pos-ontonotes_loss: 0.5710
09/17 12:25:11 AM: Update 140: task edges-pos-ontonotes, batch 140 (140): mcc: 0.0860, acc: 0.1658, precision: 0.0413, recall: 0.5247, f1: 0.0766, edges-pos-ontonotes_loss: 0.4631
09/17 12:25:21 AM: Update 219: task edges-pos-ontonotes, batch 219 (219): mcc: 0.0930, acc: 0.2004, precision: 0.0457, recall: 0.4869, f1: 0.0835, edges-pos-ontonotes_loss: 0.4009
09/17 12:25:32 AM: Update 314: task edges-pos-ontonotes, batch 314 (314): mcc: 0.1065, acc: 0.2412, precision: 0.0519, recall: 0.4819, f1: 0.0937, edges-pos-ontonotes_loss: 0.3569
09/17 12:25:42 AM: Update 393: task edges-pos-ontonotes, batch 393 (393): mcc: 0.1168, acc: 0.2695, precision: 0.0566, recall: 0.4858, f1: 0.1013, edges-pos-ontonotes_loss: 0.3422
09/17 12:25:52 AM: Update 476: task edges-pos-ontonotes, batch 476 (476): mcc: 0.1257, acc: 0.2889, precision: 0.0611, recall: 0.4861, f1: 0.1086, edges-pos-ontonotes_loss: 0.3265
09/17 12:26:02 AM: Update 559: task edges-pos-ontonotes, batch 559 (559): mcc: 0.1344, acc: 0.3046, precision: 0.0659, recall: 0.4859, f1: 0.1160, edges-pos-ontonotes_loss: 0.3122
09/17 12:26:12 AM: Update 627: task edges-pos-ontonotes, batch 627 (627): mcc: 0.1411, acc: 0.3154, precision: 0.0698, recall: 0.4853, f1: 0.1220, edges-pos-ontonotes_loss: 0.2996
09/17 12:26:22 AM: Update 688: task edges-pos-ontonotes, batch 688 (688): mcc: 0.1462, acc: 0.3207, precision: 0.0734, recall: 0.4801, f1: 0.1274, edges-pos-ontonotes_loss: 0.2922
09/17 12:26:32 AM: Update 756: task edges-pos-ontonotes, batch 756 (756): mcc: 0.1523, acc: 0.3263, precision: 0.0779, recall: 0.4744, f1: 0.1338, edges-pos-ontonotes_loss: 0.2821
09/17 12:26:43 AM: Update 826: task edges-pos-ontonotes, batch 826 (826): mcc: 0.1588, acc: 0.3316, precision: 0.0829, recall: 0.4686, f1: 0.1409, edges-pos-ontonotes_loss: 0.2715
09/17 12:26:53 AM: Update 901: task edges-pos-ontonotes, batch 901 (901): mcc: 0.1659, acc: 0.3365, precision: 0.0886, recall: 0.4628, f1: 0.1488, edges-pos-ontonotes_loss: 0.2599
09/17 12:27:03 AM: Update 953: task edges-pos-ontonotes, batch 953 (953): mcc: 0.1713, acc: 0.3396, precision: 0.0933, recall: 0.4580, f1: 0.1551, edges-pos-ontonotes_loss: 0.2519
09/17 12:27:10 AM: ***** Step 1000 / Validation 1 *****
09/17 12:27:10 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 12:27:10 AM: Validating...
09/17 12:27:13 AM: Evaluate: task edges-pos-ontonotes, batch 29 (157): mcc: 0.5558, acc: 0.4084, precision: 0.7671, recall: 0.4120, f1: 0.5361, edges-pos-ontonotes_loss: 0.0933
09/17 12:27:23 AM: Evaluate: task edges-pos-ontonotes, batch 113 (157): mcc: 0.5797, acc: 0.4249, precision: 0.8020, recall: 0.4277, f1: 0.5579, edges-pos-ontonotes_loss: 0.0892
09/17 12:27:30 AM: Best result seen so far for edges-pos-ontonotes.
09/17 12:27:30 AM: Best result seen so far for micro.
09/17 12:27:30 AM: Best result seen so far for macro.
09/17 12:27:30 AM: Updating LR scheduler:
09/17 12:27:30 AM: 	Best result seen so far for macro_avg: 0.542
09/17 12:27:30 AM: 	# validation passes without improvement: 0
09/17 12:27:30 AM: edges-pos-ontonotes_loss: training: 0.244944 validation: 0.090498
09/17 12:27:30 AM: macro_avg: validation: 0.541720
09/17 12:27:30 AM: micro_avg: validation: 0.000000
09/17 12:27:30 AM: edges-pos-ontonotes_mcc: training: 0.175668 validation: 0.563320
09/17 12:27:30 AM: edges-pos-ontonotes_acc: training: 0.341291 validation: 0.411061
09/17 12:27:30 AM: edges-pos-ontonotes_precision: training: 0.097427 validation: 0.783353
09/17 12:27:30 AM: edges-pos-ontonotes_recall: training: 0.453176 validation: 0.414013
09/17 12:27:30 AM: edges-pos-ontonotes_f1: training: 0.160375 validation: 0.541720
09/17 12:27:30 AM: Global learning rate: 0.0001
09/17 12:27:30 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 12:27:33 AM: Update 1020: task edges-pos-ontonotes, batch 20 (1020): mcc: 0.4963, acc: 0.3712, precision: 0.6720, recall: 0.3778, f1: 0.4837, edges-pos-ontonotes_loss: 0.0968
09/17 12:27:43 AM: Update 1084: task edges-pos-ontonotes, batch 84 (1084): mcc: 0.5254, acc: 0.3774, precision: 0.7383, recall: 0.3834, f1: 0.5047, edges-pos-ontonotes_loss: 0.0901
09/17 12:27:53 AM: Update 1150: task edges-pos-ontonotes, batch 150 (1150): mcc: 0.5480, acc: 0.3838, precision: 0.7894, recall: 0.3890, f1: 0.5211, edges-pos-ontonotes_loss: 0.0852
09/17 12:28:03 AM: Update 1215: task edges-pos-ontonotes, batch 215 (1215): mcc: 0.5601, acc: 0.3870, precision: 0.8178, recall: 0.3916, f1: 0.5296, edges-pos-ontonotes_loss: 0.0813
09/17 12:28:21 AM: Update 1253: task edges-pos-ontonotes, batch 253 (1253): mcc: 0.5662, acc: 0.3893, precision: 0.8308, recall: 0.3936, f1: 0.5341, edges-pos-ontonotes_loss: 0.0792
09/17 12:28:31 AM: Update 1324: task edges-pos-ontonotes, batch 324 (1324): mcc: 0.5756, acc: 0.3942, precision: 0.8482, recall: 0.3981, f1: 0.5418, edges-pos-ontonotes_loss: 0.0758
09/17 12:28:41 AM: Update 1390: task edges-pos-ontonotes, batch 390 (1390): mcc: 0.5829, acc: 0.3983, precision: 0.8607, recall: 0.4020, f1: 0.5481, edges-pos-ontonotes_loss: 0.0730
09/17 12:28:52 AM: Update 1446: task edges-pos-ontonotes, batch 446 (1446): mcc: 0.5888, acc: 0.4023, precision: 0.8693, recall: 0.4058, f1: 0.5534, edges-pos-ontonotes_loss: 0.0709
09/17 12:29:02 AM: Update 1489: task edges-pos-ontonotes, batch 489 (1489): mcc: 0.5927, acc: 0.4053, precision: 0.8747, recall: 0.4087, f1: 0.5571, edges-pos-ontonotes_loss: 0.0695
09/17 12:29:12 AM: Update 1552: task edges-pos-ontonotes, batch 552 (1552): mcc: 0.5976, acc: 0.4092, precision: 0.8806, recall: 0.4125, f1: 0.5619, edges-pos-ontonotes_loss: 0.0675
09/17 12:29:22 AM: Update 1606: task edges-pos-ontonotes, batch 606 (1606): mcc: 0.6011, acc: 0.4121, precision: 0.8849, recall: 0.4153, f1: 0.5653, edges-pos-ontonotes_loss: 0.0661
09/17 12:29:32 AM: Update 1668: task edges-pos-ontonotes, batch 668 (1668): mcc: 0.6056, acc: 0.4161, precision: 0.8894, recall: 0.4192, f1: 0.5699, edges-pos-ontonotes_loss: 0.0645
09/17 12:29:42 AM: Update 1735: task edges-pos-ontonotes, batch 735 (1735): mcc: 0.6093, acc: 0.4196, precision: 0.8927, recall: 0.4227, f1: 0.5737, edges-pos-ontonotes_loss: 0.0630
09/17 12:29:52 AM: Update 1804: task edges-pos-ontonotes, batch 804 (1804): mcc: 0.6126, acc: 0.4227, precision: 0.8955, recall: 0.4259, f1: 0.5772, edges-pos-ontonotes_loss: 0.0616
09/17 12:30:02 AM: Update 1870: task edges-pos-ontonotes, batch 870 (1870): mcc: 0.6158, acc: 0.4260, precision: 0.8979, recall: 0.4291, f1: 0.5807, edges-pos-ontonotes_loss: 0.0604
09/17 12:30:12 AM: Update 1908: task edges-pos-ontonotes, batch 908 (1908): mcc: 0.6171, acc: 0.4274, precision: 0.8987, recall: 0.4305, f1: 0.5822, edges-pos-ontonotes_loss: 0.0598
09/17 12:30:22 AM: Update 1966: task edges-pos-ontonotes, batch 966 (1966): mcc: 0.6195, acc: 0.4298, precision: 0.9001, recall: 0.4331, f1: 0.5848, edges-pos-ontonotes_loss: 0.0587
09/17 12:30:26 AM: ***** Step 2000 / Validation 2 *****
09/17 12:30:26 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 12:30:26 AM: Validating...
09/17 12:30:32 AM: Evaluate: task edges-pos-ontonotes, batch 62 (157): mcc: 0.6039, acc: 0.4373, precision: 0.8490, recall: 0.4373, f1: 0.5773, edges-pos-ontonotes_loss: 0.0451
09/17 12:30:42 AM: Evaluate: task edges-pos-ontonotes, batch 134 (157): mcc: 0.6350, acc: 0.4502, precision: 0.9090, recall: 0.4502, f1: 0.6022, edges-pos-ontonotes_loss: 0.0439
09/17 12:30:46 AM: Best result seen so far for edges-pos-ontonotes.
09/17 12:30:46 AM: Best result seen so far for macro.
09/17 12:30:46 AM: Updating LR scheduler:
09/17 12:30:46 AM: 	Best result seen so far for macro_avg: 0.605
09/17 12:30:46 AM: 	# validation passes without improvement: 0
09/17 12:30:46 AM: edges-pos-ontonotes_loss: training: 0.058022 validation: 0.043697
09/17 12:30:46 AM: macro_avg: validation: 0.604830
09/17 12:30:46 AM: micro_avg: validation: 0.000000
09/17 12:30:46 AM: edges-pos-ontonotes_mcc: training: 0.620920 validation: 0.638147
09/17 12:30:46 AM: edges-pos-ontonotes_acc: training: 0.431252 validation: 0.451718
09/17 12:30:46 AM: edges-pos-ontonotes_precision: training: 0.900921 validation: 0.914742
09/17 12:30:46 AM: edges-pos-ontonotes_recall: training: 0.434685 validation: 0.451771
09/17 12:30:46 AM: edges-pos-ontonotes_f1: training: 0.586426 validation: 0.604830
09/17 12:30:46 AM: Global learning rate: 0.0001
09/17 12:30:46 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 12:30:52 AM: Update 2058: task edges-pos-ontonotes, batch 58 (2058): mcc: 0.6800, acc: 0.4959, precision: 0.9311, recall: 0.5031, f1: 0.6532, edges-pos-ontonotes_loss: 0.0392
09/17 12:31:02 AM: Update 2135: task edges-pos-ontonotes, batch 135 (2135): mcc: 0.6799, acc: 0.4956, precision: 0.9319, recall: 0.5025, f1: 0.6529, edges-pos-ontonotes_loss: 0.0386
09/17 12:31:12 AM: Update 2210: task edges-pos-ontonotes, batch 210 (2210): mcc: 0.6864, acc: 0.5048, precision: 0.9320, recall: 0.5120, f1: 0.6609, edges-pos-ontonotes_loss: 0.0376
09/17 12:31:22 AM: Update 2321: task edges-pos-ontonotes, batch 321 (2321): mcc: 0.7068, acc: 0.5333, precision: 0.9339, recall: 0.5413, f1: 0.6853, edges-pos-ontonotes_loss: 0.0355
09/17 12:31:32 AM: Update 2433: task edges-pos-ontonotes, batch 433 (2433): mcc: 0.7210, acc: 0.5538, precision: 0.9345, recall: 0.5626, f1: 0.7024, edges-pos-ontonotes_loss: 0.0339
09/17 12:31:42 AM: Update 2526: task edges-pos-ontonotes, batch 526 (2526): mcc: 0.7288, acc: 0.5664, precision: 0.9328, recall: 0.5758, f1: 0.7120, edges-pos-ontonotes_loss: 0.0331
09/17 12:31:52 AM: Update 2658: task edges-pos-ontonotes, batch 658 (2658): mcc: 0.7321, acc: 0.5729, precision: 0.9296, recall: 0.5830, f1: 0.7166, edges-pos-ontonotes_loss: 0.0329
09/17 12:32:03 AM: Update 2780: task edges-pos-ontonotes, batch 780 (2780): mcc: 0.7365, acc: 0.5806, precision: 0.9280, recall: 0.5911, f1: 0.7222, edges-pos-ontonotes_loss: 0.0320
09/17 12:32:13 AM: Update 2908: task edges-pos-ontonotes, batch 908 (2908): mcc: 0.7381, acc: 0.5847, precision: 0.9253, recall: 0.5952, f1: 0.7244, edges-pos-ontonotes_loss: 0.0314
09/17 12:32:17 AM: ***** Step 3000 / Validation 3 *****
09/17 12:32:17 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 12:32:17 AM: Validating...
09/17 12:32:23 AM: Evaluate: task edges-pos-ontonotes, batch 55 (157): mcc: 0.6784, acc: 0.5217, precision: 0.8937, recall: 0.5222, f1: 0.6592, edges-pos-ontonotes_loss: 0.0377
09/17 12:32:33 AM: Evaluate: task edges-pos-ontonotes, batch 131 (157): mcc: 0.6739, acc: 0.5137, precision: 0.8957, recall: 0.5142, f1: 0.6533, edges-pos-ontonotes_loss: 0.0385
09/17 12:32:37 AM: Best result seen so far for edges-pos-ontonotes.
09/17 12:32:37 AM: Best result seen so far for macro.
09/17 12:32:37 AM: Updating LR scheduler:
09/17 12:32:37 AM: 	Best result seen so far for macro_avg: 0.647
09/17 12:32:37 AM: 	# validation passes without improvement: 0
09/17 12:32:37 AM: edges-pos-ontonotes_loss: training: 0.030874 validation: 0.039205
09/17 12:32:37 AM: macro_avg: validation: 0.647036
09/17 12:32:37 AM: micro_avg: validation: 0.000000
09/17 12:32:37 AM: edges-pos-ontonotes_mcc: training: 0.739868 validation: 0.668122
09/17 12:32:37 AM: edges-pos-ontonotes_acc: training: 0.588355 validation: 0.507095
09/17 12:32:37 AM: edges-pos-ontonotes_precision: training: 0.924459 validation: 0.892015
09/17 12:32:37 AM: edges-pos-ontonotes_recall: training: 0.598655 validation: 0.507625
09/17 12:32:37 AM: edges-pos-ontonotes_f1: training: 0.726711 validation: 0.647036
09/17 12:32:37 AM: Global learning rate: 0.0001
09/17 12:32:37 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 12:32:43 AM: Update 3104: task edges-pos-ontonotes, batch 104 (3104): mcc: 0.7620, acc: 0.6439, precision: 0.8993, recall: 0.6525, f1: 0.7562, edges-pos-ontonotes_loss: 0.0255
09/17 12:32:53 AM: Update 3176: task edges-pos-ontonotes, batch 176 (3176): mcc: 0.7167, acc: 0.5782, precision: 0.8876, recall: 0.5860, f1: 0.7060, edges-pos-ontonotes_loss: 0.0294
09/17 12:33:03 AM: Update 3237: task edges-pos-ontonotes, batch 237 (3237): mcc: 0.6978, acc: 0.5509, precision: 0.8838, recall: 0.5584, f1: 0.6844, edges-pos-ontonotes_loss: 0.0324
09/17 12:33:13 AM: Update 3308: task edges-pos-ontonotes, batch 308 (3308): mcc: 0.6926, acc: 0.5419, precision: 0.8853, recall: 0.5492, f1: 0.6779, edges-pos-ontonotes_loss: 0.0340
09/17 12:33:23 AM: Update 3388: task edges-pos-ontonotes, batch 388 (3388): mcc: 0.6908, acc: 0.5381, precision: 0.8872, recall: 0.5453, f1: 0.6754, edges-pos-ontonotes_loss: 0.0350
09/17 12:33:44 AM: Update 3461: task edges-pos-ontonotes, batch 461 (3461): mcc: 0.6895, acc: 0.5359, precision: 0.8876, recall: 0.5429, f1: 0.6737, edges-pos-ontonotes_loss: 0.0355
09/17 12:33:54 AM: Update 3572: task edges-pos-ontonotes, batch 572 (3572): mcc: 0.6954, acc: 0.5441, precision: 0.8895, recall: 0.5510, f1: 0.6805, edges-pos-ontonotes_loss: 0.0346
09/17 12:34:04 AM: Update 3684: task edges-pos-ontonotes, batch 684 (3684): mcc: 0.7005, acc: 0.5511, precision: 0.8910, recall: 0.5580, f1: 0.6862, edges-pos-ontonotes_loss: 0.0337
09/17 12:34:14 AM: Update 3774: task edges-pos-ontonotes, batch 774 (3774): mcc: 0.7033, acc: 0.5552, precision: 0.8914, recall: 0.5622, f1: 0.6895, edges-pos-ontonotes_loss: 0.0331
09/17 12:34:24 AM: Update 3857: task edges-pos-ontonotes, batch 857 (3857): mcc: 0.7034, acc: 0.5551, precision: 0.8915, recall: 0.5623, f1: 0.6896, edges-pos-ontonotes_loss: 0.0332
09/17 12:34:34 AM: Update 3944: task edges-pos-ontonotes, batch 944 (3944): mcc: 0.7040, acc: 0.5555, precision: 0.8919, recall: 0.5629, f1: 0.6902, edges-pos-ontonotes_loss: 0.0331
09/17 12:34:39 AM: ***** Step 4000 / Validation 4 *****
09/17 12:34:39 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 12:34:39 AM: Validating...
09/17 12:34:44 AM: Evaluate: task edges-pos-ontonotes, batch 46 (157): mcc: 0.7298, acc: 0.5948, precision: 0.9054, recall: 0.5952, f1: 0.7182, edges-pos-ontonotes_loss: 0.0316
09/17 12:34:54 AM: Evaluate: task edges-pos-ontonotes, batch 125 (157): mcc: 0.7112, acc: 0.5677, precision: 0.8974, recall: 0.5707, f1: 0.6977, edges-pos-ontonotes_loss: 0.0323
09/17 12:34:59 AM: Best result seen so far for edges-pos-ontonotes.
09/17 12:34:59 AM: Best result seen so far for macro.
09/17 12:34:59 AM: Updating LR scheduler:
09/17 12:34:59 AM: 	Best result seen so far for macro_avg: 0.685
09/17 12:34:59 AM: 	# validation passes without improvement: 0
09/17 12:34:59 AM: edges-pos-ontonotes_loss: training: 0.033064 validation: 0.033273
09/17 12:34:59 AM: macro_avg: validation: 0.684764
09/17 12:34:59 AM: micro_avg: validation: 0.000000
09/17 12:34:59 AM: edges-pos-ontonotes_mcc: training: 0.704379 validation: 0.699705
09/17 12:34:59 AM: edges-pos-ontonotes_acc: training: 0.555861 validation: 0.551986
09/17 12:34:59 AM: edges-pos-ontonotes_precision: training: 0.892111 validation: 0.893832
09/17 12:34:59 AM: edges-pos-ontonotes_recall: training: 0.563408 validation: 0.554959
09/17 12:34:59 AM: edges-pos-ontonotes_f1: training: 0.690644 validation: 0.684764
09/17 12:34:59 AM: Global learning rate: 0.0001
09/17 12:34:59 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 12:35:04 AM: Update 4044: task edges-pos-ontonotes, batch 44 (4044): mcc: 0.7078, acc: 0.5576, precision: 0.8940, recall: 0.5676, f1: 0.6943, edges-pos-ontonotes_loss: 0.0333
09/17 12:35:14 AM: Update 4102: task edges-pos-ontonotes, batch 102 (4102): mcc: 0.7002, acc: 0.5480, precision: 0.8889, recall: 0.5588, f1: 0.6862, edges-pos-ontonotes_loss: 0.0333
09/17 12:35:24 AM: Update 4172: task edges-pos-ontonotes, batch 172 (4172): mcc: 0.6913, acc: 0.5376, precision: 0.8853, recall: 0.5473, f1: 0.6764, edges-pos-ontonotes_loss: 0.0350
09/17 12:35:34 AM: Update 4241: task edges-pos-ontonotes, batch 241 (4241): mcc: 0.6895, acc: 0.5353, precision: 0.8843, recall: 0.5450, f1: 0.6744, edges-pos-ontonotes_loss: 0.0353
09/17 12:35:44 AM: Update 4310: task edges-pos-ontonotes, batch 310 (4310): mcc: 0.6892, acc: 0.5350, precision: 0.8839, recall: 0.5448, f1: 0.6741, edges-pos-ontonotes_loss: 0.0356
09/17 12:35:54 AM: Update 4378: task edges-pos-ontonotes, batch 378 (4378): mcc: 0.6895, acc: 0.5358, precision: 0.8830, recall: 0.5459, f1: 0.6747, edges-pos-ontonotes_loss: 0.0356
09/17 12:36:04 AM: Update 4430: task edges-pos-ontonotes, batch 430 (4430): mcc: 0.6885, acc: 0.5348, precision: 0.8827, recall: 0.5446, f1: 0.6736, edges-pos-ontonotes_loss: 0.0357
09/17 12:36:14 AM: Update 4498: task edges-pos-ontonotes, batch 498 (4498): mcc: 0.6884, acc: 0.5343, precision: 0.8835, recall: 0.5438, f1: 0.6732, edges-pos-ontonotes_loss: 0.0357
09/17 12:36:24 AM: Update 4560: task edges-pos-ontonotes, batch 560 (4560): mcc: 0.6878, acc: 0.5335, precision: 0.8839, recall: 0.5427, f1: 0.6725, edges-pos-ontonotes_loss: 0.0357
09/17 12:36:34 AM: Update 4618: task edges-pos-ontonotes, batch 618 (4618): mcc: 0.6880, acc: 0.5336, precision: 0.8845, recall: 0.5426, f1: 0.6726, edges-pos-ontonotes_loss: 0.0357
09/17 12:36:45 AM: Update 4661: task edges-pos-ontonotes, batch 661 (4661): mcc: 0.6885, acc: 0.5339, precision: 0.8852, recall: 0.5429, f1: 0.6730, edges-pos-ontonotes_loss: 0.0357
09/17 12:36:56 AM: Update 4713: task edges-pos-ontonotes, batch 713 (4713): mcc: 0.6885, acc: 0.5338, precision: 0.8854, recall: 0.5428, f1: 0.6730, edges-pos-ontonotes_loss: 0.0356
09/17 12:37:06 AM: Update 4760: task edges-pos-ontonotes, batch 760 (4760): mcc: 0.6889, acc: 0.5342, precision: 0.8859, recall: 0.5431, f1: 0.6733, edges-pos-ontonotes_loss: 0.0356
09/17 12:37:16 AM: Update 4822: task edges-pos-ontonotes, batch 822 (4822): mcc: 0.6897, acc: 0.5352, precision: 0.8867, recall: 0.5439, f1: 0.6742, edges-pos-ontonotes_loss: 0.0355
09/17 12:37:26 AM: Update 4870: task edges-pos-ontonotes, batch 870 (4870): mcc: 0.6903, acc: 0.5359, precision: 0.8871, recall: 0.5445, f1: 0.6748, edges-pos-ontonotes_loss: 0.0354
09/17 12:37:36 AM: Update 4919: task edges-pos-ontonotes, batch 919 (4919): mcc: 0.6908, acc: 0.5364, precision: 0.8876, recall: 0.5450, f1: 0.6753, edges-pos-ontonotes_loss: 0.0354
09/17 12:37:46 AM: Update 4966: task edges-pos-ontonotes, batch 966 (4966): mcc: 0.6914, acc: 0.5370, precision: 0.8881, recall: 0.5455, f1: 0.6759, edges-pos-ontonotes_loss: 0.0353
09/17 12:37:55 AM: ***** Step 5000 / Validation 5 *****
09/17 12:37:55 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 12:37:55 AM: Validating...
09/17 12:37:56 AM: Evaluate: task edges-pos-ontonotes, batch 10 (157): mcc: 0.7083, acc: 0.5570, precision: 0.9112, recall: 0.5574, f1: 0.6917, edges-pos-ontonotes_loss: 0.0332
09/17 12:38:07 AM: Evaluate: task edges-pos-ontonotes, batch 78 (157): mcc: 0.7304, acc: 0.5977, precision: 0.9025, recall: 0.5982, f1: 0.7195, edges-pos-ontonotes_loss: 0.0315
09/17 12:38:17 AM: Evaluate: task edges-pos-ontonotes, batch 142 (157): mcc: 0.7135, acc: 0.5689, precision: 0.9006, recall: 0.5723, f1: 0.6999, edges-pos-ontonotes_loss: 0.0321
09/17 12:38:19 AM: Best result seen so far for edges-pos-ontonotes.
09/17 12:38:19 AM: Best result seen so far for macro.
09/17 12:38:19 AM: Updating LR scheduler:
09/17 12:38:19 AM: 	Best result seen so far for macro_avg: 0.699
09/17 12:38:19 AM: 	# validation passes without improvement: 0
09/17 12:38:19 AM: edges-pos-ontonotes_loss: training: 0.035307 validation: 0.032151
09/17 12:38:19 AM: macro_avg: validation: 0.699025
09/17 12:38:19 AM: micro_avg: validation: 0.000000
09/17 12:38:19 AM: edges-pos-ontonotes_mcc: training: 0.691654 validation: 0.712874
09/17 12:38:19 AM: edges-pos-ontonotes_acc: training: 0.537347 validation: 0.567902
09/17 12:38:19 AM: edges-pos-ontonotes_precision: training: 0.888386 validation: 0.901283
09/17 12:38:19 AM: edges-pos-ontonotes_recall: training: 0.545820 validation: 0.570907
09/17 12:38:19 AM: edges-pos-ontonotes_f1: training: 0.676192 validation: 0.699025
09/17 12:38:19 AM: Global learning rate: 0.0001
09/17 12:38:19 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 12:38:35 AM: Update 5026: task edges-pos-ontonotes, batch 26 (5026): mcc: 0.7112, acc: 0.5591, precision: 0.9029, recall: 0.5673, f1: 0.6968, edges-pos-ontonotes_loss: 0.0330
09/17 12:38:45 AM: Update 5076: task edges-pos-ontonotes, batch 76 (5076): mcc: 0.7038, acc: 0.5523, precision: 0.8960, recall: 0.5600, f1: 0.6893, edges-pos-ontonotes_loss: 0.0340
09/17 12:38:55 AM: Update 5136: task edges-pos-ontonotes, batch 136 (5136): mcc: 0.7027, acc: 0.5514, precision: 0.8951, recall: 0.5589, f1: 0.6881, edges-pos-ontonotes_loss: 0.0340
09/17 12:39:05 AM: Update 5200: task edges-pos-ontonotes, batch 200 (5200): mcc: 0.7033, acc: 0.5518, precision: 0.8956, recall: 0.5594, f1: 0.6887, edges-pos-ontonotes_loss: 0.0338
09/17 12:39:15 AM: Update 5265: task edges-pos-ontonotes, batch 265 (5265): mcc: 0.7035, acc: 0.5520, precision: 0.8961, recall: 0.5594, f1: 0.6888, edges-pos-ontonotes_loss: 0.0338
09/17 12:39:25 AM: Update 5326: task edges-pos-ontonotes, batch 326 (5326): mcc: 0.7038, acc: 0.5525, precision: 0.8958, recall: 0.5602, f1: 0.6893, edges-pos-ontonotes_loss: 0.0337
09/17 12:39:35 AM: Update 5379: task edges-pos-ontonotes, batch 379 (5379): mcc: 0.7040, acc: 0.5536, precision: 0.8935, recall: 0.5620, f1: 0.6900, edges-pos-ontonotes_loss: 0.0334
09/17 12:39:46 AM: Update 5461: task edges-pos-ontonotes, batch 461 (5461): mcc: 0.7077, acc: 0.5579, precision: 0.8950, recall: 0.5668, f1: 0.6941, edges-pos-ontonotes_loss: 0.0326
09/17 12:39:56 AM: Update 5553: task edges-pos-ontonotes, batch 553 (5553): mcc: 0.7121, acc: 0.5633, precision: 0.8968, recall: 0.5726, f1: 0.6989, edges-pos-ontonotes_loss: 0.0317
09/17 12:40:06 AM: Update 5627: task edges-pos-ontonotes, batch 627 (5627): mcc: 0.7132, acc: 0.5642, precision: 0.8972, recall: 0.5740, f1: 0.7001, edges-pos-ontonotes_loss: 0.0314
09/17 12:40:16 AM: Update 5709: task edges-pos-ontonotes, batch 709 (5709): mcc: 0.7181, acc: 0.5709, precision: 0.8984, recall: 0.5812, f1: 0.7058, edges-pos-ontonotes_loss: 0.0307
09/17 12:40:26 AM: Update 5823: task edges-pos-ontonotes, batch 823 (5823): mcc: 0.7267, acc: 0.5825, precision: 0.9008, recall: 0.5934, f1: 0.7154, edges-pos-ontonotes_loss: 0.0295
09/17 12:40:36 AM: Update 5932: task edges-pos-ontonotes, batch 932 (5932): mcc: 0.7343, acc: 0.5930, precision: 0.9026, recall: 0.6044, f1: 0.7240, edges-pos-ontonotes_loss: 0.0286
09/17 12:40:43 AM: ***** Step 6000 / Validation 6 *****
09/17 12:40:43 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 12:40:43 AM: Validating...
09/17 12:40:46 AM: Evaluate: task edges-pos-ontonotes, batch 30 (157): mcc: 0.7115, acc: 0.5598, precision: 0.9132, recall: 0.5611, f1: 0.6951, edges-pos-ontonotes_loss: 0.0323
09/17 12:40:56 AM: Evaluate: task edges-pos-ontonotes, batch 114 (157): mcc: 0.7117, acc: 0.5586, precision: 0.9131, recall: 0.5616, f1: 0.6954, edges-pos-ontonotes_loss: 0.0313
09/17 12:41:03 AM: Updating LR scheduler:
09/17 12:41:03 AM: 	Best result seen so far for macro_avg: 0.699
09/17 12:41:03 AM: 	# validation passes without improvement: 1
09/17 12:41:03 AM: edges-pos-ontonotes_loss: training: 0.028225 validation: 0.032213
09/17 12:41:03 AM: macro_avg: validation: 0.682908
09/17 12:41:03 AM: micro_avg: validation: 0.000000
09/17 12:41:03 AM: edges-pos-ontonotes_mcc: training: 0.737467 validation: 0.701025
09/17 12:41:03 AM: edges-pos-ontonotes_acc: training: 0.597521 validation: 0.541901
09/17 12:41:03 AM: edges-pos-ontonotes_precision: training: 0.903064 validation: 0.911582
09/17 12:41:03 AM: edges-pos-ontonotes_recall: training: 0.609186 validation: 0.545954
09/17 12:41:03 AM: edges-pos-ontonotes_f1: training: 0.727570 validation: 0.682908
09/17 12:41:03 AM: Global learning rate: 0.0001
09/17 12:41:03 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 12:41:06 AM: Update 6045: task edges-pos-ontonotes, batch 45 (6045): mcc: 0.7879, acc: 0.6757, precision: 0.9037, recall: 0.6934, f1: 0.7847, edges-pos-ontonotes_loss: 0.0239
09/17 12:41:16 AM: Update 6179: task edges-pos-ontonotes, batch 179 (6179): mcc: 0.7963, acc: 0.6892, precision: 0.9050, recall: 0.7071, f1: 0.7939, edges-pos-ontonotes_loss: 0.0221
09/17 12:41:27 AM: Update 6278: task edges-pos-ontonotes, batch 278 (6278): mcc: 0.7991, acc: 0.6935, precision: 0.9053, recall: 0.7116, f1: 0.7969, edges-pos-ontonotes_loss: 0.0218
09/17 12:41:38 AM: Update 6435: task edges-pos-ontonotes, batch 435 (6435): mcc: 0.7925, acc: 0.6880, precision: 0.8998, recall: 0.7046, f1: 0.7903, edges-pos-ontonotes_loss: 0.0219
09/17 12:41:49 AM: Update 6591: task edges-pos-ontonotes, batch 591 (6591): mcc: 0.7898, acc: 0.6860, precision: 0.8975, recall: 0.7017, f1: 0.7876, edges-pos-ontonotes_loss: 0.0218
09/17 12:41:59 AM: Update 6674: task edges-pos-ontonotes, batch 674 (6674): mcc: 0.7688, acc: 0.6563, precision: 0.8897, recall: 0.6714, f1: 0.7653, edges-pos-ontonotes_loss: 0.0236
09/17 12:42:09 AM: Update 6736: task edges-pos-ontonotes, batch 736 (6736): mcc: 0.7548, acc: 0.6362, precision: 0.8853, recall: 0.6508, f1: 0.7501, edges-pos-ontonotes_loss: 0.0246
09/17 12:42:19 AM: Update 6805: task edges-pos-ontonotes, batch 805 (6805): mcc: 0.7465, acc: 0.6241, precision: 0.8828, recall: 0.6385, f1: 0.7410, edges-pos-ontonotes_loss: 0.0254
09/17 12:42:29 AM: Update 6874: task edges-pos-ontonotes, batch 874 (6874): mcc: 0.7407, acc: 0.6158, precision: 0.8814, recall: 0.6298, f1: 0.7346, edges-pos-ontonotes_loss: 0.0261
09/17 12:42:39 AM: Update 6945: task edges-pos-ontonotes, batch 945 (6945): mcc: 0.7379, acc: 0.6119, precision: 0.8809, recall: 0.6255, f1: 0.7316, edges-pos-ontonotes_loss: 0.0266
09/17 12:42:44 AM: ***** Step 7000 / Validation 7 *****
09/17 12:42:44 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 12:42:44 AM: Validating...
09/17 12:42:49 AM: Evaluate: task edges-pos-ontonotes, batch 48 (157): mcc: 0.7394, acc: 0.6150, precision: 0.8985, recall: 0.6155, f1: 0.7305, edges-pos-ontonotes_loss: 0.0290
09/17 12:42:59 AM: Evaluate: task edges-pos-ontonotes, batch 125 (157): mcc: 0.7176, acc: 0.5806, precision: 0.8931, recall: 0.5837, f1: 0.7060, edges-pos-ontonotes_loss: 0.0301
09/17 12:43:04 AM: Updating LR scheduler:
09/17 12:43:04 AM: 	Best result seen so far for macro_avg: 0.699
09/17 12:43:04 AM: 	# validation passes without improvement: 2
09/17 12:43:04 AM: edges-pos-ontonotes_loss: training: 0.026586 validation: 0.030945
09/17 12:43:04 AM: macro_avg: validation: 0.691767
09/17 12:43:04 AM: micro_avg: validation: 0.000000
09/17 12:43:04 AM: edges-pos-ontonotes_mcc: training: 0.738148 validation: 0.704979
09/17 12:43:04 AM: edges-pos-ontonotes_acc: training: 0.612349 validation: 0.562632
09/17 12:43:04 AM: edges-pos-ontonotes_precision: training: 0.881014 validation: 0.889871
09/17 12:43:04 AM: edges-pos-ontonotes_recall: training: 0.625851 validation: 0.565806
09/17 12:43:04 AM: edges-pos-ontonotes_f1: training: 0.731829 validation: 0.691767
09/17 12:43:04 AM: Global learning rate: 0.0001
09/17 12:43:04 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 12:43:09 AM: Update 7058: task edges-pos-ontonotes, batch 58 (7058): mcc: 0.7529, acc: 0.6352, precision: 0.8865, recall: 0.6466, f1: 0.7478, edges-pos-ontonotes_loss: 0.0255
09/17 12:43:19 AM: Update 7165: task edges-pos-ontonotes, batch 165 (7165): mcc: 0.7478, acc: 0.6276, precision: 0.8844, recall: 0.6396, f1: 0.7423, edges-pos-ontonotes_loss: 0.0260
09/17 12:43:29 AM: Update 7253: task edges-pos-ontonotes, batch 253 (7253): mcc: 0.7445, acc: 0.6224, precision: 0.8842, recall: 0.6342, f1: 0.7386, edges-pos-ontonotes_loss: 0.0262
09/17 12:43:39 AM: Update 7335: task edges-pos-ontonotes, batch 335 (7335): mcc: 0.7384, acc: 0.6127, precision: 0.8838, recall: 0.6243, f1: 0.7317, edges-pos-ontonotes_loss: 0.0271
09/17 12:43:49 AM: Update 7423: task edges-pos-ontonotes, batch 423 (7423): mcc: 0.7342, acc: 0.6058, precision: 0.8828, recall: 0.6180, f1: 0.7270, edges-pos-ontonotes_loss: 0.0276
09/17 12:43:59 AM: Update 7511: task edges-pos-ontonotes, batch 511 (7511): mcc: 0.7325, acc: 0.6025, precision: 0.8828, recall: 0.6152, f1: 0.7251, edges-pos-ontonotes_loss: 0.0279
09/17 12:44:13 AM: Update 7547: task edges-pos-ontonotes, batch 547 (7547): mcc: 0.7313, acc: 0.6010, precision: 0.8821, recall: 0.6137, f1: 0.7239, edges-pos-ontonotes_loss: 0.0280
09/17 12:44:23 AM: Update 7608: task edges-pos-ontonotes, batch 608 (7608): mcc: 0.7240, acc: 0.5915, precision: 0.8778, recall: 0.6047, f1: 0.7161, edges-pos-ontonotes_loss: 0.0286
09/17 12:44:33 AM: Update 7673: task edges-pos-ontonotes, batch 673 (7673): mcc: 0.7203, acc: 0.5866, precision: 0.8758, recall: 0.6000, f1: 0.7121, edges-pos-ontonotes_loss: 0.0291
09/17 12:44:43 AM: Update 7751: task edges-pos-ontonotes, batch 751 (7751): mcc: 0.7182, acc: 0.5839, precision: 0.8747, recall: 0.5973, f1: 0.7099, edges-pos-ontonotes_loss: 0.0296
09/17 12:44:53 AM: Update 7819: task edges-pos-ontonotes, batch 819 (7819): mcc: 0.7167, acc: 0.5816, precision: 0.8743, recall: 0.5951, f1: 0.7082, edges-pos-ontonotes_loss: 0.0299
09/17 12:45:03 AM: Update 7870: task edges-pos-ontonotes, batch 870 (7870): mcc: 0.7154, acc: 0.5798, precision: 0.8740, recall: 0.5932, f1: 0.7067, edges-pos-ontonotes_loss: 0.0301
09/17 12:45:13 AM: Update 7934: task edges-pos-ontonotes, batch 934 (7934): mcc: 0.7135, acc: 0.5770, precision: 0.8738, recall: 0.5902, f1: 0.7045, edges-pos-ontonotes_loss: 0.0303
09/17 12:45:23 AM: Update 7998: task edges-pos-ontonotes, batch 998 (7998): mcc: 0.7123, acc: 0.5753, precision: 0.8740, recall: 0.5882, f1: 0.7032, edges-pos-ontonotes_loss: 0.0305
09/17 12:45:24 AM: ***** Step 8000 / Validation 8 *****
09/17 12:45:24 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 12:45:24 AM: Validating...
09/17 12:45:34 AM: Evaluate: task edges-pos-ontonotes, batch 93 (157): mcc: 0.7413, acc: 0.6172, precision: 0.8993, recall: 0.6181, f1: 0.7326, edges-pos-ontonotes_loss: 0.0286
09/17 12:45:44 AM: Evaluate: task edges-pos-ontonotes, batch 156 (157): mcc: 0.7262, acc: 0.5910, precision: 0.8978, recall: 0.5945, f1: 0.7153, edges-pos-ontonotes_loss: 0.0297
09/17 12:45:44 AM: Best result seen so far for edges-pos-ontonotes.
09/17 12:45:44 AM: Best result seen so far for macro.
09/17 12:45:44 AM: Updating LR scheduler:
09/17 12:45:44 AM: 	Best result seen so far for macro_avg: 0.715
09/17 12:45:44 AM: 	# validation passes without improvement: 0
09/17 12:45:44 AM: edges-pos-ontonotes_loss: training: 0.030546 validation: 0.029694
09/17 12:45:44 AM: macro_avg: validation: 0.715254
09/17 12:45:44 AM: micro_avg: validation: 0.000000
09/17 12:45:44 AM: edges-pos-ontonotes_mcc: training: 0.712331 validation: 0.726130
09/17 12:45:44 AM: edges-pos-ontonotes_acc: training: 0.575252 validation: 0.590844
09/17 12:45:44 AM: edges-pos-ontonotes_precision: training: 0.874057 validation: 0.897745
09/17 12:45:44 AM: edges-pos-ontonotes_recall: training: 0.588169 validation: 0.594421
09/17 12:45:44 AM: edges-pos-ontonotes_f1: training: 0.703165 validation: 0.715254
09/17 12:45:44 AM: Global learning rate: 0.0001
09/17 12:45:44 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 12:45:54 AM: Update 8069: task edges-pos-ontonotes, batch 69 (8069): mcc: 0.7021, acc: 0.5573, precision: 0.8810, recall: 0.5671, f1: 0.6900, edges-pos-ontonotes_loss: 0.0331
09/17 12:46:04 AM: Update 8133: task edges-pos-ontonotes, batch 133 (8133): mcc: 0.7016, acc: 0.5569, precision: 0.8797, recall: 0.5671, f1: 0.6896, edges-pos-ontonotes_loss: 0.0330
09/17 12:46:14 AM: Update 8182: task edges-pos-ontonotes, batch 182 (8182): mcc: 0.7022, acc: 0.5582, precision: 0.8795, recall: 0.5681, f1: 0.6903, edges-pos-ontonotes_loss: 0.0330
09/17 12:46:24 AM: Update 8227: task edges-pos-ontonotes, batch 227 (8227): mcc: 0.7030, acc: 0.5594, precision: 0.8802, recall: 0.5690, f1: 0.6912, edges-pos-ontonotes_loss: 0.0330
09/17 12:46:34 AM: Update 8271: task edges-pos-ontonotes, batch 271 (8271): mcc: 0.7045, acc: 0.5607, precision: 0.8814, recall: 0.5706, f1: 0.6928, edges-pos-ontonotes_loss: 0.0328
09/17 12:46:45 AM: Update 8319: task edges-pos-ontonotes, batch 319 (8319): mcc: 0.7054, acc: 0.5616, precision: 0.8823, recall: 0.5714, f1: 0.6936, edges-pos-ontonotes_loss: 0.0328
09/17 12:46:55 AM: Update 8370: task edges-pos-ontonotes, batch 370 (8370): mcc: 0.7058, acc: 0.5619, precision: 0.8829, recall: 0.5717, f1: 0.6940, edges-pos-ontonotes_loss: 0.0328
09/17 12:47:05 AM: Update 8417: task edges-pos-ontonotes, batch 417 (8417): mcc: 0.7068, acc: 0.5632, precision: 0.8835, recall: 0.5729, f1: 0.6951, edges-pos-ontonotes_loss: 0.0327
09/17 12:47:15 AM: Update 8463: task edges-pos-ontonotes, batch 463 (8463): mcc: 0.7073, acc: 0.5637, precision: 0.8840, recall: 0.5734, f1: 0.6956, edges-pos-ontonotes_loss: 0.0326
09/17 12:47:25 AM: Update 8497: task edges-pos-ontonotes, batch 497 (8497): mcc: 0.7076, acc: 0.5641, precision: 0.8842, recall: 0.5737, f1: 0.6959, edges-pos-ontonotes_loss: 0.0326
09/17 12:47:35 AM: Update 8539: task edges-pos-ontonotes, batch 539 (8539): mcc: 0.7076, acc: 0.5642, precision: 0.8841, recall: 0.5738, f1: 0.6959, edges-pos-ontonotes_loss: 0.0325
09/17 12:47:45 AM: Update 8597: task edges-pos-ontonotes, batch 597 (8597): mcc: 0.7079, acc: 0.5645, precision: 0.8844, recall: 0.5741, f1: 0.6962, edges-pos-ontonotes_loss: 0.0325
09/17 12:47:55 AM: Update 8664: task edges-pos-ontonotes, batch 664 (8664): mcc: 0.7083, acc: 0.5649, precision: 0.8846, recall: 0.5745, f1: 0.6966, edges-pos-ontonotes_loss: 0.0324
09/17 12:48:05 AM: Update 8738: task edges-pos-ontonotes, batch 738 (8738): mcc: 0.7087, acc: 0.5654, precision: 0.8847, recall: 0.5751, f1: 0.6970, edges-pos-ontonotes_loss: 0.0324
09/17 12:48:16 AM: Update 8796: task edges-pos-ontonotes, batch 796 (8796): mcc: 0.7089, acc: 0.5658, precision: 0.8847, recall: 0.5754, f1: 0.6973, edges-pos-ontonotes_loss: 0.0324
09/17 12:48:26 AM: Update 8833: task edges-pos-ontonotes, batch 833 (8833): mcc: 0.7091, acc: 0.5661, precision: 0.8842, recall: 0.5760, f1: 0.6976, edges-pos-ontonotes_loss: 0.0322
09/17 12:48:36 AM: Update 8886: task edges-pos-ontonotes, batch 886 (8886): mcc: 0.7101, acc: 0.5674, precision: 0.8846, recall: 0.5775, f1: 0.6988, edges-pos-ontonotes_loss: 0.0320
09/17 12:48:46 AM: Update 8947: task edges-pos-ontonotes, batch 947 (8947): mcc: 0.7114, acc: 0.5687, precision: 0.8853, recall: 0.5790, f1: 0.7001, edges-pos-ontonotes_loss: 0.0317
09/17 12:48:52 AM: ***** Step 9000 / Validation 9 *****
09/17 12:48:52 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 12:48:52 AM: Validating...
09/17 12:48:56 AM: Evaluate: task edges-pos-ontonotes, batch 37 (157): mcc: 0.7302, acc: 0.5918, precision: 0.9100, recall: 0.5927, f1: 0.7179, edges-pos-ontonotes_loss: 0.0301
09/17 12:49:06 AM: Evaluate: task edges-pos-ontonotes, batch 118 (157): mcc: 0.7268, acc: 0.5849, precision: 0.9122, recall: 0.5859, f1: 0.7135, edges-pos-ontonotes_loss: 0.0294
09/17 12:49:12 AM: Updating LR scheduler:
09/17 12:49:12 AM: 	Best result seen so far for macro_avg: 0.715
09/17 12:49:12 AM: 	# validation passes without improvement: 1
09/17 12:49:12 AM: edges-pos-ontonotes_loss: training: 0.031379 validation: 0.029976
09/17 12:49:12 AM: macro_avg: validation: 0.703779
09/17 12:49:12 AM: micro_avg: validation: 0.000000
09/17 12:49:12 AM: edges-pos-ontonotes_mcc: training: 0.712677 validation: 0.718482
09/17 12:49:12 AM: edges-pos-ontonotes_acc: training: 0.570216 validation: 0.572198
09/17 12:49:12 AM: edges-pos-ontonotes_precision: training: 0.886016 validation: 0.911554
09/17 12:49:12 AM: edges-pos-ontonotes_recall: training: 0.580628 validation: 0.573140
09/17 12:49:12 AM: edges-pos-ontonotes_f1: training: 0.701528 validation: 0.703779
09/17 12:49:12 AM: Global learning rate: 0.0001
09/17 12:49:12 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 12:49:16 AM: Update 9033: task edges-pos-ontonotes, batch 33 (9033): mcc: 0.7492, acc: 0.6145, precision: 0.9019, recall: 0.6292, f1: 0.7413, edges-pos-ontonotes_loss: 0.0261
09/17 12:49:35 AM: Update 9112: task edges-pos-ontonotes, batch 112 (9112): mcc: 0.7440, acc: 0.6077, precision: 0.9006, recall: 0.6217, f1: 0.7356, edges-pos-ontonotes_loss: 0.0260
09/17 12:49:45 AM: Update 9222: task edges-pos-ontonotes, batch 222 (9222): mcc: 0.7702, acc: 0.6448, precision: 0.9079, recall: 0.6600, f1: 0.7644, edges-pos-ontonotes_loss: 0.0239
09/17 12:49:55 AM: Update 9334: task edges-pos-ontonotes, batch 334 (9334): mcc: 0.7844, acc: 0.6661, precision: 0.9107, recall: 0.6820, f1: 0.7799, edges-pos-ontonotes_loss: 0.0229
09/17 12:50:05 AM: Update 9427: task edges-pos-ontonotes, batch 427 (9427): mcc: 0.7916, acc: 0.6772, precision: 0.9114, recall: 0.6939, f1: 0.7879, edges-pos-ontonotes_loss: 0.0222
09/17 12:50:15 AM: Update 9557: task edges-pos-ontonotes, batch 557 (9557): mcc: 0.7932, acc: 0.6808, precision: 0.9095, recall: 0.6981, f1: 0.7899, edges-pos-ontonotes_loss: 0.0221
09/17 12:50:25 AM: Update 9705: task edges-pos-ontonotes, batch 705 (9705): mcc: 0.7964, acc: 0.6867, precision: 0.9088, recall: 0.7043, f1: 0.7936, edges-pos-ontonotes_loss: 0.0216
09/17 12:50:35 AM: Update 9852: task edges-pos-ontonotes, batch 852 (9852): mcc: 0.7953, acc: 0.6868, precision: 0.9062, recall: 0.7044, f1: 0.7927, edges-pos-ontonotes_loss: 0.0216
09/17 12:50:44 AM: ***** Step 10000 / Validation 10 *****
09/17 12:50:44 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 12:50:44 AM: Validating...
09/17 12:50:45 AM: Evaluate: task edges-pos-ontonotes, batch 15 (157): mcc: 0.7205, acc: 0.5909, precision: 0.8833, recall: 0.5952, f1: 0.7112, edges-pos-ontonotes_loss: 0.0320
09/17 12:50:55 AM: Evaluate: task edges-pos-ontonotes, batch 106 (157): mcc: 0.7299, acc: 0.6012, precision: 0.8902, recall: 0.6057, f1: 0.7209, edges-pos-ontonotes_loss: 0.0301
09/17 12:51:03 AM: Updating LR scheduler:
09/17 12:51:03 AM: 	Best result seen so far for macro_avg: 0.715
09/17 12:51:03 AM: 	# validation passes without improvement: 2
09/17 12:51:03 AM: edges-pos-ontonotes_loss: training: 0.021312 validation: 0.031836
09/17 12:51:03 AM: macro_avg: validation: 0.691335
09/17 12:51:03 AM: micro_avg: validation: 0.000000
09/17 12:51:03 AM: edges-pos-ontonotes_mcc: training: 0.795014 validation: 0.703562
09/17 12:51:03 AM: edges-pos-ontonotes_acc: training: 0.688096 validation: 0.564346
09/17 12:51:03 AM: edges-pos-ontonotes_precision: training: 0.904359 validation: 0.883020
09/17 12:51:03 AM: edges-pos-ontonotes_recall: training: 0.705332 validation: 0.568029
09/17 12:51:03 AM: edges-pos-ontonotes_f1: training: 0.792542 validation: 0.691335
09/17 12:51:03 AM: Global learning rate: 0.0001
09/17 12:51:03 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 12:51:05 AM: Update 10024: task edges-pos-ontonotes, batch 24 (10024): mcc: 0.7714, acc: 0.6701, precision: 0.8768, recall: 0.6859, f1: 0.7697, edges-pos-ontonotes_loss: 0.0226
09/17 12:51:15 AM: Update 10085: task edges-pos-ontonotes, batch 85 (10085): mcc: 0.7194, acc: 0.5939, precision: 0.8615, recall: 0.6087, f1: 0.7134, edges-pos-ontonotes_loss: 0.0277
09/17 12:51:25 AM: Update 10159: task edges-pos-ontonotes, batch 159 (10159): mcc: 0.7056, acc: 0.5741, precision: 0.8576, recall: 0.5886, f1: 0.6981, edges-pos-ontonotes_loss: 0.0310
09/17 12:51:35 AM: Update 10227: task edges-pos-ontonotes, batch 227 (10227): mcc: 0.7043, acc: 0.5709, precision: 0.8587, recall: 0.5857, f1: 0.6964, edges-pos-ontonotes_loss: 0.0318
09/17 12:51:46 AM: Update 10281: task edges-pos-ontonotes, batch 281 (10281): mcc: 0.7042, acc: 0.5703, precision: 0.8596, recall: 0.5848, f1: 0.6961, edges-pos-ontonotes_loss: 0.0320
09/17 12:51:56 AM: Update 10339: task edges-pos-ontonotes, batch 339 (10339): mcc: 0.7038, acc: 0.5693, precision: 0.8602, recall: 0.5839, f1: 0.6956, edges-pos-ontonotes_loss: 0.0323
09/17 12:52:06 AM: Update 10406: task edges-pos-ontonotes, batch 406 (10406): mcc: 0.7049, acc: 0.5708, precision: 0.8609, recall: 0.5851, f1: 0.6967, edges-pos-ontonotes_loss: 0.0322
09/17 12:52:16 AM: Update 10494: task edges-pos-ontonotes, batch 494 (10494): mcc: 0.7107, acc: 0.5786, precision: 0.8637, recall: 0.5927, f1: 0.7030, edges-pos-ontonotes_loss: 0.0311
09/17 12:52:26 AM: Update 10573: task edges-pos-ontonotes, batch 573 (10573): mcc: 0.7149, acc: 0.5844, precision: 0.8654, recall: 0.5984, f1: 0.7075, edges-pos-ontonotes_loss: 0.0303
09/17 12:52:36 AM: Update 10648: task edges-pos-ontonotes, batch 648 (10648): mcc: 0.7184, acc: 0.5890, precision: 0.8670, recall: 0.6030, f1: 0.7113, edges-pos-ontonotes_loss: 0.0296
09/17 12:52:46 AM: Update 10712: task edges-pos-ontonotes, batch 712 (10712): mcc: 0.7203, acc: 0.5915, precision: 0.8679, recall: 0.6055, f1: 0.7133, edges-pos-ontonotes_loss: 0.0292
09/17 12:52:56 AM: Update 10765: task edges-pos-ontonotes, batch 765 (10765): mcc: 0.7202, acc: 0.5912, precision: 0.8684, recall: 0.6051, f1: 0.7132, edges-pos-ontonotes_loss: 0.0292
09/17 12:53:06 AM: Update 10826: task edges-pos-ontonotes, batch 826 (10826): mcc: 0.7208, acc: 0.5914, precision: 0.8692, recall: 0.6054, f1: 0.7137, edges-pos-ontonotes_loss: 0.0292
09/17 12:53:16 AM: Update 10887: task edges-pos-ontonotes, batch 887 (10887): mcc: 0.7213, acc: 0.5918, precision: 0.8699, recall: 0.6058, f1: 0.7142, edges-pos-ontonotes_loss: 0.0291
09/17 12:53:27 AM: Update 10945: task edges-pos-ontonotes, batch 945 (10945): mcc: 0.7217, acc: 0.5919, precision: 0.8706, recall: 0.6060, f1: 0.7146, edges-pos-ontonotes_loss: 0.0291
09/17 12:53:35 AM: ***** Step 11000 / Validation 11 *****
09/17 12:53:35 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 12:53:35 AM: Validating...
09/17 12:53:37 AM: Evaluate: task edges-pos-ontonotes, batch 10 (157): mcc: 0.7238, acc: 0.5845, precision: 0.9023, recall: 0.5876, f1: 0.7117, edges-pos-ontonotes_loss: 0.0296
09/17 12:53:47 AM: Evaluate: task edges-pos-ontonotes, batch 78 (157): mcc: 0.7557, acc: 0.6353, precision: 0.9060, recall: 0.6371, f1: 0.7481, edges-pos-ontonotes_loss: 0.0268
09/17 12:53:57 AM: Evaluate: task edges-pos-ontonotes, batch 125 (157): mcc: 0.7332, acc: 0.6028, precision: 0.8966, recall: 0.6067, f1: 0.7237, edges-pos-ontonotes_loss: 0.0280
09/17 12:54:04 AM: Updating LR scheduler:
09/17 12:54:04 AM: 	Best result seen so far for macro_avg: 0.715
09/17 12:54:04 AM: 	# validation passes without improvement: 3
09/17 12:54:04 AM: edges-pos-ontonotes_loss: training: 0.029032 validation: 0.028934
09/17 12:54:04 AM: macro_avg: validation: 0.712214
09/17 12:54:04 AM: micro_avg: validation: 0.000000
09/17 12:54:04 AM: edges-pos-ontonotes_mcc: training: 0.722137 validation: 0.722894
09/17 12:54:04 AM: edges-pos-ontonotes_acc: training: 0.592252 validation: 0.588156
09/17 12:54:04 AM: edges-pos-ontonotes_precision: training: 0.871147 validation: 0.893406
09/17 12:54:04 AM: edges-pos-ontonotes_recall: training: 0.606298 validation: 0.592125
09/17 12:54:04 AM: edges-pos-ontonotes_f1: training: 0.714984 validation: 0.712214
09/17 12:54:04 AM: Global learning rate: 0.0001
09/17 12:54:04 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 12:54:08 AM: Update 11007: task edges-pos-ontonotes, batch 7 (11007): mcc: 0.6955, acc: 0.5625, precision: 0.8460, recall: 0.5801, f1: 0.6883, edges-pos-ontonotes_loss: 0.0286
09/17 12:54:18 AM: Update 11055: task edges-pos-ontonotes, batch 55 (11055): mcc: 0.6956, acc: 0.5574, precision: 0.8523, recall: 0.5758, f1: 0.6873, edges-pos-ontonotes_loss: 0.0327
09/17 12:54:28 AM: Update 11102: task edges-pos-ontonotes, batch 102 (11102): mcc: 0.6982, acc: 0.5604, precision: 0.8565, recall: 0.5773, f1: 0.6897, edges-pos-ontonotes_loss: 0.0330
09/17 12:54:38 AM: Update 11145: task edges-pos-ontonotes, batch 145 (11145): mcc: 0.7000, acc: 0.5622, precision: 0.8591, recall: 0.5783, f1: 0.6913, edges-pos-ontonotes_loss: 0.0328
09/17 12:54:48 AM: Update 11192: task edges-pos-ontonotes, batch 192 (11192): mcc: 0.7009, acc: 0.5636, precision: 0.8598, recall: 0.5793, f1: 0.6922, edges-pos-ontonotes_loss: 0.0327
09/17 12:54:58 AM: Update 11240: task edges-pos-ontonotes, batch 240 (11240): mcc: 0.7011, acc: 0.5640, precision: 0.8599, recall: 0.5797, f1: 0.6925, edges-pos-ontonotes_loss: 0.0328
09/17 12:55:09 AM: Update 11290: task edges-pos-ontonotes, batch 290 (11290): mcc: 0.7018, acc: 0.5648, precision: 0.8603, recall: 0.5805, f1: 0.6933, edges-pos-ontonotes_loss: 0.0326
09/17 12:55:25 AM: Update 11320: task edges-pos-ontonotes, batch 320 (11320): mcc: 0.7022, acc: 0.5651, precision: 0.8607, recall: 0.5807, f1: 0.6936, edges-pos-ontonotes_loss: 0.0327
09/17 12:55:35 AM: Update 11389: task edges-pos-ontonotes, batch 389 (11389): mcc: 0.7017, acc: 0.5639, precision: 0.8625, recall: 0.5787, f1: 0.6927, edges-pos-ontonotes_loss: 0.0327
09/17 12:55:46 AM: Update 11451: task edges-pos-ontonotes, batch 451 (11451): mcc: 0.7014, acc: 0.5632, precision: 0.8638, recall: 0.5775, f1: 0.6922, edges-pos-ontonotes_loss: 0.0328
09/17 12:55:56 AM: Update 11515: task edges-pos-ontonotes, batch 515 (11515): mcc: 0.7018, acc: 0.5631, precision: 0.8652, recall: 0.5771, f1: 0.6923, edges-pos-ontonotes_loss: 0.0327
09/17 12:56:06 AM: Update 11581: task edges-pos-ontonotes, batch 581 (11581): mcc: 0.7022, acc: 0.5633, precision: 0.8665, recall: 0.5769, f1: 0.6927, edges-pos-ontonotes_loss: 0.0327
09/17 12:56:16 AM: Update 11635: task edges-pos-ontonotes, batch 635 (11635): mcc: 0.7029, acc: 0.5640, precision: 0.8673, recall: 0.5774, f1: 0.6933, edges-pos-ontonotes_loss: 0.0326
09/17 12:56:26 AM: Update 11706: task edges-pos-ontonotes, batch 706 (11706): mcc: 0.7038, acc: 0.5649, precision: 0.8686, recall: 0.5780, f1: 0.6941, edges-pos-ontonotes_loss: 0.0325
09/17 12:56:36 AM: Update 11766: task edges-pos-ontonotes, batch 766 (11766): mcc: 0.7046, acc: 0.5656, precision: 0.8698, recall: 0.5785, f1: 0.6948, edges-pos-ontonotes_loss: 0.0325
09/17 12:56:46 AM: Update 11832: task edges-pos-ontonotes, batch 832 (11832): mcc: 0.7053, acc: 0.5663, precision: 0.8708, recall: 0.5789, f1: 0.6955, edges-pos-ontonotes_loss: 0.0324
09/17 12:56:56 AM: Update 11892: task edges-pos-ontonotes, batch 892 (11892): mcc: 0.7059, acc: 0.5668, precision: 0.8716, recall: 0.5794, f1: 0.6961, edges-pos-ontonotes_loss: 0.0323
09/17 12:57:07 AM: Update 11946: task edges-pos-ontonotes, batch 946 (11946): mcc: 0.7063, acc: 0.5673, precision: 0.8720, recall: 0.5797, f1: 0.6964, edges-pos-ontonotes_loss: 0.0323
09/17 12:57:15 AM: ***** Step 12000 / Validation 12 *****
09/17 12:57:15 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 12:57:15 AM: Validating...
09/17 12:57:17 AM: Evaluate: task edges-pos-ontonotes, batch 11 (157): mcc: 0.7316, acc: 0.5986, precision: 0.9002, recall: 0.6015, f1: 0.7212, edges-pos-ontonotes_loss: 0.0297
09/17 12:57:27 AM: Evaluate: task edges-pos-ontonotes, batch 104 (157): mcc: 0.7380, acc: 0.6130, precision: 0.8974, recall: 0.6139, f1: 0.7291, edges-pos-ontonotes_loss: 0.0285
09/17 12:57:35 AM: Best result seen so far for edges-pos-ontonotes.
09/17 12:57:35 AM: Best result seen so far for macro.
09/17 12:57:35 AM: Updating LR scheduler:
09/17 12:57:35 AM: 	Best result seen so far for macro_avg: 0.716
09/17 12:57:35 AM: 	# validation passes without improvement: 0
09/17 12:57:35 AM: edges-pos-ontonotes_loss: training: 0.032242 validation: 0.029192
09/17 12:57:35 AM: macro_avg: validation: 0.715963
09/17 12:57:35 AM: micro_avg: validation: 0.000000
09/17 12:57:35 AM: edges-pos-ontonotes_mcc: training: 0.706539 validation: 0.726263
09/17 12:57:35 AM: edges-pos-ontonotes_acc: training: 0.567621 validation: 0.593193
09/17 12:57:35 AM: edges-pos-ontonotes_precision: training: 0.872388 validation: 0.894486
09/17 12:57:35 AM: edges-pos-ontonotes_recall: training: 0.579905 validation: 0.596844
09/17 12:57:35 AM: edges-pos-ontonotes_f1: training: 0.696695 validation: 0.715963
09/17 12:57:35 AM: Global learning rate: 0.0001
09/17 12:57:35 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 12:57:37 AM: Update 12012: task edges-pos-ontonotes, batch 12 (12012): mcc: 0.7133, acc: 0.5726, precision: 0.8843, recall: 0.5827, f1: 0.7025, edges-pos-ontonotes_loss: 0.0307
09/17 12:57:47 AM: Update 12079: task edges-pos-ontonotes, batch 79 (12079): mcc: 0.7105, acc: 0.5694, precision: 0.8801, recall: 0.5811, f1: 0.7000, edges-pos-ontonotes_loss: 0.0314
09/17 12:57:57 AM: Update 12151: task edges-pos-ontonotes, batch 151 (12151): mcc: 0.7127, acc: 0.5727, precision: 0.8811, recall: 0.5840, f1: 0.7025, edges-pos-ontonotes_loss: 0.0314
09/17 12:58:07 AM: Update 12221: task edges-pos-ontonotes, batch 221 (12221): mcc: 0.7140, acc: 0.5739, precision: 0.8825, recall: 0.5851, f1: 0.7037, edges-pos-ontonotes_loss: 0.0313
09/17 12:58:18 AM: Update 12275: task edges-pos-ontonotes, batch 275 (12275): mcc: 0.7135, acc: 0.5742, precision: 0.8804, recall: 0.5858, f1: 0.7035, edges-pos-ontonotes_loss: 0.0311
09/17 12:58:28 AM: Update 12359: task edges-pos-ontonotes, batch 359 (12359): mcc: 0.7178, acc: 0.5792, precision: 0.8827, recall: 0.5912, f1: 0.7081, edges-pos-ontonotes_loss: 0.0302
09/17 12:58:38 AM: Update 12445: task edges-pos-ontonotes, batch 445 (12445): mcc: 0.7217, acc: 0.5833, precision: 0.8853, recall: 0.5957, f1: 0.7122, edges-pos-ontonotes_loss: 0.0294
09/17 12:58:48 AM: Update 12523: task edges-pos-ontonotes, batch 523 (12523): mcc: 0.7239, acc: 0.5858, precision: 0.8866, recall: 0.5985, f1: 0.7146, edges-pos-ontonotes_loss: 0.0289
09/17 12:58:58 AM: Update 12595: task edges-pos-ontonotes, batch 595 (12595): mcc: 0.7279, acc: 0.5906, precision: 0.8883, recall: 0.6038, f1: 0.7189, edges-pos-ontonotes_loss: 0.0283
09/17 12:59:08 AM: Update 12711: task edges-pos-ontonotes, batch 711 (12711): mcc: 0.7375, acc: 0.6034, precision: 0.8917, recall: 0.6171, f1: 0.7294, edges-pos-ontonotes_loss: 0.0271
09/17 12:59:18 AM: Update 12819: task edges-pos-ontonotes, batch 819 (12819): mcc: 0.7456, acc: 0.6145, precision: 0.8942, recall: 0.6288, f1: 0.7384, edges-pos-ontonotes_loss: 0.0262
09/17 12:59:28 AM: Update 12927: task edges-pos-ontonotes, batch 927 (12927): mcc: 0.7511, acc: 0.6224, precision: 0.8955, recall: 0.6371, f1: 0.7445, edges-pos-ontonotes_loss: 0.0255
09/17 12:59:33 AM: ***** Step 13000 / Validation 13 *****
09/17 12:59:33 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 12:59:33 AM: Validating...
09/17 12:59:38 AM: Evaluate: task edges-pos-ontonotes, batch 49 (157): mcc: 0.7269, acc: 0.6051, precision: 0.8823, recall: 0.6062, f1: 0.7187, edges-pos-ontonotes_loss: 0.0287
09/17 12:59:48 AM: Evaluate: task edges-pos-ontonotes, batch 127 (157): mcc: 0.7108, acc: 0.5765, precision: 0.8818, recall: 0.5804, f1: 0.7000, edges-pos-ontonotes_loss: 0.0296
09/17 12:59:53 AM: Updating LR scheduler:
09/17 12:59:53 AM: 	Best result seen so far for macro_avg: 0.716
09/17 12:59:53 AM: 	# validation passes without improvement: 1
09/17 12:59:53 AM: edges-pos-ontonotes_loss: training: 0.025148 validation: 0.030177
09/17 12:59:53 AM: macro_avg: validation: 0.689735
09/17 12:59:53 AM: micro_avg: validation: 0.000000
09/17 12:59:53 AM: edges-pos-ontonotes_mcc: training: 0.753650 validation: 0.701944
09/17 12:59:53 AM: edges-pos-ontonotes_acc: training: 0.626056 validation: 0.562854
09/17 12:59:53 AM: edges-pos-ontonotes_precision: training: 0.896072 validation: 0.881302
09/17 12:59:53 AM: edges-pos-ontonotes_recall: training: 0.640865 validation: 0.566579
09/17 12:59:53 AM: edges-pos-ontonotes_f1: training: 0.747280 validation: 0.689735
09/17 12:59:53 AM: Global learning rate: 0.0001
09/17 12:59:53 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 12:59:58 AM: Update 13070: task edges-pos-ontonotes, batch 70 (13070): mcc: 0.8137, acc: 0.7180, precision: 0.9063, recall: 0.7367, f1: 0.8127, edges-pos-ontonotes_loss: 0.0198
09/17 01:00:09 AM: Update 13198: task edges-pos-ontonotes, batch 198 (13198): mcc: 0.8121, acc: 0.7168, precision: 0.9031, recall: 0.7365, f1: 0.8114, edges-pos-ontonotes_loss: 0.0196
09/17 01:00:19 AM: Update 13366: task edges-pos-ontonotes, batch 366 (13366): mcc: 0.8010, acc: 0.7048, precision: 0.8944, recall: 0.7238, f1: 0.8001, edges-pos-ontonotes_loss: 0.0202
09/17 01:00:39 AM: Update 13511: task edges-pos-ontonotes, batch 511 (13511): mcc: 0.7965, acc: 0.6998, precision: 0.8918, recall: 0.7180, f1: 0.7955, edges-pos-ontonotes_loss: 0.0202
09/17 01:00:49 AM: Update 13583: task edges-pos-ontonotes, batch 583 (13583): mcc: 0.7718, acc: 0.6646, precision: 0.8823, recall: 0.6822, f1: 0.7695, edges-pos-ontonotes_loss: 0.0219
09/17 01:00:59 AM: Update 13661: task edges-pos-ontonotes, batch 661 (13661): mcc: 0.7580, acc: 0.6452, precision: 0.8777, recall: 0.6620, f1: 0.7547, edges-pos-ontonotes_loss: 0.0233
09/17 01:01:09 AM: Update 13738: task edges-pos-ontonotes, batch 738 (13738): mcc: 0.7490, acc: 0.6322, precision: 0.8742, recall: 0.6491, f1: 0.7450, edges-pos-ontonotes_loss: 0.0243
09/17 01:01:19 AM: Update 13809: task edges-pos-ontonotes, batch 809 (13809): mcc: 0.7425, acc: 0.6227, precision: 0.8728, recall: 0.6393, f1: 0.7380, edges-pos-ontonotes_loss: 0.0251
09/17 01:01:29 AM: Update 13879: task edges-pos-ontonotes, batch 879 (13879): mcc: 0.7399, acc: 0.6189, precision: 0.8723, recall: 0.6352, f1: 0.7351, edges-pos-ontonotes_loss: 0.0254
09/17 01:01:39 AM: Update 13986: task edges-pos-ontonotes, batch 986 (13986): mcc: 0.7409, acc: 0.6203, precision: 0.8729, recall: 0.6364, f1: 0.7361, edges-pos-ontonotes_loss: 0.0254
09/17 01:01:41 AM: ***** Step 14000 / Validation 14 *****
09/17 01:01:41 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:01:41 AM: Validating...
09/17 01:01:49 AM: Evaluate: task edges-pos-ontonotes, batch 87 (157): mcc: 0.7504, acc: 0.6260, precision: 0.9069, recall: 0.6278, f1: 0.7419, edges-pos-ontonotes_loss: 0.0270
09/17 01:01:59 AM: Evaluate: task edges-pos-ontonotes, batch 151 (157): mcc: 0.7195, acc: 0.5808, precision: 0.8956, recall: 0.5852, f1: 0.7079, edges-pos-ontonotes_loss: 0.0290
09/17 01:02:00 AM: Updating LR scheduler:
09/17 01:02:00 AM: 	Best result seen so far for macro_avg: 0.716
09/17 01:02:00 AM: 	# validation passes without improvement: 2
09/17 01:02:00 AM: edges-pos-ontonotes_loss: training: 0.025391 validation: 0.029106
09/17 01:02:00 AM: macro_avg: validation: 0.706645
09/17 01:02:00 AM: micro_avg: validation: 0.000000
09/17 01:02:00 AM: edges-pos-ontonotes_mcc: training: 0.741029 validation: 0.718399
09/17 01:02:00 AM: edges-pos-ontonotes_acc: training: 0.620513 validation: 0.579352
09/17 01:02:00 AM: edges-pos-ontonotes_precision: training: 0.872984 validation: 0.895149
09/17 01:02:00 AM: edges-pos-ontonotes_recall: training: 0.636579 validation: 0.583722
09/17 01:02:00 AM: edges-pos-ontonotes_f1: training: 0.736270 validation: 0.706645
09/17 01:02:00 AM: Global learning rate: 0.0001
09/17 01:02:00 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:02:10 AM: Update 14120: task edges-pos-ontonotes, batch 120 (14120): mcc: 0.7596, acc: 0.6458, precision: 0.8832, recall: 0.6605, f1: 0.7558, edges-pos-ontonotes_loss: 0.0241
09/17 01:02:20 AM: Update 14200: task edges-pos-ontonotes, batch 200 (14200): mcc: 0.7484, acc: 0.6291, precision: 0.8805, recall: 0.6435, f1: 0.7436, edges-pos-ontonotes_loss: 0.0253
09/17 01:02:30 AM: Update 14292: task edges-pos-ontonotes, batch 292 (14292): mcc: 0.7393, acc: 0.6151, precision: 0.8780, recall: 0.6300, f1: 0.7336, edges-pos-ontonotes_loss: 0.0264
09/17 01:02:40 AM: Update 14380: task edges-pos-ontonotes, batch 380 (14380): mcc: 0.7364, acc: 0.6105, precision: 0.8773, recall: 0.6256, f1: 0.7304, edges-pos-ontonotes_loss: 0.0268
09/17 01:02:50 AM: Update 14458: task edges-pos-ontonotes, batch 458 (14458): mcc: 0.7359, acc: 0.6096, precision: 0.8776, recall: 0.6245, f1: 0.7297, edges-pos-ontonotes_loss: 0.0270
09/17 01:03:00 AM: Update 14514: task edges-pos-ontonotes, batch 514 (14514): mcc: 0.7296, acc: 0.6012, precision: 0.8736, recall: 0.6169, f1: 0.7232, edges-pos-ontonotes_loss: 0.0276
09/17 01:03:10 AM: Update 14592: task edges-pos-ontonotes, batch 592 (14592): mcc: 0.7254, acc: 0.5959, precision: 0.8715, recall: 0.6115, f1: 0.7187, edges-pos-ontonotes_loss: 0.0284
09/17 01:03:20 AM: Update 14659: task edges-pos-ontonotes, batch 659 (14659): mcc: 0.7229, acc: 0.5926, precision: 0.8700, recall: 0.6083, f1: 0.7160, edges-pos-ontonotes_loss: 0.0287
09/17 01:03:30 AM: Update 14726: task edges-pos-ontonotes, batch 726 (14726): mcc: 0.7211, acc: 0.5903, precision: 0.8690, recall: 0.6061, f1: 0.7141, edges-pos-ontonotes_loss: 0.0290
09/17 01:03:41 AM: Update 14780: task edges-pos-ontonotes, batch 780 (14780): mcc: 0.7202, acc: 0.5890, precision: 0.8688, recall: 0.6048, f1: 0.7131, edges-pos-ontonotes_loss: 0.0291
09/17 01:03:51 AM: Update 14843: task edges-pos-ontonotes, batch 843 (14843): mcc: 0.7184, acc: 0.5863, precision: 0.8686, recall: 0.6019, f1: 0.7111, edges-pos-ontonotes_loss: 0.0294
09/17 01:04:01 AM: Update 14911: task edges-pos-ontonotes, batch 911 (14911): mcc: 0.7172, acc: 0.5845, precision: 0.8688, recall: 0.5997, f1: 0.7096, edges-pos-ontonotes_loss: 0.0296
09/17 01:04:11 AM: Update 14973: task edges-pos-ontonotes, batch 973 (14973): mcc: 0.7162, acc: 0.5828, precision: 0.8691, recall: 0.5980, f1: 0.7085, edges-pos-ontonotes_loss: 0.0297
09/17 01:04:15 AM: ***** Step 15000 / Validation 15 *****
09/17 01:04:15 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:04:15 AM: Validating...
09/17 01:04:21 AM: Evaluate: task edges-pos-ontonotes, batch 63 (157): mcc: 0.7506, acc: 0.6367, precision: 0.8938, recall: 0.6373, f1: 0.7441, edges-pos-ontonotes_loss: 0.0272
09/17 01:04:31 AM: Evaluate: task edges-pos-ontonotes, batch 134 (157): mcc: 0.7323, acc: 0.6056, precision: 0.8952, recall: 0.6062, f1: 0.7229, edges-pos-ontonotes_loss: 0.0281
09/17 01:04:35 AM: Best result seen so far for edges-pos-ontonotes.
09/17 01:04:35 AM: Best result seen so far for macro.
09/17 01:04:35 AM: Updating LR scheduler:
09/17 01:04:35 AM: 	Best result seen so far for macro_avg: 0.720
09/17 01:04:35 AM: 	# validation passes without improvement: 0
09/17 01:04:35 AM: edges-pos-ontonotes_loss: training: 0.029790 validation: 0.028429
09/17 01:04:35 AM: macro_avg: validation: 0.719836
09/17 01:04:35 AM: micro_avg: validation: 0.000000
09/17 01:04:35 AM: edges-pos-ontonotes_mcc: training: 0.716092 validation: 0.729631
09/17 01:04:35 AM: edges-pos-ontonotes_acc: training: 0.582548 validation: 0.601448
09/17 01:04:35 AM: edges-pos-ontonotes_precision: training: 0.869317 validation: 0.894777
09/17 01:04:35 AM: edges-pos-ontonotes_recall: training: 0.597613 validation: 0.602114
09/17 01:04:35 AM: edges-pos-ontonotes_f1: training: 0.708303 validation: 0.719836
09/17 01:04:35 AM: Global learning rate: 0.0001
09/17 01:04:35 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:04:41 AM: Update 15040: task edges-pos-ontonotes, batch 40 (15040): mcc: 0.7067, acc: 0.5686, precision: 0.8708, recall: 0.5813, f1: 0.6972, edges-pos-ontonotes_loss: 0.0319
09/17 01:04:51 AM: Update 15088: task edges-pos-ontonotes, batch 88 (15088): mcc: 0.7079, acc: 0.5695, precision: 0.8732, recall: 0.5815, f1: 0.6981, edges-pos-ontonotes_loss: 0.0320
09/17 01:05:03 AM: Update 15093: task edges-pos-ontonotes, batch 93 (15093): mcc: 0.7075, acc: 0.5695, precision: 0.8725, recall: 0.5814, f1: 0.6978, edges-pos-ontonotes_loss: 0.0320
09/17 01:05:13 AM: Update 15162: task edges-pos-ontonotes, batch 162 (15162): mcc: 0.7104, acc: 0.5730, precision: 0.8751, recall: 0.5843, f1: 0.7007, edges-pos-ontonotes_loss: 0.0318
09/17 01:05:24 AM: Update 15225: task edges-pos-ontonotes, batch 225 (15225): mcc: 0.7115, acc: 0.5742, precision: 0.8766, recall: 0.5851, f1: 0.7018, edges-pos-ontonotes_loss: 0.0317
09/17 01:05:34 AM: Update 15270: task edges-pos-ontonotes, batch 270 (15270): mcc: 0.7115, acc: 0.5741, precision: 0.8767, recall: 0.5850, f1: 0.7018, edges-pos-ontonotes_loss: 0.0316
09/17 01:05:44 AM: Update 15316: task edges-pos-ontonotes, batch 316 (15316): mcc: 0.7124, acc: 0.5751, precision: 0.8775, recall: 0.5860, f1: 0.7027, edges-pos-ontonotes_loss: 0.0315
09/17 01:05:54 AM: Update 15366: task edges-pos-ontonotes, batch 366 (15366): mcc: 0.7132, acc: 0.5760, precision: 0.8779, recall: 0.5869, f1: 0.7035, edges-pos-ontonotes_loss: 0.0315
09/17 01:06:04 AM: Update 15411: task edges-pos-ontonotes, batch 411 (15411): mcc: 0.7136, acc: 0.5764, precision: 0.8782, recall: 0.5874, f1: 0.7040, edges-pos-ontonotes_loss: 0.0314
09/17 01:06:14 AM: Update 15475: task edges-pos-ontonotes, batch 475 (15475): mcc: 0.7135, acc: 0.5763, precision: 0.8780, recall: 0.5874, f1: 0.7039, edges-pos-ontonotes_loss: 0.0314
09/17 01:06:25 AM: Update 15542: task edges-pos-ontonotes, batch 542 (15542): mcc: 0.7134, acc: 0.5759, precision: 0.8783, recall: 0.5870, f1: 0.7037, edges-pos-ontonotes_loss: 0.0313
09/17 01:06:35 AM: Update 15604: task edges-pos-ontonotes, batch 604 (15604): mcc: 0.7138, acc: 0.5764, precision: 0.8787, recall: 0.5874, f1: 0.7041, edges-pos-ontonotes_loss: 0.0312
09/17 01:06:45 AM: Update 15675: task edges-pos-ontonotes, batch 675 (15675): mcc: 0.7140, acc: 0.5767, precision: 0.8786, recall: 0.5878, f1: 0.7044, edges-pos-ontonotes_loss: 0.0312
09/17 01:06:55 AM: Update 15732: task edges-pos-ontonotes, batch 732 (15732): mcc: 0.7138, acc: 0.5765, precision: 0.8782, recall: 0.5877, f1: 0.7042, edges-pos-ontonotes_loss: 0.0312
09/17 01:07:05 AM: Update 15808: task edges-pos-ontonotes, batch 808 (15808): mcc: 0.7153, acc: 0.5781, precision: 0.8789, recall: 0.5897, f1: 0.7058, edges-pos-ontonotes_loss: 0.0308
09/17 01:07:15 AM: Update 15889: task edges-pos-ontonotes, batch 889 (15889): mcc: 0.7172, acc: 0.5802, precision: 0.8799, recall: 0.5920, f1: 0.7078, edges-pos-ontonotes_loss: 0.0304
09/17 01:07:25 AM: Update 15974: task edges-pos-ontonotes, batch 974 (15974): mcc: 0.7191, acc: 0.5821, precision: 0.8812, recall: 0.5942, f1: 0.7098, edges-pos-ontonotes_loss: 0.0299
09/17 01:07:28 AM: ***** Step 16000 / Validation 16 *****
09/17 01:07:28 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:07:28 AM: Validating...
09/17 01:07:35 AM: Evaluate: task edges-pos-ontonotes, batch 70 (157): mcc: 0.7483, acc: 0.6230, precision: 0.9068, recall: 0.6243, f1: 0.7395, edges-pos-ontonotes_loss: 0.0280
09/17 01:07:45 AM: Evaluate: task edges-pos-ontonotes, batch 139 (157): mcc: 0.7248, acc: 0.5866, precision: 0.9043, recall: 0.5879, f1: 0.7125, edges-pos-ontonotes_loss: 0.0289
09/17 01:07:48 AM: Updating LR scheduler:
09/17 01:07:48 AM: 	Best result seen so far for macro_avg: 0.720
09/17 01:07:48 AM: 	# validation passes without improvement: 1
09/17 01:07:48 AM: edges-pos-ontonotes_loss: training: 0.029791 validation: 0.029061
09/17 01:07:48 AM: macro_avg: validation: 0.710010
09/17 01:07:48 AM: micro_avg: validation: 0.000000
09/17 01:07:48 AM: edges-pos-ontonotes_mcc: training: 0.719796 validation: 0.722621
09/17 01:07:48 AM: edges-pos-ontonotes_acc: training: 0.582909 validation: 0.583278
09/17 01:07:48 AM: edges-pos-ontonotes_precision: training: 0.881667 validation: 0.904198
09/17 01:07:48 AM: edges-pos-ontonotes_recall: training: 0.595102 validation: 0.584484
09/17 01:07:48 AM: edges-pos-ontonotes_f1: training: 0.710581 validation: 0.710010
09/17 01:07:48 AM: Global learning rate: 0.0001
09/17 01:07:48 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:07:55 AM: Update 16051: task edges-pos-ontonotes, batch 51 (16051): mcc: 0.7591, acc: 0.6320, precision: 0.8988, recall: 0.6481, f1: 0.7531, edges-pos-ontonotes_loss: 0.0243
09/17 01:08:05 AM: Update 16163: task edges-pos-ontonotes, batch 163 (16163): mcc: 0.7935, acc: 0.6807, precision: 0.9095, recall: 0.6987, f1: 0.7902, edges-pos-ontonotes_loss: 0.0217
09/17 01:08:16 AM: Update 16280: task edges-pos-ontonotes, batch 280 (16280): mcc: 0.8037, acc: 0.6961, precision: 0.9115, recall: 0.7149, f1: 0.8013, edges-pos-ontonotes_loss: 0.0209
09/17 01:08:26 AM: Update 16380: task edges-pos-ontonotes, batch 380 (16380): mcc: 0.8063, acc: 0.7010, precision: 0.9105, recall: 0.7202, f1: 0.8042, edges-pos-ontonotes_loss: 0.0207
09/17 01:08:36 AM: Update 16514: task edges-pos-ontonotes, batch 514 (16514): mcc: 0.8069, acc: 0.7034, precision: 0.9087, recall: 0.7227, f1: 0.8051, edges-pos-ontonotes_loss: 0.0205
09/17 01:08:46 AM: Update 16654: task edges-pos-ontonotes, batch 654 (16654): mcc: 0.8091, acc: 0.7075, precision: 0.9082, recall: 0.7270, f1: 0.8076, edges-pos-ontonotes_loss: 0.0202
09/17 01:08:56 AM: Update 16804: task edges-pos-ontonotes, batch 804 (16804): mcc: 0.8058, acc: 0.7048, precision: 0.9044, recall: 0.7242, f1: 0.8043, edges-pos-ontonotes_loss: 0.0204
09/17 01:09:07 AM: Update 16971: task edges-pos-ontonotes, batch 971 (16971): mcc: 0.8027, acc: 0.7023, precision: 0.9014, recall: 0.7212, f1: 0.8013, edges-pos-ontonotes_loss: 0.0202
09/17 01:09:12 AM: ***** Step 17000 / Validation 17 *****
09/17 01:09:12 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:09:12 AM: Validating...
09/17 01:09:18 AM: Evaluate: task edges-pos-ontonotes, batch 53 (157): mcc: 0.7459, acc: 0.6306, precision: 0.8914, recall: 0.6314, f1: 0.7392, edges-pos-ontonotes_loss: 0.0279
09/17 01:09:28 AM: Evaluate: task edges-pos-ontonotes, batch 129 (157): mcc: 0.7179, acc: 0.5873, precision: 0.8873, recall: 0.5882, f1: 0.7074, edges-pos-ontonotes_loss: 0.0294
09/17 01:09:32 AM: Updating LR scheduler:
09/17 01:09:32 AM: 	Best result seen so far for macro_avg: 0.720
09/17 01:09:32 AM: 	# validation passes without improvement: 2
09/17 01:09:32 AM: edges-pos-ontonotes_loss: training: 0.020654 validation: 0.030095
09/17 01:09:32 AM: macro_avg: validation: 0.696242
09/17 01:09:32 AM: micro_avg: validation: 0.000000
09/17 01:09:32 AM: edges-pos-ontonotes_mcc: training: 0.795348 validation: 0.707890
09/17 01:09:32 AM: edges-pos-ontonotes_acc: training: 0.692045 validation: 0.573288
09/17 01:09:32 AM: edges-pos-ontonotes_precision: training: 0.898004 validation: 0.884093
09/17 01:09:32 AM: edges-pos-ontonotes_recall: training: 0.710981 validation: 0.574230
09/17 01:09:32 AM: edges-pos-ontonotes_f1: training: 0.793623 validation: 0.696242
09/17 01:09:32 AM: Global learning rate: 0.0001
09/17 01:09:32 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:09:38 AM: Update 17045: task edges-pos-ontonotes, batch 45 (17045): mcc: 0.6995, acc: 0.5691, precision: 0.8485, recall: 0.5850, f1: 0.6925, edges-pos-ontonotes_loss: 0.0331
09/17 01:09:48 AM: Update 17116: task edges-pos-ontonotes, batch 116 (17116): mcc: 0.6979, acc: 0.5644, precision: 0.8504, recall: 0.5810, f1: 0.6904, edges-pos-ontonotes_loss: 0.0334
09/17 01:09:58 AM: Update 17188: task edges-pos-ontonotes, batch 188 (17188): mcc: 0.7002, acc: 0.5665, precision: 0.8532, recall: 0.5828, f1: 0.6926, edges-pos-ontonotes_loss: 0.0332
09/17 01:10:08 AM: Update 17262: task edges-pos-ontonotes, batch 262 (17262): mcc: 0.7017, acc: 0.5680, precision: 0.8555, recall: 0.5837, f1: 0.6939, edges-pos-ontonotes_loss: 0.0331
09/17 01:10:22 AM: Update 17301: task edges-pos-ontonotes, batch 301 (17301): mcc: 0.7017, acc: 0.5678, precision: 0.8556, recall: 0.5835, f1: 0.6939, edges-pos-ontonotes_loss: 0.0331
09/17 01:10:32 AM: Update 17414: task edges-pos-ontonotes, batch 414 (17414): mcc: 0.7111, acc: 0.5806, precision: 0.8595, recall: 0.5962, f1: 0.7041, edges-pos-ontonotes_loss: 0.0309
09/17 01:10:42 AM: Update 17526: task edges-pos-ontonotes, batch 526 (17526): mcc: 0.7180, acc: 0.5897, precision: 0.8631, recall: 0.6052, f1: 0.7115, edges-pos-ontonotes_loss: 0.0295
09/17 01:10:52 AM: Update 17617: task edges-pos-ontonotes, batch 617 (17617): mcc: 0.7223, acc: 0.5955, precision: 0.8653, recall: 0.6108, f1: 0.7161, edges-pos-ontonotes_loss: 0.0287
09/17 01:11:02 AM: Update 17710: task edges-pos-ontonotes, batch 710 (17710): mcc: 0.7227, acc: 0.5958, precision: 0.8656, recall: 0.6113, f1: 0.7165, edges-pos-ontonotes_loss: 0.0286
09/17 01:11:12 AM: Update 17800: task edges-pos-ontonotes, batch 800 (17800): mcc: 0.7235, acc: 0.5962, precision: 0.8668, recall: 0.6117, f1: 0.7172, edges-pos-ontonotes_loss: 0.0286
09/17 01:11:23 AM: Update 17879: task edges-pos-ontonotes, batch 879 (17879): mcc: 0.7243, acc: 0.5968, precision: 0.8678, recall: 0.6123, f1: 0.7180, edges-pos-ontonotes_loss: 0.0285
09/17 01:11:33 AM: Update 17939: task edges-pos-ontonotes, batch 939 (17939): mcc: 0.7234, acc: 0.5955, precision: 0.8671, recall: 0.6114, f1: 0.7171, edges-pos-ontonotes_loss: 0.0285
09/17 01:11:42 AM: ***** Step 18000 / Validation 18 *****
09/17 01:11:42 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:11:42 AM: Validating...
09/17 01:11:43 AM: Evaluate: task edges-pos-ontonotes, batch 12 (157): mcc: 0.7378, acc: 0.6104, precision: 0.9010, recall: 0.6112, f1: 0.7284, edges-pos-ontonotes_loss: 0.0284
09/17 01:11:53 AM: Evaluate: task edges-pos-ontonotes, batch 103 (157): mcc: 0.7505, acc: 0.6366, precision: 0.8931, recall: 0.6378, f1: 0.7441, edges-pos-ontonotes_loss: 0.0267
09/17 01:12:02 AM: Best result seen so far for edges-pos-ontonotes.
09/17 01:12:02 AM: Best result seen so far for macro.
09/17 01:12:02 AM: Updating LR scheduler:
09/17 01:12:02 AM: 	Best result seen so far for macro_avg: 0.724
09/17 01:12:02 AM: 	# validation passes without improvement: 0
09/17 01:12:02 AM: edges-pos-ontonotes_loss: training: 0.028802 validation: 0.028113
09/17 01:12:02 AM: macro_avg: validation: 0.723853
09/17 01:12:02 AM: micro_avg: validation: 0.000000
09/17 01:12:02 AM: edges-pos-ontonotes_mcc: training: 0.721540 validation: 0.732585
09/17 01:12:02 AM: edges-pos-ontonotes_acc: training: 0.592873 validation: 0.608263
09/17 01:12:02 AM: edges-pos-ontonotes_precision: training: 0.866136 validation: 0.891181
09/17 01:12:02 AM: edges-pos-ontonotes_recall: training: 0.608879 validation: 0.609427
09/17 01:12:02 AM: edges-pos-ontonotes_f1: training: 0.715074 validation: 0.723853
09/17 01:12:02 AM: Global learning rate: 0.0001
09/17 01:12:02 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:12:03 AM: Update 18010: task edges-pos-ontonotes, batch 10 (18010): mcc: 0.7058, acc: 0.5717, precision: 0.8582, recall: 0.5885, f1: 0.6982, edges-pos-ontonotes_loss: 0.0317
09/17 01:12:13 AM: Update 18077: task edges-pos-ontonotes, batch 77 (18077): mcc: 0.7035, acc: 0.5689, precision: 0.8568, recall: 0.5857, f1: 0.6958, edges-pos-ontonotes_loss: 0.0320
09/17 01:12:23 AM: Update 18147: task edges-pos-ontonotes, batch 147 (18147): mcc: 0.7058, acc: 0.5718, precision: 0.8588, recall: 0.5880, f1: 0.6980, edges-pos-ontonotes_loss: 0.0320
09/17 01:12:33 AM: Update 18222: task edges-pos-ontonotes, batch 222 (18222): mcc: 0.7081, acc: 0.5749, precision: 0.8601, recall: 0.5909, f1: 0.7006, edges-pos-ontonotes_loss: 0.0317
09/17 01:12:43 AM: Update 18274: task edges-pos-ontonotes, batch 274 (18274): mcc: 0.7075, acc: 0.5736, precision: 0.8613, recall: 0.5891, f1: 0.6996, edges-pos-ontonotes_loss: 0.0318
09/17 01:12:53 AM: Update 18338: task edges-pos-ontonotes, batch 338 (18338): mcc: 0.7066, acc: 0.5718, precision: 0.8625, recall: 0.5868, f1: 0.6984, edges-pos-ontonotes_loss: 0.0320
09/17 01:13:03 AM: Update 18404: task edges-pos-ontonotes, batch 404 (18404): mcc: 0.7064, acc: 0.5710, precision: 0.8638, recall: 0.5856, f1: 0.6980, edges-pos-ontonotes_loss: 0.0320
09/17 01:13:13 AM: Update 18464: task edges-pos-ontonotes, batch 464 (18464): mcc: 0.7064, acc: 0.5706, precision: 0.8648, recall: 0.5850, f1: 0.6979, edges-pos-ontonotes_loss: 0.0319
09/17 01:13:23 AM: Update 18535: task edges-pos-ontonotes, batch 535 (18535): mcc: 0.7073, acc: 0.5713, precision: 0.8662, recall: 0.5854, f1: 0.6986, edges-pos-ontonotes_loss: 0.0318
09/17 01:13:33 AM: Update 18588: task edges-pos-ontonotes, batch 588 (18588): mcc: 0.7076, acc: 0.5716, precision: 0.8668, recall: 0.5855, f1: 0.6989, edges-pos-ontonotes_loss: 0.0318
09/17 01:13:44 AM: Update 18655: task edges-pos-ontonotes, batch 655 (18655): mcc: 0.7084, acc: 0.5724, precision: 0.8679, recall: 0.5860, f1: 0.6996, edges-pos-ontonotes_loss: 0.0317
09/17 01:13:54 AM: Update 18708: task edges-pos-ontonotes, batch 708 (18708): mcc: 0.7090, acc: 0.5730, precision: 0.8689, recall: 0.5863, f1: 0.7002, edges-pos-ontonotes_loss: 0.0317
09/17 01:14:04 AM: Update 18754: task edges-pos-ontonotes, batch 754 (18754): mcc: 0.7094, acc: 0.5733, precision: 0.8695, recall: 0.5866, f1: 0.7006, edges-pos-ontonotes_loss: 0.0316
09/17 01:14:14 AM: Update 18797: task edges-pos-ontonotes, batch 797 (18797): mcc: 0.7097, acc: 0.5737, precision: 0.8698, recall: 0.5869, f1: 0.7009, edges-pos-ontonotes_loss: 0.0316
09/17 01:14:24 AM: Update 18860: task edges-pos-ontonotes, batch 860 (18860): mcc: 0.7104, acc: 0.5745, precision: 0.8705, recall: 0.5875, f1: 0.7016, edges-pos-ontonotes_loss: 0.0316
09/17 01:14:34 AM: Update 18912: task edges-pos-ontonotes, batch 912 (18912): mcc: 0.7105, acc: 0.5745, precision: 0.8707, recall: 0.5875, f1: 0.7016, edges-pos-ontonotes_loss: 0.0315
09/17 01:14:44 AM: Update 18979: task edges-pos-ontonotes, batch 979 (18979): mcc: 0.7110, acc: 0.5751, precision: 0.8714, recall: 0.5879, f1: 0.7021, edges-pos-ontonotes_loss: 0.0315
09/17 01:14:47 AM: ***** Step 19000 / Validation 19 *****
09/17 01:14:47 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:14:47 AM: Validating...
09/17 01:14:54 AM: Evaluate: task edges-pos-ontonotes, batch 71 (157): mcc: 0.7474, acc: 0.6217, precision: 0.9064, recall: 0.6232, f1: 0.7386, edges-pos-ontonotes_loss: 0.0277
09/17 01:15:04 AM: Evaluate: task edges-pos-ontonotes, batch 140 (157): mcc: 0.7286, acc: 0.5921, precision: 0.9011, recall: 0.5961, f1: 0.7175, edges-pos-ontonotes_loss: 0.0285
09/17 01:15:07 AM: Updating LR scheduler:
09/17 01:15:07 AM: 	Best result seen so far for macro_avg: 0.724
09/17 01:15:07 AM: 	# validation passes without improvement: 1
09/17 01:15:07 AM: edges-pos-ontonotes_loss: training: 0.031446 validation: 0.028567
09/17 01:15:07 AM: macro_avg: validation: 0.715988
09/17 01:15:07 AM: micro_avg: validation: 0.000000
09/17 01:15:07 AM: edges-pos-ontonotes_mcc: training: 0.711286 validation: 0.727273
09/17 01:15:07 AM: edges-pos-ontonotes_acc: training: 0.575306 validation: 0.590400
09/17 01:15:07 AM: edges-pos-ontonotes_precision: training: 0.871664 validation: 0.901254
09/17 01:15:07 AM: edges-pos-ontonotes_recall: training: 0.588112 validation: 0.593902
09/17 01:15:07 AM: edges-pos-ontonotes_f1: training: 0.702349 validation: 0.715988
09/17 01:15:07 AM: Global learning rate: 0.0001
09/17 01:15:07 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:15:14 AM: Update 19047: task edges-pos-ontonotes, batch 47 (19047): mcc: 0.7134, acc: 0.5757, precision: 0.8777, recall: 0.5874, f1: 0.7038, edges-pos-ontonotes_loss: 0.0313
09/17 01:15:24 AM: Update 19115: task edges-pos-ontonotes, batch 115 (19115): mcc: 0.7147, acc: 0.5773, precision: 0.8776, recall: 0.5896, f1: 0.7053, edges-pos-ontonotes_loss: 0.0311
09/17 01:15:44 AM: Update 19179: task edges-pos-ontonotes, batch 179 (19179): mcc: 0.7137, acc: 0.5768, precision: 0.8762, recall: 0.5889, f1: 0.7044, edges-pos-ontonotes_loss: 0.0310
09/17 01:15:54 AM: Update 19249: task edges-pos-ontonotes, batch 249 (19249): mcc: 0.7167, acc: 0.5803, precision: 0.8770, recall: 0.5933, f1: 0.7078, edges-pos-ontonotes_loss: 0.0300
09/17 01:16:04 AM: Update 19337: task edges-pos-ontonotes, batch 337 (19337): mcc: 0.7231, acc: 0.5875, precision: 0.8812, recall: 0.6009, f1: 0.7145, edges-pos-ontonotes_loss: 0.0288
09/17 01:16:14 AM: Update 19420: task edges-pos-ontonotes, batch 420 (19420): mcc: 0.7269, acc: 0.5915, precision: 0.8838, recall: 0.6053, f1: 0.7185, edges-pos-ontonotes_loss: 0.0281
09/17 01:16:24 AM: Update 19492: task edges-pos-ontonotes, batch 492 (19492): mcc: 0.7293, acc: 0.5940, precision: 0.8853, recall: 0.6081, f1: 0.7210, edges-pos-ontonotes_loss: 0.0277
09/17 01:16:34 AM: Update 19607: task edges-pos-ontonotes, batch 607 (19607): mcc: 0.7402, acc: 0.6084, precision: 0.8897, recall: 0.6231, f1: 0.7329, edges-pos-ontonotes_loss: 0.0264
09/17 01:16:44 AM: Update 19714: task edges-pos-ontonotes, batch 714 (19714): mcc: 0.7497, acc: 0.6213, precision: 0.8929, recall: 0.6365, f1: 0.7432, edges-pos-ontonotes_loss: 0.0254
09/17 01:16:55 AM: Update 19817: task edges-pos-ontonotes, batch 817 (19817): mcc: 0.7565, acc: 0.6309, precision: 0.8949, recall: 0.6464, f1: 0.7507, edges-pos-ontonotes_loss: 0.0246
09/17 01:17:05 AM: Update 19941: task edges-pos-ontonotes, batch 941 (19941): mcc: 0.7611, acc: 0.6377, precision: 0.8955, recall: 0.6538, f1: 0.7558, edges-pos-ontonotes_loss: 0.0241
09/17 01:17:09 AM: ***** Step 20000 / Validation 20 *****
09/17 01:17:09 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:17:09 AM: Validating...
09/17 01:17:15 AM: Evaluate: task edges-pos-ontonotes, batch 60 (157): mcc: 0.7403, acc: 0.6263, precision: 0.8761, recall: 0.6330, f1: 0.7350, edges-pos-ontonotes_loss: 0.0277
09/17 01:17:25 AM: Evaluate: task edges-pos-ontonotes, batch 132 (157): mcc: 0.7099, acc: 0.5783, precision: 0.8706, recall: 0.5866, f1: 0.7009, edges-pos-ontonotes_loss: 0.0295
09/17 01:17:28 AM: Updating LR scheduler:
09/17 01:17:28 AM: 	Best result seen so far for macro_avg: 0.724
09/17 01:17:28 AM: 	# validation passes without improvement: 2
09/17 01:17:28 AM: edges-pos-ontonotes_loss: training: 0.023723 validation: 0.030003
09/17 01:17:28 AM: macro_avg: validation: 0.692737
09/17 01:17:28 AM: micro_avg: validation: 0.000000
09/17 01:17:28 AM: edges-pos-ontonotes_mcc: training: 0.762875 validation: 0.702762
09/17 01:17:28 AM: edges-pos-ontonotes_acc: training: 0.640377 validation: 0.568410
09/17 01:17:28 AM: edges-pos-ontonotes_precision: training: 0.895952 validation: 0.869717
09/17 01:17:28 AM: edges-pos-ontonotes_recall: training: 0.656499 validation: 0.575606
09/17 01:17:28 AM: edges-pos-ontonotes_f1: training: 0.757758 validation: 0.692737
09/17 01:17:28 AM: Global learning rate: 0.0001
09/17 01:17:28 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:17:35 AM: Update 20086: task edges-pos-ontonotes, batch 86 (20086): mcc: 0.8202, acc: 0.7294, precision: 0.9055, recall: 0.7490, f1: 0.8198, edges-pos-ontonotes_loss: 0.0190
09/17 01:17:45 AM: Update 20228: task edges-pos-ontonotes, batch 228 (20228): mcc: 0.8021, acc: 0.7075, precision: 0.8933, recall: 0.7267, f1: 0.8014, edges-pos-ontonotes_loss: 0.0193
09/17 01:17:55 AM: Update 20396: task edges-pos-ontonotes, batch 396 (20396): mcc: 0.7984, acc: 0.7041, precision: 0.8906, recall: 0.7224, f1: 0.7977, edges-pos-ontonotes_loss: 0.0196
09/17 01:18:05 AM: Update 20472: task edges-pos-ontonotes, batch 472 (20472): mcc: 0.7772, acc: 0.6741, precision: 0.8819, recall: 0.6920, f1: 0.7755, edges-pos-ontonotes_loss: 0.0210
09/17 01:18:15 AM: Update 20545: task edges-pos-ontonotes, batch 545 (20545): mcc: 0.7589, acc: 0.6482, precision: 0.8745, recall: 0.6659, f1: 0.7561, edges-pos-ontonotes_loss: 0.0227
09/17 01:18:25 AM: Update 20627: task edges-pos-ontonotes, batch 627 (20627): mcc: 0.7486, acc: 0.6335, precision: 0.8711, recall: 0.6509, f1: 0.7450, edges-pos-ontonotes_loss: 0.0240
09/17 01:18:35 AM: Update 20698: task edges-pos-ontonotes, batch 698 (20698): mcc: 0.7410, acc: 0.6224, precision: 0.8688, recall: 0.6397, f1: 0.7368, edges-pos-ontonotes_loss: 0.0249
09/17 01:18:46 AM: Update 20761: task edges-pos-ontonotes, batch 761 (20761): mcc: 0.7360, acc: 0.6151, precision: 0.8673, recall: 0.6323, f1: 0.7314, edges-pos-ontonotes_loss: 0.0255
09/17 01:18:56 AM: Update 20876: task edges-pos-ontonotes, batch 876 (20876): mcc: 0.7378, acc: 0.6176, precision: 0.8683, recall: 0.6346, f1: 0.7333, edges-pos-ontonotes_loss: 0.0254
09/17 01:19:06 AM: Update 20991: task edges-pos-ontonotes, batch 991 (20991): mcc: 0.7398, acc: 0.6204, precision: 0.8693, recall: 0.6373, f1: 0.7354, edges-pos-ontonotes_loss: 0.0252
09/17 01:19:07 AM: ***** Step 21000 / Validation 21 *****
09/17 01:19:07 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:19:07 AM: Validating...
09/17 01:19:17 AM: Evaluate: task edges-pos-ontonotes, batch 89 (157): mcc: 0.7521, acc: 0.6287, precision: 0.9079, recall: 0.6297, f1: 0.7437, edges-pos-ontonotes_loss: 0.0266
09/17 01:19:27 AM: Evaluate: task edges-pos-ontonotes, batch 154 (157): mcc: 0.7206, acc: 0.5842, precision: 0.8944, recall: 0.5877, f1: 0.7093, edges-pos-ontonotes_loss: 0.0286
09/17 01:19:27 AM: Updating LR scheduler:
09/17 01:19:27 AM: 	Best result seen so far for macro_avg: 0.724
09/17 01:19:27 AM: 	# validation passes without improvement: 3
09/17 01:19:27 AM: edges-pos-ontonotes_loss: training: 0.025242 validation: 0.028657
09/17 01:19:27 AM: macro_avg: validation: 0.708481
09/17 01:19:27 AM: micro_avg: validation: 0.000000
09/17 01:19:27 AM: edges-pos-ontonotes_mcc: training: 0.739788 validation: 0.719850
09/17 01:19:27 AM: edges-pos-ontonotes_acc: training: 0.620395 validation: 0.583140
09/17 01:19:27 AM: edges-pos-ontonotes_precision: training: 0.869260 validation: 0.894390
09/17 01:19:27 AM: edges-pos-ontonotes_recall: training: 0.637247 validation: 0.586558
09/17 01:19:27 AM: edges-pos-ontonotes_f1: training: 0.735388 validation: 0.708481
09/17 01:19:27 AM: Global learning rate: 0.0001
09/17 01:19:27 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:19:37 AM: Update 21083: task edges-pos-ontonotes, batch 83 (21083): mcc: 0.7486, acc: 0.6306, precision: 0.8779, recall: 0.6458, f1: 0.7442, edges-pos-ontonotes_loss: 0.0251
09/17 01:19:47 AM: Update 21156: task edges-pos-ontonotes, batch 156 (21156): mcc: 0.7362, acc: 0.6119, precision: 0.8746, recall: 0.6273, f1: 0.7306, edges-pos-ontonotes_loss: 0.0270
09/17 01:19:57 AM: Update 21250: task edges-pos-ontonotes, batch 250 (21250): mcc: 0.7347, acc: 0.6083, precision: 0.8749, recall: 0.6245, f1: 0.7288, edges-pos-ontonotes_loss: 0.0273
09/17 01:20:07 AM: Update 21343: task edges-pos-ontonotes, batch 343 (21343): mcc: 0.7336, acc: 0.6067, precision: 0.8748, recall: 0.6228, f1: 0.7276, edges-pos-ontonotes_loss: 0.0273
09/17 01:20:22 AM: Update 21387: task edges-pos-ontonotes, batch 387 (21387): mcc: 0.7332, acc: 0.6062, precision: 0.8744, recall: 0.6225, f1: 0.7272, edges-pos-ontonotes_loss: 0.0273
09/17 01:20:32 AM: Update 21453: task edges-pos-ontonotes, batch 453 (21453): mcc: 0.7266, acc: 0.5976, precision: 0.8701, recall: 0.6145, f1: 0.7203, edges-pos-ontonotes_loss: 0.0281
09/17 01:20:42 AM: Update 21517: task edges-pos-ontonotes, batch 517 (21517): mcc: 0.7229, acc: 0.5932, precision: 0.8676, recall: 0.6100, f1: 0.7164, edges-pos-ontonotes_loss: 0.0285
09/17 01:20:53 AM: Update 21590: task edges-pos-ontonotes, batch 590 (21590): mcc: 0.7208, acc: 0.5907, precision: 0.8667, recall: 0.6073, f1: 0.7142, edges-pos-ontonotes_loss: 0.0290
09/17 01:21:03 AM: Update 21664: task edges-pos-ontonotes, batch 664 (21664): mcc: 0.7197, acc: 0.5893, precision: 0.8661, recall: 0.6059, f1: 0.7130, edges-pos-ontonotes_loss: 0.0292
09/17 01:21:13 AM: Update 21719: task edges-pos-ontonotes, batch 719 (21719): mcc: 0.7184, acc: 0.5875, precision: 0.8656, recall: 0.6041, f1: 0.7116, edges-pos-ontonotes_loss: 0.0294
09/17 01:21:23 AM: Update 21782: task edges-pos-ontonotes, batch 782 (21782): mcc: 0.7168, acc: 0.5852, precision: 0.8654, recall: 0.6016, f1: 0.7098, edges-pos-ontonotes_loss: 0.0297
09/17 01:21:33 AM: Update 21846: task edges-pos-ontonotes, batch 846 (21846): mcc: 0.7160, acc: 0.5840, precision: 0.8658, recall: 0.6000, f1: 0.7088, edges-pos-ontonotes_loss: 0.0298
09/17 01:21:43 AM: Update 21908: task edges-pos-ontonotes, batch 908 (21908): mcc: 0.7154, acc: 0.5828, precision: 0.8664, recall: 0.5986, f1: 0.7080, edges-pos-ontonotes_loss: 0.0299
09/17 01:21:53 AM: Update 21979: task edges-pos-ontonotes, batch 979 (21979): mcc: 0.7150, acc: 0.5822, precision: 0.8668, recall: 0.5976, f1: 0.7075, edges-pos-ontonotes_loss: 0.0300
09/17 01:21:56 AM: ***** Step 22000 / Validation 22 *****
09/17 01:21:56 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:21:56 AM: Validating...
09/17 01:22:03 AM: Evaluate: task edges-pos-ontonotes, batch 71 (157): mcc: 0.7506, acc: 0.6364, precision: 0.8938, recall: 0.6374, f1: 0.7441, edges-pos-ontonotes_loss: 0.0270
09/17 01:22:13 AM: Evaluate: task edges-pos-ontonotes, batch 140 (157): mcc: 0.7334, acc: 0.6054, precision: 0.8932, recall: 0.6094, f1: 0.7245, edges-pos-ontonotes_loss: 0.0279
09/17 01:22:16 AM: Updating LR scheduler:
09/17 01:22:16 AM: 	Best result seen so far for macro_avg: 0.724
09/17 01:22:16 AM: 	# validation passes without improvement: 0
09/17 01:22:16 AM: edges-pos-ontonotes_loss: training: 0.030060 validation: 0.028103
09/17 01:22:16 AM: macro_avg: validation: 0.722619
09/17 01:22:16 AM: micro_avg: validation: 0.000000
09/17 01:22:16 AM: edges-pos-ontonotes_mcc: training: 0.714868 validation: 0.731825
09/17 01:22:16 AM: edges-pos-ontonotes_acc: training: 0.581929 validation: 0.603151
09/17 01:22:16 AM: edges-pos-ontonotes_precision: training: 0.866811 validation: 0.893351
09/17 01:22:16 AM: edges-pos-ontonotes_recall: training: 0.597357 validation: 0.606675
09/17 01:22:16 AM: edges-pos-ontonotes_f1: training: 0.707290 validation: 0.722619
09/17 01:22:16 AM: Global learning rate: 5e-05
09/17 01:22:16 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:22:23 AM: Update 22031: task edges-pos-ontonotes, batch 31 (22031): mcc: 0.7082, acc: 0.5725, precision: 0.8683, recall: 0.5854, f1: 0.6993, edges-pos-ontonotes_loss: 0.0316
09/17 01:22:33 AM: Update 22098: task edges-pos-ontonotes, batch 98 (22098): mcc: 0.7134, acc: 0.5781, precision: 0.8734, recall: 0.5904, f1: 0.7045, edges-pos-ontonotes_loss: 0.0313
09/17 01:22:43 AM: Update 22154: task edges-pos-ontonotes, batch 154 (22154): mcc: 0.7145, acc: 0.5794, precision: 0.8740, recall: 0.5918, f1: 0.7057, edges-pos-ontonotes_loss: 0.0311
09/17 01:22:54 AM: Update 22220: task edges-pos-ontonotes, batch 220 (22220): mcc: 0.7154, acc: 0.5800, precision: 0.8754, recall: 0.5922, f1: 0.7065, edges-pos-ontonotes_loss: 0.0310
09/17 01:23:04 AM: Update 22283: task edges-pos-ontonotes, batch 283 (22283): mcc: 0.7153, acc: 0.5800, precision: 0.8755, recall: 0.5919, f1: 0.7063, edges-pos-ontonotes_loss: 0.0310
09/17 01:23:14 AM: Update 22339: task edges-pos-ontonotes, batch 339 (22339): mcc: 0.7153, acc: 0.5799, precision: 0.8758, recall: 0.5919, f1: 0.7064, edges-pos-ontonotes_loss: 0.0310
09/17 01:23:24 AM: Update 22406: task edges-pos-ontonotes, batch 406 (22406): mcc: 0.7155, acc: 0.5798, precision: 0.8763, recall: 0.5917, f1: 0.7064, edges-pos-ontonotes_loss: 0.0310
09/17 01:23:34 AM: Update 22475: task edges-pos-ontonotes, batch 475 (22475): mcc: 0.7153, acc: 0.5795, precision: 0.8764, recall: 0.5914, f1: 0.7062, edges-pos-ontonotes_loss: 0.0310
09/17 01:23:44 AM: Update 22544: task edges-pos-ontonotes, batch 544 (22544): mcc: 0.7154, acc: 0.5795, precision: 0.8767, recall: 0.5914, f1: 0.7063, edges-pos-ontonotes_loss: 0.0310
09/17 01:23:54 AM: Update 22606: task edges-pos-ontonotes, batch 606 (22606): mcc: 0.7151, acc: 0.5790, precision: 0.8765, recall: 0.5910, f1: 0.7059, edges-pos-ontonotes_loss: 0.0310
09/17 01:24:04 AM: Update 22657: task edges-pos-ontonotes, batch 657 (22657): mcc: 0.7143, acc: 0.5782, precision: 0.8754, recall: 0.5904, f1: 0.7052, edges-pos-ontonotes_loss: 0.0309
09/17 01:24:14 AM: Update 22732: task edges-pos-ontonotes, batch 732 (22732): mcc: 0.7160, acc: 0.5801, precision: 0.8761, recall: 0.5927, f1: 0.7071, edges-pos-ontonotes_loss: 0.0305
09/17 01:24:24 AM: Update 22816: task edges-pos-ontonotes, batch 816 (22816): mcc: 0.7186, acc: 0.5831, precision: 0.8777, recall: 0.5959, f1: 0.7099, edges-pos-ontonotes_loss: 0.0300
09/17 01:24:34 AM: Update 22906: task edges-pos-ontonotes, batch 906 (22906): mcc: 0.7209, acc: 0.5856, precision: 0.8792, recall: 0.5986, f1: 0.7123, edges-pos-ontonotes_loss: 0.0295
09/17 01:24:44 AM: Update 22978: task edges-pos-ontonotes, batch 978 (22978): mcc: 0.7229, acc: 0.5879, precision: 0.8802, recall: 0.6012, f1: 0.7144, edges-pos-ontonotes_loss: 0.0292
09/17 01:24:46 AM: ***** Step 23000 / Validation 23 *****
09/17 01:24:46 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:24:46 AM: Validating...
09/17 01:24:54 AM: Evaluate: task edges-pos-ontonotes, batch 79 (157): mcc: 0.7469, acc: 0.6207, precision: 0.9075, recall: 0.6215, f1: 0.7378, edges-pos-ontonotes_loss: 0.0273
09/17 01:25:04 AM: Evaluate: task edges-pos-ontonotes, batch 145 (157): mcc: 0.7285, acc: 0.5907, precision: 0.9077, recall: 0.5915, f1: 0.7163, edges-pos-ontonotes_loss: 0.0282
09/17 01:25:06 AM: Updating LR scheduler:
09/17 01:25:06 AM: 	Best result seen so far for macro_avg: 0.724
09/17 01:25:06 AM: 	# validation passes without improvement: 1
09/17 01:25:06 AM: edges-pos-ontonotes_loss: training: 0.028997 validation: 0.028366
09/17 01:25:06 AM: macro_avg: validation: 0.714605
09/17 01:25:06 AM: micro_avg: validation: 0.000000
09/17 01:25:06 AM: edges-pos-ontonotes_mcc: training: 0.724049 validation: 0.727056
09/17 01:25:06 AM: edges-pos-ontonotes_acc: training: 0.589311 validation: 0.588463
09/17 01:25:06 AM: edges-pos-ontonotes_precision: training: 0.880685 validation: 0.907716
09/17 01:25:06 AM: edges-pos-ontonotes_recall: training: 0.602739 validation: 0.589246
09/17 01:25:06 AM: edges-pos-ontonotes_f1: training: 0.715673 validation: 0.714605
09/17 01:25:06 AM: Global learning rate: 5e-05
09/17 01:25:06 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:25:15 AM: Update 23093: task edges-pos-ontonotes, batch 93 (23093): mcc: 0.8093, acc: 0.7028, precision: 0.9155, recall: 0.7215, f1: 0.8070, edges-pos-ontonotes_loss: 0.0208
09/17 01:25:25 AM: Update 23204: task edges-pos-ontonotes, batch 204 (23204): mcc: 0.8132, acc: 0.7088, precision: 0.9160, recall: 0.7278, f1: 0.8112, edges-pos-ontonotes_loss: 0.0203
09/17 01:25:39 AM: Update 23265: task edges-pos-ontonotes, batch 265 (23265): mcc: 0.8134, acc: 0.7095, precision: 0.9155, recall: 0.7286, f1: 0.8114, edges-pos-ontonotes_loss: 0.0203
09/17 01:25:49 AM: Update 23408: task edges-pos-ontonotes, batch 408 (23408): mcc: 0.8108, acc: 0.7076, precision: 0.9121, recall: 0.7268, f1: 0.8090, edges-pos-ontonotes_loss: 0.0204
09/17 01:25:59 AM: Update 23543: task edges-pos-ontonotes, batch 543 (23543): mcc: 0.8109, acc: 0.7089, precision: 0.9106, recall: 0.7283, f1: 0.8093, edges-pos-ontonotes_loss: 0.0202
09/17 01:26:09 AM: Update 23672: task edges-pos-ontonotes, batch 672 (23672): mcc: 0.8081, acc: 0.7060, precision: 0.9076, recall: 0.7257, f1: 0.8065, edges-pos-ontonotes_loss: 0.0203
09/17 01:26:20 AM: Update 23845: task edges-pos-ontonotes, batch 845 (23845): mcc: 0.8043, acc: 0.7026, precision: 0.9041, recall: 0.7218, f1: 0.8028, edges-pos-ontonotes_loss: 0.0202
09/17 01:26:30 AM: Update 23928: task edges-pos-ontonotes, batch 928 (23928): mcc: 0.7942, acc: 0.6893, precision: 0.8992, recall: 0.7080, f1: 0.7922, edges-pos-ontonotes_loss: 0.0208
09/17 01:26:39 AM: ***** Step 24000 / Validation 24 *****
09/17 01:26:39 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:26:39 AM: Validating...
09/17 01:26:40 AM: Evaluate: task edges-pos-ontonotes, batch 7 (157): mcc: 0.7075, acc: 0.5613, precision: 0.9025, recall: 0.5616, f1: 0.6924, edges-pos-ontonotes_loss: 0.0295
09/17 01:26:50 AM: Evaluate: task edges-pos-ontonotes, batch 102 (157): mcc: 0.7422, acc: 0.6106, precision: 0.9091, recall: 0.6128, f1: 0.7321, edges-pos-ontonotes_loss: 0.0272
09/17 01:26:58 AM: Updating LR scheduler:
09/17 01:26:58 AM: 	Best result seen so far for macro_avg: 0.724
09/17 01:26:58 AM: 	# validation passes without improvement: 2
09/17 01:26:58 AM: edges-pos-ontonotes_loss: training: 0.021712 validation: 0.028772
09/17 01:26:58 AM: macro_avg: validation: 0.703176
09/17 01:26:58 AM: micro_avg: validation: 0.000000
09/17 01:26:58 AM: edges-pos-ontonotes_mcc: training: 0.782479 validation: 0.716615
09/17 01:26:58 AM: edges-pos-ontonotes_acc: training: 0.673254 validation: 0.573785
09/17 01:26:58 AM: edges-pos-ontonotes_precision: training: 0.893947 validation: 0.902795
09/17 01:26:58 AM: edges-pos-ontonotes_recall: training: 0.691695 validation: 0.575849
09/17 01:26:58 AM: edges-pos-ontonotes_f1: training: 0.779922 validation: 0.703176
09/17 01:26:58 AM: Global learning rate: 5e-05
09/17 01:26:58 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:27:00 AM: Update 24012: task edges-pos-ontonotes, batch 12 (24012): mcc: 0.6963, acc: 0.5595, precision: 0.8551, recall: 0.5751, f1: 0.6877, edges-pos-ontonotes_loss: 0.0328
09/17 01:27:10 AM: Update 24078: task edges-pos-ontonotes, batch 78 (24078): mcc: 0.6983, acc: 0.5624, precision: 0.8554, recall: 0.5782, f1: 0.6900, edges-pos-ontonotes_loss: 0.0330
09/17 01:27:20 AM: Update 24158: task edges-pos-ontonotes, batch 158 (24158): mcc: 0.7014, acc: 0.5655, precision: 0.8575, recall: 0.5817, f1: 0.6932, edges-pos-ontonotes_loss: 0.0324
09/17 01:27:30 AM: Update 24222: task edges-pos-ontonotes, batch 222 (24222): mcc: 0.7024, acc: 0.5674, precision: 0.8571, recall: 0.5836, f1: 0.6944, edges-pos-ontonotes_loss: 0.0324
09/17 01:27:40 AM: Update 24336: task edges-pos-ontonotes, batch 336 (24336): mcc: 0.7142, acc: 0.5832, precision: 0.8622, recall: 0.5995, f1: 0.7072, edges-pos-ontonotes_loss: 0.0298
09/17 01:27:50 AM: Update 24451: task edges-pos-ontonotes, batch 451 (24451): mcc: 0.7221, acc: 0.5942, precision: 0.8655, recall: 0.6103, f1: 0.7158, edges-pos-ontonotes_loss: 0.0282
09/17 01:28:00 AM: Update 24541: task edges-pos-ontonotes, batch 541 (24541): mcc: 0.7262, acc: 0.6000, precision: 0.8673, recall: 0.6158, f1: 0.7202, edges-pos-ontonotes_loss: 0.0276
09/17 01:28:11 AM: Update 24623: task edges-pos-ontonotes, batch 623 (24623): mcc: 0.7262, acc: 0.5991, precision: 0.8685, recall: 0.6149, f1: 0.7200, edges-pos-ontonotes_loss: 0.0278
09/17 01:28:21 AM: Update 24722: task edges-pos-ontonotes, batch 722 (24722): mcc: 0.7268, acc: 0.5997, precision: 0.8692, recall: 0.6154, f1: 0.7206, edges-pos-ontonotes_loss: 0.0278
09/17 01:28:31 AM: Update 24805: task edges-pos-ontonotes, batch 805 (24805): mcc: 0.7272, acc: 0.6000, precision: 0.8698, recall: 0.6157, f1: 0.7210, edges-pos-ontonotes_loss: 0.0277
09/17 01:28:41 AM: Update 24868: task edges-pos-ontonotes, batch 868 (24868): mcc: 0.7265, acc: 0.5987, precision: 0.8692, recall: 0.6148, f1: 0.7202, edges-pos-ontonotes_loss: 0.0279
09/17 01:28:51 AM: Update 24934: task edges-pos-ontonotes, batch 934 (24934): mcc: 0.7239, acc: 0.5953, precision: 0.8679, recall: 0.6115, f1: 0.7175, edges-pos-ontonotes_loss: 0.0282
09/17 01:29:01 AM: Update 24990: task edges-pos-ontonotes, batch 990 (24990): mcc: 0.7226, acc: 0.5936, precision: 0.8670, recall: 0.6100, f1: 0.7161, edges-pos-ontonotes_loss: 0.0283
09/17 01:29:03 AM: ***** Step 25000 / Validation 25 *****
09/17 01:29:03 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:29:03 AM: Validating...
09/17 01:29:11 AM: Evaluate: task edges-pos-ontonotes, batch 78 (157): mcc: 0.7570, acc: 0.6470, precision: 0.8937, recall: 0.6482, f1: 0.7514, edges-pos-ontonotes_loss: 0.0262
09/17 01:29:21 AM: Evaluate: task edges-pos-ontonotes, batch 145 (157): mcc: 0.7363, acc: 0.6117, precision: 0.8950, recall: 0.6129, f1: 0.7276, edges-pos-ontonotes_loss: 0.0276
09/17 01:29:23 AM: Best result seen so far for edges-pos-ontonotes.
09/17 01:29:23 AM: Best result seen so far for macro.
09/17 01:29:23 AM: Updating LR scheduler:
09/17 01:29:23 AM: 	Best result seen so far for macro_avg: 0.725
09/17 01:29:23 AM: 	# validation passes without improvement: 0
09/17 01:29:23 AM: edges-pos-ontonotes_loss: training: 0.028357 validation: 0.027806
09/17 01:29:23 AM: macro_avg: validation: 0.725466
09/17 01:29:23 AM: micro_avg: validation: 0.000000
09/17 01:29:23 AM: edges-pos-ontonotes_mcc: training: 0.722522 validation: 0.734438
09/17 01:29:23 AM: edges-pos-ontonotes_acc: training: 0.593520 validation: 0.608951
09/17 01:29:23 AM: edges-pos-ontonotes_precision: training: 0.866952 validation: 0.894467
09/17 01:29:23 AM: edges-pos-ontonotes_recall: training: 0.609928 validation: 0.610178
09/17 01:29:23 AM: edges-pos-ontonotes_f1: training: 0.716075 validation: 0.725466
09/17 01:29:23 AM: Global learning rate: 5e-05
09/17 01:29:23 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:29:31 AM: Update 25037: task edges-pos-ontonotes, batch 37 (25037): mcc: 0.7084, acc: 0.5732, precision: 0.8632, recall: 0.5893, f1: 0.7004, edges-pos-ontonotes_loss: 0.0325
09/17 01:29:41 AM: Update 25097: task edges-pos-ontonotes, batch 97 (25097): mcc: 0.7078, acc: 0.5737, precision: 0.8593, recall: 0.5911, f1: 0.7004, edges-pos-ontonotes_loss: 0.0317
09/17 01:30:00 AM: Update 25160: task edges-pos-ontonotes, batch 160 (25160): mcc: 0.7081, acc: 0.5743, precision: 0.8593, recall: 0.5915, f1: 0.7007, edges-pos-ontonotes_loss: 0.0318
09/17 01:30:10 AM: Update 25228: task edges-pos-ontonotes, batch 228 (25228): mcc: 0.7071, acc: 0.5724, precision: 0.8608, recall: 0.5888, f1: 0.6993, edges-pos-ontonotes_loss: 0.0319
09/17 01:30:20 AM: Update 25292: task edges-pos-ontonotes, batch 292 (25292): mcc: 0.7068, acc: 0.5720, precision: 0.8618, recall: 0.5876, f1: 0.6987, edges-pos-ontonotes_loss: 0.0319
09/17 01:30:30 AM: Update 25358: task edges-pos-ontonotes, batch 358 (25358): mcc: 0.7067, acc: 0.5715, precision: 0.8628, recall: 0.5868, f1: 0.6985, edges-pos-ontonotes_loss: 0.0319
09/17 01:30:40 AM: Update 25420: task edges-pos-ontonotes, batch 420 (25420): mcc: 0.7071, acc: 0.5719, precision: 0.8638, recall: 0.5867, f1: 0.6988, edges-pos-ontonotes_loss: 0.0318
09/17 01:30:50 AM: Update 25474: task edges-pos-ontonotes, batch 474 (25474): mcc: 0.7071, acc: 0.5719, precision: 0.8639, recall: 0.5866, f1: 0.6987, edges-pos-ontonotes_loss: 0.0317
09/17 01:31:00 AM: Update 25542: task edges-pos-ontonotes, batch 542 (25542): mcc: 0.7081, acc: 0.5729, precision: 0.8651, recall: 0.5874, f1: 0.6997, edges-pos-ontonotes_loss: 0.0317
09/17 01:31:10 AM: Update 25610: task edges-pos-ontonotes, batch 610 (25610): mcc: 0.7085, acc: 0.5734, precision: 0.8658, recall: 0.5877, f1: 0.7001, edges-pos-ontonotes_loss: 0.0317
09/17 01:31:21 AM: Update 25677: task edges-pos-ontonotes, batch 677 (25677): mcc: 0.7090, acc: 0.5739, precision: 0.8666, recall: 0.5880, f1: 0.7006, edges-pos-ontonotes_loss: 0.0316
09/17 01:31:31 AM: Update 25744: task edges-pos-ontonotes, batch 744 (25744): mcc: 0.7097, acc: 0.5746, precision: 0.8671, recall: 0.5886, f1: 0.7012, edges-pos-ontonotes_loss: 0.0315
09/17 01:31:41 AM: Update 25799: task edges-pos-ontonotes, batch 799 (25799): mcc: 0.7102, acc: 0.5754, precision: 0.8676, recall: 0.5892, f1: 0.7018, edges-pos-ontonotes_loss: 0.0315
09/17 01:31:51 AM: Update 25859: task edges-pos-ontonotes, batch 859 (25859): mcc: 0.7104, acc: 0.5755, precision: 0.8680, recall: 0.5892, f1: 0.7019, edges-pos-ontonotes_loss: 0.0314
09/17 01:32:01 AM: Update 25895: task edges-pos-ontonotes, batch 895 (25895): mcc: 0.7106, acc: 0.5756, precision: 0.8683, recall: 0.5893, f1: 0.7021, edges-pos-ontonotes_loss: 0.0314
09/17 01:32:11 AM: Update 25957: task edges-pos-ontonotes, batch 957 (25957): mcc: 0.7108, acc: 0.5757, precision: 0.8688, recall: 0.5893, f1: 0.7023, edges-pos-ontonotes_loss: 0.0314
09/17 01:32:18 AM: ***** Step 26000 / Validation 26 *****
09/17 01:32:18 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:32:18 AM: Validating...
09/17 01:32:21 AM: Evaluate: task edges-pos-ontonotes, batch 36 (157): mcc: 0.7370, acc: 0.6163, precision: 0.8907, recall: 0.6169, f1: 0.7290, edges-pos-ontonotes_loss: 0.0280
09/17 01:32:31 AM: Evaluate: task edges-pos-ontonotes, batch 118 (157): mcc: 0.7390, acc: 0.6152, precision: 0.8942, recall: 0.6178, f1: 0.7308, edges-pos-ontonotes_loss: 0.0275
09/17 01:32:38 AM: Updating LR scheduler:
09/17 01:32:38 AM: 	Best result seen so far for macro_avg: 0.725
09/17 01:32:38 AM: 	# validation passes without improvement: 1
09/17 01:32:38 AM: edges-pos-ontonotes_loss: training: 0.031384 validation: 0.028120
09/17 01:32:38 AM: macro_avg: validation: 0.721678
09/17 01:32:38 AM: micro_avg: validation: 0.000000
09/17 01:32:38 AM: edges-pos-ontonotes_mcc: training: 0.711076 validation: 0.730947
09/17 01:32:38 AM: edges-pos-ontonotes_acc: training: 0.575945 validation: 0.602199
09/17 01:32:38 AM: edges-pos-ontonotes_precision: training: 0.869042 validation: 0.892883
09/17 01:32:38 AM: edges-pos-ontonotes_recall: training: 0.589579 validation: 0.605564
09/17 01:32:38 AM: edges-pos-ontonotes_f1: training: 0.702539 validation: 0.721678
09/17 01:32:38 AM: Global learning rate: 5e-05
09/17 01:32:38 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:32:42 AM: Update 26028: task edges-pos-ontonotes, batch 28 (26028): mcc: 0.7099, acc: 0.5737, precision: 0.8727, recall: 0.5852, f1: 0.7006, edges-pos-ontonotes_loss: 0.0310
09/17 01:32:53 AM: Update 26099: task edges-pos-ontonotes, batch 99 (26099): mcc: 0.7115, acc: 0.5759, precision: 0.8731, recall: 0.5874, f1: 0.7023, edges-pos-ontonotes_loss: 0.0309
09/17 01:33:03 AM: Update 26181: task edges-pos-ontonotes, batch 181 (26181): mcc: 0.7221, acc: 0.5888, precision: 0.8765, recall: 0.6024, f1: 0.7141, edges-pos-ontonotes_loss: 0.0289
09/17 01:33:14 AM: Update 26261: task edges-pos-ontonotes, batch 261 (26261): mcc: 0.7255, acc: 0.5921, precision: 0.8788, recall: 0.6065, f1: 0.7177, edges-pos-ontonotes_loss: 0.0281
09/17 01:33:24 AM: Update 26342: task edges-pos-ontonotes, batch 342 (26342): mcc: 0.7305, acc: 0.5972, precision: 0.8829, recall: 0.6118, f1: 0.7228, edges-pos-ontonotes_loss: 0.0274
09/17 01:33:34 AM: Update 26413: task edges-pos-ontonotes, batch 413 (26413): mcc: 0.7333, acc: 0.6002, precision: 0.8847, recall: 0.6151, f1: 0.7257, edges-pos-ontonotes_loss: 0.0270
09/17 01:33:44 AM: Update 26524: task edges-pos-ontonotes, batch 524 (26524): mcc: 0.7455, acc: 0.6162, precision: 0.8898, recall: 0.6318, f1: 0.7389, edges-pos-ontonotes_loss: 0.0257
09/17 01:33:54 AM: Update 26636: task edges-pos-ontonotes, batch 636 (26636): mcc: 0.7554, acc: 0.6294, precision: 0.8938, recall: 0.6455, f1: 0.7496, edges-pos-ontonotes_loss: 0.0247
09/17 01:34:04 AM: Update 26733: task edges-pos-ontonotes, batch 733 (26733): mcc: 0.7618, acc: 0.6383, precision: 0.8957, recall: 0.6548, f1: 0.7566, edges-pos-ontonotes_loss: 0.0241
09/17 01:34:14 AM: Update 26855: task edges-pos-ontonotes, batch 855 (26855): mcc: 0.7665, acc: 0.6453, precision: 0.8967, recall: 0.6621, f1: 0.7617, edges-pos-ontonotes_loss: 0.0236
09/17 01:34:24 AM: ***** Step 27000 / Validation 27 *****
09/17 01:34:24 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:34:24 AM: Validating...
09/17 01:34:24 AM: Evaluate: task edges-pos-ontonotes, batch 1 (157): mcc: 0.7201, acc: 0.5775, precision: 0.9088, recall: 0.5775, f1: 0.7062, edges-pos-ontonotes_loss: 0.0286
09/17 01:34:34 AM: Evaluate: task edges-pos-ontonotes, batch 98 (157): mcc: 0.7417, acc: 0.6184, precision: 0.8980, recall: 0.6195, f1: 0.7332, edges-pos-ontonotes_loss: 0.0274
09/17 01:34:44 AM: Updating LR scheduler:
09/17 01:34:44 AM: 	Best result seen so far for macro_avg: 0.725
09/17 01:34:44 AM: 	# validation passes without improvement: 2
09/17 01:34:44 AM: edges-pos-ontonotes_loss: training: 0.022967 validation: 0.029021
09/17 01:34:44 AM: macro_avg: validation: 0.701032
09/17 01:34:44 AM: micro_avg: validation: 0.000000
09/17 01:34:44 AM: edges-pos-ontonotes_mcc: training: 0.770841 validation: 0.712392
09/17 01:34:44 AM: edges-pos-ontonotes_acc: training: 0.651876 validation: 0.575923
09/17 01:34:44 AM: edges-pos-ontonotes_precision: training: 0.897407 validation: 0.886942
09/17 01:34:44 AM: edges-pos-ontonotes_recall: training: 0.668962 validation: 0.579553
09/17 01:34:44 AM: edges-pos-ontonotes_f1: training: 0.766526 validation: 0.701032
09/17 01:34:44 AM: Global learning rate: 5e-05
09/17 01:34:44 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:34:45 AM: Update 27008: task edges-pos-ontonotes, batch 8 (27008): mcc: 0.8005, acc: 0.7032, precision: 0.8999, recall: 0.7185, f1: 0.7990, edges-pos-ontonotes_loss: 0.0197
09/17 01:34:55 AM: Update 27124: task edges-pos-ontonotes, batch 124 (27124): mcc: 0.7840, acc: 0.6799, precision: 0.8877, recall: 0.6992, f1: 0.7823, edges-pos-ontonotes_loss: 0.0202
09/17 01:35:05 AM: Update 27300: task edges-pos-ontonotes, batch 300 (27300): mcc: 0.7882, acc: 0.6894, precision: 0.8875, recall: 0.7068, f1: 0.7869, edges-pos-ontonotes_loss: 0.0202
09/17 01:35:18 AM: Update 27351: task edges-pos-ontonotes, batch 351 (27351): mcc: 0.7867, acc: 0.6877, precision: 0.8867, recall: 0.7049, f1: 0.7854, edges-pos-ontonotes_loss: 0.0200
09/17 01:35:28 AM: Update 27423: task edges-pos-ontonotes, batch 423 (27423): mcc: 0.7559, acc: 0.6440, precision: 0.8740, recall: 0.6611, f1: 0.7528, edges-pos-ontonotes_loss: 0.0224
09/17 01:35:38 AM: Update 27500: task edges-pos-ontonotes, batch 500 (27500): mcc: 0.7425, acc: 0.6248, precision: 0.8696, recall: 0.6417, f1: 0.7384, edges-pos-ontonotes_loss: 0.0240
09/17 01:35:48 AM: Update 27572: task edges-pos-ontonotes, batch 572 (27572): mcc: 0.7344, acc: 0.6129, precision: 0.8673, recall: 0.6295, f1: 0.7295, edges-pos-ontonotes_loss: 0.0250
09/17 01:35:58 AM: Update 27643: task edges-pos-ontonotes, batch 643 (27643): mcc: 0.7289, acc: 0.6052, precision: 0.8649, recall: 0.6221, f1: 0.7237, edges-pos-ontonotes_loss: 0.0259
09/17 01:36:08 AM: Update 27716: task edges-pos-ontonotes, batch 716 (27716): mcc: 0.7275, acc: 0.6030, precision: 0.8644, recall: 0.6200, f1: 0.7221, edges-pos-ontonotes_loss: 0.0262
09/17 01:36:18 AM: Update 27831: task edges-pos-ontonotes, batch 831 (27831): mcc: 0.7306, acc: 0.6074, precision: 0.8659, recall: 0.6242, f1: 0.7254, edges-pos-ontonotes_loss: 0.0259
09/17 01:36:28 AM: Update 27946: task edges-pos-ontonotes, batch 946 (27946): mcc: 0.7335, acc: 0.6112, precision: 0.8676, recall: 0.6279, f1: 0.7285, edges-pos-ontonotes_loss: 0.0257
09/17 01:36:35 AM: ***** Step 28000 / Validation 28 *****
09/17 01:36:35 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:36:35 AM: Validating...
09/17 01:36:38 AM: Evaluate: task edges-pos-ontonotes, batch 26 (157): mcc: 0.7302, acc: 0.6062, precision: 0.8878, recall: 0.6078, f1: 0.7216, edges-pos-ontonotes_loss: 0.0285
09/17 01:36:48 AM: Evaluate: task edges-pos-ontonotes, batch 112 (157): mcc: 0.7395, acc: 0.6175, precision: 0.8914, recall: 0.6207, f1: 0.7318, edges-pos-ontonotes_loss: 0.0270
09/17 01:36:55 AM: Updating LR scheduler:
09/17 01:36:55 AM: 	Best result seen so far for macro_avg: 0.725
09/17 01:36:55 AM: 	# validation passes without improvement: 3
09/17 01:36:55 AM: edges-pos-ontonotes_loss: training: 0.025632 validation: 0.028312
09/17 01:36:55 AM: macro_avg: validation: 0.710795
09/17 01:36:55 AM: micro_avg: validation: 0.000000
09/17 01:36:55 AM: edges-pos-ontonotes_mcc: training: 0.734261 validation: 0.720159
09/17 01:36:55 AM: edges-pos-ontonotes_acc: training: 0.612099 validation: 0.590463
09/17 01:36:55 AM: edges-pos-ontonotes_precision: training: 0.868191 validation: 0.882917
09/17 01:36:55 AM: edges-pos-ontonotes_recall: training: 0.628692 validation: 0.594834
09/17 01:36:55 AM: edges-pos-ontonotes_f1: training: 0.729282 validation: 0.710795
09/17 01:36:55 AM: Global learning rate: 5e-05
09/17 01:36:55 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:36:58 AM: Update 28029: task edges-pos-ontonotes, batch 29 (28029): mcc: 0.7281, acc: 0.5961, precision: 0.8715, recall: 0.6159, f1: 0.7217, edges-pos-ontonotes_loss: 0.0285
09/17 01:37:08 AM: Update 28118: task edges-pos-ontonotes, batch 118 (28118): mcc: 0.7289, acc: 0.5995, precision: 0.8739, recall: 0.6156, f1: 0.7223, edges-pos-ontonotes_loss: 0.0280
09/17 01:37:18 AM: Update 28206: task edges-pos-ontonotes, batch 206 (28206): mcc: 0.7287, acc: 0.5995, precision: 0.8735, recall: 0.6156, f1: 0.7222, edges-pos-ontonotes_loss: 0.0281
09/17 01:37:28 AM: Update 28292: task edges-pos-ontonotes, batch 292 (28292): mcc: 0.7305, acc: 0.6014, precision: 0.8744, recall: 0.6179, f1: 0.7241, edges-pos-ontonotes_loss: 0.0278
09/17 01:37:38 AM: Update 28348: task edges-pos-ontonotes, batch 348 (28348): mcc: 0.7247, acc: 0.5940, precision: 0.8698, recall: 0.6115, f1: 0.7181, edges-pos-ontonotes_loss: 0.0283
09/17 01:37:48 AM: Update 28418: task edges-pos-ontonotes, batch 418 (28418): mcc: 0.7207, acc: 0.5891, precision: 0.8673, recall: 0.6066, f1: 0.7139, edges-pos-ontonotes_loss: 0.0290
09/17 01:37:58 AM: Update 28486: task edges-pos-ontonotes, batch 486 (28486): mcc: 0.7177, acc: 0.5859, precision: 0.8647, recall: 0.6035, f1: 0.7109, edges-pos-ontonotes_loss: 0.0294
09/17 01:38:08 AM: Update 28554: task edges-pos-ontonotes, batch 554 (28554): mcc: 0.7162, acc: 0.5841, precision: 0.8637, recall: 0.6018, f1: 0.7093, edges-pos-ontonotes_loss: 0.0296
09/17 01:38:20 AM: Update 28620: task edges-pos-ontonotes, batch 620 (28620): mcc: 0.7155, acc: 0.5834, precision: 0.8631, recall: 0.6010, f1: 0.7086, edges-pos-ontonotes_loss: 0.0298
09/17 01:38:30 AM: Update 28681: task edges-pos-ontonotes, batch 681 (28681): mcc: 0.7137, acc: 0.5811, precision: 0.8627, recall: 0.5983, f1: 0.7065, edges-pos-ontonotes_loss: 0.0301
09/17 01:38:40 AM: Update 28750: task edges-pos-ontonotes, batch 750 (28750): mcc: 0.7133, acc: 0.5804, precision: 0.8635, recall: 0.5972, f1: 0.7060, edges-pos-ontonotes_loss: 0.0302
09/17 01:38:50 AM: Update 28818: task edges-pos-ontonotes, batch 818 (28818): mcc: 0.7127, acc: 0.5795, precision: 0.8637, recall: 0.5960, f1: 0.7053, edges-pos-ontonotes_loss: 0.0303
09/17 01:39:00 AM: Update 28887: task edges-pos-ontonotes, batch 887 (28887): mcc: 0.7124, acc: 0.5789, precision: 0.8640, recall: 0.5952, f1: 0.7049, edges-pos-ontonotes_loss: 0.0304
09/17 01:39:10 AM: Update 28934: task edges-pos-ontonotes, batch 934 (28934): mcc: 0.7122, acc: 0.5789, precision: 0.8640, recall: 0.5950, f1: 0.7047, edges-pos-ontonotes_loss: 0.0305
09/17 01:39:20 AM: Update 28995: task edges-pos-ontonotes, batch 995 (28995): mcc: 0.7125, acc: 0.5791, precision: 0.8645, recall: 0.5951, f1: 0.7049, edges-pos-ontonotes_loss: 0.0305
09/17 01:39:21 AM: ***** Step 29000 / Validation 29 *****
09/17 01:39:21 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:39:21 AM: Validating...
09/17 01:39:30 AM: Evaluate: task edges-pos-ontonotes, batch 91 (157): mcc: 0.7496, acc: 0.6345, precision: 0.8936, recall: 0.6359, f1: 0.7431, edges-pos-ontonotes_loss: 0.0268
09/17 01:39:40 AM: Evaluate: task edges-pos-ontonotes, batch 155 (157): mcc: 0.7332, acc: 0.6061, precision: 0.8918, recall: 0.6100, f1: 0.7245, edges-pos-ontonotes_loss: 0.0279
09/17 01:39:40 AM: Updating LR scheduler:
09/17 01:39:40 AM: 	Best result seen so far for macro_avg: 0.725
09/17 01:39:40 AM: 	# validation passes without improvement: 0
09/17 01:39:40 AM: edges-pos-ontonotes_loss: training: 0.030488 validation: 0.027882
09/17 01:39:40 AM: macro_avg: validation: 0.724297
09/17 01:39:40 AM: micro_avg: validation: 0.000000
09/17 01:39:40 AM: edges-pos-ontonotes_mcc: training: 0.712546 validation: 0.733101
09/17 01:39:40 AM: edges-pos-ontonotes_acc: training: 0.579182 validation: 0.605702
09/17 01:39:40 AM: edges-pos-ontonotes_precision: training: 0.864584 validation: 0.892122
09/17 01:39:40 AM: edges-pos-ontonotes_recall: training: 0.595098 validation: 0.609617
09/17 01:39:40 AM: edges-pos-ontonotes_f1: training: 0.704965 validation: 0.724297
09/17 01:39:40 AM: Global learning rate: 2.5e-05
09/17 01:39:40 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:39:50 AM: Update 29058: task edges-pos-ontonotes, batch 58 (29058): mcc: 0.7185, acc: 0.5853, precision: 0.8748, recall: 0.5978, f1: 0.7103, edges-pos-ontonotes_loss: 0.0310
09/17 01:40:01 AM: Update 29122: task edges-pos-ontonotes, batch 122 (29122): mcc: 0.7165, acc: 0.5825, precision: 0.8744, recall: 0.5948, f1: 0.7080, edges-pos-ontonotes_loss: 0.0312
09/17 01:40:11 AM: Update 29189: task edges-pos-ontonotes, batch 189 (29189): mcc: 0.7156, acc: 0.5815, precision: 0.8734, recall: 0.5939, f1: 0.7071, edges-pos-ontonotes_loss: 0.0311
09/17 01:40:30 AM: Update 29246: task edges-pos-ontonotes, batch 246 (29246): mcc: 0.7157, acc: 0.5818, precision: 0.8732, recall: 0.5942, f1: 0.7072, edges-pos-ontonotes_loss: 0.0311
09/17 01:40:40 AM: Update 29298: task edges-pos-ontonotes, batch 298 (29298): mcc: 0.7148, acc: 0.5808, precision: 0.8729, recall: 0.5930, f1: 0.7062, edges-pos-ontonotes_loss: 0.0311
09/17 01:40:50 AM: Update 29342: task edges-pos-ontonotes, batch 342 (29342): mcc: 0.7138, acc: 0.5799, precision: 0.8719, recall: 0.5920, f1: 0.7052, edges-pos-ontonotes_loss: 0.0311
09/17 01:41:00 AM: Update 29391: task edges-pos-ontonotes, batch 391 (29391): mcc: 0.7133, acc: 0.5790, precision: 0.8718, recall: 0.5913, f1: 0.7047, edges-pos-ontonotes_loss: 0.0312
09/17 01:41:10 AM: Update 29440: task edges-pos-ontonotes, batch 440 (29440): mcc: 0.7133, acc: 0.5789, precision: 0.8720, recall: 0.5912, f1: 0.7047, edges-pos-ontonotes_loss: 0.0312
09/17 01:41:20 AM: Update 29490: task edges-pos-ontonotes, batch 490 (29490): mcc: 0.7136, acc: 0.5791, precision: 0.8722, recall: 0.5915, f1: 0.7049, edges-pos-ontonotes_loss: 0.0312
09/17 01:41:30 AM: Update 29535: task edges-pos-ontonotes, batch 535 (29535): mcc: 0.7138, acc: 0.5792, precision: 0.8725, recall: 0.5916, f1: 0.7051, edges-pos-ontonotes_loss: 0.0311
09/17 01:41:40 AM: Update 29575: task edges-pos-ontonotes, batch 575 (29575): mcc: 0.7134, acc: 0.5790, precision: 0.8719, recall: 0.5914, f1: 0.7048, edges-pos-ontonotes_loss: 0.0310
09/17 01:41:50 AM: Update 29651: task edges-pos-ontonotes, batch 651 (29651): mcc: 0.7158, acc: 0.5818, precision: 0.8726, recall: 0.5948, f1: 0.7074, edges-pos-ontonotes_loss: 0.0305
09/17 01:42:01 AM: Update 29740: task edges-pos-ontonotes, batch 740 (29740): mcc: 0.7184, acc: 0.5850, precision: 0.8739, recall: 0.5983, f1: 0.7103, edges-pos-ontonotes_loss: 0.0299
09/17 01:42:11 AM: Update 29819: task edges-pos-ontonotes, batch 819 (29819): mcc: 0.7204, acc: 0.5872, precision: 0.8751, recall: 0.6007, f1: 0.7124, edges-pos-ontonotes_loss: 0.0295
09/17 01:42:21 AM: Update 29902: task edges-pos-ontonotes, batch 902 (29902): mcc: 0.7236, acc: 0.5910, precision: 0.8769, recall: 0.6047, f1: 0.7158, edges-pos-ontonotes_loss: 0.0290
09/17 01:42:30 AM: ***** Step 30000 / Validation 30 *****
09/17 01:42:30 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:42:30 AM: Validating...
09/17 01:42:31 AM: Evaluate: task edges-pos-ontonotes, batch 12 (157): mcc: 0.7366, acc: 0.6030, precision: 0.9101, recall: 0.6030, f1: 0.7253, edges-pos-ontonotes_loss: 0.0285
09/17 01:42:41 AM: Evaluate: task edges-pos-ontonotes, batch 106 (157): mcc: 0.7439, acc: 0.6147, precision: 0.9095, recall: 0.6152, f1: 0.7339, edges-pos-ontonotes_loss: 0.0272
09/17 01:42:49 AM: Updating LR scheduler:
09/17 01:42:49 AM: 	Best result seen so far for macro_avg: 0.725
09/17 01:42:49 AM: 	# validation passes without improvement: 1
09/17 01:42:49 AM: edges-pos-ontonotes_loss: training: 0.028227 validation: 0.028061
09/17 01:42:49 AM: macro_avg: validation: 0.716854
09/17 01:42:49 AM: micro_avg: validation: 0.000000
09/17 01:42:49 AM: edges-pos-ontonotes_mcc: training: 0.729496 validation: 0.728932
09/17 01:42:49 AM: edges-pos-ontonotes_acc: training: 0.598397 validation: 0.591786
09/17 01:42:49 AM: edges-pos-ontonotes_precision: training: 0.879541 validation: 0.907458
09/17 01:42:49 AM: edges-pos-ontonotes_recall: training: 0.612521 validation: 0.592421
09/17 01:42:49 AM: edges-pos-ontonotes_f1: training: 0.722138 validation: 0.716854
09/17 01:42:49 AM: Global learning rate: 2.5e-05
09/17 01:42:49 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:42:51 AM: Update 30026: task edges-pos-ontonotes, batch 26 (30026): mcc: 0.8124, acc: 0.7077, precision: 0.9168, recall: 0.7259, f1: 0.8103, edges-pos-ontonotes_loss: 0.0204
09/17 01:43:01 AM: Update 30139: task edges-pos-ontonotes, batch 139 (30139): mcc: 0.8137, acc: 0.7102, precision: 0.9157, recall: 0.7290, f1: 0.8118, edges-pos-ontonotes_loss: 0.0204
09/17 01:43:11 AM: Update 30243: task edges-pos-ontonotes, batch 243 (30243): mcc: 0.8109, acc: 0.7083, precision: 0.9120, recall: 0.7271, f1: 0.8091, edges-pos-ontonotes_loss: 0.0206
09/17 01:43:21 AM: Update 30369: task edges-pos-ontonotes, batch 369 (30369): mcc: 0.8099, acc: 0.7082, precision: 0.9102, recall: 0.7269, f1: 0.8082, edges-pos-ontonotes_loss: 0.0204
09/17 01:43:31 AM: Update 30498: task edges-pos-ontonotes, batch 498 (30498): mcc: 0.8093, acc: 0.7080, precision: 0.9084, recall: 0.7272, f1: 0.8078, edges-pos-ontonotes_loss: 0.0203
09/17 01:43:41 AM: Update 30662: task edges-pos-ontonotes, batch 662 (30662): mcc: 0.8041, acc: 0.7022, precision: 0.9039, recall: 0.7217, f1: 0.8026, edges-pos-ontonotes_loss: 0.0204
09/17 01:43:52 AM: Update 30811: task edges-pos-ontonotes, batch 811 (30811): mcc: 0.8010, acc: 0.6992, precision: 0.9013, recall: 0.7183, f1: 0.7994, edges-pos-ontonotes_loss: 0.0203
09/17 01:44:03 AM: Update 30889: task edges-pos-ontonotes, batch 889 (30889): mcc: 0.7851, acc: 0.6774, precision: 0.8945, recall: 0.6959, f1: 0.7828, edges-pos-ontonotes_loss: 0.0215
09/17 01:44:13 AM: Update 30961: task edges-pos-ontonotes, batch 961 (30961): mcc: 0.7743, acc: 0.6626, precision: 0.8896, recall: 0.6808, f1: 0.7713, edges-pos-ontonotes_loss: 0.0223
09/17 01:44:18 AM: ***** Step 31000 / Validation 31 *****
09/17 01:44:18 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:44:18 AM: Validating...
09/17 01:44:23 AM: Evaluate: task edges-pos-ontonotes, batch 47 (157): mcc: 0.7456, acc: 0.6168, precision: 0.9104, recall: 0.6174, f1: 0.7358, edges-pos-ontonotes_loss: 0.0269
09/17 01:44:33 AM: Evaluate: task edges-pos-ontonotes, batch 126 (157): mcc: 0.7283, acc: 0.5920, precision: 0.9055, recall: 0.5928, f1: 0.7165, edges-pos-ontonotes_loss: 0.0277
09/17 01:44:38 AM: Updating LR scheduler:
09/17 01:44:38 AM: 	Best result seen so far for macro_avg: 0.725
09/17 01:44:38 AM: 	# validation passes without improvement: 2
09/17 01:44:38 AM: edges-pos-ontonotes_loss: training: 0.022767 validation: 0.028367
09/17 01:44:38 AM: macro_avg: validation: 0.705523
09/17 01:44:38 AM: micro_avg: validation: 0.000000
09/17 01:44:38 AM: edges-pos-ontonotes_mcc: training: 0.768716 validation: 0.718696
09/17 01:44:38 AM: edges-pos-ontonotes_acc: training: 0.655176 validation: 0.577902
09/17 01:44:38 AM: edges-pos-ontonotes_precision: training: 0.887071 validation: 0.903414
09/17 01:44:38 AM: edges-pos-ontonotes_recall: training: 0.673211 validation: 0.578749
09/17 01:44:38 AM: edges-pos-ontonotes_f1: training: 0.765485 validation: 0.705523
09/17 01:44:38 AM: Global learning rate: 2.5e-05
09/17 01:44:38 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:44:43 AM: Update 31036: task edges-pos-ontonotes, batch 36 (31036): mcc: 0.7009, acc: 0.5648, precision: 0.8596, recall: 0.5795, f1: 0.6923, edges-pos-ontonotes_loss: 0.0323
09/17 01:44:53 AM: Update 31106: task edges-pos-ontonotes, batch 106 (31106): mcc: 0.7016, acc: 0.5654, precision: 0.8586, recall: 0.5814, f1: 0.6933, edges-pos-ontonotes_loss: 0.0322
09/17 01:45:03 AM: Update 31184: task edges-pos-ontonotes, batch 184 (31184): mcc: 0.7094, acc: 0.5760, precision: 0.8613, recall: 0.5922, f1: 0.7019, edges-pos-ontonotes_loss: 0.0306
09/17 01:45:13 AM: Update 31293: task edges-pos-ontonotes, batch 293 (31293): mcc: 0.7217, acc: 0.5928, precision: 0.8659, recall: 0.6093, f1: 0.7152, edges-pos-ontonotes_loss: 0.0284
09/17 01:45:23 AM: Update 31401: task edges-pos-ontonotes, batch 401 (31401): mcc: 0.7284, acc: 0.6025, precision: 0.8685, recall: 0.6186, f1: 0.7226, edges-pos-ontonotes_loss: 0.0271
09/17 01:45:37 AM: Update 31454: task edges-pos-ontonotes, batch 454 (31454): mcc: 0.7310, acc: 0.6061, precision: 0.8700, recall: 0.6220, f1: 0.7254, edges-pos-ontonotes_loss: 0.0267
09/17 01:45:47 AM: Update 31519: task edges-pos-ontonotes, batch 519 (31519): mcc: 0.7307, acc: 0.6053, precision: 0.8710, recall: 0.6207, f1: 0.7249, edges-pos-ontonotes_loss: 0.0269
09/17 01:45:57 AM: Update 31580: task edges-pos-ontonotes, batch 580 (31580): mcc: 0.7306, acc: 0.6045, precision: 0.8718, recall: 0.6199, f1: 0.7246, edges-pos-ontonotes_loss: 0.0270
09/17 01:46:07 AM: Update 31649: task edges-pos-ontonotes, batch 649 (31649): mcc: 0.7303, acc: 0.6039, precision: 0.8722, recall: 0.6192, f1: 0.7242, edges-pos-ontonotes_loss: 0.0271
09/17 01:46:18 AM: Update 31716: task edges-pos-ontonotes, batch 716 (31716): mcc: 0.7301, acc: 0.6034, precision: 0.8724, recall: 0.6186, f1: 0.7239, edges-pos-ontonotes_loss: 0.0272
09/17 01:46:30 AM: Update 31767: task edges-pos-ontonotes, batch 767 (31767): mcc: 0.7298, acc: 0.6027, precision: 0.8725, recall: 0.6181, f1: 0.7236, edges-pos-ontonotes_loss: 0.0272
09/17 01:46:40 AM: Update 31816: task edges-pos-ontonotes, batch 816 (31816): mcc: 0.7267, acc: 0.5983, precision: 0.8703, recall: 0.6144, f1: 0.7203, edges-pos-ontonotes_loss: 0.0276
09/17 01:46:50 AM: Update 31881: task edges-pos-ontonotes, batch 881 (31881): mcc: 0.7242, acc: 0.5947, precision: 0.8689, recall: 0.6113, f1: 0.7177, edges-pos-ontonotes_loss: 0.0279
09/17 01:47:00 AM: Update 31947: task edges-pos-ontonotes, batch 947 (31947): mcc: 0.7228, acc: 0.5927, precision: 0.8685, recall: 0.6094, f1: 0.7162, edges-pos-ontonotes_loss: 0.0281
09/17 01:47:09 AM: ***** Step 32000 / Validation 32 *****
09/17 01:47:09 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:47:09 AM: Validating...
09/17 01:47:10 AM: Evaluate: task edges-pos-ontonotes, batch 17 (157): mcc: 0.7396, acc: 0.6162, precision: 0.8974, recall: 0.6166, f1: 0.7310, edges-pos-ontonotes_loss: 0.0282
09/17 01:47:20 AM: Evaluate: task edges-pos-ontonotes, batch 95 (157): mcc: 0.7518, acc: 0.6381, precision: 0.8941, recall: 0.6392, f1: 0.7455, edges-pos-ontonotes_loss: 0.0264
09/17 01:47:30 AM: Updating LR scheduler:
09/17 01:47:30 AM: 	Best result seen so far for macro_avg: 0.725
09/17 01:47:30 AM: 	# validation passes without improvement: 3
09/17 01:47:30 AM: edges-pos-ontonotes_loss: training: 0.028287 validation: 0.027761
09/17 01:47:30 AM: macro_avg: validation: 0.723972
09/17 01:47:30 AM: micro_avg: validation: 0.000000
09/17 01:47:30 AM: edges-pos-ontonotes_mcc: training: 0.721363 validation: 0.733039
09/17 01:47:30 AM: edges-pos-ontonotes_acc: training: 0.590848 validation: 0.607215
09/17 01:47:30 AM: edges-pos-ontonotes_precision: training: 0.867462 validation: 0.893682
09/17 01:47:30 AM: edges-pos-ontonotes_recall: training: 0.607638 validation: 0.608432
09/17 01:47:30 AM: edges-pos-ontonotes_f1: training: 0.714667 validation: 0.723972
09/17 01:47:30 AM: Global learning rate: 2.5e-05
09/17 01:47:30 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:47:30 AM: Update 32001: task edges-pos-ontonotes, batch 1 (32001): mcc: 0.7190, acc: 0.5927, precision: 0.8621, recall: 0.6075, f1: 0.7128, edges-pos-ontonotes_loss: 0.0303
09/17 01:47:40 AM: Update 32079: task edges-pos-ontonotes, batch 79 (32079): mcc: 0.7069, acc: 0.5710, precision: 0.8599, recall: 0.5891, f1: 0.6992, edges-pos-ontonotes_loss: 0.0320
09/17 01:47:51 AM: Update 32129: task edges-pos-ontonotes, batch 129 (32129): mcc: 0.7042, acc: 0.5683, precision: 0.8604, recall: 0.5844, f1: 0.6960, edges-pos-ontonotes_loss: 0.0321
09/17 01:48:01 AM: Update 32194: task edges-pos-ontonotes, batch 194 (32194): mcc: 0.7054, acc: 0.5690, precision: 0.8624, recall: 0.5849, f1: 0.6970, edges-pos-ontonotes_loss: 0.0319
09/17 01:48:11 AM: Update 32256: task edges-pos-ontonotes, batch 256 (32256): mcc: 0.7059, acc: 0.5694, precision: 0.8637, recall: 0.5849, f1: 0.6974, edges-pos-ontonotes_loss: 0.0319
09/17 01:48:21 AM: Update 32320: task edges-pos-ontonotes, batch 320 (32320): mcc: 0.7068, acc: 0.5702, precision: 0.8652, recall: 0.5853, f1: 0.6983, edges-pos-ontonotes_loss: 0.0318
09/17 01:48:31 AM: Update 32385: task edges-pos-ontonotes, batch 385 (32385): mcc: 0.7068, acc: 0.5704, precision: 0.8652, recall: 0.5851, f1: 0.6981, edges-pos-ontonotes_loss: 0.0317
09/17 01:48:41 AM: Update 32436: task edges-pos-ontonotes, batch 436 (32436): mcc: 0.7068, acc: 0.5709, precision: 0.8650, recall: 0.5854, f1: 0.6983, edges-pos-ontonotes_loss: 0.0318
09/17 01:48:51 AM: Update 32498: task edges-pos-ontonotes, batch 498 (32498): mcc: 0.7076, acc: 0.5718, precision: 0.8654, recall: 0.5864, f1: 0.6991, edges-pos-ontonotes_loss: 0.0317
09/17 01:49:02 AM: Update 32559: task edges-pos-ontonotes, batch 559 (32559): mcc: 0.7081, acc: 0.5726, precision: 0.8658, recall: 0.5870, f1: 0.6996, edges-pos-ontonotes_loss: 0.0316
09/17 01:49:12 AM: Update 32629: task edges-pos-ontonotes, batch 629 (32629): mcc: 0.7090, acc: 0.5738, precision: 0.8666, recall: 0.5879, f1: 0.7006, edges-pos-ontonotes_loss: 0.0315
09/17 01:49:22 AM: Update 32696: task edges-pos-ontonotes, batch 696 (32696): mcc: 0.7099, acc: 0.5747, precision: 0.8674, recall: 0.5888, f1: 0.7014, edges-pos-ontonotes_loss: 0.0315
09/17 01:49:32 AM: Update 32750: task edges-pos-ontonotes, batch 750 (32750): mcc: 0.7100, acc: 0.5749, precision: 0.8676, recall: 0.5888, f1: 0.7016, edges-pos-ontonotes_loss: 0.0315
09/17 01:49:42 AM: Update 32821: task edges-pos-ontonotes, batch 821 (32821): mcc: 0.7104, acc: 0.5753, precision: 0.8681, recall: 0.5891, f1: 0.7019, edges-pos-ontonotes_loss: 0.0314
09/17 01:49:52 AM: Update 32893: task edges-pos-ontonotes, batch 893 (32893): mcc: 0.7105, acc: 0.5754, precision: 0.8682, recall: 0.5893, f1: 0.7021, edges-pos-ontonotes_loss: 0.0314
09/17 01:50:02 AM: Update 32956: task edges-pos-ontonotes, batch 956 (32956): mcc: 0.7106, acc: 0.5755, precision: 0.8683, recall: 0.5892, f1: 0.7021, edges-pos-ontonotes_loss: 0.0314
09/17 01:50:10 AM: ***** Step 33000 / Validation 33 *****
09/17 01:50:10 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:50:10 AM: Validating...
09/17 01:50:12 AM: Evaluate: task edges-pos-ontonotes, batch 17 (157): mcc: 0.7304, acc: 0.6011, precision: 0.8978, recall: 0.6013, f1: 0.7202, edges-pos-ontonotes_loss: 0.0285
09/17 01:50:22 AM: Evaluate: task edges-pos-ontonotes, batch 101 (157): mcc: 0.7468, acc: 0.6288, precision: 0.8958, recall: 0.6297, f1: 0.7395, edges-pos-ontonotes_loss: 0.0269
09/17 01:50:31 AM: Updating LR scheduler:
09/17 01:50:31 AM: 	Best result seen so far for macro_avg: 0.725
09/17 01:50:31 AM: 	# validation passes without improvement: 0
09/17 01:50:31 AM: edges-pos-ontonotes_loss: training: 0.031400 validation: 0.027915
09/17 01:50:31 AM: macro_avg: validation: 0.723271
09/17 01:50:31 AM: micro_avg: validation: 0.000000
09/17 01:50:31 AM: edges-pos-ontonotes_mcc: training: 0.710642 validation: 0.732230
09/17 01:50:31 AM: edges-pos-ontonotes_acc: training: 0.575540 validation: 0.604591
09/17 01:50:31 AM: edges-pos-ontonotes_precision: training: 0.868462 validation: 0.892231
09/17 01:50:31 AM: edges-pos-ontonotes_recall: training: 0.589270 validation: 0.608115
09/17 01:50:31 AM: edges-pos-ontonotes_f1: training: 0.702130 validation: 0.723271
09/17 01:50:31 AM: Global learning rate: 1.25e-05
09/17 01:50:31 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:50:32 AM: Update 33009: task edges-pos-ontonotes, batch 9 (33009): mcc: 0.7049, acc: 0.5726, precision: 0.8580, recall: 0.5872, f1: 0.6972, edges-pos-ontonotes_loss: 0.0316
09/17 01:50:45 AM: Update 33019: task edges-pos-ontonotes, batch 19 (33019): mcc: 0.6976, acc: 0.5641, precision: 0.8523, recall: 0.5791, f1: 0.6896, edges-pos-ontonotes_loss: 0.0315
09/17 01:50:55 AM: Update 33095: task edges-pos-ontonotes, batch 95 (33095): mcc: 0.7252, acc: 0.5969, precision: 0.8688, recall: 0.6131, f1: 0.7189, edges-pos-ontonotes_loss: 0.0271
09/17 01:51:05 AM: Update 33179: task edges-pos-ontonotes, batch 179 (33179): mcc: 0.7308, acc: 0.6027, precision: 0.8727, recall: 0.6197, f1: 0.7247, edges-pos-ontonotes_loss: 0.0268
09/17 01:51:15 AM: Update 33249: task edges-pos-ontonotes, batch 249 (33249): mcc: 0.7348, acc: 0.6069, precision: 0.8763, recall: 0.6236, f1: 0.7287, edges-pos-ontonotes_loss: 0.0264
09/17 01:51:25 AM: Update 33311: task edges-pos-ontonotes, batch 311 (33311): mcc: 0.7358, acc: 0.6074, precision: 0.8781, recall: 0.6240, f1: 0.7295, edges-pos-ontonotes_loss: 0.0263
09/17 01:51:35 AM: Update 33379: task edges-pos-ontonotes, batch 379 (33379): mcc: 0.7429, acc: 0.6169, precision: 0.8815, recall: 0.6334, f1: 0.7372, edges-pos-ontonotes_loss: 0.0257
09/17 01:51:46 AM: Update 33469: task edges-pos-ontonotes, batch 469 (33469): mcc: 0.7531, acc: 0.6307, precision: 0.8859, recall: 0.6474, f1: 0.7481, edges-pos-ontonotes_loss: 0.0248
09/17 01:51:56 AM: Update 33553: task edges-pos-ontonotes, batch 553 (33553): mcc: 0.7601, acc: 0.6400, precision: 0.8889, recall: 0.6570, f1: 0.7556, edges-pos-ontonotes_loss: 0.0242
09/17 01:52:06 AM: Update 33654: task edges-pos-ontonotes, batch 654 (33654): mcc: 0.7663, acc: 0.6484, precision: 0.8918, recall: 0.6654, f1: 0.7622, edges-pos-ontonotes_loss: 0.0236
09/17 01:52:16 AM: Update 33780: task edges-pos-ontonotes, batch 780 (33780): mcc: 0.7710, acc: 0.6555, precision: 0.8931, recall: 0.6726, f1: 0.7673, edges-pos-ontonotes_loss: 0.0231
09/17 01:52:26 AM: Update 33915: task edges-pos-ontonotes, batch 915 (33915): mcc: 0.7746, acc: 0.6609, precision: 0.8939, recall: 0.6782, f1: 0.7712, edges-pos-ontonotes_loss: 0.0228
09/17 01:52:33 AM: ***** Step 34000 / Validation 34 *****
09/17 01:52:33 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:52:33 AM: Validating...
09/17 01:52:36 AM: Evaluate: task edges-pos-ontonotes, batch 32 (157): mcc: 0.7342, acc: 0.6051, precision: 0.9001, recall: 0.6059, f1: 0.7243, edges-pos-ontonotes_loss: 0.0279
09/17 01:52:46 AM: Evaluate: task edges-pos-ontonotes, batch 114 (157): mcc: 0.7382, acc: 0.6095, precision: 0.9007, recall: 0.6119, f1: 0.7288, edges-pos-ontonotes_loss: 0.0271
09/17 01:52:53 AM: Updating LR scheduler:
09/17 01:52:53 AM: 	Best result seen so far for macro_avg: 0.725
09/17 01:52:53 AM: 	# validation passes without improvement: 1
09/17 01:52:53 AM: edges-pos-ontonotes_loss: training: 0.022689 validation: 0.028045
09/17 01:52:53 AM: macro_avg: validation: 0.714091
09/17 01:52:53 AM: micro_avg: validation: 0.000000
09/17 01:52:53 AM: edges-pos-ontonotes_mcc: training: 0.775011 validation: 0.724819
09/17 01:52:53 AM: edges-pos-ontonotes_acc: training: 0.661600 validation: 0.590294
09/17 01:52:53 AM: edges-pos-ontonotes_precision: training: 0.893390 validation: 0.895580
09/17 01:52:53 AM: edges-pos-ontonotes_recall: training: 0.679193 validation: 0.593765
09/17 01:52:53 AM: edges-pos-ontonotes_f1: training: 0.771704 validation: 0.714091
09/17 01:52:53 AM: Global learning rate: 1.25e-05
09/17 01:52:53 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:52:56 AM: Update 34064: task edges-pos-ontonotes, batch 64 (34064): mcc: 0.7895, acc: 0.6898, precision: 0.8852, recall: 0.7109, f1: 0.7886, edges-pos-ontonotes_loss: 0.0203
09/17 01:53:06 AM: Update 34223: task edges-pos-ontonotes, batch 223 (34223): mcc: 0.7819, acc: 0.6809, precision: 0.8815, recall: 0.7006, f1: 0.7807, edges-pos-ontonotes_loss: 0.0206
09/17 01:53:16 AM: Update 34311: task edges-pos-ontonotes, batch 311 (34311): mcc: 0.7592, acc: 0.6492, precision: 0.8726, recall: 0.6680, f1: 0.7567, edges-pos-ontonotes_loss: 0.0222
09/17 01:53:26 AM: Update 34388: task edges-pos-ontonotes, batch 388 (34388): mcc: 0.7384, acc: 0.6203, precision: 0.8648, recall: 0.6383, f1: 0.7345, edges-pos-ontonotes_loss: 0.0244
09/17 01:53:36 AM: Update 34464: task edges-pos-ontonotes, batch 464 (34464): mcc: 0.7296, acc: 0.6075, precision: 0.8629, recall: 0.6248, f1: 0.7248, edges-pos-ontonotes_loss: 0.0256
09/17 01:53:46 AM: Update 34533: task edges-pos-ontonotes, batch 533 (34533): mcc: 0.7229, acc: 0.5982, precision: 0.8605, recall: 0.6152, f1: 0.7175, edges-pos-ontonotes_loss: 0.0266
09/17 01:53:57 AM: Update 34601: task edges-pos-ontonotes, batch 601 (34601): mcc: 0.7184, acc: 0.5921, precision: 0.8587, recall: 0.6091, f1: 0.7127, edges-pos-ontonotes_loss: 0.0273
09/17 01:54:08 AM: Update 34713: task edges-pos-ontonotes, batch 713 (34713): mcc: 0.7231, acc: 0.5979, precision: 0.8617, recall: 0.6146, f1: 0.7175, edges-pos-ontonotes_loss: 0.0269
09/17 01:54:18 AM: Update 34827: task edges-pos-ontonotes, batch 827 (34827): mcc: 0.7272, acc: 0.6029, precision: 0.8646, recall: 0.6194, f1: 0.7218, edges-pos-ontonotes_loss: 0.0265
09/17 01:54:28 AM: Update 34917: task edges-pos-ontonotes, batch 917 (34917): mcc: 0.7296, acc: 0.6061, precision: 0.8657, recall: 0.6226, f1: 0.7243, edges-pos-ontonotes_loss: 0.0262
09/17 01:54:38 AM: Update 34998: task edges-pos-ontonotes, batch 998 (34998): mcc: 0.7293, acc: 0.6052, precision: 0.8669, recall: 0.6214, f1: 0.7239, edges-pos-ontonotes_loss: 0.0264
09/17 01:54:38 AM: ***** Step 35000 / Validation 35 *****
09/17 01:54:38 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:54:38 AM: Validating...
09/17 01:54:48 AM: Evaluate: task edges-pos-ontonotes, batch 94 (157): mcc: 0.7460, acc: 0.6251, precision: 0.8988, recall: 0.6262, f1: 0.7381, edges-pos-ontonotes_loss: 0.0264
09/17 01:54:58 AM: Updating LR scheduler:
09/17 01:54:58 AM: 	Best result seen so far for macro_avg: 0.725
09/17 01:54:58 AM: 	# validation passes without improvement: 2
09/17 01:54:58 AM: Ran out of early stopping patience. Stopping training.
09/17 01:54:58 AM: edges-pos-ontonotes_loss: training: 0.026389 validation: 0.028017
09/17 01:54:58 AM: macro_avg: validation: 0.708988
09/17 01:54:58 AM: micro_avg: validation: 0.000000
09/17 01:54:58 AM: edges-pos-ontonotes_mcc: training: 0.729354 validation: 0.719455
09/17 01:54:58 AM: edges-pos-ontonotes_acc: training: 0.605233 validation: 0.586156
09/17 01:54:58 AM: edges-pos-ontonotes_precision: training: 0.866955 validation: 0.888770
09/17 01:54:58 AM: edges-pos-ontonotes_recall: training: 0.621342 validation: 0.589701
09/17 01:54:58 AM: edges-pos-ontonotes_f1: training: 0.723882 validation: 0.708988
09/17 01:54:58 AM: Global learning rate: 1.25e-05
09/17 01:54:58 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:54:58 AM: Stopped training after 35 validation checks
09/17 01:54:58 AM: Trained edges-pos-ontonotes for 35000 batches or 10.133 epochs
09/17 01:54:58 AM: ***** VALIDATION RESULTS *****
09/17 01:54:58 AM: edges-pos-ontonotes_f1 (for best val pass 25): edges-pos-ontonotes_loss: 0.02781, macro_avg: 0.72547, micro_avg: 0.00000, edges-pos-ontonotes_mcc: 0.73444, edges-pos-ontonotes_acc: 0.60895, edges-pos-ontonotes_precision: 0.89447, edges-pos-ontonotes_recall: 0.61018, edges-pos-ontonotes_f1: 0.72547
09/17 01:54:58 AM: micro_avg (for best val pass 1): edges-pos-ontonotes_loss: 0.09050, macro_avg: 0.54172, micro_avg: 0.00000, edges-pos-ontonotes_mcc: 0.56332, edges-pos-ontonotes_acc: 0.41106, edges-pos-ontonotes_precision: 0.78335, edges-pos-ontonotes_recall: 0.41401, edges-pos-ontonotes_f1: 0.54172
09/17 01:54:58 AM: macro_avg (for best val pass 25): edges-pos-ontonotes_loss: 0.02781, macro_avg: 0.72547, micro_avg: 0.00000, edges-pos-ontonotes_mcc: 0.73444, edges-pos-ontonotes_acc: 0.60895, edges-pos-ontonotes_precision: 0.89447, edges-pos-ontonotes_recall: 0.61018, edges-pos-ontonotes_f1: 0.72547
09/17 01:54:58 AM: Evaluating...
09/17 01:54:58 AM: Loaded model state from ./experiments/pos-ontonotes-RANDOM-only/run/edges-pos-ontonotes/model_state_target_train_val_25.best.th
09/17 01:54:58 AM: Evaluating on: edges-pos-ontonotes, split: val
09/17 01:55:28 AM: 	Task edges-pos-ontonotes: batch 200
09/17 01:55:58 AM: 	Task edges-pos-ontonotes: batch 324
09/17 01:56:13 AM: Task 'edges-pos-ontonotes': sorting predictions by 'idx'
09/17 01:56:13 AM: Finished evaluating on: edges-pos-ontonotes
09/17 01:56:14 AM: Task 'edges-pos-ontonotes': joining predictions with input split 'val'
09/17 01:56:25 AM: Task 'edges-pos-ontonotes': Wrote predictions to ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:56:25 AM: Wrote all preds for split 'val' to ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:56:25 AM: Evaluating on: edges-pos-ontonotes, split: test
09/17 01:56:55 AM: 	Task edges-pos-ontonotes: batch 195
09/17 01:57:15 AM: Task 'edges-pos-ontonotes': sorting predictions by 'idx'
09/17 01:57:15 AM: Finished evaluating on: edges-pos-ontonotes
09/17 01:57:15 AM: Task 'edges-pos-ontonotes': joining predictions with input split 'test'
09/17 01:57:23 AM: Task 'edges-pos-ontonotes': Wrote predictions to ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:57:23 AM: Wrote all preds for split 'test' to ./experiments/pos-ontonotes-RANDOM-only/run
09/17 01:57:23 AM: Writing results for split 'val' to ./experiments/pos-ontonotes-RANDOM-only/results.tsv
09/17 01:57:23 AM: micro_avg: 0.000, macro_avg: 0.725, edges-pos-ontonotes_mcc: 0.734, edges-pos-ontonotes_acc: 0.608, edges-pos-ontonotes_precision: 0.893, edges-pos-ontonotes_recall: 0.610, edges-pos-ontonotes_f1: 0.725
09/17 01:57:25 AM: Done!
09/17 01:57:25 AM: Fatal error in main():
Traceback (most recent call last):
  File "main.py", line 16, in <module>
    main(sys.argv[1:])
  File "/srv/home/ericwallace/jiant/jiant/__main__.py", line 610, in main
    exit("Done exited")
  File "/home/ericwallace/miniconda3/envs/jiant/lib/python3.6/_sitebuiltins.py", line 26, in __call__
    raise SystemExit(code)
SystemExit: Done exited
