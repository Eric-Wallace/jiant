09/16 05:59:29 AM: Git branch: master
09/16 05:59:29 AM: Git SHA: 03401462a9f5f9b569ed41ceca48ecd81700406f
09/16 05:59:29 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/ner-ontonotes-sts-top/",
  "exp_name": "experiments/ner-ontonotes-sts-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/ner-ontonotes-sts-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/sts",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/ner-ontonotes-sts-top__run",
  "run_dir": "./experiments/ner-ontonotes-sts-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-ner-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 05:59:29 AM: Saved config to ./experiments/ner-ontonotes-sts-top/run/params.conf
09/16 05:59:29 AM: Using random seed 1234
09/16 05:59:53 AM: Git branch: master
09/16 05:59:53 AM: Git SHA: 03401462a9f5f9b569ed41ceca48ecd81700406f
09/16 05:59:54 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/ner-ontonotes-sts-top/",
  "exp_name": "experiments/ner-ontonotes-sts-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/ner-ontonotes-sts-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/sts",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/ner-ontonotes-sts-top__run",
  "run_dir": "./experiments/ner-ontonotes-sts-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-ner-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 05:59:54 AM: Saved config to ./experiments/ner-ontonotes-sts-top/run/params.conf
09/16 05:59:54 AM: Using random seed 1234
09/16 06:00:33 AM: Using GPU 0
09/16 06:00:33 AM: Loading tasks...
09/16 06:00:33 AM: Writing pre-preprocessed tasks to ./experiments/ner-ontonotes-sts-top/
09/16 06:00:33 AM: 	Creating task edges-ner-ontonotes from scratch.
09/16 06:00:33 AM: Using GPU 0
09/16 06:00:33 AM: Loading tasks...
09/16 06:00:33 AM: Writing pre-preprocessed tasks to ./experiments/ner-ontonotes-sts-top/
09/16 06:00:33 AM: 	Creating task edges-ner-ontonotes from scratch.
09/16 06:00:35 AM: Read=49706, Skip=66106, Total=115812 from ./probing_data/edges/ontonotes/ner/train.json.retokenized.bert-base-uncased
09/16 06:00:35 AM: Read=49706, Skip=66106, Total=115812 from ./probing_data/edges/ontonotes/ner/train.json.retokenized.bert-base-uncased
09/16 06:00:35 AM: Read=7610, Skip=8070, Total=15680 from ./probing_data/edges/ontonotes/ner/development.json.retokenized.bert-base-uncased
09/16 06:00:35 AM: Read=5099, Skip=7118, Total=12217 from ./probing_data/edges/ontonotes/ner/test.json.retokenized.bert-base-uncased
09/16 06:00:35 AM: Read=7610, Skip=8070, Total=15680 from ./probing_data/edges/ontonotes/ner/development.json.retokenized.bert-base-uncased
09/16 06:00:36 AM: Read=5099, Skip=7118, Total=12217 from ./probing_data/edges/ontonotes/ner/test.json.retokenized.bert-base-uncased
09/16 06:00:38 AM: 	Task 'edges-ner-ontonotes': |train|=49706 |val|=7610 |test|=5099
09/16 06:00:38 AM: 	Finished loading tasks: edges-ner-ontonotes.
09/16 06:00:38 AM: 	Building vocab from scratch.
09/16 06:00:38 AM: 	Counting units for task edges-ner-ontonotes.
09/16 06:00:39 AM: 	Task 'edges-ner-ontonotes': |train|=49706 |val|=7610 |test|=5099
09/16 06:00:39 AM: 	Finished loading tasks: edges-ner-ontonotes.
09/16 06:00:39 AM: 	Building vocab from scratch.
09/16 06:00:39 AM: 	Counting units for task edges-ner-ontonotes.
09/16 06:00:41 AM: 	Task 'edges-ner-ontonotes': adding vocab namespace 'edges-ner-ontonotes_labels'
09/16 06:00:42 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpampns1jd
09/16 06:00:42 AM: 	Task 'edges-ner-ontonotes': adding vocab namespace 'edges-ner-ontonotes_labels'
09/16 06:00:43 AM: copying /tmp/tmpampns1jd to cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:43 AM: creating metadata file for /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:43 AM: removing temp file /tmp/tmpampns1jd
09/16 06:00:43 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:43 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 06:00:43 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:44 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 06:00:44 AM: 	Saved vocab to ./experiments/ner-ontonotes-sts-top/vocab
09/16 06:00:44 AM: Loading token dictionary from ./experiments/ner-ontonotes-sts-top/vocab.
09/16 06:00:44 AM: vocabulary serialization directory ./experiments/ner-ontonotes-sts-top/vocab is not empty
09/16 06:00:44 AM: 	Loaded vocab from ./experiments/ner-ontonotes-sts-top/vocab
09/16 06:00:44 AM: 	Vocab namespace edges-ner-ontonotes_labels: size 18
09/16 06:00:44 AM: 	Vocab namespace tokens: size 22840
09/16 06:00:44 AM: 	Vocab namespace bert_uncased: size 30524
09/16 06:00:44 AM: 	Vocab namespace chars: size 77
09/16 06:00:44 AM: 	Finished building vocab.
09/16 06:00:44 AM: 	Task edges-ner-ontonotes (train): Indexing from scratch.
09/16 06:00:44 AM: 	Saved vocab to ./experiments/ner-ontonotes-sts-top/vocab
09/16 06:00:44 AM: Loading token dictionary from ./experiments/ner-ontonotes-sts-top/vocab.
09/16 06:00:44 AM: 	Loaded vocab from ./experiments/ner-ontonotes-sts-top/vocab
09/16 06:00:44 AM: 	Vocab namespace edges-ner-ontonotes_labels: size 18
09/16 06:00:44 AM: 	Vocab namespace tokens: size 22840
09/16 06:00:44 AM: 	Vocab namespace bert_uncased: size 30524
09/16 06:00:44 AM: 	Vocab namespace chars: size 77
09/16 06:00:44 AM: 	Finished building vocab.
09/16 06:00:44 AM: 	Task 'edges-ner-ontonotes', split 'train': Found preprocessed copy in ./experiments/ner-ontonotes-sts-top/preproc/edges-ner-ontonotes__train_data
09/16 06:00:44 AM: 	Task edges-ner-ontonotes (val): Indexing from scratch.
09/16 06:00:46 AM: 	Task edges-ner-ontonotes (val): Saved 7610 instances to ./experiments/ner-ontonotes-sts-top/preproc/edges-ner-ontonotes__val_data
09/16 06:00:46 AM: 	Task edges-ner-ontonotes (test): Indexing from scratch.
09/16 06:00:48 AM: 	Task edges-ner-ontonotes (test): Saved 5099 instances to ./experiments/ner-ontonotes-sts-top/preproc/edges-ner-ontonotes__test_data
09/16 06:00:48 AM: 	Finished indexing tasks
09/16 06:00:48 AM: 	Creating trimmed target-only version of edges-ner-ontonotes train.
09/16 06:00:48 AM: 	  Training on 
09/16 06:00:48 AM: 	  Evaluating on edges-ner-ontonotes
09/16 06:00:48 AM: 	Finished loading tasks in 14.530s
09/16 06:00:48 AM: 	 Tasks: ['edges-ner-ontonotes']
09/16 06:00:48 AM: Building model...
09/16 06:00:48 AM: Using BERT model (bert-base-uncased).
09/16 06:00:48 AM: LOADING A FUNETUNED MODEL from: 
09/16 06:00:48 AM: models/sts
09/16 06:00:48 AM: loading configuration file models/sts/config.json
09/16 06:00:48 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "sts-b",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 06:00:48 AM: loading weights file models/sts/pytorch_model.bin
09/16 06:00:55 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpmojmxu49
09/16 06:00:57 AM: copying /tmp/tmpmojmxu49 to cache at ./experiments/ner-ontonotes-sts-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:57 AM: creating metadata file for ./experiments/ner-ontonotes-sts-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:57 AM: removing temp file /tmp/tmpmojmxu49
09/16 06:00:57 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/ner-ontonotes-sts-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:57 AM: Initializing parameters
09/16 06:00:57 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 06:00:57 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 06:00:57 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 06:00:57 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 06:00:57 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 06:00:57 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 06:00:57 AM: 	Task 'edges-ner-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-ner-ontonotes"
}
09/16 06:01:02 AM: 	Task edges-ner-ontonotes (train): Saved 49706 instances to ./experiments/ner-ontonotes-sts-top/preproc/edges-ner-ontonotes__train_data
09/16 06:01:02 AM: 	Task 'edges-ner-ontonotes', split 'val': Found preprocessed copy in ./experiments/ner-ontonotes-sts-top/preproc/edges-ner-ontonotes__val_data
09/16 06:01:02 AM: 	Task 'edges-ner-ontonotes', split 'test': Found preprocessed copy in ./experiments/ner-ontonotes-sts-top/preproc/edges-ner-ontonotes__test_data
09/16 06:01:02 AM: 	Finished indexing tasks
09/16 06:01:02 AM: 	Creating trimmed target-only version of edges-ner-ontonotes train.
09/16 06:01:02 AM: 	  Training on 
09/16 06:01:02 AM: 	  Evaluating on edges-ner-ontonotes
09/16 06:01:02 AM: 	Finished loading tasks in 28.331s
09/16 06:01:02 AM: 	 Tasks: ['edges-ner-ontonotes']
09/16 06:01:02 AM: Building model...
09/16 06:01:02 AM: Using BERT model (bert-base-uncased).
09/16 06:01:02 AM: LOADING A FUNETUNED MODEL from: 
09/16 06:01:02 AM: models/sts
09/16 06:01:02 AM: loading configuration file models/sts/config.json
09/16 06:01:02 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "sts-b",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 06:01:02 AM: loading weights file models/sts/pytorch_model.bin
09/16 06:01:07 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/ner-ontonotes-sts-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:01:07 AM: Initializing parameters
09/16 06:01:07 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 06:01:07 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 06:01:07 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 06:01:07 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 06:01:07 AM: 	Task 'edges-ner-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-ner-ontonotes"
}
09/16 06:01:35 AM: Model specification:
09/16 06:01:35 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-ner-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=18, bias=True)
    )
  )
)
09/16 06:01:35 AM: Model parameters:
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:35 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:35 AM: 	edges-ner-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 06:01:35 AM: 	edges-ner-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 06:01:35 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 9216 with torch.Size([18, 512])
09/16 06:01:35 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 18 with torch.Size([18])
09/16 06:01:35 AM: Total number of parameters: 109688338 (1.09688e+08)
09/16 06:01:35 AM: Number of trainable parameters: 206098 (206098)
09/16 06:01:35 AM: Finished building model in 47.634s
09/16 06:01:35 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-ner-ontonotes 

09/16 06:01:36 AM: Model specification:
09/16 06:01:36 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-ner-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=18, bias=True)
    )
  )
)
09/16 06:01:36 AM: Model parameters:
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	edges-ner-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 06:01:36 AM: 	edges-ner-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 06:01:36 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 9216 with torch.Size([18, 512])
09/16 06:01:36 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 18 with torch.Size([18])
09/16 06:01:36 AM: Total number of parameters: 109688338 (1.09688e+08)
09/16 06:01:36 AM: Number of trainable parameters: 206098 (206098)
09/16 06:01:36 AM: Finished building model in 34.568s
09/16 06:01:36 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-ner-ontonotes 

09/16 06:01:40 AM: patience = 9
09/16 06:01:40 AM: val_interval = 1000
09/16 06:01:40 AM: max_vals = 250
09/16 06:01:40 AM: cuda_device = 0
09/16 06:01:40 AM: grad_norm = 5.0
09/16 06:01:40 AM: grad_clipping = None
09/16 06:01:40 AM: lr_decay = 0.99
09/16 06:01:40 AM: min_lr = 1e-06
09/16 06:01:40 AM: keep_all_checkpoints = 0
09/16 06:01:40 AM: val_data_limit = 5000
09/16 06:01:40 AM: max_epochs = -1
09/16 06:01:40 AM: dec_val_scale = 250
09/16 06:01:40 AM: training_data_fraction = 1
09/16 06:01:40 AM: type = adam
09/16 06:01:40 AM: parameter_groups = None
09/16 06:01:40 AM: Number of trainable parameters: 206098
09/16 06:01:40 AM: infer_type_and_cast = True
09/16 06:01:40 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:40 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:40 AM: lr = 0.0001
09/16 06:01:40 AM: amsgrad = True
09/16 06:01:40 AM: type = reduce_on_plateau
09/16 06:01:40 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:40 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:40 AM: mode = max
09/16 06:01:40 AM: factor = 0.5
09/16 06:01:40 AM: patience = 3
09/16 06:01:40 AM: threshold = 0.0001
09/16 06:01:40 AM: threshold_mode = abs
09/16 06:01:40 AM: verbose = True
09/16 06:01:40 AM: type = adam
09/16 06:01:40 AM: parameter_groups = None
09/16 06:01:40 AM: Number of trainable parameters: 206098
09/16 06:01:40 AM: infer_type_and_cast = True
09/16 06:01:40 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:40 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:40 AM: lr = 0.0001
09/16 06:01:40 AM: amsgrad = True
09/16 06:01:40 AM: type = reduce_on_plateau
09/16 06:01:40 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:40 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:40 AM: mode = max
09/16 06:01:40 AM: factor = 0.5
09/16 06:01:40 AM: patience = 3
09/16 06:01:40 AM: threshold = 0.0001
09/16 06:01:40 AM: threshold_mode = abs
09/16 06:01:40 AM: verbose = True
09/16 06:01:40 AM: Starting training without restoring from a checkpoint.
09/16 06:01:40 AM: Training examples per task, before any subsampling: {'edges-ner-ontonotes': 49706}
09/16 06:01:40 AM: Beginning training with stopping criteria based on metric: edges-ner-ontonotes_f1
09/16 06:01:42 AM: patience = 9
09/16 06:01:42 AM: val_interval = 1000
09/16 06:01:42 AM: max_vals = 250
09/16 06:01:42 AM: cuda_device = 0
09/16 06:01:42 AM: grad_norm = 5.0
09/16 06:01:42 AM: grad_clipping = None
09/16 06:01:42 AM: lr_decay = 0.99
09/16 06:01:42 AM: min_lr = 1e-06
09/16 06:01:42 AM: keep_all_checkpoints = 0
09/16 06:01:42 AM: val_data_limit = 5000
09/16 06:01:42 AM: max_epochs = -1
09/16 06:01:42 AM: dec_val_scale = 250
09/16 06:01:42 AM: training_data_fraction = 1
09/16 06:01:42 AM: type = adam
09/16 06:01:42 AM: parameter_groups = None
09/16 06:01:42 AM: Number of trainable parameters: 206098
09/16 06:01:42 AM: infer_type_and_cast = True
09/16 06:01:42 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:42 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:42 AM: lr = 0.0001
09/16 06:01:42 AM: amsgrad = True
09/16 06:01:42 AM: type = reduce_on_plateau
09/16 06:01:42 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:42 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:42 AM: mode = max
09/16 06:01:42 AM: factor = 0.5
09/16 06:01:42 AM: patience = 3
09/16 06:01:42 AM: threshold = 0.0001
09/16 06:01:42 AM: threshold_mode = abs
09/16 06:01:42 AM: verbose = True
09/16 06:01:42 AM: type = adam
09/16 06:01:42 AM: parameter_groups = None
09/16 06:01:42 AM: Number of trainable parameters: 206098
09/16 06:01:42 AM: infer_type_and_cast = True
09/16 06:01:42 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:42 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:42 AM: lr = 0.0001
09/16 06:01:42 AM: amsgrad = True
09/16 06:01:42 AM: type = reduce_on_plateau
09/16 06:01:42 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:42 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:42 AM: mode = max
09/16 06:01:42 AM: factor = 0.5
09/16 06:01:42 AM: patience = 3
09/16 06:01:42 AM: threshold = 0.0001
09/16 06:01:42 AM: threshold_mode = abs
09/16 06:01:42 AM: verbose = True
09/16 06:01:42 AM: Starting training without restoring from a checkpoint.
09/16 06:01:42 AM: Training examples per task, before any subsampling: {'edges-ner-ontonotes': 49706}
09/16 06:01:42 AM: Beginning training with stopping criteria based on metric: edges-ner-ontonotes_f1
09/16 06:01:57 AM: Update 27: task edges-ner-ontonotes, batch 27 (27): mcc: -0.0001, acc: 0.0071, precision: 0.0555, recall: 0.1204, f1: 0.0760, edges-ner-ontonotes_loss: 0.5237
09/16 06:01:57 AM: Update 27: task edges-ner-ontonotes, batch 27 (27): mcc: -0.0001, acc: 0.0071, precision: 0.0555, recall: 0.1204, f1: 0.0760, edges-ner-ontonotes_loss: 0.5237
09/16 06:02:07 AM: Update 118: task edges-ner-ontonotes, batch 118 (118): mcc: -0.0000, acc: 0.0019, precision: 0.0555, recall: 0.0316, f1: 0.0403, edges-ner-ontonotes_loss: 0.2709
09/16 06:02:07 AM: Update 119: task edges-ner-ontonotes, batch 119 (119): mcc: -0.0000, acc: 0.0018, precision: 0.0555, recall: 0.0312, f1: 0.0399, edges-ner-ontonotes_loss: 0.2700
09/16 06:02:17 AM: Update 206: task edges-ner-ontonotes, batch 206 (206): mcc: 0.0213, acc: 0.0138, precision: 0.0907, recall: 0.0309, f1: 0.0461, edges-ner-ontonotes_loss: 0.2193
09/16 06:02:17 AM: Update 207: task edges-ner-ontonotes, batch 207 (207): mcc: 0.0221, acc: 0.0142, precision: 0.0920, recall: 0.0313, f1: 0.0467, edges-ner-ontonotes_loss: 0.2189
09/16 06:02:27 AM: Update 300: task edges-ner-ontonotes, batch 300 (300): mcc: 0.1115, acc: 0.0622, precision: 0.2550, recall: 0.0741, f1: 0.1148, edges-ner-ontonotes_loss: 0.1911
09/16 06:02:27 AM: Update 300: task edges-ner-ontonotes, batch 300 (300): mcc: 0.1115, acc: 0.0622, precision: 0.2550, recall: 0.0741, f1: 0.1148, edges-ner-ontonotes_loss: 0.1911
09/16 06:02:37 AM: Update 366: task edges-ner-ontonotes, batch 366 (366): mcc: 0.2185, acc: 0.1243, precision: 0.4352, recall: 0.1338, f1: 0.2047, edges-ner-ontonotes_loss: 0.1768
09/16 06:02:38 AM: Update 315: task edges-ner-ontonotes, batch 315 (315): mcc: 0.1357, acc: 0.0754, precision: 0.2983, recall: 0.0866, f1: 0.1343, edges-ner-ontonotes_loss: 0.1878
09/16 06:02:47 AM: Update 440: task edges-ner-ontonotes, batch 440 (440): mcc: 0.3222, acc: 0.1951, precision: 0.5789, recall: 0.2032, f1: 0.3008, edges-ner-ontonotes_loss: 0.1632
09/16 06:02:48 AM: Update 397: task edges-ner-ontonotes, batch 397 (397): mcc: 0.2643, acc: 0.1540, precision: 0.5028, recall: 0.1628, f1: 0.2460, edges-ner-ontonotes_loss: 0.1708
09/16 06:02:57 AM: Update 513: task edges-ner-ontonotes, batch 513 (513): mcc: 0.4014, acc: 0.2568, precision: 0.6688, recall: 0.2647, f1: 0.3793, edges-ner-ontonotes_loss: 0.1522
09/16 06:02:58 AM: Update 474: task edges-ner-ontonotes, batch 474 (474): mcc: 0.3607, acc: 0.2241, precision: 0.6248, recall: 0.2320, f1: 0.3383, edges-ner-ontonotes_loss: 0.1578
09/16 06:03:08 AM: Update 585: task edges-ner-ontonotes, batch 585 (585): mcc: 0.4587, acc: 0.3065, precision: 0.7232, recall: 0.3146, f1: 0.4385, edges-ner-ontonotes_loss: 0.1432
09/16 06:03:08 AM: Update 547: task edges-ner-ontonotes, batch 547 (547): mcc: 0.4312, acc: 0.2820, precision: 0.6986, recall: 0.2899, f1: 0.4097, edges-ner-ontonotes_loss: 0.1477
09/16 06:03:18 AM: Update 648: task edges-ner-ontonotes, batch 648 (648): mcc: 0.4991, acc: 0.3440, precision: 0.7575, recall: 0.3523, f1: 0.4809, edges-ner-ontonotes_loss: 0.1363
09/16 06:03:20 AM: Update 627: task edges-ner-ontonotes, batch 627 (627): mcc: 0.4867, acc: 0.3325, precision: 0.7470, recall: 0.3406, f1: 0.4679, edges-ner-ontonotes_loss: 0.1384
09/16 06:03:28 AM: Update 722: task edges-ner-ontonotes, batch 722 (722): mcc: 0.5431, acc: 0.3871, precision: 0.7916, recall: 0.3957, f1: 0.5276, edges-ner-ontonotes_loss: 0.1290
09/16 06:03:30 AM: Update 695: task edges-ner-ontonotes, batch 695 (695): mcc: 0.5275, acc: 0.3714, precision: 0.7802, recall: 0.3798, f1: 0.5109, edges-ner-ontonotes_loss: 0.1316
09/16 06:03:38 AM: Update 795: task edges-ner-ontonotes, batch 795 (795): mcc: 0.5738, acc: 0.4191, precision: 0.8126, recall: 0.4280, f1: 0.5607, edges-ner-ontonotes_loss: 0.1228
09/16 06:03:40 AM: Update 769: task edges-ner-ontonotes, batch 769 (769): mcc: 0.5633, acc: 0.4080, precision: 0.8056, recall: 0.4167, f1: 0.5493, edges-ner-ontonotes_loss: 0.1250
09/16 06:03:48 AM: Update 873: task edges-ner-ontonotes, batch 873 (873): mcc: 0.6032, acc: 0.4515, precision: 0.8304, recall: 0.4607, f1: 0.5926, edges-ner-ontonotes_loss: 0.1167
09/16 06:03:50 AM: Update 842: task edges-ner-ontonotes, batch 842 (842): mcc: 0.5927, acc: 0.4398, precision: 0.8244, recall: 0.4488, f1: 0.5812, edges-ner-ontonotes_loss: 0.1190
09/16 06:04:00 AM: Update 925: task edges-ner-ontonotes, batch 925 (925): mcc: 0.6223, acc: 0.4731, precision: 0.8410, recall: 0.4827, f1: 0.6133, edges-ner-ontonotes_loss: 0.1129
09/16 06:04:00 AM: Update 940: task edges-ner-ontonotes, batch 940 (940): mcc: 0.6264, acc: 0.4780, precision: 0.8431, recall: 0.4876, f1: 0.6179, edges-ner-ontonotes_loss: 0.1120
09/16 06:04:07 AM: ***** Step 1000 / Validation 1 *****
09/16 06:04:07 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:04:07 AM: Validating...
09/16 06:04:10 AM: Update 974: task edges-ner-ontonotes, batch 974 (974): mcc: 0.6362, acc: 0.4895, precision: 0.8481, recall: 0.4992, f1: 0.6285, edges-ner-ontonotes_loss: 0.1100
09/16 06:04:11 AM: Evaluate: task edges-ner-ontonotes, batch 20 (157): mcc: 0.7218, acc: 0.6303, precision: 0.8481, recall: 0.6367, f1: 0.7274, edges-ner-ontonotes_loss: 0.0823
09/16 06:04:14 AM: ***** Step 1000 / Validation 1 *****
09/16 06:04:14 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:04:14 AM: Validating...
09/16 06:04:20 AM: Evaluate: task edges-ner-ontonotes, batch 39 (157): mcc: 0.7705, acc: 0.6911, precision: 0.8739, recall: 0.6991, f1: 0.7768, edges-ner-ontonotes_loss: 0.0745
09/16 06:04:23 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.8102, acc: 0.7378, precision: 0.8985, recall: 0.7477, f1: 0.8162, edges-ner-ontonotes_loss: 0.0665
09/16 06:04:30 AM: Evaluate: task edges-ner-ontonotes, batch 87 (157): mcc: 0.8251, acc: 0.7530, precision: 0.9097, recall: 0.7643, f1: 0.8307, edges-ner-ontonotes_loss: 0.0625
09/16 06:04:33 AM: Evaluate: task edges-ner-ontonotes, batch 107 (157): mcc: 0.8331, acc: 0.7645, precision: 0.9116, recall: 0.7768, f1: 0.8388, edges-ner-ontonotes_loss: 0.0598
09/16 06:04:42 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:04:42 AM: Best result seen so far for micro.
09/16 06:04:42 AM: Best result seen so far for macro.
09/16 06:04:42 AM: Updating LR scheduler:
09/16 06:04:42 AM: 	Best result seen so far for macro_avg: 0.851
09/16 06:04:42 AM: 	# validation passes without improvement: 0
09/16 06:04:42 AM: edges-ner-ontonotes_loss: training: 0.108482 validation: 0.055153
09/16 06:04:42 AM: macro_avg: validation: 0.851248
09/16 06:04:42 AM: micro_avg: validation: 0.000000
09/16 06:04:42 AM: edges-ner-ontonotes_mcc: training: 0.643354 validation: 0.845879
09/16 06:04:42 AM: edges-ner-ontonotes_acc: training: 0.497988 validation: 0.778662
09/16 06:04:42 AM: edges-ner-ontonotes_precision: training: 0.851767 validation: 0.920783
09/16 06:04:42 AM: edges-ner-ontonotes_recall: training: 0.507823 validation: 0.791477
09/16 06:04:42 AM: edges-ner-ontonotes_f1: training: 0.636290 validation: 0.851248
09/16 06:04:42 AM: Global learning rate: 0.0001
09/16 06:04:42 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:04:43 AM: Update 1010: task edges-ner-ontonotes, batch 10 (1010): mcc: 0.8613, acc: 0.7884, precision: 0.9437, recall: 0.7988, f1: 0.8652, edges-ner-ontonotes_loss: 0.0490
09/16 06:04:45 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.8359, acc: 0.7666, precision: 0.9146, recall: 0.7793, f1: 0.8415, edges-ner-ontonotes_loss: 0.0586
09/16 06:04:53 AM: Update 1079: task edges-ner-ontonotes, batch 79 (1079): mcc: 0.8538, acc: 0.7821, precision: 0.9348, recall: 0.7933, f1: 0.8583, edges-ner-ontonotes_loss: 0.0489
09/16 06:04:54 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:04:54 AM: Best result seen so far for micro.
09/16 06:04:54 AM: Best result seen so far for macro.
09/16 06:04:54 AM: Updating LR scheduler:
09/16 06:04:54 AM: 	Best result seen so far for macro_avg: 0.851
09/16 06:04:54 AM: 	# validation passes without improvement: 0
09/16 06:04:54 AM: edges-ner-ontonotes_loss: training: 0.108482 validation: 0.055153
09/16 06:04:54 AM: macro_avg: validation: 0.851248
09/16 06:04:54 AM: micro_avg: validation: 0.000000
09/16 06:04:54 AM: edges-ner-ontonotes_mcc: training: 0.643354 validation: 0.845879
09/16 06:04:54 AM: edges-ner-ontonotes_acc: training: 0.497988 validation: 0.778662
09/16 06:04:54 AM: edges-ner-ontonotes_precision: training: 0.851767 validation: 0.920783
09/16 06:04:54 AM: edges-ner-ontonotes_recall: training: 0.507823 validation: 0.791477
09/16 06:04:54 AM: edges-ner-ontonotes_f1: training: 0.636290 validation: 0.851248
09/16 06:04:54 AM: Global learning rate: 0.0001
09/16 06:04:54 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:04:56 AM: Update 1001: task edges-ner-ontonotes, batch 1 (1001): mcc: 0.9028, acc: 0.8235, precision: 1.0000, recall: 0.8235, f1: 0.9032, edges-ner-ontonotes_loss: 0.0449
09/16 06:05:03 AM: Update 1158: task edges-ner-ontonotes, batch 158 (1158): mcc: 0.8587, acc: 0.7889, precision: 0.9363, recall: 0.8006, f1: 0.8632, edges-ner-ontonotes_loss: 0.0480
09/16 06:05:06 AM: Update 1074: task edges-ner-ontonotes, batch 74 (1074): mcc: 0.8529, acc: 0.7818, precision: 0.9339, recall: 0.7925, f1: 0.8574, edges-ner-ontonotes_loss: 0.0492
09/16 06:05:13 AM: Update 1232: task edges-ner-ontonotes, batch 232 (1232): mcc: 0.8611, acc: 0.7921, precision: 0.9362, recall: 0.8050, f1: 0.8656, edges-ner-ontonotes_loss: 0.0474
09/16 06:05:16 AM: Update 1145: task edges-ner-ontonotes, batch 145 (1145): mcc: 0.8567, acc: 0.7858, precision: 0.9356, recall: 0.7977, f1: 0.8611, edges-ner-ontonotes_loss: 0.0485
09/16 06:05:23 AM: Update 1284: task edges-ner-ontonotes, batch 284 (1284): mcc: 0.8565, acc: 0.7860, precision: 0.9339, recall: 0.7988, f1: 0.8611, edges-ner-ontonotes_loss: 0.0488
09/16 06:05:28 AM: Update 1225: task edges-ner-ontonotes, batch 225 (1225): mcc: 0.8612, acc: 0.7919, precision: 0.9366, recall: 0.8048, f1: 0.8657, edges-ner-ontonotes_loss: 0.0475
09/16 06:05:35 AM: Update 1369: task edges-ner-ontonotes, batch 369 (1369): mcc: 0.8505, acc: 0.7772, precision: 0.9307, recall: 0.7909, f1: 0.8551, edges-ner-ontonotes_loss: 0.0518
09/16 06:05:40 AM: Update 1277: task edges-ner-ontonotes, batch 277 (1277): mcc: 0.8574, acc: 0.7869, precision: 0.9347, recall: 0.7997, f1: 0.8620, edges-ner-ontonotes_loss: 0.0484
09/16 06:05:45 AM: Update 1445: task edges-ner-ontonotes, batch 445 (1445): mcc: 0.8478, acc: 0.7734, precision: 0.9294, recall: 0.7874, f1: 0.8525, edges-ner-ontonotes_loss: 0.0522
09/16 06:05:50 AM: Update 1349: task edges-ner-ontonotes, batch 349 (1349): mcc: 0.8512, acc: 0.7782, precision: 0.9313, recall: 0.7917, f1: 0.8559, edges-ner-ontonotes_loss: 0.0514
09/16 06:05:55 AM: Update 1523: task edges-ner-ontonotes, batch 523 (1523): mcc: 0.8456, acc: 0.7712, precision: 0.9273, recall: 0.7853, f1: 0.8504, edges-ner-ontonotes_loss: 0.0530
09/16 06:06:00 AM: Update 1434: task edges-ner-ontonotes, batch 434 (1434): mcc: 0.8484, acc: 0.7742, precision: 0.9295, recall: 0.7883, f1: 0.8531, edges-ner-ontonotes_loss: 0.0522
09/16 06:06:07 AM: Update 1587: task edges-ner-ontonotes, batch 587 (1587): mcc: 0.8447, acc: 0.7704, precision: 0.9265, recall: 0.7844, f1: 0.8495, edges-ner-ontonotes_loss: 0.0531
09/16 06:06:10 AM: Update 1520: task edges-ner-ontonotes, batch 520 (1520): mcc: 0.8455, acc: 0.7710, precision: 0.9273, recall: 0.7851, f1: 0.8503, edges-ner-ontonotes_loss: 0.0530
09/16 06:06:17 AM: Update 1682: task edges-ner-ontonotes, batch 682 (1682): mcc: 0.8434, acc: 0.7685, precision: 0.9262, recall: 0.7824, f1: 0.8482, edges-ner-ontonotes_loss: 0.0532
09/16 06:06:20 AM: Update 1588: task edges-ner-ontonotes, batch 588 (1588): mcc: 0.8448, acc: 0.7705, precision: 0.9265, recall: 0.7845, f1: 0.8496, edges-ner-ontonotes_loss: 0.0531
09/16 06:06:27 AM: Update 1770: task edges-ner-ontonotes, batch 770 (1770): mcc: 0.8421, acc: 0.7675, precision: 0.9246, recall: 0.7814, f1: 0.8470, edges-ner-ontonotes_loss: 0.0533
09/16 06:06:30 AM: Update 1679: task edges-ner-ontonotes, batch 679 (1679): mcc: 0.8435, acc: 0.7686, precision: 0.9262, recall: 0.7825, f1: 0.8483, edges-ner-ontonotes_loss: 0.0532
09/16 06:06:37 AM: Update 1856: task edges-ner-ontonotes, batch 856 (1856): mcc: 0.8424, acc: 0.7680, precision: 0.9244, recall: 0.7821, f1: 0.8473, edges-ner-ontonotes_loss: 0.0527
09/16 06:06:40 AM: Update 1770: task edges-ner-ontonotes, batch 770 (1770): mcc: 0.8421, acc: 0.7675, precision: 0.9246, recall: 0.7814, f1: 0.8470, edges-ner-ontonotes_loss: 0.0533
09/16 06:06:47 AM: Update 1914: task edges-ner-ontonotes, batch 914 (1914): mcc: 0.8438, acc: 0.7702, precision: 0.9246, recall: 0.7844, f1: 0.8488, edges-ner-ontonotes_loss: 0.0522
09/16 06:06:50 AM: Update 1858: task edges-ner-ontonotes, batch 858 (1858): mcc: 0.8423, acc: 0.7679, precision: 0.9243, recall: 0.7821, f1: 0.8473, edges-ner-ontonotes_loss: 0.0527
09/16 06:06:57 AM: Update 1998: task edges-ner-ontonotes, batch 998 (1998): mcc: 0.8464, acc: 0.7741, precision: 0.9250, recall: 0.7888, f1: 0.8515, edges-ner-ontonotes_loss: 0.0513
09/16 06:07:00 AM: ***** Step 2000 / Validation 2 *****
09/16 06:07:00 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:07:00 AM: Validating...
09/16 06:07:00 AM: Update 1920: task edges-ner-ontonotes, batch 920 (1920): mcc: 0.8438, acc: 0.7703, precision: 0.9245, recall: 0.7846, f1: 0.8488, edges-ner-ontonotes_loss: 0.0521
09/16 06:07:10 AM: Evaluate: task edges-ner-ontonotes, batch 62 (157): mcc: 0.8619, acc: 0.8082, precision: 0.9204, recall: 0.8206, f1: 0.8676, edges-ner-ontonotes_loss: 0.0434
09/16 06:07:10 AM: Update 1977: task edges-ner-ontonotes, batch 977 (1977): mcc: 0.8457, acc: 0.7731, precision: 0.9248, recall: 0.7877, f1: 0.8507, edges-ner-ontonotes_loss: 0.0514
09/16 06:07:14 AM: ***** Step 2000 / Validation 2 *****
09/16 06:07:14 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:07:14 AM: Validating...
09/16 06:07:20 AM: Evaluate: task edges-ner-ontonotes, batch 112 (157): mcc: 0.8787, acc: 0.8270, precision: 0.9318, recall: 0.8405, f1: 0.8838, edges-ner-ontonotes_loss: 0.0394
09/16 06:07:20 AM: Evaluate: task edges-ner-ontonotes, batch 31 (157): mcc: 0.8240, acc: 0.7592, precision: 0.9006, recall: 0.7702, f1: 0.8304, edges-ner-ontonotes_loss: 0.0529
09/16 06:07:30 AM: Evaluate: task edges-ner-ontonotes, batch 80 (157): mcc: 0.8704, acc: 0.8161, precision: 0.9290, recall: 0.8281, f1: 0.8756, edges-ner-ontonotes_loss: 0.0421
09/16 06:07:30 AM: Evaluate: task edges-ner-ontonotes, batch 148 (157): mcc: 0.8863, acc: 0.8361, precision: 0.9371, recall: 0.8497, f1: 0.8912, edges-ner-ontonotes_loss: 0.0378
09/16 06:07:32 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:07:32 AM: Best result seen so far for macro.
09/16 06:07:32 AM: Updating LR scheduler:
09/16 06:07:32 AM: 	Best result seen so far for macro_avg: 0.891
09/16 06:07:32 AM: 	# validation passes without improvement: 0
09/16 06:07:32 AM: edges-ner-ontonotes_loss: training: 0.051218 validation: 0.037470
09/16 06:07:32 AM: macro_avg: validation: 0.891424
09/16 06:07:32 AM: micro_avg: validation: 0.000000
09/16 06:07:32 AM: edges-ner-ontonotes_mcc: training: 0.846554 validation: 0.886513
09/16 06:07:32 AM: edges-ner-ontonotes_acc: training: 0.774226 validation: 0.836518
09/16 06:07:32 AM: edges-ner-ontonotes_precision: training: 0.925091 validation: 0.936613
09/16 06:07:32 AM: edges-ner-ontonotes_recall: training: 0.788892 validation: 0.850394
09/16 06:07:32 AM: edges-ner-ontonotes_f1: training: 0.851580 validation: 0.891424
09/16 06:07:32 AM: Global learning rate: 0.0001
09/16 06:07:32 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:07:40 AM: Update 2036: task edges-ner-ontonotes, batch 36 (2036): mcc: 0.8844, acc: 0.8301, precision: 0.9410, recall: 0.8425, f1: 0.8890, edges-ner-ontonotes_loss: 0.0379
09/16 06:07:40 AM: Evaluate: task edges-ner-ontonotes, batch 131 (157): mcc: 0.8842, acc: 0.8335, precision: 0.9363, recall: 0.8465, f1: 0.8891, edges-ner-ontonotes_loss: 0.0384
09/16 06:07:45 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:07:45 AM: Best result seen so far for macro.
09/16 06:07:45 AM: Updating LR scheduler:
09/16 06:07:45 AM: 	Best result seen so far for macro_avg: 0.891
09/16 06:07:45 AM: 	# validation passes without improvement: 0
09/16 06:07:45 AM: edges-ner-ontonotes_loss: training: 0.051218 validation: 0.037470
09/16 06:07:45 AM: macro_avg: validation: 0.891424
09/16 06:07:45 AM: micro_avg: validation: 0.000000
09/16 06:07:45 AM: edges-ner-ontonotes_mcc: training: 0.846554 validation: 0.886513
09/16 06:07:45 AM: edges-ner-ontonotes_acc: training: 0.774226 validation: 0.836518
09/16 06:07:45 AM: edges-ner-ontonotes_precision: training: 0.925091 validation: 0.936613
09/16 06:07:45 AM: edges-ner-ontonotes_recall: training: 0.788892 validation: 0.850394
09/16 06:07:45 AM: edges-ner-ontonotes_f1: training: 0.851580 validation: 0.891424
09/16 06:07:45 AM: Global learning rate: 0.0001
09/16 06:07:45 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:07:50 AM: Update 2103: task edges-ner-ontonotes, batch 103 (2103): mcc: 0.8846, acc: 0.8302, precision: 0.9406, recall: 0.8432, f1: 0.8893, edges-ner-ontonotes_loss: 0.0377
09/16 06:07:50 AM: Update 2042: task edges-ner-ontonotes, batch 42 (2042): mcc: 0.8836, acc: 0.8286, precision: 0.9417, recall: 0.8405, f1: 0.8882, edges-ner-ontonotes_loss: 0.0381
09/16 06:08:02 AM: Update 2117: task edges-ner-ontonotes, batch 117 (2117): mcc: 0.8835, acc: 0.8290, precision: 0.9396, recall: 0.8423, f1: 0.8883, edges-ner-ontonotes_loss: 0.0380
09/16 06:08:02 AM: Update 2176: task edges-ner-ontonotes, batch 176 (2176): mcc: 0.8843, acc: 0.8313, precision: 0.9381, recall: 0.8450, f1: 0.8891, edges-ner-ontonotes_loss: 0.0377
09/16 06:08:12 AM: Update 2236: task edges-ner-ontonotes, batch 236 (2236): mcc: 0.8867, acc: 0.8334, precision: 0.9401, recall: 0.8475, f1: 0.8914, edges-ner-ontonotes_loss: 0.0370
09/16 06:08:12 AM: Update 2183: task edges-ner-ontonotes, batch 183 (2183): mcc: 0.8834, acc: 0.8298, precision: 0.9380, recall: 0.8434, f1: 0.8882, edges-ner-ontonotes_loss: 0.0378
09/16 06:08:22 AM: Update 2306: task edges-ner-ontonotes, batch 306 (2306): mcc: 0.8904, acc: 0.8380, precision: 0.9418, recall: 0.8527, f1: 0.8950, edges-ner-ontonotes_loss: 0.0358
09/16 06:08:22 AM: Update 2254: task edges-ner-ontonotes, batch 254 (2254): mcc: 0.8877, acc: 0.8346, precision: 0.9407, recall: 0.8489, f1: 0.8924, edges-ner-ontonotes_loss: 0.0366
09/16 06:08:32 AM: Update 2378: task edges-ner-ontonotes, batch 378 (2378): mcc: 0.8931, acc: 0.8423, precision: 0.9421, recall: 0.8572, f1: 0.8977, edges-ner-ontonotes_loss: 0.0350
09/16 06:08:33 AM: Update 2325: task edges-ner-ontonotes, batch 325 (2325): mcc: 0.8914, acc: 0.8397, precision: 0.9417, recall: 0.8545, f1: 0.8960, edges-ner-ontonotes_loss: 0.0355
09/16 06:08:42 AM: Update 2448: task edges-ner-ontonotes, batch 448 (2448): mcc: 0.8950, acc: 0.8451, precision: 0.9425, recall: 0.8603, f1: 0.8995, edges-ner-ontonotes_loss: 0.0344
09/16 06:08:43 AM: Update 2398: task edges-ner-ontonotes, batch 398 (2398): mcc: 0.8936, acc: 0.8431, precision: 0.9421, recall: 0.8582, f1: 0.8982, edges-ner-ontonotes_loss: 0.0349
09/16 06:08:52 AM: Update 2498: task edges-ner-ontonotes, batch 498 (2498): mcc: 0.8955, acc: 0.8455, precision: 0.9429, recall: 0.8610, f1: 0.9001, edges-ner-ontonotes_loss: 0.0341
09/16 06:08:53 AM: Update 2477: task edges-ner-ontonotes, batch 477 (2477): mcc: 0.8956, acc: 0.8458, precision: 0.9427, recall: 0.8613, f1: 0.9002, edges-ner-ontonotes_loss: 0.0342
09/16 06:09:02 AM: Update 2579: task edges-ner-ontonotes, batch 579 (2579): mcc: 0.8958, acc: 0.8456, precision: 0.9424, recall: 0.8620, f1: 0.9004, edges-ner-ontonotes_loss: 0.0339
09/16 06:09:03 AM: Update 2526: task edges-ner-ontonotes, batch 526 (2526): mcc: 0.8954, acc: 0.8453, precision: 0.9426, recall: 0.8611, f1: 0.9000, edges-ner-ontonotes_loss: 0.0341
09/16 06:09:12 AM: Update 2649: task edges-ner-ontonotes, batch 649 (2649): mcc: 0.8964, acc: 0.8464, precision: 0.9424, recall: 0.8631, f1: 0.9010, edges-ner-ontonotes_loss: 0.0337
09/16 06:09:13 AM: Update 2601: task edges-ner-ontonotes, batch 601 (2601): mcc: 0.8962, acc: 0.8461, precision: 0.9425, recall: 0.8625, f1: 0.9008, edges-ner-ontonotes_loss: 0.0338
09/16 06:09:22 AM: Update 2719: task edges-ner-ontonotes, batch 719 (2719): mcc: 0.8970, acc: 0.8473, precision: 0.9423, recall: 0.8643, f1: 0.9016, edges-ner-ontonotes_loss: 0.0334
09/16 06:09:23 AM: Update 2672: task edges-ner-ontonotes, batch 672 (2672): mcc: 0.8967, acc: 0.8469, precision: 0.9423, recall: 0.8637, f1: 0.9013, edges-ner-ontonotes_loss: 0.0336
09/16 06:09:32 AM: Update 2789: task edges-ner-ontonotes, batch 789 (2789): mcc: 0.8981, acc: 0.8487, precision: 0.9429, recall: 0.8658, f1: 0.9027, edges-ner-ontonotes_loss: 0.0330
09/16 06:09:33 AM: Update 2743: task edges-ner-ontonotes, batch 743 (2743): mcc: 0.8971, acc: 0.8474, precision: 0.9424, recall: 0.8645, f1: 0.9017, edges-ner-ontonotes_loss: 0.0333
09/16 06:09:42 AM: Update 2839: task edges-ner-ontonotes, batch 839 (2839): mcc: 0.8973, acc: 0.8475, precision: 0.9424, recall: 0.8647, f1: 0.9018, edges-ner-ontonotes_loss: 0.0335
09/16 06:09:44 AM: Update 2809: task edges-ner-ontonotes, batch 809 (2809): mcc: 0.8985, acc: 0.8492, precision: 0.9432, recall: 0.8662, f1: 0.9031, edges-ner-ontonotes_loss: 0.0329
09/16 06:09:52 AM: Update 2911: task edges-ner-ontonotes, batch 911 (2911): mcc: 0.8952, acc: 0.8444, precision: 0.9414, recall: 0.8618, f1: 0.8998, edges-ner-ontonotes_loss: 0.0342
09/16 06:09:54 AM: Update 2875: task edges-ner-ontonotes, batch 875 (2875): mcc: 0.8963, acc: 0.8460, precision: 0.9420, recall: 0.8632, f1: 0.9009, edges-ner-ontonotes_loss: 0.0338
09/16 06:10:02 AM: Update 2985: task edges-ner-ontonotes, batch 985 (2985): mcc: 0.8933, acc: 0.8420, precision: 0.9404, recall: 0.8594, f1: 0.8980, edges-ner-ontonotes_loss: 0.0350
09/16 06:10:04 AM: ***** Step 3000 / Validation 3 *****
09/16 06:10:04 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:10:04 AM: Update 2949: task edges-ner-ontonotes, batch 949 (2949): mcc: 0.8943, acc: 0.8432, precision: 0.9410, recall: 0.8606, f1: 0.8990, edges-ner-ontonotes_loss: 0.0346
09/16 06:10:05 AM: Validating...
09/16 06:10:12 AM: Evaluate: task edges-ner-ontonotes, batch 46 (157): mcc: 0.8583, acc: 0.8037, precision: 0.9148, recall: 0.8192, f1: 0.8644, edges-ner-ontonotes_loss: 0.0434
09/16 06:10:14 AM: ***** Step 3000 / Validation 3 *****
09/16 06:10:14 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:10:14 AM: Validating...
09/16 06:10:15 AM: Evaluate: task edges-ner-ontonotes, batch 7 (157): mcc: 0.7917, acc: 0.7198, precision: 0.8706, recall: 0.7392, f1: 0.7995, edges-ner-ontonotes_loss: 0.0588
09/16 06:10:22 AM: Evaluate: task edges-ner-ontonotes, batch 93 (157): mcc: 0.8901, acc: 0.8419, precision: 0.9362, recall: 0.8574, f1: 0.8950, edges-ner-ontonotes_loss: 0.0358
09/16 06:10:25 AM: Evaluate: task edges-ner-ontonotes, batch 57 (157): mcc: 0.8741, acc: 0.8249, precision: 0.9225, recall: 0.8407, f1: 0.8797, edges-ner-ontonotes_loss: 0.0397
09/16 06:10:33 AM: Evaluate: task edges-ner-ontonotes, batch 124 (157): mcc: 0.8974, acc: 0.8515, precision: 0.9406, recall: 0.8666, f1: 0.9021, edges-ner-ontonotes_loss: 0.0337
09/16 06:10:36 AM: Evaluate: task edges-ner-ontonotes, batch 104 (157): mcc: 0.8919, acc: 0.8456, precision: 0.9352, recall: 0.8614, f1: 0.8968, edges-ner-ontonotes_loss: 0.0353
09/16 06:10:40 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:10:41 AM: Best result seen so far for macro.
09/16 06:10:41 AM: Updating LR scheduler:
09/16 06:10:41 AM: 	Best result seen so far for macro_avg: 0.908
09/16 06:10:41 AM: 	# validation passes without improvement: 0
09/16 06:10:41 AM: edges-ner-ontonotes_loss: training: 0.035132 validation: 0.031719
09/16 06:10:41 AM: macro_avg: validation: 0.907982
09/16 06:10:41 AM: micro_avg: validation: 0.000000
09/16 06:10:41 AM: edges-ner-ontonotes_mcc: training: 0.892985 validation: 0.903519
09/16 06:10:41 AM: edges-ner-ontonotes_acc: training: 0.841556 validation: 0.859039
09/16 06:10:41 AM: edges-ner-ontonotes_precision: training: 0.940127 validation: 0.943944
09/16 06:10:41 AM: edges-ner-ontonotes_recall: training: 0.858939 validation: 0.874659
09/16 06:10:41 AM: edges-ner-ontonotes_f1: training: 0.897701 validation: 0.907982
09/16 06:10:41 AM: Global learning rate: 0.0001
09/16 06:10:41 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:10:43 AM: Update 3008: task edges-ner-ontonotes, batch 8 (3008): mcc: 0.8887, acc: 0.8367, precision: 0.9456, recall: 0.8462, f1: 0.8931, edges-ner-ontonotes_loss: 0.0413
09/16 06:10:46 AM: Evaluate: task edges-ner-ontonotes, batch 154 (157): mcc: 0.9031, acc: 0.8585, precision: 0.9440, recall: 0.8739, f1: 0.9076, edges-ner-ontonotes_loss: 0.0320
09/16 06:10:46 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:10:46 AM: Best result seen so far for macro.
09/16 06:10:46 AM: Updating LR scheduler:
09/16 06:10:46 AM: 	Best result seen so far for macro_avg: 0.908
09/16 06:10:46 AM: 	# validation passes without improvement: 0
09/16 06:10:46 AM: edges-ner-ontonotes_loss: training: 0.035132 validation: 0.031719
09/16 06:10:46 AM: macro_avg: validation: 0.907982
09/16 06:10:46 AM: micro_avg: validation: 0.000000
09/16 06:10:46 AM: edges-ner-ontonotes_mcc: training: 0.892985 validation: 0.903519
09/16 06:10:46 AM: edges-ner-ontonotes_acc: training: 0.841556 validation: 0.859039
09/16 06:10:46 AM: edges-ner-ontonotes_precision: training: 0.940127 validation: 0.943944
09/16 06:10:46 AM: edges-ner-ontonotes_recall: training: 0.858939 validation: 0.874659
09/16 06:10:46 AM: edges-ner-ontonotes_f1: training: 0.897701 validation: 0.907982
09/16 06:10:46 AM: Global learning rate: 0.0001
09/16 06:10:46 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:10:53 AM: Update 3078: task edges-ner-ontonotes, batch 78 (3078): mcc: 0.8662, acc: 0.8048, precision: 0.9270, recall: 0.8224, f1: 0.8716, edges-ner-ontonotes_loss: 0.0449
09/16 06:10:56 AM: Update 3076: task edges-ner-ontonotes, batch 76 (3076): mcc: 0.8664, acc: 0.8042, precision: 0.9279, recall: 0.8219, f1: 0.8717, edges-ner-ontonotes_loss: 0.0451
09/16 06:11:03 AM: Update 3143: task edges-ner-ontonotes, batch 143 (3143): mcc: 0.8654, acc: 0.8041, precision: 0.9261, recall: 0.8217, f1: 0.8708, edges-ner-ontonotes_loss: 0.0450
09/16 06:11:06 AM: Update 3142: task edges-ner-ontonotes, batch 142 (3142): mcc: 0.8649, acc: 0.8035, precision: 0.9258, recall: 0.8211, f1: 0.8703, edges-ner-ontonotes_loss: 0.0451
09/16 06:11:13 AM: Update 3237: task edges-ner-ontonotes, batch 237 (3237): mcc: 0.8660, acc: 0.8053, precision: 0.9263, recall: 0.8227, f1: 0.8714, edges-ner-ontonotes_loss: 0.0437
09/16 06:11:18 AM: Update 3237: task edges-ner-ontonotes, batch 237 (3237): mcc: 0.8660, acc: 0.8053, precision: 0.9263, recall: 0.8227, f1: 0.8714, edges-ner-ontonotes_loss: 0.0437
09/16 06:11:25 AM: Update 3335: task edges-ner-ontonotes, batch 335 (3335): mcc: 0.8675, acc: 0.8078, precision: 0.9270, recall: 0.8248, f1: 0.8729, edges-ner-ontonotes_loss: 0.0425
09/16 06:11:30 AM: Update 3328: task edges-ner-ontonotes, batch 328 (3328): mcc: 0.8676, acc: 0.8082, precision: 0.9266, recall: 0.8252, f1: 0.8730, edges-ner-ontonotes_loss: 0.0426
09/16 06:11:39 AM: Update 3426: task edges-ner-ontonotes, batch 426 (3426): mcc: 0.8690, acc: 0.8091, precision: 0.9276, recall: 0.8268, f1: 0.8743, edges-ner-ontonotes_loss: 0.0419
09/16 06:11:43 AM: Update 3426: task edges-ner-ontonotes, batch 426 (3426): mcc: 0.8690, acc: 0.8091, precision: 0.9276, recall: 0.8268, f1: 0.8743, edges-ner-ontonotes_loss: 0.0419
09/16 06:11:49 AM: Update 3511: task edges-ner-ontonotes, batch 511 (3511): mcc: 0.8742, acc: 0.8170, precision: 0.9297, recall: 0.8344, f1: 0.8795, edges-ner-ontonotes_loss: 0.0406
09/16 06:11:53 AM: Update 3502: task edges-ner-ontonotes, batch 502 (3502): mcc: 0.8738, acc: 0.8163, precision: 0.9296, recall: 0.8337, f1: 0.8790, edges-ner-ontonotes_loss: 0.0406
09/16 06:11:59 AM: Update 3584: task edges-ner-ontonotes, batch 584 (3584): mcc: 0.8782, acc: 0.8228, precision: 0.9311, recall: 0.8403, f1: 0.8834, edges-ner-ontonotes_loss: 0.0394
09/16 06:12:04 AM: Update 3581: task edges-ner-ontonotes, batch 581 (3581): mcc: 0.8780, acc: 0.8226, precision: 0.9310, recall: 0.8401, f1: 0.8832, edges-ner-ontonotes_loss: 0.0395
09/16 06:12:10 AM: Update 3657: task edges-ner-ontonotes, batch 657 (3657): mcc: 0.8814, acc: 0.8274, precision: 0.9321, recall: 0.8453, f1: 0.8866, edges-ner-ontonotes_loss: 0.0386
09/16 06:12:14 AM: Update 3653: task edges-ner-ontonotes, batch 653 (3653): mcc: 0.8812, acc: 0.8272, precision: 0.9321, recall: 0.8449, f1: 0.8864, edges-ner-ontonotes_loss: 0.0386
09/16 06:12:20 AM: Update 3732: task edges-ner-ontonotes, batch 732 (3732): mcc: 0.8842, acc: 0.8313, precision: 0.9331, recall: 0.8495, f1: 0.8893, edges-ner-ontonotes_loss: 0.0378
09/16 06:12:24 AM: Update 3735: task edges-ner-ontonotes, batch 735 (3735): mcc: 0.8843, acc: 0.8313, precision: 0.9331, recall: 0.8496, f1: 0.8894, edges-ner-ontonotes_loss: 0.0377
09/16 06:12:30 AM: Update 3786: task edges-ner-ontonotes, batch 786 (3786): mcc: 0.8867, acc: 0.8345, precision: 0.9344, recall: 0.8529, f1: 0.8918, edges-ner-ontonotes_loss: 0.0371
09/16 06:12:34 AM: Update 3783: task edges-ner-ontonotes, batch 783 (3783): mcc: 0.8865, acc: 0.8342, precision: 0.9342, recall: 0.8527, f1: 0.8916, edges-ner-ontonotes_loss: 0.0372
09/16 06:12:40 AM: Update 3853: task edges-ner-ontonotes, batch 853 (3853): mcc: 0.8896, acc: 0.8385, precision: 0.9358, recall: 0.8569, f1: 0.8946, edges-ner-ontonotes_loss: 0.0363
09/16 06:12:44 AM: Update 3853: task edges-ner-ontonotes, batch 853 (3853): mcc: 0.8896, acc: 0.8385, precision: 0.9358, recall: 0.8569, f1: 0.8946, edges-ner-ontonotes_loss: 0.0363
09/16 06:12:50 AM: Update 3929: task edges-ner-ontonotes, batch 929 (3929): mcc: 0.8925, acc: 0.8422, precision: 0.9374, recall: 0.8606, f1: 0.8973, edges-ner-ontonotes_loss: 0.0355
09/16 06:12:54 AM: Update 3930: task edges-ner-ontonotes, batch 930 (3930): mcc: 0.8926, acc: 0.8423, precision: 0.9374, recall: 0.8606, f1: 0.8974, edges-ner-ontonotes_loss: 0.0355
09/16 06:13:00 AM: ***** Step 4000 / Validation 4 *****
09/16 06:13:01 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:13:01 AM: Validating...
09/16 06:13:02 AM: Evaluate: task edges-ner-ontonotes, batch 1 (157): mcc: 0.7371, acc: 0.6557, precision: 0.8367, recall: 0.6721, f1: 0.7455, edges-ner-ontonotes_loss: 0.0717
09/16 06:13:03 AM: ***** Step 4000 / Validation 4 *****
09/16 06:13:03 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:13:03 AM: Validating...
09/16 06:13:04 AM: Evaluate: task edges-ner-ontonotes, batch 4 (157): mcc: 0.7356, acc: 0.6630, precision: 0.8274, recall: 0.6775, f1: 0.7450, edges-ner-ontonotes_loss: 0.0742
09/16 06:13:12 AM: Evaluate: task edges-ner-ontonotes, batch 55 (157): mcc: 0.8845, acc: 0.8416, precision: 0.9253, recall: 0.8573, f1: 0.8900, edges-ner-ontonotes_loss: 0.0363
09/16 06:13:14 AM: Evaluate: task edges-ner-ontonotes, batch 55 (157): mcc: 0.8845, acc: 0.8416, precision: 0.9253, recall: 0.8573, f1: 0.8900, edges-ner-ontonotes_loss: 0.0363
09/16 06:13:22 AM: Evaluate: task edges-ner-ontonotes, batch 99 (157): mcc: 0.9009, acc: 0.8602, precision: 0.9375, recall: 0.8758, f1: 0.9056, edges-ner-ontonotes_loss: 0.0320
09/16 06:13:24 AM: Evaluate: task edges-ner-ontonotes, batch 99 (157): mcc: 0.9009, acc: 0.8602, precision: 0.9375, recall: 0.8758, f1: 0.9056, edges-ner-ontonotes_loss: 0.0320
09/16 06:13:32 AM: Evaluate: task edges-ner-ontonotes, batch 145 (157): mcc: 0.9140, acc: 0.8762, precision: 0.9469, recall: 0.8911, f1: 0.9182, edges-ner-ontonotes_loss: 0.0281
09/16 06:13:34 AM: Evaluate: task edges-ner-ontonotes, batch 129 (157): mcc: 0.9109, acc: 0.8724, precision: 0.9457, recall: 0.8866, f1: 0.9152, edges-ner-ontonotes_loss: 0.0291
09/16 06:13:35 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:13:35 AM: Best result seen so far for macro.
09/16 06:13:35 AM: Updating LR scheduler:
09/16 06:13:35 AM: 	Best result seen so far for macro_avg: 0.918
09/16 06:13:35 AM: 	# validation passes without improvement: 0
09/16 06:13:35 AM: edges-ner-ontonotes_loss: training: 0.034638 validation: 0.027740
09/16 06:13:35 AM: macro_avg: validation: 0.918273
09/16 06:13:35 AM: micro_avg: validation: 0.000000
09/16 06:13:35 AM: edges-ner-ontonotes_mcc: training: 0.895152 validation: 0.914058
09/16 06:13:35 AM: edges-ner-ontonotes_acc: training: 0.845866 validation: 0.875796
09/16 06:13:35 AM: edges-ner-ontonotes_precision: training: 0.938930 validation: 0.946115
09/16 06:13:35 AM: edges-ner-ontonotes_recall: training: 0.864019 validation: 0.892023
09/16 06:13:35 AM: edges-ner-ontonotes_f1: training: 0.899918 validation: 0.918273
09/16 06:13:35 AM: Global learning rate: 0.0001
09/16 06:13:35 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:13:40 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:13:42 AM: Best result seen so far for macro.
09/16 06:13:42 AM: Updating LR scheduler:
09/16 06:13:42 AM: 	Best result seen so far for macro_avg: 0.918
09/16 06:13:42 AM: 	# validation passes without improvement: 0
09/16 06:13:42 AM: edges-ner-ontonotes_loss: training: 0.034638 validation: 0.027740
09/16 06:13:42 AM: macro_avg: validation: 0.918273
09/16 06:13:42 AM: micro_avg: validation: 0.000000
09/16 06:13:42 AM: edges-ner-ontonotes_mcc: training: 0.895152 validation: 0.914058
09/16 06:13:42 AM: edges-ner-ontonotes_acc: training: 0.845866 validation: 0.875796
09/16 06:13:42 AM: edges-ner-ontonotes_precision: training: 0.938930 validation: 0.946115
09/16 06:13:42 AM: edges-ner-ontonotes_recall: training: 0.864019 validation: 0.892023
09/16 06:13:42 AM: edges-ner-ontonotes_f1: training: 0.899918 validation: 0.918273
09/16 06:13:42 AM: Global learning rate: 0.0001
09/16 06:13:42 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:13:43 AM: Update 4047: task edges-ner-ontonotes, batch 47 (4047): mcc: 0.9221, acc: 0.8843, precision: 0.9481, recall: 0.9051, f1: 0.9261, edges-ner-ontonotes_loss: 0.0254
09/16 06:13:45 AM: Update 4029: task edges-ner-ontonotes, batch 29 (4029): mcc: 0.9212, acc: 0.8837, precision: 0.9471, recall: 0.9042, f1: 0.9252, edges-ner-ontonotes_loss: 0.0261
09/16 06:13:53 AM: Update 4104: task edges-ner-ontonotes, batch 104 (4104): mcc: 0.9197, acc: 0.8792, precision: 0.9495, recall: 0.8993, f1: 0.9237, edges-ner-ontonotes_loss: 0.0256
09/16 06:13:55 AM: Update 4078: task edges-ner-ontonotes, batch 78 (4078): mcc: 0.9202, acc: 0.8808, precision: 0.9494, recall: 0.9003, f1: 0.9242, edges-ner-ontonotes_loss: 0.0255
09/16 06:14:03 AM: Update 4173: task edges-ner-ontonotes, batch 173 (4173): mcc: 0.9209, acc: 0.8814, precision: 0.9497, recall: 0.9012, f1: 0.9248, edges-ner-ontonotes_loss: 0.0255
09/16 06:14:05 AM: Update 4148: task edges-ner-ontonotes, batch 148 (4148): mcc: 0.9201, acc: 0.8803, precision: 0.9495, recall: 0.8999, f1: 0.9240, edges-ner-ontonotes_loss: 0.0257
09/16 06:14:13 AM: Update 4243: task edges-ner-ontonotes, batch 243 (4243): mcc: 0.9200, acc: 0.8803, precision: 0.9488, recall: 0.9005, f1: 0.9240, edges-ner-ontonotes_loss: 0.0259
09/16 06:14:15 AM: Update 4218: task edges-ner-ontonotes, batch 218 (4218): mcc: 0.9204, acc: 0.8812, precision: 0.9490, recall: 0.9010, f1: 0.9244, edges-ner-ontonotes_loss: 0.0257
09/16 06:14:23 AM: Update 4315: task edges-ner-ontonotes, batch 315 (4315): mcc: 0.9203, acc: 0.8807, precision: 0.9493, recall: 0.9006, f1: 0.9243, edges-ner-ontonotes_loss: 0.0256
09/16 06:14:26 AM: Update 4288: task edges-ner-ontonotes, batch 288 (4288): mcc: 0.9203, acc: 0.8806, precision: 0.9494, recall: 0.9005, f1: 0.9243, edges-ner-ontonotes_loss: 0.0257
09/16 06:14:33 AM: Update 4371: task edges-ner-ontonotes, batch 371 (4371): mcc: 0.9185, acc: 0.8781, precision: 0.9478, recall: 0.8986, f1: 0.9226, edges-ner-ontonotes_loss: 0.0262
09/16 06:14:36 AM: Update 4364: task edges-ner-ontonotes, batch 364 (4364): mcc: 0.9197, acc: 0.8798, precision: 0.9484, recall: 0.9002, f1: 0.9237, edges-ner-ontonotes_loss: 0.0259
09/16 06:14:43 AM: Update 4450: task edges-ner-ontonotes, batch 450 (4450): mcc: 0.9136, acc: 0.8712, precision: 0.9455, recall: 0.8917, f1: 0.9178, edges-ner-ontonotes_loss: 0.0282
09/16 06:14:46 AM: Update 4428: task edges-ner-ontonotes, batch 428 (4428): mcc: 0.9153, acc: 0.8739, precision: 0.9462, recall: 0.8943, f1: 0.9195, edges-ner-ontonotes_loss: 0.0276
09/16 06:14:53 AM: Update 4520: task edges-ner-ontonotes, batch 520 (4520): mcc: 0.9103, acc: 0.8668, precision: 0.9439, recall: 0.8872, f1: 0.9147, edges-ner-ontonotes_loss: 0.0297
09/16 06:14:56 AM: Update 4506: task edges-ner-ontonotes, batch 506 (4506): mcc: 0.9107, acc: 0.8675, precision: 0.9441, recall: 0.8878, f1: 0.9151, edges-ner-ontonotes_loss: 0.0295
09/16 06:15:05 AM: Update 4596: task edges-ner-ontonotes, batch 596 (4596): mcc: 0.9067, acc: 0.8623, precision: 0.9414, recall: 0.8829, f1: 0.9112, edges-ner-ontonotes_loss: 0.0314
09/16 06:15:06 AM: Update 4579: task edges-ner-ontonotes, batch 579 (4579): mcc: 0.9072, acc: 0.8630, precision: 0.9415, recall: 0.8836, f1: 0.9117, edges-ner-ontonotes_loss: 0.0311
09/16 06:15:15 AM: Update 4667: task edges-ner-ontonotes, batch 667 (4667): mcc: 0.9041, acc: 0.8590, precision: 0.9400, recall: 0.8794, f1: 0.9087, edges-ner-ontonotes_loss: 0.0323
09/16 06:15:16 AM: Update 4659: task edges-ner-ontonotes, batch 659 (4659): mcc: 0.9045, acc: 0.8595, precision: 0.9404, recall: 0.8799, f1: 0.9091, edges-ner-ontonotes_loss: 0.0322
09/16 06:15:25 AM: Update 4744: task edges-ner-ontonotes, batch 744 (4744): mcc: 0.9023, acc: 0.8566, precision: 0.9393, recall: 0.8768, f1: 0.9070, edges-ner-ontonotes_loss: 0.0328
09/16 06:15:27 AM: Update 4730: task edges-ner-ontonotes, batch 730 (4730): mcc: 0.9025, acc: 0.8569, precision: 0.9393, recall: 0.8771, f1: 0.9072, edges-ner-ontonotes_loss: 0.0328
09/16 06:15:35 AM: Update 4831: task edges-ner-ontonotes, batch 831 (4831): mcc: 0.9010, acc: 0.8547, precision: 0.9387, recall: 0.8750, f1: 0.9057, edges-ner-ontonotes_loss: 0.0332
09/16 06:15:37 AM: Update 4814: task edges-ner-ontonotes, batch 814 (4814): mcc: 0.9011, acc: 0.8549, precision: 0.9388, recall: 0.8751, f1: 0.9058, edges-ner-ontonotes_loss: 0.0331
09/16 06:15:45 AM: Update 4912: task edges-ner-ontonotes, batch 912 (4912): mcc: 0.9002, acc: 0.8538, precision: 0.9384, recall: 0.8739, f1: 0.9050, edges-ner-ontonotes_loss: 0.0334
09/16 06:15:47 AM: Update 4897: task edges-ner-ontonotes, batch 897 (4897): mcc: 0.9002, acc: 0.8538, precision: 0.9384, recall: 0.8739, f1: 0.9050, edges-ner-ontonotes_loss: 0.0334
09/16 06:15:57 AM: Update 4982: task edges-ner-ontonotes, batch 982 (4982): mcc: 0.8991, acc: 0.8524, precision: 0.9376, recall: 0.8726, f1: 0.9039, edges-ner-ontonotes_loss: 0.0337
09/16 06:15:58 AM: Update 4982: task edges-ner-ontonotes, batch 982 (4982): mcc: 0.8991, acc: 0.8524, precision: 0.9376, recall: 0.8726, f1: 0.9039, edges-ner-ontonotes_loss: 0.0337
09/16 06:15:59 AM: ***** Step 5000 / Validation 5 *****
09/16 06:15:59 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:15:59 AM: Validating...
09/16 06:16:01 AM: ***** Step 5000 / Validation 5 *****
09/16 06:16:01 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:16:02 AM: Validating...
09/16 06:16:07 AM: Evaluate: task edges-ner-ontonotes, batch 51 (157): mcc: 0.8939, acc: 0.8529, precision: 0.9333, recall: 0.8670, f1: 0.8989, edges-ner-ontonotes_loss: 0.0333
09/16 06:16:08 AM: Evaluate: task edges-ner-ontonotes, batch 32 (157): mcc: 0.8796, acc: 0.8347, precision: 0.9253, recall: 0.8482, f1: 0.8851, edges-ner-ontonotes_loss: 0.0373
09/16 06:16:17 AM: Evaluate: task edges-ner-ontonotes, batch 94 (157): mcc: 0.9134, acc: 0.8743, precision: 0.9496, recall: 0.8875, f1: 0.9175, edges-ner-ontonotes_loss: 0.0287
09/16 06:16:18 AM: Evaluate: task edges-ner-ontonotes, batch 75 (157): mcc: 0.9042, acc: 0.8632, precision: 0.9430, recall: 0.8769, f1: 0.9087, edges-ner-ontonotes_loss: 0.0311
09/16 06:16:27 AM: Evaluate: task edges-ner-ontonotes, batch 122 (157): mcc: 0.9160, acc: 0.8783, precision: 0.9498, recall: 0.8920, f1: 0.9200, edges-ner-ontonotes_loss: 0.0276
09/16 06:16:29 AM: Evaluate: task edges-ner-ontonotes, batch 120 (157): mcc: 0.9155, acc: 0.8777, precision: 0.9493, recall: 0.8916, f1: 0.9195, edges-ner-ontonotes_loss: 0.0277
09/16 06:16:35 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:16:36 AM: Best result seen so far for macro.
09/16 06:16:36 AM: Updating LR scheduler:
09/16 06:16:36 AM: 	Best result seen so far for macro_avg: 0.925
09/16 06:16:36 AM: 	# validation passes without improvement: 0
09/16 06:16:36 AM: edges-ner-ontonotes_loss: training: 0.033606 validation: 0.025734
09/16 06:16:36 AM: macro_avg: validation: 0.925273
09/16 06:16:36 AM: micro_avg: validation: 0.000000
09/16 06:16:36 AM: edges-ner-ontonotes_mcc: training: 0.899303 validation: 0.921435
09/16 06:16:36 AM: edges-ner-ontonotes_acc: training: 0.852545 validation: 0.885199
09/16 06:16:36 AM: edges-ner-ontonotes_precision: training: 0.937735 validation: 0.952618
09/16 06:16:36 AM: edges-ner-ontonotes_recall: training: 0.872765 validation: 0.899454
09/16 06:16:36 AM: edges-ner-ontonotes_f1: training: 0.904084 validation: 0.925273
09/16 06:16:36 AM: Global learning rate: 0.0001
09/16 06:16:36 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:16:36 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:16:36 AM: Best result seen so far for macro.
09/16 06:16:36 AM: Updating LR scheduler:
09/16 06:16:36 AM: 	Best result seen so far for macro_avg: 0.925
09/16 06:16:36 AM: 	# validation passes without improvement: 0
09/16 06:16:36 AM: edges-ner-ontonotes_loss: training: 0.033606 validation: 0.025734
09/16 06:16:36 AM: macro_avg: validation: 0.925273
09/16 06:16:36 AM: micro_avg: validation: 0.000000
09/16 06:16:36 AM: edges-ner-ontonotes_mcc: training: 0.899303 validation: 0.921435
09/16 06:16:36 AM: edges-ner-ontonotes_acc: training: 0.852545 validation: 0.885199
09/16 06:16:36 AM: edges-ner-ontonotes_precision: training: 0.937735 validation: 0.952618
09/16 06:16:36 AM: edges-ner-ontonotes_recall: training: 0.872765 validation: 0.899454
09/16 06:16:36 AM: edges-ner-ontonotes_f1: training: 0.904084 validation: 0.925273
09/16 06:16:36 AM: Global learning rate: 0.0001
09/16 06:16:36 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:16:37 AM: Update 5009: task edges-ner-ontonotes, batch 9 (5009): mcc: 0.8946, acc: 0.8535, precision: 0.9279, recall: 0.8735, f1: 0.8999, edges-ner-ontonotes_loss: 0.0319
09/16 06:16:39 AM: Update 5016: task edges-ner-ontonotes, batch 16 (5016): mcc: 0.8808, acc: 0.8372, precision: 0.9154, recall: 0.8598, f1: 0.8867, edges-ner-ontonotes_loss: 0.0356
09/16 06:16:47 AM: Update 5074: task edges-ner-ontonotes, batch 74 (5074): mcc: 0.8998, acc: 0.8564, precision: 0.9334, recall: 0.8778, f1: 0.9047, edges-ner-ontonotes_loss: 0.0305
09/16 06:16:49 AM: Update 5082: task edges-ner-ontonotes, batch 82 (5082): mcc: 0.8989, acc: 0.8551, precision: 0.9335, recall: 0.8760, f1: 0.9038, edges-ner-ontonotes_loss: 0.0311
09/16 06:16:58 AM: Update 5143: task edges-ner-ontonotes, batch 143 (5143): mcc: 0.9028, acc: 0.8601, precision: 0.9364, recall: 0.8804, f1: 0.9075, edges-ner-ontonotes_loss: 0.0308
09/16 06:16:59 AM: Update 5156: task edges-ner-ontonotes, batch 156 (5156): mcc: 0.9032, acc: 0.8602, precision: 0.9371, recall: 0.8804, f1: 0.9079, edges-ner-ontonotes_loss: 0.0305
09/16 06:17:08 AM: Update 5215: task edges-ner-ontonotes, batch 215 (5215): mcc: 0.9050, acc: 0.8629, precision: 0.9381, recall: 0.8829, f1: 0.9097, edges-ner-ontonotes_loss: 0.0300
09/16 06:17:09 AM: Update 5227: task edges-ner-ontonotes, batch 227 (5227): mcc: 0.9055, acc: 0.8633, precision: 0.9386, recall: 0.8835, f1: 0.9102, edges-ner-ontonotes_loss: 0.0299
09/16 06:17:19 AM: Update 5295: task edges-ner-ontonotes, batch 295 (5295): mcc: 0.9089, acc: 0.8673, precision: 0.9409, recall: 0.8874, f1: 0.9134, edges-ner-ontonotes_loss: 0.0291
09/16 06:17:20 AM: Update 5295: task edges-ner-ontonotes, batch 295 (5295): mcc: 0.9089, acc: 0.8673, precision: 0.9409, recall: 0.8874, f1: 0.9134, edges-ner-ontonotes_loss: 0.0291
09/16 06:17:29 AM: Update 5363: task edges-ner-ontonotes, batch 363 (5363): mcc: 0.9124, acc: 0.8720, precision: 0.9428, recall: 0.8922, f1: 0.9168, edges-ner-ontonotes_loss: 0.0279
09/16 06:17:30 AM: Update 5362: task edges-ner-ontonotes, batch 362 (5362): mcc: 0.9123, acc: 0.8717, precision: 0.9427, recall: 0.8919, f1: 0.9166, edges-ner-ontonotes_loss: 0.0279
09/16 06:17:39 AM: Update 5437: task edges-ner-ontonotes, batch 437 (5437): mcc: 0.9147, acc: 0.8748, precision: 0.9439, recall: 0.8953, f1: 0.9190, edges-ner-ontonotes_loss: 0.0272
09/16 06:17:40 AM: Update 5436: task edges-ner-ontonotes, batch 436 (5436): mcc: 0.9146, acc: 0.8748, precision: 0.9438, recall: 0.8953, f1: 0.9189, edges-ner-ontonotes_loss: 0.0272
09/16 06:17:50 AM: Update 5506: task edges-ner-ontonotes, batch 506 (5506): mcc: 0.9167, acc: 0.8775, precision: 0.9448, recall: 0.8981, f1: 0.9209, edges-ner-ontonotes_loss: 0.0267
09/16 06:17:50 AM: Update 5503: task edges-ner-ontonotes, batch 503 (5503): mcc: 0.9166, acc: 0.8774, precision: 0.9447, recall: 0.8981, f1: 0.9208, edges-ner-ontonotes_loss: 0.0267
09/16 06:18:00 AM: Update 5579: task edges-ner-ontonotes, batch 579 (5579): mcc: 0.9184, acc: 0.8797, precision: 0.9458, recall: 0.9004, f1: 0.9225, edges-ner-ontonotes_loss: 0.0262
09/16 06:18:00 AM: Update 5575: task edges-ner-ontonotes, batch 575 (5575): mcc: 0.9182, acc: 0.8794, precision: 0.9457, recall: 0.9000, f1: 0.9223, edges-ner-ontonotes_loss: 0.0263
09/16 06:18:10 AM: Update 5626: task edges-ner-ontonotes, batch 626 (5626): mcc: 0.9187, acc: 0.8801, precision: 0.9459, recall: 0.9008, f1: 0.9228, edges-ner-ontonotes_loss: 0.0261
09/16 06:18:11 AM: Update 5622: task edges-ner-ontonotes, batch 622 (5622): mcc: 0.9187, acc: 0.8802, precision: 0.9459, recall: 0.9009, f1: 0.9228, edges-ner-ontonotes_loss: 0.0261
09/16 06:18:20 AM: Update 5692: task edges-ner-ontonotes, batch 692 (5692): mcc: 0.9193, acc: 0.8810, precision: 0.9462, recall: 0.9017, f1: 0.9234, edges-ner-ontonotes_loss: 0.0259
09/16 06:18:21 AM: Update 5687: task edges-ner-ontonotes, batch 687 (5687): mcc: 0.9195, acc: 0.8811, precision: 0.9464, recall: 0.9019, f1: 0.9236, edges-ner-ontonotes_loss: 0.0258
09/16 06:18:30 AM: Update 5764: task edges-ner-ontonotes, batch 764 (5764): mcc: 0.9201, acc: 0.8817, precision: 0.9468, recall: 0.9027, f1: 0.9242, edges-ner-ontonotes_loss: 0.0256
09/16 06:18:31 AM: Update 5759: task edges-ner-ontonotes, batch 759 (5759): mcc: 0.9201, acc: 0.8817, precision: 0.9467, recall: 0.9027, f1: 0.9242, edges-ner-ontonotes_loss: 0.0256
09/16 06:18:40 AM: Update 5839: task edges-ner-ontonotes, batch 839 (5839): mcc: 0.9205, acc: 0.8821, precision: 0.9470, recall: 0.9031, f1: 0.9245, edges-ner-ontonotes_loss: 0.0254
09/16 06:18:41 AM: Update 5833: task edges-ner-ontonotes, batch 833 (5833): mcc: 0.9204, acc: 0.8820, precision: 0.9469, recall: 0.9031, f1: 0.9245, edges-ner-ontonotes_loss: 0.0254
09/16 06:18:50 AM: Update 5908: task edges-ner-ontonotes, batch 908 (5908): mcc: 0.9207, acc: 0.8824, precision: 0.9469, recall: 0.9036, f1: 0.9247, edges-ner-ontonotes_loss: 0.0254
09/16 06:18:51 AM: Update 5901: task edges-ner-ontonotes, batch 901 (5901): mcc: 0.9207, acc: 0.8824, precision: 0.9469, recall: 0.9035, f1: 0.9247, edges-ner-ontonotes_loss: 0.0254
09/16 06:19:00 AM: Update 5971: task edges-ner-ontonotes, batch 971 (5971): mcc: 0.9190, acc: 0.8802, precision: 0.9463, recall: 0.9010, f1: 0.9231, edges-ner-ontonotes_loss: 0.0261
09/16 06:19:01 AM: Update 5958: task edges-ner-ontonotes, batch 958 (5958): mcc: 0.9193, acc: 0.8806, precision: 0.9464, recall: 0.9014, f1: 0.9234, edges-ner-ontonotes_loss: 0.0260
09/16 06:19:05 AM: ***** Step 6000 / Validation 6 *****
09/16 06:19:05 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:19:05 AM: Validating...
09/16 06:19:08 AM: ***** Step 6000 / Validation 6 *****
09/16 06:19:08 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:19:08 AM: Validating...
09/16 06:19:10 AM: Evaluate: task edges-ner-ontonotes, batch 30 (157): mcc: 0.8711, acc: 0.8285, precision: 0.9085, recall: 0.8485, f1: 0.8775, edges-ner-ontonotes_loss: 0.0395
09/16 06:19:11 AM: Evaluate: task edges-ner-ontonotes, batch 18 (157): mcc: 0.8588, acc: 0.8067, precision: 0.9040, recall: 0.8300, f1: 0.8654, edges-ner-ontonotes_loss: 0.0383
09/16 06:19:21 AM: Evaluate: task edges-ner-ontonotes, batch 74 (157): mcc: 0.9041, acc: 0.8644, precision: 0.9358, recall: 0.8834, f1: 0.9088, edges-ner-ontonotes_loss: 0.0318
09/16 06:19:21 AM: Evaluate: task edges-ner-ontonotes, batch 64 (157): mcc: 0.9034, acc: 0.8652, precision: 0.9319, recall: 0.8860, f1: 0.9083, edges-ner-ontonotes_loss: 0.0317
09/16 06:19:31 AM: Evaluate: task edges-ner-ontonotes, batch 107 (157): mcc: 0.9144, acc: 0.8775, precision: 0.9424, recall: 0.8963, f1: 0.9188, edges-ner-ontonotes_loss: 0.0286
09/16 06:19:33 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9153, acc: 0.8782, precision: 0.9439, recall: 0.8963, f1: 0.9195, edges-ner-ontonotes_loss: 0.0280
09/16 06:19:41 AM: Evaluate: task edges-ner-ontonotes, batch 149 (157): mcc: 0.9244, acc: 0.8899, precision: 0.9494, recall: 0.9080, f1: 0.9283, edges-ner-ontonotes_loss: 0.0254
09/16 06:19:43 AM: Evaluate: task edges-ner-ontonotes, batch 156 (157): mcc: 0.9244, acc: 0.8897, precision: 0.9489, recall: 0.9086, f1: 0.9283, edges-ner-ontonotes_loss: 0.0252
09/16 06:19:43 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:19:44 AM: Best result seen so far for macro.
09/16 06:19:44 AM: Updating LR scheduler:
09/16 06:19:44 AM: 	Best result seen so far for macro_avg: 0.928
09/16 06:19:44 AM: 	# validation passes without improvement: 0
09/16 06:19:44 AM: edges-ner-ontonotes_loss: training: 0.026486 validation: 0.025087
09/16 06:19:44 AM: macro_avg: validation: 0.928298
09/16 06:19:44 AM: micro_avg: validation: 0.000000
09/16 06:19:44 AM: edges-ner-ontonotes_mcc: training: 0.918030 validation: 0.924421
09/16 06:19:44 AM: edges-ner-ontonotes_acc: training: 0.878821 validation: 0.889672
09/16 06:19:44 AM: edges-ner-ontonotes_precision: training: 0.945810 validation: 0.948919
09/16 06:19:44 AM: edges-ner-ontonotes_recall: training: 0.899677 validation: 0.908553
09/16 06:19:44 AM: edges-ner-ontonotes_f1: training: 0.922167 validation: 0.928298
09/16 06:19:44 AM: Global learning rate: 0.0001
09/16 06:19:44 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:19:44 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:19:44 AM: Best result seen so far for macro.
09/16 06:19:44 AM: Updating LR scheduler:
09/16 06:19:44 AM: 	Best result seen so far for macro_avg: 0.928
09/16 06:19:44 AM: 	# validation passes without improvement: 0
09/16 06:19:44 AM: edges-ner-ontonotes_loss: training: 0.026486 validation: 0.025087
09/16 06:19:44 AM: macro_avg: validation: 0.928298
09/16 06:19:44 AM: micro_avg: validation: 0.000000
09/16 06:19:44 AM: edges-ner-ontonotes_mcc: training: 0.918030 validation: 0.924421
09/16 06:19:44 AM: edges-ner-ontonotes_acc: training: 0.878821 validation: 0.889672
09/16 06:19:44 AM: edges-ner-ontonotes_precision: training: 0.945810 validation: 0.948919
09/16 06:19:44 AM: edges-ner-ontonotes_recall: training: 0.899677 validation: 0.908553
09/16 06:19:44 AM: edges-ner-ontonotes_f1: training: 0.922167 validation: 0.928298
09/16 06:19:44 AM: Global learning rate: 0.0001
09/16 06:19:44 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:19:51 AM: Update 6056: task edges-ner-ontonotes, batch 56 (6056): mcc: 0.8915, acc: 0.8453, precision: 0.9285, recall: 0.8672, f1: 0.8968, edges-ner-ontonotes_loss: 0.0375
09/16 06:19:54 AM: Update 6072: task edges-ner-ontonotes, batch 72 (6072): mcc: 0.8889, acc: 0.8427, precision: 0.9243, recall: 0.8662, f1: 0.8943, edges-ner-ontonotes_loss: 0.0377
09/16 06:20:01 AM: Update 6127: task edges-ner-ontonotes, batch 127 (6127): mcc: 0.8877, acc: 0.8396, precision: 0.9250, recall: 0.8634, f1: 0.8931, edges-ner-ontonotes_loss: 0.0385
09/16 06:20:04 AM: Update 6146: task edges-ner-ontonotes, batch 146 (6146): mcc: 0.8870, acc: 0.8389, precision: 0.9248, recall: 0.8624, f1: 0.8925, edges-ner-ontonotes_loss: 0.0387
09/16 06:20:12 AM: Update 6199: task edges-ner-ontonotes, batch 199 (6199): mcc: 0.8891, acc: 0.8423, precision: 0.9276, recall: 0.8636, f1: 0.8944, edges-ner-ontonotes_loss: 0.0385
09/16 06:20:14 AM: Update 6219: task edges-ner-ontonotes, batch 219 (6219): mcc: 0.8895, acc: 0.8425, precision: 0.9281, recall: 0.8638, f1: 0.8948, edges-ner-ontonotes_loss: 0.0382
09/16 06:20:22 AM: Update 6276: task edges-ner-ontonotes, batch 276 (6276): mcc: 0.8904, acc: 0.8431, precision: 0.9290, recall: 0.8646, f1: 0.8956, edges-ner-ontonotes_loss: 0.0374
09/16 06:20:27 AM: Update 6279: task edges-ner-ontonotes, batch 279 (6279): mcc: 0.8906, acc: 0.8433, precision: 0.9293, recall: 0.8648, f1: 0.8959, edges-ner-ontonotes_loss: 0.0374
09/16 06:20:32 AM: Update 6364: task edges-ner-ontonotes, batch 364 (6364): mcc: 0.8895, acc: 0.8414, precision: 0.9286, recall: 0.8634, f1: 0.8948, edges-ner-ontonotes_loss: 0.0370
09/16 06:20:37 AM: Update 6374: task edges-ner-ontonotes, batch 374 (6374): mcc: 0.8891, acc: 0.8410, precision: 0.9282, recall: 0.8629, f1: 0.8944, edges-ner-ontonotes_loss: 0.0371
09/16 06:20:43 AM: Update 6450: task edges-ner-ontonotes, batch 450 (6450): mcc: 0.8896, acc: 0.8415, precision: 0.9290, recall: 0.8633, f1: 0.8949, edges-ner-ontonotes_loss: 0.0366
09/16 06:20:47 AM: Update 6464: task edges-ner-ontonotes, batch 464 (6464): mcc: 0.8898, acc: 0.8418, precision: 0.9291, recall: 0.8634, f1: 0.8951, edges-ner-ontonotes_loss: 0.0366
09/16 06:20:57 AM: Update 6538: task edges-ner-ontonotes, batch 538 (6538): mcc: 0.8907, acc: 0.8426, precision: 0.9299, recall: 0.8644, f1: 0.8959, edges-ner-ontonotes_loss: 0.0359
09/16 06:20:58 AM: Update 6538: task edges-ner-ontonotes, batch 538 (6538): mcc: 0.8907, acc: 0.8426, precision: 0.9299, recall: 0.8644, f1: 0.8959, edges-ner-ontonotes_loss: 0.0359
09/16 06:21:08 AM: Update 6610: task edges-ner-ontonotes, batch 610 (6610): mcc: 0.8942, acc: 0.8475, precision: 0.9316, recall: 0.8692, f1: 0.8993, edges-ner-ontonotes_loss: 0.0350
09/16 06:21:08 AM: Update 6611: task edges-ner-ontonotes, batch 611 (6611): mcc: 0.8942, acc: 0.8476, precision: 0.9314, recall: 0.8694, f1: 0.8993, edges-ner-ontonotes_loss: 0.0350
09/16 06:21:18 AM: Update 6683: task edges-ner-ontonotes, batch 683 (6683): mcc: 0.8966, acc: 0.8508, precision: 0.9327, recall: 0.8725, f1: 0.9016, edges-ner-ontonotes_loss: 0.0341
09/16 06:21:18 AM: Update 6683: task edges-ner-ontonotes, batch 683 (6683): mcc: 0.8966, acc: 0.8508, precision: 0.9327, recall: 0.8725, f1: 0.9016, edges-ner-ontonotes_loss: 0.0341
09/16 06:21:28 AM: Update 6761: task edges-ner-ontonotes, batch 761 (6761): mcc: 0.8988, acc: 0.8537, precision: 0.9339, recall: 0.8754, f1: 0.9037, edges-ner-ontonotes_loss: 0.0335
09/16 06:21:28 AM: Update 6760: task edges-ner-ontonotes, batch 760 (6760): mcc: 0.8988, acc: 0.8537, precision: 0.9339, recall: 0.8754, f1: 0.9037, edges-ner-ontonotes_loss: 0.0335
09/16 06:21:38 AM: Update 6827: task edges-ner-ontonotes, batch 827 (6827): mcc: 0.9001, acc: 0.8555, precision: 0.9345, recall: 0.8773, f1: 0.9050, edges-ner-ontonotes_loss: 0.0330
09/16 06:21:39 AM: Update 6825: task edges-ner-ontonotes, batch 825 (6825): mcc: 0.9001, acc: 0.8555, precision: 0.9344, recall: 0.8774, f1: 0.9050, edges-ner-ontonotes_loss: 0.0330
09/16 06:21:48 AM: Update 6890: task edges-ner-ontonotes, batch 890 (6890): mcc: 0.9021, acc: 0.8583, precision: 0.9356, recall: 0.8800, f1: 0.9070, edges-ner-ontonotes_loss: 0.0323
09/16 06:21:49 AM: Update 6881: task edges-ner-ontonotes, batch 881 (6881): mcc: 0.9018, acc: 0.8579, precision: 0.9354, recall: 0.8796, f1: 0.9067, edges-ner-ontonotes_loss: 0.0324
09/16 06:21:58 AM: Update 6959: task edges-ner-ontonotes, batch 959 (6959): mcc: 0.9043, acc: 0.8609, precision: 0.9367, recall: 0.8828, f1: 0.9090, edges-ner-ontonotes_loss: 0.0317
09/16 06:21:59 AM: Update 6949: task edges-ner-ontonotes, batch 949 (6949): mcc: 0.9041, acc: 0.8607, precision: 0.9366, recall: 0.8827, f1: 0.9088, edges-ner-ontonotes_loss: 0.0318
09/16 06:22:04 AM: ***** Step 7000 / Validation 7 *****
09/16 06:22:04 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:22:04 AM: Validating...
09/16 06:22:07 AM: ***** Step 7000 / Validation 7 *****
09/16 06:22:07 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:22:07 AM: Validating...
09/16 06:22:08 AM: Evaluate: task edges-ner-ontonotes, batch 23 (157): mcc: 0.8429, acc: 0.7983, precision: 0.8879, recall: 0.8161, f1: 0.8505, edges-ner-ontonotes_loss: 0.0440
09/16 06:22:09 AM: Evaluate: task edges-ner-ontonotes, batch 12 (157): mcc: 0.8185, acc: 0.7589, precision: 0.8831, recall: 0.7760, f1: 0.8261, edges-ner-ontonotes_loss: 0.0457
09/16 06:22:18 AM: Evaluate: task edges-ner-ontonotes, batch 69 (157): mcc: 0.9045, acc: 0.8660, precision: 0.9371, recall: 0.8830, f1: 0.9092, edges-ner-ontonotes_loss: 0.0308
09/16 06:22:19 AM: Evaluate: task edges-ner-ontonotes, batch 60 (157): mcc: 0.9052, acc: 0.8698, precision: 0.9341, recall: 0.8870, f1: 0.9100, edges-ner-ontonotes_loss: 0.0301
09/16 06:22:28 AM: Evaluate: task edges-ner-ontonotes, batch 111 (157): mcc: 0.9175, acc: 0.8837, precision: 0.9439, recall: 0.9004, f1: 0.9217, edges-ner-ontonotes_loss: 0.0270
09/16 06:22:29 AM: Evaluate: task edges-ner-ontonotes, batch 102 (157): mcc: 0.9132, acc: 0.8782, precision: 0.9411, recall: 0.8952, f1: 0.9176, edges-ner-ontonotes_loss: 0.0282
09/16 06:22:38 AM: Evaluate: task edges-ner-ontonotes, batch 150 (157): mcc: 0.9266, acc: 0.8947, precision: 0.9494, recall: 0.9121, f1: 0.9304, edges-ner-ontonotes_loss: 0.0243
09/16 06:22:39 AM: Evaluate: task edges-ner-ontonotes, batch 140 (157): mcc: 0.9266, acc: 0.8949, precision: 0.9502, recall: 0.9113, f1: 0.9304, edges-ner-ontonotes_loss: 0.0245
09/16 06:22:40 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:22:40 AM: Best result seen so far for macro.
09/16 06:22:40 AM: Updating LR scheduler:
09/16 06:22:40 AM: 	Best result seen so far for macro_avg: 0.931
09/16 06:22:40 AM: 	# validation passes without improvement: 0
09/16 06:22:40 AM: edges-ner-ontonotes_loss: training: 0.031286 validation: 0.024039
09/16 06:22:40 AM: macro_avg: validation: 0.931097
09/16 06:22:40 AM: micro_avg: validation: 0.000000
09/16 06:22:40 AM: edges-ner-ontonotes_mcc: training: 0.905643 validation: 0.927320
09/16 06:22:40 AM: edges-ner-ontonotes_acc: training: 0.862613 validation: 0.895587
09/16 06:22:40 AM: edges-ner-ontonotes_precision: training: 0.937671 validation: 0.949405
09/16 06:22:40 AM: edges-ner-ontonotes_recall: training: 0.884528 validation: 0.913482
09/16 06:22:40 AM: edges-ner-ontonotes_f1: training: 0.910325 validation: 0.931097
09/16 06:22:40 AM: Global learning rate: 0.0001
09/16 06:22:40 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:22:42 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:22:42 AM: Best result seen so far for macro.
09/16 06:22:42 AM: Updating LR scheduler:
09/16 06:22:42 AM: 	Best result seen so far for macro_avg: 0.931
09/16 06:22:42 AM: 	# validation passes without improvement: 0
09/16 06:22:42 AM: edges-ner-ontonotes_loss: training: 0.031286 validation: 0.024039
09/16 06:22:42 AM: macro_avg: validation: 0.931097
09/16 06:22:42 AM: micro_avg: validation: 0.000000
09/16 06:22:42 AM: edges-ner-ontonotes_mcc: training: 0.905643 validation: 0.927320
09/16 06:22:42 AM: edges-ner-ontonotes_acc: training: 0.862613 validation: 0.895587
09/16 06:22:42 AM: edges-ner-ontonotes_precision: training: 0.937671 validation: 0.949405
09/16 06:22:42 AM: edges-ner-ontonotes_recall: training: 0.884528 validation: 0.913482
09/16 06:22:42 AM: edges-ner-ontonotes_f1: training: 0.910325 validation: 0.931097
09/16 06:22:42 AM: Global learning rate: 0.0001
09/16 06:22:42 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:22:48 AM: Update 7054: task edges-ner-ontonotes, batch 54 (7054): mcc: 0.9292, acc: 0.8948, precision: 0.9497, recall: 0.9166, f1: 0.9329, edges-ner-ontonotes_loss: 0.0227
09/16 06:22:49 AM: Update 7047: task edges-ner-ontonotes, batch 47 (7047): mcc: 0.9291, acc: 0.8952, precision: 0.9486, recall: 0.9176, f1: 0.9328, edges-ner-ontonotes_loss: 0.0228
09/16 06:22:58 AM: Update 7122: task edges-ner-ontonotes, batch 122 (7122): mcc: 0.9303, acc: 0.8961, precision: 0.9500, recall: 0.9185, f1: 0.9340, edges-ner-ontonotes_loss: 0.0220
09/16 06:22:59 AM: Update 7117: task edges-ner-ontonotes, batch 117 (7117): mcc: 0.9302, acc: 0.8959, precision: 0.9494, recall: 0.9188, f1: 0.9339, edges-ner-ontonotes_loss: 0.0222
09/16 06:23:08 AM: Update 7165: task edges-ner-ontonotes, batch 165 (7165): mcc: 0.9313, acc: 0.8976, precision: 0.9518, recall: 0.9185, f1: 0.9349, edges-ner-ontonotes_loss: 0.0218
09/16 06:23:09 AM: Update 7177: task edges-ner-ontonotes, batch 177 (7177): mcc: 0.9312, acc: 0.8973, precision: 0.9516, recall: 0.9185, f1: 0.9348, edges-ner-ontonotes_loss: 0.0218
09/16 06:23:18 AM: Update 7236: task edges-ner-ontonotes, batch 236 (7236): mcc: 0.9288, acc: 0.8934, precision: 0.9498, recall: 0.9159, f1: 0.9325, edges-ner-ontonotes_loss: 0.0225
09/16 06:23:19 AM: Update 7247: task edges-ner-ontonotes, batch 247 (7247): mcc: 0.9291, acc: 0.8938, precision: 0.9502, recall: 0.9161, f1: 0.9328, edges-ner-ontonotes_loss: 0.0226
09/16 06:23:28 AM: Update 7309: task edges-ner-ontonotes, batch 309 (7309): mcc: 0.9302, acc: 0.8950, precision: 0.9517, recall: 0.9166, f1: 0.9338, edges-ner-ontonotes_loss: 0.0223
09/16 06:23:30 AM: Update 7320: task edges-ner-ontonotes, batch 320 (7320): mcc: 0.9304, acc: 0.8952, precision: 0.9518, recall: 0.9168, f1: 0.9340, edges-ner-ontonotes_loss: 0.0222
09/16 06:23:38 AM: Update 7371: task edges-ner-ontonotes, batch 371 (7371): mcc: 0.9304, acc: 0.8952, precision: 0.9514, recall: 0.9173, f1: 0.9341, edges-ner-ontonotes_loss: 0.0220
09/16 06:23:40 AM: Update 7391: task edges-ner-ontonotes, batch 391 (7391): mcc: 0.9306, acc: 0.8955, precision: 0.9515, recall: 0.9176, f1: 0.9343, edges-ner-ontonotes_loss: 0.0220
09/16 06:23:51 AM: Update 7446: task edges-ner-ontonotes, batch 446 (7446): mcc: 0.9298, acc: 0.8943, precision: 0.9508, recall: 0.9168, f1: 0.9335, edges-ner-ontonotes_loss: 0.0224
09/16 06:23:51 AM: Update 7464: task edges-ner-ontonotes, batch 464 (7464): mcc: 0.9293, acc: 0.8936, precision: 0.9503, recall: 0.9163, f1: 0.9330, edges-ner-ontonotes_loss: 0.0225
09/16 06:24:01 AM: Update 7514: task edges-ner-ontonotes, batch 514 (7514): mcc: 0.9267, acc: 0.8898, precision: 0.9492, recall: 0.9124, f1: 0.9305, edges-ner-ontonotes_loss: 0.0237
09/16 06:24:01 AM: Update 7522: task edges-ner-ontonotes, batch 522 (7522): mcc: 0.9262, acc: 0.8894, precision: 0.9487, recall: 0.9120, f1: 0.9300, edges-ner-ontonotes_loss: 0.0239
09/16 06:24:11 AM: Update 7578: task edges-ner-ontonotes, batch 578 (7578): mcc: 0.9230, acc: 0.8853, precision: 0.9469, recall: 0.9078, f1: 0.9269, edges-ner-ontonotes_loss: 0.0252
09/16 06:24:11 AM: Update 7588: task edges-ner-ontonotes, batch 588 (7588): mcc: 0.9224, acc: 0.8845, precision: 0.9466, recall: 0.9070, f1: 0.9264, edges-ner-ontonotes_loss: 0.0254
09/16 06:24:21 AM: Update 7655: task edges-ner-ontonotes, batch 655 (7655): mcc: 0.9198, acc: 0.8812, precision: 0.9451, recall: 0.9037, f1: 0.9239, edges-ner-ontonotes_loss: 0.0267
09/16 06:24:21 AM: Update 7664: task edges-ner-ontonotes, batch 664 (7664): mcc: 0.9194, acc: 0.8808, precision: 0.9448, recall: 0.9033, f1: 0.9236, edges-ner-ontonotes_loss: 0.0269
09/16 06:24:31 AM: Update 7723: task edges-ner-ontonotes, batch 723 (7723): mcc: 0.9172, acc: 0.8778, precision: 0.9434, recall: 0.9004, f1: 0.9214, edges-ner-ontonotes_loss: 0.0277
09/16 06:24:31 AM: Update 7732: task edges-ner-ontonotes, batch 732 (7732): mcc: 0.9169, acc: 0.8774, precision: 0.9432, recall: 0.9001, f1: 0.9212, edges-ner-ontonotes_loss: 0.0278
09/16 06:24:41 AM: Update 7782: task edges-ner-ontonotes, batch 782 (7782): mcc: 0.9156, acc: 0.8758, precision: 0.9426, recall: 0.8983, f1: 0.9199, edges-ner-ontonotes_loss: 0.0284
09/16 06:24:41 AM: Update 7799: task edges-ner-ontonotes, batch 799 (7799): mcc: 0.9152, acc: 0.8752, precision: 0.9422, recall: 0.8978, f1: 0.9195, edges-ner-ontonotes_loss: 0.0286
09/16 06:24:51 AM: Update 7871: task edges-ner-ontonotes, batch 871 (7871): mcc: 0.9137, acc: 0.8733, precision: 0.9414, recall: 0.8959, f1: 0.9181, edges-ner-ontonotes_loss: 0.0292
09/16 06:24:51 AM: Update 7886: task edges-ner-ontonotes, batch 886 (7886): mcc: 0.9136, acc: 0.8732, precision: 0.9413, recall: 0.8957, f1: 0.9180, edges-ner-ontonotes_loss: 0.0292
09/16 06:25:01 AM: Update 7960: task edges-ner-ontonotes, batch 960 (7960): mcc: 0.9129, acc: 0.8723, precision: 0.9410, recall: 0.8947, f1: 0.9173, edges-ner-ontonotes_loss: 0.0295
09/16 06:25:01 AM: Update 7975: task edges-ner-ontonotes, batch 975 (7975): mcc: 0.9125, acc: 0.8719, precision: 0.9406, recall: 0.8944, f1: 0.9170, edges-ner-ontonotes_loss: 0.0296
09/16 06:25:04 AM: ***** Step 8000 / Validation 8 *****
09/16 06:25:04 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:25:04 AM: Validating...
09/16 06:25:06 AM: ***** Step 8000 / Validation 8 *****
09/16 06:25:06 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:25:06 AM: Validating...
09/16 06:25:11 AM: Evaluate: task edges-ner-ontonotes, batch 40 (157): mcc: 0.8967, acc: 0.8587, precision: 0.9315, recall: 0.8738, f1: 0.9018, edges-ner-ontonotes_loss: 0.0326
09/16 06:25:11 AM: Evaluate: task edges-ner-ontonotes, batch 25 (157): mcc: 0.8621, acc: 0.8164, precision: 0.9084, recall: 0.8321, f1: 0.8686, edges-ner-ontonotes_loss: 0.0394
09/16 06:25:21 AM: Evaluate: task edges-ner-ontonotes, batch 71 (157): mcc: 0.9102, acc: 0.8720, precision: 0.9448, recall: 0.8862, f1: 0.9146, edges-ner-ontonotes_loss: 0.0293
09/16 06:25:21 AM: Evaluate: task edges-ner-ontonotes, batch 84 (157): mcc: 0.9189, acc: 0.8834, precision: 0.9503, recall: 0.8970, f1: 0.9228, edges-ner-ontonotes_loss: 0.0273
09/16 06:25:31 AM: Evaluate: task edges-ner-ontonotes, batch 123 (157): mcc: 0.9235, acc: 0.8895, precision: 0.9524, recall: 0.9035, f1: 0.9273, edges-ner-ontonotes_loss: 0.0251
09/16 06:25:32 AM: Evaluate: task edges-ner-ontonotes, batch 112 (157): mcc: 0.9211, acc: 0.8867, precision: 0.9497, recall: 0.9016, f1: 0.9250, edges-ner-ontonotes_loss: 0.0257
09/16 06:25:39 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:25:39 AM: Best result seen so far for macro.
09/16 06:25:39 AM: Updating LR scheduler:
09/16 06:25:39 AM: 	Best result seen so far for macro_avg: 0.933
09/16 06:25:39 AM: 	# validation passes without improvement: 0
09/16 06:25:39 AM: edges-ner-ontonotes_loss: training: 0.029611 validation: 0.023296
09/16 06:25:39 AM: macro_avg: validation: 0.932764
09/16 06:25:39 AM: micro_avg: validation: 0.000000
09/16 06:25:39 AM: edges-ner-ontonotes_mcc: training: 0.912255 validation: 0.929189
09/16 06:25:39 AM: edges-ner-ontonotes_acc: training: 0.871535 validation: 0.896345
09/16 06:25:39 AM: edges-ner-ontonotes_precision: training: 0.940611 validation: 0.955033
09/16 06:25:39 AM: edges-ner-ontonotes_recall: training: 0.893964 validation: 0.911510
09/16 06:25:39 AM: edges-ner-ontonotes_f1: training: 0.916694 validation: 0.932764
09/16 06:25:39 AM: Global learning rate: 0.0001
09/16 06:25:39 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:25:42 AM: Evaluate: task edges-ner-ontonotes, batch 154 (157): mcc: 0.9288, acc: 0.8958, precision: 0.9551, recall: 0.9108, f1: 0.9324, edges-ner-ontonotes_loss: 0.0235
09/16 06:25:42 AM: Update 8014: task edges-ner-ontonotes, batch 14 (8014): mcc: 0.9021, acc: 0.8567, precision: 0.9390, recall: 0.8767, f1: 0.9068, edges-ner-ontonotes_loss: 0.0317
09/16 06:25:42 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:25:42 AM: Best result seen so far for macro.
09/16 06:25:42 AM: Updating LR scheduler:
09/16 06:25:42 AM: 	Best result seen so far for macro_avg: 0.933
09/16 06:25:42 AM: 	# validation passes without improvement: 0
09/16 06:25:42 AM: edges-ner-ontonotes_loss: training: 0.029611 validation: 0.023296
09/16 06:25:42 AM: macro_avg: validation: 0.932764
09/16 06:25:42 AM: micro_avg: validation: 0.000000
09/16 06:25:42 AM: edges-ner-ontonotes_mcc: training: 0.912255 validation: 0.929189
09/16 06:25:42 AM: edges-ner-ontonotes_acc: training: 0.871535 validation: 0.896345
09/16 06:25:42 AM: edges-ner-ontonotes_precision: training: 0.940611 validation: 0.955033
09/16 06:25:42 AM: edges-ner-ontonotes_recall: training: 0.893964 validation: 0.911510
09/16 06:25:42 AM: edges-ner-ontonotes_f1: training: 0.916694 validation: 0.932764
09/16 06:25:42 AM: Global learning rate: 0.0001
09/16 06:25:42 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:25:52 AM: Update 8073: task edges-ner-ontonotes, batch 73 (8073): mcc: 0.8994, acc: 0.8523, precision: 0.9346, recall: 0.8759, f1: 0.9043, edges-ner-ontonotes_loss: 0.0321
09/16 06:25:53 AM: Update 8094: task edges-ner-ontonotes, batch 94 (8094): mcc: 0.8985, acc: 0.8517, precision: 0.9330, recall: 0.8757, f1: 0.9035, edges-ner-ontonotes_loss: 0.0322
09/16 06:26:02 AM: Update 8129: task edges-ner-ontonotes, batch 129 (8129): mcc: 0.9048, acc: 0.8603, precision: 0.9355, recall: 0.8850, f1: 0.9096, edges-ner-ontonotes_loss: 0.0306
09/16 06:26:03 AM: Update 8176: task edges-ner-ontonotes, batch 176 (8176): mcc: 0.9086, acc: 0.8656, precision: 0.9371, recall: 0.8906, f1: 0.9133, edges-ner-ontonotes_loss: 0.0296
09/16 06:26:12 AM: Update 8203: task edges-ner-ontonotes, batch 203 (8203): mcc: 0.9100, acc: 0.8674, precision: 0.9382, recall: 0.8922, f1: 0.9146, edges-ner-ontonotes_loss: 0.0293
09/16 06:26:13 AM: Update 8249: task edges-ner-ontonotes, batch 249 (8249): mcc: 0.9124, acc: 0.8709, precision: 0.9396, recall: 0.8952, f1: 0.9169, edges-ner-ontonotes_loss: 0.0284
09/16 06:26:22 AM: Update 8276: task edges-ner-ontonotes, batch 276 (8276): mcc: 0.9117, acc: 0.8705, precision: 0.9388, recall: 0.8947, f1: 0.9162, edges-ner-ontonotes_loss: 0.0286
09/16 06:26:24 AM: Update 8321: task edges-ner-ontonotes, batch 321 (8321): mcc: 0.9127, acc: 0.8724, precision: 0.9388, recall: 0.8965, f1: 0.9172, edges-ner-ontonotes_loss: 0.0282
09/16 06:26:32 AM: Update 8348: task edges-ner-ontonotes, batch 348 (8348): mcc: 0.9132, acc: 0.8732, precision: 0.9391, recall: 0.8972, f1: 0.9176, edges-ner-ontonotes_loss: 0.0281
09/16 06:26:34 AM: Update 8392: task edges-ner-ontonotes, batch 392 (8392): mcc: 0.9145, acc: 0.8748, precision: 0.9404, recall: 0.8983, f1: 0.9189, edges-ner-ontonotes_loss: 0.0278
09/16 06:26:42 AM: Update 8409: task edges-ner-ontonotes, batch 409 (8409): mcc: 0.9144, acc: 0.8745, precision: 0.9407, recall: 0.8978, f1: 0.9188, edges-ner-ontonotes_loss: 0.0279
09/16 06:26:44 AM: Update 8453: task edges-ner-ontonotes, batch 453 (8453): mcc: 0.9165, acc: 0.8770, precision: 0.9417, recall: 0.9008, f1: 0.9208, edges-ner-ontonotes_loss: 0.0274
09/16 06:26:52 AM: Update 8483: task edges-ner-ontonotes, batch 483 (8483): mcc: 0.9176, acc: 0.8785, precision: 0.9427, recall: 0.9019, f1: 0.9219, edges-ner-ontonotes_loss: 0.0270
09/16 06:26:54 AM: Update 8525: task edges-ner-ontonotes, batch 525 (8525): mcc: 0.9190, acc: 0.8807, precision: 0.9434, recall: 0.9039, f1: 0.9232, edges-ner-ontonotes_loss: 0.0266
09/16 06:27:02 AM: Update 8550: task edges-ner-ontonotes, batch 550 (8550): mcc: 0.9194, acc: 0.8812, precision: 0.9433, recall: 0.9045, f1: 0.9235, edges-ner-ontonotes_loss: 0.0265
09/16 06:27:04 AM: Update 8594: task edges-ner-ontonotes, batch 594 (8594): mcc: 0.9208, acc: 0.8833, precision: 0.9442, recall: 0.9064, f1: 0.9249, edges-ner-ontonotes_loss: 0.0261
09/16 06:27:12 AM: Update 8618: task edges-ner-ontonotes, batch 618 (8618): mcc: 0.9215, acc: 0.8842, precision: 0.9447, recall: 0.9072, f1: 0.9256, edges-ner-ontonotes_loss: 0.0259
09/16 06:27:14 AM: Update 8662: task edges-ner-ontonotes, batch 662 (8662): mcc: 0.9229, acc: 0.8862, precision: 0.9455, recall: 0.9090, f1: 0.9269, edges-ner-ontonotes_loss: 0.0255
09/16 06:27:22 AM: Update 8694: task edges-ner-ontonotes, batch 694 (8694): mcc: 0.9235, acc: 0.8872, precision: 0.9459, recall: 0.9097, f1: 0.9275, edges-ner-ontonotes_loss: 0.0253
09/16 06:27:26 AM: Update 8720: task edges-ner-ontonotes, batch 720 (8720): mcc: 0.9239, acc: 0.8878, precision: 0.9463, recall: 0.9102, f1: 0.9279, edges-ner-ontonotes_loss: 0.0252
09/16 06:27:32 AM: Update 8754: task edges-ner-ontonotes, batch 754 (8754): mcc: 0.9244, acc: 0.8883, precision: 0.9466, recall: 0.9107, f1: 0.9283, edges-ner-ontonotes_loss: 0.0249
09/16 06:27:37 AM: Update 8788: task edges-ner-ontonotes, batch 788 (8788): mcc: 0.9252, acc: 0.8895, precision: 0.9471, recall: 0.9117, f1: 0.9291, edges-ner-ontonotes_loss: 0.0248
09/16 06:27:42 AM: Update 8829: task edges-ner-ontonotes, batch 829 (8829): mcc: 0.9253, acc: 0.8898, precision: 0.9471, recall: 0.9120, f1: 0.9292, edges-ner-ontonotes_loss: 0.0247
09/16 06:27:48 AM: Update 8864: task edges-ner-ontonotes, batch 864 (8864): mcc: 0.9255, acc: 0.8899, precision: 0.9473, recall: 0.9121, f1: 0.9294, edges-ner-ontonotes_loss: 0.0246
09/16 06:27:53 AM: Update 8907: task edges-ner-ontonotes, batch 907 (8907): mcc: 0.9259, acc: 0.8902, precision: 0.9476, recall: 0.9126, f1: 0.9298, edges-ner-ontonotes_loss: 0.0245
09/16 06:28:00 AM: Update 8935: task edges-ner-ontonotes, batch 935 (8935): mcc: 0.9260, acc: 0.8905, precision: 0.9477, recall: 0.9127, f1: 0.9299, edges-ner-ontonotes_loss: 0.0244
09/16 06:28:03 AM: Update 8978: task edges-ner-ontonotes, batch 978 (8978): mcc: 0.9262, acc: 0.8907, precision: 0.9476, recall: 0.9131, f1: 0.9300, edges-ner-ontonotes_loss: 0.0243
09/16 06:28:06 AM: ***** Step 9000 / Validation 9 *****
09/16 06:28:06 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:28:06 AM: Validating...
09/16 06:28:10 AM: ***** Step 9000 / Validation 9 *****
09/16 06:28:10 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:28:10 AM: Validating...
09/16 06:28:10 AM: Evaluate: task edges-ner-ontonotes, batch 1 (157): mcc: 0.7480, acc: 0.6885, precision: 0.8400, recall: 0.6885, f1: 0.7568, edges-ner-ontonotes_loss: 0.0599
09/16 06:28:13 AM: Evaluate: task edges-ner-ontonotes, batch 37 (157): mcc: 0.8861, acc: 0.8462, precision: 0.9246, recall: 0.8608, f1: 0.8916, edges-ner-ontonotes_loss: 0.0360
09/16 06:28:20 AM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.8998, acc: 0.8642, precision: 0.9326, recall: 0.8785, f1: 0.9048, edges-ner-ontonotes_loss: 0.0321
09/16 06:28:23 AM: Evaluate: task edges-ner-ontonotes, batch 85 (157): mcc: 0.9174, acc: 0.8827, precision: 0.9473, recall: 0.8970, f1: 0.9215, edges-ner-ontonotes_loss: 0.0282
09/16 06:28:30 AM: Evaluate: task edges-ner-ontonotes, batch 92 (157): mcc: 0.9173, acc: 0.8822, precision: 0.9473, recall: 0.8970, f1: 0.9214, edges-ner-ontonotes_loss: 0.0279
09/16 06:28:33 AM: Evaluate: task edges-ner-ontonotes, batch 122 (157): mcc: 0.9242, acc: 0.8914, precision: 0.9498, recall: 0.9074, f1: 0.9281, edges-ner-ontonotes_loss: 0.0256
09/16 06:28:39 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:28:39 AM: Best result seen so far for macro.
09/16 06:28:39 AM: Updating LR scheduler:
09/16 06:28:39 AM: 	Best result seen so far for macro_avg: 0.935
09/16 06:28:39 AM: 	# validation passes without improvement: 0
09/16 06:28:39 AM: edges-ner-ontonotes_loss: training: 0.024192 validation: 0.023166
09/16 06:28:39 AM: macro_avg: validation: 0.934904
09/16 06:28:39 AM: micro_avg: validation: 0.000000
09/16 06:28:39 AM: edges-ner-ontonotes_mcc: training: 0.926363 validation: 0.931339
09/16 06:28:39 AM: edges-ner-ontonotes_acc: training: 0.891024 validation: 0.900440
09/16 06:28:39 AM: edges-ner-ontonotes_precision: training: 0.947673 validation: 0.952981
09/16 06:28:39 AM: edges-ner-ontonotes_recall: training: 0.913384 validation: 0.917501
09/16 06:28:39 AM: edges-ner-ontonotes_f1: training: 0.930213 validation: 0.934904
09/16 06:28:39 AM: Global learning rate: 0.0001
09/16 06:28:39 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:28:40 AM: Evaluate: task edges-ner-ontonotes, batch 119 (157): mcc: 0.9228, acc: 0.8895, precision: 0.9490, recall: 0.9055, f1: 0.9268, edges-ner-ontonotes_loss: 0.0259
09/16 06:28:43 AM: Update 9022: task edges-ner-ontonotes, batch 22 (9022): mcc: 0.9309, acc: 0.8945, precision: 0.9507, recall: 0.9189, f1: 0.9345, edges-ner-ontonotes_loss: 0.0233
09/16 06:28:46 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:28:46 AM: Best result seen so far for macro.
09/16 06:28:46 AM: Updating LR scheduler:
09/16 06:28:46 AM: 	Best result seen so far for macro_avg: 0.935
09/16 06:28:46 AM: 	# validation passes without improvement: 0
09/16 06:28:46 AM: edges-ner-ontonotes_loss: training: 0.024192 validation: 0.023166
09/16 06:28:46 AM: macro_avg: validation: 0.934904
09/16 06:28:46 AM: micro_avg: validation: 0.000000
09/16 06:28:46 AM: edges-ner-ontonotes_mcc: training: 0.926363 validation: 0.931339
09/16 06:28:46 AM: edges-ner-ontonotes_acc: training: 0.891024 validation: 0.900440
09/16 06:28:46 AM: edges-ner-ontonotes_precision: training: 0.947673 validation: 0.952981
09/16 06:28:46 AM: edges-ner-ontonotes_recall: training: 0.913384 validation: 0.917501
09/16 06:28:46 AM: edges-ner-ontonotes_f1: training: 0.930213 validation: 0.934904
09/16 06:28:46 AM: Global learning rate: 0.0001
09/16 06:28:46 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:28:53 AM: Update 9033: task edges-ner-ontonotes, batch 33 (9033): mcc: 0.9291, acc: 0.8914, precision: 0.9514, recall: 0.9149, f1: 0.9328, edges-ner-ontonotes_loss: 0.0235
09/16 06:28:56 AM: Update 9076: task edges-ner-ontonotes, batch 76 (9076): mcc: 0.9046, acc: 0.8610, precision: 0.9345, recall: 0.8857, f1: 0.9094, edges-ner-ontonotes_loss: 0.0322
09/16 06:29:03 AM: Update 9105: task edges-ner-ontonotes, batch 105 (9105): mcc: 0.9030, acc: 0.8599, precision: 0.9333, recall: 0.8838, f1: 0.9079, edges-ner-ontonotes_loss: 0.0333
09/16 06:29:06 AM: Update 9151: task edges-ner-ontonotes, batch 151 (9151): mcc: 0.9015, acc: 0.8573, precision: 0.9336, recall: 0.8807, f1: 0.9064, edges-ner-ontonotes_loss: 0.0337
09/16 06:29:13 AM: Update 9180: task edges-ner-ontonotes, batch 180 (9180): mcc: 0.9017, acc: 0.8578, precision: 0.9338, recall: 0.8809, f1: 0.9066, edges-ner-ontonotes_loss: 0.0338
09/16 06:29:16 AM: Update 9224: task edges-ner-ontonotes, batch 224 (9224): mcc: 0.9003, acc: 0.8566, precision: 0.9323, recall: 0.8798, f1: 0.9053, edges-ner-ontonotes_loss: 0.0347
09/16 06:29:23 AM: Update 9256: task edges-ner-ontonotes, batch 256 (9256): mcc: 0.8983, acc: 0.8544, precision: 0.9308, recall: 0.8776, f1: 0.9034, edges-ner-ontonotes_loss: 0.0354
09/16 06:29:26 AM: Update 9299: task edges-ner-ontonotes, batch 299 (9299): mcc: 0.8983, acc: 0.8544, precision: 0.9314, recall: 0.8769, f1: 0.9033, edges-ner-ontonotes_loss: 0.0355
09/16 06:29:33 AM: Update 9331: task edges-ner-ontonotes, batch 331 (9331): mcc: 0.8979, acc: 0.8541, precision: 0.9311, recall: 0.8766, f1: 0.9030, edges-ner-ontonotes_loss: 0.0355
09/16 06:29:36 AM: Update 9350: task edges-ner-ontonotes, batch 350 (9350): mcc: 0.8979, acc: 0.8542, precision: 0.9312, recall: 0.8763, f1: 0.9029, edges-ner-ontonotes_loss: 0.0356
09/16 06:29:43 AM: Update 9406: task edges-ner-ontonotes, batch 406 (9406): mcc: 0.8967, acc: 0.8524, precision: 0.9299, recall: 0.8754, f1: 0.9018, edges-ner-ontonotes_loss: 0.0356
09/16 06:29:46 AM: Update 9432: task edges-ner-ontonotes, batch 432 (9432): mcc: 0.8969, acc: 0.8525, precision: 0.9299, recall: 0.8758, f1: 0.9020, edges-ner-ontonotes_loss: 0.0354
09/16 06:29:53 AM: Update 9492: task edges-ner-ontonotes, batch 492 (9492): mcc: 0.8979, acc: 0.8536, precision: 0.9307, recall: 0.8769, f1: 0.9030, edges-ner-ontonotes_loss: 0.0349
09/16 06:29:56 AM: Update 9523: task edges-ner-ontonotes, batch 523 (9523): mcc: 0.8979, acc: 0.8539, precision: 0.9305, recall: 0.8770, f1: 0.9029, edges-ner-ontonotes_loss: 0.0348
09/16 06:30:04 AM: Update 9583: task edges-ner-ontonotes, batch 583 (9583): mcc: 0.8983, acc: 0.8543, precision: 0.9312, recall: 0.8771, f1: 0.9034, edges-ner-ontonotes_loss: 0.0344
09/16 06:30:06 AM: Update 9606: task edges-ner-ontonotes, batch 606 (9606): mcc: 0.8984, acc: 0.8543, precision: 0.9313, recall: 0.8772, f1: 0.9034, edges-ner-ontonotes_loss: 0.0343
09/16 06:30:14 AM: Update 9650: task edges-ner-ontonotes, batch 650 (9650): mcc: 0.8990, acc: 0.8551, precision: 0.9317, recall: 0.8781, f1: 0.9041, edges-ner-ontonotes_loss: 0.0340
09/16 06:30:16 AM: Update 9664: task edges-ner-ontonotes, batch 664 (9664): mcc: 0.8994, acc: 0.8556, precision: 0.9319, recall: 0.8785, f1: 0.9044, edges-ner-ontonotes_loss: 0.0339
09/16 06:30:24 AM: Update 9719: task edges-ner-ontonotes, batch 719 (9719): mcc: 0.9009, acc: 0.8575, precision: 0.9323, recall: 0.8809, f1: 0.9059, edges-ner-ontonotes_loss: 0.0333
09/16 06:30:27 AM: Update 9731: task edges-ner-ontonotes, batch 731 (9731): mcc: 0.9013, acc: 0.8581, precision: 0.9325, recall: 0.8814, f1: 0.9062, edges-ner-ontonotes_loss: 0.0331
09/16 06:30:34 AM: Update 9792: task edges-ner-ontonotes, batch 792 (9792): mcc: 0.9030, acc: 0.8606, precision: 0.9335, recall: 0.8837, f1: 0.9079, edges-ner-ontonotes_loss: 0.0326
09/16 06:30:37 AM: Update 9803: task edges-ner-ontonotes, batch 803 (9803): mcc: 0.9033, acc: 0.8610, precision: 0.9337, recall: 0.8841, f1: 0.9082, edges-ner-ontonotes_loss: 0.0325
09/16 06:30:44 AM: Update 9870: task edges-ner-ontonotes, batch 870 (9870): mcc: 0.9048, acc: 0.8628, precision: 0.9348, recall: 0.8857, f1: 0.9096, edges-ner-ontonotes_loss: 0.0319
09/16 06:30:47 AM: Update 9878: task edges-ner-ontonotes, batch 878 (9878): mcc: 0.9050, acc: 0.8631, precision: 0.9349, recall: 0.8860, f1: 0.9098, edges-ner-ontonotes_loss: 0.0318
09/16 06:30:54 AM: Update 9944: task edges-ner-ontonotes, batch 944 (9944): mcc: 0.9064, acc: 0.8649, precision: 0.9357, recall: 0.8877, f1: 0.9111, edges-ner-ontonotes_loss: 0.0314
09/16 06:30:57 AM: Update 9951: task edges-ner-ontonotes, batch 951 (9951): mcc: 0.9064, acc: 0.8650, precision: 0.9357, recall: 0.8877, f1: 0.9111, edges-ner-ontonotes_loss: 0.0314
09/16 06:31:04 AM: Update 9994: task edges-ner-ontonotes, batch 994 (9994): mcc: 0.9076, acc: 0.8664, precision: 0.9365, recall: 0.8893, f1: 0.9123, edges-ner-ontonotes_loss: 0.0309
09/16 06:31:05 AM: ***** Step 10000 / Validation 10 *****
09/16 06:31:05 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:31:05 AM: Validating...
09/16 06:31:06 AM: ***** Step 10000 / Validation 10 *****
09/16 06:31:06 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:31:06 AM: Validating...
09/16 06:31:07 AM: Evaluate: task edges-ner-ontonotes, batch 2 (157): mcc: 0.7963, acc: 0.7077, precision: 0.8807, recall: 0.7385, f1: 0.8033, edges-ner-ontonotes_loss: 0.0550
09/16 06:31:15 AM: Evaluate: task edges-ner-ontonotes, batch 50 (157): mcc: 0.9020, acc: 0.8636, precision: 0.9341, recall: 0.8811, f1: 0.9068, edges-ner-ontonotes_loss: 0.0309
09/16 06:31:17 AM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.9061, acc: 0.8693, precision: 0.9369, recall: 0.8861, f1: 0.9108, edges-ner-ontonotes_loss: 0.0299
09/16 06:31:25 AM: Evaluate: task edges-ner-ontonotes, batch 94 (157): mcc: 0.9229, acc: 0.8879, precision: 0.9507, recall: 0.9040, f1: 0.9267, edges-ner-ontonotes_loss: 0.0260
09/16 06:31:27 AM: Evaluate: task edges-ner-ontonotes, batch 96 (157): mcc: 0.9232, acc: 0.8891, precision: 0.9502, recall: 0.9050, f1: 0.9270, edges-ner-ontonotes_loss: 0.0260
09/16 06:31:35 AM: Evaluate: task edges-ner-ontonotes, batch 139 (157): mcc: 0.9320, acc: 0.9009, precision: 0.9544, recall: 0.9173, f1: 0.9355, edges-ner-ontonotes_loss: 0.0230
09/16 06:31:37 AM: Evaluate: task edges-ner-ontonotes, batch 119 (157): mcc: 0.9250, acc: 0.8912, precision: 0.9505, recall: 0.9080, f1: 0.9288, edges-ner-ontonotes_loss: 0.0248
09/16 06:31:38 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:31:38 AM: Best result seen so far for macro.
09/16 06:31:38 AM: Updating LR scheduler:
09/16 06:31:38 AM: 	Best result seen so far for macro_avg: 0.936
09/16 06:31:38 AM: 	# validation passes without improvement: 0
09/16 06:31:38 AM: edges-ner-ontonotes_loss: training: 0.030844 validation: 0.022505
09/16 06:31:38 AM: macro_avg: validation: 0.935876
09/16 06:31:38 AM: micro_avg: validation: 0.000000
09/16 06:31:38 AM: edges-ner-ontonotes_mcc: training: 0.907838 validation: 0.932351
09/16 06:31:38 AM: edges-ner-ontonotes_acc: training: 0.866706 validation: 0.901274
09/16 06:31:38 AM: edges-ner-ontonotes_precision: training: 0.936616 validation: 0.953284
09/16 06:31:38 AM: edges-ner-ontonotes_recall: training: 0.889611 validation: 0.919093
09/16 06:31:38 AM: edges-ner-ontonotes_f1: training: 0.912508 validation: 0.935876
09/16 06:31:38 AM: Global learning rate: 0.0001
09/16 06:31:38 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:31:44 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:31:44 AM: Best result seen so far for macro.
09/16 06:31:44 AM: Updating LR scheduler:
09/16 06:31:44 AM: 	Best result seen so far for macro_avg: 0.936
09/16 06:31:44 AM: 	# validation passes without improvement: 0
09/16 06:31:44 AM: edges-ner-ontonotes_loss: training: 0.030844 validation: 0.022505
09/16 06:31:44 AM: macro_avg: validation: 0.935876
09/16 06:31:44 AM: micro_avg: validation: 0.000000
09/16 06:31:44 AM: edges-ner-ontonotes_mcc: training: 0.907838 validation: 0.932351
09/16 06:31:44 AM: edges-ner-ontonotes_acc: training: 0.866706 validation: 0.901274
09/16 06:31:44 AM: edges-ner-ontonotes_precision: training: 0.936616 validation: 0.953284
09/16 06:31:44 AM: edges-ner-ontonotes_recall: training: 0.889611 validation: 0.919093
09/16 06:31:44 AM: edges-ner-ontonotes_f1: training: 0.912508 validation: 0.935876
09/16 06:31:44 AM: Global learning rate: 0.0001
09/16 06:31:44 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:31:45 AM: Update 10039: task edges-ner-ontonotes, batch 39 (10039): mcc: 0.9391, acc: 0.9079, precision: 0.9551, recall: 0.9299, f1: 0.9424, edges-ner-ontonotes_loss: 0.0198
09/16 06:31:47 AM: Update 10003: task edges-ner-ontonotes, batch 3 (10003): mcc: 0.9394, acc: 0.9027, precision: 0.9459, recall: 0.9396, f1: 0.9428, edges-ner-ontonotes_loss: 0.0227
09/16 06:31:55 AM: Update 10116: task edges-ner-ontonotes, batch 116 (10116): mcc: 0.9363, acc: 0.9048, precision: 0.9549, recall: 0.9249, f1: 0.9397, edges-ner-ontonotes_loss: 0.0211
09/16 06:31:57 AM: Update 10074: task edges-ner-ontonotes, batch 74 (10074): mcc: 0.9365, acc: 0.9062, precision: 0.9550, recall: 0.9252, f1: 0.9399, edges-ner-ontonotes_loss: 0.0208
09/16 06:32:05 AM: Update 10186: task edges-ner-ontonotes, batch 186 (10186): mcc: 0.9373, acc: 0.9062, precision: 0.9555, recall: 0.9261, f1: 0.9406, edges-ner-ontonotes_loss: 0.0206
09/16 06:32:07 AM: Update 10143: task edges-ner-ontonotes, batch 143 (10143): mcc: 0.9355, acc: 0.9034, precision: 0.9543, recall: 0.9240, f1: 0.9389, edges-ner-ontonotes_loss: 0.0210
09/16 06:32:15 AM: Update 10255: task edges-ner-ontonotes, batch 255 (10255): mcc: 0.9368, acc: 0.9050, precision: 0.9546, recall: 0.9262, f1: 0.9402, edges-ner-ontonotes_loss: 0.0206
09/16 06:32:17 AM: Update 10211: task edges-ner-ontonotes, batch 211 (10211): mcc: 0.9366, acc: 0.9051, precision: 0.9545, recall: 0.9258, f1: 0.9399, edges-ner-ontonotes_loss: 0.0207
09/16 06:32:25 AM: Update 10308: task edges-ner-ontonotes, batch 308 (10308): mcc: 0.9358, acc: 0.9037, precision: 0.9537, recall: 0.9250, f1: 0.9392, edges-ner-ontonotes_loss: 0.0207
09/16 06:32:29 AM: Update 10276: task edges-ner-ontonotes, batch 276 (10276): mcc: 0.9364, acc: 0.9046, precision: 0.9542, recall: 0.9257, f1: 0.9397, edges-ner-ontonotes_loss: 0.0206
09/16 06:32:35 AM: Update 10388: task edges-ner-ontonotes, batch 388 (10388): mcc: 0.9355, acc: 0.9032, precision: 0.9536, recall: 0.9247, f1: 0.9389, edges-ner-ontonotes_loss: 0.0207
09/16 06:32:39 AM: Update 10348: task edges-ner-ontonotes, batch 348 (10348): mcc: 0.9358, acc: 0.9036, precision: 0.9540, recall: 0.9249, f1: 0.9392, edges-ner-ontonotes_loss: 0.0208
09/16 06:32:46 AM: Update 10456: task edges-ner-ontonotes, batch 456 (10456): mcc: 0.9348, acc: 0.9021, precision: 0.9532, recall: 0.9238, f1: 0.9382, edges-ner-ontonotes_loss: 0.0209
09/16 06:32:49 AM: Update 10419: task edges-ner-ontonotes, batch 419 (10419): mcc: 0.9353, acc: 0.9028, precision: 0.9535, recall: 0.9244, f1: 0.9387, edges-ner-ontonotes_loss: 0.0208
09/16 06:32:57 AM: Update 10531: task edges-ner-ontonotes, batch 531 (10531): mcc: 0.9351, acc: 0.9024, precision: 0.9532, recall: 0.9243, f1: 0.9385, edges-ner-ontonotes_loss: 0.0211
09/16 06:32:59 AM: Update 10491: task edges-ner-ontonotes, batch 491 (10491): mcc: 0.9350, acc: 0.9026, precision: 0.9532, recall: 0.9242, f1: 0.9385, edges-ner-ontonotes_loss: 0.0211
09/16 06:33:08 AM: Update 10589: task edges-ner-ontonotes, batch 589 (10589): mcc: 0.9345, acc: 0.9015, precision: 0.9527, recall: 0.9237, f1: 0.9380, edges-ner-ontonotes_loss: 0.0212
09/16 06:33:09 AM: Update 10571: task edges-ner-ontonotes, batch 571 (10571): mcc: 0.9349, acc: 0.9021, precision: 0.9529, recall: 0.9243, f1: 0.9384, edges-ner-ontonotes_loss: 0.0211
09/16 06:33:18 AM: Update 10663: task edges-ner-ontonotes, batch 663 (10663): mcc: 0.9304, acc: 0.8960, precision: 0.9502, recall: 0.9184, f1: 0.9340, edges-ner-ontonotes_loss: 0.0229
09/16 06:33:19 AM: Update 10629: task edges-ner-ontonotes, batch 629 (10629): mcc: 0.9325, acc: 0.8987, precision: 0.9516, recall: 0.9210, f1: 0.9360, edges-ner-ontonotes_loss: 0.0220
09/16 06:33:28 AM: Update 10738: task edges-ner-ontonotes, batch 738 (10738): mcc: 0.9271, acc: 0.8918, precision: 0.9481, recall: 0.9144, f1: 0.9309, edges-ner-ontonotes_loss: 0.0241
09/16 06:33:29 AM: Update 10702: task edges-ner-ontonotes, batch 702 (10702): mcc: 0.9284, acc: 0.8934, precision: 0.9487, recall: 0.9162, f1: 0.9322, edges-ner-ontonotes_loss: 0.0236
09/16 06:33:38 AM: Update 10817: task edges-ner-ontonotes, batch 817 (10817): mcc: 0.9249, acc: 0.8888, precision: 0.9468, recall: 0.9114, f1: 0.9288, edges-ner-ontonotes_loss: 0.0253
09/16 06:33:39 AM: Update 10779: task edges-ner-ontonotes, batch 779 (10779): mcc: 0.9260, acc: 0.8903, precision: 0.9474, recall: 0.9130, f1: 0.9299, edges-ner-ontonotes_loss: 0.0247
09/16 06:33:48 AM: Update 10888: task edges-ner-ontonotes, batch 888 (10888): mcc: 0.9229, acc: 0.8864, precision: 0.9455, recall: 0.9090, f1: 0.9269, edges-ner-ontonotes_loss: 0.0262
09/16 06:33:49 AM: Update 10852: task edges-ner-ontonotes, batch 852 (10852): mcc: 0.9237, acc: 0.8875, precision: 0.9459, recall: 0.9102, f1: 0.9277, edges-ner-ontonotes_loss: 0.0258
09/16 06:33:58 AM: Update 10948: task edges-ner-ontonotes, batch 948 (10948): mcc: 0.9212, acc: 0.8841, precision: 0.9444, recall: 0.9068, f1: 0.9252, edges-ner-ontonotes_loss: 0.0267
09/16 06:34:00 AM: Update 10925: task edges-ner-ontonotes, batch 925 (10925): mcc: 0.9219, acc: 0.8850, precision: 0.9448, recall: 0.9077, f1: 0.9259, edges-ner-ontonotes_loss: 0.0265
09/16 06:34:04 AM: ***** Step 11000 / Validation 11 *****
09/16 06:34:04 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:34:04 AM: Validating...
09/16 06:34:08 AM: Evaluate: task edges-ner-ontonotes, batch 27 (157): mcc: 0.8773, acc: 0.8378, precision: 0.9129, recall: 0.8559, f1: 0.8834, edges-ner-ontonotes_loss: 0.0362
09/16 06:34:10 AM: Update 10997: task edges-ner-ontonotes, batch 997 (10997): mcc: 0.9205, acc: 0.8832, precision: 0.9441, recall: 0.9059, f1: 0.9246, edges-ner-ontonotes_loss: 0.0269
09/16 06:34:10 AM: ***** Step 11000 / Validation 11 *****
09/16 06:34:10 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:34:10 AM: Validating...
09/16 06:34:18 AM: Evaluate: task edges-ner-ontonotes, batch 78 (157): mcc: 0.9193, acc: 0.8850, precision: 0.9448, recall: 0.9030, f1: 0.9234, edges-ner-ontonotes_loss: 0.0269
09/16 06:34:20 AM: Evaluate: task edges-ner-ontonotes, batch 49 (157): mcc: 0.9057, acc: 0.8707, precision: 0.9313, recall: 0.8909, f1: 0.9106, edges-ner-ontonotes_loss: 0.0299
09/16 06:34:28 AM: Evaluate: task edges-ner-ontonotes, batch 117 (157): mcc: 0.9258, acc: 0.8924, precision: 0.9493, recall: 0.9108, f1: 0.9297, edges-ner-ontonotes_loss: 0.0244
09/16 06:34:30 AM: Evaluate: task edges-ner-ontonotes, batch 92 (157): mcc: 0.9234, acc: 0.8888, precision: 0.9487, recall: 0.9068, f1: 0.9273, edges-ner-ontonotes_loss: 0.0256
09/16 06:34:37 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:34:37 AM: Best result seen so far for macro.
09/16 06:34:37 AM: Updating LR scheduler:
09/16 06:34:37 AM: 	Best result seen so far for macro_avg: 0.936
09/16 06:34:37 AM: 	# validation passes without improvement: 0
09/16 06:34:37 AM: edges-ner-ontonotes_loss: training: 0.026942 validation: 0.022109
09/16 06:34:37 AM: macro_avg: validation: 0.936303
09/16 06:34:37 AM: micro_avg: validation: 0.000000
09/16 06:34:37 AM: edges-ner-ontonotes_mcc: training: 0.920476 validation: 0.932802
09/16 06:34:37 AM: edges-ner-ontonotes_acc: training: 0.883171 validation: 0.901350
09/16 06:34:37 AM: edges-ner-ontonotes_precision: training: 0.944067 validation: 0.953680
09/16 06:34:37 AM: edges-ner-ontonotes_recall: training: 0.905911 validation: 0.919548
09/16 06:34:37 AM: edges-ner-ontonotes_f1: training: 0.924596 validation: 0.936303
09/16 06:34:37 AM: Global learning rate: 0.0001
09/16 06:34:37 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:34:38 AM: Update 11009: task edges-ner-ontonotes, batch 9 (11009): mcc: 0.9093, acc: 0.8685, precision: 0.9537, recall: 0.8762, f1: 0.9133, edges-ner-ontonotes_loss: 0.0302
09/16 06:34:40 AM: Evaluate: task edges-ner-ontonotes, batch 132 (157): mcc: 0.9306, acc: 0.8985, precision: 0.9527, recall: 0.9164, f1: 0.9342, edges-ner-ontonotes_loss: 0.0231
09/16 06:34:44 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:34:44 AM: Best result seen so far for macro.
09/16 06:34:44 AM: Updating LR scheduler:
09/16 06:34:44 AM: 	Best result seen so far for macro_avg: 0.936
09/16 06:34:44 AM: 	# validation passes without improvement: 0
09/16 06:34:44 AM: edges-ner-ontonotes_loss: training: 0.026942 validation: 0.022109
09/16 06:34:44 AM: macro_avg: validation: 0.936303
09/16 06:34:44 AM: micro_avg: validation: 0.000000
09/16 06:34:44 AM: edges-ner-ontonotes_mcc: training: 0.920476 validation: 0.932802
09/16 06:34:44 AM: edges-ner-ontonotes_acc: training: 0.883171 validation: 0.901350
09/16 06:34:44 AM: edges-ner-ontonotes_precision: training: 0.944067 validation: 0.953680
09/16 06:34:44 AM: edges-ner-ontonotes_recall: training: 0.905911 validation: 0.919548
09/16 06:34:44 AM: edges-ner-ontonotes_f1: training: 0.924596 validation: 0.936303
09/16 06:34:44 AM: Global learning rate: 0.0001
09/16 06:34:44 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:34:48 AM: Update 11098: task edges-ner-ontonotes, batch 98 (11098): mcc: 0.9013, acc: 0.8561, precision: 0.9344, recall: 0.8795, f1: 0.9061, edges-ner-ontonotes_loss: 0.0308
09/16 06:34:50 AM: Update 11024: task edges-ner-ontonotes, batch 24 (11024): mcc: 0.9004, acc: 0.8571, precision: 0.9348, recall: 0.8776, f1: 0.9053, edges-ner-ontonotes_loss: 0.0318
09/16 06:34:59 AM: Update 11193: task edges-ner-ontonotes, batch 193 (11193): mcc: 0.9036, acc: 0.8606, precision: 0.9355, recall: 0.8828, f1: 0.9084, edges-ner-ontonotes_loss: 0.0307
09/16 06:35:02 AM: Update 11121: task edges-ner-ontonotes, batch 121 (11121): mcc: 0.9010, acc: 0.8560, precision: 0.9340, recall: 0.8793, f1: 0.9059, edges-ner-ontonotes_loss: 0.0307
09/16 06:35:09 AM: Update 11250: task edges-ner-ontonotes, batch 250 (11250): mcc: 0.9051, acc: 0.8626, precision: 0.9360, recall: 0.8851, f1: 0.9098, edges-ner-ontonotes_loss: 0.0301
09/16 06:35:14 AM: Update 11206: task edges-ner-ontonotes, batch 206 (11206): mcc: 0.9026, acc: 0.8594, precision: 0.9345, recall: 0.8819, f1: 0.9074, edges-ner-ontonotes_loss: 0.0309
09/16 06:35:20 AM: Update 11333: task edges-ner-ontonotes, batch 333 (11333): mcc: 0.9096, acc: 0.8691, precision: 0.9379, recall: 0.8917, f1: 0.9142, edges-ner-ontonotes_loss: 0.0290
09/16 06:35:24 AM: Update 11284: task edges-ner-ontonotes, batch 284 (11284): mcc: 0.9080, acc: 0.8667, precision: 0.9376, recall: 0.8890, f1: 0.9126, edges-ner-ontonotes_loss: 0.0294
09/16 06:35:31 AM: Update 11402: task edges-ner-ontonotes, batch 402 (11402): mcc: 0.9120, acc: 0.8723, precision: 0.9390, recall: 0.8951, f1: 0.9165, edges-ner-ontonotes_loss: 0.0283
09/16 06:35:34 AM: Update 11352: task edges-ner-ontonotes, batch 352 (11352): mcc: 0.9103, acc: 0.8699, precision: 0.9382, recall: 0.8927, f1: 0.9149, edges-ner-ontonotes_loss: 0.0287
09/16 06:35:41 AM: Update 11475: task edges-ner-ontonotes, batch 475 (11475): mcc: 0.9125, acc: 0.8734, precision: 0.9386, recall: 0.8964, f1: 0.9170, edges-ner-ontonotes_loss: 0.0281
09/16 06:35:44 AM: Update 11424: task edges-ner-ontonotes, batch 424 (11424): mcc: 0.9119, acc: 0.8725, precision: 0.9385, recall: 0.8953, f1: 0.9164, edges-ner-ontonotes_loss: 0.0283
09/16 06:35:51 AM: Update 11530: task edges-ner-ontonotes, batch 530 (11530): mcc: 0.9138, acc: 0.8750, precision: 0.9397, recall: 0.8977, f1: 0.9182, edges-ner-ontonotes_loss: 0.0277
09/16 06:35:54 AM: Update 11511: task edges-ner-ontonotes, batch 511 (11511): mcc: 0.9137, acc: 0.8750, precision: 0.9395, recall: 0.8976, f1: 0.9181, edges-ner-ontonotes_loss: 0.0278
09/16 06:36:01 AM: Update 11605: task edges-ner-ontonotes, batch 605 (11605): mcc: 0.9177, acc: 0.8798, precision: 0.9424, recall: 0.9024, f1: 0.9219, edges-ner-ontonotes_loss: 0.0267
09/16 06:36:05 AM: Update 11566: task edges-ner-ontonotes, batch 566 (11566): mcc: 0.9159, acc: 0.8776, precision: 0.9410, recall: 0.9003, f1: 0.9202, edges-ner-ontonotes_loss: 0.0272
09/16 06:36:11 AM: Update 11675: task edges-ner-ontonotes, batch 675 (11675): mcc: 0.9197, acc: 0.8824, precision: 0.9430, recall: 0.9054, f1: 0.9238, edges-ner-ontonotes_loss: 0.0260
09/16 06:36:15 AM: Update 11635: task edges-ner-ontonotes, batch 635 (11635): mcc: 0.9187, acc: 0.8811, precision: 0.9427, recall: 0.9039, f1: 0.9229, edges-ner-ontonotes_loss: 0.0264
09/16 06:36:22 AM: Update 11749: task edges-ner-ontonotes, batch 749 (11749): mcc: 0.9216, acc: 0.8851, precision: 0.9444, recall: 0.9077, f1: 0.9257, edges-ner-ontonotes_loss: 0.0254
09/16 06:36:25 AM: Update 11706: task edges-ner-ontonotes, batch 706 (11706): mcc: 0.9205, acc: 0.8836, precision: 0.9437, recall: 0.9064, f1: 0.9246, edges-ner-ontonotes_loss: 0.0257
09/16 06:36:32 AM: Update 11819: task edges-ner-ontonotes, batch 819 (11819): mcc: 0.9233, acc: 0.8873, precision: 0.9453, recall: 0.9101, f1: 0.9273, edges-ner-ontonotes_loss: 0.0249
09/16 06:36:35 AM: Update 11786: task edges-ner-ontonotes, batch 786 (11786): mcc: 0.9225, acc: 0.8863, precision: 0.9448, recall: 0.9090, f1: 0.9266, edges-ner-ontonotes_loss: 0.0251
09/16 06:36:43 AM: Update 11885: task edges-ner-ontonotes, batch 885 (11885): mcc: 0.9241, acc: 0.8881, precision: 0.9457, recall: 0.9111, f1: 0.9281, edges-ner-ontonotes_loss: 0.0246
09/16 06:36:45 AM: Update 11835: task edges-ner-ontonotes, batch 835 (11835): mcc: 0.9236, acc: 0.8875, precision: 0.9454, recall: 0.9104, f1: 0.9276, edges-ner-ontonotes_loss: 0.0248
09/16 06:36:53 AM: Update 11958: task edges-ner-ontonotes, batch 958 (11958): mcc: 0.9250, acc: 0.8893, precision: 0.9462, recall: 0.9124, f1: 0.9290, edges-ner-ontonotes_loss: 0.0243
09/16 06:36:55 AM: Update 11906: task edges-ner-ontonotes, batch 906 (11906): mcc: 0.9245, acc: 0.8885, precision: 0.9458, recall: 0.9117, f1: 0.9284, edges-ner-ontonotes_loss: 0.0245
09/16 06:36:59 AM: ***** Step 12000 / Validation 12 *****
09/16 06:37:03 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:37:03 AM: Validating...
09/16 06:37:03 AM: Evaluate: task edges-ner-ontonotes, batch 5 (157): mcc: 0.7870, acc: 0.7284, precision: 0.8532, recall: 0.7463, f1: 0.7962, edges-ner-ontonotes_loss: 0.0551
09/16 06:37:05 AM: Update 11987: task edges-ner-ontonotes, batch 987 (11987): mcc: 0.9253, acc: 0.8895, precision: 0.9463, recall: 0.9127, f1: 0.9292, edges-ner-ontonotes_loss: 0.0243
09/16 06:37:09 AM: ***** Step 12000 / Validation 12 *****
09/16 06:37:09 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:37:09 AM: Validating...
09/16 06:37:14 AM: Evaluate: task edges-ner-ontonotes, batch 69 (157): mcc: 0.9110, acc: 0.8770, precision: 0.9354, recall: 0.8966, f1: 0.9156, edges-ner-ontonotes_loss: 0.0293
09/16 06:37:17 AM: Evaluate: task edges-ner-ontonotes, batch 41 (157): mcc: 0.8936, acc: 0.8593, precision: 0.9216, recall: 0.8777, f1: 0.8991, edges-ner-ontonotes_loss: 0.0336
09/16 06:37:25 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9240, acc: 0.8941, precision: 0.9435, recall: 0.9131, f1: 0.9281, edges-ner-ontonotes_loss: 0.0252
09/16 06:37:28 AM: Evaluate: task edges-ner-ontonotes, batch 87 (157): mcc: 0.9217, acc: 0.8904, precision: 0.9418, recall: 0.9104, f1: 0.9258, edges-ner-ontonotes_loss: 0.0266
09/16 06:37:35 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:37:35 AM: Best result seen so far for macro.
09/16 06:37:35 AM: Updating LR scheduler:
09/16 06:37:35 AM: 	Best result seen so far for macro_avg: 0.938
09/16 06:37:35 AM: 	# validation passes without improvement: 0
09/16 06:37:35 AM: edges-ner-ontonotes_loss: training: 0.024260 validation: 0.022060
09/16 06:37:35 AM: macro_avg: validation: 0.937831
09/16 06:37:35 AM: micro_avg: validation: 0.000000
09/16 06:37:35 AM: edges-ner-ontonotes_mcc: training: 0.925298 validation: 0.934299
09/16 06:37:35 AM: edges-ner-ontonotes_acc: training: 0.889474 validation: 0.906885
09/16 06:37:35 AM: edges-ner-ontonotes_precision: training: 0.946298 validation: 0.949417
09/16 06:37:35 AM: edges-ner-ontonotes_recall: training: 0.912734 validation: 0.926524
09/16 06:37:35 AM: edges-ner-ontonotes_f1: training: 0.929213 validation: 0.937831
09/16 06:37:35 AM: Global learning rate: 0.0001
09/16 06:37:35 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:37:37 AM: Update 12001: task edges-ner-ontonotes, batch 1 (12001): mcc: 0.9418, acc: 0.9231, precision: 0.9451, recall: 0.9451, f1: 0.9451, edges-ner-ontonotes_loss: 0.0207
09/16 06:37:38 AM: Evaluate: task edges-ner-ontonotes, batch 132 (157): mcc: 0.9309, acc: 0.9028, precision: 0.9482, recall: 0.9215, f1: 0.9346, edges-ner-ontonotes_loss: 0.0234
09/16 06:37:43 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:37:43 AM: Best result seen so far for macro.
09/16 06:37:43 AM: Updating LR scheduler:
09/16 06:37:43 AM: 	Best result seen so far for macro_avg: 0.938
09/16 06:37:43 AM: 	# validation passes without improvement: 0
09/16 06:37:43 AM: edges-ner-ontonotes_loss: training: 0.024260 validation: 0.022060
09/16 06:37:43 AM: macro_avg: validation: 0.937831
09/16 06:37:43 AM: micro_avg: validation: 0.000000
09/16 06:37:43 AM: edges-ner-ontonotes_mcc: training: 0.925298 validation: 0.934299
09/16 06:37:43 AM: edges-ner-ontonotes_acc: training: 0.889474 validation: 0.906885
09/16 06:37:43 AM: edges-ner-ontonotes_precision: training: 0.946298 validation: 0.949417
09/16 06:37:43 AM: edges-ner-ontonotes_recall: training: 0.912734 validation: 0.926524
09/16 06:37:43 AM: edges-ner-ontonotes_f1: training: 0.929213 validation: 0.937831
09/16 06:37:43 AM: Global learning rate: 0.0001
09/16 06:37:43 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:37:47 AM: Update 12064: task edges-ner-ontonotes, batch 64 (12064): mcc: 0.9360, acc: 0.9037, precision: 0.9534, recall: 0.9258, f1: 0.9394, edges-ner-ontonotes_loss: 0.0202
09/16 06:37:49 AM: Update 12043: task edges-ner-ontonotes, batch 43 (12043): mcc: 0.9330, acc: 0.8998, precision: 0.9493, recall: 0.9242, f1: 0.9366, edges-ner-ontonotes_loss: 0.0209
09/16 06:37:58 AM: Update 12134: task edges-ner-ontonotes, batch 134 (12134): mcc: 0.9356, acc: 0.9027, precision: 0.9524, recall: 0.9261, f1: 0.9391, edges-ner-ontonotes_loss: 0.0204
09/16 06:37:59 AM: Update 12113: task edges-ner-ontonotes, batch 113 (12113): mcc: 0.9367, acc: 0.9043, precision: 0.9529, recall: 0.9276, f1: 0.9401, edges-ner-ontonotes_loss: 0.0200
09/16 06:38:08 AM: Update 12191: task edges-ner-ontonotes, batch 191 (12191): mcc: 0.9260, acc: 0.8899, precision: 0.9472, recall: 0.9131, f1: 0.9298, edges-ner-ontonotes_loss: 0.0246
09/16 06:38:09 AM: Update 12186: task edges-ner-ontonotes, batch 186 (12186): mcc: 0.9270, acc: 0.8912, precision: 0.9480, recall: 0.9143, f1: 0.9309, edges-ner-ontonotes_loss: 0.0241
09/16 06:38:18 AM: Update 12266: task edges-ner-ontonotes, batch 266 (12266): mcc: 0.9190, acc: 0.8818, precision: 0.9424, recall: 0.9048, f1: 0.9232, edges-ner-ontonotes_loss: 0.0281
09/16 06:38:19 AM: Update 12255: task edges-ner-ontonotes, batch 255 (12255): mcc: 0.9202, acc: 0.8834, precision: 0.9433, recall: 0.9061, f1: 0.9244, edges-ner-ontonotes_loss: 0.0274
09/16 06:38:28 AM: Update 12337: task edges-ner-ontonotes, batch 337 (12337): mcc: 0.9152, acc: 0.8769, precision: 0.9398, recall: 0.9003, f1: 0.9196, edges-ner-ontonotes_loss: 0.0296
09/16 06:38:29 AM: Update 12325: task edges-ner-ontonotes, batch 325 (12325): mcc: 0.9154, acc: 0.8770, precision: 0.9402, recall: 0.9002, f1: 0.9198, edges-ner-ontonotes_loss: 0.0293
09/16 06:38:38 AM: Update 12412: task edges-ner-ontonotes, batch 412 (12412): mcc: 0.9120, acc: 0.8731, precision: 0.9377, recall: 0.8962, f1: 0.9165, edges-ner-ontonotes_loss: 0.0307
09/16 06:38:39 AM: Update 12402: task edges-ner-ontonotes, batch 402 (12402): mcc: 0.9126, acc: 0.8736, precision: 0.9382, recall: 0.8969, f1: 0.9171, edges-ner-ontonotes_loss: 0.0306
09/16 06:38:48 AM: Update 12483: task edges-ner-ontonotes, batch 483 (12483): mcc: 0.9101, acc: 0.8705, precision: 0.9366, recall: 0.8937, f1: 0.9147, edges-ner-ontonotes_loss: 0.0311
09/16 06:38:49 AM: Update 12461: task edges-ner-ontonotes, batch 461 (12461): mcc: 0.9105, acc: 0.8710, precision: 0.9368, recall: 0.8943, f1: 0.9151, edges-ner-ontonotes_loss: 0.0310
09/16 06:38:58 AM: Update 12568: task edges-ner-ontonotes, batch 568 (12568): mcc: 0.9092, acc: 0.8690, precision: 0.9360, recall: 0.8927, f1: 0.9138, edges-ner-ontonotes_loss: 0.0310
09/16 06:38:59 AM: Update 12551: task edges-ner-ontonotes, batch 551 (12551): mcc: 0.9096, acc: 0.8696, precision: 0.9364, recall: 0.8930, f1: 0.9142, edges-ner-ontonotes_loss: 0.0310
09/16 06:39:08 AM: Update 12660: task edges-ner-ontonotes, batch 660 (12660): mcc: 0.9088, acc: 0.8683, precision: 0.9363, recall: 0.8918, f1: 0.9135, edges-ner-ontonotes_loss: 0.0310
09/16 06:39:09 AM: Update 12639: task edges-ner-ontonotes, batch 639 (12639): mcc: 0.9091, acc: 0.8687, precision: 0.9364, recall: 0.8922, f1: 0.9138, edges-ner-ontonotes_loss: 0.0310
09/16 06:39:18 AM: Update 12751: task edges-ner-ontonotes, batch 751 (12751): mcc: 0.9083, acc: 0.8678, precision: 0.9359, recall: 0.8912, f1: 0.9130, edges-ner-ontonotes_loss: 0.0311
09/16 06:39:19 AM: Update 12728: task edges-ner-ontonotes, batch 728 (12728): mcc: 0.9084, acc: 0.8680, precision: 0.9360, recall: 0.8913, f1: 0.9131, edges-ner-ontonotes_loss: 0.0311
09/16 06:39:28 AM: Update 12813: task edges-ner-ontonotes, batch 813 (12813): mcc: 0.9087, acc: 0.8681, precision: 0.9360, recall: 0.8919, f1: 0.9134, edges-ner-ontonotes_loss: 0.0308
09/16 06:39:29 AM: Update 12791: task edges-ner-ontonotes, batch 791 (12791): mcc: 0.9087, acc: 0.8682, precision: 0.9362, recall: 0.8917, f1: 0.9134, edges-ner-ontonotes_loss: 0.0309
09/16 06:39:38 AM: Update 12886: task edges-ner-ontonotes, batch 886 (12886): mcc: 0.9103, acc: 0.8702, precision: 0.9372, recall: 0.8937, f1: 0.9149, edges-ner-ontonotes_loss: 0.0302
09/16 06:39:39 AM: Update 12864: task edges-ner-ontonotes, batch 864 (12864): mcc: 0.9099, acc: 0.8696, precision: 0.9370, recall: 0.8930, f1: 0.9145, edges-ner-ontonotes_loss: 0.0304
09/16 06:39:49 AM: Update 12956: task edges-ner-ontonotes, batch 956 (12956): mcc: 0.9114, acc: 0.8716, precision: 0.9378, recall: 0.8952, f1: 0.9160, edges-ner-ontonotes_loss: 0.0299
09/16 06:39:49 AM: Update 12930: task edges-ner-ontonotes, batch 930 (12930): mcc: 0.9109, acc: 0.8709, precision: 0.9375, recall: 0.8945, f1: 0.9155, edges-ner-ontonotes_loss: 0.0301
09/16 06:39:55 AM: ***** Step 13000 / Validation 13 *****
09/16 06:39:55 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:39:55 AM: Validating...
09/16 06:39:59 AM: Evaluate: task edges-ner-ontonotes, batch 25 (157): mcc: 0.8643, acc: 0.8203, precision: 0.9064, recall: 0.8380, f1: 0.8709, edges-ner-ontonotes_loss: 0.0382
09/16 06:40:00 AM: Update 12997: task edges-ner-ontonotes, batch 997 (12997): mcc: 0.9121, acc: 0.8725, precision: 0.9381, recall: 0.8961, f1: 0.9166, edges-ner-ontonotes_loss: 0.0297
09/16 06:40:00 AM: ***** Step 13000 / Validation 13 *****
09/16 06:40:00 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:40:00 AM: Validating...
09/16 06:40:09 AM: Evaluate: task edges-ner-ontonotes, batch 74 (157): mcc: 0.9169, acc: 0.8831, precision: 0.9452, recall: 0.8981, f1: 0.9210, edges-ner-ontonotes_loss: 0.0269
09/16 06:40:10 AM: Evaluate: task edges-ner-ontonotes, batch 48 (157): mcc: 0.9043, acc: 0.8699, precision: 0.9333, recall: 0.8862, f1: 0.9091, edges-ner-ontonotes_loss: 0.0295
09/16 06:40:19 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9253, acc: 0.8928, precision: 0.9500, recall: 0.9091, f1: 0.9291, edges-ner-ontonotes_loss: 0.0240
09/16 06:40:20 AM: Evaluate: task edges-ner-ontonotes, batch 91 (157): mcc: 0.9233, acc: 0.8897, precision: 0.9504, recall: 0.9049, f1: 0.9271, edges-ner-ontonotes_loss: 0.0251
09/16 06:40:29 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:40:29 AM: Best result seen so far for macro.
09/16 06:40:29 AM: Updating LR scheduler:
09/16 06:40:29 AM: 	Best result seen so far for macro_avg: 0.938
09/16 06:40:29 AM: 	# validation passes without improvement: 0
09/16 06:40:29 AM: edges-ner-ontonotes_loss: training: 0.029653 validation: 0.021366
09/16 06:40:29 AM: macro_avg: validation: 0.937936
09/16 06:40:29 AM: micro_avg: validation: 0.000000
09/16 06:40:29 AM: edges-ner-ontonotes_mcc: training: 0.912060 validation: 0.934511
09/16 06:40:29 AM: edges-ner-ontonotes_acc: training: 0.872464 validation: 0.905141
09/16 06:40:29 AM: edges-ner-ontonotes_precision: training: 0.938047 validation: 0.954542
09/16 06:40:29 AM: edges-ner-ontonotes_recall: training: 0.896076 validation: 0.921899
09/16 06:40:29 AM: edges-ner-ontonotes_f1: training: 0.916581 validation: 0.937936
09/16 06:40:29 AM: Global learning rate: 0.0001
09/16 06:40:29 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:40:29 AM: Update 13003: task edges-ner-ontonotes, batch 3 (13003): mcc: 0.9448, acc: 0.9084, precision: 0.9608, recall: 0.9351, f1: 0.9478, edges-ner-ontonotes_loss: 0.0170
09/16 06:40:30 AM: Evaluate: task edges-ner-ontonotes, batch 131 (157): mcc: 0.9305, acc: 0.8996, precision: 0.9529, recall: 0.9161, f1: 0.9341, edges-ner-ontonotes_loss: 0.0226
09/16 06:40:34 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:40:34 AM: Best result seen so far for macro.
09/16 06:40:34 AM: Updating LR scheduler:
09/16 06:40:34 AM: 	Best result seen so far for macro_avg: 0.938
09/16 06:40:34 AM: 	# validation passes without improvement: 0
09/16 06:40:34 AM: edges-ner-ontonotes_loss: training: 0.029653 validation: 0.021366
09/16 06:40:34 AM: macro_avg: validation: 0.937936
09/16 06:40:34 AM: micro_avg: validation: 0.000000
09/16 06:40:34 AM: edges-ner-ontonotes_mcc: training: 0.912060 validation: 0.934511
09/16 06:40:34 AM: edges-ner-ontonotes_acc: training: 0.872464 validation: 0.905141
09/16 06:40:34 AM: edges-ner-ontonotes_precision: training: 0.938047 validation: 0.954542
09/16 06:40:34 AM: edges-ner-ontonotes_recall: training: 0.896076 validation: 0.921899
09/16 06:40:34 AM: edges-ner-ontonotes_f1: training: 0.916581 validation: 0.937936
09/16 06:40:34 AM: Global learning rate: 0.0001
09/16 06:40:34 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:40:40 AM: Update 13039: task edges-ner-ontonotes, batch 39 (13039): mcc: 0.9242, acc: 0.8898, precision: 0.9443, recall: 0.9127, f1: 0.9282, edges-ner-ontonotes_loss: 0.0254
09/16 06:40:42 AM: Update 13075: task edges-ner-ontonotes, batch 75 (13075): mcc: 0.9225, acc: 0.8857, precision: 0.9454, recall: 0.9084, f1: 0.9265, edges-ner-ontonotes_loss: 0.0255
09/16 06:40:50 AM: Update 13101: task edges-ner-ontonotes, batch 101 (13101): mcc: 0.9265, acc: 0.8902, precision: 0.9473, recall: 0.9140, f1: 0.9304, edges-ner-ontonotes_loss: 0.0237
09/16 06:40:52 AM: Update 13153: task edges-ner-ontonotes, batch 153 (13153): mcc: 0.9284, acc: 0.8930, precision: 0.9479, recall: 0.9171, f1: 0.9322, edges-ner-ontonotes_loss: 0.0228
09/16 06:41:00 AM: Update 13170: task edges-ner-ontonotes, batch 170 (13170): mcc: 0.9304, acc: 0.8958, precision: 0.9486, recall: 0.9201, f1: 0.9341, edges-ner-ontonotes_loss: 0.0222
09/16 06:41:02 AM: Update 13223: task edges-ner-ontonotes, batch 223 (13223): mcc: 0.9330, acc: 0.8988, precision: 0.9507, recall: 0.9228, f1: 0.9365, edges-ner-ontonotes_loss: 0.0217
09/16 06:41:10 AM: Update 13241: task edges-ner-ontonotes, batch 241 (13241): mcc: 0.9334, acc: 0.8993, precision: 0.9510, recall: 0.9234, f1: 0.9370, edges-ner-ontonotes_loss: 0.0215
09/16 06:41:12 AM: Update 13292: task edges-ner-ontonotes, batch 292 (13292): mcc: 0.9342, acc: 0.9006, precision: 0.9514, recall: 0.9244, f1: 0.9377, edges-ner-ontonotes_loss: 0.0213
09/16 06:41:20 AM: Update 13309: task edges-ner-ontonotes, batch 309 (13309): mcc: 0.9347, acc: 0.9016, precision: 0.9519, recall: 0.9250, f1: 0.9382, edges-ner-ontonotes_loss: 0.0212
09/16 06:41:22 AM: Update 13361: task edges-ner-ontonotes, batch 361 (13361): mcc: 0.9361, acc: 0.9034, precision: 0.9528, recall: 0.9267, f1: 0.9396, edges-ner-ontonotes_loss: 0.0208
09/16 06:41:32 AM: Update 13388: task edges-ner-ontonotes, batch 388 (13388): mcc: 0.9362, acc: 0.9036, precision: 0.9530, recall: 0.9266, f1: 0.9396, edges-ner-ontonotes_loss: 0.0207
09/16 06:41:32 AM: Update 13422: task edges-ner-ontonotes, batch 422 (13422): mcc: 0.9359, acc: 0.9031, precision: 0.9529, recall: 0.9261, f1: 0.9393, edges-ner-ontonotes_loss: 0.0209
09/16 06:41:42 AM: Update 13458: task edges-ner-ontonotes, batch 458 (13458): mcc: 0.9356, acc: 0.9027, precision: 0.9526, recall: 0.9258, f1: 0.9390, edges-ner-ontonotes_loss: 0.0209
09/16 06:41:42 AM: Update 13494: task edges-ner-ontonotes, batch 494 (13494): mcc: 0.9353, acc: 0.9024, precision: 0.9525, recall: 0.9253, f1: 0.9387, edges-ner-ontonotes_loss: 0.0210
09/16 06:41:52 AM: Update 13531: task edges-ner-ontonotes, batch 531 (13531): mcc: 0.9361, acc: 0.9034, precision: 0.9533, recall: 0.9261, f1: 0.9395, edges-ner-ontonotes_loss: 0.0207
09/16 06:41:53 AM: Update 13564: task edges-ner-ontonotes, batch 564 (13564): mcc: 0.9358, acc: 0.9031, precision: 0.9530, recall: 0.9258, f1: 0.9392, edges-ner-ontonotes_loss: 0.0208
09/16 06:42:02 AM: Update 13600: task edges-ner-ontonotes, batch 600 (13600): mcc: 0.9363, acc: 0.9036, precision: 0.9535, recall: 0.9261, f1: 0.9396, edges-ner-ontonotes_loss: 0.0207
09/16 06:42:03 AM: Update 13633: task edges-ner-ontonotes, batch 633 (13633): mcc: 0.9360, acc: 0.9032, precision: 0.9534, recall: 0.9258, f1: 0.9394, edges-ner-ontonotes_loss: 0.0207
09/16 06:42:12 AM: Update 13670: task edges-ner-ontonotes, batch 670 (13670): mcc: 0.9364, acc: 0.9038, precision: 0.9536, recall: 0.9264, f1: 0.9398, edges-ner-ontonotes_loss: 0.0206
09/16 06:42:15 AM: Update 13701: task edges-ner-ontonotes, batch 701 (13701): mcc: 0.9361, acc: 0.9032, precision: 0.9535, recall: 0.9259, f1: 0.9395, edges-ner-ontonotes_loss: 0.0207
09/16 06:42:22 AM: Update 13736: task edges-ner-ontonotes, batch 736 (13736): mcc: 0.9342, acc: 0.9008, precision: 0.9523, recall: 0.9235, f1: 0.9377, edges-ner-ontonotes_loss: 0.0214
09/16 06:42:25 AM: Update 13779: task edges-ner-ontonotes, batch 779 (13779): mcc: 0.9324, acc: 0.8986, precision: 0.9511, recall: 0.9213, f1: 0.9360, edges-ner-ontonotes_loss: 0.0222
09/16 06:42:32 AM: Update 13809: task edges-ner-ontonotes, batch 809 (13809): mcc: 0.9315, acc: 0.8974, precision: 0.9506, recall: 0.9201, f1: 0.9351, edges-ner-ontonotes_loss: 0.0227
09/16 06:42:35 AM: Update 13850: task edges-ner-ontonotes, batch 850 (13850): mcc: 0.9303, acc: 0.8958, precision: 0.9499, recall: 0.9185, f1: 0.9339, edges-ner-ontonotes_loss: 0.0232
09/16 06:42:42 AM: Update 13881: task edges-ner-ontonotes, batch 881 (13881): mcc: 0.9293, acc: 0.8946, precision: 0.9493, recall: 0.9173, f1: 0.9330, edges-ner-ontonotes_loss: 0.0235
09/16 06:42:45 AM: Update 13920: task edges-ner-ontonotes, batch 920 (13920): mcc: 0.9279, acc: 0.8929, precision: 0.9484, recall: 0.9156, f1: 0.9317, edges-ner-ontonotes_loss: 0.0241
09/16 06:42:52 AM: Update 13950: task edges-ner-ontonotes, batch 950 (13950): mcc: 0.9271, acc: 0.8921, precision: 0.9479, recall: 0.9147, f1: 0.9310, edges-ner-ontonotes_loss: 0.0245
09/16 06:42:56 AM: Update 13995: task edges-ner-ontonotes, batch 995 (13995): mcc: 0.9261, acc: 0.8907, precision: 0.9472, recall: 0.9134, f1: 0.9300, edges-ner-ontonotes_loss: 0.0250
09/16 06:42:56 AM: ***** Step 14000 / Validation 14 *****
09/16 06:42:56 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:42:56 AM: Validating...
09/16 06:42:59 AM: ***** Step 14000 / Validation 14 *****
09/16 06:42:59 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:42:59 AM: Validating...
09/16 06:43:02 AM: Evaluate: task edges-ner-ontonotes, batch 16 (157): mcc: 0.8672, acc: 0.8221, precision: 0.9043, recall: 0.8452, f1: 0.8738, edges-ner-ontonotes_loss: 0.0353
09/16 06:43:06 AM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.9120, acc: 0.8812, precision: 0.9339, recall: 0.8999, f1: 0.9166, edges-ner-ontonotes_loss: 0.0292
09/16 06:43:12 AM: Evaluate: task edges-ner-ontonotes, batch 62 (157): mcc: 0.9183, acc: 0.8886, precision: 0.9381, recall: 0.9076, f1: 0.9226, edges-ner-ontonotes_loss: 0.0275
09/16 06:43:16 AM: Evaluate: task edges-ner-ontonotes, batch 98 (157): mcc: 0.9275, acc: 0.8975, precision: 0.9493, recall: 0.9139, f1: 0.9312, edges-ner-ontonotes_loss: 0.0251
09/16 06:43:22 AM: Evaluate: task edges-ner-ontonotes, batch 105 (157): mcc: 0.9255, acc: 0.8951, precision: 0.9473, recall: 0.9121, f1: 0.9294, edges-ner-ontonotes_loss: 0.0252
09/16 06:43:26 AM: Evaluate: task edges-ner-ontonotes, batch 135 (157): mcc: 0.9333, acc: 0.9041, precision: 0.9536, recall: 0.9205, f1: 0.9368, edges-ner-ontonotes_loss: 0.0227
09/16 06:43:32 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:43:32 AM: Best result seen so far for macro.
09/16 06:43:32 AM: Updating LR scheduler:
09/16 06:43:32 AM: 	Best result seen so far for macro_avg: 0.938
09/16 06:43:32 AM: 	# validation passes without improvement: 0
09/16 06:43:32 AM: edges-ner-ontonotes_loss: training: 0.025029 validation: 0.021952
09/16 06:43:32 AM: macro_avg: validation: 0.938488
09/16 06:43:32 AM: micro_avg: validation: 0.000000
09/16 06:43:32 AM: edges-ner-ontonotes_mcc: training: 0.925954 validation: 0.935076
09/16 06:43:32 AM: edges-ner-ontonotes_acc: training: 0.890542 validation: 0.906278
09/16 06:43:32 AM: edges-ner-ontonotes_precision: training: 0.947079 validation: 0.954303
09/16 06:43:32 AM: edges-ner-ontonotes_recall: training: 0.913199 validation: 0.923188
09/16 06:43:32 AM: edges-ner-ontonotes_f1: training: 0.929830 validation: 0.938488
09/16 06:43:32 AM: Global learning rate: 0.0001
09/16 06:43:32 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:43:32 AM: Evaluate: task edges-ner-ontonotes, batch 150 (157): mcc: 0.9345, acc: 0.9056, precision: 0.9540, recall: 0.9224, f1: 0.9379, edges-ner-ontonotes_loss: 0.0223
09/16 06:43:33 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:43:33 AM: Best result seen so far for macro.
09/16 06:43:33 AM: Updating LR scheduler:
09/16 06:43:33 AM: 	Best result seen so far for macro_avg: 0.938
09/16 06:43:33 AM: 	# validation passes without improvement: 0
09/16 06:43:33 AM: edges-ner-ontonotes_loss: training: 0.025029 validation: 0.021952
09/16 06:43:33 AM: macro_avg: validation: 0.938488
09/16 06:43:33 AM: micro_avg: validation: 0.000000
09/16 06:43:33 AM: edges-ner-ontonotes_mcc: training: 0.925954 validation: 0.935076
09/16 06:43:33 AM: edges-ner-ontonotes_acc: training: 0.890542 validation: 0.906278
09/16 06:43:33 AM: edges-ner-ontonotes_precision: training: 0.947079 validation: 0.954303
09/16 06:43:33 AM: edges-ner-ontonotes_recall: training: 0.913199 validation: 0.923188
09/16 06:43:33 AM: edges-ner-ontonotes_f1: training: 0.929830 validation: 0.938488
09/16 06:43:33 AM: Global learning rate: 0.0001
09/16 06:43:33 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:43:37 AM: Update 14023: task edges-ner-ontonotes, batch 23 (14023): mcc: 0.9172, acc: 0.8812, precision: 0.9460, recall: 0.8981, f1: 0.9214, edges-ner-ontonotes_loss: 0.0291
09/16 06:43:43 AM: Update 14062: task edges-ner-ontonotes, batch 62 (14062): mcc: 0.9073, acc: 0.8656, precision: 0.9395, recall: 0.8859, f1: 0.9119, edges-ner-ontonotes_loss: 0.0310
09/16 06:43:49 AM: Update 14113: task edges-ner-ontonotes, batch 113 (14113): mcc: 0.9067, acc: 0.8642, precision: 0.9383, recall: 0.8858, f1: 0.9113, edges-ner-ontonotes_loss: 0.0306
09/16 06:43:53 AM: Update 14146: task edges-ner-ontonotes, batch 146 (14146): mcc: 0.9075, acc: 0.8657, precision: 0.9386, recall: 0.8870, f1: 0.9121, edges-ner-ontonotes_loss: 0.0307
09/16 06:43:59 AM: Update 14195: task edges-ner-ontonotes, batch 195 (14195): mcc: 0.9084, acc: 0.8659, precision: 0.9386, recall: 0.8887, f1: 0.9130, edges-ner-ontonotes_loss: 0.0303
09/16 06:44:03 AM: Update 14232: task edges-ner-ontonotes, batch 232 (14232): mcc: 0.9062, acc: 0.8627, precision: 0.9371, recall: 0.8862, f1: 0.9109, edges-ner-ontonotes_loss: 0.0306
09/16 06:44:09 AM: Update 14281: task edges-ner-ontonotes, batch 281 (14281): mcc: 0.9066, acc: 0.8639, precision: 0.9365, recall: 0.8874, f1: 0.9113, edges-ner-ontonotes_loss: 0.0304
09/16 06:44:15 AM: Update 14318: task edges-ner-ontonotes, batch 318 (14318): mcc: 0.9057, acc: 0.8634, precision: 0.9355, recall: 0.8867, f1: 0.9105, edges-ner-ontonotes_loss: 0.0307
09/16 06:44:19 AM: Update 14342: task edges-ner-ontonotes, batch 342 (14342): mcc: 0.9056, acc: 0.8637, precision: 0.9348, recall: 0.8872, f1: 0.9104, edges-ner-ontonotes_loss: 0.0306
09/16 06:44:27 AM: Update 14389: task edges-ner-ontonotes, batch 389 (14389): mcc: 0.9076, acc: 0.8661, precision: 0.9358, recall: 0.8900, f1: 0.9123, edges-ner-ontonotes_loss: 0.0300
09/16 06:44:29 AM: Update 14419: task edges-ner-ontonotes, batch 419 (14419): mcc: 0.9085, acc: 0.8676, precision: 0.9361, recall: 0.8914, f1: 0.9132, edges-ner-ontonotes_loss: 0.0298
09/16 06:44:37 AM: Update 14464: task edges-ner-ontonotes, batch 464 (14464): mcc: 0.9107, acc: 0.8701, precision: 0.9372, recall: 0.8943, f1: 0.9152, edges-ner-ontonotes_loss: 0.0292
09/16 06:44:39 AM: Update 14493: task edges-ner-ontonotes, batch 493 (14493): mcc: 0.9109, acc: 0.8705, precision: 0.9371, recall: 0.8948, f1: 0.9155, edges-ner-ontonotes_loss: 0.0289
09/16 06:44:47 AM: Update 14539: task edges-ner-ontonotes, batch 539 (14539): mcc: 0.9122, acc: 0.8723, precision: 0.9379, recall: 0.8966, f1: 0.9167, edges-ner-ontonotes_loss: 0.0285
09/16 06:44:49 AM: Update 14567: task edges-ner-ontonotes, batch 567 (14567): mcc: 0.9133, acc: 0.8739, precision: 0.9387, recall: 0.8978, f1: 0.9178, edges-ner-ontonotes_loss: 0.0282
09/16 06:44:57 AM: Update 14618: task edges-ner-ontonotes, batch 618 (14618): mcc: 0.9146, acc: 0.8757, precision: 0.9395, recall: 0.8994, f1: 0.9190, edges-ner-ontonotes_loss: 0.0279
09/16 06:45:02 AM: Update 14631: task edges-ner-ontonotes, batch 631 (14631): mcc: 0.9148, acc: 0.8761, precision: 0.9395, recall: 0.8997, f1: 0.9192, edges-ner-ontonotes_loss: 0.0278
09/16 06:45:07 AM: Update 14669: task edges-ner-ontonotes, batch 669 (14669): mcc: 0.9163, acc: 0.8779, precision: 0.9405, recall: 0.9017, f1: 0.9207, edges-ner-ontonotes_loss: 0.0274
09/16 06:45:12 AM: Update 14700: task edges-ner-ontonotes, batch 700 (14700): mcc: 0.9177, acc: 0.8799, precision: 0.9413, recall: 0.9035, f1: 0.9220, edges-ner-ontonotes_loss: 0.0270
09/16 06:45:17 AM: Update 14740: task edges-ner-ontonotes, batch 740 (14740): mcc: 0.9190, acc: 0.8816, precision: 0.9421, recall: 0.9050, f1: 0.9232, edges-ner-ontonotes_loss: 0.0266
09/16 06:45:22 AM: Update 14768: task edges-ner-ontonotes, batch 768 (14768): mcc: 0.9199, acc: 0.8828, precision: 0.9427, recall: 0.9062, f1: 0.9241, edges-ner-ontonotes_loss: 0.0264
09/16 06:45:27 AM: Update 14809: task edges-ner-ontonotes, batch 809 (14809): mcc: 0.9210, acc: 0.8845, precision: 0.9433, recall: 0.9076, f1: 0.9251, edges-ner-ontonotes_loss: 0.0260
09/16 06:45:32 AM: Update 14840: task edges-ner-ontonotes, batch 840 (14840): mcc: 0.9221, acc: 0.8857, precision: 0.9440, recall: 0.9089, f1: 0.9261, edges-ner-ontonotes_loss: 0.0257
09/16 06:45:37 AM: Update 14883: task edges-ner-ontonotes, batch 883 (14883): mcc: 0.9231, acc: 0.8874, precision: 0.9446, recall: 0.9103, f1: 0.9271, edges-ner-ontonotes_loss: 0.0254
09/16 06:45:42 AM: Update 14908: task edges-ner-ontonotes, batch 908 (14908): mcc: 0.9242, acc: 0.8888, precision: 0.9453, recall: 0.9116, f1: 0.9281, edges-ner-ontonotes_loss: 0.0251
09/16 06:45:48 AM: Update 14944: task edges-ner-ontonotes, batch 944 (14944): mcc: 0.9246, acc: 0.8893, precision: 0.9456, recall: 0.9121, f1: 0.9285, edges-ner-ontonotes_loss: 0.0250
09/16 06:45:52 AM: Update 14958: task edges-ner-ontonotes, batch 958 (14958): mcc: 0.9247, acc: 0.8894, precision: 0.9456, recall: 0.9122, f1: 0.9286, edges-ner-ontonotes_loss: 0.0250
09/16 06:45:55 AM: ***** Step 15000 / Validation 15 *****
09/16 06:45:55 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:45:55 AM: Validating...
09/16 06:45:58 AM: Evaluate: task edges-ner-ontonotes, batch 23 (157): mcc: 0.8581, acc: 0.8161, precision: 0.9002, recall: 0.8324, f1: 0.8649, edges-ner-ontonotes_loss: 0.0417
09/16 06:45:59 AM: ***** Step 15000 / Validation 15 *****
09/16 06:45:59 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:45:59 AM: Validating...
09/16 06:46:02 AM: Evaluate: task edges-ner-ontonotes, batch 16 (157): mcc: 0.8527, acc: 0.8010, precision: 0.9018, recall: 0.8211, f1: 0.8595, edges-ner-ontonotes_loss: 0.0386
09/16 06:46:08 AM: Evaluate: task edges-ner-ontonotes, batch 71 (157): mcc: 0.9146, acc: 0.8799, precision: 0.9422, recall: 0.8967, f1: 0.9189, edges-ner-ontonotes_loss: 0.0285
09/16 06:46:12 AM: Evaluate: task edges-ner-ontonotes, batch 63 (157): mcc: 0.9169, acc: 0.8855, precision: 0.9400, recall: 0.9032, f1: 0.9212, edges-ner-ontonotes_loss: 0.0276
09/16 06:46:20 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9270, acc: 0.8964, precision: 0.9491, recall: 0.9131, f1: 0.9308, edges-ner-ontonotes_loss: 0.0245
09/16 06:46:23 AM: Evaluate: task edges-ner-ontonotes, batch 111 (157): mcc: 0.9268, acc: 0.8970, precision: 0.9481, recall: 0.9138, f1: 0.9306, edges-ner-ontonotes_loss: 0.0246
09/16 06:46:31 AM: Evaluate: task edges-ner-ontonotes, batch 156 (157): mcc: 0.9365, acc: 0.9089, precision: 0.9540, recall: 0.9262, f1: 0.9399, edges-ner-ontonotes_loss: 0.0215
09/16 06:46:31 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:46:31 AM: Best result seen so far for macro.
09/16 06:46:31 AM: Updating LR scheduler:
09/16 06:46:31 AM: 	Best result seen so far for macro_avg: 0.940
09/16 06:46:31 AM: 	# validation passes without improvement: 0
09/16 06:46:31 AM: edges-ner-ontonotes_loss: training: 0.024802 validation: 0.021421
09/16 06:46:31 AM: macro_avg: validation: 0.939945
09/16 06:46:31 AM: micro_avg: validation: 0.000000
09/16 06:46:31 AM: edges-ner-ontonotes_mcc: training: 0.925084 validation: 0.936582
09/16 06:46:31 AM: edges-ner-ontonotes_acc: training: 0.889952 validation: 0.908932
09/16 06:46:31 AM: edges-ner-ontonotes_precision: training: 0.945852 validation: 0.954002
09/16 06:46:31 AM: edges-ner-ontonotes_recall: training: 0.912771 validation: 0.926297
09/16 06:46:31 AM: edges-ner-ontonotes_f1: training: 0.929017 validation: 0.939945
09/16 06:46:31 AM: Global learning rate: 0.0001
09/16 06:46:31 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:46:33 AM: Evaluate: task edges-ner-ontonotes, batch 154 (157): mcc: 0.9362, acc: 0.9083, precision: 0.9538, recall: 0.9257, f1: 0.9395, edges-ner-ontonotes_loss: 0.0216
09/16 06:46:33 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:46:33 AM: Best result seen so far for macro.
09/16 06:46:33 AM: Updating LR scheduler:
09/16 06:46:33 AM: 	Best result seen so far for macro_avg: 0.940
09/16 06:46:33 AM: 	# validation passes without improvement: 0
09/16 06:46:33 AM: edges-ner-ontonotes_loss: training: 0.024802 validation: 0.021421
09/16 06:46:33 AM: macro_avg: validation: 0.939945
09/16 06:46:33 AM: micro_avg: validation: 0.000000
09/16 06:46:33 AM: edges-ner-ontonotes_mcc: training: 0.925084 validation: 0.936582
09/16 06:46:33 AM: edges-ner-ontonotes_acc: training: 0.889952 validation: 0.908932
09/16 06:46:33 AM: edges-ner-ontonotes_precision: training: 0.945852 validation: 0.954002
09/16 06:46:33 AM: edges-ner-ontonotes_recall: training: 0.912771 validation: 0.926297
09/16 06:46:33 AM: edges-ner-ontonotes_f1: training: 0.929017 validation: 0.939945
09/16 06:46:33 AM: Global learning rate: 0.0001
09/16 06:46:33 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:46:41 AM: Update 15059: task edges-ner-ontonotes, batch 59 (15059): mcc: 0.9375, acc: 0.9064, precision: 0.9526, recall: 0.9294, f1: 0.9409, edges-ner-ontonotes_loss: 0.0207
09/16 06:46:43 AM: Update 15067: task edges-ner-ontonotes, batch 67 (15067): mcc: 0.9377, acc: 0.9069, precision: 0.9529, recall: 0.9294, f1: 0.9410, edges-ner-ontonotes_loss: 0.0206
09/16 06:46:51 AM: Update 15128: task edges-ner-ontonotes, batch 128 (15128): mcc: 0.9355, acc: 0.9040, precision: 0.9519, recall: 0.9263, f1: 0.9389, edges-ner-ontonotes_loss: 0.0204
09/16 06:46:53 AM: Update 15136: task edges-ner-ontonotes, batch 136 (15136): mcc: 0.9347, acc: 0.9034, precision: 0.9512, recall: 0.9256, f1: 0.9382, edges-ner-ontonotes_loss: 0.0205
09/16 06:47:01 AM: Update 15199: task edges-ner-ontonotes, batch 199 (15199): mcc: 0.9370, acc: 0.9059, precision: 0.9532, recall: 0.9279, f1: 0.9404, edges-ner-ontonotes_loss: 0.0199
09/16 06:47:03 AM: Update 15209: task edges-ner-ontonotes, batch 209 (15209): mcc: 0.9374, acc: 0.9064, precision: 0.9530, recall: 0.9287, f1: 0.9407, edges-ner-ontonotes_loss: 0.0200
09/16 06:47:11 AM: Update 15258: task edges-ner-ontonotes, batch 258 (15258): mcc: 0.9359, acc: 0.9045, precision: 0.9524, recall: 0.9266, f1: 0.9393, edges-ner-ontonotes_loss: 0.0202
09/16 06:47:16 AM: Update 15280: task edges-ner-ontonotes, batch 280 (15280): mcc: 0.9332, acc: 0.9009, precision: 0.9510, recall: 0.9228, f1: 0.9367, edges-ner-ontonotes_loss: 0.0212
09/16 06:47:23 AM: Update 15322: task edges-ner-ontonotes, batch 322 (15322): mcc: 0.9294, acc: 0.8958, precision: 0.9488, recall: 0.9180, f1: 0.9331, edges-ner-ontonotes_loss: 0.0227
09/16 06:47:26 AM: Update 15361: task edges-ner-ontonotes, batch 361 (15361): mcc: 0.9260, acc: 0.8911, precision: 0.9466, recall: 0.9137, f1: 0.9299, edges-ner-ontonotes_loss: 0.0245
09/16 06:47:34 AM: Update 15400: task edges-ner-ontonotes, batch 400 (15400): mcc: 0.9247, acc: 0.8893, precision: 0.9458, recall: 0.9121, f1: 0.9286, edges-ner-ontonotes_loss: 0.0252
09/16 06:47:36 AM: Update 15445: task edges-ner-ontonotes, batch 445 (15445): mcc: 0.9223, acc: 0.8866, precision: 0.9439, recall: 0.9094, f1: 0.9264, edges-ner-ontonotes_loss: 0.0260
09/16 06:47:45 AM: Update 15475: task edges-ner-ontonotes, batch 475 (15475): mcc: 0.9210, acc: 0.8848, precision: 0.9431, recall: 0.9078, f1: 0.9251, edges-ner-ontonotes_loss: 0.0267
09/16 06:47:46 AM: Update 15522: task edges-ner-ontonotes, batch 522 (15522): mcc: 0.9191, acc: 0.8827, precision: 0.9419, recall: 0.9054, f1: 0.9233, edges-ner-ontonotes_loss: 0.0278
09/16 06:47:55 AM: Update 15560: task edges-ner-ontonotes, batch 560 (15560): mcc: 0.9179, acc: 0.8814, precision: 0.9412, recall: 0.9039, f1: 0.9221, edges-ner-ontonotes_loss: 0.0283
09/16 06:47:56 AM: Update 15573: task edges-ner-ontonotes, batch 573 (15573): mcc: 0.9174, acc: 0.8808, precision: 0.9409, recall: 0.9034, f1: 0.9217, edges-ner-ontonotes_loss: 0.0283
09/16 06:48:05 AM: Update 15635: task edges-ner-ontonotes, batch 635 (15635): mcc: 0.9162, acc: 0.8791, precision: 0.9399, recall: 0.9020, f1: 0.9205, edges-ner-ontonotes_loss: 0.0288
09/16 06:48:06 AM: Update 15663: task edges-ner-ontonotes, batch 663 (15663): mcc: 0.9156, acc: 0.8782, precision: 0.9396, recall: 0.9012, f1: 0.9200, edges-ner-ontonotes_loss: 0.0289
09/16 06:48:16 AM: Update 15723: task edges-ner-ontonotes, batch 723 (15723): mcc: 0.9150, acc: 0.8772, precision: 0.9394, recall: 0.9002, f1: 0.9194, edges-ner-ontonotes_loss: 0.0290
09/16 06:48:17 AM: Update 15751: task edges-ner-ontonotes, batch 751 (15751): mcc: 0.9146, acc: 0.8766, precision: 0.9392, recall: 0.8997, f1: 0.9190, edges-ner-ontonotes_loss: 0.0291
09/16 06:48:26 AM: Update 15809: task edges-ner-ontonotes, batch 809 (15809): mcc: 0.9142, acc: 0.8760, precision: 0.9389, recall: 0.8992, f1: 0.9187, edges-ner-ontonotes_loss: 0.0292
09/16 06:48:27 AM: Update 15836: task edges-ner-ontonotes, batch 836 (15836): mcc: 0.9140, acc: 0.8757, precision: 0.9387, recall: 0.8991, f1: 0.9185, edges-ner-ontonotes_loss: 0.0292
09/16 06:48:36 AM: Update 15875: task edges-ner-ontonotes, batch 875 (15875): mcc: 0.9138, acc: 0.8755, precision: 0.9386, recall: 0.8988, f1: 0.9182, edges-ner-ontonotes_loss: 0.0292
09/16 06:48:37 AM: Update 15900: task edges-ner-ontonotes, batch 900 (15900): mcc: 0.9140, acc: 0.8758, precision: 0.9386, recall: 0.8991, f1: 0.9184, edges-ner-ontonotes_loss: 0.0291
09/16 06:48:46 AM: Update 15953: task edges-ner-ontonotes, batch 953 (15953): mcc: 0.9144, acc: 0.8762, precision: 0.9389, recall: 0.8996, f1: 0.9188, edges-ner-ontonotes_loss: 0.0289
09/16 06:48:47 AM: Update 15977: task edges-ner-ontonotes, batch 977 (15977): mcc: 0.9149, acc: 0.8770, precision: 0.9392, recall: 0.9003, f1: 0.9193, edges-ner-ontonotes_loss: 0.0287
09/16 06:48:50 AM: ***** Step 16000 / Validation 16 *****
09/16 06:48:50 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:48:50 AM: Validating...
09/16 06:48:53 AM: ***** Step 16000 / Validation 16 *****
09/16 06:48:54 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:48:54 AM: Validating...
09/16 06:48:56 AM: Evaluate: task edges-ner-ontonotes, batch 9 (157): mcc: 0.8373, acc: 0.7840, precision: 0.8876, recall: 0.8061, f1: 0.8449, edges-ner-ontonotes_loss: 0.0426
09/16 06:48:57 AM: Evaluate: task edges-ner-ontonotes, batch 44 (157): mcc: 0.9084, acc: 0.8747, precision: 0.9344, recall: 0.8928, f1: 0.9131, edges-ner-ontonotes_loss: 0.0296
09/16 06:49:06 AM: Evaluate: task edges-ner-ontonotes, batch 56 (157): mcc: 0.9161, acc: 0.8840, precision: 0.9398, recall: 0.9019, f1: 0.9205, edges-ner-ontonotes_loss: 0.0274
09/16 06:49:07 AM: Evaluate: task edges-ner-ontonotes, batch 89 (157): mcc: 0.9268, acc: 0.8947, precision: 0.9506, recall: 0.9114, f1: 0.9306, edges-ner-ontonotes_loss: 0.0245
09/16 06:49:16 AM: Evaluate: task edges-ner-ontonotes, batch 99 (157): mcc: 0.9237, acc: 0.8910, precision: 0.9474, recall: 0.9087, f1: 0.9277, edges-ner-ontonotes_loss: 0.0249
09/16 06:49:17 AM: Evaluate: task edges-ner-ontonotes, batch 127 (157): mcc: 0.9299, acc: 0.8989, precision: 0.9515, recall: 0.9163, f1: 0.9335, edges-ner-ontonotes_loss: 0.0228
09/16 06:49:24 AM: Updating LR scheduler:
09/16 06:49:24 AM: 	Best result seen so far for macro_avg: 0.940
09/16 06:49:24 AM: 	# validation passes without improvement: 1
09/16 06:49:24 AM: edges-ner-ontonotes_loss: training: 0.028545 validation: 0.021093
09/16 06:49:24 AM: macro_avg: validation: 0.938923
09/16 06:49:24 AM: micro_avg: validation: 0.000000
09/16 06:49:24 AM: edges-ner-ontonotes_mcc: training: 0.915280 validation: 0.935533
09/16 06:49:24 AM: edges-ner-ontonotes_acc: training: 0.877326 validation: 0.906733
09/16 06:49:24 AM: edges-ner-ontonotes_precision: training: 0.939434 validation: 0.954556
09/16 06:49:24 AM: edges-ner-ontonotes_recall: training: 0.900726 validation: 0.923794
09/16 06:49:24 AM: edges-ner-ontonotes_f1: training: 0.919673 validation: 0.938923
09/16 06:49:24 AM: Global learning rate: 0.0001
09/16 06:49:24 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:49:26 AM: Evaluate: task edges-ner-ontonotes, batch 139 (157): mcc: 0.9341, acc: 0.9050, precision: 0.9540, recall: 0.9217, f1: 0.9376, edges-ner-ontonotes_loss: 0.0217
09/16 06:49:27 AM: Update 16018: task edges-ner-ontonotes, batch 18 (16018): mcc: 0.9295, acc: 0.8942, precision: 0.9542, recall: 0.9130, f1: 0.9331, edges-ner-ontonotes_loss: 0.0227
09/16 06:49:29 AM: Updating LR scheduler:
09/16 06:49:29 AM: 	Best result seen so far for macro_avg: 0.940
09/16 06:49:32 AM: 	# validation passes without improvement: 1
09/16 06:49:32 AM: edges-ner-ontonotes_loss: training: 0.028545 validation: 0.021093
09/16 06:49:32 AM: macro_avg: validation: 0.938923
09/16 06:49:32 AM: micro_avg: validation: 0.000000
09/16 06:49:32 AM: edges-ner-ontonotes_mcc: training: 0.915280 validation: 0.935533
09/16 06:49:32 AM: edges-ner-ontonotes_acc: training: 0.877326 validation: 0.906733
09/16 06:49:32 AM: edges-ner-ontonotes_precision: training: 0.939434 validation: 0.954556
09/16 06:49:32 AM: edges-ner-ontonotes_recall: training: 0.900726 validation: 0.923794
09/16 06:49:32 AM: edges-ner-ontonotes_f1: training: 0.919673 validation: 0.938923
09/16 06:49:32 AM: Global learning rate: 0.0001
09/16 06:49:32 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:49:36 AM: Update 16025: task edges-ner-ontonotes, batch 25 (16025): mcc: 0.9308, acc: 0.8974, precision: 0.9519, recall: 0.9175, f1: 0.9344, edges-ner-ontonotes_loss: 0.0229
09/16 06:49:37 AM: Update 16100: task edges-ner-ontonotes, batch 100 (16100): mcc: 0.9202, acc: 0.8857, precision: 0.9404, recall: 0.9089, f1: 0.9244, edges-ner-ontonotes_loss: 0.0256
09/16 06:49:46 AM: Update 16094: task edges-ner-ontonotes, batch 94 (16094): mcc: 0.9210, acc: 0.8862, precision: 0.9418, recall: 0.9091, f1: 0.9252, edges-ner-ontonotes_loss: 0.0253
09/16 06:49:47 AM: Update 16172: task edges-ner-ontonotes, batch 172 (16172): mcc: 0.9204, acc: 0.8860, precision: 0.9412, recall: 0.9086, f1: 0.9246, edges-ner-ontonotes_loss: 0.0253
09/16 06:49:56 AM: Update 16176: task edges-ner-ontonotes, batch 176 (16176): mcc: 0.9204, acc: 0.8860, precision: 0.9412, recall: 0.9085, f1: 0.9246, edges-ner-ontonotes_loss: 0.0254
09/16 06:49:58 AM: Update 16224: task edges-ner-ontonotes, batch 224 (16224): mcc: 0.9245, acc: 0.8907, precision: 0.9443, recall: 0.9132, f1: 0.9285, edges-ner-ontonotes_loss: 0.0241
09/16 06:50:06 AM: Update 16225: task edges-ner-ontonotes, batch 225 (16225): mcc: 0.9246, acc: 0.8908, precision: 0.9444, recall: 0.9132, f1: 0.9285, edges-ner-ontonotes_loss: 0.0241
09/16 06:50:08 AM: Update 16309: task edges-ner-ontonotes, batch 309 (16309): mcc: 0.9276, acc: 0.8944, precision: 0.9466, recall: 0.9167, f1: 0.9314, edges-ner-ontonotes_loss: 0.0230
09/16 06:50:16 AM: Update 16303: task edges-ner-ontonotes, batch 303 (16303): mcc: 0.9273, acc: 0.8941, precision: 0.9463, recall: 0.9164, f1: 0.9311, edges-ner-ontonotes_loss: 0.0231
09/16 06:50:18 AM: Update 16383: task edges-ner-ontonotes, batch 383 (16383): mcc: 0.9300, acc: 0.8975, precision: 0.9483, recall: 0.9196, f1: 0.9337, edges-ner-ontonotes_loss: 0.0222
09/16 06:50:27 AM: Update 16375: task edges-ner-ontonotes, batch 375 (16375): mcc: 0.9297, acc: 0.8971, precision: 0.9481, recall: 0.9191, f1: 0.9334, edges-ner-ontonotes_loss: 0.0223
09/16 06:50:28 AM: Update 16452: task edges-ner-ontonotes, batch 452 (16452): mcc: 0.9320, acc: 0.8998, precision: 0.9497, recall: 0.9220, f1: 0.9356, edges-ner-ontonotes_loss: 0.0217
09/16 06:50:37 AM: Update 16445: task edges-ner-ontonotes, batch 445 (16445): mcc: 0.9316, acc: 0.8993, precision: 0.9494, recall: 0.9215, f1: 0.9353, edges-ner-ontonotes_loss: 0.0218
09/16 06:50:38 AM: Update 16506: task edges-ner-ontonotes, batch 506 (16506): mcc: 0.9332, acc: 0.9010, precision: 0.9507, recall: 0.9231, f1: 0.9367, edges-ner-ontonotes_loss: 0.0214
09/16 06:50:48 AM: Update 16500: task edges-ner-ontonotes, batch 500 (16500): mcc: 0.9332, acc: 0.9011, precision: 0.9506, recall: 0.9233, f1: 0.9367, edges-ner-ontonotes_loss: 0.0214
09/16 06:50:48 AM: Update 16587: task edges-ner-ontonotes, batch 587 (16587): mcc: 0.9338, acc: 0.9018, precision: 0.9510, recall: 0.9241, f1: 0.9373, edges-ner-ontonotes_loss: 0.0212
09/16 06:50:58 AM: Update 16569: task edges-ner-ontonotes, batch 569 (16569): mcc: 0.9336, acc: 0.9014, precision: 0.9508, recall: 0.9238, f1: 0.9371, edges-ner-ontonotes_loss: 0.0213
09/16 06:50:58 AM: Update 16656: task edges-ner-ontonotes, batch 656 (16656): mcc: 0.9342, acc: 0.9021, precision: 0.9512, recall: 0.9246, f1: 0.9377, edges-ner-ontonotes_loss: 0.0210
09/16 06:51:08 AM: Update 16638: task edges-ner-ontonotes, batch 638 (16638): mcc: 0.9343, acc: 0.9022, precision: 0.9513, recall: 0.9247, f1: 0.9378, edges-ner-ontonotes_loss: 0.0210
09/16 06:51:08 AM: Update 16725: task edges-ner-ontonotes, batch 725 (16725): mcc: 0.9345, acc: 0.9025, precision: 0.9516, recall: 0.9248, f1: 0.9380, edges-ner-ontonotes_loss: 0.0210
09/16 06:51:18 AM: Update 16707: task edges-ner-ontonotes, batch 707 (16707): mcc: 0.9343, acc: 0.9022, precision: 0.9513, recall: 0.9246, f1: 0.9378, edges-ner-ontonotes_loss: 0.0211
09/16 06:51:18 AM: Update 16793: task edges-ner-ontonotes, batch 793 (16793): mcc: 0.9349, acc: 0.9028, precision: 0.9519, recall: 0.9251, f1: 0.9383, edges-ner-ontonotes_loss: 0.0209
09/16 06:51:28 AM: Update 16799: task edges-ner-ontonotes, batch 799 (16799): mcc: 0.9348, acc: 0.9028, precision: 0.9519, recall: 0.9251, f1: 0.9383, edges-ner-ontonotes_loss: 0.0209
09/16 06:51:31 AM: Update 16851: task edges-ner-ontonotes, batch 851 (16851): mcc: 0.9330, acc: 0.9006, precision: 0.9507, recall: 0.9228, f1: 0.9366, edges-ner-ontonotes_loss: 0.0214
09/16 06:51:38 AM: Update 16852: task edges-ner-ontonotes, batch 852 (16852): mcc: 0.9330, acc: 0.9006, precision: 0.9507, recall: 0.9229, f1: 0.9366, edges-ner-ontonotes_loss: 0.0214
09/16 06:51:42 AM: Update 16923: task edges-ner-ontonotes, batch 923 (16923): mcc: 0.9306, acc: 0.8975, precision: 0.9492, recall: 0.9197, f1: 0.9342, edges-ner-ontonotes_loss: 0.0225
09/16 06:51:48 AM: Update 16927: task edges-ner-ontonotes, batch 927 (16927): mcc: 0.9305, acc: 0.8974, precision: 0.9493, recall: 0.9196, f1: 0.9342, edges-ner-ontonotes_loss: 0.0225
09/16 06:51:54 AM: Update 16996: task edges-ner-ontonotes, batch 996 (16996): mcc: 0.9285, acc: 0.8948, precision: 0.9479, recall: 0.9171, f1: 0.9323, edges-ner-ontonotes_loss: 0.0235
09/16 06:51:55 AM: ***** Step 17000 / Validation 17 *****
09/16 06:51:55 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:51:55 AM: Validating...
09/16 06:51:58 AM: ***** Step 17000 / Validation 17 *****
09/16 06:51:58 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:51:58 AM: Validating...
09/16 06:51:58 AM: Evaluate: task edges-ner-ontonotes, batch 1 (157): mcc: 0.8243, acc: 0.7377, precision: 0.9200, recall: 0.7541, f1: 0.8288, edges-ner-ontonotes_loss: 0.0472
09/16 06:52:05 AM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.9126, acc: 0.8788, precision: 0.9362, recall: 0.8989, f1: 0.9171, edges-ner-ontonotes_loss: 0.0292
09/16 06:52:08 AM: Evaluate: task edges-ner-ontonotes, batch 51 (157): mcc: 0.9100, acc: 0.8757, precision: 0.9347, recall: 0.8956, f1: 0.9147, edges-ner-ontonotes_loss: 0.0298
09/16 06:52:15 AM: Evaluate: task edges-ner-ontonotes, batch 98 (157): mcc: 0.9272, acc: 0.8947, precision: 0.9505, recall: 0.9122, f1: 0.9309, edges-ner-ontonotes_loss: 0.0254
09/16 06:52:19 AM: Evaluate: task edges-ner-ontonotes, batch 95 (157): mcc: 0.9269, acc: 0.8936, precision: 0.9512, recall: 0.9109, f1: 0.9306, edges-ner-ontonotes_loss: 0.0255
09/16 06:52:25 AM: Evaluate: task edges-ner-ontonotes, batch 127 (157): mcc: 0.9303, acc: 0.8990, precision: 0.9524, recall: 0.9162, f1: 0.9339, edges-ner-ontonotes_loss: 0.0236
09/16 06:52:29 AM: Evaluate: task edges-ner-ontonotes, batch 138 (157): mcc: 0.9340, acc: 0.9043, precision: 0.9548, recall: 0.9207, f1: 0.9374, edges-ner-ontonotes_loss: 0.0226
09/16 06:52:32 AM: Updating LR scheduler:
09/16 06:52:32 AM: Updating LR scheduler:
09/16 06:52:33 AM: 	Best result seen so far for macro_avg: 0.940
09/16 06:52:33 AM: 	Best result seen so far for macro_avg: 0.940
09/16 06:52:33 AM: 	# validation passes without improvement: 2
09/16 06:52:33 AM: 	# validation passes without improvement: 2
09/16 06:52:33 AM: edges-ner-ontonotes_loss: training: 0.023502 validation: 0.021934
09/16 06:52:33 AM: macro_avg: validation: 0.938322
09/16 06:52:33 AM: edges-ner-ontonotes_loss: training: 0.023502 validation: 0.021934
09/16 06:52:33 AM: macro_avg: validation: 0.938322
09/16 06:52:33 AM: micro_avg: validation: 0.000000
09/16 06:52:33 AM: edges-ner-ontonotes_mcc: training: 0.928447 validation: 0.934919
09/16 06:52:33 AM: micro_avg: validation: 0.000000
09/16 06:52:33 AM: edges-ner-ontonotes_acc: training: 0.894741 validation: 0.905141
09/16 06:52:33 AM: edges-ner-ontonotes_mcc: training: 0.928447 validation: 0.934919
09/16 06:52:33 AM: edges-ner-ontonotes_precision: training: 0.947939 validation: 0.954934
09/16 06:52:33 AM: edges-ner-ontonotes_acc: training: 0.894741 validation: 0.905141
09/16 06:52:33 AM: edges-ner-ontonotes_recall: training: 0.917016 validation: 0.922278
09/16 06:52:33 AM: edges-ner-ontonotes_f1: training: 0.932221 validation: 0.938322
09/16 06:52:33 AM: edges-ner-ontonotes_precision: training: 0.947939 validation: 0.954934
09/16 06:52:33 AM: edges-ner-ontonotes_recall: training: 0.917016 validation: 0.922278
09/16 06:52:33 AM: edges-ner-ontonotes_f1: training: 0.932221 validation: 0.938322
09/16 06:52:33 AM: Global learning rate: 0.0001
09/16 06:52:33 AM: Global learning rate: 0.0001
09/16 06:52:33 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:52:33 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:52:35 AM: Update 17015: task edges-ner-ontonotes, batch 15 (17015): mcc: 0.9079, acc: 0.8675, precision: 0.9389, recall: 0.8875, f1: 0.9125, edges-ner-ontonotes_loss: 0.0359
09/16 06:52:39 AM: Update 17040: task edges-ner-ontonotes, batch 40 (17040): mcc: 0.9098, acc: 0.8690, precision: 0.9386, recall: 0.8914, f1: 0.9144, edges-ner-ontonotes_loss: 0.0319
09/16 06:52:45 AM: Update 17099: task edges-ner-ontonotes, batch 99 (17099): mcc: 0.9019, acc: 0.8581, precision: 0.9332, recall: 0.8818, f1: 0.9068, edges-ner-ontonotes_loss: 0.0339
09/16 06:52:51 AM: Update 17117: task edges-ner-ontonotes, batch 117 (17117): mcc: 0.9021, acc: 0.8579, precision: 0.9332, recall: 0.8822, f1: 0.9070, edges-ner-ontonotes_loss: 0.0339
09/16 06:52:55 AM: Update 17166: task edges-ner-ontonotes, batch 166 (17166): mcc: 0.9038, acc: 0.8613, precision: 0.9332, recall: 0.8854, f1: 0.9087, edges-ner-ontonotes_loss: 0.0328
09/16 06:53:01 AM: Update 17199: task edges-ner-ontonotes, batch 199 (17199): mcc: 0.9035, acc: 0.8610, precision: 0.9332, recall: 0.8849, f1: 0.9084, edges-ner-ontonotes_loss: 0.0326
09/16 06:53:06 AM: Update 17255: task edges-ner-ontonotes, batch 255 (17255): mcc: 0.9042, acc: 0.8611, precision: 0.9340, recall: 0.8855, f1: 0.9091, edges-ner-ontonotes_loss: 0.0321
09/16 06:53:11 AM: Update 17289: task edges-ner-ontonotes, batch 289 (17289): mcc: 0.9043, acc: 0.8611, precision: 0.9340, recall: 0.8857, f1: 0.9092, edges-ner-ontonotes_loss: 0.0319
09/16 06:53:16 AM: Update 17352: task edges-ner-ontonotes, batch 352 (17352): mcc: 0.9047, acc: 0.8612, precision: 0.9346, recall: 0.8858, f1: 0.9095, edges-ner-ontonotes_loss: 0.0317
09/16 06:53:24 AM: Update 17372: task edges-ner-ontonotes, batch 372 (17372): mcc: 0.9053, acc: 0.8623, precision: 0.9348, recall: 0.8866, f1: 0.9101, edges-ner-ontonotes_loss: 0.0314
09/16 06:53:28 AM: Update 17430: task edges-ner-ontonotes, batch 430 (17430): mcc: 0.9058, acc: 0.8632, precision: 0.9352, recall: 0.8873, f1: 0.9106, edges-ner-ontonotes_loss: 0.0311
09/16 06:53:34 AM: Update 17443: task edges-ner-ontonotes, batch 443 (17443): mcc: 0.9065, acc: 0.8640, precision: 0.9353, recall: 0.8884, f1: 0.9112, edges-ner-ontonotes_loss: 0.0310
09/16 06:53:38 AM: Update 17514: task edges-ner-ontonotes, batch 514 (17514): mcc: 0.9089, acc: 0.8674, precision: 0.9365, recall: 0.8917, f1: 0.9135, edges-ner-ontonotes_loss: 0.0302
09/16 06:53:44 AM: Update 17515: task edges-ner-ontonotes, batch 515 (17515): mcc: 0.9089, acc: 0.8674, precision: 0.9365, recall: 0.8917, f1: 0.9135, edges-ner-ontonotes_loss: 0.0302
09/16 06:53:48 AM: Update 17584: task edges-ner-ontonotes, batch 584 (17584): mcc: 0.9112, acc: 0.8708, precision: 0.9376, recall: 0.8949, f1: 0.9158, edges-ner-ontonotes_loss: 0.0295
09/16 06:53:54 AM: Update 17588: task edges-ner-ontonotes, batch 588 (17588): mcc: 0.9113, acc: 0.8710, precision: 0.9376, recall: 0.8951, f1: 0.9158, edges-ner-ontonotes_loss: 0.0295
09/16 06:53:58 AM: Update 17654: task edges-ner-ontonotes, batch 654 (17654): mcc: 0.9130, acc: 0.8737, precision: 0.9386, recall: 0.8973, f1: 0.9175, edges-ner-ontonotes_loss: 0.0289
09/16 06:54:04 AM: Update 17664: task edges-ner-ontonotes, batch 664 (17664): mcc: 0.9134, acc: 0.8740, precision: 0.9388, recall: 0.8977, f1: 0.9178, edges-ner-ontonotes_loss: 0.0287
09/16 06:54:09 AM: Update 17727: task edges-ner-ontonotes, batch 727 (17727): mcc: 0.9142, acc: 0.8755, precision: 0.9391, recall: 0.8991, f1: 0.9187, edges-ner-ontonotes_loss: 0.0283
09/16 06:54:16 AM: Update 17743: task edges-ner-ontonotes, batch 743 (17743): mcc: 0.9145, acc: 0.8759, precision: 0.9394, recall: 0.8993, f1: 0.9189, edges-ner-ontonotes_loss: 0.0283
09/16 06:54:19 AM: Update 17797: task edges-ner-ontonotes, batch 797 (17797): mcc: 0.9166, acc: 0.8786, precision: 0.9406, recall: 0.9021, f1: 0.9209, edges-ner-ontonotes_loss: 0.0276
09/16 06:54:26 AM: Update 17814: task edges-ner-ontonotes, batch 814 (17814): mcc: 0.9171, acc: 0.8793, precision: 0.9409, recall: 0.9027, f1: 0.9214, edges-ner-ontonotes_loss: 0.0274
09/16 06:54:29 AM: Update 17866: task edges-ner-ontonotes, batch 866 (17866): mcc: 0.9186, acc: 0.8810, precision: 0.9420, recall: 0.9045, f1: 0.9229, edges-ner-ontonotes_loss: 0.0270
09/16 06:54:36 AM: Update 17884: task edges-ner-ontonotes, batch 884 (17884): mcc: 0.9192, acc: 0.8819, precision: 0.9424, recall: 0.9053, f1: 0.9234, edges-ner-ontonotes_loss: 0.0268
09/16 06:54:39 AM: Update 17937: task edges-ner-ontonotes, batch 937 (17937): mcc: 0.9207, acc: 0.8838, precision: 0.9433, recall: 0.9071, f1: 0.9248, edges-ner-ontonotes_loss: 0.0263
09/16 06:54:47 AM: Update 17955: task edges-ner-ontonotes, batch 955 (17955): mcc: 0.9212, acc: 0.8845, precision: 0.9436, recall: 0.9078, f1: 0.9253, edges-ner-ontonotes_loss: 0.0262
09/16 06:54:48 AM: ***** Step 18000 / Validation 18 *****
09/16 06:54:48 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:54:48 AM: Validating...
09/16 06:54:49 AM: Evaluate: task edges-ner-ontonotes, batch 9 (157): mcc: 0.8335, acc: 0.7755, precision: 0.8929, recall: 0.7942, f1: 0.8407, edges-ner-ontonotes_loss: 0.0444
09/16 06:54:54 AM: ***** Step 18000 / Validation 18 *****
09/16 06:54:54 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:54:54 AM: Validating...
09/16 06:54:57 AM: Evaluate: task edges-ner-ontonotes, batch 13 (157): mcc: 0.8453, acc: 0.7886, precision: 0.9000, recall: 0.8092, f1: 0.8522, edges-ner-ontonotes_loss: 0.0414
09/16 06:54:59 AM: Evaluate: task edges-ner-ontonotes, batch 63 (157): mcc: 0.9190, acc: 0.8875, precision: 0.9410, recall: 0.9062, f1: 0.9233, edges-ner-ontonotes_loss: 0.0270
09/16 06:55:07 AM: Evaluate: task edges-ner-ontonotes, batch 62 (157): mcc: 0.9181, acc: 0.8864, precision: 0.9403, recall: 0.9052, f1: 0.9224, edges-ner-ontonotes_loss: 0.0273
09/16 06:55:10 AM: Evaluate: task edges-ner-ontonotes, batch 108 (157): mcc: 0.9262, acc: 0.8947, precision: 0.9484, recall: 0.9124, f1: 0.9301, edges-ner-ontonotes_loss: 0.0246
09/16 06:55:17 AM: Evaluate: task edges-ner-ontonotes, batch 104 (157): mcc: 0.9255, acc: 0.8938, precision: 0.9481, recall: 0.9113, f1: 0.9293, edges-ner-ontonotes_loss: 0.0249
09/16 06:55:20 AM: Evaluate: task edges-ner-ontonotes, batch 151 (157): mcc: 0.9365, acc: 0.9082, precision: 0.9550, recall: 0.9252, f1: 0.9399, edges-ner-ontonotes_loss: 0.0213
09/16 06:55:21 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:55:21 AM: Best result seen so far for macro.
09/16 06:55:21 AM: Updating LR scheduler:
09/16 06:55:21 AM: 	Best result seen so far for macro_avg: 0.940
09/16 06:55:21 AM: 	# validation passes without improvement: 0
09/16 06:55:21 AM: edges-ner-ontonotes_loss: training: 0.025837 validation: 0.021113
09/16 06:55:21 AM: macro_avg: validation: 0.940144
09/16 06:55:21 AM: micro_avg: validation: 0.000000
09/16 06:55:21 AM: edges-ner-ontonotes_mcc: training: 0.922300 validation: 0.936802
09/16 06:55:21 AM: edges-ner-ontonotes_acc: training: 0.885954 validation: 0.908553
09/16 06:55:21 AM: edges-ner-ontonotes_precision: training: 0.944432 validation: 0.954734
09/16 06:55:21 AM: edges-ner-ontonotes_recall: training: 0.908957 validation: 0.925993
09/16 06:55:21 AM: edges-ner-ontonotes_f1: training: 0.926355 validation: 0.940144
09/16 06:55:21 AM: Global learning rate: 0.0001
09/16 06:55:21 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:55:28 AM: Evaluate: task edges-ner-ontonotes, batch 143 (157): mcc: 0.9362, acc: 0.9080, precision: 0.9551, recall: 0.9245, f1: 0.9396, edges-ner-ontonotes_loss: 0.0216
09/16 06:55:30 AM: Update 18051: task edges-ner-ontonotes, batch 51 (18051): mcc: 0.9412, acc: 0.9124, precision: 0.9567, recall: 0.9322, f1: 0.9443, edges-ner-ontonotes_loss: 0.0191
09/16 06:55:30 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:55:30 AM: Best result seen so far for macro.
09/16 06:55:30 AM: Updating LR scheduler:
09/16 06:55:30 AM: 	Best result seen so far for macro_avg: 0.940
09/16 06:55:30 AM: 	# validation passes without improvement: 0
09/16 06:55:30 AM: edges-ner-ontonotes_loss: training: 0.025837 validation: 0.021113
09/16 06:55:30 AM: macro_avg: validation: 0.940144
09/16 06:55:30 AM: micro_avg: validation: 0.000000
09/16 06:55:30 AM: edges-ner-ontonotes_mcc: training: 0.922300 validation: 0.936802
09/16 06:55:30 AM: edges-ner-ontonotes_acc: training: 0.885954 validation: 0.908553
09/16 06:55:30 AM: edges-ner-ontonotes_precision: training: 0.944432 validation: 0.954734
09/16 06:55:30 AM: edges-ner-ontonotes_recall: training: 0.908957 validation: 0.925993
09/16 06:55:30 AM: edges-ner-ontonotes_f1: training: 0.926355 validation: 0.940144
09/16 06:55:30 AM: Global learning rate: 0.0001
09/16 06:55:30 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:55:38 AM: Update 18031: task edges-ner-ontonotes, batch 31 (18031): mcc: 0.9399, acc: 0.9113, precision: 0.9544, recall: 0.9322, f1: 0.9432, edges-ner-ontonotes_loss: 0.0196
09/16 06:55:40 AM: Update 18101: task edges-ner-ontonotes, batch 101 (18101): mcc: 0.9379, acc: 0.9073, precision: 0.9539, recall: 0.9289, f1: 0.9412, edges-ner-ontonotes_loss: 0.0204
09/16 06:55:48 AM: Update 18080: task edges-ner-ontonotes, batch 80 (18080): mcc: 0.9356, acc: 0.9044, precision: 0.9525, recall: 0.9259, f1: 0.9390, edges-ner-ontonotes_loss: 0.0204
09/16 06:55:50 AM: Update 18182: task edges-ner-ontonotes, batch 182 (18182): mcc: 0.9372, acc: 0.9058, precision: 0.9538, recall: 0.9277, f1: 0.9406, edges-ner-ontonotes_loss: 0.0203
09/16 06:55:58 AM: Update 18159: task edges-ner-ontonotes, batch 159 (18159): mcc: 0.9373, acc: 0.9060, precision: 0.9533, recall: 0.9283, f1: 0.9407, edges-ner-ontonotes_loss: 0.0203
09/16 06:56:02 AM: Update 18252: task edges-ner-ontonotes, batch 252 (18252): mcc: 0.9381, acc: 0.9063, precision: 0.9539, recall: 0.9293, f1: 0.9415, edges-ner-ontonotes_loss: 0.0199
09/16 06:56:08 AM: Update 18228: task edges-ner-ontonotes, batch 228 (18228): mcc: 0.9373, acc: 0.9053, precision: 0.9533, recall: 0.9283, f1: 0.9406, edges-ner-ontonotes_loss: 0.0202
09/16 06:56:12 AM: Update 18320: task edges-ner-ontonotes, batch 320 (18320): mcc: 0.9378, acc: 0.9059, precision: 0.9538, recall: 0.9287, f1: 0.9411, edges-ner-ontonotes_loss: 0.0200
09/16 06:56:18 AM: Update 18297: task edges-ner-ontonotes, batch 297 (18297): mcc: 0.9382, acc: 0.9061, precision: 0.9543, recall: 0.9290, f1: 0.9415, edges-ner-ontonotes_loss: 0.0198
09/16 06:56:22 AM: Update 18374: task edges-ner-ontonotes, batch 374 (18374): mcc: 0.9368, acc: 0.9047, precision: 0.9534, recall: 0.9272, f1: 0.9401, edges-ner-ontonotes_loss: 0.0204
09/16 06:56:30 AM: Update 18369: task edges-ner-ontonotes, batch 369 (18369): mcc: 0.9377, acc: 0.9058, precision: 0.9541, recall: 0.9282, f1: 0.9410, edges-ner-ontonotes_loss: 0.0202
09/16 06:56:32 AM: Update 18449: task edges-ner-ontonotes, batch 449 (18449): mcc: 0.9306, acc: 0.8967, precision: 0.9489, recall: 0.9200, f1: 0.9342, edges-ner-ontonotes_loss: 0.0230
09/16 06:56:40 AM: Update 18436: task edges-ner-ontonotes, batch 436 (18436): mcc: 0.9311, acc: 0.8973, precision: 0.9493, recall: 0.9206, f1: 0.9347, edges-ner-ontonotes_loss: 0.0228
09/16 06:56:42 AM: Update 18520: task edges-ner-ontonotes, batch 520 (18520): mcc: 0.9273, acc: 0.8927, precision: 0.9470, recall: 0.9158, f1: 0.9311, edges-ner-ontonotes_loss: 0.0244
09/16 06:56:50 AM: Update 18509: task edges-ner-ontonotes, batch 509 (18509): mcc: 0.9278, acc: 0.8934, precision: 0.9473, recall: 0.9165, f1: 0.9316, edges-ner-ontonotes_loss: 0.0243
09/16 06:56:52 AM: Update 18599: task edges-ner-ontonotes, batch 599 (18599): mcc: 0.9241, acc: 0.8887, precision: 0.9450, recall: 0.9119, f1: 0.9281, edges-ner-ontonotes_loss: 0.0258
09/16 06:57:00 AM: Update 18586: task edges-ner-ontonotes, batch 586 (18586): mcc: 0.9245, acc: 0.8891, precision: 0.9453, recall: 0.9123, f1: 0.9285, edges-ner-ontonotes_loss: 0.0256
09/16 06:57:04 AM: Update 18673: task edges-ner-ontonotes, batch 673 (18673): mcc: 0.9225, acc: 0.8866, precision: 0.9438, recall: 0.9099, f1: 0.9265, edges-ner-ontonotes_loss: 0.0267
09/16 06:57:10 AM: Update 18672: task edges-ner-ontonotes, batch 672 (18672): mcc: 0.9225, acc: 0.8867, precision: 0.9438, recall: 0.9099, f1: 0.9266, edges-ner-ontonotes_loss: 0.0267
09/16 06:57:14 AM: Update 18762: task edges-ner-ontonotes, batch 762 (18762): mcc: 0.9203, acc: 0.8836, precision: 0.9425, recall: 0.9070, f1: 0.9244, edges-ner-ontonotes_loss: 0.0274
09/16 06:57:20 AM: Update 18733: task edges-ner-ontonotes, batch 733 (18733): mcc: 0.9207, acc: 0.8843, precision: 0.9427, recall: 0.9077, f1: 0.9249, edges-ner-ontonotes_loss: 0.0272
09/16 06:57:24 AM: Update 18848: task edges-ner-ontonotes, batch 848 (18848): mcc: 0.9198, acc: 0.8828, precision: 0.9425, recall: 0.9062, f1: 0.9240, edges-ner-ontonotes_loss: 0.0275
09/16 06:57:30 AM: Update 18824: task edges-ner-ontonotes, batch 824 (18824): mcc: 0.9196, acc: 0.8826, precision: 0.9423, recall: 0.9060, f1: 0.9238, edges-ner-ontonotes_loss: 0.0275
09/16 06:57:34 AM: Update 18941: task edges-ner-ontonotes, batch 941 (18941): mcc: 0.9193, acc: 0.8822, precision: 0.9423, recall: 0.9054, f1: 0.9235, edges-ner-ontonotes_loss: 0.0276
09/16 06:57:40 AM: Update 18919: task edges-ner-ontonotes, batch 919 (18919): mcc: 0.9196, acc: 0.8825, precision: 0.9425, recall: 0.9059, f1: 0.9238, edges-ner-ontonotes_loss: 0.0275
09/16 06:57:44 AM: ***** Step 19000 / Validation 19 *****
09/16 06:57:44 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:57:44 AM: Validating...
09/16 06:57:44 AM: Evaluate: task edges-ner-ontonotes, batch 2 (157): mcc: 0.8052, acc: 0.7385, precision: 0.8559, recall: 0.7769, f1: 0.8145, edges-ner-ontonotes_loss: 0.0489
09/16 06:57:51 AM: Update 18986: task edges-ner-ontonotes, batch 986 (18986): mcc: 0.9186, acc: 0.8812, precision: 0.9419, recall: 0.9046, f1: 0.9228, edges-ner-ontonotes_loss: 0.0277
09/16 06:57:54 AM: ***** Step 19000 / Validation 19 *****
09/16 06:57:54 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:57:54 AM: Validating...
09/16 06:57:54 AM: Evaluate: task edges-ner-ontonotes, batch 68 (157): mcc: 0.9211, acc: 0.8894, precision: 0.9435, recall: 0.9076, f1: 0.9252, edges-ner-ontonotes_loss: 0.0264
09/16 06:58:01 AM: Evaluate: task edges-ner-ontonotes, batch 39 (157): mcc: 0.9075, acc: 0.8757, precision: 0.9313, recall: 0.8940, f1: 0.9123, edges-ner-ontonotes_loss: 0.0301
09/16 06:58:05 AM: Evaluate: task edges-ner-ontonotes, batch 112 (157): mcc: 0.9292, acc: 0.9001, precision: 0.9481, recall: 0.9182, f1: 0.9329, edges-ner-ontonotes_loss: 0.0232
09/16 06:58:11 AM: Evaluate: task edges-ner-ontonotes, batch 82 (157): mcc: 0.9272, acc: 0.8975, precision: 0.9477, recall: 0.9149, f1: 0.9310, edges-ner-ontonotes_loss: 0.0247
09/16 06:58:15 AM: Evaluate: task edges-ner-ontonotes, batch 153 (157): mcc: 0.9368, acc: 0.9093, precision: 0.9538, recall: 0.9269, f1: 0.9402, edges-ner-ontonotes_loss: 0.0209
09/16 06:58:16 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:58:16 AM: Best result seen so far for macro.
09/16 06:58:16 AM: Updating LR scheduler:
09/16 06:58:16 AM: 	Best result seen so far for macro_avg: 0.941
09/16 06:58:16 AM: 	# validation passes without improvement: 0
09/16 06:58:16 AM: edges-ner-ontonotes_loss: training: 0.027668 validation: 0.020665
09/16 06:58:16 AM: macro_avg: validation: 0.940674
09/16 06:58:16 AM: micro_avg: validation: 0.000000
09/16 06:58:16 AM: edges-ner-ontonotes_mcc: training: 0.918568 validation: 0.937341
09/16 06:58:16 AM: edges-ner-ontonotes_acc: training: 0.881113 validation: 0.909994
09/16 06:58:16 AM: edges-ner-ontonotes_precision: training: 0.941848 validation: 0.954138
09/16 06:58:16 AM: edges-ner-ontonotes_recall: training: 0.904511 validation: 0.927586
09/16 06:58:16 AM: edges-ner-ontonotes_f1: training: 0.922802 validation: 0.940674
09/16 06:58:16 AM: Global learning rate: 0.0001
09/16 06:58:16 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:58:22 AM: Evaluate: task edges-ner-ontonotes, batch 127 (157): mcc: 0.9324, acc: 0.9032, precision: 0.9512, recall: 0.9212, f1: 0.9359, edges-ner-ontonotes_loss: 0.0222
09/16 06:58:25 AM: Update 19051: task edges-ner-ontonotes, batch 51 (19051): mcc: 0.9269, acc: 0.8907, precision: 0.9433, recall: 0.9186, f1: 0.9308, edges-ner-ontonotes_loss: 0.0242
09/16 06:58:27 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:58:27 AM: Best result seen so far for macro.
09/16 06:58:27 AM: Updating LR scheduler:
09/16 06:58:27 AM: 	Best result seen so far for macro_avg: 0.941
09/16 06:58:27 AM: 	# validation passes without improvement: 0
09/16 06:58:27 AM: edges-ner-ontonotes_loss: training: 0.027668 validation: 0.020665
09/16 06:58:27 AM: macro_avg: validation: 0.940674
09/16 06:58:27 AM: micro_avg: validation: 0.000000
09/16 06:58:27 AM: edges-ner-ontonotes_mcc: training: 0.918568 validation: 0.937341
09/16 06:58:27 AM: edges-ner-ontonotes_acc: training: 0.881113 validation: 0.909994
09/16 06:58:27 AM: edges-ner-ontonotes_precision: training: 0.941848 validation: 0.954138
09/16 06:58:27 AM: edges-ner-ontonotes_recall: training: 0.904511 validation: 0.927586
09/16 06:58:27 AM: edges-ner-ontonotes_f1: training: 0.922802 validation: 0.940674
09/16 06:58:27 AM: Global learning rate: 0.0001
09/16 06:58:27 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 06:58:32 AM: Update 19026: task edges-ner-ontonotes, batch 26 (19026): mcc: 0.9266, acc: 0.8911, precision: 0.9427, recall: 0.9188, f1: 0.9306, edges-ner-ontonotes_loss: 0.0241
09/16 06:58:35 AM: Update 19125: task edges-ner-ontonotes, batch 125 (19125): mcc: 0.9252, acc: 0.8906, precision: 0.9431, recall: 0.9157, f1: 0.9292, edges-ner-ontonotes_loss: 0.0247
09/16 06:58:42 AM: Update 19096: task edges-ner-ontonotes, batch 96 (19096): mcc: 0.9281, acc: 0.8934, precision: 0.9461, recall: 0.9182, f1: 0.9320, edges-ner-ontonotes_loss: 0.0238
09/16 06:58:45 AM: Update 19195: task edges-ner-ontonotes, batch 195 (19195): mcc: 0.9245, acc: 0.8892, precision: 0.9432, recall: 0.9142, f1: 0.9285, edges-ner-ontonotes_loss: 0.0244
09/16 06:58:52 AM: Update 19164: task edges-ner-ontonotes, batch 164 (19164): mcc: 0.9240, acc: 0.8887, precision: 0.9429, recall: 0.9137, f1: 0.9280, edges-ner-ontonotes_loss: 0.0245
09/16 06:58:55 AM: Update 19271: task edges-ner-ontonotes, batch 271 (19271): mcc: 0.9269, acc: 0.8922, precision: 0.9459, recall: 0.9161, f1: 0.9307, edges-ner-ontonotes_loss: 0.0240
09/16 06:59:02 AM: Update 19253: task edges-ner-ontonotes, batch 253 (19253): mcc: 0.9261, acc: 0.8911, precision: 0.9454, recall: 0.9152, f1: 0.9300, edges-ner-ontonotes_loss: 0.0242
09/16 06:59:05 AM: Update 19318: task edges-ner-ontonotes, batch 318 (19318): mcc: 0.9269, acc: 0.8924, precision: 0.9456, recall: 0.9164, f1: 0.9308, edges-ner-ontonotes_loss: 0.0239
09/16 06:59:12 AM: Update 19300: task edges-ner-ontonotes, batch 300 (19300): mcc: 0.9263, acc: 0.8914, precision: 0.9456, recall: 0.9153, f1: 0.9302, edges-ner-ontonotes_loss: 0.0241
09/16 06:59:16 AM: Update 19401: task edges-ner-ontonotes, batch 401 (19401): mcc: 0.9303, acc: 0.8969, precision: 0.9478, recall: 0.9206, f1: 0.9340, edges-ner-ontonotes_loss: 0.0228
09/16 06:59:22 AM: Update 19365: task edges-ner-ontonotes, batch 365 (19365): mcc: 0.9294, acc: 0.8959, precision: 0.9473, recall: 0.9194, f1: 0.9331, edges-ner-ontonotes_loss: 0.0231
09/16 06:59:26 AM: Update 19473: task edges-ner-ontonotes, batch 473 (19473): mcc: 0.9327, acc: 0.9001, precision: 0.9499, recall: 0.9231, f1: 0.9363, edges-ner-ontonotes_loss: 0.0220
09/16 06:59:32 AM: Update 19435: task edges-ner-ontonotes, batch 435 (19435): mcc: 0.9313, acc: 0.8981, precision: 0.9488, recall: 0.9216, f1: 0.9350, edges-ner-ontonotes_loss: 0.0224
09/16 06:59:36 AM: Update 19543: task edges-ner-ontonotes, batch 543 (19543): mcc: 0.9341, acc: 0.9021, precision: 0.9508, recall: 0.9249, f1: 0.9377, edges-ner-ontonotes_loss: 0.0214
09/16 06:59:42 AM: Update 19505: task edges-ner-ontonotes, batch 505 (19505): mcc: 0.9332, acc: 0.9009, precision: 0.9501, recall: 0.9238, f1: 0.9368, edges-ner-ontonotes_loss: 0.0217
09/16 06:59:47 AM: Update 19612: task edges-ner-ontonotes, batch 612 (19612): mcc: 0.9347, acc: 0.9026, precision: 0.9512, recall: 0.9254, f1: 0.9381, edges-ner-ontonotes_loss: 0.0212
09/16 06:59:53 AM: Update 19585: task edges-ner-ontonotes, batch 585 (19585): mcc: 0.9344, acc: 0.9025, precision: 0.9509, recall: 0.9253, f1: 0.9379, edges-ner-ontonotes_loss: 0.0213
09/16 06:59:57 AM: Update 19686: task edges-ner-ontonotes, batch 686 (19686): mcc: 0.9353, acc: 0.9035, precision: 0.9517, recall: 0.9263, f1: 0.9388, edges-ner-ontonotes_loss: 0.0210
09/16 07:00:04 AM: Update 19644: task edges-ner-ontonotes, batch 644 (19644): mcc: 0.9349, acc: 0.9029, precision: 0.9512, recall: 0.9258, f1: 0.9383, edges-ner-ontonotes_loss: 0.0211
09/16 07:00:08 AM: Update 19766: task edges-ner-ontonotes, batch 766 (19766): mcc: 0.9354, acc: 0.9039, precision: 0.9517, recall: 0.9264, f1: 0.9389, edges-ner-ontonotes_loss: 0.0209
09/16 07:00:14 AM: Update 19713: task edges-ner-ontonotes, batch 713 (19713): mcc: 0.9355, acc: 0.9038, precision: 0.9518, recall: 0.9264, f1: 0.9390, edges-ner-ontonotes_loss: 0.0210
09/16 07:00:18 AM: Update 19837: task edges-ner-ontonotes, batch 837 (19837): mcc: 0.9356, acc: 0.9039, precision: 0.9520, recall: 0.9264, f1: 0.9390, edges-ner-ontonotes_loss: 0.0208
09/16 07:00:24 AM: Update 19786: task edges-ner-ontonotes, batch 786 (19786): mcc: 0.9353, acc: 0.9037, precision: 0.9515, recall: 0.9264, f1: 0.9388, edges-ner-ontonotes_loss: 0.0209
09/16 07:00:28 AM: Update 19908: task edges-ner-ontonotes, batch 908 (19908): mcc: 0.9359, acc: 0.9043, precision: 0.9521, recall: 0.9268, f1: 0.9393, edges-ner-ontonotes_loss: 0.0207
09/16 07:00:34 AM: Update 19861: task edges-ner-ontonotes, batch 861 (19861): mcc: 0.9358, acc: 0.9041, precision: 0.9521, recall: 0.9266, f1: 0.9392, edges-ner-ontonotes_loss: 0.0207
09/16 07:00:38 AM: Update 19960: task edges-ner-ontonotes, batch 960 (19960): mcc: 0.9344, acc: 0.9022, precision: 0.9514, recall: 0.9247, f1: 0.9379, edges-ner-ontonotes_loss: 0.0213
09/16 07:00:44 AM: ***** Step 20000 / Validation 20 *****
09/16 07:00:44 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:00:44 AM: Validating...
09/16 07:00:44 AM: Update 19925: task edges-ner-ontonotes, batch 925 (19925): mcc: 0.9358, acc: 0.9042, precision: 0.9522, recall: 0.9266, f1: 0.9392, edges-ner-ontonotes_loss: 0.0207
09/16 07:00:50 AM: Evaluate: task edges-ner-ontonotes, batch 36 (157): mcc: 0.9027, acc: 0.8692, precision: 0.9262, recall: 0.8902, f1: 0.9078, edges-ner-ontonotes_loss: 0.0314
09/16 07:00:54 AM: Update 19980: task edges-ner-ontonotes, batch 980 (19980): mcc: 0.9339, acc: 0.9017, precision: 0.9512, recall: 0.9241, f1: 0.9374, edges-ner-ontonotes_loss: 0.0216
09/16 07:00:58 AM: ***** Step 20000 / Validation 20 *****
09/16 07:00:58 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:00:58 AM: Validating...
09/16 07:01:00 AM: Evaluate: task edges-ner-ontonotes, batch 90 (157): mcc: 0.9269, acc: 0.8957, precision: 0.9487, recall: 0.9135, f1: 0.9308, edges-ner-ontonotes_loss: 0.0250
09/16 07:01:05 AM: Evaluate: task edges-ner-ontonotes, batch 35 (157): mcc: 0.9015, acc: 0.8678, precision: 0.9256, recall: 0.8885, f1: 0.9067, edges-ner-ontonotes_loss: 0.0317
09/16 07:01:10 AM: Evaluate: task edges-ner-ontonotes, batch 129 (157): mcc: 0.9318, acc: 0.9022, precision: 0.9529, recall: 0.9185, f1: 0.9354, edges-ner-ontonotes_loss: 0.0230
09/16 07:01:15 AM: Evaluate: task edges-ner-ontonotes, batch 79 (157): mcc: 0.9229, acc: 0.8912, precision: 0.9459, recall: 0.9088, f1: 0.9269, edges-ner-ontonotes_loss: 0.0264
09/16 07:01:16 AM: Updating LR scheduler:
09/16 07:01:16 AM: 	Best result seen so far for macro_avg: 0.941
09/16 07:01:16 AM: 	# validation passes without improvement: 1
09/16 07:01:16 AM: edges-ner-ontonotes_loss: training: 0.021976 validation: 0.021497
09/16 07:01:16 AM: macro_avg: validation: 0.939071
09/16 07:01:16 AM: micro_avg: validation: 0.000000
09/16 07:01:16 AM: edges-ner-ontonotes_mcc: training: 0.932910 validation: 0.935706
09/16 07:01:16 AM: edges-ner-ontonotes_acc: training: 0.900389 validation: 0.907037
09/16 07:01:16 AM: edges-ner-ontonotes_precision: training: 0.950389 validation: 0.955430
09/16 07:01:16 AM: edges-ner-ontonotes_recall: training: 0.922966 validation: 0.923264
09/16 07:01:16 AM: edges-ner-ontonotes_f1: training: 0.936477 validation: 0.939071
09/16 07:01:16 AM: Global learning rate: 0.0001
09/16 07:01:16 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:01:20 AM: Update 20024: task edges-ner-ontonotes, batch 24 (20024): mcc: 0.9064, acc: 0.8654, precision: 0.9337, recall: 0.8898, f1: 0.9112, edges-ner-ontonotes_loss: 0.0361
09/16 07:01:26 AM: Evaluate: task edges-ner-ontonotes, batch 128 (157): mcc: 0.9315, acc: 0.9018, precision: 0.9526, recall: 0.9182, f1: 0.9351, edges-ner-ontonotes_loss: 0.0231
09/16 07:01:30 AM: Update 20086: task edges-ner-ontonotes, batch 86 (20086): mcc: 0.9068, acc: 0.8670, precision: 0.9335, recall: 0.8907, f1: 0.9116, edges-ner-ontonotes_loss: 0.0325
09/16 07:01:32 AM: Updating LR scheduler:
09/16 07:01:32 AM: 	Best result seen so far for macro_avg: 0.941
09/16 07:01:32 AM: 	# validation passes without improvement: 1
09/16 07:01:32 AM: edges-ner-ontonotes_loss: training: 0.021976 validation: 0.021497
09/16 07:01:32 AM: macro_avg: validation: 0.939071
09/16 07:01:32 AM: micro_avg: validation: 0.000000
09/16 07:01:32 AM: edges-ner-ontonotes_mcc: training: 0.932910 validation: 0.935706
09/16 07:01:32 AM: edges-ner-ontonotes_acc: training: 0.900389 validation: 0.907037
09/16 07:01:32 AM: edges-ner-ontonotes_precision: training: 0.950389 validation: 0.955430
09/16 07:01:32 AM: edges-ner-ontonotes_recall: training: 0.922966 validation: 0.923264
09/16 07:01:32 AM: edges-ner-ontonotes_f1: training: 0.936477 validation: 0.939071
09/16 07:01:32 AM: Global learning rate: 0.0001
09/16 07:01:32 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:01:37 AM: Update 20008: task edges-ner-ontonotes, batch 8 (20008): mcc: 0.9075, acc: 0.8648, precision: 0.9396, recall: 0.8861, f1: 0.9121, edges-ner-ontonotes_loss: 0.0406
09/16 07:01:40 AM: Update 20169: task edges-ner-ontonotes, batch 169 (20169): mcc: 0.9055, acc: 0.8660, precision: 0.9324, recall: 0.8894, f1: 0.9104, edges-ner-ontonotes_loss: 0.0326
09/16 07:01:47 AM: Update 20082: task edges-ner-ontonotes, batch 82 (20082): mcc: 0.9054, acc: 0.8649, precision: 0.9322, recall: 0.8893, f1: 0.9102, edges-ner-ontonotes_loss: 0.0331
09/16 07:01:51 AM: Update 20229: task edges-ner-ontonotes, batch 229 (20229): mcc: 0.9038, acc: 0.8639, precision: 0.9309, recall: 0.8875, f1: 0.9087, edges-ner-ontonotes_loss: 0.0338
09/16 07:01:57 AM: Update 20164: task edges-ner-ontonotes, batch 164 (20164): mcc: 0.9062, acc: 0.8672, precision: 0.9327, recall: 0.8903, f1: 0.9110, edges-ner-ontonotes_loss: 0.0324
09/16 07:02:01 AM: Update 20308: task edges-ner-ontonotes, batch 308 (20308): mcc: 0.9042, acc: 0.8639, precision: 0.9318, recall: 0.8874, f1: 0.9091, edges-ner-ontonotes_loss: 0.0328
09/16 07:02:09 AM: Update 20229: task edges-ner-ontonotes, batch 229 (20229): mcc: 0.9038, acc: 0.8639, precision: 0.9309, recall: 0.8875, f1: 0.9087, edges-ner-ontonotes_loss: 0.0338
09/16 07:02:11 AM: Update 20404: task edges-ner-ontonotes, batch 404 (20404): mcc: 0.9059, acc: 0.8660, precision: 0.9334, recall: 0.8891, f1: 0.9107, edges-ner-ontonotes_loss: 0.0320
09/16 07:02:19 AM: Update 20313: task edges-ner-ontonotes, batch 313 (20313): mcc: 0.9043, acc: 0.8641, precision: 0.9320, recall: 0.8875, f1: 0.9092, edges-ner-ontonotes_loss: 0.0326
09/16 07:02:21 AM: Update 20492: task edges-ner-ontonotes, batch 492 (20492): mcc: 0.9064, acc: 0.8666, precision: 0.9335, recall: 0.8899, f1: 0.9112, edges-ner-ontonotes_loss: 0.0316
09/16 07:02:29 AM: Update 20409: task edges-ner-ontonotes, batch 409 (20409): mcc: 0.9056, acc: 0.8657, precision: 0.9333, recall: 0.8887, f1: 0.9105, edges-ner-ontonotes_loss: 0.0321
09/16 07:02:31 AM: Update 20551: task edges-ner-ontonotes, batch 551 (20551): mcc: 0.9069, acc: 0.8670, precision: 0.9338, recall: 0.8905, f1: 0.9116, edges-ner-ontonotes_loss: 0.0313
09/16 07:02:39 AM: Update 20498: task edges-ner-ontonotes, batch 498 (20498): mcc: 0.9064, acc: 0.8667, precision: 0.9335, recall: 0.8900, f1: 0.9112, edges-ner-ontonotes_loss: 0.0315
09/16 07:02:42 AM: Update 20631: task edges-ner-ontonotes, batch 631 (20631): mcc: 0.9100, acc: 0.8713, precision: 0.9358, recall: 0.8945, f1: 0.9147, edges-ner-ontonotes_loss: 0.0303
09/16 07:02:49 AM: Update 20559: task edges-ner-ontonotes, batch 559 (20559): mcc: 0.9072, acc: 0.8675, precision: 0.9341, recall: 0.8909, f1: 0.9120, edges-ner-ontonotes_loss: 0.0311
09/16 07:02:54 AM: Update 20709: task edges-ner-ontonotes, batch 709 (20709): mcc: 0.9124, acc: 0.8743, precision: 0.9374, recall: 0.8974, f1: 0.9169, edges-ner-ontonotes_loss: 0.0295
09/16 07:02:59 AM: Update 20633: task edges-ner-ontonotes, batch 633 (20633): mcc: 0.9101, acc: 0.8714, precision: 0.9359, recall: 0.8945, f1: 0.9148, edges-ner-ontonotes_loss: 0.0302
09/16 07:03:04 AM: Update 20779: task edges-ner-ontonotes, batch 779 (20779): mcc: 0.9130, acc: 0.8751, precision: 0.9377, recall: 0.8981, f1: 0.9175, edges-ner-ontonotes_loss: 0.0292
09/16 07:03:09 AM: Update 20707: task edges-ner-ontonotes, batch 707 (20707): mcc: 0.9124, acc: 0.8742, precision: 0.9374, recall: 0.8973, f1: 0.9169, edges-ner-ontonotes_loss: 0.0295
09/16 07:03:14 AM: Update 20854: task edges-ner-ontonotes, batch 854 (20854): mcc: 0.9144, acc: 0.8768, precision: 0.9385, recall: 0.9000, f1: 0.9189, edges-ner-ontonotes_loss: 0.0286
09/16 07:03:19 AM: Update 20786: task edges-ner-ontonotes, batch 786 (20786): mcc: 0.9133, acc: 0.8753, precision: 0.9379, recall: 0.8985, f1: 0.9178, edges-ner-ontonotes_loss: 0.0291
09/16 07:03:24 AM: Update 20906: task edges-ner-ontonotes, batch 906 (20906): mcc: 0.9163, acc: 0.8793, precision: 0.9395, recall: 0.9025, f1: 0.9206, edges-ner-ontonotes_loss: 0.0280
09/16 07:03:32 AM: Update 20855: task edges-ner-ontonotes, batch 855 (20855): mcc: 0.9145, acc: 0.8769, precision: 0.9385, recall: 0.9001, f1: 0.9189, edges-ner-ontonotes_loss: 0.0286
09/16 07:03:34 AM: Update 20987: task edges-ner-ontonotes, batch 987 (20987): mcc: 0.9189, acc: 0.8826, precision: 0.9413, recall: 0.9057, f1: 0.9232, edges-ner-ontonotes_loss: 0.0272
09/16 07:03:36 AM: ***** Step 21000 / Validation 21 *****
09/16 07:03:36 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:03:36 AM: Validating...
09/16 07:03:42 AM: Update 20918: task edges-ner-ontonotes, batch 918 (20918): mcc: 0.9167, acc: 0.8798, precision: 0.9398, recall: 0.9030, f1: 0.9211, edges-ner-ontonotes_loss: 0.0279
09/16 07:03:44 AM: Evaluate: task edges-ner-ontonotes, batch 52 (157): mcc: 0.9106, acc: 0.8800, precision: 0.9320, recall: 0.8992, f1: 0.9153, edges-ner-ontonotes_loss: 0.0294
09/16 07:03:52 AM: Update 20973: task edges-ner-ontonotes, batch 973 (20973): mcc: 0.9185, acc: 0.8820, precision: 0.9410, recall: 0.9052, f1: 0.9227, edges-ner-ontonotes_loss: 0.0273
09/16 07:03:55 AM: Evaluate: task edges-ner-ontonotes, batch 104 (157): mcc: 0.9259, acc: 0.8978, precision: 0.9436, recall: 0.9165, f1: 0.9298, edges-ner-ontonotes_loss: 0.0251
09/16 07:03:56 AM: ***** Step 21000 / Validation 21 *****
09/16 07:03:56 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:03:56 AM: Validating...
09/16 07:04:02 AM: Evaluate: task edges-ner-ontonotes, batch 28 (157): mcc: 0.8771, acc: 0.8374, precision: 0.9101, recall: 0.8580, f1: 0.8833, edges-ner-ontonotes_loss: 0.0375
09/16 07:04:07 AM: Evaluate: task edges-ner-ontonotes, batch 145 (157): mcc: 0.9363, acc: 0.9103, precision: 0.9507, recall: 0.9290, f1: 0.9397, edges-ner-ontonotes_loss: 0.0217
09/16 07:04:10 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:04:10 AM: Best result seen so far for macro.
09/16 07:04:10 AM: Updating LR scheduler:
09/16 07:04:10 AM: 	Best result seen so far for macro_avg: 0.941
09/16 07:04:10 AM: 	# validation passes without improvement: 0
09/16 07:04:10 AM: edges-ner-ontonotes_loss: training: 0.027046 validation: 0.021126
09/16 07:04:10 AM: macro_avg: validation: 0.941140
09/16 07:04:10 AM: micro_avg: validation: 0.000000
09/16 07:04:10 AM: edges-ner-ontonotes_mcc: training: 0.919354 validation: 0.937778
09/16 07:04:10 AM: edges-ner-ontonotes_acc: training: 0.883168 validation: 0.912193
09/16 07:04:10 AM: edges-ner-ontonotes_precision: training: 0.941535 validation: 0.951348
09/16 07:04:10 AM: edges-ner-ontonotes_recall: training: 0.906282 validation: 0.931150
09/16 07:04:10 AM: edges-ner-ontonotes_f1: training: 0.923572 validation: 0.941140
09/16 07:04:10 AM: Global learning rate: 0.0001
09/16 07:04:10 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:04:12 AM: Evaluate: task edges-ner-ontonotes, batch 78 (157): mcc: 0.9223, acc: 0.8922, precision: 0.9426, recall: 0.9108, f1: 0.9264, edges-ner-ontonotes_loss: 0.0267
09/16 07:04:18 AM: Update 21042: task edges-ner-ontonotes, batch 42 (21042): mcc: 0.9432, acc: 0.9118, precision: 0.9558, recall: 0.9370, f1: 0.9463, edges-ner-ontonotes_loss: 0.0187
09/16 07:04:22 AM: Evaluate: task edges-ner-ontonotes, batch 126 (157): mcc: 0.9324, acc: 0.9054, precision: 0.9488, recall: 0.9236, f1: 0.9360, edges-ner-ontonotes_loss: 0.0230
09/16 07:04:28 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:04:28 AM: Update 21099: task edges-ner-ontonotes, batch 99 (21099): mcc: 0.9423, acc: 0.9113, precision: 0.9558, recall: 0.9353, f1: 0.9454, edges-ner-ontonotes_loss: 0.0185
09/16 07:04:30 AM: Best result seen so far for macro.
09/16 07:04:30 AM: Updating LR scheduler:
09/16 07:04:30 AM: 	Best result seen so far for macro_avg: 0.941
09/16 07:04:30 AM: 	# validation passes without improvement: 0
09/16 07:04:30 AM: edges-ner-ontonotes_loss: training: 0.027046 validation: 0.021126
09/16 07:04:30 AM: macro_avg: validation: 0.941140
09/16 07:04:30 AM: micro_avg: validation: 0.000000
09/16 07:04:30 AM: edges-ner-ontonotes_mcc: training: 0.919354 validation: 0.937778
09/16 07:04:30 AM: edges-ner-ontonotes_acc: training: 0.883168 validation: 0.912193
09/16 07:04:30 AM: edges-ner-ontonotes_precision: training: 0.941535 validation: 0.951348
09/16 07:04:30 AM: edges-ner-ontonotes_recall: training: 0.906282 validation: 0.931150
09/16 07:04:30 AM: edges-ner-ontonotes_f1: training: 0.923572 validation: 0.941140
09/16 07:04:30 AM: Global learning rate: 0.0001
09/16 07:04:30 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:04:32 AM: Update 21012: task edges-ner-ontonotes, batch 12 (21012): mcc: 0.9441, acc: 0.9143, precision: 0.9510, recall: 0.9435, f1: 0.9472, edges-ner-ontonotes_loss: 0.0192
09/16 07:04:42 AM: Update 21090: task edges-ner-ontonotes, batch 90 (21090): mcc: 0.9437, acc: 0.9134, precision: 0.9571, recall: 0.9367, f1: 0.9468, edges-ner-ontonotes_loss: 0.0180
09/16 07:04:43 AM: Update 21168: task edges-ner-ontonotes, batch 168 (21168): mcc: 0.9417, acc: 0.9114, precision: 0.9560, recall: 0.9340, f1: 0.9449, edges-ner-ontonotes_loss: 0.0189
09/16 07:04:52 AM: Update 21162: task edges-ner-ontonotes, batch 162 (21162): mcc: 0.9421, acc: 0.9117, precision: 0.9562, recall: 0.9345, f1: 0.9452, edges-ner-ontonotes_loss: 0.0188
09/16 07:04:53 AM: Update 21240: task edges-ner-ontonotes, batch 240 (21240): mcc: 0.9406, acc: 0.9097, precision: 0.9552, recall: 0.9327, f1: 0.9438, edges-ner-ontonotes_loss: 0.0192
09/16 07:05:02 AM: Update 21212: task edges-ner-ontonotes, batch 212 (21212): mcc: 0.9406, acc: 0.9098, precision: 0.9549, recall: 0.9330, f1: 0.9438, edges-ner-ontonotes_loss: 0.0192
09/16 07:05:03 AM: Update 21319: task edges-ner-ontonotes, batch 319 (21319): mcc: 0.9410, acc: 0.9100, precision: 0.9561, recall: 0.9325, f1: 0.9442, edges-ner-ontonotes_loss: 0.0191
09/16 07:05:12 AM: Update 21282: task edges-ner-ontonotes, batch 282 (21282): mcc: 0.9410, acc: 0.9100, precision: 0.9559, recall: 0.9326, f1: 0.9441, edges-ner-ontonotes_loss: 0.0191
09/16 07:05:13 AM: Update 21388: task edges-ner-ontonotes, batch 388 (21388): mcc: 0.9397, acc: 0.9085, precision: 0.9550, recall: 0.9313, f1: 0.9430, edges-ner-ontonotes_loss: 0.0196
09/16 07:05:22 AM: Update 21354: task edges-ner-ontonotes, batch 354 (21354): mcc: 0.9405, acc: 0.9094, precision: 0.9555, recall: 0.9322, f1: 0.9437, edges-ner-ontonotes_loss: 0.0193
09/16 07:05:23 AM: Update 21459: task edges-ner-ontonotes, batch 459 (21459): mcc: 0.9390, acc: 0.9075, precision: 0.9543, recall: 0.9306, f1: 0.9423, edges-ner-ontonotes_loss: 0.0196
09/16 07:05:33 AM: Update 21429: task edges-ner-ontonotes, batch 429 (21429): mcc: 0.9397, acc: 0.9082, precision: 0.9549, recall: 0.9312, f1: 0.9429, edges-ner-ontonotes_loss: 0.0195
09/16 07:05:33 AM: Update 21518: task edges-ner-ontonotes, batch 518 (21518): mcc: 0.9356, acc: 0.9033, precision: 0.9520, recall: 0.9264, f1: 0.9390, edges-ner-ontonotes_loss: 0.0209
09/16 07:05:43 AM: Update 21488: task edges-ner-ontonotes, batch 488 (21488): mcc: 0.9381, acc: 0.9063, precision: 0.9536, recall: 0.9294, f1: 0.9414, edges-ner-ontonotes_loss: 0.0199
09/16 07:05:43 AM: Update 21598: task edges-ner-ontonotes, batch 598 (21598): mcc: 0.9319, acc: 0.8987, precision: 0.9498, recall: 0.9216, f1: 0.9355, edges-ner-ontonotes_loss: 0.0227
09/16 07:05:53 AM: Update 21563: task edges-ner-ontonotes, batch 563 (21563): mcc: 0.9337, acc: 0.9009, precision: 0.9508, recall: 0.9240, f1: 0.9372, edges-ner-ontonotes_loss: 0.0218
09/16 07:05:53 AM: Update 21671: task edges-ner-ontonotes, batch 671 (21671): mcc: 0.9292, acc: 0.8951, precision: 0.9480, recall: 0.9183, f1: 0.9329, edges-ner-ontonotes_loss: 0.0238
09/16 07:06:03 AM: Update 21636: task edges-ner-ontonotes, batch 636 (21636): mcc: 0.9303, acc: 0.8964, precision: 0.9488, recall: 0.9197, f1: 0.9340, edges-ner-ontonotes_loss: 0.0233
09/16 07:06:03 AM: Update 21743: task edges-ner-ontonotes, batch 743 (21743): mcc: 0.9268, acc: 0.8921, precision: 0.9464, recall: 0.9155, f1: 0.9307, edges-ner-ontonotes_loss: 0.0248
09/16 07:06:13 AM: Update 21718: task edges-ner-ontonotes, batch 718 (21718): mcc: 0.9273, acc: 0.8927, precision: 0.9467, recall: 0.9161, f1: 0.9312, edges-ner-ontonotes_loss: 0.0246
09/16 07:06:13 AM: Update 21798: task edges-ner-ontonotes, batch 798 (21798): mcc: 0.9253, acc: 0.8902, precision: 0.9455, recall: 0.9136, f1: 0.9293, edges-ner-ontonotes_loss: 0.0253
09/16 07:06:23 AM: Update 21889: task edges-ner-ontonotes, batch 889 (21889): mcc: 0.9237, acc: 0.8880, precision: 0.9446, recall: 0.9115, f1: 0.9277, edges-ner-ontonotes_loss: 0.0259
09/16 07:06:24 AM: Update 21785: task edges-ner-ontonotes, batch 785 (21785): mcc: 0.9257, acc: 0.8907, precision: 0.9458, recall: 0.9140, f1: 0.9296, edges-ner-ontonotes_loss: 0.0253
09/16 07:06:33 AM: Update 21977: task edges-ner-ontonotes, batch 977 (21977): mcc: 0.9225, acc: 0.8864, precision: 0.9437, recall: 0.9101, f1: 0.9266, edges-ner-ontonotes_loss: 0.0263
09/16 07:06:34 AM: Update 21870: task edges-ner-ontonotes, batch 870 (21870): mcc: 0.9241, acc: 0.8885, precision: 0.9448, recall: 0.9120, f1: 0.9281, edges-ner-ontonotes_loss: 0.0258
09/16 07:06:36 AM: ***** Step 22000 / Validation 22 *****
09/16 07:06:36 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:06:36 AM: Validating...
09/16 07:06:43 AM: Evaluate: task edges-ner-ontonotes, batch 50 (157): mcc: 0.9129, acc: 0.8844, precision: 0.9368, recall: 0.8988, f1: 0.9174, edges-ner-ontonotes_loss: 0.0280
09/16 07:06:44 AM: Update 21940: task edges-ner-ontonotes, batch 940 (21940): mcc: 0.9230, acc: 0.8872, precision: 0.9441, recall: 0.9107, f1: 0.9271, edges-ner-ontonotes_loss: 0.0261
09/16 07:06:53 AM: Evaluate: task edges-ner-ontonotes, batch 105 (157): mcc: 0.9273, acc: 0.8997, precision: 0.9501, recall: 0.9128, f1: 0.9311, edges-ner-ontonotes_loss: 0.0237
09/16 07:06:54 AM: Update 21998: task edges-ner-ontonotes, batch 998 (21998): mcc: 0.9224, acc: 0.8863, precision: 0.9437, recall: 0.9100, f1: 0.9265, edges-ner-ontonotes_loss: 0.0263
09/16 07:06:54 AM: ***** Step 22000 / Validation 22 *****
09/16 07:06:54 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:06:54 AM: Validating...
09/16 07:07:04 AM: Evaluate: task edges-ner-ontonotes, batch 148 (157): mcc: 0.9363, acc: 0.9099, precision: 0.9565, recall: 0.9234, f1: 0.9396, edges-ner-ontonotes_loss: 0.0209
09/16 07:07:04 AM: Evaluate: task edges-ner-ontonotes, batch 50 (157): mcc: 0.9129, acc: 0.8844, precision: 0.9368, recall: 0.8988, f1: 0.9174, edges-ner-ontonotes_loss: 0.0280
09/16 07:07:05 AM: Updating LR scheduler:
09/16 07:07:05 AM: 	Best result seen so far for macro_avg: 0.941
09/16 07:07:05 AM: 	# validation passes without improvement: 1
09/16 07:07:05 AM: edges-ner-ontonotes_loss: training: 0.026329 validation: 0.020586
09/16 07:07:05 AM: macro_avg: validation: 0.940233
09/16 07:07:05 AM: micro_avg: validation: 0.000000
09/16 07:07:05 AM: edges-ner-ontonotes_mcc: training: 0.922431 validation: 0.936933
09/16 07:07:05 AM: edges-ner-ontonotes_acc: training: 0.886321 validation: 0.910525
09/16 07:07:05 AM: edges-ner-ontonotes_precision: training: 0.943685 validation: 0.956535
09/16 07:07:05 AM: edges-ner-ontonotes_recall: training: 0.909931 validation: 0.924477
09/16 07:07:05 AM: edges-ner-ontonotes_f1: training: 0.926501 validation: 0.940233
09/16 07:07:05 AM: Global learning rate: 0.0001
09/16 07:07:05 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:07:14 AM: Update 22049: task edges-ner-ontonotes, batch 49 (22049): mcc: 0.9188, acc: 0.8817, precision: 0.9446, recall: 0.9023, f1: 0.9230, edges-ner-ontonotes_loss: 0.0264
09/16 07:07:14 AM: Evaluate: task edges-ner-ontonotes, batch 104 (157): mcc: 0.9270, acc: 0.8993, precision: 0.9498, recall: 0.9124, f1: 0.9307, edges-ner-ontonotes_loss: 0.0238
09/16 07:07:24 AM: Updating LR scheduler:
09/16 07:07:24 AM: 	Best result seen so far for macro_avg: 0.941
09/16 07:07:24 AM: 	# validation passes without improvement: 1
09/16 07:07:24 AM: edges-ner-ontonotes_loss: training: 0.026329 validation: 0.020586
09/16 07:07:24 AM: macro_avg: validation: 0.940233
09/16 07:07:24 AM: micro_avg: validation: 0.000000
09/16 07:07:24 AM: edges-ner-ontonotes_mcc: training: 0.922431 validation: 0.936933
09/16 07:07:24 AM: edges-ner-ontonotes_acc: training: 0.886321 validation: 0.910525
09/16 07:07:24 AM: edges-ner-ontonotes_precision: training: 0.943685 validation: 0.956535
09/16 07:07:24 AM: edges-ner-ontonotes_recall: training: 0.909931 validation: 0.924477
09/16 07:07:24 AM: edges-ner-ontonotes_f1: training: 0.926501 validation: 0.940233
09/16 07:07:24 AM: Global learning rate: 0.0001
09/16 07:07:24 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:07:25 AM: Update 22001: task edges-ner-ontonotes, batch 1 (22001): mcc: 0.9460, acc: 0.9275, precision: 0.9559, recall: 0.9420, f1: 0.9489, edges-ner-ontonotes_loss: 0.0164
09/16 07:07:25 AM: Update 22098: task edges-ner-ontonotes, batch 98 (22098): mcc: 0.9143, acc: 0.8769, precision: 0.9394, recall: 0.8988, f1: 0.9187, edges-ner-ontonotes_loss: 0.0275
09/16 07:07:35 AM: Update 22181: task edges-ner-ontonotes, batch 181 (22181): mcc: 0.9195, acc: 0.8832, precision: 0.9417, recall: 0.9063, f1: 0.9237, edges-ner-ontonotes_loss: 0.0261
09/16 07:07:35 AM: Update 22085: task edges-ner-ontonotes, batch 85 (22085): mcc: 0.9161, acc: 0.8787, precision: 0.9409, recall: 0.9008, f1: 0.9204, edges-ner-ontonotes_loss: 0.0270
09/16 07:07:45 AM: Update 22265: task edges-ner-ontonotes, batch 265 (22265): mcc: 0.9216, acc: 0.8862, precision: 0.9428, recall: 0.9093, f1: 0.9257, edges-ner-ontonotes_loss: 0.0253
09/16 07:07:45 AM: Update 22133: task edges-ner-ontonotes, batch 133 (22133): mcc: 0.9177, acc: 0.8807, precision: 0.9419, recall: 0.9029, f1: 0.9220, edges-ner-ontonotes_loss: 0.0268
09/16 07:07:56 AM: Update 22208: task edges-ner-ontonotes, batch 208 (22208): mcc: 0.9205, acc: 0.8842, precision: 0.9422, recall: 0.9077, f1: 0.9246, edges-ner-ontonotes_loss: 0.0257
09/16 07:07:56 AM: Update 22337: task edges-ner-ontonotes, batch 337 (22337): mcc: 0.9227, acc: 0.8873, precision: 0.9429, recall: 0.9112, f1: 0.9267, edges-ner-ontonotes_loss: 0.0249
09/16 07:08:06 AM: Update 22277: task edges-ner-ontonotes, batch 277 (22277): mcc: 0.9222, acc: 0.8867, precision: 0.9430, recall: 0.9101, f1: 0.9263, edges-ner-ontonotes_loss: 0.0251
09/16 07:08:06 AM: Update 22405: task edges-ner-ontonotes, batch 405 (22405): mcc: 0.9234, acc: 0.8884, precision: 0.9435, recall: 0.9118, f1: 0.9274, edges-ner-ontonotes_loss: 0.0247
09/16 07:08:16 AM: Update 22459: task edges-ner-ontonotes, batch 459 (22459): mcc: 0.9254, acc: 0.8906, precision: 0.9450, recall: 0.9142, f1: 0.9293, edges-ner-ontonotes_loss: 0.0241
09/16 07:08:16 AM: Update 22356: task edges-ner-ontonotes, batch 356 (22356): mcc: 0.9220, acc: 0.8868, precision: 0.9423, recall: 0.9105, f1: 0.9261, edges-ner-ontonotes_loss: 0.0251
09/16 07:08:26 AM: Update 22535: task edges-ner-ontonotes, batch 535 (22535): mcc: 0.9279, acc: 0.8941, precision: 0.9465, recall: 0.9174, f1: 0.9317, edges-ner-ontonotes_loss: 0.0234
09/16 07:08:26 AM: Update 22412: task edges-ner-ontonotes, batch 412 (22412): mcc: 0.9233, acc: 0.8883, precision: 0.9436, recall: 0.9118, f1: 0.9274, edges-ner-ontonotes_loss: 0.0247
09/16 07:08:36 AM: Update 22479: task edges-ner-ontonotes, batch 479 (22479): mcc: 0.9261, acc: 0.8915, precision: 0.9451, recall: 0.9154, f1: 0.9300, edges-ner-ontonotes_loss: 0.0240
09/16 07:08:36 AM: Update 22607: task edges-ner-ontonotes, batch 607 (22607): mcc: 0.9298, acc: 0.8965, precision: 0.9479, recall: 0.9195, f1: 0.9335, edges-ner-ontonotes_loss: 0.0228
09/16 07:08:46 AM: Update 22677: task edges-ner-ontonotes, batch 677 (22677): mcc: 0.9317, acc: 0.8990, precision: 0.9494, recall: 0.9217, f1: 0.9354, edges-ner-ontonotes_loss: 0.0222
09/16 07:08:46 AM: Update 22550: task edges-ner-ontonotes, batch 550 (22550): mcc: 0.9284, acc: 0.8948, precision: 0.9468, recall: 0.9179, f1: 0.9322, edges-ner-ontonotes_loss: 0.0233
09/16 07:08:56 AM: Update 22729: task edges-ner-ontonotes, batch 729 (22729): mcc: 0.9331, acc: 0.9010, precision: 0.9503, recall: 0.9235, f1: 0.9367, edges-ner-ontonotes_loss: 0.0218
09/16 07:08:56 AM: Update 22629: task edges-ner-ontonotes, batch 629 (22629): mcc: 0.9306, acc: 0.8976, precision: 0.9485, recall: 0.9205, f1: 0.9343, edges-ner-ontonotes_loss: 0.0226
09/16 07:09:06 AM: Update 22701: task edges-ner-ontonotes, batch 701 (22701): mcc: 0.9322, acc: 0.8997, precision: 0.9498, recall: 0.9222, f1: 0.9358, edges-ner-ontonotes_loss: 0.0220
09/16 07:09:06 AM: Update 22801: task edges-ner-ontonotes, batch 801 (22801): mcc: 0.9337, acc: 0.9017, precision: 0.9506, recall: 0.9242, f1: 0.9372, edges-ner-ontonotes_loss: 0.0216
09/16 07:09:16 AM: Update 22752: task edges-ner-ontonotes, batch 752 (22752): mcc: 0.9332, acc: 0.9012, precision: 0.9503, recall: 0.9237, f1: 0.9368, edges-ner-ontonotes_loss: 0.0217
09/16 07:09:16 AM: Update 22880: task edges-ner-ontonotes, batch 880 (22880): mcc: 0.9342, acc: 0.9021, precision: 0.9510, recall: 0.9247, f1: 0.9377, edges-ner-ontonotes_loss: 0.0213
09/16 07:09:26 AM: Update 22825: task edges-ner-ontonotes, batch 825 (22825): mcc: 0.9337, acc: 0.9016, precision: 0.9506, recall: 0.9242, f1: 0.9372, edges-ner-ontonotes_loss: 0.0215
09/16 07:09:27 AM: Update 22952: task edges-ner-ontonotes, batch 952 (22952): mcc: 0.9346, acc: 0.9026, precision: 0.9513, recall: 0.9251, f1: 0.9380, edges-ner-ontonotes_loss: 0.0212
09/16 07:09:33 AM: ***** Step 23000 / Validation 23 *****
09/16 07:09:33 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:09:33 AM: Validating...
09/16 07:09:37 AM: Evaluate: task edges-ner-ontonotes, batch 21 (157): mcc: 0.8791, acc: 0.8362, precision: 0.9150, recall: 0.8570, f1: 0.8851, edges-ner-ontonotes_loss: 0.0334
09/16 07:09:37 AM: Update 22890: task edges-ner-ontonotes, batch 890 (22890): mcc: 0.9341, acc: 0.9021, precision: 0.9508, recall: 0.9248, f1: 0.9377, edges-ner-ontonotes_loss: 0.0214
09/16 07:09:47 AM: Evaluate: task edges-ner-ontonotes, batch 77 (157): mcc: 0.9207, acc: 0.8910, precision: 0.9426, recall: 0.9078, f1: 0.9249, edges-ner-ontonotes_loss: 0.0272
09/16 07:09:47 AM: Update 22943: task edges-ner-ontonotes, batch 943 (22943): mcc: 0.9344, acc: 0.9024, precision: 0.9512, recall: 0.9250, f1: 0.9379, edges-ner-ontonotes_loss: 0.0212
09/16 07:09:57 AM: Evaluate: task edges-ner-ontonotes, batch 127 (157): mcc: 0.9328, acc: 0.9060, precision: 0.9508, recall: 0.9224, f1: 0.9364, edges-ner-ontonotes_loss: 0.0229
09/16 07:09:57 AM: Update 22996: task edges-ner-ontonotes, batch 996 (22996): mcc: 0.9348, acc: 0.9028, precision: 0.9516, recall: 0.9253, f1: 0.9383, edges-ner-ontonotes_loss: 0.0211
09/16 07:09:58 AM: ***** Step 23000 / Validation 23 *****
09/16 07:09:59 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:09:59 AM: Validating...
09/16 07:10:02 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:10:02 AM: Best result seen so far for macro.
09/16 07:10:02 AM: Updating LR scheduler:
09/16 07:10:02 AM: 	Best result seen so far for macro_avg: 0.941
09/16 07:10:02 AM: 	# validation passes without improvement: 2
09/16 07:10:02 AM: edges-ner-ontonotes_loss: training: 0.021055 validation: 0.020911
09/16 07:10:02 AM: macro_avg: validation: 0.941149
09/16 07:10:02 AM: micro_avg: validation: 0.000000
09/16 07:10:02 AM: edges-ner-ontonotes_mcc: training: 0.934892 validation: 0.937828
09/16 07:10:02 AM: edges-ner-ontonotes_acc: training: 0.902867 validation: 0.912496
09/16 07:10:02 AM: edges-ner-ontonotes_precision: training: 0.951684 validation: 0.953753
09/16 07:10:02 AM: edges-ner-ontonotes_recall: training: 0.925407 validation: 0.928875
09/16 07:10:02 AM: edges-ner-ontonotes_f1: training: 0.938362 validation: 0.941149
09/16 07:10:02 AM: Global learning rate: 0.0001
09/16 07:10:02 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:10:07 AM: Update 23028: task edges-ner-ontonotes, batch 28 (23028): mcc: 0.9378, acc: 0.9068, precision: 0.9539, recall: 0.9286, f1: 0.9411, edges-ner-ontonotes_loss: 0.0194
09/16 07:10:07 AM: Evaluate: task edges-ner-ontonotes, batch 49 (157): mcc: 0.9053, acc: 0.8744, precision: 0.9282, recall: 0.8930, f1: 0.9103, edges-ner-ontonotes_loss: 0.0308
09/16 07:10:17 AM: Update 23068: task edges-ner-ontonotes, batch 68 (23068): mcc: 0.9150, acc: 0.8745, precision: 0.9393, recall: 0.9003, f1: 0.9194, edges-ner-ontonotes_loss: 0.0278
09/16 07:10:17 AM: Evaluate: task edges-ner-ontonotes, batch 105 (157): mcc: 0.9262, acc: 0.8982, precision: 0.9460, recall: 0.9146, f1: 0.9300, edges-ner-ontonotes_loss: 0.0249
09/16 07:10:27 AM: Update 23123: task edges-ner-ontonotes, batch 123 (23123): mcc: 0.9086, acc: 0.8673, precision: 0.9346, recall: 0.8930, f1: 0.9134, edges-ner-ontonotes_loss: 0.0313
09/16 07:10:27 AM: Evaluate: task edges-ner-ontonotes, batch 156 (157): mcc: 0.9378, acc: 0.9124, precision: 0.9537, recall: 0.9288, f1: 0.9411, edges-ner-ontonotes_loss: 0.0210
09/16 07:10:27 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:10:27 AM: Best result seen so far for macro.
09/16 07:10:27 AM: Updating LR scheduler:
09/16 07:10:27 AM: 	Best result seen so far for macro_avg: 0.941
09/16 07:10:27 AM: 	# validation passes without improvement: 2
09/16 07:10:27 AM: edges-ner-ontonotes_loss: training: 0.021055 validation: 0.020911
09/16 07:10:27 AM: macro_avg: validation: 0.941149
09/16 07:10:27 AM: micro_avg: validation: 0.000000
09/16 07:10:27 AM: edges-ner-ontonotes_mcc: training: 0.934892 validation: 0.937828
09/16 07:10:27 AM: edges-ner-ontonotes_acc: training: 0.902867 validation: 0.912496
09/16 07:10:27 AM: edges-ner-ontonotes_precision: training: 0.951684 validation: 0.953753
09/16 07:10:27 AM: edges-ner-ontonotes_recall: training: 0.925407 validation: 0.928875
09/16 07:10:27 AM: edges-ner-ontonotes_f1: training: 0.938362 validation: 0.941149
09/16 07:10:27 AM: Global learning rate: 0.0001
09/16 07:10:27 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:10:37 AM: Update 23203: task edges-ner-ontonotes, batch 203 (23203): mcc: 0.9070, acc: 0.8663, precision: 0.9335, recall: 0.8910, f1: 0.9118, edges-ner-ontonotes_loss: 0.0318
09/16 07:10:37 AM: Update 23052: task edges-ner-ontonotes, batch 52 (23052): mcc: 0.9213, acc: 0.8836, precision: 0.9452, recall: 0.9063, f1: 0.9254, edges-ner-ontonotes_loss: 0.0256
09/16 07:10:47 AM: Update 23278: task edges-ner-ontonotes, batch 278 (23278): mcc: 0.9071, acc: 0.8669, precision: 0.9325, recall: 0.8923, f1: 0.9120, edges-ner-ontonotes_loss: 0.0320
09/16 07:10:47 AM: Update 23129: task edges-ner-ontonotes, batch 129 (23129): mcc: 0.9087, acc: 0.8679, precision: 0.9348, recall: 0.8930, f1: 0.9134, edges-ner-ontonotes_loss: 0.0313
09/16 07:10:57 AM: Update 23206: task edges-ner-ontonotes, batch 206 (23206): mcc: 0.9067, acc: 0.8661, precision: 0.9331, recall: 0.8910, f1: 0.9115, edges-ner-ontonotes_loss: 0.0318
09/16 07:10:59 AM: Update 23341: task edges-ner-ontonotes, batch 341 (23341): mcc: 0.9060, acc: 0.8654, precision: 0.9321, recall: 0.8905, f1: 0.9108, edges-ner-ontonotes_loss: 0.0323
09/16 07:11:08 AM: Update 23290: task edges-ner-ontonotes, batch 290 (23290): mcc: 0.9069, acc: 0.8666, precision: 0.9327, recall: 0.8917, f1: 0.9117, edges-ner-ontonotes_loss: 0.0320
09/16 07:11:09 AM: Update 23419: task edges-ner-ontonotes, batch 419 (23419): mcc: 0.9060, acc: 0.8655, precision: 0.9324, recall: 0.8904, f1: 0.9109, edges-ner-ontonotes_loss: 0.0317
09/16 07:11:18 AM: Update 23345: task edges-ner-ontonotes, batch 345 (23345): mcc: 0.9060, acc: 0.8655, precision: 0.9321, recall: 0.8906, f1: 0.9109, edges-ner-ontonotes_loss: 0.0323
09/16 07:11:19 AM: Update 23518: task edges-ner-ontonotes, batch 518 (23518): mcc: 0.9065, acc: 0.8663, precision: 0.9327, recall: 0.8909, f1: 0.9113, edges-ner-ontonotes_loss: 0.0314
09/16 07:11:28 AM: Update 23432: task edges-ner-ontonotes, batch 432 (23432): mcc: 0.9063, acc: 0.8658, precision: 0.9327, recall: 0.8905, f1: 0.9111, edges-ner-ontonotes_loss: 0.0316
09/16 07:11:29 AM: Update 23605: task edges-ner-ontonotes, batch 605 (23605): mcc: 0.9066, acc: 0.8662, precision: 0.9330, recall: 0.8908, f1: 0.9114, edges-ner-ontonotes_loss: 0.0312
09/16 07:11:38 AM: Update 23535: task edges-ner-ontonotes, batch 535 (23535): mcc: 0.9062, acc: 0.8658, precision: 0.9326, recall: 0.8905, f1: 0.9111, edges-ner-ontonotes_loss: 0.0314
09/16 07:11:41 AM: Update 23668: task edges-ner-ontonotes, batch 668 (23668): mcc: 0.9073, acc: 0.8671, precision: 0.9335, recall: 0.8916, f1: 0.9121, edges-ner-ontonotes_loss: 0.0310
09/16 07:11:48 AM: Update 23624: task edges-ner-ontonotes, batch 624 (23624): mcc: 0.9064, acc: 0.8658, precision: 0.9330, recall: 0.8905, f1: 0.9113, edges-ner-ontonotes_loss: 0.0312
09/16 07:11:51 AM: Update 23745: task edges-ner-ontonotes, batch 745 (23745): mcc: 0.9100, acc: 0.8705, precision: 0.9352, recall: 0.8950, f1: 0.9147, edges-ner-ontonotes_loss: 0.0301
09/16 07:11:58 AM: Update 23679: task edges-ner-ontonotes, batch 679 (23679): mcc: 0.9075, acc: 0.8674, precision: 0.9336, recall: 0.8919, f1: 0.9123, edges-ner-ontonotes_loss: 0.0308
09/16 07:12:01 AM: Update 23829: task edges-ner-ontonotes, batch 829 (23829): mcc: 0.9112, acc: 0.8723, precision: 0.9359, recall: 0.8966, f1: 0.9158, edges-ner-ontonotes_loss: 0.0295
09/16 07:12:08 AM: Update 23756: task edges-ner-ontonotes, batch 756 (23756): mcc: 0.9101, acc: 0.8707, precision: 0.9352, recall: 0.8952, f1: 0.9148, edges-ner-ontonotes_loss: 0.0300
09/16 07:12:12 AM: Update 23905: task edges-ner-ontonotes, batch 905 (23905): mcc: 0.9125, acc: 0.8740, precision: 0.9366, recall: 0.8982, f1: 0.9170, edges-ner-ontonotes_loss: 0.0290
09/16 07:12:18 AM: Update 23837: task edges-ner-ontonotes, batch 837 (23837): mcc: 0.9113, acc: 0.8724, precision: 0.9359, recall: 0.8967, f1: 0.9159, edges-ner-ontonotes_loss: 0.0295
09/16 07:12:24 AM: Update 23967: task edges-ner-ontonotes, batch 967 (23967): mcc: 0.9135, acc: 0.8754, precision: 0.9371, recall: 0.8997, f1: 0.9180, edges-ner-ontonotes_loss: 0.0287
09/16 07:12:28 AM: Update 23919: task edges-ner-ontonotes, batch 919 (23919): mcc: 0.9125, acc: 0.8741, precision: 0.9365, recall: 0.8984, f1: 0.9171, edges-ner-ontonotes_loss: 0.0290
09/16 07:12:29 AM: ***** Step 24000 / Validation 24 *****
09/16 07:12:29 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:12:29 AM: Validating...
09/16 07:12:35 AM: Evaluate: task edges-ner-ontonotes, batch 34 (157): mcc: 0.8969, acc: 0.8599, precision: 0.9270, recall: 0.8784, f1: 0.9021, edges-ner-ontonotes_loss: 0.0329
09/16 07:12:39 AM: Update 23967: task edges-ner-ontonotes, batch 967 (23967): mcc: 0.9135, acc: 0.8754, precision: 0.9371, recall: 0.8997, f1: 0.9180, edges-ner-ontonotes_loss: 0.0287
09/16 07:12:45 AM: Evaluate: task edges-ner-ontonotes, batch 95 (157): mcc: 0.9294, acc: 0.8997, precision: 0.9502, recall: 0.9167, f1: 0.9331, edges-ner-ontonotes_loss: 0.0244
09/16 07:12:46 AM: ***** Step 24000 / Validation 24 *****
09/16 07:12:47 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:12:47 AM: Validating...
09/16 07:12:49 AM: Evaluate: task edges-ner-ontonotes, batch 12 (157): mcc: 0.8428, acc: 0.7879, precision: 0.9010, recall: 0.8037, f1: 0.8496, edges-ner-ontonotes_loss: 0.0416
09/16 07:12:55 AM: Evaluate: task edges-ner-ontonotes, batch 139 (157): mcc: 0.9369, acc: 0.9104, precision: 0.9533, recall: 0.9276, f1: 0.9403, edges-ner-ontonotes_loss: 0.0214
09/16 07:12:59 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:12:59 AM: Best result seen so far for macro.
09/16 07:12:59 AM: Updating LR scheduler:
09/16 07:12:59 AM: 	Best result seen so far for macro_avg: 0.941
09/16 07:12:59 AM: 	# validation passes without improvement: 0
09/16 07:12:59 AM: edges-ner-ontonotes_loss: training: 0.028339 validation: 0.020772
09/16 07:12:59 AM: macro_avg: validation: 0.941398
09/16 07:12:59 AM: micro_avg: validation: 0.000000
09/16 07:12:59 AM: edges-ner-ontonotes_mcc: training: 0.914931 validation: 0.938074
09/16 07:12:59 AM: edges-ner-ontonotes_acc: training: 0.877167 validation: 0.911738
09/16 07:12:59 AM: edges-ner-ontonotes_precision: training: 0.938158 validation: 0.953066
09/16 07:12:59 AM: edges-ner-ontonotes_recall: training: 0.901316 validation: 0.930012
09/16 07:12:59 AM: edges-ner-ontonotes_f1: training: 0.919368 validation: 0.941398
09/16 07:12:59 AM: Global learning rate: 0.0001
09/16 07:12:59 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:13:00 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.9209, acc: 0.8917, precision: 0.9420, recall: 0.9088, f1: 0.9251, edges-ner-ontonotes_loss: 0.0266
09/16 07:13:05 AM: Update 24035: task edges-ner-ontonotes, batch 35 (24035): mcc: 0.9476, acc: 0.9203, precision: 0.9581, recall: 0.9429, f1: 0.9505, edges-ner-ontonotes_loss: 0.0175
09/16 07:13:10 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9286, acc: 0.8991, precision: 0.9480, recall: 0.9172, f1: 0.9323, edges-ner-ontonotes_loss: 0.0237
09/16 07:13:15 AM: Update 24087: task edges-ner-ontonotes, batch 87 (24087): mcc: 0.9448, acc: 0.9165, precision: 0.9578, recall: 0.9380, f1: 0.9478, edges-ner-ontonotes_loss: 0.0177
09/16 07:13:18 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:13:18 AM: Best result seen so far for macro.
09/16 07:13:18 AM: Updating LR scheduler:
09/16 07:13:18 AM: 	Best result seen so far for macro_avg: 0.941
09/16 07:13:18 AM: 	# validation passes without improvement: 0
09/16 07:13:18 AM: edges-ner-ontonotes_loss: training: 0.028339 validation: 0.020772
09/16 07:13:18 AM: macro_avg: validation: 0.941398
09/16 07:13:18 AM: micro_avg: validation: 0.000000
09/16 07:13:18 AM: edges-ner-ontonotes_mcc: training: 0.914931 validation: 0.938074
09/16 07:13:18 AM: edges-ner-ontonotes_acc: training: 0.877167 validation: 0.911738
09/16 07:13:18 AM: edges-ner-ontonotes_precision: training: 0.938158 validation: 0.953066
09/16 07:13:18 AM: edges-ner-ontonotes_recall: training: 0.901316 validation: 0.930012
09/16 07:13:18 AM: edges-ner-ontonotes_f1: training: 0.919368 validation: 0.941398
09/16 07:13:18 AM: Global learning rate: 0.0001
09/16 07:13:18 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:13:21 AM: Update 24001: task edges-ner-ontonotes, batch 1 (24001): mcc: 0.9654, acc: 0.9333, precision: 0.9516, recall: 0.9833, f1: 0.9672, edges-ner-ontonotes_loss: 0.0120
09/16 07:13:25 AM: Update 24167: task edges-ner-ontonotes, batch 167 (24167): mcc: 0.9444, acc: 0.9156, precision: 0.9568, recall: 0.9382, f1: 0.9474, edges-ner-ontonotes_loss: 0.0183
09/16 07:13:31 AM: Update 24071: task edges-ner-ontonotes, batch 71 (24071): mcc: 0.9439, acc: 0.9163, precision: 0.9566, recall: 0.9374, f1: 0.9469, edges-ner-ontonotes_loss: 0.0183
09/16 07:13:35 AM: Update 24243: task edges-ner-ontonotes, batch 243 (24243): mcc: 0.9438, acc: 0.9142, precision: 0.9569, recall: 0.9369, f1: 0.9468, edges-ner-ontonotes_loss: 0.0182
09/16 07:13:42 AM: Update 24147: task edges-ner-ontonotes, batch 147 (24147): mcc: 0.9453, acc: 0.9167, precision: 0.9579, recall: 0.9389, f1: 0.9483, edges-ner-ontonotes_loss: 0.0180
09/16 07:13:45 AM: Update 24293: task edges-ner-ontonotes, batch 293 (24293): mcc: 0.9433, acc: 0.9137, precision: 0.9564, recall: 0.9366, f1: 0.9464, edges-ner-ontonotes_loss: 0.0184
09/16 07:13:52 AM: Update 24223: task edges-ner-ontonotes, batch 223 (24223): mcc: 0.9443, acc: 0.9150, precision: 0.9569, recall: 0.9378, f1: 0.9473, edges-ner-ontonotes_loss: 0.0181
09/16 07:13:55 AM: Update 24363: task edges-ner-ontonotes, batch 363 (24363): mcc: 0.9432, acc: 0.9135, precision: 0.9567, recall: 0.9361, f1: 0.9463, edges-ner-ontonotes_loss: 0.0185
09/16 07:14:03 AM: Update 24280: task edges-ner-ontonotes, batch 280 (24280): mcc: 0.9435, acc: 0.9143, precision: 0.9565, recall: 0.9369, f1: 0.9466, edges-ner-ontonotes_loss: 0.0184
09/16 07:14:05 AM: Update 24446: task edges-ner-ontonotes, batch 446 (24446): mcc: 0.9429, acc: 0.9131, precision: 0.9564, recall: 0.9357, f1: 0.9459, edges-ner-ontonotes_loss: 0.0186
09/16 07:14:13 AM: Update 24345: task edges-ner-ontonotes, batch 345 (24345): mcc: 0.9428, acc: 0.9129, precision: 0.9564, recall: 0.9355, f1: 0.9458, edges-ner-ontonotes_loss: 0.0185
09/16 07:14:16 AM: Update 24513: task edges-ner-ontonotes, batch 513 (24513): mcc: 0.9427, acc: 0.9127, precision: 0.9567, recall: 0.9351, f1: 0.9458, edges-ner-ontonotes_loss: 0.0186
09/16 07:14:23 AM: Update 24421: task edges-ner-ontonotes, batch 421 (24421): mcc: 0.9432, acc: 0.9136, precision: 0.9567, recall: 0.9360, f1: 0.9462, edges-ner-ontonotes_loss: 0.0185
09/16 07:14:26 AM: Update 24589: task edges-ner-ontonotes, batch 589 (24589): mcc: 0.9414, acc: 0.9112, precision: 0.9558, recall: 0.9335, f1: 0.9445, edges-ner-ontonotes_loss: 0.0189
09/16 07:14:33 AM: Update 24495: task edges-ner-ontonotes, batch 495 (24495): mcc: 0.9427, acc: 0.9127, precision: 0.9568, recall: 0.9350, f1: 0.9458, edges-ner-ontonotes_loss: 0.0186
09/16 07:14:36 AM: Update 24647: task edges-ner-ontonotes, batch 647 (24647): mcc: 0.9383, acc: 0.9072, precision: 0.9536, recall: 0.9300, f1: 0.9417, edges-ner-ontonotes_loss: 0.0202
09/16 07:14:43 AM: Update 24571: task edges-ner-ontonotes, batch 571 (24571): mcc: 0.9419, acc: 0.9119, precision: 0.9563, recall: 0.9340, f1: 0.9450, edges-ner-ontonotes_loss: 0.0187
09/16 07:14:46 AM: Update 24720: task edges-ner-ontonotes, batch 720 (24720): mcc: 0.9351, acc: 0.9029, precision: 0.9518, recall: 0.9257, f1: 0.9386, edges-ner-ontonotes_loss: 0.0216
09/16 07:14:53 AM: Update 24633: task edges-ner-ontonotes, batch 633 (24633): mcc: 0.9393, acc: 0.9086, precision: 0.9542, recall: 0.9312, f1: 0.9426, edges-ner-ontonotes_loss: 0.0198
09/16 07:14:56 AM: Update 24800: task edges-ner-ontonotes, batch 800 (24800): mcc: 0.9329, acc: 0.9002, precision: 0.9502, recall: 0.9231, f1: 0.9365, edges-ner-ontonotes_loss: 0.0228
09/16 07:15:04 AM: Update 24707: task edges-ner-ontonotes, batch 707 (24707): mcc: 0.9356, acc: 0.9036, precision: 0.9520, recall: 0.9264, f1: 0.9390, edges-ner-ontonotes_loss: 0.0214
09/16 07:15:06 AM: Update 24876: task edges-ner-ontonotes, batch 876 (24876): mcc: 0.9306, acc: 0.8972, precision: 0.9486, recall: 0.9203, f1: 0.9343, edges-ner-ontonotes_loss: 0.0238
09/16 07:15:14 AM: Update 24790: task edges-ner-ontonotes, batch 790 (24790): mcc: 0.9333, acc: 0.9007, precision: 0.9506, recall: 0.9236, f1: 0.9369, edges-ner-ontonotes_loss: 0.0226
09/16 07:15:16 AM: Update 24935: task edges-ner-ontonotes, batch 935 (24935): mcc: 0.9292, acc: 0.8954, precision: 0.9477, recall: 0.9187, f1: 0.9330, edges-ner-ontonotes_loss: 0.0243
09/16 07:15:24 AM: Update 24868: task edges-ner-ontonotes, batch 868 (24868): mcc: 0.9309, acc: 0.8975, precision: 0.9488, recall: 0.9206, f1: 0.9345, edges-ner-ontonotes_loss: 0.0237
09/16 07:15:24 AM: ***** Step 25000 / Validation 25 *****
09/16 07:15:24 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:15:24 AM: Validating...
09/16 07:15:26 AM: Evaluate: task edges-ner-ontonotes, batch 15 (157): mcc: 0.8678, acc: 0.8271, precision: 0.9090, recall: 0.8420, f1: 0.8742, edges-ner-ontonotes_loss: 0.0355
09/16 07:15:34 AM: Update 24910: task edges-ner-ontonotes, batch 910 (24910): mcc: 0.9296, acc: 0.8959, precision: 0.9480, recall: 0.9191, f1: 0.9333, edges-ner-ontonotes_loss: 0.0241
09/16 07:15:36 AM: Evaluate: task edges-ner-ontonotes, batch 73 (157): mcc: 0.9210, acc: 0.8922, precision: 0.9437, recall: 0.9074, f1: 0.9252, edges-ner-ontonotes_loss: 0.0265
09/16 07:15:44 AM: Update 24990: task edges-ner-ontonotes, batch 990 (24990): mcc: 0.9282, acc: 0.8940, precision: 0.9471, recall: 0.9174, f1: 0.9320, edges-ner-ontonotes_loss: 0.0246
09/16 07:15:46 AM: ***** Step 25000 / Validation 25 *****
09/16 07:15:46 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:15:46 AM: Validating...
09/16 07:15:48 AM: Evaluate: task edges-ner-ontonotes, batch 122 (157): mcc: 0.9327, acc: 0.9053, precision: 0.9529, recall: 0.9201, f1: 0.9362, edges-ner-ontonotes_loss: 0.0226
09/16 07:15:54 AM: Evaluate: task edges-ner-ontonotes, batch 44 (157): mcc: 0.9137, acc: 0.8875, precision: 0.9354, recall: 0.9018, f1: 0.9183, edges-ner-ontonotes_loss: 0.0287
09/16 07:15:56 AM: Updating LR scheduler:
09/16 07:15:56 AM: 	Best result seen so far for macro_avg: 0.941
09/16 07:15:56 AM: 	# validation passes without improvement: 1
09/16 07:15:56 AM: edges-ner-ontonotes_loss: training: 0.024595 validation: 0.020629
09/16 07:15:56 AM: macro_avg: validation: 0.941371
09/16 07:15:56 AM: micro_avg: validation: 0.000000
09/16 07:15:56 AM: edges-ner-ontonotes_mcc: training: 0.928166 validation: 0.938102
09/16 07:15:56 AM: edges-ner-ontonotes_acc: training: 0.893917 validation: 0.912041
09/16 07:15:56 AM: edges-ner-ontonotes_precision: training: 0.947154 validation: 0.956056
09/16 07:15:56 AM: edges-ner-ontonotes_recall: training: 0.917258 validation: 0.927131
09/16 07:15:56 AM: edges-ner-ontonotes_f1: training: 0.931966 validation: 0.941371
09/16 07:15:56 AM: Global learning rate: 0.0001
09/16 07:15:56 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:15:58 AM: Update 25015: task edges-ner-ontonotes, batch 15 (25015): mcc: 0.9150, acc: 0.8798, precision: 0.9428, recall: 0.8969, f1: 0.9193, edges-ner-ontonotes_loss: 0.0268
09/16 07:16:04 AM: Evaluate: task edges-ner-ontonotes, batch 96 (157): mcc: 0.9301, acc: 0.9023, precision: 0.9516, recall: 0.9166, f1: 0.9338, edges-ner-ontonotes_loss: 0.0239
09/16 07:16:08 AM: Update 25074: task edges-ner-ontonotes, batch 74 (25074): mcc: 0.9127, acc: 0.8720, precision: 0.9395, recall: 0.8958, f1: 0.9171, edges-ner-ontonotes_loss: 0.0278
09/16 07:16:14 AM: Evaluate: task edges-ner-ontonotes, batch 147 (157): mcc: 0.9372, acc: 0.9109, precision: 0.9556, recall: 0.9258, f1: 0.9405, edges-ner-ontonotes_loss: 0.0211
09/16 07:16:16 AM: Updating LR scheduler:
09/16 07:16:16 AM: 	Best result seen so far for macro_avg: 0.941
09/16 07:16:16 AM: 	# validation passes without improvement: 1
09/16 07:16:16 AM: edges-ner-ontonotes_loss: training: 0.024595 validation: 0.020629
09/16 07:16:16 AM: macro_avg: validation: 0.941371
09/16 07:16:16 AM: micro_avg: validation: 0.000000
09/16 07:16:16 AM: edges-ner-ontonotes_mcc: training: 0.928166 validation: 0.938102
09/16 07:16:16 AM: edges-ner-ontonotes_acc: training: 0.893917 validation: 0.912041
09/16 07:16:16 AM: edges-ner-ontonotes_precision: training: 0.947154 validation: 0.956056
09/16 07:16:16 AM: edges-ner-ontonotes_recall: training: 0.917258 validation: 0.927131
09/16 07:16:16 AM: edges-ner-ontonotes_f1: training: 0.931966 validation: 0.941371
09/16 07:16:16 AM: Global learning rate: 0.0001
09/16 07:16:16 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:16:18 AM: Update 25141: task edges-ner-ontonotes, batch 141 (25141): mcc: 0.9115, acc: 0.8701, precision: 0.9390, recall: 0.8941, f1: 0.9160, edges-ner-ontonotes_loss: 0.0282
09/16 07:16:24 AM: Update 25071: task edges-ner-ontonotes, batch 71 (25071): mcc: 0.9128, acc: 0.8726, precision: 0.9403, recall: 0.8953, f1: 0.9172, edges-ner-ontonotes_loss: 0.0277
09/16 07:16:29 AM: Update 25210: task edges-ner-ontonotes, batch 210 (25210): mcc: 0.9100, acc: 0.8692, precision: 0.9363, recall: 0.8939, f1: 0.9146, edges-ner-ontonotes_loss: 0.0287
09/16 07:16:34 AM: Update 25164: task edges-ner-ontonotes, batch 164 (25164): mcc: 0.9112, acc: 0.8708, precision: 0.9376, recall: 0.8949, f1: 0.9158, edges-ner-ontonotes_loss: 0.0287
09/16 07:16:39 AM: Update 25285: task edges-ner-ontonotes, batch 285 (25285): mcc: 0.9151, acc: 0.8761, precision: 0.9393, recall: 0.9006, f1: 0.9195, edges-ner-ontonotes_loss: 0.0276
09/16 07:16:44 AM: Update 25220: task edges-ner-ontonotes, batch 220 (25220): mcc: 0.9096, acc: 0.8687, precision: 0.9354, recall: 0.8940, f1: 0.9143, edges-ner-ontonotes_loss: 0.0287
09/16 07:16:49 AM: Update 25370: task edges-ner-ontonotes, batch 370 (25370): mcc: 0.9175, acc: 0.8798, precision: 0.9401, recall: 0.9042, f1: 0.9218, edges-ner-ontonotes_loss: 0.0267
09/16 07:16:54 AM: Update 25292: task edges-ner-ontonotes, batch 292 (25292): mcc: 0.9155, acc: 0.8766, precision: 0.9394, recall: 0.9012, f1: 0.9199, edges-ner-ontonotes_loss: 0.0276
09/16 07:16:59 AM: Update 25445: task edges-ner-ontonotes, batch 445 (25445): mcc: 0.9203, acc: 0.8832, precision: 0.9422, recall: 0.9074, f1: 0.9244, edges-ner-ontonotes_loss: 0.0259
09/16 07:17:04 AM: Update 25371: task edges-ner-ontonotes, batch 371 (25371): mcc: 0.9176, acc: 0.8801, precision: 0.9402, recall: 0.9044, f1: 0.9219, edges-ner-ontonotes_loss: 0.0266
09/16 07:17:09 AM: Update 25522: task edges-ner-ontonotes, batch 522 (25522): mcc: 0.9209, acc: 0.8844, precision: 0.9423, recall: 0.9084, f1: 0.9251, edges-ner-ontonotes_loss: 0.0257
09/16 07:17:15 AM: Update 25458: task edges-ner-ontonotes, batch 458 (25458): mcc: 0.9208, acc: 0.8839, precision: 0.9426, recall: 0.9079, f1: 0.9249, edges-ner-ontonotes_loss: 0.0258
09/16 07:17:20 AM: Update 25574: task edges-ner-ontonotes, batch 574 (25574): mcc: 0.9229, acc: 0.8867, precision: 0.9435, recall: 0.9110, f1: 0.9269, edges-ner-ontonotes_loss: 0.0252
09/16 07:17:28 AM: Update 25523: task edges-ner-ontonotes, batch 523 (25523): mcc: 0.9209, acc: 0.8844, precision: 0.9423, recall: 0.9084, f1: 0.9250, edges-ner-ontonotes_loss: 0.0257
09/16 07:17:30 AM: Update 25655: task edges-ner-ontonotes, batch 655 (25655): mcc: 0.9256, acc: 0.8903, precision: 0.9452, recall: 0.9144, f1: 0.9296, edges-ner-ontonotes_loss: 0.0243
09/16 07:17:38 AM: Update 25591: task edges-ner-ontonotes, batch 591 (25591): mcc: 0.9231, acc: 0.8870, precision: 0.9436, recall: 0.9112, f1: 0.9271, edges-ner-ontonotes_loss: 0.0251
09/16 07:17:40 AM: Update 25725: task edges-ner-ontonotes, batch 725 (25725): mcc: 0.9276, acc: 0.8929, precision: 0.9465, recall: 0.9169, f1: 0.9314, edges-ner-ontonotes_loss: 0.0236
09/16 07:17:48 AM: Update 25663: task edges-ner-ontonotes, batch 663 (25663): mcc: 0.9261, acc: 0.8909, precision: 0.9454, recall: 0.9150, f1: 0.9300, edges-ner-ontonotes_loss: 0.0241
09/16 07:17:50 AM: Update 25795: task edges-ner-ontonotes, batch 795 (25795): mcc: 0.9292, acc: 0.8950, precision: 0.9476, recall: 0.9188, f1: 0.9330, edges-ner-ontonotes_loss: 0.0231
09/16 07:17:58 AM: Update 25745: task edges-ner-ontonotes, batch 745 (25745): mcc: 0.9278, acc: 0.8932, precision: 0.9466, recall: 0.9171, f1: 0.9316, edges-ner-ontonotes_loss: 0.0236
09/16 07:18:00 AM: Update 25850: task edges-ner-ontonotes, batch 850 (25850): mcc: 0.9304, acc: 0.8963, precision: 0.9483, recall: 0.9202, f1: 0.9341, edges-ner-ontonotes_loss: 0.0228
09/16 07:18:09 AM: Update 25813: task edges-ner-ontonotes, batch 813 (25813): mcc: 0.9296, acc: 0.8954, precision: 0.9477, recall: 0.9193, f1: 0.9333, edges-ner-ontonotes_loss: 0.0230
09/16 07:18:10 AM: Update 25921: task edges-ner-ontonotes, batch 921 (25921): mcc: 0.9310, acc: 0.8972, precision: 0.9486, recall: 0.9211, f1: 0.9347, edges-ner-ontonotes_loss: 0.0225
09/16 07:18:19 AM: Update 25869: task edges-ner-ontonotes, batch 869 (25869): mcc: 0.9307, acc: 0.8968, precision: 0.9486, recall: 0.9207, f1: 0.9344, edges-ner-ontonotes_loss: 0.0227
09/16 07:18:20 AM: Update 25998: task edges-ner-ontonotes, batch 998 (25998): mcc: 0.9315, acc: 0.8978, precision: 0.9489, recall: 0.9217, f1: 0.9351, edges-ner-ontonotes_loss: 0.0223
09/16 07:18:21 AM: ***** Step 26000 / Validation 26 *****
09/16 07:18:21 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:18:21 AM: Validating...
09/16 07:18:29 AM: Update 25928: task edges-ner-ontonotes, batch 928 (25928): mcc: 0.9311, acc: 0.8973, precision: 0.9488, recall: 0.9212, f1: 0.9348, edges-ner-ontonotes_loss: 0.0225
09/16 07:18:31 AM: Evaluate: task edges-ner-ontonotes, batch 59 (157): mcc: 0.9174, acc: 0.8870, precision: 0.9397, recall: 0.9043, f1: 0.9217, edges-ner-ontonotes_loss: 0.0279
09/16 07:18:39 AM: Update 25984: task edges-ner-ontonotes, batch 984 (25984): mcc: 0.9313, acc: 0.8976, precision: 0.9489, recall: 0.9214, f1: 0.9349, edges-ner-ontonotes_loss: 0.0224
09/16 07:18:41 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9286, acc: 0.8999, precision: 0.9485, recall: 0.9168, f1: 0.9324, edges-ner-ontonotes_loss: 0.0241
09/16 07:18:42 AM: ***** Step 26000 / Validation 26 *****
09/16 07:18:42 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:18:42 AM: Validating...
09/16 07:18:49 AM: Evaluate: task edges-ner-ontonotes, batch 36 (157): mcc: 0.8958, acc: 0.8585, precision: 0.9256, recall: 0.8778, f1: 0.9011, edges-ner-ontonotes_loss: 0.0334
09/16 07:18:51 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:18:51 AM: Best result seen so far for macro.
09/16 07:18:51 AM: Updating LR scheduler:
09/16 07:18:51 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:18:51 AM: 	# validation passes without improvement: 0
09/16 07:18:51 AM: edges-ner-ontonotes_loss: training: 0.022328 validation: 0.020822
09/16 07:18:51 AM: macro_avg: validation: 0.941958
09/16 07:18:51 AM: micro_avg: validation: 0.000000
09/16 07:18:51 AM: edges-ner-ontonotes_mcc: training: 0.931555 validation: 0.938671
09/16 07:18:51 AM: edges-ner-ontonotes_acc: training: 0.897969 validation: 0.912724
09/16 07:18:51 AM: edges-ner-ontonotes_precision: training: 0.948961 validation: 0.953895
09/16 07:18:51 AM: edges-ner-ontonotes_recall: training: 0.921830 validation: 0.930315
09/16 07:18:51 AM: edges-ner-ontonotes_f1: training: 0.935198 validation: 0.941958
09/16 07:18:51 AM: Global learning rate: 0.0001
09/16 07:18:51 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:18:52 AM: Update 26003: task edges-ner-ontonotes, batch 3 (26003): mcc: 0.9641, acc: 0.9387, precision: 0.9676, recall: 0.9645, f1: 0.9661, edges-ner-ontonotes_loss: 0.0119
09/16 07:18:59 AM: Evaluate: task edges-ner-ontonotes, batch 82 (157): mcc: 0.9255, acc: 0.8951, precision: 0.9474, recall: 0.9120, f1: 0.9294, edges-ner-ontonotes_loss: 0.0261
09/16 07:19:02 AM: Update 26060: task edges-ner-ontonotes, batch 60 (26060): mcc: 0.9399, acc: 0.9093, precision: 0.9567, recall: 0.9298, f1: 0.9431, edges-ner-ontonotes_loss: 0.0186
09/16 07:19:09 AM: Evaluate: task edges-ner-ontonotes, batch 132 (157): mcc: 0.9351, acc: 0.9083, precision: 0.9526, recall: 0.9249, f1: 0.9386, edges-ner-ontonotes_loss: 0.0222
09/16 07:19:12 AM: Update 26114: task edges-ner-ontonotes, batch 114 (26114): mcc: 0.9390, acc: 0.9073, precision: 0.9547, recall: 0.9301, f1: 0.9423, edges-ner-ontonotes_loss: 0.0190
09/16 07:19:13 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:19:13 AM: Best result seen so far for macro.
09/16 07:19:13 AM: Updating LR scheduler:
09/16 07:19:13 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:19:13 AM: 	# validation passes without improvement: 0
09/16 07:19:13 AM: edges-ner-ontonotes_loss: training: 0.022328 validation: 0.020822
09/16 07:19:13 AM: macro_avg: validation: 0.941958
09/16 07:19:13 AM: micro_avg: validation: 0.000000
09/16 07:19:13 AM: edges-ner-ontonotes_mcc: training: 0.931555 validation: 0.938671
09/16 07:19:13 AM: edges-ner-ontonotes_acc: training: 0.897969 validation: 0.912724
09/16 07:19:13 AM: edges-ner-ontonotes_precision: training: 0.948961 validation: 0.953895
09/16 07:19:13 AM: edges-ner-ontonotes_recall: training: 0.921830 validation: 0.930315
09/16 07:19:13 AM: edges-ner-ontonotes_f1: training: 0.935198 validation: 0.941958
09/16 07:19:13 AM: Global learning rate: 0.0001
09/16 07:19:13 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:19:19 AM: Update 26044: task edges-ner-ontonotes, batch 44 (26044): mcc: 0.9423, acc: 0.9115, precision: 0.9587, recall: 0.9324, f1: 0.9453, edges-ner-ontonotes_loss: 0.0170
09/16 07:19:22 AM: Update 26165: task edges-ner-ontonotes, batch 165 (26165): mcc: 0.9347, acc: 0.9017, precision: 0.9529, recall: 0.9238, f1: 0.9381, edges-ner-ontonotes_loss: 0.0208
09/16 07:19:30 AM: Update 26120: task edges-ner-ontonotes, batch 120 (26120): mcc: 0.9390, acc: 0.9071, precision: 0.9551, recall: 0.9297, f1: 0.9423, edges-ner-ontonotes_loss: 0.0190
09/16 07:19:32 AM: Update 26235: task edges-ner-ontonotes, batch 235 (26235): mcc: 0.9252, acc: 0.8898, precision: 0.9454, recall: 0.9135, f1: 0.9292, edges-ner-ontonotes_loss: 0.0251
09/16 07:19:40 AM: Update 26171: task edges-ner-ontonotes, batch 171 (26171): mcc: 0.9339, acc: 0.9008, precision: 0.9523, recall: 0.9230, f1: 0.9374, edges-ner-ontonotes_loss: 0.0211
09/16 07:19:42 AM: Update 26321: task edges-ner-ontonotes, batch 321 (26321): mcc: 0.9206, acc: 0.8841, precision: 0.9424, recall: 0.9078, f1: 0.9248, edges-ner-ontonotes_loss: 0.0271
09/16 07:19:50 AM: Update 26242: task edges-ner-ontonotes, batch 242 (26242): mcc: 0.9251, acc: 0.8898, precision: 0.9454, recall: 0.9133, f1: 0.9291, edges-ner-ontonotes_loss: 0.0251
09/16 07:19:52 AM: Update 26393: task edges-ner-ontonotes, batch 393 (26393): mcc: 0.9185, acc: 0.8813, precision: 0.9414, recall: 0.9048, f1: 0.9227, edges-ner-ontonotes_loss: 0.0282
09/16 07:20:00 AM: Update 26321: task edges-ner-ontonotes, batch 321 (26321): mcc: 0.9206, acc: 0.8841, precision: 0.9424, recall: 0.9078, f1: 0.9248, edges-ner-ontonotes_loss: 0.0271
09/16 07:20:03 AM: Update 26454: task edges-ner-ontonotes, batch 454 (26454): mcc: 0.9166, acc: 0.8791, precision: 0.9399, recall: 0.9026, f1: 0.9209, edges-ner-ontonotes_loss: 0.0289
09/16 07:20:10 AM: Update 26403: task edges-ner-ontonotes, batch 403 (26403): mcc: 0.9183, acc: 0.8812, precision: 0.9412, recall: 0.9046, f1: 0.9225, edges-ner-ontonotes_loss: 0.0282
09/16 07:20:13 AM: Update 26539: task edges-ner-ontonotes, batch 539 (26539): mcc: 0.9149, acc: 0.8768, precision: 0.9389, recall: 0.9006, f1: 0.9193, edges-ner-ontonotes_loss: 0.0292
09/16 07:20:20 AM: Update 26479: task edges-ner-ontonotes, batch 479 (26479): mcc: 0.9158, acc: 0.8782, precision: 0.9393, recall: 0.9018, f1: 0.9202, edges-ner-ontonotes_loss: 0.0291
09/16 07:20:24 AM: Update 26635: task edges-ner-ontonotes, batch 635 (26635): mcc: 0.9143, acc: 0.8760, precision: 0.9387, recall: 0.8996, f1: 0.9187, edges-ner-ontonotes_loss: 0.0292
09/16 07:20:30 AM: Update 26568: task edges-ner-ontonotes, batch 568 (26568): mcc: 0.9149, acc: 0.8766, precision: 0.9390, recall: 0.9005, f1: 0.9193, edges-ner-ontonotes_loss: 0.0291
09/16 07:20:34 AM: Update 26723: task edges-ner-ontonotes, batch 723 (26723): mcc: 0.9141, acc: 0.8757, precision: 0.9385, recall: 0.8995, f1: 0.9186, edges-ner-ontonotes_loss: 0.0290
09/16 07:20:41 AM: Update 26663: task edges-ner-ontonotes, batch 663 (26663): mcc: 0.9140, acc: 0.8756, precision: 0.9383, recall: 0.8994, f1: 0.9184, edges-ner-ontonotes_loss: 0.0292
09/16 07:20:44 AM: Update 26781: task edges-ner-ontonotes, batch 781 (26781): mcc: 0.9145, acc: 0.8762, precision: 0.9388, recall: 0.8999, f1: 0.9189, edges-ner-ontonotes_loss: 0.0288
09/16 07:20:51 AM: Update 26751: task edges-ner-ontonotes, batch 751 (26751): mcc: 0.9142, acc: 0.8760, precision: 0.9386, recall: 0.8996, f1: 0.9187, edges-ner-ontonotes_loss: 0.0289
09/16 07:20:54 AM: Update 26864: task edges-ner-ontonotes, batch 864 (26864): mcc: 0.9160, acc: 0.8784, precision: 0.9396, recall: 0.9019, f1: 0.9204, edges-ner-ontonotes_loss: 0.0283
09/16 07:21:01 AM: Update 26805: task edges-ner-ontonotes, batch 805 (26805): mcc: 0.9149, acc: 0.8770, precision: 0.9390, recall: 0.9005, f1: 0.9194, edges-ner-ontonotes_loss: 0.0286
09/16 07:21:04 AM: Update 26944: task edges-ner-ontonotes, batch 944 (26944): mcc: 0.9165, acc: 0.8792, precision: 0.9396, recall: 0.9029, f1: 0.9209, edges-ner-ontonotes_loss: 0.0280
09/16 07:21:11 AM: Update 26882: task edges-ner-ontonotes, batch 882 (26882): mcc: 0.9163, acc: 0.8787, precision: 0.9398, recall: 0.9023, f1: 0.9207, edges-ner-ontonotes_loss: 0.0282
09/16 07:21:12 AM: ***** Step 27000 / Validation 27 *****
09/16 07:21:12 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:21:12 AM: Validating...
09/16 07:21:14 AM: Evaluate: task edges-ner-ontonotes, batch 15 (157): mcc: 0.8690, acc: 0.8186, precision: 0.9101, recall: 0.8431, f1: 0.8753, edges-ner-ontonotes_loss: 0.0353
09/16 07:21:21 AM: Update 26940: task edges-ner-ontonotes, batch 940 (26940): mcc: 0.9165, acc: 0.8792, precision: 0.9396, recall: 0.9029, f1: 0.9209, edges-ner-ontonotes_loss: 0.0280
09/16 07:21:25 AM: Evaluate: task edges-ner-ontonotes, batch 76 (157): mcc: 0.9260, acc: 0.8959, precision: 0.9480, recall: 0.9124, f1: 0.9299, edges-ner-ontonotes_loss: 0.0252
09/16 07:21:31 AM: Update 26994: task edges-ner-ontonotes, batch 994 (26994): mcc: 0.9176, acc: 0.8805, precision: 0.9404, recall: 0.9042, f1: 0.9219, edges-ner-ontonotes_loss: 0.0276
09/16 07:21:32 AM: ***** Step 27000 / Validation 27 *****
09/16 07:21:32 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:21:32 AM: Validating...
09/16 07:21:35 AM: Evaluate: task edges-ner-ontonotes, batch 125 (157): mcc: 0.9341, acc: 0.9059, precision: 0.9526, recall: 0.9230, f1: 0.9376, edges-ner-ontonotes_loss: 0.0220
09/16 07:21:41 AM: Evaluate: task edges-ner-ontonotes, batch 45 (157): mcc: 0.9129, acc: 0.8821, precision: 0.9336, recall: 0.9019, f1: 0.9175, edges-ner-ontonotes_loss: 0.0283
09/16 07:21:41 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:21:41 AM: Best result seen so far for macro.
09/16 07:21:41 AM: Updating LR scheduler:
09/16 07:21:41 AM: 	Best result seen so far for macro_avg: 0.943
09/16 07:21:41 AM: 	# validation passes without improvement: 0
09/16 07:21:41 AM: edges-ner-ontonotes_loss: training: 0.027584 validation: 0.020185
09/16 07:21:41 AM: macro_avg: validation: 0.942786
09/16 07:21:41 AM: micro_avg: validation: 0.000000
09/16 07:21:41 AM: edges-ner-ontonotes_mcc: training: 0.917712 validation: 0.939564
09/16 07:21:41 AM: edges-ner-ontonotes_acc: training: 0.880607 validation: 0.912875
09/16 07:21:41 AM: edges-ner-ontonotes_precision: training: 0.940416 validation: 0.955675
09/16 07:21:41 AM: edges-ner-ontonotes_recall: training: 0.904307 validation: 0.930240
09/16 07:21:41 AM: edges-ner-ontonotes_f1: training: 0.922008 validation: 0.942786
09/16 07:21:41 AM: Global learning rate: 0.0001
09/16 07:21:41 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:21:45 AM: Update 27017: task edges-ner-ontonotes, batch 17 (27017): mcc: 0.9199, acc: 0.8874, precision: 0.9384, recall: 0.9104, f1: 0.9242, edges-ner-ontonotes_loss: 0.0277
09/16 07:21:52 AM: Evaluate: task edges-ner-ontonotes, batch 99 (157): mcc: 0.9282, acc: 0.8982, precision: 0.9484, recall: 0.9161, f1: 0.9320, edges-ner-ontonotes_loss: 0.0239
09/16 07:21:55 AM: Update 27072: task edges-ner-ontonotes, batch 72 (27072): mcc: 0.9270, acc: 0.8953, precision: 0.9465, recall: 0.9158, f1: 0.9309, edges-ner-ontonotes_loss: 0.0247
09/16 07:22:01 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:22:01 AM: Best result seen so far for macro.
09/16 07:22:01 AM: Updating LR scheduler:
09/16 07:22:01 AM: 	Best result seen so far for macro_avg: 0.943
09/16 07:22:01 AM: 	# validation passes without improvement: 0
09/16 07:22:01 AM: edges-ner-ontonotes_loss: training: 0.027584 validation: 0.020185
09/16 07:22:01 AM: macro_avg: validation: 0.942786
09/16 07:22:01 AM: micro_avg: validation: 0.000000
09/16 07:22:01 AM: edges-ner-ontonotes_mcc: training: 0.917712 validation: 0.939564
09/16 07:22:01 AM: edges-ner-ontonotes_acc: training: 0.880607 validation: 0.912875
09/16 07:22:01 AM: edges-ner-ontonotes_precision: training: 0.940416 validation: 0.955675
09/16 07:22:01 AM: edges-ner-ontonotes_recall: training: 0.904307 validation: 0.930240
09/16 07:22:01 AM: edges-ner-ontonotes_f1: training: 0.922008 validation: 0.942786
09/16 07:22:01 AM: Global learning rate: 0.0001
09/16 07:22:01 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:22:02 AM: Update 27005: task edges-ner-ontonotes, batch 5 (27005): mcc: 0.9286, acc: 0.8955, precision: 0.9462, recall: 0.9189, f1: 0.9324, edges-ner-ontonotes_loss: 0.0234
09/16 07:22:07 AM: Update 27114: task edges-ner-ontonotes, batch 114 (27114): mcc: 0.9305, acc: 0.8983, precision: 0.9478, recall: 0.9210, f1: 0.9342, edges-ner-ontonotes_loss: 0.0227
09/16 07:22:14 AM: Update 27079: task edges-ner-ontonotes, batch 79 (27079): mcc: 0.9266, acc: 0.8940, precision: 0.9466, recall: 0.9149, f1: 0.9305, edges-ner-ontonotes_loss: 0.0247
09/16 07:22:18 AM: Update 27194: task edges-ner-ontonotes, batch 194 (27194): mcc: 0.9363, acc: 0.9059, precision: 0.9522, recall: 0.9275, f1: 0.9397, edges-ner-ontonotes_loss: 0.0212
09/16 07:22:24 AM: Update 27147: task edges-ner-ontonotes, batch 147 (27147): mcc: 0.9332, acc: 0.9016, precision: 0.9497, recall: 0.9243, f1: 0.9368, edges-ner-ontonotes_loss: 0.0219
09/16 07:22:28 AM: Update 27265: task edges-ner-ontonotes, batch 265 (27265): mcc: 0.9390, acc: 0.9093, precision: 0.9534, recall: 0.9315, f1: 0.9423, edges-ner-ontonotes_loss: 0.0200
09/16 07:22:34 AM: Update 27216: task edges-ner-ontonotes, batch 216 (27216): mcc: 0.9370, acc: 0.9065, precision: 0.9527, recall: 0.9283, f1: 0.9404, edges-ner-ontonotes_loss: 0.0208
09/16 07:22:38 AM: Update 27337: task edges-ner-ontonotes, batch 337 (27337): mcc: 0.9401, acc: 0.9103, precision: 0.9545, recall: 0.9324, f1: 0.9433, edges-ner-ontonotes_loss: 0.0195
09/16 07:22:44 AM: Update 27285: task edges-ner-ontonotes, batch 285 (27285): mcc: 0.9397, acc: 0.9100, precision: 0.9543, recall: 0.9319, f1: 0.9429, edges-ner-ontonotes_loss: 0.0197
09/16 07:22:48 AM: Update 27398: task edges-ner-ontonotes, batch 398 (27398): mcc: 0.9411, acc: 0.9114, precision: 0.9549, recall: 0.9338, f1: 0.9442, edges-ner-ontonotes_loss: 0.0192
09/16 07:22:56 AM: Update 27362: task edges-ner-ontonotes, batch 362 (27362): mcc: 0.9407, acc: 0.9111, precision: 0.9548, recall: 0.9332, f1: 0.9439, edges-ner-ontonotes_loss: 0.0192
09/16 07:22:58 AM: Update 27469: task edges-ner-ontonotes, batch 469 (27469): mcc: 0.9419, acc: 0.9124, precision: 0.9557, recall: 0.9346, f1: 0.9451, edges-ner-ontonotes_loss: 0.0190
09/16 07:23:06 AM: Update 27413: task edges-ner-ontonotes, batch 413 (27413): mcc: 0.9408, acc: 0.9111, precision: 0.9548, recall: 0.9335, f1: 0.9440, edges-ner-ontonotes_loss: 0.0193
09/16 07:23:08 AM: Update 27548: task edges-ner-ontonotes, batch 548 (27548): mcc: 0.9416, acc: 0.9120, precision: 0.9554, recall: 0.9344, f1: 0.9448, edges-ner-ontonotes_loss: 0.0189
09/16 07:23:16 AM: Update 27485: task edges-ner-ontonotes, batch 485 (27485): mcc: 0.9419, acc: 0.9123, precision: 0.9556, recall: 0.9347, f1: 0.9450, edges-ner-ontonotes_loss: 0.0190
09/16 07:23:19 AM: Update 27619: task edges-ner-ontonotes, batch 619 (27619): mcc: 0.9415, acc: 0.9116, precision: 0.9549, recall: 0.9345, f1: 0.9446, edges-ner-ontonotes_loss: 0.0190
09/16 07:23:26 AM: Update 27557: task edges-ner-ontonotes, batch 557 (27557): mcc: 0.9416, acc: 0.9120, precision: 0.9552, recall: 0.9345, f1: 0.9448, edges-ner-ontonotes_loss: 0.0189
09/16 07:23:29 AM: Update 27689: task edges-ner-ontonotes, batch 689 (27689): mcc: 0.9413, acc: 0.9113, precision: 0.9550, recall: 0.9342, f1: 0.9445, edges-ner-ontonotes_loss: 0.0191
09/16 07:23:36 AM: Update 27636: task edges-ner-ontonotes, batch 636 (27636): mcc: 0.9415, acc: 0.9116, precision: 0.9551, recall: 0.9345, f1: 0.9447, edges-ner-ontonotes_loss: 0.0189
09/16 07:23:39 AM: Update 27739: task edges-ner-ontonotes, batch 739 (27739): mcc: 0.9396, acc: 0.9091, precision: 0.9540, recall: 0.9320, f1: 0.9429, edges-ner-ontonotes_loss: 0.0196
09/16 07:23:48 AM: Update 27705: task edges-ner-ontonotes, batch 705 (27705): mcc: 0.9411, acc: 0.9110, precision: 0.9549, recall: 0.9338, f1: 0.9443, edges-ner-ontonotes_loss: 0.0191
09/16 07:23:49 AM: Update 27814: task edges-ner-ontonotes, batch 814 (27814): mcc: 0.9365, acc: 0.9053, precision: 0.9518, recall: 0.9284, f1: 0.9399, edges-ner-ontonotes_loss: 0.0209
09/16 07:23:59 AM: Update 27774: task edges-ner-ontonotes, batch 774 (27774): mcc: 0.9382, acc: 0.9073, precision: 0.9529, recall: 0.9303, f1: 0.9415, edges-ner-ontonotes_loss: 0.0202
09/16 07:23:59 AM: Update 27891: task edges-ner-ontonotes, batch 891 (27891): mcc: 0.9339, acc: 0.9018, precision: 0.9500, recall: 0.9251, f1: 0.9374, edges-ner-ontonotes_loss: 0.0222
09/16 07:24:09 AM: Update 27853: task edges-ner-ontonotes, batch 853 (27853): mcc: 0.9351, acc: 0.9034, precision: 0.9509, recall: 0.9266, f1: 0.9386, edges-ner-ontonotes_loss: 0.0217
09/16 07:24:09 AM: Update 27967: task edges-ner-ontonotes, batch 967 (27967): mcc: 0.9317, acc: 0.8992, precision: 0.9483, recall: 0.9227, f1: 0.9353, edges-ner-ontonotes_loss: 0.0231
09/16 07:24:14 AM: ***** Step 28000 / Validation 28 *****
09/16 07:24:14 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:24:14 AM: Validating...
09/16 07:24:19 AM: Update 27922: task edges-ner-ontonotes, batch 922 (27922): mcc: 0.9329, acc: 0.9006, precision: 0.9492, recall: 0.9241, f1: 0.9365, edges-ner-ontonotes_loss: 0.0226
09/16 07:24:19 AM: Evaluate: task edges-ner-ontonotes, batch 39 (157): mcc: 0.9099, acc: 0.8825, precision: 0.9299, recall: 0.9000, f1: 0.9147, edges-ner-ontonotes_loss: 0.0306
09/16 07:24:29 AM: Update 27978: task edges-ner-ontonotes, batch 978 (27978): mcc: 0.9315, acc: 0.8990, precision: 0.9482, recall: 0.9225, f1: 0.9352, edges-ner-ontonotes_loss: 0.0232
09/16 07:24:29 AM: Evaluate: task edges-ner-ontonotes, batch 94 (157): mcc: 0.9317, acc: 0.9037, precision: 0.9520, recall: 0.9192, f1: 0.9353, edges-ner-ontonotes_loss: 0.0240
09/16 07:24:33 AM: ***** Step 28000 / Validation 28 *****
09/16 07:24:33 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:24:33 AM: Validating...
09/16 07:24:39 AM: Evaluate: task edges-ner-ontonotes, batch 30 (157): mcc: 0.8954, acc: 0.8654, precision: 0.9202, recall: 0.8823, f1: 0.9009, edges-ner-ontonotes_loss: 0.0338
09/16 07:24:39 AM: Evaluate: task edges-ner-ontonotes, batch 136 (157): mcc: 0.9390, acc: 0.9136, precision: 0.9555, recall: 0.9292, f1: 0.9422, edges-ner-ontonotes_loss: 0.0213
09/16 07:24:44 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:24:44 AM: Best result seen so far for macro.
09/16 07:24:44 AM: Updating LR scheduler:
09/16 07:24:44 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:24:44 AM: 	# validation passes without improvement: 0
09/16 07:24:44 AM: edges-ner-ontonotes_loss: training: 0.023435 validation: 0.020481
09/16 07:24:44 AM: macro_avg: validation: 0.943815
09/16 07:24:44 AM: micro_avg: validation: 0.000000
09/16 07:24:44 AM: edges-ner-ontonotes_mcc: training: 0.930843 validation: 0.940643
09/16 07:24:44 AM: edges-ner-ontonotes_acc: training: 0.898100 validation: 0.915908
09/16 07:24:44 AM: edges-ner-ontonotes_precision: training: 0.947814 validation: 0.956190
09/16 07:24:44 AM: edges-ner-ontonotes_recall: training: 0.921622 validation: 0.931756
09/16 07:24:44 AM: edges-ner-ontonotes_f1: training: 0.934535 validation: 0.943815
09/16 07:24:44 AM: Global learning rate: 0.0001
09/16 07:24:44 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:24:49 AM: Evaluate: task edges-ner-ontonotes, batch 87 (157): mcc: 0.9313, acc: 0.9041, precision: 0.9503, recall: 0.9201, f1: 0.9350, edges-ner-ontonotes_loss: 0.0242
09/16 07:24:50 AM: Update 28017: task edges-ner-ontonotes, batch 17 (28017): mcc: 0.8965, acc: 0.8566, precision: 0.9243, recall: 0.8804, f1: 0.9018, edges-ner-ontonotes_loss: 0.0343
09/16 07:24:59 AM: Evaluate: task edges-ner-ontonotes, batch 138 (157): mcc: 0.9390, acc: 0.9139, precision: 0.9555, recall: 0.9294, f1: 0.9423, edges-ner-ontonotes_loss: 0.0212
09/16 07:25:00 AM: Update 28078: task edges-ner-ontonotes, batch 78 (28078): mcc: 0.9065, acc: 0.8648, precision: 0.9348, recall: 0.8890, f1: 0.9113, edges-ner-ontonotes_loss: 0.0305
09/16 07:25:02 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:25:02 AM: Best result seen so far for macro.
09/16 07:25:02 AM: Updating LR scheduler:
09/16 07:25:02 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:25:02 AM: 	# validation passes without improvement: 0
09/16 07:25:02 AM: edges-ner-ontonotes_loss: training: 0.023435 validation: 0.020481
09/16 07:25:02 AM: macro_avg: validation: 0.943815
09/16 07:25:02 AM: micro_avg: validation: 0.000000
09/16 07:25:02 AM: edges-ner-ontonotes_mcc: training: 0.930843 validation: 0.940643
09/16 07:25:02 AM: edges-ner-ontonotes_acc: training: 0.898100 validation: 0.915908
09/16 07:25:02 AM: edges-ner-ontonotes_precision: training: 0.947814 validation: 0.956190
09/16 07:25:02 AM: edges-ner-ontonotes_recall: training: 0.921622 validation: 0.931756
09/16 07:25:02 AM: edges-ner-ontonotes_f1: training: 0.934535 validation: 0.943815
09/16 07:25:02 AM: Global learning rate: 0.0001
09/16 07:25:02 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:25:09 AM: Update 28039: task edges-ner-ontonotes, batch 39 (28039): mcc: 0.9032, acc: 0.8610, precision: 0.9323, recall: 0.8852, f1: 0.9081, edges-ner-ontonotes_loss: 0.0308
09/16 07:25:10 AM: Update 28167: task edges-ner-ontonotes, batch 167 (28167): mcc: 0.9071, acc: 0.8658, precision: 0.9339, recall: 0.8908, f1: 0.9119, edges-ner-ontonotes_loss: 0.0304
09/16 07:25:19 AM: Update 28126: task edges-ner-ontonotes, batch 126 (28126): mcc: 0.9076, acc: 0.8661, precision: 0.9339, recall: 0.8919, f1: 0.9124, edges-ner-ontonotes_loss: 0.0302
09/16 07:25:20 AM: Update 28254: task edges-ner-ontonotes, batch 254 (28254): mcc: 0.9093, acc: 0.8682, precision: 0.9359, recall: 0.8930, f1: 0.9140, edges-ner-ontonotes_loss: 0.0297
09/16 07:25:29 AM: Update 28227: task edges-ner-ontonotes, batch 227 (28227): mcc: 0.9085, acc: 0.8672, precision: 0.9356, recall: 0.8919, f1: 0.9132, edges-ner-ontonotes_loss: 0.0300
09/16 07:25:30 AM: Update 28323: task edges-ner-ontonotes, batch 323 (28323): mcc: 0.9099, acc: 0.8692, precision: 0.9362, recall: 0.8938, f1: 0.9145, edges-ner-ontonotes_loss: 0.0294
09/16 07:25:40 AM: Update 28312: task edges-ner-ontonotes, batch 312 (28312): mcc: 0.9098, acc: 0.8690, precision: 0.9359, recall: 0.8939, f1: 0.9144, edges-ner-ontonotes_loss: 0.0294
09/16 07:25:41 AM: Update 28402: task edges-ner-ontonotes, batch 402 (28402): mcc: 0.9142, acc: 0.8747, precision: 0.9383, recall: 0.8997, f1: 0.9186, edges-ner-ontonotes_loss: 0.0283
09/16 07:25:50 AM: Update 28366: task edges-ner-ontonotes, batch 366 (28366): mcc: 0.9126, acc: 0.8726, precision: 0.9374, recall: 0.8977, f1: 0.9171, edges-ner-ontonotes_loss: 0.0288
09/16 07:25:51 AM: Update 28483: task edges-ner-ontonotes, batch 483 (28483): mcc: 0.9173, acc: 0.8789, precision: 0.9398, recall: 0.9041, f1: 0.9216, edges-ner-ontonotes_loss: 0.0274
09/16 07:26:00 AM: Update 28440: task edges-ner-ontonotes, batch 440 (28440): mcc: 0.9156, acc: 0.8766, precision: 0.9391, recall: 0.9017, f1: 0.9200, edges-ner-ontonotes_loss: 0.0279
09/16 07:26:01 AM: Update 28555: task edges-ner-ontonotes, batch 555 (28555): mcc: 0.9180, acc: 0.8801, precision: 0.9400, recall: 0.9053, f1: 0.9223, edges-ner-ontonotes_loss: 0.0271
09/16 07:26:10 AM: Update 28512: task edges-ner-ontonotes, batch 512 (28512): mcc: 0.9174, acc: 0.8791, precision: 0.9398, recall: 0.9044, f1: 0.9217, edges-ner-ontonotes_loss: 0.0274
09/16 07:26:11 AM: Update 28628: task edges-ner-ontonotes, batch 628 (28628): mcc: 0.9197, acc: 0.8825, precision: 0.9410, recall: 0.9074, f1: 0.9239, edges-ner-ontonotes_loss: 0.0265
09/16 07:26:20 AM: Update 28588: task edges-ner-ontonotes, batch 588 (28588): mcc: 0.9192, acc: 0.8816, precision: 0.9408, recall: 0.9066, f1: 0.9234, edges-ner-ontonotes_loss: 0.0267
09/16 07:26:21 AM: Update 28684: task edges-ner-ontonotes, batch 684 (28684): mcc: 0.9219, acc: 0.8854, precision: 0.9425, recall: 0.9101, f1: 0.9260, edges-ner-ontonotes_loss: 0.0259
09/16 07:26:30 AM: Update 28639: task edges-ner-ontonotes, batch 639 (28639): mcc: 0.9198, acc: 0.8826, precision: 0.9412, recall: 0.9075, f1: 0.9240, edges-ner-ontonotes_loss: 0.0264
09/16 07:26:31 AM: Update 28765: task edges-ner-ontonotes, batch 765 (28765): mcc: 0.9246, acc: 0.8889, precision: 0.9443, recall: 0.9134, f1: 0.9286, edges-ner-ontonotes_loss: 0.0250
09/16 07:26:40 AM: Update 28706: task edges-ner-ontonotes, batch 706 (28706): mcc: 0.9229, acc: 0.8866, precision: 0.9433, recall: 0.9112, f1: 0.9270, edges-ner-ontonotes_loss: 0.0256
09/16 07:26:41 AM: Update 28839: task edges-ner-ontonotes, batch 839 (28839): mcc: 0.9266, acc: 0.8915, precision: 0.9456, recall: 0.9158, f1: 0.9305, edges-ner-ontonotes_loss: 0.0243
09/16 07:26:50 AM: Update 28779: task edges-ner-ontonotes, batch 779 (28779): mcc: 0.9250, acc: 0.8893, precision: 0.9445, recall: 0.9139, f1: 0.9289, edges-ner-ontonotes_loss: 0.0249
09/16 07:26:51 AM: Update 28908: task edges-ner-ontonotes, batch 908 (28908): mcc: 0.9284, acc: 0.8940, precision: 0.9471, recall: 0.9179, f1: 0.9322, edges-ner-ontonotes_loss: 0.0238
09/16 07:27:00 AM: Update 28867: task edges-ner-ontonotes, batch 867 (28867): mcc: 0.9274, acc: 0.8927, precision: 0.9461, recall: 0.9169, f1: 0.9313, edges-ner-ontonotes_loss: 0.0241
09/16 07:27:02 AM: Update 28956: task edges-ner-ontonotes, batch 956 (28956): mcc: 0.9291, acc: 0.8948, precision: 0.9473, recall: 0.9189, f1: 0.9329, edges-ner-ontonotes_loss: 0.0235
09/16 07:27:08 AM: ***** Step 29000 / Validation 29 *****
09/16 07:27:08 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:27:08 AM: Validating...
09/16 07:27:10 AM: Update 28939: task edges-ner-ontonotes, batch 939 (28939): mcc: 0.9289, acc: 0.8946, precision: 0.9471, recall: 0.9186, f1: 0.9326, edges-ner-ontonotes_loss: 0.0236
09/16 07:27:12 AM: Evaluate: task edges-ner-ontonotes, batch 28 (157): mcc: 0.8783, acc: 0.8380, precision: 0.9149, recall: 0.8558, f1: 0.8844, edges-ner-ontonotes_loss: 0.0379
09/16 07:27:20 AM: Update 28980: task edges-ner-ontonotes, batch 980 (28980): mcc: 0.9293, acc: 0.8951, precision: 0.9474, recall: 0.9192, f1: 0.9331, edges-ner-ontonotes_loss: 0.0234
09/16 07:27:22 AM: Evaluate: task edges-ner-ontonotes, batch 89 (157): mcc: 0.9283, acc: 0.8973, precision: 0.9497, recall: 0.9149, f1: 0.9320, edges-ner-ontonotes_loss: 0.0250
09/16 07:27:24 AM: ***** Step 29000 / Validation 29 *****
09/16 07:27:24 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:27:26 AM: Validating...
09/16 07:27:31 AM: Evaluate: task edges-ner-ontonotes, batch 25 (157): mcc: 0.8657, acc: 0.8230, precision: 0.9049, recall: 0.8420, f1: 0.8723, edges-ner-ontonotes_loss: 0.0408
09/16 07:27:32 AM: Evaluate: task edges-ner-ontonotes, batch 137 (157): mcc: 0.9373, acc: 0.9107, precision: 0.9546, recall: 0.9270, f1: 0.9406, edges-ner-ontonotes_loss: 0.0216
09/16 07:27:36 AM: Updating LR scheduler:
09/16 07:27:36 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:27:36 AM: 	# validation passes without improvement: 1
09/16 07:27:36 AM: edges-ner-ontonotes_loss: training: 0.023331 validation: 0.020669
09/16 07:27:36 AM: macro_avg: validation: 0.942406
09/16 07:27:36 AM: micro_avg: validation: 0.000000
09/16 07:27:36 AM: edges-ner-ontonotes_mcc: training: 0.929510 validation: 0.939161
09/16 07:27:36 AM: edges-ner-ontonotes_acc: training: 0.895389 validation: 0.912951
09/16 07:27:36 AM: edges-ner-ontonotes_precision: training: 0.947498 validation: 0.955215
09/16 07:27:36 AM: edges-ner-ontonotes_recall: training: 0.919437 validation: 0.929936
09/16 07:27:36 AM: edges-ner-ontonotes_f1: training: 0.933256 validation: 0.942406
09/16 07:27:36 AM: Global learning rate: 0.0001
09/16 07:27:36 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:27:41 AM: Evaluate: task edges-ner-ontonotes, batch 75 (157): mcc: 0.9200, acc: 0.8869, precision: 0.9445, recall: 0.9046, f1: 0.9241, edges-ner-ontonotes_loss: 0.0273
09/16 07:27:42 AM: Update 29031: task edges-ner-ontonotes, batch 31 (29031): mcc: 0.9359, acc: 0.9013, precision: 0.9493, recall: 0.9297, f1: 0.9394, edges-ner-ontonotes_loss: 0.0195
09/16 07:27:51 AM: Evaluate: task edges-ner-ontonotes, batch 126 (157): mcc: 0.9334, acc: 0.9054, precision: 0.9520, recall: 0.9224, f1: 0.9370, edges-ner-ontonotes_loss: 0.0227
09/16 07:27:52 AM: Update 29086: task edges-ner-ontonotes, batch 86 (29086): mcc: 0.9391, acc: 0.9068, precision: 0.9547, recall: 0.9304, f1: 0.9424, edges-ner-ontonotes_loss: 0.0198
09/16 07:27:56 AM: Updating LR scheduler:
09/16 07:27:56 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:27:56 AM: 	# validation passes without improvement: 1
09/16 07:27:56 AM: edges-ner-ontonotes_loss: training: 0.023331 validation: 0.020669
09/16 07:27:56 AM: macro_avg: validation: 0.942406
09/16 07:27:56 AM: micro_avg: validation: 0.000000
09/16 07:27:56 AM: edges-ner-ontonotes_mcc: training: 0.929510 validation: 0.939161
09/16 07:27:56 AM: edges-ner-ontonotes_acc: training: 0.895389 validation: 0.912951
09/16 07:27:56 AM: edges-ner-ontonotes_precision: training: 0.947498 validation: 0.955215
09/16 07:27:56 AM: edges-ner-ontonotes_recall: training: 0.919437 validation: 0.929936
09/16 07:27:56 AM: edges-ner-ontonotes_f1: training: 0.933256 validation: 0.942406
09/16 07:27:56 AM: Global learning rate: 0.0001
09/16 07:27:56 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:28:01 AM: Update 29031: task edges-ner-ontonotes, batch 31 (29031): mcc: 0.9359, acc: 0.9013, precision: 0.9493, recall: 0.9297, f1: 0.9394, edges-ner-ontonotes_loss: 0.0195
09/16 07:28:02 AM: Update 29152: task edges-ner-ontonotes, batch 152 (29152): mcc: 0.9379, acc: 0.9063, precision: 0.9536, recall: 0.9292, f1: 0.9412, edges-ner-ontonotes_loss: 0.0198
09/16 07:28:11 AM: Update 29101: task edges-ner-ontonotes, batch 101 (29101): mcc: 0.9392, acc: 0.9071, precision: 0.9545, recall: 0.9307, f1: 0.9424, edges-ner-ontonotes_loss: 0.0197
09/16 07:28:12 AM: Update 29225: task edges-ner-ontonotes, batch 225 (29225): mcc: 0.9404, acc: 0.9100, precision: 0.9552, recall: 0.9323, f1: 0.9436, edges-ner-ontonotes_loss: 0.0193
09/16 07:28:21 AM: Update 29174: task edges-ner-ontonotes, batch 174 (29174): mcc: 0.9386, acc: 0.9073, precision: 0.9538, recall: 0.9303, f1: 0.9419, edges-ner-ontonotes_loss: 0.0197
09/16 07:28:22 AM: Update 29281: task edges-ner-ontonotes, batch 281 (29281): mcc: 0.9377, acc: 0.9063, precision: 0.9530, recall: 0.9293, f1: 0.9410, edges-ner-ontonotes_loss: 0.0200
09/16 07:28:31 AM: Update 29244: task edges-ner-ontonotes, batch 244 (29244): mcc: 0.9406, acc: 0.9099, precision: 0.9551, recall: 0.9327, f1: 0.9438, edges-ner-ontonotes_loss: 0.0193
09/16 07:28:32 AM: Update 29356: task edges-ner-ontonotes, batch 356 (29356): mcc: 0.9308, acc: 0.8974, precision: 0.9486, recall: 0.9207, f1: 0.9344, edges-ner-ontonotes_loss: 0.0230
09/16 07:28:41 AM: Update 29303: task edges-ner-ontonotes, batch 303 (29303): mcc: 0.9355, acc: 0.9036, precision: 0.9517, recall: 0.9265, f1: 0.9390, edges-ner-ontonotes_loss: 0.0211
09/16 07:28:42 AM: Update 29433: task edges-ner-ontonotes, batch 433 (29433): mcc: 0.9267, acc: 0.8926, precision: 0.9458, recall: 0.9158, f1: 0.9305, edges-ner-ontonotes_loss: 0.0250
09/16 07:28:51 AM: Update 29379: task edges-ner-ontonotes, batch 379 (29379): mcc: 0.9291, acc: 0.8952, precision: 0.9474, recall: 0.9187, f1: 0.9328, edges-ner-ontonotes_loss: 0.0237
09/16 07:28:52 AM: Update 29504: task edges-ner-ontonotes, batch 504 (29504): mcc: 0.9244, acc: 0.8896, precision: 0.9443, recall: 0.9129, f1: 0.9284, edges-ner-ontonotes_loss: 0.0259
09/16 07:29:01 AM: Update 29463: task edges-ner-ontonotes, batch 463 (29463): mcc: 0.9247, acc: 0.8899, precision: 0.9444, recall: 0.9135, f1: 0.9287, edges-ner-ontonotes_loss: 0.0258
09/16 07:29:04 AM: Update 29565: task edges-ner-ontonotes, batch 565 (29565): mcc: 0.9229, acc: 0.8878, precision: 0.9436, recall: 0.9109, f1: 0.9269, edges-ner-ontonotes_loss: 0.0268
09/16 07:29:11 AM: Update 29548: task edges-ner-ontonotes, batch 548 (29548): mcc: 0.9232, acc: 0.8882, precision: 0.9437, recall: 0.9115, f1: 0.9273, edges-ner-ontonotes_loss: 0.0265
09/16 07:29:14 AM: Update 29650: task edges-ner-ontonotes, batch 650 (29650): mcc: 0.9214, acc: 0.8860, precision: 0.9425, recall: 0.9092, f1: 0.9256, edges-ner-ontonotes_loss: 0.0271
09/16 07:29:21 AM: Update 29610: task edges-ner-ontonotes, batch 610 (29610): mcc: 0.9220, acc: 0.8867, precision: 0.9430, recall: 0.9099, f1: 0.9261, edges-ner-ontonotes_loss: 0.0271
09/16 07:29:24 AM: Update 29746: task edges-ner-ontonotes, batch 746 (29746): mcc: 0.9202, acc: 0.8841, precision: 0.9415, recall: 0.9078, f1: 0.9244, edges-ner-ontonotes_loss: 0.0275
09/16 07:29:31 AM: Update 29698: task edges-ner-ontonotes, batch 698 (29698): mcc: 0.9206, acc: 0.8848, precision: 0.9418, recall: 0.9083, f1: 0.9247, edges-ner-ontonotes_loss: 0.0275
09/16 07:29:34 AM: Update 29834: task edges-ner-ontonotes, batch 834 (29834): mcc: 0.9194, acc: 0.8830, precision: 0.9411, recall: 0.9068, f1: 0.9236, edges-ner-ontonotes_loss: 0.0277
09/16 07:29:41 AM: Update 29795: task edges-ner-ontonotes, batch 795 (29795): mcc: 0.9196, acc: 0.8833, precision: 0.9411, recall: 0.9072, f1: 0.9239, edges-ner-ontonotes_loss: 0.0276
09/16 07:29:44 AM: Update 29895: task edges-ner-ontonotes, batch 895 (29895): mcc: 0.9191, acc: 0.8824, precision: 0.9409, recall: 0.9064, f1: 0.9233, edges-ner-ontonotes_loss: 0.0276
09/16 07:29:52 AM: Update 29875: task edges-ner-ontonotes, batch 875 (29875): mcc: 0.9192, acc: 0.8826, precision: 0.9411, recall: 0.9065, f1: 0.9235, edges-ner-ontonotes_loss: 0.0276
09/16 07:29:54 AM: Update 29979: task edges-ner-ontonotes, batch 979 (29979): mcc: 0.9201, acc: 0.8836, precision: 0.9416, recall: 0.9077, f1: 0.9243, edges-ner-ontonotes_loss: 0.0272
09/16 07:29:57 AM: ***** Step 30000 / Validation 30 *****
09/16 07:29:57 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:30:00 AM: Validating...
09/16 07:30:02 AM: Update 29939: task edges-ner-ontonotes, batch 939 (29939): mcc: 0.9196, acc: 0.8830, precision: 0.9413, recall: 0.9069, f1: 0.9238, edges-ner-ontonotes_loss: 0.0274
09/16 07:30:04 AM: Evaluate: task edges-ner-ontonotes, batch 25 (157): mcc: 0.8820, acc: 0.8439, precision: 0.9192, recall: 0.8584, f1: 0.8878, edges-ner-ontonotes_loss: 0.0366
09/16 07:30:12 AM: Update 29994: task edges-ner-ontonotes, batch 994 (29994): mcc: 0.9202, acc: 0.8838, precision: 0.9415, recall: 0.9079, f1: 0.9244, edges-ner-ontonotes_loss: 0.0272
09/16 07:30:13 AM: ***** Step 30000 / Validation 30 *****
09/16 07:30:13 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:30:13 AM: Validating...
09/16 07:30:15 AM: Evaluate: task edges-ner-ontonotes, batch 83 (157): mcc: 0.9305, acc: 0.9004, precision: 0.9551, recall: 0.9139, f1: 0.9340, edges-ner-ontonotes_loss: 0.0240
09/16 07:30:22 AM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.9194, acc: 0.8891, precision: 0.9439, recall: 0.9040, f1: 0.9235, edges-ner-ontonotes_loss: 0.0265
09/16 07:30:27 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9309, acc: 0.9010, precision: 0.9544, recall: 0.9152, f1: 0.9344, edges-ner-ontonotes_loss: 0.0228
09/16 07:30:32 AM: Evaluate: task edges-ner-ontonotes, batch 107 (157): mcc: 0.9302, acc: 0.9008, precision: 0.9533, recall: 0.9151, f1: 0.9338, edges-ner-ontonotes_loss: 0.0232
09/16 07:30:37 AM: Updating LR scheduler:
09/16 07:30:37 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:30:37 AM: 	# validation passes without improvement: 2
09/16 07:30:37 AM: edges-ner-ontonotes_loss: training: 0.027114 validation: 0.020081
09/16 07:30:37 AM: macro_avg: validation: 0.943024
09/16 07:30:37 AM: micro_avg: validation: 0.000000
09/16 07:30:37 AM: edges-ner-ontonotes_mcc: training: 0.920311 validation: 0.939895
09/16 07:30:37 AM: edges-ner-ontonotes_acc: training: 0.883914 validation: 0.913179
09/16 07:30:37 AM: edges-ner-ontonotes_precision: training: 0.941574 validation: 0.959796
09/16 07:30:37 AM: edges-ner-ontonotes_recall: training: 0.908030 validation: 0.926827
09/16 07:30:37 AM: edges-ner-ontonotes_f1: training: 0.924498 validation: 0.943024
09/16 07:30:37 AM: Global learning rate: 0.0001
09/16 07:30:37 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:30:38 AM: Update 30001: task edges-ner-ontonotes, batch 1 (30001): mcc: 0.9636, acc: 0.9432, precision: 0.9767, recall: 0.9545, f1: 0.9655, edges-ner-ontonotes_loss: 0.0146
09/16 07:30:42 AM: Evaluate: task edges-ner-ontonotes, batch 152 (157): mcc: 0.9393, acc: 0.9124, precision: 0.9595, recall: 0.9259, f1: 0.9424, edges-ner-ontonotes_loss: 0.0204
09/16 07:30:43 AM: Updating LR scheduler:
09/16 07:30:43 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:30:43 AM: 	# validation passes without improvement: 2
09/16 07:30:43 AM: edges-ner-ontonotes_loss: training: 0.027114 validation: 0.020081
09/16 07:30:43 AM: macro_avg: validation: 0.943024
09/16 07:30:43 AM: micro_avg: validation: 0.000000
09/16 07:30:43 AM: edges-ner-ontonotes_mcc: training: 0.920311 validation: 0.939895
09/16 07:30:43 AM: edges-ner-ontonotes_acc: training: 0.883914 validation: 0.913179
09/16 07:30:43 AM: edges-ner-ontonotes_precision: training: 0.941574 validation: 0.959796
09/16 07:30:43 AM: edges-ner-ontonotes_recall: training: 0.908030 validation: 0.926827
09/16 07:30:43 AM: edges-ner-ontonotes_f1: training: 0.924498 validation: 0.943024
09/16 07:30:43 AM: Global learning rate: 0.0001
09/16 07:30:43 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:30:48 AM: Update 30076: task edges-ner-ontonotes, batch 76 (30076): mcc: 0.9303, acc: 0.8986, precision: 0.9452, recall: 0.9232, f1: 0.9341, edges-ner-ontonotes_loss: 0.0232
09/16 07:30:52 AM: Update 30058: task edges-ner-ontonotes, batch 58 (30058): mcc: 0.9302, acc: 0.8981, precision: 0.9450, recall: 0.9232, f1: 0.9340, edges-ner-ontonotes_loss: 0.0232
09/16 07:30:58 AM: Update 30151: task edges-ner-ontonotes, batch 151 (30151): mcc: 0.9270, acc: 0.8948, precision: 0.9448, recall: 0.9173, f1: 0.9309, edges-ner-ontonotes_loss: 0.0236
09/16 07:31:02 AM: Update 30133: task edges-ner-ontonotes, batch 133 (30133): mcc: 0.9274, acc: 0.8957, precision: 0.9453, recall: 0.9177, f1: 0.9313, edges-ner-ontonotes_loss: 0.0235
09/16 07:31:08 AM: Update 30199: task edges-ner-ontonotes, batch 199 (30199): mcc: 0.9273, acc: 0.8941, precision: 0.9450, recall: 0.9177, f1: 0.9311, edges-ner-ontonotes_loss: 0.0232
09/16 07:31:12 AM: Update 30191: task edges-ner-ontonotes, batch 191 (30191): mcc: 0.9268, acc: 0.8939, precision: 0.9439, recall: 0.9178, f1: 0.9307, edges-ner-ontonotes_loss: 0.0234
09/16 07:31:18 AM: Update 30282: task edges-ner-ontonotes, batch 282 (30282): mcc: 0.9326, acc: 0.9006, precision: 0.9487, recall: 0.9240, f1: 0.9362, edges-ner-ontonotes_loss: 0.0216
09/16 07:31:22 AM: Update 30268: task edges-ner-ontonotes, batch 268 (30268): mcc: 0.9319, acc: 0.9000, precision: 0.9479, recall: 0.9235, f1: 0.9355, edges-ner-ontonotes_loss: 0.0218
09/16 07:31:29 AM: Update 30354: task edges-ner-ontonotes, batch 354 (30354): mcc: 0.9347, acc: 0.9032, precision: 0.9505, recall: 0.9263, f1: 0.9382, edges-ner-ontonotes_loss: 0.0210
09/16 07:31:32 AM: Update 30335: task edges-ner-ontonotes, batch 335 (30335): mcc: 0.9346, acc: 0.9033, precision: 0.9508, recall: 0.9258, f1: 0.9381, edges-ner-ontonotes_loss: 0.0211
09/16 07:31:39 AM: Update 30423: task edges-ner-ontonotes, batch 423 (30423): mcc: 0.9369, acc: 0.9061, precision: 0.9524, recall: 0.9284, f1: 0.9402, edges-ner-ontonotes_loss: 0.0203
09/16 07:31:42 AM: Update 30405: task edges-ner-ontonotes, batch 405 (30405): mcc: 0.9365, acc: 0.9054, precision: 0.9522, recall: 0.9279, f1: 0.9399, edges-ner-ontonotes_loss: 0.0204
09/16 07:31:49 AM: Update 30495: task edges-ner-ontonotes, batch 495 (30495): mcc: 0.9381, acc: 0.9076, precision: 0.9536, recall: 0.9296, f1: 0.9414, edges-ner-ontonotes_loss: 0.0200
09/16 07:31:52 AM: Update 30480: task edges-ner-ontonotes, batch 480 (30480): mcc: 0.9379, acc: 0.9073, precision: 0.9534, recall: 0.9295, f1: 0.9413, edges-ner-ontonotes_loss: 0.0200
09/16 07:31:59 AM: Update 30557: task edges-ner-ontonotes, batch 557 (30557): mcc: 0.9381, acc: 0.9074, precision: 0.9534, recall: 0.9296, f1: 0.9414, edges-ner-ontonotes_loss: 0.0200
09/16 07:32:03 AM: Update 30537: task edges-ner-ontonotes, batch 537 (30537): mcc: 0.9380, acc: 0.9072, precision: 0.9535, recall: 0.9294, f1: 0.9413, edges-ner-ontonotes_loss: 0.0200
09/16 07:32:09 AM: Update 30638: task edges-ner-ontonotes, batch 638 (30638): mcc: 0.9380, acc: 0.9073, precision: 0.9534, recall: 0.9296, f1: 0.9413, edges-ner-ontonotes_loss: 0.0199
09/16 07:32:14 AM: Update 30603: task edges-ner-ontonotes, batch 603 (30603): mcc: 0.9383, acc: 0.9079, precision: 0.9536, recall: 0.9300, f1: 0.9416, edges-ner-ontonotes_loss: 0.0199
09/16 07:32:19 AM: Update 30711: task edges-ner-ontonotes, batch 711 (30711): mcc: 0.9385, acc: 0.9080, precision: 0.9535, recall: 0.9304, f1: 0.9418, edges-ner-ontonotes_loss: 0.0198
09/16 07:32:25 AM: Update 30674: task edges-ner-ontonotes, batch 674 (30674): mcc: 0.9385, acc: 0.9080, precision: 0.9536, recall: 0.9303, f1: 0.9418, edges-ner-ontonotes_loss: 0.0198
09/16 07:32:30 AM: Update 30791: task edges-ner-ontonotes, batch 791 (30791): mcc: 0.9386, acc: 0.9081, precision: 0.9536, recall: 0.9306, f1: 0.9419, edges-ner-ontonotes_loss: 0.0197
09/16 07:32:37 AM: Update 30759: task edges-ner-ontonotes, batch 759 (30759): mcc: 0.9386, acc: 0.9082, precision: 0.9535, recall: 0.9306, f1: 0.9419, edges-ner-ontonotes_loss: 0.0197
09/16 07:32:40 AM: Update 30837: task edges-ner-ontonotes, batch 837 (30837): mcc: 0.9377, acc: 0.9067, precision: 0.9530, recall: 0.9293, f1: 0.9410, edges-ner-ontonotes_loss: 0.0200
09/16 07:32:48 AM: Update 30817: task edges-ner-ontonotes, batch 817 (30817): mcc: 0.9387, acc: 0.9080, precision: 0.9535, recall: 0.9307, f1: 0.9420, edges-ner-ontonotes_loss: 0.0196
09/16 07:32:50 AM: Update 30920: task edges-ner-ontonotes, batch 920 (30920): mcc: 0.9351, acc: 0.9035, precision: 0.9514, recall: 0.9261, f1: 0.9386, edges-ner-ontonotes_loss: 0.0213
09/16 07:32:58 AM: Update 30884: task edges-ner-ontonotes, batch 884 (30884): mcc: 0.9363, acc: 0.9048, precision: 0.9521, recall: 0.9275, f1: 0.9397, edges-ner-ontonotes_loss: 0.0206
09/16 07:33:00 AM: Update 30993: task edges-ner-ontonotes, batch 993 (30993): mcc: 0.9335, acc: 0.9015, precision: 0.9504, recall: 0.9240, f1: 0.9370, edges-ner-ontonotes_loss: 0.0220
09/16 07:33:01 AM: ***** Step 31000 / Validation 31 *****
09/16 07:33:01 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:33:01 AM: Validating...
09/16 07:33:08 AM: Update 30949: task edges-ner-ontonotes, batch 949 (30949): mcc: 0.9343, acc: 0.9023, precision: 0.9509, recall: 0.9250, f1: 0.9378, edges-ner-ontonotes_loss: 0.0217
09/16 07:33:10 AM: Evaluate: task edges-ner-ontonotes, batch 60 (157): mcc: 0.9238, acc: 0.8965, precision: 0.9445, recall: 0.9117, f1: 0.9278, edges-ner-ontonotes_loss: 0.0264
09/16 07:33:16 AM: ***** Step 31000 / Validation 31 *****
09/16 07:33:16 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:33:16 AM: Validating...
09/16 07:33:18 AM: Evaluate: task edges-ner-ontonotes, batch 10 (157): mcc: 0.8588, acc: 0.8152, precision: 0.9051, recall: 0.8292, f1: 0.8655, edges-ner-ontonotes_loss: 0.0387
09/16 07:33:22 AM: Evaluate: task edges-ner-ontonotes, batch 110 (157): mcc: 0.9319, acc: 0.9041, precision: 0.9525, recall: 0.9189, f1: 0.9354, edges-ner-ontonotes_loss: 0.0235
09/16 07:33:28 AM: Evaluate: task edges-ner-ontonotes, batch 69 (157): mcc: 0.9226, acc: 0.8928, precision: 0.9466, recall: 0.9074, f1: 0.9266, edges-ner-ontonotes_loss: 0.0269
09/16 07:33:33 AM: Evaluate: task edges-ner-ontonotes, batch 138 (157): mcc: 0.9392, acc: 0.9133, precision: 0.9578, recall: 0.9274, f1: 0.9424, edges-ner-ontonotes_loss: 0.0212
09/16 07:33:37 AM: Updating LR scheduler:
09/16 07:33:37 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:33:37 AM: 	# validation passes without improvement: 3
09/16 07:33:37 AM: edges-ner-ontonotes_loss: training: 0.022117 validation: 0.020462
09/16 07:33:37 AM: macro_avg: validation: 0.943585
09/16 07:33:37 AM: micro_avg: validation: 0.000000
09/16 07:33:37 AM: edges-ner-ontonotes_mcc: training: 0.933332 validation: 0.940438
09/16 07:33:37 AM: edges-ner-ontonotes_acc: training: 0.901317 validation: 0.914544
09/16 07:33:37 AM: edges-ner-ontonotes_precision: training: 0.950302 validation: 0.957962
09/16 07:33:37 AM: edges-ner-ontonotes_recall: training: 0.923842 validation: 0.929633
09/16 07:33:37 AM: edges-ner-ontonotes_f1: training: 0.936885 validation: 0.943585
09/16 07:33:37 AM: Global learning rate: 0.0001
09/16 07:33:37 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:33:39 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9320, acc: 0.9036, precision: 0.9533, recall: 0.9185, f1: 0.9355, edges-ner-ontonotes_loss: 0.0233
09/16 07:33:44 AM: Update 31037: task edges-ner-ontonotes, batch 37 (31037): mcc: 0.9034, acc: 0.8621, precision: 0.9351, recall: 0.8828, f1: 0.9082, edges-ner-ontonotes_loss: 0.0349
09/16 07:33:46 AM: Updating LR scheduler:
09/16 07:33:46 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:33:46 AM: 	# validation passes without improvement: 3
09/16 07:33:46 AM: edges-ner-ontonotes_loss: training: 0.022117 validation: 0.020462
09/16 07:33:46 AM: macro_avg: validation: 0.943585
09/16 07:33:46 AM: micro_avg: validation: 0.000000
09/16 07:33:46 AM: edges-ner-ontonotes_mcc: training: 0.933332 validation: 0.940438
09/16 07:33:46 AM: edges-ner-ontonotes_acc: training: 0.901317 validation: 0.914544
09/16 07:33:46 AM: edges-ner-ontonotes_precision: training: 0.950302 validation: 0.957962
09/16 07:33:46 AM: edges-ner-ontonotes_recall: training: 0.923842 validation: 0.929633
09/16 07:33:46 AM: edges-ner-ontonotes_f1: training: 0.936885 validation: 0.943585
09/16 07:33:46 AM: Global learning rate: 0.0001
09/16 07:33:46 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:33:50 AM: Update 31001: task edges-ner-ontonotes, batch 1 (31001): mcc: 0.9298, acc: 0.9130, precision: 0.9545, recall: 0.9130, f1: 0.9333, edges-ner-ontonotes_loss: 0.0291
09/16 07:33:57 AM: Update 31121: task edges-ner-ontonotes, batch 121 (31121): mcc: 0.9023, acc: 0.8629, precision: 0.9302, recall: 0.8855, f1: 0.9073, edges-ner-ontonotes_loss: 0.0349
09/16 07:34:00 AM: Update 31085: task edges-ner-ontonotes, batch 85 (31085): mcc: 0.9038, acc: 0.8644, precision: 0.9326, recall: 0.8859, f1: 0.9087, edges-ner-ontonotes_loss: 0.0349
09/16 07:34:07 AM: Update 31217: task edges-ner-ontonotes, batch 217 (31217): mcc: 0.9032, acc: 0.8633, precision: 0.9316, recall: 0.8858, f1: 0.9081, edges-ner-ontonotes_loss: 0.0329
09/16 07:34:10 AM: Update 31147: task edges-ner-ontonotes, batch 147 (31147): mcc: 0.9031, acc: 0.8643, precision: 0.9308, recall: 0.8865, f1: 0.9081, edges-ner-ontonotes_loss: 0.0339
09/16 07:34:17 AM: Update 31316: task edges-ner-ontonotes, batch 316 (31316): mcc: 0.9071, acc: 0.8669, precision: 0.9349, recall: 0.8899, f1: 0.9118, edges-ner-ontonotes_loss: 0.0314
09/16 07:34:22 AM: Update 31242: task edges-ner-ontonotes, batch 242 (31242): mcc: 0.9038, acc: 0.8634, precision: 0.9321, recall: 0.8865, f1: 0.9087, edges-ner-ontonotes_loss: 0.0328
09/16 07:34:29 AM: Update 31403: task edges-ner-ontonotes, batch 403 (31403): mcc: 0.9093, acc: 0.8697, precision: 0.9366, recall: 0.8924, f1: 0.9140, edges-ner-ontonotes_loss: 0.0305
09/16 07:34:32 AM: Update 31338: task edges-ner-ontonotes, batch 338 (31338): mcc: 0.9078, acc: 0.8678, precision: 0.9350, recall: 0.8912, f1: 0.9126, edges-ner-ontonotes_loss: 0.0310
09/16 07:34:40 AM: Update 31460: task edges-ner-ontonotes, batch 460 (31460): mcc: 0.9110, acc: 0.8713, precision: 0.9375, recall: 0.8946, f1: 0.9156, edges-ner-ontonotes_loss: 0.0299
09/16 07:34:42 AM: Update 31427: task edges-ner-ontonotes, batch 427 (31427): mcc: 0.9100, acc: 0.8702, precision: 0.9371, recall: 0.8931, f1: 0.9146, edges-ner-ontonotes_loss: 0.0303
09/16 07:34:50 AM: Update 31543: task edges-ner-ontonotes, batch 543 (31543): mcc: 0.9138, acc: 0.8752, precision: 0.9387, recall: 0.8987, f1: 0.9183, edges-ner-ontonotes_loss: 0.0289
09/16 07:34:52 AM: Update 31484: task edges-ner-ontonotes, batch 484 (31484): mcc: 0.9122, acc: 0.8730, precision: 0.9380, recall: 0.8963, f1: 0.9167, edges-ner-ontonotes_loss: 0.0295
09/16 07:35:00 AM: Update 31617: task edges-ner-ontonotes, batch 617 (31617): mcc: 0.9163, acc: 0.8786, precision: 0.9403, recall: 0.9018, f1: 0.9206, edges-ner-ontonotes_loss: 0.0281
09/16 07:35:02 AM: Update 31560: task edges-ner-ontonotes, batch 560 (31560): mcc: 0.9145, acc: 0.8761, precision: 0.9392, recall: 0.8995, f1: 0.9189, edges-ner-ontonotes_loss: 0.0287
09/16 07:35:10 AM: Update 31691: task edges-ner-ontonotes, batch 691 (31691): mcc: 0.9180, acc: 0.8810, precision: 0.9412, recall: 0.9042, f1: 0.9223, edges-ner-ontonotes_loss: 0.0275
09/16 07:35:12 AM: Update 31633: task edges-ner-ontonotes, batch 633 (31633): mcc: 0.9163, acc: 0.8787, precision: 0.9403, recall: 0.9018, f1: 0.9206, edges-ner-ontonotes_loss: 0.0281
09/16 07:35:21 AM: Update 31747: task edges-ner-ontonotes, batch 747 (31747): mcc: 0.9189, acc: 0.8822, precision: 0.9415, recall: 0.9054, f1: 0.9231, edges-ner-ontonotes_loss: 0.0273
09/16 07:35:22 AM: Update 31714: task edges-ner-ontonotes, batch 714 (31714): mcc: 0.9183, acc: 0.8816, precision: 0.9413, recall: 0.9046, f1: 0.9226, edges-ner-ontonotes_loss: 0.0274
09/16 07:35:31 AM: Update 31826: task edges-ner-ontonotes, batch 826 (31826): mcc: 0.9217, acc: 0.8857, precision: 0.9433, recall: 0.9089, f1: 0.9258, edges-ner-ontonotes_loss: 0.0264
09/16 07:35:33 AM: Update 31771: task edges-ner-ontonotes, batch 771 (31771): mcc: 0.9196, acc: 0.8830, precision: 0.9419, recall: 0.9065, f1: 0.9238, edges-ner-ontonotes_loss: 0.0271
09/16 07:35:41 AM: Update 31896: task edges-ner-ontonotes, batch 896 (31896): mcc: 0.9240, acc: 0.8889, precision: 0.9448, recall: 0.9117, f1: 0.9279, edges-ner-ontonotes_loss: 0.0257
09/16 07:35:43 AM: Update 31839: task edges-ner-ontonotes, batch 839 (31839): mcc: 0.9223, acc: 0.8865, precision: 0.9437, recall: 0.9096, f1: 0.9264, edges-ner-ontonotes_loss: 0.0262
09/16 07:35:51 AM: Update 31969: task edges-ner-ontonotes, batch 969 (31969): mcc: 0.9261, acc: 0.8916, precision: 0.9463, recall: 0.9141, f1: 0.9299, edges-ner-ontonotes_loss: 0.0250
09/16 07:35:53 AM: Update 31911: task edges-ner-ontonotes, batch 911 (31911): mcc: 0.9244, acc: 0.8895, precision: 0.9451, recall: 0.9123, f1: 0.9284, edges-ner-ontonotes_loss: 0.0256
09/16 07:35:55 AM: ***** Step 32000 / Validation 32 *****
09/16 07:35:55 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:35:55 AM: Validating...
09/16 07:36:02 AM: Evaluate: task edges-ner-ontonotes, batch 40 (157): mcc: 0.9011, acc: 0.8657, precision: 0.9335, recall: 0.8800, f1: 0.9060, edges-ner-ontonotes_loss: 0.0329
09/16 07:36:03 AM: Update 31970: task edges-ner-ontonotes, batch 970 (31970): mcc: 0.9261, acc: 0.8917, precision: 0.9464, recall: 0.9142, f1: 0.9300, edges-ner-ontonotes_loss: 0.0250
09/16 07:36:09 AM: ***** Step 32000 / Validation 32 *****
09/16 07:36:09 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:36:09 AM: Validating...
09/16 07:36:12 AM: Evaluate: task edges-ner-ontonotes, batch 92 (157): mcc: 0.9275, acc: 0.8960, precision: 0.9524, recall: 0.9109, f1: 0.9312, edges-ner-ontonotes_loss: 0.0254
09/16 07:36:13 AM: Evaluate: task edges-ner-ontonotes, batch 23 (157): mcc: 0.8655, acc: 0.8217, precision: 0.9110, recall: 0.8359, f1: 0.8719, edges-ner-ontonotes_loss: 0.0417
09/16 07:36:22 AM: Evaluate: task edges-ner-ontonotes, batch 131 (157): mcc: 0.9351, acc: 0.9069, precision: 0.9561, recall: 0.9214, f1: 0.9384, edges-ner-ontonotes_loss: 0.0224
09/16 07:36:23 AM: Evaluate: task edges-ner-ontonotes, batch 67 (157): mcc: 0.9177, acc: 0.8838, precision: 0.9461, recall: 0.8988, f1: 0.9219, edges-ner-ontonotes_loss: 0.0284
09/16 07:36:28 AM: Updating LR scheduler:
09/16 07:36:28 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:36:28 AM: 	# validation passes without improvement: 0
09/16 07:36:28 AM: edges-ner-ontonotes_loss: training: 0.024793 validation: 0.020821
09/16 07:36:28 AM: macro_avg: validation: 0.942432
09/16 07:36:28 AM: micro_avg: validation: 0.000000
09/16 07:36:28 AM: edges-ner-ontonotes_mcc: training: 0.926633 validation: 0.939245
09/16 07:36:28 AM: edges-ner-ontonotes_acc: training: 0.892362 validation: 0.912572
09/16 07:36:28 AM: edges-ner-ontonotes_precision: training: 0.946612 validation: 0.958085
09/16 07:36:28 AM: edges-ner-ontonotes_recall: training: 0.914922 validation: 0.927282
09/16 07:36:28 AM: edges-ner-ontonotes_f1: training: 0.930498 validation: 0.942432
09/16 07:36:28 AM: Global learning rate: 5e-05
09/16 07:36:28 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:36:32 AM: Update 32026: task edges-ner-ontonotes, batch 26 (32026): mcc: 0.9418, acc: 0.9126, precision: 0.9587, recall: 0.9314, f1: 0.9449, edges-ner-ontonotes_loss: 0.0176
09/16 07:36:34 AM: Evaluate: task edges-ner-ontonotes, batch 112 (157): mcc: 0.9297, acc: 0.9005, precision: 0.9520, recall: 0.9155, f1: 0.9334, edges-ner-ontonotes_loss: 0.0240
09/16 07:36:42 AM: Updating LR scheduler:
09/16 07:36:42 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:36:42 AM: 	# validation passes without improvement: 0
09/16 07:36:42 AM: edges-ner-ontonotes_loss: training: 0.024793 validation: 0.020821
09/16 07:36:42 AM: macro_avg: validation: 0.942432
09/16 07:36:42 AM: micro_avg: validation: 0.000000
09/16 07:36:42 AM: edges-ner-ontonotes_mcc: training: 0.926633 validation: 0.939245
09/16 07:36:42 AM: edges-ner-ontonotes_acc: training: 0.892362 validation: 0.912572
09/16 07:36:42 AM: edges-ner-ontonotes_precision: training: 0.946612 validation: 0.958085
09/16 07:36:42 AM: edges-ner-ontonotes_recall: training: 0.914922 validation: 0.927282
09/16 07:36:42 AM: edges-ner-ontonotes_f1: training: 0.930498 validation: 0.942432
09/16 07:36:42 AM: Global learning rate: 5e-05
09/16 07:36:42 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-top/run
09/16 07:36:42 AM: Update 32064: task edges-ner-ontonotes, batch 64 (32064): mcc: 0.9411, acc: 0.9125, precision: 0.9560, recall: 0.9328, f1: 0.9442, edges-ner-ontonotes_loss: 0.0184
09/16 07:36:44 AM: Update 32006: task edges-ner-ontonotes, batch 6 (32006): mcc: 0.9374, acc: 0.9112, precision: 0.9516, recall: 0.9301, f1: 0.9407, edges-ner-ontonotes_loss: 0.0190
09/16 07:36:52 AM: Update 32139: task edges-ner-ontonotes, batch 139 (32139): mcc: 0.9391, acc: 0.9090, precision: 0.9539, recall: 0.9311, f1: 0.9424, edges-ner-ontonotes_loss: 0.0195
09/16 07:36:55 AM: Update 32060: task edges-ner-ontonotes, batch 60 (32060): mcc: 0.9413, acc: 0.9124, precision: 0.9569, recall: 0.9324, f1: 0.9444, edges-ner-ontonotes_loss: 0.0184
09/16 07:37:02 AM: Update 32215: task edges-ner-ontonotes, batch 215 (32215): mcc: 0.9402, acc: 0.9103, precision: 0.9546, recall: 0.9325, f1: 0.9434, edges-ner-ontonotes_loss: 0.0190
09/16 07:37:05 AM: Update 32132: task edges-ner-ontonotes, batch 132 (32132): mcc: 0.9389, acc: 0.9087, precision: 0.9533, recall: 0.9312, f1: 0.9422, edges-ner-ontonotes_loss: 0.0196
09/16 07:37:12 AM: Update 32286: task edges-ner-ontonotes, batch 286 (32286): mcc: 0.9404, acc: 0.9110, precision: 0.9548, recall: 0.9327, f1: 0.9436, edges-ner-ontonotes_loss: 0.0192
09/16 07:37:15 AM: Update 32197: task edges-ner-ontonotes, batch 197 (32197): mcc: 0.9400, acc: 0.9102, precision: 0.9541, recall: 0.9326, f1: 0.9432, edges-ner-ontonotes_loss: 0.0190
09/16 07:37:22 AM: Update 32358: task edges-ner-ontonotes, batch 358 (32358): mcc: 0.9406, acc: 0.9110, precision: 0.9544, recall: 0.9334, f1: 0.9438, edges-ner-ontonotes_loss: 0.0191
09/16 07:37:25 AM: Update 32272: task edges-ner-ontonotes, batch 272 (32272): mcc: 0.9403, acc: 0.9108, precision: 0.9547, recall: 0.9326, f1: 0.9435, edges-ner-ontonotes_loss: 0.0192
09/16 07:37:32 AM: Update 32415: task edges-ner-ontonotes, batch 415 (32415): mcc: 0.9366, acc: 0.9054, precision: 0.9523, recall: 0.9281, f1: 0.9400, edges-ner-ontonotes_loss: 0.0206
09/16 07:37:35 AM: Update 32347: task edges-ner-ontonotes, batch 347 (32347): mcc: 0.9404, acc: 0.9108, precision: 0.9542, recall: 0.9332, f1: 0.9436, edges-ner-ontonotes_loss: 0.0191
09/16 07:37:42 AM: Update 32492: task edges-ner-ontonotes, batch 492 (32492): mcc: 0.9326, acc: 0.8998, precision: 0.9498, recall: 0.9229, f1: 0.9361, edges-ner-ontonotes_loss: 0.0224
09/16 07:37:45 AM: Update 32405: task edges-ner-ontonotes, batch 405 (32405): mcc: 0.9372, acc: 0.9063, precision: 0.9526, recall: 0.9289, f1: 0.9406, edges-ner-ontonotes_loss: 0.0203
09/16 07:37:53 AM: Update 32567: task edges-ner-ontonotes, batch 567 (32567): mcc: 0.9292, acc: 0.8954, precision: 0.9479, recall: 0.9185, f1: 0.9330, edges-ner-ontonotes_loss: 0.0241
09/16 07:37:55 AM: Update 32479: task edges-ner-ontonotes, batch 479 (32479): mcc: 0.9333, acc: 0.9007, precision: 0.9502, recall: 0.9238, f1: 0.9368, edges-ner-ontonotes_loss: 0.0221
09/16 07:38:03 AM: Update 32640: task edges-ner-ontonotes, batch 640 (32640): mcc: 0.9274, acc: 0.8929, precision: 0.9469, recall: 0.9161, f1: 0.9312, edges-ner-ontonotes_loss: 0.0250
09/16 07:38:06 AM: Update 32553: task edges-ner-ontonotes, batch 553 (32553): mcc: 0.9298, acc: 0.8961, precision: 0.9482, recall: 0.9193, f1: 0.9335, edges-ner-ontonotes_loss: 0.0239
09/16 07:38:13 AM: Update 32699: task edges-ner-ontonotes, batch 699 (32699): mcc: 0.9255, acc: 0.8906, precision: 0.9455, recall: 0.9139, f1: 0.9294, edges-ner-ontonotes_loss: 0.0257
09/16 07:38:16 AM: Update 32637: task edges-ner-ontonotes, batch 637 (32637): mcc: 0.9274, acc: 0.8929, precision: 0.9469, recall: 0.9161, f1: 0.9312, edges-ner-ontonotes_loss: 0.0250
09/16 07:38:23 AM: Update 32789: task edges-ner-ontonotes, batch 789 (32789): mcc: 0.9249, acc: 0.8898, precision: 0.9452, recall: 0.9130, f1: 0.9288, edges-ner-ontonotes_loss: 0.0257
09/16 07:38:26 AM: Update 32695: task edges-ner-ontonotes, batch 695 (32695): mcc: 0.9255, acc: 0.8906, precision: 0.9455, recall: 0.9139, f1: 0.9294, edges-ner-ontonotes_loss: 0.0257
09/16 07:38:33 AM: Update 32879: task edges-ner-ontonotes, batch 879 (32879): mcc: 0.9238, acc: 0.8883, precision: 0.9444, recall: 0.9118, f1: 0.9278, edges-ner-ontonotes_loss: 0.0260
09/16 07:38:36 AM: Update 32779: task edges-ner-ontonotes, batch 779 (32779): mcc: 0.9249, acc: 0.8899, precision: 0.9452, recall: 0.9131, f1: 0.9289, edges-ner-ontonotes_loss: 0.0257
09/16 07:38:43 AM: Update 32968: task edges-ner-ontonotes, batch 968 (32968): mcc: 0.9229, acc: 0.8874, precision: 0.9438, recall: 0.9108, f1: 0.9270, edges-ner-ontonotes_loss: 0.0263
09/16 07:38:46 AM: Update 32867: task edges-ner-ontonotes, batch 867 (32867): mcc: 0.9242, acc: 0.8888, precision: 0.9446, recall: 0.9122, f1: 0.9281, edges-ner-ontonotes_loss: 0.0258
09/16 07:38:49 AM: ***** Step 33000 / Validation 33 *****
09/16 07:38:49 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:38:49 AM: Validating...
09/16 07:38:53 AM: Evaluate: task edges-ner-ontonotes, batch 30 (157): mcc: 0.8965, acc: 0.8660, precision: 0.9246, recall: 0.8802, f1: 0.9019, edges-ner-ontonotes_loss: 0.0330
