09/16 09:13:23 AM: Git branch: master
09/16 09:13:23 AM: Git SHA: 3ca0f74688379229ab3eec908a215358ad18b3f4
09/16 09:13:23 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/ner-ontonotes-squad-top/",
  "exp_name": "experiments/ner-ontonotes-squad-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/ner-ontonotes-squad-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/squad",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/ner-ontonotes-squad-top__run",
  "run_dir": "./experiments/ner-ontonotes-squad-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-ner-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 09:13:23 AM: Saved config to ./experiments/ner-ontonotes-squad-top/run/params.conf
09/16 09:13:23 AM: Using random seed 1234
09/16 09:13:58 AM: Using GPU 0
09/16 09:13:58 AM: Loading tasks...
09/16 09:13:58 AM: Writing pre-preprocessed tasks to ./experiments/ner-ontonotes-squad-top/
09/16 09:13:58 AM: 	Creating task edges-ner-ontonotes from scratch.
09/16 09:13:59 AM: Read=49706, Skip=66106, Total=115812 from ./probing_data/edges/ontonotes/ner/train.json.retokenized.bert-base-uncased
09/16 09:13:59 AM: Read=7610, Skip=8070, Total=15680 from ./probing_data/edges/ontonotes/ner/development.json.retokenized.bert-base-uncased
09/16 09:13:59 AM: Read=5099, Skip=7118, Total=12217 from ./probing_data/edges/ontonotes/ner/test.json.retokenized.bert-base-uncased
09/16 09:14:00 AM: 	Task 'edges-ner-ontonotes': |train|=49706 |val|=7610 |test|=5099
09/16 09:14:00 AM: 	Finished loading tasks: edges-ner-ontonotes.
09/16 09:14:00 AM: 	Building vocab from scratch.
09/16 09:14:00 AM: 	Counting units for task edges-ner-ontonotes.
09/16 09:14:01 AM: 	Task 'edges-ner-ontonotes': adding vocab namespace 'edges-ner-ontonotes_labels'
09/16 09:14:02 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:14:02 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 09:14:03 AM: 	Saved vocab to ./experiments/ner-ontonotes-squad-top/vocab
09/16 09:14:03 AM: Loading token dictionary from ./experiments/ner-ontonotes-squad-top/vocab.
09/16 09:14:04 AM: 	Loaded vocab from ./experiments/ner-ontonotes-squad-top/vocab
09/16 09:14:04 AM: 	Vocab namespace edges-ner-ontonotes_labels: size 18
09/16 09:14:04 AM: 	Vocab namespace tokens: size 22840
09/16 09:14:04 AM: 	Vocab namespace bert_uncased: size 30524
09/16 09:14:04 AM: 	Vocab namespace chars: size 77
09/16 09:14:04 AM: 	Finished building vocab.
09/16 09:14:04 AM: 	Task edges-ner-ontonotes (train): Indexing from scratch.
09/16 09:14:14 AM: 	Task edges-ner-ontonotes (train): Saved 49706 instances to ./experiments/ner-ontonotes-squad-top/preproc/edges-ner-ontonotes__train_data
09/16 09:14:14 AM: 	Task edges-ner-ontonotes (val): Indexing from scratch.
09/16 09:14:16 AM: 	Task edges-ner-ontonotes (val): Saved 7610 instances to ./experiments/ner-ontonotes-squad-top/preproc/edges-ner-ontonotes__val_data
09/16 09:14:16 AM: 	Task edges-ner-ontonotes (test): Indexing from scratch.
09/16 09:14:17 AM: 	Task edges-ner-ontonotes (test): Saved 5099 instances to ./experiments/ner-ontonotes-squad-top/preproc/edges-ner-ontonotes__test_data
09/16 09:14:17 AM: 	Finished indexing tasks
09/16 09:14:17 AM: 	Creating trimmed target-only version of edges-ner-ontonotes train.
09/16 09:14:17 AM: 	  Training on 
09/16 09:14:17 AM: 	  Evaluating on edges-ner-ontonotes
09/16 09:14:17 AM: 	Finished loading tasks in 18.941s
09/16 09:14:17 AM: 	 Tasks: ['edges-ner-ontonotes']
09/16 09:14:17 AM: Building model...
09/16 09:14:17 AM: Using BERT model (bert-base-uncased).
09/16 09:14:17 AM: LOADING A FUNETUNED MODEL from: 
09/16 09:14:17 AM: models/squad
09/16 09:14:17 AM: loading configuration file models/squad/config.json
09/16 09:14:17 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 09:14:17 AM: loading weights file models/squad/pytorch_model.bin
09/16 09:14:22 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpx79r_wcv
09/16 09:14:29 AM: copying /tmp/tmpx79r_wcv to cache at ./experiments/ner-ontonotes-squad-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:14:29 AM: creating metadata file for ./experiments/ner-ontonotes-squad-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:14:29 AM: removing temp file /tmp/tmpx79r_wcv
09/16 09:14:29 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/ner-ontonotes-squad-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:14:30 AM: Initializing parameters
09/16 09:14:30 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 09:14:30 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 09:14:30 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 09:14:30 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 09:14:30 AM: 	Task 'edges-ner-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-ner-ontonotes"
}
09/16 09:14:53 AM: Model specification:
09/16 09:14:53 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-ner-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=18, bias=True)
    )
  )
)
09/16 09:14:53 AM: Model parameters:
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	edges-ner-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 09:14:53 AM: 	edges-ner-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 09:14:53 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 9216 with torch.Size([18, 512])
09/16 09:14:53 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 18 with torch.Size([18])
09/16 09:14:53 AM: Total number of parameters: 109688338 (1.09688e+08)
09/16 09:14:53 AM: Number of trainable parameters: 206098 (206098)
09/16 09:14:53 AM: Finished building model in 36.562s
09/16 09:14:53 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-ner-ontonotes 

09/16 09:14:56 AM: patience = 9
09/16 09:14:56 AM: val_interval = 1000
09/16 09:14:56 AM: max_vals = 250
09/16 09:14:56 AM: cuda_device = 0
09/16 09:14:56 AM: grad_norm = 5.0
09/16 09:14:56 AM: grad_clipping = None
09/16 09:14:56 AM: lr_decay = 0.99
09/16 09:14:56 AM: min_lr = 1e-06
09/16 09:14:56 AM: keep_all_checkpoints = 0
09/16 09:14:56 AM: val_data_limit = 5000
09/16 09:14:56 AM: max_epochs = -1
09/16 09:14:56 AM: dec_val_scale = 250
09/16 09:14:56 AM: training_data_fraction = 1
09/16 09:14:56 AM: type = adam
09/16 09:14:56 AM: parameter_groups = None
09/16 09:14:56 AM: Number of trainable parameters: 206098
09/16 09:14:56 AM: infer_type_and_cast = True
09/16 09:14:56 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:14:56 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:14:56 AM: lr = 0.0001
09/16 09:14:56 AM: amsgrad = True
09/16 09:14:56 AM: type = reduce_on_plateau
09/16 09:14:56 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:14:56 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:14:56 AM: mode = max
09/16 09:14:56 AM: factor = 0.5
09/16 09:14:56 AM: patience = 3
09/16 09:14:56 AM: threshold = 0.0001
09/16 09:14:56 AM: threshold_mode = abs
09/16 09:14:56 AM: verbose = True
09/16 09:14:56 AM: type = adam
09/16 09:14:56 AM: parameter_groups = None
09/16 09:14:56 AM: Number of trainable parameters: 206098
09/16 09:14:56 AM: infer_type_and_cast = True
09/16 09:14:56 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:14:56 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:14:56 AM: lr = 0.0001
09/16 09:14:56 AM: amsgrad = True
09/16 09:14:56 AM: type = reduce_on_plateau
09/16 09:14:56 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:14:56 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:14:56 AM: mode = max
09/16 09:14:56 AM: factor = 0.5
09/16 09:14:56 AM: patience = 3
09/16 09:14:56 AM: threshold = 0.0001
09/16 09:14:56 AM: threshold_mode = abs
09/16 09:14:56 AM: verbose = True
09/16 09:14:56 AM: Starting training without restoring from a checkpoint.
09/16 09:14:56 AM: Training examples per task, before any subsampling: {'edges-ner-ontonotes': 49706}
09/16 09:14:56 AM: Beginning training with stopping criteria based on metric: edges-ner-ontonotes_f1
09/16 09:15:06 AM: Update 42: task edges-ner-ontonotes, batch 42 (42): mcc: -0.0055, acc: 0.0050, precision: 0.0511, recall: 0.0682, f1: 0.0584, edges-ner-ontonotes_loss: 0.3571
09/16 09:15:16 AM: Update 209: task edges-ner-ontonotes, batch 209 (209): mcc: 0.0257, acc: 0.0169, precision: 0.1006, recall: 0.0304, f1: 0.0467, edges-ner-ontonotes_loss: 0.2066
09/16 09:15:26 AM: Update 323: task edges-ner-ontonotes, batch 323 (323): mcc: 0.0753, acc: 0.0382, precision: 0.2094, recall: 0.0468, f1: 0.0765, edges-ner-ontonotes_loss: 0.1883
09/16 09:15:37 AM: Update 466: task edges-ner-ontonotes, batch 466 (466): mcc: 0.1750, acc: 0.0839, precision: 0.4228, recall: 0.0896, f1: 0.1479, edges-ner-ontonotes_loss: 0.1725
09/16 09:15:47 AM: Update 603: task edges-ner-ontonotes, batch 603 (603): mcc: 0.2524, acc: 0.1246, precision: 0.5660, recall: 0.1291, f1: 0.2102, edges-ner-ontonotes_loss: 0.1619
09/16 09:15:57 AM: Update 717: task edges-ner-ontonotes, batch 717 (717): mcc: 0.3062, acc: 0.1574, precision: 0.6461, recall: 0.1618, f1: 0.2588, edges-ner-ontonotes_loss: 0.1552
09/16 09:16:07 AM: Update 860: task edges-ner-ontonotes, batch 860 (860): mcc: 0.3587, acc: 0.1941, precision: 0.7063, recall: 0.1995, f1: 0.3111, edges-ner-ontonotes_loss: 0.1474
09/16 09:16:17 AM: Update 970: task edges-ner-ontonotes, batch 970 (970): mcc: 0.3921, acc: 0.2208, precision: 0.7350, recall: 0.2272, f1: 0.3471, edges-ner-ontonotes_loss: 0.1425
09/16 09:16:19 AM: ***** Step 1000 / Validation 1 *****
09/16 09:16:19 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:16:19 AM: Validating...
09/16 09:16:33 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.5691, acc: 0.3945, precision: 0.8493, recall: 0.4015, f1: 0.5452, edges-ner-ontonotes_loss: 0.1152
09/16 09:16:45 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.5798, acc: 0.4087, precision: 0.8453, recall: 0.4185, f1: 0.5598, edges-ner-ontonotes_loss: 0.1094
09/16 09:16:50 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:16:51 AM: Best result seen so far for micro.
09/16 09:16:51 AM: Best result seen so far for macro.
09/16 09:16:51 AM: Updating LR scheduler:
09/16 09:16:51 AM: 	Best result seen so far for macro_avg: 0.570
09/16 09:16:51 AM: 	# validation passes without improvement: 0
09/16 09:16:51 AM: edges-ner-ontonotes_loss: training: 0.141351 validation: 0.106526
09/16 09:16:51 AM: macro_avg: validation: 0.570206
09/16 09:16:51 AM: micro_avg: validation: 0.000000
09/16 09:16:51 AM: edges-ner-ontonotes_mcc: training: 0.400726 validation: 0.588740
09/16 09:16:51 AM: edges-ner-ontonotes_acc: training: 0.228013 validation: 0.418941
09/16 09:16:51 AM: edges-ner-ontonotes_precision: training: 0.742077 validation: 0.848390
09/16 09:16:51 AM: edges-ner-ontonotes_recall: training: 0.234595 validation: 0.429406
09/16 09:16:51 AM: edges-ner-ontonotes_f1: training: 0.356491 validation: 0.570206
09/16 09:16:51 AM: Global learning rate: 0.0001
09/16 09:16:51 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:16:55 AM: Update 1053: task edges-ner-ontonotes, batch 53 (1053): mcc: 0.6001, acc: 0.4301, precision: 0.8461, recall: 0.4470, f1: 0.5850, edges-ner-ontonotes_loss: 0.0999
09/16 09:17:05 AM: Update 1188: task edges-ner-ontonotes, batch 188 (1188): mcc: 0.6057, acc: 0.4390, precision: 0.8432, recall: 0.4569, f1: 0.5926, edges-ner-ontonotes_loss: 0.0998
09/16 09:17:15 AM: Update 1296: task edges-ner-ontonotes, batch 296 (1296): mcc: 0.5994, acc: 0.4352, precision: 0.8344, recall: 0.4527, f1: 0.5870, edges-ner-ontonotes_loss: 0.1007
09/16 09:17:25 AM: Update 1440: task edges-ner-ontonotes, batch 440 (1440): mcc: 0.5931, acc: 0.4290, precision: 0.8301, recall: 0.4460, f1: 0.5802, edges-ner-ontonotes_loss: 0.1026
09/16 09:17:35 AM: Update 1569: task edges-ner-ontonotes, batch 569 (1569): mcc: 0.5903, acc: 0.4274, precision: 0.8264, recall: 0.4440, f1: 0.5777, edges-ner-ontonotes_loss: 0.1030
09/16 09:17:45 AM: Update 1741: task edges-ner-ontonotes, batch 741 (1741): mcc: 0.5927, acc: 0.4322, precision: 0.8252, recall: 0.4482, f1: 0.5809, edges-ner-ontonotes_loss: 0.1026
09/16 09:17:55 AM: Update 1875: task edges-ner-ontonotes, batch 875 (1875): mcc: 0.5933, acc: 0.4344, precision: 0.8229, recall: 0.4505, f1: 0.5823, edges-ner-ontonotes_loss: 0.1021
09/16 09:18:04 AM: ***** Step 2000 / Validation 2 *****
09/16 09:18:04 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:18:04 AM: Validating...
09/16 09:18:05 AM: Evaluate: task edges-ner-ontonotes, batch 14 (157): mcc: 0.6020, acc: 0.4642, precision: 0.8158, recall: 0.4677, f1: 0.5945, edges-ner-ontonotes_loss: 0.1036
09/16 09:18:15 AM: Evaluate: task edges-ner-ontonotes, batch 106 (157): mcc: 0.6871, acc: 0.5467, precision: 0.8755, recall: 0.5600, f1: 0.6831, edges-ner-ontonotes_loss: 0.0854
09/16 09:18:22 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:18:22 AM: Best result seen so far for macro.
09/16 09:18:22 AM: Updating LR scheduler:
09/16 09:18:22 AM: 	Best result seen so far for macro_avg: 0.678
09/16 09:18:22 AM: 	# validation passes without improvement: 0
09/16 09:18:22 AM: edges-ner-ontonotes_loss: training: 0.100652 validation: 0.085224
09/16 09:18:22 AM: macro_avg: validation: 0.677741
09/16 09:18:22 AM: micro_avg: validation: 0.000000
09/16 09:18:22 AM: edges-ner-ontonotes_mcc: training: 0.600871 validation: 0.682155
09/16 09:18:22 AM: edges-ner-ontonotes_acc: training: 0.444290 validation: 0.537989
09/16 09:18:22 AM: edges-ner-ontonotes_precision: training: 0.823570 validation: 0.873251
09/16 09:18:22 AM: edges-ner-ontonotes_recall: training: 0.461287 validation: 0.553761
09/16 09:18:22 AM: edges-ner-ontonotes_f1: training: 0.591354 validation: 0.677741
09/16 09:18:22 AM: Global learning rate: 0.0001
09/16 09:18:22 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:18:25 AM: Update 2050: task edges-ner-ontonotes, batch 50 (2050): mcc: 0.6507, acc: 0.5130, precision: 0.8270, recall: 0.5356, f1: 0.6502, edges-ner-ontonotes_loss: 0.0898
09/16 09:18:36 AM: Update 2183: task edges-ner-ontonotes, batch 183 (2183): mcc: 0.6555, acc: 0.5169, precision: 0.8325, recall: 0.5394, f1: 0.6547, edges-ner-ontonotes_loss: 0.0883
09/16 09:18:47 AM: Update 2318: task edges-ner-ontonotes, batch 318 (2318): mcc: 0.6622, acc: 0.5240, precision: 0.8353, recall: 0.5483, f1: 0.6620, edges-ner-ontonotes_loss: 0.0870
09/16 09:18:57 AM: Update 2452: task edges-ner-ontonotes, batch 452 (2452): mcc: 0.6703, acc: 0.5339, precision: 0.8385, recall: 0.5589, f1: 0.6708, edges-ner-ontonotes_loss: 0.0855
09/16 09:19:07 AM: Update 2562: task edges-ner-ontonotes, batch 562 (2562): mcc: 0.6709, acc: 0.5341, precision: 0.8397, recall: 0.5591, f1: 0.6713, edges-ner-ontonotes_loss: 0.0853
09/16 09:19:17 AM: Update 2699: task edges-ner-ontonotes, batch 699 (2699): mcc: 0.6731, acc: 0.5378, precision: 0.8388, recall: 0.5632, f1: 0.6739, edges-ner-ontonotes_loss: 0.0849
09/16 09:19:27 AM: Update 2811: task edges-ner-ontonotes, batch 811 (2811): mcc: 0.6738, acc: 0.5394, precision: 0.8383, recall: 0.5647, f1: 0.6748, edges-ner-ontonotes_loss: 0.0846
09/16 09:19:37 AM: Update 2945: task edges-ner-ontonotes, batch 945 (2945): mcc: 0.6679, acc: 0.5325, precision: 0.8345, recall: 0.5579, f1: 0.6687, edges-ner-ontonotes_loss: 0.0860
09/16 09:19:40 AM: ***** Step 3000 / Validation 3 *****
09/16 09:19:40 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:19:40 AM: Validating...
09/16 09:19:47 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.7127, acc: 0.5909, precision: 0.8652, recall: 0.6084, f1: 0.7144, edges-ner-ontonotes_loss: 0.0808
09/16 09:19:57 AM: Evaluate: task edges-ner-ontonotes, batch 144 (157): mcc: 0.7250, acc: 0.5990, precision: 0.8792, recall: 0.6182, f1: 0.7260, edges-ner-ontonotes_loss: 0.0769
09/16 09:19:58 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:19:58 AM: Best result seen so far for macro.
09/16 09:19:58 AM: Updating LR scheduler:
09/16 09:19:58 AM: 	Best result seen so far for macro_avg: 0.721
09/16 09:19:58 AM: 	# validation passes without improvement: 0
09/16 09:19:58 AM: edges-ner-ontonotes_loss: training: 0.086405 validation: 0.077634
09/16 09:19:58 AM: macro_avg: validation: 0.720984
09/16 09:19:58 AM: micro_avg: validation: 0.000000
09/16 09:19:58 AM: edges-ner-ontonotes_mcc: training: 0.666220 validation: 0.719889
09/16 09:19:58 AM: edges-ner-ontonotes_acc: training: 0.530761 validation: 0.593722
09/16 09:19:58 AM: edges-ner-ontonotes_precision: training: 0.833299 validation: 0.874567
09/16 09:19:58 AM: edges-ner-ontonotes_recall: training: 0.556075 validation: 0.613285
09/16 09:19:58 AM: edges-ner-ontonotes_f1: training: 0.667030 validation: 0.720984
09/16 09:19:58 AM: Global learning rate: 0.0001
09/16 09:19:58 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:20:07 AM: Update 3113: task edges-ner-ontonotes, batch 113 (3113): mcc: 0.6426, acc: 0.5051, precision: 0.8162, recall: 0.5303, f1: 0.6429, edges-ner-ontonotes_loss: 0.0925
09/16 09:20:17 AM: Update 3265: task edges-ner-ontonotes, batch 265 (3265): mcc: 0.6412, acc: 0.5050, precision: 0.8157, recall: 0.5285, f1: 0.6414, edges-ner-ontonotes_loss: 0.0920
09/16 09:20:27 AM: Update 3420: task edges-ner-ontonotes, batch 420 (3420): mcc: 0.6440, acc: 0.5078, precision: 0.8176, recall: 0.5316, f1: 0.6443, edges-ner-ontonotes_loss: 0.0910
09/16 09:20:37 AM: Update 3533: task edges-ner-ontonotes, batch 533 (3533): mcc: 0.6524, acc: 0.5184, precision: 0.8194, recall: 0.5437, f1: 0.6536, edges-ner-ontonotes_loss: 0.0891
09/16 09:20:47 AM: Update 3670: task edges-ner-ontonotes, batch 670 (3670): mcc: 0.6608, acc: 0.5284, precision: 0.8232, recall: 0.5545, f1: 0.6627, edges-ner-ontonotes_loss: 0.0874
09/16 09:20:57 AM: Update 3782: task edges-ner-ontonotes, batch 782 (3782): mcc: 0.6646, acc: 0.5329, precision: 0.8248, recall: 0.5595, f1: 0.6668, edges-ner-ontonotes_loss: 0.0866
09/16 09:21:08 AM: Update 3921: task edges-ner-ontonotes, batch 921 (3921): mcc: 0.6724, acc: 0.5426, precision: 0.8279, recall: 0.5699, f1: 0.6751, edges-ner-ontonotes_loss: 0.0852
09/16 09:21:13 AM: ***** Step 4000 / Validation 4 *****
09/16 09:21:13 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:21:13 AM: Validating...
09/16 09:21:18 AM: Evaluate: task edges-ner-ontonotes, batch 46 (157): mcc: 0.6928, acc: 0.5763, precision: 0.8490, recall: 0.5878, f1: 0.6946, edges-ner-ontonotes_loss: 0.0847
09/16 09:21:28 AM: Evaluate: task edges-ner-ontonotes, batch 125 (157): mcc: 0.7295, acc: 0.6116, precision: 0.8779, recall: 0.6266, f1: 0.7313, edges-ner-ontonotes_loss: 0.0750
09/16 09:21:31 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:21:31 AM: Best result seen so far for macro.
09/16 09:21:31 AM: Updating LR scheduler:
09/16 09:21:31 AM: 	Best result seen so far for macro_avg: 0.733
09/16 09:21:31 AM: 	# validation passes without improvement: 0
09/16 09:21:31 AM: edges-ner-ontonotes_loss: training: 0.084346 validation: 0.074195
09/16 09:21:31 AM: macro_avg: validation: 0.732717
09/16 09:21:31 AM: micro_avg: validation: 0.000000
09/16 09:21:31 AM: edges-ner-ontonotes_mcc: training: 0.676096 validation: 0.730199
09/16 09:21:31 AM: edges-ner-ontonotes_acc: training: 0.546964 validation: 0.613285
09/16 09:21:31 AM: edges-ner-ontonotes_precision: training: 0.829663 validation: 0.873766
09/16 09:21:31 AM: edges-ner-ontonotes_recall: training: 0.574710 validation: 0.630877
09/16 09:21:31 AM: edges-ner-ontonotes_f1: training: 0.679044 validation: 0.732717
09/16 09:21:31 AM: Global learning rate: 0.0001
09/16 09:21:31 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:21:38 AM: Update 4060: task edges-ner-ontonotes, batch 60 (4060): mcc: 0.6926, acc: 0.5664, precision: 0.8311, recall: 0.6008, f1: 0.6974, edges-ner-ontonotes_loss: 0.0790
09/16 09:21:48 AM: Update 4199: task edges-ner-ontonotes, batch 199 (4199): mcc: 0.7028, acc: 0.5801, precision: 0.8403, recall: 0.6109, f1: 0.7075, edges-ner-ontonotes_loss: 0.0775
09/16 09:21:58 AM: Update 4335: task edges-ner-ontonotes, batch 335 (4335): mcc: 0.7034, acc: 0.5809, precision: 0.8412, recall: 0.6112, f1: 0.7080, edges-ner-ontonotes_loss: 0.0776
09/16 09:22:08 AM: Update 4458: task edges-ner-ontonotes, batch 458 (4458): mcc: 0.6951, acc: 0.5706, precision: 0.8366, recall: 0.6008, f1: 0.6993, edges-ner-ontonotes_loss: 0.0795
09/16 09:22:18 AM: Update 4599: task edges-ner-ontonotes, batch 599 (4599): mcc: 0.6853, acc: 0.5592, precision: 0.8298, recall: 0.5897, f1: 0.6894, edges-ner-ontonotes_loss: 0.0821
09/16 09:22:28 AM: Update 4728: task edges-ner-ontonotes, batch 728 (4728): mcc: 0.6803, acc: 0.5535, precision: 0.8265, recall: 0.5839, f1: 0.6844, edges-ner-ontonotes_loss: 0.0830
09/16 09:22:38 AM: Update 4892: task edges-ner-ontonotes, batch 892 (4892): mcc: 0.6770, acc: 0.5496, precision: 0.8246, recall: 0.5800, f1: 0.6810, edges-ner-ontonotes_loss: 0.0836
09/16 09:22:47 AM: ***** Step 5000 / Validation 5 *****
09/16 09:22:47 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:22:47 AM: Validating...
09/16 09:22:48 AM: Evaluate: task edges-ner-ontonotes, batch 12 (157): mcc: 0.6617, acc: 0.5468, precision: 0.8071, recall: 0.5679, f1: 0.6667, edges-ner-ontonotes_loss: 0.0860
09/16 09:22:58 AM: Evaluate: task edges-ner-ontonotes, batch 104 (157): mcc: 0.7556, acc: 0.6483, precision: 0.8856, recall: 0.6642, f1: 0.7591, edges-ner-ontonotes_loss: 0.0691
09/16 09:23:05 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:23:05 AM: Best result seen so far for macro.
09/16 09:23:05 AM: Updating LR scheduler:
09/16 09:23:05 AM: 	Best result seen so far for macro_avg: 0.754
09/16 09:23:05 AM: 	# validation passes without improvement: 0
09/16 09:23:05 AM: edges-ner-ontonotes_loss: training: 0.083796 validation: 0.069156
09/16 09:23:05 AM: macro_avg: validation: 0.753603
09/16 09:23:05 AM: micro_avg: validation: 0.000000
09/16 09:23:05 AM: edges-ner-ontonotes_mcc: training: 0.675430 validation: 0.750532
09/16 09:23:05 AM: edges-ner-ontonotes_acc: training: 0.547654 validation: 0.637625
09/16 09:23:05 AM: edges-ner-ontonotes_precision: training: 0.823552 validation: 0.884958
09/16 09:23:05 AM: edges-ner-ontonotes_recall: training: 0.578140 validation: 0.656203
09/16 09:23:05 AM: edges-ner-ontonotes_f1: training: 0.679362 validation: 0.753603
09/16 09:23:05 AM: Global learning rate: 0.0001
09/16 09:23:05 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:23:08 AM: Update 5044: task edges-ner-ontonotes, batch 44 (5044): mcc: 0.6912, acc: 0.5730, precision: 0.8237, recall: 0.6042, f1: 0.6971, edges-ner-ontonotes_loss: 0.0809
09/16 09:23:18 AM: Update 5182: task edges-ner-ontonotes, batch 182 (5182): mcc: 0.6902, acc: 0.5702, precision: 0.8251, recall: 0.6014, f1: 0.6957, edges-ner-ontonotes_loss: 0.0796
09/16 09:23:28 AM: Update 5309: task edges-ner-ontonotes, batch 309 (5309): mcc: 0.6969, acc: 0.5765, precision: 0.8310, recall: 0.6080, f1: 0.7022, edges-ner-ontonotes_loss: 0.0778
09/16 09:23:38 AM: Update 5448: task edges-ner-ontonotes, batch 448 (5448): mcc: 0.7047, acc: 0.5859, precision: 0.8343, recall: 0.6186, f1: 0.7105, edges-ner-ontonotes_loss: 0.0761
09/16 09:23:48 AM: Update 5583: task edges-ner-ontonotes, batch 583 (5583): mcc: 0.7099, acc: 0.5914, precision: 0.8382, recall: 0.6243, f1: 0.7156, edges-ner-ontonotes_loss: 0.0754
09/16 09:23:58 AM: Update 5683: task edges-ner-ontonotes, batch 683 (5683): mcc: 0.7079, acc: 0.5893, precision: 0.8369, recall: 0.6220, f1: 0.7137, edges-ner-ontonotes_loss: 0.0756
09/16 09:24:08 AM: Update 5823: task edges-ner-ontonotes, batch 823 (5823): mcc: 0.7109, acc: 0.5925, precision: 0.8386, recall: 0.6258, f1: 0.7167, edges-ner-ontonotes_loss: 0.0752
09/16 09:24:18 AM: Update 5936: task edges-ner-ontonotes, batch 936 (5936): mcc: 0.7093, acc: 0.5910, precision: 0.8372, recall: 0.6242, f1: 0.7152, edges-ner-ontonotes_loss: 0.0756
09/16 09:24:23 AM: ***** Step 6000 / Validation 6 *****
09/16 09:24:23 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:24:23 AM: Validating...
09/16 09:24:29 AM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.7372, acc: 0.6285, precision: 0.8625, recall: 0.6513, f1: 0.7422, edges-ner-ontonotes_loss: 0.0727
09/16 09:24:39 AM: Evaluate: task edges-ner-ontonotes, batch 134 (157): mcc: 0.7628, acc: 0.6508, precision: 0.8909, recall: 0.6722, f1: 0.7662, edges-ner-ontonotes_loss: 0.0670
09/16 09:24:41 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:24:41 AM: Best result seen so far for macro.
09/16 09:24:41 AM: Updating LR scheduler:
09/16 09:24:41 AM: 	Best result seen so far for macro_avg: 0.762
09/16 09:24:41 AM: 	# validation passes without improvement: 0
09/16 09:24:41 AM: edges-ner-ontonotes_loss: training: 0.076327 validation: 0.067560
09/16 09:24:41 AM: macro_avg: validation: 0.762197
09/16 09:24:41 AM: micro_avg: validation: 0.000000
09/16 09:24:41 AM: edges-ner-ontonotes_mcc: training: 0.706433 validation: 0.758481
09/16 09:24:41 AM: edges-ner-ontonotes_acc: training: 0.587256 validation: 0.646269
09/16 09:24:41 AM: edges-ner-ontonotes_precision: training: 0.835943 validation: 0.886065
09/16 09:24:41 AM: edges-ner-ontonotes_recall: training: 0.620286 validation: 0.668714
09/16 09:24:41 AM: edges-ner-ontonotes_f1: training: 0.712146 validation: 0.762197
09/16 09:24:41 AM: Global learning rate: 0.0001
09/16 09:24:41 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:24:49 AM: Update 6100: task edges-ner-ontonotes, batch 100 (6100): mcc: 0.6728, acc: 0.5454, precision: 0.8158, recall: 0.5796, f1: 0.6777, edges-ner-ontonotes_loss: 0.0852
09/16 09:24:59 AM: Update 6225: task edges-ner-ontonotes, batch 225 (6225): mcc: 0.6735, acc: 0.5466, precision: 0.8162, recall: 0.5805, f1: 0.6785, edges-ner-ontonotes_loss: 0.0854
09/16 09:25:09 AM: Update 6390: task edges-ner-ontonotes, batch 390 (6390): mcc: 0.6730, acc: 0.5465, precision: 0.8170, recall: 0.5790, f1: 0.6777, edges-ner-ontonotes_loss: 0.0849
09/16 09:25:20 AM: Update 6538: task edges-ner-ontonotes, batch 538 (6538): mcc: 0.6709, acc: 0.5441, precision: 0.8148, recall: 0.5773, f1: 0.6758, edges-ner-ontonotes_loss: 0.0848
09/16 09:25:30 AM: Update 6677: task edges-ner-ontonotes, batch 677 (6677): mcc: 0.6781, acc: 0.5530, precision: 0.8181, recall: 0.5867, f1: 0.6833, edges-ner-ontonotes_loss: 0.0832
09/16 09:25:40 AM: Update 6817: task edges-ner-ontonotes, batch 817 (6817): mcc: 0.6833, acc: 0.5597, precision: 0.8204, recall: 0.5936, f1: 0.6888, edges-ner-ontonotes_loss: 0.0818
09/16 09:25:50 AM: Update 6932: task edges-ner-ontonotes, batch 932 (6932): mcc: 0.6873, acc: 0.5645, precision: 0.8227, recall: 0.5986, f1: 0.6930, edges-ner-ontonotes_loss: 0.0808
09/16 09:25:55 AM: ***** Step 7000 / Validation 7 *****
09/16 09:25:55 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:25:55 AM: Validating...
09/16 09:26:00 AM: Evaluate: task edges-ner-ontonotes, batch 50 (157): mcc: 0.7238, acc: 0.6128, precision: 0.8637, recall: 0.6279, f1: 0.7272, edges-ner-ontonotes_loss: 0.0751
09/16 09:26:10 AM: Evaluate: task edges-ner-ontonotes, batch 129 (157): mcc: 0.7553, acc: 0.6438, precision: 0.8917, recall: 0.6590, f1: 0.7579, edges-ner-ontonotes_loss: 0.0674
09/16 09:26:13 AM: Updating LR scheduler:
09/16 09:26:13 AM: 	Best result seen so far for macro_avg: 0.762
09/16 09:26:13 AM: 	# validation passes without improvement: 1
09/16 09:26:13 AM: edges-ner-ontonotes_loss: training: 0.080232 validation: 0.067043
09/16 09:26:13 AM: macro_avg: validation: 0.757472
09/16 09:26:13 AM: micro_avg: validation: 0.000000
09/16 09:26:13 AM: edges-ner-ontonotes_mcc: training: 0.690146 validation: 0.754503
09/16 09:26:13 AM: edges-ner-ontonotes_acc: training: 0.567995 validation: 0.643464
09/16 09:26:13 AM: edges-ner-ontonotes_precision: training: 0.823792 validation: 0.888458
09/16 09:26:13 AM: edges-ner-ontonotes_recall: training: 0.602386 validation: 0.660146
09/16 09:26:13 AM: edges-ner-ontonotes_f1: training: 0.695903 validation: 0.757472
09/16 09:26:13 AM: Global learning rate: 0.0001
09/16 09:26:13 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:26:20 AM: Update 7095: task edges-ner-ontonotes, batch 95 (7095): mcc: 0.7355, acc: 0.6229, precision: 0.8469, recall: 0.6610, f1: 0.7425, edges-ner-ontonotes_loss: 0.0696
09/16 09:26:30 AM: Update 7211: task edges-ner-ontonotes, batch 211 (7211): mcc: 0.7259, acc: 0.6110, precision: 0.8453, recall: 0.6459, f1: 0.7323, edges-ner-ontonotes_loss: 0.0716
09/16 09:26:40 AM: Update 7345: task edges-ner-ontonotes, batch 345 (7345): mcc: 0.7239, acc: 0.6093, precision: 0.8424, recall: 0.6449, f1: 0.7305, edges-ner-ontonotes_loss: 0.0721
09/16 09:26:51 AM: Update 7477: task edges-ner-ontonotes, batch 477 (7477): mcc: 0.7226, acc: 0.6080, precision: 0.8409, recall: 0.6437, f1: 0.7292, edges-ner-ontonotes_loss: 0.0726
09/16 09:27:01 AM: Update 7614: task edges-ner-ontonotes, batch 614 (7614): mcc: 0.7108, acc: 0.5932, precision: 0.8342, recall: 0.6290, f1: 0.7172, edges-ner-ontonotes_loss: 0.0753
09/16 09:27:12 AM: Update 7758: task edges-ner-ontonotes, batch 758 (7758): mcc: 0.7051, acc: 0.5859, precision: 0.8310, recall: 0.6219, f1: 0.7114, edges-ner-ontonotes_loss: 0.0771
09/16 09:27:22 AM: Update 7895: task edges-ner-ontonotes, batch 895 (7895): mcc: 0.7029, acc: 0.5828, precision: 0.8302, recall: 0.6187, f1: 0.7091, edges-ner-ontonotes_loss: 0.0778
09/16 09:27:28 AM: ***** Step 8000 / Validation 8 *****
09/16 09:27:28 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:27:28 AM: Validating...
09/16 09:27:32 AM: Evaluate: task edges-ner-ontonotes, batch 41 (157): mcc: 0.7433, acc: 0.6293, precision: 0.8637, recall: 0.6608, f1: 0.7487, edges-ner-ontonotes_loss: 0.0684
09/16 09:27:42 AM: Evaluate: task edges-ner-ontonotes, batch 120 (157): mcc: 0.7633, acc: 0.6484, precision: 0.8946, recall: 0.6701, f1: 0.7663, edges-ner-ontonotes_loss: 0.0641
09/16 09:27:46 AM: Updating LR scheduler:
09/16 09:27:46 AM: 	Best result seen so far for macro_avg: 0.762
09/16 09:27:48 AM: 	# validation passes without improvement: 2
09/16 09:27:48 AM: edges-ner-ontonotes_loss: training: 0.078006 validation: 0.064813
09/16 09:27:48 AM: macro_avg: validation: 0.762120
09/16 09:27:48 AM: micro_avg: validation: 0.000000
09/16 09:27:48 AM: edges-ner-ontonotes_mcc: training: 0.701819 validation: 0.759359
09/16 09:27:48 AM: edges-ner-ontonotes_acc: training: 0.581258 validation: 0.642554
09/16 09:27:48 AM: edges-ner-ontonotes_precision: training: 0.829838 validation: 0.893283
09/16 09:27:48 AM: edges-ner-ontonotes_recall: training: 0.617293 validation: 0.664544
09/16 09:27:48 AM: edges-ner-ontonotes_f1: training: 0.707957 validation: 0.762120
09/16 09:27:48 AM: Global learning rate: 0.0001
09/16 09:27:48 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:27:52 AM: Update 8060: task edges-ner-ontonotes, batch 60 (8060): mcc: 0.6727, acc: 0.5470, precision: 0.8145, recall: 0.5805, f1: 0.6779, edges-ner-ontonotes_loss: 0.0808
09/16 09:28:03 AM: Update 8177: task edges-ner-ontonotes, batch 177 (8177): mcc: 0.6875, acc: 0.5654, precision: 0.8210, recall: 0.6001, f1: 0.6934, edges-ner-ontonotes_loss: 0.0795
09/16 09:28:13 AM: Update 8316: task edges-ner-ontonotes, batch 316 (8316): mcc: 0.7005, acc: 0.5821, precision: 0.8289, recall: 0.6158, f1: 0.7067, edges-ner-ontonotes_loss: 0.0771
09/16 09:28:23 AM: Update 8430: task edges-ner-ontonotes, batch 430 (8430): mcc: 0.7010, acc: 0.5827, precision: 0.8286, recall: 0.6169, f1: 0.7073, edges-ner-ontonotes_loss: 0.0767
09/16 09:28:33 AM: Update 8561: task edges-ner-ontonotes, batch 561 (8561): mcc: 0.7089, acc: 0.5912, precision: 0.8336, recall: 0.6262, f1: 0.7152, edges-ner-ontonotes_loss: 0.0754
09/16 09:28:43 AM: Update 8693: task edges-ner-ontonotes, batch 693 (8693): mcc: 0.7141, acc: 0.5977, precision: 0.8361, recall: 0.6331, f1: 0.7206, edges-ner-ontonotes_loss: 0.0744
09/16 09:28:53 AM: Update 8811: task edges-ner-ontonotes, batch 811 (8811): mcc: 0.7151, acc: 0.5987, precision: 0.8365, recall: 0.6345, f1: 0.7216, edges-ner-ontonotes_loss: 0.0739
09/16 09:29:03 AM: Update 8953: task edges-ner-ontonotes, batch 953 (8953): mcc: 0.7159, acc: 0.6001, precision: 0.8359, recall: 0.6363, f1: 0.7226, edges-ner-ontonotes_loss: 0.0736
09/16 09:29:07 AM: ***** Step 9000 / Validation 9 *****
09/16 09:29:07 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:29:07 AM: Validating...
09/16 09:29:13 AM: Evaluate: task edges-ner-ontonotes, batch 59 (157): mcc: 0.7434, acc: 0.6322, precision: 0.8748, recall: 0.6522, f1: 0.7473, edges-ner-ontonotes_loss: 0.0695
09/16 09:29:23 AM: Evaluate: task edges-ner-ontonotes, batch 139 (157): mcc: 0.7678, acc: 0.6570, precision: 0.8978, recall: 0.6752, f1: 0.7708, edges-ner-ontonotes_loss: 0.0635
09/16 09:29:25 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:29:25 AM: Best result seen so far for macro.
09/16 09:29:25 AM: Updating LR scheduler:
09/16 09:29:25 AM: 	Best result seen so far for macro_avg: 0.768
09/16 09:29:25 AM: 	# validation passes without improvement: 0
09/16 09:29:25 AM: edges-ner-ontonotes_loss: training: 0.073542 validation: 0.063975
09/16 09:29:25 AM: macro_avg: validation: 0.768107
09/16 09:29:25 AM: micro_avg: validation: 0.000000
09/16 09:29:25 AM: edges-ner-ontonotes_mcc: training: 0.716813 validation: 0.764847
09/16 09:29:25 AM: edges-ner-ontonotes_acc: training: 0.601062 validation: 0.654534
09/16 09:29:25 AM: edges-ner-ontonotes_precision: training: 0.836579 validation: 0.893651
09/16 09:29:25 AM: edges-ner-ontonotes_recall: training: 0.637361 validation: 0.673491
09/16 09:29:25 AM: edges-ner-ontonotes_f1: training: 0.723507 validation: 0.768107
09/16 09:29:25 AM: Global learning rate: 0.0001
09/16 09:29:25 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:29:33 AM: Update 9082: task edges-ner-ontonotes, batch 82 (9082): mcc: 0.6750, acc: 0.5529, precision: 0.8055, recall: 0.5912, f1: 0.6819, edges-ner-ontonotes_loss: 0.0830
09/16 09:29:43 AM: Update 9221: task edges-ner-ontonotes, batch 221 (9221): mcc: 0.6770, acc: 0.5523, precision: 0.8116, recall: 0.5899, f1: 0.6832, edges-ner-ontonotes_loss: 0.0839
09/16 09:29:53 AM: Update 9349: task edges-ner-ontonotes, batch 349 (9349): mcc: 0.6798, acc: 0.5555, precision: 0.8145, recall: 0.5923, f1: 0.6859, edges-ner-ontonotes_loss: 0.0834
09/16 09:30:03 AM: Update 9511: task edges-ner-ontonotes, batch 511 (9511): mcc: 0.6796, acc: 0.5550, precision: 0.8151, recall: 0.5915, f1: 0.6855, edges-ner-ontonotes_loss: 0.0826
09/16 09:30:13 AM: Update 9650: task edges-ner-ontonotes, batch 650 (9650): mcc: 0.6799, acc: 0.5546, precision: 0.8156, recall: 0.5915, f1: 0.6857, edges-ner-ontonotes_loss: 0.0823
09/16 09:30:24 AM: Update 9780: task edges-ner-ontonotes, batch 780 (9780): mcc: 0.6845, acc: 0.5609, precision: 0.8180, recall: 0.5974, f1: 0.6905, edges-ner-ontonotes_loss: 0.0812
09/16 09:30:34 AM: Update 9927: task edges-ner-ontonotes, batch 927 (9927): mcc: 0.6919, acc: 0.5702, precision: 0.8218, recall: 0.6068, f1: 0.6981, edges-ner-ontonotes_loss: 0.0796
09/16 09:30:41 AM: ***** Step 10000 / Validation 10 *****
09/16 09:30:41 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:30:41 AM: Validating...
09/16 09:30:44 AM: Evaluate: task edges-ner-ontonotes, batch 25 (157): mcc: 0.7082, acc: 0.6033, precision: 0.8439, recall: 0.6170, f1: 0.7129, edges-ner-ontonotes_loss: 0.0782
09/16 09:30:54 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.7618, acc: 0.6550, precision: 0.8921, recall: 0.6695, f1: 0.7650, edges-ner-ontonotes_loss: 0.0652
09/16 09:30:59 AM: Updating LR scheduler:
09/16 09:30:59 AM: 	Best result seen so far for macro_avg: 0.768
09/16 09:30:59 AM: 	# validation passes without improvement: 1
09/16 09:30:59 AM: edges-ner-ontonotes_loss: training: 0.079201 validation: 0.064219
09/16 09:30:59 AM: macro_avg: validation: 0.767152
09/16 09:30:59 AM: micro_avg: validation: 0.000000
09/16 09:30:59 AM: edges-ner-ontonotes_mcc: training: 0.692778 validation: 0.763610
09/16 09:30:59 AM: edges-ner-ontonotes_acc: training: 0.571636 validation: 0.657188
09/16 09:30:59 AM: edges-ner-ontonotes_precision: training: 0.822087 validation: 0.890805
09/16 09:30:59 AM: edges-ner-ontonotes_recall: training: 0.608131 validation: 0.673643
09/16 09:30:59 AM: edges-ner-ontonotes_f1: training: 0.699105 validation: 0.767152
09/16 09:30:59 AM: Global learning rate: 0.0001
09/16 09:30:59 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:31:04 AM: Update 10069: task edges-ner-ontonotes, batch 69 (10069): mcc: 0.7411, acc: 0.6280, precision: 0.8505, recall: 0.6676, f1: 0.7480, edges-ner-ontonotes_loss: 0.0684
09/16 09:31:14 AM: Update 10203: task edges-ner-ontonotes, batch 203 (10203): mcc: 0.7376, acc: 0.6234, precision: 0.8477, recall: 0.6638, f1: 0.7446, edges-ner-ontonotes_loss: 0.0686
09/16 09:31:24 AM: Update 10311: task edges-ner-ontonotes, batch 311 (10311): mcc: 0.7315, acc: 0.6170, precision: 0.8448, recall: 0.6558, f1: 0.7384, edges-ner-ontonotes_loss: 0.0694
09/16 09:31:35 AM: Update 10447: task edges-ner-ontonotes, batch 447 (10447): mcc: 0.7309, acc: 0.6167, precision: 0.8431, recall: 0.6561, f1: 0.7379, edges-ner-ontonotes_loss: 0.0698
09/16 09:31:45 AM: Update 10583: task edges-ner-ontonotes, batch 583 (10583): mcc: 0.7306, acc: 0.6173, precision: 0.8423, recall: 0.6563, f1: 0.7377, edges-ner-ontonotes_loss: 0.0700
09/16 09:31:55 AM: Update 10698: task edges-ner-ontonotes, batch 698 (10698): mcc: 0.7215, acc: 0.6062, precision: 0.8369, recall: 0.6452, f1: 0.7286, edges-ner-ontonotes_loss: 0.0724
09/16 09:32:05 AM: Update 10837: task edges-ner-ontonotes, batch 837 (10837): mcc: 0.7164, acc: 0.5998, precision: 0.8336, recall: 0.6391, f1: 0.7235, edges-ner-ontonotes_loss: 0.0739
09/16 09:32:15 AM: Update 10959: task edges-ner-ontonotes, batch 959 (10959): mcc: 0.7116, acc: 0.5938, precision: 0.8306, recall: 0.6333, f1: 0.7187, edges-ner-ontonotes_loss: 0.0752
09/16 09:32:17 AM: ***** Step 11000 / Validation 11 *****
09/16 09:32:17 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:32:17 AM: Validating...
09/16 09:32:25 AM: Evaluate: task edges-ner-ontonotes, batch 71 (157): mcc: 0.7618, acc: 0.6480, precision: 0.8724, recall: 0.6854, f1: 0.7677, edges-ner-ontonotes_loss: 0.0655
09/16 09:32:35 AM: Evaluate: task edges-ner-ontonotes, batch 153 (157): mcc: 0.7691, acc: 0.6534, precision: 0.8939, recall: 0.6804, f1: 0.7727, edges-ner-ontonotes_loss: 0.0631
09/16 09:32:35 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:32:35 AM: Best result seen so far for macro.
09/16 09:32:35 AM: Updating LR scheduler:
09/16 09:32:35 AM: 	Best result seen so far for macro_avg: 0.772
09/16 09:32:35 AM: 	# validation passes without improvement: 0
09/16 09:32:35 AM: edges-ner-ontonotes_loss: training: 0.075457 validation: 0.063225
09/16 09:32:35 AM: macro_avg: validation: 0.771543
09/16 09:32:35 AM: micro_avg: validation: 0.000000
09/16 09:32:35 AM: edges-ner-ontonotes_mcc: training: 0.710756 validation: 0.767883
09/16 09:32:35 AM: edges-ner-ontonotes_acc: training: 0.592796 validation: 0.652563
09/16 09:32:35 AM: edges-ner-ontonotes_precision: training: 0.830141 validation: 0.892854
09/16 09:32:35 AM: edges-ner-ontonotes_recall: training: 0.632201 validation: 0.679254
09/16 09:32:35 AM: edges-ner-ontonotes_f1: training: 0.717775 validation: 0.771543
09/16 09:32:35 AM: Global learning rate: 0.0001
09/16 09:32:35 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:32:45 AM: Update 11163: task edges-ner-ontonotes, batch 163 (11163): mcc: 0.6942, acc: 0.5708, precision: 0.8248, recall: 0.6084, f1: 0.7002, edges-ner-ontonotes_loss: 0.0786
09/16 09:32:55 AM: Update 11284: task edges-ner-ontonotes, batch 284 (11284): mcc: 0.6963, acc: 0.5752, precision: 0.8245, recall: 0.6121, f1: 0.7026, edges-ner-ontonotes_loss: 0.0779
09/16 09:33:05 AM: Update 11415: task edges-ner-ontonotes, batch 415 (11415): mcc: 0.7028, acc: 0.5843, precision: 0.8273, recall: 0.6210, f1: 0.7095, edges-ner-ontonotes_loss: 0.0762
09/16 09:33:15 AM: Update 11534: task edges-ner-ontonotes, batch 534 (11534): mcc: 0.7050, acc: 0.5873, precision: 0.8272, recall: 0.6248, f1: 0.7119, edges-ner-ontonotes_loss: 0.0758
09/16 09:33:25 AM: Update 11668: task edges-ner-ontonotes, batch 668 (11668): mcc: 0.7104, acc: 0.5935, precision: 0.8309, recall: 0.6311, f1: 0.7173, edges-ner-ontonotes_loss: 0.0746
09/16 09:33:35 AM: Update 11800: task edges-ner-ontonotes, batch 800 (11800): mcc: 0.7163, acc: 0.6009, precision: 0.8338, recall: 0.6386, f1: 0.7233, edges-ner-ontonotes_loss: 0.0735
09/16 09:33:45 AM: Update 11920: task edges-ner-ontonotes, batch 920 (11920): mcc: 0.7179, acc: 0.6032, precision: 0.8343, recall: 0.6411, f1: 0.7251, edges-ner-ontonotes_loss: 0.0731
09/16 09:33:51 AM: ***** Step 12000 / Validation 12 *****
09/16 09:33:51 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:33:51 AM: Validating...
09/16 09:33:55 AM: Evaluate: task edges-ner-ontonotes, batch 44 (157): mcc: 0.7338, acc: 0.6201, precision: 0.8634, recall: 0.6448, f1: 0.7383, edges-ner-ontonotes_loss: 0.0713
09/16 09:34:05 AM: Evaluate: task edges-ner-ontonotes, batch 123 (157): mcc: 0.7622, acc: 0.6491, precision: 0.8971, recall: 0.6664, f1: 0.7647, edges-ner-ontonotes_loss: 0.0641
09/16 09:34:09 AM: Updating LR scheduler:
09/16 09:34:09 AM: 	Best result seen so far for macro_avg: 0.772
09/16 09:34:09 AM: 	# validation passes without improvement: 1
09/16 09:34:09 AM: edges-ner-ontonotes_loss: training: 0.072968 validation: 0.062806
09/16 09:34:09 AM: macro_avg: validation: 0.768924
09/16 09:34:09 AM: micro_avg: validation: 0.000000
09/16 09:34:09 AM: edges-ner-ontonotes_mcc: training: 0.719079 validation: 0.765863
09/16 09:34:09 AM: edges-ner-ontonotes_acc: training: 0.604523 validation: 0.654914
09/16 09:34:09 AM: edges-ner-ontonotes_precision: training: 0.834977 validation: 0.895735
09/16 09:34:09 AM: edges-ner-ontonotes_recall: training: 0.642517 validation: 0.673567
09/16 09:34:09 AM: edges-ner-ontonotes_f1: training: 0.726212 validation: 0.768924
09/16 09:34:09 AM: Global learning rate: 0.0001
09/16 09:34:09 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:34:15 AM: Update 12084: task edges-ner-ontonotes, batch 84 (12084): mcc: 0.7355, acc: 0.6233, precision: 0.8474, recall: 0.6606, f1: 0.7424, edges-ner-ontonotes_loss: 0.0687
09/16 09:34:25 AM: Update 12197: task edges-ner-ontonotes, batch 197 (12197): mcc: 0.7138, acc: 0.5961, precision: 0.8325, recall: 0.6354, f1: 0.7208, edges-ner-ontonotes_loss: 0.0746
09/16 09:34:35 AM: Update 12336: task edges-ner-ontonotes, batch 336 (12336): mcc: 0.6994, acc: 0.5778, precision: 0.8239, recall: 0.6180, f1: 0.7062, edges-ner-ontonotes_loss: 0.0779
09/16 09:34:45 AM: Update 12456: task edges-ner-ontonotes, batch 456 (12456): mcc: 0.6958, acc: 0.5741, precision: 0.8215, recall: 0.6137, f1: 0.7026, edges-ner-ontonotes_loss: 0.0790
09/16 09:34:55 AM: Update 12624: task edges-ner-ontonotes, batch 624 (12624): mcc: 0.6938, acc: 0.5711, precision: 0.8200, recall: 0.6114, f1: 0.7005, edges-ner-ontonotes_loss: 0.0792
09/16 09:35:06 AM: Update 12762: task edges-ner-ontonotes, batch 762 (12762): mcc: 0.6916, acc: 0.5689, precision: 0.8184, recall: 0.6090, f1: 0.6984, edges-ner-ontonotes_loss: 0.0795
09/16 09:35:16 AM: Update 12895: task edges-ner-ontonotes, batch 895 (12895): mcc: 0.6948, acc: 0.5733, precision: 0.8197, recall: 0.6134, f1: 0.7017, edges-ner-ontonotes_loss: 0.0787
09/16 09:35:24 AM: ***** Step 13000 / Validation 13 *****
09/16 09:35:24 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:35:24 AM: Validating...
09/16 09:35:26 AM: Evaluate: task edges-ner-ontonotes, batch 20 (157): mcc: 0.7324, acc: 0.6222, precision: 0.8615, recall: 0.6440, f1: 0.7370, edges-ner-ontonotes_loss: 0.0701
09/16 09:35:36 AM: Evaluate: task edges-ner-ontonotes, batch 110 (157): mcc: 0.7839, acc: 0.6821, precision: 0.8939, recall: 0.7058, f1: 0.7888, edges-ner-ontonotes_loss: 0.0608
09/16 09:35:42 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:35:42 AM: Best result seen so far for macro.
09/16 09:35:42 AM: Updating LR scheduler:
09/16 09:35:42 AM: 	Best result seen so far for macro_avg: 0.783
09/16 09:35:42 AM: 	# validation passes without improvement: 0
09/16 09:35:42 AM: edges-ner-ontonotes_loss: training: 0.078001 validation: 0.060789
09/16 09:35:42 AM: macro_avg: validation: 0.783108
09/16 09:35:42 AM: micro_avg: validation: 0.000000
09/16 09:35:42 AM: edges-ner-ontonotes_mcc: training: 0.697767 validation: 0.778513
09/16 09:35:42 AM: edges-ner-ontonotes_acc: training: 0.577250 validation: 0.672884
09/16 09:35:42 AM: edges-ner-ontonotes_precision: training: 0.821936 validation: 0.892750
09/16 09:35:42 AM: edges-ner-ontonotes_recall: training: 0.616675 validation: 0.697452
09/16 09:35:42 AM: edges-ner-ontonotes_f1: training: 0.704662 validation: 0.783108
09/16 09:35:42 AM: Global learning rate: 0.0001
09/16 09:35:42 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:35:46 AM: Update 13058: task edges-ner-ontonotes, batch 58 (13058): mcc: 0.7284, acc: 0.6200, precision: 0.8347, recall: 0.6588, f1: 0.7364, edges-ner-ontonotes_loss: 0.0716
09/16 09:35:56 AM: Update 13166: task edges-ner-ontonotes, batch 166 (13166): mcc: 0.7276, acc: 0.6152, precision: 0.8383, recall: 0.6545, f1: 0.7350, edges-ner-ontonotes_loss: 0.0712
09/16 09:36:06 AM: Update 13298: task edges-ner-ontonotes, batch 298 (13298): mcc: 0.7306, acc: 0.6195, precision: 0.8400, recall: 0.6582, f1: 0.7381, edges-ner-ontonotes_loss: 0.0704
09/16 09:36:16 AM: Update 13404: task edges-ner-ontonotes, batch 404 (13404): mcc: 0.7331, acc: 0.6223, precision: 0.8420, recall: 0.6609, f1: 0.7406, edges-ner-ontonotes_loss: 0.0697
09/16 09:36:26 AM: Update 13540: task edges-ner-ontonotes, batch 540 (13540): mcc: 0.7333, acc: 0.6220, precision: 0.8418, recall: 0.6613, f1: 0.7407, edges-ner-ontonotes_loss: 0.0696
09/16 09:36:36 AM: Update 13673: task edges-ner-ontonotes, batch 673 (13673): mcc: 0.7330, acc: 0.6219, precision: 0.8416, recall: 0.6610, f1: 0.7405, edges-ner-ontonotes_loss: 0.0697
09/16 09:36:46 AM: Update 13788: task edges-ner-ontonotes, batch 788 (13788): mcc: 0.7267, acc: 0.6141, precision: 0.8379, recall: 0.6532, f1: 0.7341, edges-ner-ontonotes_loss: 0.0712
09/16 09:36:56 AM: Update 13923: task edges-ner-ontonotes, batch 923 (13923): mcc: 0.7203, acc: 0.6065, precision: 0.8330, recall: 0.6462, f1: 0.7278, edges-ner-ontonotes_loss: 0.0730
09/16 09:37:01 AM: ***** Step 14000 / Validation 14 *****
09/16 09:37:01 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:37:01 AM: Validating...
09/16 09:37:06 AM: Evaluate: task edges-ner-ontonotes, batch 50 (157): mcc: 0.7526, acc: 0.6398, precision: 0.8724, recall: 0.6696, f1: 0.7577, edges-ner-ontonotes_loss: 0.0661
09/16 09:37:18 AM: Evaluate: task edges-ner-ontonotes, batch 130 (157): mcc: 0.7726, acc: 0.6578, precision: 0.9014, recall: 0.6804, f1: 0.7755, edges-ner-ontonotes_loss: 0.0618
09/16 09:37:20 AM: Updating LR scheduler:
09/16 09:37:20 AM: 	Best result seen so far for macro_avg: 0.783
09/16 09:37:20 AM: 	# validation passes without improvement: 1
09/16 09:37:20 AM: edges-ner-ontonotes_loss: training: 0.073625 validation: 0.062150
09/16 09:37:20 AM: macro_avg: validation: 0.770949
09/16 09:37:20 AM: micro_avg: validation: 0.000000
09/16 09:37:20 AM: edges-ner-ontonotes_mcc: training: 0.718397 validation: 0.768019
09/16 09:37:20 AM: edges-ner-ontonotes_acc: training: 0.603838 validation: 0.652639
09/16 09:37:20 AM: edges-ner-ontonotes_precision: training: 0.832214 validation: 0.898144
09/16 09:37:20 AM: edges-ner-ontonotes_recall: training: 0.643589 validation: 0.675311
09/16 09:37:20 AM: edges-ner-ontonotes_f1: training: 0.725847 validation: 0.770949
09/16 09:37:20 AM: Global learning rate: 0.0001
09/16 09:37:20 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:37:28 AM: Update 14087: task edges-ner-ontonotes, batch 87 (14087): mcc: 0.6966, acc: 0.5774, precision: 0.8258, recall: 0.6117, f1: 0.7028, edges-ner-ontonotes_loss: 0.0771
09/16 09:37:38 AM: Update 14251: task edges-ner-ontonotes, batch 251 (14251): mcc: 0.6884, acc: 0.5651, precision: 0.8184, recall: 0.6037, f1: 0.6948, edges-ner-ontonotes_loss: 0.0790
09/16 09:37:48 AM: Update 14371: task edges-ner-ontonotes, batch 371 (14371): mcc: 0.6865, acc: 0.5641, precision: 0.8139, recall: 0.6040, f1: 0.6934, edges-ner-ontonotes_loss: 0.0794
09/16 09:37:58 AM: Update 14513: task edges-ner-ontonotes, batch 513 (14513): mcc: 0.6979, acc: 0.5790, precision: 0.8202, recall: 0.6182, f1: 0.7050, edges-ner-ontonotes_loss: 0.0772
09/16 09:38:08 AM: Update 14631: task edges-ner-ontonotes, batch 631 (14631): mcc: 0.7013, acc: 0.5837, precision: 0.8223, recall: 0.6224, f1: 0.7085, edges-ner-ontonotes_loss: 0.0764
09/16 09:38:18 AM: Update 14759: task edges-ner-ontonotes, batch 759 (14759): mcc: 0.7076, acc: 0.5912, precision: 0.8260, recall: 0.6301, f1: 0.7149, edges-ner-ontonotes_loss: 0.0752
09/16 09:38:28 AM: Update 14896: task edges-ner-ontonotes, batch 896 (14896): mcc: 0.7138, acc: 0.5983, precision: 0.8299, recall: 0.6375, f1: 0.7211, edges-ner-ontonotes_loss: 0.0740
09/16 09:38:37 AM: ***** Step 15000 / Validation 15 *****
09/16 09:38:37 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:38:37 AM: Validating...
09/16 09:38:38 AM: Evaluate: task edges-ner-ontonotes, batch 6 (157): mcc: 0.6845, acc: 0.5725, precision: 0.8114, recall: 0.6025, f1: 0.6915, edges-ner-ontonotes_loss: 0.0814
09/16 09:38:48 AM: Evaluate: task edges-ner-ontonotes, batch 99 (157): mcc: 0.7659, acc: 0.6599, precision: 0.8875, recall: 0.6801, f1: 0.7701, edges-ner-ontonotes_loss: 0.0641
09/16 09:38:56 AM: Updating LR scheduler:
09/16 09:38:56 AM: 	Best result seen so far for macro_avg: 0.783
09/16 09:38:56 AM: 	# validation passes without improvement: 2
09/16 09:38:56 AM: edges-ner-ontonotes_loss: training: 0.073728 validation: 0.061263
09/16 09:38:56 AM: macro_avg: validation: 0.776089
09/16 09:38:56 AM: micro_avg: validation: 0.000000
09/16 09:38:56 AM: edges-ner-ontonotes_mcc: training: 0.715202 validation: 0.772296
09/16 09:38:56 AM: edges-ner-ontonotes_acc: training: 0.599784 validation: 0.664619
09/16 09:38:56 AM: edges-ner-ontonotes_precision: training: 0.830640 validation: 0.894831
09/16 09:38:56 AM: edges-ner-ontonotes_recall: training: 0.639392 validation: 0.685168
09/16 09:38:56 AM: edges-ner-ontonotes_f1: training: 0.722575 validation: 0.776089
09/16 09:38:56 AM: Global learning rate: 0.0001
09/16 09:38:56 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:38:59 AM: Update 15032: task edges-ner-ontonotes, batch 32 (15032): mcc: 0.7437, acc: 0.6335, precision: 0.8451, recall: 0.6766, f1: 0.7516, edges-ner-ontonotes_loss: 0.0670
09/16 09:39:10 AM: Update 15167: task edges-ner-ontonotes, batch 167 (15167): mcc: 0.7338, acc: 0.6207, precision: 0.8416, recall: 0.6624, f1: 0.7413, edges-ner-ontonotes_loss: 0.0699
09/16 09:39:21 AM: Update 15271: task edges-ner-ontonotes, batch 271 (15271): mcc: 0.7239, acc: 0.6092, precision: 0.8375, recall: 0.6488, f1: 0.7312, edges-ner-ontonotes_loss: 0.0709
09/16 09:39:31 AM: Update 15415: task edges-ner-ontonotes, batch 415 (15415): mcc: 0.7159, acc: 0.5988, precision: 0.8327, recall: 0.6389, f1: 0.7231, edges-ner-ontonotes_loss: 0.0740
09/16 09:39:41 AM: Update 15560: task edges-ner-ontonotes, batch 560 (15560): mcc: 0.7085, acc: 0.5908, precision: 0.8275, recall: 0.6304, f1: 0.7156, edges-ner-ontonotes_loss: 0.0765
09/16 09:39:51 AM: Update 15707: task edges-ner-ontonotes, batch 707 (15707): mcc: 0.7050, acc: 0.5862, precision: 0.8252, recall: 0.6264, f1: 0.7122, edges-ner-ontonotes_loss: 0.0771
09/16 09:40:01 AM: Update 15868: task edges-ner-ontonotes, batch 868 (15868): mcc: 0.7016, acc: 0.5820, precision: 0.8232, recall: 0.6223, f1: 0.7088, edges-ner-ontonotes_loss: 0.0777
09/16 09:40:11 AM: Update 15985: task edges-ner-ontonotes, batch 985 (15985): mcc: 0.7032, acc: 0.5842, precision: 0.8240, recall: 0.6243, f1: 0.7104, edges-ner-ontonotes_loss: 0.0772
09/16 09:40:12 AM: ***** Step 16000 / Validation 16 *****
09/16 09:40:13 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:40:13 AM: Validating...
09/16 09:40:21 AM: Evaluate: task edges-ner-ontonotes, batch 71 (157): mcc: 0.7705, acc: 0.6639, precision: 0.8895, recall: 0.6863, f1: 0.7748, edges-ner-ontonotes_loss: 0.0638
09/16 09:40:31 AM: Evaluate: task edges-ner-ontonotes, batch 153 (157): mcc: 0.7825, acc: 0.6739, precision: 0.9027, recall: 0.6962, f1: 0.7861, edges-ner-ontonotes_loss: 0.0600
09/16 09:40:31 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:40:31 AM: Best result seen so far for macro.
09/16 09:40:31 AM: Updating LR scheduler:
09/16 09:40:31 AM: 	Best result seen so far for macro_avg: 0.786
09/16 09:40:31 AM: 	# validation passes without improvement: 0
09/16 09:40:31 AM: edges-ner-ontonotes_loss: training: 0.076987 validation: 0.060062
09/16 09:40:31 AM: macro_avg: validation: 0.785830
09/16 09:40:31 AM: micro_avg: validation: 0.000000
09/16 09:40:31 AM: edges-ner-ontonotes_mcc: training: 0.703714 validation: 0.782089
09/16 09:40:31 AM: edges-ner-ontonotes_acc: training: 0.584800 validation: 0.674022
09/16 09:40:31 AM: edges-ner-ontonotes_precision: training: 0.824471 validation: 0.901630
09/16 09:40:31 AM: edges-ner-ontonotes_recall: training: 0.624752 validation: 0.696391
09/16 09:40:31 AM: edges-ner-ontonotes_f1: training: 0.710850 validation: 0.785830
09/16 09:40:31 AM: Global learning rate: 0.0001
09/16 09:40:31 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:40:41 AM: Update 16129: task edges-ner-ontonotes, batch 129 (16129): mcc: 0.7119, acc: 0.5996, precision: 0.8230, recall: 0.6399, f1: 0.7200, edges-ner-ontonotes_loss: 0.0744
09/16 09:40:51 AM: Update 16243: task edges-ner-ontonotes, batch 243 (16243): mcc: 0.7207, acc: 0.6076, precision: 0.8316, recall: 0.6480, f1: 0.7284, edges-ner-ontonotes_loss: 0.0725
09/16 09:41:01 AM: Update 16388: task edges-ner-ontonotes, batch 388 (16388): mcc: 0.7317, acc: 0.6198, precision: 0.8402, recall: 0.6599, f1: 0.7392, edges-ner-ontonotes_loss: 0.0699
09/16 09:41:12 AM: Update 16500: task edges-ner-ontonotes, batch 500 (16500): mcc: 0.7324, acc: 0.6202, precision: 0.8418, recall: 0.6597, f1: 0.7397, edges-ner-ontonotes_loss: 0.0698
09/16 09:41:22 AM: Update 16636: task edges-ner-ontonotes, batch 636 (16636): mcc: 0.7324, acc: 0.6211, precision: 0.8408, recall: 0.6607, f1: 0.7399, edges-ner-ontonotes_loss: 0.0697
09/16 09:41:32 AM: Update 16766: task edges-ner-ontonotes, batch 766 (16766): mcc: 0.7318, acc: 0.6204, precision: 0.8404, recall: 0.6599, f1: 0.7393, edges-ner-ontonotes_loss: 0.0697
09/16 09:41:42 AM: Update 16884: task edges-ner-ontonotes, batch 884 (16884): mcc: 0.7268, acc: 0.6141, precision: 0.8373, recall: 0.6539, f1: 0.7344, edges-ner-ontonotes_loss: 0.0708
09/16 09:41:51 AM: ***** Step 17000 / Validation 17 *****
09/16 09:41:51 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:41:51 AM: Validating...
09/16 09:41:52 AM: Evaluate: task edges-ner-ontonotes, batch 19 (157): mcc: 0.7445, acc: 0.6337, precision: 0.8627, recall: 0.6635, f1: 0.7501, edges-ner-ontonotes_loss: 0.0696
09/16 09:42:02 AM: Evaluate: task edges-ner-ontonotes, batch 110 (157): mcc: 0.7854, acc: 0.6789, precision: 0.8956, recall: 0.7069, f1: 0.7901, edges-ner-ontonotes_loss: 0.0612
09/16 09:42:08 AM: Updating LR scheduler:
09/16 09:42:08 AM: 	Best result seen so far for macro_avg: 0.786
09/16 09:42:08 AM: 	# validation passes without improvement: 1
09/16 09:42:08 AM: edges-ner-ontonotes_loss: training: 0.072066 validation: 0.060807
09/16 09:42:08 AM: macro_avg: validation: 0.783838
09/16 09:42:08 AM: micro_avg: validation: 0.000000
09/16 09:42:08 AM: edges-ner-ontonotes_mcc: training: 0.722375 validation: 0.779742
09/16 09:42:08 AM: edges-ner-ontonotes_acc: training: 0.608612 validation: 0.669472
09/16 09:42:08 AM: edges-ner-ontonotes_precision: training: 0.834327 validation: 0.897408
09/16 09:42:08 AM: edges-ner-ontonotes_recall: training: 0.648696 validation: 0.695784
09/16 09:42:08 AM: edges-ner-ontonotes_f1: training: 0.729894 validation: 0.783838
09/16 09:42:08 AM: Global learning rate: 0.0001
09/16 09:42:08 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:42:13 AM: Update 17062: task edges-ner-ontonotes, batch 62 (17062): mcc: 0.7059, acc: 0.5814, precision: 0.8338, recall: 0.6211, f1: 0.7119, edges-ner-ontonotes_loss: 0.0792
09/16 09:42:23 AM: Update 17189: task edges-ner-ontonotes, batch 189 (17189): mcc: 0.7058, acc: 0.5853, precision: 0.8275, recall: 0.6259, f1: 0.7127, edges-ner-ontonotes_loss: 0.0784
09/16 09:42:33 AM: Update 17351: task edges-ner-ontonotes, batch 351 (17351): mcc: 0.6982, acc: 0.5761, precision: 0.8211, recall: 0.6181, f1: 0.7053, edges-ner-ontonotes_loss: 0.0791
09/16 09:42:43 AM: Update 17479: task edges-ner-ontonotes, batch 479 (17479): mcc: 0.6979, acc: 0.5758, precision: 0.8209, recall: 0.6177, f1: 0.7050, edges-ner-ontonotes_loss: 0.0784
09/16 09:42:53 AM: Update 17612: task edges-ner-ontonotes, batch 612 (17612): mcc: 0.7037, acc: 0.5837, precision: 0.8245, recall: 0.6247, f1: 0.7108, edges-ner-ontonotes_loss: 0.0771
09/16 09:43:03 AM: Update 17743: task edges-ner-ontonotes, batch 743 (17743): mcc: 0.7077, acc: 0.5894, precision: 0.8258, recall: 0.6305, f1: 0.7150, edges-ner-ontonotes_loss: 0.0761
09/16 09:43:14 AM: Update 17869: task edges-ner-ontonotes, batch 869 (17869): mcc: 0.7124, acc: 0.5954, precision: 0.8285, recall: 0.6364, f1: 0.7198, edges-ner-ontonotes_loss: 0.0750
09/16 09:43:24 AM: Update 17997: task edges-ner-ontonotes, batch 997 (17997): mcc: 0.7177, acc: 0.6017, precision: 0.8321, recall: 0.6425, f1: 0.7251, edges-ner-ontonotes_loss: 0.0739
09/16 09:43:24 AM: ***** Step 18000 / Validation 18 *****
09/16 09:43:24 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:43:24 AM: Validating...
09/16 09:43:34 AM: Evaluate: task edges-ner-ontonotes, batch 85 (157): mcc: 0.7639, acc: 0.6563, precision: 0.8867, recall: 0.6774, f1: 0.7680, edges-ner-ontonotes_loss: 0.0649
09/16 09:43:42 AM: Updating LR scheduler:
09/16 09:43:42 AM: 	Best result seen so far for macro_avg: 0.786
09/16 09:43:42 AM: 	# validation passes without improvement: 2
09/16 09:43:42 AM: edges-ner-ontonotes_loss: training: 0.073823 validation: 0.061234
09/16 09:43:42 AM: macro_avg: validation: 0.776526
09/16 09:43:42 AM: micro_avg: validation: 0.000000
09/16 09:43:42 AM: edges-ner-ontonotes_mcc: training: 0.717823 validation: 0.772396
09/16 09:43:42 AM: edges-ner-ontonotes_acc: training: 0.601903 validation: 0.664923
09/16 09:43:42 AM: edges-ner-ontonotes_precision: training: 0.832176 validation: 0.892389
09/16 09:43:42 AM: edges-ner-ontonotes_recall: training: 0.642636 validation: 0.687292
09/16 09:43:42 AM: edges-ner-ontonotes_f1: training: 0.725227 validation: 0.776526
09/16 09:43:42 AM: Global learning rate: 0.0001
09/16 09:43:42 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:43:44 AM: Update 18017: task edges-ner-ontonotes, batch 17 (18017): mcc: 0.7536, acc: 0.6426, precision: 0.8532, recall: 0.6871, f1: 0.7612, edges-ner-ontonotes_loss: 0.0667
09/16 09:43:54 AM: Update 18121: task edges-ner-ontonotes, batch 121 (18121): mcc: 0.7380, acc: 0.6276, precision: 0.8444, recall: 0.6673, f1: 0.7455, edges-ner-ontonotes_loss: 0.0688
09/16 09:44:04 AM: Update 18253: task edges-ner-ontonotes, batch 253 (18253): mcc: 0.7392, acc: 0.6291, precision: 0.8444, recall: 0.6695, f1: 0.7468, edges-ner-ontonotes_loss: 0.0687
09/16 09:44:14 AM: Update 18370: task edges-ner-ontonotes, batch 370 (18370): mcc: 0.7332, acc: 0.6212, precision: 0.8392, recall: 0.6633, f1: 0.7410, edges-ner-ontonotes_loss: 0.0694
09/16 09:44:24 AM: Update 18500: task edges-ner-ontonotes, batch 500 (18500): mcc: 0.7187, acc: 0.6029, precision: 0.8307, recall: 0.6453, f1: 0.7263, edges-ner-ontonotes_loss: 0.0735
09/16 09:44:34 AM: Update 18646: task edges-ner-ontonotes, batch 646 (18646): mcc: 0.7160, acc: 0.5992, precision: 0.8295, recall: 0.6416, f1: 0.7236, edges-ner-ontonotes_loss: 0.0745
09/16 09:44:44 AM: Update 18771: task edges-ner-ontonotes, batch 771 (18771): mcc: 0.7107, acc: 0.5931, precision: 0.8260, recall: 0.6354, f1: 0.7183, edges-ner-ontonotes_loss: 0.0758
09/16 09:44:54 AM: Update 18944: task edges-ner-ontonotes, batch 944 (18944): mcc: 0.7091, acc: 0.5915, precision: 0.8250, recall: 0.6335, f1: 0.7167, edges-ner-ontonotes_loss: 0.0757
09/16 09:45:00 AM: ***** Step 19000 / Validation 19 *****
09/16 09:45:00 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:45:00 AM: Validating...
09/16 09:45:04 AM: Evaluate: task edges-ner-ontonotes, batch 48 (157): mcc: 0.7647, acc: 0.6621, precision: 0.8724, recall: 0.6903, f1: 0.7707, edges-ner-ontonotes_loss: 0.0645
09/16 09:45:14 AM: Evaluate: task edges-ner-ontonotes, batch 127 (157): mcc: 0.7865, acc: 0.6808, precision: 0.8956, recall: 0.7089, f1: 0.7914, edges-ner-ontonotes_loss: 0.0593
09/16 09:45:18 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:45:18 AM: Best result seen so far for macro.
09/16 09:45:18 AM: Updating LR scheduler:
09/16 09:45:18 AM: 	Best result seen so far for macro_avg: 0.789
09/16 09:45:18 AM: 	# validation passes without improvement: 0
09/16 09:45:18 AM: edges-ner-ontonotes_loss: training: 0.075866 validation: 0.059330
09/16 09:45:18 AM: macro_avg: validation: 0.789449
09/16 09:45:18 AM: micro_avg: validation: 0.000000
09/16 09:45:18 AM: edges-ner-ontonotes_mcc: training: 0.707796 validation: 0.784517
09/16 09:45:18 AM: edges-ner-ontonotes_acc: training: 0.589561 validation: 0.678344
09/16 09:45:18 AM: edges-ner-ontonotes_precision: training: 0.824106 validation: 0.893778
09/16 09:45:18 AM: edges-ner-ontonotes_recall: training: 0.632007 validation: 0.706931
09/16 09:45:18 AM: edges-ner-ontonotes_f1: training: 0.715385 validation: 0.789449
09/16 09:45:18 AM: Global learning rate: 0.0001
09/16 09:45:18 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:45:24 AM: Update 19094: task edges-ner-ontonotes, batch 94 (19094): mcc: 0.7306, acc: 0.6246, precision: 0.8370, recall: 0.6607, f1: 0.7385, edges-ner-ontonotes_loss: 0.0700
09/16 09:45:34 AM: Update 19228: task edges-ner-ontonotes, batch 228 (19228): mcc: 0.7222, acc: 0.6143, precision: 0.8312, recall: 0.6509, f1: 0.7301, edges-ner-ontonotes_loss: 0.0717
09/16 09:45:45 AM: Update 19340: task edges-ner-ontonotes, batch 340 (19340): mcc: 0.7215, acc: 0.6106, precision: 0.8318, recall: 0.6493, f1: 0.7293, edges-ner-ontonotes_loss: 0.0718
09/16 09:45:55 AM: Update 19476: task edges-ner-ontonotes, batch 476 (19476): mcc: 0.7275, acc: 0.6166, precision: 0.8362, recall: 0.6560, f1: 0.7353, edges-ner-ontonotes_loss: 0.0707
09/16 09:46:05 AM: Update 19612: task edges-ner-ontonotes, batch 612 (19612): mcc: 0.7327, acc: 0.6226, precision: 0.8393, recall: 0.6624, f1: 0.7404, edges-ner-ontonotes_loss: 0.0694
09/16 09:46:16 AM: Update 19750: task edges-ner-ontonotes, batch 750 (19750): mcc: 0.7332, acc: 0.6226, precision: 0.8395, recall: 0.6631, f1: 0.7409, edges-ner-ontonotes_loss: 0.0693
09/16 09:46:26 AM: Update 19881: task edges-ner-ontonotes, batch 881 (19881): mcc: 0.7330, acc: 0.6223, precision: 0.8395, recall: 0.6627, f1: 0.7407, edges-ner-ontonotes_loss: 0.0692
09/16 09:46:36 AM: Update 19998: task edges-ner-ontonotes, batch 998 (19998): mcc: 0.7295, acc: 0.6181, precision: 0.8369, recall: 0.6589, f1: 0.7373, edges-ner-ontonotes_loss: 0.0704
09/16 09:46:36 AM: ***** Step 20000 / Validation 20 *****
09/16 09:46:36 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:46:36 AM: Validating...
09/16 09:46:46 AM: Evaluate: task edges-ner-ontonotes, batch 94 (157): mcc: 0.7877, acc: 0.6829, precision: 0.8906, recall: 0.7151, f1: 0.7932, edges-ner-ontonotes_loss: 0.0601
09/16 09:46:54 AM: Updating LR scheduler:
09/16 09:46:54 AM: 	Best result seen so far for macro_avg: 0.789
09/16 09:46:54 AM: 	# validation passes without improvement: 1
09/16 09:46:54 AM: edges-ner-ontonotes_loss: training: 0.070447 validation: 0.059551
09/16 09:46:54 AM: macro_avg: validation: 0.786216
09/16 09:46:54 AM: micro_avg: validation: 0.000000
09/16 09:46:54 AM: edges-ner-ontonotes_mcc: training: 0.729537 validation: 0.781888
09/16 09:46:54 AM: edges-ner-ontonotes_acc: training: 0.618082 validation: 0.671520
09/16 09:46:54 AM: edges-ner-ontonotes_precision: training: 0.836967 validation: 0.896977
09/16 09:46:54 AM: edges-ner-ontonotes_recall: training: 0.658868 validation: 0.699803
09/16 09:46:54 AM: edges-ner-ontonotes_f1: training: 0.737315 validation: 0.786216
09/16 09:46:54 AM: Global learning rate: 0.0001
09/16 09:46:54 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:46:56 AM: Update 20030: task edges-ner-ontonotes, batch 30 (20030): mcc: 0.7008, acc: 0.5755, precision: 0.8250, recall: 0.6193, f1: 0.7075, edges-ner-ontonotes_loss: 0.0789
09/16 09:47:06 AM: Update 20166: task edges-ner-ontonotes, batch 166 (20166): mcc: 0.6940, acc: 0.5744, precision: 0.8134, recall: 0.6170, f1: 0.7018, edges-ner-ontonotes_loss: 0.0795
09/16 09:47:16 AM: Update 20283: task edges-ner-ontonotes, batch 283 (20283): mcc: 0.6888, acc: 0.5672, precision: 0.8111, recall: 0.6100, f1: 0.6964, edges-ner-ontonotes_loss: 0.0805
09/16 09:47:26 AM: Update 20444: task edges-ner-ontonotes, batch 444 (20444): mcc: 0.6915, acc: 0.5700, precision: 0.8140, recall: 0.6123, f1: 0.6989, edges-ner-ontonotes_loss: 0.0795
09/16 09:47:36 AM: Update 20569: task edges-ner-ontonotes, batch 569 (20569): mcc: 0.6922, acc: 0.5706, precision: 0.8142, recall: 0.6134, f1: 0.6997, edges-ner-ontonotes_loss: 0.0790
09/16 09:47:46 AM: Update 20707: task edges-ner-ontonotes, batch 707 (20707): mcc: 0.6998, acc: 0.5804, precision: 0.8188, recall: 0.6226, f1: 0.7074, edges-ner-ontonotes_loss: 0.0774
09/16 09:47:56 AM: Update 20844: task edges-ner-ontonotes, batch 844 (20844): mcc: 0.7048, acc: 0.5869, precision: 0.8217, recall: 0.6288, f1: 0.7124, edges-ner-ontonotes_loss: 0.0764
09/16 09:48:06 AM: Update 20949: task edges-ner-ontonotes, batch 949 (20949): mcc: 0.7091, acc: 0.5923, precision: 0.8244, recall: 0.6339, f1: 0.7167, edges-ner-ontonotes_loss: 0.0755
09/16 09:48:10 AM: ***** Step 21000 / Validation 21 *****
09/16 09:48:10 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:48:10 AM: Validating...
09/16 09:48:16 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.7576, acc: 0.6536, precision: 0.8712, recall: 0.6792, f1: 0.7633, edges-ner-ontonotes_loss: 0.0656
09/16 09:48:26 AM: Evaluate: task edges-ner-ontonotes, batch 144 (157): mcc: 0.7767, acc: 0.6748, precision: 0.8872, recall: 0.6988, f1: 0.7818, edges-ner-ontonotes_loss: 0.0609
09/16 09:48:28 AM: Updating LR scheduler:
09/16 09:48:28 AM: 	Best result seen so far for macro_avg: 0.789
09/16 09:48:28 AM: 	# validation passes without improvement: 2
09/16 09:48:28 AM: edges-ner-ontonotes_loss: training: 0.075024 validation: 0.061398
09/16 09:48:28 AM: macro_avg: validation: 0.779187
09/16 09:48:28 AM: micro_avg: validation: 0.000000
09/16 09:48:28 AM: edges-ner-ontonotes_mcc: training: 0.710824 validation: 0.773850
09/16 09:48:28 AM: edges-ner-ontonotes_acc: training: 0.594561 validation: 0.671899
09/16 09:48:28 AM: edges-ner-ontonotes_precision: training: 0.825304 validation: 0.883960
09/16 09:48:28 AM: edges-ner-ontonotes_recall: training: 0.636221 validation: 0.696618
09/16 09:48:28 AM: edges-ner-ontonotes_f1: training: 0.718531 validation: 0.779187
09/16 09:48:28 AM: Global learning rate: 0.0001
09/16 09:48:28 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:48:36 AM: Update 21107: task edges-ner-ontonotes, batch 107 (21107): mcc: 0.7455, acc: 0.6328, precision: 0.8474, recall: 0.6778, f1: 0.7532, edges-ner-ontonotes_loss: 0.0673
09/16 09:48:46 AM: Update 21218: task edges-ner-ontonotes, batch 218 (21218): mcc: 0.7374, acc: 0.6257, precision: 0.8412, recall: 0.6690, f1: 0.7453, edges-ner-ontonotes_loss: 0.0683
09/16 09:48:56 AM: Update 21353: task edges-ner-ontonotes, batch 353 (21353): mcc: 0.7365, acc: 0.6250, precision: 0.8405, recall: 0.6679, f1: 0.7444, edges-ner-ontonotes_loss: 0.0684
09/16 09:49:07 AM: Update 21481: task edges-ner-ontonotes, batch 481 (21481): mcc: 0.7377, acc: 0.6270, precision: 0.8418, recall: 0.6689, f1: 0.7455, edges-ner-ontonotes_loss: 0.0684
09/16 09:49:17 AM: Update 21623: task edges-ner-ontonotes, batch 623 (21623): mcc: 0.7287, acc: 0.6157, precision: 0.8368, recall: 0.6576, f1: 0.7364, edges-ner-ontonotes_loss: 0.0711
09/16 09:49:27 AM: Update 21763: task edges-ner-ontonotes, batch 763 (21763): mcc: 0.7213, acc: 0.6067, precision: 0.8318, recall: 0.6490, f1: 0.7291, edges-ner-ontonotes_loss: 0.0728
09/16 09:49:37 AM: Update 21897: task edges-ner-ontonotes, batch 897 (21897): mcc: 0.7176, acc: 0.6016, precision: 0.8301, recall: 0.6439, f1: 0.7252, edges-ner-ontonotes_loss: 0.0739
09/16 09:49:44 AM: ***** Step 22000 / Validation 22 *****
09/16 09:49:44 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:49:44 AM: Validating...
09/16 09:49:47 AM: Evaluate: task edges-ner-ontonotes, batch 34 (157): mcc: 0.7638, acc: 0.6530, precision: 0.8654, recall: 0.6945, f1: 0.7706, edges-ner-ontonotes_loss: 0.0645
09/16 09:49:59 AM: Evaluate: task edges-ner-ontonotes, batch 112 (157): mcc: 0.7909, acc: 0.6861, precision: 0.8984, recall: 0.7142, f1: 0.7958, edges-ner-ontonotes_loss: 0.0584
09/16 09:50:05 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:50:05 AM: Best result seen so far for macro.
09/16 09:50:05 AM: Updating LR scheduler:
09/16 09:50:05 AM: 	Best result seen so far for macro_avg: 0.790
09/16 09:50:05 AM: 	# validation passes without improvement: 0
09/16 09:50:05 AM: edges-ner-ontonotes_loss: training: 0.074254 validation: 0.058539
09/16 09:50:05 AM: macro_avg: validation: 0.790029
09/16 09:50:05 AM: micro_avg: validation: 0.000000
09/16 09:50:05 AM: edges-ner-ontonotes_mcc: training: 0.715863 validation: 0.785751
09/16 09:50:05 AM: edges-ner-ontonotes_acc: training: 0.599160 validation: 0.676676
09/16 09:50:05 AM: edges-ner-ontonotes_precision: training: 0.829620 validation: 0.899806
09/16 09:50:05 AM: edges-ner-ontonotes_recall: training: 0.641352 validation: 0.704125
09/16 09:50:05 AM: edges-ner-ontonotes_f1: training: 0.723438 validation: 0.790029
09/16 09:50:05 AM: Global learning rate: 0.0001
09/16 09:50:05 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:50:09 AM: Update 22068: task edges-ner-ontonotes, batch 68 (22068): mcc: 0.7143, acc: 0.5943, precision: 0.8336, recall: 0.6355, f1: 0.7212, edges-ner-ontonotes_loss: 0.0737
09/16 09:50:19 AM: Update 22174: task edges-ner-ontonotes, batch 174 (22174): mcc: 0.7107, acc: 0.5955, precision: 0.8235, recall: 0.6374, f1: 0.7186, edges-ner-ontonotes_loss: 0.0737
09/16 09:50:29 AM: Update 22309: task edges-ner-ontonotes, batch 309 (22309): mcc: 0.7152, acc: 0.6021, precision: 0.8253, recall: 0.6437, f1: 0.7233, edges-ner-ontonotes_loss: 0.0730
09/16 09:50:39 AM: Update 22426: task edges-ner-ontonotes, batch 426 (22426): mcc: 0.7150, acc: 0.6013, precision: 0.8253, recall: 0.6434, f1: 0.7230, edges-ner-ontonotes_loss: 0.0728
09/16 09:50:49 AM: Update 22556: task edges-ner-ontonotes, batch 556 (22556): mcc: 0.7207, acc: 0.6074, precision: 0.8307, recall: 0.6488, f1: 0.7286, edges-ner-ontonotes_loss: 0.0717
09/16 09:50:59 AM: Update 22695: task edges-ner-ontonotes, batch 695 (22695): mcc: 0.7265, acc: 0.6140, precision: 0.8347, recall: 0.6554, f1: 0.7343, edges-ner-ontonotes_loss: 0.0702
09/16 09:51:09 AM: Update 22804: task edges-ner-ontonotes, batch 804 (22804): mcc: 0.7282, acc: 0.6163, precision: 0.8358, recall: 0.6576, f1: 0.7361, edges-ner-ontonotes_loss: 0.0699
09/16 09:51:19 AM: Update 22938: task edges-ner-ontonotes, batch 938 (22938): mcc: 0.7298, acc: 0.6181, precision: 0.8370, recall: 0.6593, f1: 0.7376, edges-ner-ontonotes_loss: 0.0696
09/16 09:51:24 AM: ***** Step 23000 / Validation 23 *****
09/16 09:51:24 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:51:24 AM: Validating...
09/16 09:51:29 AM: Evaluate: task edges-ner-ontonotes, batch 54 (157): mcc: 0.7603, acc: 0.6546, precision: 0.8720, recall: 0.6831, f1: 0.7661, edges-ner-ontonotes_loss: 0.0666
09/16 09:51:39 AM: Evaluate: task edges-ner-ontonotes, batch 135 (157): mcc: 0.7873, acc: 0.6843, precision: 0.8999, recall: 0.7067, f1: 0.7917, edges-ner-ontonotes_loss: 0.0593
09/16 09:51:42 AM: Updating LR scheduler:
09/16 09:51:42 AM: 	Best result seen so far for macro_avg: 0.790
09/16 09:51:42 AM: 	# validation passes without improvement: 1
09/16 09:51:42 AM: edges-ner-ontonotes_loss: training: 0.069672 validation: 0.059554
09/16 09:51:42 AM: macro_avg: validation: 0.788878
09/16 09:51:42 AM: micro_avg: validation: 0.000000
09/16 09:51:42 AM: edges-ner-ontonotes_mcc: training: 0.729694 validation: 0.784054
09/16 09:51:42 AM: edges-ner-ontonotes_acc: training: 0.618152 validation: 0.681908
09/16 09:51:42 AM: edges-ner-ontonotes_precision: training: 0.836797 validation: 0.894378
09/16 09:51:42 AM: edges-ner-ontonotes_recall: training: 0.659280 validation: 0.705642
09/16 09:51:42 AM: edges-ner-ontonotes_f1: training: 0.737507 validation: 0.788878
09/16 09:51:42 AM: Global learning rate: 0.0001
09/16 09:51:42 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:51:49 AM: Update 23081: task edges-ner-ontonotes, batch 81 (23081): mcc: 0.6953, acc: 0.5755, precision: 0.8136, recall: 0.6191, f1: 0.7031, edges-ner-ontonotes_loss: 0.0782
09/16 09:51:59 AM: Update 23223: task edges-ner-ontonotes, batch 223 (23223): mcc: 0.6929, acc: 0.5710, precision: 0.8128, recall: 0.6158, f1: 0.7007, edges-ner-ontonotes_loss: 0.0794
09/16 09:52:09 AM: Update 23341: task edges-ner-ontonotes, batch 341 (23341): mcc: 0.6935, acc: 0.5718, precision: 0.8143, recall: 0.6154, f1: 0.7011, edges-ner-ontonotes_loss: 0.0792
09/16 09:52:19 AM: Update 23501: task edges-ner-ontonotes, batch 501 (23501): mcc: 0.6944, acc: 0.5720, precision: 0.8149, recall: 0.6166, f1: 0.7020, edges-ner-ontonotes_loss: 0.0787
09/16 09:52:30 AM: Update 23654: task edges-ner-ontonotes, batch 654 (23654): mcc: 0.6953, acc: 0.5729, precision: 0.8161, recall: 0.6171, f1: 0.7028, edges-ner-ontonotes_loss: 0.0783
09/16 09:52:40 AM: Update 23791: task edges-ner-ontonotes, batch 791 (23791): mcc: 0.6999, acc: 0.5796, precision: 0.8180, recall: 0.6234, f1: 0.7076, edges-ner-ontonotes_loss: 0.0770
09/16 09:52:50 AM: Update 23931: task edges-ner-ontonotes, batch 931 (23931): mcc: 0.7042, acc: 0.5855, precision: 0.8204, recall: 0.6288, f1: 0.7119, edges-ner-ontonotes_loss: 0.0760
09/16 09:52:58 AM: ***** Step 24000 / Validation 24 *****
09/16 09:52:58 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:52:58 AM: Validating...
09/16 09:53:00 AM: Evaluate: task edges-ner-ontonotes, batch 27 (157): mcc: 0.7353, acc: 0.6288, precision: 0.8595, recall: 0.6505, f1: 0.7405, edges-ner-ontonotes_loss: 0.0714
09/16 09:53:11 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.7798, acc: 0.6737, precision: 0.8997, recall: 0.6940, f1: 0.7836, edges-ner-ontonotes_loss: 0.0606
09/16 09:53:16 AM: Updating LR scheduler:
09/16 09:53:16 AM: 	Best result seen so far for macro_avg: 0.790
09/16 09:53:16 AM: 	# validation passes without improvement: 2
09/16 09:53:16 AM: edges-ner-ontonotes_loss: training: 0.075887 validation: 0.059687
09/16 09:53:16 AM: macro_avg: validation: 0.783709
09/16 09:53:16 AM: micro_avg: validation: 0.000000
09/16 09:53:16 AM: edges-ner-ontonotes_mcc: training: 0.704940 validation: 0.779688
09/16 09:53:16 AM: edges-ner-ontonotes_acc: training: 0.586609 validation: 0.673946
09/16 09:53:16 AM: edges-ner-ontonotes_precision: training: 0.820688 validation: 0.897953
09/16 09:53:16 AM: edges-ner-ontonotes_recall: training: 0.629885 validation: 0.695253
09/16 09:53:16 AM: edges-ner-ontonotes_f1: training: 0.712738 validation: 0.783709
09/16 09:53:16 AM: Global learning rate: 0.0001
09/16 09:53:16 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:53:21 AM: Update 24067: task edges-ner-ontonotes, batch 67 (24067): mcc: 0.7487, acc: 0.6439, precision: 0.8520, recall: 0.6796, f1: 0.7561, edges-ner-ontonotes_loss: 0.0664
09/16 09:53:31 AM: Update 24203: task edges-ner-ontonotes, batch 203 (24203): mcc: 0.7527, acc: 0.6454, precision: 0.8544, recall: 0.6846, f1: 0.7601, edges-ner-ontonotes_loss: 0.0653
09/16 09:53:41 AM: Update 24310: task edges-ner-ontonotes, batch 310 (24310): mcc: 0.7469, acc: 0.6376, precision: 0.8503, recall: 0.6780, f1: 0.7544, edges-ner-ontonotes_loss: 0.0662
09/16 09:53:51 AM: Update 24448: task edges-ner-ontonotes, batch 448 (24448): mcc: 0.7454, acc: 0.6361, precision: 0.8466, recall: 0.6785, f1: 0.7532, edges-ner-ontonotes_loss: 0.0664
09/16 09:54:01 AM: Update 24584: task edges-ner-ontonotes, batch 584 (24584): mcc: 0.7431, acc: 0.6332, precision: 0.8453, recall: 0.6755, f1: 0.7509, edges-ner-ontonotes_loss: 0.0671
09/16 09:54:11 AM: Update 24699: task edges-ner-ontonotes, batch 699 (24699): mcc: 0.7346, acc: 0.6223, precision: 0.8399, recall: 0.6652, f1: 0.7424, edges-ner-ontonotes_loss: 0.0695
09/16 09:54:21 AM: Update 24831: task edges-ner-ontonotes, batch 831 (24831): mcc: 0.7282, acc: 0.6145, precision: 0.8357, recall: 0.6577, f1: 0.7361, edges-ner-ontonotes_loss: 0.0713
09/16 09:54:31 AM: Update 24960: task edges-ner-ontonotes, batch 960 (24960): mcc: 0.7247, acc: 0.6098, precision: 0.8336, recall: 0.6533, f1: 0.7325, edges-ner-ontonotes_loss: 0.0724
09/16 09:54:34 AM: ***** Step 25000 / Validation 25 *****
09/16 09:54:34 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:54:34 AM: Validating...
09/16 09:54:42 AM: Evaluate: task edges-ner-ontonotes, batch 64 (157): mcc: 0.7806, acc: 0.6733, precision: 0.8878, recall: 0.7050, f1: 0.7859, edges-ner-ontonotes_loss: 0.0603
09/16 09:54:52 AM: Evaluate: task edges-ner-ontonotes, batch 146 (157): mcc: 0.7842, acc: 0.6729, precision: 0.9048, recall: 0.6975, f1: 0.7877, edges-ner-ontonotes_loss: 0.0581
09/16 09:54:53 AM: Updating LR scheduler:
09/16 09:54:53 AM: 	Best result seen so far for macro_avg: 0.790
09/16 09:54:53 AM: 	# validation passes without improvement: 3
09/16 09:54:53 AM: edges-ner-ontonotes_loss: training: 0.072691 validation: 0.058460
09/16 09:54:53 AM: macro_avg: validation: 0.785497
09/16 09:54:53 AM: micro_avg: validation: 0.000000
09/16 09:54:53 AM: edges-ner-ontonotes_mcc: training: 0.723618 validation: 0.781985
09/16 09:54:53 AM: edges-ner-ontonotes_acc: training: 0.608248 validation: 0.671065
09/16 09:54:53 AM: edges-ner-ontonotes_precision: training: 0.833039 validation: 0.903302
09/16 09:54:53 AM: edges-ner-ontonotes_recall: training: 0.651891 validation: 0.694874
09/16 09:54:53 AM: edges-ner-ontonotes_f1: training: 0.731415 validation: 0.785497
09/16 09:54:53 AM: Global learning rate: 0.0001
09/16 09:54:53 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:55:02 AM: Update 25142: task edges-ner-ontonotes, batch 142 (25142): mcc: 0.6971, acc: 0.5743, precision: 0.8202, recall: 0.6169, f1: 0.7042, edges-ner-ontonotes_loss: 0.0769
09/16 09:55:12 AM: Update 25262: task edges-ner-ontonotes, batch 262 (25262): mcc: 0.7013, acc: 0.5796, precision: 0.8223, recall: 0.6225, f1: 0.7086, edges-ner-ontonotes_loss: 0.0765
09/16 09:55:22 AM: Update 25403: task edges-ner-ontonotes, batch 403 (25403): mcc: 0.7105, acc: 0.5926, precision: 0.8263, recall: 0.6348, f1: 0.7180, edges-ner-ontonotes_loss: 0.0745
09/16 09:55:32 AM: Update 25523: task edges-ner-ontonotes, batch 523 (25523): mcc: 0.7141, acc: 0.5981, precision: 0.8280, recall: 0.6396, f1: 0.7217, edges-ner-ontonotes_loss: 0.0738
09/16 09:55:43 AM: Update 25651: task edges-ner-ontonotes, batch 651 (25651): mcc: 0.7194, acc: 0.6048, precision: 0.8311, recall: 0.6462, f1: 0.7271, edges-ner-ontonotes_loss: 0.0726
09/16 09:55:53 AM: Update 25784: task edges-ner-ontonotes, batch 784 (25784): mcc: 0.7253, acc: 0.6118, precision: 0.8357, recall: 0.6526, f1: 0.7329, edges-ner-ontonotes_loss: 0.0712
09/16 09:56:03 AM: Update 25899: task edges-ner-ontonotes, batch 899 (25899): mcc: 0.7267, acc: 0.6134, precision: 0.8358, recall: 0.6550, f1: 0.7344, edges-ner-ontonotes_loss: 0.0709
09/16 09:56:10 AM: ***** Step 26000 / Validation 26 *****
09/16 09:56:10 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:56:10 AM: Validating...
09/16 09:56:13 AM: Evaluate: task edges-ner-ontonotes, batch 29 (157): mcc: 0.7312, acc: 0.6219, precision: 0.8473, recall: 0.6533, f1: 0.7377, edges-ner-ontonotes_loss: 0.0742
09/16 09:56:23 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.7751, acc: 0.6706, precision: 0.8892, recall: 0.6945, f1: 0.7799, edges-ner-ontonotes_loss: 0.0626
09/16 09:56:28 AM: Updating LR scheduler:
09/16 09:56:28 AM: 	Best result seen so far for macro_avg: 0.790
09/16 09:56:28 AM: 	# validation passes without improvement: 0
09/16 09:56:28 AM: edges-ner-ontonotes_loss: training: 0.070620 validation: 0.060333
09/16 09:56:28 AM: macro_avg: validation: 0.786495
09/16 09:56:28 AM: micro_avg: validation: 0.000000
09/16 09:56:28 AM: edges-ner-ontonotes_mcc: training: 0.728192 validation: 0.781458
09/16 09:56:28 AM: edges-ner-ontonotes_acc: training: 0.615403 validation: 0.678647
09/16 09:56:28 AM: edges-ner-ontonotes_precision: training: 0.835751 validation: 0.891054
09/16 09:56:28 AM: edges-ner-ontonotes_recall: training: 0.657550 validation: 0.703897
09/16 09:56:28 AM: edges-ner-ontonotes_f1: training: 0.736017 validation: 0.786495
09/16 09:56:28 AM: Global learning rate: 5e-05
09/16 09:56:28 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:56:33 AM: Update 26065: task edges-ner-ontonotes, batch 65 (26065): mcc: 0.7395, acc: 0.6315, precision: 0.8452, recall: 0.6694, f1: 0.7471, edges-ner-ontonotes_loss: 0.0675
09/16 09:56:43 AM: Update 26177: task edges-ner-ontonotes, batch 177 (26177): mcc: 0.7226, acc: 0.6107, precision: 0.8300, recall: 0.6526, f1: 0.7307, edges-ner-ontonotes_loss: 0.0712
09/16 09:56:53 AM: Update 26318: task edges-ner-ontonotes, batch 318 (26318): mcc: 0.7114, acc: 0.5954, precision: 0.8252, recall: 0.6373, f1: 0.7192, edges-ner-ontonotes_loss: 0.0750
09/16 09:57:04 AM: Update 26453: task edges-ner-ontonotes, batch 453 (26453): mcc: 0.7070, acc: 0.5896, precision: 0.8246, recall: 0.6302, f1: 0.7144, edges-ner-ontonotes_loss: 0.0763
09/16 09:57:15 AM: Update 26619: task edges-ner-ontonotes, batch 619 (26619): mcc: 0.7045, acc: 0.5859, precision: 0.8230, recall: 0.6272, f1: 0.7119, edges-ner-ontonotes_loss: 0.0766
09/16 09:57:25 AM: Update 26766: task edges-ner-ontonotes, batch 766 (26766): mcc: 0.7040, acc: 0.5846, precision: 0.8233, recall: 0.6262, f1: 0.7113, edges-ner-ontonotes_loss: 0.0766
09/16 09:57:35 AM: Update 26903: task edges-ner-ontonotes, batch 903 (26903): mcc: 0.7066, acc: 0.5884, precision: 0.8242, recall: 0.6299, f1: 0.7141, edges-ner-ontonotes_loss: 0.0757
09/16 09:57:42 AM: ***** Step 27000 / Validation 27 *****
09/16 09:57:42 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:57:42 AM: Validating...
09/16 09:57:45 AM: Evaluate: task edges-ner-ontonotes, batch 35 (157): mcc: 0.7662, acc: 0.6637, precision: 0.8715, recall: 0.6937, f1: 0.7725, edges-ner-ontonotes_loss: 0.0638
09/16 09:57:55 AM: Evaluate: task edges-ner-ontonotes, batch 115 (157): mcc: 0.7909, acc: 0.6868, precision: 0.9041, recall: 0.7094, f1: 0.7950, edges-ner-ontonotes_loss: 0.0572
09/16 09:58:00 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:58:00 AM: Best result seen so far for macro.
09/16 09:58:00 AM: Updating LR scheduler:
09/16 09:58:00 AM: 	Best result seen so far for macro_avg: 0.792
09/16 09:58:00 AM: 	# validation passes without improvement: 0
09/16 09:58:00 AM: edges-ner-ontonotes_loss: training: 0.075236 validation: 0.056994
09/16 09:58:00 AM: macro_avg: validation: 0.792244
09/16 09:58:00 AM: micro_avg: validation: 0.000000
09/16 09:58:00 AM: edges-ner-ontonotes_mcc: training: 0.707798 validation: 0.788348
09/16 09:58:00 AM: edges-ner-ontonotes_acc: training: 0.590280 validation: 0.682590
09/16 09:58:00 AM: edges-ner-ontonotes_precision: training: 0.824165 validation: 0.904447
09/16 09:58:00 AM: edges-ner-ontonotes_recall: training: 0.631963 validation: 0.704807
09/16 09:58:00 AM: edges-ner-ontonotes_f1: training: 0.715379 validation: 0.792244
09/16 09:58:00 AM: Global learning rate: 5e-05
09/16 09:58:00 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:58:05 AM: Update 27070: task edges-ner-ontonotes, batch 70 (27070): mcc: 0.7257, acc: 0.6175, precision: 0.8338, recall: 0.6549, f1: 0.7336, edges-ner-ontonotes_loss: 0.0713
09/16 09:58:15 AM: Update 27175: task edges-ner-ontonotes, batch 175 (27175): mcc: 0.7324, acc: 0.6228, precision: 0.8386, recall: 0.6624, f1: 0.7402, edges-ner-ontonotes_loss: 0.0697
09/16 09:58:26 AM: Update 27307: task edges-ner-ontonotes, batch 307 (27307): mcc: 0.7392, acc: 0.6290, precision: 0.8441, recall: 0.6696, f1: 0.7468, edges-ner-ontonotes_loss: 0.0676
09/16 09:58:36 AM: Update 27426: task edges-ner-ontonotes, batch 426 (27426): mcc: 0.7398, acc: 0.6298, precision: 0.8440, recall: 0.6708, f1: 0.7475, edges-ner-ontonotes_loss: 0.0677
09/16 09:58:46 AM: Update 27561: task edges-ner-ontonotes, batch 561 (27561): mcc: 0.7415, acc: 0.6318, precision: 0.8444, recall: 0.6735, f1: 0.7493, edges-ner-ontonotes_loss: 0.0674
09/16 09:58:56 AM: Update 27698: task edges-ner-ontonotes, batch 698 (27698): mcc: 0.7407, acc: 0.6313, precision: 0.8436, recall: 0.6727, f1: 0.7485, edges-ner-ontonotes_loss: 0.0676
09/16 09:59:06 AM: Update 27801: task edges-ner-ontonotes, batch 801 (27801): mcc: 0.7334, acc: 0.6220, precision: 0.8387, recall: 0.6640, f1: 0.7412, edges-ner-ontonotes_loss: 0.0690
09/16 09:59:16 AM: Update 27946: task edges-ner-ontonotes, batch 946 (27946): mcc: 0.7286, acc: 0.6162, precision: 0.8356, recall: 0.6585, f1: 0.7365, edges-ner-ontonotes_loss: 0.0709
09/16 09:59:20 AM: ***** Step 28000 / Validation 28 *****
09/16 09:59:20 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:59:20 AM: Validating...
09/16 09:59:26 AM: Evaluate: task edges-ner-ontonotes, batch 56 (157): mcc: 0.7762, acc: 0.6683, precision: 0.8816, recall: 0.7027, f1: 0.7820, edges-ner-ontonotes_loss: 0.0617
09/16 09:59:37 AM: Evaluate: task edges-ner-ontonotes, batch 134 (157): mcc: 0.7943, acc: 0.6870, precision: 0.9068, recall: 0.7132, f1: 0.7984, edges-ner-ontonotes_loss: 0.0573
09/16 09:59:39 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:59:39 AM: Best result seen so far for macro.
09/16 09:59:39 AM: Updating LR scheduler:
09/16 09:59:39 AM: 	Best result seen so far for macro_avg: 0.794
09/16 09:59:39 AM: 	# validation passes without improvement: 0
09/16 09:59:39 AM: edges-ner-ontonotes_loss: training: 0.071439 validation: 0.057704
09/16 09:59:39 AM: macro_avg: validation: 0.794181
09/16 09:59:39 AM: micro_avg: validation: 0.000000
09/16 09:59:39 AM: edges-ner-ontonotes_mcc: training: 0.727197 validation: 0.789752
09/16 09:59:39 AM: edges-ner-ontonotes_acc: training: 0.614422 validation: 0.682514
09/16 09:59:39 AM: edges-ner-ontonotes_precision: training: 0.834865 validation: 0.901068
09/16 09:59:39 AM: edges-ner-ontonotes_recall: training: 0.656561 validation: 0.709964
09/16 09:59:39 AM: edges-ner-ontonotes_f1: training: 0.735055 validation: 0.794181
09/16 09:59:39 AM: Global learning rate: 5e-05
09/16 09:59:39 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 09:59:47 AM: Update 28080: task edges-ner-ontonotes, batch 80 (28080): mcc: 0.6956, acc: 0.5692, precision: 0.8169, recall: 0.6170, f1: 0.7030, edges-ner-ontonotes_loss: 0.0790
09/16 09:59:57 AM: Update 28248: task edges-ner-ontonotes, batch 248 (28248): mcc: 0.6956, acc: 0.5707, precision: 0.8174, recall: 0.6166, f1: 0.7029, edges-ner-ontonotes_loss: 0.0781
09/16 10:00:07 AM: Update 28373: task edges-ner-ontonotes, batch 373 (28373): mcc: 0.7004, acc: 0.5788, precision: 0.8191, recall: 0.6234, f1: 0.7080, edges-ner-ontonotes_loss: 0.0771
09/16 10:00:17 AM: Update 28509: task edges-ner-ontonotes, batch 509 (28509): mcc: 0.7066, acc: 0.5883, precision: 0.8225, recall: 0.6313, f1: 0.7143, edges-ner-ontonotes_loss: 0.0759
09/16 10:00:27 AM: Update 28635: task edges-ner-ontonotes, batch 635 (28635): mcc: 0.7106, acc: 0.5937, precision: 0.8251, recall: 0.6360, f1: 0.7183, edges-ner-ontonotes_loss: 0.0745
09/16 10:00:37 AM: Update 28764: task edges-ner-ontonotes, batch 764 (28764): mcc: 0.7178, acc: 0.6022, precision: 0.8303, recall: 0.6441, f1: 0.7255, edges-ner-ontonotes_loss: 0.0730
09/16 10:00:47 AM: Update 28901: task edges-ner-ontonotes, batch 901 (28901): mcc: 0.7233, acc: 0.6087, precision: 0.8336, recall: 0.6508, f1: 0.7310, edges-ner-ontonotes_loss: 0.0719
09/16 10:00:57 AM: ***** Step 29000 / Validation 29 *****
09/16 10:00:57 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:00:57 AM: Validating...
09/16 10:00:57 AM: Evaluate: task edges-ner-ontonotes, batch 3 (157): mcc: 0.6284, acc: 0.4951, precision: 0.7655, recall: 0.5441, f1: 0.6361, edges-ner-ontonotes_loss: 0.0954
09/16 10:01:07 AM: Evaluate: task edges-ner-ontonotes, batch 97 (157): mcc: 0.7822, acc: 0.6807, precision: 0.8912, recall: 0.7051, f1: 0.7873, edges-ner-ontonotes_loss: 0.0610
09/16 10:01:15 AM: Updating LR scheduler:
09/16 10:01:15 AM: 	Best result seen so far for macro_avg: 0.794
09/16 10:01:15 AM: 	# validation passes without improvement: 1
09/16 10:01:15 AM: edges-ner-ontonotes_loss: training: 0.071406 validation: 0.058459
09/16 10:01:15 AM: macro_avg: validation: 0.789295
09/16 10:01:15 AM: micro_avg: validation: 0.000000
09/16 10:01:15 AM: edges-ner-ontonotes_mcc: training: 0.724624 validation: 0.784579
09/16 10:01:15 AM: edges-ner-ontonotes_acc: training: 0.610106 validation: 0.680619
09/16 10:01:15 AM: edges-ner-ontonotes_precision: training: 0.834186 validation: 0.895573
09/16 10:01:15 AM: edges-ner-ontonotes_recall: training: 0.652683 validation: 0.705566
09/16 10:01:15 AM: edges-ner-ontonotes_f1: training: 0.732356 validation: 0.789295
09/16 10:01:15 AM: Global learning rate: 5e-05
09/16 10:01:15 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 10:01:17 AM: Update 29034: task edges-ner-ontonotes, batch 34 (29034): mcc: 0.7563, acc: 0.6519, precision: 0.8524, recall: 0.6924, f1: 0.7641, edges-ner-ontonotes_loss: 0.0702
09/16 10:01:30 AM: Update 29159: task edges-ner-ontonotes, batch 159 (29159): mcc: 0.7443, acc: 0.6350, precision: 0.8444, recall: 0.6783, f1: 0.7523, edges-ner-ontonotes_loss: 0.0676
09/16 10:01:40 AM: Update 29264: task edges-ner-ontonotes, batch 264 (29264): mcc: 0.7371, acc: 0.6257, precision: 0.8396, recall: 0.6698, f1: 0.7451, edges-ner-ontonotes_loss: 0.0685
09/16 10:01:50 AM: Update 29403: task edges-ner-ontonotes, batch 403 (29403): mcc: 0.7228, acc: 0.6079, precision: 0.8305, recall: 0.6525, f1: 0.7309, edges-ner-ontonotes_loss: 0.0727
09/16 10:02:00 AM: Update 29542: task edges-ner-ontonotes, batch 542 (29542): mcc: 0.7152, acc: 0.5985, precision: 0.8257, recall: 0.6433, f1: 0.7232, edges-ner-ontonotes_loss: 0.0747
09/16 10:02:10 AM: Update 29672: task edges-ner-ontonotes, batch 672 (29672): mcc: 0.7129, acc: 0.5951, precision: 0.8249, recall: 0.6401, f1: 0.7209, edges-ner-ontonotes_loss: 0.0753
09/16 10:02:20 AM: Update 29837: task edges-ner-ontonotes, batch 837 (29837): mcc: 0.7107, acc: 0.5924, precision: 0.8237, recall: 0.6373, f1: 0.7186, edges-ner-ontonotes_loss: 0.0755
09/16 10:02:30 AM: Update 29952: task edges-ner-ontonotes, batch 952 (29952): mcc: 0.7095, acc: 0.5909, precision: 0.8234, recall: 0.6355, f1: 0.7173, edges-ner-ontonotes_loss: 0.0756
09/16 10:02:33 AM: ***** Step 30000 / Validation 30 *****
09/16 10:02:33 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:02:33 AM: Validating...
09/16 10:02:40 AM: Evaluate: task edges-ner-ontonotes, batch 65 (157): mcc: 0.7807, acc: 0.6749, precision: 0.8929, recall: 0.7010, f1: 0.7854, edges-ner-ontonotes_loss: 0.0600
09/16 10:02:50 AM: Evaluate: task edges-ner-ontonotes, batch 148 (157): mcc: 0.7896, acc: 0.6825, precision: 0.9072, recall: 0.7048, f1: 0.7933, edges-ner-ontonotes_loss: 0.0569
09/16 10:02:51 AM: Updating LR scheduler:
09/16 10:02:51 AM: 	Best result seen so far for macro_avg: 0.794
09/16 10:02:51 AM: 	# validation passes without improvement: 2
09/16 10:02:51 AM: edges-ner-ontonotes_loss: training: 0.075266 validation: 0.057026
09/16 10:02:51 AM: macro_avg: validation: 0.792643
09/16 10:02:51 AM: micro_avg: validation: 0.000000
09/16 10:02:51 AM: edges-ner-ontonotes_mcc: training: 0.710601 validation: 0.788960
09/16 10:02:51 AM: edges-ner-ontonotes_acc: training: 0.592568 validation: 0.682135
09/16 10:02:51 AM: edges-ner-ontonotes_precision: training: 0.823920 validation: 0.906491
09/16 10:02:51 AM: edges-ner-ontonotes_recall: training: 0.636962 validation: 0.704201
09/16 10:02:51 AM: edges-ner-ontonotes_f1: training: 0.718478 validation: 0.792643
09/16 10:02:51 AM: Global learning rate: 5e-05
09/16 10:02:51 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 10:03:00 AM: Update 30132: task edges-ner-ontonotes, batch 132 (30132): mcc: 0.7345, acc: 0.6254, precision: 0.8385, recall: 0.6663, f1: 0.7425, edges-ner-ontonotes_loss: 0.0691
09/16 10:03:10 AM: Update 30237: task edges-ner-ontonotes, batch 237 (30237): mcc: 0.7272, acc: 0.6151, precision: 0.8325, recall: 0.6585, f1: 0.7354, edges-ner-ontonotes_loss: 0.0702
09/16 10:03:20 AM: Update 30370: task edges-ner-ontonotes, batch 370 (30370): mcc: 0.7348, acc: 0.6245, precision: 0.8385, recall: 0.6667, f1: 0.7428, edges-ner-ontonotes_loss: 0.0683
09/16 10:03:31 AM: Update 30504: task edges-ner-ontonotes, batch 504 (30504): mcc: 0.7395, acc: 0.6299, precision: 0.8416, recall: 0.6722, f1: 0.7474, edges-ner-ontonotes_loss: 0.0676
09/16 10:03:41 AM: Update 30638: task edges-ner-ontonotes, batch 638 (30638): mcc: 0.7378, acc: 0.6274, precision: 0.8405, recall: 0.6702, f1: 0.7458, edges-ner-ontonotes_loss: 0.0676
09/16 10:03:51 AM: Update 30773: task edges-ner-ontonotes, batch 773 (30773): mcc: 0.7393, acc: 0.6294, precision: 0.8414, recall: 0.6721, f1: 0.7473, edges-ner-ontonotes_loss: 0.0675
09/16 10:04:01 AM: Update 30873: task edges-ner-ontonotes, batch 873 (30873): mcc: 0.7337, acc: 0.6226, precision: 0.8379, recall: 0.6653, f1: 0.7417, edges-ner-ontonotes_loss: 0.0688
09/16 10:04:10 AM: ***** Step 31000 / Validation 31 *****
09/16 10:04:10 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:04:10 AM: Validating...
09/16 10:04:11 AM: Evaluate: task edges-ner-ontonotes, batch 15 (157): mcc: 0.7419, acc: 0.6286, precision: 0.8477, recall: 0.6713, f1: 0.7493, edges-ner-ontonotes_loss: 0.0687
09/16 10:04:22 AM: Evaluate: task edges-ner-ontonotes, batch 105 (157): mcc: 0.7947, acc: 0.6940, precision: 0.8928, recall: 0.7253, f1: 0.8004, edges-ner-ontonotes_loss: 0.0580
09/16 10:04:28 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:04:28 AM: Best result seen so far for macro.
09/16 10:04:28 AM: Updating LR scheduler:
09/16 10:04:28 AM: 	Best result seen so far for macro_avg: 0.795
09/16 10:04:28 AM: 	# validation passes without improvement: 0
09/16 10:04:28 AM: edges-ner-ontonotes_loss: training: 0.069985 validation: 0.057211
09/16 10:04:28 AM: macro_avg: validation: 0.795409
09/16 10:04:28 AM: micro_avg: validation: 0.000000
09/16 10:04:28 AM: edges-ner-ontonotes_mcc: training: 0.730292 validation: 0.790418
09/16 10:04:28 AM: edges-ner-ontonotes_acc: training: 0.618048 validation: 0.684638
09/16 10:04:28 AM: edges-ner-ontonotes_precision: training: 0.836464 validation: 0.896841
09/16 10:04:28 AM: edges-ner-ontonotes_recall: training: 0.660588 validation: 0.714589
09/16 10:04:28 AM: edges-ner-ontonotes_f1: training: 0.738195 validation: 0.795409
09/16 10:04:28 AM: Global learning rate: 5e-05
09/16 10:04:28 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 10:04:32 AM: Update 31047: task edges-ner-ontonotes, batch 47 (31047): mcc: 0.7219, acc: 0.6078, precision: 0.8362, recall: 0.6463, f1: 0.7291, edges-ner-ontonotes_loss: 0.0784
09/16 10:04:42 AM: Update 31163: task edges-ner-ontonotes, batch 163 (31163): mcc: 0.6978, acc: 0.5789, precision: 0.8192, recall: 0.6189, f1: 0.7051, edges-ner-ontonotes_loss: 0.0792
09/16 10:04:52 AM: Update 31320: task edges-ner-ontonotes, batch 320 (31320): mcc: 0.6975, acc: 0.5760, precision: 0.8189, recall: 0.6187, f1: 0.7049, edges-ner-ontonotes_loss: 0.0788
09/16 10:05:02 AM: Update 31446: task edges-ner-ontonotes, batch 446 (31446): mcc: 0.6979, acc: 0.5768, precision: 0.8179, recall: 0.6202, f1: 0.7055, edges-ner-ontonotes_loss: 0.0782
09/16 10:05:12 AM: Update 31589: task edges-ner-ontonotes, batch 589 (31589): mcc: 0.7069, acc: 0.5888, precision: 0.8228, recall: 0.6316, f1: 0.7146, edges-ner-ontonotes_loss: 0.0760
09/16 10:05:22 AM: Update 31727: task edges-ner-ontonotes, batch 727 (31727): mcc: 0.7109, acc: 0.5942, precision: 0.8247, recall: 0.6369, f1: 0.7187, edges-ner-ontonotes_loss: 0.0752
09/16 10:05:32 AM: Update 31835: task edges-ner-ontonotes, batch 835 (31835): mcc: 0.7138, acc: 0.5974, precision: 0.8268, recall: 0.6402, f1: 0.7216, edges-ner-ontonotes_loss: 0.0744
09/16 10:05:42 AM: Update 31975: task edges-ner-ontonotes, batch 975 (31975): mcc: 0.7205, acc: 0.6056, precision: 0.8309, recall: 0.6482, f1: 0.7283, edges-ner-ontonotes_loss: 0.0729
09/16 10:05:44 AM: ***** Step 32000 / Validation 32 *****
09/16 10:05:44 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:05:44 AM: Validating...
09/16 10:05:52 AM: Evaluate: task edges-ner-ontonotes, batch 78 (157): mcc: 0.7698, acc: 0.6640, precision: 0.8889, recall: 0.6856, f1: 0.7741, edges-ner-ontonotes_loss: 0.0636
09/16 10:06:01 AM: Updating LR scheduler:
09/16 10:06:01 AM: 	Best result seen so far for macro_avg: 0.795
09/16 10:06:01 AM: 	# validation passes without improvement: 1
09/16 10:06:01 AM: edges-ner-ontonotes_loss: training: 0.072722 validation: 0.058742
09/16 10:06:01 AM: macro_avg: validation: 0.787365
09/16 10:06:01 AM: micro_avg: validation: 0.000000
09/16 10:06:01 AM: edges-ner-ontonotes_mcc: training: 0.721355 validation: 0.783216
09/16 10:06:01 AM: edges-ner-ontonotes_acc: training: 0.606761 validation: 0.678420
09/16 10:06:01 AM: edges-ner-ontonotes_precision: training: 0.831493 validation: 0.899221
09/16 10:06:01 AM: edges-ner-ontonotes_recall: training: 0.649262 validation: 0.700258
09/16 10:06:01 AM: edges-ner-ontonotes_f1: training: 0.729164 validation: 0.787365
09/16 10:06:01 AM: Global learning rate: 5e-05
09/16 10:06:01 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 10:06:02 AM: Update 32006: task edges-ner-ontonotes, batch 6 (32006): mcc: 0.7559, acc: 0.6541, precision: 0.8636, recall: 0.6824, f1: 0.7624, edges-ner-ontonotes_loss: 0.0674
09/16 10:06:12 AM: Update 32117: task edges-ner-ontonotes, batch 117 (32117): mcc: 0.7310, acc: 0.6221, precision: 0.8357, recall: 0.6624, f1: 0.7390, edges-ner-ontonotes_loss: 0.0678
09/16 10:06:22 AM: Update 32251: task edges-ner-ontonotes, batch 251 (32251): mcc: 0.7372, acc: 0.6284, precision: 0.8398, recall: 0.6699, f1: 0.7453, edges-ner-ontonotes_loss: 0.0673
09/16 10:06:32 AM: Update 32373: task edges-ner-ontonotes, batch 373 (32373): mcc: 0.7350, acc: 0.6242, precision: 0.8390, recall: 0.6666, f1: 0.7429, edges-ner-ontonotes_loss: 0.0678
09/16 10:06:42 AM: Update 32507: task edges-ner-ontonotes, batch 507 (32507): mcc: 0.7234, acc: 0.6094, precision: 0.8319, recall: 0.6524, f1: 0.7313, edges-ner-ontonotes_loss: 0.0712
09/16 10:06:52 AM: Update 32649: task edges-ner-ontonotes, batch 649 (32649): mcc: 0.7193, acc: 0.6042, precision: 0.8297, recall: 0.6472, f1: 0.7272, edges-ner-ontonotes_loss: 0.0731
09/16 10:07:02 AM: Update 32782: task edges-ner-ontonotes, batch 782 (32782): mcc: 0.7164, acc: 0.6004, precision: 0.8284, recall: 0.6433, f1: 0.7242, edges-ner-ontonotes_loss: 0.0738
09/16 10:07:13 AM: Update 32943: task edges-ner-ontonotes, batch 943 (32943): mcc: 0.7143, acc: 0.5975, precision: 0.8273, recall: 0.6406, f1: 0.7220, edges-ner-ontonotes_loss: 0.0743
09/16 10:07:18 AM: ***** Step 33000 / Validation 33 *****
09/16 10:07:18 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:07:18 AM: Validating...
09/16 10:07:23 AM: Evaluate: task edges-ner-ontonotes, batch 45 (157): mcc: 0.7749, acc: 0.6655, precision: 0.8823, recall: 0.6998, f1: 0.7805, edges-ner-ontonotes_loss: 0.0612
09/16 10:07:33 AM: Evaluate: task edges-ner-ontonotes, batch 122 (157): mcc: 0.7903, acc: 0.6810, precision: 0.9087, recall: 0.7047, f1: 0.7938, edges-ner-ontonotes_loss: 0.0572
09/16 10:07:37 AM: Updating LR scheduler:
09/16 10:07:37 AM: 	Best result seen so far for macro_avg: 0.795
09/16 10:07:37 AM: 	# validation passes without improvement: 2
09/16 10:07:37 AM: edges-ner-ontonotes_loss: training: 0.074586 validation: 0.056973
09/16 10:07:37 AM: macro_avg: validation: 0.792112
09/16 10:07:37 AM: micro_avg: validation: 0.000000
09/16 10:07:37 AM: edges-ner-ontonotes_mcc: training: 0.712497 validation: 0.788727
09/16 10:07:37 AM: edges-ner-ontonotes_acc: training: 0.595132 validation: 0.678571
09/16 10:07:37 AM: edges-ner-ontonotes_precision: training: 0.826073 validation: 0.908636
09/16 10:07:37 AM: edges-ner-ontonotes_recall: training: 0.638462 validation: 0.702078
09/16 10:07:37 AM: edges-ner-ontonotes_f1: training: 0.720251 validation: 0.792112
09/16 10:07:37 AM: Global learning rate: 5e-05
09/16 10:07:37 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 10:07:43 AM: Update 33083: task edges-ner-ontonotes, batch 83 (33083): mcc: 0.7138, acc: 0.6014, precision: 0.8181, recall: 0.6472, f1: 0.7227, edges-ner-ontonotes_loss: 0.0742
09/16 10:07:53 AM: Update 33222: task edges-ner-ontonotes, batch 222 (33222): mcc: 0.7248, acc: 0.6142, precision: 0.8299, recall: 0.6565, f1: 0.7331, edges-ner-ontonotes_loss: 0.0707
09/16 10:08:03 AM: Update 33320: task edges-ner-ontonotes, batch 320 (33320): mcc: 0.7228, acc: 0.6108, precision: 0.8293, recall: 0.6536, f1: 0.7310, edges-ner-ontonotes_loss: 0.0710
09/16 10:08:13 AM: Update 33452: task edges-ner-ontonotes, batch 452 (33452): mcc: 0.7293, acc: 0.6184, precision: 0.8351, recall: 0.6601, f1: 0.7373, edges-ner-ontonotes_loss: 0.0696
09/16 10:08:23 AM: Update 33585: task edges-ner-ontonotes, batch 585 (33585): mcc: 0.7354, acc: 0.6255, precision: 0.8387, recall: 0.6675, f1: 0.7434, edges-ner-ontonotes_loss: 0.0685
09/16 10:08:33 AM: Update 33707: task edges-ner-ontonotes, batch 707 (33707): mcc: 0.7363, acc: 0.6266, precision: 0.8394, recall: 0.6686, f1: 0.7444, edges-ner-ontonotes_loss: 0.0683
09/16 10:08:43 AM: Update 33839: task edges-ner-ontonotes, batch 839 (33839): mcc: 0.7368, acc: 0.6273, precision: 0.8397, recall: 0.6691, f1: 0.7448, edges-ner-ontonotes_loss: 0.0682
09/16 10:08:53 AM: Update 33948: task edges-ner-ontonotes, batch 948 (33948): mcc: 0.7340, acc: 0.6238, precision: 0.8379, recall: 0.6658, f1: 0.7420, edges-ner-ontonotes_loss: 0.0687
09/16 10:08:57 AM: ***** Step 34000 / Validation 34 *****
09/16 10:08:57 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:08:57 AM: Validating...
09/16 10:09:03 AM: Evaluate: task edges-ner-ontonotes, batch 62 (157): mcc: 0.7812, acc: 0.6745, precision: 0.8836, recall: 0.7096, f1: 0.7871, edges-ner-ontonotes_loss: 0.0597
09/16 10:09:13 AM: Evaluate: task edges-ner-ontonotes, batch 145 (157): mcc: 0.7896, acc: 0.6811, precision: 0.9042, recall: 0.7071, f1: 0.7936, edges-ner-ontonotes_loss: 0.0568
09/16 10:09:14 AM: Updating LR scheduler:
09/16 10:09:14 AM: 	Best result seen so far for macro_avg: 0.795
09/16 10:09:14 AM: 	# validation passes without improvement: 3
09/16 10:09:14 AM: edges-ner-ontonotes_loss: training: 0.069175 validation: 0.057190
09/16 10:09:14 AM: macro_avg: validation: 0.791475
09/16 10:09:14 AM: micro_avg: validation: 0.000000
09/16 10:09:14 AM: edges-ner-ontonotes_mcc: training: 0.732638 validation: 0.787285
09/16 10:09:14 AM: edges-ner-ontonotes_acc: training: 0.621946 validation: 0.679026
09/16 10:09:14 AM: edges-ner-ontonotes_precision: training: 0.837478 validation: 0.901453
09/16 10:09:14 AM: edges-ner-ontonotes_recall: training: 0.663809 validation: 0.705414
09/16 10:09:14 AM: edges-ner-ontonotes_f1: training: 0.740598 validation: 0.791475
09/16 10:09:14 AM: Global learning rate: 5e-05
09/16 10:09:14 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 10:09:23 AM: Update 34126: task edges-ner-ontonotes, batch 126 (34126): mcc: 0.6941, acc: 0.5750, precision: 0.8122, recall: 0.6182, f1: 0.7020, edges-ner-ontonotes_loss: 0.0800
09/16 10:09:33 AM: Update 34243: task edges-ner-ontonotes, batch 243 (34243): mcc: 0.6935, acc: 0.5739, precision: 0.8133, recall: 0.6164, f1: 0.7013, edges-ner-ontonotes_loss: 0.0802
09/16 10:09:44 AM: Update 34407: task edges-ner-ontonotes, batch 407 (34407): mcc: 0.6950, acc: 0.5738, precision: 0.8150, recall: 0.6175, f1: 0.7026, edges-ner-ontonotes_loss: 0.0791
09/16 10:09:54 AM: Update 34546: task edges-ner-ontonotes, batch 546 (34546): mcc: 0.6963, acc: 0.5752, precision: 0.8161, recall: 0.6189, f1: 0.7039, edges-ner-ontonotes_loss: 0.0784
09/16 10:10:04 AM: Update 34680: task edges-ner-ontonotes, batch 680 (34680): mcc: 0.7005, acc: 0.5805, precision: 0.8182, recall: 0.6242, f1: 0.7082, edges-ner-ontonotes_loss: 0.0773
09/16 10:10:14 AM: Update 34820: task edges-ner-ontonotes, batch 820 (34820): mcc: 0.7066, acc: 0.5889, precision: 0.8220, recall: 0.6317, f1: 0.7144, edges-ner-ontonotes_loss: 0.0760
09/16 10:10:24 AM: Update 34939: task edges-ner-ontonotes, batch 939 (34939): mcc: 0.7112, acc: 0.5945, precision: 0.8249, recall: 0.6371, f1: 0.7190, edges-ner-ontonotes_loss: 0.0749
09/16 10:10:29 AM: ***** Step 35000 / Validation 35 *****
09/16 10:10:29 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:10:29 AM: Validating...
09/16 10:10:34 AM: Evaluate: task edges-ner-ontonotes, batch 55 (157): mcc: 0.7514, acc: 0.6410, precision: 0.8797, recall: 0.6617, f1: 0.7553, edges-ner-ontonotes_loss: 0.0656
09/16 10:10:44 AM: Evaluate: task edges-ner-ontonotes, batch 135 (157): mcc: 0.7790, acc: 0.6689, precision: 0.9064, recall: 0.6873, f1: 0.7818, edges-ner-ontonotes_loss: 0.0591
09/16 10:10:47 AM: Updating LR scheduler:
09/16 10:10:47 AM: 	Best result seen so far for macro_avg: 0.795
09/16 10:10:47 AM: 	# validation passes without improvement: 0
09/16 10:10:47 AM: edges-ner-ontonotes_loss: training: 0.074248 validation: 0.059502
09/16 10:10:47 AM: macro_avg: validation: 0.778988
09/16 10:10:47 AM: micro_avg: validation: 0.000000
09/16 10:10:47 AM: edges-ner-ontonotes_mcc: training: 0.714110 validation: 0.775759
09/16 10:10:47 AM: edges-ner-ontonotes_acc: training: 0.597952 validation: 0.666591
09/16 10:10:47 AM: edges-ner-ontonotes_precision: training: 0.827141 validation: 0.901265
09/16 10:10:47 AM: edges-ner-ontonotes_recall: training: 0.640362 validation: 0.685927
09/16 10:10:47 AM: edges-ner-ontonotes_f1: training: 0.721865 validation: 0.778988
09/16 10:10:47 AM: Global learning rate: 2.5e-05
09/16 10:10:47 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 10:10:54 AM: Update 35090: task edges-ner-ontonotes, batch 90 (35090): mcc: 0.7456, acc: 0.6356, precision: 0.8532, recall: 0.6732, f1: 0.7526, edges-ner-ontonotes_loss: 0.0659
09/16 10:11:05 AM: Update 35193: task edges-ner-ontonotes, batch 193 (35193): mcc: 0.7451, acc: 0.6361, precision: 0.8491, recall: 0.6757, f1: 0.7525, edges-ner-ontonotes_loss: 0.0659
09/16 10:11:15 AM: Update 35323: task edges-ner-ontonotes, batch 323 (35323): mcc: 0.7419, acc: 0.6317, precision: 0.8455, recall: 0.6732, f1: 0.7495, edges-ner-ontonotes_loss: 0.0670
09/16 10:11:25 AM: Update 35461: task edges-ner-ontonotes, batch 461 (35461): mcc: 0.7441, acc: 0.6346, precision: 0.8461, recall: 0.6765, f1: 0.7519, edges-ner-ontonotes_loss: 0.0668
09/16 10:11:35 AM: Update 35585: task edges-ner-ontonotes, batch 585 (35585): mcc: 0.7346, acc: 0.6230, precision: 0.8406, recall: 0.6645, f1: 0.7423, edges-ner-ontonotes_loss: 0.0693
09/16 10:11:45 AM: Update 35724: task edges-ner-ontonotes, batch 724 (35724): mcc: 0.7269, acc: 0.6136, precision: 0.8354, recall: 0.6556, f1: 0.7346, edges-ner-ontonotes_loss: 0.0713
09/16 10:11:55 AM: Update 35854: task edges-ner-ontonotes, batch 854 (35854): mcc: 0.7226, acc: 0.6084, precision: 0.8323, recall: 0.6508, f1: 0.7304, edges-ner-ontonotes_loss: 0.0726
09/16 10:12:03 AM: ***** Step 36000 / Validation 36 *****
09/16 10:12:03 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:12:03 AM: Validating...
09/16 10:12:05 AM: Evaluate: task edges-ner-ontonotes, batch 17 (157): mcc: 0.7539, acc: 0.6353, precision: 0.8690, recall: 0.6747, f1: 0.7596, edges-ner-ontonotes_loss: 0.0650
09/16 10:12:15 AM: Evaluate: task edges-ner-ontonotes, batch 108 (157): mcc: 0.7900, acc: 0.6834, precision: 0.9023, recall: 0.7094, f1: 0.7943, edges-ner-ontonotes_loss: 0.0576
09/16 10:12:21 AM: Updating LR scheduler:
09/16 10:12:21 AM: 	Best result seen so far for macro_avg: 0.795
09/16 10:12:21 AM: 	# validation passes without improvement: 1
09/16 10:12:21 AM: edges-ner-ontonotes_loss: training: 0.073062 validation: 0.056946
09/16 10:12:21 AM: macro_avg: validation: 0.791311
09/16 10:12:21 AM: micro_avg: validation: 0.000000
09/16 10:12:21 AM: edges-ner-ontonotes_mcc: training: 0.720888 validation: 0.787553
09/16 10:12:21 AM: edges-ner-ontonotes_acc: training: 0.605895 validation: 0.677889
09/16 10:12:21 AM: edges-ner-ontonotes_precision: training: 0.831187 validation: 0.905018
09/16 10:12:21 AM: edges-ner-ontonotes_recall: training: 0.648707 validation: 0.702988
09/16 10:12:21 AM: edges-ner-ontonotes_f1: training: 0.728697 validation: 0.791311
09/16 10:12:21 AM: Global learning rate: 2.5e-05
09/16 10:12:21 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 10:12:25 AM: Update 36063: task edges-ner-ontonotes, batch 63 (36063): mcc: 0.7024, acc: 0.5790, precision: 0.8243, recall: 0.6227, f1: 0.7094, edges-ner-ontonotes_loss: 0.0748
09/16 10:12:35 AM: Update 36171: task edges-ner-ontonotes, batch 171 (36171): mcc: 0.7073, acc: 0.5882, precision: 0.8264, recall: 0.6294, f1: 0.7146, edges-ner-ontonotes_loss: 0.0738
09/16 10:12:45 AM: Update 36307: task edges-ner-ontonotes, batch 307 (36307): mcc: 0.7191, acc: 0.6020, precision: 0.8322, recall: 0.6448, f1: 0.7266, edges-ner-ontonotes_loss: 0.0720
09/16 10:12:55 AM: Update 36429: task edges-ner-ontonotes, batch 429 (36429): mcc: 0.7200, acc: 0.6051, precision: 0.8305, recall: 0.6477, f1: 0.7278, edges-ner-ontonotes_loss: 0.0717
09/16 10:13:05 AM: Update 36560: task edges-ner-ontonotes, batch 560 (36560): mcc: 0.7271, acc: 0.6138, precision: 0.8351, recall: 0.6562, f1: 0.7349, edges-ner-ontonotes_loss: 0.0704
09/16 10:13:15 AM: Update 36698: task edges-ner-ontonotes, batch 698 (36698): mcc: 0.7337, acc: 0.6219, precision: 0.8397, recall: 0.6638, f1: 0.7415, edges-ner-ontonotes_loss: 0.0691
09/16 10:13:25 AM: Update 36807: task edges-ner-ontonotes, batch 807 (36807): mcc: 0.7347, acc: 0.6224, precision: 0.8406, recall: 0.6647, f1: 0.7424, edges-ner-ontonotes_loss: 0.0689
09/16 10:13:35 AM: Update 36939: task edges-ner-ontonotes, batch 939 (36939): mcc: 0.7341, acc: 0.6221, precision: 0.8394, recall: 0.6648, f1: 0.7420, edges-ner-ontonotes_loss: 0.0690
09/16 10:13:40 AM: ***** Step 37000 / Validation 37 *****
09/16 10:13:40 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:13:40 AM: Validating...
09/16 10:13:45 AM: Evaluate: task edges-ner-ontonotes, batch 55 (157): mcc: 0.7642, acc: 0.6566, precision: 0.8750, recall: 0.6873, f1: 0.7699, edges-ner-ontonotes_loss: 0.0637
09/16 10:13:55 AM: Evaluate: task edges-ner-ontonotes, batch 135 (157): mcc: 0.7881, acc: 0.6829, precision: 0.9019, recall: 0.7065, f1: 0.7923, edges-ner-ontonotes_loss: 0.0576
09/16 10:13:58 AM: Updating LR scheduler:
09/16 10:13:58 AM: 	Best result seen so far for macro_avg: 0.795
09/16 10:13:58 AM: 	# validation passes without improvement: 2
09/16 10:13:58 AM: edges-ner-ontonotes_loss: training: 0.068926 validation: 0.057934
09/16 10:13:58 AM: macro_avg: validation: 0.789811
09/16 10:13:58 AM: micro_avg: validation: 0.000000
09/16 10:13:58 AM: edges-ner-ontonotes_mcc: training: 0.734929 validation: 0.785254
09/16 10:13:58 AM: edges-ner-ontonotes_acc: training: 0.623523 validation: 0.680391
09/16 10:13:58 AM: edges-ner-ontonotes_precision: training: 0.839431 validation: 0.897270
09/16 10:13:58 AM: edges-ner-ontonotes_recall: training: 0.666156 validation: 0.705338
09/16 10:13:58 AM: edges-ner-ontonotes_f1: training: 0.742822 validation: 0.789811
09/16 10:13:58 AM: Global learning rate: 2.5e-05
09/16 10:13:58 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 10:14:05 AM: Update 37080: task edges-ner-ontonotes, batch 80 (37080): mcc: 0.7129, acc: 0.5993, precision: 0.8273, recall: 0.6381, f1: 0.7205, edges-ner-ontonotes_loss: 0.0746
09/16 10:14:15 AM: Update 37209: task edges-ner-ontonotes, batch 209 (37209): mcc: 0.6982, acc: 0.5802, precision: 0.8165, recall: 0.6217, f1: 0.7059, edges-ner-ontonotes_loss: 0.0774
09/16 10:14:27 AM: Update 37345: task edges-ner-ontonotes, batch 345 (37345): mcc: 0.6982, acc: 0.5795, precision: 0.8157, recall: 0.6224, f1: 0.7060, edges-ner-ontonotes_loss: 0.0785
09/16 10:14:37 AM: Update 37508: task edges-ner-ontonotes, batch 508 (37508): mcc: 0.6978, acc: 0.5787, precision: 0.8155, recall: 0.6219, f1: 0.7057, edges-ner-ontonotes_loss: 0.0779
09/16 10:14:48 AM: Update 37658: task edges-ner-ontonotes, batch 658 (37658): mcc: 0.6990, acc: 0.5796, precision: 0.8170, recall: 0.6226, f1: 0.7067, edges-ner-ontonotes_loss: 0.0776
09/16 10:14:58 AM: Update 37798: task edges-ner-ontonotes, batch 798 (37798): mcc: 0.7028, acc: 0.5845, precision: 0.8195, recall: 0.6271, f1: 0.7105, edges-ner-ontonotes_loss: 0.0764
09/16 10:15:09 AM: Update 37938: task edges-ner-ontonotes, batch 938 (37938): mcc: 0.7066, acc: 0.5891, precision: 0.8221, recall: 0.6316, f1: 0.7144, edges-ner-ontonotes_loss: 0.0756
09/16 10:15:15 AM: ***** Step 38000 / Validation 38 *****
09/16 10:15:15 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:15:15 AM: Validating...
09/16 10:15:19 AM: Evaluate: task edges-ner-ontonotes, batch 37 (157): mcc: 0.7570, acc: 0.6536, precision: 0.8635, recall: 0.6845, f1: 0.7636, edges-ner-ontonotes_loss: 0.0655
09/16 10:15:30 AM: Evaluate: task edges-ner-ontonotes, batch 117 (157): mcc: 0.7845, acc: 0.6818, precision: 0.8945, recall: 0.7063, f1: 0.7894, edges-ner-ontonotes_loss: 0.0591
09/16 10:15:34 AM: Updating LR scheduler:
09/16 10:15:34 AM: 	Best result seen so far for macro_avg: 0.795
09/16 10:15:34 AM: 	# validation passes without improvement: 3
09/16 10:15:34 AM: edges-ner-ontonotes_loss: training: 0.075240 validation: 0.058191
09/16 10:15:34 AM: macro_avg: validation: 0.790680
09/16 10:15:34 AM: micro_avg: validation: 0.000000
09/16 10:15:34 AM: edges-ner-ontonotes_mcc: training: 0.707194 validation: 0.785664
09/16 10:15:34 AM: edges-ner-ontonotes_acc: training: 0.589785 validation: 0.683348
09/16 10:15:34 AM: edges-ner-ontonotes_precision: training: 0.822457 validation: 0.893786
09/16 10:15:34 AM: edges-ner-ontonotes_recall: training: 0.632310 validation: 0.708902
09/16 10:15:34 AM: edges-ner-ontonotes_f1: training: 0.714957 validation: 0.790680
09/16 10:15:34 AM: Global learning rate: 2.5e-05
09/16 10:15:34 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 10:15:40 AM: Update 38077: task edges-ner-ontonotes, batch 77 (38077): mcc: 0.7639, acc: 0.6593, precision: 0.8609, recall: 0.6986, f1: 0.7713, edges-ner-ontonotes_loss: 0.0638
09/16 10:15:50 AM: Update 38205: task edges-ner-ontonotes, batch 205 (38205): mcc: 0.7506, acc: 0.6428, precision: 0.8523, recall: 0.6827, f1: 0.7581, edges-ner-ontonotes_loss: 0.0657
09/16 10:16:00 AM: Update 38318: task edges-ner-ontonotes, batch 318 (38318): mcc: 0.7505, acc: 0.6427, precision: 0.8526, recall: 0.6822, f1: 0.7579, edges-ner-ontonotes_loss: 0.0652
09/16 10:16:10 AM: Update 38456: task edges-ner-ontonotes, batch 456 (38456): mcc: 0.7465, acc: 0.6379, precision: 0.8479, recall: 0.6792, f1: 0.7542, edges-ner-ontonotes_loss: 0.0661
09/16 10:16:20 AM: Update 38588: task edges-ner-ontonotes, batch 588 (38588): mcc: 0.7438, acc: 0.6343, precision: 0.8456, recall: 0.6764, f1: 0.7516, edges-ner-ontonotes_loss: 0.0667
09/16 10:16:30 AM: Update 38708: task edges-ner-ontonotes, batch 708 (38708): mcc: 0.7339, acc: 0.6223, precision: 0.8390, recall: 0.6648, f1: 0.7418, edges-ner-ontonotes_loss: 0.0694
09/16 10:16:40 AM: Update 38856: task edges-ner-ontonotes, batch 856 (38856): mcc: 0.7305, acc: 0.6179, precision: 0.8376, recall: 0.6600, f1: 0.7383, edges-ner-ontonotes_loss: 0.0707
09/16 10:16:50 AM: Update 38988: task edges-ner-ontonotes, batch 988 (38988): mcc: 0.7260, acc: 0.6123, precision: 0.8349, recall: 0.6544, f1: 0.7337, edges-ner-ontonotes_loss: 0.0718
09/16 10:16:50 AM: ***** Step 39000 / Validation 39 *****
09/16 10:16:50 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:16:50 AM: Validating...
09/16 10:17:00 AM: Evaluate: task edges-ner-ontonotes, batch 84 (157): mcc: 0.7932, acc: 0.6880, precision: 0.8984, recall: 0.7181, f1: 0.7982, edges-ner-ontonotes_loss: 0.0577
09/16 10:17:09 AM: Updating LR scheduler:
09/16 10:17:09 AM: 	Best result seen so far for macro_avg: 0.795
09/16 10:17:09 AM: 	# validation passes without improvement: 0
09/16 10:17:09 AM: edges-ner-ontonotes_loss: training: 0.071803 validation: 0.056588
09/16 10:17:09 AM: macro_avg: validation: 0.793562
09/16 10:17:09 AM: micro_avg: validation: 0.000000
09/16 10:17:09 AM: edges-ner-ontonotes_mcc: training: 0.725794 validation: 0.789635
09/16 10:17:09 AM: edges-ner-ontonotes_acc: training: 0.612066 validation: 0.680315
09/16 10:17:09 AM: edges-ner-ontonotes_precision: training: 0.834781 validation: 0.905012
09/16 10:17:09 AM: edges-ner-ontonotes_recall: training: 0.654209 validation: 0.706551
09/16 10:17:09 AM: edges-ner-ontonotes_f1: training: 0.733546 validation: 0.793562
09/16 10:17:09 AM: Global learning rate: 1.25e-05
09/16 10:17:09 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 10:17:10 AM: Update 39020: task edges-ner-ontonotes, batch 20 (39020): mcc: 0.6999, acc: 0.5752, precision: 0.8171, recall: 0.6242, f1: 0.7077, edges-ner-ontonotes_loss: 0.0786
09/16 10:17:20 AM: Update 39185: task edges-ner-ontonotes, batch 185 (39185): mcc: 0.7073, acc: 0.5855, precision: 0.8265, recall: 0.6293, f1: 0.7145, edges-ner-ontonotes_loss: 0.0748
09/16 10:17:30 AM: Update 39306: task edges-ner-ontonotes, batch 306 (39306): mcc: 0.7110, acc: 0.5911, precision: 0.8272, recall: 0.6350, f1: 0.7185, edges-ner-ontonotes_loss: 0.0737
09/16 10:17:40 AM: Update 39442: task edges-ner-ontonotes, batch 442 (39442): mcc: 0.7176, acc: 0.6014, precision: 0.8299, recall: 0.6441, f1: 0.7253, edges-ner-ontonotes_loss: 0.0728
09/16 10:17:50 AM: Update 39552: task edges-ner-ontonotes, batch 552 (39552): mcc: 0.7195, acc: 0.6035, precision: 0.8316, recall: 0.6459, f1: 0.7271, edges-ner-ontonotes_loss: 0.0723
09/16 10:18:00 AM: Update 39689: task edges-ner-ontonotes, batch 689 (39689): mcc: 0.7280, acc: 0.6139, precision: 0.8359, recall: 0.6571, f1: 0.7358, edges-ner-ontonotes_loss: 0.0707
09/16 10:18:10 AM: Update 39814: task edges-ner-ontonotes, batch 814 (39814): mcc: 0.7312, acc: 0.6179, precision: 0.8383, recall: 0.6606, f1: 0.7389, edges-ner-ontonotes_loss: 0.0699
09/16 10:18:20 AM: Update 39936: task edges-ner-ontonotes, batch 936 (39936): mcc: 0.7321, acc: 0.6196, precision: 0.8382, recall: 0.6622, f1: 0.7399, edges-ner-ontonotes_loss: 0.0698
09/16 10:18:25 AM: ***** Step 40000 / Validation 40 *****
09/16 10:18:25 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:18:25 AM: Validating...
09/16 10:18:30 AM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.7662, acc: 0.6600, precision: 0.8785, recall: 0.6879, f1: 0.7716, edges-ner-ontonotes_loss: 0.0641
09/16 10:18:40 AM: Evaluate: task edges-ner-ontonotes, batch 134 (157): mcc: 0.7936, acc: 0.6894, precision: 0.9070, recall: 0.7117, f1: 0.7976, edges-ner-ontonotes_loss: 0.0572
09/16 10:18:43 AM: Updating LR scheduler:
09/16 10:18:43 AM: 	Best result seen so far for macro_avg: 0.795
09/16 10:18:43 AM: 	# validation passes without improvement: 1
09/16 10:18:43 AM: edges-ner-ontonotes_loss: training: 0.069655 validation: 0.057493
09/16 10:18:43 AM: macro_avg: validation: 0.794826
09/16 10:18:43 AM: micro_avg: validation: 0.000000
09/16 10:18:43 AM: edges-ner-ontonotes_mcc: training: 0.732225 validation: 0.790430
09/16 10:18:43 AM: edges-ner-ontonotes_acc: training: 0.619470 validation: 0.687064
09/16 10:18:43 AM: edges-ner-ontonotes_precision: training: 0.838146 validation: 0.901751
09/16 10:18:43 AM: edges-ner-ontonotes_recall: training: 0.662540 validation: 0.710570
09/16 10:18:43 AM: edges-ner-ontonotes_f1: training: 0.740068 validation: 0.794826
09/16 10:18:43 AM: Global learning rate: 1.25e-05
09/16 10:18:43 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 10:18:50 AM: Update 40097: task edges-ner-ontonotes, batch 97 (40097): mcc: 0.7412, acc: 0.6337, precision: 0.8412, recall: 0.6756, f1: 0.7494, edges-ner-ontonotes_loss: 0.0674
09/16 10:19:00 AM: Update 40204: task edges-ner-ontonotes, batch 204 (40204): mcc: 0.7185, acc: 0.6061, precision: 0.8274, recall: 0.6478, f1: 0.7266, edges-ner-ontonotes_loss: 0.0723
09/16 10:19:10 AM: Update 40343: task edges-ner-ontonotes, batch 343 (40343): mcc: 0.7118, acc: 0.5964, precision: 0.8255, recall: 0.6377, f1: 0.7195, edges-ner-ontonotes_loss: 0.0745
09/16 10:19:20 AM: Update 40463: task edges-ner-ontonotes, batch 463 (40463): mcc: 0.7068, acc: 0.5897, precision: 0.8221, recall: 0.6319, f1: 0.7145, edges-ner-ontonotes_loss: 0.0760
09/16 10:19:30 AM: Update 40625: task edges-ner-ontonotes, batch 625 (40625): mcc: 0.7054, acc: 0.5876, precision: 0.8215, recall: 0.6300, f1: 0.7131, edges-ner-ontonotes_loss: 0.0762
09/16 10:19:41 AM: Update 40771: task edges-ner-ontonotes, batch 771 (40771): mcc: 0.7046, acc: 0.5863, precision: 0.8213, recall: 0.6288, f1: 0.7123, edges-ner-ontonotes_loss: 0.0761
09/16 10:19:51 AM: Update 40917: task edges-ner-ontonotes, batch 917 (40917): mcc: 0.7093, acc: 0.5921, precision: 0.8238, recall: 0.6349, f1: 0.7171, edges-ner-ontonotes_loss: 0.0749
09/16 10:19:57 AM: ***** Step 41000 / Validation 41 *****
09/16 10:19:58 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:19:58 AM: Validating...
09/16 10:20:01 AM: Evaluate: task edges-ner-ontonotes, batch 31 (157): mcc: 0.7614, acc: 0.6581, precision: 0.8686, recall: 0.6878, f1: 0.7677, edges-ner-ontonotes_loss: 0.0648
09/16 10:20:11 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.7940, acc: 0.6901, precision: 0.9048, recall: 0.7143, f1: 0.7983, edges-ner-ontonotes_loss: 0.0568
09/16 10:20:16 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:20:16 AM: Best result seen so far for macro.
09/16 10:20:16 AM: Updating LR scheduler:
09/16 10:20:16 AM: 	Best result seen so far for macro_avg: 0.797
09/16 10:20:16 AM: 	# validation passes without improvement: 0
09/16 10:20:16 AM: edges-ner-ontonotes_loss: training: 0.074826 validation: 0.056201
09/16 10:20:16 AM: macro_avg: validation: 0.797165
09/16 10:20:16 AM: micro_avg: validation: 0.000000
09/16 10:20:16 AM: edges-ner-ontonotes_mcc: training: 0.709453 validation: 0.792987
09/16 10:20:16 AM: edges-ner-ontonotes_acc: training: 0.592543 validation: 0.688277
09/16 10:20:16 AM: edges-ner-ontonotes_precision: training: 0.823335 validation: 0.905088
09/16 10:20:16 AM: edges-ner-ontonotes_recall: training: 0.635469 validation: 0.712238
09/16 10:20:16 AM: edges-ner-ontonotes_f1: training: 0.717305 validation: 0.797165
09/16 10:20:16 AM: Global learning rate: 1.25e-05
09/16 10:20:16 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 10:20:21 AM: Update 41071: task edges-ner-ontonotes, batch 71 (41071): mcc: 0.7399, acc: 0.6271, precision: 0.8458, recall: 0.6695, f1: 0.7474, edges-ner-ontonotes_loss: 0.0689
09/16 10:20:31 AM: Update 41181: task edges-ner-ontonotes, batch 181 (41181): mcc: 0.7416, acc: 0.6315, precision: 0.8458, recall: 0.6723, f1: 0.7492, edges-ner-ontonotes_loss: 0.0676
09/16 10:20:41 AM: Update 41318: task edges-ner-ontonotes, batch 318 (41318): mcc: 0.7480, acc: 0.6395, precision: 0.8500, recall: 0.6800, f1: 0.7556, edges-ner-ontonotes_loss: 0.0660
09/16 10:20:51 AM: Update 41430: task edges-ner-ontonotes, batch 430 (41430): mcc: 0.7452, acc: 0.6365, precision: 0.8483, recall: 0.6766, f1: 0.7528, edges-ner-ontonotes_loss: 0.0666
09/16 10:21:01 AM: Update 41546: task edges-ner-ontonotes, batch 546 (41546): mcc: 0.7452, acc: 0.6363, precision: 0.8483, recall: 0.6766, f1: 0.7528, edges-ner-ontonotes_loss: 0.0667
09/16 10:21:11 AM: Update 41673: task edges-ner-ontonotes, batch 673 (41673): mcc: 0.7443, acc: 0.6342, precision: 0.8469, recall: 0.6761, f1: 0.7519, edges-ner-ontonotes_loss: 0.0669
09/16 10:21:21 AM: Update 41777: task edges-ner-ontonotes, batch 777 (41777): mcc: 0.7371, acc: 0.6251, precision: 0.8427, recall: 0.6672, f1: 0.7448, edges-ner-ontonotes_loss: 0.0686
09/16 10:21:31 AM: Update 41918: task edges-ner-ontonotes, batch 918 (41918): mcc: 0.7308, acc: 0.6175, precision: 0.8388, recall: 0.6596, f1: 0.7385, edges-ner-ontonotes_loss: 0.0703
09/16 10:21:37 AM: ***** Step 42000 / Validation 42 *****
09/16 10:21:37 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:21:37 AM: Validating...
09/16 10:21:41 AM: Evaluate: task edges-ner-ontonotes, batch 48 (157): mcc: 0.7732, acc: 0.6683, precision: 0.8766, recall: 0.7016, f1: 0.7794, edges-ner-ontonotes_loss: 0.0616
09/16 10:21:53 AM: Evaluate: task edges-ner-ontonotes, batch 128 (157): mcc: 0.7939, acc: 0.6882, precision: 0.9059, recall: 0.7131, f1: 0.7981, edges-ner-ontonotes_loss: 0.0565
09/16 10:21:56 AM: Updating LR scheduler:
09/16 10:21:56 AM: 	Best result seen so far for macro_avg: 0.797
09/16 10:21:56 AM: 	# validation passes without improvement: 1
09/16 10:21:56 AM: edges-ner-ontonotes_loss: training: 0.070899 validation: 0.056625
09/16 10:21:56 AM: macro_avg: validation: 0.795503
09/16 10:21:56 AM: micro_avg: validation: 0.000000
09/16 10:21:56 AM: edges-ner-ontonotes_mcc: training: 0.729447 validation: 0.791202
09/16 10:21:56 AM: edges-ner-ontonotes_acc: training: 0.615849 validation: 0.685623
09/16 10:21:56 AM: edges-ner-ontonotes_precision: training: 0.837674 validation: 0.903005
09/16 10:21:56 AM: edges-ner-ontonotes_recall: training: 0.658130 validation: 0.710874
09/16 10:21:56 AM: edges-ner-ontonotes_f1: training: 0.737127 validation: 0.795503
09/16 10:21:56 AM: Global learning rate: 1.25e-05
09/16 10:21:56 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 10:22:03 AM: Update 42082: task edges-ner-ontonotes, batch 82 (42082): mcc: 0.6984, acc: 0.5777, precision: 0.8149, recall: 0.6234, f1: 0.7064, edges-ner-ontonotes_loss: 0.0784
09/16 10:22:13 AM: Update 42250: task edges-ner-ontonotes, batch 250 (42250): mcc: 0.7039, acc: 0.5799, precision: 0.8232, recall: 0.6261, f1: 0.7113, edges-ner-ontonotes_loss: 0.0766
09/16 10:22:23 AM: Update 42383: task edges-ner-ontonotes, batch 383 (42383): mcc: 0.7063, acc: 0.5842, precision: 0.8240, recall: 0.6295, f1: 0.7138, edges-ner-ontonotes_loss: 0.0755
09/16 10:22:33 AM: Update 42527: task edges-ner-ontonotes, batch 527 (42527): mcc: 0.7124, acc: 0.5931, precision: 0.8272, recall: 0.6374, f1: 0.7200, edges-ner-ontonotes_loss: 0.0742
09/16 10:22:43 AM: Update 42649: task edges-ner-ontonotes, batch 649 (42649): mcc: 0.7140, acc: 0.5964, precision: 0.8272, recall: 0.6401, f1: 0.7217, edges-ner-ontonotes_loss: 0.0738
09/16 10:22:53 AM: Update 42791: task edges-ner-ontonotes, batch 791 (42791): mcc: 0.7218, acc: 0.6058, precision: 0.8322, recall: 0.6494, f1: 0.7295, edges-ner-ontonotes_loss: 0.0721
09/16 10:23:03 AM: Update 42926: task edges-ner-ontonotes, batch 926 (42926): mcc: 0.7263, acc: 0.6116, precision: 0.8352, recall: 0.6547, f1: 0.7341, edges-ner-ontonotes_loss: 0.0711
09/16 10:23:11 AM: ***** Step 43000 / Validation 43 *****
09/16 10:23:11 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:23:12 AM: Validating...
09/16 10:23:13 AM: Evaluate: task edges-ner-ontonotes, batch 15 (157): mcc: 0.7238, acc: 0.6094, precision: 0.8424, recall: 0.6446, f1: 0.7304, edges-ner-ontonotes_loss: 0.0707
09/16 10:23:23 AM: Evaluate: task edges-ner-ontonotes, batch 103 (157): mcc: 0.7875, acc: 0.6858, precision: 0.8978, recall: 0.7087, f1: 0.7921, edges-ner-ontonotes_loss: 0.0596
09/16 10:23:30 AM: Updating LR scheduler:
09/16 10:23:30 AM: 	Best result seen so far for macro_avg: 0.797
09/16 10:23:30 AM: 	# validation passes without improvement: 2
09/16 10:23:30 AM: edges-ner-ontonotes_loss: training: 0.070950 validation: 0.057395
09/16 10:23:30 AM: macro_avg: validation: 0.793842
09/16 10:23:30 AM: micro_avg: validation: 0.000000
09/16 10:23:30 AM: edges-ner-ontonotes_mcc: training: 0.726820 validation: 0.789392
09/16 10:23:30 AM: edges-ner-ontonotes_acc: training: 0.612126 validation: 0.686457
09/16 10:23:30 AM: edges-ner-ontonotes_precision: training: 0.835974 validation: 0.900683
09/16 10:23:30 AM: edges-ner-ontonotes_recall: training: 0.654998 validation: 0.709660
09/16 10:23:30 AM: edges-ner-ontonotes_f1: training: 0.734502 validation: 0.793842
09/16 10:23:30 AM: Global learning rate: 1.25e-05
09/16 10:23:30 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 10:23:33 AM: Update 43042: task edges-ner-ontonotes, batch 42 (43042): mcc: 0.7249, acc: 0.6158, precision: 0.8325, recall: 0.6545, f1: 0.7328, edges-ner-ontonotes_loss: 0.0711
09/16 10:23:43 AM: Update 43179: task edges-ner-ontonotes, batch 179 (43179): mcc: 0.7404, acc: 0.6312, precision: 0.8412, recall: 0.6741, f1: 0.7485, edges-ner-ontonotes_loss: 0.0680
09/16 10:23:53 AM: Update 43294: task edges-ner-ontonotes, batch 294 (43294): mcc: 0.7316, acc: 0.6192, precision: 0.8368, recall: 0.6626, f1: 0.7395, edges-ner-ontonotes_loss: 0.0693
09/16 10:24:03 AM: Update 43438: task edges-ner-ontonotes, batch 438 (43438): mcc: 0.7213, acc: 0.6064, precision: 0.8306, recall: 0.6499, f1: 0.7292, edges-ner-ontonotes_loss: 0.0725
09/16 10:24:14 AM: Update 43569: task edges-ner-ontonotes, batch 569 (43569): mcc: 0.7151, acc: 0.5989, precision: 0.8268, recall: 0.6423, f1: 0.7230, edges-ner-ontonotes_loss: 0.0746
09/16 10:24:25 AM: Update 43731: task edges-ner-ontonotes, batch 731 (43731): mcc: 0.7105, acc: 0.5933, precision: 0.8235, recall: 0.6372, f1: 0.7185, edges-ner-ontonotes_loss: 0.0752
09/16 10:24:35 AM: Update 43882: task edges-ner-ontonotes, batch 882 (43882): mcc: 0.7085, acc: 0.5904, precision: 0.8224, recall: 0.6346, f1: 0.7164, edges-ner-ontonotes_loss: 0.0755
09/16 10:24:43 AM: ***** Step 44000 / Validation 44 *****
09/16 10:24:43 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:24:43 AM: Validating...
09/16 10:24:45 AM: Evaluate: task edges-ner-ontonotes, batch 16 (157): mcc: 0.7494, acc: 0.6392, precision: 0.8621, recall: 0.6724, f1: 0.7555, edges-ner-ontonotes_loss: 0.0670
09/16 10:24:55 AM: Evaluate: task edges-ner-ontonotes, batch 108 (157): mcc: 0.7943, acc: 0.6925, precision: 0.9019, recall: 0.7171, f1: 0.7990, edges-ner-ontonotes_loss: 0.0570
09/16 10:25:01 AM: Updating LR scheduler:
09/16 10:25:01 AM: 	Best result seen so far for macro_avg: 0.797
09/16 10:25:01 AM: 	# validation passes without improvement: 3
09/16 10:25:01 AM: edges-ner-ontonotes_loss: training: 0.075080 validation: 0.056003
09/16 10:25:01 AM: macro_avg: validation: 0.796722
09/16 10:25:01 AM: micro_avg: validation: 0.000000
09/16 10:25:01 AM: edges-ner-ontonotes_mcc: training: 0.709247 validation: 0.792585
09/16 10:25:01 AM: edges-ner-ontonotes_acc: training: 0.591935 validation: 0.687898
09/16 10:25:01 AM: edges-ner-ontonotes_precision: training: 0.822684 validation: 0.905171
09/16 10:25:01 AM: edges-ner-ontonotes_recall: training: 0.635645 validation: 0.711480
09/16 10:25:01 AM: edges-ner-ontonotes_f1: training: 0.717170 validation: 0.796722
09/16 10:25:01 AM: Global learning rate: 1.25e-05
09/16 10:25:01 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 10:25:05 AM: Update 44056: task edges-ner-ontonotes, batch 56 (44056): mcc: 0.7362, acc: 0.6304, precision: 0.8424, recall: 0.6659, f1: 0.7438, edges-ner-ontonotes_loss: 0.0675
09/16 10:25:16 AM: Update 44195: task edges-ner-ontonotes, batch 195 (44195): mcc: 0.7260, acc: 0.6161, precision: 0.8328, recall: 0.6562, f1: 0.7340, edges-ner-ontonotes_loss: 0.0704
09/16 10:25:26 AM: Update 44333: task edges-ner-ontonotes, batch 333 (44333): mcc: 0.7359, acc: 0.6272, precision: 0.8409, recall: 0.6666, f1: 0.7437, edges-ner-ontonotes_loss: 0.0687
09/16 10:25:36 AM: Update 44467: task edges-ner-ontonotes, batch 467 (44467): mcc: 0.7411, acc: 0.6320, precision: 0.8453, recall: 0.6720, f1: 0.7487, edges-ner-ontonotes_loss: 0.0674
09/16 10:25:46 AM: Update 44586: task edges-ner-ontonotes, batch 586 (44586): mcc: 0.7398, acc: 0.6304, precision: 0.8436, recall: 0.6711, f1: 0.7475, edges-ner-ontonotes_loss: 0.0675
09/16 10:25:56 AM: Update 44724: task edges-ner-ontonotes, batch 724 (44724): mcc: 0.7396, acc: 0.6302, precision: 0.8432, recall: 0.6712, f1: 0.7474, edges-ner-ontonotes_loss: 0.0675
09/16 10:26:07 AM: Update 44834: task edges-ner-ontonotes, batch 834 (44834): mcc: 0.7378, acc: 0.6279, precision: 0.8424, recall: 0.6686, f1: 0.7455, edges-ner-ontonotes_loss: 0.0679
09/16 10:26:17 AM: Update 44970: task edges-ner-ontonotes, batch 970 (44970): mcc: 0.7319, acc: 0.6206, precision: 0.8392, recall: 0.6612, f1: 0.7396, edges-ner-ontonotes_loss: 0.0694
09/16 10:26:19 AM: ***** Step 45000 / Validation 45 *****
09/16 10:26:19 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:26:19 AM: Validating...
09/16 10:26:27 AM: Evaluate: task edges-ner-ontonotes, batch 75 (157): mcc: 0.7854, acc: 0.6805, precision: 0.8909, recall: 0.7107, f1: 0.7907, edges-ner-ontonotes_loss: 0.0596
09/16 10:26:36 AM: Updating LR scheduler:
09/16 10:26:36 AM: 	Best result seen so far for macro_avg: 0.797
09/16 10:26:36 AM: 	# validation passes without improvement: 0
09/16 10:26:36 AM: edges-ner-ontonotes_loss: training: 0.069785 validation: 0.056606
09/16 10:26:36 AM: macro_avg: validation: 0.794141
09/16 10:26:36 AM: micro_avg: validation: 0.000000
09/16 10:26:36 AM: edges-ner-ontonotes_mcc: training: 0.730980 validation: 0.789844
09/16 10:26:36 AM: edges-ner-ontonotes_acc: training: 0.619372 validation: 0.683576
09/16 10:26:36 AM: edges-ner-ontonotes_precision: training: 0.838519 validation: 0.902190
09/16 10:26:36 AM: edges-ner-ontonotes_recall: training: 0.660080 validation: 0.709205
09/16 10:26:36 AM: edges-ner-ontonotes_f1: training: 0.738676 validation: 0.794141
09/16 10:26:36 AM: Global learning rate: 6.25e-06
09/16 10:26:36 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 10:26:37 AM: Update 45002: task edges-ner-ontonotes, batch 2 (45002): mcc: 0.6730, acc: 0.5449, precision: 0.8175, recall: 0.5787, f1: 0.6776, edges-ner-ontonotes_loss: 0.0922
09/16 10:26:47 AM: Update 45133: task edges-ner-ontonotes, batch 133 (45133): mcc: 0.7037, acc: 0.5840, precision: 0.8192, recall: 0.6289, f1: 0.7116, edges-ner-ontonotes_loss: 0.0798
09/16 10:26:57 AM: Update 45305: task edges-ner-ontonotes, batch 305 (45305): mcc: 0.7016, acc: 0.5803, precision: 0.8187, recall: 0.6258, f1: 0.7094, edges-ner-ontonotes_loss: 0.0782
09/16 10:27:07 AM: Update 45440: task edges-ner-ontonotes, batch 440 (45440): mcc: 0.7000, acc: 0.5772, precision: 0.8196, recall: 0.6224, f1: 0.7075, edges-ner-ontonotes_loss: 0.0778
09/16 10:27:17 AM: Update 45575: task edges-ner-ontonotes, batch 575 (45575): mcc: 0.7049, acc: 0.5837, precision: 0.8229, recall: 0.6279, f1: 0.7123, edges-ner-ontonotes_loss: 0.0765
09/16 10:27:27 AM: Update 45722: task edges-ner-ontonotes, batch 722 (45722): mcc: 0.7124, acc: 0.5933, precision: 0.8267, recall: 0.6378, f1: 0.7201, edges-ner-ontonotes_loss: 0.0748
09/16 10:27:37 AM: Update 45834: task edges-ner-ontonotes, batch 834 (45834): mcc: 0.7150, acc: 0.5960, precision: 0.8285, recall: 0.6407, f1: 0.7226, edges-ner-ontonotes_loss: 0.0739
09/16 10:27:47 AM: Update 45967: task edges-ner-ontonotes, batch 967 (45967): mcc: 0.7206, acc: 0.6029, precision: 0.8322, recall: 0.6473, f1: 0.7282, edges-ner-ontonotes_loss: 0.0728
09/16 10:27:49 AM: ***** Step 46000 / Validation 46 *****
09/16 10:27:49 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:27:49 AM: Validating...
09/16 10:27:57 AM: Evaluate: task edges-ner-ontonotes, batch 72 (157): mcc: 0.7710, acc: 0.6650, precision: 0.8862, recall: 0.6900, f1: 0.7758, edges-ner-ontonotes_loss: 0.0630
09/16 10:28:08 AM: Evaluate: task edges-ner-ontonotes, batch 156 (157): mcc: 0.7883, acc: 0.6858, precision: 0.8989, recall: 0.7093, f1: 0.7929, edges-ner-ontonotes_loss: 0.0574
09/16 10:28:08 AM: Updating LR scheduler:
09/16 10:28:08 AM: 	Best result seen so far for macro_avg: 0.797
09/16 10:28:08 AM: 	# validation passes without improvement: 1
09/16 10:28:08 AM: edges-ner-ontonotes_loss: training: 0.072632 validation: 0.057496
09/16 10:28:08 AM: macro_avg: validation: 0.792965
09/16 10:28:08 AM: micro_avg: validation: 0.000000
09/16 10:28:08 AM: edges-ner-ontonotes_mcc: training: 0.721499 validation: 0.788374
09/16 10:28:08 AM: edges-ner-ontonotes_acc: training: 0.604248 validation: 0.685927
09/16 10:28:08 AM: edges-ner-ontonotes_precision: training: 0.832775 validation: 0.898914
09/16 10:28:08 AM: edges-ner-ontonotes_recall: training: 0.648459 validation: 0.709357
09/16 10:28:08 AM: edges-ner-ontonotes_f1: training: 0.729149 validation: 0.792965
09/16 10:28:08 AM: Global learning rate: 6.25e-06
09/16 10:28:08 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 10:28:18 AM: Update 46117: task edges-ner-ontonotes, batch 117 (46117): mcc: 0.7475, acc: 0.6400, precision: 0.8449, recall: 0.6834, f1: 0.7556, edges-ner-ontonotes_loss: 0.0661
09/16 10:28:28 AM: Update 46259: task edges-ner-ontonotes, batch 259 (46259): mcc: 0.7439, acc: 0.6350, precision: 0.8444, recall: 0.6776, f1: 0.7518, edges-ner-ontonotes_loss: 0.0666
09/16 10:28:38 AM: Update 46377: task edges-ner-ontonotes, batch 377 (46377): mcc: 0.7412, acc: 0.6315, precision: 0.8438, recall: 0.6733, f1: 0.7490, edges-ner-ontonotes_loss: 0.0675
09/16 10:28:48 AM: Update 46513: task edges-ner-ontonotes, batch 513 (46513): mcc: 0.7277, acc: 0.6158, precision: 0.8352, recall: 0.6572, f1: 0.7356, edges-ner-ontonotes_loss: 0.0707
09/16 10:28:58 AM: Update 46659: task edges-ner-ontonotes, batch 659 (46659): mcc: 0.7212, acc: 0.6074, precision: 0.8313, recall: 0.6491, f1: 0.7290, edges-ner-ontonotes_loss: 0.0729
09/16 10:29:08 AM: Update 46798: task edges-ner-ontonotes, batch 798 (46798): mcc: 0.7179, acc: 0.6027, precision: 0.8289, recall: 0.6454, f1: 0.7257, edges-ner-ontonotes_loss: 0.0736
09/16 10:29:18 AM: Update 46965: task edges-ner-ontonotes, batch 965 (46965): mcc: 0.7157, acc: 0.5998, precision: 0.8277, recall: 0.6425, f1: 0.7235, edges-ner-ontonotes_loss: 0.0740
09/16 10:29:22 AM: ***** Step 47000 / Validation 47 *****
09/16 10:29:22 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:29:22 AM: Validating...
09/16 10:29:28 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.7857, acc: 0.6785, precision: 0.8899, recall: 0.7122, f1: 0.7912, edges-ner-ontonotes_loss: 0.0581
09/16 10:29:38 AM: Evaluate: task edges-ner-ontonotes, batch 144 (157): mcc: 0.7939, acc: 0.6857, precision: 0.9087, recall: 0.7108, f1: 0.7977, edges-ner-ontonotes_loss: 0.0558
09/16 10:29:39 AM: Updating LR scheduler:
09/16 10:29:39 AM: 	Best result seen so far for macro_avg: 0.797
09/16 10:29:39 AM: 	# validation passes without improvement: 2
09/16 10:29:39 AM: edges-ner-ontonotes_loss: training: 0.074175 validation: 0.056319
09/16 10:29:39 AM: macro_avg: validation: 0.794772
09/16 10:29:39 AM: micro_avg: validation: 0.000000
09/16 10:29:39 AM: edges-ner-ontonotes_mcc: training: 0.714486 validation: 0.790878
09/16 10:29:39 AM: edges-ner-ontonotes_acc: training: 0.598310 validation: 0.682439
09/16 10:29:39 AM: edges-ner-ontonotes_precision: training: 0.827228 validation: 0.906047
09/16 10:29:39 AM: edges-ner-ontonotes_recall: training: 0.640936 validation: 0.707840
09/16 10:29:39 AM: edges-ner-ontonotes_f1: training: 0.722263 validation: 0.794772
09/16 10:29:39 AM: Global learning rate: 6.25e-06
09/16 10:29:39 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 10:29:48 AM: Update 47123: task edges-ner-ontonotes, batch 123 (47123): mcc: 0.7302, acc: 0.6158, precision: 0.8394, recall: 0.6580, f1: 0.7377, edges-ner-ontonotes_loss: 0.0692
09/16 10:29:58 AM: Update 47264: task edges-ner-ontonotes, batch 264 (47264): mcc: 0.7263, acc: 0.6116, precision: 0.8364, recall: 0.6538, f1: 0.7339, edges-ner-ontonotes_loss: 0.0703
09/16 10:30:10 AM: Update 47373: task edges-ner-ontonotes, batch 373 (47373): mcc: 0.7286, acc: 0.6141, precision: 0.8384, recall: 0.6561, f1: 0.7361, edges-ner-ontonotes_loss: 0.0697
09/16 10:30:20 AM: Update 47504: task edges-ner-ontonotes, batch 504 (47504): mcc: 0.7376, acc: 0.6248, precision: 0.8444, recall: 0.6666, f1: 0.7451, edges-ner-ontonotes_loss: 0.0685
09/16 10:30:30 AM: Update 47622: task edges-ner-ontonotes, batch 622 (47622): mcc: 0.7391, acc: 0.6274, precision: 0.8446, recall: 0.6691, f1: 0.7467, edges-ner-ontonotes_loss: 0.0679
09/16 10:30:40 AM: Update 47745: task edges-ner-ontonotes, batch 745 (47745): mcc: 0.7391, acc: 0.6278, precision: 0.8442, recall: 0.6694, f1: 0.7467, edges-ner-ontonotes_loss: 0.0681
09/16 10:30:50 AM: Update 47880: task edges-ner-ontonotes, batch 880 (47880): mcc: 0.7405, acc: 0.6295, precision: 0.8451, recall: 0.6711, f1: 0.7481, edges-ner-ontonotes_loss: 0.0679
09/16 10:31:00 AM: Update 47993: task edges-ner-ontonotes, batch 993 (47993): mcc: 0.7367, acc: 0.6250, precision: 0.8424, recall: 0.6667, f1: 0.7443, edges-ner-ontonotes_loss: 0.0687
09/16 10:31:01 AM: ***** Step 48000 / Validation 48 *****
09/16 10:31:01 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:31:01 AM: Validating...
09/16 10:31:11 AM: Evaluate: task edges-ner-ontonotes, batch 91 (157): mcc: 0.7924, acc: 0.6897, precision: 0.9022, recall: 0.7136, f1: 0.7969, edges-ner-ontonotes_loss: 0.0585
09/16 10:31:19 AM: Updating LR scheduler:
09/16 10:31:19 AM: 	Best result seen so far for macro_avg: 0.797
09/16 10:31:19 AM: 	# validation passes without improvement: 3
09/16 10:31:19 AM: edges-ner-ontonotes_loss: training: 0.068690 validation: 0.056346
09/16 10:31:19 AM: macro_avg: validation: 0.796495
09/16 10:31:19 AM: micro_avg: validation: 0.000000
09/16 10:31:19 AM: edges-ner-ontonotes_mcc: training: 0.736563 validation: 0.792605
09/16 10:31:19 AM: edges-ner-ontonotes_acc: training: 0.624851 validation: 0.687291
09/16 10:31:19 AM: edges-ner-ontonotes_precision: training: 0.842595 validation: 0.907171
09/16 10:31:19 AM: edges-ner-ontonotes_recall: training: 0.666361 validation: 0.709888
09/16 10:31:19 AM: edges-ner-ontonotes_f1: training: 0.744186 validation: 0.796495
09/16 10:31:19 AM: Global learning rate: 6.25e-06
09/16 10:31:19 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 10:31:21 AM: Update 48027: task edges-ner-ontonotes, batch 27 (48027): mcc: 0.6898, acc: 0.5705, precision: 0.8099, recall: 0.6127, f1: 0.6976, edges-ner-ontonotes_loss: 0.0819
09/16 10:31:31 AM: Update 48171: task edges-ner-ontonotes, batch 171 (48171): mcc: 0.6924, acc: 0.5723, precision: 0.8133, recall: 0.6145, f1: 0.7000, edges-ner-ontonotes_loss: 0.0807
09/16 10:31:41 AM: Update 48295: task edges-ner-ontonotes, batch 295 (48295): mcc: 0.6947, acc: 0.5756, precision: 0.8140, recall: 0.6177, f1: 0.7024, edges-ner-ontonotes_loss: 0.0791
09/16 10:31:51 AM: Update 48469: task edges-ner-ontonotes, batch 469 (48469): mcc: 0.6980, acc: 0.5789, precision: 0.8162, recall: 0.6216, f1: 0.7058, edges-ner-ontonotes_loss: 0.0777
09/16 10:32:01 AM: Update 48599: task edges-ner-ontonotes, batch 599 (48599): mcc: 0.7005, acc: 0.5811, precision: 0.8189, recall: 0.6238, f1: 0.7081, edges-ner-ontonotes_loss: 0.0770
09/16 10:32:11 AM: Update 48745: task edges-ner-ontonotes, batch 745 (48745): mcc: 0.7068, acc: 0.5888, precision: 0.8230, recall: 0.6312, f1: 0.7145, edges-ner-ontonotes_loss: 0.0754
09/16 10:32:21 AM: Update 48865: task edges-ner-ontonotes, batch 865 (48865): mcc: 0.7078, acc: 0.5906, precision: 0.8231, recall: 0.6329, f1: 0.7156, edges-ner-ontonotes_loss: 0.0751
09/16 10:32:31 AM: ***** Step 49000 / Validation 49 *****
09/16 10:32:31 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:32:31 AM: Validating...
09/16 10:32:31 AM: Evaluate: task edges-ner-ontonotes, batch 3 (157): mcc: 0.6185, acc: 0.4755, precision: 0.7698, recall: 0.5245, f1: 0.6239, edges-ner-ontonotes_loss: 0.0943
09/16 10:32:41 AM: Evaluate: task edges-ner-ontonotes, batch 99 (157): mcc: 0.7857, acc: 0.6851, precision: 0.8938, recall: 0.7090, f1: 0.7907, edges-ner-ontonotes_loss: 0.0594
09/16 10:32:48 AM: Updating LR scheduler:
09/16 10:32:48 AM: 	Best result seen so far for macro_avg: 0.797
09/16 10:32:48 AM: 	# validation passes without improvement: 0
09/16 10:32:48 AM: edges-ner-ontonotes_loss: training: 0.073928 validation: 0.057219
09/16 10:32:48 AM: macro_avg: validation: 0.792966
09/16 10:32:48 AM: micro_avg: validation: 0.000000
09/16 10:32:48 AM: edges-ner-ontonotes_mcc: training: 0.713617 validation: 0.788348
09/16 10:32:48 AM: edges-ner-ontonotes_acc: training: 0.597392 validation: 0.686609
09/16 10:32:48 AM: edges-ner-ontonotes_precision: training: 0.827124 validation: 0.898675
09/16 10:32:48 AM: edges-ner-ontonotes_recall: training: 0.639529 validation: 0.709509
09/16 10:32:48 AM: edges-ner-ontonotes_f1: training: 0.721329 validation: 0.792966
09/16 10:32:48 AM: Global learning rate: 3.125e-06
09/16 10:32:48 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 10:32:51 AM: Update 49037: task edges-ner-ontonotes, batch 37 (49037): mcc: 0.7469, acc: 0.6410, precision: 0.8451, recall: 0.6823, f1: 0.7550, edges-ner-ontonotes_loss: 0.0658
09/16 10:33:01 AM: Update 49174: task edges-ner-ontonotes, batch 174 (49174): mcc: 0.7547, acc: 0.6462, precision: 0.8521, recall: 0.6899, f1: 0.7625, edges-ner-ontonotes_loss: 0.0650
09/16 10:33:11 AM: Update 49285: task edges-ner-ontonotes, batch 285 (49285): mcc: 0.7450, acc: 0.6352, precision: 0.8447, recall: 0.6793, f1: 0.7530, edges-ner-ontonotes_loss: 0.0670
09/16 10:33:21 AM: Update 49423: task edges-ner-ontonotes, batch 423 (49423): mcc: 0.7458, acc: 0.6369, precision: 0.8446, recall: 0.6808, f1: 0.7539, edges-ner-ontonotes_loss: 0.0669
09/16 10:33:31 AM: Update 49548: task edges-ner-ontonotes, batch 548 (49548): mcc: 0.7398, acc: 0.6301, precision: 0.8416, recall: 0.6728, f1: 0.7478, edges-ner-ontonotes_loss: 0.0685
09/16 10:33:41 AM: Update 49688: task edges-ner-ontonotes, batch 688 (49688): mcc: 0.7302, acc: 0.6191, precision: 0.8358, recall: 0.6611, f1: 0.7382, edges-ner-ontonotes_loss: 0.0710
09/16 10:33:51 AM: Update 49813: task edges-ner-ontonotes, batch 813 (49813): mcc: 0.7251, acc: 0.6126, precision: 0.8329, recall: 0.6546, f1: 0.7331, edges-ner-ontonotes_loss: 0.0723
09/16 10:34:01 AM: Update 49985: task edges-ner-ontonotes, batch 985 (49985): mcc: 0.7223, acc: 0.6092, precision: 0.8313, recall: 0.6512, f1: 0.7303, edges-ner-ontonotes_loss: 0.0731
09/16 10:34:02 AM: ***** Step 50000 / Validation 50 *****
09/16 10:34:02 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:34:02 AM: Validating...
09/16 10:34:11 AM: Evaluate: task edges-ner-ontonotes, batch 87 (157): mcc: 0.7921, acc: 0.6869, precision: 0.8986, recall: 0.7160, f1: 0.7970, edges-ner-ontonotes_loss: 0.0576
09/16 10:34:20 AM: Updating LR scheduler:
09/16 10:34:20 AM: 	Best result seen so far for macro_avg: 0.797
09/16 10:34:20 AM: 	# validation passes without improvement: 1
09/16 10:34:20 AM: edges-ner-ontonotes_loss: training: 0.073079 validation: 0.056233
09/16 10:34:20 AM: macro_avg: validation: 0.795683
09/16 10:34:20 AM: micro_avg: validation: 0.000000
09/16 10:34:20 AM: edges-ner-ontonotes_mcc: training: 0.722284 validation: 0.791580
09/16 10:34:20 AM: edges-ner-ontonotes_acc: training: 0.609060 validation: 0.684031
09/16 10:34:20 AM: edges-ner-ontonotes_precision: training: 0.831143 validation: 0.904822
09/16 10:34:20 AM: edges-ner-ontonotes_recall: training: 0.651149 validation: 0.710039
09/16 10:34:20 AM: edges-ner-ontonotes_f1: training: 0.730218 validation: 0.795683
09/16 10:34:20 AM: Global learning rate: 3.125e-06
09/16 10:34:20 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 10:34:21 AM: Update 50024: task edges-ner-ontonotes, batch 24 (50024): mcc: 0.6886, acc: 0.5685, precision: 0.8035, recall: 0.6159, f1: 0.6973, edges-ner-ontonotes_loss: 0.0789
09/16 10:34:31 AM: Update 50141: task edges-ner-ontonotes, batch 141 (50141): mcc: 0.6996, acc: 0.5791, precision: 0.8164, recall: 0.6242, f1: 0.7075, edges-ner-ontonotes_loss: 0.0769
09/16 10:34:42 AM: Update 50287: task edges-ner-ontonotes, batch 287 (50287): mcc: 0.7147, acc: 0.5989, precision: 0.8258, recall: 0.6425, f1: 0.7227, edges-ner-ontonotes_loss: 0.0729
09/16 10:34:52 AM: Update 50419: task edges-ner-ontonotes, batch 419 (50419): mcc: 0.7158, acc: 0.5999, precision: 0.8270, recall: 0.6434, f1: 0.7237, edges-ner-ontonotes_loss: 0.0725
09/16 10:35:02 AM: Update 50549: task edges-ner-ontonotes, batch 549 (50549): mcc: 0.7222, acc: 0.6066, precision: 0.8330, recall: 0.6495, f1: 0.7299, edges-ner-ontonotes_loss: 0.0712
09/16 10:35:12 AM: Update 50685: task edges-ner-ontonotes, batch 685 (50685): mcc: 0.7274, acc: 0.6133, precision: 0.8357, recall: 0.6562, f1: 0.7352, edges-ner-ontonotes_loss: 0.0701
09/16 10:35:22 AM: Update 50802: task edges-ner-ontonotes, batch 802 (50802): mcc: 0.7291, acc: 0.6157, precision: 0.8359, recall: 0.6589, f1: 0.7369, edges-ner-ontonotes_loss: 0.0697
09/16 10:35:32 AM: Update 50941: task edges-ner-ontonotes, batch 941 (50941): mcc: 0.7319, acc: 0.6198, precision: 0.8373, recall: 0.6626, f1: 0.7398, edges-ner-ontonotes_loss: 0.0691
09/16 10:35:37 AM: ***** Step 51000 / Validation 51 *****
09/16 10:35:37 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:35:37 AM: Validating...
09/16 10:35:42 AM: Evaluate: task edges-ner-ontonotes, batch 55 (157): mcc: 0.7683, acc: 0.6635, precision: 0.8798, recall: 0.6904, f1: 0.7737, edges-ner-ontonotes_loss: 0.0631
09/16 10:35:52 AM: Evaluate: task edges-ner-ontonotes, batch 136 (157): mcc: 0.7914, acc: 0.6879, precision: 0.9042, recall: 0.7102, f1: 0.7956, edges-ner-ontonotes_loss: 0.0572
09/16 10:35:55 AM: Updating LR scheduler:
09/16 10:35:55 AM: 	Best result seen so far for macro_avg: 0.797
09/16 10:35:55 AM: 	# validation passes without improvement: 2
09/16 10:35:55 AM: Ran out of early stopping patience. Stopping training.
09/16 10:35:55 AM: edges-ner-ontonotes_loss: training: 0.069184 validation: 0.057520
09/16 10:35:55 AM: macro_avg: validation: 0.792754
09/16 10:35:55 AM: micro_avg: validation: 0.000000
09/16 10:35:55 AM: edges-ner-ontonotes_mcc: training: 0.732187 validation: 0.788284
09/16 10:35:55 AM: edges-ner-ontonotes_acc: training: 0.620197 validation: 0.684941
09/16 10:35:55 AM: edges-ner-ontonotes_precision: training: 0.837470 validation: 0.899836
09/16 10:35:55 AM: edges-ner-ontonotes_recall: training: 0.663035 validation: 0.708447
09/16 10:35:55 AM: edges-ner-ontonotes_f1: training: 0.740114 validation: 0.792754
09/16 10:35:55 AM: Global learning rate: 3.125e-06
09/16 10:35:55 AM: Saving checkpoints to: ./experiments/ner-ontonotes-squad-top/run
09/16 10:35:55 AM: Stopped training after 51 validation checks
09/16 10:35:55 AM: Trained edges-ner-ontonotes for 51000 batches or 32.819 epochs
09/16 10:35:55 AM: ***** VALIDATION RESULTS *****
09/16 10:35:55 AM: edges-ner-ontonotes_f1 (for best val pass 41): edges-ner-ontonotes_loss: 0.05620, macro_avg: 0.79717, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.79299, edges-ner-ontonotes_acc: 0.68828, edges-ner-ontonotes_precision: 0.90509, edges-ner-ontonotes_recall: 0.71224, edges-ner-ontonotes_f1: 0.79717
09/16 10:35:55 AM: micro_avg (for best val pass 1): edges-ner-ontonotes_loss: 0.10653, macro_avg: 0.57021, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.58874, edges-ner-ontonotes_acc: 0.41894, edges-ner-ontonotes_precision: 0.84839, edges-ner-ontonotes_recall: 0.42941, edges-ner-ontonotes_f1: 0.57021
09/16 10:35:55 AM: macro_avg (for best val pass 41): edges-ner-ontonotes_loss: 0.05620, macro_avg: 0.79717, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.79299, edges-ner-ontonotes_acc: 0.68828, edges-ner-ontonotes_precision: 0.90509, edges-ner-ontonotes_recall: 0.71224, edges-ner-ontonotes_f1: 0.79717
09/16 10:35:55 AM: Evaluating...
09/16 10:35:55 AM: Loaded model state from ./experiments/ner-ontonotes-squad-top/run/edges-ner-ontonotes/model_state_target_train_val_41.best.th
09/16 10:35:55 AM: Evaluating on: edges-ner-ontonotes, split: val
09/16 10:36:24 AM: Task 'edges-ner-ontonotes': sorting predictions by 'idx'
09/16 10:36:24 AM: Finished evaluating on: edges-ner-ontonotes
09/16 10:36:24 AM: Task 'edges-ner-ontonotes': joining predictions with input split 'val'
09/16 10:36:24 AM: Task 'edges-ner-ontonotes': Wrote predictions to ./experiments/ner-ontonotes-squad-top/run
09/16 10:36:24 AM: Wrote all preds for split 'val' to ./experiments/ner-ontonotes-squad-top/run
09/16 10:36:24 AM: Evaluating on: edges-ner-ontonotes, split: test
09/16 10:36:42 AM: Task 'edges-ner-ontonotes': sorting predictions by 'idx'
09/16 10:36:42 AM: Finished evaluating on: edges-ner-ontonotes
09/16 10:36:42 AM: Task 'edges-ner-ontonotes': joining predictions with input split 'test'
09/16 10:36:43 AM: Task 'edges-ner-ontonotes': Wrote predictions to ./experiments/ner-ontonotes-squad-top/run
09/16 10:36:43 AM: Wrote all preds for split 'test' to ./experiments/ner-ontonotes-squad-top/run
09/16 10:36:43 AM: Writing results for split 'val' to ./experiments/ner-ontonotes-squad-top/results.tsv
09/16 10:36:43 AM: micro_avg: 0.000, macro_avg: 0.791, edges-ner-ontonotes_mcc: 0.787, edges-ner-ontonotes_acc: 0.681, edges-ner-ontonotes_precision: 0.901, edges-ner-ontonotes_recall: 0.705, edges-ner-ontonotes_f1: 0.791
09/16 10:36:43 AM: Done!
