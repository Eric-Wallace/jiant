09/16 09:13:23 AM: Git branch: master
09/16 09:13:23 AM: Git SHA: 3ca0f74688379229ab3eec908a215358ad18b3f4
09/16 09:13:23 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/ner-ontonotes-multiqa-top/",
  "exp_name": "experiments/ner-ontonotes-multiqa-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/ner-ontonotes-multiqa-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/multiqa",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/ner-ontonotes-multiqa-top__run",
  "run_dir": "./experiments/ner-ontonotes-multiqa-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-ner-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 09:13:23 AM: Saved config to ./experiments/ner-ontonotes-multiqa-top/run/params.conf
09/16 09:13:23 AM: Using random seed 1234
09/16 09:13:58 AM: Using GPU 0
09/16 09:13:58 AM: Loading tasks...
09/16 09:13:58 AM: Writing pre-preprocessed tasks to ./experiments/ner-ontonotes-multiqa-top/
09/16 09:13:58 AM: 	Creating task edges-ner-ontonotes from scratch.
09/16 09:13:59 AM: Read=49706, Skip=66106, Total=115812 from ./probing_data/edges/ontonotes/ner/train.json.retokenized.bert-base-uncased
09/16 09:13:59 AM: Read=7610, Skip=8070, Total=15680 from ./probing_data/edges/ontonotes/ner/development.json.retokenized.bert-base-uncased
09/16 09:13:59 AM: Read=5099, Skip=7118, Total=12217 from ./probing_data/edges/ontonotes/ner/test.json.retokenized.bert-base-uncased
09/16 09:14:00 AM: 	Task 'edges-ner-ontonotes': |train|=49706 |val|=7610 |test|=5099
09/16 09:14:00 AM: 	Finished loading tasks: edges-ner-ontonotes.
09/16 09:14:00 AM: 	Building vocab from scratch.
09/16 09:14:00 AM: 	Counting units for task edges-ner-ontonotes.
09/16 09:14:02 AM: 	Task 'edges-ner-ontonotes': adding vocab namespace 'edges-ner-ontonotes_labels'
09/16 09:14:03 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:14:03 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 09:14:04 AM: 	Saved vocab to ./experiments/ner-ontonotes-multiqa-top/vocab
09/16 09:14:04 AM: Loading token dictionary from ./experiments/ner-ontonotes-multiqa-top/vocab.
09/16 09:14:04 AM: 	Loaded vocab from ./experiments/ner-ontonotes-multiqa-top/vocab
09/16 09:14:04 AM: 	Vocab namespace edges-ner-ontonotes_labels: size 18
09/16 09:14:04 AM: 	Vocab namespace tokens: size 22840
09/16 09:14:04 AM: 	Vocab namespace bert_uncased: size 30524
09/16 09:14:04 AM: 	Vocab namespace chars: size 77
09/16 09:14:04 AM: 	Finished building vocab.
09/16 09:14:04 AM: 	Task edges-ner-ontonotes (train): Indexing from scratch.
09/16 09:14:14 AM: 	Task edges-ner-ontonotes (train): Saved 49706 instances to ./experiments/ner-ontonotes-multiqa-top/preproc/edges-ner-ontonotes__train_data
09/16 09:14:14 AM: 	Task edges-ner-ontonotes (val): Indexing from scratch.
09/16 09:14:16 AM: 	Task edges-ner-ontonotes (val): Saved 7610 instances to ./experiments/ner-ontonotes-multiqa-top/preproc/edges-ner-ontonotes__val_data
09/16 09:14:16 AM: 	Task edges-ner-ontonotes (test): Indexing from scratch.
09/16 09:14:17 AM: 	Task edges-ner-ontonotes (test): Saved 5099 instances to ./experiments/ner-ontonotes-multiqa-top/preproc/edges-ner-ontonotes__test_data
09/16 09:14:17 AM: 	Finished indexing tasks
09/16 09:14:17 AM: 	Creating trimmed target-only version of edges-ner-ontonotes train.
09/16 09:14:17 AM: 	  Training on 
09/16 09:14:17 AM: 	  Evaluating on edges-ner-ontonotes
09/16 09:14:17 AM: 	Finished loading tasks in 19.205s
09/16 09:14:17 AM: 	 Tasks: ['edges-ner-ontonotes']
09/16 09:14:17 AM: Building model...
09/16 09:14:17 AM: Using BERT model (bert-base-uncased).
09/16 09:14:17 AM: LOADING A FUNETUNED MODEL from: 
09/16 09:14:17 AM: models/multiqa
09/16 09:14:17 AM: loading configuration file models/multiqa/config.json
09/16 09:14:17 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 09:14:17 AM: loading weights file models/multiqa/pytorch_model.bin
09/16 09:14:22 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpxrtc8pol
09/16 09:14:29 AM: copying /tmp/tmpxrtc8pol to cache at ./experiments/ner-ontonotes-multiqa-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:14:29 AM: creating metadata file for ./experiments/ner-ontonotes-multiqa-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:14:29 AM: removing temp file /tmp/tmpxrtc8pol
09/16 09:14:29 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/ner-ontonotes-multiqa-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:14:30 AM: Initializing parameters
09/16 09:14:30 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 09:14:30 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 09:14:30 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 09:14:30 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 09:14:30 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 09:14:30 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 09:14:30 AM: 	Task 'edges-ner-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-ner-ontonotes"
}
09/16 09:14:53 AM: Model specification:
09/16 09:14:53 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-ner-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=18, bias=True)
    )
  )
)
09/16 09:14:53 AM: Model parameters:
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:14:53 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:14:53 AM: 	edges-ner-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 09:14:53 AM: 	edges-ner-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 09:14:53 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 9216 with torch.Size([18, 512])
09/16 09:14:53 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 18 with torch.Size([18])
09/16 09:14:53 AM: Total number of parameters: 109688338 (1.09688e+08)
09/16 09:14:53 AM: Number of trainable parameters: 206098 (206098)
09/16 09:14:53 AM: Finished building model in 35.886s
09/16 09:14:53 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-ner-ontonotes 

09/16 09:14:56 AM: patience = 9
09/16 09:14:56 AM: val_interval = 1000
09/16 09:14:56 AM: max_vals = 250
09/16 09:14:56 AM: cuda_device = 0
09/16 09:14:56 AM: grad_norm = 5.0
09/16 09:14:56 AM: grad_clipping = None
09/16 09:14:56 AM: lr_decay = 0.99
09/16 09:14:56 AM: min_lr = 1e-06
09/16 09:14:56 AM: keep_all_checkpoints = 0
09/16 09:14:56 AM: val_data_limit = 5000
09/16 09:14:56 AM: max_epochs = -1
09/16 09:14:56 AM: dec_val_scale = 250
09/16 09:14:56 AM: training_data_fraction = 1
09/16 09:14:56 AM: type = adam
09/16 09:14:56 AM: parameter_groups = None
09/16 09:14:56 AM: Number of trainable parameters: 206098
09/16 09:14:56 AM: infer_type_and_cast = True
09/16 09:14:56 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:14:56 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:14:56 AM: lr = 0.0001
09/16 09:14:56 AM: amsgrad = True
09/16 09:14:56 AM: type = reduce_on_plateau
09/16 09:14:56 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:14:56 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:14:56 AM: mode = max
09/16 09:14:56 AM: factor = 0.5
09/16 09:14:56 AM: patience = 3
09/16 09:14:56 AM: threshold = 0.0001
09/16 09:14:56 AM: threshold_mode = abs
09/16 09:14:56 AM: verbose = True
09/16 09:14:56 AM: type = adam
09/16 09:14:56 AM: parameter_groups = None
09/16 09:14:56 AM: Number of trainable parameters: 206098
09/16 09:14:56 AM: infer_type_and_cast = True
09/16 09:14:56 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:14:56 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:14:56 AM: lr = 0.0001
09/16 09:14:56 AM: amsgrad = True
09/16 09:14:56 AM: type = reduce_on_plateau
09/16 09:14:56 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:14:56 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:14:56 AM: mode = max
09/16 09:14:56 AM: factor = 0.5
09/16 09:14:56 AM: patience = 3
09/16 09:14:56 AM: threshold = 0.0001
09/16 09:14:56 AM: threshold_mode = abs
09/16 09:14:56 AM: verbose = True
09/16 09:14:56 AM: Starting training without restoring from a checkpoint.
09/16 09:14:56 AM: Training examples per task, before any subsampling: {'edges-ner-ontonotes': 49706}
09/16 09:14:56 AM: Beginning training with stopping criteria based on metric: edges-ner-ontonotes_f1
09/16 09:15:06 AM: Update 35: task edges-ner-ontonotes, batch 35 (35): mcc: -0.0099, acc: 0.0055, precision: 0.0488, recall: 0.0877, f1: 0.0627, edges-ner-ontonotes_loss: 0.4118
09/16 09:15:16 AM: Update 186: task edges-ner-ontonotes, batch 186 (186): mcc: 0.0449, acc: 0.0334, precision: 0.1234, recall: 0.0500, f1: 0.0711, edges-ner-ontonotes_loss: 0.2133
09/16 09:15:27 AM: Update 314: task edges-ner-ontonotes, batch 314 (314): mcc: 0.1238, acc: 0.0731, precision: 0.2712, recall: 0.0829, f1: 0.1270, edges-ner-ontonotes_loss: 0.1845
09/16 09:15:37 AM: Update 443: task edges-ner-ontonotes, batch 443 (443): mcc: 0.2263, acc: 0.1285, precision: 0.4562, recall: 0.1352, f1: 0.2085, edges-ner-ontonotes_loss: 0.1673
09/16 09:15:47 AM: Update 568: task edges-ner-ontonotes, batch 568 (568): mcc: 0.3079, acc: 0.1791, precision: 0.5819, recall: 0.1847, f1: 0.2804, edges-ner-ontonotes_loss: 0.1552
09/16 09:15:57 AM: Update 677: task edges-ner-ontonotes, batch 677 (677): mcc: 0.3655, acc: 0.2196, precision: 0.6557, recall: 0.2253, f1: 0.3354, edges-ner-ontonotes_loss: 0.1468
09/16 09:16:07 AM: Update 803: task edges-ner-ontonotes, batch 803 (803): mcc: 0.4182, acc: 0.2601, precision: 0.7113, recall: 0.2675, f1: 0.3888, edges-ner-ontonotes_loss: 0.1387
09/16 09:16:17 AM: Update 928: task edges-ner-ontonotes, batch 928 (928): mcc: 0.4613, acc: 0.2974, precision: 0.7472, recall: 0.3068, f1: 0.4350, edges-ner-ontonotes_loss: 0.1317
09/16 09:16:25 AM: ***** Step 1000 / Validation 1 *****
09/16 09:16:25 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:16:25 AM: Validating...
09/16 09:16:27 AM: Evaluate: task edges-ner-ontonotes, batch 26 (157): mcc: 0.6176, acc: 0.4902, precision: 0.7939, recall: 0.5060, f1: 0.6181, edges-ner-ontonotes_loss: 0.1085
09/16 09:16:37 AM: Evaluate: task edges-ner-ontonotes, batch 82 (157): mcc: 0.6563, acc: 0.5195, precision: 0.8314, recall: 0.5415, f1: 0.6559, edges-ner-ontonotes_loss: 0.0962
09/16 09:16:47 AM: Evaluate: task edges-ner-ontonotes, batch 131 (157): mcc: 0.6801, acc: 0.5382, precision: 0.8628, recall: 0.5576, f1: 0.6774, edges-ner-ontonotes_loss: 0.0896
09/16 09:16:50 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:16:51 AM: Best result seen so far for micro.
09/16 09:16:51 AM: Best result seen so far for macro.
09/16 09:16:51 AM: Updating LR scheduler:
09/16 09:16:51 AM: 	Best result seen so far for macro_avg: 0.677
09/16 09:16:51 AM: 	# validation passes without improvement: 0
09/16 09:16:51 AM: edges-ner-ontonotes_loss: training: 0.128548 validation: 0.088802
09/16 09:16:51 AM: macro_avg: validation: 0.677218
09/16 09:16:51 AM: micro_avg: validation: 0.000000
09/16 09:16:51 AM: edges-ner-ontonotes_mcc: training: 0.481499 validation: 0.680298
09/16 09:16:51 AM: edges-ner-ontonotes_acc: training: 0.315864 validation: 0.538217
09/16 09:16:51 AM: edges-ner-ontonotes_precision: training: 0.762041 validation: 0.865024
09/16 09:16:51 AM: edges-ner-ontonotes_recall: training: 0.326348 validation: 0.556415
09/16 09:16:51 AM: edges-ner-ontonotes_f1: training: 0.456988 validation: 0.677218
09/16 09:16:51 AM: Global learning rate: 0.0001
09/16 09:16:51 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:16:57 AM: Update 1076: task edges-ner-ontonotes, batch 76 (1076): mcc: 0.6924, acc: 0.5431, precision: 0.8743, recall: 0.5692, f1: 0.6895, edges-ner-ontonotes_loss: 0.0833
09/16 09:17:07 AM: Update 1201: task edges-ner-ontonotes, batch 201 (1201): mcc: 0.6997, acc: 0.5547, precision: 0.8748, recall: 0.5804, f1: 0.6978, edges-ner-ontonotes_loss: 0.0812
09/16 09:17:18 AM: Update 1299: task edges-ner-ontonotes, batch 299 (1299): mcc: 0.6905, acc: 0.5455, precision: 0.8681, recall: 0.5704, f1: 0.6885, edges-ner-ontonotes_loss: 0.0829
09/16 09:17:28 AM: Update 1426: task edges-ner-ontonotes, batch 426 (1426): mcc: 0.6843, acc: 0.5402, precision: 0.8637, recall: 0.5637, f1: 0.6822, edges-ner-ontonotes_loss: 0.0846
09/16 09:17:38 AM: Update 1555: task edges-ner-ontonotes, batch 555 (1555): mcc: 0.6836, acc: 0.5410, precision: 0.8616, recall: 0.5640, f1: 0.6817, edges-ner-ontonotes_loss: 0.0849
09/16 09:17:48 AM: Update 1693: task edges-ner-ontonotes, batch 693 (1693): mcc: 0.6864, acc: 0.5468, precision: 0.8604, recall: 0.5694, f1: 0.6853, edges-ner-ontonotes_loss: 0.0840
09/16 09:17:58 AM: Update 1840: task edges-ner-ontonotes, batch 840 (1840): mcc: 0.6895, acc: 0.5522, precision: 0.8602, recall: 0.5745, f1: 0.6889, edges-ner-ontonotes_loss: 0.0831
09/16 09:18:08 AM: Update 1948: task edges-ner-ontonotes, batch 948 (1948): mcc: 0.6941, acc: 0.5587, precision: 0.8610, recall: 0.5813, f1: 0.6940, edges-ner-ontonotes_loss: 0.0820
09/16 09:18:12 AM: ***** Step 2000 / Validation 2 *****
09/16 09:18:12 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:18:12 AM: Validating...
09/16 09:18:18 AM: Evaluate: task edges-ner-ontonotes, batch 54 (157): mcc: 0.7594, acc: 0.6602, precision: 0.8865, recall: 0.6699, f1: 0.7632, edges-ner-ontonotes_loss: 0.0715
09/16 09:18:28 AM: Evaluate: task edges-ner-ontonotes, batch 127 (157): mcc: 0.7783, acc: 0.6694, precision: 0.9094, recall: 0.6838, f1: 0.7806, edges-ner-ontonotes_loss: 0.0666
09/16 09:18:31 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:18:31 AM: Best result seen so far for macro.
09/16 09:18:31 AM: Updating LR scheduler:
09/16 09:18:31 AM: 	Best result seen so far for macro_avg: 0.777
09/16 09:18:31 AM: 	# validation passes without improvement: 0
09/16 09:18:31 AM: edges-ner-ontonotes_loss: training: 0.081575 validation: 0.066552
09/16 09:18:31 AM: macro_avg: validation: 0.776727
09/16 09:18:31 AM: micro_avg: validation: 0.000000
09/16 09:18:31 AM: edges-ner-ontonotes_mcc: training: 0.696233 validation: 0.774536
09/16 09:18:31 AM: edges-ner-ontonotes_acc: training: 0.561921 validation: 0.663861
09/16 09:18:31 AM: edges-ner-ontonotes_precision: training: 0.861090 validation: 0.907809
09/16 09:18:31 AM: edges-ner-ontonotes_recall: training: 0.584613 validation: 0.678723
09/16 09:18:31 AM: edges-ner-ontonotes_f1: training: 0.696415 validation: 0.776727
09/16 09:18:31 AM: Global learning rate: 0.0001
09/16 09:18:31 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:18:38 AM: Update 2082: task edges-ner-ontonotes, batch 82 (2082): mcc: 0.7399, acc: 0.6268, precision: 0.8648, recall: 0.6541, f1: 0.7448, edges-ner-ontonotes_loss: 0.0696
09/16 09:18:48 AM: Update 2185: task edges-ner-ontonotes, batch 185 (2185): mcc: 0.7385, acc: 0.6243, precision: 0.8659, recall: 0.6509, f1: 0.7432, edges-ner-ontonotes_loss: 0.0699
09/16 09:18:58 AM: Update 2308: task edges-ner-ontonotes, batch 308 (2308): mcc: 0.7513, acc: 0.6369, precision: 0.8744, recall: 0.6659, f1: 0.7560, edges-ner-ontonotes_loss: 0.0678
09/16 09:19:08 AM: Update 2432: task edges-ner-ontonotes, batch 432 (2432): mcc: 0.7581, acc: 0.6449, precision: 0.8766, recall: 0.6756, f1: 0.7631, edges-ner-ontonotes_loss: 0.0662
09/16 09:19:18 AM: Update 2528: task edges-ner-ontonotes, batch 528 (2528): mcc: 0.7590, acc: 0.6455, precision: 0.8767, recall: 0.6771, f1: 0.7641, edges-ner-ontonotes_loss: 0.0659
09/16 09:19:28 AM: Update 2649: task edges-ner-ontonotes, batch 649 (2649): mcc: 0.7609, acc: 0.6485, precision: 0.8766, recall: 0.6804, f1: 0.7661, edges-ner-ontonotes_loss: 0.0656
09/16 09:19:38 AM: Update 2773: task edges-ner-ontonotes, batch 773 (2773): mcc: 0.7641, acc: 0.6527, precision: 0.8774, recall: 0.6852, f1: 0.7695, edges-ner-ontonotes_loss: 0.0649
09/16 09:19:48 AM: Update 2870: task edges-ner-ontonotes, batch 870 (2870): mcc: 0.7607, acc: 0.6486, precision: 0.8749, recall: 0.6815, f1: 0.7662, edges-ner-ontonotes_loss: 0.0657
09/16 09:19:58 AM: Update 2996: task edges-ner-ontonotes, batch 996 (2996): mcc: 0.7563, acc: 0.6438, precision: 0.8717, recall: 0.6765, f1: 0.7618, edges-ner-ontonotes_loss: 0.0669
09/16 09:19:59 AM: ***** Step 3000 / Validation 3 *****
09/16 09:19:59 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:19:59 AM: Validating...
09/16 09:20:08 AM: Evaluate: task edges-ner-ontonotes, batch 83 (157): mcc: 0.7953, acc: 0.7037, precision: 0.9032, recall: 0.7178, f1: 0.7999, edges-ner-ontonotes_loss: 0.0617
09/16 09:20:18 AM: Evaluate: task edges-ner-ontonotes, batch 156 (157): mcc: 0.8012, acc: 0.7041, precision: 0.9167, recall: 0.7170, f1: 0.8046, edges-ner-ontonotes_loss: 0.0589
09/16 09:20:18 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:20:18 AM: Best result seen so far for macro.
09/16 09:20:18 AM: Updating LR scheduler:
09/16 09:20:18 AM: 	Best result seen so far for macro_avg: 0.805
09/16 09:20:18 AM: 	# validation passes without improvement: 0
09/16 09:20:18 AM: edges-ner-ontonotes_loss: training: 0.066872 validation: 0.058797
09/16 09:20:18 AM: macro_avg: validation: 0.804629
09/16 09:20:18 AM: micro_avg: validation: 0.000000
09/16 09:20:18 AM: edges-ner-ontonotes_mcc: training: 0.756381 validation: 0.801251
09/16 09:20:18 AM: edges-ner-ontonotes_acc: training: 0.643841 validation: 0.704201
09/16 09:20:18 AM: edges-ner-ontonotes_precision: training: 0.871800 validation: 0.916634
09/16 09:20:18 AM: edges-ner-ontonotes_recall: training: 0.676542 validation: 0.717015
09/16 09:20:18 AM: edges-ner-ontonotes_f1: training: 0.761859 validation: 0.804629
09/16 09:20:18 AM: Global learning rate: 0.0001
09/16 09:20:18 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:20:29 AM: Update 3113: task edges-ner-ontonotes, batch 113 (3113): mcc: 0.7308, acc: 0.6176, precision: 0.8539, recall: 0.6474, f1: 0.7364, edges-ner-ontonotes_loss: 0.0736
09/16 09:20:39 AM: Update 3255: task edges-ner-ontonotes, batch 255 (3255): mcc: 0.7360, acc: 0.6251, precision: 0.8556, recall: 0.6547, f1: 0.7418, edges-ner-ontonotes_loss: 0.0719
09/16 09:20:49 AM: Update 3402: task edges-ner-ontonotes, batch 402 (3402): mcc: 0.7392, acc: 0.6274, precision: 0.8584, recall: 0.6580, f1: 0.7450, edges-ner-ontonotes_loss: 0.0709
09/16 09:20:59 AM: Update 3515: task edges-ner-ontonotes, batch 515 (3515): mcc: 0.7433, acc: 0.6336, precision: 0.8597, recall: 0.6640, f1: 0.7493, edges-ner-ontonotes_loss: 0.0696
09/16 09:21:09 AM: Update 3638: task edges-ner-ontonotes, batch 638 (3638): mcc: 0.7494, acc: 0.6417, precision: 0.8622, recall: 0.6724, f1: 0.7556, edges-ner-ontonotes_loss: 0.0681
09/16 09:21:19 AM: Update 3740: task edges-ner-ontonotes, batch 740 (3740): mcc: 0.7518, acc: 0.6451, precision: 0.8635, recall: 0.6755, f1: 0.7580, edges-ner-ontonotes_loss: 0.0674
09/16 09:21:29 AM: Update 3855: task edges-ner-ontonotes, batch 855 (3855): mcc: 0.7573, acc: 0.6514, precision: 0.8659, recall: 0.6830, f1: 0.7636, edges-ner-ontonotes_loss: 0.0662
09/16 09:21:39 AM: Update 3985: task edges-ner-ontonotes, batch 985 (3985): mcc: 0.7630, acc: 0.6579, precision: 0.8692, recall: 0.6901, f1: 0.7694, edges-ner-ontonotes_loss: 0.0649
09/16 09:21:40 AM: ***** Step 4000 / Validation 4 *****
09/16 09:21:40 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:21:40 AM: Validating...
09/16 09:21:49 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.8006, acc: 0.7205, precision: 0.8907, recall: 0.7376, f1: 0.8069, edges-ner-ontonotes_loss: 0.0610
09/16 09:21:59 AM: Evaluate: task edges-ner-ontonotes, batch 135 (157): mcc: 0.8201, acc: 0.7349, precision: 0.9166, recall: 0.7497, f1: 0.8248, edges-ner-ontonotes_loss: 0.0548
09/16 09:22:02 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:22:02 AM: Best result seen so far for macro.
09/16 09:22:02 AM: Updating LR scheduler:
09/16 09:22:02 AM: 	Best result seen so far for macro_avg: 0.824
09/16 09:22:02 AM: 	# validation passes without improvement: 0
09/16 09:22:02 AM: edges-ner-ontonotes_loss: training: 0.064694 validation: 0.054600
09/16 09:22:02 AM: macro_avg: validation: 0.824104
09/16 09:22:02 AM: micro_avg: validation: 0.000000
09/16 09:22:02 AM: edges-ner-ontonotes_mcc: training: 0.763892 validation: 0.819470
09/16 09:22:02 AM: edges-ner-ontonotes_acc: training: 0.658843 validation: 0.733773
09/16 09:22:02 AM: edges-ner-ontonotes_precision: training: 0.869818 validation: 0.916381
09/16 09:22:02 AM: edges-ner-ontonotes_recall: training: 0.691089 validation: 0.748711
09/16 09:22:02 AM: edges-ner-ontonotes_f1: training: 0.770221 validation: 0.824104
09/16 09:22:02 AM: Global learning rate: 0.0001
09/16 09:22:02 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:22:09 AM: Update 4065: task edges-ner-ontonotes, batch 65 (4065): mcc: 0.7949, acc: 0.6949, precision: 0.8901, recall: 0.7281, f1: 0.8010, edges-ner-ontonotes_loss: 0.0561
09/16 09:22:19 AM: Update 4191: task edges-ner-ontonotes, batch 191 (4191): mcc: 0.7939, acc: 0.6941, precision: 0.8841, recall: 0.7314, f1: 0.8005, edges-ner-ontonotes_loss: 0.0564
09/16 09:22:29 AM: Update 4316: task edges-ner-ontonotes, batch 316 (4316): mcc: 0.7959, acc: 0.6971, precision: 0.8846, recall: 0.7345, f1: 0.8026, edges-ner-ontonotes_loss: 0.0562
09/16 09:22:40 AM: Update 4424: task edges-ner-ontonotes, batch 424 (4424): mcc: 0.7883, acc: 0.6878, precision: 0.8794, recall: 0.7255, f1: 0.7951, edges-ner-ontonotes_loss: 0.0584
09/16 09:22:50 AM: Update 4550: task edges-ner-ontonotes, batch 550 (4550): mcc: 0.7796, acc: 0.6764, precision: 0.8750, recall: 0.7140, f1: 0.7863, edges-ner-ontonotes_loss: 0.0615
09/16 09:23:01 AM: Update 4669: task edges-ner-ontonotes, batch 669 (4669): mcc: 0.7739, acc: 0.6701, precision: 0.8705, recall: 0.7079, f1: 0.7808, edges-ner-ontonotes_loss: 0.0632
09/16 09:23:11 AM: Update 4817: task edges-ner-ontonotes, batch 817 (4817): mcc: 0.7713, acc: 0.6677, precision: 0.8689, recall: 0.7046, f1: 0.7782, edges-ner-ontonotes_loss: 0.0637
09/16 09:23:21 AM: Update 4956: task edges-ner-ontonotes, batch 956 (4956): mcc: 0.7693, acc: 0.6653, precision: 0.8675, recall: 0.7025, f1: 0.7763, edges-ner-ontonotes_loss: 0.0639
09/16 09:23:26 AM: ***** Step 5000 / Validation 5 *****
09/16 09:23:26 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:23:26 AM: Validating...
09/16 09:23:31 AM: Evaluate: task edges-ner-ontonotes, batch 44 (157): mcc: 0.8030, acc: 0.7256, precision: 0.8836, recall: 0.7479, f1: 0.8101, edges-ner-ontonotes_loss: 0.0566
09/16 09:23:42 AM: Evaluate: task edges-ner-ontonotes, batch 116 (157): mcc: 0.8314, acc: 0.7533, precision: 0.9118, recall: 0.7737, f1: 0.8371, edges-ner-ontonotes_loss: 0.0510
09/16 09:23:47 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:23:47 AM: Best result seen so far for macro.
09/16 09:23:50 AM: Updating LR scheduler:
09/16 09:23:50 AM: 	Best result seen so far for macro_avg: 0.836
09/16 09:23:50 AM: 	# validation passes without improvement: 0
09/16 09:23:50 AM: edges-ner-ontonotes_loss: training: 0.063882 validation: 0.050777
09/16 09:23:50 AM: macro_avg: validation: 0.835646
09/16 09:23:50 AM: micro_avg: validation: 0.000000
09/16 09:23:50 AM: edges-ner-ontonotes_mcc: training: 0.768570 validation: 0.830286
09/16 09:23:50 AM: edges-ner-ontonotes_acc: training: 0.664252 validation: 0.749469
09/16 09:23:50 AM: edges-ner-ontonotes_precision: training: 0.867127 validation: 0.914466
09/16 09:23:50 AM: edges-ner-ontonotes_recall: training: 0.701460 validation: 0.769336
09/16 09:23:50 AM: edges-ner-ontonotes_f1: training: 0.775545 validation: 0.835646
09/16 09:23:50 AM: Global learning rate: 0.0001
09/16 09:23:50 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:23:52 AM: Update 5018: task edges-ner-ontonotes, batch 18 (5018): mcc: 0.7565, acc: 0.6544, precision: 0.8564, recall: 0.6895, f1: 0.7639, edges-ner-ontonotes_loss: 0.0661
09/16 09:24:02 AM: Update 5139: task edges-ner-ontonotes, batch 139 (5139): mcc: 0.7708, acc: 0.6723, precision: 0.8663, recall: 0.7060, f1: 0.7780, edges-ner-ontonotes_loss: 0.0623
09/16 09:24:12 AM: Update 5273: task edges-ner-ontonotes, batch 273 (5273): mcc: 0.7769, acc: 0.6795, precision: 0.8694, recall: 0.7141, f1: 0.7841, edges-ner-ontonotes_loss: 0.0603
09/16 09:24:22 AM: Update 5384: task edges-ner-ontonotes, batch 384 (5384): mcc: 0.7833, acc: 0.6862, precision: 0.8737, recall: 0.7217, f1: 0.7905, edges-ner-ontonotes_loss: 0.0587
09/16 09:24:32 AM: Update 5502: task edges-ner-ontonotes, batch 502 (5502): mcc: 0.7889, acc: 0.6921, precision: 0.8773, recall: 0.7285, f1: 0.7960, edges-ner-ontonotes_loss: 0.0574
09/16 09:24:43 AM: Update 5608: task edges-ner-ontonotes, batch 608 (5608): mcc: 0.7922, acc: 0.6961, precision: 0.8790, recall: 0.7327, f1: 0.7992, edges-ner-ontonotes_loss: 0.0566
09/16 09:24:53 AM: Update 5719: task edges-ner-ontonotes, batch 719 (5719): mcc: 0.7939, acc: 0.6980, precision: 0.8799, recall: 0.7350, f1: 0.8010, edges-ner-ontonotes_loss: 0.0563
09/16 09:25:03 AM: Update 5843: task edges-ner-ontonotes, batch 843 (5843): mcc: 0.7964, acc: 0.7012, precision: 0.8813, recall: 0.7382, f1: 0.8034, edges-ner-ontonotes_loss: 0.0558
09/16 09:25:13 AM: Update 5951: task edges-ner-ontonotes, batch 951 (5951): mcc: 0.7949, acc: 0.6991, precision: 0.8807, recall: 0.7360, f1: 0.8019, edges-ner-ontonotes_loss: 0.0563
09/16 09:25:18 AM: ***** Step 6000 / Validation 6 *****
09/16 09:25:18 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:25:18 AM: Validating...
09/16 09:25:23 AM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.8056, acc: 0.7272, precision: 0.8894, recall: 0.7476, f1: 0.8123, edges-ner-ontonotes_loss: 0.0565
09/16 09:25:35 AM: Evaluate: task edges-ner-ontonotes, batch 124 (157): mcc: 0.8320, acc: 0.7514, precision: 0.9197, recall: 0.7679, f1: 0.8370, edges-ner-ontonotes_loss: 0.0506
09/16 09:25:39 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:25:39 AM: Best result seen so far for macro.
09/16 09:25:39 AM: Updating LR scheduler:
09/16 09:25:39 AM: 	Best result seen so far for macro_avg: 0.839
09/16 09:25:39 AM: 	# validation passes without improvement: 0
09/16 09:25:39 AM: edges-ner-ontonotes_loss: training: 0.056949 validation: 0.049208
09/16 09:25:39 AM: macro_avg: validation: 0.838515
09/16 09:25:39 AM: micro_avg: validation: 0.000000
09/16 09:25:39 AM: edges-ner-ontonotes_mcc: training: 0.792135 validation: 0.833713
09/16 09:25:39 AM: edges-ner-ontonotes_acc: training: 0.695515 validation: 0.751971
09/16 09:25:39 AM: edges-ner-ontonotes_precision: training: 0.879213 validation: 0.921909
09/16 09:25:39 AM: edges-ner-ontonotes_recall: training: 0.732479 validation: 0.768957
09/16 09:25:39 AM: edges-ner-ontonotes_f1: training: 0.799166 validation: 0.838515
09/16 09:25:39 AM: Global learning rate: 0.0001
09/16 09:25:39 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:25:45 AM: Update 6076: task edges-ner-ontonotes, batch 76 (6076): mcc: 0.7535, acc: 0.6500, precision: 0.8576, recall: 0.6832, f1: 0.7605, edges-ner-ontonotes_loss: 0.0683
09/16 09:25:55 AM: Update 6204: task edges-ner-ontonotes, batch 204 (6204): mcc: 0.7550, acc: 0.6512, precision: 0.8564, recall: 0.6867, f1: 0.7623, edges-ner-ontonotes_loss: 0.0688
09/16 09:26:05 AM: Update 6323: task edges-ner-ontonotes, batch 323 (6323): mcc: 0.7594, acc: 0.6560, precision: 0.8589, recall: 0.6925, f1: 0.7668, edges-ner-ontonotes_loss: 0.0672
09/16 09:26:15 AM: Update 6469: task edges-ner-ontonotes, batch 469 (6469): mcc: 0.7577, acc: 0.6539, precision: 0.8570, recall: 0.6911, f1: 0.7651, edges-ner-ontonotes_loss: 0.0663
09/16 09:26:26 AM: Update 6583: task edges-ner-ontonotes, batch 583 (6583): mcc: 0.7606, acc: 0.6577, precision: 0.8585, recall: 0.6950, f1: 0.7681, edges-ner-ontonotes_loss: 0.0652
09/16 09:26:36 AM: Update 6708: task edges-ner-ontonotes, batch 708 (6708): mcc: 0.7653, acc: 0.6645, precision: 0.8610, recall: 0.7010, f1: 0.7728, edges-ner-ontonotes_loss: 0.0640
09/16 09:26:46 AM: Update 6833: task edges-ner-ontonotes, batch 833 (6833): mcc: 0.7699, acc: 0.6698, precision: 0.8639, recall: 0.7065, f1: 0.7773, edges-ner-ontonotes_loss: 0.0628
09/16 09:26:56 AM: Update 6936: task edges-ner-ontonotes, batch 936 (6936): mcc: 0.7742, acc: 0.6752, precision: 0.8663, recall: 0.7120, f1: 0.7816, edges-ner-ontonotes_loss: 0.0618
09/16 09:27:01 AM: ***** Step 7000 / Validation 7 *****
09/16 09:27:01 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:27:01 AM: Validating...
09/16 09:27:06 AM: Evaluate: task edges-ner-ontonotes, batch 46 (157): mcc: 0.7929, acc: 0.7127, precision: 0.8704, recall: 0.7416, f1: 0.8009, edges-ner-ontonotes_loss: 0.0601
09/16 09:27:16 AM: Evaluate: task edges-ner-ontonotes, batch 115 (157): mcc: 0.8294, acc: 0.7501, precision: 0.9097, recall: 0.7719, f1: 0.8351, edges-ner-ontonotes_loss: 0.0511
09/16 09:27:21 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:27:21 AM: Best result seen so far for macro.
09/16 09:27:21 AM: Updating LR scheduler:
09/16 09:27:21 AM: 	Best result seen so far for macro_avg: 0.842
09/16 09:27:21 AM: 	# validation passes without improvement: 0
09/16 09:27:21 AM: edges-ner-ontonotes_loss: training: 0.061023 validation: 0.048891
09/16 09:27:21 AM: macro_avg: validation: 0.841536
09/16 09:27:21 AM: micro_avg: validation: 0.000000
09/16 09:27:21 AM: edges-ner-ontonotes_mcc: training: 0.777562 validation: 0.836049
09/16 09:27:21 AM: edges-ner-ontonotes_acc: training: 0.679071 validation: 0.757507
09/16 09:27:21 AM: edges-ner-ontonotes_precision: training: 0.868683 validation: 0.915560
09/16 09:27:21 AM: edges-ner-ontonotes_recall: training: 0.715876 validation: 0.778587
09/16 09:27:21 AM: edges-ner-ontonotes_f1: training: 0.784911 validation: 0.841536
09/16 09:27:21 AM: Global learning rate: 0.0001
09/16 09:27:21 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:27:26 AM: Update 7061: task edges-ner-ontonotes, batch 61 (7061): mcc: 0.8200, acc: 0.7335, precision: 0.8882, recall: 0.7742, f1: 0.8273, edges-ner-ontonotes_loss: 0.0494
09/16 09:27:36 AM: Update 7165: task edges-ner-ontonotes, batch 165 (7165): mcc: 0.8131, acc: 0.7222, precision: 0.8897, recall: 0.7605, f1: 0.8201, edges-ner-ontonotes_loss: 0.0507
09/16 09:27:46 AM: Update 7293: task edges-ner-ontonotes, batch 293 (7293): mcc: 0.8127, acc: 0.7229, precision: 0.8885, recall: 0.7608, f1: 0.8197, edges-ner-ontonotes_loss: 0.0512
09/16 09:27:56 AM: Update 7412: task edges-ner-ontonotes, batch 412 (7412): mcc: 0.8118, acc: 0.7216, precision: 0.8880, recall: 0.7597, f1: 0.8189, edges-ner-ontonotes_loss: 0.0513
09/16 09:28:06 AM: Update 7518: task edges-ner-ontonotes, batch 518 (7518): mcc: 0.8060, acc: 0.7138, precision: 0.8842, recall: 0.7526, f1: 0.8131, edges-ner-ontonotes_loss: 0.0531
09/16 09:28:16 AM: Update 7641: task edges-ner-ontonotes, batch 641 (7641): mcc: 0.7966, acc: 0.7019, precision: 0.8782, recall: 0.7412, f1: 0.8039, edges-ner-ontonotes_loss: 0.0558
09/16 09:28:26 AM: Update 7773: task edges-ner-ontonotes, batch 773 (7773): mcc: 0.7918, acc: 0.6956, precision: 0.8754, recall: 0.7352, f1: 0.7992, edges-ner-ontonotes_loss: 0.0577
09/16 09:28:36 AM: Update 7892: task edges-ner-ontonotes, batch 892 (7892): mcc: 0.7891, acc: 0.6922, precision: 0.8734, recall: 0.7322, f1: 0.7966, edges-ner-ontonotes_loss: 0.0585
09/16 09:28:44 AM: ***** Step 8000 / Validation 8 *****
09/16 09:28:44 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:28:44 AM: Validating...
09/16 09:28:46 AM: Evaluate: task edges-ner-ontonotes, batch 23 (157): mcc: 0.7766, acc: 0.6953, precision: 0.8577, recall: 0.7237, f1: 0.7851, edges-ner-ontonotes_loss: 0.0617
09/16 09:28:56 AM: Evaluate: task edges-ner-ontonotes, batch 101 (157): mcc: 0.8314, acc: 0.7495, precision: 0.9143, recall: 0.7713, f1: 0.8368, edges-ner-ontonotes_loss: 0.0486
09/16 09:29:04 AM: Updating LR scheduler:
09/16 09:29:04 AM: 	Best result seen so far for macro_avg: 0.842
09/16 09:29:04 AM: 	# validation passes without improvement: 1
09/16 09:29:04 AM: edges-ner-ontonotes_loss: training: 0.058738 validation: 0.047917
09/16 09:29:04 AM: macro_avg: validation: 0.837518
09/16 09:29:04 AM: micro_avg: validation: 0.000000
09/16 09:29:04 AM: edges-ner-ontonotes_mcc: training: 0.787982 validation: 0.832873
09/16 09:29:04 AM: edges-ner-ontonotes_acc: training: 0.690958 validation: 0.746436
09/16 09:29:04 AM: edges-ner-ontonotes_precision: training: 0.872691 validation: 0.923105
09/16 09:29:04 AM: edges-ner-ontonotes_recall: training: 0.730790 validation: 0.766454
09/16 09:29:04 AM: edges-ner-ontonotes_f1: training: 0.795462 validation: 0.837518
09/16 09:29:04 AM: Global learning rate: 0.0001
09/16 09:29:04 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:29:06 AM: Update 8029: task edges-ner-ontonotes, batch 29 (8029): mcc: 0.7787, acc: 0.6779, precision: 0.8523, recall: 0.7323, f1: 0.7877, edges-ner-ontonotes_loss: 0.0579
09/16 09:29:16 AM: Update 8135: task edges-ner-ontonotes, batch 135 (8135): mcc: 0.7790, acc: 0.6799, precision: 0.8655, recall: 0.7212, f1: 0.7868, edges-ner-ontonotes_loss: 0.0595
09/16 09:29:26 AM: Update 8263: task edges-ner-ontonotes, batch 263 (8263): mcc: 0.7856, acc: 0.6896, precision: 0.8692, recall: 0.7295, f1: 0.7933, edges-ner-ontonotes_loss: 0.0578
09/16 09:29:36 AM: Update 8387: task edges-ner-ontonotes, batch 387 (8387): mcc: 0.7861, acc: 0.6904, precision: 0.8696, recall: 0.7302, f1: 0.7938, edges-ner-ontonotes_loss: 0.0575
09/16 09:29:46 AM: Update 8492: task edges-ner-ontonotes, batch 492 (8492): mcc: 0.7897, acc: 0.6948, precision: 0.8717, recall: 0.7347, f1: 0.7974, edges-ner-ontonotes_loss: 0.0567
09/16 09:29:56 AM: Update 8609: task edges-ner-ontonotes, batch 609 (8609): mcc: 0.7973, acc: 0.7040, precision: 0.8773, recall: 0.7433, f1: 0.8047, edges-ner-ontonotes_loss: 0.0550
09/16 09:30:07 AM: Update 8720: task edges-ner-ontonotes, batch 720 (8720): mcc: 0.8006, acc: 0.7079, precision: 0.8796, recall: 0.7471, f1: 0.8080, edges-ner-ontonotes_loss: 0.0542
09/16 09:30:17 AM: Update 8839: task edges-ner-ontonotes, batch 839 (8839): mcc: 0.8022, acc: 0.7099, precision: 0.8808, recall: 0.7489, f1: 0.8095, edges-ner-ontonotes_loss: 0.0538
09/16 09:30:27 AM: Update 8965: task edges-ner-ontonotes, batch 965 (8965): mcc: 0.8038, acc: 0.7117, precision: 0.8820, recall: 0.7507, f1: 0.8110, edges-ner-ontonotes_loss: 0.0534
09/16 09:30:30 AM: ***** Step 9000 / Validation 9 *****
09/16 09:30:30 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:30:30 AM: Validating...
09/16 09:30:37 AM: Evaluate: task edges-ner-ontonotes, batch 57 (157): mcc: 0.8217, acc: 0.7467, precision: 0.8942, recall: 0.7719, f1: 0.8285, edges-ner-ontonotes_loss: 0.0538
09/16 09:30:48 AM: Evaluate: task edges-ner-ontonotes, batch 129 (157): mcc: 0.8427, acc: 0.7679, precision: 0.9173, recall: 0.7888, f1: 0.8482, edges-ner-ontonotes_loss: 0.0474
09/16 09:30:51 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:30:51 AM: Best result seen so far for macro.
09/16 09:30:51 AM: Updating LR scheduler:
09/16 09:30:51 AM: 	Best result seen so far for macro_avg: 0.851
09/16 09:30:51 AM: 	# validation passes without improvement: 0
09/16 09:30:51 AM: edges-ner-ontonotes_loss: training: 0.053345 validation: 0.046086
09/16 09:30:51 AM: macro_avg: validation: 0.850592
09/16 09:30:51 AM: micro_avg: validation: 0.000000
09/16 09:30:51 AM: edges-ner-ontonotes_mcc: training: 0.804337 validation: 0.845071
09/16 09:30:51 AM: edges-ner-ontonotes_acc: training: 0.712273 validation: 0.770094
09/16 09:30:51 AM: edges-ner-ontonotes_precision: training: 0.882199 validation: 0.918638
09/16 09:30:51 AM: edges-ner-ontonotes_recall: training: 0.751498 validation: 0.791932
09/16 09:30:51 AM: edges-ner-ontonotes_f1: training: 0.811620 validation: 0.850592
09/16 09:30:51 AM: Global learning rate: 0.0001
09/16 09:30:51 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:30:58 AM: Update 9058: task edges-ner-ontonotes, batch 58 (9058): mcc: 0.7706, acc: 0.6708, precision: 0.8580, recall: 0.7127, f1: 0.7786, edges-ner-ontonotes_loss: 0.0613
09/16 09:31:08 AM: Update 9187: task edges-ner-ontonotes, batch 187 (9187): mcc: 0.7626, acc: 0.6608, precision: 0.8539, recall: 0.7023, f1: 0.7707, edges-ner-ontonotes_loss: 0.0648
09/16 09:31:21 AM: Update 9321: task edges-ner-ontonotes, batch 321 (9321): mcc: 0.7644, acc: 0.6626, precision: 0.8556, recall: 0.7040, f1: 0.7724, edges-ner-ontonotes_loss: 0.0652
09/16 09:31:31 AM: Update 9449: task edges-ner-ontonotes, batch 449 (9449): mcc: 0.7654, acc: 0.6634, precision: 0.8566, recall: 0.7049, f1: 0.7734, edges-ner-ontonotes_loss: 0.0644
09/16 09:31:41 AM: Update 9603: task edges-ner-ontonotes, batch 603 (9603): mcc: 0.7686, acc: 0.6672, precision: 0.8588, recall: 0.7086, f1: 0.7765, edges-ner-ontonotes_loss: 0.0633
09/16 09:31:52 AM: Update 9708: task edges-ner-ontonotes, batch 708 (9708): mcc: 0.7714, acc: 0.6708, precision: 0.8609, recall: 0.7118, f1: 0.7793, edges-ner-ontonotes_loss: 0.0625
09/16 09:32:02 AM: Update 9833: task edges-ner-ontonotes, batch 833 (9833): mcc: 0.7758, acc: 0.6764, precision: 0.8631, recall: 0.7176, f1: 0.7837, edges-ner-ontonotes_loss: 0.0613
09/16 09:32:12 AM: Update 9957: task edges-ner-ontonotes, batch 957 (9957): mcc: 0.7785, acc: 0.6800, precision: 0.8648, recall: 0.7209, f1: 0.7863, edges-ner-ontonotes_loss: 0.0606
09/16 09:32:17 AM: ***** Step 10000 / Validation 10 *****
09/16 09:32:17 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:32:17 AM: Validating...
09/16 09:32:22 AM: Evaluate: task edges-ner-ontonotes, batch 46 (157): mcc: 0.8032, acc: 0.7265, precision: 0.8796, recall: 0.7518, f1: 0.8107, edges-ner-ontonotes_loss: 0.0565
09/16 09:32:32 AM: Evaluate: task edges-ner-ontonotes, batch 116 (157): mcc: 0.8365, acc: 0.7591, precision: 0.9163, recall: 0.7787, f1: 0.8419, edges-ner-ontonotes_loss: 0.0481
09/16 09:32:37 AM: Updating LR scheduler:
09/16 09:32:37 AM: 	Best result seen so far for macro_avg: 0.851
09/16 09:32:37 AM: 	# validation passes without improvement: 1
09/16 09:32:37 AM: edges-ner-ontonotes_loss: training: 0.060128 validation: 0.046297
09/16 09:32:37 AM: macro_avg: validation: 0.847502
09/16 09:32:37 AM: micro_avg: validation: 0.000000
09/16 09:32:37 AM: edges-ner-ontonotes_mcc: training: 0.780065 validation: 0.842295
09/16 09:32:37 AM: edges-ner-ontonotes_acc: training: 0.681937 validation: 0.765469
09/16 09:32:37 AM: edges-ner-ontonotes_precision: training: 0.865667 validation: 0.921296
09/16 09:32:37 AM: edges-ner-ontonotes_recall: training: 0.722884 validation: 0.784653
09/16 09:32:37 AM: edges-ner-ontonotes_f1: training: 0.787859 validation: 0.847502
09/16 09:32:37 AM: Global learning rate: 0.0001
09/16 09:32:37 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:32:42 AM: Update 10059: task edges-ner-ontonotes, batch 59 (10059): mcc: 0.8295, acc: 0.7420, precision: 0.8973, recall: 0.7832, f1: 0.8363, edges-ner-ontonotes_loss: 0.0476
09/16 09:32:52 AM: Update 10182: task edges-ner-ontonotes, batch 182 (10182): mcc: 0.8246, acc: 0.7347, precision: 0.8935, recall: 0.7777, f1: 0.8316, edges-ner-ontonotes_loss: 0.0486
09/16 09:33:02 AM: Update 10277: task edges-ner-ontonotes, batch 277 (10277): mcc: 0.8213, acc: 0.7313, precision: 0.8923, recall: 0.7729, f1: 0.8283, edges-ner-ontonotes_loss: 0.0487
09/16 09:33:12 AM: Update 10396: task edges-ner-ontonotes, batch 396 (10396): mcc: 0.8220, acc: 0.7321, precision: 0.8926, recall: 0.7738, f1: 0.8289, edges-ner-ontonotes_loss: 0.0491
09/16 09:33:22 AM: Update 10520: task edges-ner-ontonotes, batch 520 (10520): mcc: 0.8215, acc: 0.7318, precision: 0.8917, recall: 0.7738, f1: 0.8285, edges-ner-ontonotes_loss: 0.0494
09/16 09:33:32 AM: Update 10622: task edges-ner-ontonotes, batch 622 (10622): mcc: 0.8172, acc: 0.7264, precision: 0.8891, recall: 0.7684, f1: 0.8243, edges-ner-ontonotes_loss: 0.0506
09/16 09:33:42 AM: Update 10742: task edges-ner-ontonotes, batch 742 (10742): mcc: 0.8090, acc: 0.7163, precision: 0.8835, recall: 0.7587, f1: 0.8163, edges-ner-ontonotes_loss: 0.0530
09/16 09:33:52 AM: Update 10869: task edges-ner-ontonotes, batch 869 (10869): mcc: 0.8032, acc: 0.7093, precision: 0.8793, recall: 0.7519, f1: 0.8106, edges-ner-ontonotes_loss: 0.0548
09/16 09:34:02 AM: Update 10987: task edges-ner-ontonotes, batch 987 (10987): mcc: 0.7993, acc: 0.7049, precision: 0.8765, recall: 0.7476, f1: 0.8069, edges-ner-ontonotes_loss: 0.0560
09/16 09:34:03 AM: ***** Step 11000 / Validation 11 *****
09/16 09:34:03 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:34:03 AM: Validating...
09/16 09:34:12 AM: Evaluate: task edges-ner-ontonotes, batch 76 (157): mcc: 0.8386, acc: 0.7574, precision: 0.9138, recall: 0.7847, f1: 0.8443, edges-ner-ontonotes_loss: 0.0479
09/16 09:34:22 AM: Evaluate: task edges-ner-ontonotes, batch 149 (157): mcc: 0.8446, acc: 0.7591, precision: 0.9309, recall: 0.7805, f1: 0.8491, edges-ner-ontonotes_loss: 0.0453
09/16 09:34:23 AM: Updating LR scheduler:
09/16 09:34:23 AM: 	Best result seen so far for macro_avg: 0.851
09/16 09:34:23 AM: 	# validation passes without improvement: 2
09/16 09:34:23 AM: edges-ner-ontonotes_loss: training: 0.055972 validation: 0.044986
09/16 09:34:23 AM: macro_avg: validation: 0.848867
09/16 09:34:23 AM: micro_avg: validation: 0.000000
09/16 09:34:23 AM: edges-ner-ontonotes_mcc: training: 0.799075 validation: 0.844461
09/16 09:34:23 AM: edges-ner-ontonotes_acc: training: 0.704536 validation: 0.758720
09/16 09:34:23 AM: edges-ner-ontonotes_precision: training: 0.876390 validation: 0.931035
09/16 09:34:23 AM: edges-ner-ontonotes_recall: training: 0.747244 validation: 0.780027
09/16 09:34:23 AM: edges-ner-ontonotes_f1: training: 0.806681 validation: 0.848867
09/16 09:34:23 AM: Global learning rate: 0.0001
09/16 09:34:23 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:34:32 AM: Update 11137: task edges-ner-ontonotes, batch 137 (11137): mcc: 0.7825, acc: 0.6843, precision: 0.8663, recall: 0.7266, f1: 0.7903, edges-ner-ontonotes_loss: 0.0586
09/16 09:34:42 AM: Update 11254: task edges-ner-ontonotes, batch 254 (11254): mcc: 0.7821, acc: 0.6830, precision: 0.8668, recall: 0.7255, f1: 0.7899, edges-ner-ontonotes_loss: 0.0583
09/16 09:34:52 AM: Update 11377: task edges-ner-ontonotes, batch 377 (11377): mcc: 0.7885, acc: 0.6933, precision: 0.8696, recall: 0.7343, f1: 0.7963, edges-ner-ontonotes_loss: 0.0568
09/16 09:35:03 AM: Update 11502: task edges-ner-ontonotes, batch 502 (11502): mcc: 0.7910, acc: 0.6966, precision: 0.8705, recall: 0.7381, f1: 0.7989, edges-ner-ontonotes_loss: 0.0563
09/16 09:35:13 AM: Update 11603: task edges-ner-ontonotes, batch 603 (11603): mcc: 0.7954, acc: 0.7012, precision: 0.8738, recall: 0.7429, f1: 0.8031, edges-ner-ontonotes_loss: 0.0554
09/16 09:35:23 AM: Update 11726: task edges-ner-ontonotes, batch 726 (11726): mcc: 0.8012, acc: 0.7089, precision: 0.8774, recall: 0.7501, f1: 0.8088, edges-ner-ontonotes_loss: 0.0541
09/16 09:35:33 AM: Update 11835: task edges-ner-ontonotes, batch 835 (11835): mcc: 0.8046, acc: 0.7127, precision: 0.8796, recall: 0.7543, f1: 0.8121, edges-ner-ontonotes_loss: 0.0532
09/16 09:35:43 AM: Update 11957: task edges-ner-ontonotes, batch 957 (11957): mcc: 0.8069, acc: 0.7156, precision: 0.8810, recall: 0.7571, f1: 0.8144, edges-ner-ontonotes_loss: 0.0527
09/16 09:35:46 AM: ***** Step 12000 / Validation 12 *****
09/16 09:35:48 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:35:48 AM: Validating...
09/16 09:35:53 AM: Evaluate: task edges-ner-ontonotes, batch 46 (157): mcc: 0.8035, acc: 0.7295, precision: 0.8665, recall: 0.7640, f1: 0.8120, edges-ner-ontonotes_loss: 0.0569
09/16 09:36:05 AM: Evaluate: task edges-ner-ontonotes, batch 117 (157): mcc: 0.8414, acc: 0.7694, precision: 0.9051, recall: 0.7974, f1: 0.8478, edges-ner-ontonotes_loss: 0.0474
09/16 09:36:10 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:36:10 AM: Best result seen so far for macro.
09/16 09:36:10 AM: Updating LR scheduler:
09/16 09:36:10 AM: 	Best result seen so far for macro_avg: 0.854
09/16 09:36:10 AM: 	# validation passes without improvement: 0
09/16 09:36:10 AM: edges-ner-ontonotes_loss: training: 0.052668 validation: 0.044893
09/16 09:36:10 AM: macro_avg: validation: 0.854428
09/16 09:36:10 AM: micro_avg: validation: 0.000000
09/16 09:36:10 AM: edges-ner-ontonotes_mcc: training: 0.807416 validation: 0.848250
09/16 09:36:10 AM: edges-ner-ontonotes_acc: training: 0.716169 validation: 0.776539
09/16 09:36:10 AM: edges-ner-ontonotes_precision: training: 0.881153 validation: 0.911035
09/16 09:36:10 AM: edges-ner-ontonotes_recall: training: 0.757914 validation: 0.804443
09/16 09:36:10 AM: edges-ner-ontonotes_f1: training: 0.814901 validation: 0.854428
09/16 09:36:10 AM: Global learning rate: 0.0001
09/16 09:36:10 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:36:15 AM: Update 12056: task edges-ner-ontonotes, batch 56 (12056): mcc: 0.8275, acc: 0.7407, precision: 0.8956, recall: 0.7811, f1: 0.8344, edges-ner-ontonotes_loss: 0.0484
09/16 09:36:25 AM: Update 12156: task edges-ner-ontonotes, batch 156 (12156): mcc: 0.8156, acc: 0.7257, precision: 0.8888, recall: 0.7658, f1: 0.8227, edges-ner-ontonotes_loss: 0.0513
09/16 09:36:35 AM: Update 12283: task edges-ner-ontonotes, batch 283 (12283): mcc: 0.7914, acc: 0.6951, precision: 0.8714, recall: 0.7380, f1: 0.7992, edges-ner-ontonotes_loss: 0.0578
09/16 09:36:45 AM: Update 12410: task edges-ner-ontonotes, batch 410 (12410): mcc: 0.7856, acc: 0.6872, precision: 0.8677, recall: 0.7308, f1: 0.7934, edges-ner-ontonotes_loss: 0.0598
09/16 09:36:55 AM: Update 12524: task edges-ner-ontonotes, batch 524 (12524): mcc: 0.7834, acc: 0.6849, precision: 0.8657, recall: 0.7287, f1: 0.7913, edges-ner-ontonotes_loss: 0.0602
09/16 09:37:05 AM: Update 12675: task edges-ner-ontonotes, batch 675 (12675): mcc: 0.7824, acc: 0.6838, precision: 0.8647, recall: 0.7278, f1: 0.7904, edges-ner-ontonotes_loss: 0.0599
09/16 09:37:15 AM: Update 12788: task edges-ner-ontonotes, batch 788 (12788): mcc: 0.7824, acc: 0.6838, precision: 0.8645, recall: 0.7280, f1: 0.7904, edges-ner-ontonotes_loss: 0.0596
09/16 09:37:25 AM: Update 12913: task edges-ner-ontonotes, batch 913 (12913): mcc: 0.7838, acc: 0.6860, precision: 0.8651, recall: 0.7300, f1: 0.7918, edges-ner-ontonotes_loss: 0.0591
09/16 09:37:32 AM: ***** Step 13000 / Validation 13 *****
09/16 09:37:32 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:37:32 AM: Validating...
09/16 09:37:35 AM: Evaluate: task edges-ner-ontonotes, batch 31 (157): mcc: 0.8083, acc: 0.7345, precision: 0.8843, recall: 0.7567, f1: 0.8155, edges-ner-ontonotes_loss: 0.0545
09/16 09:37:47 AM: Evaluate: task edges-ner-ontonotes, batch 111 (157): mcc: 0.8516, acc: 0.7801, precision: 0.9221, recall: 0.8005, f1: 0.8570, edges-ner-ontonotes_loss: 0.0441
09/16 09:37:54 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:37:54 AM: Best result seen so far for macro.
09/16 09:37:54 AM: Updating LR scheduler:
09/16 09:37:54 AM: 	Best result seen so far for macro_avg: 0.856
09/16 09:37:54 AM: 	# validation passes without improvement: 0
09/16 09:37:54 AM: edges-ner-ontonotes_loss: training: 0.058625 validation: 0.043395
09/16 09:37:54 AM: macro_avg: validation: 0.856432
09/16 09:37:54 AM: micro_avg: validation: 0.000000
09/16 09:37:54 AM: edges-ner-ontonotes_mcc: training: 0.785278 validation: 0.851382
09/16 09:37:54 AM: edges-ner-ontonotes_acc: training: 0.688103 validation: 0.776691
09/16 09:37:54 AM: edges-ner-ontonotes_precision: training: 0.866208 validation: 0.926655
09/16 09:37:54 AM: edges-ner-ontonotes_recall: training: 0.731648 validation: 0.796103
09/16 09:37:54 AM: edges-ner-ontonotes_f1: training: 0.793262 validation: 0.856432
09/16 09:37:54 AM: Global learning rate: 0.0001
09/16 09:37:54 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:37:57 AM: Update 13040: task edges-ner-ontonotes, batch 40 (13040): mcc: 0.8137, acc: 0.7275, precision: 0.8788, recall: 0.7712, f1: 0.8215, edges-ner-ontonotes_loss: 0.0534
09/16 09:38:09 AM: Update 13140: task edges-ner-ontonotes, batch 140 (13140): mcc: 0.8115, acc: 0.7227, precision: 0.8802, recall: 0.7661, f1: 0.8192, edges-ner-ontonotes_loss: 0.0518
09/16 09:38:19 AM: Update 13260: task edges-ner-ontonotes, batch 260 (13260): mcc: 0.8182, acc: 0.7301, precision: 0.8864, recall: 0.7725, f1: 0.8256, edges-ner-ontonotes_loss: 0.0498
09/16 09:38:29 AM: Update 13384: task edges-ner-ontonotes, batch 384 (13384): mcc: 0.8216, acc: 0.7345, precision: 0.8888, recall: 0.7765, f1: 0.8289, edges-ner-ontonotes_loss: 0.0490
09/16 09:38:39 AM: Update 13484: task edges-ner-ontonotes, batch 484 (13484): mcc: 0.8203, acc: 0.7323, precision: 0.8877, recall: 0.7752, f1: 0.8276, edges-ner-ontonotes_loss: 0.0491
09/16 09:38:50 AM: Update 13606: task edges-ner-ontonotes, batch 606 (13606): mcc: 0.8208, acc: 0.7328, precision: 0.8886, recall: 0.7753, f1: 0.8281, edges-ner-ontonotes_loss: 0.0491
09/16 09:39:00 AM: Update 13706: task edges-ner-ontonotes, batch 706 (13706): mcc: 0.8197, acc: 0.7310, precision: 0.8883, recall: 0.7736, f1: 0.8270, edges-ner-ontonotes_loss: 0.0494
09/16 09:39:10 AM: Update 13828: task edges-ner-ontonotes, batch 828 (13828): mcc: 0.8130, acc: 0.7224, precision: 0.8843, recall: 0.7651, f1: 0.8204, edges-ner-ontonotes_loss: 0.0518
09/16 09:39:20 AM: Update 13946: task edges-ner-ontonotes, batch 946 (13946): mcc: 0.8078, acc: 0.7157, precision: 0.8805, recall: 0.7591, f1: 0.8153, edges-ner-ontonotes_loss: 0.0535
09/16 09:39:24 AM: ***** Step 14000 / Validation 14 *****
09/16 09:39:24 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:39:24 AM: Validating...
09/16 09:39:30 AM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.8254, acc: 0.7511, precision: 0.8951, recall: 0.7777, f1: 0.8323, edges-ner-ontonotes_loss: 0.0507
09/16 09:39:40 AM: Evaluate: task edges-ner-ontonotes, batch 123 (157): mcc: 0.8486, acc: 0.7744, precision: 0.9220, recall: 0.7952, f1: 0.8540, edges-ner-ontonotes_loss: 0.0453
09/16 09:39:44 AM: Updating LR scheduler:
09/16 09:39:44 AM: 	Best result seen so far for macro_avg: 0.856
09/16 09:39:44 AM: 	# validation passes without improvement: 1
09/16 09:39:44 AM: edges-ner-ontonotes_loss: training: 0.054016 validation: 0.044091
09/16 09:39:44 AM: macro_avg: validation: 0.855291
09/16 09:39:44 AM: micro_avg: validation: 0.000000
09/16 09:39:44 AM: edges-ner-ontonotes_mcc: training: 0.806654 validation: 0.850150
09/16 09:39:44 AM: edges-ner-ontonotes_acc: training: 0.714302 validation: 0.774189
09/16 09:39:44 AM: edges-ner-ontonotes_precision: training: 0.879801 validation: 0.925112
09/16 09:39:44 AM: edges-ner-ontonotes_recall: training: 0.757755 validation: 0.795268
09/16 09:39:44 AM: edges-ner-ontonotes_f1: training: 0.814230 validation: 0.855291
09/16 09:39:44 AM: Global learning rate: 0.0001
09/16 09:39:44 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:39:50 AM: Update 14057: task edges-ner-ontonotes, batch 57 (14057): mcc: 0.7922, acc: 0.6990, precision: 0.8649, recall: 0.7452, f1: 0.8006, edges-ner-ontonotes_loss: 0.0575
09/16 09:40:00 AM: Update 14200: task edges-ner-ontonotes, batch 200 (14200): mcc: 0.7859, acc: 0.6896, precision: 0.8642, recall: 0.7346, f1: 0.7941, edges-ner-ontonotes_loss: 0.0580
09/16 09:40:10 AM: Update 14319: task edges-ner-ontonotes, batch 319 (14319): mcc: 0.7829, acc: 0.6857, precision: 0.8619, recall: 0.7311, f1: 0.7911, edges-ner-ontonotes_loss: 0.0582
09/16 09:40:20 AM: Update 14446: task edges-ner-ontonotes, batch 446 (14446): mcc: 0.7868, acc: 0.6916, precision: 0.8654, recall: 0.7351, f1: 0.7949, edges-ner-ontonotes_loss: 0.0577
09/16 09:40:30 AM: Update 14574: task edges-ner-ontonotes, batch 574 (14574): mcc: 0.7911, acc: 0.6970, precision: 0.8679, recall: 0.7406, f1: 0.7992, edges-ner-ontonotes_loss: 0.0565
09/16 09:40:40 AM: Update 14675: task edges-ner-ontonotes, batch 675 (14675): mcc: 0.7958, acc: 0.7028, precision: 0.8715, recall: 0.7457, f1: 0.8037, edges-ner-ontonotes_loss: 0.0556
09/16 09:40:50 AM: Update 14794: task edges-ner-ontonotes, batch 794 (14794): mcc: 0.8008, acc: 0.7085, precision: 0.8748, recall: 0.7517, f1: 0.8086, edges-ner-ontonotes_loss: 0.0544
09/16 09:41:00 AM: Update 14916: task edges-ner-ontonotes, batch 916 (14916): mcc: 0.8054, acc: 0.7140, precision: 0.8781, recall: 0.7570, f1: 0.8131, edges-ner-ontonotes_loss: 0.0534
09/16 09:41:08 AM: ***** Step 15000 / Validation 15 *****
09/16 09:41:08 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:41:08 AM: Validating...
09/16 09:41:10 AM: Evaluate: task edges-ner-ontonotes, batch 13 (157): mcc: 0.7601, acc: 0.6780, precision: 0.8322, recall: 0.7169, f1: 0.7702, edges-ner-ontonotes_loss: 0.0650
09/16 09:41:20 AM: Evaluate: task edges-ner-ontonotes, batch 96 (157): mcc: 0.8432, acc: 0.7732, precision: 0.9037, recall: 0.8019, f1: 0.8498, edges-ner-ontonotes_loss: 0.0475
09/16 09:41:29 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:41:29 AM: Best result seen so far for macro.
09/16 09:41:29 AM: Updating LR scheduler:
09/16 09:41:29 AM: 	Best result seen so far for macro_avg: 0.860
09/16 09:41:29 AM: 	# validation passes without improvement: 0
09/16 09:41:29 AM: edges-ner-ontonotes_loss: training: 0.053094 validation: 0.043506
09/16 09:41:29 AM: macro_avg: validation: 0.860309
09/16 09:41:29 AM: micro_avg: validation: 0.000000
09/16 09:41:29 AM: edges-ner-ontonotes_mcc: training: 0.806681 validation: 0.854509
09/16 09:41:29 AM: edges-ner-ontonotes_acc: training: 0.715628 validation: 0.784198
09/16 09:41:29 AM: edges-ner-ontonotes_precision: training: 0.879270 validation: 0.917892
09/16 09:41:29 AM: edges-ner-ontonotes_recall: training: 0.758275 validation: 0.809524
09/16 09:41:29 AM: edges-ner-ontonotes_f1: training: 0.814303 validation: 0.860309
09/16 09:41:29 AM: Global learning rate: 0.0001
09/16 09:41:29 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:41:30 AM: Update 15015: task edges-ner-ontonotes, batch 15 (15015): mcc: 0.8354, acc: 0.7479, precision: 0.8983, recall: 0.7928, f1: 0.8423, edges-ner-ontonotes_loss: 0.0454
09/16 09:41:40 AM: Update 15131: task edges-ner-ontonotes, batch 131 (15131): mcc: 0.8232, acc: 0.7369, precision: 0.8893, recall: 0.7788, f1: 0.8304, edges-ner-ontonotes_loss: 0.0487
09/16 09:41:50 AM: Update 15256: task edges-ner-ontonotes, batch 256 (15256): mcc: 0.8249, acc: 0.7392, precision: 0.8912, recall: 0.7803, f1: 0.8320, edges-ner-ontonotes_loss: 0.0482
09/16 09:42:00 AM: Update 15352: task edges-ner-ontonotes, batch 352 (15352): mcc: 0.8057, acc: 0.7141, precision: 0.8796, recall: 0.7562, f1: 0.8133, edges-ner-ontonotes_loss: 0.0532
09/16 09:42:10 AM: Update 15485: task edges-ner-ontonotes, batch 485 (15485): mcc: 0.7987, acc: 0.7055, precision: 0.8750, recall: 0.7479, f1: 0.8065, edges-ner-ontonotes_loss: 0.0559
09/16 09:42:21 AM: Update 15605: task edges-ner-ontonotes, batch 605 (15605): mcc: 0.7937, acc: 0.6999, precision: 0.8708, recall: 0.7426, f1: 0.8016, edges-ner-ontonotes_loss: 0.0575
09/16 09:42:31 AM: Update 15758: task edges-ner-ontonotes, batch 758 (15758): mcc: 0.7922, acc: 0.6979, precision: 0.8694, recall: 0.7412, f1: 0.8002, edges-ner-ontonotes_loss: 0.0577
09/16 09:42:41 AM: Update 15881: task edges-ner-ontonotes, batch 881 (15881): mcc: 0.7917, acc: 0.6970, precision: 0.8696, recall: 0.7402, f1: 0.7997, edges-ner-ontonotes_loss: 0.0576
09/16 09:42:50 AM: ***** Step 16000 / Validation 16 *****
09/16 09:42:50 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:42:50 AM: Validating...
09/16 09:42:51 AM: Evaluate: task edges-ner-ontonotes, batch 10 (157): mcc: 0.7575, acc: 0.6693, precision: 0.8475, recall: 0.6988, f1: 0.7660, edges-ner-ontonotes_loss: 0.0602
09/16 09:43:01 AM: Evaluate: task edges-ner-ontonotes, batch 93 (157): mcc: 0.8510, acc: 0.7780, precision: 0.9217, recall: 0.7997, f1: 0.8564, edges-ner-ontonotes_loss: 0.0446
09/16 09:43:10 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:43:10 AM: Best result seen so far for macro.
09/16 09:43:10 AM: Updating LR scheduler:
09/16 09:43:10 AM: 	Best result seen so far for macro_avg: 0.863
09/16 09:43:10 AM: 	# validation passes without improvement: 0
09/16 09:43:10 AM: edges-ner-ontonotes_loss: training: 0.057066 validation: 0.042335
09/16 09:43:10 AM: macro_avg: validation: 0.862852
09/16 09:43:10 AM: micro_avg: validation: 0.000000
09/16 09:43:10 AM: edges-ner-ontonotes_mcc: training: 0.793350 validation: 0.857983
09/16 09:43:10 AM: edges-ner-ontonotes_acc: training: 0.699097 validation: 0.784274
09/16 09:43:10 AM: edges-ner-ontonotes_precision: training: 0.870536 validation: 0.931219
09/16 09:43:10 AM: edges-ner-ontonotes_recall: training: 0.742207 validation: 0.803837
09/16 09:43:10 AM: edges-ner-ontonotes_f1: training: 0.801266 validation: 0.862852
09/16 09:43:10 AM: Global learning rate: 0.0001
09/16 09:43:10 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:43:11 AM: Update 16013: task edges-ner-ontonotes, batch 13 (16013): mcc: 0.8140, acc: 0.7265, precision: 0.8713, recall: 0.7788, f1: 0.8224, edges-ner-ontonotes_loss: 0.0498
09/16 09:43:21 AM: Update 16136: task edges-ner-ontonotes, batch 136 (16136): mcc: 0.7938, acc: 0.7036, precision: 0.8640, recall: 0.7489, f1: 0.8023, edges-ner-ontonotes_loss: 0.0559
09/16 09:43:31 AM: Update 16239: task edges-ner-ontonotes, batch 239 (16239): mcc: 0.8012, acc: 0.7108, precision: 0.8711, recall: 0.7557, f1: 0.8093, edges-ner-ontonotes_loss: 0.0537
09/16 09:43:41 AM: Update 16374: task edges-ner-ontonotes, batch 374 (16374): mcc: 0.8116, acc: 0.7235, precision: 0.8791, recall: 0.7673, f1: 0.8194, edges-ner-ontonotes_loss: 0.0510
09/16 09:43:51 AM: Update 16487: task edges-ner-ontonotes, batch 487 (16487): mcc: 0.8162, acc: 0.7283, precision: 0.8832, recall: 0.7718, f1: 0.8238, edges-ner-ontonotes_loss: 0.0501
09/16 09:44:01 AM: Update 16579: task edges-ner-ontonotes, batch 579 (16579): mcc: 0.8183, acc: 0.7311, precision: 0.8848, recall: 0.7742, f1: 0.8258, edges-ner-ontonotes_loss: 0.0497
09/16 09:44:11 AM: Update 16699: task edges-ner-ontonotes, batch 699 (16699): mcc: 0.8186, acc: 0.7316, precision: 0.8851, recall: 0.7744, f1: 0.8261, edges-ner-ontonotes_loss: 0.0497
09/16 09:44:21 AM: Update 16813: task edges-ner-ontonotes, batch 813 (16813): mcc: 0.8186, acc: 0.7315, precision: 0.8852, recall: 0.7743, f1: 0.8261, edges-ner-ontonotes_loss: 0.0494
09/16 09:44:32 AM: Update 16926: task edges-ner-ontonotes, batch 926 (16926): mcc: 0.8122, acc: 0.7227, precision: 0.8813, recall: 0.7664, f1: 0.8198, edges-ner-ontonotes_loss: 0.0513
09/16 09:44:38 AM: ***** Step 17000 / Validation 17 *****
09/16 09:44:38 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:44:38 AM: Validating...
09/16 09:44:42 AM: Evaluate: task edges-ner-ontonotes, batch 39 (157): mcc: 0.8207, acc: 0.7515, precision: 0.8874, recall: 0.7761, f1: 0.8280, edges-ner-ontonotes_loss: 0.0527
09/16 09:44:52 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.8499, acc: 0.7787, precision: 0.9205, recall: 0.7989, f1: 0.8554, edges-ner-ontonotes_loss: 0.0450
09/16 09:44:58 AM: Updating LR scheduler:
09/16 09:44:58 AM: 	Best result seen so far for macro_avg: 0.863
09/16 09:44:58 AM: 	# validation passes without improvement: 1
09/16 09:44:58 AM: edges-ner-ontonotes_loss: training: 0.052274 validation: 0.043323
09/16 09:44:58 AM: macro_avg: validation: 0.858351
09/16 09:44:58 AM: micro_avg: validation: 0.000000
09/16 09:44:58 AM: edges-ner-ontonotes_mcc: training: 0.809639 validation: 0.853166
09/16 09:44:58 AM: edges-ner-ontonotes_acc: training: 0.719558 validation: 0.779724
09/16 09:44:58 AM: edges-ner-ontonotes_precision: training: 0.879549 validation: 0.925621
09/16 09:44:58 AM: edges-ner-ontonotes_recall: training: 0.763328 validation: 0.800197
09/16 09:44:58 AM: edges-ner-ontonotes_f1: training: 0.817328 validation: 0.858351
09/16 09:44:58 AM: Global learning rate: 0.0001
09/16 09:44:58 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:45:02 AM: Update 17057: task edges-ner-ontonotes, batch 57 (17057): mcc: 0.7812, acc: 0.6847, precision: 0.8619, recall: 0.7281, f1: 0.7894, edges-ner-ontonotes_loss: 0.0628
09/16 09:45:12 AM: Update 17168: task edges-ner-ontonotes, batch 168 (17168): mcc: 0.7821, acc: 0.6872, precision: 0.8604, recall: 0.7311, f1: 0.7905, edges-ner-ontonotes_loss: 0.0613
09/16 09:45:22 AM: Update 17315: task edges-ner-ontonotes, batch 315 (17315): mcc: 0.7844, acc: 0.6894, precision: 0.8620, recall: 0.7337, f1: 0.7927, edges-ner-ontonotes_loss: 0.0596
09/16 09:45:32 AM: Update 17434: task edges-ner-ontonotes, batch 434 (17434): mcc: 0.7845, acc: 0.6884, precision: 0.8629, recall: 0.7331, f1: 0.7927, edges-ner-ontonotes_loss: 0.0590
09/16 09:45:42 AM: Update 17558: task edges-ner-ontonotes, batch 558 (17558): mcc: 0.7879, acc: 0.6933, precision: 0.8649, recall: 0.7375, f1: 0.7961, edges-ner-ontonotes_loss: 0.0581
09/16 09:45:52 AM: Update 17683: task edges-ner-ontonotes, batch 683 (17683): mcc: 0.7917, acc: 0.6982, precision: 0.8676, recall: 0.7419, f1: 0.7998, edges-ner-ontonotes_loss: 0.0571
09/16 09:46:03 AM: Update 17795: task edges-ner-ontonotes, batch 795 (17795): mcc: 0.7958, acc: 0.7034, precision: 0.8701, recall: 0.7470, f1: 0.8039, edges-ner-ontonotes_loss: 0.0560
09/16 09:46:13 AM: Update 17915: task edges-ner-ontonotes, batch 915 (17915): mcc: 0.7999, acc: 0.7078, precision: 0.8731, recall: 0.7516, f1: 0.8078, edges-ner-ontonotes_loss: 0.0550
09/16 09:46:20 AM: ***** Step 18000 / Validation 18 *****
09/16 09:46:20 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:46:20 AM: Validating...
09/16 09:46:23 AM: Evaluate: task edges-ner-ontonotes, batch 30 (157): mcc: 0.8099, acc: 0.7356, precision: 0.8764, recall: 0.7668, f1: 0.8179, edges-ner-ontonotes_loss: 0.0563
09/16 09:46:33 AM: Evaluate: task edges-ner-ontonotes, batch 103 (157): mcc: 0.8503, acc: 0.7794, precision: 0.9134, recall: 0.8060, f1: 0.8563, edges-ner-ontonotes_loss: 0.0453
09/16 09:46:40 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:46:40 AM: Best result seen so far for macro.
09/16 09:46:40 AM: Updating LR scheduler:
09/16 09:46:40 AM: 	Best result seen so far for macro_avg: 0.865
09/16 09:46:40 AM: 	# validation passes without improvement: 0
09/16 09:46:40 AM: edges-ner-ontonotes_loss: training: 0.054229 validation: 0.041930
09/16 09:46:40 AM: macro_avg: validation: 0.865325
09/16 09:46:40 AM: micro_avg: validation: 0.000000
09/16 09:46:40 AM: edges-ner-ontonotes_mcc: training: 0.803465 validation: 0.859889
09/16 09:46:40 AM: edges-ner-ontonotes_acc: training: 0.712299 validation: 0.789126
09/16 09:46:40 AM: edges-ner-ontonotes_precision: training: 0.875556 validation: 0.924343
09/16 09:46:40 AM: edges-ner-ontonotes_recall: training: 0.755826 validation: 0.813391
09/16 09:46:40 AM: edges-ner-ontonotes_f1: training: 0.811297 validation: 0.865325
09/16 09:46:40 AM: Global learning rate: 0.0001
09/16 09:46:40 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:46:43 AM: Update 18028: task edges-ner-ontonotes, batch 28 (18028): mcc: 0.8339, acc: 0.7519, precision: 0.8912, recall: 0.7965, f1: 0.8412, edges-ner-ontonotes_loss: 0.0463
09/16 09:46:53 AM: Update 18126: task edges-ner-ontonotes, batch 126 (18126): mcc: 0.8231, acc: 0.7347, precision: 0.8897, recall: 0.7783, f1: 0.8303, edges-ner-ontonotes_loss: 0.0480
09/16 09:47:03 AM: Update 18250: task edges-ner-ontonotes, batch 250 (18250): mcc: 0.8274, acc: 0.7422, precision: 0.8917, recall: 0.7845, f1: 0.8346, edges-ner-ontonotes_loss: 0.0478
09/16 09:47:14 AM: Update 18369: task edges-ner-ontonotes, batch 369 (18369): mcc: 0.8266, acc: 0.7414, precision: 0.8902, recall: 0.7843, f1: 0.8339, edges-ner-ontonotes_loss: 0.0481
09/16 09:47:24 AM: Update 18490: task edges-ner-ontonotes, batch 490 (18490): mcc: 0.8099, acc: 0.7197, precision: 0.8798, recall: 0.7635, f1: 0.8176, edges-ner-ontonotes_loss: 0.0528
09/16 09:47:34 AM: Update 18618: task edges-ner-ontonotes, batch 618 (18618): mcc: 0.8050, acc: 0.7133, precision: 0.8767, recall: 0.7575, f1: 0.8128, edges-ner-ontonotes_loss: 0.0545
09/16 09:47:44 AM: Update 18725: task edges-ner-ontonotes, batch 725 (18725): mcc: 0.8007, acc: 0.7084, precision: 0.8737, recall: 0.7526, f1: 0.8086, edges-ner-ontonotes_loss: 0.0559
09/16 09:47:54 AM: Update 18876: task edges-ner-ontonotes, batch 876 (18876): mcc: 0.7992, acc: 0.7066, precision: 0.8722, recall: 0.7512, f1: 0.8072, edges-ner-ontonotes_loss: 0.0560
09/16 09:48:04 AM: Update 18997: task edges-ner-ontonotes, batch 997 (18997): mcc: 0.7978, acc: 0.7045, precision: 0.8711, recall: 0.7496, f1: 0.8058, edges-ner-ontonotes_loss: 0.0562
09/16 09:48:04 AM: ***** Step 19000 / Validation 19 *****
09/16 09:48:04 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:48:04 AM: Validating...
09/16 09:48:14 AM: Evaluate: task edges-ner-ontonotes, batch 85 (157): mcc: 0.8559, acc: 0.7849, precision: 0.9145, recall: 0.8151, f1: 0.8619, edges-ner-ontonotes_loss: 0.0442
09/16 09:48:24 AM: Best result seen so far for edges-ner-ontonotes.
09/16 09:48:24 AM: Best result seen so far for macro.
09/16 09:48:24 AM: Updating LR scheduler:
09/16 09:48:24 AM: 	Best result seen so far for macro_avg: 0.868
09/16 09:48:24 AM: 	# validation passes without improvement: 0
09/16 09:48:24 AM: edges-ner-ontonotes_loss: training: 0.056154 validation: 0.041741
09/16 09:48:24 AM: macro_avg: validation: 0.868169
09/16 09:48:24 AM: micro_avg: validation: 0.000000
09/16 09:48:24 AM: edges-ner-ontonotes_mcc: training: 0.797898 validation: 0.862729
09/16 09:48:24 AM: edges-ner-ontonotes_acc: training: 0.704621 validation: 0.791250
09/16 09:48:24 AM: edges-ner-ontonotes_precision: training: 0.871163 validation: 0.924970
09/16 09:48:24 AM: edges-ner-ontonotes_recall: training: 0.749772 validation: 0.817941
09/16 09:48:24 AM: edges-ner-ontonotes_f1: training: 0.805923 validation: 0.868169
09/16 09:48:24 AM: Global learning rate: 0.0001
09/16 09:48:24 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:48:24 AM: Update 19001: task edges-ner-ontonotes, batch 1 (19001): mcc: 0.8548, acc: 0.7959, precision: 0.9000, recall: 0.8265, f1: 0.8617, edges-ner-ontonotes_loss: 0.0448
09/16 09:48:34 AM: Update 19123: task edges-ner-ontonotes, batch 123 (19123): mcc: 0.8057, acc: 0.7164, precision: 0.8758, recall: 0.7596, f1: 0.8136, edges-ner-ontonotes_loss: 0.0540
09/16 09:48:44 AM: Update 19248: task edges-ner-ontonotes, batch 248 (19248): mcc: 0.8040, acc: 0.7128, precision: 0.8735, recall: 0.7587, f1: 0.8121, edges-ner-ontonotes_loss: 0.0533
09/16 09:48:54 AM: Update 19346: task edges-ner-ontonotes, batch 346 (19346): mcc: 0.8064, acc: 0.7154, precision: 0.8760, recall: 0.7607, f1: 0.8143, edges-ner-ontonotes_loss: 0.0525
09/16 09:49:04 AM: Update 19465: task edges-ner-ontonotes, batch 465 (19465): mcc: 0.8133, acc: 0.7237, precision: 0.8814, recall: 0.7682, f1: 0.8209, edges-ner-ontonotes_loss: 0.0509
09/16 09:49:14 AM: Update 19586: task edges-ner-ontonotes, batch 586 (19586): mcc: 0.8180, acc: 0.7299, precision: 0.8848, recall: 0.7737, f1: 0.8255, edges-ner-ontonotes_loss: 0.0497
09/16 09:49:24 AM: Update 19696: task edges-ner-ontonotes, batch 696 (19696): mcc: 0.8205, acc: 0.7330, precision: 0.8864, recall: 0.7767, f1: 0.8279, edges-ner-ontonotes_loss: 0.0493
09/16 09:49:34 AM: Update 19820: task edges-ner-ontonotes, batch 820 (19820): mcc: 0.8210, acc: 0.7337, precision: 0.8869, recall: 0.7771, f1: 0.8284, edges-ner-ontonotes_loss: 0.0491
09/16 09:49:45 AM: Update 19925: task edges-ner-ontonotes, batch 925 (19925): mcc: 0.8211, acc: 0.7341, precision: 0.8869, recall: 0.7774, f1: 0.8285, edges-ner-ontonotes_loss: 0.0490
09/16 09:49:51 AM: ***** Step 20000 / Validation 20 *****
09/16 09:49:51 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:49:51 AM: Validating...
09/16 09:49:55 AM: Evaluate: task edges-ner-ontonotes, batch 42 (157): mcc: 0.8306, acc: 0.7558, precision: 0.8914, recall: 0.7905, f1: 0.8379, edges-ner-ontonotes_loss: 0.0501
09/16 09:50:05 AM: Evaluate: task edges-ner-ontonotes, batch 114 (157): mcc: 0.8544, acc: 0.7808, precision: 0.9234, recall: 0.8044, f1: 0.8598, edges-ner-ontonotes_loss: 0.0437
09/16 09:50:10 AM: Updating LR scheduler:
09/16 09:50:10 AM: 	Best result seen so far for macro_avg: 0.868
09/16 09:50:10 AM: 	# validation passes without improvement: 1
09/16 09:50:10 AM: edges-ner-ontonotes_loss: training: 0.050275 validation: 0.042193
09/16 09:50:10 AM: macro_avg: validation: 0.862901
09/16 09:50:10 AM: micro_avg: validation: 0.000000
09/16 09:50:10 AM: edges-ner-ontonotes_mcc: training: 0.817370 validation: 0.857906
09/16 09:50:10 AM: edges-ner-ontonotes_acc: training: 0.729510 validation: 0.782985
09/16 09:50:10 AM: edges-ner-ontonotes_precision: training: 0.884194 validation: 0.929610
09/16 09:50:10 AM: edges-ner-ontonotes_recall: training: 0.773049 validation: 0.805126
09/16 09:50:10 AM: edges-ner-ontonotes_f1: training: 0.824894 validation: 0.862901
09/16 09:50:10 AM: Global learning rate: 0.0001
09/16 09:50:10 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:50:15 AM: Update 20058: task edges-ner-ontonotes, batch 58 (20058): mcc: 0.7724, acc: 0.6703, precision: 0.8562, recall: 0.7175, f1: 0.7807, edges-ner-ontonotes_loss: 0.0647
09/16 09:50:25 AM: Update 20181: task edges-ner-ontonotes, batch 181 (20181): mcc: 0.7760, acc: 0.6762, precision: 0.8585, recall: 0.7220, f1: 0.7843, edges-ner-ontonotes_loss: 0.0628
09/16 09:50:35 AM: Update 20284: task edges-ner-ontonotes, batch 284 (20284): mcc: 0.7733, acc: 0.6735, precision: 0.8555, recall: 0.7197, f1: 0.7817, edges-ner-ontonotes_loss: 0.0629
09/16 09:50:45 AM: Update 20432: task edges-ner-ontonotes, batch 432 (20432): mcc: 0.7789, acc: 0.6804, precision: 0.8585, recall: 0.7270, f1: 0.7873, edges-ner-ontonotes_loss: 0.0607
09/16 09:50:55 AM: Update 20549: task edges-ner-ontonotes, batch 549 (20549): mcc: 0.7808, acc: 0.6823, precision: 0.8606, recall: 0.7286, f1: 0.7891, edges-ner-ontonotes_loss: 0.0599
09/16 09:51:05 AM: Update 20677: task edges-ner-ontonotes, batch 677 (20677): mcc: 0.7858, acc: 0.6891, precision: 0.8638, recall: 0.7346, f1: 0.7940, edges-ner-ontonotes_loss: 0.0586
09/16 09:51:15 AM: Update 20803: task edges-ner-ontonotes, batch 803 (20803): mcc: 0.7889, acc: 0.6933, precision: 0.8657, recall: 0.7385, f1: 0.7971, edges-ner-ontonotes_loss: 0.0578
09/16 09:51:25 AM: Update 20901: task edges-ner-ontonotes, batch 901 (20901): mcc: 0.7919, acc: 0.6971, precision: 0.8675, recall: 0.7423, f1: 0.8000, edges-ner-ontonotes_loss: 0.0570
09/16 09:51:33 AM: ***** Step 21000 / Validation 21 *****
09/16 09:51:33 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:51:33 AM: Validating...
09/16 09:51:35 AM: Evaluate: task edges-ner-ontonotes, batch 19 (157): mcc: 0.7858, acc: 0.7104, precision: 0.8491, recall: 0.7479, f1: 0.7953, edges-ner-ontonotes_loss: 0.0578
09/16 09:51:45 AM: Evaluate: task edges-ner-ontonotes, batch 101 (157): mcc: 0.8437, acc: 0.7738, precision: 0.9054, recall: 0.8014, f1: 0.8502, edges-ner-ontonotes_loss: 0.0470
09/16 09:51:53 AM: Updating LR scheduler:
09/16 09:51:53 AM: 	Best result seen so far for macro_avg: 0.868
09/16 09:51:53 AM: 	# validation passes without improvement: 2
09/16 09:51:53 AM: edges-ner-ontonotes_loss: training: 0.055811 validation: 0.042823
09/16 09:51:53 AM: macro_avg: validation: 0.863278
09/16 09:51:53 AM: micro_avg: validation: 0.000000
09/16 09:51:53 AM: edges-ner-ontonotes_mcc: training: 0.796567 validation: 0.857507
09/16 09:51:53 AM: edges-ner-ontonotes_acc: training: 0.703009 validation: 0.788823
09/16 09:51:53 AM: edges-ner-ontonotes_precision: training: 0.870460 validation: 0.919007
09/16 09:51:53 AM: edges-ner-ontonotes_recall: training: 0.748017 validation: 0.813922
09/16 09:51:53 AM: edges-ner-ontonotes_f1: training: 0.804607 validation: 0.863278
09/16 09:51:53 AM: Global learning rate: 0.0001
09/16 09:51:53 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:51:55 AM: Update 21027: task edges-ner-ontonotes, batch 27 (21027): mcc: 0.8175, acc: 0.7285, precision: 0.8834, recall: 0.7740, f1: 0.8251, edges-ner-ontonotes_loss: 0.0500
09/16 09:52:05 AM: Update 21147: task edges-ner-ontonotes, batch 147 (21147): mcc: 0.8281, acc: 0.7408, precision: 0.8929, recall: 0.7845, f1: 0.8352, edges-ner-ontonotes_loss: 0.0466
09/16 09:52:15 AM: Update 21243: task edges-ner-ontonotes, batch 243 (21243): mcc: 0.8276, acc: 0.7400, precision: 0.8934, recall: 0.7832, f1: 0.8347, edges-ner-ontonotes_loss: 0.0473
09/16 09:52:25 AM: Update 21369: task edges-ner-ontonotes, batch 369 (21369): mcc: 0.8279, acc: 0.7418, precision: 0.8924, recall: 0.7846, f1: 0.8351, edges-ner-ontonotes_loss: 0.0472
09/16 09:52:36 AM: Update 21481: task edges-ner-ontonotes, batch 481 (21481): mcc: 0.8278, acc: 0.7419, precision: 0.8920, recall: 0.7848, f1: 0.8350, edges-ner-ontonotes_loss: 0.0474
09/16 09:52:46 AM: Update 21610: task edges-ner-ontonotes, batch 610 (21610): mcc: 0.8176, acc: 0.7292, precision: 0.8849, recall: 0.7728, f1: 0.8251, edges-ner-ontonotes_loss: 0.0507
09/16 09:52:56 AM: Update 21732: task edges-ner-ontonotes, batch 732 (21732): mcc: 0.8099, acc: 0.7196, precision: 0.8799, recall: 0.7635, f1: 0.8176, edges-ner-ontonotes_loss: 0.0529
09/16 09:53:06 AM: Update 21848: task edges-ner-ontonotes, batch 848 (21848): mcc: 0.8067, acc: 0.7156, precision: 0.8773, recall: 0.7601, f1: 0.8145, edges-ner-ontonotes_loss: 0.0539
09/16 09:53:16 AM: Update 21996: task edges-ner-ontonotes, batch 996 (21996): mcc: 0.8053, acc: 0.7136, precision: 0.8763, recall: 0.7584, f1: 0.8131, edges-ner-ontonotes_loss: 0.0542
09/16 09:53:16 AM: ***** Step 22000 / Validation 22 *****
09/16 09:53:16 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:53:16 AM: Validating...
09/16 09:53:26 AM: Evaluate: task edges-ner-ontonotes, batch 82 (157): mcc: 0.8544, acc: 0.7810, precision: 0.9238, recall: 0.8040, f1: 0.8597, edges-ner-ontonotes_loss: 0.0436
09/16 09:53:36 AM: Evaluate: task edges-ner-ontonotes, batch 154 (157): mcc: 0.8580, acc: 0.7815, precision: 0.9350, recall: 0.8004, f1: 0.8625, edges-ner-ontonotes_loss: 0.0415
09/16 09:53:37 AM: Updating LR scheduler:
09/16 09:53:37 AM: 	Best result seen so far for macro_avg: 0.868
09/16 09:53:37 AM: 	# validation passes without improvement: 3
09/16 09:53:37 AM: edges-ner-ontonotes_loss: training: 0.054233 validation: 0.041316
09/16 09:53:37 AM: macro_avg: validation: 0.862931
09/16 09:53:37 AM: micro_avg: validation: 0.000000
09/16 09:53:37 AM: edges-ner-ontonotes_mcc: training: 0.805157 validation: 0.858377
09/16 09:53:37 AM: edges-ner-ontonotes_acc: training: 0.713434 validation: 0.782150
09/16 09:53:37 AM: edges-ner-ontonotes_precision: training: 0.876184 validation: 0.935198
09/16 09:53:37 AM: edges-ner-ontonotes_recall: training: 0.758298 validation: 0.801031
09/16 09:53:37 AM: edges-ner-ontonotes_f1: training: 0.812990 validation: 0.862931
09/16 09:53:37 AM: Global learning rate: 0.0001
09/16 09:53:37 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:53:46 AM: Update 22103: task edges-ner-ontonotes, batch 103 (22103): mcc: 0.7924, acc: 0.6947, precision: 0.8658, recall: 0.7446, f1: 0.8007, edges-ner-ontonotes_loss: 0.0556
09/16 09:53:56 AM: Update 22231: task edges-ner-ontonotes, batch 231 (22231): mcc: 0.8012, acc: 0.7087, precision: 0.8706, recall: 0.7563, f1: 0.8094, edges-ner-ontonotes_loss: 0.0540
09/16 09:54:06 AM: Update 22353: task edges-ner-ontonotes, batch 353 (22353): mcc: 0.8020, acc: 0.7105, precision: 0.8710, recall: 0.7573, f1: 0.8102, edges-ner-ontonotes_loss: 0.0536
09/16 09:54:16 AM: Update 22458: task edges-ner-ontonotes, batch 458 (22458): mcc: 0.8048, acc: 0.7140, precision: 0.8734, recall: 0.7601, f1: 0.8128, edges-ner-ontonotes_loss: 0.0530
09/16 09:54:26 AM: Update 22578: task edges-ner-ontonotes, batch 578 (22578): mcc: 0.8100, acc: 0.7203, precision: 0.8771, recall: 0.7662, f1: 0.8179, edges-ner-ontonotes_loss: 0.0517
09/16 09:54:36 AM: Update 22702: task edges-ner-ontonotes, batch 702 (22702): mcc: 0.8154, acc: 0.7271, precision: 0.8813, recall: 0.7722, f1: 0.8231, edges-ner-ontonotes_loss: 0.0503
09/16 09:54:47 AM: Update 22798: task edges-ner-ontonotes, batch 798 (22798): mcc: 0.8178, acc: 0.7302, precision: 0.8829, recall: 0.7749, f1: 0.8254, edges-ner-ontonotes_loss: 0.0498
09/16 09:54:57 AM: Update 22918: task edges-ner-ontonotes, batch 918 (22918): mcc: 0.8189, acc: 0.7316, precision: 0.8838, recall: 0.7762, f1: 0.8265, edges-ner-ontonotes_loss: 0.0496
09/16 09:55:03 AM: ***** Step 23000 / Validation 23 *****
09/16 09:55:03 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:55:03 AM: Validating...
09/16 09:55:07 AM: Evaluate: task edges-ner-ontonotes, batch 31 (157): mcc: 0.8068, acc: 0.7310, precision: 0.8735, recall: 0.7637, f1: 0.8149, edges-ner-ontonotes_loss: 0.0568
09/16 09:55:17 AM: Evaluate: task edges-ner-ontonotes, batch 110 (157): mcc: 0.8537, acc: 0.7853, precision: 0.9154, recall: 0.8102, f1: 0.8596, edges-ner-ontonotes_loss: 0.0447
09/16 09:55:24 AM: Updating LR scheduler:
09/16 09:55:24 AM: 	Best result seen so far for macro_avg: 0.868
09/16 09:55:24 AM: 	# validation passes without improvement: 0
09/16 09:55:24 AM: edges-ner-ontonotes_loss: training: 0.049494 validation: 0.041709
09/16 09:55:24 AM: macro_avg: validation: 0.866417
09/16 09:55:24 AM: micro_avg: validation: 0.000000
09/16 09:55:24 AM: edges-ner-ontonotes_mcc: training: 0.819459 validation: 0.860932
09/16 09:55:24 AM: edges-ner-ontonotes_acc: training: 0.732248 validation: 0.791932
09/16 09:55:24 AM: edges-ner-ontonotes_precision: training: 0.884121 validation: 0.923903
09/16 09:55:24 AM: edges-ner-ontonotes_recall: training: 0.776879 validation: 0.815666
09/16 09:55:24 AM: edges-ner-ontonotes_f1: training: 0.827038 validation: 0.866417
09/16 09:55:24 AM: Global learning rate: 5e-05
09/16 09:55:24 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:55:28 AM: Update 23037: task edges-ner-ontonotes, batch 37 (23037): mcc: 0.8260, acc: 0.7337, precision: 0.8902, recall: 0.7831, f1: 0.8332, edges-ner-ontonotes_loss: 0.0467
09/16 09:55:38 AM: Update 23160: task edges-ner-ontonotes, batch 160 (23160): mcc: 0.7827, acc: 0.6831, precision: 0.8639, recall: 0.7291, f1: 0.7908, edges-ner-ontonotes_loss: 0.0609
09/16 09:55:48 AM: Update 23288: task edges-ner-ontonotes, batch 288 (23288): mcc: 0.7806, acc: 0.6828, precision: 0.8611, recall: 0.7278, f1: 0.7889, edges-ner-ontonotes_loss: 0.0613
09/16 09:55:58 AM: Update 23396: task edges-ner-ontonotes, batch 396 (23396): mcc: 0.7788, acc: 0.6797, precision: 0.8598, recall: 0.7257, f1: 0.7871, edges-ner-ontonotes_loss: 0.0615
09/16 09:56:08 AM: Update 23538: task edges-ner-ontonotes, batch 538 (23538): mcc: 0.7816, acc: 0.6832, precision: 0.8609, recall: 0.7297, f1: 0.7899, edges-ner-ontonotes_loss: 0.0601
09/16 09:56:18 AM: Update 23656: task edges-ner-ontonotes, batch 656 (23656): mcc: 0.7839, acc: 0.6865, precision: 0.8622, recall: 0.7328, f1: 0.7922, edges-ner-ontonotes_loss: 0.0593
09/16 09:56:28 AM: Update 23779: task edges-ner-ontonotes, batch 779 (23779): mcc: 0.7883, acc: 0.6931, precision: 0.8642, recall: 0.7387, f1: 0.7965, edges-ner-ontonotes_loss: 0.0581
09/16 09:56:38 AM: Update 23908: task edges-ner-ontonotes, batch 908 (23908): mcc: 0.7908, acc: 0.6965, precision: 0.8659, recall: 0.7417, f1: 0.7990, edges-ner-ontonotes_loss: 0.0575
09/16 09:56:48 AM: ***** Step 24000 / Validation 24 *****
09/16 09:56:48 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:56:48 AM: Validating...
09/16 09:56:48 AM: Evaluate: task edges-ner-ontonotes, batch 3 (157): mcc: 0.6590, acc: 0.5539, precision: 0.8000, recall: 0.5686, f1: 0.6648, edges-ner-ontonotes_loss: 0.0911
09/16 09:56:58 AM: Evaluate: task edges-ner-ontonotes, batch 89 (157): mcc: 0.8516, acc: 0.7818, precision: 0.9149, recall: 0.8070, f1: 0.8576, edges-ner-ontonotes_loss: 0.0446
09/16 09:57:08 AM: Updating LR scheduler:
09/16 09:57:08 AM: 	Best result seen so far for macro_avg: 0.868
09/16 09:57:08 AM: 	# validation passes without improvement: 1
09/16 09:57:08 AM: edges-ner-ontonotes_loss: training: 0.056881 validation: 0.041102
09/16 09:57:08 AM: macro_avg: validation: 0.867212
09/16 09:57:08 AM: micro_avg: validation: 0.000000
09/16 09:57:08 AM: edges-ner-ontonotes_mcc: training: 0.792900 validation: 0.861867
09/16 09:57:08 AM: edges-ner-ontonotes_acc: training: 0.699447 validation: 0.793069
09/16 09:57:08 AM: edges-ner-ontonotes_precision: training: 0.867092 validation: 0.926105
09/16 09:57:08 AM: edges-ner-ontonotes_recall: training: 0.744452 validation: 0.815362
09/16 09:57:08 AM: edges-ner-ontonotes_f1: training: 0.801106 validation: 0.867212
09/16 09:57:08 AM: Global learning rate: 5e-05
09/16 09:57:08 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:57:10 AM: Update 24005: task edges-ner-ontonotes, batch 5 (24005): mcc: 0.8526, acc: 0.7805, precision: 0.9036, recall: 0.8191, f1: 0.8593, edges-ner-ontonotes_loss: 0.0427
09/16 09:57:20 AM: Update 24123: task edges-ner-ontonotes, batch 123 (24123): mcc: 0.8346, acc: 0.7491, precision: 0.8983, recall: 0.7913, f1: 0.8414, edges-ner-ontonotes_loss: 0.0450
09/16 09:57:30 AM: Update 24250: task edges-ner-ontonotes, batch 250 (24250): mcc: 0.8365, acc: 0.7528, precision: 0.8976, recall: 0.7954, f1: 0.8434, edges-ner-ontonotes_loss: 0.0449
09/16 09:57:40 AM: Update 24339: task edges-ner-ontonotes, batch 339 (24339): mcc: 0.8334, acc: 0.7490, precision: 0.8953, recall: 0.7920, f1: 0.8405, edges-ner-ontonotes_loss: 0.0458
09/16 09:57:51 AM: Update 24465: task edges-ner-ontonotes, batch 465 (24465): mcc: 0.8333, acc: 0.7493, precision: 0.8945, recall: 0.7925, f1: 0.8404, edges-ner-ontonotes_loss: 0.0459
09/16 09:58:01 AM: Update 24590: task edges-ner-ontonotes, batch 590 (24590): mcc: 0.8327, acc: 0.7488, precision: 0.8939, recall: 0.7919, f1: 0.8398, edges-ner-ontonotes_loss: 0.0462
09/16 09:58:11 AM: Update 24701: task edges-ner-ontonotes, batch 701 (24701): mcc: 0.8237, acc: 0.7371, precision: 0.8883, recall: 0.7808, f1: 0.8311, edges-ner-ontonotes_loss: 0.0488
09/16 09:58:21 AM: Update 24828: task edges-ner-ontonotes, batch 828 (24828): mcc: 0.8173, acc: 0.7288, precision: 0.8844, recall: 0.7727, f1: 0.8248, edges-ner-ontonotes_loss: 0.0510
09/16 09:58:31 AM: Update 24942: task edges-ner-ontonotes, batch 942 (24942): mcc: 0.8140, acc: 0.7247, precision: 0.8820, recall: 0.7689, f1: 0.8216, edges-ner-ontonotes_loss: 0.0520
09/16 09:58:35 AM: ***** Step 25000 / Validation 25 *****
09/16 09:58:36 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 09:58:36 AM: Validating...
09/16 09:58:41 AM: Evaluate: task edges-ner-ontonotes, batch 39 (157): mcc: 0.8329, acc: 0.7578, precision: 0.9053, recall: 0.7821, f1: 0.8392, edges-ner-ontonotes_loss: 0.0483
09/16 09:58:51 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.8579, acc: 0.7844, precision: 0.9338, recall: 0.8014, f1: 0.8626, edges-ner-ontonotes_loss: 0.0420
09/16 09:58:57 AM: Updating LR scheduler:
09/16 09:58:59 AM: 	Best result seen so far for macro_avg: 0.868
09/16 09:58:59 AM: 	# validation passes without improvement: 2
09/16 09:58:59 AM: edges-ner-ontonotes_loss: training: 0.052391 validation: 0.040721
09/16 09:58:59 AM: macro_avg: validation: 0.864231
09/16 09:58:59 AM: micro_avg: validation: 0.000000
09/16 09:58:59 AM: edges-ner-ontonotes_mcc: training: 0.812582 validation: 0.859810
09/16 09:58:59 AM: edges-ner-ontonotes_acc: training: 0.722814 validation: 0.784729
09/16 09:58:59 AM: edges-ner-ontonotes_precision: training: 0.881307 validation: 0.937323
09/16 09:58:59 AM: edges-ner-ontonotes_recall: training: 0.767036 validation: 0.801714
09/16 09:58:59 AM: edges-ner-ontonotes_f1: training: 0.820210 validation: 0.864231
09/16 09:58:59 AM: Global learning rate: 5e-05
09/16 09:58:59 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 09:59:01 AM: Update 25024: task edges-ner-ontonotes, batch 24 (25024): mcc: 0.7924, acc: 0.6942, precision: 0.8653, recall: 0.7451, f1: 0.8007, edges-ner-ontonotes_loss: 0.0568
09/16 09:59:11 AM: Update 25169: task edges-ner-ontonotes, batch 169 (25169): mcc: 0.7960, acc: 0.7016, precision: 0.8700, recall: 0.7474, f1: 0.8041, edges-ner-ontonotes_loss: 0.0549
09/16 09:59:21 AM: Update 25269: task edges-ner-ontonotes, batch 269 (25269): mcc: 0.7960, acc: 0.7025, precision: 0.8699, recall: 0.7475, f1: 0.8041, edges-ner-ontonotes_loss: 0.0550
09/16 09:59:31 AM: Update 25399: task edges-ner-ontonotes, batch 399 (25399): mcc: 0.8006, acc: 0.7091, precision: 0.8719, recall: 0.7539, f1: 0.8086, edges-ner-ontonotes_loss: 0.0538
09/16 09:59:43 AM: Update 25523: task edges-ner-ontonotes, batch 523 (25523): mcc: 0.8015, acc: 0.7105, precision: 0.8723, recall: 0.7551, f1: 0.8095, edges-ner-ontonotes_loss: 0.0537
09/16 09:59:53 AM: Update 25642: task edges-ner-ontonotes, batch 642 (25642): mcc: 0.8075, acc: 0.7179, precision: 0.8764, recall: 0.7624, f1: 0.8154, edges-ner-ontonotes_loss: 0.0524
09/16 10:00:03 AM: Update 25767: task edges-ner-ontonotes, batch 767 (25767): mcc: 0.8133, acc: 0.7247, precision: 0.8806, recall: 0.7689, f1: 0.8210, edges-ner-ontonotes_loss: 0.0510
09/16 10:00:13 AM: Update 25870: task edges-ner-ontonotes, batch 870 (25870): mcc: 0.8155, acc: 0.7272, precision: 0.8826, recall: 0.7712, f1: 0.8231, edges-ner-ontonotes_loss: 0.0503
09/16 10:00:23 AM: Update 25995: task edges-ner-ontonotes, batch 995 (25995): mcc: 0.8178, acc: 0.7303, precision: 0.8841, recall: 0.7739, f1: 0.8254, edges-ner-ontonotes_loss: 0.0500
09/16 10:00:24 AM: ***** Step 26000 / Validation 26 *****
09/16 10:00:24 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:00:24 AM: Validating...
09/16 10:00:33 AM: Evaluate: task edges-ner-ontonotes, batch 82 (157): mcc: 0.8497, acc: 0.7807, precision: 0.9050, recall: 0.8126, f1: 0.8563, edges-ner-ontonotes_loss: 0.0462
09/16 10:00:43 AM: Evaluate: task edges-ner-ontonotes, batch 153 (157): mcc: 0.8638, acc: 0.7963, precision: 0.9232, recall: 0.8215, f1: 0.8694, edges-ner-ontonotes_loss: 0.0412
09/16 10:00:44 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:00:44 AM: Best result seen so far for macro.
09/16 10:00:44 AM: Updating LR scheduler:
09/16 10:00:44 AM: 	Best result seen so far for macro_avg: 0.870
09/16 10:00:44 AM: 	# validation passes without improvement: 0
09/16 10:00:44 AM: edges-ner-ontonotes_loss: training: 0.049935 validation: 0.041035
09/16 10:00:44 AM: macro_avg: validation: 0.869621
09/16 10:00:44 AM: micro_avg: validation: 0.000000
09/16 10:00:44 AM: edges-ner-ontonotes_mcc: training: 0.817943 validation: 0.864027
09/16 10:00:44 AM: edges-ner-ontonotes_acc: training: 0.730454 validation: 0.796861
09/16 10:00:44 AM: edges-ner-ontonotes_precision: training: 0.884105 validation: 0.922959
09/16 10:00:44 AM: edges-ner-ontonotes_recall: training: 0.774162 validation: 0.822111
09/16 10:00:44 AM: edges-ner-ontonotes_f1: training: 0.825489 validation: 0.869621
09/16 10:00:44 AM: Global learning rate: 5e-05
09/16 10:00:44 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:00:53 AM: Update 26115: task edges-ner-ontonotes, batch 115 (26115): mcc: 0.8321, acc: 0.7447, precision: 0.8939, recall: 0.7908, f1: 0.8392, edges-ner-ontonotes_loss: 0.0463
09/16 10:01:03 AM: Update 26214: task edges-ner-ontonotes, batch 214 (26214): mcc: 0.8078, acc: 0.7152, precision: 0.8795, recall: 0.7601, f1: 0.8155, edges-ner-ontonotes_loss: 0.0527
09/16 10:01:13 AM: Update 26342: task edges-ner-ontonotes, batch 342 (26342): mcc: 0.7976, acc: 0.7029, precision: 0.8731, recall: 0.7475, f1: 0.8054, edges-ner-ontonotes_loss: 0.0560
09/16 10:01:23 AM: Update 26453: task edges-ner-ontonotes, batch 453 (26453): mcc: 0.7943, acc: 0.6998, precision: 0.8698, recall: 0.7444, f1: 0.8023, edges-ner-ontonotes_loss: 0.0574
09/16 10:01:33 AM: Update 26602: task edges-ner-ontonotes, batch 602 (26602): mcc: 0.7928, acc: 0.6981, precision: 0.8678, recall: 0.7437, f1: 0.8010, edges-ner-ontonotes_loss: 0.0575
09/16 10:01:44 AM: Update 26753: task edges-ner-ontonotes, batch 753 (26753): mcc: 0.7943, acc: 0.6999, precision: 0.8685, recall: 0.7456, f1: 0.8024, edges-ner-ontonotes_loss: 0.0569
09/16 10:01:54 AM: Update 26852: task edges-ner-ontonotes, batch 852 (26852): mcc: 0.7946, acc: 0.7004, precision: 0.8686, recall: 0.7461, f1: 0.8027, edges-ner-ontonotes_loss: 0.0566
09/16 10:02:04 AM: Update 26982: task edges-ner-ontonotes, batch 982 (26982): mcc: 0.7959, acc: 0.7026, precision: 0.8689, recall: 0.7482, f1: 0.8041, edges-ner-ontonotes_loss: 0.0560
09/16 10:02:05 AM: ***** Step 27000 / Validation 27 *****
09/16 10:02:05 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:02:05 AM: Validating...
09/16 10:02:14 AM: Evaluate: task edges-ner-ontonotes, batch 72 (157): mcc: 0.8492, acc: 0.7771, precision: 0.9146, recall: 0.8028, f1: 0.8551, edges-ner-ontonotes_loss: 0.0449
09/16 10:02:24 AM: Evaluate: task edges-ner-ontonotes, batch 145 (157): mcc: 0.8630, acc: 0.7912, precision: 0.9335, recall: 0.8107, f1: 0.8678, edges-ner-ontonotes_loss: 0.0405
09/16 10:02:25 AM: Updating LR scheduler:
09/16 10:02:25 AM: 	Best result seen so far for macro_avg: 0.870
09/16 10:02:25 AM: 	# validation passes without improvement: 1
09/16 10:02:25 AM: edges-ner-ontonotes_loss: training: 0.055930 validation: 0.040167
09/16 10:02:25 AM: macro_avg: validation: 0.868306
09/16 10:02:25 AM: micro_avg: validation: 0.000000
09/16 10:02:25 AM: edges-ner-ontonotes_mcc: training: 0.796243 validation: 0.863494
09/16 10:02:25 AM: edges-ner-ontonotes_acc: training: 0.702988 validation: 0.791856
09/16 10:02:25 AM: edges-ner-ontonotes_precision: training: 0.869247 validation: 0.933770
09/16 10:02:25 AM: edges-ner-ontonotes_recall: training: 0.748516 validation: 0.811419
09/16 10:02:25 AM: edges-ner-ontonotes_f1: training: 0.804377 validation: 0.868306
09/16 10:02:25 AM: Global learning rate: 5e-05
09/16 10:02:25 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:02:34 AM: Update 27080: task edges-ner-ontonotes, batch 80 (27080): mcc: 0.8004, acc: 0.7074, precision: 0.8731, recall: 0.7526, f1: 0.8084, edges-ner-ontonotes_loss: 0.0543
09/16 10:02:44 AM: Update 27198: task edges-ner-ontonotes, batch 198 (27198): mcc: 0.8199, acc: 0.7319, precision: 0.8851, recall: 0.7767, f1: 0.8274, edges-ner-ontonotes_loss: 0.0494
09/16 10:02:54 AM: Update 27313: task edges-ner-ontonotes, batch 313 (27313): mcc: 0.8260, acc: 0.7391, precision: 0.8896, recall: 0.7837, f1: 0.8333, edges-ner-ontonotes_loss: 0.0476
09/16 10:03:04 AM: Update 27422: task edges-ner-ontonotes, batch 422 (27422): mcc: 0.8272, acc: 0.7408, precision: 0.8901, recall: 0.7854, f1: 0.8345, edges-ner-ontonotes_loss: 0.0472
09/16 10:03:14 AM: Update 27548: task edges-ner-ontonotes, batch 548 (27548): mcc: 0.8291, acc: 0.7435, precision: 0.8916, recall: 0.7875, f1: 0.8363, edges-ner-ontonotes_loss: 0.0467
09/16 10:03:24 AM: Update 27669: task edges-ner-ontonotes, batch 669 (27669): mcc: 0.8300, acc: 0.7450, precision: 0.8926, recall: 0.7883, f1: 0.8372, edges-ner-ontonotes_loss: 0.0466
09/16 10:03:34 AM: Update 27761: task edges-ner-ontonotes, batch 761 (27761): mcc: 0.8244, acc: 0.7370, precision: 0.8893, recall: 0.7811, f1: 0.8317, edges-ner-ontonotes_loss: 0.0479
09/16 10:03:44 AM: Update 27895: task edges-ner-ontonotes, batch 895 (27895): mcc: 0.8182, acc: 0.7292, precision: 0.8849, recall: 0.7740, f1: 0.8257, edges-ner-ontonotes_loss: 0.0503
09/16 10:03:52 AM: ***** Step 28000 / Validation 28 *****
09/16 10:03:52 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:03:52 AM: Validating...
09/16 10:03:54 AM: Evaluate: task edges-ner-ontonotes, batch 19 (157): mcc: 0.8071, acc: 0.7325, precision: 0.8690, recall: 0.7683, f1: 0.8156, edges-ner-ontonotes_loss: 0.0511
09/16 10:04:05 AM: Evaluate: task edges-ner-ontonotes, batch 100 (157): mcc: 0.8562, acc: 0.7865, precision: 0.9202, recall: 0.8104, f1: 0.8618, edges-ner-ontonotes_loss: 0.0435
09/16 10:04:12 AM: Updating LR scheduler:
09/16 10:04:12 AM: 	Best result seen so far for macro_avg: 0.870
09/16 10:04:12 AM: 	# validation passes without improvement: 2
09/16 10:04:12 AM: edges-ner-ontonotes_loss: training: 0.051539 validation: 0.040388
09/16 10:04:12 AM: macro_avg: validation: 0.869534
09/16 10:04:12 AM: micro_avg: validation: 0.000000
09/16 10:04:12 AM: edges-ner-ontonotes_mcc: training: 0.814982 validation: 0.864565
09/16 10:04:12 AM: edges-ner-ontonotes_acc: training: 0.725373 validation: 0.793449
09/16 10:04:12 AM: edges-ner-ontonotes_precision: training: 0.882670 validation: 0.932009
09/16 10:04:12 AM: edges-ner-ontonotes_recall: training: 0.770124 validation: 0.814907
09/16 10:04:12 AM: edges-ner-ontonotes_f1: training: 0.822566 validation: 0.869534
09/16 10:04:12 AM: Global learning rate: 5e-05
09/16 10:04:12 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:04:15 AM: Update 28009: task edges-ner-ontonotes, batch 9 (28009): mcc: 0.7780, acc: 0.6699, precision: 0.8562, recall: 0.7275, f1: 0.7866, edges-ner-ontonotes_loss: 0.0613
09/16 10:04:25 AM: Update 28146: task edges-ner-ontonotes, batch 146 (28146): mcc: 0.7835, acc: 0.6855, precision: 0.8581, recall: 0.7356, f1: 0.7921, edges-ner-ontonotes_loss: 0.0583
09/16 10:04:35 AM: Update 28296: task edges-ner-ontonotes, batch 296 (28296): mcc: 0.7916, acc: 0.6959, precision: 0.8650, recall: 0.7439, f1: 0.7999, edges-ner-ontonotes_loss: 0.0564
09/16 10:04:45 AM: Update 28403: task edges-ner-ontonotes, batch 403 (28403): mcc: 0.7933, acc: 0.6988, precision: 0.8658, recall: 0.7463, f1: 0.8016, edges-ner-ontonotes_loss: 0.0559
09/16 10:04:55 AM: Update 28526: task edges-ner-ontonotes, batch 526 (28526): mcc: 0.7966, acc: 0.7041, precision: 0.8678, recall: 0.7504, f1: 0.8048, edges-ner-ontonotes_loss: 0.0553
09/16 10:05:05 AM: Update 28641: task edges-ner-ontonotes, batch 641 (28641): mcc: 0.7991, acc: 0.7069, precision: 0.8704, recall: 0.7526, f1: 0.8073, edges-ner-ontonotes_loss: 0.0544
09/16 10:05:15 AM: Update 28762: task edges-ner-ontonotes, batch 762 (28762): mcc: 0.8059, acc: 0.7149, precision: 0.8755, recall: 0.7602, f1: 0.8138, edges-ner-ontonotes_loss: 0.0530
09/16 10:05:25 AM: Update 28889: task edges-ner-ontonotes, batch 889 (28889): mcc: 0.8118, acc: 0.7222, precision: 0.8794, recall: 0.7674, f1: 0.8196, edges-ner-ontonotes_loss: 0.0517
09/16 10:05:35 AM: Update 28979: task edges-ner-ontonotes, batch 979 (28979): mcc: 0.8136, acc: 0.7245, precision: 0.8804, recall: 0.7696, f1: 0.8213, edges-ner-ontonotes_loss: 0.0511
09/16 10:05:37 AM: ***** Step 29000 / Validation 29 *****
09/16 10:05:37 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:05:37 AM: Validating...
09/16 10:05:45 AM: Evaluate: task edges-ner-ontonotes, batch 71 (157): mcc: 0.8382, acc: 0.7666, precision: 0.8965, recall: 0.7996, f1: 0.8453, edges-ner-ontonotes_loss: 0.0490
09/16 10:05:55 AM: Evaluate: task edges-ner-ontonotes, batch 142 (157): mcc: 0.8653, acc: 0.7984, precision: 0.9242, recall: 0.8232, f1: 0.8708, edges-ner-ontonotes_loss: 0.0414
09/16 10:05:57 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:05:57 AM: Best result seen so far for macro.
09/16 10:05:57 AM: Updating LR scheduler:
09/16 10:05:57 AM: 	Best result seen so far for macro_avg: 0.870
09/16 10:05:57 AM: 	# validation passes without improvement: 0
09/16 10:05:57 AM: edges-ner-ontonotes_loss: training: 0.050970 validation: 0.041108
09/16 10:05:57 AM: macro_avg: validation: 0.870220
09/16 10:05:57 AM: micro_avg: validation: 0.000000
09/16 10:05:57 AM: edges-ner-ontonotes_mcc: training: 0.814101 validation: 0.864621
09/16 10:05:57 AM: edges-ner-ontonotes_acc: training: 0.725157 validation: 0.797467
09/16 10:05:57 AM: edges-ner-ontonotes_precision: training: 0.880902 validation: 0.922972
09/16 10:05:57 AM: edges-ner-ontonotes_recall: training: 0.770132 validation: 0.823173
09/16 10:05:57 AM: edges-ner-ontonotes_f1: training: 0.821801 validation: 0.870220
09/16 10:05:57 AM: Global learning rate: 5e-05
09/16 10:05:57 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:06:05 AM: Update 29101: task edges-ner-ontonotes, batch 101 (29101): mcc: 0.8293, acc: 0.7428, precision: 0.8899, recall: 0.7893, f1: 0.8366, edges-ner-ontonotes_loss: 0.0476
09/16 10:06:16 AM: Update 29223: task edges-ner-ontonotes, batch 223 (29223): mcc: 0.8285, acc: 0.7435, precision: 0.8889, recall: 0.7889, f1: 0.8359, edges-ner-ontonotes_loss: 0.0471
09/16 10:06:26 AM: Update 29332: task edges-ner-ontonotes, batch 332 (29332): mcc: 0.8167, acc: 0.7276, precision: 0.8822, recall: 0.7737, f1: 0.8244, edges-ner-ontonotes_loss: 0.0506
09/16 10:06:36 AM: Update 29461: task edges-ner-ontonotes, batch 461 (29461): mcc: 0.8055, acc: 0.7133, precision: 0.8755, recall: 0.7595, f1: 0.8134, edges-ner-ontonotes_loss: 0.0541
09/16 10:06:46 AM: Update 29565: task edges-ner-ontonotes, batch 565 (29565): mcc: 0.8020, acc: 0.7091, precision: 0.8731, recall: 0.7553, f1: 0.8099, edges-ner-ontonotes_loss: 0.0554
09/16 10:06:56 AM: Update 29715: task edges-ner-ontonotes, batch 715 (29715): mcc: 0.8000, acc: 0.7067, precision: 0.8711, recall: 0.7535, f1: 0.8081, edges-ner-ontonotes_loss: 0.0557
09/16 10:07:06 AM: Update 29862: task edges-ner-ontonotes, batch 862 (29862): mcc: 0.7999, acc: 0.7064, precision: 0.8716, recall: 0.7531, f1: 0.8080, edges-ner-ontonotes_loss: 0.0556
09/16 10:07:16 AM: Update 29962: task edges-ner-ontonotes, batch 962 (29962): mcc: 0.8000, acc: 0.7064, precision: 0.8718, recall: 0.7529, f1: 0.8080, edges-ner-ontonotes_loss: 0.0554
09/16 10:07:19 AM: ***** Step 30000 / Validation 30 *****
09/16 10:07:19 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:07:19 AM: Validating...
09/16 10:07:26 AM: Evaluate: task edges-ner-ontonotes, batch 63 (157): mcc: 0.8559, acc: 0.7874, precision: 0.9145, recall: 0.8151, f1: 0.8620, edges-ner-ontonotes_loss: 0.0435
09/16 10:07:36 AM: Evaluate: task edges-ner-ontonotes, batch 135 (157): mcc: 0.8675, acc: 0.7981, precision: 0.9349, recall: 0.8175, f1: 0.8723, edges-ner-ontonotes_loss: 0.0401
09/16 10:07:39 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:07:39 AM: Best result seen so far for macro.
09/16 10:07:39 AM: Updating LR scheduler:
09/16 10:07:39 AM: 	Best result seen so far for macro_avg: 0.872
09/16 10:07:39 AM: 	# validation passes without improvement: 0
09/16 10:07:39 AM: edges-ner-ontonotes_loss: training: 0.055340 validation: 0.039693
09/16 10:07:39 AM: macro_avg: validation: 0.872124
09/16 10:07:39 AM: micro_avg: validation: 0.000000
09/16 10:07:39 AM: edges-ner-ontonotes_mcc: training: 0.800127 validation: 0.867254
09/16 10:07:39 AM: edges-ner-ontonotes_acc: training: 0.706741 validation: 0.797164
09/16 10:07:39 AM: edges-ner-ontonotes_precision: training: 0.871672 validation: 0.934095
09/16 10:07:39 AM: edges-ner-ontonotes_recall: training: 0.753312 validation: 0.817865
09/16 10:07:39 AM: edges-ner-ontonotes_f1: training: 0.808181 validation: 0.872124
09/16 10:07:39 AM: Global learning rate: 5e-05
09/16 10:07:39 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:07:46 AM: Update 30090: task edges-ner-ontonotes, batch 90 (30090): mcc: 0.8128, acc: 0.7262, precision: 0.8785, recall: 0.7701, f1: 0.8207, edges-ner-ontonotes_loss: 0.0517
09/16 10:07:56 AM: Update 30191: task edges-ner-ontonotes, batch 191 (30191): mcc: 0.8069, acc: 0.7190, precision: 0.8747, recall: 0.7627, f1: 0.8149, edges-ner-ontonotes_loss: 0.0530
09/16 10:08:06 AM: Update 30312: task edges-ner-ontonotes, batch 312 (30312): mcc: 0.8185, acc: 0.7325, precision: 0.8836, recall: 0.7756, f1: 0.8261, edges-ner-ontonotes_loss: 0.0498
09/16 10:08:16 AM: Update 30432: task edges-ner-ontonotes, batch 432 (30432): mcc: 0.8244, acc: 0.7400, precision: 0.8879, recall: 0.7823, f1: 0.8318, edges-ner-ontonotes_loss: 0.0484
09/16 10:08:26 AM: Update 30538: task edges-ner-ontonotes, batch 538 (30538): mcc: 0.8242, acc: 0.7390, precision: 0.8882, recall: 0.7818, f1: 0.8316, edges-ner-ontonotes_loss: 0.0482
09/16 10:08:36 AM: Update 30657: task edges-ner-ontonotes, batch 657 (30657): mcc: 0.8250, acc: 0.7393, precision: 0.8884, recall: 0.7830, f1: 0.8324, edges-ner-ontonotes_loss: 0.0478
09/16 10:08:46 AM: Update 30780: task edges-ner-ontonotes, batch 780 (30780): mcc: 0.8270, acc: 0.7415, precision: 0.8897, recall: 0.7854, f1: 0.8343, edges-ner-ontonotes_loss: 0.0475
09/16 10:08:57 AM: Update 30870: task edges-ner-ontonotes, batch 870 (30870): mcc: 0.8218, acc: 0.7349, precision: 0.8870, recall: 0.7786, f1: 0.8292, edges-ner-ontonotes_loss: 0.0487
09/16 10:09:06 AM: ***** Step 31000 / Validation 31 *****
09/16 10:09:06 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:09:06 AM: Validating...
09/16 10:09:07 AM: Evaluate: task edges-ner-ontonotes, batch 3 (157): mcc: 0.6958, acc: 0.5833, precision: 0.7927, recall: 0.6373, f1: 0.7065, edges-ner-ontonotes_loss: 0.0847
09/16 10:09:17 AM: Evaluate: task edges-ner-ontonotes, batch 88 (157): mcc: 0.8604, acc: 0.7941, precision: 0.9171, recall: 0.8209, f1: 0.8663, edges-ner-ontonotes_loss: 0.0430
09/16 10:09:26 AM: Updating LR scheduler:
09/16 10:09:26 AM: 	Best result seen so far for macro_avg: 0.872
09/16 10:09:26 AM: 	# validation passes without improvement: 1
09/16 10:09:26 AM: edges-ner-ontonotes_loss: training: 0.050562 validation: 0.040379
09/16 10:09:26 AM: macro_avg: validation: 0.871220
09/16 10:09:26 AM: micro_avg: validation: 0.000000
09/16 10:09:26 AM: edges-ner-ontonotes_mcc: training: 0.816672 validation: 0.866095
09/16 10:09:26 AM: edges-ner-ontonotes_acc: training: 0.728462 validation: 0.797164
09/16 10:09:26 AM: edges-ner-ontonotes_precision: training: 0.883374 validation: 0.930257
09/16 10:09:26 AM: edges-ner-ontonotes_recall: training: 0.772531 validation: 0.819230
09/16 10:09:26 AM: edges-ner-ontonotes_f1: training: 0.824243 validation: 0.871220
09/16 10:09:26 AM: Global learning rate: 5e-05
09/16 10:09:26 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:09:27 AM: Update 31006: task edges-ner-ontonotes, batch 6 (31006): mcc: 0.7963, acc: 0.7017, precision: 0.8840, recall: 0.7358, f1: 0.8031, edges-ner-ontonotes_loss: 0.0650
09/16 10:09:38 AM: Update 31121: task edges-ner-ontonotes, batch 121 (31121): mcc: 0.7811, acc: 0.6869, precision: 0.8585, recall: 0.7309, f1: 0.7896, edges-ner-ontonotes_loss: 0.0624
09/16 10:09:48 AM: Update 31269: task edges-ner-ontonotes, batch 269 (31269): mcc: 0.7845, acc: 0.6897, precision: 0.8604, recall: 0.7354, f1: 0.7930, edges-ner-ontonotes_loss: 0.0598
09/16 10:09:58 AM: Update 31416: task edges-ner-ontonotes, batch 416 (31416): mcc: 0.7883, acc: 0.6933, precision: 0.8623, recall: 0.7404, f1: 0.7967, edges-ner-ontonotes_loss: 0.0582
09/16 10:10:08 AM: Update 31520: task edges-ner-ontonotes, batch 520 (31520): mcc: 0.7910, acc: 0.6968, precision: 0.8634, recall: 0.7444, f1: 0.7995, edges-ner-ontonotes_loss: 0.0572
09/16 10:10:18 AM: Update 31650: task edges-ner-ontonotes, batch 650 (31650): mcc: 0.7959, acc: 0.7033, precision: 0.8672, recall: 0.7497, f1: 0.8042, edges-ner-ontonotes_loss: 0.0560
09/16 10:10:28 AM: Update 31748: task edges-ner-ontonotes, batch 748 (31748): mcc: 0.7967, acc: 0.7044, precision: 0.8678, recall: 0.7506, f1: 0.8049, edges-ner-ontonotes_loss: 0.0556
09/16 10:10:38 AM: Update 31864: task edges-ner-ontonotes, batch 864 (31864): mcc: 0.8027, acc: 0.7117, precision: 0.8723, recall: 0.7575, f1: 0.8108, edges-ner-ontonotes_loss: 0.0542
09/16 10:10:48 AM: Update 31991: task edges-ner-ontonotes, batch 991 (31991): mcc: 0.8076, acc: 0.7179, precision: 0.8754, recall: 0.7634, f1: 0.8156, edges-ner-ontonotes_loss: 0.0529
09/16 10:10:49 AM: ***** Step 32000 / Validation 32 *****
09/16 10:10:49 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:10:49 AM: Validating...
09/16 10:10:58 AM: Evaluate: task edges-ner-ontonotes, batch 78 (157): mcc: 0.8482, acc: 0.7794, precision: 0.9069, recall: 0.8081, f1: 0.8546, edges-ner-ontonotes_loss: 0.0472
09/16 10:11:08 AM: Evaluate: task edges-ner-ontonotes, batch 151 (157): mcc: 0.8647, acc: 0.7973, precision: 0.9251, recall: 0.8213, f1: 0.8701, edges-ner-ontonotes_loss: 0.0413
09/16 10:11:09 AM: Updating LR scheduler:
09/16 10:11:09 AM: 	Best result seen so far for macro_avg: 0.872
09/16 10:11:09 AM: 	# validation passes without improvement: 2
09/16 10:11:09 AM: edges-ner-ontonotes_loss: training: 0.052830 validation: 0.041106
09/16 10:11:09 AM: macro_avg: validation: 0.870421
09/16 10:11:09 AM: micro_avg: validation: 0.000000
09/16 10:11:09 AM: edges-ner-ontonotes_mcc: training: 0.807692 validation: 0.864980
09/16 10:11:09 AM: edges-ner-ontonotes_acc: training: 0.718008 validation: 0.797771
09/16 10:11:09 AM: edges-ner-ontonotes_precision: training: 0.875525 validation: 0.925436
09/16 10:11:09 AM: edges-ner-ontonotes_recall: training: 0.763442 validation: 0.821580
09/16 10:11:09 AM: edges-ner-ontonotes_f1: training: 0.815651 validation: 0.870421
09/16 10:11:09 AM: Global learning rate: 5e-05
09/16 10:11:09 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:11:18 AM: Update 32088: task edges-ner-ontonotes, batch 88 (32088): mcc: 0.8278, acc: 0.7423, precision: 0.8920, recall: 0.7849, f1: 0.8350, edges-ner-ontonotes_loss: 0.0472
09/16 10:11:28 AM: Update 32207: task edges-ner-ontonotes, batch 207 (32207): mcc: 0.8303, acc: 0.7449, precision: 0.8928, recall: 0.7886, f1: 0.8375, edges-ner-ontonotes_loss: 0.0466
09/16 10:11:38 AM: Update 32336: task edges-ner-ontonotes, batch 336 (32336): mcc: 0.8320, acc: 0.7471, precision: 0.8930, recall: 0.7914, f1: 0.8391, edges-ner-ontonotes_loss: 0.0466
09/16 10:11:48 AM: Update 32440: task edges-ner-ontonotes, batch 440 (32440): mcc: 0.8211, acc: 0.7327, precision: 0.8869, recall: 0.7773, f1: 0.8285, edges-ner-ontonotes_loss: 0.0495
09/16 10:11:58 AM: Update 32567: task edges-ner-ontonotes, batch 567 (32567): mcc: 0.8124, acc: 0.7224, precision: 0.8805, recall: 0.7674, f1: 0.8201, edges-ner-ontonotes_loss: 0.0524
09/16 10:12:08 AM: Update 32677: task edges-ner-ontonotes, batch 677 (32677): mcc: 0.8072, acc: 0.7156, precision: 0.8766, recall: 0.7615, f1: 0.8150, edges-ner-ontonotes_loss: 0.0540
09/16 10:12:19 AM: Update 32828: task edges-ner-ontonotes, batch 828 (32828): mcc: 0.8052, acc: 0.7130, precision: 0.8749, recall: 0.7596, f1: 0.8132, edges-ner-ontonotes_loss: 0.0542
09/16 10:12:29 AM: Update 32975: task edges-ner-ontonotes, batch 975 (32975): mcc: 0.8035, acc: 0.7110, precision: 0.8738, recall: 0.7576, f1: 0.8115, edges-ner-ontonotes_loss: 0.0546
09/16 10:12:32 AM: ***** Step 33000 / Validation 33 *****
09/16 10:12:32 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:12:32 AM: Validating...
09/16 10:12:39 AM: Evaluate: task edges-ner-ontonotes, batch 57 (157): mcc: 0.8565, acc: 0.7877, precision: 0.9209, recall: 0.8105, f1: 0.8622, edges-ner-ontonotes_loss: 0.0437
09/16 10:12:49 AM: Evaluate: task edges-ner-ontonotes, batch 128 (157): mcc: 0.8645, acc: 0.7944, precision: 0.9351, recall: 0.8120, f1: 0.8692, edges-ner-ontonotes_loss: 0.0407
09/16 10:12:52 AM: Updating LR scheduler:
09/16 10:12:52 AM: 	Best result seen so far for macro_avg: 0.872
09/16 10:12:52 AM: 	# validation passes without improvement: 3
09/16 10:12:52 AM: edges-ner-ontonotes_loss: training: 0.054681 validation: 0.039947
09/16 10:12:52 AM: macro_avg: validation: 0.869816
09/16 10:12:52 AM: micro_avg: validation: 0.000000
09/16 10:12:52 AM: edges-ner-ontonotes_mcc: training: 0.802740 validation: 0.865187
09/16 10:12:52 AM: edges-ner-ontonotes_acc: training: 0.710060 validation: 0.794055
09/16 10:12:52 AM: edges-ner-ontonotes_precision: training: 0.873199 validation: 0.936663
09/16 10:12:52 AM: edges-ner-ontonotes_recall: training: 0.756632 validation: 0.811874
09/16 10:12:52 AM: edges-ner-ontonotes_f1: training: 0.810747 validation: 0.869816
09/16 10:12:52 AM: Global learning rate: 5e-05
09/16 10:12:52 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:12:59 AM: Update 33079: task edges-ner-ontonotes, batch 79 (33079): mcc: 0.7988, acc: 0.7076, precision: 0.8696, recall: 0.7528, f1: 0.8070, edges-ner-ontonotes_loss: 0.0543
09/16 10:13:09 AM: Update 33200: task edges-ner-ontonotes, batch 200 (33200): mcc: 0.8055, acc: 0.7162, precision: 0.8748, recall: 0.7603, f1: 0.8135, edges-ner-ontonotes_loss: 0.0523
09/16 10:13:20 AM: Update 33303: task edges-ner-ontonotes, batch 303 (33303): mcc: 0.8057, acc: 0.7160, precision: 0.8752, recall: 0.7601, f1: 0.8136, edges-ner-ontonotes_loss: 0.0522
09/16 10:13:30 AM: Update 33423: task edges-ner-ontonotes, batch 423 (33423): mcc: 0.8118, acc: 0.7221, precision: 0.8793, recall: 0.7675, f1: 0.8196, edges-ner-ontonotes_loss: 0.0505
09/16 10:13:40 AM: Update 33546: task edges-ner-ontonotes, batch 546 (33546): mcc: 0.8197, acc: 0.7326, precision: 0.8847, recall: 0.7768, f1: 0.8272, edges-ner-ontonotes_loss: 0.0489
09/16 10:13:50 AM: Update 33648: task edges-ner-ontonotes, batch 648 (33648): mcc: 0.8217, acc: 0.7352, precision: 0.8855, recall: 0.7796, f1: 0.8292, edges-ner-ontonotes_loss: 0.0483
09/16 10:14:00 AM: Update 33764: task edges-ner-ontonotes, batch 764 (33764): mcc: 0.8234, acc: 0.7373, precision: 0.8864, recall: 0.7819, f1: 0.8309, edges-ner-ontonotes_loss: 0.0480
09/16 10:14:10 AM: Update 33884: task edges-ner-ontonotes, batch 884 (33884): mcc: 0.8244, acc: 0.7385, precision: 0.8873, recall: 0.7830, f1: 0.8319, edges-ner-ontonotes_loss: 0.0478
09/16 10:14:20 AM: Update 33984: task edges-ner-ontonotes, batch 984 (33984): mcc: 0.8211, acc: 0.7342, precision: 0.8852, recall: 0.7789, f1: 0.8287, edges-ner-ontonotes_loss: 0.0487
09/16 10:14:22 AM: ***** Step 34000 / Validation 34 *****
09/16 10:14:22 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:14:22 AM: Validating...
09/16 10:14:31 AM: Evaluate: task edges-ner-ontonotes, batch 71 (157): mcc: 0.8467, acc: 0.7731, precision: 0.9092, recall: 0.8034, f1: 0.8530, edges-ner-ontonotes_loss: 0.0456
09/16 10:14:41 AM: Evaluate: task edges-ner-ontonotes, batch 143 (157): mcc: 0.8656, acc: 0.7938, precision: 0.9345, recall: 0.8146, f1: 0.8704, edges-ner-ontonotes_loss: 0.0403
09/16 10:14:42 AM: Updating LR scheduler:
09/16 10:14:42 AM: 	Best result seen so far for macro_avg: 0.872
09/16 10:14:42 AM: 	# validation passes without improvement: 0
09/16 10:14:42 AM: edges-ner-ontonotes_loss: training: 0.048926 validation: 0.040149
09/16 10:14:42 AM: macro_avg: validation: 0.869622
09/16 10:14:42 AM: micro_avg: validation: 0.000000
09/16 10:14:42 AM: edges-ner-ontonotes_mcc: training: 0.820248 validation: 0.864775
09/16 10:14:42 AM: edges-ner-ontonotes_acc: training: 0.733016 validation: 0.792008
09/16 10:14:42 AM: edges-ner-ontonotes_precision: training: 0.884796 validation: 0.933705
09/16 10:14:42 AM: edges-ner-ontonotes_recall: training: 0.777691 validation: 0.813770
09/16 10:14:42 AM: edges-ner-ontonotes_f1: training: 0.827793 validation: 0.869622
09/16 10:14:42 AM: Global learning rate: 2.5e-05
09/16 10:14:42 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:14:51 AM: Update 34106: task edges-ner-ontonotes, batch 106 (34106): mcc: 0.7770, acc: 0.6812, precision: 0.8548, recall: 0.7270, f1: 0.7858, edges-ner-ontonotes_loss: 0.0642
09/16 10:15:02 AM: Update 34233: task edges-ner-ontonotes, batch 233 (34233): mcc: 0.7791, acc: 0.6817, precision: 0.8572, recall: 0.7285, f1: 0.7876, edges-ner-ontonotes_loss: 0.0626
09/16 10:15:12 AM: Update 34381: task edges-ner-ontonotes, batch 381 (34381): mcc: 0.7828, acc: 0.6867, precision: 0.8589, recall: 0.7336, f1: 0.7913, edges-ner-ontonotes_loss: 0.0605
09/16 10:15:23 AM: Update 34531: task edges-ner-ontonotes, batch 531 (34531): mcc: 0.7866, acc: 0.6916, precision: 0.8618, recall: 0.7379, f1: 0.7951, edges-ner-ontonotes_loss: 0.0591
09/16 10:15:33 AM: Update 34634: task edges-ner-ontonotes, batch 634 (34634): mcc: 0.7895, acc: 0.6955, precision: 0.8633, recall: 0.7418, f1: 0.7979, edges-ner-ontonotes_loss: 0.0582
09/16 10:15:43 AM: Update 34762: task edges-ner-ontonotes, batch 762 (34762): mcc: 0.7937, acc: 0.7010, precision: 0.8661, recall: 0.7468, f1: 0.8021, edges-ner-ontonotes_loss: 0.0570
09/16 10:15:53 AM: Update 34865: task edges-ner-ontonotes, batch 865 (34865): mcc: 0.7946, acc: 0.7026, precision: 0.8670, recall: 0.7475, f1: 0.8029, edges-ner-ontonotes_loss: 0.0565
09/16 10:16:03 AM: Update 34991: task edges-ner-ontonotes, batch 991 (34991): mcc: 0.8008, acc: 0.7102, precision: 0.8716, recall: 0.7546, f1: 0.8089, edges-ner-ontonotes_loss: 0.0549
09/16 10:16:04 AM: ***** Step 35000 / Validation 35 *****
09/16 10:16:04 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:16:04 AM: Validating...
09/16 10:16:13 AM: Evaluate: task edges-ner-ontonotes, batch 77 (157): mcc: 0.8493, acc: 0.7795, precision: 0.9124, recall: 0.8051, f1: 0.8554, edges-ner-ontonotes_loss: 0.0459
09/16 10:16:23 AM: Evaluate: task edges-ner-ontonotes, batch 152 (157): mcc: 0.8661, acc: 0.7976, precision: 0.9305, recall: 0.8191, f1: 0.8713, edges-ner-ontonotes_loss: 0.0403
09/16 10:16:24 AM: Updating LR scheduler:
09/16 10:16:24 AM: 	Best result seen so far for macro_avg: 0.872
09/16 10:16:24 AM: 	# validation passes without improvement: 1
09/16 10:16:24 AM: edges-ner-ontonotes_loss: training: 0.054864 validation: 0.040148
09/16 10:16:24 AM: macro_avg: validation: 0.871735
09/16 10:16:24 AM: micro_avg: validation: 0.000000
09/16 10:16:24 AM: edges-ner-ontonotes_mcc: training: 0.801132 validation: 0.866621
09/16 10:16:24 AM: edges-ner-ontonotes_acc: training: 0.710616 validation: 0.798377
09/16 10:16:24 AM: edges-ner-ontonotes_precision: training: 0.871839 validation: 0.930551
09/16 10:16:24 AM: edges-ner-ontonotes_recall: training: 0.754965 validation: 0.819912
09/16 10:16:24 AM: edges-ner-ontonotes_f1: training: 0.809204 validation: 0.871735
09/16 10:16:24 AM: Global learning rate: 2.5e-05
09/16 10:16:24 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:16:33 AM: Update 35115: task edges-ner-ontonotes, batch 115 (35115): mcc: 0.8391, acc: 0.7575, precision: 0.8999, recall: 0.7980, f1: 0.8459, edges-ner-ontonotes_loss: 0.0444
09/16 10:16:43 AM: Update 35208: task edges-ner-ontonotes, batch 208 (35208): mcc: 0.8348, acc: 0.7529, precision: 0.8963, recall: 0.7936, f1: 0.8418, edges-ner-ontonotes_loss: 0.0449
09/16 10:16:53 AM: Update 35329: task edges-ner-ontonotes, batch 329 (35329): mcc: 0.8329, acc: 0.7497, precision: 0.8940, recall: 0.7922, f1: 0.8400, edges-ner-ontonotes_loss: 0.0456
09/16 10:17:03 AM: Update 35452: task edges-ner-ontonotes, batch 452 (35452): mcc: 0.8325, acc: 0.7489, precision: 0.8930, recall: 0.7924, f1: 0.8397, edges-ner-ontonotes_loss: 0.0459
09/16 10:17:13 AM: Update 35558: task edges-ner-ontonotes, batch 558 (35558): mcc: 0.8248, acc: 0.7386, precision: 0.8887, recall: 0.7824, f1: 0.8321, edges-ner-ontonotes_loss: 0.0484
09/16 10:17:23 AM: Update 35677: task edges-ner-ontonotes, batch 677 (35677): mcc: 0.8160, acc: 0.7267, precision: 0.8832, recall: 0.7714, f1: 0.8235, edges-ner-ontonotes_loss: 0.0510
09/16 10:17:33 AM: Update 35790: task edges-ner-ontonotes, batch 790 (35790): mcc: 0.8122, acc: 0.7223, precision: 0.8802, recall: 0.7672, f1: 0.8199, edges-ner-ontonotes_loss: 0.0526
09/16 10:17:44 AM: Update 35936: task edges-ner-ontonotes, batch 936 (35936): mcc: 0.8097, acc: 0.7193, precision: 0.8782, recall: 0.7647, f1: 0.8175, edges-ner-ontonotes_loss: 0.0533
09/16 10:17:48 AM: ***** Step 36000 / Validation 36 *****
09/16 10:17:48 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:17:48 AM: Validating...
09/16 10:17:54 AM: Evaluate: task edges-ner-ontonotes, batch 55 (157): mcc: 0.8503, acc: 0.7801, precision: 0.9156, recall: 0.8039, f1: 0.8562, edges-ner-ontonotes_loss: 0.0445
09/16 10:18:04 AM: Evaluate: task edges-ner-ontonotes, batch 125 (157): mcc: 0.8625, acc: 0.7915, precision: 0.9347, recall: 0.8088, f1: 0.8672, edges-ner-ontonotes_loss: 0.0408
09/16 10:18:10 AM: Updating LR scheduler:
09/16 10:18:10 AM: 	Best result seen so far for macro_avg: 0.872
09/16 10:18:10 AM: 	# validation passes without improvement: 2
09/16 10:18:10 AM: edges-ner-ontonotes_loss: training: 0.053322 validation: 0.039623
09/16 10:18:10 AM: macro_avg: validation: 0.869342
09/16 10:18:10 AM: micro_avg: validation: 0.000000
09/16 10:18:10 AM: edges-ner-ontonotes_mcc: training: 0.809384 validation: 0.864781
09/16 10:18:10 AM: edges-ner-ontonotes_acc: training: 0.718792 validation: 0.792842
09/16 10:18:10 AM: edges-ner-ontonotes_precision: training: 0.877912 validation: 0.937385
09/16 10:18:10 AM: edges-ner-ontonotes_recall: training: 0.764337 validation: 0.810510
09/16 10:18:10 AM: edges-ner-ontonotes_f1: training: 0.817197 validation: 0.869342
09/16 10:18:10 AM: Global learning rate: 2.5e-05
09/16 10:18:10 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:18:14 AM: Update 36060: task edges-ner-ontonotes, batch 60 (36060): mcc: 0.8008, acc: 0.7084, precision: 0.8677, recall: 0.7581, f1: 0.8092, edges-ner-ontonotes_loss: 0.0550
09/16 10:18:24 AM: Update 36165: task edges-ner-ontonotes, batch 165 (36165): mcc: 0.7985, acc: 0.7048, precision: 0.8680, recall: 0.7538, f1: 0.8068, edges-ner-ontonotes_loss: 0.0544
09/16 10:18:34 AM: Update 36285: task edges-ner-ontonotes, batch 285 (36285): mcc: 0.8037, acc: 0.7114, precision: 0.8729, recall: 0.7586, f1: 0.8117, edges-ner-ontonotes_loss: 0.0531
09/16 10:18:44 AM: Update 36413: task edges-ner-ontonotes, batch 413 (36413): mcc: 0.8054, acc: 0.7150, precision: 0.8745, recall: 0.7602, f1: 0.8134, edges-ner-ontonotes_loss: 0.0526
09/16 10:18:54 AM: Update 36517: task edges-ner-ontonotes, batch 517 (36517): mcc: 0.8112, acc: 0.7222, precision: 0.8792, recall: 0.7665, f1: 0.8190, edges-ner-ontonotes_loss: 0.0515
09/16 10:19:04 AM: Update 36641: task edges-ner-ontonotes, batch 641 (36641): mcc: 0.8172, acc: 0.7300, precision: 0.8826, recall: 0.7741, f1: 0.8248, edges-ner-ontonotes_loss: 0.0500
09/16 10:19:14 AM: Update 36744: task edges-ner-ontonotes, batch 744 (36744): mcc: 0.8206, acc: 0.7344, precision: 0.8848, recall: 0.7784, f1: 0.8282, edges-ner-ontonotes_loss: 0.0492
09/16 10:19:24 AM: Update 36866: task edges-ner-ontonotes, batch 866 (36866): mcc: 0.8219, acc: 0.7361, precision: 0.8858, recall: 0.7797, f1: 0.8294, edges-ner-ontonotes_loss: 0.0488
09/16 10:19:34 AM: Update 36992: task edges-ner-ontonotes, batch 992 (36992): mcc: 0.8228, acc: 0.7374, precision: 0.8861, recall: 0.7812, f1: 0.8304, edges-ner-ontonotes_loss: 0.0487
09/16 10:19:35 AM: ***** Step 37000 / Validation 37 *****
09/16 10:19:35 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:19:35 AM: Validating...
09/16 10:19:44 AM: Evaluate: task edges-ner-ontonotes, batch 79 (157): mcc: 0.8519, acc: 0.7818, precision: 0.9091, recall: 0.8127, f1: 0.8582, edges-ner-ontonotes_loss: 0.0459
09/16 10:19:54 AM: Evaluate: task edges-ner-ontonotes, batch 152 (157): mcc: 0.8665, acc: 0.7981, precision: 0.9272, recall: 0.8227, f1: 0.8718, edges-ner-ontonotes_loss: 0.0403
09/16 10:19:55 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:19:55 AM: Best result seen so far for macro.
09/16 10:19:55 AM: Updating LR scheduler:
09/16 10:19:55 AM: 	Best result seen so far for macro_avg: 0.872
09/16 10:19:55 AM: 	# validation passes without improvement: 3
09/16 10:19:55 AM: edges-ner-ontonotes_loss: training: 0.048669 validation: 0.040113
09/16 10:19:55 AM: macro_avg: validation: 0.872128
09/16 10:19:55 AM: micro_avg: validation: 0.000000
09/16 10:19:55 AM: edges-ner-ontonotes_mcc: training: 0.822935 validation: 0.866774
09/16 10:19:55 AM: edges-ner-ontonotes_acc: training: 0.737429 validation: 0.798529
09/16 10:19:55 AM: edges-ner-ontonotes_precision: training: 0.886259 validation: 0.927083
09/16 10:19:55 AM: edges-ner-ontonotes_recall: training: 0.781214 validation: 0.823324
09/16 10:19:55 AM: edges-ner-ontonotes_f1: training: 0.830428 validation: 0.872128
09/16 10:19:55 AM: Global learning rate: 2.5e-05
09/16 10:19:55 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:20:04 AM: Update 37099: task edges-ner-ontonotes, batch 99 (37099): mcc: 0.7945, acc: 0.7022, precision: 0.8718, recall: 0.7431, f1: 0.8023, edges-ner-ontonotes_loss: 0.0570
09/16 10:20:14 AM: Update 37226: task edges-ner-ontonotes, batch 226 (37226): mcc: 0.7855, acc: 0.6881, precision: 0.8649, recall: 0.7331, f1: 0.7936, edges-ner-ontonotes_loss: 0.0594
09/16 10:20:25 AM: Update 37345: task edges-ner-ontonotes, batch 345 (37345): mcc: 0.7845, acc: 0.6870, precision: 0.8641, recall: 0.7320, f1: 0.7926, edges-ner-ontonotes_loss: 0.0603
09/16 10:20:35 AM: Update 37500: task edges-ner-ontonotes, batch 500 (37500): mcc: 0.7868, acc: 0.6900, precision: 0.8638, recall: 0.7365, f1: 0.7951, edges-ner-ontonotes_loss: 0.0590
09/16 10:20:45 AM: Update 37645: task edges-ner-ontonotes, batch 645 (37645): mcc: 0.7884, acc: 0.6921, precision: 0.8648, recall: 0.7385, f1: 0.7966, edges-ner-ontonotes_loss: 0.0583
09/16 10:20:55 AM: Update 37757: task edges-ner-ontonotes, batch 757 (37757): mcc: 0.7901, acc: 0.6949, precision: 0.8651, recall: 0.7413, f1: 0.7984, edges-ner-ontonotes_loss: 0.0575
09/16 10:21:05 AM: Update 37885: task edges-ner-ontonotes, batch 885 (37885): mcc: 0.7924, acc: 0.6980, precision: 0.8667, recall: 0.7440, f1: 0.8007, edges-ner-ontonotes_loss: 0.0568
09/16 10:21:15 AM: Update 37989: task edges-ner-ontonotes, batch 989 (37989): mcc: 0.7946, acc: 0.7009, precision: 0.8681, recall: 0.7465, f1: 0.8027, edges-ner-ontonotes_loss: 0.0562
09/16 10:21:16 AM: ***** Step 38000 / Validation 38 *****
09/16 10:21:16 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:21:16 AM: Validating...
09/16 10:21:25 AM: Evaluate: task edges-ner-ontonotes, batch 78 (157): mcc: 0.8535, acc: 0.7868, precision: 0.9090, recall: 0.8158, f1: 0.8599, edges-ner-ontonotes_loss: 0.0453
09/16 10:21:35 AM: Evaluate: task edges-ner-ontonotes, batch 151 (157): mcc: 0.8667, acc: 0.7997, precision: 0.9259, recall: 0.8242, f1: 0.8721, edges-ner-ontonotes_loss: 0.0403
09/16 10:21:36 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:21:36 AM: Best result seen so far for macro.
09/16 10:21:36 AM: Updating LR scheduler:
09/16 10:21:36 AM: 	Best result seen so far for macro_avg: 0.873
09/16 10:21:36 AM: 	# validation passes without improvement: 0
09/16 10:21:36 AM: edges-ner-ontonotes_loss: training: 0.056093 validation: 0.040089
09/16 10:21:36 AM: macro_avg: validation: 0.872770
09/16 10:21:36 AM: micro_avg: validation: 0.000000
09/16 10:21:36 AM: edges-ner-ontonotes_mcc: training: 0.795029 validation: 0.867345
09/16 10:21:36 AM: edges-ner-ontonotes_acc: training: 0.701405 validation: 0.800804
09/16 10:21:36 AM: edges-ner-ontonotes_precision: training: 0.868485 validation: 0.926134
09/16 10:21:36 AM: edges-ner-ontonotes_recall: training: 0.747022 validation: 0.825220
09/16 10:21:36 AM: edges-ner-ontonotes_f1: training: 0.803188 validation: 0.872770
09/16 10:21:36 AM: Global learning rate: 2.5e-05
09/16 10:21:36 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:21:45 AM: Update 38111: task edges-ner-ontonotes, batch 111 (38111): mcc: 0.8393, acc: 0.7579, precision: 0.8986, recall: 0.7996, f1: 0.8462, edges-ner-ontonotes_loss: 0.0441
09/16 10:21:55 AM: Update 38227: task edges-ner-ontonotes, batch 227 (38227): mcc: 0.8372, acc: 0.7545, precision: 0.8994, recall: 0.7950, f1: 0.8440, edges-ner-ontonotes_loss: 0.0442
09/16 10:22:06 AM: Update 38329: task edges-ner-ontonotes, batch 329 (38329): mcc: 0.8376, acc: 0.7554, precision: 0.8985, recall: 0.7966, f1: 0.8445, edges-ner-ontonotes_loss: 0.0442
09/16 10:22:16 AM: Update 38455: task edges-ner-ontonotes, batch 455 (38455): mcc: 0.8364, acc: 0.7538, precision: 0.8972, recall: 0.7955, f1: 0.8433, edges-ner-ontonotes_loss: 0.0448
09/16 10:22:26 AM: Update 38576: task edges-ner-ontonotes, batch 576 (38576): mcc: 0.8348, acc: 0.7515, precision: 0.8956, recall: 0.7941, f1: 0.8418, edges-ner-ontonotes_loss: 0.0454
09/16 10:22:36 AM: Update 38685: task edges-ner-ontonotes, batch 685 (38685): mcc: 0.8259, acc: 0.7400, precision: 0.8902, recall: 0.7831, f1: 0.8332, edges-ner-ontonotes_loss: 0.0481
09/16 10:22:46 AM: Update 38811: task edges-ner-ontonotes, batch 811 (38811): mcc: 0.8205, acc: 0.7334, precision: 0.8867, recall: 0.7765, f1: 0.8279, edges-ner-ontonotes_loss: 0.0502
09/16 10:22:56 AM: Update 38920: task edges-ner-ontonotes, batch 920 (38920): mcc: 0.8173, acc: 0.7295, precision: 0.8839, recall: 0.7731, f1: 0.8248, edges-ner-ontonotes_loss: 0.0513
09/16 10:23:01 AM: ***** Step 39000 / Validation 39 *****
09/16 10:23:01 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:23:01 AM: Validating...
09/16 10:23:06 AM: Evaluate: task edges-ner-ontonotes, batch 39 (157): mcc: 0.8420, acc: 0.7705, precision: 0.9039, recall: 0.7995, f1: 0.8485, edges-ner-ontonotes_loss: 0.0473
09/16 10:23:16 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.8621, acc: 0.7911, precision: 0.9313, recall: 0.8111, f1: 0.8671, edges-ner-ontonotes_loss: 0.0412
09/16 10:23:22 AM: Updating LR scheduler:
09/16 10:23:22 AM: 	Best result seen so far for macro_avg: 0.873
09/16 10:23:22 AM: 	# validation passes without improvement: 1
09/16 10:23:22 AM: edges-ner-ontonotes_loss: training: 0.051670 validation: 0.039783
09/16 10:23:22 AM: macro_avg: validation: 0.869760
09/16 10:23:22 AM: micro_avg: validation: 0.000000
09/16 10:23:22 AM: edges-ner-ontonotes_mcc: training: 0.815720 validation: 0.865138
09/16 10:23:22 AM: edges-ner-ontonotes_acc: training: 0.727612 validation: 0.792463
09/16 10:23:22 AM: edges-ner-ontonotes_precision: training: 0.882737 validation: 0.936734
09/16 10:23:22 AM: edges-ner-ontonotes_recall: training: 0.771393 validation: 0.811723
09/16 10:23:22 AM: edges-ner-ontonotes_f1: training: 0.823317 validation: 0.869760
09/16 10:23:22 AM: Global learning rate: 2.5e-05
09/16 10:23:22 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:23:26 AM: Update 39070: task edges-ner-ontonotes, batch 70 (39070): mcc: 0.7988, acc: 0.7010, precision: 0.8697, recall: 0.7526, f1: 0.8069, edges-ner-ontonotes_loss: 0.0540
09/16 10:23:38 AM: Update 39214: task edges-ner-ontonotes, batch 214 (39214): mcc: 0.7980, acc: 0.7029, precision: 0.8684, recall: 0.7524, f1: 0.8062, edges-ner-ontonotes_loss: 0.0549
09/16 10:23:48 AM: Update 39318: task edges-ner-ontonotes, batch 318 (39318): mcc: 0.8010, acc: 0.7079, precision: 0.8723, recall: 0.7542, f1: 0.8090, edges-ner-ontonotes_loss: 0.0540
09/16 10:23:58 AM: Update 39442: task edges-ner-ontonotes, batch 442 (39442): mcc: 0.8020, acc: 0.7095, precision: 0.8724, recall: 0.7561, f1: 0.8101, edges-ner-ontonotes_loss: 0.0539
09/16 10:24:08 AM: Update 39547: task edges-ner-ontonotes, batch 547 (39547): mcc: 0.8045, acc: 0.7133, precision: 0.8741, recall: 0.7590, f1: 0.8125, edges-ner-ontonotes_loss: 0.0531
09/16 10:24:18 AM: Update 39673: task edges-ner-ontonotes, batch 673 (39673): mcc: 0.8115, acc: 0.7224, precision: 0.8787, recall: 0.7675, f1: 0.8193, edges-ner-ontonotes_loss: 0.0515
09/16 10:24:28 AM: Update 39794: task edges-ner-ontonotes, batch 794 (39794): mcc: 0.8165, acc: 0.7288, precision: 0.8825, recall: 0.7731, f1: 0.8242, edges-ner-ontonotes_loss: 0.0503
09/16 10:24:38 AM: Update 39903: task edges-ner-ontonotes, batch 903 (39903): mcc: 0.8188, acc: 0.7317, precision: 0.8840, recall: 0.7759, f1: 0.8264, edges-ner-ontonotes_loss: 0.0498
09/16 10:24:46 AM: ***** Step 40000 / Validation 40 *****
09/16 10:24:46 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:24:46 AM: Validating...
09/16 10:24:48 AM: Evaluate: task edges-ner-ontonotes, batch 23 (157): mcc: 0.7941, acc: 0.7202, precision: 0.8508, recall: 0.7614, f1: 0.8036, edges-ner-ontonotes_loss: 0.0605
09/16 10:24:58 AM: Evaluate: task edges-ner-ontonotes, batch 105 (157): mcc: 0.8595, acc: 0.7940, precision: 0.9140, recall: 0.8222, f1: 0.8656, edges-ner-ontonotes_loss: 0.0435
09/16 10:25:05 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:25:05 AM: Best result seen so far for macro.
09/16 10:25:05 AM: Updating LR scheduler:
09/16 10:25:05 AM: 	Best result seen so far for macro_avg: 0.874
09/16 10:25:05 AM: 	# validation passes without improvement: 0
09/16 10:25:05 AM: edges-ner-ontonotes_loss: training: 0.049490 validation: 0.040169
09/16 10:25:05 AM: macro_avg: validation: 0.874200
09/16 10:25:05 AM: micro_avg: validation: 0.000000
09/16 10:25:05 AM: edges-ner-ontonotes_mcc: training: 0.819750 validation: 0.868676
09/16 10:25:05 AM: edges-ner-ontonotes_acc: training: 0.732893 validation: 0.802699
09/16 10:25:05 AM: edges-ner-ontonotes_precision: training: 0.884616 validation: 0.924788
09/16 10:25:05 AM: edges-ner-ontonotes_recall: training: 0.776955 validation: 0.828860
09/16 10:25:05 AM: edges-ner-ontonotes_f1: training: 0.827298 validation: 0.874200
09/16 10:25:05 AM: Global learning rate: 2.5e-05
09/16 10:25:05 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:25:08 AM: Update 40032: task edges-ner-ontonotes, batch 32 (40032): mcc: 0.8208, acc: 0.7300, precision: 0.8831, recall: 0.7802, f1: 0.8285, edges-ner-ontonotes_loss: 0.0480
09/16 10:25:20 AM: Update 40153: task edges-ner-ontonotes, batch 153 (40153): mcc: 0.8263, acc: 0.7380, precision: 0.8892, recall: 0.7845, f1: 0.8336, edges-ner-ontonotes_loss: 0.0470
09/16 10:25:30 AM: Update 40275: task edges-ner-ontonotes, batch 275 (40275): mcc: 0.8037, acc: 0.7096, precision: 0.8764, recall: 0.7555, f1: 0.8115, edges-ner-ontonotes_loss: 0.0545
09/16 10:25:40 AM: Update 40404: task edges-ner-ontonotes, batch 404 (40404): mcc: 0.7967, acc: 0.7016, precision: 0.8706, recall: 0.7482, f1: 0.8048, edges-ner-ontonotes_loss: 0.0568
09/16 10:25:50 AM: Update 40515: task edges-ner-ontonotes, batch 515 (40515): mcc: 0.7962, acc: 0.7013, precision: 0.8695, recall: 0.7482, f1: 0.8043, edges-ner-ontonotes_loss: 0.0571
09/16 10:26:00 AM: Update 40654: task edges-ner-ontonotes, batch 654 (40654): mcc: 0.7946, acc: 0.6994, precision: 0.8679, recall: 0.7468, f1: 0.8028, edges-ner-ontonotes_loss: 0.0572
09/16 10:26:10 AM: Update 40781: task edges-ner-ontonotes, batch 781 (40781): mcc: 0.7959, acc: 0.7011, precision: 0.8685, recall: 0.7485, f1: 0.8041, edges-ner-ontonotes_loss: 0.0565
09/16 10:26:20 AM: Update 40906: task edges-ner-ontonotes, batch 906 (40906): mcc: 0.7974, acc: 0.7036, precision: 0.8696, recall: 0.7502, f1: 0.8055, edges-ner-ontonotes_loss: 0.0560
09/16 10:26:28 AM: ***** Step 41000 / Validation 41 *****
09/16 10:26:28 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:26:28 AM: Validating...
09/16 10:26:30 AM: Evaluate: task edges-ner-ontonotes, batch 22 (157): mcc: 0.8119, acc: 0.7356, precision: 0.8755, recall: 0.7711, f1: 0.8200, edges-ner-ontonotes_loss: 0.0499
09/16 10:26:40 AM: Evaluate: task edges-ner-ontonotes, batch 102 (157): mcc: 0.8614, acc: 0.7931, precision: 0.9260, recall: 0.8145, f1: 0.8667, edges-ner-ontonotes_loss: 0.0416
09/16 10:26:48 AM: Updating LR scheduler:
09/16 10:26:48 AM: 	Best result seen so far for macro_avg: 0.874
09/16 10:26:48 AM: 	# validation passes without improvement: 1
09/16 10:26:48 AM: edges-ner-ontonotes_loss: training: 0.055800 validation: 0.039284
09/16 10:26:48 AM: macro_avg: validation: 0.871857
09/16 10:26:48 AM: micro_avg: validation: 0.000000
09/16 10:26:48 AM: edges-ner-ontonotes_mcc: training: 0.797320 validation: 0.867085
09/16 10:26:48 AM: edges-ner-ontonotes_acc: training: 0.704007 validation: 0.796861
09/16 10:26:48 AM: edges-ner-ontonotes_precision: training: 0.869002 validation: 0.935366
09/16 10:26:48 AM: edges-ner-ontonotes_recall: training: 0.750664 validation: 0.816424
09/16 10:26:48 AM: edges-ner-ontonotes_f1: training: 0.805510 validation: 0.871857
09/16 10:26:48 AM: Global learning rate: 2.5e-05
09/16 10:26:48 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:26:50 AM: Update 41030: task edges-ner-ontonotes, batch 30 (41030): mcc: 0.8241, acc: 0.7474, precision: 0.8890, recall: 0.7808, f1: 0.8314, edges-ner-ontonotes_loss: 0.0482
09/16 10:27:00 AM: Update 41131: task edges-ner-ontonotes, batch 131 (41131): mcc: 0.8216, acc: 0.7372, precision: 0.8843, recall: 0.7807, f1: 0.8292, edges-ner-ontonotes_loss: 0.0498
09/16 10:27:10 AM: Update 41253: task edges-ner-ontonotes, batch 253 (41253): mcc: 0.8307, acc: 0.7471, precision: 0.8924, recall: 0.7896, f1: 0.8379, edges-ner-ontonotes_loss: 0.0470
09/16 10:27:20 AM: Update 41376: task edges-ner-ontonotes, batch 376 (41376): mcc: 0.8322, acc: 0.7485, precision: 0.8938, recall: 0.7911, f1: 0.8393, edges-ner-ontonotes_loss: 0.0462
09/16 10:27:30 AM: Update 41477: task edges-ner-ontonotes, batch 477 (41477): mcc: 0.8323, acc: 0.7486, precision: 0.8939, recall: 0.7911, f1: 0.8394, edges-ner-ontonotes_loss: 0.0463
09/16 10:27:40 AM: Update 41597: task edges-ner-ontonotes, batch 597 (41597): mcc: 0.8314, acc: 0.7476, precision: 0.8922, recall: 0.7910, f1: 0.8386, edges-ner-ontonotes_loss: 0.0465
09/16 10:27:51 AM: Update 41709: task edges-ner-ontonotes, batch 709 (41709): mcc: 0.8304, acc: 0.7458, precision: 0.8919, recall: 0.7895, f1: 0.8376, edges-ner-ontonotes_loss: 0.0466
09/16 10:28:01 AM: Update 41829: task edges-ner-ontonotes, batch 829 (41829): mcc: 0.8218, acc: 0.7349, precision: 0.8866, recall: 0.7789, f1: 0.8293, edges-ner-ontonotes_loss: 0.0491
09/16 10:28:11 AM: Update 41958: task edges-ner-ontonotes, batch 958 (41958): mcc: 0.8169, acc: 0.7290, precision: 0.8833, recall: 0.7731, f1: 0.8245, edges-ner-ontonotes_loss: 0.0509
09/16 10:28:14 AM: ***** Step 42000 / Validation 42 *****
09/16 10:28:14 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:28:14 AM: Validating...
09/16 10:28:21 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.8544, acc: 0.7879, precision: 0.9118, recall: 0.8149, f1: 0.8606, edges-ner-ontonotes_loss: 0.0440
09/16 10:28:31 AM: Evaluate: task edges-ner-ontonotes, batch 133 (157): mcc: 0.8659, acc: 0.7968, precision: 0.9332, recall: 0.8164, f1: 0.8709, edges-ner-ontonotes_loss: 0.0403
09/16 10:28:34 AM: Updating LR scheduler:
09/16 10:28:34 AM: 	Best result seen so far for macro_avg: 0.874
09/16 10:28:34 AM: 	# validation passes without improvement: 2
09/16 10:28:34 AM: edges-ner-ontonotes_loss: training: 0.051380 validation: 0.039797
09/16 10:28:34 AM: macro_avg: validation: 0.871274
09/16 10:28:34 AM: micro_avg: validation: 0.000000
09/16 10:28:34 AM: edges-ner-ontonotes_mcc: training: 0.815919 validation: 0.866380
09/16 10:28:34 AM: edges-ner-ontonotes_acc: training: 0.727825 validation: 0.796482
09/16 10:28:34 AM: edges-ner-ontonotes_precision: training: 0.882456 validation: 0.933530
09/16 10:28:34 AM: edges-ner-ontonotes_recall: training: 0.772002 validation: 0.816803
09/16 10:28:34 AM: edges-ner-ontonotes_f1: training: 0.823542 validation: 0.871274
09/16 10:28:34 AM: Global learning rate: 2.5e-05
09/16 10:28:34 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:28:41 AM: Update 42078: task edges-ner-ontonotes, batch 78 (42078): mcc: 0.7788, acc: 0.6841, precision: 0.8519, recall: 0.7327, f1: 0.7878, edges-ner-ontonotes_loss: 0.0592
09/16 10:28:52 AM: Update 42227: task edges-ner-ontonotes, batch 227 (42227): mcc: 0.7883, acc: 0.6945, precision: 0.8595, recall: 0.7430, f1: 0.7970, edges-ner-ontonotes_loss: 0.0567
09/16 10:29:02 AM: Update 42352: task edges-ner-ontonotes, batch 352 (42352): mcc: 0.7938, acc: 0.7013, precision: 0.8648, recall: 0.7482, f1: 0.8023, edges-ner-ontonotes_loss: 0.0555
09/16 10:29:12 AM: Update 42483: task edges-ner-ontonotes, batch 483 (42483): mcc: 0.7985, acc: 0.7080, precision: 0.8684, recall: 0.7533, f1: 0.8068, edges-ner-ontonotes_loss: 0.0545
09/16 10:29:22 AM: Update 42608: task edges-ner-ontonotes, batch 608 (42608): mcc: 0.7991, acc: 0.7084, precision: 0.8685, recall: 0.7543, f1: 0.8074, edges-ner-ontonotes_loss: 0.0544
09/16 10:29:32 AM: Update 42716: task edges-ner-ontonotes, batch 716 (42716): mcc: 0.8040, acc: 0.7139, precision: 0.8727, recall: 0.7593, f1: 0.8121, edges-ner-ontonotes_loss: 0.0532
09/16 10:29:42 AM: Update 42838: task edges-ner-ontonotes, batch 838 (42838): mcc: 0.8090, acc: 0.7203, precision: 0.8762, recall: 0.7652, f1: 0.8169, edges-ner-ontonotes_loss: 0.0520
09/16 10:29:53 AM: Update 42952: task edges-ner-ontonotes, batch 952 (42952): mcc: 0.8135, acc: 0.7260, precision: 0.8795, recall: 0.7704, f1: 0.8213, edges-ner-ontonotes_loss: 0.0510
09/16 10:29:57 AM: ***** Step 43000 / Validation 43 *****
09/16 10:30:00 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:30:00 AM: Validating...
09/16 10:30:03 AM: Evaluate: task edges-ner-ontonotes, batch 31 (157): mcc: 0.8218, acc: 0.7516, precision: 0.8817, recall: 0.7833, f1: 0.8296, edges-ner-ontonotes_loss: 0.0532
09/16 10:30:15 AM: Evaluate: task edges-ner-ontonotes, batch 110 (157): mcc: 0.8626, acc: 0.7968, precision: 0.9202, recall: 0.8221, f1: 0.8684, edges-ner-ontonotes_loss: 0.0426
09/16 10:30:21 AM: Updating LR scheduler:
09/16 10:30:21 AM: 	Best result seen so far for macro_avg: 0.874
09/16 10:30:21 AM: 	# validation passes without improvement: 3
09/16 10:30:21 AM: edges-ner-ontonotes_loss: training: 0.050860 validation: 0.040002
09/16 10:30:21 AM: macro_avg: validation: 0.873606
09/16 10:30:21 AM: micro_avg: validation: 0.000000
09/16 10:30:21 AM: edges-ner-ontonotes_mcc: training: 0.813674 validation: 0.868275
09/16 10:30:21 AM: edges-ner-ontonotes_acc: training: 0.726026 validation: 0.801259
09/16 10:30:21 AM: edges-ner-ontonotes_precision: training: 0.879993 validation: 0.927731
09/16 10:30:21 AM: edges-ner-ontonotes_recall: training: 0.770182 validation: 0.825447
09/16 10:30:21 AM: edges-ner-ontonotes_f1: training: 0.821434 validation: 0.873606
09/16 10:30:21 AM: Global learning rate: 2.5e-05
09/16 10:30:21 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:30:25 AM: Update 43042: task edges-ner-ontonotes, batch 42 (43042): mcc: 0.8183, acc: 0.7338, precision: 0.8793, recall: 0.7792, f1: 0.8262, edges-ner-ontonotes_loss: 0.0482
09/16 10:30:35 AM: Update 43171: task edges-ner-ontonotes, batch 171 (43171): mcc: 0.8307, acc: 0.7493, precision: 0.8896, recall: 0.7922, f1: 0.8381, edges-ner-ontonotes_loss: 0.0469
09/16 10:30:45 AM: Update 43274: task edges-ner-ontonotes, batch 274 (43274): mcc: 0.8279, acc: 0.7428, precision: 0.8904, recall: 0.7864, f1: 0.8352, edges-ner-ontonotes_loss: 0.0471
09/16 10:30:55 AM: Update 43401: task edges-ner-ontonotes, batch 401 (43401): mcc: 0.8123, acc: 0.7224, precision: 0.8795, recall: 0.7681, f1: 0.8200, edges-ner-ontonotes_loss: 0.0521
09/16 10:31:05 AM: Update 43534: task edges-ner-ontonotes, batch 534 (43534): mcc: 0.8052, acc: 0.7142, precision: 0.8751, recall: 0.7593, f1: 0.8131, edges-ner-ontonotes_loss: 0.0545
09/16 10:31:15 AM: Update 43648: task edges-ner-ontonotes, batch 648 (43648): mcc: 0.8022, acc: 0.7101, precision: 0.8726, recall: 0.7563, f1: 0.8103, edges-ner-ontonotes_loss: 0.0553
09/16 10:31:25 AM: Update 43801: task edges-ner-ontonotes, batch 801 (43801): mcc: 0.8013, acc: 0.7088, precision: 0.8718, recall: 0.7553, f1: 0.8094, edges-ner-ontonotes_loss: 0.0553
09/16 10:31:35 AM: Update 43920: task edges-ner-ontonotes, batch 920 (43920): mcc: 0.8007, acc: 0.7079, precision: 0.8719, recall: 0.7541, f1: 0.8088, edges-ner-ontonotes_loss: 0.0552
09/16 10:31:41 AM: ***** Step 44000 / Validation 44 *****
09/16 10:31:41 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:31:41 AM: Validating...
09/16 10:31:45 AM: Evaluate: task edges-ner-ontonotes, batch 39 (157): mcc: 0.8403, acc: 0.7697, precision: 0.9036, recall: 0.7967, f1: 0.8468, edges-ner-ontonotes_loss: 0.0474
09/16 10:31:55 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.8634, acc: 0.7946, precision: 0.9321, recall: 0.8127, f1: 0.8684, edges-ner-ontonotes_loss: 0.0411
09/16 10:32:01 AM: Updating LR scheduler:
09/16 10:32:01 AM: 	Best result seen so far for macro_avg: 0.874
09/16 10:32:01 AM: 	# validation passes without improvement: 0
09/16 10:32:01 AM: edges-ner-ontonotes_loss: training: 0.054944 validation: 0.039414
09/16 10:32:01 AM: macro_avg: validation: 0.871572
09/16 10:32:01 AM: micro_avg: validation: 0.000000
09/16 10:32:01 AM: edges-ner-ontonotes_mcc: training: 0.801011 validation: 0.866935
09/16 10:32:01 AM: edges-ner-ontonotes_acc: training: 0.708377 validation: 0.797240
09/16 10:32:01 AM: edges-ner-ontonotes_precision: training: 0.871861 validation: 0.937107
09/16 10:32:01 AM: edges-ner-ontonotes_recall: training: 0.754727 validation: 0.814604
09/16 10:32:01 AM: edges-ner-ontonotes_f1: training: 0.809076 validation: 0.871572
09/16 10:32:01 AM: Global learning rate: 1.25e-05
09/16 10:32:01 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:32:05 AM: Update 44023: task edges-ner-ontonotes, batch 23 (44023): mcc: 0.8084, acc: 0.7184, precision: 0.8758, recall: 0.7644, f1: 0.8163, edges-ner-ontonotes_loss: 0.0506
09/16 10:32:15 AM: Update 44153: task edges-ner-ontonotes, batch 153 (44153): mcc: 0.8116, acc: 0.7227, precision: 0.8781, recall: 0.7682, f1: 0.8195, edges-ner-ontonotes_loss: 0.0509
09/16 10:32:25 AM: Update 44259: task edges-ner-ontonotes, batch 259 (44259): mcc: 0.8138, acc: 0.7251, precision: 0.8801, recall: 0.7703, f1: 0.8216, edges-ner-ontonotes_loss: 0.0500
09/16 10:32:36 AM: Update 44377: task edges-ner-ontonotes, batch 377 (44377): mcc: 0.8188, acc: 0.7307, precision: 0.8837, recall: 0.7761, f1: 0.8264, edges-ner-ontonotes_loss: 0.0489
09/16 10:32:46 AM: Update 44499: task edges-ner-ontonotes, batch 499 (44499): mcc: 0.8238, acc: 0.7374, precision: 0.8870, recall: 0.7822, f1: 0.8313, edges-ner-ontonotes_loss: 0.0477
09/16 10:32:56 AM: Update 44603: task edges-ner-ontonotes, batch 603 (44603): mcc: 0.8240, acc: 0.7375, precision: 0.8869, recall: 0.7826, f1: 0.8315, edges-ner-ontonotes_loss: 0.0478
09/16 10:33:06 AM: Update 44729: task edges-ner-ontonotes, batch 729 (44729): mcc: 0.8252, acc: 0.7394, precision: 0.8874, recall: 0.7843, f1: 0.8327, edges-ner-ontonotes_loss: 0.0476
09/16 10:33:16 AM: Update 44827: task edges-ner-ontonotes, batch 827 (44827): mcc: 0.8245, acc: 0.7379, precision: 0.8875, recall: 0.7828, f1: 0.8319, edges-ner-ontonotes_loss: 0.0476
09/16 10:33:26 AM: Update 44948: task edges-ner-ontonotes, batch 948 (44948): mcc: 0.8185, acc: 0.7302, precision: 0.8840, recall: 0.7753, f1: 0.8261, edges-ner-ontonotes_loss: 0.0495
09/16 10:33:30 AM: ***** Step 45000 / Validation 45 *****
09/16 10:33:30 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:33:30 AM: Validating...
09/16 10:33:36 AM: Evaluate: task edges-ner-ontonotes, batch 54 (157): mcc: 0.8470, acc: 0.7757, precision: 0.9083, recall: 0.8047, f1: 0.8534, edges-ner-ontonotes_loss: 0.0452
09/16 10:33:46 AM: Evaluate: task edges-ner-ontonotes, batch 125 (157): mcc: 0.8616, acc: 0.7906, precision: 0.9312, recall: 0.8104, f1: 0.8666, edges-ner-ontonotes_loss: 0.0409
09/16 10:33:50 AM: Updating LR scheduler:
09/16 10:33:50 AM: 	Best result seen so far for macro_avg: 0.874
09/16 10:33:50 AM: 	# validation passes without improvement: 1
09/16 10:33:50 AM: edges-ner-ontonotes_loss: training: 0.050143 validation: 0.039715
09/16 10:33:50 AM: macro_avg: validation: 0.869096
09/16 10:33:50 AM: micro_avg: validation: 0.000000
09/16 10:33:50 AM: edges-ner-ontonotes_mcc: training: 0.816595 validation: 0.864268
09/16 10:33:50 AM: edges-ner-ontonotes_acc: training: 0.727738 validation: 0.792539
09/16 10:33:50 AM: edges-ner-ontonotes_precision: training: 0.882666 validation: 0.933792
09/16 10:33:50 AM: edges-ner-ontonotes_recall: training: 0.773032 validation: 0.812784
09/16 10:33:50 AM: edges-ner-ontonotes_f1: training: 0.824219 validation: 0.869096
09/16 10:33:50 AM: Global learning rate: 1.25e-05
09/16 10:33:50 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:33:56 AM: Update 45083: task edges-ner-ontonotes, batch 83 (45083): mcc: 0.7881, acc: 0.6906, precision: 0.8653, recall: 0.7374, f1: 0.7962, edges-ner-ontonotes_loss: 0.0600
09/16 10:34:06 AM: Update 45202: task edges-ner-ontonotes, batch 202 (45202): mcc: 0.7840, acc: 0.6879, precision: 0.8582, recall: 0.7365, f1: 0.7927, edges-ner-ontonotes_loss: 0.0602
09/16 10:34:16 AM: Update 45355: task edges-ner-ontonotes, batch 355 (45355): mcc: 0.7894, acc: 0.6937, precision: 0.8620, recall: 0.7428, f1: 0.7980, edges-ner-ontonotes_loss: 0.0582
09/16 10:34:26 AM: Update 45471: task edges-ner-ontonotes, batch 471 (45471): mcc: 0.7911, acc: 0.6962, precision: 0.8650, recall: 0.7431, f1: 0.7994, edges-ner-ontonotes_loss: 0.0573
09/16 10:34:36 AM: Update 45593: task edges-ner-ontonotes, batch 593 (45593): mcc: 0.7950, acc: 0.7020, precision: 0.8670, recall: 0.7484, f1: 0.8033, edges-ner-ontonotes_loss: 0.0564
09/16 10:34:46 AM: Update 45723: task edges-ner-ontonotes, batch 723 (45723): mcc: 0.7983, acc: 0.7063, precision: 0.8690, recall: 0.7523, f1: 0.8065, edges-ner-ontonotes_loss: 0.0552
09/16 10:34:56 AM: Update 45824: task edges-ner-ontonotes, batch 824 (45824): mcc: 0.8022, acc: 0.7109, precision: 0.8722, recall: 0.7565, f1: 0.8102, edges-ner-ontonotes_loss: 0.0542
09/16 10:35:06 AM: Update 45947: task edges-ner-ontonotes, batch 947 (45947): mcc: 0.8078, acc: 0.7180, precision: 0.8763, recall: 0.7630, f1: 0.8157, edges-ner-ontonotes_loss: 0.0530
09/16 10:35:11 AM: ***** Step 46000 / Validation 46 *****
09/16 10:35:11 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:35:11 AM: Validating...
09/16 10:35:16 AM: Evaluate: task edges-ner-ontonotes, batch 51 (157): mcc: 0.8395, acc: 0.7707, precision: 0.9026, recall: 0.7964, f1: 0.8462, edges-ner-ontonotes_loss: 0.0485
09/16 10:35:26 AM: Evaluate: task edges-ner-ontonotes, batch 121 (157): mcc: 0.8643, acc: 0.7971, precision: 0.9284, recall: 0.8176, f1: 0.8695, edges-ner-ontonotes_loss: 0.0418
09/16 10:35:31 AM: Updating LR scheduler:
09/16 10:35:31 AM: 	Best result seen so far for macro_avg: 0.874
09/16 10:35:31 AM: 	# validation passes without improvement: 2
09/16 10:35:31 AM: edges-ner-ontonotes_loss: training: 0.052694 validation: 0.039959
09/16 10:35:31 AM: macro_avg: validation: 0.873213
09/16 10:35:31 AM: micro_avg: validation: 0.000000
09/16 10:35:31 AM: edges-ner-ontonotes_mcc: training: 0.809226 validation: 0.868100
09/16 10:35:31 AM: edges-ner-ontonotes_acc: training: 0.719524 validation: 0.800804
09/16 10:35:31 AM: edges-ner-ontonotes_precision: training: 0.877263 validation: 0.930895
09/16 10:35:31 AM: edges-ner-ontonotes_recall: training: 0.764637 validation: 0.822263
09/16 10:35:31 AM: edges-ner-ontonotes_f1: training: 0.817087 validation: 0.873213
09/16 10:35:31 AM: Global learning rate: 1.25e-05
09/16 10:35:31 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:35:37 AM: Update 46064: task edges-ner-ontonotes, batch 64 (46064): mcc: 0.8403, acc: 0.7603, precision: 0.8985, recall: 0.8014, f1: 0.8472, edges-ner-ontonotes_loss: 0.0439
09/16 10:35:47 AM: Update 46189: task edges-ner-ontonotes, batch 189 (46189): mcc: 0.8356, acc: 0.7542, precision: 0.8939, recall: 0.7971, f1: 0.8427, edges-ner-ontonotes_loss: 0.0458
09/16 10:35:57 AM: Update 46314: task edges-ner-ontonotes, batch 314 (46314): mcc: 0.8348, acc: 0.7530, precision: 0.8928, recall: 0.7968, f1: 0.8421, edges-ner-ontonotes_loss: 0.0461
09/16 10:36:07 AM: Update 46418: task edges-ner-ontonotes, batch 418 (46418): mcc: 0.8250, acc: 0.7402, precision: 0.8863, recall: 0.7849, f1: 0.8326, edges-ner-ontonotes_loss: 0.0480
09/16 10:36:17 AM: Update 46541: task edges-ner-ontonotes, batch 541 (46541): mcc: 0.8156, acc: 0.7275, precision: 0.8814, recall: 0.7724, f1: 0.8233, edges-ner-ontonotes_loss: 0.0511
09/16 10:36:27 AM: Update 46675: task edges-ner-ontonotes, batch 675 (46675): mcc: 0.8093, acc: 0.7196, precision: 0.8769, recall: 0.7651, f1: 0.8172, edges-ner-ontonotes_loss: 0.0533
09/16 10:36:37 AM: Update 46804: task edges-ner-ontonotes, batch 804 (46804): mcc: 0.8074, acc: 0.7168, precision: 0.8756, recall: 0.7629, f1: 0.8153, edges-ner-ontonotes_loss: 0.0538
09/16 10:36:47 AM: Update 46957: task edges-ner-ontonotes, batch 957 (46957): mcc: 0.8061, acc: 0.7151, precision: 0.8748, recall: 0.7612, f1: 0.8141, edges-ner-ontonotes_loss: 0.0539
09/16 10:36:52 AM: ***** Step 47000 / Validation 47 *****
09/16 10:36:52 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:36:52 AM: Validating...
09/16 10:36:57 AM: Evaluate: task edges-ner-ontonotes, batch 50 (157): mcc: 0.8452, acc: 0.7717, precision: 0.9121, recall: 0.7980, f1: 0.8512, edges-ner-ontonotes_loss: 0.0454
09/16 10:37:07 AM: Evaluate: task edges-ner-ontonotes, batch 121 (157): mcc: 0.8636, acc: 0.7922, precision: 0.9351, recall: 0.8104, f1: 0.8683, edges-ner-ontonotes_loss: 0.0405
09/16 10:37:12 AM: Updating LR scheduler:
09/16 10:37:12 AM: 	Best result seen so far for macro_avg: 0.874
09/16 10:37:12 AM: 	# validation passes without improvement: 3
09/16 10:37:12 AM: edges-ner-ontonotes_loss: training: 0.053981 validation: 0.039456
09/16 10:37:12 AM: macro_avg: validation: 0.869017
09/16 10:37:12 AM: micro_avg: validation: 0.000000
09/16 10:37:12 AM: edges-ner-ontonotes_mcc: training: 0.804888 validation: 0.864515
09/16 10:37:12 AM: edges-ner-ontonotes_acc: training: 0.713746 validation: 0.791250
09/16 10:37:12 AM: edges-ner-ontonotes_precision: training: 0.874105 validation: 0.938049
09/16 10:37:12 AM: edges-ner-ontonotes_recall: training: 0.759677 validation: 0.809448
09/16 10:37:12 AM: edges-ner-ontonotes_f1: training: 0.812884 validation: 0.869017
09/16 10:37:12 AM: Global learning rate: 1.25e-05
09/16 10:37:12 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:37:18 AM: Update 47075: task edges-ner-ontonotes, batch 75 (47075): mcc: 0.8187, acc: 0.7315, precision: 0.8856, recall: 0.7741, f1: 0.8261, edges-ner-ontonotes_loss: 0.0500
09/16 10:37:28 AM: Update 47198: task edges-ner-ontonotes, batch 198 (47198): mcc: 0.8104, acc: 0.7207, precision: 0.8784, recall: 0.7658, f1: 0.8182, edges-ner-ontonotes_loss: 0.0519
09/16 10:37:38 AM: Update 47307: task edges-ner-ontonotes, batch 307 (47307): mcc: 0.8092, acc: 0.7199, precision: 0.8776, recall: 0.7642, f1: 0.8170, edges-ner-ontonotes_loss: 0.0519
09/16 10:37:48 AM: Update 47432: task edges-ner-ontonotes, batch 432 (47432): mcc: 0.8160, acc: 0.7286, precision: 0.8818, recall: 0.7727, f1: 0.8236, edges-ner-ontonotes_loss: 0.0502
09/16 10:37:58 AM: Update 47550: task edges-ner-ontonotes, batch 550 (47550): mcc: 0.8200, acc: 0.7335, precision: 0.8846, recall: 0.7774, f1: 0.8275, edges-ner-ontonotes_loss: 0.0491
09/16 10:38:08 AM: Update 47660: task edges-ner-ontonotes, batch 660 (47660): mcc: 0.8219, acc: 0.7356, precision: 0.8862, recall: 0.7795, f1: 0.8294, edges-ner-ontonotes_loss: 0.0485
09/16 10:38:18 AM: Update 47783: task edges-ner-ontonotes, batch 783 (47783): mcc: 0.8233, acc: 0.7369, precision: 0.8876, recall: 0.7807, f1: 0.8307, edges-ner-ontonotes_loss: 0.0484
09/16 10:38:28 AM: Update 47912: task edges-ner-ontonotes, batch 912 (47912): mcc: 0.8251, acc: 0.7394, precision: 0.8884, recall: 0.7832, f1: 0.8325, edges-ner-ontonotes_loss: 0.0479
09/16 10:38:37 AM: ***** Step 48000 / Validation 48 *****
09/16 10:38:37 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:38:37 AM: Validating...
09/16 10:38:38 AM: Evaluate: task edges-ner-ontonotes, batch 9 (157): mcc: 0.7662, acc: 0.6854, precision: 0.8340, recall: 0.7262, f1: 0.7764, edges-ner-ontonotes_loss: 0.0599
09/16 10:38:48 AM: Evaluate: task edges-ner-ontonotes, batch 92 (157): mcc: 0.8600, acc: 0.7914, precision: 0.9223, recall: 0.8154, f1: 0.8656, edges-ner-ontonotes_loss: 0.0425
09/16 10:38:58 AM: Updating LR scheduler:
09/16 10:38:58 AM: 	Best result seen so far for macro_avg: 0.874
09/16 10:38:58 AM: 	# validation passes without improvement: 0
09/16 10:38:58 AM: edges-ner-ontonotes_loss: training: 0.048974 validation: 0.039518
09/16 10:38:58 AM: macro_avg: validation: 0.871023
09/16 10:38:58 AM: micro_avg: validation: 0.000000
09/16 10:38:58 AM: edges-ner-ontonotes_mcc: training: 0.821132 validation: 0.866193
09/16 10:38:58 AM: edges-ner-ontonotes_acc: training: 0.734247 validation: 0.795799
09/16 10:38:58 AM: edges-ner-ontonotes_precision: training: 0.886240 validation: 0.934341
09/16 10:38:58 AM: edges-ner-ontonotes_recall: training: 0.777978 validation: 0.815742
09/16 10:38:58 AM: edges-ner-ontonotes_f1: training: 0.828588 validation: 0.871023
09/16 10:38:58 AM: Global learning rate: 6.25e-06
09/16 10:38:58 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:38:58 AM: Update 48009: task edges-ner-ontonotes, batch 9 (48009): mcc: 0.7498, acc: 0.6519, precision: 0.8266, recall: 0.7034, f1: 0.7601, edges-ner-ontonotes_loss: 0.0708
09/16 10:39:08 AM: Update 48135: task edges-ner-ontonotes, batch 135 (48135): mcc: 0.7782, acc: 0.6790, precision: 0.8593, recall: 0.7252, f1: 0.7865, edges-ner-ontonotes_loss: 0.0633
09/16 10:39:18 AM: Update 48242: task edges-ner-ontonotes, batch 242 (48242): mcc: 0.7799, acc: 0.6807, precision: 0.8597, recall: 0.7278, f1: 0.7883, edges-ner-ontonotes_loss: 0.0622
09/16 10:39:28 AM: Update 48393: task edges-ner-ontonotes, batch 393 (48393): mcc: 0.7853, acc: 0.6884, precision: 0.8615, recall: 0.7359, f1: 0.7938, edges-ner-ontonotes_loss: 0.0595
09/16 10:39:39 AM: Update 48546: task edges-ner-ontonotes, batch 546 (48546): mcc: 0.7879, acc: 0.6906, precision: 0.8635, recall: 0.7387, f1: 0.7963, edges-ner-ontonotes_loss: 0.0584
09/16 10:39:49 AM: Update 48656: task edges-ner-ontonotes, batch 656 (48656): mcc: 0.7910, acc: 0.6951, precision: 0.8656, recall: 0.7423, f1: 0.7992, edges-ner-ontonotes_loss: 0.0573
09/16 10:39:59 AM: Update 48782: task edges-ner-ontonotes, batch 782 (48782): mcc: 0.7937, acc: 0.6987, precision: 0.8670, recall: 0.7460, f1: 0.8020, edges-ner-ontonotes_loss: 0.0565
09/16 10:40:09 AM: Update 48884: task edges-ner-ontonotes, batch 884 (48884): mcc: 0.7955, acc: 0.7010, precision: 0.8690, recall: 0.7474, f1: 0.8036, edges-ner-ontonotes_loss: 0.0560
09/16 10:40:18 AM: ***** Step 49000 / Validation 49 *****
09/16 10:40:18 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:40:18 AM: Validating...
09/16 10:40:19 AM: Evaluate: task edges-ner-ontonotes, batch 10 (157): mcc: 0.7729, acc: 0.6972, precision: 0.8450, recall: 0.7283, f1: 0.7823, edges-ner-ontonotes_loss: 0.0590
09/16 10:40:29 AM: Evaluate: task edges-ner-ontonotes, batch 95 (157): mcc: 0.8617, acc: 0.7966, precision: 0.9170, recall: 0.8234, f1: 0.8677, edges-ner-ontonotes_loss: 0.0428
09/16 10:40:37 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:40:37 AM: Best result seen so far for macro.
09/16 10:40:37 AM: Updating LR scheduler:
09/16 10:40:37 AM: 	Best result seen so far for macro_avg: 0.875
09/16 10:40:37 AM: 	# validation passes without improvement: 0
09/16 10:40:37 AM: edges-ner-ontonotes_loss: training: 0.054694 validation: 0.039524
09/16 10:40:37 AM: macro_avg: validation: 0.874599
09/16 10:40:37 AM: micro_avg: validation: 0.000000
09/16 10:40:37 AM: edges-ner-ontonotes_mcc: training: 0.800579 validation: 0.869309
09/16 10:40:37 AM: edges-ner-ontonotes_acc: training: 0.707255 validation: 0.803230
09/16 10:40:37 AM: edges-ner-ontonotes_precision: training: 0.872445 validation: 0.928535
09/16 10:40:37 AM: edges-ner-ontonotes_recall: training: 0.753431 validation: 0.826585
09/16 10:40:37 AM: edges-ner-ontonotes_f1: training: 0.808582 validation: 0.874599
09/16 10:40:37 AM: Global learning rate: 6.25e-06
09/16 10:40:37 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:40:39 AM: Update 49016: task edges-ner-ontonotes, batch 16 (49016): mcc: 0.8515, acc: 0.7748, precision: 0.9072, recall: 0.8139, f1: 0.8580, edges-ner-ontonotes_loss: 0.0409
09/16 10:40:49 AM: Update 49140: task edges-ner-ontonotes, batch 140 (49140): mcc: 0.8423, acc: 0.7612, precision: 0.9002, recall: 0.8036, f1: 0.8491, edges-ner-ontonotes_loss: 0.0430
09/16 10:40:59 AM: Update 49241: task edges-ner-ontonotes, batch 241 (49241): mcc: 0.8367, acc: 0.7542, precision: 0.8955, recall: 0.7977, f1: 0.8438, edges-ner-ontonotes_loss: 0.0445
09/16 10:41:09 AM: Update 49371: task edges-ner-ontonotes, batch 371 (49371): mcc: 0.8362, acc: 0.7538, precision: 0.8959, recall: 0.7965, f1: 0.8433, edges-ner-ontonotes_loss: 0.0453
09/16 10:41:19 AM: Update 49489: task edges-ner-ontonotes, batch 489 (49489): mcc: 0.8339, acc: 0.7501, precision: 0.8941, recall: 0.7939, f1: 0.8410, edges-ner-ontonotes_loss: 0.0459
09/16 10:41:29 AM: Update 49615: task edges-ner-ontonotes, batch 615 (49615): mcc: 0.8216, acc: 0.7341, precision: 0.8868, recall: 0.7783, f1: 0.8290, edges-ner-ontonotes_loss: 0.0497
09/16 10:41:39 AM: Update 49743: task edges-ner-ontonotes, batch 743 (49743): mcc: 0.8143, acc: 0.7253, precision: 0.8819, recall: 0.7697, f1: 0.8220, edges-ner-ontonotes_loss: 0.0522
09/16 10:41:49 AM: Update 49868: task edges-ner-ontonotes, batch 868 (49868): mcc: 0.8124, acc: 0.7229, precision: 0.8803, recall: 0.7676, f1: 0.8201, edges-ner-ontonotes_loss: 0.0528
09/16 10:41:58 AM: ***** Step 50000 / Validation 50 *****
09/16 10:41:58 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:41:58 AM: Validating...
09/16 10:42:00 AM: Evaluate: task edges-ner-ontonotes, batch 15 (157): mcc: 0.8037, acc: 0.7247, precision: 0.8762, recall: 0.7556, f1: 0.8115, edges-ner-ontonotes_loss: 0.0526
09/16 10:42:10 AM: Evaluate: task edges-ner-ontonotes, batch 99 (157): mcc: 0.8613, acc: 0.7917, precision: 0.9268, recall: 0.8136, f1: 0.8665, edges-ner-ontonotes_loss: 0.0417
09/16 10:42:18 AM: Updating LR scheduler:
09/16 10:42:18 AM: 	Best result seen so far for macro_avg: 0.875
09/16 10:42:18 AM: 	# validation passes without improvement: 1
09/16 10:42:18 AM: edges-ner-ontonotes_loss: training: 0.052966 validation: 0.039366
09/16 10:42:18 AM: macro_avg: validation: 0.870818
09/16 10:42:18 AM: micro_avg: validation: 0.000000
09/16 10:42:18 AM: edges-ner-ontonotes_mcc: training: 0.811198 validation: 0.866204
09/16 10:42:18 AM: edges-ner-ontonotes_acc: training: 0.721223 validation: 0.794131
09/16 10:42:18 AM: edges-ner-ontonotes_precision: training: 0.879501 validation: 0.937172
09/16 10:42:18 AM: edges-ner-ontonotes_recall: training: 0.766171 validation: 0.813239
09/16 10:42:18 AM: edges-ner-ontonotes_f1: training: 0.818934 validation: 0.870818
09/16 10:42:18 AM: Global learning rate: 6.25e-06
09/16 10:42:18 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:42:20 AM: Update 50028: task edges-ner-ontonotes, batch 28 (50028): mcc: 0.7906, acc: 0.6915, precision: 0.8697, recall: 0.7381, f1: 0.7985, edges-ner-ontonotes_loss: 0.0570
09/16 10:42:30 AM: Update 50135: task edges-ner-ontonotes, batch 135 (50135): mcc: 0.7936, acc: 0.6982, precision: 0.8689, recall: 0.7441, f1: 0.8017, edges-ner-ontonotes_loss: 0.0557
09/16 10:42:40 AM: Update 50265: task edges-ner-ontonotes, batch 265 (50265): mcc: 0.8017, acc: 0.7105, precision: 0.8737, recall: 0.7544, f1: 0.8097, edges-ner-ontonotes_loss: 0.0536
09/16 10:42:50 AM: Update 50391: task edges-ner-ontonotes, batch 391 (50391): mcc: 0.8036, acc: 0.7135, precision: 0.8741, recall: 0.7574, f1: 0.8116, edges-ner-ontonotes_loss: 0.0533
09/16 10:43:00 AM: Update 50493: task edges-ner-ontonotes, batch 493 (50493): mcc: 0.8093, acc: 0.7197, precision: 0.8800, recall: 0.7623, f1: 0.8169, edges-ner-ontonotes_loss: 0.0522
09/16 10:43:10 AM: Update 50614: task edges-ner-ontonotes, batch 614 (50614): mcc: 0.8158, acc: 0.7280, precision: 0.8840, recall: 0.7705, f1: 0.8233, edges-ner-ontonotes_loss: 0.0507
09/16 10:43:21 AM: Update 50732: task edges-ner-ontonotes, batch 732 (50732): mcc: 0.8193, acc: 0.7320, precision: 0.8858, recall: 0.7750, f1: 0.8267, edges-ner-ontonotes_loss: 0.0496
09/16 10:43:31 AM: Update 50859: task edges-ner-ontonotes, batch 859 (50859): mcc: 0.8207, acc: 0.7338, precision: 0.8866, recall: 0.7769, f1: 0.8281, edges-ner-ontonotes_loss: 0.0492
09/16 10:43:41 AM: Update 50983: task edges-ner-ontonotes, batch 983 (50983): mcc: 0.8216, acc: 0.7350, precision: 0.8868, recall: 0.7783, f1: 0.8290, edges-ner-ontonotes_loss: 0.0490
09/16 10:43:42 AM: ***** Step 51000 / Validation 51 *****
09/16 10:43:42 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:43:42 AM: Validating...
09/16 10:43:51 AM: Evaluate: task edges-ner-ontonotes, batch 72 (157): mcc: 0.8445, acc: 0.7746, precision: 0.9053, recall: 0.8028, f1: 0.8510, edges-ner-ontonotes_loss: 0.0471
09/16 10:44:01 AM: Evaluate: task edges-ner-ontonotes, batch 147 (157): mcc: 0.8673, acc: 0.8000, precision: 0.9285, recall: 0.8230, f1: 0.8726, edges-ner-ontonotes_loss: 0.0403
09/16 10:44:02 AM: Updating LR scheduler:
09/16 10:44:02 AM: 	Best result seen so far for macro_avg: 0.875
09/16 10:44:02 AM: 	# validation passes without improvement: 2
09/16 10:44:02 AM: edges-ner-ontonotes_loss: training: 0.049006 validation: 0.039907
09/16 10:44:02 AM: macro_avg: validation: 0.873272
09/16 10:44:02 AM: micro_avg: validation: 0.000000
09/16 10:44:02 AM: edges-ner-ontonotes_mcc: training: 0.821788 validation: 0.868017
09/16 10:44:02 AM: edges-ner-ontonotes_acc: training: 0.735218 validation: 0.800880
09/16 10:44:02 AM: edges-ner-ontonotes_precision: training: 0.886899 validation: 0.928803
09/16 10:44:02 AM: edges-ner-ontonotes_recall: training: 0.778565 validation: 0.824007
09/16 10:44:02 AM: edges-ner-ontonotes_f1: training: 0.829208 validation: 0.873272
09/16 10:44:02 AM: Global learning rate: 6.25e-06
09/16 10:44:02 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:44:11 AM: Update 51085: task edges-ner-ontonotes, batch 85 (51085): mcc: 0.7936, acc: 0.6972, precision: 0.8695, recall: 0.7436, f1: 0.8016, edges-ner-ontonotes_loss: 0.0558
09/16 10:44:21 AM: Update 51220: task edges-ner-ontonotes, batch 220 (51220): mcc: 0.7877, acc: 0.6900, precision: 0.8657, recall: 0.7364, f1: 0.7958, edges-ner-ontonotes_loss: 0.0598
09/16 10:44:31 AM: Update 51345: task edges-ner-ontonotes, batch 345 (51345): mcc: 0.7830, acc: 0.6848, precision: 0.8609, recall: 0.7322, f1: 0.7914, edges-ner-ontonotes_loss: 0.0604
09/16 10:44:41 AM: Update 51470: task edges-ner-ontonotes, batch 470 (51470): mcc: 0.7845, acc: 0.6867, precision: 0.8608, recall: 0.7351, f1: 0.7930, edges-ner-ontonotes_loss: 0.0596
09/16 10:44:51 AM: Update 51626: task edges-ner-ontonotes, batch 626 (51626): mcc: 0.7867, acc: 0.6896, precision: 0.8616, recall: 0.7383, f1: 0.7952, edges-ner-ontonotes_loss: 0.0584
09/16 10:45:01 AM: Update 51742: task edges-ner-ontonotes, batch 742 (51742): mcc: 0.7882, acc: 0.6919, precision: 0.8628, recall: 0.7398, f1: 0.7966, edges-ner-ontonotes_loss: 0.0581
09/16 10:45:11 AM: Update 51867: task edges-ner-ontonotes, batch 867 (51867): mcc: 0.7906, acc: 0.6946, precision: 0.8642, recall: 0.7429, f1: 0.7990, edges-ner-ontonotes_loss: 0.0573
09/16 10:45:21 AM: Update 51982: task edges-ner-ontonotes, batch 982 (51982): mcc: 0.7940, acc: 0.6990, precision: 0.8670, recall: 0.7464, f1: 0.8022, edges-ner-ontonotes_loss: 0.0564
09/16 10:45:23 AM: ***** Step 52000 / Validation 52 *****
09/16 10:45:23 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:45:23 AM: Validating...
09/16 10:45:31 AM: Evaluate: task edges-ner-ontonotes, batch 75 (157): mcc: 0.8560, acc: 0.7886, precision: 0.9154, recall: 0.8144, f1: 0.8620, edges-ner-ontonotes_loss: 0.0440
09/16 10:45:41 AM: Evaluate: task edges-ner-ontonotes, batch 149 (157): mcc: 0.8686, acc: 0.8008, precision: 0.9332, recall: 0.8210, f1: 0.8736, edges-ner-ontonotes_loss: 0.0393
09/16 10:45:42 AM: Updating LR scheduler:
09/16 10:45:42 AM: 	Best result seen so far for macro_avg: 0.875
09/16 10:45:42 AM: 	# validation passes without improvement: 3
09/16 10:45:42 AM: edges-ner-ontonotes_loss: training: 0.056227 validation: 0.038987
09/16 10:45:42 AM: macro_avg: validation: 0.874138
09/16 10:45:42 AM: micro_avg: validation: 0.000000
09/16 10:45:42 AM: edges-ner-ontonotes_mcc: training: 0.794780 validation: 0.869195
09/16 10:45:42 AM: edges-ner-ontonotes_acc: training: 0.700088 validation: 0.801562
09/16 10:45:42 AM: edges-ner-ontonotes_precision: training: 0.867761 validation: 0.933586
09/16 10:45:42 AM: edges-ner-ontonotes_recall: training: 0.747222 validation: 0.821808
09/16 10:45:42 AM: edges-ner-ontonotes_f1: training: 0.802993 validation: 0.874138
09/16 10:45:42 AM: Global learning rate: 6.25e-06
09/16 10:45:42 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:45:51 AM: Update 52114: task edges-ner-ontonotes, batch 114 (52114): mcc: 0.8367, acc: 0.7541, precision: 0.8959, recall: 0.7973, f1: 0.8437, edges-ner-ontonotes_loss: 0.0452
09/16 10:46:01 AM: Update 52237: task edges-ner-ontonotes, batch 237 (52237): mcc: 0.8363, acc: 0.7533, precision: 0.8953, recall: 0.7971, f1: 0.8433, edges-ner-ontonotes_loss: 0.0450
09/16 10:46:11 AM: Update 52347: task edges-ner-ontonotes, batch 347 (52347): mcc: 0.8357, acc: 0.7531, precision: 0.8942, recall: 0.7971, f1: 0.8429, edges-ner-ontonotes_loss: 0.0449
09/16 10:46:22 AM: Update 52469: task edges-ner-ontonotes, batch 469 (52469): mcc: 0.8337, acc: 0.7507, precision: 0.8931, recall: 0.7944, f1: 0.8408, edges-ner-ontonotes_loss: 0.0456
09/16 10:46:32 AM: Update 52592: task edges-ner-ontonotes, batch 592 (52592): mcc: 0.8334, acc: 0.7502, precision: 0.8940, recall: 0.7932, f1: 0.8406, edges-ner-ontonotes_loss: 0.0458
09/16 10:46:42 AM: Update 52705: task edges-ner-ontonotes, batch 705 (52705): mcc: 0.8255, acc: 0.7397, precision: 0.8892, recall: 0.7831, f1: 0.8328, edges-ner-ontonotes_loss: 0.0484
09/16 10:46:52 AM: Update 52835: task edges-ner-ontonotes, batch 835 (52835): mcc: 0.8197, acc: 0.7321, precision: 0.8855, recall: 0.7761, f1: 0.8272, edges-ner-ontonotes_loss: 0.0501
09/16 10:47:02 AM: Update 52955: task edges-ner-ontonotes, batch 955 (52955): mcc: 0.8157, acc: 0.7273, precision: 0.8828, recall: 0.7712, f1: 0.8233, edges-ner-ontonotes_loss: 0.0516
09/16 10:47:05 AM: ***** Step 53000 / Validation 53 *****
09/16 10:47:06 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:47:06 AM: Validating...
09/16 10:47:12 AM: Evaluate: task edges-ner-ontonotes, batch 51 (157): mcc: 0.8470, acc: 0.7762, precision: 0.9104, recall: 0.8027, f1: 0.8532, edges-ner-ontonotes_loss: 0.0457
09/16 10:47:22 AM: Evaluate: task edges-ner-ontonotes, batch 123 (157): mcc: 0.8649, acc: 0.7950, precision: 0.9329, recall: 0.8147, f1: 0.8698, edges-ner-ontonotes_loss: 0.0406
09/16 10:47:26 AM: Updating LR scheduler:
09/16 10:47:26 AM: 	Best result seen so far for macro_avg: 0.875
09/16 10:47:26 AM: 	# validation passes without improvement: 0
09/16 10:47:26 AM: edges-ner-ontonotes_loss: training: 0.051682 validation: 0.039284
09/16 10:47:26 AM: macro_avg: validation: 0.872241
09/16 10:47:26 AM: micro_avg: validation: 0.000000
09/16 10:47:26 AM: edges-ner-ontonotes_mcc: training: 0.815198 validation: 0.867504
09/16 10:47:26 AM: edges-ner-ontonotes_acc: training: 0.726744 validation: 0.796709
09/16 10:47:26 AM: edges-ner-ontonotes_precision: training: 0.882233 validation: 0.935952
09/16 10:47:26 AM: edges-ner-ontonotes_recall: training: 0.770908 validation: 0.816652
09/16 10:47:26 AM: edges-ner-ontonotes_f1: training: 0.822822 validation: 0.872241
09/16 10:47:26 AM: Global learning rate: 3.125e-06
09/16 10:47:26 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:47:32 AM: Update 53082: task edges-ner-ontonotes, batch 82 (53082): mcc: 0.8012, acc: 0.7109, precision: 0.8686, recall: 0.7580, f1: 0.8096, edges-ner-ontonotes_loss: 0.0533
09/16 10:47:43 AM: Update 53218: task edges-ner-ontonotes, batch 218 (53218): mcc: 0.7947, acc: 0.7008, precision: 0.8637, recall: 0.7508, f1: 0.8033, edges-ner-ontonotes_loss: 0.0557
09/16 10:47:53 AM: Update 53343: task edges-ner-ontonotes, batch 343 (53343): mcc: 0.8012, acc: 0.7102, precision: 0.8700, recall: 0.7567, f1: 0.8094, edges-ner-ontonotes_loss: 0.0543
09/16 10:48:03 AM: Update 53470: task edges-ner-ontonotes, batch 470 (53470): mcc: 0.8034, acc: 0.7124, precision: 0.8719, recall: 0.7589, f1: 0.8115, edges-ner-ontonotes_loss: 0.0536
09/16 10:48:13 AM: Update 53580: task edges-ner-ontonotes, batch 580 (53580): mcc: 0.8060, acc: 0.7159, precision: 0.8745, recall: 0.7613, f1: 0.8140, edges-ner-ontonotes_loss: 0.0531
09/16 10:48:23 AM: Update 53705: task edges-ner-ontonotes, batch 705 (53705): mcc: 0.8124, acc: 0.7231, precision: 0.8797, recall: 0.7681, f1: 0.8201, edges-ner-ontonotes_loss: 0.0516
09/16 10:48:33 AM: Update 53829: task edges-ner-ontonotes, batch 829 (53829): mcc: 0.8166, acc: 0.7279, precision: 0.8829, recall: 0.7728, f1: 0.8242, edges-ner-ontonotes_loss: 0.0505
09/16 10:48:43 AM: Update 53944: task edges-ner-ontonotes, batch 944 (53944): mcc: 0.8178, acc: 0.7294, precision: 0.8832, recall: 0.7748, f1: 0.8254, edges-ner-ontonotes_loss: 0.0501
09/16 10:48:48 AM: ***** Step 54000 / Validation 54 *****
09/16 10:48:48 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:48:48 AM: Validating...
09/16 10:48:53 AM: Evaluate: task edges-ner-ontonotes, batch 50 (157): mcc: 0.8400, acc: 0.7714, precision: 0.8982, recall: 0.8012, f1: 0.8470, edges-ner-ontonotes_loss: 0.0485
09/16 10:49:03 AM: Evaluate: task edges-ner-ontonotes, batch 122 (157): mcc: 0.8643, acc: 0.7976, precision: 0.9247, recall: 0.8209, f1: 0.8698, edges-ner-ontonotes_loss: 0.0418
09/16 10:49:07 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:49:07 AM: Best result seen so far for macro.
09/16 10:49:07 AM: Updating LR scheduler:
09/16 10:49:07 AM: 	Best result seen so far for macro_avg: 0.875
09/16 10:49:07 AM: 	# validation passes without improvement: 1
09/16 10:49:07 AM: edges-ner-ontonotes_loss: training: 0.049925 validation: 0.039741
09/16 10:49:07 AM: macro_avg: validation: 0.874659
09/16 10:49:07 AM: micro_avg: validation: 0.000000
09/16 10:49:07 AM: edges-ner-ontonotes_mcc: training: 0.818615 validation: 0.869340
09/16 10:49:07 AM: edges-ner-ontonotes_acc: training: 0.730539 validation: 0.803003
09/16 10:49:07 AM: edges-ner-ontonotes_precision: training: 0.883420 validation: 0.928097
09/16 10:49:07 AM: edges-ner-ontonotes_recall: training: 0.775990 validation: 0.827040
09/16 10:49:07 AM: edges-ner-ontonotes_f1: training: 0.826228 validation: 0.874659
09/16 10:49:07 AM: Global learning rate: 3.125e-06
09/16 10:49:07 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:49:13 AM: Update 54071: task edges-ner-ontonotes, batch 71 (54071): mcc: 0.8319, acc: 0.7477, precision: 0.8922, recall: 0.7921, f1: 0.8392, edges-ner-ontonotes_loss: 0.0472
09/16 10:49:23 AM: Update 54174: task edges-ner-ontonotes, batch 174 (54174): mcc: 0.8261, acc: 0.7401, precision: 0.8881, recall: 0.7852, f1: 0.8335, edges-ner-ontonotes_loss: 0.0484
09/16 10:49:33 AM: Update 54301: task edges-ner-ontonotes, batch 301 (54301): mcc: 0.8041, acc: 0.7127, precision: 0.8756, recall: 0.7570, f1: 0.8120, edges-ner-ontonotes_loss: 0.0551
09/16 10:49:43 AM: Update 54436: task edges-ner-ontonotes, batch 436 (54436): mcc: 0.7987, acc: 0.7050, precision: 0.8726, recall: 0.7499, f1: 0.8066, edges-ner-ontonotes_loss: 0.0569
09/16 10:49:53 AM: Update 54565: task edges-ner-ontonotes, batch 565 (54565): mcc: 0.7973, acc: 0.7041, precision: 0.8697, recall: 0.7500, f1: 0.8055, edges-ner-ontonotes_loss: 0.0565
09/16 10:50:03 AM: Update 54715: task edges-ner-ontonotes, batch 715 (54715): mcc: 0.7969, acc: 0.7039, precision: 0.8688, recall: 0.7500, f1: 0.8051, edges-ner-ontonotes_loss: 0.0565
09/16 10:50:13 AM: Update 54832: task edges-ner-ontonotes, batch 832 (54832): mcc: 0.7967, acc: 0.7032, precision: 0.8688, recall: 0.7496, f1: 0.8048, edges-ner-ontonotes_loss: 0.0563
09/16 10:50:23 AM: Update 54960: task edges-ner-ontonotes, batch 960 (54960): mcc: 0.7985, acc: 0.7054, precision: 0.8703, recall: 0.7517, f1: 0.8066, edges-ner-ontonotes_loss: 0.0557
09/16 10:50:27 AM: ***** Step 55000 / Validation 55 *****
09/16 10:50:27 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:50:27 AM: Validating...
09/16 10:50:34 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.8567, acc: 0.7906, precision: 0.9149, recall: 0.8162, f1: 0.8627, edges-ner-ontonotes_loss: 0.0431
09/16 10:50:44 AM: Evaluate: task edges-ner-ontonotes, batch 134 (157): mcc: 0.8680, acc: 0.7994, precision: 0.9350, recall: 0.8183, f1: 0.8728, edges-ner-ontonotes_loss: 0.0394
09/16 10:50:46 AM: Updating LR scheduler:
09/16 10:50:46 AM: 	Best result seen so far for macro_avg: 0.875
09/16 10:50:48 AM: 	# validation passes without improvement: 2
09/16 10:50:48 AM: edges-ner-ontonotes_loss: training: 0.055538 validation: 0.039033
09/16 10:50:48 AM: macro_avg: validation: 0.872635
09/16 10:50:48 AM: micro_avg: validation: 0.000000
09/16 10:50:48 AM: edges-ner-ontonotes_mcc: training: 0.798660 validation: 0.867803
09/16 10:50:48 AM: edges-ner-ontonotes_acc: training: 0.705760 validation: 0.798074
09/16 10:50:48 AM: edges-ner-ontonotes_precision: training: 0.870343 validation: 0.934771
09/16 10:50:48 AM: edges-ner-ontonotes_recall: training: 0.751868 validation: 0.818244
09/16 10:50:48 AM: edges-ner-ontonotes_f1: training: 0.806779 validation: 0.872635
09/16 10:50:48 AM: Global learning rate: 3.125e-06
09/16 10:50:48 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:50:54 AM: Update 55073: task edges-ner-ontonotes, batch 73 (55073): mcc: 0.8150, acc: 0.7312, precision: 0.8795, recall: 0.7731, f1: 0.8228, edges-ner-ontonotes_loss: 0.0502
09/16 10:51:04 AM: Update 55180: task edges-ner-ontonotes, batch 180 (55180): mcc: 0.8227, acc: 0.7376, precision: 0.8887, recall: 0.7786, f1: 0.8300, edges-ner-ontonotes_loss: 0.0484
09/16 10:51:14 AM: Update 55307: task edges-ner-ontonotes, batch 307 (55307): mcc: 0.8302, acc: 0.7476, precision: 0.8931, recall: 0.7880, f1: 0.8373, edges-ner-ontonotes_loss: 0.0468
09/16 10:51:24 AM: Update 55420: task edges-ner-ontonotes, batch 420 (55420): mcc: 0.8313, acc: 0.7482, precision: 0.8927, recall: 0.7904, f1: 0.8385, edges-ner-ontonotes_loss: 0.0460
09/16 10:51:34 AM: Update 55546: task edges-ner-ontonotes, batch 546 (55546): mcc: 0.8322, acc: 0.7490, precision: 0.8933, recall: 0.7916, f1: 0.8394, edges-ner-ontonotes_loss: 0.0461
09/16 10:51:44 AM: Update 55669: task edges-ner-ontonotes, batch 669 (55669): mcc: 0.8312, acc: 0.7472, precision: 0.8930, recall: 0.7900, f1: 0.8384, edges-ner-ontonotes_loss: 0.0464
09/16 10:51:54 AM: Update 55779: task edges-ner-ontonotes, batch 779 (55779): mcc: 0.8258, acc: 0.7403, precision: 0.8893, recall: 0.7837, f1: 0.8332, edges-ner-ontonotes_loss: 0.0481
09/16 10:52:04 AM: Update 55910: task edges-ner-ontonotes, batch 910 (55910): mcc: 0.8192, acc: 0.7319, precision: 0.8854, recall: 0.7752, f1: 0.8267, edges-ner-ontonotes_loss: 0.0502
09/16 10:52:11 AM: ***** Step 56000 / Validation 56 *****
09/16 10:52:11 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:52:11 AM: Validating...
09/16 10:52:14 AM: Evaluate: task edges-ner-ontonotes, batch 31 (157): mcc: 0.8288, acc: 0.7602, precision: 0.8895, recall: 0.7888, f1: 0.8361, edges-ner-ontonotes_loss: 0.0506
09/16 10:52:24 AM: Evaluate: task edges-ner-ontonotes, batch 112 (157): mcc: 0.8655, acc: 0.7983, precision: 0.9275, recall: 0.8206, f1: 0.8708, edges-ner-ontonotes_loss: 0.0409
09/16 10:52:30 AM: Updating LR scheduler:
09/16 10:52:32 AM: 	Best result seen so far for macro_avg: 0.875
09/16 10:52:32 AM: 	# validation passes without improvement: 3
09/16 10:52:32 AM: edges-ner-ontonotes_loss: training: 0.051200 validation: 0.039251
09/16 10:52:32 AM: macro_avg: validation: 0.873289
09/16 10:52:32 AM: micro_avg: validation: 0.000000
09/16 10:52:32 AM: edges-ner-ontonotes_mcc: training: 0.815865 validation: 0.868370
09/16 10:52:32 AM: edges-ner-ontonotes_acc: training: 0.727705 validation: 0.799287
09/16 10:52:32 AM: edges-ner-ontonotes_precision: training: 0.883272 validation: 0.933707
09/16 10:52:32 AM: edges-ner-ontonotes_recall: training: 0.771171 validation: 0.820215
09/16 10:52:32 AM: edges-ner-ontonotes_f1: training: 0.823424 validation: 0.873289
09/16 10:52:32 AM: Global learning rate: 3.125e-06
09/16 10:52:32 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:52:35 AM: Update 56017: task edges-ner-ontonotes, batch 17 (56017): mcc: 0.7777, acc: 0.6719, precision: 0.8621, recall: 0.7217, f1: 0.7857, edges-ner-ontonotes_loss: 0.0618
09/16 10:52:45 AM: Update 56167: task edges-ner-ontonotes, batch 167 (56167): mcc: 0.7929, acc: 0.6998, precision: 0.8646, recall: 0.7468, f1: 0.8014, edges-ner-ontonotes_loss: 0.0569
09/16 10:52:55 AM: Update 56319: task edges-ner-ontonotes, batch 319 (56319): mcc: 0.7941, acc: 0.7013, precision: 0.8632, recall: 0.7501, f1: 0.8027, edges-ner-ontonotes_loss: 0.0563
09/16 10:53:05 AM: Update 56431: task edges-ner-ontonotes, batch 431 (56431): mcc: 0.7956, acc: 0.7021, precision: 0.8667, recall: 0.7496, f1: 0.8039, edges-ner-ontonotes_loss: 0.0555
09/16 10:53:15 AM: Update 56561: task edges-ner-ontonotes, batch 561 (56561): mcc: 0.7996, acc: 0.7071, precision: 0.8692, recall: 0.7545, f1: 0.8078, edges-ner-ontonotes_loss: 0.0546
09/16 10:53:25 AM: Update 56678: task edges-ner-ontonotes, batch 678 (56678): mcc: 0.8028, acc: 0.7115, precision: 0.8726, recall: 0.7573, f1: 0.8108, edges-ner-ontonotes_loss: 0.0539
09/16 10:53:35 AM: Update 56798: task edges-ner-ontonotes, batch 798 (56798): mcc: 0.8092, acc: 0.7194, precision: 0.8774, recall: 0.7644, f1: 0.8170, edges-ner-ontonotes_loss: 0.0524
09/16 10:53:45 AM: Update 56928: task edges-ner-ontonotes, batch 928 (56928): mcc: 0.8136, acc: 0.7248, precision: 0.8803, recall: 0.7697, f1: 0.8213, edges-ner-ontonotes_loss: 0.0513
09/16 10:53:53 AM: ***** Step 57000 / Validation 57 *****
09/16 10:53:53 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:53:53 AM: Validating...
09/16 10:53:55 AM: Evaluate: task edges-ner-ontonotes, batch 23 (157): mcc: 0.7979, acc: 0.7273, precision: 0.8583, recall: 0.7614, f1: 0.8069, edges-ner-ontonotes_loss: 0.0584
09/16 10:54:05 AM: Evaluate: task edges-ner-ontonotes, batch 106 (157): mcc: 0.8608, acc: 0.7944, precision: 0.9209, recall: 0.8182, f1: 0.8665, edges-ner-ontonotes_loss: 0.0427
09/16 10:54:12 AM: Updating LR scheduler:
09/16 10:54:12 AM: 	Best result seen so far for macro_avg: 0.875
09/16 10:54:12 AM: 	# validation passes without improvement: 0
09/16 10:54:12 AM: edges-ner-ontonotes_loss: training: 0.050904 validation: 0.039637
09/16 10:54:12 AM: macro_avg: validation: 0.874101
09/16 10:54:12 AM: micro_avg: validation: 0.000000
09/16 10:54:12 AM: edges-ner-ontonotes_mcc: training: 0.815067 validation: 0.868901
09/16 10:54:12 AM: edges-ner-ontonotes_acc: training: 0.726875 validation: 0.801183
09/16 10:54:12 AM: edges-ner-ontonotes_precision: training: 0.881221 validation: 0.929811
09/16 10:54:12 AM: edges-ner-ontonotes_recall: training: 0.771584 validation: 0.824689
09/16 10:54:12 AM: edges-ner-ontonotes_f1: training: 0.822766 validation: 0.874101
09/16 10:54:12 AM: Global learning rate: 1.5625e-06
09/16 10:54:12 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:54:15 AM: Update 57035: task edges-ner-ontonotes, batch 35 (57035): mcc: 0.8437, acc: 0.7623, precision: 0.8962, recall: 0.8097, f1: 0.8508, edges-ner-ontonotes_loss: 0.0431
09/16 10:54:25 AM: Update 57162: task edges-ner-ontonotes, batch 162 (57162): mcc: 0.8322, acc: 0.7462, precision: 0.8923, recall: 0.7924, f1: 0.8394, edges-ner-ontonotes_loss: 0.0461
09/16 10:54:35 AM: Update 57270: task edges-ner-ontonotes, batch 270 (57270): mcc: 0.8282, acc: 0.7415, precision: 0.8911, recall: 0.7864, f1: 0.8355, edges-ner-ontonotes_loss: 0.0466
09/16 10:54:46 AM: Update 57402: task edges-ner-ontonotes, batch 402 (57402): mcc: 0.8125, acc: 0.7229, precision: 0.8797, recall: 0.7683, f1: 0.8202, edges-ner-ontonotes_loss: 0.0522
09/16 10:54:56 AM: Update 57532: task edges-ner-ontonotes, batch 532 (57532): mcc: 0.8039, acc: 0.7122, precision: 0.8750, recall: 0.7572, f1: 0.8118, edges-ner-ontonotes_loss: 0.0548
09/16 10:55:06 AM: Update 57652: task edges-ner-ontonotes, batch 652 (57652): mcc: 0.8023, acc: 0.7104, precision: 0.8732, recall: 0.7559, f1: 0.8103, edges-ner-ontonotes_loss: 0.0553
09/16 10:55:16 AM: Update 57804: task edges-ner-ontonotes, batch 804 (57804): mcc: 0.8015, acc: 0.7092, precision: 0.8725, recall: 0.7550, f1: 0.8095, edges-ner-ontonotes_loss: 0.0552
09/16 10:55:26 AM: Update 57929: task edges-ner-ontonotes, batch 929 (57929): mcc: 0.8017, acc: 0.7090, precision: 0.8726, recall: 0.7553, f1: 0.8097, edges-ner-ontonotes_loss: 0.0552
09/16 10:55:31 AM: ***** Step 58000 / Validation 58 *****
09/16 10:55:31 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:55:31 AM: Validating...
09/16 10:55:36 AM: Evaluate: task edges-ner-ontonotes, batch 46 (157): mcc: 0.8416, acc: 0.7705, precision: 0.9043, recall: 0.7985, f1: 0.8481, edges-ner-ontonotes_loss: 0.0469
09/16 10:55:46 AM: Evaluate: task edges-ner-ontonotes, batch 118 (157): mcc: 0.8642, acc: 0.7950, precision: 0.9317, recall: 0.8145, f1: 0.8692, edges-ner-ontonotes_loss: 0.0405
09/16 10:55:51 AM: Updating LR scheduler:
09/16 10:55:51 AM: 	Best result seen so far for macro_avg: 0.875
09/16 10:55:51 AM: 	# validation passes without improvement: 1
09/16 10:55:51 AM: edges-ner-ontonotes_loss: training: 0.054972 validation: 0.039085
09/16 10:55:51 AM: macro_avg: validation: 0.872495
09/16 10:55:51 AM: micro_avg: validation: 0.000000
09/16 10:55:51 AM: edges-ner-ontonotes_mcc: training: 0.802022 validation: 0.867765
09/16 10:55:51 AM: edges-ner-ontonotes_acc: training: 0.709786 validation: 0.797543
09/16 10:55:51 AM: edges-ner-ontonotes_precision: training: 0.872918 validation: 0.936137
09/16 10:55:51 AM: edges-ner-ontonotes_recall: training: 0.755595 validation: 0.816955
09/16 10:55:51 AM: edges-ner-ontonotes_f1: training: 0.810031 validation: 0.872495
09/16 10:55:51 AM: Global learning rate: 1.5625e-06
09/16 10:55:51 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:55:56 AM: Update 58069: task edges-ner-ontonotes, batch 69 (58069): mcc: 0.8075, acc: 0.7194, precision: 0.8760, recall: 0.7626, f1: 0.8154, edges-ner-ontonotes_loss: 0.0529
09/16 10:56:06 AM: Update 58195: task edges-ner-ontonotes, batch 195 (58195): mcc: 0.8072, acc: 0.7167, precision: 0.8784, recall: 0.7600, f1: 0.8149, edges-ner-ontonotes_loss: 0.0526
09/16 10:56:16 AM: Update 58298: task edges-ner-ontonotes, batch 298 (58298): mcc: 0.8130, acc: 0.7232, precision: 0.8858, recall: 0.7638, f1: 0.8203, edges-ner-ontonotes_loss: 0.0507
09/16 10:56:26 AM: Update 58427: task edges-ner-ontonotes, batch 427 (58427): mcc: 0.8208, acc: 0.7327, precision: 0.8900, recall: 0.7740, f1: 0.8280, edges-ner-ontonotes_loss: 0.0488
09/16 10:56:36 AM: Update 58537: task edges-ner-ontonotes, batch 537 (58537): mcc: 0.8235, acc: 0.7366, precision: 0.8908, recall: 0.7782, f1: 0.8307, edges-ner-ontonotes_loss: 0.0481
09/16 10:56:46 AM: Update 58661: task edges-ner-ontonotes, batch 661 (58661): mcc: 0.8245, acc: 0.7382, precision: 0.8902, recall: 0.7805, f1: 0.8317, edges-ner-ontonotes_loss: 0.0478
09/16 10:56:56 AM: Update 58788: task edges-ner-ontonotes, batch 788 (58788): mcc: 0.8254, acc: 0.7391, precision: 0.8906, recall: 0.7817, f1: 0.8326, edges-ner-ontonotes_loss: 0.0478
09/16 10:57:06 AM: Update 58900: task edges-ner-ontonotes, batch 900 (58900): mcc: 0.8219, acc: 0.7350, precision: 0.8881, recall: 0.7778, f1: 0.8293, edges-ner-ontonotes_loss: 0.0491
09/16 10:57:14 AM: ***** Step 59000 / Validation 59 *****
09/16 10:57:14 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:57:14 AM: Validating...
09/16 10:57:16 AM: Evaluate: task edges-ner-ontonotes, batch 22 (157): mcc: 0.8141, acc: 0.7430, precision: 0.8741, recall: 0.7763, f1: 0.8223, edges-ner-ontonotes_loss: 0.0501
09/16 10:57:26 AM: Evaluate: task edges-ner-ontonotes, batch 103 (157): mcc: 0.8616, acc: 0.7946, precision: 0.9238, recall: 0.8169, f1: 0.8671, edges-ner-ontonotes_loss: 0.0419
09/16 10:57:34 AM: Updating LR scheduler:
09/16 10:57:36 AM: 	Best result seen so far for macro_avg: 0.875
09/16 10:57:36 AM: 	# validation passes without improvement: 2
09/16 10:57:36 AM: edges-ner-ontonotes_loss: training: 0.050557 validation: 0.039046
09/16 10:57:36 AM: macro_avg: validation: 0.873962
09/16 10:57:36 AM: micro_avg: validation: 0.000000
09/16 10:57:36 AM: edges-ner-ontonotes_mcc: training: 0.817464 validation: 0.868994
09/16 10:57:36 AM: edges-ner-ontonotes_acc: training: 0.729359 validation: 0.800728
09/16 10:57:36 AM: edges-ner-ontonotes_precision: training: 0.884947 validation: 0.933184
09/16 10:57:36 AM: edges-ner-ontonotes_recall: training: 0.772541 validation: 0.821808
09/16 10:57:36 AM: edges-ner-ontonotes_f1: training: 0.824932 validation: 0.873962
09/16 10:57:36 AM: Global learning rate: 1.5625e-06
09/16 10:57:36 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:57:36 AM: Update 59004: task edges-ner-ontonotes, batch 4 (59004): mcc: 0.7017, acc: 0.5811, precision: 0.8234, recall: 0.6222, f1: 0.7088, edges-ner-ontonotes_loss: 0.0818
09/16 10:57:47 AM: Update 59129: task edges-ner-ontonotes, batch 129 (59129): mcc: 0.7747, acc: 0.6766, precision: 0.8562, recall: 0.7216, f1: 0.7831, edges-ner-ontonotes_loss: 0.0621
09/16 10:57:57 AM: Update 59288: task edges-ner-ontonotes, batch 288 (59288): mcc: 0.7853, acc: 0.6902, precision: 0.8576, recall: 0.7393, f1: 0.7940, edges-ner-ontonotes_loss: 0.0581
09/16 10:58:07 AM: Update 59436: task edges-ner-ontonotes, batch 436 (59436): mcc: 0.7902, acc: 0.6954, precision: 0.8607, recall: 0.7452, f1: 0.7988, edges-ner-ontonotes_loss: 0.0574
09/16 10:58:17 AM: Update 59546: task edges-ner-ontonotes, batch 546 (59546): mcc: 0.7923, acc: 0.6985, precision: 0.8633, recall: 0.7468, f1: 0.8008, edges-ner-ontonotes_loss: 0.0566
09/16 10:58:27 AM: Update 59678: task edges-ner-ontonotes, batch 678 (59678): mcc: 0.7963, acc: 0.7039, precision: 0.8660, recall: 0.7514, f1: 0.8047, edges-ner-ontonotes_loss: 0.0557
09/16 10:58:37 AM: Update 59784: task edges-ner-ontonotes, batch 784 (59784): mcc: 0.7992, acc: 0.7078, precision: 0.8691, recall: 0.7540, f1: 0.8075, edges-ner-ontonotes_loss: 0.0548
09/16 10:58:47 AM: Update 59906: task edges-ner-ontonotes, batch 906 (59906): mcc: 0.8038, acc: 0.7128, precision: 0.8734, recall: 0.7583, f1: 0.8118, edges-ner-ontonotes_loss: 0.0537
09/16 10:58:55 AM: ***** Step 60000 / Validation 60 *****
09/16 10:58:55 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 10:58:55 AM: Validating...
09/16 10:58:58 AM: Evaluate: task edges-ner-ontonotes, batch 28 (157): mcc: 0.8203, acc: 0.7527, precision: 0.8822, recall: 0.7802, f1: 0.8281, edges-ner-ontonotes_loss: 0.0529
09/16 10:59:08 AM: Evaluate: task edges-ner-ontonotes, batch 108 (157): mcc: 0.8642, acc: 0.7983, precision: 0.9238, recall: 0.8215, f1: 0.8697, edges-ner-ontonotes_loss: 0.0416
09/16 10:59:15 AM: Best result seen so far for edges-ner-ontonotes.
09/16 10:59:15 AM: Best result seen so far for macro.
09/16 10:59:15 AM: Updating LR scheduler:
09/16 10:59:15 AM: 	Best result seen so far for macro_avg: 0.876
09/16 10:59:15 AM: 	# validation passes without improvement: 0
09/16 10:59:15 AM: edges-ner-ontonotes_loss: training: 0.052776 validation: 0.039046
09/16 10:59:15 AM: macro_avg: validation: 0.875674
09/16 10:59:15 AM: micro_avg: validation: 0.000000
09/16 10:59:15 AM: edges-ner-ontonotes_mcc: training: 0.807250 validation: 0.870606
09/16 10:59:15 AM: edges-ner-ontonotes_acc: training: 0.717122 validation: 0.803458
09/16 10:59:15 AM: edges-ner-ontonotes_precision: training: 0.876220 validation: 0.932118
09/16 10:59:15 AM: edges-ner-ontonotes_recall: training: 0.762023 validation: 0.825675
09/16 10:59:15 AM: edges-ner-ontonotes_f1: training: 0.815141 validation: 0.875674
09/16 10:59:15 AM: Global learning rate: 1.5625e-06
09/16 10:59:15 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 10:59:18 AM: Update 60032: task edges-ner-ontonotes, batch 32 (60032): mcc: 0.8349, acc: 0.7514, precision: 0.8909, recall: 0.7986, f1: 0.8422, edges-ner-ontonotes_loss: 0.0442
09/16 10:59:28 AM: Update 60138: task edges-ner-ontonotes, batch 138 (60138): mcc: 0.8326, acc: 0.7493, precision: 0.8943, recall: 0.7914, f1: 0.8397, edges-ner-ontonotes_loss: 0.0454
09/16 10:59:38 AM: Update 60269: task edges-ner-ontonotes, batch 269 (60269): mcc: 0.8309, acc: 0.7478, precision: 0.8928, recall: 0.7896, f1: 0.8381, edges-ner-ontonotes_loss: 0.0465
09/16 10:59:48 AM: Update 60382: task edges-ner-ontonotes, batch 382 (60382): mcc: 0.8292, acc: 0.7451, precision: 0.8908, recall: 0.7884, f1: 0.8365, edges-ner-ontonotes_loss: 0.0467
09/16 10:59:58 AM: Update 60514: task edges-ner-ontonotes, batch 514 (60514): mcc: 0.8163, acc: 0.7296, precision: 0.8818, recall: 0.7733, f1: 0.8240, edges-ner-ontonotes_loss: 0.0513
09/16 11:00:08 AM: Update 60647: task edges-ner-ontonotes, batch 647 (60647): mcc: 0.8099, acc: 0.7208, precision: 0.8782, recall: 0.7651, f1: 0.8177, edges-ner-ontonotes_loss: 0.0534
09/16 11:00:18 AM: Update 60774: task edges-ner-ontonotes, batch 774 (60774): mcc: 0.8070, acc: 0.7170, precision: 0.8763, recall: 0.7615, f1: 0.8149, edges-ner-ontonotes_loss: 0.0540
09/16 11:00:28 AM: Update 60919: task edges-ner-ontonotes, batch 919 (60919): mcc: 0.8057, acc: 0.7150, precision: 0.8754, recall: 0.7600, f1: 0.8136, edges-ner-ontonotes_loss: 0.0543
09/16 11:00:35 AM: ***** Step 61000 / Validation 61 *****
09/16 11:00:35 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 11:00:35 AM: Validating...
09/16 11:00:38 AM: Evaluate: task edges-ner-ontonotes, batch 35 (157): mcc: 0.8384, acc: 0.7677, precision: 0.9007, recall: 0.7959, f1: 0.8451, edges-ner-ontonotes_loss: 0.0480
09/16 11:00:49 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.8632, acc: 0.7925, precision: 0.9316, recall: 0.8129, f1: 0.8682, edges-ner-ontonotes_loss: 0.0408
09/16 11:00:54 AM: Updating LR scheduler:
09/16 11:00:54 AM: 	Best result seen so far for macro_avg: 0.876
09/16 11:00:58 AM: 	# validation passes without improvement: 1
09/16 11:00:58 AM: edges-ner-ontonotes_loss: training: 0.054364 validation: 0.039080
09/16 11:00:58 AM: macro_avg: validation: 0.872437
09/16 11:00:58 AM: micro_avg: validation: 0.000000
09/16 11:00:58 AM: edges-ner-ontonotes_mcc: training: 0.804664 validation: 0.867765
09/16 11:00:58 AM: edges-ner-ontonotes_acc: training: 0.713901 validation: 0.796633
09/16 11:00:58 AM: edges-ner-ontonotes_precision: training: 0.873944 validation: 0.936902
09/16 11:00:58 AM: edges-ner-ontonotes_recall: training: 0.759419 validation: 0.816272
09/16 11:00:58 AM: edges-ner-ontonotes_f1: training: 0.812666 validation: 0.872437
09/16 11:00:58 AM: Global learning rate: 1.5625e-06
09/16 11:00:58 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 11:00:59 AM: Update 61007: task edges-ner-ontonotes, batch 7 (61007): mcc: 0.7691, acc: 0.6683, precision: 0.8710, recall: 0.6991, f1: 0.7756, edges-ner-ontonotes_loss: 0.0612
09/16 11:01:09 AM: Update 61140: task edges-ner-ontonotes, batch 140 (61140): mcc: 0.8028, acc: 0.7102, precision: 0.8769, recall: 0.7534, f1: 0.8105, edges-ner-ontonotes_loss: 0.0530
09/16 11:01:19 AM: Update 61275: task edges-ner-ontonotes, batch 275 (61275): mcc: 0.8078, acc: 0.7186, precision: 0.8780, recall: 0.7614, f1: 0.8156, edges-ner-ontonotes_loss: 0.0521
09/16 11:01:29 AM: Update 61379: task edges-ner-ontonotes, batch 379 (61379): mcc: 0.8117, acc: 0.7227, precision: 0.8823, recall: 0.7645, f1: 0.8192, edges-ner-ontonotes_loss: 0.0511
09/16 11:01:39 AM: Update 61505: task edges-ner-ontonotes, batch 505 (61505): mcc: 0.8169, acc: 0.7285, precision: 0.8862, recall: 0.7704, f1: 0.8243, edges-ner-ontonotes_loss: 0.0496
09/16 11:01:49 AM: Update 61624: task edges-ner-ontonotes, batch 624 (61624): mcc: 0.8211, acc: 0.7332, precision: 0.8886, recall: 0.7757, f1: 0.8283, edges-ner-ontonotes_loss: 0.0486
09/16 11:01:59 AM: Update 61744: task edges-ner-ontonotes, batch 744 (61744): mcc: 0.8229, acc: 0.7357, precision: 0.8896, recall: 0.7781, f1: 0.8301, edges-ner-ontonotes_loss: 0.0482
09/16 11:02:09 AM: Update 61875: task edges-ner-ontonotes, batch 875 (61875): mcc: 0.8247, acc: 0.7381, precision: 0.8900, recall: 0.7811, f1: 0.8320, edges-ner-ontonotes_loss: 0.0479
09/16 11:02:19 AM: Update 61986: task edges-ner-ontonotes, batch 986 (61986): mcc: 0.8220, acc: 0.7347, precision: 0.8879, recall: 0.7780, f1: 0.8294, edges-ner-ontonotes_loss: 0.0489
09/16 11:02:20 AM: ***** Step 62000 / Validation 62 *****
09/16 11:02:20 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 11:02:20 AM: Validating...
09/16 11:02:29 AM: Evaluate: task edges-ner-ontonotes, batch 79 (157): mcc: 0.8576, acc: 0.7898, precision: 0.9158, recall: 0.8170, f1: 0.8636, edges-ner-ontonotes_loss: 0.0441
09/16 11:02:39 AM: Evaluate: task edges-ner-ontonotes, batch 154 (157): mcc: 0.8697, acc: 0.8021, precision: 0.9315, recall: 0.8246, f1: 0.8748, edges-ner-ontonotes_loss: 0.0394
09/16 11:02:40 AM: Updating LR scheduler:
09/16 11:02:40 AM: 	Best result seen so far for macro_avg: 0.876
09/16 11:02:40 AM: 	# validation passes without improvement: 2
09/16 11:02:40 AM: edges-ner-ontonotes_loss: training: 0.049231 validation: 0.039203
09/16 11:02:40 AM: macro_avg: validation: 0.875166
09/16 11:02:40 AM: micro_avg: validation: 0.000000
09/16 11:02:40 AM: edges-ner-ontonotes_mcc: training: 0.821145 validation: 0.870061
09/16 11:02:40 AM: edges-ner-ontonotes_acc: training: 0.733629 validation: 0.802851
09/16 11:02:40 AM: edges-ner-ontonotes_precision: training: 0.887399 validation: 0.931451
09/16 11:02:40 AM: edges-ner-ontonotes_recall: training: 0.776955 validation: 0.825296
09/16 11:02:40 AM: edges-ner-ontonotes_f1: training: 0.828513 validation: 0.875166
09/16 11:02:40 AM: Global learning rate: 1.5625e-06
09/16 11:02:40 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 11:02:49 AM: Update 62127: task edges-ner-ontonotes, batch 127 (62127): mcc: 0.7776, acc: 0.6781, precision: 0.8583, recall: 0.7249, f1: 0.7860, edges-ner-ontonotes_loss: 0.0613
09/16 11:03:00 AM: Update 62241: task edges-ner-ontonotes, batch 241 (62241): mcc: 0.7754, acc: 0.6770, precision: 0.8561, recall: 0.7230, f1: 0.7839, edges-ner-ontonotes_loss: 0.0623
09/16 11:03:10 AM: Update 62393: task edges-ner-ontonotes, batch 393 (62393): mcc: 0.7829, acc: 0.6869, precision: 0.8591, recall: 0.7337, f1: 0.7914, edges-ner-ontonotes_loss: 0.0598
09/16 11:03:20 AM: Update 62551: task edges-ner-ontonotes, batch 551 (62551): mcc: 0.7871, acc: 0.6923, precision: 0.8613, recall: 0.7393, f1: 0.7957, edges-ner-ontonotes_loss: 0.0584
09/16 11:03:30 AM: Update 62664: task edges-ner-ontonotes, batch 664 (62664): mcc: 0.7907, acc: 0.6968, precision: 0.8637, recall: 0.7436, f1: 0.7991, edges-ner-ontonotes_loss: 0.0573
09/16 11:03:40 AM: Update 62795: task edges-ner-ontonotes, batch 795 (62795): mcc: 0.7943, acc: 0.7012, precision: 0.8674, recall: 0.7468, f1: 0.8026, edges-ner-ontonotes_loss: 0.0563
09/16 11:03:50 AM: Update 62904: task edges-ner-ontonotes, batch 904 (62904): mcc: 0.7970, acc: 0.7042, precision: 0.8695, recall: 0.7496, f1: 0.8051, edges-ner-ontonotes_loss: 0.0555
09/16 11:03:58 AM: ***** Step 63000 / Validation 63 *****
09/16 11:03:58 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 11:03:58 AM: Validating...
09/16 11:04:00 AM: Evaluate: task edges-ner-ontonotes, batch 24 (157): mcc: 0.8096, acc: 0.7412, precision: 0.8696, recall: 0.7724, f1: 0.8181, edges-ner-ontonotes_loss: 0.0552
09/16 11:04:10 AM: Evaluate: task edges-ner-ontonotes, batch 107 (157): mcc: 0.8635, acc: 0.7967, precision: 0.9252, recall: 0.8191, f1: 0.8689, edges-ner-ontonotes_loss: 0.0414
09/16 11:04:17 AM: Updating LR scheduler:
09/16 11:04:17 AM: 	Best result seen so far for macro_avg: 0.876
09/16 11:04:17 AM: 	# validation passes without improvement: 3
09/16 11:04:17 AM: edges-ner-ontonotes_loss: training: 0.054493 validation: 0.038892
09/16 11:04:17 AM: macro_avg: validation: 0.875040
09/16 11:04:17 AM: micro_avg: validation: 0.000000
09/16 11:04:17 AM: edges-ner-ontonotes_mcc: training: 0.801458 validation: 0.870069
09/16 11:04:17 AM: edges-ner-ontonotes_acc: training: 0.709683 validation: 0.802169
09/16 11:04:17 AM: edges-ner-ontonotes_precision: training: 0.872762 validation: 0.933396
09/16 11:04:17 AM: edges-ner-ontonotes_recall: training: 0.754724 validation: 0.823552
09/16 11:04:17 AM: edges-ner-ontonotes_f1: training: 0.809462 validation: 0.875040
09/16 11:04:17 AM: Global learning rate: 1.5625e-06
09/16 11:04:17 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 11:04:20 AM: Update 63040: task edges-ner-ontonotes, batch 40 (63040): mcc: 0.8317, acc: 0.7432, precision: 0.8947, recall: 0.7893, f1: 0.8387, edges-ner-ontonotes_loss: 0.0459
09/16 11:04:31 AM: Update 63167: task edges-ner-ontonotes, batch 167 (63167): mcc: 0.8356, acc: 0.7515, precision: 0.8956, recall: 0.7956, f1: 0.8426, edges-ner-ontonotes_loss: 0.0450
09/16 11:04:41 AM: Update 63276: task edges-ner-ontonotes, batch 276 (63276): mcc: 0.8345, acc: 0.7503, precision: 0.8947, recall: 0.7945, f1: 0.8416, edges-ner-ontonotes_loss: 0.0453
09/16 11:04:51 AM: Update 63403: task edges-ner-ontonotes, batch 403 (63403): mcc: 0.8329, acc: 0.7486, precision: 0.8931, recall: 0.7930, f1: 0.8401, edges-ner-ontonotes_loss: 0.0460
09/16 11:05:01 AM: Update 63515: task edges-ner-ontonotes, batch 515 (63515): mcc: 0.8287, acc: 0.7427, precision: 0.8896, recall: 0.7887, f1: 0.8361, edges-ner-ontonotes_loss: 0.0471
09/16 11:05:11 AM: Update 63645: task edges-ner-ontonotes, batch 645 (63645): mcc: 0.8187, acc: 0.7305, precision: 0.8830, recall: 0.7766, f1: 0.8264, edges-ner-ontonotes_loss: 0.0503
09/16 11:05:21 AM: Update 63775: task edges-ner-ontonotes, batch 775 (63775): mcc: 0.8122, acc: 0.7223, precision: 0.8793, recall: 0.7682, f1: 0.8200, edges-ner-ontonotes_loss: 0.0522
09/16 11:05:31 AM: Update 63912: task edges-ner-ontonotes, batch 912 (63912): mcc: 0.8105, acc: 0.7206, precision: 0.8780, recall: 0.7662, f1: 0.8183, edges-ner-ontonotes_loss: 0.0529
09/16 11:05:37 AM: ***** Step 64000 / Validation 64 *****
09/16 11:05:37 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 11:05:38 AM: Validating...
09/16 11:05:41 AM: Evaluate: task edges-ner-ontonotes, batch 30 (157): mcc: 0.8270, acc: 0.7567, precision: 0.8900, recall: 0.7852, f1: 0.8343, edges-ner-ontonotes_loss: 0.0507
09/16 11:05:51 AM: Evaluate: task edges-ner-ontonotes, batch 111 (157): mcc: 0.8654, acc: 0.7977, precision: 0.9286, recall: 0.8194, f1: 0.8706, edges-ner-ontonotes_loss: 0.0405
09/16 11:05:57 AM: Updating LR scheduler:
09/16 11:05:57 AM: 	Best result seen so far for macro_avg: 0.876
09/16 11:05:57 AM: 	# validation passes without improvement: 0
09/16 11:05:57 AM: Minimum LR reached. Stopping training.
09/16 11:05:57 AM: edges-ner-ontonotes_loss: training: 0.053193 validation: 0.039073
09/16 11:05:57 AM: macro_avg: validation: 0.872355
09/16 11:05:57 AM: micro_avg: validation: 0.000000
09/16 11:05:57 AM: edges-ner-ontonotes_mcc: training: 0.809328 validation: 0.867554
09/16 11:05:57 AM: edges-ner-ontonotes_acc: training: 0.719203 validation: 0.797392
09/16 11:05:57 AM: edges-ner-ontonotes_precision: training: 0.877214 validation: 0.935120
09/16 11:05:57 AM: edges-ner-ontonotes_recall: training: 0.764863 validation: 0.817486
09/16 11:05:57 AM: edges-ner-ontonotes_f1: training: 0.817195 validation: 0.872355
09/16 11:05:57 AM: Global learning rate: 7.8125e-07
09/16 11:05:57 AM: Saving checkpoints to: ./experiments/ner-ontonotes-multiqa-top/run
09/16 11:05:57 AM: Stopped training after 64 validation checks
09/16 11:05:57 AM: Trained edges-ner-ontonotes for 64000 batches or 41.184 epochs
09/16 11:05:57 AM: ***** VALIDATION RESULTS *****
09/16 11:05:57 AM: edges-ner-ontonotes_f1 (for best val pass 60): edges-ner-ontonotes_loss: 0.03905, macro_avg: 0.87567, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.87061, edges-ner-ontonotes_acc: 0.80346, edges-ner-ontonotes_precision: 0.93212, edges-ner-ontonotes_recall: 0.82567, edges-ner-ontonotes_f1: 0.87567
09/16 11:05:57 AM: micro_avg (for best val pass 1): edges-ner-ontonotes_loss: 0.08880, macro_avg: 0.67722, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.68030, edges-ner-ontonotes_acc: 0.53822, edges-ner-ontonotes_precision: 0.86502, edges-ner-ontonotes_recall: 0.55641, edges-ner-ontonotes_f1: 0.67722
09/16 11:05:57 AM: macro_avg (for best val pass 60): edges-ner-ontonotes_loss: 0.03905, macro_avg: 0.87567, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.87061, edges-ner-ontonotes_acc: 0.80346, edges-ner-ontonotes_precision: 0.93212, edges-ner-ontonotes_recall: 0.82567, edges-ner-ontonotes_f1: 0.87567
09/16 11:05:57 AM: Evaluating...
09/16 11:05:57 AM: Loaded model state from ./experiments/ner-ontonotes-multiqa-top/run/edges-ner-ontonotes/model_state_target_train_val_60.best.th
09/16 11:05:57 AM: Evaluating on: edges-ner-ontonotes, split: val
09/16 11:06:27 AM: 	Task edges-ner-ontonotes: batch 228
09/16 11:06:29 AM: Task 'edges-ner-ontonotes': sorting predictions by 'idx'
09/16 11:06:29 AM: Finished evaluating on: edges-ner-ontonotes
09/16 11:06:29 AM: Task 'edges-ner-ontonotes': joining predictions with input split 'val'
09/16 11:06:29 AM: Task 'edges-ner-ontonotes': Wrote predictions to ./experiments/ner-ontonotes-multiqa-top/run
09/16 11:06:29 AM: Wrote all preds for split 'val' to ./experiments/ner-ontonotes-multiqa-top/run
09/16 11:06:29 AM: Evaluating on: edges-ner-ontonotes, split: test
09/16 11:06:49 AM: Task 'edges-ner-ontonotes': sorting predictions by 'idx'
09/16 11:06:49 AM: Finished evaluating on: edges-ner-ontonotes
09/16 11:06:50 AM: Task 'edges-ner-ontonotes': joining predictions with input split 'test'
09/16 11:06:51 AM: Task 'edges-ner-ontonotes': Wrote predictions to ./experiments/ner-ontonotes-multiqa-top/run
09/16 11:06:51 AM: Wrote all preds for split 'test' to ./experiments/ner-ontonotes-multiqa-top/run
09/16 11:06:51 AM: Writing results for split 'val' to ./experiments/ner-ontonotes-multiqa-top/results.tsv
09/16 11:06:51 AM: micro_avg: 0.000, macro_avg: 0.870, edges-ner-ontonotes_mcc: 0.865, edges-ner-ontonotes_acc: 0.797, edges-ner-ontonotes_precision: 0.929, edges-ner-ontonotes_recall: 0.819, edges-ner-ontonotes_f1: 0.870
09/16 11:06:51 AM: Done!
