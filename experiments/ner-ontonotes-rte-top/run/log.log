09/16 05:59:29 AM: Git branch: master
09/16 05:59:29 AM: Git SHA: 03401462a9f5f9b569ed41ceca48ecd81700406f
09/16 05:59:30 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/ner-ontonotes-rte-top/",
  "exp_name": "experiments/ner-ontonotes-rte-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/ner-ontonotes-rte-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/rte",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/ner-ontonotes-rte-top__run",
  "run_dir": "./experiments/ner-ontonotes-rte-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-ner-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 05:59:30 AM: Saved config to ./experiments/ner-ontonotes-rte-top/run/params.conf
09/16 05:59:30 AM: Using random seed 1234
09/16 05:59:53 AM: Git branch: master
09/16 05:59:53 AM: Git SHA: 03401462a9f5f9b569ed41ceca48ecd81700406f
09/16 05:59:54 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/ner-ontonotes-rte-top/",
  "exp_name": "experiments/ner-ontonotes-rte-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/ner-ontonotes-rte-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/rte",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/ner-ontonotes-rte-top__run",
  "run_dir": "./experiments/ner-ontonotes-rte-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-ner-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 05:59:54 AM: Saved config to ./experiments/ner-ontonotes-rte-top/run/params.conf
09/16 05:59:54 AM: Using random seed 1234
09/16 06:00:33 AM: Using GPU 0
09/16 06:00:33 AM: Loading tasks...
09/16 06:00:33 AM: Writing pre-preprocessed tasks to ./experiments/ner-ontonotes-rte-top/
09/16 06:00:33 AM: 	Creating task edges-ner-ontonotes from scratch.
09/16 06:00:33 AM: Using GPU 0
09/16 06:00:33 AM: Loading tasks...
09/16 06:00:33 AM: Writing pre-preprocessed tasks to ./experiments/ner-ontonotes-rte-top/
09/16 06:00:33 AM: 	Creating task edges-ner-ontonotes from scratch.
09/16 06:00:35 AM: Read=49706, Skip=66106, Total=115812 from ./probing_data/edges/ontonotes/ner/train.json.retokenized.bert-base-uncased
09/16 06:00:36 AM: Read=49706, Skip=66106, Total=115812 from ./probing_data/edges/ontonotes/ner/train.json.retokenized.bert-base-uncased
09/16 06:00:36 AM: Read=7610, Skip=8070, Total=15680 from ./probing_data/edges/ontonotes/ner/development.json.retokenized.bert-base-uncased
09/16 06:00:36 AM: Read=5099, Skip=7118, Total=12217 from ./probing_data/edges/ontonotes/ner/test.json.retokenized.bert-base-uncased
09/16 06:00:36 AM: Read=7610, Skip=8070, Total=15680 from ./probing_data/edges/ontonotes/ner/development.json.retokenized.bert-base-uncased
09/16 06:00:36 AM: Read=5099, Skip=7118, Total=12217 from ./probing_data/edges/ontonotes/ner/test.json.retokenized.bert-base-uncased
09/16 06:00:38 AM: 	Task 'edges-ner-ontonotes': |train|=49706 |val|=7610 |test|=5099
09/16 06:00:38 AM: 	Finished loading tasks: edges-ner-ontonotes.
09/16 06:00:38 AM: 	Building vocab from scratch.
09/16 06:00:38 AM: 	Counting units for task edges-ner-ontonotes.
09/16 06:00:39 AM: 	Task 'edges-ner-ontonotes': |train|=49706 |val|=7610 |test|=5099
09/16 06:00:39 AM: 	Finished loading tasks: edges-ner-ontonotes.
09/16 06:00:39 AM: 	Building vocab from scratch.
09/16 06:00:39 AM: 	Counting units for task edges-ner-ontonotes.
09/16 06:00:41 AM: 	Task 'edges-ner-ontonotes': adding vocab namespace 'edges-ner-ontonotes_labels'
09/16 06:00:41 AM: 	Task 'edges-ner-ontonotes': adding vocab namespace 'edges-ner-ontonotes_labels'
09/16 06:00:42 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmph6iev90f
09/16 06:00:42 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:43 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 06:00:43 AM: 	Saved vocab to ./experiments/ner-ontonotes-rte-top/vocab
09/16 06:00:43 AM: Loading token dictionary from ./experiments/ner-ontonotes-rte-top/vocab.
09/16 06:00:43 AM: 	Loaded vocab from ./experiments/ner-ontonotes-rte-top/vocab
09/16 06:00:43 AM: 	Vocab namespace edges-ner-ontonotes_labels: size 18
09/16 06:00:43 AM: 	Vocab namespace tokens: size 22840
09/16 06:00:43 AM: 	Vocab namespace bert_uncased: size 30524
09/16 06:00:43 AM: 	Vocab namespace chars: size 77
09/16 06:00:43 AM: 	Finished building vocab.
09/16 06:00:43 AM: 	Task edges-ner-ontonotes (train): Indexing from scratch.
09/16 06:00:43 AM: copying /tmp/tmph6iev90f to cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:43 AM: creating metadata file for /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:43 AM: removing temp file /tmp/tmph6iev90f
09/16 06:00:43 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:44 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 06:00:44 AM: vocabulary serialization directory ./experiments/ner-ontonotes-rte-top/vocab is not empty
09/16 06:00:44 AM: 	Saved vocab to ./experiments/ner-ontonotes-rte-top/vocab
09/16 06:00:44 AM: Loading token dictionary from ./experiments/ner-ontonotes-rte-top/vocab.
09/16 06:00:44 AM: 	Loaded vocab from ./experiments/ner-ontonotes-rte-top/vocab
09/16 06:00:44 AM: 	Vocab namespace edges-ner-ontonotes_labels: size 18
09/16 06:00:44 AM: 	Vocab namespace tokens: size 22840
09/16 06:00:44 AM: 	Vocab namespace bert_uncased: size 30524
09/16 06:00:44 AM: 	Vocab namespace chars: size 77
09/16 06:00:44 AM: 	Finished building vocab.
09/16 06:00:44 AM: 	Task 'edges-ner-ontonotes', split 'train': Found preprocessed copy in ./experiments/ner-ontonotes-rte-top/preproc/edges-ner-ontonotes__train_data
09/16 06:00:44 AM: 	Task edges-ner-ontonotes (val): Indexing from scratch.
09/16 06:00:46 AM: 	Task edges-ner-ontonotes (val): Saved 7610 instances to ./experiments/ner-ontonotes-rte-top/preproc/edges-ner-ontonotes__val_data
09/16 06:00:46 AM: 	Task edges-ner-ontonotes (test): Indexing from scratch.
09/16 06:00:48 AM: 	Task edges-ner-ontonotes (test): Saved 5099 instances to ./experiments/ner-ontonotes-rte-top/preproc/edges-ner-ontonotes__test_data
09/16 06:00:48 AM: 	Finished indexing tasks
09/16 06:00:48 AM: 	Creating trimmed target-only version of edges-ner-ontonotes train.
09/16 06:00:48 AM: 	  Training on 
09/16 06:00:48 AM: 	  Evaluating on edges-ner-ontonotes
09/16 06:00:48 AM: 	Finished loading tasks in 14.437s
09/16 06:00:48 AM: 	 Tasks: ['edges-ner-ontonotes']
09/16 06:00:48 AM: Building model...
09/16 06:00:48 AM: Using BERT model (bert-base-uncased).
09/16 06:00:48 AM: LOADING A FUNETUNED MODEL from: 
09/16 06:00:48 AM: models/rte
09/16 06:00:48 AM: loading configuration file models/rte/config.json
09/16 06:00:48 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "rte",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 06:00:48 AM: loading weights file models/rte/pytorch_model.bin
09/16 06:00:53 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpc0suksg5
09/16 06:00:56 AM: copying /tmp/tmpc0suksg5 to cache at ./experiments/ner-ontonotes-rte-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:56 AM: creating metadata file for ./experiments/ner-ontonotes-rte-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:56 AM: removing temp file /tmp/tmpc0suksg5
09/16 06:00:56 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/ner-ontonotes-rte-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:56 AM: Initializing parameters
09/16 06:00:56 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 06:00:56 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 06:00:56 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 06:00:56 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 06:00:56 AM: 	Task 'edges-ner-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-ner-ontonotes"
}
09/16 06:01:01 AM: 	Task edges-ner-ontonotes (train): Saved 49706 instances to ./experiments/ner-ontonotes-rte-top/preproc/edges-ner-ontonotes__train_data
09/16 06:01:01 AM: 	Task 'edges-ner-ontonotes', split 'val': Found preprocessed copy in ./experiments/ner-ontonotes-rte-top/preproc/edges-ner-ontonotes__val_data
09/16 06:01:01 AM: 	Task 'edges-ner-ontonotes', split 'test': Found preprocessed copy in ./experiments/ner-ontonotes-rte-top/preproc/edges-ner-ontonotes__test_data
09/16 06:01:01 AM: 	Finished indexing tasks
09/16 06:01:01 AM: 	Creating trimmed target-only version of edges-ner-ontonotes train.
09/16 06:01:01 AM: 	  Training on 
09/16 06:01:01 AM: 	  Evaluating on edges-ner-ontonotes
09/16 06:01:01 AM: 	Finished loading tasks in 28.234s
09/16 06:01:01 AM: 	 Tasks: ['edges-ner-ontonotes']
09/16 06:01:01 AM: Building model...
09/16 06:01:01 AM: Using BERT model (bert-base-uncased).
09/16 06:01:01 AM: LOADING A FUNETUNED MODEL from: 
09/16 06:01:01 AM: models/rte
09/16 06:01:01 AM: loading configuration file models/rte/config.json
09/16 06:01:01 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "rte",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 06:01:01 AM: loading weights file models/rte/pytorch_model.bin
09/16 06:01:07 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/ner-ontonotes-rte-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:01:07 AM: Initializing parameters
09/16 06:01:07 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 06:01:07 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 06:01:07 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 06:01:07 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 06:01:07 AM: 	Task 'edges-ner-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-ner-ontonotes"
}
09/16 06:01:24 AM: Model specification:
09/16 06:01:24 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-ner-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=18, bias=True)
    )
  )
)
09/16 06:01:24 AM: Model parameters:
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:24 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:24 AM: 	edges-ner-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 06:01:24 AM: 	edges-ner-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 06:01:24 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 9216 with torch.Size([18, 512])
09/16 06:01:24 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 18 with torch.Size([18])
09/16 06:01:24 AM: Total number of parameters: 109688338 (1.09688e+08)
09/16 06:01:24 AM: Number of trainable parameters: 206098 (206098)
09/16 06:01:24 AM: Finished building model in 36.494s
09/16 06:01:24 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-ner-ontonotes 

09/16 06:01:28 AM: patience = 9
09/16 06:01:28 AM: val_interval = 1000
09/16 06:01:28 AM: max_vals = 250
09/16 06:01:28 AM: cuda_device = 0
09/16 06:01:28 AM: grad_norm = 5.0
09/16 06:01:28 AM: grad_clipping = None
09/16 06:01:28 AM: lr_decay = 0.99
09/16 06:01:28 AM: min_lr = 1e-06
09/16 06:01:28 AM: keep_all_checkpoints = 0
09/16 06:01:28 AM: val_data_limit = 5000
09/16 06:01:28 AM: max_epochs = -1
09/16 06:01:28 AM: dec_val_scale = 250
09/16 06:01:28 AM: training_data_fraction = 1
09/16 06:01:28 AM: type = adam
09/16 06:01:28 AM: parameter_groups = None
09/16 06:01:28 AM: Number of trainable parameters: 206098
09/16 06:01:28 AM: infer_type_and_cast = True
09/16 06:01:28 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:28 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:28 AM: lr = 0.0001
09/16 06:01:28 AM: amsgrad = True
09/16 06:01:28 AM: type = reduce_on_plateau
09/16 06:01:28 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:28 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:28 AM: mode = max
09/16 06:01:28 AM: factor = 0.5
09/16 06:01:28 AM: patience = 3
09/16 06:01:28 AM: threshold = 0.0001
09/16 06:01:28 AM: threshold_mode = abs
09/16 06:01:28 AM: verbose = True
09/16 06:01:28 AM: type = adam
09/16 06:01:28 AM: parameter_groups = None
09/16 06:01:28 AM: Number of trainable parameters: 206098
09/16 06:01:28 AM: infer_type_and_cast = True
09/16 06:01:28 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:28 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:28 AM: lr = 0.0001
09/16 06:01:28 AM: amsgrad = True
09/16 06:01:28 AM: type = reduce_on_plateau
09/16 06:01:28 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:28 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:28 AM: mode = max
09/16 06:01:28 AM: factor = 0.5
09/16 06:01:28 AM: patience = 3
09/16 06:01:28 AM: threshold = 0.0001
09/16 06:01:28 AM: threshold_mode = abs
09/16 06:01:28 AM: verbose = True
09/16 06:01:28 AM: Starting training without restoring from a checkpoint.
09/16 06:01:28 AM: Training examples per task, before any subsampling: {'edges-ner-ontonotes': 49706}
09/16 06:01:28 AM: Beginning training with stopping criteria based on metric: edges-ner-ontonotes_f1
09/16 06:01:36 AM: Model specification:
09/16 06:01:36 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-ner-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=18, bias=True)
    )
  )
)
09/16 06:01:36 AM: Model parameters:
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	edges-ner-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 06:01:36 AM: 	edges-ner-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 06:01:36 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 9216 with torch.Size([18, 512])
09/16 06:01:36 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 18 with torch.Size([18])
09/16 06:01:36 AM: Total number of parameters: 109688338 (1.09688e+08)
09/16 06:01:36 AM: Number of trainable parameters: 206098 (206098)
09/16 06:01:36 AM: Finished building model in 34.325s
09/16 06:01:36 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-ner-ontonotes 

09/16 06:01:38 AM: Update 44: task edges-ner-ontonotes, batch 44 (44): mcc: 0.0088, acc: 0.0123, precision: 0.0620, recall: 0.0991, f1: 0.0763, edges-ner-ontonotes_loss: 0.4556
09/16 06:01:41 AM: patience = 9
09/16 06:01:41 AM: val_interval = 1000
09/16 06:01:41 AM: max_vals = 250
09/16 06:01:41 AM: cuda_device = 0
09/16 06:01:41 AM: grad_norm = 5.0
09/16 06:01:41 AM: grad_clipping = None
09/16 06:01:41 AM: lr_decay = 0.99
09/16 06:01:41 AM: min_lr = 1e-06
09/16 06:01:41 AM: keep_all_checkpoints = 0
09/16 06:01:41 AM: val_data_limit = 5000
09/16 06:01:41 AM: max_epochs = -1
09/16 06:01:41 AM: dec_val_scale = 250
09/16 06:01:41 AM: training_data_fraction = 1
09/16 06:01:41 AM: type = adam
09/16 06:01:41 AM: parameter_groups = None
09/16 06:01:41 AM: Number of trainable parameters: 206098
09/16 06:01:41 AM: infer_type_and_cast = True
09/16 06:01:41 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:41 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:41 AM: lr = 0.0001
09/16 06:01:41 AM: amsgrad = True
09/16 06:01:41 AM: type = reduce_on_plateau
09/16 06:01:41 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:41 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:41 AM: mode = max
09/16 06:01:41 AM: factor = 0.5
09/16 06:01:41 AM: patience = 3
09/16 06:01:41 AM: threshold = 0.0001
09/16 06:01:41 AM: threshold_mode = abs
09/16 06:01:41 AM: verbose = True
09/16 06:01:41 AM: type = adam
09/16 06:01:41 AM: parameter_groups = None
09/16 06:01:41 AM: Number of trainable parameters: 206098
09/16 06:01:41 AM: infer_type_and_cast = True
09/16 06:01:41 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:41 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:41 AM: lr = 0.0001
09/16 06:01:41 AM: amsgrad = True
09/16 06:01:41 AM: type = reduce_on_plateau
09/16 06:01:41 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:41 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:41 AM: mode = max
09/16 06:01:41 AM: factor = 0.5
09/16 06:01:41 AM: patience = 3
09/16 06:01:41 AM: threshold = 0.0001
09/16 06:01:41 AM: threshold_mode = abs
09/16 06:01:41 AM: verbose = True
09/16 06:01:41 AM: Starting training without restoring from a checkpoint.
09/16 06:01:41 AM: Training examples per task, before any subsampling: {'edges-ner-ontonotes': 49706}
09/16 06:01:41 AM: Beginning training with stopping criteria based on metric: edges-ner-ontonotes_f1
09/16 06:01:48 AM: Update 189: task edges-ner-ontonotes, batch 189 (189): mcc: 0.0914, acc: 0.0632, precision: 0.1850, recall: 0.0849, f1: 0.1164, edges-ner-ontonotes_loss: 0.2264
09/16 06:01:57 AM: Update 27: task edges-ner-ontonotes, batch 27 (27): mcc: 0.0106, acc: 0.0175, precision: 0.0617, recall: 0.1483, f1: 0.0872, edges-ner-ontonotes_loss: 0.5430
09/16 06:01:58 AM: Update 314: task edges-ner-ontonotes, batch 314 (314): mcc: 0.2891, acc: 0.1952, precision: 0.4724, recall: 0.2093, f1: 0.2900, edges-ner-ontonotes_loss: 0.1785
09/16 06:02:07 AM: Update 116: task edges-ner-ontonotes, batch 116 (116): mcc: 0.0161, acc: 0.0136, precision: 0.0746, recall: 0.0488, f1: 0.0590, edges-ner-ontonotes_loss: 0.2830
09/16 06:02:09 AM: Update 406: task edges-ner-ontonotes, batch 406 (406): mcc: 0.4161, acc: 0.2942, precision: 0.6256, recall: 0.3062, f1: 0.4112, edges-ner-ontonotes_loss: 0.1575
09/16 06:02:17 AM: Update 193: task edges-ner-ontonotes, batch 193 (193): mcc: 0.1000, acc: 0.0687, precision: 0.1982, recall: 0.0897, f1: 0.1235, edges-ner-ontonotes_loss: 0.2242
09/16 06:02:19 AM: Update 496: task edges-ner-ontonotes, batch 496 (496): mcc: 0.5035, acc: 0.3724, precision: 0.7118, recall: 0.3838, f1: 0.4987, edges-ner-ontonotes_loss: 0.1417
09/16 06:02:27 AM: Update 275: task edges-ner-ontonotes, batch 275 (275): mcc: 0.2306, acc: 0.1542, precision: 0.3921, recall: 0.1697, f1: 0.2369, edges-ner-ontonotes_loss: 0.1901
09/16 06:02:29 AM: Update 583: task edges-ner-ontonotes, batch 583 (583): mcc: 0.5599, acc: 0.4280, precision: 0.7596, recall: 0.4391, f1: 0.5565, edges-ner-ontonotes_loss: 0.1301
09/16 06:02:37 AM: Update 315: task edges-ner-ontonotes, batch 315 (315): mcc: 0.2927, acc: 0.1977, precision: 0.4773, recall: 0.2117, f1: 0.2934, edges-ner-ontonotes_loss: 0.1783
09/16 06:02:39 AM: Update 670: task edges-ner-ontonotes, batch 670 (670): mcc: 0.6049, acc: 0.4743, precision: 0.7949, recall: 0.4854, f1: 0.6028, edges-ner-ontonotes_loss: 0.1206
09/16 06:02:48 AM: Update 389: task edges-ner-ontonotes, batch 389 (389): mcc: 0.3978, acc: 0.2787, precision: 0.6059, recall: 0.2911, f1: 0.3932, edges-ner-ontonotes_loss: 0.1609
09/16 06:02:49 AM: Update 749: task edges-ner-ontonotes, batch 749 (749): mcc: 0.6394, acc: 0.5120, precision: 0.8193, recall: 0.5232, f1: 0.6386, edges-ner-ontonotes_loss: 0.1132
09/16 06:02:58 AM: Update 464: task edges-ner-ontonotes, batch 464 (464): mcc: 0.4744, acc: 0.3454, precision: 0.6847, recall: 0.3570, f1: 0.4693, edges-ner-ontonotes_loss: 0.1469
09/16 06:02:59 AM: Update 832: task edges-ner-ontonotes, batch 832 (832): mcc: 0.6664, acc: 0.5429, precision: 0.8360, recall: 0.5545, f1: 0.6668, edges-ner-ontonotes_loss: 0.1066
09/16 06:03:08 AM: Update 534: task edges-ner-ontonotes, batch 534 (534): mcc: 0.5311, acc: 0.3991, precision: 0.7361, recall: 0.4104, f1: 0.5270, edges-ner-ontonotes_loss: 0.1364
09/16 06:03:09 AM: Update 916: task edges-ner-ontonotes, batch 916 (916): mcc: 0.6900, acc: 0.5709, precision: 0.8498, recall: 0.5826, f1: 0.6913, edges-ner-ontonotes_loss: 0.1007
09/16 06:03:18 AM: Update 611: task edges-ner-ontonotes, batch 611 (611): mcc: 0.5752, acc: 0.4436, precision: 0.7720, recall: 0.4546, f1: 0.5722, edges-ner-ontonotes_loss: 0.1268
09/16 06:03:19 AM: Update 986: task edges-ner-ontonotes, batch 986 (986): mcc: 0.7060, acc: 0.5904, precision: 0.8585, recall: 0.6025, f1: 0.7080, edges-ner-ontonotes_loss: 0.0966
09/16 06:03:20 AM: ***** Step 1000 / Validation 1 *****
09/16 06:03:20 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:03:20 AM: Validating...
09/16 06:03:28 AM: Update 659: task edges-ner-ontonotes, batch 659 (659): mcc: 0.5987, acc: 0.4678, precision: 0.7903, recall: 0.4789, f1: 0.5964, edges-ner-ontonotes_loss: 0.1217
09/16 06:03:38 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.8409, acc: 0.7816, precision: 0.9110, recall: 0.7913, f1: 0.8469, edges-ner-ontonotes_loss: 0.0544
09/16 06:03:38 AM: Update 756: task edges-ner-ontonotes, batch 756 (756): mcc: 0.6412, acc: 0.5139, precision: 0.8205, recall: 0.5251, f1: 0.6404, edges-ner-ontonotes_loss: 0.1127
09/16 06:03:48 AM: Update 821: task edges-ner-ontonotes, batch 821 (821): mcc: 0.6631, acc: 0.5391, precision: 0.8339, recall: 0.5506, f1: 0.6633, edges-ner-ontonotes_loss: 0.1075
09/16 06:03:49 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.8633, acc: 0.8070, precision: 0.9250, recall: 0.8189, f1: 0.8687, edges-ner-ontonotes_loss: 0.0484
09/16 06:03:56 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:03:56 AM: Best result seen so far for micro.
09/16 06:03:56 AM: Best result seen so far for macro.
09/16 06:03:56 AM: Updating LR scheduler:
09/16 06:03:56 AM: 	Best result seen so far for macro_avg: 0.877
09/16 06:03:56 AM: 	# validation passes without improvement: 0
09/16 06:03:56 AM: edges-ner-ontonotes_loss: training: 0.095819 validation: 0.045199
09/16 06:03:56 AM: macro_avg: validation: 0.876833
09/16 06:03:56 AM: micro_avg: validation: 0.000000
09/16 06:03:56 AM: edges-ner-ontonotes_mcc: training: 0.708951 validation: 0.871590
09/16 06:03:56 AM: edges-ner-ontonotes_acc: training: 0.593937 validation: 0.817713
09/16 06:03:56 AM: edges-ner-ontonotes_precision: training: 0.859982 validation: 0.929652
09/16 06:03:56 AM: edges-ner-ontonotes_recall: training: 0.606146 validation: 0.829694
09/16 06:03:56 AM: edges-ner-ontonotes_f1: training: 0.711090 validation: 0.876833
09/16 06:03:56 AM: Global learning rate: 0.0001
09/16 06:03:56 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:03:58 AM: Update 881: task edges-ner-ontonotes, batch 881 (881): mcc: 0.6802, acc: 0.5592, precision: 0.8442, recall: 0.5708, f1: 0.6811, edges-ner-ontonotes_loss: 0.1030
09/16 06:03:59 AM: Update 1023: task edges-ner-ontonotes, batch 23 (1023): mcc: 0.8865, acc: 0.8305, precision: 0.9398, recall: 0.8473, f1: 0.8912, edges-ner-ontonotes_loss: 0.0399
09/16 06:04:10 AM: Update 1119: task edges-ner-ontonotes, batch 119 (1119): mcc: 0.8828, acc: 0.8268, precision: 0.9381, recall: 0.8423, f1: 0.8876, edges-ner-ontonotes_loss: 0.0407
09/16 06:04:10 AM: Update 940: task edges-ner-ontonotes, batch 940 (940): mcc: 0.6957, acc: 0.5777, precision: 0.8529, recall: 0.5896, f1: 0.6972, edges-ner-ontonotes_loss: 0.0992
09/16 06:04:19 AM: ***** Step 1000 / Validation 1 *****
09/16 06:04:19 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:04:19 AM: Validating...
09/16 06:04:20 AM: Update 1197: task edges-ner-ontonotes, batch 197 (1197): mcc: 0.8884, acc: 0.8333, precision: 0.9423, recall: 0.8485, f1: 0.8930, edges-ner-ontonotes_loss: 0.0392
09/16 06:04:20 AM: Evaluate: task edges-ner-ontonotes, batch 8 (157): mcc: 0.7380, acc: 0.6635, precision: 0.8421, recall: 0.6692, f1: 0.7458, edges-ner-ontonotes_loss: 0.0821
09/16 06:04:30 AM: Evaluate: task edges-ner-ontonotes, batch 59 (157): mcc: 0.8372, acc: 0.7770, precision: 0.9090, recall: 0.7864, f1: 0.8432, edges-ner-ontonotes_loss: 0.0552
09/16 06:04:30 AM: Update 1253: task edges-ner-ontonotes, batch 253 (1253): mcc: 0.8857, acc: 0.8299, precision: 0.9399, recall: 0.8459, f1: 0.8904, edges-ner-ontonotes_loss: 0.0390
09/16 06:04:40 AM: Evaluate: task edges-ner-ontonotes, batch 97 (157): mcc: 0.8574, acc: 0.7994, precision: 0.9228, recall: 0.8104, f1: 0.8629, edges-ner-ontonotes_loss: 0.0503
09/16 06:04:40 AM: Update 1331: task edges-ner-ontonotes, batch 331 (1331): mcc: 0.8764, acc: 0.8168, precision: 0.9359, recall: 0.8327, f1: 0.8813, edges-ner-ontonotes_loss: 0.0425
09/16 06:04:50 AM: Evaluate: task edges-ner-ontonotes, batch 135 (157): mcc: 0.8728, acc: 0.8186, precision: 0.9319, recall: 0.8297, f1: 0.8779, edges-ner-ontonotes_loss: 0.0459
09/16 06:04:51 AM: Update 1409: task edges-ner-ontonotes, batch 409 (1409): mcc: 0.8711, acc: 0.8091, precision: 0.9337, recall: 0.8251, f1: 0.8761, edges-ner-ontonotes_loss: 0.0442
09/16 06:04:54 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:04:54 AM: Best result seen so far for micro.
09/16 06:04:54 AM: Best result seen so far for macro.
09/16 06:04:54 AM: Updating LR scheduler:
09/16 06:04:54 AM: 	Best result seen so far for macro_avg: 0.877
09/16 06:04:54 AM: 	# validation passes without improvement: 0
09/16 06:04:54 AM: edges-ner-ontonotes_loss: training: 0.095819 validation: 0.045199
09/16 06:04:54 AM: macro_avg: validation: 0.876833
09/16 06:04:54 AM: micro_avg: validation: 0.000000
09/16 06:04:54 AM: edges-ner-ontonotes_mcc: training: 0.708951 validation: 0.871590
09/16 06:04:54 AM: edges-ner-ontonotes_acc: training: 0.593937 validation: 0.817713
09/16 06:04:54 AM: edges-ner-ontonotes_precision: training: 0.859982 validation: 0.929652
09/16 06:04:54 AM: edges-ner-ontonotes_recall: training: 0.606146 validation: 0.829694
09/16 06:04:54 AM: edges-ner-ontonotes_f1: training: 0.711090 validation: 0.876833
09/16 06:04:54 AM: Global learning rate: 0.0001
09/16 06:04:54 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:05:00 AM: Update 1044: task edges-ner-ontonotes, batch 44 (1044): mcc: 0.8860, acc: 0.8298, precision: 0.9409, recall: 0.8455, f1: 0.8906, edges-ner-ontonotes_loss: 0.0399
09/16 06:05:01 AM: Update 1487: task edges-ner-ontonotes, batch 487 (1487): mcc: 0.8691, acc: 0.8064, precision: 0.9327, recall: 0.8224, f1: 0.8741, edges-ner-ontonotes_loss: 0.0446
09/16 06:05:10 AM: Update 1122: task edges-ner-ontonotes, batch 122 (1122): mcc: 0.8828, acc: 0.8269, precision: 0.9379, recall: 0.8424, f1: 0.8876, edges-ner-ontonotes_loss: 0.0406
09/16 06:05:13 AM: Update 1562: task edges-ner-ontonotes, batch 562 (1562): mcc: 0.8667, acc: 0.8038, precision: 0.9309, recall: 0.8199, f1: 0.8718, edges-ner-ontonotes_loss: 0.0453
09/16 06:05:20 AM: Update 1198: task edges-ner-ontonotes, batch 198 (1198): mcc: 0.8883, acc: 0.8334, precision: 0.9422, recall: 0.8486, f1: 0.8929, edges-ner-ontonotes_loss: 0.0392
09/16 06:05:23 AM: Update 1655: task edges-ner-ontonotes, batch 655 (1655): mcc: 0.8653, acc: 0.8020, precision: 0.9299, recall: 0.8180, f1: 0.8704, edges-ner-ontonotes_loss: 0.0453
09/16 06:05:30 AM: Update 1259: task edges-ner-ontonotes, batch 259 (1259): mcc: 0.8837, acc: 0.8273, precision: 0.9390, recall: 0.8432, f1: 0.8885, edges-ner-ontonotes_loss: 0.0394
09/16 06:05:35 AM: Update 1760: task edges-ner-ontonotes, batch 760 (1760): mcc: 0.8648, acc: 0.8014, precision: 0.9297, recall: 0.8174, f1: 0.8699, edges-ner-ontonotes_loss: 0.0452
09/16 06:05:41 AM: Update 1333: task edges-ner-ontonotes, batch 333 (1333): mcc: 0.8762, acc: 0.8164, precision: 0.9358, recall: 0.8324, f1: 0.8811, edges-ner-ontonotes_loss: 0.0425
09/16 06:05:45 AM: Update 1849: task edges-ner-ontonotes, batch 849 (1849): mcc: 0.8657, acc: 0.8026, precision: 0.9304, recall: 0.8184, f1: 0.8708, edges-ner-ontonotes_loss: 0.0445
09/16 06:05:51 AM: Update 1417: task edges-ner-ontonotes, batch 417 (1417): mcc: 0.8709, acc: 0.8088, precision: 0.9336, recall: 0.8249, f1: 0.8759, edges-ner-ontonotes_loss: 0.0442
09/16 06:05:55 AM: Update 1915: task edges-ner-ontonotes, batch 915 (1915): mcc: 0.8667, acc: 0.8040, precision: 0.9306, recall: 0.8200, f1: 0.8718, edges-ner-ontonotes_loss: 0.0441
09/16 06:06:01 AM: Update 1498: task edges-ner-ontonotes, batch 498 (1498): mcc: 0.8686, acc: 0.8057, precision: 0.9324, recall: 0.8218, f1: 0.8736, edges-ner-ontonotes_loss: 0.0447
09/16 06:06:07 AM: ***** Step 2000 / Validation 2 *****
09/16 06:06:07 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:06:10 AM: Validating...
09/16 06:06:10 AM: Evaluate: task edges-ner-ontonotes, batch 1 (157): mcc: 0.7922, acc: 0.6885, precision: 0.9333, recall: 0.6885, f1: 0.7925, edges-ner-ontonotes_loss: 0.0599
09/16 06:06:11 AM: Update 1565: task edges-ner-ontonotes, batch 565 (1565): mcc: 0.8666, acc: 0.8036, precision: 0.9308, recall: 0.8197, f1: 0.8717, edges-ner-ontonotes_loss: 0.0453
09/16 06:06:20 AM: Evaluate: task edges-ner-ontonotes, batch 71 (157): mcc: 0.8822, acc: 0.8327, precision: 0.9354, recall: 0.8436, f1: 0.8872, edges-ner-ontonotes_loss: 0.0369
09/16 06:06:21 AM: Update 1623: task edges-ner-ontonotes, batch 623 (1623): mcc: 0.8658, acc: 0.8027, precision: 0.9302, recall: 0.8187, f1: 0.8709, edges-ner-ontonotes_loss: 0.0453
09/16 06:06:30 AM: Evaluate: task edges-ner-ontonotes, batch 130 (157): mcc: 0.9006, acc: 0.8547, precision: 0.9469, recall: 0.8666, f1: 0.9049, edges-ner-ontonotes_loss: 0.0324
09/16 06:06:31 AM: Update 1679: task edges-ner-ontonotes, batch 679 (1679): mcc: 0.8653, acc: 0.8019, precision: 0.9302, recall: 0.8179, f1: 0.8704, edges-ner-ontonotes_loss: 0.0452
09/16 06:06:35 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:06:35 AM: Best result seen so far for macro.
09/16 06:06:35 AM: Updating LR scheduler:
09/16 06:06:35 AM: 	Best result seen so far for macro_avg: 0.907
09/16 06:06:35 AM: 	# validation passes without improvement: 0
09/16 06:06:35 AM: edges-ner-ontonotes_loss: training: 0.043317 validation: 0.031422
09/16 06:06:35 AM: macro_avg: validation: 0.907403
09/16 06:06:35 AM: micro_avg: validation: 0.000000
09/16 06:06:35 AM: edges-ner-ontonotes_mcc: training: 0.868842 validation: 0.903085
09/16 06:06:35 AM: edges-ner-ontonotes_acc: training: 0.807363 validation: 0.858129
09/16 06:06:35 AM: edges-ner-ontonotes_precision: training: 0.930988 validation: 0.947138
09/16 06:06:35 AM: edges-ner-ontonotes_recall: training: 0.823516 validation: 0.870867
09/16 06:06:35 AM: edges-ner-ontonotes_f1: training: 0.873960 validation: 0.907403
09/16 06:06:35 AM: Global learning rate: 0.0001
09/16 06:06:35 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:06:40 AM: Update 2051: task edges-ner-ontonotes, batch 51 (2051): mcc: 0.8965, acc: 0.8450, precision: 0.9436, recall: 0.8621, f1: 0.9010, edges-ner-ontonotes_loss: 0.0324
09/16 06:06:42 AM: Update 1750: task edges-ner-ontonotes, batch 750 (1750): mcc: 0.8649, acc: 0.8015, precision: 0.9298, recall: 0.8175, f1: 0.8700, edges-ner-ontonotes_loss: 0.0451
09/16 06:06:51 AM: Update 2142: task edges-ner-ontonotes, batch 142 (2142): mcc: 0.8973, acc: 0.8487, precision: 0.9430, recall: 0.8641, f1: 0.9018, edges-ner-ontonotes_loss: 0.0327
09/16 06:06:52 AM: Update 1827: task edges-ner-ontonotes, batch 827 (1827): mcc: 0.8654, acc: 0.8021, precision: 0.9301, recall: 0.8180, f1: 0.8705, edges-ner-ontonotes_loss: 0.0447
09/16 06:07:01 AM: Update 2219: task edges-ner-ontonotes, batch 219 (2219): mcc: 0.8984, acc: 0.8506, precision: 0.9428, recall: 0.8663, f1: 0.9030, edges-ner-ontonotes_loss: 0.0323
09/16 06:07:02 AM: Update 1886: task edges-ner-ontonotes, batch 886 (1886): mcc: 0.8659, acc: 0.8030, precision: 0.9301, recall: 0.8190, f1: 0.8710, edges-ner-ontonotes_loss: 0.0444
09/16 06:07:11 AM: Update 2297: task edges-ner-ontonotes, batch 297 (2297): mcc: 0.9027, acc: 0.8556, precision: 0.9454, recall: 0.8718, f1: 0.9071, edges-ner-ontonotes_loss: 0.0311
09/16 06:07:12 AM: Update 1960: task edges-ner-ontonotes, batch 960 (1960): mcc: 0.8678, acc: 0.8057, precision: 0.9308, recall: 0.8218, f1: 0.8729, edges-ner-ontonotes_loss: 0.0436
09/16 06:07:18 AM: ***** Step 2000 / Validation 2 *****
09/16 06:07:18 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:07:18 AM: Validating...
09/16 06:07:21 AM: Update 2371: task edges-ner-ontonotes, batch 371 (2371): mcc: 0.9055, acc: 0.8598, precision: 0.9464, recall: 0.8761, f1: 0.9099, edges-ner-ontonotes_loss: 0.0302
09/16 06:07:22 AM: Evaluate: task edges-ner-ontonotes, batch 28 (157): mcc: 0.8464, acc: 0.7911, precision: 0.9114, recall: 0.8008, f1: 0.8525, edges-ner-ontonotes_loss: 0.0451
09/16 06:07:31 AM: Update 2427: task edges-ner-ontonotes, batch 427 (2427): mcc: 0.9068, acc: 0.8615, precision: 0.9466, recall: 0.8782, f1: 0.9111, edges-ner-ontonotes_loss: 0.0297
09/16 06:07:32 AM: Evaluate: task edges-ner-ontonotes, batch 88 (157): mcc: 0.8915, acc: 0.8435, precision: 0.9413, recall: 0.8551, f1: 0.8961, edges-ner-ontonotes_loss: 0.0346
09/16 06:07:43 AM: Evaluate: task edges-ner-ontonotes, batch 136 (157): mcc: 0.9034, acc: 0.8582, precision: 0.9487, recall: 0.8700, f1: 0.9077, edges-ner-ontonotes_loss: 0.0318
09/16 06:07:43 AM: Update 2484: task edges-ner-ontonotes, batch 484 (2484): mcc: 0.9086, acc: 0.8639, precision: 0.9476, recall: 0.8806, f1: 0.9129, edges-ner-ontonotes_loss: 0.0293
09/16 06:07:47 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:07:47 AM: Best result seen so far for macro.
09/16 06:07:47 AM: Updating LR scheduler:
09/16 06:07:47 AM: 	Best result seen so far for macro_avg: 0.907
09/16 06:07:47 AM: 	# validation passes without improvement: 0
09/16 06:07:47 AM: edges-ner-ontonotes_loss: training: 0.043317 validation: 0.031422
09/16 06:07:47 AM: macro_avg: validation: 0.907403
09/16 06:07:47 AM: micro_avg: validation: 0.000000
09/16 06:07:47 AM: edges-ner-ontonotes_mcc: training: 0.868842 validation: 0.903085
09/16 06:07:47 AM: edges-ner-ontonotes_acc: training: 0.807363 validation: 0.858129
09/16 06:07:47 AM: edges-ner-ontonotes_precision: training: 0.930988 validation: 0.947138
09/16 06:07:47 AM: edges-ner-ontonotes_recall: training: 0.823516 validation: 0.870867
09/16 06:07:47 AM: edges-ner-ontonotes_f1: training: 0.873960 validation: 0.907403
09/16 06:07:47 AM: Global learning rate: 0.0001
09/16 06:07:47 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:07:53 AM: Update 2046: task edges-ner-ontonotes, batch 46 (2046): mcc: 0.8951, acc: 0.8434, precision: 0.9425, recall: 0.8605, f1: 0.8997, edges-ner-ontonotes_loss: 0.0327
09/16 06:07:53 AM: Update 2543: task edges-ner-ontonotes, batch 543 (2543): mcc: 0.9085, acc: 0.8636, precision: 0.9473, recall: 0.8807, f1: 0.9128, edges-ner-ontonotes_loss: 0.0292
09/16 06:08:03 AM: Update 2624: task edges-ner-ontonotes, batch 624 (2624): mcc: 0.9095, acc: 0.8648, precision: 0.9474, recall: 0.8824, f1: 0.9138, edges-ner-ontonotes_loss: 0.0290
09/16 06:08:04 AM: Update 2116: task edges-ner-ontonotes, batch 116 (2116): mcc: 0.8962, acc: 0.8461, precision: 0.9433, recall: 0.8618, f1: 0.9007, edges-ner-ontonotes_loss: 0.0328
09/16 06:08:13 AM: Update 2703: task edges-ner-ontonotes, batch 703 (2703): mcc: 0.9101, acc: 0.8656, precision: 0.9473, recall: 0.8836, f1: 0.9144, edges-ner-ontonotes_loss: 0.0288
09/16 06:08:16 AM: Update 2183: task edges-ner-ontonotes, batch 183 (2183): mcc: 0.8966, acc: 0.8484, precision: 0.9422, recall: 0.8636, f1: 0.9012, edges-ner-ontonotes_loss: 0.0328
09/16 06:08:23 AM: Update 2793: task edges-ner-ontonotes, batch 793 (2793): mcc: 0.9117, acc: 0.8675, precision: 0.9480, recall: 0.8859, f1: 0.9159, edges-ner-ontonotes_loss: 0.0283
09/16 06:08:26 AM: Update 2254: task edges-ner-ontonotes, batch 254 (2254): mcc: 0.9017, acc: 0.8547, precision: 0.9448, recall: 0.8706, f1: 0.9062, edges-ner-ontonotes_loss: 0.0316
09/16 06:08:34 AM: Update 2854: task edges-ner-ontonotes, batch 854 (2854): mcc: 0.9099, acc: 0.8650, precision: 0.9472, recall: 0.8833, f1: 0.9141, edges-ner-ontonotes_loss: 0.0290
09/16 06:08:36 AM: Update 2323: task edges-ner-ontonotes, batch 323 (2323): mcc: 0.9043, acc: 0.8579, precision: 0.9460, recall: 0.8742, f1: 0.9087, edges-ner-ontonotes_loss: 0.0306
09/16 06:08:44 AM: Update 2930: task edges-ner-ontonotes, batch 930 (2930): mcc: 0.9072, acc: 0.8615, precision: 0.9453, recall: 0.8801, f1: 0.9116, edges-ner-ontonotes_loss: 0.0300
09/16 06:08:46 AM: Update 2392: task edges-ner-ontonotes, batch 392 (2392): mcc: 0.9056, acc: 0.8599, precision: 0.9462, recall: 0.8763, f1: 0.9099, edges-ner-ontonotes_loss: 0.0301
09/16 06:08:51 AM: ***** Step 3000 / Validation 3 *****
09/16 06:08:51 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:08:51 AM: Validating...
09/16 06:08:54 AM: Evaluate: task edges-ner-ontonotes, batch 19 (157): mcc: 0.8543, acc: 0.7973, precision: 0.9067, recall: 0.8194, f1: 0.8609, edges-ner-ontonotes_loss: 0.0390
09/16 06:08:58 AM: Update 2451: task edges-ner-ontonotes, batch 451 (2451): mcc: 0.9079, acc: 0.8629, precision: 0.9471, recall: 0.8798, f1: 0.9122, edges-ner-ontonotes_loss: 0.0295
09/16 06:09:04 AM: Evaluate: task edges-ner-ontonotes, batch 82 (157): mcc: 0.9009, acc: 0.8572, precision: 0.9406, recall: 0.8730, f1: 0.9055, edges-ner-ontonotes_loss: 0.0325
09/16 06:09:10 AM: Update 2496: task edges-ner-ontonotes, batch 496 (2496): mcc: 0.9086, acc: 0.8638, precision: 0.9476, recall: 0.8806, f1: 0.9128, edges-ner-ontonotes_loss: 0.0292
09/16 06:09:14 AM: Evaluate: task edges-ner-ontonotes, batch 140 (157): mcc: 0.9159, acc: 0.8767, precision: 0.9511, recall: 0.8907, f1: 0.9199, edges-ner-ontonotes_loss: 0.0281
09/16 06:09:17 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:09:17 AM: Best result seen so far for macro.
09/16 06:09:17 AM: Updating LR scheduler:
09/16 06:09:17 AM: 	Best result seen so far for macro_avg: 0.920
09/16 06:09:17 AM: 	# validation passes without improvement: 0
09/16 06:09:17 AM: edges-ner-ontonotes_loss: training: 0.030706 validation: 0.027691
09/16 06:09:17 AM: macro_avg: validation: 0.919873
09/16 06:09:17 AM: micro_avg: validation: 0.000000
09/16 06:09:17 AM: edges-ner-ontonotes_mcc: training: 0.905579 validation: 0.915860
09/16 06:09:17 AM: edges-ner-ontonotes_acc: training: 0.859427 validation: 0.876403
09/16 06:09:17 AM: edges-ner-ontonotes_precision: training: 0.944462 validation: 0.950724
09/16 06:09:17 AM: edges-ner-ontonotes_recall: training: 0.877956 validation: 0.890961
09/16 06:09:17 AM: edges-ner-ontonotes_f1: training: 0.909995 validation: 0.919873
09/16 06:09:17 AM: Global learning rate: 0.0001
09/16 06:09:17 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:09:21 AM: Update 2553: task edges-ner-ontonotes, batch 553 (2553): mcc: 0.9088, acc: 0.8640, precision: 0.9474, recall: 0.8811, f1: 0.9130, edges-ner-ontonotes_loss: 0.0292
09/16 06:09:24 AM: Update 3062: task edges-ner-ontonotes, batch 62 (3062): mcc: 0.8732, acc: 0.8175, precision: 0.9237, recall: 0.8380, f1: 0.8788, edges-ner-ontonotes_loss: 0.0425
09/16 06:09:31 AM: Update 2625: task edges-ner-ontonotes, batch 625 (2625): mcc: 0.9096, acc: 0.8649, precision: 0.9475, recall: 0.8825, f1: 0.9138, edges-ner-ontonotes_loss: 0.0289
09/16 06:09:34 AM: Update 3130: task edges-ner-ontonotes, batch 130 (3130): mcc: 0.8747, acc: 0.8202, precision: 0.9254, recall: 0.8393, f1: 0.8802, edges-ner-ontonotes_loss: 0.0419
09/16 06:09:41 AM: Update 2703: task edges-ner-ontonotes, batch 703 (2703): mcc: 0.9101, acc: 0.8656, precision: 0.9473, recall: 0.8836, f1: 0.9144, edges-ner-ontonotes_loss: 0.0288
09/16 06:09:44 AM: Update 3222: task edges-ner-ontonotes, batch 222 (3222): mcc: 0.8758, acc: 0.8212, precision: 0.9256, recall: 0.8411, f1: 0.8813, edges-ner-ontonotes_loss: 0.0403
09/16 06:09:51 AM: Update 2776: task edges-ner-ontonotes, batch 776 (2776): mcc: 0.9114, acc: 0.8671, precision: 0.9480, recall: 0.8853, f1: 0.9156, edges-ner-ontonotes_loss: 0.0284
09/16 06:09:54 AM: Update 3318: task edges-ner-ontonotes, batch 318 (3318): mcc: 0.8801, acc: 0.8267, precision: 0.9274, recall: 0.8471, f1: 0.8855, edges-ner-ontonotes_loss: 0.0384
09/16 06:10:01 AM: Update 2832: task edges-ner-ontonotes, batch 832 (2832): mcc: 0.9106, acc: 0.8661, precision: 0.9474, recall: 0.8845, f1: 0.9149, edges-ner-ontonotes_loss: 0.0286
09/16 06:10:06 AM: Update 3412: task edges-ner-ontonotes, batch 412 (3412): mcc: 0.8823, acc: 0.8293, precision: 0.9289, recall: 0.8498, f1: 0.8876, edges-ner-ontonotes_loss: 0.0375
09/16 06:10:11 AM: Update 2908: task edges-ner-ontonotes, batch 908 (2908): mcc: 0.9079, acc: 0.8623, precision: 0.9458, recall: 0.8809, f1: 0.9122, edges-ner-ontonotes_loss: 0.0297
09/16 06:10:16 AM: Update 3484: task edges-ner-ontonotes, batch 484 (3484): mcc: 0.8850, acc: 0.8336, precision: 0.9301, recall: 0.8537, f1: 0.8903, edges-ner-ontonotes_loss: 0.0367
09/16 06:10:22 AM: Update 2991: task edges-ner-ontonotes, batch 991 (2991): mcc: 0.9058, acc: 0.8597, precision: 0.9446, recall: 0.8782, f1: 0.9102, edges-ner-ontonotes_loss: 0.0306
09/16 06:10:24 AM: ***** Step 3000 / Validation 3 *****
09/16 06:10:24 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:10:24 AM: Validating...
09/16 06:10:29 AM: Update 3565: task edges-ner-ontonotes, batch 565 (3565): mcc: 0.8884, acc: 0.8385, precision: 0.9322, recall: 0.8581, f1: 0.8936, edges-ner-ontonotes_loss: 0.0357
09/16 06:10:33 AM: Evaluate: task edges-ner-ontonotes, batch 57 (157): mcc: 0.8942, acc: 0.8498, precision: 0.9330, recall: 0.8679, f1: 0.8993, edges-ner-ontonotes_loss: 0.0341
09/16 06:10:40 AM: Update 3628: task edges-ner-ontonotes, batch 628 (3628): mcc: 0.8916, acc: 0.8425, precision: 0.9340, recall: 0.8622, f1: 0.8967, edges-ner-ontonotes_loss: 0.0349
09/16 06:10:43 AM: Evaluate: task edges-ner-ontonotes, batch 112 (157): mcc: 0.9068, acc: 0.8651, precision: 0.9447, recall: 0.8799, f1: 0.9111, edges-ner-ontonotes_loss: 0.0305
09/16 06:10:51 AM: Update 3687: task edges-ner-ontonotes, batch 687 (3687): mcc: 0.8932, acc: 0.8447, precision: 0.9349, recall: 0.8643, f1: 0.8982, edges-ner-ontonotes_loss: 0.0344
09/16 06:10:52 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:10:52 AM: Best result seen so far for macro.
09/16 06:10:52 AM: Updating LR scheduler:
09/16 06:10:52 AM: 	Best result seen so far for macro_avg: 0.920
09/16 06:10:52 AM: 	# validation passes without improvement: 0
09/16 06:10:52 AM: edges-ner-ontonotes_loss: training: 0.030706 validation: 0.027691
09/16 06:10:52 AM: macro_avg: validation: 0.919873
09/16 06:10:52 AM: micro_avg: validation: 0.000000
09/16 06:10:52 AM: edges-ner-ontonotes_mcc: training: 0.905579 validation: 0.915860
09/16 06:10:52 AM: edges-ner-ontonotes_acc: training: 0.859427 validation: 0.876403
09/16 06:10:52 AM: edges-ner-ontonotes_precision: training: 0.944462 validation: 0.950724
09/16 06:10:52 AM: edges-ner-ontonotes_recall: training: 0.877956 validation: 0.890961
09/16 06:10:52 AM: edges-ner-ontonotes_f1: training: 0.909995 validation: 0.919873
09/16 06:10:52 AM: Global learning rate: 0.0001
09/16 06:10:52 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:10:53 AM: Update 3005: task edges-ner-ontonotes, batch 5 (3005): mcc: 0.8902, acc: 0.8412, precision: 0.9169, recall: 0.8759, f1: 0.8959, edges-ner-ontonotes_loss: 0.0380
09/16 06:11:01 AM: Update 3747: task edges-ner-ontonotes, batch 747 (3747): mcc: 0.8954, acc: 0.8475, precision: 0.9360, recall: 0.8673, f1: 0.9003, edges-ner-ontonotes_loss: 0.0338
09/16 06:11:03 AM: Update 3088: task edges-ner-ontonotes, batch 88 (3088): mcc: 0.8741, acc: 0.8205, precision: 0.9235, recall: 0.8399, f1: 0.8797, edges-ner-ontonotes_loss: 0.0416
09/16 06:11:11 AM: Update 3834: task edges-ner-ontonotes, batch 834 (3834): mcc: 0.8992, acc: 0.8527, precision: 0.9379, recall: 0.8725, f1: 0.9040, edges-ner-ontonotes_loss: 0.0328
09/16 06:11:13 AM: Update 3142: task edges-ner-ontonotes, batch 142 (3142): mcc: 0.8752, acc: 0.8209, precision: 0.9253, recall: 0.8403, f1: 0.8807, edges-ner-ontonotes_loss: 0.0418
09/16 06:11:21 AM: Update 3923: task edges-ner-ontonotes, batch 923 (3923): mcc: 0.9020, acc: 0.8566, precision: 0.9392, recall: 0.8764, f1: 0.9067, edges-ner-ontonotes_loss: 0.0319
09/16 06:11:24 AM: Update 3217: task edges-ner-ontonotes, batch 217 (3217): mcc: 0.8757, acc: 0.8210, precision: 0.9255, recall: 0.8409, f1: 0.8812, edges-ner-ontonotes_loss: 0.0405
09/16 06:11:29 AM: ***** Step 4000 / Validation 4 *****
09/16 06:11:29 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:11:31 AM: Validating...
09/16 06:11:31 AM: Evaluate: task edges-ner-ontonotes, batch 5 (157): mcc: 0.8001, acc: 0.7224, precision: 0.8830, recall: 0.7433, f1: 0.8071, edges-ner-ontonotes_loss: 0.0553
09/16 06:11:36 AM: Update 3299: task edges-ner-ontonotes, batch 299 (3299): mcc: 0.8790, acc: 0.8254, precision: 0.9267, recall: 0.8459, f1: 0.8844, edges-ner-ontonotes_loss: 0.0388
09/16 06:11:42 AM: Evaluate: task edges-ner-ontonotes, batch 76 (157): mcc: 0.9062, acc: 0.8685, precision: 0.9386, recall: 0.8847, f1: 0.9109, edges-ner-ontonotes_loss: 0.0313
09/16 06:11:48 AM: Update 3358: task edges-ner-ontonotes, batch 358 (3358): mcc: 0.8811, acc: 0.8278, precision: 0.9280, recall: 0.8486, f1: 0.8865, edges-ner-ontonotes_loss: 0.0379
09/16 06:11:52 AM: Evaluate: task edges-ner-ontonotes, batch 133 (157): mcc: 0.9228, acc: 0.8887, precision: 0.9503, recall: 0.9042, f1: 0.9267, edges-ner-ontonotes_loss: 0.0262
09/16 06:11:56 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:11:56 AM: Best result seen so far for macro.
09/16 06:11:56 AM: Updating LR scheduler:
09/16 06:11:56 AM: 	Best result seen so far for macro_avg: 0.929
09/16 06:11:56 AM: 	# validation passes without improvement: 0
09/16 06:11:56 AM: edges-ner-ontonotes_loss: training: 0.031105 validation: 0.025160
09/16 06:11:56 AM: macro_avg: validation: 0.928965
09/16 06:11:56 AM: micro_avg: validation: 0.000000
09/16 06:11:56 AM: edges-ner-ontonotes_mcc: training: 0.904498 validation: 0.925154
09/16 06:11:56 AM: edges-ner-ontonotes_acc: training: 0.859959 validation: 0.891720
09/16 06:11:56 AM: edges-ner-ontonotes_precision: training: 0.940583 validation: 0.950563
09/16 06:11:56 AM: edges-ner-ontonotes_recall: training: 0.879637 validation: 0.908326
09/16 06:11:56 AM: edges-ner-ontonotes_f1: training: 0.909090 validation: 0.928965
09/16 06:11:56 AM: Global learning rate: 0.0001
09/16 06:11:56 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:11:59 AM: Update 3418: task edges-ner-ontonotes, batch 418 (3418): mcc: 0.8825, acc: 0.8297, precision: 0.9290, recall: 0.8501, f1: 0.8878, edges-ner-ontonotes_loss: 0.0374
09/16 06:12:04 AM: Update 4052: task edges-ner-ontonotes, batch 52 (4052): mcc: 0.9349, acc: 0.8997, precision: 0.9580, recall: 0.9193, f1: 0.9382, edges-ner-ontonotes_loss: 0.0209
09/16 06:12:10 AM: Update 3470: task edges-ner-ontonotes, batch 470 (3470): mcc: 0.8842, acc: 0.8323, precision: 0.9300, recall: 0.8523, f1: 0.8895, edges-ner-ontonotes_loss: 0.0369
09/16 06:12:14 AM: Update 4129: task edges-ner-ontonotes, batch 129 (4129): mcc: 0.9296, acc: 0.8926, precision: 0.9539, recall: 0.9133, f1: 0.9331, edges-ner-ontonotes_loss: 0.0226
09/16 06:12:20 AM: Update 3541: task edges-ner-ontonotes, batch 541 (3541): mcc: 0.8873, acc: 0.8370, precision: 0.9315, recall: 0.8567, f1: 0.8925, edges-ner-ontonotes_loss: 0.0360
09/16 06:12:24 AM: Update 4205: task edges-ner-ontonotes, batch 205 (4205): mcc: 0.9281, acc: 0.8912, precision: 0.9527, recall: 0.9117, f1: 0.9318, edges-ner-ontonotes_loss: 0.0231
09/16 06:12:30 AM: Update 3609: task edges-ner-ontonotes, batch 609 (3609): mcc: 0.8905, acc: 0.8409, precision: 0.9334, recall: 0.8606, f1: 0.8956, edges-ner-ontonotes_loss: 0.0352
09/16 06:12:34 AM: Update 4283: task edges-ner-ontonotes, batch 283 (4283): mcc: 0.9290, acc: 0.8918, precision: 0.9533, recall: 0.9128, f1: 0.9326, edges-ner-ontonotes_loss: 0.0229
09/16 06:12:41 AM: Update 3676: task edges-ner-ontonotes, batch 676 (3676): mcc: 0.8930, acc: 0.8445, precision: 0.9346, recall: 0.8642, f1: 0.8980, edges-ner-ontonotes_loss: 0.0345
09/16 06:12:44 AM: Update 4363: task edges-ner-ontonotes, batch 363 (4363): mcc: 0.9283, acc: 0.8910, precision: 0.9521, recall: 0.9127, f1: 0.9319, edges-ner-ontonotes_loss: 0.0230
09/16 06:12:52 AM: Update 3739: task edges-ner-ontonotes, batch 739 (3739): mcc: 0.8950, acc: 0.8470, precision: 0.9357, recall: 0.8668, f1: 0.9000, edges-ner-ontonotes_loss: 0.0339
09/16 06:12:54 AM: Update 4445: task edges-ner-ontonotes, batch 445 (4445): mcc: 0.9221, acc: 0.8827, precision: 0.9488, recall: 0.9043, f1: 0.9260, edges-ner-ontonotes_loss: 0.0254
09/16 06:13:02 AM: Update 3801: task edges-ner-ontonotes, batch 801 (3801): mcc: 0.8981, acc: 0.8512, precision: 0.9373, recall: 0.8709, f1: 0.9029, edges-ner-ontonotes_loss: 0.0332
09/16 06:13:04 AM: Update 4518: task edges-ner-ontonotes, batch 518 (4518): mcc: 0.9187, acc: 0.8783, precision: 0.9470, recall: 0.8998, f1: 0.9228, edges-ner-ontonotes_loss: 0.0272
09/16 06:13:12 AM: Update 3871: task edges-ner-ontonotes, batch 871 (3871): mcc: 0.9003, acc: 0.8543, precision: 0.9384, recall: 0.8740, f1: 0.9051, edges-ner-ontonotes_loss: 0.0324
09/16 06:13:14 AM: Update 4600: task edges-ner-ontonotes, batch 600 (4600): mcc: 0.9144, acc: 0.8728, precision: 0.9441, recall: 0.8947, f1: 0.9187, edges-ner-ontonotes_loss: 0.0292
09/16 06:13:22 AM: Update 3944: task edges-ner-ontonotes, batch 944 (3944): mcc: 0.9026, acc: 0.8574, precision: 0.9395, recall: 0.8772, f1: 0.9073, edges-ner-ontonotes_loss: 0.0317
09/16 06:13:24 AM: Update 4669: task edges-ner-ontonotes, batch 669 (4669): mcc: 0.9115, acc: 0.8691, precision: 0.9424, recall: 0.8908, f1: 0.9159, edges-ner-ontonotes_loss: 0.0303
09/16 06:13:29 AM: ***** Step 4000 / Validation 4 *****
09/16 06:13:31 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:13:31 AM: Validating...
09/16 06:13:32 AM: Evaluate: task edges-ner-ontonotes, batch 9 (157): mcc: 0.8284, acc: 0.7653, precision: 0.8904, recall: 0.7874, f1: 0.8357, edges-ner-ontonotes_loss: 0.0473
09/16 06:13:34 AM: Update 4764: task edges-ner-ontonotes, batch 764 (4764): mcc: 0.9105, acc: 0.8678, precision: 0.9418, recall: 0.8894, f1: 0.9149, edges-ner-ontonotes_loss: 0.0306
09/16 06:13:42 AM: Evaluate: task edges-ner-ontonotes, batch 72 (157): mcc: 0.9026, acc: 0.8637, precision: 0.9363, recall: 0.8802, f1: 0.9074, edges-ner-ontonotes_loss: 0.0320
09/16 06:13:45 AM: Update 4831: task edges-ner-ontonotes, batch 831 (4831): mcc: 0.9098, acc: 0.8670, precision: 0.9413, recall: 0.8888, f1: 0.9143, edges-ner-ontonotes_loss: 0.0308
09/16 06:13:52 AM: Evaluate: task edges-ner-ontonotes, batch 123 (157): mcc: 0.9194, acc: 0.8843, precision: 0.9476, recall: 0.9005, f1: 0.9234, edges-ner-ontonotes_loss: 0.0273
09/16 06:13:55 AM: Update 4894: task edges-ner-ontonotes, batch 894 (4894): mcc: 0.9090, acc: 0.8661, precision: 0.9406, recall: 0.8880, f1: 0.9135, edges-ner-ontonotes_loss: 0.0309
09/16 06:13:58 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:13:58 AM: Best result seen so far for macro.
09/16 06:13:58 AM: Updating LR scheduler:
09/16 06:13:58 AM: 	Best result seen so far for macro_avg: 0.929
09/16 06:13:58 AM: 	# validation passes without improvement: 0
09/16 06:13:58 AM: edges-ner-ontonotes_loss: training: 0.031105 validation: 0.025160
09/16 06:13:58 AM: macro_avg: validation: 0.928965
09/16 06:13:58 AM: micro_avg: validation: 0.000000
09/16 06:13:58 AM: edges-ner-ontonotes_mcc: training: 0.904498 validation: 0.925154
09/16 06:13:58 AM: edges-ner-ontonotes_acc: training: 0.859959 validation: 0.891720
09/16 06:13:58 AM: edges-ner-ontonotes_precision: training: 0.940583 validation: 0.950563
09/16 06:13:58 AM: edges-ner-ontonotes_recall: training: 0.879637 validation: 0.908326
09/16 06:13:58 AM: edges-ner-ontonotes_f1: training: 0.909090 validation: 0.928965
09/16 06:13:58 AM: Global learning rate: 0.0001
09/16 06:13:58 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:14:03 AM: Update 4030: task edges-ner-ontonotes, batch 30 (4030): mcc: 0.9349, acc: 0.8994, precision: 0.9603, recall: 0.9170, f1: 0.9382, edges-ner-ontonotes_loss: 0.0211
09/16 06:14:05 AM: Update 4975: task edges-ner-ontonotes, batch 975 (4975): mcc: 0.9084, acc: 0.8654, precision: 0.9402, recall: 0.8872, f1: 0.9129, edges-ner-ontonotes_loss: 0.0310
09/16 06:14:10 AM: ***** Step 5000 / Validation 5 *****
09/16 06:14:10 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:14:10 AM: Validating...
09/16 06:14:13 AM: Update 4079: task edges-ner-ontonotes, batch 79 (4079): mcc: 0.9308, acc: 0.8947, precision: 0.9563, recall: 0.9134, f1: 0.9343, edges-ner-ontonotes_loss: 0.0215
09/16 06:14:15 AM: Evaluate: task edges-ner-ontonotes, batch 32 (157): mcc: 0.8954, acc: 0.8549, precision: 0.9262, recall: 0.8766, f1: 0.9007, edges-ner-ontonotes_loss: 0.0331
09/16 06:14:23 AM: Update 4130: task edges-ner-ontonotes, batch 130 (4130): mcc: 0.9295, acc: 0.8926, precision: 0.9539, recall: 0.9132, f1: 0.9331, edges-ner-ontonotes_loss: 0.0226
09/16 06:14:25 AM: Evaluate: task edges-ner-ontonotes, batch 92 (157): mcc: 0.9203, acc: 0.8829, precision: 0.9499, recall: 0.9001, f1: 0.9243, edges-ner-ontonotes_loss: 0.0270
09/16 06:14:33 AM: Update 4181: task edges-ner-ontonotes, batch 181 (4181): mcc: 0.9294, acc: 0.8934, precision: 0.9536, recall: 0.9133, f1: 0.9330, edges-ner-ontonotes_loss: 0.0225
09/16 06:14:35 AM: Evaluate: task edges-ner-ontonotes, batch 144 (157): mcc: 0.9277, acc: 0.8937, precision: 0.9541, recall: 0.9097, f1: 0.9314, edges-ner-ontonotes_loss: 0.0243
09/16 06:14:37 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:14:37 AM: Best result seen so far for macro.
09/16 06:14:37 AM: Updating LR scheduler:
09/16 06:14:37 AM: 	Best result seen so far for macro_avg: 0.931
09/16 06:14:37 AM: 	# validation passes without improvement: 0
09/16 06:14:37 AM: edges-ner-ontonotes_loss: training: 0.031001 validation: 0.024031
09/16 06:14:37 AM: macro_avg: validation: 0.931409
09/16 06:14:37 AM: micro_avg: validation: 0.000000
09/16 06:14:37 AM: edges-ner-ontonotes_mcc: training: 0.908286 validation: 0.927755
09/16 06:14:37 AM: edges-ner-ontonotes_acc: training: 0.865184 validation: 0.893615
09/16 06:14:37 AM: edges-ner-ontonotes_precision: training: 0.940090 validation: 0.953607
09/16 06:14:37 AM: edges-ner-ontonotes_recall: training: 0.887106 validation: 0.910221
09/16 06:14:37 AM: edges-ner-ontonotes_f1: training: 0.912830 validation: 0.931409
09/16 06:14:37 AM: Global learning rate: 0.0001
09/16 06:14:37 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:14:43 AM: Update 4240: task edges-ner-ontonotes, batch 240 (4240): mcc: 0.9287, acc: 0.8918, precision: 0.9528, recall: 0.9128, f1: 0.9324, edges-ner-ontonotes_loss: 0.0230
09/16 06:14:45 AM: Update 5058: task edges-ner-ontonotes, batch 58 (5058): mcc: 0.9056, acc: 0.8644, precision: 0.9324, recall: 0.8895, f1: 0.9104, edges-ner-ontonotes_loss: 0.0296
09/16 06:14:53 AM: Update 4307: task edges-ner-ontonotes, batch 307 (4307): mcc: 0.9284, acc: 0.8912, precision: 0.9526, recall: 0.9124, f1: 0.9320, edges-ner-ontonotes_loss: 0.0230
09/16 06:14:55 AM: Update 5144: task edges-ner-ontonotes, batch 144 (5144): mcc: 0.9108, acc: 0.8709, precision: 0.9380, recall: 0.8938, f1: 0.9154, edges-ner-ontonotes_loss: 0.0286
09/16 06:15:05 AM: Update 4365: task edges-ner-ontonotes, batch 365 (4365): mcc: 0.9279, acc: 0.8903, precision: 0.9522, recall: 0.9119, f1: 0.9316, edges-ner-ontonotes_loss: 0.0231
09/16 06:15:05 AM: Update 5231: task edges-ner-ontonotes, batch 231 (5231): mcc: 0.9129, acc: 0.8726, precision: 0.9416, recall: 0.8942, f1: 0.9173, edges-ner-ontonotes_loss: 0.0275
09/16 06:15:15 AM: Update 4440: task edges-ner-ontonotes, batch 440 (4440): mcc: 0.9224, acc: 0.8831, precision: 0.9488, recall: 0.9048, f1: 0.9263, edges-ner-ontonotes_loss: 0.0253
09/16 06:15:15 AM: Update 5305: task edges-ner-ontonotes, batch 305 (5305): mcc: 0.9163, acc: 0.8767, precision: 0.9439, recall: 0.8983, f1: 0.9205, edges-ner-ontonotes_loss: 0.0267
09/16 06:15:25 AM: Update 4505: task edges-ner-ontonotes, batch 505 (4505): mcc: 0.9190, acc: 0.8788, precision: 0.9471, recall: 0.9003, f1: 0.9231, edges-ner-ontonotes_loss: 0.0271
09/16 06:15:25 AM: Update 5383: task edges-ner-ontonotes, batch 383 (5383): mcc: 0.9202, acc: 0.8820, precision: 0.9458, recall: 0.9037, f1: 0.9243, edges-ner-ontonotes_loss: 0.0255
09/16 06:15:35 AM: Update 4574: task edges-ner-ontonotes, batch 574 (4574): mcc: 0.9154, acc: 0.8742, precision: 0.9445, recall: 0.8961, f1: 0.9196, edges-ner-ontonotes_loss: 0.0288
09/16 06:15:35 AM: Update 5461: task edges-ner-ontonotes, batch 461 (5461): mcc: 0.9224, acc: 0.8851, precision: 0.9471, recall: 0.9066, f1: 0.9264, edges-ner-ontonotes_loss: 0.0249
09/16 06:15:45 AM: Update 4641: task edges-ner-ontonotes, batch 641 (4641): mcc: 0.9125, acc: 0.8704, precision: 0.9431, recall: 0.8920, f1: 0.9169, edges-ner-ontonotes_loss: 0.0299
09/16 06:15:46 AM: Update 5544: task edges-ner-ontonotes, batch 544 (5544): mcc: 0.9241, acc: 0.8872, precision: 0.9478, recall: 0.9090, f1: 0.9280, edges-ner-ontonotes_loss: 0.0244
09/16 06:15:55 AM: Update 4712: task edges-ner-ontonotes, batch 712 (4712): mcc: 0.9107, acc: 0.8682, precision: 0.9420, recall: 0.8898, f1: 0.9152, edges-ner-ontonotes_loss: 0.0305
09/16 06:15:56 AM: Update 5612: task edges-ner-ontonotes, batch 612 (5612): mcc: 0.9258, acc: 0.8892, precision: 0.9493, recall: 0.9108, f1: 0.9296, edges-ner-ontonotes_loss: 0.0239
09/16 06:16:05 AM: Update 4786: task edges-ner-ontonotes, batch 786 (4786): mcc: 0.9102, acc: 0.8675, precision: 0.9415, recall: 0.8893, f1: 0.9146, edges-ner-ontonotes_loss: 0.0307
09/16 06:16:06 AM: Update 5693: task edges-ner-ontonotes, batch 693 (5693): mcc: 0.9262, acc: 0.8899, precision: 0.9491, recall: 0.9118, f1: 0.9300, edges-ner-ontonotes_loss: 0.0238
09/16 06:16:15 AM: Update 4860: task edges-ner-ontonotes, batch 860 (4860): mcc: 0.9092, acc: 0.8662, precision: 0.9407, recall: 0.8882, f1: 0.9137, edges-ner-ontonotes_loss: 0.0309
09/16 06:16:16 AM: Update 5778: task edges-ner-ontonotes, batch 778 (5778): mcc: 0.9269, acc: 0.8908, precision: 0.9496, recall: 0.9126, f1: 0.9307, edges-ner-ontonotes_loss: 0.0235
09/16 06:16:25 AM: Update 4938: task edges-ner-ontonotes, batch 938 (4938): mcc: 0.9087, acc: 0.8658, precision: 0.9404, recall: 0.8876, f1: 0.9132, edges-ner-ontonotes_loss: 0.0309
09/16 06:16:26 AM: Update 5865: task edges-ner-ontonotes, batch 865 (5865): mcc: 0.9274, acc: 0.8913, precision: 0.9497, recall: 0.9134, f1: 0.9312, edges-ner-ontonotes_loss: 0.0235
09/16 06:16:35 AM: Update 4985: task edges-ner-ontonotes, batch 985 (4985): mcc: 0.9082, acc: 0.8651, precision: 0.9400, recall: 0.8870, f1: 0.9127, edges-ner-ontonotes_loss: 0.0310
09/16 06:16:36 AM: Update 5948: task edges-ner-ontonotes, batch 948 (5948): mcc: 0.9266, acc: 0.8902, precision: 0.9492, recall: 0.9123, f1: 0.9304, edges-ner-ontonotes_loss: 0.0238
09/16 06:16:38 AM: ***** Step 5000 / Validation 5 *****
09/16 06:16:38 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:16:38 AM: Validating...
09/16 06:16:44 AM: ***** Step 6000 / Validation 6 *****
09/16 06:16:44 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:16:44 AM: Validating...
09/16 06:16:46 AM: Evaluate: task edges-ner-ontonotes, batch 13 (157): mcc: 0.8491, acc: 0.7971, precision: 0.8879, recall: 0.8275, f1: 0.8566, edges-ner-ontonotes_loss: 0.0394
09/16 06:16:46 AM: Evaluate: task edges-ner-ontonotes, batch 48 (157): mcc: 0.9050, acc: 0.8652, precision: 0.9331, recall: 0.8878, f1: 0.9099, edges-ner-ontonotes_loss: 0.0307
09/16 06:16:56 AM: Evaluate: task edges-ner-ontonotes, batch 63 (157): mcc: 0.9118, acc: 0.8765, precision: 0.9349, recall: 0.8986, f1: 0.9164, edges-ner-ontonotes_loss: 0.0290
09/16 06:16:56 AM: Evaluate: task edges-ner-ontonotes, batch 91 (157): mcc: 0.9194, acc: 0.8816, precision: 0.9493, recall: 0.8989, f1: 0.9234, edges-ner-ontonotes_loss: 0.0273
09/16 06:17:06 AM: Evaluate: task edges-ner-ontonotes, batch 109 (157): mcc: 0.9193, acc: 0.8842, precision: 0.9452, recall: 0.9025, f1: 0.9234, edges-ner-ontonotes_loss: 0.0270
09/16 06:17:06 AM: Evaluate: task edges-ner-ontonotes, batch 128 (157): mcc: 0.9243, acc: 0.8891, precision: 0.9527, recall: 0.9047, f1: 0.9281, edges-ner-ontonotes_loss: 0.0253
09/16 06:17:13 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:17:13 AM: Best result seen so far for macro.
09/16 06:17:13 AM: Updating LR scheduler:
09/16 06:17:13 AM: 	Best result seen so far for macro_avg: 0.931
09/16 06:17:13 AM: 	# validation passes without improvement: 0
09/16 06:17:13 AM: edges-ner-ontonotes_loss: training: 0.031001 validation: 0.024031
09/16 06:17:13 AM: macro_avg: validation: 0.931409
09/16 06:17:13 AM: micro_avg: validation: 0.000000
09/16 06:17:13 AM: edges-ner-ontonotes_mcc: training: 0.908286 validation: 0.927755
09/16 06:17:13 AM: edges-ner-ontonotes_acc: training: 0.865184 validation: 0.893615
09/16 06:17:13 AM: edges-ner-ontonotes_precision: training: 0.940090 validation: 0.953607
09/16 06:17:13 AM: edges-ner-ontonotes_recall: training: 0.887106 validation: 0.910221
09/16 06:17:13 AM: edges-ner-ontonotes_f1: training: 0.912830 validation: 0.931409
09/16 06:17:13 AM: Global learning rate: 0.0001
09/16 06:17:13 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:17:16 AM: Evaluate: task edges-ner-ontonotes, batch 156 (157): mcc: 0.9288, acc: 0.8963, precision: 0.9529, recall: 0.9129, f1: 0.9325, edges-ner-ontonotes_loss: 0.0238
09/16 06:17:16 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:17:16 AM: Best result seen so far for macro.
09/16 06:17:16 AM: Updating LR scheduler:
09/16 06:17:16 AM: 	Best result seen so far for macro_avg: 0.933
09/16 06:17:16 AM: 	# validation passes without improvement: 0
09/16 06:17:16 AM: edges-ner-ontonotes_loss: training: 0.024594 validation: 0.023682
09/16 06:17:16 AM: macro_avg: validation: 0.932538
09/16 06:17:16 AM: micro_avg: validation: 0.000000
09/16 06:17:16 AM: edges-ner-ontonotes_mcc: training: 0.924760 validation: 0.928899
09/16 06:17:16 AM: edges-ner-ontonotes_acc: training: 0.887830 validation: 0.896345
09/16 06:17:16 AM: edges-ner-ontonotes_precision: training: 0.948128 validation: 0.952984
09/16 06:17:16 AM: edges-ner-ontonotes_recall: training: 0.909952 validation: 0.912951
09/16 06:17:16 AM: edges-ner-ontonotes_f1: training: 0.928648 validation: 0.932538
09/16 06:17:16 AM: Global learning rate: 0.0001
09/16 06:17:16 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:17:16 AM: Update 5012: task edges-ner-ontonotes, batch 12 (5012): mcc: 0.8951, acc: 0.8495, precision: 0.9217, recall: 0.8804, f1: 0.9006, edges-ner-ontonotes_loss: 0.0321
09/16 06:17:26 AM: Update 6081: task edges-ner-ontonotes, batch 81 (6081): mcc: 0.8935, acc: 0.8460, precision: 0.9289, recall: 0.8705, f1: 0.8988, edges-ner-ontonotes_loss: 0.0361
09/16 06:17:26 AM: Update 5079: task edges-ner-ontonotes, batch 79 (5079): mcc: 0.9073, acc: 0.8653, precision: 0.9351, recall: 0.8901, f1: 0.9120, edges-ner-ontonotes_loss: 0.0289
09/16 06:17:36 AM: Update 6156: task edges-ner-ontonotes, batch 156 (6156): mcc: 0.8919, acc: 0.8452, precision: 0.9274, recall: 0.8689, f1: 0.8972, edges-ner-ontonotes_loss: 0.0375
09/16 06:17:37 AM: Update 5150: task edges-ner-ontonotes, batch 150 (5150): mcc: 0.9107, acc: 0.8707, precision: 0.9381, recall: 0.8936, f1: 0.9153, edges-ner-ontonotes_loss: 0.0285
09/16 06:17:47 AM: Update 6225: task edges-ner-ontonotes, batch 225 (6225): mcc: 0.8929, acc: 0.8469, precision: 0.9282, recall: 0.8700, f1: 0.8982, edges-ner-ontonotes_loss: 0.0374
09/16 06:17:47 AM: Update 5230: task edges-ner-ontonotes, batch 230 (5230): mcc: 0.9129, acc: 0.8725, precision: 0.9417, recall: 0.8941, f1: 0.9173, edges-ner-ontonotes_loss: 0.0275
09/16 06:17:57 AM: Update 6325: task edges-ner-ontonotes, batch 325 (6325): mcc: 0.8956, acc: 0.8503, precision: 0.9300, recall: 0.8733, f1: 0.9008, edges-ner-ontonotes_loss: 0.0356
09/16 06:17:57 AM: Update 5296: task edges-ner-ontonotes, batch 296 (5296): mcc: 0.9157, acc: 0.8761, precision: 0.9436, recall: 0.8974, f1: 0.9199, edges-ner-ontonotes_loss: 0.0268
09/16 06:18:07 AM: Update 6408: task edges-ner-ontonotes, batch 408 (6408): mcc: 0.8951, acc: 0.8499, precision: 0.9294, recall: 0.8729, f1: 0.9003, edges-ner-ontonotes_loss: 0.0351
09/16 06:18:07 AM: Update 5368: task edges-ner-ontonotes, batch 368 (5368): mcc: 0.9198, acc: 0.8812, precision: 0.9460, recall: 0.9028, f1: 0.9239, edges-ner-ontonotes_loss: 0.0256
09/16 06:18:17 AM: Update 6503: task edges-ner-ontonotes, batch 503 (6503): mcc: 0.8973, acc: 0.8523, precision: 0.9310, recall: 0.8754, f1: 0.9024, edges-ner-ontonotes_loss: 0.0343
09/16 06:18:17 AM: Update 5445: task edges-ner-ontonotes, batch 445 (5445): mcc: 0.9221, acc: 0.8847, precision: 0.9468, recall: 0.9063, f1: 0.9261, edges-ner-ontonotes_loss: 0.0250
09/16 06:18:27 AM: Update 6570: task edges-ner-ontonotes, batch 570 (6570): mcc: 0.8990, acc: 0.8545, precision: 0.9320, recall: 0.8776, f1: 0.9040, edges-ner-ontonotes_loss: 0.0335
09/16 06:18:27 AM: Update 5519: task edges-ner-ontonotes, batch 519 (5519): mcc: 0.9236, acc: 0.8864, precision: 0.9477, recall: 0.9082, f1: 0.9275, edges-ner-ontonotes_loss: 0.0245
09/16 06:18:37 AM: Update 6649: task edges-ner-ontonotes, batch 649 (6649): mcc: 0.9020, acc: 0.8584, precision: 0.9338, recall: 0.8815, f1: 0.9069, edges-ner-ontonotes_loss: 0.0325
09/16 06:18:37 AM: Update 5588: task edges-ner-ontonotes, batch 588 (5588): mcc: 0.9254, acc: 0.8888, precision: 0.9488, recall: 0.9105, f1: 0.9292, edges-ner-ontonotes_loss: 0.0240
09/16 06:18:47 AM: Update 6746: task edges-ner-ontonotes, batch 746 (6746): mcc: 0.9045, acc: 0.8619, precision: 0.9352, recall: 0.8847, f1: 0.9093, edges-ner-ontonotes_loss: 0.0316
09/16 06:18:47 AM: Update 5632: task edges-ner-ontonotes, batch 632 (5632): mcc: 0.9258, acc: 0.8894, precision: 0.9492, recall: 0.9109, f1: 0.9296, edges-ner-ontonotes_loss: 0.0239
09/16 06:18:57 AM: Update 5695: task edges-ner-ontonotes, batch 695 (5695): mcc: 0.9262, acc: 0.8899, precision: 0.9491, recall: 0.9118, f1: 0.9300, edges-ner-ontonotes_loss: 0.0238
09/16 06:18:57 AM: Update 6823: task edges-ner-ontonotes, batch 823 (6823): mcc: 0.9057, acc: 0.8636, precision: 0.9359, recall: 0.8863, f1: 0.9104, edges-ner-ontonotes_loss: 0.0312
09/16 06:19:09 AM: Update 6886: task edges-ner-ontonotes, batch 886 (6886): mcc: 0.9076, acc: 0.8660, precision: 0.9373, recall: 0.8885, f1: 0.9122, edges-ner-ontonotes_loss: 0.0306
09/16 06:19:09 AM: Update 5774: task edges-ner-ontonotes, batch 774 (5774): mcc: 0.9269, acc: 0.8907, precision: 0.9495, recall: 0.9126, f1: 0.9306, edges-ner-ontonotes_loss: 0.0235
09/16 06:19:19 AM: Update 6967: task edges-ner-ontonotes, batch 967 (6967): mcc: 0.9100, acc: 0.8692, precision: 0.9385, recall: 0.8918, f1: 0.9145, edges-ner-ontonotes_loss: 0.0298
09/16 06:19:20 AM: Update 5843: task edges-ner-ontonotes, batch 843 (5843): mcc: 0.9274, acc: 0.8913, precision: 0.9497, recall: 0.9133, f1: 0.9312, edges-ner-ontonotes_loss: 0.0234
09/16 06:19:23 AM: ***** Step 7000 / Validation 7 *****
09/16 06:19:23 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:19:23 AM: Validating...
09/16 06:19:29 AM: Evaluate: task edges-ner-ontonotes, batch 38 (157): mcc: 0.8961, acc: 0.8590, precision: 0.9226, recall: 0.8813, f1: 0.9015, edges-ner-ontonotes_loss: 0.0332
09/16 06:19:30 AM: Update 5900: task edges-ner-ontonotes, batch 900 (5900): mcc: 0.9275, acc: 0.8916, precision: 0.9496, recall: 0.9137, f1: 0.9313, edges-ner-ontonotes_loss: 0.0235
09/16 06:19:39 AM: Evaluate: task edges-ner-ontonotes, batch 99 (157): mcc: 0.9182, acc: 0.8856, precision: 0.9432, recall: 0.9025, f1: 0.9224, edges-ner-ontonotes_loss: 0.0273
09/16 06:19:40 AM: Update 5940: task edges-ner-ontonotes, batch 940 (5940): mcc: 0.9268, acc: 0.8905, precision: 0.9493, recall: 0.9126, f1: 0.9306, edges-ner-ontonotes_loss: 0.0237
09/16 06:19:49 AM: Evaluate: task edges-ner-ontonotes, batch 151 (157): mcc: 0.9323, acc: 0.9030, precision: 0.9519, recall: 0.9203, f1: 0.9359, edges-ner-ontonotes_loss: 0.0232
09/16 06:19:50 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:19:50 AM: Best result seen so far for macro.
09/16 06:19:50 AM: Updating LR scheduler:
09/16 06:19:50 AM: 	Best result seen so far for macro_avg: 0.936
09/16 06:19:50 AM: 	# validation passes without improvement: 0
09/16 06:19:50 AM: edges-ner-ontonotes_loss: training: 0.029496 validation: 0.022901
09/16 06:19:50 AM: macro_avg: validation: 0.936185
09/16 06:19:50 AM: micro_avg: validation: 0.000000
09/16 06:19:50 AM: edges-ner-ontonotes_mcc: training: 0.910911 validation: 0.932637
09/16 06:19:50 AM: edges-ner-ontonotes_acc: training: 0.870464 validation: 0.903397
09/16 06:19:50 AM: edges-ner-ontonotes_precision: training: 0.939110 validation: 0.951810
09/16 06:19:50 AM: edges-ner-ontonotes_recall: training: 0.892913 validation: 0.921065
09/16 06:19:50 AM: edges-ner-ontonotes_f1: training: 0.915429 validation: 0.936185
09/16 06:19:50 AM: Update 5988: task edges-ner-ontonotes, batch 988 (5988): mcc: 0.9251, acc: 0.8883, precision: 0.9482, recall: 0.9104, f1: 0.9289, edges-ner-ontonotes_loss: 0.0244
09/16 06:19:50 AM: Global learning rate: 0.0001
09/16 06:19:50 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:19:52 AM: ***** Step 6000 / Validation 6 *****
09/16 06:19:52 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:19:52 AM: Validating...
09/16 06:19:59 AM: Update 7058: task edges-ner-ontonotes, batch 58 (7058): mcc: 0.9357, acc: 0.9027, precision: 0.9506, recall: 0.9280, f1: 0.9391, edges-ner-ontonotes_loss: 0.0203
09/16 06:20:00 AM: Evaluate: task edges-ner-ontonotes, batch 51 (157): mcc: 0.9014, acc: 0.8641, precision: 0.9270, recall: 0.8869, f1: 0.9065, edges-ner-ontonotes_loss: 0.0316
09/16 06:20:09 AM: Update 7116: task edges-ner-ontonotes, batch 116 (7116): mcc: 0.9356, acc: 0.9019, precision: 0.9533, recall: 0.9252, f1: 0.9390, edges-ner-ontonotes_loss: 0.0205
09/16 06:20:10 AM: Evaluate: task edges-ner-ontonotes, batch 101 (157): mcc: 0.9164, acc: 0.8804, precision: 0.9439, recall: 0.8985, f1: 0.9206, edges-ner-ontonotes_loss: 0.0279
09/16 06:20:19 AM: Update 7164: task edges-ner-ontonotes, batch 164 (7164): mcc: 0.9372, acc: 0.9042, precision: 0.9559, recall: 0.9257, f1: 0.9405, edges-ner-ontonotes_loss: 0.0200
09/16 06:20:21 AM: Evaluate: task edges-ner-ontonotes, batch 152 (157): mcc: 0.9286, acc: 0.8959, precision: 0.9532, recall: 0.9121, f1: 0.9322, edges-ner-ontonotes_loss: 0.0240
09/16 06:20:21 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:20:21 AM: Best result seen so far for macro.
09/16 06:20:21 AM: Updating LR scheduler:
09/16 06:20:21 AM: 	Best result seen so far for macro_avg: 0.933
09/16 06:20:21 AM: 	# validation passes without improvement: 0
09/16 06:20:21 AM: edges-ner-ontonotes_loss: training: 0.024594 validation: 0.023682
09/16 06:20:21 AM: macro_avg: validation: 0.932538
09/16 06:20:21 AM: micro_avg: validation: 0.000000
09/16 06:20:21 AM: edges-ner-ontonotes_mcc: training: 0.924760 validation: 0.928899
09/16 06:20:21 AM: edges-ner-ontonotes_acc: training: 0.887830 validation: 0.896345
09/16 06:20:21 AM: edges-ner-ontonotes_precision: training: 0.948128 validation: 0.952984
09/16 06:20:21 AM: edges-ner-ontonotes_recall: training: 0.909952 validation: 0.912951
09/16 06:20:21 AM: edges-ner-ontonotes_f1: training: 0.928648 validation: 0.932538
09/16 06:20:21 AM: Global learning rate: 0.0001
09/16 06:20:21 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:20:29 AM: Update 7239: task edges-ner-ontonotes, batch 239 (7239): mcc: 0.9347, acc: 0.9014, precision: 0.9539, recall: 0.9229, f1: 0.9382, edges-ner-ontonotes_loss: 0.0208
09/16 06:20:31 AM: Update 6064: task edges-ner-ontonotes, batch 64 (6064): mcc: 0.8952, acc: 0.8480, precision: 0.9300, recall: 0.8724, f1: 0.9003, edges-ner-ontonotes_loss: 0.0362
09/16 06:20:39 AM: Update 7330: task edges-ner-ontonotes, batch 330 (7330): mcc: 0.9349, acc: 0.9016, precision: 0.9539, recall: 0.9233, f1: 0.9384, edges-ner-ontonotes_loss: 0.0207
09/16 06:20:43 AM: Update 6131: task edges-ner-ontonotes, batch 131 (6131): mcc: 0.8926, acc: 0.8459, precision: 0.9277, recall: 0.8699, f1: 0.8979, edges-ner-ontonotes_loss: 0.0371
09/16 06:20:50 AM: Update 7412: task edges-ner-ontonotes, batch 412 (7412): mcc: 0.9348, acc: 0.9010, precision: 0.9536, recall: 0.9232, f1: 0.9382, edges-ner-ontonotes_loss: 0.0206
09/16 06:20:55 AM: Update 6207: task edges-ner-ontonotes, batch 207 (6207): mcc: 0.8936, acc: 0.8477, precision: 0.9288, recall: 0.8706, f1: 0.8988, edges-ner-ontonotes_loss: 0.0371
09/16 06:21:01 AM: Update 7485: task edges-ner-ontonotes, batch 485 (7485): mcc: 0.9323, acc: 0.8974, precision: 0.9519, recall: 0.9203, f1: 0.9358, edges-ner-ontonotes_loss: 0.0215
09/16 06:21:05 AM: Update 6273: task edges-ner-ontonotes, batch 273 (6273): mcc: 0.8950, acc: 0.8496, precision: 0.9297, recall: 0.8725, f1: 0.9002, edges-ner-ontonotes_loss: 0.0362
09/16 06:21:11 AM: Update 7568: task edges-ner-ontonotes, batch 568 (7568): mcc: 0.9271, acc: 0.8909, precision: 0.9486, recall: 0.9139, f1: 0.9309, edges-ner-ontonotes_loss: 0.0238
09/16 06:21:15 AM: Update 6350: task edges-ner-ontonotes, batch 350 (6350): mcc: 0.8959, acc: 0.8507, precision: 0.9300, recall: 0.8739, f1: 0.9011, edges-ner-ontonotes_loss: 0.0354
09/16 06:21:21 AM: Update 7647: task edges-ner-ontonotes, batch 647 (7647): mcc: 0.9240, acc: 0.8867, precision: 0.9467, recall: 0.9099, f1: 0.9279, edges-ner-ontonotes_loss: 0.0251
09/16 06:21:25 AM: Update 6428: task edges-ner-ontonotes, batch 428 (6428): mcc: 0.8960, acc: 0.8509, precision: 0.9300, recall: 0.8741, f1: 0.9011, edges-ner-ontonotes_loss: 0.0349
09/16 06:21:31 AM: Update 7732: task edges-ner-ontonotes, batch 732 (7732): mcc: 0.9210, acc: 0.8825, precision: 0.9451, recall: 0.9058, f1: 0.9250, edges-ner-ontonotes_loss: 0.0265
09/16 06:21:35 AM: Update 6508: task edges-ner-ontonotes, batch 508 (6508): mcc: 0.8974, acc: 0.8524, precision: 0.9312, recall: 0.8755, f1: 0.9025, edges-ner-ontonotes_loss: 0.0342
09/16 06:21:41 AM: Update 7825: task edges-ner-ontonotes, batch 825 (7825): mcc: 0.9187, acc: 0.8797, precision: 0.9439, recall: 0.9028, f1: 0.9229, edges-ner-ontonotes_loss: 0.0275
09/16 06:21:45 AM: Update 6561: task edges-ner-ontonotes, batch 561 (6561): mcc: 0.8984, acc: 0.8537, precision: 0.9317, recall: 0.8769, f1: 0.9034, edges-ner-ontonotes_loss: 0.0336
09/16 06:21:52 AM: Update 7915: task edges-ner-ontonotes, batch 915 (7915): mcc: 0.9179, acc: 0.8787, precision: 0.9434, recall: 0.9017, f1: 0.9221, edges-ner-ontonotes_loss: 0.0278
09/16 06:21:55 AM: Update 6637: task edges-ner-ontonotes, batch 637 (6637): mcc: 0.9018, acc: 0.8581, precision: 0.9337, recall: 0.8813, f1: 0.9067, edges-ner-ontonotes_loss: 0.0325
09/16 06:22:01 AM: ***** Step 8000 / Validation 8 *****
09/16 06:22:01 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:22:01 AM: Validating...
09/16 06:22:02 AM: Evaluate: task edges-ner-ontonotes, batch 2 (157): mcc: 0.8254, acc: 0.7462, precision: 0.8548, recall: 0.8154, f1: 0.8346, edges-ner-ontonotes_loss: 0.0454
09/16 06:22:05 AM: Update 6705: task edges-ner-ontonotes, batch 705 (6705): mcc: 0.9030, acc: 0.8601, precision: 0.9343, recall: 0.8829, f1: 0.9079, edges-ner-ontonotes_loss: 0.0321
09/16 06:22:12 AM: Evaluate: task edges-ner-ontonotes, batch 66 (157): mcc: 0.9161, acc: 0.8805, precision: 0.9434, recall: 0.8985, f1: 0.9204, edges-ner-ontonotes_loss: 0.0283
09/16 06:22:15 AM: Update 6757: task edges-ner-ontonotes, batch 757 (6757): mcc: 0.9047, acc: 0.8621, precision: 0.9354, recall: 0.8849, f1: 0.9094, edges-ner-ontonotes_loss: 0.0316
09/16 06:22:22 AM: Evaluate: task edges-ner-ontonotes, batch 118 (157): mcc: 0.9276, acc: 0.8952, precision: 0.9520, recall: 0.9115, f1: 0.9313, edges-ner-ontonotes_loss: 0.0246
09/16 06:22:25 AM: Update 6807: task edges-ner-ontonotes, batch 807 (6807): mcc: 0.9056, acc: 0.8634, precision: 0.9360, recall: 0.8861, f1: 0.9103, edges-ner-ontonotes_loss: 0.0313
09/16 06:22:29 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:22:29 AM: Best result seen so far for macro.
09/16 06:22:29 AM: Updating LR scheduler:
09/16 06:22:29 AM: 	Best result seen so far for macro_avg: 0.937
09/16 06:22:29 AM: 	# validation passes without improvement: 0
09/16 06:22:29 AM: edges-ner-ontonotes_loss: training: 0.027954 validation: 0.022517
09/16 06:22:29 AM: macro_avg: validation: 0.937476
09/16 06:22:29 AM: micro_avg: validation: 0.000000
09/16 06:22:29 AM: edges-ner-ontonotes_mcc: training: 0.917201 validation: 0.934066
09/16 06:22:29 AM: edges-ner-ontonotes_acc: training: 0.877875 validation: 0.904155
09/16 06:22:29 AM: edges-ner-ontonotes_precision: training: 0.943072 validation: 0.955871
09/16 06:22:29 AM: edges-ner-ontonotes_recall: training: 0.900779 validation: 0.919776
09/16 06:22:29 AM: edges-ner-ontonotes_f1: training: 0.921440 validation: 0.937476
09/16 06:22:29 AM: Global learning rate: 0.0001
09/16 06:22:29 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:22:32 AM: Update 8028: task edges-ner-ontonotes, batch 28 (8028): mcc: 0.9111, acc: 0.8723, precision: 0.9359, recall: 0.8964, f1: 0.9157, edges-ner-ontonotes_loss: 0.0272
09/16 06:22:35 AM: Update 6861: task edges-ner-ontonotes, batch 861 (6861): mcc: 0.9067, acc: 0.8649, precision: 0.9366, recall: 0.8875, f1: 0.9114, edges-ner-ontonotes_loss: 0.0309
09/16 06:22:43 AM: Update 8101: task edges-ner-ontonotes, batch 101 (8101): mcc: 0.9052, acc: 0.8622, precision: 0.9319, recall: 0.8892, f1: 0.9101, edges-ner-ontonotes_loss: 0.0297
09/16 06:22:45 AM: Update 6938: task edges-ner-ontonotes, batch 938 (6938): mcc: 0.9090, acc: 0.8680, precision: 0.9380, recall: 0.8905, f1: 0.9136, edges-ner-ontonotes_loss: 0.0301
09/16 06:22:53 AM: Update 8184: task edges-ner-ontonotes, batch 184 (8184): mcc: 0.9140, acc: 0.8733, precision: 0.9384, recall: 0.8995, f1: 0.9185, edges-ner-ontonotes_loss: 0.0277
09/16 06:22:54 AM: ***** Step 7000 / Validation 7 *****
09/16 06:22:54 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:22:54 AM: Validating...
09/16 06:22:55 AM: Evaluate: task edges-ner-ontonotes, batch 7 (157): mcc: 0.8367, acc: 0.7759, precision: 0.8959, recall: 0.7974, f1: 0.8438, edges-ner-ontonotes_loss: 0.0437
09/16 06:23:04 AM: Update 8246: task edges-ner-ontonotes, batch 246 (8246): mcc: 0.9169, acc: 0.8771, precision: 0.9408, recall: 0.9023, f1: 0.9212, edges-ner-ontonotes_loss: 0.0269
09/16 06:23:05 AM: Evaluate: task edges-ner-ontonotes, batch 64 (157): mcc: 0.9131, acc: 0.8790, precision: 0.9365, recall: 0.8995, f1: 0.9176, edges-ner-ontonotes_loss: 0.0289
09/16 06:23:14 AM: Update 8314: task edges-ner-ontonotes, batch 314 (8314): mcc: 0.9179, acc: 0.8797, precision: 0.9414, recall: 0.9038, f1: 0.9222, edges-ner-ontonotes_loss: 0.0266
09/16 06:23:17 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9228, acc: 0.8907, precision: 0.9467, recall: 0.9077, f1: 0.9268, edges-ner-ontonotes_loss: 0.0259
09/16 06:23:24 AM: Update 8379: task edges-ner-ontonotes, batch 379 (8379): mcc: 0.9188, acc: 0.8808, precision: 0.9424, recall: 0.9045, f1: 0.9230, edges-ner-ontonotes_loss: 0.0264
09/16 06:23:26 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:23:26 AM: Best result seen so far for macro.
09/16 06:23:26 AM: Updating LR scheduler:
09/16 06:23:26 AM: 	Best result seen so far for macro_avg: 0.936
09/16 06:23:26 AM: 	# validation passes without improvement: 0
09/16 06:23:26 AM: edges-ner-ontonotes_loss: training: 0.029496 validation: 0.022901
09/16 06:23:26 AM: macro_avg: validation: 0.936185
09/16 06:23:26 AM: micro_avg: validation: 0.000000
09/16 06:23:26 AM: edges-ner-ontonotes_mcc: training: 0.910911 validation: 0.932637
09/16 06:23:26 AM: edges-ner-ontonotes_acc: training: 0.870464 validation: 0.903397
09/16 06:23:26 AM: edges-ner-ontonotes_precision: training: 0.939110 validation: 0.951810
09/16 06:23:26 AM: edges-ner-ontonotes_recall: training: 0.892913 validation: 0.921065
09/16 06:23:26 AM: edges-ner-ontonotes_f1: training: 0.915429 validation: 0.936185
09/16 06:23:26 AM: Global learning rate: 0.0001
09/16 06:23:26 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:23:28 AM: Update 7014: task edges-ner-ontonotes, batch 14 (7014): mcc: 0.9474, acc: 0.9192, precision: 0.9514, recall: 0.9492, f1: 0.9503, edges-ner-ontonotes_loss: 0.0174
09/16 06:23:34 AM: Update 8443: task edges-ner-ontonotes, batch 443 (8443): mcc: 0.9206, acc: 0.8834, precision: 0.9434, recall: 0.9069, f1: 0.9248, edges-ner-ontonotes_loss: 0.0261
09/16 06:23:38 AM: Update 7087: task edges-ner-ontonotes, batch 87 (7087): mcc: 0.9361, acc: 0.9027, precision: 0.9530, recall: 0.9264, f1: 0.9395, edges-ner-ontonotes_loss: 0.0204
09/16 06:23:44 AM: Update 8529: task edges-ner-ontonotes, batch 529 (8529): mcc: 0.9243, acc: 0.8884, precision: 0.9459, recall: 0.9112, f1: 0.9283, edges-ner-ontonotes_loss: 0.0250
09/16 06:23:51 AM: Update 7155: task edges-ner-ontonotes, batch 155 (7155): mcc: 0.9377, acc: 0.9050, precision: 0.9554, recall: 0.9270, f1: 0.9410, edges-ner-ontonotes_loss: 0.0199
09/16 06:23:55 AM: Update 8619: task edges-ner-ontonotes, batch 619 (8619): mcc: 0.9262, acc: 0.8911, precision: 0.9468, recall: 0.9139, f1: 0.9301, edges-ner-ontonotes_loss: 0.0243
09/16 06:24:01 AM: Update 7197: task edges-ner-ontonotes, batch 197 (7197): mcc: 0.9368, acc: 0.9039, precision: 0.9552, recall: 0.9254, f1: 0.9401, edges-ner-ontonotes_loss: 0.0202
09/16 06:24:05 AM: Update 8694: task edges-ner-ontonotes, batch 694 (8694): mcc: 0.9277, acc: 0.8930, precision: 0.9478, recall: 0.9158, f1: 0.9315, edges-ner-ontonotes_loss: 0.0238
09/16 06:24:11 AM: Update 7269: task edges-ner-ontonotes, batch 269 (7269): mcc: 0.9351, acc: 0.9021, precision: 0.9538, recall: 0.9238, f1: 0.9385, edges-ner-ontonotes_loss: 0.0208
09/16 06:24:16 AM: Update 8778: task edges-ner-ontonotes, batch 778 (8778): mcc: 0.9291, acc: 0.8947, precision: 0.9492, recall: 0.9171, f1: 0.9329, edges-ner-ontonotes_loss: 0.0234
09/16 06:24:25 AM: Update 7339: task edges-ner-ontonotes, batch 339 (7339): mcc: 0.9351, acc: 0.9018, precision: 0.9540, recall: 0.9236, f1: 0.9386, edges-ner-ontonotes_loss: 0.0207
09/16 06:24:26 AM: Update 8857: task edges-ner-ontonotes, batch 857 (8857): mcc: 0.9299, acc: 0.8957, precision: 0.9497, recall: 0.9180, f1: 0.9335, edges-ner-ontonotes_loss: 0.0232
09/16 06:24:35 AM: Update 7405: task edges-ner-ontonotes, batch 405 (7405): mcc: 0.9348, acc: 0.9010, precision: 0.9537, recall: 0.9233, f1: 0.9382, edges-ner-ontonotes_loss: 0.0205
09/16 06:24:36 AM: Update 8934: task edges-ner-ontonotes, batch 934 (8934): mcc: 0.9303, acc: 0.8961, precision: 0.9500, recall: 0.9185, f1: 0.9340, edges-ner-ontonotes_loss: 0.0230
09/16 06:24:44 AM: ***** Step 9000 / Validation 9 *****
09/16 06:24:44 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:24:44 AM: Validating...
09/16 06:24:45 AM: Update 7472: task edges-ner-ontonotes, batch 472 (7472): mcc: 0.9334, acc: 0.8990, precision: 0.9526, recall: 0.9217, f1: 0.9369, edges-ner-ontonotes_loss: 0.0211
09/16 06:24:46 AM: Evaluate: task edges-ner-ontonotes, batch 9 (157): mcc: 0.8384, acc: 0.7789, precision: 0.8879, recall: 0.8078, f1: 0.8459, edges-ner-ontonotes_loss: 0.0437
09/16 06:24:55 AM: Update 7518: task edges-ner-ontonotes, batch 518 (7518): mcc: 0.9301, acc: 0.8946, precision: 0.9507, recall: 0.9174, f1: 0.9338, edges-ner-ontonotes_loss: 0.0225
09/16 06:24:56 AM: Evaluate: task edges-ner-ontonotes, batch 71 (157): mcc: 0.9094, acc: 0.8722, precision: 0.9393, recall: 0.8898, f1: 0.9139, edges-ner-ontonotes_loss: 0.0302
09/16 06:25:05 AM: Update 7567: task edges-ner-ontonotes, batch 567 (7567): mcc: 0.9271, acc: 0.8910, precision: 0.9486, recall: 0.9140, f1: 0.9310, edges-ner-ontonotes_loss: 0.0238
09/16 06:25:06 AM: Evaluate: task edges-ner-ontonotes, batch 122 (157): mcc: 0.9266, acc: 0.8955, precision: 0.9503, recall: 0.9112, f1: 0.9304, edges-ner-ontonotes_loss: 0.0251
09/16 06:25:12 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:25:12 AM: Best result seen so far for macro.
09/16 06:25:14 AM: Updating LR scheduler:
09/16 06:25:14 AM: 	Best result seen so far for macro_avg: 0.938
09/16 06:25:14 AM: 	# validation passes without improvement: 0
09/16 06:25:14 AM: edges-ner-ontonotes_loss: training: 0.022797 validation: 0.022562
09/16 06:25:14 AM: macro_avg: validation: 0.937589
09/16 06:25:14 AM: micro_avg: validation: 0.000000
09/16 06:25:14 AM: edges-ner-ontonotes_mcc: training: 0.930682 validation: 0.934158
09/16 06:25:14 AM: edges-ner-ontonotes_acc: training: 0.896530 validation: 0.905596
09/16 06:25:14 AM: edges-ner-ontonotes_precision: training: 0.950060 validation: 0.954799
09/16 06:25:14 AM: edges-ner-ontonotes_recall: training: 0.919120 validation: 0.920989
09/16 06:25:14 AM: edges-ner-ontonotes_f1: training: 0.934334 validation: 0.937589
09/16 06:25:14 AM: Global learning rate: 0.0001
09/16 06:25:14 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:25:15 AM: Update 7633: task edges-ner-ontonotes, batch 633 (7633): mcc: 0.9246, acc: 0.8878, precision: 0.9472, recall: 0.9106, f1: 0.9285, edges-ner-ontonotes_loss: 0.0248
09/16 06:25:16 AM: Update 9017: task edges-ner-ontonotes, batch 17 (9017): mcc: 0.9354, acc: 0.9022, precision: 0.9567, recall: 0.9215, f1: 0.9388, edges-ner-ontonotes_loss: 0.0219
09/16 06:25:25 AM: Update 7709: task edges-ner-ontonotes, batch 709 (7709): mcc: 0.9215, acc: 0.8833, precision: 0.9454, recall: 0.9066, f1: 0.9256, edges-ner-ontonotes_loss: 0.0262
09/16 06:25:26 AM: Update 9076: task edges-ner-ontonotes, batch 76 (9076): mcc: 0.9068, acc: 0.8646, precision: 0.9354, recall: 0.8888, f1: 0.9115, edges-ner-ontonotes_loss: 0.0318
09/16 06:25:36 AM: Update 9163: task edges-ner-ontonotes, batch 163 (9163): mcc: 0.9042, acc: 0.8611, precision: 0.9340, recall: 0.8854, f1: 0.9090, edges-ner-ontonotes_loss: 0.0330
09/16 06:25:38 AM: Update 7781: task edges-ner-ontonotes, batch 781 (7781): mcc: 0.9199, acc: 0.8811, precision: 0.9447, recall: 0.9042, f1: 0.9240, edges-ner-ontonotes_loss: 0.0270
09/16 06:25:46 AM: Update 9259: task edges-ner-ontonotes, batch 259 (9259): mcc: 0.9007, acc: 0.8563, precision: 0.9322, recall: 0.8805, f1: 0.9056, edges-ner-ontonotes_loss: 0.0347
09/16 06:25:48 AM: Update 7861: task edges-ner-ontonotes, batch 861 (7861): mcc: 0.9182, acc: 0.8792, precision: 0.9435, recall: 0.9023, f1: 0.9224, edges-ner-ontonotes_loss: 0.0276
09/16 06:25:57 AM: Update 9337: task edges-ner-ontonotes, batch 337 (9337): mcc: 0.9000, acc: 0.8562, precision: 0.9317, recall: 0.8798, f1: 0.9050, edges-ner-ontonotes_loss: 0.0348
09/16 06:25:58 AM: Update 7941: task edges-ner-ontonotes, batch 941 (7941): mcc: 0.9178, acc: 0.8786, precision: 0.9434, recall: 0.9015, f1: 0.9220, edges-ner-ontonotes_loss: 0.0278
09/16 06:26:05 AM: ***** Step 8000 / Validation 8 *****
09/16 06:26:05 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:26:05 AM: Validating...
09/16 06:26:07 AM: Update 9424: task edges-ner-ontonotes, batch 424 (9424): mcc: 0.8998, acc: 0.8563, precision: 0.9313, recall: 0.8798, f1: 0.9048, edges-ner-ontonotes_loss: 0.0344
09/16 06:26:08 AM: Evaluate: task edges-ner-ontonotes, batch 20 (157): mcc: 0.8873, acc: 0.8447, precision: 0.9202, recall: 0.8673, f1: 0.8930, edges-ner-ontonotes_loss: 0.0308
09/16 06:26:17 AM: Update 9489: task edges-ner-ontonotes, batch 489 (9489): mcc: 0.9020, acc: 0.8589, precision: 0.9334, recall: 0.8820, f1: 0.9069, edges-ner-ontonotes_loss: 0.0335
09/16 06:26:18 AM: Evaluate: task edges-ner-ontonotes, batch 77 (157): mcc: 0.9207, acc: 0.8868, precision: 0.9468, recall: 0.9037, f1: 0.9247, edges-ner-ontonotes_loss: 0.0273
09/16 06:26:27 AM: Update 9553: task edges-ner-ontonotes, batch 553 (9553): mcc: 0.9025, acc: 0.8597, precision: 0.9337, recall: 0.8825, f1: 0.9074, edges-ner-ontonotes_loss: 0.0331
09/16 06:26:29 AM: Evaluate: task edges-ner-ontonotes, batch 130 (157): mcc: 0.9304, acc: 0.8988, precision: 0.9544, recall: 0.9144, f1: 0.9339, edges-ner-ontonotes_loss: 0.0238
09/16 06:26:33 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:26:33 AM: Best result seen so far for macro.
09/16 06:26:33 AM: Updating LR scheduler:
09/16 06:26:33 AM: 	Best result seen so far for macro_avg: 0.937
09/16 06:26:33 AM: 	# validation passes without improvement: 0
09/16 06:26:33 AM: edges-ner-ontonotes_loss: training: 0.027954 validation: 0.022517
09/16 06:26:33 AM: macro_avg: validation: 0.937476
09/16 06:26:33 AM: micro_avg: validation: 0.000000
09/16 06:26:33 AM: edges-ner-ontonotes_mcc: training: 0.917201 validation: 0.934066
09/16 06:26:33 AM: edges-ner-ontonotes_acc: training: 0.877875 validation: 0.904155
09/16 06:26:33 AM: edges-ner-ontonotes_precision: training: 0.943072 validation: 0.955871
09/16 06:26:33 AM: edges-ner-ontonotes_recall: training: 0.900779 validation: 0.919776
09/16 06:26:33 AM: edges-ner-ontonotes_f1: training: 0.921440 validation: 0.937476
09/16 06:26:33 AM: Global learning rate: 0.0001
09/16 06:26:33 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:26:37 AM: Update 9629: task edges-ner-ontonotes, batch 629 (9629): mcc: 0.9022, acc: 0.8591, precision: 0.9332, recall: 0.8824, f1: 0.9071, edges-ner-ontonotes_loss: 0.0328
09/16 06:26:39 AM: Update 8046: task edges-ner-ontonotes, batch 46 (8046): mcc: 0.9083, acc: 0.8680, precision: 0.9354, recall: 0.8917, f1: 0.9130, edges-ner-ontonotes_loss: 0.0294
09/16 06:26:47 AM: Update 9711: task edges-ner-ontonotes, batch 711 (9711): mcc: 0.9040, acc: 0.8611, precision: 0.9343, recall: 0.8846, f1: 0.9088, edges-ner-ontonotes_loss: 0.0320
09/16 06:26:49 AM: Update 8102: task edges-ner-ontonotes, batch 102 (8102): mcc: 0.9054, acc: 0.8625, precision: 0.9320, recall: 0.8896, f1: 0.9103, edges-ner-ontonotes_loss: 0.0297
09/16 06:26:57 AM: Update 9784: task edges-ner-ontonotes, batch 784 (9784): mcc: 0.9059, acc: 0.8640, precision: 0.9354, recall: 0.8871, f1: 0.9106, edges-ner-ontonotes_loss: 0.0313
09/16 06:26:59 AM: Update 8173: task edges-ner-ontonotes, batch 173 (8173): mcc: 0.9134, acc: 0.8724, precision: 0.9380, recall: 0.8985, f1: 0.9178, edges-ner-ontonotes_loss: 0.0279
09/16 06:27:08 AM: Update 9867: task edges-ner-ontonotes, batch 867 (9867): mcc: 0.9076, acc: 0.8662, precision: 0.9365, recall: 0.8893, f1: 0.9123, edges-ner-ontonotes_loss: 0.0307
09/16 06:27:09 AM: Update 8252: task edges-ner-ontonotes, batch 252 (8252): mcc: 0.9165, acc: 0.8772, precision: 0.9404, recall: 0.9022, f1: 0.9209, edges-ner-ontonotes_loss: 0.0268
09/16 06:27:19 AM: Update 9949: task edges-ner-ontonotes, batch 949 (9949): mcc: 0.9092, acc: 0.8685, precision: 0.9374, recall: 0.8913, f1: 0.9138, edges-ner-ontonotes_loss: 0.0302
09/16 06:27:19 AM: Update 8321: task edges-ner-ontonotes, batch 321 (8321): mcc: 0.9177, acc: 0.8793, precision: 0.9411, recall: 0.9036, f1: 0.9220, edges-ner-ontonotes_loss: 0.0266
09/16 06:27:27 AM: ***** Step 10000 / Validation 10 *****
09/16 06:27:27 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:27:27 AM: Validating...
09/16 06:27:29 AM: Evaluate: task edges-ner-ontonotes, batch 14 (157): mcc: 0.8643, acc: 0.8093, precision: 0.9128, recall: 0.8320, f1: 0.8705, edges-ner-ontonotes_loss: 0.0380
09/16 06:27:29 AM: Update 8393: task edges-ner-ontonotes, batch 393 (8393): mcc: 0.9194, acc: 0.8817, precision: 0.9427, recall: 0.9053, f1: 0.9236, edges-ner-ontonotes_loss: 0.0263
09/16 06:27:39 AM: Evaluate: task edges-ner-ontonotes, batch 82 (157): mcc: 0.9245, acc: 0.8916, precision: 0.9509, recall: 0.9068, f1: 0.9283, edges-ner-ontonotes_loss: 0.0262
09/16 06:27:39 AM: Update 8431: task edges-ner-ontonotes, batch 431 (8431): mcc: 0.9200, acc: 0.8825, precision: 0.9430, recall: 0.9060, f1: 0.9241, edges-ner-ontonotes_loss: 0.0262
09/16 06:27:49 AM: Evaluate: task edges-ner-ontonotes, batch 135 (157): mcc: 0.9338, acc: 0.9043, precision: 0.9559, recall: 0.9193, f1: 0.9372, edges-ner-ontonotes_loss: 0.0227
09/16 06:27:49 AM: Update 8483: task edges-ner-ontonotes, batch 483 (8483): mcc: 0.9225, acc: 0.8859, precision: 0.9449, recall: 0.9089, f1: 0.9265, edges-ner-ontonotes_loss: 0.0255
09/16 06:27:53 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:27:53 AM: Best result seen so far for macro.
09/16 06:27:54 AM: Updating LR scheduler:
09/16 06:27:54 AM: 	Best result seen so far for macro_avg: 0.939
09/16 06:27:54 AM: 	# validation passes without improvement: 0
09/16 06:27:54 AM: edges-ner-ontonotes_loss: training: 0.029607 validation: 0.021807
09/16 06:27:54 AM: macro_avg: validation: 0.938694
09/16 06:27:54 AM: micro_avg: validation: 0.000000
09/16 06:27:54 AM: edges-ner-ontonotes_mcc: training: 0.910901 validation: 0.935317
09/16 06:27:54 AM: edges-ner-ontonotes_acc: training: 0.870623 validation: 0.906582
09/16 06:27:54 AM: edges-ner-ontonotes_precision: training: 0.938493 validation: 0.955542
09/16 06:27:54 AM: edges-ner-ontonotes_recall: training: 0.893490 validation: 0.922430
09/16 06:27:54 AM: edges-ner-ontonotes_f1: training: 0.915439 validation: 0.938694
09/16 06:27:54 AM: Global learning rate: 0.0001
09/16 06:27:54 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:28:00 AM: Update 10043: task edges-ner-ontonotes, batch 43 (10043): mcc: 0.9435, acc: 0.9154, precision: 0.9589, recall: 0.9344, f1: 0.9465, edges-ner-ontonotes_loss: 0.0180
09/16 06:28:00 AM: Update 8546: task edges-ner-ontonotes, batch 546 (8546): mcc: 0.9244, acc: 0.8885, precision: 0.9458, recall: 0.9115, f1: 0.9283, edges-ner-ontonotes_loss: 0.0250
09/16 06:28:11 AM: Update 10121: task edges-ner-ontonotes, batch 121 (10121): mcc: 0.9402, acc: 0.9106, precision: 0.9568, recall: 0.9303, f1: 0.9434, edges-ner-ontonotes_loss: 0.0197
09/16 06:28:11 AM: Update 8610: task edges-ner-ontonotes, batch 610 (8610): mcc: 0.9260, acc: 0.8907, precision: 0.9466, recall: 0.9137, f1: 0.9299, edges-ner-ontonotes_loss: 0.0244
09/16 06:28:21 AM: Update 10198: task edges-ner-ontonotes, batch 198 (10198): mcc: 0.9409, acc: 0.9106, precision: 0.9571, recall: 0.9313, f1: 0.9440, edges-ner-ontonotes_loss: 0.0193
09/16 06:28:21 AM: Update 8677: task edges-ner-ontonotes, batch 677 (8677): mcc: 0.9273, acc: 0.8924, precision: 0.9476, recall: 0.9152, f1: 0.9311, edges-ner-ontonotes_loss: 0.0239
09/16 06:28:31 AM: Update 8730: task edges-ner-ontonotes, batch 730 (8730): mcc: 0.9284, acc: 0.8938, precision: 0.9485, recall: 0.9164, f1: 0.9322, edges-ner-ontonotes_loss: 0.0236
09/16 06:28:33 AM: Update 10276: task edges-ner-ontonotes, batch 276 (10276): mcc: 0.9399, acc: 0.9093, precision: 0.9561, recall: 0.9304, f1: 0.9431, edges-ner-ontonotes_loss: 0.0196
09/16 06:28:41 AM: Update 8802: task edges-ner-ontonotes, batch 802 (8802): mcc: 0.9296, acc: 0.8953, precision: 0.9495, recall: 0.9176, f1: 0.9333, edges-ner-ontonotes_loss: 0.0233
09/16 06:28:43 AM: Update 10352: task edges-ner-ontonotes, batch 352 (10352): mcc: 0.9393, acc: 0.9086, precision: 0.9558, recall: 0.9297, f1: 0.9426, edges-ner-ontonotes_loss: 0.0198
09/16 06:28:51 AM: Update 8889: task edges-ner-ontonotes, batch 889 (8889): mcc: 0.9301, acc: 0.8958, precision: 0.9497, recall: 0.9183, f1: 0.9338, edges-ner-ontonotes_loss: 0.0231
09/16 06:28:56 AM: Update 10430: task edges-ner-ontonotes, batch 430 (10430): mcc: 0.9390, acc: 0.9081, precision: 0.9552, recall: 0.9295, f1: 0.9422, edges-ner-ontonotes_loss: 0.0197
09/16 06:29:01 AM: Update 8956: task edges-ner-ontonotes, batch 956 (8956): mcc: 0.9303, acc: 0.8960, precision: 0.9499, recall: 0.9185, f1: 0.9339, edges-ner-ontonotes_loss: 0.0229
09/16 06:29:06 AM: Update 10508: task edges-ner-ontonotes, batch 508 (10508): mcc: 0.9386, acc: 0.9076, precision: 0.9550, recall: 0.9291, f1: 0.9418, edges-ner-ontonotes_loss: 0.0199
09/16 06:29:09 AM: ***** Step 9000 / Validation 9 *****
09/16 06:29:09 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:29:09 AM: Validating...
09/16 06:29:12 AM: Evaluate: task edges-ner-ontonotes, batch 21 (157): mcc: 0.8748, acc: 0.8269, precision: 0.9116, recall: 0.8524, f1: 0.8810, edges-ner-ontonotes_loss: 0.0342
09/16 06:29:16 AM: Update 10573: task edges-ner-ontonotes, batch 573 (10573): mcc: 0.9386, acc: 0.9077, precision: 0.9550, recall: 0.9291, f1: 0.9419, edges-ner-ontonotes_loss: 0.0200
09/16 06:29:22 AM: Evaluate: task edges-ner-ontonotes, batch 78 (157): mcc: 0.9145, acc: 0.8791, precision: 0.9433, recall: 0.8956, f1: 0.9188, edges-ner-ontonotes_loss: 0.0292
09/16 06:29:26 AM: Update 10621: task edges-ner-ontonotes, batch 621 (10621): mcc: 0.9364, acc: 0.9047, precision: 0.9538, recall: 0.9262, f1: 0.9398, edges-ner-ontonotes_loss: 0.0207
09/16 06:29:32 AM: Evaluate: task edges-ner-ontonotes, batch 129 (157): mcc: 0.9287, acc: 0.8981, precision: 0.9520, recall: 0.9136, f1: 0.9324, edges-ner-ontonotes_loss: 0.0245
09/16 06:29:36 AM: Update 10678: task edges-ner-ontonotes, batch 678 (10678): mcc: 0.9332, acc: 0.9003, precision: 0.9519, recall: 0.9221, f1: 0.9368, edges-ner-ontonotes_loss: 0.0221
09/16 06:29:37 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:29:37 AM: Best result seen so far for macro.
09/16 06:29:37 AM: Updating LR scheduler:
09/16 06:29:37 AM: 	Best result seen so far for macro_avg: 0.938
09/16 06:29:37 AM: 	# validation passes without improvement: 0
09/16 06:29:37 AM: edges-ner-ontonotes_loss: training: 0.022797 validation: 0.022562
09/16 06:29:37 AM: macro_avg: validation: 0.937589
09/16 06:29:37 AM: micro_avg: validation: 0.000000
09/16 06:29:37 AM: edges-ner-ontonotes_mcc: training: 0.930682 validation: 0.934158
09/16 06:29:37 AM: edges-ner-ontonotes_acc: training: 0.896530 validation: 0.905596
09/16 06:29:37 AM: edges-ner-ontonotes_precision: training: 0.950060 validation: 0.954799
09/16 06:29:37 AM: edges-ner-ontonotes_recall: training: 0.919120 validation: 0.920989
09/16 06:29:37 AM: edges-ner-ontonotes_f1: training: 0.934334 validation: 0.937589
09/16 06:29:37 AM: Global learning rate: 0.0001
09/16 06:29:37 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:29:42 AM: Update 9031: task edges-ner-ontonotes, batch 31 (9031): mcc: 0.9342, acc: 0.8996, precision: 0.9538, recall: 0.9221, f1: 0.9377, edges-ner-ontonotes_loss: 0.0220
09/16 06:29:46 AM: Update 10768: task edges-ner-ontonotes, batch 768 (10768): mcc: 0.9300, acc: 0.8962, precision: 0.9497, recall: 0.9182, f1: 0.9337, edges-ner-ontonotes_loss: 0.0235
09/16 06:29:52 AM: Update 9080: task edges-ner-ontonotes, batch 80 (9080): mcc: 0.9068, acc: 0.8644, precision: 0.9354, recall: 0.8888, f1: 0.9115, edges-ner-ontonotes_loss: 0.0316
09/16 06:29:57 AM: Update 10847: task edges-ner-ontonotes, batch 847 (10847): mcc: 0.9272, acc: 0.8925, precision: 0.9478, recall: 0.9148, f1: 0.9310, edges-ner-ontonotes_loss: 0.0247
09/16 06:30:02 AM: Update 9152: task edges-ner-ontonotes, batch 152 (9152): mcc: 0.9050, acc: 0.8615, precision: 0.9347, recall: 0.8863, f1: 0.9098, edges-ner-ontonotes_loss: 0.0329
09/16 06:30:07 AM: Update 10914: task edges-ner-ontonotes, batch 914 (10914): mcc: 0.9255, acc: 0.8902, precision: 0.9468, recall: 0.9126, f1: 0.9294, edges-ner-ontonotes_loss: 0.0255
09/16 06:30:12 AM: Update 9230: task edges-ner-ontonotes, batch 230 (9230): mcc: 0.9025, acc: 0.8588, precision: 0.9335, recall: 0.8827, f1: 0.9074, edges-ner-ontonotes_loss: 0.0340
09/16 06:30:16 AM: ***** Step 11000 / Validation 11 *****
09/16 06:30:16 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:30:16 AM: Validating...
09/16 06:30:17 AM: Evaluate: task edges-ner-ontonotes, batch 1 (157): mcc: 0.8344, acc: 0.7213, precision: 0.9216, recall: 0.7705, f1: 0.8393, edges-ner-ontonotes_loss: 0.0431
09/16 06:30:22 AM: Update 9294: task edges-ner-ontonotes, batch 294 (9294): mcc: 0.9006, acc: 0.8565, precision: 0.9325, recall: 0.8801, f1: 0.9056, edges-ner-ontonotes_loss: 0.0346
09/16 06:30:27 AM: Evaluate: task edges-ner-ontonotes, batch 64 (157): mcc: 0.9208, acc: 0.8887, precision: 0.9415, recall: 0.9090, f1: 0.9250, edges-ner-ontonotes_loss: 0.0268
09/16 06:30:34 AM: Update 9337: task edges-ner-ontonotes, batch 337 (9337): mcc: 0.9000, acc: 0.8562, precision: 0.9317, recall: 0.8798, f1: 0.9050, edges-ner-ontonotes_loss: 0.0348
09/16 06:30:37 AM: Evaluate: task edges-ner-ontonotes, batch 123 (157): mcc: 0.9303, acc: 0.8989, precision: 0.9535, recall: 0.9151, f1: 0.9339, edges-ner-ontonotes_loss: 0.0237
09/16 06:30:42 AM: Updating LR scheduler:
09/16 06:30:42 AM: 	Best result seen so far for macro_avg: 0.939
09/16 06:30:42 AM: 	# validation passes without improvement: 1
09/16 06:30:42 AM: edges-ner-ontonotes_loss: training: 0.025908 validation: 0.021914
09/16 06:30:42 AM: macro_avg: validation: 0.938632
09/16 06:30:42 AM: micro_avg: validation: 0.000000
09/16 06:30:42 AM: edges-ner-ontonotes_mcc: training: 0.924149 validation: 0.935275
09/16 06:30:42 AM: edges-ner-ontonotes_acc: training: 0.888565 validation: 0.905596
09/16 06:30:42 AM: edges-ner-ontonotes_precision: training: 0.945806 validation: 0.956474
09/16 06:30:42 AM: edges-ner-ontonotes_recall: training: 0.911071 validation: 0.921444
09/16 06:30:42 AM: edges-ner-ontonotes_f1: training: 0.928114 validation: 0.938632
09/16 06:30:42 AM: Global learning rate: 0.0001
09/16 06:30:42 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:30:44 AM: Update 9398: task edges-ner-ontonotes, batch 398 (9398): mcc: 0.8995, acc: 0.8557, precision: 0.9314, recall: 0.8793, f1: 0.9046, edges-ner-ontonotes_loss: 0.0346
09/16 06:30:47 AM: Update 11046: task edges-ner-ontonotes, batch 46 (11046): mcc: 0.9047, acc: 0.8618, precision: 0.9357, recall: 0.8847, f1: 0.9095, edges-ner-ontonotes_loss: 0.0299
09/16 06:30:54 AM: Update 9477: task edges-ner-ontonotes, batch 477 (9477): mcc: 0.9023, acc: 0.8593, precision: 0.9335, recall: 0.8823, f1: 0.9072, edges-ner-ontonotes_loss: 0.0335
09/16 06:30:57 AM: Update 11142: task edges-ner-ontonotes, batch 142 (11142): mcc: 0.9066, acc: 0.8639, precision: 0.9337, recall: 0.8902, f1: 0.9114, edges-ner-ontonotes_loss: 0.0291
09/16 06:31:04 AM: Update 9565: task edges-ner-ontonotes, batch 565 (9565): mcc: 0.9021, acc: 0.8592, precision: 0.9332, recall: 0.8823, f1: 0.9070, edges-ner-ontonotes_loss: 0.0331
09/16 06:31:07 AM: Update 11213: task edges-ner-ontonotes, batch 213 (11213): mcc: 0.9051, acc: 0.8639, precision: 0.9321, recall: 0.8889, f1: 0.9100, edges-ner-ontonotes_loss: 0.0294
09/16 06:31:17 AM: Update 9650: task edges-ner-ontonotes, batch 650 (9650): mcc: 0.9026, acc: 0.8595, precision: 0.9335, recall: 0.8828, f1: 0.9074, edges-ner-ontonotes_loss: 0.0326
09/16 06:31:17 AM: Update 11304: task edges-ner-ontonotes, batch 304 (11304): mcc: 0.9124, acc: 0.8729, precision: 0.9377, recall: 0.8971, f1: 0.9170, edges-ner-ontonotes_loss: 0.0277
09/16 06:31:27 AM: Update 9715: task edges-ner-ontonotes, batch 715 (9715): mcc: 0.9041, acc: 0.8613, precision: 0.9345, recall: 0.8847, f1: 0.9089, edges-ner-ontonotes_loss: 0.0319
09/16 06:31:27 AM: Update 11382: task edges-ner-ontonotes, batch 382 (11382): mcc: 0.9144, acc: 0.8758, precision: 0.9389, recall: 0.8995, f1: 0.9188, edges-ner-ontonotes_loss: 0.0271
09/16 06:31:37 AM: Update 9782: task edges-ner-ontonotes, batch 782 (9782): mcc: 0.9058, acc: 0.8638, precision: 0.9354, recall: 0.8870, f1: 0.9105, edges-ner-ontonotes_loss: 0.0314
09/16 06:31:37 AM: Update 11461: task edges-ner-ontonotes, batch 461 (11461): mcc: 0.9166, acc: 0.8790, precision: 0.9406, recall: 0.9022, f1: 0.9210, edges-ner-ontonotes_loss: 0.0267
09/16 06:31:47 AM: Update 9863: task edges-ner-ontonotes, batch 863 (9863): mcc: 0.9075, acc: 0.8661, precision: 0.9365, recall: 0.8891, f1: 0.9122, edges-ner-ontonotes_loss: 0.0307
09/16 06:31:47 AM: Update 11532: task edges-ner-ontonotes, batch 532 (11532): mcc: 0.9189, acc: 0.8817, precision: 0.9425, recall: 0.9044, f1: 0.9231, edges-ner-ontonotes_loss: 0.0263
09/16 06:31:57 AM: Update 9932: task edges-ner-ontonotes, batch 932 (9932): mcc: 0.9089, acc: 0.8681, precision: 0.9373, recall: 0.8910, f1: 0.9136, edges-ner-ontonotes_loss: 0.0302
09/16 06:31:57 AM: Update 11607: task edges-ner-ontonotes, batch 607 (11607): mcc: 0.9225, acc: 0.8858, precision: 0.9448, recall: 0.9089, f1: 0.9265, edges-ner-ontonotes_loss: 0.0253
09/16 06:32:07 AM: Update 9979: task edges-ner-ontonotes, batch 979 (9979): mcc: 0.9100, acc: 0.8695, precision: 0.9380, recall: 0.8924, f1: 0.9146, edges-ner-ontonotes_loss: 0.0299
09/16 06:32:07 AM: Update 11696: task edges-ner-ontonotes, batch 696 (11696): mcc: 0.9246, acc: 0.8886, precision: 0.9463, recall: 0.9114, f1: 0.9285, edges-ner-ontonotes_loss: 0.0245
09/16 06:32:10 AM: ***** Step 10000 / Validation 10 *****
09/16 06:32:10 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:32:10 AM: Validating...
09/16 06:32:17 AM: Evaluate: task edges-ner-ontonotes, batch 45 (157): mcc: 0.9082, acc: 0.8731, precision: 0.9367, recall: 0.8902, f1: 0.9129, edges-ner-ontonotes_loss: 0.0303
09/16 06:32:18 AM: Update 11765: task edges-ner-ontonotes, batch 765 (11765): mcc: 0.9261, acc: 0.8907, precision: 0.9470, recall: 0.9136, f1: 0.9300, edges-ner-ontonotes_loss: 0.0240
09/16 06:32:27 AM: Evaluate: task edges-ner-ontonotes, batch 101 (157): mcc: 0.9235, acc: 0.8915, precision: 0.9490, recall: 0.9067, f1: 0.9274, edges-ner-ontonotes_loss: 0.0259
09/16 06:32:31 AM: Update 11819: task edges-ner-ontonotes, batch 819 (11819): mcc: 0.9276, acc: 0.8926, precision: 0.9480, recall: 0.9153, f1: 0.9314, edges-ner-ontonotes_loss: 0.0236
09/16 06:32:38 AM: Evaluate: task edges-ner-ontonotes, batch 152 (157): mcc: 0.9349, acc: 0.9060, precision: 0.9557, recall: 0.9216, f1: 0.9383, edges-ner-ontonotes_loss: 0.0221
09/16 06:32:38 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:32:38 AM: Best result seen so far for macro.
09/16 06:32:38 AM: Updating LR scheduler:
09/16 06:32:38 AM: 	Best result seen so far for macro_avg: 0.939
09/16 06:32:38 AM: 	# validation passes without improvement: 0
09/16 06:32:38 AM: edges-ner-ontonotes_loss: training: 0.029607 validation: 0.021807
09/16 06:32:38 AM: macro_avg: validation: 0.938694
09/16 06:32:38 AM: micro_avg: validation: 0.000000
09/16 06:32:38 AM: edges-ner-ontonotes_mcc: training: 0.910901 validation: 0.935317
09/16 06:32:38 AM: edges-ner-ontonotes_acc: training: 0.870623 validation: 0.906582
09/16 06:32:38 AM: edges-ner-ontonotes_precision: training: 0.938493 validation: 0.955542
09/16 06:32:38 AM: edges-ner-ontonotes_recall: training: 0.893490 validation: 0.922430
09/16 06:32:38 AM: edges-ner-ontonotes_f1: training: 0.915439 validation: 0.938694
09/16 06:32:38 AM: Global learning rate: 0.0001
09/16 06:32:38 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:32:41 AM: Update 11874: task edges-ner-ontonotes, batch 874 (11874): mcc: 0.9283, acc: 0.8934, precision: 0.9485, recall: 0.9162, f1: 0.9321, edges-ner-ontonotes_loss: 0.0233
09/16 06:32:48 AM: Update 10071: task edges-ner-ontonotes, batch 71 (10071): mcc: 0.9390, acc: 0.9097, precision: 0.9554, recall: 0.9294, f1: 0.9422, edges-ner-ontonotes_loss: 0.0194
09/16 06:32:53 AM: Update 11954: task edges-ner-ontonotes, batch 954 (11954): mcc: 0.9294, acc: 0.8948, precision: 0.9491, recall: 0.9177, f1: 0.9331, edges-ner-ontonotes_loss: 0.0230
09/16 06:32:58 AM: Update 10146: task edges-ner-ontonotes, batch 146 (10146): mcc: 0.9398, acc: 0.9099, precision: 0.9564, recall: 0.9301, f1: 0.9430, edges-ner-ontonotes_loss: 0.0196
09/16 06:33:01 AM: ***** Step 12000 / Validation 12 *****
09/16 06:33:01 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:33:01 AM: Validating...
09/16 06:33:05 AM: Evaluate: task edges-ner-ontonotes, batch 27 (157): mcc: 0.8753, acc: 0.8360, precision: 0.9046, recall: 0.8601, f1: 0.8818, edges-ner-ontonotes_loss: 0.0388
09/16 06:33:08 AM: Update 10207: task edges-ner-ontonotes, batch 207 (10207): mcc: 0.9403, acc: 0.9098, precision: 0.9567, recall: 0.9307, f1: 0.9435, edges-ner-ontonotes_loss: 0.0195
09/16 06:33:16 AM: Evaluate: task edges-ner-ontonotes, batch 85 (157): mcc: 0.9234, acc: 0.8914, precision: 0.9455, recall: 0.9101, f1: 0.9274, edges-ner-ontonotes_loss: 0.0268
09/16 06:33:18 AM: Update 10258: task edges-ner-ontonotes, batch 258 (10258): mcc: 0.9400, acc: 0.9094, precision: 0.9563, recall: 0.9305, f1: 0.9432, edges-ner-ontonotes_loss: 0.0196
09/16 06:33:26 AM: Evaluate: task edges-ner-ontonotes, batch 144 (157): mcc: 0.9360, acc: 0.9090, precision: 0.9535, recall: 0.9257, f1: 0.9394, edges-ner-ontonotes_loss: 0.0224
09/16 06:33:28 AM: Update 10292: task edges-ner-ontonotes, batch 292 (10292): mcc: 0.9396, acc: 0.9088, precision: 0.9558, recall: 0.9301, f1: 0.9428, edges-ner-ontonotes_loss: 0.0196
09/16 06:33:28 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:33:28 AM: Best result seen so far for macro.
09/16 06:33:28 AM: Updating LR scheduler:
09/16 06:33:28 AM: 	Best result seen so far for macro_avg: 0.940
09/16 06:33:28 AM: 	# validation passes without improvement: 0
09/16 06:33:28 AM: edges-ner-ontonotes_loss: training: 0.022950 validation: 0.021802
09/16 06:33:28 AM: macro_avg: validation: 0.940290
09/16 06:33:28 AM: micro_avg: validation: 0.000000
09/16 06:33:28 AM: edges-ner-ontonotes_mcc: training: 0.929598 validation: 0.936934
09/16 06:33:28 AM: edges-ner-ontonotes_acc: training: 0.895095 validation: 0.910297
09/16 06:33:28 AM: edges-ner-ontonotes_precision: training: 0.949220 validation: 0.953748
09/16 06:33:28 AM: edges-ner-ontonotes_recall: training: 0.917915 validation: 0.927207
09/16 06:33:28 AM: edges-ner-ontonotes_f1: training: 0.933305 validation: 0.940290
09/16 06:33:28 AM: Global learning rate: 0.0001
09/16 06:33:28 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:33:36 AM: Update 12058: task edges-ner-ontonotes, batch 58 (12058): mcc: 0.9392, acc: 0.9075, precision: 0.9559, recall: 0.9294, f1: 0.9425, edges-ner-ontonotes_loss: 0.0193
09/16 06:33:38 AM: Update 10358: task edges-ner-ontonotes, batch 358 (10358): mcc: 0.9393, acc: 0.9085, precision: 0.9558, recall: 0.9296, f1: 0.9425, edges-ner-ontonotes_loss: 0.0197
09/16 06:33:46 AM: Update 12131: task edges-ner-ontonotes, batch 131 (12131): mcc: 0.9406, acc: 0.9092, precision: 0.9567, recall: 0.9312, f1: 0.9438, edges-ner-ontonotes_loss: 0.0192
09/16 06:33:48 AM: Update 10429: task edges-ner-ontonotes, batch 429 (10429): mcc: 0.9389, acc: 0.9080, precision: 0.9552, recall: 0.9295, f1: 0.9422, edges-ner-ontonotes_loss: 0.0197
09/16 06:33:56 AM: Update 12200: task edges-ner-ontonotes, batch 200 (12200): mcc: 0.9288, acc: 0.8936, precision: 0.9495, recall: 0.9161, f1: 0.9325, edges-ner-ontonotes_loss: 0.0242
09/16 06:33:58 AM: Update 10501: task edges-ner-ontonotes, batch 501 (10501): mcc: 0.9387, acc: 0.9078, precision: 0.9551, recall: 0.9291, f1: 0.9419, edges-ner-ontonotes_loss: 0.0199
09/16 06:34:06 AM: Update 12280: task edges-ner-ontonotes, batch 280 (12280): mcc: 0.9217, acc: 0.8851, precision: 0.9448, recall: 0.9075, f1: 0.9258, edges-ner-ontonotes_loss: 0.0275
09/16 06:34:08 AM: Update 10570: task edges-ner-ontonotes, batch 570 (10570): mcc: 0.9386, acc: 0.9078, precision: 0.9551, recall: 0.9291, f1: 0.9419, edges-ner-ontonotes_loss: 0.0200
09/16 06:34:16 AM: Update 12366: task edges-ner-ontonotes, batch 366 (12366): mcc: 0.9173, acc: 0.8796, precision: 0.9422, recall: 0.9018, f1: 0.9216, edges-ner-ontonotes_loss: 0.0292
09/16 06:34:18 AM: Update 10628: task edges-ner-ontonotes, batch 628 (10628): mcc: 0.9361, acc: 0.9043, precision: 0.9536, recall: 0.9258, f1: 0.9395, edges-ner-ontonotes_loss: 0.0209
09/16 06:34:26 AM: Update 12446: task edges-ner-ontonotes, batch 446 (12446): mcc: 0.9142, acc: 0.8759, precision: 0.9395, recall: 0.8986, f1: 0.9186, edges-ner-ontonotes_loss: 0.0300
09/16 06:34:28 AM: Update 10702: task edges-ner-ontonotes, batch 702 (10702): mcc: 0.9322, acc: 0.8990, precision: 0.9512, recall: 0.9209, f1: 0.9358, edges-ner-ontonotes_loss: 0.0225
09/16 06:34:36 AM: Update 12518: task edges-ner-ontonotes, batch 518 (12518): mcc: 0.9128, acc: 0.8740, precision: 0.9384, recall: 0.8971, f1: 0.9173, edges-ner-ontonotes_loss: 0.0300
09/16 06:34:38 AM: Update 10780: task edges-ner-ontonotes, batch 780 (10780): mcc: 0.9296, acc: 0.8957, precision: 0.9495, recall: 0.9177, f1: 0.9333, edges-ner-ontonotes_loss: 0.0237
09/16 06:34:46 AM: Update 12606: task edges-ner-ontonotes, batch 606 (12606): mcc: 0.9123, acc: 0.8732, precision: 0.9381, recall: 0.8965, f1: 0.9168, edges-ner-ontonotes_loss: 0.0298
09/16 06:34:48 AM: Update 10853: task edges-ner-ontonotes, batch 853 (10853): mcc: 0.9272, acc: 0.8925, precision: 0.9478, recall: 0.9147, f1: 0.9310, edges-ner-ontonotes_loss: 0.0247
09/16 06:34:57 AM: Update 12710: task edges-ner-ontonotes, batch 710 (12710): mcc: 0.9121, acc: 0.8730, precision: 0.9382, recall: 0.8960, f1: 0.9166, edges-ner-ontonotes_loss: 0.0298
09/16 06:34:58 AM: Update 10920: task edges-ner-ontonotes, batch 920 (10920): mcc: 0.9253, acc: 0.8901, precision: 0.9466, recall: 0.9125, f1: 0.9292, edges-ner-ontonotes_loss: 0.0255
09/16 06:35:07 AM: ***** Step 11000 / Validation 11 *****
09/16 06:35:09 AM: Update 12787: task edges-ner-ontonotes, batch 787 (12787): mcc: 0.9122, acc: 0.8730, precision: 0.9380, recall: 0.8963, f1: 0.9167, edges-ner-ontonotes_loss: 0.0297
09/16 06:35:10 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:35:10 AM: Validating...
09/16 06:35:10 AM: Evaluate: task edges-ner-ontonotes, batch 1 (157): mcc: 0.8344, acc: 0.7213, precision: 0.9216, recall: 0.7705, f1: 0.8393, edges-ner-ontonotes_loss: 0.0431
09/16 06:35:20 AM: Update 12850: task edges-ner-ontonotes, batch 850 (12850): mcc: 0.9130, acc: 0.8739, precision: 0.9387, recall: 0.8972, f1: 0.9175, edges-ner-ontonotes_loss: 0.0293
09/16 06:35:20 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.9228, acc: 0.8917, precision: 0.9424, recall: 0.9119, f1: 0.9269, edges-ner-ontonotes_loss: 0.0264
09/16 06:35:30 AM: Update 12907: task edges-ner-ontonotes, batch 907 (12907): mcc: 0.9135, acc: 0.8748, precision: 0.9389, recall: 0.8980, f1: 0.9180, edges-ner-ontonotes_loss: 0.0290
09/16 06:35:32 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9278, acc: 0.8956, precision: 0.9516, recall: 0.9123, f1: 0.9315, edges-ner-ontonotes_loss: 0.0244
09/16 06:35:40 AM: Updating LR scheduler:
09/16 06:35:40 AM: 	Best result seen so far for macro_avg: 0.939
09/16 06:35:40 AM: 	# validation passes without improvement: 1
09/16 06:35:40 AM: edges-ner-ontonotes_loss: training: 0.025908 validation: 0.021914
09/16 06:35:40 AM: macro_avg: validation: 0.938632
09/16 06:35:40 AM: micro_avg: validation: 0.000000
09/16 06:35:40 AM: edges-ner-ontonotes_mcc: training: 0.924149 validation: 0.935275
09/16 06:35:40 AM: edges-ner-ontonotes_acc: training: 0.888565 validation: 0.905596
09/16 06:35:40 AM: edges-ner-ontonotes_precision: training: 0.945806 validation: 0.956474
09/16 06:35:40 AM: edges-ner-ontonotes_recall: training: 0.911071 validation: 0.921444
09/16 06:35:40 AM: edges-ner-ontonotes_f1: training: 0.928114 validation: 0.938632
09/16 06:35:40 AM: Global learning rate: 0.0001
09/16 06:35:40 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:35:40 AM: Update 12969: task edges-ner-ontonotes, batch 969 (12969): mcc: 0.9148, acc: 0.8765, precision: 0.9398, recall: 0.8994, f1: 0.9192, edges-ner-ontonotes_loss: 0.0287
09/16 06:35:42 AM: Update 11018: task edges-ner-ontonotes, batch 18 (11018): mcc: 0.9152, acc: 0.8744, precision: 0.9464, recall: 0.8939, f1: 0.9194, edges-ner-ontonotes_loss: 0.0289
09/16 06:35:43 AM: ***** Step 13000 / Validation 13 *****
09/16 06:35:44 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:35:44 AM: Validating...
09/16 06:35:50 AM: Evaluate: task edges-ner-ontonotes, batch 47 (157): mcc: 0.9113, acc: 0.8779, precision: 0.9345, recall: 0.8981, f1: 0.9159, edges-ner-ontonotes_loss: 0.0290
09/16 06:35:54 AM: Update 11073: task edges-ner-ontonotes, batch 73 (11073): mcc: 0.9088, acc: 0.8676, precision: 0.9366, recall: 0.8914, f1: 0.9135, edges-ner-ontonotes_loss: 0.0292
09/16 06:36:00 AM: Evaluate: task edges-ner-ontonotes, batch 109 (157): mcc: 0.9277, acc: 0.8976, precision: 0.9485, recall: 0.9152, f1: 0.9315, edges-ner-ontonotes_loss: 0.0242
09/16 06:36:04 AM: Update 11128: task edges-ner-ontonotes, batch 128 (11128): mcc: 0.9071, acc: 0.8642, precision: 0.9340, recall: 0.8908, f1: 0.9119, edges-ner-ontonotes_loss: 0.0291
09/16 06:36:09 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:36:09 AM: Best result seen so far for macro.
09/16 06:36:09 AM: Updating LR scheduler:
09/16 06:36:09 AM: 	Best result seen so far for macro_avg: 0.941
09/16 06:36:09 AM: 	# validation passes without improvement: 0
09/16 06:36:09 AM: edges-ner-ontonotes_loss: training: 0.028500 validation: 0.021157
09/16 06:36:09 AM: macro_avg: validation: 0.940597
09/16 06:36:09 AM: micro_avg: validation: 0.000000
09/16 06:36:09 AM: edges-ner-ontonotes_mcc: training: 0.915168 validation: 0.937272
09/16 06:36:09 AM: edges-ner-ontonotes_acc: training: 0.877101 validation: 0.909539
09/16 06:36:09 AM: edges-ner-ontonotes_precision: training: 0.940025 validation: 0.954702
09/16 06:36:09 AM: edges-ner-ontonotes_recall: training: 0.899945 validation: 0.926903
09/16 06:36:09 AM: edges-ner-ontonotes_f1: training: 0.919548 validation: 0.940597
09/16 06:36:09 AM: Global learning rate: 0.0001
09/16 06:36:09 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:36:10 AM: Update 13010: task edges-ner-ontonotes, batch 10 (13010): mcc: 0.9388, acc: 0.9030, precision: 0.9653, recall: 0.9195, f1: 0.9418, edges-ner-ontonotes_loss: 0.0205
09/16 06:36:14 AM: Update 11197: task edges-ner-ontonotes, batch 197 (11197): mcc: 0.9065, acc: 0.8652, precision: 0.9329, recall: 0.8907, f1: 0.9113, edges-ner-ontonotes_loss: 0.0292
09/16 06:36:20 AM: Update 13086: task edges-ner-ontonotes, batch 86 (13086): mcc: 0.9268, acc: 0.8916, precision: 0.9483, recall: 0.9136, f1: 0.9306, edges-ner-ontonotes_loss: 0.0239
09/16 06:36:24 AM: Update 11253: task edges-ner-ontonotes, batch 253 (11253): mcc: 0.9088, acc: 0.8687, precision: 0.9348, recall: 0.8932, f1: 0.9135, edges-ner-ontonotes_loss: 0.0285
09/16 06:36:30 AM: Update 13162: task edges-ner-ontonotes, batch 162 (13162): mcc: 0.9337, acc: 0.9014, precision: 0.9513, recall: 0.9235, f1: 0.9372, edges-ner-ontonotes_loss: 0.0216
09/16 06:36:34 AM: Update 11333: task edges-ner-ontonotes, batch 333 (11333): mcc: 0.9127, acc: 0.8736, precision: 0.9375, recall: 0.8979, f1: 0.9172, edges-ner-ontonotes_loss: 0.0276
09/16 06:36:43 AM: Update 13241: task edges-ner-ontonotes, batch 241 (13241): mcc: 0.9357, acc: 0.9035, precision: 0.9529, recall: 0.9257, f1: 0.9391, edges-ner-ontonotes_loss: 0.0208
09/16 06:36:44 AM: Update 11397: task edges-ner-ontonotes, batch 397 (11397): mcc: 0.9153, acc: 0.8770, precision: 0.9396, recall: 0.9006, f1: 0.9196, edges-ner-ontonotes_loss: 0.0270
09/16 06:36:53 AM: Update 13320: task edges-ner-ontonotes, batch 320 (13320): mcc: 0.9373, acc: 0.9059, precision: 0.9537, recall: 0.9280, f1: 0.9406, edges-ner-ontonotes_loss: 0.0201
09/16 06:36:54 AM: Update 11467: task edges-ner-ontonotes, batch 467 (11467): mcc: 0.9166, acc: 0.8790, precision: 0.9405, recall: 0.9022, f1: 0.9209, edges-ner-ontonotes_loss: 0.0268
09/16 06:37:04 AM: Update 13388: task edges-ner-ontonotes, batch 388 (13388): mcc: 0.9386, acc: 0.9076, precision: 0.9546, recall: 0.9295, f1: 0.9419, edges-ner-ontonotes_loss: 0.0198
09/16 06:37:04 AM: Update 11528: task edges-ner-ontonotes, batch 528 (11528): mcc: 0.9186, acc: 0.8814, precision: 0.9423, recall: 0.9042, f1: 0.9229, edges-ner-ontonotes_loss: 0.0263
09/16 06:37:14 AM: Update 13481: task edges-ner-ontonotes, batch 481 (13481): mcc: 0.9377, acc: 0.9061, precision: 0.9541, recall: 0.9284, f1: 0.9411, edges-ner-ontonotes_loss: 0.0199
09/16 06:37:17 AM: Update 11594: task edges-ner-ontonotes, batch 594 (11594): mcc: 0.9217, acc: 0.8849, precision: 0.9443, recall: 0.9080, f1: 0.9258, edges-ner-ontonotes_loss: 0.0254
09/16 06:37:24 AM: Update 13564: task edges-ner-ontonotes, batch 564 (13564): mcc: 0.9378, acc: 0.9059, precision: 0.9539, recall: 0.9286, f1: 0.9411, edges-ner-ontonotes_loss: 0.0198
09/16 06:37:28 AM: Update 11662: task edges-ner-ontonotes, batch 662 (11662): mcc: 0.9238, acc: 0.8875, precision: 0.9456, recall: 0.9106, f1: 0.9277, edges-ner-ontonotes_loss: 0.0249
09/16 06:37:34 AM: Update 13638: task edges-ner-ontonotes, batch 638 (13638): mcc: 0.9383, acc: 0.9066, precision: 0.9543, recall: 0.9292, f1: 0.9416, edges-ner-ontonotes_loss: 0.0197
09/16 06:37:38 AM: Update 11731: task edges-ner-ontonotes, batch 731 (11731): mcc: 0.9253, acc: 0.8895, precision: 0.9465, recall: 0.9125, f1: 0.9292, edges-ner-ontonotes_loss: 0.0243
09/16 06:37:44 AM: Update 13704: task edges-ner-ontonotes, batch 704 (13704): mcc: 0.9379, acc: 0.9060, precision: 0.9542, recall: 0.9285, f1: 0.9412, edges-ner-ontonotes_loss: 0.0198
09/16 06:37:49 AM: Update 11802: task edges-ner-ontonotes, batch 802 (11802): mcc: 0.9272, acc: 0.8921, precision: 0.9477, recall: 0.9149, f1: 0.9310, edges-ner-ontonotes_loss: 0.0237
09/16 06:37:54 AM: Update 13794: task edges-ner-ontonotes, batch 794 (13794): mcc: 0.9339, acc: 0.9008, precision: 0.9517, recall: 0.9235, f1: 0.9374, edges-ner-ontonotes_loss: 0.0217
09/16 06:37:59 AM: Update 11843: task edges-ner-ontonotes, batch 843 (11843): mcc: 0.9279, acc: 0.8930, precision: 0.9482, recall: 0.9157, f1: 0.9317, edges-ner-ontonotes_loss: 0.0235
09/16 06:38:05 AM: Update 13885: task edges-ner-ontonotes, batch 885 (13885): mcc: 0.9309, acc: 0.8970, precision: 0.9499, recall: 0.9197, f1: 0.9346, edges-ner-ontonotes_loss: 0.0228
09/16 06:38:09 AM: Update 11911: task edges-ner-ontonotes, batch 911 (11911): mcc: 0.9288, acc: 0.8940, precision: 0.9488, recall: 0.9169, f1: 0.9326, edges-ner-ontonotes_loss: 0.0232
09/16 06:38:15 AM: Update 13960: task edges-ner-ontonotes, batch 960 (13960): mcc: 0.9286, acc: 0.8940, precision: 0.9484, recall: 0.9169, f1: 0.9324, edges-ner-ontonotes_loss: 0.0238
09/16 06:38:19 AM: Update 11981: task edges-ner-ontonotes, batch 981 (11981): mcc: 0.9295, acc: 0.8950, precision: 0.9492, recall: 0.9177, f1: 0.9332, edges-ner-ontonotes_loss: 0.0230
09/16 06:38:20 AM: ***** Step 14000 / Validation 14 *****
09/16 06:38:20 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:38:20 AM: Validating...
09/16 06:38:22 AM: ***** Step 12000 / Validation 12 *****
09/16 06:38:22 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:38:22 AM: Validating...
09/16 06:38:25 AM: Evaluate: task edges-ner-ontonotes, batch 33 (157): mcc: 0.8978, acc: 0.8637, precision: 0.9187, recall: 0.8883, f1: 0.9032, edges-ner-ontonotes_loss: 0.0327
09/16 06:38:29 AM: Evaluate: task edges-ner-ontonotes, batch 37 (157): mcc: 0.8974, acc: 0.8634, precision: 0.9216, recall: 0.8847, f1: 0.9028, edges-ner-ontonotes_loss: 0.0336
09/16 06:38:35 AM: Evaluate: task edges-ner-ontonotes, batch 79 (157): mcc: 0.9209, acc: 0.8892, precision: 0.9435, recall: 0.9073, f1: 0.9250, edges-ner-ontonotes_loss: 0.0270
09/16 06:38:39 AM: Evaluate: task edges-ner-ontonotes, batch 80 (157): mcc: 0.9211, acc: 0.8888, precision: 0.9440, recall: 0.9071, f1: 0.9252, edges-ner-ontonotes_loss: 0.0276
09/16 06:38:45 AM: Evaluate: task edges-ner-ontonotes, batch 116 (157): mcc: 0.9274, acc: 0.8968, precision: 0.9481, recall: 0.9149, f1: 0.9312, edges-ner-ontonotes_loss: 0.0245
09/16 06:38:49 AM: Evaluate: task edges-ner-ontonotes, batch 119 (157): mcc: 0.9290, acc: 0.8999, precision: 0.9491, recall: 0.9169, f1: 0.9327, edges-ner-ontonotes_loss: 0.0245
09/16 06:38:54 AM: Updating LR scheduler:
09/16 06:38:54 AM: 	Best result seen so far for macro_avg: 0.941
09/16 06:38:54 AM: 	# validation passes without improvement: 1
09/16 06:38:54 AM: edges-ner-ontonotes_loss: training: 0.024205 validation: 0.021962
09/16 06:38:54 AM: macro_avg: validation: 0.937873
09/16 06:38:54 AM: micro_avg: validation: 0.000000
09/16 06:38:54 AM: edges-ner-ontonotes_mcc: training: 0.927693 validation: 0.934412
09/16 06:38:54 AM: edges-ner-ontonotes_acc: training: 0.892785 validation: 0.906354
09/16 06:38:54 AM: edges-ner-ontonotes_precision: training: 0.947883 validation: 0.953033
09/16 06:38:54 AM: edges-ner-ontonotes_recall: training: 0.915662 validation: 0.923188
09/16 06:38:54 AM: edges-ner-ontonotes_f1: training: 0.931494 validation: 0.937873
09/16 06:38:54 AM: Global learning rate: 0.0001
09/16 06:38:54 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:38:56 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:38:56 AM: Best result seen so far for macro.
09/16 06:38:56 AM: Updating LR scheduler:
09/16 06:38:56 AM: 	Best result seen so far for macro_avg: 0.940
09/16 06:38:56 AM: 	# validation passes without improvement: 0
09/16 06:38:56 AM: edges-ner-ontonotes_loss: training: 0.022950 validation: 0.021802
09/16 06:38:56 AM: macro_avg: validation: 0.940290
09/16 06:38:56 AM: micro_avg: validation: 0.000000
09/16 06:38:56 AM: edges-ner-ontonotes_mcc: training: 0.929598 validation: 0.936934
09/16 06:38:56 AM: edges-ner-ontonotes_acc: training: 0.895095 validation: 0.910297
09/16 06:38:56 AM: edges-ner-ontonotes_precision: training: 0.949220 validation: 0.953748
09/16 06:38:56 AM: edges-ner-ontonotes_recall: training: 0.917915 validation: 0.927207
09/16 06:38:56 AM: edges-ner-ontonotes_f1: training: 0.933305 validation: 0.940290
09/16 06:38:56 AM: Global learning rate: 0.0001
09/16 06:38:56 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:38:57 AM: Update 14005: task edges-ner-ontonotes, batch 5 (14005): mcc: 0.9008, acc: 0.8576, precision: 0.9371, recall: 0.8762, f1: 0.9056, edges-ner-ontonotes_loss: 0.0323
09/16 06:38:59 AM: Update 12021: task edges-ner-ontonotes, batch 21 (12021): mcc: 0.9329, acc: 0.8970, precision: 0.9529, recall: 0.9205, f1: 0.9365, edges-ner-ontonotes_loss: 0.0206
09/16 06:39:07 AM: Update 14089: task edges-ner-ontonotes, batch 89 (14089): mcc: 0.9103, acc: 0.8691, precision: 0.9362, recall: 0.8946, f1: 0.9149, edges-ner-ontonotes_loss: 0.0299
09/16 06:39:09 AM: Update 12095: task edges-ner-ontonotes, batch 95 (12095): mcc: 0.9403, acc: 0.9098, precision: 0.9557, recall: 0.9316, f1: 0.9435, edges-ner-ontonotes_loss: 0.0191
09/16 06:39:17 AM: Update 14182: task edges-ner-ontonotes, batch 182 (14182): mcc: 0.9133, acc: 0.8739, precision: 0.9393, recall: 0.8971, f1: 0.9177, edges-ner-ontonotes_loss: 0.0289
09/16 06:39:19 AM: Update 12156: task edges-ner-ontonotes, batch 156 (12156): mcc: 0.9359, acc: 0.9032, precision: 0.9536, recall: 0.9254, f1: 0.9393, edges-ner-ontonotes_loss: 0.0211
09/16 06:39:28 AM: Update 14275: task edges-ner-ontonotes, batch 275 (14275): mcc: 0.9130, acc: 0.8736, precision: 0.9387, recall: 0.8972, f1: 0.9175, edges-ner-ontonotes_loss: 0.0286
09/16 06:39:29 AM: Update 12230: task edges-ner-ontonotes, batch 230 (12230): mcc: 0.9256, acc: 0.8899, precision: 0.9474, recall: 0.9122, f1: 0.9295, edges-ner-ontonotes_loss: 0.0257
09/16 06:39:38 AM: Update 14341: task edges-ner-ontonotes, batch 341 (14341): mcc: 0.9109, acc: 0.8717, precision: 0.9363, recall: 0.8957, f1: 0.9155, edges-ner-ontonotes_loss: 0.0290
09/16 06:39:39 AM: Update 12304: task edges-ner-ontonotes, batch 304 (12304): mcc: 0.9198, acc: 0.8826, precision: 0.9435, recall: 0.9052, f1: 0.9239, edges-ner-ontonotes_loss: 0.0280
09/16 06:39:48 AM: Update 14430: task edges-ner-ontonotes, batch 430 (14430): mcc: 0.9138, acc: 0.8756, precision: 0.9384, recall: 0.8989, f1: 0.9182, edges-ner-ontonotes_loss: 0.0282
09/16 06:39:51 AM: Update 12378: task edges-ner-ontonotes, batch 378 (12378): mcc: 0.9169, acc: 0.8790, precision: 0.9419, recall: 0.9014, f1: 0.9212, edges-ner-ontonotes_loss: 0.0294
09/16 06:39:58 AM: Update 14510: task edges-ner-ontonotes, batch 510 (14510): mcc: 0.9156, acc: 0.8783, precision: 0.9395, recall: 0.9013, f1: 0.9200, edges-ner-ontonotes_loss: 0.0274
09/16 06:40:01 AM: Update 12448: task edges-ner-ontonotes, batch 448 (12448): mcc: 0.9141, acc: 0.8758, precision: 0.9394, recall: 0.8985, f1: 0.9185, edges-ner-ontonotes_loss: 0.0300
09/16 06:40:08 AM: Update 14604: task edges-ner-ontonotes, batch 604 (14604): mcc: 0.9188, acc: 0.8826, precision: 0.9418, recall: 0.9050, f1: 0.9230, edges-ner-ontonotes_loss: 0.0265
09/16 06:40:11 AM: Update 12504: task edges-ner-ontonotes, batch 504 (12504): mcc: 0.9128, acc: 0.8741, precision: 0.9384, recall: 0.8971, f1: 0.9173, edges-ner-ontonotes_loss: 0.0301
09/16 06:40:18 AM: Update 14668: task edges-ner-ontonotes, batch 668 (14668): mcc: 0.9203, acc: 0.8845, precision: 0.9430, recall: 0.9066, f1: 0.9245, edges-ner-ontonotes_loss: 0.0260
09/16 06:40:21 AM: Update 12587: task edges-ner-ontonotes, batch 587 (12587): mcc: 0.9124, acc: 0.8733, precision: 0.9381, recall: 0.8966, f1: 0.9169, edges-ner-ontonotes_loss: 0.0299
09/16 06:40:28 AM: Update 14749: task edges-ner-ontonotes, batch 749 (14749): mcc: 0.9229, acc: 0.8880, precision: 0.9448, recall: 0.9098, f1: 0.9270, edges-ner-ontonotes_loss: 0.0253
09/16 06:40:31 AM: Update 12662: task edges-ner-ontonotes, batch 662 (12662): mcc: 0.9123, acc: 0.8730, precision: 0.9383, recall: 0.8962, f1: 0.9168, edges-ner-ontonotes_loss: 0.0298
09/16 06:40:39 AM: Update 14834: task edges-ner-ontonotes, batch 834 (14834): mcc: 0.9255, acc: 0.8914, precision: 0.9465, recall: 0.9129, f1: 0.9294, edges-ner-ontonotes_loss: 0.0245
09/16 06:40:41 AM: Update 12738: task edges-ner-ontonotes, batch 738 (12738): mcc: 0.9117, acc: 0.8726, precision: 0.9377, recall: 0.8957, f1: 0.9162, edges-ner-ontonotes_loss: 0.0300
09/16 06:40:49 AM: Update 14923: task edges-ner-ontonotes, batch 923 (14923): mcc: 0.9277, acc: 0.8941, precision: 0.9480, recall: 0.9155, f1: 0.9315, edges-ner-ontonotes_loss: 0.0238
09/16 06:40:51 AM: Update 12788: task edges-ner-ontonotes, batch 788 (12788): mcc: 0.9122, acc: 0.8730, precision: 0.9380, recall: 0.8963, f1: 0.9167, edges-ner-ontonotes_loss: 0.0297
09/16 06:40:59 AM: Update 14995: task edges-ner-ontonotes, batch 995 (14995): mcc: 0.9282, acc: 0.8947, precision: 0.9482, recall: 0.9163, f1: 0.9320, edges-ner-ontonotes_loss: 0.0236
09/16 06:41:00 AM: ***** Step 15000 / Validation 15 *****
09/16 06:41:00 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:41:00 AM: Validating...
09/16 06:41:01 AM: Update 12860: task edges-ner-ontonotes, batch 860 (12860): mcc: 0.9131, acc: 0.8741, precision: 0.9388, recall: 0.8974, f1: 0.9176, edges-ner-ontonotes_loss: 0.0293
09/16 06:41:09 AM: Evaluate: task edges-ner-ontonotes, batch 55 (157): mcc: 0.9147, acc: 0.8839, precision: 0.9353, recall: 0.9036, f1: 0.9192, edges-ner-ontonotes_loss: 0.0292
09/16 06:41:11 AM: Update 12910: task edges-ner-ontonotes, batch 910 (12910): mcc: 0.9136, acc: 0.8750, precision: 0.9389, recall: 0.8981, f1: 0.9181, edges-ner-ontonotes_loss: 0.0290
09/16 06:41:19 AM: Evaluate: task edges-ner-ontonotes, batch 112 (157): mcc: 0.9286, acc: 0.9003, precision: 0.9484, recall: 0.9169, f1: 0.9324, edges-ner-ontonotes_loss: 0.0248
09/16 06:41:21 AM: Update 12961: task edges-ner-ontonotes, batch 961 (12961): mcc: 0.9146, acc: 0.8763, precision: 0.9397, recall: 0.8992, f1: 0.9190, edges-ner-ontonotes_loss: 0.0287
09/16 06:41:27 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:41:27 AM: Best result seen so far for macro.
09/16 06:41:27 AM: Updating LR scheduler:
09/16 06:41:27 AM: 	Best result seen so far for macro_avg: 0.942
09/16 06:41:27 AM: 	# validation passes without improvement: 0
09/16 06:41:27 AM: edges-ner-ontonotes_loss: training: 0.023522 validation: 0.021381
09/16 06:41:27 AM: macro_avg: validation: 0.941791
09/16 06:41:27 AM: micro_avg: validation: 0.000000
09/16 06:41:27 AM: edges-ner-ontonotes_mcc: training: 0.928279 validation: 0.938510
09/16 06:41:27 AM: edges-ner-ontonotes_acc: training: 0.894768 validation: 0.912572
09/16 06:41:27 AM: edges-ner-ontonotes_precision: training: 0.948250 validation: 0.954591
09/16 06:41:27 AM: edges-ner-ontonotes_recall: training: 0.916398 validation: 0.929330
09/16 06:41:27 AM: edges-ner-ontonotes_f1: training: 0.932052 validation: 0.941791
09/16 06:41:27 AM: Global learning rate: 0.0001
09/16 06:41:27 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:41:29 AM: Update 15014: task edges-ner-ontonotes, batch 14 (15014): mcc: 0.9420, acc: 0.9141, precision: 0.9578, recall: 0.9327, f1: 0.9451, edges-ner-ontonotes_loss: 0.0190
09/16 06:41:30 AM: ***** Step 13000 / Validation 13 *****
09/16 06:41:30 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:41:30 AM: Validating...
09/16 06:41:33 AM: Evaluate: task edges-ner-ontonotes, batch 21 (157): mcc: 0.8921, acc: 0.8509, precision: 0.9225, recall: 0.8740, f1: 0.8976, edges-ner-ontonotes_loss: 0.0302
09/16 06:41:39 AM: Update 15077: task edges-ner-ontonotes, batch 77 (15077): mcc: 0.9393, acc: 0.9086, precision: 0.9527, recall: 0.9326, f1: 0.9426, edges-ner-ontonotes_loss: 0.0201
09/16 06:41:43 AM: Evaluate: task edges-ner-ontonotes, batch 77 (157): mcc: 0.9240, acc: 0.8920, precision: 0.9471, recall: 0.9095, f1: 0.9279, edges-ner-ontonotes_loss: 0.0260
09/16 06:41:49 AM: Update 15150: task edges-ner-ontonotes, batch 150 (15150): mcc: 0.9394, acc: 0.9073, precision: 0.9546, recall: 0.9311, f1: 0.9427, edges-ner-ontonotes_loss: 0.0194
09/16 06:41:55 AM: Evaluate: task edges-ner-ontonotes, batch 129 (157): mcc: 0.9331, acc: 0.9039, precision: 0.9532, recall: 0.9207, f1: 0.9366, edges-ner-ontonotes_loss: 0.0227
09/16 06:42:00 AM: Update 15206: task edges-ner-ontonotes, batch 206 (15206): mcc: 0.9402, acc: 0.9085, precision: 0.9554, recall: 0.9316, f1: 0.9434, edges-ner-ontonotes_loss: 0.0192
09/16 06:42:00 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:42:00 AM: Best result seen so far for macro.
09/16 06:42:01 AM: Updating LR scheduler:
09/16 06:42:01 AM: 	Best result seen so far for macro_avg: 0.941
09/16 06:42:01 AM: 	# validation passes without improvement: 0
09/16 06:42:01 AM: edges-ner-ontonotes_loss: training: 0.028500 validation: 0.021157
09/16 06:42:01 AM: macro_avg: validation: 0.940597
09/16 06:42:01 AM: micro_avg: validation: 0.000000
09/16 06:42:01 AM: edges-ner-ontonotes_mcc: training: 0.915168 validation: 0.937272
09/16 06:42:01 AM: edges-ner-ontonotes_acc: training: 0.877101 validation: 0.909539
09/16 06:42:01 AM: edges-ner-ontonotes_precision: training: 0.940025 validation: 0.954702
09/16 06:42:01 AM: edges-ner-ontonotes_recall: training: 0.899945 validation: 0.926903
09/16 06:42:01 AM: edges-ner-ontonotes_f1: training: 0.919548 validation: 0.940597
09/16 06:42:01 AM: Global learning rate: 0.0001
09/16 06:42:01 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:42:05 AM: Update 13032: task edges-ner-ontonotes, batch 32 (13032): mcc: 0.9295, acc: 0.8938, precision: 0.9496, recall: 0.9173, f1: 0.9332, edges-ner-ontonotes_loss: 0.0242
09/16 06:42:10 AM: Update 15273: task edges-ner-ontonotes, batch 273 (15273): mcc: 0.9372, acc: 0.9044, precision: 0.9539, recall: 0.9275, f1: 0.9405, edges-ner-ontonotes_loss: 0.0201
09/16 06:42:18 AM: Update 13085: task edges-ner-ontonotes, batch 85 (13085): mcc: 0.9263, acc: 0.8909, precision: 0.9480, recall: 0.9130, f1: 0.9302, edges-ner-ontonotes_loss: 0.0241
09/16 06:42:20 AM: Update 15366: task edges-ner-ontonotes, batch 366 (15366): mcc: 0.9293, acc: 0.8944, precision: 0.9487, recall: 0.9179, f1: 0.9331, edges-ner-ontonotes_loss: 0.0239
09/16 06:42:28 AM: Update 13159: task edges-ner-ontonotes, batch 159 (13159): mcc: 0.9330, acc: 0.9005, precision: 0.9509, recall: 0.9226, f1: 0.9366, edges-ner-ontonotes_loss: 0.0217
09/16 06:42:30 AM: Update 15444: task edges-ner-ontonotes, batch 444 (15444): mcc: 0.9254, acc: 0.8895, precision: 0.9462, recall: 0.9130, f1: 0.9293, edges-ner-ontonotes_loss: 0.0254
09/16 06:42:38 AM: Update 13229: task edges-ner-ontonotes, batch 229 (13229): mcc: 0.9356, acc: 0.9038, precision: 0.9530, recall: 0.9255, f1: 0.9390, edges-ner-ontonotes_loss: 0.0209
09/16 06:42:41 AM: Update 15527: task edges-ner-ontonotes, batch 527 (15527): mcc: 0.9217, acc: 0.8848, precision: 0.9437, recall: 0.9086, f1: 0.9258, edges-ner-ontonotes_loss: 0.0272
09/16 06:42:48 AM: Update 13306: task edges-ner-ontonotes, batch 306 (13306): mcc: 0.9372, acc: 0.9059, precision: 0.9536, recall: 0.9279, f1: 0.9406, edges-ner-ontonotes_loss: 0.0202
09/16 06:42:52 AM: Update 15601: task edges-ner-ontonotes, batch 601 (15601): mcc: 0.9199, acc: 0.8827, precision: 0.9422, recall: 0.9067, f1: 0.9241, edges-ner-ontonotes_loss: 0.0279
09/16 06:42:58 AM: Update 13380: task edges-ner-ontonotes, batch 380 (13380): mcc: 0.9387, acc: 0.9076, precision: 0.9546, recall: 0.9296, f1: 0.9419, edges-ner-ontonotes_loss: 0.0198
09/16 06:43:02 AM: Update 15702: task edges-ner-ontonotes, batch 702 (15702): mcc: 0.9189, acc: 0.8812, precision: 0.9416, recall: 0.9053, f1: 0.9231, edges-ner-ontonotes_loss: 0.0280
09/16 06:43:08 AM: Update 13437: task edges-ner-ontonotes, batch 437 (13437): mcc: 0.9378, acc: 0.9063, precision: 0.9539, recall: 0.9286, f1: 0.9411, edges-ner-ontonotes_loss: 0.0199
09/16 06:43:12 AM: Update 15794: task edges-ner-ontonotes, batch 794 (15794): mcc: 0.9179, acc: 0.8799, precision: 0.9412, recall: 0.9040, f1: 0.9222, edges-ner-ontonotes_loss: 0.0280
09/16 06:43:18 AM: Update 13509: task edges-ner-ontonotes, batch 509 (13509): mcc: 0.9373, acc: 0.9054, precision: 0.9538, recall: 0.9279, f1: 0.9407, edges-ner-ontonotes_loss: 0.0199
09/16 06:43:23 AM: Update 15874: task edges-ner-ontonotes, batch 874 (15874): mcc: 0.9173, acc: 0.8791, precision: 0.9406, recall: 0.9033, f1: 0.9216, edges-ner-ontonotes_loss: 0.0280
09/16 06:43:28 AM: Update 13586: task edges-ner-ontonotes, batch 586 (13586): mcc: 0.9380, acc: 0.9064, precision: 0.9540, recall: 0.9290, f1: 0.9413, edges-ner-ontonotes_loss: 0.0197
09/16 06:43:33 AM: Update 15956: task edges-ner-ontonotes, batch 956 (15956): mcc: 0.9178, acc: 0.8797, precision: 0.9409, recall: 0.9041, f1: 0.9221, edges-ner-ontonotes_loss: 0.0277
09/16 06:43:38 AM: Update 13654: task edges-ner-ontonotes, batch 654 (13654): mcc: 0.9382, acc: 0.9066, precision: 0.9543, recall: 0.9292, f1: 0.9415, edges-ner-ontonotes_loss: 0.0197
09/16 06:43:39 AM: ***** Step 16000 / Validation 16 *****
09/16 06:43:39 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:43:39 AM: Validating...
09/16 06:43:43 AM: Evaluate: task edges-ner-ontonotes, batch 29 (157): mcc: 0.8920, acc: 0.8547, precision: 0.9178, recall: 0.8784, f1: 0.8976, edges-ner-ontonotes_loss: 0.0340
09/16 06:43:50 AM: Update 13701: task edges-ner-ontonotes, batch 701 (13701): mcc: 0.9383, acc: 0.9066, precision: 0.9545, recall: 0.9290, f1: 0.9416, edges-ner-ontonotes_loss: 0.0197
09/16 06:43:53 AM: Evaluate: task edges-ner-ontonotes, batch 94 (157): mcc: 0.9308, acc: 0.9012, precision: 0.9522, recall: 0.9173, f1: 0.9344, edges-ner-ontonotes_loss: 0.0243
09/16 06:44:00 AM: Update 13750: task edges-ner-ontonotes, batch 750 (13750): mcc: 0.9357, acc: 0.9031, precision: 0.9528, recall: 0.9258, f1: 0.9391, edges-ner-ontonotes_loss: 0.0209
09/16 06:44:03 AM: Evaluate: task edges-ner-ontonotes, batch 147 (157): mcc: 0.9375, acc: 0.9101, precision: 0.9554, recall: 0.9266, f1: 0.9408, edges-ner-ontonotes_loss: 0.0214
09/16 06:44:05 AM: Updating LR scheduler:
09/16 06:44:05 AM: 	Best result seen so far for macro_avg: 0.942
09/16 06:44:05 AM: 	# validation passes without improvement: 1
09/16 06:44:05 AM: edges-ner-ontonotes_loss: training: 0.027447 validation: 0.020973
09/16 06:44:05 AM: macro_avg: validation: 0.941502
09/16 06:44:05 AM: micro_avg: validation: 0.000000
09/16 06:44:05 AM: edges-ner-ontonotes_mcc: training: 0.918395 validation: 0.938223
09/16 06:44:05 AM: edges-ner-ontonotes_acc: training: 0.880422 validation: 0.911056
09/16 06:44:05 AM: edges-ner-ontonotes_precision: training: 0.941315 validation: 0.955280
09/16 06:44:05 AM: edges-ner-ontonotes_recall: training: 0.904707 validation: 0.928116
09/16 06:44:05 AM: edges-ner-ontonotes_f1: training: 0.922648 validation: 0.941502
09/16 06:44:05 AM: Global learning rate: 0.0001
09/16 06:44:05 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:44:10 AM: Update 13811: task edges-ner-ontonotes, batch 811 (13811): mcc: 0.9333, acc: 0.9002, precision: 0.9514, recall: 0.9228, f1: 0.9369, edges-ner-ontonotes_loss: 0.0219
09/16 06:44:13 AM: Update 16065: task edges-ner-ontonotes, batch 65 (16065): mcc: 0.9245, acc: 0.8915, precision: 0.9438, recall: 0.9137, f1: 0.9285, edges-ner-ontonotes_loss: 0.0237
09/16 06:44:20 AM: Update 13877: task edges-ner-ontonotes, batch 877 (13877): mcc: 0.9311, acc: 0.8973, precision: 0.9500, recall: 0.9200, f1: 0.9348, edges-ner-ontonotes_loss: 0.0227
09/16 06:44:24 AM: Update 16160: task edges-ner-ontonotes, batch 160 (16160): mcc: 0.9227, acc: 0.8893, precision: 0.9425, recall: 0.9115, f1: 0.9267, edges-ner-ontonotes_loss: 0.0247
09/16 06:44:34 AM: Update 13949: task edges-ner-ontonotes, batch 949 (13949): mcc: 0.9288, acc: 0.8943, precision: 0.9485, recall: 0.9172, f1: 0.9326, edges-ner-ontonotes_loss: 0.0237
09/16 06:44:34 AM: Update 16223: task edges-ner-ontonotes, batch 223 (16223): mcc: 0.9269, acc: 0.8938, precision: 0.9455, recall: 0.9165, f1: 0.9308, edges-ner-ontonotes_loss: 0.0233
09/16 06:44:41 AM: ***** Step 14000 / Validation 14 *****
09/16 06:44:41 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:44:41 AM: Validating...
09/16 06:44:44 AM: Update 16301: task edges-ner-ontonotes, batch 301 (16301): mcc: 0.9294, acc: 0.8963, precision: 0.9474, recall: 0.9193, f1: 0.9331, edges-ner-ontonotes_loss: 0.0224
09/16 06:44:44 AM: Evaluate: task edges-ner-ontonotes, batch 21 (157): mcc: 0.8858, acc: 0.8447, precision: 0.9073, recall: 0.8771, f1: 0.8919, edges-ner-ontonotes_loss: 0.0306
09/16 06:44:54 AM: Update 16364: task edges-ner-ontonotes, batch 364 (16364): mcc: 0.9315, acc: 0.8987, precision: 0.9491, recall: 0.9215, f1: 0.9351, edges-ner-ontonotes_loss: 0.0217
09/16 06:44:54 AM: Evaluate: task edges-ner-ontonotes, batch 77 (157): mcc: 0.9199, acc: 0.8879, precision: 0.9423, recall: 0.9064, f1: 0.9240, edges-ner-ontonotes_loss: 0.0273
09/16 06:45:04 AM: Update 16419: task edges-ner-ontonotes, batch 419 (16419): mcc: 0.9337, acc: 0.9015, precision: 0.9508, recall: 0.9240, f1: 0.9372, edges-ner-ontonotes_loss: 0.0210
09/16 06:45:04 AM: Evaluate: task edges-ner-ontonotes, batch 126 (157): mcc: 0.9294, acc: 0.8995, precision: 0.9502, recall: 0.9166, f1: 0.9331, edges-ner-ontonotes_loss: 0.0238
09/16 06:45:10 AM: Updating LR scheduler:
09/16 06:45:10 AM: 	Best result seen so far for macro_avg: 0.941
09/16 06:45:10 AM: 	# validation passes without improvement: 1
09/16 06:45:10 AM: edges-ner-ontonotes_loss: training: 0.024205 validation: 0.021962
09/16 06:45:10 AM: macro_avg: validation: 0.937873
09/16 06:45:10 AM: micro_avg: validation: 0.000000
09/16 06:45:10 AM: edges-ner-ontonotes_mcc: training: 0.927693 validation: 0.934412
09/16 06:45:10 AM: edges-ner-ontonotes_acc: training: 0.892785 validation: 0.906354
09/16 06:45:10 AM: edges-ner-ontonotes_precision: training: 0.947883 validation: 0.953033
09/16 06:45:10 AM: edges-ner-ontonotes_recall: training: 0.915662 validation: 0.923188
09/16 06:45:10 AM: edges-ner-ontonotes_f1: training: 0.931494 validation: 0.937873
09/16 06:45:10 AM: Global learning rate: 0.0001
09/16 06:45:10 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:45:14 AM: Update 16494: task edges-ner-ontonotes, batch 494 (16494): mcc: 0.9352, acc: 0.9031, precision: 0.9520, recall: 0.9256, f1: 0.9386, edges-ner-ontonotes_loss: 0.0207
09/16 06:45:14 AM: Update 14009: task edges-ner-ontonotes, batch 9 (14009): mcc: 0.9025, acc: 0.8576, precision: 0.9328, recall: 0.8833, f1: 0.9074, edges-ner-ontonotes_loss: 0.0307
09/16 06:45:24 AM: Update 16557: task edges-ner-ontonotes, batch 557 (16557): mcc: 0.9354, acc: 0.9035, precision: 0.9522, recall: 0.9259, f1: 0.9389, edges-ner-ontonotes_loss: 0.0206
09/16 06:45:24 AM: Update 14098: task edges-ner-ontonotes, batch 98 (14098): mcc: 0.9118, acc: 0.8709, precision: 0.9376, recall: 0.8959, f1: 0.9163, edges-ner-ontonotes_loss: 0.0296
09/16 06:45:34 AM: Update 14175: task edges-ner-ontonotes, batch 175 (14175): mcc: 0.9134, acc: 0.8739, precision: 0.9395, recall: 0.8972, f1: 0.9179, edges-ner-ontonotes_loss: 0.0290
09/16 06:45:34 AM: Update 16641: task edges-ner-ontonotes, batch 641 (16641): mcc: 0.9367, acc: 0.9049, precision: 0.9531, recall: 0.9273, f1: 0.9400, edges-ner-ontonotes_loss: 0.0202
09/16 06:45:44 AM: Update 16725: task edges-ner-ontonotes, batch 725 (16725): mcc: 0.9368, acc: 0.9050, precision: 0.9531, recall: 0.9276, f1: 0.9402, edges-ner-ontonotes_loss: 0.0202
09/16 06:45:44 AM: Update 14246: task edges-ner-ontonotes, batch 246 (14246): mcc: 0.9132, acc: 0.8739, precision: 0.9386, recall: 0.8977, f1: 0.9177, edges-ner-ontonotes_loss: 0.0286
09/16 06:45:56 AM: Update 16813: task edges-ner-ontonotes, batch 813 (16813): mcc: 0.9372, acc: 0.9054, precision: 0.9537, recall: 0.9278, f1: 0.9406, edges-ner-ontonotes_loss: 0.0201
09/16 06:45:57 AM: Update 14318: task edges-ner-ontonotes, batch 318 (14318): mcc: 0.9115, acc: 0.8717, precision: 0.9369, recall: 0.8961, f1: 0.9161, edges-ner-ontonotes_loss: 0.0289
09/16 06:46:06 AM: Update 16889: task edges-ner-ontonotes, batch 889 (16889): mcc: 0.9343, acc: 0.9015, precision: 0.9519, recall: 0.9241, f1: 0.9378, edges-ner-ontonotes_loss: 0.0212
09/16 06:46:07 AM: Update 14382: task edges-ner-ontonotes, batch 382 (14382): mcc: 0.9124, acc: 0.8736, precision: 0.9373, recall: 0.8973, f1: 0.9169, edges-ner-ontonotes_loss: 0.0286
09/16 06:46:16 AM: Update 16965: task edges-ner-ontonotes, batch 965 (16965): mcc: 0.9319, acc: 0.8983, precision: 0.9504, recall: 0.9211, f1: 0.9355, edges-ner-ontonotes_loss: 0.0224
09/16 06:46:17 AM: Update 14455: task edges-ner-ontonotes, batch 455 (14455): mcc: 0.9145, acc: 0.8768, precision: 0.9390, recall: 0.8998, f1: 0.9190, edges-ner-ontonotes_loss: 0.0278
09/16 06:46:20 AM: ***** Step 17000 / Validation 17 *****
09/16 06:46:21 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:46:21 AM: Validating...
09/16 06:46:26 AM: Evaluate: task edges-ner-ontonotes, batch 35 (157): mcc: 0.9009, acc: 0.8682, precision: 0.9236, recall: 0.8894, f1: 0.9062, edges-ner-ontonotes_loss: 0.0327
09/16 06:46:27 AM: Update 14530: task edges-ner-ontonotes, batch 530 (14530): mcc: 0.9161, acc: 0.8790, precision: 0.9397, recall: 0.9020, f1: 0.9205, edges-ner-ontonotes_loss: 0.0272
09/16 06:46:38 AM: Update 14583: task edges-ner-ontonotes, batch 583 (14583): mcc: 0.9179, acc: 0.8814, precision: 0.9410, recall: 0.9041, f1: 0.9221, edges-ner-ontonotes_loss: 0.0267
09/16 06:46:38 AM: Evaluate: task edges-ner-ontonotes, batch 94 (157): mcc: 0.9248, acc: 0.8930, precision: 0.9486, recall: 0.9095, f1: 0.9286, edges-ner-ontonotes_loss: 0.0261
09/16 06:46:48 AM: Evaluate: task edges-ner-ontonotes, batch 147 (157): mcc: 0.9331, acc: 0.9045, precision: 0.9534, recall: 0.9203, f1: 0.9366, edges-ner-ontonotes_loss: 0.0228
09/16 06:46:49 AM: Updating LR scheduler:
09/16 06:46:50 AM: Update 14631: task edges-ner-ontonotes, batch 631 (14631): mcc: 0.9192, acc: 0.8832, precision: 0.9422, recall: 0.9054, f1: 0.9234, edges-ner-ontonotes_loss: 0.0264
09/16 06:46:50 AM: 	Best result seen so far for macro_avg: 0.942
09/16 06:46:50 AM: 	# validation passes without improvement: 2
09/16 06:46:50 AM: edges-ner-ontonotes_loss: training: 0.022890 validation: 0.022333
09/16 06:46:50 AM: macro_avg: validation: 0.937358
09/16 06:46:50 AM: micro_avg: validation: 0.000000
09/16 06:46:50 AM: edges-ner-ontonotes_mcc: training: 0.930970 validation: 0.933885
09/16 06:46:50 AM: edges-ner-ontonotes_acc: training: 0.897206 validation: 0.905596
09/16 06:46:50 AM: edges-ner-ontonotes_precision: training: 0.949757 validation: 0.953344
09/16 06:46:50 AM: edges-ner-ontonotes_recall: training: 0.919956 validation: 0.921899
09/16 06:46:50 AM: edges-ner-ontonotes_f1: training: 0.934619 validation: 0.937358
09/16 06:46:50 AM: Global learning rate: 0.0001
09/16 06:46:50 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:46:58 AM: Update 17063: task edges-ner-ontonotes, batch 63 (17063): mcc: 0.9042, acc: 0.8563, precision: 0.9346, recall: 0.8849, f1: 0.9091, edges-ner-ontonotes_loss: 0.0329
09/16 06:47:00 AM: Update 14702: task edges-ner-ontonotes, batch 702 (14702): mcc: 0.9215, acc: 0.8861, precision: 0.9437, recall: 0.9081, f1: 0.9256, edges-ner-ontonotes_loss: 0.0257
09/16 06:47:08 AM: Update 17133: task edges-ner-ontonotes, batch 133 (17133): mcc: 0.9006, acc: 0.8551, precision: 0.9285, recall: 0.8839, f1: 0.9057, edges-ner-ontonotes_loss: 0.0335
09/16 06:47:10 AM: Update 14776: task edges-ner-ontonotes, batch 776 (14776): mcc: 0.9238, acc: 0.8893, precision: 0.9453, recall: 0.9110, f1: 0.9278, edges-ner-ontonotes_loss: 0.0250
09/16 06:47:18 AM: Update 17237: task edges-ner-ontonotes, batch 237 (17237): mcc: 0.9043, acc: 0.8603, precision: 0.9312, recall: 0.8883, f1: 0.9092, edges-ner-ontonotes_loss: 0.0311
09/16 06:47:23 AM: Update 14852: task edges-ner-ontonotes, batch 852 (14852): mcc: 0.9257, acc: 0.8917, precision: 0.9468, recall: 0.9131, f1: 0.9296, edges-ner-ontonotes_loss: 0.0244
09/16 06:47:28 AM: Update 17334: task edges-ner-ontonotes, batch 334 (17334): mcc: 0.9054, acc: 0.8619, precision: 0.9321, recall: 0.8895, f1: 0.9103, edges-ner-ontonotes_loss: 0.0307
09/16 06:47:34 AM: Update 14924: task edges-ner-ontonotes, batch 924 (14924): mcc: 0.9277, acc: 0.8941, precision: 0.9480, recall: 0.9155, f1: 0.9315, edges-ner-ontonotes_loss: 0.0238
09/16 06:47:40 AM: Update 17430: task edges-ner-ontonotes, batch 430 (17430): mcc: 0.9078, acc: 0.8654, precision: 0.9339, recall: 0.8922, f1: 0.9126, edges-ner-ontonotes_loss: 0.0300
09/16 06:47:45 AM: Update 14986: task edges-ner-ontonotes, batch 986 (14986): mcc: 0.9281, acc: 0.8946, precision: 0.9482, recall: 0.9162, f1: 0.9319, edges-ner-ontonotes_loss: 0.0236
09/16 06:47:49 AM: ***** Step 15000 / Validation 15 *****
09/16 06:47:49 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:47:49 AM: Validating...
09/16 06:47:50 AM: Update 17513: task edges-ner-ontonotes, batch 513 (17513): mcc: 0.9116, acc: 0.8703, precision: 0.9365, recall: 0.8967, f1: 0.9162, edges-ner-ontonotes_loss: 0.0291
09/16 06:47:56 AM: Evaluate: task edges-ner-ontonotes, batch 49 (157): mcc: 0.9069, acc: 0.8744, precision: 0.9298, recall: 0.8945, f1: 0.9118, edges-ner-ontonotes_loss: 0.0311
09/16 06:48:01 AM: Update 17579: task edges-ner-ontonotes, batch 579 (17579): mcc: 0.9134, acc: 0.8730, precision: 0.9379, recall: 0.8988, f1: 0.9179, edges-ner-ontonotes_loss: 0.0285
09/16 06:48:08 AM: Evaluate: task edges-ner-ontonotes, batch 104 (157): mcc: 0.9256, acc: 0.8966, precision: 0.9465, recall: 0.9131, f1: 0.9295, edges-ner-ontonotes_loss: 0.0256
09/16 06:48:12 AM: Update 17643: task edges-ner-ontonotes, batch 643 (17643): mcc: 0.9148, acc: 0.8751, precision: 0.9390, recall: 0.9003, f1: 0.9192, edges-ner-ontonotes_loss: 0.0280
09/16 06:48:18 AM: Evaluate: task edges-ner-ontonotes, batch 152 (157): mcc: 0.9380, acc: 0.9120, precision: 0.9547, recall: 0.9283, f1: 0.9413, edges-ner-ontonotes_loss: 0.0217
09/16 06:48:21 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:48:21 AM: Best result seen so far for macro.
09/16 06:48:21 AM: Updating LR scheduler:
09/16 06:48:21 AM: 	Best result seen so far for macro_avg: 0.942
09/16 06:48:21 AM: 	# validation passes without improvement: 0
09/16 06:48:21 AM: edges-ner-ontonotes_loss: training: 0.023522 validation: 0.021381
09/16 06:48:21 AM: macro_avg: validation: 0.941791
09/16 06:48:21 AM: micro_avg: validation: 0.000000
09/16 06:48:21 AM: edges-ner-ontonotes_mcc: training: 0.928279 validation: 0.938510
09/16 06:48:21 AM: edges-ner-ontonotes_acc: training: 0.894768 validation: 0.912572
09/16 06:48:21 AM: edges-ner-ontonotes_precision: training: 0.948250 validation: 0.954591
09/16 06:48:21 AM: edges-ner-ontonotes_recall: training: 0.916398 validation: 0.929330
09/16 06:48:21 AM: edges-ner-ontonotes_f1: training: 0.932052 validation: 0.941791
09/16 06:48:21 AM: Global learning rate: 0.0001
09/16 06:48:21 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:48:23 AM: Update 17726: task edges-ner-ontonotes, batch 726 (17726): mcc: 0.9166, acc: 0.8778, precision: 0.9399, recall: 0.9028, f1: 0.9210, edges-ner-ontonotes_loss: 0.0274
09/16 06:48:30 AM: Update 15073: task edges-ner-ontonotes, batch 73 (15073): mcc: 0.9390, acc: 0.9080, precision: 0.9527, recall: 0.9321, f1: 0.9423, edges-ner-ontonotes_loss: 0.0202
09/16 06:48:35 AM: Update 17795: task edges-ner-ontonotes, batch 795 (17795): mcc: 0.9191, acc: 0.8813, precision: 0.9414, recall: 0.9060, f1: 0.9233, edges-ner-ontonotes_loss: 0.0267
09/16 06:48:40 AM: Update 15143: task edges-ner-ontonotes, batch 143 (15143): mcc: 0.9396, acc: 0.9077, precision: 0.9543, recall: 0.9317, f1: 0.9429, edges-ner-ontonotes_loss: 0.0193
09/16 06:48:46 AM: Update 17881: task edges-ner-ontonotes, batch 881 (17881): mcc: 0.9218, acc: 0.8847, precision: 0.9432, recall: 0.9091, f1: 0.9259, edges-ner-ontonotes_loss: 0.0259
09/16 06:48:53 AM: Update 15210: task edges-ner-ontonotes, batch 210 (15210): mcc: 0.9402, acc: 0.9084, precision: 0.9553, recall: 0.9319, f1: 0.9434, edges-ner-ontonotes_loss: 0.0192
09/16 06:48:56 AM: Update 17964: task edges-ner-ontonotes, batch 964 (17964): mcc: 0.9239, acc: 0.8877, precision: 0.9447, recall: 0.9117, f1: 0.9279, edges-ner-ontonotes_loss: 0.0253
09/16 06:49:01 AM: ***** Step 18000 / Validation 18 *****
09/16 06:49:01 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:49:01 AM: Validating...
09/16 06:49:04 AM: Update 15258: task edges-ner-ontonotes, batch 258 (15258): mcc: 0.9392, acc: 0.9070, precision: 0.9547, recall: 0.9304, f1: 0.9424, edges-ner-ontonotes_loss: 0.0192
09/16 06:49:06 AM: Evaluate: task edges-ner-ontonotes, batch 47 (157): mcc: 0.9078, acc: 0.8741, precision: 0.9312, recall: 0.8949, f1: 0.9126, edges-ner-ontonotes_loss: 0.0312
09/16 06:49:15 AM: Update 15310: task edges-ner-ontonotes, batch 310 (15310): mcc: 0.9335, acc: 0.8998, precision: 0.9518, recall: 0.9227, f1: 0.9370, edges-ner-ontonotes_loss: 0.0218
09/16 06:49:16 AM: Evaluate: task edges-ner-ontonotes, batch 100 (157): mcc: 0.9239, acc: 0.8934, precision: 0.9460, recall: 0.9105, f1: 0.9279, edges-ner-ontonotes_loss: 0.0260
09/16 06:49:25 AM: Update 15362: task edges-ner-ontonotes, batch 362 (15362): mcc: 0.9293, acc: 0.8945, precision: 0.9486, recall: 0.9180, f1: 0.9331, edges-ner-ontonotes_loss: 0.0239
09/16 06:49:26 AM: Evaluate: task edges-ner-ontonotes, batch 154 (157): mcc: 0.9382, acc: 0.9113, precision: 0.9550, recall: 0.9284, f1: 0.9415, edges-ner-ontonotes_loss: 0.0214
09/16 06:49:27 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:49:27 AM: Best result seen so far for macro.
09/16 06:49:27 AM: Updating LR scheduler:
09/16 06:49:27 AM: 	Best result seen so far for macro_avg: 0.942
09/16 06:49:27 AM: 	# validation passes without improvement: 3
09/16 06:49:27 AM: edges-ner-ontonotes_loss: training: 0.024937 validation: 0.021185
09/16 06:49:27 AM: macro_avg: validation: 0.941877
09/16 06:49:27 AM: micro_avg: validation: 0.000000
09/16 06:49:27 AM: edges-ner-ontonotes_mcc: training: 0.924798 validation: 0.938611
09/16 06:49:27 AM: edges-ner-ontonotes_acc: training: 0.888848 validation: 0.911890
09/16 06:49:27 AM: edges-ner-ontonotes_precision: training: 0.945292 validation: 0.955169
09/16 06:49:27 AM: edges-ner-ontonotes_recall: training: 0.912782 validation: 0.928951
09/16 06:49:27 AM: edges-ner-ontonotes_f1: training: 0.928753 validation: 0.941877
09/16 06:49:27 AM: Global learning rate: 0.0001
09/16 06:49:27 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:49:36 AM: Update 15437: task edges-ner-ontonotes, batch 437 (15437): mcc: 0.9260, acc: 0.8903, precision: 0.9467, recall: 0.9137, f1: 0.9299, edges-ner-ontonotes_loss: 0.0253
09/16 06:49:36 AM: Update 18060: task edges-ner-ontonotes, batch 60 (18060): mcc: 0.9391, acc: 0.9092, precision: 0.9543, recall: 0.9306, f1: 0.9423, edges-ner-ontonotes_loss: 0.0194
09/16 06:49:46 AM: Update 15508: task edges-ner-ontonotes, batch 508 (15508): mcc: 0.9225, acc: 0.8859, precision: 0.9441, recall: 0.9096, f1: 0.9266, edges-ner-ontonotes_loss: 0.0268
09/16 06:49:47 AM: Update 18140: task edges-ner-ontonotes, batch 140 (18140): mcc: 0.9388, acc: 0.9081, precision: 0.9529, recall: 0.9315, f1: 0.9421, edges-ner-ontonotes_loss: 0.0191
09/16 06:49:56 AM: Update 15570: task edges-ner-ontonotes, batch 570 (15570): mcc: 0.9206, acc: 0.8833, precision: 0.9428, recall: 0.9073, f1: 0.9247, edges-ner-ontonotes_loss: 0.0277
09/16 06:49:57 AM: Update 18220: task edges-ner-ontonotes, batch 220 (18220): mcc: 0.9399, acc: 0.9086, precision: 0.9545, recall: 0.9320, f1: 0.9431, edges-ner-ontonotes_loss: 0.0189
09/16 06:50:06 AM: Update 15649: task edges-ner-ontonotes, batch 649 (15649): mcc: 0.9193, acc: 0.8819, precision: 0.9418, recall: 0.9060, f1: 0.9235, edges-ner-ontonotes_loss: 0.0280
09/16 06:50:07 AM: Update 18305: task edges-ner-ontonotes, batch 305 (18305): mcc: 0.9414, acc: 0.9108, precision: 0.9554, recall: 0.9340, f1: 0.9446, edges-ner-ontonotes_loss: 0.0186
09/16 06:50:16 AM: Update 15727: task edges-ner-ontonotes, batch 727 (15727): mcc: 0.9183, acc: 0.8806, precision: 0.9412, recall: 0.9046, f1: 0.9226, edges-ner-ontonotes_loss: 0.0281
09/16 06:50:17 AM: Update 18375: task edges-ner-ontonotes, batch 375 (18375): mcc: 0.9400, acc: 0.9090, precision: 0.9548, recall: 0.9320, f1: 0.9432, edges-ner-ontonotes_loss: 0.0192
09/16 06:50:26 AM: Update 15802: task edges-ner-ontonotes, batch 802 (15802): mcc: 0.9179, acc: 0.8799, precision: 0.9413, recall: 0.9039, f1: 0.9222, edges-ner-ontonotes_loss: 0.0280
09/16 06:50:27 AM: Update 18460: task edges-ner-ontonotes, batch 460 (18460): mcc: 0.9334, acc: 0.9008, precision: 0.9503, recall: 0.9239, f1: 0.9369, edges-ner-ontonotes_loss: 0.0220
09/16 06:50:37 AM: Update 18550: task edges-ner-ontonotes, batch 550 (18550): mcc: 0.9289, acc: 0.8947, precision: 0.9481, recall: 0.9177, f1: 0.9326, edges-ner-ontonotes_loss: 0.0238
09/16 06:50:38 AM: Update 15874: task edges-ner-ontonotes, batch 874 (15874): mcc: 0.9173, acc: 0.8791, precision: 0.9406, recall: 0.9033, f1: 0.9216, edges-ner-ontonotes_loss: 0.0280
09/16 06:50:47 AM: Update 18639: task edges-ner-ontonotes, batch 639 (18639): mcc: 0.9259, acc: 0.8912, precision: 0.9458, recall: 0.9144, f1: 0.9298, edges-ner-ontonotes_loss: 0.0251
09/16 06:50:48 AM: Update 15947: task edges-ner-ontonotes, batch 947 (15947): mcc: 0.9178, acc: 0.8797, precision: 0.9408, recall: 0.9040, f1: 0.9220, edges-ner-ontonotes_loss: 0.0278
09/16 06:50:55 AM: ***** Step 16000 / Validation 16 *****
09/16 06:50:55 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:50:55 AM: Validating...
09/16 06:50:57 AM: Update 18703: task edges-ner-ontonotes, batch 703 (18703): mcc: 0.9237, acc: 0.8883, precision: 0.9443, recall: 0.9117, f1: 0.9277, edges-ner-ontonotes_loss: 0.0260
09/16 06:50:58 AM: Evaluate: task edges-ner-ontonotes, batch 24 (157): mcc: 0.8822, acc: 0.8449, precision: 0.9104, recall: 0.8672, f1: 0.8883, edges-ner-ontonotes_loss: 0.0369
09/16 06:51:07 AM: Update 18770: task edges-ner-ontonotes, batch 770 (18770): mcc: 0.9226, acc: 0.8867, precision: 0.9437, recall: 0.9103, f1: 0.9267, edges-ner-ontonotes_loss: 0.0263
09/16 06:51:09 AM: Evaluate: task edges-ner-ontonotes, batch 82 (157): mcc: 0.9286, acc: 0.8985, precision: 0.9497, recall: 0.9155, f1: 0.9323, edges-ner-ontonotes_loss: 0.0251
09/16 06:51:17 AM: Update 18832: task edges-ner-ontonotes, batch 832 (18832): mcc: 0.9223, acc: 0.8861, precision: 0.9436, recall: 0.9098, f1: 0.9264, edges-ner-ontonotes_loss: 0.0263
09/16 06:51:19 AM: Evaluate: task edges-ner-ontonotes, batch 135 (157): mcc: 0.9366, acc: 0.9088, precision: 0.9550, recall: 0.9254, f1: 0.9400, edges-ner-ontonotes_loss: 0.0218
09/16 06:51:25 AM: Updating LR scheduler:
09/16 06:51:26 AM: 	Best result seen so far for macro_avg: 0.942
09/16 06:51:26 AM: 	# validation passes without improvement: 1
09/16 06:51:26 AM: edges-ner-ontonotes_loss: training: 0.027447 validation: 0.020973
09/16 06:51:26 AM: macro_avg: validation: 0.941502
09/16 06:51:26 AM: micro_avg: validation: 0.000000
09/16 06:51:26 AM: edges-ner-ontonotes_mcc: training: 0.918395 validation: 0.938223
09/16 06:51:26 AM: edges-ner-ontonotes_acc: training: 0.880422 validation: 0.911056
09/16 06:51:26 AM: edges-ner-ontonotes_precision: training: 0.941315 validation: 0.955280
09/16 06:51:26 AM: edges-ner-ontonotes_recall: training: 0.904707 validation: 0.928116
09/16 06:51:26 AM: edges-ner-ontonotes_f1: training: 0.922648 validation: 0.941502
09/16 06:51:26 AM: Global learning rate: 0.0001
09/16 06:51:26 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:51:27 AM: Update 18929: task edges-ner-ontonotes, batch 929 (18929): mcc: 0.9222, acc: 0.8860, precision: 0.9437, recall: 0.9096, f1: 0.9263, edges-ner-ontonotes_loss: 0.0262
09/16 06:51:31 AM: Update 16043: task edges-ner-ontonotes, batch 43 (16043): mcc: 0.9256, acc: 0.8925, precision: 0.9476, recall: 0.9120, f1: 0.9295, edges-ner-ontonotes_loss: 0.0226
09/16 06:51:36 AM: ***** Step 19000 / Validation 19 *****
09/16 06:51:37 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:51:37 AM: Validating...
09/16 06:51:37 AM: Evaluate: task edges-ner-ontonotes, batch 3 (157): mcc: 0.7804, acc: 0.6863, precision: 0.8361, recall: 0.7500, f1: 0.7907, edges-ner-ontonotes_loss: 0.0537
09/16 06:51:42 AM: Update 16108: task edges-ner-ontonotes, batch 108 (16108): mcc: 0.9218, acc: 0.8878, precision: 0.9427, recall: 0.9097, f1: 0.9259, edges-ner-ontonotes_loss: 0.0250
09/16 06:51:47 AM: Evaluate: task edges-ner-ontonotes, batch 69 (157): mcc: 0.9234, acc: 0.8899, precision: 0.9465, recall: 0.9090, f1: 0.9273, edges-ner-ontonotes_loss: 0.0260
09/16 06:51:54 AM: Update 16161: task edges-ner-ontonotes, batch 161 (16161): mcc: 0.9227, acc: 0.8894, precision: 0.9425, recall: 0.9116, f1: 0.9268, edges-ner-ontonotes_loss: 0.0246
09/16 06:51:57 AM: Evaluate: task edges-ner-ontonotes, batch 121 (157): mcc: 0.9327, acc: 0.9026, precision: 0.9530, recall: 0.9201, f1: 0.9363, edges-ner-ontonotes_loss: 0.0227
09/16 06:52:03 AM: Updating LR scheduler:
09/16 06:52:03 AM: 	Best result seen so far for macro_avg: 0.942
09/16 06:52:03 AM: 	# validation passes without improvement: 0
09/16 06:52:03 AM: edges-ner-ontonotes_loss: training: 0.026364 validation: 0.020714
09/16 06:52:03 AM: macro_avg: validation: 0.941476
09/16 06:52:03 AM: micro_avg: validation: 0.000000
09/16 06:52:03 AM: edges-ner-ontonotes_mcc: training: 0.921401 validation: 0.938230
09/16 06:52:03 AM: edges-ner-ontonotes_acc: training: 0.885077 validation: 0.910297
09/16 06:52:03 AM: edges-ner-ontonotes_precision: training: 0.942885 validation: 0.956999
09/16 06:52:03 AM: edges-ner-ontonotes_recall: training: 0.908787 validation: 0.926448
09/16 06:52:03 AM: edges-ner-ontonotes_f1: training: 0.925522 validation: 0.941476
09/16 06:52:03 AM: Global learning rate: 5e-05
09/16 06:52:03 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:52:04 AM: Update 16200: task edges-ner-ontonotes, batch 200 (16200): mcc: 0.9253, acc: 0.8919, precision: 0.9444, recall: 0.9146, f1: 0.9293, edges-ner-ontonotes_loss: 0.0239
09/16 06:52:07 AM: Update 19036: task edges-ner-ontonotes, batch 36 (19036): mcc: 0.9272, acc: 0.8954, precision: 0.9457, recall: 0.9169, f1: 0.9311, edges-ner-ontonotes_loss: 0.0237
09/16 06:52:14 AM: Update 16272: task edges-ner-ontonotes, batch 272 (16272): mcc: 0.9283, acc: 0.8948, precision: 0.9469, recall: 0.9177, f1: 0.9321, edges-ner-ontonotes_loss: 0.0228
09/16 06:52:18 AM: Update 19113: task edges-ner-ontonotes, batch 113 (19113): mcc: 0.9257, acc: 0.8926, precision: 0.9466, recall: 0.9131, f1: 0.9296, edges-ner-ontonotes_loss: 0.0247
09/16 06:52:24 AM: Update 16344: task edges-ner-ontonotes, batch 344 (16344): mcc: 0.9308, acc: 0.8978, precision: 0.9485, recall: 0.9209, f1: 0.9345, edges-ner-ontonotes_loss: 0.0219
09/16 06:52:28 AM: Update 19188: task edges-ner-ontonotes, batch 188 (19188): mcc: 0.9255, acc: 0.8913, precision: 0.9459, recall: 0.9135, f1: 0.9294, edges-ner-ontonotes_loss: 0.0242
09/16 06:52:34 AM: Update 16414: task edges-ner-ontonotes, batch 414 (16414): mcc: 0.9334, acc: 0.9010, precision: 0.9506, recall: 0.9236, f1: 0.9369, edges-ner-ontonotes_loss: 0.0211
09/16 06:52:39 AM: Update 19269: task edges-ner-ontonotes, batch 269 (19269): mcc: 0.9274, acc: 0.8936, precision: 0.9477, recall: 0.9153, f1: 0.9312, edges-ner-ontonotes_loss: 0.0236
09/16 06:52:44 AM: Update 16485: task edges-ner-ontonotes, batch 485 (16485): mcc: 0.9350, acc: 0.9030, precision: 0.9520, recall: 0.9253, f1: 0.9385, edges-ner-ontonotes_loss: 0.0207
09/16 06:52:49 AM: Update 19336: task edges-ner-ontonotes, batch 336 (19336): mcc: 0.9292, acc: 0.8955, precision: 0.9489, recall: 0.9175, f1: 0.9329, edges-ner-ontonotes_loss: 0.0231
09/16 06:52:54 AM: Update 16532: task edges-ner-ontonotes, batch 532 (16532): mcc: 0.9353, acc: 0.9033, precision: 0.9523, recall: 0.9257, f1: 0.9388, edges-ner-ontonotes_loss: 0.0206
09/16 06:52:59 AM: Update 19414: task edges-ner-ontonotes, batch 414 (19414): mcc: 0.9319, acc: 0.8989, precision: 0.9504, recall: 0.9210, f1: 0.9355, edges-ner-ontonotes_loss: 0.0221
09/16 06:53:04 AM: Update 16599: task edges-ner-ontonotes, batch 599 (16599): mcc: 0.9363, acc: 0.9046, precision: 0.9529, recall: 0.9269, f1: 0.9397, edges-ner-ontonotes_loss: 0.0203
09/16 06:53:09 AM: Update 19490: task edges-ner-ontonotes, batch 490 (19490): mcc: 0.9332, acc: 0.9005, precision: 0.9512, recall: 0.9228, f1: 0.9368, edges-ner-ontonotes_loss: 0.0214
09/16 06:53:15 AM: Update 16667: task edges-ner-ontonotes, batch 667 (16667): mcc: 0.9366, acc: 0.9049, precision: 0.9530, recall: 0.9274, f1: 0.9400, edges-ner-ontonotes_loss: 0.0204
09/16 06:53:19 AM: Update 19568: task edges-ner-ontonotes, batch 568 (19568): mcc: 0.9347, acc: 0.9024, precision: 0.9522, recall: 0.9245, f1: 0.9381, edges-ner-ontonotes_loss: 0.0209
09/16 06:53:25 AM: Update 16734: task edges-ner-ontonotes, batch 734 (16734): mcc: 0.9369, acc: 0.9050, precision: 0.9531, recall: 0.9277, f1: 0.9403, edges-ner-ontonotes_loss: 0.0202
09/16 06:53:29 AM: Update 19639: task edges-ner-ontonotes, batch 639 (19639): mcc: 0.9354, acc: 0.9031, precision: 0.9526, recall: 0.9254, f1: 0.9388, edges-ner-ontonotes_loss: 0.0207
09/16 06:53:35 AM: Update 16801: task edges-ner-ontonotes, batch 801 (16801): mcc: 0.9372, acc: 0.9054, precision: 0.9536, recall: 0.9279, f1: 0.9406, edges-ner-ontonotes_loss: 0.0201
09/16 06:53:39 AM: Update 19728: task edges-ner-ontonotes, batch 728 (19728): mcc: 0.9361, acc: 0.9039, precision: 0.9528, recall: 0.9265, f1: 0.9395, edges-ner-ontonotes_loss: 0.0205
09/16 06:53:46 AM: Update 16851: task edges-ner-ontonotes, batch 851 (16851): mcc: 0.9357, acc: 0.9033, precision: 0.9527, recall: 0.9258, f1: 0.9391, edges-ner-ontonotes_loss: 0.0207
09/16 06:53:49 AM: Update 19811: task edges-ner-ontonotes, batch 811 (19811): mcc: 0.9361, acc: 0.9039, precision: 0.9527, recall: 0.9267, f1: 0.9395, edges-ner-ontonotes_loss: 0.0205
09/16 06:53:58 AM: Update 16917: task edges-ner-ontonotes, batch 917 (16917): mcc: 0.9331, acc: 0.8999, precision: 0.9511, recall: 0.9227, f1: 0.9367, edges-ner-ontonotes_loss: 0.0217
09/16 06:53:59 AM: Update 19894: task edges-ner-ontonotes, batch 894 (19894): mcc: 0.9365, acc: 0.9044, precision: 0.9530, recall: 0.9271, f1: 0.9399, edges-ner-ontonotes_loss: 0.0202
09/16 06:54:09 AM: Update 16990: task edges-ner-ontonotes, batch 990 (16990): mcc: 0.9311, acc: 0.8974, precision: 0.9499, recall: 0.9201, f1: 0.9348, edges-ner-ontonotes_loss: 0.0227
09/16 06:54:09 AM: Update 19958: task edges-ner-ontonotes, batch 958 (19958): mcc: 0.9352, acc: 0.9027, precision: 0.9522, recall: 0.9256, f1: 0.9387, edges-ner-ontonotes_loss: 0.0208
09/16 06:54:10 AM: ***** Step 17000 / Validation 17 *****
09/16 06:54:10 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:54:10 AM: Validating...
09/16 06:54:17 AM: ***** Step 20000 / Validation 20 *****
09/16 06:54:17 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:54:17 AM: Validating...
09/16 06:54:19 AM: Evaluate: task edges-ner-ontonotes, batch 56 (157): mcc: 0.9159, acc: 0.8845, precision: 0.9350, recall: 0.9061, f1: 0.9203, edges-ner-ontonotes_loss: 0.0287
09/16 06:54:20 AM: Evaluate: task edges-ner-ontonotes, batch 17 (157): mcc: 0.8782, acc: 0.8349, precision: 0.9114, recall: 0.8589, f1: 0.8844, edges-ner-ontonotes_loss: 0.0324
09/16 06:54:29 AM: Evaluate: task edges-ner-ontonotes, batch 104 (157): mcc: 0.9230, acc: 0.8917, precision: 0.9459, recall: 0.9088, f1: 0.9270, edges-ner-ontonotes_loss: 0.0261
09/16 06:54:32 AM: Evaluate: task edges-ner-ontonotes, batch 66 (157): mcc: 0.9186, acc: 0.8865, precision: 0.9420, recall: 0.9044, f1: 0.9228, edges-ner-ontonotes_loss: 0.0274
09/16 06:54:39 AM: Evaluate: task edges-ner-ontonotes, batch 146 (157): mcc: 0.9330, acc: 0.9045, precision: 0.9534, recall: 0.9201, f1: 0.9365, edges-ner-ontonotes_loss: 0.0229
09/16 06:54:42 AM: Updating LR scheduler:
09/16 06:54:42 AM: 	Best result seen so far for macro_avg: 0.942
09/16 06:54:42 AM: 	# validation passes without improvement: 2
09/16 06:54:42 AM: edges-ner-ontonotes_loss: training: 0.022890 validation: 0.022333
09/16 06:54:42 AM: macro_avg: validation: 0.937358
09/16 06:54:42 AM: micro_avg: validation: 0.000000
09/16 06:54:42 AM: edges-ner-ontonotes_mcc: training: 0.930970 validation: 0.933885
09/16 06:54:42 AM: edges-ner-ontonotes_acc: training: 0.897206 validation: 0.905596
09/16 06:54:42 AM: edges-ner-ontonotes_precision: training: 0.949757 validation: 0.953344
09/16 06:54:42 AM: edges-ner-ontonotes_recall: training: 0.919956 validation: 0.921899
09/16 06:54:42 AM: edges-ner-ontonotes_f1: training: 0.934619 validation: 0.937358
09/16 06:54:42 AM: Global learning rate: 0.0001
09/16 06:54:42 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:54:44 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9304, acc: 0.9013, precision: 0.9521, recall: 0.9166, f1: 0.9340, edges-ner-ontonotes_loss: 0.0238
09/16 06:54:49 AM: Update 17036: task edges-ner-ontonotes, batch 36 (17036): mcc: 0.9087, acc: 0.8623, precision: 0.9363, recall: 0.8915, f1: 0.9134, edges-ner-ontonotes_loss: 0.0312
09/16 06:54:51 AM: Updating LR scheduler:
09/16 06:54:51 AM: 	Best result seen so far for macro_avg: 0.942
09/16 06:54:51 AM: 	# validation passes without improvement: 1
09/16 06:54:51 AM: edges-ner-ontonotes_loss: training: 0.021497 validation: 0.021060
09/16 06:54:51 AM: macro_avg: validation: 0.941068
09/16 06:54:51 AM: micro_avg: validation: 0.000000
09/16 06:54:51 AM: edges-ner-ontonotes_mcc: training: 0.933675 validation: 0.937807
09/16 06:54:51 AM: edges-ner-ontonotes_acc: training: 0.900742 validation: 0.910525
09/16 06:54:51 AM: edges-ner-ontonotes_precision: training: 0.951201 validation: 0.956965
09/16 06:54:51 AM: edges-ner-ontonotes_recall: training: 0.923603 validation: 0.925690
09/16 06:54:51 AM: edges-ner-ontonotes_f1: training: 0.937199 validation: 0.941068
09/16 06:54:51 AM: Global learning rate: 5e-05
09/16 06:54:51 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:54:54 AM: Update 20023: task edges-ner-ontonotes, batch 23 (20023): mcc: 0.8957, acc: 0.8520, precision: 0.9230, recall: 0.8801, f1: 0.9011, edges-ner-ontonotes_loss: 0.0351
09/16 06:54:59 AM: Update 17107: task edges-ner-ontonotes, batch 107 (17107): mcc: 0.8996, acc: 0.8530, precision: 0.9285, recall: 0.8822, f1: 0.9048, edges-ner-ontonotes_loss: 0.0342
09/16 06:55:04 AM: Update 20117: task edges-ner-ontonotes, batch 117 (20117): mcc: 0.9084, acc: 0.8676, precision: 0.9345, recall: 0.8926, f1: 0.9131, edges-ner-ontonotes_loss: 0.0308
09/16 06:55:10 AM: Update 17163: task edges-ner-ontonotes, batch 163 (17163): mcc: 0.9036, acc: 0.8597, precision: 0.9310, recall: 0.8872, f1: 0.9086, edges-ner-ontonotes_loss: 0.0323
09/16 06:55:14 AM: Update 20200: task edges-ner-ontonotes, batch 200 (20200): mcc: 0.9054, acc: 0.8641, precision: 0.9324, recall: 0.8892, f1: 0.9103, edges-ner-ontonotes_loss: 0.0320
09/16 06:55:20 AM: Update 17247: task edges-ner-ontonotes, batch 247 (17247): mcc: 0.9048, acc: 0.8611, precision: 0.9317, recall: 0.8887, f1: 0.9097, edges-ner-ontonotes_loss: 0.0310
09/16 06:55:24 AM: Update 20267: task edges-ner-ontonotes, batch 267 (20267): mcc: 0.9045, acc: 0.8628, precision: 0.9319, recall: 0.8880, f1: 0.9094, edges-ner-ontonotes_loss: 0.0322
09/16 06:55:30 AM: Update 17333: task edges-ner-ontonotes, batch 333 (17333): mcc: 0.9055, acc: 0.8620, precision: 0.9321, recall: 0.8896, f1: 0.9103, edges-ner-ontonotes_loss: 0.0307
09/16 06:55:34 AM: Update 20363: task edges-ner-ontonotes, batch 363 (20363): mcc: 0.9069, acc: 0.8659, precision: 0.9331, recall: 0.8913, f1: 0.9117, edges-ner-ontonotes_loss: 0.0308
09/16 06:55:40 AM: Update 17417: task edges-ner-ontonotes, batch 417 (17417): mcc: 0.9080, acc: 0.8659, precision: 0.9339, recall: 0.8924, f1: 0.9127, edges-ner-ontonotes_loss: 0.0300
09/16 06:55:44 AM: Update 20471: task edges-ner-ontonotes, batch 471 (20471): mcc: 0.9083, acc: 0.8678, precision: 0.9340, recall: 0.8930, f1: 0.9130, edges-ner-ontonotes_loss: 0.0303
09/16 06:55:50 AM: Update 17473: task edges-ner-ontonotes, batch 473 (17473): mcc: 0.9095, acc: 0.8680, precision: 0.9349, recall: 0.8944, f1: 0.9142, edges-ner-ontonotes_loss: 0.0296
09/16 06:55:54 AM: Update 20549: task edges-ner-ontonotes, batch 549 (20549): mcc: 0.9092, acc: 0.8687, precision: 0.9345, recall: 0.8941, f1: 0.9139, edges-ner-ontonotes_loss: 0.0299
09/16 06:56:02 AM: Update 17541: task edges-ner-ontonotes, batch 541 (17541): mcc: 0.9120, acc: 0.8710, precision: 0.9368, recall: 0.8972, f1: 0.9166, edges-ner-ontonotes_loss: 0.0290
09/16 06:56:04 AM: Update 20631: task edges-ner-ontonotes, batch 631 (20631): mcc: 0.9120, acc: 0.8729, precision: 0.9365, recall: 0.8975, f1: 0.9166, edges-ner-ontonotes_loss: 0.0290
09/16 06:56:12 AM: Update 17610: task edges-ner-ontonotes, batch 610 (17610): mcc: 0.9139, acc: 0.8738, precision: 0.9380, recall: 0.8995, f1: 0.9184, edges-ner-ontonotes_loss: 0.0283
09/16 06:56:14 AM: Update 20710: task edges-ner-ontonotes, batch 710 (20710): mcc: 0.9141, acc: 0.8757, precision: 0.9378, recall: 0.9001, f1: 0.9185, edges-ner-ontonotes_loss: 0.0284
09/16 06:56:22 AM: Update 17676: task edges-ner-ontonotes, batch 676 (17676): mcc: 0.9156, acc: 0.8763, precision: 0.9393, recall: 0.9015, f1: 0.9200, edges-ner-ontonotes_loss: 0.0277
09/16 06:56:24 AM: Update 20788: task edges-ner-ontonotes, batch 788 (20788): mcc: 0.9153, acc: 0.8771, precision: 0.9389, recall: 0.9013, f1: 0.9197, edges-ner-ontonotes_loss: 0.0279
09/16 06:56:34 AM: Update 17743: task edges-ner-ontonotes, batch 743 (17743): mcc: 0.9170, acc: 0.8782, precision: 0.9402, recall: 0.9031, f1: 0.9213, edges-ner-ontonotes_loss: 0.0273
09/16 06:56:34 AM: Update 20857: task edges-ner-ontonotes, batch 857 (20857): mcc: 0.9163, acc: 0.8786, precision: 0.9395, recall: 0.9025, f1: 0.9206, edges-ner-ontonotes_loss: 0.0276
09/16 06:56:44 AM: Update 17809: task edges-ner-ontonotes, batch 809 (17809): mcc: 0.9195, acc: 0.8818, precision: 0.9418, recall: 0.9064, f1: 0.9237, edges-ner-ontonotes_loss: 0.0266
09/16 06:56:44 AM: Update 20938: task edges-ner-ontonotes, batch 938 (20938): mcc: 0.9190, acc: 0.8821, precision: 0.9414, recall: 0.9058, f1: 0.9232, edges-ner-ontonotes_loss: 0.0267
09/16 06:56:53 AM: ***** Step 21000 / Validation 21 *****
09/16 06:56:53 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:56:53 AM: Validating...
09/16 06:56:54 AM: Update 17873: task edges-ner-ontonotes, batch 873 (17873): mcc: 0.9215, acc: 0.8844, precision: 0.9431, recall: 0.9088, f1: 0.9256, edges-ner-ontonotes_loss: 0.0260
09/16 06:56:55 AM: Evaluate: task edges-ner-ontonotes, batch 13 (157): mcc: 0.8600, acc: 0.8092, precision: 0.9026, recall: 0.8335, f1: 0.8667, edges-ner-ontonotes_loss: 0.0395
09/16 06:57:04 AM: Update 17926: task edges-ner-ontonotes, batch 926 (17926): mcc: 0.9228, acc: 0.8862, precision: 0.9438, recall: 0.9104, f1: 0.9268, edges-ner-ontonotes_loss: 0.0256
09/16 06:57:05 AM: Evaluate: task edges-ner-ontonotes, batch 73 (157): mcc: 0.9222, acc: 0.8915, precision: 0.9448, recall: 0.9085, f1: 0.9263, edges-ner-ontonotes_loss: 0.0270
09/16 06:57:14 AM: Update 17977: task edges-ner-ontonotes, batch 977 (17977): mcc: 0.9243, acc: 0.8882, precision: 0.9450, recall: 0.9121, f1: 0.9283, edges-ner-ontonotes_loss: 0.0252
09/16 06:57:15 AM: Evaluate: task edges-ner-ontonotes, batch 126 (157): mcc: 0.9346, acc: 0.9073, precision: 0.9530, recall: 0.9235, f1: 0.9380, edges-ner-ontonotes_loss: 0.0226
09/16 06:57:19 AM: ***** Step 18000 / Validation 18 *****
09/16 06:57:19 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:57:19 AM: Validating...
09/16 06:57:20 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:57:20 AM: Best result seen so far for macro.
09/16 06:57:20 AM: Updating LR scheduler:
09/16 06:57:20 AM: 	Best result seen so far for macro_avg: 0.943
09/16 06:57:20 AM: 	# validation passes without improvement: 0
09/16 06:57:20 AM: edges-ner-ontonotes_loss: training: 0.026178 validation: 0.020746
09/16 06:57:20 AM: macro_avg: validation: 0.942844
09/16 06:57:20 AM: micro_avg: validation: 0.000000
09/16 06:57:20 AM: edges-ner-ontonotes_mcc: training: 0.920672 validation: 0.939619
09/16 06:57:20 AM: edges-ner-ontonotes_acc: training: 0.884250 validation: 0.913861
09/16 06:57:20 AM: edges-ner-ontonotes_precision: training: 0.942559 validation: 0.955395
09/16 06:57:20 AM: edges-ner-ontonotes_recall: training: 0.907743 validation: 0.930619
09/16 06:57:20 AM: edges-ner-ontonotes_f1: training: 0.924823 validation: 0.942844
09/16 06:57:20 AM: Global learning rate: 5e-05
09/16 06:57:20 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:57:24 AM: Evaluate: task edges-ner-ontonotes, batch 34 (157): mcc: 0.9003, acc: 0.8644, precision: 0.9263, recall: 0.8857, f1: 0.9055, edges-ner-ontonotes_loss: 0.0335
09/16 06:57:25 AM: Update 21026: task edges-ner-ontonotes, batch 26 (21026): mcc: 0.9401, acc: 0.9071, precision: 0.9493, recall: 0.9375, f1: 0.9434, edges-ner-ontonotes_loss: 0.0202
09/16 06:57:34 AM: Evaluate: task edges-ner-ontonotes, batch 89 (157): mcc: 0.9286, acc: 0.8976, precision: 0.9502, recall: 0.9151, f1: 0.9323, edges-ner-ontonotes_loss: 0.0254
09/16 06:57:35 AM: Update 21086: task edges-ner-ontonotes, batch 86 (21086): mcc: 0.9427, acc: 0.9118, precision: 0.9561, recall: 0.9357, f1: 0.9458, edges-ner-ontonotes_loss: 0.0183
09/16 06:57:44 AM: Evaluate: task edges-ner-ontonotes, batch 137 (157): mcc: 0.9367, acc: 0.9097, precision: 0.9549, recall: 0.9256, f1: 0.9400, edges-ner-ontonotes_loss: 0.0221
09/16 06:57:45 AM: Update 21144: task edges-ner-ontonotes, batch 144 (21144): mcc: 0.9418, acc: 0.9111, precision: 0.9557, recall: 0.9344, f1: 0.9449, edges-ner-ontonotes_loss: 0.0189
09/16 06:57:48 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:57:48 AM: Best result seen so far for macro.
09/16 06:57:48 AM: Updating LR scheduler:
09/16 06:57:48 AM: 	Best result seen so far for macro_avg: 0.942
09/16 06:57:48 AM: 	# validation passes without improvement: 3
09/16 06:57:48 AM: edges-ner-ontonotes_loss: training: 0.024937 validation: 0.021185
09/16 06:57:48 AM: macro_avg: validation: 0.941877
09/16 06:57:48 AM: micro_avg: validation: 0.000000
09/16 06:57:48 AM: edges-ner-ontonotes_mcc: training: 0.924798 validation: 0.938611
09/16 06:57:48 AM: edges-ner-ontonotes_acc: training: 0.888848 validation: 0.911890
09/16 06:57:48 AM: edges-ner-ontonotes_precision: training: 0.945292 validation: 0.955169
09/16 06:57:48 AM: edges-ner-ontonotes_recall: training: 0.912782 validation: 0.928951
09/16 06:57:48 AM: edges-ner-ontonotes_f1: training: 0.928753 validation: 0.941877
09/16 06:57:48 AM: Global learning rate: 0.0001
09/16 06:57:48 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 06:57:54 AM: Update 18047: task edges-ner-ontonotes, batch 47 (18047): mcc: 0.9403, acc: 0.9105, precision: 0.9557, recall: 0.9316, f1: 0.9435, edges-ner-ontonotes_loss: 0.0190
09/16 06:57:55 AM: Update 21200: task edges-ner-ontonotes, batch 200 (21200): mcc: 0.9413, acc: 0.9103, precision: 0.9558, recall: 0.9335, f1: 0.9445, edges-ner-ontonotes_loss: 0.0189
09/16 06:58:05 AM: Update 18098: task edges-ner-ontonotes, batch 98 (18098): mcc: 0.9392, acc: 0.9088, precision: 0.9540, recall: 0.9312, f1: 0.9425, edges-ner-ontonotes_loss: 0.0190
09/16 06:58:05 AM: Update 21292: task edges-ner-ontonotes, batch 292 (21292): mcc: 0.9413, acc: 0.9103, precision: 0.9557, recall: 0.9335, f1: 0.9445, edges-ner-ontonotes_loss: 0.0188
09/16 06:58:15 AM: Update 18168: task edges-ner-ontonotes, batch 168 (18168): mcc: 0.9390, acc: 0.9079, precision: 0.9537, recall: 0.9312, f1: 0.9423, edges-ner-ontonotes_loss: 0.0190
09/16 06:58:15 AM: Update 21368: task edges-ner-ontonotes, batch 368 (21368): mcc: 0.9406, acc: 0.9093, precision: 0.9550, recall: 0.9328, f1: 0.9437, edges-ner-ontonotes_loss: 0.0191
09/16 06:58:25 AM: Update 18237: task edges-ner-ontonotes, batch 237 (18237): mcc: 0.9404, acc: 0.9095, precision: 0.9549, recall: 0.9327, f1: 0.9436, edges-ner-ontonotes_loss: 0.0187
09/16 06:58:25 AM: Update 21443: task edges-ner-ontonotes, batch 443 (21443): mcc: 0.9403, acc: 0.9086, precision: 0.9554, recall: 0.9319, f1: 0.9435, edges-ner-ontonotes_loss: 0.0191
09/16 06:58:35 AM: Update 18310: task edges-ner-ontonotes, batch 310 (18310): mcc: 0.9416, acc: 0.9114, precision: 0.9555, recall: 0.9342, f1: 0.9448, edges-ner-ontonotes_loss: 0.0186
09/16 06:58:35 AM: Update 21506: task edges-ner-ontonotes, batch 506 (21506): mcc: 0.9381, acc: 0.9063, precision: 0.9541, recall: 0.9291, f1: 0.9414, edges-ner-ontonotes_loss: 0.0201
09/16 06:58:45 AM: Update 18369: task edges-ner-ontonotes, batch 369 (18369): mcc: 0.9413, acc: 0.9107, precision: 0.9555, recall: 0.9337, f1: 0.9445, edges-ner-ontonotes_loss: 0.0188
09/16 06:58:45 AM: Update 21591: task edges-ner-ontonotes, batch 591 (21591): mcc: 0.9342, acc: 0.9014, precision: 0.9518, recall: 0.9239, f1: 0.9377, edges-ner-ontonotes_loss: 0.0220
09/16 06:58:55 AM: Update 18433: task edges-ner-ontonotes, batch 433 (18433): mcc: 0.9345, acc: 0.9023, precision: 0.9512, recall: 0.9253, f1: 0.9380, edges-ner-ontonotes_loss: 0.0214
09/16 06:58:55 AM: Update 21669: task edges-ner-ontonotes, batch 669 (21669): mcc: 0.9314, acc: 0.8978, precision: 0.9501, recall: 0.9204, f1: 0.9350, edges-ner-ontonotes_loss: 0.0232
09/16 06:59:05 AM: Update 18502: task edges-ner-ontonotes, batch 502 (18502): mcc: 0.9310, acc: 0.8976, precision: 0.9492, recall: 0.9205, f1: 0.9347, edges-ner-ontonotes_loss: 0.0231
09/16 06:59:05 AM: Update 21746: task edges-ner-ontonotes, batch 746 (21746): mcc: 0.9287, acc: 0.8943, precision: 0.9481, recall: 0.9175, f1: 0.9325, edges-ner-ontonotes_loss: 0.0243
09/16 06:59:15 AM: Update 18581: task edges-ner-ontonotes, batch 581 (18581): mcc: 0.9275, acc: 0.8930, precision: 0.9469, recall: 0.9163, f1: 0.9313, edges-ner-ontonotes_loss: 0.0245
09/16 06:59:16 AM: Update 21817: task edges-ner-ontonotes, batch 817 (21817): mcc: 0.9273, acc: 0.8925, precision: 0.9473, recall: 0.9155, f1: 0.9311, edges-ner-ontonotes_loss: 0.0249
09/16 06:59:25 AM: Update 18657: task edges-ner-ontonotes, batch 657 (18657): mcc: 0.9253, acc: 0.8905, precision: 0.9454, recall: 0.9137, f1: 0.9292, edges-ner-ontonotes_loss: 0.0255
09/16 06:59:26 AM: Update 21915: task edges-ner-ontonotes, batch 915 (21915): mcc: 0.9262, acc: 0.8909, precision: 0.9464, recall: 0.9142, f1: 0.9300, edges-ner-ontonotes_loss: 0.0252
09/16 06:59:34 AM: ***** Step 22000 / Validation 22 *****
09/16 06:59:34 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:59:34 AM: Validating...
09/16 06:59:35 AM: Update 18714: task edges-ner-ontonotes, batch 714 (18714): mcc: 0.9235, acc: 0.8880, precision: 0.9442, recall: 0.9115, f1: 0.9275, edges-ner-ontonotes_loss: 0.0260
09/16 06:59:36 AM: Evaluate: task edges-ner-ontonotes, batch 14 (157): mcc: 0.8712, acc: 0.8263, precision: 0.9058, recall: 0.8513, f1: 0.8777, edges-ner-ontonotes_loss: 0.0345
09/16 06:59:45 AM: Update 18768: task edges-ner-ontonotes, batch 768 (18768): mcc: 0.9225, acc: 0.8866, precision: 0.9436, recall: 0.9102, f1: 0.9266, edges-ner-ontonotes_loss: 0.0263
09/16 06:59:46 AM: Evaluate: task edges-ner-ontonotes, batch 76 (157): mcc: 0.9251, acc: 0.8950, precision: 0.9469, recall: 0.9117, f1: 0.9290, edges-ner-ontonotes_loss: 0.0254
09/16 06:59:56 AM: Update 18824: task edges-ner-ontonotes, batch 824 (18824): mcc: 0.9224, acc: 0.8862, precision: 0.9436, recall: 0.9099, f1: 0.9264, edges-ner-ontonotes_loss: 0.0263
09/16 06:59:56 AM: Evaluate: task edges-ner-ontonotes, batch 131 (157): mcc: 0.9363, acc: 0.9090, precision: 0.9563, recall: 0.9236, f1: 0.9397, edges-ner-ontonotes_loss: 0.0217
09/16 06:59:59 AM: Updating LR scheduler:
09/16 06:59:59 AM: 	Best result seen so far for macro_avg: 0.943
09/16 06:59:59 AM: 	# validation passes without improvement: 1
09/16 06:59:59 AM: edges-ner-ontonotes_loss: training: 0.025437 validation: 0.020443
09/16 06:59:59 AM: macro_avg: validation: 0.942789
09/16 06:59:59 AM: micro_avg: validation: 0.000000
09/16 06:59:59 AM: edges-ner-ontonotes_mcc: training: 0.925648 validation: 0.939605
09/16 06:59:59 AM: edges-ner-ontonotes_acc: training: 0.890317 validation: 0.913482
09/16 06:59:59 AM: edges-ner-ontonotes_precision: training: 0.946206 validation: 0.957610
09/16 06:59:59 AM: edges-ner-ontonotes_recall: training: 0.913478 validation: 0.928420
09/16 06:59:59 AM: edges-ner-ontonotes_f1: training: 0.929554 validation: 0.942789
09/16 06:59:59 AM: Global learning rate: 5e-05
09/16 06:59:59 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:00:06 AM: Update 18899: task edges-ner-ontonotes, batch 899 (18899): mcc: 0.9223, acc: 0.8861, precision: 0.9437, recall: 0.9097, f1: 0.9264, edges-ner-ontonotes_loss: 0.0262
09/16 07:00:06 AM: Update 22063: task edges-ner-ontonotes, batch 63 (22063): mcc: 0.9225, acc: 0.8855, precision: 0.9465, recall: 0.9073, f1: 0.9265, edges-ner-ontonotes_loss: 0.0263
09/16 07:00:16 AM: Update 22137: task edges-ner-ontonotes, batch 137 (22137): mcc: 0.9208, acc: 0.8827, precision: 0.9458, recall: 0.9048, f1: 0.9248, edges-ner-ontonotes_loss: 0.0265
09/16 07:00:18 AM: Update 18986: task edges-ner-ontonotes, batch 986 (18986): mcc: 0.9215, acc: 0.8852, precision: 0.9429, recall: 0.9090, f1: 0.9256, edges-ner-ontonotes_loss: 0.0264
09/16 07:00:20 AM: ***** Step 19000 / Validation 19 *****
09/16 07:00:20 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:00:20 AM: Validating...
09/16 07:00:26 AM: Update 22216: task edges-ner-ontonotes, batch 216 (22216): mcc: 0.9245, acc: 0.8882, precision: 0.9465, recall: 0.9111, f1: 0.9285, edges-ner-ontonotes_loss: 0.0252
09/16 07:00:28 AM: Evaluate: task edges-ner-ontonotes, batch 48 (157): mcc: 0.9159, acc: 0.8821, precision: 0.9387, recall: 0.9025, f1: 0.9202, edges-ner-ontonotes_loss: 0.0279
09/16 07:00:36 AM: Update 22275: task edges-ner-ontonotes, batch 275 (22275): mcc: 0.9245, acc: 0.8885, precision: 0.9465, recall: 0.9111, f1: 0.9285, edges-ner-ontonotes_loss: 0.0249
09/16 07:00:38 AM: Evaluate: task edges-ner-ontonotes, batch 100 (157): mcc: 0.9261, acc: 0.8939, precision: 0.9484, recall: 0.9122, f1: 0.9299, edges-ner-ontonotes_loss: 0.0244
09/16 07:00:46 AM: Update 22342: task edges-ner-ontonotes, batch 342 (22342): mcc: 0.9255, acc: 0.8899, precision: 0.9467, recall: 0.9127, f1: 0.9294, edges-ner-ontonotes_loss: 0.0245
09/16 07:00:50 AM: Evaluate: task edges-ner-ontonotes, batch 150 (157): mcc: 0.9376, acc: 0.9095, precision: 0.9569, recall: 0.9253, f1: 0.9409, edges-ner-ontonotes_loss: 0.0210
09/16 07:00:51 AM: Updating LR scheduler:
09/16 07:00:51 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:00:51 AM: 	# validation passes without improvement: 0
09/16 07:00:51 AM: edges-ner-ontonotes_loss: training: 0.026364 validation: 0.020714
09/16 07:00:51 AM: macro_avg: validation: 0.941476
09/16 07:00:51 AM: micro_avg: validation: 0.000000
09/16 07:00:51 AM: edges-ner-ontonotes_mcc: training: 0.921401 validation: 0.938230
09/16 07:00:51 AM: edges-ner-ontonotes_acc: training: 0.885077 validation: 0.910297
09/16 07:00:51 AM: edges-ner-ontonotes_precision: training: 0.942885 validation: 0.956999
09/16 07:00:51 AM: edges-ner-ontonotes_recall: training: 0.908787 validation: 0.926448
09/16 07:00:51 AM: edges-ner-ontonotes_f1: training: 0.925522 validation: 0.941476
09/16 07:00:51 AM: Global learning rate: 5e-05
09/16 07:00:51 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:00:57 AM: Update 22411: task edges-ner-ontonotes, batch 411 (22411): mcc: 0.9254, acc: 0.8907, precision: 0.9466, recall: 0.9126, f1: 0.9293, edges-ner-ontonotes_loss: 0.0243
09/16 07:01:00 AM: Update 19062: task edges-ner-ontonotes, batch 62 (19062): mcc: 0.9289, acc: 0.8948, precision: 0.9506, recall: 0.9152, f1: 0.9326, edges-ner-ontonotes_loss: 0.0235
09/16 07:01:08 AM: Update 22484: task edges-ner-ontonotes, batch 484 (22484): mcc: 0.9284, acc: 0.8943, precision: 0.9481, recall: 0.9167, f1: 0.9321, edges-ner-ontonotes_loss: 0.0236
09/16 07:01:10 AM: Update 19125: task edges-ner-ontonotes, batch 125 (19125): mcc: 0.9259, acc: 0.8931, precision: 0.9460, recall: 0.9142, f1: 0.9298, edges-ner-ontonotes_loss: 0.0244
09/16 07:01:18 AM: Update 22560: task edges-ner-ontonotes, batch 560 (22560): mcc: 0.9308, acc: 0.8974, precision: 0.9497, recall: 0.9197, f1: 0.9344, edges-ner-ontonotes_loss: 0.0227
09/16 07:01:20 AM: Update 19192: task edges-ner-ontonotes, batch 192 (19192): mcc: 0.9257, acc: 0.8915, precision: 0.9460, recall: 0.9137, f1: 0.9296, edges-ner-ontonotes_loss: 0.0241
09/16 07:01:28 AM: Update 22640: task edges-ner-ontonotes, batch 640 (22640): mcc: 0.9325, acc: 0.8995, precision: 0.9506, recall: 0.9221, f1: 0.9361, edges-ner-ontonotes_loss: 0.0220
09/16 07:01:30 AM: Update 19265: task edges-ner-ontonotes, batch 265 (19265): mcc: 0.9273, acc: 0.8934, precision: 0.9475, recall: 0.9152, f1: 0.9311, edges-ner-ontonotes_loss: 0.0236
09/16 07:01:39 AM: Update 22724: task edges-ner-ontonotes, batch 724 (22724): mcc: 0.9343, acc: 0.9019, precision: 0.9519, recall: 0.9242, f1: 0.9378, edges-ner-ontonotes_loss: 0.0214
09/16 07:01:40 AM: Update 19315: task edges-ner-ontonotes, batch 315 (19315): mcc: 0.9280, acc: 0.8937, precision: 0.9481, recall: 0.9160, f1: 0.9318, edges-ner-ontonotes_loss: 0.0234
09/16 07:01:49 AM: Update 22801: task edges-ner-ontonotes, batch 801 (22801): mcc: 0.9351, acc: 0.9030, precision: 0.9522, recall: 0.9252, f1: 0.9385, edges-ner-ontonotes_loss: 0.0212
09/16 07:01:50 AM: Update 19381: task edges-ner-ontonotes, batch 381 (19381): mcc: 0.9302, acc: 0.8965, precision: 0.9495, recall: 0.9188, f1: 0.9339, edges-ner-ontonotes_loss: 0.0226
09/16 07:01:59 AM: Update 22876: task edges-ner-ontonotes, batch 876 (22876): mcc: 0.9358, acc: 0.9039, precision: 0.9527, recall: 0.9260, f1: 0.9392, edges-ner-ontonotes_loss: 0.0209
09/16 07:02:00 AM: Update 19448: task edges-ner-ontonotes, batch 448 (19448): mcc: 0.9325, acc: 0.8996, precision: 0.9507, recall: 0.9218, f1: 0.9360, edges-ner-ontonotes_loss: 0.0217
09/16 07:02:09 AM: Update 22949: task edges-ner-ontonotes, batch 949 (22949): mcc: 0.9360, acc: 0.9041, precision: 0.9529, recall: 0.9264, f1: 0.9395, edges-ner-ontonotes_loss: 0.0208
09/16 07:02:10 AM: Update 19512: task edges-ner-ontonotes, batch 512 (19512): mcc: 0.9335, acc: 0.9010, precision: 0.9513, recall: 0.9233, f1: 0.9371, edges-ner-ontonotes_loss: 0.0213
09/16 07:02:15 AM: ***** Step 23000 / Validation 23 *****
09/16 07:02:15 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:02:15 AM: Validating...
09/16 07:02:19 AM: Evaluate: task edges-ner-ontonotes, batch 25 (157): mcc: 0.8776, acc: 0.8420, precision: 0.9075, recall: 0.8616, f1: 0.8840, edges-ner-ontonotes_loss: 0.0397
09/16 07:02:20 AM: Update 19581: task edges-ner-ontonotes, batch 581 (19581): mcc: 0.9347, acc: 0.9023, precision: 0.9520, recall: 0.9246, f1: 0.9381, edges-ner-ontonotes_loss: 0.0209
09/16 07:02:31 AM: Update 19622: task edges-ner-ontonotes, batch 622 (19622): mcc: 0.9352, acc: 0.9030, precision: 0.9525, recall: 0.9252, f1: 0.9387, edges-ner-ontonotes_loss: 0.0208
09/16 07:02:31 AM: Evaluate: task edges-ner-ontonotes, batch 91 (157): mcc: 0.9279, acc: 0.8989, precision: 0.9486, recall: 0.9154, f1: 0.9317, edges-ner-ontonotes_loss: 0.0257
09/16 07:02:41 AM: Update 19672: task edges-ner-ontonotes, batch 672 (19672): mcc: 0.9358, acc: 0.9036, precision: 0.9529, recall: 0.9260, f1: 0.9392, edges-ner-ontonotes_loss: 0.0207
09/16 07:02:41 AM: Evaluate: task edges-ner-ontonotes, batch 142 (157): mcc: 0.9393, acc: 0.9147, precision: 0.9548, recall: 0.9306, f1: 0.9425, edges-ner-ontonotes_loss: 0.0215
09/16 07:02:46 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:02:46 AM: Best result seen so far for macro.
09/16 07:02:48 AM: Updating LR scheduler:
09/16 07:02:48 AM: 	Best result seen so far for macro_avg: 0.943
09/16 07:02:48 AM: 	# validation passes without improvement: 0
09/16 07:02:48 AM: edges-ner-ontonotes_loss: training: 0.020725 validation: 0.020901
09/16 07:02:48 AM: macro_avg: validation: 0.943415
09/16 07:02:48 AM: micro_avg: validation: 0.000000
09/16 07:02:48 AM: edges-ner-ontonotes_mcc: training: 0.936341 validation: 0.940202
09/16 07:02:48 AM: edges-ner-ontonotes_acc: training: 0.904550 validation: 0.915833
09/16 07:02:48 AM: edges-ner-ontonotes_precision: training: 0.953157 validation: 0.954733
09/16 07:02:48 AM: edges-ner-ontonotes_recall: training: 0.926675 validation: 0.932363
09/16 07:02:48 AM: edges-ner-ontonotes_f1: training: 0.939730 validation: 0.943415
09/16 07:02:48 AM: Global learning rate: 5e-05
09/16 07:02:48 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:02:54 AM: Update 19752: task edges-ner-ontonotes, batch 752 (19752): mcc: 0.9360, acc: 0.9039, precision: 0.9526, recall: 0.9266, f1: 0.9395, edges-ner-ontonotes_loss: 0.0205
09/16 07:02:54 AM: Update 23037: task edges-ner-ontonotes, batch 37 (23037): mcc: 0.9360, acc: 0.9022, precision: 0.9534, recall: 0.9259, f1: 0.9394, edges-ner-ontonotes_loss: 0.0191
09/16 07:03:04 AM: Update 19819: task edges-ner-ontonotes, batch 819 (19819): mcc: 0.9361, acc: 0.9040, precision: 0.9526, recall: 0.9267, f1: 0.9395, edges-ner-ontonotes_loss: 0.0204
09/16 07:03:05 AM: Update 23117: task edges-ner-ontonotes, batch 117 (23117): mcc: 0.9093, acc: 0.8692, precision: 0.9363, recall: 0.8927, f1: 0.9140, edges-ner-ontonotes_loss: 0.0311
09/16 07:03:14 AM: Update 19886: task edges-ner-ontonotes, batch 886 (19886): mcc: 0.9364, acc: 0.9043, precision: 0.9529, recall: 0.9270, f1: 0.9398, edges-ner-ontonotes_loss: 0.0203
09/16 07:03:15 AM: Update 23195: task edges-ner-ontonotes, batch 195 (23195): mcc: 0.9094, acc: 0.8691, precision: 0.9356, recall: 0.8934, f1: 0.9140, edges-ner-ontonotes_loss: 0.0312
09/16 07:03:24 AM: Update 19937: task edges-ner-ontonotes, batch 937 (19937): mcc: 0.9358, acc: 0.9034, precision: 0.9525, recall: 0.9262, f1: 0.9392, edges-ner-ontonotes_loss: 0.0204
09/16 07:03:25 AM: Update 23286: task edges-ner-ontonotes, batch 286 (23286): mcc: 0.9093, acc: 0.8690, precision: 0.9353, recall: 0.8936, f1: 0.9139, edges-ner-ontonotes_loss: 0.0315
09/16 07:03:32 AM: ***** Step 20000 / Validation 20 *****
09/16 07:03:32 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:03:32 AM: Validating...
09/16 07:03:34 AM: Evaluate: task edges-ner-ontonotes, batch 15 (157): mcc: 0.8683, acc: 0.8239, precision: 0.9043, recall: 0.8474, f1: 0.8749, edges-ner-ontonotes_loss: 0.0349
09/16 07:03:35 AM: Update 23348: task edges-ner-ontonotes, batch 348 (23348): mcc: 0.9077, acc: 0.8669, precision: 0.9337, recall: 0.8923, f1: 0.9125, edges-ner-ontonotes_loss: 0.0320
09/16 07:03:44 AM: Evaluate: task edges-ner-ontonotes, batch 73 (157): mcc: 0.9196, acc: 0.8878, precision: 0.9442, recall: 0.9042, f1: 0.9238, edges-ner-ontonotes_loss: 0.0271
09/16 07:03:45 AM: Update 23410: task edges-ner-ontonotes, batch 410 (23410): mcc: 0.9082, acc: 0.8678, precision: 0.9335, recall: 0.8933, f1: 0.9130, edges-ner-ontonotes_loss: 0.0313
09/16 07:03:54 AM: Evaluate: task edges-ner-ontonotes, batch 126 (157): mcc: 0.9334, acc: 0.9050, precision: 0.9546, recall: 0.9198, f1: 0.9369, edges-ner-ontonotes_loss: 0.0229
09/16 07:03:55 AM: Update 23476: task edges-ner-ontonotes, batch 476 (23476): mcc: 0.9092, acc: 0.8689, precision: 0.9346, recall: 0.8942, f1: 0.9139, edges-ner-ontonotes_loss: 0.0307
09/16 07:03:59 AM: Updating LR scheduler:
09/16 07:03:59 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:04:01 AM: 	# validation passes without improvement: 1
09/16 07:04:01 AM: edges-ner-ontonotes_loss: training: 0.021497 validation: 0.021060
09/16 07:04:01 AM: macro_avg: validation: 0.941068
09/16 07:04:01 AM: micro_avg: validation: 0.000000
09/16 07:04:01 AM: edges-ner-ontonotes_mcc: training: 0.933675 validation: 0.937807
09/16 07:04:01 AM: edges-ner-ontonotes_acc: training: 0.900742 validation: 0.910525
09/16 07:04:01 AM: edges-ner-ontonotes_precision: training: 0.951201 validation: 0.956965
09/16 07:04:01 AM: edges-ner-ontonotes_recall: training: 0.923603 validation: 0.925690
09/16 07:04:01 AM: edges-ner-ontonotes_f1: training: 0.937199 validation: 0.941068
09/16 07:04:01 AM: Global learning rate: 5e-05
09/16 07:04:01 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:04:04 AM: Update 20026: task edges-ner-ontonotes, batch 26 (20026): mcc: 0.8985, acc: 0.8554, precision: 0.9270, recall: 0.8815, f1: 0.9037, edges-ner-ontonotes_loss: 0.0346
09/16 07:04:05 AM: Update 23572: task edges-ner-ontonotes, batch 572 (23572): mcc: 0.9103, acc: 0.8703, precision: 0.9356, recall: 0.8952, f1: 0.9149, edges-ner-ontonotes_loss: 0.0302
09/16 07:04:18 AM: Update 20107: task edges-ner-ontonotes, batch 107 (20107): mcc: 0.9078, acc: 0.8670, precision: 0.9342, recall: 0.8918, f1: 0.9125, edges-ner-ontonotes_loss: 0.0309
09/16 07:04:19 AM: Update 23654: task edges-ner-ontonotes, batch 654 (23654): mcc: 0.9107, acc: 0.8707, precision: 0.9358, recall: 0.8957, f1: 0.9153, edges-ner-ontonotes_loss: 0.0299
09/16 07:04:28 AM: Update 20175: task edges-ner-ontonotes, batch 175 (20175): mcc: 0.9063, acc: 0.8652, precision: 0.9331, recall: 0.8902, f1: 0.9112, edges-ner-ontonotes_loss: 0.0316
09/16 07:04:29 AM: Update 23732: task edges-ner-ontonotes, batch 732 (23732): mcc: 0.9131, acc: 0.8739, precision: 0.9376, recall: 0.8984, f1: 0.9176, edges-ner-ontonotes_loss: 0.0291
09/16 07:04:39 AM: Update 20229: task edges-ner-ontonotes, batch 229 (20229): mcc: 0.9033, acc: 0.8617, precision: 0.9310, recall: 0.8866, f1: 0.9082, edges-ner-ontonotes_loss: 0.0329
09/16 07:04:39 AM: Update 23825: task edges-ner-ontonotes, batch 825 (23825): mcc: 0.9146, acc: 0.8760, precision: 0.9386, recall: 0.9003, f1: 0.9190, edges-ner-ontonotes_loss: 0.0284
09/16 07:04:49 AM: Update 23913: task edges-ner-ontonotes, batch 913 (23913): mcc: 0.9155, acc: 0.8773, precision: 0.9391, recall: 0.9015, f1: 0.9199, edges-ner-ontonotes_loss: 0.0280
09/16 07:04:49 AM: Update 20306: task edges-ner-ontonotes, batch 306 (20306): mcc: 0.9055, acc: 0.8640, precision: 0.9322, recall: 0.8894, f1: 0.9103, edges-ner-ontonotes_loss: 0.0316
09/16 07:04:59 AM: Update 23977: task edges-ner-ontonotes, batch 977 (23977): mcc: 0.9168, acc: 0.8789, precision: 0.9399, recall: 0.9030, f1: 0.9211, edges-ner-ontonotes_loss: 0.0276
09/16 07:04:59 AM: Update 20391: task edges-ner-ontonotes, batch 391 (20391): mcc: 0.9073, acc: 0.8663, precision: 0.9333, recall: 0.8919, f1: 0.9121, edges-ner-ontonotes_loss: 0.0307
09/16 07:05:02 AM: ***** Step 24000 / Validation 24 *****
09/16 07:05:02 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:05:02 AM: Validating...
09/16 07:05:09 AM: Evaluate: task edges-ner-ontonotes, batch 51 (157): mcc: 0.9192, acc: 0.8904, precision: 0.9389, recall: 0.9086, f1: 0.9235, edges-ner-ontonotes_loss: 0.0281
09/16 07:05:09 AM: Update 20453: task edges-ner-ontonotes, batch 453 (20453): mcc: 0.9080, acc: 0.8672, precision: 0.9338, recall: 0.8926, f1: 0.9127, edges-ner-ontonotes_loss: 0.0304
09/16 07:05:19 AM: Evaluate: task edges-ner-ontonotes, batch 110 (157): mcc: 0.9315, acc: 0.9048, precision: 0.9490, recall: 0.9218, f1: 0.9352, edges-ner-ontonotes_loss: 0.0236
09/16 07:05:19 AM: Update 20509: task edges-ner-ontonotes, batch 509 (20509): mcc: 0.9090, acc: 0.8685, precision: 0.9344, recall: 0.8940, f1: 0.9137, edges-ner-ontonotes_loss: 0.0300
09/16 07:05:27 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:05:27 AM: Best result seen so far for macro.
09/16 07:05:27 AM: Updating LR scheduler:
09/16 07:05:27 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:05:27 AM: 	# validation passes without improvement: 0
09/16 07:05:27 AM: edges-ner-ontonotes_loss: training: 0.027366 validation: 0.020507
09/16 07:05:27 AM: macro_avg: validation: 0.943756
09/16 07:05:27 AM: micro_avg: validation: 0.000000
09/16 07:05:27 AM: edges-ner-ontonotes_mcc: training: 0.917591 validation: 0.940554
09/16 07:05:27 AM: edges-ner-ontonotes_acc: training: 0.879939 validation: 0.915453
09/16 07:05:27 AM: edges-ner-ontonotes_precision: training: 0.940526 validation: 0.954479
09/16 07:05:27 AM: edges-ner-ontonotes_recall: training: 0.903974 validation: 0.933273
09/16 07:05:27 AM: edges-ner-ontonotes_f1: training: 0.921888 validation: 0.943756
09/16 07:05:27 AM: Global learning rate: 5e-05
09/16 07:05:27 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:05:29 AM: Update 24017: task edges-ner-ontonotes, batch 17 (24017): mcc: 0.9476, acc: 0.9197, precision: 0.9595, recall: 0.9415, f1: 0.9504, edges-ner-ontonotes_loss: 0.0179
09/16 07:05:29 AM: Update 20548: task edges-ner-ontonotes, batch 548 (20548): mcc: 0.9092, acc: 0.8687, precision: 0.9346, recall: 0.8941, f1: 0.9139, edges-ner-ontonotes_loss: 0.0299
09/16 07:05:39 AM: Update 24090: task edges-ner-ontonotes, batch 90 (24090): mcc: 0.9466, acc: 0.9179, precision: 0.9575, recall: 0.9417, f1: 0.9495, edges-ner-ontonotes_loss: 0.0176
09/16 07:05:39 AM: Update 20616: task edges-ner-ontonotes, batch 616 (20616): mcc: 0.9119, acc: 0.8726, precision: 0.9364, recall: 0.8973, f1: 0.9164, edges-ner-ontonotes_loss: 0.0290
09/16 07:05:49 AM: Update 24170: task edges-ner-ontonotes, batch 170 (24170): mcc: 0.9452, acc: 0.9172, precision: 0.9572, recall: 0.9393, f1: 0.9482, edges-ner-ontonotes_loss: 0.0180
09/16 07:05:49 AM: Update 20686: task edges-ner-ontonotes, batch 686 (20686): mcc: 0.9133, acc: 0.8746, precision: 0.9372, recall: 0.8992, f1: 0.9178, edges-ner-ontonotes_loss: 0.0285
09/16 07:05:59 AM: Update 24248: task edges-ner-ontonotes, batch 248 (24248): mcc: 0.9455, acc: 0.9173, precision: 0.9582, recall: 0.9389, f1: 0.9484, edges-ner-ontonotes_loss: 0.0177
09/16 07:05:59 AM: Update 20753: task edges-ner-ontonotes, batch 753 (20753): mcc: 0.9145, acc: 0.8762, precision: 0.9381, recall: 0.9006, f1: 0.9189, edges-ner-ontonotes_loss: 0.0282
09/16 07:06:09 AM: Update 24308: task edges-ner-ontonotes, batch 308 (24308): mcc: 0.9437, acc: 0.9145, precision: 0.9565, recall: 0.9372, f1: 0.9467, edges-ner-ontonotes_loss: 0.0181
09/16 07:06:09 AM: Update 20827: task edges-ner-ontonotes, batch 827 (20827): mcc: 0.9160, acc: 0.8782, precision: 0.9393, recall: 0.9022, f1: 0.9203, edges-ner-ontonotes_loss: 0.0277
09/16 07:06:19 AM: Update 24394: task edges-ner-ontonotes, batch 394 (24394): mcc: 0.9438, acc: 0.9141, precision: 0.9571, recall: 0.9367, f1: 0.9468, edges-ner-ontonotes_loss: 0.0181
09/16 07:06:19 AM: Update 20875: task edges-ner-ontonotes, batch 875 (20875): mcc: 0.9170, acc: 0.8794, precision: 0.9400, recall: 0.9033, f1: 0.9213, edges-ner-ontonotes_loss: 0.0273
09/16 07:06:29 AM: Update 24474: task edges-ner-ontonotes, batch 474 (24474): mcc: 0.9431, acc: 0.9133, precision: 0.9567, recall: 0.9359, f1: 0.9462, edges-ner-ontonotes_loss: 0.0183
09/16 07:06:29 AM: Update 20943: task edges-ner-ontonotes, batch 943 (20943): mcc: 0.9191, acc: 0.8822, precision: 0.9415, recall: 0.9059, f1: 0.9233, edges-ner-ontonotes_loss: 0.0267
09/16 07:06:39 AM: ***** Step 21000 / Validation 21 *****
09/16 07:06:39 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:06:39 AM: Validating...
09/16 07:06:39 AM: Evaluate: task edges-ner-ontonotes, batch 5 (157): mcc: 0.8132, acc: 0.7493, precision: 0.8725, recall: 0.7761, f1: 0.8215, edges-ner-ontonotes_loss: 0.0497
09/16 07:06:39 AM: Update 24548: task edges-ner-ontonotes, batch 548 (24548): mcc: 0.9429, acc: 0.9128, precision: 0.9565, recall: 0.9357, f1: 0.9460, edges-ner-ontonotes_loss: 0.0184
09/16 07:06:50 AM: Evaluate: task edges-ner-ontonotes, batch 66 (157): mcc: 0.9216, acc: 0.8904, precision: 0.9440, recall: 0.9082, f1: 0.9257, edges-ner-ontonotes_loss: 0.0273
09/16 07:06:50 AM: Update 24599: task edges-ner-ontonotes, batch 599 (24599): mcc: 0.9418, acc: 0.9114, precision: 0.9558, recall: 0.9342, f1: 0.9449, edges-ner-ontonotes_loss: 0.0187
09/16 07:07:00 AM: Update 24659: task edges-ner-ontonotes, batch 659 (24659): mcc: 0.9384, acc: 0.9068, precision: 0.9535, recall: 0.9301, f1: 0.9417, edges-ner-ontonotes_loss: 0.0203
09/16 07:07:00 AM: Evaluate: task edges-ner-ontonotes, batch 116 (157): mcc: 0.9322, acc: 0.9041, precision: 0.9513, recall: 0.9208, f1: 0.9358, edges-ner-ontonotes_loss: 0.0234
09/16 07:07:07 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:07:07 AM: Best result seen so far for macro.
09/16 07:07:07 AM: Updating LR scheduler:
09/16 07:07:07 AM: 	Best result seen so far for macro_avg: 0.943
09/16 07:07:07 AM: 	# validation passes without improvement: 0
09/16 07:07:07 AM: edges-ner-ontonotes_loss: training: 0.026178 validation: 0.020746
09/16 07:07:07 AM: macro_avg: validation: 0.942844
09/16 07:07:07 AM: micro_avg: validation: 0.000000
09/16 07:07:07 AM: edges-ner-ontonotes_mcc: training: 0.920672 validation: 0.939619
09/16 07:07:07 AM: edges-ner-ontonotes_acc: training: 0.884250 validation: 0.913861
09/16 07:07:07 AM: edges-ner-ontonotes_precision: training: 0.942559 validation: 0.955395
09/16 07:07:07 AM: edges-ner-ontonotes_recall: training: 0.907743 validation: 0.930619
09/16 07:07:07 AM: edges-ner-ontonotes_f1: training: 0.924823 validation: 0.942844
09/16 07:07:07 AM: Global learning rate: 5e-05
09/16 07:07:07 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:07:10 AM: Update 24725: task edges-ner-ontonotes, batch 725 (24725): mcc: 0.9355, acc: 0.9030, precision: 0.9517, recall: 0.9265, f1: 0.9389, edges-ner-ontonotes_loss: 0.0215
09/16 07:07:10 AM: Update 21019: task edges-ner-ontonotes, batch 19 (21019): mcc: 0.9365, acc: 0.9022, precision: 0.9480, recall: 0.9321, f1: 0.9400, edges-ner-ontonotes_loss: 0.0221
09/16 07:07:20 AM: Update 24802: task edges-ner-ontonotes, batch 802 (24802): mcc: 0.9328, acc: 0.9000, precision: 0.9499, recall: 0.9233, f1: 0.9364, edges-ner-ontonotes_loss: 0.0226
09/16 07:07:20 AM: Update 21087: task edges-ner-ontonotes, batch 87 (21087): mcc: 0.9424, acc: 0.9115, precision: 0.9556, recall: 0.9356, f1: 0.9455, edges-ner-ontonotes_loss: 0.0184
09/16 07:07:30 AM: Update 21155: task edges-ner-ontonotes, batch 155 (21155): mcc: 0.9421, acc: 0.9113, precision: 0.9562, recall: 0.9344, f1: 0.9452, edges-ner-ontonotes_loss: 0.0189
09/16 07:07:30 AM: Update 24885: task edges-ner-ontonotes, batch 885 (24885): mcc: 0.9304, acc: 0.8969, precision: 0.9484, recall: 0.9203, f1: 0.9341, edges-ner-ontonotes_loss: 0.0237
09/16 07:07:40 AM: Update 24960: task edges-ner-ontonotes, batch 960 (24960): mcc: 0.9293, acc: 0.8953, precision: 0.9477, recall: 0.9189, f1: 0.9331, edges-ner-ontonotes_loss: 0.0240
09/16 07:07:40 AM: Update 21210: task edges-ner-ontonotes, batch 210 (21210): mcc: 0.9409, acc: 0.9097, precision: 0.9555, recall: 0.9329, f1: 0.9441, edges-ner-ontonotes_loss: 0.0191
09/16 07:07:45 AM: ***** Step 25000 / Validation 25 *****
09/16 07:07:45 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:07:45 AM: Validating...
09/16 07:07:50 AM: Evaluate: task edges-ner-ontonotes, batch 38 (157): mcc: 0.9104, acc: 0.8801, precision: 0.9325, recall: 0.8984, f1: 0.9151, edges-ner-ontonotes_loss: 0.0295
09/16 07:07:50 AM: Update 21273: task edges-ner-ontonotes, batch 273 (21273): mcc: 0.9413, acc: 0.9102, precision: 0.9559, recall: 0.9333, f1: 0.9445, edges-ner-ontonotes_loss: 0.0188
09/16 07:08:00 AM: Evaluate: task edges-ner-ontonotes, batch 92 (157): mcc: 0.9305, acc: 0.9010, precision: 0.9529, recall: 0.9161, f1: 0.9341, edges-ner-ontonotes_loss: 0.0240
09/16 07:08:00 AM: Update 21327: task edges-ner-ontonotes, batch 327 (21327): mcc: 0.9415, acc: 0.9104, precision: 0.9561, recall: 0.9334, f1: 0.9446, edges-ner-ontonotes_loss: 0.0187
09/16 07:08:10 AM: Evaluate: task edges-ner-ontonotes, batch 144 (157): mcc: 0.9396, acc: 0.9138, precision: 0.9577, recall: 0.9282, f1: 0.9428, edges-ner-ontonotes_loss: 0.0209
09/16 07:08:10 AM: Update 21378: task edges-ner-ontonotes, batch 378 (21378): mcc: 0.9406, acc: 0.9092, precision: 0.9551, recall: 0.9327, f1: 0.9438, edges-ner-ontonotes_loss: 0.0191
09/16 07:08:12 AM: Updating LR scheduler:
09/16 07:08:12 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:08:12 AM: 	# validation passes without improvement: 1
09/16 07:08:12 AM: edges-ner-ontonotes_loss: training: 0.024210 validation: 0.020466
09/16 07:08:12 AM: macro_avg: validation: 0.943237
09/16 07:08:12 AM: micro_avg: validation: 0.000000
09/16 07:08:12 AM: edges-ner-ontonotes_mcc: training: 0.928829 validation: 0.940070
09/16 07:08:12 AM: edges-ner-ontonotes_acc: training: 0.894662 validation: 0.914392
09/16 07:08:12 AM: edges-ner-ontonotes_precision: training: 0.947383 validation: 0.957646
09/16 07:08:12 AM: edges-ner-ontonotes_recall: training: 0.918276 validation: 0.929254
09/16 07:08:12 AM: edges-ner-ontonotes_f1: training: 0.932602 validation: 0.943237
09/16 07:08:12 AM: Global learning rate: 5e-05
09/16 07:08:12 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:08:20 AM: Update 25070: task edges-ner-ontonotes, batch 70 (25070): mcc: 0.9160, acc: 0.8769, precision: 0.9392, recall: 0.9023, f1: 0.9204, edges-ner-ontonotes_loss: 0.0274
09/16 07:08:21 AM: Update 21446: task edges-ner-ontonotes, batch 446 (21446): mcc: 0.9403, acc: 0.9087, precision: 0.9553, recall: 0.9320, f1: 0.9435, edges-ner-ontonotes_loss: 0.0191
09/16 07:08:30 AM: Update 25168: task edges-ner-ontonotes, batch 168 (25168): mcc: 0.9163, acc: 0.8779, precision: 0.9408, recall: 0.9014, f1: 0.9207, edges-ner-ontonotes_loss: 0.0273
09/16 07:08:31 AM: Update 21503: task edges-ner-ontonotes, batch 503 (21503): mcc: 0.9384, acc: 0.9066, precision: 0.9542, recall: 0.9294, f1: 0.9417, edges-ner-ontonotes_loss: 0.0200
09/16 07:08:40 AM: Update 25236: task edges-ner-ontonotes, batch 236 (25236): mcc: 0.9159, acc: 0.8777, precision: 0.9402, recall: 0.9011, f1: 0.9202, edges-ner-ontonotes_loss: 0.0272
09/16 07:08:41 AM: Update 21585: task edges-ner-ontonotes, batch 585 (21585): mcc: 0.9346, acc: 0.9018, precision: 0.9521, recall: 0.9244, f1: 0.9381, edges-ner-ontonotes_loss: 0.0219
09/16 07:08:50 AM: Update 25310: task edges-ner-ontonotes, batch 310 (25310): mcc: 0.9183, acc: 0.8805, precision: 0.9409, recall: 0.9049, f1: 0.9225, edges-ner-ontonotes_loss: 0.0264
09/16 07:08:51 AM: Update 21651: task edges-ner-ontonotes, batch 651 (21651): mcc: 0.9319, acc: 0.8984, precision: 0.9504, recall: 0.9211, f1: 0.9355, edges-ner-ontonotes_loss: 0.0229
09/16 07:09:01 AM: Update 25393: task edges-ner-ontonotes, batch 393 (25393): mcc: 0.9209, acc: 0.8844, precision: 0.9430, recall: 0.9077, f1: 0.9250, edges-ner-ontonotes_loss: 0.0256
09/16 07:09:01 AM: Update 21723: task edges-ner-ontonotes, batch 723 (21723): mcc: 0.9293, acc: 0.8952, precision: 0.9484, recall: 0.9182, f1: 0.9331, edges-ner-ontonotes_loss: 0.0241
09/16 07:09:11 AM: Update 25477: task edges-ner-ontonotes, batch 477 (25477): mcc: 0.9226, acc: 0.8866, precision: 0.9439, recall: 0.9100, f1: 0.9267, edges-ner-ontonotes_loss: 0.0250
09/16 07:09:12 AM: Update 21785: task edges-ner-ontonotes, batch 785 (21785): mcc: 0.9278, acc: 0.8931, precision: 0.9476, recall: 0.9162, f1: 0.9316, edges-ner-ontonotes_loss: 0.0247
09/16 07:09:21 AM: Update 25555: task edges-ner-ontonotes, batch 555 (25555): mcc: 0.9238, acc: 0.8886, precision: 0.9444, recall: 0.9119, f1: 0.9279, edges-ner-ontonotes_loss: 0.0246
09/16 07:09:24 AM: Update 21866: task edges-ner-ontonotes, batch 866 (21866): mcc: 0.9268, acc: 0.8918, precision: 0.9469, recall: 0.9149, f1: 0.9306, edges-ner-ontonotes_loss: 0.0251
09/16 07:09:31 AM: Update 25641: task edges-ner-ontonotes, batch 641 (25641): mcc: 0.9267, acc: 0.8924, precision: 0.9462, recall: 0.9154, f1: 0.9306, edges-ner-ontonotes_loss: 0.0238
09/16 07:09:34 AM: Update 21944: task edges-ner-ontonotes, batch 944 (21944): mcc: 0.9258, acc: 0.8905, precision: 0.9463, recall: 0.9137, f1: 0.9297, edges-ner-ontonotes_loss: 0.0253
09/16 07:09:41 AM: Update 25725: task edges-ner-ontonotes, batch 725 (25725): mcc: 0.9290, acc: 0.8954, precision: 0.9479, recall: 0.9181, f1: 0.9328, edges-ner-ontonotes_loss: 0.0231
09/16 07:09:41 AM: ***** Step 22000 / Validation 22 *****
09/16 07:09:41 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:09:41 AM: Validating...
09/16 07:09:44 AM: Evaluate: task edges-ner-ontonotes, batch 16 (157): mcc: 0.8781, acc: 0.8342, precision: 0.9097, recall: 0.8603, f1: 0.8843, edges-ner-ontonotes_loss: 0.0332
09/16 07:09:51 AM: Update 25787: task edges-ner-ontonotes, batch 787 (25787): mcc: 0.9303, acc: 0.8970, precision: 0.9487, recall: 0.9197, f1: 0.9340, edges-ner-ontonotes_loss: 0.0226
09/16 07:09:54 AM: Evaluate: task edges-ner-ontonotes, batch 70 (157): mcc: 0.9221, acc: 0.8900, precision: 0.9454, recall: 0.9077, f1: 0.9262, edges-ner-ontonotes_loss: 0.0258
09/16 07:10:01 AM: Update 25837: task edges-ner-ontonotes, batch 837 (25837): mcc: 0.9314, acc: 0.8982, precision: 0.9494, recall: 0.9211, f1: 0.9350, edges-ner-ontonotes_loss: 0.0223
09/16 07:10:04 AM: Evaluate: task edges-ner-ontonotes, batch 120 (157): mcc: 0.9340, acc: 0.9060, precision: 0.9542, recall: 0.9212, f1: 0.9374, edges-ner-ontonotes_loss: 0.0225
09/16 07:10:11 AM: Updating LR scheduler:
09/16 07:10:11 AM: 	Best result seen so far for macro_avg: 0.943
09/16 07:10:11 AM: 	# validation passes without improvement: 1
09/16 07:10:11 AM: edges-ner-ontonotes_loss: training: 0.025437 validation: 0.020443
09/16 07:10:11 AM: macro_avg: validation: 0.942789
09/16 07:10:11 AM: micro_avg: validation: 0.000000
09/16 07:10:11 AM: edges-ner-ontonotes_mcc: training: 0.925648 validation: 0.939605
09/16 07:10:11 AM: edges-ner-ontonotes_acc: training: 0.890317 validation: 0.913482
09/16 07:10:11 AM: edges-ner-ontonotes_precision: training: 0.946206 validation: 0.957610
09/16 07:10:11 AM: edges-ner-ontonotes_recall: training: 0.913478 validation: 0.928420
09/16 07:10:11 AM: edges-ner-ontonotes_f1: training: 0.929554 validation: 0.942789
09/16 07:10:11 AM: Global learning rate: 5e-05
09/16 07:10:11 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:10:11 AM: Update 25897: task edges-ner-ontonotes, batch 897 (25897): mcc: 0.9318, acc: 0.8987, precision: 0.9496, recall: 0.9216, f1: 0.9354, edges-ner-ontonotes_loss: 0.0221
09/16 07:10:14 AM: Update 22027: task edges-ner-ontonotes, batch 27 (22027): mcc: 0.9183, acc: 0.8795, precision: 0.9433, recall: 0.9025, f1: 0.9225, edges-ner-ontonotes_loss: 0.0270
09/16 07:10:21 AM: Update 25982: task edges-ner-ontonotes, batch 982 (25982): mcc: 0.9323, acc: 0.8992, precision: 0.9498, recall: 0.9223, f1: 0.9359, edges-ner-ontonotes_loss: 0.0219
09/16 07:10:23 AM: ***** Step 26000 / Validation 26 *****
09/16 07:10:24 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:10:24 AM: Validating...
09/16 07:10:26 AM: Update 22098: task edges-ner-ontonotes, batch 98 (22098): mcc: 0.9191, acc: 0.8807, precision: 0.9432, recall: 0.9042, f1: 0.9233, edges-ner-ontonotes_loss: 0.0270
09/16 07:10:31 AM: Evaluate: task edges-ner-ontonotes, batch 57 (157): mcc: 0.9231, acc: 0.8945, precision: 0.9416, recall: 0.9133, f1: 0.9272, edges-ner-ontonotes_loss: 0.0276
09/16 07:10:37 AM: Update 22151: task edges-ner-ontonotes, batch 151 (22151): mcc: 0.9221, acc: 0.8844, precision: 0.9460, recall: 0.9071, f1: 0.9261, edges-ner-ontonotes_loss: 0.0263
09/16 07:10:42 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9319, acc: 0.9045, precision: 0.9502, recall: 0.9212, f1: 0.9355, edges-ner-ontonotes_loss: 0.0240
09/16 07:10:47 AM: Update 22216: task edges-ner-ontonotes, batch 216 (22216): mcc: 0.9245, acc: 0.8882, precision: 0.9465, recall: 0.9111, f1: 0.9285, edges-ner-ontonotes_loss: 0.0252
09/16 07:10:51 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:10:51 AM: Best result seen so far for macro.
09/16 07:10:51 AM: Updating LR scheduler:
09/16 07:10:51 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:10:51 AM: 	# validation passes without improvement: 0
09/16 07:10:51 AM: edges-ner-ontonotes_loss: training: 0.021836 validation: 0.020859
09/16 07:10:51 AM: macro_avg: validation: 0.943929
09/16 07:10:51 AM: micro_avg: validation: 0.000000
09/16 07:10:51 AM: edges-ner-ontonotes_mcc: training: 0.932583 validation: 0.940742
09/16 07:10:51 AM: edges-ner-ontonotes_acc: training: 0.899708 validation: 0.915908
09/16 07:10:51 AM: edges-ner-ontonotes_precision: training: 0.949975 validation: 0.954990
09/16 07:10:51 AM: edges-ner-ontonotes_recall: training: 0.922759 validation: 0.933121
09/16 07:10:51 AM: edges-ner-ontonotes_f1: training: 0.936169 validation: 0.943929
09/16 07:10:51 AM: Global learning rate: 5e-05
09/16 07:10:51 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:10:54 AM: Update 26016: task edges-ner-ontonotes, batch 16 (26016): mcc: 0.9431, acc: 0.9112, precision: 0.9607, recall: 0.9319, f1: 0.9461, edges-ner-ontonotes_loss: 0.0168
09/16 07:10:57 AM: Update 22276: task edges-ner-ontonotes, batch 276 (22276): mcc: 0.9247, acc: 0.8887, precision: 0.9467, recall: 0.9112, f1: 0.9286, edges-ner-ontonotes_loss: 0.0249
09/16 07:11:04 AM: Update 26095: task edges-ner-ontonotes, batch 95 (26095): mcc: 0.9430, acc: 0.9133, precision: 0.9583, recall: 0.9340, f1: 0.9460, edges-ner-ontonotes_loss: 0.0183
09/16 07:11:07 AM: Update 22344: task edges-ner-ontonotes, batch 344 (22344): mcc: 0.9252, acc: 0.8898, precision: 0.9463, recall: 0.9125, f1: 0.9291, edges-ner-ontonotes_loss: 0.0246
09/16 07:11:14 AM: Update 26157: task edges-ner-ontonotes, batch 157 (26157): mcc: 0.9407, acc: 0.9096, precision: 0.9570, recall: 0.9310, f1: 0.9438, edges-ner-ontonotes_loss: 0.0194
09/16 07:11:18 AM: Update 22411: task edges-ner-ontonotes, batch 411 (22411): mcc: 0.9254, acc: 0.8907, precision: 0.9466, recall: 0.9126, f1: 0.9293, edges-ner-ontonotes_loss: 0.0243
09/16 07:11:24 AM: Update 26240: task edges-ner-ontonotes, batch 240 (26240): mcc: 0.9298, acc: 0.8957, precision: 0.9500, recall: 0.9175, f1: 0.9334, edges-ner-ontonotes_loss: 0.0241
09/16 07:11:28 AM: Update 22474: task edges-ner-ontonotes, batch 474 (22474): mcc: 0.9283, acc: 0.8942, precision: 0.9482, recall: 0.9165, f1: 0.9321, edges-ner-ontonotes_loss: 0.0236
09/16 07:11:34 AM: Update 26322: task edges-ner-ontonotes, batch 322 (26322): mcc: 0.9237, acc: 0.8879, precision: 0.9464, recall: 0.9097, f1: 0.9277, edges-ner-ontonotes_loss: 0.0262
09/16 07:11:38 AM: Update 22545: task edges-ner-ontonotes, batch 545 (22545): mcc: 0.9303, acc: 0.8968, precision: 0.9494, recall: 0.9192, f1: 0.9340, edges-ner-ontonotes_loss: 0.0229
09/16 07:11:44 AM: Update 26403: task edges-ner-ontonotes, batch 403 (26403): mcc: 0.9208, acc: 0.8842, precision: 0.9445, recall: 0.9062, f1: 0.9249, edges-ner-ontonotes_loss: 0.0273
09/16 07:11:48 AM: Update 22617: task edges-ner-ontonotes, batch 617 (22617): mcc: 0.9320, acc: 0.8988, precision: 0.9502, recall: 0.9214, f1: 0.9356, edges-ner-ontonotes_loss: 0.0222
09/16 07:11:54 AM: Update 26479: task edges-ner-ontonotes, batch 479 (26479): mcc: 0.9184, acc: 0.8808, precision: 0.9425, recall: 0.9036, f1: 0.9226, edges-ner-ontonotes_loss: 0.0282
09/16 07:12:01 AM: Update 22697: task edges-ner-ontonotes, batch 697 (22697): mcc: 0.9336, acc: 0.9008, precision: 0.9514, recall: 0.9233, f1: 0.9371, edges-ner-ontonotes_loss: 0.0216
09/16 07:12:05 AM: Update 26580: task edges-ner-ontonotes, batch 580 (26580): mcc: 0.9176, acc: 0.8796, precision: 0.9416, recall: 0.9029, f1: 0.9218, edges-ner-ontonotes_loss: 0.0281
09/16 07:12:12 AM: Update 22749: task edges-ner-ontonotes, batch 749 (22749): mcc: 0.9343, acc: 0.9020, precision: 0.9517, recall: 0.9244, f1: 0.9378, edges-ner-ontonotes_loss: 0.0213
09/16 07:12:15 AM: Update 26688: task edges-ner-ontonotes, batch 688 (26688): mcc: 0.9169, acc: 0.8788, precision: 0.9411, recall: 0.9021, f1: 0.9212, edges-ner-ontonotes_loss: 0.0281
09/16 07:12:23 AM: Update 22823: task edges-ner-ontonotes, batch 823 (22823): mcc: 0.9351, acc: 0.9031, precision: 0.9523, recall: 0.9253, f1: 0.9386, edges-ner-ontonotes_loss: 0.0211
09/16 07:12:25 AM: Update 26766: task edges-ner-ontonotes, batch 766 (26766): mcc: 0.9171, acc: 0.8789, precision: 0.9411, recall: 0.9024, f1: 0.9214, edges-ner-ontonotes_loss: 0.0279
09/16 07:12:34 AM: Update 22891: task edges-ner-ontonotes, batch 891 (22891): mcc: 0.9357, acc: 0.9038, precision: 0.9527, recall: 0.9260, f1: 0.9391, edges-ner-ontonotes_loss: 0.0209
09/16 07:12:35 AM: Update 26846: task edges-ner-ontonotes, batch 846 (26846): mcc: 0.9180, acc: 0.8800, precision: 0.9417, recall: 0.9036, f1: 0.9222, edges-ner-ontonotes_loss: 0.0274
09/16 07:12:44 AM: Update 22961: task edges-ner-ontonotes, batch 961 (22961): mcc: 0.9361, acc: 0.9043, precision: 0.9530, recall: 0.9264, f1: 0.9395, edges-ner-ontonotes_loss: 0.0208
09/16 07:12:46 AM: Update 26929: task edges-ner-ontonotes, batch 929 (26929): mcc: 0.9185, acc: 0.8808, precision: 0.9418, recall: 0.9043, f1: 0.9227, edges-ner-ontonotes_loss: 0.0271
09/16 07:12:50 AM: ***** Step 23000 / Validation 23 *****
09/16 07:12:50 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:12:50 AM: Validating...
09/16 07:12:55 AM: Evaluate: task edges-ner-ontonotes, batch 28 (157): mcc: 0.8869, acc: 0.8523, precision: 0.9142, recall: 0.8724, f1: 0.8928, edges-ner-ontonotes_loss: 0.0369
09/16 07:12:56 AM: Update 27000: task edges-ner-ontonotes, batch 1000 (27000): mcc: 0.9197, acc: 0.8826, precision: 0.9425, recall: 0.9059, f1: 0.9239, edges-ner-ontonotes_loss: 0.0267
09/16 07:12:56 AM: ***** Step 27000 / Validation 27 *****
09/16 07:12:56 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:12:56 AM: Validating...
09/16 07:13:05 AM: Evaluate: task edges-ner-ontonotes, batch 75 (157): mcc: 0.9223, acc: 0.8929, precision: 0.9434, recall: 0.9100, f1: 0.9264, edges-ner-ontonotes_loss: 0.0274
09/16 07:13:06 AM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.9192, acc: 0.8902, precision: 0.9399, recall: 0.9075, f1: 0.9234, edges-ner-ontonotes_loss: 0.0266
09/16 07:13:15 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9312, acc: 0.9042, precision: 0.9493, recall: 0.9207, f1: 0.9348, edges-ner-ontonotes_loss: 0.0241
09/16 07:13:17 AM: Evaluate: task edges-ner-ontonotes, batch 99 (157): mcc: 0.9283, acc: 0.8998, precision: 0.9497, recall: 0.9151, f1: 0.9321, edges-ner-ontonotes_loss: 0.0242
09/16 07:13:25 AM: Evaluate: task edges-ner-ontonotes, batch 156 (157): mcc: 0.9402, acc: 0.9158, precision: 0.9547, recall: 0.9323, f1: 0.9434, edges-ner-ontonotes_loss: 0.0210
09/16 07:13:25 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:13:25 AM: Best result seen so far for macro.
09/16 07:13:25 AM: Updating LR scheduler:
09/16 07:13:25 AM: 	Best result seen so far for macro_avg: 0.943
09/16 07:13:25 AM: 	# validation passes without improvement: 0
09/16 07:13:25 AM: edges-ner-ontonotes_loss: training: 0.020725 validation: 0.020901
09/16 07:13:25 AM: macro_avg: validation: 0.943415
09/16 07:13:25 AM: micro_avg: validation: 0.000000
09/16 07:13:25 AM: edges-ner-ontonotes_mcc: training: 0.936341 validation: 0.940202
09/16 07:13:25 AM: edges-ner-ontonotes_acc: training: 0.904550 validation: 0.915833
09/16 07:13:25 AM: edges-ner-ontonotes_precision: training: 0.953157 validation: 0.954733
09/16 07:13:25 AM: edges-ner-ontonotes_recall: training: 0.926675 validation: 0.932363
09/16 07:13:25 AM: edges-ner-ontonotes_f1: training: 0.939730 validation: 0.943415
09/16 07:13:25 AM: Global learning rate: 5e-05
09/16 07:13:25 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:13:27 AM: Evaluate: task edges-ner-ontonotes, batch 142 (157): mcc: 0.9397, acc: 0.9143, precision: 0.9572, recall: 0.9289, f1: 0.9429, edges-ner-ontonotes_loss: 0.0208
09/16 07:13:29 AM: Updating LR scheduler:
09/16 07:13:29 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:13:29 AM: 	# validation passes without improvement: 1
09/16 07:13:29 AM: edges-ner-ontonotes_loss: training: 0.026710 validation: 0.020300
09/16 07:13:29 AM: macro_avg: validation: 0.943750
09/16 07:13:29 AM: micro_avg: validation: 0.000000
09/16 07:13:29 AM: edges-ner-ontonotes_mcc: training: 0.919691 validation: 0.940596
09/16 07:13:29 AM: edges-ner-ontonotes_acc: training: 0.882593 validation: 0.915150
09/16 07:13:29 AM: edges-ner-ontonotes_precision: training: 0.942547 validation: 0.957258
09/16 07:13:29 AM: edges-ner-ontonotes_recall: training: 0.905924 validation: 0.930619
09/16 07:13:29 AM: edges-ner-ontonotes_f1: training: 0.923873 validation: 0.943750
09/16 07:13:29 AM: Global learning rate: 5e-05
09/16 07:13:29 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:13:35 AM: Update 23042: task edges-ner-ontonotes, batch 42 (23042): mcc: 0.9271, acc: 0.8921, precision: 0.9457, recall: 0.9167, f1: 0.9310, edges-ner-ontonotes_loss: 0.0209
09/16 07:13:37 AM: Update 27066: task edges-ner-ontonotes, batch 66 (27066): mcc: 0.9237, acc: 0.8883, precision: 0.9435, recall: 0.9125, f1: 0.9277, edges-ner-ontonotes_loss: 0.0247
09/16 07:13:45 AM: Update 23118: task edges-ner-ontonotes, batch 118 (23118): mcc: 0.9096, acc: 0.8695, precision: 0.9364, recall: 0.8931, f1: 0.9142, edges-ner-ontonotes_loss: 0.0310
09/16 07:13:47 AM: Update 27132: task edges-ner-ontonotes, batch 132 (27132): mcc: 0.9322, acc: 0.8986, precision: 0.9498, recall: 0.9221, f1: 0.9358, edges-ner-ontonotes_loss: 0.0220
09/16 07:13:55 AM: Update 23191: task edges-ner-ontonotes, batch 191 (23191): mcc: 0.9092, acc: 0.8687, precision: 0.9358, recall: 0.8929, f1: 0.9138, edges-ner-ontonotes_loss: 0.0313
09/16 07:13:57 AM: Update 27210: task edges-ner-ontonotes, batch 210 (27210): mcc: 0.9374, acc: 0.9062, precision: 0.9535, recall: 0.9284, f1: 0.9408, edges-ner-ontonotes_loss: 0.0203
09/16 07:14:05 AM: Update 23256: task edges-ner-ontonotes, batch 256 (23256): mcc: 0.9086, acc: 0.8681, precision: 0.9344, recall: 0.8931, f1: 0.9133, edges-ner-ontonotes_loss: 0.0316
09/16 07:14:07 AM: Update 27286: task edges-ner-ontonotes, batch 286 (27286): mcc: 0.9399, acc: 0.9095, precision: 0.9555, recall: 0.9309, f1: 0.9431, edges-ner-ontonotes_loss: 0.0194
09/16 07:14:16 AM: Update 23327: task edges-ner-ontonotes, batch 327 (23327): mcc: 0.9088, acc: 0.8683, precision: 0.9343, recall: 0.8937, f1: 0.9135, edges-ner-ontonotes_loss: 0.0319
09/16 07:14:17 AM: Update 27371: task edges-ner-ontonotes, batch 371 (27371): mcc: 0.9414, acc: 0.9113, precision: 0.9570, recall: 0.9323, f1: 0.9445, edges-ner-ontonotes_loss: 0.0190
09/16 07:14:26 AM: Update 23377: task edges-ner-ontonotes, batch 377 (23377): mcc: 0.9079, acc: 0.8672, precision: 0.9339, recall: 0.8924, f1: 0.9127, edges-ner-ontonotes_loss: 0.0317
09/16 07:14:27 AM: Update 27450: task edges-ner-ontonotes, batch 450 (27450): mcc: 0.9420, acc: 0.9118, precision: 0.9574, recall: 0.9331, f1: 0.9451, edges-ner-ontonotes_loss: 0.0188
09/16 07:14:36 AM: Update 23451: task edges-ner-ontonotes, batch 451 (23451): mcc: 0.9088, acc: 0.8685, precision: 0.9340, recall: 0.8939, f1: 0.9135, edges-ner-ontonotes_loss: 0.0310
09/16 07:14:37 AM: Update 27535: task edges-ner-ontonotes, batch 535 (27535): mcc: 0.9428, acc: 0.9126, precision: 0.9579, recall: 0.9340, f1: 0.9458, edges-ner-ontonotes_loss: 0.0186
09/16 07:14:46 AM: Update 23538: task edges-ner-ontonotes, batch 538 (23538): mcc: 0.9095, acc: 0.8693, precision: 0.9351, recall: 0.8942, f1: 0.9142, edges-ner-ontonotes_loss: 0.0304
09/16 07:14:49 AM: Update 27618: task edges-ner-ontonotes, batch 618 (27618): mcc: 0.9420, acc: 0.9115, precision: 0.9572, recall: 0.9333, f1: 0.9451, edges-ner-ontonotes_loss: 0.0188
09/16 07:14:56 AM: Update 23624: task edges-ner-ontonotes, batch 624 (23624): mcc: 0.9102, acc: 0.8700, precision: 0.9356, recall: 0.8950, f1: 0.9149, edges-ner-ontonotes_loss: 0.0300
09/16 07:15:02 AM: Update 27705: task edges-ner-ontonotes, batch 705 (27705): mcc: 0.9416, acc: 0.9109, precision: 0.9567, recall: 0.9330, f1: 0.9447, edges-ner-ontonotes_loss: 0.0189
09/16 07:15:06 AM: Update 23678: task edges-ner-ontonotes, batch 678 (23678): mcc: 0.9113, acc: 0.8715, precision: 0.9363, recall: 0.8963, f1: 0.9159, edges-ner-ontonotes_loss: 0.0297
09/16 07:15:12 AM: Update 27777: task edges-ner-ontonotes, batch 777 (27777): mcc: 0.9386, acc: 0.9070, precision: 0.9547, recall: 0.9293, f1: 0.9418, edges-ner-ontonotes_loss: 0.0200
09/16 07:15:16 AM: Update 23743: task edges-ner-ontonotes, batch 743 (23743): mcc: 0.9134, acc: 0.8742, precision: 0.9378, recall: 0.8988, f1: 0.9179, edges-ner-ontonotes_loss: 0.0290
09/16 07:15:22 AM: Update 27862: task edges-ner-ontonotes, batch 862 (27862): mcc: 0.9351, acc: 0.9024, precision: 0.9525, recall: 0.9251, f1: 0.9386, edges-ner-ontonotes_loss: 0.0215
09/16 07:15:26 AM: Update 23815: task edges-ner-ontonotes, batch 815 (23815): mcc: 0.9144, acc: 0.8758, precision: 0.9384, recall: 0.9001, f1: 0.9189, edges-ner-ontonotes_loss: 0.0285
09/16 07:15:33 AM: Update 27948: task edges-ner-ontonotes, batch 948 (27948): mcc: 0.9324, acc: 0.8991, precision: 0.9506, recall: 0.9218, f1: 0.9360, edges-ner-ontonotes_loss: 0.0227
09/16 07:15:36 AM: Update 23889: task edges-ner-ontonotes, batch 889 (23889): mcc: 0.9151, acc: 0.8768, precision: 0.9389, recall: 0.9010, f1: 0.9195, edges-ner-ontonotes_loss: 0.0281
09/16 07:15:38 AM: ***** Step 28000 / Validation 28 *****
09/16 07:15:38 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:15:38 AM: Validating...
09/16 07:15:43 AM: Evaluate: task edges-ner-ontonotes, batch 31 (157): mcc: 0.8993, acc: 0.8683, precision: 0.9235, recall: 0.8864, f1: 0.9046, edges-ner-ontonotes_loss: 0.0326
09/16 07:15:48 AM: Update 23941: task edges-ner-ontonotes, batch 941 (23941): mcc: 0.9162, acc: 0.8781, precision: 0.9395, recall: 0.9023, f1: 0.9205, edges-ner-ontonotes_loss: 0.0278
09/16 07:15:53 AM: Evaluate: task edges-ner-ontonotes, batch 89 (157): mcc: 0.9297, acc: 0.9018, precision: 0.9501, recall: 0.9172, f1: 0.9334, edges-ner-ontonotes_loss: 0.0244
09/16 07:15:58 AM: Update 23974: task edges-ner-ontonotes, batch 974 (23974): mcc: 0.9167, acc: 0.8789, precision: 0.9399, recall: 0.9029, f1: 0.9211, edges-ner-ontonotes_loss: 0.0276
09/16 07:16:03 AM: Evaluate: task edges-ner-ontonotes, batch 146 (157): mcc: 0.9378, acc: 0.9123, precision: 0.9562, recall: 0.9266, f1: 0.9411, edges-ner-ontonotes_loss: 0.0215
09/16 07:16:04 AM: ***** Step 24000 / Validation 24 *****
09/16 07:16:04 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:16:04 AM: Validating...
09/16 07:16:05 AM: Updating LR scheduler:
09/16 07:16:05 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:16:05 AM: 	# validation passes without improvement: 2
09/16 07:16:05 AM: edges-ner-ontonotes_loss: training: 0.023254 validation: 0.020889
09/16 07:16:05 AM: macro_avg: validation: 0.941950
09/16 07:16:05 AM: micro_avg: validation: 0.000000
09/16 07:16:05 AM: edges-ner-ontonotes_mcc: training: 0.931245 validation: 0.938701
09/16 07:16:05 AM: edges-ner-ontonotes_acc: training: 0.897550 validation: 0.913482
09/16 07:16:05 AM: edges-ner-ontonotes_precision: training: 0.949950 validation: 0.955962
09/16 07:16:05 AM: edges-ner-ontonotes_recall: training: 0.920281 validation: 0.928344
09/16 07:16:05 AM: edges-ner-ontonotes_f1: training: 0.934881 validation: 0.941950
09/16 07:16:05 AM: Global learning rate: 5e-05
09/16 07:16:05 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:16:08 AM: Evaluate: task edges-ner-ontonotes, batch 33 (157): mcc: 0.9063, acc: 0.8739, precision: 0.9302, recall: 0.8930, f1: 0.9112, edges-ner-ontonotes_loss: 0.0315
09/16 07:16:13 AM: Update 28040: task edges-ner-ontonotes, batch 40 (28040): mcc: 0.9112, acc: 0.8675, precision: 0.9426, recall: 0.8900, f1: 0.9156, edges-ner-ontonotes_loss: 0.0283
09/16 07:16:18 AM: Evaluate: task edges-ner-ontonotes, batch 89 (157): mcc: 0.9321, acc: 0.9047, precision: 0.9508, recall: 0.9212, f1: 0.9357, edges-ner-ontonotes_loss: 0.0241
09/16 07:16:23 AM: Update 28103: task edges-ner-ontonotes, batch 103 (28103): mcc: 0.9120, acc: 0.8729, precision: 0.9372, recall: 0.8968, f1: 0.9166, edges-ner-ontonotes_loss: 0.0290
09/16 07:16:29 AM: Evaluate: task edges-ner-ontonotes, batch 140 (157): mcc: 0.9394, acc: 0.9144, precision: 0.9546, recall: 0.9311, f1: 0.9427, edges-ner-ontonotes_loss: 0.0212
09/16 07:16:31 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:16:32 AM: Best result seen so far for macro.
09/16 07:16:32 AM: Updating LR scheduler:
09/16 07:16:32 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:16:32 AM: 	# validation passes without improvement: 0
09/16 07:16:32 AM: edges-ner-ontonotes_loss: training: 0.027366 validation: 0.020507
09/16 07:16:32 AM: macro_avg: validation: 0.943756
09/16 07:16:32 AM: micro_avg: validation: 0.000000
09/16 07:16:32 AM: edges-ner-ontonotes_mcc: training: 0.917591 validation: 0.940554
09/16 07:16:32 AM: edges-ner-ontonotes_acc: training: 0.879939 validation: 0.915453
09/16 07:16:32 AM: edges-ner-ontonotes_precision: training: 0.940526 validation: 0.954479
09/16 07:16:32 AM: edges-ner-ontonotes_recall: training: 0.903974 validation: 0.933273
09/16 07:16:32 AM: edges-ner-ontonotes_f1: training: 0.921888 validation: 0.943756
09/16 07:16:32 AM: Global learning rate: 5e-05
09/16 07:16:32 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:16:33 AM: Update 28181: task edges-ner-ontonotes, batch 181 (28181): mcc: 0.9110, acc: 0.8715, precision: 0.9351, recall: 0.8970, f1: 0.9157, edges-ner-ontonotes_loss: 0.0292
09/16 07:16:39 AM: Update 24052: task edges-ner-ontonotes, batch 52 (24052): mcc: 0.9448, acc: 0.9160, precision: 0.9549, recall: 0.9409, f1: 0.9478, edges-ner-ontonotes_loss: 0.0180
09/16 07:16:43 AM: Update 28268: task edges-ner-ontonotes, batch 268 (28268): mcc: 0.9132, acc: 0.8749, precision: 0.9371, recall: 0.8992, f1: 0.9177, edges-ner-ontonotes_loss: 0.0286
09/16 07:16:49 AM: Update 24121: task edges-ner-ontonotes, batch 121 (24121): mcc: 0.9470, acc: 0.9193, precision: 0.9579, recall: 0.9420, f1: 0.9499, edges-ner-ontonotes_loss: 0.0174
09/16 07:16:53 AM: Update 28339: task edges-ner-ontonotes, batch 339 (28339): mcc: 0.9145, acc: 0.8761, precision: 0.9389, recall: 0.8997, f1: 0.9189, edges-ner-ontonotes_loss: 0.0279
09/16 07:16:59 AM: Update 24207: task edges-ner-ontonotes, batch 207 (24207): mcc: 0.9452, acc: 0.9169, precision: 0.9572, recall: 0.9393, f1: 0.9481, edges-ner-ontonotes_loss: 0.0178
09/16 07:17:04 AM: Update 28417: task edges-ner-ontonotes, batch 417 (28417): mcc: 0.9170, acc: 0.8795, precision: 0.9404, recall: 0.9030, f1: 0.9213, edges-ner-ontonotes_loss: 0.0273
09/16 07:17:09 AM: Update 24279: task edges-ner-ontonotes, batch 279 (24279): mcc: 0.9444, acc: 0.9158, precision: 0.9570, recall: 0.9381, f1: 0.9474, edges-ner-ontonotes_loss: 0.0180
09/16 07:17:15 AM: Update 28508: task edges-ner-ontonotes, batch 508 (28508): mcc: 0.9193, acc: 0.8826, precision: 0.9415, recall: 0.9062, f1: 0.9235, edges-ner-ontonotes_loss: 0.0266
09/16 07:17:19 AM: Update 24328: task edges-ner-ontonotes, batch 328 (24328): mcc: 0.9432, acc: 0.9134, precision: 0.9566, recall: 0.9361, f1: 0.9462, edges-ner-ontonotes_loss: 0.0182
09/16 07:17:25 AM: Update 28587: task edges-ner-ontonotes, batch 587 (28587): mcc: 0.9212, acc: 0.8853, precision: 0.9428, recall: 0.9085, f1: 0.9254, edges-ner-ontonotes_loss: 0.0259
09/16 07:17:29 AM: Update 24397: task edges-ner-ontonotes, batch 397 (24397): mcc: 0.9438, acc: 0.9142, precision: 0.9571, recall: 0.9367, f1: 0.9468, edges-ner-ontonotes_loss: 0.0181
09/16 07:17:36 AM: Update 28652: task edges-ner-ontonotes, batch 652 (28652): mcc: 0.9226, acc: 0.8872, precision: 0.9437, recall: 0.9102, f1: 0.9266, edges-ner-ontonotes_loss: 0.0255
09/16 07:17:39 AM: Update 24472: task edges-ner-ontonotes, batch 472 (24472): mcc: 0.9431, acc: 0.9132, precision: 0.9566, recall: 0.9359, f1: 0.9462, edges-ner-ontonotes_loss: 0.0183
09/16 07:17:46 AM: Update 28730: task edges-ner-ontonotes, batch 730 (28730): mcc: 0.9256, acc: 0.8908, precision: 0.9457, recall: 0.9138, f1: 0.9295, edges-ner-ontonotes_loss: 0.0246
09/16 07:17:49 AM: Update 24537: task edges-ner-ontonotes, batch 537 (24537): mcc: 0.9428, acc: 0.9127, precision: 0.9564, recall: 0.9356, f1: 0.9459, edges-ner-ontonotes_loss: 0.0184
09/16 07:17:56 AM: Update 28804: task edges-ner-ontonotes, batch 804 (28804): mcc: 0.9275, acc: 0.8933, precision: 0.9468, recall: 0.9164, f1: 0.9313, edges-ner-ontonotes_loss: 0.0240
09/16 07:17:59 AM: Update 24594: task edges-ner-ontonotes, batch 594 (24594): mcc: 0.9421, acc: 0.9117, precision: 0.9561, recall: 0.9345, f1: 0.9452, edges-ner-ontonotes_loss: 0.0186
09/16 07:18:06 AM: Update 28895: task edges-ner-ontonotes, batch 895 (28895): mcc: 0.9297, acc: 0.8963, precision: 0.9483, recall: 0.9189, f1: 0.9334, edges-ner-ontonotes_loss: 0.0232
09/16 07:18:10 AM: Update 24661: task edges-ner-ontonotes, batch 661 (24661): mcc: 0.9383, acc: 0.9068, precision: 0.9534, recall: 0.9302, f1: 0.9417, edges-ner-ontonotes_loss: 0.0202
09/16 07:18:16 AM: Update 28952: task edges-ner-ontonotes, batch 952 (28952): mcc: 0.9305, acc: 0.8973, precision: 0.9488, recall: 0.9200, f1: 0.9342, edges-ner-ontonotes_loss: 0.0230
09/16 07:18:20 AM: Update 24741: task edges-ner-ontonotes, batch 741 (24741): mcc: 0.9345, acc: 0.9018, precision: 0.9509, recall: 0.9254, f1: 0.9380, edges-ner-ontonotes_loss: 0.0219
09/16 07:18:21 AM: ***** Step 29000 / Validation 29 *****
09/16 07:18:21 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:18:21 AM: Validating...
09/16 07:18:26 AM: Evaluate: task edges-ner-ontonotes, batch 32 (157): mcc: 0.8977, acc: 0.8641, precision: 0.9230, recall: 0.8839, f1: 0.9030, edges-ner-ontonotes_loss: 0.0339
09/16 07:18:30 AM: Update 24796: task edges-ner-ontonotes, batch 796 (24796): mcc: 0.9331, acc: 0.9003, precision: 0.9501, recall: 0.9236, f1: 0.9367, edges-ner-ontonotes_loss: 0.0226
09/16 07:18:36 AM: Evaluate: task edges-ner-ontonotes, batch 92 (157): mcc: 0.9272, acc: 0.8968, precision: 0.9484, recall: 0.9143, f1: 0.9310, edges-ner-ontonotes_loss: 0.0257
09/16 07:18:40 AM: Update 24847: task edges-ner-ontonotes, batch 847 (24847): mcc: 0.9317, acc: 0.8985, precision: 0.9494, recall: 0.9217, f1: 0.9353, edges-ner-ontonotes_loss: 0.0231
09/16 07:18:46 AM: Evaluate: task edges-ner-ontonotes, batch 145 (157): mcc: 0.9379, acc: 0.9121, precision: 0.9537, recall: 0.9290, f1: 0.9412, edges-ner-ontonotes_loss: 0.0216
09/16 07:18:48 AM: Updating LR scheduler:
09/16 07:18:48 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:18:48 AM: 	# validation passes without improvement: 3
09/16 07:18:48 AM: edges-ner-ontonotes_loss: training: 0.022734 validation: 0.021033
09/16 07:18:48 AM: macro_avg: validation: 0.942549
09/16 07:18:48 AM: micro_avg: validation: 0.000000
09/16 07:18:48 AM: edges-ner-ontonotes_mcc: training: 0.931097 validation: 0.939292
09/16 07:18:48 AM: edges-ner-ontonotes_acc: training: 0.898069 validation: 0.913634
09/16 07:18:48 AM: edges-ner-ontonotes_precision: training: 0.949354 validation: 0.954231
09/16 07:18:48 AM: edges-ner-ontonotes_recall: training: 0.920587 validation: 0.931150
09/16 07:18:48 AM: edges-ner-ontonotes_f1: training: 0.934749 validation: 0.942549
09/16 07:18:48 AM: Global learning rate: 5e-05
09/16 07:18:48 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:18:52 AM: Update 24897: task edges-ner-ontonotes, batch 897 (24897): mcc: 0.9302, acc: 0.8965, precision: 0.9483, recall: 0.9199, f1: 0.9339, edges-ner-ontonotes_loss: 0.0237
09/16 07:18:56 AM: Update 29074: task edges-ner-ontonotes, batch 74 (29074): mcc: 0.9383, acc: 0.9054, precision: 0.9527, recall: 0.9308, f1: 0.9416, edges-ner-ontonotes_loss: 0.0202
09/16 07:19:02 AM: Update 24972: task edges-ner-ontonotes, batch 972 (24972): mcc: 0.9291, acc: 0.8950, precision: 0.9475, recall: 0.9186, f1: 0.9328, edges-ner-ontonotes_loss: 0.0242
09/16 07:19:06 AM: ***** Step 25000 / Validation 25 *****
09/16 07:19:06 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:19:06 AM: Validating...
09/16 07:19:06 AM: Update 29162: task edges-ner-ontonotes, batch 162 (29162): mcc: 0.9397, acc: 0.9074, precision: 0.9547, recall: 0.9315, f1: 0.9429, edges-ner-ontonotes_loss: 0.0189
09/16 07:19:12 AM: Evaluate: task edges-ner-ontonotes, batch 40 (157): mcc: 0.9112, acc: 0.8808, precision: 0.9326, recall: 0.8998, f1: 0.9159, edges-ner-ontonotes_loss: 0.0295
09/16 07:19:17 AM: Update 29220: task edges-ner-ontonotes, batch 220 (29220): mcc: 0.9410, acc: 0.9099, precision: 0.9566, recall: 0.9321, f1: 0.9441, edges-ner-ontonotes_loss: 0.0188
09/16 07:19:22 AM: Evaluate: task edges-ner-ontonotes, batch 94 (157): mcc: 0.9316, acc: 0.9025, precision: 0.9536, recall: 0.9173, f1: 0.9351, edges-ner-ontonotes_loss: 0.0238
09/16 07:19:27 AM: Update 29267: task edges-ner-ontonotes, batch 267 (29267): mcc: 0.9397, acc: 0.9083, precision: 0.9554, recall: 0.9307, f1: 0.9429, edges-ner-ontonotes_loss: 0.0192
09/16 07:19:32 AM: Evaluate: task edges-ner-ontonotes, batch 142 (157): mcc: 0.9394, acc: 0.9136, precision: 0.9579, recall: 0.9278, f1: 0.9426, edges-ner-ontonotes_loss: 0.0209
09/16 07:19:35 AM: Updating LR scheduler:
09/16 07:19:35 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:19:35 AM: 	# validation passes without improvement: 1
09/16 07:19:35 AM: edges-ner-ontonotes_loss: training: 0.024210 validation: 0.020466
09/16 07:19:35 AM: macro_avg: validation: 0.943237
09/16 07:19:35 AM: micro_avg: validation: 0.000000
09/16 07:19:35 AM: edges-ner-ontonotes_mcc: training: 0.928829 validation: 0.940070
09/16 07:19:35 AM: edges-ner-ontonotes_acc: training: 0.894662 validation: 0.914392
09/16 07:19:35 AM: edges-ner-ontonotes_precision: training: 0.947383 validation: 0.957646
09/16 07:19:35 AM: edges-ner-ontonotes_recall: training: 0.918276 validation: 0.929254
09/16 07:19:35 AM: edges-ner-ontonotes_f1: training: 0.932602 validation: 0.943237
09/16 07:19:35 AM: Global learning rate: 5e-05
09/16 07:19:35 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:19:37 AM: Update 29334: task edges-ner-ontonotes, batch 334 (29334): mcc: 0.9329, acc: 0.8994, precision: 0.9512, recall: 0.9222, f1: 0.9365, edges-ner-ontonotes_loss: 0.0219
09/16 07:19:42 AM: Update 25054: task edges-ner-ontonotes, batch 54 (25054): mcc: 0.9142, acc: 0.8757, precision: 0.9369, recall: 0.9011, f1: 0.9186, edges-ner-ontonotes_loss: 0.0272
09/16 07:19:47 AM: Update 29424: task edges-ner-ontonotes, batch 424 (29424): mcc: 0.9273, acc: 0.8922, precision: 0.9474, recall: 0.9154, f1: 0.9311, edges-ner-ontonotes_loss: 0.0243
09/16 07:19:52 AM: Update 25134: task edges-ner-ontonotes, batch 134 (25134): mcc: 0.9161, acc: 0.8764, precision: 0.9410, recall: 0.9008, f1: 0.9205, edges-ner-ontonotes_loss: 0.0273
09/16 07:19:57 AM: Update 29507: task edges-ner-ontonotes, batch 507 (29507): mcc: 0.9240, acc: 0.8878, precision: 0.9452, recall: 0.9114, f1: 0.9280, edges-ner-ontonotes_loss: 0.0255
09/16 07:20:05 AM: Update 25210: task edges-ner-ontonotes, batch 210 (25210): mcc: 0.9154, acc: 0.8771, precision: 0.9393, recall: 0.9010, f1: 0.9198, edges-ner-ontonotes_loss: 0.0275
09/16 07:20:07 AM: Update 29587: task edges-ner-ontonotes, batch 587 (29587): mcc: 0.9217, acc: 0.8852, precision: 0.9436, recall: 0.9087, f1: 0.9258, edges-ner-ontonotes_loss: 0.0265
09/16 07:20:15 AM: Update 25292: task edges-ner-ontonotes, batch 292 (25292): mcc: 0.9185, acc: 0.8808, precision: 0.9415, recall: 0.9047, f1: 0.9227, edges-ner-ontonotes_loss: 0.0265
09/16 07:20:19 AM: Update 29678: task edges-ner-ontonotes, batch 678 (29678): mcc: 0.9209, acc: 0.8843, precision: 0.9427, recall: 0.9080, f1: 0.9250, edges-ner-ontonotes_loss: 0.0268
09/16 07:20:25 AM: Update 25374: task edges-ner-ontonotes, batch 374 (25374): mcc: 0.9206, acc: 0.8839, precision: 0.9427, recall: 0.9074, f1: 0.9247, edges-ner-ontonotes_loss: 0.0257
09/16 07:20:30 AM: Update 29780: task edges-ner-ontonotes, batch 780 (29780): mcc: 0.9199, acc: 0.8829, precision: 0.9421, recall: 0.9068, f1: 0.9241, edges-ner-ontonotes_loss: 0.0269
09/16 07:20:37 AM: Update 25458: task edges-ner-ontonotes, batch 458 (25458): mcc: 0.9229, acc: 0.8870, precision: 0.9440, recall: 0.9105, f1: 0.9269, edges-ner-ontonotes_loss: 0.0250
09/16 07:20:42 AM: Update 29869: task edges-ner-ontonotes, batch 869 (29869): mcc: 0.9198, acc: 0.8826, precision: 0.9421, recall: 0.9065, f1: 0.9240, edges-ner-ontonotes_loss: 0.0269
09/16 07:20:47 AM: Update 25523: task edges-ner-ontonotes, batch 523 (25523): mcc: 0.9228, acc: 0.8872, precision: 0.9437, recall: 0.9107, f1: 0.9269, edges-ner-ontonotes_loss: 0.0249
09/16 07:20:53 AM: Update 29937: task edges-ner-ontonotes, batch 937 (29937): mcc: 0.9198, acc: 0.8828, precision: 0.9421, recall: 0.9066, f1: 0.9240, edges-ner-ontonotes_loss: 0.0267
09/16 07:20:58 AM: Update 25594: task edges-ner-ontonotes, batch 594 (25594): mcc: 0.9251, acc: 0.8903, precision: 0.9451, recall: 0.9136, f1: 0.9291, edges-ner-ontonotes_loss: 0.0243
09/16 07:21:02 AM: ***** Step 30000 / Validation 30 *****
09/16 07:21:02 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:21:02 AM: Validating...
09/16 07:21:04 AM: Evaluate: task edges-ner-ontonotes, batch 17 (157): mcc: 0.8836, acc: 0.8436, precision: 0.9148, recall: 0.8656, f1: 0.8895, edges-ner-ontonotes_loss: 0.0322
09/16 07:21:08 AM: Update 25657: task edges-ner-ontonotes, batch 657 (25657): mcc: 0.9274, acc: 0.8933, precision: 0.9468, recall: 0.9162, f1: 0.9313, edges-ner-ontonotes_loss: 0.0236
09/16 07:21:14 AM: Evaluate: task edges-ner-ontonotes, batch 79 (157): mcc: 0.9282, acc: 0.9005, precision: 0.9492, recall: 0.9154, f1: 0.9320, edges-ner-ontonotes_loss: 0.0250
09/16 07:21:18 AM: Update 25708: task edges-ner-ontonotes, batch 708 (25708): mcc: 0.9285, acc: 0.8946, precision: 0.9475, recall: 0.9175, f1: 0.9322, edges-ner-ontonotes_loss: 0.0232
09/16 07:21:24 AM: Evaluate: task edges-ner-ontonotes, batch 132 (157): mcc: 0.9378, acc: 0.9115, precision: 0.9562, recall: 0.9264, f1: 0.9411, edges-ner-ontonotes_loss: 0.0215
09/16 07:21:28 AM: Update 25760: task edges-ner-ontonotes, batch 760 (25760): mcc: 0.9297, acc: 0.8962, precision: 0.9483, recall: 0.9190, f1: 0.9334, edges-ner-ontonotes_loss: 0.0229
09/16 07:21:29 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:21:29 AM: Best result seen so far for macro.
09/16 07:21:29 AM: Updating LR scheduler:
09/16 07:21:29 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:21:29 AM: 	# validation passes without improvement: 0
09/16 07:21:29 AM: edges-ner-ontonotes_loss: training: 0.026469 validation: 0.020278
09/16 07:21:29 AM: macro_avg: validation: 0.944107
09/16 07:21:29 AM: micro_avg: validation: 0.000000
09/16 07:21:29 AM: edges-ner-ontonotes_mcc: training: 0.920155 validation: 0.940970
09/16 07:21:29 AM: edges-ner-ontonotes_acc: training: 0.883210 validation: 0.915833
09/16 07:21:29 AM: edges-ner-ontonotes_precision: training: 0.942243 validation: 0.957430
09/16 07:21:29 AM: edges-ner-ontonotes_recall: training: 0.907086 validation: 0.931150
09/16 07:21:29 AM: edges-ner-ontonotes_f1: training: 0.924330 validation: 0.944107
09/16 07:21:29 AM: Global learning rate: 5e-05
09/16 07:21:29 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:21:34 AM: Update 30045: task edges-ner-ontonotes, batch 45 (30045): mcc: 0.9309, acc: 0.8980, precision: 0.9526, recall: 0.9171, f1: 0.9345, edges-ner-ontonotes_loss: 0.0237
09/16 07:21:38 AM: Update 25826: task edges-ner-ontonotes, batch 826 (25826): mcc: 0.9311, acc: 0.8979, precision: 0.9491, recall: 0.9208, f1: 0.9347, edges-ner-ontonotes_loss: 0.0223
09/16 07:21:45 AM: Update 30138: task edges-ner-ontonotes, batch 138 (30138): mcc: 0.9273, acc: 0.8941, precision: 0.9476, recall: 0.9152, f1: 0.9311, edges-ner-ontonotes_loss: 0.0239
09/16 07:21:48 AM: Update 25880: task edges-ner-ontonotes, batch 880 (25880): mcc: 0.9318, acc: 0.8988, precision: 0.9497, recall: 0.9216, f1: 0.9354, edges-ner-ontonotes_loss: 0.0221
09/16 07:21:55 AM: Update 30200: task edges-ner-ontonotes, batch 200 (30200): mcc: 0.9284, acc: 0.8944, precision: 0.9488, recall: 0.9162, f1: 0.9322, edges-ner-ontonotes_loss: 0.0230
09/16 07:21:58 AM: Update 25960: task edges-ner-ontonotes, batch 960 (25960): mcc: 0.9321, acc: 0.8990, precision: 0.9496, recall: 0.9222, f1: 0.9357, edges-ner-ontonotes_loss: 0.0219
09/16 07:22:04 AM: ***** Step 26000 / Validation 26 *****
09/16 07:22:04 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:22:04 AM: Validating...
09/16 07:22:07 AM: Update 30279: task edges-ner-ontonotes, batch 279 (30279): mcc: 0.9321, acc: 0.8988, precision: 0.9501, recall: 0.9217, f1: 0.9357, edges-ner-ontonotes_loss: 0.0216
09/16 07:22:08 AM: Evaluate: task edges-ner-ontonotes, batch 32 (157): mcc: 0.9014, acc: 0.8694, precision: 0.9257, recall: 0.8882, f1: 0.9065, edges-ner-ontonotes_loss: 0.0335
09/16 07:22:18 AM: Update 30344: task edges-ner-ontonotes, batch 344 (30344): mcc: 0.9339, acc: 0.9014, precision: 0.9514, recall: 0.9239, f1: 0.9375, edges-ner-ontonotes_loss: 0.0211
09/16 07:22:19 AM: Evaluate: task edges-ner-ontonotes, batch 82 (157): mcc: 0.9286, acc: 0.8994, precision: 0.9491, recall: 0.9162, f1: 0.9324, edges-ner-ontonotes_loss: 0.0259
09/16 07:22:28 AM: Update 30402: task edges-ner-ontonotes, batch 402 (30402): mcc: 0.9363, acc: 0.9043, precision: 0.9528, recall: 0.9270, f1: 0.9397, edges-ner-ontonotes_loss: 0.0204
09/16 07:22:29 AM: Evaluate: task edges-ner-ontonotes, batch 130 (157): mcc: 0.9367, acc: 0.9107, precision: 0.9534, recall: 0.9272, f1: 0.9401, edges-ner-ontonotes_loss: 0.0225
09/16 07:22:34 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:22:34 AM: Best result seen so far for macro.
09/16 07:22:34 AM: Updating LR scheduler:
09/16 07:22:34 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:22:34 AM: 	# validation passes without improvement: 0
09/16 07:22:34 AM: edges-ner-ontonotes_loss: training: 0.021836 validation: 0.020859
09/16 07:22:34 AM: macro_avg: validation: 0.943929
09/16 07:22:34 AM: micro_avg: validation: 0.000000
09/16 07:22:34 AM: edges-ner-ontonotes_mcc: training: 0.932583 validation: 0.940742
09/16 07:22:34 AM: edges-ner-ontonotes_acc: training: 0.899708 validation: 0.915908
09/16 07:22:34 AM: edges-ner-ontonotes_precision: training: 0.949975 validation: 0.954990
09/16 07:22:34 AM: edges-ner-ontonotes_recall: training: 0.922759 validation: 0.933121
09/16 07:22:34 AM: edges-ner-ontonotes_f1: training: 0.936169 validation: 0.943929
09/16 07:22:34 AM: Global learning rate: 5e-05
09/16 07:22:34 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:22:38 AM: Update 30472: task edges-ner-ontonotes, batch 472 (30472): mcc: 0.9376, acc: 0.9061, precision: 0.9539, recall: 0.9284, f1: 0.9410, edges-ner-ontonotes_loss: 0.0201
09/16 07:22:39 AM: Update 26030: task edges-ner-ontonotes, batch 30 (26030): mcc: 0.9423, acc: 0.9112, precision: 0.9596, recall: 0.9315, f1: 0.9453, edges-ner-ontonotes_loss: 0.0173
09/16 07:22:48 AM: Update 30539: task edges-ner-ontonotes, batch 539 (30539): mcc: 0.9380, acc: 0.9066, precision: 0.9542, recall: 0.9288, f1: 0.9413, edges-ner-ontonotes_loss: 0.0199
09/16 07:22:49 AM: Update 26103: task edges-ner-ontonotes, batch 103 (26103): mcc: 0.9428, acc: 0.9130, precision: 0.9578, recall: 0.9342, f1: 0.9458, edges-ner-ontonotes_loss: 0.0183
09/16 07:22:58 AM: Update 30631: task edges-ner-ontonotes, batch 631 (30631): mcc: 0.9383, acc: 0.9071, precision: 0.9543, recall: 0.9292, f1: 0.9416, edges-ner-ontonotes_loss: 0.0198
09/16 07:22:59 AM: Update 26151: task edges-ner-ontonotes, batch 151 (26151): mcc: 0.9424, acc: 0.9121, precision: 0.9579, recall: 0.9334, f1: 0.9455, edges-ner-ontonotes_loss: 0.0182
09/16 07:23:08 AM: Update 30707: task edges-ner-ontonotes, batch 707 (30707): mcc: 0.9388, acc: 0.9079, precision: 0.9544, recall: 0.9301, f1: 0.9421, edges-ner-ontonotes_loss: 0.0196
09/16 07:23:09 AM: Update 26218: task edges-ner-ontonotes, batch 218 (26218): mcc: 0.9319, acc: 0.8980, precision: 0.9521, recall: 0.9194, f1: 0.9354, edges-ner-ontonotes_loss: 0.0232
09/16 07:23:19 AM: Update 30784: task edges-ner-ontonotes, batch 784 (30784): mcc: 0.9389, acc: 0.9078, precision: 0.9546, recall: 0.9301, f1: 0.9422, edges-ner-ontonotes_loss: 0.0197
09/16 07:23:19 AM: Update 26290: task edges-ner-ontonotes, batch 290 (26290): mcc: 0.9259, acc: 0.8908, precision: 0.9478, recall: 0.9124, f1: 0.9298, edges-ner-ontonotes_loss: 0.0256
09/16 07:23:29 AM: Update 30847: task edges-ner-ontonotes, batch 847 (30847): mcc: 0.9373, acc: 0.9057, precision: 0.9537, recall: 0.9279, f1: 0.9406, edges-ner-ontonotes_loss: 0.0202
09/16 07:23:29 AM: Update 26360: task edges-ner-ontonotes, batch 360 (26360): mcc: 0.9217, acc: 0.8850, precision: 0.9452, recall: 0.9070, f1: 0.9257, edges-ner-ontonotes_loss: 0.0268
09/16 07:23:39 AM: Update 30934: task edges-ner-ontonotes, batch 934 (30934): mcc: 0.9345, acc: 0.9022, precision: 0.9518, recall: 0.9245, f1: 0.9380, edges-ner-ontonotes_loss: 0.0215
09/16 07:23:39 AM: Update 26430: task edges-ner-ontonotes, batch 430 (26430): mcc: 0.9198, acc: 0.8828, precision: 0.9438, recall: 0.9050, f1: 0.9240, edges-ner-ontonotes_loss: 0.0277
09/16 07:23:46 AM: ***** Step 31000 / Validation 31 *****
09/16 07:23:46 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:23:46 AM: Validating...
09/16 07:23:49 AM: Evaluate: task edges-ner-ontonotes, batch 27 (157): mcc: 0.8852, acc: 0.8511, precision: 0.9125, recall: 0.8709, f1: 0.8912, edges-ner-ontonotes_loss: 0.0361
09/16 07:23:49 AM: Update 26487: task edges-ner-ontonotes, batch 487 (26487): mcc: 0.9182, acc: 0.8805, precision: 0.9423, recall: 0.9034, f1: 0.9225, edges-ner-ontonotes_loss: 0.0282
09/16 07:23:59 AM: Evaluate: task edges-ner-ontonotes, batch 91 (157): mcc: 0.9289, acc: 0.8991, precision: 0.9510, recall: 0.9149, f1: 0.9326, edges-ner-ontonotes_loss: 0.0249
09/16 07:23:59 AM: Update 26545: task edges-ner-ontonotes, batch 545 (26545): mcc: 0.9175, acc: 0.8795, precision: 0.9415, recall: 0.9028, f1: 0.9217, edges-ner-ontonotes_loss: 0.0282
09/16 07:24:09 AM: Evaluate: task edges-ner-ontonotes, batch 145 (157): mcc: 0.9390, acc: 0.9134, precision: 0.9569, recall: 0.9281, f1: 0.9422, edges-ner-ontonotes_loss: 0.0214
09/16 07:24:09 AM: Update 26601: task edges-ner-ontonotes, batch 601 (26601): mcc: 0.9172, acc: 0.8792, precision: 0.9412, recall: 0.9026, f1: 0.9215, edges-ner-ontonotes_loss: 0.0282
09/16 07:24:11 AM: Updating LR scheduler:
09/16 07:24:12 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:24:12 AM: 	# validation passes without improvement: 1
09/16 07:24:12 AM: edges-ner-ontonotes_loss: training: 0.022137 validation: 0.020813
09/16 07:24:12 AM: macro_avg: validation: 0.942837
09/16 07:24:12 AM: micro_avg: validation: 0.000000
09/16 07:24:12 AM: edges-ner-ontonotes_mcc: training: 0.933097 validation: 0.939639
09/16 07:24:12 AM: edges-ner-ontonotes_acc: training: 0.900472 validation: 0.914013
09/16 07:24:12 AM: edges-ner-ontonotes_precision: training: 0.950993 validation: 0.956824
09/16 07:24:12 AM: edges-ner-ontonotes_recall: training: 0.922724 validation: 0.929254
09/16 07:24:12 AM: edges-ner-ontonotes_f1: training: 0.936645 validation: 0.942837
09/16 07:24:12 AM: Global learning rate: 5e-05
09/16 07:24:12 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:24:19 AM: Update 31070: task edges-ner-ontonotes, batch 70 (31070): mcc: 0.9049, acc: 0.8633, precision: 0.9311, recall: 0.8896, f1: 0.9098, edges-ner-ontonotes_loss: 0.0340
09/16 07:24:19 AM: Update 26679: task edges-ner-ontonotes, batch 679 (26679): mcc: 0.9169, acc: 0.8788, precision: 0.9412, recall: 0.9021, f1: 0.9212, edges-ner-ontonotes_loss: 0.0281
09/16 07:24:29 AM: Update 31141: task edges-ner-ontonotes, batch 141 (31141): mcc: 0.9072, acc: 0.8673, precision: 0.9326, recall: 0.8922, f1: 0.9120, edges-ner-ontonotes_loss: 0.0326
09/16 07:24:32 AM: Update 26766: task edges-ner-ontonotes, batch 766 (26766): mcc: 0.9171, acc: 0.8789, precision: 0.9411, recall: 0.9024, f1: 0.9214, edges-ner-ontonotes_loss: 0.0279
09/16 07:24:39 AM: Update 31245: task edges-ner-ontonotes, batch 245 (31245): mcc: 0.9075, acc: 0.8681, precision: 0.9327, recall: 0.8928, f1: 0.9123, edges-ner-ontonotes_loss: 0.0311
09/16 07:24:42 AM: Update 26840: task edges-ner-ontonotes, batch 840 (26840): mcc: 0.9178, acc: 0.8798, precision: 0.9416, recall: 0.9034, f1: 0.9221, edges-ner-ontonotes_loss: 0.0275
09/16 07:24:49 AM: Update 31336: task edges-ner-ontonotes, batch 336 (31336): mcc: 0.9104, acc: 0.8713, precision: 0.9347, recall: 0.8961, f1: 0.9150, edges-ner-ontonotes_loss: 0.0297
09/16 07:24:52 AM: Update 26915: task edges-ner-ontonotes, batch 915 (26915): mcc: 0.9186, acc: 0.8810, precision: 0.9420, recall: 0.9044, f1: 0.9228, edges-ner-ontonotes_loss: 0.0271
09/16 07:24:59 AM: Update 31431: task edges-ner-ontonotes, batch 431 (31431): mcc: 0.9117, acc: 0.8726, precision: 0.9356, recall: 0.8978, f1: 0.9163, edges-ner-ontonotes_loss: 0.0291
09/16 07:25:03 AM: Update 26994: task edges-ner-ontonotes, batch 994 (26994): mcc: 0.9196, acc: 0.8824, precision: 0.9425, recall: 0.9058, f1: 0.9238, edges-ner-ontonotes_loss: 0.0268
09/16 07:25:03 AM: ***** Step 27000 / Validation 27 *****
09/16 07:25:03 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:25:03 AM: Validating...
09/16 07:25:10 AM: Update 31485: task edges-ner-ontonotes, batch 485 (31485): mcc: 0.9139, acc: 0.8750, precision: 0.9374, recall: 0.9001, f1: 0.9184, edges-ner-ontonotes_loss: 0.0284
09/16 07:25:13 AM: Evaluate: task edges-ner-ontonotes, batch 55 (157): mcc: 0.9220, acc: 0.8934, precision: 0.9420, recall: 0.9108, f1: 0.9261, edges-ner-ontonotes_loss: 0.0260
09/16 07:25:20 AM: Update 31548: task edges-ner-ontonotes, batch 548 (31548): mcc: 0.9154, acc: 0.8770, precision: 0.9381, recall: 0.9022, f1: 0.9198, edges-ner-ontonotes_loss: 0.0278
09/16 07:25:23 AM: Evaluate: task edges-ner-ontonotes, batch 107 (157): mcc: 0.9301, acc: 0.9021, precision: 0.9505, recall: 0.9176, f1: 0.9338, edges-ner-ontonotes_loss: 0.0235
09/16 07:25:30 AM: Update 31609: task edges-ner-ontonotes, batch 609 (31609): mcc: 0.9168, acc: 0.8788, precision: 0.9392, recall: 0.9039, f1: 0.9212, edges-ner-ontonotes_loss: 0.0273
09/16 07:25:33 AM: Updating LR scheduler:
09/16 07:25:33 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:25:33 AM: 	# validation passes without improvement: 1
09/16 07:25:33 AM: edges-ner-ontonotes_loss: training: 0.026710 validation: 0.020300
09/16 07:25:33 AM: macro_avg: validation: 0.943750
09/16 07:25:33 AM: micro_avg: validation: 0.000000
09/16 07:25:33 AM: edges-ner-ontonotes_mcc: training: 0.919691 validation: 0.940596
09/16 07:25:33 AM: edges-ner-ontonotes_acc: training: 0.882593 validation: 0.915150
09/16 07:25:33 AM: edges-ner-ontonotes_precision: training: 0.942547 validation: 0.957258
09/16 07:25:33 AM: edges-ner-ontonotes_recall: training: 0.905924 validation: 0.930619
09/16 07:25:33 AM: edges-ner-ontonotes_f1: training: 0.923873 validation: 0.943750
09/16 07:25:33 AM: Global learning rate: 5e-05
09/16 07:25:33 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:25:33 AM: Update 27001: task edges-ner-ontonotes, batch 1 (27001): mcc: 0.9456, acc: 0.9205, precision: 0.9540, recall: 0.9432, f1: 0.9486, edges-ner-ontonotes_loss: 0.0185
09/16 07:25:41 AM: Update 31688: task edges-ner-ontonotes, batch 688 (31688): mcc: 0.9187, acc: 0.8815, precision: 0.9405, recall: 0.9062, f1: 0.9230, edges-ner-ontonotes_loss: 0.0266
09/16 07:25:43 AM: Update 27068: task edges-ner-ontonotes, batch 68 (27068): mcc: 0.9244, acc: 0.8891, precision: 0.9443, recall: 0.9129, f1: 0.9284, edges-ner-ontonotes_loss: 0.0247
09/16 07:25:51 AM: Update 31763: task edges-ner-ontonotes, batch 763 (31763): mcc: 0.9197, acc: 0.8827, precision: 0.9412, recall: 0.9073, f1: 0.9240, edges-ner-ontonotes_loss: 0.0263
09/16 07:25:53 AM: Update 27122: task edges-ner-ontonotes, batch 122 (27122): mcc: 0.9316, acc: 0.8979, precision: 0.9497, recall: 0.9211, f1: 0.9352, edges-ner-ontonotes_loss: 0.0222
09/16 07:26:01 AM: Update 31836: task edges-ner-ontonotes, batch 836 (31836): mcc: 0.9223, acc: 0.8858, precision: 0.9430, recall: 0.9102, f1: 0.9264, edges-ner-ontonotes_loss: 0.0255
09/16 07:26:03 AM: Update 27191: task edges-ner-ontonotes, batch 191 (27191): mcc: 0.9371, acc: 0.9053, precision: 0.9532, recall: 0.9279, f1: 0.9404, edges-ner-ontonotes_loss: 0.0206
09/16 07:26:11 AM: Update 31923: task edges-ner-ontonotes, batch 923 (31923): mcc: 0.9250, acc: 0.8895, precision: 0.9450, recall: 0.9135, f1: 0.9290, edges-ner-ontonotes_loss: 0.0248
09/16 07:26:14 AM: Update 27258: task edges-ner-ontonotes, batch 258 (27258): mcc: 0.9392, acc: 0.9088, precision: 0.9545, recall: 0.9307, f1: 0.9425, edges-ner-ontonotes_loss: 0.0198
09/16 07:26:20 AM: ***** Step 32000 / Validation 32 *****
09/16 07:26:20 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:26:20 AM: Validating...
09/16 07:26:21 AM: Evaluate: task edges-ner-ontonotes, batch 6 (157): mcc: 0.8349, acc: 0.7775, precision: 0.8867, recall: 0.8025, f1: 0.8425, edges-ner-ontonotes_loss: 0.0471
09/16 07:26:26 AM: Update 27317: task edges-ner-ontonotes, batch 317 (27317): mcc: 0.9401, acc: 0.9096, precision: 0.9556, recall: 0.9312, f1: 0.9433, edges-ner-ontonotes_loss: 0.0194
09/16 07:26:31 AM: Evaluate: task edges-ner-ontonotes, batch 72 (157): mcc: 0.9230, acc: 0.8931, precision: 0.9471, recall: 0.9076, f1: 0.9269, edges-ner-ontonotes_loss: 0.0273
09/16 07:26:37 AM: Update 27372: task edges-ner-ontonotes, batch 372 (27372): mcc: 0.9414, acc: 0.9114, precision: 0.9570, recall: 0.9324, f1: 0.9445, edges-ner-ontonotes_loss: 0.0189
09/16 07:26:41 AM: Evaluate: task edges-ner-ontonotes, batch 128 (157): mcc: 0.9362, acc: 0.9102, precision: 0.9553, recall: 0.9243, f1: 0.9395, edges-ner-ontonotes_loss: 0.0226
09/16 07:26:45 AM: Updating LR scheduler:
09/16 07:26:45 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:26:45 AM: 	# validation passes without improvement: 2
09/16 07:26:45 AM: edges-ner-ontonotes_loss: training: 0.024166 validation: 0.020732
09/16 07:26:45 AM: macro_avg: validation: 0.943637
09/16 07:26:45 AM: micro_avg: validation: 0.000000
09/16 07:26:45 AM: edges-ner-ontonotes_mcc: training: 0.926936 validation: 0.940475
09/16 07:26:45 AM: edges-ner-ontonotes_acc: training: 0.891898 validation: 0.915833
09/16 07:26:45 AM: edges-ner-ontonotes_precision: training: 0.946409 validation: 0.957105
09/16 07:26:45 AM: edges-ner-ontonotes_recall: training: 0.915687 validation: 0.930543
09/16 07:26:45 AM: edges-ner-ontonotes_f1: training: 0.930795 validation: 0.943637
09/16 07:26:45 AM: Global learning rate: 5e-05
09/16 07:26:45 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:26:48 AM: Update 27412: task edges-ner-ontonotes, batch 412 (27412): mcc: 0.9417, acc: 0.9116, precision: 0.9570, recall: 0.9330, f1: 0.9448, edges-ner-ontonotes_loss: 0.0189
09/16 07:26:51 AM: Update 32051: task edges-ner-ontonotes, batch 51 (32051): mcc: 0.9448, acc: 0.9181, precision: 0.9600, recall: 0.9358, f1: 0.9478, edges-ner-ontonotes_loss: 0.0172
09/16 07:26:59 AM: Update 27490: task edges-ner-ontonotes, batch 490 (27490): mcc: 0.9424, acc: 0.9122, precision: 0.9578, recall: 0.9335, f1: 0.9455, edges-ner-ontonotes_loss: 0.0187
09/16 07:27:01 AM: Update 32118: task edges-ner-ontonotes, batch 118 (32118): mcc: 0.9397, acc: 0.9109, precision: 0.9557, recall: 0.9305, f1: 0.9429, edges-ner-ontonotes_loss: 0.0189
09/16 07:27:11 AM: Update 27557: task edges-ner-ontonotes, batch 557 (27557): mcc: 0.9426, acc: 0.9122, precision: 0.9577, recall: 0.9339, f1: 0.9457, edges-ner-ontonotes_loss: 0.0186
09/16 07:27:11 AM: Update 32192: task edges-ner-ontonotes, batch 192 (32192): mcc: 0.9411, acc: 0.9124, precision: 0.9570, recall: 0.9318, f1: 0.9442, edges-ner-ontonotes_loss: 0.0185
09/16 07:27:21 AM: Update 27623: task edges-ner-ontonotes, batch 623 (27623): mcc: 0.9421, acc: 0.9116, precision: 0.9573, recall: 0.9333, f1: 0.9452, edges-ner-ontonotes_loss: 0.0187
09/16 07:27:22 AM: Update 32273: task edges-ner-ontonotes, batch 273 (32273): mcc: 0.9421, acc: 0.9131, precision: 0.9572, recall: 0.9334, f1: 0.9452, edges-ner-ontonotes_loss: 0.0185
09/16 07:27:31 AM: Update 27691: task edges-ner-ontonotes, batch 691 (27691): mcc: 0.9416, acc: 0.9110, precision: 0.9568, recall: 0.9330, f1: 0.9448, edges-ner-ontonotes_loss: 0.0189
09/16 07:27:32 AM: Update 32354: task edges-ner-ontonotes, batch 354 (32354): mcc: 0.9421, acc: 0.9129, precision: 0.9565, recall: 0.9342, f1: 0.9452, edges-ner-ontonotes_loss: 0.0184
09/16 07:27:41 AM: Update 27739: task edges-ner-ontonotes, batch 739 (27739): mcc: 0.9403, acc: 0.9092, precision: 0.9560, recall: 0.9313, f1: 0.9435, edges-ner-ontonotes_loss: 0.0193
09/16 07:27:42 AM: Update 32427: task edges-ner-ontonotes, batch 427 (32427): mcc: 0.9368, acc: 0.9053, precision: 0.9535, recall: 0.9271, f1: 0.9401, edges-ner-ontonotes_loss: 0.0205
09/16 07:27:51 AM: Update 27804: task edges-ner-ontonotes, batch 804 (27804): mcc: 0.9375, acc: 0.9055, precision: 0.9541, recall: 0.9279, f1: 0.9408, edges-ner-ontonotes_loss: 0.0204
09/16 07:27:52 AM: Update 32503: task edges-ner-ontonotes, batch 503 (32503): mcc: 0.9323, acc: 0.8995, precision: 0.9504, recall: 0.9219, f1: 0.9359, edges-ner-ontonotes_loss: 0.0223
09/16 07:28:01 AM: Update 27876: task edges-ner-ontonotes, batch 876 (27876): mcc: 0.9348, acc: 0.9019, precision: 0.9523, recall: 0.9246, f1: 0.9382, edges-ner-ontonotes_loss: 0.0217
09/16 07:28:02 AM: Update 32590: task edges-ner-ontonotes, batch 590 (32590): mcc: 0.9291, acc: 0.8953, precision: 0.9483, recall: 0.9179, f1: 0.9329, edges-ner-ontonotes_loss: 0.0239
09/16 07:28:11 AM: Update 27949: task edges-ner-ontonotes, batch 949 (27949): mcc: 0.9323, acc: 0.8990, precision: 0.9505, recall: 0.9217, f1: 0.9359, edges-ner-ontonotes_loss: 0.0227
09/16 07:28:12 AM: Update 32674: task edges-ner-ontonotes, batch 674 (32674): mcc: 0.9268, acc: 0.8923, precision: 0.9467, recall: 0.9151, f1: 0.9306, edges-ner-ontonotes_loss: 0.0249
09/16 07:28:18 AM: ***** Step 28000 / Validation 28 *****
09/16 07:28:18 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:28:18 AM: Validating...
09/16 07:28:22 AM: Evaluate: task edges-ner-ontonotes, batch 26 (157): mcc: 0.8853, acc: 0.8528, precision: 0.9099, recall: 0.8737, f1: 0.8914, edges-ner-ontonotes_loss: 0.0362
09/16 07:28:22 AM: Update 32742: task edges-ner-ontonotes, batch 742 (32742): mcc: 0.9255, acc: 0.8909, precision: 0.9457, recall: 0.9137, f1: 0.9294, edges-ner-ontonotes_loss: 0.0252
09/16 07:28:32 AM: Evaluate: task edges-ner-ontonotes, batch 85 (157): mcc: 0.9282, acc: 0.9003, precision: 0.9489, recall: 0.9156, f1: 0.9320, edges-ner-ontonotes_loss: 0.0249
09/16 07:28:32 AM: Update 32806: task edges-ner-ontonotes, batch 806 (32806): mcc: 0.9252, acc: 0.8905, precision: 0.9457, recall: 0.9131, f1: 0.9291, edges-ner-ontonotes_loss: 0.0251
09/16 07:28:42 AM: Evaluate: task edges-ner-ontonotes, batch 136 (157): mcc: 0.9377, acc: 0.9123, precision: 0.9561, recall: 0.9263, f1: 0.9410, edges-ner-ontonotes_loss: 0.0217
09/16 07:28:42 AM: Update 32871: task edges-ner-ontonotes, batch 871 (32871): mcc: 0.9246, acc: 0.8897, precision: 0.9453, recall: 0.9125, f1: 0.9286, edges-ner-ontonotes_loss: 0.0253
09/16 07:28:45 AM: Updating LR scheduler:
09/16 07:28:45 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:28:45 AM: 	# validation passes without improvement: 2
09/16 07:28:45 AM: edges-ner-ontonotes_loss: training: 0.023254 validation: 0.020889
09/16 07:28:45 AM: macro_avg: validation: 0.941950
09/16 07:28:45 AM: micro_avg: validation: 0.000000
09/16 07:28:45 AM: edges-ner-ontonotes_mcc: training: 0.931245 validation: 0.938701
09/16 07:28:45 AM: edges-ner-ontonotes_acc: training: 0.897550 validation: 0.913482
09/16 07:28:45 AM: edges-ner-ontonotes_precision: training: 0.949950 validation: 0.955962
09/16 07:28:45 AM: edges-ner-ontonotes_recall: training: 0.920281 validation: 0.928344
09/16 07:28:45 AM: edges-ner-ontonotes_f1: training: 0.934881 validation: 0.941950
09/16 07:28:45 AM: Global learning rate: 5e-05
09/16 07:28:45 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:28:52 AM: Update 28029: task edges-ner-ontonotes, batch 29 (28029): mcc: 0.9089, acc: 0.8654, precision: 0.9428, recall: 0.8856, f1: 0.9133, edges-ner-ontonotes_loss: 0.0296
09/16 07:28:52 AM: Update 32973: task edges-ner-ontonotes, batch 973 (32973): mcc: 0.9236, acc: 0.8884, precision: 0.9446, recall: 0.9113, f1: 0.9277, edges-ner-ontonotes_loss: 0.0257
09/16 07:28:57 AM: ***** Step 33000 / Validation 33 *****
09/16 07:28:57 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:28:57 AM: Validating...
09/16 07:29:02 AM: Update 28103: task edges-ner-ontonotes, batch 103 (28103): mcc: 0.9120, acc: 0.8729, precision: 0.9372, recall: 0.8968, f1: 0.9166, edges-ner-ontonotes_loss: 0.0290
09/16 07:29:02 AM: Evaluate: task edges-ner-ontonotes, batch 38 (157): mcc: 0.9114, acc: 0.8822, precision: 0.9356, recall: 0.8972, f1: 0.9160, edges-ner-ontonotes_loss: 0.0295
09/16 07:29:12 AM: Update 28158: task edges-ner-ontonotes, batch 158 (28158): mcc: 0.9116, acc: 0.8717, precision: 0.9358, recall: 0.8975, f1: 0.9162, edges-ner-ontonotes_loss: 0.0289
09/16 07:29:12 AM: Evaluate: task edges-ner-ontonotes, batch 98 (157): mcc: 0.9340, acc: 0.9072, precision: 0.9555, recall: 0.9200, f1: 0.9374, edges-ner-ontonotes_loss: 0.0236
09/16 07:29:22 AM: Update 28215: task edges-ner-ontonotes, batch 215 (28215): mcc: 0.9130, acc: 0.8741, precision: 0.9367, recall: 0.8992, f1: 0.9176, edges-ner-ontonotes_loss: 0.0287
09/16 07:29:23 AM: Evaluate: task edges-ner-ontonotes, batch 156 (157): mcc: 0.9410, acc: 0.9160, precision: 0.9593, recall: 0.9294, f1: 0.9441, edges-ner-ontonotes_loss: 0.0206
09/16 07:29:23 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:29:23 AM: Best result seen so far for macro.
09/16 07:29:23 AM: Updating LR scheduler:
09/16 07:29:23 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:29:23 AM: 	# validation passes without improvement: 3
09/16 07:29:23 AM: edges-ner-ontonotes_loss: training: 0.025635 validation: 0.020455
09/16 07:29:23 AM: macro_avg: validation: 0.944117
09/16 07:29:23 AM: micro_avg: validation: 0.000000
09/16 07:29:23 AM: edges-ner-ontonotes_mcc: training: 0.923505 validation: 0.941017
09/16 07:29:23 AM: edges-ner-ontonotes_acc: training: 0.888313 validation: 0.916060
09/16 07:29:23 AM: edges-ner-ontonotes_precision: training: 0.944385 validation: 0.959302
09/16 07:29:23 AM: edges-ner-ontonotes_recall: training: 0.911252 validation: 0.929406
09/16 07:29:23 AM: edges-ner-ontonotes_f1: training: 0.927523 validation: 0.944117
09/16 07:29:23 AM: Global learning rate: 5e-05
09/16 07:29:23 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:29:32 AM: Update 28290: task edges-ner-ontonotes, batch 290 (28290): mcc: 0.9135, acc: 0.8750, precision: 0.9377, recall: 0.8991, f1: 0.9180, edges-ner-ontonotes_loss: 0.0283
09/16 07:29:33 AM: Update 33081: task edges-ner-ontonotes, batch 81 (33081): mcc: 0.9255, acc: 0.8911, precision: 0.9441, recall: 0.9152, f1: 0.9295, edges-ner-ontonotes_loss: 0.0246
09/16 07:29:42 AM: Update 28345: task edges-ner-ontonotes, batch 345 (28345): mcc: 0.9145, acc: 0.8760, precision: 0.9391, recall: 0.8995, f1: 0.9189, edges-ner-ontonotes_loss: 0.0279
09/16 07:29:43 AM: Update 33174: task edges-ner-ontonotes, batch 174 (33174): mcc: 0.9282, acc: 0.8953, precision: 0.9464, recall: 0.9181, f1: 0.9320, edges-ner-ontonotes_loss: 0.0231
09/16 07:29:52 AM: Update 28414: task edges-ner-ontonotes, batch 414 (28414): mcc: 0.9173, acc: 0.8798, precision: 0.9408, recall: 0.9031, f1: 0.9216, edges-ner-ontonotes_loss: 0.0272
09/16 07:29:53 AM: Update 33259: task edges-ner-ontonotes, batch 259 (33259): mcc: 0.9283, acc: 0.8949, precision: 0.9470, recall: 0.9176, f1: 0.9321, edges-ner-ontonotes_loss: 0.0230
09/16 07:30:02 AM: Update 28492: task edges-ner-ontonotes, batch 492 (28492): mcc: 0.9195, acc: 0.8829, precision: 0.9415, recall: 0.9065, f1: 0.9237, edges-ner-ontonotes_loss: 0.0265
09/16 07:30:03 AM: Update 33318: task edges-ner-ontonotes, batch 318 (33318): mcc: 0.9292, acc: 0.8961, precision: 0.9477, recall: 0.9187, f1: 0.9330, edges-ner-ontonotes_loss: 0.0227
09/16 07:30:12 AM: Update 28562: task edges-ner-ontonotes, batch 562 (28562): mcc: 0.9205, acc: 0.8843, precision: 0.9424, recall: 0.9075, f1: 0.9246, edges-ner-ontonotes_loss: 0.0262
09/16 07:30:13 AM: Update 33396: task edges-ner-ontonotes, batch 396 (33396): mcc: 0.9318, acc: 0.8995, precision: 0.9491, recall: 0.9220, f1: 0.9354, edges-ner-ontonotes_loss: 0.0219
09/16 07:30:23 AM: Update 28633: task edges-ner-ontonotes, batch 633 (28633): mcc: 0.9218, acc: 0.8862, precision: 0.9431, recall: 0.9093, f1: 0.9259, edges-ner-ontonotes_loss: 0.0257
09/16 07:30:23 AM: Update 33481: task edges-ner-ontonotes, batch 481 (33481): mcc: 0.9345, acc: 0.9029, precision: 0.9514, recall: 0.9248, f1: 0.9380, edges-ner-ontonotes_loss: 0.0211
09/16 07:30:33 AM: Update 28677: task edges-ner-ontonotes, batch 677 (28677): mcc: 0.9238, acc: 0.8885, precision: 0.9447, recall: 0.9115, f1: 0.9278, edges-ner-ontonotes_loss: 0.0252
09/16 07:30:33 AM: Update 33565: task edges-ner-ontonotes, batch 565 (33565): mcc: 0.9367, acc: 0.9057, precision: 0.9530, recall: 0.9274, f1: 0.9401, edges-ner-ontonotes_loss: 0.0205
09/16 07:30:43 AM: Update 28751: task edges-ner-ontonotes, batch 751 (28751): mcc: 0.9260, acc: 0.8915, precision: 0.9458, recall: 0.9146, f1: 0.9299, edges-ner-ontonotes_loss: 0.0245
09/16 07:30:43 AM: Update 33631: task edges-ner-ontonotes, batch 631 (33631): mcc: 0.9379, acc: 0.9073, precision: 0.9538, recall: 0.9290, f1: 0.9412, edges-ner-ontonotes_loss: 0.0201
09/16 07:30:53 AM: Update 28820: task edges-ner-ontonotes, batch 820 (28820): mcc: 0.9278, acc: 0.8938, precision: 0.9469, recall: 0.9167, f1: 0.9316, edges-ner-ontonotes_loss: 0.0239
09/16 07:30:53 AM: Update 33713: task edges-ner-ontonotes, batch 713 (33713): mcc: 0.9383, acc: 0.9079, precision: 0.9540, recall: 0.9296, f1: 0.9416, edges-ner-ontonotes_loss: 0.0199
09/16 07:31:03 AM: Update 28886: task edges-ner-ontonotes, batch 886 (28886): mcc: 0.9295, acc: 0.8961, precision: 0.9482, recall: 0.9187, f1: 0.9332, edges-ner-ontonotes_loss: 0.0233
09/16 07:31:03 AM: Update 33792: task edges-ner-ontonotes, batch 792 (33792): mcc: 0.9387, acc: 0.9082, precision: 0.9543, recall: 0.9300, f1: 0.9420, edges-ner-ontonotes_loss: 0.0197
09/16 07:31:13 AM: Update 33881: task edges-ner-ontonotes, batch 881 (33881): mcc: 0.9395, acc: 0.9091, precision: 0.9551, recall: 0.9308, f1: 0.9427, edges-ner-ontonotes_loss: 0.0195
09/16 07:31:14 AM: Update 28948: task edges-ner-ontonotes, batch 948 (28948): mcc: 0.9303, acc: 0.8970, precision: 0.9486, recall: 0.9198, f1: 0.9340, edges-ner-ontonotes_loss: 0.0230
09/16 07:31:21 AM: ***** Step 29000 / Validation 29 *****
09/16 07:31:21 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:31:21 AM: Validating...
09/16 07:31:24 AM: Update 33943: task edges-ner-ontonotes, batch 943 (33943): mcc: 0.9386, acc: 0.9077, precision: 0.9545, recall: 0.9295, f1: 0.9418, edges-ner-ontonotes_loss: 0.0198
09/16 07:31:24 AM: Evaluate: task edges-ner-ontonotes, batch 20 (157): mcc: 0.8845, acc: 0.8422, precision: 0.9140, recall: 0.8681, f1: 0.8905, edges-ner-ontonotes_loss: 0.0333
09/16 07:31:33 AM: ***** Step 34000 / Validation 34 *****
09/16 07:31:33 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:31:33 AM: Validating...
09/16 07:31:34 AM: Evaluate: task edges-ner-ontonotes, batch 3 (157): mcc: 0.7756, acc: 0.6961, precision: 0.8427, recall: 0.7353, f1: 0.7853, edges-ner-ontonotes_loss: 0.0562
09/16 07:31:35 AM: Evaluate: task edges-ner-ontonotes, batch 76 (157): mcc: 0.9231, acc: 0.8924, precision: 0.9443, recall: 0.9106, f1: 0.9272, edges-ner-ontonotes_loss: 0.0273
09/16 07:31:44 AM: Evaluate: task edges-ner-ontonotes, batch 56 (157): mcc: 0.9216, acc: 0.8927, precision: 0.9429, recall: 0.9091, f1: 0.9257, edges-ner-ontonotes_loss: 0.0269
09/16 07:31:45 AM: Evaluate: task edges-ner-ontonotes, batch 114 (157): mcc: 0.9304, acc: 0.9024, precision: 0.9491, recall: 0.9194, f1: 0.9340, edges-ner-ontonotes_loss: 0.0242
09/16 07:31:54 AM: Evaluate: task edges-ner-ontonotes, batch 100 (157): mcc: 0.9257, acc: 0.8956, precision: 0.9502, recall: 0.9098, f1: 0.9295, edges-ner-ontonotes_loss: 0.0252
09/16 07:31:55 AM: Evaluate: task edges-ner-ontonotes, batch 157 (157): mcc: 0.9393, acc: 0.9136, precision: 0.9542, recall: 0.9311, f1: 0.9425, edges-ner-ontonotes_loss: 0.0210
09/16 07:31:57 AM: Updating LR scheduler:
09/16 07:31:57 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:31:57 AM: 	# validation passes without improvement: 3
09/16 07:31:57 AM: edges-ner-ontonotes_loss: training: 0.022734 validation: 0.021033
09/16 07:31:57 AM: macro_avg: validation: 0.942549
09/16 07:31:57 AM: micro_avg: validation: 0.000000
09/16 07:31:57 AM: edges-ner-ontonotes_mcc: training: 0.931097 validation: 0.939292
09/16 07:31:57 AM: edges-ner-ontonotes_acc: training: 0.898069 validation: 0.913634
09/16 07:31:57 AM: edges-ner-ontonotes_precision: training: 0.949354 validation: 0.954231
09/16 07:31:57 AM: edges-ner-ontonotes_recall: training: 0.920587 validation: 0.931150
09/16 07:31:57 AM: edges-ner-ontonotes_f1: training: 0.934749 validation: 0.942549
09/16 07:31:57 AM: Global learning rate: 5e-05
09/16 07:31:57 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:32:04 AM: Updating LR scheduler:
09/16 07:32:04 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:32:04 AM: 	# validation passes without improvement: 0
09/16 07:32:04 AM: edges-ner-ontonotes_loss: training: 0.020544 validation: 0.020888
09/16 07:32:04 AM: macro_avg: validation: 0.942265
09/16 07:32:04 AM: micro_avg: validation: 0.000000
09/16 07:32:04 AM: edges-ner-ontonotes_mcc: training: 0.936900 validation: 0.939087
09/16 07:32:04 AM: edges-ner-ontonotes_acc: training: 0.905489 validation: 0.913027
09/16 07:32:04 AM: edges-ner-ontonotes_precision: training: 0.953369 validation: 0.958794
09/16 07:32:04 AM: edges-ner-ontonotes_recall: training: 0.927515 validation: 0.926297
09/16 07:32:04 AM: edges-ner-ontonotes_f1: training: 0.940264 validation: 0.942265
09/16 07:32:04 AM: Global learning rate: 2.5e-05
09/16 07:32:04 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:32:04 AM: Update 34001: task edges-ner-ontonotes, batch 1 (34001): mcc: 0.9174, acc: 0.8788, precision: 0.9667, recall: 0.8788, f1: 0.9206, edges-ner-ontonotes_loss: 0.0239
09/16 07:32:07 AM: Update 29057: task edges-ner-ontonotes, batch 57 (29057): mcc: 0.9385, acc: 0.9052, precision: 0.9522, recall: 0.9316, f1: 0.9418, edges-ner-ontonotes_loss: 0.0205
09/16 07:32:14 AM: Update 34080: task edges-ner-ontonotes, batch 80 (34080): mcc: 0.9016, acc: 0.8599, precision: 0.9332, recall: 0.8812, f1: 0.9065, edges-ner-ontonotes_loss: 0.0343
09/16 07:32:18 AM: Update 29138: task edges-ner-ontonotes, batch 138 (29138): mcc: 0.9393, acc: 0.9070, precision: 0.9536, recall: 0.9318, f1: 0.9426, edges-ner-ontonotes_loss: 0.0192
09/16 07:32:25 AM: Update 34160: task edges-ner-ontonotes, batch 160 (34160): mcc: 0.9045, acc: 0.8652, precision: 0.9332, recall: 0.8866, f1: 0.9093, edges-ner-ontonotes_loss: 0.0339
09/16 07:32:28 AM: Update 29211: task edges-ner-ontonotes, batch 211 (29211): mcc: 0.9408, acc: 0.9096, precision: 0.9565, recall: 0.9317, f1: 0.9439, edges-ner-ontonotes_loss: 0.0189
09/16 07:32:37 AM: Update 34233: task edges-ner-ontonotes, batch 233 (34233): mcc: 0.9068, acc: 0.8674, precision: 0.9349, recall: 0.8893, f1: 0.9116, edges-ner-ontonotes_loss: 0.0329
09/16 07:32:38 AM: Update 29269: task edges-ner-ontonotes, batch 269 (29269): mcc: 0.9395, acc: 0.9082, precision: 0.9554, recall: 0.9305, f1: 0.9428, edges-ner-ontonotes_loss: 0.0192
09/16 07:32:47 AM: Update 34320: task edges-ner-ontonotes, batch 320 (34320): mcc: 0.9073, acc: 0.8672, precision: 0.9341, recall: 0.8911, f1: 0.9121, edges-ner-ontonotes_loss: 0.0318
09/16 07:32:48 AM: Update 29346: task edges-ner-ontonotes, batch 346 (29346): mcc: 0.9319, acc: 0.8981, precision: 0.9504, recall: 0.9210, f1: 0.9355, edges-ner-ontonotes_loss: 0.0223
09/16 07:32:58 AM: Update 34416: task edges-ner-ontonotes, batch 416 (34416): mcc: 0.9084, acc: 0.8683, precision: 0.9345, recall: 0.8927, f1: 0.9131, edges-ner-ontonotes_loss: 0.0309
09/16 07:32:58 AM: Update 29419: task edges-ner-ontonotes, batch 419 (29419): mcc: 0.9274, acc: 0.8924, precision: 0.9476, recall: 0.9155, f1: 0.9313, edges-ner-ontonotes_loss: 0.0243
09/16 07:33:08 AM: Update 34504: task edges-ner-ontonotes, batch 504 (34504): mcc: 0.9095, acc: 0.8694, precision: 0.9354, recall: 0.8939, f1: 0.9141, edges-ner-ontonotes_loss: 0.0303
09/16 07:33:08 AM: Update 29489: task edges-ner-ontonotes, batch 489 (29489): mcc: 0.9240, acc: 0.8880, precision: 0.9452, recall: 0.9114, f1: 0.9280, edges-ner-ontonotes_loss: 0.0254
09/16 07:33:18 AM: Update 34577: task edges-ner-ontonotes, batch 577 (34577): mcc: 0.9110, acc: 0.8714, precision: 0.9361, recall: 0.8959, f1: 0.9156, edges-ner-ontonotes_loss: 0.0296
09/16 07:33:20 AM: Update 29565: task edges-ner-ontonotes, batch 565 (29565): mcc: 0.9225, acc: 0.8861, precision: 0.9441, recall: 0.9096, f1: 0.9265, edges-ner-ontonotes_loss: 0.0263
09/16 07:33:28 AM: Update 34671: task edges-ner-ontonotes, batch 671 (34671): mcc: 0.9136, acc: 0.8747, precision: 0.9378, recall: 0.8993, f1: 0.9181, edges-ner-ontonotes_loss: 0.0287
09/16 07:33:30 AM: Update 29643: task edges-ner-ontonotes, batch 643 (29643): mcc: 0.9213, acc: 0.8849, precision: 0.9431, recall: 0.9084, f1: 0.9254, edges-ner-ontonotes_loss: 0.0266
09/16 07:33:38 AM: Update 34759: task edges-ner-ontonotes, batch 759 (34759): mcc: 0.9162, acc: 0.8782, precision: 0.9394, recall: 0.9024, f1: 0.9205, edges-ner-ontonotes_loss: 0.0279
09/16 07:33:40 AM: Update 29722: task edges-ner-ontonotes, batch 722 (29722): mcc: 0.9203, acc: 0.8835, precision: 0.9422, recall: 0.9073, f1: 0.9244, edges-ner-ontonotes_loss: 0.0269
09/16 07:33:48 AM: Update 34843: task edges-ner-ontonotes, batch 843 (34843): mcc: 0.9170, acc: 0.8794, precision: 0.9401, recall: 0.9032, f1: 0.9213, edges-ner-ontonotes_loss: 0.0275
09/16 07:33:50 AM: Update 29806: task edges-ner-ontonotes, batch 806 (29806): mcc: 0.9200, acc: 0.8830, precision: 0.9423, recall: 0.9068, f1: 0.9242, edges-ner-ontonotes_loss: 0.0269
09/16 07:33:58 AM: Update 34913: task edges-ner-ontonotes, batch 913 (34913): mcc: 0.9186, acc: 0.8816, precision: 0.9413, recall: 0.9051, f1: 0.9229, edges-ner-ontonotes_loss: 0.0269
09/16 07:34:02 AM: Update 29878: task edges-ner-ontonotes, batch 878 (29878): mcc: 0.9196, acc: 0.8824, precision: 0.9420, recall: 0.9063, f1: 0.9238, edges-ner-ontonotes_loss: 0.0269
09/16 07:34:08 AM: ***** Step 35000 / Validation 35 *****
09/16 07:34:08 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:34:08 AM: Validating...
09/16 07:34:08 AM: Evaluate: task edges-ner-ontonotes, batch 1 (157): mcc: 0.8344, acc: 0.7377, precision: 0.9216, recall: 0.7705, f1: 0.8393, edges-ner-ontonotes_loss: 0.0491
09/16 07:34:12 AM: Update 29937: task edges-ner-ontonotes, batch 937 (29937): mcc: 0.9198, acc: 0.8828, precision: 0.9421, recall: 0.9066, f1: 0.9240, edges-ner-ontonotes_loss: 0.0267
09/16 07:34:18 AM: Evaluate: task edges-ner-ontonotes, batch 65 (157): mcc: 0.9238, acc: 0.8953, precision: 0.9440, recall: 0.9122, f1: 0.9278, edges-ner-ontonotes_loss: 0.0265
09/16 07:34:22 AM: Update 29995: task edges-ner-ontonotes, batch 995 (29995): mcc: 0.9201, acc: 0.8831, precision: 0.9422, recall: 0.9070, f1: 0.9242, edges-ner-ontonotes_loss: 0.0265
09/16 07:34:23 AM: ***** Step 30000 / Validation 30 *****
09/16 07:34:23 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:34:23 AM: Validating...
09/16 07:34:29 AM: Evaluate: task edges-ner-ontonotes, batch 114 (157): mcc: 0.9330, acc: 0.9058, precision: 0.9517, recall: 0.9218, f1: 0.9365, edges-ner-ontonotes_loss: 0.0233
09/16 07:34:32 AM: Evaluate: task edges-ner-ontonotes, batch 52 (157): mcc: 0.9194, acc: 0.8912, precision: 0.9396, recall: 0.9082, f1: 0.9236, edges-ner-ontonotes_loss: 0.0269
09/16 07:34:39 AM: Updating LR scheduler:
09/16 07:34:39 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:34:39 AM: 	# validation passes without improvement: 1
09/16 07:34:39 AM: edges-ner-ontonotes_loss: training: 0.026061 validation: 0.020390
09/16 07:34:39 AM: macro_avg: validation: 0.944050
09/16 07:34:39 AM: micro_avg: validation: 0.000000
09/16 07:34:39 AM: edges-ner-ontonotes_mcc: training: 0.921488 validation: 0.940891
09/16 07:34:39 AM: edges-ner-ontonotes_acc: training: 0.885295 validation: 0.916060
09/16 07:34:39 AM: edges-ner-ontonotes_precision: training: 0.943153 validation: 0.956353
09/16 07:34:39 AM: edges-ner-ontonotes_recall: training: 0.908687 validation: 0.932059
09/16 07:34:39 AM: edges-ner-ontonotes_f1: training: 0.925599 validation: 0.944050
09/16 07:34:39 AM: Global learning rate: 2.5e-05
09/16 07:34:39 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:34:40 AM: Update 35006: task edges-ner-ontonotes, batch 6 (35006): mcc: 0.9618, acc: 0.9413, precision: 0.9676, recall: 0.9602, f1: 0.9639, edges-ner-ontonotes_loss: 0.0151
09/16 07:34:42 AM: Evaluate: task edges-ner-ontonotes, batch 101 (157): mcc: 0.9283, acc: 0.9001, precision: 0.9490, recall: 0.9157, f1: 0.9321, edges-ner-ontonotes_loss: 0.0241
09/16 07:34:51 AM: Update 35060: task edges-ner-ontonotes, batch 60 (35060): mcc: 0.9446, acc: 0.9152, precision: 0.9591, recall: 0.9363, f1: 0.9476, edges-ner-ontonotes_loss: 0.0177
09/16 07:34:53 AM: Evaluate: task edges-ner-ontonotes, batch 152 (157): mcc: 0.9405, acc: 0.9153, precision: 0.9574, recall: 0.9304, f1: 0.9437, edges-ner-ontonotes_loss: 0.0206
09/16 07:34:53 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:34:53 AM: Best result seen so far for macro.
09/16 07:34:53 AM: Updating LR scheduler:
09/16 07:34:53 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:34:53 AM: 	# validation passes without improvement: 0
09/16 07:34:53 AM: edges-ner-ontonotes_loss: training: 0.026469 validation: 0.020278
09/16 07:34:53 AM: macro_avg: validation: 0.944107
09/16 07:34:53 AM: micro_avg: validation: 0.000000
09/16 07:34:53 AM: edges-ner-ontonotes_mcc: training: 0.920155 validation: 0.940970
09/16 07:34:53 AM: edges-ner-ontonotes_acc: training: 0.883210 validation: 0.915833
09/16 07:34:53 AM: edges-ner-ontonotes_precision: training: 0.942243 validation: 0.957430
09/16 07:34:53 AM: edges-ner-ontonotes_recall: training: 0.907086 validation: 0.931150
09/16 07:34:53 AM: edges-ner-ontonotes_f1: training: 0.924330 validation: 0.944107
09/16 07:34:53 AM: Global learning rate: 5e-05
09/16 07:34:53 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:35:01 AM: Update 35139: task edges-ner-ontonotes, batch 139 (35139): mcc: 0.9471, acc: 0.9188, precision: 0.9600, recall: 0.9401, f1: 0.9500, edges-ner-ontonotes_loss: 0.0169
09/16 07:35:03 AM: Update 30062: task edges-ner-ontonotes, batch 62 (30062): mcc: 0.9300, acc: 0.8968, precision: 0.9509, recall: 0.9170, f1: 0.9336, edges-ner-ontonotes_loss: 0.0238
09/16 07:35:11 AM: Update 35201: task edges-ner-ontonotes, batch 201 (35201): mcc: 0.9452, acc: 0.9158, precision: 0.9588, recall: 0.9377, f1: 0.9481, edges-ner-ontonotes_loss: 0.0172
09/16 07:35:13 AM: Update 30138: task edges-ner-ontonotes, batch 138 (30138): mcc: 0.9273, acc: 0.8941, precision: 0.9476, recall: 0.9152, f1: 0.9311, edges-ner-ontonotes_loss: 0.0239
09/16 07:35:21 AM: Update 35282: task edges-ner-ontonotes, batch 282 (35282): mcc: 0.9446, acc: 0.9151, precision: 0.9584, recall: 0.9371, f1: 0.9476, edges-ner-ontonotes_loss: 0.0176
09/16 07:35:23 AM: Update 30191: task edges-ner-ontonotes, batch 191 (30191): mcc: 0.9279, acc: 0.8939, precision: 0.9479, recall: 0.9161, f1: 0.9317, edges-ner-ontonotes_loss: 0.0232
09/16 07:35:32 AM: Update 35371: task edges-ner-ontonotes, batch 371 (35371): mcc: 0.9443, acc: 0.9148, precision: 0.9585, recall: 0.9363, f1: 0.9473, edges-ner-ontonotes_loss: 0.0176
09/16 07:35:33 AM: Update 30262: task edges-ner-ontonotes, batch 262 (30262): mcc: 0.9308, acc: 0.8973, precision: 0.9497, recall: 0.9198, f1: 0.9345, edges-ner-ontonotes_loss: 0.0219
09/16 07:35:42 AM: Update 35446: task edges-ner-ontonotes, batch 446 (35446): mcc: 0.9445, acc: 0.9151, precision: 0.9588, recall: 0.9365, f1: 0.9475, edges-ner-ontonotes_loss: 0.0177
09/16 07:35:43 AM: Update 30326: task edges-ner-ontonotes, batch 326 (30326): mcc: 0.9339, acc: 0.9013, precision: 0.9515, recall: 0.9238, f1: 0.9374, edges-ner-ontonotes_loss: 0.0212
09/16 07:35:52 AM: Update 35516: task edges-ner-ontonotes, batch 516 (35516): mcc: 0.9415, acc: 0.9110, precision: 0.9572, recall: 0.9323, f1: 0.9446, edges-ner-ontonotes_loss: 0.0189
09/16 07:35:53 AM: Update 30397: task edges-ner-ontonotes, batch 397 (30397): mcc: 0.9362, acc: 0.9042, precision: 0.9526, recall: 0.9269, f1: 0.9396, edges-ner-ontonotes_loss: 0.0204
09/16 07:36:02 AM: Update 35596: task edges-ner-ontonotes, batch 596 (35596): mcc: 0.9375, acc: 0.9060, precision: 0.9547, recall: 0.9274, f1: 0.9408, edges-ner-ontonotes_loss: 0.0207
09/16 07:36:03 AM: Update 30467: task edges-ner-ontonotes, batch 467 (30467): mcc: 0.9375, acc: 0.9059, precision: 0.9538, recall: 0.9282, f1: 0.9408, edges-ner-ontonotes_loss: 0.0201
09/16 07:36:12 AM: Update 35678: task edges-ner-ontonotes, batch 678 (35678): mcc: 0.9340, acc: 0.9015, precision: 0.9525, recall: 0.9229, f1: 0.9374, edges-ner-ontonotes_loss: 0.0221
09/16 07:36:13 AM: Update 30521: task edges-ner-ontonotes, batch 521 (30521): mcc: 0.9382, acc: 0.9069, precision: 0.9544, recall: 0.9290, f1: 0.9415, edges-ner-ontonotes_loss: 0.0199
09/16 07:36:22 AM: Update 35764: task edges-ner-ontonotes, batch 764 (35764): mcc: 0.9313, acc: 0.8981, precision: 0.9510, recall: 0.9194, f1: 0.9349, edges-ner-ontonotes_loss: 0.0232
09/16 07:36:23 AM: Update 30592: task edges-ner-ontonotes, batch 592 (30592): mcc: 0.9383, acc: 0.9072, precision: 0.9544, recall: 0.9292, f1: 0.9416, edges-ner-ontonotes_loss: 0.0198
09/16 07:36:32 AM: Update 35835: task edges-ner-ontonotes, batch 835 (35835): mcc: 0.9292, acc: 0.8955, precision: 0.9491, recall: 0.9172, f1: 0.9329, edges-ner-ontonotes_loss: 0.0241
09/16 07:36:33 AM: Update 30666: task edges-ner-ontonotes, batch 666 (30666): mcc: 0.9386, acc: 0.9076, precision: 0.9544, recall: 0.9297, f1: 0.9419, edges-ner-ontonotes_loss: 0.0197
09/16 07:36:42 AM: Update 35925: task edges-ner-ontonotes, batch 925 (35925): mcc: 0.9281, acc: 0.8940, precision: 0.9480, recall: 0.9162, f1: 0.9318, edges-ner-ontonotes_loss: 0.0244
09/16 07:36:43 AM: Update 30741: task edges-ner-ontonotes, batch 741 (30741): mcc: 0.9388, acc: 0.9077, precision: 0.9545, recall: 0.9300, f1: 0.9421, edges-ner-ontonotes_loss: 0.0197
09/16 07:36:50 AM: ***** Step 36000 / Validation 36 *****
09/16 07:36:50 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:36:50 AM: Validating...
09/16 07:36:52 AM: Evaluate: task edges-ner-ontonotes, batch 15 (157): mcc: 0.8738, acc: 0.8324, precision: 0.9071, recall: 0.8549, f1: 0.8802, edges-ner-ontonotes_loss: 0.0340
09/16 07:36:54 AM: Update 30809: task edges-ner-ontonotes, batch 809 (30809): mcc: 0.9390, acc: 0.9079, precision: 0.9547, recall: 0.9302, f1: 0.9423, edges-ner-ontonotes_loss: 0.0196
09/16 07:37:02 AM: Evaluate: task edges-ner-ontonotes, batch 82 (157): mcc: 0.9284, acc: 0.8994, precision: 0.9506, recall: 0.9143, f1: 0.9321, edges-ner-ontonotes_loss: 0.0245
09/16 07:37:04 AM: Update 30843: task edges-ner-ontonotes, batch 843 (30843): mcc: 0.9375, acc: 0.9060, precision: 0.9539, recall: 0.9281, f1: 0.9408, edges-ner-ontonotes_loss: 0.0201
09/16 07:37:12 AM: Evaluate: task edges-ner-ontonotes, batch 134 (157): mcc: 0.9387, acc: 0.9126, precision: 0.9580, recall: 0.9263, f1: 0.9419, edges-ner-ontonotes_loss: 0.0212
09/16 07:37:14 AM: Update 30890: task edges-ner-ontonotes, batch 890 (30890): mcc: 0.9359, acc: 0.9039, precision: 0.9527, recall: 0.9262, f1: 0.9393, edges-ner-ontonotes_loss: 0.0208
09/16 07:37:16 AM: Updating LR scheduler:
09/16 07:37:16 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:37:18 AM: 	# validation passes without improvement: 2
09/16 07:37:18 AM: edges-ner-ontonotes_loss: training: 0.024489 validation: 0.020262
09/16 07:37:18 AM: macro_avg: validation: 0.943382
09/16 07:37:18 AM: micro_avg: validation: 0.000000
09/16 07:37:18 AM: edges-ner-ontonotes_mcc: training: 0.927585 validation: 0.940226
09/16 07:37:18 AM: edges-ner-ontonotes_acc: training: 0.893331 validation: 0.914695
09/16 07:37:18 AM: edges-ner-ontonotes_precision: training: 0.947781 validation: 0.957946
09/16 07:37:18 AM: edges-ner-ontonotes_recall: training: 0.915560 validation: 0.929254
09/16 07:37:18 AM: edges-ner-ontonotes_f1: training: 0.931392 validation: 0.943382
09/16 07:37:18 AM: Global learning rate: 2.5e-05
09/16 07:37:18 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:37:22 AM: Update 36040: task edges-ner-ontonotes, batch 40 (36040): mcc: 0.9129, acc: 0.8753, precision: 0.9366, recall: 0.8989, f1: 0.9174, edges-ner-ontonotes_loss: 0.0274
09/16 07:37:24 AM: Update 30974: task edges-ner-ontonotes, batch 974 (30974): mcc: 0.9335, acc: 0.9009, precision: 0.9512, recall: 0.9233, f1: 0.9370, edges-ner-ontonotes_loss: 0.0219
09/16 07:37:27 AM: ***** Step 31000 / Validation 31 *****
09/16 07:37:27 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:37:29 AM: Validating...
09/16 07:37:33 AM: Update 36112: task edges-ner-ontonotes, batch 112 (36112): mcc: 0.9139, acc: 0.8751, precision: 0.9368, recall: 0.9007, f1: 0.9184, edges-ner-ontonotes_loss: 0.0272
09/16 07:37:34 AM: Evaluate: task edges-ner-ontonotes, batch 37 (157): mcc: 0.9060, acc: 0.8742, precision: 0.9288, recall: 0.8939, f1: 0.9110, edges-ner-ontonotes_loss: 0.0311
09/16 07:37:44 AM: Update 36173: task edges-ner-ontonotes, batch 173 (36173): mcc: 0.9200, acc: 0.8840, precision: 0.9414, recall: 0.9075, f1: 0.9242, edges-ner-ontonotes_loss: 0.0258
09/16 07:37:44 AM: Evaluate: task edges-ner-ontonotes, batch 92 (157): mcc: 0.9297, acc: 0.9002, precision: 0.9515, recall: 0.9158, f1: 0.9333, edges-ner-ontonotes_loss: 0.0247
09/16 07:37:54 AM: Update 36234: task edges-ner-ontonotes, batch 234 (36234): mcc: 0.9246, acc: 0.8890, precision: 0.9458, recall: 0.9119, f1: 0.9285, edges-ner-ontonotes_loss: 0.0245
09/16 07:37:54 AM: Evaluate: task edges-ner-ontonotes, batch 135 (157): mcc: 0.9384, acc: 0.9125, precision: 0.9569, recall: 0.9269, f1: 0.9417, edges-ner-ontonotes_loss: 0.0217
09/16 07:37:58 AM: Updating LR scheduler:
09/16 07:37:58 AM: 	Best result seen so far for macro_avg: 0.944
09/16 07:37:58 AM: 	# validation passes without improvement: 1
09/16 07:37:58 AM: edges-ner-ontonotes_loss: training: 0.022137 validation: 0.020813
09/16 07:37:58 AM: macro_avg: validation: 0.942837
09/16 07:37:58 AM: micro_avg: validation: 0.000000
09/16 07:37:58 AM: edges-ner-ontonotes_mcc: training: 0.933097 validation: 0.939639
09/16 07:37:58 AM: edges-ner-ontonotes_acc: training: 0.900472 validation: 0.914013
09/16 07:37:58 AM: edges-ner-ontonotes_precision: training: 0.950993 validation: 0.956824
09/16 07:37:58 AM: edges-ner-ontonotes_recall: training: 0.922724 validation: 0.929254
09/16 07:37:58 AM: edges-ner-ontonotes_f1: training: 0.936645 validation: 0.942837
09/16 07:37:58 AM: Global learning rate: 5e-05
09/16 07:37:58 AM: Saving checkpoints to: ./experiments/ner-ontonotes-rte-top/run
09/16 07:38:04 AM: Update 36309: task edges-ner-ontonotes, batch 309 (36309): mcc: 0.9263, acc: 0.8914, precision: 0.9465, recall: 0.9145, f1: 0.9302, edges-ner-ontonotes_loss: 0.0238
09/16 07:38:04 AM: Update 31047: task edges-ner-ontonotes, batch 47 (31047): mcc: 0.9059, acc: 0.8638, precision: 0.9326, recall: 0.8899, f1: 0.9107, edges-ner-ontonotes_loss: 0.0329
09/16 07:38:14 AM: Update 36392: task edges-ner-ontonotes, batch 392 (36392): mcc: 0.9261, acc: 0.8917, precision: 0.9462, recall: 0.9144, f1: 0.9300, edges-ner-ontonotes_loss: 0.0239
09/16 07:38:14 AM: Update 31116: task edges-ner-ontonotes, batch 116 (31116): mcc: 0.9058, acc: 0.8652, precision: 0.9323, recall: 0.8899, f1: 0.9106, edges-ner-ontonotes_loss: 0.0333
09/16 07:38:24 AM: Update 36475: task edges-ner-ontonotes, batch 475 (36475): mcc: 0.9281, acc: 0.8942, precision: 0.9473, recall: 0.9170, f1: 0.9319, edges-ner-ontonotes_loss: 0.0230
09/16 07:38:25 AM: Update 31171: task edges-ner-ontonotes, batch 171 (31171): mcc: 0.9079, acc: 0.8690, precision: 0.9328, recall: 0.8934, f1: 0.9127, edges-ner-ontonotes_loss: 0.0317
09/16 07:38:35 AM: Update 36553: task edges-ner-ontonotes, batch 553 (36553): mcc: 0.9318, acc: 0.8988, precision: 0.9498, recall: 0.9214, f1: 0.9354, edges-ner-ontonotes_loss: 0.0222
09/16 07:38:35 AM: Update 31247: task edges-ner-ontonotes, batch 247 (31247): mcc: 0.9075, acc: 0.8683, precision: 0.9325, recall: 0.8930, f1: 0.9123, edges-ner-ontonotes_loss: 0.0311
09/16 07:38:45 AM: Update 36636: task edges-ner-ontonotes, batch 636 (36636): mcc: 0.9337, acc: 0.9011, precision: 0.9510, recall: 0.9239, f1: 0.9373, edges-ner-ontonotes_loss: 0.0215
09/16 07:38:45 AM: Update 31328: task edges-ner-ontonotes, batch 328 (31328): mcc: 0.9104, acc: 0.8715, precision: 0.9349, recall: 0.8960, f1: 0.9151, edges-ner-ontonotes_loss: 0.0298
