09/16 06:46:18 AM: Git branch: master
09/16 06:46:18 AM: Git SHA: fb3796f035a61c062bc75b422b0939a7eeec20ff
09/16 06:46:18 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/pos-ontonotes-hotpot-top/",
  "exp_name": "experiments/pos-ontonotes-hotpot-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/pos-ontonotes-hotpot-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/hotpot",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/pos-ontonotes-hotpot-top__run",
  "run_dir": "./experiments/pos-ontonotes-hotpot-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-pos-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 06:46:18 AM: Saved config to ./experiments/pos-ontonotes-hotpot-top/run/params.conf
09/16 06:46:18 AM: Using random seed 1234
09/16 06:46:19 AM: Using GPU 0
09/16 06:46:19 AM: Loading tasks...
09/16 06:46:19 AM: Writing pre-preprocessed tasks to ./experiments/pos-ontonotes-hotpot-top/
09/16 06:46:19 AM: 	Creating task edges-pos-ontonotes from scratch.
09/16 06:46:34 AM: Read=110514, Skip=5298, Total=115812 from ./probing_data/edges/ontonotes/const/pos/train.json.retokenized.bert-base-uncased
09/16 06:46:35 AM: Read=15060, Skip=620, Total=15680 from ./probing_data/edges/ontonotes/const/pos/development.json.retokenized.bert-base-uncased
09/16 06:46:38 AM: Read=11462, Skip=755, Total=12217 from ./probing_data/edges/ontonotes/const/pos/test.json.retokenized.bert-base-uncased
09/16 06:46:48 AM: 	Task 'edges-pos-ontonotes': |train|=110514 |val|=15060 |test|=11462
09/16 06:46:48 AM: 	Finished loading tasks: edges-pos-ontonotes.
09/16 06:46:48 AM: 	Building vocab from scratch.
09/16 06:46:48 AM: 	Counting units for task edges-pos-ontonotes.
09/16 06:46:50 AM: 	Task 'edges-pos-ontonotes': adding vocab namespace 'edges-pos-ontonotes_labels'
09/16 06:46:51 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:46:51 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 06:46:51 AM: 	Saved vocab to ./experiments/pos-ontonotes-hotpot-top/vocab
09/16 06:46:51 AM: Loading token dictionary from ./experiments/pos-ontonotes-hotpot-top/vocab.
09/16 06:46:51 AM: 	Loaded vocab from ./experiments/pos-ontonotes-hotpot-top/vocab
09/16 06:46:51 AM: 	Vocab namespace bert_uncased: size 30524
09/16 06:46:51 AM: 	Vocab namespace tokens: size 24015
09/16 06:46:51 AM: 	Vocab namespace edges-pos-ontonotes_labels: size 48
09/16 06:46:51 AM: 	Vocab namespace chars: size 81
09/16 06:46:51 AM: 	Finished building vocab.
09/16 06:46:51 AM: 	Task edges-pos-ontonotes (train): Indexing from scratch.
09/16 06:47:20 AM: 	Task edges-pos-ontonotes (train): Saved 110514 instances to ./experiments/pos-ontonotes-hotpot-top/preproc/edges-pos-ontonotes__train_data
09/16 06:47:20 AM: 	Task edges-pos-ontonotes (val): Indexing from scratch.
09/16 06:47:24 AM: 	Task edges-pos-ontonotes (val): Saved 15060 instances to ./experiments/pos-ontonotes-hotpot-top/preproc/edges-pos-ontonotes__val_data
09/16 06:47:24 AM: 	Task edges-pos-ontonotes (test): Indexing from scratch.
09/16 06:47:27 AM: 	Task edges-pos-ontonotes (test): Saved 11462 instances to ./experiments/pos-ontonotes-hotpot-top/preproc/edges-pos-ontonotes__test_data
09/16 06:47:27 AM: 	Finished indexing tasks
09/16 06:47:27 AM: 	Creating trimmed target-only version of edges-pos-ontonotes train.
09/16 06:47:27 AM: 	  Training on 
09/16 06:47:27 AM: 	  Evaluating on edges-pos-ontonotes
09/16 06:47:27 AM: 	Finished loading tasks in 68.510s
09/16 06:47:27 AM: 	 Tasks: ['edges-pos-ontonotes']
09/16 06:47:27 AM: Building model...
09/16 06:47:27 AM: Using BERT model (bert-base-uncased).
09/16 06:47:27 AM: LOADING A FUNETUNED MODEL from: 
09/16 06:47:27 AM: models/hotpot
09/16 06:47:27 AM: loading configuration file models/hotpot/config.json
09/16 06:47:27 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 06:47:27 AM: loading weights file models/hotpot/pytorch_model.bin
09/16 06:47:30 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpq7tmtxhf
09/16 06:47:32 AM: copying /tmp/tmpq7tmtxhf to cache at ./experiments/pos-ontonotes-hotpot-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:47:32 AM: creating metadata file for ./experiments/pos-ontonotes-hotpot-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:47:32 AM: removing temp file /tmp/tmpq7tmtxhf
09/16 06:47:32 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/pos-ontonotes-hotpot-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:47:32 AM: Initializing parameters
09/16 06:47:32 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 06:47:32 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 06:47:32 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 06:47:32 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 06:47:32 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 06:47:32 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 06:47:32 AM: 	Task 'edges-pos-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-pos-ontonotes"
}
09/16 06:47:36 AM: Model specification:
09/16 06:47:36 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-pos-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=48, bias=True)
    )
  )
)
09/16 06:47:36 AM: Model parameters:
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:47:36 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:47:36 AM: 	edges-pos-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 06:47:36 AM: 	edges-pos-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 06:47:36 AM: 	edges-pos-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 24576 with torch.Size([48, 512])
09/16 06:47:36 AM: 	edges-pos-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 48 with torch.Size([48])
09/16 06:47:36 AM: Total number of parameters: 109703728 (1.09704e+08)
09/16 06:47:36 AM: Number of trainable parameters: 221488 (221488)
09/16 06:47:36 AM: Finished building model in 8.971s
09/16 06:47:36 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-pos-ontonotes 

09/16 06:48:40 AM: patience = 9
09/16 06:48:40 AM: val_interval = 1000
09/16 06:48:40 AM: max_vals = 250
09/16 06:48:40 AM: cuda_device = 0
09/16 06:48:40 AM: grad_norm = 5.0
09/16 06:48:40 AM: grad_clipping = None
09/16 06:48:40 AM: lr_decay = 0.99
09/16 06:48:40 AM: min_lr = 1e-06
09/16 06:48:40 AM: keep_all_checkpoints = 0
09/16 06:48:40 AM: val_data_limit = 5000
09/16 06:48:40 AM: max_epochs = -1
09/16 06:48:40 AM: dec_val_scale = 250
09/16 06:48:40 AM: training_data_fraction = 1
09/16 06:48:40 AM: type = adam
09/16 06:48:40 AM: parameter_groups = None
09/16 06:48:40 AM: Number of trainable parameters: 221488
09/16 06:48:40 AM: infer_type_and_cast = True
09/16 06:48:40 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:48:40 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:48:40 AM: lr = 0.0001
09/16 06:48:40 AM: amsgrad = True
09/16 06:48:40 AM: type = reduce_on_plateau
09/16 06:48:40 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:48:40 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:48:40 AM: mode = max
09/16 06:48:40 AM: factor = 0.5
09/16 06:48:40 AM: patience = 3
09/16 06:48:40 AM: threshold = 0.0001
09/16 06:48:40 AM: threshold_mode = abs
09/16 06:48:40 AM: verbose = True
09/16 06:48:40 AM: type = adam
09/16 06:48:40 AM: parameter_groups = None
09/16 06:48:40 AM: Number of trainable parameters: 221488
09/16 06:48:40 AM: infer_type_and_cast = True
09/16 06:48:40 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:48:40 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:48:40 AM: lr = 0.0001
09/16 06:48:40 AM: amsgrad = True
09/16 06:48:40 AM: type = reduce_on_plateau
09/16 06:48:40 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:48:40 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:48:40 AM: mode = max
09/16 06:48:40 AM: factor = 0.5
09/16 06:48:40 AM: patience = 3
09/16 06:48:40 AM: threshold = 0.0001
09/16 06:48:40 AM: threshold_mode = abs
09/16 06:48:40 AM: verbose = True
09/16 06:48:40 AM: Starting training without restoring from a checkpoint.
09/16 06:48:40 AM: Training examples per task, before any subsampling: {'edges-pos-ontonotes': 110514}
09/16 06:48:40 AM: Beginning training with stopping criteria based on metric: edges-pos-ontonotes_f1
09/16 06:48:50 AM: Update 81: task edges-pos-ontonotes, batch 81 (81): mcc: -0.0044, acc: 0.0008, precision: 0.0186, recall: 0.0636, f1: 0.0287, edges-pos-ontonotes_loss: 0.2387
09/16 06:49:00 AM: Update 173: task edges-pos-ontonotes, batch 173 (173): mcc: -0.0017, acc: 0.0018, precision: 0.0195, recall: 0.0311, f1: 0.0240, edges-pos-ontonotes_loss: 0.1562
09/16 06:49:10 AM: Update 268: task edges-pos-ontonotes, batch 268 (268): mcc: 0.0013, acc: 0.0037, precision: 0.0221, recall: 0.0230, f1: 0.0225, edges-pos-ontonotes_loss: 0.1287
09/16 06:49:20 AM: Update 337: task edges-pos-ontonotes, batch 337 (337): mcc: 0.0057, acc: 0.0064, precision: 0.0271, recall: 0.0218, f1: 0.0241, edges-pos-ontonotes_loss: 0.1181
09/16 06:49:30 AM: Update 414: task edges-pos-ontonotes, batch 414 (414): mcc: 0.0107, acc: 0.0091, precision: 0.0340, recall: 0.0217, f1: 0.0265, edges-pos-ontonotes_loss: 0.1101
09/16 06:49:41 AM: Update 488: task edges-pos-ontonotes, batch 488 (488): mcc: 0.0205, acc: 0.0151, precision: 0.0483, recall: 0.0261, f1: 0.0339, edges-pos-ontonotes_loss: 0.1043
09/16 06:49:51 AM: Update 558: task edges-pos-ontonotes, batch 558 (558): mcc: 0.0299, acc: 0.0198, precision: 0.0637, recall: 0.0301, f1: 0.0409, edges-pos-ontonotes_loss: 0.1002
09/16 06:50:02 AM: Update 627: task edges-pos-ontonotes, batch 627 (627): mcc: 0.0405, acc: 0.0251, precision: 0.0818, recall: 0.0351, f1: 0.0491, edges-pos-ontonotes_loss: 0.0967
09/16 06:50:12 AM: Update 678: task edges-pos-ontonotes, batch 678 (678): mcc: 0.0488, acc: 0.0286, precision: 0.0978, recall: 0.0382, f1: 0.0549, edges-pos-ontonotes_loss: 0.0948
09/16 06:50:22 AM: Update 734: task edges-pos-ontonotes, batch 734 (734): mcc: 0.0564, acc: 0.0314, precision: 0.1136, recall: 0.0408, f1: 0.0601, edges-pos-ontonotes_loss: 0.0929
09/16 06:50:32 AM: Update 798: task edges-pos-ontonotes, batch 798 (798): mcc: 0.0650, acc: 0.0349, precision: 0.1314, recall: 0.0442, f1: 0.0662, edges-pos-ontonotes_loss: 0.0910
09/16 06:50:42 AM: Update 863: task edges-pos-ontonotes, batch 863 (863): mcc: 0.0737, acc: 0.0384, precision: 0.1497, recall: 0.0477, f1: 0.0723, edges-pos-ontonotes_loss: 0.0892
09/16 06:50:52 AM: Update 918: task edges-pos-ontonotes, batch 918 (918): mcc: 0.0819, acc: 0.0414, precision: 0.1675, recall: 0.0508, f1: 0.0780, edges-pos-ontonotes_loss: 0.0879
09/16 06:51:03 AM: Update 965: task edges-pos-ontonotes, batch 965 (965): mcc: 0.0882, acc: 0.0438, precision: 0.1816, recall: 0.0532, f1: 0.0823, edges-pos-ontonotes_loss: 0.0868
09/16 06:51:09 AM: ***** Step 1000 / Validation 1 *****
09/16 06:51:09 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 06:51:09 AM: Validating...
09/16 06:51:13 AM: Evaluate: task edges-pos-ontonotes, batch 25 (157): mcc: 0.2787, acc: 0.0991, precision: 0.7607, recall: 0.1054, f1: 0.1851, edges-pos-ontonotes_loss: 0.0654
09/16 06:51:23 AM: Evaluate: task edges-pos-ontonotes, batch 92 (157): mcc: 0.2977, acc: 0.1084, precision: 0.7966, recall: 0.1145, f1: 0.2003, edges-pos-ontonotes_loss: 0.0654
09/16 06:51:33 AM: Evaluate: task edges-pos-ontonotes, batch 139 (157): mcc: 0.2952, acc: 0.1096, precision: 0.7610, recall: 0.1181, f1: 0.2045, edges-pos-ontonotes_loss: 0.0646
09/16 06:51:36 AM: Best result seen so far for edges-pos-ontonotes.
09/16 06:51:36 AM: Best result seen so far for micro.
09/16 06:51:36 AM: Best result seen so far for macro.
09/16 06:51:36 AM: Updating LR scheduler:
09/16 06:51:36 AM: 	Best result seen so far for macro_avg: 0.204
09/16 06:51:36 AM: 	# validation passes without improvement: 0
09/16 06:51:36 AM: edges-pos-ontonotes_loss: training: 0.086128 validation: 0.064438
09/16 06:51:36 AM: macro_avg: validation: 0.204444
09/16 06:51:36 AM: micro_avg: validation: 0.000000
09/16 06:51:36 AM: edges-pos-ontonotes_mcc: training: 0.093637 validation: 0.294256
09/16 06:51:36 AM: edges-pos-ontonotes_acc: training: 0.045865 validation: 0.109485
09/16 06:51:36 AM: edges-pos-ontonotes_precision: training: 0.193587 validation: 0.756007
09/16 06:51:36 AM: edges-pos-ontonotes_recall: training: 0.055358 validation: 0.118205
09/16 06:51:36 AM: edges-pos-ontonotes_f1: training: 0.086096 validation: 0.204444
09/16 06:51:36 AM: Global learning rate: 0.0001
09/16 06:51:36 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 06:51:43 AM: Update 1037: task edges-pos-ontonotes, batch 37 (1037): mcc: 0.2650, acc: 0.0924, precision: 0.7083, recall: 0.1027, f1: 0.1794, edges-pos-ontonotes_loss: 0.0654
09/16 06:51:53 AM: Update 1091: task edges-pos-ontonotes, batch 91 (1091): mcc: 0.2743, acc: 0.1004, precision: 0.6941, recall: 0.1124, f1: 0.1935, edges-pos-ontonotes_loss: 0.0651
09/16 06:52:03 AM: Update 1147: task edges-pos-ontonotes, batch 147 (1147): mcc: 0.2816, acc: 0.1056, precision: 0.6969, recall: 0.1180, f1: 0.2018, edges-pos-ontonotes_loss: 0.0646
09/16 06:52:13 AM: Update 1204: task edges-pos-ontonotes, batch 204 (1204): mcc: 0.2855, acc: 0.1082, precision: 0.7007, recall: 0.1206, f1: 0.2058, edges-pos-ontonotes_loss: 0.0643
09/16 06:52:33 AM: Update 1253: task edges-pos-ontonotes, batch 253 (1253): mcc: 0.2905, acc: 0.1119, precision: 0.7021, recall: 0.1245, f1: 0.2115, edges-pos-ontonotes_loss: 0.0641
09/16 06:52:43 AM: Update 1311: task edges-pos-ontonotes, batch 311 (1311): mcc: 0.2948, acc: 0.1148, precision: 0.7066, recall: 0.1274, f1: 0.2159, edges-pos-ontonotes_loss: 0.0638
09/16 06:52:53 AM: Update 1369: task edges-pos-ontonotes, batch 369 (1369): mcc: 0.3005, acc: 0.1188, precision: 0.7116, recall: 0.1313, f1: 0.2217, edges-pos-ontonotes_loss: 0.0635
09/16 06:53:03 AM: Update 1427: task edges-pos-ontonotes, batch 427 (1427): mcc: 0.3068, acc: 0.1233, precision: 0.7157, recall: 0.1360, f1: 0.2286, edges-pos-ontonotes_loss: 0.0632
09/16 06:53:13 AM: Update 1481: task edges-pos-ontonotes, batch 481 (1481): mcc: 0.3120, acc: 0.1272, precision: 0.7181, recall: 0.1402, f1: 0.2346, edges-pos-ontonotes_loss: 0.0629
09/16 06:53:23 AM: Update 1536: task edges-pos-ontonotes, batch 536 (1536): mcc: 0.3170, acc: 0.1308, precision: 0.7215, recall: 0.1440, f1: 0.2401, edges-pos-ontonotes_loss: 0.0627
09/16 06:53:33 AM: Update 1586: task edges-pos-ontonotes, batch 586 (1586): mcc: 0.3212, acc: 0.1340, precision: 0.7245, recall: 0.1472, f1: 0.2447, edges-pos-ontonotes_loss: 0.0624
09/16 06:53:43 AM: Update 1641: task edges-pos-ontonotes, batch 641 (1641): mcc: 0.3262, acc: 0.1378, precision: 0.7272, recall: 0.1512, f1: 0.2503, edges-pos-ontonotes_loss: 0.0621
09/16 06:53:53 AM: Update 1699: task edges-pos-ontonotes, batch 699 (1699): mcc: 0.3316, acc: 0.1419, precision: 0.7308, recall: 0.1554, f1: 0.2563, edges-pos-ontonotes_loss: 0.0618
09/16 06:54:03 AM: Update 1753: task edges-pos-ontonotes, batch 753 (1753): mcc: 0.3358, acc: 0.1452, precision: 0.7325, recall: 0.1589, f1: 0.2612, edges-pos-ontonotes_loss: 0.0616
09/16 06:54:13 AM: Update 1812: task edges-pos-ontonotes, batch 812 (1812): mcc: 0.3401, acc: 0.1487, precision: 0.7347, recall: 0.1626, f1: 0.2662, edges-pos-ontonotes_loss: 0.0613
09/16 06:54:23 AM: Update 1866: task edges-pos-ontonotes, batch 866 (1866): mcc: 0.3443, acc: 0.1521, precision: 0.7367, recall: 0.1661, f1: 0.2711, edges-pos-ontonotes_loss: 0.0610
09/16 06:54:34 AM: Update 1908: task edges-pos-ontonotes, batch 908 (1908): mcc: 0.3452, acc: 0.1530, precision: 0.7357, recall: 0.1672, f1: 0.2724, edges-pos-ontonotes_loss: 0.0609
09/16 06:54:44 AM: Update 1977: task edges-pos-ontonotes, batch 977 (1977): mcc: 0.3482, acc: 0.1554, precision: 0.7372, recall: 0.1697, f1: 0.2759, edges-pos-ontonotes_loss: 0.0606
09/16 06:54:46 AM: ***** Step 2000 / Validation 2 *****
09/16 06:54:46 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 06:54:46 AM: Validating...
09/16 06:54:54 AM: Evaluate: task edges-pos-ontonotes, batch 50 (157): mcc: 0.4249, acc: 0.2097, precision: 0.8393, recall: 0.2203, f1: 0.3490, edges-pos-ontonotes_loss: 0.0578
09/16 06:55:04 AM: Evaluate: task edges-pos-ontonotes, batch 110 (157): mcc: 0.4578, acc: 0.2418, precision: 0.8439, recall: 0.2540, f1: 0.3905, edges-pos-ontonotes_loss: 0.0548
09/16 06:55:14 AM: Evaluate: task edges-pos-ontonotes, batch 156 (157): mcc: 0.4574, acc: 0.2444, precision: 0.8263, recall: 0.2592, f1: 0.3946, edges-pos-ontonotes_loss: 0.0542
09/16 06:55:14 AM: Best result seen so far for edges-pos-ontonotes.
09/16 06:55:14 AM: Best result seen so far for macro.
09/16 06:55:14 AM: Updating LR scheduler:
09/16 06:55:14 AM: 	Best result seen so far for macro_avg: 0.395
09/16 06:55:14 AM: 	# validation passes without improvement: 0
09/16 06:55:14 AM: edges-pos-ontonotes_loss: training: 0.060493 validation: 0.054229
09/16 06:55:14 AM: macro_avg: validation: 0.394506
09/16 06:55:14 AM: micro_avg: validation: 0.000000
09/16 06:55:14 AM: edges-pos-ontonotes_mcc: training: 0.349446 validation: 0.457307
09/16 06:55:14 AM: edges-pos-ontonotes_acc: training: 0.156373 validation: 0.244283
09/16 06:55:14 AM: edges-pos-ontonotes_precision: training: 0.738303 validation: 0.826275
09/16 06:55:14 AM: edges-pos-ontonotes_recall: training: 0.170666 validation: 0.259109
09/16 06:55:14 AM: edges-pos-ontonotes_f1: training: 0.277245 validation: 0.394506
09/16 06:55:14 AM: Global learning rate: 0.0001
09/16 06:55:14 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 06:55:24 AM: Update 2072: task edges-pos-ontonotes, batch 72 (2072): mcc: 0.4131, acc: 0.2119, precision: 0.7617, recall: 0.2305, f1: 0.3539, edges-pos-ontonotes_loss: 0.0552
09/16 06:55:34 AM: Update 2138: task edges-pos-ontonotes, batch 138 (2138): mcc: 0.4084, acc: 0.2091, precision: 0.7526, recall: 0.2280, f1: 0.3500, edges-pos-ontonotes_loss: 0.0550
09/16 06:55:44 AM: Update 2199: task edges-pos-ontonotes, batch 199 (2199): mcc: 0.4098, acc: 0.2110, precision: 0.7519, recall: 0.2299, f1: 0.3521, edges-pos-ontonotes_loss: 0.0545
09/16 06:55:54 AM: Update 2295: task edges-pos-ontonotes, batch 295 (2295): mcc: 0.4286, acc: 0.2255, precision: 0.7764, recall: 0.2430, f1: 0.3701, edges-pos-ontonotes_loss: 0.0530
09/16 06:56:04 AM: Update 2390: task edges-pos-ontonotes, batch 390 (2390): mcc: 0.4451, acc: 0.2392, precision: 0.7930, recall: 0.2563, f1: 0.3874, edges-pos-ontonotes_loss: 0.0519
09/16 06:56:14 AM: Update 2485: task edges-pos-ontonotes, batch 485 (2485): mcc: 0.4582, acc: 0.2506, precision: 0.8041, recall: 0.2676, f1: 0.4015, edges-pos-ontonotes_loss: 0.0509
09/16 06:56:24 AM: Update 2580: task edges-pos-ontonotes, batch 580 (2580): mcc: 0.4669, acc: 0.2591, precision: 0.8092, recall: 0.2760, f1: 0.4116, edges-pos-ontonotes_loss: 0.0505
09/16 06:56:34 AM: Update 2687: task edges-pos-ontonotes, batch 687 (2687): mcc: 0.4776, acc: 0.2697, precision: 0.8144, recall: 0.2867, f1: 0.4241, edges-pos-ontonotes_loss: 0.0498
09/16 06:56:44 AM: Update 2798: task edges-pos-ontonotes, batch 798 (2798): mcc: 0.4887, acc: 0.2808, precision: 0.8200, recall: 0.2980, f1: 0.4372, edges-pos-ontonotes_loss: 0.0489
09/16 06:56:54 AM: Update 2914: task edges-pos-ontonotes, batch 914 (2914): mcc: 0.4875, acc: 0.2805, precision: 0.8160, recall: 0.2981, f1: 0.4366, edges-pos-ontonotes_loss: 0.0490
09/16 06:57:00 AM: ***** Step 3000 / Validation 3 *****
09/16 06:57:00 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 06:57:00 AM: Validating...
09/16 06:57:04 AM: Evaluate: task edges-pos-ontonotes, batch 31 (157): mcc: 0.5171, acc: 0.3130, precision: 0.8158, recall: 0.3351, f1: 0.4751, edges-pos-ontonotes_loss: 0.0478
09/16 06:57:14 AM: Evaluate: task edges-pos-ontonotes, batch 97 (157): mcc: 0.5466, acc: 0.3454, precision: 0.8270, recall: 0.3688, f1: 0.5101, edges-pos-ontonotes_loss: 0.0459
09/16 06:57:24 AM: Evaluate: task edges-pos-ontonotes, batch 143 (157): mcc: 0.5276, acc: 0.3271, precision: 0.7973, recall: 0.3571, f1: 0.4933, edges-pos-ontonotes_loss: 0.0476
09/16 06:57:27 AM: Best result seen so far for edges-pos-ontonotes.
09/16 06:57:27 AM: Best result seen so far for macro.
09/16 06:57:27 AM: Updating LR scheduler:
09/16 06:57:27 AM: 	Best result seen so far for macro_avg: 0.496
09/16 06:57:27 AM: 	# validation passes without improvement: 0
09/16 06:57:27 AM: edges-pos-ontonotes_loss: training: 0.048818 validation: 0.047773
09/16 06:57:27 AM: macro_avg: validation: 0.495546
09/16 06:57:27 AM: micro_avg: validation: 0.000000
09/16 06:57:27 AM: edges-pos-ontonotes_mcc: training: 0.487507 validation: 0.529510
09/16 06:57:27 AM: edges-pos-ontonotes_acc: training: 0.280778 validation: 0.328688
09/16 06:57:27 AM: edges-pos-ontonotes_precision: training: 0.815681 validation: 0.797909
09/16 06:57:27 AM: edges-pos-ontonotes_recall: training: 0.298161 validation: 0.359366
09/16 06:57:27 AM: edges-pos-ontonotes_f1: training: 0.436694 validation: 0.495546
09/16 06:57:27 AM: Global learning rate: 0.0001
09/16 06:57:27 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 06:57:34 AM: Update 3095: task edges-pos-ontonotes, batch 95 (3095): mcc: 0.4773, acc: 0.2811, precision: 0.7831, recall: 0.2982, f1: 0.4319, edges-pos-ontonotes_loss: 0.0478
09/16 06:57:44 AM: Update 3159: task edges-pos-ontonotes, batch 159 (3159): mcc: 0.4466, acc: 0.2558, precision: 0.7378, recall: 0.2781, f1: 0.4039, edges-pos-ontonotes_loss: 0.0490
09/16 06:57:54 AM: Update 3215: task edges-pos-ontonotes, batch 215 (3215): mcc: 0.4361, acc: 0.2457, precision: 0.7248, recall: 0.2703, f1: 0.3937, edges-pos-ontonotes_loss: 0.0504
09/16 06:58:05 AM: Update 3274: task edges-pos-ontonotes, batch 274 (3274): mcc: 0.4342, acc: 0.2425, precision: 0.7245, recall: 0.2680, f1: 0.3913, edges-pos-ontonotes_loss: 0.0514
09/16 06:58:15 AM: Update 3337: task edges-pos-ontonotes, batch 337 (3337): mcc: 0.4348, acc: 0.2425, precision: 0.7267, recall: 0.2679, f1: 0.3915, edges-pos-ontonotes_loss: 0.0518
09/16 06:58:25 AM: Update 3407: task edges-pos-ontonotes, batch 407 (3407): mcc: 0.4386, acc: 0.2456, precision: 0.7315, recall: 0.2708, f1: 0.3952, edges-pos-ontonotes_loss: 0.0518
09/16 06:58:42 AM: Update 3461: task edges-pos-ontonotes, batch 461 (3461): mcc: 0.4399, acc: 0.2468, precision: 0.7328, recall: 0.2719, f1: 0.3966, edges-pos-ontonotes_loss: 0.0519
09/16 06:58:52 AM: Update 3561: task edges-pos-ontonotes, batch 561 (3561): mcc: 0.4482, acc: 0.2538, precision: 0.7443, recall: 0.2776, f1: 0.4044, edges-pos-ontonotes_loss: 0.0508
09/16 06:59:02 AM: Update 3657: task edges-pos-ontonotes, batch 657 (3657): mcc: 0.4559, acc: 0.2604, precision: 0.7533, recall: 0.2835, f1: 0.4120, edges-pos-ontonotes_loss: 0.0498
09/16 06:59:12 AM: Update 3743: task edges-pos-ontonotes, batch 743 (3743): mcc: 0.4618, acc: 0.2657, precision: 0.7590, recall: 0.2885, f1: 0.4181, edges-pos-ontonotes_loss: 0.0491
09/16 06:59:23 AM: Update 3812: task edges-pos-ontonotes, batch 812 (3812): mcc: 0.4659, acc: 0.2699, precision: 0.7595, recall: 0.2935, f1: 0.4234, edges-pos-ontonotes_loss: 0.0487
09/16 06:59:33 AM: Update 3881: task edges-pos-ontonotes, batch 881 (3881): mcc: 0.4714, acc: 0.2753, precision: 0.7608, recall: 0.2998, f1: 0.4301, edges-pos-ontonotes_loss: 0.0484
09/16 06:59:43 AM: Update 3959: task edges-pos-ontonotes, batch 959 (3959): mcc: 0.4768, acc: 0.2807, precision: 0.7628, recall: 0.3058, f1: 0.4366, edges-pos-ontonotes_loss: 0.0480
09/16 06:59:48 AM: ***** Step 4000 / Validation 4 *****
09/16 06:59:48 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 06:59:48 AM: Validating...
09/16 06:59:53 AM: Evaluate: task edges-pos-ontonotes, batch 37 (157): mcc: 0.6025, acc: 0.4019, precision: 0.8808, recall: 0.4191, f1: 0.5680, edges-pos-ontonotes_loss: 0.0406
09/16 07:00:03 AM: Evaluate: task edges-pos-ontonotes, batch 101 (157): mcc: 0.6116, acc: 0.4124, precision: 0.8810, recall: 0.4317, f1: 0.5794, edges-pos-ontonotes_loss: 0.0397
09/16 07:00:13 AM: Evaluate: task edges-pos-ontonotes, batch 148 (157): mcc: 0.5859, acc: 0.3842, precision: 0.8618, recall: 0.4057, f1: 0.5516, edges-pos-ontonotes_loss: 0.0416
09/16 07:00:15 AM: Best result seen so far for edges-pos-ontonotes.
09/16 07:00:15 AM: Best result seen so far for macro.
09/16 07:00:15 AM: Updating LR scheduler:
09/16 07:00:15 AM: 	Best result seen so far for macro_avg: 0.552
09/16 07:00:15 AM: 	# validation passes without improvement: 0
09/16 07:00:15 AM: edges-pos-ontonotes_loss: training: 0.047775 validation: 0.041666
09/16 07:00:15 AM: macro_avg: validation: 0.551511
09/16 07:00:15 AM: micro_avg: validation: 0.000000
09/16 07:00:15 AM: edges-pos-ontonotes_mcc: training: 0.479659 validation: 0.585780
09/16 07:00:15 AM: edges-pos-ontonotes_acc: training: 0.283480 validation: 0.384171
09/16 07:00:15 AM: edges-pos-ontonotes_precision: training: 0.764420 validation: 0.861436
09/16 07:00:15 AM: edges-pos-ontonotes_recall: training: 0.308830 validation: 0.405590
09/16 07:00:15 AM: edges-pos-ontonotes_f1: training: 0.439928 validation: 0.551511
09/16 07:00:15 AM: Global learning rate: 0.0001
09/16 07:00:15 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 07:00:23 AM: Update 4062: task edges-pos-ontonotes, batch 62 (4062): mcc: 0.5370, acc: 0.3438, precision: 0.7801, recall: 0.3782, f1: 0.5095, edges-pos-ontonotes_loss: 0.0446
09/16 07:00:33 AM: Update 4113: task edges-pos-ontonotes, batch 113 (4113): mcc: 0.5107, acc: 0.3208, precision: 0.7566, recall: 0.3535, f1: 0.4819, edges-pos-ontonotes_loss: 0.0462
09/16 07:00:43 AM: Update 4171: task edges-pos-ontonotes, batch 171 (4171): mcc: 0.4988, acc: 0.3085, precision: 0.7504, recall: 0.3403, f1: 0.4682, edges-pos-ontonotes_loss: 0.0477
09/16 07:00:53 AM: Update 4231: task edges-pos-ontonotes, batch 231 (4231): mcc: 0.4959, acc: 0.3061, precision: 0.7492, recall: 0.3368, f1: 0.4647, edges-pos-ontonotes_loss: 0.0482
09/16 07:01:03 AM: Update 4289: task edges-pos-ontonotes, batch 289 (4289): mcc: 0.4919, acc: 0.3030, precision: 0.7442, recall: 0.3339, f1: 0.4609, edges-pos-ontonotes_loss: 0.0486
09/16 07:01:14 AM: Update 4346: task edges-pos-ontonotes, batch 346 (4346): mcc: 0.4893, acc: 0.3003, precision: 0.7432, recall: 0.3308, f1: 0.4579, edges-pos-ontonotes_loss: 0.0489
09/16 07:01:25 AM: Update 4400: task edges-pos-ontonotes, batch 400 (4400): mcc: 0.4889, acc: 0.2996, precision: 0.7437, recall: 0.3300, f1: 0.4571, edges-pos-ontonotes_loss: 0.0490
09/16 07:01:35 AM: Update 4456: task edges-pos-ontonotes, batch 456 (4456): mcc: 0.4879, acc: 0.2987, precision: 0.7434, recall: 0.3288, f1: 0.4559, edges-pos-ontonotes_loss: 0.0491
09/16 07:01:45 AM: Update 4513: task edges-pos-ontonotes, batch 513 (4513): mcc: 0.4890, acc: 0.2996, precision: 0.7448, recall: 0.3297, f1: 0.4570, edges-pos-ontonotes_loss: 0.0490
09/16 07:01:55 AM: Update 4564: task edges-pos-ontonotes, batch 564 (4564): mcc: 0.4871, acc: 0.2978, precision: 0.7432, recall: 0.3278, f1: 0.4549, edges-pos-ontonotes_loss: 0.0491
09/16 07:02:05 AM: Update 4621: task edges-pos-ontonotes, batch 621 (4621): mcc: 0.4885, acc: 0.2990, precision: 0.7450, recall: 0.3289, f1: 0.4563, edges-pos-ontonotes_loss: 0.0490
09/16 07:02:15 AM: Update 4674: task edges-pos-ontonotes, batch 674 (4674): mcc: 0.4899, acc: 0.3001, precision: 0.7466, recall: 0.3300, f1: 0.4577, edges-pos-ontonotes_loss: 0.0490
09/16 07:02:25 AM: Update 4720: task edges-pos-ontonotes, batch 720 (4720): mcc: 0.4903, acc: 0.3005, precision: 0.7470, recall: 0.3304, f1: 0.4581, edges-pos-ontonotes_loss: 0.0489
09/16 07:02:35 AM: Update 4778: task edges-pos-ontonotes, batch 778 (4778): mcc: 0.4919, acc: 0.3019, precision: 0.7486, recall: 0.3317, f1: 0.4597, edges-pos-ontonotes_loss: 0.0488
09/16 07:02:45 AM: Update 4834: task edges-pos-ontonotes, batch 834 (4834): mcc: 0.4931, acc: 0.3031, precision: 0.7496, recall: 0.3328, f1: 0.4610, edges-pos-ontonotes_loss: 0.0488
09/16 07:02:56 AM: Update 4892: task edges-pos-ontonotes, batch 892 (4892): mcc: 0.4940, acc: 0.3041, precision: 0.7505, recall: 0.3338, f1: 0.4621, edges-pos-ontonotes_loss: 0.0487
09/16 07:03:06 AM: Update 4950: task edges-pos-ontonotes, batch 950 (4950): mcc: 0.4950, acc: 0.3050, precision: 0.7510, recall: 0.3348, f1: 0.4631, edges-pos-ontonotes_loss: 0.0486
09/16 07:03:15 AM: ***** Step 5000 / Validation 5 *****
09/16 07:03:15 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:03:15 AM: Validating...
09/16 07:03:16 AM: Evaluate: task edges-pos-ontonotes, batch 2 (157): mcc: 0.6472, acc: 0.4542, precision: 0.8949, recall: 0.4752, f1: 0.6207, edges-pos-ontonotes_loss: 0.0359
09/16 07:03:26 AM: Evaluate: task edges-pos-ontonotes, batch 73 (157): mcc: 0.6275, acc: 0.4284, precision: 0.8967, recall: 0.4460, f1: 0.5957, edges-pos-ontonotes_loss: 0.0393
09/16 07:03:36 AM: Evaluate: task edges-pos-ontonotes, batch 125 (157): mcc: 0.6141, acc: 0.4139, precision: 0.8861, recall: 0.4327, f1: 0.5814, edges-pos-ontonotes_loss: 0.0394
09/16 07:03:43 AM: Best result seen so far for edges-pos-ontonotes.
09/16 07:03:43 AM: Best result seen so far for macro.
09/16 07:03:43 AM: Updating LR scheduler:
09/16 07:03:43 AM: 	Best result seen so far for macro_avg: 0.574
09/16 07:03:43 AM: 	# validation passes without improvement: 0
09/16 07:03:43 AM: edges-pos-ontonotes_loss: training: 0.048634 validation: 0.039694
09/16 07:03:43 AM: macro_avg: validation: 0.573746
09/16 07:03:43 AM: micro_avg: validation: 0.000000
09/16 07:03:43 AM: edges-pos-ontonotes_mcc: training: 0.495744 validation: 0.607533
09/16 07:03:43 AM: edges-pos-ontonotes_acc: training: 0.305914 validation: 0.405939
09/16 07:03:43 AM: edges-pos-ontonotes_precision: training: 0.751442 validation: 0.883322
09/16 07:03:43 AM: edges-pos-ontonotes_recall: training: 0.335611 validation: 0.424849
09/16 07:03:43 AM: edges-pos-ontonotes_f1: training: 0.463993 validation: 0.573746
09/16 07:03:43 AM: Global learning rate: 0.0001
09/16 07:03:43 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 07:03:46 AM: Update 5021: task edges-pos-ontonotes, batch 21 (5021): mcc: 0.5324, acc: 0.3422, precision: 0.7802, recall: 0.3718, f1: 0.5036, edges-pos-ontonotes_loss: 0.0455
09/16 07:03:57 AM: Update 5026: task edges-pos-ontonotes, batch 26 (5026): mcc: 0.5225, acc: 0.3313, precision: 0.7740, recall: 0.3612, f1: 0.4926, edges-pos-ontonotes_loss: 0.0464
09/16 07:04:07 AM: Update 5088: task edges-pos-ontonotes, batch 88 (5088): mcc: 0.5216, acc: 0.3307, precision: 0.7714, recall: 0.3612, f1: 0.4920, edges-pos-ontonotes_loss: 0.0467
09/16 07:04:17 AM: Update 5142: task edges-pos-ontonotes, batch 142 (5142): mcc: 0.5177, acc: 0.3275, precision: 0.7673, recall: 0.3578, f1: 0.4880, edges-pos-ontonotes_loss: 0.0471
09/16 07:04:27 AM: Update 5202: task edges-pos-ontonotes, batch 202 (5202): mcc: 0.5199, acc: 0.3300, precision: 0.7687, recall: 0.3602, f1: 0.4905, edges-pos-ontonotes_loss: 0.0468
09/16 07:04:37 AM: Update 5259: task edges-pos-ontonotes, batch 259 (5259): mcc: 0.5210, acc: 0.3314, precision: 0.7694, recall: 0.3614, f1: 0.4918, edges-pos-ontonotes_loss: 0.0469
09/16 07:04:47 AM: Update 5313: task edges-pos-ontonotes, batch 313 (5313): mcc: 0.5201, acc: 0.3305, precision: 0.7685, recall: 0.3606, f1: 0.4909, edges-pos-ontonotes_loss: 0.0469
09/16 07:04:57 AM: Update 5352: task edges-pos-ontonotes, batch 352 (5352): mcc: 0.5148, acc: 0.3264, precision: 0.7619, recall: 0.3565, f1: 0.4858, edges-pos-ontonotes_loss: 0.0471
09/16 07:05:07 AM: Update 5421: task edges-pos-ontonotes, batch 421 (5421): mcc: 0.5171, acc: 0.3287, precision: 0.7629, recall: 0.3592, f1: 0.4885, edges-pos-ontonotes_loss: 0.0464
09/16 07:05:17 AM: Update 5494: task edges-pos-ontonotes, batch 494 (5494): mcc: 0.5213, acc: 0.3328, precision: 0.7653, recall: 0.3638, f1: 0.4931, edges-pos-ontonotes_loss: 0.0457
09/16 07:05:28 AM: Update 5571: task edges-pos-ontonotes, batch 571 (5571): mcc: 0.5239, acc: 0.3356, precision: 0.7663, recall: 0.3669, f1: 0.4963, edges-pos-ontonotes_loss: 0.0452
09/16 07:05:38 AM: Update 5630: task edges-pos-ontonotes, batch 630 (5630): mcc: 0.5225, acc: 0.3345, precision: 0.7640, recall: 0.3661, f1: 0.4950, edges-pos-ontonotes_loss: 0.0451
09/16 07:05:48 AM: Update 5700: task edges-pos-ontonotes, batch 700 (5700): mcc: 0.5280, acc: 0.3398, precision: 0.7680, recall: 0.3718, f1: 0.5010, edges-pos-ontonotes_loss: 0.0445
09/16 07:05:58 AM: Update 5797: task edges-pos-ontonotes, batch 797 (5797): mcc: 0.5377, acc: 0.3493, precision: 0.7758, recall: 0.3814, f1: 0.5114, edges-pos-ontonotes_loss: 0.0434
09/16 07:06:08 AM: Update 5886: task edges-pos-ontonotes, batch 886 (5886): mcc: 0.5460, acc: 0.3574, precision: 0.7823, recall: 0.3898, f1: 0.5203, edges-pos-ontonotes_loss: 0.0426
09/16 07:06:18 AM: Update 5966: task edges-pos-ontonotes, batch 966 (5966): mcc: 0.5524, acc: 0.3640, precision: 0.7870, recall: 0.3964, f1: 0.5272, edges-pos-ontonotes_loss: 0.0420
09/16 07:06:21 AM: ***** Step 6000 / Validation 6 *****
09/16 07:06:21 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:06:21 AM: Validating...
09/16 07:06:28 AM: Evaluate: task edges-pos-ontonotes, batch 49 (157): mcc: 0.6151, acc: 0.4151, precision: 0.9014, recall: 0.4264, f1: 0.5789, edges-pos-ontonotes_loss: 0.0387
09/16 07:06:38 AM: Evaluate: task edges-pos-ontonotes, batch 109 (157): mcc: 0.6312, acc: 0.4351, precision: 0.9043, recall: 0.4473, f1: 0.5986, edges-pos-ontonotes_loss: 0.0370
09/16 07:06:48 AM: Evaluate: task edges-pos-ontonotes, batch 155 (157): mcc: 0.6125, acc: 0.4123, precision: 0.8974, recall: 0.4249, f1: 0.5767, edges-pos-ontonotes_loss: 0.0384
09/16 07:06:48 AM: Best result seen so far for edges-pos-ontonotes.
09/16 07:06:48 AM: Best result seen so far for macro.
09/16 07:06:48 AM: Updating LR scheduler:
09/16 07:06:48 AM: 	Best result seen so far for macro_avg: 0.577
09/16 07:06:48 AM: 	# validation passes without improvement: 0
09/16 07:06:48 AM: edges-pos-ontonotes_loss: training: 0.041863 validation: 0.038425
09/16 07:06:48 AM: macro_avg: validation: 0.577172
09/16 07:06:48 AM: micro_avg: validation: 0.000000
09/16 07:06:48 AM: edges-pos-ontonotes_mcc: training: 0.554505 validation: 0.612935
09/16 07:06:48 AM: edges-pos-ontonotes_acc: training: 0.366166 validation: 0.412690
09/16 07:06:48 AM: edges-pos-ontonotes_precision: training: 0.788563 validation: 0.897452
09/16 07:06:48 AM: edges-pos-ontonotes_recall: training: 0.398556 validation: 0.425368
09/16 07:06:48 AM: edges-pos-ontonotes_f1: training: 0.529495 validation: 0.577172
09/16 07:06:48 AM: Global learning rate: 0.0001
09/16 07:06:48 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 07:06:58 AM: Update 6113: task edges-pos-ontonotes, batch 113 (6113): mcc: 0.6553, acc: 0.4812, precision: 0.8502, recall: 0.5131, f1: 0.6400, edges-pos-ontonotes_loss: 0.0356
09/16 07:07:08 AM: Update 6214: task edges-pos-ontonotes, batch 214 (6214): mcc: 0.6580, acc: 0.4857, precision: 0.8483, recall: 0.5185, f1: 0.6436, edges-pos-ontonotes_loss: 0.0353
09/16 07:07:18 AM: Update 6320: task edges-pos-ontonotes, batch 320 (6320): mcc: 0.6452, acc: 0.4714, precision: 0.8384, recall: 0.5049, f1: 0.6302, edges-pos-ontonotes_loss: 0.0365
09/16 07:07:28 AM: Update 6448: task edges-pos-ontonotes, batch 448 (6448): mcc: 0.6224, acc: 0.4445, precision: 0.8265, recall: 0.4771, f1: 0.6050, edges-pos-ontonotes_loss: 0.0380
09/16 07:07:40 AM: Update 6591: task edges-pos-ontonotes, batch 591 (6591): mcc: 0.6095, acc: 0.4308, precision: 0.8178, recall: 0.4628, f1: 0.5911, edges-pos-ontonotes_loss: 0.0388
09/16 07:07:50 AM: Update 6662: task edges-pos-ontonotes, batch 662 (6662): mcc: 0.5915, acc: 0.4109, precision: 0.8032, recall: 0.4443, f1: 0.5722, edges-pos-ontonotes_loss: 0.0398
09/16 07:08:00 AM: Update 6719: task edges-pos-ontonotes, batch 719 (6719): mcc: 0.5746, acc: 0.3924, precision: 0.7910, recall: 0.4263, f1: 0.5540, edges-pos-ontonotes_loss: 0.0406
09/16 07:08:10 AM: Update 6775: task edges-pos-ontonotes, batch 775 (6775): mcc: 0.5633, acc: 0.3801, precision: 0.7829, recall: 0.4142, f1: 0.5417, edges-pos-ontonotes_loss: 0.0411
09/16 07:08:20 AM: Update 6835: task edges-pos-ontonotes, batch 835 (6835): mcc: 0.5559, acc: 0.3721, precision: 0.7774, recall: 0.4065, f1: 0.5338, edges-pos-ontonotes_loss: 0.0417
09/16 07:08:30 AM: Update 6900: task edges-pos-ontonotes, batch 900 (6900): mcc: 0.5521, acc: 0.3677, precision: 0.7751, recall: 0.4022, f1: 0.5296, edges-pos-ontonotes_loss: 0.0420
09/16 07:08:41 AM: Update 6969: task edges-pos-ontonotes, batch 969 (6969): mcc: 0.5505, acc: 0.3659, precision: 0.7750, recall: 0.4000, f1: 0.5277, edges-pos-ontonotes_loss: 0.0421
09/16 07:08:44 AM: ***** Step 7000 / Validation 7 *****
09/16 07:08:44 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:08:44 AM: Validating...
09/16 07:08:51 AM: Evaluate: task edges-pos-ontonotes, batch 47 (157): mcc: 0.6481, acc: 0.4527, precision: 0.9130, recall: 0.4668, f1: 0.6177, edges-pos-ontonotes_loss: 0.0353
09/16 07:09:01 AM: Evaluate: task edges-pos-ontonotes, batch 107 (157): mcc: 0.6486, acc: 0.4546, precision: 0.9074, recall: 0.4704, f1: 0.6196, edges-pos-ontonotes_loss: 0.0345
09/16 07:09:11 AM: Evaluate: task edges-pos-ontonotes, batch 154 (157): mcc: 0.6209, acc: 0.4208, precision: 0.8941, recall: 0.4380, f1: 0.5880, edges-pos-ontonotes_loss: 0.0364
09/16 07:09:11 AM: Best result seen so far for edges-pos-ontonotes.
09/16 07:09:11 AM: Best result seen so far for macro.
09/16 07:09:11 AM: Updating LR scheduler:
09/16 07:09:11 AM: 	Best result seen so far for macro_avg: 0.588
09/16 07:09:11 AM: 	# validation passes without improvement: 0
09/16 07:09:11 AM: edges-pos-ontonotes_loss: training: 0.042059 validation: 0.036401
09/16 07:09:11 AM: macro_avg: validation: 0.588050
09/16 07:09:11 AM: micro_avg: validation: 0.000000
09/16 07:09:11 AM: edges-pos-ontonotes_mcc: training: 0.550283 validation: 0.620915
09/16 07:09:11 AM: edges-pos-ontonotes_acc: training: 0.365683 validation: 0.420722
09/16 07:09:11 AM: edges-pos-ontonotes_precision: training: 0.775136 validation: 0.894070
09/16 07:09:11 AM: edges-pos-ontonotes_recall: training: 0.399601 validation: 0.438099
09/16 07:09:11 AM: edges-pos-ontonotes_f1: training: 0.527344 validation: 0.588050
09/16 07:09:11 AM: Global learning rate: 0.0001
09/16 07:09:11 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 07:09:21 AM: Update 7091: task edges-pos-ontonotes, batch 91 (7091): mcc: 0.5689, acc: 0.3810, precision: 0.8083, recall: 0.4087, f1: 0.5429, edges-pos-ontonotes_loss: 0.0383
09/16 07:09:31 AM: Update 7183: task edges-pos-ontonotes, batch 183 (7183): mcc: 0.5735, acc: 0.3863, precision: 0.8101, recall: 0.4143, f1: 0.5483, edges-pos-ontonotes_loss: 0.0386
09/16 07:09:41 AM: Update 7254: task edges-pos-ontonotes, batch 254 (7254): mcc: 0.5711, acc: 0.3849, precision: 0.8027, recall: 0.4148, f1: 0.5470, edges-pos-ontonotes_loss: 0.0389
09/16 07:09:51 AM: Update 7326: task edges-pos-ontonotes, batch 326 (7326): mcc: 0.5693, acc: 0.3841, precision: 0.7933, recall: 0.4173, f1: 0.5469, edges-pos-ontonotes_loss: 0.0393
09/16 07:10:01 AM: Update 7403: task edges-pos-ontonotes, batch 403 (7403): mcc: 0.5723, acc: 0.3877, precision: 0.7912, recall: 0.4229, f1: 0.5511, edges-pos-ontonotes_loss: 0.0393
09/16 07:10:11 AM: Update 7474: task edges-pos-ontonotes, batch 474 (7474): mcc: 0.5721, acc: 0.3877, precision: 0.7881, recall: 0.4241, f1: 0.5515, edges-pos-ontonotes_loss: 0.0395
09/16 07:10:30 AM: Update 7547: task edges-pos-ontonotes, batch 547 (7547): mcc: 0.5735, acc: 0.3897, precision: 0.7870, recall: 0.4269, f1: 0.5535, edges-pos-ontonotes_loss: 0.0394
09/16 07:10:40 AM: Update 7600: task edges-pos-ontonotes, batch 600 (7600): mcc: 0.5638, acc: 0.3803, precision: 0.7781, recall: 0.4176, f1: 0.5435, edges-pos-ontonotes_loss: 0.0402
09/16 07:10:51 AM: Update 7658: task edges-pos-ontonotes, batch 658 (7658): mcc: 0.5577, acc: 0.3746, precision: 0.7723, recall: 0.4119, f1: 0.5373, edges-pos-ontonotes_loss: 0.0408
09/16 07:11:01 AM: Update 7720: task edges-pos-ontonotes, batch 720 (7720): mcc: 0.5541, acc: 0.3708, precision: 0.7689, recall: 0.4085, f1: 0.5335, edges-pos-ontonotes_loss: 0.0413
09/16 07:11:11 AM: Update 7787: task edges-pos-ontonotes, batch 787 (7787): mcc: 0.5529, acc: 0.3696, precision: 0.7676, recall: 0.4074, f1: 0.5323, edges-pos-ontonotes_loss: 0.0417
09/16 07:11:21 AM: Update 7841: task edges-pos-ontonotes, batch 841 (7841): mcc: 0.5494, acc: 0.3660, precision: 0.7646, recall: 0.4040, f1: 0.5287, edges-pos-ontonotes_loss: 0.0420
09/16 07:11:31 AM: Update 7884: task edges-pos-ontonotes, batch 884 (7884): mcc: 0.5473, acc: 0.3639, precision: 0.7625, recall: 0.4020, f1: 0.5265, edges-pos-ontonotes_loss: 0.0422
09/16 07:11:41 AM: Update 7940: task edges-pos-ontonotes, batch 940 (7940): mcc: 0.5462, acc: 0.3628, precision: 0.7615, recall: 0.4010, f1: 0.5254, edges-pos-ontonotes_loss: 0.0425
09/16 07:11:51 AM: Update 7993: task edges-pos-ontonotes, batch 993 (7993): mcc: 0.5451, acc: 0.3618, precision: 0.7605, recall: 0.4000, f1: 0.5243, edges-pos-ontonotes_loss: 0.0427
09/16 07:11:52 AM: ***** Step 8000 / Validation 8 *****
09/16 07:11:52 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:11:52 AM: Validating...
09/16 07:12:01 AM: Evaluate: task edges-pos-ontonotes, batch 64 (157): mcc: 0.6638, acc: 0.4745, precision: 0.9112, recall: 0.4903, f1: 0.6376, edges-pos-ontonotes_loss: 0.0347
09/16 07:12:11 AM: Evaluate: task edges-pos-ontonotes, batch 118 (157): mcc: 0.6577, acc: 0.4683, precision: 0.9027, recall: 0.4861, f1: 0.6319, edges-pos-ontonotes_loss: 0.0345
09/16 07:12:19 AM: Best result seen so far for edges-pos-ontonotes.
09/16 07:12:19 AM: Best result seen so far for macro.
09/16 07:12:19 AM: Updating LR scheduler:
09/16 07:12:19 AM: 	Best result seen so far for macro_avg: 0.617
09/16 07:12:19 AM: 	# validation passes without improvement: 0
09/16 07:12:19 AM: edges-pos-ontonotes_loss: training: 0.042661 validation: 0.035330
09/16 07:12:19 AM: macro_avg: validation: 0.616583
09/16 07:12:19 AM: micro_avg: validation: 0.000000
09/16 07:12:19 AM: edges-pos-ontonotes_mcc: training: 0.545129 validation: 0.644356
09/16 07:12:19 AM: edges-pos-ontonotes_acc: training: 0.361864 validation: 0.451147
09/16 07:12:19 AM: edges-pos-ontonotes_precision: training: 0.760448 validation: 0.897448
09/16 07:12:19 AM: edges-pos-ontonotes_recall: training: 0.400062 validation: 0.469613
09/16 07:12:19 AM: edges-pos-ontonotes_f1: training: 0.524297 validation: 0.616583
09/16 07:12:19 AM: Global learning rate: 0.0001
09/16 07:12:19 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 07:12:21 AM: Update 8010: task edges-pos-ontonotes, batch 10 (8010): mcc: 0.5316, acc: 0.3474, precision: 0.7491, recall: 0.3866, f1: 0.5100, edges-pos-ontonotes_loss: 0.0458
09/16 07:12:31 AM: Update 8069: task edges-pos-ontonotes, batch 69 (8069): mcc: 0.5420, acc: 0.3575, precision: 0.7597, recall: 0.3960, f1: 0.5206, edges-pos-ontonotes_loss: 0.0449
09/16 07:12:42 AM: Update 8121: task edges-pos-ontonotes, batch 121 (8121): mcc: 0.5356, acc: 0.3517, precision: 0.7538, recall: 0.3898, f1: 0.5139, edges-pos-ontonotes_loss: 0.0454
09/16 07:12:53 AM: Update 8173: task edges-pos-ontonotes, batch 173 (8173): mcc: 0.5355, acc: 0.3520, precision: 0.7526, recall: 0.3903, f1: 0.5141, edges-pos-ontonotes_loss: 0.0454
09/16 07:13:03 AM: Update 8227: task edges-pos-ontonotes, batch 227 (8227): mcc: 0.5332, acc: 0.3498, precision: 0.7519, recall: 0.3874, f1: 0.5113, edges-pos-ontonotes_loss: 0.0457
09/16 07:13:13 AM: Update 8283: task edges-pos-ontonotes, batch 283 (8283): mcc: 0.5350, acc: 0.3517, precision: 0.7533, recall: 0.3893, f1: 0.5133, edges-pos-ontonotes_loss: 0.0455
09/16 07:13:23 AM: Update 8343: task edges-pos-ontonotes, batch 343 (8343): mcc: 0.5366, acc: 0.3530, precision: 0.7551, recall: 0.3906, f1: 0.5149, edges-pos-ontonotes_loss: 0.0454
09/16 07:13:33 AM: Update 8401: task edges-pos-ontonotes, batch 401 (8401): mcc: 0.5386, acc: 0.3550, precision: 0.7566, recall: 0.3928, f1: 0.5171, edges-pos-ontonotes_loss: 0.0452
09/16 07:13:43 AM: Update 8459: task edges-pos-ontonotes, batch 459 (8459): mcc: 0.5403, acc: 0.3567, precision: 0.7579, recall: 0.3945, f1: 0.5189, edges-pos-ontonotes_loss: 0.0452
09/16 07:13:53 AM: Update 8503: task edges-pos-ontonotes, batch 503 (8503): mcc: 0.5400, acc: 0.3564, precision: 0.7572, recall: 0.3944, f1: 0.5186, edges-pos-ontonotes_loss: 0.0452
09/16 07:14:03 AM: Update 8557: task edges-pos-ontonotes, batch 557 (8557): mcc: 0.5400, acc: 0.3563, precision: 0.7572, recall: 0.3943, f1: 0.5186, edges-pos-ontonotes_loss: 0.0452
09/16 07:14:13 AM: Update 8614: task edges-pos-ontonotes, batch 614 (8614): mcc: 0.5415, acc: 0.3580, precision: 0.7583, recall: 0.3960, f1: 0.5203, edges-pos-ontonotes_loss: 0.0452
09/16 07:14:23 AM: Update 8671: task edges-pos-ontonotes, batch 671 (8671): mcc: 0.5429, acc: 0.3593, precision: 0.7594, recall: 0.3974, f1: 0.5218, edges-pos-ontonotes_loss: 0.0450
09/16 07:14:33 AM: Update 8732: task edges-pos-ontonotes, batch 732 (8732): mcc: 0.5443, acc: 0.3608, precision: 0.7606, recall: 0.3988, f1: 0.5233, edges-pos-ontonotes_loss: 0.0449
09/16 07:14:43 AM: Update 8787: task edges-pos-ontonotes, batch 787 (8787): mcc: 0.5435, acc: 0.3600, precision: 0.7598, recall: 0.3980, f1: 0.5224, edges-pos-ontonotes_loss: 0.0449
09/16 07:14:53 AM: Update 8833: task edges-pos-ontonotes, batch 833 (8833): mcc: 0.5418, acc: 0.3587, precision: 0.7576, recall: 0.3967, f1: 0.5207, edges-pos-ontonotes_loss: 0.0449
09/16 07:15:03 AM: Update 8897: task edges-pos-ontonotes, batch 897 (8897): mcc: 0.5420, acc: 0.3591, precision: 0.7574, recall: 0.3972, f1: 0.5211, edges-pos-ontonotes_loss: 0.0446
09/16 07:15:13 AM: Update 8965: task edges-pos-ontonotes, batch 965 (8965): mcc: 0.5430, acc: 0.3602, precision: 0.7578, recall: 0.3984, f1: 0.5223, edges-pos-ontonotes_loss: 0.0443
09/16 07:15:18 AM: ***** Step 9000 / Validation 9 *****
09/16 07:15:18 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:15:18 AM: Validating...
09/16 07:15:23 AM: Evaluate: task edges-pos-ontonotes, batch 37 (157): mcc: 0.6544, acc: 0.4645, precision: 0.9064, recall: 0.4793, f1: 0.6270, edges-pos-ontonotes_loss: 0.0354
09/16 07:15:34 AM: Evaluate: task edges-pos-ontonotes, batch 100 (157): mcc: 0.6650, acc: 0.4781, precision: 0.9088, recall: 0.4935, f1: 0.6396, edges-pos-ontonotes_loss: 0.0340
09/16 07:15:44 AM: Evaluate: task edges-pos-ontonotes, batch 146 (157): mcc: 0.6444, acc: 0.4533, precision: 0.8948, recall: 0.4711, f1: 0.6172, edges-pos-ontonotes_loss: 0.0351
09/16 07:15:46 AM: Best result seen so far for edges-pos-ontonotes.
09/16 07:15:46 AM: Best result seen so far for macro.
09/16 07:15:46 AM: Updating LR scheduler:
09/16 07:15:46 AM: 	Best result seen so far for macro_avg: 0.619
09/16 07:15:46 AM: 	# validation passes without improvement: 0
09/16 07:15:46 AM: edges-pos-ontonotes_loss: training: 0.044087 validation: 0.035017
09/16 07:15:46 AM: macro_avg: validation: 0.619496
09/16 07:15:46 AM: micro_avg: validation: 0.000000
09/16 07:15:46 AM: edges-pos-ontonotes_mcc: training: 0.543864 validation: 0.646318
09/16 07:15:46 AM: edges-pos-ontonotes_acc: training: 0.361079 validation: 0.455454
09/16 07:15:46 AM: edges-pos-ontonotes_precision: training: 0.758383 validation: 0.895329
09/16 07:15:46 AM: edges-pos-ontonotes_recall: training: 0.399349 validation: 0.473592
09/16 07:15:46 AM: edges-pos-ontonotes_f1: training: 0.523194 validation: 0.619496
09/16 07:15:46 AM: Global learning rate: 0.0001
09/16 07:15:46 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 07:15:54 AM: Update 9059: task edges-pos-ontonotes, batch 59 (9059): mcc: 0.5714, acc: 0.3929, precision: 0.7682, recall: 0.4346, f1: 0.5551, edges-pos-ontonotes_loss: 0.0392
09/16 07:16:11 AM: Update 9112: task edges-pos-ontonotes, batch 112 (9112): mcc: 0.5716, acc: 0.3933, precision: 0.7690, recall: 0.4343, f1: 0.5551, edges-pos-ontonotes_loss: 0.0393
09/16 07:16:21 AM: Update 9209: task edges-pos-ontonotes, batch 209 (9209): mcc: 0.6118, acc: 0.4340, precision: 0.8018, recall: 0.4759, f1: 0.5972, edges-pos-ontonotes_loss: 0.0364
09/16 07:16:31 AM: Update 9303: task edges-pos-ontonotes, batch 303 (9303): mcc: 0.6296, acc: 0.4531, precision: 0.8148, recall: 0.4953, f1: 0.6161, edges-pos-ontonotes_loss: 0.0352
09/16 07:16:41 AM: Update 9391: task edges-pos-ontonotes, batch 391 (9391): mcc: 0.6404, acc: 0.4650, precision: 0.8232, recall: 0.5069, f1: 0.6275, edges-pos-ontonotes_loss: 0.0346
09/16 07:16:51 AM: Update 9476: task edges-pos-ontonotes, batch 476 (9476): mcc: 0.6457, acc: 0.4714, precision: 0.8267, recall: 0.5130, f1: 0.6331, edges-pos-ontonotes_loss: 0.0344
09/16 07:17:01 AM: Update 9581: task edges-pos-ontonotes, batch 581 (9581): mcc: 0.6516, acc: 0.4787, precision: 0.8301, recall: 0.5200, f1: 0.6395, edges-pos-ontonotes_loss: 0.0341
09/16 07:17:11 AM: Update 9700: task edges-pos-ontonotes, batch 700 (9700): mcc: 0.6570, acc: 0.4856, precision: 0.8332, recall: 0.5265, f1: 0.6453, edges-pos-ontonotes_loss: 0.0338
09/16 07:17:21 AM: Update 9811: task edges-pos-ontonotes, batch 811 (9811): mcc: 0.6524, acc: 0.4808, precision: 0.8295, recall: 0.5217, f1: 0.6405, edges-pos-ontonotes_loss: 0.0344
09/16 07:17:31 AM: Update 9958: task edges-pos-ontonotes, batch 958 (9958): mcc: 0.6461, acc: 0.4738, precision: 0.8259, recall: 0.5142, f1: 0.6338, edges-pos-ontonotes_loss: 0.0352
09/16 07:17:34 AM: ***** Step 10000 / Validation 10 *****
09/16 07:17:34 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:17:34 AM: Validating...
09/16 07:17:41 AM: Evaluate: task edges-pos-ontonotes, batch 49 (157): mcc: 0.6543, acc: 0.4678, precision: 0.8799, recall: 0.4939, f1: 0.6327, edges-pos-ontonotes_loss: 0.0345
09/16 07:17:51 AM: Evaluate: task edges-pos-ontonotes, batch 109 (157): mcc: 0.6630, acc: 0.4806, precision: 0.8765, recall: 0.5091, f1: 0.6441, edges-pos-ontonotes_loss: 0.0333
09/16 07:18:01 AM: Evaluate: task edges-pos-ontonotes, batch 155 (157): mcc: 0.6405, acc: 0.4521, precision: 0.8611, recall: 0.4841, f1: 0.6198, edges-pos-ontonotes_loss: 0.0351
09/16 07:18:02 AM: Best result seen so far for edges-pos-ontonotes.
09/16 07:18:02 AM: Best result seen so far for macro.
09/16 07:18:02 AM: Updating LR scheduler:
09/16 07:18:02 AM: 	Best result seen so far for macro_avg: 0.620
09/16 07:18:02 AM: 	# validation passes without improvement: 0
09/16 07:18:02 AM: edges-pos-ontonotes_loss: training: 0.035320 validation: 0.035132
09/16 07:18:02 AM: macro_avg: validation: 0.620262
09/16 07:18:02 AM: micro_avg: validation: 0.000000
09/16 07:18:02 AM: edges-pos-ontonotes_mcc: training: 0.644766 validation: 0.640857
09/16 07:18:02 AM: edges-pos-ontonotes_acc: training: 0.472255 validation: 0.452448
09/16 07:18:02 AM: edges-pos-ontonotes_precision: training: 0.825028 validation: 0.861118
09/16 07:18:02 AM: edges-pos-ontonotes_recall: training: 0.512565 validation: 0.484693
09/16 07:18:02 AM: edges-pos-ontonotes_f1: training: 0.632300 validation: 0.620262
09/16 07:18:02 AM: Global learning rate: 0.0001
09/16 07:18:02 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 07:18:12 AM: Update 10066: task edges-pos-ontonotes, batch 66 (10066): mcc: 0.5097, acc: 0.3351, precision: 0.7038, recall: 0.3796, f1: 0.4932, edges-pos-ontonotes_loss: 0.0436
09/16 07:18:22 AM: Update 10127: task edges-pos-ontonotes, batch 127 (10127): mcc: 0.5138, acc: 0.3349, precision: 0.7157, recall: 0.3789, f1: 0.4955, edges-pos-ontonotes_loss: 0.0452
09/16 07:18:32 AM: Update 10187: task edges-pos-ontonotes, batch 187 (10187): mcc: 0.5140, acc: 0.3339, precision: 0.7183, recall: 0.3778, f1: 0.4952, edges-pos-ontonotes_loss: 0.0455
09/16 07:18:42 AM: Update 10252: task edges-pos-ontonotes, batch 252 (10252): mcc: 0.5170, acc: 0.3361, precision: 0.7234, recall: 0.3794, f1: 0.4977, edges-pos-ontonotes_loss: 0.0456
09/16 07:18:52 AM: Update 10315: task edges-pos-ontonotes, batch 315 (10315): mcc: 0.5181, acc: 0.3366, precision: 0.7265, recall: 0.3793, f1: 0.4984, edges-pos-ontonotes_loss: 0.0457
09/16 07:19:02 AM: Update 10373: task edges-pos-ontonotes, batch 373 (10373): mcc: 0.5203, acc: 0.3383, precision: 0.7296, recall: 0.3808, f1: 0.5004, edges-pos-ontonotes_loss: 0.0457
09/16 07:19:12 AM: Update 10445: task edges-pos-ontonotes, batch 445 (10445): mcc: 0.5259, acc: 0.3437, precision: 0.7365, recall: 0.3852, f1: 0.5058, edges-pos-ontonotes_loss: 0.0447
09/16 07:19:22 AM: Update 10533: task edges-pos-ontonotes, batch 533 (10533): mcc: 0.5337, acc: 0.3515, precision: 0.7448, recall: 0.3920, f1: 0.5136, edges-pos-ontonotes_loss: 0.0436
09/16 07:19:32 AM: Update 10619: task edges-pos-ontonotes, batch 619 (10619): mcc: 0.5391, acc: 0.3570, precision: 0.7502, recall: 0.3969, f1: 0.5191, edges-pos-ontonotes_loss: 0.0428
09/16 07:19:42 AM: Update 10690: task edges-pos-ontonotes, batch 690 (10690): mcc: 0.5429, acc: 0.3610, precision: 0.7538, recall: 0.4004, f1: 0.5230, edges-pos-ontonotes_loss: 0.0420
09/16 07:19:52 AM: Update 10737: task edges-pos-ontonotes, batch 737 (10737): mcc: 0.5451, acc: 0.3633, precision: 0.7546, recall: 0.4032, f1: 0.5256, edges-pos-ontonotes_loss: 0.0419
09/16 07:20:02 AM: Update 10785: task edges-pos-ontonotes, batch 785 (10785): mcc: 0.5470, acc: 0.3653, precision: 0.7553, recall: 0.4056, f1: 0.5278, edges-pos-ontonotes_loss: 0.0417
09/16 07:20:12 AM: Update 10844: task edges-pos-ontonotes, batch 844 (10844): mcc: 0.5505, acc: 0.3689, precision: 0.7570, recall: 0.4097, f1: 0.5317, edges-pos-ontonotes_loss: 0.0415
09/16 07:20:22 AM: Update 10897: task edges-pos-ontonotes, batch 897 (10897): mcc: 0.5530, acc: 0.3715, precision: 0.7582, recall: 0.4128, f1: 0.5346, edges-pos-ontonotes_loss: 0.0413
09/16 07:20:33 AM: Update 10950: task edges-pos-ontonotes, batch 950 (10950): mcc: 0.5552, acc: 0.3739, precision: 0.7592, recall: 0.4155, f1: 0.5371, edges-pos-ontonotes_loss: 0.0411
09/16 07:20:41 AM: ***** Step 11000 / Validation 11 *****
09/16 07:20:41 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:20:41 AM: Validating...
09/16 07:20:43 AM: Evaluate: task edges-pos-ontonotes, batch 11 (157): mcc: 0.6885, acc: 0.5152, precision: 0.8754, recall: 0.5491, f1: 0.6749, edges-pos-ontonotes_loss: 0.0320
09/16 07:20:53 AM: Evaluate: task edges-pos-ontonotes, batch 70 (157): mcc: 0.6973, acc: 0.5247, precision: 0.8952, recall: 0.5503, f1: 0.6816, edges-pos-ontonotes_loss: 0.0312
09/16 07:21:03 AM: Evaluate: task edges-pos-ontonotes, batch 115 (157): mcc: 0.6839, acc: 0.5082, precision: 0.8848, recall: 0.5361, f1: 0.6676, edges-pos-ontonotes_loss: 0.0319
09/16 07:21:13 AM: Evaluate: task edges-pos-ontonotes, batch 156 (157): mcc: 0.6667, acc: 0.4854, precision: 0.8757, recall: 0.5151, f1: 0.6487, edges-pos-ontonotes_loss: 0.0333
09/16 07:21:13 AM: Best result seen so far for edges-pos-ontonotes.
09/16 07:21:13 AM: Best result seen so far for macro.
09/16 07:21:13 AM: Updating LR scheduler:
09/16 07:21:13 AM: 	Best result seen so far for macro_avg: 0.649
09/16 07:21:13 AM: 	# validation passes without improvement: 0
09/16 07:21:13 AM: edges-pos-ontonotes_loss: training: 0.040913 validation: 0.033277
09/16 07:21:13 AM: macro_avg: validation: 0.648730
09/16 07:21:13 AM: micro_avg: validation: 0.000000
09/16 07:21:13 AM: edges-pos-ontonotes_mcc: training: 0.557660 validation: 0.666750
09/16 07:21:13 AM: edges-pos-ontonotes_acc: training: 0.376556 validation: 0.485402
09/16 07:21:13 AM: edges-pos-ontonotes_precision: training: 0.760716 validation: 0.875751
09/16 07:21:13 AM: edges-pos-ontonotes_recall: training: 0.418301 validation: 0.515180
09/16 07:21:13 AM: edges-pos-ontonotes_f1: training: 0.539786 validation: 0.648730
09/16 07:21:13 AM: Global learning rate: 0.0001
09/16 07:21:13 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 07:21:23 AM: Update 11037: task edges-pos-ontonotes, batch 37 (11037): mcc: 0.5346, acc: 0.3582, precision: 0.7281, recall: 0.4026, f1: 0.5185, edges-pos-ontonotes_loss: 0.0448
09/16 07:21:33 AM: Update 11084: task edges-pos-ontonotes, batch 84 (11084): mcc: 0.5335, acc: 0.3557, precision: 0.7298, recall: 0.4001, f1: 0.5168, edges-pos-ontonotes_loss: 0.0452
09/16 07:21:44 AM: Update 11128: task edges-pos-ontonotes, batch 128 (11128): mcc: 0.5333, acc: 0.3545, precision: 0.7320, recall: 0.3985, f1: 0.5161, edges-pos-ontonotes_loss: 0.0454
09/16 07:21:54 AM: Update 11171: task edges-pos-ontonotes, batch 171 (11171): mcc: 0.5331, acc: 0.3541, precision: 0.7317, recall: 0.3984, f1: 0.5159, edges-pos-ontonotes_loss: 0.0454
09/16 07:22:04 AM: Update 11220: task edges-pos-ontonotes, batch 220 (11220): mcc: 0.5318, acc: 0.3528, precision: 0.7314, recall: 0.3966, f1: 0.5143, edges-pos-ontonotes_loss: 0.0456
09/16 07:22:14 AM: Update 11265: task edges-pos-ontonotes, batch 265 (11265): mcc: 0.5308, acc: 0.3518, precision: 0.7309, recall: 0.3954, f1: 0.5132, edges-pos-ontonotes_loss: 0.0454
09/16 07:22:24 AM: Update 11314: task edges-pos-ontonotes, batch 314 (11314): mcc: 0.5328, acc: 0.3536, precision: 0.7327, recall: 0.3974, f1: 0.5153, edges-pos-ontonotes_loss: 0.0453
09/16 07:22:36 AM: Update 11320: task edges-pos-ontonotes, batch 320 (11320): mcc: 0.5317, acc: 0.3526, precision: 0.7314, recall: 0.3965, f1: 0.5142, edges-pos-ontonotes_loss: 0.0453
09/16 07:22:46 AM: Update 11365: task edges-pos-ontonotes, batch 365 (11365): mcc: 0.5336, acc: 0.3544, precision: 0.7330, recall: 0.3983, f1: 0.5162, edges-pos-ontonotes_loss: 0.0452
09/16 07:22:56 AM: Update 11410: task edges-pos-ontonotes, batch 410 (11410): mcc: 0.5349, acc: 0.3555, precision: 0.7344, recall: 0.3995, f1: 0.5175, edges-pos-ontonotes_loss: 0.0452
09/16 07:23:06 AM: Update 11450: task edges-pos-ontonotes, batch 450 (11450): mcc: 0.5349, acc: 0.3556, precision: 0.7345, recall: 0.3994, f1: 0.5175, edges-pos-ontonotes_loss: 0.0452
09/16 07:23:16 AM: Update 11492: task edges-pos-ontonotes, batch 492 (11492): mcc: 0.5355, acc: 0.3562, precision: 0.7356, recall: 0.3997, f1: 0.5179, edges-pos-ontonotes_loss: 0.0452
09/16 07:23:26 AM: Update 11535: task edges-pos-ontonotes, batch 535 (11535): mcc: 0.5368, acc: 0.3574, precision: 0.7372, recall: 0.4007, f1: 0.5192, edges-pos-ontonotes_loss: 0.0451
09/16 07:23:36 AM: Update 11580: task edges-pos-ontonotes, batch 580 (11580): mcc: 0.5376, acc: 0.3583, precision: 0.7381, recall: 0.4014, f1: 0.5200, edges-pos-ontonotes_loss: 0.0450
09/16 07:23:47 AM: Update 11623: task edges-pos-ontonotes, batch 623 (11623): mcc: 0.5386, acc: 0.3592, precision: 0.7393, recall: 0.4022, f1: 0.5210, edges-pos-ontonotes_loss: 0.0449
09/16 07:23:57 AM: Update 11662: task edges-pos-ontonotes, batch 662 (11662): mcc: 0.5393, acc: 0.3597, precision: 0.7401, recall: 0.4027, f1: 0.5216, edges-pos-ontonotes_loss: 0.0449
09/16 07:24:07 AM: Update 11708: task edges-pos-ontonotes, batch 708 (11708): mcc: 0.5395, acc: 0.3599, precision: 0.7407, recall: 0.4028, f1: 0.5218, edges-pos-ontonotes_loss: 0.0449
09/16 07:24:17 AM: Update 11754: task edges-pos-ontonotes, batch 754 (11754): mcc: 0.5408, acc: 0.3611, precision: 0.7422, recall: 0.4039, f1: 0.5231, edges-pos-ontonotes_loss: 0.0448
09/16 07:24:27 AM: Update 11799: task edges-pos-ontonotes, batch 799 (11799): mcc: 0.5423, acc: 0.3625, precision: 0.7437, recall: 0.4052, f1: 0.5245, edges-pos-ontonotes_loss: 0.0447
09/16 07:24:38 AM: Update 11844: task edges-pos-ontonotes, batch 844 (11844): mcc: 0.5433, acc: 0.3635, precision: 0.7446, recall: 0.4061, f1: 0.5256, edges-pos-ontonotes_loss: 0.0446
09/16 07:24:48 AM: Update 11888: task edges-pos-ontonotes, batch 888 (11888): mcc: 0.5433, acc: 0.3635, precision: 0.7447, recall: 0.4061, f1: 0.5256, edges-pos-ontonotes_loss: 0.0446
09/16 07:24:58 AM: Update 11942: task edges-pos-ontonotes, batch 942 (11942): mcc: 0.5441, acc: 0.3643, precision: 0.7455, recall: 0.4069, f1: 0.5264, edges-pos-ontonotes_loss: 0.0446
09/16 07:25:08 AM: Update 11986: task edges-pos-ontonotes, batch 986 (11986): mcc: 0.5442, acc: 0.3644, precision: 0.7455, recall: 0.4069, f1: 0.5265, edges-pos-ontonotes_loss: 0.0446
09/16 07:25:11 AM: ***** Step 12000 / Validation 12 *****
09/16 07:25:11 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:25:11 AM: Validating...
09/16 07:25:18 AM: Evaluate: task edges-pos-ontonotes, batch 52 (157): mcc: 0.6765, acc: 0.4915, precision: 0.9101, recall: 0.5098, f1: 0.6535, edges-pos-ontonotes_loss: 0.0338
09/16 07:25:28 AM: Evaluate: task edges-pos-ontonotes, batch 111 (157): mcc: 0.6803, acc: 0.4989, precision: 0.9042, recall: 0.5188, f1: 0.6593, edges-pos-ontonotes_loss: 0.0324
09/16 07:25:38 AM: Updating LR scheduler:
09/16 07:25:38 AM: 	Best result seen so far for macro_avg: 0.649
09/16 07:25:38 AM: 	# validation passes without improvement: 1
09/16 07:25:38 AM: edges-pos-ontonotes_loss: training: 0.044553 validation: 0.033264
09/16 07:25:38 AM: macro_avg: validation: 0.643800
09/16 07:25:38 AM: micro_avg: validation: 0.000000
09/16 07:25:38 AM: edges-pos-ontonotes_mcc: training: 0.544168 validation: 0.666307
09/16 07:25:38 AM: edges-pos-ontonotes_acc: training: 0.364382 validation: 0.480735
09/16 07:25:38 AM: edges-pos-ontonotes_precision: training: 0.745560 validation: 0.896823
09/16 07:25:38 AM: edges-pos-ontonotes_recall: training: 0.406902 validation: 0.502132
09/16 07:25:38 AM: edges-pos-ontonotes_f1: training: 0.526473 validation: 0.643800
09/16 07:25:38 AM: Global learning rate: 0.0001
09/16 07:25:38 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 07:25:38 AM: Update 12001: task edges-pos-ontonotes, batch 1 (12001): mcc: 0.6773, acc: 0.5057, precision: 0.8670, recall: 0.5369, f1: 0.6632, edges-pos-ontonotes_loss: 0.0345
09/16 07:25:48 AM: Update 12058: task edges-pos-ontonotes, batch 58 (12058): mcc: 0.5562, acc: 0.3766, precision: 0.7585, recall: 0.4174, f1: 0.5385, edges-pos-ontonotes_loss: 0.0439
09/16 07:25:58 AM: Update 12115: task edges-pos-ontonotes, batch 115 (12115): mcc: 0.5590, acc: 0.3792, precision: 0.7616, recall: 0.4198, f1: 0.5412, edges-pos-ontonotes_loss: 0.0436
09/16 07:26:08 AM: Update 12176: task edges-pos-ontonotes, batch 176 (12176): mcc: 0.5608, acc: 0.3808, precision: 0.7631, recall: 0.4216, f1: 0.5431, edges-pos-ontonotes_loss: 0.0433
09/16 07:26:19 AM: Update 12234: task edges-pos-ontonotes, batch 234 (12234): mcc: 0.5632, acc: 0.3833, precision: 0.7660, recall: 0.4235, f1: 0.5455, edges-pos-ontonotes_loss: 0.0433
09/16 07:26:29 AM: Update 12277: task edges-pos-ontonotes, batch 277 (12277): mcc: 0.5568, acc: 0.3775, precision: 0.7588, recall: 0.4181, f1: 0.5391, edges-pos-ontonotes_loss: 0.0433
09/16 07:26:39 AM: Update 12347: task edges-pos-ontonotes, batch 347 (12347): mcc: 0.5594, acc: 0.3801, precision: 0.7597, recall: 0.4214, f1: 0.5421, edges-pos-ontonotes_loss: 0.0424
09/16 07:26:49 AM: Update 12422: task edges-pos-ontonotes, batch 422 (12422): mcc: 0.5626, acc: 0.3835, precision: 0.7616, recall: 0.4252, f1: 0.5457, edges-pos-ontonotes_loss: 0.0416
09/16 07:26:59 AM: Update 12492: task edges-pos-ontonotes, batch 492 (12492): mcc: 0.5640, acc: 0.3852, precision: 0.7620, recall: 0.4269, f1: 0.5473, edges-pos-ontonotes_loss: 0.0411
09/16 07:27:10 AM: Update 12557: task edges-pos-ontonotes, batch 557 (12557): mcc: 0.5638, acc: 0.3854, precision: 0.7609, recall: 0.4273, f1: 0.5473, edges-pos-ontonotes_loss: 0.0409
09/16 07:27:20 AM: Update 12627: task edges-pos-ontonotes, batch 627 (12627): mcc: 0.5714, acc: 0.3931, precision: 0.7668, recall: 0.4353, f1: 0.5554, edges-pos-ontonotes_loss: 0.0401
09/16 07:27:30 AM: Update 12722: task edges-pos-ontonotes, batch 722 (12722): mcc: 0.5826, acc: 0.4045, precision: 0.7754, recall: 0.4472, f1: 0.5672, edges-pos-ontonotes_loss: 0.0390
09/16 07:27:40 AM: Update 12811: task edges-pos-ontonotes, batch 811 (12811): mcc: 0.5917, acc: 0.4141, precision: 0.7822, recall: 0.4569, f1: 0.5769, edges-pos-ontonotes_loss: 0.0382
09/16 07:27:50 AM: Update 12896: task edges-pos-ontonotes, batch 896 (12896): mcc: 0.5984, acc: 0.4213, precision: 0.7871, recall: 0.4642, f1: 0.5840, edges-pos-ontonotes_loss: 0.0375
09/16 07:27:59 AM: ***** Step 13000 / Validation 13 *****
09/16 07:27:59 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:27:59 AM: Validating...
09/16 07:28:00 AM: Evaluate: task edges-pos-ontonotes, batch 6 (157): mcc: 0.6979, acc: 0.5257, precision: 0.8937, recall: 0.5523, f1: 0.6827, edges-pos-ontonotes_loss: 0.0299
09/16 07:28:10 AM: Evaluate: task edges-pos-ontonotes, batch 77 (157): mcc: 0.7041, acc: 0.5339, precision: 0.9071, recall: 0.5535, f1: 0.6875, edges-pos-ontonotes_loss: 0.0308
09/16 07:28:20 AM: Evaluate: task edges-pos-ontonotes, batch 128 (157): mcc: 0.6766, acc: 0.4984, precision: 0.8944, recall: 0.5190, f1: 0.6568, edges-pos-ontonotes_loss: 0.0324
09/16 07:28:26 AM: Best result seen so far for edges-pos-ontonotes.
09/16 07:28:26 AM: Best result seen so far for macro.
09/16 07:28:26 AM: Updating LR scheduler:
09/16 07:28:26 AM: 	Best result seen so far for macro_avg: 0.650
09/16 07:28:26 AM: 	# validation passes without improvement: 0
09/16 07:28:26 AM: edges-pos-ontonotes_loss: training: 0.036937 validation: 0.033054
09/16 07:28:26 AM: macro_avg: validation: 0.650043
09/16 07:28:26 AM: micro_avg: validation: 0.000000
09/16 07:28:26 AM: edges-pos-ontonotes_mcc: training: 0.605017 validation: 0.670516
09/16 07:28:26 AM: edges-pos-ontonotes_acc: training: 0.428680 validation: 0.490248
09/16 07:28:26 AM: edges-pos-ontonotes_precision: training: 0.791947 validation: 0.891588
09/16 07:28:26 AM: edges-pos-ontonotes_recall: training: 0.471445 validation: 0.511477
09/16 07:28:26 AM: edges-pos-ontonotes_f1: training: 0.591043 validation: 0.650043
09/16 07:28:26 AM: Global learning rate: 0.0001
09/16 07:28:26 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 07:28:30 AM: Update 13043: task edges-pos-ontonotes, batch 43 (13043): mcc: 0.6942, acc: 0.5374, precision: 0.8428, recall: 0.5802, f1: 0.6872, edges-pos-ontonotes_loss: 0.0316
09/16 07:28:40 AM: Update 13149: task edges-pos-ontonotes, batch 149 (13149): mcc: 0.6961, acc: 0.5375, precision: 0.8469, recall: 0.5804, f1: 0.6888, edges-pos-ontonotes_loss: 0.0319
09/16 07:28:50 AM: Update 13261: task edges-pos-ontonotes, batch 261 (13261): mcc: 0.6721, acc: 0.5089, precision: 0.8316, recall: 0.5518, f1: 0.6634, edges-pos-ontonotes_loss: 0.0336
09/16 07:29:00 AM: Update 13389: task edges-pos-ontonotes, batch 389 (13389): mcc: 0.6484, acc: 0.4813, precision: 0.8166, recall: 0.5237, f1: 0.6381, edges-pos-ontonotes_loss: 0.0356
09/16 07:29:19 AM: Update 13511: task edges-pos-ontonotes, batch 511 (13511): mcc: 0.6333, acc: 0.4651, precision: 0.8045, recall: 0.5077, f1: 0.6225, edges-pos-ontonotes_loss: 0.0363
09/16 07:29:29 AM: Update 13572: task edges-pos-ontonotes, batch 572 (13572): mcc: 0.6116, acc: 0.4399, precision: 0.7883, recall: 0.4839, f1: 0.5997, edges-pos-ontonotes_loss: 0.0373
09/16 07:29:39 AM: Update 13634: task edges-pos-ontonotes, batch 634 (13634): mcc: 0.5979, acc: 0.4240, precision: 0.7794, recall: 0.4682, f1: 0.5850, edges-pos-ontonotes_loss: 0.0381
09/16 07:29:49 AM: Update 13697: task edges-pos-ontonotes, batch 697 (13697): mcc: 0.5890, acc: 0.4137, precision: 0.7736, recall: 0.4580, f1: 0.5754, edges-pos-ontonotes_loss: 0.0387
09/16 07:29:59 AM: Update 13757: task edges-pos-ontonotes, batch 757 (13757): mcc: 0.5808, acc: 0.4044, precision: 0.7674, recall: 0.4491, f1: 0.5666, edges-pos-ontonotes_loss: 0.0392
09/16 07:30:09 AM: Update 13820: task edges-pos-ontonotes, batch 820 (13820): mcc: 0.5743, acc: 0.3973, precision: 0.7628, recall: 0.4421, f1: 0.5598, edges-pos-ontonotes_loss: 0.0397
09/16 07:30:19 AM: Update 13882: task edges-pos-ontonotes, batch 882 (13882): mcc: 0.5721, acc: 0.3947, precision: 0.7624, recall: 0.4390, f1: 0.5572, edges-pos-ontonotes_loss: 0.0398
09/16 07:30:29 AM: Update 13973: task edges-pos-ontonotes, batch 973 (13973): mcc: 0.5734, acc: 0.3958, precision: 0.7650, recall: 0.4394, f1: 0.5582, edges-pos-ontonotes_loss: 0.0396
09/16 07:30:32 AM: ***** Step 14000 / Validation 14 *****
09/16 07:30:32 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:30:32 AM: Validating...
09/16 07:30:39 AM: Evaluate: task edges-pos-ontonotes, batch 48 (157): mcc: 0.6892, acc: 0.5076, precision: 0.9143, recall: 0.5263, f1: 0.6680, edges-pos-ontonotes_loss: 0.0309
09/16 07:30:49 AM: Evaluate: task edges-pos-ontonotes, batch 109 (157): mcc: 0.6848, acc: 0.5037, precision: 0.9067, recall: 0.5242, f1: 0.6643, edges-pos-ontonotes_loss: 0.0305
09/16 07:30:59 AM: Evaluate: task edges-pos-ontonotes, batch 155 (157): mcc: 0.6597, acc: 0.4713, precision: 0.8937, recall: 0.4941, f1: 0.6364, edges-pos-ontonotes_loss: 0.0323
09/16 07:31:00 AM: Updating LR scheduler:
09/16 07:31:00 AM: 	Best result seen so far for macro_avg: 0.650
09/16 07:31:00 AM: 	# validation passes without improvement: 1
09/16 07:31:00 AM: edges-pos-ontonotes_loss: training: 0.039502 validation: 0.032364
09/16 07:31:00 AM: macro_avg: validation: 0.636772
09/16 07:31:00 AM: micro_avg: validation: 0.000000
09/16 07:31:00 AM: edges-pos-ontonotes_mcc: training: 0.573660 validation: 0.660045
09/16 07:31:00 AM: edges-pos-ontonotes_acc: training: 0.395949 validation: 0.471634
09/16 07:31:00 AM: edges-pos-ontonotes_precision: training: 0.765704 validation: 0.893798
09/16 07:31:00 AM: edges-pos-ontonotes_recall: training: 0.439381 validation: 0.494555
09/16 07:31:00 AM: edges-pos-ontonotes_f1: training: 0.558360 validation: 0.636772
09/16 07:31:00 AM: Global learning rate: 0.0001
09/16 07:31:00 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 07:31:10 AM: Update 14105: task edges-pos-ontonotes, batch 105 (14105): mcc: 0.6180, acc: 0.4416, precision: 0.8155, recall: 0.4771, f1: 0.6020, edges-pos-ontonotes_loss: 0.0352
09/16 07:31:20 AM: Update 14171: task edges-pos-ontonotes, batch 171 (14171): mcc: 0.6005, acc: 0.4235, precision: 0.7969, recall: 0.4616, f1: 0.5846, edges-pos-ontonotes_loss: 0.0363
09/16 07:31:30 AM: Update 14251: task edges-pos-ontonotes, batch 251 (14251): mcc: 0.5999, acc: 0.4233, precision: 0.7874, recall: 0.4663, f1: 0.5857, edges-pos-ontonotes_loss: 0.0367
09/16 07:31:40 AM: Update 14325: task edges-pos-ontonotes, batch 325 (14325): mcc: 0.5995, acc: 0.4234, precision: 0.7840, recall: 0.4679, f1: 0.5860, edges-pos-ontonotes_loss: 0.0370
09/16 07:31:50 AM: Update 14396: task edges-pos-ontonotes, batch 396 (14396): mcc: 0.5994, acc: 0.4235, precision: 0.7828, recall: 0.4684, f1: 0.5861, edges-pos-ontonotes_loss: 0.0371
09/16 07:32:00 AM: Update 14465: task edges-pos-ontonotes, batch 465 (14465): mcc: 0.5983, acc: 0.4224, precision: 0.7806, recall: 0.4681, f1: 0.5852, edges-pos-ontonotes_loss: 0.0372
09/16 07:32:10 AM: Update 14511: task edges-pos-ontonotes, batch 511 (14511): mcc: 0.5903, acc: 0.4140, precision: 0.7735, recall: 0.4601, f1: 0.5770, edges-pos-ontonotes_loss: 0.0379
09/16 07:32:20 AM: Update 14573: task edges-pos-ontonotes, batch 573 (14573): mcc: 0.5831, acc: 0.4063, precision: 0.7676, recall: 0.4527, f1: 0.5695, edges-pos-ontonotes_loss: 0.0387
09/16 07:32:30 AM: Update 14635: task edges-pos-ontonotes, batch 635 (14635): mcc: 0.5793, acc: 0.4021, precision: 0.7647, recall: 0.4486, f1: 0.5654, edges-pos-ontonotes_loss: 0.0392
09/16 07:32:40 AM: Update 14690: task edges-pos-ontonotes, batch 690 (14690): mcc: 0.5749, acc: 0.3976, precision: 0.7610, recall: 0.4442, f1: 0.5609, edges-pos-ontonotes_loss: 0.0396
09/16 07:32:51 AM: Update 14746: task edges-pos-ontonotes, batch 746 (14746): mcc: 0.5719, acc: 0.3942, precision: 0.7591, recall: 0.4406, f1: 0.5576, edges-pos-ontonotes_loss: 0.0400
09/16 07:33:01 AM: Update 14791: task edges-pos-ontonotes, batch 791 (14791): mcc: 0.5695, acc: 0.3916, precision: 0.7572, recall: 0.4381, f1: 0.5551, edges-pos-ontonotes_loss: 0.0402
09/16 07:33:11 AM: Update 14845: task edges-pos-ontonotes, batch 845 (14845): mcc: 0.5675, acc: 0.3895, precision: 0.7558, recall: 0.4360, f1: 0.5530, edges-pos-ontonotes_loss: 0.0405
09/16 07:33:21 AM: Update 14904: task edges-pos-ontonotes, batch 904 (14904): mcc: 0.5671, acc: 0.3890, precision: 0.7555, recall: 0.4354, f1: 0.5525, edges-pos-ontonotes_loss: 0.0407
09/16 07:33:31 AM: Update 14955: task edges-pos-ontonotes, batch 955 (14955): mcc: 0.5654, acc: 0.3873, precision: 0.7542, recall: 0.4337, f1: 0.5507, edges-pos-ontonotes_loss: 0.0409
09/16 07:33:39 AM: ***** Step 15000 / Validation 15 *****
09/16 07:33:39 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:33:39 AM: Validating...
09/16 07:33:41 AM: Evaluate: task edges-pos-ontonotes, batch 17 (157): mcc: 0.6889, acc: 0.5091, precision: 0.9036, recall: 0.5321, f1: 0.6698, edges-pos-ontonotes_loss: 0.0317
09/16 07:33:51 AM: Evaluate: task edges-pos-ontonotes, batch 87 (157): mcc: 0.7019, acc: 0.5274, precision: 0.9112, recall: 0.5475, f1: 0.6840, edges-pos-ontonotes_loss: 0.0307
09/16 07:34:02 AM: Evaluate: task edges-pos-ontonotes, batch 134 (157): mcc: 0.6751, acc: 0.4926, precision: 0.8996, recall: 0.5137, f1: 0.6540, edges-pos-ontonotes_loss: 0.0320
09/16 07:34:06 AM: Best result seen so far for edges-pos-ontonotes.
09/16 07:34:06 AM: Best result seen so far for macro.
09/16 07:34:06 AM: Updating LR scheduler:
09/16 07:34:06 AM: 	Best result seen so far for macro_avg: 0.653
09/16 07:34:06 AM: 	# validation passes without improvement: 0
09/16 07:34:06 AM: edges-pos-ontonotes_loss: training: 0.040965 validation: 0.032225
09/16 07:34:06 AM: macro_avg: validation: 0.652686
09/16 07:34:06 AM: micro_avg: validation: 0.000000
09/16 07:34:06 AM: edges-pos-ontonotes_mcc: training: 0.565564 validation: 0.673965
09/16 07:34:06 AM: edges-pos-ontonotes_acc: training: 0.387440 validation: 0.490841
09/16 07:34:06 AM: edges-pos-ontonotes_precision: training: 0.754497 validation: 0.899047
09/16 07:34:06 AM: edges-pos-ontonotes_recall: training: 0.433761 validation: 0.512302
09/16 07:34:06 AM: edges-pos-ontonotes_f1: training: 0.550842 validation: 0.652686
09/16 07:34:06 AM: Global learning rate: 0.0001
09/16 07:34:06 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 07:34:12 AM: Update 15028: task edges-pos-ontonotes, batch 28 (15028): mcc: 0.5443, acc: 0.3652, precision: 0.7368, recall: 0.4122, f1: 0.5286, edges-pos-ontonotes_loss: 0.0453
09/16 07:34:22 AM: Update 15084: task edges-pos-ontonotes, batch 84 (15084): mcc: 0.5492, acc: 0.3715, precision: 0.7431, recall: 0.4158, f1: 0.5332, edges-pos-ontonotes_loss: 0.0446
09/16 07:34:33 AM: Update 15093: task edges-pos-ontonotes, batch 93 (15093): mcc: 0.5479, acc: 0.3703, precision: 0.7414, recall: 0.4149, f1: 0.5320, edges-pos-ontonotes_loss: 0.0446
09/16 07:34:44 AM: Update 15148: task edges-pos-ontonotes, batch 148 (15148): mcc: 0.5513, acc: 0.3737, precision: 0.7462, recall: 0.4171, f1: 0.5351, edges-pos-ontonotes_loss: 0.0441
09/16 07:34:54 AM: Update 15202: task edges-pos-ontonotes, batch 202 (15202): mcc: 0.5535, acc: 0.3752, precision: 0.7493, recall: 0.4186, f1: 0.5371, edges-pos-ontonotes_loss: 0.0439
09/16 07:35:04 AM: Update 15255: task edges-pos-ontonotes, batch 255 (15255): mcc: 0.5546, acc: 0.3762, precision: 0.7505, recall: 0.4196, f1: 0.5382, edges-pos-ontonotes_loss: 0.0439
09/16 07:35:14 AM: Update 15311: task edges-pos-ontonotes, batch 311 (15311): mcc: 0.5563, acc: 0.3781, precision: 0.7519, recall: 0.4214, f1: 0.5401, edges-pos-ontonotes_loss: 0.0437
09/16 07:35:24 AM: Update 15372: task edges-pos-ontonotes, batch 372 (15372): mcc: 0.5587, acc: 0.3805, precision: 0.7538, recall: 0.4238, f1: 0.5426, edges-pos-ontonotes_loss: 0.0435
09/16 07:35:34 AM: Update 15415: task edges-pos-ontonotes, batch 415 (15415): mcc: 0.5580, acc: 0.3797, precision: 0.7538, recall: 0.4228, f1: 0.5417, edges-pos-ontonotes_loss: 0.0435
09/16 07:35:44 AM: Update 15470: task edges-pos-ontonotes, batch 470 (15470): mcc: 0.5588, acc: 0.3805, precision: 0.7542, recall: 0.4238, f1: 0.5426, edges-pos-ontonotes_loss: 0.0435
09/16 07:35:54 AM: Update 15525: task edges-pos-ontonotes, batch 525 (15525): mcc: 0.5602, acc: 0.3820, precision: 0.7553, recall: 0.4251, f1: 0.5440, edges-pos-ontonotes_loss: 0.0434
09/16 07:36:05 AM: Update 15580: task edges-pos-ontonotes, batch 580 (15580): mcc: 0.5605, acc: 0.3823, precision: 0.7557, recall: 0.4254, f1: 0.5444, edges-pos-ontonotes_loss: 0.0433
09/16 07:36:15 AM: Update 15634: task edges-pos-ontonotes, batch 634 (15634): mcc: 0.5608, acc: 0.3827, precision: 0.7559, recall: 0.4258, f1: 0.5448, edges-pos-ontonotes_loss: 0.0433
09/16 07:36:25 AM: Update 15681: task edges-pos-ontonotes, batch 681 (15681): mcc: 0.5614, acc: 0.3833, precision: 0.7564, recall: 0.4263, f1: 0.5453, edges-pos-ontonotes_loss: 0.0432
09/16 07:36:35 AM: Update 15719: task edges-pos-ontonotes, batch 719 (15719): mcc: 0.5611, acc: 0.3832, precision: 0.7560, recall: 0.4261, f1: 0.5451, edges-pos-ontonotes_loss: 0.0433
09/16 07:36:45 AM: Update 15764: task edges-pos-ontonotes, batch 764 (15764): mcc: 0.5597, acc: 0.3818, precision: 0.7546, recall: 0.4248, f1: 0.5436, edges-pos-ontonotes_loss: 0.0430
09/16 07:36:55 AM: Update 15816: task edges-pos-ontonotes, batch 816 (15816): mcc: 0.5606, acc: 0.3829, precision: 0.7551, recall: 0.4260, f1: 0.5447, edges-pos-ontonotes_loss: 0.0427
09/16 07:37:05 AM: Update 15864: task edges-pos-ontonotes, batch 864 (15864): mcc: 0.5607, acc: 0.3830, precision: 0.7548, recall: 0.4263, f1: 0.5449, edges-pos-ontonotes_loss: 0.0425
09/16 07:37:15 AM: Update 15915: task edges-pos-ontonotes, batch 915 (15915): mcc: 0.5618, acc: 0.3842, precision: 0.7556, recall: 0.4275, f1: 0.5460, edges-pos-ontonotes_loss: 0.0422
09/16 07:37:25 AM: Update 15972: task edges-pos-ontonotes, batch 972 (15972): mcc: 0.5635, acc: 0.3858, precision: 0.7568, recall: 0.4293, f1: 0.5478, edges-pos-ontonotes_loss: 0.0419
09/16 07:37:30 AM: ***** Step 16000 / Validation 16 *****
09/16 07:37:30 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:37:30 AM: Validating...
09/16 07:37:35 AM: Evaluate: task edges-pos-ontonotes, batch 31 (157): mcc: 0.6833, acc: 0.5005, precision: 0.9106, recall: 0.5196, f1: 0.6616, edges-pos-ontonotes_loss: 0.0326
09/16 07:37:45 AM: Evaluate: task edges-pos-ontonotes, batch 88 (157): mcc: 0.6979, acc: 0.5202, precision: 0.9162, recall: 0.5384, f1: 0.6782, edges-pos-ontonotes_loss: 0.0309
09/16 07:37:56 AM: Evaluate: task edges-pos-ontonotes, batch 129 (157): mcc: 0.6746, acc: 0.4910, precision: 0.9030, recall: 0.5110, f1: 0.6527, edges-pos-ontonotes_loss: 0.0320
09/16 07:38:02 AM: Updating LR scheduler:
09/16 07:38:02 AM: 	Best result seen so far for macro_avg: 0.653
09/16 07:38:02 AM: 	# validation passes without improvement: 1
09/16 07:38:02 AM: edges-pos-ontonotes_loss: training: 0.041755 validation: 0.032299
09/16 07:38:02 AM: macro_avg: validation: 0.649305
09/16 07:38:02 AM: micro_avg: validation: 0.000000
09/16 07:38:02 AM: edges-pos-ontonotes_mcc: training: 0.564395 validation: 0.671473
09/16 07:38:02 AM: edges-pos-ontonotes_acc: training: 0.386835 validation: 0.486904
09/16 07:38:02 AM: edges-pos-ontonotes_precision: training: 0.757326 validation: 0.900659
09/16 07:38:02 AM: edges-pos-ontonotes_recall: training: 0.430326 validation: 0.507635
09/16 07:38:02 AM: edges-pos-ontonotes_f1: training: 0.548809 validation: 0.649305
09/16 07:38:02 AM: Global learning rate: 0.0001
09/16 07:38:02 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 07:38:06 AM: Update 16020: task edges-pos-ontonotes, batch 20 (16020): mcc: 0.5854, acc: 0.4092, precision: 0.7756, recall: 0.4512, f1: 0.5705, edges-pos-ontonotes_loss: 0.0383
09/16 07:38:16 AM: Update 16077: task edges-pos-ontonotes, batch 77 (16077): mcc: 0.6268, acc: 0.4529, precision: 0.8029, recall: 0.4984, f1: 0.6150, edges-pos-ontonotes_loss: 0.0346
09/16 07:38:26 AM: Update 16143: task edges-pos-ontonotes, batch 143 (16143): mcc: 0.6550, acc: 0.4838, precision: 0.8242, recall: 0.5294, f1: 0.6447, edges-pos-ontonotes_loss: 0.0327
09/16 07:38:36 AM: Update 16211: task edges-pos-ontonotes, batch 211 (16211): mcc: 0.6694, acc: 0.5002, precision: 0.8334, recall: 0.5463, f1: 0.6600, edges-pos-ontonotes_loss: 0.0320
09/16 07:38:46 AM: Update 16282: task edges-pos-ontonotes, batch 282 (16282): mcc: 0.6773, acc: 0.5095, precision: 0.8387, recall: 0.5554, f1: 0.6683, edges-pos-ontonotes_loss: 0.0316
09/16 07:38:57 AM: Update 16345: task edges-pos-ontonotes, batch 345 (16345): mcc: 0.6790, acc: 0.5116, precision: 0.8394, recall: 0.5578, f1: 0.6702, edges-pos-ontonotes_loss: 0.0315
09/16 07:39:07 AM: Update 16420: task edges-pos-ontonotes, batch 420 (16420): mcc: 0.6801, acc: 0.5136, precision: 0.8395, recall: 0.5594, f1: 0.6714, edges-pos-ontonotes_loss: 0.0317
09/16 07:39:17 AM: Update 16500: task edges-pos-ontonotes, batch 500 (16500): mcc: 0.6835, acc: 0.5181, precision: 0.8419, recall: 0.5633, f1: 0.6750, edges-pos-ontonotes_loss: 0.0315
09/16 07:39:28 AM: Update 16571: task edges-pos-ontonotes, batch 571 (16571): mcc: 0.6858, acc: 0.5214, precision: 0.8423, recall: 0.5667, f1: 0.6776, edges-pos-ontonotes_loss: 0.0315
09/16 07:39:38 AM: Update 16651: task edges-pos-ontonotes, batch 651 (16651): mcc: 0.6884, acc: 0.5247, precision: 0.8439, recall: 0.5699, f1: 0.6803, edges-pos-ontonotes_loss: 0.0313
09/16 07:39:48 AM: Update 16729: task edges-pos-ontonotes, batch 729 (16729): mcc: 0.6804, acc: 0.5158, precision: 0.8382, recall: 0.5608, f1: 0.6720, edges-pos-ontonotes_loss: 0.0322
09/16 07:39:58 AM: Update 16823: task edges-pos-ontonotes, batch 823 (16823): mcc: 0.6752, acc: 0.5097, precision: 0.8352, recall: 0.5544, f1: 0.6664, edges-pos-ontonotes_loss: 0.0330
09/16 07:40:08 AM: Update 16926: task edges-pos-ontonotes, batch 926 (16926): mcc: 0.6702, acc: 0.5038, precision: 0.8322, recall: 0.5483, f1: 0.6611, edges-pos-ontonotes_loss: 0.0335
09/16 07:40:18 AM: Update 16981: task edges-pos-ontonotes, batch 981 (16981): mcc: 0.6593, acc: 0.4921, precision: 0.8234, recall: 0.5367, f1: 0.6498, edges-pos-ontonotes_loss: 0.0339
09/16 07:40:23 AM: ***** Step 17000 / Validation 17 *****
09/16 07:40:23 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:40:23 AM: Validating...
09/16 07:40:28 AM: Evaluate: task edges-pos-ontonotes, batch 35 (157): mcc: 0.6884, acc: 0.5066, precision: 0.9054, recall: 0.5303, f1: 0.6689, edges-pos-ontonotes_loss: 0.0316
09/16 07:40:39 AM: Evaluate: task edges-pos-ontonotes, batch 90 (157): mcc: 0.7045, acc: 0.5296, precision: 0.9099, recall: 0.5524, f1: 0.6875, edges-pos-ontonotes_loss: 0.0300
09/16 07:40:49 AM: Evaluate: task edges-pos-ontonotes, batch 130 (157): mcc: 0.6738, acc: 0.4895, precision: 0.8935, recall: 0.5152, f1: 0.6536, edges-pos-ontonotes_loss: 0.0318
09/16 07:40:55 AM: Updating LR scheduler:
09/16 07:40:55 AM: 	Best result seen so far for macro_avg: 0.653
09/16 07:40:55 AM: 	# validation passes without improvement: 2
09/16 07:40:55 AM: edges-pos-ontonotes_loss: training: 0.034102 validation: 0.032270
09/16 07:40:55 AM: macro_avg: validation: 0.648814
09/16 07:40:55 AM: micro_avg: validation: 0.000000
09/16 07:40:55 AM: edges-pos-ontonotes_mcc: training: 0.654451 validation: 0.669237
09/16 07:40:55 AM: edges-pos-ontonotes_acc: training: 0.486612 validation: 0.483962
09/16 07:40:55 AM: edges-pos-ontonotes_precision: training: 0.819418 validation: 0.890016
09/16 07:40:55 AM: edges-pos-ontonotes_recall: training: 0.531576 validation: 0.510471
09/16 07:40:55 AM: edges-pos-ontonotes_f1: training: 0.644833 validation: 0.648814
09/16 07:40:55 AM: Global learning rate: 0.0001
09/16 07:40:55 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 07:40:59 AM: Update 17019: task edges-pos-ontonotes, batch 19 (17019): mcc: 0.5504, acc: 0.3699, precision: 0.7402, recall: 0.4192, f1: 0.5353, edges-pos-ontonotes_loss: 0.0436
09/16 07:41:09 AM: Update 17069: task edges-pos-ontonotes, batch 69 (17069): mcc: 0.5451, acc: 0.3662, precision: 0.7365, recall: 0.4134, f1: 0.5296, edges-pos-ontonotes_loss: 0.0438
09/16 07:41:19 AM: Update 17116: task edges-pos-ontonotes, batch 116 (17116): mcc: 0.5356, acc: 0.3563, precision: 0.7279, recall: 0.4042, f1: 0.5198, edges-pos-ontonotes_loss: 0.0448
09/16 07:41:29 AM: Update 17164: task edges-pos-ontonotes, batch 164 (17164): mcc: 0.5326, acc: 0.3534, precision: 0.7259, recall: 0.4009, f1: 0.5165, edges-pos-ontonotes_loss: 0.0450
09/16 07:41:39 AM: Update 17216: task edges-pos-ontonotes, batch 216 (17216): mcc: 0.5366, acc: 0.3570, precision: 0.7297, recall: 0.4047, f1: 0.5207, edges-pos-ontonotes_loss: 0.0447
09/16 07:41:49 AM: Update 17264: task edges-pos-ontonotes, batch 264 (17264): mcc: 0.5355, acc: 0.3557, precision: 0.7294, recall: 0.4033, f1: 0.5194, edges-pos-ontonotes_loss: 0.0448
09/16 07:42:05 AM: Update 17301: task edges-pos-ontonotes, batch 301 (17301): mcc: 0.5371, acc: 0.3570, precision: 0.7313, recall: 0.4045, f1: 0.5209, edges-pos-ontonotes_loss: 0.0447
09/16 07:42:15 AM: Update 17367: task edges-pos-ontonotes, batch 367 (17367): mcc: 0.5420, acc: 0.3619, precision: 0.7376, recall: 0.4082, f1: 0.5256, edges-pos-ontonotes_loss: 0.0434
09/16 07:42:26 AM: Update 17440: task edges-pos-ontonotes, batch 440 (17440): mcc: 0.5501, acc: 0.3702, precision: 0.7461, recall: 0.4155, f1: 0.5337, edges-pos-ontonotes_loss: 0.0421
09/16 07:42:36 AM: Update 17506: task edges-pos-ontonotes, batch 506 (17506): mcc: 0.5541, acc: 0.3746, precision: 0.7502, recall: 0.4191, f1: 0.5378, edges-pos-ontonotes_loss: 0.0415
09/16 07:42:46 AM: Update 17574: task edges-pos-ontonotes, batch 574 (17574): mcc: 0.5589, acc: 0.3796, precision: 0.7546, recall: 0.4237, f1: 0.5427, edges-pos-ontonotes_loss: 0.0407
09/16 07:42:56 AM: Update 17630: task edges-pos-ontonotes, batch 630 (17630): mcc: 0.5605, acc: 0.3814, precision: 0.7558, recall: 0.4253, f1: 0.5443, edges-pos-ontonotes_loss: 0.0403
09/16 07:43:06 AM: Update 17690: task edges-pos-ontonotes, batch 690 (17690): mcc: 0.5652, acc: 0.3864, precision: 0.7583, recall: 0.4310, f1: 0.5496, edges-pos-ontonotes_loss: 0.0400
09/16 07:43:16 AM: Update 17747: task edges-pos-ontonotes, batch 747 (17747): mcc: 0.5683, acc: 0.3897, precision: 0.7600, recall: 0.4346, f1: 0.5530, edges-pos-ontonotes_loss: 0.0397
09/16 07:43:26 AM: Update 17801: task edges-pos-ontonotes, batch 801 (17801): mcc: 0.5710, acc: 0.3925, precision: 0.7613, recall: 0.4379, f1: 0.5560, edges-pos-ontonotes_loss: 0.0396
09/16 07:43:36 AM: Update 17848: task edges-pos-ontonotes, batch 848 (17848): mcc: 0.5718, acc: 0.3935, precision: 0.7612, recall: 0.4392, f1: 0.5570, edges-pos-ontonotes_loss: 0.0396
09/16 07:43:46 AM: Update 17908: task edges-pos-ontonotes, batch 908 (17908): mcc: 0.5743, acc: 0.3961, precision: 0.7628, recall: 0.4421, f1: 0.5597, edges-pos-ontonotes_loss: 0.0394
09/16 07:43:56 AM: Update 17945: task edges-pos-ontonotes, batch 945 (17945): mcc: 0.5725, acc: 0.3945, precision: 0.7608, recall: 0.4405, f1: 0.5579, edges-pos-ontonotes_loss: 0.0395
09/16 07:44:07 AM: Update 17995: task edges-pos-ontonotes, batch 995 (17995): mcc: 0.5705, acc: 0.3926, precision: 0.7588, recall: 0.4388, f1: 0.5560, edges-pos-ontonotes_loss: 0.0398
09/16 07:44:07 AM: ***** Step 18000 / Validation 18 *****
09/16 07:44:07 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:44:07 AM: Validating...
09/16 07:44:17 AM: Evaluate: task edges-pos-ontonotes, batch 67 (157): mcc: 0.7094, acc: 0.5348, precision: 0.9215, recall: 0.5527, f1: 0.6910, edges-pos-ontonotes_loss: 0.0295
09/16 07:44:27 AM: Evaluate: task edges-pos-ontonotes, batch 120 (157): mcc: 0.6932, acc: 0.5142, precision: 0.9117, recall: 0.5339, f1: 0.6734, edges-pos-ontonotes_loss: 0.0301
09/16 07:44:34 AM: Best result seen so far for edges-pos-ontonotes.
09/16 07:44:34 AM: Best result seen so far for macro.
09/16 07:44:34 AM: Updating LR scheduler:
09/16 07:44:34 AM: 	Best result seen so far for macro_avg: 0.656
09/16 07:44:34 AM: 	# validation passes without improvement: 0
09/16 07:44:34 AM: edges-pos-ontonotes_loss: training: 0.039815 validation: 0.031231
09/16 07:44:34 AM: macro_avg: validation: 0.656185
09/16 07:44:34 AM: micro_avg: validation: 0.000000
09/16 07:44:34 AM: edges-pos-ontonotes_mcc: training: 0.570623 validation: 0.678055
09/16 07:44:34 AM: edges-pos-ontonotes_acc: training: 0.392671 validation: 0.494301
09/16 07:44:34 AM: edges-pos-ontonotes_precision: training: 0.758900 validation: 0.906143
09/16 07:44:34 AM: edges-pos-ontonotes_recall: training: 0.438819 validation: 0.514313
09/16 07:44:34 AM: edges-pos-ontonotes_f1: training: 0.556090 validation: 0.656185
09/16 07:44:34 AM: Global learning rate: 0.0001
09/16 07:44:34 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 07:44:37 AM: Update 18012: task edges-pos-ontonotes, batch 12 (18012): mcc: 0.5380, acc: 0.3609, precision: 0.7287, recall: 0.4073, f1: 0.5226, edges-pos-ontonotes_loss: 0.0436
09/16 07:44:47 AM: Update 18067: task edges-pos-ontonotes, batch 67 (18067): mcc: 0.5447, acc: 0.3673, precision: 0.7352, recall: 0.4136, f1: 0.5294, edges-pos-ontonotes_loss: 0.0437
09/16 07:44:57 AM: Update 18128: task edges-pos-ontonotes, batch 128 (18128): mcc: 0.5419, acc: 0.3637, precision: 0.7317, recall: 0.4114, f1: 0.5267, edges-pos-ontonotes_loss: 0.0443
09/16 07:45:07 AM: Update 18187: task edges-pos-ontonotes, batch 187 (18187): mcc: 0.5483, acc: 0.3699, precision: 0.7372, recall: 0.4179, f1: 0.5334, edges-pos-ontonotes_loss: 0.0438
09/16 07:45:17 AM: Update 18240: task edges-pos-ontonotes, batch 240 (18240): mcc: 0.5491, acc: 0.3711, precision: 0.7372, recall: 0.4191, f1: 0.5344, edges-pos-ontonotes_loss: 0.0437
09/16 07:45:27 AM: Update 18296: task edges-pos-ontonotes, batch 296 (18296): mcc: 0.5507, acc: 0.3726, precision: 0.7388, recall: 0.4205, f1: 0.5360, edges-pos-ontonotes_loss: 0.0436
09/16 07:45:37 AM: Update 18349: task edges-pos-ontonotes, batch 349 (18349): mcc: 0.5510, acc: 0.3728, precision: 0.7398, recall: 0.4204, f1: 0.5361, edges-pos-ontonotes_loss: 0.0438
09/16 07:45:48 AM: Update 18405: task edges-pos-ontonotes, batch 405 (18405): mcc: 0.5515, acc: 0.3735, precision: 0.7407, recall: 0.4207, f1: 0.5366, edges-pos-ontonotes_loss: 0.0437
09/16 07:45:58 AM: Update 18457: task edges-pos-ontonotes, batch 457 (18457): mcc: 0.5524, acc: 0.3746, precision: 0.7417, recall: 0.4214, f1: 0.5375, edges-pos-ontonotes_loss: 0.0437
09/16 07:46:08 AM: Update 18517: task edges-pos-ontonotes, batch 517 (18517): mcc: 0.5541, acc: 0.3762, precision: 0.7435, recall: 0.4228, f1: 0.5391, edges-pos-ontonotes_loss: 0.0435
09/16 07:46:18 AM: Update 18557: task edges-pos-ontonotes, batch 557 (18557): mcc: 0.5535, acc: 0.3758, precision: 0.7431, recall: 0.4223, f1: 0.5386, edges-pos-ontonotes_loss: 0.0436
09/16 07:46:28 AM: Update 18620: task edges-pos-ontonotes, batch 620 (18620): mcc: 0.5556, acc: 0.3779, precision: 0.7452, recall: 0.4241, f1: 0.5406, edges-pos-ontonotes_loss: 0.0434
09/16 07:46:38 AM: Update 18678: task edges-pos-ontonotes, batch 678 (18678): mcc: 0.5564, acc: 0.3788, precision: 0.7463, recall: 0.4248, f1: 0.5414, edges-pos-ontonotes_loss: 0.0434
09/16 07:46:48 AM: Update 18737: task edges-pos-ontonotes, batch 737 (18737): mcc: 0.5575, acc: 0.3799, precision: 0.7473, recall: 0.4258, f1: 0.5425, edges-pos-ontonotes_loss: 0.0433
09/16 07:46:58 AM: Update 18794: task edges-pos-ontonotes, batch 794 (18794): mcc: 0.5580, acc: 0.3803, precision: 0.7481, recall: 0.4262, f1: 0.5430, edges-pos-ontonotes_loss: 0.0433
09/16 07:47:08 AM: Update 18850: task edges-pos-ontonotes, batch 850 (18850): mcc: 0.5585, acc: 0.3808, precision: 0.7488, recall: 0.4264, f1: 0.5434, edges-pos-ontonotes_loss: 0.0433
09/16 07:47:19 AM: Update 18893: task edges-pos-ontonotes, batch 893 (18893): mcc: 0.5579, acc: 0.3802, precision: 0.7486, recall: 0.4257, f1: 0.5427, edges-pos-ontonotes_loss: 0.0433
09/16 07:47:29 AM: Update 18952: task edges-pos-ontonotes, batch 952 (18952): mcc: 0.5591, acc: 0.3813, precision: 0.7496, recall: 0.4268, f1: 0.5439, edges-pos-ontonotes_loss: 0.0432
09/16 07:47:37 AM: ***** Step 19000 / Validation 19 *****
09/16 07:47:37 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:47:37 AM: Validating...
09/16 07:47:39 AM: Evaluate: task edges-pos-ontonotes, batch 11 (157): mcc: 0.7046, acc: 0.5295, precision: 0.9066, recall: 0.5545, f1: 0.6881, edges-pos-ontonotes_loss: 0.0305
09/16 07:47:49 AM: Evaluate: task edges-pos-ontonotes, batch 82 (157): mcc: 0.7091, acc: 0.5357, precision: 0.9133, recall: 0.5575, f1: 0.6923, edges-pos-ontonotes_loss: 0.0303
09/16 07:47:59 AM: Evaluate: task edges-pos-ontonotes, batch 130 (157): mcc: 0.6833, acc: 0.5031, precision: 0.9006, recall: 0.5255, f1: 0.6637, edges-pos-ontonotes_loss: 0.0315
09/16 07:48:04 AM: Best result seen so far for edges-pos-ontonotes.
09/16 07:48:04 AM: Best result seen so far for macro.
09/16 07:48:04 AM: Updating LR scheduler:
09/16 07:48:04 AM: 	Best result seen so far for macro_avg: 0.663
09/16 07:48:04 AM: 	# validation passes without improvement: 0
09/16 07:48:04 AM: edges-pos-ontonotes_loss: training: 0.043198 validation: 0.031601
09/16 07:48:04 AM: macro_avg: validation: 0.662887
09/16 07:48:04 AM: micro_avg: validation: 0.000000
09/16 07:48:04 AM: edges-pos-ontonotes_mcc: training: 0.559607 validation: 0.682523
09/16 07:48:04 AM: edges-pos-ontonotes_acc: training: 0.381934 validation: 0.502016
09/16 07:48:04 AM: edges-pos-ontonotes_precision: training: 0.750263 validation: 0.900027
09/16 07:48:04 AM: edges-pos-ontonotes_recall: training: 0.427255 validation: 0.524652
09/16 07:48:04 AM: edges-pos-ontonotes_f1: training: 0.544456 validation: 0.662887
09/16 07:48:04 AM: Global learning rate: 0.0001
09/16 07:48:04 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 07:48:09 AM: Update 19023: task edges-pos-ontonotes, batch 23 (19023): mcc: 0.5599, acc: 0.3830, precision: 0.7510, recall: 0.4272, f1: 0.5446, edges-pos-ontonotes_loss: 0.0436
09/16 07:48:19 AM: Update 19082: task edges-pos-ontonotes, batch 82 (19082): mcc: 0.5662, acc: 0.3885, precision: 0.7569, recall: 0.4333, f1: 0.5512, edges-pos-ontonotes_loss: 0.0429
09/16 07:48:29 AM: Update 19142: task edges-pos-ontonotes, batch 142 (19142): mcc: 0.5716, acc: 0.3930, precision: 0.7630, recall: 0.4378, f1: 0.5564, edges-pos-ontonotes_loss: 0.0424
09/16 07:48:46 AM: Update 19179: task edges-pos-ontonotes, batch 179 (19179): mcc: 0.5671, acc: 0.3903, precision: 0.7572, recall: 0.4344, f1: 0.5521, edges-pos-ontonotes_loss: 0.0425
09/16 07:48:56 AM: Update 19237: task edges-pos-ontonotes, batch 237 (19237): mcc: 0.5596, acc: 0.3831, precision: 0.7494, recall: 0.4277, f1: 0.5446, edges-pos-ontonotes_loss: 0.0421
09/16 07:49:06 AM: Update 19311: task edges-pos-ontonotes, batch 311 (19311): mcc: 0.5675, acc: 0.3911, precision: 0.7558, recall: 0.4360, f1: 0.5530, edges-pos-ontonotes_loss: 0.0409
09/16 07:49:17 AM: Update 19377: task edges-pos-ontonotes, batch 377 (19377): mcc: 0.5690, acc: 0.3930, precision: 0.7561, recall: 0.4381, f1: 0.5547, edges-pos-ontonotes_loss: 0.0403
09/16 07:49:27 AM: Update 19449: task edges-pos-ontonotes, batch 449 (19449): mcc: 0.5726, acc: 0.3968, precision: 0.7585, recall: 0.4421, f1: 0.5586, edges-pos-ontonotes_loss: 0.0398
09/16 07:49:37 AM: Update 19519: task edges-pos-ontonotes, batch 519 (19519): mcc: 0.5772, acc: 0.4016, precision: 0.7619, recall: 0.4471, f1: 0.5635, edges-pos-ontonotes_loss: 0.0390
09/16 07:49:47 AM: Update 19616: task edges-pos-ontonotes, batch 616 (19616): mcc: 0.5915, acc: 0.4163, precision: 0.7729, recall: 0.4623, f1: 0.5785, edges-pos-ontonotes_loss: 0.0376
09/16 07:49:57 AM: Update 19706: task edges-pos-ontonotes, batch 706 (19706): mcc: 0.6027, acc: 0.4281, precision: 0.7813, recall: 0.4745, f1: 0.5904, edges-pos-ontonotes_loss: 0.0367
09/16 07:50:07 AM: Update 19801: task edges-pos-ontonotes, batch 801 (19801): mcc: 0.6120, acc: 0.4380, precision: 0.7882, recall: 0.4847, f1: 0.6003, edges-pos-ontonotes_loss: 0.0360
09/16 07:50:17 AM: Update 19896: task edges-pos-ontonotes, batch 896 (19896): mcc: 0.6182, acc: 0.4449, precision: 0.7926, recall: 0.4914, f1: 0.6067, edges-pos-ontonotes_loss: 0.0355
09/16 07:50:25 AM: ***** Step 20000 / Validation 20 *****
09/16 07:50:25 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:50:25 AM: Validating...
09/16 07:50:27 AM: Evaluate: task edges-pos-ontonotes, batch 10 (157): mcc: 0.6877, acc: 0.5086, precision: 0.9004, recall: 0.5323, f1: 0.6691, edges-pos-ontonotes_loss: 0.0313
09/16 07:50:37 AM: Evaluate: task edges-pos-ontonotes, batch 80 (157): mcc: 0.7071, acc: 0.5360, precision: 0.9112, recall: 0.5556, f1: 0.6903, edges-pos-ontonotes_loss: 0.0298
09/16 07:50:47 AM: Evaluate: task edges-pos-ontonotes, batch 129 (157): mcc: 0.6791, acc: 0.5004, precision: 0.8959, recall: 0.5219, f1: 0.6596, edges-pos-ontonotes_loss: 0.0315
09/16 07:50:53 AM: Updating LR scheduler:
09/16 07:50:53 AM: 	Best result seen so far for macro_avg: 0.663
09/16 07:50:53 AM: 	# validation passes without improvement: 1
09/16 07:50:53 AM: edges-pos-ontonotes_loss: training: 0.034901 validation: 0.032075
09/16 07:50:53 AM: macro_avg: validation: 0.654509
09/16 07:50:53 AM: micro_avg: validation: 0.000000
09/16 07:50:53 AM: edges-pos-ontonotes_mcc: training: 0.623882 validation: 0.674439
09/16 07:50:53 AM: edges-pos-ontonotes_acc: training: 0.451447 validation: 0.494450
09/16 07:50:53 AM: edges-pos-ontonotes_precision: training: 0.796699 validation: 0.893058
09/16 07:50:53 AM: edges-pos-ontonotes_recall: training: 0.497842 validation: 0.516535
09/16 07:50:53 AM: edges-pos-ontonotes_f1: training: 0.612774 validation: 0.654509
09/16 07:50:53 AM: Global learning rate: 0.0001
09/16 07:50:53 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 07:50:57 AM: Update 20049: task edges-pos-ontonotes, batch 49 (20049): mcc: 0.7151, acc: 0.5631, precision: 0.8523, recall: 0.6081, f1: 0.7098, edges-pos-ontonotes_loss: 0.0300
09/16 07:51:07 AM: Update 20135: task edges-pos-ontonotes, batch 135 (20135): mcc: 0.6807, acc: 0.5225, precision: 0.8267, recall: 0.5693, f1: 0.6743, edges-pos-ontonotes_loss: 0.0318
09/16 07:51:17 AM: Update 20285: task edges-pos-ontonotes, batch 285 (20285): mcc: 0.6515, acc: 0.4860, precision: 0.8130, recall: 0.5312, f1: 0.6426, edges-pos-ontonotes_loss: 0.0350
09/16 07:51:27 AM: Update 20419: task edges-pos-ontonotes, batch 419 (20419): mcc: 0.6375, acc: 0.4690, precision: 0.8048, recall: 0.5141, f1: 0.6274, edges-pos-ontonotes_loss: 0.0362
09/16 07:51:37 AM: Update 20475: task edges-pos-ontonotes, batch 475 (20475): mcc: 0.6115, acc: 0.4406, precision: 0.7842, recall: 0.4864, f1: 0.6004, edges-pos-ontonotes_loss: 0.0371
09/16 07:51:48 AM: Update 20537: task edges-pos-ontonotes, batch 537 (20537): mcc: 0.5968, acc: 0.4234, precision: 0.7727, recall: 0.4706, f1: 0.5850, edges-pos-ontonotes_loss: 0.0379
09/16 07:51:58 AM: Update 20604: task edges-pos-ontonotes, batch 604 (20604): mcc: 0.5877, acc: 0.4128, precision: 0.7668, recall: 0.4602, f1: 0.5752, edges-pos-ontonotes_loss: 0.0387
09/16 07:52:08 AM: Update 20668: task edges-pos-ontonotes, batch 668 (20668): mcc: 0.5813, acc: 0.4058, precision: 0.7621, recall: 0.4533, f1: 0.5684, edges-pos-ontonotes_loss: 0.0391
09/16 07:52:18 AM: Update 20724: task edges-pos-ontonotes, batch 724 (20724): mcc: 0.5746, acc: 0.3984, precision: 0.7576, recall: 0.4456, f1: 0.5612, edges-pos-ontonotes_loss: 0.0396
09/16 07:52:28 AM: Update 20782: task edges-pos-ontonotes, batch 782 (20782): mcc: 0.5730, acc: 0.3964, precision: 0.7573, recall: 0.4435, f1: 0.5594, edges-pos-ontonotes_loss: 0.0397
09/16 07:52:38 AM: Update 20876: task edges-pos-ontonotes, batch 876 (20876): mcc: 0.5760, acc: 0.3994, precision: 0.7613, recall: 0.4456, f1: 0.5622, edges-pos-ontonotes_loss: 0.0394
09/16 07:52:48 AM: Update 20973: task edges-pos-ontonotes, batch 973 (20973): mcc: 0.5788, acc: 0.4021, precision: 0.7647, recall: 0.4478, f1: 0.5648, edges-pos-ontonotes_loss: 0.0389
09/16 07:52:51 AM: ***** Step 21000 / Validation 21 *****
09/16 07:52:51 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:52:51 AM: Validating...
09/16 07:52:58 AM: Evaluate: task edges-pos-ontonotes, batch 48 (157): mcc: 0.7043, acc: 0.5275, precision: 0.9187, recall: 0.5467, f1: 0.6855, edges-pos-ontonotes_loss: 0.0296
09/16 07:53:08 AM: Evaluate: task edges-pos-ontonotes, batch 109 (157): mcc: 0.6984, acc: 0.5215, precision: 0.9106, recall: 0.5425, f1: 0.6799, edges-pos-ontonotes_loss: 0.0292
09/16 07:53:18 AM: Evaluate: task edges-pos-ontonotes, batch 155 (157): mcc: 0.6728, acc: 0.4881, precision: 0.8977, recall: 0.5114, f1: 0.6516, edges-pos-ontonotes_loss: 0.0311
09/16 07:53:18 AM: Updating LR scheduler:
09/16 07:53:18 AM: 	Best result seen so far for macro_avg: 0.663
09/16 07:53:18 AM: 	# validation passes without improvement: 2
09/16 07:53:18 AM: edges-pos-ontonotes_loss: training: 0.038835 validation: 0.031096
09/16 07:53:18 AM: macro_avg: validation: 0.651920
09/16 07:53:18 AM: micro_avg: validation: 0.000000
09/16 07:53:18 AM: edges-pos-ontonotes_mcc: training: 0.579356 validation: 0.673111
09/16 07:53:18 AM: edges-pos-ontonotes_acc: training: 0.402638 validation: 0.488492
09/16 07:53:18 AM: edges-pos-ontonotes_precision: training: 0.765437 validation: 0.897737
09/16 07:53:18 AM: edges-pos-ontonotes_recall: training: 0.448204 validation: 0.511783
09/16 07:53:18 AM: edges-pos-ontonotes_f1: training: 0.565360 validation: 0.651920
09/16 07:53:18 AM: Global learning rate: 0.0001
09/16 07:53:18 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 07:53:28 AM: Update 21074: task edges-pos-ontonotes, batch 74 (21074): mcc: 0.5983, acc: 0.4228, precision: 0.7872, recall: 0.4641, f1: 0.5839, edges-pos-ontonotes_loss: 0.0359
09/16 07:53:38 AM: Update 21140: task edges-pos-ontonotes, batch 140 (21140): mcc: 0.5973, acc: 0.4206, precision: 0.7777, recall: 0.4683, f1: 0.5846, edges-pos-ontonotes_loss: 0.0371
09/16 07:53:48 AM: Update 21211: task edges-pos-ontonotes, batch 211 (21211): mcc: 0.5968, acc: 0.4205, precision: 0.7738, recall: 0.4700, f1: 0.5848, edges-pos-ontonotes_loss: 0.0372
09/16 07:53:59 AM: Update 21291: task edges-pos-ontonotes, batch 291 (21291): mcc: 0.6007, acc: 0.4248, precision: 0.7762, recall: 0.4745, f1: 0.5889, edges-pos-ontonotes_loss: 0.0368
09/16 07:54:09 AM: Update 21363: task edges-pos-ontonotes, batch 363 (21363): mcc: 0.6020, acc: 0.4265, precision: 0.7767, recall: 0.4762, f1: 0.5904, edges-pos-ontonotes_loss: 0.0370
09/16 07:54:21 AM: Update 21387: task edges-pos-ontonotes, batch 387 (21387): mcc: 0.6019, acc: 0.4267, precision: 0.7762, recall: 0.4764, f1: 0.5904, edges-pos-ontonotes_loss: 0.0369
09/16 07:54:31 AM: Update 21443: task edges-pos-ontonotes, batch 443 (21443): mcc: 0.5924, acc: 0.4166, precision: 0.7683, recall: 0.4666, f1: 0.5806, edges-pos-ontonotes_loss: 0.0378
09/16 07:54:42 AM: Update 21497: task edges-pos-ontonotes, batch 497 (21497): mcc: 0.5851, acc: 0.4088, precision: 0.7626, recall: 0.4587, f1: 0.5729, edges-pos-ontonotes_loss: 0.0386
09/16 07:54:52 AM: Update 21554: task edges-pos-ontonotes, batch 554 (21554): mcc: 0.5795, acc: 0.4029, precision: 0.7586, recall: 0.4525, f1: 0.5669, edges-pos-ontonotes_loss: 0.0391
09/16 07:55:02 AM: Update 21619: task edges-pos-ontonotes, batch 619 (21619): mcc: 0.5777, acc: 0.4010, precision: 0.7572, recall: 0.4507, f1: 0.5650, edges-pos-ontonotes_loss: 0.0396
09/16 07:55:12 AM: Update 21677: task edges-pos-ontonotes, batch 677 (21677): mcc: 0.5757, acc: 0.3986, precision: 0.7562, recall: 0.4483, f1: 0.5629, edges-pos-ontonotes_loss: 0.0399
09/16 07:55:22 AM: Update 21722: task edges-pos-ontonotes, batch 722 (21722): mcc: 0.5734, acc: 0.3964, precision: 0.7541, recall: 0.4460, f1: 0.5605, edges-pos-ontonotes_loss: 0.0401
09/16 07:55:32 AM: Update 21773: task edges-pos-ontonotes, batch 773 (21773): mcc: 0.5716, acc: 0.3946, precision: 0.7528, recall: 0.4440, f1: 0.5585, edges-pos-ontonotes_loss: 0.0404
09/16 07:55:42 AM: Update 21828: task edges-pos-ontonotes, batch 828 (21828): mcc: 0.5714, acc: 0.3943, precision: 0.7530, recall: 0.4436, f1: 0.5583, edges-pos-ontonotes_loss: 0.0405
09/16 07:55:52 AM: Update 21880: task edges-pos-ontonotes, batch 880 (21880): mcc: 0.5701, acc: 0.3930, precision: 0.7522, recall: 0.4420, f1: 0.5568, edges-pos-ontonotes_loss: 0.0407
09/16 07:56:02 AM: Update 21939: task edges-pos-ontonotes, batch 939 (21939): mcc: 0.5698, acc: 0.3927, precision: 0.7523, recall: 0.4416, f1: 0.5565, edges-pos-ontonotes_loss: 0.0408
09/16 07:56:12 AM: Update 21998: task edges-pos-ontonotes, batch 998 (21998): mcc: 0.5697, acc: 0.3927, precision: 0.7525, recall: 0.4413, f1: 0.5563, edges-pos-ontonotes_loss: 0.0409
09/16 07:56:13 AM: ***** Step 22000 / Validation 22 *****
09/16 07:56:13 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:56:13 AM: Validating...
09/16 07:56:22 AM: Evaluate: task edges-pos-ontonotes, batch 70 (157): mcc: 0.7076, acc: 0.5328, precision: 0.9169, recall: 0.5529, f1: 0.6898, edges-pos-ontonotes_loss: 0.0300
09/16 07:56:33 AM: Evaluate: task edges-pos-ontonotes, batch 123 (157): mcc: 0.6922, acc: 0.5136, precision: 0.9089, recall: 0.5341, f1: 0.6728, edges-pos-ontonotes_loss: 0.0304
09/16 07:56:40 AM: Updating LR scheduler:
09/16 07:56:40 AM: 	Best result seen so far for macro_avg: 0.663
09/16 07:56:40 AM: 	# validation passes without improvement: 3
09/16 07:56:40 AM: edges-pos-ontonotes_loss: training: 0.040920 validation: 0.031077
09/16 07:56:40 AM: macro_avg: validation: 0.661127
09/16 07:56:40 AM: micro_avg: validation: 0.000000
09/16 07:56:40 AM: edges-pos-ontonotes_mcc: training: 0.569767 validation: 0.682136
09/16 07:56:40 AM: edges-pos-ontonotes_acc: training: 0.392727 validation: 0.499645
09/16 07:56:40 AM: edges-pos-ontonotes_precision: training: 0.752545 validation: 0.906281
09/16 07:56:40 AM: edges-pos-ontonotes_recall: training: 0.441332 validation: 0.520366
09/16 07:56:40 AM: edges-pos-ontonotes_f1: training: 0.556376 validation: 0.661127
09/16 07:56:40 AM: Global learning rate: 0.0001
09/16 07:56:40 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 07:56:45 AM: Update 22013: task edges-pos-ontonotes, batch 13 (22013): mcc: 0.5434, acc: 0.3719, precision: 0.7302, recall: 0.4146, f1: 0.5289, edges-pos-ontonotes_loss: 0.0446
09/16 07:56:55 AM: Update 22066: task edges-pos-ontonotes, batch 66 (22066): mcc: 0.5588, acc: 0.3823, precision: 0.7482, recall: 0.4273, f1: 0.5439, edges-pos-ontonotes_loss: 0.0438
09/16 07:57:05 AM: Update 22123: task edges-pos-ontonotes, batch 123 (22123): mcc: 0.5621, acc: 0.3852, precision: 0.7521, recall: 0.4300, f1: 0.5471, edges-pos-ontonotes_loss: 0.0433
09/16 07:57:15 AM: Update 22180: task edges-pos-ontonotes, batch 180 (22180): mcc: 0.5664, acc: 0.3896, precision: 0.7564, recall: 0.4340, f1: 0.5515, edges-pos-ontonotes_loss: 0.0428
09/16 07:57:25 AM: Update 22237: task edges-pos-ontonotes, batch 237 (22237): mcc: 0.5678, acc: 0.3909, precision: 0.7571, recall: 0.4356, f1: 0.5530, edges-pos-ontonotes_loss: 0.0426
09/16 07:57:35 AM: Update 22293: task edges-pos-ontonotes, batch 293 (22293): mcc: 0.5691, acc: 0.3922, precision: 0.7580, recall: 0.4370, f1: 0.5544, edges-pos-ontonotes_loss: 0.0425
09/16 07:57:45 AM: Update 22341: task edges-pos-ontonotes, batch 341 (22341): mcc: 0.5684, acc: 0.3914, precision: 0.7575, recall: 0.4363, f1: 0.5537, edges-pos-ontonotes_loss: 0.0425
09/16 07:57:55 AM: Update 22400: task edges-pos-ontonotes, batch 400 (22400): mcc: 0.5699, acc: 0.3928, precision: 0.7592, recall: 0.4375, f1: 0.5551, edges-pos-ontonotes_loss: 0.0424
09/16 07:58:05 AM: Update 22459: task edges-pos-ontonotes, batch 459 (22459): mcc: 0.5704, acc: 0.3934, precision: 0.7598, recall: 0.4379, f1: 0.5556, edges-pos-ontonotes_loss: 0.0424
09/16 07:58:16 AM: Update 22516: task edges-pos-ontonotes, batch 516 (22516): mcc: 0.5716, acc: 0.3947, precision: 0.7606, recall: 0.4393, f1: 0.5570, edges-pos-ontonotes_loss: 0.0423
09/16 07:58:26 AM: Update 22569: task edges-pos-ontonotes, batch 569 (22569): mcc: 0.5723, acc: 0.3952, precision: 0.7609, recall: 0.4402, f1: 0.5577, edges-pos-ontonotes_loss: 0.0422
09/16 07:58:36 AM: Update 22609: task edges-pos-ontonotes, batch 609 (22609): mcc: 0.5715, acc: 0.3945, precision: 0.7601, recall: 0.4394, f1: 0.5569, edges-pos-ontonotes_loss: 0.0423
09/16 07:58:47 AM: Update 22640: task edges-pos-ontonotes, batch 640 (22640): mcc: 0.5683, acc: 0.3914, precision: 0.7570, recall: 0.4364, f1: 0.5536, edges-pos-ontonotes_loss: 0.0424
09/16 07:58:57 AM: Update 22684: task edges-pos-ontonotes, batch 684 (22684): mcc: 0.5667, acc: 0.3901, precision: 0.7554, recall: 0.4350, f1: 0.5521, edges-pos-ontonotes_loss: 0.0423
09/16 07:59:07 AM: Update 22733: task edges-pos-ontonotes, batch 733 (22733): mcc: 0.5678, acc: 0.3911, precision: 0.7561, recall: 0.4362, f1: 0.5532, edges-pos-ontonotes_loss: 0.0420
09/16 07:59:17 AM: Update 22786: task edges-pos-ontonotes, batch 786 (22786): mcc: 0.5701, acc: 0.3936, precision: 0.7579, recall: 0.4387, f1: 0.5557, edges-pos-ontonotes_loss: 0.0416
09/16 07:59:27 AM: Update 22833: task edges-pos-ontonotes, batch 833 (22833): mcc: 0.5700, acc: 0.3936, precision: 0.7575, recall: 0.4388, f1: 0.5557, edges-pos-ontonotes_loss: 0.0414
09/16 07:59:38 AM: Update 22892: task edges-pos-ontonotes, batch 892 (22892): mcc: 0.5724, acc: 0.3961, precision: 0.7592, recall: 0.4413, f1: 0.5582, edges-pos-ontonotes_loss: 0.0410
09/16 07:59:48 AM: Update 22942: task edges-pos-ontonotes, batch 942 (22942): mcc: 0.5730, acc: 0.3969, precision: 0.7593, recall: 0.4422, f1: 0.5589, edges-pos-ontonotes_loss: 0.0408
09/16 07:59:58 AM: Update 22989: task edges-pos-ontonotes, batch 989 (22989): mcc: 0.5758, acc: 0.3997, precision: 0.7615, recall: 0.4451, f1: 0.5618, edges-pos-ontonotes_loss: 0.0404
09/16 07:59:59 AM: ***** Step 23000 / Validation 23 *****
09/16 07:59:59 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 07:59:59 AM: Validating...
09/16 08:00:08 AM: Evaluate: task edges-pos-ontonotes, batch 48 (157): mcc: 0.6940, acc: 0.5164, precision: 0.9102, recall: 0.5360, f1: 0.6747, edges-pos-ontonotes_loss: 0.0319
09/16 08:00:18 AM: Evaluate: task edges-pos-ontonotes, batch 100 (157): mcc: 0.7080, acc: 0.5356, precision: 0.9134, recall: 0.5557, f1: 0.6910, edges-pos-ontonotes_loss: 0.0299
09/16 08:00:28 AM: Evaluate: task edges-pos-ontonotes, batch 139 (157): mcc: 0.6866, acc: 0.5070, precision: 0.9048, recall: 0.5281, f1: 0.6669, edges-pos-ontonotes_loss: 0.0312
09/16 08:00:32 AM: Best result seen so far for edges-pos-ontonotes.
09/16 08:00:32 AM: Best result seen so far for macro.
09/16 08:00:32 AM: Updating LR scheduler:
09/16 08:00:32 AM: 	Best result seen so far for macro_avg: 0.668
09/16 08:00:32 AM: 	# validation passes without improvement: 0
09/16 08:00:32 AM: edges-pos-ontonotes_loss: training: 0.040290 validation: 0.031258
09/16 08:00:32 AM: macro_avg: validation: 0.667900
09/16 08:00:32 AM: micro_avg: validation: 0.000000
09/16 08:00:32 AM: edges-pos-ontonotes_mcc: training: 0.576554 validation: 0.687471
09/16 08:00:32 AM: edges-pos-ontonotes_acc: training: 0.400533 validation: 0.508164
09/16 08:00:32 AM: edges-pos-ontonotes_precision: training: 0.762157 validation: 0.904843
09/16 08:00:32 AM: edges-pos-ontonotes_recall: training: 0.445902 validation: 0.529297
09/16 08:00:32 AM: edges-pos-ontonotes_f1: training: 0.562634 validation: 0.667900
09/16 08:00:32 AM: Global learning rate: 0.0001
09/16 08:00:32 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 08:00:38 AM: Update 23041: task edges-pos-ontonotes, batch 41 (23041): mcc: 0.6994, acc: 0.5352, precision: 0.8463, recall: 0.5863, f1: 0.6927, edges-pos-ontonotes_loss: 0.0303
09/16 08:00:48 AM: Update 23090: task edges-pos-ontonotes, batch 90 (23090): mcc: 0.7037, acc: 0.5400, precision: 0.8514, recall: 0.5897, f1: 0.6968, edges-pos-ontonotes_loss: 0.0301
09/16 08:00:59 AM: Update 23150: task edges-pos-ontonotes, batch 150 (23150): mcc: 0.7025, acc: 0.5387, precision: 0.8497, recall: 0.5890, f1: 0.6957, edges-pos-ontonotes_loss: 0.0300
09/16 08:01:09 AM: Update 23210: task edges-pos-ontonotes, batch 210 (23210): mcc: 0.7052, acc: 0.5421, precision: 0.8511, recall: 0.5925, f1: 0.6986, edges-pos-ontonotes_loss: 0.0298
09/16 08:01:28 AM: Update 23265: task edges-pos-ontonotes, batch 265 (23265): mcc: 0.7029, acc: 0.5397, precision: 0.8501, recall: 0.5894, f1: 0.6961, edges-pos-ontonotes_loss: 0.0299
09/16 08:01:38 AM: Update 23339: task edges-pos-ontonotes, batch 339 (23339): mcc: 0.7019, acc: 0.5394, precision: 0.8490, recall: 0.5884, f1: 0.6951, edges-pos-ontonotes_loss: 0.0304
09/16 08:01:48 AM: Update 23416: task edges-pos-ontonotes, batch 416 (23416): mcc: 0.7039, acc: 0.5426, precision: 0.8502, recall: 0.5910, f1: 0.6973, edges-pos-ontonotes_loss: 0.0304
09/16 08:01:58 AM: Update 23489: task edges-pos-ontonotes, batch 489 (23489): mcc: 0.7046, acc: 0.5442, precision: 0.8505, recall: 0.5920, f1: 0.6981, edges-pos-ontonotes_loss: 0.0303
09/16 08:02:08 AM: Update 23562: task edges-pos-ontonotes, batch 562 (23562): mcc: 0.7052, acc: 0.5455, precision: 0.8507, recall: 0.5928, f1: 0.6987, edges-pos-ontonotes_loss: 0.0302
09/16 08:02:18 AM: Update 23634: task edges-pos-ontonotes, batch 634 (23634): mcc: 0.6982, acc: 0.5374, precision: 0.8457, recall: 0.5847, f1: 0.6914, edges-pos-ontonotes_loss: 0.0310
09/16 08:02:28 AM: Update 23724: task edges-pos-ontonotes, batch 724 (23724): mcc: 0.6906, acc: 0.5282, precision: 0.8411, recall: 0.5754, f1: 0.6833, edges-pos-ontonotes_loss: 0.0320
09/16 08:02:38 AM: Update 23816: task edges-pos-ontonotes, batch 816 (23816): mcc: 0.6828, acc: 0.5192, precision: 0.8359, recall: 0.5663, f1: 0.6752, edges-pos-ontonotes_loss: 0.0326
09/16 08:02:49 AM: Update 23891: task edges-pos-ontonotes, batch 891 (23891): mcc: 0.6756, acc: 0.5112, precision: 0.8304, recall: 0.5583, f1: 0.6677, edges-pos-ontonotes_loss: 0.0330
09/16 08:02:59 AM: Update 23938: task edges-pos-ontonotes, batch 938 (23938): mcc: 0.6617, acc: 0.4951, precision: 0.8207, recall: 0.5424, f1: 0.6532, edges-pos-ontonotes_loss: 0.0336
09/16 08:03:09 AM: Update 23986: task edges-pos-ontonotes, batch 986 (23986): mcc: 0.6515, acc: 0.4833, precision: 0.8134, recall: 0.5308, f1: 0.6424, edges-pos-ontonotes_loss: 0.0341
09/16 08:03:13 AM: ***** Step 24000 / Validation 24 *****
09/16 08:03:13 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:03:13 AM: Validating...
09/16 08:03:19 AM: Evaluate: task edges-pos-ontonotes, batch 36 (157): mcc: 0.6983, acc: 0.5232, precision: 0.8958, recall: 0.5515, f1: 0.6827, edges-pos-ontonotes_loss: 0.0308
09/16 08:03:30 AM: Evaluate: task edges-pos-ontonotes, batch 99 (157): mcc: 0.7050, acc: 0.5321, precision: 0.8999, recall: 0.5594, f1: 0.6899, edges-pos-ontonotes_loss: 0.0296
09/16 08:03:40 AM: Evaluate: task edges-pos-ontonotes, batch 145 (157): mcc: 0.6764, acc: 0.4952, precision: 0.8830, recall: 0.5255, f1: 0.6589, edges-pos-ontonotes_loss: 0.0314
09/16 08:03:42 AM: Updating LR scheduler:
09/16 08:03:42 AM: 	Best result seen so far for macro_avg: 0.668
09/16 08:03:42 AM: 	# validation passes without improvement: 1
09/16 08:03:42 AM: edges-pos-ontonotes_loss: training: 0.034273 validation: 0.031386
09/16 08:03:42 AM: macro_avg: validation: 0.660966
09/16 08:03:42 AM: micro_avg: validation: 0.000000
09/16 08:03:42 AM: edges-pos-ontonotes_mcc: training: 0.649873 validation: 0.678156
09/16 08:03:42 AM: edges-pos-ontonotes_acc: training: 0.481389 validation: 0.497307
09/16 08:03:42 AM: edges-pos-ontonotes_precision: training: 0.812154 validation: 0.883397
09/16 08:03:42 AM: edges-pos-ontonotes_recall: training: 0.529069 validation: 0.528017
09/16 08:03:42 AM: edges-pos-ontonotes_f1: training: 0.640737 validation: 0.660966
09/16 08:03:42 AM: Global learning rate: 0.0001
09/16 08:03:42 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 08:03:50 AM: Update 24044: task edges-pos-ontonotes, batch 44 (24044): mcc: 0.5398, acc: 0.3600, precision: 0.7280, recall: 0.4106, f1: 0.5250, edges-pos-ontonotes_loss: 0.0447
09/16 08:04:00 AM: Update 24100: task edges-pos-ontonotes, batch 100 (24100): mcc: 0.5346, acc: 0.3553, precision: 0.7250, recall: 0.4045, f1: 0.5193, edges-pos-ontonotes_loss: 0.0449
09/16 08:04:10 AM: Update 24165: task edges-pos-ontonotes, batch 165 (24165): mcc: 0.5390, acc: 0.3599, precision: 0.7287, recall: 0.4089, f1: 0.5239, edges-pos-ontonotes_loss: 0.0442
09/16 08:04:20 AM: Update 24221: task edges-pos-ontonotes, batch 221 (24221): mcc: 0.5411, acc: 0.3616, precision: 0.7307, recall: 0.4108, f1: 0.5259, edges-pos-ontonotes_loss: 0.0440
09/16 08:04:30 AM: Update 24316: task edges-pos-ontonotes, batch 316 (24316): mcc: 0.5531, acc: 0.3741, precision: 0.7438, recall: 0.4212, f1: 0.5378, edges-pos-ontonotes_loss: 0.0416
09/16 08:04:40 AM: Update 24407: task edges-pos-ontonotes, batch 407 (24407): mcc: 0.5606, acc: 0.3821, precision: 0.7517, recall: 0.4280, f1: 0.5454, edges-pos-ontonotes_loss: 0.0402
09/16 08:04:50 AM: Update 24508: task edges-pos-ontonotes, batch 508 (24508): mcc: 0.5695, acc: 0.3913, precision: 0.7601, recall: 0.4364, f1: 0.5544, edges-pos-ontonotes_loss: 0.0391
09/16 08:05:00 AM: Update 24572: task edges-pos-ontonotes, batch 572 (24572): mcc: 0.5722, acc: 0.3942, precision: 0.7611, recall: 0.4399, f1: 0.5576, edges-pos-ontonotes_loss: 0.0389
09/16 08:05:10 AM: Update 24646: task edges-pos-ontonotes, batch 646 (24646): mcc: 0.5766, acc: 0.3989, precision: 0.7633, recall: 0.4453, f1: 0.5625, edges-pos-ontonotes_loss: 0.0386
09/16 08:05:20 AM: Update 24726: task edges-pos-ontonotes, batch 726 (24726): mcc: 0.5816, acc: 0.4044, precision: 0.7660, recall: 0.4513, f1: 0.5680, edges-pos-ontonotes_loss: 0.0384
09/16 08:05:30 AM: Update 24798: task edges-pos-ontonotes, batch 798 (24798): mcc: 0.5837, acc: 0.4069, precision: 0.7665, recall: 0.4542, f1: 0.5704, edges-pos-ontonotes_loss: 0.0382
09/16 08:05:40 AM: Update 24851: task edges-pos-ontonotes, batch 851 (24851): mcc: 0.5835, acc: 0.4070, precision: 0.7655, recall: 0.4546, f1: 0.5704, edges-pos-ontonotes_loss: 0.0383
09/16 08:05:50 AM: Update 24912: task edges-pos-ontonotes, batch 912 (24912): mcc: 0.5813, acc: 0.4048, precision: 0.7633, recall: 0.4525, f1: 0.5681, edges-pos-ontonotes_loss: 0.0386
09/16 08:06:00 AM: Update 24968: task edges-pos-ontonotes, batch 968 (24968): mcc: 0.5786, acc: 0.4020, precision: 0.7608, recall: 0.4499, f1: 0.5654, edges-pos-ontonotes_loss: 0.0389
09/16 08:06:06 AM: ***** Step 25000 / Validation 25 *****
09/16 08:06:06 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:06:06 AM: Validating...
09/16 08:06:10 AM: Evaluate: task edges-pos-ontonotes, batch 35 (157): mcc: 0.7080, acc: 0.5345, precision: 0.9142, recall: 0.5552, f1: 0.6908, edges-pos-ontonotes_loss: 0.0300
09/16 08:06:21 AM: Evaluate: task edges-pos-ontonotes, batch 99 (157): mcc: 0.7152, acc: 0.5443, precision: 0.9176, recall: 0.5641, f1: 0.6987, edges-pos-ontonotes_loss: 0.0287
09/16 08:06:31 AM: Evaluate: task edges-pos-ontonotes, batch 146 (157): mcc: 0.6869, acc: 0.5066, precision: 0.9059, recall: 0.5278, f1: 0.6670, edges-pos-ontonotes_loss: 0.0304
09/16 08:06:33 AM: Best result seen so far for edges-pos-ontonotes.
09/16 08:06:33 AM: Best result seen so far for macro.
09/16 08:06:33 AM: Updating LR scheduler:
09/16 08:06:33 AM: 	Best result seen so far for macro_avg: 0.668
09/16 08:06:33 AM: 	# validation passes without improvement: 2
09/16 08:06:33 AM: edges-pos-ontonotes_loss: training: 0.039035 validation: 0.030473
09/16 08:06:33 AM: macro_avg: validation: 0.667914
09/16 08:06:33 AM: micro_avg: validation: 0.000000
09/16 08:06:33 AM: edges-pos-ontonotes_mcc: training: 0.578020 validation: 0.687695
09/16 08:06:33 AM: edges-pos-ontonotes_acc: training: 0.401267 validation: 0.507445
09/16 08:06:33 AM: edges-pos-ontonotes_precision: training: 0.760198 validation: 0.906104
09/16 08:06:33 AM: edges-pos-ontonotes_recall: training: 0.449336 validation: 0.528885
09/16 08:06:33 AM: edges-pos-ontonotes_f1: training: 0.564820 validation: 0.667914
09/16 08:06:33 AM: Global learning rate: 0.0001
09/16 08:06:33 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 08:06:41 AM: Update 25044: task edges-pos-ontonotes, batch 44 (25044): mcc: 0.5557, acc: 0.3803, precision: 0.7349, recall: 0.4305, f1: 0.5430, edges-pos-ontonotes_loss: 0.0439
09/16 08:06:51 AM: Update 25097: task edges-pos-ontonotes, batch 97 (25097): mcc: 0.5452, acc: 0.3680, precision: 0.7293, recall: 0.4179, f1: 0.5314, edges-pos-ontonotes_loss: 0.0441
09/16 08:07:11 AM: Update 25160: task edges-pos-ontonotes, batch 160 (25160): mcc: 0.5518, acc: 0.3751, precision: 0.7339, recall: 0.4251, f1: 0.5384, edges-pos-ontonotes_loss: 0.0436
09/16 08:07:21 AM: Update 25219: task edges-pos-ontonotes, batch 219 (25219): mcc: 0.5547, acc: 0.3775, precision: 0.7382, recall: 0.4270, f1: 0.5410, edges-pos-ontonotes_loss: 0.0433
09/16 08:07:31 AM: Update 25270: task edges-pos-ontonotes, batch 270 (25270): mcc: 0.5569, acc: 0.3799, precision: 0.7407, recall: 0.4289, f1: 0.5432, edges-pos-ontonotes_loss: 0.0432
09/16 08:07:41 AM: Update 25324: task edges-pos-ontonotes, batch 324 (25324): mcc: 0.5581, acc: 0.3815, precision: 0.7418, recall: 0.4300, f1: 0.5444, edges-pos-ontonotes_loss: 0.0432
09/16 08:07:51 AM: Update 25381: task edges-pos-ontonotes, batch 381 (25381): mcc: 0.5592, acc: 0.3826, precision: 0.7431, recall: 0.4309, f1: 0.5455, edges-pos-ontonotes_loss: 0.0432
09/16 08:08:02 AM: Update 25432: task edges-pos-ontonotes, batch 432 (25432): mcc: 0.5591, acc: 0.3826, precision: 0.7433, recall: 0.4307, f1: 0.5454, edges-pos-ontonotes_loss: 0.0432
09/16 08:08:12 AM: Update 25477: task edges-pos-ontonotes, batch 477 (25477): mcc: 0.5585, acc: 0.3821, precision: 0.7432, recall: 0.4298, f1: 0.5446, edges-pos-ontonotes_loss: 0.0431
09/16 08:08:22 AM: Update 25536: task edges-pos-ontonotes, batch 536 (25536): mcc: 0.5607, acc: 0.3842, precision: 0.7456, recall: 0.4317, f1: 0.5468, edges-pos-ontonotes_loss: 0.0430
09/16 08:08:32 AM: Update 25592: task edges-pos-ontonotes, batch 592 (25592): mcc: 0.5611, acc: 0.3846, precision: 0.7464, recall: 0.4318, f1: 0.5471, edges-pos-ontonotes_loss: 0.0430
09/16 08:08:42 AM: Update 25650: task edges-pos-ontonotes, batch 650 (25650): mcc: 0.5623, acc: 0.3858, precision: 0.7477, recall: 0.4328, f1: 0.5483, edges-pos-ontonotes_loss: 0.0429
09/16 08:08:52 AM: Update 25706: task edges-pos-ontonotes, batch 706 (25706): mcc: 0.5630, acc: 0.3865, precision: 0.7484, recall: 0.4334, f1: 0.5489, edges-pos-ontonotes_loss: 0.0429
09/16 08:09:02 AM: Update 25763: task edges-pos-ontonotes, batch 763 (25763): mcc: 0.5638, acc: 0.3875, precision: 0.7494, recall: 0.4341, f1: 0.5498, edges-pos-ontonotes_loss: 0.0428
09/16 08:09:12 AM: Update 25810: task edges-pos-ontonotes, batch 810 (25810): mcc: 0.5638, acc: 0.3874, precision: 0.7499, recall: 0.4339, f1: 0.5497, edges-pos-ontonotes_loss: 0.0428
09/16 08:09:22 AM: Update 25865: task edges-pos-ontonotes, batch 865 (25865): mcc: 0.5645, acc: 0.3881, precision: 0.7506, recall: 0.4346, f1: 0.5504, edges-pos-ontonotes_loss: 0.0427
09/16 08:09:32 AM: Update 25920: task edges-pos-ontonotes, batch 920 (25920): mcc: 0.5651, acc: 0.3887, precision: 0.7511, recall: 0.4351, f1: 0.5510, edges-pos-ontonotes_loss: 0.0427
09/16 08:09:42 AM: Update 25976: task edges-pos-ontonotes, batch 976 (25976): mcc: 0.5655, acc: 0.3891, precision: 0.7515, recall: 0.4355, f1: 0.5515, edges-pos-ontonotes_loss: 0.0427
09/16 08:09:46 AM: ***** Step 26000 / Validation 26 *****
09/16 08:09:46 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:09:46 AM: Validating...
09/16 08:09:52 AM: Evaluate: task edges-pos-ontonotes, batch 42 (157): mcc: 0.6969, acc: 0.5194, precision: 0.9100, recall: 0.5406, f1: 0.6783, edges-pos-ontonotes_loss: 0.0315
09/16 08:10:02 AM: Evaluate: task edges-pos-ontonotes, batch 104 (157): mcc: 0.7078, acc: 0.5362, precision: 0.9093, recall: 0.5579, f1: 0.6915, edges-pos-ontonotes_loss: 0.0298
09/16 08:10:12 AM: Evaluate: task edges-pos-ontonotes, batch 150 (157): mcc: 0.6876, acc: 0.5095, precision: 0.9002, recall: 0.5323, f1: 0.6690, edges-pos-ontonotes_loss: 0.0309
09/16 08:10:14 AM: Best result seen so far for edges-pos-ontonotes.
09/16 08:10:14 AM: Best result seen so far for macro.
09/16 08:10:14 AM: Updating LR scheduler:
09/16 08:10:14 AM: 	Best result seen so far for macro_avg: 0.670
09/16 08:10:14 AM: 	# validation passes without improvement: 0
09/16 08:10:14 AM: edges-pos-ontonotes_loss: training: 0.042647 validation: 0.030885
09/16 08:10:14 AM: macro_avg: validation: 0.670180
09/16 08:10:14 AM: micro_avg: validation: 0.000000
09/16 08:10:14 AM: edges-pos-ontonotes_mcc: training: 0.565834 validation: 0.688683
09/16 08:10:14 AM: edges-pos-ontonotes_acc: training: 0.389354 validation: 0.510842
09/16 08:10:14 AM: edges-pos-ontonotes_precision: training: 0.751907 validation: 0.900809
09/16 08:10:14 AM: edges-pos-ontonotes_recall: training: 0.435714 validation: 0.533572
09/16 08:10:14 AM: edges-pos-ontonotes_f1: training: 0.551719 validation: 0.670180
09/16 08:10:14 AM: Global learning rate: 0.0001
09/16 08:10:14 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 08:10:22 AM: Update 26051: task edges-pos-ontonotes, batch 51 (26051): mcc: 0.5768, acc: 0.4025, precision: 0.7609, recall: 0.4470, f1: 0.5632, edges-pos-ontonotes_loss: 0.0415
09/16 08:10:33 AM: Update 26100: task edges-pos-ontonotes, batch 100 (26100): mcc: 0.5636, acc: 0.3907, precision: 0.7466, recall: 0.4355, f1: 0.5501, edges-pos-ontonotes_loss: 0.0419
09/16 08:10:43 AM: Update 26171: task edges-pos-ontonotes, batch 171 (26171): mcc: 0.5811, acc: 0.4079, precision: 0.7628, recall: 0.4525, f1: 0.5681, edges-pos-ontonotes_loss: 0.0395
09/16 08:10:53 AM: Update 26230: task edges-pos-ontonotes, batch 230 (26230): mcc: 0.5736, acc: 0.4007, precision: 0.7550, recall: 0.4457, f1: 0.5605, edges-pos-ontonotes_loss: 0.0394
09/16 08:11:03 AM: Update 26296: task edges-pos-ontonotes, batch 296 (26296): mcc: 0.5758, acc: 0.4025, precision: 0.7566, recall: 0.4481, f1: 0.5629, edges-pos-ontonotes_loss: 0.0387
09/16 08:11:13 AM: Update 26360: task edges-pos-ontonotes, batch 360 (26360): mcc: 0.5798, acc: 0.4066, precision: 0.7595, recall: 0.4525, f1: 0.5671, edges-pos-ontonotes_loss: 0.0384
09/16 08:11:23 AM: Update 26417: task edges-pos-ontonotes, batch 417 (26417): mcc: 0.5807, acc: 0.4073, precision: 0.7597, recall: 0.4537, f1: 0.5681, edges-pos-ontonotes_loss: 0.0382
09/16 08:11:33 AM: Update 26504: task edges-pos-ontonotes, batch 504 (26504): mcc: 0.5967, acc: 0.4239, precision: 0.7724, recall: 0.4707, f1: 0.5849, edges-pos-ontonotes_loss: 0.0368
09/16 08:11:43 AM: Update 26597: task edges-pos-ontonotes, batch 597 (26597): mcc: 0.6096, acc: 0.4373, precision: 0.7825, recall: 0.4844, f1: 0.5984, edges-pos-ontonotes_loss: 0.0357
09/16 08:11:53 AM: Update 26684: task edges-pos-ontonotes, batch 684 (26684): mcc: 0.6199, acc: 0.4484, precision: 0.7903, recall: 0.4957, f1: 0.6093, edges-pos-ontonotes_loss: 0.0349
09/16 08:12:03 AM: Update 26761: task edges-pos-ontonotes, batch 761 (26761): mcc: 0.6261, acc: 0.4550, precision: 0.7949, recall: 0.5025, f1: 0.6157, edges-pos-ontonotes_loss: 0.0345
09/16 08:12:14 AM: Update 26863: task edges-pos-ontonotes, batch 863 (26863): mcc: 0.6330, acc: 0.4629, precision: 0.7998, recall: 0.5103, f1: 0.6231, edges-pos-ontonotes_loss: 0.0340
09/16 08:12:24 AM: Update 26977: task edges-pos-ontonotes, batch 977 (26977): mcc: 0.6392, acc: 0.4701, precision: 0.8041, recall: 0.5173, f1: 0.6296, edges-pos-ontonotes_loss: 0.0336
09/16 08:12:26 AM: ***** Step 27000 / Validation 27 *****
09/16 08:12:26 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:12:26 AM: Validating...
09/16 08:12:34 AM: Evaluate: task edges-pos-ontonotes, batch 52 (157): mcc: 0.7059, acc: 0.5331, precision: 0.9130, recall: 0.5526, f1: 0.6885, edges-pos-ontonotes_loss: 0.0302
09/16 08:12:44 AM: Evaluate: task edges-pos-ontonotes, batch 109 (157): mcc: 0.7060, acc: 0.5349, precision: 0.9082, recall: 0.5558, f1: 0.6896, edges-pos-ontonotes_loss: 0.0294
09/16 08:12:54 AM: Evaluate: task edges-pos-ontonotes, batch 154 (157): mcc: 0.6858, acc: 0.5083, precision: 0.8972, recall: 0.5314, f1: 0.6675, edges-pos-ontonotes_loss: 0.0310
09/16 08:12:54 AM: Updating LR scheduler:
09/16 08:12:54 AM: 	Best result seen so far for macro_avg: 0.670
09/16 08:12:54 AM: 	# validation passes without improvement: 1
09/16 08:12:54 AM: edges-pos-ontonotes_loss: training: 0.033452 validation: 0.031018
09/16 08:12:54 AM: macro_avg: validation: 0.667601
09/16 08:12:54 AM: micro_avg: validation: 0.000000
09/16 08:12:54 AM: edges-pos-ontonotes_mcc: training: 0.640328 validation: 0.685945
09/16 08:12:54 AM: edges-pos-ontonotes_acc: training: 0.471418 validation: 0.508429
09/16 08:12:54 AM: edges-pos-ontonotes_precision: training: 0.804878 validation: 0.897192
09/16 08:12:54 AM: edges-pos-ontonotes_recall: training: 0.518610 validation: 0.531572
09/16 08:12:54 AM: edges-pos-ontonotes_f1: training: 0.630784 validation: 0.667601
09/16 08:12:54 AM: Global learning rate: 0.0001
09/16 08:12:54 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 08:13:04 AM: Update 27093: task edges-pos-ontonotes, batch 93 (27093): mcc: 0.6355, acc: 0.4690, precision: 0.7962, recall: 0.5165, f1: 0.6266, edges-pos-ontonotes_loss: 0.0355
09/16 08:13:14 AM: Update 27227: task edges-pos-ontonotes, batch 227 (27227): mcc: 0.6217, acc: 0.4516, precision: 0.7919, recall: 0.4974, f1: 0.6110, edges-pos-ontonotes_loss: 0.0369
09/16 08:13:33 AM: Update 27351: task edges-pos-ontonotes, batch 351 (27351): mcc: 0.6135, acc: 0.4446, precision: 0.7836, recall: 0.4899, f1: 0.6029, edges-pos-ontonotes_loss: 0.0370
09/16 08:13:43 AM: Update 27411: task edges-pos-ontonotes, batch 411 (27411): mcc: 0.5889, acc: 0.4167, precision: 0.7631, recall: 0.4644, f1: 0.5774, edges-pos-ontonotes_loss: 0.0382
09/16 08:13:53 AM: Update 27473: task edges-pos-ontonotes, batch 473 (27473): mcc: 0.5813, acc: 0.4073, precision: 0.7583, recall: 0.4556, f1: 0.5692, edges-pos-ontonotes_loss: 0.0389
09/16 08:14:03 AM: Update 27534: task edges-pos-ontonotes, batch 534 (27534): mcc: 0.5752, acc: 0.4001, precision: 0.7546, recall: 0.4485, f1: 0.5626, edges-pos-ontonotes_loss: 0.0394
09/16 08:14:13 AM: Update 27596: task edges-pos-ontonotes, batch 596 (27596): mcc: 0.5718, acc: 0.3960, precision: 0.7528, recall: 0.4443, f1: 0.5588, edges-pos-ontonotes_loss: 0.0399
09/16 08:14:23 AM: Update 27653: task edges-pos-ontonotes, batch 653 (27653): mcc: 0.5657, acc: 0.3891, precision: 0.7486, recall: 0.4375, f1: 0.5522, edges-pos-ontonotes_loss: 0.0403
09/16 08:14:33 AM: Update 27719: task edges-pos-ontonotes, batch 719 (27719): mcc: 0.5663, acc: 0.3895, precision: 0.7504, recall: 0.4374, f1: 0.5526, edges-pos-ontonotes_loss: 0.0402
09/16 08:14:43 AM: Update 27813: task edges-pos-ontonotes, batch 813 (27813): mcc: 0.5701, acc: 0.3932, precision: 0.7551, recall: 0.4403, f1: 0.5563, edges-pos-ontonotes_loss: 0.0396
09/16 08:14:53 AM: Update 27910: task edges-pos-ontonotes, batch 910 (27910): mcc: 0.5743, acc: 0.3976, precision: 0.7595, recall: 0.4441, f1: 0.5605, edges-pos-ontonotes_loss: 0.0390
09/16 08:15:05 AM: Update 27994: task edges-pos-ontonotes, batch 994 (27994): mcc: 0.5765, acc: 0.3998, precision: 0.7618, recall: 0.4460, f1: 0.5626, edges-pos-ontonotes_loss: 0.0388
09/16 08:15:06 AM: ***** Step 28000 / Validation 28 *****
09/16 08:15:06 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:15:06 AM: Validating...
09/16 08:15:15 AM: Evaluate: task edges-pos-ontonotes, batch 59 (157): mcc: 0.7192, acc: 0.5465, precision: 0.9265, recall: 0.5648, f1: 0.7018, edges-pos-ontonotes_loss: 0.0280
09/16 08:15:25 AM: Evaluate: task edges-pos-ontonotes, batch 114 (157): mcc: 0.7020, acc: 0.5251, precision: 0.9152, recall: 0.5453, f1: 0.6834, edges-pos-ontonotes_loss: 0.0287
09/16 08:15:34 AM: Updating LR scheduler:
09/16 08:15:34 AM: 	Best result seen so far for macro_avg: 0.670
09/16 08:15:34 AM: 	# validation passes without improvement: 2
09/16 08:15:34 AM: edges-pos-ontonotes_loss: training: 0.038796 validation: 0.030272
09/16 08:15:34 AM: macro_avg: validation: 0.659360
09/16 08:15:34 AM: micro_avg: validation: 0.000000
09/16 08:15:34 AM: edges-pos-ontonotes_mcc: training: 0.575909 validation: 0.680825
09/16 08:15:34 AM: edges-pos-ontonotes_acc: training: 0.399142 validation: 0.496492
09/16 08:15:34 AM: edges-pos-ontonotes_precision: training: 0.761234 validation: 0.907104
09/16 08:15:34 AM: edges-pos-ontonotes_recall: training: 0.445474 validation: 0.517911
09/16 08:15:34 AM: edges-pos-ontonotes_f1: training: 0.562041 validation: 0.659360
09/16 08:15:34 AM: Global learning rate: 0.0001
09/16 08:15:34 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 08:15:35 AM: Update 28007: task edges-pos-ontonotes, batch 7 (28007): mcc: 0.6051, acc: 0.4264, precision: 0.7869, recall: 0.4748, f1: 0.5922, edges-pos-ontonotes_loss: 0.0361
09/16 08:15:45 AM: Update 28078: task edges-pos-ontonotes, batch 78 (28078): mcc: 0.6070, acc: 0.4308, precision: 0.7752, recall: 0.4850, f1: 0.5967, edges-pos-ontonotes_loss: 0.0368
09/16 08:15:55 AM: Update 28161: task edges-pos-ontonotes, batch 161 (28161): mcc: 0.6164, acc: 0.4418, precision: 0.7828, recall: 0.4950, f1: 0.6064, edges-pos-ontonotes_loss: 0.0363
09/16 08:16:05 AM: Update 28230: task edges-pos-ontonotes, batch 230 (28230): mcc: 0.6127, acc: 0.4383, precision: 0.7792, recall: 0.4915, f1: 0.6028, edges-pos-ontonotes_loss: 0.0365
09/16 08:16:16 AM: Update 28301: task edges-pos-ontonotes, batch 301 (28301): mcc: 0.6119, acc: 0.4378, precision: 0.7782, recall: 0.4909, f1: 0.6020, edges-pos-ontonotes_loss: 0.0364
09/16 08:16:26 AM: Update 28345: task edges-pos-ontonotes, batch 345 (28345): mcc: 0.5989, acc: 0.4240, precision: 0.7684, recall: 0.4767, f1: 0.5884, edges-pos-ontonotes_loss: 0.0374
09/16 08:16:36 AM: Update 28404: task edges-pos-ontonotes, batch 404 (28404): mcc: 0.5924, acc: 0.4172, precision: 0.7638, recall: 0.4694, f1: 0.5815, edges-pos-ontonotes_loss: 0.0383
09/16 08:16:46 AM: Update 28457: task edges-pos-ontonotes, batch 457 (28457): mcc: 0.5842, acc: 0.4086, precision: 0.7579, recall: 0.4603, f1: 0.5727, edges-pos-ontonotes_loss: 0.0390
09/16 08:16:56 AM: Update 28521: task edges-pos-ontonotes, batch 521 (28521): mcc: 0.5824, acc: 0.4064, precision: 0.7567, recall: 0.4582, f1: 0.5708, edges-pos-ontonotes_loss: 0.0395
09/16 08:17:06 AM: Update 28577: task edges-pos-ontonotes, batch 577 (28577): mcc: 0.5799, acc: 0.4036, precision: 0.7551, recall: 0.4553, f1: 0.5681, edges-pos-ontonotes_loss: 0.0398
09/16 08:17:16 AM: Update 28624: task edges-pos-ontonotes, batch 624 (28624): mcc: 0.5774, acc: 0.4010, precision: 0.7535, recall: 0.4525, f1: 0.5654, edges-pos-ontonotes_loss: 0.0400
09/16 08:17:26 AM: Update 28676: task edges-pos-ontonotes, batch 676 (28676): mcc: 0.5753, acc: 0.3987, precision: 0.7524, recall: 0.4500, f1: 0.5632, edges-pos-ontonotes_loss: 0.0403
09/16 08:17:36 AM: Update 28735: task edges-pos-ontonotes, batch 735 (28735): mcc: 0.5752, acc: 0.3985, precision: 0.7529, recall: 0.4495, f1: 0.5629, edges-pos-ontonotes_loss: 0.0405
09/16 08:17:47 AM: Update 28792: task edges-pos-ontonotes, batch 792 (28792): mcc: 0.5751, acc: 0.3984, precision: 0.7533, recall: 0.4492, f1: 0.5628, edges-pos-ontonotes_loss: 0.0406
09/16 08:17:57 AM: Update 28849: task edges-pos-ontonotes, batch 849 (28849): mcc: 0.5752, acc: 0.3985, precision: 0.7537, recall: 0.4489, f1: 0.5627, edges-pos-ontonotes_loss: 0.0407
09/16 08:18:07 AM: Update 28903: task edges-pos-ontonotes, batch 903 (28903): mcc: 0.5746, acc: 0.3981, precision: 0.7535, recall: 0.4483, f1: 0.5621, edges-pos-ontonotes_loss: 0.0408
09/16 08:18:17 AM: Update 28941: task edges-pos-ontonotes, batch 941 (28941): mcc: 0.5729, acc: 0.3963, precision: 0.7522, recall: 0.4463, f1: 0.5602, edges-pos-ontonotes_loss: 0.0409
09/16 08:18:27 AM: Update 28995: task edges-pos-ontonotes, batch 995 (28995): mcc: 0.5724, acc: 0.3958, precision: 0.7521, recall: 0.4456, f1: 0.5596, edges-pos-ontonotes_loss: 0.0410
09/16 08:18:28 AM: ***** Step 29000 / Validation 29 *****
09/16 08:18:28 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:18:28 AM: Validating...
09/16 08:18:37 AM: Evaluate: task edges-pos-ontonotes, batch 66 (157): mcc: 0.7131, acc: 0.5399, precision: 0.9194, recall: 0.5598, f1: 0.6959, edges-pos-ontonotes_loss: 0.0297
09/16 08:18:47 AM: Evaluate: task edges-pos-ontonotes, batch 119 (157): mcc: 0.7019, acc: 0.5274, precision: 0.9092, recall: 0.5488, f1: 0.6845, edges-pos-ontonotes_loss: 0.0297
09/16 08:19:02 AM: Evaluate: task edges-pos-ontonotes, batch 154 (157): mcc: 0.6893, acc: 0.5099, precision: 0.9058, recall: 0.5315, f1: 0.6699, edges-pos-ontonotes_loss: 0.0305
09/16 08:19:03 AM: Best result seen so far for edges-pos-ontonotes.
09/16 08:19:03 AM: Best result seen so far for macro.
09/16 08:19:03 AM: Updating LR scheduler:
09/16 08:19:03 AM: 	Best result seen so far for macro_avg: 0.670
09/16 08:19:03 AM: 	# validation passes without improvement: 0
09/16 08:19:03 AM: edges-pos-ontonotes_loss: training: 0.041029 validation: 0.030527
09/16 08:19:03 AM: macro_avg: validation: 0.670396
09/16 08:19:03 AM: micro_avg: validation: 0.000000
09/16 08:19:03 AM: edges-pos-ontonotes_mcc: training: 0.572495 validation: 0.689734
09/16 08:19:03 AM: edges-pos-ontonotes_acc: training: 0.395960 validation: 0.510429
09/16 08:19:03 AM: edges-pos-ontonotes_precision: training: 0.752275 validation: 0.906035
09/16 08:19:03 AM: edges-pos-ontonotes_recall: training: 0.445681 validation: 0.532027
09/16 08:19:03 AM: edges-pos-ontonotes_f1: training: 0.559744 validation: 0.670396
09/16 08:19:03 AM: Global learning rate: 0.0001
09/16 08:19:03 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 08:19:13 AM: Update 29061: task edges-pos-ontonotes, batch 61 (29061): mcc: 0.5912, acc: 0.4152, precision: 0.7745, recall: 0.4608, f1: 0.5779, edges-pos-ontonotes_loss: 0.0411
09/16 08:19:23 AM: Update 29122: task edges-pos-ontonotes, batch 122 (29122): mcc: 0.5868, acc: 0.4111, precision: 0.7693, recall: 0.4572, f1: 0.5736, edges-pos-ontonotes_loss: 0.0414
09/16 08:19:33 AM: Update 29180: task edges-pos-ontonotes, batch 180 (29180): mcc: 0.5833, acc: 0.4075, precision: 0.7666, recall: 0.4536, f1: 0.5699, edges-pos-ontonotes_loss: 0.0414
09/16 08:19:43 AM: Update 29236: task edges-pos-ontonotes, batch 236 (29236): mcc: 0.5816, acc: 0.4060, precision: 0.7650, recall: 0.4519, f1: 0.5682, edges-pos-ontonotes_loss: 0.0415
09/16 08:19:53 AM: Update 29279: task edges-pos-ontonotes, batch 279 (29279): mcc: 0.5791, acc: 0.4032, precision: 0.7631, recall: 0.4492, f1: 0.5655, edges-pos-ontonotes_loss: 0.0416
09/16 08:20:03 AM: Update 29328: task edges-pos-ontonotes, batch 328 (29328): mcc: 0.5756, acc: 0.3996, precision: 0.7609, recall: 0.4452, f1: 0.5618, edges-pos-ontonotes_loss: 0.0419
09/16 08:20:13 AM: Update 29389: task edges-pos-ontonotes, batch 389 (29389): mcc: 0.5762, acc: 0.4001, precision: 0.7614, recall: 0.4459, f1: 0.5624, edges-pos-ontonotes_loss: 0.0419
09/16 08:20:23 AM: Update 29444: task edges-pos-ontonotes, batch 444 (29444): mcc: 0.5762, acc: 0.3999, precision: 0.7616, recall: 0.4457, f1: 0.5623, edges-pos-ontonotes_loss: 0.0419
09/16 08:20:33 AM: Update 29505: task edges-pos-ontonotes, batch 505 (29505): mcc: 0.5779, acc: 0.4017, precision: 0.7629, recall: 0.4474, f1: 0.5641, edges-pos-ontonotes_loss: 0.0418
09/16 08:20:45 AM: Update 29559: task edges-pos-ontonotes, batch 559 (29559): mcc: 0.5767, acc: 0.4008, precision: 0.7612, recall: 0.4467, f1: 0.5630, edges-pos-ontonotes_loss: 0.0418
09/16 08:20:55 AM: Update 29623: task edges-pos-ontonotes, batch 623 (29623): mcc: 0.5753, acc: 0.3994, precision: 0.7596, recall: 0.4455, f1: 0.5616, edges-pos-ontonotes_loss: 0.0415
09/16 08:21:05 AM: Update 29687: task edges-pos-ontonotes, batch 687 (29687): mcc: 0.5747, acc: 0.3989, precision: 0.7587, recall: 0.4451, f1: 0.5610, edges-pos-ontonotes_loss: 0.0412
09/16 08:21:15 AM: Update 29761: task edges-pos-ontonotes, batch 761 (29761): mcc: 0.5763, acc: 0.4008, precision: 0.7597, recall: 0.4470, f1: 0.5628, edges-pos-ontonotes_loss: 0.0407
09/16 08:21:25 AM: Update 29832: task edges-pos-ontonotes, batch 832 (29832): mcc: 0.5779, acc: 0.4027, precision: 0.7605, recall: 0.4490, f1: 0.5646, edges-pos-ontonotes_loss: 0.0403
09/16 08:21:35 AM: Update 29901: task edges-pos-ontonotes, batch 901 (29901): mcc: 0.5809, acc: 0.4058, precision: 0.7627, recall: 0.4523, f1: 0.5678, edges-pos-ontonotes_loss: 0.0398
09/16 08:21:45 AM: Update 29994: task edges-pos-ontonotes, batch 994 (29994): mcc: 0.5888, acc: 0.4140, precision: 0.7689, recall: 0.4607, f1: 0.5761, edges-pos-ontonotes_loss: 0.0389
09/16 08:21:46 AM: ***** Step 30000 / Validation 30 *****
09/16 08:21:46 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:21:46 AM: Validating...
09/16 08:21:55 AM: Evaluate: task edges-pos-ontonotes, batch 66 (157): mcc: 0.7115, acc: 0.5382, precision: 0.9232, recall: 0.5549, f1: 0.6932, edges-pos-ontonotes_loss: 0.0296
09/16 08:22:05 AM: Evaluate: task edges-pos-ontonotes, batch 119 (157): mcc: 0.6984, acc: 0.5212, precision: 0.9172, recall: 0.5385, f1: 0.6786, edges-pos-ontonotes_loss: 0.0299
09/16 08:22:13 AM: Updating LR scheduler:
09/16 08:22:13 AM: 	Best result seen so far for macro_avg: 0.670
09/16 08:22:13 AM: 	# validation passes without improvement: 1
09/16 08:22:13 AM: edges-pos-ontonotes_loss: training: 0.038797 validation: 0.030841
09/16 08:22:13 AM: macro_avg: validation: 0.662974
09/16 08:22:13 AM: micro_avg: validation: 0.000000
09/16 08:22:13 AM: edges-pos-ontonotes_mcc: training: 0.589356 validation: 0.685071
09/16 08:22:13 AM: edges-pos-ontonotes_acc: training: 0.414567 validation: 0.502534
09/16 08:22:13 AM: edges-pos-ontonotes_precision: training: 0.769300 validation: 0.914562
09/16 08:22:13 AM: edges-pos-ontonotes_recall: training: 0.461215 validation: 0.519942
09/16 08:22:13 AM: edges-pos-ontonotes_f1: training: 0.576690 validation: 0.662974
09/16 08:22:13 AM: Global learning rate: 0.0001
09/16 08:22:13 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 08:22:15 AM: Update 30019: task edges-pos-ontonotes, batch 19 (30019): mcc: 0.7039, acc: 0.5414, precision: 0.8526, recall: 0.5893, f1: 0.6969, edges-pos-ontonotes_loss: 0.0299
09/16 08:22:25 AM: Update 30112: task edges-pos-ontonotes, batch 112 (30112): mcc: 0.7132, acc: 0.5526, precision: 0.8565, recall: 0.6019, f1: 0.7070, edges-pos-ontonotes_loss: 0.0292
09/16 08:22:35 AM: Update 30189: task edges-pos-ontonotes, batch 189 (30189): mcc: 0.7101, acc: 0.5494, precision: 0.8528, recall: 0.5994, f1: 0.7040, edges-pos-ontonotes_loss: 0.0294
09/16 08:22:46 AM: Update 30292: task edges-pos-ontonotes, batch 292 (30292): mcc: 0.7086, acc: 0.5491, precision: 0.8513, recall: 0.5979, f1: 0.7025, edges-pos-ontonotes_loss: 0.0299
09/16 08:22:56 AM: Update 30408: task edges-pos-ontonotes, batch 408 (30408): mcc: 0.7111, acc: 0.5532, precision: 0.8523, recall: 0.6014, f1: 0.7052, edges-pos-ontonotes_loss: 0.0298
09/16 08:23:06 AM: Update 30508: task edges-pos-ontonotes, batch 508 (30508): mcc: 0.7066, acc: 0.5490, precision: 0.8479, recall: 0.5970, f1: 0.7007, edges-pos-ontonotes_loss: 0.0299
09/16 08:23:16 AM: Update 30649: task edges-pos-ontonotes, batch 649 (30649): mcc: 0.6920, acc: 0.5316, precision: 0.8390, recall: 0.5793, f1: 0.6854, edges-pos-ontonotes_loss: 0.0317
09/16 08:23:26 AM: Update 30784: task edges-pos-ontonotes, batch 784 (30784): mcc: 0.6806, acc: 0.5179, precision: 0.8323, recall: 0.5652, f1: 0.6732, edges-pos-ontonotes_loss: 0.0327
09/16 08:23:36 AM: Update 30853: task edges-pos-ontonotes, batch 853 (30853): mcc: 0.6643, acc: 0.4999, precision: 0.8192, recall: 0.5477, f1: 0.6565, edges-pos-ontonotes_loss: 0.0334
09/16 08:23:46 AM: Update 30918: task edges-pos-ontonotes, batch 918 (30918): mcc: 0.6507, acc: 0.4840, precision: 0.8095, recall: 0.5322, f1: 0.6422, edges-pos-ontonotes_loss: 0.0341
09/16 08:23:56 AM: Update 30980: task edges-pos-ontonotes, batch 980 (30980): mcc: 0.6395, acc: 0.4709, precision: 0.8015, recall: 0.5194, f1: 0.6304, edges-pos-ontonotes_loss: 0.0347
09/16 08:24:00 AM: ***** Step 31000 / Validation 31 *****
09/16 08:24:00 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:24:00 AM: Validating...
09/16 08:24:06 AM: Evaluate: task edges-pos-ontonotes, batch 44 (157): mcc: 0.6997, acc: 0.5227, precision: 0.9113, recall: 0.5441, f1: 0.6814, edges-pos-ontonotes_loss: 0.0307
09/16 08:24:16 AM: Evaluate: task edges-pos-ontonotes, batch 105 (157): mcc: 0.7057, acc: 0.5327, precision: 0.9084, recall: 0.5551, f1: 0.6891, edges-pos-ontonotes_loss: 0.0292
09/16 08:24:26 AM: Evaluate: task edges-pos-ontonotes, batch 151 (157): mcc: 0.6801, acc: 0.4985, precision: 0.8958, recall: 0.5235, f1: 0.6608, edges-pos-ontonotes_loss: 0.0308
09/16 08:24:27 AM: Updating LR scheduler:
09/16 08:24:27 AM: 	Best result seen so far for macro_avg: 0.670
09/16 08:24:27 AM: 	# validation passes without improvement: 2
09/16 08:24:27 AM: edges-pos-ontonotes_loss: training: 0.034941 validation: 0.030785
09/16 08:24:27 AM: macro_avg: validation: 0.661521
09/16 08:24:27 AM: micro_avg: validation: 0.000000
09/16 08:24:27 AM: edges-pos-ontonotes_mcc: training: 0.635342 validation: 0.680778
09/16 08:24:27 AM: edges-pos-ontonotes_acc: training: 0.466006 validation: 0.499106
09/16 08:24:27 AM: edges-pos-ontonotes_precision: training: 0.798676 validation: 0.896365
09/16 08:24:27 AM: edges-pos-ontonotes_recall: training: 0.514740 validation: 0.524186
09/16 08:24:27 AM: edges-pos-ontonotes_f1: training: 0.626018 validation: 0.661521
09/16 08:24:27 AM: Global learning rate: 0.0001
09/16 08:24:27 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 08:24:36 AM: Update 31054: task edges-pos-ontonotes, batch 54 (31054): mcc: 0.5605, acc: 0.3807, precision: 0.7469, recall: 0.4306, f1: 0.5463, edges-pos-ontonotes_loss: 0.0432
09/16 08:24:46 AM: Update 31111: task edges-pos-ontonotes, batch 111 (31111): mcc: 0.5507, acc: 0.3706, precision: 0.7392, recall: 0.4203, f1: 0.5359, edges-pos-ontonotes_loss: 0.0436
09/16 08:24:57 AM: Update 31173: task edges-pos-ontonotes, batch 173 (31173): mcc: 0.5570, acc: 0.3768, precision: 0.7472, recall: 0.4251, f1: 0.5419, edges-pos-ontonotes_loss: 0.0423
09/16 08:25:07 AM: Update 31270: task edges-pos-ontonotes, batch 270 (31270): mcc: 0.5723, acc: 0.3930, precision: 0.7627, recall: 0.4391, f1: 0.5573, edges-pos-ontonotes_loss: 0.0398
09/16 08:25:17 AM: Update 31362: task edges-pos-ontonotes, batch 362 (31362): mcc: 0.5772, acc: 0.3987, precision: 0.7678, recall: 0.4435, f1: 0.5622, edges-pos-ontonotes_loss: 0.0386
09/16 08:25:36 AM: Update 31454: task edges-pos-ontonotes, batch 454 (31454): mcc: 0.5839, acc: 0.4063, precision: 0.7726, recall: 0.4508, f1: 0.5694, edges-pos-ontonotes_loss: 0.0378
09/16 08:25:46 AM: Update 31526: task edges-pos-ontonotes, batch 526 (31526): mcc: 0.5878, acc: 0.4106, precision: 0.7729, recall: 0.4565, f1: 0.5740, edges-pos-ontonotes_loss: 0.0377
09/16 08:25:56 AM: Update 31596: task edges-pos-ontonotes, batch 596 (31596): mcc: 0.5895, acc: 0.4126, precision: 0.7723, recall: 0.4595, f1: 0.5762, edges-pos-ontonotes_loss: 0.0376
09/16 08:26:06 AM: Update 31673: task edges-pos-ontonotes, batch 673 (31673): mcc: 0.5931, acc: 0.4164, precision: 0.7740, recall: 0.4641, f1: 0.5802, edges-pos-ontonotes_loss: 0.0374
09/16 08:26:16 AM: Update 31746: task edges-pos-ontonotes, batch 746 (31746): mcc: 0.5951, acc: 0.4187, precision: 0.7743, recall: 0.4670, f1: 0.5826, edges-pos-ontonotes_loss: 0.0373
09/16 08:26:27 AM: Update 31797: task edges-pos-ontonotes, batch 797 (31797): mcc: 0.5921, acc: 0.4157, precision: 0.7713, recall: 0.4642, f1: 0.5795, edges-pos-ontonotes_loss: 0.0376
09/16 08:26:37 AM: Update 31854: task edges-pos-ontonotes, batch 854 (31854): mcc: 0.5889, acc: 0.4125, precision: 0.7682, recall: 0.4613, f1: 0.5764, edges-pos-ontonotes_loss: 0.0380
09/16 08:26:47 AM: Update 31912: task edges-pos-ontonotes, batch 912 (31912): mcc: 0.5866, acc: 0.4100, precision: 0.7659, recall: 0.4590, f1: 0.5740, edges-pos-ontonotes_loss: 0.0383
09/16 08:26:57 AM: Update 31970: task edges-pos-ontonotes, batch 970 (31970): mcc: 0.5844, acc: 0.4077, precision: 0.7636, recall: 0.4570, f1: 0.5718, edges-pos-ontonotes_loss: 0.0386
09/16 08:27:03 AM: ***** Step 32000 / Validation 32 *****
09/16 08:27:03 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:27:03 AM: Validating...
09/16 08:27:07 AM: Evaluate: task edges-pos-ontonotes, batch 28 (157): mcc: 0.7083, acc: 0.5370, precision: 0.8969, recall: 0.5664, f1: 0.6944, edges-pos-ontonotes_loss: 0.0300
09/16 08:27:17 AM: Evaluate: task edges-pos-ontonotes, batch 94 (157): mcc: 0.7177, acc: 0.5505, precision: 0.9023, recall: 0.5778, f1: 0.7045, edges-pos-ontonotes_loss: 0.0286
09/16 08:27:27 AM: Evaluate: task edges-pos-ontonotes, batch 141 (157): mcc: 0.6895, acc: 0.5128, precision: 0.8890, recall: 0.5421, f1: 0.6735, edges-pos-ontonotes_loss: 0.0302
09/16 08:27:30 AM: Best result seen so far for edges-pos-ontonotes.
09/16 08:27:30 AM: Best result seen so far for macro.
09/16 08:27:30 AM: Updating LR scheduler:
09/16 08:27:30 AM: 	Best result seen so far for macro_avg: 0.674
09/16 08:27:30 AM: 	# validation passes without improvement: 0
09/16 08:27:30 AM: edges-pos-ontonotes_loss: training: 0.038757 validation: 0.030303
09/16 08:27:30 AM: macro_avg: validation: 0.674287
09/16 08:27:30 AM: micro_avg: validation: 0.000000
09/16 08:27:30 AM: edges-pos-ontonotes_mcc: training: 0.582557 validation: 0.690046
09/16 08:27:30 AM: edges-pos-ontonotes_acc: training: 0.405852 validation: 0.513805
09/16 08:27:30 AM: edges-pos-ontonotes_precision: training: 0.761923 validation: 0.888281
09/16 08:27:30 AM: edges-pos-ontonotes_recall: training: 0.455263 validation: 0.543382
09/16 08:27:30 AM: edges-pos-ontonotes_f1: training: 0.569963 validation: 0.674287
09/16 08:27:30 AM: Global learning rate: 0.0001
09/16 08:27:30 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 08:27:37 AM: Update 32043: task edges-pos-ontonotes, batch 43 (32043): mcc: 0.5726, acc: 0.3950, precision: 0.7516, recall: 0.4463, f1: 0.5601, edges-pos-ontonotes_loss: 0.0413
09/16 08:27:47 AM: Update 32091: task edges-pos-ontonotes, batch 91 (32091): mcc: 0.5547, acc: 0.3782, precision: 0.7371, recall: 0.4276, f1: 0.5412, edges-pos-ontonotes_loss: 0.0428
09/16 08:27:57 AM: Update 32147: task edges-pos-ontonotes, batch 147 (32147): mcc: 0.5585, acc: 0.3822, precision: 0.7403, recall: 0.4315, f1: 0.5452, edges-pos-ontonotes_loss: 0.0426
09/16 08:28:07 AM: Update 32203: task edges-pos-ontonotes, batch 203 (32203): mcc: 0.5619, acc: 0.3856, precision: 0.7436, recall: 0.4347, f1: 0.5486, edges-pos-ontonotes_loss: 0.0424
09/16 08:28:17 AM: Update 32258: task edges-pos-ontonotes, batch 258 (32258): mcc: 0.5634, acc: 0.3873, precision: 0.7453, recall: 0.4359, f1: 0.5501, edges-pos-ontonotes_loss: 0.0426
09/16 08:28:28 AM: Update 32318: task edges-pos-ontonotes, batch 318 (32318): mcc: 0.5662, acc: 0.3903, precision: 0.7482, recall: 0.4385, f1: 0.5529, edges-pos-ontonotes_loss: 0.0424
09/16 08:28:38 AM: Update 32370: task edges-pos-ontonotes, batch 370 (32370): mcc: 0.5664, acc: 0.3902, precision: 0.7489, recall: 0.4383, f1: 0.5530, edges-pos-ontonotes_loss: 0.0425
09/16 08:28:48 AM: Update 32415: task edges-pos-ontonotes, batch 415 (32415): mcc: 0.5652, acc: 0.3890, precision: 0.7484, recall: 0.4369, f1: 0.5517, edges-pos-ontonotes_loss: 0.0426
09/16 08:28:58 AM: Update 32474: task edges-pos-ontonotes, batch 474 (32474): mcc: 0.5667, acc: 0.3907, precision: 0.7500, recall: 0.4382, f1: 0.5532, edges-pos-ontonotes_loss: 0.0425
09/16 08:29:08 AM: Update 32526: task edges-pos-ontonotes, batch 526 (32526): mcc: 0.5668, acc: 0.3909, precision: 0.7501, recall: 0.4383, f1: 0.5533, edges-pos-ontonotes_loss: 0.0425
09/16 08:29:18 AM: Update 32584: task edges-pos-ontonotes, batch 584 (32584): mcc: 0.5673, acc: 0.3915, precision: 0.7507, recall: 0.4387, f1: 0.5538, edges-pos-ontonotes_loss: 0.0425
09/16 08:29:28 AM: Update 32646: task edges-pos-ontonotes, batch 646 (32646): mcc: 0.5691, acc: 0.3932, precision: 0.7524, recall: 0.4404, f1: 0.5556, edges-pos-ontonotes_loss: 0.0423
09/16 08:29:38 AM: Update 32702: task edges-pos-ontonotes, batch 702 (32702): mcc: 0.5699, acc: 0.3940, precision: 0.7532, recall: 0.4411, f1: 0.5564, edges-pos-ontonotes_loss: 0.0422
09/16 08:29:48 AM: Update 32748: task edges-pos-ontonotes, batch 748 (32748): mcc: 0.5702, acc: 0.3943, precision: 0.7534, recall: 0.4415, f1: 0.5568, edges-pos-ontonotes_loss: 0.0422
09/16 08:29:59 AM: Update 32811: task edges-pos-ontonotes, batch 811 (32811): mcc: 0.5714, acc: 0.3954, precision: 0.7546, recall: 0.4425, f1: 0.5579, edges-pos-ontonotes_loss: 0.0421
09/16 08:30:09 AM: Update 32871: task edges-pos-ontonotes, batch 871 (32871): mcc: 0.5720, acc: 0.3960, precision: 0.7553, recall: 0.4431, f1: 0.5585, edges-pos-ontonotes_loss: 0.0421
09/16 08:30:19 AM: Update 32925: task edges-pos-ontonotes, batch 925 (32925): mcc: 0.5721, acc: 0.3962, precision: 0.7554, recall: 0.4432, f1: 0.5586, edges-pos-ontonotes_loss: 0.0421
09/16 08:30:29 AM: Update 32982: task edges-pos-ontonotes, batch 982 (32982): mcc: 0.5724, acc: 0.3965, precision: 0.7557, recall: 0.4434, f1: 0.5589, edges-pos-ontonotes_loss: 0.0421
09/16 08:30:32 AM: ***** Step 33000 / Validation 33 *****
09/16 08:30:32 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:30:32 AM: Validating...
09/16 08:30:39 AM: Evaluate: task edges-pos-ontonotes, batch 48 (157): mcc: 0.6945, acc: 0.5141, precision: 0.9188, recall: 0.5317, f1: 0.6736, edges-pos-ontonotes_loss: 0.0313
09/16 08:30:49 AM: Evaluate: task edges-pos-ontonotes, batch 109 (157): mcc: 0.7043, acc: 0.5288, precision: 0.9167, recall: 0.5479, f1: 0.6859, edges-pos-ontonotes_loss: 0.0296
09/16 08:30:59 AM: Evaluate: task edges-pos-ontonotes, batch 155 (157): mcc: 0.6889, acc: 0.5083, precision: 0.9112, recall: 0.5276, f1: 0.6683, edges-pos-ontonotes_loss: 0.0305
09/16 08:31:00 AM: Updating LR scheduler:
09/16 08:31:00 AM: 	Best result seen so far for macro_avg: 0.674
09/16 08:31:00 AM: 	# validation passes without improvement: 1
09/16 08:31:00 AM: edges-pos-ontonotes_loss: training: 0.042057 validation: 0.030487
09/16 08:31:00 AM: macro_avg: validation: 0.668846
09/16 08:31:00 AM: micro_avg: validation: 0.000000
09/16 08:31:00 AM: edges-pos-ontonotes_mcc: training: 0.572428 validation: 0.689363
09/16 08:31:00 AM: edges-pos-ontonotes_acc: training: 0.396526 validation: 0.508894
09/16 08:31:00 AM: edges-pos-ontonotes_precision: training: 0.755727 validation: 0.911428
09/16 08:31:00 AM: edges-pos-ontonotes_recall: training: 0.443479 validation: 0.528250
09/16 08:31:00 AM: edges-pos-ontonotes_f1: training: 0.558951 validation: 0.668846
09/16 08:31:00 AM: Global learning rate: 0.0001
09/16 08:31:00 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 08:31:13 AM: Update 33019: task edges-pos-ontonotes, batch 19 (33019): mcc: 0.5237, acc: 0.3564, precision: 0.7054, recall: 0.3995, f1: 0.5101, edges-pos-ontonotes_loss: 0.0442
09/16 08:31:24 AM: Update 33084: task edges-pos-ontonotes, batch 84 (33084): mcc: 0.5495, acc: 0.3773, precision: 0.7321, recall: 0.4227, f1: 0.5359, edges-pos-ontonotes_loss: 0.0394
09/16 08:31:34 AM: Update 33154: task edges-pos-ontonotes, batch 154 (33154): mcc: 0.5668, acc: 0.3935, precision: 0.7472, recall: 0.4400, f1: 0.5538, edges-pos-ontonotes_loss: 0.0383
09/16 08:31:44 AM: Update 33223: task edges-pos-ontonotes, batch 223 (33223): mcc: 0.5745, acc: 0.4014, precision: 0.7535, recall: 0.4480, f1: 0.5619, edges-pos-ontonotes_loss: 0.0378
09/16 08:31:54 AM: Update 33292: task edges-pos-ontonotes, batch 292 (33292): mcc: 0.5772, acc: 0.4041, precision: 0.7559, recall: 0.4507, f1: 0.5647, edges-pos-ontonotes_loss: 0.0375
09/16 08:32:04 AM: Update 33358: task edges-pos-ontonotes, batch 358 (33358): mcc: 0.5858, acc: 0.4129, precision: 0.7629, recall: 0.4597, f1: 0.5737, edges-pos-ontonotes_loss: 0.0369
09/16 08:32:14 AM: Update 33449: task edges-pos-ontonotes, batch 449 (33449): mcc: 0.6047, acc: 0.4322, precision: 0.7781, recall: 0.4796, f1: 0.5934, edges-pos-ontonotes_loss: 0.0355
09/16 08:32:24 AM: Update 33535: task edges-pos-ontonotes, batch 535 (33535): mcc: 0.6188, acc: 0.4472, precision: 0.7890, recall: 0.4948, f1: 0.6082, edges-pos-ontonotes_loss: 0.0345
09/16 08:32:34 AM: Update 33631: task edges-pos-ontonotes, batch 631 (33631): mcc: 0.6305, acc: 0.4599, precision: 0.7974, recall: 0.5078, f1: 0.6205, edges-pos-ontonotes_loss: 0.0336
09/16 08:32:44 AM: Update 33720: task edges-pos-ontonotes, batch 720 (33720): mcc: 0.6370, acc: 0.4675, precision: 0.8021, recall: 0.5152, f1: 0.6274, edges-pos-ontonotes_loss: 0.0333
09/16 08:32:54 AM: Update 33833: task edges-pos-ontonotes, batch 833 (33833): mcc: 0.6442, acc: 0.4758, precision: 0.8072, recall: 0.5232, f1: 0.6349, edges-pos-ontonotes_loss: 0.0328
09/16 08:33:04 AM: Update 33950: task edges-pos-ontonotes, batch 950 (33950): mcc: 0.6509, acc: 0.4839, precision: 0.8116, recall: 0.5312, f1: 0.6421, edges-pos-ontonotes_loss: 0.0324
09/16 08:33:10 AM: ***** Step 34000 / Validation 34 *****
09/16 08:33:10 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:33:10 AM: Validating...
09/16 08:33:14 AM: Evaluate: task edges-pos-ontonotes, batch 35 (157): mcc: 0.7042, acc: 0.5313, precision: 0.9070, recall: 0.5537, f1: 0.6876, edges-pos-ontonotes_loss: 0.0298
09/16 08:33:25 AM: Evaluate: task edges-pos-ontonotes, batch 99 (157): mcc: 0.7109, acc: 0.5415, precision: 0.9087, recall: 0.5630, f1: 0.6953, edges-pos-ontonotes_loss: 0.0287
09/16 08:33:35 AM: Evaluate: task edges-pos-ontonotes, batch 146 (157): mcc: 0.6821, acc: 0.5033, precision: 0.8930, recall: 0.5281, f1: 0.6637, edges-pos-ontonotes_loss: 0.0307
09/16 08:33:37 AM: Updating LR scheduler:
09/16 08:33:37 AM: 	Best result seen so far for macro_avg: 0.674
09/16 08:33:37 AM: 	# validation passes without improvement: 2
09/16 08:33:37 AM: edges-pos-ontonotes_loss: training: 0.032707 validation: 0.030703
09/16 08:33:37 AM: macro_avg: validation: 0.665209
09/16 08:33:37 AM: micro_avg: validation: 0.000000
09/16 08:33:37 AM: edges-pos-ontonotes_mcc: training: 0.649267 validation: 0.683409
09/16 08:33:37 AM: edges-pos-ontonotes_acc: training: 0.482107 validation: 0.504926
09/16 08:33:37 AM: edges-pos-ontonotes_precision: training: 0.810206 validation: 0.893857
09/16 08:33:37 AM: edges-pos-ontonotes_recall: training: 0.529397 validation: 0.529710
09/16 08:33:37 AM: edges-pos-ontonotes_f1: training: 0.640370 validation: 0.665209
09/16 08:33:37 AM: Global learning rate: 0.0001
09/16 08:33:37 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 08:33:45 AM: Update 34110: task edges-pos-ontonotes, batch 110 (34110): mcc: 0.6059, acc: 0.4326, precision: 0.7812, recall: 0.4795, f1: 0.5942, edges-pos-ontonotes_loss: 0.0372
09/16 08:33:55 AM: Update 34248: task edges-pos-ontonotes, batch 248 (34248): mcc: 0.6113, acc: 0.4382, precision: 0.7877, recall: 0.4839, f1: 0.5995, edges-pos-ontonotes_loss: 0.0371
09/16 08:34:05 AM: Update 34311: task edges-pos-ontonotes, batch 311 (34311): mcc: 0.5859, acc: 0.4123, precision: 0.7618, recall: 0.4606, f1: 0.5741, edges-pos-ontonotes_loss: 0.0382
09/16 08:34:15 AM: Update 34378: task edges-pos-ontonotes, batch 378 (34378): mcc: 0.5750, acc: 0.3995, precision: 0.7528, recall: 0.4492, f1: 0.5627, edges-pos-ontonotes_loss: 0.0392
09/16 08:34:25 AM: Update 34438: task edges-pos-ontonotes, batch 438 (34438): mcc: 0.5685, acc: 0.3919, precision: 0.7480, recall: 0.4421, f1: 0.5558, edges-pos-ontonotes_loss: 0.0397
09/16 08:34:35 AM: Update 34497: task edges-pos-ontonotes, batch 497 (34497): mcc: 0.5655, acc: 0.3882, precision: 0.7464, recall: 0.4385, f1: 0.5524, edges-pos-ontonotes_loss: 0.0402
09/16 08:34:45 AM: Update 34556: task edges-pos-ontonotes, batch 556 (34556): mcc: 0.5601, acc: 0.3825, precision: 0.7423, recall: 0.4328, f1: 0.5468, edges-pos-ontonotes_loss: 0.0406
09/16 08:34:55 AM: Update 34610: task edges-pos-ontonotes, batch 610 (34610): mcc: 0.5582, acc: 0.3804, precision: 0.7411, recall: 0.4306, f1: 0.5447, edges-pos-ontonotes_loss: 0.0408
09/16 08:35:06 AM: Update 34698: task edges-pos-ontonotes, batch 698 (34698): mcc: 0.5633, acc: 0.3856, precision: 0.7471, recall: 0.4348, f1: 0.5497, edges-pos-ontonotes_loss: 0.0402
09/16 08:35:16 AM: Update 34778: task edges-pos-ontonotes, batch 778 (34778): mcc: 0.5679, acc: 0.3902, precision: 0.7522, recall: 0.4387, f1: 0.5542, edges-pos-ontonotes_loss: 0.0397
09/16 08:35:26 AM: Update 34851: task edges-pos-ontonotes, batch 851 (34851): mcc: 0.5720, acc: 0.3944, precision: 0.7563, recall: 0.4425, f1: 0.5583, edges-pos-ontonotes_loss: 0.0392
09/16 08:35:37 AM: Update 34914: task edges-pos-ontonotes, batch 914 (34914): mcc: 0.5739, acc: 0.3965, precision: 0.7582, recall: 0.4442, f1: 0.5602, edges-pos-ontonotes_loss: 0.0389
09/16 08:35:47 AM: Update 34963: task edges-pos-ontonotes, batch 963 (34963): mcc: 0.5756, acc: 0.3983, precision: 0.7589, recall: 0.4464, f1: 0.5621, edges-pos-ontonotes_loss: 0.0388
09/16 08:35:55 AM: ***** Step 35000 / Validation 35 *****
09/16 08:35:55 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:35:55 AM: Validating...
09/16 08:35:57 AM: Evaluate: task edges-pos-ontonotes, batch 14 (157): mcc: 0.7081, acc: 0.5341, precision: 0.9052, recall: 0.5610, f1: 0.6927, edges-pos-ontonotes_loss: 0.0293
09/16 08:36:07 AM: Evaluate: task edges-pos-ontonotes, batch 71 (157): mcc: 0.7263, acc: 0.5591, precision: 0.9194, recall: 0.5805, f1: 0.7116, edges-pos-ontonotes_loss: 0.0276
09/16 08:36:18 AM: Evaluate: task edges-pos-ontonotes, batch 116 (157): mcc: 0.7081, acc: 0.5356, precision: 0.9082, recall: 0.5590, f1: 0.6921, edges-pos-ontonotes_loss: 0.0286
09/16 08:36:28 AM: Evaluate: task edges-pos-ontonotes, batch 157 (157): mcc: 0.6909, acc: 0.5119, precision: 0.9013, recall: 0.5367, f1: 0.6728, edges-pos-ontonotes_loss: 0.0300
09/16 08:36:28 AM: Updating LR scheduler:
09/16 08:36:28 AM: 	Best result seen so far for macro_avg: 0.674
09/16 08:36:28 AM: 	# validation passes without improvement: 3
09/16 08:36:28 AM: edges-pos-ontonotes_loss: training: 0.038748 validation: 0.029953
09/16 08:36:28 AM: macro_avg: validation: 0.672804
09/16 08:36:28 AM: micro_avg: validation: 0.000000
09/16 08:36:28 AM: edges-pos-ontonotes_mcc: training: 0.576146 validation: 0.690932
09/16 08:36:28 AM: edges-pos-ontonotes_acc: training: 0.398982 validation: 0.511889
09/16 08:36:28 AM: edges-pos-ontonotes_precision: training: 0.758895 validation: 0.901258
09/16 08:36:28 AM: edges-pos-ontonotes_recall: training: 0.447252 validation: 0.536747
09/16 08:36:28 AM: edges-pos-ontonotes_f1: training: 0.562813 validation: 0.672804
09/16 08:36:28 AM: Global learning rate: 0.0001
09/16 08:36:28 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 08:36:38 AM: Update 35057: task edges-pos-ontonotes, batch 57 (35057): mcc: 0.6296, acc: 0.4566, precision: 0.7930, recall: 0.5093, f1: 0.6203, edges-pos-ontonotes_loss: 0.0357
09/16 08:36:48 AM: Update 35109: task edges-pos-ontonotes, batch 109 (35109): mcc: 0.6196, acc: 0.4469, precision: 0.7844, recall: 0.4990, f1: 0.6100, edges-pos-ontonotes_loss: 0.0363
09/16 08:36:58 AM: Update 35171: task edges-pos-ontonotes, batch 171 (35171): mcc: 0.6194, acc: 0.4473, precision: 0.7837, recall: 0.4992, f1: 0.6099, edges-pos-ontonotes_loss: 0.0358
09/16 08:37:08 AM: Update 35214: task edges-pos-ontonotes, batch 214 (35214): mcc: 0.6190, acc: 0.4468, precision: 0.7829, recall: 0.4991, f1: 0.6096, edges-pos-ontonotes_loss: 0.0360
09/16 08:37:21 AM: Update 35227: task edges-pos-ontonotes, batch 227 (35227): mcc: 0.6165, acc: 0.4444, precision: 0.7803, recall: 0.4968, f1: 0.6071, edges-pos-ontonotes_loss: 0.0361
09/16 08:37:31 AM: Update 35270: task edges-pos-ontonotes, batch 270 (35270): mcc: 0.5998, acc: 0.4268, precision: 0.7671, recall: 0.4790, f1: 0.5897, edges-pos-ontonotes_loss: 0.0375
09/16 08:37:41 AM: Update 35316: task edges-pos-ontonotes, batch 316 (35316): mcc: 0.5926, acc: 0.4187, precision: 0.7625, recall: 0.4706, f1: 0.5820, edges-pos-ontonotes_loss: 0.0383
09/16 08:37:51 AM: Update 35364: task edges-pos-ontonotes, batch 364 (35364): mcc: 0.5884, acc: 0.4142, precision: 0.7597, recall: 0.4657, f1: 0.5775, edges-pos-ontonotes_loss: 0.0390
09/16 08:38:01 AM: Update 35407: task edges-pos-ontonotes, batch 407 (35407): mcc: 0.5855, acc: 0.4109, precision: 0.7578, recall: 0.4623, f1: 0.5743, edges-pos-ontonotes_loss: 0.0393
09/16 08:38:12 AM: Update 35457: task edges-pos-ontonotes, batch 457 (35457): mcc: 0.5831, acc: 0.4084, precision: 0.7560, recall: 0.4598, f1: 0.5718, edges-pos-ontonotes_loss: 0.0395
09/16 08:38:22 AM: Update 35502: task edges-pos-ontonotes, batch 502 (35502): mcc: 0.5797, acc: 0.4044, precision: 0.7536, recall: 0.4560, f1: 0.5682, edges-pos-ontonotes_loss: 0.0399
09/16 08:38:32 AM: Update 35540: task edges-pos-ontonotes, batch 540 (35540): mcc: 0.5782, acc: 0.4030, precision: 0.7525, recall: 0.4544, f1: 0.5666, edges-pos-ontonotes_loss: 0.0401
09/16 08:38:42 AM: Update 35579: task edges-pos-ontonotes, batch 579 (35579): mcc: 0.5754, acc: 0.4001, precision: 0.7505, recall: 0.4513, f1: 0.5637, edges-pos-ontonotes_loss: 0.0404
09/16 08:38:52 AM: Update 35623: task edges-pos-ontonotes, batch 623 (35623): mcc: 0.5751, acc: 0.3996, precision: 0.7505, recall: 0.4507, f1: 0.5632, edges-pos-ontonotes_loss: 0.0406
09/16 08:39:02 AM: Update 35668: task edges-pos-ontonotes, batch 668 (35668): mcc: 0.5750, acc: 0.3996, precision: 0.7508, recall: 0.4505, f1: 0.5631, edges-pos-ontonotes_loss: 0.0407
09/16 08:39:12 AM: Update 35711: task edges-pos-ontonotes, batch 711 (35711): mcc: 0.5743, acc: 0.3988, precision: 0.7507, recall: 0.4495, f1: 0.5623, edges-pos-ontonotes_loss: 0.0408
09/16 08:39:22 AM: Update 35756: task edges-pos-ontonotes, batch 756 (35756): mcc: 0.5736, acc: 0.3980, precision: 0.7505, recall: 0.4486, f1: 0.5615, edges-pos-ontonotes_loss: 0.0409
09/16 08:39:32 AM: Update 35800: task edges-pos-ontonotes, batch 800 (35800): mcc: 0.5737, acc: 0.3980, precision: 0.7510, recall: 0.4483, f1: 0.5615, edges-pos-ontonotes_loss: 0.0409
09/16 08:39:42 AM: Update 35847: task edges-pos-ontonotes, batch 847 (35847): mcc: 0.5739, acc: 0.3981, precision: 0.7514, recall: 0.4484, f1: 0.5616, edges-pos-ontonotes_loss: 0.0410
09/16 08:39:53 AM: Update 35883: task edges-pos-ontonotes, batch 883 (35883): mcc: 0.5731, acc: 0.3974, precision: 0.7509, recall: 0.4474, f1: 0.5607, edges-pos-ontonotes_loss: 0.0410
09/16 08:40:03 AM: Update 35925: task edges-pos-ontonotes, batch 925 (35925): mcc: 0.5730, acc: 0.3974, precision: 0.7510, recall: 0.4472, f1: 0.5606, edges-pos-ontonotes_loss: 0.0411
09/16 08:40:13 AM: Update 35969: task edges-pos-ontonotes, batch 969 (35969): mcc: 0.5729, acc: 0.3972, precision: 0.7513, recall: 0.4468, f1: 0.5604, edges-pos-ontonotes_loss: 0.0412
09/16 08:40:20 AM: ***** Step 36000 / Validation 36 *****
09/16 08:40:20 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:40:20 AM: Validating...
09/16 08:40:23 AM: Evaluate: task edges-pos-ontonotes, batch 16 (157): mcc: 0.7064, acc: 0.5311, precision: 0.9082, recall: 0.5563, f1: 0.6900, edges-pos-ontonotes_loss: 0.0299
09/16 08:40:33 AM: Evaluate: task edges-pos-ontonotes, batch 74 (157): mcc: 0.7197, acc: 0.5505, precision: 0.9169, recall: 0.5716, f1: 0.7042, edges-pos-ontonotes_loss: 0.0290
09/16 08:40:43 AM: Evaluate: task edges-pos-ontonotes, batch 119 (157): mcc: 0.7047, acc: 0.5315, precision: 0.9084, recall: 0.5536, f1: 0.6879, edges-pos-ontonotes_loss: 0.0295
09/16 08:40:53 AM: Best result seen so far for edges-pos-ontonotes.
09/16 08:40:53 AM: Best result seen so far for macro.
09/16 08:40:53 AM: Updating LR scheduler:
09/16 08:40:53 AM: 	Best result seen so far for macro_avg: 0.676
09/16 08:40:53 AM: 	# validation passes without improvement: 0
09/16 08:40:53 AM: edges-pos-ontonotes_loss: training: 0.041211 validation: 0.030209
09/16 08:40:53 AM: macro_avg: validation: 0.675580
09/16 08:40:53 AM: micro_avg: validation: 0.000000
09/16 08:40:53 AM: edges-pos-ontonotes_mcc: training: 0.572858 validation: 0.693827
09/16 08:40:53 AM: edges-pos-ontonotes_acc: training: 0.397165 validation: 0.516662
09/16 08:40:53 AM: edges-pos-ontonotes_precision: training: 0.751560 validation: 0.904836
09/16 08:40:53 AM: edges-pos-ontonotes_recall: training: 0.446678 validation: 0.539012
09/16 08:40:53 AM: edges-pos-ontonotes_f1: training: 0.560331 validation: 0.675580
09/16 08:40:53 AM: Global learning rate: 0.0001
09/16 08:40:53 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 08:40:54 AM: Update 36005: task edges-pos-ontonotes, batch 5 (36005): mcc: 0.6150, acc: 0.4388, precision: 0.7838, recall: 0.4922, f1: 0.6047, edges-pos-ontonotes_loss: 0.0388
09/16 08:41:04 AM: Update 36056: task edges-pos-ontonotes, batch 56 (36056): mcc: 0.5968, acc: 0.4214, precision: 0.7763, recall: 0.4684, f1: 0.5842, edges-pos-ontonotes_loss: 0.0400
09/16 08:41:14 AM: Update 36102: task edges-pos-ontonotes, batch 102 (36102): mcc: 0.5915, acc: 0.4157, precision: 0.7725, recall: 0.4625, f1: 0.5786, edges-pos-ontonotes_loss: 0.0403
09/16 08:41:24 AM: Update 36144: task edges-pos-ontonotes, batch 144 (36144): mcc: 0.5867, acc: 0.4104, precision: 0.7687, recall: 0.4574, f1: 0.5736, edges-pos-ontonotes_loss: 0.0409
09/16 08:41:34 AM: Update 36177: task edges-pos-ontonotes, batch 177 (36177): mcc: 0.5816, acc: 0.4050, precision: 0.7653, recall: 0.4517, f1: 0.5681, edges-pos-ontonotes_loss: 0.0413
09/16 08:41:44 AM: Update 36223: task edges-pos-ontonotes, batch 223 (36223): mcc: 0.5835, acc: 0.4072, precision: 0.7664, recall: 0.4539, f1: 0.5701, edges-pos-ontonotes_loss: 0.0410
09/16 08:41:54 AM: Update 36281: task edges-pos-ontonotes, batch 281 (36281): mcc: 0.5833, acc: 0.4069, precision: 0.7669, recall: 0.4533, f1: 0.5698, edges-pos-ontonotes_loss: 0.0411
09/16 08:42:05 AM: Update 36338: task edges-pos-ontonotes, batch 338 (36338): mcc: 0.5829, acc: 0.4072, precision: 0.7658, recall: 0.4535, f1: 0.5696, edges-pos-ontonotes_loss: 0.0412
09/16 08:42:15 AM: Update 36395: task edges-pos-ontonotes, batch 395 (36395): mcc: 0.5827, acc: 0.4068, precision: 0.7654, recall: 0.4534, f1: 0.5694, edges-pos-ontonotes_loss: 0.0411
09/16 08:42:25 AM: Update 36451: task edges-pos-ontonotes, batch 451 (36451): mcc: 0.5823, acc: 0.4066, precision: 0.7648, recall: 0.4531, f1: 0.5690, edges-pos-ontonotes_loss: 0.0413
09/16 08:42:35 AM: Update 36491: task edges-pos-ontonotes, batch 491 (36491): mcc: 0.5770, acc: 0.4017, precision: 0.7593, recall: 0.4483, f1: 0.5637, edges-pos-ontonotes_loss: 0.0414
09/16 08:42:45 AM: Update 36565: task edges-pos-ontonotes, batch 565 (36565): mcc: 0.5796, acc: 0.4042, precision: 0.7616, recall: 0.4509, f1: 0.5665, edges-pos-ontonotes_loss: 0.0407
09/16 08:42:55 AM: Update 36627: task edges-pos-ontonotes, batch 627 (36627): mcc: 0.5791, acc: 0.4040, precision: 0.7606, recall: 0.4508, f1: 0.5661, edges-pos-ontonotes_loss: 0.0405
09/16 08:43:05 AM: Update 36702: task edges-pos-ontonotes, batch 702 (36702): mcc: 0.5822, acc: 0.4073, precision: 0.7630, recall: 0.4540, f1: 0.5693, edges-pos-ontonotes_loss: 0.0399
09/16 08:43:15 AM: Update 36769: task edges-pos-ontonotes, batch 769 (36769): mcc: 0.5821, acc: 0.4074, precision: 0.7623, recall: 0.4543, f1: 0.5693, edges-pos-ontonotes_loss: 0.0396
09/16 08:43:26 AM: Update 36842: task edges-pos-ontonotes, batch 842 (36842): mcc: 0.5869, acc: 0.4123, precision: 0.7661, recall: 0.4594, f1: 0.5743, edges-pos-ontonotes_loss: 0.0390
09/16 08:43:36 AM: Update 36935: task edges-pos-ontonotes, batch 935 (36935): mcc: 0.5953, acc: 0.4211, precision: 0.7725, recall: 0.4684, f1: 0.5832, edges-pos-ontonotes_loss: 0.0380
09/16 08:43:43 AM: ***** Step 37000 / Validation 37 *****
09/16 08:43:43 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:43:43 AM: Validating...
09/16 08:43:46 AM: Evaluate: task edges-pos-ontonotes, batch 22 (157): mcc: 0.7011, acc: 0.5267, precision: 0.9076, recall: 0.5485, f1: 0.6838, edges-pos-ontonotes_loss: 0.0308
09/16 08:43:56 AM: Evaluate: task edges-pos-ontonotes, batch 91 (157): mcc: 0.7245, acc: 0.5591, precision: 0.9188, recall: 0.5779, f1: 0.7095, edges-pos-ontonotes_loss: 0.0285
09/16 08:44:06 AM: Evaluate: task edges-pos-ontonotes, batch 138 (157): mcc: 0.6951, acc: 0.5189, precision: 0.9082, recall: 0.5389, f1: 0.6764, edges-pos-ontonotes_loss: 0.0302
09/16 08:44:10 AM: Best result seen so far for edges-pos-ontonotes.
09/16 08:44:10 AM: Best result seen so far for macro.
09/16 08:44:10 AM: Updating LR scheduler:
09/16 08:44:10 AM: 	Best result seen so far for macro_avg: 0.677
09/16 08:44:10 AM: 	# validation passes without improvement: 0
09/16 08:44:10 AM: edges-pos-ontonotes_loss: training: 0.037432 validation: 0.030346
09/16 08:44:10 AM: macro_avg: validation: 0.676965
09/16 08:44:10 AM: micro_avg: validation: 0.000000
09/16 08:44:10 AM: edges-pos-ontonotes_mcc: training: 0.600724 validation: 0.695538
09/16 08:44:10 AM: edges-pos-ontonotes_acc: training: 0.426870 validation: 0.519498
09/16 08:44:10 AM: edges-pos-ontonotes_precision: training: 0.776597 validation: 0.908229
09/16 08:44:10 AM: edges-pos-ontonotes_recall: training: 0.474316 validation: 0.539573
09/16 08:44:10 AM: edges-pos-ontonotes_f1: training: 0.588934 validation: 0.676965
09/16 08:44:10 AM: Global learning rate: 0.0001
09/16 08:44:10 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 08:44:16 AM: Update 37052: task edges-pos-ontonotes, batch 52 (37052): mcc: 0.7056, acc: 0.5457, precision: 0.8499, recall: 0.5940, f1: 0.6993, edges-pos-ontonotes_loss: 0.0298
09/16 08:44:31 AM: Update 37105: task edges-pos-ontonotes, batch 105 (37105): mcc: 0.7074, acc: 0.5473, precision: 0.8506, recall: 0.5965, f1: 0.7013, edges-pos-ontonotes_loss: 0.0294
09/16 08:44:41 AM: Update 37224: task edges-pos-ontonotes, batch 224 (37224): mcc: 0.7104, acc: 0.5533, precision: 0.8520, recall: 0.6005, f1: 0.7045, edges-pos-ontonotes_loss: 0.0297
09/16 08:44:51 AM: Update 37332: task edges-pos-ontonotes, batch 332 (37332): mcc: 0.7125, acc: 0.5572, precision: 0.8520, recall: 0.6039, f1: 0.7068, edges-pos-ontonotes_loss: 0.0297
09/16 08:45:01 AM: Update 37419: task edges-pos-ontonotes, batch 419 (37419): mcc: 0.7079, acc: 0.5522, precision: 0.8476, recall: 0.5995, f1: 0.7023, edges-pos-ontonotes_loss: 0.0298
09/16 08:45:11 AM: Update 37566: task edges-pos-ontonotes, batch 566 (37566): mcc: 0.6918, acc: 0.5325, precision: 0.8379, recall: 0.5796, f1: 0.6852, edges-pos-ontonotes_loss: 0.0317
09/16 08:45:21 AM: Update 37708: task edges-pos-ontonotes, batch 708 (37708): mcc: 0.6788, acc: 0.5170, precision: 0.8294, recall: 0.5642, f1: 0.6716, edges-pos-ontonotes_loss: 0.0329
09/16 08:45:31 AM: Update 37768: task edges-pos-ontonotes, batch 768 (37768): mcc: 0.6584, acc: 0.4941, precision: 0.8133, recall: 0.5421, f1: 0.6506, edges-pos-ontonotes_loss: 0.0338
09/16 08:45:41 AM: Update 37832: task edges-pos-ontonotes, batch 832 (37832): mcc: 0.6435, acc: 0.4765, precision: 0.8023, recall: 0.5254, f1: 0.6350, edges-pos-ontonotes_loss: 0.0345
09/16 08:45:51 AM: Update 37893: task edges-pos-ontonotes, batch 893 (37893): mcc: 0.6333, acc: 0.4644, precision: 0.7954, recall: 0.5136, f1: 0.6242, edges-pos-ontonotes_loss: 0.0351
09/16 08:46:02 AM: Update 37957: task edges-pos-ontonotes, batch 957 (37957): mcc: 0.6250, acc: 0.4546, precision: 0.7900, recall: 0.5039, f1: 0.6153, edges-pos-ontonotes_loss: 0.0356
09/16 08:46:08 AM: ***** Step 38000 / Validation 38 *****
09/16 08:46:08 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:46:08 AM: Validating...
09/16 08:46:12 AM: Evaluate: task edges-pos-ontonotes, batch 25 (157): mcc: 0.7014, acc: 0.5259, precision: 0.9041, recall: 0.5511, f1: 0.6848, edges-pos-ontonotes_loss: 0.0302
09/16 08:46:22 AM: Evaluate: task edges-pos-ontonotes, batch 92 (157): mcc: 0.7200, acc: 0.5522, precision: 0.9139, recall: 0.5740, f1: 0.7051, edges-pos-ontonotes_loss: 0.0283
09/16 08:46:32 AM: Evaluate: task edges-pos-ontonotes, batch 139 (157): mcc: 0.6875, acc: 0.5079, precision: 0.8997, recall: 0.5325, f1: 0.6690, edges-pos-ontonotes_loss: 0.0302
09/16 08:46:35 AM: Updating LR scheduler:
09/16 08:46:35 AM: 	Best result seen so far for macro_avg: 0.677
09/16 08:46:35 AM: 	# validation passes without improvement: 1
09/16 08:46:35 AM: edges-pos-ontonotes_loss: training: 0.035872 validation: 0.030288
09/16 08:46:35 AM: macro_avg: validation: 0.669876
09/16 08:46:35 AM: micro_avg: validation: 0.000000
09/16 08:46:35 AM: edges-pos-ontonotes_mcc: training: 0.621062 validation: 0.688159
09/16 08:46:35 AM: edges-pos-ontonotes_acc: training: 0.449993 validation: 0.508767
09/16 08:46:35 AM: edges-pos-ontonotes_precision: training: 0.787342 validation: 0.899171
09/16 08:46:35 AM: edges-pos-ontonotes_recall: training: 0.499434 validation: 0.533763
09/16 08:46:35 AM: edges-pos-ontonotes_f1: training: 0.611179 validation: 0.669876
09/16 08:46:35 AM: Global learning rate: 0.0001
09/16 08:46:35 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 08:46:42 AM: Update 38034: task edges-pos-ontonotes, batch 34 (38034): mcc: 0.5256, acc: 0.3458, precision: 0.7172, recall: 0.3955, f1: 0.5099, edges-pos-ontonotes_loss: 0.0448
09/16 08:46:52 AM: Update 38093: task edges-pos-ontonotes, batch 93 (38093): mcc: 0.5455, acc: 0.3650, precision: 0.7409, recall: 0.4115, f1: 0.5291, edges-pos-ontonotes_loss: 0.0420
09/16 08:47:02 AM: Update 38192: task edges-pos-ontonotes, batch 192 (38192): mcc: 0.5738, acc: 0.3953, precision: 0.7655, recall: 0.4398, f1: 0.5586, edges-pos-ontonotes_loss: 0.0385
09/16 08:47:12 AM: Update 38288: task edges-pos-ontonotes, batch 288 (38288): mcc: 0.5861, acc: 0.4087, precision: 0.7755, recall: 0.4524, f1: 0.5714, edges-pos-ontonotes_loss: 0.0371
09/16 08:47:23 AM: Update 38374: task edges-pos-ontonotes, batch 374 (38374): mcc: 0.5925, acc: 0.4158, precision: 0.7805, recall: 0.4592, f1: 0.5782, edges-pos-ontonotes_loss: 0.0364
09/16 08:47:33 AM: Update 38442: task edges-pos-ontonotes, batch 442 (38442): mcc: 0.5954, acc: 0.4190, precision: 0.7796, recall: 0.4642, f1: 0.5819, edges-pos-ontonotes_loss: 0.0365
09/16 08:47:43 AM: Update 38500: task edges-pos-ontonotes, batch 500 (38500): mcc: 0.5965, acc: 0.4202, precision: 0.7778, recall: 0.4670, f1: 0.5836, edges-pos-ontonotes_loss: 0.0365
09/16 08:47:53 AM: Update 38549: task edges-pos-ontonotes, batch 549 (38549): mcc: 0.5982, acc: 0.4222, precision: 0.7775, recall: 0.4699, f1: 0.5858, edges-pos-ontonotes_loss: 0.0365
09/16 08:48:03 AM: Update 38611: task edges-pos-ontonotes, batch 611 (38611): mcc: 0.6016, acc: 0.4259, precision: 0.7790, recall: 0.4742, f1: 0.5895, edges-pos-ontonotes_loss: 0.0364
09/16 08:48:14 AM: Update 38661: task edges-pos-ontonotes, batch 661 (38661): mcc: 0.6024, acc: 0.4269, precision: 0.7790, recall: 0.4755, f1: 0.5905, edges-pos-ontonotes_loss: 0.0363
09/16 08:48:24 AM: Update 38696: task edges-pos-ontonotes, batch 696 (38696): mcc: 0.5993, acc: 0.4239, precision: 0.7754, recall: 0.4728, f1: 0.5874, edges-pos-ontonotes_loss: 0.0365
09/16 08:48:34 AM: Update 38727: task edges-pos-ontonotes, batch 727 (38727): mcc: 0.5956, acc: 0.4201, precision: 0.7721, recall: 0.4691, f1: 0.5836, edges-pos-ontonotes_loss: 0.0368
09/16 08:48:44 AM: Update 38770: task edges-pos-ontonotes, batch 770 (38770): mcc: 0.5935, acc: 0.4180, precision: 0.7701, recall: 0.4672, f1: 0.5816, edges-pos-ontonotes_loss: 0.0372
09/16 08:48:54 AM: Update 38809: task edges-pos-ontonotes, batch 809 (38809): mcc: 0.5910, acc: 0.4153, precision: 0.7679, recall: 0.4646, f1: 0.5789, edges-pos-ontonotes_loss: 0.0375
09/16 08:49:05 AM: Update 38842: task edges-pos-ontonotes, batch 842 (38842): mcc: 0.5895, acc: 0.4138, precision: 0.7662, recall: 0.4634, f1: 0.5775, edges-pos-ontonotes_loss: 0.0377
09/16 08:49:15 AM: Update 38879: task edges-pos-ontonotes, batch 879 (38879): mcc: 0.5889, acc: 0.4132, precision: 0.7657, recall: 0.4628, f1: 0.5769, edges-pos-ontonotes_loss: 0.0378
09/16 08:49:25 AM: Update 38924: task edges-pos-ontonotes, batch 924 (38924): mcc: 0.5876, acc: 0.4118, precision: 0.7643, recall: 0.4616, f1: 0.5756, edges-pos-ontonotes_loss: 0.0380
09/16 08:49:35 AM: Update 38972: task edges-pos-ontonotes, batch 972 (38972): mcc: 0.5869, acc: 0.4109, precision: 0.7638, recall: 0.4609, f1: 0.5749, edges-pos-ontonotes_loss: 0.0382
09/16 08:49:43 AM: ***** Step 39000 / Validation 39 *****
09/16 08:49:43 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:49:43 AM: Validating...
09/16 08:49:45 AM: Evaluate: task edges-pos-ontonotes, batch 12 (157): mcc: 0.7127, acc: 0.5441, precision: 0.9058, recall: 0.5678, f1: 0.6980, edges-pos-ontonotes_loss: 0.0293
09/16 08:50:03 AM: Evaluate: task edges-pos-ontonotes, batch 68 (157): mcc: 0.7234, acc: 0.5548, precision: 0.9170, recall: 0.5774, f1: 0.7086, edges-pos-ontonotes_loss: 0.0286
09/16 08:50:13 AM: Evaluate: task edges-pos-ontonotes, batch 114 (157): mcc: 0.7112, acc: 0.5392, precision: 0.9103, recall: 0.5625, f1: 0.6954, edges-pos-ontonotes_loss: 0.0288
09/16 08:50:23 AM: Evaluate: task edges-pos-ontonotes, batch 155 (157): mcc: 0.6942, acc: 0.5164, precision: 0.9045, recall: 0.5398, f1: 0.6761, edges-pos-ontonotes_loss: 0.0299
09/16 08:50:23 AM: Updating LR scheduler:
09/16 08:50:23 AM: 	Best result seen so far for macro_avg: 0.677
09/16 08:50:23 AM: 	# validation passes without improvement: 2
09/16 08:50:23 AM: edges-pos-ontonotes_loss: training: 0.038376 validation: 0.029941
09/16 08:50:23 AM: macro_avg: validation: 0.676539
09/16 08:50:23 AM: micro_avg: validation: 0.000000
09/16 08:50:23 AM: edges-pos-ontonotes_mcc: training: 0.585074 validation: 0.694595
09/16 08:50:23 AM: edges-pos-ontonotes_acc: training: 0.409053 validation: 0.516852
09/16 08:50:23 AM: edges-pos-ontonotes_precision: training: 0.762035 validation: 0.904671
09/16 08:50:23 AM: edges-pos-ontonotes_recall: training: 0.459086 validation: 0.540292
09/16 08:50:23 AM: edges-pos-ontonotes_f1: training: 0.572981 validation: 0.676539
09/16 08:50:23 AM: Global learning rate: 0.0001
09/16 08:50:23 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 08:50:33 AM: Update 39030: task edges-pos-ontonotes, batch 30 (39030): mcc: 0.5577, acc: 0.3811, precision: 0.7437, recall: 0.4283, f1: 0.5436, edges-pos-ontonotes_loss: 0.0434
09/16 08:50:43 AM: Update 39060: task edges-pos-ontonotes, batch 60 (39060): mcc: 0.5651, acc: 0.3876, precision: 0.7492, recall: 0.4361, f1: 0.5513, edges-pos-ontonotes_loss: 0.0431
09/16 08:50:53 AM: Update 39100: task edges-pos-ontonotes, batch 100 (39100): mcc: 0.5682, acc: 0.3918, precision: 0.7508, recall: 0.4400, f1: 0.5549, edges-pos-ontonotes_loss: 0.0426
09/16 08:51:04 AM: Update 39146: task edges-pos-ontonotes, batch 146 (39146): mcc: 0.5697, acc: 0.3937, precision: 0.7522, recall: 0.4415, f1: 0.5564, edges-pos-ontonotes_loss: 0.0422
09/16 08:51:14 AM: Update 39194: task edges-pos-ontonotes, batch 194 (39194): mcc: 0.5740, acc: 0.3979, precision: 0.7555, recall: 0.4460, f1: 0.5609, edges-pos-ontonotes_loss: 0.0417
09/16 08:51:24 AM: Update 39238: task edges-pos-ontonotes, batch 238 (39238): mcc: 0.5731, acc: 0.3968, precision: 0.7542, recall: 0.4454, f1: 0.5601, edges-pos-ontonotes_loss: 0.0420
09/16 08:51:34 AM: Update 39279: task edges-pos-ontonotes, batch 279 (39279): mcc: 0.5718, acc: 0.3958, precision: 0.7534, recall: 0.4439, f1: 0.5587, edges-pos-ontonotes_loss: 0.0421
09/16 08:51:45 AM: Update 39313: task edges-pos-ontonotes, batch 313 (39313): mcc: 0.5700, acc: 0.3941, precision: 0.7516, recall: 0.4423, f1: 0.5569, edges-pos-ontonotes_loss: 0.0422
09/16 08:51:55 AM: Update 39356: task edges-pos-ontonotes, batch 356 (39356): mcc: 0.5700, acc: 0.3940, precision: 0.7520, recall: 0.4420, f1: 0.5568, edges-pos-ontonotes_loss: 0.0422
09/16 08:52:05 AM: Update 39404: task edges-pos-ontonotes, batch 404 (39404): mcc: 0.5707, acc: 0.3947, precision: 0.7531, recall: 0.4425, f1: 0.5574, edges-pos-ontonotes_loss: 0.0421
09/16 08:52:15 AM: Update 39452: task edges-pos-ontonotes, batch 452 (39452): mcc: 0.5711, acc: 0.3950, precision: 0.7537, recall: 0.4426, f1: 0.5577, edges-pos-ontonotes_loss: 0.0421
09/16 08:52:26 AM: Update 39495: task edges-pos-ontonotes, batch 495 (39495): mcc: 0.5720, acc: 0.3961, precision: 0.7548, recall: 0.4433, f1: 0.5586, edges-pos-ontonotes_loss: 0.0420
09/16 08:52:36 AM: Update 39538: task edges-pos-ontonotes, batch 538 (39538): mcc: 0.5732, acc: 0.3973, precision: 0.7561, recall: 0.4444, f1: 0.5598, edges-pos-ontonotes_loss: 0.0420
09/16 08:52:46 AM: Update 39592: task edges-pos-ontonotes, batch 592 (39592): mcc: 0.5741, acc: 0.3981, precision: 0.7568, recall: 0.4454, f1: 0.5608, edges-pos-ontonotes_loss: 0.0419
09/16 08:52:56 AM: Update 39634: task edges-pos-ontonotes, batch 634 (39634): mcc: 0.5735, acc: 0.3976, precision: 0.7562, recall: 0.4449, f1: 0.5602, edges-pos-ontonotes_loss: 0.0419
09/16 08:53:06 AM: Update 39692: task edges-pos-ontonotes, batch 692 (39692): mcc: 0.5742, acc: 0.3983, precision: 0.7567, recall: 0.4456, f1: 0.5609, edges-pos-ontonotes_loss: 0.0419
09/16 08:53:16 AM: Update 39747: task edges-pos-ontonotes, batch 747 (39747): mcc: 0.5745, acc: 0.3986, precision: 0.7570, recall: 0.4459, f1: 0.5612, edges-pos-ontonotes_loss: 0.0418
09/16 08:53:26 AM: Update 39799: task edges-pos-ontonotes, batch 799 (39799): mcc: 0.5750, acc: 0.3990, precision: 0.7576, recall: 0.4462, f1: 0.5616, edges-pos-ontonotes_loss: 0.0419
09/16 08:53:36 AM: Update 39855: task edges-pos-ontonotes, batch 855 (39855): mcc: 0.5755, acc: 0.3995, precision: 0.7582, recall: 0.4466, f1: 0.5621, edges-pos-ontonotes_loss: 0.0418
09/16 08:53:46 AM: Update 39914: task edges-pos-ontonotes, batch 914 (39914): mcc: 0.5761, acc: 0.4002, precision: 0.7587, recall: 0.4473, f1: 0.5628, edges-pos-ontonotes_loss: 0.0418
09/16 08:53:56 AM: Update 39966: task edges-pos-ontonotes, batch 966 (39966): mcc: 0.5754, acc: 0.3998, precision: 0.7577, recall: 0.4468, f1: 0.5622, edges-pos-ontonotes_loss: 0.0416
09/16 08:54:01 AM: ***** Step 40000 / Validation 40 *****
09/16 08:54:01 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:54:01 AM: Validating...
09/16 08:54:07 AM: Evaluate: task edges-pos-ontonotes, batch 36 (157): mcc: 0.7018, acc: 0.5259, precision: 0.9171, recall: 0.5437, f1: 0.6827, edges-pos-ontonotes_loss: 0.0305
09/16 08:54:17 AM: Evaluate: task edges-pos-ontonotes, batch 99 (157): mcc: 0.7118, acc: 0.5396, precision: 0.9195, recall: 0.5577, f1: 0.6943, edges-pos-ontonotes_loss: 0.0292
09/16 08:54:27 AM: Evaluate: task edges-pos-ontonotes, batch 144 (157): mcc: 0.6899, acc: 0.5107, precision: 0.9096, recall: 0.5302, f1: 0.6699, edges-pos-ontonotes_loss: 0.0304
09/16 08:54:29 AM: Updating LR scheduler:
09/16 08:54:29 AM: 	Best result seen so far for macro_avg: 0.677
09/16 08:54:29 AM: 	# validation passes without improvement: 3
09/16 08:54:29 AM: edges-pos-ontonotes_loss: training: 0.041459 validation: 0.030305
09/16 08:54:29 AM: macro_avg: validation: 0.672773
09/16 08:54:29 AM: micro_avg: validation: 0.000000
09/16 08:54:29 AM: edges-pos-ontonotes_mcc: training: 0.576021 validation: 0.692382
09/16 08:54:29 AM: edges-pos-ontonotes_acc: training: 0.400416 validation: 0.514154
09/16 08:54:29 AM: edges-pos-ontonotes_precision: training: 0.758176 validation: 0.910116
09/16 08:54:29 AM: edges-pos-ontonotes_recall: training: 0.447498 validation: 0.533615
09/16 08:54:29 AM: edges-pos-ontonotes_f1: training: 0.562810 validation: 0.672773
09/16 08:54:29 AM: Global learning rate: 0.0001
09/16 08:54:29 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 08:54:37 AM: Update 40043: task edges-pos-ontonotes, batch 43 (40043): mcc: 0.5571, acc: 0.3824, precision: 0.7379, recall: 0.4308, f1: 0.5440, edges-pos-ontonotes_loss: 0.0394
09/16 08:54:47 AM: Update 40107: task edges-pos-ontonotes, batch 107 (40107): mcc: 0.5646, acc: 0.3907, precision: 0.7453, recall: 0.4379, f1: 0.5516, edges-pos-ontonotes_loss: 0.0382
09/16 08:54:57 AM: Update 40183: task edges-pos-ontonotes, batch 183 (40183): mcc: 0.5790, acc: 0.4055, precision: 0.7569, recall: 0.4529, f1: 0.5667, edges-pos-ontonotes_loss: 0.0370
09/16 08:55:08 AM: Update 40252: task edges-pos-ontonotes, batch 252 (40252): mcc: 0.5860, acc: 0.4133, precision: 0.7623, recall: 0.4604, f1: 0.5741, edges-pos-ontonotes_loss: 0.0368
09/16 08:55:18 AM: Update 40342: task edges-pos-ontonotes, batch 342 (40342): mcc: 0.6109, acc: 0.4389, precision: 0.7820, recall: 0.4868, f1: 0.6000, edges-pos-ontonotes_loss: 0.0351
09/16 08:55:28 AM: Update 40442: task edges-pos-ontonotes, batch 442 (40442): mcc: 0.6303, acc: 0.4599, precision: 0.7969, recall: 0.5079, f1: 0.6204, edges-pos-ontonotes_loss: 0.0337
09/16 08:55:38 AM: Update 40538: task edges-pos-ontonotes, batch 538 (40538): mcc: 0.6428, acc: 0.4735, precision: 0.8058, recall: 0.5220, f1: 0.6335, edges-pos-ontonotes_loss: 0.0328
09/16 08:55:48 AM: Update 40621: task edges-pos-ontonotes, batch 621 (40621): mcc: 0.6484, acc: 0.4800, precision: 0.8093, recall: 0.5286, f1: 0.6395, edges-pos-ontonotes_loss: 0.0326
09/16 08:55:58 AM: Update 40736: task edges-pos-ontonotes, batch 736 (40736): mcc: 0.6566, acc: 0.4897, precision: 0.8150, recall: 0.5379, f1: 0.6481, edges-pos-ontonotes_loss: 0.0321
09/16 08:56:08 AM: Update 40849: task edges-pos-ontonotes, batch 849 (40849): mcc: 0.6627, acc: 0.4969, precision: 0.8190, recall: 0.5452, f1: 0.6546, edges-pos-ontonotes_loss: 0.0317
09/16 08:56:18 AM: Update 40963: task edges-pos-ontonotes, batch 963 (40963): mcc: 0.6599, acc: 0.4939, precision: 0.8168, recall: 0.5421, f1: 0.6517, edges-pos-ontonotes_loss: 0.0322
09/16 08:56:21 AM: ***** Step 41000 / Validation 41 *****
09/16 08:56:21 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:56:21 AM: Validating...
09/16 08:56:29 AM: Evaluate: task edges-pos-ontonotes, batch 54 (157): mcc: 0.7113, acc: 0.5408, precision: 0.9085, recall: 0.5637, f1: 0.6957, edges-pos-ontonotes_loss: 0.0292
09/16 08:56:39 AM: Evaluate: task edges-pos-ontonotes, batch 113 (157): mcc: 0.7030, acc: 0.5319, precision: 0.8993, recall: 0.5566, f1: 0.6877, edges-pos-ontonotes_loss: 0.0290
09/16 08:56:48 AM: Updating LR scheduler:
09/16 08:56:48 AM: 	Best result seen so far for macro_avg: 0.677
09/16 08:56:48 AM: 	# validation passes without improvement: 0
09/16 08:56:48 AM: edges-pos-ontonotes_loss: training: 0.032401 validation: 0.030489
09/16 08:56:48 AM: macro_avg: validation: 0.665452
09/16 08:56:48 AM: micro_avg: validation: 0.000000
09/16 08:56:48 AM: edges-pos-ontonotes_mcc: training: 0.658876 validation: 0.682878
09/16 08:56:48 AM: edges-pos-ontonotes_acc: training: 0.492608 validation: 0.504672
09/16 08:56:48 AM: edges-pos-ontonotes_precision: training: 0.816159 validation: 0.889442
09/16 08:56:48 AM: edges-pos-ontonotes_recall: training: 0.540892 validation: 0.531583
09/16 08:56:48 AM: edges-pos-ontonotes_f1: training: 0.650608 validation: 0.665452
09/16 08:56:48 AM: Global learning rate: 5e-05
09/16 08:56:48 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 08:56:49 AM: Update 41013: task edges-pos-ontonotes, batch 13 (41013): mcc: 0.6560, acc: 0.4838, precision: 0.8180, recall: 0.5350, f1: 0.6469, edges-pos-ontonotes_loss: 0.0354
09/16 08:56:59 AM: Update 41151: task edges-pos-ontonotes, batch 151 (41151): mcc: 0.6161, acc: 0.4447, precision: 0.7888, recall: 0.4907, f1: 0.6050, edges-pos-ontonotes_loss: 0.0369
09/16 08:57:12 AM: Update 41191: task edges-pos-ontonotes, batch 191 (41191): mcc: 0.6016, acc: 0.4323, precision: 0.7714, recall: 0.4790, f1: 0.5910, edges-pos-ontonotes_loss: 0.0374
09/16 08:57:22 AM: Update 41250: task edges-pos-ontonotes, batch 250 (41250): mcc: 0.5724, acc: 0.3997, precision: 0.7466, recall: 0.4491, f1: 0.5608, edges-pos-ontonotes_loss: 0.0391
09/16 08:57:32 AM: Update 41314: task edges-pos-ontonotes, batch 314 (41314): mcc: 0.5659, acc: 0.3914, precision: 0.7420, recall: 0.4418, f1: 0.5539, edges-pos-ontonotes_loss: 0.0400
09/16 08:57:43 AM: Update 41376: task edges-pos-ontonotes, batch 376 (41376): mcc: 0.5621, acc: 0.3866, precision: 0.7393, recall: 0.4376, f1: 0.5498, edges-pos-ontonotes_loss: 0.0405
09/16 08:57:53 AM: Update 41447: task edges-pos-ontonotes, batch 447 (41447): mcc: 0.5617, acc: 0.3860, precision: 0.7394, recall: 0.4370, f1: 0.5493, edges-pos-ontonotes_loss: 0.0408
09/16 08:58:03 AM: Update 41503: task edges-pos-ontonotes, batch 503 (41503): mcc: 0.5589, acc: 0.3827, precision: 0.7377, recall: 0.4337, f1: 0.5463, edges-pos-ontonotes_loss: 0.0412
09/16 08:58:13 AM: Update 41573: task edges-pos-ontonotes, batch 573 (41573): mcc: 0.5623, acc: 0.3859, precision: 0.7424, recall: 0.4360, f1: 0.5494, edges-pos-ontonotes_loss: 0.0408
09/16 08:58:23 AM: Update 41669: task edges-pos-ontonotes, batch 669 (41669): mcc: 0.5672, acc: 0.3908, precision: 0.7482, recall: 0.4400, f1: 0.5542, edges-pos-ontonotes_loss: 0.0400
09/16 08:58:33 AM: Update 41767: task edges-pos-ontonotes, batch 767 (41767): mcc: 0.5740, acc: 0.3979, precision: 0.7551, recall: 0.4462, f1: 0.5610, edges-pos-ontonotes_loss: 0.0393
09/16 08:58:43 AM: Update 41837: task edges-pos-ontonotes, batch 837 (41837): mcc: 0.5747, acc: 0.3988, precision: 0.7563, recall: 0.4466, f1: 0.5616, edges-pos-ontonotes_loss: 0.0389
09/16 08:58:53 AM: Update 41911: task edges-pos-ontonotes, batch 911 (41911): mcc: 0.5782, acc: 0.4025, precision: 0.7583, recall: 0.4508, f1: 0.5654, edges-pos-ontonotes_loss: 0.0387
09/16 08:59:03 AM: Update 41983: task edges-pos-ontonotes, batch 983 (41983): mcc: 0.5806, acc: 0.4049, precision: 0.7594, recall: 0.4537, f1: 0.5681, edges-pos-ontonotes_loss: 0.0386
09/16 08:59:06 AM: ***** Step 42000 / Validation 42 *****
09/16 08:59:06 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 08:59:06 AM: Validating...
09/16 08:59:13 AM: Evaluate: task edges-pos-ontonotes, batch 53 (157): mcc: 0.7188, acc: 0.5493, precision: 0.9170, recall: 0.5702, f1: 0.7031, edges-pos-ontonotes_loss: 0.0287
09/16 08:59:24 AM: Evaluate: task edges-pos-ontonotes, batch 110 (157): mcc: 0.7167, acc: 0.5478, precision: 0.9101, recall: 0.5713, f1: 0.7020, edges-pos-ontonotes_loss: 0.0281
09/16 08:59:34 AM: Evaluate: task edges-pos-ontonotes, batch 154 (157): mcc: 0.6958, acc: 0.5196, precision: 0.9009, recall: 0.5445, f1: 0.6788, edges-pos-ontonotes_loss: 0.0296
09/16 08:59:34 AM: Best result seen so far for edges-pos-ontonotes.
09/16 08:59:34 AM: Best result seen so far for macro.
09/16 08:59:34 AM: Updating LR scheduler:
09/16 08:59:34 AM: 	Best result seen so far for macro_avg: 0.679
09/16 08:59:34 AM: 	# validation passes without improvement: 0
09/16 08:59:34 AM: edges-pos-ontonotes_loss: training: 0.038505 validation: 0.029668
09/16 08:59:34 AM: macro_avg: validation: 0.679063
09/16 08:59:34 AM: micro_avg: validation: 0.000000
09/16 08:59:34 AM: edges-pos-ontonotes_mcc: training: 0.581336 validation: 0.696074
09/16 08:59:34 AM: edges-pos-ontonotes_acc: training: 0.405687 validation: 0.519847
09/16 08:59:34 AM: edges-pos-ontonotes_precision: training: 0.759807 validation: 0.900885
09/16 08:59:34 AM: edges-pos-ontonotes_recall: training: 0.454683 validation: 0.544896
09/16 08:59:34 AM: edges-pos-ontonotes_f1: training: 0.568916 validation: 0.679063
09/16 08:59:34 AM: Global learning rate: 5e-05
09/16 08:59:34 AM: Saving checkpoints to: ./experiments/pos-ontonotes-hotpot-top/run
09/16 08:59:44 AM: Update 42060: task edges-pos-ontonotes, batch 60 (42060): mcc: 0.6141, acc: 0.4413, precision: 0.7813, recall: 0.4924, f1: 0.6041, edges-pos-ontonotes_loss: 0.0367
09/16 08:59:54 AM: Update 42138: task edges-pos-ontonotes, batch 138 (42138): mcc: 0.6219, acc: 0.4495, precision: 0.7854, recall: 0.5020, f1: 0.6125, edges-pos-ontonotes_loss: 0.0361
09/16 09:00:04 AM: Update 42182: task edges-pos-ontonotes, batch 182 (42182): mcc: 0.5992, acc: 0.4252, precision: 0.7665, recall: 0.4784, f1: 0.5891, edges-pos-ontonotes_loss: 0.0379
09/16 09:00:14 AM: Update 42238: task edges-pos-ontonotes, batch 238 (42238): mcc: 0.5872, acc: 0.4118, precision: 0.7585, recall: 0.4646, f1: 0.5762, edges-pos-ontonotes_loss: 0.0390
