09/16 12:14:43 PM: Git branch: master
09/16 12:14:43 PM: Git SHA: 93c1dfd555f3458ddbb66d458dfeca984f2d8527
09/16 12:14:43 PM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/ner-ontonotes-sst-only/",
  "exp_name": "experiments/ner-ontonotes-sst-only",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/ner-ontonotes-sst-only/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/sst",
  "pytorch_transformers_output_mode": "only",
  "remote_log_name": "experiments/ner-ontonotes-sst-only__run",
  "run_dir": "./experiments/ner-ontonotes-sst-only/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-ner-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 12:14:43 PM: Saved config to ./experiments/ner-ontonotes-sst-only/run/params.conf
09/16 12:14:43 PM: Using random seed 1234
09/16 12:15:22 PM: Using GPU 0
09/16 12:15:22 PM: Loading tasks...
09/16 12:15:22 PM: Writing pre-preprocessed tasks to ./experiments/ner-ontonotes-sst-only/
09/16 12:15:22 PM: 	Creating task edges-ner-ontonotes from scratch.
09/16 12:15:23 PM: Read=49706, Skip=66106, Total=115812 from ./probing_data/edges/ontonotes/ner/train.json.retokenized.bert-base-uncased
09/16 12:15:24 PM: Read=7610, Skip=8070, Total=15680 from ./probing_data/edges/ontonotes/ner/development.json.retokenized.bert-base-uncased
09/16 12:15:24 PM: Read=5099, Skip=7118, Total=12217 from ./probing_data/edges/ontonotes/ner/test.json.retokenized.bert-base-uncased
09/16 12:15:25 PM: 	Task 'edges-ner-ontonotes': |train|=49706 |val|=7610 |test|=5099
09/16 12:15:25 PM: 	Finished loading tasks: edges-ner-ontonotes.
09/16 12:15:25 PM: 	Building vocab from scratch.
09/16 12:15:25 PM: 	Counting units for task edges-ner-ontonotes.
09/16 12:15:26 PM: 	Task 'edges-ner-ontonotes': adding vocab namespace 'edges-ner-ontonotes_labels'
09/16 12:15:28 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:15:28 PM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 12:15:28 PM: 	Saved vocab to ./experiments/ner-ontonotes-sst-only/vocab
09/16 12:15:28 PM: Loading token dictionary from ./experiments/ner-ontonotes-sst-only/vocab.
09/16 12:15:28 PM: 	Loaded vocab from ./experiments/ner-ontonotes-sst-only/vocab
09/16 12:15:28 PM: 	Vocab namespace edges-ner-ontonotes_labels: size 18
09/16 12:15:28 PM: 	Vocab namespace tokens: size 22840
09/16 12:15:28 PM: 	Vocab namespace bert_uncased: size 30524
09/16 12:15:28 PM: 	Vocab namespace chars: size 77
09/16 12:15:28 PM: 	Finished building vocab.
09/16 12:15:28 PM: 	Task edges-ner-ontonotes (train): Indexing from scratch.
09/16 12:15:42 PM: 	Task edges-ner-ontonotes (train): Saved 49706 instances to ./experiments/ner-ontonotes-sst-only/preproc/edges-ner-ontonotes__train_data
09/16 12:15:42 PM: 	Task edges-ner-ontonotes (val): Indexing from scratch.
09/16 12:15:44 PM: 	Task edges-ner-ontonotes (val): Saved 7610 instances to ./experiments/ner-ontonotes-sst-only/preproc/edges-ner-ontonotes__val_data
09/16 12:15:44 PM: 	Task edges-ner-ontonotes (test): Indexing from scratch.
09/16 12:15:45 PM: 	Task edges-ner-ontonotes (test): Saved 5099 instances to ./experiments/ner-ontonotes-sst-only/preproc/edges-ner-ontonotes__test_data
09/16 12:15:45 PM: 	Finished indexing tasks
09/16 12:15:45 PM: 	Creating trimmed target-only version of edges-ner-ontonotes train.
09/16 12:15:45 PM: 	  Training on 
09/16 12:15:45 PM: 	  Evaluating on edges-ner-ontonotes
09/16 12:15:45 PM: 	Finished loading tasks in 23.336s
09/16 12:15:45 PM: 	 Tasks: ['edges-ner-ontonotes']
09/16 12:15:45 PM: Building model...
09/16 12:15:45 PM: Using BERT model (bert-base-uncased).
09/16 12:15:45 PM: LOADING A FUNETUNED MODEL from: 
09/16 12:15:45 PM: models/sst
09/16 12:15:45 PM: loading configuration file models/sst/config.json
09/16 12:15:45 PM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "sst-2",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 12:15:45 PM: loading weights file models/sst/pytorch_model.bin
09/16 12:15:52 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmppvy_r014
09/16 12:15:55 PM: copying /tmp/tmppvy_r014 to cache at ./experiments/ner-ontonotes-sst-only/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:15:55 PM: creating metadata file for ./experiments/ner-ontonotes-sst-only/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:15:55 PM: removing temp file /tmp/tmppvy_r014
09/16 12:15:55 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/ner-ontonotes-sst-only/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:15:55 PM: Initializing parameters
09/16 12:15:55 PM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 12:15:55 PM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 12:15:55 PM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 12:15:55 PM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 12:15:55 PM:    _text_field_embedder.model.pooler.dense.bias
09/16 12:15:55 PM:    _text_field_embedder.model.pooler.dense.weight
09/16 12:15:55 PM: 	Task 'edges-ner-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-ner-ontonotes"
}
09/16 12:17:10 PM: Model specification:
09/16 12:17:10 PM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-ner-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=18, bias=True)
    )
  )
)
09/16 12:17:10 PM: Model parameters:
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:10 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:10 PM: 	edges-ner-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 12:17:10 PM: 	edges-ner-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 12:17:10 PM: 	edges-ner-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 9216 with torch.Size([18, 512])
09/16 12:17:10 PM: 	edges-ner-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 18 with torch.Size([18])
09/16 12:17:10 PM: Total number of parameters: 109688338 (1.09688e+08)
09/16 12:17:10 PM: Number of trainable parameters: 206098 (206098)
09/16 12:17:10 PM: Finished building model in 85.297s
09/16 12:17:10 PM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-ner-ontonotes 

09/16 12:17:22 PM: patience = 9
09/16 12:17:22 PM: val_interval = 1000
09/16 12:17:22 PM: max_vals = 250
09/16 12:17:22 PM: cuda_device = 0
09/16 12:17:22 PM: grad_norm = 5.0
09/16 12:17:22 PM: grad_clipping = None
09/16 12:17:22 PM: lr_decay = 0.99
09/16 12:17:22 PM: min_lr = 1e-06
09/16 12:17:22 PM: keep_all_checkpoints = 0
09/16 12:17:22 PM: val_data_limit = 5000
09/16 12:17:22 PM: max_epochs = -1
09/16 12:17:22 PM: dec_val_scale = 250
09/16 12:17:22 PM: training_data_fraction = 1
09/16 12:17:22 PM: type = adam
09/16 12:17:22 PM: parameter_groups = None
09/16 12:17:22 PM: Number of trainable parameters: 206098
09/16 12:17:22 PM: infer_type_and_cast = True
09/16 12:17:22 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:17:22 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:17:22 PM: lr = 0.0001
09/16 12:17:22 PM: amsgrad = True
09/16 12:17:22 PM: type = reduce_on_plateau
09/16 12:17:22 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:17:22 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:17:22 PM: mode = max
09/16 12:17:22 PM: factor = 0.5
09/16 12:17:22 PM: patience = 3
09/16 12:17:22 PM: threshold = 0.0001
09/16 12:17:22 PM: threshold_mode = abs
09/16 12:17:22 PM: verbose = True
09/16 12:17:22 PM: type = adam
09/16 12:17:22 PM: parameter_groups = None
09/16 12:17:22 PM: Number of trainable parameters: 206098
09/16 12:17:22 PM: infer_type_and_cast = True
09/16 12:17:22 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:17:22 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:17:22 PM: lr = 0.0001
09/16 12:17:22 PM: amsgrad = True
09/16 12:17:22 PM: type = reduce_on_plateau
09/16 12:17:22 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:17:22 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:17:22 PM: mode = max
09/16 12:17:22 PM: factor = 0.5
09/16 12:17:22 PM: patience = 3
09/16 12:17:22 PM: threshold = 0.0001
09/16 12:17:22 PM: threshold_mode = abs
09/16 12:17:22 PM: verbose = True
09/16 12:17:22 PM: Starting training without restoring from a checkpoint.
09/16 12:17:22 PM: Training examples per task, before any subsampling: {'edges-ner-ontonotes': 49706}
09/16 12:17:22 PM: Beginning training with stopping criteria based on metric: edges-ner-ontonotes_f1
09/16 12:17:35 PM: Update 1: task edges-ner-ontonotes, batch 1 (1): mcc: 0.0121, acc: 0.0000, precision: 0.0585, recall: 0.5000, f1: 0.1047, edges-ner-ontonotes_loss: 0.6967
09/16 12:17:45 PM: Update 142: task edges-ner-ontonotes, batch 142 (142): mcc: 0.2023, acc: 0.1831, precision: 0.2346, recall: 0.2650, f1: 0.2489, edges-ner-ontonotes_loss: 0.2708
09/16 12:17:55 PM: Update 255: task edges-ner-ontonotes, batch 255 (255): mcc: 0.3798, acc: 0.3434, precision: 0.4365, recall: 0.3894, f1: 0.4116, edges-ner-ontonotes_loss: 0.1940
09/16 12:18:06 PM: Update 314: task edges-ner-ontonotes, batch 314 (314): mcc: 0.4460, acc: 0.4021, precision: 0.5119, recall: 0.4398, f1: 0.4731, edges-ner-ontonotes_loss: 0.1725
09/16 12:18:16 PM: Update 424: task edges-ner-ontonotes, batch 424 (424): mcc: 0.5277, acc: 0.4713, precision: 0.6093, recall: 0.4989, f1: 0.5486, edges-ner-ontonotes_loss: 0.1485
09/16 12:18:26 PM: Update 539: task edges-ner-ontonotes, batch 539 (539): mcc: 0.5883, acc: 0.5252, precision: 0.6757, recall: 0.5484, f1: 0.6054, edges-ner-ontonotes_loss: 0.1311
09/16 12:18:36 PM: Update 639: task edges-ner-ontonotes, batch 639 (639): mcc: 0.6254, acc: 0.5595, precision: 0.7144, recall: 0.5805, f1: 0.6405, edges-ner-ontonotes_loss: 0.1200
09/16 12:18:46 PM: Update 794: task edges-ner-ontonotes, batch 794 (794): mcc: 0.6633, acc: 0.5940, precision: 0.7520, recall: 0.6150, f1: 0.6766, edges-ner-ontonotes_loss: 0.1081
09/16 12:19:01 PM: Update 940: task edges-ner-ontonotes, batch 940 (940): mcc: 0.6906, acc: 0.6210, precision: 0.7764, recall: 0.6422, f1: 0.7029, edges-ner-ontonotes_loss: 0.0994
09/16 12:19:07 PM: ***** Step 1000 / Validation 1 *****
09/16 12:19:07 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:19:07 PM: Validating...
09/16 12:19:12 PM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.7965, acc: 0.7245, precision: 0.8684, recall: 0.7497, f1: 0.8047, edges-ner-ontonotes_loss: 0.0672
09/16 12:19:22 PM: Evaluate: task edges-ner-ontonotes, batch 142 (157): mcc: 0.8104, acc: 0.7399, precision: 0.8825, recall: 0.7620, f1: 0.8178, edges-ner-ontonotes_loss: 0.0594
09/16 12:19:23 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:19:23 PM: Best result seen so far for micro.
09/16 12:19:23 PM: Best result seen so far for macro.
09/16 12:19:23 PM: Updating LR scheduler:
09/16 12:19:23 PM: 	Best result seen so far for macro_avg: 0.820
09/16 12:19:23 PM: 	# validation passes without improvement: 0
09/16 12:19:23 PM: edges-ner-ontonotes_loss: training: 0.096765 validation: 0.058355
09/16 12:19:23 PM: macro_avg: validation: 0.820300
09/16 12:19:23 PM: micro_avg: validation: 0.000000
09/16 12:19:23 PM: edges-ner-ontonotes_mcc: training: 0.698116 validation: 0.812794
09/16 12:19:23 PM: edges-ner-ontonotes_acc: training: 0.628081 validation: 0.743934
09/16 12:19:23 PM: edges-ner-ontonotes_precision: training: 0.782977 validation: 0.882888
09/16 12:19:23 PM: edges-ner-ontonotes_recall: training: 0.649698 validation: 0.765999
09/16 12:19:23 PM: edges-ner-ontonotes_f1: training: 0.710139 validation: 0.820300
09/16 12:19:23 PM: Global learning rate: 0.0001
09/16 12:19:23 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 12:19:32 PM: Update 1083: task edges-ner-ontonotes, batch 83 (1083): mcc: 0.8275, acc: 0.7627, precision: 0.8876, recall: 0.7883, f1: 0.8350, edges-ner-ontonotes_loss: 0.0491
09/16 12:19:42 PM: Update 1193: task edges-ner-ontonotes, batch 193 (1193): mcc: 0.8329, acc: 0.7680, precision: 0.8932, recall: 0.7929, f1: 0.8400, edges-ner-ontonotes_loss: 0.0485
09/16 12:19:56 PM: Update 1253: task edges-ner-ontonotes, batch 253 (1253): mcc: 0.8300, acc: 0.7648, precision: 0.8911, recall: 0.7896, f1: 0.8373, edges-ner-ontonotes_loss: 0.0486
09/16 12:20:06 PM: Update 1376: task edges-ner-ontonotes, batch 376 (1376): mcc: 0.8185, acc: 0.7520, precision: 0.8856, recall: 0.7739, f1: 0.8260, edges-ner-ontonotes_loss: 0.0539
09/16 12:20:16 PM: Update 1518: task edges-ner-ontonotes, batch 518 (1518): mcc: 0.8192, acc: 0.7534, precision: 0.8874, recall: 0.7734, f1: 0.8265, edges-ner-ontonotes_loss: 0.0549
09/16 12:20:26 PM: Update 1598: task edges-ner-ontonotes, batch 598 (1598): mcc: 0.8205, acc: 0.7554, precision: 0.8886, recall: 0.7747, f1: 0.8277, edges-ner-ontonotes_loss: 0.0546
09/16 12:20:36 PM: Update 1736: task edges-ner-ontonotes, batch 736 (1736): mcc: 0.8262, acc: 0.7637, precision: 0.8926, recall: 0.7814, f1: 0.8333, edges-ner-ontonotes_loss: 0.0529
09/16 12:20:47 PM: Update 1870: task edges-ner-ontonotes, batch 870 (1870): mcc: 0.8317, acc: 0.7715, precision: 0.8963, recall: 0.7879, f1: 0.8386, edges-ner-ontonotes_loss: 0.0512
09/16 12:20:56 PM: ***** Step 2000 / Validation 2 *****
09/16 12:20:56 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:20:56 PM: Validating...
09/16 12:20:57 PM: Evaluate: task edges-ner-ontonotes, batch 39 (157): mcc: 0.8312, acc: 0.7840, precision: 0.8939, recall: 0.7892, f1: 0.8383, edges-ner-ontonotes_loss: 0.0530
09/16 12:21:05 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:21:05 PM: Best result seen so far for macro.
09/16 12:21:05 PM: Updating LR scheduler:
09/16 12:21:05 PM: 	Best result seen so far for macro_avg: 0.843
09/16 12:21:05 PM: 	# validation passes without improvement: 0
09/16 12:21:05 PM: edges-ner-ontonotes_loss: training: 0.050708 validation: 0.049489
09/16 12:21:05 PM: macro_avg: validation: 0.843111
09/16 12:21:05 PM: micro_avg: validation: 0.000000
09/16 12:21:05 PM: edges-ner-ontonotes_mcc: training: 0.832787 validation: 0.836036
09/16 12:21:05 PM: edges-ner-ontonotes_acc: training: 0.773609 validation: 0.783819
09/16 12:21:05 PM: edges-ner-ontonotes_precision: training: 0.896222 validation: 0.895347
09/16 12:21:05 PM: edges-ner-ontonotes_recall: training: 0.789963 validation: 0.796633
09/16 12:21:05 PM: edges-ner-ontonotes_f1: training: 0.839744 validation: 0.843111
09/16 12:21:05 PM: Global learning rate: 0.0001
09/16 12:21:05 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 12:21:07 PM: Update 2024: task edges-ner-ontonotes, batch 24 (2024): mcc: 0.8536, acc: 0.8002, precision: 0.9100, recall: 0.8150, f1: 0.8599, edges-ner-ontonotes_loss: 0.0414
09/16 12:21:17 PM: Update 2118: task edges-ner-ontonotes, batch 118 (2118): mcc: 0.8606, acc: 0.8114, precision: 0.9137, recall: 0.8244, f1: 0.8668, edges-ner-ontonotes_loss: 0.0416
09/16 12:21:27 PM: Update 2205: task edges-ner-ontonotes, batch 205 (2205): mcc: 0.8519, acc: 0.8012, precision: 0.9050, recall: 0.8167, f1: 0.8586, edges-ner-ontonotes_loss: 0.0433
09/16 12:21:37 PM: Update 2359: task edges-ner-ontonotes, batch 359 (2359): mcc: 0.8510, acc: 0.7986, precision: 0.9009, recall: 0.8188, f1: 0.8579, edges-ner-ontonotes_loss: 0.0428
09/16 12:21:47 PM: Update 2463: task edges-ner-ontonotes, batch 463 (2463): mcc: 0.8526, acc: 0.8003, precision: 0.9001, recall: 0.8224, f1: 0.8595, edges-ner-ontonotes_loss: 0.0423
09/16 12:21:57 PM: Update 2497: task edges-ner-ontonotes, batch 497 (2497): mcc: 0.8533, acc: 0.8011, precision: 0.9004, recall: 0.8234, f1: 0.8602, edges-ner-ontonotes_loss: 0.0419
09/16 12:22:07 PM: Update 2620: task edges-ner-ontonotes, batch 620 (2620): mcc: 0.8525, acc: 0.7996, precision: 0.8995, recall: 0.8228, f1: 0.8595, edges-ner-ontonotes_loss: 0.0421
09/16 12:22:18 PM: Update 2776: task edges-ner-ontonotes, batch 776 (2776): mcc: 0.8537, acc: 0.8007, precision: 0.8999, recall: 0.8247, f1: 0.8606, edges-ner-ontonotes_loss: 0.0416
09/16 12:22:28 PM: Update 2856: task edges-ner-ontonotes, batch 856 (2856): mcc: 0.8522, acc: 0.7993, precision: 0.8988, recall: 0.8230, f1: 0.8592, edges-ner-ontonotes_loss: 0.0424
09/16 12:22:38 PM: Update 2983: task edges-ner-ontonotes, batch 983 (2983): mcc: 0.8505, acc: 0.7976, precision: 0.8982, recall: 0.8203, f1: 0.8575, edges-ner-ontonotes_loss: 0.0436
09/16 12:22:39 PM: ***** Step 3000 / Validation 3 *****
09/16 12:22:39 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:22:39 PM: Validating...
09/16 12:22:48 PM: Evaluate: task edges-ner-ontonotes, batch 83 (157): mcc: 0.8486, acc: 0.8053, precision: 0.8993, recall: 0.8158, f1: 0.8556, edges-ner-ontonotes_loss: 0.0492
09/16 12:22:55 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:22:55 PM: Best result seen so far for macro.
09/16 12:22:55 PM: Updating LR scheduler:
09/16 12:22:55 PM: 	Best result seen so far for macro_avg: 0.850
09/16 12:22:55 PM: 	# validation passes without improvement: 0
09/16 12:22:55 PM: edges-ner-ontonotes_loss: training: 0.043672 validation: 0.047384
09/16 12:22:55 PM: macro_avg: validation: 0.850012
09/16 12:22:55 PM: micro_avg: validation: 0.000000
09/16 12:22:55 PM: edges-ner-ontonotes_mcc: training: 0.850524 validation: 0.843019
09/16 12:22:55 PM: edges-ner-ontonotes_acc: training: 0.797588 validation: 0.796027
09/16 12:22:55 PM: edges-ner-ontonotes_precision: training: 0.898226 validation: 0.897840
09/16 12:22:55 PM: edges-ner-ontonotes_recall: training: 0.820360 validation: 0.807022
09/16 12:22:55 PM: edges-ner-ontonotes_f1: training: 0.857529 validation: 0.850012
09/16 12:22:55 PM: Global learning rate: 0.0001
09/16 12:22:55 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 12:22:58 PM: Update 3032: task edges-ner-ontonotes, batch 32 (3032): mcc: 0.8455, acc: 0.7893, precision: 0.9036, recall: 0.8062, f1: 0.8521, edges-ner-ontonotes_loss: 0.0505
09/16 12:23:08 PM: Update 3134: task edges-ner-ontonotes, batch 134 (3134): mcc: 0.8411, acc: 0.7889, precision: 0.8965, recall: 0.8049, f1: 0.8482, edges-ner-ontonotes_loss: 0.0501
09/16 12:23:18 PM: Update 3281: task edges-ner-ontonotes, batch 281 (3281): mcc: 0.8587, acc: 0.8132, precision: 0.9069, recall: 0.8271, f1: 0.8652, edges-ner-ontonotes_loss: 0.0444
09/16 12:23:31 PM: Update 3426: task edges-ner-ontonotes, batch 426 (3426): mcc: 0.8652, acc: 0.8222, precision: 0.9108, recall: 0.8355, f1: 0.8716, edges-ner-ontonotes_loss: 0.0421
09/16 12:23:41 PM: Update 3516: task edges-ner-ontonotes, batch 516 (3516): mcc: 0.8625, acc: 0.8181, precision: 0.9093, recall: 0.8319, f1: 0.8689, edges-ner-ontonotes_loss: 0.0423
09/16 12:23:51 PM: Update 3636: task edges-ner-ontonotes, batch 636 (3636): mcc: 0.8639, acc: 0.8193, precision: 0.9102, recall: 0.8336, f1: 0.8702, edges-ner-ontonotes_loss: 0.0418
09/16 12:24:01 PM: Update 3732: task edges-ner-ontonotes, batch 732 (3732): mcc: 0.8655, acc: 0.8213, precision: 0.9110, recall: 0.8359, f1: 0.8718, edges-ner-ontonotes_loss: 0.0413
09/16 12:24:12 PM: Update 3753: task edges-ner-ontonotes, batch 753 (3753): mcc: 0.8647, acc: 0.8205, precision: 0.9101, recall: 0.8351, f1: 0.8710, edges-ner-ontonotes_loss: 0.0414
09/16 12:24:22 PM: Update 3858: task edges-ner-ontonotes, batch 858 (3858): mcc: 0.8638, acc: 0.8187, precision: 0.9082, recall: 0.8354, f1: 0.8703, edges-ner-ontonotes_loss: 0.0412
09/16 12:24:32 PM: Update 3991: task edges-ner-ontonotes, batch 991 (3991): mcc: 0.8642, acc: 0.8189, precision: 0.9076, recall: 0.8367, f1: 0.8707, edges-ner-ontonotes_loss: 0.0406
09/16 12:24:32 PM: ***** Step 4000 / Validation 4 *****
09/16 12:24:32 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:24:32 PM: Validating...
09/16 12:24:41 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:24:41 PM: Best result seen so far for macro.
09/16 12:24:41 PM: Updating LR scheduler:
09/16 12:24:41 PM: 	Best result seen so far for macro_avg: 0.860
09/16 12:24:41 PM: 	# validation passes without improvement: 0
09/16 12:24:41 PM: edges-ner-ontonotes_loss: training: 0.040580 validation: 0.045611
09/16 12:24:41 PM: macro_avg: validation: 0.859528
09/16 12:24:41 PM: micro_avg: validation: 0.000000
09/16 12:24:41 PM: edges-ner-ontonotes_mcc: training: 0.864434 validation: 0.852302
09/16 12:24:41 PM: edges-ner-ontonotes_acc: training: 0.819053 validation: 0.812254
09/16 12:24:41 PM: edges-ner-ontonotes_precision: training: 0.907762 validation: 0.893875
09/16 12:24:41 PM: edges-ner-ontonotes_recall: training: 0.836928 validation: 0.827722
09/16 12:24:41 PM: edges-ner-ontonotes_f1: training: 0.870907 validation: 0.859528
09/16 12:24:41 PM: Global learning rate: 0.0001
09/16 12:24:41 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 12:24:42 PM: Update 4005: task edges-ner-ontonotes, batch 5 (4005): mcc: 0.8446, acc: 0.7872, precision: 0.8825, recall: 0.8243, f1: 0.8524, edges-ner-ontonotes_loss: 0.0428
09/16 12:24:52 PM: Update 4061: task edges-ner-ontonotes, batch 61 (4061): mcc: 0.8603, acc: 0.8111, precision: 0.8942, recall: 0.8421, f1: 0.8674, edges-ner-ontonotes_loss: 0.0374
09/16 12:25:02 PM: Update 4185: task edges-ner-ontonotes, batch 185 (4185): mcc: 0.8659, acc: 0.8187, precision: 0.9001, recall: 0.8468, f1: 0.8727, edges-ner-ontonotes_loss: 0.0370
09/16 12:25:12 PM: Update 4310: task edges-ner-ontonotes, batch 310 (4310): mcc: 0.8673, acc: 0.8198, precision: 0.9031, recall: 0.8467, f1: 0.8740, edges-ner-ontonotes_loss: 0.0370
09/16 12:25:22 PM: Update 4434: task edges-ner-ontonotes, batch 434 (4434): mcc: 0.8632, acc: 0.8150, precision: 0.9010, recall: 0.8410, f1: 0.8700, edges-ner-ontonotes_loss: 0.0391
09/16 12:25:32 PM: Update 4634: task edges-ner-ontonotes, batch 634 (4634): mcc: 0.8580, acc: 0.8091, precision: 0.8998, recall: 0.8327, f1: 0.8649, edges-ner-ontonotes_loss: 0.0426
09/16 12:25:42 PM: Update 4757: task edges-ner-ontonotes, batch 757 (4757): mcc: 0.8593, acc: 0.8116, precision: 0.9009, recall: 0.8340, f1: 0.8662, edges-ner-ontonotes_loss: 0.0425
09/16 12:25:52 PM: Update 4869: task edges-ner-ontonotes, batch 869 (4869): mcc: 0.8620, acc: 0.8153, precision: 0.9031, recall: 0.8369, f1: 0.8687, edges-ner-ontonotes_loss: 0.0417
09/16 12:26:08 PM: Update 4982: task edges-ner-ontonotes, batch 982 (4982): mcc: 0.8644, acc: 0.8187, precision: 0.9051, recall: 0.8394, f1: 0.8710, edges-ner-ontonotes_loss: 0.0410
09/16 12:26:10 PM: ***** Step 5000 / Validation 5 *****
09/16 12:26:10 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:26:10 PM: Validating...
09/16 12:26:18 PM: Evaluate: task edges-ner-ontonotes, batch 102 (157): mcc: 0.8486, acc: 0.8052, precision: 0.9021, recall: 0.8132, f1: 0.8553, edges-ner-ontonotes_loss: 0.0464
09/16 12:26:23 PM: Updating LR scheduler:
09/16 12:26:23 PM: 	Best result seen so far for macro_avg: 0.860
09/16 12:26:23 PM: 	# validation passes without improvement: 1
09/16 12:26:23 PM: edges-ner-ontonotes_loss: training: 0.041023 validation: 0.044550
09/16 12:26:23 PM: macro_avg: validation: 0.852596
09/16 12:26:23 PM: micro_avg: validation: 0.000000
09/16 12:26:23 PM: edges-ner-ontonotes_mcc: training: 0.863988 validation: 0.845527
09/16 12:26:23 PM: edges-ner-ontonotes_acc: training: 0.818107 validation: 0.803382
09/16 12:26:23 PM: edges-ner-ontonotes_precision: training: 0.904870 validation: 0.896878
09/16 12:26:23 PM: edges-ner-ontonotes_recall: training: 0.838837 validation: 0.812481
09/16 12:26:23 PM: edges-ner-ontonotes_f1: training: 0.870603 validation: 0.852596
09/16 12:26:24 PM: Global learning rate: 0.0001
09/16 12:26:24 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 12:26:28 PM: Update 5099: task edges-ner-ontonotes, batch 99 (5099): mcc: 0.8601, acc: 0.8146, precision: 0.9034, recall: 0.8331, f1: 0.8668, edges-ner-ontonotes_loss: 0.0417
09/16 12:26:38 PM: Update 5194: task edges-ner-ontonotes, batch 194 (5194): mcc: 0.8680, acc: 0.8242, precision: 0.9091, recall: 0.8422, f1: 0.8744, edges-ner-ontonotes_loss: 0.0393
09/16 12:26:51 PM: Update 5295: task edges-ner-ontonotes, batch 295 (5295): mcc: 0.8728, acc: 0.8314, precision: 0.9119, recall: 0.8484, f1: 0.8790, edges-ner-ontonotes_loss: 0.0378
09/16 12:27:01 PM: Update 5417: task edges-ner-ontonotes, batch 417 (5417): mcc: 0.8691, acc: 0.8258, precision: 0.9063, recall: 0.8469, f1: 0.8756, edges-ner-ontonotes_loss: 0.0382
09/16 12:27:11 PM: Update 5515: task edges-ner-ontonotes, batch 515 (5515): mcc: 0.8695, acc: 0.8254, precision: 0.9062, recall: 0.8477, f1: 0.8760, edges-ner-ontonotes_loss: 0.0379
09/16 12:27:27 PM: Update 5608: task edges-ner-ontonotes, batch 608 (5608): mcc: 0.8704, acc: 0.8256, precision: 0.9065, recall: 0.8491, f1: 0.8769, edges-ner-ontonotes_loss: 0.0374
09/16 12:27:37 PM: Update 5731: task edges-ner-ontonotes, batch 731 (5731): mcc: 0.8697, acc: 0.8244, precision: 0.9055, recall: 0.8487, f1: 0.8762, edges-ner-ontonotes_loss: 0.0373
09/16 12:27:47 PM: Update 5886: task edges-ner-ontonotes, batch 886 (5886): mcc: 0.8706, acc: 0.8253, precision: 0.9062, recall: 0.8499, f1: 0.8771, edges-ner-ontonotes_loss: 0.0370
09/16 12:27:56 PM: ***** Step 6000 / Validation 6 *****
09/16 12:27:56 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:27:56 PM: Validating...
09/16 12:27:57 PM: Evaluate: task edges-ner-ontonotes, batch 14 (157): mcc: 0.7987, acc: 0.7446, precision: 0.8535, recall: 0.7673, f1: 0.8081, edges-ner-ontonotes_loss: 0.0588
09/16 12:28:07 PM: Evaluate: task edges-ner-ontonotes, batch 135 (157): mcc: 0.8506, acc: 0.8083, precision: 0.9015, recall: 0.8175, f1: 0.8574, edges-ner-ontonotes_loss: 0.0460
09/16 12:28:08 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:28:10 PM: Best result seen so far for macro.
09/16 12:28:10 PM: Updating LR scheduler:
09/16 12:28:10 PM: 	Best result seen so far for macro_avg: 0.861
09/16 12:28:10 PM: 	# validation passes without improvement: 0
09/16 12:28:10 PM: edges-ner-ontonotes_loss: training: 0.038011 validation: 0.044738
09/16 12:28:10 PM: macro_avg: validation: 0.860643
09/16 12:28:10 PM: micro_avg: validation: 0.000000
09/16 12:28:10 PM: edges-ner-ontonotes_mcc: training: 0.868451 validation: 0.854013
09/16 12:28:10 PM: edges-ner-ontonotes_acc: training: 0.822493 validation: 0.811950
09/16 12:28:10 PM: edges-ner-ontonotes_precision: training: 0.904841 validation: 0.904985
09/16 12:28:10 PM: edges-ner-ontonotes_recall: training: 0.847102 validation: 0.820443
09/16 12:28:10 PM: edges-ner-ontonotes_f1: training: 0.875020 validation: 0.860643
09/16 12:28:10 PM: Global learning rate: 0.0001
09/16 12:28:10 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 12:28:17 PM: Update 6067: task edges-ner-ontonotes, batch 67 (6067): mcc: 0.8518, acc: 0.8075, precision: 0.8962, recall: 0.8245, f1: 0.8589, edges-ner-ontonotes_loss: 0.0485
09/16 12:28:27 PM: Update 6190: task edges-ner-ontonotes, batch 190 (6190): mcc: 0.8506, acc: 0.8047, precision: 0.8967, recall: 0.8218, f1: 0.8576, edges-ner-ontonotes_loss: 0.0474
09/16 12:28:37 PM: Update 6246: task edges-ner-ontonotes, batch 246 (6246): mcc: 0.8530, acc: 0.8074, precision: 0.8981, recall: 0.8250, f1: 0.8600, edges-ner-ontonotes_loss: 0.0465
09/16 12:28:48 PM: Update 6379: task edges-ner-ontonotes, batch 379 (6379): mcc: 0.8620, acc: 0.8190, precision: 0.9041, recall: 0.8359, f1: 0.8687, edges-ner-ontonotes_loss: 0.0430
09/16 12:28:58 PM: Update 6516: task edges-ner-ontonotes, batch 516 (6516): mcc: 0.8696, acc: 0.8287, precision: 0.9091, recall: 0.8452, f1: 0.8760, edges-ner-ontonotes_loss: 0.0408
09/16 12:29:09 PM: Update 6566: task edges-ner-ontonotes, batch 566 (6566): mcc: 0.8692, acc: 0.8283, precision: 0.9087, recall: 0.8447, f1: 0.8755, edges-ner-ontonotes_loss: 0.0405
09/16 12:29:19 PM: Update 6718: task edges-ner-ontonotes, batch 718 (6718): mcc: 0.8704, acc: 0.8291, precision: 0.9097, recall: 0.8460, f1: 0.8767, edges-ner-ontonotes_loss: 0.0397
09/16 12:29:29 PM: Update 6827: task edges-ner-ontonotes, batch 827 (6827): mcc: 0.8723, acc: 0.8314, precision: 0.9107, recall: 0.8486, f1: 0.8785, edges-ner-ontonotes_loss: 0.0392
09/16 12:29:39 PM: Update 6893: task edges-ner-ontonotes, batch 893 (6893): mcc: 0.8715, acc: 0.8304, precision: 0.9093, recall: 0.8484, f1: 0.8778, edges-ner-ontonotes_loss: 0.0391
09/16 12:29:51 PM: Update 6992: task edges-ner-ontonotes, batch 992 (6992): mcc: 0.8714, acc: 0.8296, precision: 0.9085, recall: 0.8491, f1: 0.8778, edges-ner-ontonotes_loss: 0.0388
09/16 12:29:51 PM: ***** Step 7000 / Validation 7 *****
09/16 12:29:51 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:29:51 PM: Validating...
09/16 12:30:01 PM: Evaluate: task edges-ner-ontonotes, batch 104 (157): mcc: 0.8474, acc: 0.8074, precision: 0.8886, recall: 0.8237, f1: 0.8549, edges-ner-ontonotes_loss: 0.0482
09/16 12:30:05 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:30:05 PM: Best result seen so far for macro.
09/16 12:30:05 PM: Updating LR scheduler:
09/16 12:30:05 PM: 	Best result seen so far for macro_avg: 0.862
09/16 12:30:05 PM: 	# validation passes without improvement: 0
09/16 12:30:05 PM: edges-ner-ontonotes_loss: training: 0.038830 validation: 0.044258
09/16 12:30:05 PM: macro_avg: validation: 0.861939
09/16 12:30:05 PM: micro_avg: validation: 0.000000
09/16 12:30:05 PM: edges-ner-ontonotes_mcc: training: 0.871334 validation: 0.854588
09/16 12:30:05 PM: edges-ner-ontonotes_acc: training: 0.829416 validation: 0.815059
09/16 12:30:05 PM: edges-ner-ontonotes_precision: training: 0.908297 validation: 0.890587
09/16 12:30:05 PM: edges-ner-ontonotes_recall: training: 0.849134 validation: 0.835077
09/16 12:30:05 PM: edges-ner-ontonotes_f1: training: 0.877719 validation: 0.861939
09/16 12:30:05 PM: Global learning rate: 0.0001
09/16 12:30:05 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 12:30:11 PM: Update 7066: task edges-ner-ontonotes, batch 66 (7066): mcc: 0.8724, acc: 0.8258, precision: 0.9004, recall: 0.8587, f1: 0.8790, edges-ner-ontonotes_loss: 0.0356
09/16 12:30:21 PM: Update 7172: task edges-ner-ontonotes, batch 172 (7172): mcc: 0.8733, acc: 0.8286, precision: 0.9036, recall: 0.8573, f1: 0.8798, edges-ner-ontonotes_loss: 0.0352
09/16 12:30:31 PM: Update 7316: task edges-ner-ontonotes, batch 316 (7316): mcc: 0.8723, acc: 0.8266, precision: 0.9039, recall: 0.8551, f1: 0.8788, edges-ner-ontonotes_loss: 0.0356
09/16 12:30:41 PM: Update 7461: task edges-ner-ontonotes, batch 461 (7461): mcc: 0.8734, acc: 0.8278, precision: 0.9048, recall: 0.8563, f1: 0.8799, edges-ner-ontonotes_loss: 0.0355
09/16 12:30:51 PM: Update 7576: task edges-ner-ontonotes, batch 576 (7576): mcc: 0.8691, acc: 0.8231, precision: 0.9026, recall: 0.8504, f1: 0.8757, edges-ner-ontonotes_loss: 0.0378
09/16 12:31:01 PM: Update 7691: task edges-ner-ontonotes, batch 691 (7691): mcc: 0.8665, acc: 0.8201, precision: 0.9018, recall: 0.8463, f1: 0.8732, edges-ner-ontonotes_loss: 0.0394
09/16 12:31:14 PM: Update 7781: task edges-ner-ontonotes, batch 781 (7781): mcc: 0.8657, acc: 0.8191, precision: 0.9018, recall: 0.8449, f1: 0.8724, edges-ner-ontonotes_loss: 0.0399
09/16 12:31:24 PM: Update 7944: task edges-ner-ontonotes, batch 944 (7944): mcc: 0.8688, acc: 0.8239, precision: 0.9042, recall: 0.8483, f1: 0.8754, edges-ner-ontonotes_loss: 0.0391
09/16 12:31:29 PM: ***** Step 8000 / Validation 8 *****
09/16 12:31:31 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:31:31 PM: Validating...
09/16 12:31:34 PM: Evaluate: task edges-ner-ontonotes, batch 43 (157): mcc: 0.8721, acc: 0.8406, precision: 0.9052, recall: 0.8534, f1: 0.8785, edges-ner-ontonotes_loss: 0.0429
09/16 12:31:44 PM: Evaluate: task edges-ner-ontonotes, batch 130 (157): mcc: 0.8455, acc: 0.8061, precision: 0.8935, recall: 0.8156, f1: 0.8528, edges-ner-ontonotes_loss: 0.0466
09/16 12:31:46 PM: Updating LR scheduler:
09/16 12:31:46 PM: 	Best result seen so far for macro_avg: 0.862
09/16 12:31:46 PM: 	# validation passes without improvement: 1
09/16 12:31:46 PM: edges-ner-ontonotes_loss: training: 0.038744 validation: 0.045176
09/16 12:31:46 PM: macro_avg: validation: 0.856169
09/16 12:31:46 PM: micro_avg: validation: 0.000000
09/16 12:31:46 PM: edges-ner-ontonotes_mcc: training: 0.870022 validation: 0.849075
09/16 12:31:46 PM: edges-ner-ontonotes_acc: training: 0.825593 validation: 0.810282
09/16 12:31:46 PM: edges-ner-ontonotes_precision: training: 0.905187 validation: 0.896598
09/16 12:31:46 PM: edges-ner-ontonotes_recall: training: 0.849678 validation: 0.819230
09/16 12:31:46 PM: edges-ner-ontonotes_f1: training: 0.876554 validation: 0.856169
09/16 12:31:46 PM: Global learning rate: 0.0001
09/16 12:31:46 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 12:31:54 PM: Update 8066: task edges-ner-ontonotes, batch 66 (8066): mcc: 0.8898, acc: 0.8561, precision: 0.9176, recall: 0.8745, f1: 0.8955, edges-ner-ontonotes_loss: 0.0332
09/16 12:32:04 PM: Update 8094: task edges-ner-ontonotes, batch 94 (8094): mcc: 0.8898, acc: 0.8549, precision: 0.9168, recall: 0.8751, f1: 0.8955, edges-ner-ontonotes_loss: 0.0333
09/16 12:32:15 PM: Update 8181: task edges-ner-ontonotes, batch 181 (8181): mcc: 0.8805, acc: 0.8418, precision: 0.9131, recall: 0.8615, f1: 0.8865, edges-ner-ontonotes_loss: 0.0354
09/16 12:32:25 PM: Update 8276: task edges-ner-ontonotes, batch 276 (8276): mcc: 0.8802, acc: 0.8414, precision: 0.9139, recall: 0.8601, f1: 0.8862, edges-ner-ontonotes_loss: 0.0357
09/16 12:32:35 PM: Update 8375: task edges-ner-ontonotes, batch 375 (8375): mcc: 0.8808, acc: 0.8411, precision: 0.9149, recall: 0.8604, f1: 0.8868, edges-ner-ontonotes_loss: 0.0356
09/16 12:32:45 PM: Update 8452: task edges-ner-ontonotes, batch 452 (8452): mcc: 0.8780, acc: 0.8370, precision: 0.9121, recall: 0.8579, f1: 0.8842, edges-ner-ontonotes_loss: 0.0360
09/16 12:32:55 PM: Update 8567: task edges-ner-ontonotes, batch 567 (8567): mcc: 0.8769, acc: 0.8347, precision: 0.9099, recall: 0.8578, f1: 0.8831, edges-ner-ontonotes_loss: 0.0358
09/16 12:33:05 PM: Update 8692: task edges-ner-ontonotes, batch 692 (8692): mcc: 0.8773, acc: 0.8349, precision: 0.9097, recall: 0.8588, f1: 0.8835, edges-ner-ontonotes_loss: 0.0354
09/16 12:33:15 PM: Update 8744: task edges-ner-ontonotes, batch 744 (8744): mcc: 0.8768, acc: 0.8339, precision: 0.9092, recall: 0.8583, f1: 0.8830, edges-ner-ontonotes_loss: 0.0354
09/16 12:33:26 PM: Update 8866: task edges-ner-ontonotes, batch 866 (8866): mcc: 0.8765, acc: 0.8332, precision: 0.9088, recall: 0.8581, f1: 0.8827, edges-ner-ontonotes_loss: 0.0354
09/16 12:33:38 PM: Update 8969: task edges-ner-ontonotes, batch 969 (8969): mcc: 0.8762, acc: 0.8327, precision: 0.9082, recall: 0.8583, f1: 0.8825, edges-ner-ontonotes_loss: 0.0353
09/16 12:33:39 PM: ***** Step 9000 / Validation 9 *****
09/16 12:33:39 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:33:39 PM: Validating...
09/16 12:33:48 PM: Evaluate: task edges-ner-ontonotes, batch 94 (157): mcc: 0.8560, acc: 0.8134, precision: 0.9041, recall: 0.8249, f1: 0.8627, edges-ner-ontonotes_loss: 0.0493
09/16 12:33:53 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:33:55 PM: Best result seen so far for macro.
09/16 12:33:55 PM: Updating LR scheduler:
09/16 12:33:55 PM: 	Best result seen so far for macro_avg: 0.869
09/16 12:33:55 PM: 	# validation passes without improvement: 0
09/16 12:33:55 PM: edges-ner-ontonotes_loss: training: 0.035267 validation: 0.044018
09/16 12:33:55 PM: macro_avg: validation: 0.868667
09/16 12:33:55 PM: micro_avg: validation: 0.000000
09/16 12:33:55 PM: edges-ner-ontonotes_mcc: training: 0.876259 validation: 0.861855
09/16 12:33:55 PM: edges-ner-ontonotes_acc: training: 0.832711 validation: 0.818926
09/16 12:33:55 PM: edges-ner-ontonotes_precision: training: 0.908266 validation: 0.901010
09/16 12:33:55 PM: edges-ner-ontonotes_recall: training: 0.858285 validation: 0.838565
09/16 12:33:55 PM: edges-ner-ontonotes_f1: training: 0.882569 validation: 0.868667
09/16 12:33:55 PM: Global learning rate: 0.0001
09/16 12:33:55 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 12:33:58 PM: Update 9024: task edges-ner-ontonotes, batch 24 (9024): mcc: 0.8813, acc: 0.8353, precision: 0.9125, recall: 0.8636, f1: 0.8874, edges-ner-ontonotes_loss: 0.0336
09/16 12:34:08 PM: Update 9047: task edges-ner-ontonotes, batch 47 (9047): mcc: 0.8570, acc: 0.8098, precision: 0.8918, recall: 0.8384, f1: 0.8643, edges-ner-ontonotes_loss: 0.0422
09/16 12:34:18 PM: Update 9207: task edges-ner-ontonotes, batch 207 (9207): mcc: 0.8560, acc: 0.8089, precision: 0.8953, recall: 0.8333, f1: 0.8631, edges-ner-ontonotes_loss: 0.0448
09/16 12:34:28 PM: Update 9314: task edges-ner-ontonotes, batch 314 (9314): mcc: 0.8557, acc: 0.8084, precision: 0.8957, recall: 0.8322, f1: 0.8628, edges-ner-ontonotes_loss: 0.0453
09/16 12:34:40 PM: Update 9397: task edges-ner-ontonotes, batch 397 (9397): mcc: 0.8592, acc: 0.8133, precision: 0.8986, recall: 0.8360, f1: 0.8662, edges-ner-ontonotes_loss: 0.0439
09/16 12:34:52 PM: Update 9508: task edges-ner-ontonotes, batch 508 (9508): mcc: 0.8665, acc: 0.8228, precision: 0.9039, recall: 0.8444, f1: 0.8731, edges-ner-ontonotes_loss: 0.0414
09/16 12:35:02 PM: Update 9627: task edges-ner-ontonotes, batch 627 (9627): mcc: 0.8711, acc: 0.8294, precision: 0.9072, recall: 0.8498, f1: 0.8776, edges-ner-ontonotes_loss: 0.0400
09/16 12:35:12 PM: Update 9661: task edges-ner-ontonotes, batch 661 (9661): mcc: 0.8717, acc: 0.8302, precision: 0.9078, recall: 0.8504, f1: 0.8781, edges-ner-ontonotes_loss: 0.0397
09/16 12:35:22 PM: Update 9783: task edges-ner-ontonotes, batch 783 (9783): mcc: 0.8716, acc: 0.8299, precision: 0.9077, recall: 0.8502, f1: 0.8781, edges-ner-ontonotes_loss: 0.0394
09/16 12:35:32 PM: Update 9956: task edges-ner-ontonotes, batch 956 (9956): mcc: 0.8745, acc: 0.8334, precision: 0.9098, recall: 0.8536, f1: 0.8808, edges-ner-ontonotes_loss: 0.0385
09/16 12:35:40 PM: ***** Step 10000 / Validation 10 *****
09/16 12:35:40 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:35:40 PM: Validating...
09/16 12:35:42 PM: Evaluate: task edges-ner-ontonotes, batch 44 (157): mcc: 0.8505, acc: 0.8207, precision: 0.8864, recall: 0.8315, f1: 0.8581, edges-ner-ontonotes_loss: 0.0469
09/16 12:35:48 PM: Updating LR scheduler:
09/16 12:35:48 PM: 	Best result seen so far for macro_avg: 0.869
09/16 12:35:48 PM: 	# validation passes without improvement: 1
09/16 12:35:48 PM: edges-ner-ontonotes_loss: training: 0.038387 validation: 0.043858
09/16 12:35:48 PM: macro_avg: validation: 0.861907
09/16 12:35:48 PM: micro_avg: validation: 0.000000
09/16 12:35:48 PM: edges-ner-ontonotes_mcc: training: 0.874138 validation: 0.854658
09/16 12:35:48 PM: edges-ner-ontonotes_acc: training: 0.832878 validation: 0.816803
09/16 12:35:48 PM: edges-ner-ontonotes_precision: training: 0.908969 validation: 0.892944
09/16 12:35:48 PM: edges-ner-ontonotes_recall: training: 0.853678 validation: 0.832954
09/16 12:35:48 PM: edges-ner-ontonotes_f1: training: 0.880456 validation: 0.861907
09/16 12:35:48 PM: Global learning rate: 0.0001
09/16 12:35:48 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 12:35:52 PM: Update 10072: task edges-ner-ontonotes, batch 72 (10072): mcc: 0.8697, acc: 0.8220, precision: 0.8994, recall: 0.8547, f1: 0.8764, edges-ner-ontonotes_loss: 0.0363
09/16 12:36:02 PM: Update 10257: task edges-ner-ontonotes, batch 257 (10257): mcc: 0.8739, acc: 0.8283, precision: 0.9033, recall: 0.8586, f1: 0.8804, edges-ner-ontonotes_loss: 0.0347
09/16 12:36:13 PM: Update 10365: task edges-ner-ontonotes, batch 365 (10365): mcc: 0.8726, acc: 0.8273, precision: 0.9025, recall: 0.8571, f1: 0.8792, edges-ner-ontonotes_loss: 0.0349
09/16 12:36:23 PM: Update 10509: task edges-ner-ontonotes, batch 509 (10509): mcc: 0.8741, acc: 0.8287, precision: 0.9041, recall: 0.8583, f1: 0.8806, edges-ner-ontonotes_loss: 0.0348
09/16 12:36:33 PM: Update 10589: task edges-ner-ontonotes, batch 589 (10589): mcc: 0.8748, acc: 0.8296, precision: 0.9045, recall: 0.8591, f1: 0.8813, edges-ner-ontonotes_loss: 0.0346
09/16 12:36:43 PM: Update 10703: task edges-ner-ontonotes, batch 703 (10703): mcc: 0.8700, acc: 0.8241, precision: 0.9019, recall: 0.8529, f1: 0.8767, edges-ner-ontonotes_loss: 0.0368
09/16 12:36:53 PM: Update 10825: task edges-ner-ontonotes, batch 825 (10825): mcc: 0.8691, acc: 0.8234, precision: 0.9015, recall: 0.8515, f1: 0.8758, edges-ner-ontonotes_loss: 0.0379
09/16 12:37:05 PM: Update 10893: task edges-ner-ontonotes, batch 893 (10893): mcc: 0.8685, acc: 0.8229, precision: 0.9014, recall: 0.8505, f1: 0.8752, edges-ner-ontonotes_loss: 0.0385
09/16 12:37:08 PM: ***** Step 11000 / Validation 11 *****
09/16 12:37:08 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:37:08 PM: Validating...
09/16 12:37:15 PM: Evaluate: task edges-ner-ontonotes, batch 96 (157): mcc: 0.8608, acc: 0.8197, precision: 0.9078, recall: 0.8302, f1: 0.8673, edges-ner-ontonotes_loss: 0.0450
09/16 12:37:20 PM: Updating LR scheduler:
09/16 12:37:20 PM: 	Best result seen so far for macro_avg: 0.869
09/16 12:37:20 PM: 	# validation passes without improvement: 2
09/16 12:37:20 PM: edges-ner-ontonotes_loss: training: 0.038250 validation: 0.044141
09/16 12:37:20 PM: macro_avg: validation: 0.858650
09/16 12:37:20 PM: micro_avg: validation: 0.000000
09/16 12:37:20 PM: edges-ner-ontonotes_mcc: training: 0.869901 validation: 0.851765
09/16 12:37:20 PM: edges-ner-ontonotes_acc: training: 0.825303 validation: 0.810889
09/16 12:37:20 PM: edges-ner-ontonotes_precision: training: 0.902616 validation: 0.900408
09/16 12:37:20 PM: edges-ner-ontonotes_recall: training: 0.851921 validation: 0.820594
09/16 12:37:21 PM: edges-ner-ontonotes_f1: training: 0.876536 validation: 0.858650
09/16 12:37:21 PM: Global learning rate: 0.0001
09/16 12:37:21 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 12:37:25 PM: Update 11053: task edges-ner-ontonotes, batch 53 (11053): mcc: 0.8982, acc: 0.8677, precision: 0.9268, recall: 0.8812, f1: 0.9034, edges-ner-ontonotes_loss: 0.0321
09/16 12:37:35 PM: Update 11192: task edges-ner-ontonotes, batch 192 (11192): mcc: 0.8960, acc: 0.8625, precision: 0.9244, recall: 0.8794, f1: 0.9013, edges-ner-ontonotes_loss: 0.0319
09/16 12:37:45 PM: Update 11239: task edges-ner-ontonotes, batch 239 (11239): mcc: 0.8910, acc: 0.8557, precision: 0.9207, recall: 0.8736, f1: 0.8965, edges-ner-ontonotes_loss: 0.0324
09/16 12:37:55 PM: Update 11374: task edges-ner-ontonotes, batch 374 (11374): mcc: 0.8837, acc: 0.8460, precision: 0.9162, recall: 0.8646, f1: 0.8896, edges-ner-ontonotes_loss: 0.0339
09/16 12:38:07 PM: Update 11494: task edges-ner-ontonotes, batch 494 (11494): mcc: 0.8846, acc: 0.8473, precision: 0.9160, recall: 0.8664, f1: 0.8905, edges-ner-ontonotes_loss: 0.0340
09/16 12:38:17 PM: Update 11541: task edges-ner-ontonotes, batch 541 (11541): mcc: 0.8830, acc: 0.8449, precision: 0.9146, recall: 0.8647, f1: 0.8889, edges-ner-ontonotes_loss: 0.0343
09/16 12:38:28 PM: Update 11657: task edges-ner-ontonotes, batch 657 (11657): mcc: 0.8811, acc: 0.8415, precision: 0.9121, recall: 0.8636, f1: 0.8872, edges-ner-ontonotes_loss: 0.0345
09/16 12:38:41 PM: Update 11748: task edges-ner-ontonotes, batch 748 (11748): mcc: 0.8808, acc: 0.8408, precision: 0.9115, recall: 0.8636, f1: 0.8869, edges-ner-ontonotes_loss: 0.0344
09/16 12:38:52 PM: Update 11832: task edges-ner-ontonotes, batch 832 (11832): mcc: 0.8802, acc: 0.8399, precision: 0.9103, recall: 0.8637, f1: 0.8864, edges-ner-ontonotes_loss: 0.0343
09/16 12:39:02 PM: Update 11939: task edges-ner-ontonotes, batch 939 (11939): mcc: 0.8793, acc: 0.8383, precision: 0.9095, recall: 0.8627, f1: 0.8855, edges-ner-ontonotes_loss: 0.0343
09/16 12:39:08 PM: ***** Step 12000 / Validation 12 *****
09/16 12:39:08 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:39:08 PM: Validating...
09/16 12:39:12 PM: Evaluate: task edges-ner-ontonotes, batch 47 (157): mcc: 0.8434, acc: 0.8095, precision: 0.8843, recall: 0.8204, f1: 0.8511, edges-ner-ontonotes_loss: 0.0502
09/16 12:39:20 PM: Updating LR scheduler:
09/16 12:39:20 PM: 	Best result seen so far for macro_avg: 0.869
09/16 12:39:20 PM: 	# validation passes without improvement: 3
09/16 12:39:20 PM: edges-ner-ontonotes_loss: training: 0.034339 validation: 0.043705
09/16 12:39:20 PM: macro_avg: validation: 0.867809
09/16 12:39:20 PM: micro_avg: validation: 0.000000
09/16 12:39:20 PM: edges-ner-ontonotes_mcc: training: 0.879339 validation: 0.860881
09/16 12:39:20 PM: edges-ner-ontonotes_acc: training: 0.838284 validation: 0.823855
09/16 12:39:20 PM: edges-ner-ontonotes_precision: training: 0.909412 validation: 0.898644
09/16 12:39:20 PM: edges-ner-ontonotes_recall: training: 0.862902 validation: 0.839020
09/16 12:39:20 PM: edges-ner-ontonotes_f1: training: 0.885547 validation: 0.867809
09/16 12:39:20 PM: Global learning rate: 0.0001
09/16 12:39:20 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 12:39:23 PM: Update 12025: task edges-ner-ontonotes, batch 25 (12025): mcc: 0.8776, acc: 0.8308, precision: 0.9114, recall: 0.8578, f1: 0.8838, edges-ner-ontonotes_loss: 0.0340
09/16 12:39:36 PM: Update 12135: task edges-ner-ontonotes, batch 135 (12135): mcc: 0.8782, acc: 0.8326, precision: 0.9077, recall: 0.8625, f1: 0.8845, edges-ner-ontonotes_loss: 0.0337
09/16 12:39:46 PM: Update 12204: task edges-ner-ontonotes, batch 204 (12204): mcc: 0.8682, acc: 0.8214, precision: 0.9021, recall: 0.8493, f1: 0.8749, edges-ner-ontonotes_loss: 0.0385
09/16 12:39:57 PM: Update 12318: task edges-ner-ontonotes, batch 318 (12318): mcc: 0.8665, acc: 0.8206, precision: 0.9022, recall: 0.8460, f1: 0.8732, edges-ner-ontonotes_loss: 0.0405
09/16 12:40:07 PM: Update 12443: task edges-ner-ontonotes, batch 443 (12443): mcc: 0.8647, acc: 0.8186, precision: 0.9013, recall: 0.8435, f1: 0.8715, edges-ner-ontonotes_loss: 0.0417
09/16 12:40:17 PM: Update 12526: task edges-ner-ontonotes, batch 526 (12526): mcc: 0.8666, acc: 0.8216, precision: 0.9025, recall: 0.8460, f1: 0.8733, edges-ner-ontonotes_loss: 0.0408
09/16 12:40:27 PM: Update 12655: task edges-ner-ontonotes, batch 655 (12655): mcc: 0.8713, acc: 0.8283, precision: 0.9053, recall: 0.8518, f1: 0.8778, edges-ner-ontonotes_loss: 0.0391
09/16 12:40:37 PM: Update 12771: task edges-ner-ontonotes, batch 771 (12771): mcc: 0.8743, acc: 0.8328, precision: 0.9073, recall: 0.8555, f1: 0.8806, edges-ner-ontonotes_loss: 0.0381
09/16 12:40:47 PM: Update 12932: task edges-ner-ontonotes, batch 932 (12932): mcc: 0.8748, acc: 0.8337, precision: 0.9077, recall: 0.8561, f1: 0.8811, edges-ner-ontonotes_loss: 0.0378
09/16 12:40:51 PM: ***** Step 13000 / Validation 13 *****
09/16 12:40:51 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:40:51 PM: Validating...
09/16 12:40:57 PM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.8528, acc: 0.8165, precision: 0.8911, recall: 0.8313, f1: 0.8602, edges-ner-ontonotes_loss: 0.0457
09/16 12:40:59 PM: Updating LR scheduler:
09/16 12:40:59 PM: 	Best result seen so far for macro_avg: 0.869
09/16 12:40:59 PM: 	# validation passes without improvement: 0
09/16 12:40:59 PM: edges-ner-ontonotes_loss: training: 0.037539 validation: 0.043219
09/16 12:40:59 PM: macro_avg: validation: 0.866594
09/16 12:40:59 PM: micro_avg: validation: 0.000000
09/16 12:40:59 PM: edges-ner-ontonotes_mcc: training: 0.875583 validation: 0.859475
09/16 12:40:59 PM: edges-ner-ontonotes_acc: training: 0.834501 validation: 0.822642
09/16 12:40:59 PM: edges-ner-ontonotes_precision: training: 0.908176 validation: 0.894575
09/16 12:40:59 PM: edges-ner-ontonotes_recall: training: 0.857118 validation: 0.840309
09/16 12:40:59 PM: edges-ner-ontonotes_f1: training: 0.881908 validation: 0.866594
09/16 12:40:59 PM: Global learning rate: 5e-05
09/16 12:40:59 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 12:41:07 PM: Update 13113: task edges-ner-ontonotes, batch 113 (13113): mcc: 0.8800, acc: 0.8414, precision: 0.9103, recall: 0.8633, f1: 0.8862, edges-ner-ontonotes_loss: 0.0343
09/16 12:41:19 PM: Update 13299: task edges-ner-ontonotes, batch 299 (13299): mcc: 0.8754, acc: 0.8327, precision: 0.9050, recall: 0.8599, f1: 0.8819, edges-ner-ontonotes_loss: 0.0346
09/16 12:41:33 PM: Update 13388: task edges-ner-ontonotes, batch 388 (13388): mcc: 0.8745, acc: 0.8307, precision: 0.9032, recall: 0.8599, f1: 0.8810, edges-ner-ontonotes_loss: 0.0348
09/16 12:41:43 PM: Update 13547: task edges-ner-ontonotes, batch 547 (13547): mcc: 0.8737, acc: 0.8290, precision: 0.9028, recall: 0.8588, f1: 0.8803, edges-ner-ontonotes_loss: 0.0350
09/16 12:41:53 PM: Update 13657: task edges-ner-ontonotes, batch 657 (13657): mcc: 0.8743, acc: 0.8291, precision: 0.9038, recall: 0.8589, f1: 0.8808, edges-ner-ontonotes_loss: 0.0348
09/16 12:42:03 PM: Update 13727: task edges-ner-ontonotes, batch 727 (13727): mcc: 0.8735, acc: 0.8282, precision: 0.9032, recall: 0.8581, f1: 0.8800, edges-ner-ontonotes_loss: 0.0351
09/16 12:42:13 PM: Update 13864: task edges-ner-ontonotes, batch 864 (13864): mcc: 0.8711, acc: 0.8254, precision: 0.9021, recall: 0.8547, f1: 0.8777, edges-ner-ontonotes_loss: 0.0367
09/16 12:42:23 PM: ***** Step 14000 / Validation 14 *****
09/16 12:42:23 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:42:23 PM: Validating...
09/16 12:42:23 PM: Evaluate: task edges-ner-ontonotes, batch 13 (157): mcc: 0.8136, acc: 0.7631, precision: 0.8547, recall: 0.7934, f1: 0.8229, edges-ner-ontonotes_loss: 0.0564
09/16 12:42:32 PM: Updating LR scheduler:
09/16 12:42:32 PM: 	Best result seen so far for macro_avg: 0.869
09/16 12:42:32 PM: 	# validation passes without improvement: 1
09/16 12:42:32 PM: edges-ner-ontonotes_loss: training: 0.037752 validation: 0.043721
09/16 12:42:32 PM: macro_avg: validation: 0.863311
09/16 12:42:32 PM: micro_avg: validation: 0.000000
09/16 12:42:32 PM: edges-ner-ontonotes_mcc: training: 0.869388 validation: 0.856515
09/16 12:42:32 PM: edges-ner-ontonotes_acc: training: 0.823795 validation: 0.818699
09/16 12:42:32 PM: edges-ner-ontonotes_precision: training: 0.901373 validation: 0.902008
09/16 12:42:32 PM: edges-ner-ontonotes_recall: training: 0.852166 validation: 0.827798
09/16 12:42:32 PM: edges-ner-ontonotes_f1: training: 0.876079 validation: 0.863311
09/16 12:42:32 PM: Global learning rate: 5e-05
09/16 12:42:32 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 12:42:39 PM: Update 14005: task edges-ner-ontonotes, batch 5 (14005): mcc: 0.8496, acc: 0.7926, precision: 0.8770, recall: 0.8390, f1: 0.8576, edges-ner-ontonotes_loss: 0.0450
09/16 12:42:49 PM: Update 14182: task edges-ner-ontonotes, batch 182 (14182): mcc: 0.8955, acc: 0.8618, precision: 0.9228, recall: 0.8801, f1: 0.9009, edges-ner-ontonotes_loss: 0.0327
09/16 12:43:06 PM: Update 14318: task edges-ner-ontonotes, batch 318 (14318): mcc: 0.8976, acc: 0.8647, precision: 0.9240, recall: 0.8828, f1: 0.9029, edges-ner-ontonotes_loss: 0.0322
09/16 12:43:17 PM: Update 14449: task edges-ner-ontonotes, batch 449 (14449): mcc: 0.8900, acc: 0.8538, precision: 0.9193, recall: 0.8732, f1: 0.8956, edges-ner-ontonotes_loss: 0.0334
09/16 12:43:29 PM: Update 14596: task edges-ner-ontonotes, batch 596 (14596): mcc: 0.8900, acc: 0.8538, precision: 0.9195, recall: 0.8729, f1: 0.8956, edges-ner-ontonotes_loss: 0.0331
09/16 12:43:40 PM: Update 14631: task edges-ner-ontonotes, batch 631 (14631): mcc: 0.8893, acc: 0.8531, precision: 0.9188, recall: 0.8723, f1: 0.8950, edges-ner-ontonotes_loss: 0.0332
09/16 12:43:52 PM: Update 14736: task edges-ner-ontonotes, batch 736 (14736): mcc: 0.8861, acc: 0.8483, precision: 0.9157, recall: 0.8695, f1: 0.8920, edges-ner-ontonotes_loss: 0.0336
09/16 12:44:02 PM: Update 14881: task edges-ner-ontonotes, batch 881 (14881): mcc: 0.8852, acc: 0.8461, precision: 0.9145, recall: 0.8689, f1: 0.8911, edges-ner-ontonotes_loss: 0.0335
09/16 12:44:12 PM: Update 14976: task edges-ner-ontonotes, batch 976 (14976): mcc: 0.8837, acc: 0.8439, precision: 0.9129, recall: 0.8677, f1: 0.8897, edges-ner-ontonotes_loss: 0.0337
09/16 12:44:15 PM: ***** Step 15000 / Validation 15 *****
09/16 12:44:16 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:44:16 PM: Validating...
09/16 12:44:22 PM: Evaluate: task edges-ner-ontonotes, batch 80 (157): mcc: 0.8609, acc: 0.8248, precision: 0.9004, recall: 0.8374, f1: 0.8678, edges-ner-ontonotes_loss: 0.0471
09/16 12:44:29 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:44:29 PM: Best result seen so far for macro.
09/16 12:44:29 PM: Updating LR scheduler:
09/16 12:44:29 PM: 	Best result seen so far for macro_avg: 0.869
09/16 12:44:29 PM: 	# validation passes without improvement: 0
09/16 12:44:29 PM: edges-ner-ontonotes_loss: training: 0.033635 validation: 0.043405
09/16 12:44:29 PM: macro_avg: validation: 0.869415
09/16 12:44:29 PM: micro_avg: validation: 0.000000
09/16 12:44:29 PM: edges-ner-ontonotes_mcc: training: 0.883395 validation: 0.862517
09/16 12:44:29 PM: edges-ner-ontonotes_acc: training: 0.843409 validation: 0.823400
09/16 12:44:29 PM: edges-ner-ontonotes_precision: training: 0.912723 validation: 0.898875
09/16 12:44:29 PM: edges-ner-ontonotes_recall: training: 0.867244 validation: 0.841826
09/16 12:44:29 PM: edges-ner-ontonotes_f1: training: 0.889403 validation: 0.869415
09/16 12:44:29 PM: Global learning rate: 5e-05
09/16 12:44:29 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 12:44:33 PM: Update 15052: task edges-ner-ontonotes, batch 52 (15052): mcc: 0.8733, acc: 0.8275, precision: 0.9054, recall: 0.8555, f1: 0.8797, edges-ner-ontonotes_loss: 0.0356
09/16 12:44:43 PM: Update 15163: task edges-ner-ontonotes, batch 163 (15163): mcc: 0.8740, acc: 0.8291, precision: 0.9019, recall: 0.8603, f1: 0.8806, edges-ner-ontonotes_loss: 0.0344
09/16 12:44:55 PM: Update 15257: task edges-ner-ontonotes, batch 257 (15257): mcc: 0.8756, acc: 0.8310, precision: 0.9036, recall: 0.8616, f1: 0.8821, edges-ner-ontonotes_loss: 0.0344
09/16 12:45:05 PM: Update 15379: task edges-ner-ontonotes, batch 379 (15379): mcc: 0.8687, acc: 0.8228, precision: 0.9007, recall: 0.8515, f1: 0.8754, edges-ner-ontonotes_loss: 0.0381
09/16 12:45:15 PM: Update 15497: task edges-ner-ontonotes, batch 497 (15497): mcc: 0.8671, acc: 0.8212, precision: 0.9007, recall: 0.8486, f1: 0.8739, edges-ner-ontonotes_loss: 0.0395
09/16 12:45:25 PM: Update 15562: task edges-ner-ontonotes, batch 562 (15562): mcc: 0.8661, acc: 0.8204, precision: 0.9004, recall: 0.8470, f1: 0.8729, edges-ner-ontonotes_loss: 0.0401
09/16 12:45:35 PM: Update 15723: task edges-ner-ontonotes, batch 723 (15723): mcc: 0.8715, acc: 0.8283, precision: 0.9041, recall: 0.8534, f1: 0.8780, edges-ner-ontonotes_loss: 0.0384
09/16 12:45:45 PM: Update 15830: task edges-ner-ontonotes, batch 830 (15830): mcc: 0.8748, acc: 0.8329, precision: 0.9069, recall: 0.8570, f1: 0.8812, edges-ner-ontonotes_loss: 0.0375
09/16 12:45:55 PM: Update 15897: task edges-ner-ontonotes, batch 897 (15897): mcc: 0.8756, acc: 0.8342, precision: 0.9073, recall: 0.8580, f1: 0.8819, edges-ner-ontonotes_loss: 0.0371
09/16 12:46:02 PM: ***** Step 16000 / Validation 16 *****
09/16 12:46:02 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:46:02 PM: Validating...
09/16 12:46:05 PM: Evaluate: task edges-ner-ontonotes, batch 79 (157): mcc: 0.8696, acc: 0.8340, precision: 0.9064, recall: 0.8478, f1: 0.8761, edges-ner-ontonotes_loss: 0.0434
09/16 12:46:09 PM: Updating LR scheduler:
09/16 12:46:09 PM: 	Best result seen so far for macro_avg: 0.869
09/16 12:46:09 PM: 	# validation passes without improvement: 1
09/16 12:46:09 PM: edges-ner-ontonotes_loss: training: 0.036744 validation: 0.042754
09/16 12:46:09 PM: macro_avg: validation: 0.865983
09/16 12:46:09 PM: micro_avg: validation: 0.000000
09/16 12:46:09 PM: edges-ner-ontonotes_mcc: training: 0.877130 validation: 0.859060
09/16 12:46:09 PM: edges-ner-ontonotes_acc: training: 0.836376 validation: 0.822566
09/16 12:46:09 PM: edges-ner-ontonotes_precision: training: 0.908751 validation: 0.899175
09/16 12:46:09 PM: edges-ner-ontonotes_recall: training: 0.859435 validation: 0.835153
09/16 12:46:09 PM: edges-ner-ontonotes_f1: training: 0.883405 validation: 0.865983
09/16 12:46:09 PM: Global learning rate: 5e-05
09/16 12:46:09 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 12:46:15 PM: Update 16115: task edges-ner-ontonotes, batch 115 (16115): mcc: 0.8818, acc: 0.8430, precision: 0.9133, recall: 0.8638, f1: 0.8879, edges-ner-ontonotes_loss: 0.0353
09/16 12:46:25 PM: Update 16239: task edges-ner-ontonotes, batch 239 (16239): mcc: 0.8779, acc: 0.8381, precision: 0.9085, recall: 0.8612, f1: 0.8842, edges-ner-ontonotes_loss: 0.0353
09/16 12:46:36 PM: Update 16420: task edges-ner-ontonotes, batch 420 (16420): mcc: 0.8774, acc: 0.8354, precision: 0.9066, recall: 0.8621, f1: 0.8838, edges-ner-ontonotes_loss: 0.0348
09/16 12:46:46 PM: Update 16518: task edges-ner-ontonotes, batch 518 (16518): mcc: 0.8776, acc: 0.8351, precision: 0.9065, recall: 0.8624, f1: 0.8839, edges-ner-ontonotes_loss: 0.0345
09/16 12:46:57 PM: Update 16613: task edges-ner-ontonotes, batch 613 (16613): mcc: 0.8778, acc: 0.8348, precision: 0.9063, recall: 0.8629, f1: 0.8841, edges-ner-ontonotes_loss: 0.0344
09/16 12:47:07 PM: Update 16713: task edges-ner-ontonotes, batch 713 (16713): mcc: 0.8766, acc: 0.8330, precision: 0.9055, recall: 0.8615, f1: 0.8830, edges-ner-ontonotes_loss: 0.0345
09/16 12:47:20 PM: Update 16813: task edges-ner-ontonotes, batch 813 (16813): mcc: 0.8775, acc: 0.8339, precision: 0.9063, recall: 0.8625, f1: 0.8839, edges-ner-ontonotes_loss: 0.0343
09/16 12:47:31 PM: Update 16958: task edges-ner-ontonotes, batch 958 (16958): mcc: 0.8739, acc: 0.8298, precision: 0.9040, recall: 0.8581, f1: 0.8805, edges-ner-ontonotes_loss: 0.0361
09/16 12:47:33 PM: ***** Step 17000 / Validation 17 *****
09/16 12:47:33 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:47:33 PM: Validating...
09/16 12:47:41 PM: Evaluate: task edges-ner-ontonotes, batch 109 (157): mcc: 0.8574, acc: 0.8183, precision: 0.9041, recall: 0.8275, f1: 0.8641, edges-ner-ontonotes_loss: 0.0463
09/16 12:47:44 PM: Updating LR scheduler:
09/16 12:47:44 PM: 	Best result seen so far for macro_avg: 0.869
09/16 12:47:44 PM: 	# validation passes without improvement: 2
09/16 12:47:44 PM: edges-ner-ontonotes_loss: training: 0.036286 validation: 0.043556
09/16 12:47:44 PM: macro_avg: validation: 0.864257
09/16 12:47:44 PM: micro_avg: validation: 0.000000
09/16 12:47:44 PM: edges-ner-ontonotes_mcc: training: 0.873744 validation: 0.857577
09/16 12:47:44 PM: edges-ner-ontonotes_acc: training: 0.829589 validation: 0.818926
09/16 12:47:44 PM: edges-ner-ontonotes_precision: training: 0.904064 validation: 0.904166
09/16 12:47:44 PM: edges-ner-ontonotes_recall: training: 0.857665 validation: 0.827722
09/16 12:47:44 PM: edges-ner-ontonotes_f1: training: 0.880253 validation: 0.864257
09/16 12:47:44 PM: Global learning rate: 5e-05
09/16 12:47:44 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 12:47:51 PM: Update 17075: task edges-ner-ontonotes, batch 75 (17075): mcc: 0.8627, acc: 0.8167, precision: 0.9029, recall: 0.8384, f1: 0.8695, edges-ner-ontonotes_loss: 0.0435
09/16 12:48:01 PM: Update 17121: task edges-ner-ontonotes, batch 121 (17121): mcc: 0.8638, acc: 0.8166, precision: 0.9039, recall: 0.8394, f1: 0.8705, edges-ner-ontonotes_loss: 0.0426
09/16 12:48:12 PM: Update 17259: task edges-ner-ontonotes, batch 259 (17259): mcc: 0.8793, acc: 0.8386, precision: 0.9136, recall: 0.8588, f1: 0.8854, edges-ner-ontonotes_loss: 0.0373
09/16 12:48:26 PM: Update 17387: task edges-ner-ontonotes, batch 387 (17387): mcc: 0.8868, acc: 0.8489, precision: 0.9174, recall: 0.8689, f1: 0.8925, edges-ner-ontonotes_loss: 0.0353
09/16 12:48:36 PM: Update 17430: task edges-ner-ontonotes, batch 430 (17430): mcc: 0.8878, acc: 0.8509, precision: 0.9181, recall: 0.8703, f1: 0.8935, edges-ner-ontonotes_loss: 0.0347
09/16 12:48:46 PM: Update 17578: task edges-ner-ontonotes, batch 578 (17578): mcc: 0.8862, acc: 0.8486, precision: 0.9170, recall: 0.8683, f1: 0.8920, edges-ner-ontonotes_loss: 0.0349
09/16 12:48:58 PM: Update 17708: task edges-ner-ontonotes, batch 708 (17708): mcc: 0.8852, acc: 0.8471, precision: 0.9167, recall: 0.8667, f1: 0.8910, edges-ner-ontonotes_loss: 0.0346
09/16 12:49:08 PM: Update 17750: task edges-ner-ontonotes, batch 750 (17750): mcc: 0.8847, acc: 0.8467, precision: 0.9160, recall: 0.8666, f1: 0.8906, edges-ner-ontonotes_loss: 0.0346
09/16 12:49:21 PM: Update 17876: task edges-ner-ontonotes, batch 876 (17876): mcc: 0.8822, acc: 0.8430, precision: 0.9129, recall: 0.8648, f1: 0.8882, edges-ner-ontonotes_loss: 0.0349
09/16 12:49:31 PM: Update 17988: task edges-ner-ontonotes, batch 988 (17988): mcc: 0.8824, acc: 0.8430, precision: 0.9126, recall: 0.8655, f1: 0.8884, edges-ner-ontonotes_loss: 0.0345
09/16 12:49:32 PM: ***** Step 18000 / Validation 18 *****
09/16 12:49:32 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:49:32 PM: Validating...
09/16 12:49:41 PM: Evaluate: task edges-ner-ontonotes, batch 122 (157): mcc: 0.8537, acc: 0.8144, precision: 0.8893, recall: 0.8347, f1: 0.8611, edges-ner-ontonotes_loss: 0.0462
09/16 12:49:42 PM: Updating LR scheduler:
09/16 12:49:42 PM: 	Best result seen so far for macro_avg: 0.869
09/16 12:49:42 PM: 	# validation passes without improvement: 3
09/16 12:49:42 PM: edges-ner-ontonotes_loss: training: 0.034421 validation: 0.043308
09/16 12:49:42 PM: macro_avg: validation: 0.868858
09/16 12:49:42 PM: micro_avg: validation: 0.000000
09/16 12:49:42 PM: edges-ner-ontonotes_mcc: training: 0.882461 validation: 0.861859
09/16 12:49:42 PM: edges-ner-ontonotes_acc: training: 0.843031 validation: 0.823021
09/16 12:49:42 PM: edges-ner-ontonotes_precision: training: 0.912556 validation: 0.896652
09/16 12:49:42 PM: edges-ner-ontonotes_recall: training: 0.865669 validation: 0.842736
09/16 12:49:42 PM: edges-ner-ontonotes_f1: training: 0.888494 validation: 0.868858
09/16 12:49:42 PM: Global learning rate: 5e-05
09/16 12:49:42 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 12:49:51 PM: Update 18097: task edges-ner-ontonotes, batch 97 (18097): mcc: 0.8717, acc: 0.8253, precision: 0.9006, recall: 0.8571, f1: 0.8783, edges-ner-ontonotes_loss: 0.0342
09/16 12:50:01 PM: Update 18210: task edges-ner-ontonotes, batch 210 (18210): mcc: 0.8738, acc: 0.8274, precision: 0.9025, recall: 0.8594, f1: 0.8804, edges-ner-ontonotes_loss: 0.0338
09/16 12:50:11 PM: Update 18325: task edges-ner-ontonotes, batch 325 (18325): mcc: 0.8749, acc: 0.8295, precision: 0.9033, recall: 0.8606, f1: 0.8814, edges-ner-ontonotes_loss: 0.0339
09/16 12:50:22 PM: Update 18372: task edges-ner-ontonotes, batch 372 (18372): mcc: 0.8744, acc: 0.8290, precision: 0.9030, recall: 0.8600, f1: 0.8810, edges-ner-ontonotes_loss: 0.0339
09/16 12:50:33 PM: Update 18475: task edges-ner-ontonotes, batch 475 (18475): mcc: 0.8691, acc: 0.8229, precision: 0.9003, recall: 0.8527, f1: 0.8759, edges-ner-ontonotes_loss: 0.0368
09/16 12:50:43 PM: Update 18603: task edges-ner-ontonotes, batch 603 (18603): mcc: 0.8675, acc: 0.8214, precision: 0.8998, recall: 0.8502, f1: 0.8743, edges-ner-ontonotes_loss: 0.0381
09/16 12:50:54 PM: Update 18673: task edges-ner-ontonotes, batch 673 (18673): mcc: 0.8672, acc: 0.8211, precision: 0.9001, recall: 0.8494, f1: 0.8740, edges-ner-ontonotes_loss: 0.0386
09/16 12:51:04 PM: Update 18901: task edges-ner-ontonotes, batch 901 (18901): mcc: 0.8734, acc: 0.8304, precision: 0.9047, recall: 0.8565, f1: 0.8799, edges-ner-ontonotes_loss: 0.0369
09/16 12:51:12 PM: ***** Step 19000 / Validation 19 *****
09/16 12:51:12 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:51:12 PM: Validating...
09/16 12:51:14 PM: Evaluate: task edges-ner-ontonotes, batch 42 (157): mcc: 0.8707, acc: 0.8394, precision: 0.9008, recall: 0.8551, f1: 0.8774, edges-ner-ontonotes_loss: 0.0427
09/16 12:51:20 PM: Updating LR scheduler:
09/16 12:51:21 PM: 	Best result seen so far for macro_avg: 0.869
09/16 12:51:21 PM: 	# validation passes without improvement: 0
09/16 12:51:21 PM: edges-ner-ontonotes_loss: training: 0.036421 validation: 0.043325
09/16 12:51:21 PM: macro_avg: validation: 0.862838
09/16 12:51:21 PM: micro_avg: validation: 0.000000
09/16 12:51:21 PM: edges-ner-ontonotes_mcc: training: 0.875170 validation: 0.856136
09/16 12:51:21 PM: edges-ner-ontonotes_acc: training: 0.832982 validation: 0.815514
09/16 12:51:21 PM: edges-ner-ontonotes_precision: training: 0.906150 validation: 0.903777
09/16 12:51:21 PM: edges-ner-ontonotes_recall: training: 0.858300 validation: 0.825447
09/16 12:51:21 PM: edges-ner-ontonotes_f1: training: 0.881576 validation: 0.862838
09/16 12:51:21 PM: Global learning rate: 2.5e-05
09/16 12:51:21 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 12:51:24 PM: Update 19031: task edges-ner-ontonotes, batch 31 (19031): mcc: 0.8715, acc: 0.8274, precision: 0.9116, recall: 0.8463, f1: 0.8778, edges-ner-ontonotes_loss: 0.0367
09/16 12:51:34 PM: Update 19148: task edges-ner-ontonotes, batch 148 (19148): mcc: 0.8756, acc: 0.8335, precision: 0.9117, recall: 0.8537, f1: 0.8818, edges-ner-ontonotes_loss: 0.0358
09/16 12:51:44 PM: Update 19264: task edges-ner-ontonotes, batch 264 (19264): mcc: 0.8805, acc: 0.8399, precision: 0.9141, recall: 0.8605, f1: 0.8865, edges-ner-ontonotes_loss: 0.0353
09/16 12:51:54 PM: Update 19314: task edges-ner-ontonotes, batch 314 (19314): mcc: 0.8795, acc: 0.8389, precision: 0.9128, recall: 0.8599, f1: 0.8855, edges-ner-ontonotes_loss: 0.0352
09/16 12:52:06 PM: Update 19448: task edges-ner-ontonotes, batch 448 (19448): mcc: 0.8789, acc: 0.8376, precision: 0.9107, recall: 0.8609, f1: 0.8851, edges-ner-ontonotes_loss: 0.0348
09/16 12:52:16 PM: Update 19567: task edges-ner-ontonotes, batch 567 (19567): mcc: 0.8782, acc: 0.8360, precision: 0.9089, recall: 0.8613, f1: 0.8845, edges-ner-ontonotes_loss: 0.0347
09/16 12:52:26 PM: Update 19628: task edges-ner-ontonotes, batch 628 (19628): mcc: 0.8780, acc: 0.8355, precision: 0.9085, recall: 0.8613, f1: 0.8843, edges-ner-ontonotes_loss: 0.0346
09/16 12:52:36 PM: Update 19755: task edges-ner-ontonotes, batch 755 (19755): mcc: 0.8772, acc: 0.8341, precision: 0.9076, recall: 0.8608, f1: 0.8835, edges-ner-ontonotes_loss: 0.0346
09/16 12:52:46 PM: Update 19876: task edges-ner-ontonotes, batch 876 (19876): mcc: 0.8778, acc: 0.8344, precision: 0.9080, recall: 0.8614, f1: 0.8841, edges-ner-ontonotes_loss: 0.0344
09/16 12:52:56 PM: Update 19940: task edges-ner-ontonotes, batch 940 (19940): mcc: 0.8769, acc: 0.8334, precision: 0.9069, recall: 0.8607, f1: 0.8832, edges-ner-ontonotes_loss: 0.0346
09/16 12:53:01 PM: ***** Step 20000 / Validation 20 *****
09/16 12:53:01 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:53:01 PM: Validating...
09/16 12:53:06 PM: Evaluate: task edges-ner-ontonotes, batch 89 (157): mcc: 0.8703, acc: 0.8320, precision: 0.9113, recall: 0.8444, f1: 0.8766, edges-ner-ontonotes_loss: 0.0439
09/16 12:53:12 PM: Updating LR scheduler:
09/16 12:53:12 PM: 	Best result seen so far for macro_avg: 0.869
09/16 12:53:12 PM: 	# validation passes without improvement: 1
09/16 12:53:12 PM: edges-ner-ontonotes_loss: training: 0.035417 validation: 0.042180
09/16 12:53:12 PM: macro_avg: validation: 0.868387
09/16 12:53:12 PM: micro_avg: validation: 0.000000
09/16 12:53:12 PM: edges-ner-ontonotes_mcc: training: 0.875457 validation: 0.861844
09/16 12:53:12 PM: edges-ner-ontonotes_acc: training: 0.831851 validation: 0.821504
09/16 12:53:12 PM: edges-ner-ontonotes_precision: training: 0.906097 validation: 0.906608
09/16 12:53:12 PM: edges-ner-ontonotes_recall: training: 0.858886 validation: 0.833257
09/16 12:53:12 PM: edges-ner-ontonotes_f1: training: 0.881860 validation: 0.868387
09/16 12:53:12 PM: Global learning rate: 2.5e-05
09/16 12:53:12 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 12:53:16 PM: Update 20044: task edges-ner-ontonotes, batch 44 (20044): mcc: 0.8518, acc: 0.8006, precision: 0.8948, recall: 0.8259, f1: 0.8590, edges-ner-ontonotes_loss: 0.0434
09/16 12:53:26 PM: Update 20165: task edges-ner-ontonotes, batch 165 (20165): mcc: 0.8624, acc: 0.8151, precision: 0.9017, recall: 0.8389, f1: 0.8692, edges-ner-ontonotes_loss: 0.0420
09/16 12:53:36 PM: Update 20291: task edges-ner-ontonotes, batch 291 (20291): mcc: 0.8682, acc: 0.8239, precision: 0.9052, recall: 0.8463, f1: 0.8747, edges-ner-ontonotes_loss: 0.0407
09/16 12:53:46 PM: Update 20422: task edges-ner-ontonotes, batch 422 (20422): mcc: 0.8776, acc: 0.8367, precision: 0.9113, recall: 0.8578, f1: 0.8838, edges-ner-ontonotes_loss: 0.0375
09/16 12:53:59 PM: Update 20542: task edges-ner-ontonotes, batch 542 (20542): mcc: 0.8816, acc: 0.8423, precision: 0.9136, recall: 0.8630, f1: 0.8876, edges-ner-ontonotes_loss: 0.0363
09/16 12:54:09 PM: Update 20661: task edges-ner-ontonotes, batch 661 (20661): mcc: 0.8819, acc: 0.8430, precision: 0.9137, recall: 0.8634, f1: 0.8879, edges-ner-ontonotes_loss: 0.0358
09/16 12:54:19 PM: Update 20790: task edges-ner-ontonotes, batch 790 (20790): mcc: 0.8815, acc: 0.8423, precision: 0.9137, recall: 0.8628, f1: 0.8875, edges-ner-ontonotes_loss: 0.0358
09/16 12:54:29 PM: Update 20866: task edges-ner-ontonotes, batch 866 (20866): mcc: 0.8811, acc: 0.8419, precision: 0.9132, recall: 0.8625, f1: 0.8871, edges-ner-ontonotes_loss: 0.0357
09/16 12:54:38 PM: ***** Step 21000 / Validation 21 *****
09/16 12:54:38 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:54:38 PM: Validating...
09/16 12:54:39 PM: Evaluate: task edges-ner-ontonotes, batch 24 (157): mcc: 0.8081, acc: 0.7710, precision: 0.8507, recall: 0.7873, f1: 0.8177, edges-ner-ontonotes_loss: 0.0581
09/16 12:54:49 PM: Evaluate: task edges-ner-ontonotes, batch 116 (157): mcc: 0.8525, acc: 0.8093, precision: 0.8861, recall: 0.8356, f1: 0.8601, edges-ner-ontonotes_loss: 0.0458
09/16 12:54:52 PM: Updating LR scheduler:
09/16 12:54:52 PM: 	Best result seen so far for macro_avg: 0.869
09/16 12:54:52 PM: 	# validation passes without improvement: 2
09/16 12:54:52 PM: edges-ner-ontonotes_loss: training: 0.035471 validation: 0.042561
09/16 12:54:52 PM: macro_avg: validation: 0.868979
09/16 12:54:52 PM: micro_avg: validation: 0.000000
09/16 12:54:52 PM: edges-ner-ontonotes_mcc: training: 0.880518 validation: 0.861874
09/16 12:54:52 PM: edges-ner-ontonotes_acc: training: 0.840677 validation: 0.819230
09/16 12:54:52 PM: edges-ner-ontonotes_precision: training: 0.911935 validation: 0.893922
09/16 12:54:52 PM: edges-ner-ontonotes_recall: training: 0.862659 validation: 0.845390
09/16 12:54:52 PM: edges-ner-ontonotes_f1: training: 0.886613 validation: 0.868979
09/16 12:54:52 PM: Global learning rate: 2.5e-05
09/16 12:54:52 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 12:54:59 PM: Update 21153: task edges-ner-ontonotes, batch 153 (21153): mcc: 0.8781, acc: 0.8347, precision: 0.9059, recall: 0.8641, f1: 0.8845, edges-ner-ontonotes_loss: 0.0334
09/16 12:55:09 PM: Update 21191: task edges-ner-ontonotes, batch 191 (21191): mcc: 0.8767, acc: 0.8324, precision: 0.9039, recall: 0.8634, f1: 0.8832, edges-ner-ontonotes_loss: 0.0337
09/16 12:55:20 PM: Update 21308: task edges-ner-ontonotes, batch 308 (21308): mcc: 0.8774, acc: 0.8324, precision: 0.9053, recall: 0.8633, f1: 0.8838, edges-ner-ontonotes_loss: 0.0335
09/16 12:55:30 PM: Update 21408: task edges-ner-ontonotes, batch 408 (21408): mcc: 0.8770, acc: 0.8318, precision: 0.9055, recall: 0.8623, f1: 0.8834, edges-ner-ontonotes_loss: 0.0337
09/16 12:55:40 PM: Update 21501: task edges-ner-ontonotes, batch 501 (21501): mcc: 0.8769, acc: 0.8321, precision: 0.9048, recall: 0.8628, f1: 0.8833, edges-ner-ontonotes_loss: 0.0342
09/16 12:55:50 PM: Update 21626: task edges-ner-ontonotes, batch 626 (21626): mcc: 0.8734, acc: 0.8282, precision: 0.9034, recall: 0.8576, f1: 0.8799, edges-ner-ontonotes_loss: 0.0362
09/16 12:56:03 PM: Update 21785: task edges-ner-ontonotes, batch 785 (21785): mcc: 0.8709, acc: 0.8253, precision: 0.9029, recall: 0.8535, f1: 0.8775, edges-ner-ontonotes_loss: 0.0376
09/16 12:56:13 PM: Update 21959: task edges-ner-ontonotes, batch 959 (21959): mcc: 0.8744, acc: 0.8308, precision: 0.9053, recall: 0.8577, f1: 0.8809, edges-ner-ontonotes_loss: 0.0367
09/16 12:56:16 PM: ***** Step 22000 / Validation 22 *****
09/16 12:56:16 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:56:16 PM: Validating...
09/16 12:56:23 PM: Evaluate: task edges-ner-ontonotes, batch 125 (157): mcc: 0.8513, acc: 0.8112, precision: 0.9001, recall: 0.8201, f1: 0.8582, edges-ner-ontonotes_loss: 0.0445
09/16 12:56:26 PM: Updating LR scheduler:
09/16 12:56:26 PM: 	Best result seen so far for macro_avg: 0.869
09/16 12:56:26 PM: 	# validation passes without improvement: 3
09/16 12:56:26 PM: edges-ner-ontonotes_loss: training: 0.036373 validation: 0.042803
09/16 12:56:26 PM: macro_avg: validation: 0.863858
09/16 12:56:26 PM: micro_avg: validation: 0.000000
09/16 12:56:26 PM: edges-ner-ontonotes_mcc: training: 0.875472 validation: 0.857315
09/16 12:56:26 PM: edges-ner-ontonotes_acc: training: 0.832214 validation: 0.816424
09/16 12:56:26 PM: edges-ner-ontonotes_precision: training: 0.906278 validation: 0.906659
09/16 12:56:26 PM: edges-ner-ontonotes_recall: training: 0.858739 validation: 0.824917
09/16 12:56:26 PM: edges-ner-ontonotes_f1: training: 0.881868 validation: 0.863858
09/16 12:56:26 PM: Global learning rate: 2.5e-05
09/16 12:56:26 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 12:56:38 PM: Update 22098: task edges-ner-ontonotes, batch 98 (22098): mcc: 0.8993, acc: 0.8675, precision: 0.9247, recall: 0.8853, f1: 0.9046, edges-ner-ontonotes_loss: 0.0305
09/16 12:56:48 PM: Update 22324: task edges-ner-ontonotes, batch 324 (22324): mcc: 0.8872, acc: 0.8496, precision: 0.9186, recall: 0.8687, f1: 0.8929, edges-ner-ontonotes_loss: 0.0332
09/16 12:57:02 PM: Update 22411: task edges-ner-ontonotes, batch 411 (22411): mcc: 0.8854, acc: 0.8476, precision: 0.9164, recall: 0.8674, f1: 0.8912, edges-ner-ontonotes_loss: 0.0337
09/16 12:57:12 PM: Update 22506: task edges-ner-ontonotes, batch 506 (22506): mcc: 0.8824, acc: 0.8430, precision: 0.9126, recall: 0.8654, f1: 0.8884, edges-ner-ontonotes_loss: 0.0341
09/16 12:57:22 PM: Update 22625: task edges-ner-ontonotes, batch 625 (22625): mcc: 0.8814, acc: 0.8411, precision: 0.9110, recall: 0.8652, f1: 0.8875, edges-ner-ontonotes_loss: 0.0340
09/16 12:57:32 PM: Update 22729: task edges-ner-ontonotes, batch 729 (22729): mcc: 0.8811, acc: 0.8403, precision: 0.9101, recall: 0.8655, f1: 0.8873, edges-ner-ontonotes_loss: 0.0338
09/16 12:57:42 PM: Update 22840: task edges-ner-ontonotes, batch 840 (22840): mcc: 0.8803, acc: 0.8388, precision: 0.9093, recall: 0.8648, f1: 0.8865, edges-ner-ontonotes_loss: 0.0337
09/16 12:57:52 PM: Update 22972: task edges-ner-ontonotes, batch 972 (22972): mcc: 0.8801, acc: 0.8380, precision: 0.9091, recall: 0.8646, f1: 0.8863, edges-ner-ontonotes_loss: 0.0338
09/16 12:57:54 PM: ***** Step 23000 / Validation 23 *****
09/16 12:57:54 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:57:54 PM: Validating...
09/16 12:58:02 PM: Evaluate: task edges-ner-ontonotes, batch 104 (157): mcc: 0.8559, acc: 0.8181, precision: 0.8945, recall: 0.8338, f1: 0.8631, edges-ner-ontonotes_loss: 0.0467
09/16 12:58:07 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:58:07 PM: Best result seen so far for macro.
09/16 12:58:07 PM: Updating LR scheduler:
09/16 12:58:07 PM: 	Best result seen so far for macro_avg: 0.871
09/16 12:58:07 PM: 	# validation passes without improvement: 0
09/16 12:58:07 PM: edges-ner-ontonotes_loss: training: 0.033680 validation: 0.042514
09/16 12:58:07 PM: macro_avg: validation: 0.870844
09/16 12:58:07 PM: micro_avg: validation: 0.000000
09/16 12:58:07 PM: edges-ner-ontonotes_mcc: training: 0.880327 validation: 0.863986
09/16 12:58:07 PM: edges-ner-ontonotes_acc: training: 0.838300 validation: 0.823931
09/16 12:58:07 PM: edges-ner-ontonotes_precision: training: 0.909118 validation: 0.899338
09/16 12:58:07 PM: edges-ner-ontonotes_recall: training: 0.865023 validation: 0.844101
09/16 12:58:07 PM: edges-ner-ontonotes_f1: training: 0.886523 validation: 0.870844
09/16 12:58:07 PM: Global learning rate: 2.5e-05
09/16 12:58:07 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 12:58:12 PM: Update 23037: task edges-ner-ontonotes, batch 37 (23037): mcc: 0.8717, acc: 0.8224, precision: 0.9022, recall: 0.8556, f1: 0.8783, edges-ner-ontonotes_loss: 0.0340
09/16 12:58:24 PM: Update 23147: task edges-ner-ontonotes, batch 147 (23147): mcc: 0.8582, acc: 0.8114, precision: 0.8950, recall: 0.8374, f1: 0.8653, edges-ner-ontonotes_loss: 0.0427
09/16 12:58:34 PM: Update 23256: task edges-ner-ontonotes, batch 256 (23256): mcc: 0.8596, acc: 0.8136, precision: 0.8968, recall: 0.8384, f1: 0.8666, edges-ner-ontonotes_loss: 0.0431
09/16 12:58:49 PM: Update 23341: task edges-ner-ontonotes, batch 341 (23341): mcc: 0.8607, acc: 0.8151, precision: 0.8978, recall: 0.8395, f1: 0.8677, edges-ner-ontonotes_loss: 0.0428
09/16 12:58:59 PM: Update 23471: task edges-ner-ontonotes, batch 471 (23471): mcc: 0.8707, acc: 0.8284, precision: 0.9047, recall: 0.8515, f1: 0.8773, edges-ner-ontonotes_loss: 0.0395
09/16 12:59:09 PM: Update 23598: task edges-ner-ontonotes, batch 598 (23598): mcc: 0.8757, acc: 0.8353, precision: 0.9078, recall: 0.8576, f1: 0.8820, edges-ner-ontonotes_loss: 0.0379
09/16 12:59:19 PM: Update 23664: task edges-ner-ontonotes, batch 664 (23664): mcc: 0.8768, acc: 0.8371, precision: 0.9088, recall: 0.8589, f1: 0.8831, edges-ner-ontonotes_loss: 0.0373
09/16 12:59:29 PM: Update 23768: task edges-ner-ontonotes, batch 768 (23768): mcc: 0.8779, acc: 0.8381, precision: 0.9100, recall: 0.8596, f1: 0.8841, edges-ner-ontonotes_loss: 0.0369
09/16 12:59:39 PM: Update 23878: task edges-ner-ontonotes, batch 878 (23878): mcc: 0.8786, acc: 0.8391, precision: 0.9104, recall: 0.8605, f1: 0.8848, edges-ner-ontonotes_loss: 0.0366
09/16 12:59:49 PM: Update 23972: task edges-ner-ontonotes, batch 972 (23972): mcc: 0.8787, acc: 0.8396, precision: 0.9104, recall: 0.8607, f1: 0.8849, edges-ner-ontonotes_loss: 0.0364
09/16 12:59:53 PM: ***** Step 24000 / Validation 24 *****
09/16 12:59:53 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:59:53 PM: Validating...
09/16 12:59:59 PM: Evaluate: task edges-ner-ontonotes, batch 102 (157): mcc: 0.8609, acc: 0.8265, precision: 0.8993, recall: 0.8383, f1: 0.8678, edges-ner-ontonotes_loss: 0.0454
09/16 01:00:04 PM: Best result seen so far for edges-ner-ontonotes.
09/16 01:00:04 PM: Best result seen so far for macro.
09/16 01:00:04 PM: Updating LR scheduler:
09/16 01:00:04 PM: 	Best result seen so far for macro_avg: 0.871
09/16 01:00:04 PM: 	# validation passes without improvement: 0
09/16 01:00:04 PM: edges-ner-ontonotes_loss: training: 0.036342 validation: 0.042045
09/16 01:00:04 PM: macro_avg: validation: 0.871427
09/16 01:00:04 PM: micro_avg: validation: 0.000000
09/16 01:00:04 PM: edges-ner-ontonotes_mcc: training: 0.878492 validation: 0.864640
09/16 01:00:04 PM: edges-ner-ontonotes_acc: training: 0.839168 validation: 0.829921
09/16 01:00:04 PM: edges-ner-ontonotes_precision: training: 0.910249 validation: 0.900842
09/16 01:00:04 PM: edges-ner-ontonotes_recall: training: 0.860520 validation: 0.843873
09/16 01:00:04 PM: edges-ner-ontonotes_f1: training: 0.884686 validation: 0.871427
09/16 01:00:04 PM: Global learning rate: 2.5e-05
09/16 01:00:04 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 01:00:09 PM: Update 24053: task edges-ner-ontonotes, batch 53 (24053): mcc: 0.8735, acc: 0.8279, precision: 0.9042, recall: 0.8572, f1: 0.8801, edges-ner-ontonotes_loss: 0.0339
09/16 01:00:19 PM: Update 24141: task edges-ner-ontonotes, batch 141 (24141): mcc: 0.8768, acc: 0.8312, precision: 0.9037, recall: 0.8638, f1: 0.8833, edges-ner-ontonotes_loss: 0.0339
09/16 01:00:32 PM: Update 24280: task edges-ner-ontonotes, batch 280 (24280): mcc: 0.8779, acc: 0.8337, precision: 0.9044, recall: 0.8651, f1: 0.8843, edges-ner-ontonotes_loss: 0.0335
09/16 01:00:42 PM: Update 24398: task edges-ner-ontonotes, batch 398 (24398): mcc: 0.8766, acc: 0.8317, precision: 0.9039, recall: 0.8632, f1: 0.8831, edges-ner-ontonotes_loss: 0.0336
09/16 01:00:55 PM: Update 24512: task edges-ner-ontonotes, batch 512 (24512): mcc: 0.8777, acc: 0.8329, precision: 0.9053, recall: 0.8638, f1: 0.8841, edges-ner-ontonotes_loss: 0.0335
09/16 01:01:05 PM: Update 24613: task edges-ner-ontonotes, batch 613 (24613): mcc: 0.8769, acc: 0.8322, precision: 0.9052, recall: 0.8623, f1: 0.8833, edges-ner-ontonotes_loss: 0.0339
09/16 01:01:15 PM: Update 24788: task edges-ner-ontonotes, batch 788 (24788): mcc: 0.8732, acc: 0.8281, precision: 0.9041, recall: 0.8567, f1: 0.8798, edges-ner-ontonotes_loss: 0.0362
09/16 01:01:25 PM: Update 24927: task edges-ner-ontonotes, batch 927 (24927): mcc: 0.8724, acc: 0.8275, precision: 0.9039, recall: 0.8553, f1: 0.8789, edges-ner-ontonotes_loss: 0.0370
09/16 01:01:28 PM: ***** Step 25000 / Validation 25 *****
09/16 01:01:28 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:01:28 PM: Validating...
09/16 01:01:35 PM: Evaluate: task edges-ner-ontonotes, batch 104 (157): mcc: 0.8588, acc: 0.8193, precision: 0.9061, recall: 0.8282, f1: 0.8654, edges-ner-ontonotes_loss: 0.0454
09/16 01:01:41 PM: Updating LR scheduler:
09/16 01:01:41 PM: 	Best result seen so far for macro_avg: 0.871
09/16 01:01:41 PM: 	# validation passes without improvement: 1
09/16 01:01:41 PM: edges-ner-ontonotes_loss: training: 0.036570 validation: 0.042801
09/16 01:01:41 PM: macro_avg: validation: 0.865139
09/16 01:01:41 PM: micro_avg: validation: 0.000000
09/16 01:01:41 PM: edges-ner-ontonotes_mcc: training: 0.873933 validation: 0.858584
09/16 01:01:41 PM: edges-ner-ontonotes_acc: training: 0.829796 validation: 0.818244
09/16 01:01:41 PM: edges-ner-ontonotes_precision: training: 0.904889 validation: 0.906463
09/16 01:01:41 PM: edges-ner-ontonotes_recall: training: 0.857219 validation: 0.827419
09/16 01:01:41 PM: edges-ner-ontonotes_f1: training: 0.880409 validation: 0.865139
09/16 01:01:41 PM: Global learning rate: 2.5e-05
09/16 01:01:41 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 01:01:45 PM: Update 25120: task edges-ner-ontonotes, batch 120 (25120): mcc: 0.8972, acc: 0.8650, precision: 0.9250, recall: 0.8810, f1: 0.9024, edges-ner-ontonotes_loss: 0.0320
09/16 01:01:56 PM: Update 25210: task edges-ner-ontonotes, batch 210 (25210): mcc: 0.8985, acc: 0.8662, precision: 0.9250, recall: 0.8834, f1: 0.9037, edges-ner-ontonotes_loss: 0.0310
09/16 01:02:06 PM: Update 25341: task edges-ner-ontonotes, batch 341 (25341): mcc: 0.8893, acc: 0.8539, precision: 0.9190, recall: 0.8721, f1: 0.8949, edges-ner-ontonotes_loss: 0.0328
09/16 01:02:16 PM: Update 25459: task edges-ner-ontonotes, batch 459 (25459): mcc: 0.8887, acc: 0.8526, precision: 0.9186, recall: 0.8714, f1: 0.8944, edges-ner-ontonotes_loss: 0.0328
09/16 01:02:26 PM: Update 25523: task edges-ner-ontonotes, batch 523 (25523): mcc: 0.8874, acc: 0.8511, precision: 0.9172, recall: 0.8704, f1: 0.8932, edges-ner-ontonotes_loss: 0.0331
09/16 01:02:36 PM: Update 25648: task edges-ner-ontonotes, batch 648 (25648): mcc: 0.8844, acc: 0.8468, precision: 0.9138, recall: 0.8681, f1: 0.8904, edges-ner-ontonotes_loss: 0.0336
09/16 01:02:46 PM: Update 25792: task edges-ner-ontonotes, batch 792 (25792): mcc: 0.8835, acc: 0.8444, precision: 0.9121, recall: 0.8681, f1: 0.8895, edges-ner-ontonotes_loss: 0.0334
09/16 01:02:56 PM: Update 25855: task edges-ner-ontonotes, batch 855 (25855): mcc: 0.8830, acc: 0.8433, precision: 0.9114, recall: 0.8678, f1: 0.8891, edges-ner-ontonotes_loss: 0.0334
09/16 01:03:07 PM: Update 25994: task edges-ner-ontonotes, batch 994 (25994): mcc: 0.8824, acc: 0.8418, precision: 0.9109, recall: 0.8672, f1: 0.8885, edges-ner-ontonotes_loss: 0.0334
09/16 01:03:07 PM: ***** Step 26000 / Validation 26 *****
09/16 01:03:07 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:03:07 PM: Validating...
09/16 01:03:17 PM: Evaluate: task edges-ner-ontonotes, batch 121 (157): mcc: 0.8558, acc: 0.8158, precision: 0.8946, recall: 0.8335, f1: 0.8630, edges-ner-ontonotes_loss: 0.0456
09/16 01:03:20 PM: Updating LR scheduler:
09/16 01:03:21 PM: 	Best result seen so far for macro_avg: 0.871
09/16 01:03:21 PM: 	# validation passes without improvement: 2
09/16 01:03:21 PM: edges-ner-ontonotes_loss: training: 0.033427 validation: 0.042559
09/16 01:03:21 PM: macro_avg: validation: 0.871240
09/16 01:03:21 PM: micro_avg: validation: 0.000000
09/16 01:03:21 PM: edges-ner-ontonotes_mcc: training: 0.882361 validation: 0.864515
09/16 01:03:21 PM: edges-ner-ontonotes_acc: training: 0.841789 validation: 0.826054
09/16 01:03:21 PM: edges-ner-ontonotes_precision: training: 0.910855 validation: 0.902348
09/16 01:03:21 PM: edges-ner-ontonotes_recall: training: 0.867127 validation: 0.842205
09/16 01:03:21 PM: edges-ner-ontonotes_f1: training: 0.888454 validation: 0.871240
09/16 01:03:21 PM: Global learning rate: 2.5e-05
09/16 01:03:21 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 01:03:27 PM: Update 26049: task edges-ner-ontonotes, batch 49 (26049): mcc: 0.8786, acc: 0.8362, precision: 0.9066, recall: 0.8642, f1: 0.8849, edges-ner-ontonotes_loss: 0.0333
09/16 01:03:39 PM: Update 26149: task edges-ner-ontonotes, batch 149 (26149): mcc: 0.8797, acc: 0.8357, precision: 0.9068, recall: 0.8661, f1: 0.8860, edges-ner-ontonotes_loss: 0.0332
09/16 01:03:49 PM: Update 26318: task edges-ner-ontonotes, batch 318 (26318): mcc: 0.8683, acc: 0.8232, precision: 0.9000, recall: 0.8515, f1: 0.8751, edges-ner-ontonotes_loss: 0.0393
09/16 01:04:00 PM: Update 26450: task edges-ner-ontonotes, batch 450 (26450): mcc: 0.8665, acc: 0.8208, precision: 0.9000, recall: 0.8481, f1: 0.8733, edges-ner-ontonotes_loss: 0.0405
09/16 01:04:10 PM: Update 26516: task edges-ner-ontonotes, batch 516 (26516): mcc: 0.8693, acc: 0.8250, precision: 0.9018, recall: 0.8516, f1: 0.8760, edges-ner-ontonotes_loss: 0.0396
09/16 01:04:20 PM: Update 26682: task edges-ner-ontonotes, batch 682 (26682): mcc: 0.8751, acc: 0.8330, precision: 0.9060, recall: 0.8583, f1: 0.8815, edges-ner-ontonotes_loss: 0.0376
09/16 01:04:30 PM: Update 26766: task edges-ner-ontonotes, batch 766 (26766): mcc: 0.8779, acc: 0.8369, precision: 0.9082, recall: 0.8615, f1: 0.8842, edges-ner-ontonotes_loss: 0.0367
09/16 01:04:40 PM: Update 26953: task edges-ner-ontonotes, batch 953 (26953): mcc: 0.8786, acc: 0.8380, precision: 0.9094, recall: 0.8616, f1: 0.8849, edges-ner-ontonotes_loss: 0.0363
09/16 01:04:43 PM: ***** Step 27000 / Validation 27 *****
09/16 01:04:44 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:04:44 PM: Validating...
09/16 01:04:50 PM: Evaluate: task edges-ner-ontonotes, batch 75 (157): mcc: 0.8698, acc: 0.8344, precision: 0.9055, recall: 0.8490, f1: 0.8763, edges-ner-ontonotes_loss: 0.0438
09/16 01:04:57 PM: Updating LR scheduler:
09/16 01:04:57 PM: 	Best result seen so far for macro_avg: 0.871
09/16 01:04:57 PM: 	# validation passes without improvement: 3
09/16 01:04:57 PM: edges-ner-ontonotes_loss: training: 0.036149 validation: 0.042390
09/16 01:04:57 PM: macro_avg: validation: 0.868297
09/16 01:04:57 PM: micro_avg: validation: 0.000000
09/16 01:04:57 PM: edges-ner-ontonotes_mcc: training: 0.879335 validation: 0.861509
09/16 01:04:57 PM: edges-ner-ontonotes_acc: training: 0.838975 validation: 0.825978
09/16 01:04:57 PM: edges-ner-ontonotes_precision: training: 0.910087 validation: 0.901617
09/16 01:04:57 PM: edges-ner-ontonotes_recall: training: 0.862242 validation: 0.837352
09/16 01:04:57 PM: edges-ner-ontonotes_f1: training: 0.885519 validation: 0.868297
09/16 01:04:57 PM: Global learning rate: 2.5e-05
09/16 01:04:57 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 01:05:00 PM: Update 27038: task edges-ner-ontonotes, batch 38 (27038): mcc: 0.8777, acc: 0.8392, precision: 0.9081, recall: 0.8612, f1: 0.8840, edges-ner-ontonotes_loss: 0.0364
09/16 01:05:10 PM: Update 27091: task edges-ner-ontonotes, batch 91 (27091): mcc: 0.8802, acc: 0.8414, precision: 0.9113, recall: 0.8627, f1: 0.8863, edges-ner-ontonotes_loss: 0.0349
09/16 01:05:20 PM: Update 27207: task edges-ner-ontonotes, batch 207 (27207): mcc: 0.8785, acc: 0.8375, precision: 0.9081, recall: 0.8625, f1: 0.8847, edges-ner-ontonotes_loss: 0.0342
09/16 01:05:30 PM: Update 27341: task edges-ner-ontonotes, batch 341 (27341): mcc: 0.8783, acc: 0.8351, precision: 0.9064, recall: 0.8638, f1: 0.8846, edges-ner-ontonotes_loss: 0.0340
09/16 01:05:41 PM: Update 27401: task edges-ner-ontonotes, batch 401 (27401): mcc: 0.8781, acc: 0.8347, precision: 0.9058, recall: 0.8640, f1: 0.8844, edges-ner-ontonotes_loss: 0.0340
09/16 01:05:51 PM: Update 27509: task edges-ner-ontonotes, batch 509 (27509): mcc: 0.8796, acc: 0.8363, precision: 0.9069, recall: 0.8657, f1: 0.8859, edges-ner-ontonotes_loss: 0.0336
09/16 01:06:01 PM: Update 27653: task edges-ner-ontonotes, batch 653 (27653): mcc: 0.8794, acc: 0.8358, precision: 0.9067, recall: 0.8656, f1: 0.8857, edges-ner-ontonotes_loss: 0.0337
09/16 01:06:11 PM: Update 27766: task edges-ner-ontonotes, batch 766 (27766): mcc: 0.8776, acc: 0.8333, precision: 0.9058, recall: 0.8631, f1: 0.8840, edges-ner-ontonotes_loss: 0.0343
09/16 01:06:21 PM: Update 27989: task edges-ner-ontonotes, batch 989 (27989): mcc: 0.8737, acc: 0.8289, precision: 0.9037, recall: 0.8579, f1: 0.8802, edges-ner-ontonotes_loss: 0.0367
09/16 01:06:21 PM: ***** Step 28000 / Validation 28 *****
09/16 01:06:21 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:06:21 PM: Validating...
09/16 01:06:30 PM: Updating LR scheduler:
09/16 01:06:30 PM: 	Best result seen so far for macro_avg: 0.871
09/16 01:06:30 PM: 	# validation passes without improvement: 0
09/16 01:06:30 PM: edges-ner-ontonotes_loss: training: 0.036723 validation: 0.042809
09/16 01:06:30 PM: macro_avg: validation: 0.866018
09/16 01:06:30 PM: micro_avg: validation: 0.000000
09/16 01:06:30 PM: edges-ner-ontonotes_mcc: training: 0.873587 validation: 0.859415
09/16 01:06:30 PM: edges-ner-ontonotes_acc: training: 0.828796 validation: 0.819912
09/16 01:06:30 PM: edges-ner-ontonotes_precision: training: 0.903686 validation: 0.905578
09/16 01:06:30 PM: edges-ner-ontonotes_recall: training: 0.857737 validation: 0.829769
09/16 01:06:30 PM: edges-ner-ontonotes_f1: training: 0.880112 validation: 0.866018
09/16 01:06:30 PM: Global learning rate: 1.25e-05
09/16 01:06:30 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 01:06:34 PM: Update 28009: task edges-ner-ontonotes, batch 9 (28009): mcc: 0.8495, acc: 0.7963, precision: 0.8933, recall: 0.8230, f1: 0.8567, edges-ner-ontonotes_loss: 0.0459
09/16 01:06:44 PM: Update 28211: task edges-ner-ontonotes, batch 211 (28211): mcc: 0.8943, acc: 0.8612, precision: 0.9205, recall: 0.8800, f1: 0.8998, edges-ner-ontonotes_loss: 0.0325
09/16 01:06:59 PM: Update 28322: task edges-ner-ontonotes, batch 322 (28322): mcc: 0.8960, acc: 0.8634, precision: 0.9217, recall: 0.8820, f1: 0.9014, edges-ner-ontonotes_loss: 0.0320
09/16 01:07:09 PM: Update 28448: task edges-ner-ontonotes, batch 448 (28448): mcc: 0.8904, acc: 0.8555, precision: 0.9191, recall: 0.8742, f1: 0.8960, edges-ner-ontonotes_loss: 0.0330
09/16 01:07:19 PM: Update 28571: task edges-ner-ontonotes, batch 571 (28571): mcc: 0.8884, acc: 0.8530, precision: 0.9170, recall: 0.8724, f1: 0.8942, edges-ner-ontonotes_loss: 0.0334
09/16 01:07:31 PM: Update 28635: task edges-ner-ontonotes, batch 635 (28635): mcc: 0.8877, acc: 0.8516, precision: 0.9168, recall: 0.8714, f1: 0.8935, edges-ner-ontonotes_loss: 0.0334
09/16 01:07:41 PM: Update 28752: task edges-ner-ontonotes, batch 752 (28752): mcc: 0.8852, acc: 0.8482, precision: 0.9145, recall: 0.8689, f1: 0.8911, edges-ner-ontonotes_loss: 0.0337
09/16 01:07:51 PM: Update 28852: task edges-ner-ontonotes, batch 852 (28852): mcc: 0.8850, acc: 0.8472, precision: 0.9135, recall: 0.8694, f1: 0.8909, edges-ner-ontonotes_loss: 0.0336
09/16 01:08:04 PM: Update 28948: task edges-ner-ontonotes, batch 948 (28948): mcc: 0.8844, acc: 0.8459, precision: 0.9127, recall: 0.8692, f1: 0.8904, edges-ner-ontonotes_loss: 0.0336
09/16 01:08:06 PM: ***** Step 29000 / Validation 29 *****
09/16 01:08:06 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:08:06 PM: Validating...
09/16 01:08:14 PM: Evaluate: task edges-ner-ontonotes, batch 139 (157): mcc: 0.8614, acc: 0.8215, precision: 0.8943, recall: 0.8442, f1: 0.8685, edges-ner-ontonotes_loss: 0.0432
09/16 01:08:17 PM: Updating LR scheduler:
09/16 01:08:17 PM: 	Best result seen so far for macro_avg: 0.871
09/16 01:08:17 PM: 	# validation passes without improvement: 1
09/16 01:08:17 PM: edges-ner-ontonotes_loss: training: 0.033587 validation: 0.042429
09/16 01:08:17 PM: macro_avg: validation: 0.870380
09/16 01:08:17 PM: micro_avg: validation: 0.000000
09/16 01:08:17 PM: edges-ner-ontonotes_mcc: training: 0.883977 validation: 0.863411
09/16 01:08:17 PM: edges-ner-ontonotes_acc: training: 0.845041 validation: 0.823400
09/16 01:08:17 PM: edges-ner-ontonotes_precision: training: 0.912353 validation: 0.896807
09/16 01:08:17 PM: edges-ner-ontonotes_recall: training: 0.868685 validation: 0.845466
09/16 01:08:17 PM: edges-ner-ontonotes_f1: training: 0.889984 validation: 0.870380
09/16 01:08:17 PM: Global learning rate: 1.25e-05
09/16 01:08:17 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 01:08:25 PM: Update 29093: task edges-ner-ontonotes, batch 93 (29093): mcc: 0.8764, acc: 0.8319, precision: 0.9062, recall: 0.8605, f1: 0.8828, edges-ner-ontonotes_loss: 0.0350
09/16 01:08:35 PM: Update 29215: task edges-ner-ontonotes, batch 215 (29215): mcc: 0.8770, acc: 0.8324, precision: 0.9046, recall: 0.8632, f1: 0.8834, edges-ner-ontonotes_loss: 0.0340
09/16 01:08:45 PM: Update 29283: task edges-ner-ontonotes, batch 283 (29283): mcc: 0.8762, acc: 0.8315, precision: 0.9047, recall: 0.8616, f1: 0.8826, edges-ner-ontonotes_loss: 0.0344
09/16 01:08:55 PM: Update 29390: task edges-ner-ontonotes, batch 390 (29390): mcc: 0.8723, acc: 0.8277, precision: 0.9026, recall: 0.8564, f1: 0.8789, edges-ner-ontonotes_loss: 0.0368
09/16 01:09:07 PM: Update 29520: task edges-ner-ontonotes, batch 520 (29520): mcc: 0.8691, acc: 0.8245, precision: 0.9014, recall: 0.8516, f1: 0.8758, edges-ner-ontonotes_loss: 0.0386
09/16 01:09:17 PM: Update 29621: task edges-ner-ontonotes, batch 621 (29621): mcc: 0.8708, acc: 0.8271, precision: 0.9026, recall: 0.8536, f1: 0.8774, edges-ner-ontonotes_loss: 0.0382
09/16 01:09:27 PM: Update 29766: task edges-ner-ontonotes, batch 766 (29766): mcc: 0.8749, acc: 0.8331, precision: 0.9061, recall: 0.8579, f1: 0.8814, edges-ner-ontonotes_loss: 0.0370
09/16 01:09:37 PM: Update 29878: task edges-ner-ontonotes, batch 878 (29878): mcc: 0.8776, acc: 0.8368, precision: 0.9082, recall: 0.8609, f1: 0.8839, edges-ner-ontonotes_loss: 0.0362
09/16 01:09:47 PM: Update 29984: task edges-ner-ontonotes, batch 984 (29984): mcc: 0.8778, acc: 0.8370, precision: 0.9090, recall: 0.8605, f1: 0.8841, edges-ner-ontonotes_loss: 0.0361
09/16 01:09:49 PM: ***** Step 30000 / Validation 30 *****
09/16 01:09:52 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:09:52 PM: Validating...
09/16 01:09:57 PM: Evaluate: task edges-ner-ontonotes, batch 88 (157): mcc: 0.8758, acc: 0.8413, precision: 0.9130, recall: 0.8529, f1: 0.8819, edges-ner-ontonotes_loss: 0.0422
09/16 01:10:03 PM: Updating LR scheduler:
09/16 01:10:03 PM: 	Best result seen so far for macro_avg: 0.871
09/16 01:10:03 PM: 	# validation passes without improvement: 2
09/16 01:10:03 PM: edges-ner-ontonotes_loss: training: 0.036038 validation: 0.042102
09/16 01:10:03 PM: macro_avg: validation: 0.869113
09/16 01:10:03 PM: micro_avg: validation: 0.000000
09/16 01:10:03 PM: edges-ner-ontonotes_mcc: training: 0.878149 validation: 0.862487
09/16 01:10:03 PM: edges-ner-ontonotes_acc: training: 0.837470 validation: 0.825978
09/16 01:10:03 PM: edges-ner-ontonotes_precision: training: 0.909305 validation: 0.904883
09/16 01:10:03 PM: edges-ner-ontonotes_recall: training: 0.860793 validation: 0.836063
09/16 01:10:03 PM: edges-ner-ontonotes_f1: training: 0.884384 validation: 0.869113
09/16 01:10:03 PM: Global learning rate: 1.25e-05
09/16 01:10:03 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 01:10:08 PM: Update 30051: task edges-ner-ontonotes, batch 51 (30051): mcc: 0.8851, acc: 0.8510, precision: 0.9166, recall: 0.8667, f1: 0.8910, edges-ner-ontonotes_loss: 0.0344
09/16 01:10:18 PM: Update 30163: task edges-ner-ontonotes, batch 163 (30163): mcc: 0.8824, acc: 0.8439, precision: 0.9130, recall: 0.8650, f1: 0.8884, edges-ner-ontonotes_loss: 0.0337
09/16 01:10:28 PM: Update 30219: task edges-ner-ontonotes, batch 219 (30219): mcc: 0.8792, acc: 0.8395, precision: 0.9111, recall: 0.8610, f1: 0.8853, edges-ner-ontonotes_loss: 0.0345
09/16 01:10:38 PM: Update 30351: task edges-ner-ontonotes, batch 351 (30351): mcc: 0.8785, acc: 0.8373, precision: 0.9095, recall: 0.8613, f1: 0.8848, edges-ner-ontonotes_loss: 0.0341
09/16 01:10:48 PM: Update 30495: task edges-ner-ontonotes, batch 495 (30495): mcc: 0.8808, acc: 0.8391, precision: 0.9099, recall: 0.8651, f1: 0.8869, edges-ner-ontonotes_loss: 0.0336
09/16 01:10:58 PM: Update 30622: task edges-ner-ontonotes, batch 622 (30622): mcc: 0.8795, acc: 0.8367, precision: 0.9084, recall: 0.8642, f1: 0.8857, edges-ner-ontonotes_loss: 0.0337
09/16 01:11:08 PM: Update 30741: task edges-ner-ontonotes, batch 741 (30741): mcc: 0.8794, acc: 0.8359, precision: 0.9081, recall: 0.8643, f1: 0.8856, edges-ner-ontonotes_loss: 0.0337
09/16 01:11:19 PM: Update 30817: task edges-ner-ontonotes, batch 817 (30817): mcc: 0.8796, acc: 0.8360, precision: 0.9082, recall: 0.8646, f1: 0.8858, edges-ner-ontonotes_loss: 0.0336
09/16 01:11:31 PM: Update 30979: task edges-ner-ontonotes, batch 979 (30979): mcc: 0.8765, acc: 0.8326, precision: 0.9067, recall: 0.8603, f1: 0.8829, edges-ner-ontonotes_loss: 0.0352
09/16 01:11:32 PM: ***** Step 31000 / Validation 31 *****
09/16 01:11:32 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:11:32 PM: Validating...
09/16 01:11:40 PM: Updating LR scheduler:
09/16 01:11:40 PM: 	Best result seen so far for macro_avg: 0.871
09/16 01:11:40 PM: 	# validation passes without improvement: 3
09/16 01:11:40 PM: edges-ner-ontonotes_loss: training: 0.035306 validation: 0.042070
09/16 01:11:40 PM: macro_avg: validation: 0.869840
09/16 01:11:40 PM: micro_avg: validation: 0.000000
09/16 01:11:40 PM: edges-ner-ontonotes_mcc: training: 0.876369 validation: 0.863279
09/16 01:11:40 PM: edges-ner-ontonotes_acc: training: 0.832462 validation: 0.826585
09/16 01:11:40 PM: edges-ner-ontonotes_precision: training: 0.906701 validation: 0.906104
09/16 01:11:40 PM: edges-ner-ontonotes_recall: training: 0.859997 validation: 0.836366
09/16 01:11:40 PM: edges-ner-ontonotes_f1: training: 0.882732 validation: 0.869840
09/16 01:11:40 PM: Global learning rate: 1.25e-05
09/16 01:11:40 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 01:11:41 PM: Update 31013: task edges-ner-ontonotes, batch 13 (31013): mcc: 0.8504, acc: 0.7939, precision: 0.9095, recall: 0.8098, f1: 0.8567, edges-ner-ontonotes_loss: 0.0489
09/16 01:11:51 PM: Update 31121: task edges-ner-ontonotes, batch 121 (31121): mcc: 0.8576, acc: 0.8103, precision: 0.8962, recall: 0.8353, f1: 0.8646, edges-ner-ontonotes_loss: 0.0446
09/16 01:12:01 PM: Update 31258: task edges-ner-ontonotes, batch 258 (31258): mcc: 0.8774, acc: 0.8365, precision: 0.9095, recall: 0.8591, f1: 0.8836, edges-ner-ontonotes_loss: 0.0382
09/16 01:12:11 PM: Update 31391: task edges-ner-ontonotes, batch 391 (31391): mcc: 0.8861, acc: 0.8483, precision: 0.9161, recall: 0.8691, f1: 0.8920, edges-ner-ontonotes_loss: 0.0354
09/16 01:12:21 PM: Update 31466: task edges-ner-ontonotes, batch 466 (31466): mcc: 0.8859, acc: 0.8484, precision: 0.9158, recall: 0.8689, f1: 0.8918, edges-ner-ontonotes_loss: 0.0350
09/16 01:12:32 PM: Update 31584: task edges-ner-ontonotes, batch 584 (31584): mcc: 0.8850, acc: 0.8471, precision: 0.9161, recall: 0.8670, f1: 0.8909, edges-ner-ontonotes_loss: 0.0347
09/16 01:12:42 PM: Update 31725: task edges-ner-ontonotes, batch 725 (31725): mcc: 0.8855, acc: 0.8474, precision: 0.9165, recall: 0.8675, f1: 0.8913, edges-ner-ontonotes_loss: 0.0346
09/16 01:12:52 PM: Update 31848: task edges-ner-ontonotes, batch 848 (31848): mcc: 0.8829, acc: 0.8439, precision: 0.9141, recall: 0.8651, f1: 0.8889, edges-ner-ontonotes_loss: 0.0348
09/16 01:13:02 PM: Update 31950: task edges-ner-ontonotes, batch 950 (31950): mcc: 0.8828, acc: 0.8434, precision: 0.9134, recall: 0.8655, f1: 0.8888, edges-ner-ontonotes_loss: 0.0345
09/16 01:13:06 PM: ***** Step 32000 / Validation 32 *****
09/16 01:13:06 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:13:06 PM: Validating...
09/16 01:13:13 PM: Evaluate: task edges-ner-ontonotes, batch 92 (157): mcc: 0.8634, acc: 0.8237, precision: 0.9011, recall: 0.8413, f1: 0.8702, edges-ner-ontonotes_loss: 0.0460
09/16 01:13:17 PM: Updating LR scheduler:
09/16 01:13:17 PM: 	Best result seen so far for macro_avg: 0.871
09/16 01:13:17 PM: 	# validation passes without improvement: 0
09/16 01:13:17 PM: edges-ner-ontonotes_loss: training: 0.034482 validation: 0.042344
09/16 01:13:17 PM: macro_avg: validation: 0.869480
09/16 01:13:17 PM: micro_avg: validation: 0.000000
09/16 01:13:17 PM: edges-ner-ontonotes_mcc: training: 0.882583 validation: 0.862439
09/16 01:13:17 PM: edges-ner-ontonotes_acc: training: 0.843268 validation: 0.823097
09/16 01:13:17 PM: edges-ner-ontonotes_precision: training: 0.912834 validation: 0.895325
09/16 01:13:17 PM: edges-ner-ontonotes_recall: training: 0.865628 validation: 0.845086
09/16 01:13:17 PM: edges-ner-ontonotes_f1: training: 0.888604 validation: 0.869480
09/16 01:13:17 PM: Global learning rate: 6.25e-06
09/16 01:13:17 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 01:13:26 PM: Update 32060: task edges-ner-ontonotes, batch 60 (32060): mcc: 0.8830, acc: 0.8414, precision: 0.9112, recall: 0.8681, f1: 0.8891, edges-ner-ontonotes_loss: 0.0323
09/16 01:13:36 PM: Update 32176: task edges-ner-ontonotes, batch 176 (32176): mcc: 0.8781, acc: 0.8332, precision: 0.9065, recall: 0.8633, f1: 0.8844, edges-ner-ontonotes_loss: 0.0336
09/16 01:13:46 PM: Update 32316: task edges-ner-ontonotes, batch 316 (32316): mcc: 0.8786, acc: 0.8340, precision: 0.9057, recall: 0.8651, f1: 0.8849, edges-ner-ontonotes_loss: 0.0335
09/16 01:13:56 PM: Update 32380: task edges-ner-ontonotes, batch 380 (32380): mcc: 0.8776, acc: 0.8328, precision: 0.9053, recall: 0.8637, f1: 0.8840, edges-ner-ontonotes_loss: 0.0336
09/16 01:14:06 PM: Update 32522: task edges-ner-ontonotes, batch 522 (32522): mcc: 0.8719, acc: 0.8264, precision: 0.9018, recall: 0.8564, f1: 0.8785, edges-ner-ontonotes_loss: 0.0368
09/16 01:14:21 PM: Update 32677: task edges-ner-ontonotes, batch 677 (32677): mcc: 0.8704, acc: 0.8249, precision: 0.9015, recall: 0.8538, f1: 0.8770, edges-ner-ontonotes_loss: 0.0382
09/16 01:14:31 PM: Update 32836: task edges-ner-ontonotes, batch 836 (32836): mcc: 0.8743, acc: 0.8308, precision: 0.9045, recall: 0.8583, f1: 0.8808, edges-ner-ontonotes_loss: 0.0369
09/16 01:14:42 PM: Update 32977: task edges-ner-ontonotes, batch 977 (32977): mcc: 0.8769, acc: 0.8349, precision: 0.9067, recall: 0.8610, f1: 0.8833, edges-ner-ontonotes_loss: 0.0363
09/16 01:14:47 PM: ***** Step 33000 / Validation 33 *****
09/16 01:14:47 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:14:47 PM: Validating...
09/16 01:14:52 PM: Evaluate: task edges-ner-ontonotes, batch 47 (157): mcc: 0.8671, acc: 0.8354, precision: 0.9001, recall: 0.8492, f1: 0.8739, edges-ner-ontonotes_loss: 0.0433
09/16 01:15:01 PM: Updating LR scheduler:
09/16 01:15:01 PM: 	Best result seen so far for macro_avg: 0.871
09/16 01:15:01 PM: 	# validation passes without improvement: 1
09/16 01:15:01 PM: edges-ner-ontonotes_loss: training: 0.036178 validation: 0.042080
09/16 01:15:01 PM: macro_avg: validation: 0.867004
09/16 01:15:01 PM: micro_avg: validation: 0.000000
09/16 01:15:01 PM: edges-ner-ontonotes_mcc: training: 0.877148 validation: 0.860413
09/16 01:15:01 PM: edges-ner-ontonotes_acc: training: 0.835283 validation: 0.820443
09/16 01:15:01 PM: edges-ner-ontonotes_precision: training: 0.907031 validation: 0.905749
09/16 01:15:01 PM: edges-ner-ontonotes_recall: training: 0.861128 validation: 0.831438
09/16 01:15:01 PM: edges-ner-ontonotes_f1: training: 0.883484 validation: 0.867004
09/16 01:15:01 PM: Global learning rate: 6.25e-06
09/16 01:15:01 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 01:15:02 PM: Update 33010: task edges-ner-ontonotes, batch 10 (33010): mcc: 0.8811, acc: 0.8392, precision: 0.9155, recall: 0.8603, f1: 0.8871, edges-ner-ontonotes_loss: 0.0356
09/16 01:15:12 PM: Update 33118: task edges-ner-ontonotes, batch 118 (33118): mcc: 0.8748, acc: 0.8318, precision: 0.9129, recall: 0.8512, f1: 0.8810, edges-ner-ontonotes_loss: 0.0359
09/16 01:15:22 PM: Update 33221: task edges-ner-ontonotes, batch 221 (33221): mcc: 0.8806, acc: 0.8401, precision: 0.9152, recall: 0.8597, f1: 0.8866, edges-ner-ontonotes_loss: 0.0347
09/16 01:15:33 PM: Update 33303: task edges-ner-ontonotes, batch 303 (33303): mcc: 0.8830, acc: 0.8430, precision: 0.9164, recall: 0.8630, f1: 0.8889, edges-ner-ontonotes_loss: 0.0343
09/16 01:15:43 PM: Update 33459: task edges-ner-ontonotes, batch 459 (33459): mcc: 0.8804, acc: 0.8394, precision: 0.9129, recall: 0.8615, f1: 0.8865, edges-ner-ontonotes_loss: 0.0341
09/16 01:15:53 PM: Update 33584: task edges-ner-ontonotes, batch 584 (33584): mcc: 0.8810, acc: 0.8398, precision: 0.9123, recall: 0.8632, f1: 0.8870, edges-ner-ontonotes_loss: 0.0339
09/16 01:16:03 PM: Update 33633: task edges-ner-ontonotes, batch 633 (33633): mcc: 0.8803, acc: 0.8391, precision: 0.9114, recall: 0.8627, f1: 0.8864, edges-ner-ontonotes_loss: 0.0340
09/16 01:16:13 PM: Update 33776: task edges-ner-ontonotes, batch 776 (33776): mcc: 0.8803, acc: 0.8381, precision: 0.9107, recall: 0.8634, f1: 0.8864, edges-ner-ontonotes_loss: 0.0338
09/16 01:16:25 PM: Update 33929: task edges-ner-ontonotes, batch 929 (33929): mcc: 0.8795, acc: 0.8372, precision: 0.9091, recall: 0.8636, f1: 0.8857, edges-ner-ontonotes_loss: 0.0339
09/16 01:16:30 PM: ***** Step 34000 / Validation 34 *****
09/16 01:16:33 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:16:33 PM: Validating...
09/16 01:16:36 PM: Evaluate: task edges-ner-ontonotes, batch 70 (157): mcc: 0.8691, acc: 0.8369, precision: 0.9043, recall: 0.8489, f1: 0.8757, edges-ner-ontonotes_loss: 0.0452
09/16 01:16:41 PM: Best result seen so far for edges-ner-ontonotes.
09/16 01:16:41 PM: Best result seen so far for macro.
09/16 01:16:41 PM: Updating LR scheduler:
09/16 01:16:41 PM: 	Best result seen so far for macro_avg: 0.873
09/16 01:16:41 PM: 	# validation passes without improvement: 0
09/16 01:16:41 PM: edges-ner-ontonotes_loss: training: 0.034764 validation: 0.041870
09/16 01:16:41 PM: macro_avg: validation: 0.872882
09/16 01:16:41 PM: micro_avg: validation: 0.000000
09/16 01:16:41 PM: edges-ner-ontonotes_mcc: training: 0.877550 validation: 0.866152
09/16 01:16:41 PM: edges-ner-ontonotes_acc: training: 0.834944 validation: 0.828480
09/16 01:16:41 PM: edges-ner-ontonotes_precision: training: 0.907566 validation: 0.901706
09/16 01:16:41 PM: edges-ner-ontonotes_recall: training: 0.861359 validation: 0.845845
09/16 01:16:41 PM: edges-ner-ontonotes_f1: training: 0.883859 validation: 0.872882
09/16 01:16:41 PM: Global learning rate: 6.25e-06
09/16 01:16:41 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 01:16:46 PM: Update 34095: task edges-ner-ontonotes, batch 95 (34095): mcc: 0.8555, acc: 0.8074, precision: 0.8929, recall: 0.8345, f1: 0.8627, edges-ner-ontonotes_loss: 0.0460
09/16 01:16:59 PM: Update 34233: task edges-ner-ontonotes, batch 233 (34233): mcc: 0.8617, acc: 0.8166, precision: 0.8983, recall: 0.8408, f1: 0.8686, edges-ner-ontonotes_loss: 0.0435
09/16 01:17:09 PM: Update 34370: task edges-ner-ontonotes, batch 370 (34370): mcc: 0.8723, acc: 0.8317, precision: 0.9049, recall: 0.8543, f1: 0.8789, edges-ner-ontonotes_loss: 0.0394
09/16 01:17:19 PM: Update 34506: task edges-ner-ontonotes, batch 506 (34506): mcc: 0.8789, acc: 0.8402, precision: 0.9096, recall: 0.8620, f1: 0.8852, edges-ner-ontonotes_loss: 0.0373
09/16 01:17:29 PM: Update 34617: task edges-ner-ontonotes, batch 617 (34617): mcc: 0.8807, acc: 0.8426, precision: 0.9113, recall: 0.8636, f1: 0.8868, edges-ner-ontonotes_loss: 0.0365
09/16 01:17:39 PM: Update 34814: task edges-ner-ontonotes, batch 814 (34814): mcc: 0.8812, acc: 0.8425, precision: 0.9125, recall: 0.8633, f1: 0.8872, edges-ner-ontonotes_loss: 0.0359
09/16 01:17:49 PM: Update 34901: task edges-ner-ontonotes, batch 901 (34901): mcc: 0.8804, acc: 0.8411, precision: 0.9120, recall: 0.8623, f1: 0.8864, edges-ner-ontonotes_loss: 0.0358
09/16 01:17:59 PM: ***** Step 35000 / Validation 35 *****
09/16 01:17:59 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:17:59 PM: Validating...
09/16 01:17:59 PM: Evaluate: task edges-ner-ontonotes, batch 19 (157): mcc: 0.8197, acc: 0.7794, precision: 0.8599, recall: 0.7998, f1: 0.8288, edges-ner-ontonotes_loss: 0.0530
09/16 01:18:10 PM: Evaluate: task edges-ner-ontonotes, batch 143 (157): mcc: 0.8630, acc: 0.8275, precision: 0.8988, recall: 0.8428, f1: 0.8699, edges-ner-ontonotes_loss: 0.0422
09/16 01:18:11 PM: Updating LR scheduler:
09/16 01:18:11 PM: 	Best result seen so far for macro_avg: 0.873
09/16 01:18:11 PM: 	# validation passes without improvement: 1
09/16 01:18:11 PM: edges-ner-ontonotes_loss: training: 0.035592 validation: 0.041727
09/16 01:18:11 PM: macro_avg: validation: 0.871295
09/16 01:18:11 PM: micro_avg: validation: 0.000000
09/16 01:18:11 PM: edges-ner-ontonotes_mcc: training: 0.880125 validation: 0.864505
09/16 01:18:11 PM: edges-ner-ontonotes_acc: training: 0.840589 validation: 0.828935
09/16 01:18:11 PM: edges-ner-ontonotes_precision: training: 0.911831 validation: 0.900818
09/16 01:18:11 PM: edges-ner-ontonotes_recall: training: 0.862030 validation: 0.843646
09/16 01:18:11 PM: edges-ner-ontonotes_f1: training: 0.886231 validation: 0.871295
09/16 01:18:11 PM: Global learning rate: 6.25e-06
09/16 01:18:11 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 01:18:20 PM: Update 35109: task edges-ner-ontonotes, batch 109 (35109): mcc: 0.8819, acc: 0.8389, precision: 0.9084, recall: 0.8686, f1: 0.8881, edges-ner-ontonotes_loss: 0.0331
09/16 01:18:30 PM: Update 35172: task edges-ner-ontonotes, batch 172 (35172): mcc: 0.8795, acc: 0.8361, precision: 0.9070, recall: 0.8654, f1: 0.8858, edges-ner-ontonotes_loss: 0.0336
09/16 01:18:40 PM: Update 35273: task edges-ner-ontonotes, batch 273 (35273): mcc: 0.8771, acc: 0.8320, precision: 0.9049, recall: 0.8632, f1: 0.8836, edges-ner-ontonotes_loss: 0.0338
09/16 01:18:50 PM: Update 35386: task edges-ner-ontonotes, batch 386 (35386): mcc: 0.8788, acc: 0.8350, precision: 0.9060, recall: 0.8652, f1: 0.8851, edges-ner-ontonotes_loss: 0.0335
09/16 01:19:00 PM: Update 35488: task edges-ner-ontonotes, batch 488 (35488): mcc: 0.8785, acc: 0.8345, precision: 0.9058, recall: 0.8649, f1: 0.8849, edges-ner-ontonotes_loss: 0.0337
09/16 01:19:10 PM: Update 35634: task edges-ner-ontonotes, batch 634 (35634): mcc: 0.8735, acc: 0.8292, precision: 0.9029, recall: 0.8583, f1: 0.8800, edges-ner-ontonotes_loss: 0.0362
09/16 01:19:20 PM: Update 35715: task edges-ner-ontonotes, batch 715 (35715): mcc: 0.8721, acc: 0.8279, precision: 0.9018, recall: 0.8567, f1: 0.8787, edges-ner-ontonotes_loss: 0.0369
09/16 01:19:34 PM: Update 35789: task edges-ner-ontonotes, batch 789 (35789): mcc: 0.8712, acc: 0.8267, precision: 0.9016, recall: 0.8552, f1: 0.8778, edges-ner-ontonotes_loss: 0.0375
09/16 01:19:45 PM: Update 35914: task edges-ner-ontonotes, batch 914 (35914): mcc: 0.8733, acc: 0.8302, precision: 0.9032, recall: 0.8577, f1: 0.8798, edges-ner-ontonotes_loss: 0.0370
09/16 01:19:52 PM: ***** Step 36000 / Validation 36 *****
09/16 01:19:52 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:19:52 PM: Validating...
09/16 01:19:55 PM: Evaluate: task edges-ner-ontonotes, batch 49 (157): mcc: 0.8670, acc: 0.8371, precision: 0.8986, recall: 0.8505, f1: 0.8739, edges-ner-ontonotes_loss: 0.0434
09/16 01:20:05 PM: Evaluate: task edges-ner-ontonotes, batch 139 (157): mcc: 0.8597, acc: 0.8211, precision: 0.9041, recall: 0.8317, f1: 0.8664, edges-ner-ontonotes_loss: 0.0427
09/16 01:20:06 PM: Updating LR scheduler:
09/16 01:20:07 PM: 	Best result seen so far for macro_avg: 0.873
09/16 01:20:07 PM: 	# validation passes without improvement: 2
09/16 01:20:07 PM: edges-ner-ontonotes_loss: training: 0.036232 validation: 0.042028
09/16 01:20:07 PM: macro_avg: validation: 0.868084
09/16 01:20:07 PM: micro_avg: validation: 0.000000
09/16 01:20:07 PM: edges-ner-ontonotes_mcc: training: 0.875350 validation: 0.861534
09/16 01:20:07 PM: edges-ner-ontonotes_acc: training: 0.832922 validation: 0.822718
09/16 01:20:07 PM: edges-ner-ontonotes_precision: training: 0.904889 validation: 0.906487
09/16 01:20:07 PM: edges-ner-ontonotes_recall: training: 0.859855 validation: 0.832803
09/16 01:20:07 PM: edges-ner-ontonotes_f1: training: 0.881797 validation: 0.868084
09/16 01:20:07 PM: Global learning rate: 6.25e-06
09/16 01:20:07 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 01:20:16 PM: Update 36102: task edges-ner-ontonotes, batch 102 (36102): mcc: 0.8957, acc: 0.8647, precision: 0.9206, recall: 0.8826, f1: 0.9012, edges-ner-ontonotes_loss: 0.0317
09/16 01:20:26 PM: Update 36233: task edges-ner-ontonotes, batch 233 (36233): mcc: 0.8883, acc: 0.8517, precision: 0.9172, recall: 0.8720, f1: 0.8941, edges-ner-ontonotes_loss: 0.0330
09/16 01:20:37 PM: Update 36353: task edges-ner-ontonotes, batch 353 (36353): mcc: 0.8853, acc: 0.8481, precision: 0.9157, recall: 0.8679, f1: 0.8912, edges-ner-ontonotes_loss: 0.0334
09/16 01:20:47 PM: Update 36415: task edges-ner-ontonotes, batch 415 (36415): mcc: 0.8836, acc: 0.8454, precision: 0.9146, recall: 0.8658, f1: 0.8895, edges-ner-ontonotes_loss: 0.0338
09/16 01:20:58 PM: Update 36526: task edges-ner-ontonotes, batch 526 (36526): mcc: 0.8827, acc: 0.8434, precision: 0.9132, recall: 0.8654, f1: 0.8887, edges-ner-ontonotes_loss: 0.0336
09/16 01:21:08 PM: Update 36630: task edges-ner-ontonotes, batch 630 (36630): mcc: 0.8818, acc: 0.8419, precision: 0.9124, recall: 0.8645, f1: 0.8878, edges-ner-ontonotes_loss: 0.0335
09/16 01:21:19 PM: Update 36728: task edges-ner-ontonotes, batch 728 (36728): mcc: 0.8812, acc: 0.8408, precision: 0.9116, recall: 0.8643, f1: 0.8873, edges-ner-ontonotes_loss: 0.0337
09/16 01:21:29 PM: Update 36870: task edges-ner-ontonotes, batch 870 (36870): mcc: 0.8802, acc: 0.8391, precision: 0.9099, recall: 0.8640, f1: 0.8864, edges-ner-ontonotes_loss: 0.0338
09/16 01:21:36 PM: ***** Step 37000 / Validation 37 *****
09/16 01:21:36 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:21:36 PM: Validating...
09/16 01:21:39 PM: Evaluate: task edges-ner-ontonotes, batch 54 (157): mcc: 0.8670, acc: 0.8398, precision: 0.8940, recall: 0.8549, f1: 0.8740, edges-ner-ontonotes_loss: 0.0439
09/16 01:21:45 PM: Updating LR scheduler:
09/16 01:21:45 PM: 	Best result seen so far for macro_avg: 0.873
09/16 01:21:45 PM: 	# validation passes without improvement: 3
09/16 01:21:45 PM: edges-ner-ontonotes_loss: training: 0.033698 validation: 0.042212
09/16 01:21:45 PM: macro_avg: validation: 0.872053
09/16 01:21:45 PM: micro_avg: validation: 0.000000
09/16 01:21:45 PM: edges-ner-ontonotes_mcc: training: 0.880838 validation: 0.865241
09/16 01:21:45 PM: edges-ner-ontonotes_acc: training: 0.839463 validation: 0.825447
09/16 01:21:45 PM: edges-ner-ontonotes_precision: training: 0.910169 validation: 0.900024
09/16 01:21:45 PM: edges-ner-ontonotes_recall: training: 0.864957 validation: 0.845769
09/16 01:21:45 PM: edges-ner-ontonotes_f1: training: 0.886987 validation: 0.872053
09/16 01:21:45 PM: Global learning rate: 6.25e-06
09/16 01:21:45 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 01:21:54 PM: Update 37041: task edges-ner-ontonotes, batch 41 (37041): mcc: 0.8792, acc: 0.8332, precision: 0.9056, recall: 0.8662, f1: 0.8855, edges-ner-ontonotes_loss: 0.0324
09/16 01:22:04 PM: Update 37220: task edges-ner-ontonotes, batch 220 (37220): mcc: 0.8590, acc: 0.8117, precision: 0.8940, recall: 0.8401, f1: 0.8662, edges-ner-ontonotes_loss: 0.0422
09/16 01:22:15 PM: Update 37345: task edges-ner-ontonotes, batch 345 (37345): mcc: 0.8606, acc: 0.8138, precision: 0.8952, recall: 0.8419, f1: 0.8677, edges-ner-ontonotes_loss: 0.0427
09/16 01:22:25 PM: Update 37485: task edges-ner-ontonotes, batch 485 (37485): mcc: 0.8696, acc: 0.8258, precision: 0.9021, recall: 0.8518, f1: 0.8763, edges-ner-ontonotes_loss: 0.0393
09/16 01:22:35 PM: Update 37611: task edges-ner-ontonotes, batch 611 (37611): mcc: 0.8750, acc: 0.8335, precision: 0.9058, recall: 0.8584, f1: 0.8815, edges-ner-ontonotes_loss: 0.0378
09/16 01:22:45 PM: Update 37701: task edges-ner-ontonotes, batch 701 (37701): mcc: 0.8759, acc: 0.8350, precision: 0.9064, recall: 0.8595, f1: 0.8823, edges-ner-ontonotes_loss: 0.0372
09/16 01:22:55 PM: Update 37830: task edges-ner-ontonotes, batch 830 (37830): mcc: 0.8771, acc: 0.8363, precision: 0.9084, recall: 0.8598, f1: 0.8834, edges-ner-ontonotes_loss: 0.0367
09/16 01:23:05 PM: Update 37945: task edges-ner-ontonotes, batch 945 (37945): mcc: 0.8778, acc: 0.8372, precision: 0.9097, recall: 0.8598, f1: 0.8841, edges-ner-ontonotes_loss: 0.0364
09/16 01:23:15 PM: Update 37982: task edges-ner-ontonotes, batch 982 (37982): mcc: 0.8777, acc: 0.8370, precision: 0.9095, recall: 0.8598, f1: 0.8839, edges-ner-ontonotes_loss: 0.0364
09/16 01:23:17 PM: ***** Step 38000 / Validation 38 *****
09/16 01:23:19 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:23:19 PM: Validating...
09/16 01:23:25 PM: Evaluate: task edges-ner-ontonotes, batch 87 (157): mcc: 0.8771, acc: 0.8439, precision: 0.9112, recall: 0.8570, f1: 0.8833, edges-ner-ontonotes_loss: 0.0422
09/16 01:23:30 PM: Updating LR scheduler:
09/16 01:23:30 PM: 	Best result seen so far for macro_avg: 0.873
09/16 01:23:30 PM: 	# validation passes without improvement: 0
09/16 01:23:30 PM: edges-ner-ontonotes_loss: training: 0.036343 validation: 0.041808
09/16 01:23:30 PM: macro_avg: validation: 0.870167
09/16 01:23:30 PM: micro_avg: validation: 0.000000
09/16 01:23:30 PM: edges-ner-ontonotes_mcc: training: 0.877647 validation: 0.863465
09/16 01:23:30 PM: edges-ner-ontonotes_acc: training: 0.836998 validation: 0.826736
09/16 01:23:30 PM: edges-ner-ontonotes_precision: training: 0.909394 validation: 0.903100
09/16 01:23:30 PM: edges-ner-ontonotes_recall: training: 0.859775 validation: 0.839551
09/16 01:23:30 PM: edges-ner-ontonotes_f1: training: 0.883889 validation: 0.870167
09/16 01:23:30 PM: Global learning rate: 3.125e-06
09/16 01:23:30 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 01:23:35 PM: Update 38098: task edges-ner-ontonotes, batch 98 (38098): mcc: 0.8708, acc: 0.8287, precision: 0.9004, recall: 0.8557, f1: 0.8775, edges-ner-ontonotes_loss: 0.0351
09/16 01:23:45 PM: Update 38236: task edges-ner-ontonotes, batch 236 (38236): mcc: 0.8773, acc: 0.8357, precision: 0.9078, recall: 0.8606, f1: 0.8836, edges-ner-ontonotes_loss: 0.0335
09/16 01:23:55 PM: Update 38333: task edges-ner-ontonotes, batch 333 (38333): mcc: 0.8763, acc: 0.8344, precision: 0.9065, recall: 0.8602, f1: 0.8827, edges-ner-ontonotes_loss: 0.0338
09/16 01:24:05 PM: Update 38453: task edges-ner-ontonotes, batch 453 (38453): mcc: 0.8774, acc: 0.8349, precision: 0.9066, recall: 0.8619, f1: 0.8837, edges-ner-ontonotes_loss: 0.0337
09/16 01:24:16 PM: Update 38590: task edges-ner-ontonotes, batch 590 (38590): mcc: 0.8776, acc: 0.8350, precision: 0.9066, recall: 0.8624, f1: 0.8839, edges-ner-ontonotes_loss: 0.0338
09/16 01:24:26 PM: Update 38663: task edges-ner-ontonotes, batch 663 (38663): mcc: 0.8751, acc: 0.8323, precision: 0.9044, recall: 0.8599, f1: 0.8816, edges-ner-ontonotes_loss: 0.0351
09/16 01:24:36 PM: Update 38848: task edges-ner-ontonotes, batch 848 (38848): mcc: 0.8724, acc: 0.8293, precision: 0.9027, recall: 0.8564, f1: 0.8790, edges-ner-ontonotes_loss: 0.0368
09/16 01:24:46 PM: Update 38955: task edges-ner-ontonotes, batch 955 (38955): mcc: 0.8729, acc: 0.8302, precision: 0.9030, recall: 0.8571, f1: 0.8794, edges-ner-ontonotes_loss: 0.0368
09/16 01:24:47 PM: ***** Step 39000 / Validation 39 *****
09/16 01:24:49 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:24:49 PM: Validating...
09/16 01:24:56 PM: Evaluate: task edges-ner-ontonotes, batch 83 (157): mcc: 0.8725, acc: 0.8388, precision: 0.9092, recall: 0.8504, f1: 0.8788, edges-ner-ontonotes_loss: 0.0432
09/16 01:25:01 PM: Updating LR scheduler:
09/16 01:25:01 PM: 	Best result seen so far for macro_avg: 0.873
09/16 01:25:01 PM: 	# validation passes without improvement: 1
09/16 01:25:01 PM: edges-ner-ontonotes_loss: training: 0.036762 validation: 0.041756
09/16 01:25:01 PM: macro_avg: validation: 0.870667
09/16 01:25:01 PM: micro_avg: validation: 0.000000
09/16 01:25:01 PM: edges-ner-ontonotes_mcc: training: 0.873394 validation: 0.864053
09/16 01:25:01 PM: edges-ner-ontonotes_acc: training: 0.831062 validation: 0.827116
09/16 01:25:01 PM: edges-ner-ontonotes_precision: training: 0.903483 validation: 0.904883
09/16 01:25:01 PM: edges-ner-ontonotes_recall: training: 0.857575 validation: 0.838944
09/16 01:25:01 PM: edges-ner-ontonotes_f1: training: 0.879931 validation: 0.870667
09/16 01:25:01 PM: Global learning rate: 3.125e-06
09/16 01:25:01 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 01:25:06 PM: Update 39059: task edges-ner-ontonotes, batch 59 (39059): mcc: 0.8949, acc: 0.8610, precision: 0.9211, recall: 0.8806, f1: 0.9004, edges-ner-ontonotes_loss: 0.0312
09/16 01:25:22 PM: Update 39214: task edges-ner-ontonotes, batch 214 (39214): mcc: 0.8991, acc: 0.8680, precision: 0.9216, recall: 0.8878, f1: 0.9044, edges-ner-ontonotes_loss: 0.0306
09/16 01:25:32 PM: Update 39334: task edges-ner-ontonotes, batch 334 (39334): mcc: 0.8911, acc: 0.8560, precision: 0.9189, recall: 0.8756, f1: 0.8968, edges-ner-ontonotes_loss: 0.0320
09/16 01:25:42 PM: Update 39450: task edges-ner-ontonotes, batch 450 (39450): mcc: 0.8880, acc: 0.8509, precision: 0.9174, recall: 0.8713, f1: 0.8938, edges-ner-ontonotes_loss: 0.0328
09/16 01:25:52 PM: Update 39527: task edges-ner-ontonotes, batch 527 (39527): mcc: 0.8884, acc: 0.8514, precision: 0.9180, recall: 0.8715, f1: 0.8941, edges-ner-ontonotes_loss: 0.0327
09/16 01:26:02 PM: Update 39658: task edges-ner-ontonotes, batch 658 (39658): mcc: 0.8863, acc: 0.8479, precision: 0.9166, recall: 0.8689, f1: 0.8921, edges-ner-ontonotes_loss: 0.0328
09/16 01:26:13 PM: Update 39785: task edges-ner-ontonotes, batch 785 (39785): mcc: 0.8839, acc: 0.8448, precision: 0.9142, recall: 0.8668, f1: 0.8899, edges-ner-ontonotes_loss: 0.0331
09/16 01:26:23 PM: Update 39841: task edges-ner-ontonotes, batch 841 (39841): mcc: 0.8833, acc: 0.8437, precision: 0.9136, recall: 0.8663, f1: 0.8893, edges-ner-ontonotes_loss: 0.0331
09/16 01:26:33 PM: Update 39969: task edges-ner-ontonotes, batch 969 (39969): mcc: 0.8827, acc: 0.8427, precision: 0.9128, recall: 0.8660, f1: 0.8887, edges-ner-ontonotes_loss: 0.0333
09/16 01:26:34 PM: ***** Step 40000 / Validation 40 *****
09/16 01:26:34 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:26:34 PM: Validating...
09/16 01:26:42 PM: Updating LR scheduler:
09/16 01:26:42 PM: 	Best result seen so far for macro_avg: 0.873
09/16 01:26:42 PM: 	# validation passes without improvement: 2
09/16 01:26:42 PM: edges-ner-ontonotes_loss: training: 0.033281 validation: 0.041859
09/16 01:26:42 PM: macro_avg: validation: 0.871632
09/16 01:26:42 PM: micro_avg: validation: 0.000000
09/16 01:26:42 PM: edges-ner-ontonotes_mcc: training: 0.882356 validation: 0.864805
09/16 01:26:42 PM: edges-ner-ontonotes_acc: training: 0.841858 validation: 0.829315
09/16 01:26:42 PM: edges-ner-ontonotes_precision: training: 0.912446 validation: 0.899814
09/16 01:26:42 PM: edges-ner-ontonotes_recall: training: 0.865580 validation: 0.845162
09/16 01:26:42 PM: edges-ner-ontonotes_f1: training: 0.888396 validation: 0.871632
09/16 01:26:42 PM: Global learning rate: 3.125e-06
09/16 01:26:42 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 01:26:43 PM: Update 40006: task edges-ner-ontonotes, batch 6 (40006): mcc: 0.8565, acc: 0.8083, precision: 0.8894, recall: 0.8398, f1: 0.8639, edges-ner-ontonotes_loss: 0.0375
09/16 01:26:54 PM: Update 40153: task edges-ner-ontonotes, batch 153 (40153): mcc: 0.8756, acc: 0.8325, precision: 0.9038, recall: 0.8613, f1: 0.8820, edges-ner-ontonotes_loss: 0.0339
09/16 01:27:04 PM: Update 40322: task edges-ner-ontonotes, batch 322 (40322): mcc: 0.8667, acc: 0.8230, precision: 0.8977, recall: 0.8508, f1: 0.8736, edges-ner-ontonotes_loss: 0.0393
09/16 01:27:15 PM: Update 40457: task edges-ner-ontonotes, batch 457 (40457): mcc: 0.8642, acc: 0.8200, precision: 0.8971, recall: 0.8466, f1: 0.8712, edges-ner-ontonotes_loss: 0.0406
09/16 01:27:25 PM: Update 40573: task edges-ner-ontonotes, batch 573 (40573): mcc: 0.8700, acc: 0.8280, precision: 0.9011, recall: 0.8536, f1: 0.8767, edges-ner-ontonotes_loss: 0.0389
09/16 01:27:35 PM: Update 40690: task edges-ner-ontonotes, batch 690 (40690): mcc: 0.8735, acc: 0.8325, precision: 0.9034, recall: 0.8578, f1: 0.8800, edges-ner-ontonotes_loss: 0.0378
09/16 01:27:47 PM: Update 40770: task edges-ner-ontonotes, batch 770 (40770): mcc: 0.8758, acc: 0.8357, precision: 0.9052, recall: 0.8603, f1: 0.8822, edges-ner-ontonotes_loss: 0.0370
09/16 01:27:57 PM: Update 40884: task edges-ner-ontonotes, batch 884 (40884): mcc: 0.8768, acc: 0.8368, precision: 0.9065, recall: 0.8610, f1: 0.8832, edges-ner-ontonotes_loss: 0.0366
09/16 01:28:07 PM: Update 40994: task edges-ner-ontonotes, batch 994 (40994): mcc: 0.8774, acc: 0.8374, precision: 0.9076, recall: 0.8611, f1: 0.8837, edges-ner-ontonotes_loss: 0.0363
09/16 01:28:08 PM: ***** Step 41000 / Validation 41 *****
09/16 01:28:08 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:28:08 PM: Validating...
09/16 01:28:17 PM: Updating LR scheduler:
09/16 01:28:17 PM: 	Best result seen so far for macro_avg: 0.873
09/16 01:28:17 PM: 	# validation passes without improvement: 3
09/16 01:28:17 PM: edges-ner-ontonotes_loss: training: 0.036280 validation: 0.041792
09/16 01:28:17 PM: macro_avg: validation: 0.870986
09/16 01:28:17 PM: micro_avg: validation: 0.000000
09/16 01:28:17 PM: edges-ner-ontonotes_mcc: training: 0.877496 validation: 0.864402
09/16 01:28:17 PM: edges-ner-ontonotes_acc: training: 0.837515 validation: 0.826812
09/16 01:28:17 PM: edges-ner-ontonotes_precision: training: 0.907726 validation: 0.905483
09/16 01:28:17 PM: edges-ner-ontonotes_recall: training: 0.861103 validation: 0.839020
09/16 01:28:17 PM: edges-ner-ontonotes_f1: training: 0.883800 validation: 0.870986
09/16 01:28:17 PM: Global learning rate: 3.125e-06
09/16 01:28:17 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 01:28:17 PM: Update 41001: task edges-ner-ontonotes, batch 1 (41001): mcc: 0.8731, acc: 0.8070, precision: 0.9583, recall: 0.8070, f1: 0.8762, edges-ner-ontonotes_loss: 0.0283
09/16 01:28:27 PM: Update 41084: task edges-ner-ontonotes, batch 84 (41084): mcc: 0.8795, acc: 0.8387, precision: 0.9123, recall: 0.8604, f1: 0.8856, edges-ner-ontonotes_loss: 0.0345
09/16 01:28:37 PM: Update 41222: task edges-ner-ontonotes, batch 222 (41222): mcc: 0.8760, acc: 0.8329, precision: 0.9092, recall: 0.8569, f1: 0.8823, edges-ner-ontonotes_loss: 0.0344
09/16 01:28:47 PM: Update 41339: task edges-ner-ontonotes, batch 339 (41339): mcc: 0.8769, acc: 0.8337, precision: 0.9096, recall: 0.8582, f1: 0.8831, edges-ner-ontonotes_loss: 0.0341
09/16 01:29:00 PM: Update 41396: task edges-ner-ontonotes, batch 396 (41396): mcc: 0.8771, acc: 0.8341, precision: 0.9093, recall: 0.8588, f1: 0.8833, edges-ner-ontonotes_loss: 0.0340
09/16 01:29:10 PM: Update 41524: task edges-ner-ontonotes, batch 524 (41524): mcc: 0.8772, acc: 0.8342, precision: 0.9089, recall: 0.8595, f1: 0.8835, edges-ner-ontonotes_loss: 0.0340
09/16 01:29:20 PM: Update 41628: task edges-ner-ontonotes, batch 628 (41628): mcc: 0.8766, acc: 0.8335, precision: 0.9081, recall: 0.8591, f1: 0.8829, edges-ner-ontonotes_loss: 0.0340
09/16 01:29:30 PM: Update 41723: task edges-ner-ontonotes, batch 723 (41723): mcc: 0.8758, acc: 0.8321, precision: 0.9071, recall: 0.8586, f1: 0.8822, edges-ner-ontonotes_loss: 0.0343
09/16 01:29:40 PM: Update 41886: task edges-ner-ontonotes, batch 886 (41886): mcc: 0.8731, acc: 0.8294, precision: 0.9048, recall: 0.8558, f1: 0.8796, edges-ner-ontonotes_loss: 0.0359
09/16 01:29:48 PM: ***** Step 42000 / Validation 42 *****
09/16 01:29:48 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:29:48 PM: Validating...
09/16 01:29:50 PM: Evaluate: task edges-ner-ontonotes, batch 35 (157): mcc: 0.8528, acc: 0.8246, precision: 0.8838, recall: 0.8383, f1: 0.8604, edges-ner-ontonotes_loss: 0.0476
09/16 01:29:59 PM: Updating LR scheduler:
09/16 01:29:59 PM: 	Best result seen so far for macro_avg: 0.873
09/16 01:29:59 PM: 	# validation passes without improvement: 0
09/16 01:29:59 PM: edges-ner-ontonotes_loss: training: 0.036799 validation: 0.041720
09/16 01:29:59 PM: macro_avg: validation: 0.871716
09/16 01:29:59 PM: micro_avg: validation: 0.000000
09/16 01:29:59 PM: edges-ner-ontonotes_mcc: training: 0.872330 validation: 0.865070
09/16 01:29:59 PM: edges-ner-ontonotes_acc: training: 0.828381 validation: 0.830452
09/16 01:29:59 PM: edges-ner-ontonotes_precision: training: 0.904445 validation: 0.903982
09/16 01:29:59 PM: edges-ner-ontonotes_recall: training: 0.854669 validation: 0.841674
09/16 01:29:59 PM: edges-ner-ontonotes_f1: training: 0.878853 validation: 0.871716
09/16 01:29:59 PM: Global learning rate: 1.5625e-06
09/16 01:29:59 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 01:30:01 PM: Update 42001: task edges-ner-ontonotes, batch 1 (42001): mcc: 0.8384, acc: 0.7826, precision: 0.8916, recall: 0.8043, f1: 0.8457, edges-ner-ontonotes_loss: 0.0582
09/16 01:30:11 PM: Update 42068: task edges-ner-ontonotes, batch 68 (42068): mcc: 0.8872, acc: 0.8506, precision: 0.9141, recall: 0.8729, f1: 0.8930, edges-ner-ontonotes_loss: 0.0346
09/16 01:30:21 PM: Update 42235: task edges-ner-ontonotes, batch 235 (42235): mcc: 0.8918, acc: 0.8601, precision: 0.9164, recall: 0.8794, f1: 0.8975, edges-ner-ontonotes_loss: 0.0329
09/16 01:30:34 PM: Update 42326: task edges-ner-ontonotes, batch 326 (42326): mcc: 0.8928, acc: 0.8610, precision: 0.9165, recall: 0.8811, f1: 0.8984, edges-ner-ontonotes_loss: 0.0324
09/16 01:30:44 PM: Update 42441: task edges-ner-ontonotes, batch 441 (42441): mcc: 0.8905, acc: 0.8561, precision: 0.9165, recall: 0.8767, f1: 0.8962, edges-ner-ontonotes_loss: 0.0327
09/16 01:30:54 PM: Update 42594: task edges-ner-ontonotes, batch 594 (42594): mcc: 0.8871, acc: 0.8513, precision: 0.9150, recall: 0.8720, f1: 0.8930, edges-ner-ontonotes_loss: 0.0331
09/16 01:31:04 PM: Update 42747: task edges-ner-ontonotes, batch 747 (42747): mcc: 0.8860, acc: 0.8486, precision: 0.9151, recall: 0.8697, f1: 0.8918, edges-ner-ontonotes_loss: 0.0331
09/16 01:31:14 PM: Update 42895: task edges-ner-ontonotes, batch 895 (42895): mcc: 0.8842, acc: 0.8456, precision: 0.9137, recall: 0.8677, f1: 0.8901, edges-ner-ontonotes_loss: 0.0333
09/16 01:31:24 PM: Update 42974: task edges-ner-ontonotes, batch 974 (42974): mcc: 0.8834, acc: 0.8442, precision: 0.9132, recall: 0.8668, f1: 0.8894, edges-ner-ontonotes_loss: 0.0334
09/16 01:31:26 PM: ***** Step 43000 / Validation 43 *****
09/16 01:31:26 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:31:26 PM: Validating...
09/16 01:31:34 PM: Updating LR scheduler:
09/16 01:31:34 PM: 	Best result seen so far for macro_avg: 0.873
09/16 01:31:34 PM: 	# validation passes without improvement: 1
09/16 01:31:34 PM: edges-ner-ontonotes_loss: training: 0.033398 validation: 0.041701
09/16 01:31:34 PM: macro_avg: validation: 0.871391
09/16 01:31:34 PM: micro_avg: validation: 0.000000
09/16 01:31:34 PM: edges-ner-ontonotes_mcc: training: 0.883349 validation: 0.864626
09/16 01:31:34 PM: edges-ner-ontonotes_acc: training: 0.843963 validation: 0.828860
09/16 01:31:34 PM: edges-ner-ontonotes_precision: training: 0.913298 validation: 0.901370
09/16 01:31:34 PM: edges-ner-ontonotes_recall: training: 0.866603 validation: 0.843342
09/16 01:31:34 PM: edges-ner-ontonotes_f1: training: 0.889338 validation: 0.871391
09/16 01:31:34 PM: Global learning rate: 1.5625e-06
09/16 01:31:34 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 01:31:35 PM: Update 43001: task edges-ner-ontonotes, batch 1 (43001): mcc: 0.9153, acc: 0.9067, precision: 0.9200, recall: 0.9200, f1: 0.9200, edges-ner-ontonotes_loss: 0.0307
09/16 01:31:45 PM: Update 43158: task edges-ner-ontonotes, batch 158 (43158): mcc: 0.8767, acc: 0.8324, precision: 0.9061, recall: 0.8612, f1: 0.8830, edges-ner-ontonotes_loss: 0.0343
09/16 01:31:59 PM: Update 43265: task edges-ner-ontonotes, batch 265 (43265): mcc: 0.8770, acc: 0.8327, precision: 0.9057, recall: 0.8620, f1: 0.8833, edges-ner-ontonotes_loss: 0.0341
09/16 01:32:09 PM: Update 43416: task edges-ner-ontonotes, batch 416 (43416): mcc: 0.8714, acc: 0.8276, precision: 0.9020, recall: 0.8553, f1: 0.8780, edges-ner-ontonotes_loss: 0.0375
09/16 01:32:19 PM: Update 43567: task edges-ner-ontonotes, batch 567 (43567): mcc: 0.8678, acc: 0.8235, precision: 0.8998, recall: 0.8507, f1: 0.8745, edges-ner-ontonotes_loss: 0.0392
09/16 01:32:29 PM: Update 43619: task edges-ner-ontonotes, batch 619 (43619): mcc: 0.8693, acc: 0.8257, precision: 0.9007, recall: 0.8527, f1: 0.8760, edges-ner-ontonotes_loss: 0.0388
09/16 01:32:39 PM: Update 43785: task edges-ner-ontonotes, batch 785 (43785): mcc: 0.8743, acc: 0.8327, precision: 0.9038, recall: 0.8589, f1: 0.8808, edges-ner-ontonotes_loss: 0.0373
09/16 01:32:50 PM: Update 43882: task edges-ner-ontonotes, batch 882 (43882): mcc: 0.8763, acc: 0.8358, precision: 0.9053, recall: 0.8611, f1: 0.8827, edges-ner-ontonotes_loss: 0.0367
09/16 01:32:59 PM: ***** Step 44000 / Validation 44 *****
09/16 01:32:59 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:32:59 PM: Validating...
09/16 01:33:00 PM: Evaluate: task edges-ner-ontonotes, batch 18 (157): mcc: 0.8201, acc: 0.7797, precision: 0.8592, recall: 0.8013, f1: 0.8292, edges-ner-ontonotes_loss: 0.0537
09/16 01:33:10 PM: Evaluate: task edges-ner-ontonotes, batch 132 (157): mcc: 0.8580, acc: 0.8215, precision: 0.9000, recall: 0.8324, f1: 0.8649, edges-ner-ontonotes_loss: 0.0434
09/16 01:33:12 PM: Updating LR scheduler:
09/16 01:33:12 PM: 	Best result seen so far for macro_avg: 0.873
09/16 01:33:12 PM: 	# validation passes without improvement: 2
09/16 01:33:12 PM: Ran out of early stopping patience. Stopping training.
09/16 01:33:12 PM: edges-ner-ontonotes_loss: training: 0.036678 validation: 0.041724
09/16 01:33:12 PM: macro_avg: validation: 0.870418
09/16 01:33:12 PM: micro_avg: validation: 0.000000
09/16 01:33:12 PM: edges-ner-ontonotes_mcc: training: 0.876226 validation: 0.863822
09/16 01:33:12 PM: edges-ner-ontonotes_acc: training: 0.835706 validation: 0.827798
09/16 01:33:12 PM: edges-ner-ontonotes_precision: training: 0.905752 validation: 0.905316
09/16 01:33:12 PM: edges-ner-ontonotes_recall: training: 0.860648 validation: 0.838110
09/16 01:33:12 PM: edges-ner-ontonotes_f1: training: 0.882625 validation: 0.870418
09/16 01:33:12 PM: Global learning rate: 1.5625e-06
09/16 01:33:12 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-only/run
09/16 01:33:12 PM: Stopped training after 44 validation checks
09/16 01:33:12 PM: Trained edges-ner-ontonotes for 44000 batches or 28.314 epochs
09/16 01:33:12 PM: ***** VALIDATION RESULTS *****
09/16 01:33:12 PM: edges-ner-ontonotes_f1 (for best val pass 34): edges-ner-ontonotes_loss: 0.04187, macro_avg: 0.87288, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.86615, edges-ner-ontonotes_acc: 0.82848, edges-ner-ontonotes_precision: 0.90171, edges-ner-ontonotes_recall: 0.84584, edges-ner-ontonotes_f1: 0.87288
09/16 01:33:12 PM: micro_avg (for best val pass 1): edges-ner-ontonotes_loss: 0.05835, macro_avg: 0.82030, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.81279, edges-ner-ontonotes_acc: 0.74393, edges-ner-ontonotes_precision: 0.88289, edges-ner-ontonotes_recall: 0.76600, edges-ner-ontonotes_f1: 0.82030
09/16 01:33:12 PM: macro_avg (for best val pass 34): edges-ner-ontonotes_loss: 0.04187, macro_avg: 0.87288, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.86615, edges-ner-ontonotes_acc: 0.82848, edges-ner-ontonotes_precision: 0.90171, edges-ner-ontonotes_recall: 0.84584, edges-ner-ontonotes_f1: 0.87288
09/16 01:33:12 PM: Evaluating...
09/16 01:33:12 PM: Loaded model state from ./experiments/ner-ontonotes-sst-only/run/edges-ner-ontonotes/model_state_target_train_val_34.best.th
09/16 01:33:12 PM: Evaluating on: edges-ner-ontonotes, split: val
09/16 01:33:32 PM: Task 'edges-ner-ontonotes': sorting predictions by 'idx'
09/16 01:33:32 PM: Finished evaluating on: edges-ner-ontonotes
09/16 01:33:32 PM: Task 'edges-ner-ontonotes': joining predictions with input split 'val'
09/16 01:33:36 PM: Task 'edges-ner-ontonotes': Wrote predictions to ./experiments/ner-ontonotes-sst-only/run
09/16 01:33:36 PM: Wrote all preds for split 'val' to ./experiments/ner-ontonotes-sst-only/run
09/16 01:33:36 PM: Evaluating on: edges-ner-ontonotes, split: test
09/16 01:33:47 PM: Task 'edges-ner-ontonotes': sorting predictions by 'idx'
09/16 01:33:47 PM: Finished evaluating on: edges-ner-ontonotes
09/16 01:33:47 PM: Task 'edges-ner-ontonotes': joining predictions with input split 'test'
09/16 01:33:49 PM: Task 'edges-ner-ontonotes': Wrote predictions to ./experiments/ner-ontonotes-sst-only/run
09/16 01:33:49 PM: Wrote all preds for split 'test' to ./experiments/ner-ontonotes-sst-only/run
09/16 01:33:49 PM: Writing results for split 'val' to ./experiments/ner-ontonotes-sst-only/results.tsv
09/16 01:33:49 PM: micro_avg: 0.000, macro_avg: 0.875, edges-ner-ontonotes_mcc: 0.868, edges-ner-ontonotes_acc: 0.831, edges-ner-ontonotes_precision: 0.904, edges-ner-ontonotes_recall: 0.847, edges-ner-ontonotes_f1: 0.875
09/16 01:33:50 PM: Done!
09/16 01:33:50 PM: Fatal error in main():
Traceback (most recent call last):
  File "main.py", line 16, in <module>
    main(sys.argv[1:])
  File "/srv/home/ericwallace/jiant/jiant/__main__.py", line 610, in main
    exit("Done exited")
  File "/home/ericwallace/miniconda3/envs/jiant/lib/python3.6/_sitebuiltins.py", line 26, in __call__
    raise SystemExit(code)
SystemExit: Done exited
