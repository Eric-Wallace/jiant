10/01 04:33:43 AM: Git branch: master
10/01 04:33:43 AM: Git SHA: 8a5d6bbc81dc2562b6a149e8b00815e7e9113c4c
10/01 04:33:43 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/srl-ontonotes-allstrings-mix/",
  "exp_name": "experiments/srl-ontonotes-allstrings-mix",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/srl-ontonotes-allstrings-mix/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/allstrings",
  "pytorch_transformers_output_mode": "mix",
  "remote_log_name": "experiments/srl-ontonotes-allstrings-mix__run",
  "run_dir": "./experiments/srl-ontonotes-allstrings-mix/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-srl-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
10/01 04:33:43 AM: Saved config to ./experiments/srl-ontonotes-allstrings-mix/run/params.conf
10/01 04:33:43 AM: Using random seed 1234
10/01 04:33:45 AM: Using GPU 0
10/01 04:33:45 AM: Loading tasks...
10/01 04:33:45 AM: Writing pre-preprocessed tasks to ./experiments/srl-ontonotes-allstrings-mix/
10/01 04:33:45 AM: 	Creating task edges-srl-ontonotes from scratch.
10/01 04:33:49 AM: Read=231480, Skip=21590, Total=253070 from ./probing_data/edges/ontonotes/srl/train.json.retokenized.bert-base-uncased
10/01 04:33:49 AM: Read=32486, Skip=2811, Total=35297 from ./probing_data/edges/ontonotes/srl/development.json.retokenized.bert-base-uncased
10/01 04:33:50 AM: Read=23800, Skip=2915, Total=26715 from ./probing_data/edges/ontonotes/srl/test.json.retokenized.bert-base-uncased
10/01 04:33:52 AM: 	Task 'edges-srl-ontonotes': |train|=231480 |val|=32486 |test|=23800
10/01 04:33:52 AM: 	Finished loading tasks: edges-srl-ontonotes.
10/01 04:33:52 AM: 	Building vocab from scratch.
10/01 04:33:52 AM: 	Counting units for task edges-srl-ontonotes.
10/01 04:33:58 AM: 	Task 'edges-srl-ontonotes': adding vocab namespace 'edges-srl-ontonotes_labels'
10/01 04:33:59 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
10/01 04:33:59 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
10/01 04:33:59 AM: 	Saved vocab to ./experiments/srl-ontonotes-allstrings-mix/vocab
10/01 04:33:59 AM: Loading token dictionary from ./experiments/srl-ontonotes-allstrings-mix/vocab.
10/01 04:33:59 AM: 	Loaded vocab from ./experiments/srl-ontonotes-allstrings-mix/vocab
10/01 04:33:59 AM: 	Vocab namespace bert_uncased: size 30524
10/01 04:33:59 AM: 	Vocab namespace tokens: size 23662
10/01 04:33:59 AM: 	Vocab namespace chars: size 76
10/01 04:33:59 AM: 	Vocab namespace edges-srl-ontonotes_labels: size 66
10/01 04:33:59 AM: 	Finished building vocab.
10/01 04:33:59 AM: 	Task edges-srl-ontonotes (train): Indexing from scratch.
10/01 04:34:29 AM: 	Task edges-srl-ontonotes (train): Saved 231480 instances to ./experiments/srl-ontonotes-allstrings-mix/preproc/edges-srl-ontonotes__train_data
10/01 04:34:29 AM: 	Task edges-srl-ontonotes (val): Indexing from scratch.
10/01 04:34:33 AM: 	Task edges-srl-ontonotes (val): Saved 32486 instances to ./experiments/srl-ontonotes-allstrings-mix/preproc/edges-srl-ontonotes__val_data
10/01 04:34:33 AM: 	Task edges-srl-ontonotes (test): Indexing from scratch.
10/01 04:34:36 AM: 	Task edges-srl-ontonotes (test): Saved 23800 instances to ./experiments/srl-ontonotes-allstrings-mix/preproc/edges-srl-ontonotes__test_data
10/01 04:34:36 AM: 	Finished indexing tasks
10/01 04:34:36 AM: 	Creating trimmed target-only version of edges-srl-ontonotes train.
10/01 04:34:36 AM: 	  Training on 
10/01 04:34:36 AM: 	  Evaluating on edges-srl-ontonotes
10/01 04:34:36 AM: 	Finished loading tasks in 51.340s
10/01 04:34:36 AM: 	 Tasks: ['edges-srl-ontonotes']
10/01 04:34:36 AM: Building model...
10/01 04:34:36 AM: Using BERT model (bert-base-uncased).
10/01 04:34:36 AM: LOADING A FUNETUNED MODEL from: 
10/01 04:34:36 AM: models/allstrings
10/01 04:34:36 AM: loading configuration file models/allstrings/config.json
10/01 04:34:36 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "random-memorize-all-binary",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

10/01 04:34:36 AM: loading weights file models/allstrings/pytorch_model.bin
10/01 04:34:40 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp134icu96
10/01 04:34:41 AM: copying /tmp/tmp134icu96 to cache at ./experiments/srl-ontonotes-allstrings-mix/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
10/01 04:34:41 AM: creating metadata file for ./experiments/srl-ontonotes-allstrings-mix/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
10/01 04:34:41 AM: removing temp file /tmp/tmp134icu96
10/01 04:34:41 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/srl-ontonotes-allstrings-mix/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
10/01 04:34:41 AM: NOTE: pytorch_transformers_output_mode='mix', so scalar mixing weights will be fine-tuned even if BERT model is frozen.
10/01 04:34:41 AM: Initializing parameters
10/01 04:34:41 AM: Done initializing parameters; the following parameters are using their default initialization from their code
10/01 04:34:41 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
10/01 04:34:41 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
10/01 04:34:41 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.model.pooler.dense.bias
10/01 04:34:41 AM:    _text_field_embedder.model.pooler.dense.weight
10/01 04:34:41 AM:    _text_field_embedder.scalar_mix.gamma
10/01 04:34:41 AM:    _text_field_embedder.scalar_mix.scalar_parameters.0
10/01 04:34:41 AM:    _text_field_embedder.scalar_mix.scalar_parameters.1
10/01 04:34:41 AM:    _text_field_embedder.scalar_mix.scalar_parameters.10
10/01 04:34:41 AM:    _text_field_embedder.scalar_mix.scalar_parameters.11
10/01 04:34:41 AM:    _text_field_embedder.scalar_mix.scalar_parameters.12
10/01 04:34:41 AM:    _text_field_embedder.scalar_mix.scalar_parameters.2
10/01 04:34:41 AM:    _text_field_embedder.scalar_mix.scalar_parameters.3
10/01 04:34:41 AM:    _text_field_embedder.scalar_mix.scalar_parameters.4
10/01 04:34:41 AM:    _text_field_embedder.scalar_mix.scalar_parameters.5
10/01 04:34:41 AM:    _text_field_embedder.scalar_mix.scalar_parameters.6
10/01 04:34:41 AM:    _text_field_embedder.scalar_mix.scalar_parameters.7
10/01 04:34:41 AM:    _text_field_embedder.scalar_mix.scalar_parameters.8
10/01 04:34:41 AM:    _text_field_embedder.scalar_mix.scalar_parameters.9
10/01 04:34:41 AM: 	Task 'edges-srl-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-srl-ontonotes"
}
10/01 04:34:47 AM: Model specification:
10/01 04:34:47 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
      (scalar_mix): ScalarMix(
        (scalar_parameters): ParameterList(
            (0): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (1): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (2): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (3): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (4): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (5): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (6): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (7): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (8): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (9): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (10): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (11): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (12): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-srl-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (proj2): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (span_extractor2): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Sequential(
        (0): Linear(in_features=1024, out_features=256, bias=True)
        (1): Tanh()
        (2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)
        (3): Dropout(p=0.3)
        (4): Linear(in_features=256, out_features=66, bias=True)
      )
    )
  )
)
10/01 04:34:47 AM: Model parameters:
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.scalar_mix.gamma: Trainable parameter, count 1 with torch.Size([1])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.0: Trainable parameter, count 1 with torch.Size([1])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.1: Trainable parameter, count 1 with torch.Size([1])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.2: Trainable parameter, count 1 with torch.Size([1])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.3: Trainable parameter, count 1 with torch.Size([1])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.4: Trainable parameter, count 1 with torch.Size([1])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.5: Trainable parameter, count 1 with torch.Size([1])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.6: Trainable parameter, count 1 with torch.Size([1])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.7: Trainable parameter, count 1 with torch.Size([1])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.8: Trainable parameter, count 1 with torch.Size([1])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.9: Trainable parameter, count 1 with torch.Size([1])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.10: Trainable parameter, count 1 with torch.Size([1])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.11: Trainable parameter, count 1 with torch.Size([1])
10/01 04:34:47 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.12: Trainable parameter, count 1 with torch.Size([1])
10/01 04:34:47 AM: 	edges-srl-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
10/01 04:34:47 AM: 	edges-srl-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
10/01 04:34:47 AM: 	edges-srl-ontonotes_mdl.proj2.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
10/01 04:34:47 AM: 	edges-srl-ontonotes_mdl.proj2.bias: Trainable parameter, count 256 with torch.Size([256])
10/01 04:34:47 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.0.weight: Trainable parameter, count 262144 with torch.Size([256, 1024])
10/01 04:34:47 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.0.bias: Trainable parameter, count 256 with torch.Size([256])
10/01 04:34:47 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.2.weight: Trainable parameter, count 256 with torch.Size([256])
10/01 04:34:47 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.2.bias: Trainable parameter, count 256 with torch.Size([256])
10/01 04:34:47 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.4.weight: Trainable parameter, count 16896 with torch.Size([66, 256])
10/01 04:34:47 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.4.bias: Trainable parameter, count 66 with torch.Size([66])
10/01 04:34:47 AM: Total number of parameters: 110155856 (1.10156e+08)
10/01 04:34:47 AM: Number of trainable parameters: 673616 (673616)
10/01 04:34:47 AM: Finished building model in 10.893s
10/01 04:34:47 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-srl-ontonotes 

10/01 04:35:01 AM: patience = 9
10/01 04:35:01 AM: val_interval = 1000
10/01 04:35:01 AM: max_vals = 250
10/01 04:35:01 AM: cuda_device = 0
10/01 04:35:01 AM: grad_norm = 5.0
10/01 04:35:01 AM: grad_clipping = None
10/01 04:35:01 AM: lr_decay = 0.99
10/01 04:35:01 AM: min_lr = 1e-06
10/01 04:35:01 AM: keep_all_checkpoints = 0
10/01 04:35:01 AM: val_data_limit = 5000
10/01 04:35:01 AM: max_epochs = -1
10/01 04:35:01 AM: dec_val_scale = 250
10/01 04:35:01 AM: training_data_fraction = 1
10/01 04:35:01 AM: type = adam
10/01 04:35:01 AM: parameter_groups = None
10/01 04:35:01 AM: Number of trainable parameters: 673616
10/01 04:35:01 AM: infer_type_and_cast = True
10/01 04:35:01 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
10/01 04:35:01 AM: CURRENTLY DEFINED PARAMETERS: 
10/01 04:35:01 AM: lr = 0.0001
10/01 04:35:01 AM: amsgrad = True
10/01 04:35:01 AM: type = reduce_on_plateau
10/01 04:35:01 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
10/01 04:35:01 AM: CURRENTLY DEFINED PARAMETERS: 
10/01 04:35:01 AM: mode = max
10/01 04:35:01 AM: factor = 0.5
10/01 04:35:01 AM: patience = 3
10/01 04:35:01 AM: threshold = 0.0001
10/01 04:35:01 AM: threshold_mode = abs
10/01 04:35:01 AM: verbose = True
10/01 04:35:01 AM: type = adam
10/01 04:35:01 AM: parameter_groups = None
10/01 04:35:01 AM: Number of trainable parameters: 673616
10/01 04:35:01 AM: infer_type_and_cast = True
10/01 04:35:01 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
10/01 04:35:01 AM: CURRENTLY DEFINED PARAMETERS: 
10/01 04:35:01 AM: lr = 0.0001
10/01 04:35:01 AM: amsgrad = True
10/01 04:35:01 AM: type = reduce_on_plateau
10/01 04:35:01 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
10/01 04:35:01 AM: CURRENTLY DEFINED PARAMETERS: 
10/01 04:35:01 AM: mode = max
10/01 04:35:01 AM: factor = 0.5
10/01 04:35:01 AM: patience = 3
10/01 04:35:01 AM: threshold = 0.0001
10/01 04:35:01 AM: threshold_mode = abs
10/01 04:35:01 AM: verbose = True
10/01 04:35:01 AM: Starting training without restoring from a checkpoint.
10/01 04:35:01 AM: Training examples per task, before any subsampling: {'edges-srl-ontonotes': 231480}
10/01 04:35:01 AM: Beginning training with stopping criteria based on metric: edges-srl-ontonotes_f1
10/01 04:35:11 AM: Update 118: task edges-srl-ontonotes, batch 118 (118): mcc: 0.0639, acc: 0.0443, precision: 0.0656, recall: 0.1012, f1: 0.0796, edges-srl-ontonotes_loss: 0.2020
10/01 04:35:21 AM: Update 243: task edges-srl-ontonotes, batch 243 (243): mcc: 0.0737, acc: 0.0486, precision: 0.0977, recall: 0.0758, f1: 0.0854, edges-srl-ontonotes_loss: 0.1338
10/01 04:35:31 AM: Update 361: task edges-srl-ontonotes, batch 361 (361): mcc: 0.1532, acc: 0.1091, precision: 0.2071, recall: 0.1287, f1: 0.1588, edges-srl-ontonotes_loss: 0.1061
10/01 04:35:41 AM: Update 499: task edges-srl-ontonotes, batch 499 (499): mcc: 0.2626, acc: 0.1903, precision: 0.3522, recall: 0.2087, f1: 0.2621, edges-srl-ontonotes_loss: 0.0873
10/01 04:35:53 AM: Update 627: task edges-srl-ontonotes, batch 627 (627): mcc: 0.3500, acc: 0.2584, precision: 0.4600, recall: 0.2779, f1: 0.3464, edges-srl-ontonotes_loss: 0.0759
10/01 04:36:03 AM: Update 758: task edges-srl-ontonotes, batch 758 (758): mcc: 0.4097, acc: 0.3062, precision: 0.5307, recall: 0.3270, f1: 0.4047, edges-srl-ontonotes_loss: 0.0679
10/01 04:36:13 AM: Update 880: task edges-srl-ontonotes, batch 880 (880): mcc: 0.4548, acc: 0.3449, precision: 0.5803, recall: 0.3665, f1: 0.4493, edges-srl-ontonotes_loss: 0.0621
10/01 04:36:23 AM: ***** Step 1000 / Validation 1 *****
10/01 04:36:23 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 04:36:23 AM: Validating...
10/01 04:36:23 AM: Evaluate: task edges-srl-ontonotes, batch 2 (157): mcc: 0.7871, acc: 0.6648, precision: 0.9225, recall: 0.6761, f1: 0.7803, edges-srl-ontonotes_loss: 0.0217
10/01 04:36:33 AM: Evaluate: task edges-srl-ontonotes, batch 138 (157): mcc: 0.7748, acc: 0.6623, precision: 0.8952, recall: 0.6755, f1: 0.7700, edges-srl-ontonotes_loss: 0.0215
10/01 04:36:35 AM: Best result seen so far for edges-srl-ontonotes.
10/01 04:36:35 AM: Best result seen so far for micro.
10/01 04:36:35 AM: Best result seen so far for macro.
10/01 04:36:35 AM: Updating LR scheduler:
10/01 04:36:35 AM: 	Best result seen so far for macro_avg: 0.768
10/01 04:36:35 AM: 	# validation passes without improvement: 0
10/01 04:36:35 AM: edges-srl-ontonotes_loss: training: 0.057668 validation: 0.021693
10/01 04:36:35 AM: macro_avg: validation: 0.768199
10/01 04:36:35 AM: micro_avg: validation: 0.000000
10/01 04:36:35 AM: edges-srl-ontonotes_mcc: training: 0.488728 validation: 0.772805
10/01 04:36:35 AM: edges-srl-ontonotes_acc: training: 0.374988 validation: 0.660996
10/01 04:36:35 AM: edges-srl-ontonotes_precision: training: 0.615816 validation: 0.891919
10/01 04:36:35 AM: edges-srl-ontonotes_recall: training: 0.397578 validation: 0.674621
10/01 04:36:35 AM: edges-srl-ontonotes_f1: training: 0.483198 validation: 0.768199
10/01 04:36:35 AM: Global learning rate: 0.0001
10/01 04:36:35 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 04:36:44 AM: Update 1123: task edges-srl-ontonotes, batch 123 (1123): mcc: 0.7380, acc: 0.6194, precision: 0.8481, recall: 0.6481, f1: 0.7347, edges-srl-ontonotes_loss: 0.0241
10/01 04:36:54 AM: Update 1253: task edges-srl-ontonotes, batch 253 (1253): mcc: 0.7411, acc: 0.6242, precision: 0.8459, recall: 0.6551, f1: 0.7384, edges-srl-ontonotes_loss: 0.0235
10/01 04:37:04 AM: Update 1379: task edges-srl-ontonotes, batch 379 (1379): mcc: 0.7415, acc: 0.6267, precision: 0.8424, recall: 0.6586, f1: 0.7392, edges-srl-ontonotes_loss: 0.0231
10/01 04:37:14 AM: Update 1504: task edges-srl-ontonotes, batch 504 (1504): mcc: 0.7495, acc: 0.6375, precision: 0.8463, recall: 0.6696, f1: 0.7477, edges-srl-ontonotes_loss: 0.0223
10/01 04:37:24 AM: Update 1621: task edges-srl-ontonotes, batch 621 (1621): mcc: 0.7512, acc: 0.6399, precision: 0.8461, recall: 0.6728, f1: 0.7496, edges-srl-ontonotes_loss: 0.0220
10/01 04:37:34 AM: Update 1747: task edges-srl-ontonotes, batch 747 (1747): mcc: 0.7507, acc: 0.6397, precision: 0.8447, recall: 0.6731, f1: 0.7492, edges-srl-ontonotes_loss: 0.0219
10/01 04:37:45 AM: Update 1860: task edges-srl-ontonotes, batch 860 (1860): mcc: 0.7506, acc: 0.6399, precision: 0.8435, recall: 0.6738, f1: 0.7492, edges-srl-ontonotes_loss: 0.0218
10/01 04:37:55 AM: Update 1950: task edges-srl-ontonotes, batch 950 (1950): mcc: 0.7517, acc: 0.6415, precision: 0.8434, recall: 0.6758, f1: 0.7504, edges-srl-ontonotes_loss: 0.0217
10/01 04:37:59 AM: ***** Step 2000 / Validation 2 *****
10/01 04:37:59 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 04:37:59 AM: Validating...
10/01 04:38:05 AM: Evaluate: task edges-srl-ontonotes, batch 79 (157): mcc: 0.8022, acc: 0.7105, precision: 0.8895, recall: 0.7283, f1: 0.8009, edges-srl-ontonotes_loss: 0.0172
10/01 04:38:10 AM: Best result seen so far for edges-srl-ontonotes.
10/01 04:38:10 AM: Best result seen so far for macro.
10/01 04:38:10 AM: Updating LR scheduler:
10/01 04:38:10 AM: 	Best result seen so far for macro_avg: 0.816
10/01 04:38:10 AM: 	# validation passes without improvement: 0
10/01 04:38:10 AM: edges-srl-ontonotes_loss: training: 0.021606 validation: 0.016429
10/01 04:38:10 AM: macro_avg: validation: 0.816308
10/01 04:38:10 AM: micro_avg: validation: 0.000000
10/01 04:38:10 AM: edges-srl-ontonotes_mcc: training: 0.752416 validation: 0.817044
10/01 04:38:10 AM: edges-srl-ontonotes_acc: training: 0.642418 validation: 0.733662
10/01 04:38:10 AM: edges-srl-ontonotes_precision: training: 0.843688 validation: 0.895724
10/01 04:38:10 AM: edges-srl-ontonotes_recall: training: 0.676913 validation: 0.749827
10/01 04:38:10 AM: edges-srl-ontonotes_f1: training: 0.751155 validation: 0.816308
10/01 04:38:10 AM: Global learning rate: 0.0001
10/01 04:38:10 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 04:38:15 AM: Update 2053: task edges-srl-ontonotes, batch 53 (2053): mcc: 0.7690, acc: 0.6650, precision: 0.8540, recall: 0.6980, f1: 0.7682, edges-srl-ontonotes_loss: 0.0200
10/01 04:38:25 AM: Update 2180: task edges-srl-ontonotes, batch 180 (2180): mcc: 0.7609, acc: 0.6577, precision: 0.8411, recall: 0.6943, f1: 0.7607, edges-srl-ontonotes_loss: 0.0202
10/01 04:38:35 AM: Update 2289: task edges-srl-ontonotes, batch 289 (2289): mcc: 0.7656, acc: 0.6641, precision: 0.8432, recall: 0.7010, f1: 0.7656, edges-srl-ontonotes_loss: 0.0199
10/01 04:38:45 AM: Update 2392: task edges-srl-ontonotes, batch 392 (2392): mcc: 0.7737, acc: 0.6740, precision: 0.8484, recall: 0.7112, f1: 0.7738, edges-srl-ontonotes_loss: 0.0193
10/01 04:38:55 AM: Update 2504: task edges-srl-ontonotes, batch 504 (2504): mcc: 0.7772, acc: 0.6787, precision: 0.8502, recall: 0.7161, f1: 0.7774, edges-srl-ontonotes_loss: 0.0190
10/01 04:39:05 AM: Update 2616: task edges-srl-ontonotes, batch 616 (2616): mcc: 0.7787, acc: 0.6814, precision: 0.8503, recall: 0.7187, f1: 0.7790, edges-srl-ontonotes_loss: 0.0188
10/01 04:39:15 AM: Update 2734: task edges-srl-ontonotes, batch 734 (2734): mcc: 0.7811, acc: 0.6849, precision: 0.8512, recall: 0.7222, f1: 0.7815, edges-srl-ontonotes_loss: 0.0186
10/01 04:39:25 AM: Update 2818: task edges-srl-ontonotes, batch 818 (2818): mcc: 0.7831, acc: 0.6881, precision: 0.8522, recall: 0.7252, f1: 0.7836, edges-srl-ontonotes_loss: 0.0184
10/01 04:39:35 AM: Update 2939: task edges-srl-ontonotes, batch 939 (2939): mcc: 0.7854, acc: 0.6912, precision: 0.8534, recall: 0.7284, f1: 0.7859, edges-srl-ontonotes_loss: 0.0183
10/01 04:39:40 AM: ***** Step 3000 / Validation 3 *****
10/01 04:39:41 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 04:39:41 AM: Validating...
10/01 04:39:45 AM: Evaluate: task edges-srl-ontonotes, batch 63 (157): mcc: 0.8119, acc: 0.7329, precision: 0.8761, recall: 0.7572, f1: 0.8123, edges-srl-ontonotes_loss: 0.0164
10/01 04:39:52 AM: Best result seen so far for edges-srl-ontonotes.
10/01 04:39:52 AM: Best result seen so far for macro.
10/01 04:39:52 AM: Updating LR scheduler:
10/01 04:39:52 AM: 	Best result seen so far for macro_avg: 0.828
10/01 04:39:52 AM: 	# validation passes without improvement: 0
10/01 04:39:52 AM: edges-srl-ontonotes_loss: training: 0.018186 validation: 0.015272
10/01 04:39:52 AM: macro_avg: validation: 0.828056
10/01 04:39:52 AM: micro_avg: validation: 0.000000
10/01 04:39:52 AM: edges-srl-ontonotes_mcc: training: 0.786491 validation: 0.827427
10/01 04:39:52 AM: edges-srl-ontonotes_acc: training: 0.692763 validation: 0.753984
10/01 04:39:52 AM: edges-srl-ontonotes_precision: training: 0.854024 validation: 0.886294
10/01 04:39:52 AM: edges-srl-ontonotes_recall: training: 0.729753 validation: 0.776999
10/01 04:39:52 AM: edges-srl-ontonotes_f1: training: 0.787013 validation: 0.828056
10/01 04:39:52 AM: Global learning rate: 0.0001
10/01 04:39:52 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 04:39:55 AM: Update 3037: task edges-srl-ontonotes, batch 37 (3037): mcc: 0.8102, acc: 0.7248, precision: 0.8700, recall: 0.7595, f1: 0.8110, edges-srl-ontonotes_loss: 0.0162
10/01 04:40:05 AM: Update 3151: task edges-srl-ontonotes, batch 151 (3151): mcc: 0.8060, acc: 0.7195, precision: 0.8656, recall: 0.7556, f1: 0.8069, edges-srl-ontonotes_loss: 0.0166
10/01 04:40:15 AM: Update 3277: task edges-srl-ontonotes, batch 277 (3277): mcc: 0.8000, acc: 0.7121, precision: 0.8599, recall: 0.7495, f1: 0.8009, edges-srl-ontonotes_loss: 0.0170
10/01 04:40:25 AM: Update 3402: task edges-srl-ontonotes, batch 402 (3402): mcc: 0.7974, acc: 0.7080, precision: 0.8581, recall: 0.7462, f1: 0.7982, edges-srl-ontonotes_loss: 0.0171
10/01 04:40:35 AM: Update 3506: task edges-srl-ontonotes, batch 506 (3506): mcc: 0.7977, acc: 0.7083, precision: 0.8585, recall: 0.7464, f1: 0.7986, edges-srl-ontonotes_loss: 0.0171
10/01 04:40:46 AM: Update 3620: task edges-srl-ontonotes, batch 620 (3620): mcc: 0.7970, acc: 0.7073, precision: 0.8582, recall: 0.7454, f1: 0.7978, edges-srl-ontonotes_loss: 0.0171
10/01 04:40:56 AM: Update 3734: task edges-srl-ontonotes, batch 734 (3734): mcc: 0.7976, acc: 0.7081, precision: 0.8587, recall: 0.7462, f1: 0.7985, edges-srl-ontonotes_loss: 0.0170
10/01 04:41:06 AM: Update 3847: task edges-srl-ontonotes, batch 847 (3847): mcc: 0.7982, acc: 0.7089, precision: 0.8590, recall: 0.7468, f1: 0.7990, edges-srl-ontonotes_loss: 0.0169
10/01 04:41:16 AM: Update 3972: task edges-srl-ontonotes, batch 972 (3972): mcc: 0.7983, acc: 0.7094, precision: 0.8586, recall: 0.7474, f1: 0.7992, edges-srl-ontonotes_loss: 0.0169
10/01 04:41:18 AM: ***** Step 4000 / Validation 4 *****
10/01 04:41:18 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 04:41:18 AM: Validating...
10/01 04:41:26 AM: Evaluate: task edges-srl-ontonotes, batch 102 (157): mcc: 0.8219, acc: 0.7463, precision: 0.8928, recall: 0.7612, f1: 0.8218, edges-srl-ontonotes_loss: 0.0152
10/01 04:41:32 AM: Best result seen so far for edges-srl-ontonotes.
10/01 04:41:32 AM: Best result seen so far for macro.
10/01 04:41:32 AM: Updating LR scheduler:
10/01 04:41:32 AM: 	Best result seen so far for macro_avg: 0.829
10/01 04:41:32 AM: 	# validation passes without improvement: 0
10/01 04:41:32 AM: edges-srl-ontonotes_loss: training: 0.016890 validation: 0.014805
10/01 04:41:32 AM: macro_avg: validation: 0.828671
10/01 04:41:32 AM: micro_avg: validation: 0.000000
10/01 04:41:32 AM: edges-srl-ontonotes_mcc: training: 0.798206 validation: 0.828447
10/01 04:41:32 AM: edges-srl-ontonotes_acc: training: 0.709539 validation: 0.757447
10/01 04:41:32 AM: edges-srl-ontonotes_precision: training: 0.858542 validation: 0.893089
10/01 04:41:32 AM: edges-srl-ontonotes_recall: training: 0.747372 validation: 0.772920
10/01 04:41:32 AM: edges-srl-ontonotes_f1: training: 0.799109 validation: 0.828671
10/01 04:41:32 AM: Global learning rate: 0.0001
10/01 04:41:32 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 04:41:36 AM: Update 4053: task edges-srl-ontonotes, batch 53 (4053): mcc: 0.7947, acc: 0.7061, precision: 0.8538, recall: 0.7451, f1: 0.7958, edges-srl-ontonotes_loss: 0.0170
10/01 04:41:46 AM: Update 4163: task edges-srl-ontonotes, batch 163 (4163): mcc: 0.8011, acc: 0.7184, precision: 0.8574, recall: 0.7538, f1: 0.8023, edges-srl-ontonotes_loss: 0.0166
10/01 04:41:56 AM: Update 4275: task edges-srl-ontonotes, batch 275 (4275): mcc: 0.8041, acc: 0.7229, precision: 0.8600, recall: 0.7570, f1: 0.8052, edges-srl-ontonotes_loss: 0.0164
10/01 04:42:06 AM: Update 4384: task edges-srl-ontonotes, batch 384 (4384): mcc: 0.8080, acc: 0.7282, precision: 0.8625, recall: 0.7620, f1: 0.8091, edges-srl-ontonotes_loss: 0.0161
10/01 04:42:16 AM: Update 4509: task edges-srl-ontonotes, batch 509 (4509): mcc: 0.8111, acc: 0.7318, precision: 0.8652, recall: 0.7654, f1: 0.8122, edges-srl-ontonotes_loss: 0.0159
10/01 04:42:26 AM: Update 4621: task edges-srl-ontonotes, batch 621 (4621): mcc: 0.8126, acc: 0.7343, precision: 0.8661, recall: 0.7674, f1: 0.8138, edges-srl-ontonotes_loss: 0.0158
10/01 04:42:36 AM: Update 4721: task edges-srl-ontonotes, batch 721 (4721): mcc: 0.8116, acc: 0.7334, precision: 0.8653, recall: 0.7663, f1: 0.8128, edges-srl-ontonotes_loss: 0.0159
10/01 04:42:46 AM: Update 4829: task edges-srl-ontonotes, batch 829 (4829): mcc: 0.8091, acc: 0.7299, precision: 0.8636, recall: 0.7631, f1: 0.8103, edges-srl-ontonotes_loss: 0.0160
10/01 04:42:56 AM: Update 4939: task edges-srl-ontonotes, batch 939 (4939): mcc: 0.8075, acc: 0.7274, precision: 0.8628, recall: 0.7609, f1: 0.8086, edges-srl-ontonotes_loss: 0.0161
10/01 04:43:02 AM: ***** Step 5000 / Validation 5 *****
10/01 04:43:02 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 04:43:02 AM: Validating...
10/01 04:43:06 AM: Evaluate: task edges-srl-ontonotes, batch 63 (157): mcc: 0.8200, acc: 0.7474, precision: 0.8892, recall: 0.7608, f1: 0.8200, edges-srl-ontonotes_loss: 0.0152
10/01 04:43:13 AM: Best result seen so far for edges-srl-ontonotes.
10/01 04:43:13 AM: Best result seen so far for macro.
10/01 04:43:13 AM: Updating LR scheduler:
10/01 04:43:13 AM: 	Best result seen so far for macro_avg: 0.835
10/01 04:43:13 AM: 	# validation passes without improvement: 0
10/01 04:43:13 AM: edges-srl-ontonotes_loss: training: 0.016087 validation: 0.014090
10/01 04:43:13 AM: macro_avg: validation: 0.835274
10/01 04:43:13 AM: micro_avg: validation: 0.000000
10/01 04:43:13 AM: edges-srl-ontonotes_mcc: training: 0.807779 validation: 0.834976
10/01 04:43:13 AM: edges-srl-ontonotes_acc: training: 0.727817 validation: 0.766608
10/01 04:43:13 AM: edges-srl-ontonotes_precision: training: 0.862968 validation: 0.897348
10/01 04:43:13 AM: edges-srl-ontonotes_recall: training: 0.761205 validation: 0.781233
10/01 04:43:13 AM: edges-srl-ontonotes_f1: training: 0.808899 validation: 0.835274
10/01 04:43:13 AM: Global learning rate: 0.0001
10/01 04:43:13 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 04:43:17 AM: Update 5009: task edges-srl-ontonotes, batch 9 (5009): mcc: 0.7960, acc: 0.7092, precision: 0.8671, recall: 0.7359, f1: 0.7961, edges-srl-ontonotes_loss: 0.0175
10/01 04:43:27 AM: Update 5147: task edges-srl-ontonotes, batch 147 (5147): mcc: 0.8286, acc: 0.7534, precision: 0.8793, recall: 0.7854, f1: 0.8297, edges-srl-ontonotes_loss: 0.0145
10/01 04:43:37 AM: Update 5281: task edges-srl-ontonotes, batch 281 (5281): mcc: 0.8361, acc: 0.7637, precision: 0.8833, recall: 0.7959, f1: 0.8373, edges-srl-ontonotes_loss: 0.0140
10/01 04:43:47 AM: Update 5421: task edges-srl-ontonotes, batch 421 (5421): mcc: 0.8472, acc: 0.7789, precision: 0.8917, recall: 0.8091, f1: 0.8484, edges-srl-ontonotes_loss: 0.0133
10/01 04:43:57 AM: Update 5566: task edges-srl-ontonotes, batch 566 (5566): mcc: 0.8559, acc: 0.7907, precision: 0.8977, recall: 0.8200, f1: 0.8571, edges-srl-ontonotes_loss: 0.0127
10/01 04:44:07 AM: Update 5698: task edges-srl-ontonotes, batch 698 (5698): mcc: 0.8608, acc: 0.7973, precision: 0.9014, recall: 0.8259, f1: 0.8620, edges-srl-ontonotes_loss: 0.0123
10/01 04:44:17 AM: Update 5850: task edges-srl-ontonotes, batch 850 (5850): mcc: 0.8652, acc: 0.8032, precision: 0.9046, recall: 0.8313, f1: 0.8664, edges-srl-ontonotes_loss: 0.0120
10/01 04:44:27 AM: Update 5949: task edges-srl-ontonotes, batch 949 (5949): mcc: 0.8672, acc: 0.8058, precision: 0.9061, recall: 0.8336, f1: 0.8684, edges-srl-ontonotes_loss: 0.0119
10/01 04:44:30 AM: ***** Step 6000 / Validation 6 *****
10/01 04:44:30 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 04:44:30 AM: Validating...
10/01 04:44:37 AM: Evaluate: task edges-srl-ontonotes, batch 93 (157): mcc: 0.8477, acc: 0.7871, precision: 0.9055, recall: 0.7977, f1: 0.8482, edges-srl-ontonotes_loss: 0.0133
10/01 04:44:42 AM: Best result seen so far for edges-srl-ontonotes.
10/01 04:44:42 AM: Best result seen so far for macro.
10/01 04:44:42 AM: Updating LR scheduler:
10/01 04:44:42 AM: 	Best result seen so far for macro_avg: 0.854
10/01 04:44:42 AM: 	# validation passes without improvement: 0
10/01 04:44:42 AM: edges-srl-ontonotes_loss: training: 0.011866 validation: 0.013006
10/01 04:44:42 AM: macro_avg: validation: 0.853844
10/01 04:44:42 AM: micro_avg: validation: 0.000000
10/01 04:44:42 AM: edges-srl-ontonotes_mcc: training: 0.868209 validation: 0.853117
10/01 04:44:42 AM: edges-srl-ontonotes_acc: training: 0.807142 validation: 0.796551
10/01 04:44:42 AM: edges-srl-ontonotes_precision: training: 0.906868 validation: 0.904791
10/01 04:44:42 AM: edges-srl-ontonotes_recall: training: 0.834848 validation: 0.808329
10/01 04:44:42 AM: edges-srl-ontonotes_f1: training: 0.869369 validation: 0.853844
10/01 04:44:42 AM: Global learning rate: 0.0001
10/01 04:44:42 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 04:44:47 AM: Update 6076: task edges-srl-ontonotes, batch 76 (6076): mcc: 0.8824, acc: 0.8301, precision: 0.9130, recall: 0.8562, f1: 0.8837, edges-srl-ontonotes_loss: 0.0108
10/01 04:44:57 AM: Update 6215: task edges-srl-ontonotes, batch 215 (6215): mcc: 0.8851, acc: 0.8326, precision: 0.9159, recall: 0.8585, f1: 0.8863, edges-srl-ontonotes_loss: 0.0105
10/01 04:45:07 AM: Update 6353: task edges-srl-ontonotes, batch 353 (6353): mcc: 0.8836, acc: 0.8312, precision: 0.9143, recall: 0.8573, f1: 0.8849, edges-srl-ontonotes_loss: 0.0107
10/01 04:45:17 AM: Update 6499: task edges-srl-ontonotes, batch 499 (6499): mcc: 0.8831, acc: 0.8312, precision: 0.9135, recall: 0.8570, f1: 0.8844, edges-srl-ontonotes_loss: 0.0106
10/01 04:45:27 AM: Update 6621: task edges-srl-ontonotes, batch 621 (6621): mcc: 0.8795, acc: 0.8267, precision: 0.9108, recall: 0.8526, f1: 0.8808, edges-srl-ontonotes_loss: 0.0109
10/01 04:45:37 AM: Update 6743: task edges-srl-ontonotes, batch 743 (6743): mcc: 0.8744, acc: 0.8200, precision: 0.9070, recall: 0.8465, f1: 0.8757, edges-srl-ontonotes_loss: 0.0113
10/01 04:45:47 AM: Update 6856: task edges-srl-ontonotes, batch 856 (6856): mcc: 0.8710, acc: 0.8156, precision: 0.9045, recall: 0.8424, f1: 0.8723, edges-srl-ontonotes_loss: 0.0116
10/01 04:45:57 AM: Update 6966: task edges-srl-ontonotes, batch 966 (6966): mcc: 0.8664, acc: 0.8097, precision: 0.9012, recall: 0.8367, f1: 0.8677, edges-srl-ontonotes_loss: 0.0119
10/01 04:46:00 AM: ***** Step 7000 / Validation 7 *****
10/01 04:46:00 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 04:46:00 AM: Validating...
10/01 04:46:07 AM: Evaluate: task edges-srl-ontonotes, batch 96 (157): mcc: 0.8586, acc: 0.8036, precision: 0.9083, recall: 0.8154, f1: 0.8594, edges-srl-ontonotes_loss: 0.0123
10/01 04:46:14 AM: Best result seen so far for edges-srl-ontonotes.
10/01 04:46:14 AM: Best result seen so far for macro.
10/01 04:46:14 AM: Updating LR scheduler:
10/01 04:46:14 AM: 	Best result seen so far for macro_avg: 0.863
10/01 04:46:14 AM: 	# validation passes without improvement: 0
10/01 04:46:14 AM: edges-srl-ontonotes_loss: training: 0.012041 validation: 0.012120
10/01 04:46:14 AM: macro_avg: validation: 0.863239
10/01 04:46:14 AM: micro_avg: validation: 0.000000
10/01 04:46:14 AM: edges-srl-ontonotes_mcc: training: 0.864593 validation: 0.862255
10/01 04:46:14 AM: edges-srl-ontonotes_acc: training: 0.807352 validation: 0.811793
10/01 04:46:14 AM: edges-srl-ontonotes_precision: training: 0.899889 validation: 0.906642
10/01 04:46:14 AM: edges-srl-ontonotes_recall: training: 0.834463 validation: 0.823801
10/01 04:46:14 AM: edges-srl-ontonotes_f1: training: 0.865942 validation: 0.863239
10/01 04:46:14 AM: Global learning rate: 0.0001
10/01 04:46:14 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 04:46:17 AM: Update 7047: task edges-srl-ontonotes, batch 47 (7047): mcc: 0.8298, acc: 0.7628, precision: 0.8727, recall: 0.7937, f1: 0.8313, edges-srl-ontonotes_loss: 0.0144
10/01 04:46:27 AM: Update 7164: task edges-srl-ontonotes, batch 164 (7164): mcc: 0.8336, acc: 0.7678, precision: 0.8767, recall: 0.7971, f1: 0.8350, edges-srl-ontonotes_loss: 0.0143
10/01 04:46:37 AM: Update 7279: task edges-srl-ontonotes, batch 279 (7279): mcc: 0.8326, acc: 0.7663, precision: 0.8768, recall: 0.7951, f1: 0.8340, edges-srl-ontonotes_loss: 0.0143
10/01 04:46:48 AM: Update 7429: task edges-srl-ontonotes, batch 429 (7429): mcc: 0.8393, acc: 0.7746, precision: 0.8820, recall: 0.8030, f1: 0.8407, edges-srl-ontonotes_loss: 0.0138
10/01 04:46:58 AM: Update 7565: task edges-srl-ontonotes, batch 565 (7565): mcc: 0.8444, acc: 0.7813, precision: 0.8858, recall: 0.8092, f1: 0.8458, edges-srl-ontonotes_loss: 0.0135
10/01 04:47:08 AM: Update 7713: task edges-srl-ontonotes, batch 713 (7713): mcc: 0.8472, acc: 0.7854, precision: 0.8871, recall: 0.8133, f1: 0.8486, edges-srl-ontonotes_loss: 0.0132
10/01 04:47:18 AM: Update 7860: task edges-srl-ontonotes, batch 860 (7860): mcc: 0.8501, acc: 0.7887, precision: 0.8898, recall: 0.8163, f1: 0.8514, edges-srl-ontonotes_loss: 0.0130
10/01 04:47:28 AM: Update 7993: task edges-srl-ontonotes, batch 993 (7993): mcc: 0.8502, acc: 0.7891, precision: 0.8897, recall: 0.8166, f1: 0.8516, edges-srl-ontonotes_loss: 0.0130
10/01 04:47:28 AM: ***** Step 8000 / Validation 8 *****
10/01 04:47:28 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 04:47:28 AM: Validating...
10/01 04:47:38 AM: Evaluate: task edges-srl-ontonotes, batch 128 (157): mcc: 0.8758, acc: 0.8311, precision: 0.9162, recall: 0.8405, f1: 0.8768, edges-srl-ontonotes_loss: 0.0107
10/01 04:47:40 AM: Best result seen so far for edges-srl-ontonotes.
10/01 04:47:40 AM: Best result seen so far for macro.
10/01 04:47:40 AM: Updating LR scheduler:
10/01 04:47:40 AM: 	Best result seen so far for macro_avg: 0.872
10/01 04:47:40 AM: 	# validation passes without improvement: 0
10/01 04:47:40 AM: edges-srl-ontonotes_loss: training: 0.012965 validation: 0.011084
10/01 04:47:40 AM: macro_avg: validation: 0.872147
10/01 04:47:40 AM: micro_avg: validation: 0.000000
10/01 04:47:40 AM: edges-srl-ontonotes_mcc: training: 0.850098 validation: 0.871135
10/01 04:47:40 AM: edges-srl-ontonotes_acc: training: 0.788976 validation: 0.825802
10/01 04:47:40 AM: edges-srl-ontonotes_precision: training: 0.889597 validation: 0.912247
10/01 04:47:40 AM: edges-srl-ontonotes_recall: training: 0.816494 validation: 0.835425
10/01 04:47:40 AM: edges-srl-ontonotes_f1: training: 0.851480 validation: 0.872147
10/01 04:47:40 AM: Global learning rate: 0.0001
10/01 04:47:40 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 04:47:48 AM: Update 8115: task edges-srl-ontonotes, batch 115 (8115): mcc: 0.8419, acc: 0.7790, precision: 0.8834, recall: 0.8067, f1: 0.8433, edges-srl-ontonotes_loss: 0.0132
10/01 04:47:58 AM: Update 8218: task edges-srl-ontonotes, batch 218 (8218): mcc: 0.8403, acc: 0.7770, precision: 0.8808, recall: 0.8061, f1: 0.8418, edges-srl-ontonotes_loss: 0.0134
10/01 04:48:08 AM: Update 8363: task edges-srl-ontonotes, batch 363 (8363): mcc: 0.8374, acc: 0.7729, precision: 0.8798, recall: 0.8015, f1: 0.8388, edges-srl-ontonotes_loss: 0.0137
10/01 04:48:19 AM: Update 8499: task edges-srl-ontonotes, batch 499 (8499): mcc: 0.8370, acc: 0.7726, precision: 0.8796, recall: 0.8009, f1: 0.8384, edges-srl-ontonotes_loss: 0.0137
10/01 04:48:29 AM: Update 8629: task edges-srl-ontonotes, batch 629 (8629): mcc: 0.8355, acc: 0.7707, precision: 0.8783, recall: 0.7993, f1: 0.8369, edges-srl-ontonotes_loss: 0.0138
10/01 04:48:39 AM: Update 8766: task edges-srl-ontonotes, batch 766 (8766): mcc: 0.8368, acc: 0.7721, precision: 0.8793, recall: 0.8007, f1: 0.8382, edges-srl-ontonotes_loss: 0.0137
10/01 04:48:49 AM: Update 8886: task edges-srl-ontonotes, batch 886 (8886): mcc: 0.8352, acc: 0.7703, precision: 0.8776, recall: 0.7993, f1: 0.8366, edges-srl-ontonotes_loss: 0.0138
10/01 04:48:58 AM: ***** Step 9000 / Validation 9 *****
10/01 04:48:58 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 04:48:58 AM: Validating...
10/01 04:48:59 AM: Evaluate: task edges-srl-ontonotes, batch 16 (157): mcc: 0.8715, acc: 0.8161, precision: 0.9247, recall: 0.8248, f1: 0.8719, edges-srl-ontonotes_loss: 0.0107
10/01 04:49:09 AM: Evaluate: task edges-srl-ontonotes, batch 152 (157): mcc: 0.8727, acc: 0.8248, precision: 0.9186, recall: 0.8326, f1: 0.8735, edges-srl-ontonotes_loss: 0.0109
10/01 04:49:09 AM: Best result seen so far for edges-srl-ontonotes.
10/01 04:49:09 AM: Best result seen so far for macro.
10/01 04:49:09 AM: Updating LR scheduler:
10/01 04:49:09 AM: 	Best result seen so far for macro_avg: 0.873
10/01 04:49:09 AM: 	# validation passes without improvement: 0
10/01 04:49:09 AM: edges-srl-ontonotes_loss: training: 0.013976 validation: 0.010971
10/01 04:49:09 AM: macro_avg: validation: 0.872921
10/01 04:49:09 AM: micro_avg: validation: 0.000000
10/01 04:49:09 AM: edges-srl-ontonotes_mcc: training: 0.832174 validation: 0.872135
10/01 04:49:09 AM: edges-srl-ontonotes_acc: training: 0.766553 validation: 0.824340
10/01 04:49:09 AM: edges-srl-ontonotes_precision: training: 0.875461 validation: 0.917749
10/01 04:49:09 AM: edges-srl-ontonotes_recall: training: 0.795617 validation: 0.832268
10/01 04:49:09 AM: edges-srl-ontonotes_f1: training: 0.833631 validation: 0.872921
10/01 04:49:09 AM: Global learning rate: 0.0001
10/01 04:49:09 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 04:49:21 AM: Update 9125: task edges-srl-ontonotes, batch 125 (9125): mcc: 0.8235, acc: 0.7534, precision: 0.8710, recall: 0.7835, f1: 0.8249, edges-srl-ontonotes_loss: 0.0148
10/01 04:49:31 AM: Update 9255: task edges-srl-ontonotes, batch 255 (9255): mcc: 0.8210, acc: 0.7506, precision: 0.8695, recall: 0.7800, f1: 0.8223, edges-srl-ontonotes_loss: 0.0149
10/01 04:49:41 AM: Update 9371: task edges-srl-ontonotes, batch 371 (9371): mcc: 0.8230, acc: 0.7538, precision: 0.8706, recall: 0.7828, f1: 0.8244, edges-srl-ontonotes_loss: 0.0147
10/01 04:49:51 AM: Update 9479: task edges-srl-ontonotes, batch 479 (9479): mcc: 0.8247, acc: 0.7558, precision: 0.8719, recall: 0.7847, f1: 0.8260, edges-srl-ontonotes_loss: 0.0146
10/01 04:50:01 AM: Update 9600: task edges-srl-ontonotes, batch 600 (9600): mcc: 0.8296, acc: 0.7622, precision: 0.8752, recall: 0.7910, f1: 0.8310, edges-srl-ontonotes_loss: 0.0142
10/01 04:50:11 AM: Update 9720: task edges-srl-ontonotes, batch 720 (9720): mcc: 0.8316, acc: 0.7653, precision: 0.8767, recall: 0.7934, f1: 0.8330, edges-srl-ontonotes_loss: 0.0141
10/01 04:50:22 AM: Update 9836: task edges-srl-ontonotes, batch 836 (9836): mcc: 0.8331, acc: 0.7677, precision: 0.8777, recall: 0.7953, f1: 0.8344, edges-srl-ontonotes_loss: 0.0140
10/01 04:50:32 AM: Update 9960: task edges-srl-ontonotes, batch 960 (9960): mcc: 0.8351, acc: 0.7701, precision: 0.8794, recall: 0.7975, f1: 0.8364, edges-srl-ontonotes_loss: 0.0138
10/01 04:50:35 AM: ***** Step 10000 / Validation 10 *****
10/01 04:50:35 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 04:50:35 AM: Validating...
10/01 04:50:42 AM: Evaluate: task edges-srl-ontonotes, batch 91 (157): mcc: 0.8647, acc: 0.8168, precision: 0.9090, recall: 0.8262, f1: 0.8656, edges-srl-ontonotes_loss: 0.0113
10/01 04:50:47 AM: Updating LR scheduler:
10/01 04:50:47 AM: 	Best result seen so far for macro_avg: 0.873
10/01 04:50:47 AM: 	# validation passes without improvement: 1
10/01 04:50:47 AM: edges-srl-ontonotes_loss: training: 0.013788 validation: 0.011025
10/01 04:50:47 AM: macro_avg: validation: 0.870065
10/01 04:50:47 AM: micro_avg: validation: 0.000000
10/01 04:50:47 AM: edges-srl-ontonotes_mcc: training: 0.835335 validation: 0.869004
10/01 04:50:47 AM: edges-srl-ontonotes_acc: training: 0.770349 validation: 0.825264
10/01 04:50:47 AM: edges-srl-ontonotes_precision: training: 0.879644 validation: 0.909709
10/01 04:50:47 AM: edges-srl-ontonotes_recall: training: 0.797750 validation: 0.833731
10/01 04:50:47 AM: edges-srl-ontonotes_f1: training: 0.836698 validation: 0.870065
10/01 04:50:47 AM: Global learning rate: 0.0001
10/01 04:50:47 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 04:50:52 AM: Update 10062: task edges-srl-ontonotes, batch 62 (10062): mcc: 0.8479, acc: 0.7862, precision: 0.8903, recall: 0.8117, f1: 0.8492, edges-srl-ontonotes_loss: 0.0133
10/01 04:51:02 AM: Update 10150: task edges-srl-ontonotes, batch 150 (10150): mcc: 0.8546, acc: 0.7961, precision: 0.8951, recall: 0.8199, f1: 0.8559, edges-srl-ontonotes_loss: 0.0127
10/01 04:51:12 AM: Update 10274: task edges-srl-ontonotes, batch 274 (10274): mcc: 0.8521, acc: 0.7928, precision: 0.8918, recall: 0.8183, f1: 0.8534, edges-srl-ontonotes_loss: 0.0127
10/01 04:51:22 AM: Update 10381: task edges-srl-ontonotes, batch 381 (10381): mcc: 0.8527, acc: 0.7944, precision: 0.8916, recall: 0.8196, f1: 0.8541, edges-srl-ontonotes_loss: 0.0126
10/01 04:51:32 AM: Update 10505: task edges-srl-ontonotes, batch 505 (10505): mcc: 0.8480, acc: 0.7887, precision: 0.8882, recall: 0.8137, f1: 0.8493, edges-srl-ontonotes_loss: 0.0129
10/01 04:51:42 AM: Update 10631: task edges-srl-ontonotes, batch 631 (10631): mcc: 0.8464, acc: 0.7862, precision: 0.8875, recall: 0.8114, f1: 0.8477, edges-srl-ontonotes_loss: 0.0130
10/01 04:51:52 AM: Update 10738: task edges-srl-ontonotes, batch 738 (10738): mcc: 0.8455, acc: 0.7847, precision: 0.8874, recall: 0.8098, f1: 0.8468, edges-srl-ontonotes_loss: 0.0130
10/01 04:52:02 AM: Update 10852: task edges-srl-ontonotes, batch 852 (10852): mcc: 0.8449, acc: 0.7838, precision: 0.8874, recall: 0.8086, f1: 0.8462, edges-srl-ontonotes_loss: 0.0130
10/01 04:52:12 AM: Update 10965: task edges-srl-ontonotes, batch 965 (10965): mcc: 0.8446, acc: 0.7831, precision: 0.8874, recall: 0.8082, f1: 0.8460, edges-srl-ontonotes_loss: 0.0131
10/01 04:52:15 AM: ***** Step 11000 / Validation 11 *****
10/01 04:52:15 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 04:52:15 AM: Validating...
10/01 04:52:22 AM: Evaluate: task edges-srl-ontonotes, batch 95 (157): mcc: 0.8594, acc: 0.8119, precision: 0.9047, recall: 0.8202, f1: 0.8604, edges-srl-ontonotes_loss: 0.0118
10/01 04:52:27 AM: Updating LR scheduler:
10/01 04:52:27 AM: 	Best result seen so far for macro_avg: 0.873
10/01 04:52:27 AM: 	# validation passes without improvement: 2
10/01 04:52:27 AM: edges-srl-ontonotes_loss: training: 0.013061 validation: 0.011503
10/01 04:52:27 AM: macro_avg: validation: 0.865588
10/01 04:52:27 AM: micro_avg: validation: 0.000000
10/01 04:52:27 AM: edges-srl-ontonotes_mcc: training: 0.844625 validation: 0.864450
10/01 04:52:27 AM: edges-srl-ontonotes_acc: training: 0.783170 validation: 0.819490
10/01 04:52:27 AM: edges-srl-ontonotes_precision: training: 0.887356 validation: 0.904870
10/01 04:52:27 AM: edges-srl-ontonotes_recall: training: 0.808208 validation: 0.829574
10/01 04:52:27 AM: edges-srl-ontonotes_f1: training: 0.845935 validation: 0.865588
10/01 04:52:27 AM: Global learning rate: 0.0001
10/01 04:52:27 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 04:52:32 AM: Update 11055: task edges-srl-ontonotes, batch 55 (11055): mcc: 0.8436, acc: 0.7806, precision: 0.8862, recall: 0.8074, f1: 0.8449, edges-srl-ontonotes_loss: 0.0129
10/01 04:52:42 AM: Update 11169: task edges-srl-ontonotes, batch 169 (11169): mcc: 0.8409, acc: 0.7783, precision: 0.8837, recall: 0.8045, f1: 0.8423, edges-srl-ontonotes_loss: 0.0133
10/01 04:52:52 AM: Update 11283: task edges-srl-ontonotes, batch 283 (11283): mcc: 0.8415, acc: 0.7784, precision: 0.8855, recall: 0.8039, f1: 0.8427, edges-srl-ontonotes_loss: 0.0132
10/01 04:53:02 AM: Update 11367: task edges-srl-ontonotes, batch 367 (11367): mcc: 0.8418, acc: 0.7792, precision: 0.8856, recall: 0.8046, f1: 0.8431, edges-srl-ontonotes_loss: 0.0133
10/01 04:53:12 AM: Update 11492: task edges-srl-ontonotes, batch 492 (11492): mcc: 0.8430, acc: 0.7819, precision: 0.8854, recall: 0.8069, f1: 0.8444, edges-srl-ontonotes_loss: 0.0131
10/01 04:53:22 AM: Update 11619: task edges-srl-ontonotes, batch 619 (11619): mcc: 0.8444, acc: 0.7841, precision: 0.8860, recall: 0.8091, f1: 0.8458, edges-srl-ontonotes_loss: 0.0130
10/01 04:53:32 AM: Update 11731: task edges-srl-ontonotes, batch 731 (11731): mcc: 0.8464, acc: 0.7864, precision: 0.8879, recall: 0.8110, f1: 0.8477, edges-srl-ontonotes_loss: 0.0129
10/01 04:53:42 AM: Update 11856: task edges-srl-ontonotes, batch 856 (11856): mcc: 0.8481, acc: 0.7886, precision: 0.8891, recall: 0.8131, f1: 0.8494, edges-srl-ontonotes_loss: 0.0128
10/01 04:53:53 AM: Update 11959: task edges-srl-ontonotes, batch 959 (11959): mcc: 0.8475, acc: 0.7877, precision: 0.8890, recall: 0.8122, f1: 0.8488, edges-srl-ontonotes_loss: 0.0128
10/01 04:53:56 AM: ***** Step 12000 / Validation 12 *****
10/01 04:53:56 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 04:53:56 AM: Validating...
10/01 04:54:03 AM: Evaluate: task edges-srl-ontonotes, batch 85 (157): mcc: 0.8615, acc: 0.8125, precision: 0.9095, recall: 0.8197, f1: 0.8623, edges-srl-ontonotes_loss: 0.0118
10/01 04:54:08 AM: Updating LR scheduler:
10/01 04:54:08 AM: 	Best result seen so far for macro_avg: 0.873
10/01 04:54:08 AM: 	# validation passes without improvement: 3
10/01 04:54:08 AM: edges-srl-ontonotes_loss: training: 0.012892 validation: 0.011201
10/01 04:54:08 AM: macro_avg: validation: 0.871333
10/01 04:54:08 AM: micro_avg: validation: 0.000000
10/01 04:54:08 AM: edges-srl-ontonotes_mcc: training: 0.846274 validation: 0.870380
10/01 04:54:08 AM: edges-srl-ontonotes_acc: training: 0.786108 validation: 0.825956
10/01 04:54:08 AM: edges-srl-ontonotes_precision: training: 0.888075 validation: 0.913040
10/01 04:54:08 AM: edges-srl-ontonotes_recall: training: 0.810663 validation: 0.833269
10/01 04:54:08 AM: edges-srl-ontonotes_f1: training: 0.847605 validation: 0.871333
10/01 04:54:08 AM: Global learning rate: 0.0001
10/01 04:54:08 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 04:54:13 AM: Update 12049: task edges-srl-ontonotes, batch 49 (12049): mcc: 0.8321, acc: 0.7660, precision: 0.8819, recall: 0.7897, f1: 0.8332, edges-srl-ontonotes_loss: 0.0142
10/01 04:54:23 AM: Update 12155: task edges-srl-ontonotes, batch 155 (12155): mcc: 0.8303, acc: 0.7649, precision: 0.8784, recall: 0.7894, f1: 0.8315, edges-srl-ontonotes_loss: 0.0140
10/01 04:54:35 AM: Update 12255: task edges-srl-ontonotes, batch 255 (12255): mcc: 0.8334, acc: 0.7676, precision: 0.8811, recall: 0.7927, f1: 0.8346, edges-srl-ontonotes_loss: 0.0139
10/01 04:54:45 AM: Update 12385: task edges-srl-ontonotes, batch 385 (12385): mcc: 0.8435, acc: 0.7817, precision: 0.8868, recall: 0.8065, f1: 0.8448, edges-srl-ontonotes_loss: 0.0131
10/01 04:54:55 AM: Update 12512: task edges-srl-ontonotes, batch 512 (12512): mcc: 0.8511, acc: 0.7917, precision: 0.8927, recall: 0.8155, f1: 0.8523, edges-srl-ontonotes_loss: 0.0125
10/01 04:55:05 AM: Update 12641: task edges-srl-ontonotes, batch 641 (12641): mcc: 0.8591, acc: 0.8021, precision: 0.8982, recall: 0.8256, f1: 0.8603, edges-srl-ontonotes_loss: 0.0119
10/01 04:55:15 AM: Update 12782: task edges-srl-ontonotes, batch 782 (12782): mcc: 0.8684, acc: 0.8143, precision: 0.9048, recall: 0.8371, f1: 0.8697, edges-srl-ontonotes_loss: 0.0113
10/01 04:55:25 AM: Update 12912: task edges-srl-ontonotes, batch 912 (12912): mcc: 0.8744, acc: 0.8222, precision: 0.9093, recall: 0.8443, f1: 0.8756, edges-srl-ontonotes_loss: 0.0108
10/01 04:55:30 AM: ***** Step 13000 / Validation 13 *****
10/01 04:55:30 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 04:55:30 AM: Validating...
10/01 04:55:35 AM: Evaluate: task edges-srl-ontonotes, batch 61 (157): mcc: 0.8654, acc: 0.8195, precision: 0.9082, recall: 0.8283, f1: 0.8664, edges-srl-ontonotes_loss: 0.0117
10/01 04:55:42 AM: Best result seen so far for edges-srl-ontonotes.
10/01 04:55:42 AM: Best result seen so far for macro.
10/01 04:55:42 AM: Updating LR scheduler:
10/01 04:55:42 AM: 	Best result seen so far for macro_avg: 0.876
10/01 04:55:42 AM: 	# validation passes without improvement: 0
10/01 04:55:42 AM: edges-srl-ontonotes_loss: training: 0.010635 validation: 0.010992
10/01 04:55:42 AM: macro_avg: validation: 0.875946
10/01 04:55:42 AM: micro_avg: validation: 0.000000
10/01 04:55:42 AM: edges-srl-ontonotes_mcc: training: 0.877539 validation: 0.874838
10/01 04:55:42 AM: edges-srl-ontonotes_acc: training: 0.826317 validation: 0.832345
10/01 04:55:42 AM: edges-srl-ontonotes_precision: training: 0.911834 validation: 0.912510
10/01 04:55:42 AM: edges-srl-ontonotes_recall: training: 0.847966 validation: 0.842198
10/01 04:55:42 AM: edges-srl-ontonotes_f1: training: 0.878741 validation: 0.875946
10/01 04:55:42 AM: Global learning rate: 0.0001
10/01 04:55:42 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 04:55:45 AM: Update 13043: task edges-srl-ontonotes, batch 43 (13043): mcc: 0.9038, acc: 0.8625, precision: 0.9297, recall: 0.8813, f1: 0.9049, edges-srl-ontonotes_loss: 0.0089
10/01 04:55:55 AM: Update 13194: task edges-srl-ontonotes, batch 194 (13194): mcc: 0.9085, acc: 0.8688, precision: 0.9345, recall: 0.8858, f1: 0.9095, edges-srl-ontonotes_loss: 0.0084
10/01 04:56:06 AM: Update 13352: task edges-srl-ontonotes, batch 352 (13352): mcc: 0.9069, acc: 0.8667, precision: 0.9330, recall: 0.8842, f1: 0.9080, edges-srl-ontonotes_loss: 0.0086
10/01 04:56:18 AM: Update 13507: task edges-srl-ontonotes, batch 507 (13507): mcc: 0.9077, acc: 0.8683, precision: 0.9332, recall: 0.8856, f1: 0.9088, edges-srl-ontonotes_loss: 0.0085
10/01 04:56:28 AM: Update 13653: task edges-srl-ontonotes, batch 653 (13653): mcc: 0.9063, acc: 0.8668, precision: 0.9313, recall: 0.8847, f1: 0.9074, edges-srl-ontonotes_loss: 0.0087
10/01 04:56:38 AM: Update 13796: task edges-srl-ontonotes, batch 796 (13796): mcc: 0.9059, acc: 0.8666, precision: 0.9304, recall: 0.8847, f1: 0.9070, edges-srl-ontonotes_loss: 0.0087
10/01 04:56:48 AM: Update 13912: task edges-srl-ontonotes, batch 912 (13912): mcc: 0.9017, acc: 0.8609, precision: 0.9270, recall: 0.8799, f1: 0.9028, edges-srl-ontonotes_loss: 0.0090
10/01 04:56:55 AM: ***** Step 14000 / Validation 14 *****
10/01 04:56:55 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 04:56:55 AM: Validating...
10/01 04:56:58 AM: Evaluate: task edges-srl-ontonotes, batch 43 (157): mcc: 0.8635, acc: 0.8180, precision: 0.9058, recall: 0.8269, f1: 0.8645, edges-srl-ontonotes_loss: 0.0115
10/01 04:57:06 AM: Best result seen so far for edges-srl-ontonotes.
10/01 04:57:06 AM: Best result seen so far for macro.
10/01 04:57:06 AM: Updating LR scheduler:
10/01 04:57:06 AM: 	Best result seen so far for macro_avg: 0.878
10/01 04:57:06 AM: 	# validation passes without improvement: 0
10/01 04:57:06 AM: edges-srl-ontonotes_loss: training: 0.009227 validation: 0.010509
10/01 04:57:06 AM: macro_avg: validation: 0.878481
10/01 04:57:06 AM: micro_avg: validation: 0.000000
10/01 04:57:06 AM: edges-srl-ontonotes_mcc: training: 0.898492 validation: 0.877448
10/01 04:57:06 AM: edges-srl-ontonotes_acc: training: 0.856890 validation: 0.836348
10/01 04:57:06 AM: edges-srl-ontonotes_precision: training: 0.924500 validation: 0.916026
10/01 04:57:06 AM: edges-srl-ontonotes_recall: training: 0.876119 validation: 0.843892
10/01 04:57:06 AM: edges-srl-ontonotes_f1: training: 0.899660 validation: 0.878481
10/01 04:57:06 AM: Global learning rate: 0.0001
10/01 04:57:06 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 04:57:08 AM: Update 14022: task edges-srl-ontonotes, batch 22 (14022): mcc: 0.8690, acc: 0.8175, precision: 0.8977, recall: 0.8449, f1: 0.8705, edges-srl-ontonotes_loss: 0.0112
10/01 04:57:18 AM: Update 14144: task edges-srl-ontonotes, batch 144 (14144): mcc: 0.8720, acc: 0.8226, precision: 0.9046, recall: 0.8441, f1: 0.8733, edges-srl-ontonotes_loss: 0.0112
10/01 04:57:28 AM: Update 14276: task edges-srl-ontonotes, batch 276 (14276): mcc: 0.8607, acc: 0.8077, precision: 0.8960, recall: 0.8306, f1: 0.8621, edges-srl-ontonotes_loss: 0.0120
10/01 04:57:38 AM: Update 14410: task edges-srl-ontonotes, batch 410 (14410): mcc: 0.8571, acc: 0.8026, precision: 0.8929, recall: 0.8267, f1: 0.8585, edges-srl-ontonotes_loss: 0.0122
10/01 04:57:48 AM: Update 14517: task edges-srl-ontonotes, batch 517 (14517): mcc: 0.8573, acc: 0.8030, precision: 0.8938, recall: 0.8263, f1: 0.8587, edges-srl-ontonotes_loss: 0.0122
10/01 04:57:58 AM: Update 14670: task edges-srl-ontonotes, batch 670 (14670): mcc: 0.8623, acc: 0.8098, precision: 0.8977, recall: 0.8322, f1: 0.8637, edges-srl-ontonotes_loss: 0.0118
10/01 04:58:08 AM: Update 14806: task edges-srl-ontonotes, batch 806 (14806): mcc: 0.8642, acc: 0.8115, precision: 0.8991, recall: 0.8344, f1: 0.8656, edges-srl-ontonotes_loss: 0.0117
10/01 04:58:18 AM: Update 14948: task edges-srl-ontonotes, batch 948 (14948): mcc: 0.8660, acc: 0.8138, precision: 0.9008, recall: 0.8363, f1: 0.8674, edges-srl-ontonotes_loss: 0.0115
10/01 04:58:22 AM: ***** Step 15000 / Validation 15 *****
10/01 04:58:22 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 04:58:22 AM: Validating...
10/01 04:58:28 AM: Evaluate: task edges-srl-ontonotes, batch 88 (157): mcc: 0.8848, acc: 0.8455, precision: 0.9199, recall: 0.8542, f1: 0.8858, edges-srl-ontonotes_loss: 0.0098
10/01 04:58:34 AM: Best result seen so far for edges-srl-ontonotes.
10/01 04:58:34 AM: Best result seen so far for macro.
10/01 04:58:34 AM: Updating LR scheduler:
10/01 04:58:34 AM: 	Best result seen so far for macro_avg: 0.888
10/01 04:58:34 AM: 	# validation passes without improvement: 0
10/01 04:58:34 AM: edges-srl-ontonotes_loss: training: 0.011493 validation: 0.009785
10/01 04:58:34 AM: macro_avg: validation: 0.887899
10/01 04:58:34 AM: micro_avg: validation: 0.000000
10/01 04:58:34 AM: edges-srl-ontonotes_mcc: training: 0.866806 validation: 0.886736
10/01 04:58:34 AM: edges-srl-ontonotes_acc: training: 0.814848 validation: 0.851513
10/01 04:58:34 AM: edges-srl-ontonotes_precision: training: 0.901237 validation: 0.918394
10/01 04:58:34 AM: edges-srl-ontonotes_recall: training: 0.837420 validation: 0.859364
10/01 04:58:34 AM: edges-srl-ontonotes_f1: training: 0.868157 validation: 0.887899
10/01 04:58:34 AM: Global learning rate: 0.0001
10/01 04:58:34 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 04:58:38 AM: Update 15066: task edges-srl-ontonotes, batch 66 (15066): mcc: 0.8786, acc: 0.8298, precision: 0.9109, recall: 0.8508, f1: 0.8798, edges-srl-ontonotes_loss: 0.0105
10/01 04:58:49 AM: Update 15191: task edges-srl-ontonotes, batch 191 (15191): mcc: 0.8717, acc: 0.8216, precision: 0.9045, recall: 0.8437, f1: 0.8730, edges-srl-ontonotes_loss: 0.0110
10/01 04:58:59 AM: Update 15327: task edges-srl-ontonotes, batch 327 (15327): mcc: 0.8687, acc: 0.8182, precision: 0.9016, recall: 0.8408, f1: 0.8701, edges-srl-ontonotes_loss: 0.0112
10/01 04:59:09 AM: Update 15432: task edges-srl-ontonotes, batch 432 (15432): mcc: 0.8681, acc: 0.8173, precision: 0.9010, recall: 0.8401, f1: 0.8695, edges-srl-ontonotes_loss: 0.0112
10/01 04:59:19 AM: Update 15561: task edges-srl-ontonotes, batch 561 (15561): mcc: 0.8637, acc: 0.8113, precision: 0.8976, recall: 0.8349, f1: 0.8651, edges-srl-ontonotes_loss: 0.0115
10/01 04:59:29 AM: Update 15697: task edges-srl-ontonotes, batch 697 (15697): mcc: 0.8625, acc: 0.8094, precision: 0.8973, recall: 0.8329, f1: 0.8639, edges-srl-ontonotes_loss: 0.0116
10/01 04:59:39 AM: Update 15818: task edges-srl-ontonotes, batch 818 (15818): mcc: 0.8613, acc: 0.8080, precision: 0.8961, recall: 0.8317, f1: 0.8627, edges-srl-ontonotes_loss: 0.0117
10/01 04:59:49 AM: Update 15942: task edges-srl-ontonotes, batch 942 (15942): mcc: 0.8611, acc: 0.8077, precision: 0.8962, recall: 0.8312, f1: 0.8625, edges-srl-ontonotes_loss: 0.0117
10/01 04:59:55 AM: ***** Step 16000 / Validation 16 *****
10/01 04:59:55 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 04:59:55 AM: Validating...
10/01 05:00:00 AM: Evaluate: task edges-srl-ontonotes, batch 67 (157): mcc: 0.8750, acc: 0.8336, precision: 0.9137, recall: 0.8414, f1: 0.8760, edges-srl-ontonotes_loss: 0.0105
10/01 05:00:06 AM: Best result seen so far for edges-srl-ontonotes.
10/01 05:00:06 AM: Best result seen so far for macro.
10/01 05:00:06 AM: Updating LR scheduler:
10/01 05:00:06 AM: 	Best result seen so far for macro_avg: 0.888
10/01 05:00:06 AM: 	# validation passes without improvement: 0
10/01 05:00:06 AM: edges-srl-ontonotes_loss: training: 0.011762 validation: 0.009637
10/01 05:00:06 AM: macro_avg: validation: 0.888499
10/01 05:00:06 AM: micro_avg: validation: 0.000000
10/01 05:00:06 AM: edges-srl-ontonotes_mcc: training: 0.860573 validation: 0.887456
10/01 05:00:06 AM: edges-srl-ontonotes_acc: training: 0.807024 validation: 0.850358
10/01 05:00:06 AM: edges-srl-ontonotes_precision: training: 0.895757 validation: 0.922160
10/01 05:00:06 AM: edges-srl-ontonotes_recall: training: 0.830668 validation: 0.857209
10/01 05:00:06 AM: edges-srl-ontonotes_f1: training: 0.861986 validation: 0.888499
10/01 05:00:06 AM: Global learning rate: 0.0001
10/01 05:00:06 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:00:10 AM: Update 16044: task edges-srl-ontonotes, batch 44 (16044): mcc: 0.8618, acc: 0.8079, precision: 0.8949, recall: 0.8339, f1: 0.8633, edges-srl-ontonotes_loss: 0.0113
10/01 05:00:20 AM: Update 16156: task edges-srl-ontonotes, batch 156 (16156): mcc: 0.8419, acc: 0.7840, precision: 0.8789, recall: 0.8109, f1: 0.8435, edges-srl-ontonotes_loss: 0.0131
10/01 05:00:30 AM: Update 16276: task edges-srl-ontonotes, batch 276 (16276): mcc: 0.8403, acc: 0.7827, precision: 0.8779, recall: 0.8087, f1: 0.8419, edges-srl-ontonotes_loss: 0.0132
10/01 05:00:41 AM: Update 16371: task edges-srl-ontonotes, batch 371 (16371): mcc: 0.8397, acc: 0.7811, precision: 0.8785, recall: 0.8071, f1: 0.8413, edges-srl-ontonotes_loss: 0.0133
10/01 05:00:51 AM: Update 16491: task edges-srl-ontonotes, batch 491 (16491): mcc: 0.8394, acc: 0.7801, precision: 0.8791, recall: 0.8059, f1: 0.8409, edges-srl-ontonotes_loss: 0.0133
10/01 05:01:01 AM: Update 16605: task edges-srl-ontonotes, batch 605 (16605): mcc: 0.8392, acc: 0.7798, precision: 0.8795, recall: 0.8051, f1: 0.8407, edges-srl-ontonotes_loss: 0.0133
10/01 05:01:11 AM: Update 16708: task edges-srl-ontonotes, batch 708 (16708): mcc: 0.8401, acc: 0.7809, precision: 0.8802, recall: 0.8062, f1: 0.8416, edges-srl-ontonotes_loss: 0.0132
10/01 05:01:21 AM: Update 16825: task edges-srl-ontonotes, batch 825 (16825): mcc: 0.8432, acc: 0.7847, precision: 0.8832, recall: 0.8095, f1: 0.8447, edges-srl-ontonotes_loss: 0.0129
10/01 05:01:31 AM: Update 16949: task edges-srl-ontonotes, batch 949 (16949): mcc: 0.8464, acc: 0.7885, precision: 0.8858, recall: 0.8130, f1: 0.8478, edges-srl-ontonotes_loss: 0.0127
10/01 05:01:37 AM: ***** Step 17000 / Validation 17 *****
10/01 05:01:37 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:01:37 AM: Validating...
10/01 05:01:41 AM: Evaluate: task edges-srl-ontonotes, batch 65 (157): mcc: 0.8746, acc: 0.8321, precision: 0.9148, recall: 0.8396, f1: 0.8756, edges-srl-ontonotes_loss: 0.0106
10/01 05:01:48 AM: Updating LR scheduler:
10/01 05:01:48 AM: 	Best result seen so far for macro_avg: 0.888
10/01 05:01:48 AM: 	# validation passes without improvement: 1
10/01 05:01:48 AM: edges-srl-ontonotes_loss: training: 0.012661 validation: 0.009743
10/01 05:01:48 AM: macro_avg: validation: 0.887646
10/01 05:01:48 AM: micro_avg: validation: 0.000000
10/01 05:01:48 AM: edges-srl-ontonotes_mcc: training: 0.847070 validation: 0.886648
10/01 05:01:48 AM: edges-srl-ontonotes_acc: training: 0.789356 validation: 0.848511
10/01 05:01:48 AM: edges-srl-ontonotes_precision: training: 0.886481 validation: 0.922821
10/01 05:01:48 AM: edges-srl-ontonotes_recall: training: 0.813636 validation: 0.855053
10/01 05:01:48 AM: edges-srl-ontonotes_f1: training: 0.848498 validation: 0.887646
10/01 05:01:48 AM: Global learning rate: 0.0001
10/01 05:01:48 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:01:51 AM: Update 17039: task edges-srl-ontonotes, batch 39 (17039): mcc: 0.8566, acc: 0.8048, precision: 0.8950, recall: 0.8239, f1: 0.8580, edges-srl-ontonotes_loss: 0.0121
10/01 05:02:01 AM: Update 17165: task edges-srl-ontonotes, batch 165 (17165): mcc: 0.8594, acc: 0.8062, precision: 0.8948, recall: 0.8293, f1: 0.8608, edges-srl-ontonotes_loss: 0.0118
10/01 05:02:11 AM: Update 17276: task edges-srl-ontonotes, batch 276 (17276): mcc: 0.8594, acc: 0.8064, precision: 0.8949, recall: 0.8293, f1: 0.8608, edges-srl-ontonotes_loss: 0.0117
10/01 05:02:22 AM: Update 17387: task edges-srl-ontonotes, batch 387 (17387): mcc: 0.8604, acc: 0.8079, precision: 0.8958, recall: 0.8303, f1: 0.8618, edges-srl-ontonotes_loss: 0.0116
10/01 05:02:32 AM: Update 17507: task edges-srl-ontonotes, batch 507 (17507): mcc: 0.8634, acc: 0.8114, precision: 0.8985, recall: 0.8334, f1: 0.8647, edges-srl-ontonotes_loss: 0.0115
10/01 05:02:42 AM: Update 17620: task edges-srl-ontonotes, batch 620 (17620): mcc: 0.8650, acc: 0.8134, precision: 0.9000, recall: 0.8353, f1: 0.8664, edges-srl-ontonotes_loss: 0.0114
10/01 05:02:52 AM: Update 17706: task edges-srl-ontonotes, batch 706 (17706): mcc: 0.8637, acc: 0.8116, precision: 0.8990, recall: 0.8335, f1: 0.8651, edges-srl-ontonotes_loss: 0.0115
10/01 05:03:02 AM: Update 17821: task edges-srl-ontonotes, batch 821 (17821): mcc: 0.8627, acc: 0.8103, precision: 0.8986, recall: 0.8321, f1: 0.8641, edges-srl-ontonotes_loss: 0.0116
10/01 05:03:12 AM: Update 17934: task edges-srl-ontonotes, batch 934 (17934): mcc: 0.8621, acc: 0.8094, precision: 0.8982, recall: 0.8313, f1: 0.8635, edges-srl-ontonotes_loss: 0.0116
10/01 05:03:18 AM: ***** Step 18000 / Validation 18 *****
10/01 05:03:18 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:03:18 AM: Validating...
10/01 05:03:22 AM: Evaluate: task edges-srl-ontonotes, batch 57 (157): mcc: 0.8712, acc: 0.8295, precision: 0.9107, recall: 0.8370, f1: 0.8723, edges-srl-ontonotes_loss: 0.0109
10/01 05:03:29 AM: Updating LR scheduler:
10/01 05:03:29 AM: 	Best result seen so far for macro_avg: 0.888
10/01 05:03:29 AM: 	# validation passes without improvement: 2
10/01 05:03:29 AM: edges-srl-ontonotes_loss: training: 0.011659 validation: 0.009979
10/01 05:03:29 AM: macro_avg: validation: 0.884423
10/01 05:03:29 AM: micro_avg: validation: 0.000000
10/01 05:03:29 AM: edges-srl-ontonotes_mcc: training: 0.861297 validation: 0.883371
10/01 05:03:29 AM: edges-srl-ontonotes_acc: training: 0.808147 validation: 0.844508
10/01 05:03:29 AM: edges-srl-ontonotes_precision: training: 0.897885 validation: 0.919352
10/01 05:03:29 AM: edges-srl-ontonotes_recall: training: 0.830062 validation: 0.852051
10/01 05:03:29 AM: edges-srl-ontonotes_f1: training: 0.862642 validation: 0.884423
10/01 05:03:29 AM: Global learning rate: 0.0001
10/01 05:03:29 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:03:32 AM: Update 18033: task edges-srl-ontonotes, batch 33 (18033): mcc: 0.8529, acc: 0.7976, precision: 0.8890, recall: 0.8224, f1: 0.8544, edges-srl-ontonotes_loss: 0.0123
10/01 05:03:42 AM: Update 18156: task edges-srl-ontonotes, batch 156 (18156): mcc: 0.8635, acc: 0.8072, precision: 0.9019, recall: 0.8304, f1: 0.8647, edges-srl-ontonotes_loss: 0.0116
10/01 05:03:52 AM: Update 18264: task edges-srl-ontonotes, batch 264 (18264): mcc: 0.8621, acc: 0.8073, precision: 0.8997, recall: 0.8300, f1: 0.8634, edges-srl-ontonotes_loss: 0.0117
10/01 05:04:02 AM: Update 18387: task edges-srl-ontonotes, batch 387 (18387): mcc: 0.8608, acc: 0.8052, precision: 0.8990, recall: 0.8281, f1: 0.8621, edges-srl-ontonotes_loss: 0.0118
10/01 05:04:12 AM: Update 18503: task edges-srl-ontonotes, batch 503 (18503): mcc: 0.8599, acc: 0.8051, precision: 0.8979, recall: 0.8274, f1: 0.8612, edges-srl-ontonotes_loss: 0.0118
10/01 05:04:22 AM: Update 18584: task edges-srl-ontonotes, batch 584 (18584): mcc: 0.8599, acc: 0.8048, precision: 0.8979, recall: 0.8273, f1: 0.8612, edges-srl-ontonotes_loss: 0.0118
10/01 05:04:32 AM: Update 18701: task edges-srl-ontonotes, batch 701 (18701): mcc: 0.8608, acc: 0.8063, precision: 0.8981, recall: 0.8288, f1: 0.8621, edges-srl-ontonotes_loss: 0.0118
10/01 05:04:42 AM: Update 18816: task edges-srl-ontonotes, batch 816 (18816): mcc: 0.8611, acc: 0.8070, precision: 0.8981, recall: 0.8295, f1: 0.8624, edges-srl-ontonotes_loss: 0.0117
10/01 05:04:52 AM: Update 18923: task edges-srl-ontonotes, batch 923 (18923): mcc: 0.8618, acc: 0.8080, precision: 0.8987, recall: 0.8303, f1: 0.8632, edges-srl-ontonotes_loss: 0.0117
10/01 05:04:58 AM: ***** Step 19000 / Validation 19 *****
10/01 05:04:58 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:04:58 AM: Validating...
10/01 05:05:02 AM: Evaluate: task edges-srl-ontonotes, batch 50 (157): mcc: 0.8708, acc: 0.8288, precision: 0.9099, recall: 0.8370, f1: 0.8719, edges-srl-ontonotes_loss: 0.0108
10/01 05:05:10 AM: Updating LR scheduler:
10/01 05:05:10 AM: 	Best result seen so far for macro_avg: 0.888
10/01 05:05:10 AM: 	# validation passes without improvement: 3
10/01 05:05:10 AM: edges-srl-ontonotes_loss: training: 0.011623 validation: 0.010064
10/01 05:05:10 AM: macro_avg: validation: 0.881773
10/01 05:05:10 AM: micro_avg: validation: 0.000000
10/01 05:05:10 AM: edges-srl-ontonotes_mcc: training: 0.862622 validation: 0.880658
10/01 05:05:10 AM: edges-srl-ontonotes_acc: training: 0.809150 validation: 0.842429
10/01 05:05:10 AM: edges-srl-ontonotes_precision: training: 0.899580 validation: 0.916044
10/01 05:05:10 AM: edges-srl-ontonotes_recall: training: 0.831005 validation: 0.849973
10/01 05:05:10 AM: edges-srl-ontonotes_f1: training: 0.863934 validation: 0.881773
10/01 05:05:10 AM: Global learning rate: 0.0001
10/01 05:05:10 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:05:12 AM: Update 19027: task edges-srl-ontonotes, batch 27 (19027): mcc: 0.8643, acc: 0.8157, precision: 0.8986, recall: 0.8351, f1: 0.8657, edges-srl-ontonotes_loss: 0.0113
10/01 05:05:22 AM: Update 19139: task edges-srl-ontonotes, batch 139 (19139): mcc: 0.8639, acc: 0.8121, precision: 0.8995, recall: 0.8335, f1: 0.8652, edges-srl-ontonotes_loss: 0.0113
10/01 05:05:32 AM: Update 19240: task edges-srl-ontonotes, batch 240 (19240): mcc: 0.8583, acc: 0.8045, precision: 0.8958, recall: 0.8263, f1: 0.8596, edges-srl-ontonotes_loss: 0.0117
10/01 05:05:42 AM: Update 19350: task edges-srl-ontonotes, batch 350 (19350): mcc: 0.8540, acc: 0.7981, precision: 0.8928, recall: 0.8209, f1: 0.8553, edges-srl-ontonotes_loss: 0.0121
10/01 05:05:52 AM: Update 19457: task edges-srl-ontonotes, batch 457 (19457): mcc: 0.8521, acc: 0.7956, precision: 0.8916, recall: 0.8184, f1: 0.8534, edges-srl-ontonotes_loss: 0.0122
10/01 05:06:02 AM: Update 19573: task edges-srl-ontonotes, batch 573 (19573): mcc: 0.8563, acc: 0.8010, precision: 0.8945, recall: 0.8237, f1: 0.8576, edges-srl-ontonotes_loss: 0.0120
10/01 05:06:12 AM: Update 19696: task edges-srl-ontonotes, batch 696 (19696): mcc: 0.8614, acc: 0.8074, precision: 0.8985, recall: 0.8297, f1: 0.8628, edges-srl-ontonotes_loss: 0.0116
10/01 05:06:24 AM: Update 19814: task edges-srl-ontonotes, batch 814 (19814): mcc: 0.8651, acc: 0.8123, precision: 0.9007, recall: 0.8347, f1: 0.8664, edges-srl-ontonotes_loss: 0.0113
10/01 05:06:34 AM: Update 19973: task edges-srl-ontonotes, batch 973 (19973): mcc: 0.8732, acc: 0.8231, precision: 0.9066, recall: 0.8446, f1: 0.8745, edges-srl-ontonotes_loss: 0.0107
10/01 05:06:36 AM: ***** Step 20000 / Validation 20 *****
10/01 05:06:36 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:06:36 AM: Validating...
10/01 05:06:44 AM: Evaluate: task edges-srl-ontonotes, batch 114 (157): mcc: 0.8837, acc: 0.8442, precision: 0.9200, recall: 0.8521, f1: 0.8848, edges-srl-ontonotes_loss: 0.0100
10/01 05:06:47 AM: Updating LR scheduler:
10/01 05:06:47 AM: 	Best result seen so far for macro_avg: 0.888
10/01 05:06:47 AM: 	# validation passes without improvement: 0
10/01 05:06:47 AM: edges-srl-ontonotes_loss: training: 0.010613 validation: 0.009925
10/01 05:06:47 AM: macro_avg: validation: 0.886382
10/01 05:06:47 AM: micro_avg: validation: 0.000000
10/01 05:06:47 AM: edges-srl-ontonotes_mcc: training: 0.874720 validation: 0.885282
10/01 05:06:47 AM: edges-srl-ontonotes_acc: training: 0.825064 validation: 0.848126
10/01 05:06:47 AM: edges-srl-ontonotes_precision: training: 0.907667 validation: 0.919292
10/01 05:06:47 AM: edges-srl-ontonotes_recall: training: 0.846491 validation: 0.855746
10/01 05:06:47 AM: edges-srl-ontonotes_f1: training: 0.876012 validation: 0.886382
10/01 05:06:47 AM: Global learning rate: 5e-05
10/01 05:06:47 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:06:54 AM: Update 20106: task edges-srl-ontonotes, batch 106 (20106): mcc: 0.9216, acc: 0.8871, precision: 0.9420, recall: 0.9040, f1: 0.9226, edges-srl-ontonotes_loss: 0.0069
10/01 05:07:04 AM: Update 20250: task edges-srl-ontonotes, batch 250 (20250): mcc: 0.9174, acc: 0.8822, precision: 0.9402, recall: 0.8974, f1: 0.9183, edges-srl-ontonotes_loss: 0.0073
10/01 05:07:14 AM: Update 20402: task edges-srl-ontonotes, batch 402 (20402): mcc: 0.9166, acc: 0.8815, precision: 0.9395, recall: 0.8966, f1: 0.9176, edges-srl-ontonotes_loss: 0.0075
10/01 05:07:24 AM: Update 20541: task edges-srl-ontonotes, batch 541 (20541): mcc: 0.9163, acc: 0.8807, precision: 0.9388, recall: 0.8967, f1: 0.9173, edges-srl-ontonotes_loss: 0.0075
10/01 05:07:34 AM: Update 20679: task edges-srl-ontonotes, batch 679 (20679): mcc: 0.9155, acc: 0.8797, precision: 0.9382, recall: 0.8958, f1: 0.9165, edges-srl-ontonotes_loss: 0.0076
10/01 05:07:44 AM: Update 20785: task edges-srl-ontonotes, batch 785 (20785): mcc: 0.9142, acc: 0.8783, precision: 0.9371, recall: 0.8944, f1: 0.9152, edges-srl-ontonotes_loss: 0.0077
10/01 05:07:54 AM: Update 20927: task edges-srl-ontonotes, batch 927 (20927): mcc: 0.9125, acc: 0.8765, precision: 0.9351, recall: 0.8929, f1: 0.9135, edges-srl-ontonotes_loss: 0.0079
10/01 05:07:59 AM: ***** Step 21000 / Validation 21 *****
10/01 05:07:59 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:07:59 AM: Validating...
10/01 05:08:04 AM: Evaluate: task edges-srl-ontonotes, batch 68 (157): mcc: 0.8810, acc: 0.8402, precision: 0.9205, recall: 0.8465, f1: 0.8820, edges-srl-ontonotes_loss: 0.0103
10/01 05:08:11 AM: Best result seen so far for edges-srl-ontonotes.
10/01 05:08:11 AM: Best result seen so far for macro.
10/01 05:08:11 AM: Updating LR scheduler:
10/01 05:08:11 AM: 	Best result seen so far for macro_avg: 0.890
10/01 05:08:11 AM: 	# validation passes without improvement: 0
10/01 05:08:11 AM: edges-srl-ontonotes_loss: training: 0.007872 validation: 0.009625
10/01 05:08:11 AM: macro_avg: validation: 0.889830
10/01 05:08:11 AM: micro_avg: validation: 0.000000
10/01 05:08:11 AM: edges-srl-ontonotes_mcc: training: 0.912394 validation: 0.888857
10/01 05:08:11 AM: edges-srl-ontonotes_acc: training: 0.876516 validation: 0.851359
10/01 05:08:11 AM: edges-srl-ontonotes_precision: training: 0.934916 validation: 0.924853
10/01 05:08:11 AM: edges-srl-ontonotes_recall: training: 0.892940 validation: 0.857363
10/01 05:08:11 AM: edges-srl-ontonotes_f1: training: 0.913446 validation: 0.889830
10/01 05:08:11 AM: Global learning rate: 5e-05
10/01 05:08:11 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:08:14 AM: Update 21049: task edges-srl-ontonotes, batch 49 (21049): mcc: 0.9111, acc: 0.8743, precision: 0.9325, recall: 0.8928, f1: 0.9122, edges-srl-ontonotes_loss: 0.0083
10/01 05:08:24 AM: Update 21165: task edges-srl-ontonotes, batch 165 (21165): mcc: 0.8904, acc: 0.8468, precision: 0.9158, recall: 0.8688, f1: 0.8917, edges-srl-ontonotes_loss: 0.0097
10/01 05:08:34 AM: Update 21284: task edges-srl-ontonotes, batch 284 (21284): mcc: 0.8869, acc: 0.8422, precision: 0.9135, recall: 0.8643, f1: 0.8882, edges-srl-ontonotes_loss: 0.0099
10/01 05:08:45 AM: Update 21390: task edges-srl-ontonotes, batch 390 (21390): mcc: 0.8822, acc: 0.8363, precision: 0.9103, recall: 0.8583, f1: 0.8835, edges-srl-ontonotes_loss: 0.0103
10/01 05:08:55 AM: Update 21501: task edges-srl-ontonotes, batch 501 (21501): mcc: 0.8778, acc: 0.8304, precision: 0.9073, recall: 0.8528, f1: 0.8792, edges-srl-ontonotes_loss: 0.0106
10/01 05:09:05 AM: Update 21620: task edges-srl-ontonotes, batch 620 (21620): mcc: 0.8747, acc: 0.8269, precision: 0.9047, recall: 0.8494, f1: 0.8761, edges-srl-ontonotes_loss: 0.0108
10/01 05:09:15 AM: Update 21736: task edges-srl-ontonotes, batch 736 (21736): mcc: 0.8721, acc: 0.8233, precision: 0.9035, recall: 0.8453, f1: 0.8735, edges-srl-ontonotes_loss: 0.0110
10/01 05:09:25 AM: Update 21844: task edges-srl-ontonotes, batch 844 (21844): mcc: 0.8737, acc: 0.8251, precision: 0.9050, recall: 0.8469, f1: 0.8750, edges-srl-ontonotes_loss: 0.0109
10/01 05:09:35 AM: Update 21986: task edges-srl-ontonotes, batch 986 (21986): mcc: 0.8746, acc: 0.8265, precision: 0.9060, recall: 0.8479, f1: 0.8760, edges-srl-ontonotes_loss: 0.0108
10/01 05:09:36 AM: ***** Step 22000 / Validation 22 *****
10/01 05:09:36 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:09:36 AM: Validating...
10/01 05:09:45 AM: Evaluate: task edges-srl-ontonotes, batch 121 (157): mcc: 0.8965, acc: 0.8641, precision: 0.9246, recall: 0.8722, f1: 0.8976, edges-srl-ontonotes_loss: 0.0089
10/01 05:09:47 AM: Best result seen so far for edges-srl-ontonotes.
10/01 05:09:47 AM: Best result seen so far for macro.
10/01 05:09:47 AM: Updating LR scheduler:
10/01 05:09:47 AM: 	Best result seen so far for macro_avg: 0.895
10/01 05:09:47 AM: 	# validation passes without improvement: 0
10/01 05:09:47 AM: edges-srl-ontonotes_loss: training: 0.010779 validation: 0.009196
10/01 05:09:47 AM: macro_avg: validation: 0.895281
10/01 05:09:47 AM: micro_avg: validation: 0.000000
10/01 05:09:47 AM: edges-srl-ontonotes_mcc: training: 0.874708 validation: 0.894117
10/01 05:09:47 AM: edges-srl-ontonotes_acc: training: 0.826485 validation: 0.861673
10/01 05:09:47 AM: edges-srl-ontonotes_precision: training: 0.906024 validation: 0.922436
10/01 05:09:47 AM: edges-srl-ontonotes_recall: training: 0.848011 validation: 0.869679
10/01 05:09:47 AM: edges-srl-ontonotes_f1: training: 0.876058 validation: 0.895281
10/01 05:09:47 AM: Global learning rate: 5e-05
10/01 05:09:47 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:09:55 AM: Update 22089: task edges-srl-ontonotes, batch 89 (22089): mcc: 0.8772, acc: 0.8300, precision: 0.9071, recall: 0.8517, f1: 0.8785, edges-srl-ontonotes_loss: 0.0104
10/01 05:10:05 AM: Update 22220: task edges-srl-ontonotes, batch 220 (22220): mcc: 0.8815, acc: 0.8355, precision: 0.9106, recall: 0.8568, f1: 0.8829, edges-srl-ontonotes_loss: 0.0101
10/01 05:10:15 AM: Update 22343: task edges-srl-ontonotes, batch 343 (22343): mcc: 0.8835, acc: 0.8372, precision: 0.9129, recall: 0.8583, f1: 0.8848, edges-srl-ontonotes_loss: 0.0101
10/01 05:10:25 AM: Update 22459: task edges-srl-ontonotes, batch 459 (22459): mcc: 0.8811, acc: 0.8348, precision: 0.9105, recall: 0.8560, f1: 0.8824, edges-srl-ontonotes_loss: 0.0102
10/01 05:10:35 AM: Update 22582: task edges-srl-ontonotes, batch 582 (22582): mcc: 0.8802, acc: 0.8344, precision: 0.9094, recall: 0.8553, f1: 0.8816, edges-srl-ontonotes_loss: 0.0103
10/01 05:10:46 AM: Update 22678: task edges-srl-ontonotes, batch 678 (22678): mcc: 0.8798, acc: 0.8341, precision: 0.9086, recall: 0.8554, f1: 0.8812, edges-srl-ontonotes_loss: 0.0103
10/01 05:10:56 AM: Update 22809: task edges-srl-ontonotes, batch 809 (22809): mcc: 0.8772, acc: 0.8306, precision: 0.9066, recall: 0.8522, f1: 0.8786, edges-srl-ontonotes_loss: 0.0106
10/01 05:11:06 AM: Update 22948: task edges-srl-ontonotes, batch 948 (22948): mcc: 0.8749, acc: 0.8274, precision: 0.9052, recall: 0.8492, f1: 0.8763, edges-srl-ontonotes_loss: 0.0107
10/01 05:11:10 AM: ***** Step 23000 / Validation 23 *****
10/01 05:11:10 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:11:10 AM: Validating...
10/01 05:11:16 AM: Evaluate: task edges-srl-ontonotes, batch 73 (157): mcc: 0.8902, acc: 0.8541, precision: 0.9249, recall: 0.8598, f1: 0.8912, edges-srl-ontonotes_loss: 0.0093
10/01 05:11:22 AM: Best result seen so far for edges-srl-ontonotes.
10/01 05:11:22 AM: Best result seen so far for macro.
10/01 05:11:22 AM: Updating LR scheduler:
10/01 05:11:22 AM: 	Best result seen so far for macro_avg: 0.896
10/01 05:11:22 AM: 	# validation passes without improvement: 0
10/01 05:11:22 AM: edges-srl-ontonotes_loss: training: 0.010740 validation: 0.008923
10/01 05:11:22 AM: macro_avg: validation: 0.895869
10/01 05:11:22 AM: micro_avg: validation: 0.000000
10/01 05:11:22 AM: edges-srl-ontonotes_mcc: training: 0.874378 validation: 0.894824
10/01 05:11:22 AM: edges-srl-ontonotes_acc: training: 0.826644 validation: 0.860981
10/01 05:11:22 AM: edges-srl-ontonotes_precision: training: 0.904887 validation: 0.926480
10/01 05:11:22 AM: edges-srl-ontonotes_recall: training: 0.848450 validation: 0.867216
10/01 05:11:22 AM: edges-srl-ontonotes_f1: training: 0.875760 validation: 0.895869
10/01 05:11:22 AM: Global learning rate: 5e-05
10/01 05:11:22 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:11:26 AM: Update 23047: task edges-srl-ontonotes, batch 47 (23047): mcc: 0.8778, acc: 0.8277, precision: 0.9115, recall: 0.8489, f1: 0.8791, edges-srl-ontonotes_loss: 0.0105
10/01 05:11:36 AM: Update 23169: task edges-srl-ontonotes, batch 169 (23169): mcc: 0.8704, acc: 0.8202, precision: 0.9023, recall: 0.8432, f1: 0.8718, edges-srl-ontonotes_loss: 0.0109
10/01 05:11:46 AM: Update 23286: task edges-srl-ontonotes, batch 286 (23286): mcc: 0.8677, acc: 0.8175, precision: 0.8997, recall: 0.8406, f1: 0.8692, edges-srl-ontonotes_loss: 0.0111
10/01 05:11:56 AM: Update 23392: task edges-srl-ontonotes, batch 392 (23392): mcc: 0.8609, acc: 0.8096, precision: 0.8941, recall: 0.8328, f1: 0.8623, edges-srl-ontonotes_loss: 0.0115
10/01 05:12:06 AM: Update 23507: task edges-srl-ontonotes, batch 507 (23507): mcc: 0.8564, acc: 0.8035, precision: 0.8907, recall: 0.8275, f1: 0.8579, edges-srl-ontonotes_loss: 0.0119
10/01 05:12:17 AM: Update 23617: task edges-srl-ontonotes, batch 617 (23617): mcc: 0.8552, acc: 0.8016, precision: 0.8903, recall: 0.8255, f1: 0.8567, edges-srl-ontonotes_loss: 0.0120
10/01 05:12:27 AM: Update 23732: task edges-srl-ontonotes, batch 732 (23732): mcc: 0.8539, acc: 0.7999, precision: 0.8897, recall: 0.8236, f1: 0.8554, edges-srl-ontonotes_loss: 0.0120
10/01 05:12:37 AM: Update 23846: task edges-srl-ontonotes, batch 846 (23846): mcc: 0.8532, acc: 0.7988, precision: 0.8893, recall: 0.8226, f1: 0.8546, edges-srl-ontonotes_loss: 0.0121
10/01 05:12:47 AM: Update 23931: task edges-srl-ontonotes, batch 931 (23931): mcc: 0.8525, acc: 0.7980, precision: 0.8888, recall: 0.8217, f1: 0.8540, edges-srl-ontonotes_loss: 0.0121
10/01 05:12:53 AM: ***** Step 24000 / Validation 24 *****
10/01 05:12:53 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:12:53 AM: Validating...
10/01 05:12:57 AM: Evaluate: task edges-srl-ontonotes, batch 57 (157): mcc: 0.8812, acc: 0.8429, precision: 0.9178, recall: 0.8494, f1: 0.8823, edges-srl-ontonotes_loss: 0.0100
10/01 05:13:04 AM: Updating LR scheduler:
10/01 05:13:04 AM: 	Best result seen so far for macro_avg: 0.896
10/01 05:13:04 AM: 	# validation passes without improvement: 1
10/01 05:13:04 AM: edges-srl-ontonotes_loss: training: 0.012004 validation: 0.009099
10/01 05:13:04 AM: macro_avg: validation: 0.893883
10/01 05:13:04 AM: micro_avg: validation: 0.000000
10/01 05:13:04 AM: edges-srl-ontonotes_mcc: training: 0.853878 validation: 0.892884
10/01 05:13:04 AM: edges-srl-ontonotes_acc: training: 0.799613 validation: 0.857055
10/01 05:13:04 AM: edges-srl-ontonotes_precision: training: 0.890151 validation: 0.926636
10/01 05:13:04 AM: edges-srl-ontonotes_recall: training: 0.823155 validation: 0.863367
10/01 05:13:04 AM: edges-srl-ontonotes_f1: training: 0.855343 validation: 0.893883
10/01 05:13:04 AM: Global learning rate: 5e-05
10/01 05:13:04 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:13:07 AM: Update 24032: task edges-srl-ontonotes, batch 32 (24032): mcc: 0.8783, acc: 0.8307, precision: 0.9101, recall: 0.8510, f1: 0.8795, edges-srl-ontonotes_loss: 0.0106
10/01 05:13:17 AM: Update 24149: task edges-srl-ontonotes, batch 149 (24149): mcc: 0.8712, acc: 0.8213, precision: 0.9044, recall: 0.8428, f1: 0.8725, edges-srl-ontonotes_loss: 0.0109
10/01 05:13:27 AM: Update 24260: task edges-srl-ontonotes, batch 260 (24260): mcc: 0.8707, acc: 0.8206, precision: 0.9043, recall: 0.8421, f1: 0.8721, edges-srl-ontonotes_loss: 0.0108
10/01 05:13:37 AM: Update 24387: task edges-srl-ontonotes, batch 387 (24387): mcc: 0.8719, acc: 0.8219, precision: 0.9050, recall: 0.8436, f1: 0.8732, edges-srl-ontonotes_loss: 0.0108
10/01 05:13:47 AM: Update 24510: task edges-srl-ontonotes, batch 510 (24510): mcc: 0.8711, acc: 0.8206, precision: 0.9044, recall: 0.8426, f1: 0.8724, edges-srl-ontonotes_loss: 0.0108
10/01 05:13:57 AM: Update 24626: task edges-srl-ontonotes, batch 626 (24626): mcc: 0.8716, acc: 0.8215, precision: 0.9045, recall: 0.8435, f1: 0.8729, edges-srl-ontonotes_loss: 0.0108
10/01 05:14:07 AM: Update 24751: task edges-srl-ontonotes, batch 751 (24751): mcc: 0.8725, acc: 0.8231, precision: 0.9051, recall: 0.8447, f1: 0.8739, edges-srl-ontonotes_loss: 0.0107
10/01 05:14:19 AM: Update 24869: task edges-srl-ontonotes, batch 869 (24869): mcc: 0.8742, acc: 0.8250, precision: 0.9065, recall: 0.8465, f1: 0.8755, edges-srl-ontonotes_loss: 0.0106
10/01 05:14:29 AM: Update 24991: task edges-srl-ontonotes, batch 991 (24991): mcc: 0.8725, acc: 0.8226, precision: 0.9053, recall: 0.8444, f1: 0.8738, edges-srl-ontonotes_loss: 0.0108
10/01 05:14:30 AM: ***** Step 25000 / Validation 25 *****
10/01 05:14:30 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:14:30 AM: Validating...
10/01 05:14:39 AM: Evaluate: task edges-srl-ontonotes, batch 128 (157): mcc: 0.8927, acc: 0.8583, precision: 0.9245, recall: 0.8650, f1: 0.8938, edges-srl-ontonotes_loss: 0.0091
10/01 05:14:41 AM: Updating LR scheduler:
10/01 05:14:41 AM: 	Best result seen so far for macro_avg: 0.896
10/01 05:14:41 AM: 	# validation passes without improvement: 2
10/01 05:14:41 AM: edges-srl-ontonotes_loss: training: 0.010777 validation: 0.009279
10/01 05:14:41 AM: macro_avg: validation: 0.891983
10/01 05:14:41 AM: micro_avg: validation: 0.000000
10/01 05:14:41 AM: edges-srl-ontonotes_mcc: training: 0.872170 validation: 0.890899
10/01 05:14:41 AM: edges-srl-ontonotes_acc: training: 0.822262 validation: 0.855977
10/01 05:14:41 AM: edges-srl-ontonotes_precision: training: 0.905138 validation: 0.923090
10/01 05:14:41 AM: edges-srl-ontonotes_recall: training: 0.843996 validation: 0.862905
10/01 05:14:41 AM: edges-srl-ontonotes_f1: training: 0.873498 validation: 0.891983
10/01 05:14:41 AM: Global learning rate: 5e-05
10/01 05:14:41 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:14:49 AM: Update 25099: task edges-srl-ontonotes, batch 99 (25099): mcc: 0.8640, acc: 0.8123, precision: 0.8982, recall: 0.8350, f1: 0.8654, edges-srl-ontonotes_loss: 0.0113
10/01 05:14:59 AM: Update 25217: task edges-srl-ontonotes, batch 217 (25217): mcc: 0.8634, acc: 0.8111, precision: 0.8989, recall: 0.8332, f1: 0.8648, edges-srl-ontonotes_loss: 0.0113
10/01 05:15:09 AM: Update 25347: task edges-srl-ontonotes, batch 347 (25347): mcc: 0.8642, acc: 0.8117, precision: 0.8988, recall: 0.8347, f1: 0.8656, edges-srl-ontonotes_loss: 0.0112
10/01 05:15:19 AM: Update 25473: task edges-srl-ontonotes, batch 473 (25473): mcc: 0.8649, acc: 0.8127, precision: 0.8995, recall: 0.8354, f1: 0.8663, edges-srl-ontonotes_loss: 0.0112
10/01 05:15:29 AM: Update 25590: task edges-srl-ontonotes, batch 590 (25590): mcc: 0.8647, acc: 0.8117, precision: 0.8996, recall: 0.8349, f1: 0.8660, edges-srl-ontonotes_loss: 0.0113
10/01 05:15:39 AM: Update 25716: task edges-srl-ontonotes, batch 716 (25716): mcc: 0.8645, acc: 0.8121, precision: 0.8993, recall: 0.8349, f1: 0.8659, edges-srl-ontonotes_loss: 0.0113
10/01 05:15:50 AM: Update 25808: task edges-srl-ontonotes, batch 808 (25808): mcc: 0.8643, acc: 0.8118, precision: 0.8993, recall: 0.8345, f1: 0.8657, edges-srl-ontonotes_loss: 0.0113
10/01 05:16:00 AM: Update 25935: task edges-srl-ontonotes, batch 935 (25935): mcc: 0.8653, acc: 0.8132, precision: 0.9000, recall: 0.8357, f1: 0.8667, edges-srl-ontonotes_loss: 0.0112
10/01 05:16:06 AM: ***** Step 26000 / Validation 26 *****
10/01 05:16:06 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:16:06 AM: Validating...
10/01 05:16:10 AM: Evaluate: task edges-srl-ontonotes, batch 66 (157): mcc: 0.8781, acc: 0.8392, precision: 0.9132, recall: 0.8477, f1: 0.8792, edges-srl-ontonotes_loss: 0.0103
10/01 05:16:17 AM: Updating LR scheduler:
10/01 05:16:17 AM: 	Best result seen so far for macro_avg: 0.896
10/01 05:16:17 AM: 	# validation passes without improvement: 3
10/01 05:16:17 AM: edges-srl-ontonotes_loss: training: 0.011204 validation: 0.009440
10/01 05:16:17 AM: macro_avg: validation: 0.890816
10/01 05:16:17 AM: micro_avg: validation: 0.000000
10/01 05:16:17 AM: edges-srl-ontonotes_mcc: training: 0.865586 validation: 0.889706
10/01 05:16:17 AM: edges-srl-ontonotes_acc: training: 0.813761 validation: 0.853283
10/01 05:16:17 AM: edges-srl-ontonotes_precision: training: 0.900054 validation: 0.921646
10/01 05:16:17 AM: edges-srl-ontonotes_recall: training: 0.836201 validation: 0.861981
10/01 05:16:17 AM: edges-srl-ontonotes_f1: training: 0.866954 validation: 0.890816
10/01 05:16:17 AM: Global learning rate: 5e-05
10/01 05:16:17 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:16:20 AM: Update 26041: task edges-srl-ontonotes, batch 41 (26041): mcc: 0.8697, acc: 0.8193, precision: 0.9012, recall: 0.8430, f1: 0.8712, edges-srl-ontonotes_loss: 0.0115
10/01 05:16:30 AM: Update 26152: task edges-srl-ontonotes, batch 152 (26152): mcc: 0.8737, acc: 0.8263, precision: 0.9054, recall: 0.8466, f1: 0.8750, edges-srl-ontonotes_loss: 0.0110
10/01 05:16:41 AM: Update 26269: task edges-srl-ontonotes, batch 269 (26269): mcc: 0.8737, acc: 0.8245, precision: 0.9063, recall: 0.8458, f1: 0.8750, edges-srl-ontonotes_loss: 0.0108
10/01 05:16:51 AM: Update 26386: task edges-srl-ontonotes, batch 386 (26386): mcc: 0.8736, acc: 0.8240, precision: 0.9063, recall: 0.8456, f1: 0.8749, edges-srl-ontonotes_loss: 0.0108
10/01 05:17:01 AM: Update 26480: task edges-srl-ontonotes, batch 480 (26480): mcc: 0.8696, acc: 0.8186, precision: 0.9037, recall: 0.8404, f1: 0.8709, edges-srl-ontonotes_loss: 0.0111
10/01 05:17:11 AM: Update 26594: task edges-srl-ontonotes, batch 594 (26594): mcc: 0.8664, acc: 0.8141, precision: 0.9018, recall: 0.8361, f1: 0.8677, edges-srl-ontonotes_loss: 0.0113
10/01 05:17:21 AM: Update 26705: task edges-srl-ontonotes, batch 705 (26705): mcc: 0.8648, acc: 0.8119, precision: 0.9007, recall: 0.8341, f1: 0.8661, edges-srl-ontonotes_loss: 0.0114
10/01 05:17:31 AM: Update 26819: task edges-srl-ontonotes, batch 819 (26819): mcc: 0.8659, acc: 0.8134, precision: 0.9013, recall: 0.8357, f1: 0.8673, edges-srl-ontonotes_loss: 0.0113
10/01 05:17:41 AM: Update 26962: task edges-srl-ontonotes, batch 962 (26962): mcc: 0.8702, acc: 0.8191, precision: 0.9043, recall: 0.8411, f1: 0.8716, edges-srl-ontonotes_loss: 0.0109
10/01 05:17:44 AM: ***** Step 27000 / Validation 27 *****
10/01 05:17:44 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:17:44 AM: Validating...
10/01 05:17:51 AM: Evaluate: task edges-srl-ontonotes, batch 98 (157): mcc: 0.8888, acc: 0.8501, precision: 0.9252, recall: 0.8570, f1: 0.8898, edges-srl-ontonotes_loss: 0.0094
10/01 05:17:55 AM: Updating LR scheduler:
10/01 05:17:55 AM: 	Best result seen so far for macro_avg: 0.896
10/01 05:17:55 AM: 	# validation passes without improvement: 0
10/01 05:17:55 AM: edges-srl-ontonotes_loss: training: 0.010842 validation: 0.009299
10/01 05:17:55 AM: macro_avg: validation: 0.893517
10/01 05:17:55 AM: micro_avg: validation: 0.000000
10/01 05:17:55 AM: edges-srl-ontonotes_mcc: training: 0.871379 validation: 0.892488
10/01 05:17:55 AM: edges-srl-ontonotes_acc: training: 0.820578 validation: 0.856978
10/01 05:17:55 AM: edges-srl-ontonotes_precision: training: 0.905183 validation: 0.925584
10/01 05:17:55 AM: edges-srl-ontonotes_recall: training: 0.842444 validation: 0.863598
10/01 05:17:55 AM: edges-srl-ontonotes_f1: training: 0.872687 validation: 0.893517
10/01 05:17:55 AM: Global learning rate: 2.5e-05
10/01 05:17:55 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:18:02 AM: Update 27060: task edges-srl-ontonotes, batch 60 (27060): mcc: 0.8945, acc: 0.8515, precision: 0.9228, recall: 0.8700, f1: 0.8956, edges-srl-ontonotes_loss: 0.0091
10/01 05:18:12 AM: Update 27220: task edges-srl-ontonotes, batch 220 (27220): mcc: 0.9115, acc: 0.8731, precision: 0.9350, recall: 0.8911, f1: 0.9125, edges-srl-ontonotes_loss: 0.0077
10/01 05:18:22 AM: Update 27373: task edges-srl-ontonotes, batch 373 (27373): mcc: 0.9154, acc: 0.8781, precision: 0.9384, recall: 0.8954, f1: 0.9164, edges-srl-ontonotes_loss: 0.0074
10/01 05:18:32 AM: Update 27525: task edges-srl-ontonotes, batch 525 (27525): mcc: 0.9152, acc: 0.8779, precision: 0.9386, recall: 0.8948, f1: 0.9162, edges-srl-ontonotes_loss: 0.0075
10/01 05:18:42 AM: Update 27683: task edges-srl-ontonotes, batch 683 (27683): mcc: 0.9164, acc: 0.8797, precision: 0.9395, recall: 0.8963, f1: 0.9174, edges-srl-ontonotes_loss: 0.0074
10/01 05:18:52 AM: Update 27830: task edges-srl-ontonotes, batch 830 (27830): mcc: 0.9164, acc: 0.8798, precision: 0.9393, recall: 0.8964, f1: 0.9173, edges-srl-ontonotes_loss: 0.0074
10/01 05:19:02 AM: Update 27990: task edges-srl-ontonotes, batch 990 (27990): mcc: 0.9167, acc: 0.8804, precision: 0.9392, recall: 0.8971, f1: 0.9177, edges-srl-ontonotes_loss: 0.0074
10/01 05:19:06 AM: ***** Step 28000 / Validation 28 *****
10/01 05:19:06 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:19:06 AM: Validating...
10/01 05:19:12 AM: Evaluate: task edges-srl-ontonotes, batch 94 (157): mcc: 0.8908, acc: 0.8537, precision: 0.9248, recall: 0.8611, f1: 0.8918, edges-srl-ontonotes_loss: 0.0094
10/01 05:19:17 AM: Updating LR scheduler:
10/01 05:19:17 AM: 	Best result seen so far for macro_avg: 0.896
10/01 05:19:17 AM: 	# validation passes without improvement: 1
10/01 05:19:17 AM: edges-srl-ontonotes_loss: training: 0.007434 validation: 0.009236
10/01 05:19:17 AM: macro_avg: validation: 0.894452
10/01 05:19:17 AM: micro_avg: validation: 0.000000
10/01 05:19:17 AM: edges-srl-ontonotes_mcc: training: 0.916517 validation: 0.893368
10/01 05:19:17 AM: edges-srl-ontonotes_acc: training: 0.880249 validation: 0.858979
10/01 05:19:17 AM: edges-srl-ontonotes_precision: training: 0.939008 validation: 0.924505
10/01 05:19:17 AM: edges-srl-ontonotes_recall: training: 0.896972 validation: 0.866292
10/01 05:19:17 AM: edges-srl-ontonotes_f1: training: 0.917509 validation: 0.894452
10/01 05:19:17 AM: Global learning rate: 2.5e-05
10/01 05:19:17 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:19:22 AM: Update 28086: task edges-srl-ontonotes, batch 86 (28086): mcc: 0.9047, acc: 0.8691, precision: 0.9239, recall: 0.8887, f1: 0.9059, edges-srl-ontonotes_loss: 0.0088
10/01 05:19:32 AM: Update 28242: task edges-srl-ontonotes, batch 242 (28242): mcc: 0.9060, acc: 0.8702, precision: 0.9267, recall: 0.8885, f1: 0.9072, edges-srl-ontonotes_loss: 0.0085
10/01 05:19:42 AM: Update 28361: task edges-srl-ontonotes, batch 361 (28361): mcc: 0.9030, acc: 0.8662, precision: 0.9251, recall: 0.8842, f1: 0.9042, edges-srl-ontonotes_loss: 0.0087
10/01 05:19:53 AM: Update 28484: task edges-srl-ontonotes, batch 484 (28484): mcc: 0.8978, acc: 0.8590, precision: 0.9218, recall: 0.8773, f1: 0.8990, edges-srl-ontonotes_loss: 0.0091
10/01 05:20:03 AM: Update 28604: task edges-srl-ontonotes, batch 604 (28604): mcc: 0.8947, acc: 0.8548, precision: 0.9197, recall: 0.8735, f1: 0.8960, edges-srl-ontonotes_loss: 0.0093
10/01 05:20:13 AM: Update 28713: task edges-srl-ontonotes, batch 713 (28713): mcc: 0.8904, acc: 0.8490, precision: 0.9164, recall: 0.8683, f1: 0.8917, edges-srl-ontonotes_loss: 0.0096
10/01 05:20:23 AM: Update 28830: task edges-srl-ontonotes, batch 830 (28830): mcc: 0.8866, acc: 0.8438, precision: 0.9137, recall: 0.8636, f1: 0.8880, edges-srl-ontonotes_loss: 0.0099
10/01 05:20:33 AM: Update 28945: task edges-srl-ontonotes, batch 945 (28945): mcc: 0.8844, acc: 0.8407, precision: 0.9123, recall: 0.8607, f1: 0.8858, edges-srl-ontonotes_loss: 0.0101
10/01 05:20:37 AM: ***** Step 29000 / Validation 29 *****
10/01 05:20:37 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:20:37 AM: Validating...
10/01 05:20:43 AM: Evaluate: task edges-srl-ontonotes, batch 74 (157): mcc: 0.8899, acc: 0.8552, precision: 0.9226, recall: 0.8615, f1: 0.8910, edges-srl-ontonotes_loss: 0.0095
10/01 05:20:49 AM: Best result seen so far for edges-srl-ontonotes.
10/01 05:20:49 AM: Best result seen so far for macro.
10/01 05:20:49 AM: Updating LR scheduler:
10/01 05:20:49 AM: 	Best result seen so far for macro_avg: 0.897
10/01 05:20:49 AM: 	# validation passes without improvement: 0
10/01 05:20:49 AM: edges-srl-ontonotes_loss: training: 0.010087 validation: 0.009040
10/01 05:20:49 AM: macro_avg: validation: 0.896557
10/01 05:20:49 AM: micro_avg: validation: 0.000000
10/01 05:20:49 AM: edges-srl-ontonotes_mcc: training: 0.884051 validation: 0.895481
10/01 05:20:49 AM: edges-srl-ontonotes_acc: training: 0.839927 validation: 0.862520
10/01 05:20:49 AM: edges-srl-ontonotes_precision: training: 0.912409 validation: 0.925935
10/01 05:20:49 AM: edges-srl-ontonotes_recall: training: 0.859871 validation: 0.868986
10/01 05:20:49 AM: edges-srl-ontonotes_f1: training: 0.885361 validation: 0.896557
10/01 05:20:49 AM: Global learning rate: 2.5e-05
10/01 05:20:49 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:20:53 AM: Update 29055: task edges-srl-ontonotes, batch 55 (29055): mcc: 0.8811, acc: 0.8378, precision: 0.9088, recall: 0.8577, f1: 0.8825, edges-srl-ontonotes_loss: 0.0104
10/01 05:21:03 AM: Update 29200: task edges-srl-ontonotes, batch 200 (29200): mcc: 0.8853, acc: 0.8408, precision: 0.9146, recall: 0.8602, f1: 0.8866, edges-srl-ontonotes_loss: 0.0100
10/01 05:21:13 AM: Update 29298: task edges-srl-ontonotes, batch 298 (29298): mcc: 0.8856, acc: 0.8413, precision: 0.9148, recall: 0.8606, f1: 0.8869, edges-srl-ontonotes_loss: 0.0100
10/01 05:21:23 AM: Update 29435: task edges-srl-ontonotes, batch 435 (29435): mcc: 0.8872, acc: 0.8426, precision: 0.9161, recall: 0.8624, f1: 0.8884, edges-srl-ontonotes_loss: 0.0098
10/01 05:21:33 AM: Update 29572: task edges-srl-ontonotes, batch 572 (29572): mcc: 0.8872, acc: 0.8428, precision: 0.9164, recall: 0.8621, f1: 0.8884, edges-srl-ontonotes_loss: 0.0098
10/01 05:21:43 AM: Update 29688: task edges-srl-ontonotes, batch 688 (29688): mcc: 0.8853, acc: 0.8405, precision: 0.9147, recall: 0.8601, f1: 0.8866, edges-srl-ontonotes_loss: 0.0099
10/01 05:21:53 AM: Update 29821: task edges-srl-ontonotes, batch 821 (29821): mcc: 0.8846, acc: 0.8399, precision: 0.9141, recall: 0.8593, f1: 0.8859, edges-srl-ontonotes_loss: 0.0099
10/01 05:22:03 AM: Update 29938: task edges-srl-ontonotes, batch 938 (29938): mcc: 0.8840, acc: 0.8393, precision: 0.9133, recall: 0.8589, f1: 0.8852, edges-srl-ontonotes_loss: 0.0100
10/01 05:22:08 AM: ***** Step 30000 / Validation 30 *****
10/01 05:22:08 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:22:08 AM: Validating...
10/01 05:22:13 AM: Evaluate: task edges-srl-ontonotes, batch 77 (157): mcc: 0.8928, acc: 0.8564, precision: 0.9269, recall: 0.8629, f1: 0.8938, edges-srl-ontonotes_loss: 0.0092
10/01 05:22:19 AM: Best result seen so far for edges-srl-ontonotes.
10/01 05:22:19 AM: Best result seen so far for macro.
10/01 05:22:19 AM: Updating LR scheduler:
10/01 05:22:19 AM: 	Best result seen so far for macro_avg: 0.899
10/01 05:22:19 AM: 	# validation passes without improvement: 0
10/01 05:22:19 AM: edges-srl-ontonotes_loss: training: 0.010058 validation: 0.008778
10/01 05:22:19 AM: macro_avg: validation: 0.898811
10/01 05:22:19 AM: micro_avg: validation: 0.000000
10/01 05:22:19 AM: edges-srl-ontonotes_mcc: training: 0.883032 validation: 0.897812
10/01 05:22:19 AM: edges-srl-ontonotes_acc: training: 0.838167 validation: 0.863983
10/01 05:22:19 AM: edges-srl-ontonotes_precision: training: 0.912369 validation: 0.929523
10/01 05:22:19 AM: edges-srl-ontonotes_recall: training: 0.857955 validation: 0.870064
10/01 05:22:19 AM: edges-srl-ontonotes_f1: training: 0.884326 validation: 0.898811
10/01 05:22:19 AM: Global learning rate: 2.5e-05
10/01 05:22:19 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:22:24 AM: Update 30055: task edges-srl-ontonotes, batch 55 (30055): mcc: 0.8637, acc: 0.8149, precision: 0.8983, recall: 0.8343, f1: 0.8651, edges-srl-ontonotes_loss: 0.0111
10/01 05:22:34 AM: Update 30185: task edges-srl-ontonotes, batch 185 (30185): mcc: 0.8642, acc: 0.8130, precision: 0.8987, recall: 0.8347, f1: 0.8655, edges-srl-ontonotes_loss: 0.0113
10/01 05:22:44 AM: Update 30270: task edges-srl-ontonotes, batch 270 (30270): mcc: 0.8654, acc: 0.8139, precision: 0.8993, recall: 0.8366, f1: 0.8668, edges-srl-ontonotes_loss: 0.0113
10/01 05:22:54 AM: Update 30398: task edges-srl-ontonotes, batch 398 (30398): mcc: 0.8675, acc: 0.8171, precision: 0.9008, recall: 0.8392, f1: 0.8689, edges-srl-ontonotes_loss: 0.0111
10/01 05:23:04 AM: Update 30517: task edges-srl-ontonotes, batch 517 (30517): mcc: 0.8678, acc: 0.8172, precision: 0.9011, recall: 0.8395, f1: 0.8692, edges-srl-ontonotes_loss: 0.0110
10/01 05:23:14 AM: Update 30631: task edges-srl-ontonotes, batch 631 (30631): mcc: 0.8654, acc: 0.8142, precision: 0.8988, recall: 0.8370, f1: 0.8668, edges-srl-ontonotes_loss: 0.0112
10/01 05:23:24 AM: Update 30751: task edges-srl-ontonotes, batch 751 (30751): mcc: 0.8625, acc: 0.8109, precision: 0.8966, recall: 0.8335, f1: 0.8639, edges-srl-ontonotes_loss: 0.0114
10/01 05:23:34 AM: Update 30866: task edges-srl-ontonotes, batch 866 (30866): mcc: 0.8613, acc: 0.8097, precision: 0.8955, recall: 0.8323, f1: 0.8628, edges-srl-ontonotes_loss: 0.0115
10/01 05:23:44 AM: Update 30994: task edges-srl-ontonotes, batch 994 (30994): mcc: 0.8592, acc: 0.8068, precision: 0.8940, recall: 0.8297, f1: 0.8607, edges-srl-ontonotes_loss: 0.0116
10/01 05:23:44 AM: ***** Step 31000 / Validation 31 *****
10/01 05:23:44 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:23:44 AM: Validating...
10/01 05:23:54 AM: Evaluate: task edges-srl-ontonotes, batch 130 (157): mcc: 0.8991, acc: 0.8660, precision: 0.9283, recall: 0.8737, f1: 0.9002, edges-srl-ontonotes_loss: 0.0085
10/01 05:23:56 AM: Updating LR scheduler:
10/01 05:23:56 AM: 	Best result seen so far for macro_avg: 0.899
10/01 05:23:56 AM: 	# validation passes without improvement: 1
10/01 05:23:56 AM: edges-srl-ontonotes_loss: training: 0.011644 validation: 0.008800
10/01 05:23:56 AM: macro_avg: validation: 0.897253
10/01 05:23:56 AM: micro_avg: validation: 0.000000
10/01 05:23:56 AM: edges-srl-ontonotes_mcc: training: 0.859127 validation: 0.896181
10/01 05:23:56 AM: edges-srl-ontonotes_acc: training: 0.806716 validation: 0.862366
10/01 05:23:56 AM: edges-srl-ontonotes_precision: training: 0.893963 validation: 0.926457
10/01 05:23:56 AM: edges-srl-ontonotes_recall: training: 0.829588 validation: 0.869833
10/01 05:23:56 AM: edges-srl-ontonotes_f1: training: 0.860573 validation: 0.897253
10/01 05:23:56 AM: Global learning rate: 2.5e-05
10/01 05:23:56 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:24:04 AM: Update 31100: task edges-srl-ontonotes, batch 100 (31100): mcc: 0.8550, acc: 0.7995, precision: 0.8898, recall: 0.8255, f1: 0.8565, edges-srl-ontonotes_loss: 0.0122
10/01 05:24:14 AM: Update 31192: task edges-srl-ontonotes, batch 192 (31192): mcc: 0.8567, acc: 0.8037, precision: 0.8913, recall: 0.8275, f1: 0.8582, edges-srl-ontonotes_loss: 0.0120
10/01 05:24:24 AM: Update 31313: task edges-srl-ontonotes, batch 313 (31313): mcc: 0.8633, acc: 0.8117, precision: 0.8971, recall: 0.8345, f1: 0.8647, edges-srl-ontonotes_loss: 0.0113
10/01 05:24:34 AM: Update 31435: task edges-srl-ontonotes, batch 435 (31435): mcc: 0.8685, acc: 0.8186, precision: 0.9019, recall: 0.8401, f1: 0.8699, edges-srl-ontonotes_loss: 0.0109
10/01 05:24:44 AM: Update 31544: task edges-srl-ontonotes, batch 544 (31544): mcc: 0.8696, acc: 0.8197, precision: 0.9029, recall: 0.8413, f1: 0.8710, edges-srl-ontonotes_loss: 0.0108
10/01 05:24:54 AM: Update 31665: task edges-srl-ontonotes, batch 665 (31665): mcc: 0.8701, acc: 0.8200, precision: 0.9036, recall: 0.8416, f1: 0.8715, edges-srl-ontonotes_loss: 0.0108
10/01 05:25:04 AM: Update 31791: task edges-srl-ontonotes, batch 791 (31791): mcc: 0.8712, acc: 0.8213, precision: 0.9045, recall: 0.8428, f1: 0.8726, edges-srl-ontonotes_loss: 0.0107
10/01 05:25:14 AM: Update 31907: task edges-srl-ontonotes, batch 907 (31907): mcc: 0.8721, acc: 0.8228, precision: 0.9048, recall: 0.8442, f1: 0.8734, edges-srl-ontonotes_loss: 0.0107
10/01 05:25:22 AM: ***** Step 32000 / Validation 32 *****
10/01 05:25:22 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:25:22 AM: Validating...
10/01 05:25:24 AM: Evaluate: task edges-srl-ontonotes, batch 36 (157): mcc: 0.8894, acc: 0.8526, precision: 0.9244, recall: 0.8588, f1: 0.8904, edges-srl-ontonotes_loss: 0.0093
10/01 05:25:33 AM: Updating LR scheduler:
10/01 05:25:33 AM: 	Best result seen so far for macro_avg: 0.899
10/01 05:25:33 AM: 	# validation passes without improvement: 2
10/01 05:25:33 AM: edges-srl-ontonotes_loss: training: 0.010632 validation: 0.008917
10/01 05:25:33 AM: macro_avg: validation: 0.896244
10/01 05:25:33 AM: micro_avg: validation: 0.000000
10/01 05:25:33 AM: edges-srl-ontonotes_mcc: training: 0.872878 validation: 0.895225
10/01 05:25:33 AM: edges-srl-ontonotes_acc: training: 0.823906 validation: 0.860981
10/01 05:25:33 AM: edges-srl-ontonotes_precision: training: 0.905377 validation: 0.927460
10/01 05:25:33 AM: edges-srl-ontonotes_recall: training: 0.845122 validation: 0.867062
10/01 05:25:33 AM: edges-srl-ontonotes_f1: training: 0.874212 validation: 0.896244
10/01 05:25:33 AM: Global learning rate: 2.5e-05
10/01 05:25:33 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:25:34 AM: Update 32014: task edges-srl-ontonotes, batch 14 (32014): mcc: 0.8726, acc: 0.8193, precision: 0.9126, recall: 0.8379, f1: 0.8737, edges-srl-ontonotes_loss: 0.0105
10/01 05:25:44 AM: Update 32129: task edges-srl-ontonotes, batch 129 (32129): mcc: 0.8816, acc: 0.8341, precision: 0.9131, recall: 0.8545, f1: 0.8828, edges-srl-ontonotes_loss: 0.0102
10/01 05:25:55 AM: Update 32254: task edges-srl-ontonotes, batch 254 (32254): mcc: 0.8726, acc: 0.8239, precision: 0.9056, recall: 0.8443, f1: 0.8739, edges-srl-ontonotes_loss: 0.0108
10/01 05:26:05 AM: Update 32367: task edges-srl-ontonotes, batch 367 (32367): mcc: 0.8696, acc: 0.8206, precision: 0.9028, recall: 0.8413, f1: 0.8710, edges-srl-ontonotes_loss: 0.0110
10/01 05:26:15 AM: Update 32455: task edges-srl-ontonotes, batch 455 (32455): mcc: 0.8692, acc: 0.8199, precision: 0.9028, recall: 0.8406, f1: 0.8706, edges-srl-ontonotes_loss: 0.0110
10/01 05:26:25 AM: Update 32586: task edges-srl-ontonotes, batch 586 (32586): mcc: 0.8686, acc: 0.8184, precision: 0.9025, recall: 0.8397, f1: 0.8700, edges-srl-ontonotes_loss: 0.0110
10/01 05:26:35 AM: Update 32701: task edges-srl-ontonotes, batch 701 (32701): mcc: 0.8688, acc: 0.8185, precision: 0.9029, recall: 0.8396, f1: 0.8701, edges-srl-ontonotes_loss: 0.0110
10/01 05:26:45 AM: Update 32810: task edges-srl-ontonotes, batch 810 (32810): mcc: 0.8682, acc: 0.8178, precision: 0.9027, recall: 0.8388, f1: 0.8696, edges-srl-ontonotes_loss: 0.0110
10/01 05:26:55 AM: Update 32937: task edges-srl-ontonotes, batch 937 (32937): mcc: 0.8687, acc: 0.8182, precision: 0.9030, recall: 0.8394, f1: 0.8700, edges-srl-ontonotes_loss: 0.0110
10/01 05:27:00 AM: ***** Step 33000 / Validation 33 *****
10/01 05:27:00 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:27:00 AM: Validating...
10/01 05:27:05 AM: Evaluate: task edges-srl-ontonotes, batch 68 (157): mcc: 0.8846, acc: 0.8484, precision: 0.9187, recall: 0.8551, f1: 0.8857, edges-srl-ontonotes_loss: 0.0098
10/01 05:27:11 AM: Updating LR scheduler:
10/01 05:27:11 AM: 	Best result seen so far for macro_avg: 0.899
10/01 05:27:11 AM: 	# validation passes without improvement: 3
10/01 05:27:11 AM: edges-srl-ontonotes_loss: training: 0.010986 validation: 0.009107
10/01 05:27:11 AM: macro_avg: validation: 0.895049
10/01 05:27:11 AM: micro_avg: validation: 0.000000
10/01 05:27:11 AM: edges-srl-ontonotes_mcc: training: 0.868733 validation: 0.893999
10/01 05:27:11 AM: edges-srl-ontonotes_acc: training: 0.817977 validation: 0.859441
10/01 05:27:11 AM: edges-srl-ontonotes_precision: training: 0.902919 validation: 0.925868
10/01 05:27:11 AM: edges-srl-ontonotes_recall: training: 0.839520 validation: 0.866215
10/01 05:27:11 AM: edges-srl-ontonotes_f1: training: 0.870066 validation: 0.895049
10/01 05:27:11 AM: Global learning rate: 2.5e-05
10/01 05:27:11 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:27:15 AM: Update 33046: task edges-srl-ontonotes, batch 46 (33046): mcc: 0.8600, acc: 0.8055, precision: 0.8909, recall: 0.8341, f1: 0.8616, edges-srl-ontonotes_loss: 0.0114
10/01 05:27:25 AM: Update 33168: task edges-srl-ontonotes, batch 168 (33168): mcc: 0.8678, acc: 0.8171, precision: 0.9009, recall: 0.8396, f1: 0.8692, edges-srl-ontonotes_loss: 0.0111
10/01 05:27:35 AM: Update 33300: task edges-srl-ontonotes, batch 300 (33300): mcc: 0.8691, acc: 0.8190, precision: 0.9011, recall: 0.8418, f1: 0.8705, edges-srl-ontonotes_loss: 0.0109
10/01 05:27:45 AM: Update 33398: task edges-srl-ontonotes, batch 398 (33398): mcc: 0.8709, acc: 0.8214, precision: 0.9025, recall: 0.8440, f1: 0.8723, edges-srl-ontonotes_loss: 0.0108
10/01 05:27:55 AM: Update 33532: task edges-srl-ontonotes, batch 532 (33532): mcc: 0.8713, acc: 0.8220, precision: 0.9032, recall: 0.8442, f1: 0.8727, edges-srl-ontonotes_loss: 0.0108
10/01 05:28:05 AM: Update 33666: task edges-srl-ontonotes, batch 666 (33666): mcc: 0.8729, acc: 0.8238, precision: 0.9049, recall: 0.8456, f1: 0.8743, edges-srl-ontonotes_loss: 0.0107
10/01 05:28:15 AM: Update 33766: task edges-srl-ontonotes, batch 766 (33766): mcc: 0.8691, acc: 0.8189, precision: 0.9023, recall: 0.8409, f1: 0.8705, edges-srl-ontonotes_loss: 0.0110
10/01 05:28:25 AM: Update 33877: task edges-srl-ontonotes, batch 877 (33877): mcc: 0.8680, acc: 0.8170, precision: 0.9017, recall: 0.8393, f1: 0.8694, edges-srl-ontonotes_loss: 0.0110
10/01 05:28:35 AM: Update 33978: task edges-srl-ontonotes, batch 978 (33978): mcc: 0.8669, acc: 0.8152, precision: 0.9011, recall: 0.8377, f1: 0.8682, edges-srl-ontonotes_loss: 0.0111
10/01 05:28:38 AM: ***** Step 34000 / Validation 34 *****
10/01 05:28:38 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:28:38 AM: Validating...
10/01 05:28:45 AM: Evaluate: task edges-srl-ontonotes, batch 102 (157): mcc: 0.8917, acc: 0.8568, precision: 0.9234, recall: 0.8642, f1: 0.8928, edges-srl-ontonotes_loss: 0.0091
10/01 05:28:49 AM: Updating LR scheduler:
10/01 05:28:49 AM: 	Best result seen so far for macro_avg: 0.899
10/01 05:28:49 AM: 	# validation passes without improvement: 0
10/01 05:28:49 AM: edges-srl-ontonotes_loss: training: 0.011106 validation: 0.009057
10/01 05:28:49 AM: macro_avg: validation: 0.895999
10/01 05:28:49 AM: micro_avg: validation: 0.000000
10/01 05:28:49 AM: edges-srl-ontonotes_mcc: training: 0.867024 validation: 0.894868
10/01 05:28:49 AM: edges-srl-ontonotes_acc: training: 0.815490 validation: 0.862135
10/01 05:28:49 AM: edges-srl-ontonotes_precision: training: 0.901173 validation: 0.923876
10/01 05:28:49 AM: edges-srl-ontonotes_recall: training: 0.837896 validation: 0.869756
10/01 05:28:49 AM: edges-srl-ontonotes_f1: training: 0.868383 validation: 0.895999
10/01 05:28:49 AM: Global learning rate: 1.25e-05
10/01 05:28:49 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:28:55 AM: Update 34084: task edges-srl-ontonotes, batch 84 (34084): mcc: 0.8951, acc: 0.8540, precision: 0.9188, recall: 0.8751, f1: 0.8964, edges-srl-ontonotes_loss: 0.0090
10/01 05:29:05 AM: Update 34224: task edges-srl-ontonotes, batch 224 (34224): mcc: 0.8930, acc: 0.8496, precision: 0.9192, recall: 0.8706, f1: 0.8942, edges-srl-ontonotes_loss: 0.0091
10/01 05:29:15 AM: Update 34330: task edges-srl-ontonotes, batch 330 (34330): mcc: 0.8946, acc: 0.8518, precision: 0.9209, recall: 0.8721, f1: 0.8959, edges-srl-ontonotes_loss: 0.0089
10/01 05:29:25 AM: Update 34484: task edges-srl-ontonotes, batch 484 (34484): mcc: 0.9024, acc: 0.8617, precision: 0.9270, recall: 0.8813, f1: 0.9036, edges-srl-ontonotes_loss: 0.0083
10/01 05:29:36 AM: Update 34619: task edges-srl-ontonotes, batch 619 (34619): mcc: 0.9063, acc: 0.8670, precision: 0.9302, recall: 0.8857, f1: 0.9074, edges-srl-ontonotes_loss: 0.0081
10/01 05:29:46 AM: Update 34773: task edges-srl-ontonotes, batch 773 (34773): mcc: 0.9084, acc: 0.8693, precision: 0.9325, recall: 0.8875, f1: 0.9094, edges-srl-ontonotes_loss: 0.0079
10/01 05:29:56 AM: Update 34928: task edges-srl-ontonotes, batch 928 (34928): mcc: 0.9104, acc: 0.8719, precision: 0.9345, recall: 0.8895, f1: 0.9114, edges-srl-ontonotes_loss: 0.0078
10/01 05:30:01 AM: ***** Step 35000 / Validation 35 *****
10/01 05:30:01 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:30:01 AM: Validating...
10/01 05:30:06 AM: Evaluate: task edges-srl-ontonotes, batch 66 (157): mcc: 0.8856, acc: 0.8475, precision: 0.9218, recall: 0.8540, f1: 0.8866, edges-srl-ontonotes_loss: 0.0098
10/01 05:30:13 AM: Updating LR scheduler:
10/01 05:30:13 AM: 	Best result seen so far for macro_avg: 0.899
10/01 05:30:13 AM: 	# validation passes without improvement: 1
10/01 05:30:13 AM: edges-srl-ontonotes_loss: training: 0.007793 validation: 0.008991
10/01 05:30:13 AM: macro_avg: validation: 0.896283
10/01 05:30:13 AM: micro_avg: validation: 0.000000
10/01 05:30:13 AM: edges-srl-ontonotes_mcc: training: 0.910679 validation: 0.895278
10/01 05:30:13 AM: edges-srl-ontonotes_acc: training: 0.872411 validation: 0.859980
10/01 05:30:13 AM: edges-srl-ontonotes_precision: training: 0.934595 validation: 0.927895
10/01 05:30:13 AM: edges-srl-ontonotes_recall: training: 0.889943 validation: 0.866754
10/01 05:30:13 AM: edges-srl-ontonotes_f1: training: 0.911722 validation: 0.896283
10/01 05:30:13 AM: Global learning rate: 1.25e-05
10/01 05:30:13 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:30:16 AM: Update 35053: task edges-srl-ontonotes, batch 53 (35053): mcc: 0.9075, acc: 0.8720, precision: 0.9280, recall: 0.8902, f1: 0.9087, edges-srl-ontonotes_loss: 0.0077
10/01 05:30:26 AM: Update 35206: task edges-srl-ontonotes, batch 206 (35206): mcc: 0.9158, acc: 0.8802, precision: 0.9371, recall: 0.8974, f1: 0.9168, edges-srl-ontonotes_loss: 0.0074
10/01 05:30:36 AM: Update 35351: task edges-srl-ontonotes, batch 351 (35351): mcc: 0.9134, acc: 0.8776, precision: 0.9346, recall: 0.8953, f1: 0.9145, edges-srl-ontonotes_loss: 0.0078
10/01 05:30:46 AM: Update 35514: task edges-srl-ontonotes, batch 514 (35514): mcc: 0.9128, acc: 0.8767, precision: 0.9338, recall: 0.8948, f1: 0.9139, edges-srl-ontonotes_loss: 0.0079
10/01 05:30:56 AM: Update 35618: task edges-srl-ontonotes, batch 618 (35618): mcc: 0.9095, acc: 0.8721, precision: 0.9314, recall: 0.8908, f1: 0.9106, edges-srl-ontonotes_loss: 0.0081
10/01 05:31:06 AM: Update 35747: task edges-srl-ontonotes, batch 747 (35747): mcc: 0.9046, acc: 0.8655, precision: 0.9280, recall: 0.8845, f1: 0.9057, edges-srl-ontonotes_loss: 0.0085
10/01 05:31:17 AM: Update 35871: task edges-srl-ontonotes, batch 871 (35871): mcc: 0.9024, acc: 0.8627, precision: 0.9267, recall: 0.8816, f1: 0.9036, edges-srl-ontonotes_loss: 0.0087
10/01 05:31:27 AM: Update 35998: task edges-srl-ontonotes, batch 998 (35998): mcc: 0.8981, acc: 0.8573, precision: 0.9234, recall: 0.8763, f1: 0.8992, edges-srl-ontonotes_loss: 0.0090
10/01 05:31:27 AM: ***** Step 36000 / Validation 36 *****
10/01 05:31:27 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:31:27 AM: Validating...
10/01 05:31:37 AM: Evaluate: task edges-srl-ontonotes, batch 134 (157): mcc: 0.8997, acc: 0.8661, precision: 0.9302, recall: 0.8731, f1: 0.9007, edges-srl-ontonotes_loss: 0.0086
10/01 05:31:38 AM: Updating LR scheduler:
10/01 05:31:38 AM: 	Best result seen so far for macro_avg: 0.899
10/01 05:31:38 AM: 	# validation passes without improvement: 2
10/01 05:31:38 AM: edges-srl-ontonotes_loss: training: 0.009046 validation: 0.008898
10/01 05:31:38 AM: macro_avg: validation: 0.897703
10/01 05:31:38 AM: micro_avg: validation: 0.000000
10/01 05:31:38 AM: edges-srl-ontonotes_mcc: training: 0.898017 validation: 0.896672
10/01 05:31:38 AM: edges-srl-ontonotes_acc: training: 0.857226 validation: 0.862443
10/01 05:31:38 AM: edges-srl-ontonotes_precision: training: 0.923379 validation: 0.927943
10/01 05:31:38 AM: edges-srl-ontonotes_recall: training: 0.876273 validation: 0.869371
10/01 05:31:38 AM: edges-srl-ontonotes_f1: training: 0.899210 validation: 0.897703
10/01 05:31:38 AM: Global learning rate: 1.25e-05
10/01 05:31:38 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:31:47 AM: Update 36101: task edges-srl-ontonotes, batch 101 (36101): mcc: 0.8627, acc: 0.8101, precision: 0.8955, recall: 0.8348, f1: 0.8641, edges-srl-ontonotes_loss: 0.0115
10/01 05:31:57 AM: Update 36230: task edges-srl-ontonotes, batch 230 (36230): mcc: 0.8657, acc: 0.8140, precision: 0.8992, recall: 0.8372, f1: 0.8671, edges-srl-ontonotes_loss: 0.0113
10/01 05:32:07 AM: Update 36354: task edges-srl-ontonotes, batch 354 (36354): mcc: 0.8732, acc: 0.8243, precision: 0.9055, recall: 0.8457, f1: 0.8746, edges-srl-ontonotes_loss: 0.0108
10/01 05:32:17 AM: Update 36479: task edges-srl-ontonotes, batch 479 (36479): mcc: 0.8766, acc: 0.8279, precision: 0.9084, recall: 0.8493, f1: 0.8779, edges-srl-ontonotes_loss: 0.0105
10/01 05:32:27 AM: Update 36582: task edges-srl-ontonotes, batch 582 (36582): mcc: 0.8796, acc: 0.8319, precision: 0.9107, recall: 0.8530, f1: 0.8809, edges-srl-ontonotes_loss: 0.0103
10/01 05:32:37 AM: Update 36719: task edges-srl-ontonotes, batch 719 (36719): mcc: 0.8809, acc: 0.8336, precision: 0.9119, recall: 0.8543, f1: 0.8822, edges-srl-ontonotes_loss: 0.0102
10/01 05:32:48 AM: Update 36857: task edges-srl-ontonotes, batch 857 (36857): mcc: 0.8825, acc: 0.8357, precision: 0.9128, recall: 0.8564, f1: 0.8837, edges-srl-ontonotes_loss: 0.0101
10/01 05:32:58 AM: Update 36994: task edges-srl-ontonotes, batch 994 (36994): mcc: 0.8824, acc: 0.8361, precision: 0.9126, recall: 0.8565, f1: 0.8837, edges-srl-ontonotes_loss: 0.0101
10/01 05:32:58 AM: ***** Step 37000 / Validation 37 *****
10/01 05:32:58 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:32:58 AM: Validating...
10/01 05:33:08 AM: Evaluate: task edges-srl-ontonotes, batch 131 (157): mcc: 0.9035, acc: 0.8718, precision: 0.9317, recall: 0.8790, f1: 0.9045, edges-srl-ontonotes_loss: 0.0083
10/01 05:33:09 AM: Best result seen so far for edges-srl-ontonotes.
10/01 05:33:09 AM: Best result seen so far for macro.
10/01 05:33:09 AM: Updating LR scheduler:
10/01 05:33:09 AM: 	Best result seen so far for macro_avg: 0.900
10/01 05:33:09 AM: 	# validation passes without improvement: 0
10/01 05:33:09 AM: edges-srl-ontonotes_loss: training: 0.010105 validation: 0.008684
10/01 05:33:09 AM: macro_avg: validation: 0.900440
10/01 05:33:09 AM: micro_avg: validation: 0.000000
10/01 05:33:09 AM: edges-srl-ontonotes_mcc: training: 0.882554 validation: 0.899377
10/01 05:33:09 AM: edges-srl-ontonotes_acc: training: 0.836280 validation: 0.867139
10/01 05:33:09 AM: edges-srl-ontonotes_precision: training: 0.912709 validation: 0.928455
10/01 05:33:09 AM: edges-srl-ontonotes_recall: training: 0.856720 validation: 0.874067
10/01 05:33:09 AM: edges-srl-ontonotes_f1: training: 0.883828 validation: 0.900440
10/01 05:33:09 AM: Global learning rate: 1.25e-05
10/01 05:33:09 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:33:18 AM: Update 37104: task edges-srl-ontonotes, batch 104 (37104): mcc: 0.8812, acc: 0.8371, precision: 0.9114, recall: 0.8553, f1: 0.8825, edges-srl-ontonotes_loss: 0.0101
10/01 05:33:28 AM: Update 37221: task edges-srl-ontonotes, batch 221 (37221): mcc: 0.8792, acc: 0.8332, precision: 0.9091, recall: 0.8537, f1: 0.8805, edges-srl-ontonotes_loss: 0.0103
10/01 05:33:38 AM: Update 37358: task edges-srl-ontonotes, batch 358 (37358): mcc: 0.8745, acc: 0.8267, precision: 0.9048, recall: 0.8488, f1: 0.8759, edges-srl-ontonotes_loss: 0.0106
10/01 05:33:48 AM: Update 37483: task edges-srl-ontonotes, batch 483 (37483): mcc: 0.8710, acc: 0.8219, precision: 0.9018, recall: 0.8448, f1: 0.8724, edges-srl-ontonotes_loss: 0.0109
10/01 05:33:58 AM: Update 37611: task edges-srl-ontonotes, batch 611 (37611): mcc: 0.8707, acc: 0.8216, precision: 0.9018, recall: 0.8443, f1: 0.8721, edges-srl-ontonotes_loss: 0.0108
10/01 05:34:08 AM: Update 37739: task edges-srl-ontonotes, batch 739 (37739): mcc: 0.8708, acc: 0.8216, precision: 0.9020, recall: 0.8443, f1: 0.8722, edges-srl-ontonotes_loss: 0.0108
10/01 05:34:18 AM: Update 37836: task edges-srl-ontonotes, batch 836 (37836): mcc: 0.8698, acc: 0.8205, precision: 0.9013, recall: 0.8431, f1: 0.8712, edges-srl-ontonotes_loss: 0.0109
10/01 05:34:28 AM: Update 37958: task edges-srl-ontonotes, batch 958 (37958): mcc: 0.8676, acc: 0.8180, precision: 0.8996, recall: 0.8404, f1: 0.8690, edges-srl-ontonotes_loss: 0.0110
10/01 05:34:32 AM: ***** Step 38000 / Validation 38 *****
10/01 05:34:32 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:34:32 AM: Validating...
10/01 05:34:38 AM: Evaluate: task edges-srl-ontonotes, batch 87 (157): mcc: 0.8967, acc: 0.8601, precision: 0.9302, recall: 0.8673, f1: 0.8977, edges-srl-ontonotes_loss: 0.0088
10/01 05:34:43 AM: Updating LR scheduler:
10/01 05:34:43 AM: 	Best result seen so far for macro_avg: 0.900
10/01 05:34:43 AM: 	# validation passes without improvement: 1
10/01 05:34:43 AM: edges-srl-ontonotes_loss: training: 0.011085 validation: 0.008653
10/01 05:34:43 AM: macro_avg: validation: 0.900358
10/01 05:34:43 AM: micro_avg: validation: 0.000000
10/01 05:34:43 AM: edges-srl-ontonotes_mcc: training: 0.866517 validation: 0.899357
10/01 05:34:43 AM: edges-srl-ontonotes_acc: training: 0.816737 validation: 0.865445
10/01 05:34:43 AM: edges-srl-ontonotes_precision: training: 0.898527 validation: 0.930372
10/01 05:34:43 AM: edges-srl-ontonotes_recall: training: 0.839408 validation: 0.872219
10/01 05:34:43 AM: edges-srl-ontonotes_f1: training: 0.867962 validation: 0.900358
10/01 05:34:43 AM: Global learning rate: 1.25e-05
10/01 05:34:43 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:34:48 AM: Update 38059: task edges-srl-ontonotes, batch 59 (38059): mcc: 0.8465, acc: 0.7939, precision: 0.8863, recall: 0.8128, f1: 0.8479, edges-srl-ontonotes_loss: 0.0126
10/01 05:34:58 AM: Update 38172: task edges-srl-ontonotes, batch 172 (38172): mcc: 0.8489, acc: 0.7945, precision: 0.8857, recall: 0.8179, f1: 0.8504, edges-srl-ontonotes_loss: 0.0124
10/01 05:35:08 AM: Update 38304: task edges-srl-ontonotes, batch 304 (38304): mcc: 0.8495, acc: 0.7945, precision: 0.8864, recall: 0.8183, f1: 0.8510, edges-srl-ontonotes_loss: 0.0123
10/01 05:35:19 AM: Update 38422: task edges-srl-ontonotes, batch 422 (38422): mcc: 0.8508, acc: 0.7959, precision: 0.8881, recall: 0.8192, f1: 0.8522, edges-srl-ontonotes_loss: 0.0122
10/01 05:35:29 AM: Update 38544: task edges-srl-ontonotes, batch 544 (38544): mcc: 0.8577, acc: 0.8046, precision: 0.8937, recall: 0.8271, f1: 0.8591, edges-srl-ontonotes_loss: 0.0117
10/01 05:35:39 AM: Update 38666: task edges-srl-ontonotes, batch 666 (38666): mcc: 0.8614, acc: 0.8093, precision: 0.8964, recall: 0.8316, f1: 0.8628, edges-srl-ontonotes_loss: 0.0114
10/01 05:35:49 AM: Update 38757: task edges-srl-ontonotes, batch 757 (38757): mcc: 0.8630, acc: 0.8111, precision: 0.8977, recall: 0.8335, f1: 0.8644, edges-srl-ontonotes_loss: 0.0113
10/01 05:35:59 AM: Update 38880: task edges-srl-ontonotes, batch 880 (38880): mcc: 0.8653, acc: 0.8142, precision: 0.8994, recall: 0.8363, f1: 0.8667, edges-srl-ontonotes_loss: 0.0111
10/01 05:36:09 AM: Update 38991: task edges-srl-ontonotes, batch 991 (38991): mcc: 0.8670, acc: 0.8160, precision: 0.9009, recall: 0.8381, f1: 0.8683, edges-srl-ontonotes_loss: 0.0110
10/01 05:36:10 AM: ***** Step 39000 / Validation 39 *****
10/01 05:36:10 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:36:10 AM: Validating...
10/01 05:36:19 AM: Evaluate: task edges-srl-ontonotes, batch 128 (157): mcc: 0.9001, acc: 0.8677, precision: 0.9295, recall: 0.8745, f1: 0.9012, edges-srl-ontonotes_loss: 0.0085
10/01 05:36:21 AM: Updating LR scheduler:
10/01 05:36:21 AM: 	Best result seen so far for macro_avg: 0.900
10/01 05:36:21 AM: 	# validation passes without improvement: 2
10/01 05:36:21 AM: edges-srl-ontonotes_loss: training: 0.010990 validation: 0.008735
10/01 05:36:21 AM: macro_avg: validation: 0.898615
10/01 05:36:21 AM: micro_avg: validation: 0.000000
10/01 05:36:21 AM: edges-srl-ontonotes_mcc: training: 0.867142 validation: 0.897548
10/01 05:36:21 AM: edges-srl-ontonotes_acc: training: 0.816353 validation: 0.864753
10/01 05:36:21 AM: edges-srl-ontonotes_precision: training: 0.900972 validation: 0.927355
10/01 05:36:21 AM: edges-srl-ontonotes_recall: training: 0.838307 validation: 0.871603
10/01 05:36:21 AM: edges-srl-ontonotes_f1: training: 0.868511 validation: 0.898615
10/01 05:36:21 AM: Global learning rate: 1.25e-05
10/01 05:36:21 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:36:29 AM: Update 39088: task edges-srl-ontonotes, batch 88 (39088): mcc: 0.8745, acc: 0.8255, precision: 0.9076, recall: 0.8462, f1: 0.8758, edges-srl-ontonotes_loss: 0.0106
10/01 05:36:39 AM: Update 39210: task edges-srl-ontonotes, batch 210 (39210): mcc: 0.8818, acc: 0.8353, precision: 0.9119, recall: 0.8561, f1: 0.8831, edges-srl-ontonotes_loss: 0.0102
10/01 05:36:49 AM: Update 39324: task edges-srl-ontonotes, batch 324 (39324): mcc: 0.8822, acc: 0.8360, precision: 0.9117, recall: 0.8569, f1: 0.8835, edges-srl-ontonotes_loss: 0.0101
10/01 05:36:59 AM: Update 39437: task edges-srl-ontonotes, batch 437 (39437): mcc: 0.8797, acc: 0.8322, precision: 0.9098, recall: 0.8541, f1: 0.8811, edges-srl-ontonotes_loss: 0.0102
10/01 05:37:09 AM: Update 39564: task edges-srl-ontonotes, batch 564 (39564): mcc: 0.8771, acc: 0.8296, precision: 0.9080, recall: 0.8508, f1: 0.8785, edges-srl-ontonotes_loss: 0.0104
10/01 05:37:22 AM: Update 39674: task edges-srl-ontonotes, batch 674 (39674): mcc: 0.8752, acc: 0.8268, precision: 0.9066, recall: 0.8484, f1: 0.8765, edges-srl-ontonotes_loss: 0.0106
10/01 05:37:32 AM: Update 39795: task edges-srl-ontonotes, batch 795 (39795): mcc: 0.8740, acc: 0.8256, precision: 0.9054, recall: 0.8473, f1: 0.8754, edges-srl-ontonotes_loss: 0.0107
10/01 05:37:42 AM: Update 39912: task edges-srl-ontonotes, batch 912 (39912): mcc: 0.8733, acc: 0.8246, precision: 0.9048, recall: 0.8464, f1: 0.8746, edges-srl-ontonotes_loss: 0.0107
10/01 05:37:50 AM: ***** Step 40000 / Validation 40 *****
10/01 05:37:50 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:37:50 AM: Validating...
10/01 05:37:52 AM: Evaluate: task edges-srl-ontonotes, batch 19 (157): mcc: 0.8951, acc: 0.8598, precision: 0.9305, recall: 0.8641, f1: 0.8960, edges-srl-ontonotes_loss: 0.0084
10/01 05:38:02 AM: Evaluate: task edges-srl-ontonotes, batch 156 (157): mcc: 0.8972, acc: 0.8625, precision: 0.9296, recall: 0.8688, f1: 0.8982, edges-srl-ontonotes_loss: 0.0088
10/01 05:38:02 AM: Updating LR scheduler:
10/01 05:38:02 AM: 	Best result seen so far for macro_avg: 0.900
10/01 05:38:02 AM: 	# validation passes without improvement: 3
10/01 05:38:02 AM: edges-srl-ontonotes_loss: training: 0.010780 validation: 0.008819
10/01 05:38:02 AM: macro_avg: validation: 0.898094
10/01 05:38:02 AM: micro_avg: validation: 0.000000
10/01 05:38:02 AM: edges-srl-ontonotes_mcc: training: 0.872332 validation: 0.897110
10/01 05:38:02 AM: edges-srl-ontonotes_acc: training: 0.823392 validation: 0.862443
10/01 05:38:02 AM: edges-srl-ontonotes_precision: training: 0.904288 validation: 0.929572
10/01 05:38:02 AM: edges-srl-ontonotes_recall: training: 0.845103 validation: 0.868678
10/01 05:38:02 AM: edges-srl-ontonotes_f1: training: 0.873695 validation: 0.898094
10/01 05:38:02 AM: Global learning rate: 1.25e-05
10/01 05:38:02 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:38:12 AM: Update 40128: task edges-srl-ontonotes, batch 128 (40128): mcc: 0.8647, acc: 0.8123, precision: 0.8992, recall: 0.8353, f1: 0.8661, edges-srl-ontonotes_loss: 0.0111
10/01 05:38:22 AM: Update 40242: task edges-srl-ontonotes, batch 242 (40242): mcc: 0.8668, acc: 0.8148, precision: 0.9018, recall: 0.8368, f1: 0.8681, edges-srl-ontonotes_loss: 0.0111
10/01 05:38:32 AM: Update 40353: task edges-srl-ontonotes, batch 353 (40353): mcc: 0.8700, acc: 0.8191, precision: 0.9038, recall: 0.8410, f1: 0.8713, edges-srl-ontonotes_loss: 0.0109
10/01 05:38:42 AM: Update 40468: task edges-srl-ontonotes, batch 468 (40468): mcc: 0.8700, acc: 0.8192, precision: 0.9030, recall: 0.8418, f1: 0.8713, edges-srl-ontonotes_loss: 0.0109
10/01 05:38:52 AM: Update 40580: task edges-srl-ontonotes, batch 580 (40580): mcc: 0.8712, acc: 0.8210, precision: 0.9038, recall: 0.8435, f1: 0.8726, edges-srl-ontonotes_loss: 0.0108
10/01 05:39:02 AM: Update 40693: task edges-srl-ontonotes, batch 693 (40693): mcc: 0.8721, acc: 0.8222, precision: 0.9044, recall: 0.8445, f1: 0.8734, edges-srl-ontonotes_loss: 0.0107
10/01 05:39:12 AM: Update 40810: task edges-srl-ontonotes, batch 810 (40810): mcc: 0.8731, acc: 0.8235, precision: 0.9050, recall: 0.8459, f1: 0.8745, edges-srl-ontonotes_loss: 0.0106
10/01 05:39:22 AM: Update 40925: task edges-srl-ontonotes, batch 925 (40925): mcc: 0.8739, acc: 0.8243, precision: 0.9058, recall: 0.8467, f1: 0.8753, edges-srl-ontonotes_loss: 0.0106
10/01 05:39:32 AM: ***** Step 41000 / Validation 41 *****
10/01 05:39:32 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:39:32 AM: Validating...
10/01 05:39:32 AM: Evaluate: task edges-srl-ontonotes, batch 2 (157): mcc: 0.9079, acc: 0.8750, precision: 0.9448, recall: 0.8750, f1: 0.9086, edges-srl-ontonotes_loss: 0.0074
10/01 05:39:42 AM: Evaluate: task edges-srl-ontonotes, batch 140 (157): mcc: 0.8981, acc: 0.8641, precision: 0.9301, recall: 0.8702, f1: 0.8991, edges-srl-ontonotes_loss: 0.0087
10/01 05:39:43 AM: Updating LR scheduler:
10/01 05:39:43 AM: 	Best result seen so far for macro_avg: 0.900
10/01 05:39:43 AM: 	# validation passes without improvement: 0
10/01 05:39:43 AM: edges-srl-ontonotes_loss: training: 0.010674 validation: 0.008868
10/01 05:39:43 AM: macro_avg: validation: 0.897418
10/01 05:39:43 AM: micro_avg: validation: 0.000000
10/01 05:39:43 AM: edges-srl-ontonotes_mcc: training: 0.872316 validation: 0.896411
10/01 05:39:43 AM: edges-srl-ontonotes_acc: training: 0.821965 validation: 0.862135
10/01 05:39:43 AM: edges-srl-ontonotes_precision: training: 0.904859 validation: 0.928477
10/01 05:39:43 AM: edges-srl-ontonotes_recall: training: 0.844536 validation: 0.868370
10/01 05:39:43 AM: edges-srl-ontonotes_f1: training: 0.873657 validation: 0.897418
10/01 05:39:43 AM: Global learning rate: 6.25e-06
10/01 05:39:43 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:39:52 AM: Update 41097: task edges-srl-ontonotes, batch 97 (41097): mcc: 0.8581, acc: 0.8031, precision: 0.8966, recall: 0.8252, f1: 0.8594, edges-srl-ontonotes_loss: 0.0121
10/01 05:40:02 AM: Update 41211: task edges-srl-ontonotes, batch 211 (41211): mcc: 0.8586, acc: 0.8049, precision: 0.8956, recall: 0.8271, f1: 0.8600, edges-srl-ontonotes_loss: 0.0118
10/01 05:40:12 AM: Update 41334: task edges-srl-ontonotes, batch 334 (41334): mcc: 0.8681, acc: 0.8170, precision: 0.9031, recall: 0.8382, f1: 0.8694, edges-srl-ontonotes_loss: 0.0111
10/01 05:40:22 AM: Update 41477: task edges-srl-ontonotes, batch 477 (41477): mcc: 0.8771, acc: 0.8289, precision: 0.9098, recall: 0.8491, f1: 0.8784, edges-srl-ontonotes_loss: 0.0104
10/01 05:40:32 AM: Update 41615: task edges-srl-ontonotes, batch 615 (41615): mcc: 0.8838, acc: 0.8374, precision: 0.9147, recall: 0.8573, f1: 0.8851, edges-srl-ontonotes_loss: 0.0099
10/01 05:40:42 AM: Update 41768: task edges-srl-ontonotes, batch 768 (41768): mcc: 0.8909, acc: 0.8467, precision: 0.9197, recall: 0.8660, f1: 0.8921, edges-srl-ontonotes_loss: 0.0093
10/01 05:40:53 AM: Update 41871: task edges-srl-ontonotes, batch 871 (41871): mcc: 0.8949, acc: 0.8521, precision: 0.9227, recall: 0.8710, f1: 0.8961, edges-srl-ontonotes_loss: 0.0090
10/01 05:41:01 AM: ***** Step 42000 / Validation 42 *****
10/01 05:41:01 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:41:01 AM: Validating...
10/01 05:41:03 AM: Evaluate: task edges-srl-ontonotes, batch 28 (157): mcc: 0.8968, acc: 0.8594, precision: 0.9334, recall: 0.8645, f1: 0.8976, edges-srl-ontonotes_loss: 0.0088
10/01 05:41:12 AM: Updating LR scheduler:
10/01 05:41:12 AM: 	Best result seen so far for macro_avg: 0.900
10/01 05:41:12 AM: 	# validation passes without improvement: 1
10/01 05:41:12 AM: edges-srl-ontonotes_loss: training: 0.008834 validation: 0.008854
10/01 05:41:12 AM: macro_avg: validation: 0.898091
10/01 05:41:12 AM: micro_avg: validation: 0.000000
10/01 05:41:12 AM: edges-srl-ontonotes_mcc: training: 0.897143 validation: 0.897095
10/01 05:41:12 AM: edges-srl-ontonotes_acc: training: 0.855059 validation: 0.862905
10/01 05:41:12 AM: edges-srl-ontonotes_precision: training: 0.924479 validation: 0.929212
10/01 05:41:12 AM: edges-srl-ontonotes_recall: training: 0.873547 validation: 0.868986
10/01 05:41:12 AM: edges-srl-ontonotes_f1: training: 0.898292 validation: 0.898091
10/01 05:41:12 AM: Global learning rate: 6.25e-06
10/01 05:41:12 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:41:13 AM: Update 42010: task edges-srl-ontonotes, batch 10 (42010): mcc: 0.9106, acc: 0.8785, precision: 0.9344, recall: 0.8899, f1: 0.9116, edges-srl-ontonotes_loss: 0.0079
10/01 05:41:23 AM: Update 42167: task edges-srl-ontonotes, batch 167 (42167): mcc: 0.9171, acc: 0.8815, precision: 0.9397, recall: 0.8975, f1: 0.9181, edges-srl-ontonotes_loss: 0.0074
10/01 05:41:33 AM: Update 42319: task edges-srl-ontonotes, batch 319 (42319): mcc: 0.9184, acc: 0.8831, precision: 0.9400, recall: 0.8997, f1: 0.9194, edges-srl-ontonotes_loss: 0.0073
10/01 05:41:43 AM: Update 42478: task edges-srl-ontonotes, batch 478 (42478): mcc: 0.9167, acc: 0.8806, precision: 0.9387, recall: 0.8975, f1: 0.9177, edges-srl-ontonotes_loss: 0.0074
10/01 05:41:53 AM: Update 42619: task edges-srl-ontonotes, batch 619 (42619): mcc: 0.9147, acc: 0.8788, precision: 0.9363, recall: 0.8961, f1: 0.9158, edges-srl-ontonotes_loss: 0.0076
10/01 05:42:03 AM: Update 42761: task edges-srl-ontonotes, batch 761 (42761): mcc: 0.9140, acc: 0.8781, precision: 0.9352, recall: 0.8958, f1: 0.9151, edges-srl-ontonotes_loss: 0.0077
10/01 05:42:13 AM: Update 42884: task edges-srl-ontonotes, batch 884 (42884): mcc: 0.9112, acc: 0.8745, precision: 0.9331, recall: 0.8924, f1: 0.9123, edges-srl-ontonotes_loss: 0.0079
10/01 05:42:22 AM: ***** Step 43000 / Validation 43 *****
10/01 05:42:22 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:42:22 AM: Validating...
10/01 05:42:23 AM: Evaluate: task edges-srl-ontonotes, batch 18 (157): mcc: 0.9028, acc: 0.8676, precision: 0.9360, recall: 0.8735, f1: 0.9037, edges-srl-ontonotes_loss: 0.0082
10/01 05:42:33 AM: Evaluate: task edges-srl-ontonotes, batch 156 (157): mcc: 0.8982, acc: 0.8646, precision: 0.9293, recall: 0.8709, f1: 0.8992, edges-srl-ontonotes_loss: 0.0088
10/01 05:42:33 AM: Updating LR scheduler:
10/01 05:42:33 AM: 	Best result seen so far for macro_avg: 0.900
10/01 05:42:33 AM: 	# validation passes without improvement: 2
10/01 05:42:33 AM: edges-srl-ontonotes_loss: training: 0.008141 validation: 0.008788
10/01 05:42:33 AM: macro_avg: validation: 0.899106
10/01 05:42:33 AM: micro_avg: validation: 0.000000
10/01 05:42:33 AM: edges-srl-ontonotes_mcc: training: 0.908605 validation: 0.898092
10/01 05:42:33 AM: edges-srl-ontonotes_acc: training: 0.871283 validation: 0.864522
10/01 05:42:33 AM: edges-srl-ontonotes_precision: training: 0.930969 validation: 0.929276
10/01 05:42:33 AM: edges-srl-ontonotes_recall: training: 0.889416 validation: 0.870834
10/01 05:42:33 AM: edges-srl-ontonotes_f1: training: 0.909718 validation: 0.899106
10/01 05:42:33 AM: Global learning rate: 6.25e-06
10/01 05:42:33 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:42:45 AM: Update 43117: task edges-srl-ontonotes, batch 117 (43117): mcc: 0.8792, acc: 0.8331, precision: 0.9088, recall: 0.8541, f1: 0.8806, edges-srl-ontonotes_loss: 0.0103
10/01 05:42:55 AM: Update 43242: task edges-srl-ontonotes, batch 242 (43242): mcc: 0.8705, acc: 0.8226, precision: 0.9016, recall: 0.8441, f1: 0.8719, edges-srl-ontonotes_loss: 0.0110
10/01 05:43:05 AM: Update 43374: task edges-srl-ontonotes, batch 374 (43374): mcc: 0.8703, acc: 0.8220, precision: 0.9020, recall: 0.8434, f1: 0.8717, edges-srl-ontonotes_loss: 0.0111
10/01 05:43:15 AM: Update 43490: task edges-srl-ontonotes, batch 490 (43490): mcc: 0.8699, acc: 0.8210, precision: 0.9022, recall: 0.8423, f1: 0.8713, edges-srl-ontonotes_loss: 0.0111
10/01 05:43:25 AM: Update 43634: task edges-srl-ontonotes, batch 634 (43634): mcc: 0.8751, acc: 0.8270, precision: 0.9068, recall: 0.8480, f1: 0.8764, edges-srl-ontonotes_loss: 0.0107
10/01 05:43:35 AM: Update 43776: task edges-srl-ontonotes, batch 776 (43776): mcc: 0.8772, acc: 0.8299, precision: 0.9082, recall: 0.8508, f1: 0.8785, edges-srl-ontonotes_loss: 0.0106
10/01 05:43:45 AM: Update 43901: task edges-srl-ontonotes, batch 901 (43901): mcc: 0.8788, acc: 0.8318, precision: 0.9092, recall: 0.8528, f1: 0.8801, edges-srl-ontonotes_loss: 0.0104
10/01 05:43:52 AM: ***** Step 44000 / Validation 44 *****
10/01 05:43:52 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:43:52 AM: Validating...
10/01 05:43:55 AM: Evaluate: task edges-srl-ontonotes, batch 45 (157): mcc: 0.8921, acc: 0.8562, precision: 0.9245, recall: 0.8639, f1: 0.8931, edges-srl-ontonotes_loss: 0.0093
10/01 05:44:03 AM: Best result seen so far for edges-srl-ontonotes.
10/01 05:44:03 AM: Best result seen so far for macro.
10/01 05:44:03 AM: Updating LR scheduler:
10/01 05:44:03 AM: 	Best result seen so far for macro_avg: 0.901
10/01 05:44:03 AM: 	# validation passes without improvement: 0
10/01 05:44:03 AM: edges-srl-ontonotes_loss: training: 0.010362 validation: 0.008639
10/01 05:44:03 AM: macro_avg: validation: 0.901276
10/01 05:44:03 AM: micro_avg: validation: 0.000000
10/01 05:44:03 AM: edges-srl-ontonotes_mcc: training: 0.879784 validation: 0.900201
10/01 05:44:03 AM: edges-srl-ontonotes_acc: training: 0.833010 validation: 0.867832
10/01 05:44:03 AM: edges-srl-ontonotes_precision: training: 0.910126 validation: 0.928496
10/01 05:44:03 AM: edges-srl-ontonotes_recall: training: 0.853856 validation: 0.875606
10/01 05:44:03 AM: edges-srl-ontonotes_f1: training: 0.881093 validation: 0.901276
10/01 05:44:03 AM: Global learning rate: 6.25e-06
10/01 05:44:03 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:44:05 AM: Update 44027: task edges-srl-ontonotes, batch 27 (44027): mcc: 0.8963, acc: 0.8546, precision: 0.9239, recall: 0.8724, f1: 0.8975, edges-srl-ontonotes_loss: 0.0087
10/01 05:44:15 AM: Update 44134: task edges-srl-ontonotes, batch 134 (44134): mcc: 0.8889, acc: 0.8453, precision: 0.9181, recall: 0.8638, f1: 0.8901, edges-srl-ontonotes_loss: 0.0094
10/01 05:44:25 AM: Update 44276: task edges-srl-ontonotes, batch 276 (44276): mcc: 0.8862, acc: 0.8421, precision: 0.9142, recall: 0.8623, f1: 0.8875, edges-srl-ontonotes_loss: 0.0097
10/01 05:44:35 AM: Update 44411: task edges-srl-ontonotes, batch 411 (44411): mcc: 0.8840, acc: 0.8393, precision: 0.9130, recall: 0.8593, f1: 0.8853, edges-srl-ontonotes_loss: 0.0098
10/01 05:44:45 AM: Update 44530: task edges-srl-ontonotes, batch 530 (44530): mcc: 0.8802, acc: 0.8339, precision: 0.9103, recall: 0.8544, f1: 0.8815, edges-srl-ontonotes_loss: 0.0101
10/01 05:44:55 AM: Update 44652: task edges-srl-ontonotes, batch 652 (44652): mcc: 0.8786, acc: 0.8319, precision: 0.9091, recall: 0.8526, f1: 0.8799, edges-srl-ontonotes_loss: 0.0103
10/01 05:45:05 AM: Update 44765: task edges-srl-ontonotes, batch 765 (44765): mcc: 0.8777, acc: 0.8305, precision: 0.9085, recall: 0.8514, f1: 0.8790, edges-srl-ontonotes_loss: 0.0104
10/01 05:45:16 AM: Update 44898: task edges-srl-ontonotes, batch 898 (44898): mcc: 0.8771, acc: 0.8296, precision: 0.9078, recall: 0.8508, f1: 0.8784, edges-srl-ontonotes_loss: 0.0104
10/01 05:45:24 AM: ***** Step 45000 / Validation 45 *****
10/01 05:45:24 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:45:24 AM: Validating...
10/01 05:45:26 AM: Evaluate: task edges-srl-ontonotes, batch 19 (157): mcc: 0.9047, acc: 0.8678, precision: 0.9380, recall: 0.8752, f1: 0.9055, edges-srl-ontonotes_loss: 0.0080
10/01 05:45:36 AM: Evaluate: task edges-srl-ontonotes, batch 156 (157): mcc: 0.9005, acc: 0.8671, precision: 0.9311, recall: 0.8737, f1: 0.9015, edges-srl-ontonotes_loss: 0.0086
10/01 05:45:36 AM: Best result seen so far for edges-srl-ontonotes.
10/01 05:45:36 AM: Best result seen so far for macro.
10/01 05:45:36 AM: Updating LR scheduler:
10/01 05:45:36 AM: 	Best result seen so far for macro_avg: 0.901
10/01 05:45:36 AM: 	# validation passes without improvement: 0
10/01 05:45:36 AM: edges-srl-ontonotes_loss: training: 0.010445 validation: 0.008605
10/01 05:45:36 AM: macro_avg: validation: 0.901394
10/01 05:45:36 AM: micro_avg: validation: 0.000000
10/01 05:45:36 AM: edges-srl-ontonotes_mcc: training: 0.876059 validation: 0.900395
10/01 05:45:36 AM: edges-srl-ontonotes_acc: training: 0.828327 validation: 0.867062
10/01 05:45:36 AM: edges-srl-ontonotes_precision: training: 0.906848 validation: 0.931009
10/01 05:45:36 AM: edges-srl-ontonotes_recall: training: 0.849818 validation: 0.873605
10/01 05:45:36 AM: edges-srl-ontonotes_f1: training: 0.877407 validation: 0.901394
10/01 05:45:36 AM: Global learning rate: 6.25e-06
10/01 05:45:36 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:45:46 AM: Update 45095: task edges-srl-ontonotes, batch 95 (45095): mcc: 0.8629, acc: 0.8124, precision: 0.8963, recall: 0.8346, f1: 0.8643, edges-srl-ontonotes_loss: 0.0111
10/01 05:45:56 AM: Update 45221: task edges-srl-ontonotes, batch 221 (45221): mcc: 0.8584, acc: 0.8063, precision: 0.8938, recall: 0.8283, f1: 0.8599, edges-srl-ontonotes_loss: 0.0118
10/01 05:46:06 AM: Update 45340: task edges-srl-ontonotes, batch 340 (45340): mcc: 0.8572, acc: 0.8049, precision: 0.8926, recall: 0.8272, f1: 0.8586, edges-srl-ontonotes_loss: 0.0118
10/01 05:46:16 AM: Update 45454: task edges-srl-ontonotes, batch 454 (45454): mcc: 0.8541, acc: 0.8012, precision: 0.8898, recall: 0.8239, f1: 0.8556, edges-srl-ontonotes_loss: 0.0121
10/01 05:46:26 AM: Update 45582: task edges-srl-ontonotes, batch 582 (45582): mcc: 0.8540, acc: 0.8015, precision: 0.8894, recall: 0.8241, f1: 0.8555, edges-srl-ontonotes_loss: 0.0121
10/01 05:46:36 AM: Update 45695: task edges-srl-ontonotes, batch 695 (45695): mcc: 0.8553, acc: 0.8025, precision: 0.8904, recall: 0.8257, f1: 0.8568, edges-srl-ontonotes_loss: 0.0119
10/01 05:46:46 AM: Update 45820: task edges-srl-ontonotes, batch 820 (45820): mcc: 0.8590, acc: 0.8069, precision: 0.8936, recall: 0.8296, f1: 0.8604, edges-srl-ontonotes_loss: 0.0116
10/01 05:46:56 AM: Update 45935: task edges-srl-ontonotes, batch 935 (45935): mcc: 0.8612, acc: 0.8097, precision: 0.8954, recall: 0.8322, f1: 0.8626, edges-srl-ontonotes_loss: 0.0114
10/01 05:47:03 AM: ***** Step 46000 / Validation 46 *****
10/01 05:47:03 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:47:03 AM: Validating...
10/01 05:47:06 AM: Evaluate: task edges-srl-ontonotes, batch 46 (157): mcc: 0.8904, acc: 0.8543, precision: 0.9229, recall: 0.8621, f1: 0.8915, edges-srl-ontonotes_loss: 0.0092
10/01 05:47:14 AM: Updating LR scheduler:
10/01 05:47:14 AM: 	Best result seen so far for macro_avg: 0.901
10/01 05:47:14 AM: 	# validation passes without improvement: 1
10/01 05:47:14 AM: edges-srl-ontonotes_loss: training: 0.011329 validation: 0.008651
10/01 05:47:14 AM: macro_avg: validation: 0.899913
10/01 05:47:14 AM: micro_avg: validation: 0.000000
10/01 05:47:14 AM: edges-srl-ontonotes_mcc: training: 0.862756 validation: 0.898870
10/01 05:47:14 AM: edges-srl-ontonotes_acc: training: 0.811512 validation: 0.865907
10/01 05:47:14 AM: edges-srl-ontonotes_precision: training: 0.896674 validation: 0.928811
10/01 05:47:14 AM: edges-srl-ontonotes_recall: training: 0.833968 validation: 0.872758
10/01 05:47:14 AM: edges-srl-ontonotes_f1: training: 0.864185 validation: 0.899913
10/01 05:47:14 AM: Global learning rate: 6.25e-06
10/01 05:47:14 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:47:16 AM: Update 46025: task edges-srl-ontonotes, batch 25 (46025): mcc: 0.8765, acc: 0.8242, precision: 0.9129, recall: 0.8451, f1: 0.8777, edges-srl-ontonotes_loss: 0.0101
10/01 05:47:26 AM: Update 46151: task edges-srl-ontonotes, batch 151 (46151): mcc: 0.8783, acc: 0.8291, precision: 0.9115, recall: 0.8497, f1: 0.8795, edges-srl-ontonotes_loss: 0.0103
10/01 05:47:36 AM: Update 46278: task edges-srl-ontonotes, batch 278 (46278): mcc: 0.8778, acc: 0.8297, precision: 0.9099, recall: 0.8502, f1: 0.8791, edges-srl-ontonotes_loss: 0.0102
10/01 05:47:46 AM: Update 46374: task edges-srl-ontonotes, batch 374 (46374): mcc: 0.8797, acc: 0.8327, precision: 0.9104, recall: 0.8533, f1: 0.8809, edges-srl-ontonotes_loss: 0.0102
10/01 05:47:56 AM: Update 46499: task edges-srl-ontonotes, batch 499 (46499): mcc: 0.8810, acc: 0.8340, precision: 0.9115, recall: 0.8549, f1: 0.8823, edges-srl-ontonotes_loss: 0.0101
10/01 05:48:06 AM: Update 46615: task edges-srl-ontonotes, batch 615 (46615): mcc: 0.8818, acc: 0.8353, precision: 0.9120, recall: 0.8559, f1: 0.8830, edges-srl-ontonotes_loss: 0.0100
10/01 05:48:16 AM: Update 46731: task edges-srl-ontonotes, batch 731 (46731): mcc: 0.8800, acc: 0.8328, precision: 0.9110, recall: 0.8535, f1: 0.8813, edges-srl-ontonotes_loss: 0.0101
10/01 05:48:26 AM: Update 46844: task edges-srl-ontonotes, batch 844 (46844): mcc: 0.8782, acc: 0.8306, precision: 0.9094, recall: 0.8515, f1: 0.8795, edges-srl-ontonotes_loss: 0.0103
10/01 05:48:36 AM: Update 46950: task edges-srl-ontonotes, batch 950 (46950): mcc: 0.8772, acc: 0.8292, precision: 0.9089, recall: 0.8501, f1: 0.8785, edges-srl-ontonotes_loss: 0.0104
10/01 05:48:40 AM: ***** Step 47000 / Validation 47 *****
10/01 05:48:40 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:48:40 AM: Validating...
10/01 05:48:46 AM: Evaluate: task edges-srl-ontonotes, batch 87 (157): mcc: 0.8944, acc: 0.8583, precision: 0.9283, recall: 0.8646, f1: 0.8953, edges-srl-ontonotes_loss: 0.0089
10/01 05:48:51 AM: Updating LR scheduler:
10/01 05:48:51 AM: 	Best result seen so far for macro_avg: 0.901
10/01 05:48:51 AM: 	# validation passes without improvement: 2
10/01 05:48:51 AM: edges-srl-ontonotes_loss: training: 0.010426 validation: 0.008704
10/01 05:48:51 AM: macro_avg: validation: 0.899253
10/01 05:48:51 AM: micro_avg: validation: 0.000000
10/01 05:48:51 AM: edges-srl-ontonotes_mcc: training: 0.876637 validation: 0.898233
10/01 05:48:51 AM: edges-srl-ontonotes_acc: training: 0.828512 validation: 0.864676
10/01 05:48:51 AM: edges-srl-ontonotes_precision: training: 0.908414 validation: 0.929152
10/01 05:48:51 AM: edges-srl-ontonotes_recall: training: 0.849450 validation: 0.871219
10/01 05:48:51 AM: edges-srl-ontonotes_f1: training: 0.877943 validation: 0.899253
10/01 05:48:51 AM: Global learning rate: 6.25e-06
10/01 05:48:51 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:48:56 AM: Update 47063: task edges-srl-ontonotes, batch 63 (47063): mcc: 0.8689, acc: 0.8207, precision: 0.9038, recall: 0.8390, f1: 0.8702, edges-srl-ontonotes_loss: 0.0108
10/01 05:49:06 AM: Update 47189: task edges-srl-ontonotes, batch 189 (47189): mcc: 0.8680, acc: 0.8187, precision: 0.9044, recall: 0.8367, f1: 0.8692, edges-srl-ontonotes_loss: 0.0110
10/01 05:49:16 AM: Update 47286: task edges-srl-ontonotes, batch 286 (47286): mcc: 0.8682, acc: 0.8182, precision: 0.9044, recall: 0.8372, f1: 0.8695, edges-srl-ontonotes_loss: 0.0109
10/01 05:49:26 AM: Update 47411: task edges-srl-ontonotes, batch 411 (47411): mcc: 0.8681, acc: 0.8187, precision: 0.9029, recall: 0.8384, f1: 0.8694, edges-srl-ontonotes_loss: 0.0110
10/01 05:49:36 AM: Update 47541: task edges-srl-ontonotes, batch 541 (47541): mcc: 0.8675, acc: 0.8177, precision: 0.9019, recall: 0.8381, f1: 0.8688, edges-srl-ontonotes_loss: 0.0110
10/01 05:49:46 AM: Update 47658: task edges-srl-ontonotes, batch 658 (47658): mcc: 0.8693, acc: 0.8199, precision: 0.9028, recall: 0.8407, f1: 0.8706, edges-srl-ontonotes_loss: 0.0109
10/01 05:49:56 AM: Update 47786: task edges-srl-ontonotes, batch 786 (47786): mcc: 0.8702, acc: 0.8211, precision: 0.9029, recall: 0.8423, f1: 0.8715, edges-srl-ontonotes_loss: 0.0108
10/01 05:50:07 AM: Update 47894: task edges-srl-ontonotes, batch 894 (47894): mcc: 0.8707, acc: 0.8215, precision: 0.9032, recall: 0.8430, f1: 0.8721, edges-srl-ontonotes_loss: 0.0108
10/01 05:50:15 AM: ***** Step 48000 / Validation 48 *****
10/01 05:50:15 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:50:15 AM: Validating...
10/01 05:50:17 AM: Evaluate: task edges-srl-ontonotes, batch 25 (157): mcc: 0.8941, acc: 0.8583, precision: 0.9275, recall: 0.8649, f1: 0.8951, edges-srl-ontonotes_loss: 0.0087
10/01 05:50:26 AM: Updating LR scheduler:
10/01 05:50:26 AM: 	Best result seen so far for macro_avg: 0.901
10/01 05:50:26 AM: 	# validation passes without improvement: 3
10/01 05:50:26 AM: edges-srl-ontonotes_loss: training: 0.010708 validation: 0.008769
10/01 05:50:26 AM: macro_avg: validation: 0.899405
10/01 05:50:26 AM: micro_avg: validation: 0.000000
10/01 05:50:26 AM: edges-srl-ontonotes_mcc: training: 0.871486 validation: 0.898364
10/01 05:50:26 AM: edges-srl-ontonotes_acc: training: 0.822239 validation: 0.865291
10/01 05:50:26 AM: edges-srl-ontonotes_precision: training: 0.904083 validation: 0.928601
10/01 05:50:26 AM: edges-srl-ontonotes_recall: training: 0.843679 validation: 0.871988
10/01 05:50:26 AM: edges-srl-ontonotes_f1: training: 0.872837 validation: 0.899405
10/01 05:50:26 AM: Global learning rate: 6.25e-06
10/01 05:50:26 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:50:27 AM: Update 48004: task edges-srl-ontonotes, batch 4 (48004): mcc: 0.8993, acc: 0.8485, precision: 0.9322, recall: 0.8705, f1: 0.9003, edges-srl-ontonotes_loss: 0.0090
10/01 05:50:37 AM: Update 48119: task edges-srl-ontonotes, batch 119 (48119): mcc: 0.8770, acc: 0.8265, precision: 0.9090, recall: 0.8497, f1: 0.8783, edges-srl-ontonotes_loss: 0.0102
10/01 05:50:47 AM: Update 48200: task edges-srl-ontonotes, batch 200 (48200): mcc: 0.8738, acc: 0.8225, precision: 0.9070, recall: 0.8454, f1: 0.8751, edges-srl-ontonotes_loss: 0.0105
10/01 05:50:57 AM: Update 48311: task edges-srl-ontonotes, batch 311 (48311): mcc: 0.8674, acc: 0.8140, precision: 0.9026, recall: 0.8373, f1: 0.8687, edges-srl-ontonotes_loss: 0.0110
10/01 05:51:07 AM: Update 48423: task edges-srl-ontonotes, batch 423 (48423): mcc: 0.8647, acc: 0.8105, precision: 0.9005, recall: 0.8341, f1: 0.8661, edges-srl-ontonotes_loss: 0.0111
10/01 05:51:17 AM: Update 48536: task edges-srl-ontonotes, batch 536 (48536): mcc: 0.8657, acc: 0.8124, precision: 0.9010, recall: 0.8355, f1: 0.8670, edges-srl-ontonotes_loss: 0.0111
10/01 05:51:27 AM: Update 48667: task edges-srl-ontonotes, batch 667 (48667): mcc: 0.8718, acc: 0.8208, precision: 0.9055, recall: 0.8430, f1: 0.8731, edges-srl-ontonotes_loss: 0.0107
10/01 05:51:37 AM: Update 48791: task edges-srl-ontonotes, batch 791 (48791): mcc: 0.8756, acc: 0.8259, precision: 0.9082, recall: 0.8477, f1: 0.8769, edges-srl-ontonotes_loss: 0.0103
10/01 05:51:47 AM: Update 48939: task edges-srl-ontonotes, batch 939 (48939): mcc: 0.8827, acc: 0.8353, precision: 0.9131, recall: 0.8565, f1: 0.8839, edges-srl-ontonotes_loss: 0.0099
10/01 05:51:51 AM: ***** Step 49000 / Validation 49 *****
10/01 05:51:51 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:51:51 AM: Validating...
10/01 05:51:57 AM: Evaluate: task edges-srl-ontonotes, batch 88 (157): mcc: 0.8941, acc: 0.8569, precision: 0.9294, recall: 0.8630, f1: 0.8950, edges-srl-ontonotes_loss: 0.0090
10/01 05:52:02 AM: Updating LR scheduler:
10/01 05:52:02 AM: 	Best result seen so far for macro_avg: 0.901
10/01 05:52:02 AM: 	# validation passes without improvement: 0
10/01 05:52:02 AM: edges-srl-ontonotes_loss: training: 0.009666 validation: 0.008774
10/01 05:52:02 AM: macro_avg: validation: 0.898878
10/01 05:52:02 AM: micro_avg: validation: 0.000000
10/01 05:52:02 AM: edges-srl-ontonotes_mcc: training: 0.885346 validation: 0.897897
10/01 05:52:02 AM: edges-srl-ontonotes_acc: training: 0.838992 validation: 0.863521
10/01 05:52:02 AM: edges-srl-ontonotes_precision: training: 0.915129 validation: 0.930106
10/01 05:52:02 AM: edges-srl-ontonotes_recall: training: 0.859781 validation: 0.869679
10/01 05:52:02 AM: edges-srl-ontonotes_f1: training: 0.886592 validation: 0.898878
10/01 05:52:02 AM: Global learning rate: 3.125e-06
10/01 05:52:02 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:52:07 AM: Update 49082: task edges-srl-ontonotes, batch 82 (49082): mcc: 0.9223, acc: 0.8861, precision: 0.9458, recall: 0.9015, f1: 0.9231, edges-srl-ontonotes_loss: 0.0067
10/01 05:52:17 AM: Update 49229: task edges-srl-ontonotes, batch 229 (49229): mcc: 0.9204, acc: 0.8842, precision: 0.9431, recall: 0.9005, f1: 0.9213, edges-srl-ontonotes_loss: 0.0070
10/01 05:52:27 AM: Update 49366: task edges-srl-ontonotes, batch 366 (49366): mcc: 0.9187, acc: 0.8824, precision: 0.9416, recall: 0.8987, f1: 0.9197, edges-srl-ontonotes_loss: 0.0072
10/01 05:52:37 AM: Update 49475: task edges-srl-ontonotes, batch 475 (49475): mcc: 0.9189, acc: 0.8829, precision: 0.9413, recall: 0.8994, f1: 0.9199, edges-srl-ontonotes_loss: 0.0072
10/01 05:52:47 AM: Update 49629: task edges-srl-ontonotes, batch 629 (49629): mcc: 0.9177, acc: 0.8816, precision: 0.9401, recall: 0.8981, f1: 0.9187, edges-srl-ontonotes_loss: 0.0073
10/01 05:52:57 AM: Update 49762: task edges-srl-ontonotes, batch 762 (49762): mcc: 0.9179, acc: 0.8821, precision: 0.9399, recall: 0.8987, f1: 0.9189, edges-srl-ontonotes_loss: 0.0073
10/01 05:53:07 AM: Update 49928: task edges-srl-ontonotes, batch 928 (49928): mcc: 0.9159, acc: 0.8799, precision: 0.9376, recall: 0.8972, f1: 0.9169, edges-srl-ontonotes_loss: 0.0075
10/01 05:53:12 AM: ***** Step 50000 / Validation 50 *****
10/01 05:53:12 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:53:12 AM: Validating...
10/01 05:53:17 AM: Evaluate: task edges-srl-ontonotes, batch 80 (157): mcc: 0.8926, acc: 0.8552, precision: 0.9291, recall: 0.8606, f1: 0.8935, edges-srl-ontonotes_loss: 0.0092
10/01 05:53:23 AM: Updating LR scheduler:
10/01 05:53:23 AM: 	Best result seen so far for macro_avg: 0.901
10/01 05:53:23 AM: 	# validation passes without improvement: 1
10/01 05:53:23 AM: edges-srl-ontonotes_loss: training: 0.007482 validation: 0.008762
10/01 05:53:23 AM: macro_avg: validation: 0.898945
10/01 05:53:23 AM: micro_avg: validation: 0.000000
10/01 05:53:23 AM: edges-srl-ontonotes_mcc: training: 0.915770 validation: 0.897983
10/01 05:53:23 AM: edges-srl-ontonotes_acc: training: 0.879864 validation: 0.863367
10/01 05:53:23 AM: edges-srl-ontonotes_precision: training: 0.937311 validation: 0.930691
10/01 05:53:23 AM: edges-srl-ontonotes_recall: training: 0.897160 validation: 0.869294
10/01 05:53:23 AM: edges-srl-ontonotes_f1: training: 0.916796 validation: 0.898945
10/01 05:53:23 AM: Global learning rate: 3.125e-06
10/01 05:53:23 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:53:27 AM: Update 50055: task edges-srl-ontonotes, batch 55 (50055): mcc: 0.9037, acc: 0.8675, precision: 0.9263, recall: 0.8845, f1: 0.9049, edges-srl-ontonotes_loss: 0.0083
10/01 05:53:37 AM: Update 50187: task edges-srl-ontonotes, batch 187 (50187): mcc: 0.8873, acc: 0.8442, precision: 0.9164, recall: 0.8624, f1: 0.8886, edges-srl-ontonotes_loss: 0.0096
10/01 05:53:47 AM: Update 50316: task edges-srl-ontonotes, batch 316 (50316): mcc: 0.8860, acc: 0.8422, precision: 0.9148, recall: 0.8613, f1: 0.8873, edges-srl-ontonotes_loss: 0.0097
10/01 05:53:57 AM: Update 50406: task edges-srl-ontonotes, batch 406 (50406): mcc: 0.8831, acc: 0.8375, precision: 0.9132, recall: 0.8573, f1: 0.8844, edges-srl-ontonotes_loss: 0.0100
10/01 05:54:07 AM: Update 50531: task edges-srl-ontonotes, batch 531 (50531): mcc: 0.8791, acc: 0.8325, precision: 0.9099, recall: 0.8526, f1: 0.8804, edges-srl-ontonotes_loss: 0.0103
10/01 05:54:17 AM: Update 50664: task edges-srl-ontonotes, batch 664 (50664): mcc: 0.8769, acc: 0.8298, precision: 0.9081, recall: 0.8503, f1: 0.8783, edges-srl-ontonotes_loss: 0.0105
10/01 05:54:27 AM: Update 50789: task edges-srl-ontonotes, batch 789 (50789): mcc: 0.8761, acc: 0.8289, precision: 0.9074, recall: 0.8494, f1: 0.8774, edges-srl-ontonotes_loss: 0.0105
10/01 05:54:38 AM: Update 50936: task edges-srl-ontonotes, batch 936 (50936): mcc: 0.8783, acc: 0.8317, precision: 0.9088, recall: 0.8523, f1: 0.8796, edges-srl-ontonotes_loss: 0.0103
10/01 05:54:42 AM: ***** Step 51000 / Validation 51 *****
10/01 05:54:42 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:54:42 AM: Validating...
10/01 05:54:48 AM: Evaluate: task edges-srl-ontonotes, batch 77 (157): mcc: 0.8935, acc: 0.8583, precision: 0.9260, recall: 0.8652, f1: 0.8946, edges-srl-ontonotes_loss: 0.0091
10/01 05:54:53 AM: Updating LR scheduler:
10/01 05:54:53 AM: 	Best result seen so far for macro_avg: 0.901
10/01 05:54:53 AM: 	# validation passes without improvement: 2
10/01 05:54:53 AM: edges-srl-ontonotes_loss: training: 0.010333 validation: 0.008664
10/01 05:54:53 AM: macro_avg: validation: 0.900317
10/01 05:54:53 AM: micro_avg: validation: 0.000000
10/01 05:54:53 AM: edges-srl-ontonotes_mcc: training: 0.878317 validation: 0.899254
10/01 05:54:53 AM: edges-srl-ontonotes_acc: training: 0.831713 validation: 0.866523
10/01 05:54:53 AM: edges-srl-ontonotes_precision: training: 0.908876 validation: 0.928367
10/01 05:54:53 AM: edges-srl-ontonotes_recall: training: 0.852227 validation: 0.873913
10/01 05:54:53 AM: edges-srl-ontonotes_f1: training: 0.879640 validation: 0.900317
10/01 05:54:53 AM: Global learning rate: 3.125e-06
10/01 05:54:53 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:54:58 AM: Update 51047: task edges-srl-ontonotes, batch 47 (51047): mcc: 0.8916, acc: 0.8458, precision: 0.9160, recall: 0.8710, f1: 0.8929, edges-srl-ontonotes_loss: 0.0096
10/01 05:55:08 AM: Update 51186: task edges-srl-ontonotes, batch 186 (51186): mcc: 0.8888, acc: 0.8439, precision: 0.9173, recall: 0.8643, f1: 0.8901, edges-srl-ontonotes_loss: 0.0096
10/01 05:55:18 AM: Update 51309: task edges-srl-ontonotes, batch 309 (51309): mcc: 0.8894, acc: 0.8451, precision: 0.9168, recall: 0.8660, f1: 0.8907, edges-srl-ontonotes_loss: 0.0094
10/01 05:55:28 AM: Update 51434: task edges-srl-ontonotes, batch 434 (51434): mcc: 0.8877, acc: 0.8434, precision: 0.9151, recall: 0.8643, f1: 0.8890, edges-srl-ontonotes_loss: 0.0096
10/01 05:55:38 AM: Update 51564: task edges-srl-ontonotes, batch 564 (51564): mcc: 0.8866, acc: 0.8420, precision: 0.9139, recall: 0.8633, f1: 0.8879, edges-srl-ontonotes_loss: 0.0097
10/01 05:55:49 AM: Update 51662: task edges-srl-ontonotes, batch 662 (51662): mcc: 0.8861, acc: 0.8413, precision: 0.9135, recall: 0.8628, f1: 0.8874, edges-srl-ontonotes_loss: 0.0097
10/01 05:55:59 AM: Update 51786: task edges-srl-ontonotes, batch 786 (51786): mcc: 0.8834, acc: 0.8382, precision: 0.9116, recall: 0.8595, f1: 0.8848, edges-srl-ontonotes_loss: 0.0099
10/01 05:56:09 AM: Update 51906: task edges-srl-ontonotes, batch 906 (51906): mcc: 0.8816, acc: 0.8356, precision: 0.9102, recall: 0.8573, f1: 0.8829, edges-srl-ontonotes_loss: 0.0101
10/01 05:56:17 AM: ***** Step 52000 / Validation 52 *****
10/01 05:56:17 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:56:17 AM: Validating...
10/01 05:56:19 AM: Evaluate: task edges-srl-ontonotes, batch 27 (157): mcc: 0.8993, acc: 0.8640, precision: 0.9317, recall: 0.8710, f1: 0.9003, edges-srl-ontonotes_loss: 0.0087
10/01 05:56:28 AM: Updating LR scheduler:
10/01 05:56:28 AM: 	Best result seen so far for macro_avg: 0.901
10/01 05:56:28 AM: 	# validation passes without improvement: 3
10/01 05:56:28 AM: edges-srl-ontonotes_loss: training: 0.010165 validation: 0.008625
10/01 05:56:28 AM: macro_avg: validation: 0.901310
10/01 05:56:28 AM: micro_avg: validation: 0.000000
10/01 05:56:28 AM: edges-srl-ontonotes_mcc: training: 0.880504 validation: 0.900299
10/01 05:56:28 AM: edges-srl-ontonotes_acc: training: 0.833971 validation: 0.867062
10/01 05:56:28 AM: edges-srl-ontonotes_precision: training: 0.909483 validation: 0.930568
10/01 05:56:28 AM: edges-srl-ontonotes_recall: training: 0.855842 validation: 0.873836
10/01 05:56:28 AM: edges-srl-ontonotes_f1: training: 0.881847 validation: 0.901310
10/01 05:56:28 AM: Global learning rate: 3.125e-06
10/01 05:56:28 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:56:29 AM: Update 52008: task edges-srl-ontonotes, batch 8 (52008): mcc: 0.8738, acc: 0.8219, precision: 0.9022, recall: 0.8500, f1: 0.8753, edges-srl-ontonotes_loss: 0.0106
10/01 05:56:39 AM: Update 52143: task edges-srl-ontonotes, batch 143 (52143): mcc: 0.8749, acc: 0.8265, precision: 0.9058, recall: 0.8485, f1: 0.8762, edges-srl-ontonotes_loss: 0.0107
10/01 05:56:49 AM: Update 52276: task edges-srl-ontonotes, batch 276 (52276): mcc: 0.8734, acc: 0.8245, precision: 0.9046, recall: 0.8469, f1: 0.8748, edges-srl-ontonotes_loss: 0.0107
10/01 05:56:59 AM: Update 52393: task edges-srl-ontonotes, batch 393 (52393): mcc: 0.8672, acc: 0.8173, precision: 0.9002, recall: 0.8392, f1: 0.8686, edges-srl-ontonotes_loss: 0.0112
10/01 05:57:09 AM: Update 52519: task edges-srl-ontonotes, batch 519 (52519): mcc: 0.8637, acc: 0.8134, precision: 0.8972, recall: 0.8354, f1: 0.8652, edges-srl-ontonotes_loss: 0.0114
10/01 05:57:19 AM: Update 52610: task edges-srl-ontonotes, batch 610 (52610): mcc: 0.8633, acc: 0.8127, precision: 0.8972, recall: 0.8346, f1: 0.8648, edges-srl-ontonotes_loss: 0.0115
10/01 05:57:29 AM: Update 52740: task edges-srl-ontonotes, batch 740 (52740): mcc: 0.8617, acc: 0.8109, precision: 0.8957, recall: 0.8329, f1: 0.8632, edges-srl-ontonotes_loss: 0.0116
10/01 05:57:39 AM: Update 52856: task edges-srl-ontonotes, batch 856 (52856): mcc: 0.8603, acc: 0.8089, precision: 0.8943, recall: 0.8315, f1: 0.8618, edges-srl-ontonotes_loss: 0.0117
10/01 05:57:49 AM: Update 52961: task edges-srl-ontonotes, batch 961 (52961): mcc: 0.8611, acc: 0.8101, precision: 0.8947, recall: 0.8327, f1: 0.8626, edges-srl-ontonotes_loss: 0.0116
10/01 05:57:53 AM: ***** Step 53000 / Validation 53 *****
10/01 05:57:53 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:57:53 AM: Validating...
10/01 05:57:59 AM: Evaluate: task edges-srl-ontonotes, batch 90 (157): mcc: 0.8970, acc: 0.8606, precision: 0.9304, recall: 0.8676, f1: 0.8979, edges-srl-ontonotes_loss: 0.0088
10/01 05:58:04 AM: Updating LR scheduler:
10/01 05:58:04 AM: 	Best result seen so far for macro_avg: 0.901
10/01 05:58:04 AM: 	# validation passes without improvement: 0
10/01 05:58:04 AM: edges-srl-ontonotes_loss: training: 0.011526 validation: 0.008626
10/01 05:58:04 AM: macro_avg: validation: 0.900659
10/01 05:58:04 AM: micro_avg: validation: 0.000000
10/01 05:58:04 AM: edges-srl-ontonotes_mcc: training: 0.862194 validation: 0.899643
10/01 05:58:04 AM: edges-srl-ontonotes_acc: training: 0.811334 validation: 0.866523
10/01 05:58:04 AM: edges-srl-ontonotes_precision: training: 0.895702 validation: 0.930053
10/01 05:58:04 AM: edges-srl-ontonotes_recall: training: 0.833807 validation: 0.873066
10/01 05:58:04 AM: edges-srl-ontonotes_f1: training: 0.863647 validation: 0.900659
10/01 05:58:04 AM: Global learning rate: 1.5625e-06
10/01 05:58:04 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:58:09 AM: Update 53063: task edges-srl-ontonotes, batch 63 (53063): mcc: 0.8827, acc: 0.8359, precision: 0.9158, recall: 0.8542, f1: 0.8839, edges-srl-ontonotes_loss: 0.0102
10/01 05:58:19 AM: Update 53178: task edges-srl-ontonotes, batch 178 (53178): mcc: 0.8808, acc: 0.8346, precision: 0.9124, recall: 0.8537, f1: 0.8821, edges-srl-ontonotes_loss: 0.0100
10/01 05:58:29 AM: Update 53281: task edges-srl-ontonotes, batch 281 (53281): mcc: 0.8793, acc: 0.8314, precision: 0.9117, recall: 0.8514, f1: 0.8805, edges-srl-ontonotes_loss: 0.0100
10/01 05:58:39 AM: Update 53410: task edges-srl-ontonotes, batch 410 (53410): mcc: 0.8800, acc: 0.8320, precision: 0.9118, recall: 0.8527, f1: 0.8813, edges-srl-ontonotes_loss: 0.0100
10/01 05:58:49 AM: Update 53535: task edges-srl-ontonotes, batch 535 (53535): mcc: 0.8791, acc: 0.8310, precision: 0.9105, recall: 0.8522, f1: 0.8804, edges-srl-ontonotes_loss: 0.0101
10/01 05:59:00 AM: Update 53625: task edges-srl-ontonotes, batch 625 (53625): mcc: 0.8797, acc: 0.8320, precision: 0.9110, recall: 0.8528, f1: 0.8810, edges-srl-ontonotes_loss: 0.0101
10/01 05:59:10 AM: Update 53736: task edges-srl-ontonotes, batch 736 (53736): mcc: 0.8799, acc: 0.8322, precision: 0.9113, recall: 0.8529, f1: 0.8812, edges-srl-ontonotes_loss: 0.0101
10/01 05:59:20 AM: Update 53851: task edges-srl-ontonotes, batch 851 (53851): mcc: 0.8809, acc: 0.8335, precision: 0.9121, recall: 0.8541, f1: 0.8821, edges-srl-ontonotes_loss: 0.0100
10/01 05:59:30 AM: Update 53962: task edges-srl-ontonotes, batch 962 (53962): mcc: 0.8790, acc: 0.8312, precision: 0.9105, recall: 0.8519, f1: 0.8803, edges-srl-ontonotes_loss: 0.0102
10/01 05:59:33 AM: ***** Step 54000 / Validation 54 *****
10/01 05:59:33 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 05:59:33 AM: Validating...
10/01 05:59:40 AM: Evaluate: task edges-srl-ontonotes, batch 99 (157): mcc: 0.8979, acc: 0.8629, precision: 0.9302, recall: 0.8696, f1: 0.8989, edges-srl-ontonotes_loss: 0.0086
10/01 05:59:44 AM: Updating LR scheduler:
10/01 05:59:44 AM: 	Best result seen so far for macro_avg: 0.901
10/01 05:59:44 AM: 	# validation passes without improvement: 1
10/01 05:59:44 AM: edges-srl-ontonotes_loss: training: 0.010177 validation: 0.008641
10/01 05:59:44 AM: macro_avg: validation: 0.900436
10/01 05:59:44 AM: micro_avg: validation: 0.000000
10/01 05:59:44 AM: edges-srl-ontonotes_mcc: training: 0.878668 validation: 0.899387
10/01 05:59:44 AM: edges-srl-ontonotes_acc: training: 0.830905 validation: 0.866985
10/01 05:59:44 AM: edges-srl-ontonotes_precision: training: 0.910319 validation: 0.928881
10/01 05:59:44 AM: edges-srl-ontonotes_recall: training: 0.851540 validation: 0.873682
10/01 05:59:44 AM: edges-srl-ontonotes_f1: training: 0.879949 validation: 0.900436
10/01 05:59:44 AM: Global learning rate: 1.5625e-06
10/01 05:59:44 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 05:59:50 AM: Update 54074: task edges-srl-ontonotes, batch 74 (54074): mcc: 0.8705, acc: 0.8171, precision: 0.9062, recall: 0.8399, f1: 0.8718, edges-srl-ontonotes_loss: 0.0110
10/01 06:00:00 AM: Update 54192: task edges-srl-ontonotes, batch 192 (54192): mcc: 0.8694, acc: 0.8171, precision: 0.9051, recall: 0.8389, f1: 0.8707, edges-srl-ontonotes_loss: 0.0110
10/01 06:00:10 AM: Update 54323: task edges-srl-ontonotes, batch 323 (54323): mcc: 0.8692, acc: 0.8185, precision: 0.9035, recall: 0.8399, f1: 0.8705, edges-srl-ontonotes_loss: 0.0111
10/01 06:00:20 AM: Update 54449: task edges-srl-ontonotes, batch 449 (54449): mcc: 0.8683, acc: 0.8172, precision: 0.9031, recall: 0.8386, f1: 0.8697, edges-srl-ontonotes_loss: 0.0110
10/01 06:00:30 AM: Update 54567: task edges-srl-ontonotes, batch 567 (54567): mcc: 0.8683, acc: 0.8173, precision: 0.9022, recall: 0.8393, f1: 0.8696, edges-srl-ontonotes_loss: 0.0110
10/01 06:00:40 AM: Update 54689: task edges-srl-ontonotes, batch 689 (54689): mcc: 0.8681, acc: 0.8173, precision: 0.9021, recall: 0.8391, f1: 0.8695, edges-srl-ontonotes_loss: 0.0111
10/01 06:00:51 AM: Update 54792: task edges-srl-ontonotes, batch 792 (54792): mcc: 0.8679, acc: 0.8173, precision: 0.9019, recall: 0.8389, f1: 0.8693, edges-srl-ontonotes_loss: 0.0111
10/01 06:01:01 AM: Update 54920: task edges-srl-ontonotes, batch 920 (54920): mcc: 0.8680, acc: 0.8175, precision: 0.9015, recall: 0.8394, f1: 0.8693, edges-srl-ontonotes_loss: 0.0110
10/01 06:01:08 AM: ***** Step 55000 / Validation 55 *****
10/01 06:01:08 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
10/01 06:01:08 AM: Validating...
10/01 06:01:11 AM: Evaluate: task edges-srl-ontonotes, batch 42 (157): mcc: 0.8915, acc: 0.8541, precision: 0.9270, recall: 0.8603, f1: 0.8924, edges-srl-ontonotes_loss: 0.0093
10/01 06:01:20 AM: Updating LR scheduler:
10/01 06:01:20 AM: 	Best result seen so far for macro_avg: 0.901
10/01 06:01:20 AM: 	# validation passes without improvement: 2
10/01 06:01:20 AM: Ran out of early stopping patience. Stopping training.
10/01 06:01:20 AM: edges-srl-ontonotes_loss: training: 0.010973 validation: 0.008656
10/01 06:01:20 AM: macro_avg: validation: 0.900183
10/01 06:01:20 AM: micro_avg: validation: 0.000000
10/01 06:01:20 AM: edges-srl-ontonotes_mcc: training: 0.868387 validation: 0.899185
10/01 06:01:20 AM: edges-srl-ontonotes_acc: training: 0.818253 validation: 0.866138
10/01 06:01:20 AM: edges-srl-ontonotes_precision: training: 0.901420 validation: 0.930349
10/01 06:01:20 AM: edges-srl-ontonotes_recall: training: 0.840263 validation: 0.871911
10/01 06:01:20 AM: edges-srl-ontonotes_f1: training: 0.869768 validation: 0.900183
10/01 06:01:20 AM: Global learning rate: 1.5625e-06
10/01 06:01:20 AM: Saving checkpoints to: ./experiments/srl-ontonotes-allstrings-mix/run
10/01 06:01:20 AM: Stopped training after 55 validation checks
10/01 06:01:20 AM: Trained edges-srl-ontonotes for 55000 batches or 7.603 epochs
10/01 06:01:20 AM: ***** VALIDATION RESULTS *****
10/01 06:01:20 AM: edges-srl-ontonotes_f1 (for best val pass 45): edges-srl-ontonotes_loss: 0.00861, macro_avg: 0.90139, micro_avg: 0.00000, edges-srl-ontonotes_mcc: 0.90040, edges-srl-ontonotes_acc: 0.86706, edges-srl-ontonotes_precision: 0.93101, edges-srl-ontonotes_recall: 0.87360, edges-srl-ontonotes_f1: 0.90139
10/01 06:01:20 AM: micro_avg (for best val pass 1): edges-srl-ontonotes_loss: 0.02169, macro_avg: 0.76820, micro_avg: 0.00000, edges-srl-ontonotes_mcc: 0.77280, edges-srl-ontonotes_acc: 0.66100, edges-srl-ontonotes_precision: 0.89192, edges-srl-ontonotes_recall: 0.67462, edges-srl-ontonotes_f1: 0.76820
10/01 06:01:20 AM: macro_avg (for best val pass 45): edges-srl-ontonotes_loss: 0.00861, macro_avg: 0.90139, micro_avg: 0.00000, edges-srl-ontonotes_mcc: 0.90040, edges-srl-ontonotes_acc: 0.86706, edges-srl-ontonotes_precision: 0.93101, edges-srl-ontonotes_recall: 0.87360, edges-srl-ontonotes_f1: 0.90139
10/01 06:01:20 AM: Evaluating...
10/01 06:01:20 AM: Loaded model state from ./experiments/srl-ontonotes-allstrings-mix/run/edges-srl-ontonotes/model_state_target_train_val_45.best.th
10/01 06:01:20 AM: Evaluating on: edges-srl-ontonotes, split: val
10/01 06:01:50 AM: 	Task edges-srl-ontonotes: batch 367
10/01 06:02:20 AM: 	Task edges-srl-ontonotes: batch 709
10/01 06:02:45 AM: Task 'edges-srl-ontonotes': sorting predictions by 'idx'
10/01 06:02:45 AM: Finished evaluating on: edges-srl-ontonotes
10/01 06:02:45 AM: Task 'edges-srl-ontonotes': joining predictions with input split 'val'
10/01 06:02:50 AM: Task 'edges-srl-ontonotes': Wrote predictions to ./experiments/srl-ontonotes-allstrings-mix/run
10/01 06:02:50 AM: Wrote all preds for split 'val' to ./experiments/srl-ontonotes-allstrings-mix/run
10/01 06:02:50 AM: Evaluating on: edges-srl-ontonotes, split: test
10/01 06:03:20 AM: 	Task edges-srl-ontonotes: batch 354
10/01 06:03:50 AM: 	Task edges-srl-ontonotes: batch 715
10/01 06:03:52 AM: Task 'edges-srl-ontonotes': sorting predictions by 'idx'
10/01 06:03:52 AM: Finished evaluating on: edges-srl-ontonotes
10/01 06:03:55 AM: Task 'edges-srl-ontonotes': joining predictions with input split 'test'
10/01 06:03:58 AM: Task 'edges-srl-ontonotes': Wrote predictions to ./experiments/srl-ontonotes-allstrings-mix/run
10/01 06:03:58 AM: Wrote all preds for split 'test' to ./experiments/srl-ontonotes-allstrings-mix/run
10/01 06:03:58 AM: Writing results for split 'val' to ./experiments/srl-ontonotes-allstrings-mix/results.tsv
10/01 06:03:58 AM: micro_avg: 0.000, macro_avg: 0.902, edges-srl-ontonotes_mcc: 0.900, edges-srl-ontonotes_acc: 0.868, edges-srl-ontonotes_precision: 0.930, edges-srl-ontonotes_recall: 0.875, edges-srl-ontonotes_f1: 0.902
10/01 06:03:58 AM: Done!
10/01 06:03:58 AM: Fatal error in main():
Traceback (most recent call last):
  File "main.py", line 16, in <module>
    main(sys.argv[1:])
  File "/srv/home/ericwallace/jiant/jiant/__main__.py", line 610, in main
    exit("Done exited")
  File "/home/ericwallace/miniconda3/envs/jiant/lib/python3.6/_sitebuiltins.py", line 26, in __call__
    raise SystemExit(code)
SystemExit: Done exited
