09/16 12:14:43 PM: Git branch: master
09/16 12:14:43 PM: Git SHA: 93c1dfd555f3458ddbb66d458dfeca984f2d8527
09/16 12:14:43 PM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/",
  "exp_name": "experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/RANDOM_WITH_GOOD_EMBEDDINGS",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top__run",
  "run_dir": "./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-ner-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 12:14:43 PM: Saved config to ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run/params.conf
09/16 12:14:43 PM: Using random seed 1234
09/16 12:15:22 PM: Using GPU 0
09/16 12:15:22 PM: Loading tasks...
09/16 12:15:22 PM: Writing pre-preprocessed tasks to ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/
09/16 12:15:22 PM: 	Creating task edges-ner-ontonotes from scratch.
09/16 12:15:23 PM: Read=49706, Skip=66106, Total=115812 from ./probing_data/edges/ontonotes/ner/train.json.retokenized.bert-base-uncased
09/16 12:15:24 PM: Read=7610, Skip=8070, Total=15680 from ./probing_data/edges/ontonotes/ner/development.json.retokenized.bert-base-uncased
09/16 12:15:24 PM: Read=5099, Skip=7118, Total=12217 from ./probing_data/edges/ontonotes/ner/test.json.retokenized.bert-base-uncased
09/16 12:15:25 PM: 	Task 'edges-ner-ontonotes': |train|=49706 |val|=7610 |test|=5099
09/16 12:15:25 PM: 	Finished loading tasks: edges-ner-ontonotes.
09/16 12:15:25 PM: 	Building vocab from scratch.
09/16 12:15:25 PM: 	Counting units for task edges-ner-ontonotes.
09/16 12:15:27 PM: 	Task 'edges-ner-ontonotes': adding vocab namespace 'edges-ner-ontonotes_labels'
09/16 12:15:28 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:15:28 PM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 12:15:29 PM: 	Saved vocab to ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/vocab
09/16 12:15:29 PM: Loading token dictionary from ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/vocab.
09/16 12:15:29 PM: 	Loaded vocab from ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/vocab
09/16 12:15:29 PM: 	Vocab namespace edges-ner-ontonotes_labels: size 18
09/16 12:15:29 PM: 	Vocab namespace tokens: size 22840
09/16 12:15:29 PM: 	Vocab namespace bert_uncased: size 30524
09/16 12:15:29 PM: 	Vocab namespace chars: size 77
09/16 12:15:29 PM: 	Finished building vocab.
09/16 12:15:29 PM: 	Task edges-ner-ontonotes (train): Indexing from scratch.
09/16 12:15:43 PM: 	Task edges-ner-ontonotes (train): Saved 49706 instances to ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/preproc/edges-ner-ontonotes__train_data
09/16 12:15:43 PM: 	Task edges-ner-ontonotes (val): Indexing from scratch.
09/16 12:15:45 PM: 	Task edges-ner-ontonotes (val): Saved 7610 instances to ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/preproc/edges-ner-ontonotes__val_data
09/16 12:15:45 PM: 	Task edges-ner-ontonotes (test): Indexing from scratch.
09/16 12:15:49 PM: 	Task edges-ner-ontonotes (test): Saved 5099 instances to ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/preproc/edges-ner-ontonotes__test_data
09/16 12:15:49 PM: 	Finished indexing tasks
09/16 12:15:49 PM: 	Creating trimmed target-only version of edges-ner-ontonotes train.
09/16 12:15:49 PM: 	  Training on 
09/16 12:15:49 PM: 	  Evaluating on edges-ner-ontonotes
09/16 12:15:49 PM: 	Finished loading tasks in 27.203s
09/16 12:15:49 PM: 	 Tasks: ['edges-ner-ontonotes']
09/16 12:15:49 PM: Building model...
09/16 12:15:49 PM: Using BERT model (bert-base-uncased).
09/16 12:15:49 PM: LOADING A RANDOMLY WEIGHTS BERT
09/16 12:15:54 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpzkiifhxn
09/16 12:15:55 PM: copying /tmp/tmpzkiifhxn to cache at ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/16 12:15:55 PM: creating metadata file for ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/16 12:15:55 PM: removing temp file /tmp/tmpzkiifhxn
09/16 12:15:55 PM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/16 12:15:55 PM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 12:15:56 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpokw8khh4
09/16 12:29:03 PM: copying /tmp/tmpokw8khh4 to cache at ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/16 12:29:08 PM: creating metadata file for ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/16 12:29:08 PM: removing temp file /tmp/tmpokw8khh4
09/16 12:29:08 PM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/16 12:29:18 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp6xtqmymi
09/16 12:29:20 PM: copying /tmp/tmp6xtqmymi to cache at ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:29:20 PM: creating metadata file for ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:29:20 PM: removing temp file /tmp/tmp6xtqmymi
09/16 12:29:20 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:29:20 PM: Initializing parameters
09/16 12:29:20 PM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 12:29:20 PM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 12:29:20 PM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 12:29:20 PM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 12:29:20 PM:    _text_field_embedder.model.pooler.dense.bias
09/16 12:29:20 PM:    _text_field_embedder.model.pooler.dense.weight
09/16 12:29:20 PM: 	Task 'edges-ner-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-ner-ontonotes"
}
09/16 12:30:02 PM: Model specification:
09/16 12:30:03 PM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-ner-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=18, bias=True)
    )
  )
)
09/16 12:30:03 PM: Model parameters:
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:30:03 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:30:03 PM: 	edges-ner-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 12:30:03 PM: 	edges-ner-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 12:30:03 PM: 	edges-ner-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 9216 with torch.Size([18, 512])
09/16 12:30:03 PM: 	edges-ner-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 18 with torch.Size([18])
09/16 12:30:03 PM: Total number of parameters: 109688338 (1.09688e+08)
09/16 12:30:03 PM: Number of trainable parameters: 206098 (206098)
09/16 12:30:03 PM: Finished building model in 854.063s
09/16 12:30:03 PM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-ner-ontonotes 

09/16 12:30:11 PM: patience = 9
09/16 12:30:11 PM: val_interval = 1000
09/16 12:30:11 PM: max_vals = 250
09/16 12:30:11 PM: cuda_device = 0
09/16 12:30:11 PM: grad_norm = 5.0
09/16 12:30:11 PM: grad_clipping = None
09/16 12:30:11 PM: lr_decay = 0.99
09/16 12:30:11 PM: min_lr = 1e-06
09/16 12:30:11 PM: keep_all_checkpoints = 0
09/16 12:30:11 PM: val_data_limit = 5000
09/16 12:30:11 PM: max_epochs = -1
09/16 12:30:11 PM: dec_val_scale = 250
09/16 12:30:11 PM: training_data_fraction = 1
09/16 12:30:12 PM: type = adam
09/16 12:30:12 PM: parameter_groups = None
09/16 12:30:12 PM: Number of trainable parameters: 206098
09/16 12:30:12 PM: infer_type_and_cast = True
09/16 12:30:12 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:30:12 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:30:12 PM: lr = 0.0001
09/16 12:30:12 PM: amsgrad = True
09/16 12:30:12 PM: type = reduce_on_plateau
09/16 12:30:12 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:30:12 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:30:12 PM: mode = max
09/16 12:30:12 PM: factor = 0.5
09/16 12:30:12 PM: patience = 3
09/16 12:30:12 PM: threshold = 0.0001
09/16 12:30:12 PM: threshold_mode = abs
09/16 12:30:12 PM: verbose = True
09/16 12:30:12 PM: type = adam
09/16 12:30:12 PM: parameter_groups = None
09/16 12:30:12 PM: Number of trainable parameters: 206098
09/16 12:30:12 PM: infer_type_and_cast = True
09/16 12:30:12 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:30:12 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:30:12 PM: lr = 0.0001
09/16 12:30:12 PM: amsgrad = True
09/16 12:30:12 PM: type = reduce_on_plateau
09/16 12:30:12 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:30:12 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:30:12 PM: mode = max
09/16 12:30:12 PM: factor = 0.5
09/16 12:30:12 PM: patience = 3
09/16 12:30:12 PM: threshold = 0.0001
09/16 12:30:12 PM: threshold_mode = abs
09/16 12:30:12 PM: verbose = True
09/16 12:30:12 PM: Starting training without restoring from a checkpoint.
09/16 12:30:12 PM: Training examples per task, before any subsampling: {'edges-ner-ontonotes': 49706}
09/16 12:30:12 PM: Beginning training with stopping criteria based on metric: edges-ner-ontonotes_f1
09/16 12:30:22 PM: Update 27: task edges-ner-ontonotes, batch 27 (27): mcc: 0.0201, acc: 0.0109, precision: 0.0697, recall: 0.1199, f1: 0.0882, edges-ner-ontonotes_loss: 0.3921
09/16 12:30:32 PM: Update 119: task edges-ner-ontonotes, batch 119 (119): mcc: 0.0099, acc: 0.0028, precision: 0.0697, recall: 0.0311, f1: 0.0430, edges-ner-ontonotes_loss: 0.2255
09/16 12:30:43 PM: Update 209: task edges-ner-ontonotes, batch 209 (209): mcc: 0.0092, acc: 0.0026, precision: 0.0731, recall: 0.0189, f1: 0.0300, edges-ner-ontonotes_loss: 0.2008
09/16 12:30:53 PM: Update 298: task edges-ner-ontonotes, batch 298 (298): mcc: 0.0166, acc: 0.0059, precision: 0.0924, recall: 0.0174, f1: 0.0293, edges-ner-ontonotes_loss: 0.1892
09/16 12:31:05 PM: Update 314: task edges-ner-ontonotes, batch 314 (314): mcc: 0.0179, acc: 0.0064, precision: 0.0965, recall: 0.0172, f1: 0.0292, edges-ner-ontonotes_loss: 0.1877
09/16 12:31:15 PM: Update 370: task edges-ner-ontonotes, batch 370 (370): mcc: 0.0248, acc: 0.0088, precision: 0.1177, recall: 0.0176, f1: 0.0306, edges-ner-ontonotes_loss: 0.1834
09/16 12:31:25 PM: Update 435: task edges-ner-ontonotes, batch 435 (435): mcc: 0.0501, acc: 0.0182, precision: 0.1870, recall: 0.0255, f1: 0.0449, edges-ner-ontonotes_loss: 0.1792
09/16 12:31:35 PM: Update 492: task edges-ner-ontonotes, batch 492 (492): mcc: 0.0752, acc: 0.0274, precision: 0.2566, recall: 0.0337, f1: 0.0596, edges-ner-ontonotes_loss: 0.1757
09/16 12:31:45 PM: Update 543: task edges-ner-ontonotes, batch 543 (543): mcc: 0.0976, acc: 0.0357, precision: 0.3178, recall: 0.0413, f1: 0.0731, edges-ner-ontonotes_loss: 0.1731
09/16 12:31:55 PM: Update 595: task edges-ner-ontonotes, batch 595 (595): mcc: 0.1209, acc: 0.0448, precision: 0.3776, recall: 0.0499, f1: 0.0882, edges-ner-ontonotes_loss: 0.1704
09/16 12:32:08 PM: Update 627: task edges-ner-ontonotes, batch 627 (627): mcc: 0.1352, acc: 0.0507, precision: 0.4123, recall: 0.0555, f1: 0.0978, edges-ner-ontonotes_loss: 0.1689
09/16 12:32:18 PM: Update 672: task edges-ner-ontonotes, batch 672 (672): mcc: 0.1442, acc: 0.0540, precision: 0.4371, recall: 0.0585, f1: 0.1032, edges-ner-ontonotes_loss: 0.1676
09/16 12:32:28 PM: Update 725: task edges-ner-ontonotes, batch 725 (725): mcc: 0.1607, acc: 0.0607, precision: 0.4773, recall: 0.0650, f1: 0.1144, edges-ner-ontonotes_loss: 0.1658
09/16 12:32:38 PM: Update 779: task edges-ner-ontonotes, batch 779 (779): mcc: 0.1793, acc: 0.0689, precision: 0.5176, recall: 0.0730, f1: 0.1280, edges-ner-ontonotes_loss: 0.1640
09/16 12:32:48 PM: Update 857: task edges-ner-ontonotes, batch 857 (857): mcc: 0.2040, acc: 0.0806, precision: 0.5662, recall: 0.0846, f1: 0.1472, edges-ner-ontonotes_loss: 0.1614
09/16 12:32:58 PM: Update 915: task edges-ner-ontonotes, batch 915 (915): mcc: 0.2231, acc: 0.0904, precision: 0.5995, recall: 0.0944, f1: 0.1632, edges-ner-ontonotes_loss: 0.1596
09/16 12:33:09 PM: Update 940: task edges-ner-ontonotes, batch 940 (940): mcc: 0.2301, acc: 0.0942, precision: 0.6106, recall: 0.0982, f1: 0.1692, edges-ner-ontonotes_loss: 0.1589
09/16 12:33:19 PM: Update 997: task edges-ner-ontonotes, batch 997 (997): mcc: 0.2455, acc: 0.1028, precision: 0.6343, recall: 0.1068, f1: 0.1828, edges-ner-ontonotes_loss: 0.1576
09/16 12:33:19 PM: ***** Step 1000 / Validation 1 *****
09/16 12:33:19 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:33:19 PM: Validating...
09/16 12:33:29 PM: Evaluate: task edges-ner-ontonotes, batch 54 (157): mcc: 0.2911, acc: 0.1303, precision: 0.7110, recall: 0.1311, f1: 0.2214, edges-ner-ontonotes_loss: 0.1604
09/16 12:33:39 PM: Evaluate: task edges-ner-ontonotes, batch 103 (157): mcc: 0.3620, acc: 0.1754, precision: 0.8014, recall: 0.1761, f1: 0.2888, edges-ner-ontonotes_loss: 0.1497
09/16 12:33:49 PM: Evaluate: task edges-ner-ontonotes, batch 141 (157): mcc: 0.3917, acc: 0.1966, precision: 0.8315, recall: 0.1975, f1: 0.3191, edges-ner-ontonotes_loss: 0.1421
09/16 12:33:53 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:33:55 PM: Best result seen so far for micro.
09/16 12:33:55 PM: Best result seen so far for macro.
09/16 12:33:55 PM: Updating LR scheduler:
09/16 12:33:55 PM: 	Best result seen so far for macro_avg: 0.318
09/16 12:33:55 PM: 	# validation passes without improvement: 0
09/16 12:33:55 PM: edges-ner-ontonotes_loss: training: 0.157486 validation: 0.141464
09/16 12:33:55 PM: macro_avg: validation: 0.318332
09/16 12:33:55 PM: micro_avg: validation: 0.000000
09/16 12:33:55 PM: edges-ner-ontonotes_mcc: training: 0.246238 validation: 0.391070
09/16 12:33:55 PM: edges-ner-ontonotes_acc: training: 0.103167 validation: 0.195936
09/16 12:33:55 PM: edges-ner-ontonotes_precision: training: 0.635349 validation: 0.831518
09/16 12:33:55 PM: edges-ner-ontonotes_recall: training: 0.107217 validation: 0.196846
09/16 12:33:55 PM: edges-ner-ontonotes_f1: training: 0.183472 validation: 0.318332
09/16 12:33:55 PM: Global learning rate: 0.0001
09/16 12:33:55 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 12:33:59 PM: Update 1022: task edges-ner-ontonotes, batch 22 (1022): mcc: 0.4349, acc: 0.2309, precision: 0.8515, recall: 0.2363, f1: 0.3700, edges-ner-ontonotes_loss: 0.1335
09/16 12:34:09 PM: Update 1082: task edges-ner-ontonotes, batch 82 (1082): mcc: 0.4452, acc: 0.2437, precision: 0.8493, recall: 0.2483, f1: 0.3842, edges-ner-ontonotes_loss: 0.1307
09/16 12:34:19 PM: Update 1155: task edges-ner-ontonotes, batch 155 (1155): mcc: 0.4469, acc: 0.2463, precision: 0.8455, recall: 0.2513, f1: 0.3875, edges-ner-ontonotes_loss: 0.1297
09/16 12:34:30 PM: Update 1208: task edges-ner-ontonotes, batch 208 (1208): mcc: 0.4509, acc: 0.2518, precision: 0.8427, recall: 0.2568, f1: 0.3936, edges-ner-ontonotes_loss: 0.1291
09/16 12:34:42 PM: Update 1253: task edges-ner-ontonotes, batch 253 (1253): mcc: 0.4509, acc: 0.2537, precision: 0.8368, recall: 0.2587, f1: 0.3952, edges-ner-ontonotes_loss: 0.1289
09/16 12:34:53 PM: Update 1307: task edges-ner-ontonotes, batch 307 (1307): mcc: 0.4395, acc: 0.2445, precision: 0.8276, recall: 0.2491, f1: 0.3830, edges-ner-ontonotes_loss: 0.1323
09/16 12:35:03 PM: Update 1364: task edges-ner-ontonotes, batch 364 (1364): mcc: 0.4319, acc: 0.2377, precision: 0.8239, recall: 0.2419, f1: 0.3740, edges-ner-ontonotes_loss: 0.1344
09/16 12:35:13 PM: Update 1428: task edges-ner-ontonotes, batch 428 (1428): mcc: 0.4299, acc: 0.2360, precision: 0.8225, recall: 0.2401, f1: 0.3717, edges-ner-ontonotes_loss: 0.1350
09/16 12:35:23 PM: Update 1486: task edges-ner-ontonotes, batch 486 (1486): mcc: 0.4288, acc: 0.2353, precision: 0.8211, recall: 0.2394, f1: 0.3707, edges-ner-ontonotes_loss: 0.1356
09/16 12:35:34 PM: Update 1557: task edges-ner-ontonotes, batch 557 (1557): mcc: 0.4301, acc: 0.2374, precision: 0.8200, recall: 0.2412, f1: 0.3728, edges-ner-ontonotes_loss: 0.1360
09/16 12:35:44 PM: Update 1649: task edges-ner-ontonotes, batch 649 (1649): mcc: 0.4274, acc: 0.2353, precision: 0.8178, recall: 0.2389, f1: 0.3698, edges-ner-ontonotes_loss: 0.1362
09/16 12:35:54 PM: Update 1748: task edges-ner-ontonotes, batch 748 (1748): mcc: 0.4274, acc: 0.2359, precision: 0.8167, recall: 0.2393, f1: 0.3701, edges-ner-ontonotes_loss: 0.1358
09/16 12:36:04 PM: Update 1847: task edges-ner-ontonotes, batch 847 (1847): mcc: 0.4310, acc: 0.2395, precision: 0.8181, recall: 0.2428, f1: 0.3745, edges-ner-ontonotes_loss: 0.1350
09/16 12:36:15 PM: Update 1886: task edges-ner-ontonotes, batch 886 (1886): mcc: 0.4316, acc: 0.2407, precision: 0.8161, recall: 0.2441, f1: 0.3758, edges-ner-ontonotes_loss: 0.1348
09/16 12:36:25 PM: Update 1963: task edges-ner-ontonotes, batch 963 (1963): mcc: 0.4331, acc: 0.2433, precision: 0.8132, recall: 0.2467, f1: 0.3786, edges-ner-ontonotes_loss: 0.1343
09/16 12:36:31 PM: ***** Step 2000 / Validation 2 *****
09/16 12:36:31 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:36:31 PM: Validating...
09/16 12:36:35 PM: Evaluate: task edges-ner-ontonotes, batch 27 (157): mcc: 0.3961, acc: 0.1946, precision: 0.8594, recall: 0.1946, f1: 0.3173, edges-ner-ontonotes_loss: 0.1429
09/16 12:36:45 PM: Evaluate: task edges-ner-ontonotes, batch 85 (157): mcc: 0.4668, acc: 0.2521, precision: 0.9110, recall: 0.2523, f1: 0.3951, edges-ner-ontonotes_loss: 0.1280
09/16 12:36:55 PM: Evaluate: task edges-ner-ontonotes, batch 133 (157): mcc: 0.4647, acc: 0.2496, precision: 0.9116, recall: 0.2498, f1: 0.3921, edges-ner-ontonotes_loss: 0.1260
09/16 12:37:00 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:37:00 PM: Best result seen so far for macro.
09/16 12:37:01 PM: Updating LR scheduler:
09/16 12:37:01 PM: 	Best result seen so far for macro_avg: 0.386
09/16 12:37:01 PM: 	# validation passes without improvement: 0
09/16 12:37:01 PM: edges-ner-ontonotes_loss: training: 0.134028 validation: 0.127000
09/16 12:37:01 PM: macro_avg: validation: 0.385608
09/16 12:37:01 PM: micro_avg: validation: 0.000000
09/16 12:37:01 PM: edges-ner-ontonotes_mcc: training: 0.434630 validation: 0.459364
09/16 12:37:01 PM: edges-ner-ontonotes_acc: training: 0.245203 validation: 0.244465
09/16 12:37:01 PM: edges-ner-ontonotes_precision: training: 0.812387 validation: 0.910271
09/16 12:37:01 PM: edges-ner-ontonotes_recall: training: 0.248731 validation: 0.244616
09/16 12:37:01 PM: edges-ner-ontonotes_f1: training: 0.380854 validation: 0.385608
09/16 12:37:01 PM: Global learning rate: 0.0001
09/16 12:37:01 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 12:37:05 PM: Update 2023: task edges-ner-ontonotes, batch 23 (2023): mcc: 0.4766, acc: 0.2936, precision: 0.8120, recall: 0.2982, f1: 0.4362, edges-ner-ontonotes_loss: 0.1252
09/16 12:37:18 PM: Update 2083: task edges-ner-ontonotes, batch 83 (2083): mcc: 0.4801, acc: 0.2951, precision: 0.8220, recall: 0.2985, f1: 0.4380, edges-ner-ontonotes_loss: 0.1242
09/16 12:37:28 PM: Update 2142: task edges-ner-ontonotes, batch 142 (2142): mcc: 0.4843, acc: 0.3032, precision: 0.8140, recall: 0.3069, f1: 0.4458, edges-ner-ontonotes_loss: 0.1238
09/16 12:37:39 PM: Update 2183: task edges-ner-ontonotes, batch 183 (2183): mcc: 0.4822, acc: 0.3036, precision: 0.8054, recall: 0.3079, f1: 0.4455, edges-ner-ontonotes_loss: 0.1240
09/16 12:37:49 PM: Update 2241: task edges-ner-ontonotes, batch 241 (2241): mcc: 0.4778, acc: 0.2979, precision: 0.8020, recall: 0.3038, f1: 0.4407, edges-ner-ontonotes_loss: 0.1249
09/16 12:38:00 PM: Update 2308: task edges-ner-ontonotes, batch 308 (2308): mcc: 0.4795, acc: 0.2992, precision: 0.8007, recall: 0.3064, f1: 0.4432, edges-ner-ontonotes_loss: 0.1244
09/16 12:38:10 PM: Update 2366: task edges-ner-ontonotes, batch 366 (2366): mcc: 0.4784, acc: 0.2982, precision: 0.7988, recall: 0.3059, f1: 0.4424, edges-ner-ontonotes_loss: 0.1241
09/16 12:38:20 PM: Update 2424: task edges-ner-ontonotes, batch 424 (2424): mcc: 0.4805, acc: 0.3001, precision: 0.7982, recall: 0.3089, f1: 0.4454, edges-ner-ontonotes_loss: 0.1236
09/16 12:38:30 PM: Update 2493: task edges-ner-ontonotes, batch 493 (2493): mcc: 0.4834, acc: 0.3029, precision: 0.7973, recall: 0.3128, f1: 0.4494, edges-ner-ontonotes_loss: 0.1229
09/16 12:38:40 PM: Update 2523: task edges-ner-ontonotes, batch 523 (2523): mcc: 0.4839, acc: 0.3039, precision: 0.7964, recall: 0.3139, f1: 0.4503, edges-ner-ontonotes_loss: 0.1230
09/16 12:38:50 PM: Update 2583: task edges-ner-ontonotes, batch 583 (2583): mcc: 0.4848, acc: 0.3047, precision: 0.7961, recall: 0.3151, f1: 0.4515, edges-ner-ontonotes_loss: 0.1230
09/16 12:39:00 PM: Update 2640: task edges-ner-ontonotes, batch 640 (2640): mcc: 0.4857, acc: 0.3060, precision: 0.7950, recall: 0.3167, f1: 0.4530, edges-ner-ontonotes_loss: 0.1229
09/16 12:39:10 PM: Update 2704: task edges-ner-ontonotes, batch 704 (2704): mcc: 0.4872, acc: 0.3078, precision: 0.7945, recall: 0.3188, f1: 0.4551, edges-ner-ontonotes_loss: 0.1227
09/16 12:39:20 PM: Update 2776: task edges-ner-ontonotes, batch 776 (2776): mcc: 0.4888, acc: 0.3099, precision: 0.7941, recall: 0.3212, f1: 0.4573, edges-ner-ontonotes_loss: 0.1223
09/16 12:39:33 PM: Update 2809: task edges-ner-ontonotes, batch 809 (2809): mcc: 0.4893, acc: 0.3111, precision: 0.7921, recall: 0.3226, f1: 0.4585, edges-ner-ontonotes_loss: 0.1221
09/16 12:39:43 PM: Update 2872: task edges-ner-ontonotes, batch 872 (2872): mcc: 0.4855, acc: 0.3076, precision: 0.7897, recall: 0.3189, f1: 0.4543, edges-ner-ontonotes_loss: 0.1233
09/16 12:39:53 PM: Update 2928: task edges-ner-ontonotes, batch 928 (2928): mcc: 0.4836, acc: 0.3060, precision: 0.7885, recall: 0.3170, f1: 0.4522, edges-ner-ontonotes_loss: 0.1238
09/16 12:40:03 PM: Update 2989: task edges-ner-ontonotes, batch 989 (2989): mcc: 0.4830, acc: 0.3057, precision: 0.7882, recall: 0.3164, f1: 0.4515, edges-ner-ontonotes_loss: 0.1244
09/16 12:40:04 PM: ***** Step 3000 / Validation 3 *****
09/16 12:40:04 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:40:04 PM: Validating...
09/16 12:40:13 PM: Evaluate: task edges-ner-ontonotes, batch 62 (157): mcc: 0.4322, acc: 0.2314, precision: 0.8570, recall: 0.2318, f1: 0.3649, edges-ner-ontonotes_loss: 0.1284
09/16 12:40:24 PM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.4715, acc: 0.2679, precision: 0.8683, recall: 0.2712, f1: 0.4133, edges-ner-ontonotes_loss: 0.1243
09/16 12:40:33 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:40:33 PM: Best result seen so far for macro.
09/16 12:40:33 PM: Updating LR scheduler:
09/16 12:40:33 PM: 	Best result seen so far for macro_avg: 0.416
09/16 12:40:33 PM: 	# validation passes without improvement: 0
09/16 12:40:33 PM: edges-ner-ontonotes_loss: training: 0.124503 validation: 0.122508
09/16 12:40:33 PM: macro_avg: validation: 0.416186
09/16 12:40:33 PM: micro_avg: validation: 0.000000
09/16 12:40:33 PM: edges-ner-ontonotes_mcc: training: 0.483035 validation: 0.473575
09/16 12:40:33 PM: edges-ner-ontonotes_acc: training: 0.305791 validation: 0.270322
09/16 12:40:33 PM: edges-ner-ontonotes_precision: training: 0.788096 validation: 0.867788
09/16 12:40:33 PM: edges-ner-ontonotes_recall: training: 0.316412 validation: 0.273734
09/16 12:40:33 PM: edges-ner-ontonotes_f1: training: 0.451537 validation: 0.416186
09/16 12:40:33 PM: Global learning rate: 0.0001
09/16 12:40:33 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 12:40:34 PM: Update 3017: task edges-ner-ontonotes, batch 17 (3017): mcc: 0.4606, acc: 0.2800, precision: 0.7917, recall: 0.2868, f1: 0.4211, edges-ner-ontonotes_loss: 0.1343
09/16 12:40:44 PM: Update 3104: task edges-ner-ontonotes, batch 104 (3104): mcc: 0.4735, acc: 0.2959, precision: 0.7956, recall: 0.3012, f1: 0.4370, edges-ner-ontonotes_loss: 0.1305
09/16 12:40:54 PM: Update 3156: task edges-ner-ontonotes, batch 156 (3156): mcc: 0.4634, acc: 0.2891, precision: 0.7822, recall: 0.2941, f1: 0.4275, edges-ner-ontonotes_loss: 0.1303
09/16 12:41:04 PM: Update 3252: task edges-ner-ontonotes, batch 252 (3252): mcc: 0.4655, acc: 0.2908, precision: 0.7823, recall: 0.2967, f1: 0.4302, edges-ner-ontonotes_loss: 0.1283
09/16 12:41:14 PM: Update 3359: task edges-ner-ontonotes, batch 359 (3359): mcc: 0.4695, acc: 0.2945, precision: 0.7860, recall: 0.3002, f1: 0.4345, edges-ner-ontonotes_loss: 0.1270
09/16 12:41:28 PM: Update 3426: task edges-ner-ontonotes, batch 426 (3426): mcc: 0.4710, acc: 0.2967, precision: 0.7851, recall: 0.3025, f1: 0.4367, edges-ner-ontonotes_loss: 0.1267
09/16 12:41:38 PM: Update 3496: task edges-ner-ontonotes, batch 496 (3496): mcc: 0.4719, acc: 0.2989, precision: 0.7817, recall: 0.3051, f1: 0.4388, edges-ner-ontonotes_loss: 0.1267
09/16 12:41:48 PM: Update 3560: task edges-ner-ontonotes, batch 560 (3560): mcc: 0.4740, acc: 0.3013, precision: 0.7817, recall: 0.3078, f1: 0.4416, edges-ner-ontonotes_loss: 0.1260
09/16 12:41:59 PM: Update 3628: task edges-ner-ontonotes, batch 628 (3628): mcc: 0.4769, acc: 0.3048, precision: 0.7816, recall: 0.3115, f1: 0.4455, edges-ner-ontonotes_loss: 0.1254
09/16 12:42:09 PM: Update 3694: task edges-ner-ontonotes, batch 694 (3694): mcc: 0.4798, acc: 0.3082, precision: 0.7814, recall: 0.3152, f1: 0.4492, edges-ner-ontonotes_loss: 0.1249
09/16 12:42:19 PM: Update 3739: task edges-ner-ontonotes, batch 739 (3739): mcc: 0.4827, acc: 0.3111, precision: 0.7832, recall: 0.3181, f1: 0.4525, edges-ner-ontonotes_loss: 0.1245
09/16 12:42:29 PM: Update 3812: task edges-ner-ontonotes, batch 812 (3812): mcc: 0.4832, acc: 0.3122, precision: 0.7798, recall: 0.3204, f1: 0.4542, edges-ner-ontonotes_loss: 0.1242
09/16 12:42:39 PM: Update 3876: task edges-ner-ontonotes, batch 876 (3876): mcc: 0.4842, acc: 0.3132, precision: 0.7788, recall: 0.3221, f1: 0.4557, edges-ner-ontonotes_loss: 0.1238
09/16 12:42:49 PM: Update 3949: task edges-ner-ontonotes, batch 949 (3949): mcc: 0.4865, acc: 0.3152, precision: 0.7792, recall: 0.3249, f1: 0.4586, edges-ner-ontonotes_loss: 0.1233
09/16 12:42:58 PM: ***** Step 4000 / Validation 4 *****
09/16 12:42:58 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:42:58 PM: Validating...
09/16 12:43:00 PM: Evaluate: task edges-ner-ontonotes, batch 12 (157): mcc: 0.3927, acc: 0.2345, precision: 0.7131, recall: 0.2358, f1: 0.3545, edges-ner-ontonotes_loss: 0.1522
09/16 12:43:10 PM: Evaluate: task edges-ner-ontonotes, batch 65 (157): mcc: 0.4389, acc: 0.2561, precision: 0.7910, recall: 0.2611, f1: 0.3926, edges-ner-ontonotes_loss: 0.1315
09/16 12:43:20 PM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.4904, acc: 0.2995, precision: 0.8274, recall: 0.3090, f1: 0.4499, edges-ner-ontonotes_loss: 0.1238
09/16 12:43:28 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:43:28 PM: Best result seen so far for macro.
09/16 12:43:28 PM: Updating LR scheduler:
09/16 12:43:28 PM: 	Best result seen so far for macro_avg: 0.469
09/16 12:43:28 PM: 	# validation passes without improvement: 0
09/16 12:43:28 PM: edges-ner-ontonotes_loss: training: 0.122966 validation: 0.119202
09/16 12:43:28 PM: macro_avg: validation: 0.468921
09/16 12:43:28 PM: micro_avg: validation: 0.000000
09/16 12:43:28 PM: edges-ner-ontonotes_mcc: training: 0.488385 validation: 0.508238
09/16 12:43:28 PM: edges-ner-ontonotes_acc: training: 0.316992 validation: 0.316045
09/16 12:43:28 PM: edges-ner-ontonotes_precision: training: 0.780084 validation: 0.842178
09/16 12:43:28 PM: edges-ner-ontonotes_recall: training: 0.326963 validation: 0.324917
09/16 12:43:28 PM: edges-ner-ontonotes_f1: training: 0.460791 validation: 0.468921
09/16 12:43:28 PM: Global learning rate: 0.0001
09/16 12:43:28 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 12:43:30 PM: Update 4013: task edges-ner-ontonotes, batch 13 (4013): mcc: 0.4785, acc: 0.3125, precision: 0.7474, recall: 0.3295, f1: 0.4573, edges-ner-ontonotes_loss: 0.1227
09/16 12:43:45 PM: Update 4052: task edges-ner-ontonotes, batch 52 (4052): mcc: 0.5099, acc: 0.3423, precision: 0.7764, recall: 0.3575, f1: 0.4896, edges-ner-ontonotes_loss: 0.1180
09/16 12:43:55 PM: Update 4113: task edges-ner-ontonotes, batch 113 (4113): mcc: 0.5087, acc: 0.3382, precision: 0.7787, recall: 0.3547, f1: 0.4873, edges-ner-ontonotes_loss: 0.1182
09/16 12:44:05 PM: Update 4193: task edges-ner-ontonotes, batch 193 (4193): mcc: 0.5168, acc: 0.3466, precision: 0.7829, recall: 0.3637, f1: 0.4967, edges-ner-ontonotes_loss: 0.1165
09/16 12:44:15 PM: Update 4254: task edges-ner-ontonotes, batch 254 (4254): mcc: 0.5173, acc: 0.3474, precision: 0.7836, recall: 0.3640, f1: 0.4971, edges-ner-ontonotes_loss: 0.1169
09/16 12:44:25 PM: Update 4324: task edges-ner-ontonotes, batch 324 (4324): mcc: 0.5149, acc: 0.3459, precision: 0.7794, recall: 0.3629, f1: 0.4952, edges-ner-ontonotes_loss: 0.1171
09/16 12:44:35 PM: Update 4370: task edges-ner-ontonotes, batch 370 (4370): mcc: 0.5122, acc: 0.3446, precision: 0.7750, recall: 0.3614, f1: 0.4930, edges-ner-ontonotes_loss: 0.1178
09/16 12:44:45 PM: Update 4442: task edges-ner-ontonotes, batch 442 (4442): mcc: 0.5060, acc: 0.3381, precision: 0.7733, recall: 0.3538, f1: 0.4855, edges-ner-ontonotes_loss: 0.1201
09/16 12:44:55 PM: Update 4498: task edges-ner-ontonotes, batch 498 (4498): mcc: 0.5019, acc: 0.3338, precision: 0.7717, recall: 0.3490, f1: 0.4806, edges-ner-ontonotes_loss: 0.1215
09/16 12:45:05 PM: Update 4561: task edges-ner-ontonotes, batch 561 (4561): mcc: 0.4993, acc: 0.3318, precision: 0.7693, recall: 0.3467, f1: 0.4779, edges-ner-ontonotes_loss: 0.1225
09/16 12:45:16 PM: Update 4626: task edges-ner-ontonotes, batch 626 (4626): mcc: 0.4988, acc: 0.3313, precision: 0.7700, recall: 0.3456, f1: 0.4770, edges-ner-ontonotes_loss: 0.1231
09/16 12:45:30 PM: Update 4669: task edges-ner-ontonotes, batch 669 (4669): mcc: 0.4979, acc: 0.3307, precision: 0.7698, recall: 0.3445, f1: 0.4760, edges-ner-ontonotes_loss: 0.1235
09/16 12:45:40 PM: Update 4743: task edges-ner-ontonotes, batch 743 (4743): mcc: 0.4955, acc: 0.3285, precision: 0.7684, recall: 0.3420, f1: 0.4733, edges-ner-ontonotes_loss: 0.1234
09/16 12:45:50 PM: Update 4820: task edges-ner-ontonotes, batch 820 (4820): mcc: 0.4946, acc: 0.3274, precision: 0.7692, recall: 0.3404, f1: 0.4720, edges-ner-ontonotes_loss: 0.1234
09/16 12:46:00 PM: Update 4898: task edges-ner-ontonotes, batch 898 (4898): mcc: 0.4943, acc: 0.3268, precision: 0.7707, recall: 0.3393, f1: 0.4712, edges-ner-ontonotes_loss: 0.1233
09/16 12:46:12 PM: Update 4982: task edges-ner-ontonotes, batch 982 (4982): mcc: 0.4955, acc: 0.3279, precision: 0.7727, recall: 0.3399, f1: 0.4721, edges-ner-ontonotes_loss: 0.1230
09/16 12:46:14 PM: ***** Step 5000 / Validation 5 *****
09/16 12:46:14 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:46:14 PM: Validating...
09/16 12:46:22 PM: Evaluate: task edges-ner-ontonotes, batch 41 (157): mcc: 0.5239, acc: 0.3381, precision: 0.8566, recall: 0.3385, f1: 0.4852, edges-ner-ontonotes_loss: 0.1190
09/16 12:46:32 PM: Evaluate: task edges-ner-ontonotes, batch 99 (157): mcc: 0.5223, acc: 0.3308, precision: 0.8670, recall: 0.3321, f1: 0.4802, edges-ner-ontonotes_loss: 0.1174
09/16 12:46:42 PM: Evaluate: task edges-ner-ontonotes, batch 153 (157): mcc: 0.5189, acc: 0.3275, precision: 0.8628, recall: 0.3295, f1: 0.4769, edges-ner-ontonotes_loss: 0.1154
09/16 12:46:43 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:46:43 PM: Best result seen so far for macro.
09/16 12:46:43 PM: Updating LR scheduler:
09/16 12:46:43 PM: 	Best result seen so far for macro_avg: 0.479
09/16 12:46:43 PM: 	# validation passes without improvement: 0
09/16 12:46:43 PM: edges-ner-ontonotes_loss: training: 0.123021 validation: 0.115116
09/16 12:46:43 PM: macro_avg: validation: 0.478921
09/16 12:46:43 PM: micro_avg: validation: 0.000000
09/16 12:46:43 PM: edges-ner-ontonotes_mcc: training: 0.495100 validation: 0.520780
09/16 12:46:43 PM: edges-ner-ontonotes_acc: training: 0.327509 validation: 0.329239
09/16 12:46:43 PM: edges-ner-ontonotes_precision: training: 0.772439 validation: 0.864437
09/16 12:46:43 PM: edges-ner-ontonotes_recall: training: 0.339464 validation: 0.331210
09/16 12:46:43 PM: edges-ner-ontonotes_f1: training: 0.471652 validation: 0.478921
09/16 12:46:43 PM: Global learning rate: 0.0001
09/16 12:46:43 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 12:46:52 PM: Update 5057: task edges-ner-ontonotes, batch 57 (5057): mcc: 0.4855, acc: 0.3222, precision: 0.7616, recall: 0.3319, f1: 0.4623, edges-ner-ontonotes_loss: 0.1226
09/16 12:47:02 PM: Update 5119: task edges-ner-ontonotes, batch 119 (5119): mcc: 0.4879, acc: 0.3251, precision: 0.7587, recall: 0.3365, f1: 0.4662, edges-ner-ontonotes_loss: 0.1221
09/16 12:47:13 PM: Update 5181: task edges-ner-ontonotes, batch 181 (5181): mcc: 0.4962, acc: 0.3325, precision: 0.7659, recall: 0.3441, f1: 0.4749, edges-ner-ontonotes_loss: 0.1210
09/16 12:47:23 PM: Update 5247: task edges-ner-ontonotes, batch 247 (5247): mcc: 0.5003, acc: 0.3373, precision: 0.7671, recall: 0.3491, f1: 0.4799, edges-ner-ontonotes_loss: 0.1201
09/16 12:47:33 PM: Update 5300: task edges-ner-ontonotes, batch 300 (5300): mcc: 0.5041, acc: 0.3411, precision: 0.7698, recall: 0.3529, f1: 0.4840, edges-ner-ontonotes_loss: 0.1193
09/16 12:47:43 PM: Update 5371: task edges-ner-ontonotes, batch 371 (5371): mcc: 0.5031, acc: 0.3390, precision: 0.7670, recall: 0.3530, f1: 0.4835, edges-ner-ontonotes_loss: 0.1193
09/16 12:47:53 PM: Update 5432: task edges-ner-ontonotes, batch 432 (5432): mcc: 0.5025, acc: 0.3382, precision: 0.7660, recall: 0.3526, f1: 0.4829, edges-ner-ontonotes_loss: 0.1193
09/16 12:48:03 PM: Update 5500: task edges-ner-ontonotes, batch 500 (5500): mcc: 0.5062, acc: 0.3414, precision: 0.7682, recall: 0.3566, f1: 0.4871, edges-ner-ontonotes_loss: 0.1187
09/16 12:48:13 PM: Update 5568: task edges-ner-ontonotes, batch 568 (5568): mcc: 0.5083, acc: 0.3428, precision: 0.7703, recall: 0.3584, f1: 0.4892, edges-ner-ontonotes_loss: 0.1183
09/16 12:48:24 PM: Update 5608: task edges-ner-ontonotes, batch 608 (5608): mcc: 0.5099, acc: 0.3443, precision: 0.7718, recall: 0.3599, f1: 0.4909, edges-ner-ontonotes_loss: 0.1181
09/16 12:48:35 PM: Update 5654: task edges-ner-ontonotes, batch 654 (5654): mcc: 0.5106, acc: 0.3454, precision: 0.7716, recall: 0.3610, f1: 0.4918, edges-ner-ontonotes_loss: 0.1179
09/16 12:48:45 PM: Update 5729: task edges-ner-ontonotes, batch 729 (5729): mcc: 0.5125, acc: 0.3467, precision: 0.7732, recall: 0.3628, f1: 0.4938, edges-ner-ontonotes_loss: 0.1176
09/16 12:48:55 PM: Update 5788: task edges-ner-ontonotes, batch 788 (5788): mcc: 0.5129, acc: 0.3473, precision: 0.7730, recall: 0.3634, f1: 0.4944, edges-ner-ontonotes_loss: 0.1175
09/16 12:49:05 PM: Update 5863: task edges-ner-ontonotes, batch 863 (5863): mcc: 0.5138, acc: 0.3482, precision: 0.7731, recall: 0.3646, f1: 0.4955, edges-ner-ontonotes_loss: 0.1173
09/16 12:49:19 PM: Update 5921: task edges-ner-ontonotes, batch 921 (5921): mcc: 0.5144, acc: 0.3487, precision: 0.7733, recall: 0.3653, f1: 0.4962, edges-ner-ontonotes_loss: 0.1173
09/16 12:49:29 PM: Update 5982: task edges-ner-ontonotes, batch 982 (5982): mcc: 0.5110, acc: 0.3454, precision: 0.7714, recall: 0.3617, f1: 0.4924, edges-ner-ontonotes_loss: 0.1183
09/16 12:49:31 PM: ***** Step 6000 / Validation 6 *****
09/16 12:49:31 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:49:31 PM: Validating...
09/16 12:49:39 PM: Evaluate: task edges-ner-ontonotes, batch 50 (157): mcc: 0.4724, acc: 0.2641, precision: 0.8898, recall: 0.2650, f1: 0.4084, edges-ner-ontonotes_loss: 0.1225
09/16 12:49:49 PM: Evaluate: task edges-ner-ontonotes, batch 107 (157): mcc: 0.5049, acc: 0.2944, precision: 0.9049, recall: 0.2965, f1: 0.4467, edges-ner-ontonotes_loss: 0.1174
09/16 12:49:59 PM: Evaluate: task edges-ner-ontonotes, batch 154 (157): mcc: 0.5161, acc: 0.3055, precision: 0.9052, recall: 0.3095, f1: 0.4612, edges-ner-ontonotes_loss: 0.1140
09/16 12:49:59 PM: Updating LR scheduler:
09/16 12:49:59 PM: 	Best result seen so far for macro_avg: 0.479
09/16 12:49:59 PM: 	# validation passes without improvement: 1
09/16 12:49:59 PM: edges-ner-ontonotes_loss: training: 0.118660 validation: 0.113661
09/16 12:49:59 PM: macro_avg: validation: 0.462659
09/16 12:49:59 PM: micro_avg: validation: 0.000000
09/16 12:49:59 PM: edges-ner-ontonotes_mcc: training: 0.510350 validation: 0.517206
09/16 12:49:59 PM: edges-ner-ontonotes_acc: training: 0.344716 validation: 0.306870
09/16 12:49:59 PM: edges-ner-ontonotes_precision: training: 0.770992 validation: 0.905235
09/16 12:49:59 PM: edges-ner-ontonotes_recall: training: 0.360893 validation: 0.310737
09/16 12:49:59 PM: edges-ner-ontonotes_f1: training: 0.491650 validation: 0.462659
09/16 12:49:59 PM: Global learning rate: 0.0001
09/16 12:49:59 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 12:50:09 PM: Update 6072: task edges-ner-ontonotes, batch 72 (6072): mcc: 0.4770, acc: 0.3119, precision: 0.7658, recall: 0.3187, f1: 0.4501, edges-ner-ontonotes_loss: 0.1287
09/16 12:50:19 PM: Update 6146: task edges-ner-ontonotes, batch 146 (6146): mcc: 0.4755, acc: 0.3115, precision: 0.7609, recall: 0.3190, f1: 0.4495, edges-ner-ontonotes_loss: 0.1289
09/16 12:50:29 PM: Update 6210: task edges-ner-ontonotes, batch 210 (6210): mcc: 0.4796, acc: 0.3155, precision: 0.7623, recall: 0.3237, f1: 0.4545, edges-ner-ontonotes_loss: 0.1282
09/16 12:50:39 PM: Update 6240: task edges-ner-ontonotes, batch 240 (6240): mcc: 0.4791, acc: 0.3153, precision: 0.7605, recall: 0.3239, f1: 0.4543, edges-ner-ontonotes_loss: 0.1279
09/16 12:50:49 PM: Update 6301: task edges-ner-ontonotes, batch 301 (6301): mcc: 0.4804, acc: 0.3163, precision: 0.7615, recall: 0.3251, f1: 0.4557, edges-ner-ontonotes_loss: 0.1266
09/16 12:50:59 PM: Update 6385: task edges-ner-ontonotes, batch 385 (6385): mcc: 0.4845, acc: 0.3194, precision: 0.7665, recall: 0.3282, f1: 0.4596, edges-ner-ontonotes_loss: 0.1255
09/16 12:51:09 PM: Update 6490: task edges-ner-ontonotes, batch 490 (6490): mcc: 0.4891, acc: 0.3235, precision: 0.7705, recall: 0.3324, f1: 0.4644, edges-ner-ontonotes_loss: 0.1241
09/16 12:51:19 PM: Update 6546: task edges-ner-ontonotes, batch 546 (6546): mcc: 0.4919, acc: 0.3261, precision: 0.7729, recall: 0.3350, f1: 0.4674, edges-ner-ontonotes_loss: 0.1233
09/16 12:51:30 PM: Update 6609: task edges-ner-ontonotes, batch 609 (6609): mcc: 0.4929, acc: 0.3275, precision: 0.7719, recall: 0.3368, f1: 0.4689, edges-ner-ontonotes_loss: 0.1232
09/16 12:51:40 PM: Update 6668: task edges-ner-ontonotes, batch 668 (6668): mcc: 0.4938, acc: 0.3286, precision: 0.7721, recall: 0.3378, f1: 0.4700, edges-ner-ontonotes_loss: 0.1229
09/16 12:51:50 PM: Update 6728: task edges-ner-ontonotes, batch 728 (6728): mcc: 0.4954, acc: 0.3308, precision: 0.7714, recall: 0.3403, f1: 0.4723, edges-ner-ontonotes_loss: 0.1224
09/16 12:52:00 PM: Update 6795: task edges-ner-ontonotes, batch 795 (6795): mcc: 0.4978, acc: 0.3332, precision: 0.7724, recall: 0.3432, f1: 0.4752, edges-ner-ontonotes_loss: 0.1218
09/16 12:52:14 PM: Update 6851: task edges-ner-ontonotes, batch 851 (6851): mcc: 0.4990, acc: 0.3346, precision: 0.7728, recall: 0.3445, f1: 0.4766, edges-ner-ontonotes_loss: 0.1214
09/16 12:52:24 PM: Update 6919: task edges-ner-ontonotes, batch 919 (6919): mcc: 0.4987, acc: 0.3343, precision: 0.7709, recall: 0.3451, f1: 0.4768, edges-ner-ontonotes_loss: 0.1213
09/16 12:52:34 PM: Update 6984: task edges-ner-ontonotes, batch 984 (6984): mcc: 0.4995, acc: 0.3351, precision: 0.7696, recall: 0.3467, f1: 0.4781, edges-ner-ontonotes_loss: 0.1210
09/16 12:52:36 PM: ***** Step 7000 / Validation 7 *****
09/16 12:52:36 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:52:36 PM: Validating...
09/16 12:52:44 PM: Evaluate: task edges-ner-ontonotes, batch 51 (157): mcc: 0.4716, acc: 0.2879, precision: 0.8112, recall: 0.2925, f1: 0.4299, edges-ner-ontonotes_loss: 0.1274
09/16 12:52:54 PM: Evaluate: task edges-ner-ontonotes, batch 104 (157): mcc: 0.5193, acc: 0.3264, precision: 0.8550, recall: 0.3333, f1: 0.4796, edges-ner-ontonotes_loss: 0.1205
09/16 12:53:04 PM: Evaluate: task edges-ner-ontonotes, batch 154 (157): mcc: 0.5316, acc: 0.3375, precision: 0.8603, recall: 0.3465, f1: 0.4941, edges-ner-ontonotes_loss: 0.1153
09/16 12:53:04 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:53:04 PM: Best result seen so far for macro.
09/16 12:53:04 PM: Updating LR scheduler:
09/16 12:53:04 PM: 	Best result seen so far for macro_avg: 0.495
09/16 12:53:04 PM: 	# validation passes without improvement: 0
09/16 12:53:04 PM: edges-ner-ontonotes_loss: training: 0.120885 validation: 0.115084
09/16 12:53:04 PM: macro_avg: validation: 0.494840
09/16 12:53:04 PM: micro_avg: validation: 0.000000
09/16 12:53:04 PM: edges-ner-ontonotes_mcc: training: 0.499713 validation: 0.532264
09/16 12:53:04 PM: edges-ner-ontonotes_acc: training: 0.335209 validation: 0.338110
09/16 12:53:04 PM: edges-ner-ontonotes_precision: training: 0.769660 validation: 0.860876
09/16 12:53:04 PM: edges-ner-ontonotes_recall: training: 0.347037 validation: 0.347210
09/16 12:53:04 PM: edges-ner-ontonotes_f1: training: 0.478376 validation: 0.494840
09/16 12:53:04 PM: Global learning rate: 0.0001
09/16 12:53:04 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 12:53:14 PM: Update 7065: task edges-ner-ontonotes, batch 65 (7065): mcc: 0.5189, acc: 0.3527, precision: 0.7672, recall: 0.3747, f1: 0.5035, edges-ner-ontonotes_loss: 0.1149
09/16 12:53:24 PM: Update 7117: task edges-ner-ontonotes, batch 117 (7117): mcc: 0.5193, acc: 0.3535, precision: 0.7670, recall: 0.3754, f1: 0.5041, edges-ner-ontonotes_loss: 0.1148
09/16 12:53:35 PM: Update 7164: task edges-ner-ontonotes, batch 164 (7164): mcc: 0.5231, acc: 0.3585, precision: 0.7675, recall: 0.3805, f1: 0.5088, edges-ner-ontonotes_loss: 0.1145
09/16 12:53:45 PM: Update 7232: task edges-ner-ontonotes, batch 232 (7232): mcc: 0.5214, acc: 0.3580, precision: 0.7649, recall: 0.3795, f1: 0.5073, edges-ner-ontonotes_loss: 0.1148
09/16 12:53:55 PM: Update 7303: task edges-ner-ontonotes, batch 303 (7303): mcc: 0.5243, acc: 0.3601, precision: 0.7708, recall: 0.3805, f1: 0.5095, edges-ner-ontonotes_loss: 0.1143
09/16 12:54:06 PM: Update 7367: task edges-ner-ontonotes, batch 367 (7367): mcc: 0.5272, acc: 0.3630, precision: 0.7730, recall: 0.3834, f1: 0.5125, edges-ner-ontonotes_loss: 0.1141
09/16 12:54:16 PM: Update 7425: task edges-ner-ontonotes, batch 425 (7425): mcc: 0.5247, acc: 0.3612, precision: 0.7691, recall: 0.3819, f1: 0.5104, edges-ner-ontonotes_loss: 0.1146
09/16 12:54:28 PM: Update 7477: task edges-ner-ontonotes, batch 477 (7477): mcc: 0.5238, acc: 0.3600, precision: 0.7691, recall: 0.3807, f1: 0.5093, edges-ner-ontonotes_loss: 0.1148
09/16 12:54:38 PM: Update 7556: task edges-ner-ontonotes, batch 556 (7556): mcc: 0.5181, acc: 0.3551, precision: 0.7660, recall: 0.3743, f1: 0.5029, edges-ner-ontonotes_loss: 0.1170
09/16 12:54:48 PM: Update 7618: task edges-ner-ontonotes, batch 618 (7618): mcc: 0.5151, acc: 0.3518, precision: 0.7659, recall: 0.3701, f1: 0.4991, edges-ner-ontonotes_loss: 0.1181
09/16 12:54:58 PM: Update 7704: task edges-ner-ontonotes, batch 704 (7704): mcc: 0.5113, acc: 0.3478, precision: 0.7651, recall: 0.3653, f1: 0.4945, edges-ner-ontonotes_loss: 0.1196
09/16 12:55:08 PM: Update 7767: task edges-ner-ontonotes, batch 767 (7767): mcc: 0.5097, acc: 0.3464, precision: 0.7645, recall: 0.3634, f1: 0.4926, edges-ner-ontonotes_loss: 0.1202
09/16 12:55:18 PM: Update 7814: task edges-ner-ontonotes, batch 814 (7814): mcc: 0.5084, acc: 0.3449, precision: 0.7643, recall: 0.3616, f1: 0.4910, edges-ner-ontonotes_loss: 0.1206
09/16 12:55:28 PM: Update 7880: task edges-ner-ontonotes, batch 880 (7880): mcc: 0.5069, acc: 0.3432, precision: 0.7642, recall: 0.3596, f1: 0.4890, edges-ner-ontonotes_loss: 0.1206
09/16 12:55:38 PM: Update 7956: task edges-ner-ontonotes, batch 956 (7956): mcc: 0.5069, acc: 0.3431, precision: 0.7653, recall: 0.3591, f1: 0.4888, edges-ner-ontonotes_loss: 0.1204
09/16 12:55:45 PM: ***** Step 8000 / Validation 8 *****
09/16 12:55:45 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:55:45 PM: Validating...
09/16 12:55:48 PM: Evaluate: task edges-ner-ontonotes, batch 19 (157): mcc: 0.5024, acc: 0.3083, precision: 0.8588, recall: 0.3109, f1: 0.4565, edges-ner-ontonotes_loss: 0.1226
09/16 12:55:59 PM: Evaluate: task edges-ner-ontonotes, batch 79 (157): mcc: 0.5273, acc: 0.3195, precision: 0.9120, recall: 0.3202, f1: 0.4740, edges-ner-ontonotes_loss: 0.1152
09/16 12:56:09 PM: Evaluate: task edges-ner-ontonotes, batch 135 (157): mcc: 0.5121, acc: 0.3084, precision: 0.8941, recall: 0.3089, f1: 0.4592, edges-ner-ontonotes_loss: 0.1155
09/16 12:56:12 PM: Updating LR scheduler:
09/16 12:56:12 PM: 	Best result seen so far for macro_avg: 0.495
09/16 12:56:12 PM: 	# validation passes without improvement: 1
09/16 12:56:12 PM: edges-ner-ontonotes_loss: training: 0.120147 validation: 0.116414
09/16 12:56:12 PM: macro_avg: validation: 0.448822
09/16 12:56:12 PM: micro_avg: validation: 0.000000
09/16 12:56:12 PM: edges-ner-ontonotes_mcc: training: 0.507752 validation: 0.503947
09/16 12:56:12 PM: edges-ner-ontonotes_acc: training: 0.343726 validation: 0.299287
09/16 12:56:12 PM: edges-ner-ontonotes_precision: training: 0.766769 validation: 0.892930
09/16 12:56:12 PM: edges-ner-ontonotes_recall: training: 0.359486 validation: 0.299742
09/16 12:56:12 PM: edges-ner-ontonotes_f1: training: 0.489486 validation: 0.448822
09/16 12:56:12 PM: Global learning rate: 0.0001
09/16 12:56:12 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 12:56:19 PM: Update 8068: task edges-ner-ontonotes, batch 68 (8068): mcc: 0.5143, acc: 0.3454, precision: 0.7903, recall: 0.3565, f1: 0.4914, edges-ner-ontonotes_loss: 0.1165
09/16 12:56:29 PM: Update 8094: task edges-ner-ontonotes, batch 94 (8094): mcc: 0.5143, acc: 0.3474, precision: 0.7884, recall: 0.3575, f1: 0.4919, edges-ner-ontonotes_loss: 0.1160
09/16 12:56:39 PM: Update 8154: task edges-ner-ontonotes, batch 154 (8154): mcc: 0.5043, acc: 0.3433, precision: 0.7672, recall: 0.3546, f1: 0.4850, edges-ner-ontonotes_loss: 0.1173
09/16 12:56:49 PM: Update 8234: task edges-ner-ontonotes, batch 234 (8234): mcc: 0.5094, acc: 0.3475, precision: 0.7714, recall: 0.3594, f1: 0.4904, edges-ner-ontonotes_loss: 0.1173
09/16 12:56:59 PM: Update 8295: task edges-ner-ontonotes, batch 295 (8295): mcc: 0.5079, acc: 0.3468, precision: 0.7689, recall: 0.3586, f1: 0.4891, edges-ner-ontonotes_loss: 0.1173
09/16 12:57:09 PM: Update 8353: task edges-ner-ontonotes, batch 353 (8353): mcc: 0.5106, acc: 0.3506, precision: 0.7685, recall: 0.3625, f1: 0.4927, edges-ner-ontonotes_loss: 0.1170
09/16 12:57:22 PM: Update 8407: task edges-ner-ontonotes, batch 407 (8407): mcc: 0.5111, acc: 0.3517, precision: 0.7682, recall: 0.3633, f1: 0.4934, edges-ner-ontonotes_loss: 0.1170
09/16 12:57:32 PM: Update 8470: task edges-ner-ontonotes, batch 470 (8470): mcc: 0.5109, acc: 0.3510, precision: 0.7669, recall: 0.3637, f1: 0.4935, edges-ner-ontonotes_loss: 0.1169
09/16 12:57:42 PM: Update 8531: task edges-ner-ontonotes, batch 531 (8531): mcc: 0.5103, acc: 0.3505, precision: 0.7648, recall: 0.3641, f1: 0.4933, edges-ner-ontonotes_loss: 0.1169
09/16 12:57:52 PM: Update 8605: task edges-ner-ontonotes, batch 605 (8605): mcc: 0.5118, acc: 0.3516, precision: 0.7647, recall: 0.3661, f1: 0.4952, edges-ner-ontonotes_loss: 0.1164
09/16 12:58:02 PM: Update 8670: task edges-ner-ontonotes, batch 670 (8670): mcc: 0.5130, acc: 0.3524, precision: 0.7654, recall: 0.3675, f1: 0.4966, edges-ner-ontonotes_loss: 0.1163
09/16 12:58:13 PM: Update 8720: task edges-ner-ontonotes, batch 720 (8720): mcc: 0.5142, acc: 0.3534, precision: 0.7656, recall: 0.3690, f1: 0.4980, edges-ner-ontonotes_loss: 0.1161
09/16 12:58:23 PM: Update 8782: task edges-ner-ontonotes, batch 782 (8782): mcc: 0.5147, acc: 0.3536, precision: 0.7649, recall: 0.3701, f1: 0.4988, edges-ner-ontonotes_loss: 0.1159
09/16 12:58:33 PM: Update 8858: task edges-ner-ontonotes, batch 858 (8858): mcc: 0.5164, acc: 0.3552, precision: 0.7659, recall: 0.3719, f1: 0.5007, edges-ner-ontonotes_loss: 0.1156
09/16 12:58:43 PM: Update 8943: task edges-ner-ontonotes, batch 943 (8943): mcc: 0.5176, acc: 0.3566, precision: 0.7661, recall: 0.3735, f1: 0.5022, edges-ner-ontonotes_loss: 0.1154
09/16 12:58:51 PM: ***** Step 9000 / Validation 9 *****
09/16 12:58:51 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:58:51 PM: Validating...
09/16 12:58:53 PM: Evaluate: task edges-ner-ontonotes, batch 10 (157): mcc: 0.4781, acc: 0.3075, precision: 0.7799, recall: 0.3137, f1: 0.4474, edges-ner-ontonotes_loss: 0.1422
09/16 12:59:03 PM: Evaluate: task edges-ner-ontonotes, batch 65 (157): mcc: 0.4704, acc: 0.2745, precision: 0.8418, recall: 0.2793, f1: 0.4195, edges-ner-ontonotes_loss: 0.1253
09/16 12:59:13 PM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.5178, acc: 0.3190, precision: 0.8641, recall: 0.3276, f1: 0.4751, edges-ner-ontonotes_loss: 0.1176
09/16 12:59:22 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:59:22 PM: Best result seen so far for macro.
09/16 12:59:22 PM: Updating LR scheduler:
09/16 12:59:22 PM: 	Best result seen so far for macro_avg: 0.498
09/16 12:59:22 PM: 	# validation passes without improvement: 0
09/16 12:59:22 PM: edges-ner-ontonotes_loss: training: 0.115431 validation: 0.112347
09/16 12:59:22 PM: macro_avg: validation: 0.497801
09/16 12:59:22 PM: micro_avg: validation: 0.000000
09/16 12:59:22 PM: edges-ner-ontonotes_mcc: training: 0.517802 validation: 0.537870
09/16 12:59:22 PM: edges-ner-ontonotes_acc: training: 0.356764 validation: 0.338793
09/16 12:59:22 PM: edges-ner-ontonotes_precision: training: 0.766255 validation: 0.876170
09/16 12:59:22 PM: edges-ner-ontonotes_recall: training: 0.373744 validation: 0.347665
09/16 12:59:22 PM: edges-ner-ontonotes_f1: training: 0.502427 validation: 0.497801
09/16 12:59:22 PM: Global learning rate: 0.0001
09/16 12:59:22 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 12:59:23 PM: Update 9009: task edges-ner-ontonotes, batch 9 (9009): mcc: 0.5220, acc: 0.3564, precision: 0.7662, recall: 0.3798, f1: 0.5078, edges-ner-ontonotes_loss: 0.1129
09/16 12:59:33 PM: Update 9035: task edges-ner-ontonotes, batch 35 (9035): mcc: 0.5186, acc: 0.3645, precision: 0.7476, recall: 0.3851, f1: 0.5083, edges-ner-ontonotes_loss: 0.1154
09/16 12:59:43 PM: Update 9104: task edges-ner-ontonotes, batch 104 (9104): mcc: 0.4904, acc: 0.3309, precision: 0.7462, recall: 0.3462, f1: 0.4730, edges-ner-ontonotes_loss: 0.1255
09/16 12:59:53 PM: Update 9182: task edges-ner-ontonotes, batch 182 (9182): mcc: 0.4928, acc: 0.3315, precision: 0.7558, recall: 0.3446, f1: 0.4734, edges-ner-ontonotes_loss: 0.1261
09/16 01:00:03 PM: Update 9252: task edges-ner-ontonotes, batch 252 (9252): mcc: 0.4891, acc: 0.3279, precision: 0.7546, recall: 0.3401, f1: 0.4689, edges-ner-ontonotes_loss: 0.1275
09/16 01:00:14 PM: Update 9321: task edges-ner-ontonotes, batch 321 (9321): mcc: 0.4899, acc: 0.3293, precision: 0.7552, recall: 0.3410, f1: 0.4698, edges-ner-ontonotes_loss: 0.1274
09/16 01:00:24 PM: Update 9344: task edges-ner-ontonotes, batch 344 (9344): mcc: 0.4890, acc: 0.3285, precision: 0.7542, recall: 0.3402, f1: 0.4689, edges-ner-ontonotes_loss: 0.1272
09/16 01:00:34 PM: Update 9430: task edges-ner-ontonotes, batch 430 (9430): mcc: 0.4888, acc: 0.3272, precision: 0.7565, recall: 0.3388, f1: 0.4680, edges-ner-ontonotes_loss: 0.1258
09/16 01:00:45 PM: Update 9503: task edges-ner-ontonotes, batch 503 (9503): mcc: 0.4910, acc: 0.3293, precision: 0.7583, recall: 0.3409, f1: 0.4703, edges-ner-ontonotes_loss: 0.1245
09/16 01:00:55 PM: Update 9580: task edges-ner-ontonotes, batch 580 (9580): mcc: 0.4943, acc: 0.3319, precision: 0.7626, recall: 0.3432, f1: 0.4734, edges-ner-ontonotes_loss: 0.1237
09/16 01:01:06 PM: Update 9650: task edges-ner-ontonotes, batch 650 (9650): mcc: 0.4966, acc: 0.3342, precision: 0.7648, recall: 0.3452, f1: 0.4757, edges-ner-ontonotes_loss: 0.1229
09/16 01:01:16 PM: Update 9733: task edges-ner-ontonotes, batch 733 (9733): mcc: 0.4937, acc: 0.3320, precision: 0.7609, recall: 0.3432, f1: 0.4730, edges-ner-ontonotes_loss: 0.1230
09/16 01:01:26 PM: Update 9830: task edges-ner-ontonotes, batch 830 (9830): mcc: 0.4963, acc: 0.3349, precision: 0.7623, recall: 0.3461, f1: 0.4761, edges-ner-ontonotes_loss: 0.1222
09/16 01:01:36 PM: Update 9909: task edges-ner-ontonotes, batch 909 (9909): mcc: 0.4992, acc: 0.3376, precision: 0.7640, recall: 0.3491, f1: 0.4792, edges-ner-ontonotes_loss: 0.1215
09/16 01:01:48 PM: Update 9963: task edges-ner-ontonotes, batch 963 (9963): mcc: 0.5013, acc: 0.3399, precision: 0.7648, recall: 0.3517, f1: 0.4818, edges-ner-ontonotes_loss: 0.1211
09/16 01:01:54 PM: ***** Step 10000 / Validation 10 *****
09/16 01:01:54 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:01:54 PM: Validating...
09/16 01:01:59 PM: Evaluate: task edges-ner-ontonotes, batch 18 (157): mcc: 0.4300, acc: 0.2608, precision: 0.7571, recall: 0.2635, f1: 0.3909, edges-ner-ontonotes_loss: 0.1373
09/16 01:02:09 PM: Evaluate: task edges-ner-ontonotes, batch 72 (157): mcc: 0.4857, acc: 0.2980, precision: 0.8252, recall: 0.3040, f1: 0.4444, edges-ner-ontonotes_loss: 0.1229
09/16 01:02:19 PM: Evaluate: task edges-ner-ontonotes, batch 123 (157): mcc: 0.5236, acc: 0.3285, precision: 0.8593, recall: 0.3369, f1: 0.4840, edges-ner-ontonotes_loss: 0.1164
09/16 01:02:27 PM: Updating LR scheduler:
09/16 01:02:27 PM: 	Best result seen so far for macro_avg: 0.498
09/16 01:02:27 PM: 	# validation passes without improvement: 1
09/16 01:02:27 PM: edges-ner-ontonotes_loss: training: 0.120798 validation: 0.114389
09/16 01:02:27 PM: macro_avg: validation: 0.486596
09/16 01:02:27 PM: micro_avg: validation: 0.000000
09/16 01:02:27 PM: edges-ner-ontonotes_mcc: training: 0.501709 validation: 0.526726
09/16 01:02:27 PM: edges-ner-ontonotes_acc: training: 0.340139 validation: 0.330149
09/16 01:02:27 PM: edges-ner-ontonotes_precision: training: 0.764263 validation: 0.864640
09/16 01:02:27 PM: edges-ner-ontonotes_recall: training: 0.352465 validation: 0.338565
09/16 01:02:27 PM: edges-ner-ontonotes_f1: training: 0.482438 validation: 0.486596
09/16 01:02:27 PM: Global learning rate: 0.0001
09/16 01:02:27 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 01:02:29 PM: Update 10013: task edges-ner-ontonotes, batch 13 (10013): mcc: 0.5312, acc: 0.3602, precision: 0.7887, recall: 0.3806, f1: 0.5134, edges-ner-ontonotes_loss: 0.1119
09/16 01:02:39 PM: Update 10077: task edges-ner-ontonotes, batch 77 (10077): mcc: 0.5185, acc: 0.3556, precision: 0.7609, recall: 0.3776, f1: 0.5047, edges-ner-ontonotes_loss: 0.1152
09/16 01:02:49 PM: Update 10149: task edges-ner-ontonotes, batch 149 (10149): mcc: 0.5204, acc: 0.3566, precision: 0.7650, recall: 0.3781, f1: 0.5061, edges-ner-ontonotes_loss: 0.1148
09/16 01:03:00 PM: Update 10211: task edges-ner-ontonotes, batch 211 (10211): mcc: 0.5222, acc: 0.3587, precision: 0.7640, recall: 0.3812, f1: 0.5087, edges-ner-ontonotes_loss: 0.1145
09/16 01:03:13 PM: Update 10276: task edges-ner-ontonotes, batch 276 (10276): mcc: 0.5209, acc: 0.3584, precision: 0.7627, recall: 0.3800, f1: 0.5073, edges-ner-ontonotes_loss: 0.1148
09/16 01:03:23 PM: Update 10343: task edges-ner-ontonotes, batch 343 (10343): mcc: 0.5223, acc: 0.3594, precision: 0.7634, recall: 0.3816, f1: 0.5088, edges-ner-ontonotes_loss: 0.1145
09/16 01:03:33 PM: Update 10396: task edges-ner-ontonotes, batch 396 (10396): mcc: 0.5233, acc: 0.3605, precision: 0.7646, recall: 0.3824, f1: 0.5098, edges-ner-ontonotes_loss: 0.1142
09/16 01:03:43 PM: Update 10470: task edges-ner-ontonotes, batch 470 (10470): mcc: 0.5245, acc: 0.3616, precision: 0.7658, recall: 0.3835, f1: 0.5110, edges-ner-ontonotes_loss: 0.1140
09/16 01:03:53 PM: Update 10534: task edges-ner-ontonotes, batch 534 (10534): mcc: 0.5239, acc: 0.3611, precision: 0.7652, recall: 0.3829, f1: 0.5104, edges-ner-ontonotes_loss: 0.1142
09/16 01:04:07 PM: Update 10589: task edges-ner-ontonotes, batch 589 (10589): mcc: 0.5234, acc: 0.3608, precision: 0.7653, recall: 0.3821, f1: 0.5097, edges-ner-ontonotes_loss: 0.1142
09/16 01:04:17 PM: Update 10625: task edges-ner-ontonotes, batch 625 (10625): mcc: 0.5200, acc: 0.3579, precision: 0.7626, recall: 0.3789, f1: 0.5062, edges-ner-ontonotes_loss: 0.1153
09/16 01:04:27 PM: Update 10681: task edges-ner-ontonotes, batch 681 (10681): mcc: 0.5164, acc: 0.3542, precision: 0.7611, recall: 0.3745, f1: 0.5020, edges-ner-ontonotes_loss: 0.1167
09/16 01:04:37 PM: Update 10761: task edges-ner-ontonotes, batch 761 (10761): mcc: 0.5132, acc: 0.3512, precision: 0.7599, recall: 0.3707, f1: 0.4983, edges-ner-ontonotes_loss: 0.1177
09/16 01:04:47 PM: Update 10831: task edges-ner-ontonotes, batch 831 (10831): mcc: 0.5123, acc: 0.3502, precision: 0.7605, recall: 0.3691, f1: 0.4969, edges-ner-ontonotes_loss: 0.1184
09/16 01:04:57 PM: Update 10892: task edges-ner-ontonotes, batch 892 (10892): mcc: 0.5117, acc: 0.3498, precision: 0.7608, recall: 0.3682, f1: 0.4962, edges-ner-ontonotes_loss: 0.1189
09/16 01:05:07 PM: Update 10921: task edges-ner-ontonotes, batch 921 (10921): mcc: 0.5111, acc: 0.3492, precision: 0.7608, recall: 0.3673, f1: 0.4954, edges-ner-ontonotes_loss: 0.1190
09/16 01:05:17 PM: Update 10983: task edges-ner-ontonotes, batch 983 (10983): mcc: 0.5108, acc: 0.3484, precision: 0.7619, recall: 0.3662, f1: 0.4947, edges-ner-ontonotes_loss: 0.1190
09/16 01:05:20 PM: ***** Step 11000 / Validation 11 *****
09/16 01:05:20 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:05:20 PM: Validating...
09/16 01:05:28 PM: Evaluate: task edges-ner-ontonotes, batch 48 (157): mcc: 0.5222, acc: 0.3210, precision: 0.8915, recall: 0.3219, f1: 0.4731, edges-ner-ontonotes_loss: 0.1142
09/16 01:05:38 PM: Evaluate: task edges-ner-ontonotes, batch 102 (157): mcc: 0.5231, acc: 0.3176, precision: 0.9026, recall: 0.3187, f1: 0.4711, edges-ner-ontonotes_loss: 0.1136
09/16 01:05:48 PM: Evaluate: task edges-ner-ontonotes, batch 152 (157): mcc: 0.5239, acc: 0.3193, precision: 0.9005, recall: 0.3205, f1: 0.4728, edges-ner-ontonotes_loss: 0.1121
09/16 01:05:48 PM: Updating LR scheduler:
09/16 01:05:48 PM: 	Best result seen so far for macro_avg: 0.498
09/16 01:05:48 PM: 	# validation passes without improvement: 2
09/16 01:05:48 PM: edges-ner-ontonotes_loss: training: 0.118980 validation: 0.111992
09/16 01:05:48 PM: macro_avg: validation: 0.474402
09/16 01:05:48 PM: micro_avg: validation: 0.000000
09/16 01:05:48 PM: edges-ner-ontonotes_mcc: training: 0.511011 validation: 0.525544
09/16 01:05:48 PM: edges-ner-ontonotes_acc: training: 0.348525 validation: 0.320594
09/16 01:05:48 PM: edges-ner-ontonotes_precision: training: 0.762478 validation: 0.902211
09/16 01:05:48 PM: edges-ner-ontonotes_recall: training: 0.366248 validation: 0.321808
09/16 01:05:48 PM: edges-ner-ontonotes_f1: training: 0.494816 validation: 0.474402
09/16 01:05:48 PM: Global learning rate: 0.0001
09/16 01:05:48 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 01:05:58 PM: Update 11071: task edges-ner-ontonotes, batch 71 (11071): mcc: 0.5056, acc: 0.3439, precision: 0.7732, recall: 0.3533, f1: 0.4850, edges-ner-ontonotes_loss: 0.1172
09/16 01:06:08 PM: Update 11151: task edges-ner-ontonotes, batch 151 (11151): mcc: 0.5148, acc: 0.3519, precision: 0.7801, recall: 0.3623, f1: 0.4948, edges-ner-ontonotes_loss: 0.1158
09/16 01:06:19 PM: Update 11206: task edges-ner-ontonotes, batch 206 (11206): mcc: 0.5181, acc: 0.3558, precision: 0.7807, recall: 0.3666, f1: 0.4989, edges-ner-ontonotes_loss: 0.1153
09/16 01:06:29 PM: Update 11293: task edges-ner-ontonotes, batch 293 (11293): mcc: 0.5140, acc: 0.3538, precision: 0.7733, recall: 0.3647, f1: 0.4957, edges-ner-ontonotes_loss: 0.1160
09/16 01:06:39 PM: Update 11370: task edges-ner-ontonotes, batch 370 (11370): mcc: 0.5123, acc: 0.3527, precision: 0.7697, recall: 0.3642, f1: 0.4945, edges-ner-ontonotes_loss: 0.1163
09/16 01:06:49 PM: Update 11440: task edges-ner-ontonotes, batch 440 (11440): mcc: 0.5108, acc: 0.3513, precision: 0.7676, recall: 0.3632, f1: 0.4931, edges-ner-ontonotes_loss: 0.1164
09/16 01:06:59 PM: Update 11516: task edges-ner-ontonotes, batch 516 (11516): mcc: 0.5146, acc: 0.3552, precision: 0.7700, recall: 0.3673, f1: 0.4973, edges-ner-ontonotes_loss: 0.1159
09/16 01:07:09 PM: Update 11551: task edges-ner-ontonotes, batch 551 (11551): mcc: 0.5144, acc: 0.3549, precision: 0.7683, recall: 0.3679, f1: 0.4976, edges-ner-ontonotes_loss: 0.1159
09/16 01:07:20 PM: Update 11602: task edges-ner-ontonotes, batch 602 (11602): mcc: 0.5151, acc: 0.3549, precision: 0.7674, recall: 0.3693, f1: 0.4986, edges-ner-ontonotes_loss: 0.1159
09/16 01:07:30 PM: Update 11659: task edges-ner-ontonotes, batch 659 (11659): mcc: 0.5137, acc: 0.3532, precision: 0.7659, recall: 0.3682, f1: 0.4973, edges-ner-ontonotes_loss: 0.1162
09/16 01:07:40 PM: Update 11724: task edges-ner-ontonotes, batch 724 (11724): mcc: 0.5150, acc: 0.3540, precision: 0.7664, recall: 0.3697, f1: 0.4988, edges-ner-ontonotes_loss: 0.1158
09/16 01:07:50 PM: Update 11786: task edges-ner-ontonotes, batch 786 (11786): mcc: 0.5168, acc: 0.3555, precision: 0.7672, recall: 0.3718, f1: 0.5009, edges-ner-ontonotes_loss: 0.1155
09/16 01:08:02 PM: Update 11832: task edges-ner-ontonotes, batch 832 (11832): mcc: 0.5179, acc: 0.3570, precision: 0.7670, recall: 0.3734, f1: 0.5023, edges-ner-ontonotes_loss: 0.1154
09/16 01:08:12 PM: Update 11907: task edges-ner-ontonotes, batch 907 (11907): mcc: 0.5178, acc: 0.3568, precision: 0.7660, recall: 0.3738, f1: 0.5024, edges-ner-ontonotes_loss: 0.1153
09/16 01:08:22 PM: Update 11981: task edges-ner-ontonotes, batch 981 (11981): mcc: 0.5197, acc: 0.3586, precision: 0.7668, recall: 0.3761, f1: 0.5047, edges-ner-ontonotes_loss: 0.1150
09/16 01:08:25 PM: ***** Step 12000 / Validation 12 *****
09/16 01:08:25 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:08:25 PM: Validating...
09/16 01:08:32 PM: Evaluate: task edges-ner-ontonotes, batch 44 (157): mcc: 0.4648, acc: 0.2876, precision: 0.7921, recall: 0.2918, f1: 0.4265, edges-ner-ontonotes_loss: 0.1283
09/16 01:08:42 PM: Evaluate: task edges-ner-ontonotes, batch 97 (157): mcc: 0.5038, acc: 0.3148, precision: 0.8411, recall: 0.3198, f1: 0.4634, edges-ner-ontonotes_loss: 0.1213
09/16 01:08:52 PM: Evaluate: task edges-ner-ontonotes, batch 142 (157): mcc: 0.5406, acc: 0.3485, precision: 0.8670, recall: 0.3551, f1: 0.5039, edges-ner-ontonotes_loss: 0.1136
09/16 01:08:55 PM: Best result seen so far for edges-ner-ontonotes.
09/16 01:08:57 PM: Best result seen so far for macro.
09/16 01:08:57 PM: Updating LR scheduler:
09/16 01:08:57 PM: 	Best result seen so far for macro_avg: 0.505
09/16 01:08:57 PM: 	# validation passes without improvement: 0
09/16 01:08:57 PM: edges-ner-ontonotes_loss: training: 0.115060 validation: 0.112903
09/16 01:08:57 PM: macro_avg: validation: 0.504682
09/16 01:08:57 PM: micro_avg: validation: 0.000000
09/16 01:08:57 PM: edges-ner-ontonotes_mcc: training: 0.519588 validation: 0.541697
09/16 01:08:57 PM: edges-ner-ontonotes_acc: training: 0.358674 validation: 0.349105
09/16 01:08:57 PM: edges-ner-ontonotes_precision: training: 0.766283 validation: 0.869299
09/16 01:08:57 PM: edges-ner-ontonotes_recall: training: 0.376242 validation: 0.355550
09/16 01:08:57 PM: edges-ner-ontonotes_f1: training: 0.504685 validation: 0.504682
09/16 01:08:57 PM: Global learning rate: 0.0001
09/16 01:08:57 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 01:09:02 PM: Update 12034: task edges-ner-ontonotes, batch 34 (12034): mcc: 0.5214, acc: 0.3574, precision: 0.7659, recall: 0.3791, f1: 0.5072, edges-ner-ontonotes_loss: 0.1139
09/16 01:09:12 PM: Update 12107: task edges-ner-ontonotes, batch 107 (12107): mcc: 0.5292, acc: 0.3664, precision: 0.7723, recall: 0.3866, f1: 0.5153, edges-ner-ontonotes_loss: 0.1118
09/16 01:09:24 PM: Update 12145: task edges-ner-ontonotes, batch 145 (12145): mcc: 0.5285, acc: 0.3666, precision: 0.7682, recall: 0.3878, f1: 0.5154, edges-ner-ontonotes_loss: 0.1123
09/16 01:09:34 PM: Update 12219: task edges-ner-ontonotes, batch 219 (12219): mcc: 0.5106, acc: 0.3493, precision: 0.7579, recall: 0.3681, f1: 0.4955, edges-ner-ontonotes_loss: 0.1189
09/16 01:09:44 PM: Update 12281: task edges-ner-ontonotes, batch 281 (12281): mcc: 0.5055, acc: 0.3433, precision: 0.7584, recall: 0.3607, f1: 0.4889, edges-ner-ontonotes_loss: 0.1212
09/16 01:09:54 PM: Update 12341: task edges-ner-ontonotes, batch 341 (12341): mcc: 0.5063, acc: 0.3438, precision: 0.7611, recall: 0.3604, f1: 0.4892, edges-ner-ontonotes_loss: 0.1218
09/16 01:10:05 PM: Update 12407: task edges-ner-ontonotes, batch 407 (12407): mcc: 0.5055, acc: 0.3431, precision: 0.7619, recall: 0.3589, f1: 0.4880, edges-ner-ontonotes_loss: 0.1223
09/16 01:10:19 PM: Update 12449: task edges-ner-ontonotes, batch 449 (12449): mcc: 0.5051, acc: 0.3432, precision: 0.7610, recall: 0.3588, f1: 0.4876, edges-ner-ontonotes_loss: 0.1226
09/16 01:10:30 PM: Update 12529: task edges-ner-ontonotes, batch 529 (12529): mcc: 0.5025, acc: 0.3405, precision: 0.7604, recall: 0.3555, f1: 0.4845, edges-ner-ontonotes_loss: 0.1223
09/16 01:10:40 PM: Update 12604: task edges-ner-ontonotes, batch 604 (12604): mcc: 0.5035, acc: 0.3408, precision: 0.7631, recall: 0.3555, f1: 0.4851, edges-ner-ontonotes_loss: 0.1216
09/16 01:10:50 PM: Update 12687: task edges-ner-ontonotes, batch 687 (12687): mcc: 0.5049, acc: 0.3422, precision: 0.7651, recall: 0.3565, f1: 0.4864, edges-ner-ontonotes_loss: 0.1210
09/16 01:11:04 PM: Update 12762: task edges-ner-ontonotes, batch 762 (12762): mcc: 0.5074, acc: 0.3447, precision: 0.7668, recall: 0.3590, f1: 0.4890, edges-ner-ontonotes_loss: 0.1203
09/16 01:11:14 PM: Update 12823: task edges-ner-ontonotes, batch 823 (12823): mcc: 0.5054, acc: 0.3428, precision: 0.7652, recall: 0.3571, f1: 0.4870, edges-ner-ontonotes_loss: 0.1203
09/16 01:11:24 PM: Update 12894: task edges-ner-ontonotes, batch 894 (12894): mcc: 0.5065, acc: 0.3443, precision: 0.7654, recall: 0.3585, f1: 0.4883, edges-ner-ontonotes_loss: 0.1200
09/16 01:11:34 PM: Update 12977: task edges-ner-ontonotes, batch 977 (12977): mcc: 0.5079, acc: 0.3459, precision: 0.7666, recall: 0.3599, f1: 0.4898, edges-ner-ontonotes_loss: 0.1195
09/16 01:11:37 PM: ***** Step 13000 / Validation 13 *****
09/16 01:11:37 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:11:37 PM: Validating...
09/16 01:11:44 PM: Evaluate: task edges-ner-ontonotes, batch 56 (157): mcc: 0.5281, acc: 0.3272, precision: 0.8914, recall: 0.3292, f1: 0.4808, edges-ner-ontonotes_loss: 0.1123
09/16 01:11:54 PM: Evaluate: task edges-ner-ontonotes, batch 115 (157): mcc: 0.5296, acc: 0.3284, precision: 0.8865, recall: 0.3330, f1: 0.4841, edges-ner-ontonotes_loss: 0.1111
09/16 01:12:02 PM: Updating LR scheduler:
09/16 01:12:02 PM: 	Best result seen so far for macro_avg: 0.505
09/16 01:12:02 PM: 	# validation passes without improvement: 1
09/16 01:12:02 PM: edges-ner-ontonotes_loss: training: 0.119470 validation: 0.109895
09/16 01:12:02 PM: macro_avg: validation: 0.482217
09/16 01:12:02 PM: micro_avg: validation: 0.000000
09/16 01:12:02 PM: edges-ner-ontonotes_mcc: training: 0.508171 validation: 0.529150
09/16 01:12:02 PM: edges-ner-ontonotes_acc: training: 0.346156 validation: 0.325827
09/16 01:12:02 PM: edges-ner-ontonotes_precision: training: 0.766840 validation: 0.891229
09/16 01:12:02 PM: edges-ner-ontonotes_recall: training: 0.360028 validation: 0.330528
09/16 01:12:02 PM: edges-ner-ontonotes_f1: training: 0.490002 validation: 0.482217
09/16 01:12:02 PM: Global learning rate: 0.0001
09/16 01:12:02 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 01:12:04 PM: Update 13015: task edges-ner-ontonotes, batch 15 (13015): mcc: 0.5393, acc: 0.3825, precision: 0.7806, recall: 0.3963, f1: 0.5257, edges-ner-ontonotes_loss: 0.1144
09/16 01:12:20 PM: Update 13075: task edges-ner-ontonotes, batch 75 (13075): mcc: 0.5277, acc: 0.3704, precision: 0.7762, recall: 0.3824, f1: 0.5124, edges-ner-ontonotes_loss: 0.1143
09/16 01:12:30 PM: Update 13138: task edges-ner-ontonotes, batch 138 (13138): mcc: 0.5225, acc: 0.3618, precision: 0.7676, recall: 0.3797, f1: 0.5081, edges-ner-ontonotes_loss: 0.1147
09/16 01:12:40 PM: Update 13199: task edges-ner-ontonotes, batch 199 (13199): mcc: 0.5201, acc: 0.3577, precision: 0.7649, recall: 0.3777, f1: 0.5057, edges-ner-ontonotes_loss: 0.1147
09/16 01:12:50 PM: Update 13270: task edges-ner-ontonotes, batch 270 (13270): mcc: 0.5237, acc: 0.3609, precision: 0.7682, recall: 0.3811, f1: 0.5094, edges-ner-ontonotes_loss: 0.1139
09/16 01:13:00 PM: Update 13328: task edges-ner-ontonotes, batch 328 (13328): mcc: 0.5241, acc: 0.3614, precision: 0.7674, recall: 0.3821, f1: 0.5101, edges-ner-ontonotes_loss: 0.1138
09/16 01:13:16 PM: Update 13388: task edges-ner-ontonotes, batch 388 (13388): mcc: 0.5263, acc: 0.3630, precision: 0.7694, recall: 0.3841, f1: 0.5124, edges-ner-ontonotes_loss: 0.1136
09/16 01:13:26 PM: Update 13462: task edges-ner-ontonotes, batch 462 (13462): mcc: 0.5261, acc: 0.3634, precision: 0.7674, recall: 0.3849, f1: 0.5127, edges-ner-ontonotes_loss: 0.1135
09/16 01:13:36 PM: Update 13525: task edges-ner-ontonotes, batch 525 (13525): mcc: 0.5261, acc: 0.3630, precision: 0.7682, recall: 0.3844, f1: 0.5124, edges-ner-ontonotes_loss: 0.1134
09/16 01:13:46 PM: Update 13593: task edges-ner-ontonotes, batch 593 (13593): mcc: 0.5272, acc: 0.3643, precision: 0.7684, recall: 0.3859, f1: 0.5138, edges-ner-ontonotes_loss: 0.1132
09/16 01:13:56 PM: Update 13650: task edges-ner-ontonotes, batch 650 (13650): mcc: 0.5270, acc: 0.3640, precision: 0.7686, recall: 0.3854, f1: 0.5134, edges-ner-ontonotes_loss: 0.1131
09/16 01:14:08 PM: Update 13701: task edges-ner-ontonotes, batch 701 (13701): mcc: 0.5270, acc: 0.3643, precision: 0.7680, recall: 0.3858, f1: 0.5136, edges-ner-ontonotes_loss: 0.1131
09/16 01:14:18 PM: Update 13773: task edges-ner-ontonotes, batch 773 (13773): mcc: 0.5226, acc: 0.3605, precision: 0.7643, recall: 0.3815, f1: 0.5090, edges-ner-ontonotes_loss: 0.1148
09/16 01:14:28 PM: Update 13837: task edges-ner-ontonotes, batch 837 (13837): mcc: 0.5197, acc: 0.3578, precision: 0.7630, recall: 0.3781, f1: 0.5057, edges-ner-ontonotes_loss: 0.1159
09/16 01:14:38 PM: Update 13898: task edges-ner-ontonotes, batch 898 (13898): mcc: 0.5185, acc: 0.3567, precision: 0.7631, recall: 0.3765, f1: 0.5042, edges-ner-ontonotes_loss: 0.1166
09/16 01:14:48 PM: Update 13971: task edges-ner-ontonotes, batch 971 (13971): mcc: 0.5165, acc: 0.3547, precision: 0.7628, recall: 0.3738, f1: 0.5017, edges-ner-ontonotes_loss: 0.1172
09/16 01:14:53 PM: ***** Step 14000 / Validation 14 *****
09/16 01:14:53 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:14:53 PM: Validating...
09/16 01:14:58 PM: Evaluate: task edges-ner-ontonotes, batch 27 (157): mcc: 0.4827, acc: 0.2919, precision: 0.8455, recall: 0.2925, f1: 0.4346, edges-ner-ontonotes_loss: 0.1249
09/16 01:15:08 PM: Evaluate: task edges-ner-ontonotes, batch 82 (157): mcc: 0.5170, acc: 0.3138, precision: 0.8941, recall: 0.3147, f1: 0.4656, edges-ner-ontonotes_loss: 0.1135
09/16 01:15:18 PM: Evaluate: task edges-ner-ontonotes, batch 127 (157): mcc: 0.5193, acc: 0.3160, precision: 0.8915, recall: 0.3184, f1: 0.4693, edges-ner-ontonotes_loss: 0.1116
09/16 01:15:25 PM: Updating LR scheduler:
09/16 01:15:25 PM: 	Best result seen so far for macro_avg: 0.505
09/16 01:15:25 PM: 	# validation passes without improvement: 2
09/16 01:15:25 PM: edges-ner-ontonotes_loss: training: 0.117474 validation: 0.110832
09/16 01:15:25 PM: macro_avg: validation: 0.470299
09/16 01:15:25 PM: micro_avg: validation: 0.000000
09/16 01:15:25 PM: edges-ner-ontonotes_mcc: training: 0.516193 validation: 0.520609
09/16 01:15:25 PM: edges-ner-ontonotes_acc: training: 0.354294 validation: 0.316272
09/16 01:15:25 PM: edges-ner-ontonotes_precision: training: 0.763195 validation: 0.893988
09/16 01:15:25 PM: edges-ner-ontonotes_recall: training: 0.373123 validation: 0.319078
09/16 01:15:25 PM: edges-ner-ontonotes_f1: training: 0.501208 validation: 0.470299
09/16 01:15:25 PM: Global learning rate: 0.0001
09/16 01:15:25 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 01:15:31 PM: Update 14005: task edges-ner-ontonotes, batch 5 (14005): mcc: 0.5099, acc: 0.3591, precision: 0.7613, recall: 0.3653, f1: 0.4937, edges-ner-ontonotes_loss: 0.1163
09/16 01:15:41 PM: Update 14086: task edges-ner-ontonotes, batch 86 (14086): mcc: 0.4972, acc: 0.3352, precision: 0.7689, recall: 0.3440, f1: 0.4753, edges-ner-ontonotes_loss: 0.1196
09/16 01:15:51 PM: Update 14159: task edges-ner-ontonotes, batch 159 (14159): mcc: 0.5051, acc: 0.3417, precision: 0.7738, recall: 0.3522, f1: 0.4841, edges-ner-ontonotes_loss: 0.1182
09/16 01:16:01 PM: Update 14242: task edges-ner-ontonotes, batch 242 (14242): mcc: 0.5108, acc: 0.3468, precision: 0.7772, recall: 0.3583, f1: 0.4905, edges-ner-ontonotes_loss: 0.1171
09/16 01:16:16 PM: Update 14318: task edges-ner-ontonotes, batch 318 (14318): mcc: 0.5136, acc: 0.3499, precision: 0.7783, recall: 0.3616, f1: 0.4938, edges-ner-ontonotes_loss: 0.1164
09/16 01:16:27 PM: Update 14396: task edges-ner-ontonotes, batch 396 (14396): mcc: 0.5103, acc: 0.3480, precision: 0.7729, recall: 0.3599, f1: 0.4911, edges-ner-ontonotes_loss: 0.1171
09/16 01:16:37 PM: Update 14482: task edges-ner-ontonotes, batch 482 (14482): mcc: 0.5106, acc: 0.3490, precision: 0.7711, recall: 0.3612, f1: 0.4920, edges-ner-ontonotes_loss: 0.1171
09/16 01:16:47 PM: Update 14574: task edges-ner-ontonotes, batch 574 (14574): mcc: 0.5136, acc: 0.3518, precision: 0.7731, recall: 0.3643, f1: 0.4953, edges-ner-ontonotes_loss: 0.1163
09/16 01:16:58 PM: Update 14631: task edges-ner-ontonotes, batch 631 (14631): mcc: 0.5148, acc: 0.3536, precision: 0.7725, recall: 0.3663, f1: 0.4970, edges-ner-ontonotes_loss: 0.1161
09/16 01:17:08 PM: Update 14696: task edges-ner-ontonotes, batch 696 (14696): mcc: 0.5141, acc: 0.3529, precision: 0.7693, recall: 0.3669, f1: 0.4968, edges-ner-ontonotes_loss: 0.1161
09/16 01:17:18 PM: Update 14759: task edges-ner-ontonotes, batch 759 (14759): mcc: 0.5138, acc: 0.3528, precision: 0.7666, recall: 0.3679, f1: 0.4972, edges-ner-ontonotes_loss: 0.1160
09/16 01:17:28 PM: Update 14844: task edges-ner-ontonotes, batch 844 (14844): mcc: 0.5148, acc: 0.3533, precision: 0.7668, recall: 0.3693, f1: 0.4985, edges-ner-ontonotes_loss: 0.1157
09/16 01:17:38 PM: Update 14927: task edges-ner-ontonotes, batch 927 (14927): mcc: 0.5173, acc: 0.3561, precision: 0.7674, recall: 0.3725, f1: 0.5015, edges-ner-ontonotes_loss: 0.1153
09/16 01:17:48 PM: Update 14964: task edges-ner-ontonotes, batch 964 (14964): mcc: 0.5173, acc: 0.3560, precision: 0.7671, recall: 0.3726, f1: 0.5015, edges-ner-ontonotes_loss: 0.1152
09/16 01:17:55 PM: ***** Step 15000 / Validation 15 *****
09/16 01:17:55 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:17:55 PM: Validating...
09/16 01:17:58 PM: Evaluate: task edges-ner-ontonotes, batch 19 (157): mcc: 0.4532, acc: 0.2811, precision: 0.7749, recall: 0.2845, f1: 0.4162, edges-ner-ontonotes_loss: 0.1377
09/16 01:18:09 PM: Evaluate: task edges-ner-ontonotes, batch 72 (157): mcc: 0.4725, acc: 0.2871, precision: 0.8161, recall: 0.2916, f1: 0.4297, edges-ner-ontonotes_loss: 0.1259
09/16 01:18:19 PM: Evaluate: task edges-ner-ontonotes, batch 121 (157): mcc: 0.5287, acc: 0.3360, precision: 0.8569, recall: 0.3444, f1: 0.4913, edges-ner-ontonotes_loss: 0.1157
09/16 01:18:25 PM: Updating LR scheduler:
09/16 01:18:25 PM: 	Best result seen so far for macro_avg: 0.505
09/16 01:18:25 PM: 	# validation passes without improvement: 3
09/16 01:18:25 PM: edges-ner-ontonotes_loss: training: 0.115160 validation: 0.112184
09/16 01:18:25 PM: macro_avg: validation: 0.503147
09/16 01:18:25 PM: micro_avg: validation: 0.000000
09/16 01:18:25 PM: edges-ner-ontonotes_mcc: training: 0.517753 validation: 0.539814
09/16 01:18:25 PM: edges-ner-ontonotes_acc: training: 0.356197 validation: 0.346148
09/16 01:18:25 PM: edges-ner-ontonotes_precision: training: 0.767109 validation: 0.866086
09/16 01:18:25 PM: edges-ner-ontonotes_recall: training: 0.373218 validation: 0.354565
09/16 01:18:25 PM: edges-ner-ontonotes_f1: training: 0.502135 validation: 0.503147
09/16 01:18:26 PM: Global learning rate: 0.0001
09/16 01:18:26 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 01:18:29 PM: Update 15024: task edges-ner-ontonotes, batch 24 (15024): mcc: 0.5277, acc: 0.3651, precision: 0.7655, recall: 0.3882, f1: 0.5152, edges-ner-ontonotes_loss: 0.1146
09/16 01:18:39 PM: Update 15087: task edges-ner-ontonotes, batch 87 (15087): mcc: 0.5298, acc: 0.3703, precision: 0.7650, recall: 0.3915, f1: 0.5179, edges-ner-ontonotes_loss: 0.1129
09/16 01:18:49 PM: Update 15148: task edges-ner-ontonotes, batch 148 (15148): mcc: 0.5279, acc: 0.3660, precision: 0.7694, recall: 0.3864, f1: 0.5144, edges-ner-ontonotes_loss: 0.1133
09/16 01:18:59 PM: Update 15213: task edges-ner-ontonotes, batch 213 (15213): mcc: 0.5312, acc: 0.3689, precision: 0.7728, recall: 0.3891, f1: 0.5176, edges-ner-ontonotes_loss: 0.1126
09/16 01:19:12 PM: Update 15257: task edges-ner-ontonotes, batch 257 (15257): mcc: 0.5312, acc: 0.3701, precision: 0.7705, recall: 0.3904, f1: 0.5182, edges-ner-ontonotes_loss: 0.1126
09/16 01:19:22 PM: Update 15314: task edges-ner-ontonotes, batch 314 (15314): mcc: 0.5212, acc: 0.3610, precision: 0.7633, recall: 0.3801, f1: 0.5075, edges-ner-ontonotes_loss: 0.1157
09/16 01:19:32 PM: Update 15396: task edges-ner-ontonotes, batch 396 (15396): mcc: 0.5161, acc: 0.3552, precision: 0.7626, recall: 0.3733, f1: 0.5013, edges-ner-ontonotes_loss: 0.1181
09/16 01:19:42 PM: Update 15465: task edges-ner-ontonotes, batch 465 (15465): mcc: 0.5134, acc: 0.3525, precision: 0.7626, recall: 0.3695, f1: 0.4978, edges-ner-ontonotes_loss: 0.1192
09/16 01:19:52 PM: Update 15526: task edges-ner-ontonotes, batch 526 (15526): mcc: 0.5116, acc: 0.3503, precision: 0.7628, recall: 0.3668, f1: 0.4954, edges-ner-ontonotes_loss: 0.1203
09/16 01:20:07 PM: Update 15561: task edges-ner-ontonotes, batch 561 (15561): mcc: 0.5109, acc: 0.3500, precision: 0.7619, recall: 0.3664, f1: 0.4948, edges-ner-ontonotes_loss: 0.1205
09/16 01:20:17 PM: Update 15657: task edges-ner-ontonotes, batch 657 (15657): mcc: 0.5104, acc: 0.3488, precision: 0.7633, recall: 0.3649, f1: 0.4938, edges-ner-ontonotes_loss: 0.1200
09/16 01:20:27 PM: Update 15731: task edges-ner-ontonotes, batch 731 (15731): mcc: 0.5099, acc: 0.3479, precision: 0.7639, recall: 0.3640, f1: 0.4930, edges-ner-ontonotes_loss: 0.1199
09/16 01:20:37 PM: Update 15796: task edges-ner-ontonotes, batch 796 (15796): mcc: 0.5108, acc: 0.3485, precision: 0.7655, recall: 0.3644, f1: 0.4937, edges-ner-ontonotes_loss: 0.1196
09/16 01:20:47 PM: Update 15866: task edges-ner-ontonotes, batch 866 (15866): mcc: 0.5121, acc: 0.3496, precision: 0.7673, recall: 0.3652, f1: 0.4949, edges-ner-ontonotes_loss: 0.1191
09/16 01:20:57 PM: Update 15900: task edges-ner-ontonotes, batch 900 (15900): mcc: 0.5114, acc: 0.3492, precision: 0.7664, recall: 0.3648, f1: 0.4943, edges-ner-ontonotes_loss: 0.1191
09/16 01:21:07 PM: Update 15958: task edges-ner-ontonotes, batch 958 (15958): mcc: 0.5112, acc: 0.3490, precision: 0.7664, recall: 0.3645, f1: 0.4940, edges-ner-ontonotes_loss: 0.1189
09/16 01:21:14 PM: ***** Step 16000 / Validation 16 *****
09/16 01:21:14 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:21:14 PM: Validating...
09/16 01:21:18 PM: Evaluate: task edges-ner-ontonotes, batch 18 (157): mcc: 0.4868, acc: 0.3138, precision: 0.8028, recall: 0.3147, f1: 0.4522, edges-ner-ontonotes_loss: 0.1261
09/16 01:21:28 PM: Evaluate: task edges-ner-ontonotes, batch 78 (157): mcc: 0.5285, acc: 0.3343, precision: 0.8740, recall: 0.3368, f1: 0.4862, edges-ner-ontonotes_loss: 0.1138
09/16 01:21:38 PM: Evaluate: task edges-ner-ontonotes, batch 135 (157): mcc: 0.5308, acc: 0.3345, precision: 0.8757, recall: 0.3390, f1: 0.4888, edges-ner-ontonotes_loss: 0.1107
09/16 01:21:41 PM: Updating LR scheduler:
09/16 01:21:42 PM: 	Best result seen so far for macro_avg: 0.505
09/16 01:21:42 PM: 	# validation passes without improvement: 0
09/16 01:21:42 PM: edges-ner-ontonotes_loss: training: 0.118670 validation: 0.110683
09/16 01:21:42 PM: macro_avg: validation: 0.484323
09/16 01:21:42 PM: micro_avg: validation: 0.000000
09/16 01:21:42 PM: edges-ner-ontonotes_mcc: training: 0.511821 validation: 0.527879
09/16 01:21:42 PM: edges-ner-ontonotes_acc: training: 0.349447 validation: 0.329921
09/16 01:21:42 PM: edges-ner-ontonotes_precision: training: 0.767187 validation: 0.877961
09/16 01:21:42 PM: edges-ner-ontonotes_recall: training: 0.364900 validation: 0.334395
09/16 01:21:42 PM: edges-ner-ontonotes_f1: training: 0.494567 validation: 0.484323
09/16 01:21:42 PM: Global learning rate: 5e-05
09/16 01:21:42 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 01:21:48 PM: Update 16042: task edges-ner-ontonotes, batch 42 (16042): mcc: 0.5236, acc: 0.3671, precision: 0.7683, recall: 0.3808, f1: 0.5092, edges-ner-ontonotes_loss: 0.1141
09/16 01:21:58 PM: Update 16113: task edges-ner-ontonotes, batch 113 (16113): mcc: 0.5107, acc: 0.3559, precision: 0.7557, recall: 0.3695, f1: 0.4963, edges-ner-ontonotes_loss: 0.1164
09/16 01:22:08 PM: Update 16168: task edges-ner-ontonotes, batch 168 (16168): mcc: 0.5117, acc: 0.3558, precision: 0.7585, recall: 0.3694, f1: 0.4968, edges-ner-ontonotes_loss: 0.1157
09/16 01:22:18 PM: Update 16199: task edges-ner-ontonotes, batch 199 (16199): mcc: 0.5101, acc: 0.3537, precision: 0.7586, recall: 0.3670, f1: 0.4947, edges-ner-ontonotes_loss: 0.1158
09/16 01:22:28 PM: Update 16278: task edges-ner-ontonotes, batch 278 (16278): mcc: 0.5124, acc: 0.3544, precision: 0.7586, recall: 0.3703, f1: 0.4977, edges-ner-ontonotes_loss: 0.1156
09/16 01:22:38 PM: Update 16348: task edges-ner-ontonotes, batch 348 (16348): mcc: 0.5126, acc: 0.3534, precision: 0.7589, recall: 0.3705, f1: 0.4979, edges-ner-ontonotes_loss: 0.1151
09/16 01:22:49 PM: Update 16418: task edges-ner-ontonotes, batch 418 (16418): mcc: 0.5144, acc: 0.3545, precision: 0.7599, recall: 0.3723, f1: 0.4998, edges-ner-ontonotes_loss: 0.1150
09/16 01:22:59 PM: Update 16476: task edges-ner-ontonotes, batch 476 (16476): mcc: 0.5155, acc: 0.3550, precision: 0.7602, recall: 0.3737, f1: 0.5011, edges-ner-ontonotes_loss: 0.1147
09/16 01:23:09 PM: Update 16503: task edges-ner-ontonotes, batch 503 (16503): mcc: 0.5156, acc: 0.3549, precision: 0.7602, recall: 0.3739, f1: 0.5013, edges-ner-ontonotes_loss: 0.1148
09/16 01:23:19 PM: Update 16562: task edges-ner-ontonotes, batch 562 (16562): mcc: 0.5157, acc: 0.3548, precision: 0.7603, recall: 0.3740, f1: 0.5014, edges-ner-ontonotes_loss: 0.1148
09/16 01:23:29 PM: Update 16634: task edges-ner-ontonotes, batch 634 (16634): mcc: 0.5184, acc: 0.3573, precision: 0.7619, recall: 0.3770, f1: 0.5044, edges-ner-ontonotes_loss: 0.1144
09/16 01:23:40 PM: Update 16701: task edges-ner-ontonotes, batch 701 (16701): mcc: 0.5174, acc: 0.3559, precision: 0.7613, recall: 0.3758, f1: 0.5032, edges-ner-ontonotes_loss: 0.1146
09/16 01:23:50 PM: Update 16766: task edges-ner-ontonotes, batch 766 (16766): mcc: 0.5182, acc: 0.3564, precision: 0.7619, recall: 0.3767, f1: 0.5041, edges-ner-ontonotes_loss: 0.1143
09/16 01:24:00 PM: Update 16815: task edges-ner-ontonotes, batch 815 (16815): mcc: 0.5184, acc: 0.3563, precision: 0.7619, recall: 0.3768, f1: 0.5043, edges-ner-ontonotes_loss: 0.1143
09/16 01:24:10 PM: Update 16884: task edges-ner-ontonotes, batch 884 (16884): mcc: 0.5154, acc: 0.3533, precision: 0.7608, recall: 0.3733, f1: 0.5009, edges-ner-ontonotes_loss: 0.1155
09/16 01:24:20 PM: Update 16950: task edges-ner-ontonotes, batch 950 (16950): mcc: 0.5142, acc: 0.3522, precision: 0.7609, recall: 0.3716, f1: 0.4993, edges-ner-ontonotes_loss: 0.1162
09/16 01:24:26 PM: ***** Step 17000 / Validation 17 *****
09/16 01:24:26 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:24:26 PM: Validating...
09/16 01:24:30 PM: Evaluate: task edges-ner-ontonotes, batch 26 (157): mcc: 0.4925, acc: 0.2937, precision: 0.8710, recall: 0.2944, f1: 0.4400, edges-ner-ontonotes_loss: 0.1263
09/16 01:24:40 PM: Evaluate: task edges-ner-ontonotes, batch 84 (157): mcc: 0.5314, acc: 0.3228, precision: 0.9146, recall: 0.3241, f1: 0.4786, edges-ner-ontonotes_loss: 0.1125
09/16 01:24:50 PM: Evaluate: task edges-ner-ontonotes, batch 141 (157): mcc: 0.5319, acc: 0.3244, precision: 0.9056, recall: 0.3281, f1: 0.4817, edges-ner-ontonotes_loss: 0.1099
09/16 01:24:53 PM: Updating LR scheduler:
09/16 01:24:53 PM: 	Best result seen so far for macro_avg: 0.505
09/16 01:24:53 PM: 	# validation passes without improvement: 1
09/16 01:24:53 PM: edges-ner-ontonotes_loss: training: 0.116552 validation: 0.109835
09/16 01:24:53 PM: macro_avg: validation: 0.479719
09/16 01:24:53 PM: micro_avg: validation: 0.000000
09/16 01:24:53 PM: edges-ner-ontonotes_mcc: training: 0.514104 validation: 0.530863
09/16 01:24:53 PM: edges-ner-ontonotes_acc: training: 0.352231 validation: 0.322338
09/16 01:24:53 PM: edges-ner-ontonotes_precision: training: 0.761192 validation: 0.907920
09/16 01:24:53 PM: edges-ner-ontonotes_recall: training: 0.371262 validation: 0.325978
09/16 01:24:53 PM: edges-ner-ontonotes_f1: training: 0.499096 validation: 0.479719
09/16 01:24:53 PM: Global learning rate: 5e-05
09/16 01:24:53 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 01:25:00 PM: Update 17049: task edges-ner-ontonotes, batch 49 (17049): mcc: 0.5022, acc: 0.3377, precision: 0.7714, recall: 0.3496, f1: 0.4811, edges-ner-ontonotes_loss: 0.1258
09/16 01:25:13 PM: Update 17117: task edges-ner-ontonotes, batch 117 (17117): mcc: 0.5002, acc: 0.3388, precision: 0.7626, recall: 0.3512, f1: 0.4809, edges-ner-ontonotes_loss: 0.1244
09/16 01:25:23 PM: Update 17188: task edges-ner-ontonotes, batch 188 (17188): mcc: 0.5083, acc: 0.3467, precision: 0.7698, recall: 0.3587, f1: 0.4894, edges-ner-ontonotes_loss: 0.1209
09/16 01:25:33 PM: Update 17265: task edges-ner-ontonotes, batch 265 (17265): mcc: 0.5156, acc: 0.3519, precision: 0.7783, recall: 0.3644, f1: 0.4964, edges-ner-ontonotes_loss: 0.1191
09/16 01:25:43 PM: Update 17338: task edges-ner-ontonotes, batch 338 (17338): mcc: 0.5153, acc: 0.3515, precision: 0.7781, recall: 0.3640, f1: 0.4960, edges-ner-ontonotes_loss: 0.1187
09/16 01:25:53 PM: Update 17397: task edges-ner-ontonotes, batch 397 (17397): mcc: 0.5179, acc: 0.3534, precision: 0.7811, recall: 0.3661, f1: 0.4985, edges-ner-ontonotes_loss: 0.1178
09/16 01:26:05 PM: Update 17430: task edges-ner-ontonotes, batch 430 (17430): mcc: 0.5177, acc: 0.3535, precision: 0.7804, recall: 0.3662, f1: 0.4984, edges-ner-ontonotes_loss: 0.1175
09/16 01:26:15 PM: Update 17501: task edges-ner-ontonotes, batch 501 (17501): mcc: 0.5152, acc: 0.3515, precision: 0.7775, recall: 0.3642, f1: 0.4961, edges-ner-ontonotes_loss: 0.1176
09/16 01:26:25 PM: Update 17568: task edges-ner-ontonotes, batch 568 (17568): mcc: 0.5157, acc: 0.3528, precision: 0.7765, recall: 0.3655, f1: 0.4970, edges-ner-ontonotes_loss: 0.1172
09/16 01:26:35 PM: Update 17645: task edges-ner-ontonotes, batch 645 (17645): mcc: 0.5161, acc: 0.3532, precision: 0.7765, recall: 0.3660, f1: 0.4975, edges-ner-ontonotes_loss: 0.1170
09/16 01:26:45 PM: Update 17741: task edges-ner-ontonotes, batch 741 (17741): mcc: 0.5165, acc: 0.3541, precision: 0.7755, recall: 0.3671, f1: 0.4983, edges-ner-ontonotes_loss: 0.1165
09/16 01:26:55 PM: Update 17805: task edges-ner-ontonotes, batch 805 (17805): mcc: 0.5159, acc: 0.3532, precision: 0.7729, recall: 0.3676, f1: 0.4982, edges-ner-ontonotes_loss: 0.1165
09/16 01:27:05 PM: Update 17875: task edges-ner-ontonotes, batch 875 (17875): mcc: 0.5164, acc: 0.3540, precision: 0.7717, recall: 0.3690, f1: 0.4992, edges-ner-ontonotes_loss: 0.1164
09/16 01:27:15 PM: Update 17959: task edges-ner-ontonotes, batch 959 (17959): mcc: 0.5167, acc: 0.3540, precision: 0.7707, recall: 0.3698, f1: 0.4998, edges-ner-ontonotes_loss: 0.1161
09/16 01:27:23 PM: ***** Step 18000 / Validation 18 *****
09/16 01:27:23 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:27:23 PM: Validating...
09/16 01:27:25 PM: Evaluate: task edges-ner-ontonotes, batch 16 (157): mcc: 0.4427, acc: 0.2804, precision: 0.7415, recall: 0.2854, f1: 0.4122, edges-ner-ontonotes_loss: 0.1381
09/16 01:27:35 PM: Evaluate: task edges-ner-ontonotes, batch 73 (157): mcc: 0.4811, acc: 0.2981, precision: 0.8091, recall: 0.3049, f1: 0.4429, edges-ner-ontonotes_loss: 0.1244
09/16 01:27:45 PM: Evaluate: task edges-ner-ontonotes, batch 122 (157): mcc: 0.5338, acc: 0.3439, precision: 0.8525, recall: 0.3530, f1: 0.4992, edges-ner-ontonotes_loss: 0.1153
09/16 01:27:53 PM: Best result seen so far for edges-ner-ontonotes.
09/16 01:27:53 PM: Best result seen so far for macro.
09/16 01:27:53 PM: Updating LR scheduler:
09/16 01:27:53 PM: 	Best result seen so far for macro_avg: 0.509
09/16 01:27:53 PM: 	# validation passes without improvement: 0
09/16 01:27:53 PM: edges-ner-ontonotes_loss: training: 0.115884 validation: 0.112223
09/16 01:27:53 PM: macro_avg: validation: 0.508871
09/16 01:27:53 PM: micro_avg: validation: 0.000000
09/16 01:27:53 PM: edges-ner-ontonotes_mcc: training: 0.517225 validation: 0.543337
09/16 01:27:53 PM: edges-ner-ontonotes_acc: training: 0.354394 validation: 0.351683
09/16 01:27:53 PM: edges-ner-ontonotes_precision: training: 0.770694 validation: 0.861875
09/16 01:27:53 PM: edges-ner-ontonotes_recall: training: 0.370577 validation: 0.361010
09/16 01:27:53 PM: edges-ner-ontonotes_f1: training: 0.500497 validation: 0.508871
09/16 01:27:53 PM: Global learning rate: 5e-05
09/16 01:27:53 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 01:27:55 PM: Update 18020: task edges-ner-ontonotes, batch 20 (18020): mcc: 0.5375, acc: 0.3756, precision: 0.7833, recall: 0.3923, f1: 0.5228, edges-ner-ontonotes_loss: 0.1129
09/16 01:28:09 PM: Update 18056: task edges-ner-ontonotes, batch 56 (18056): mcc: 0.5339, acc: 0.3721, precision: 0.7725, recall: 0.3931, f1: 0.5211, edges-ner-ontonotes_loss: 0.1121
09/16 01:28:19 PM: Update 18128: task edges-ner-ontonotes, batch 128 (18128): mcc: 0.5307, acc: 0.3665, precision: 0.7713, recall: 0.3893, f1: 0.5174, edges-ner-ontonotes_loss: 0.1127
09/16 01:28:29 PM: Update 18197: task edges-ner-ontonotes, batch 197 (18197): mcc: 0.5309, acc: 0.3669, precision: 0.7715, recall: 0.3895, f1: 0.5177, edges-ner-ontonotes_loss: 0.1129
09/16 01:28:39 PM: Update 18263: task edges-ner-ontonotes, batch 263 (18263): mcc: 0.5323, acc: 0.3679, precision: 0.7751, recall: 0.3895, f1: 0.5185, edges-ner-ontonotes_loss: 0.1131
09/16 01:28:49 PM: Update 18319: task edges-ner-ontonotes, batch 319 (18319): mcc: 0.5310, acc: 0.3669, precision: 0.7740, recall: 0.3882, f1: 0.5170, edges-ner-ontonotes_loss: 0.1131
09/16 01:29:01 PM: Update 18369: task edges-ner-ontonotes, batch 369 (18369): mcc: 0.5298, acc: 0.3665, precision: 0.7716, recall: 0.3879, f1: 0.5162, edges-ner-ontonotes_loss: 0.1131
09/16 01:29:11 PM: Update 18426: task edges-ner-ontonotes, batch 426 (18426): mcc: 0.5223, acc: 0.3595, precision: 0.7667, recall: 0.3799, f1: 0.5080, edges-ner-ontonotes_loss: 0.1156
09/16 01:29:21 PM: Update 18498: task edges-ner-ontonotes, batch 498 (18498): mcc: 0.5179, acc: 0.3552, precision: 0.7653, recall: 0.3745, f1: 0.5029, edges-ner-ontonotes_loss: 0.1172
09/16 01:29:31 PM: Update 18573: task edges-ner-ontonotes, batch 573 (18573): mcc: 0.5154, acc: 0.3528, precision: 0.7651, recall: 0.3710, f1: 0.4997, edges-ner-ontonotes_loss: 0.1184
09/16 01:29:42 PM: Update 18647: task edges-ner-ontonotes, batch 647 (18647): mcc: 0.5142, acc: 0.3517, precision: 0.7645, recall: 0.3696, f1: 0.4983, edges-ner-ontonotes_loss: 0.1189
09/16 01:29:52 PM: Update 18696: task edges-ner-ontonotes, batch 696 (18696): mcc: 0.5130, acc: 0.3507, precision: 0.7637, recall: 0.3684, f1: 0.4970, edges-ner-ontonotes_loss: 0.1191
09/16 01:30:02 PM: Update 18767: task edges-ner-ontonotes, batch 767 (18767): mcc: 0.5130, acc: 0.3503, precision: 0.7654, recall: 0.3675, f1: 0.4965, edges-ner-ontonotes_loss: 0.1190
09/16 01:30:12 PM: Update 18840: task edges-ner-ontonotes, batch 840 (18840): mcc: 0.5130, acc: 0.3500, precision: 0.7670, recall: 0.3667, f1: 0.4962, edges-ner-ontonotes_loss: 0.1186
09/16 01:30:22 PM: Update 18923: task edges-ner-ontonotes, batch 923 (18923): mcc: 0.5142, acc: 0.3508, precision: 0.7688, recall: 0.3674, f1: 0.4971, edges-ner-ontonotes_loss: 0.1181
09/16 01:30:34 PM: Update 18986: task edges-ner-ontonotes, batch 986 (18986): mcc: 0.5149, acc: 0.3514, precision: 0.7702, recall: 0.3677, f1: 0.4977, edges-ner-ontonotes_loss: 0.1178
09/16 01:30:36 PM: ***** Step 19000 / Validation 19 *****
09/16 01:30:36 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:30:36 PM: Validating...
09/16 01:30:44 PM: Evaluate: task edges-ner-ontonotes, batch 49 (157): mcc: 0.5309, acc: 0.3259, precision: 0.9059, recall: 0.3268, f1: 0.4803, edges-ner-ontonotes_loss: 0.1117
09/16 01:30:54 PM: Evaluate: task edges-ner-ontonotes, batch 110 (157): mcc: 0.5319, acc: 0.3244, precision: 0.9118, recall: 0.3257, f1: 0.4800, edges-ner-ontonotes_loss: 0.1107
09/16 01:31:03 PM: Updating LR scheduler:
09/16 01:31:03 PM: 	Best result seen so far for macro_avg: 0.509
09/16 01:31:03 PM: 	# validation passes without improvement: 1
09/16 01:31:03 PM: edges-ner-ontonotes_loss: training: 0.117864 validation: 0.109169
09/16 01:31:03 PM: macro_avg: validation: 0.478302
09/16 01:31:03 PM: micro_avg: validation: 0.000000
09/16 01:31:03 PM: edges-ner-ontonotes_mcc: training: 0.514701 validation: 0.529746
09/16 01:31:03 PM: edges-ner-ontonotes_acc: training: 0.351214 validation: 0.323097
09/16 01:31:03 PM: edges-ner-ontonotes_precision: training: 0.769922 validation: 0.907780
09/16 01:31:03 PM: edges-ner-ontonotes_recall: training: 0.367469 validation: 0.324689
09/16 01:31:03 PM: edges-ner-ontonotes_f1: training: 0.497494 validation: 0.478302
09/16 01:31:03 PM: Global learning rate: 5e-05
09/16 01:31:03 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 01:31:04 PM: Update 19010: task edges-ner-ontonotes, batch 10 (19010): mcc: 0.4960, acc: 0.3192, precision: 0.7798, recall: 0.3372, f1: 0.4708, edges-ner-ontonotes_loss: 0.1144
09/16 01:31:15 PM: Update 19085: task edges-ner-ontonotes, batch 85 (19085): mcc: 0.5118, acc: 0.3490, precision: 0.7739, recall: 0.3614, f1: 0.4927, edges-ner-ontonotes_loss: 0.1160
09/16 01:31:27 PM: Update 19163: task edges-ner-ontonotes, batch 163 (19163): mcc: 0.5090, acc: 0.3484, precision: 0.7674, recall: 0.3609, f1: 0.4909, edges-ner-ontonotes_loss: 0.1163
09/16 01:31:37 PM: Update 19251: task edges-ner-ontonotes, batch 251 (19251): mcc: 0.5148, acc: 0.3544, precision: 0.7707, recall: 0.3673, f1: 0.4975, edges-ner-ontonotes_loss: 0.1156
09/16 01:31:50 PM: Update 19299: task edges-ner-ontonotes, batch 299 (19299): mcc: 0.5164, acc: 0.3563, precision: 0.7708, recall: 0.3694, f1: 0.4994, edges-ner-ontonotes_loss: 0.1153
09/16 01:32:00 PM: Update 19357: task edges-ner-ontonotes, batch 357 (19357): mcc: 0.5149, acc: 0.3543, precision: 0.7666, recall: 0.3695, f1: 0.4987, edges-ner-ontonotes_loss: 0.1154
09/16 01:32:10 PM: Update 19433: task edges-ner-ontonotes, batch 433 (19433): mcc: 0.5157, acc: 0.3542, precision: 0.7667, recall: 0.3706, f1: 0.4997, edges-ner-ontonotes_loss: 0.1150
09/16 01:32:20 PM: Update 19502: task edges-ner-ontonotes, batch 502 (19502): mcc: 0.5160, acc: 0.3542, precision: 0.7655, recall: 0.3716, f1: 0.5004, edges-ner-ontonotes_loss: 0.1148
09/16 01:32:30 PM: Update 19573: task edges-ner-ontonotes, batch 573 (19573): mcc: 0.5184, acc: 0.3565, precision: 0.7656, recall: 0.3749, f1: 0.5033, edges-ner-ontonotes_loss: 0.1144
09/16 01:32:40 PM: Update 19629: task edges-ner-ontonotes, batch 629 (19629): mcc: 0.5199, acc: 0.3581, precision: 0.7656, recall: 0.3770, f1: 0.5052, edges-ner-ontonotes_loss: 0.1142
09/16 01:32:50 PM: Update 19708: task edges-ner-ontonotes, batch 708 (19708): mcc: 0.5209, acc: 0.3589, precision: 0.7657, recall: 0.3784, f1: 0.5065, edges-ner-ontonotes_loss: 0.1140
09/16 01:33:01 PM: Update 19782: task edges-ner-ontonotes, batch 782 (19782): mcc: 0.5210, acc: 0.3589, precision: 0.7658, recall: 0.3785, f1: 0.5066, edges-ner-ontonotes_loss: 0.1141
09/16 01:33:11 PM: Update 19838: task edges-ner-ontonotes, batch 838 (19838): mcc: 0.5200, acc: 0.3581, precision: 0.7640, recall: 0.3780, f1: 0.5058, edges-ner-ontonotes_loss: 0.1141
09/16 01:33:21 PM: Update 19902: task edges-ner-ontonotes, batch 902 (19902): mcc: 0.5209, acc: 0.3592, precision: 0.7648, recall: 0.3790, f1: 0.5068, edges-ner-ontonotes_loss: 0.1140
09/16 01:33:31 PM: Update 19930: task edges-ner-ontonotes, batch 930 (19930): mcc: 0.5207, acc: 0.3591, precision: 0.7639, recall: 0.3791, f1: 0.5067, edges-ner-ontonotes_loss: 0.1141
09/16 01:33:41 PM: ***** Step 20000 / Validation 20 *****
09/16 01:33:42 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:33:42 PM: Validating...
09/16 01:33:42 PM: Evaluate: task edges-ner-ontonotes, batch 1 (157): mcc: 0.6308, acc: 0.4590, precision: 0.9032, recall: 0.4590, f1: 0.6087, edges-ner-ontonotes_loss: 0.1358
09/16 01:33:52 PM: Evaluate: task edges-ner-ontonotes, batch 62 (157): mcc: 0.5145, acc: 0.3041, precision: 0.9091, recall: 0.3061, f1: 0.4580, edges-ner-ontonotes_loss: 0.1118
09/16 01:34:03 PM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.5324, acc: 0.3242, precision: 0.9057, recall: 0.3287, f1: 0.4824, edges-ner-ontonotes_loss: 0.1099
09/16 01:34:10 PM: Updating LR scheduler:
09/16 01:34:10 PM: 	Best result seen so far for macro_avg: 0.509
09/16 01:34:10 PM: 	# validation passes without improvement: 2
09/16 01:34:10 PM: edges-ner-ontonotes_loss: training: 0.115202 validation: 0.107804
09/16 01:34:10 PM: macro_avg: validation: 0.488741
09/16 01:34:10 PM: micro_avg: validation: 0.000000
09/16 01:34:10 PM: edges-ner-ontonotes_mcc: training: 0.518445 validation: 0.538233
09/16 01:34:10 PM: edges-ner-ontonotes_acc: training: 0.356850 validation: 0.328935
09/16 01:34:10 PM: edges-ner-ontonotes_precision: training: 0.762770 validation: 0.909955
09/16 01:34:10 PM: edges-ner-ontonotes_recall: training: 0.376527 validation: 0.334092
09/16 01:34:10 PM: edges-ner-ontonotes_f1: training: 0.504177 validation: 0.488741
09/16 01:34:10 PM: Global learning rate: 5e-05
09/16 01:34:10 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 01:34:13 PM: Update 20018: task edges-ner-ontonotes, batch 18 (20018): mcc: 0.4860, acc: 0.3177, precision: 0.7628, recall: 0.3320, f1: 0.4626, edges-ner-ontonotes_loss: 0.1279
09/16 01:34:23 PM: Update 20089: task edges-ner-ontonotes, batch 89 (20089): mcc: 0.4901, acc: 0.3276, precision: 0.7612, recall: 0.3382, f1: 0.4684, edges-ner-ontonotes_loss: 0.1255
09/16 01:34:33 PM: Update 20155: task edges-ner-ontonotes, batch 155 (20155): mcc: 0.4992, acc: 0.3358, precision: 0.7688, recall: 0.3468, f1: 0.4779, edges-ner-ontonotes_loss: 0.1243
09/16 01:34:43 PM: Update 20224: task edges-ner-ontonotes, batch 224 (20224): mcc: 0.4962, acc: 0.3343, precision: 0.7624, recall: 0.3459, f1: 0.4758, edges-ner-ontonotes_loss: 0.1254
09/16 01:34:53 PM: Update 20275: task edges-ner-ontonotes, batch 275 (20275): mcc: 0.4953, acc: 0.3336, precision: 0.7594, recall: 0.3462, f1: 0.4755, edges-ner-ontonotes_loss: 0.1239
09/16 01:35:03 PM: Update 20339: task edges-ner-ontonotes, batch 339 (20339): mcc: 0.4982, acc: 0.3352, precision: 0.7626, recall: 0.3485, f1: 0.4783, edges-ner-ontonotes_loss: 0.1222
09/16 01:35:13 PM: Update 20417: task edges-ner-ontonotes, batch 417 (20417): mcc: 0.5024, acc: 0.3380, precision: 0.7680, recall: 0.3515, f1: 0.4823, edges-ner-ontonotes_loss: 0.1206
09/16 01:35:23 PM: Update 20496: task edges-ner-ontonotes, batch 496 (20496): mcc: 0.5058, acc: 0.3414, precision: 0.7714, recall: 0.3545, f1: 0.4857, edges-ner-ontonotes_loss: 0.1196
09/16 01:35:35 PM: Update 20542: task edges-ner-ontonotes, batch 542 (20542): mcc: 0.5062, acc: 0.3420, precision: 0.7710, recall: 0.3552, f1: 0.4863, edges-ner-ontonotes_loss: 0.1194
09/16 01:35:46 PM: Update 20613: task edges-ner-ontonotes, batch 613 (20613): mcc: 0.5067, acc: 0.3431, precision: 0.7702, recall: 0.3563, f1: 0.4872, edges-ner-ontonotes_loss: 0.1188
09/16 01:35:56 PM: Update 20701: task edges-ner-ontonotes, batch 701 (20701): mcc: 0.5092, acc: 0.3456, precision: 0.7722, recall: 0.3587, f1: 0.4899, edges-ner-ontonotes_loss: 0.1183
09/16 01:36:06 PM: Update 20795: task edges-ner-ontonotes, batch 795 (20795): mcc: 0.5103, acc: 0.3466, precision: 0.7727, recall: 0.3599, f1: 0.4911, edges-ner-ontonotes_loss: 0.1180
09/16 01:36:20 PM: Update 20855: task edges-ner-ontonotes, batch 855 (20855): mcc: 0.5116, acc: 0.3479, precision: 0.7735, recall: 0.3613, f1: 0.4926, edges-ner-ontonotes_loss: 0.1177
09/16 01:36:30 PM: Update 20918: task edges-ner-ontonotes, batch 918 (20918): mcc: 0.5116, acc: 0.3485, precision: 0.7712, recall: 0.3625, f1: 0.4932, edges-ner-ontonotes_loss: 0.1173
09/16 01:36:40 PM: Update 20986: task edges-ner-ontonotes, batch 986 (20986): mcc: 0.5113, acc: 0.3481, precision: 0.7699, recall: 0.3627, f1: 0.4931, edges-ner-ontonotes_loss: 0.1170
09/16 01:36:42 PM: ***** Step 21000 / Validation 21 *****
09/16 01:36:42 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:36:42 PM: Validating...
09/16 01:36:50 PM: Evaluate: task edges-ner-ontonotes, batch 46 (157): mcc: 0.4823, acc: 0.3005, precision: 0.8062, recall: 0.3077, f1: 0.4454, edges-ner-ontonotes_loss: 0.1241
09/16 01:37:00 PM: Evaluate: task edges-ner-ontonotes, batch 101 (157): mcc: 0.5193, acc: 0.3264, precision: 0.8515, recall: 0.3348, f1: 0.4806, edges-ner-ontonotes_loss: 0.1186
09/16 01:37:10 PM: Evaluate: task edges-ner-ontonotes, batch 145 (157): mcc: 0.5428, acc: 0.3493, precision: 0.8616, recall: 0.3604, f1: 0.5082, edges-ner-ontonotes_loss: 0.1119
09/16 01:37:12 PM: Best result seen so far for edges-ner-ontonotes.
09/16 01:37:12 PM: Best result seen so far for macro.
09/16 01:37:12 PM: Updating LR scheduler:
09/16 01:37:12 PM: 	Best result seen so far for macro_avg: 0.509
09/16 01:37:12 PM: 	# validation passes without improvement: 3
09/16 01:37:12 PM: edges-ner-ontonotes_loss: training: 0.116991 validation: 0.111642
09/16 01:37:12 PM: macro_avg: validation: 0.508879
09/16 01:37:12 PM: micro_avg: validation: 0.000000
09/16 01:37:12 PM: edges-ner-ontonotes_mcc: training: 0.511118 validation: 0.543727
09/16 01:37:12 PM: edges-ner-ontonotes_acc: training: 0.348067 validation: 0.349636
09/16 01:37:12 PM: edges-ner-ontonotes_precision: training: 0.769307 validation: 0.863653
09/16 01:37:12 PM: edges-ner-ontonotes_recall: training: 0.362823 validation: 0.360707
09/16 01:37:12 PM: edges-ner-ontonotes_f1: training: 0.493092 validation: 0.508879
09/16 01:37:12 PM: Global learning rate: 5e-05
09/16 01:37:12 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 01:37:20 PM: Update 21050: task edges-ner-ontonotes, batch 50 (21050): mcc: 0.5286, acc: 0.3618, precision: 0.7752, recall: 0.3842, f1: 0.5138, edges-ner-ontonotes_loss: 0.1140
09/16 01:37:30 PM: Update 21119: task edges-ner-ontonotes, batch 119 (21119): mcc: 0.5261, acc: 0.3600, precision: 0.7706, recall: 0.3831, f1: 0.5118, edges-ner-ontonotes_loss: 0.1130
09/16 01:37:43 PM: Update 21168: task edges-ner-ontonotes, batch 168 (21168): mcc: 0.5286, acc: 0.3629, precision: 0.7723, recall: 0.3858, f1: 0.5145, edges-ner-ontonotes_loss: 0.1128
09/16 01:37:53 PM: Update 21236: task edges-ner-ontonotes, batch 236 (21236): mcc: 0.5272, acc: 0.3623, precision: 0.7707, recall: 0.3846, f1: 0.5132, edges-ner-ontonotes_loss: 0.1129
09/16 01:38:03 PM: Update 21303: task edges-ner-ontonotes, batch 303 (21303): mcc: 0.5289, acc: 0.3634, precision: 0.7731, recall: 0.3856, f1: 0.5146, edges-ner-ontonotes_loss: 0.1128
09/16 01:38:13 PM: Update 21382: task edges-ner-ontonotes, batch 382 (21382): mcc: 0.5288, acc: 0.3640, precision: 0.7726, recall: 0.3859, f1: 0.5147, edges-ner-ontonotes_loss: 0.1127
09/16 01:38:23 PM: Update 21439: task edges-ner-ontonotes, batch 439 (21439): mcc: 0.5289, acc: 0.3639, precision: 0.7721, recall: 0.3863, f1: 0.5149, edges-ner-ontonotes_loss: 0.1125
09/16 01:38:34 PM: Update 21481: task edges-ner-ontonotes, batch 481 (21481): mcc: 0.5290, acc: 0.3646, precision: 0.7716, recall: 0.3867, f1: 0.5152, edges-ner-ontonotes_loss: 0.1125
09/16 01:38:44 PM: Update 21552: task edges-ner-ontonotes, batch 552 (21552): mcc: 0.5229, acc: 0.3595, precision: 0.7671, recall: 0.3804, f1: 0.5086, edges-ner-ontonotes_loss: 0.1145
09/16 01:38:54 PM: Update 21629: task edges-ner-ontonotes, batch 629 (21629): mcc: 0.5193, acc: 0.3565, precision: 0.7652, recall: 0.3765, f1: 0.5046, edges-ner-ontonotes_loss: 0.1159
09/16 01:39:04 PM: Update 21700: task edges-ner-ontonotes, batch 700 (21700): mcc: 0.5178, acc: 0.3551, precision: 0.7654, recall: 0.3742, f1: 0.5026, edges-ner-ontonotes_loss: 0.1169
09/16 01:39:17 PM: Update 21785: task edges-ner-ontonotes, batch 785 (21785): mcc: 0.5162, acc: 0.3536, precision: 0.7656, recall: 0.3718, f1: 0.5006, edges-ner-ontonotes_loss: 0.1176
09/16 01:39:27 PM: Update 21860: task edges-ner-ontonotes, batch 860 (21860): mcc: 0.5154, acc: 0.3525, precision: 0.7661, recall: 0.3705, f1: 0.4994, edges-ner-ontonotes_loss: 0.1175
09/16 01:39:37 PM: Update 21935: task edges-ner-ontonotes, batch 935 (21935): mcc: 0.5146, acc: 0.3516, precision: 0.7661, recall: 0.3693, f1: 0.4984, edges-ner-ontonotes_loss: 0.1174
09/16 01:39:45 PM: ***** Step 22000 / Validation 22 *****
09/16 01:39:45 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:39:45 PM: Validating...
09/16 01:39:47 PM: Evaluate: task edges-ner-ontonotes, batch 15 (157): mcc: 0.5148, acc: 0.3298, precision: 0.8451, recall: 0.3319, f1: 0.4766, edges-ner-ontonotes_loss: 0.1263
09/16 01:39:58 PM: Evaluate: task edges-ner-ontonotes, batch 75 (157): mcc: 0.5443, acc: 0.3430, precision: 0.9045, recall: 0.3437, f1: 0.4981, edges-ner-ontonotes_loss: 0.1109
09/16 01:40:08 PM: Evaluate: task edges-ner-ontonotes, batch 122 (157): mcc: 0.5405, acc: 0.3421, precision: 0.8943, recall: 0.3433, f1: 0.4961, edges-ner-ontonotes_loss: 0.1098
09/16 01:40:15 PM: Updating LR scheduler:
09/16 01:40:15 PM: 	Best result seen so far for macro_avg: 0.509
09/16 01:40:15 PM: 	# validation passes without improvement: 0
09/16 01:40:15 PM: edges-ner-ontonotes_loss: training: 0.117156 validation: 0.109547
09/16 01:40:15 PM: macro_avg: validation: 0.489942
09/16 01:40:15 PM: micro_avg: validation: 0.000000
09/16 01:40:15 PM: edges-ner-ontonotes_mcc: training: 0.515141 validation: 0.536279
09/16 01:40:15 PM: edges-ner-ontonotes_acc: training: 0.351980 validation: 0.335836
09/16 01:40:15 PM: edges-ner-ontonotes_precision: training: 0.767264 validation: 0.896712
09/16 01:40:15 PM: edges-ner-ontonotes_recall: training: 0.369482 validation: 0.337049
09/16 01:40:15 PM: edges-ner-ontonotes_f1: training: 0.498774 validation: 0.489942
09/16 01:40:15 PM: Global learning rate: 2.5e-05
09/16 01:40:15 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 01:40:18 PM: Update 22025: task edges-ner-ontonotes, batch 25 (22025): mcc: 0.5221, acc: 0.3625, precision: 0.7779, recall: 0.3736, f1: 0.5048, edges-ner-ontonotes_loss: 0.1149
09/16 01:40:30 PM: Update 22098: task edges-ner-ontonotes, batch 98 (22098): mcc: 0.5236, acc: 0.3598, precision: 0.7827, recall: 0.3732, f1: 0.5054, edges-ner-ontonotes_loss: 0.1139
09/16 01:40:40 PM: Update 22191: task edges-ner-ontonotes, batch 191 (22191): mcc: 0.5164, acc: 0.3533, precision: 0.7752, recall: 0.3671, f1: 0.4982, edges-ner-ontonotes_loss: 0.1147
09/16 01:40:51 PM: Update 22266: task edges-ner-ontonotes, batch 266 (22266): mcc: 0.5124, acc: 0.3511, precision: 0.7692, recall: 0.3647, f1: 0.4948, edges-ner-ontonotes_loss: 0.1148
09/16 01:41:01 PM: Update 22331: task edges-ner-ontonotes, batch 331 (22331): mcc: 0.5140, acc: 0.3517, precision: 0.7714, recall: 0.3656, f1: 0.4961, edges-ner-ontonotes_loss: 0.1147
09/16 01:41:11 PM: Update 22391: task edges-ner-ontonotes, batch 391 (22391): mcc: 0.5112, acc: 0.3496, precision: 0.7681, recall: 0.3636, f1: 0.4936, edges-ner-ontonotes_loss: 0.1153
09/16 01:41:21 PM: Update 22437: task edges-ner-ontonotes, batch 437 (22437): mcc: 0.5114, acc: 0.3493, precision: 0.7686, recall: 0.3635, f1: 0.4936, edges-ner-ontonotes_loss: 0.1153
09/16 01:41:31 PM: Update 22499: task edges-ner-ontonotes, batch 499 (22499): mcc: 0.5134, acc: 0.3511, precision: 0.7687, recall: 0.3663, f1: 0.4962, edges-ner-ontonotes_loss: 0.1152
09/16 01:41:41 PM: Update 22561: task edges-ner-ontonotes, batch 561 (22561): mcc: 0.5137, acc: 0.3514, precision: 0.7670, recall: 0.3676, f1: 0.4970, edges-ner-ontonotes_loss: 0.1152
09/16 01:41:51 PM: Update 22627: task edges-ner-ontonotes, batch 627 (22627): mcc: 0.5151, acc: 0.3523, precision: 0.7674, recall: 0.3694, f1: 0.4987, edges-ner-ontonotes_loss: 0.1149
09/16 01:42:02 PM: Update 22699: task edges-ner-ontonotes, batch 699 (22699): mcc: 0.5164, acc: 0.3533, precision: 0.7675, recall: 0.3711, f1: 0.5003, edges-ner-ontonotes_loss: 0.1145
09/16 01:42:12 PM: Update 22734: task edges-ner-ontonotes, batch 734 (22734): mcc: 0.5169, acc: 0.3542, precision: 0.7666, recall: 0.3723, f1: 0.5012, edges-ner-ontonotes_loss: 0.1144
09/16 01:42:23 PM: Update 22806: task edges-ner-ontonotes, batch 806 (22806): mcc: 0.5177, acc: 0.3550, precision: 0.7667, recall: 0.3734, f1: 0.5022, edges-ner-ontonotes_loss: 0.1142
09/16 01:42:33 PM: Update 22873: task edges-ner-ontonotes, batch 873 (22873): mcc: 0.5178, acc: 0.3547, precision: 0.7668, recall: 0.3734, f1: 0.5022, edges-ner-ontonotes_loss: 0.1143
09/16 01:42:43 PM: Update 22937: task edges-ner-ontonotes, batch 937 (22937): mcc: 0.5183, acc: 0.3552, precision: 0.7670, recall: 0.3740, f1: 0.5028, edges-ner-ontonotes_loss: 0.1143
09/16 01:42:52 PM: ***** Step 23000 / Validation 23 *****
09/16 01:42:52 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:42:52 PM: Validating...
09/16 01:42:53 PM: Evaluate: task edges-ner-ontonotes, batch 3 (157): mcc: 0.4860, acc: 0.3382, precision: 0.7500, recall: 0.3382, f1: 0.4662, edges-ner-ontonotes_loss: 0.1630
09/16 01:43:03 PM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.4842, acc: 0.2950, precision: 0.8284, recall: 0.3010, f1: 0.4415, edges-ner-ontonotes_loss: 0.1212
09/16 01:43:13 PM: Evaluate: task edges-ner-ontonotes, batch 111 (157): mcc: 0.5299, acc: 0.3342, precision: 0.8679, recall: 0.3412, f1: 0.4898, edges-ner-ontonotes_loss: 0.1150
09/16 01:43:22 PM: Updating LR scheduler:
09/16 01:43:22 PM: 	Best result seen so far for macro_avg: 0.509
09/16 01:43:22 PM: 	# validation passes without improvement: 1
09/16 01:43:22 PM: edges-ner-ontonotes_loss: training: 0.114126 validation: 0.110149
09/16 01:43:22 PM: macro_avg: validation: 0.508662
09/16 01:43:22 PM: micro_avg: validation: 0.000000
09/16 01:43:22 PM: edges-ner-ontonotes_mcc: training: 0.518953 validation: 0.546162
09/16 01:43:22 PM: edges-ner-ontonotes_acc: training: 0.355874 validation: 0.349636
09/16 01:43:22 PM: edges-ner-ontonotes_precision: training: 0.767441 validation: 0.875695
09/16 01:43:22 PM: edges-ner-ontonotes_recall: training: 0.374726 validation: 0.358432
09/16 01:43:22 PM: edges-ner-ontonotes_f1: training: 0.503569 validation: 0.508662
09/16 01:43:22 PM: Global learning rate: 2.5e-05
09/16 01:43:22 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 01:43:23 PM: Update 23008: task edges-ner-ontonotes, batch 8 (23008): mcc: 0.5307, acc: 0.3716, precision: 0.7683, recall: 0.3910, f1: 0.5182, edges-ner-ontonotes_loss: 0.1152
09/16 01:43:36 PM: Update 23046: task edges-ner-ontonotes, batch 46 (23046): mcc: 0.5195, acc: 0.3594, precision: 0.7557, recall: 0.3819, f1: 0.5074, edges-ner-ontonotes_loss: 0.1156
09/16 01:43:46 PM: Update 23130: task edges-ner-ontonotes, batch 130 (23130): mcc: 0.5036, acc: 0.3427, precision: 0.7571, recall: 0.3588, f1: 0.4868, edges-ner-ontonotes_loss: 0.1231
09/16 01:43:57 PM: Update 23204: task edges-ner-ontonotes, batch 204 (23204): mcc: 0.5026, acc: 0.3419, precision: 0.7590, recall: 0.3563, f1: 0.4850, edges-ner-ontonotes_loss: 0.1232
09/16 01:44:07 PM: Update 23271: task edges-ner-ontonotes, batch 271 (23271): mcc: 0.5037, acc: 0.3421, precision: 0.7622, recall: 0.3563, f1: 0.4856, edges-ner-ontonotes_loss: 0.1234
09/16 01:44:18 PM: Update 23341: task edges-ner-ontonotes, batch 341 (23341): mcc: 0.5003, acc: 0.3388, precision: 0.7593, recall: 0.3530, f1: 0.4820, edges-ner-ontonotes_loss: 0.1240
09/16 01:44:28 PM: Update 23417: task edges-ner-ontonotes, batch 417 (23417): mcc: 0.5021, acc: 0.3397, precision: 0.7623, recall: 0.3540, f1: 0.4835, edges-ner-ontonotes_loss: 0.1224
09/16 01:44:39 PM: Update 23489: task edges-ner-ontonotes, batch 489 (23489): mcc: 0.5049, acc: 0.3423, precision: 0.7648, recall: 0.3566, f1: 0.4864, edges-ner-ontonotes_loss: 0.1211
09/16 01:44:49 PM: Update 23571: task edges-ner-ontonotes, batch 571 (23571): mcc: 0.5081, acc: 0.3454, precision: 0.7680, recall: 0.3593, f1: 0.4895, edges-ner-ontonotes_loss: 0.1201
09/16 01:45:00 PM: Update 23654: task edges-ner-ontonotes, batch 654 (23654): mcc: 0.5094, acc: 0.3461, precision: 0.7698, recall: 0.3602, f1: 0.4908, edges-ner-ontonotes_loss: 0.1194
09/16 01:45:11 PM: Update 23739: task edges-ner-ontonotes, batch 739 (23739): mcc: 0.5095, acc: 0.3462, precision: 0.7699, recall: 0.3602, f1: 0.4908, edges-ner-ontonotes_loss: 0.1189
09/16 01:45:21 PM: Update 23811: task edges-ner-ontonotes, batch 811 (23811): mcc: 0.5084, acc: 0.3452, precision: 0.7689, recall: 0.3592, f1: 0.4897, edges-ner-ontonotes_loss: 0.1188
09/16 01:45:31 PM: Update 23881: task edges-ner-ontonotes, batch 881 (23881): mcc: 0.5087, acc: 0.3457, precision: 0.7682, recall: 0.3600, f1: 0.4903, edges-ner-ontonotes_loss: 0.1184
09/16 01:45:41 PM: Update 23950: task edges-ner-ontonotes, batch 950 (23950): mcc: 0.5099, acc: 0.3467, precision: 0.7695, recall: 0.3611, f1: 0.4915, edges-ner-ontonotes_loss: 0.1181
09/16 01:45:51 PM: Update 23974: task edges-ner-ontonotes, batch 974 (23974): mcc: 0.5103, acc: 0.3473, precision: 0.7692, recall: 0.3618, f1: 0.4921, edges-ner-ontonotes_loss: 0.1180
09/16 01:45:56 PM: ***** Step 24000 / Validation 24 *****
09/16 01:45:56 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:45:56 PM: Validating...
09/16 01:46:01 PM: Evaluate: task edges-ner-ontonotes, batch 36 (157): mcc: 0.4892, acc: 0.3098, precision: 0.8054, recall: 0.3167, f1: 0.4546, edges-ner-ontonotes_loss: 0.1215
09/16 01:46:11 PM: Evaluate: task edges-ner-ontonotes, batch 92 (157): mcc: 0.5245, acc: 0.3331, precision: 0.8532, recall: 0.3407, f1: 0.4870, edges-ner-ontonotes_loss: 0.1149
09/16 01:46:21 PM: Evaluate: task edges-ner-ontonotes, batch 143 (157): mcc: 0.5463, acc: 0.3541, precision: 0.8649, recall: 0.3635, f1: 0.5119, edges-ner-ontonotes_loss: 0.1094
09/16 01:46:24 PM: Best result seen so far for edges-ner-ontonotes.
09/16 01:46:24 PM: Best result seen so far for macro.
09/16 01:46:24 PM: Updating LR scheduler:
09/16 01:46:24 PM: 	Best result seen so far for macro_avg: 0.511
09/16 01:46:24 PM: 	# validation passes without improvement: 0
09/16 01:46:24 PM: edges-ner-ontonotes_loss: training: 0.118022 validation: 0.109214
09/16 01:46:24 PM: macro_avg: validation: 0.510964
09/16 01:46:24 PM: micro_avg: validation: 0.000000
09/16 01:46:24 PM: edges-ner-ontonotes_mcc: training: 0.510101 validation: 0.546060
09/16 01:46:24 PM: edges-ner-ontonotes_acc: training: 0.347046 validation: 0.352745
09/16 01:46:24 PM: edges-ner-ontonotes_precision: training: 0.768964 validation: 0.866969
09/16 01:46:24 PM: edges-ner-ontonotes_recall: training: 0.361595 validation: 0.362223
09/16 01:46:24 PM: edges-ner-ontonotes_f1: training: 0.491887 validation: 0.510964
09/16 01:46:24 PM: Global learning rate: 2.5e-05
09/16 01:46:24 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 01:46:31 PM: Update 24049: task edges-ner-ontonotes, batch 49 (24049): mcc: 0.5311, acc: 0.3683, precision: 0.7685, recall: 0.3914, f1: 0.5186, edges-ner-ontonotes_loss: 0.1125
09/16 01:46:41 PM: Update 24109: task edges-ner-ontonotes, batch 109 (24109): mcc: 0.5276, acc: 0.3641, precision: 0.7678, recall: 0.3867, f1: 0.5143, edges-ner-ontonotes_loss: 0.1125
09/16 01:46:51 PM: Update 24186: task edges-ner-ontonotes, batch 186 (24186): mcc: 0.5278, acc: 0.3628, precision: 0.7701, recall: 0.3858, f1: 0.5141, edges-ner-ontonotes_loss: 0.1126
09/16 01:47:01 PM: Update 24257: task edges-ner-ontonotes, batch 257 (24257): mcc: 0.5277, acc: 0.3635, precision: 0.7688, recall: 0.3864, f1: 0.5143, edges-ner-ontonotes_loss: 0.1122
09/16 01:47:11 PM: Update 24289: task edges-ner-ontonotes, batch 289 (24289): mcc: 0.5282, acc: 0.3644, precision: 0.7676, recall: 0.3878, f1: 0.5153, edges-ner-ontonotes_loss: 0.1122
09/16 01:47:21 PM: Update 24349: task edges-ner-ontonotes, batch 349 (24349): mcc: 0.5267, acc: 0.3624, precision: 0.7667, recall: 0.3861, f1: 0.5136, edges-ner-ontonotes_loss: 0.1126
09/16 01:47:32 PM: Update 24432: task edges-ner-ontonotes, batch 432 (24432): mcc: 0.5283, acc: 0.3642, precision: 0.7690, recall: 0.3871, f1: 0.5149, edges-ner-ontonotes_loss: 0.1123
09/16 01:47:42 PM: Update 24501: task edges-ner-ontonotes, batch 501 (24501): mcc: 0.5282, acc: 0.3641, precision: 0.7688, recall: 0.3871, f1: 0.5149, edges-ner-ontonotes_loss: 0.1123
09/16 01:47:52 PM: Update 24567: task edges-ner-ontonotes, batch 567 (24567): mcc: 0.5280, acc: 0.3641, precision: 0.7688, recall: 0.3869, f1: 0.5147, edges-ner-ontonotes_loss: 0.1123
09/16 01:48:02 PM: Update 24595: task edges-ner-ontonotes, batch 595 (24595): mcc: 0.5274, acc: 0.3635, precision: 0.7684, recall: 0.3861, f1: 0.5140, edges-ner-ontonotes_loss: 0.1124
09/16 01:48:12 PM: Update 24678: task edges-ner-ontonotes, batch 678 (24678): mcc: 0.5230, acc: 0.3593, precision: 0.7667, recall: 0.3808, f1: 0.5089, edges-ner-ontonotes_loss: 0.1143
09/16 01:48:22 PM: Update 24744: task edges-ner-ontonotes, batch 744 (24744): mcc: 0.5207, acc: 0.3571, precision: 0.7661, recall: 0.3779, f1: 0.5061, edges-ner-ontonotes_loss: 0.1152
09/16 01:48:32 PM: Update 24807: task edges-ner-ontonotes, batch 807 (24807): mcc: 0.5190, acc: 0.3557, precision: 0.7655, recall: 0.3759, f1: 0.5042, edges-ner-ontonotes_loss: 0.1160
09/16 01:48:42 PM: Update 24876: task edges-ner-ontonotes, batch 876 (24876): mcc: 0.5170, acc: 0.3540, precision: 0.7645, recall: 0.3735, f1: 0.5018, edges-ner-ontonotes_loss: 0.1168
09/16 01:48:52 PM: Update 24899: task edges-ner-ontonotes, batch 899 (24899): mcc: 0.5162, acc: 0.3533, precision: 0.7641, recall: 0.3727, f1: 0.5010, edges-ner-ontonotes_loss: 0.1170
09/16 01:49:03 PM: Update 24965: task edges-ner-ontonotes, batch 965 (24965): mcc: 0.5160, acc: 0.3530, precision: 0.7643, recall: 0.3722, f1: 0.5006, edges-ner-ontonotes_loss: 0.1169
09/16 01:49:08 PM: ***** Step 25000 / Validation 25 *****
09/16 01:49:08 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:49:08 PM: Validating...
09/16 01:49:13 PM: Evaluate: task edges-ner-ontonotes, batch 34 (157): mcc: 0.5282, acc: 0.3308, precision: 0.8854, recall: 0.3317, f1: 0.4826, edges-ner-ontonotes_loss: 0.1153
09/16 01:49:23 PM: Evaluate: task edges-ner-ontonotes, batch 96 (157): mcc: 0.5391, acc: 0.3375, precision: 0.9005, recall: 0.3390, f1: 0.4925, edges-ner-ontonotes_loss: 0.1096
09/16 01:49:33 PM: Evaluate: task edges-ner-ontonotes, batch 153 (157): mcc: 0.5317, acc: 0.3310, precision: 0.8914, recall: 0.3336, f1: 0.4855, edges-ner-ontonotes_loss: 0.1088
09/16 01:49:33 PM: Updating LR scheduler:
09/16 01:49:33 PM: 	Best result seen so far for macro_avg: 0.511
09/16 01:49:33 PM: 	# validation passes without improvement: 1
09/16 01:49:33 PM: edges-ner-ontonotes_loss: training: 0.116861 validation: 0.108558
09/16 01:49:33 PM: macro_avg: validation: 0.487264
09/16 01:49:33 PM: micro_avg: validation: 0.000000
09/16 01:49:33 PM: edges-ner-ontonotes_mcc: training: 0.516299 validation: 0.533354
09/16 01:49:33 PM: edges-ner-ontonotes_acc: training: 0.353102 validation: 0.332575
09/16 01:49:33 PM: edges-ner-ontonotes_precision: training: 0.765404 validation: 0.892727
09/16 01:49:33 PM: edges-ner-ontonotes_recall: training: 0.372090 validation: 0.335077
09/16 01:49:33 PM: edges-ner-ontonotes_f1: training: 0.500748 validation: 0.487264
09/16 01:49:33 PM: Global learning rate: 2.5e-05
09/16 01:49:33 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 01:49:43 PM: Update 25105: task edges-ner-ontonotes, batch 105 (25105): mcc: 0.5215, acc: 0.3546, precision: 0.7839, recall: 0.3697, f1: 0.5024, edges-ner-ontonotes_loss: 0.1137
09/16 01:49:53 PM: Update 25159: task edges-ner-ontonotes, batch 159 (25159): mcc: 0.5227, acc: 0.3556, precision: 0.7852, recall: 0.3706, f1: 0.5036, edges-ner-ontonotes_loss: 0.1133
09/16 01:50:03 PM: Update 25215: task edges-ner-ontonotes, batch 215 (25215): mcc: 0.5206, acc: 0.3550, precision: 0.7819, recall: 0.3694, f1: 0.5018, edges-ner-ontonotes_loss: 0.1137
09/16 01:50:13 PM: Update 25282: task edges-ner-ontonotes, batch 282 (25282): mcc: 0.5196, acc: 0.3545, precision: 0.7813, recall: 0.3683, f1: 0.5007, edges-ner-ontonotes_loss: 0.1140
09/16 01:50:23 PM: Update 25352: task edges-ner-ontonotes, batch 352 (25352): mcc: 0.5182, acc: 0.3541, precision: 0.7792, recall: 0.3675, f1: 0.4995, edges-ner-ontonotes_loss: 0.1145
09/16 01:50:33 PM: Update 25426: task edges-ner-ontonotes, batch 426 (25426): mcc: 0.5187, acc: 0.3555, precision: 0.7779, recall: 0.3689, f1: 0.5005, edges-ner-ontonotes_loss: 0.1143
09/16 01:50:44 PM: Update 25498: task edges-ner-ontonotes, batch 498 (25498): mcc: 0.5190, acc: 0.3559, precision: 0.7776, recall: 0.3695, f1: 0.5010, edges-ner-ontonotes_loss: 0.1142
09/16 01:50:54 PM: Update 25535: task edges-ner-ontonotes, batch 535 (25535): mcc: 0.5183, acc: 0.3558, precision: 0.7758, recall: 0.3694, f1: 0.5005, edges-ner-ontonotes_loss: 0.1145
09/16 01:51:04 PM: Update 25602: task edges-ner-ontonotes, batch 602 (25602): mcc: 0.5182, acc: 0.3554, precision: 0.7749, recall: 0.3697, f1: 0.5005, edges-ner-ontonotes_loss: 0.1144
09/16 01:51:14 PM: Update 25671: task edges-ner-ontonotes, batch 671 (25671): mcc: 0.5197, acc: 0.3565, precision: 0.7746, recall: 0.3720, f1: 0.5026, edges-ner-ontonotes_loss: 0.1141
09/16 01:51:24 PM: Update 25748: task edges-ner-ontonotes, batch 748 (25748): mcc: 0.5203, acc: 0.3573, precision: 0.7732, recall: 0.3736, f1: 0.5038, edges-ner-ontonotes_loss: 0.1140
09/16 01:51:34 PM: Update 25823: task edges-ner-ontonotes, batch 823 (25823): mcc: 0.5221, acc: 0.3590, precision: 0.7734, recall: 0.3760, f1: 0.5060, edges-ner-ontonotes_loss: 0.1137
09/16 01:51:44 PM: Update 25844: task edges-ner-ontonotes, batch 844 (25844): mcc: 0.5226, acc: 0.3597, precision: 0.7732, recall: 0.3767, f1: 0.5066, edges-ner-ontonotes_loss: 0.1136
09/16 01:51:54 PM: Update 25914: task edges-ner-ontonotes, batch 914 (25914): mcc: 0.5232, acc: 0.3602, precision: 0.7736, recall: 0.3775, f1: 0.5074, edges-ner-ontonotes_loss: 0.1135
09/16 01:52:04 PM: Update 25984: task edges-ner-ontonotes, batch 984 (25984): mcc: 0.5229, acc: 0.3597, precision: 0.7728, recall: 0.3773, f1: 0.5071, edges-ner-ontonotes_loss: 0.1135
09/16 01:52:07 PM: ***** Step 26000 / Validation 26 *****
09/16 01:52:07 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:52:07 PM: Validating...
09/16 01:52:15 PM: Evaluate: task edges-ner-ontonotes, batch 47 (157): mcc: 0.4874, acc: 0.3020, precision: 0.8228, recall: 0.3071, f1: 0.4473, edges-ner-ontonotes_loss: 0.1228
09/16 01:52:25 PM: Evaluate: task edges-ner-ontonotes, batch 98 (157): mcc: 0.5210, acc: 0.3269, precision: 0.8580, recall: 0.3342, f1: 0.4811, edges-ner-ontonotes_loss: 0.1163
09/16 01:52:35 PM: Evaluate: task edges-ner-ontonotes, batch 144 (157): mcc: 0.5462, acc: 0.3519, precision: 0.8701, recall: 0.3609, f1: 0.5102, edges-ner-ontonotes_loss: 0.1101
09/16 01:52:37 PM: Updating LR scheduler:
09/16 01:52:37 PM: 	Best result seen so far for macro_avg: 0.511
09/16 01:52:37 PM: 	# validation passes without improvement: 2
09/16 01:52:37 PM: edges-ner-ontonotes_loss: training: 0.113464 validation: 0.109776
09/16 01:52:37 PM: macro_avg: validation: 0.509713
09/16 01:52:37 PM: micro_avg: validation: 0.000000
09/16 01:52:37 PM: edges-ner-ontonotes_mcc: training: 0.523231 validation: 0.546180
09/16 01:52:37 PM: edges-ner-ontonotes_acc: training: 0.359926 validation: 0.351153
09/16 01:52:37 PM: edges-ner-ontonotes_precision: training: 0.773351 validation: 0.872016
09/16 01:52:37 PM: edges-ner-ontonotes_recall: training: 0.377569 validation: 0.360100
09/16 01:52:37 PM: edges-ner-ontonotes_f1: training: 0.507408 validation: 0.509713
09/16 01:52:37 PM: Global learning rate: 2.5e-05
09/16 01:52:37 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 01:52:45 PM: Update 26050: task edges-ner-ontonotes, batch 50 (26050): mcc: 0.5341, acc: 0.3661, precision: 0.7734, recall: 0.3929, f1: 0.5211, edges-ner-ontonotes_loss: 0.1103
09/16 01:52:55 PM: Update 26109: task edges-ner-ontonotes, batch 109 (26109): mcc: 0.5331, acc: 0.3647, precision: 0.7756, recall: 0.3903, f1: 0.5193, edges-ner-ontonotes_loss: 0.1118
09/16 01:53:06 PM: Update 26149: task edges-ner-ontonotes, batch 149 (26149): mcc: 0.5280, acc: 0.3604, precision: 0.7714, recall: 0.3853, f1: 0.5139, edges-ner-ontonotes_loss: 0.1124
09/16 01:53:16 PM: Update 26212: task edges-ner-ontonotes, batch 212 (26212): mcc: 0.5117, acc: 0.3471, precision: 0.7593, recall: 0.3690, f1: 0.4966, edges-ner-ontonotes_loss: 0.1178
09/16 01:53:26 PM: Update 26279: task edges-ner-ontonotes, batch 279 (26279): mcc: 0.5076, acc: 0.3441, precision: 0.7582, recall: 0.3637, f1: 0.4916, edges-ner-ontonotes_loss: 0.1195
09/16 01:53:36 PM: Update 26343: task edges-ner-ontonotes, batch 343 (26343): mcc: 0.5055, acc: 0.3428, precision: 0.7579, recall: 0.3610, f1: 0.4890, edges-ner-ontonotes_loss: 0.1207
09/16 01:53:46 PM: Update 26423: task edges-ner-ontonotes, batch 423 (26423): mcc: 0.5065, acc: 0.3438, precision: 0.7612, recall: 0.3607, f1: 0.4894, edges-ner-ontonotes_loss: 0.1210
09/16 01:53:56 PM: Update 26459: task edges-ner-ontonotes, batch 459 (26459): mcc: 0.5048, acc: 0.3428, precision: 0.7596, recall: 0.3592, f1: 0.4877, edges-ner-ontonotes_loss: 0.1212
09/16 01:54:06 PM: Update 26536: task edges-ner-ontonotes, batch 536 (26536): mcc: 0.5053, acc: 0.3427, precision: 0.7620, recall: 0.3586, f1: 0.4877, edges-ner-ontonotes_loss: 0.1204
09/16 01:54:16 PM: Update 26634: task edges-ner-ontonotes, batch 634 (26634): mcc: 0.5066, acc: 0.3437, precision: 0.7641, recall: 0.3592, f1: 0.4887, edges-ner-ontonotes_loss: 0.1197
09/16 01:54:27 PM: Update 26736: task edges-ner-ontonotes, batch 736 (26736): mcc: 0.5089, acc: 0.3456, precision: 0.7666, recall: 0.3611, f1: 0.4910, edges-ner-ontonotes_loss: 0.1186
09/16 01:54:38 PM: Update 26766: task edges-ner-ontonotes, batch 766 (26766): mcc: 0.5093, acc: 0.3462, precision: 0.7664, recall: 0.3618, f1: 0.4915, edges-ner-ontonotes_loss: 0.1185
09/16 01:54:48 PM: Update 26829: task edges-ner-ontonotes, batch 829 (26829): mcc: 0.5089, acc: 0.3457, precision: 0.7666, recall: 0.3612, f1: 0.4910, edges-ner-ontonotes_loss: 0.1183
09/16 01:54:58 PM: Update 26897: task edges-ner-ontonotes, batch 897 (26897): mcc: 0.5105, acc: 0.3472, precision: 0.7677, recall: 0.3628, f1: 0.4927, edges-ner-ontonotes_loss: 0.1180
09/16 01:55:08 PM: Update 26980: task edges-ner-ontonotes, batch 980 (26980): mcc: 0.5108, acc: 0.3475, precision: 0.7681, recall: 0.3630, f1: 0.4930, edges-ner-ontonotes_loss: 0.1176
09/16 01:55:12 PM: ***** Step 27000 / Validation 27 *****
09/16 01:55:12 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:55:12 PM: Validating...
09/16 01:55:18 PM: Evaluate: task edges-ner-ontonotes, batch 44 (157): mcc: 0.5351, acc: 0.3370, precision: 0.8915, recall: 0.3377, f1: 0.4899, edges-ner-ontonotes_loss: 0.1117
09/16 01:55:29 PM: Evaluate: task edges-ner-ontonotes, batch 100 (157): mcc: 0.5393, acc: 0.3374, precision: 0.9000, recall: 0.3395, f1: 0.4930, edges-ner-ontonotes_loss: 0.1109
09/16 01:55:39 PM: Evaluate: task edges-ner-ontonotes, batch 148 (157): mcc: 0.5429, acc: 0.3422, precision: 0.8972, recall: 0.3451, f1: 0.4985, edges-ner-ontonotes_loss: 0.1077
09/16 01:55:40 PM: Updating LR scheduler:
09/16 01:55:40 PM: 	Best result seen so far for macro_avg: 0.511
09/16 01:55:40 PM: 	# validation passes without improvement: 3
09/16 01:55:40 PM: edges-ner-ontonotes_loss: training: 0.117545 validation: 0.107563
09/16 01:55:40 PM: macro_avg: validation: 0.499288
09/16 01:55:40 PM: micro_avg: validation: 0.000000
09/16 01:55:40 PM: edges-ner-ontonotes_mcc: training: 0.511143 validation: 0.543974
09/16 01:55:40 PM: edges-ner-ontonotes_acc: training: 0.347890 validation: 0.342812
09/16 01:55:40 PM: edges-ner-ontonotes_precision: training: 0.768381 validation: 0.899014
09/16 01:55:40 PM: edges-ner-ontonotes_recall: training: 0.363338 validation: 0.345617
09/16 01:55:40 PM: edges-ner-ontonotes_f1: training: 0.493377 validation: 0.499288
09/16 01:55:40 PM: Global learning rate: 2.5e-05
09/16 01:55:40 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 01:55:49 PM: Update 27053: task edges-ner-ontonotes, batch 53 (27053): mcc: 0.5147, acc: 0.3558, precision: 0.7670, recall: 0.3691, f1: 0.4983, edges-ner-ontonotes_loss: 0.1178
09/16 01:55:59 PM: Update 27092: task edges-ner-ontonotes, batch 92 (27092): mcc: 0.5178, acc: 0.3599, precision: 0.7650, recall: 0.3744, f1: 0.5027, edges-ner-ontonotes_loss: 0.1157
09/16 01:56:09 PM: Update 27160: task edges-ner-ontonotes, batch 160 (27160): mcc: 0.5203, acc: 0.3615, precision: 0.7654, recall: 0.3777, f1: 0.5058, edges-ner-ontonotes_loss: 0.1141
09/16 01:56:19 PM: Update 27223: task edges-ner-ontonotes, batch 223 (27223): mcc: 0.5225, acc: 0.3625, precision: 0.7665, recall: 0.3802, f1: 0.5083, edges-ner-ontonotes_loss: 0.1137
09/16 01:56:29 PM: Update 27282: task edges-ner-ontonotes, batch 282 (27282): mcc: 0.5259, acc: 0.3652, precision: 0.7689, recall: 0.3837, f1: 0.5119, edges-ner-ontonotes_loss: 0.1131
09/16 01:56:39 PM: Update 27359: task edges-ner-ontonotes, batch 359 (27359): mcc: 0.5274, acc: 0.3652, precision: 0.7697, recall: 0.3854, f1: 0.5136, edges-ner-ontonotes_loss: 0.1129
09/16 01:56:49 PM: Update 27398: task edges-ner-ontonotes, batch 398 (27398): mcc: 0.5270, acc: 0.3653, precision: 0.7674, recall: 0.3861, f1: 0.5137, edges-ner-ontonotes_loss: 0.1130
09/16 01:56:59 PM: Update 27461: task edges-ner-ontonotes, batch 461 (27461): mcc: 0.5275, acc: 0.3659, precision: 0.7678, recall: 0.3867, f1: 0.5143, edges-ner-ontonotes_loss: 0.1130
09/16 01:57:09 PM: Update 27525: task edges-ner-ontonotes, batch 525 (27525): mcc: 0.5282, acc: 0.3662, precision: 0.7691, recall: 0.3869, f1: 0.5149, edges-ner-ontonotes_loss: 0.1128
09/16 01:57:19 PM: Update 27593: task edges-ner-ontonotes, batch 593 (27593): mcc: 0.5272, acc: 0.3652, precision: 0.7671, recall: 0.3866, f1: 0.5141, edges-ner-ontonotes_loss: 0.1129
09/16 01:57:30 PM: Update 27678: task edges-ner-ontonotes, batch 678 (27678): mcc: 0.5266, acc: 0.3645, precision: 0.7667, recall: 0.3859, f1: 0.5134, edges-ner-ontonotes_loss: 0.1129
09/16 01:57:40 PM: Update 27713: task edges-ner-ontonotes, batch 713 (27713): mcc: 0.5258, acc: 0.3641, precision: 0.7651, recall: 0.3857, f1: 0.5129, edges-ner-ontonotes_loss: 0.1131
09/16 01:57:50 PM: Update 27778: task edges-ner-ontonotes, batch 778 (27778): mcc: 0.5233, acc: 0.3614, precision: 0.7648, recall: 0.3822, f1: 0.5097, edges-ner-ontonotes_loss: 0.1139
09/16 01:58:00 PM: Update 27844: task edges-ner-ontonotes, batch 844 (27844): mcc: 0.5215, acc: 0.3596, precision: 0.7643, recall: 0.3800, f1: 0.5076, edges-ner-ontonotes_loss: 0.1150
09/16 01:58:10 PM: Update 27920: task edges-ner-ontonotes, batch 920 (27920): mcc: 0.5195, acc: 0.3573, precision: 0.7643, recall: 0.3772, f1: 0.5051, edges-ner-ontonotes_loss: 0.1160
09/16 01:58:20 PM: Update 27994: task edges-ner-ontonotes, batch 994 (27994): mcc: 0.5182, acc: 0.3560, precision: 0.7639, recall: 0.3755, f1: 0.5035, edges-ner-ontonotes_loss: 0.1168
09/16 01:58:21 PM: ***** Step 28000 / Validation 28 *****
09/16 01:58:21 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:58:21 PM: Validating...
09/16 01:58:31 PM: Evaluate: task edges-ner-ontonotes, batch 52 (157): mcc: 0.5227, acc: 0.3151, precision: 0.9079, recall: 0.3162, f1: 0.4691, edges-ner-ontonotes_loss: 0.1121
09/16 01:58:41 PM: Evaluate: task edges-ner-ontonotes, batch 108 (157): mcc: 0.5326, acc: 0.3243, precision: 0.9120, recall: 0.3265, f1: 0.4808, edges-ner-ontonotes_loss: 0.1105
09/16 01:58:49 PM: Updating LR scheduler:
09/16 01:58:49 PM: 	Best result seen so far for macro_avg: 0.511
09/16 01:58:49 PM: 	# validation passes without improvement: 0
09/16 01:58:49 PM: edges-ner-ontonotes_loss: training: 0.116839 validation: 0.108244
09/16 01:58:49 PM: macro_avg: validation: 0.486252
09/16 01:58:49 PM: micro_avg: validation: 0.000000
09/16 01:58:49 PM: edges-ner-ontonotes_mcc: training: 0.518052 validation: 0.536121
09/16 01:58:49 PM: edges-ner-ontonotes_acc: training: 0.355961 validation: 0.328556
09/16 01:58:49 PM: edges-ner-ontonotes_precision: training: 0.763545 validation: 0.909034
09/16 01:58:49 PM: edges-ner-ontonotes_recall: training: 0.375553 validation: 0.331893
09/16 01:58:49 PM: edges-ner-ontonotes_f1: training: 0.503471 validation: 0.486252
09/16 01:58:49 PM: Global learning rate: 1.25e-05
09/16 01:58:49 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 01:58:53 PM: Update 28009: task edges-ner-ontonotes, batch 9 (28009): mcc: 0.5282, acc: 0.3694, precision: 0.7756, recall: 0.3834, f1: 0.5132, edges-ner-ontonotes_loss: 0.1199
09/16 01:59:03 PM: Update 28113: task edges-ner-ontonotes, batch 113 (28113): mcc: 0.5162, acc: 0.3474, precision: 0.7855, recall: 0.3615, f1: 0.4951, edges-ner-ontonotes_loss: 0.1159
09/16 01:59:14 PM: Update 28201: task edges-ner-ontonotes, batch 201 (28201): mcc: 0.5190, acc: 0.3517, precision: 0.7845, recall: 0.3658, f1: 0.4990, edges-ner-ontonotes_loss: 0.1154
09/16 01:59:24 PM: Update 28275: task edges-ner-ontonotes, batch 275 (28275): mcc: 0.5192, acc: 0.3523, precision: 0.7847, recall: 0.3660, f1: 0.4992, edges-ner-ontonotes_loss: 0.1150
09/16 01:59:34 PM: Update 28331: task edges-ner-ontonotes, batch 331 (28331): mcc: 0.5201, acc: 0.3526, precision: 0.7866, recall: 0.3663, f1: 0.4998, edges-ner-ontonotes_loss: 0.1147
09/16 01:59:44 PM: Update 28396: task edges-ner-ontonotes, batch 396 (28396): mcc: 0.5207, acc: 0.3537, precision: 0.7862, recall: 0.3673, f1: 0.5007, edges-ner-ontonotes_loss: 0.1144
09/16 01:59:54 PM: Update 28465: task edges-ner-ontonotes, batch 465 (28465): mcc: 0.5185, acc: 0.3520, precision: 0.7836, recall: 0.3656, f1: 0.4986, edges-ner-ontonotes_loss: 0.1147
09/16 02:00:04 PM: Update 28535: task edges-ner-ontonotes, batch 535 (28535): mcc: 0.5168, acc: 0.3512, precision: 0.7814, recall: 0.3645, f1: 0.4971, edges-ner-ontonotes_loss: 0.1149
09/16 02:00:14 PM: Update 28596: task edges-ner-ontonotes, batch 596 (28596): mcc: 0.5173, acc: 0.3521, precision: 0.7807, recall: 0.3655, f1: 0.4979, edges-ner-ontonotes_loss: 0.1148
09/16 02:00:26 PM: Update 28635: task edges-ner-ontonotes, batch 635 (28635): mcc: 0.5165, acc: 0.3514, precision: 0.7795, recall: 0.3650, f1: 0.4972, edges-ner-ontonotes_loss: 0.1148
09/16 02:00:36 PM: Update 28696: task edges-ner-ontonotes, batch 696 (28696): mcc: 0.5155, acc: 0.3506, precision: 0.7776, recall: 0.3645, f1: 0.4964, edges-ner-ontonotes_loss: 0.1148
09/16 02:00:46 PM: Update 28758: task edges-ner-ontonotes, batch 758 (28758): mcc: 0.5164, acc: 0.3515, precision: 0.7770, recall: 0.3662, f1: 0.4978, edges-ner-ontonotes_loss: 0.1146
09/16 02:00:56 PM: Update 28824: task edges-ner-ontonotes, batch 824 (28824): mcc: 0.5174, acc: 0.3529, precision: 0.7756, recall: 0.3682, f1: 0.4994, edges-ner-ontonotes_loss: 0.1144
09/16 02:01:06 PM: Update 28905: task edges-ner-ontonotes, batch 905 (28905): mcc: 0.5187, acc: 0.3540, precision: 0.7757, recall: 0.3699, f1: 0.5010, edges-ner-ontonotes_loss: 0.1141
09/16 02:01:19 PM: Update 28948: task edges-ner-ontonotes, batch 948 (28948): mcc: 0.5198, acc: 0.3553, precision: 0.7753, recall: 0.3718, f1: 0.5025, edges-ner-ontonotes_loss: 0.1139
09/16 02:01:27 PM: ***** Step 29000 / Validation 29 *****
09/16 02:01:27 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 02:01:27 PM: Validating...
09/16 02:01:29 PM: Evaluate: task edges-ner-ontonotes, batch 13 (157): mcc: 0.4485, acc: 0.2868, precision: 0.7415, recall: 0.2928, f1: 0.4199, edges-ner-ontonotes_loss: 0.1377
09/16 02:01:40 PM: Evaluate: task edges-ner-ontonotes, batch 76 (157): mcc: 0.4914, acc: 0.3012, precision: 0.8297, recall: 0.3093, f1: 0.4506, edges-ner-ontonotes_loss: 0.1202
09/16 02:01:50 PM: Evaluate: task edges-ner-ontonotes, batch 127 (157): mcc: 0.5374, acc: 0.3411, precision: 0.8682, recall: 0.3505, f1: 0.4994, edges-ner-ontonotes_loss: 0.1124
09/16 02:01:55 PM: Updating LR scheduler:
09/16 02:01:55 PM: 	Best result seen so far for macro_avg: 0.511
09/16 02:01:55 PM: 	# validation passes without improvement: 1
09/16 02:01:55 PM: edges-ner-ontonotes_loss: training: 0.113797 validation: 0.110166
09/16 02:01:55 PM: macro_avg: validation: 0.506592
09/16 02:01:55 PM: micro_avg: validation: 0.000000
09/16 02:01:55 PM: edges-ner-ontonotes_mcc: training: 0.519906 validation: 0.543862
09/16 02:01:55 PM: edges-ner-ontonotes_acc: training: 0.355529 validation: 0.347134
09/16 02:01:55 PM: edges-ner-ontonotes_precision: training: 0.774082 validation: 0.872474
09/16 02:01:55 PM: edges-ner-ontonotes_recall: training: 0.372528 validation: 0.356915
09/16 02:01:55 PM: edges-ner-ontonotes_f1: training: 0.502991 validation: 0.506592
09/16 02:01:55 PM: Global learning rate: 1.25e-05
09/16 02:01:55 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 02:02:00 PM: Update 29041: task edges-ner-ontonotes, batch 41 (29041): mcc: 0.5110, acc: 0.3435, precision: 0.7591, recall: 0.3679, f1: 0.4956, edges-ner-ontonotes_loss: 0.1130
09/16 02:02:10 PM: Update 29112: task edges-ner-ontonotes, batch 112 (29112): mcc: 0.5160, acc: 0.3506, precision: 0.7626, recall: 0.3732, f1: 0.5012, edges-ner-ontonotes_loss: 0.1128
09/16 02:02:20 PM: Update 29187: task edges-ner-ontonotes, batch 187 (29187): mcc: 0.5187, acc: 0.3539, precision: 0.7668, recall: 0.3746, f1: 0.5034, edges-ner-ontonotes_loss: 0.1129
09/16 02:02:34 PM: Update 29261: task edges-ner-ontonotes, batch 261 (29261): mcc: 0.5261, acc: 0.3619, precision: 0.7701, recall: 0.3834, f1: 0.5119, edges-ner-ontonotes_loss: 0.1118
09/16 02:02:44 PM: Update 29326: task edges-ner-ontonotes, batch 326 (29326): mcc: 0.5183, acc: 0.3542, precision: 0.7653, recall: 0.3749, f1: 0.5033, edges-ner-ontonotes_loss: 0.1152
09/16 02:02:54 PM: Update 29394: task edges-ner-ontonotes, batch 394 (29394): mcc: 0.5165, acc: 0.3528, precision: 0.7657, recall: 0.3722, f1: 0.5009, edges-ner-ontonotes_loss: 0.1170
09/16 02:03:04 PM: Update 29462: task edges-ner-ontonotes, batch 462 (29462): mcc: 0.5123, acc: 0.3491, precision: 0.7630, recall: 0.3678, f1: 0.4963, edges-ner-ontonotes_loss: 0.1183
09/16 02:03:14 PM: Update 29546: task edges-ner-ontonotes, batch 546 (29546): mcc: 0.5115, acc: 0.3483, precision: 0.7639, recall: 0.3662, f1: 0.4950, edges-ner-ontonotes_loss: 0.1190
09/16 02:03:24 PM: Update 29607: task edges-ner-ontonotes, batch 607 (29607): mcc: 0.5107, acc: 0.3473, precision: 0.7646, recall: 0.3647, f1: 0.4938, edges-ner-ontonotes_loss: 0.1190
09/16 02:03:34 PM: Update 29678: task edges-ner-ontonotes, batch 678 (29678): mcc: 0.5120, acc: 0.3484, precision: 0.7660, recall: 0.3657, f1: 0.4951, edges-ner-ontonotes_loss: 0.1186
09/16 02:03:44 PM: Update 29740: task edges-ner-ontonotes, batch 740 (29740): mcc: 0.5120, acc: 0.3484, precision: 0.7663, recall: 0.3657, f1: 0.4951, edges-ner-ontonotes_loss: 0.1183
09/16 02:03:54 PM: Update 29834: task edges-ner-ontonotes, batch 834 (29834): mcc: 0.5129, acc: 0.3491, precision: 0.7678, recall: 0.3660, f1: 0.4957, edges-ner-ontonotes_loss: 0.1179
09/16 02:04:05 PM: Update 29879: task edges-ner-ontonotes, batch 879 (29879): mcc: 0.5131, acc: 0.3492, precision: 0.7685, recall: 0.3659, f1: 0.4958, edges-ner-ontonotes_loss: 0.1178
09/16 02:04:15 PM: Update 29948: task edges-ner-ontonotes, batch 948 (29948): mcc: 0.5131, acc: 0.3492, precision: 0.7692, recall: 0.3657, f1: 0.4957, edges-ner-ontonotes_loss: 0.1177
09/16 02:04:23 PM: ***** Step 30000 / Validation 30 *****
09/16 02:04:23 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 02:04:23 PM: Validating...
09/16 02:04:25 PM: Evaluate: task edges-ner-ontonotes, batch 13 (157): mcc: 0.5193, acc: 0.3378, precision: 0.8363, recall: 0.3414, f1: 0.4849, edges-ner-ontonotes_loss: 0.1274
09/16 02:04:35 PM: Evaluate: task edges-ner-ontonotes, batch 72 (157): mcc: 0.5372, acc: 0.3341, precision: 0.9026, recall: 0.3358, f1: 0.4895, edges-ner-ontonotes_loss: 0.1110
09/16 02:04:45 PM: Evaluate: task edges-ner-ontonotes, batch 116 (157): mcc: 0.5392, acc: 0.3382, precision: 0.8955, recall: 0.3412, f1: 0.4941, edges-ner-ontonotes_loss: 0.1090
09/16 02:04:53 PM: Updating LR scheduler:
09/16 02:04:53 PM: 	Best result seen so far for macro_avg: 0.511
09/16 02:04:53 PM: 	# validation passes without improvement: 2
09/16 02:04:53 PM: edges-ner-ontonotes_loss: training: 0.117542 validation: 0.107473
09/16 02:04:53 PM: macro_avg: validation: 0.495357
09/16 02:04:53 PM: micro_avg: validation: 0.000000
09/16 02:04:53 PM: edges-ner-ontonotes_mcc: training: 0.513470 validation: 0.541000
09/16 02:04:53 PM: edges-ner-ontonotes_acc: training: 0.349616 validation: 0.337959
09/16 02:04:53 PM: edges-ner-ontonotes_precision: training: 0.769591 validation: 0.899262
09/16 02:04:53 PM: edges-ner-ontonotes_recall: training: 0.365932 validation: 0.341826
09/16 02:04:53 PM: edges-ner-ontonotes_f1: training: 0.496014 validation: 0.495357
09/16 02:04:53 PM: Global learning rate: 1.25e-05
09/16 02:04:53 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 02:04:55 PM: Update 30017: task edges-ner-ontonotes, batch 17 (30017): mcc: 0.5008, acc: 0.3431, precision: 0.7553, recall: 0.3559, f1: 0.4838, edges-ner-ontonotes_loss: 0.1160
09/16 02:05:05 PM: Update 30091: task edges-ner-ontonotes, batch 91 (30091): mcc: 0.5094, acc: 0.3462, precision: 0.7700, recall: 0.3601, f1: 0.4908, edges-ner-ontonotes_loss: 0.1156
09/16 02:05:15 PM: Update 30171: task edges-ner-ontonotes, batch 171 (30171): mcc: 0.5082, acc: 0.3473, precision: 0.7642, recall: 0.3615, f1: 0.4908, edges-ner-ontonotes_loss: 0.1154
09/16 02:05:25 PM: Update 30224: task edges-ner-ontonotes, batch 224 (30224): mcc: 0.5054, acc: 0.3448, precision: 0.7605, recall: 0.3595, f1: 0.4882, edges-ner-ontonotes_loss: 0.1159
09/16 02:05:35 PM: Update 30298: task edges-ner-ontonotes, batch 298 (30298): mcc: 0.5092, acc: 0.3483, precision: 0.7606, recall: 0.3647, f1: 0.4930, edges-ner-ontonotes_loss: 0.1152
09/16 02:05:45 PM: Update 30364: task edges-ner-ontonotes, batch 364 (30364): mcc: 0.5153, acc: 0.3536, precision: 0.7642, recall: 0.3713, f1: 0.4998, edges-ner-ontonotes_loss: 0.1143
09/16 02:05:55 PM: Update 30434: task edges-ner-ontonotes, batch 434 (30434): mcc: 0.5192, acc: 0.3568, precision: 0.7669, recall: 0.3753, f1: 0.5040, edges-ner-ontonotes_loss: 0.1138
09/16 02:06:06 PM: Update 30501: task edges-ner-ontonotes, batch 501 (30501): mcc: 0.5207, acc: 0.3581, precision: 0.7673, recall: 0.3772, f1: 0.5058, edges-ner-ontonotes_loss: 0.1137
09/16 02:06:16 PM: Update 30520: task edges-ner-ontonotes, batch 520 (30520): mcc: 0.5203, acc: 0.3580, precision: 0.7662, recall: 0.3772, f1: 0.5056, edges-ner-ontonotes_loss: 0.1137
09/16 02:06:26 PM: Update 30580: task edges-ner-ontonotes, batch 580 (30580): mcc: 0.5217, acc: 0.3593, precision: 0.7671, recall: 0.3788, f1: 0.5071, edges-ner-ontonotes_loss: 0.1135
09/16 02:06:36 PM: Update 30653: task edges-ner-ontonotes, batch 653 (30653): mcc: 0.5213, acc: 0.3588, precision: 0.7662, recall: 0.3787, f1: 0.5069, edges-ner-ontonotes_loss: 0.1135
09/16 02:06:46 PM: Update 30723: task edges-ner-ontonotes, batch 723 (30723): mcc: 0.5221, acc: 0.3593, precision: 0.7670, recall: 0.3795, f1: 0.5077, edges-ner-ontonotes_loss: 0.1135
09/16 02:06:56 PM: Update 30787: task edges-ner-ontonotes, batch 787 (30787): mcc: 0.5230, acc: 0.3597, precision: 0.7680, recall: 0.3801, f1: 0.5085, edges-ner-ontonotes_loss: 0.1132
09/16 02:07:06 PM: Update 30819: task edges-ner-ontonotes, batch 819 (30819): mcc: 0.5229, acc: 0.3597, precision: 0.7675, recall: 0.3802, f1: 0.5085, edges-ner-ontonotes_loss: 0.1133
09/16 02:07:16 PM: Update 30880: task edges-ner-ontonotes, batch 880 (30880): mcc: 0.5207, acc: 0.3577, precision: 0.7668, recall: 0.3775, f1: 0.5060, edges-ner-ontonotes_loss: 0.1143
09/16 02:07:26 PM: Update 30952: task edges-ner-ontonotes, batch 952 (30952): mcc: 0.5193, acc: 0.3562, precision: 0.7666, recall: 0.3757, f1: 0.5042, edges-ner-ontonotes_loss: 0.1150
09/16 02:07:33 PM: ***** Step 31000 / Validation 31 *****
09/16 02:07:33 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 02:07:33 PM: Validating...
09/16 02:07:36 PM: Evaluate: task edges-ner-ontonotes, batch 16 (157): mcc: 0.5065, acc: 0.3166, precision: 0.8522, recall: 0.3186, f1: 0.4638, edges-ner-ontonotes_loss: 0.1262
09/16 02:07:47 PM: Evaluate: task edges-ner-ontonotes, batch 78 (157): mcc: 0.5353, acc: 0.3282, precision: 0.9111, recall: 0.3301, f1: 0.4846, edges-ner-ontonotes_loss: 0.1109
09/16 02:07:57 PM: Evaluate: task edges-ner-ontonotes, batch 139 (157): mcc: 0.5449, acc: 0.3388, precision: 0.9071, recall: 0.3434, f1: 0.4982, edges-ner-ontonotes_loss: 0.1071
09/16 02:07:59 PM: Updating LR scheduler:
09/16 02:07:59 PM: 	Best result seen so far for macro_avg: 0.511
09/16 02:07:59 PM: 	# validation passes without improvement: 3
09/16 02:07:59 PM: edges-ner-ontonotes_loss: training: 0.115469 validation: 0.107191
09/16 02:07:59 PM: macro_avg: validation: 0.496638
09/16 02:07:59 PM: micro_avg: validation: 0.000000
09/16 02:07:59 PM: edges-ner-ontonotes_mcc: training: 0.518282 validation: 0.544064
09/16 02:07:59 PM: edges-ner-ontonotes_acc: training: 0.355148 validation: 0.337200
09/16 02:07:59 PM: edges-ner-ontonotes_precision: training: 0.766529 validation: 0.908834
09/16 02:07:59 PM: edges-ner-ontonotes_recall: training: 0.374273 validation: 0.341674
09/16 02:07:59 PM: edges-ner-ontonotes_f1: training: 0.502963 validation: 0.496638
09/16 02:07:59 PM: Global learning rate: 1.25e-05
09/16 02:07:59 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 02:08:07 PM: Update 31070: task edges-ner-ontonotes, batch 70 (31070): mcc: 0.4973, acc: 0.3393, precision: 0.7506, recall: 0.3534, f1: 0.4805, edges-ner-ontonotes_loss: 0.1259
09/16 02:08:18 PM: Update 31121: task edges-ner-ontonotes, batch 121 (31121): mcc: 0.4954, acc: 0.3382, precision: 0.7490, recall: 0.3516, f1: 0.4786, edges-ner-ontonotes_loss: 0.1266
09/16 02:08:28 PM: Update 31202: task edges-ner-ontonotes, batch 202 (31202): mcc: 0.4945, acc: 0.3363, precision: 0.7501, recall: 0.3498, f1: 0.4771, edges-ner-ontonotes_loss: 0.1228
09/16 02:08:39 PM: Update 31278: task edges-ner-ontonotes, batch 278 (31278): mcc: 0.5017, acc: 0.3409, precision: 0.7602, recall: 0.3545, f1: 0.4835, edges-ner-ontonotes_loss: 0.1207
09/16 02:08:49 PM: Update 31348: task edges-ner-ontonotes, batch 348 (31348): mcc: 0.5060, acc: 0.3440, precision: 0.7656, recall: 0.3576, f1: 0.4875, edges-ner-ontonotes_loss: 0.1191
09/16 02:08:59 PM: Update 31427: task edges-ner-ontonotes, batch 427 (31427): mcc: 0.5087, acc: 0.3455, precision: 0.7691, recall: 0.3596, f1: 0.4900, edges-ner-ontonotes_loss: 0.1182
09/16 02:09:09 PM: Update 31469: task edges-ner-ontonotes, batch 469 (31469): mcc: 0.5083, acc: 0.3452, precision: 0.7683, recall: 0.3594, f1: 0.4898, edges-ner-ontonotes_loss: 0.1181
09/16 02:09:19 PM: Update 31537: task edges-ner-ontonotes, batch 537 (31537): mcc: 0.5101, acc: 0.3470, precision: 0.7697, recall: 0.3612, f1: 0.4916, edges-ner-ontonotes_loss: 0.1178
09/16 02:09:29 PM: Update 31619: task edges-ner-ontonotes, batch 619 (31619): mcc: 0.5114, acc: 0.3484, precision: 0.7701, recall: 0.3628, f1: 0.4932, edges-ner-ontonotes_loss: 0.1172
09/16 02:09:39 PM: Update 31697: task edges-ner-ontonotes, batch 697 (31697): mcc: 0.5129, acc: 0.3500, precision: 0.7712, recall: 0.3642, f1: 0.4948, edges-ner-ontonotes_loss: 0.1169
09/16 02:09:49 PM: Update 31746: task edges-ner-ontonotes, batch 746 (31746): mcc: 0.5128, acc: 0.3503, precision: 0.7703, recall: 0.3646, f1: 0.4950, edges-ner-ontonotes_loss: 0.1168
09/16 02:09:59 PM: Update 31765: task edges-ner-ontonotes, batch 765 (31765): mcc: 0.5127, acc: 0.3499, precision: 0.7710, recall: 0.3642, f1: 0.4947, edges-ner-ontonotes_loss: 0.1168
09/16 02:10:09 PM: Update 31826: task edges-ner-ontonotes, batch 826 (31826): mcc: 0.5119, acc: 0.3496, precision: 0.7687, recall: 0.3642, f1: 0.4942, edges-ner-ontonotes_loss: 0.1167
09/16 02:10:19 PM: Update 31885: task edges-ner-ontonotes, batch 885 (31885): mcc: 0.5137, acc: 0.3512, precision: 0.7693, recall: 0.3664, f1: 0.4964, edges-ner-ontonotes_loss: 0.1163
09/16 02:10:30 PM: Update 31940: task edges-ner-ontonotes, batch 940 (31940): mcc: 0.5151, acc: 0.3521, precision: 0.7701, recall: 0.3680, f1: 0.4980, edges-ner-ontonotes_loss: 0.1159
09/16 02:10:40 PM: Update 31989: task edges-ner-ontonotes, batch 989 (31989): mcc: 0.5165, acc: 0.3536, precision: 0.7706, recall: 0.3697, f1: 0.4997, edges-ner-ontonotes_loss: 0.1157
09/16 02:10:42 PM: ***** Step 32000 / Validation 32 *****
09/16 02:10:42 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 02:10:42 PM: Validating...
09/16 02:10:50 PM: Evaluate: task edges-ner-ontonotes, batch 52 (157): mcc: 0.4748, acc: 0.2897, precision: 0.8097, recall: 0.2970, f1: 0.4346, edges-ner-ontonotes_loss: 0.1214
09/16 02:11:00 PM: Evaluate: task edges-ner-ontonotes, batch 104 (157): mcc: 0.5265, acc: 0.3327, precision: 0.8581, recall: 0.3411, f1: 0.4882, edges-ner-ontonotes_loss: 0.1160
09/16 02:11:10 PM: Evaluate: task edges-ner-ontonotes, batch 154 (157): mcc: 0.5442, acc: 0.3502, precision: 0.8658, recall: 0.3604, f1: 0.5089, edges-ner-ontonotes_loss: 0.1106
09/16 02:11:10 PM: Updating LR scheduler:
09/16 02:11:10 PM: 	Best result seen so far for macro_avg: 0.511
09/16 02:11:10 PM: 	# validation passes without improvement: 0
09/16 02:11:10 PM: edges-ner-ontonotes_loss: training: 0.115670 validation: 0.110335
09/16 02:11:10 PM: macro_avg: validation: 0.510249
09/16 02:11:10 PM: micro_avg: validation: 0.000000
09/16 02:11:10 PM: edges-ner-ontonotes_mcc: training: 0.516500 validation: 0.545555
09/16 02:11:10 PM: edges-ner-ontonotes_acc: training: 0.353621 validation: 0.351228
09/16 02:11:10 PM: edges-ner-ontonotes_precision: training: 0.770390 validation: 0.867200
09/16 02:11:10 PM: edges-ner-ontonotes_recall: training: 0.369727 validation: 0.361465
09/16 02:11:10 PM: edges-ner-ontonotes_f1: training: 0.499657 validation: 0.510249
09/16 02:11:10 PM: Global learning rate: 6.25e-06
09/16 02:11:10 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 02:11:20 PM: Update 32058: task edges-ner-ontonotes, batch 58 (32058): mcc: 0.5352, acc: 0.3715, precision: 0.7762, recall: 0.3930, f1: 0.5218, edges-ner-ontonotes_loss: 0.1121
09/16 02:11:31 PM: Update 32099: task edges-ner-ontonotes, batch 99 (32099): mcc: 0.5311, acc: 0.3683, precision: 0.7700, recall: 0.3906, f1: 0.5183, edges-ner-ontonotes_loss: 0.1138
09/16 02:11:41 PM: Update 32159: task edges-ner-ontonotes, batch 159 (32159): mcc: 0.5288, acc: 0.3645, precision: 0.7700, recall: 0.3872, f1: 0.5153, edges-ner-ontonotes_loss: 0.1140
09/16 02:11:51 PM: Update 32231: task edges-ner-ontonotes, batch 231 (32231): mcc: 0.5284, acc: 0.3638, precision: 0.7704, recall: 0.3865, f1: 0.5148, edges-ner-ontonotes_loss: 0.1132
09/16 02:12:01 PM: Update 32295: task edges-ner-ontonotes, batch 295 (32295): mcc: 0.5272, acc: 0.3624, precision: 0.7704, recall: 0.3847, f1: 0.5132, edges-ner-ontonotes_loss: 0.1128
09/16 02:12:15 PM: Update 32373: task edges-ner-ontonotes, batch 373 (32373): mcc: 0.5279, acc: 0.3641, precision: 0.7686, recall: 0.3868, f1: 0.5146, edges-ner-ontonotes_loss: 0.1129
09/16 02:12:25 PM: Update 32457: task edges-ner-ontonotes, batch 457 (32457): mcc: 0.5219, acc: 0.3581, precision: 0.7662, recall: 0.3796, f1: 0.5076, edges-ner-ontonotes_loss: 0.1154
09/16 02:12:35 PM: Update 32545: task edges-ner-ontonotes, batch 545 (32545): mcc: 0.5186, acc: 0.3549, precision: 0.7660, recall: 0.3750, f1: 0.5035, edges-ner-ontonotes_loss: 0.1170
09/16 02:12:45 PM: Update 32620: task edges-ner-ontonotes, batch 620 (32620): mcc: 0.5165, acc: 0.3533, precision: 0.7653, recall: 0.3724, f1: 0.5010, edges-ner-ontonotes_loss: 0.1180
09/16 02:12:59 PM: Update 32677: task edges-ner-ontonotes, batch 677 (32677): mcc: 0.5143, acc: 0.3511, precision: 0.7649, recall: 0.3696, f1: 0.4984, edges-ner-ontonotes_loss: 0.1186
09/16 02:13:09 PM: Update 32751: task edges-ner-ontonotes, batch 751 (32751): mcc: 0.5145, acc: 0.3511, precision: 0.7658, recall: 0.3694, f1: 0.4984, edges-ner-ontonotes_loss: 0.1183
09/16 02:13:19 PM: Update 32844: task edges-ner-ontonotes, batch 844 (32844): mcc: 0.5151, acc: 0.3515, precision: 0.7675, recall: 0.3693, f1: 0.4987, edges-ner-ontonotes_loss: 0.1178
09/16 02:13:29 PM: Update 32927: task edges-ner-ontonotes, batch 927 (32927): mcc: 0.5150, acc: 0.3512, precision: 0.7685, recall: 0.3686, f1: 0.4982, edges-ner-ontonotes_loss: 0.1176
09/16 02:13:41 PM: Update 32990: task edges-ner-ontonotes, batch 990 (32990): mcc: 0.5155, acc: 0.3517, precision: 0.7691, recall: 0.3689, f1: 0.4987, edges-ner-ontonotes_loss: 0.1173
09/16 02:13:43 PM: ***** Step 33000 / Validation 33 *****
09/16 02:13:43 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 02:13:43 PM: Validating...
09/16 02:13:51 PM: Evaluate: task edges-ner-ontonotes, batch 56 (157): mcc: 0.5486, acc: 0.3456, precision: 0.9109, recall: 0.3464, f1: 0.5019, edges-ner-ontonotes_loss: 0.1089
09/16 02:14:02 PM: Evaluate: task edges-ner-ontonotes, batch 112 (157): mcc: 0.5390, acc: 0.3390, precision: 0.8948, recall: 0.3412, f1: 0.4941, edges-ner-ontonotes_loss: 0.1091
09/16 02:14:11 PM: Updating LR scheduler:
09/16 02:14:11 PM: 	Best result seen so far for macro_avg: 0.511
09/16 02:14:11 PM: 	# validation passes without improvement: 1
09/16 02:14:11 PM: edges-ner-ontonotes_loss: training: 0.117327 validation: 0.108065
09/16 02:14:11 PM: macro_avg: validation: 0.491253
09/16 02:14:11 PM: micro_avg: validation: 0.000000
09/16 02:14:11 PM: edges-ner-ontonotes_mcc: training: 0.515072 validation: 0.536870
09/16 02:14:11 PM: edges-ner-ontonotes_acc: training: 0.351428 validation: 0.335760
09/16 02:14:11 PM: edges-ner-ontonotes_precision: training: 0.768719 validation: 0.894790
09/16 02:14:11 PM: edges-ner-ontonotes_recall: training: 0.368616 validation: 0.338565
09/16 02:14:11 PM: edges-ner-ontonotes_f1: training: 0.498292 validation: 0.491253
09/16 02:14:11 PM: Global learning rate: 6.25e-06
09/16 02:14:11 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 02:14:12 PM: Update 33008: task edges-ner-ontonotes, batch 8 (33008): mcc: 0.4991, acc: 0.3320, precision: 0.7768, recall: 0.3428, f1: 0.4757, edges-ner-ontonotes_loss: 0.1185
09/16 02:14:22 PM: Update 33079: task edges-ner-ontonotes, batch 79 (33079): mcc: 0.5142, acc: 0.3513, precision: 0.7788, recall: 0.3622, f1: 0.4944, edges-ner-ontonotes_loss: 0.1157
09/16 02:14:32 PM: Update 33146: task edges-ner-ontonotes, batch 146 (33146): mcc: 0.5190, acc: 0.3544, precision: 0.7838, recall: 0.3662, f1: 0.4992, edges-ner-ontonotes_loss: 0.1151
09/16 02:14:42 PM: Update 33215: task edges-ner-ontonotes, batch 215 (33215): mcc: 0.5153, acc: 0.3506, precision: 0.7791, recall: 0.3636, f1: 0.4958, edges-ner-ontonotes_loss: 0.1148
09/16 02:14:52 PM: Update 33282: task edges-ner-ontonotes, batch 282 (33282): mcc: 0.5160, acc: 0.3508, precision: 0.7803, recall: 0.3639, f1: 0.4963, edges-ner-ontonotes_loss: 0.1145
09/16 02:15:02 PM: Update 33317: task edges-ner-ontonotes, batch 317 (33317): mcc: 0.5133, acc: 0.3487, precision: 0.7770, recall: 0.3619, f1: 0.4938, edges-ner-ontonotes_loss: 0.1150
09/16 02:15:12 PM: Update 33396: task edges-ner-ontonotes, batch 396 (33396): mcc: 0.5134, acc: 0.3482, precision: 0.7759, recall: 0.3625, f1: 0.4941, edges-ner-ontonotes_loss: 0.1148
09/16 02:15:22 PM: Update 33469: task edges-ner-ontonotes, batch 469 (33469): mcc: 0.5140, acc: 0.3491, precision: 0.7739, recall: 0.3644, f1: 0.4955, edges-ner-ontonotes_loss: 0.1144
09/16 02:15:32 PM: Update 33539: task edges-ner-ontonotes, batch 539 (33539): mcc: 0.5166, acc: 0.3517, precision: 0.7738, recall: 0.3681, f1: 0.4988, edges-ner-ontonotes_loss: 0.1141
09/16 02:15:43 PM: Update 33605: task edges-ner-ontonotes, batch 605 (33605): mcc: 0.5199, acc: 0.3554, precision: 0.7740, recall: 0.3725, f1: 0.5030, edges-ner-ontonotes_loss: 0.1137
09/16 02:15:53 PM: Update 33651: task edges-ner-ontonotes, batch 651 (33651): mcc: 0.5195, acc: 0.3555, precision: 0.7726, recall: 0.3728, f1: 0.5029, edges-ner-ontonotes_loss: 0.1137
09/16 02:16:03 PM: Update 33722: task edges-ner-ontonotes, batch 722 (33722): mcc: 0.5203, acc: 0.3562, precision: 0.7723, recall: 0.3741, f1: 0.5040, edges-ner-ontonotes_loss: 0.1135
09/16 02:16:13 PM: Update 33794: task edges-ner-ontonotes, batch 794 (33794): mcc: 0.5213, acc: 0.3569, precision: 0.7722, recall: 0.3754, f1: 0.5052, edges-ner-ontonotes_loss: 0.1133
09/16 02:16:23 PM: Update 33859: task edges-ner-ontonotes, batch 859 (33859): mcc: 0.5210, acc: 0.3568, precision: 0.7711, recall: 0.3756, f1: 0.5052, edges-ner-ontonotes_loss: 0.1134
09/16 02:16:33 PM: Update 33925: task edges-ner-ontonotes, batch 925 (33925): mcc: 0.5211, acc: 0.3570, precision: 0.7704, recall: 0.3761, f1: 0.5055, edges-ner-ontonotes_loss: 0.1133
09/16 02:16:43 PM: Update 33979: task edges-ner-ontonotes, batch 979 (33979): mcc: 0.5197, acc: 0.3559, precision: 0.7688, recall: 0.3750, f1: 0.5041, edges-ner-ontonotes_loss: 0.1141
09/16 02:16:46 PM: ***** Step 34000 / Validation 34 *****
09/16 02:16:46 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 02:16:46 PM: Validating...
09/16 02:16:53 PM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.5111, acc: 0.3053, precision: 0.8925, recall: 0.3083, f1: 0.4583, edges-ner-ontonotes_loss: 0.1145
09/16 02:17:03 PM: Evaluate: task edges-ner-ontonotes, batch 102 (157): mcc: 0.5323, acc: 0.3232, precision: 0.9064, recall: 0.3284, f1: 0.4821, edges-ner-ontonotes_loss: 0.1119
09/16 02:17:13 PM: Evaluate: task edges-ner-ontonotes, batch 146 (157): mcc: 0.5439, acc: 0.3357, precision: 0.9054, recall: 0.3428, f1: 0.4973, edges-ner-ontonotes_loss: 0.1075
09/16 02:17:16 PM: Updating LR scheduler:
09/16 02:17:16 PM: 	Best result seen so far for macro_avg: 0.511
09/16 02:17:16 PM: 	# validation passes without improvement: 2
09/16 02:17:16 PM: Ran out of early stopping patience. Stopping training.
09/16 02:17:16 PM: edges-ner-ontonotes_loss: training: 0.114353 validation: 0.107214
09/16 02:17:16 PM: macro_avg: validation: 0.498901
09/16 02:17:16 PM: micro_avg: validation: 0.000000
09/16 02:17:16 PM: edges-ner-ontonotes_mcc: training: 0.519097 validation: 0.545381
09/16 02:17:16 PM: edges-ner-ontonotes_acc: training: 0.355291 validation: 0.337200
09/16 02:17:16 PM: edges-ner-ontonotes_precision: training: 0.768743 validation: 0.906874
09/16 02:17:16 PM: edges-ner-ontonotes_recall: training: 0.374232 validation: 0.344101
09/16 02:17:16 PM: edges-ner-ontonotes_f1: training: 0.503402 validation: 0.498901
09/16 02:17:16 PM: Global learning rate: 6.25e-06
09/16 02:17:16 PM: Saving checkpoints to: ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 02:17:16 PM: Stopped training after 34 validation checks
09/16 02:17:16 PM: Trained edges-ner-ontonotes for 34000 batches or 21.879 epochs
09/16 02:17:16 PM: ***** VALIDATION RESULTS *****
09/16 02:17:16 PM: edges-ner-ontonotes_f1 (for best val pass 24): edges-ner-ontonotes_loss: 0.10921, macro_avg: 0.51096, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.54606, edges-ner-ontonotes_acc: 0.35274, edges-ner-ontonotes_precision: 0.86697, edges-ner-ontonotes_recall: 0.36222, edges-ner-ontonotes_f1: 0.51096
09/16 02:17:16 PM: micro_avg (for best val pass 1): edges-ner-ontonotes_loss: 0.14146, macro_avg: 0.31833, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.39107, edges-ner-ontonotes_acc: 0.19594, edges-ner-ontonotes_precision: 0.83152, edges-ner-ontonotes_recall: 0.19685, edges-ner-ontonotes_f1: 0.31833
09/16 02:17:16 PM: macro_avg (for best val pass 24): edges-ner-ontonotes_loss: 0.10921, macro_avg: 0.51096, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.54606, edges-ner-ontonotes_acc: 0.35274, edges-ner-ontonotes_precision: 0.86697, edges-ner-ontonotes_recall: 0.36222, edges-ner-ontonotes_f1: 0.51096
09/16 02:17:16 PM: Evaluating...
09/16 02:17:16 PM: Loaded model state from ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run/edges-ner-ontonotes/model_state_target_train_val_24.best.th
09/16 02:17:16 PM: Evaluating on: edges-ner-ontonotes, split: val
09/16 02:17:46 PM: 	Task edges-ner-ontonotes: batch 154
09/16 02:18:02 PM: Task 'edges-ner-ontonotes': sorting predictions by 'idx'
09/16 02:18:02 PM: Finished evaluating on: edges-ner-ontonotes
09/16 02:18:02 PM: Task 'edges-ner-ontonotes': joining predictions with input split 'val'
09/16 02:18:04 PM: Task 'edges-ner-ontonotes': Wrote predictions to ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 02:18:04 PM: Wrote all preds for split 'val' to ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 02:18:04 PM: Evaluating on: edges-ner-ontonotes, split: test
09/16 02:18:32 PM: Task 'edges-ner-ontonotes': sorting predictions by 'idx'
09/16 02:18:32 PM: Finished evaluating on: edges-ner-ontonotes
09/16 02:18:32 PM: Task 'edges-ner-ontonotes': joining predictions with input split 'test'
09/16 02:18:33 PM: Task 'edges-ner-ontonotes': Wrote predictions to ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 02:18:33 PM: Wrote all preds for split 'test' to ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/run
09/16 02:18:33 PM: Writing results for split 'val' to ./experiments/ner-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-top/results.tsv
09/16 02:18:33 PM: micro_avg: 0.000, macro_avg: 0.513, edges-ner-ontonotes_mcc: 0.549, edges-ner-ontonotes_acc: 0.354, edges-ner-ontonotes_precision: 0.873, edges-ner-ontonotes_recall: 0.363, edges-ner-ontonotes_f1: 0.513
09/16 02:18:33 PM: Done!
09/16 02:18:33 PM: Fatal error in main():
Traceback (most recent call last):
  File "main.py", line 16, in <module>
    main(sys.argv[1:])
  File "/srv/home/ericwallace/jiant/jiant/__main__.py", line 610, in main
    exit("Done exited")
  File "/home/ericwallace/miniconda3/envs/jiant/lib/python3.6/_sitebuiltins.py", line 26, in __call__
    raise SystemExit(code)
SystemExit: Done exited
