<<<<<<< HEAD
09/16 03:11:38 AM: Git branch: master
09/16 03:11:38 AM: Git SHA: fb3796f035a61c062bc75b422b0939a7eeec20ff
09/16 03:11:38 AM: Parsed args: 
=======
<<<<<<< HEAD
09/16 12:22:32 PM: Git branch: master
09/16 12:22:32 PM: Git SHA: ce97551376ebcff91ec7c178ddad0ca53f8fcb03
09/16 12:22:33 PM: Parsed args: 
=======
09/16 09:39:17 AM: Git branch: master
09/16 09:39:17 AM: Git SHA: 0869c6f0712662a0adcfe16ed0072c1997d1c5da
09/16 09:39:17 AM: Parsed args: 
>>>>>>> c9d1f3d70352f2e7d47f7ef89b434d6d01abf5d2
>>>>>>> 1ff7cb9943cafa999ead70f38407af315c736ff9
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/pos-ontonotes-sts-b-top/",
  "exp_name": "experiments/pos-ontonotes-sts-b-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/pos-ontonotes-sts-b-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/sts-b",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/pos-ontonotes-sts-b-top__run",
  "run_dir": "./experiments/pos-ontonotes-sts-b-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-pos-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
<<<<<<< HEAD
09/16 03:11:38 AM: Saved config to ./experiments/pos-ontonotes-sts-b-top/run/params.conf
09/16 03:11:38 AM: Using random seed 1234
09/16 03:11:39 AM: Using GPU 0
09/16 03:11:39 AM: Loading tasks...
09/16 03:11:39 AM: Writing pre-preprocessed tasks to ./experiments/pos-ontonotes-sts-b-top/
09/16 03:11:39 AM: 	Creating task edges-pos-ontonotes from scratch.
09/16 03:11:56 AM: Read=110514, Skip=5298, Total=115812 from ./probing_data/edges/ontonotes/const/pos/train.json.retokenized.bert-base-uncased
09/16 03:11:57 AM: Read=15060, Skip=620, Total=15680 from ./probing_data/edges/ontonotes/const/pos/development.json.retokenized.bert-base-uncased
09/16 03:12:00 AM: Read=11462, Skip=755, Total=12217 from ./probing_data/edges/ontonotes/const/pos/test.json.retokenized.bert-base-uncased
09/16 03:12:10 AM: 	Task 'edges-pos-ontonotes': |train|=110514 |val|=15060 |test|=11462
09/16 03:12:10 AM: 	Finished loading tasks: edges-pos-ontonotes.
09/16 03:12:10 AM: 	Building vocab from scratch.
09/16 03:12:10 AM: 	Counting units for task edges-pos-ontonotes.
09/16 03:12:12 AM: 	Task 'edges-pos-ontonotes': adding vocab namespace 'edges-pos-ontonotes_labels'
09/16 03:12:13 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 03:12:13 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 03:12:13 AM: 	Saved vocab to ./experiments/pos-ontonotes-sts-b-top/vocab
09/16 03:12:13 AM: Loading token dictionary from ./experiments/pos-ontonotes-sts-b-top/vocab.
09/16 03:12:13 AM: 	Loaded vocab from ./experiments/pos-ontonotes-sts-b-top/vocab
09/16 03:12:13 AM: 	Vocab namespace bert_uncased: size 30524
09/16 03:12:13 AM: 	Vocab namespace tokens: size 24015
09/16 03:12:13 AM: 	Vocab namespace edges-pos-ontonotes_labels: size 48
09/16 03:12:13 AM: 	Vocab namespace chars: size 81
09/16 03:12:13 AM: 	Finished building vocab.
09/16 03:12:13 AM: 	Task edges-pos-ontonotes (train): Indexing from scratch.
09/16 03:12:42 AM: 	Task edges-pos-ontonotes (train): Saved 110514 instances to ./experiments/pos-ontonotes-sts-b-top/preproc/edges-pos-ontonotes__train_data
09/16 03:12:42 AM: 	Task edges-pos-ontonotes (val): Indexing from scratch.
09/16 03:12:46 AM: 	Task edges-pos-ontonotes (val): Saved 15060 instances to ./experiments/pos-ontonotes-sts-b-top/preproc/edges-pos-ontonotes__val_data
09/16 03:12:46 AM: 	Task edges-pos-ontonotes (test): Indexing from scratch.
09/16 03:12:49 AM: 	Task edges-pos-ontonotes (test): Saved 11462 instances to ./experiments/pos-ontonotes-sts-b-top/preproc/edges-pos-ontonotes__test_data
09/16 03:12:49 AM: 	Finished indexing tasks
09/16 03:12:49 AM: 	Creating trimmed target-only version of edges-pos-ontonotes train.
09/16 03:12:49 AM: 	  Training on 
09/16 03:12:49 AM: 	  Evaluating on edges-pos-ontonotes
09/16 03:12:49 AM: 	Finished loading tasks in 70.481s
09/16 03:12:49 AM: 	 Tasks: ['edges-pos-ontonotes']
09/16 03:12:49 AM: Building model...
09/16 03:12:49 AM: Using BERT model (bert-base-uncased).
09/16 03:12:49 AM: LOADING A FUNETUNED MODEL from: 
09/16 03:12:49 AM: models/sts-b
09/16 03:12:49 AM: loading configuration file models/sts-b/config.json
09/16 03:12:49 AM: Model config {
=======
<<<<<<< HEAD
09/16 12:22:33 PM: Saved config to ./experiments/pos-ontonotes-sts-top/run/params.conf
09/16 12:22:33 PM: Using random seed 1234
09/16 12:22:33 PM: Using GPU 0
09/16 12:22:33 PM: Loading tasks...
09/16 12:22:33 PM: Writing pre-preprocessed tasks to ./experiments/pos-ontonotes-sts-top/
09/16 12:22:33 PM: 	Creating task edges-pos-ontonotes from scratch.
09/16 12:22:54 PM: Read=110514, Skip=5298, Total=115812 from ./probing_data/edges/ontonotes/const/pos/train.json.retokenized.bert-base-uncased
09/16 12:22:54 PM: Read=15060, Skip=620, Total=15680 from ./probing_data/edges/ontonotes/const/pos/development.json.retokenized.bert-base-uncased
09/16 12:22:58 PM: Read=11462, Skip=755, Total=12217 from ./probing_data/edges/ontonotes/const/pos/test.json.retokenized.bert-base-uncased
09/16 12:23:10 PM: 	Task 'edges-pos-ontonotes': |train|=110514 |val|=15060 |test|=11462
09/16 12:23:10 PM: 	Finished loading tasks: edges-pos-ontonotes.
09/16 12:23:10 PM: 	Building vocab from scratch.
09/16 12:23:10 PM: 	Counting units for task edges-pos-ontonotes.
09/16 12:23:13 PM: 	Task 'edges-pos-ontonotes': adding vocab namespace 'edges-pos-ontonotes_labels'
09/16 12:23:14 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:23:14 PM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 12:23:14 PM: 	Saved vocab to ./experiments/pos-ontonotes-sts-top/vocab
09/16 12:23:14 PM: Loading token dictionary from ./experiments/pos-ontonotes-sts-top/vocab.
09/16 12:23:14 PM: 	Loaded vocab from ./experiments/pos-ontonotes-sts-top/vocab
09/16 12:23:14 PM: 	Vocab namespace bert_uncased: size 30524
09/16 12:23:14 PM: 	Vocab namespace tokens: size 24015
09/16 12:23:14 PM: 	Vocab namespace edges-pos-ontonotes_labels: size 48
09/16 12:23:14 PM: 	Vocab namespace chars: size 81
09/16 12:23:14 PM: 	Finished building vocab.
09/16 12:23:14 PM: 	Task edges-pos-ontonotes (train): Indexing from scratch.
09/16 12:23:45 PM: 	Task edges-pos-ontonotes (train): Saved 110514 instances to ./experiments/pos-ontonotes-sts-top/preproc/edges-pos-ontonotes__train_data
09/16 12:23:45 PM: 	Task edges-pos-ontonotes (val): Indexing from scratch.
09/16 12:23:49 PM: 	Task edges-pos-ontonotes (val): Saved 15060 instances to ./experiments/pos-ontonotes-sts-top/preproc/edges-pos-ontonotes__val_data
09/16 12:23:49 PM: 	Task edges-pos-ontonotes (test): Indexing from scratch.
09/16 12:23:52 PM: 	Task edges-pos-ontonotes (test): Saved 11462 instances to ./experiments/pos-ontonotes-sts-top/preproc/edges-pos-ontonotes__test_data
09/16 12:23:52 PM: 	Finished indexing tasks
09/16 12:23:52 PM: 	Creating trimmed target-only version of edges-pos-ontonotes train.
09/16 12:23:52 PM: 	  Training on 
09/16 12:23:52 PM: 	  Evaluating on edges-pos-ontonotes
09/16 12:23:52 PM: 	Finished loading tasks in 78.594s
09/16 12:23:52 PM: 	 Tasks: ['edges-pos-ontonotes']
09/16 12:23:52 PM: Building model...
09/16 12:23:52 PM: Using BERT model (bert-base-uncased).
09/16 12:23:52 PM: LOADING A FUNETUNED MODEL from: 
09/16 12:23:52 PM: models/sts
09/16 12:23:52 PM: loading configuration file models/sts/config.json
09/16 12:23:52 PM: Model config {
=======
09/16 09:39:17 AM: Saved config to ./experiments/pos-ontonotes-sts-top/run/params.conf
09/16 09:39:17 AM: Using random seed 1234
09/16 09:39:18 AM: Using GPU 0
09/16 09:39:18 AM: Loading tasks...
09/16 09:39:18 AM: Writing pre-preprocessed tasks to ./experiments/pos-ontonotes-sts-top/
09/16 09:39:18 AM: 	Creating task edges-pos-ontonotes from scratch.
09/16 09:39:37 AM: Read=110514, Skip=5298, Total=115812 from ./probing_data/edges/ontonotes/const/pos/train.json.retokenized.bert-base-uncased
09/16 09:39:38 AM: Read=15060, Skip=620, Total=15680 from ./probing_data/edges/ontonotes/const/pos/development.json.retokenized.bert-base-uncased
09/16 09:39:41 AM: Read=11462, Skip=755, Total=12217 from ./probing_data/edges/ontonotes/const/pos/test.json.retokenized.bert-base-uncased
09/16 09:39:53 AM: 	Task 'edges-pos-ontonotes': |train|=110514 |val|=15060 |test|=11462
09/16 09:39:53 AM: 	Finished loading tasks: edges-pos-ontonotes.
09/16 09:39:53 AM: 	Building vocab from scratch.
09/16 09:39:53 AM: 	Counting units for task edges-pos-ontonotes.
09/16 09:39:56 AM: 	Task 'edges-pos-ontonotes': adding vocab namespace 'edges-pos-ontonotes_labels'
09/16 09:39:57 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:39:57 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 09:39:57 AM: 	Saved vocab to ./experiments/pos-ontonotes-sts-top/vocab
09/16 09:39:57 AM: Loading token dictionary from ./experiments/pos-ontonotes-sts-top/vocab.
09/16 09:39:57 AM: 	Loaded vocab from ./experiments/pos-ontonotes-sts-top/vocab
09/16 09:39:57 AM: 	Vocab namespace bert_uncased: size 30524
09/16 09:39:57 AM: 	Vocab namespace tokens: size 24015
09/16 09:39:57 AM: 	Vocab namespace chars: size 81
09/16 09:39:57 AM: 	Vocab namespace edges-pos-ontonotes_labels: size 48
09/16 09:39:57 AM: 	Finished building vocab.
09/16 09:39:57 AM: 	Task edges-pos-ontonotes (train): Indexing from scratch.
09/16 09:40:41 AM: 	Task edges-pos-ontonotes (train): Saved 110514 instances to ./experiments/pos-ontonotes-sts-top/preproc/edges-pos-ontonotes__train_data
09/16 09:40:41 AM: 	Task edges-pos-ontonotes (val): Indexing from scratch.
09/16 09:40:47 AM: 	Task edges-pos-ontonotes (val): Saved 15060 instances to ./experiments/pos-ontonotes-sts-top/preproc/edges-pos-ontonotes__val_data
09/16 09:40:47 AM: 	Task edges-pos-ontonotes (test): Indexing from scratch.
09/16 09:40:51 AM: 	Task edges-pos-ontonotes (test): Saved 11462 instances to ./experiments/pos-ontonotes-sts-top/preproc/edges-pos-ontonotes__test_data
09/16 09:40:51 AM: 	Finished indexing tasks
09/16 09:40:51 AM: 	Creating trimmed target-only version of edges-pos-ontonotes train.
09/16 09:40:51 AM: 	  Training on 
09/16 09:40:51 AM: 	  Evaluating on edges-pos-ontonotes
09/16 09:40:51 AM: 	Finished loading tasks in 93.758s
09/16 09:40:51 AM: 	 Tasks: ['edges-pos-ontonotes']
09/16 09:40:51 AM: Building model...
09/16 09:40:51 AM: Using BERT model (bert-base-uncased).
09/16 09:40:51 AM: LOADING A FUNETUNED MODEL from: 
09/16 09:40:51 AM: models/sts
09/16 09:40:51 AM: loading configuration file models/sts/config.json
09/16 09:40:51 AM: Model config {
>>>>>>> c9d1f3d70352f2e7d47f7ef89b434d6d01abf5d2
>>>>>>> 1ff7cb9943cafa999ead70f38407af315c736ff9
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "sts-b",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

<<<<<<< HEAD
09/16 03:12:49 AM: loading weights file models/sts-b/pytorch_model.bin
09/16 03:12:53 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp_0f4wqur
09/16 03:12:56 AM: copying /tmp/tmp_0f4wqur to cache at ./experiments/pos-ontonotes-sts-b-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 03:12:56 AM: creating metadata file for ./experiments/pos-ontonotes-sts-b-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 03:12:56 AM: removing temp file /tmp/tmp_0f4wqur
09/16 03:12:56 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/pos-ontonotes-sts-b-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 03:12:56 AM: Initializing parameters
09/16 03:12:56 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 03:12:56 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 03:12:56 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 03:12:56 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 03:12:56 AM: 	Task 'edges-pos-ontonotes' params: {
=======
<<<<<<< HEAD
09/16 12:23:52 PM: loading weights file models/sts/pytorch_model.bin
09/16 12:23:55 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp9kpfsccr
09/16 12:23:57 PM: copying /tmp/tmp9kpfsccr to cache at ./experiments/pos-ontonotes-sts-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:23:57 PM: creating metadata file for ./experiments/pos-ontonotes-sts-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:23:57 PM: removing temp file /tmp/tmp9kpfsccr
09/16 12:23:57 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/pos-ontonotes-sts-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:23:57 PM: Initializing parameters
09/16 12:23:57 PM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 12:23:57 PM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 12:23:57 PM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 12:23:57 PM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.pooler.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.pooler.dense.weight
09/16 12:23:57 PM: 	Task 'edges-pos-ontonotes' params: {
=======
09/16 09:40:51 AM: loading weights file models/sts/pytorch_model.bin
09/16 09:40:56 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp201m373h
09/16 09:41:00 AM: copying /tmp/tmp201m373h to cache at ./experiments/pos-ontonotes-sts-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:41:00 AM: creating metadata file for ./experiments/pos-ontonotes-sts-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:41:00 AM: removing temp file /tmp/tmp201m373h
09/16 09:41:00 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/pos-ontonotes-sts-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:41:00 AM: Initializing parameters
09/16 09:41:00 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 09:41:00 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 09:41:00 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 09:41:00 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 09:41:00 AM: 	Task 'edges-pos-ontonotes' params: {
>>>>>>> c9d1f3d70352f2e7d47f7ef89b434d6d01abf5d2
>>>>>>> 1ff7cb9943cafa999ead70f38407af315c736ff9
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-pos-ontonotes"
}
<<<<<<< HEAD
09/16 03:13:01 AM: Model specification:
09/16 03:13:01 AM: MultiTaskModel(
=======
<<<<<<< HEAD
09/16 12:24:02 PM: Model specification:
09/16 12:24:02 PM: MultiTaskModel(
>>>>>>> 1ff7cb9943cafa999ead70f38407af315c736ff9
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-pos-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=48, bias=True)
    )
  )
)
<<<<<<< HEAD
09/16 03:13:01 AM: Model parameters:
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	edges-pos-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 03:13:01 AM: 	edges-pos-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 03:13:01 AM: 	edges-pos-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 24576 with torch.Size([48, 512])
09/16 03:13:01 AM: 	edges-pos-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 48 with torch.Size([48])
09/16 03:13:01 AM: Total number of parameters: 109703728 (1.09704e+08)
09/16 03:13:01 AM: Number of trainable parameters: 221488 (221488)
09/16 03:13:01 AM: Finished building model in 11.360s
09/16 03:13:01 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-pos-ontonotes 

09/16 03:14:02 AM: patience = 9
09/16 03:14:02 AM: val_interval = 1000
09/16 03:14:02 AM: max_vals = 250
09/16 03:14:02 AM: cuda_device = 0
09/16 03:14:02 AM: grad_norm = 5.0
09/16 03:14:02 AM: grad_clipping = None
09/16 03:14:02 AM: lr_decay = 0.99
09/16 03:14:02 AM: min_lr = 1e-06
09/16 03:14:02 AM: keep_all_checkpoints = 0
09/16 03:14:02 AM: val_data_limit = 5000
09/16 03:14:02 AM: max_epochs = -1
09/16 03:14:02 AM: dec_val_scale = 250
09/16 03:14:02 AM: training_data_fraction = 1
09/16 03:14:02 AM: type = adam
09/16 03:14:02 AM: parameter_groups = None
09/16 03:14:02 AM: Number of trainable parameters: 221488
09/16 03:14:02 AM: infer_type_and_cast = True
09/16 03:14:02 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 03:14:02 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 03:14:02 AM: lr = 0.0001
09/16 03:14:02 AM: amsgrad = True
09/16 03:14:02 AM: type = reduce_on_plateau
09/16 03:14:02 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 03:14:02 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 03:14:02 AM: mode = max
09/16 03:14:02 AM: factor = 0.5
09/16 03:14:02 AM: patience = 3
09/16 03:14:02 AM: threshold = 0.0001
09/16 03:14:02 AM: threshold_mode = abs
09/16 03:14:02 AM: verbose = True
09/16 03:14:02 AM: type = adam
09/16 03:14:02 AM: parameter_groups = None
09/16 03:14:02 AM: Number of trainable parameters: 221488
09/16 03:14:02 AM: infer_type_and_cast = True
09/16 03:14:02 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 03:14:02 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 03:14:02 AM: lr = 0.0001
09/16 03:14:02 AM: amsgrad = True
09/16 03:14:02 AM: type = reduce_on_plateau
09/16 03:14:02 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 03:14:02 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 03:14:02 AM: mode = max
09/16 03:14:02 AM: factor = 0.5
09/16 03:14:02 AM: patience = 3
09/16 03:14:02 AM: threshold = 0.0001
09/16 03:14:02 AM: threshold_mode = abs
09/16 03:14:02 AM: verbose = True
09/16 03:14:02 AM: Starting training without restoring from a checkpoint.
09/16 03:14:02 AM: Training examples per task, before any subsampling: {'edges-pos-ontonotes': 110514}
09/16 03:14:02 AM: Beginning training with stopping criteria based on metric: edges-pos-ontonotes_f1
09/16 03:14:12 AM: Update 71: task edges-pos-ontonotes, batch 71 (71): mcc: 0.0102, acc: 0.0017, precision: 0.0255, recall: 0.1072, f1: 0.0412, edges-pos-ontonotes_loss: 0.3182
09/16 03:14:22 AM: Update 160: task edges-pos-ontonotes, batch 160 (160): mcc: 0.0069, acc: 0.0010, precision: 0.0256, recall: 0.0495, f1: 0.0338, edges-pos-ontonotes_loss: 0.1894
09/16 03:14:32 AM: Update 242: task edges-pos-ontonotes, batch 242 (242): mcc: 0.0091, acc: 0.0047, precision: 0.0287, recall: 0.0361, f1: 0.0320, edges-pos-ontonotes_loss: 0.1517
09/16 03:14:42 AM: Update 314: task edges-pos-ontonotes, batch 314 (314): mcc: 0.0203, acc: 0.0159, precision: 0.0409, recall: 0.0401, f1: 0.0405, edges-pos-ontonotes_loss: 0.1340
09/16 03:14:53 AM: Update 382: task edges-pos-ontonotes, batch 382 (382): mcc: 0.0247, acc: 0.0184, precision: 0.0486, recall: 0.0371, f1: 0.0421, edges-pos-ontonotes_loss: 0.1235
09/16 03:15:03 AM: Update 457: task edges-pos-ontonotes, batch 457 (457): mcc: 0.0335, acc: 0.0239, precision: 0.0624, recall: 0.0392, f1: 0.0482, edges-pos-ontonotes_loss: 0.1146
09/16 03:15:13 AM: Update 523: task edges-pos-ontonotes, batch 523 (523): mcc: 0.0446, acc: 0.0303, precision: 0.0803, recall: 0.0436, f1: 0.0566, edges-pos-ontonotes_loss: 0.1085
09/16 03:15:23 AM: Update 593: task edges-pos-ontonotes, batch 593 (593): mcc: 0.0605, acc: 0.0396, precision: 0.1063, recall: 0.0516, f1: 0.0695, edges-pos-ontonotes_loss: 0.1030
09/16 03:15:33 AM: Update 641: task edges-pos-ontonotes, batch 641 (641): mcc: 0.0770, acc: 0.0492, precision: 0.1333, recall: 0.0606, f1: 0.0833, edges-pos-ontonotes_loss: 0.0998
09/16 03:15:44 AM: Update 692: task edges-pos-ontonotes, batch 692 (692): mcc: 0.1009, acc: 0.0629, precision: 0.1732, recall: 0.0738, f1: 0.1035, edges-pos-ontonotes_loss: 0.0968
09/16 03:15:54 AM: Update 743: task edges-pos-ontonotes, batch 743 (743): mcc: 0.1257, acc: 0.0771, precision: 0.2149, recall: 0.0876, f1: 0.1244, edges-pos-ontonotes_loss: 0.0941
09/16 03:16:04 AM: Update 804: task edges-pos-ontonotes, batch 804 (804): mcc: 0.1513, acc: 0.0920, precision: 0.2578, recall: 0.1021, f1: 0.1463, edges-pos-ontonotes_loss: 0.0912
09/16 03:16:14 AM: Update 863: task edges-pos-ontonotes, batch 863 (863): mcc: 0.1747, acc: 0.1056, precision: 0.2967, recall: 0.1155, f1: 0.1663, edges-pos-ontonotes_loss: 0.0885
09/16 03:16:24 AM: Update 911: task edges-pos-ontonotes, batch 911 (911): mcc: 0.1995, acc: 0.1206, precision: 0.3371, recall: 0.1303, f1: 0.1880, edges-pos-ontonotes_loss: 0.0865
09/16 03:16:34 AM: Update 951: task edges-pos-ontonotes, batch 951 (951): mcc: 0.2169, acc: 0.1310, precision: 0.3654, recall: 0.1407, f1: 0.2031, edges-pos-ontonotes_loss: 0.0849
09/16 03:16:44 AM: ***** Step 1000 / Validation 1 *****
09/16 03:16:44 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:16:44 AM: Validating...
09/16 03:16:44 AM: Evaluate: task edges-pos-ontonotes, batch 2 (157): mcc: 0.6384, acc: 0.4359, precision: 0.9387, recall: 0.4403, f1: 0.5994, edges-pos-ontonotes_loss: 0.0405
09/16 03:16:54 AM: Evaluate: task edges-pos-ontonotes, batch 68 (157): mcc: 0.5412, acc: 0.3102, precision: 0.9496, recall: 0.3135, f1: 0.4714, edges-pos-ontonotes_loss: 0.0479
09/16 03:17:05 AM: Evaluate: task edges-pos-ontonotes, batch 117 (157): mcc: 0.5781, acc: 0.3586, precision: 0.9336, recall: 0.3638, f1: 0.5235, edges-pos-ontonotes_loss: 0.0457
09/16 03:17:13 AM: Best result seen so far for edges-pos-ontonotes.
09/16 03:17:13 AM: Best result seen so far for micro.
09/16 03:17:13 AM: Best result seen so far for macro.
09/16 03:17:13 AM: Updating LR scheduler:
09/16 03:17:13 AM: 	Best result seen so far for macro_avg: 0.541
09/16 03:17:13 AM: 	# validation passes without improvement: 0
09/16 03:17:13 AM: edges-pos-ontonotes_loss: training: 0.083116 validation: 0.045122
09/16 03:17:13 AM: macro_avg: validation: 0.540954
09/16 03:17:13 AM: micro_avg: validation: 0.000000
09/16 03:17:13 AM: edges-pos-ontonotes_mcc: training: 0.238055 validation: 0.590688
09/16 03:17:13 AM: edges-pos-ontonotes_acc: training: 0.143936 validation: 0.375303
09/16 03:17:13 AM: edges-pos-ontonotes_precision: training: 0.398862 validation: 0.928831
09/16 03:17:13 AM: edges-pos-ontonotes_recall: training: 0.153633 validation: 0.381599
09/16 03:17:13 AM: edges-pos-ontonotes_f1: training: 0.221824 validation: 0.540954
09/16 03:17:13 AM: Global learning rate: 0.0001
09/16 03:17:13 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:17:15 AM: Update 1005: task edges-pos-ontonotes, batch 5 (1005): mcc: 0.5525, acc: 0.3364, precision: 0.9022, recall: 0.3444, f1: 0.4985, edges-pos-ontonotes_loss: 0.0470
09/16 03:17:25 AM: Update 1058: task edges-pos-ontonotes, batch 58 (1058): mcc: 0.5761, acc: 0.3630, precision: 0.9064, recall: 0.3723, f1: 0.5278, edges-pos-ontonotes_loss: 0.0461
09/16 03:17:35 AM: Update 1110: task edges-pos-ontonotes, batch 110 (1110): mcc: 0.5895, acc: 0.3792, precision: 0.9071, recall: 0.3894, f1: 0.5449, edges-pos-ontonotes_loss: 0.0449
09/16 03:17:45 AM: Update 1162: task edges-pos-ontonotes, batch 162 (1162): mcc: 0.5986, acc: 0.3909, precision: 0.9076, recall: 0.4013, f1: 0.5565, edges-pos-ontonotes_loss: 0.0440
09/16 03:17:55 AM: Update 1216: task edges-pos-ontonotes, batch 216 (1216): mcc: 0.6082, acc: 0.4030, precision: 0.9085, recall: 0.4136, f1: 0.5684, edges-pos-ontonotes_loss: 0.0432
09/16 03:18:12 AM: Update 1253: task edges-pos-ontonotes, batch 253 (1253): mcc: 0.6142, acc: 0.4108, precision: 0.9090, recall: 0.4215, f1: 0.5760, edges-pos-ontonotes_loss: 0.0427
09/16 03:18:22 AM: Update 1308: task edges-pos-ontonotes, batch 308 (1308): mcc: 0.6205, acc: 0.4189, precision: 0.9096, recall: 0.4298, f1: 0.5838, edges-pos-ontonotes_loss: 0.0420
09/16 03:18:32 AM: Update 1362: task edges-pos-ontonotes, batch 362 (1362): mcc: 0.6276, acc: 0.4283, precision: 0.9099, recall: 0.4395, f1: 0.5927, edges-pos-ontonotes_loss: 0.0413
09/16 03:18:43 AM: Update 1417: task edges-pos-ontonotes, batch 417 (1417): mcc: 0.6348, acc: 0.4376, precision: 0.9105, recall: 0.4492, f1: 0.6016, edges-pos-ontonotes_loss: 0.0406
09/16 03:18:53 AM: Update 1465: task edges-pos-ontonotes, batch 465 (1465): mcc: 0.6419, acc: 0.4471, precision: 0.9105, recall: 0.4592, f1: 0.6105, edges-pos-ontonotes_loss: 0.0400
09/16 03:19:03 AM: Update 1519: task edges-pos-ontonotes, batch 519 (1519): mcc: 0.6484, acc: 0.4557, precision: 0.9109, recall: 0.4682, f1: 0.6185, edges-pos-ontonotes_loss: 0.0394
09/16 03:19:13 AM: Update 1566: task edges-pos-ontonotes, batch 566 (1566): mcc: 0.6530, acc: 0.4622, precision: 0.9110, recall: 0.4748, f1: 0.6243, edges-pos-ontonotes_loss: 0.0389
09/16 03:19:24 AM: Update 1614: task edges-pos-ontonotes, batch 614 (1614): mcc: 0.6582, acc: 0.4692, precision: 0.9110, recall: 0.4823, f1: 0.6307, edges-pos-ontonotes_loss: 0.0384
09/16 03:19:34 AM: Update 1662: task edges-pos-ontonotes, batch 662 (1662): mcc: 0.6636, acc: 0.4768, precision: 0.9109, recall: 0.4903, f1: 0.6375, edges-pos-ontonotes_loss: 0.0379
09/16 03:19:44 AM: Update 1715: task edges-pos-ontonotes, batch 715 (1715): mcc: 0.6689, acc: 0.4841, precision: 0.9109, recall: 0.4981, f1: 0.6440, edges-pos-ontonotes_loss: 0.0374
09/16 03:19:54 AM: Update 1769: task edges-pos-ontonotes, batch 769 (1769): mcc: 0.6738, acc: 0.4909, precision: 0.9106, recall: 0.5054, f1: 0.6500, edges-pos-ontonotes_loss: 0.0369
09/16 03:20:04 AM: Update 1824: task edges-pos-ontonotes, batch 824 (1824): mcc: 0.6783, acc: 0.4972, precision: 0.9105, recall: 0.5121, f1: 0.6555, edges-pos-ontonotes_loss: 0.0365
09/16 03:20:14 AM: Update 1872: task edges-pos-ontonotes, batch 872 (1872): mcc: 0.6830, acc: 0.5039, precision: 0.9105, recall: 0.5192, f1: 0.6613, edges-pos-ontonotes_loss: 0.0360
09/16 03:20:24 AM: Update 1911: task edges-pos-ontonotes, batch 911 (1911): mcc: 0.6862, acc: 0.5086, precision: 0.9098, recall: 0.5244, f1: 0.6653, edges-pos-ontonotes_loss: 0.0358
09/16 03:20:34 AM: Update 1974: task edges-pos-ontonotes, batch 974 (1974): mcc: 0.6898, acc: 0.5139, precision: 0.9093, recall: 0.5302, f1: 0.6698, edges-pos-ontonotes_loss: 0.0354
09/16 03:20:38 AM: ***** Step 2000 / Validation 2 *****
09/16 03:20:38 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:20:38 AM: Validating...
09/16 03:20:44 AM: Evaluate: task edges-pos-ontonotes, batch 37 (157): mcc: 0.7276, acc: 0.5698, precision: 0.9210, recall: 0.5815, f1: 0.7129, edges-pos-ontonotes_loss: 0.0319
09/16 03:20:54 AM: Evaluate: task edges-pos-ontonotes, batch 98 (157): mcc: 0.7607, acc: 0.6227, precision: 0.9152, recall: 0.6389, f1: 0.7525, edges-pos-ontonotes_loss: 0.0298
09/16 03:21:05 AM: Evaluate: task edges-pos-ontonotes, batch 142 (157): mcc: 0.7795, acc: 0.6526, precision: 0.9093, recall: 0.6747, f1: 0.7746, edges-pos-ontonotes_loss: 0.0283
09/16 03:21:08 AM: Best result seen so far for edges-pos-ontonotes.
09/16 03:21:08 AM: Best result seen so far for macro.
09/16 03:21:08 AM: Updating LR scheduler:
09/16 03:21:08 AM: 	Best result seen so far for macro_avg: 0.779
09/16 03:21:08 AM: 	# validation passes without improvement: 0
09/16 03:21:08 AM: edges-pos-ontonotes_loss: training: 0.035201 validation: 0.027865
09/16 03:21:08 AM: macro_avg: validation: 0.778787
09/16 03:21:08 AM: micro_avg: validation: 0.000000
09/16 03:21:08 AM: edges-pos-ontonotes_mcc: training: 0.691180 validation: 0.783251
09/16 03:21:08 AM: edges-pos-ontonotes_acc: training: 0.515858 validation: 0.658084
09/16 03:21:08 AM: edges-pos-ontonotes_precision: training: 0.909249 validation: 0.909942
09/16 03:21:08 AM: edges-pos-ontonotes_recall: training: 0.532305 validation: 0.680678
09/16 03:21:08 AM: edges-pos-ontonotes_f1: training: 0.671494 validation: 0.778787
09/16 03:21:08 AM: Global learning rate: 0.0001
09/16 03:21:08 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:21:15 AM: Update 2046: task edges-pos-ontonotes, batch 46 (2046): mcc: 0.7630, acc: 0.6231, precision: 0.9104, recall: 0.6461, f1: 0.7558, edges-pos-ontonotes_loss: 0.0289
09/16 03:21:25 AM: Update 2106: task edges-pos-ontonotes, batch 106 (2106): mcc: 0.7657, acc: 0.6281, precision: 0.9060, recall: 0.6538, f1: 0.7595, edges-pos-ontonotes_loss: 0.0282
09/16 03:21:35 AM: Update 2165: task edges-pos-ontonotes, batch 165 (2165): mcc: 0.7704, acc: 0.6352, precision: 0.9059, recall: 0.6619, f1: 0.7649, edges-pos-ontonotes_loss: 0.0277
09/16 03:21:45 AM: Update 2224: task edges-pos-ontonotes, batch 224 (2224): mcc: 0.7713, acc: 0.6364, precision: 0.9066, recall: 0.6629, f1: 0.7658, edges-pos-ontonotes_loss: 0.0274
09/16 03:21:55 AM: Update 2301: task edges-pos-ontonotes, batch 301 (2301): mcc: 0.7741, acc: 0.6394, precision: 0.9100, recall: 0.6651, f1: 0.7685, edges-pos-ontonotes_loss: 0.0269
09/16 03:22:05 AM: Update 2378: task edges-pos-ontonotes, batch 378 (2378): mcc: 0.7775, acc: 0.6437, precision: 0.9122, recall: 0.6691, f1: 0.7720, edges-pos-ontonotes_loss: 0.0264
09/16 03:22:15 AM: Update 2457: task edges-pos-ontonotes, batch 457 (2457): mcc: 0.7811, acc: 0.6484, precision: 0.9142, recall: 0.6737, f1: 0.7758, edges-pos-ontonotes_loss: 0.0259
09/16 03:22:26 AM: Update 2527: task edges-pos-ontonotes, batch 527 (2527): mcc: 0.7836, acc: 0.6519, precision: 0.9154, recall: 0.6772, f1: 0.7785, edges-pos-ontonotes_loss: 0.0257
09/16 03:22:36 AM: Update 2624: task edges-pos-ontonotes, batch 624 (2624): mcc: 0.7863, acc: 0.6555, precision: 0.9172, recall: 0.6804, f1: 0.7812, edges-pos-ontonotes_loss: 0.0257
09/16 03:22:46 AM: Update 2730: task edges-pos-ontonotes, batch 730 (2730): mcc: 0.7892, acc: 0.6598, precision: 0.9182, recall: 0.6846, f1: 0.7844, edges-pos-ontonotes_loss: 0.0254
09/16 03:22:56 AM: Update 2819: task edges-pos-ontonotes, batch 819 (2819): mcc: 0.7920, acc: 0.6641, precision: 0.9188, recall: 0.6890, f1: 0.7875, edges-pos-ontonotes_loss: 0.0251
09/16 03:23:06 AM: Update 2933: task edges-pos-ontonotes, batch 933 (2933): mcc: 0.7902, acc: 0.6616, precision: 0.9176, recall: 0.6869, f1: 0.7856, edges-pos-ontonotes_loss: 0.0253
09/16 03:23:12 AM: ***** Step 3000 / Validation 3 *****
09/16 03:23:12 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:23:12 AM: Validating...
09/16 03:23:16 AM: Evaluate: task edges-pos-ontonotes, batch 23 (157): mcc: 0.8092, acc: 0.7003, precision: 0.9042, recall: 0.7305, f1: 0.8081, edges-pos-ontonotes_loss: 0.0230
09/16 03:23:26 AM: Evaluate: task edges-pos-ontonotes, batch 79 (157): mcc: 0.8247, acc: 0.7217, precision: 0.9087, recall: 0.7544, f1: 0.8244, edges-pos-ontonotes_loss: 0.0218
09/16 03:23:36 AM: Evaluate: task edges-pos-ontonotes, batch 126 (157): mcc: 0.8282, acc: 0.7295, precision: 0.8957, recall: 0.7719, f1: 0.8292, edges-pos-ontonotes_loss: 0.0218
09/16 03:23:43 AM: Best result seen so far for edges-pos-ontonotes.
09/16 03:23:43 AM: Best result seen so far for macro.
09/16 03:23:43 AM: Updating LR scheduler:
09/16 03:23:43 AM: 	Best result seen so far for macro_avg: 0.832
09/16 03:23:43 AM: 	# validation passes without improvement: 0
09/16 03:23:43 AM: edges-pos-ontonotes_loss: training: 0.025215 validation: 0.021723
09/16 03:23:43 AM: macro_avg: validation: 0.832484
09/16 03:23:43 AM: micro_avg: validation: 0.000000
09/16 03:23:43 AM: edges-pos-ontonotes_mcc: training: 0.789768 validation: 0.831127
09/16 03:23:43 AM: edges-pos-ontonotes_acc: training: 0.661002 validation: 0.734743
09/16 03:23:43 AM: edges-pos-ontonotes_precision: training: 0.917022 validation: 0.892592
09/16 03:23:43 AM: edges-pos-ontonotes_recall: training: 0.686452 validation: 0.779961
09/16 03:23:43 AM: edges-pos-ontonotes_f1: training: 0.785160 validation: 0.832484
09/16 03:23:43 AM: Global learning rate: 0.0001
09/16 03:23:43 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:23:46 AM: Update 3035: task edges-pos-ontonotes, batch 35 (3035): mcc: 0.7817, acc: 0.6530, precision: 0.8995, recall: 0.6860, f1: 0.7784, edges-pos-ontonotes_loss: 0.0253
09/16 03:23:57 AM: Update 3131: task edges-pos-ontonotes, batch 131 (3131): mcc: 0.7874, acc: 0.6608, precision: 0.9006, recall: 0.6950, f1: 0.7846, edges-pos-ontonotes_loss: 0.0242
09/16 03:24:07 AM: Update 3183: task edges-pos-ontonotes, batch 183 (3183): mcc: 0.7865, acc: 0.6620, precision: 0.8909, recall: 0.7012, f1: 0.7847, edges-pos-ontonotes_loss: 0.0247
09/16 03:24:17 AM: Update 3236: task edges-pos-ontonotes, batch 236 (3236): mcc: 0.7861, acc: 0.6619, precision: 0.8896, recall: 0.7015, f1: 0.7844, edges-pos-ontonotes_loss: 0.0251
09/16 03:24:27 AM: Update 3292: task edges-pos-ontonotes, batch 292 (3292): mcc: 0.7873, acc: 0.6640, precision: 0.8897, recall: 0.7035, f1: 0.7857, edges-pos-ontonotes_loss: 0.0253
09/16 03:24:37 AM: Update 3349: task edges-pos-ontonotes, batch 349 (3349): mcc: 0.7878, acc: 0.6650, precision: 0.8897, recall: 0.7045, f1: 0.7863, edges-pos-ontonotes_loss: 0.0254
09/16 03:24:47 AM: Update 3411: task edges-pos-ontonotes, batch 411 (3411): mcc: 0.7890, acc: 0.6668, precision: 0.8905, recall: 0.7059, f1: 0.7875, edges-pos-ontonotes_loss: 0.0252
09/16 03:25:05 AM: Update 3461: task edges-pos-ontonotes, batch 461 (3461): mcc: 0.7891, acc: 0.6671, precision: 0.8907, recall: 0.7059, f1: 0.7876, edges-pos-ontonotes_loss: 0.0251
09/16 03:25:15 AM: Update 3551: task edges-pos-ontonotes, batch 551 (3551): mcc: 0.7895, acc: 0.6670, precision: 0.8933, recall: 0.7044, f1: 0.7877, edges-pos-ontonotes_loss: 0.0249
09/16 03:25:25 AM: Update 3638: task edges-pos-ontonotes, batch 638 (3638): mcc: 0.7906, acc: 0.6684, precision: 0.8949, recall: 0.7052, f1: 0.7888, edges-pos-ontonotes_loss: 0.0245
09/16 03:25:35 AM: Update 3718: task edges-pos-ontonotes, batch 718 (3718): mcc: 0.7918, acc: 0.6698, precision: 0.8960, recall: 0.7063, f1: 0.7899, edges-pos-ontonotes_loss: 0.0242
09/16 03:25:45 AM: Update 3790: task edges-pos-ontonotes, batch 790 (3790): mcc: 0.7935, acc: 0.6724, precision: 0.8966, recall: 0.7089, f1: 0.7918, edges-pos-ontonotes_loss: 0.0239
09/16 03:25:55 AM: Update 3855: task edges-pos-ontonotes, batch 855 (3855): mcc: 0.7958, acc: 0.6760, precision: 0.8969, recall: 0.7127, f1: 0.7943, edges-pos-ontonotes_loss: 0.0237
09/16 03:26:06 AM: Update 3922: task edges-pos-ontonotes, batch 922 (3922): mcc: 0.7980, acc: 0.6794, precision: 0.8971, recall: 0.7164, f1: 0.7966, edges-pos-ontonotes_loss: 0.0235
09/16 03:26:16 AM: ***** Step 4000 / Validation 4 *****
09/16 03:26:16 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:26:16 AM: Validating...
09/16 03:26:16 AM: Evaluate: task edges-pos-ontonotes, batch 1 (157): mcc: 0.8590, acc: 0.7717, precision: 0.9393, recall: 0.7905, f1: 0.8585, edges-pos-ontonotes_loss: 0.0166
09/16 03:26:26 AM: Evaluate: task edges-pos-ontonotes, batch 65 (157): mcc: 0.8552, acc: 0.7662, precision: 0.9351, recall: 0.7870, f1: 0.8547, edges-pos-ontonotes_loss: 0.0176
09/16 03:26:36 AM: Evaluate: task edges-pos-ontonotes, batch 113 (157): mcc: 0.8593, acc: 0.7753, precision: 0.9254, recall: 0.8029, f1: 0.8598, edges-pos-ontonotes_loss: 0.0173
09/16 03:26:46 AM: Evaluate: task edges-pos-ontonotes, batch 155 (157): mcc: 0.8591, acc: 0.7765, precision: 0.9188, recall: 0.8083, f1: 0.8600, edges-pos-ontonotes_loss: 0.0175
09/16 03:26:46 AM: Best result seen so far for edges-pos-ontonotes.
09/16 03:26:46 AM: Best result seen so far for macro.
09/16 03:26:46 AM: Updating LR scheduler:
09/16 03:26:46 AM: 	Best result seen so far for macro_avg: 0.860
09/16 03:26:46 AM: 	# validation passes without improvement: 0
09/16 03:26:46 AM: edges-pos-ontonotes_loss: training: 0.023207 validation: 0.017472
09/16 03:26:46 AM: macro_avg: validation: 0.860186
09/16 03:26:46 AM: micro_avg: validation: 0.000000
09/16 03:26:46 AM: edges-pos-ontonotes_mcc: training: 0.799741 validation: 0.859237
09/16 03:26:46 AM: edges-pos-ontonotes_acc: training: 0.682009 validation: 0.776638
09/16 03:26:46 AM: edges-pos-ontonotes_precision: training: 0.897423 validation: 0.918984
09/16 03:26:46 AM: edges-pos-ontonotes_recall: training: 0.719197 validation: 0.808460
09/16 03:26:46 AM: edges-pos-ontonotes_f1: training: 0.798486 validation: 0.860186
09/16 03:26:46 AM: Global learning rate: 0.0001
09/16 03:26:46 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:26:56 AM: Update 4062: task edges-pos-ontonotes, batch 62 (4062): mcc: 0.8237, acc: 0.7184, precision: 0.9023, recall: 0.7580, f1: 0.8239, edges-pos-ontonotes_loss: 0.0203
09/16 03:27:06 AM: Update 4108: task edges-pos-ontonotes, batch 108 (4108): mcc: 0.8212, acc: 0.7166, precision: 0.8981, recall: 0.7570, f1: 0.8215, edges-pos-ontonotes_loss: 0.0207
09/16 03:27:17 AM: Update 4163: task edges-pos-ontonotes, batch 163 (4163): mcc: 0.8183, acc: 0.7136, precision: 0.8945, recall: 0.7548, f1: 0.8187, edges-pos-ontonotes_loss: 0.0213
09/16 03:27:27 AM: Update 4220: task edges-pos-ontonotes, batch 220 (4220): mcc: 0.8188, acc: 0.7144, precision: 0.8953, recall: 0.7551, f1: 0.8192, edges-pos-ontonotes_loss: 0.0214
09/16 03:27:37 AM: Update 4278: task edges-pos-ontonotes, batch 278 (4278): mcc: 0.8196, acc: 0.7154, precision: 0.8959, recall: 0.7560, f1: 0.8200, edges-pos-ontonotes_loss: 0.0213
09/16 03:27:47 AM: Update 4334: task edges-pos-ontonotes, batch 334 (4334): mcc: 0.8198, acc: 0.7157, precision: 0.8958, recall: 0.7565, f1: 0.8202, edges-pos-ontonotes_loss: 0.0213
09/16 03:27:57 AM: Update 4384: task edges-pos-ontonotes, batch 384 (4384): mcc: 0.8203, acc: 0.7165, precision: 0.8964, recall: 0.7569, f1: 0.8208, edges-pos-ontonotes_loss: 0.0212
09/16 03:28:07 AM: Update 4423: task edges-pos-ontonotes, batch 423 (4423): mcc: 0.8202, acc: 0.7162, precision: 0.8956, recall: 0.7573, f1: 0.8207, edges-pos-ontonotes_loss: 0.0212
09/16 03:28:17 AM: Update 4478: task edges-pos-ontonotes, batch 478 (4478): mcc: 0.8209, acc: 0.7173, precision: 0.8957, recall: 0.7586, f1: 0.8215, edges-pos-ontonotes_loss: 0.0211
09/16 03:28:27 AM: Update 4527: task edges-pos-ontonotes, batch 527 (4527): mcc: 0.8220, acc: 0.7189, precision: 0.8962, recall: 0.7601, f1: 0.8225, edges-pos-ontonotes_loss: 0.0210
09/16 03:28:37 AM: Update 4578: task edges-pos-ontonotes, batch 578 (4578): mcc: 0.8228, acc: 0.7203, precision: 0.8965, recall: 0.7612, f1: 0.8234, edges-pos-ontonotes_loss: 0.0209
09/16 03:28:48 AM: Update 4630: task edges-pos-ontonotes, batch 630 (4630): mcc: 0.8240, acc: 0.7220, precision: 0.8974, recall: 0.7626, f1: 0.8246, edges-pos-ontonotes_loss: 0.0208
09/16 03:28:58 AM: Update 4679: task edges-pos-ontonotes, batch 679 (4679): mcc: 0.8249, acc: 0.7235, precision: 0.8981, recall: 0.7638, f1: 0.8255, edges-pos-ontonotes_loss: 0.0207
09/16 03:29:08 AM: Update 4719: task edges-pos-ontonotes, batch 719 (4719): mcc: 0.8251, acc: 0.7239, precision: 0.8984, recall: 0.7640, f1: 0.8257, edges-pos-ontonotes_loss: 0.0206
09/16 03:29:18 AM: Update 4767: task edges-pos-ontonotes, batch 767 (4767): mcc: 0.8259, acc: 0.7251, precision: 0.8988, recall: 0.7649, f1: 0.8265, edges-pos-ontonotes_loss: 0.0206
09/16 03:29:28 AM: Update 4817: task edges-pos-ontonotes, batch 817 (4817): mcc: 0.8267, acc: 0.7265, precision: 0.8996, recall: 0.7658, f1: 0.8273, edges-pos-ontonotes_loss: 0.0205
09/16 03:29:38 AM: Update 4868: task edges-pos-ontonotes, batch 868 (4868): mcc: 0.8276, acc: 0.7277, precision: 0.9002, recall: 0.7668, f1: 0.8282, edges-pos-ontonotes_loss: 0.0204
09/16 03:29:49 AM: Update 4924: task edges-pos-ontonotes, batch 924 (4924): mcc: 0.8283, acc: 0.7288, precision: 0.9006, recall: 0.7677, f1: 0.8289, edges-pos-ontonotes_loss: 0.0203
09/16 03:29:59 AM: Update 4976: task edges-pos-ontonotes, batch 976 (4976): mcc: 0.8290, acc: 0.7300, precision: 0.9010, recall: 0.7688, f1: 0.8297, edges-pos-ontonotes_loss: 0.0202
09/16 03:30:04 AM: ***** Step 5000 / Validation 5 *****
09/16 03:30:04 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:30:04 AM: Validating...
09/16 03:30:09 AM: Evaluate: task edges-pos-ontonotes, batch 28 (157): mcc: 0.8547, acc: 0.7682, precision: 0.9358, recall: 0.7857, f1: 0.8542, edges-pos-ontonotes_loss: 0.0171
09/16 03:30:19 AM: Evaluate: task edges-pos-ontonotes, batch 89 (157): mcc: 0.8649, acc: 0.7828, precision: 0.9365, recall: 0.8035, f1: 0.8649, edges-pos-ontonotes_loss: 0.0163
09/16 03:30:29 AM: Evaluate: task edges-pos-ontonotes, batch 133 (157): mcc: 0.8691, acc: 0.7919, precision: 0.9300, recall: 0.8169, f1: 0.8698, edges-pos-ontonotes_loss: 0.0160
09/16 03:30:34 AM: Best result seen so far for edges-pos-ontonotes.
09/16 03:30:34 AM: Best result seen so far for macro.
09/16 03:30:34 AM: Updating LR scheduler:
09/16 03:30:34 AM: 	Best result seen so far for macro_avg: 0.873
09/16 03:30:34 AM: 	# validation passes without improvement: 0
09/16 03:30:34 AM: edges-pos-ontonotes_loss: training: 0.020192 validation: 0.015696
09/16 03:30:34 AM: macro_avg: validation: 0.872713
09/16 03:30:34 AM: micro_avg: validation: 0.000000
09/16 03:30:34 AM: edges-pos-ontonotes_mcc: training: 0.829430 validation: 0.871893
09/16 03:30:34 AM: edges-pos-ontonotes_acc: training: 0.730639 validation: 0.797009
09/16 03:30:34 AM: edges-pos-ontonotes_precision: training: 0.901242 validation: 0.929939
09/16 03:30:34 AM: edges-pos-ontonotes_recall: training: 0.769301 validation: 0.822121
09/16 03:30:34 AM: edges-pos-ontonotes_f1: training: 0.830061 validation: 0.872713
09/16 03:30:34 AM: Global learning rate: 0.0001
09/16 03:30:34 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:30:49 AM: Update 5026: task edges-pos-ontonotes, batch 26 (5026): mcc: 0.8416, acc: 0.7494, precision: 0.9078, recall: 0.7858, f1: 0.8424, edges-pos-ontonotes_loss: 0.0184
09/16 03:30:59 AM: Update 5086: task edges-pos-ontonotes, batch 86 (5086): mcc: 0.8408, acc: 0.7484, precision: 0.9084, recall: 0.7839, f1: 0.8416, edges-pos-ontonotes_loss: 0.0190
09/16 03:31:09 AM: Update 5139: task edges-pos-ontonotes, batch 139 (5139): mcc: 0.8418, acc: 0.7497, precision: 0.9087, recall: 0.7855, f1: 0.8426, edges-pos-ontonotes_loss: 0.0189
09/16 03:31:19 AM: Update 5194: task edges-pos-ontonotes, batch 194 (5194): mcc: 0.8426, acc: 0.7511, precision: 0.9087, recall: 0.7869, f1: 0.8434, edges-pos-ontonotes_loss: 0.0188
09/16 03:31:29 AM: Update 5246: task edges-pos-ontonotes, batch 246 (5246): mcc: 0.8433, acc: 0.7524, precision: 0.9088, recall: 0.7881, f1: 0.8441, edges-pos-ontonotes_loss: 0.0187
09/16 03:31:39 AM: Update 5297: task edges-pos-ontonotes, batch 297 (5297): mcc: 0.8439, acc: 0.7534, precision: 0.9089, recall: 0.7891, f1: 0.8448, edges-pos-ontonotes_loss: 0.0186
09/16 03:31:50 AM: Update 5339: task edges-pos-ontonotes, batch 339 (5339): mcc: 0.8442, acc: 0.7536, precision: 0.9091, recall: 0.7894, f1: 0.8451, edges-pos-ontonotes_loss: 0.0186
09/16 03:32:00 AM: Update 5399: task edges-pos-ontonotes, batch 399 (5399): mcc: 0.8449, acc: 0.7547, precision: 0.9094, recall: 0.7906, f1: 0.8458, edges-pos-ontonotes_loss: 0.0184
09/16 03:32:10 AM: Update 5462: task edges-pos-ontonotes, batch 462 (5462): mcc: 0.8454, acc: 0.7554, precision: 0.9097, recall: 0.7913, f1: 0.8463, edges-pos-ontonotes_loss: 0.0182
09/16 03:32:20 AM: Update 5527: task edges-pos-ontonotes, batch 527 (5527): mcc: 0.8464, acc: 0.7566, precision: 0.9106, recall: 0.7923, f1: 0.8473, edges-pos-ontonotes_loss: 0.0180
09/16 03:32:31 AM: Update 5583: task edges-pos-ontonotes, batch 583 (5583): mcc: 0.8469, acc: 0.7572, precision: 0.9106, recall: 0.7930, f1: 0.8478, edges-pos-ontonotes_loss: 0.0178
09/16 03:32:41 AM: Update 5633: task edges-pos-ontonotes, batch 633 (5633): mcc: 0.8471, acc: 0.7576, precision: 0.9105, recall: 0.7936, f1: 0.8480, edges-pos-ontonotes_loss: 0.0178
09/16 03:32:51 AM: Update 5694: task edges-pos-ontonotes, batch 694 (5694): mcc: 0.8482, acc: 0.7589, precision: 0.9115, recall: 0.7947, f1: 0.8491, edges-pos-ontonotes_loss: 0.0176
09/16 03:33:01 AM: Update 5777: task edges-pos-ontonotes, batch 777 (5777): mcc: 0.8502, acc: 0.7615, precision: 0.9132, recall: 0.7969, f1: 0.8511, edges-pos-ontonotes_loss: 0.0173
09/16 03:33:11 AM: Update 5865: task edges-pos-ontonotes, batch 865 (5865): mcc: 0.8522, acc: 0.7641, precision: 0.9147, recall: 0.7992, f1: 0.8531, edges-pos-ontonotes_loss: 0.0170
09/16 03:33:21 AM: Update 5948: task edges-pos-ontonotes, batch 948 (5948): mcc: 0.8539, acc: 0.7665, precision: 0.9160, recall: 0.8014, f1: 0.8548, edges-pos-ontonotes_loss: 0.0167
09/16 03:33:28 AM: ***** Step 6000 / Validation 6 *****
09/16 03:33:28 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:33:28 AM: Validating...
09/16 03:33:31 AM: Evaluate: task edges-pos-ontonotes, batch 20 (157): mcc: 0.8582, acc: 0.7770, precision: 0.9314, recall: 0.7957, f1: 0.8582, edges-pos-ontonotes_loss: 0.0163
09/16 03:33:41 AM: Evaluate: task edges-pos-ontonotes, batch 84 (157): mcc: 0.8729, acc: 0.7968, precision: 0.9353, recall: 0.8193, f1: 0.8735, edges-pos-ontonotes_loss: 0.0152
09/16 03:33:51 AM: Evaluate: task edges-pos-ontonotes, batch 129 (157): mcc: 0.8743, acc: 0.8007, precision: 0.9301, recall: 0.8264, f1: 0.8752, edges-pos-ontonotes_loss: 0.0150
09/16 03:33:57 AM: Best result seen so far for edges-pos-ontonotes.
09/16 03:33:57 AM: Best result seen so far for macro.
09/16 03:33:57 AM: Updating LR scheduler:
09/16 03:33:57 AM: 	Best result seen so far for macro_avg: 0.878
09/16 03:33:57 AM: 	# validation passes without improvement: 0
09/16 03:33:57 AM: edges-pos-ontonotes_loss: training: 0.016698 validation: 0.014800
09/16 03:33:57 AM: macro_avg: validation: 0.877837
09/16 03:33:57 AM: micro_avg: validation: 0.000000
09/16 03:33:57 AM: edges-pos-ontonotes_mcc: training: 0.854583 validation: 0.876797
09/16 03:33:57 AM: edges-pos-ontonotes_acc: training: 0.767355 validation: 0.805528
09/16 03:33:57 AM: edges-pos-ontonotes_precision: training: 0.916587 validation: 0.929515
09/16 03:33:57 AM: edges-pos-ontonotes_recall: training: 0.801995 validation: 0.831603
09/16 03:33:57 AM: edges-pos-ontonotes_f1: training: 0.855471 validation: 0.877837
09/16 03:33:57 AM: Global learning rate: 0.0001
09/16 03:33:57 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:34:01 AM: Update 6041: task edges-pos-ontonotes, batch 41 (6041): mcc: 0.8742, acc: 0.7948, precision: 0.9328, recall: 0.8239, f1: 0.8750, edges-pos-ontonotes_loss: 0.0159
09/16 03:34:11 AM: Update 6140: task edges-pos-ontonotes, batch 140 (6140): mcc: 0.8732, acc: 0.7922, precision: 0.9338, recall: 0.8210, f1: 0.8738, edges-pos-ontonotes_loss: 0.0154
09/16 03:34:21 AM: Update 6234: task edges-pos-ontonotes, batch 234 (6234): mcc: 0.8760, acc: 0.7965, precision: 0.9337, recall: 0.8265, f1: 0.8768, edges-pos-ontonotes_loss: 0.0151
09/16 03:34:31 AM: Update 6334: task edges-pos-ontonotes, batch 334 (6334): mcc: 0.8709, acc: 0.7888, precision: 0.9304, recall: 0.8198, f1: 0.8716, edges-pos-ontonotes_loss: 0.0157
09/16 03:34:41 AM: Update 6452: task edges-pos-ontonotes, batch 452 (6452): mcc: 0.8631, acc: 0.7775, precision: 0.9254, recall: 0.8100, f1: 0.8639, edges-pos-ontonotes_loss: 0.0164
09/16 03:34:51 AM: Update 6584: task edges-pos-ontonotes, batch 584 (6584): mcc: 0.8601, acc: 0.7729, precision: 0.9236, recall: 0.8060, f1: 0.8608, edges-pos-ontonotes_loss: 0.0166
09/16 03:35:02 AM: Update 6635: task edges-pos-ontonotes, batch 635 (6635): mcc: 0.8556, acc: 0.7667, precision: 0.9185, recall: 0.8022, f1: 0.8564, edges-pos-ontonotes_loss: 0.0170
09/16 03:35:12 AM: Update 6696: task edges-pos-ontonotes, batch 696 (6696): mcc: 0.8521, acc: 0.7619, precision: 0.9148, recall: 0.7990, f1: 0.8530, edges-pos-ontonotes_loss: 0.0172
09/16 03:35:22 AM: Update 6746: task edges-pos-ontonotes, batch 746 (6746): mcc: 0.8490, acc: 0.7581, precision: 0.9112, recall: 0.7964, f1: 0.8500, edges-pos-ontonotes_loss: 0.0174
09/16 03:35:32 AM: Update 6799: task edges-pos-ontonotes, batch 799 (6799): mcc: 0.8475, acc: 0.7561, precision: 0.9097, recall: 0.7950, f1: 0.8485, edges-pos-ontonotes_loss: 0.0175
09/16 03:35:42 AM: Update 6854: task edges-pos-ontonotes, batch 854 (6854): mcc: 0.8462, acc: 0.7544, precision: 0.9084, recall: 0.7937, f1: 0.8472, edges-pos-ontonotes_loss: 0.0176
09/16 03:35:52 AM: Update 6908: task edges-pos-ontonotes, batch 908 (6908): mcc: 0.8452, acc: 0.7532, precision: 0.9076, recall: 0.7927, f1: 0.8463, edges-pos-ontonotes_loss: 0.0177
09/16 03:36:02 AM: Update 6975: task edges-pos-ontonotes, batch 975 (6975): mcc: 0.8444, acc: 0.7519, precision: 0.9075, recall: 0.7912, f1: 0.8454, edges-pos-ontonotes_loss: 0.0178
09/16 03:36:06 AM: ***** Step 7000 / Validation 7 *****
09/16 03:36:06 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:36:06 AM: Validating...
09/16 03:36:12 AM: Evaluate: task edges-pos-ontonotes, batch 42 (157): mcc: 0.8804, acc: 0.8096, precision: 0.9358, recall: 0.8326, f1: 0.8812, edges-pos-ontonotes_loss: 0.0147
09/16 03:36:22 AM: Evaluate: task edges-pos-ontonotes, batch 100 (157): mcc: 0.8902, acc: 0.8261, precision: 0.9324, recall: 0.8541, f1: 0.8915, edges-pos-ontonotes_loss: 0.0137
09/16 03:36:33 AM: Evaluate: task edges-pos-ontonotes, batch 140 (157): mcc: 0.8884, acc: 0.8243, precision: 0.9245, recall: 0.8580, f1: 0.8900, edges-pos-ontonotes_loss: 0.0138
09/16 03:36:37 AM: Best result seen so far for edges-pos-ontonotes.
09/16 03:36:37 AM: Best result seen so far for macro.
09/16 03:36:37 AM: Updating LR scheduler:
09/16 03:36:37 AM: 	Best result seen so far for macro_avg: 0.891
09/16 03:36:37 AM: 	# validation passes without improvement: 0
09/16 03:36:37 AM: edges-pos-ontonotes_loss: training: 0.017812 validation: 0.013749
09/16 03:36:37 AM: macro_avg: validation: 0.890744
09/16 03:36:37 AM: micro_avg: validation: 0.000000
09/16 03:36:37 AM: edges-pos-ontonotes_mcc: training: 0.844242 validation: 0.889096
09/16 03:36:37 AM: edges-pos-ontonotes_acc: training: 0.751569 validation: 0.826079
09/16 03:36:37 AM: edges-pos-ontonotes_precision: training: 0.907578 validation: 0.923772
09/16 03:36:37 AM: edges-pos-ontonotes_recall: training: 0.790897 validation: 0.859996
09/16 03:36:37 AM: edges-pos-ontonotes_f1: training: 0.845230 validation: 0.890744
09/16 03:36:37 AM: Global learning rate: 0.0001
09/16 03:36:37 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:36:43 AM: Update 7044: task edges-pos-ontonotes, batch 44 (7044): mcc: 0.8452, acc: 0.7514, precision: 0.9155, recall: 0.7857, f1: 0.8456, edges-pos-ontonotes_loss: 0.0168
09/16 03:36:53 AM: Update 7125: task edges-pos-ontonotes, batch 125 (7125): mcc: 0.8443, acc: 0.7497, precision: 0.9155, recall: 0.7842, f1: 0.8448, edges-pos-ontonotes_loss: 0.0170
09/16 03:37:03 AM: Update 7212: task edges-pos-ontonotes, batch 212 (7212): mcc: 0.8444, acc: 0.7498, precision: 0.9149, recall: 0.7848, f1: 0.8448, edges-pos-ontonotes_loss: 0.0170
09/16 03:37:13 AM: Update 7271: task edges-pos-ontonotes, batch 271 (7271): mcc: 0.8468, acc: 0.7542, precision: 0.9118, recall: 0.7919, f1: 0.8476, edges-pos-ontonotes_loss: 0.0170
09/16 03:37:23 AM: Update 7335: task edges-pos-ontonotes, batch 335 (7335): mcc: 0.8487, acc: 0.7573, precision: 0.9102, recall: 0.7967, f1: 0.8497, edges-pos-ontonotes_loss: 0.0169
09/16 03:37:33 AM: Update 7403: task edges-pos-ontonotes, batch 403 (7403): mcc: 0.8494, acc: 0.7588, precision: 0.9093, recall: 0.7988, f1: 0.8505, edges-pos-ontonotes_loss: 0.0169
09/16 03:37:43 AM: Update 7471: task edges-pos-ontonotes, batch 471 (7471): mcc: 0.8502, acc: 0.7602, precision: 0.9088, recall: 0.8007, f1: 0.8514, edges-pos-ontonotes_loss: 0.0168
09/16 03:37:53 AM: Update 7546: task edges-pos-ontonotes, batch 546 (7546): mcc: 0.8513, acc: 0.7621, precision: 0.9090, recall: 0.8028, f1: 0.8526, edges-pos-ontonotes_loss: 0.0167
09/16 03:38:03 AM: Update 7547: task edges-pos-ontonotes, batch 547 (7547): mcc: 0.8509, acc: 0.7616, precision: 0.9086, recall: 0.8023, f1: 0.8522, edges-pos-ontonotes_loss: 0.0168
09/16 03:38:13 AM: Update 7597: task edges-pos-ontonotes, batch 597 (7597): mcc: 0.8494, acc: 0.7599, precision: 0.9063, recall: 0.8016, f1: 0.8507, edges-pos-ontonotes_loss: 0.0169
09/16 03:38:23 AM: Update 7650: task edges-pos-ontonotes, batch 650 (7650): mcc: 0.8491, acc: 0.7597, precision: 0.9053, recall: 0.8018, f1: 0.8504, edges-pos-ontonotes_loss: 0.0170
09/16 03:38:34 AM: Update 7705: task edges-pos-ontonotes, batch 705 (7705): mcc: 0.8486, acc: 0.7592, precision: 0.9045, recall: 0.8016, f1: 0.8499, edges-pos-ontonotes_loss: 0.0171
09/16 03:38:44 AM: Update 7768: task edges-pos-ontonotes, batch 768 (7768): mcc: 0.8490, acc: 0.7600, precision: 0.9048, recall: 0.8022, f1: 0.8504, edges-pos-ontonotes_loss: 0.0171
09/16 03:38:54 AM: Update 7820: task edges-pos-ontonotes, batch 820 (7820): mcc: 0.8491, acc: 0.7602, precision: 0.9045, recall: 0.8026, f1: 0.8505, edges-pos-ontonotes_loss: 0.0171
09/16 03:39:04 AM: Update 7861: task edges-pos-ontonotes, batch 861 (7861): mcc: 0.8489, acc: 0.7601, precision: 0.9042, recall: 0.8026, f1: 0.8504, edges-pos-ontonotes_loss: 0.0172
09/16 03:39:14 AM: Update 7907: task edges-pos-ontonotes, batch 907 (7907): mcc: 0.8489, acc: 0.7601, precision: 0.9037, recall: 0.8029, f1: 0.8503, edges-pos-ontonotes_loss: 0.0172
09/16 03:39:24 AM: Update 7957: task edges-pos-ontonotes, batch 957 (7957): mcc: 0.8494, acc: 0.7611, precision: 0.9039, recall: 0.8038, f1: 0.8509, edges-pos-ontonotes_loss: 0.0172
09/16 03:39:32 AM: ***** Step 8000 / Validation 8 *****
09/16 03:39:32 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:39:32 AM: Validating...
09/16 03:39:34 AM: Evaluate: task edges-pos-ontonotes, batch 12 (157): mcc: 0.8820, acc: 0.8165, precision: 0.9338, recall: 0.8374, f1: 0.8830, edges-pos-ontonotes_loss: 0.0138
09/16 03:39:44 AM: Evaluate: task edges-pos-ontonotes, batch 78 (157): mcc: 0.8909, acc: 0.8249, precision: 0.9439, recall: 0.8449, f1: 0.8917, edges-pos-ontonotes_loss: 0.0132
09/16 03:39:54 AM: Evaluate: task edges-pos-ontonotes, batch 127 (157): mcc: 0.8925, acc: 0.8290, precision: 0.9390, recall: 0.8524, f1: 0.8936, edges-pos-ontonotes_loss: 0.0130
09/16 03:40:01 AM: Best result seen so far for edges-pos-ontonotes.
09/16 03:40:01 AM: Best result seen so far for macro.
09/16 03:40:01 AM: Updating LR scheduler:
09/16 03:40:01 AM: 	Best result seen so far for macro_avg: 0.895
09/16 03:40:01 AM: 	# validation passes without improvement: 0
09/16 03:40:01 AM: edges-pos-ontonotes_loss: training: 0.017128 validation: 0.012827
09/16 03:40:01 AM: macro_avg: validation: 0.895145
09/16 03:40:01 AM: micro_avg: validation: 0.000000
09/16 03:40:01 AM: edges-pos-ontonotes_mcc: training: 0.849813 validation: 0.893939
09/16 03:40:01 AM: edges-pos-ontonotes_acc: training: 0.761693 validation: 0.832619
09/16 03:40:01 AM: edges-pos-ontonotes_precision: training: 0.903978 validation: 0.936869
09/16 03:40:01 AM: edges-pos-ontonotes_recall: training: 0.804398 validation: 0.856980
09/16 03:40:01 AM: edges-pos-ontonotes_f1: training: 0.851286 validation: 0.895145
09/16 03:40:01 AM: Global learning rate: 0.0001
09/16 03:40:01 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:40:04 AM: Update 8018: task edges-pos-ontonotes, batch 18 (8018): mcc: 0.8521, acc: 0.7665, precision: 0.9052, recall: 0.8076, f1: 0.8536, edges-pos-ontonotes_loss: 0.0171
09/16 03:40:14 AM: Update 8071: task edges-pos-ontonotes, batch 71 (8071): mcc: 0.8573, acc: 0.7749, precision: 0.9078, recall: 0.8148, f1: 0.8588, edges-pos-ontonotes_loss: 0.0167
09/16 03:40:24 AM: Update 8118: task edges-pos-ontonotes, batch 118 (8118): mcc: 0.8573, acc: 0.7757, precision: 0.9070, recall: 0.8157, f1: 0.8589, edges-pos-ontonotes_loss: 0.0166
09/16 03:40:35 AM: Update 8171: task edges-pos-ontonotes, batch 171 (8171): mcc: 0.8579, acc: 0.7763, precision: 0.9072, recall: 0.8165, f1: 0.8594, edges-pos-ontonotes_loss: 0.0166
09/16 03:40:45 AM: Update 8208: task edges-pos-ontonotes, batch 208 (8208): mcc: 0.8565, acc: 0.7744, precision: 0.9065, recall: 0.8146, f1: 0.8581, edges-pos-ontonotes_loss: 0.0167
09/16 03:40:55 AM: Update 8259: task edges-pos-ontonotes, batch 259 (8259): mcc: 0.8565, acc: 0.7744, precision: 0.9064, recall: 0.8147, f1: 0.8581, edges-pos-ontonotes_loss: 0.0168
09/16 03:41:05 AM: Update 8314: task edges-pos-ontonotes, batch 314 (8314): mcc: 0.8573, acc: 0.7754, precision: 0.9072, recall: 0.8154, f1: 0.8589, edges-pos-ontonotes_loss: 0.0168
09/16 03:41:15 AM: Update 8369: task edges-pos-ontonotes, batch 369 (8369): mcc: 0.8578, acc: 0.7761, precision: 0.9077, recall: 0.8159, f1: 0.8593, edges-pos-ontonotes_loss: 0.0167
09/16 03:41:25 AM: Update 8423: task edges-pos-ontonotes, batch 423 (8423): mcc: 0.8585, acc: 0.7772, precision: 0.9082, recall: 0.8168, f1: 0.8601, edges-pos-ontonotes_loss: 0.0166
09/16 03:41:35 AM: Update 8478: task edges-pos-ontonotes, batch 478 (8478): mcc: 0.8593, acc: 0.7783, precision: 0.9087, recall: 0.8177, f1: 0.8608, edges-pos-ontonotes_loss: 0.0166
09/16 03:41:45 AM: Update 8516: task edges-pos-ontonotes, batch 516 (8516): mcc: 0.8593, acc: 0.7784, precision: 0.9088, recall: 0.8177, f1: 0.8609, edges-pos-ontonotes_loss: 0.0166
09/16 03:41:55 AM: Update 8571: task edges-pos-ontonotes, batch 571 (8571): mcc: 0.8596, acc: 0.7787, precision: 0.9089, recall: 0.8181, f1: 0.8611, edges-pos-ontonotes_loss: 0.0165
09/16 03:42:06 AM: Update 8623: task edges-pos-ontonotes, batch 623 (8623): mcc: 0.8602, acc: 0.7796, precision: 0.9094, recall: 0.8189, f1: 0.8618, edges-pos-ontonotes_loss: 0.0165
09/16 03:42:16 AM: Update 8673: task edges-pos-ontonotes, batch 673 (8673): mcc: 0.8606, acc: 0.7802, precision: 0.9096, recall: 0.8193, f1: 0.8621, edges-pos-ontonotes_loss: 0.0165
09/16 03:42:26 AM: Update 8726: task edges-pos-ontonotes, batch 726 (8726): mcc: 0.8610, acc: 0.7808, precision: 0.9101, recall: 0.8197, f1: 0.8625, edges-pos-ontonotes_loss: 0.0164
09/16 03:42:36 AM: Update 8776: task edges-pos-ontonotes, batch 776 (8776): mcc: 0.8611, acc: 0.7810, precision: 0.9101, recall: 0.8199, f1: 0.8626, edges-pos-ontonotes_loss: 0.0165
09/16 03:42:46 AM: Update 8819: task edges-pos-ontonotes, batch 819 (8819): mcc: 0.8610, acc: 0.7809, precision: 0.9100, recall: 0.8198, f1: 0.8625, edges-pos-ontonotes_loss: 0.0164
09/16 03:42:56 AM: Update 8875: task edges-pos-ontonotes, batch 875 (8875): mcc: 0.8613, acc: 0.7813, precision: 0.9100, recall: 0.8204, f1: 0.8629, edges-pos-ontonotes_loss: 0.0163
09/16 03:43:06 AM: Update 8941: task edges-pos-ontonotes, batch 941 (8941): mcc: 0.8617, acc: 0.7818, precision: 0.9104, recall: 0.8207, f1: 0.8633, edges-pos-ontonotes_loss: 0.0162
09/16 03:43:16 AM: Update 9000: task edges-pos-ontonotes, batch 1000 (9000): mcc: 0.8619, acc: 0.7820, precision: 0.9105, recall: 0.8211, f1: 0.8635, edges-pos-ontonotes_loss: 0.0161
09/16 03:43:16 AM: ***** Step 9000 / Validation 9 *****
09/16 03:43:16 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:43:16 AM: Validating...
09/16 03:43:26 AM: Evaluate: task edges-pos-ontonotes, batch 69 (157): mcc: 0.8887, acc: 0.8217, precision: 0.9422, recall: 0.8423, f1: 0.8895, edges-pos-ontonotes_loss: 0.0135
09/16 03:43:37 AM: Evaluate: task edges-pos-ontonotes, batch 119 (157): mcc: 0.8939, acc: 0.8317, precision: 0.9387, recall: 0.8553, f1: 0.8950, edges-pos-ontonotes_loss: 0.0128
09/16 03:43:45 AM: Best result seen so far for edges-pos-ontonotes.
09/16 03:43:45 AM: Best result seen so far for macro.
09/16 03:43:45 AM: Updating LR scheduler:
09/16 03:43:45 AM: 	Best result seen so far for macro_avg: 0.898
09/16 03:43:45 AM: 	# validation passes without improvement: 0
09/16 03:43:45 AM: edges-pos-ontonotes_loss: training: 0.016066 validation: 0.012561
09/16 03:43:45 AM: macro_avg: validation: 0.898091
09/16 03:43:45 AM: micro_avg: validation: 0.000000
09/16 03:43:45 AM: edges-pos-ontonotes_mcc: training: 0.861928 validation: 0.896812
09/16 03:43:45 AM: edges-pos-ontonotes_acc: training: 0.782027 validation: 0.837550
09/16 03:43:45 AM: edges-pos-ontonotes_precision: training: 0.910465 validation: 0.936792
09/16 03:43:45 AM: edges-pos-ontonotes_recall: training: 0.821116 validation: 0.862461
09/16 03:43:45 AM: edges-pos-ontonotes_f1: training: 0.863485 validation: 0.898091
09/16 03:43:45 AM: Global learning rate: 0.0001
09/16 03:43:45 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:43:47 AM: Update 9010: task edges-pos-ontonotes, batch 10 (9010): mcc: 0.8767, acc: 0.8005, precision: 0.9218, recall: 0.8384, f1: 0.8781, edges-pos-ontonotes_loss: 0.0139
09/16 03:43:57 AM: Update 9077: task edges-pos-ontonotes, batch 77 (9077): mcc: 0.8701, acc: 0.7917, precision: 0.9157, recall: 0.8317, f1: 0.8717, edges-pos-ontonotes_loss: 0.0142
09/16 03:44:12 AM: Update 9112: task edges-pos-ontonotes, batch 112 (9112): mcc: 0.8697, acc: 0.7914, precision: 0.9155, recall: 0.8312, f1: 0.8713, edges-pos-ontonotes_loss: 0.0142
09/16 03:44:22 AM: Update 9200: task edges-pos-ontonotes, batch 200 (9200): mcc: 0.8779, acc: 0.8020, precision: 0.9228, recall: 0.8398, f1: 0.8794, edges-pos-ontonotes_loss: 0.0136
09/16 03:44:32 AM: Update 9285: task edges-pos-ontonotes, batch 285 (9285): mcc: 0.8824, acc: 0.8080, precision: 0.9266, recall: 0.8448, f1: 0.8838, edges-pos-ontonotes_loss: 0.0132
09/16 03:44:42 AM: Update 9370: task edges-pos-ontonotes, batch 370 (9370): mcc: 0.8857, acc: 0.8127, precision: 0.9290, recall: 0.8487, f1: 0.8870, edges-pos-ontonotes_loss: 0.0130
09/16 03:44:52 AM: Update 9444: task edges-pos-ontonotes, batch 444 (9444): mcc: 0.8863, acc: 0.8135, precision: 0.9299, recall: 0.8490, f1: 0.8876, edges-pos-ontonotes_loss: 0.0130
09/16 03:45:02 AM: Update 9536: task edges-pos-ontonotes, batch 536 (9536): mcc: 0.8866, acc: 0.8140, precision: 0.9307, recall: 0.8489, f1: 0.8879, edges-pos-ontonotes_loss: 0.0130
09/16 03:45:12 AM: Update 9626: task edges-pos-ontonotes, batch 626 (9626): mcc: 0.8869, acc: 0.8146, precision: 0.9313, recall: 0.8490, f1: 0.8882, edges-pos-ontonotes_loss: 0.0131
09/16 03:45:22 AM: Update 9718: task edges-pos-ontonotes, batch 718 (9718): mcc: 0.8874, acc: 0.8153, precision: 0.9319, recall: 0.8492, f1: 0.8886, edges-pos-ontonotes_loss: 0.0130
09/16 03:45:32 AM: Update 9817: task edges-pos-ontonotes, batch 817 (9817): mcc: 0.8855, acc: 0.8125, precision: 0.9310, recall: 0.8465, f1: 0.8867, edges-pos-ontonotes_loss: 0.0134
09/16 03:45:42 AM: Update 9942: task edges-pos-ontonotes, batch 942 (9942): mcc: 0.8834, acc: 0.8093, precision: 0.9298, recall: 0.8438, f1: 0.8847, edges-pos-ontonotes_loss: 0.0138
09/16 03:45:47 AM: ***** Step 10000 / Validation 10 *****
09/16 03:45:47 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:45:47 AM: Validating...
09/16 03:45:52 AM: Evaluate: task edges-pos-ontonotes, batch 37 (157): mcc: 0.8875, acc: 0.8208, precision: 0.9370, recall: 0.8447, f1: 0.8885, edges-pos-ontonotes_loss: 0.0134
09/16 03:46:02 AM: Evaluate: task edges-pos-ontonotes, batch 91 (157): mcc: 0.8955, acc: 0.8346, precision: 0.9358, recall: 0.8609, f1: 0.8968, edges-pos-ontonotes_loss: 0.0126
09/16 03:46:13 AM: Evaluate: task edges-pos-ontonotes, batch 132 (157): mcc: 0.8941, acc: 0.8337, precision: 0.9263, recall: 0.8671, f1: 0.8957, edges-pos-ontonotes_loss: 0.0127
09/16 03:46:18 AM: Updating LR scheduler:
09/16 03:46:18 AM: 	Best result seen so far for macro_avg: 0.898
09/16 03:46:18 AM: 	# validation passes without improvement: 1
09/16 03:46:18 AM: edges-pos-ontonotes_loss: training: 0.013870 validation: 0.012632
09/16 03:46:18 AM: macro_avg: validation: 0.897114
09/16 03:46:18 AM: micro_avg: validation: 0.000000
09/16 03:46:18 AM: edges-pos-ontonotes_mcc: training: 0.882301 validation: 0.895417
09/16 03:46:18 AM: edges-pos-ontonotes_acc: training: 0.807624 validation: 0.836736
09/16 03:46:18 AM: edges-pos-ontonotes_precision: training: 0.929090 validation: 0.925043
09/16 03:46:18 AM: edges-pos-ontonotes_recall: training: 0.842267 validation: 0.870821
09/16 03:46:18 AM: edges-pos-ontonotes_f1: training: 0.883551 validation: 0.897114
09/16 03:46:18 AM: Global learning rate: 0.0001
09/16 03:46:18 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:46:23 AM: Update 10039: task edges-pos-ontonotes, batch 39 (10039): mcc: 0.8569, acc: 0.7699, precision: 0.9110, recall: 0.8113, f1: 0.8582, edges-pos-ontonotes_loss: 0.0166
09/16 03:46:33 AM: Update 10083: task edges-pos-ontonotes, batch 83 (10083): mcc: 0.8476, acc: 0.7597, precision: 0.8968, recall: 0.8068, f1: 0.8494, edges-pos-ontonotes_loss: 0.0172
09/16 03:46:43 AM: Update 10143: task edges-pos-ontonotes, batch 143 (10143): mcc: 0.8471, acc: 0.7580, precision: 0.8957, recall: 0.8068, f1: 0.8490, edges-pos-ontonotes_loss: 0.0175
09/16 03:46:53 AM: Update 10202: task edges-pos-ontonotes, batch 202 (10202): mcc: 0.8482, acc: 0.7591, precision: 0.8973, recall: 0.8074, f1: 0.8500, edges-pos-ontonotes_loss: 0.0175
09/16 03:47:03 AM: Update 10263: task edges-pos-ontonotes, batch 263 (10263): mcc: 0.8486, acc: 0.7597, precision: 0.8977, recall: 0.8078, f1: 0.8504, edges-pos-ontonotes_loss: 0.0176
09/16 03:47:13 AM: Update 10321: task edges-pos-ontonotes, batch 321 (10321): mcc: 0.8492, acc: 0.7608, precision: 0.8982, recall: 0.8084, f1: 0.8509, edges-pos-ontonotes_loss: 0.0176
09/16 03:47:23 AM: Update 10376: task edges-pos-ontonotes, batch 376 (10376): mcc: 0.8493, acc: 0.7611, precision: 0.8988, recall: 0.8082, f1: 0.8511, edges-pos-ontonotes_loss: 0.0176
09/16 03:47:34 AM: Update 10443: task edges-pos-ontonotes, batch 443 (10443): mcc: 0.8496, acc: 0.7612, precision: 0.9005, recall: 0.8071, f1: 0.8512, edges-pos-ontonotes_loss: 0.0174
09/16 03:47:44 AM: Update 10526: task edges-pos-ontonotes, batch 526 (10526): mcc: 0.8500, acc: 0.7616, precision: 0.9020, recall: 0.8065, f1: 0.8516, edges-pos-ontonotes_loss: 0.0173
09/16 03:47:54 AM: Update 10601: task edges-pos-ontonotes, batch 601 (10601): mcc: 0.8507, acc: 0.7624, precision: 0.9032, recall: 0.8067, f1: 0.8522, edges-pos-ontonotes_loss: 0.0171
09/16 03:48:05 AM: Update 10694: task edges-pos-ontonotes, batch 694 (10694): mcc: 0.8514, acc: 0.7634, precision: 0.9043, recall: 0.8072, f1: 0.8530, edges-pos-ontonotes_loss: 0.0169
09/16 03:48:15 AM: Update 10757: task edges-pos-ontonotes, batch 757 (10757): mcc: 0.8525, acc: 0.7651, precision: 0.9044, recall: 0.8091, f1: 0.8541, edges-pos-ontonotes_loss: 0.0168
09/16 03:48:26 AM: Update 10827: task edges-pos-ontonotes, batch 827 (10827): mcc: 0.8536, acc: 0.7667, precision: 0.9047, recall: 0.8109, f1: 0.8552, edges-pos-ontonotes_loss: 0.0166
09/16 03:48:36 AM: Update 10895: task edges-pos-ontonotes, batch 895 (10895): mcc: 0.8547, acc: 0.7682, precision: 0.9051, recall: 0.8124, f1: 0.8563, edges-pos-ontonotes_loss: 0.0165
09/16 03:48:46 AM: Update 10965: task edges-pos-ontonotes, batch 965 (10965): mcc: 0.8554, acc: 0.7693, precision: 0.9054, recall: 0.8136, f1: 0.8570, edges-pos-ontonotes_loss: 0.0164
09/16 03:48:51 AM: ***** Step 11000 / Validation 11 *****
09/16 03:48:51 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:48:51 AM: Validating...
09/16 03:48:56 AM: Evaluate: task edges-pos-ontonotes, batch 36 (157): mcc: 0.8942, acc: 0.8321, precision: 0.9422, recall: 0.8526, f1: 0.8951, edges-pos-ontonotes_loss: 0.0126
09/16 03:49:06 AM: Evaluate: task edges-pos-ontonotes, batch 93 (157): mcc: 0.9035, acc: 0.8464, precision: 0.9426, recall: 0.8698, f1: 0.9047, edges-pos-ontonotes_loss: 0.0117
09/16 03:49:16 AM: Evaluate: task edges-pos-ontonotes, batch 132 (157): mcc: 0.9021, acc: 0.8451, precision: 0.9370, recall: 0.8723, f1: 0.9035, edges-pos-ontonotes_loss: 0.0118
09/16 03:49:22 AM: Best result seen so far for edges-pos-ontonotes.
09/16 03:49:22 AM: Best result seen so far for macro.
09/16 03:49:22 AM: Updating LR scheduler:
09/16 03:49:22 AM: 	Best result seen so far for macro_avg: 0.904
09/16 03:49:22 AM: 	# validation passes without improvement: 0
09/16 03:49:22 AM: edges-pos-ontonotes_loss: training: 0.016349 validation: 0.011793
09/16 03:49:22 AM: macro_avg: validation: 0.904040
09/16 03:49:22 AM: micro_avg: validation: 0.000000
09/16 03:49:22 AM: edges-pos-ontonotes_mcc: training: 0.855801 validation: 0.902604
09/16 03:49:22 AM: edges-pos-ontonotes_acc: training: 0.769832 validation: 0.847032
09/16 03:49:22 AM: edges-pos-ontonotes_precision: training: 0.905653 validation: 0.935604
09/16 03:49:22 AM: edges-pos-ontonotes_recall: training: 0.814038 validation: 0.874536
09/16 03:49:22 AM: edges-pos-ontonotes_f1: training: 0.857405 validation: 0.904040
09/16 03:49:22 AM: Global learning rate: 0.0001
09/16 03:49:22 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:49:27 AM: Update 11011: task edges-pos-ontonotes, batch 11 (11011): mcc: 0.8428, acc: 0.7561, precision: 0.8894, recall: 0.8045, f1: 0.8449, edges-pos-ontonotes_loss: 0.0170
09/16 03:49:37 AM: Update 11066: task edges-pos-ontonotes, batch 66 (11066): mcc: 0.8547, acc: 0.7704, precision: 0.8995, recall: 0.8175, f1: 0.8566, edges-pos-ontonotes_loss: 0.0170
09/16 03:49:47 AM: Update 11119: task edges-pos-ontonotes, batch 119 (11119): mcc: 0.8567, acc: 0.7730, precision: 0.8998, recall: 0.8210, f1: 0.8586, edges-pos-ontonotes_loss: 0.0169
09/16 03:49:57 AM: Update 11171: task edges-pos-ontonotes, batch 171 (11171): mcc: 0.8567, acc: 0.7732, precision: 0.8993, recall: 0.8215, f1: 0.8586, edges-pos-ontonotes_loss: 0.0168
09/16 03:50:07 AM: Update 11225: task edges-pos-ontonotes, batch 225 (11225): mcc: 0.8567, acc: 0.7736, precision: 0.8993, recall: 0.8217, f1: 0.8587, edges-pos-ontonotes_loss: 0.0168
09/16 03:50:17 AM: Update 11282: task edges-pos-ontonotes, batch 282 (11282): mcc: 0.8574, acc: 0.7746, precision: 0.9001, recall: 0.8221, f1: 0.8593, edges-pos-ontonotes_loss: 0.0166
09/16 03:50:34 AM: Update 11320: task edges-pos-ontonotes, batch 320 (11320): mcc: 0.8570, acc: 0.7740, precision: 0.9002, recall: 0.8212, f1: 0.8589, edges-pos-ontonotes_loss: 0.0166
09/16 03:50:44 AM: Update 11373: task edges-pos-ontonotes, batch 373 (11373): mcc: 0.8579, acc: 0.7754, precision: 0.9007, recall: 0.8225, f1: 0.8598, edges-pos-ontonotes_loss: 0.0166
09/16 03:50:54 AM: Update 11426: task edges-pos-ontonotes, batch 426 (11426): mcc: 0.8589, acc: 0.7769, precision: 0.9017, recall: 0.8235, f1: 0.8608, edges-pos-ontonotes_loss: 0.0165
09/16 03:51:05 AM: Update 11475: task edges-pos-ontonotes, batch 475 (11475): mcc: 0.8595, acc: 0.7777, precision: 0.9022, recall: 0.8242, f1: 0.8614, edges-pos-ontonotes_loss: 0.0164
09/16 03:51:15 AM: Update 11528: task edges-pos-ontonotes, batch 528 (11528): mcc: 0.8600, acc: 0.7786, precision: 0.9025, recall: 0.8248, f1: 0.8619, edges-pos-ontonotes_loss: 0.0163
09/16 03:51:25 AM: Update 11580: task edges-pos-ontonotes, batch 580 (11580): mcc: 0.8602, acc: 0.7789, precision: 0.9029, recall: 0.8249, f1: 0.8621, edges-pos-ontonotes_loss: 0.0163
09/16 03:51:35 AM: Update 11631: task edges-pos-ontonotes, batch 631 (11631): mcc: 0.8610, acc: 0.7800, precision: 0.9035, recall: 0.8258, f1: 0.8629, edges-pos-ontonotes_loss: 0.0162
09/16 03:51:45 AM: Update 11676: task edges-pos-ontonotes, batch 676 (11676): mcc: 0.8612, acc: 0.7804, precision: 0.9037, recall: 0.8259, f1: 0.8631, edges-pos-ontonotes_loss: 0.0162
09/16 03:51:55 AM: Update 11725: task edges-pos-ontonotes, batch 725 (11725): mcc: 0.8616, acc: 0.7811, precision: 0.9042, recall: 0.8263, f1: 0.8635, edges-pos-ontonotes_loss: 0.0161
09/16 03:52:05 AM: Update 11776: task edges-pos-ontonotes, batch 776 (11776): mcc: 0.8622, acc: 0.7820, precision: 0.9047, recall: 0.8269, f1: 0.8640, edges-pos-ontonotes_loss: 0.0161
09/16 03:52:16 AM: Update 11825: task edges-pos-ontonotes, batch 825 (11825): mcc: 0.8627, acc: 0.7828, precision: 0.9052, recall: 0.8274, f1: 0.8646, edges-pos-ontonotes_loss: 0.0160
09/16 03:52:26 AM: Update 11875: task edges-pos-ontonotes, batch 875 (11875): mcc: 0.8632, acc: 0.7835, precision: 0.9055, recall: 0.8280, f1: 0.8650, edges-pos-ontonotes_loss: 0.0160
09/16 03:52:36 AM: Update 11926: task edges-pos-ontonotes, batch 926 (11926): mcc: 0.8635, acc: 0.7840, precision: 0.9059, recall: 0.8283, f1: 0.8654, edges-pos-ontonotes_loss: 0.0159
09/16 03:52:46 AM: Update 11964: task edges-pos-ontonotes, batch 964 (11964): mcc: 0.8637, acc: 0.7844, precision: 0.9061, recall: 0.8286, f1: 0.8656, edges-pos-ontonotes_loss: 0.0159
09/16 03:52:53 AM: ***** Step 12000 / Validation 12 *****
09/16 03:52:53 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:52:53 AM: Validating...
09/16 03:52:56 AM: Evaluate: task edges-pos-ontonotes, batch 17 (157): mcc: 0.8922, acc: 0.8296, precision: 0.9395, recall: 0.8514, f1: 0.8933, edges-pos-ontonotes_loss: 0.0127
09/16 03:53:06 AM: Evaluate: task edges-pos-ontonotes, batch 82 (157): mcc: 0.9011, acc: 0.8415, precision: 0.9459, recall: 0.8621, f1: 0.9020, edges-pos-ontonotes_loss: 0.0121
09/16 03:53:16 AM: Evaluate: task edges-pos-ontonotes, batch 128 (157): mcc: 0.9016, acc: 0.8439, precision: 0.9412, recall: 0.8674, f1: 0.9028, edges-pos-ontonotes_loss: 0.0119
09/16 03:53:23 AM: Best result seen so far for edges-pos-ontonotes.
09/16 03:53:23 AM: Best result seen so far for macro.
09/16 03:53:23 AM: Updating LR scheduler:
09/16 03:53:23 AM: 	Best result seen so far for macro_avg: 0.905
09/16 03:53:23 AM: 	# validation passes without improvement: 0
09/16 03:53:23 AM: edges-pos-ontonotes_loss: training: 0.015911 validation: 0.011620
09/16 03:53:23 AM: macro_avg: validation: 0.905297
09/16 03:53:23 AM: micro_avg: validation: 0.000000
09/16 03:53:23 AM: edges-pos-ontonotes_mcc: training: 0.863974 validation: 0.904015
09/16 03:53:23 AM: edges-pos-ontonotes_acc: training: 0.784850 validation: 0.848937
09/16 03:53:23 AM: edges-pos-ontonotes_precision: training: 0.906202 validation: 0.940417
09/16 03:53:23 AM: edges-pos-ontonotes_recall: training: 0.828857 validation: 0.872705
09/16 03:53:23 AM: edges-pos-ontonotes_f1: training: 0.865806 validation: 0.905297
09/16 03:53:23 AM: Global learning rate: 0.0001
09/16 03:53:23 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:53:26 AM: Update 12019: task edges-pos-ontonotes, batch 19 (12019): mcc: 0.8696, acc: 0.7943, precision: 0.9156, recall: 0.8307, f1: 0.8711, edges-pos-ontonotes_loss: 0.0151
09/16 03:53:37 AM: Update 12065: task edges-pos-ontonotes, batch 65 (12065): mcc: 0.8709, acc: 0.7963, precision: 0.9123, recall: 0.8364, f1: 0.8727, edges-pos-ontonotes_loss: 0.0159
09/16 03:53:47 AM: Update 12117: task edges-pos-ontonotes, batch 117 (12117): mcc: 0.8707, acc: 0.7957, precision: 0.9127, recall: 0.8356, f1: 0.8724, edges-pos-ontonotes_loss: 0.0157
09/16 03:53:57 AM: Update 12171: task edges-pos-ontonotes, batch 171 (12171): mcc: 0.8701, acc: 0.7950, precision: 0.9123, recall: 0.8347, f1: 0.8718, edges-pos-ontonotes_loss: 0.0157
09/16 03:54:07 AM: Update 12225: task edges-pos-ontonotes, batch 225 (12225): mcc: 0.8704, acc: 0.7954, precision: 0.9121, recall: 0.8356, f1: 0.8722, edges-pos-ontonotes_loss: 0.0156
09/16 03:54:17 AM: Update 12260: task edges-pos-ontonotes, batch 260 (12260): mcc: 0.8698, acc: 0.7944, precision: 0.9119, recall: 0.8346, f1: 0.8716, edges-pos-ontonotes_loss: 0.0155
09/16 03:54:27 AM: Update 12320: task edges-pos-ontonotes, batch 320 (12320): mcc: 0.8701, acc: 0.7947, precision: 0.9122, recall: 0.8348, f1: 0.8718, edges-pos-ontonotes_loss: 0.0152
09/16 03:54:38 AM: Update 12388: task edges-pos-ontonotes, batch 388 (12388): mcc: 0.8717, acc: 0.7967, precision: 0.9134, recall: 0.8367, f1: 0.8734, edges-pos-ontonotes_loss: 0.0148
09/16 03:54:48 AM: Update 12456: task edges-pos-ontonotes, batch 456 (12456): mcc: 0.8723, acc: 0.7976, precision: 0.9137, recall: 0.8376, f1: 0.8740, edges-pos-ontonotes_loss: 0.0146
09/16 03:54:58 AM: Update 12516: task edges-pos-ontonotes, batch 516 (12516): mcc: 0.8727, acc: 0.7982, precision: 0.9137, recall: 0.8383, f1: 0.8744, edges-pos-ontonotes_loss: 0.0145
09/16 03:55:09 AM: Update 12572: task edges-pos-ontonotes, batch 572 (12572): mcc: 0.8732, acc: 0.7988, precision: 0.9141, recall: 0.8389, f1: 0.8749, edges-pos-ontonotes_loss: 0.0144
09/16 03:55:19 AM: Update 12652: task edges-pos-ontonotes, batch 652 (12652): mcc: 0.8756, acc: 0.8019, precision: 0.9162, recall: 0.8415, f1: 0.8772, edges-pos-ontonotes_loss: 0.0140
09/16 03:55:29 AM: Update 12728: task edges-pos-ontonotes, batch 728 (12728): mcc: 0.8774, acc: 0.8043, precision: 0.9178, recall: 0.8435, f1: 0.8791, edges-pos-ontonotes_loss: 0.0138
09/16 03:55:39 AM: Update 12802: task edges-pos-ontonotes, batch 802 (12802): mcc: 0.8791, acc: 0.8065, precision: 0.9192, recall: 0.8454, f1: 0.8808, edges-pos-ontonotes_loss: 0.0136
09/16 03:55:50 AM: Update 12885: task edges-pos-ontonotes, batch 885 (12885): mcc: 0.8806, acc: 0.8084, precision: 0.9205, recall: 0.8470, f1: 0.8822, edges-pos-ontonotes_loss: 0.0134
09/16 03:56:00 AM: Update 12973: task edges-pos-ontonotes, batch 973 (12973): mcc: 0.8813, acc: 0.8093, precision: 0.9215, recall: 0.8474, f1: 0.8829, edges-pos-ontonotes_loss: 0.0133
09/16 03:56:02 AM: ***** Step 13000 / Validation 13 *****
09/16 03:56:02 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:56:02 AM: Validating...
09/16 03:56:10 AM: Evaluate: task edges-pos-ontonotes, batch 52 (157): mcc: 0.8956, acc: 0.8336, precision: 0.9453, recall: 0.8523, f1: 0.8964, edges-pos-ontonotes_loss: 0.0125
09/16 03:56:20 AM: Evaluate: task edges-pos-ontonotes, batch 108 (157): mcc: 0.9010, acc: 0.8439, precision: 0.9404, recall: 0.8669, f1: 0.9022, edges-pos-ontonotes_loss: 0.0119
09/16 03:56:30 AM: Evaluate: task edges-pos-ontonotes, batch 151 (157): mcc: 0.9020, acc: 0.8468, precision: 0.9357, recall: 0.8732, f1: 0.9034, edges-pos-ontonotes_loss: 0.0118
09/16 03:56:31 AM: Updating LR scheduler:
09/16 03:56:31 AM: 	Best result seen so far for macro_avg: 0.905
09/16 03:56:31 AM: 	# validation passes without improvement: 1
09/16 03:56:31 AM: edges-pos-ontonotes_loss: training: 0.013291 validation: 0.011731
09/16 03:56:31 AM: macro_avg: validation: 0.903918
09/16 03:56:31 AM: micro_avg: validation: 0.000000
09/16 03:56:31 AM: edges-pos-ontonotes_mcc: training: 0.881582 validation: 0.902498
09/16 03:56:31 AM: edges-pos-ontonotes_acc: training: 0.809608 validation: 0.847762
09/16 03:56:31 AM: edges-pos-ontonotes_precision: training: 0.921727 validation: 0.936010
09/16 03:56:31 AM: edges-pos-ontonotes_recall: training: 0.847688 validation: 0.873954
09/16 03:56:31 AM: edges-pos-ontonotes_f1: training: 0.883158 validation: 0.903918
09/16 03:56:31 AM: Global learning rate: 0.0001
09/16 03:56:31 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:56:40 AM: Update 13085: task edges-pos-ontonotes, batch 85 (13085): mcc: 0.8978, acc: 0.8313, precision: 0.9382, recall: 0.8631, f1: 0.8991, edges-pos-ontonotes_loss: 0.0124
09/16 03:56:50 AM: Update 13175: task edges-pos-ontonotes, batch 175 (13175): mcc: 0.8976, acc: 0.8313, precision: 0.9362, recall: 0.8645, f1: 0.8989, edges-pos-ontonotes_loss: 0.0123
09/16 03:57:00 AM: Update 13270: task edges-pos-ontonotes, batch 270 (13270): mcc: 0.8902, acc: 0.8205, precision: 0.9320, recall: 0.8544, f1: 0.8915, edges-pos-ontonotes_loss: 0.0131
09/16 03:57:10 AM: Update 13388: task edges-pos-ontonotes, batch 388 (13388): mcc: 0.8824, acc: 0.8089, precision: 0.9268, recall: 0.8446, f1: 0.8838, edges-pos-ontonotes_loss: 0.0138
09/16 03:57:20 AM: Update 13498: task edges-pos-ontonotes, batch 498 (13498): mcc: 0.8791, acc: 0.8040, precision: 0.9242, recall: 0.8407, f1: 0.8805, edges-pos-ontonotes_loss: 0.0141
09/16 03:57:31 AM: Update 13511: task edges-pos-ontonotes, batch 511 (13511): mcc: 0.8784, acc: 0.8029, precision: 0.9236, recall: 0.8399, f1: 0.8798, edges-pos-ontonotes_loss: 0.0142
09/16 03:57:41 AM: Update 13568: task edges-pos-ontonotes, batch 568 (13568): mcc: 0.8739, acc: 0.7963, precision: 0.9188, recall: 0.8359, f1: 0.8754, edges-pos-ontonotes_loss: 0.0144
09/16 03:57:51 AM: Update 13625: task edges-pos-ontonotes, batch 625 (13625): mcc: 0.8712, acc: 0.7926, precision: 0.9158, recall: 0.8335, f1: 0.8728, edges-pos-ontonotes_loss: 0.0146
09/16 03:58:01 AM: Update 13684: task edges-pos-ontonotes, batch 684 (13684): mcc: 0.8693, acc: 0.7901, precision: 0.9137, recall: 0.8320, f1: 0.8709, edges-pos-ontonotes_loss: 0.0148
09/16 03:58:11 AM: Update 13743: task edges-pos-ontonotes, batch 743 (13743): mcc: 0.8680, acc: 0.7882, precision: 0.9121, recall: 0.8310, f1: 0.8697, edges-pos-ontonotes_loss: 0.0150
09/16 03:58:22 AM: Update 13797: task edges-pos-ontonotes, batch 797 (13797): mcc: 0.8666, acc: 0.7864, precision: 0.9105, recall: 0.8298, f1: 0.8683, edges-pos-ontonotes_loss: 0.0152
09/16 03:58:32 AM: Update 13843: task edges-pos-ontonotes, batch 843 (13843): mcc: 0.8655, acc: 0.7847, precision: 0.9098, recall: 0.8283, f1: 0.8672, edges-pos-ontonotes_loss: 0.0153
09/16 03:58:42 AM: Update 13936: task edges-pos-ontonotes, batch 936 (13936): mcc: 0.8650, acc: 0.7839, precision: 0.9106, recall: 0.8269, f1: 0.8667, edges-pos-ontonotes_loss: 0.0153
09/16 03:58:51 AM: ***** Step 14000 / Validation 14 *****
09/16 03:58:51 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:58:51 AM: Validating...
09/16 03:58:52 AM: Evaluate: task edges-pos-ontonotes, batch 5 (157): mcc: 0.8972, acc: 0.8441, precision: 0.9241, recall: 0.8750, f1: 0.8989, edges-pos-ontonotes_loss: 0.0123
09/16 03:59:02 AM: Evaluate: task edges-pos-ontonotes, batch 70 (157): mcc: 0.9073, acc: 0.8533, precision: 0.9413, recall: 0.8781, f1: 0.9086, edges-pos-ontonotes_loss: 0.0115
09/16 03:59:12 AM: Evaluate: task edges-pos-ontonotes, batch 115 (157): mcc: 0.9068, acc: 0.8539, precision: 0.9351, recall: 0.8830, f1: 0.9083, edges-pos-ontonotes_loss: 0.0114
09/16 03:59:22 AM: Best result seen so far for edges-pos-ontonotes.
09/16 03:59:22 AM: Best result seen so far for macro.
09/16 03:59:22 AM: Updating LR scheduler:
09/16 03:59:22 AM: 	Best result seen so far for macro_avg: 0.909
09/16 03:59:22 AM: 	# validation passes without improvement: 0
09/16 03:59:22 AM: edges-pos-ontonotes_loss: training: 0.015298 validation: 0.011338
09/16 03:59:22 AM: macro_avg: validation: 0.908917
09/16 03:59:22 AM: micro_avg: validation: 0.000000
09/16 03:59:22 AM: edges-pos-ontonotes_mcc: training: 0.864691 validation: 0.907311
09/16 03:59:22 AM: edges-pos-ontonotes_acc: training: 0.783193 validation: 0.855562
09/16 03:59:22 AM: edges-pos-ontonotes_precision: training: 0.910597 validation: 0.931710
09/16 03:59:22 AM: edges-pos-ontonotes_recall: training: 0.826168 validation: 0.887213
09/16 03:59:22 AM: edges-pos-ontonotes_f1: training: 0.866330 validation: 0.908917
09/16 03:59:22 AM: Global learning rate: 0.0001
09/16 03:59:22 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:59:22 AM: Update 14002: task edges-pos-ontonotes, batch 2 (14002): mcc: 0.8575, acc: 0.7669, precision: 0.9161, recall: 0.8079, f1: 0.8586, edges-pos-ontonotes_loss: 0.0172
09/16 03:59:32 AM: Update 14092: task edges-pos-ontonotes, batch 92 (14092): mcc: 0.8645, acc: 0.7804, precision: 0.9203, recall: 0.8170, f1: 0.8656, edges-pos-ontonotes_loss: 0.0150
09/16 03:59:42 AM: Update 14155: task edges-pos-ontonotes, batch 155 (14155): mcc: 0.8659, acc: 0.7829, precision: 0.9180, recall: 0.8216, f1: 0.8672, edges-pos-ontonotes_loss: 0.0150
09/16 03:59:52 AM: Update 14225: task edges-pos-ontonotes, batch 225 (14225): mcc: 0.8672, acc: 0.7860, precision: 0.9143, recall: 0.8275, f1: 0.8687, edges-pos-ontonotes_loss: 0.0150
09/16 04:00:02 AM: Update 14289: task edges-pos-ontonotes, batch 289 (14289): mcc: 0.8670, acc: 0.7861, precision: 0.9123, recall: 0.8291, f1: 0.8687, edges-pos-ontonotes_loss: 0.0150
09/16 04:00:12 AM: Update 14358: task edges-pos-ontonotes, batch 358 (14358): mcc: 0.8678, acc: 0.7875, precision: 0.9119, recall: 0.8309, f1: 0.8695, edges-pos-ontonotes_loss: 0.0149
09/16 04:00:22 AM: Update 14422: task edges-pos-ontonotes, batch 422 (14422): mcc: 0.8688, acc: 0.7889, precision: 0.9117, recall: 0.8328, f1: 0.8705, edges-pos-ontonotes_loss: 0.0148
09/16 04:00:32 AM: Update 14469: task edges-pos-ontonotes, batch 469 (14469): mcc: 0.8682, acc: 0.7882, precision: 0.9111, recall: 0.8323, f1: 0.8699, edges-pos-ontonotes_loss: 0.0148
09/16 04:00:42 AM: Update 14525: task edges-pos-ontonotes, batch 525 (14525): mcc: 0.8668, acc: 0.7865, precision: 0.9092, recall: 0.8315, f1: 0.8686, edges-pos-ontonotes_loss: 0.0150
09/16 04:00:52 AM: Update 14584: task edges-pos-ontonotes, batch 584 (14584): mcc: 0.8664, acc: 0.7860, precision: 0.9081, recall: 0.8315, f1: 0.8682, edges-pos-ontonotes_loss: 0.0151
09/16 04:01:03 AM: Update 14640: task edges-pos-ontonotes, batch 640 (14640): mcc: 0.8660, acc: 0.7858, precision: 0.9075, recall: 0.8316, f1: 0.8679, edges-pos-ontonotes_loss: 0.0152
09/16 04:01:13 AM: Update 14692: task edges-pos-ontonotes, batch 692 (14692): mcc: 0.8661, acc: 0.7859, precision: 0.9071, recall: 0.8320, f1: 0.8679, edges-pos-ontonotes_loss: 0.0152
09/16 04:01:23 AM: Update 14743: task edges-pos-ontonotes, batch 743 (14743): mcc: 0.8662, acc: 0.7861, precision: 0.9071, recall: 0.8323, f1: 0.8681, edges-pos-ontonotes_loss: 0.0152
09/16 04:01:33 AM: Update 14781: task edges-pos-ontonotes, batch 781 (14781): mcc: 0.8660, acc: 0.7859, precision: 0.9067, recall: 0.8321, f1: 0.8678, edges-pos-ontonotes_loss: 0.0153
09/16 04:01:43 AM: Update 14831: task edges-pos-ontonotes, batch 831 (14831): mcc: 0.8661, acc: 0.7861, precision: 0.9066, recall: 0.8325, f1: 0.8679, edges-pos-ontonotes_loss: 0.0152
09/16 04:01:53 AM: Update 14881: task edges-pos-ontonotes, batch 881 (14881): mcc: 0.8663, acc: 0.7865, precision: 0.9066, recall: 0.8328, f1: 0.8681, edges-pos-ontonotes_loss: 0.0152
09/16 04:02:03 AM: Update 14928: task edges-pos-ontonotes, batch 928 (14928): mcc: 0.8666, acc: 0.7870, precision: 0.9067, recall: 0.8333, f1: 0.8685, edges-pos-ontonotes_loss: 0.0152
09/16 04:02:13 AM: Update 14982: task edges-pos-ontonotes, batch 982 (14982): mcc: 0.8668, acc: 0.7874, precision: 0.9068, recall: 0.8336, f1: 0.8687, edges-pos-ontonotes_loss: 0.0152
09/16 04:02:17 AM: ***** Step 15000 / Validation 15 *****
09/16 04:02:17 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:02:17 AM: Validating...
09/16 04:02:23 AM: Evaluate: task edges-pos-ontonotes, batch 44 (157): mcc: 0.8989, acc: 0.8382, precision: 0.9473, recall: 0.8567, f1: 0.8997, edges-pos-ontonotes_loss: 0.0121
09/16 04:02:33 AM: Evaluate: task edges-pos-ontonotes, batch 104 (157): mcc: 0.9090, acc: 0.8553, precision: 0.9466, recall: 0.8764, f1: 0.9102, edges-pos-ontonotes_loss: 0.0112
09/16 04:02:44 AM: Evaluate: task edges-pos-ontonotes, batch 148 (157): mcc: 0.9090, acc: 0.8566, precision: 0.9421, recall: 0.8805, f1: 0.9103, edges-pos-ontonotes_loss: 0.0111
09/16 04:02:45 AM: Best result seen so far for edges-pos-ontonotes.
09/16 04:02:45 AM: Best result seen so far for macro.
09/16 04:02:45 AM: Updating LR scheduler:
09/16 04:02:45 AM: 	Best result seen so far for macro_avg: 0.911
09/16 04:02:45 AM: 	# validation passes without improvement: 0
09/16 04:02:45 AM: edges-pos-ontonotes_loss: training: 0.015209 validation: 0.011003
09/16 04:02:45 AM: macro_avg: validation: 0.910793
09/16 04:02:45 AM: micro_avg: validation: 0.000000
09/16 04:02:45 AM: edges-pos-ontonotes_mcc: training: 0.866915 validation: 0.909483
09/16 04:02:45 AM: edges-pos-ontonotes_acc: training: 0.787585 validation: 0.857826
09/16 04:02:45 AM: edges-pos-ontonotes_precision: training: 0.906926 validation: 0.942125
09/16 04:02:45 AM: edges-pos-ontonotes_recall: training: 0.833729 validation: 0.881478
09/16 04:02:45 AM: edges-pos-ontonotes_f1: training: 0.868788 validation: 0.910793
09/16 04:02:45 AM: Global learning rate: 0.0001
09/16 04:02:45 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:02:54 AM: Update 15042: task edges-pos-ontonotes, batch 42 (15042): mcc: 0.8703, acc: 0.7945, precision: 0.9073, recall: 0.8398, f1: 0.8722, edges-pos-ontonotes_loss: 0.0151
09/16 04:03:13 AM: Update 15093: task edges-pos-ontonotes, batch 93 (15093): mcc: 0.8707, acc: 0.7954, precision: 0.9090, recall: 0.8389, f1: 0.8726, edges-pos-ontonotes_loss: 0.0153
09/16 04:03:23 AM: Update 15149: task edges-pos-ontonotes, batch 149 (15149): mcc: 0.8705, acc: 0.7951, precision: 0.9095, recall: 0.8381, f1: 0.8723, edges-pos-ontonotes_loss: 0.0153
09/16 04:03:33 AM: Update 15202: task edges-pos-ontonotes, batch 202 (15202): mcc: 0.8718, acc: 0.7971, precision: 0.9103, recall: 0.8398, f1: 0.8736, edges-pos-ontonotes_loss: 0.0151
09/16 04:03:44 AM: Update 15254: task edges-pos-ontonotes, batch 254 (15254): mcc: 0.8719, acc: 0.7973, precision: 0.9104, recall: 0.8399, f1: 0.8737, edges-pos-ontonotes_loss: 0.0150
09/16 04:03:54 AM: Update 15304: task edges-pos-ontonotes, batch 304 (15304): mcc: 0.8723, acc: 0.7980, precision: 0.9106, recall: 0.8405, f1: 0.8742, edges-pos-ontonotes_loss: 0.0149
09/16 04:04:04 AM: Update 15361: task edges-pos-ontonotes, batch 361 (15361): mcc: 0.8730, acc: 0.7989, precision: 0.9113, recall: 0.8411, f1: 0.8748, edges-pos-ontonotes_loss: 0.0150
09/16 04:04:14 AM: Update 15406: task edges-pos-ontonotes, batch 406 (15406): mcc: 0.8731, acc: 0.7991, precision: 0.9117, recall: 0.8411, f1: 0.8750, edges-pos-ontonotes_loss: 0.0149
09/16 04:04:24 AM: Update 15455: task edges-pos-ontonotes, batch 455 (15455): mcc: 0.8730, acc: 0.7990, precision: 0.9114, recall: 0.8410, f1: 0.8748, edges-pos-ontonotes_loss: 0.0150
09/16 04:04:35 AM: Update 15506: task edges-pos-ontonotes, batch 506 (15506): mcc: 0.8733, acc: 0.7996, precision: 0.9116, recall: 0.8415, f1: 0.8752, edges-pos-ontonotes_loss: 0.0149
09/16 04:04:45 AM: Update 15554: task edges-pos-ontonotes, batch 554 (15554): mcc: 0.8738, acc: 0.8003, precision: 0.9119, recall: 0.8421, f1: 0.8756, edges-pos-ontonotes_loss: 0.0149
09/16 04:04:55 AM: Update 15600: task edges-pos-ontonotes, batch 600 (15600): mcc: 0.8738, acc: 0.8003, precision: 0.9120, recall: 0.8420, f1: 0.8756, edges-pos-ontonotes_loss: 0.0149
09/16 04:05:05 AM: Update 15649: task edges-pos-ontonotes, batch 649 (15649): mcc: 0.8740, acc: 0.8007, precision: 0.9121, recall: 0.8423, f1: 0.8758, edges-pos-ontonotes_loss: 0.0149
09/16 04:05:15 AM: Update 15703: task edges-pos-ontonotes, batch 703 (15703): mcc: 0.8741, acc: 0.8008, precision: 0.9123, recall: 0.8423, f1: 0.8759, edges-pos-ontonotes_loss: 0.0149
09/16 04:05:25 AM: Update 15746: task edges-pos-ontonotes, batch 746 (15746): mcc: 0.8737, acc: 0.8003, precision: 0.9120, recall: 0.8419, f1: 0.8756, edges-pos-ontonotes_loss: 0.0149
09/16 04:05:35 AM: Update 15808: task edges-pos-ontonotes, batch 808 (15808): mcc: 0.8740, acc: 0.8006, precision: 0.9122, recall: 0.8422, f1: 0.8758, edges-pos-ontonotes_loss: 0.0148
09/16 04:05:45 AM: Update 15870: task edges-pos-ontonotes, batch 870 (15870): mcc: 0.8743, acc: 0.8010, precision: 0.9125, recall: 0.8425, f1: 0.8761, edges-pos-ontonotes_loss: 0.0147
09/16 04:05:55 AM: Update 15938: task edges-pos-ontonotes, batch 938 (15938): mcc: 0.8749, acc: 0.8018, precision: 0.9130, recall: 0.8432, f1: 0.8767, edges-pos-ontonotes_loss: 0.0145
09/16 04:06:04 AM: ***** Step 16000 / Validation 16 *****
09/16 04:06:04 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:06:04 AM: Validating...
09/16 04:06:05 AM: Evaluate: task edges-pos-ontonotes, batch 6 (157): mcc: 0.9065, acc: 0.8589, precision: 0.9344, recall: 0.8830, f1: 0.9080, edges-pos-ontonotes_loss: 0.0112
09/16 04:06:15 AM: Evaluate: task edges-pos-ontonotes, batch 72 (157): mcc: 0.9049, acc: 0.8489, precision: 0.9448, recall: 0.8704, f1: 0.9061, edges-pos-ontonotes_loss: 0.0117
09/16 04:06:26 AM: Evaluate: task edges-pos-ontonotes, batch 123 (157): mcc: 0.9071, acc: 0.8535, precision: 0.9409, recall: 0.8782, f1: 0.9084, edges-pos-ontonotes_loss: 0.0112
09/16 04:06:33 AM: Updating LR scheduler:
09/16 04:06:33 AM: 	Best result seen so far for macro_avg: 0.911
09/16 04:06:33 AM: 	# validation passes without improvement: 1
09/16 04:06:33 AM: edges-pos-ontonotes_loss: training: 0.014407 validation: 0.011021
09/16 04:06:33 AM: macro_avg: validation: 0.910567
09/16 04:06:33 AM: micro_avg: validation: 0.000000
09/16 04:06:33 AM: edges-pos-ontonotes_mcc: training: 0.875293 validation: 0.909162
09/16 04:06:33 AM: edges-pos-ontonotes_acc: training: 0.802277 validation: 0.857879
09/16 04:06:33 AM: edges-pos-ontonotes_precision: training: 0.913311 validation: 0.939155
09/16 04:06:33 AM: edges-pos-ontonotes_recall: training: 0.843623 validation: 0.883668
09/16 04:06:33 AM: edges-pos-ontonotes_f1: training: 0.877085 validation: 0.910567
09/16 04:06:33 AM: Global learning rate: 0.0001
09/16 04:06:33 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:06:36 AM: Update 16018: task edges-pos-ontonotes, batch 18 (16018): mcc: 0.8810, acc: 0.8094, precision: 0.9124, recall: 0.8553, f1: 0.8829, edges-pos-ontonotes_loss: 0.0127
09/16 04:06:46 AM: Update 16078: task edges-pos-ontonotes, batch 78 (16078): mcc: 0.8919, acc: 0.8242, precision: 0.9256, recall: 0.8636, f1: 0.8935, edges-pos-ontonotes_loss: 0.0120
09/16 04:06:56 AM: Update 16161: task edges-pos-ontonotes, batch 161 (16161): mcc: 0.8981, acc: 0.8320, precision: 0.9317, recall: 0.8696, f1: 0.8996, edges-pos-ontonotes_loss: 0.0116
09/16 04:07:06 AM: Update 16244: task edges-pos-ontonotes, batch 244 (16244): mcc: 0.9003, acc: 0.8355, precision: 0.9337, recall: 0.8720, f1: 0.9018, edges-pos-ontonotes_loss: 0.0114
09/16 04:07:16 AM: Update 16327: task edges-pos-ontonotes, batch 327 (16327): mcc: 0.9019, acc: 0.8375, precision: 0.9351, recall: 0.8738, f1: 0.9034, edges-pos-ontonotes_loss: 0.0113
09/16 04:07:26 AM: Update 16412: task edges-pos-ontonotes, batch 412 (16412): mcc: 0.9008, acc: 0.8357, precision: 0.9352, recall: 0.8715, f1: 0.9022, edges-pos-ontonotes_loss: 0.0115
09/16 04:07:36 AM: Update 16509: task edges-pos-ontonotes, batch 509 (16509): mcc: 0.9008, acc: 0.8356, precision: 0.9358, recall: 0.8708, f1: 0.9022, edges-pos-ontonotes_loss: 0.0115
09/16 04:07:46 AM: Update 16608: task edges-pos-ontonotes, batch 608 (16608): mcc: 0.9009, acc: 0.8361, precision: 0.9360, recall: 0.8710, f1: 0.9023, edges-pos-ontonotes_loss: 0.0115
09/16 04:07:56 AM: Update 16704: task edges-pos-ontonotes, batch 704 (16704): mcc: 0.8991, acc: 0.8336, precision: 0.9350, recall: 0.8685, f1: 0.9005, edges-pos-ontonotes_loss: 0.0117
09/16 04:08:06 AM: Update 16835: task edges-pos-ontonotes, batch 835 (16835): mcc: 0.8961, acc: 0.8289, precision: 0.9332, recall: 0.8644, f1: 0.8975, edges-pos-ontonotes_loss: 0.0122
09/16 04:08:17 AM: Update 16950: task edges-pos-ontonotes, batch 950 (16950): mcc: 0.8934, acc: 0.8252, precision: 0.9314, recall: 0.8611, f1: 0.8949, edges-pos-ontonotes_loss: 0.0126
09/16 04:08:26 AM: ***** Step 17000 / Validation 17 *****
09/16 04:08:26 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:08:26 AM: Validating...
09/16 04:08:27 AM: Evaluate: task edges-pos-ontonotes, batch 2 (157): mcc: 0.9085, acc: 0.8588, precision: 0.9421, recall: 0.8797, f1: 0.9098, edges-pos-ontonotes_loss: 0.0106
09/16 04:08:37 AM: Evaluate: task edges-pos-ontonotes, batch 66 (157): mcc: 0.9032, acc: 0.8463, precision: 0.9451, recall: 0.8668, f1: 0.9043, edges-pos-ontonotes_loss: 0.0117
09/16 04:08:47 AM: Evaluate: task edges-pos-ontonotes, batch 113 (157): mcc: 0.9045, acc: 0.8494, precision: 0.9394, recall: 0.8746, f1: 0.9058, edges-pos-ontonotes_loss: 0.0114
09/16 04:08:57 AM: Evaluate: task edges-pos-ontonotes, batch 156 (157): mcc: 0.9059, acc: 0.8525, precision: 0.9347, recall: 0.8817, f1: 0.9074, edges-pos-ontonotes_loss: 0.0113
09/16 04:08:57 AM: Updating LR scheduler:
09/16 04:08:57 AM: 	Best result seen so far for macro_avg: 0.911
09/16 04:08:57 AM: 	# validation passes without improvement: 2
09/16 04:08:57 AM: edges-pos-ontonotes_loss: training: 0.012693 validation: 0.011276
09/16 04:08:57 AM: macro_avg: validation: 0.907460
09/16 04:08:57 AM: micro_avg: validation: 0.000000
09/16 04:08:57 AM: edges-pos-ontonotes_mcc: training: 0.890702 validation: 0.905953
09/16 04:08:57 AM: edges-pos-ontonotes_acc: training: 0.821281 validation: 0.852577
09/16 04:08:57 AM: edges-pos-ontonotes_precision: training: 0.928670 validation: 0.934771
09/16 04:08:57 AM: edges-pos-ontonotes_recall: training: 0.858463 validation: 0.881700
09/16 04:08:57 AM: edges-pos-ontonotes_f1: training: 0.892188 validation: 0.907460
09/16 04:08:57 AM: Global learning rate: 0.0001
09/16 04:08:57 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:09:07 AM: Update 17057: task edges-pos-ontonotes, batch 57 (17057): mcc: 0.8621, acc: 0.7798, precision: 0.9015, recall: 0.8297, f1: 0.8641, edges-pos-ontonotes_loss: 0.0160
09/16 04:09:17 AM: Update 17108: task edges-pos-ontonotes, batch 108 (17108): mcc: 0.8610, acc: 0.7776, precision: 0.9001, recall: 0.8288, f1: 0.8630, edges-pos-ontonotes_loss: 0.0163
09/16 04:09:28 AM: Update 17164: task edges-pos-ontonotes, batch 164 (17164): mcc: 0.8611, acc: 0.7780, precision: 0.9009, recall: 0.8284, f1: 0.8631, edges-pos-ontonotes_loss: 0.0164
09/16 04:09:38 AM: Update 17223: task edges-pos-ontonotes, batch 223 (17223): mcc: 0.8618, acc: 0.7791, precision: 0.9018, recall: 0.8288, f1: 0.8638, edges-pos-ontonotes_loss: 0.0164
09/16 04:09:48 AM: Update 17282: task edges-pos-ontonotes, batch 282 (17282): mcc: 0.8615, acc: 0.7791, precision: 0.9018, recall: 0.8283, f1: 0.8635, edges-pos-ontonotes_loss: 0.0164
09/16 04:10:01 AM: Update 17301: task edges-pos-ontonotes, batch 301 (17301): mcc: 0.8610, acc: 0.7782, precision: 0.9016, recall: 0.8275, f1: 0.8629, edges-pos-ontonotes_loss: 0.0165
09/16 04:10:11 AM: Update 17388: task edges-pos-ontonotes, batch 388 (17388): mcc: 0.8615, acc: 0.7786, precision: 0.9038, recall: 0.8264, f1: 0.8634, edges-pos-ontonotes_loss: 0.0162
09/16 04:10:21 AM: Update 17469: task edges-pos-ontonotes, batch 469 (17469): mcc: 0.8620, acc: 0.7793, precision: 0.9054, recall: 0.8260, f1: 0.8639, edges-pos-ontonotes_loss: 0.0160
09/16 04:10:31 AM: Update 17548: task edges-pos-ontonotes, batch 548 (17548): mcc: 0.8625, acc: 0.7799, precision: 0.9062, recall: 0.8261, f1: 0.8643, edges-pos-ontonotes_loss: 0.0158
09/16 04:10:41 AM: Update 17620: task edges-pos-ontonotes, batch 620 (17620): mcc: 0.8631, acc: 0.7807, precision: 0.9068, recall: 0.8266, f1: 0.8649, edges-pos-ontonotes_loss: 0.0156
09/16 04:10:51 AM: Update 17694: task edges-pos-ontonotes, batch 694 (17694): mcc: 0.8639, acc: 0.7819, precision: 0.9069, recall: 0.8282, f1: 0.8657, edges-pos-ontonotes_loss: 0.0156
09/16 04:11:01 AM: Update 17768: task edges-pos-ontonotes, batch 768 (17768): mcc: 0.8649, acc: 0.7833, precision: 0.9074, recall: 0.8295, f1: 0.8667, edges-pos-ontonotes_loss: 0.0154
09/16 04:11:11 AM: Update 17827: task edges-pos-ontonotes, batch 827 (17827): mcc: 0.8656, acc: 0.7843, precision: 0.9076, recall: 0.8307, f1: 0.8674, edges-pos-ontonotes_loss: 0.0154
09/16 04:11:21 AM: Update 17892: task edges-pos-ontonotes, batch 892 (17892): mcc: 0.8664, acc: 0.7854, precision: 0.9079, recall: 0.8318, f1: 0.8682, edges-pos-ontonotes_loss: 0.0153
09/16 04:11:31 AM: Update 17942: task edges-pos-ontonotes, batch 942 (17942): mcc: 0.8664, acc: 0.7855, precision: 0.9076, recall: 0.8320, f1: 0.8682, edges-pos-ontonotes_loss: 0.0153
09/16 04:11:41 AM: Update 17993: task edges-pos-ontonotes, batch 993 (17993): mcc: 0.8661, acc: 0.7853, precision: 0.9071, recall: 0.8320, f1: 0.8679, edges-pos-ontonotes_loss: 0.0153
09/16 04:11:42 AM: ***** Step 18000 / Validation 18 *****
09/16 04:11:42 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:11:42 AM: Validating...
09/16 04:11:51 AM: Evaluate: task edges-pos-ontonotes, batch 56 (157): mcc: 0.9064, acc: 0.8499, precision: 0.9503, recall: 0.8680, f1: 0.9073, edges-pos-ontonotes_loss: 0.0113
09/16 04:12:02 AM: Evaluate: task edges-pos-ontonotes, batch 106 (157): mcc: 0.9116, acc: 0.8589, precision: 0.9489, recall: 0.8790, f1: 0.9127, edges-pos-ontonotes_loss: 0.0107
09/16 04:12:12 AM: Evaluate: task edges-pos-ontonotes, batch 148 (157): mcc: 0.9104, acc: 0.8585, precision: 0.9435, recall: 0.8819, f1: 0.9117, edges-pos-ontonotes_loss: 0.0107
09/16 04:12:14 AM: Best result seen so far for edges-pos-ontonotes.
09/16 04:12:14 AM: Best result seen so far for macro.
09/16 04:12:14 AM: Updating LR scheduler:
09/16 04:12:14 AM: 	Best result seen so far for macro_avg: 0.912
09/16 04:12:14 AM: 	# validation passes without improvement: 0
09/16 04:12:14 AM: edges-pos-ontonotes_loss: training: 0.015304 validation: 0.010715
09/16 04:12:14 AM: macro_avg: validation: 0.912151
09/16 04:12:14 AM: micro_avg: validation: 0.000000
09/16 04:12:14 AM: edges-pos-ontonotes_mcc: training: 0.866055 validation: 0.910869
09/16 04:12:14 AM: edges-pos-ontonotes_acc: training: 0.785272 validation: 0.859593
09/16 04:12:14 AM: edges-pos-ontonotes_precision: training: 0.907063 validation: 0.943497
09/16 04:12:14 AM: edges-pos-ontonotes_recall: training: 0.831981 validation: 0.882822
09/16 04:12:14 AM: edges-pos-ontonotes_f1: training: 0.867901 validation: 0.912151
09/16 04:12:14 AM: Global learning rate: 0.0001
09/16 04:12:14 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:12:22 AM: Update 18044: task edges-pos-ontonotes, batch 44 (18044): mcc: 0.8669, acc: 0.7880, precision: 0.9040, recall: 0.8364, f1: 0.8689, edges-pos-ontonotes_loss: 0.0151
09/16 04:12:32 AM: Update 18099: task edges-pos-ontonotes, batch 99 (18099): mcc: 0.8670, acc: 0.7887, precision: 0.9035, recall: 0.8371, f1: 0.8691, edges-pos-ontonotes_loss: 0.0156
09/16 04:12:42 AM: Update 18154: task edges-pos-ontonotes, batch 154 (18154): mcc: 0.8671, acc: 0.7886, precision: 0.9032, recall: 0.8376, f1: 0.8692, edges-pos-ontonotes_loss: 0.0154
09/16 04:12:52 AM: Update 18210: task edges-pos-ontonotes, batch 210 (18210): mcc: 0.8680, acc: 0.7899, precision: 0.9040, recall: 0.8384, f1: 0.8700, edges-pos-ontonotes_loss: 0.0153
09/16 04:13:02 AM: Update 18253: task edges-pos-ontonotes, batch 253 (18253): mcc: 0.8677, acc: 0.7895, precision: 0.9042, recall: 0.8378, f1: 0.8697, edges-pos-ontonotes_loss: 0.0154
09/16 04:13:12 AM: Update 18306: task edges-pos-ontonotes, batch 306 (18306): mcc: 0.8686, acc: 0.7907, precision: 0.9050, recall: 0.8387, f1: 0.8706, edges-pos-ontonotes_loss: 0.0152
09/16 04:13:22 AM: Update 18356: task edges-pos-ontonotes, batch 356 (18356): mcc: 0.8691, acc: 0.7916, precision: 0.9054, recall: 0.8392, f1: 0.8711, edges-pos-ontonotes_loss: 0.0153
09/16 04:13:32 AM: Update 18408: task edges-pos-ontonotes, batch 408 (18408): mcc: 0.8692, acc: 0.7920, precision: 0.9055, recall: 0.8393, f1: 0.8712, edges-pos-ontonotes_loss: 0.0152
09/16 04:13:42 AM: Update 18458: task edges-pos-ontonotes, batch 458 (18458): mcc: 0.8697, acc: 0.7930, precision: 0.9060, recall: 0.8399, f1: 0.8717, edges-pos-ontonotes_loss: 0.0152
09/16 04:13:52 AM: Update 18515: task edges-pos-ontonotes, batch 515 (18515): mcc: 0.8703, acc: 0.7938, precision: 0.9065, recall: 0.8406, f1: 0.8723, edges-pos-ontonotes_loss: 0.0151
09/16 04:14:02 AM: Update 18554: task edges-pos-ontonotes, batch 554 (18554): mcc: 0.8702, acc: 0.7938, precision: 0.9064, recall: 0.8403, f1: 0.8721, edges-pos-ontonotes_loss: 0.0151
09/16 04:14:12 AM: Update 18612: task edges-pos-ontonotes, batch 612 (18612): mcc: 0.8708, acc: 0.7949, precision: 0.9071, recall: 0.8409, f1: 0.8728, edges-pos-ontonotes_loss: 0.0150
09/16 04:14:23 AM: Update 18663: task edges-pos-ontonotes, batch 663 (18663): mcc: 0.8711, acc: 0.7955, precision: 0.9073, recall: 0.8413, f1: 0.8731, edges-pos-ontonotes_loss: 0.0150
09/16 04:14:33 AM: Update 18718: task edges-pos-ontonotes, batch 718 (18718): mcc: 0.8715, acc: 0.7962, precision: 0.9077, recall: 0.8417, f1: 0.8735, edges-pos-ontonotes_loss: 0.0150
09/16 04:14:43 AM: Update 18766: task edges-pos-ontonotes, batch 766 (18766): mcc: 0.8719, acc: 0.7967, precision: 0.9079, recall: 0.8423, f1: 0.8738, edges-pos-ontonotes_loss: 0.0149
09/16 04:14:53 AM: Update 18816: task edges-pos-ontonotes, batch 816 (18816): mcc: 0.8722, acc: 0.7972, precision: 0.9082, recall: 0.8426, f1: 0.8741, edges-pos-ontonotes_loss: 0.0149
09/16 04:15:03 AM: Update 18862: task edges-pos-ontonotes, batch 862 (18862): mcc: 0.8725, acc: 0.7977, precision: 0.9084, recall: 0.8429, f1: 0.8744, edges-pos-ontonotes_loss: 0.0149
09/16 04:15:13 AM: Update 18899: task edges-pos-ontonotes, batch 899 (18899): mcc: 0.8725, acc: 0.7977, precision: 0.9085, recall: 0.8428, f1: 0.8744, edges-pos-ontonotes_loss: 0.0149
09/16 04:15:23 AM: Update 18952: task edges-pos-ontonotes, batch 952 (18952): mcc: 0.8729, acc: 0.7984, precision: 0.9089, recall: 0.8432, f1: 0.8748, edges-pos-ontonotes_loss: 0.0149
09/16 04:15:32 AM: ***** Step 19000 / Validation 19 *****
09/16 04:15:32 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:15:32 AM: Validating...
09/16 04:15:33 AM: Evaluate: task edges-pos-ontonotes, batch 5 (157): mcc: 0.9041, acc: 0.8510, precision: 0.9328, recall: 0.8800, f1: 0.9056, edges-pos-ontonotes_loss: 0.0115
09/16 04:15:43 AM: Evaluate: task edges-pos-ontonotes, batch 72 (157): mcc: 0.9090, acc: 0.8552, precision: 0.9459, recall: 0.8771, f1: 0.9102, edges-pos-ontonotes_loss: 0.0113
09/16 04:15:53 AM: Evaluate: task edges-pos-ontonotes, batch 123 (157): mcc: 0.9105, acc: 0.8589, precision: 0.9421, recall: 0.8834, f1: 0.9118, edges-pos-ontonotes_loss: 0.0109
09/16 04:16:01 AM: Best result seen so far for edges-pos-ontonotes.
09/16 04:16:01 AM: Best result seen so far for macro.
09/16 04:16:01 AM: Updating LR scheduler:
09/16 04:16:01 AM: 	Best result seen so far for macro_avg: 0.913
09/16 04:16:01 AM: 	# validation passes without improvement: 0
09/16 04:16:01 AM: edges-pos-ontonotes_loss: training: 0.014878 validation: 0.010728
09/16 04:16:01 AM: macro_avg: validation: 0.913409
09/16 04:16:01 AM: micro_avg: validation: 0.000000
09/16 04:16:01 AM: edges-pos-ontonotes_mcc: training: 0.872933 validation: 0.912008
09/16 04:16:01 AM: edges-pos-ontonotes_acc: training: 0.798554 validation: 0.862281
09/16 04:16:01 AM: edges-pos-ontonotes_precision: training: 0.909001 validation: 0.940248
09/16 04:16:01 AM: edges-pos-ontonotes_recall: training: 0.843176 validation: 0.888060
09/16 04:16:01 AM: edges-pos-ontonotes_f1: training: 0.874852 validation: 0.913409
09/16 04:16:01 AM: Global learning rate: 0.0001
09/16 04:16:01 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:16:03 AM: Update 19008: task edges-pos-ontonotes, batch 8 (19008): mcc: 0.8801, acc: 0.8109, precision: 0.9106, recall: 0.8552, f1: 0.8820, edges-pos-ontonotes_loss: 0.0142
09/16 04:16:14 AM: Update 19056: task edges-pos-ontonotes, batch 56 (19056): mcc: 0.8791, acc: 0.8088, precision: 0.9138, recall: 0.8504, f1: 0.8810, edges-pos-ontonotes_loss: 0.0149
09/16 04:16:24 AM: Update 19106: task edges-pos-ontonotes, batch 106 (19106): mcc: 0.8779, acc: 0.8073, precision: 0.9135, recall: 0.8485, f1: 0.8798, edges-pos-ontonotes_loss: 0.0150
09/16 04:16:34 AM: Update 19155: task edges-pos-ontonotes, batch 155 (19155): mcc: 0.8781, acc: 0.8075, precision: 0.9138, recall: 0.8485, f1: 0.8799, edges-pos-ontonotes_loss: 0.0148
09/16 04:16:48 AM: Update 19179: task edges-pos-ontonotes, batch 179 (19179): mcc: 0.8771, acc: 0.8058, precision: 0.9133, recall: 0.8470, f1: 0.8789, edges-pos-ontonotes_loss: 0.0148
09/16 04:16:58 AM: Update 19233: task edges-pos-ontonotes, batch 233 (19233): mcc: 0.8768, acc: 0.8052, precision: 0.9127, recall: 0.8470, f1: 0.8786, edges-pos-ontonotes_loss: 0.0144
09/16 04:17:08 AM: Update 19298: task edges-pos-ontonotes, batch 298 (19298): mcc: 0.8776, acc: 0.8061, precision: 0.9134, recall: 0.8480, f1: 0.8795, edges-pos-ontonotes_loss: 0.0141
09/16 04:17:19 AM: Update 19365: task edges-pos-ontonotes, batch 365 (19365): mcc: 0.8782, acc: 0.8068, precision: 0.9138, recall: 0.8487, f1: 0.8800, edges-pos-ontonotes_loss: 0.0138
09/16 04:17:29 AM: Update 19428: task edges-pos-ontonotes, batch 428 (19428): mcc: 0.8795, acc: 0.8085, precision: 0.9149, recall: 0.8501, f1: 0.8813, edges-pos-ontonotes_loss: 0.0136
09/16 04:17:39 AM: Update 19490: task edges-pos-ontonotes, batch 490 (19490): mcc: 0.8802, acc: 0.8094, precision: 0.9153, recall: 0.8510, f1: 0.8820, edges-pos-ontonotes_loss: 0.0134
09/16 04:17:49 AM: Update 19567: task edges-pos-ontonotes, batch 567 (19567): mcc: 0.8823, acc: 0.8121, precision: 0.9172, recall: 0.8532, f1: 0.8841, edges-pos-ontonotes_loss: 0.0131
09/16 04:18:00 AM: Update 19648: task edges-pos-ontonotes, batch 648 (19648): mcc: 0.8845, acc: 0.8150, precision: 0.9192, recall: 0.8556, f1: 0.8863, edges-pos-ontonotes_loss: 0.0129
09/16 04:18:10 AM: Update 19718: task edges-pos-ontonotes, batch 718 (19718): mcc: 0.8863, acc: 0.8172, precision: 0.9207, recall: 0.8575, f1: 0.8880, edges-pos-ontonotes_loss: 0.0127
09/16 04:18:20 AM: Update 19793: task edges-pos-ontonotes, batch 793 (19793): mcc: 0.8878, acc: 0.8192, precision: 0.9219, recall: 0.8592, f1: 0.8894, edges-pos-ontonotes_loss: 0.0125
09/16 04:18:30 AM: Update 19862: task edges-pos-ontonotes, batch 862 (19862): mcc: 0.8884, acc: 0.8200, precision: 0.9227, recall: 0.8597, f1: 0.8901, edges-pos-ontonotes_loss: 0.0124
09/16 04:18:40 AM: Update 19952: task edges-pos-ontonotes, batch 952 (19952): mcc: 0.8892, acc: 0.8211, precision: 0.9236, recall: 0.8604, f1: 0.8909, edges-pos-ontonotes_loss: 0.0123
09/16 04:18:44 AM: ***** Step 20000 / Validation 20 *****
09/16 04:18:44 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:18:44 AM: Validating...
09/16 04:18:50 AM: Evaluate: task edges-pos-ontonotes, batch 39 (157): mcc: 0.8987, acc: 0.8392, precision: 0.9456, recall: 0.8579, f1: 0.8996, edges-pos-ontonotes_loss: 0.0120
09/16 04:19:00 AM: Evaluate: task edges-pos-ontonotes, batch 98 (157): mcc: 0.9062, acc: 0.8527, precision: 0.9431, recall: 0.8744, f1: 0.9075, edges-pos-ontonotes_loss: 0.0113
09/16 04:19:10 AM: Evaluate: task edges-pos-ontonotes, batch 142 (157): mcc: 0.9065, acc: 0.8539, precision: 0.9373, recall: 0.8803, f1: 0.9079, edges-pos-ontonotes_loss: 0.0111
09/16 04:19:14 AM: Updating LR scheduler:
09/16 04:19:14 AM: 	Best result seen so far for macro_avg: 0.913
09/16 04:19:14 AM: 	# validation passes without improvement: 1
09/16 04:19:14 AM: edges-pos-ontonotes_loss: training: 0.012263 validation: 0.011050
09/16 04:19:14 AM: macro_avg: validation: 0.909020
09/16 04:19:14 AM: micro_avg: validation: 0.000000
09/16 04:19:14 AM: edges-pos-ontonotes_mcc: training: 0.889577 validation: 0.907576
09/16 04:19:14 AM: edges-pos-ontonotes_acc: training: 0.821571 validation: 0.856122
09/16 04:19:14 AM: edges-pos-ontonotes_precision: training: 0.924035 validation: 0.937369
09/16 04:19:14 AM: edges-pos-ontonotes_recall: training: 0.860662 validation: 0.882335
09/16 04:19:14 AM: edges-pos-ontonotes_f1: training: 0.891224 validation: 0.909020
09/16 04:19:14 AM: Global learning rate: 0.0001
09/16 04:19:14 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:19:20 AM: Update 20071: task edges-pos-ontonotes, batch 71 (20071): mcc: 0.9059, acc: 0.8432, precision: 0.9393, recall: 0.8774, f1: 0.9073, edges-pos-ontonotes_loss: 0.0113
09/16 04:19:30 AM: Update 20138: task edges-pos-ontonotes, batch 138 (20138): mcc: 0.8979, acc: 0.8326, precision: 0.9333, recall: 0.8678, f1: 0.8994, edges-pos-ontonotes_loss: 0.0120
09/16 04:19:40 AM: Update 20272: task edges-pos-ontonotes, batch 272 (20272): mcc: 0.8888, acc: 0.8191, precision: 0.9278, recall: 0.8557, f1: 0.8903, edges-pos-ontonotes_loss: 0.0131
09/16 04:19:51 AM: Update 20390: task edges-pos-ontonotes, batch 390 (20390): mcc: 0.8840, acc: 0.8115, precision: 0.9241, recall: 0.8500, f1: 0.8855, edges-pos-ontonotes_loss: 0.0135
09/16 04:20:01 AM: Update 20453: task edges-pos-ontonotes, batch 453 (20453): mcc: 0.8796, acc: 0.8052, precision: 0.9192, recall: 0.8462, f1: 0.8812, edges-pos-ontonotes_loss: 0.0139
09/16 04:20:11 AM: Update 20514: task edges-pos-ontonotes, batch 514 (20514): mcc: 0.8765, acc: 0.8007, precision: 0.9157, recall: 0.8437, f1: 0.8782, edges-pos-ontonotes_loss: 0.0141
09/16 04:20:21 AM: Update 20570: task edges-pos-ontonotes, batch 570 (20570): mcc: 0.8743, acc: 0.7977, precision: 0.9135, recall: 0.8414, f1: 0.8760, edges-pos-ontonotes_loss: 0.0144
09/16 04:20:31 AM: Update 20633: task edges-pos-ontonotes, batch 633 (20633): mcc: 0.8726, acc: 0.7955, precision: 0.9117, recall: 0.8401, f1: 0.8744, edges-pos-ontonotes_loss: 0.0146
09/16 04:20:41 AM: Update 20687: task edges-pos-ontonotes, batch 687 (20687): mcc: 0.8715, acc: 0.7939, precision: 0.9105, recall: 0.8390, f1: 0.8733, edges-pos-ontonotes_loss: 0.0147
09/16 04:20:51 AM: Update 20738: task edges-pos-ontonotes, batch 738 (20738): mcc: 0.8708, acc: 0.7929, precision: 0.9095, recall: 0.8386, f1: 0.8726, edges-pos-ontonotes_loss: 0.0147
09/16 04:21:01 AM: Update 20800: task edges-pos-ontonotes, batch 800 (20800): mcc: 0.8700, acc: 0.7916, precision: 0.9095, recall: 0.8371, f1: 0.8718, edges-pos-ontonotes_loss: 0.0148
09/16 04:21:11 AM: Update 20884: task edges-pos-ontonotes, batch 884 (20884): mcc: 0.8696, acc: 0.7909, precision: 0.9101, recall: 0.8359, f1: 0.8714, edges-pos-ontonotes_loss: 0.0148
09/16 04:21:22 AM: Update 20972: task edges-pos-ontonotes, batch 972 (20972): mcc: 0.8696, acc: 0.7907, precision: 0.9108, recall: 0.8352, f1: 0.8714, edges-pos-ontonotes_loss: 0.0147
09/16 04:21:25 AM: ***** Step 21000 / Validation 21 *****
09/16 04:21:25 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:21:25 AM: Validating...
09/16 04:21:32 AM: Evaluate: task edges-pos-ontonotes, batch 44 (157): mcc: 0.9058, acc: 0.8509, precision: 0.9432, recall: 0.8735, f1: 0.9070, edges-pos-ontonotes_loss: 0.0113
09/16 04:21:42 AM: Evaluate: task edges-pos-ontonotes, batch 100 (157): mcc: 0.9123, acc: 0.8623, precision: 0.9401, recall: 0.8888, f1: 0.9137, edges-pos-ontonotes_loss: 0.0107
09/16 04:21:52 AM: Evaluate: task edges-pos-ontonotes, batch 141 (157): mcc: 0.9113, acc: 0.8611, precision: 0.9339, recall: 0.8928, f1: 0.9129, edges-pos-ontonotes_loss: 0.0107
09/16 04:21:56 AM: Best result seen so far for edges-pos-ontonotes.
09/16 04:21:56 AM: Best result seen so far for macro.
09/16 04:21:56 AM: Updating LR scheduler:
09/16 04:21:56 AM: 	Best result seen so far for macro_avg: 0.913
09/16 04:21:56 AM: 	# validation passes without improvement: 2
09/16 04:21:56 AM: edges-pos-ontonotes_loss: training: 0.014717 validation: 0.010671
09/16 04:21:56 AM: macro_avg: validation: 0.913479
09/16 04:21:56 AM: micro_avg: validation: 0.000000
09/16 04:21:56 AM: edges-pos-ontonotes_mcc: training: 0.869552 validation: 0.911895
09/16 04:21:56 AM: edges-pos-ontonotes_acc: training: 0.790636 validation: 0.862800
09/16 04:21:56 AM: edges-pos-ontonotes_precision: training: 0.910880 validation: 0.933414
09/16 04:21:56 AM: edges-pos-ontonotes_recall: training: 0.835043 validation: 0.894378
09/16 04:21:56 AM: edges-pos-ontonotes_f1: training: 0.871315 validation: 0.913479
09/16 04:21:56 AM: Global learning rate: 0.0001
09/16 04:21:56 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:22:02 AM: Update 21045: task edges-pos-ontonotes, batch 45 (21045): mcc: 0.8735, acc: 0.7954, precision: 0.9199, recall: 0.8342, f1: 0.8749, edges-pos-ontonotes_loss: 0.0139
09/16 04:22:12 AM: Update 21103: task edges-pos-ontonotes, batch 103 (21103): mcc: 0.8721, acc: 0.7937, precision: 0.9135, recall: 0.8374, f1: 0.8738, edges-pos-ontonotes_loss: 0.0143
09/16 04:22:22 AM: Update 21164: task edges-pos-ontonotes, batch 164 (21164): mcc: 0.8726, acc: 0.7953, precision: 0.9108, recall: 0.8410, f1: 0.8745, edges-pos-ontonotes_loss: 0.0143
09/16 04:22:32 AM: Update 21238: task edges-pos-ontonotes, batch 238 (21238): mcc: 0.8735, acc: 0.7964, precision: 0.9103, recall: 0.8430, f1: 0.8754, edges-pos-ontonotes_loss: 0.0143
09/16 04:22:42 AM: Update 21314: task edges-pos-ontonotes, batch 314 (21314): mcc: 0.8740, acc: 0.7974, precision: 0.9108, recall: 0.8435, f1: 0.8759, edges-pos-ontonotes_loss: 0.0142
09/16 04:22:53 AM: Update 21384: task edges-pos-ontonotes, batch 384 (21384): mcc: 0.8745, acc: 0.7979, precision: 0.9109, recall: 0.8443, f1: 0.8763, edges-pos-ontonotes_loss: 0.0141
09/16 04:23:04 AM: Update 21387: task edges-pos-ontonotes, batch 387 (21387): mcc: 0.8740, acc: 0.7972, precision: 0.9106, recall: 0.8437, f1: 0.8759, edges-pos-ontonotes_loss: 0.0142
09/16 04:23:14 AM: Update 21431: task edges-pos-ontonotes, batch 431 (21431): mcc: 0.8728, acc: 0.7957, precision: 0.9091, recall: 0.8429, f1: 0.8747, edges-pos-ontonotes_loss: 0.0143
09/16 04:23:24 AM: Update 21484: task edges-pos-ontonotes, batch 484 (21484): mcc: 0.8720, acc: 0.7948, precision: 0.9081, recall: 0.8422, f1: 0.8739, edges-pos-ontonotes_loss: 0.0144
09/16 04:23:34 AM: Update 21533: task edges-pos-ontonotes, batch 533 (21533): mcc: 0.8714, acc: 0.7942, precision: 0.9073, recall: 0.8419, f1: 0.8734, edges-pos-ontonotes_loss: 0.0145
09/16 04:23:44 AM: Update 21587: task edges-pos-ontonotes, batch 587 (21587): mcc: 0.8712, acc: 0.7940, precision: 0.9071, recall: 0.8417, f1: 0.8732, edges-pos-ontonotes_loss: 0.0146
09/16 04:23:54 AM: Update 21644: task edges-pos-ontonotes, batch 644 (21644): mcc: 0.8712, acc: 0.7940, precision: 0.9069, recall: 0.8419, f1: 0.8731, edges-pos-ontonotes_loss: 0.0147
09/16 04:24:06 AM: Update 21700: task edges-pos-ontonotes, batch 700 (21700): mcc: 0.8712, acc: 0.7941, precision: 0.9069, recall: 0.8419, f1: 0.8732, edges-pos-ontonotes_loss: 0.0147
09/16 04:24:16 AM: Update 21744: task edges-pos-ontonotes, batch 744 (21744): mcc: 0.8712, acc: 0.7941, precision: 0.9067, recall: 0.8420, f1: 0.8731, edges-pos-ontonotes_loss: 0.0147
09/16 04:24:26 AM: Update 21792: task edges-pos-ontonotes, batch 792 (21792): mcc: 0.8713, acc: 0.7944, precision: 0.9067, recall: 0.8422, f1: 0.8733, edges-pos-ontonotes_loss: 0.0147
09/16 04:24:37 AM: Update 21841: task edges-pos-ontonotes, batch 841 (21841): mcc: 0.8715, acc: 0.7948, precision: 0.9068, recall: 0.8425, f1: 0.8734, edges-pos-ontonotes_loss: 0.0147
09/16 04:24:47 AM: Update 21889: task edges-pos-ontonotes, batch 889 (21889): mcc: 0.8718, acc: 0.7955, precision: 0.9070, recall: 0.8430, f1: 0.8738, edges-pos-ontonotes_loss: 0.0147
09/16 04:24:57 AM: Update 21945: task edges-pos-ontonotes, batch 945 (21945): mcc: 0.8719, acc: 0.7957, precision: 0.9070, recall: 0.8431, f1: 0.8739, edges-pos-ontonotes_loss: 0.0147
09/16 04:25:07 AM: ***** Step 22000 / Validation 22 *****
09/16 04:25:07 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:25:07 AM: Validating...
09/16 04:25:07 AM: Evaluate: task edges-pos-ontonotes, batch 2 (157): mcc: 0.9213, acc: 0.8797, precision: 0.9569, recall: 0.8901, f1: 0.9223, edges-pos-ontonotes_loss: 0.0098
09/16 04:25:17 AM: Evaluate: task edges-pos-ontonotes, batch 69 (157): mcc: 0.9101, acc: 0.8565, precision: 0.9493, recall: 0.8760, f1: 0.9112, edges-pos-ontonotes_loss: 0.0111
09/16 04:25:27 AM: Evaluate: task edges-pos-ontonotes, batch 120 (157): mcc: 0.9127, acc: 0.8617, precision: 0.9461, recall: 0.8840, f1: 0.9140, edges-pos-ontonotes_loss: 0.0106
09/16 04:25:35 AM: Best result seen so far for edges-pos-ontonotes.
09/16 04:25:35 AM: Best result seen so far for macro.
09/16 04:25:35 AM: Updating LR scheduler:
09/16 04:25:35 AM: 	Best result seen so far for macro_avg: 0.915
09/16 04:25:35 AM: 	# validation passes without improvement: 0
09/16 04:25:35 AM: edges-pos-ontonotes_loss: training: 0.014653 validation: 0.010462
09/16 04:25:35 AM: macro_avg: validation: 0.914926
09/16 04:25:35 AM: micro_avg: validation: 0.000000
09/16 04:25:35 AM: edges-pos-ontonotes_mcc: training: 0.872326 validation: 0.913608
09/16 04:25:35 AM: edges-pos-ontonotes_acc: training: 0.796342 validation: 0.864080
09/16 04:25:35 AM: edges-pos-ontonotes_precision: training: 0.907432 validation: 0.943492
09/16 04:25:35 AM: edges-pos-ontonotes_recall: training: 0.843494 validation: 0.888039
09/16 04:25:35 AM: edges-pos-ontonotes_f1: training: 0.874295 validation: 0.914926
09/16 04:25:35 AM: Global learning rate: 0.0001
09/16 04:25:35 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:25:37 AM: Update 22008: task edges-pos-ontonotes, batch 8 (22008): mcc: 0.8766, acc: 0.8031, precision: 0.9095, recall: 0.8497, f1: 0.8786, edges-pos-ontonotes_loss: 0.0146
09/16 04:25:47 AM: Update 22045: task edges-pos-ontonotes, batch 45 (22045): mcc: 0.8715, acc: 0.7979, precision: 0.9078, recall: 0.8416, f1: 0.8734, edges-pos-ontonotes_loss: 0.0153
09/16 04:25:58 AM: Update 22101: task edges-pos-ontonotes, batch 101 (22101): mcc: 0.8752, acc: 0.8029, precision: 0.9102, recall: 0.8464, f1: 0.8772, edges-pos-ontonotes_loss: 0.0150
09/16 04:26:08 AM: Update 22154: task edges-pos-ontonotes, batch 154 (22154): mcc: 0.8765, acc: 0.8047, precision: 0.9113, recall: 0.8478, f1: 0.8784, edges-pos-ontonotes_loss: 0.0147
09/16 04:26:18 AM: Update 22212: task edges-pos-ontonotes, batch 212 (22212): mcc: 0.8769, acc: 0.8052, precision: 0.9124, recall: 0.8475, f1: 0.8788, edges-pos-ontonotes_loss: 0.0146
09/16 04:26:28 AM: Update 22262: task edges-pos-ontonotes, batch 262 (22262): mcc: 0.8777, acc: 0.8062, precision: 0.9130, recall: 0.8485, f1: 0.8796, edges-pos-ontonotes_loss: 0.0144
09/16 04:26:38 AM: Update 22317: task edges-pos-ontonotes, batch 317 (22317): mcc: 0.8778, acc: 0.8062, precision: 0.9130, recall: 0.8487, f1: 0.8797, edges-pos-ontonotes_loss: 0.0144
09/16 04:26:48 AM: Update 22357: task edges-pos-ontonotes, batch 357 (22357): mcc: 0.8778, acc: 0.8063, precision: 0.9129, recall: 0.8488, f1: 0.8797, edges-pos-ontonotes_loss: 0.0144
09/16 04:26:58 AM: Update 22405: task edges-pos-ontonotes, batch 405 (22405): mcc: 0.8775, acc: 0.8058, precision: 0.9128, recall: 0.8484, f1: 0.8794, edges-pos-ontonotes_loss: 0.0144
09/16 04:27:08 AM: Update 22455: task edges-pos-ontonotes, batch 455 (22455): mcc: 0.8777, acc: 0.8062, precision: 0.9127, recall: 0.8488, f1: 0.8796, edges-pos-ontonotes_loss: 0.0144
09/16 04:27:18 AM: Update 22505: task edges-pos-ontonotes, batch 505 (22505): mcc: 0.8779, acc: 0.8063, precision: 0.9127, recall: 0.8491, f1: 0.8797, edges-pos-ontonotes_loss: 0.0145
09/16 04:27:29 AM: Update 22556: task edges-pos-ontonotes, batch 556 (22556): mcc: 0.8782, acc: 0.8068, precision: 0.9130, recall: 0.8495, f1: 0.8801, edges-pos-ontonotes_loss: 0.0145
09/16 04:27:39 AM: Update 22600: task edges-pos-ontonotes, batch 600 (22600): mcc: 0.8782, acc: 0.8070, precision: 0.9131, recall: 0.8494, f1: 0.8801, edges-pos-ontonotes_loss: 0.0145
09/16 04:27:50 AM: Update 22639: task edges-pos-ontonotes, batch 639 (22639): mcc: 0.8780, acc: 0.8067, precision: 0.9130, recall: 0.8490, f1: 0.8798, edges-pos-ontonotes_loss: 0.0145
09/16 04:28:00 AM: Update 22691: task edges-pos-ontonotes, batch 691 (22691): mcc: 0.8778, acc: 0.8065, precision: 0.9127, recall: 0.8489, f1: 0.8796, edges-pos-ontonotes_loss: 0.0144
09/16 04:28:10 AM: Update 22755: task edges-pos-ontonotes, batch 755 (22755): mcc: 0.8783, acc: 0.8072, precision: 0.9130, recall: 0.8495, f1: 0.8801, edges-pos-ontonotes_loss: 0.0142
09/16 04:28:20 AM: Update 22820: task edges-pos-ontonotes, batch 820 (22820): mcc: 0.8785, acc: 0.8075, precision: 0.9134, recall: 0.8497, f1: 0.8804, edges-pos-ontonotes_loss: 0.0141
09/16 04:28:30 AM: Update 22894: task edges-pos-ontonotes, batch 894 (22894): mcc: 0.8792, acc: 0.8082, precision: 0.9138, recall: 0.8505, f1: 0.8810, edges-pos-ontonotes_loss: 0.0139
09/16 04:28:41 AM: Update 22952: task edges-pos-ontonotes, batch 952 (22952): mcc: 0.8793, acc: 0.8084, precision: 0.9139, recall: 0.8507, f1: 0.8811, edges-pos-ontonotes_loss: 0.0138
09/16 04:28:47 AM: ***** Step 23000 / Validation 23 *****
09/16 04:28:47 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:28:47 AM: Validating...
09/16 04:28:51 AM: Evaluate: task edges-pos-ontonotes, batch 27 (157): mcc: 0.9008, acc: 0.8423, precision: 0.9452, recall: 0.8622, f1: 0.9018, edges-pos-ontonotes_loss: 0.0117
09/16 04:29:01 AM: Evaluate: task edges-pos-ontonotes, batch 90 (157): mcc: 0.9100, acc: 0.8565, precision: 0.9471, recall: 0.8779, f1: 0.9112, edges-pos-ontonotes_loss: 0.0109
09/16 04:29:11 AM: Evaluate: task edges-pos-ontonotes, batch 133 (157): mcc: 0.9112, acc: 0.8597, precision: 0.9425, recall: 0.8844, f1: 0.9125, edges-pos-ontonotes_loss: 0.0107
09/16 04:29:16 AM: Updating LR scheduler:
09/16 04:29:16 AM: 	Best result seen so far for macro_avg: 0.915
09/16 04:29:16 AM: 	# validation passes without improvement: 1
09/16 04:29:16 AM: edges-pos-ontonotes_loss: training: 0.013707 validation: 0.010549
09/16 04:29:16 AM: macro_avg: validation: 0.914125
09/16 04:29:16 AM: micro_avg: validation: 0.000000
09/16 04:29:16 AM: edges-pos-ontonotes_mcc: training: 0.880146 validation: 0.912778
09/16 04:29:16 AM: edges-pos-ontonotes_acc: training: 0.809511 validation: 0.863043
09/16 04:29:16 AM: edges-pos-ontonotes_precision: training: 0.914626 validation: 0.942279
09/16 04:29:16 AM: edges-pos-ontonotes_recall: training: 0.851588 validation: 0.887605
09/16 04:29:16 AM: edges-pos-ontonotes_f1: training: 0.881982 validation: 0.914125
09/16 04:29:16 AM: Global learning rate: 0.0001
09/16 04:29:16 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:29:21 AM: Update 23043: task edges-pos-ontonotes, batch 43 (23043): mcc: 0.9077, acc: 0.8472, precision: 0.9380, recall: 0.8820, f1: 0.9091, edges-pos-ontonotes_loss: 0.0109
09/16 04:29:32 AM: Update 23129: task edges-pos-ontonotes, batch 129 (23129): mcc: 0.9077, acc: 0.8460, precision: 0.9386, recall: 0.8815, f1: 0.9091, edges-pos-ontonotes_loss: 0.0108
09/16 04:29:42 AM: Update 23215: task edges-pos-ontonotes, batch 215 (23215): mcc: 0.9096, acc: 0.8485, precision: 0.9392, recall: 0.8844, f1: 0.9110, edges-pos-ontonotes_loss: 0.0106
09/16 04:29:57 AM: Update 23265: task edges-pos-ontonotes, batch 265 (23265): mcc: 0.9096, acc: 0.8484, precision: 0.9398, recall: 0.8839, f1: 0.9110, edges-pos-ontonotes_loss: 0.0106
09/16 04:30:07 AM: Update 23368: task edges-pos-ontonotes, batch 368 (23368): mcc: 0.9084, acc: 0.8464, precision: 0.9399, recall: 0.8814, f1: 0.9097, edges-pos-ontonotes_loss: 0.0109
09/16 04:30:17 AM: Update 23446: task edges-pos-ontonotes, batch 446 (23446): mcc: 0.9081, acc: 0.8463, precision: 0.9400, recall: 0.8808, f1: 0.9094, edges-pos-ontonotes_loss: 0.0109
09/16 04:30:27 AM: Update 23535: task edges-pos-ontonotes, batch 535 (23535): mcc: 0.9075, acc: 0.8457, precision: 0.9394, recall: 0.8802, f1: 0.9088, edges-pos-ontonotes_loss: 0.0109
09/16 04:30:37 AM: Update 23630: task edges-pos-ontonotes, batch 630 (23630): mcc: 0.9050, acc: 0.8424, precision: 0.9377, recall: 0.8772, f1: 0.9064, edges-pos-ontonotes_loss: 0.0113
09/16 04:30:47 AM: Update 23749: task edges-pos-ontonotes, batch 749 (23749): mcc: 0.9009, acc: 0.8362, precision: 0.9349, recall: 0.8720, f1: 0.9023, edges-pos-ontonotes_loss: 0.0118
09/16 04:30:57 AM: Update 23871: task edges-pos-ontonotes, batch 871 (23871): mcc: 0.8980, acc: 0.8319, precision: 0.9329, recall: 0.8683, f1: 0.8995, edges-pos-ontonotes_loss: 0.0122
09/16 04:31:07 AM: Update 23922: task edges-pos-ontonotes, batch 922 (23922): mcc: 0.8951, acc: 0.8278, precision: 0.9305, recall: 0.8652, f1: 0.8966, edges-pos-ontonotes_loss: 0.0123
09/16 04:31:17 AM: Update 23979: task edges-pos-ontonotes, batch 979 (23979): mcc: 0.8920, acc: 0.8231, precision: 0.9275, recall: 0.8620, f1: 0.8935, edges-pos-ontonotes_loss: 0.0126
09/16 04:31:21 AM: ***** Step 24000 / Validation 24 *****
09/16 04:31:21 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:31:21 AM: Validating...
09/16 04:31:28 AM: Evaluate: task edges-pos-ontonotes, batch 47 (157): mcc: 0.9029, acc: 0.8443, precision: 0.9427, recall: 0.8685, f1: 0.9041, edges-pos-ontonotes_loss: 0.0115
09/16 04:31:38 AM: Evaluate: task edges-pos-ontonotes, batch 99 (157): mcc: 0.9085, acc: 0.8551, precision: 0.9402, recall: 0.8813, f1: 0.9098, edges-pos-ontonotes_loss: 0.0110
09/16 04:31:48 AM: Evaluate: task edges-pos-ontonotes, batch 138 (157): mcc: 0.9075, acc: 0.8541, precision: 0.9322, recall: 0.8870, f1: 0.9090, edges-pos-ontonotes_loss: 0.0110
09/16 04:31:52 AM: Updating LR scheduler:
09/16 04:31:52 AM: 	Best result seen so far for macro_avg: 0.915
09/16 04:31:52 AM: 	# validation passes without improvement: 2
09/16 04:31:52 AM: edges-pos-ontonotes_loss: training: 0.012648 validation: 0.010899
09/16 04:31:52 AM: macro_avg: validation: 0.910192
09/16 04:31:52 AM: micro_avg: validation: 0.000000
09/16 04:31:52 AM: edges-pos-ontonotes_mcc: training: 0.891247 validation: 0.908587
09/16 04:31:52 AM: edges-pos-ontonotes_acc: training: 0.822129 validation: 0.856355
09/16 04:31:52 AM: edges-pos-ontonotes_precision: training: 0.926678 validation: 0.932067
09/16 04:31:52 AM: edges-pos-ontonotes_recall: training: 0.861354 validation: 0.889319
09/16 04:31:52 AM: edges-pos-ontonotes_f1: training: 0.892823 validation: 0.910192
09/16 04:31:52 AM: Global learning rate: 0.0001
09/16 04:31:52 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:31:58 AM: Update 24028: task edges-pos-ontonotes, batch 28 (24028): mcc: 0.8669, acc: 0.7887, precision: 0.9000, recall: 0.8401, f1: 0.8690, edges-pos-ontonotes_loss: 0.0159
09/16 04:32:08 AM: Update 24079: task edges-pos-ontonotes, batch 79 (24079): mcc: 0.8676, acc: 0.7889, precision: 0.9029, recall: 0.8388, f1: 0.8696, edges-pos-ontonotes_loss: 0.0158
09/16 04:32:18 AM: Update 24139: task edges-pos-ontonotes, batch 139 (24139): mcc: 0.8670, acc: 0.7878, precision: 0.9030, recall: 0.8376, f1: 0.8691, edges-pos-ontonotes_loss: 0.0158
09/16 04:32:28 AM: Update 24201: task edges-pos-ontonotes, batch 201 (24201): mcc: 0.8667, acc: 0.7871, precision: 0.9034, recall: 0.8366, f1: 0.8687, edges-pos-ontonotes_loss: 0.0158
09/16 04:32:38 AM: Update 24264: task edges-pos-ontonotes, batch 264 (24264): mcc: 0.8665, acc: 0.7867, precision: 0.9050, recall: 0.8347, f1: 0.8684, edges-pos-ontonotes_loss: 0.0156
09/16 04:32:48 AM: Update 24350: task edges-pos-ontonotes, batch 350 (24350): mcc: 0.8671, acc: 0.7873, precision: 0.9067, recall: 0.8342, f1: 0.8690, edges-pos-ontonotes_loss: 0.0153
09/16 04:32:58 AM: Update 24428: task edges-pos-ontonotes, batch 428 (24428): mcc: 0.8674, acc: 0.7876, precision: 0.9081, recall: 0.8335, f1: 0.8692, edges-pos-ontonotes_loss: 0.0151
09/16 04:33:08 AM: Update 24517: task edges-pos-ontonotes, batch 517 (24517): mcc: 0.8682, acc: 0.7885, precision: 0.9095, recall: 0.8338, f1: 0.8700, edges-pos-ontonotes_loss: 0.0150
09/16 04:33:18 AM: Update 24573: task edges-pos-ontonotes, batch 573 (24573): mcc: 0.8687, acc: 0.7891, precision: 0.9093, recall: 0.8348, f1: 0.8705, edges-pos-ontonotes_loss: 0.0149
09/16 04:33:28 AM: Update 24641: task edges-pos-ontonotes, batch 641 (24641): mcc: 0.8696, acc: 0.7905, precision: 0.9096, recall: 0.8363, f1: 0.8714, edges-pos-ontonotes_loss: 0.0148
09/16 04:33:38 AM: Update 24719: task edges-pos-ontonotes, batch 719 (24719): mcc: 0.8702, acc: 0.7914, precision: 0.9099, recall: 0.8373, f1: 0.8721, edges-pos-ontonotes_loss: 0.0147
09/16 04:33:48 AM: Update 24788: task edges-pos-ontonotes, batch 788 (24788): mcc: 0.8710, acc: 0.7925, precision: 0.9101, recall: 0.8385, f1: 0.8729, edges-pos-ontonotes_loss: 0.0146
09/16 04:34:00 AM: Update 24847: task edges-pos-ontonotes, batch 847 (24847): mcc: 0.8713, acc: 0.7929, precision: 0.9102, recall: 0.8391, f1: 0.8732, edges-pos-ontonotes_loss: 0.0146
09/16 04:34:10 AM: Update 24905: task edges-pos-ontonotes, batch 905 (24905): mcc: 0.8710, acc: 0.7927, precision: 0.9094, recall: 0.8391, f1: 0.8729, edges-pos-ontonotes_loss: 0.0147
09/16 04:34:20 AM: Update 24953: task edges-pos-ontonotes, batch 953 (24953): mcc: 0.8709, acc: 0.7927, precision: 0.9090, recall: 0.8394, f1: 0.8728, edges-pos-ontonotes_loss: 0.0147
09/16 04:34:29 AM: ***** Step 25000 / Validation 25 *****
09/16 04:34:29 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:34:29 AM: Validating...
09/16 04:34:30 AM: Evaluate: task edges-pos-ontonotes, batch 5 (157): mcc: 0.9015, acc: 0.8491, precision: 0.9360, recall: 0.8720, f1: 0.9029, edges-pos-ontonotes_loss: 0.0113
09/16 04:34:40 AM: Evaluate: task edges-pos-ontonotes, batch 67 (157): mcc: 0.9120, acc: 0.8588, precision: 0.9512, recall: 0.8777, f1: 0.9130, edges-pos-ontonotes_loss: 0.0107
09/16 04:34:50 AM: Evaluate: task edges-pos-ontonotes, batch 115 (157): mcc: 0.9137, acc: 0.8628, precision: 0.9480, recall: 0.8840, f1: 0.9148, edges-pos-ontonotes_loss: 0.0104
09/16 04:35:00 AM: Best result seen so far for edges-pos-ontonotes.
09/16 04:35:00 AM: Best result seen so far for macro.
09/16 04:35:00 AM: Updating LR scheduler:
09/16 04:35:00 AM: 	Best result seen so far for macro_avg: 0.915
09/16 04:35:00 AM: 	# validation passes without improvement: 0
09/16 04:35:00 AM: edges-pos-ontonotes_loss: training: 0.014664 validation: 0.010298
09/16 04:35:00 AM: macro_avg: validation: 0.915164
09/16 04:35:00 AM: micro_avg: validation: 0.000000
09/16 04:35:00 AM: edges-pos-ontonotes_mcc: training: 0.870926 validation: 0.913885
09/16 04:35:00 AM: edges-pos-ontonotes_acc: training: 0.792812 validation: 0.864112
09/16 04:35:00 AM: edges-pos-ontonotes_precision: training: 0.908666 validation: 0.944789
09/16 04:35:00 AM: edges-pos-ontonotes_recall: training: 0.839689 validation: 0.887340
09/16 04:35:00 AM: edges-pos-ontonotes_f1: training: 0.872817 validation: 0.915164
09/16 04:35:00 AM: Global learning rate: 0.0001
09/16 04:35:00 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:35:00 AM: Update 25003: task edges-pos-ontonotes, batch 3 (25003): mcc: 0.8734, acc: 0.7983, precision: 0.9053, recall: 0.8476, f1: 0.8755, edges-pos-ontonotes_loss: 0.0145
09/16 04:35:10 AM: Update 25054: task edges-pos-ontonotes, batch 54 (25054): mcc: 0.8689, acc: 0.7926, precision: 0.9009, recall: 0.8431, f1: 0.8710, edges-pos-ontonotes_loss: 0.0153
09/16 04:35:21 AM: Update 25109: task edges-pos-ontonotes, batch 109 (25109): mcc: 0.8696, acc: 0.7934, precision: 0.9031, recall: 0.8424, f1: 0.8717, edges-pos-ontonotes_loss: 0.0152
09/16 04:35:39 AM: Update 25160: task edges-pos-ontonotes, batch 160 (25160): mcc: 0.8702, acc: 0.7940, precision: 0.9040, recall: 0.8426, f1: 0.8722, edges-pos-ontonotes_loss: 0.0152
09/16 04:35:49 AM: Update 25214: task edges-pos-ontonotes, batch 214 (25214): mcc: 0.8710, acc: 0.7953, precision: 0.9045, recall: 0.8437, f1: 0.8730, edges-pos-ontonotes_loss: 0.0150
09/16 04:36:00 AM: Update 25261: task edges-pos-ontonotes, batch 261 (25261): mcc: 0.8718, acc: 0.7964, precision: 0.9054, recall: 0.8443, f1: 0.8738, edges-pos-ontonotes_loss: 0.0149
09/16 04:36:10 AM: Update 25311: task edges-pos-ontonotes, batch 311 (25311): mcc: 0.8722, acc: 0.7971, precision: 0.9060, recall: 0.8446, f1: 0.8742, edges-pos-ontonotes_loss: 0.0149
09/16 04:36:20 AM: Update 25361: task edges-pos-ontonotes, batch 361 (25361): mcc: 0.8729, acc: 0.7980, precision: 0.9066, recall: 0.8454, f1: 0.8749, edges-pos-ontonotes_loss: 0.0148
09/16 04:36:30 AM: Update 25410: task edges-pos-ontonotes, batch 410 (25410): mcc: 0.8735, acc: 0.7989, precision: 0.9069, recall: 0.8462, f1: 0.8755, edges-pos-ontonotes_loss: 0.0148
09/16 04:36:40 AM: Update 25464: task edges-pos-ontonotes, batch 464 (25464): mcc: 0.8744, acc: 0.8002, precision: 0.9079, recall: 0.8470, f1: 0.8764, edges-pos-ontonotes_loss: 0.0146
09/16 04:36:50 AM: Update 25502: task edges-pos-ontonotes, batch 502 (25502): mcc: 0.8744, acc: 0.8003, precision: 0.9079, recall: 0.8470, f1: 0.8764, edges-pos-ontonotes_loss: 0.0146
09/16 04:37:00 AM: Update 25552: task edges-pos-ontonotes, batch 552 (25552): mcc: 0.8747, acc: 0.8008, precision: 0.9082, recall: 0.8473, f1: 0.8767, edges-pos-ontonotes_loss: 0.0146
09/16 04:37:10 AM: Update 25605: task edges-pos-ontonotes, batch 605 (25605): mcc: 0.8751, acc: 0.8015, precision: 0.9084, recall: 0.8477, f1: 0.8770, edges-pos-ontonotes_loss: 0.0146
09/16 04:37:20 AM: Update 25651: task edges-pos-ontonotes, batch 651 (25651): mcc: 0.8754, acc: 0.8019, precision: 0.9088, recall: 0.8480, f1: 0.8774, edges-pos-ontonotes_loss: 0.0146
09/16 04:37:31 AM: Update 25697: task edges-pos-ontonotes, batch 697 (25697): mcc: 0.8755, acc: 0.8023, precision: 0.9090, recall: 0.8481, f1: 0.8775, edges-pos-ontonotes_loss: 0.0145
09/16 04:37:41 AM: Update 25744: task edges-pos-ontonotes, batch 744 (25744): mcc: 0.8757, acc: 0.8026, precision: 0.9092, recall: 0.8483, f1: 0.8777, edges-pos-ontonotes_loss: 0.0145
09/16 04:37:51 AM: Update 25787: task edges-pos-ontonotes, batch 787 (25787): mcc: 0.8758, acc: 0.8027, precision: 0.9093, recall: 0.8483, f1: 0.8778, edges-pos-ontonotes_loss: 0.0145
09/16 04:38:01 AM: Update 25841: task edges-pos-ontonotes, batch 841 (25841): mcc: 0.8760, acc: 0.8029, precision: 0.9096, recall: 0.8484, f1: 0.8779, edges-pos-ontonotes_loss: 0.0145
09/16 04:38:11 AM: Update 25889: task edges-pos-ontonotes, batch 889 (25889): mcc: 0.8761, acc: 0.8032, precision: 0.9097, recall: 0.8486, f1: 0.8781, edges-pos-ontonotes_loss: 0.0145
09/16 04:38:21 AM: Update 25942: task edges-pos-ontonotes, batch 942 (25942): mcc: 0.8763, acc: 0.8035, precision: 0.9099, recall: 0.8487, f1: 0.8782, edges-pos-ontonotes_loss: 0.0145
09/16 04:38:31 AM: Update 25995: task edges-pos-ontonotes, batch 995 (25995): mcc: 0.8765, acc: 0.8039, precision: 0.9100, recall: 0.8490, f1: 0.8785, edges-pos-ontonotes_loss: 0.0145
09/16 04:38:32 AM: ***** Step 26000 / Validation 26 *****
09/16 04:38:32 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:38:32 AM: Validating...
09/16 04:38:41 AM: Evaluate: task edges-pos-ontonotes, batch 61 (157): mcc: 0.9089, acc: 0.8542, precision: 0.9493, recall: 0.8737, f1: 0.9099, edges-pos-ontonotes_loss: 0.0113
09/16 04:38:51 AM: Evaluate: task edges-pos-ontonotes, batch 114 (157): mcc: 0.9127, acc: 0.8622, precision: 0.9457, recall: 0.8841, f1: 0.9139, edges-pos-ontonotes_loss: 0.0106
09/16 04:39:01 AM: Best result seen so far for edges-pos-ontonotes.
09/16 04:39:01 AM: Best result seen so far for macro.
09/16 04:39:01 AM: Updating LR scheduler:
09/16 04:39:01 AM: 	Best result seen so far for macro_avg: 0.916
09/16 04:39:01 AM: 	# validation passes without improvement: 0
09/16 04:39:01 AM: edges-pos-ontonotes_loss: training: 0.014486 validation: 0.010372
09/16 04:39:01 AM: macro_avg: validation: 0.915850
09/16 04:39:01 AM: micro_avg: validation: 0.000000
09/16 04:39:01 AM: edges-pos-ontonotes_mcc: training: 0.876521 validation: 0.914523
09/16 04:39:01 AM: edges-pos-ontonotes_acc: training: 0.803883 validation: 0.866059
09/16 04:39:01 AM: edges-pos-ontonotes_precision: training: 0.910039 validation: 0.943501
09/16 04:39:01 AM: edges-pos-ontonotes_recall: training: 0.849010 validation: 0.889774
09/16 04:39:01 AM: edges-pos-ontonotes_f1: training: 0.878466 validation: 0.915850
09/16 04:39:01 AM: Global learning rate: 0.0001
09/16 04:39:01 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:39:01 AM: Update 26003: task edges-pos-ontonotes, batch 3 (26003): mcc: 0.8805, acc: 0.8116, precision: 0.9097, recall: 0.8569, f1: 0.8825, edges-pos-ontonotes_loss: 0.0141
09/16 04:39:11 AM: Update 26059: task edges-pos-ontonotes, batch 59 (26059): mcc: 0.8795, acc: 0.8100, precision: 0.9133, recall: 0.8516, f1: 0.8813, edges-pos-ontonotes_loss: 0.0143
09/16 04:39:21 AM: Update 26105: task edges-pos-ontonotes, batch 105 (26105): mcc: 0.8761, acc: 0.8054, precision: 0.9109, recall: 0.8475, f1: 0.8780, edges-pos-ontonotes_loss: 0.0145
09/16 04:39:32 AM: Update 26178: task edges-pos-ontonotes, batch 178 (26178): mcc: 0.8803, acc: 0.8099, precision: 0.9141, recall: 0.8524, f1: 0.8822, edges-pos-ontonotes_loss: 0.0136
09/16 04:39:42 AM: Update 26235: task edges-pos-ontonotes, batch 235 (26235): mcc: 0.8802, acc: 0.8100, precision: 0.9135, recall: 0.8528, f1: 0.8821, edges-pos-ontonotes_loss: 0.0134
09/16 04:39:52 AM: Update 26293: task edges-pos-ontonotes, batch 293 (26293): mcc: 0.8814, acc: 0.8116, precision: 0.9145, recall: 0.8542, f1: 0.8833, edges-pos-ontonotes_loss: 0.0131
09/16 04:40:02 AM: Update 26356: task edges-pos-ontonotes, batch 356 (26356): mcc: 0.8822, acc: 0.8126, precision: 0.9153, recall: 0.8549, f1: 0.8841, edges-pos-ontonotes_loss: 0.0129
09/16 04:40:12 AM: Update 26412: task edges-pos-ontonotes, batch 412 (26412): mcc: 0.8827, acc: 0.8130, precision: 0.9155, recall: 0.8555, f1: 0.8845, edges-pos-ontonotes_loss: 0.0128
09/16 04:40:22 AM: Update 26497: task edges-pos-ontonotes, batch 497 (26497): mcc: 0.8859, acc: 0.8173, precision: 0.9184, recall: 0.8590, f1: 0.8877, edges-pos-ontonotes_loss: 0.0125
09/16 04:40:32 AM: Update 26581: task edges-pos-ontonotes, batch 581 (26581): mcc: 0.8882, acc: 0.8204, precision: 0.9206, recall: 0.8613, f1: 0.8900, edges-pos-ontonotes_loss: 0.0122
09/16 04:40:42 AM: Update 26660: task edges-pos-ontonotes, batch 660 (26660): mcc: 0.8905, acc: 0.8235, precision: 0.9225, recall: 0.8638, f1: 0.8922, edges-pos-ontonotes_loss: 0.0120
09/16 04:40:52 AM: Update 26727: task edges-pos-ontonotes, batch 727 (26727): mcc: 0.8918, acc: 0.8253, precision: 0.9238, recall: 0.8652, f1: 0.8935, edges-pos-ontonotes_loss: 0.0119
09/16 04:41:02 AM: Update 26810: task edges-pos-ontonotes, batch 810 (26810): mcc: 0.8927, acc: 0.8265, precision: 0.9248, recall: 0.8659, f1: 0.8944, edges-pos-ontonotes_loss: 0.0118
09/16 04:41:12 AM: Update 26894: task edges-pos-ontonotes, batch 894 (26894): mcc: 0.8935, acc: 0.8275, precision: 0.9256, recall: 0.8666, f1: 0.8952, edges-pos-ontonotes_loss: 0.0118
09/16 04:41:22 AM: ***** Step 27000 / Validation 27 *****
09/16 04:41:22 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:41:22 AM: Validating...
09/16 04:41:22 AM: Evaluate: task edges-pos-ontonotes, batch 1 (157): mcc: 0.9213, acc: 0.8671, precision: 0.9595, recall: 0.8876, f1: 0.9221, edges-pos-ontonotes_loss: 0.0097
09/16 04:41:32 AM: Evaluate: task edges-pos-ontonotes, batch 67 (157): mcc: 0.9092, acc: 0.8580, precision: 0.9441, recall: 0.8791, f1: 0.9104, edges-pos-ontonotes_loss: 0.0111
09/16 04:41:43 AM: Evaluate: task edges-pos-ontonotes, batch 116 (157): mcc: 0.9103, acc: 0.8606, precision: 0.9382, recall: 0.8867, f1: 0.9117, edges-pos-ontonotes_loss: 0.0108
09/16 04:41:52 AM: Updating LR scheduler:
09/16 04:41:52 AM: 	Best result seen so far for macro_avg: 0.916
09/16 04:41:52 AM: 	# validation passes without improvement: 1
09/16 04:41:52 AM: edges-pos-ontonotes_loss: training: 0.011677 validation: 0.010634
09/16 04:41:52 AM: macro_avg: validation: 0.913461
09/16 04:41:52 AM: micro_avg: validation: 0.000000
09/16 04:41:52 AM: edges-pos-ontonotes_mcc: training: 0.894371 validation: 0.911912
09/16 04:41:52 AM: edges-pos-ontonotes_acc: training: 0.828677 validation: 0.863763
09/16 04:41:52 AM: edges-pos-ontonotes_precision: training: 0.926463 validation: 0.934880
09/16 04:41:52 AM: edges-pos-ontonotes_recall: training: 0.867488 validation: 0.893002
09/16 04:41:52 AM: edges-pos-ontonotes_f1: training: 0.896006 validation: 0.913461
09/16 04:41:52 AM: Global learning rate: 0.0001
09/16 04:41:52 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:41:53 AM: Update 27008: task edges-pos-ontonotes, batch 8 (27008): mcc: 0.9094, acc: 0.8508, precision: 0.9445, recall: 0.8791, f1: 0.9106, edges-pos-ontonotes_loss: 0.0108
09/16 04:42:03 AM: Update 27092: task edges-pos-ontonotes, batch 92 (27092): mcc: 0.8867, acc: 0.8166, precision: 0.9244, recall: 0.8549, f1: 0.8883, edges-pos-ontonotes_loss: 0.0131
09/16 04:42:13 AM: Update 27211: task edges-pos-ontonotes, batch 211 (27211): mcc: 0.8802, acc: 0.8067, precision: 0.9205, recall: 0.8462, f1: 0.8818, edges-pos-ontonotes_loss: 0.0139
09/16 04:42:23 AM: Update 27345: task edges-pos-ontonotes, batch 345 (27345): mcc: 0.8796, acc: 0.8051, precision: 0.9203, recall: 0.8453, f1: 0.8812, edges-pos-ontonotes_loss: 0.0137
09/16 04:42:33 AM: Update 27351: task edges-pos-ontonotes, batch 351 (27351): mcc: 0.8790, acc: 0.8043, precision: 0.9197, recall: 0.8447, f1: 0.8806, edges-pos-ontonotes_loss: 0.0137
09/16 04:42:44 AM: Update 27409: task edges-pos-ontonotes, batch 409 (27409): mcc: 0.8748, acc: 0.7985, precision: 0.9131, recall: 0.8429, f1: 0.8766, edges-pos-ontonotes_loss: 0.0141
09/16 04:42:54 AM: Update 27466: task edges-pos-ontonotes, batch 466 (27466): mcc: 0.8737, acc: 0.7968, precision: 0.9115, recall: 0.8422, f1: 0.8755, edges-pos-ontonotes_loss: 0.0143
09/16 04:43:04 AM: Update 27522: task edges-pos-ontonotes, batch 522 (27522): mcc: 0.8720, acc: 0.7944, precision: 0.9095, recall: 0.8409, f1: 0.8739, edges-pos-ontonotes_loss: 0.0144
09/16 04:43:14 AM: Update 27582: task edges-pos-ontonotes, batch 582 (27582): mcc: 0.8713, acc: 0.7934, precision: 0.9085, recall: 0.8405, f1: 0.8732, edges-pos-ontonotes_loss: 0.0145
09/16 04:43:24 AM: Update 27639: task edges-pos-ontonotes, batch 639 (27639): mcc: 0.8709, acc: 0.7929, precision: 0.9080, recall: 0.8401, f1: 0.8728, edges-pos-ontonotes_loss: 0.0146
09/16 04:43:34 AM: Update 27682: task edges-pos-ontonotes, batch 682 (27682): mcc: 0.8700, acc: 0.7917, precision: 0.9073, recall: 0.8392, f1: 0.8719, edges-pos-ontonotes_loss: 0.0147
09/16 04:43:44 AM: Update 27774: task edges-pos-ontonotes, batch 774 (27774): mcc: 0.8699, acc: 0.7913, precision: 0.9083, recall: 0.8380, f1: 0.8718, edges-pos-ontonotes_loss: 0.0147
09/16 04:43:55 AM: Update 27864: task edges-pos-ontonotes, batch 864 (27864): mcc: 0.8700, acc: 0.7915, precision: 0.9092, recall: 0.8376, f1: 0.8719, edges-pos-ontonotes_loss: 0.0146
09/16 04:44:05 AM: Update 27951: task edges-pos-ontonotes, batch 951 (27951): mcc: 0.8703, acc: 0.7918, precision: 0.9099, recall: 0.8373, f1: 0.8721, edges-pos-ontonotes_loss: 0.0146
09/16 04:44:13 AM: ***** Step 28000 / Validation 28 *****
09/16 04:44:13 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:44:13 AM: Validating...
09/16 04:44:15 AM: Evaluate: task edges-pos-ontonotes, batch 8 (157): mcc: 0.9029, acc: 0.8522, precision: 0.9261, recall: 0.8840, f1: 0.9046, edges-pos-ontonotes_loss: 0.0113
09/16 04:44:25 AM: Evaluate: task edges-pos-ontonotes, batch 73 (157): mcc: 0.9140, acc: 0.8638, precision: 0.9433, recall: 0.8890, f1: 0.9154, edges-pos-ontonotes_loss: 0.0104
09/16 04:44:35 AM: Evaluate: task edges-pos-ontonotes, batch 118 (157): mcc: 0.9140, acc: 0.8645, precision: 0.9383, recall: 0.8937, f1: 0.9154, edges-pos-ontonotes_loss: 0.0104
09/16 04:44:45 AM: Updating LR scheduler:
09/16 04:44:45 AM: 	Best result seen so far for macro_avg: 0.916
09/16 04:44:45 AM: 	# validation passes without improvement: 2
09/16 04:44:45 AM: edges-pos-ontonotes_loss: training: 0.014541 validation: 0.010356
09/16 04:44:45 AM: macro_avg: validation: 0.915684
09/16 04:44:45 AM: micro_avg: validation: 0.000000
09/16 04:44:45 AM: edges-pos-ontonotes_mcc: training: 0.870508 validation: 0.914125
09/16 04:44:45 AM: edges-pos-ontonotes_acc: training: 0.791999 validation: 0.865541
09/16 04:44:45 AM: edges-pos-ontonotes_precision: training: 0.910111 validation: 0.934735
09/16 04:44:45 AM: edges-pos-ontonotes_recall: training: 0.837557 validation: 0.897394
09/16 04:44:45 AM: edges-pos-ontonotes_f1: training: 0.872328 validation: 0.915684
09/16 04:44:45 AM: Global learning rate: 0.0001
09/16 04:44:45 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:44:45 AM: Update 28003: task edges-pos-ontonotes, batch 3 (28003): mcc: 0.8820, acc: 0.8163, precision: 0.9038, recall: 0.8655, f1: 0.8842, edges-pos-ontonotes_loss: 0.0122
09/16 04:44:55 AM: Update 28063: task edges-pos-ontonotes, batch 63 (28063): mcc: 0.8770, acc: 0.8014, precision: 0.9093, recall: 0.8507, f1: 0.8790, edges-pos-ontonotes_loss: 0.0139
09/16 04:45:05 AM: Update 28139: task edges-pos-ontonotes, batch 139 (28139): mcc: 0.8768, acc: 0.8007, precision: 0.9097, recall: 0.8499, f1: 0.8788, edges-pos-ontonotes_loss: 0.0140
09/16 04:45:16 AM: Update 28202: task edges-pos-ontonotes, batch 202 (28202): mcc: 0.8757, acc: 0.7993, precision: 0.9090, recall: 0.8484, f1: 0.8777, edges-pos-ontonotes_loss: 0.0140
09/16 04:45:26 AM: Update 28270: task edges-pos-ontonotes, batch 270 (28270): mcc: 0.8759, acc: 0.7996, precision: 0.9095, recall: 0.8483, f1: 0.8778, edges-pos-ontonotes_loss: 0.0139
09/16 04:45:36 AM: Update 28320: task edges-pos-ontonotes, batch 320 (28320): mcc: 0.8750, acc: 0.7985, precision: 0.9084, recall: 0.8477, f1: 0.8770, edges-pos-ontonotes_loss: 0.0140
09/16 04:45:46 AM: Update 28376: task edges-pos-ontonotes, batch 376 (28376): mcc: 0.8744, acc: 0.7978, precision: 0.9077, recall: 0.8471, f1: 0.8764, edges-pos-ontonotes_loss: 0.0141
09/16 04:45:56 AM: Update 28431: task edges-pos-ontonotes, batch 431 (28431): mcc: 0.8739, acc: 0.7975, precision: 0.9070, recall: 0.8469, f1: 0.8759, edges-pos-ontonotes_loss: 0.0142
09/16 04:46:06 AM: Update 28486: task edges-pos-ontonotes, batch 486 (28486): mcc: 0.8738, acc: 0.7975, precision: 0.9068, recall: 0.8469, f1: 0.8758, edges-pos-ontonotes_loss: 0.0144
09/16 04:46:16 AM: Update 28542: task edges-pos-ontonotes, batch 542 (28542): mcc: 0.8738, acc: 0.7977, precision: 0.9068, recall: 0.8470, f1: 0.8758, edges-pos-ontonotes_loss: 0.0144
09/16 04:46:26 AM: Update 28598: task edges-pos-ontonotes, batch 598 (28598): mcc: 0.8736, acc: 0.7975, precision: 0.9065, recall: 0.8469, f1: 0.8757, edges-pos-ontonotes_loss: 0.0144
09/16 04:46:37 AM: Update 28639: task edges-pos-ontonotes, batch 639 (28639): mcc: 0.8733, acc: 0.7971, precision: 0.9062, recall: 0.8464, f1: 0.8753, edges-pos-ontonotes_loss: 0.0145
09/16 04:46:47 AM: Update 28687: task edges-pos-ontonotes, batch 687 (28687): mcc: 0.8735, acc: 0.7975, precision: 0.9064, recall: 0.8466, f1: 0.8755, edges-pos-ontonotes_loss: 0.0145
09/16 04:46:57 AM: Update 28742: task edges-pos-ontonotes, batch 742 (28742): mcc: 0.8737, acc: 0.7980, precision: 0.9066, recall: 0.8469, f1: 0.8758, edges-pos-ontonotes_loss: 0.0144
09/16 04:47:07 AM: Update 28792: task edges-pos-ontonotes, batch 792 (28792): mcc: 0.8739, acc: 0.7983, precision: 0.9067, recall: 0.8472, f1: 0.8759, edges-pos-ontonotes_loss: 0.0144
09/16 04:47:17 AM: Update 28840: task edges-pos-ontonotes, batch 840 (28840): mcc: 0.8742, acc: 0.7987, precision: 0.9070, recall: 0.8473, f1: 0.8762, edges-pos-ontonotes_loss: 0.0144
09/16 04:47:27 AM: Update 28889: task edges-pos-ontonotes, batch 889 (28889): mcc: 0.8744, acc: 0.7992, precision: 0.9072, recall: 0.8477, f1: 0.8764, edges-pos-ontonotes_loss: 0.0144
09/16 04:47:38 AM: Update 28933: task edges-pos-ontonotes, batch 933 (28933): mcc: 0.8746, acc: 0.7996, precision: 0.9074, recall: 0.8478, f1: 0.8766, edges-pos-ontonotes_loss: 0.0144
09/16 04:47:48 AM: Update 28982: task edges-pos-ontonotes, batch 982 (28982): mcc: 0.8747, acc: 0.7999, precision: 0.9075, recall: 0.8479, f1: 0.8767, edges-pos-ontonotes_loss: 0.0144
09/16 04:47:52 AM: ***** Step 29000 / Validation 29 *****
09/16 04:47:52 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:47:52 AM: Validating...
09/16 04:47:58 AM: Evaluate: task edges-pos-ontonotes, batch 42 (157): mcc: 0.9065, acc: 0.8507, precision: 0.9480, recall: 0.8703, f1: 0.9075, edges-pos-ontonotes_loss: 0.0112
09/16 04:48:08 AM: Evaluate: task edges-pos-ontonotes, batch 101 (157): mcc: 0.9150, acc: 0.8650, precision: 0.9475, recall: 0.8869, f1: 0.9162, edges-pos-ontonotes_loss: 0.0104
09/16 04:48:19 AM: Evaluate: task edges-pos-ontonotes, batch 144 (157): mcc: 0.9150, acc: 0.8661, precision: 0.9426, recall: 0.8915, f1: 0.9163, edges-pos-ontonotes_loss: 0.0103
09/16 04:48:29 AM: Evaluate: task edges-pos-ontonotes, batch 154 (157): mcc: 0.9159, acc: 0.8679, precision: 0.9427, recall: 0.8932, f1: 0.9173, edges-pos-ontonotes_loss: 0.0102
09/16 04:48:30 AM: Best result seen so far for edges-pos-ontonotes.
09/16 04:48:30 AM: Best result seen so far for macro.
09/16 04:48:30 AM: Updating LR scheduler:
09/16 04:48:30 AM: 	Best result seen so far for macro_avg: 0.917
09/16 04:48:30 AM: 	# validation passes without improvement: 0
09/16 04:48:30 AM: edges-pos-ontonotes_loss: training: 0.014364 validation: 0.010188
09/16 04:48:30 AM: macro_avg: validation: 0.917464
09/16 04:48:30 AM: micro_avg: validation: 0.000000
09/16 04:48:30 AM: edges-pos-ontonotes_mcc: training: 0.874759 validation: 0.916100
09/16 04:48:30 AM: edges-pos-ontonotes_acc: training: 0.800103 validation: 0.868229
09/16 04:48:30 AM: edges-pos-ontonotes_precision: training: 0.907485 validation: 0.942773
09/16 04:48:30 AM: edges-pos-ontonotes_recall: training: 0.848063 validation: 0.893478
09/16 04:48:30 AM: edges-pos-ontonotes_f1: training: 0.876768 validation: 0.917464
09/16 04:48:30 AM: Global learning rate: 0.0001
09/16 04:48:30 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:48:39 AM: Update 29059: task edges-pos-ontonotes, batch 59 (29059): mcc: 0.8810, acc: 0.8112, precision: 0.9139, recall: 0.8539, f1: 0.8829, edges-pos-ontonotes_loss: 0.0145
09/16 04:48:49 AM: Update 29116: task edges-pos-ontonotes, batch 116 (29116): mcc: 0.8819, acc: 0.8120, precision: 0.9151, recall: 0.8544, f1: 0.8837, edges-pos-ontonotes_loss: 0.0144
09/16 04:48:59 AM: Update 29170: task edges-pos-ontonotes, batch 170 (29170): mcc: 0.8814, acc: 0.8112, precision: 0.9150, recall: 0.8536, f1: 0.8832, edges-pos-ontonotes_loss: 0.0142
09/16 04:49:09 AM: Update 29225: task edges-pos-ontonotes, batch 225 (29225): mcc: 0.8812, acc: 0.8112, precision: 0.9144, recall: 0.8538, f1: 0.8831, edges-pos-ontonotes_loss: 0.0141
09/16 04:49:20 AM: Update 29264: task edges-pos-ontonotes, batch 264 (29264): mcc: 0.8808, acc: 0.8105, precision: 0.9141, recall: 0.8534, f1: 0.8827, edges-pos-ontonotes_loss: 0.0141
09/16 04:49:30 AM: Update 29309: task edges-pos-ontonotes, batch 309 (29309): mcc: 0.8808, acc: 0.8107, precision: 0.9138, recall: 0.8535, f1: 0.8826, edges-pos-ontonotes_loss: 0.0141
09/16 04:49:40 AM: Update 29357: task edges-pos-ontonotes, batch 357 (29357): mcc: 0.8805, acc: 0.8103, precision: 0.9136, recall: 0.8531, f1: 0.8823, edges-pos-ontonotes_loss: 0.0141
09/16 04:49:50 AM: Update 29412: task edges-pos-ontonotes, batch 412 (29412): mcc: 0.8800, acc: 0.8096, precision: 0.9135, recall: 0.8524, f1: 0.8819, edges-pos-ontonotes_loss: 0.0143
09/16 04:50:00 AM: Update 29465: task edges-pos-ontonotes, batch 465 (29465): mcc: 0.8805, acc: 0.8103, precision: 0.9139, recall: 0.8529, f1: 0.8823, edges-pos-ontonotes_loss: 0.0142
09/16 04:50:10 AM: Update 29521: task edges-pos-ontonotes, batch 521 (29521): mcc: 0.8808, acc: 0.8108, precision: 0.9142, recall: 0.8532, f1: 0.8827, edges-pos-ontonotes_loss: 0.0142
09/16 04:50:20 AM: Update 29561: task edges-pos-ontonotes, batch 561 (29561): mcc: 0.8803, acc: 0.8102, precision: 0.9137, recall: 0.8528, f1: 0.8822, edges-pos-ontonotes_loss: 0.0142
09/16 04:50:30 AM: Update 29620: task edges-pos-ontonotes, batch 620 (29620): mcc: 0.8807, acc: 0.8107, precision: 0.9139, recall: 0.8532, f1: 0.8825, edges-pos-ontonotes_loss: 0.0140
09/16 04:50:40 AM: Update 29666: task edges-pos-ontonotes, batch 666 (29666): mcc: 0.8809, acc: 0.8110, precision: 0.9139, recall: 0.8536, f1: 0.8827, edges-pos-ontonotes_loss: 0.0139
09/16 04:50:50 AM: Update 29730: task edges-pos-ontonotes, batch 730 (29730): mcc: 0.8811, acc: 0.8113, precision: 0.9141, recall: 0.8540, f1: 0.8830, edges-pos-ontonotes_loss: 0.0138
09/16 04:51:01 AM: Update 29791: task edges-pos-ontonotes, batch 791 (29791): mcc: 0.8815, acc: 0.8119, precision: 0.9143, recall: 0.8545, f1: 0.8834, edges-pos-ontonotes_loss: 0.0136
09/16 04:51:11 AM: Update 29847: task edges-pos-ontonotes, batch 847 (29847): mcc: 0.8819, acc: 0.8125, precision: 0.9147, recall: 0.8549, f1: 0.8838, edges-pos-ontonotes_loss: 0.0135
09/16 04:51:21 AM: Update 29913: task edges-pos-ontonotes, batch 913 (29913): mcc: 0.8827, acc: 0.8134, precision: 0.9153, recall: 0.8558, f1: 0.8845, edges-pos-ontonotes_loss: 0.0134
09/16 04:51:31 AM: Update 29994: task edges-pos-ontonotes, batch 994 (29994): mcc: 0.8841, acc: 0.8152, precision: 0.9167, recall: 0.8572, f1: 0.8859, edges-pos-ontonotes_loss: 0.0131
09/16 04:51:32 AM: ***** Step 30000 / Validation 30 *****
09/16 04:51:32 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:51:32 AM: Validating...
09/16 04:51:41 AM: Evaluate: task edges-pos-ontonotes, batch 62 (157): mcc: 0.9080, acc: 0.8532, precision: 0.9486, recall: 0.8725, f1: 0.9090, edges-pos-ontonotes_loss: 0.0112
09/16 04:51:51 AM: Evaluate: task edges-pos-ontonotes, batch 114 (157): mcc: 0.9120, acc: 0.8607, precision: 0.9460, recall: 0.8825, f1: 0.9132, edges-pos-ontonotes_loss: 0.0106
09/16 04:52:01 AM: Updating LR scheduler:
09/16 04:52:01 AM: 	Best result seen so far for macro_avg: 0.917
09/16 04:52:01 AM: 	# validation passes without improvement: 1
09/16 04:52:01 AM: edges-pos-ontonotes_loss: training: 0.013111 validation: 0.010359
09/16 04:52:01 AM: macro_avg: validation: 0.915572
09/16 04:52:01 AM: micro_avg: validation: 0.000000
09/16 04:52:01 AM: edges-pos-ontonotes_mcc: training: 0.884249 validation: 0.914249
09/16 04:52:01 AM: edges-pos-ontonotes_acc: training: 0.815368 validation: 0.865689
09/16 04:52:01 AM: edges-pos-ontonotes_precision: training: 0.916800 validation: 0.943541
09/16 04:52:01 AM: edges-pos-ontonotes_recall: training: 0.857339 validation: 0.889213
09/16 04:52:01 AM: edges-pos-ontonotes_f1: training: 0.886073 validation: 0.915572
09/16 04:52:01 AM: Global learning rate: 0.0001
09/16 04:52:01 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:52:01 AM: Update 30004: task edges-pos-ontonotes, batch 4 (30004): mcc: 0.9174, acc: 0.8569, precision: 0.9432, recall: 0.8955, f1: 0.9187, edges-pos-ontonotes_loss: 0.0099
09/16 04:52:12 AM: Update 30082: task edges-pos-ontonotes, batch 82 (30082): mcc: 0.9101, acc: 0.8487, precision: 0.9400, recall: 0.8846, f1: 0.9115, edges-pos-ontonotes_loss: 0.0104
09/16 04:52:22 AM: Update 30163: task edges-pos-ontonotes, batch 163 (30163): mcc: 0.9117, acc: 0.8522, precision: 0.9406, recall: 0.8871, f1: 0.9131, edges-pos-ontonotes_loss: 0.0103
09/16 04:52:32 AM: Update 30242: task edges-pos-ontonotes, batch 242 (30242): mcc: 0.9095, acc: 0.8490, precision: 0.9394, recall: 0.8841, f1: 0.9109, edges-pos-ontonotes_loss: 0.0106
09/16 04:52:42 AM: Update 30334: task edges-pos-ontonotes, batch 334 (30334): mcc: 0.9086, acc: 0.8478, precision: 0.9398, recall: 0.8821, f1: 0.9100, edges-pos-ontonotes_loss: 0.0106
09/16 04:52:52 AM: Update 30428: task edges-pos-ontonotes, batch 428 (30428): mcc: 0.9088, acc: 0.8481, precision: 0.9398, recall: 0.8823, f1: 0.9102, edges-pos-ontonotes_loss: 0.0107
09/16 04:53:02 AM: Update 30518: task edges-pos-ontonotes, batch 518 (30518): mcc: 0.9070, acc: 0.8457, precision: 0.9383, recall: 0.8804, f1: 0.9084, edges-pos-ontonotes_loss: 0.0109
09/16 04:53:12 AM: Update 30633: task edges-pos-ontonotes, batch 633 (30633): mcc: 0.9029, acc: 0.8393, precision: 0.9357, recall: 0.8750, f1: 0.9043, edges-pos-ontonotes_loss: 0.0115
09/16 04:53:22 AM: Update 30744: task edges-pos-ontonotes, batch 744 (30744): mcc: 0.8997, acc: 0.8346, precision: 0.9335, recall: 0.8711, f1: 0.9012, edges-pos-ontonotes_loss: 0.0119
09/16 04:53:32 AM: Update 30830: task edges-pos-ontonotes, batch 830 (30830): mcc: 0.8967, acc: 0.8301, precision: 0.9308, recall: 0.8678, f1: 0.8982, edges-pos-ontonotes_loss: 0.0121
09/16 04:53:42 AM: Update 30890: task edges-pos-ontonotes, batch 890 (30890): mcc: 0.8929, acc: 0.8248, precision: 0.9271, recall: 0.8641, f1: 0.8945, edges-pos-ontonotes_loss: 0.0123
09/16 04:53:52 AM: Update 30949: task edges-pos-ontonotes, batch 949 (30949): mcc: 0.8903, acc: 0.8211, precision: 0.9244, recall: 0.8616, f1: 0.8919, edges-pos-ontonotes_loss: 0.0125
09/16 04:54:02 AM: ***** Step 31000 / Validation 31 *****
09/16 04:54:02 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:54:02 AM: Validating...
09/16 04:54:02 AM: Evaluate: task edges-pos-ontonotes, batch 2 (157): mcc: 0.9191, acc: 0.8753, precision: 0.9449, recall: 0.8971, f1: 0.9204, edges-pos-ontonotes_loss: 0.0098
09/16 04:54:12 AM: Evaluate: task edges-pos-ontonotes, batch 66 (157): mcc: 0.9111, acc: 0.8596, precision: 0.9459, recall: 0.8810, f1: 0.9123, edges-pos-ontonotes_loss: 0.0109
09/16 04:54:22 AM: Evaluate: task edges-pos-ontonotes, batch 113 (157): mcc: 0.9121, acc: 0.8619, precision: 0.9406, recall: 0.8878, f1: 0.9134, edges-pos-ontonotes_loss: 0.0105
09/16 04:54:32 AM: Evaluate: task edges-pos-ontonotes, batch 152 (157): mcc: 0.9134, acc: 0.8644, precision: 0.9369, recall: 0.8939, f1: 0.9149, edges-pos-ontonotes_loss: 0.0104
09/16 04:54:34 AM: Updating LR scheduler:
09/16 04:54:34 AM: 	Best result seen so far for macro_avg: 0.917
09/16 04:54:34 AM: 	# validation passes without improvement: 2
09/16 04:54:34 AM: edges-pos-ontonotes_loss: training: 0.012725 validation: 0.010417
09/16 04:54:34 AM: macro_avg: validation: 0.915094
09/16 04:54:34 AM: micro_avg: validation: 0.000000
09/16 04:54:34 AM: edges-pos-ontonotes_mcc: training: 0.887821 validation: 0.913590
09/16 04:54:34 AM: edges-pos-ontonotes_acc: training: 0.817689 validation: 0.864863
09/16 04:54:34 AM: edges-pos-ontonotes_precision: training: 0.922036 validation: 0.936944
09/16 04:54:34 AM: edges-pos-ontonotes_recall: training: 0.859204 validation: 0.894240
09/16 04:54:34 AM: edges-pos-ontonotes_f1: training: 0.889512 validation: 0.915094
09/16 04:54:34 AM: Global learning rate: 0.0001
09/16 04:54:34 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:54:43 AM: Update 31049: task edges-pos-ontonotes, batch 49 (31049): mcc: 0.8700, acc: 0.7910, precision: 0.9049, recall: 0.8415, f1: 0.8721, edges-pos-ontonotes_loss: 0.0153
09/16 04:54:53 AM: Update 31103: task edges-pos-ontonotes, batch 103 (31103): mcc: 0.8698, acc: 0.7918, precision: 0.9050, recall: 0.8409, f1: 0.8718, edges-pos-ontonotes_loss: 0.0154
09/16 04:55:03 AM: Update 31154: task edges-pos-ontonotes, batch 154 (31154): mcc: 0.8687, acc: 0.7899, precision: 0.9061, recall: 0.8379, f1: 0.8707, edges-pos-ontonotes_loss: 0.0153
09/16 04:55:13 AM: Update 31247: task edges-pos-ontonotes, batch 247 (31247): mcc: 0.8694, acc: 0.7906, precision: 0.9090, recall: 0.8365, f1: 0.8712, edges-pos-ontonotes_loss: 0.0150
09/16 04:55:23 AM: Update 31332: task edges-pos-ontonotes, batch 332 (31332): mcc: 0.8700, acc: 0.7915, precision: 0.9105, recall: 0.8363, f1: 0.8718, edges-pos-ontonotes_loss: 0.0147
09/16 04:55:33 AM: Update 31413: task edges-pos-ontonotes, batch 413 (31413): mcc: 0.8707, acc: 0.7924, precision: 0.9119, recall: 0.8363, f1: 0.8725, edges-pos-ontonotes_loss: 0.0145
09/16 04:55:47 AM: Update 31454: task edges-pos-ontonotes, batch 454 (31454): mcc: 0.8711, acc: 0.7929, precision: 0.9122, recall: 0.8366, f1: 0.8728, edges-pos-ontonotes_loss: 0.0145
09/16 04:55:58 AM: Update 31524: task edges-pos-ontonotes, batch 524 (31524): mcc: 0.8721, acc: 0.7941, precision: 0.9120, recall: 0.8388, f1: 0.8739, edges-pos-ontonotes_loss: 0.0144
09/16 04:56:08 AM: Update 31592: task edges-pos-ontonotes, batch 592 (31592): mcc: 0.8728, acc: 0.7953, precision: 0.9118, recall: 0.8403, f1: 0.8746, edges-pos-ontonotes_loss: 0.0143
09/16 04:56:18 AM: Update 31663: task edges-pos-ontonotes, batch 663 (31663): mcc: 0.8734, acc: 0.7960, precision: 0.9118, recall: 0.8415, f1: 0.8752, edges-pos-ontonotes_loss: 0.0142
09/16 04:56:28 AM: Update 31732: task edges-pos-ontonotes, batch 732 (31732): mcc: 0.8739, acc: 0.7966, precision: 0.9119, recall: 0.8422, f1: 0.8757, edges-pos-ontonotes_loss: 0.0142
09/16 04:56:38 AM: Update 31781: task edges-pos-ontonotes, batch 781 (31781): mcc: 0.8738, acc: 0.7966, precision: 0.9113, recall: 0.8427, f1: 0.8756, edges-pos-ontonotes_loss: 0.0142
09/16 04:56:48 AM: Update 31833: task edges-pos-ontonotes, batch 833 (31833): mcc: 0.8736, acc: 0.7965, precision: 0.9105, recall: 0.8430, f1: 0.8755, edges-pos-ontonotes_loss: 0.0142
09/16 04:56:58 AM: Update 31892: task edges-pos-ontonotes, batch 892 (31892): mcc: 0.8735, acc: 0.7964, precision: 0.9100, recall: 0.8433, f1: 0.8754, edges-pos-ontonotes_loss: 0.0143
09/16 04:57:08 AM: Update 31941: task edges-pos-ontonotes, batch 941 (31941): mcc: 0.8734, acc: 0.7966, precision: 0.9095, recall: 0.8436, f1: 0.8753, edges-pos-ontonotes_loss: 0.0143
09/16 04:57:18 AM: Update 31991: task edges-pos-ontonotes, batch 991 (31991): mcc: 0.8735, acc: 0.7967, precision: 0.9093, recall: 0.8439, f1: 0.8754, edges-pos-ontonotes_loss: 0.0143
09/16 04:57:21 AM: ***** Step 32000 / Validation 32 *****
09/16 04:57:21 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:57:21 AM: Validating...
09/16 04:57:28 AM: Evaluate: task edges-pos-ontonotes, batch 49 (157): mcc: 0.9111, acc: 0.8584, precision: 0.9508, recall: 0.8765, f1: 0.9122, edges-pos-ontonotes_loss: 0.0108
09/16 04:57:39 AM: Evaluate: task edges-pos-ontonotes, batch 106 (157): mcc: 0.9171, acc: 0.8682, precision: 0.9495, recall: 0.8889, f1: 0.9182, edges-pos-ontonotes_loss: 0.0101
09/16 04:57:49 AM: Evaluate: task edges-pos-ontonotes, batch 150 (157): mcc: 0.9163, acc: 0.8685, precision: 0.9440, recall: 0.8926, f1: 0.9176, edges-pos-ontonotes_loss: 0.0101
09/16 04:57:50 AM: Best result seen so far for edges-pos-ontonotes.
09/16 04:57:50 AM: Best result seen so far for macro.
09/16 04:57:50 AM: Updating LR scheduler:
09/16 04:57:50 AM: 	Best result seen so far for macro_avg: 0.918
09/16 04:57:50 AM: 	# validation passes without improvement: 0
09/16 04:57:50 AM: edges-pos-ontonotes_loss: training: 0.014307 validation: 0.010070
09/16 04:57:50 AM: macro_avg: validation: 0.917905
09/16 04:57:50 AM: micro_avg: validation: 0.000000
09/16 04:57:50 AM: edges-pos-ontonotes_mcc: training: 0.873412 validation: 0.916575
09/16 04:57:50 AM: edges-pos-ontonotes_acc: training: 0.796647 validation: 0.869139
09/16 04:57:50 AM: edges-pos-ontonotes_precision: training: 0.909126 validation: 0.944072
09/16 04:57:50 AM: edges-pos-ontonotes_recall: training: 0.843967 validation: 0.893150
09/16 04:57:50 AM: edges-pos-ontonotes_f1: training: 0.875336 validation: 0.917905
09/16 04:57:50 AM: Global learning rate: 0.0001
09/16 04:57:50 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:57:59 AM: Update 32048: task edges-pos-ontonotes, batch 48 (32048): mcc: 0.8749, acc: 0.8007, precision: 0.9067, recall: 0.8490, f1: 0.8769, edges-pos-ontonotes_loss: 0.0145
09/16 04:58:09 AM: Update 32093: task edges-pos-ontonotes, batch 93 (32093): mcc: 0.8714, acc: 0.7964, precision: 0.9040, recall: 0.8451, f1: 0.8735, edges-pos-ontonotes_loss: 0.0151
09/16 04:58:19 AM: Update 32145: task edges-pos-ontonotes, batch 145 (32145): mcc: 0.8725, acc: 0.7973, precision: 0.9051, recall: 0.8461, f1: 0.8746, edges-pos-ontonotes_loss: 0.0148
09/16 04:58:29 AM: Update 32197: task edges-pos-ontonotes, batch 197 (32197): mcc: 0.8739, acc: 0.7996, precision: 0.9064, recall: 0.8475, f1: 0.8760, edges-pos-ontonotes_loss: 0.0147
09/16 04:58:39 AM: Update 32250: task edges-pos-ontonotes, batch 250 (32250): mcc: 0.8746, acc: 0.8009, precision: 0.9067, recall: 0.8486, f1: 0.8767, edges-pos-ontonotes_loss: 0.0146
09/16 04:58:49 AM: Update 32307: task edges-pos-ontonotes, batch 307 (32307): mcc: 0.8752, acc: 0.8019, precision: 0.9076, recall: 0.8488, f1: 0.8772, edges-pos-ontonotes_loss: 0.0145
09/16 04:59:00 AM: Update 32357: task edges-pos-ontonotes, batch 357 (32357): mcc: 0.8762, acc: 0.8031, precision: 0.9083, recall: 0.8500, f1: 0.8782, edges-pos-ontonotes_loss: 0.0144
09/16 04:59:10 AM: Update 32397: task edges-pos-ontonotes, batch 397 (32397): mcc: 0.8764, acc: 0.8036, precision: 0.9089, recall: 0.8499, f1: 0.8784, edges-pos-ontonotes_loss: 0.0144
09/16 04:59:20 AM: Update 32454: task edges-pos-ontonotes, batch 454 (32454): mcc: 0.8767, acc: 0.8040, precision: 0.9092, recall: 0.8501, f1: 0.8787, edges-pos-ontonotes_loss: 0.0144
09/16 04:59:30 AM: Update 32506: task edges-pos-ontonotes, batch 506 (32506): mcc: 0.8769, acc: 0.8043, precision: 0.9093, recall: 0.8504, f1: 0.8789, edges-pos-ontonotes_loss: 0.0144
09/16 04:59:40 AM: Update 32553: task edges-pos-ontonotes, batch 553 (32553): mcc: 0.8774, acc: 0.8052, precision: 0.9099, recall: 0.8508, f1: 0.8794, edges-pos-ontonotes_loss: 0.0143
09/16 04:59:50 AM: Update 32608: task edges-pos-ontonotes, batch 608 (32608): mcc: 0.8777, acc: 0.8057, precision: 0.9103, recall: 0.8511, f1: 0.8797, edges-pos-ontonotes_loss: 0.0143
09/16 05:00:00 AM: Update 32660: task edges-pos-ontonotes, batch 660 (32660): mcc: 0.8782, acc: 0.8064, precision: 0.9107, recall: 0.8515, f1: 0.8801, edges-pos-ontonotes_loss: 0.0143
09/16 05:00:10 AM: Update 32703: task edges-pos-ontonotes, batch 703 (32703): mcc: 0.8784, acc: 0.8067, precision: 0.9109, recall: 0.8518, f1: 0.8804, edges-pos-ontonotes_loss: 0.0142
09/16 05:00:21 AM: Update 32741: task edges-pos-ontonotes, batch 741 (32741): mcc: 0.8784, acc: 0.8068, precision: 0.9110, recall: 0.8518, f1: 0.8804, edges-pos-ontonotes_loss: 0.0142
09/16 05:00:31 AM: Update 32794: task edges-pos-ontonotes, batch 794 (32794): mcc: 0.8788, acc: 0.8074, precision: 0.9113, recall: 0.8521, f1: 0.8807, edges-pos-ontonotes_loss: 0.0142
09/16 05:00:41 AM: Update 32845: task edges-pos-ontonotes, batch 845 (32845): mcc: 0.8790, acc: 0.8076, precision: 0.9116, recall: 0.8522, f1: 0.8809, edges-pos-ontonotes_loss: 0.0142
09/16 05:00:51 AM: Update 32897: task edges-pos-ontonotes, batch 897 (32897): mcc: 0.8790, acc: 0.8077, precision: 0.9116, recall: 0.8523, f1: 0.8809, edges-pos-ontonotes_loss: 0.0142
09/16 05:01:01 AM: Update 32943: task edges-pos-ontonotes, batch 943 (32943): mcc: 0.8790, acc: 0.8078, precision: 0.9115, recall: 0.8524, f1: 0.8809, edges-pos-ontonotes_loss: 0.0142
09/16 05:01:11 AM: Update 32991: task edges-pos-ontonotes, batch 991 (32991): mcc: 0.8791, acc: 0.8080, precision: 0.9116, recall: 0.8524, f1: 0.8810, edges-pos-ontonotes_loss: 0.0142
09/16 05:01:12 AM: ***** Step 33000 / Validation 33 *****
09/16 05:01:12 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:01:12 AM: Validating...
09/16 05:01:21 AM: Evaluate: task edges-pos-ontonotes, batch 54 (157): mcc: 0.9097, acc: 0.8548, precision: 0.9503, recall: 0.8742, f1: 0.9107, edges-pos-ontonotes_loss: 0.0110
09/16 05:01:31 AM: Evaluate: task edges-pos-ontonotes, batch 109 (157): mcc: 0.9146, acc: 0.8643, precision: 0.9481, recall: 0.8856, f1: 0.9158, edges-pos-ontonotes_loss: 0.0104
09/16 05:01:41 AM: Evaluate: task edges-pos-ontonotes, batch 152 (157): mcc: 0.9163, acc: 0.8682, precision: 0.9449, recall: 0.8918, f1: 0.9176, edges-pos-ontonotes_loss: 0.0102
09/16 05:01:42 AM: Updating LR scheduler:
09/16 05:01:42 AM: 	Best result seen so far for macro_avg: 0.918
09/16 05:01:42 AM: 	# validation passes without improvement: 1
09/16 05:01:42 AM: edges-pos-ontonotes_loss: training: 0.014190 validation: 0.010176
09/16 05:01:42 AM: macro_avg: validation: 0.917855
09/16 05:01:42 AM: micro_avg: validation: 0.000000
09/16 05:01:42 AM: edges-pos-ontonotes_mcc: training: 0.879149 validation: 0.916551
09/16 05:01:42 AM: edges-pos-ontonotes_acc: training: 0.808031 validation: 0.868800
09/16 05:01:42 AM: edges-pos-ontonotes_precision: training: 0.911662 validation: 0.944961
09/16 05:01:42 AM: edges-pos-ontonotes_recall: training: 0.852478 validation: 0.892261
09/16 05:01:42 AM: edges-pos-ontonotes_f1: training: 0.881077 validation: 0.917855
09/16 05:01:42 AM: Global learning rate: 0.0001
09/16 05:01:42 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:01:56 AM: Update 33019: task edges-pos-ontonotes, batch 19 (33019): mcc: 0.8726, acc: 0.8005, precision: 0.9086, recall: 0.8428, f1: 0.8745, edges-pos-ontonotes_loss: 0.0144
09/16 05:02:06 AM: Update 33071: task edges-pos-ontonotes, batch 71 (33071): mcc: 0.8781, acc: 0.8074, precision: 0.9112, recall: 0.8509, f1: 0.8800, edges-pos-ontonotes_loss: 0.0129
09/16 05:02:16 AM: Update 33137: task edges-pos-ontonotes, batch 137 (33137): mcc: 0.8813, acc: 0.8113, precision: 0.9140, recall: 0.8543, f1: 0.8832, edges-pos-ontonotes_loss: 0.0126
09/16 05:02:27 AM: Update 33201: task edges-pos-ontonotes, batch 201 (33201): mcc: 0.8832, acc: 0.8136, precision: 0.9155, recall: 0.8566, f1: 0.8851, edges-pos-ontonotes_loss: 0.0124
09/16 05:02:37 AM: Update 33266: task edges-pos-ontonotes, batch 266 (33266): mcc: 0.8847, acc: 0.8161, precision: 0.9167, recall: 0.8584, f1: 0.8866, edges-pos-ontonotes_loss: 0.0122
09/16 05:02:47 AM: Update 33325: task edges-pos-ontonotes, batch 325 (33325): mcc: 0.8850, acc: 0.8165, precision: 0.9169, recall: 0.8587, f1: 0.8868, edges-pos-ontonotes_loss: 0.0122
09/16 05:02:57 AM: Update 33397: task edges-pos-ontonotes, batch 397 (33397): mcc: 0.8879, acc: 0.8203, precision: 0.9194, recall: 0.8618, f1: 0.8897, edges-pos-ontonotes_loss: 0.0119
09/16 05:03:07 AM: Update 33477: task edges-pos-ontonotes, batch 477 (33477): mcc: 0.8912, acc: 0.8247, precision: 0.9223, recall: 0.8654, f1: 0.8930, edges-pos-ontonotes_loss: 0.0117
09/16 05:03:17 AM: Update 33563: task edges-pos-ontonotes, batch 563 (33563): mcc: 0.8937, acc: 0.8280, precision: 0.9245, recall: 0.8681, f1: 0.8954, edges-pos-ontonotes_loss: 0.0114
09/16 05:03:28 AM: Update 33645: task edges-pos-ontonotes, batch 645 (33645): mcc: 0.8957, acc: 0.8307, precision: 0.9263, recall: 0.8701, f1: 0.8973, edges-pos-ontonotes_loss: 0.0113
09/16 05:03:38 AM: Update 33739: task edges-pos-ontonotes, batch 739 (33739): mcc: 0.8963, acc: 0.8315, precision: 0.9273, recall: 0.8704, f1: 0.8980, edges-pos-ontonotes_loss: 0.0113
09/16 05:03:48 AM: Update 33827: task edges-pos-ontonotes, batch 827 (33827): mcc: 0.8970, acc: 0.8325, precision: 0.9282, recall: 0.8709, f1: 0.8987, edges-pos-ontonotes_loss: 0.0112
09/16 05:03:58 AM: Update 33917: task edges-pos-ontonotes, batch 917 (33917): mcc: 0.8980, acc: 0.8338, precision: 0.9291, recall: 0.8719, f1: 0.8996, edges-pos-ontonotes_loss: 0.0112
09/16 05:04:07 AM: ***** Step 34000 / Validation 34 *****
09/16 05:04:07 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:04:07 AM: Validating...
09/16 05:04:08 AM: Evaluate: task edges-pos-ontonotes, batch 4 (157): mcc: 0.9067, acc: 0.8616, precision: 0.9305, recall: 0.8873, f1: 0.9084, edges-pos-ontonotes_loss: 0.0110
09/16 05:04:18 AM: Evaluate: task edges-pos-ontonotes, batch 68 (157): mcc: 0.9124, acc: 0.8639, precision: 0.9413, recall: 0.8878, f1: 0.9138, edges-pos-ontonotes_loss: 0.0109
09/16 05:04:28 AM: Evaluate: task edges-pos-ontonotes, batch 119 (157): mcc: 0.9128, acc: 0.8653, precision: 0.9355, recall: 0.8942, f1: 0.9144, edges-pos-ontonotes_loss: 0.0106
09/16 05:04:36 AM: Updating LR scheduler:
09/16 05:04:36 AM: 	Best result seen so far for macro_avg: 0.918
09/16 05:04:36 AM: 	# validation passes without improvement: 2
09/16 05:04:36 AM: edges-pos-ontonotes_loss: training: 0.011338 validation: 0.010477
09/16 05:04:36 AM: macro_avg: validation: 0.915113
09/16 05:04:36 AM: micro_avg: validation: 0.000000
09/16 05:04:36 AM: edges-pos-ontonotes_mcc: training: 0.897666 validation: 0.913499
09/16 05:04:36 AM: edges-pos-ontonotes_acc: training: 0.833159 validation: 0.866800
09/16 05:04:36 AM: edges-pos-ontonotes_precision: training: 0.928923 validation: 0.932097
09/16 05:04:36 AM: edges-pos-ontonotes_recall: training: 0.871438 validation: 0.898738
09/16 05:04:36 AM: edges-pos-ontonotes_f1: training: 0.899263 validation: 0.915113
09/16 05:04:36 AM: Global learning rate: 0.0001
09/16 05:04:36 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:04:38 AM: Update 34031: task edges-pos-ontonotes, batch 31 (34031): mcc: 0.8872, acc: 0.8123, precision: 0.9331, recall: 0.8477, f1: 0.8884, edges-pos-ontonotes_loss: 0.0133
09/16 05:04:48 AM: Update 34143: task edges-pos-ontonotes, batch 143 (34143): mcc: 0.8770, acc: 0.8011, precision: 0.9204, recall: 0.8402, f1: 0.8785, edges-pos-ontonotes_loss: 0.0135
09/16 05:05:00 AM: Update 34271: task edges-pos-ontonotes, batch 271 (34271): mcc: 0.8762, acc: 0.8004, precision: 0.9177, recall: 0.8413, f1: 0.8778, edges-pos-ontonotes_loss: 0.0137
09/16 05:05:10 AM: Update 34329: task edges-pos-ontonotes, batch 329 (34329): mcc: 0.8730, acc: 0.7960, precision: 0.9113, recall: 0.8412, f1: 0.8749, edges-pos-ontonotes_loss: 0.0140
09/16 05:05:20 AM: Update 34390: task edges-pos-ontonotes, batch 390 (34390): mcc: 0.8714, acc: 0.7938, precision: 0.9084, recall: 0.8408, f1: 0.8733, edges-pos-ontonotes_loss: 0.0144
09/16 05:05:30 AM: Update 34447: task edges-pos-ontonotes, batch 447 (34447): mcc: 0.8710, acc: 0.7936, precision: 0.9076, recall: 0.8408, f1: 0.8729, edges-pos-ontonotes_loss: 0.0144
09/16 05:05:41 AM: Update 34504: task edges-pos-ontonotes, batch 504 (34504): mcc: 0.8710, acc: 0.7934, precision: 0.9070, recall: 0.8414, f1: 0.8730, edges-pos-ontonotes_loss: 0.0145
09/16 05:05:51 AM: Update 34558: task edges-pos-ontonotes, batch 558 (34558): mcc: 0.8706, acc: 0.7929, precision: 0.9065, recall: 0.8411, f1: 0.8726, edges-pos-ontonotes_loss: 0.0147
09/16 05:06:01 AM: Update 34607: task edges-pos-ontonotes, batch 607 (34607): mcc: 0.8700, acc: 0.7921, precision: 0.9062, recall: 0.8403, f1: 0.8720, edges-pos-ontonotes_loss: 0.0147
09/16 05:06:11 AM: Update 34696: task edges-pos-ontonotes, batch 696 (34696): mcc: 0.8700, acc: 0.7918, precision: 0.9075, recall: 0.8390, f1: 0.8719, edges-pos-ontonotes_loss: 0.0147
09/16 05:06:21 AM: Update 34777: task edges-pos-ontonotes, batch 777 (34777): mcc: 0.8703, acc: 0.7920, precision: 0.9085, recall: 0.8387, f1: 0.8722, edges-pos-ontonotes_loss: 0.0146
09/16 05:06:31 AM: Update 34871: task edges-pos-ontonotes, batch 871 (34871): mcc: 0.8708, acc: 0.7927, precision: 0.9094, recall: 0.8388, f1: 0.8727, edges-pos-ontonotes_loss: 0.0145
09/16 05:06:41 AM: Update 34935: task edges-pos-ontonotes, batch 935 (34935): mcc: 0.8713, acc: 0.7934, precision: 0.9096, recall: 0.8395, f1: 0.8731, edges-pos-ontonotes_loss: 0.0145
09/16 05:06:51 AM: Update 34998: task edges-pos-ontonotes, batch 998 (34998): mcc: 0.8720, acc: 0.7944, precision: 0.9096, recall: 0.8407, f1: 0.8738, edges-pos-ontonotes_loss: 0.0144
09/16 05:06:52 AM: ***** Step 35000 / Validation 35 *****
09/16 05:06:52 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:06:52 AM: Validating...
09/16 05:07:01 AM: Evaluate: task edges-pos-ontonotes, batch 66 (157): mcc: 0.9142, acc: 0.8635, precision: 0.9483, recall: 0.8847, f1: 0.9154, edges-pos-ontonotes_loss: 0.0104
09/16 05:07:12 AM: Evaluate: task edges-pos-ontonotes, batch 116 (157): mcc: 0.9153, acc: 0.8661, precision: 0.9432, recall: 0.8915, f1: 0.9166, edges-pos-ontonotes_loss: 0.0102
09/16 05:07:21 AM: Updating LR scheduler:
09/16 05:07:21 AM: 	Best result seen so far for macro_avg: 0.918
09/16 05:07:21 AM: 	# validation passes without improvement: 3
09/16 05:07:21 AM: edges-pos-ontonotes_loss: training: 0.014414 validation: 0.010100
09/16 05:07:21 AM: macro_avg: validation: 0.917072
09/16 05:07:21 AM: micro_avg: validation: 0.000000
09/16 05:07:21 AM: edges-pos-ontonotes_mcc: training: 0.871967 validation: 0.915636
09/16 05:07:21 AM: edges-pos-ontonotes_acc: training: 0.794391 validation: 0.867403
09/16 05:07:21 AM: edges-pos-ontonotes_precision: training: 0.909632 validation: 0.940048
09/16 05:07:21 AM: edges-pos-ontonotes_recall: training: 0.840759 validation: 0.895192
09/16 05:07:21 AM: edges-pos-ontonotes_f1: training: 0.873840 validation: 0.917072
09/16 05:07:21 AM: Global learning rate: 0.0001
09/16 05:07:21 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:07:22 AM: Update 35001: task edges-pos-ontonotes, batch 1 (35001): mcc: 0.8667, acc: 0.7922, precision: 0.9080, recall: 0.8323, f1: 0.8685, edges-pos-ontonotes_loss: 0.0149
09/16 05:07:32 AM: Update 35070: task edges-pos-ontonotes, batch 70 (35070): mcc: 0.8758, acc: 0.7998, precision: 0.9093, recall: 0.8484, f1: 0.8778, edges-pos-ontonotes_loss: 0.0140
09/16 05:07:42 AM: Update 35132: task edges-pos-ontonotes, batch 132 (35132): mcc: 0.8774, acc: 0.8022, precision: 0.9119, recall: 0.8490, f1: 0.8793, edges-pos-ontonotes_loss: 0.0138
09/16 05:07:52 AM: Update 35203: task edges-pos-ontonotes, batch 203 (35203): mcc: 0.8788, acc: 0.8040, precision: 0.9132, recall: 0.8504, f1: 0.8807, edges-pos-ontonotes_loss: 0.0135
09/16 05:08:06 AM: Update 35227: task edges-pos-ontonotes, batch 227 (35227): mcc: 0.8782, acc: 0.8030, precision: 0.9126, recall: 0.8499, f1: 0.8801, edges-pos-ontonotes_loss: 0.0136
09/16 05:08:16 AM: Update 35277: task edges-pos-ontonotes, batch 277 (35277): mcc: 0.8764, acc: 0.8010, precision: 0.9097, recall: 0.8491, f1: 0.8784, edges-pos-ontonotes_loss: 0.0139
09/16 05:08:26 AM: Update 35332: task edges-pos-ontonotes, batch 332 (35332): mcc: 0.8756, acc: 0.8001, precision: 0.9087, recall: 0.8485, f1: 0.8776, edges-pos-ontonotes_loss: 0.0141
09/16 05:08:36 AM: Update 35388: task edges-pos-ontonotes, batch 388 (35388): mcc: 0.8751, acc: 0.7995, precision: 0.9081, recall: 0.8482, f1: 0.8771, edges-pos-ontonotes_loss: 0.0142
09/16 05:08:46 AM: Update 35445: task edges-pos-ontonotes, batch 445 (35445): mcc: 0.8751, acc: 0.7996, precision: 0.9078, recall: 0.8484, f1: 0.8771, edges-pos-ontonotes_loss: 0.0142
09/16 05:08:56 AM: Update 35495: task edges-pos-ontonotes, batch 495 (35495): mcc: 0.8750, acc: 0.7995, precision: 0.9075, recall: 0.8485, f1: 0.8770, edges-pos-ontonotes_loss: 0.0142
09/16 05:09:06 AM: Update 35540: task edges-pos-ontonotes, batch 540 (35540): mcc: 0.8747, acc: 0.7992, precision: 0.9073, recall: 0.8482, f1: 0.8768, edges-pos-ontonotes_loss: 0.0143
09/16 05:09:16 AM: Update 35583: task edges-pos-ontonotes, batch 583 (35583): mcc: 0.8750, acc: 0.7996, precision: 0.9072, recall: 0.8488, f1: 0.8770, edges-pos-ontonotes_loss: 0.0143
09/16 05:09:26 AM: Update 35628: task edges-pos-ontonotes, batch 628 (35628): mcc: 0.8750, acc: 0.7997, precision: 0.9073, recall: 0.8488, f1: 0.8771, edges-pos-ontonotes_loss: 0.0143
09/16 05:09:37 AM: Update 35677: task edges-pos-ontonotes, batch 677 (35677): mcc: 0.8756, acc: 0.8007, precision: 0.9077, recall: 0.8495, f1: 0.8776, edges-pos-ontonotes_loss: 0.0143
09/16 05:09:47 AM: Update 35718: task edges-pos-ontonotes, batch 718 (35718): mcc: 0.8756, acc: 0.8009, precision: 0.9077, recall: 0.8496, f1: 0.8777, edges-pos-ontonotes_loss: 0.0143
09/16 05:09:57 AM: Update 35768: task edges-pos-ontonotes, batch 768 (35768): mcc: 0.8758, acc: 0.8013, precision: 0.9079, recall: 0.8498, f1: 0.8779, edges-pos-ontonotes_loss: 0.0143
09/16 05:10:07 AM: Update 35816: task edges-pos-ontonotes, batch 816 (35816): mcc: 0.8763, acc: 0.8021, precision: 0.9083, recall: 0.8503, f1: 0.8783, edges-pos-ontonotes_loss: 0.0142
09/16 05:10:17 AM: Update 35854: task edges-pos-ontonotes, batch 854 (35854): mcc: 0.8763, acc: 0.8021, precision: 0.9083, recall: 0.8502, f1: 0.8783, edges-pos-ontonotes_loss: 0.0142
09/16 05:10:27 AM: Update 35900: task edges-pos-ontonotes, batch 900 (35900): mcc: 0.8765, acc: 0.8025, precision: 0.9085, recall: 0.8504, f1: 0.8785, edges-pos-ontonotes_loss: 0.0142
09/16 05:10:37 AM: Update 35952: task edges-pos-ontonotes, batch 952 (35952): mcc: 0.8767, acc: 0.8030, precision: 0.9088, recall: 0.8506, f1: 0.8787, edges-pos-ontonotes_loss: 0.0142
09/16 05:10:47 AM: ***** Step 36000 / Validation 36 *****
09/16 05:10:47 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:10:47 AM: Validating...
09/16 05:10:47 AM: Evaluate: task edges-pos-ontonotes, batch 4 (157): mcc: 0.9136, acc: 0.8694, precision: 0.9448, recall: 0.8868, f1: 0.9149, edges-pos-ontonotes_loss: 0.0105
09/16 05:10:57 AM: Evaluate: task edges-pos-ontonotes, batch 68 (157): mcc: 0.9143, acc: 0.8634, precision: 0.9491, recall: 0.8841, f1: 0.9155, edges-pos-ontonotes_loss: 0.0107
09/16 05:11:08 AM: Evaluate: task edges-pos-ontonotes, batch 118 (157): mcc: 0.9168, acc: 0.8686, precision: 0.9462, recall: 0.8916, f1: 0.9181, edges-pos-ontonotes_loss: 0.0102
09/16 05:11:16 AM: Best result seen so far for edges-pos-ontonotes.
09/16 05:11:16 AM: Best result seen so far for macro.
09/16 05:11:16 AM: Updating LR scheduler:
09/16 05:11:16 AM: 	Best result seen so far for macro_avg: 0.919
09/16 05:11:16 AM: 	# validation passes without improvement: 0
09/16 05:11:16 AM: edges-pos-ontonotes_loss: training: 0.014196 validation: 0.010028
09/16 05:11:16 AM: macro_avg: validation: 0.919229
09/16 05:11:16 AM: micro_avg: validation: 0.000000
09/16 05:11:16 AM: edges-pos-ontonotes_mcc: training: 0.876908 validation: 0.917879
09/16 05:11:16 AM: edges-pos-ontonotes_acc: training: 0.803338 validation: 0.871509
09/16 05:11:16 AM: edges-pos-ontonotes_precision: training: 0.908963 validation: 0.943722
09/16 05:11:16 AM: edges-pos-ontonotes_recall: training: 0.850759 validation: 0.895976
09/16 05:11:16 AM: edges-pos-ontonotes_f1: training: 0.878898 validation: 0.919229
09/16 05:11:16 AM: Global learning rate: 0.0001
09/16 05:11:16 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:11:18 AM: Update 36006: task edges-pos-ontonotes, batch 6 (36006): mcc: 0.8840, acc: 0.8158, precision: 0.9150, recall: 0.8586, f1: 0.8859, edges-pos-ontonotes_loss: 0.0131
09/16 05:11:28 AM: Update 36066: task edges-pos-ontonotes, batch 66 (36066): mcc: 0.8837, acc: 0.8139, precision: 0.9166, recall: 0.8565, f1: 0.8856, edges-pos-ontonotes_loss: 0.0136
09/16 05:11:38 AM: Update 36120: task edges-pos-ontonotes, batch 120 (36120): mcc: 0.8829, acc: 0.8135, precision: 0.9149, recall: 0.8565, f1: 0.8848, edges-pos-ontonotes_loss: 0.0137
09/16 05:11:49 AM: Update 36166: task edges-pos-ontonotes, batch 166 (36166): mcc: 0.8827, acc: 0.8131, precision: 0.9147, recall: 0.8563, f1: 0.8846, edges-pos-ontonotes_loss: 0.0137
09/16 05:12:00 AM: Update 36221: task edges-pos-ontonotes, batch 221 (36221): mcc: 0.8822, acc: 0.8127, precision: 0.9149, recall: 0.8553, f1: 0.8841, edges-pos-ontonotes_loss: 0.0138
09/16 05:12:10 AM: Update 36275: task edges-pos-ontonotes, batch 275 (36275): mcc: 0.8819, acc: 0.8124, precision: 0.9146, recall: 0.8550, f1: 0.8838, edges-pos-ontonotes_loss: 0.0140
09/16 05:12:20 AM: Update 36328: task edges-pos-ontonotes, batch 328 (36328): mcc: 0.8819, acc: 0.8122, precision: 0.9146, recall: 0.8550, f1: 0.8838, edges-pos-ontonotes_loss: 0.0140
09/16 05:12:30 AM: Update 36372: task edges-pos-ontonotes, batch 372 (36372): mcc: 0.8819, acc: 0.8123, precision: 0.9143, recall: 0.8552, f1: 0.8838, edges-pos-ontonotes_loss: 0.0140
09/16 05:12:40 AM: Update 36424: task edges-pos-ontonotes, batch 424 (36424): mcc: 0.8820, acc: 0.8125, precision: 0.9144, recall: 0.8553, f1: 0.8839, edges-pos-ontonotes_loss: 0.0140
09/16 05:12:50 AM: Update 36474: task edges-pos-ontonotes, batch 474 (36474): mcc: 0.8821, acc: 0.8126, precision: 0.9145, recall: 0.8554, f1: 0.8840, edges-pos-ontonotes_loss: 0.0140
09/16 05:13:00 AM: Update 36518: task edges-pos-ontonotes, batch 518 (36518): mcc: 0.8815, acc: 0.8119, precision: 0.9139, recall: 0.8549, f1: 0.8834, edges-pos-ontonotes_loss: 0.0139
09/16 05:13:10 AM: Update 36580: task edges-pos-ontonotes, batch 580 (36580): mcc: 0.8818, acc: 0.8122, precision: 0.9141, recall: 0.8551, f1: 0.8837, edges-pos-ontonotes_loss: 0.0137
09/16 05:13:20 AM: Update 36636: task edges-pos-ontonotes, batch 636 (36636): mcc: 0.8822, acc: 0.8128, precision: 0.9145, recall: 0.8557, f1: 0.8841, edges-pos-ontonotes_loss: 0.0136
09/16 05:13:30 AM: Update 36708: task edges-pos-ontonotes, batch 708 (36708): mcc: 0.8832, acc: 0.8142, precision: 0.9152, recall: 0.8569, f1: 0.8851, edges-pos-ontonotes_loss: 0.0133
09/16 05:13:40 AM: Update 36762: task edges-pos-ontonotes, batch 762 (36762): mcc: 0.8834, acc: 0.8146, precision: 0.9154, recall: 0.8571, f1: 0.8853, edges-pos-ontonotes_loss: 0.0132
09/16 05:13:50 AM: Update 36822: task edges-pos-ontonotes, batch 822 (36822): mcc: 0.8842, acc: 0.8155, precision: 0.9160, recall: 0.8579, f1: 0.8860, edges-pos-ontonotes_loss: 0.0131
09/16 05:14:00 AM: Update 36904: task edges-pos-ontonotes, batch 904 (36904): mcc: 0.8857, acc: 0.8176, precision: 0.9174, recall: 0.8596, f1: 0.8875, edges-pos-ontonotes_loss: 0.0129
09/16 05:14:10 AM: Update 36984: task edges-pos-ontonotes, batch 984 (36984): mcc: 0.8871, acc: 0.8193, precision: 0.9187, recall: 0.8609, f1: 0.8889, edges-pos-ontonotes_loss: 0.0127
09/16 05:14:12 AM: ***** Step 37000 / Validation 37 *****
09/16 05:14:12 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:14:12 AM: Validating...
09/16 05:14:21 AM: Evaluate: task edges-pos-ontonotes, batch 52 (157): mcc: 0.9089, acc: 0.8549, precision: 0.9486, recall: 0.8744, f1: 0.9100, edges-pos-ontonotes_loss: 0.0109
09/16 05:14:31 AM: Evaluate: task edges-pos-ontonotes, batch 109 (157): mcc: 0.9139, acc: 0.8641, precision: 0.9463, recall: 0.8858, f1: 0.9151, edges-pos-ontonotes_loss: 0.0104
09/16 05:14:41 AM: Evaluate: task edges-pos-ontonotes, batch 152 (157): mcc: 0.9157, acc: 0.8681, precision: 0.9429, recall: 0.8926, f1: 0.9170, edges-pos-ontonotes_loss: 0.0102
09/16 05:14:42 AM: Updating LR scheduler:
09/16 05:14:42 AM: 	Best result seen so far for macro_avg: 0.919
09/16 05:14:42 AM: 	# validation passes without improvement: 1
09/16 05:14:42 AM: edges-pos-ontonotes_loss: training: 0.012631 validation: 0.010143
09/16 05:14:42 AM: macro_avg: validation: 0.917279
09/16 05:14:42 AM: micro_avg: validation: 0.000000
09/16 05:14:42 AM: edges-pos-ontonotes_mcc: training: 0.887319 validation: 0.915922
09/16 05:14:42 AM: edges-pos-ontonotes_acc: training: 0.819669 validation: 0.868588
09/16 05:14:42 AM: edges-pos-ontonotes_precision: training: 0.918882 validation: 0.942983
09/16 05:14:42 AM: edges-pos-ontonotes_recall: training: 0.861217 validation: 0.892938
09/16 05:14:42 AM: edges-pos-ontonotes_f1: training: 0.889116 validation: 0.917279
09/16 05:14:42 AM: Global learning rate: 0.0001
09/16 05:14:42 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:14:51 AM: Update 37063: task edges-pos-ontonotes, batch 63 (37063): mcc: 0.9152, acc: 0.8571, precision: 0.9429, recall: 0.8916, f1: 0.9165, edges-pos-ontonotes_loss: 0.0100
09/16 05:15:05 AM: Update 37105: task edges-pos-ontonotes, batch 105 (37105): mcc: 0.9140, acc: 0.8558, precision: 0.9429, recall: 0.8894, f1: 0.9154, edges-pos-ontonotes_loss: 0.0101
09/16 05:15:15 AM: Update 37209: task edges-pos-ontonotes, batch 209 (37209): mcc: 0.9115, acc: 0.8519, precision: 0.9427, recall: 0.8848, f1: 0.9128, edges-pos-ontonotes_loss: 0.0106
09/16 05:15:25 AM: Update 37307: task edges-pos-ontonotes, batch 307 (37307): mcc: 0.9109, acc: 0.8512, precision: 0.9417, recall: 0.8846, f1: 0.9123, edges-pos-ontonotes_loss: 0.0106
09/16 05:15:35 AM: Update 37393: task edges-pos-ontonotes, batch 393 (37393): mcc: 0.9103, acc: 0.8505, precision: 0.9408, recall: 0.8843, f1: 0.9117, edges-pos-ontonotes_loss: 0.0107
09/16 05:15:45 AM: Update 37492: task edges-pos-ontonotes, batch 492 (37492): mcc: 0.9067, acc: 0.8451, precision: 0.9381, recall: 0.8799, f1: 0.9081, edges-pos-ontonotes_loss: 0.0111
09/16 05:15:55 AM: Update 37616: task edges-pos-ontonotes, batch 616 (37616): mcc: 0.9022, acc: 0.8385, precision: 0.9350, recall: 0.8744, f1: 0.9037, edges-pos-ontonotes_loss: 0.0117
09/16 05:16:07 AM: Update 37731: task edges-pos-ontonotes, batch 731 (37731): mcc: 0.8983, acc: 0.8329, precision: 0.9319, recall: 0.8699, f1: 0.8998, edges-pos-ontonotes_loss: 0.0120
09/16 05:16:17 AM: Update 37783: task edges-pos-ontonotes, batch 783 (37783): mcc: 0.8939, acc: 0.8265, precision: 0.9271, recall: 0.8659, f1: 0.8955, edges-pos-ontonotes_loss: 0.0123
09/16 05:16:27 AM: Update 37842: task edges-pos-ontonotes, batch 842 (37842): mcc: 0.8912, acc: 0.8227, precision: 0.9245, recall: 0.8633, f1: 0.8929, edges-pos-ontonotes_loss: 0.0125
09/16 05:16:37 AM: Update 37898: task edges-pos-ontonotes, batch 898 (37898): mcc: 0.8890, acc: 0.8195, precision: 0.9225, recall: 0.8610, f1: 0.8907, edges-pos-ontonotes_loss: 0.0127
09/16 05:16:47 AM: Update 37957: task edges-pos-ontonotes, batch 957 (37957): mcc: 0.8874, acc: 0.8173, precision: 0.9209, recall: 0.8595, f1: 0.8892, edges-pos-ontonotes_loss: 0.0128
09/16 05:16:54 AM: ***** Step 38000 / Validation 38 *****
09/16 05:16:54 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:16:54 AM: Validating...
09/16 05:16:57 AM: Evaluate: task edges-pos-ontonotes, batch 19 (157): mcc: 0.9016, acc: 0.8451, precision: 0.9410, recall: 0.8676, f1: 0.9028, edges-pos-ontonotes_loss: 0.0115
09/16 05:17:07 AM: Evaluate: task edges-pos-ontonotes, batch 84 (157): mcc: 0.9139, acc: 0.8638, precision: 0.9479, recall: 0.8844, f1: 0.9151, edges-pos-ontonotes_loss: 0.0104
09/16 05:17:17 AM: Evaluate: task edges-pos-ontonotes, batch 128 (157): mcc: 0.9138, acc: 0.8641, precision: 0.9427, recall: 0.8891, f1: 0.9151, edges-pos-ontonotes_loss: 0.0103
09/16 05:17:24 AM: Updating LR scheduler:
09/16 05:17:24 AM: 	Best result seen so far for macro_avg: 0.919
09/16 05:17:24 AM: 	# validation passes without improvement: 2
09/16 05:17:24 AM: edges-pos-ontonotes_loss: training: 0.012908 validation: 0.010232
09/16 05:17:24 AM: macro_avg: validation: 0.916520
09/16 05:17:24 AM: micro_avg: validation: 0.000000
09/16 05:17:24 AM: edges-pos-ontonotes_mcc: training: 0.886507 validation: 0.915119
09/16 05:17:24 AM: edges-pos-ontonotes_acc: training: 0.816018 validation: 0.867276
09/16 05:17:24 AM: edges-pos-ontonotes_precision: training: 0.920050 validation: 0.941205
09/16 05:17:24 AM: edges-pos-ontonotes_recall: training: 0.858573 validation: 0.893097
09/16 05:17:24 AM: edges-pos-ontonotes_f1: training: 0.888249 validation: 0.916520
09/16 05:17:24 AM: Global learning rate: 0.0001
09/16 05:17:24 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:17:27 AM: Update 38016: task edges-pos-ontonotes, batch 16 (38016): mcc: 0.8686, acc: 0.7916, precision: 0.9044, recall: 0.8393, f1: 0.8706, edges-pos-ontonotes_loss: 0.0152
09/16 05:17:38 AM: Update 38061: task edges-pos-ontonotes, batch 61 (38061): mcc: 0.8679, acc: 0.7902, precision: 0.9031, recall: 0.8392, f1: 0.8700, edges-pos-ontonotes_loss: 0.0157
09/16 05:17:48 AM: Update 38142: task edges-pos-ontonotes, batch 142 (38142): mcc: 0.8689, acc: 0.7902, precision: 0.9092, recall: 0.8354, f1: 0.8707, edges-pos-ontonotes_loss: 0.0149
09/16 05:17:58 AM: Update 38229: task edges-pos-ontonotes, batch 229 (38229): mcc: 0.8696, acc: 0.7907, precision: 0.9113, recall: 0.8348, f1: 0.8714, edges-pos-ontonotes_loss: 0.0145
09/16 05:18:08 AM: Update 38329: task edges-pos-ontonotes, batch 329 (38329): mcc: 0.8711, acc: 0.7925, precision: 0.9130, recall: 0.8359, f1: 0.8728, edges-pos-ontonotes_loss: 0.0143
09/16 05:18:18 AM: Update 38402: task edges-pos-ontonotes, batch 402 (38402): mcc: 0.8720, acc: 0.7939, precision: 0.9130, recall: 0.8377, f1: 0.8737, edges-pos-ontonotes_loss: 0.0143
09/16 05:18:28 AM: Update 38477: task edges-pos-ontonotes, batch 477 (38477): mcc: 0.8731, acc: 0.7955, precision: 0.9126, recall: 0.8400, f1: 0.8748, edges-pos-ontonotes_loss: 0.0142
09/16 05:18:39 AM: Update 38546: task edges-pos-ontonotes, batch 546 (38546): mcc: 0.8741, acc: 0.7969, precision: 0.9127, recall: 0.8420, f1: 0.8759, edges-pos-ontonotes_loss: 0.0141
09/16 05:18:49 AM: Update 38623: task edges-pos-ontonotes, batch 623 (38623): mcc: 0.8750, acc: 0.7982, precision: 0.9130, recall: 0.8432, f1: 0.8767, edges-pos-ontonotes_loss: 0.0141
09/16 05:18:59 AM: Update 38687: task edges-pos-ontonotes, batch 687 (38687): mcc: 0.8753, acc: 0.7988, precision: 0.9130, recall: 0.8439, f1: 0.8771, edges-pos-ontonotes_loss: 0.0140
09/16 05:19:10 AM: Update 38739: task edges-pos-ontonotes, batch 739 (38739): mcc: 0.8747, acc: 0.7983, precision: 0.9118, recall: 0.8439, f1: 0.8766, edges-pos-ontonotes_loss: 0.0141
09/16 05:19:20 AM: Update 38795: task edges-pos-ontonotes, batch 795 (38795): mcc: 0.8744, acc: 0.7980, precision: 0.9110, recall: 0.8441, f1: 0.8763, edges-pos-ontonotes_loss: 0.0141
09/16 05:19:30 AM: Update 38857: task edges-pos-ontonotes, batch 857 (38857): mcc: 0.8744, acc: 0.7981, precision: 0.9105, recall: 0.8445, f1: 0.8763, edges-pos-ontonotes_loss: 0.0142
09/16 05:19:40 AM: Update 38911: task edges-pos-ontonotes, batch 911 (38911): mcc: 0.8745, acc: 0.7984, precision: 0.9102, recall: 0.8450, f1: 0.8764, edges-pos-ontonotes_loss: 0.0142
09/16 05:19:50 AM: Update 38970: task edges-pos-ontonotes, batch 970 (38970): mcc: 0.8747, acc: 0.7988, precision: 0.9100, recall: 0.8455, f1: 0.8766, edges-pos-ontonotes_loss: 0.0142
09/16 05:19:57 AM: ***** Step 39000 / Validation 39 *****
09/16 05:19:57 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:19:57 AM: Validating...
09/16 05:20:00 AM: Evaluate: task edges-pos-ontonotes, batch 22 (157): mcc: 0.9022, acc: 0.8448, precision: 0.9444, recall: 0.8657, f1: 0.9033, edges-pos-ontonotes_loss: 0.0112
09/16 05:20:15 AM: Evaluate: task edges-pos-ontonotes, batch 68 (157): mcc: 0.9144, acc: 0.8626, precision: 0.9523, recall: 0.8813, f1: 0.9154, edges-pos-ontonotes_loss: 0.0104
09/16 05:20:25 AM: Evaluate: task edges-pos-ontonotes, batch 122 (157): mcc: 0.9167, acc: 0.8672, precision: 0.9495, recall: 0.8883, f1: 0.9179, edges-pos-ontonotes_loss: 0.0100
09/16 05:20:32 AM: Updating LR scheduler:
09/16 05:20:32 AM: 	Best result seen so far for macro_avg: 0.919
09/16 05:20:32 AM: 	# validation passes without improvement: 3
09/16 05:20:32 AM: edges-pos-ontonotes_loss: training: 0.014224 validation: 0.009937
09/16 05:20:32 AM: macro_avg: validation: 0.918142
09/16 05:20:32 AM: micro_avg: validation: 0.000000
09/16 05:20:32 AM: edges-pos-ontonotes_mcc: training: 0.874538 validation: 0.916890
09/16 05:20:32 AM: edges-pos-ontonotes_acc: training: 0.798698 validation: 0.868546
09/16 05:20:32 AM: edges-pos-ontonotes_precision: training: 0.909819 validation: 0.946738
09/16 05:20:32 AM: edges-pos-ontonotes_recall: training: 0.845453 validation: 0.891224
09/16 05:20:32 AM: edges-pos-ontonotes_f1: training: 0.876456 validation: 0.918142
09/16 05:20:32 AM: Global learning rate: 0.0001
09/16 05:20:32 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:20:35 AM: Update 39012: task edges-pos-ontonotes, batch 12 (39012): mcc: 0.8749, acc: 0.7996, precision: 0.9117, recall: 0.8444, f1: 0.8768, edges-pos-ontonotes_loss: 0.0140
09/16 05:20:45 AM: Update 39066: task edges-pos-ontonotes, batch 66 (39066): mcc: 0.8780, acc: 0.8053, precision: 0.9092, recall: 0.8527, f1: 0.8800, edges-pos-ontonotes_loss: 0.0143
09/16 05:20:55 AM: Update 39121: task edges-pos-ontonotes, batch 121 (39121): mcc: 0.8783, acc: 0.8058, precision: 0.9089, recall: 0.8535, f1: 0.8803, edges-pos-ontonotes_loss: 0.0142
09/16 05:21:05 AM: Update 39182: task edges-pos-ontonotes, batch 182 (39182): mcc: 0.8789, acc: 0.8064, precision: 0.9097, recall: 0.8538, f1: 0.8808, edges-pos-ontonotes_loss: 0.0142
09/16 05:21:15 AM: Update 39239: task edges-pos-ontonotes, batch 239 (39239): mcc: 0.8788, acc: 0.8062, precision: 0.9099, recall: 0.8534, f1: 0.8807, edges-pos-ontonotes_loss: 0.0142
09/16 05:21:25 AM: Update 39288: task edges-pos-ontonotes, batch 288 (39288): mcc: 0.8794, acc: 0.8074, precision: 0.9100, recall: 0.8544, f1: 0.8814, edges-pos-ontonotes_loss: 0.0141
09/16 05:21:35 AM: Update 39324: task edges-pos-ontonotes, batch 324 (39324): mcc: 0.8790, acc: 0.8071, precision: 0.9100, recall: 0.8537, f1: 0.8810, edges-pos-ontonotes_loss: 0.0141
09/16 05:21:45 AM: Update 39383: task edges-pos-ontonotes, batch 383 (39383): mcc: 0.8795, acc: 0.8079, precision: 0.9108, recall: 0.8540, f1: 0.8815, edges-pos-ontonotes_loss: 0.0140
09/16 05:21:55 AM: Update 39442: task edges-pos-ontonotes, batch 442 (39442): mcc: 0.8796, acc: 0.8082, precision: 0.9110, recall: 0.8539, f1: 0.8815, edges-pos-ontonotes_loss: 0.0141
09/16 05:22:05 AM: Update 39495: task edges-pos-ontonotes, batch 495 (39495): mcc: 0.8798, acc: 0.8086, precision: 0.9113, recall: 0.8540, f1: 0.8817, edges-pos-ontonotes_loss: 0.0141
09/16 05:22:16 AM: Update 39552: task edges-pos-ontonotes, batch 552 (39552): mcc: 0.8802, acc: 0.8092, precision: 0.9116, recall: 0.8544, f1: 0.8821, edges-pos-ontonotes_loss: 0.0140
09/16 05:22:26 AM: Update 39606: task edges-pos-ontonotes, batch 606 (39606): mcc: 0.8803, acc: 0.8095, precision: 0.9117, recall: 0.8547, f1: 0.8823, edges-pos-ontonotes_loss: 0.0140
09/16 05:22:36 AM: Update 39649: task edges-pos-ontonotes, batch 649 (39649): mcc: 0.8804, acc: 0.8096, precision: 0.9118, recall: 0.8548, f1: 0.8823, edges-pos-ontonotes_loss: 0.0140
09/16 05:22:46 AM: Update 39707: task edges-pos-ontonotes, batch 707 (39707): mcc: 0.8803, acc: 0.8095, precision: 0.9118, recall: 0.8545, f1: 0.8822, edges-pos-ontonotes_loss: 0.0140
09/16 05:22:56 AM: Update 39761: task edges-pos-ontonotes, batch 761 (39761): mcc: 0.8808, acc: 0.8103, precision: 0.9124, recall: 0.8550, f1: 0.8828, edges-pos-ontonotes_loss: 0.0140
09/16 05:23:06 AM: Update 39817: task edges-pos-ontonotes, batch 817 (39817): mcc: 0.8810, acc: 0.8107, precision: 0.9125, recall: 0.8553, f1: 0.8830, edges-pos-ontonotes_loss: 0.0140
09/16 05:23:16 AM: Update 39871: task edges-pos-ontonotes, batch 871 (39871): mcc: 0.8812, acc: 0.8109, precision: 0.9127, recall: 0.8554, f1: 0.8831, edges-pos-ontonotes_loss: 0.0140
09/16 05:23:26 AM: Update 39932: task edges-pos-ontonotes, batch 932 (39932): mcc: 0.8812, acc: 0.8110, precision: 0.9127, recall: 0.8554, f1: 0.8831, edges-pos-ontonotes_loss: 0.0140
09/16 05:23:36 AM: Update 39987: task edges-pos-ontonotes, batch 987 (39987): mcc: 0.8812, acc: 0.8110, precision: 0.9128, recall: 0.8554, f1: 0.8831, edges-pos-ontonotes_loss: 0.0139
09/16 05:23:38 AM: ***** Step 40000 / Validation 40 *****
09/16 05:23:38 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:23:38 AM: Validating...
09/16 05:23:46 AM: Evaluate: task edges-pos-ontonotes, batch 58 (157): mcc: 0.9098, acc: 0.8553, precision: 0.9514, recall: 0.8735, f1: 0.9108, edges-pos-ontonotes_loss: 0.0109
09/16 05:23:56 AM: Evaluate: task edges-pos-ontonotes, batch 114 (157): mcc: 0.9145, acc: 0.8643, precision: 0.9482, recall: 0.8853, f1: 0.9157, edges-pos-ontonotes_loss: 0.0103
09/16 05:24:05 AM: Updating LR scheduler:
09/16 05:24:05 AM: 	Best result seen so far for macro_avg: 0.919
09/16 05:24:05 AM: 	# validation passes without improvement: 0
09/16 05:24:05 AM: edges-pos-ontonotes_loss: training: 0.013892 validation: 0.010047
09/16 05:24:05 AM: macro_avg: validation: 0.917772
09/16 05:24:05 AM: micro_avg: validation: 0.000000
09/16 05:24:05 AM: edges-pos-ontonotes_mcc: training: 0.881264 validation: 0.916508
09/16 05:24:05 AM: edges-pos-ontonotes_acc: training: 0.811107 validation: 0.868504
09/16 05:24:05 AM: edges-pos-ontonotes_precision: training: 0.912780 validation: 0.946224
09/16 05:24:05 AM: edges-pos-ontonotes_recall: training: 0.855449 validation: 0.890981
09/16 05:24:05 AM: edges-pos-ontonotes_f1: training: 0.883185 validation: 0.917772
09/16 05:24:05 AM: Global learning rate: 5e-05
09/16 05:24:05 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:24:07 AM: Update 40007: task edges-pos-ontonotes, batch 7 (40007): mcc: 0.8953, acc: 0.8288, precision: 0.9276, recall: 0.8682, f1: 0.8969, edges-pos-ontonotes_loss: 0.0115
09/16 05:24:17 AM: Update 40062: task edges-pos-ontonotes, batch 62 (40062): mcc: 0.8831, acc: 0.8145, precision: 0.9151, recall: 0.8567, f1: 0.8850, edges-pos-ontonotes_loss: 0.0123
09/16 05:24:27 AM: Update 40134: task edges-pos-ontonotes, batch 134 (40134): mcc: 0.8853, acc: 0.8169, precision: 0.9171, recall: 0.8590, f1: 0.8871, edges-pos-ontonotes_loss: 0.0121
09/16 05:24:37 AM: Update 40209: task edges-pos-ontonotes, batch 209 (40209): mcc: 0.8864, acc: 0.8181, precision: 0.9178, recall: 0.8604, f1: 0.8882, edges-pos-ontonotes_loss: 0.0120
09/16 05:24:47 AM: Update 40272: task edges-pos-ontonotes, batch 272 (40272): mcc: 0.8886, acc: 0.8211, precision: 0.9197, recall: 0.8629, f1: 0.8904, edges-pos-ontonotes_loss: 0.0118
09/16 05:24:57 AM: Update 40368: task edges-pos-ontonotes, batch 368 (40368): mcc: 0.8930, acc: 0.8270, precision: 0.9239, recall: 0.8673, f1: 0.8947, edges-pos-ontonotes_loss: 0.0115
09/16 05:25:07 AM: Update 40463: task edges-pos-ontonotes, batch 463 (40463): mcc: 0.8960, acc: 0.8307, precision: 0.9265, recall: 0.8705, f1: 0.8976, edges-pos-ontonotes_loss: 0.0113
09/16 05:25:17 AM: Update 40562: task edges-pos-ontonotes, batch 562 (40562): mcc: 0.8979, acc: 0.8333, precision: 0.9284, recall: 0.8724, f1: 0.8995, edges-pos-ontonotes_loss: 0.0111
09/16 05:25:27 AM: Update 40658: task edges-pos-ontonotes, batch 658 (40658): mcc: 0.8987, acc: 0.8344, precision: 0.9296, recall: 0.8728, f1: 0.9003, edges-pos-ontonotes_loss: 0.0112
09/16 05:25:37 AM: Update 40772: task edges-pos-ontonotes, batch 772 (40772): mcc: 0.8995, acc: 0.8353, precision: 0.9307, recall: 0.8732, f1: 0.9011, edges-pos-ontonotes_loss: 0.0111
09/16 05:25:48 AM: Update 40878: task edges-pos-ontonotes, batch 878 (40878): mcc: 0.9002, acc: 0.8363, precision: 0.9314, recall: 0.8738, f1: 0.9017, edges-pos-ontonotes_loss: 0.0111
09/16 05:25:57 AM: ***** Step 41000 / Validation 41 *****
09/16 05:25:57 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:25:57 AM: Validating...
09/16 05:25:58 AM: Evaluate: task edges-pos-ontonotes, batch 8 (157): mcc: 0.9029, acc: 0.8544, precision: 0.9295, recall: 0.8809, f1: 0.9045, edges-pos-ontonotes_loss: 0.0113
09/16 05:26:08 AM: Evaluate: task edges-pos-ontonotes, batch 78 (157): mcc: 0.9140, acc: 0.8646, precision: 0.9464, recall: 0.8861, f1: 0.9152, edges-pos-ontonotes_loss: 0.0105
09/16 05:26:18 AM: Evaluate: task edges-pos-ontonotes, batch 129 (157): mcc: 0.9137, acc: 0.8649, precision: 0.9396, recall: 0.8919, f1: 0.9151, edges-pos-ontonotes_loss: 0.0103
09/16 05:26:24 AM: Updating LR scheduler:
09/16 05:26:24 AM: 	Best result seen so far for macro_avg: 0.919
09/16 05:26:24 AM: 	# validation passes without improvement: 1
09/16 05:26:24 AM: edges-pos-ontonotes_loss: training: 0.011457 validation: 0.010181
09/16 05:26:24 AM: macro_avg: validation: 0.916487
09/16 05:26:24 AM: micro_avg: validation: 0.000000
09/16 05:26:24 AM: edges-pos-ontonotes_mcc: training: 0.898326 validation: 0.915009
09/16 05:26:24 AM: edges-pos-ontonotes_acc: training: 0.833502 validation: 0.868038
09/16 05:26:24 AM: edges-pos-ontonotes_precision: training: 0.930444 validation: 0.938295
09/16 05:26:24 AM: edges-pos-ontonotes_recall: training: 0.871260 validation: 0.895669
09/16 05:26:24 AM: edges-pos-ontonotes_f1: training: 0.899880 validation: 0.916487
09/16 05:26:24 AM: Global learning rate: 5e-05
09/16 05:26:24 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:26:29 AM: Update 41063: task edges-pos-ontonotes, batch 63 (41063): mcc: 0.8776, acc: 0.8000, precision: 0.9204, recall: 0.8414, f1: 0.8791, edges-pos-ontonotes_loss: 0.0136
09/16 05:26:48 AM: Update 41191: task edges-pos-ontonotes, batch 191 (41191): mcc: 0.8759, acc: 0.7993, precision: 0.9180, recall: 0.8404, f1: 0.8775, edges-pos-ontonotes_loss: 0.0141
09/16 05:26:58 AM: Update 41250: task edges-pos-ontonotes, batch 250 (41250): mcc: 0.8738, acc: 0.7974, precision: 0.9115, recall: 0.8424, f1: 0.8756, edges-pos-ontonotes_loss: 0.0143
09/16 05:27:08 AM: Update 41313: task edges-pos-ontonotes, batch 313 (41313): mcc: 0.8737, acc: 0.7969, precision: 0.9104, recall: 0.8434, f1: 0.8756, edges-pos-ontonotes_loss: 0.0145
09/16 05:27:18 AM: Update 41374: task edges-pos-ontonotes, batch 374 (41374): mcc: 0.8736, acc: 0.7970, precision: 0.9098, recall: 0.8436, f1: 0.8755, edges-pos-ontonotes_loss: 0.0145
09/16 05:27:28 AM: Update 41444: task edges-pos-ontonotes, batch 444 (41444): mcc: 0.8731, acc: 0.7964, precision: 0.9088, recall: 0.8437, f1: 0.8750, edges-pos-ontonotes_loss: 0.0146
09/16 05:27:38 AM: Update 41500: task edges-pos-ontonotes, batch 500 (41500): mcc: 0.8726, acc: 0.7956, precision: 0.9080, recall: 0.8435, f1: 0.8745, edges-pos-ontonotes_loss: 0.0148
09/16 05:27:48 AM: Update 41565: task edges-pos-ontonotes, batch 565 (41565): mcc: 0.8721, acc: 0.7948, precision: 0.9084, recall: 0.8422, f1: 0.8741, edges-pos-ontonotes_loss: 0.0147
09/16 05:27:58 AM: Update 41660: task edges-pos-ontonotes, batch 660 (41660): mcc: 0.8719, acc: 0.7943, precision: 0.9096, recall: 0.8407, f1: 0.8738, edges-pos-ontonotes_loss: 0.0146
09/16 05:28:08 AM: Update 41756: task edges-pos-ontonotes, batch 756 (41756): mcc: 0.8720, acc: 0.7943, precision: 0.9103, recall: 0.8402, f1: 0.8739, edges-pos-ontonotes_loss: 0.0146
09/16 05:28:19 AM: Update 41834: task edges-pos-ontonotes, batch 834 (41834): mcc: 0.8722, acc: 0.7944, precision: 0.9108, recall: 0.8401, f1: 0.8740, edges-pos-ontonotes_loss: 0.0145
09/16 05:28:29 AM: Update 41906: task edges-pos-ontonotes, batch 906 (41906): mcc: 0.8731, acc: 0.7958, precision: 0.9110, recall: 0.8417, f1: 0.8750, edges-pos-ontonotes_loss: 0.0144
09/16 05:28:39 AM: Update 41978: task edges-pos-ontonotes, batch 978 (41978): mcc: 0.8738, acc: 0.7968, precision: 0.9111, recall: 0.8429, f1: 0.8757, edges-pos-ontonotes_loss: 0.0143
09/16 05:28:42 AM: ***** Step 42000 / Validation 42 *****
09/16 05:28:42 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:28:42 AM: Validating...
09/16 05:28:49 AM: Evaluate: task edges-pos-ontonotes, batch 48 (157): mcc: 0.9114, acc: 0.8586, precision: 0.9485, recall: 0.8790, f1: 0.9125, edges-pos-ontonotes_loss: 0.0105
09/16 05:28:59 AM: Evaluate: task edges-pos-ontonotes, batch 107 (157): mcc: 0.9168, acc: 0.8678, precision: 0.9461, recall: 0.8916, f1: 0.9181, edges-pos-ontonotes_loss: 0.0100
09/16 05:29:10 AM: Evaluate: task edges-pos-ontonotes, batch 154 (157): mcc: 0.9169, acc: 0.8695, precision: 0.9412, recall: 0.8964, f1: 0.9183, edges-pos-ontonotes_loss: 0.0099
09/16 05:29:10 AM: Updating LR scheduler:
09/16 05:29:10 AM: 	Best result seen so far for macro_avg: 0.919
09/16 05:29:10 AM: 	# validation passes without improvement: 2
09/16 05:29:10 AM: edges-pos-ontonotes_loss: training: 0.014313 validation: 0.009912
09/16 05:29:10 AM: macro_avg: validation: 0.918442
09/16 05:29:10 AM: micro_avg: validation: 0.000000
09/16 05:29:10 AM: edges-pos-ontonotes_mcc: training: 0.873962 validation: 0.917032
09/16 05:29:10 AM: edges-pos-ontonotes_acc: training: 0.796983 validation: 0.869710
09/16 05:29:10 AM: edges-pos-ontonotes_precision: training: 0.911118 validation: 0.941339
09/16 05:29:10 AM: edges-pos-ontonotes_recall: training: 0.843149 validation: 0.896632
09/16 05:29:10 AM: edges-pos-ontonotes_f1: training: 0.875816 validation: 0.918442
09/16 05:29:10 AM: Global learning rate: 5e-05
09/16 05:29:10 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:29:20 AM: Update 42064: task edges-pos-ontonotes, batch 64 (42064): mcc: 0.8802, acc: 0.8064, precision: 0.9126, recall: 0.8536, f1: 0.8821, edges-pos-ontonotes_loss: 0.0137
09/16 05:29:30 AM: Update 42143: task edges-pos-ontonotes, batch 143 (42143): mcc: 0.8806, acc: 0.8066, precision: 0.9135, recall: 0.8534, f1: 0.8825, edges-pos-ontonotes_loss: 0.0136
09/16 05:29:40 AM: Update 42187: task edges-pos-ontonotes, batch 187 (42187): mcc: 0.8777, acc: 0.8036, precision: 0.9096, recall: 0.8516, f1: 0.8796, edges-pos-ontonotes_loss: 0.0138
09/16 05:29:50 AM: Update 42245: task edges-pos-ontonotes, batch 245 (42245): mcc: 0.8761, acc: 0.8016, precision: 0.9080, recall: 0.8501, f1: 0.8781, edges-pos-ontonotes_loss: 0.0140
09/16 05:30:01 AM: Update 42302: task edges-pos-ontonotes, batch 302 (42302): mcc: 0.8765, acc: 0.8021, precision: 0.9078, recall: 0.8510, f1: 0.8785, edges-pos-ontonotes_loss: 0.0141
09/16 05:30:11 AM: Update 42363: task edges-pos-ontonotes, batch 363 (42363): mcc: 0.8762, acc: 0.8018, precision: 0.9077, recall: 0.8507, f1: 0.8783, edges-pos-ontonotes_loss: 0.0142
09/16 05:30:21 AM: Update 42423: task edges-pos-ontonotes, batch 423 (42423): mcc: 0.8759, acc: 0.8014, precision: 0.9074, recall: 0.8503, f1: 0.8779, edges-pos-ontonotes_loss: 0.0143
09/16 05:30:31 AM: Update 42471: task edges-pos-ontonotes, batch 471 (42471): mcc: 0.8759, acc: 0.8014, precision: 0.9073, recall: 0.8504, f1: 0.8779, edges-pos-ontonotes_loss: 0.0143
09/16 05:30:41 AM: Update 42528: task edges-pos-ontonotes, batch 528 (42528): mcc: 0.8763, acc: 0.8021, precision: 0.9077, recall: 0.8509, f1: 0.8784, edges-pos-ontonotes_loss: 0.0142
09/16 05:30:51 AM: Update 42585: task edges-pos-ontonotes, batch 585 (42585): mcc: 0.8766, acc: 0.8027, precision: 0.9080, recall: 0.8511, f1: 0.8787, edges-pos-ontonotes_loss: 0.0142
09/16 05:31:01 AM: Update 42643: task edges-pos-ontonotes, batch 643 (42643): mcc: 0.8769, acc: 0.8031, precision: 0.9082, recall: 0.8514, f1: 0.8789, edges-pos-ontonotes_loss: 0.0142
09/16 05:31:11 AM: Update 42698: task edges-pos-ontonotes, batch 698 (42698): mcc: 0.8773, acc: 0.8038, precision: 0.9086, recall: 0.8519, f1: 0.8793, edges-pos-ontonotes_loss: 0.0142
09/16 05:31:21 AM: Update 42752: task edges-pos-ontonotes, batch 752 (42752): mcc: 0.8777, acc: 0.8045, precision: 0.9090, recall: 0.8523, f1: 0.8797, edges-pos-ontonotes_loss: 0.0142
09/16 05:31:32 AM: Update 42792: task edges-pos-ontonotes, batch 792 (42792): mcc: 0.8777, acc: 0.8045, precision: 0.9089, recall: 0.8523, f1: 0.8797, edges-pos-ontonotes_loss: 0.0141
09/16 05:31:42 AM: Update 42851: task edges-pos-ontonotes, batch 851 (42851): mcc: 0.8780, acc: 0.8051, precision: 0.9092, recall: 0.8526, f1: 0.8800, edges-pos-ontonotes_loss: 0.0141
09/16 05:31:52 AM: Update 42909: task edges-pos-ontonotes, batch 909 (42909): mcc: 0.8782, acc: 0.8055, precision: 0.9094, recall: 0.8528, f1: 0.8802, edges-pos-ontonotes_loss: 0.0141
09/16 05:32:02 AM: Update 42967: task edges-pos-ontonotes, batch 967 (42967): mcc: 0.8785, acc: 0.8059, precision: 0.9097, recall: 0.8531, f1: 0.8805, edges-pos-ontonotes_loss: 0.0141
09/16 05:32:08 AM: ***** Step 43000 / Validation 43 *****
09/16 05:32:08 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:32:08 AM: Validating...
09/16 05:32:12 AM: Evaluate: task edges-pos-ontonotes, batch 29 (157): mcc: 0.9083, acc: 0.8525, precision: 0.9497, recall: 0.8722, f1: 0.9093, edges-pos-ontonotes_loss: 0.0108
09/16 05:32:22 AM: Evaluate: task edges-pos-ontonotes, batch 95 (157): mcc: 0.9162, acc: 0.8661, precision: 0.9508, recall: 0.8860, f1: 0.9173, edges-pos-ontonotes_loss: 0.0102
09/16 05:32:32 AM: Evaluate: task edges-pos-ontonotes, batch 142 (157): mcc: 0.9169, acc: 0.8685, precision: 0.9466, recall: 0.8915, f1: 0.9182, edges-pos-ontonotes_loss: 0.0100
09/16 05:32:35 AM: Updating LR scheduler:
09/16 05:32:35 AM: 	Best result seen so far for macro_avg: 0.919
09/16 05:32:35 AM: 	# validation passes without improvement: 3
09/16 05:32:35 AM: edges-pos-ontonotes_loss: training: 0.014075 validation: 0.009907
09/16 05:32:35 AM: macro_avg: validation: 0.919202
09/16 05:32:35 AM: micro_avg: validation: 0.000000
09/16 05:32:35 AM: edges-pos-ontonotes_mcc: training: 0.878667 validation: 0.917928
09/16 05:32:35 AM: edges-pos-ontonotes_acc: training: 0.806198 validation: 0.870620
09/16 05:32:35 AM: edges-pos-ontonotes_precision: training: 0.909771 validation: 0.946380
09/16 05:32:35 AM: edges-pos-ontonotes_recall: training: 0.853344 validation: 0.893542
09/16 05:32:35 AM: edges-pos-ontonotes_f1: training: 0.880655 validation: 0.919202
09/16 05:32:35 AM: Global learning rate: 5e-05
09/16 05:32:35 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:32:42 AM: Update 43038: task edges-pos-ontonotes, batch 38 (43038): mcc: 0.8829, acc: 0.8139, precision: 0.9172, recall: 0.8544, f1: 0.8847, edges-pos-ontonotes_loss: 0.0134
09/16 05:33:00 AM: Update 43086: task edges-pos-ontonotes, batch 86 (43086): mcc: 0.8816, acc: 0.8122, precision: 0.9149, recall: 0.8541, f1: 0.8835, edges-pos-ontonotes_loss: 0.0137
09/16 05:33:10 AM: Update 43142: task edges-pos-ontonotes, batch 142 (43142): mcc: 0.8817, acc: 0.8119, precision: 0.9139, recall: 0.8553, f1: 0.8836, edges-pos-ontonotes_loss: 0.0137
09/16 05:33:21 AM: Update 43199: task edges-pos-ontonotes, batch 199 (43199): mcc: 0.8815, acc: 0.8120, precision: 0.9136, recall: 0.8551, f1: 0.8834, edges-pos-ontonotes_loss: 0.0138
09/16 05:33:31 AM: Update 43256: task edges-pos-ontonotes, batch 256 (43256): mcc: 0.8815, acc: 0.8117, precision: 0.9138, recall: 0.8550, f1: 0.8834, edges-pos-ontonotes_loss: 0.0139
09/16 05:33:41 AM: Update 43310: task edges-pos-ontonotes, batch 310 (43310): mcc: 0.8817, acc: 0.8121, precision: 0.9137, recall: 0.8554, f1: 0.8836, edges-pos-ontonotes_loss: 0.0139
09/16 05:33:51 AM: Update 43365: task edges-pos-ontonotes, batch 365 (43365): mcc: 0.8817, acc: 0.8121, precision: 0.9135, recall: 0.8555, f1: 0.8836, edges-pos-ontonotes_loss: 0.0140
09/16 05:34:01 AM: Update 43411: task edges-pos-ontonotes, batch 411 (43411): mcc: 0.8813, acc: 0.8116, precision: 0.9133, recall: 0.8550, f1: 0.8832, edges-pos-ontonotes_loss: 0.0140
09/16 05:34:11 AM: Update 43482: task edges-pos-ontonotes, batch 482 (43482): mcc: 0.8819, acc: 0.8124, precision: 0.9137, recall: 0.8557, f1: 0.8838, edges-pos-ontonotes_loss: 0.0137
09/16 05:34:21 AM: Update 43554: task edges-pos-ontonotes, batch 554 (43554): mcc: 0.8825, acc: 0.8132, precision: 0.9143, recall: 0.8564, f1: 0.8844, edges-pos-ontonotes_loss: 0.0135
09/16 05:34:31 AM: Update 43617: task edges-pos-ontonotes, batch 617 (43617): mcc: 0.8831, acc: 0.8139, precision: 0.9147, recall: 0.8571, f1: 0.8849, edges-pos-ontonotes_loss: 0.0133
09/16 05:34:41 AM: Update 43684: task edges-pos-ontonotes, batch 684 (43684): mcc: 0.8835, acc: 0.8145, precision: 0.9150, recall: 0.8576, f1: 0.8854, edges-pos-ontonotes_loss: 0.0131
09/16 05:34:51 AM: Update 43753: task edges-pos-ontonotes, batch 753 (43753): mcc: 0.8846, acc: 0.8160, precision: 0.9160, recall: 0.8588, f1: 0.8865, edges-pos-ontonotes_loss: 0.0129
09/16 05:35:01 AM: Update 43847: task edges-pos-ontonotes, batch 847 (43847): mcc: 0.8865, acc: 0.8184, precision: 0.9177, recall: 0.8608, f1: 0.8884, edges-pos-ontonotes_loss: 0.0127
09/16 05:35:11 AM: Update 43937: task edges-pos-ontonotes, batch 937 (43937): mcc: 0.8882, acc: 0.8206, precision: 0.9193, recall: 0.8626, f1: 0.8900, edges-pos-ontonotes_loss: 0.0124
09/16 05:35:19 AM: ***** Step 44000 / Validation 44 *****
09/16 05:35:19 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:35:19 AM: Validating...
09/16 05:35:21 AM: Evaluate: task edges-pos-ontonotes, batch 19 (157): mcc: 0.9030, acc: 0.8466, precision: 0.9435, recall: 0.8679, f1: 0.9041, edges-pos-ontonotes_loss: 0.0113
09/16 05:35:32 AM: Evaluate: task edges-pos-ontonotes, batch 88 (157): mcc: 0.9148, acc: 0.8644, precision: 0.9497, recall: 0.8845, f1: 0.9160, edges-pos-ontonotes_loss: 0.0103
09/16 05:35:42 AM: Evaluate: task edges-pos-ontonotes, batch 135 (157): mcc: 0.9157, acc: 0.8672, precision: 0.9448, recall: 0.8907, f1: 0.9170, edges-pos-ontonotes_loss: 0.0101
09/16 05:35:46 AM: Updating LR scheduler:
09/16 05:35:46 AM: 	Best result seen so far for macro_avg: 0.919
09/16 05:35:46 AM: 	# validation passes without improvement: 0
09/16 05:35:46 AM: edges-pos-ontonotes_loss: training: 0.012281 validation: 0.009990
09/16 05:35:46 AM: macro_avg: validation: 0.918470
09/16 05:35:46 AM: micro_avg: validation: 0.000000
09/16 05:35:46 AM: edges-pos-ontonotes_mcc: training: 0.889362 validation: 0.917154
09/16 05:35:46 AM: edges-pos-ontonotes_acc: training: 0.822191 validation: 0.870377
09/16 05:35:46 AM: edges-pos-ontonotes_precision: training: 0.920290 validation: 0.944723
09/16 05:35:46 AM: edges-pos-ontonotes_recall: training: 0.863777 validation: 0.893637
09/16 05:35:46 AM: edges-pos-ontonotes_f1: training: 0.891139 validation: 0.918470
09/16 05:35:46 AM: Global learning rate: 2.5e-05
09/16 05:35:46 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:35:52 AM: Update 44044: task edges-pos-ontonotes, batch 44 (44044): mcc: 0.9062, acc: 0.8440, precision: 0.9393, recall: 0.8779, f1: 0.9076, edges-pos-ontonotes_loss: 0.0108
09/16 05:36:02 AM: Update 44158: task edges-pos-ontonotes, batch 158 (44158): mcc: 0.9069, acc: 0.8451, precision: 0.9414, recall: 0.8773, f1: 0.9082, edges-pos-ontonotes_loss: 0.0109
09/16 05:36:12 AM: Update 44261: task edges-pos-ontonotes, batch 261 (44261): mcc: 0.9073, acc: 0.8459, precision: 0.9407, recall: 0.8787, f1: 0.9087, edges-pos-ontonotes_loss: 0.0108
09/16 05:36:22 AM: Update 44357: task edges-pos-ontonotes, batch 357 (44357): mcc: 0.9045, acc: 0.8422, precision: 0.9386, recall: 0.8754, f1: 0.9059, edges-pos-ontonotes_loss: 0.0111
09/16 05:36:32 AM: Update 44503: task edges-pos-ontonotes, batch 503 (44503): mcc: 0.8987, acc: 0.8333, precision: 0.9349, recall: 0.8677, f1: 0.9001, edges-pos-ontonotes_loss: 0.0119
09/16 05:36:42 AM: Update 44642: task edges-pos-ontonotes, batch 642 (44642): mcc: 0.8947, acc: 0.8275, precision: 0.9323, recall: 0.8627, f1: 0.8962, edges-pos-ontonotes_loss: 0.0124
09/16 05:36:52 AM: Update 44690: task edges-pos-ontonotes, batch 690 (44690): mcc: 0.8907, acc: 0.8222, precision: 0.9275, recall: 0.8596, f1: 0.8923, edges-pos-ontonotes_loss: 0.0126
09/16 05:37:02 AM: Update 44755: task edges-pos-ontonotes, batch 755 (44755): mcc: 0.8879, acc: 0.8182, precision: 0.9244, recall: 0.8572, f1: 0.8895, edges-pos-ontonotes_loss: 0.0128
09/16 05:37:12 AM: Update 44820: task edges-pos-ontonotes, batch 820 (44820): mcc: 0.8862, acc: 0.8157, precision: 0.9223, recall: 0.8557, f1: 0.8878, edges-pos-ontonotes_loss: 0.0130
09/16 05:37:23 AM: Update 44877: task edges-pos-ontonotes, batch 877 (44877): mcc: 0.8849, acc: 0.8138, precision: 0.9206, recall: 0.8549, f1: 0.8866, edges-pos-ontonotes_loss: 0.0131
09/16 05:37:33 AM: Update 44936: task edges-pos-ontonotes, batch 936 (44936): mcc: 0.8833, acc: 0.8116, precision: 0.9189, recall: 0.8536, f1: 0.8850, edges-pos-ontonotes_loss: 0.0132
09/16 05:37:43 AM: Update 44989: task edges-pos-ontonotes, batch 989 (44989): mcc: 0.8818, acc: 0.8094, precision: 0.9177, recall: 0.8519, f1: 0.8835, edges-pos-ontonotes_loss: 0.0134
09/16 05:37:44 AM: ***** Step 45000 / Validation 45 *****
09/16 05:37:44 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:37:44 AM: Validating...
09/16 05:37:53 AM: Evaluate: task edges-pos-ontonotes, batch 65 (157): mcc: 0.9133, acc: 0.8632, precision: 0.9479, recall: 0.8834, f1: 0.9145, edges-pos-ontonotes_loss: 0.0106
09/16 05:38:03 AM: Evaluate: task edges-pos-ontonotes, batch 118 (157): mcc: 0.9161, acc: 0.8682, precision: 0.9444, recall: 0.8919, f1: 0.9174, edges-pos-ontonotes_loss: 0.0101
09/16 05:38:11 AM: Updating LR scheduler:
09/16 05:38:11 AM: 	Best result seen so far for macro_avg: 0.919
09/16 05:38:11 AM: 	# validation passes without improvement: 1
09/16 05:38:11 AM: edges-pos-ontonotes_loss: training: 0.013374 validation: 0.009956
09/16 05:38:11 AM: macro_avg: validation: 0.918722
09/16 05:38:11 AM: micro_avg: validation: 0.000000
09/16 05:38:11 AM: edges-pos-ontonotes_mcc: training: 0.881803 validation: 0.917319
09/16 05:38:11 AM: edges-pos-ontonotes_acc: training: 0.809373 validation: 0.870874
09/16 05:38:11 AM: edges-pos-ontonotes_precision: training: 0.917724 validation: 0.941648
09/16 05:38:11 AM: edges-pos-ontonotes_recall: training: 0.851829 validation: 0.896886
09/16 05:38:11 AM: edges-pos-ontonotes_f1: training: 0.883549 validation: 0.918722
09/16 05:38:11 AM: Global learning rate: 2.5e-05
09/16 05:38:11 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:38:13 AM: Update 45016: task edges-pos-ontonotes, batch 16 (45016): mcc: 0.8746, acc: 0.7965, precision: 0.9266, recall: 0.8300, f1: 0.8757, edges-pos-ontonotes_loss: 0.0140
09/16 05:38:23 AM: Update 45106: task edges-pos-ontonotes, batch 106 (45106): mcc: 0.8739, acc: 0.7946, precision: 0.9212, recall: 0.8337, f1: 0.8752, edges-pos-ontonotes_loss: 0.0140
09/16 05:38:33 AM: Update 45190: task edges-pos-ontonotes, batch 190 (45190): mcc: 0.8733, acc: 0.7943, precision: 0.9201, recall: 0.8336, f1: 0.8747, edges-pos-ontonotes_loss: 0.0140
09/16 05:38:43 AM: Update 45286: task edges-pos-ontonotes, batch 286 (45286): mcc: 0.8732, acc: 0.7946, precision: 0.9198, recall: 0.8337, f1: 0.8746, edges-pos-ontonotes_loss: 0.0139
09/16 05:38:53 AM: Update 45294: task edges-pos-ontonotes, batch 294 (45294): mcc: 0.8734, acc: 0.7950, precision: 0.9198, recall: 0.8341, f1: 0.8749, edges-pos-ontonotes_loss: 0.0139
09/16 05:39:03 AM: Update 45360: task edges-pos-ontonotes, batch 360 (45360): mcc: 0.8752, acc: 0.7980, precision: 0.9175, recall: 0.8395, f1: 0.8768, edges-pos-ontonotes_loss: 0.0139
09/16 05:39:13 AM: Update 45433: task edges-pos-ontonotes, batch 433 (45433): mcc: 0.8762, acc: 0.7998, precision: 0.9167, recall: 0.8422, f1: 0.8779, edges-pos-ontonotes_loss: 0.0138
09/16 05:39:24 AM: Update 45510: task edges-pos-ontonotes, batch 510 (45510): mcc: 0.8770, acc: 0.8010, precision: 0.9158, recall: 0.8446, f1: 0.8787, edges-pos-ontonotes_loss: 0.0138
09/16 05:39:34 AM: Update 45581: task edges-pos-ontonotes, batch 581 (45581): mcc: 0.8777, acc: 0.8020, precision: 0.9156, recall: 0.8460, f1: 0.8794, edges-pos-ontonotes_loss: 0.0138
09/16 05:39:44 AM: Update 45632: task edges-pos-ontonotes, batch 632 (45632): mcc: 0.8775, acc: 0.8020, precision: 0.9144, recall: 0.8467, f1: 0.8793, edges-pos-ontonotes_loss: 0.0138
09/16 05:39:54 AM: Update 45687: task edges-pos-ontonotes, batch 687 (45687): mcc: 0.8771, acc: 0.8017, precision: 0.9132, recall: 0.8472, f1: 0.8789, edges-pos-ontonotes_loss: 0.0138
09/16 05:40:04 AM: Update 45747: task edges-pos-ontonotes, batch 747 (45747): mcc: 0.8770, acc: 0.8018, precision: 0.9123, recall: 0.8477, f1: 0.8788, edges-pos-ontonotes_loss: 0.0139
09/16 05:40:14 AM: Update 45806: task edges-pos-ontonotes, batch 806 (45806): mcc: 0.8767, acc: 0.8016, precision: 0.9115, recall: 0.8479, f1: 0.8786, edges-pos-ontonotes_loss: 0.0139
09/16 05:40:24 AM: Update 45868: task edges-pos-ontonotes, batch 868 (45868): mcc: 0.8765, acc: 0.8015, precision: 0.9111, recall: 0.8480, f1: 0.8784, edges-pos-ontonotes_loss: 0.0140
09/16 05:40:36 AM: Update 45920: task edges-pos-ontonotes, batch 920 (45920): mcc: 0.8764, acc: 0.8016, precision: 0.9107, recall: 0.8482, f1: 0.8783, edges-pos-ontonotes_loss: 0.0140
09/16 05:40:46 AM: Update 45976: task edges-pos-ontonotes, batch 976 (45976): mcc: 0.8766, acc: 0.8020, precision: 0.9106, recall: 0.8487, f1: 0.8786, edges-pos-ontonotes_loss: 0.0141
09/16 05:40:51 AM: ***** Step 46000 / Validation 46 *****
09/16 05:40:51 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:40:51 AM: Validating...
09/16 05:40:56 AM: Evaluate: task edges-pos-ontonotes, batch 38 (157): mcc: 0.9093, acc: 0.8557, precision: 0.9491, recall: 0.8745, f1: 0.9103, edges-pos-ontonotes_loss: 0.0107
09/16 05:41:06 AM: Evaluate: task edges-pos-ontonotes, batch 101 (157): mcc: 0.9169, acc: 0.8678, precision: 0.9499, recall: 0.8883, f1: 0.9181, edges-pos-ontonotes_loss: 0.0100
09/16 05:41:16 AM: Evaluate: task edges-pos-ontonotes, batch 148 (157): mcc: 0.9172, acc: 0.8695, precision: 0.9445, recall: 0.8939, f1: 0.9185, edges-pos-ontonotes_loss: 0.0099
09/16 05:41:18 AM: Updating LR scheduler:
09/16 05:41:18 AM: 	Best result seen so far for macro_avg: 0.919
09/16 05:41:18 AM: 	# validation passes without improvement: 2
09/16 05:41:18 AM: Ran out of early stopping patience. Stopping training.
09/16 05:41:18 AM: edges-pos-ontonotes_loss: training: 0.014070 validation: 0.009862
09/16 05:41:18 AM: macro_avg: validation: 0.918990
09/16 05:41:18 AM: micro_avg: validation: 0.000000
09/16 05:41:18 AM: edges-pos-ontonotes_mcc: training: 0.876678 validation: 0.917666
09/16 05:41:18 AM: edges-pos-ontonotes_acc: training: 0.802103 validation: 0.870557
09/16 05:41:18 AM: edges-pos-ontonotes_precision: training: 0.910554 validation: 0.944618
09/16 05:41:18 AM: edges-pos-ontonotes_recall: training: 0.848824 validation: 0.894716
09/16 05:41:18 AM: edges-pos-ontonotes_f1: training: 0.878606 validation: 0.918990
09/16 05:41:18 AM: Global learning rate: 2.5e-05
09/16 05:41:18 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:41:18 AM: Stopped training after 46 validation checks
09/16 05:41:18 AM: Trained edges-pos-ontonotes for 46000 batches or 13.318 epochs
09/16 05:41:18 AM: ***** VALIDATION RESULTS *****
09/16 05:41:18 AM: edges-pos-ontonotes_f1 (for best val pass 36): edges-pos-ontonotes_loss: 0.01003, macro_avg: 0.91923, micro_avg: 0.00000, edges-pos-ontonotes_mcc: 0.91788, edges-pos-ontonotes_acc: 0.87151, edges-pos-ontonotes_precision: 0.94372, edges-pos-ontonotes_recall: 0.89598, edges-pos-ontonotes_f1: 0.91923
09/16 05:41:18 AM: micro_avg (for best val pass 1): edges-pos-ontonotes_loss: 0.04512, macro_avg: 0.54095, micro_avg: 0.00000, edges-pos-ontonotes_mcc: 0.59069, edges-pos-ontonotes_acc: 0.37530, edges-pos-ontonotes_precision: 0.92883, edges-pos-ontonotes_recall: 0.38160, edges-pos-ontonotes_f1: 0.54095
09/16 05:41:18 AM: macro_avg (for best val pass 36): edges-pos-ontonotes_loss: 0.01003, macro_avg: 0.91923, micro_avg: 0.00000, edges-pos-ontonotes_mcc: 0.91788, edges-pos-ontonotes_acc: 0.87151, edges-pos-ontonotes_precision: 0.94372, edges-pos-ontonotes_recall: 0.89598, edges-pos-ontonotes_f1: 0.91923
09/16 05:41:18 AM: Evaluating...
09/16 05:41:18 AM: Loaded model state from ./experiments/pos-ontonotes-sts-b-top/run/edges-pos-ontonotes/model_state_target_train_val_36.best.th
09/16 05:41:18 AM: Evaluating on: edges-pos-ontonotes, split: val
09/16 05:41:48 AM: 	Task edges-pos-ontonotes: batch 156
09/16 05:42:18 AM: 	Task edges-pos-ontonotes: batch 282
09/16 05:42:48 AM: 	Task edges-pos-ontonotes: batch 460
09/16 05:42:51 AM: Task 'edges-pos-ontonotes': sorting predictions by 'idx'
09/16 05:42:51 AM: Finished evaluating on: edges-pos-ontonotes
09/16 05:42:51 AM: Task 'edges-pos-ontonotes': joining predictions with input split 'val'
09/16 05:43:03 AM: Task 'edges-pos-ontonotes': Wrote predictions to ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:43:03 AM: Wrote all preds for split 'val' to ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:43:03 AM: Evaluating on: edges-pos-ontonotes, split: test
09/16 05:43:34 AM: 	Task edges-pos-ontonotes: batch 146
09/16 05:44:04 AM: 	Task edges-pos-ontonotes: batch 249
09/16 05:44:21 AM: Task 'edges-pos-ontonotes': sorting predictions by 'idx'
09/16 05:44:21 AM: Finished evaluating on: edges-pos-ontonotes
09/16 05:44:21 AM: Task 'edges-pos-ontonotes': joining predictions with input split 'test'
09/16 05:44:30 AM: Task 'edges-pos-ontonotes': Wrote predictions to ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:44:30 AM: Wrote all preds for split 'test' to ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:44:30 AM: Writing results for split 'val' to ./experiments/pos-ontonotes-sts-b-top/results.tsv
09/16 05:44:30 AM: micro_avg: 0.000, macro_avg: 0.921, edges-pos-ontonotes_mcc: 0.920, edges-pos-ontonotes_acc: 0.875, edges-pos-ontonotes_precision: 0.942, edges-pos-ontonotes_recall: 0.901, edges-pos-ontonotes_f1: 0.921
09/16 05:44:30 AM: Done!
=======
09/16 12:24:02 PM: Model parameters:
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	edges-pos-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 12:24:02 PM: 	edges-pos-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 12:24:02 PM: 	edges-pos-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 24576 with torch.Size([48, 512])
09/16 12:24:02 PM: 	edges-pos-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 48 with torch.Size([48])
09/16 12:24:02 PM: Total number of parameters: 109703728 (1.09704e+08)
09/16 12:24:02 PM: Number of trainable parameters: 221488 (221488)
09/16 12:24:02 PM: Finished building model in 9.508s
09/16 12:24:02 PM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-pos-ontonotes 

09/16 12:25:12 PM: patience = 9
09/16 12:25:12 PM: val_interval = 1000
09/16 12:25:12 PM: max_vals = 250
09/16 12:25:12 PM: cuda_device = 0
09/16 12:25:12 PM: grad_norm = 5.0
09/16 12:25:12 PM: grad_clipping = None
09/16 12:25:12 PM: lr_decay = 0.99
09/16 12:25:12 PM: min_lr = 1e-06
09/16 12:25:12 PM: keep_all_checkpoints = 0
09/16 12:25:12 PM: val_data_limit = 5000
09/16 12:25:12 PM: max_epochs = -1
09/16 12:25:12 PM: dec_val_scale = 250
09/16 12:25:12 PM: training_data_fraction = 1
09/16 12:25:12 PM: type = adam
09/16 12:25:12 PM: parameter_groups = None
09/16 12:25:12 PM: Number of trainable parameters: 221488
09/16 12:25:12 PM: infer_type_and_cast = True
09/16 12:25:12 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:25:12 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:25:12 PM: lr = 0.0001
09/16 12:25:12 PM: amsgrad = True
09/16 12:25:12 PM: type = reduce_on_plateau
09/16 12:25:12 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:25:12 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:25:12 PM: mode = max
09/16 12:25:12 PM: factor = 0.5
09/16 12:25:12 PM: patience = 3
09/16 12:25:12 PM: threshold = 0.0001
09/16 12:25:12 PM: threshold_mode = abs
09/16 12:25:12 PM: verbose = True
09/16 12:25:12 PM: type = adam
09/16 12:25:12 PM: parameter_groups = None
09/16 12:25:12 PM: Number of trainable parameters: 221488
09/16 12:25:12 PM: infer_type_and_cast = True
09/16 12:25:12 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:25:12 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:25:12 PM: lr = 0.0001
09/16 12:25:12 PM: amsgrad = True
09/16 12:25:12 PM: type = reduce_on_plateau
09/16 12:25:12 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:25:12 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:25:12 PM: mode = max
09/16 12:25:12 PM: factor = 0.5
09/16 12:25:12 PM: patience = 3
09/16 12:25:12 PM: threshold = 0.0001
09/16 12:25:12 PM: threshold_mode = abs
09/16 12:25:12 PM: verbose = True
09/16 12:25:12 PM: Starting training without restoring from a checkpoint.
09/16 12:25:12 PM: Training examples per task, before any subsampling: {'edges-pos-ontonotes': 110514}
09/16 12:25:12 PM: Beginning training with stopping criteria based on metric: edges-pos-ontonotes_f1
09/16 12:25:22 PM: Update 46: task edges-pos-ontonotes, batch 46 (46): mcc: 0.0122, acc: 0.0024, precision: 0.0255, recall: 0.1488, f1: 0.0436, edges-pos-ontonotes_loss: 0.4246
09/16 12:25:32 PM: Update 118: task edges-pos-ontonotes, batch 118 (118): mcc: 0.0077, acc: 0.0010, precision: 0.0255, recall: 0.0638, f1: 0.0365, edges-pos-ontonotes_loss: 0.2276
09/16 12:25:43 PM: Update 199: task edges-pos-ontonotes, batch 199 (199): mcc: 0.0082, acc: 0.0035, precision: 0.0274, recall: 0.0406, f1: 0.0327, edges-pos-ontonotes_loss: 0.1680
09/16 12:25:53 PM: Update 263: task edges-pos-ontonotes, batch 263 (263): mcc: 0.0128, acc: 0.0088, precision: 0.0325, recall: 0.0378, f1: 0.0349, edges-pos-ontonotes_loss: 0.1457
09/16 12:26:03 PM: Update 317: task edges-pos-ontonotes, batch 317 (317): mcc: 0.0202, acc: 0.0156, precision: 0.0410, recall: 0.0394, f1: 0.0402, edges-pos-ontonotes_loss: 0.1335
09/16 12:26:13 PM: Update 383: task edges-pos-ontonotes, batch 383 (383): mcc: 0.0248, acc: 0.0185, precision: 0.0488, recall: 0.0370, f1: 0.0421, edges-pos-ontonotes_loss: 0.1234
09/16 12:26:23 PM: Update 435: task edges-pos-ontonotes, batch 435 (435): mcc: 0.0309, acc: 0.0224, precision: 0.0581, recall: 0.0386, f1: 0.0463, edges-pos-ontonotes_loss: 0.1170
09/16 12:26:33 PM: Update 492: task edges-pos-ontonotes, batch 492 (492): mcc: 0.0389, acc: 0.0270, precision: 0.0710, recall: 0.0413, f1: 0.0522, edges-pos-ontonotes_loss: 0.1112
09/16 12:26:43 PM: Update 551: task edges-pos-ontonotes, batch 551 (551): mcc: 0.0503, acc: 0.0336, precision: 0.0896, recall: 0.0464, f1: 0.0611, edges-pos-ontonotes_loss: 0.1062
09/16 12:26:53 PM: Update 603: task edges-pos-ontonotes, batch 603 (603): mcc: 0.0629, acc: 0.0410, precision: 0.1102, recall: 0.0529, f1: 0.0715, edges-pos-ontonotes_loss: 0.1023
09/16 12:27:03 PM: Update 642: task edges-pos-ontonotes, batch 642 (642): mcc: 0.0771, acc: 0.0492, precision: 0.1335, recall: 0.0607, f1: 0.0834, edges-pos-ontonotes_loss: 0.0998
09/16 12:27:13 PM: Update 693: task edges-pos-ontonotes, batch 693 (693): mcc: 0.1018, acc: 0.0634, precision: 0.1746, recall: 0.0742, f1: 0.1042, edges-pos-ontonotes_loss: 0.0968
09/16 12:27:23 PM: Update 731: task edges-pos-ontonotes, batch 731 (731): mcc: 0.1192, acc: 0.0734, precision: 0.2040, recall: 0.0838, f1: 0.1188, edges-pos-ontonotes_loss: 0.0947
09/16 12:27:34 PM: Update 770: task edges-pos-ontonotes, batch 770 (770): mcc: 0.1354, acc: 0.0827, precision: 0.2312, recall: 0.0930, f1: 0.1326, edges-pos-ontonotes_loss: 0.0928
09/16 12:27:44 PM: Update 822: task edges-pos-ontonotes, batch 822 (822): mcc: 0.1589, acc: 0.0963, precision: 0.2706, recall: 0.1063, f1: 0.1527, edges-pos-ontonotes_loss: 0.0903
09/16 12:27:54 PM: Update 865: task edges-pos-ontonotes, batch 865 (865): mcc: 0.1752, acc: 0.1059, precision: 0.2976, recall: 0.1159, f1: 0.1668, edges-pos-ontonotes_loss: 0.0885
09/16 12:28:04 PM: Update 901: task edges-pos-ontonotes, batch 901 (901): mcc: 0.1932, acc: 0.1167, precision: 0.3271, recall: 0.1265, f1: 0.1824, edges-pos-ontonotes_loss: 0.0869
09/16 12:28:15 PM: Update 942: task edges-pos-ontonotes, batch 942 (942): mcc: 0.2129, acc: 0.1286, precision: 0.3588, recall: 0.1383, f1: 0.1996, edges-pos-ontonotes_loss: 0.0853
09/16 12:28:25 PM: Update 994: task edges-pos-ontonotes, batch 994 (994): mcc: 0.2355, acc: 0.1424, precision: 0.3950, recall: 0.1520, f1: 0.2196, edges-pos-ontonotes_loss: 0.0833
09/16 12:28:26 PM: ***** Step 1000 / Validation 1 *****
09/16 12:28:26 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:28:26 PM: Validating...
09/16 12:28:35 PM: Evaluate: task edges-pos-ontonotes, batch 45 (157): mcc: 0.5067, acc: 0.2718, precision: 0.9512, recall: 0.2746, f1: 0.4262, edges-pos-ontonotes_loss: 0.0495
09/16 12:28:45 PM: Evaluate: task edges-pos-ontonotes, batch 92 (157): mcc: 0.5601, acc: 0.3332, precision: 0.9459, recall: 0.3370, f1: 0.4970, edges-pos-ontonotes_loss: 0.0466
09/16 12:28:55 PM: Evaluate: task edges-pos-ontonotes, batch 133 (157): mcc: 0.5864, acc: 0.3700, precision: 0.9290, recall: 0.3761, f1: 0.5354, edges-pos-ontonotes_loss: 0.0454
09/16 12:29:00 PM: Best result seen so far for edges-pos-ontonotes.
09/16 12:29:00 PM: Best result seen so far for micro.
09/16 12:29:00 PM: Best result seen so far for macro.
09/16 12:29:00 PM: Updating LR scheduler:
09/16 12:29:00 PM: 	Best result seen so far for macro_avg: 0.541
09/16 12:29:00 PM: 	# validation passes without improvement: 0
09/16 12:29:00 PM: edges-pos-ontonotes_loss: training: 0.083116 validation: 0.045122
09/16 12:29:00 PM: macro_avg: validation: 0.540954
09/16 12:29:00 PM: micro_avg: validation: 0.000000
09/16 12:29:00 PM: edges-pos-ontonotes_mcc: training: 0.238055 validation: 0.590688
09/16 12:29:00 PM: edges-pos-ontonotes_acc: training: 0.143936 validation: 0.375303
09/16 12:29:00 PM: edges-pos-ontonotes_precision: training: 0.398862 validation: 0.928831
09/16 12:29:00 PM: edges-pos-ontonotes_recall: training: 0.153633 validation: 0.381599
09/16 12:29:00 PM: edges-pos-ontonotes_f1: training: 0.221824 validation: 0.540954
09/16 12:29:00 PM: Global learning rate: 0.0001
09/16 12:29:00 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 12:29:05 PM: Update 1026: task edges-pos-ontonotes, batch 26 (1026): mcc: 0.5656, acc: 0.3503, precision: 0.9050, recall: 0.3596, f1: 0.5147, edges-pos-ontonotes_loss: 0.0469
09/16 12:29:15 PM: Update 1062: task edges-pos-ontonotes, batch 62 (1062): mcc: 0.5771, acc: 0.3642, precision: 0.9063, recall: 0.3737, f1: 0.5292, edges-pos-ontonotes_loss: 0.0460
09/16 12:29:25 PM: Update 1109: task edges-pos-ontonotes, batch 109 (1109): mcc: 0.5894, acc: 0.3791, precision: 0.9072, recall: 0.3893, f1: 0.5448, edges-pos-ontonotes_loss: 0.0449
09/16 12:29:35 PM: Update 1162: task edges-pos-ontonotes, batch 162 (1162): mcc: 0.5986, acc: 0.3909, precision: 0.9076, recall: 0.4013, f1: 0.5565, edges-pos-ontonotes_loss: 0.0440
09/16 12:29:46 PM: Update 1199: task edges-pos-ontonotes, batch 199 (1199): mcc: 0.6052, acc: 0.3991, precision: 0.9086, recall: 0.4096, f1: 0.5646, edges-pos-ontonotes_loss: 0.0435
09/16 12:29:56 PM: Update 1251: task edges-pos-ontonotes, batch 251 (1251): mcc: 0.6142, acc: 0.4107, precision: 0.9092, recall: 0.4214, f1: 0.5759, edges-pos-ontonotes_loss: 0.0427
09/16 12:30:08 PM: Update 1253: task edges-pos-ontonotes, batch 253 (1253): mcc: 0.6142, acc: 0.4108, precision: 0.9090, recall: 0.4215, f1: 0.5760, edges-pos-ontonotes_loss: 0.0427
09/16 12:30:18 PM: Update 1310: task edges-pos-ontonotes, batch 310 (1310): mcc: 0.6209, acc: 0.4195, precision: 0.9095, recall: 0.4305, f1: 0.5844, edges-pos-ontonotes_loss: 0.0420
09/16 12:30:28 PM: Update 1366: task edges-pos-ontonotes, batch 366 (1366): mcc: 0.6282, acc: 0.4290, precision: 0.9101, recall: 0.4403, f1: 0.5934, edges-pos-ontonotes_loss: 0.0413
09/16 12:30:39 PM: Update 1422: task edges-pos-ontonotes, batch 422 (1422): mcc: 0.6356, acc: 0.4387, precision: 0.9104, recall: 0.4504, f1: 0.6027, edges-pos-ontonotes_loss: 0.0405
09/16 12:30:49 PM: Update 1474: task edges-pos-ontonotes, batch 474 (1474): mcc: 0.6428, acc: 0.4483, precision: 0.9105, recall: 0.4604, f1: 0.6116, edges-pos-ontonotes_loss: 0.0400
09/16 12:30:59 PM: Update 1526: task edges-pos-ontonotes, batch 526 (1526): mcc: 0.6491, acc: 0.4568, precision: 0.9109, recall: 0.4693, f1: 0.6194, edges-pos-ontonotes_loss: 0.0394
09/16 12:31:09 PM: Update 1571: task edges-pos-ontonotes, batch 571 (1571): mcc: 0.6537, acc: 0.4631, precision: 0.9109, recall: 0.4758, f1: 0.6251, edges-pos-ontonotes_loss: 0.0389
09/16 12:31:19 PM: Update 1609: task edges-pos-ontonotes, batch 609 (1609): mcc: 0.6575, acc: 0.4682, precision: 0.9111, recall: 0.4812, f1: 0.6298, edges-pos-ontonotes_loss: 0.0385
09/16 12:31:29 PM: Update 1658: task edges-pos-ontonotes, batch 658 (1658): mcc: 0.6630, acc: 0.4759, precision: 0.9109, recall: 0.4894, f1: 0.6367, edges-pos-ontonotes_loss: 0.0380
09/16 12:31:40 PM: Update 1713: task edges-pos-ontonotes, batch 713 (1713): mcc: 0.6686, acc: 0.4837, precision: 0.9108, recall: 0.4976, f1: 0.6436, edges-pos-ontonotes_loss: 0.0374
09/16 12:31:50 PM: Update 1768: task edges-pos-ontonotes, batch 768 (1768): mcc: 0.6737, acc: 0.4908, precision: 0.9106, recall: 0.5053, f1: 0.6500, edges-pos-ontonotes_loss: 0.0369
09/16 12:32:00 PM: Update 1828: task edges-pos-ontonotes, batch 828 (1828): mcc: 0.6787, acc: 0.4978, precision: 0.9105, recall: 0.5127, f1: 0.6560, edges-pos-ontonotes_loss: 0.0365
09/16 12:32:12 PM: Update 1879: task edges-pos-ontonotes, batch 879 (1879): mcc: 0.6835, acc: 0.5047, precision: 0.9103, recall: 0.5201, f1: 0.6620, edges-pos-ontonotes_loss: 0.0360
09/16 12:32:22 PM: Update 1926: task edges-pos-ontonotes, batch 926 (1926): mcc: 0.6871, acc: 0.5099, precision: 0.9098, recall: 0.5258, f1: 0.6664, edges-pos-ontonotes_loss: 0.0357
09/16 12:32:32 PM: Update 1994: task edges-pos-ontonotes, batch 994 (1994): mcc: 0.6909, acc: 0.5156, precision: 0.9092, recall: 0.5320, f1: 0.6712, edges-pos-ontonotes_loss: 0.0352
09/16 12:32:32 PM: ***** Step 2000 / Validation 2 *****
09/16 12:32:32 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:32:32 PM: Validating...
09/16 12:32:42 PM: Evaluate: task edges-pos-ontonotes, batch 66 (157): mcc: 0.7396, acc: 0.5908, precision: 0.9160, recall: 0.6039, f1: 0.7279, edges-pos-ontonotes_loss: 0.0318
09/16 12:32:52 PM: Evaluate: task edges-pos-ontonotes, batch 118 (157): mcc: 0.7711, acc: 0.6391, precision: 0.9119, recall: 0.6585, f1: 0.7648, edges-pos-ontonotes_loss: 0.0291
09/16 12:33:01 PM: Best result seen so far for edges-pos-ontonotes.
09/16 12:33:01 PM: Best result seen so far for macro.
09/16 12:33:01 PM: Updating LR scheduler:
09/16 12:33:01 PM: 	Best result seen so far for macro_avg: 0.779
09/16 12:33:01 PM: 	# validation passes without improvement: 0
09/16 12:33:01 PM: edges-pos-ontonotes_loss: training: 0.035201 validation: 0.027865
09/16 12:33:01 PM: macro_avg: validation: 0.778787
09/16 12:33:01 PM: micro_avg: validation: 0.000000
09/16 12:33:01 PM: edges-pos-ontonotes_mcc: training: 0.691180 validation: 0.783251
09/16 12:33:01 PM: edges-pos-ontonotes_acc: training: 0.515858 validation: 0.658084
09/16 12:33:01 PM: edges-pos-ontonotes_precision: training: 0.909249 validation: 0.909942
09/16 12:33:01 PM: edges-pos-ontonotes_recall: training: 0.532305 validation: 0.680678
09/16 12:33:01 PM: edges-pos-ontonotes_f1: training: 0.671494 validation: 0.778787
09/16 12:33:01 PM: Global learning rate: 0.0001
09/16 12:33:01 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 12:33:02 PM: Update 2009: task edges-pos-ontonotes, batch 9 (2009): mcc: 0.7578, acc: 0.6228, precision: 0.9022, recall: 0.6434, f1: 0.7511, edges-pos-ontonotes_loss: 0.0289
09/16 12:33:12 PM: Update 2082: task edges-pos-ontonotes, batch 82 (2082): mcc: 0.7653, acc: 0.6272, precision: 0.9083, recall: 0.6515, f1: 0.7587, edges-pos-ontonotes_loss: 0.0283
09/16 12:33:22 PM: Update 2143: task edges-pos-ontonotes, batch 143 (2143): mcc: 0.7692, acc: 0.6336, precision: 0.9054, recall: 0.6602, f1: 0.7636, edges-pos-ontonotes_loss: 0.0278
09/16 12:33:33 PM: Update 2204: task edges-pos-ontonotes, batch 204 (2204): mcc: 0.7713, acc: 0.6366, precision: 0.9060, recall: 0.6633, f1: 0.7658, edges-pos-ontonotes_loss: 0.0275
09/16 12:33:43 PM: Update 2298: task edges-pos-ontonotes, batch 298 (2298): mcc: 0.7740, acc: 0.6392, precision: 0.9100, recall: 0.6649, f1: 0.7684, edges-pos-ontonotes_loss: 0.0269
09/16 12:33:53 PM: Update 2390: task edges-pos-ontonotes, batch 390 (2390): mcc: 0.7779, acc: 0.6442, precision: 0.9125, recall: 0.6696, f1: 0.7724, edges-pos-ontonotes_loss: 0.0263
09/16 12:34:03 PM: Update 2476: task edges-pos-ontonotes, batch 476 (2476): mcc: 0.7822, acc: 0.6498, precision: 0.9148, recall: 0.6752, f1: 0.7769, edges-pos-ontonotes_loss: 0.0257
09/16 12:34:13 PM: Update 2563: task edges-pos-ontonotes, batch 563 (2563): mcc: 0.7846, acc: 0.6532, precision: 0.9159, recall: 0.6785, f1: 0.7795, edges-pos-ontonotes_loss: 0.0257
09/16 12:34:23 PM: Update 2643: task edges-pos-ontonotes, batch 643 (2643): mcc: 0.7870, acc: 0.6566, precision: 0.9174, recall: 0.6815, f1: 0.7820, edges-pos-ontonotes_loss: 0.0256
09/16 12:34:33 PM: Update 2756: task edges-pos-ontonotes, batch 756 (2756): mcc: 0.7902, acc: 0.6612, precision: 0.9184, recall: 0.6860, f1: 0.7854, edges-pos-ontonotes_loss: 0.0253
09/16 12:34:43 PM: Update 2851: task edges-pos-ontonotes, batch 851 (2851): mcc: 0.7912, acc: 0.6630, precision: 0.9183, recall: 0.6880, f1: 0.7866, edges-pos-ontonotes_loss: 0.0252
09/16 12:34:53 PM: Update 2975: task edges-pos-ontonotes, batch 975 (2975): mcc: 0.7900, acc: 0.6613, precision: 0.9173, recall: 0.6867, f1: 0.7854, edges-pos-ontonotes_loss: 0.0252
09/16 12:34:55 PM: ***** Step 3000 / Validation 3 *****
09/16 12:34:55 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:34:55 PM: Validating...
09/16 12:35:03 PM: Evaluate: task edges-pos-ontonotes, batch 39 (157): mcc: 0.8075, acc: 0.6938, precision: 0.9120, recall: 0.7211, f1: 0.8054, edges-pos-ontonotes_loss: 0.0231
09/16 12:35:13 PM: Evaluate: task edges-pos-ontonotes, batch 95 (157): mcc: 0.8258, acc: 0.7247, precision: 0.9055, recall: 0.7591, f1: 0.8259, edges-pos-ontonotes_loss: 0.0217
09/16 12:35:23 PM: Evaluate: task edges-pos-ontonotes, batch 141 (157): mcc: 0.8299, acc: 0.7324, precision: 0.8930, recall: 0.7774, f1: 0.8312, edges-pos-ontonotes_loss: 0.0218
09/16 12:35:27 PM: Best result seen so far for edges-pos-ontonotes.
09/16 12:35:27 PM: Best result seen so far for macro.
09/16 12:35:27 PM: Updating LR scheduler:
09/16 12:35:27 PM: 	Best result seen so far for macro_avg: 0.832
09/16 12:35:27 PM: 	# validation passes without improvement: 0
09/16 12:35:27 PM: edges-pos-ontonotes_loss: training: 0.025215 validation: 0.021723
09/16 12:35:27 PM: macro_avg: validation: 0.832484
09/16 12:35:27 PM: micro_avg: validation: 0.000000
09/16 12:35:27 PM: edges-pos-ontonotes_mcc: training: 0.789768 validation: 0.831127
09/16 12:35:27 PM: edges-pos-ontonotes_acc: training: 0.661002 validation: 0.734743
09/16 12:35:27 PM: edges-pos-ontonotes_precision: training: 0.917022 validation: 0.892592
09/16 12:35:27 PM: edges-pos-ontonotes_recall: training: 0.686452 validation: 0.779961
09/16 12:35:27 PM: edges-pos-ontonotes_f1: training: 0.785160 validation: 0.832484
09/16 12:35:27 PM: Global learning rate: 0.0001
09/16 12:35:27 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 12:35:33 PM: Update 3075: task edges-pos-ontonotes, batch 75 (3075): mcc: 0.7843, acc: 0.6563, precision: 0.9011, recall: 0.6892, f1: 0.7810, edges-pos-ontonotes_loss: 0.0246
09/16 12:35:43 PM: Update 3137: task edges-pos-ontonotes, batch 137 (3137): mcc: 0.7865, acc: 0.6605, precision: 0.8953, recall: 0.6976, f1: 0.7842, edges-pos-ontonotes_loss: 0.0243
09/16 12:35:54 PM: Update 3182: task edges-pos-ontonotes, batch 182 (3182): mcc: 0.7872, acc: 0.6627, precision: 0.8916, recall: 0.7018, f1: 0.7854, edges-pos-ontonotes_loss: 0.0247
09/16 12:36:04 PM: Update 3231: task edges-pos-ontonotes, batch 231 (3231): mcc: 0.7860, acc: 0.6616, precision: 0.8898, recall: 0.7012, f1: 0.7843, edges-pos-ontonotes_loss: 0.0251
09/16 12:36:14 PM: Update 3282: task edges-pos-ontonotes, batch 282 (3282): mcc: 0.7872, acc: 0.6638, precision: 0.8895, recall: 0.7034, f1: 0.7856, edges-pos-ontonotes_loss: 0.0252
09/16 12:36:24 PM: Update 3329: task edges-pos-ontonotes, batch 329 (3329): mcc: 0.7876, acc: 0.6647, precision: 0.8891, recall: 0.7044, f1: 0.7861, edges-pos-ontonotes_loss: 0.0254
09/16 12:36:34 PM: Update 3389: task edges-pos-ontonotes, batch 389 (3389): mcc: 0.7885, acc: 0.6662, precision: 0.8902, recall: 0.7053, f1: 0.7870, edges-pos-ontonotes_loss: 0.0252
09/16 12:36:44 PM: Update 3446: task edges-pos-ontonotes, batch 446 (3446): mcc: 0.7892, acc: 0.6673, precision: 0.8906, recall: 0.7062, f1: 0.7877, edges-pos-ontonotes_loss: 0.0251
09/16 12:36:58 PM: Update 3461: task edges-pos-ontonotes, batch 461 (3461): mcc: 0.7891, acc: 0.6671, precision: 0.8907, recall: 0.7059, f1: 0.7876, edges-pos-ontonotes_loss: 0.0251
09/16 12:37:08 PM: Update 3534: task edges-pos-ontonotes, batch 534 (3534): mcc: 0.7893, acc: 0.6669, precision: 0.8928, recall: 0.7045, f1: 0.7875, edges-pos-ontonotes_loss: 0.0249
09/16 12:37:18 PM: Update 3626: task edges-pos-ontonotes, batch 626 (3626): mcc: 0.7905, acc: 0.6682, precision: 0.8948, recall: 0.7050, f1: 0.7886, edges-pos-ontonotes_loss: 0.0246
09/16 12:37:28 PM: Update 3712: task edges-pos-ontonotes, batch 712 (3712): mcc: 0.7917, acc: 0.6697, precision: 0.8960, recall: 0.7061, f1: 0.7898, edges-pos-ontonotes_loss: 0.0242
09/16 12:37:38 PM: Update 3774: task edges-pos-ontonotes, batch 774 (3774): mcc: 0.7929, acc: 0.6714, precision: 0.8968, recall: 0.7076, f1: 0.7911, edges-pos-ontonotes_loss: 0.0239
09/16 12:37:49 PM: Update 3838: task edges-pos-ontonotes, batch 838 (3838): mcc: 0.7952, acc: 0.6751, precision: 0.8967, recall: 0.7118, f1: 0.7936, edges-pos-ontonotes_loss: 0.0238
09/16 12:37:59 PM: Update 3895: task edges-pos-ontonotes, batch 895 (3895): mcc: 0.7973, acc: 0.6783, precision: 0.8970, recall: 0.7153, f1: 0.7959, edges-pos-ontonotes_loss: 0.0236
09/16 12:38:09 PM: Update 3976: task edges-pos-ontonotes, batch 976 (3976): mcc: 0.7993, acc: 0.6813, precision: 0.8974, recall: 0.7185, f1: 0.7980, edges-pos-ontonotes_loss: 0.0233
09/16 12:38:12 PM: ***** Step 4000 / Validation 4 *****
09/16 12:38:12 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:38:12 PM: Validating...
09/16 12:38:19 PM: Evaluate: task edges-pos-ontonotes, batch 48 (157): mcc: 0.8479, acc: 0.7545, precision: 0.9358, recall: 0.7733, f1: 0.8468, edges-pos-ontonotes_loss: 0.0182
09/16 12:38:29 PM: Evaluate: task edges-pos-ontonotes, batch 107 (157): mcc: 0.8603, acc: 0.7759, precision: 0.9283, recall: 0.8022, f1: 0.8607, edges-pos-ontonotes_loss: 0.0172
09/16 12:38:39 PM: Evaluate: task edges-pos-ontonotes, batch 152 (157): mcc: 0.8591, acc: 0.7763, precision: 0.9191, recall: 0.8081, f1: 0.8601, edges-pos-ontonotes_loss: 0.0175
09/16 12:38:40 PM: Best result seen so far for edges-pos-ontonotes.
09/16 12:38:40 PM: Best result seen so far for macro.
09/16 12:38:40 PM: Updating LR scheduler:
09/16 12:38:40 PM: 	Best result seen so far for macro_avg: 0.860
09/16 12:38:40 PM: 	# validation passes without improvement: 0
09/16 12:38:40 PM: edges-pos-ontonotes_loss: training: 0.023207 validation: 0.017472
09/16 12:38:40 PM: macro_avg: validation: 0.860186
09/16 12:38:40 PM: micro_avg: validation: 0.000000
09/16 12:38:40 PM: edges-pos-ontonotes_mcc: training: 0.799741 validation: 0.859237
09/16 12:38:40 PM: edges-pos-ontonotes_acc: training: 0.682009 validation: 0.776638
09/16 12:38:40 PM: edges-pos-ontonotes_precision: training: 0.897423 validation: 0.918984
09/16 12:38:40 PM: edges-pos-ontonotes_recall: training: 0.719197 validation: 0.808460
09/16 12:38:40 PM: edges-pos-ontonotes_f1: training: 0.798486 validation: 0.860186
09/16 12:38:40 PM: Global learning rate: 0.0001
09/16 12:38:40 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 12:38:49 PM: Update 4061: task edges-pos-ontonotes, batch 61 (4061): mcc: 0.8229, acc: 0.7176, precision: 0.9021, recall: 0.7568, f1: 0.8231, edges-pos-ontonotes_loss: 0.0204
09/16 12:39:00 PM: Update 4092: task edges-pos-ontonotes, batch 92 (4092): mcc: 0.8221, acc: 0.7171, precision: 0.8991, recall: 0.7578, f1: 0.8224, edges-pos-ontonotes_loss: 0.0204
09/16 12:39:10 PM: Update 4137: task edges-pos-ontonotes, batch 137 (4137): mcc: 0.8192, acc: 0.7145, precision: 0.8956, recall: 0.7556, f1: 0.8196, edges-pos-ontonotes_loss: 0.0212
09/16 12:39:20 PM: Update 4193: task edges-pos-ontonotes, batch 193 (4193): mcc: 0.8183, acc: 0.7137, precision: 0.8947, recall: 0.7546, f1: 0.8187, edges-pos-ontonotes_loss: 0.0213
09/16 12:39:30 PM: Update 4253: task edges-pos-ontonotes, batch 253 (4253): mcc: 0.8192, acc: 0.7148, precision: 0.8955, recall: 0.7556, f1: 0.8196, edges-pos-ontonotes_loss: 0.0213
09/16 12:39:40 PM: Update 4309: task edges-pos-ontonotes, batch 309 (4309): mcc: 0.8193, acc: 0.7151, precision: 0.8954, recall: 0.7559, f1: 0.8198, edges-pos-ontonotes_loss: 0.0213
09/16 12:39:50 PM: Update 4366: task edges-pos-ontonotes, batch 366 (4366): mcc: 0.8201, acc: 0.7162, precision: 0.8961, recall: 0.7567, f1: 0.8205, edges-pos-ontonotes_loss: 0.0212
09/16 12:40:02 PM: Update 4400: task edges-pos-ontonotes, batch 400 (4400): mcc: 0.8202, acc: 0.7164, precision: 0.8962, recall: 0.7568, f1: 0.8206, edges-pos-ontonotes_loss: 0.0212
09/16 12:40:12 PM: Update 4452: task edges-pos-ontonotes, batch 452 (4452): mcc: 0.8205, acc: 0.7166, precision: 0.8956, recall: 0.7580, f1: 0.8211, edges-pos-ontonotes_loss: 0.0211
09/16 12:40:22 PM: Update 4507: task edges-pos-ontonotes, batch 507 (4507): mcc: 0.8216, acc: 0.7184, precision: 0.8961, recall: 0.7595, f1: 0.8222, edges-pos-ontonotes_loss: 0.0210
09/16 12:40:32 PM: Update 4536: task edges-pos-ontonotes, batch 536 (4536): mcc: 0.8221, acc: 0.7191, precision: 0.8963, recall: 0.7603, f1: 0.8227, edges-pos-ontonotes_loss: 0.0210
09/16 12:40:42 PM: Update 4569: task edges-pos-ontonotes, batch 569 (4569): mcc: 0.8226, acc: 0.7201, precision: 0.8965, recall: 0.7611, f1: 0.8232, edges-pos-ontonotes_loss: 0.0210
09/16 12:40:52 PM: Update 4623: task edges-pos-ontonotes, batch 623 (4623): mcc: 0.8237, acc: 0.7217, precision: 0.8973, recall: 0.7623, f1: 0.8243, edges-pos-ontonotes_loss: 0.0208
09/16 12:41:02 PM: Update 4668: task edges-pos-ontonotes, batch 668 (4668): mcc: 0.8248, acc: 0.7233, precision: 0.8980, recall: 0.7637, f1: 0.8254, edges-pos-ontonotes_loss: 0.0207
09/16 12:41:12 PM: Update 4709: task edges-pos-ontonotes, batch 709 (4709): mcc: 0.8253, acc: 0.7241, precision: 0.8985, recall: 0.7643, f1: 0.8259, edges-pos-ontonotes_loss: 0.0206
09/16 12:41:23 PM: Update 4748: task edges-pos-ontonotes, batch 748 (4748): mcc: 0.8257, acc: 0.7248, precision: 0.8987, recall: 0.7647, f1: 0.8263, edges-pos-ontonotes_loss: 0.0206
09/16 12:41:33 PM: Update 4805: task edges-pos-ontonotes, batch 805 (4805): mcc: 0.8266, acc: 0.7262, precision: 0.8994, recall: 0.7657, f1: 0.8272, edges-pos-ontonotes_loss: 0.0205
09/16 12:41:43 PM: Update 4851: task edges-pos-ontonotes, batch 851 (4851): mcc: 0.8273, acc: 0.7273, precision: 0.9000, recall: 0.7665, f1: 0.8279, edges-pos-ontonotes_loss: 0.0204
09/16 12:41:53 PM: Update 4902: task edges-pos-ontonotes, batch 902 (4902): mcc: 0.8280, acc: 0.7283, precision: 0.9005, recall: 0.7674, f1: 0.8286, edges-pos-ontonotes_loss: 0.0203
09/16 12:42:03 PM: Update 4951: task edges-pos-ontonotes, batch 951 (4951): mcc: 0.8286, acc: 0.7294, precision: 0.9008, recall: 0.7682, f1: 0.8292, edges-pos-ontonotes_loss: 0.0203
09/16 12:42:14 PM: Update 4995: task edges-pos-ontonotes, batch 995 (4995): mcc: 0.8294, acc: 0.7306, precision: 0.9012, recall: 0.7692, f1: 0.8300, edges-pos-ontonotes_loss: 0.0202
09/16 12:42:15 PM: ***** Step 5000 / Validation 5 *****
09/16 12:42:15 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:42:15 PM: Validating...
09/16 12:42:24 PM: Evaluate: task edges-pos-ontonotes, batch 53 (157): mcc: 0.8561, acc: 0.7683, precision: 0.9378, recall: 0.7864, f1: 0.8554, edges-pos-ontonotes_loss: 0.0172
09/16 12:42:34 PM: Evaluate: task edges-pos-ontonotes, batch 111 (157): mcc: 0.8680, acc: 0.7892, precision: 0.9332, recall: 0.8120, f1: 0.8684, edges-pos-ontonotes_loss: 0.0161
09/16 12:42:44 PM: Evaluate: task edges-pos-ontonotes, batch 156 (157): mcc: 0.8718, acc: 0.7969, precision: 0.9299, recall: 0.8221, f1: 0.8726, edges-pos-ontonotes_loss: 0.0157
09/16 12:42:44 PM: Best result seen so far for edges-pos-ontonotes.
09/16 12:42:44 PM: Best result seen so far for macro.
09/16 12:42:44 PM: Updating LR scheduler:
09/16 12:42:44 PM: 	Best result seen so far for macro_avg: 0.873
09/16 12:42:44 PM: 	# validation passes without improvement: 0
09/16 12:42:44 PM: edges-pos-ontonotes_loss: training: 0.020192 validation: 0.015696
09/16 12:42:44 PM: macro_avg: validation: 0.872713
09/16 12:42:44 PM: micro_avg: validation: 0.000000
09/16 12:42:44 PM: edges-pos-ontonotes_mcc: training: 0.829430 validation: 0.871893
09/16 12:42:44 PM: edges-pos-ontonotes_acc: training: 0.730639 validation: 0.797009
09/16 12:42:44 PM: edges-pos-ontonotes_precision: training: 0.901242 validation: 0.929939
09/16 12:42:44 PM: edges-pos-ontonotes_recall: training: 0.769301 validation: 0.822121
09/16 12:42:44 PM: edges-pos-ontonotes_f1: training: 0.830061 validation: 0.872713
09/16 12:42:44 PM: Global learning rate: 0.0001
09/16 12:42:44 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 12:43:01 PM: Update 5026: task edges-pos-ontonotes, batch 26 (5026): mcc: 0.8416, acc: 0.7494, precision: 0.9078, recall: 0.7858, f1: 0.8424, edges-pos-ontonotes_loss: 0.0184
09/16 12:43:11 PM: Update 5084: task edges-pos-ontonotes, batch 84 (5084): mcc: 0.8412, acc: 0.7486, precision: 0.9090, recall: 0.7841, f1: 0.8419, edges-pos-ontonotes_loss: 0.0190
09/16 12:43:21 PM: Update 5138: task edges-pos-ontonotes, batch 138 (5138): mcc: 0.8419, acc: 0.7497, precision: 0.9087, recall: 0.7855, f1: 0.8426, edges-pos-ontonotes_loss: 0.0189
09/16 12:43:31 PM: Update 5196: task edges-pos-ontonotes, batch 196 (5196): mcc: 0.8427, acc: 0.7513, precision: 0.9087, recall: 0.7871, f1: 0.8435, edges-pos-ontonotes_loss: 0.0188
09/16 12:43:42 PM: Update 5245: task edges-pos-ontonotes, batch 245 (5245): mcc: 0.8432, acc: 0.7523, precision: 0.9086, recall: 0.7880, f1: 0.8440, edges-pos-ontonotes_loss: 0.0187
09/16 12:43:52 PM: Update 5298: task edges-pos-ontonotes, batch 298 (5298): mcc: 0.8440, acc: 0.7535, precision: 0.9090, recall: 0.7892, f1: 0.8448, edges-pos-ontonotes_loss: 0.0186
09/16 12:44:02 PM: Update 5339: task edges-pos-ontonotes, batch 339 (5339): mcc: 0.8442, acc: 0.7536, precision: 0.9091, recall: 0.7894, f1: 0.8451, edges-pos-ontonotes_loss: 0.0186
09/16 12:44:12 PM: Update 5402: task edges-pos-ontonotes, batch 402 (5402): mcc: 0.8450, acc: 0.7548, precision: 0.9094, recall: 0.7907, f1: 0.8459, edges-pos-ontonotes_loss: 0.0184
09/16 12:44:22 PM: Update 5468: task edges-pos-ontonotes, batch 468 (5468): mcc: 0.8455, acc: 0.7555, precision: 0.9097, recall: 0.7914, f1: 0.8464, edges-pos-ontonotes_loss: 0.0182
09/16 12:44:32 PM: Update 5543: task edges-pos-ontonotes, batch 543 (5543): mcc: 0.8467, acc: 0.7569, precision: 0.9108, recall: 0.7926, f1: 0.8476, edges-pos-ontonotes_loss: 0.0179
09/16 12:44:42 PM: Update 5603: task edges-pos-ontonotes, batch 603 (5603): mcc: 0.8470, acc: 0.7574, precision: 0.9105, recall: 0.7934, f1: 0.8479, edges-pos-ontonotes_loss: 0.0178
09/16 12:44:53 PM: Update 5658: task edges-pos-ontonotes, batch 658 (5658): mcc: 0.8474, acc: 0.7579, precision: 0.9108, recall: 0.7938, f1: 0.8483, edges-pos-ontonotes_loss: 0.0177
09/16 12:45:03 PM: Update 5749: task edges-pos-ontonotes, batch 749 (5749): mcc: 0.8495, acc: 0.7606, precision: 0.9126, recall: 0.7961, f1: 0.8504, edges-pos-ontonotes_loss: 0.0174
09/16 12:45:13 PM: Update 5840: task edges-pos-ontonotes, batch 840 (5840): mcc: 0.8516, acc: 0.7634, precision: 0.9143, recall: 0.7986, f1: 0.8525, edges-pos-ontonotes_loss: 0.0171
09/16 12:45:23 PM: Update 5907: task edges-pos-ontonotes, batch 907 (5907): mcc: 0.8531, acc: 0.7653, precision: 0.9153, recall: 0.8003, f1: 0.8539, edges-pos-ontonotes_loss: 0.0169
09/16 12:45:34 PM: Update 5965: task edges-pos-ontonotes, batch 965 (5965): mcc: 0.8542, acc: 0.7669, precision: 0.9162, recall: 0.8017, f1: 0.8551, edges-pos-ontonotes_loss: 0.0167
09/16 12:45:38 PM: ***** Step 6000 / Validation 6 *****
09/16 12:45:38 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:45:38 PM: Validating...
09/16 12:45:44 PM: Evaluate: task edges-pos-ontonotes, batch 39 (157): mcc: 0.8610, acc: 0.7773, precision: 0.9361, recall: 0.7967, f1: 0.8608, edges-pos-ontonotes_loss: 0.0163
09/16 12:45:54 PM: Evaluate: task edges-pos-ontonotes, batch 99 (157): mcc: 0.8741, acc: 0.7998, precision: 0.9339, recall: 0.8227, f1: 0.8748, edges-pos-ontonotes_loss: 0.0151
09/16 12:46:04 PM: Evaluate: task edges-pos-ontonotes, batch 144 (157): mcc: 0.8752, acc: 0.8028, precision: 0.9289, recall: 0.8292, f1: 0.8762, edges-pos-ontonotes_loss: 0.0149
09/16 12:46:07 PM: Best result seen so far for edges-pos-ontonotes.
09/16 12:46:07 PM: Best result seen so far for macro.
09/16 12:46:07 PM: Updating LR scheduler:
09/16 12:46:07 PM: 	Best result seen so far for macro_avg: 0.878
09/16 12:46:07 PM: 	# validation passes without improvement: 0
09/16 12:46:07 PM: edges-pos-ontonotes_loss: training: 0.016698 validation: 0.014800
09/16 12:46:07 PM: macro_avg: validation: 0.877837
09/16 12:46:07 PM: micro_avg: validation: 0.000000
09/16 12:46:07 PM: edges-pos-ontonotes_mcc: training: 0.854583 validation: 0.876797
09/16 12:46:07 PM: edges-pos-ontonotes_acc: training: 0.767355 validation: 0.805528
09/16 12:46:07 PM: edges-pos-ontonotes_precision: training: 0.916587 validation: 0.929515
09/16 12:46:07 PM: edges-pos-ontonotes_recall: training: 0.801995 validation: 0.831603
09/16 12:46:07 PM: edges-pos-ontonotes_f1: training: 0.855471 validation: 0.877837
09/16 12:46:07 PM: Global learning rate: 0.0001
09/16 12:46:07 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 12:46:14 PM: Update 6054: task edges-pos-ontonotes, batch 54 (6054): mcc: 0.8730, acc: 0.7920, precision: 0.9335, recall: 0.8210, f1: 0.8736, edges-pos-ontonotes_loss: 0.0157
09/16 12:46:24 PM: Update 6134: task edges-pos-ontonotes, batch 134 (6134): mcc: 0.8732, acc: 0.7919, precision: 0.9340, recall: 0.8209, f1: 0.8738, edges-pos-ontonotes_loss: 0.0155
09/16 12:46:35 PM: Update 6223: task edges-pos-ontonotes, batch 223 (6223): mcc: 0.8758, acc: 0.7959, precision: 0.9339, recall: 0.8258, f1: 0.8766, edges-pos-ontonotes_loss: 0.0152
09/16 12:46:45 PM: Update 6319: task edges-pos-ontonotes, batch 319 (6319): mcc: 0.8719, acc: 0.7903, precision: 0.9311, recall: 0.8210, f1: 0.8726, edges-pos-ontonotes_loss: 0.0156
09/16 12:46:55 PM: Update 6443: task edges-pos-ontonotes, batch 443 (6443): mcc: 0.8637, acc: 0.7782, precision: 0.9259, recall: 0.8106, f1: 0.8644, edges-pos-ontonotes_loss: 0.0164
09/16 12:47:05 PM: Update 6565: task edges-pos-ontonotes, batch 565 (6565): mcc: 0.8603, acc: 0.7730, precision: 0.9237, recall: 0.8062, f1: 0.8609, edges-pos-ontonotes_loss: 0.0166
09/16 12:47:15 PM: Update 6628: task edges-pos-ontonotes, batch 628 (6628): mcc: 0.8561, acc: 0.7674, precision: 0.9190, recall: 0.8027, f1: 0.8569, edges-pos-ontonotes_loss: 0.0169
09/16 12:47:25 PM: Update 6692: task edges-pos-ontonotes, batch 692 (6692): mcc: 0.8523, acc: 0.7621, precision: 0.9149, recall: 0.7992, f1: 0.8532, edges-pos-ontonotes_loss: 0.0172
09/16 12:47:36 PM: Update 6740: task edges-pos-ontonotes, batch 740 (6740): mcc: 0.8491, acc: 0.7583, precision: 0.9113, recall: 0.7966, f1: 0.8501, edges-pos-ontonotes_loss: 0.0174
09/16 12:47:46 PM: Update 6791: task edges-pos-ontonotes, batch 791 (6791): mcc: 0.8476, acc: 0.7562, precision: 0.9097, recall: 0.7952, f1: 0.8486, edges-pos-ontonotes_loss: 0.0175
09/16 12:47:56 PM: Update 6835: task edges-pos-ontonotes, batch 835 (6835): mcc: 0.8466, acc: 0.7549, precision: 0.9088, recall: 0.7942, f1: 0.8476, edges-pos-ontonotes_loss: 0.0176
09/16 12:48:06 PM: Update 6891: task edges-pos-ontonotes, batch 891 (6891): mcc: 0.8457, acc: 0.7537, precision: 0.9079, recall: 0.7932, f1: 0.8467, edges-pos-ontonotes_loss: 0.0177
09/16 12:48:16 PM: Update 6956: task edges-pos-ontonotes, batch 956 (6956): mcc: 0.8446, acc: 0.7522, precision: 0.9075, recall: 0.7916, f1: 0.8456, edges-pos-ontonotes_loss: 0.0178
09/16 12:48:21 PM: ***** Step 7000 / Validation 7 *****
09/16 12:48:21 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:48:21 PM: Validating...
09/16 12:48:26 PM: Evaluate: task edges-pos-ontonotes, batch 33 (157): mcc: 0.8795, acc: 0.8095, precision: 0.9339, recall: 0.8326, f1: 0.8804, edges-pos-ontonotes_loss: 0.0147
09/16 12:48:36 PM: Evaluate: task edges-pos-ontonotes, batch 95 (157): mcc: 0.8894, acc: 0.8246, precision: 0.9321, recall: 0.8528, f1: 0.8907, edges-pos-ontonotes_loss: 0.0138
09/16 12:48:46 PM: Evaluate: task edges-pos-ontonotes, batch 140 (157): mcc: 0.8884, acc: 0.8243, precision: 0.9245, recall: 0.8580, f1: 0.8900, edges-pos-ontonotes_loss: 0.0138
09/16 12:48:50 PM: Best result seen so far for edges-pos-ontonotes.
09/16 12:48:50 PM: Best result seen so far for macro.
09/16 12:48:50 PM: Updating LR scheduler:
09/16 12:48:50 PM: 	Best result seen so far for macro_avg: 0.891
09/16 12:48:50 PM: 	# validation passes without improvement: 0
09/16 12:48:50 PM: edges-pos-ontonotes_loss: training: 0.017812 validation: 0.013749
09/16 12:48:50 PM: macro_avg: validation: 0.890744
09/16 12:48:50 PM: micro_avg: validation: 0.000000
09/16 12:48:50 PM: edges-pos-ontonotes_mcc: training: 0.844242 validation: 0.889096
09/16 12:48:50 PM: edges-pos-ontonotes_acc: training: 0.751569 validation: 0.826079
09/16 12:48:50 PM: edges-pos-ontonotes_precision: training: 0.907578 validation: 0.923772
09/16 12:48:50 PM: edges-pos-ontonotes_recall: training: 0.790897 validation: 0.859996
09/16 12:48:50 PM: edges-pos-ontonotes_f1: training: 0.845230 validation: 0.890744
09/16 12:48:50 PM: Global learning rate: 0.0001
09/16 12:48:50 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 12:48:56 PM: Update 7058: task edges-pos-ontonotes, batch 58 (7058): mcc: 0.8446, acc: 0.7503, precision: 0.9170, recall: 0.7834, f1: 0.8449, edges-pos-ontonotes_loss: 0.0169
09/16 12:49:06 PM: Update 7139: task edges-pos-ontonotes, batch 139 (7139): mcc: 0.8439, acc: 0.7488, precision: 0.9152, recall: 0.7835, f1: 0.8443, edges-pos-ontonotes_loss: 0.0171
09/16 12:49:16 PM: Update 7232: task edges-pos-ontonotes, batch 232 (7232): mcc: 0.8449, acc: 0.7505, precision: 0.9147, recall: 0.7859, f1: 0.8454, edges-pos-ontonotes_loss: 0.0170
09/16 12:49:26 PM: Update 7289: task edges-pos-ontonotes, batch 289 (7289): mcc: 0.8476, acc: 0.7553, precision: 0.9115, recall: 0.7936, f1: 0.8484, edges-pos-ontonotes_loss: 0.0170
09/16 12:49:37 PM: Update 7356: task edges-pos-ontonotes, batch 356 (7356): mcc: 0.8488, acc: 0.7577, precision: 0.9098, recall: 0.7973, f1: 0.8499, edges-pos-ontonotes_loss: 0.0169
09/16 12:49:47 PM: Update 7427: task edges-pos-ontonotes, batch 427 (7427): mcc: 0.8498, acc: 0.7596, precision: 0.9090, recall: 0.8000, f1: 0.8510, edges-pos-ontonotes_loss: 0.0169
09/16 12:49:57 PM: Update 7497: task edges-pos-ontonotes, batch 497 (7497): mcc: 0.8504, acc: 0.7605, precision: 0.9087, recall: 0.8012, f1: 0.8516, edges-pos-ontonotes_loss: 0.0168
09/16 12:50:16 PM: Update 7547: task edges-pos-ontonotes, batch 547 (7547): mcc: 0.8509, acc: 0.7616, precision: 0.9086, recall: 0.8023, f1: 0.8522, edges-pos-ontonotes_loss: 0.0168
09/16 12:50:26 PM: Update 7598: task edges-pos-ontonotes, batch 598 (7598): mcc: 0.8494, acc: 0.7598, precision: 0.9062, recall: 0.8016, f1: 0.8507, edges-pos-ontonotes_loss: 0.0169
09/16 12:50:36 PM: Update 7652: task edges-pos-ontonotes, batch 652 (7652): mcc: 0.8490, acc: 0.7597, precision: 0.9052, recall: 0.8018, f1: 0.8504, edges-pos-ontonotes_loss: 0.0170
09/16 12:50:46 PM: Update 7702: task edges-pos-ontonotes, batch 702 (7702): mcc: 0.8487, acc: 0.7594, precision: 0.9046, recall: 0.8017, f1: 0.8500, edges-pos-ontonotes_loss: 0.0171
09/16 12:50:57 PM: Update 7763: task edges-pos-ontonotes, batch 763 (7763): mcc: 0.8489, acc: 0.7599, precision: 0.9047, recall: 0.8021, f1: 0.8503, edges-pos-ontonotes_loss: 0.0171
09/16 12:51:07 PM: Update 7816: task edges-pos-ontonotes, batch 816 (7816): mcc: 0.8491, acc: 0.7603, precision: 0.9046, recall: 0.8026, f1: 0.8505, edges-pos-ontonotes_loss: 0.0171
09/16 12:51:18 PM: Update 7860: task edges-pos-ontonotes, batch 860 (7860): mcc: 0.8490, acc: 0.7602, precision: 0.9042, recall: 0.8027, f1: 0.8505, edges-pos-ontonotes_loss: 0.0172
09/16 12:51:28 PM: Update 7904: task edges-pos-ontonotes, batch 904 (7904): mcc: 0.8489, acc: 0.7601, precision: 0.9037, recall: 0.8029, f1: 0.8503, edges-pos-ontonotes_loss: 0.0172
09/16 12:51:38 PM: Update 7956: task edges-pos-ontonotes, batch 956 (7956): mcc: 0.8494, acc: 0.7611, precision: 0.9039, recall: 0.8037, f1: 0.8509, edges-pos-ontonotes_loss: 0.0172
09/16 12:51:48 PM: ***** Step 8000 / Validation 8 *****
09/16 12:51:48 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:51:48 PM: Validating...
09/16 12:51:48 PM: Evaluate: task edges-pos-ontonotes, batch 1 (157): mcc: 0.8977, acc: 0.8365, precision: 0.9540, recall: 0.8484, f1: 0.8981, edges-pos-ontonotes_loss: 0.0123
09/16 12:51:58 PM: Evaluate: task edges-pos-ontonotes, batch 70 (157): mcc: 0.8892, acc: 0.8221, precision: 0.9444, recall: 0.8412, f1: 0.8898, edges-pos-ontonotes_loss: 0.0134
09/16 12:52:08 PM: Evaluate: task edges-pos-ontonotes, batch 122 (157): mcc: 0.8931, acc: 0.8297, precision: 0.9402, recall: 0.8524, f1: 0.8942, edges-pos-ontonotes_loss: 0.0129
09/16 12:52:16 PM: Best result seen so far for edges-pos-ontonotes.
09/16 12:52:16 PM: Best result seen so far for macro.
09/16 12:52:16 PM: Updating LR scheduler:
09/16 12:52:16 PM: 	Best result seen so far for macro_avg: 0.895
09/16 12:52:16 PM: 	# validation passes without improvement: 0
09/16 12:52:16 PM: edges-pos-ontonotes_loss: training: 0.017128 validation: 0.012827
09/16 12:52:16 PM: macro_avg: validation: 0.895145
09/16 12:52:16 PM: micro_avg: validation: 0.000000
09/16 12:52:16 PM: edges-pos-ontonotes_mcc: training: 0.849813 validation: 0.893939
09/16 12:52:16 PM: edges-pos-ontonotes_acc: training: 0.761693 validation: 0.832619
09/16 12:52:16 PM: edges-pos-ontonotes_precision: training: 0.903978 validation: 0.936869
09/16 12:52:16 PM: edges-pos-ontonotes_recall: training: 0.804398 validation: 0.856980
09/16 12:52:16 PM: edges-pos-ontonotes_f1: training: 0.851286 validation: 0.895145
09/16 12:52:16 PM: Global learning rate: 0.0001
09/16 12:52:16 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 12:52:18 PM: Update 8013: task edges-pos-ontonotes, batch 13 (8013): mcc: 0.8479, acc: 0.7609, precision: 0.9006, recall: 0.8039, f1: 0.8495, edges-pos-ontonotes_loss: 0.0175
09/16 12:52:28 PM: Update 8059: task edges-pos-ontonotes, batch 59 (8059): mcc: 0.8564, acc: 0.7735, precision: 0.9082, recall: 0.8128, f1: 0.8579, edges-pos-ontonotes_loss: 0.0168
09/16 12:52:39 PM: Update 8111: task edges-pos-ontonotes, batch 111 (8111): mcc: 0.8573, acc: 0.7758, precision: 0.9072, recall: 0.8155, f1: 0.8589, edges-pos-ontonotes_loss: 0.0166
09/16 12:52:49 PM: Update 8166: task edges-pos-ontonotes, batch 166 (8166): mcc: 0.8578, acc: 0.7763, precision: 0.9070, recall: 0.8165, f1: 0.8594, edges-pos-ontonotes_loss: 0.0166
09/16 12:52:59 PM: Update 8206: task edges-pos-ontonotes, batch 206 (8206): mcc: 0.8564, acc: 0.7743, precision: 0.9065, recall: 0.8144, f1: 0.8580, edges-pos-ontonotes_loss: 0.0168
09/16 12:53:09 PM: Update 8261: task edges-pos-ontonotes, batch 261 (8261): mcc: 0.8566, acc: 0.7744, precision: 0.9065, recall: 0.8148, f1: 0.8582, edges-pos-ontonotes_loss: 0.0168
09/16 12:53:19 PM: Update 8317: task edges-pos-ontonotes, batch 317 (8317): mcc: 0.8574, acc: 0.7755, precision: 0.9074, recall: 0.8154, f1: 0.8589, edges-pos-ontonotes_loss: 0.0168
09/16 12:53:29 PM: Update 8375: task edges-pos-ontonotes, batch 375 (8375): mcc: 0.8578, acc: 0.7761, precision: 0.9077, recall: 0.8160, f1: 0.8594, edges-pos-ontonotes_loss: 0.0167
09/16 12:53:39 PM: Update 8428: task edges-pos-ontonotes, batch 428 (8428): mcc: 0.8586, acc: 0.7774, precision: 0.9083, recall: 0.8170, f1: 0.8602, edges-pos-ontonotes_loss: 0.0166
09/16 12:53:49 PM: Update 8484: task edges-pos-ontonotes, batch 484 (8484): mcc: 0.8594, acc: 0.7784, precision: 0.9089, recall: 0.8177, f1: 0.8609, edges-pos-ontonotes_loss: 0.0166
09/16 12:53:59 PM: Update 8522: task edges-pos-ontonotes, batch 522 (8522): mcc: 0.8594, acc: 0.7785, precision: 0.9089, recall: 0.8179, f1: 0.8610, edges-pos-ontonotes_loss: 0.0166
09/16 12:54:09 PM: Update 8579: task edges-pos-ontonotes, batch 579 (8579): mcc: 0.8596, acc: 0.7788, precision: 0.9089, recall: 0.8182, f1: 0.8612, edges-pos-ontonotes_loss: 0.0165
09/16 12:54:19 PM: Update 8636: task edges-pos-ontonotes, batch 636 (8636): mcc: 0.8603, acc: 0.7797, precision: 0.9094, recall: 0.8190, f1: 0.8618, edges-pos-ontonotes_loss: 0.0165
09/16 12:54:30 PM: Update 8692: task edges-pos-ontonotes, batch 692 (8692): mcc: 0.8607, acc: 0.7805, precision: 0.9098, recall: 0.8195, f1: 0.8623, edges-pos-ontonotes_loss: 0.0165
09/16 12:54:40 PM: Update 8752: task edges-pos-ontonotes, batch 752 (8752): mcc: 0.8609, acc: 0.7807, precision: 0.9100, recall: 0.8196, f1: 0.8624, edges-pos-ontonotes_loss: 0.0165
09/16 12:54:51 PM: Update 8799: task edges-pos-ontonotes, batch 799 (8799): mcc: 0.8610, acc: 0.7810, precision: 0.9100, recall: 0.8198, f1: 0.8626, edges-pos-ontonotes_loss: 0.0165
09/16 12:55:01 PM: Update 8859: task edges-pos-ontonotes, batch 859 (8859): mcc: 0.8613, acc: 0.7813, precision: 0.9102, recall: 0.8203, f1: 0.8629, edges-pos-ontonotes_loss: 0.0163
09/16 12:55:11 PM: Update 8930: task edges-pos-ontonotes, batch 930 (8930): mcc: 0.8616, acc: 0.7817, precision: 0.9103, recall: 0.8207, f1: 0.8632, edges-pos-ontonotes_loss: 0.0162
09/16 12:55:21 PM: Update 8993: task edges-pos-ontonotes, batch 993 (8993): mcc: 0.8619, acc: 0.7820, precision: 0.9104, recall: 0.8211, f1: 0.8634, edges-pos-ontonotes_loss: 0.0161
09/16 12:55:22 PM: ***** Step 9000 / Validation 9 *****
09/16 12:55:22 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:55:22 PM: Validating...
09/16 12:55:31 PM: Evaluate: task edges-pos-ontonotes, batch 60 (157): mcc: 0.8862, acc: 0.8174, precision: 0.9423, recall: 0.8376, f1: 0.8869, edges-pos-ontonotes_loss: 0.0137
09/16 12:55:41 PM: Evaluate: task edges-pos-ontonotes, batch 114 (157): mcc: 0.8938, acc: 0.8315, precision: 0.9390, recall: 0.8547, f1: 0.8949, edges-pos-ontonotes_loss: 0.0129
09/16 12:55:51 PM: Best result seen so far for edges-pos-ontonotes.
09/16 12:55:51 PM: Best result seen so far for macro.
09/16 12:55:51 PM: Updating LR scheduler:
09/16 12:55:51 PM: 	Best result seen so far for macro_avg: 0.898
09/16 12:55:51 PM: 	# validation passes without improvement: 0
09/16 12:55:51 PM: edges-pos-ontonotes_loss: training: 0.016066 validation: 0.012561
09/16 12:55:51 PM: macro_avg: validation: 0.898091
09/16 12:55:51 PM: micro_avg: validation: 0.000000
09/16 12:55:51 PM: edges-pos-ontonotes_mcc: training: 0.861928 validation: 0.896812
09/16 12:55:51 PM: edges-pos-ontonotes_acc: training: 0.782027 validation: 0.837550
09/16 12:55:51 PM: edges-pos-ontonotes_precision: training: 0.910465 validation: 0.936792
09/16 12:55:51 PM: edges-pos-ontonotes_recall: training: 0.821116 validation: 0.862461
09/16 12:55:51 PM: edges-pos-ontonotes_f1: training: 0.863485 validation: 0.898091
09/16 12:55:51 PM: Global learning rate: 0.0001
09/16 12:55:51 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 12:55:51 PM: Update 9006: task edges-pos-ontonotes, batch 6 (9006): mcc: 0.8713, acc: 0.7913, precision: 0.9182, recall: 0.8316, f1: 0.8727, edges-pos-ontonotes_loss: 0.0140
09/16 12:56:02 PM: Update 9077: task edges-pos-ontonotes, batch 77 (9077): mcc: 0.8701, acc: 0.7917, precision: 0.9157, recall: 0.8317, f1: 0.8717, edges-pos-ontonotes_loss: 0.0142
09/16 12:56:20 PM: Update 9112: task edges-pos-ontonotes, batch 112 (9112): mcc: 0.8697, acc: 0.7914, precision: 0.9155, recall: 0.8312, f1: 0.8713, edges-pos-ontonotes_loss: 0.0142
09/16 12:56:30 PM: Update 9206: task edges-pos-ontonotes, batch 206 (9206): mcc: 0.8786, acc: 0.8029, precision: 0.9232, recall: 0.8406, f1: 0.8800, edges-pos-ontonotes_loss: 0.0135
09/16 12:56:40 PM: Update 9299: task edges-pos-ontonotes, batch 299 (9299): mcc: 0.8831, acc: 0.8090, precision: 0.9271, recall: 0.8456, f1: 0.8845, edges-pos-ontonotes_loss: 0.0132
09/16 12:56:50 PM: Update 9387: task edges-pos-ontonotes, batch 387 (9387): mcc: 0.8859, acc: 0.8130, precision: 0.9292, recall: 0.8490, f1: 0.8873, edges-pos-ontonotes_loss: 0.0130
09/16 12:57:00 PM: Update 9468: task edges-pos-ontonotes, batch 468 (9468): mcc: 0.8865, acc: 0.8138, precision: 0.9302, recall: 0.8492, f1: 0.8878, edges-pos-ontonotes_loss: 0.0130
09/16 12:57:10 PM: Update 9571: task edges-pos-ontonotes, batch 571 (9571): mcc: 0.8867, acc: 0.8142, precision: 0.9310, recall: 0.8488, f1: 0.8880, edges-pos-ontonotes_loss: 0.0130
09/16 12:57:20 PM: Update 9691: task edges-pos-ontonotes, batch 691 (9691): mcc: 0.8873, acc: 0.8151, precision: 0.9317, recall: 0.8492, f1: 0.8885, edges-pos-ontonotes_loss: 0.0130
09/16 12:57:30 PM: Update 9790: task edges-pos-ontonotes, batch 790 (9790): mcc: 0.8859, acc: 0.8131, precision: 0.9312, recall: 0.8471, f1: 0.8872, edges-pos-ontonotes_loss: 0.0133
09/16 12:57:40 PM: Update 9938: task edges-pos-ontonotes, batch 938 (9938): mcc: 0.8835, acc: 0.8094, precision: 0.9298, recall: 0.8438, f1: 0.8847, edges-pos-ontonotes_loss: 0.0137
09/16 12:57:45 PM: ***** Step 10000 / Validation 10 *****
09/16 12:57:45 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:57:45 PM: Validating...
09/16 12:57:50 PM: Evaluate: task edges-pos-ontonotes, batch 36 (157): mcc: 0.8873, acc: 0.8206, precision: 0.9372, recall: 0.8443, f1: 0.8883, edges-pos-ontonotes_loss: 0.0134
09/16 12:58:00 PM: Evaluate: task edges-pos-ontonotes, batch 98 (157): mcc: 0.8955, acc: 0.8354, precision: 0.9340, recall: 0.8626, f1: 0.8969, edges-pos-ontonotes_loss: 0.0127
09/16 12:58:10 PM: Evaluate: task edges-pos-ontonotes, batch 141 (157): mcc: 0.8944, acc: 0.8345, precision: 0.9254, recall: 0.8686, f1: 0.8961, edges-pos-ontonotes_loss: 0.0127
09/16 12:58:14 PM: Updating LR scheduler:
09/16 12:58:14 PM: 	Best result seen so far for macro_avg: 0.898
09/16 12:58:14 PM: 	# validation passes without improvement: 1
09/16 12:58:14 PM: edges-pos-ontonotes_loss: training: 0.013870 validation: 0.012632
09/16 12:58:14 PM: macro_avg: validation: 0.897114
09/16 12:58:14 PM: micro_avg: validation: 0.000000
09/16 12:58:14 PM: edges-pos-ontonotes_mcc: training: 0.882301 validation: 0.895417
09/16 12:58:14 PM: edges-pos-ontonotes_acc: training: 0.807624 validation: 0.836736
09/16 12:58:14 PM: edges-pos-ontonotes_precision: training: 0.929090 validation: 0.925043
09/16 12:58:14 PM: edges-pos-ontonotes_recall: training: 0.842267 validation: 0.870821
09/16 12:58:14 PM: edges-pos-ontonotes_f1: training: 0.883551 validation: 0.897114
09/16 12:58:14 PM: Global learning rate: 0.0001
09/16 12:58:14 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 12:58:22 PM: Update 10051: task edges-pos-ontonotes, batch 51 (10051): mcc: 0.8542, acc: 0.7668, precision: 0.9078, recall: 0.8091, f1: 0.8556, edges-pos-ontonotes_loss: 0.0164
09/16 12:58:32 PM: Update 10095: task edges-pos-ontonotes, batch 95 (10095): mcc: 0.8481, acc: 0.7599, precision: 0.8975, recall: 0.8072, f1: 0.8499, edges-pos-ontonotes_loss: 0.0172
09/16 12:58:42 PM: Update 10156: task edges-pos-ontonotes, batch 156 (10156): mcc: 0.8468, acc: 0.7574, precision: 0.8960, recall: 0.8060, f1: 0.8487, edges-pos-ontonotes_loss: 0.0175
09/16 12:58:52 PM: Update 10214: task edges-pos-ontonotes, batch 214 (10214): mcc: 0.8479, acc: 0.7586, precision: 0.8972, recall: 0.8070, f1: 0.8497, edges-pos-ontonotes_loss: 0.0176
09/16 12:59:03 PM: Update 10274: task edges-pos-ontonotes, batch 274 (10274): mcc: 0.8487, acc: 0.7599, precision: 0.8979, recall: 0.8078, f1: 0.8505, edges-pos-ontonotes_loss: 0.0176
09/16 12:59:13 PM: Update 10323: task edges-pos-ontonotes, batch 323 (10323): mcc: 0.8492, acc: 0.7610, precision: 0.8983, recall: 0.8085, f1: 0.8510, edges-pos-ontonotes_loss: 0.0176
09/16 12:59:23 PM: Update 10372: task edges-pos-ontonotes, batch 372 (10372): mcc: 0.8494, acc: 0.7612, precision: 0.8988, recall: 0.8083, f1: 0.8511, edges-pos-ontonotes_loss: 0.0176
09/16 12:59:33 PM: Update 10444: task edges-pos-ontonotes, batch 444 (10444): mcc: 0.8496, acc: 0.7612, precision: 0.9005, recall: 0.8071, f1: 0.8513, edges-pos-ontonotes_loss: 0.0174
09/16 12:59:43 PM: Update 10522: task edges-pos-ontonotes, batch 522 (10522): mcc: 0.8500, acc: 0.7616, precision: 0.9020, recall: 0.8066, f1: 0.8516, edges-pos-ontonotes_loss: 0.0173
09/16 12:59:53 PM: Update 10602: task edges-pos-ontonotes, batch 602 (10602): mcc: 0.8506, acc: 0.7624, precision: 0.9032, recall: 0.8067, f1: 0.8522, edges-pos-ontonotes_loss: 0.0171
09/16 01:00:04 PM: Update 10694: task edges-pos-ontonotes, batch 694 (10694): mcc: 0.8514, acc: 0.7634, precision: 0.9043, recall: 0.8072, f1: 0.8530, edges-pos-ontonotes_loss: 0.0169
09/16 01:00:14 PM: Update 10759: task edges-pos-ontonotes, batch 759 (10759): mcc: 0.8525, acc: 0.7651, precision: 0.9044, recall: 0.8091, f1: 0.8541, edges-pos-ontonotes_loss: 0.0168
09/16 01:00:24 PM: Update 10829: task edges-pos-ontonotes, batch 829 (10829): mcc: 0.8537, acc: 0.7667, precision: 0.9047, recall: 0.8109, f1: 0.8553, edges-pos-ontonotes_loss: 0.0166
09/16 01:00:35 PM: Update 10901: task edges-pos-ontonotes, batch 901 (10901): mcc: 0.8548, acc: 0.7684, precision: 0.9052, recall: 0.8126, f1: 0.8564, edges-pos-ontonotes_loss: 0.0165
09/16 01:00:45 PM: Update 10955: task edges-pos-ontonotes, batch 955 (10955): mcc: 0.8554, acc: 0.7693, precision: 0.9054, recall: 0.8135, f1: 0.8570, edges-pos-ontonotes_loss: 0.0164
09/16 01:00:51 PM: ***** Step 11000 / Validation 11 *****
09/16 01:00:51 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:00:51 PM: Validating...
09/16 01:00:55 PM: Evaluate: task edges-pos-ontonotes, batch 22 (157): mcc: 0.8896, acc: 0.8266, precision: 0.9362, recall: 0.8496, f1: 0.8908, edges-pos-ontonotes_loss: 0.0130
09/16 01:01:05 PM: Evaluate: task edges-pos-ontonotes, batch 89 (157): mcc: 0.9036, acc: 0.8461, precision: 0.9436, recall: 0.8690, f1: 0.9048, edges-pos-ontonotes_loss: 0.0118
09/16 01:01:15 PM: Evaluate: task edges-pos-ontonotes, batch 134 (157): mcc: 0.9021, acc: 0.8451, precision: 0.9367, recall: 0.8725, f1: 0.9034, edges-pos-ontonotes_loss: 0.0118
09/16 01:01:20 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:01:20 PM: Best result seen so far for macro.
09/16 01:01:20 PM: Updating LR scheduler:
09/16 01:01:20 PM: 	Best result seen so far for macro_avg: 0.904
09/16 01:01:20 PM: 	# validation passes without improvement: 0
09/16 01:01:20 PM: edges-pos-ontonotes_loss: training: 0.016349 validation: 0.011793
09/16 01:01:20 PM: macro_avg: validation: 0.904040
09/16 01:01:20 PM: micro_avg: validation: 0.000000
09/16 01:01:20 PM: edges-pos-ontonotes_mcc: training: 0.855801 validation: 0.902604
09/16 01:01:20 PM: edges-pos-ontonotes_acc: training: 0.769832 validation: 0.847032
09/16 01:01:20 PM: edges-pos-ontonotes_precision: training: 0.905653 validation: 0.935604
09/16 01:01:20 PM: edges-pos-ontonotes_recall: training: 0.814038 validation: 0.874536
09/16 01:01:20 PM: edges-pos-ontonotes_f1: training: 0.857405 validation: 0.904040
09/16 01:01:20 PM: Global learning rate: 0.0001
09/16 01:01:20 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:01:25 PM: Update 11018: task edges-pos-ontonotes, batch 18 (11018): mcc: 0.8496, acc: 0.7651, precision: 0.8942, recall: 0.8129, f1: 0.8516, edges-pos-ontonotes_loss: 0.0179
09/16 01:01:35 PM: Update 11076: task edges-pos-ontonotes, batch 76 (11076): mcc: 0.8556, acc: 0.7719, precision: 0.8997, recall: 0.8191, f1: 0.8575, edges-pos-ontonotes_loss: 0.0169
09/16 01:01:45 PM: Update 11130: task edges-pos-ontonotes, batch 130 (11130): mcc: 0.8567, acc: 0.7730, precision: 0.8994, recall: 0.8213, f1: 0.8586, edges-pos-ontonotes_loss: 0.0168
09/16 01:01:55 PM: Update 11176: task edges-pos-ontonotes, batch 176 (11176): mcc: 0.8565, acc: 0.7730, precision: 0.8993, recall: 0.8212, f1: 0.8585, edges-pos-ontonotes_loss: 0.0168
09/16 01:02:05 PM: Update 11221: task edges-pos-ontonotes, batch 221 (11221): mcc: 0.8568, acc: 0.7737, precision: 0.8993, recall: 0.8217, f1: 0.8587, edges-pos-ontonotes_loss: 0.0168
09/16 01:02:15 PM: Update 11280: task edges-pos-ontonotes, batch 280 (11280): mcc: 0.8573, acc: 0.7745, precision: 0.9000, recall: 0.8221, f1: 0.8593, edges-pos-ontonotes_loss: 0.0166
09/16 01:02:35 PM: Update 11320: task edges-pos-ontonotes, batch 320 (11320): mcc: 0.8570, acc: 0.7740, precision: 0.9002, recall: 0.8212, f1: 0.8589, edges-pos-ontonotes_loss: 0.0166
09/16 01:02:46 PM: Update 11372: task edges-pos-ontonotes, batch 372 (11372): mcc: 0.8579, acc: 0.7754, precision: 0.9006, recall: 0.8225, f1: 0.8598, edges-pos-ontonotes_loss: 0.0166
09/16 01:02:56 PM: Update 11414: task edges-pos-ontonotes, batch 414 (11414): mcc: 0.8586, acc: 0.7765, precision: 0.9015, recall: 0.8232, f1: 0.8606, edges-pos-ontonotes_loss: 0.0165
09/16 01:03:06 PM: Update 11454: task edges-pos-ontonotes, batch 454 (11454): mcc: 0.8594, acc: 0.7774, precision: 0.9020, recall: 0.8241, f1: 0.8613, edges-pos-ontonotes_loss: 0.0164
09/16 01:03:16 PM: Update 11507: task edges-pos-ontonotes, batch 507 (11507): mcc: 0.8597, acc: 0.7781, precision: 0.9023, recall: 0.8244, f1: 0.8616, edges-pos-ontonotes_loss: 0.0163
09/16 01:03:26 PM: Update 11563: task edges-pos-ontonotes, batch 563 (11563): mcc: 0.8600, acc: 0.7787, precision: 0.9027, recall: 0.8247, f1: 0.8619, edges-pos-ontonotes_loss: 0.0163
09/16 01:03:36 PM: Update 11614: task edges-pos-ontonotes, batch 614 (11614): mcc: 0.8608, acc: 0.7797, precision: 0.9033, recall: 0.8256, f1: 0.8627, edges-pos-ontonotes_loss: 0.0162
09/16 01:03:46 PM: Update 11658: task edges-pos-ontonotes, batch 658 (11658): mcc: 0.8610, acc: 0.7801, precision: 0.9036, recall: 0.8257, f1: 0.8629, edges-pos-ontonotes_loss: 0.0162
09/16 01:03:56 PM: Update 11716: task edges-pos-ontonotes, batch 716 (11716): mcc: 0.8615, acc: 0.7809, precision: 0.9040, recall: 0.8262, f1: 0.8633, edges-pos-ontonotes_loss: 0.0162
09/16 01:04:07 PM: Update 11773: task edges-pos-ontonotes, batch 773 (11773): mcc: 0.8622, acc: 0.7819, precision: 0.9046, recall: 0.8269, f1: 0.8640, edges-pos-ontonotes_loss: 0.0161
09/16 01:04:17 PM: Update 11827: task edges-pos-ontonotes, batch 827 (11827): mcc: 0.8627, acc: 0.7828, precision: 0.9052, recall: 0.8274, f1: 0.8646, edges-pos-ontonotes_loss: 0.0160
09/16 01:04:27 PM: Update 11877: task edges-pos-ontonotes, batch 877 (11877): mcc: 0.8632, acc: 0.7835, precision: 0.9056, recall: 0.8280, f1: 0.8650, edges-pos-ontonotes_loss: 0.0160
09/16 01:04:37 PM: Update 11929: task edges-pos-ontonotes, batch 929 (11929): mcc: 0.8636, acc: 0.7841, precision: 0.9060, recall: 0.8283, f1: 0.8654, edges-pos-ontonotes_loss: 0.0159
09/16 01:04:47 PM: Update 11969: task edges-pos-ontonotes, batch 969 (11969): mcc: 0.8638, acc: 0.7845, precision: 0.9061, recall: 0.8286, f1: 0.8656, edges-pos-ontonotes_loss: 0.0159
09/16 01:04:52 PM: ***** Step 12000 / Validation 12 *****
09/16 01:04:52 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:04:52 PM: Validating...
09/16 01:04:57 PM: Evaluate: task edges-pos-ontonotes, batch 31 (157): mcc: 0.8924, acc: 0.8271, precision: 0.9446, recall: 0.8471, f1: 0.8932, edges-pos-ontonotes_loss: 0.0128
09/16 01:05:07 PM: Evaluate: task edges-pos-ontonotes, batch 95 (157): mcc: 0.9015, acc: 0.8426, precision: 0.9447, recall: 0.8639, f1: 0.9025, edges-pos-ontonotes_loss: 0.0120
09/16 01:05:17 PM: Evaluate: task edges-pos-ontonotes, batch 141 (157): mcc: 0.9028, acc: 0.8463, precision: 0.9406, recall: 0.8702, f1: 0.9040, edges-pos-ontonotes_loss: 0.0117
09/16 01:05:20 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:05:20 PM: Best result seen so far for macro.
09/16 01:05:20 PM: Updating LR scheduler:
09/16 01:05:20 PM: 	Best result seen so far for macro_avg: 0.905
09/16 01:05:20 PM: 	# validation passes without improvement: 0
09/16 01:05:20 PM: edges-pos-ontonotes_loss: training: 0.015911 validation: 0.011620
09/16 01:05:20 PM: macro_avg: validation: 0.905297
09/16 01:05:20 PM: micro_avg: validation: 0.000000
09/16 01:05:20 PM: edges-pos-ontonotes_mcc: training: 0.863974 validation: 0.904015
09/16 01:05:20 PM: edges-pos-ontonotes_acc: training: 0.784850 validation: 0.848937
09/16 01:05:20 PM: edges-pos-ontonotes_precision: training: 0.906202 validation: 0.940417
09/16 01:05:20 PM: edges-pos-ontonotes_recall: training: 0.828857 validation: 0.872705
09/16 01:05:20 PM: edges-pos-ontonotes_f1: training: 0.865806 validation: 0.905297
09/16 01:05:20 PM: Global learning rate: 0.0001
09/16 01:05:20 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:05:27 PM: Update 12038: task edges-pos-ontonotes, batch 38 (12038): mcc: 0.8701, acc: 0.7943, precision: 0.9109, recall: 0.8361, f1: 0.8719, edges-pos-ontonotes_loss: 0.0154
09/16 01:05:37 PM: Update 12094: task edges-pos-ontonotes, batch 94 (12094): mcc: 0.8705, acc: 0.7958, precision: 0.9122, recall: 0.8356, f1: 0.8722, edges-pos-ontonotes_loss: 0.0158
09/16 01:05:48 PM: Update 12149: task edges-pos-ontonotes, batch 149 (12149): mcc: 0.8709, acc: 0.7960, precision: 0.9129, recall: 0.8357, f1: 0.8726, edges-pos-ontonotes_loss: 0.0156
09/16 01:05:58 PM: Update 12193: task edges-pos-ontonotes, batch 193 (12193): mcc: 0.8699, acc: 0.7947, precision: 0.9118, recall: 0.8348, f1: 0.8716, edges-pos-ontonotes_loss: 0.0157
09/16 01:06:08 PM: Update 12246: task edges-pos-ontonotes, batch 246 (12246): mcc: 0.8706, acc: 0.7955, precision: 0.9122, recall: 0.8357, f1: 0.8723, edges-pos-ontonotes_loss: 0.0155
09/16 01:06:18 PM: Update 12289: task edges-pos-ontonotes, batch 289 (12289): mcc: 0.8701, acc: 0.7949, precision: 0.9120, recall: 0.8350, f1: 0.8718, edges-pos-ontonotes_loss: 0.0153
09/16 01:06:28 PM: Update 12357: task edges-pos-ontonotes, batch 357 (12357): mcc: 0.8710, acc: 0.7958, precision: 0.9129, recall: 0.8359, f1: 0.8727, edges-pos-ontonotes_loss: 0.0150
09/16 01:06:38 PM: Update 12428: task edges-pos-ontonotes, batch 428 (12428): mcc: 0.8721, acc: 0.7973, precision: 0.9137, recall: 0.8373, f1: 0.8738, edges-pos-ontonotes_loss: 0.0147
09/16 01:06:48 PM: Update 12494: task edges-pos-ontonotes, batch 494 (12494): mcc: 0.8725, acc: 0.7980, precision: 0.9136, recall: 0.8380, f1: 0.8742, edges-pos-ontonotes_loss: 0.0145
09/16 01:06:58 PM: Update 12557: task edges-pos-ontonotes, batch 557 (12557): mcc: 0.8730, acc: 0.7986, precision: 0.9138, recall: 0.8388, f1: 0.8747, edges-pos-ontonotes_loss: 0.0144
09/16 01:07:08 PM: Update 12623: task edges-pos-ontonotes, batch 623 (12623): mcc: 0.8749, acc: 0.8010, precision: 0.9155, recall: 0.8408, f1: 0.8765, edges-pos-ontonotes_loss: 0.0142
09/16 01:07:18 PM: Update 12714: task edges-pos-ontonotes, batch 714 (12714): mcc: 0.8771, acc: 0.8039, precision: 0.9175, recall: 0.8432, f1: 0.8788, edges-pos-ontonotes_loss: 0.0138
09/16 01:07:28 PM: Update 12794: task edges-pos-ontonotes, batch 794 (12794): mcc: 0.8790, acc: 0.8063, precision: 0.9191, recall: 0.8453, f1: 0.8807, edges-pos-ontonotes_loss: 0.0136
09/16 01:07:39 PM: Update 12885: task edges-pos-ontonotes, batch 885 (12885): mcc: 0.8806, acc: 0.8084, precision: 0.9205, recall: 0.8470, f1: 0.8822, edges-pos-ontonotes_loss: 0.0134
09/16 01:07:49 PM: Update 12990: task edges-pos-ontonotes, batch 990 (12990): mcc: 0.8815, acc: 0.8095, precision: 0.9217, recall: 0.8476, f1: 0.8831, edges-pos-ontonotes_loss: 0.0133
09/16 01:07:50 PM: ***** Step 13000 / Validation 13 *****
09/16 01:07:50 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:07:50 PM: Validating...
09/16 01:07:59 PM: Evaluate: task edges-pos-ontonotes, batch 62 (157): mcc: 0.8974, acc: 0.8369, precision: 0.9443, recall: 0.8568, f1: 0.8984, edges-pos-ontonotes_loss: 0.0124
09/16 01:08:10 PM: Evaluate: task edges-pos-ontonotes, batch 108 (157): mcc: 0.9010, acc: 0.8439, precision: 0.9404, recall: 0.8669, f1: 0.9022, edges-pos-ontonotes_loss: 0.0119
09/16 01:08:20 PM: Evaluate: task edges-pos-ontonotes, batch 153 (157): mcc: 0.9024, acc: 0.8475, precision: 0.9360, recall: 0.8738, f1: 0.9039, edges-pos-ontonotes_loss: 0.0117
09/16 01:08:20 PM: Updating LR scheduler:
09/16 01:08:20 PM: 	Best result seen so far for macro_avg: 0.905
09/16 01:08:20 PM: 	# validation passes without improvement: 1
09/16 01:08:20 PM: edges-pos-ontonotes_loss: training: 0.013291 validation: 0.011731
09/16 01:08:20 PM: macro_avg: validation: 0.903918
09/16 01:08:20 PM: micro_avg: validation: 0.000000
09/16 01:08:20 PM: edges-pos-ontonotes_mcc: training: 0.881582 validation: 0.902498
09/16 01:08:20 PM: edges-pos-ontonotes_acc: training: 0.809608 validation: 0.847762
09/16 01:08:20 PM: edges-pos-ontonotes_precision: training: 0.921727 validation: 0.936010
09/16 01:08:20 PM: edges-pos-ontonotes_recall: training: 0.847688 validation: 0.873954
09/16 01:08:20 PM: edges-pos-ontonotes_f1: training: 0.883158 validation: 0.903918
09/16 01:08:20 PM: Global learning rate: 0.0001
09/16 01:08:20 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:08:30 PM: Update 13094: task edges-pos-ontonotes, batch 94 (13094): mcc: 0.8973, acc: 0.8308, precision: 0.9371, recall: 0.8630, f1: 0.8985, edges-pos-ontonotes_loss: 0.0124
09/16 01:08:40 PM: Update 13198: task edges-pos-ontonotes, batch 198 (13198): mcc: 0.8973, acc: 0.8311, precision: 0.9362, recall: 0.8640, f1: 0.8987, edges-pos-ontonotes_loss: 0.0122
09/16 01:08:50 PM: Update 13299: task edges-pos-ontonotes, batch 299 (13299): mcc: 0.8881, acc: 0.8176, precision: 0.9303, recall: 0.8521, f1: 0.8895, edges-pos-ontonotes_loss: 0.0133
09/16 01:09:00 PM: Update 13423: task edges-pos-ontonotes, batch 423 (13423): mcc: 0.8815, acc: 0.8075, precision: 0.9260, recall: 0.8437, f1: 0.8829, edges-pos-ontonotes_loss: 0.0139
09/16 01:09:20 PM: Update 13511: task edges-pos-ontonotes, batch 511 (13511): mcc: 0.8784, acc: 0.8029, precision: 0.9236, recall: 0.8399, f1: 0.8798, edges-pos-ontonotes_loss: 0.0142
09/16 01:09:30 PM: Update 13570: task edges-pos-ontonotes, batch 570 (13570): mcc: 0.8737, acc: 0.7961, precision: 0.9187, recall: 0.8357, f1: 0.8752, edges-pos-ontonotes_loss: 0.0144
09/16 01:09:40 PM: Update 13626: task edges-pos-ontonotes, batch 626 (13626): mcc: 0.8712, acc: 0.7926, precision: 0.9159, recall: 0.8336, f1: 0.8728, edges-pos-ontonotes_loss: 0.0146
09/16 01:09:50 PM: Update 13686: task edges-pos-ontonotes, batch 686 (13686): mcc: 0.8692, acc: 0.7900, precision: 0.9135, recall: 0.8320, f1: 0.8709, edges-pos-ontonotes_loss: 0.0148
09/16 01:10:00 PM: Update 13746: task edges-pos-ontonotes, batch 746 (13746): mcc: 0.8678, acc: 0.7879, precision: 0.9119, recall: 0.8308, f1: 0.8695, edges-pos-ontonotes_loss: 0.0150
09/16 01:10:10 PM: Update 13805: task edges-pos-ontonotes, batch 805 (13805): mcc: 0.8664, acc: 0.7862, precision: 0.9103, recall: 0.8296, f1: 0.8681, edges-pos-ontonotes_loss: 0.0152
09/16 01:10:20 PM: Update 13841: task edges-pos-ontonotes, batch 841 (13841): mcc: 0.8655, acc: 0.7848, precision: 0.9098, recall: 0.8284, f1: 0.8672, edges-pos-ontonotes_loss: 0.0153
09/16 01:10:30 PM: Update 13927: task edges-pos-ontonotes, batch 927 (13927): mcc: 0.8651, acc: 0.7839, precision: 0.9105, recall: 0.8270, f1: 0.8668, edges-pos-ontonotes_loss: 0.0153
09/16 01:10:40 PM: ***** Step 14000 / Validation 14 *****
09/16 01:10:40 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:10:40 PM: Validating...
09/16 01:10:40 PM: Evaluate: task edges-pos-ontonotes, batch 4 (157): mcc: 0.9058, acc: 0.8578, precision: 0.9326, recall: 0.8834, f1: 0.9073, edges-pos-ontonotes_loss: 0.0116
09/16 01:10:50 PM: Evaluate: task edges-pos-ontonotes, batch 70 (157): mcc: 0.9073, acc: 0.8533, precision: 0.9413, recall: 0.8781, f1: 0.9086, edges-pos-ontonotes_loss: 0.0115
09/16 01:11:01 PM: Evaluate: task edges-pos-ontonotes, batch 117 (157): mcc: 0.9068, acc: 0.8539, precision: 0.9350, recall: 0.8832, f1: 0.9083, edges-pos-ontonotes_loss: 0.0114
09/16 01:11:09 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:11:09 PM: Best result seen so far for macro.
09/16 01:11:09 PM: Updating LR scheduler:
09/16 01:11:09 PM: 	Best result seen so far for macro_avg: 0.909
09/16 01:11:09 PM: 	# validation passes without improvement: 0
09/16 01:11:09 PM: edges-pos-ontonotes_loss: training: 0.015298 validation: 0.011338
09/16 01:11:09 PM: macro_avg: validation: 0.908917
09/16 01:11:09 PM: micro_avg: validation: 0.000000
09/16 01:11:09 PM: edges-pos-ontonotes_mcc: training: 0.864691 validation: 0.907311
09/16 01:11:09 PM: edges-pos-ontonotes_acc: training: 0.783193 validation: 0.855562
09/16 01:11:09 PM: edges-pos-ontonotes_precision: training: 0.910597 validation: 0.931710
09/16 01:11:09 PM: edges-pos-ontonotes_recall: training: 0.826168 validation: 0.887213
09/16 01:11:09 PM: edges-pos-ontonotes_f1: training: 0.866330 validation: 0.908917
09/16 01:11:09 PM: Global learning rate: 0.0001
09/16 01:11:09 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:11:11 PM: Update 14011: task edges-pos-ontonotes, batch 11 (14011): mcc: 0.8676, acc: 0.7852, precision: 0.9260, recall: 0.8176, f1: 0.8684, edges-pos-ontonotes_loss: 0.0152
09/16 01:11:21 PM: Update 14105: task edges-pos-ontonotes, batch 105 (14105): mcc: 0.8647, acc: 0.7807, precision: 0.9202, recall: 0.8174, f1: 0.8658, edges-pos-ontonotes_loss: 0.0150
09/16 01:11:31 PM: Update 14155: task edges-pos-ontonotes, batch 155 (14155): mcc: 0.8659, acc: 0.7829, precision: 0.9180, recall: 0.8216, f1: 0.8672, edges-pos-ontonotes_loss: 0.0150
09/16 01:11:41 PM: Update 14229: task edges-pos-ontonotes, batch 229 (14229): mcc: 0.8673, acc: 0.7862, precision: 0.9144, recall: 0.8277, f1: 0.8689, edges-pos-ontonotes_loss: 0.0149
09/16 01:11:51 PM: Update 14297: task edges-pos-ontonotes, batch 297 (14297): mcc: 0.8671, acc: 0.7863, precision: 0.9122, recall: 0.8293, f1: 0.8688, edges-pos-ontonotes_loss: 0.0150
09/16 01:12:01 PM: Update 14369: task edges-pos-ontonotes, batch 369 (14369): mcc: 0.8680, acc: 0.7878, precision: 0.9118, recall: 0.8313, f1: 0.8697, edges-pos-ontonotes_loss: 0.0149
09/16 01:12:11 PM: Update 14442: task edges-pos-ontonotes, batch 442 (14442): mcc: 0.8689, acc: 0.7891, precision: 0.9120, recall: 0.8327, f1: 0.8705, edges-pos-ontonotes_loss: 0.0148
09/16 01:12:21 PM: Update 14483: task edges-pos-ontonotes, batch 483 (14483): mcc: 0.8678, acc: 0.7878, precision: 0.9104, recall: 0.8322, f1: 0.8696, edges-pos-ontonotes_loss: 0.0148
09/16 01:12:31 PM: Update 14543: task edges-pos-ontonotes, batch 543 (14543): mcc: 0.8668, acc: 0.7865, precision: 0.9090, recall: 0.8316, f1: 0.8686, edges-pos-ontonotes_loss: 0.0150
09/16 01:12:42 PM: Update 14603: task edges-pos-ontonotes, batch 603 (14603): mcc: 0.8660, acc: 0.7857, precision: 0.9078, recall: 0.8313, f1: 0.8679, edges-pos-ontonotes_loss: 0.0152
09/16 01:12:52 PM: Update 14659: task edges-pos-ontonotes, batch 659 (14659): mcc: 0.8661, acc: 0.7859, precision: 0.9074, recall: 0.8318, f1: 0.8680, edges-pos-ontonotes_loss: 0.0152
09/16 01:13:02 PM: Update 14715: task edges-pos-ontonotes, batch 715 (14715): mcc: 0.8661, acc: 0.7860, precision: 0.9071, recall: 0.8320, f1: 0.8679, edges-pos-ontonotes_loss: 0.0152
09/16 01:13:12 PM: Update 14768: task edges-pos-ontonotes, batch 768 (14768): mcc: 0.8661, acc: 0.7861, precision: 0.9070, recall: 0.8322, f1: 0.8680, edges-pos-ontonotes_loss: 0.0152
09/16 01:13:22 PM: Update 14810: task edges-pos-ontonotes, batch 810 (14810): mcc: 0.8661, acc: 0.7862, precision: 0.9067, recall: 0.8324, f1: 0.8680, edges-pos-ontonotes_loss: 0.0152
09/16 01:13:32 PM: Update 14853: task edges-pos-ontonotes, batch 853 (14853): mcc: 0.8662, acc: 0.7863, precision: 0.9067, recall: 0.8326, f1: 0.8681, edges-pos-ontonotes_loss: 0.0152
09/16 01:13:42 PM: Update 14900: task edges-pos-ontonotes, batch 900 (14900): mcc: 0.8664, acc: 0.7866, precision: 0.9067, recall: 0.8329, f1: 0.8682, edges-pos-ontonotes_loss: 0.0152
09/16 01:13:52 PM: Update 14940: task edges-pos-ontonotes, batch 940 (14940): mcc: 0.8666, acc: 0.7871, precision: 0.9068, recall: 0.8333, f1: 0.8685, edges-pos-ontonotes_loss: 0.0152
09/16 01:14:03 PM: Update 14996: task edges-pos-ontonotes, batch 996 (14996): mcc: 0.8669, acc: 0.7875, precision: 0.9069, recall: 0.8337, f1: 0.8687, edges-pos-ontonotes_loss: 0.0152
09/16 01:14:03 PM: ***** Step 15000 / Validation 15 *****
09/16 01:14:03 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:14:03 PM: Validating...
09/16 01:14:13 PM: Evaluate: task edges-pos-ontonotes, batch 63 (157): mcc: 0.9048, acc: 0.8482, precision: 0.9477, recall: 0.8674, f1: 0.9058, edges-pos-ontonotes_loss: 0.0117
09/16 01:14:23 PM: Evaluate: task edges-pos-ontonotes, batch 109 (157): mcc: 0.9088, acc: 0.8552, precision: 0.9460, recall: 0.8765, f1: 0.9099, edges-pos-ontonotes_loss: 0.0112
09/16 01:14:33 PM: Evaluate: task edges-pos-ontonotes, batch 154 (157): mcc: 0.9093, acc: 0.8575, precision: 0.9420, recall: 0.8812, f1: 0.9106, edges-pos-ontonotes_loss: 0.0110
09/16 01:14:33 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:14:33 PM: Best result seen so far for macro.
09/16 01:14:33 PM: Updating LR scheduler:
09/16 01:14:33 PM: 	Best result seen so far for macro_avg: 0.911
09/16 01:14:33 PM: 	# validation passes without improvement: 0
09/16 01:14:33 PM: edges-pos-ontonotes_loss: training: 0.015209 validation: 0.011003
09/16 01:14:33 PM: macro_avg: validation: 0.910793
09/16 01:14:33 PM: micro_avg: validation: 0.000000
09/16 01:14:33 PM: edges-pos-ontonotes_mcc: training: 0.866915 validation: 0.909483
09/16 01:14:33 PM: edges-pos-ontonotes_acc: training: 0.787585 validation: 0.857826
09/16 01:14:33 PM: edges-pos-ontonotes_precision: training: 0.906926 validation: 0.942125
09/16 01:14:33 PM: edges-pos-ontonotes_recall: training: 0.833729 validation: 0.881478
09/16 01:14:33 PM: edges-pos-ontonotes_f1: training: 0.868788 validation: 0.910793
09/16 01:14:33 PM: Global learning rate: 0.0001
09/16 01:14:33 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:14:43 PM: Update 15047: task edges-pos-ontonotes, batch 47 (15047): mcc: 0.8709, acc: 0.7953, precision: 0.9078, recall: 0.8405, f1: 0.8729, edges-pos-ontonotes_loss: 0.0150
09/16 01:15:04 PM: Update 15093: task edges-pos-ontonotes, batch 93 (15093): mcc: 0.8707, acc: 0.7954, precision: 0.9090, recall: 0.8389, f1: 0.8726, edges-pos-ontonotes_loss: 0.0153
09/16 01:15:14 PM: Update 15142: task edges-pos-ontonotes, batch 142 (15142): mcc: 0.8703, acc: 0.7949, precision: 0.9094, recall: 0.8379, f1: 0.8722, edges-pos-ontonotes_loss: 0.0153
09/16 01:15:24 PM: Update 15176: task edges-pos-ontonotes, batch 176 (15176): mcc: 0.8713, acc: 0.7963, precision: 0.9101, recall: 0.8391, f1: 0.8732, edges-pos-ontonotes_loss: 0.0152
09/16 01:15:34 PM: Update 15210: task edges-pos-ontonotes, batch 210 (15210): mcc: 0.8720, acc: 0.7975, precision: 0.9106, recall: 0.8399, f1: 0.8738, edges-pos-ontonotes_loss: 0.0151
09/16 01:15:45 PM: Update 15261: task edges-pos-ontonotes, batch 261 (15261): mcc: 0.8718, acc: 0.7972, precision: 0.9104, recall: 0.8398, f1: 0.8737, edges-pos-ontonotes_loss: 0.0150
09/16 01:15:55 PM: Update 15316: task edges-pos-ontonotes, batch 316 (15316): mcc: 0.8724, acc: 0.7980, precision: 0.9107, recall: 0.8406, f1: 0.8742, edges-pos-ontonotes_loss: 0.0149
09/16 01:16:05 PM: Update 15374: task edges-pos-ontonotes, batch 374 (15374): mcc: 0.8730, acc: 0.7989, precision: 0.9114, recall: 0.8412, f1: 0.8749, edges-pos-ontonotes_loss: 0.0150
09/16 01:16:16 PM: Update 15406: task edges-pos-ontonotes, batch 406 (15406): mcc: 0.8731, acc: 0.7991, precision: 0.9117, recall: 0.8411, f1: 0.8750, edges-pos-ontonotes_loss: 0.0149
09/16 01:16:26 PM: Update 15445: task edges-pos-ontonotes, batch 445 (15445): mcc: 0.8731, acc: 0.7991, precision: 0.9115, recall: 0.8412, f1: 0.8749, edges-pos-ontonotes_loss: 0.0150
09/16 01:16:36 PM: Update 15485: task edges-pos-ontonotes, batch 485 (15485): mcc: 0.8733, acc: 0.7994, precision: 0.9116, recall: 0.8414, f1: 0.8751, edges-pos-ontonotes_loss: 0.0150
09/16 01:16:46 PM: Update 15525: task edges-pos-ontonotes, batch 525 (15525): mcc: 0.8734, acc: 0.7998, precision: 0.9117, recall: 0.8416, f1: 0.8752, edges-pos-ontonotes_loss: 0.0149
09/16 01:16:56 PM: Update 15574: task edges-pos-ontonotes, batch 574 (15574): mcc: 0.8738, acc: 0.8003, precision: 0.9119, recall: 0.8421, f1: 0.8756, edges-pos-ontonotes_loss: 0.0149
09/16 01:17:06 PM: Update 15610: task edges-pos-ontonotes, batch 610 (15610): mcc: 0.8738, acc: 0.8004, precision: 0.9120, recall: 0.8420, f1: 0.8756, edges-pos-ontonotes_loss: 0.0149
09/16 01:17:17 PM: Update 15653: task edges-pos-ontonotes, batch 653 (15653): mcc: 0.8741, acc: 0.8008, precision: 0.9121, recall: 0.8424, f1: 0.8759, edges-pos-ontonotes_loss: 0.0149
09/16 01:17:27 PM: Update 15701: task edges-pos-ontonotes, batch 701 (15701): mcc: 0.8741, acc: 0.8008, precision: 0.9123, recall: 0.8423, f1: 0.8759, edges-pos-ontonotes_loss: 0.0149
09/16 01:17:37 PM: Update 15740: task edges-pos-ontonotes, batch 740 (15740): mcc: 0.8739, acc: 0.8005, precision: 0.9121, recall: 0.8421, f1: 0.8757, edges-pos-ontonotes_loss: 0.0149
09/16 01:17:47 PM: Update 15790: task edges-pos-ontonotes, batch 790 (15790): mcc: 0.8740, acc: 0.8007, precision: 0.9123, recall: 0.8422, f1: 0.8758, edges-pos-ontonotes_loss: 0.0148
09/16 01:17:57 PM: Update 15838: task edges-pos-ontonotes, batch 838 (15838): mcc: 0.8742, acc: 0.8009, precision: 0.9124, recall: 0.8424, f1: 0.8760, edges-pos-ontonotes_loss: 0.0147
09/16 01:18:07 PM: Update 15895: task edges-pos-ontonotes, batch 895 (15895): mcc: 0.8745, acc: 0.8013, precision: 0.9127, recall: 0.8428, f1: 0.8763, edges-pos-ontonotes_loss: 0.0146
09/16 01:18:17 PM: Update 15966: task edges-pos-ontonotes, batch 966 (15966): mcc: 0.8751, acc: 0.8020, precision: 0.9131, recall: 0.8434, f1: 0.8769, edges-pos-ontonotes_loss: 0.0145
09/16 01:18:22 PM: ***** Step 16000 / Validation 16 *****
09/16 01:18:22 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:18:22 PM: Validating...
09/16 01:18:27 PM: Evaluate: task edges-pos-ontonotes, batch 36 (157): mcc: 0.8973, acc: 0.8373, precision: 0.9434, recall: 0.8573, f1: 0.8983, edges-pos-ontonotes_loss: 0.0122
09/16 01:18:37 PM: Evaluate: task edges-pos-ontonotes, batch 99 (157): mcc: 0.9064, acc: 0.8520, precision: 0.9433, recall: 0.8745, f1: 0.9076, edges-pos-ontonotes_loss: 0.0114
09/16 01:18:48 PM: Evaluate: task edges-pos-ontonotes, batch 144 (157): mcc: 0.9079, acc: 0.8555, precision: 0.9387, recall: 0.8816, f1: 0.9093, edges-pos-ontonotes_loss: 0.0111
09/16 01:18:50 PM: Updating LR scheduler:
09/16 01:18:50 PM: 	Best result seen so far for macro_avg: 0.911
09/16 01:18:50 PM: 	# validation passes without improvement: 1
09/16 01:18:50 PM: edges-pos-ontonotes_loss: training: 0.014407 validation: 0.011021
09/16 01:18:50 PM: macro_avg: validation: 0.910567
09/16 01:18:50 PM: micro_avg: validation: 0.000000
09/16 01:18:50 PM: edges-pos-ontonotes_mcc: training: 0.875293 validation: 0.909162
09/16 01:18:50 PM: edges-pos-ontonotes_acc: training: 0.802277 validation: 0.857879
09/16 01:18:50 PM: edges-pos-ontonotes_precision: training: 0.913311 validation: 0.939155
09/16 01:18:50 PM: edges-pos-ontonotes_recall: training: 0.843623 validation: 0.883668
09/16 01:18:50 PM: edges-pos-ontonotes_f1: training: 0.877085 validation: 0.910567
09/16 01:18:50 PM: Global learning rate: 0.0001
09/16 01:18:50 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:18:58 PM: Update 16037: task edges-pos-ontonotes, batch 37 (16037): mcc: 0.8815, acc: 0.8101, precision: 0.9151, recall: 0.8538, f1: 0.8834, edges-pos-ontonotes_loss: 0.0128
09/16 01:19:08 PM: Update 16106: task edges-pos-ontonotes, batch 106 (16106): mcc: 0.8944, acc: 0.8272, precision: 0.9281, recall: 0.8659, f1: 0.8959, edges-pos-ontonotes_loss: 0.0119
09/16 01:19:18 PM: Update 16171: task edges-pos-ontonotes, batch 171 (16171): mcc: 0.8982, acc: 0.8321, precision: 0.9319, recall: 0.8696, f1: 0.8997, edges-pos-ontonotes_loss: 0.0116
09/16 01:19:28 PM: Update 16242: task edges-pos-ontonotes, batch 242 (16242): mcc: 0.9002, acc: 0.8353, precision: 0.9336, recall: 0.8719, f1: 0.9017, edges-pos-ontonotes_loss: 0.0114
09/16 01:19:38 PM: Update 16308: task edges-pos-ontonotes, batch 308 (16308): mcc: 0.9018, acc: 0.8374, precision: 0.9349, recall: 0.8736, f1: 0.9032, edges-pos-ontonotes_loss: 0.0113
09/16 01:19:48 PM: Update 16365: task edges-pos-ontonotes, batch 365 (16365): mcc: 0.9014, acc: 0.8365, precision: 0.9351, recall: 0.8726, f1: 0.9028, edges-pos-ontonotes_loss: 0.0114
09/16 01:19:58 PM: Update 16442: task edges-pos-ontonotes, batch 442 (16442): mcc: 0.9009, acc: 0.8359, precision: 0.9356, recall: 0.8714, f1: 0.9023, edges-pos-ontonotes_loss: 0.0114
09/16 01:20:08 PM: Update 16523: task edges-pos-ontonotes, batch 523 (16523): mcc: 0.9007, acc: 0.8356, precision: 0.9359, recall: 0.8708, f1: 0.9021, edges-pos-ontonotes_loss: 0.0115
09/16 01:20:18 PM: Update 16603: task edges-pos-ontonotes, batch 603 (16603): mcc: 0.9008, acc: 0.8359, precision: 0.9359, recall: 0.8709, f1: 0.9022, edges-pos-ontonotes_loss: 0.0115
09/16 01:20:28 PM: Update 16673: task edges-pos-ontonotes, batch 673 (16673): mcc: 0.9003, acc: 0.8353, precision: 0.9357, recall: 0.8701, f1: 0.9017, edges-pos-ontonotes_loss: 0.0116
09/16 01:20:38 PM: Update 16778: task edges-pos-ontonotes, batch 778 (16778): mcc: 0.8975, acc: 0.8311, precision: 0.9340, recall: 0.8663, f1: 0.8989, edges-pos-ontonotes_loss: 0.0120
09/16 01:20:48 PM: Update 16892: task edges-pos-ontonotes, batch 892 (16892): mcc: 0.8946, acc: 0.8269, precision: 0.9322, recall: 0.8626, f1: 0.8960, edges-pos-ontonotes_loss: 0.0124
09/16 01:20:59 PM: Update 16971: task edges-pos-ontonotes, batch 971 (16971): mcc: 0.8930, acc: 0.8245, precision: 0.9310, recall: 0.8606, f1: 0.8944, edges-pos-ontonotes_loss: 0.0126
09/16 01:21:05 PM: ***** Step 17000 / Validation 17 *****
09/16 01:21:05 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:21:05 PM: Validating...
09/16 01:21:09 PM: Evaluate: task edges-pos-ontonotes, batch 28 (157): mcc: 0.8941, acc: 0.8310, precision: 0.9407, recall: 0.8538, f1: 0.8952, edges-pos-ontonotes_loss: 0.0123
09/16 01:21:20 PM: Evaluate: task edges-pos-ontonotes, batch 93 (157): mcc: 0.9048, acc: 0.8490, precision: 0.9430, recall: 0.8717, f1: 0.9060, edges-pos-ontonotes_loss: 0.0114
09/16 01:21:30 PM: Evaluate: task edges-pos-ontonotes, batch 139 (157): mcc: 0.9048, acc: 0.8501, precision: 0.9352, recall: 0.8791, f1: 0.9063, edges-pos-ontonotes_loss: 0.0114
09/16 01:21:33 PM: Updating LR scheduler:
09/16 01:21:33 PM: 	Best result seen so far for macro_avg: 0.911
09/16 01:21:33 PM: 	# validation passes without improvement: 2
09/16 01:21:33 PM: edges-pos-ontonotes_loss: training: 0.012693 validation: 0.011276
09/16 01:21:33 PM: macro_avg: validation: 0.907460
09/16 01:21:33 PM: micro_avg: validation: 0.000000
09/16 01:21:33 PM: edges-pos-ontonotes_mcc: training: 0.890702 validation: 0.905953
09/16 01:21:33 PM: edges-pos-ontonotes_acc: training: 0.821281 validation: 0.852577
09/16 01:21:33 PM: edges-pos-ontonotes_precision: training: 0.928670 validation: 0.934771
09/16 01:21:33 PM: edges-pos-ontonotes_recall: training: 0.858463 validation: 0.881700
09/16 01:21:33 PM: edges-pos-ontonotes_f1: training: 0.892188 validation: 0.907460
09/16 01:21:33 PM: Global learning rate: 0.0001
09/16 01:21:33 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:21:40 PM: Update 17035: task edges-pos-ontonotes, batch 35 (17035): mcc: 0.8628, acc: 0.7813, precision: 0.9018, recall: 0.8308, f1: 0.8648, edges-pos-ontonotes_loss: 0.0161
09/16 01:21:50 PM: Update 17076: task edges-pos-ontonotes, batch 76 (17076): mcc: 0.8616, acc: 0.7790, precision: 0.9006, recall: 0.8296, f1: 0.8636, edges-pos-ontonotes_loss: 0.0162
09/16 01:22:00 PM: Update 17122: task edges-pos-ontonotes, batch 122 (17122): mcc: 0.8601, acc: 0.7764, precision: 0.9000, recall: 0.8272, f1: 0.8621, edges-pos-ontonotes_loss: 0.0165
09/16 01:22:10 PM: Update 17172: task edges-pos-ontonotes, batch 172 (17172): mcc: 0.8610, acc: 0.7778, precision: 0.9010, recall: 0.8280, f1: 0.8629, edges-pos-ontonotes_loss: 0.0163
09/16 01:22:20 PM: Update 17234: task edges-pos-ontonotes, batch 234 (17234): mcc: 0.8616, acc: 0.7789, precision: 0.9017, recall: 0.8286, f1: 0.8636, edges-pos-ontonotes_loss: 0.0164
09/16 01:22:30 PM: Update 17279: task edges-pos-ontonotes, batch 279 (17279): mcc: 0.8616, acc: 0.7792, precision: 0.9018, recall: 0.8285, f1: 0.8636, edges-pos-ontonotes_loss: 0.0164
09/16 01:22:48 PM: Update 17301: task edges-pos-ontonotes, batch 301 (17301): mcc: 0.8610, acc: 0.7782, precision: 0.9016, recall: 0.8275, f1: 0.8629, edges-pos-ontonotes_loss: 0.0165
09/16 01:22:58 PM: Update 17387: task edges-pos-ontonotes, batch 387 (17387): mcc: 0.8615, acc: 0.7786, precision: 0.9037, recall: 0.8264, f1: 0.8633, edges-pos-ontonotes_loss: 0.0162
09/16 01:23:08 PM: Update 17466: task edges-pos-ontonotes, batch 466 (17466): mcc: 0.8620, acc: 0.7793, precision: 0.9053, recall: 0.8260, f1: 0.8639, edges-pos-ontonotes_loss: 0.0160
09/16 01:23:18 PM: Update 17533: task edges-pos-ontonotes, batch 533 (17533): mcc: 0.8623, acc: 0.7796, precision: 0.9061, recall: 0.8259, f1: 0.8641, edges-pos-ontonotes_loss: 0.0158
09/16 01:23:28 PM: Update 17594: task edges-pos-ontonotes, batch 594 (17594): mcc: 0.8627, acc: 0.7801, precision: 0.9067, recall: 0.8260, f1: 0.8645, edges-pos-ontonotes_loss: 0.0157
09/16 01:23:38 PM: Update 17654: task edges-pos-ontonotes, batch 654 (17654): mcc: 0.8635, acc: 0.7812, precision: 0.9067, recall: 0.8274, f1: 0.8653, edges-pos-ontonotes_loss: 0.0156
09/16 01:23:48 PM: Update 17711: task edges-pos-ontonotes, batch 711 (17711): mcc: 0.8642, acc: 0.7824, precision: 0.9070, recall: 0.8286, f1: 0.8660, edges-pos-ontonotes_loss: 0.0155
09/16 01:23:59 PM: Update 17768: task edges-pos-ontonotes, batch 768 (17768): mcc: 0.8649, acc: 0.7833, precision: 0.9074, recall: 0.8295, f1: 0.8667, edges-pos-ontonotes_loss: 0.0154
09/16 01:24:09 PM: Update 17816: task edges-pos-ontonotes, batch 816 (17816): mcc: 0.8655, acc: 0.7841, precision: 0.9075, recall: 0.8304, f1: 0.8673, edges-pos-ontonotes_loss: 0.0154
09/16 01:24:19 PM: Update 17863: task edges-pos-ontonotes, batch 863 (17863): mcc: 0.8662, acc: 0.7851, precision: 0.9079, recall: 0.8314, f1: 0.8680, edges-pos-ontonotes_loss: 0.0153
09/16 01:24:29 PM: Update 17917: task edges-pos-ontonotes, batch 917 (17917): mcc: 0.8666, acc: 0.7857, precision: 0.9081, recall: 0.8321, f1: 0.8684, edges-pos-ontonotes_loss: 0.0152
09/16 01:24:39 PM: Update 17944: task edges-pos-ontonotes, batch 944 (17944): mcc: 0.8663, acc: 0.7855, precision: 0.9076, recall: 0.8320, f1: 0.8681, edges-pos-ontonotes_loss: 0.0153
09/16 01:24:50 PM: Update 17985: task edges-pos-ontonotes, batch 985 (17985): mcc: 0.8662, acc: 0.7854, precision: 0.9072, recall: 0.8320, f1: 0.8680, edges-pos-ontonotes_loss: 0.0153
09/16 01:24:53 PM: ***** Step 18000 / Validation 18 *****
09/16 01:24:53 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:24:53 PM: Validating...
09/16 01:25:00 PM: Evaluate: task edges-pos-ontonotes, batch 41 (157): mcc: 0.9025, acc: 0.8440, precision: 0.9496, recall: 0.8614, f1: 0.9033, edges-pos-ontonotes_loss: 0.0116
09/16 01:25:10 PM: Evaluate: task edges-pos-ontonotes, batch 102 (157): mcc: 0.9113, acc: 0.8585, precision: 0.9491, recall: 0.8784, f1: 0.9124, edges-pos-ontonotes_loss: 0.0107
09/16 01:25:20 PM: Evaluate: task edges-pos-ontonotes, batch 147 (157): mcc: 0.9102, acc: 0.8582, precision: 0.9434, recall: 0.8816, f1: 0.9114, edges-pos-ontonotes_loss: 0.0108
09/16 01:25:22 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:25:22 PM: Best result seen so far for macro.
09/16 01:25:22 PM: Updating LR scheduler:
09/16 01:25:22 PM: 	Best result seen so far for macro_avg: 0.912
09/16 01:25:22 PM: 	# validation passes without improvement: 0
09/16 01:25:22 PM: edges-pos-ontonotes_loss: training: 0.015304 validation: 0.010715
09/16 01:25:22 PM: macro_avg: validation: 0.912151
09/16 01:25:22 PM: micro_avg: validation: 0.000000
09/16 01:25:22 PM: edges-pos-ontonotes_mcc: training: 0.866055 validation: 0.910869
09/16 01:25:22 PM: edges-pos-ontonotes_acc: training: 0.785272 validation: 0.859593
09/16 01:25:22 PM: edges-pos-ontonotes_precision: training: 0.907063 validation: 0.943497
09/16 01:25:22 PM: edges-pos-ontonotes_recall: training: 0.831981 validation: 0.882822
09/16 01:25:22 PM: edges-pos-ontonotes_f1: training: 0.867901 validation: 0.912151
09/16 01:25:22 PM: Global learning rate: 0.0001
09/16 01:25:22 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:25:30 PM: Update 18042: task edges-pos-ontonotes, batch 42 (18042): mcc: 0.8666, acc: 0.7876, precision: 0.9040, recall: 0.8360, f1: 0.8686, edges-pos-ontonotes_loss: 0.0151
09/16 01:25:40 PM: Update 18085: task edges-pos-ontonotes, batch 85 (18085): mcc: 0.8660, acc: 0.7876, precision: 0.9020, recall: 0.8365, f1: 0.8680, edges-pos-ontonotes_loss: 0.0156
09/16 01:25:50 PM: Update 18125: task edges-pos-ontonotes, batch 125 (18125): mcc: 0.8667, acc: 0.7883, precision: 0.9025, recall: 0.8373, f1: 0.8687, edges-pos-ontonotes_loss: 0.0155
09/16 01:26:00 PM: Update 18167: task edges-pos-ontonotes, batch 167 (18167): mcc: 0.8672, acc: 0.7887, precision: 0.9030, recall: 0.8378, f1: 0.8692, edges-pos-ontonotes_loss: 0.0154
09/16 01:26:11 PM: Update 18212: task edges-pos-ontonotes, batch 212 (18212): mcc: 0.8680, acc: 0.7900, precision: 0.9041, recall: 0.8384, f1: 0.8700, edges-pos-ontonotes_loss: 0.0153
09/16 01:26:21 PM: Update 18241: task edges-pos-ontonotes, batch 241 (18241): mcc: 0.8677, acc: 0.7893, precision: 0.9042, recall: 0.8377, f1: 0.8697, edges-pos-ontonotes_loss: 0.0154
09/16 01:26:31 PM: Update 18285: task edges-pos-ontonotes, batch 285 (18285): mcc: 0.8684, acc: 0.7904, precision: 0.9048, recall: 0.8385, f1: 0.8704, edges-pos-ontonotes_loss: 0.0153
09/16 01:26:41 PM: Update 18338: task edges-pos-ontonotes, batch 338 (18338): mcc: 0.8687, acc: 0.7909, precision: 0.9050, recall: 0.8388, f1: 0.8707, edges-pos-ontonotes_loss: 0.0153
09/16 01:26:52 PM: Update 18388: task edges-pos-ontonotes, batch 388 (18388): mcc: 0.8692, acc: 0.7921, precision: 0.9054, recall: 0.8395, f1: 0.8712, edges-pos-ontonotes_loss: 0.0152
09/16 01:27:02 PM: Update 18444: task edges-pos-ontonotes, batch 444 (18444): mcc: 0.8697, acc: 0.7928, precision: 0.9060, recall: 0.8399, f1: 0.8717, edges-pos-ontonotes_loss: 0.0152
09/16 01:27:12 PM: Update 18481: task edges-pos-ontonotes, batch 481 (18481): mcc: 0.8701, acc: 0.7936, precision: 0.9063, recall: 0.8404, f1: 0.8721, edges-pos-ontonotes_loss: 0.0151
09/16 01:27:22 PM: Update 18524: task edges-pos-ontonotes, batch 524 (18524): mcc: 0.8703, acc: 0.7938, precision: 0.9065, recall: 0.8406, f1: 0.8723, edges-pos-ontonotes_loss: 0.0151
09/16 01:27:33 PM: Update 18553: task edges-pos-ontonotes, batch 553 (18553): mcc: 0.8703, acc: 0.7940, precision: 0.9065, recall: 0.8406, f1: 0.8723, edges-pos-ontonotes_loss: 0.0151
09/16 01:27:43 PM: Update 18594: task edges-pos-ontonotes, batch 594 (18594): mcc: 0.8706, acc: 0.7946, precision: 0.9068, recall: 0.8408, f1: 0.8726, edges-pos-ontonotes_loss: 0.0150
09/16 01:27:53 PM: Update 18634: task edges-pos-ontonotes, batch 634 (18634): mcc: 0.8708, acc: 0.7950, precision: 0.9070, recall: 0.8411, f1: 0.8728, edges-pos-ontonotes_loss: 0.0150
09/16 01:28:03 PM: Update 18677: task edges-pos-ontonotes, batch 677 (18677): mcc: 0.8712, acc: 0.7956, precision: 0.9074, recall: 0.8414, f1: 0.8731, edges-pos-ontonotes_loss: 0.0150
09/16 01:28:13 PM: Update 18720: task edges-pos-ontonotes, batch 720 (18720): mcc: 0.8716, acc: 0.7962, precision: 0.9077, recall: 0.8418, f1: 0.8735, edges-pos-ontonotes_loss: 0.0150
09/16 01:28:23 PM: Update 18761: task edges-pos-ontonotes, batch 761 (18761): mcc: 0.8718, acc: 0.7966, precision: 0.9079, recall: 0.8422, f1: 0.8738, edges-pos-ontonotes_loss: 0.0149
09/16 01:28:34 PM: Update 18801: task edges-pos-ontonotes, batch 801 (18801): mcc: 0.8721, acc: 0.7971, precision: 0.9081, recall: 0.8425, f1: 0.8741, edges-pos-ontonotes_loss: 0.0150
09/16 01:28:44 PM: Update 18837: task edges-pos-ontonotes, batch 837 (18837): mcc: 0.8724, acc: 0.7975, precision: 0.9083, recall: 0.8428, f1: 0.8743, edges-pos-ontonotes_loss: 0.0149
09/16 01:28:54 PM: Update 18871: task edges-pos-ontonotes, batch 871 (18871): mcc: 0.8724, acc: 0.7977, precision: 0.9084, recall: 0.8428, f1: 0.8744, edges-pos-ontonotes_loss: 0.0149
09/16 01:29:04 PM: Update 18927: task edges-pos-ontonotes, batch 927 (18927): mcc: 0.8727, acc: 0.7981, precision: 0.9087, recall: 0.8430, f1: 0.8746, edges-pos-ontonotes_loss: 0.0149
09/16 01:29:14 PM: Update 18975: task edges-pos-ontonotes, batch 975 (18975): mcc: 0.8729, acc: 0.7984, precision: 0.9089, recall: 0.8432, f1: 0.8748, edges-pos-ontonotes_loss: 0.0149
09/16 01:29:18 PM: ***** Step 19000 / Validation 19 *****
09/16 01:29:18 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:29:18 PM: Validating...
09/16 01:29:24 PM: Evaluate: task edges-pos-ontonotes, batch 40 (157): mcc: 0.9029, acc: 0.8450, precision: 0.9449, recall: 0.8664, f1: 0.9040, edges-pos-ontonotes_loss: 0.0118
09/16 01:29:34 PM: Evaluate: task edges-pos-ontonotes, batch 101 (157): mcc: 0.9104, acc: 0.8581, precision: 0.9446, recall: 0.8808, f1: 0.9116, edges-pos-ontonotes_loss: 0.0110
09/16 01:29:45 PM: Evaluate: task edges-pos-ontonotes, batch 146 (157): mcc: 0.9108, acc: 0.8603, precision: 0.9398, recall: 0.8862, f1: 0.9122, edges-pos-ontonotes_loss: 0.0108
09/16 01:29:47 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:29:47 PM: Best result seen so far for macro.
09/16 01:29:47 PM: Updating LR scheduler:
09/16 01:29:47 PM: 	Best result seen so far for macro_avg: 0.913
09/16 01:29:47 PM: 	# validation passes without improvement: 0
09/16 01:29:47 PM: edges-pos-ontonotes_loss: training: 0.014878 validation: 0.010728
09/16 01:29:47 PM: macro_avg: validation: 0.913409
09/16 01:29:47 PM: micro_avg: validation: 0.000000
09/16 01:29:47 PM: edges-pos-ontonotes_mcc: training: 0.872933 validation: 0.912008
09/16 01:29:47 PM: edges-pos-ontonotes_acc: training: 0.798554 validation: 0.862281
09/16 01:29:47 PM: edges-pos-ontonotes_precision: training: 0.909001 validation: 0.940248
09/16 01:29:47 PM: edges-pos-ontonotes_recall: training: 0.843176 validation: 0.888060
09/16 01:29:47 PM: edges-pos-ontonotes_f1: training: 0.874852 validation: 0.913409
09/16 01:29:47 PM: Global learning rate: 0.0001
09/16 01:29:47 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:29:55 PM: Update 19038: task edges-pos-ontonotes, batch 38 (19038): mcc: 0.8823, acc: 0.8137, precision: 0.9169, recall: 0.8535, f1: 0.8841, edges-pos-ontonotes_loss: 0.0140
09/16 01:30:05 PM: Update 19087: task edges-pos-ontonotes, batch 87 (19087): mcc: 0.8783, acc: 0.8077, precision: 0.9138, recall: 0.8489, f1: 0.8801, edges-pos-ontonotes_loss: 0.0151
09/16 01:30:15 PM: Update 19140: task edges-pos-ontonotes, batch 140 (19140): mcc: 0.8779, acc: 0.8072, precision: 0.9139, recall: 0.8479, f1: 0.8797, edges-pos-ontonotes_loss: 0.0148
09/16 01:30:35 PM: Update 19179: task edges-pos-ontonotes, batch 179 (19179): mcc: 0.8771, acc: 0.8058, precision: 0.9133, recall: 0.8470, f1: 0.8789, edges-pos-ontonotes_loss: 0.0148
09/16 01:30:45 PM: Update 19234: task edges-pos-ontonotes, batch 234 (19234): mcc: 0.8768, acc: 0.8053, precision: 0.9127, recall: 0.8470, f1: 0.8786, edges-pos-ontonotes_loss: 0.0144
09/16 01:30:55 PM: Update 19285: task edges-pos-ontonotes, batch 285 (19285): mcc: 0.8775, acc: 0.8059, precision: 0.9133, recall: 0.8478, f1: 0.8793, edges-pos-ontonotes_loss: 0.0142
09/16 01:31:05 PM: Update 19338: task edges-pos-ontonotes, batch 338 (19338): mcc: 0.8783, acc: 0.8068, precision: 0.9139, recall: 0.8487, f1: 0.8801, edges-pos-ontonotes_loss: 0.0139
09/16 01:31:15 PM: Update 19387: task edges-pos-ontonotes, batch 387 (19387): mcc: 0.8787, acc: 0.8075, precision: 0.9142, recall: 0.8493, f1: 0.8805, edges-pos-ontonotes_loss: 0.0138
09/16 01:31:25 PM: Update 19438: task edges-pos-ontonotes, batch 438 (19438): mcc: 0.8796, acc: 0.8086, precision: 0.9149, recall: 0.8503, f1: 0.8814, edges-pos-ontonotes_loss: 0.0136
09/16 01:31:36 PM: Update 19498: task edges-pos-ontonotes, batch 498 (19498): mcc: 0.8804, acc: 0.8097, precision: 0.9156, recall: 0.8512, f1: 0.8822, edges-pos-ontonotes_loss: 0.0134
09/16 01:31:46 PM: Update 19588: task edges-pos-ontonotes, batch 588 (19588): mcc: 0.8828, acc: 0.8128, precision: 0.9177, recall: 0.8537, f1: 0.8846, edges-pos-ontonotes_loss: 0.0131
09/16 01:31:56 PM: Update 19655: task edges-pos-ontonotes, batch 655 (19655): mcc: 0.8847, acc: 0.8152, precision: 0.9194, recall: 0.8558, f1: 0.8865, edges-pos-ontonotes_loss: 0.0128
09/16 01:32:06 PM: Update 19734: task edges-pos-ontonotes, batch 734 (19734): mcc: 0.8866, acc: 0.8177, precision: 0.9210, recall: 0.8579, f1: 0.8883, edges-pos-ontonotes_loss: 0.0126
09/16 01:32:16 PM: Update 19804: task edges-pos-ontonotes, batch 804 (19804): mcc: 0.8879, acc: 0.8194, precision: 0.9220, recall: 0.8594, f1: 0.8896, edges-pos-ontonotes_loss: 0.0125
09/16 01:32:26 PM: Update 19891: task edges-pos-ontonotes, batch 891 (19891): mcc: 0.8886, acc: 0.8203, precision: 0.9230, recall: 0.8598, f1: 0.8903, edges-pos-ontonotes_loss: 0.0124
09/16 01:32:36 PM: Update 19988: task edges-pos-ontonotes, batch 988 (19988): mcc: 0.8895, acc: 0.8215, precision: 0.9239, recall: 0.8606, f1: 0.8911, edges-pos-ontonotes_loss: 0.0123
09/16 01:32:37 PM: ***** Step 20000 / Validation 20 *****
09/16 01:32:37 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:32:37 PM: Validating...
09/16 01:32:46 PM: Evaluate: task edges-pos-ontonotes, batch 46 (157): mcc: 0.8987, acc: 0.8389, precision: 0.9461, recall: 0.8575, f1: 0.8996, edges-pos-ontonotes_loss: 0.0120
09/16 01:32:56 PM: Evaluate: task edges-pos-ontonotes, batch 93 (157): mcc: 0.9061, acc: 0.8522, precision: 0.9435, recall: 0.8737, f1: 0.9073, edges-pos-ontonotes_loss: 0.0113
09/16 01:33:07 PM: Evaluate: task edges-pos-ontonotes, batch 128 (157): mcc: 0.9061, acc: 0.8526, precision: 0.9386, recall: 0.8782, f1: 0.9074, edges-pos-ontonotes_loss: 0.0112
09/16 01:33:14 PM: Updating LR scheduler:
09/16 01:33:14 PM: 	Best result seen so far for macro_avg: 0.913
09/16 01:33:14 PM: 	# validation passes without improvement: 1
09/16 01:33:14 PM: edges-pos-ontonotes_loss: training: 0.012263 validation: 0.011050
09/16 01:33:14 PM: macro_avg: validation: 0.909020
09/16 01:33:14 PM: micro_avg: validation: 0.000000
09/16 01:33:14 PM: edges-pos-ontonotes_mcc: training: 0.889577 validation: 0.907576
09/16 01:33:14 PM: edges-pos-ontonotes_acc: training: 0.821571 validation: 0.856122
09/16 01:33:14 PM: edges-pos-ontonotes_precision: training: 0.924035 validation: 0.937369
09/16 01:33:14 PM: edges-pos-ontonotes_recall: training: 0.860662 validation: 0.882335
09/16 01:33:14 PM: edges-pos-ontonotes_f1: training: 0.891224 validation: 0.909020
09/16 01:33:14 PM: Global learning rate: 0.0001
09/16 01:33:14 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:33:17 PM: Update 20035: task edges-pos-ontonotes, batch 35 (20035): mcc: 0.9058, acc: 0.8415, precision: 0.9412, recall: 0.8753, f1: 0.9071, edges-pos-ontonotes_loss: 0.0112
09/16 01:33:27 PM: Update 20103: task edges-pos-ontonotes, batch 103 (20103): mcc: 0.9057, acc: 0.8433, precision: 0.9391, recall: 0.8770, f1: 0.9070, edges-pos-ontonotes_loss: 0.0114
09/16 01:33:37 PM: Update 20196: task edges-pos-ontonotes, batch 196 (20196): mcc: 0.8940, acc: 0.8265, precision: 0.9316, recall: 0.8619, f1: 0.8954, edges-pos-ontonotes_loss: 0.0125
09/16 01:33:47 PM: Update 20298: task edges-pos-ontonotes, batch 298 (20298): mcc: 0.8875, acc: 0.8171, precision: 0.9268, recall: 0.8543, f1: 0.8890, edges-pos-ontonotes_loss: 0.0132
09/16 01:33:57 PM: Update 20414: task edges-pos-ontonotes, batch 414 (20414): mcc: 0.8830, acc: 0.8099, precision: 0.9234, recall: 0.8488, f1: 0.8845, edges-pos-ontonotes_loss: 0.0137
09/16 01:34:07 PM: Update 20468: task edges-pos-ontonotes, batch 468 (20468): mcc: 0.8785, acc: 0.8035, precision: 0.9181, recall: 0.8453, f1: 0.8802, edges-pos-ontonotes_loss: 0.0139
09/16 01:34:17 PM: Update 20516: task edges-pos-ontonotes, batch 516 (20516): mcc: 0.8764, acc: 0.8005, precision: 0.9157, recall: 0.8435, f1: 0.8781, edges-pos-ontonotes_loss: 0.0141
09/16 01:34:27 PM: Update 20559: task edges-pos-ontonotes, batch 559 (20559): mcc: 0.8745, acc: 0.7980, precision: 0.9139, recall: 0.8416, f1: 0.8762, edges-pos-ontonotes_loss: 0.0144
09/16 01:34:37 PM: Update 20607: task edges-pos-ontonotes, batch 607 (20607): mcc: 0.8733, acc: 0.7963, precision: 0.9124, recall: 0.8406, f1: 0.8750, edges-pos-ontonotes_loss: 0.0145
09/16 01:34:47 PM: Update 20651: task edges-pos-ontonotes, batch 651 (20651): mcc: 0.8723, acc: 0.7951, precision: 0.9112, recall: 0.8399, f1: 0.8741, edges-pos-ontonotes_loss: 0.0146
09/16 01:34:58 PM: Update 20696: task edges-pos-ontonotes, batch 696 (20696): mcc: 0.8713, acc: 0.7935, precision: 0.9102, recall: 0.8388, f1: 0.8731, edges-pos-ontonotes_loss: 0.0147
09/16 01:35:08 PM: Update 20734: task edges-pos-ontonotes, batch 734 (20734): mcc: 0.8707, acc: 0.7927, precision: 0.9095, recall: 0.8384, f1: 0.8725, edges-pos-ontonotes_loss: 0.0147
09/16 01:35:18 PM: Update 20768: task edges-pos-ontonotes, batch 768 (20768): mcc: 0.8701, acc: 0.7918, precision: 0.9092, recall: 0.8376, f1: 0.8719, edges-pos-ontonotes_loss: 0.0148
09/16 01:35:28 PM: Update 20839: task edges-pos-ontonotes, batch 839 (20839): mcc: 0.8698, acc: 0.7912, precision: 0.9098, recall: 0.8364, f1: 0.8716, edges-pos-ontonotes_loss: 0.0148
09/16 01:35:38 PM: Update 20903: task edges-pos-ontonotes, batch 903 (20903): mcc: 0.8696, acc: 0.7908, precision: 0.9102, recall: 0.8357, f1: 0.8714, edges-pos-ontonotes_loss: 0.0148
09/16 01:35:48 PM: Update 20976: task edges-pos-ontonotes, batch 976 (20976): mcc: 0.8696, acc: 0.7907, precision: 0.9108, recall: 0.8352, f1: 0.8714, edges-pos-ontonotes_loss: 0.0147
09/16 01:35:52 PM: ***** Step 21000 / Validation 21 *****
09/16 01:35:52 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:35:52 PM: Validating...
09/16 01:35:58 PM: Evaluate: task edges-pos-ontonotes, batch 31 (157): mcc: 0.9041, acc: 0.8489, precision: 0.9407, recall: 0.8726, f1: 0.9054, edges-pos-ontonotes_loss: 0.0113
09/16 01:36:08 PM: Evaluate: task edges-pos-ontonotes, batch 81 (157): mcc: 0.9120, acc: 0.8616, precision: 0.9414, recall: 0.8870, f1: 0.9134, edges-pos-ontonotes_loss: 0.0107
09/16 01:36:18 PM: Evaluate: task edges-pos-ontonotes, batch 121 (157): mcc: 0.9117, acc: 0.8616, precision: 0.9364, recall: 0.8911, f1: 0.9132, edges-pos-ontonotes_loss: 0.0107
09/16 01:36:26 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:36:26 PM: Best result seen so far for macro.
09/16 01:36:26 PM: Updating LR scheduler:
09/16 01:36:26 PM: 	Best result seen so far for macro_avg: 0.913
09/16 01:36:26 PM: 	# validation passes without improvement: 2
09/16 01:36:26 PM: edges-pos-ontonotes_loss: training: 0.014717 validation: 0.010671
09/16 01:36:26 PM: macro_avg: validation: 0.913479
09/16 01:36:26 PM: micro_avg: validation: 0.000000
09/16 01:36:26 PM: edges-pos-ontonotes_mcc: training: 0.869552 validation: 0.911895
09/16 01:36:26 PM: edges-pos-ontonotes_acc: training: 0.790636 validation: 0.862800
09/16 01:36:26 PM: edges-pos-ontonotes_precision: training: 0.910880 validation: 0.933414
09/16 01:36:26 PM: edges-pos-ontonotes_recall: training: 0.835043 validation: 0.894378
09/16 01:36:26 PM: edges-pos-ontonotes_f1: training: 0.871315 validation: 0.913479
09/16 01:36:26 PM: Global learning rate: 0.0001
09/16 01:36:26 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:36:28 PM: Update 21021: task edges-pos-ontonotes, batch 21 (21021): mcc: 0.8732, acc: 0.7924, precision: 0.9254, recall: 0.8286, f1: 0.8743, edges-pos-ontonotes_loss: 0.0140
09/16 01:36:38 PM: Update 21088: task edges-pos-ontonotes, batch 88 (21088): mcc: 0.8713, acc: 0.7920, precision: 0.9145, recall: 0.8350, f1: 0.8729, edges-pos-ontonotes_loss: 0.0144
09/16 01:36:48 PM: Update 21149: task edges-pos-ontonotes, batch 149 (21149): mcc: 0.8722, acc: 0.7946, precision: 0.9108, recall: 0.8401, f1: 0.8740, edges-pos-ontonotes_loss: 0.0143
09/16 01:36:59 PM: Update 21214: task edges-pos-ontonotes, batch 214 (21214): mcc: 0.8736, acc: 0.7966, precision: 0.9109, recall: 0.8427, f1: 0.8754, edges-pos-ontonotes_loss: 0.0143
09/16 01:37:09 PM: Update 21262: task edges-pos-ontonotes, batch 262 (21262): mcc: 0.8736, acc: 0.7965, precision: 0.9105, recall: 0.8430, f1: 0.8755, edges-pos-ontonotes_loss: 0.0142
09/16 01:37:19 PM: Update 21308: task edges-pos-ontonotes, batch 308 (21308): mcc: 0.8740, acc: 0.7973, precision: 0.9107, recall: 0.8437, f1: 0.8759, edges-pos-ontonotes_loss: 0.0142
09/16 01:37:29 PM: Update 21363: task edges-pos-ontonotes, batch 363 (21363): mcc: 0.8742, acc: 0.7975, precision: 0.9107, recall: 0.8440, f1: 0.8761, edges-pos-ontonotes_loss: 0.0142
09/16 01:37:43 PM: Update 21387: task edges-pos-ontonotes, batch 387 (21387): mcc: 0.8740, acc: 0.7972, precision: 0.9106, recall: 0.8437, f1: 0.8759, edges-pos-ontonotes_loss: 0.0142
09/16 01:37:53 PM: Update 21440: task edges-pos-ontonotes, batch 440 (21440): mcc: 0.8728, acc: 0.7958, precision: 0.9089, recall: 0.8429, f1: 0.8747, edges-pos-ontonotes_loss: 0.0143
09/16 01:38:03 PM: Update 21474: task edges-pos-ontonotes, batch 474 (21474): mcc: 0.8723, acc: 0.7952, precision: 0.9083, recall: 0.8426, f1: 0.8742, edges-pos-ontonotes_loss: 0.0144
09/16 01:38:13 PM: Update 21505: task edges-pos-ontonotes, batch 505 (21505): mcc: 0.8715, acc: 0.7943, precision: 0.9075, recall: 0.8419, f1: 0.8735, edges-pos-ontonotes_loss: 0.0145
09/16 01:38:23 PM: Update 21538: task edges-pos-ontonotes, batch 538 (21538): mcc: 0.8715, acc: 0.7944, precision: 0.9073, recall: 0.8421, f1: 0.8735, edges-pos-ontonotes_loss: 0.0145
09/16 01:38:33 PM: Update 21579: task edges-pos-ontonotes, batch 579 (21579): mcc: 0.8712, acc: 0.7939, precision: 0.9071, recall: 0.8417, f1: 0.8731, edges-pos-ontonotes_loss: 0.0146
09/16 01:38:43 PM: Update 21616: task edges-pos-ontonotes, batch 616 (21616): mcc: 0.8713, acc: 0.7941, precision: 0.9071, recall: 0.8419, f1: 0.8733, edges-pos-ontonotes_loss: 0.0147
09/16 01:38:54 PM: Update 21652: task edges-pos-ontonotes, batch 652 (21652): mcc: 0.8712, acc: 0.7940, precision: 0.9070, recall: 0.8418, f1: 0.8732, edges-pos-ontonotes_loss: 0.0147
09/16 01:39:04 PM: Update 21685: task edges-pos-ontonotes, batch 685 (21685): mcc: 0.8713, acc: 0.7941, precision: 0.9069, recall: 0.8420, f1: 0.8733, edges-pos-ontonotes_loss: 0.0147
09/16 01:39:14 PM: Update 21707: task edges-pos-ontonotes, batch 707 (21707): mcc: 0.8712, acc: 0.7941, precision: 0.9069, recall: 0.8419, f1: 0.8732, edges-pos-ontonotes_loss: 0.0147
09/16 01:39:24 PM: Update 21737: task edges-pos-ontonotes, batch 737 (21737): mcc: 0.8711, acc: 0.7939, precision: 0.9067, recall: 0.8418, f1: 0.8731, edges-pos-ontonotes_loss: 0.0147
09/16 01:39:34 PM: Update 21769: task edges-pos-ontonotes, batch 769 (21769): mcc: 0.8713, acc: 0.7942, precision: 0.9067, recall: 0.8421, f1: 0.8732, edges-pos-ontonotes_loss: 0.0147
09/16 01:39:44 PM: Update 21802: task edges-pos-ontonotes, batch 802 (21802): mcc: 0.8714, acc: 0.7945, precision: 0.9067, recall: 0.8423, f1: 0.8733, edges-pos-ontonotes_loss: 0.0147
09/16 01:39:54 PM: Update 21837: task edges-pos-ontonotes, batch 837 (21837): mcc: 0.8715, acc: 0.7948, precision: 0.9068, recall: 0.8426, f1: 0.8735, edges-pos-ontonotes_loss: 0.0147
09/16 01:40:05 PM: Update 21871: task edges-pos-ontonotes, batch 871 (21871): mcc: 0.8717, acc: 0.7953, precision: 0.9068, recall: 0.8428, f1: 0.8737, edges-pos-ontonotes_loss: 0.0147
09/16 01:40:15 PM: Update 21916: task edges-pos-ontonotes, batch 916 (21916): mcc: 0.8719, acc: 0.7957, precision: 0.9071, recall: 0.8431, f1: 0.8739, edges-pos-ontonotes_loss: 0.0146
09/16 01:40:25 PM: Update 21969: task edges-pos-ontonotes, batch 969 (21969): mcc: 0.8722, acc: 0.7961, precision: 0.9072, recall: 0.8434, f1: 0.8742, edges-pos-ontonotes_loss: 0.0147
09/16 01:40:30 PM: ***** Step 22000 / Validation 22 *****
09/16 01:40:30 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:40:30 PM: Validating...
09/16 01:40:35 PM: Evaluate: task edges-pos-ontonotes, batch 27 (157): mcc: 0.9025, acc: 0.8444, precision: 0.9461, recall: 0.8645, f1: 0.9035, edges-pos-ontonotes_loss: 0.0115
09/16 01:40:45 PM: Evaluate: task edges-pos-ontonotes, batch 84 (157): mcc: 0.9118, acc: 0.8590, precision: 0.9491, recall: 0.8792, f1: 0.9128, edges-pos-ontonotes_loss: 0.0108
09/16 01:40:55 PM: Evaluate: task edges-pos-ontonotes, batch 130 (157): mcc: 0.9123, acc: 0.8611, precision: 0.9444, recall: 0.8847, f1: 0.9136, edges-pos-ontonotes_loss: 0.0106
09/16 01:41:01 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:41:01 PM: Best result seen so far for macro.
09/16 01:41:01 PM: Updating LR scheduler:
09/16 01:41:01 PM: 	Best result seen so far for macro_avg: 0.915
09/16 01:41:01 PM: 	# validation passes without improvement: 0
09/16 01:41:01 PM: edges-pos-ontonotes_loss: training: 0.014653 validation: 0.010462
09/16 01:41:01 PM: macro_avg: validation: 0.914926
09/16 01:41:01 PM: micro_avg: validation: 0.000000
09/16 01:41:01 PM: edges-pos-ontonotes_mcc: training: 0.872326 validation: 0.913608
09/16 01:41:01 PM: edges-pos-ontonotes_acc: training: 0.796342 validation: 0.864080
09/16 01:41:01 PM: edges-pos-ontonotes_precision: training: 0.907432 validation: 0.943492
09/16 01:41:01 PM: edges-pos-ontonotes_recall: training: 0.843494 validation: 0.888039
09/16 01:41:01 PM: edges-pos-ontonotes_f1: training: 0.874295 validation: 0.914926
09/16 01:41:01 PM: Global learning rate: 0.0001
09/16 01:41:01 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:41:05 PM: Update 22013: task edges-pos-ontonotes, batch 13 (22013): mcc: 0.8725, acc: 0.7977, precision: 0.9076, recall: 0.8437, f1: 0.8745, edges-pos-ontonotes_loss: 0.0146
09/16 01:41:16 PM: Update 22043: task edges-pos-ontonotes, batch 43 (22043): mcc: 0.8711, acc: 0.7974, precision: 0.9078, recall: 0.8408, f1: 0.8730, edges-pos-ontonotes_loss: 0.0153
09/16 01:41:26 PM: Update 22079: task edges-pos-ontonotes, batch 79 (22079): mcc: 0.8733, acc: 0.8004, precision: 0.9092, recall: 0.8437, f1: 0.8752, edges-pos-ontonotes_loss: 0.0153
09/16 01:41:36 PM: Update 22116: task edges-pos-ontonotes, batch 116 (22116): mcc: 0.8754, acc: 0.8029, precision: 0.9104, recall: 0.8465, f1: 0.8773, edges-pos-ontonotes_loss: 0.0149
09/16 01:41:46 PM: Update 22162: task edges-pos-ontonotes, batch 162 (22162): mcc: 0.8766, acc: 0.8048, precision: 0.9115, recall: 0.8478, f1: 0.8785, edges-pos-ontonotes_loss: 0.0147
09/16 01:41:56 PM: Update 22221: task edges-pos-ontonotes, batch 221 (22221): mcc: 0.8772, acc: 0.8055, precision: 0.9126, recall: 0.8479, f1: 0.8791, edges-pos-ontonotes_loss: 0.0145
09/16 01:42:06 PM: Update 22271: task edges-pos-ontonotes, batch 271 (22271): mcc: 0.8778, acc: 0.8064, precision: 0.9130, recall: 0.8487, f1: 0.8797, edges-pos-ontonotes_loss: 0.0144
09/16 01:42:17 PM: Update 22320: task edges-pos-ontonotes, batch 320 (22320): mcc: 0.8778, acc: 0.8062, precision: 0.9130, recall: 0.8487, f1: 0.8797, edges-pos-ontonotes_loss: 0.0144
09/16 01:42:27 PM: Update 22340: task edges-pos-ontonotes, batch 340 (22340): mcc: 0.8776, acc: 0.8059, precision: 0.9127, recall: 0.8486, f1: 0.8795, edges-pos-ontonotes_loss: 0.0144
09/16 01:42:37 PM: Update 22374: task edges-pos-ontonotes, batch 374 (22374): mcc: 0.8778, acc: 0.8061, precision: 0.9130, recall: 0.8486, f1: 0.8797, edges-pos-ontonotes_loss: 0.0144
09/16 01:42:47 PM: Update 22416: task edges-pos-ontonotes, batch 416 (22416): mcc: 0.8777, acc: 0.8059, precision: 0.9128, recall: 0.8485, f1: 0.8795, edges-pos-ontonotes_loss: 0.0145
09/16 01:42:57 PM: Update 22455: task edges-pos-ontonotes, batch 455 (22455): mcc: 0.8777, acc: 0.8062, precision: 0.9127, recall: 0.8488, f1: 0.8796, edges-pos-ontonotes_loss: 0.0144
09/16 01:43:07 PM: Update 22502: task edges-pos-ontonotes, batch 502 (22502): mcc: 0.8779, acc: 0.8063, precision: 0.9127, recall: 0.8491, f1: 0.8797, edges-pos-ontonotes_loss: 0.0145
09/16 01:43:18 PM: Update 22554: task edges-pos-ontonotes, batch 554 (22554): mcc: 0.8782, acc: 0.8069, precision: 0.9130, recall: 0.8495, f1: 0.8801, edges-pos-ontonotes_loss: 0.0145
09/16 01:43:28 PM: Update 22606: task edges-pos-ontonotes, batch 606 (22606): mcc: 0.8783, acc: 0.8070, precision: 0.9131, recall: 0.8494, f1: 0.8801, edges-pos-ontonotes_loss: 0.0145
09/16 01:43:38 PM: Update 22644: task edges-pos-ontonotes, batch 644 (22644): mcc: 0.8778, acc: 0.8064, precision: 0.9127, recall: 0.8488, f1: 0.8796, edges-pos-ontonotes_loss: 0.0145
09/16 01:43:48 PM: Update 22702: task edges-pos-ontonotes, batch 702 (22702): mcc: 0.8779, acc: 0.8067, precision: 0.9128, recall: 0.8491, f1: 0.8798, edges-pos-ontonotes_loss: 0.0144
09/16 01:43:58 PM: Update 22756: task edges-pos-ontonotes, batch 756 (22756): mcc: 0.8782, acc: 0.8071, precision: 0.9130, recall: 0.8495, f1: 0.8801, edges-pos-ontonotes_loss: 0.0142
09/16 01:44:09 PM: Update 22814: task edges-pos-ontonotes, batch 814 (22814): mcc: 0.8785, acc: 0.8075, precision: 0.9134, recall: 0.8497, f1: 0.8804, edges-pos-ontonotes_loss: 0.0141
09/16 01:44:19 PM: Update 22882: task edges-pos-ontonotes, batch 882 (22882): mcc: 0.8791, acc: 0.8082, precision: 0.9138, recall: 0.8504, f1: 0.8810, edges-pos-ontonotes_loss: 0.0140
09/16 01:44:29 PM: Update 22943: task edges-pos-ontonotes, batch 943 (22943): mcc: 0.8793, acc: 0.8084, precision: 0.9139, recall: 0.8507, f1: 0.8812, edges-pos-ontonotes_loss: 0.0139
09/16 01:44:39 PM: Update 22991: task edges-pos-ontonotes, batch 991 (22991): mcc: 0.8800, acc: 0.8093, precision: 0.9145, recall: 0.8514, f1: 0.8818, edges-pos-ontonotes_loss: 0.0137
09/16 01:44:40 PM: ***** Step 23000 / Validation 23 *****
09/16 01:44:40 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:44:40 PM: Validating...
09/16 01:44:49 PM: Evaluate: task edges-pos-ontonotes, batch 46 (157): mcc: 0.9022, acc: 0.8434, precision: 0.9475, recall: 0.8627, f1: 0.9031, edges-pos-ontonotes_loss: 0.0117
09/16 01:44:59 PM: Evaluate: task edges-pos-ontonotes, batch 93 (157): mcc: 0.9098, acc: 0.8567, precision: 0.9460, recall: 0.8784, f1: 0.9110, edges-pos-ontonotes_loss: 0.0109
09/16 01:45:09 PM: Evaluate: task edges-pos-ontonotes, batch 138 (157): mcc: 0.9115, acc: 0.8604, precision: 0.9423, recall: 0.8852, f1: 0.9129, edges-pos-ontonotes_loss: 0.0107
09/16 01:45:13 PM: Updating LR scheduler:
09/16 01:45:13 PM: 	Best result seen so far for macro_avg: 0.915
09/16 01:45:13 PM: 	# validation passes without improvement: 1
09/16 01:45:13 PM: edges-pos-ontonotes_loss: training: 0.013707 validation: 0.010549
09/16 01:45:13 PM: macro_avg: validation: 0.914125
09/16 01:45:13 PM: micro_avg: validation: 0.000000
09/16 01:45:13 PM: edges-pos-ontonotes_mcc: training: 0.880146 validation: 0.912778
09/16 01:45:13 PM: edges-pos-ontonotes_acc: training: 0.809511 validation: 0.863043
09/16 01:45:13 PM: edges-pos-ontonotes_precision: training: 0.914626 validation: 0.942279
09/16 01:45:13 PM: edges-pos-ontonotes_recall: training: 0.851588 validation: 0.887605
09/16 01:45:13 PM: edges-pos-ontonotes_f1: training: 0.881982 validation: 0.914125
09/16 01:45:13 PM: Global learning rate: 0.0001
09/16 01:45:13 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:45:19 PM: Update 23057: task edges-pos-ontonotes, batch 57 (23057): mcc: 0.9068, acc: 0.8460, precision: 0.9376, recall: 0.8807, f1: 0.9083, edges-pos-ontonotes_loss: 0.0111
09/16 01:45:29 PM: Update 23146: task edges-pos-ontonotes, batch 146 (23146): mcc: 0.9080, acc: 0.8465, precision: 0.9381, recall: 0.8825, f1: 0.9094, edges-pos-ontonotes_loss: 0.0108
09/16 01:45:39 PM: Update 23213: task edges-pos-ontonotes, batch 213 (23213): mcc: 0.9096, acc: 0.8485, precision: 0.9392, recall: 0.8844, f1: 0.9110, edges-pos-ontonotes_loss: 0.0106
09/16 01:45:58 PM: Update 23265: task edges-pos-ontonotes, batch 265 (23265): mcc: 0.9096, acc: 0.8484, precision: 0.9398, recall: 0.8839, f1: 0.9110, edges-pos-ontonotes_loss: 0.0106
09/16 01:46:08 PM: Update 23348: task edges-pos-ontonotes, batch 348 (23348): mcc: 0.9085, acc: 0.8466, precision: 0.9400, recall: 0.8816, f1: 0.9099, edges-pos-ontonotes_loss: 0.0109
09/16 01:46:18 PM: Update 23432: task edges-pos-ontonotes, batch 432 (23432): mcc: 0.9082, acc: 0.8463, precision: 0.9401, recall: 0.8809, f1: 0.9095, edges-pos-ontonotes_loss: 0.0109
09/16 01:46:28 PM: Update 23508: task edges-pos-ontonotes, batch 508 (23508): mcc: 0.9076, acc: 0.8458, precision: 0.9395, recall: 0.8805, f1: 0.9090, edges-pos-ontonotes_loss: 0.0109
09/16 01:46:39 PM: Update 23578: task edges-pos-ontonotes, batch 578 (23578): mcc: 0.9072, acc: 0.8454, precision: 0.9393, recall: 0.8798, f1: 0.9086, edges-pos-ontonotes_loss: 0.0109
09/16 01:46:49 PM: Update 23687: task edges-pos-ontonotes, batch 687 (23687): mcc: 0.9028, acc: 0.8391, precision: 0.9363, recall: 0.8744, f1: 0.9043, edges-pos-ontonotes_loss: 0.0116
09/16 01:46:59 PM: Update 23799: task edges-pos-ontonotes, batch 799 (23799): mcc: 0.8998, acc: 0.8346, precision: 0.9343, recall: 0.8705, f1: 0.9013, edges-pos-ontonotes_loss: 0.0120
09/16 01:47:10 PM: Update 23891: task edges-pos-ontonotes, batch 891 (23891): mcc: 0.8975, acc: 0.8311, precision: 0.9326, recall: 0.8676, f1: 0.8989, edges-pos-ontonotes_loss: 0.0122
09/16 01:47:20 PM: Update 23948: task edges-pos-ontonotes, batch 948 (23948): mcc: 0.8937, acc: 0.8257, precision: 0.9292, recall: 0.8636, f1: 0.8952, edges-pos-ontonotes_loss: 0.0124
09/16 01:47:29 PM: ***** Step 24000 / Validation 24 *****
09/16 01:47:29 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:47:29 PM: Validating...
09/16 01:47:30 PM: Evaluate: task edges-pos-ontonotes, batch 6 (157): mcc: 0.9096, acc: 0.8573, precision: 0.9302, recall: 0.8930, f1: 0.9112, edges-pos-ontonotes_loss: 0.0110
09/16 01:47:40 PM: Evaluate: task edges-pos-ontonotes, batch 75 (157): mcc: 0.9085, acc: 0.8547, precision: 0.9419, recall: 0.8798, f1: 0.9098, edges-pos-ontonotes_loss: 0.0111
09/16 01:47:50 PM: Evaluate: task edges-pos-ontonotes, batch 125 (157): mcc: 0.9073, acc: 0.8536, precision: 0.9342, recall: 0.8849, f1: 0.9089, edges-pos-ontonotes_loss: 0.0110
09/16 01:47:57 PM: Updating LR scheduler:
09/16 01:47:57 PM: 	Best result seen so far for macro_avg: 0.915
09/16 01:47:57 PM: 	# validation passes without improvement: 2
09/16 01:47:57 PM: edges-pos-ontonotes_loss: training: 0.012648 validation: 0.010899
09/16 01:47:57 PM: macro_avg: validation: 0.910192
09/16 01:47:57 PM: micro_avg: validation: 0.000000
09/16 01:47:57 PM: edges-pos-ontonotes_mcc: training: 0.891247 validation: 0.908587
09/16 01:47:57 PM: edges-pos-ontonotes_acc: training: 0.822129 validation: 0.856355
09/16 01:47:57 PM: edges-pos-ontonotes_precision: training: 0.926678 validation: 0.932067
09/16 01:47:57 PM: edges-pos-ontonotes_recall: training: 0.861354 validation: 0.889319
09/16 01:47:57 PM: edges-pos-ontonotes_f1: training: 0.892823 validation: 0.910192
09/16 01:47:57 PM: Global learning rate: 0.0001
09/16 01:47:57 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:48:00 PM: Update 24019: task edges-pos-ontonotes, batch 19 (24019): mcc: 0.8611, acc: 0.7801, precision: 0.8991, recall: 0.8300, f1: 0.8632, edges-pos-ontonotes_loss: 0.0167
09/16 01:48:10 PM: Update 24064: task edges-pos-ontonotes, batch 64 (24064): mcc: 0.8659, acc: 0.7863, precision: 0.9018, recall: 0.8366, f1: 0.8680, edges-pos-ontonotes_loss: 0.0160
09/16 01:48:21 PM: Update 24112: task edges-pos-ontonotes, batch 112 (24112): mcc: 0.8670, acc: 0.7879, precision: 0.9027, recall: 0.8379, f1: 0.8691, edges-pos-ontonotes_loss: 0.0158
09/16 01:48:31 PM: Update 24171: task edges-pos-ontonotes, batch 171 (24171): mcc: 0.8666, acc: 0.7871, precision: 0.9029, recall: 0.8369, f1: 0.8686, edges-pos-ontonotes_loss: 0.0158
09/16 01:48:41 PM: Update 24221: task edges-pos-ontonotes, batch 221 (24221): mcc: 0.8660, acc: 0.7861, precision: 0.9029, recall: 0.8357, f1: 0.8680, edges-pos-ontonotes_loss: 0.0158
09/16 01:48:51 PM: Update 24291: task edges-pos-ontonotes, batch 291 (24291): mcc: 0.8664, acc: 0.7865, precision: 0.9055, recall: 0.8341, f1: 0.8683, edges-pos-ontonotes_loss: 0.0155
09/16 01:49:01 PM: Update 24361: task edges-pos-ontonotes, batch 361 (24361): mcc: 0.8672, acc: 0.7874, precision: 0.9071, recall: 0.8340, f1: 0.8691, edges-pos-ontonotes_loss: 0.0153
09/16 01:49:11 PM: Update 24412: task edges-pos-ontonotes, batch 412 (24412): mcc: 0.8673, acc: 0.7874, precision: 0.9079, recall: 0.8335, f1: 0.8691, edges-pos-ontonotes_loss: 0.0152
09/16 01:49:22 PM: Update 24473: task edges-pos-ontonotes, batch 473 (24473): mcc: 0.8678, acc: 0.7881, precision: 0.9089, recall: 0.8337, f1: 0.8697, edges-pos-ontonotes_loss: 0.0150
09/16 01:49:34 PM: Update 24534: task edges-pos-ontonotes, batch 534 (24534): mcc: 0.8683, acc: 0.7885, precision: 0.9096, recall: 0.8339, f1: 0.8701, edges-pos-ontonotes_loss: 0.0149
09/16 01:49:44 PM: Update 24583: task edges-pos-ontonotes, batch 583 (24583): mcc: 0.8688, acc: 0.7893, precision: 0.9093, recall: 0.8350, f1: 0.8706, edges-pos-ontonotes_loss: 0.0149
09/16 01:49:54 PM: Update 24632: task edges-pos-ontonotes, batch 632 (24632): mcc: 0.8695, acc: 0.7903, precision: 0.9095, recall: 0.8361, f1: 0.8713, edges-pos-ontonotes_loss: 0.0148
09/16 01:50:05 PM: Update 24697: task edges-pos-ontonotes, batch 697 (24697): mcc: 0.8700, acc: 0.7911, precision: 0.9098, recall: 0.8369, f1: 0.8718, edges-pos-ontonotes_loss: 0.0147
09/16 01:50:15 PM: Update 24754: task edges-pos-ontonotes, batch 754 (24754): mcc: 0.8708, acc: 0.7921, precision: 0.9101, recall: 0.8381, f1: 0.8726, edges-pos-ontonotes_loss: 0.0146
09/16 01:50:25 PM: Update 24818: task edges-pos-ontonotes, batch 818 (24818): mcc: 0.8713, acc: 0.7929, precision: 0.9102, recall: 0.8389, f1: 0.8731, edges-pos-ontonotes_loss: 0.0146
09/16 01:50:35 PM: Update 24870: task edges-pos-ontonotes, batch 870 (24870): mcc: 0.8710, acc: 0.7927, precision: 0.9096, recall: 0.8390, f1: 0.8729, edges-pos-ontonotes_loss: 0.0146
09/16 01:50:45 PM: Update 24926: task edges-pos-ontonotes, batch 926 (24926): mcc: 0.8710, acc: 0.7927, precision: 0.9092, recall: 0.8393, f1: 0.8729, edges-pos-ontonotes_loss: 0.0146
09/16 01:50:55 PM: Update 24980: task edges-pos-ontonotes, batch 980 (24980): mcc: 0.8709, acc: 0.7927, precision: 0.9088, recall: 0.8394, f1: 0.8727, edges-pos-ontonotes_loss: 0.0147
09/16 01:50:58 PM: ***** Step 25000 / Validation 25 *****
09/16 01:50:58 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:50:58 PM: Validating...
09/16 01:51:05 PM: Evaluate: task edges-pos-ontonotes, batch 47 (157): mcc: 0.9070, acc: 0.8506, precision: 0.9514, recall: 0.8682, f1: 0.9079, edges-pos-ontonotes_loss: 0.0111
09/16 01:51:15 PM: Evaluate: task edges-pos-ontonotes, batch 105 (157): mcc: 0.9147, acc: 0.8636, precision: 0.9502, recall: 0.8839, f1: 0.9158, edges-pos-ontonotes_loss: 0.0103
09/16 01:51:26 PM: Evaluate: task edges-pos-ontonotes, batch 149 (157): mcc: 0.9135, acc: 0.8632, precision: 0.9447, recall: 0.8867, f1: 0.9148, edges-pos-ontonotes_loss: 0.0103
09/16 01:51:27 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:51:27 PM: Best result seen so far for macro.
09/16 01:51:27 PM: Updating LR scheduler:
09/16 01:51:27 PM: 	Best result seen so far for macro_avg: 0.915
09/16 01:51:27 PM: 	# validation passes without improvement: 0
09/16 01:51:27 PM: edges-pos-ontonotes_loss: training: 0.014664 validation: 0.010298
09/16 01:51:27 PM: macro_avg: validation: 0.915164
09/16 01:51:27 PM: micro_avg: validation: 0.000000
09/16 01:51:27 PM: edges-pos-ontonotes_mcc: training: 0.870926 validation: 0.913885
09/16 01:51:27 PM: edges-pos-ontonotes_acc: training: 0.792812 validation: 0.864112
09/16 01:51:27 PM: edges-pos-ontonotes_precision: training: 0.908666 validation: 0.944789
09/16 01:51:27 PM: edges-pos-ontonotes_recall: training: 0.839689 validation: 0.887340
09/16 01:51:27 PM: edges-pos-ontonotes_f1: training: 0.872817 validation: 0.915164
09/16 01:51:27 PM: Global learning rate: 0.0001
09/16 01:51:27 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:51:36 PM: Update 25045: task edges-pos-ontonotes, batch 45 (25045): mcc: 0.8692, acc: 0.7940, precision: 0.9003, recall: 0.8442, f1: 0.8714, edges-pos-ontonotes_loss: 0.0153
09/16 01:51:46 PM: Update 25088: task edges-pos-ontonotes, batch 88 (25088): mcc: 0.8697, acc: 0.7936, precision: 0.9027, recall: 0.8430, f1: 0.8718, edges-pos-ontonotes_loss: 0.0151
09/16 01:51:56 PM: Update 25138: task edges-pos-ontonotes, batch 138 (25138): mcc: 0.8704, acc: 0.7943, precision: 0.9035, recall: 0.8436, f1: 0.8725, edges-pos-ontonotes_loss: 0.0152
09/16 01:52:11 PM: Update 25160: task edges-pos-ontonotes, batch 160 (25160): mcc: 0.8702, acc: 0.7940, precision: 0.9040, recall: 0.8426, f1: 0.8722, edges-pos-ontonotes_loss: 0.0152
09/16 01:52:22 PM: Update 25210: task edges-pos-ontonotes, batch 210 (25210): mcc: 0.8709, acc: 0.7952, precision: 0.9045, recall: 0.8435, f1: 0.8729, edges-pos-ontonotes_loss: 0.0150
09/16 01:52:32 PM: Update 25257: task edges-pos-ontonotes, batch 257 (25257): mcc: 0.8717, acc: 0.7963, precision: 0.9054, recall: 0.8443, f1: 0.8738, edges-pos-ontonotes_loss: 0.0149
09/16 01:52:42 PM: Update 25307: task edges-pos-ontonotes, batch 307 (25307): mcc: 0.8722, acc: 0.7971, precision: 0.9059, recall: 0.8446, f1: 0.8742, edges-pos-ontonotes_loss: 0.0149
09/16 01:52:52 PM: Update 25356: task edges-pos-ontonotes, batch 356 (25356): mcc: 0.8728, acc: 0.7980, precision: 0.9065, recall: 0.8453, f1: 0.8748, edges-pos-ontonotes_loss: 0.0149
09/16 01:53:03 PM: Update 25398: task edges-pos-ontonotes, batch 398 (25398): mcc: 0.8734, acc: 0.7988, precision: 0.9069, recall: 0.8461, f1: 0.8754, edges-pos-ontonotes_loss: 0.0148
09/16 01:53:13 PM: Update 25438: task edges-pos-ontonotes, batch 438 (25438): mcc: 0.8739, acc: 0.7997, precision: 0.9074, recall: 0.8466, f1: 0.8759, edges-pos-ontonotes_loss: 0.0147
09/16 01:53:24 PM: Update 25473: task edges-pos-ontonotes, batch 473 (25473): mcc: 0.8743, acc: 0.8001, precision: 0.9078, recall: 0.8470, f1: 0.8763, edges-pos-ontonotes_loss: 0.0146
09/16 01:53:34 PM: Update 25511: task edges-pos-ontonotes, batch 511 (25511): mcc: 0.8745, acc: 0.8004, precision: 0.9080, recall: 0.8471, f1: 0.8765, edges-pos-ontonotes_loss: 0.0146
09/16 01:53:44 PM: Update 25564: task edges-pos-ontonotes, batch 564 (25564): mcc: 0.8748, acc: 0.8010, precision: 0.9082, recall: 0.8475, f1: 0.8768, edges-pos-ontonotes_loss: 0.0146
09/16 01:53:54 PM: Update 25607: task edges-pos-ontonotes, batch 607 (25607): mcc: 0.8751, acc: 0.8015, precision: 0.9085, recall: 0.8477, f1: 0.8770, edges-pos-ontonotes_loss: 0.0146
09/16 01:54:04 PM: Update 25651: task edges-pos-ontonotes, batch 651 (25651): mcc: 0.8754, acc: 0.8019, precision: 0.9088, recall: 0.8480, f1: 0.8774, edges-pos-ontonotes_loss: 0.0146
09/16 01:54:14 PM: Update 25695: task edges-pos-ontonotes, batch 695 (25695): mcc: 0.8755, acc: 0.8023, precision: 0.9090, recall: 0.8481, f1: 0.8775, edges-pos-ontonotes_loss: 0.0145
09/16 01:54:24 PM: Update 25750: task edges-pos-ontonotes, batch 750 (25750): mcc: 0.8758, acc: 0.8026, precision: 0.9092, recall: 0.8483, f1: 0.8777, edges-pos-ontonotes_loss: 0.0145
09/16 01:54:37 PM: Update 25786: task edges-pos-ontonotes, batch 786 (25786): mcc: 0.8759, acc: 0.8027, precision: 0.9094, recall: 0.8484, f1: 0.8778, edges-pos-ontonotes_loss: 0.0145
09/16 01:54:47 PM: Update 25819: task edges-pos-ontonotes, batch 819 (25819): mcc: 0.8760, acc: 0.8029, precision: 0.9095, recall: 0.8484, f1: 0.8779, edges-pos-ontonotes_loss: 0.0145
09/16 01:54:58 PM: Update 25851: task edges-pos-ontonotes, batch 851 (25851): mcc: 0.8760, acc: 0.8030, precision: 0.9096, recall: 0.8485, f1: 0.8779, edges-pos-ontonotes_loss: 0.0145
09/16 01:55:08 PM: Update 25881: task edges-pos-ontonotes, batch 881 (25881): mcc: 0.8760, acc: 0.8030, precision: 0.9096, recall: 0.8485, f1: 0.8780, edges-pos-ontonotes_loss: 0.0145
09/16 01:55:18 PM: Update 25911: task edges-pos-ontonotes, batch 911 (25911): mcc: 0.8762, acc: 0.8033, precision: 0.9097, recall: 0.8486, f1: 0.8781, edges-pos-ontonotes_loss: 0.0145
09/16 01:55:28 PM: Update 25945: task edges-pos-ontonotes, batch 945 (25945): mcc: 0.8763, acc: 0.8036, precision: 0.9099, recall: 0.8488, f1: 0.8783, edges-pos-ontonotes_loss: 0.0145
09/16 01:55:38 PM: Update 25979: task edges-pos-ontonotes, batch 979 (25979): mcc: 0.8765, acc: 0.8038, precision: 0.9100, recall: 0.8489, f1: 0.8784, edges-pos-ontonotes_loss: 0.0145
09/16 01:55:43 PM: ***** Step 26000 / Validation 26 *****
09/16 01:55:43 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:55:43 PM: Validating...
09/16 01:55:49 PM: Evaluate: task edges-pos-ontonotes, batch 42 (157): mcc: 0.9045, acc: 0.8469, precision: 0.9488, recall: 0.8659, f1: 0.9054, edges-pos-ontonotes_loss: 0.0115
09/16 01:55:59 PM: Evaluate: task edges-pos-ontonotes, batch 103 (157): mcc: 0.9127, acc: 0.8617, precision: 0.9473, recall: 0.8828, f1: 0.9139, edges-pos-ontonotes_loss: 0.0106
09/16 01:56:09 PM: Evaluate: task edges-pos-ontonotes, batch 148 (157): mcc: 0.9139, acc: 0.8649, precision: 0.9435, recall: 0.8887, f1: 0.9153, edges-pos-ontonotes_loss: 0.0104
09/16 01:56:11 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:56:11 PM: Best result seen so far for macro.
09/16 01:56:11 PM: Updating LR scheduler:
09/16 01:56:11 PM: 	Best result seen so far for macro_avg: 0.916
09/16 01:56:11 PM: 	# validation passes without improvement: 0
09/16 01:56:11 PM: edges-pos-ontonotes_loss: training: 0.014486 validation: 0.010372
09/16 01:56:11 PM: macro_avg: validation: 0.915850
09/16 01:56:11 PM: micro_avg: validation: 0.000000
09/16 01:56:11 PM: edges-pos-ontonotes_mcc: training: 0.876521 validation: 0.914523
09/16 01:56:11 PM: edges-pos-ontonotes_acc: training: 0.803883 validation: 0.866059
09/16 01:56:11 PM: edges-pos-ontonotes_precision: training: 0.910039 validation: 0.943501
09/16 01:56:11 PM: edges-pos-ontonotes_recall: training: 0.849010 validation: 0.889774
09/16 01:56:11 PM: edges-pos-ontonotes_f1: training: 0.878466 validation: 0.915850
09/16 01:56:11 PM: Global learning rate: 0.0001
09/16 01:56:11 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:56:19 PM: Update 26032: task edges-pos-ontonotes, batch 32 (26032): mcc: 0.8783, acc: 0.8079, precision: 0.9121, recall: 0.8505, f1: 0.8802, edges-pos-ontonotes_loss: 0.0145
09/16 01:56:29 PM: Update 26076: task edges-pos-ontonotes, batch 76 (26076): mcc: 0.8788, acc: 0.8091, precision: 0.9126, recall: 0.8510, f1: 0.8807, edges-pos-ontonotes_loss: 0.0143
09/16 01:56:40 PM: Update 26118: task edges-pos-ontonotes, batch 118 (26118): mcc: 0.8766, acc: 0.8058, precision: 0.9106, recall: 0.8486, f1: 0.8785, edges-pos-ontonotes_loss: 0.0143
09/16 01:56:50 PM: Update 26181: task edges-pos-ontonotes, batch 181 (26181): mcc: 0.8798, acc: 0.8094, precision: 0.9135, recall: 0.8521, f1: 0.8817, edges-pos-ontonotes_loss: 0.0136
09/16 01:57:00 PM: Update 26244: task edges-pos-ontonotes, batch 244 (26244): mcc: 0.8801, acc: 0.8097, precision: 0.9132, recall: 0.8528, f1: 0.8820, edges-pos-ontonotes_loss: 0.0134
09/16 01:57:10 PM: Update 26308: task edges-pos-ontonotes, batch 308 (26308): mcc: 0.8814, acc: 0.8116, precision: 0.9145, recall: 0.8541, f1: 0.8833, edges-pos-ontonotes_loss: 0.0131
09/16 01:57:20 PM: Update 26376: task edges-pos-ontonotes, batch 376 (26376): mcc: 0.8824, acc: 0.8127, precision: 0.9154, recall: 0.8551, f1: 0.8842, edges-pos-ontonotes_loss: 0.0129
09/16 01:57:30 PM: Update 26439: task edges-pos-ontonotes, batch 439 (26439): mcc: 0.8837, acc: 0.8144, precision: 0.9164, recall: 0.8568, f1: 0.8856, edges-pos-ontonotes_loss: 0.0127
09/16 01:57:40 PM: Update 26503: task edges-pos-ontonotes, batch 503 (26503): mcc: 0.8861, acc: 0.8176, precision: 0.9186, recall: 0.8592, f1: 0.8879, edges-pos-ontonotes_loss: 0.0125
09/16 01:57:50 PM: Update 26579: task edges-pos-ontonotes, batch 579 (26579): mcc: 0.8881, acc: 0.8203, precision: 0.9205, recall: 0.8612, f1: 0.8899, edges-pos-ontonotes_loss: 0.0122
09/16 01:58:00 PM: Update 26649: task edges-pos-ontonotes, batch 649 (26649): mcc: 0.8902, acc: 0.8232, precision: 0.9223, recall: 0.8635, f1: 0.8919, edges-pos-ontonotes_loss: 0.0120
09/16 01:58:10 PM: Update 26723: task edges-pos-ontonotes, batch 723 (26723): mcc: 0.8919, acc: 0.8254, precision: 0.9237, recall: 0.8653, f1: 0.8936, edges-pos-ontonotes_loss: 0.0119
09/16 01:58:20 PM: Update 26789: task edges-pos-ontonotes, batch 789 (26789): mcc: 0.8925, acc: 0.8261, precision: 0.9245, recall: 0.8657, f1: 0.8942, edges-pos-ontonotes_loss: 0.0118
09/16 01:58:31 PM: Update 26874: task edges-pos-ontonotes, batch 874 (26874): mcc: 0.8934, acc: 0.8273, precision: 0.9255, recall: 0.8665, f1: 0.8950, edges-pos-ontonotes_loss: 0.0118
09/16 01:58:41 PM: Update 26944: task edges-pos-ontonotes, batch 944 (26944): mcc: 0.8939, acc: 0.8281, precision: 0.9260, recall: 0.8671, f1: 0.8956, edges-pos-ontonotes_loss: 0.0117
09/16 01:58:49 PM: ***** Step 27000 / Validation 27 *****
09/16 01:58:49 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:58:49 PM: Validating...
09/16 01:58:51 PM: Evaluate: task edges-pos-ontonotes, batch 9 (157): mcc: 0.8996, acc: 0.8494, precision: 0.9285, recall: 0.8756, f1: 0.9012, edges-pos-ontonotes_loss: 0.0117
09/16 01:59:01 PM: Evaluate: task edges-pos-ontonotes, batch 52 (157): mcc: 0.9071, acc: 0.8538, precision: 0.9454, recall: 0.8739, f1: 0.9082, edges-pos-ontonotes_loss: 0.0112
09/16 01:59:11 PM: Evaluate: task edges-pos-ontonotes, batch 92 (157): mcc: 0.9108, acc: 0.8604, precision: 0.9425, recall: 0.8835, f1: 0.9121, edges-pos-ontonotes_loss: 0.0108
09/16 01:59:21 PM: Evaluate: task edges-pos-ontonotes, batch 121 (157): mcc: 0.9108, acc: 0.8611, precision: 0.9380, recall: 0.8879, f1: 0.9123, edges-pos-ontonotes_loss: 0.0107
09/16 01:59:31 PM: Evaluate: task edges-pos-ontonotes, batch 148 (157): mcc: 0.9112, acc: 0.8624, precision: 0.9346, recall: 0.8919, f1: 0.9128, edges-pos-ontonotes_loss: 0.0107
09/16 01:59:34 PM: Updating LR scheduler:
09/16 01:59:34 PM: 	Best result seen so far for macro_avg: 0.916
09/16 01:59:34 PM: 	# validation passes without improvement: 1
09/16 01:59:34 PM: edges-pos-ontonotes_loss: training: 0.011677 validation: 0.010634
09/16 01:59:34 PM: macro_avg: validation: 0.913461
09/16 01:59:34 PM: micro_avg: validation: 0.000000
09/16 01:59:34 PM: edges-pos-ontonotes_mcc: training: 0.894371 validation: 0.911912
09/16 01:59:34 PM: edges-pos-ontonotes_acc: training: 0.828677 validation: 0.863763
09/16 01:59:34 PM: edges-pos-ontonotes_precision: training: 0.926463 validation: 0.934880
09/16 01:59:34 PM: edges-pos-ontonotes_recall: training: 0.867488 validation: 0.893002
09/16 01:59:34 PM: edges-pos-ontonotes_f1: training: 0.896006 validation: 0.913461
09/16 01:59:34 PM: Global learning rate: 0.0001
09/16 01:59:34 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:59:42 PM: Update 27038: task edges-pos-ontonotes, batch 38 (27038): mcc: 0.9092, acc: 0.8509, precision: 0.9406, recall: 0.8823, f1: 0.9105, edges-pos-ontonotes_loss: 0.0104
09/16 01:59:53 PM: Update 27112: task edges-pos-ontonotes, batch 112 (27112): mcc: 0.8862, acc: 0.8155, precision: 0.9239, recall: 0.8544, f1: 0.8878, edges-pos-ontonotes_loss: 0.0133
09/16 02:00:03 PM: Update 27190: task edges-pos-ontonotes, batch 190 (27190): mcc: 0.8809, acc: 0.8080, precision: 0.9207, recall: 0.8473, f1: 0.8825, edges-pos-ontonotes_loss: 0.0138
09/16 02:00:13 PM: Update 27309: task edges-pos-ontonotes, batch 309 (27309): mcc: 0.8798, acc: 0.8053, precision: 0.9203, recall: 0.8456, f1: 0.8814, edges-pos-ontonotes_loss: 0.0138
09/16 02:00:26 PM: Update 27351: task edges-pos-ontonotes, batch 351 (27351): mcc: 0.8790, acc: 0.8043, precision: 0.9197, recall: 0.8447, f1: 0.8806, edges-pos-ontonotes_loss: 0.0137
09/16 02:00:36 PM: Update 27410: task edges-pos-ontonotes, batch 410 (27410): mcc: 0.8747, acc: 0.7985, precision: 0.9131, recall: 0.8428, f1: 0.8765, edges-pos-ontonotes_loss: 0.0141
09/16 02:00:46 PM: Update 27462: task edges-pos-ontonotes, batch 462 (27462): mcc: 0.8738, acc: 0.7969, precision: 0.9115, recall: 0.8424, f1: 0.8756, edges-pos-ontonotes_loss: 0.0143
09/16 02:00:56 PM: Update 27507: task edges-pos-ontonotes, batch 507 (27507): mcc: 0.8725, acc: 0.7951, precision: 0.9098, recall: 0.8415, f1: 0.8743, edges-pos-ontonotes_loss: 0.0144
09/16 02:01:06 PM: Update 27554: task edges-pos-ontonotes, batch 554 (27554): mcc: 0.8717, acc: 0.7940, precision: 0.9091, recall: 0.8408, f1: 0.8736, edges-pos-ontonotes_loss: 0.0145
09/16 02:01:16 PM: Update 27601: task edges-pos-ontonotes, batch 601 (27601): mcc: 0.8711, acc: 0.7932, precision: 0.9083, recall: 0.8404, f1: 0.8731, edges-pos-ontonotes_loss: 0.0146
09/16 02:01:27 PM: Update 27645: task edges-pos-ontonotes, batch 645 (27645): mcc: 0.8708, acc: 0.7927, precision: 0.9080, recall: 0.8400, f1: 0.8727, edges-pos-ontonotes_loss: 0.0147
09/16 02:01:37 PM: Update 27698: task edges-pos-ontonotes, batch 698 (27698): mcc: 0.8699, acc: 0.7915, precision: 0.9075, recall: 0.8389, f1: 0.8718, edges-pos-ontonotes_loss: 0.0148
09/16 02:01:47 PM: Update 27794: task edges-pos-ontonotes, batch 794 (27794): mcc: 0.8698, acc: 0.7913, precision: 0.9085, recall: 0.8378, f1: 0.8717, edges-pos-ontonotes_loss: 0.0147
09/16 02:01:57 PM: Update 27871: task edges-pos-ontonotes, batch 871 (27871): mcc: 0.8701, acc: 0.7915, precision: 0.9093, recall: 0.8375, f1: 0.8719, edges-pos-ontonotes_loss: 0.0146
09/16 02:02:07 PM: Update 27938: task edges-pos-ontonotes, batch 938 (27938): mcc: 0.8702, acc: 0.7917, precision: 0.9099, recall: 0.8373, f1: 0.8721, edges-pos-ontonotes_loss: 0.0146
09/16 02:02:17 PM: Update 27998: task edges-pos-ontonotes, batch 998 (27998): mcc: 0.8705, acc: 0.7920, precision: 0.9101, recall: 0.8375, f1: 0.8723, edges-pos-ontonotes_loss: 0.0145
09/16 02:02:17 PM: ***** Step 28000 / Validation 28 *****
09/16 02:02:17 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:02:17 PM: Validating...
09/16 02:02:27 PM: Evaluate: task edges-pos-ontonotes, batch 68 (157): mcc: 0.9131, acc: 0.8625, precision: 0.9438, recall: 0.8867, f1: 0.9144, edges-pos-ontonotes_loss: 0.0106
09/16 02:02:37 PM: Evaluate: task edges-pos-ontonotes, batch 120 (157): mcc: 0.9141, acc: 0.8648, precision: 0.9381, recall: 0.8941, f1: 0.9156, edges-pos-ontonotes_loss: 0.0104
09/16 02:02:45 PM: Updating LR scheduler:
09/16 02:02:45 PM: 	Best result seen so far for macro_avg: 0.916
09/16 02:02:45 PM: 	# validation passes without improvement: 2
09/16 02:02:45 PM: edges-pos-ontonotes_loss: training: 0.014541 validation: 0.010356
09/16 02:02:45 PM: macro_avg: validation: 0.915684
09/16 02:02:45 PM: micro_avg: validation: 0.000000
09/16 02:02:45 PM: edges-pos-ontonotes_mcc: training: 0.870508 validation: 0.914125
09/16 02:02:45 PM: edges-pos-ontonotes_acc: training: 0.791999 validation: 0.865541
09/16 02:02:45 PM: edges-pos-ontonotes_precision: training: 0.910111 validation: 0.934735
09/16 02:02:45 PM: edges-pos-ontonotes_recall: training: 0.837557 validation: 0.897394
09/16 02:02:45 PM: edges-pos-ontonotes_f1: training: 0.872328 validation: 0.915684
09/16 02:02:45 PM: Global learning rate: 0.0001
09/16 02:02:45 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:02:47 PM: Update 28017: task edges-pos-ontonotes, batch 17 (28017): mcc: 0.8743, acc: 0.8007, precision: 0.9011, recall: 0.8532, f1: 0.8765, edges-pos-ontonotes_loss: 0.0141
09/16 02:02:57 PM: Update 28082: task edges-pos-ontonotes, batch 82 (28082): mcc: 0.8760, acc: 0.7995, precision: 0.9082, recall: 0.8497, f1: 0.8780, edges-pos-ontonotes_loss: 0.0141
09/16 02:03:07 PM: Update 28161: task edges-pos-ontonotes, batch 161 (28161): mcc: 0.8768, acc: 0.8007, precision: 0.9102, recall: 0.8494, f1: 0.8787, edges-pos-ontonotes_loss: 0.0139
09/16 02:03:18 PM: Update 28221: task edges-pos-ontonotes, batch 221 (28221): mcc: 0.8759, acc: 0.7994, precision: 0.9091, recall: 0.8486, f1: 0.8778, edges-pos-ontonotes_loss: 0.0140
09/16 02:03:28 PM: Update 28279: task edges-pos-ontonotes, batch 279 (28279): mcc: 0.8760, acc: 0.7999, precision: 0.9097, recall: 0.8484, f1: 0.8780, edges-pos-ontonotes_loss: 0.0139
09/16 02:03:38 PM: Update 28310: task edges-pos-ontonotes, batch 310 (28310): mcc: 0.8753, acc: 0.7989, precision: 0.9088, recall: 0.8478, f1: 0.8773, edges-pos-ontonotes_loss: 0.0139
09/16 02:03:48 PM: Update 28345: task edges-pos-ontonotes, batch 345 (28345): mcc: 0.8745, acc: 0.7978, precision: 0.9078, recall: 0.8472, f1: 0.8765, edges-pos-ontonotes_loss: 0.0140
09/16 02:03:58 PM: Update 28380: task edges-pos-ontonotes, batch 380 (28380): mcc: 0.8744, acc: 0.7979, precision: 0.9076, recall: 0.8472, f1: 0.8764, edges-pos-ontonotes_loss: 0.0141
09/16 02:04:08 PM: Update 28431: task edges-pos-ontonotes, batch 431 (28431): mcc: 0.8739, acc: 0.7975, precision: 0.9070, recall: 0.8469, f1: 0.8759, edges-pos-ontonotes_loss: 0.0142
09/16 02:04:19 PM: Update 28487: task edges-pos-ontonotes, batch 487 (28487): mcc: 0.8738, acc: 0.7976, precision: 0.9068, recall: 0.8470, f1: 0.8759, edges-pos-ontonotes_loss: 0.0144
09/16 02:04:29 PM: Update 28527: task edges-pos-ontonotes, batch 527 (28527): mcc: 0.8739, acc: 0.7977, precision: 0.9068, recall: 0.8470, f1: 0.8759, edges-pos-ontonotes_loss: 0.0144
09/16 02:04:39 PM: Update 28562: task edges-pos-ontonotes, batch 562 (28562): mcc: 0.8738, acc: 0.7976, precision: 0.9066, recall: 0.8471, f1: 0.8758, edges-pos-ontonotes_loss: 0.0144
09/16 02:04:51 PM: Update 28620: task edges-pos-ontonotes, batch 620 (28620): mcc: 0.8736, acc: 0.7975, precision: 0.9064, recall: 0.8468, f1: 0.8756, edges-pos-ontonotes_loss: 0.0144
09/16 02:05:01 PM: Update 28669: task edges-pos-ontonotes, batch 669 (28669): mcc: 0.8734, acc: 0.7973, precision: 0.9063, recall: 0.8465, f1: 0.8754, edges-pos-ontonotes_loss: 0.0145
09/16 02:05:11 PM: Update 28724: task edges-pos-ontonotes, batch 724 (28724): mcc: 0.8737, acc: 0.7979, precision: 0.9067, recall: 0.8469, f1: 0.8757, edges-pos-ontonotes_loss: 0.0144
09/16 02:05:21 PM: Update 28759: task edges-pos-ontonotes, batch 759 (28759): mcc: 0.8738, acc: 0.7981, precision: 0.9067, recall: 0.8470, f1: 0.8758, edges-pos-ontonotes_loss: 0.0144
09/16 02:05:31 PM: Update 28803: task edges-pos-ontonotes, batch 803 (28803): mcc: 0.8740, acc: 0.7984, precision: 0.9068, recall: 0.8472, f1: 0.8760, edges-pos-ontonotes_loss: 0.0144
09/16 02:05:42 PM: Update 28848: task edges-pos-ontonotes, batch 848 (28848): mcc: 0.8742, acc: 0.7988, precision: 0.9070, recall: 0.8474, f1: 0.8762, edges-pos-ontonotes_loss: 0.0144
09/16 02:05:52 PM: Update 28888: task edges-pos-ontonotes, batch 888 (28888): mcc: 0.8744, acc: 0.7993, precision: 0.9072, recall: 0.8477, f1: 0.8764, edges-pos-ontonotes_loss: 0.0144
09/16 02:06:02 PM: Update 28921: task edges-pos-ontonotes, batch 921 (28921): mcc: 0.8746, acc: 0.7995, precision: 0.9074, recall: 0.8478, f1: 0.8766, edges-pos-ontonotes_loss: 0.0144
09/16 02:06:12 PM: Update 28937: task edges-pos-ontonotes, batch 937 (28937): mcc: 0.8745, acc: 0.7996, precision: 0.9073, recall: 0.8478, f1: 0.8765, edges-pos-ontonotes_loss: 0.0144
09/16 02:06:23 PM: Update 28973: task edges-pos-ontonotes, batch 973 (28973): mcc: 0.8747, acc: 0.7998, precision: 0.9075, recall: 0.8479, f1: 0.8767, edges-pos-ontonotes_loss: 0.0144
09/16 02:06:29 PM: ***** Step 29000 / Validation 29 *****
09/16 02:06:29 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:06:29 PM: Validating...
09/16 02:06:33 PM: Evaluate: task edges-pos-ontonotes, batch 17 (157): mcc: 0.9048, acc: 0.8504, precision: 0.9407, recall: 0.8740, f1: 0.9061, edges-pos-ontonotes_loss: 0.0112
09/16 02:06:43 PM: Evaluate: task edges-pos-ontonotes, batch 70 (157): mcc: 0.9132, acc: 0.8619, precision: 0.9487, recall: 0.8825, f1: 0.9144, edges-pos-ontonotes_loss: 0.0107
09/16 02:06:53 PM: Evaluate: task edges-pos-ontonotes, batch 113 (157): mcc: 0.9149, acc: 0.8655, precision: 0.9457, recall: 0.8884, f1: 0.9162, edges-pos-ontonotes_loss: 0.0104
09/16 02:07:10 PM: Evaluate: task edges-pos-ontonotes, batch 154 (157): mcc: 0.9159, acc: 0.8679, precision: 0.9427, recall: 0.8932, f1: 0.9173, edges-pos-ontonotes_loss: 0.0102
09/16 02:07:10 PM: Best result seen so far for edges-pos-ontonotes.
09/16 02:07:10 PM: Best result seen so far for macro.
09/16 02:07:10 PM: Updating LR scheduler:
09/16 02:07:10 PM: 	Best result seen so far for macro_avg: 0.917
09/16 02:07:10 PM: 	# validation passes without improvement: 0
09/16 02:07:10 PM: edges-pos-ontonotes_loss: training: 0.014364 validation: 0.010188
09/16 02:07:10 PM: macro_avg: validation: 0.917464
09/16 02:07:10 PM: micro_avg: validation: 0.000000
09/16 02:07:10 PM: edges-pos-ontonotes_mcc: training: 0.874759 validation: 0.916100
09/16 02:07:10 PM: edges-pos-ontonotes_acc: training: 0.800103 validation: 0.868229
09/16 02:07:10 PM: edges-pos-ontonotes_precision: training: 0.907485 validation: 0.942773
09/16 02:07:10 PM: edges-pos-ontonotes_recall: training: 0.848063 validation: 0.893478
09/16 02:07:10 PM: edges-pos-ontonotes_f1: training: 0.876768 validation: 0.917464
09/16 02:07:10 PM: Global learning rate: 0.0001
09/16 02:07:10 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:07:20 PM: Update 29059: task edges-pos-ontonotes, batch 59 (29059): mcc: 0.8810, acc: 0.8112, precision: 0.9139, recall: 0.8539, f1: 0.8829, edges-pos-ontonotes_loss: 0.0145
09/16 02:07:30 PM: Update 29117: task edges-pos-ontonotes, batch 117 (29117): mcc: 0.8818, acc: 0.8118, precision: 0.9150, recall: 0.8543, f1: 0.8836, edges-pos-ontonotes_loss: 0.0144
09/16 02:07:41 PM: Update 29163: task edges-pos-ontonotes, batch 163 (29163): mcc: 0.8817, acc: 0.8116, precision: 0.9150, recall: 0.8543, f1: 0.8836, edges-pos-ontonotes_loss: 0.0142
09/16 02:07:51 PM: Update 29216: task edges-pos-ontonotes, batch 216 (29216): mcc: 0.8810, acc: 0.8109, precision: 0.9146, recall: 0.8533, f1: 0.8829, edges-pos-ontonotes_loss: 0.0141
09/16 02:08:01 PM: Update 29255: task edges-pos-ontonotes, batch 255 (29255): mcc: 0.8808, acc: 0.8105, precision: 0.9142, recall: 0.8533, f1: 0.8827, edges-pos-ontonotes_loss: 0.0141
09/16 02:08:11 PM: Update 29305: task edges-pos-ontonotes, batch 305 (29305): mcc: 0.8807, acc: 0.8107, precision: 0.9137, recall: 0.8535, f1: 0.8826, edges-pos-ontonotes_loss: 0.0141
09/16 02:08:21 PM: Update 29360: task edges-pos-ontonotes, batch 360 (29360): mcc: 0.8804, acc: 0.8103, precision: 0.9136, recall: 0.8531, f1: 0.8823, edges-pos-ontonotes_loss: 0.0141
09/16 02:08:31 PM: Update 29417: task edges-pos-ontonotes, batch 417 (29417): mcc: 0.8800, acc: 0.8096, precision: 0.9135, recall: 0.8523, f1: 0.8818, edges-pos-ontonotes_loss: 0.0143
09/16 02:08:41 PM: Update 29473: task edges-pos-ontonotes, batch 473 (29473): mcc: 0.8805, acc: 0.8105, precision: 0.9139, recall: 0.8530, f1: 0.8824, edges-pos-ontonotes_loss: 0.0142
09/16 02:08:51 PM: Update 29531: task edges-pos-ontonotes, batch 531 (29531): mcc: 0.8808, acc: 0.8109, precision: 0.9142, recall: 0.8533, f1: 0.8827, edges-pos-ontonotes_loss: 0.0142
09/16 02:09:02 PM: Update 29575: task edges-pos-ontonotes, batch 575 (29575): mcc: 0.8804, acc: 0.8104, precision: 0.9137, recall: 0.8529, f1: 0.8823, edges-pos-ontonotes_loss: 0.0141
09/16 02:09:12 PM: Update 29628: task edges-pos-ontonotes, batch 628 (29628): mcc: 0.8806, acc: 0.8107, precision: 0.9138, recall: 0.8533, f1: 0.8825, edges-pos-ontonotes_loss: 0.0140
09/16 02:09:22 PM: Update 29676: task edges-pos-ontonotes, batch 676 (29676): mcc: 0.8810, acc: 0.8111, precision: 0.9141, recall: 0.8537, f1: 0.8828, edges-pos-ontonotes_loss: 0.0139
09/16 02:09:32 PM: Update 29729: task edges-pos-ontonotes, batch 729 (29729): mcc: 0.8811, acc: 0.8113, precision: 0.9141, recall: 0.8540, f1: 0.8830, edges-pos-ontonotes_loss: 0.0138
09/16 02:09:42 PM: Update 29791: task edges-pos-ontonotes, batch 791 (29791): mcc: 0.8815, acc: 0.8119, precision: 0.9143, recall: 0.8545, f1: 0.8834, edges-pos-ontonotes_loss: 0.0136
09/16 02:09:52 PM: Update 29853: task edges-pos-ontonotes, batch 853 (29853): mcc: 0.8819, acc: 0.8125, precision: 0.9147, recall: 0.8549, f1: 0.8838, edges-pos-ontonotes_loss: 0.0135
09/16 02:10:03 PM: Update 29926: task edges-pos-ontonotes, batch 926 (29926): mcc: 0.8828, acc: 0.8136, precision: 0.9154, recall: 0.8559, f1: 0.8847, edges-pos-ontonotes_loss: 0.0133
09/16 02:10:11 PM: ***** Step 30000 / Validation 30 *****
09/16 02:10:11 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:10:11 PM: Validating...
09/16 02:10:13 PM: Evaluate: task edges-pos-ontonotes, batch 7 (157): mcc: 0.9033, acc: 0.8552, precision: 0.9335, recall: 0.8779, f1: 0.9048, edges-pos-ontonotes_loss: 0.0114
09/16 02:10:23 PM: Evaluate: task edges-pos-ontonotes, batch 75 (157): mcc: 0.9104, acc: 0.8571, precision: 0.9487, recall: 0.8770, f1: 0.9115, edges-pos-ontonotes_loss: 0.0109
09/16 02:10:33 PM: Evaluate: task edges-pos-ontonotes, batch 125 (157): mcc: 0.9123, acc: 0.8613, precision: 0.9451, recall: 0.8842, f1: 0.9136, edges-pos-ontonotes_loss: 0.0105
09/16 02:10:40 PM: Updating LR scheduler:
09/16 02:10:40 PM: 	Best result seen so far for macro_avg: 0.917
09/16 02:10:40 PM: 	# validation passes without improvement: 1
09/16 02:10:40 PM: edges-pos-ontonotes_loss: training: 0.013111 validation: 0.010359
09/16 02:10:40 PM: macro_avg: validation: 0.915572
09/16 02:10:40 PM: micro_avg: validation: 0.000000
09/16 02:10:40 PM: edges-pos-ontonotes_mcc: training: 0.884249 validation: 0.914249
09/16 02:10:40 PM: edges-pos-ontonotes_acc: training: 0.815368 validation: 0.865689
09/16 02:10:40 PM: edges-pos-ontonotes_precision: training: 0.916800 validation: 0.943541
09/16 02:10:40 PM: edges-pos-ontonotes_recall: training: 0.857339 validation: 0.889213
09/16 02:10:40 PM: edges-pos-ontonotes_f1: training: 0.886073 validation: 0.915572
09/16 02:10:40 PM: Global learning rate: 0.0001
09/16 02:10:40 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:10:43 PM: Update 30029: task edges-pos-ontonotes, batch 29 (30029): mcc: 0.9100, acc: 0.8472, precision: 0.9429, recall: 0.8818, f1: 0.9113, edges-pos-ontonotes_loss: 0.0104
09/16 02:10:53 PM: Update 30102: task edges-pos-ontonotes, batch 102 (30102): mcc: 0.9109, acc: 0.8500, precision: 0.9409, recall: 0.8854, f1: 0.9123, edges-pos-ontonotes_loss: 0.0103
09/16 02:11:03 PM: Update 30172: task edges-pos-ontonotes, batch 172 (30172): mcc: 0.9115, acc: 0.8520, precision: 0.9403, recall: 0.8870, f1: 0.9129, edges-pos-ontonotes_loss: 0.0103
09/16 02:11:13 PM: Update 30242: task edges-pos-ontonotes, batch 242 (30242): mcc: 0.9095, acc: 0.8490, precision: 0.9394, recall: 0.8841, f1: 0.9109, edges-pos-ontonotes_loss: 0.0106
09/16 02:11:24 PM: Update 30320: task edges-pos-ontonotes, batch 320 (30320): mcc: 0.9088, acc: 0.8480, precision: 0.9399, recall: 0.8823, f1: 0.9102, edges-pos-ontonotes_loss: 0.0106
09/16 02:11:34 PM: Update 30407: task edges-pos-ontonotes, batch 407 (30407): mcc: 0.9086, acc: 0.8479, precision: 0.9396, recall: 0.8822, f1: 0.9100, edges-pos-ontonotes_loss: 0.0107
09/16 02:11:44 PM: Update 30490: task edges-pos-ontonotes, batch 490 (30490): mcc: 0.9086, acc: 0.8479, precision: 0.9396, recall: 0.8823, f1: 0.9100, edges-pos-ontonotes_loss: 0.0107
09/16 02:11:54 PM: Update 30560: task edges-pos-ontonotes, batch 560 (30560): mcc: 0.9049, acc: 0.8425, precision: 0.9369, recall: 0.8777, f1: 0.9064, edges-pos-ontonotes_loss: 0.0112
09/16 02:12:04 PM: Update 30665: task edges-pos-ontonotes, batch 665 (30665): mcc: 0.9020, acc: 0.8379, precision: 0.9349, recall: 0.8739, f1: 0.9034, edges-pos-ontonotes_loss: 0.0117
09/16 02:12:14 PM: Update 30760: task edges-pos-ontonotes, batch 760 (30760): mcc: 0.8994, acc: 0.8342, precision: 0.9333, recall: 0.8707, f1: 0.9009, edges-pos-ontonotes_loss: 0.0119
09/16 02:12:24 PM: Update 30825: task edges-pos-ontonotes, batch 825 (30825): mcc: 0.8970, acc: 0.8307, precision: 0.9311, recall: 0.8682, f1: 0.8986, edges-pos-ontonotes_loss: 0.0121
09/16 02:12:34 PM: Update 30889: task edges-pos-ontonotes, batch 889 (30889): mcc: 0.8929, acc: 0.8249, precision: 0.9271, recall: 0.8641, f1: 0.8945, edges-pos-ontonotes_loss: 0.0123
09/16 02:12:44 PM: Update 30951: task edges-pos-ontonotes, batch 951 (30951): mcc: 0.8901, acc: 0.8209, precision: 0.9243, recall: 0.8615, f1: 0.8918, edges-pos-ontonotes_loss: 0.0125
09/16 02:12:53 PM: ***** Step 31000 / Validation 31 *****
09/16 02:12:53 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:12:53 PM: Validating...
09/16 02:12:54 PM: Evaluate: task edges-pos-ontonotes, batch 6 (157): mcc: 0.9086, acc: 0.8589, precision: 0.9321, recall: 0.8892, f1: 0.9102, edges-pos-ontonotes_loss: 0.0108
09/16 02:13:04 PM: Evaluate: task edges-pos-ontonotes, batch 74 (157): mcc: 0.9123, acc: 0.8615, precision: 0.9451, recall: 0.8840, f1: 0.9135, edges-pos-ontonotes_loss: 0.0107
09/16 02:13:15 PM: Evaluate: task edges-pos-ontonotes, batch 124 (157): mcc: 0.9124, acc: 0.8623, precision: 0.9395, recall: 0.8896, f1: 0.9139, edges-pos-ontonotes_loss: 0.0105
09/16 02:13:22 PM: Updating LR scheduler:
09/16 02:13:22 PM: 	Best result seen so far for macro_avg: 0.917
09/16 02:13:22 PM: 	# validation passes without improvement: 2
09/16 02:13:22 PM: edges-pos-ontonotes_loss: training: 0.012725 validation: 0.010417
09/16 02:13:22 PM: macro_avg: validation: 0.915094
09/16 02:13:22 PM: micro_avg: validation: 0.000000
09/16 02:13:22 PM: edges-pos-ontonotes_mcc: training: 0.887821 validation: 0.913590
09/16 02:13:22 PM: edges-pos-ontonotes_acc: training: 0.817689 validation: 0.864863
09/16 02:13:22 PM: edges-pos-ontonotes_precision: training: 0.922036 validation: 0.936944
09/16 02:13:22 PM: edges-pos-ontonotes_recall: training: 0.859204 validation: 0.894240
09/16 02:13:22 PM: edges-pos-ontonotes_f1: training: 0.889512 validation: 0.915094
09/16 02:13:22 PM: Global learning rate: 0.0001
09/16 02:13:22 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:13:25 PM: Update 31017: task edges-pos-ontonotes, batch 17 (31017): mcc: 0.8716, acc: 0.7941, precision: 0.9084, recall: 0.8412, f1: 0.8735, edges-pos-ontonotes_loss: 0.0150
09/16 02:13:35 PM: Update 31073: task edges-pos-ontonotes, batch 73 (31073): mcc: 0.8705, acc: 0.7914, precision: 0.9052, recall: 0.8421, f1: 0.8725, edges-pos-ontonotes_loss: 0.0152
09/16 02:13:45 PM: Update 31128: task edges-pos-ontonotes, batch 128 (31128): mcc: 0.8696, acc: 0.7915, precision: 0.9057, recall: 0.8400, f1: 0.8716, edges-pos-ontonotes_loss: 0.0153
09/16 02:13:55 PM: Update 31205: task edges-pos-ontonotes, batch 205 (31205): mcc: 0.8690, acc: 0.7901, precision: 0.9079, recall: 0.8367, f1: 0.8709, edges-pos-ontonotes_loss: 0.0151
09/16 02:14:05 PM: Update 31276: task edges-pos-ontonotes, batch 276 (31276): mcc: 0.8697, acc: 0.7910, precision: 0.9098, recall: 0.8364, f1: 0.8715, edges-pos-ontonotes_loss: 0.0149
09/16 02:14:15 PM: Update 31341: task edges-pos-ontonotes, batch 341 (31341): mcc: 0.8699, acc: 0.7914, precision: 0.9104, recall: 0.8362, f1: 0.8717, edges-pos-ontonotes_loss: 0.0147
09/16 02:14:25 PM: Update 31408: task edges-pos-ontonotes, batch 408 (31408): mcc: 0.8707, acc: 0.7924, precision: 0.9119, recall: 0.8363, f1: 0.8725, edges-pos-ontonotes_loss: 0.0145
09/16 02:14:43 PM: Update 31454: task edges-pos-ontonotes, batch 454 (31454): mcc: 0.8711, acc: 0.7929, precision: 0.9122, recall: 0.8366, f1: 0.8728, edges-pos-ontonotes_loss: 0.0145
09/16 02:14:53 PM: Update 31504: task edges-pos-ontonotes, batch 504 (31504): mcc: 0.8718, acc: 0.7938, precision: 0.9118, recall: 0.8385, f1: 0.8736, edges-pos-ontonotes_loss: 0.0144
09/16 02:15:03 PM: Update 31562: task edges-pos-ontonotes, batch 562 (31562): mcc: 0.8724, acc: 0.7947, precision: 0.9119, recall: 0.8396, f1: 0.8742, edges-pos-ontonotes_loss: 0.0143
09/16 02:15:13 PM: Update 31617: task edges-pos-ontonotes, batch 617 (31617): mcc: 0.8730, acc: 0.7955, precision: 0.9117, recall: 0.8408, f1: 0.8748, edges-pos-ontonotes_loss: 0.0143
09/16 02:15:23 PM: Update 31691: task edges-pos-ontonotes, batch 691 (31691): mcc: 0.8736, acc: 0.7962, precision: 0.9119, recall: 0.8418, f1: 0.8754, edges-pos-ontonotes_loss: 0.0142
09/16 02:15:34 PM: Update 31760: task edges-pos-ontonotes, batch 760 (31760): mcc: 0.8742, acc: 0.7970, precision: 0.9119, recall: 0.8428, f1: 0.8760, edges-pos-ontonotes_loss: 0.0141
09/16 02:15:44 PM: Update 31807: task edges-pos-ontonotes, batch 807 (31807): mcc: 0.8737, acc: 0.7966, precision: 0.9111, recall: 0.8428, f1: 0.8756, edges-pos-ontonotes_loss: 0.0142
09/16 02:15:54 PM: Update 31862: task edges-pos-ontonotes, batch 862 (31862): mcc: 0.8735, acc: 0.7964, precision: 0.9103, recall: 0.8431, f1: 0.8754, edges-pos-ontonotes_loss: 0.0142
09/16 02:16:04 PM: Update 31917: task edges-pos-ontonotes, batch 917 (31917): mcc: 0.8736, acc: 0.7967, precision: 0.9098, recall: 0.8436, f1: 0.8755, edges-pos-ontonotes_loss: 0.0143
09/16 02:16:14 PM: Update 31972: task edges-pos-ontonotes, batch 972 (31972): mcc: 0.8735, acc: 0.7966, precision: 0.9093, recall: 0.8439, f1: 0.8754, edges-pos-ontonotes_loss: 0.0143
09/16 02:16:20 PM: ***** Step 32000 / Validation 32 *****
09/16 02:16:20 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:16:20 PM: Validating...
09/16 02:16:24 PM: Evaluate: task edges-pos-ontonotes, batch 31 (157): mcc: 0.9076, acc: 0.8536, precision: 0.9478, recall: 0.8726, f1: 0.9087, edges-pos-ontonotes_loss: 0.0109
09/16 02:16:34 PM: Evaluate: task edges-pos-ontonotes, batch 95 (157): mcc: 0.9163, acc: 0.8670, precision: 0.9496, recall: 0.8874, f1: 0.9174, edges-pos-ontonotes_loss: 0.0102
09/16 02:16:45 PM: Evaluate: task edges-pos-ontonotes, batch 141 (157): mcc: 0.9162, acc: 0.8677, precision: 0.9448, recall: 0.8917, f1: 0.9175, edges-pos-ontonotes_loss: 0.0101
09/16 02:16:48 PM: Best result seen so far for edges-pos-ontonotes.
09/16 02:16:48 PM: Best result seen so far for macro.
09/16 02:16:48 PM: Updating LR scheduler:
09/16 02:16:48 PM: 	Best result seen so far for macro_avg: 0.918
09/16 02:16:48 PM: 	# validation passes without improvement: 0
09/16 02:16:48 PM: edges-pos-ontonotes_loss: training: 0.014307 validation: 0.010070
09/16 02:16:48 PM: macro_avg: validation: 0.917905
09/16 02:16:48 PM: micro_avg: validation: 0.000000
09/16 02:16:48 PM: edges-pos-ontonotes_mcc: training: 0.873412 validation: 0.916575
09/16 02:16:48 PM: edges-pos-ontonotes_acc: training: 0.796647 validation: 0.869139
09/16 02:16:48 PM: edges-pos-ontonotes_precision: training: 0.909126 validation: 0.944072
09/16 02:16:48 PM: edges-pos-ontonotes_recall: training: 0.843967 validation: 0.893150
09/16 02:16:48 PM: edges-pos-ontonotes_f1: training: 0.875336 validation: 0.917905
09/16 02:16:48 PM: Global learning rate: 0.0001
09/16 02:16:48 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:16:55 PM: Update 32040: task edges-pos-ontonotes, batch 40 (32040): mcc: 0.8743, acc: 0.7999, precision: 0.9069, recall: 0.8477, f1: 0.8763, edges-pos-ontonotes_loss: 0.0145
09/16 02:17:06 PM: Update 32080: task edges-pos-ontonotes, batch 80 (32080): mcc: 0.8725, acc: 0.7979, precision: 0.9048, recall: 0.8462, f1: 0.8746, edges-pos-ontonotes_loss: 0.0150
09/16 02:17:16 PM: Update 32119: task edges-pos-ontonotes, batch 119 (32119): mcc: 0.8715, acc: 0.7960, precision: 0.9041, recall: 0.8450, f1: 0.8736, edges-pos-ontonotes_loss: 0.0149
09/16 02:17:26 PM: Update 32166: task edges-pos-ontonotes, batch 166 (32166): mcc: 0.8732, acc: 0.7983, precision: 0.9056, recall: 0.8469, f1: 0.8753, edges-pos-ontonotes_loss: 0.0147
09/16 02:17:36 PM: Update 32204: task edges-pos-ontonotes, batch 204 (32204): mcc: 0.8740, acc: 0.7997, precision: 0.9065, recall: 0.8476, f1: 0.8761, edges-pos-ontonotes_loss: 0.0146
09/16 02:17:47 PM: Update 32242: task edges-pos-ontonotes, batch 242 (32242): mcc: 0.8743, acc: 0.8002, precision: 0.9065, recall: 0.8480, f1: 0.8763, edges-pos-ontonotes_loss: 0.0147
09/16 02:17:57 PM: Update 32285: task edges-pos-ontonotes, batch 285 (32285): mcc: 0.8747, acc: 0.8012, precision: 0.9071, recall: 0.8484, f1: 0.8768, edges-pos-ontonotes_loss: 0.0146
09/16 02:18:07 PM: Update 32327: task edges-pos-ontonotes, batch 327 (32327): mcc: 0.8757, acc: 0.8026, precision: 0.9079, recall: 0.8495, f1: 0.8777, edges-pos-ontonotes_loss: 0.0145
09/16 02:18:17 PM: Update 32366: task edges-pos-ontonotes, batch 366 (32366): mcc: 0.8762, acc: 0.8032, precision: 0.9084, recall: 0.8499, f1: 0.8782, edges-pos-ontonotes_loss: 0.0144
09/16 02:18:27 PM: Update 32398: task edges-pos-ontonotes, batch 398 (32398): mcc: 0.8765, acc: 0.8036, precision: 0.9090, recall: 0.8499, f1: 0.8784, edges-pos-ontonotes_loss: 0.0144
09/16 02:18:37 PM: Update 32445: task edges-pos-ontonotes, batch 445 (32445): mcc: 0.8767, acc: 0.8039, precision: 0.9092, recall: 0.8501, f1: 0.8787, edges-pos-ontonotes_loss: 0.0144
09/16 02:18:47 PM: Update 32488: task edges-pos-ontonotes, batch 488 (32488): mcc: 0.8769, acc: 0.8044, precision: 0.9094, recall: 0.8504, f1: 0.8789, edges-pos-ontonotes_loss: 0.0144
09/16 02:18:57 PM: Update 32529: task edges-pos-ontonotes, batch 529 (32529): mcc: 0.8772, acc: 0.8049, precision: 0.9096, recall: 0.8508, f1: 0.8792, edges-pos-ontonotes_loss: 0.0144
09/16 02:19:08 PM: Update 32576: task edges-pos-ontonotes, batch 576 (32576): mcc: 0.8775, acc: 0.8054, precision: 0.9100, recall: 0.8509, f1: 0.8795, edges-pos-ontonotes_loss: 0.0143
09/16 02:19:18 PM: Update 32627: task edges-pos-ontonotes, batch 627 (32627): mcc: 0.8779, acc: 0.8060, precision: 0.9103, recall: 0.8514, f1: 0.8799, edges-pos-ontonotes_loss: 0.0143
09/16 02:19:28 PM: Update 32680: task edges-pos-ontonotes, batch 680 (32680): mcc: 0.8783, acc: 0.8065, precision: 0.9109, recall: 0.8516, f1: 0.8802, edges-pos-ontonotes_loss: 0.0142
09/16 02:19:38 PM: Update 32713: task edges-pos-ontonotes, batch 713 (32713): mcc: 0.8783, acc: 0.8066, precision: 0.9109, recall: 0.8517, f1: 0.8803, edges-pos-ontonotes_loss: 0.0142
09/16 02:19:48 PM: Update 32772: task edges-pos-ontonotes, batch 772 (32772): mcc: 0.8786, acc: 0.8071, precision: 0.9111, recall: 0.8520, f1: 0.8805, edges-pos-ontonotes_loss: 0.0142
09/16 02:19:58 PM: Update 32831: task edges-pos-ontonotes, batch 831 (32831): mcc: 0.8789, acc: 0.8076, precision: 0.9115, recall: 0.8522, f1: 0.8809, edges-pos-ontonotes_loss: 0.0142
09/16 02:20:08 PM: Update 32890: task edges-pos-ontonotes, batch 890 (32890): mcc: 0.8789, acc: 0.8077, precision: 0.9115, recall: 0.8522, f1: 0.8809, edges-pos-ontonotes_loss: 0.0142
09/16 02:20:18 PM: Update 32941: task edges-pos-ontonotes, batch 941 (32941): mcc: 0.8790, acc: 0.8078, precision: 0.9115, recall: 0.8524, f1: 0.8810, edges-pos-ontonotes_loss: 0.0142
09/16 02:20:28 PM: Update 32993: task edges-pos-ontonotes, batch 993 (32993): mcc: 0.8791, acc: 0.8080, precision: 0.9116, recall: 0.8524, f1: 0.8810, edges-pos-ontonotes_loss: 0.0142
09/16 02:20:29 PM: ***** Step 33000 / Validation 33 *****
09/16 02:20:29 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:20:29 PM: Validating...
09/16 02:20:38 PM: Evaluate: task edges-pos-ontonotes, batch 62 (157): mcc: 0.9106, acc: 0.8568, precision: 0.9499, recall: 0.8763, f1: 0.9116, edges-pos-ontonotes_loss: 0.0111
09/16 02:20:48 PM: Evaluate: task edges-pos-ontonotes, batch 115 (157): mcc: 0.9147, acc: 0.8649, precision: 0.9471, recall: 0.8867, f1: 0.9159, edges-pos-ontonotes_loss: 0.0104
09/16 02:20:58 PM: Updating LR scheduler:
09/16 02:20:58 PM: 	Best result seen so far for macro_avg: 0.918
09/16 02:20:58 PM: 	# validation passes without improvement: 1
09/16 02:20:58 PM: edges-pos-ontonotes_loss: training: 0.014190 validation: 0.010176
09/16 02:20:58 PM: macro_avg: validation: 0.917855
09/16 02:20:58 PM: micro_avg: validation: 0.000000
09/16 02:20:58 PM: edges-pos-ontonotes_mcc: training: 0.879149 validation: 0.916551
09/16 02:20:58 PM: edges-pos-ontonotes_acc: training: 0.808031 validation: 0.868800
09/16 02:20:58 PM: edges-pos-ontonotes_precision: training: 0.911662 validation: 0.944961
09/16 02:20:58 PM: edges-pos-ontonotes_recall: training: 0.852478 validation: 0.892261
09/16 02:20:58 PM: edges-pos-ontonotes_f1: training: 0.881077 validation: 0.917855
09/16 02:20:58 PM: Global learning rate: 0.0001
09/16 02:20:58 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:20:59 PM: Update 33006: task edges-pos-ontonotes, batch 6 (33006): mcc: 0.8814, acc: 0.8129, precision: 0.9196, recall: 0.8493, f1: 0.8830, edges-pos-ontonotes_loss: 0.0144
09/16 02:21:11 PM: Update 33019: task edges-pos-ontonotes, batch 19 (33019): mcc: 0.8726, acc: 0.8005, precision: 0.9086, recall: 0.8428, f1: 0.8745, edges-pos-ontonotes_loss: 0.0144
09/16 02:21:21 PM: Update 33079: task edges-pos-ontonotes, batch 79 (33079): mcc: 0.8789, acc: 0.8083, precision: 0.9119, recall: 0.8518, f1: 0.8808, edges-pos-ontonotes_loss: 0.0129
09/16 02:21:32 PM: Update 33137: task edges-pos-ontonotes, batch 137 (33137): mcc: 0.8813, acc: 0.8113, precision: 0.9140, recall: 0.8543, f1: 0.8832, edges-pos-ontonotes_loss: 0.0126
09/16 02:21:42 PM: Update 33188: task edges-pos-ontonotes, batch 188 (33188): mcc: 0.8828, acc: 0.8129, precision: 0.9151, recall: 0.8562, f1: 0.8846, edges-pos-ontonotes_loss: 0.0124
09/16 02:21:52 PM: Update 33239: task edges-pos-ontonotes, batch 239 (33239): mcc: 0.8840, acc: 0.8150, precision: 0.9161, recall: 0.8576, f1: 0.8859, edges-pos-ontonotes_loss: 0.0124
09/16 02:22:02 PM: Update 33293: task edges-pos-ontonotes, batch 293 (33293): mcc: 0.8847, acc: 0.8161, precision: 0.9166, recall: 0.8584, f1: 0.8865, edges-pos-ontonotes_loss: 0.0122
09/16 02:22:12 PM: Update 33341: task edges-pos-ontonotes, batch 341 (33341): mcc: 0.8857, acc: 0.8175, precision: 0.9176, recall: 0.8594, f1: 0.8875, edges-pos-ontonotes_loss: 0.0121
09/16 02:22:23 PM: Update 33421: task edges-pos-ontonotes, batch 421 (33421): mcc: 0.8890, acc: 0.8218, precision: 0.9204, recall: 0.8629, f1: 0.8908, edges-pos-ontonotes_loss: 0.0119
09/16 02:22:33 PM: Update 33507: task edges-pos-ontonotes, batch 507 (33507): mcc: 0.8923, acc: 0.8262, precision: 0.9233, recall: 0.8666, f1: 0.8940, edges-pos-ontonotes_loss: 0.0116
09/16 02:22:43 PM: Update 33595: task edges-pos-ontonotes, batch 595 (33595): mcc: 0.8947, acc: 0.8293, precision: 0.9254, recall: 0.8691, f1: 0.8964, edges-pos-ontonotes_loss: 0.0114
09/16 02:22:53 PM: Update 33667: task edges-pos-ontonotes, batch 667 (33667): mcc: 0.8959, acc: 0.8309, precision: 0.9266, recall: 0.8701, f1: 0.8975, edges-pos-ontonotes_loss: 0.0113
09/16 02:23:03 PM: Update 33772: task edges-pos-ontonotes, batch 772 (33772): mcc: 0.8967, acc: 0.8320, precision: 0.9278, recall: 0.8706, f1: 0.8983, edges-pos-ontonotes_loss: 0.0113
09/16 02:23:13 PM: Update 33876: task edges-pos-ontonotes, batch 876 (33876): mcc: 0.8975, acc: 0.8331, precision: 0.9286, recall: 0.8714, f1: 0.8991, edges-pos-ontonotes_loss: 0.0112
09/16 02:23:23 PM: Update 33958: task edges-pos-ontonotes, batch 958 (33958): mcc: 0.8983, acc: 0.8342, precision: 0.9293, recall: 0.8723, f1: 0.8999, edges-pos-ontonotes_loss: 0.0112
09/16 02:23:27 PM: ***** Step 34000 / Validation 34 *****
09/16 02:23:27 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:23:27 PM: Validating...
09/16 02:23:33 PM: Evaluate: task edges-pos-ontonotes, batch 46 (157): mcc: 0.9068, acc: 0.8537, precision: 0.9417, recall: 0.8768, f1: 0.9081, edges-pos-ontonotes_loss: 0.0112
09/16 02:23:43 PM: Evaluate: task edges-pos-ontonotes, batch 105 (157): mcc: 0.9134, acc: 0.8658, precision: 0.9384, recall: 0.8925, f1: 0.9149, edges-pos-ontonotes_loss: 0.0105
09/16 02:23:53 PM: Evaluate: task edges-pos-ontonotes, batch 150 (157): mcc: 0.9130, acc: 0.8658, precision: 0.9318, recall: 0.8980, f1: 0.9146, edges-pos-ontonotes_loss: 0.0105
09/16 02:23:55 PM: Updating LR scheduler:
09/16 02:23:55 PM: 	Best result seen so far for macro_avg: 0.918
09/16 02:23:55 PM: 	# validation passes without improvement: 2
09/16 02:23:55 PM: edges-pos-ontonotes_loss: training: 0.011338 validation: 0.010477
09/16 02:23:55 PM: macro_avg: validation: 0.915113
09/16 02:23:55 PM: micro_avg: validation: 0.000000
09/16 02:23:55 PM: edges-pos-ontonotes_mcc: training: 0.897666 validation: 0.913499
09/16 02:23:55 PM: edges-pos-ontonotes_acc: training: 0.833159 validation: 0.866800
09/16 02:23:55 PM: edges-pos-ontonotes_precision: training: 0.928923 validation: 0.932097
09/16 02:23:55 PM: edges-pos-ontonotes_recall: training: 0.871438 validation: 0.898738
09/16 02:23:55 PM: edges-pos-ontonotes_f1: training: 0.899263 validation: 0.915113
09/16 02:23:55 PM: Global learning rate: 0.0001
09/16 02:23:55 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:24:03 PM: Update 34114: task edges-pos-ontonotes, batch 114 (34114): mcc: 0.8768, acc: 0.8012, precision: 0.9197, recall: 0.8406, f1: 0.8784, edges-pos-ontonotes_loss: 0.0135
09/16 02:24:13 PM: Update 34219: task edges-pos-ontonotes, batch 219 (34219): mcc: 0.8775, acc: 0.8020, precision: 0.9192, recall: 0.8423, f1: 0.8791, edges-pos-ontonotes_loss: 0.0136
09/16 02:24:24 PM: Update 34280: task edges-pos-ontonotes, batch 280 (34280): mcc: 0.8753, acc: 0.7995, precision: 0.9144, recall: 0.8426, f1: 0.8771, edges-pos-ontonotes_loss: 0.0138
09/16 02:24:34 PM: Update 34328: task edges-pos-ontonotes, batch 328 (34328): mcc: 0.8730, acc: 0.7961, precision: 0.9114, recall: 0.8412, f1: 0.8749, edges-pos-ontonotes_loss: 0.0140
09/16 02:24:44 PM: Update 34380: task edges-pos-ontonotes, batch 380 (34380): mcc: 0.8715, acc: 0.7940, precision: 0.9088, recall: 0.8406, f1: 0.8734, edges-pos-ontonotes_loss: 0.0143
09/16 02:24:54 PM: Update 34420: task edges-pos-ontonotes, batch 420 (34420): mcc: 0.8710, acc: 0.7934, precision: 0.9076, recall: 0.8407, f1: 0.8729, edges-pos-ontonotes_loss: 0.0144
09/16 02:25:04 PM: Update 34465: task edges-pos-ontonotes, batch 465 (34465): mcc: 0.8709, acc: 0.7933, precision: 0.9074, recall: 0.8408, f1: 0.8728, edges-pos-ontonotes_loss: 0.0145
09/16 02:25:15 PM: Update 34505: task edges-pos-ontonotes, batch 505 (34505): mcc: 0.8710, acc: 0.7935, precision: 0.9070, recall: 0.8414, f1: 0.8730, edges-pos-ontonotes_loss: 0.0145
09/16 02:25:25 PM: Update 34552: task edges-pos-ontonotes, batch 552 (34552): mcc: 0.8706, acc: 0.7928, precision: 0.9065, recall: 0.8410, f1: 0.8725, edges-pos-ontonotes_loss: 0.0147
09/16 02:25:35 PM: Update 34597: task edges-pos-ontonotes, batch 597 (34597): mcc: 0.8702, acc: 0.7923, precision: 0.9062, recall: 0.8406, f1: 0.8722, edges-pos-ontonotes_loss: 0.0147
09/16 02:25:45 PM: Update 34641: task edges-pos-ontonotes, batch 641 (34641): mcc: 0.8702, acc: 0.7922, precision: 0.9069, recall: 0.8400, f1: 0.8721, edges-pos-ontonotes_loss: 0.0147
09/16 02:25:56 PM: Update 34710: task edges-pos-ontonotes, batch 710 (34710): mcc: 0.8700, acc: 0.7917, precision: 0.9076, recall: 0.8389, f1: 0.8719, edges-pos-ontonotes_loss: 0.0147
09/16 02:26:06 PM: Update 34788: task edges-pos-ontonotes, batch 788 (34788): mcc: 0.8704, acc: 0.7921, precision: 0.9086, recall: 0.8387, f1: 0.8722, edges-pos-ontonotes_loss: 0.0146
09/16 02:26:16 PM: Update 34880: task edges-pos-ontonotes, batch 880 (34880): mcc: 0.8709, acc: 0.7928, precision: 0.9095, recall: 0.8388, f1: 0.8727, edges-pos-ontonotes_loss: 0.0145
09/16 02:26:26 PM: Update 34936: task edges-pos-ontonotes, batch 936 (34936): mcc: 0.8713, acc: 0.7934, precision: 0.9096, recall: 0.8395, f1: 0.8732, edges-pos-ontonotes_loss: 0.0145
09/16 02:26:36 PM: Update 34998: task edges-pos-ontonotes, batch 998 (34998): mcc: 0.8720, acc: 0.7944, precision: 0.9096, recall: 0.8407, f1: 0.8738, edges-pos-ontonotes_loss: 0.0144
09/16 02:26:37 PM: ***** Step 35000 / Validation 35 *****
09/16 02:26:37 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:26:37 PM: Validating...
09/16 02:26:46 PM: Evaluate: task edges-pos-ontonotes, batch 67 (157): mcc: 0.9144, acc: 0.8638, precision: 0.9481, recall: 0.8852, f1: 0.9156, edges-pos-ontonotes_loss: 0.0104
09/16 02:26:56 PM: Evaluate: task edges-pos-ontonotes, batch 119 (157): mcc: 0.9155, acc: 0.8664, precision: 0.9432, recall: 0.8920, f1: 0.9169, edges-pos-ontonotes_loss: 0.0101
09/16 02:27:05 PM: Updating LR scheduler:
09/16 02:27:05 PM: 	Best result seen so far for macro_avg: 0.918
09/16 02:27:05 PM: 	# validation passes without improvement: 3
09/16 02:27:05 PM: edges-pos-ontonotes_loss: training: 0.014414 validation: 0.010100
09/16 02:27:05 PM: macro_avg: validation: 0.917072
09/16 02:27:05 PM: micro_avg: validation: 0.000000
09/16 02:27:05 PM: edges-pos-ontonotes_mcc: training: 0.871967 validation: 0.915636
09/16 02:27:05 PM: edges-pos-ontonotes_acc: training: 0.794391 validation: 0.867403
09/16 02:27:05 PM: edges-pos-ontonotes_precision: training: 0.909632 validation: 0.940048
09/16 02:27:05 PM: edges-pos-ontonotes_recall: training: 0.840759 validation: 0.895192
09/16 02:27:05 PM: edges-pos-ontonotes_f1: training: 0.873840 validation: 0.917072
09/16 02:27:05 PM: Global learning rate: 0.0001
09/16 02:27:05 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:27:06 PM: Update 35013: task edges-pos-ontonotes, batch 13 (35013): mcc: 0.8683, acc: 0.7899, precision: 0.9047, recall: 0.8383, f1: 0.8703, edges-pos-ontonotes_loss: 0.0150
09/16 02:27:17 PM: Update 35083: task edges-pos-ontonotes, batch 83 (35083): mcc: 0.8754, acc: 0.7990, precision: 0.9100, recall: 0.8469, f1: 0.8773, edges-pos-ontonotes_loss: 0.0140
09/16 02:27:27 PM: Update 35144: task edges-pos-ontonotes, batch 144 (35144): mcc: 0.8768, acc: 0.8012, precision: 0.9118, recall: 0.8480, f1: 0.8787, edges-pos-ontonotes_loss: 0.0138
09/16 02:27:37 PM: Update 35213: task edges-pos-ontonotes, batch 213 (35213): mcc: 0.8789, acc: 0.8042, precision: 0.9130, recall: 0.8508, f1: 0.8808, edges-pos-ontonotes_loss: 0.0135
09/16 02:27:49 PM: Update 35227: task edges-pos-ontonotes, batch 227 (35227): mcc: 0.8782, acc: 0.8030, precision: 0.9126, recall: 0.8499, f1: 0.8801, edges-pos-ontonotes_loss: 0.0136
09/16 02:27:59 PM: Update 35280: task edges-pos-ontonotes, batch 280 (35280): mcc: 0.8764, acc: 0.8011, precision: 0.9097, recall: 0.8491, f1: 0.8784, edges-pos-ontonotes_loss: 0.0139
09/16 02:28:09 PM: Update 35336: task edges-pos-ontonotes, batch 336 (35336): mcc: 0.8756, acc: 0.8000, precision: 0.9087, recall: 0.8485, f1: 0.8776, edges-pos-ontonotes_loss: 0.0141
09/16 02:28:19 PM: Update 35385: task edges-pos-ontonotes, batch 385 (35385): mcc: 0.8752, acc: 0.7996, precision: 0.9081, recall: 0.8483, f1: 0.8772, edges-pos-ontonotes_loss: 0.0142
09/16 02:28:30 PM: Update 35428: task edges-pos-ontonotes, batch 428 (35428): mcc: 0.8751, acc: 0.7995, precision: 0.9079, recall: 0.8483, f1: 0.8771, edges-pos-ontonotes_loss: 0.0142
09/16 02:28:40 PM: Update 35481: task edges-pos-ontonotes, batch 481 (35481): mcc: 0.8750, acc: 0.7994, precision: 0.9077, recall: 0.8483, f1: 0.8770, edges-pos-ontonotes_loss: 0.0142
09/16 02:28:50 PM: Update 35535: task edges-pos-ontonotes, batch 535 (35535): mcc: 0.8750, acc: 0.7995, precision: 0.9074, recall: 0.8486, f1: 0.8770, edges-pos-ontonotes_loss: 0.0143
09/16 02:29:00 PM: Update 35571: task edges-pos-ontonotes, batch 571 (35571): mcc: 0.8749, acc: 0.7995, precision: 0.9071, recall: 0.8486, f1: 0.8769, edges-pos-ontonotes_loss: 0.0143
09/16 02:29:10 PM: Update 35624: task edges-pos-ontonotes, batch 624 (35624): mcc: 0.8750, acc: 0.7997, precision: 0.9072, recall: 0.8488, f1: 0.8770, edges-pos-ontonotes_loss: 0.0143
09/16 02:29:21 PM: Update 35681: task edges-pos-ontonotes, batch 681 (35681): mcc: 0.8757, acc: 0.8007, precision: 0.9077, recall: 0.8496, f1: 0.8777, edges-pos-ontonotes_loss: 0.0143
09/16 02:29:31 PM: Update 35731: task edges-pos-ontonotes, batch 731 (35731): mcc: 0.8757, acc: 0.8009, precision: 0.9077, recall: 0.8496, f1: 0.8777, edges-pos-ontonotes_loss: 0.0142
09/16 02:29:41 PM: Update 35787: task edges-pos-ontonotes, batch 787 (35787): mcc: 0.8761, acc: 0.8017, precision: 0.9081, recall: 0.8500, f1: 0.8781, edges-pos-ontonotes_loss: 0.0142
09/16 02:29:51 PM: Update 35843: task edges-pos-ontonotes, batch 843 (35843): mcc: 0.8764, acc: 0.8023, precision: 0.9083, recall: 0.8503, f1: 0.8784, edges-pos-ontonotes_loss: 0.0142
09/16 02:30:01 PM: Update 35886: task edges-pos-ontonotes, batch 886 (35886): mcc: 0.8765, acc: 0.8025, precision: 0.9085, recall: 0.8504, f1: 0.8785, edges-pos-ontonotes_loss: 0.0142
09/16 02:30:11 PM: Update 35940: task edges-pos-ontonotes, batch 940 (35940): mcc: 0.8766, acc: 0.8028, precision: 0.9087, recall: 0.8505, f1: 0.8786, edges-pos-ontonotes_loss: 0.0142
09/16 02:30:21 PM: Update 35989: task edges-pos-ontonotes, batch 989 (35989): mcc: 0.8768, acc: 0.8032, precision: 0.9089, recall: 0.8506, f1: 0.8788, edges-pos-ontonotes_loss: 0.0142
09/16 02:30:24 PM: ***** Step 36000 / Validation 36 *****
09/16 02:30:24 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:30:24 PM: Validating...
09/16 02:30:31 PM: Evaluate: task edges-pos-ontonotes, batch 38 (157): mcc: 0.9085, acc: 0.8547, precision: 0.9475, recall: 0.8746, f1: 0.9096, edges-pos-ontonotes_loss: 0.0110
09/16 02:30:41 PM: Evaluate: task edges-pos-ontonotes, batch 91 (157): mcc: 0.9168, acc: 0.8670, precision: 0.9495, recall: 0.8884, f1: 0.9179, edges-pos-ontonotes_loss: 0.0103
09/16 02:30:51 PM: Evaluate: task edges-pos-ontonotes, batch 128 (157): mcc: 0.9165, acc: 0.8681, precision: 0.9450, recall: 0.8922, f1: 0.9178, edges-pos-ontonotes_loss: 0.0102
09/16 02:30:59 PM: Best result seen so far for edges-pos-ontonotes.
09/16 02:30:59 PM: Best result seen so far for macro.
09/16 02:30:59 PM: Updating LR scheduler:
09/16 02:30:59 PM: 	Best result seen so far for macro_avg: 0.919
09/16 02:30:59 PM: 	# validation passes without improvement: 0
09/16 02:30:59 PM: edges-pos-ontonotes_loss: training: 0.014196 validation: 0.010028
09/16 02:30:59 PM: macro_avg: validation: 0.919229
09/16 02:30:59 PM: micro_avg: validation: 0.000000
09/16 02:30:59 PM: edges-pos-ontonotes_mcc: training: 0.876908 validation: 0.917879
09/16 02:30:59 PM: edges-pos-ontonotes_acc: training: 0.803338 validation: 0.871509
09/16 02:30:59 PM: edges-pos-ontonotes_precision: training: 0.908963 validation: 0.943722
09/16 02:30:59 PM: edges-pos-ontonotes_recall: training: 0.850759 validation: 0.895976
09/16 02:30:59 PM: edges-pos-ontonotes_f1: training: 0.878898 validation: 0.919229
09/16 02:30:59 PM: Global learning rate: 0.0001
09/16 02:30:59 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:31:02 PM: Update 36012: task edges-pos-ontonotes, batch 12 (36012): mcc: 0.8845, acc: 0.8156, precision: 0.9147, recall: 0.8599, f1: 0.8864, edges-pos-ontonotes_loss: 0.0139
09/16 02:31:12 PM: Update 36059: task edges-pos-ontonotes, batch 59 (36059): mcc: 0.8846, acc: 0.8152, precision: 0.9174, recall: 0.8574, f1: 0.8864, edges-pos-ontonotes_loss: 0.0136
09/16 02:31:22 PM: Update 36102: task edges-pos-ontonotes, batch 102 (36102): mcc: 0.8828, acc: 0.8134, precision: 0.9151, recall: 0.8562, f1: 0.8846, edges-pos-ontonotes_loss: 0.0139
09/16 02:31:32 PM: Update 36138: task edges-pos-ontonotes, batch 138 (36138): mcc: 0.8831, acc: 0.8137, precision: 0.9147, recall: 0.8570, f1: 0.8849, edges-pos-ontonotes_loss: 0.0137
09/16 02:31:42 PM: Update 36168: task edges-pos-ontonotes, batch 168 (36168): mcc: 0.8825, acc: 0.8127, precision: 0.9146, recall: 0.8561, f1: 0.8844, edges-pos-ontonotes_loss: 0.0137
09/16 02:31:52 PM: Update 36222: task edges-pos-ontonotes, batch 222 (36222): mcc: 0.8823, acc: 0.8127, precision: 0.9149, recall: 0.8553, f1: 0.8841, edges-pos-ontonotes_loss: 0.0138
09/16 02:32:02 PM: Update 36270: task edges-pos-ontonotes, batch 270 (36270): mcc: 0.8819, acc: 0.8124, precision: 0.9145, recall: 0.8550, f1: 0.8838, edges-pos-ontonotes_loss: 0.0140
09/16 02:32:13 PM: Update 36321: task edges-pos-ontonotes, batch 321 (36321): mcc: 0.8820, acc: 0.8124, precision: 0.9145, recall: 0.8551, f1: 0.8838, edges-pos-ontonotes_loss: 0.0140
09/16 02:32:23 PM: Update 36373: task edges-pos-ontonotes, batch 373 (36373): mcc: 0.8819, acc: 0.8123, precision: 0.9143, recall: 0.8552, f1: 0.8838, edges-pos-ontonotes_loss: 0.0140
09/16 02:32:33 PM: Update 36429: task edges-pos-ontonotes, batch 429 (36429): mcc: 0.8820, acc: 0.8126, precision: 0.9144, recall: 0.8554, f1: 0.8839, edges-pos-ontonotes_loss: 0.0140
09/16 02:32:43 PM: Update 36474: task edges-pos-ontonotes, batch 474 (36474): mcc: 0.8821, acc: 0.8126, precision: 0.9145, recall: 0.8554, f1: 0.8840, edges-pos-ontonotes_loss: 0.0140
09/16 02:32:53 PM: Update 36518: task edges-pos-ontonotes, batch 518 (36518): mcc: 0.8815, acc: 0.8119, precision: 0.9139, recall: 0.8549, f1: 0.8834, edges-pos-ontonotes_loss: 0.0139
09/16 02:33:03 PM: Update 36571: task edges-pos-ontonotes, batch 571 (36571): mcc: 0.8819, acc: 0.8124, precision: 0.9142, recall: 0.8553, f1: 0.8838, edges-pos-ontonotes_loss: 0.0138
09/16 02:33:14 PM: Update 36608: task edges-pos-ontonotes, batch 608 (36608): mcc: 0.8821, acc: 0.8127, precision: 0.9145, recall: 0.8555, f1: 0.8840, edges-pos-ontonotes_loss: 0.0136
09/16 02:33:24 PM: Update 36648: task edges-pos-ontonotes, batch 648 (36648): mcc: 0.8823, acc: 0.8130, precision: 0.9145, recall: 0.8559, f1: 0.8842, edges-pos-ontonotes_loss: 0.0135
09/16 02:33:34 PM: Update 36712: task edges-pos-ontonotes, batch 712 (36712): mcc: 0.8833, acc: 0.8143, precision: 0.9152, recall: 0.8569, f1: 0.8851, edges-pos-ontonotes_loss: 0.0133
09/16 02:33:44 PM: Update 36770: task edges-pos-ontonotes, batch 770 (36770): mcc: 0.8836, acc: 0.8147, precision: 0.9155, recall: 0.8573, f1: 0.8854, edges-pos-ontonotes_loss: 0.0132
09/16 02:33:54 PM: Update 36836: task edges-pos-ontonotes, batch 836 (36836): mcc: 0.8844, acc: 0.8159, precision: 0.9162, recall: 0.8582, f1: 0.8863, edges-pos-ontonotes_loss: 0.0131
09/16 02:34:04 PM: Update 36926: task edges-pos-ontonotes, batch 926 (36926): mcc: 0.8861, acc: 0.8181, precision: 0.9177, recall: 0.8600, f1: 0.8879, edges-pos-ontonotes_loss: 0.0128
09/16 02:34:13 PM: ***** Step 37000 / Validation 37 *****
09/16 02:34:13 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:34:13 PM: Validating...
09/16 02:34:14 PM: Evaluate: task edges-pos-ontonotes, batch 5 (157): mcc: 0.9051, acc: 0.8563, precision: 0.9368, recall: 0.8781, f1: 0.9065, edges-pos-ontonotes_loss: 0.0111
09/16 02:34:24 PM: Evaluate: task edges-pos-ontonotes, batch 73 (157): mcc: 0.9128, acc: 0.8613, precision: 0.9483, recall: 0.8820, f1: 0.9139, edges-pos-ontonotes_loss: 0.0106
09/16 02:34:34 PM: Evaluate: task edges-pos-ontonotes, batch 123 (157): mcc: 0.9145, acc: 0.8653, precision: 0.9450, recall: 0.8884, f1: 0.9158, edges-pos-ontonotes_loss: 0.0103
09/16 02:34:42 PM: Updating LR scheduler:
09/16 02:34:42 PM: 	Best result seen so far for macro_avg: 0.919
09/16 02:34:42 PM: 	# validation passes without improvement: 1
09/16 02:34:42 PM: edges-pos-ontonotes_loss: training: 0.012631 validation: 0.010143
09/16 02:34:42 PM: macro_avg: validation: 0.917279
09/16 02:34:42 PM: micro_avg: validation: 0.000000
09/16 02:34:42 PM: edges-pos-ontonotes_mcc: training: 0.887319 validation: 0.915922
09/16 02:34:42 PM: edges-pos-ontonotes_acc: training: 0.819669 validation: 0.868588
09/16 02:34:42 PM: edges-pos-ontonotes_precision: training: 0.918882 validation: 0.942983
09/16 02:34:42 PM: edges-pos-ontonotes_recall: training: 0.861217 validation: 0.892938
09/16 02:34:42 PM: edges-pos-ontonotes_f1: training: 0.889116 validation: 0.917279
09/16 02:34:42 PM: Global learning rate: 0.0001
09/16 02:34:42 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:34:44 PM: Update 37019: task edges-pos-ontonotes, batch 19 (37019): mcc: 0.9166, acc: 0.8594, precision: 0.9436, recall: 0.8937, f1: 0.9180, edges-pos-ontonotes_loss: 0.0101
09/16 02:34:54 PM: Update 37093: task edges-pos-ontonotes, batch 93 (37093): mcc: 0.9157, acc: 0.8585, precision: 0.9435, recall: 0.8921, f1: 0.9171, edges-pos-ontonotes_loss: 0.0099
09/16 02:35:05 PM: Update 37105: task edges-pos-ontonotes, batch 105 (37105): mcc: 0.9140, acc: 0.8558, precision: 0.9429, recall: 0.8894, f1: 0.9154, edges-pos-ontonotes_loss: 0.0101
09/16 02:35:15 PM: Update 37200: task edges-pos-ontonotes, batch 200 (37200): mcc: 0.9114, acc: 0.8516, precision: 0.9428, recall: 0.8844, f1: 0.9127, edges-pos-ontonotes_loss: 0.0106
09/16 02:35:25 PM: Update 37271: task edges-pos-ontonotes, batch 271 (37271): mcc: 0.9110, acc: 0.8512, precision: 0.9418, recall: 0.8847, f1: 0.9124, edges-pos-ontonotes_loss: 0.0106
09/16 02:35:36 PM: Update 37365: task edges-pos-ontonotes, batch 365 (37365): mcc: 0.9105, acc: 0.8506, precision: 0.9412, recall: 0.8843, f1: 0.9119, edges-pos-ontonotes_loss: 0.0107
09/16 02:35:46 PM: Update 37449: task edges-pos-ontonotes, batch 449 (37449): mcc: 0.9079, acc: 0.8471, precision: 0.9388, recall: 0.8817, f1: 0.9093, edges-pos-ontonotes_loss: 0.0109
09/16 02:35:56 PM: Update 37587: task edges-pos-ontonotes, batch 587 (37587): mcc: 0.9031, acc: 0.8397, precision: 0.9356, recall: 0.8755, f1: 0.9045, edges-pos-ontonotes_loss: 0.0116
09/16 02:36:06 PM: Update 37719: task edges-pos-ontonotes, batch 719 (37719): mcc: 0.8991, acc: 0.8339, precision: 0.9326, recall: 0.8707, f1: 0.9006, edges-pos-ontonotes_loss: 0.0120
09/16 02:36:16 PM: Update 37769: task edges-pos-ontonotes, batch 769 (37769): mcc: 0.8950, acc: 0.8281, precision: 0.9285, recall: 0.8667, f1: 0.8966, edges-pos-ontonotes_loss: 0.0122
09/16 02:36:26 PM: Update 37831: task edges-pos-ontonotes, batch 831 (37831): mcc: 0.8916, acc: 0.8233, precision: 0.9249, recall: 0.8638, f1: 0.8933, edges-pos-ontonotes_loss: 0.0125
09/16 02:36:36 PM: Update 37890: task edges-pos-ontonotes, batch 890 (37890): mcc: 0.8892, acc: 0.8199, precision: 0.9227, recall: 0.8613, f1: 0.8909, edges-pos-ontonotes_loss: 0.0126
09/16 02:36:46 PM: Update 37952: task edges-pos-ontonotes, batch 952 (37952): mcc: 0.8875, acc: 0.8175, precision: 0.9210, recall: 0.8596, f1: 0.8893, edges-pos-ontonotes_loss: 0.0128
09/16 02:36:54 PM: ***** Step 38000 / Validation 38 *****
09/16 02:36:54 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:36:54 PM: Validating...
09/16 02:36:56 PM: Evaluate: task edges-pos-ontonotes, batch 17 (157): mcc: 0.9032, acc: 0.8480, precision: 0.9393, recall: 0.8722, f1: 0.9045, edges-pos-ontonotes_loss: 0.0113
09/16 02:37:06 PM: Evaluate: task edges-pos-ontonotes, batch 85 (157): mcc: 0.9139, acc: 0.8638, precision: 0.9479, recall: 0.8845, f1: 0.9151, edges-pos-ontonotes_loss: 0.0105
09/16 02:37:16 PM: Evaluate: task edges-pos-ontonotes, batch 131 (157): mcc: 0.9139, acc: 0.8645, precision: 0.9422, recall: 0.8899, f1: 0.9153, edges-pos-ontonotes_loss: 0.0103
09/16 02:37:22 PM: Updating LR scheduler:
09/16 02:37:22 PM: 	Best result seen so far for macro_avg: 0.919
09/16 02:37:22 PM: 	# validation passes without improvement: 2
09/16 02:37:22 PM: edges-pos-ontonotes_loss: training: 0.012908 validation: 0.010232
09/16 02:37:22 PM: macro_avg: validation: 0.916520
09/16 02:37:22 PM: micro_avg: validation: 0.000000
09/16 02:37:22 PM: edges-pos-ontonotes_mcc: training: 0.886507 validation: 0.915119
09/16 02:37:22 PM: edges-pos-ontonotes_acc: training: 0.816018 validation: 0.867276
09/16 02:37:22 PM: edges-pos-ontonotes_precision: training: 0.920050 validation: 0.941205
09/16 02:37:22 PM: edges-pos-ontonotes_recall: training: 0.858573 validation: 0.893097
09/16 02:37:22 PM: edges-pos-ontonotes_f1: training: 0.888249 validation: 0.916520
09/16 02:37:22 PM: Global learning rate: 0.0001
09/16 02:37:22 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:37:27 PM: Update 38019: task edges-pos-ontonotes, batch 19 (38019): mcc: 0.8704, acc: 0.7950, precision: 0.9062, recall: 0.8411, f1: 0.8724, edges-pos-ontonotes_loss: 0.0150
09/16 02:37:37 PM: Update 38061: task edges-pos-ontonotes, batch 61 (38061): mcc: 0.8679, acc: 0.7902, precision: 0.9031, recall: 0.8392, f1: 0.8700, edges-pos-ontonotes_loss: 0.0157
09/16 02:37:47 PM: Update 38130: task edges-pos-ontonotes, batch 130 (38130): mcc: 0.8685, acc: 0.7897, precision: 0.9086, recall: 0.8352, f1: 0.8704, edges-pos-ontonotes_loss: 0.0149
09/16 02:37:57 PM: Update 38213: task edges-pos-ontonotes, batch 213 (38213): mcc: 0.8698, acc: 0.7910, precision: 0.9111, recall: 0.8353, f1: 0.8716, edges-pos-ontonotes_loss: 0.0146
09/16 02:38:07 PM: Update 38308: task edges-pos-ontonotes, batch 308 (38308): mcc: 0.8709, acc: 0.7925, precision: 0.9131, recall: 0.8356, f1: 0.8726, edges-pos-ontonotes_loss: 0.0143
09/16 02:38:17 PM: Update 38380: task edges-pos-ontonotes, batch 380 (38380): mcc: 0.8717, acc: 0.7936, precision: 0.9134, recall: 0.8368, f1: 0.8734, edges-pos-ontonotes_loss: 0.0142
09/16 02:38:27 PM: Update 38449: task edges-pos-ontonotes, batch 449 (38449): mcc: 0.8726, acc: 0.7948, precision: 0.9128, recall: 0.8391, f1: 0.8744, edges-pos-ontonotes_loss: 0.0142
09/16 02:38:37 PM: Update 38516: task edges-pos-ontonotes, batch 516 (38516): mcc: 0.8738, acc: 0.7965, precision: 0.9125, recall: 0.8415, f1: 0.8756, edges-pos-ontonotes_loss: 0.0142
09/16 02:38:47 PM: Update 38596: task edges-pos-ontonotes, batch 596 (38596): mcc: 0.8745, acc: 0.7975, precision: 0.9128, recall: 0.8426, f1: 0.8763, edges-pos-ontonotes_loss: 0.0141
09/16 02:38:57 PM: Update 38661: task edges-pos-ontonotes, batch 661 (38661): mcc: 0.8754, acc: 0.7989, precision: 0.9132, recall: 0.8439, f1: 0.8772, edges-pos-ontonotes_loss: 0.0140
09/16 02:39:08 PM: Update 38703: task edges-pos-ontonotes, batch 703 (38703): mcc: 0.8751, acc: 0.7986, precision: 0.9125, recall: 0.8439, f1: 0.8769, edges-pos-ontonotes_loss: 0.0140
09/16 02:39:18 PM: Update 38745: task edges-pos-ontonotes, batch 745 (38745): mcc: 0.8747, acc: 0.7983, precision: 0.9118, recall: 0.8440, f1: 0.8766, edges-pos-ontonotes_loss: 0.0141
09/16 02:39:28 PM: Update 38784: task edges-pos-ontonotes, batch 784 (38784): mcc: 0.8744, acc: 0.7981, precision: 0.9111, recall: 0.8440, f1: 0.8763, edges-pos-ontonotes_loss: 0.0141
09/16 02:39:38 PM: Update 38826: task edges-pos-ontonotes, batch 826 (38826): mcc: 0.8742, acc: 0.7978, precision: 0.9105, recall: 0.8441, f1: 0.8760, edges-pos-ontonotes_loss: 0.0142
09/16 02:39:48 PM: Update 38884: task edges-pos-ontonotes, batch 884 (38884): mcc: 0.8744, acc: 0.7983, precision: 0.9104, recall: 0.8447, f1: 0.8763, edges-pos-ontonotes_loss: 0.0142
09/16 02:39:58 PM: Update 38937: task edges-pos-ontonotes, batch 937 (38937): mcc: 0.8745, acc: 0.7986, precision: 0.9100, recall: 0.8452, f1: 0.8764, edges-pos-ontonotes_loss: 0.0142
09/16 02:40:10 PM: Update 39000: task edges-pos-ontonotes, batch 1000 (39000): mcc: 0.8745, acc: 0.7987, precision: 0.9098, recall: 0.8455, f1: 0.8765, edges-pos-ontonotes_loss: 0.0142
09/16 02:40:10 PM: ***** Step 39000 / Validation 39 *****
09/16 02:40:10 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:40:10 PM: Validating...
09/16 02:40:28 PM: Evaluate: task edges-pos-ontonotes, batch 68 (157): mcc: 0.9144, acc: 0.8626, precision: 0.9523, recall: 0.8813, f1: 0.9154, edges-pos-ontonotes_loss: 0.0104
09/16 02:40:38 PM: Evaluate: task edges-pos-ontonotes, batch 119 (157): mcc: 0.9166, acc: 0.8670, precision: 0.9495, recall: 0.8880, f1: 0.9177, edges-pos-ontonotes_loss: 0.0100
09/16 02:40:47 PM: Updating LR scheduler:
09/16 02:40:47 PM: 	Best result seen so far for macro_avg: 0.919
09/16 02:40:47 PM: 	# validation passes without improvement: 3
09/16 02:40:47 PM: edges-pos-ontonotes_loss: training: 0.014224 validation: 0.009937
09/16 02:40:47 PM: macro_avg: validation: 0.918142
09/16 02:40:47 PM: micro_avg: validation: 0.000000
09/16 02:40:47 PM: edges-pos-ontonotes_mcc: training: 0.874538 validation: 0.916890
09/16 02:40:47 PM: edges-pos-ontonotes_acc: training: 0.798698 validation: 0.868546
09/16 02:40:47 PM: edges-pos-ontonotes_precision: training: 0.909819 validation: 0.946738
09/16 02:40:47 PM: edges-pos-ontonotes_recall: training: 0.845453 validation: 0.891224
09/16 02:40:47 PM: edges-pos-ontonotes_f1: training: 0.876456 validation: 0.918142
09/16 02:40:47 PM: Global learning rate: 0.0001
09/16 02:40:47 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:40:48 PM: Update 39007: task edges-pos-ontonotes, batch 7 (39007): mcc: 0.8735, acc: 0.7966, precision: 0.9106, recall: 0.8427, f1: 0.8753, edges-pos-ontonotes_loss: 0.0139
09/16 02:40:59 PM: Update 39059: task edges-pos-ontonotes, batch 59 (39059): mcc: 0.8780, acc: 0.8053, precision: 0.9095, recall: 0.8524, f1: 0.8800, edges-pos-ontonotes_loss: 0.0143
09/16 02:41:09 PM: Update 39114: task edges-pos-ontonotes, batch 114 (39114): mcc: 0.8781, acc: 0.8056, precision: 0.9086, recall: 0.8534, f1: 0.8801, edges-pos-ontonotes_loss: 0.0143
09/16 02:41:19 PM: Update 39173: task edges-pos-ontonotes, batch 173 (39173): mcc: 0.8789, acc: 0.8065, precision: 0.9097, recall: 0.8538, f1: 0.8809, edges-pos-ontonotes_loss: 0.0142
09/16 02:41:29 PM: Update 39232: task edges-pos-ontonotes, batch 232 (39232): mcc: 0.8786, acc: 0.8060, precision: 0.9097, recall: 0.8533, f1: 0.8806, edges-pos-ontonotes_loss: 0.0142
09/16 02:41:39 PM: Update 39281: task edges-pos-ontonotes, batch 281 (39281): mcc: 0.8794, acc: 0.8075, precision: 0.9103, recall: 0.8544, f1: 0.8814, edges-pos-ontonotes_loss: 0.0141
09/16 02:41:49 PM: Update 39319: task edges-pos-ontonotes, batch 319 (39319): mcc: 0.8789, acc: 0.8070, precision: 0.9098, recall: 0.8538, f1: 0.8809, edges-pos-ontonotes_loss: 0.0142
09/16 02:42:00 PM: Update 39377: task edges-pos-ontonotes, batch 377 (39377): mcc: 0.8795, acc: 0.8079, precision: 0.9108, recall: 0.8541, f1: 0.8815, edges-pos-ontonotes_loss: 0.0140
09/16 02:42:10 PM: Update 39434: task edges-pos-ontonotes, batch 434 (39434): mcc: 0.8796, acc: 0.8082, precision: 0.9109, recall: 0.8542, f1: 0.8816, edges-pos-ontonotes_loss: 0.0141
09/16 02:42:20 PM: Update 39488: task edges-pos-ontonotes, batch 488 (39488): mcc: 0.8797, acc: 0.8085, precision: 0.9112, recall: 0.8540, f1: 0.8817, edges-pos-ontonotes_loss: 0.0141
09/16 02:42:30 PM: Update 39542: task edges-pos-ontonotes, batch 542 (39542): mcc: 0.8801, acc: 0.8091, precision: 0.9116, recall: 0.8543, f1: 0.8820, edges-pos-ontonotes_loss: 0.0140
09/16 02:42:40 PM: Update 39591: task edges-pos-ontonotes, batch 591 (39591): mcc: 0.8803, acc: 0.8094, precision: 0.9117, recall: 0.8546, f1: 0.8822, edges-pos-ontonotes_loss: 0.0140
09/16 02:42:50 PM: Update 39633: task edges-pos-ontonotes, batch 633 (39633): mcc: 0.8804, acc: 0.8096, precision: 0.9117, recall: 0.8548, f1: 0.8823, edges-pos-ontonotes_loss: 0.0140
09/16 02:43:00 PM: Update 39689: task edges-pos-ontonotes, batch 689 (39689): mcc: 0.8804, acc: 0.8095, precision: 0.9119, recall: 0.8546, f1: 0.8823, edges-pos-ontonotes_loss: 0.0140
09/16 02:43:10 PM: Update 39743: task edges-pos-ontonotes, batch 743 (39743): mcc: 0.8807, acc: 0.8100, precision: 0.9122, recall: 0.8548, f1: 0.8826, edges-pos-ontonotes_loss: 0.0140
09/16 02:43:21 PM: Update 39795: task edges-pos-ontonotes, batch 795 (39795): mcc: 0.8810, acc: 0.8105, precision: 0.9125, recall: 0.8552, f1: 0.8829, edges-pos-ontonotes_loss: 0.0140
09/16 02:43:31 PM: Update 39845: task edges-pos-ontonotes, batch 845 (39845): mcc: 0.8811, acc: 0.8107, precision: 0.9125, recall: 0.8553, f1: 0.8830, edges-pos-ontonotes_loss: 0.0140
09/16 02:43:41 PM: Update 39890: task edges-pos-ontonotes, batch 890 (39890): mcc: 0.8813, acc: 0.8110, precision: 0.9127, recall: 0.8556, f1: 0.8832, edges-pos-ontonotes_loss: 0.0140
09/16 02:43:53 PM: Update 39939: task edges-pos-ontonotes, batch 939 (39939): mcc: 0.8811, acc: 0.8108, precision: 0.9126, recall: 0.8552, f1: 0.8830, edges-pos-ontonotes_loss: 0.0140
09/16 02:44:03 PM: Update 39992: task edges-pos-ontonotes, batch 992 (39992): mcc: 0.8812, acc: 0.8110, precision: 0.9127, recall: 0.8554, f1: 0.8831, edges-pos-ontonotes_loss: 0.0139
09/16 02:44:05 PM: ***** Step 40000 / Validation 40 *****
09/16 02:44:05 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:44:05 PM: Validating...
09/16 02:44:14 PM: Evaluate: task edges-pos-ontonotes, batch 48 (157): mcc: 0.9075, acc: 0.8514, precision: 0.9513, recall: 0.8692, f1: 0.9084, edges-pos-ontonotes_loss: 0.0110
09/16 02:44:24 PM: Evaluate: task edges-pos-ontonotes, batch 98 (157): mcc: 0.9139, acc: 0.8625, precision: 0.9496, recall: 0.8827, f1: 0.9150, edges-pos-ontonotes_loss: 0.0104
09/16 02:44:34 PM: Evaluate: task edges-pos-ontonotes, batch 133 (157): mcc: 0.9148, acc: 0.8650, precision: 0.9463, recall: 0.8877, f1: 0.9160, edges-pos-ontonotes_loss: 0.0102
09/16 02:44:40 PM: Updating LR scheduler:
09/16 02:44:40 PM: 	Best result seen so far for macro_avg: 0.919
09/16 02:44:40 PM: 	# validation passes without improvement: 0
09/16 02:44:40 PM: edges-pos-ontonotes_loss: training: 0.013892 validation: 0.010047
09/16 02:44:40 PM: macro_avg: validation: 0.917772
09/16 02:44:40 PM: micro_avg: validation: 0.000000
09/16 02:44:40 PM: edges-pos-ontonotes_mcc: training: 0.881264 validation: 0.916508
09/16 02:44:40 PM: edges-pos-ontonotes_acc: training: 0.811107 validation: 0.868504
09/16 02:44:40 PM: edges-pos-ontonotes_precision: training: 0.912780 validation: 0.946224
09/16 02:44:40 PM: edges-pos-ontonotes_recall: training: 0.855449 validation: 0.890981
09/16 02:44:40 PM: edges-pos-ontonotes_f1: training: 0.883185 validation: 0.917772
09/16 02:44:40 PM: Global learning rate: 5e-05
09/16 02:44:40 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:44:44 PM: Update 40016: task edges-pos-ontonotes, batch 16 (40016): mcc: 0.8847, acc: 0.8156, precision: 0.9198, recall: 0.8554, f1: 0.8864, edges-pos-ontonotes_loss: 0.0123
09/16 02:44:54 PM: Update 40060: task edges-pos-ontonotes, batch 60 (40060): mcc: 0.8835, acc: 0.8150, precision: 0.9155, recall: 0.8572, f1: 0.8854, edges-pos-ontonotes_loss: 0.0122
09/16 02:45:04 PM: Update 40114: task edges-pos-ontonotes, batch 114 (40114): mcc: 0.8851, acc: 0.8170, precision: 0.9167, recall: 0.8591, f1: 0.8870, edges-pos-ontonotes_loss: 0.0121
09/16 02:45:14 PM: Update 40170: task edges-pos-ontonotes, batch 170 (40170): mcc: 0.8864, acc: 0.8182, precision: 0.9180, recall: 0.8603, f1: 0.8882, edges-pos-ontonotes_loss: 0.0119
09/16 02:45:24 PM: Update 40240: task edges-pos-ontonotes, batch 240 (40240): mcc: 0.8870, acc: 0.8191, precision: 0.9183, recall: 0.8612, f1: 0.8889, edges-pos-ontonotes_loss: 0.0119
09/16 02:45:34 PM: Update 40310: task edges-pos-ontonotes, batch 310 (40310): mcc: 0.8907, acc: 0.8239, precision: 0.9217, recall: 0.8650, f1: 0.8924, edges-pos-ontonotes_loss: 0.0117
09/16 02:45:44 PM: Update 40404: task edges-pos-ontonotes, batch 404 (40404): mcc: 0.8941, acc: 0.8284, precision: 0.9249, recall: 0.8684, f1: 0.8958, edges-pos-ontonotes_loss: 0.0114
09/16 02:45:54 PM: Update 40493: task edges-pos-ontonotes, batch 493 (40493): mcc: 0.8966, acc: 0.8315, precision: 0.9270, recall: 0.8712, f1: 0.8982, edges-pos-ontonotes_loss: 0.0112
09/16 02:46:05 PM: Update 40567: task edges-pos-ontonotes, batch 567 (40567): mcc: 0.8979, acc: 0.8333, precision: 0.9285, recall: 0.8723, f1: 0.8995, edges-pos-ontonotes_loss: 0.0111
09/16 02:46:15 PM: Update 40667: task edges-pos-ontonotes, batch 667 (40667): mcc: 0.8988, acc: 0.8344, precision: 0.9297, recall: 0.8728, f1: 0.9004, edges-pos-ontonotes_loss: 0.0112
09/16 02:46:25 PM: Update 40744: task edges-pos-ontonotes, batch 744 (40744): mcc: 0.8993, acc: 0.8351, precision: 0.9305, recall: 0.8731, f1: 0.9009, edges-pos-ontonotes_loss: 0.0111
09/16 02:46:35 PM: Update 40829: task edges-pos-ontonotes, batch 829 (40829): mcc: 0.9000, acc: 0.8360, precision: 0.9312, recall: 0.8736, f1: 0.9015, edges-pos-ontonotes_loss: 0.0111
09/16 02:46:45 PM: Update 40895: task edges-pos-ontonotes, batch 895 (40895): mcc: 0.8998, acc: 0.8358, precision: 0.9312, recall: 0.8734, f1: 0.9014, edges-pos-ontonotes_loss: 0.0111
09/16 02:46:55 PM: Update 40999: task edges-pos-ontonotes, batch 999 (40999): mcc: 0.8983, acc: 0.8335, precision: 0.9304, recall: 0.8713, f1: 0.8999, edges-pos-ontonotes_loss: 0.0115
09/16 02:46:55 PM: ***** Step 41000 / Validation 41 *****
09/16 02:46:55 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:46:55 PM: Validating...
09/16 02:47:05 PM: Evaluate: task edges-pos-ontonotes, batch 52 (157): mcc: 0.9107, acc: 0.8585, precision: 0.9478, recall: 0.8785, f1: 0.9118, edges-pos-ontonotes_loss: 0.0108
09/16 02:47:15 PM: Evaluate: task edges-pos-ontonotes, batch 104 (157): mcc: 0.9144, acc: 0.8658, precision: 0.9443, recall: 0.8888, f1: 0.9157, edges-pos-ontonotes_loss: 0.0103
09/16 02:47:25 PM: Evaluate: task edges-pos-ontonotes, batch 149 (157): mcc: 0.9144, acc: 0.8669, precision: 0.9382, recall: 0.8947, f1: 0.9159, edges-pos-ontonotes_loss: 0.0102
09/16 02:47:27 PM: Updating LR scheduler:
09/16 02:47:27 PM: 	Best result seen so far for macro_avg: 0.919
09/16 02:47:27 PM: 	# validation passes without improvement: 1
09/16 02:47:27 PM: edges-pos-ontonotes_loss: training: 0.011457 validation: 0.010181
09/16 02:47:27 PM: macro_avg: validation: 0.916487
09/16 02:47:27 PM: micro_avg: validation: 0.000000
09/16 02:47:27 PM: edges-pos-ontonotes_mcc: training: 0.898326 validation: 0.915009
09/16 02:47:27 PM: edges-pos-ontonotes_acc: training: 0.833502 validation: 0.868038
09/16 02:47:27 PM: edges-pos-ontonotes_precision: training: 0.930444 validation: 0.938295
09/16 02:47:27 PM: edges-pos-ontonotes_recall: training: 0.871260 validation: 0.895669
09/16 02:47:27 PM: edges-pos-ontonotes_f1: training: 0.899880 validation: 0.916487
09/16 02:47:27 PM: Global learning rate: 5e-05
09/16 02:47:27 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:47:35 PM: Update 41117: task edges-pos-ontonotes, batch 117 (41117): mcc: 0.8767, acc: 0.8001, precision: 0.9189, recall: 0.8410, f1: 0.8782, edges-pos-ontonotes_loss: 0.0141
09/16 02:47:55 PM: Update 41191: task edges-pos-ontonotes, batch 191 (41191): mcc: 0.8759, acc: 0.7993, precision: 0.9180, recall: 0.8404, f1: 0.8775, edges-pos-ontonotes_loss: 0.0141
09/16 02:48:05 PM: Update 41237: task edges-pos-ontonotes, batch 237 (41237): mcc: 0.8737, acc: 0.7969, precision: 0.9126, recall: 0.8412, f1: 0.8755, edges-pos-ontonotes_loss: 0.0143
09/16 02:48:15 PM: Update 41289: task edges-pos-ontonotes, batch 289 (41289): mcc: 0.8741, acc: 0.7975, precision: 0.9111, recall: 0.8434, f1: 0.8759, edges-pos-ontonotes_loss: 0.0144
09/16 02:48:25 PM: Update 41352: task edges-pos-ontonotes, batch 352 (41352): mcc: 0.8737, acc: 0.7969, precision: 0.9102, recall: 0.8435, f1: 0.8756, edges-pos-ontonotes_loss: 0.0145
09/16 02:48:36 PM: Update 41420: task edges-pos-ontonotes, batch 420 (41420): mcc: 0.8735, acc: 0.7970, precision: 0.9092, recall: 0.8441, f1: 0.8754, edges-pos-ontonotes_loss: 0.0146
09/16 02:48:46 PM: Update 41479: task edges-pos-ontonotes, batch 479 (41479): mcc: 0.8727, acc: 0.7959, precision: 0.9079, recall: 0.8438, f1: 0.8747, edges-pos-ontonotes_loss: 0.0148
09/16 02:48:56 PM: Update 41525: task edges-pos-ontonotes, batch 525 (41525): mcc: 0.8721, acc: 0.7948, precision: 0.9077, recall: 0.8428, f1: 0.8740, edges-pos-ontonotes_loss: 0.0148
09/16 02:49:06 PM: Update 41605: task edges-pos-ontonotes, batch 605 (41605): mcc: 0.8720, acc: 0.7947, precision: 0.9088, recall: 0.8417, f1: 0.8739, edges-pos-ontonotes_loss: 0.0147
09/16 02:49:16 PM: Update 41673: task edges-pos-ontonotes, batch 673 (41673): mcc: 0.8720, acc: 0.7943, precision: 0.9096, recall: 0.8408, f1: 0.8738, edges-pos-ontonotes_loss: 0.0146
09/16 02:49:27 PM: Update 41747: task edges-pos-ontonotes, batch 747 (41747): mcc: 0.8720, acc: 0.7942, precision: 0.9103, recall: 0.8402, f1: 0.8738, edges-pos-ontonotes_loss: 0.0146
09/16 02:49:37 PM: Update 41809: task edges-pos-ontonotes, batch 809 (41809): mcc: 0.8720, acc: 0.7942, precision: 0.9106, recall: 0.8400, f1: 0.8739, edges-pos-ontonotes_loss: 0.0145
09/16 02:49:47 PM: Update 41860: task edges-pos-ontonotes, batch 860 (41860): mcc: 0.8726, acc: 0.7950, precision: 0.9108, recall: 0.8409, f1: 0.8744, edges-pos-ontonotes_loss: 0.0145
09/16 02:49:57 PM: Update 41932: task edges-pos-ontonotes, batch 932 (41932): mcc: 0.8735, acc: 0.7963, precision: 0.9110, recall: 0.8423, f1: 0.8753, edges-pos-ontonotes_loss: 0.0144
09/16 02:50:07 PM: ***** Step 42000 / Validation 42 *****
09/16 02:50:07 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:50:07 PM: Validating...
09/16 02:50:07 PM: Evaluate: task edges-pos-ontonotes, batch 3 (157): mcc: 0.9165, acc: 0.8723, precision: 0.9405, recall: 0.8963, f1: 0.9179, edges-pos-ontonotes_loss: 0.0101
09/16 02:50:17 PM: Evaluate: task edges-pos-ontonotes, batch 65 (157): mcc: 0.9141, acc: 0.8633, precision: 0.9482, recall: 0.8845, f1: 0.9152, edges-pos-ontonotes_loss: 0.0104
09/16 02:50:27 PM: Evaluate: task edges-pos-ontonotes, batch 116 (157): mcc: 0.9162, acc: 0.8676, precision: 0.9442, recall: 0.8923, f1: 0.9175, edges-pos-ontonotes_loss: 0.0100
09/16 02:50:36 PM: Updating LR scheduler:
09/16 02:50:36 PM: 	Best result seen so far for macro_avg: 0.919
09/16 02:50:36 PM: 	# validation passes without improvement: 2
09/16 02:50:36 PM: edges-pos-ontonotes_loss: training: 0.014313 validation: 0.009912
09/16 02:50:36 PM: macro_avg: validation: 0.918442
09/16 02:50:36 PM: micro_avg: validation: 0.000000
09/16 02:50:36 PM: edges-pos-ontonotes_mcc: training: 0.873962 validation: 0.917032
09/16 02:50:36 PM: edges-pos-ontonotes_acc: training: 0.796983 validation: 0.869710
09/16 02:50:36 PM: edges-pos-ontonotes_precision: training: 0.911118 validation: 0.941339
09/16 02:50:36 PM: edges-pos-ontonotes_recall: training: 0.843149 validation: 0.896632
09/16 02:50:36 PM: edges-pos-ontonotes_f1: training: 0.875816 validation: 0.918442
09/16 02:50:36 PM: Global learning rate: 5e-05
09/16 02:50:36 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:50:38 PM: Update 42004: task edges-pos-ontonotes, batch 4 (42004): mcc: 0.8801, acc: 0.8046, precision: 0.9134, recall: 0.8526, f1: 0.8819, edges-pos-ontonotes_loss: 0.0141
09/16 02:50:48 PM: Update 42069: task edges-pos-ontonotes, batch 69 (42069): mcc: 0.8803, acc: 0.8067, precision: 0.9128, recall: 0.8536, f1: 0.8822, edges-pos-ontonotes_loss: 0.0136
09/16 02:50:58 PM: Update 42143: task edges-pos-ontonotes, batch 143 (42143): mcc: 0.8806, acc: 0.8066, precision: 0.9135, recall: 0.8534, f1: 0.8825, edges-pos-ontonotes_loss: 0.0136
09/16 02:51:08 PM: Update 42184: task edges-pos-ontonotes, batch 184 (42184): mcc: 0.8777, acc: 0.8036, precision: 0.9097, recall: 0.8516, f1: 0.8797, edges-pos-ontonotes_loss: 0.0138
09/16 02:51:18 PM: Update 42239: task edges-pos-ontonotes, batch 239 (42239): mcc: 0.8764, acc: 0.8020, precision: 0.9084, recall: 0.8504, f1: 0.8784, edges-pos-ontonotes_loss: 0.0139
09/16 02:51:28 PM: Update 42295: task edges-pos-ontonotes, batch 295 (42295): mcc: 0.8766, acc: 0.8022, precision: 0.9080, recall: 0.8510, f1: 0.8786, edges-pos-ontonotes_loss: 0.0141
09/16 02:51:38 PM: Update 42354: task edges-pos-ontonotes, batch 354 (42354): mcc: 0.8762, acc: 0.8018, precision: 0.9077, recall: 0.8507, f1: 0.8783, edges-pos-ontonotes_loss: 0.0142
09/16 02:51:49 PM: Update 42409: task edges-pos-ontonotes, batch 409 (42409): mcc: 0.8759, acc: 0.8015, precision: 0.9074, recall: 0.8504, f1: 0.8780, edges-pos-ontonotes_loss: 0.0143
09/16 02:51:59 PM: Update 42460: task edges-pos-ontonotes, batch 460 (42460): mcc: 0.8759, acc: 0.8014, precision: 0.9074, recall: 0.8503, f1: 0.8779, edges-pos-ontonotes_loss: 0.0143
09/16 02:52:09 PM: Update 42513: task edges-pos-ontonotes, batch 513 (42513): mcc: 0.8763, acc: 0.8019, precision: 0.9076, recall: 0.8508, f1: 0.8783, edges-pos-ontonotes_loss: 0.0142
09/16 02:52:19 PM: Update 42566: task edges-pos-ontonotes, batch 566 (42566): mcc: 0.8765, acc: 0.8025, precision: 0.9078, recall: 0.8510, f1: 0.8785, edges-pos-ontonotes_loss: 0.0143
09/16 02:52:29 PM: Update 42625: task edges-pos-ontonotes, batch 625 (42625): mcc: 0.8768, acc: 0.8029, precision: 0.9080, recall: 0.8514, f1: 0.8788, edges-pos-ontonotes_loss: 0.0142
09/16 02:52:39 PM: Update 42679: task edges-pos-ontonotes, batch 679 (42679): mcc: 0.8772, acc: 0.8036, precision: 0.9085, recall: 0.8517, f1: 0.8792, edges-pos-ontonotes_loss: 0.0142
09/16 02:52:50 PM: Update 42730: task edges-pos-ontonotes, batch 730 (42730): mcc: 0.8775, acc: 0.8042, precision: 0.9088, recall: 0.8521, f1: 0.8796, edges-pos-ontonotes_loss: 0.0142
09/16 02:53:00 PM: Update 42771: task edges-pos-ontonotes, batch 771 (42771): mcc: 0.8778, acc: 0.8047, precision: 0.9089, recall: 0.8525, f1: 0.8798, edges-pos-ontonotes_loss: 0.0141
09/16 02:53:10 PM: Update 42804: task edges-pos-ontonotes, batch 804 (42804): mcc: 0.8778, acc: 0.8047, precision: 0.9090, recall: 0.8524, f1: 0.8798, edges-pos-ontonotes_loss: 0.0141
09/16 02:53:20 PM: Update 42855: task edges-pos-ontonotes, batch 855 (42855): mcc: 0.8781, acc: 0.8051, precision: 0.9093, recall: 0.8527, f1: 0.8801, edges-pos-ontonotes_loss: 0.0141
09/16 02:53:30 PM: Update 42911: task edges-pos-ontonotes, batch 911 (42911): mcc: 0.8782, acc: 0.8055, precision: 0.9094, recall: 0.8528, f1: 0.8802, edges-pos-ontonotes_loss: 0.0141
09/16 02:53:40 PM: Update 42968: task edges-pos-ontonotes, batch 968 (42968): mcc: 0.8785, acc: 0.8059, precision: 0.9097, recall: 0.8531, f1: 0.8805, edges-pos-ontonotes_loss: 0.0141
09/16 02:53:46 PM: ***** Step 43000 / Validation 43 *****
09/16 02:53:46 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:53:46 PM: Validating...
09/16 02:53:50 PM: Evaluate: task edges-pos-ontonotes, batch 29 (157): mcc: 0.9083, acc: 0.8525, precision: 0.9497, recall: 0.8722, f1: 0.9093, edges-pos-ontonotes_loss: 0.0108
09/16 02:54:00 PM: Evaluate: task edges-pos-ontonotes, batch 94 (157): mcc: 0.9162, acc: 0.8661, precision: 0.9510, recall: 0.8859, f1: 0.9173, edges-pos-ontonotes_loss: 0.0102
09/16 02:54:11 PM: Evaluate: task edges-pos-ontonotes, batch 140 (157): mcc: 0.9170, acc: 0.8685, precision: 0.9467, recall: 0.8915, f1: 0.9183, edges-pos-ontonotes_loss: 0.0100
09/16 02:54:14 PM: Updating LR scheduler:
09/16 02:54:14 PM: 	Best result seen so far for macro_avg: 0.919
09/16 02:54:14 PM: 	# validation passes without improvement: 3
09/16 02:54:14 PM: edges-pos-ontonotes_loss: training: 0.014075 validation: 0.009907
09/16 02:54:14 PM: macro_avg: validation: 0.919202
09/16 02:54:14 PM: micro_avg: validation: 0.000000
09/16 02:54:14 PM: edges-pos-ontonotes_mcc: training: 0.878667 validation: 0.917928
09/16 02:54:14 PM: edges-pos-ontonotes_acc: training: 0.806198 validation: 0.870620
09/16 02:54:14 PM: edges-pos-ontonotes_precision: training: 0.909771 validation: 0.946380
09/16 02:54:14 PM: edges-pos-ontonotes_recall: training: 0.853344 validation: 0.893542
09/16 02:54:14 PM: edges-pos-ontonotes_f1: training: 0.880655 validation: 0.919202
09/16 02:54:14 PM: Global learning rate: 5e-05
09/16 02:54:14 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:54:21 PM: Update 43035: task edges-pos-ontonotes, batch 35 (43035): mcc: 0.8826, acc: 0.8137, precision: 0.9172, recall: 0.8538, f1: 0.8844, edges-pos-ontonotes_loss: 0.0133
09/16 02:54:40 PM: Update 43086: task edges-pos-ontonotes, batch 86 (43086): mcc: 0.8816, acc: 0.8122, precision: 0.9149, recall: 0.8541, f1: 0.8835, edges-pos-ontonotes_loss: 0.0137
09/16 02:54:50 PM: Update 43125: task edges-pos-ontonotes, batch 125 (43125): mcc: 0.8821, acc: 0.8125, precision: 0.9145, recall: 0.8554, f1: 0.8840, edges-pos-ontonotes_loss: 0.0136
09/16 02:55:00 PM: Update 43178: task edges-pos-ontonotes, batch 178 (43178): mcc: 0.8818, acc: 0.8123, precision: 0.9141, recall: 0.8552, f1: 0.8837, edges-pos-ontonotes_loss: 0.0137
09/16 02:55:10 PM: Update 43233: task edges-pos-ontonotes, batch 233 (43233): mcc: 0.8815, acc: 0.8116, precision: 0.9137, recall: 0.8550, f1: 0.8833, edges-pos-ontonotes_loss: 0.0139
09/16 02:55:20 PM: Update 43287: task edges-pos-ontonotes, batch 287 (43287): mcc: 0.8817, acc: 0.8120, precision: 0.9137, recall: 0.8553, f1: 0.8835, edges-pos-ontonotes_loss: 0.0139
09/16 02:55:31 PM: Update 43343: task edges-pos-ontonotes, batch 343 (43343): mcc: 0.8818, acc: 0.8122, precision: 0.9139, recall: 0.8555, f1: 0.8837, edges-pos-ontonotes_loss: 0.0140
09/16 02:55:41 PM: Update 43396: task edges-pos-ontonotes, batch 396 (43396): mcc: 0.8820, acc: 0.8126, precision: 0.9139, recall: 0.8558, f1: 0.8839, edges-pos-ontonotes_loss: 0.0140
09/16 02:55:51 PM: Update 43445: task edges-pos-ontonotes, batch 445 (43445): mcc: 0.8818, acc: 0.8122, precision: 0.9137, recall: 0.8556, f1: 0.8837, edges-pos-ontonotes_loss: 0.0138
09/16 02:56:01 PM: Update 43508: task edges-pos-ontonotes, batch 508 (43508): mcc: 0.8818, acc: 0.8124, precision: 0.9137, recall: 0.8557, f1: 0.8837, edges-pos-ontonotes_loss: 0.0136
09/16 02:56:11 PM: Update 43579: task edges-pos-ontonotes, batch 579 (43579): mcc: 0.8827, acc: 0.8134, precision: 0.9145, recall: 0.8566, f1: 0.8846, edges-pos-ontonotes_loss: 0.0134
09/16 02:56:21 PM: Update 43639: task edges-pos-ontonotes, batch 639 (43639): mcc: 0.8830, acc: 0.8138, precision: 0.9147, recall: 0.8571, f1: 0.8849, edges-pos-ontonotes_loss: 0.0133
09/16 02:56:31 PM: Update 43710: task edges-pos-ontonotes, batch 710 (43710): mcc: 0.8837, acc: 0.8147, precision: 0.9152, recall: 0.8578, f1: 0.8856, edges-pos-ontonotes_loss: 0.0131
09/16 02:56:41 PM: Update 43785: task edges-pos-ontonotes, batch 785 (43785): mcc: 0.8855, acc: 0.8171, precision: 0.9167, recall: 0.8598, f1: 0.8873, edges-pos-ontonotes_loss: 0.0128
09/16 02:56:51 PM: Update 43880: task edges-pos-ontonotes, batch 880 (43880): mcc: 0.8871, acc: 0.8192, precision: 0.9182, recall: 0.8615, f1: 0.8890, edges-pos-ontonotes_loss: 0.0126
09/16 02:57:01 PM: Update 43967: task edges-pos-ontonotes, batch 967 (43967): mcc: 0.8888, acc: 0.8214, precision: 0.9198, recall: 0.8631, f1: 0.8906, edges-pos-ontonotes_loss: 0.0124
09/16 02:57:05 PM: ***** Step 44000 / Validation 44 *****
09/16 02:57:05 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:57:05 PM: Validating...
09/16 02:57:11 PM: Evaluate: task edges-pos-ontonotes, batch 43 (157): mcc: 0.9073, acc: 0.8522, precision: 0.9498, recall: 0.8702, f1: 0.9082, edges-pos-ontonotes_loss: 0.0110
09/16 02:57:21 PM: Evaluate: task edges-pos-ontonotes, batch 102 (157): mcc: 0.9156, acc: 0.8663, precision: 0.9488, recall: 0.8868, f1: 0.9168, edges-pos-ontonotes_loss: 0.0102
09/16 02:57:31 PM: Evaluate: task edges-pos-ontonotes, batch 146 (157): mcc: 0.9160, acc: 0.8683, precision: 0.9442, recall: 0.8919, f1: 0.9173, edges-pos-ontonotes_loss: 0.0101
09/16 02:57:34 PM: Updating LR scheduler:
09/16 02:57:34 PM: 	Best result seen so far for macro_avg: 0.919
09/16 02:57:34 PM: 	# validation passes without improvement: 0
09/16 02:57:34 PM: edges-pos-ontonotes_loss: training: 0.012281 validation: 0.009990
09/16 02:57:34 PM: macro_avg: validation: 0.918470
09/16 02:57:34 PM: micro_avg: validation: 0.000000
09/16 02:57:34 PM: edges-pos-ontonotes_mcc: training: 0.889362 validation: 0.917154
09/16 02:57:34 PM: edges-pos-ontonotes_acc: training: 0.822191 validation: 0.870377
09/16 02:57:34 PM: edges-pos-ontonotes_precision: training: 0.920290 validation: 0.944723
09/16 02:57:34 PM: edges-pos-ontonotes_recall: training: 0.863777 validation: 0.893637
09/16 02:57:34 PM: edges-pos-ontonotes_f1: training: 0.891139 validation: 0.918470
09/16 02:57:34 PM: Global learning rate: 2.5e-05
09/16 02:57:34 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:57:41 PM: Update 44069: task edges-pos-ontonotes, batch 69 (44069): mcc: 0.9068, acc: 0.8447, precision: 0.9396, recall: 0.8787, f1: 0.9081, edges-pos-ontonotes_loss: 0.0108
09/16 02:57:51 PM: Update 44175: task edges-pos-ontonotes, batch 175 (44175): mcc: 0.9068, acc: 0.8449, precision: 0.9413, recall: 0.8772, f1: 0.9081, edges-pos-ontonotes_loss: 0.0109
09/16 02:58:02 PM: Update 44272: task edges-pos-ontonotes, batch 272 (44272): mcc: 0.9072, acc: 0.8456, precision: 0.9407, recall: 0.8785, f1: 0.9086, edges-pos-ontonotes_loss: 0.0108
09/16 02:58:12 PM: Update 44369: task edges-pos-ontonotes, batch 369 (44369): mcc: 0.9038, acc: 0.8411, precision: 0.9382, recall: 0.8743, f1: 0.9051, edges-pos-ontonotes_loss: 0.0112
09/16 02:58:22 PM: Update 44521: task edges-pos-ontonotes, batch 521 (44521): mcc: 0.8980, acc: 0.8323, precision: 0.9345, recall: 0.8669, f1: 0.8994, edges-pos-ontonotes_loss: 0.0120
09/16 02:58:34 PM: Update 44651: task edges-pos-ontonotes, batch 651 (44651): mcc: 0.8939, acc: 0.8265, precision: 0.9316, recall: 0.8619, f1: 0.8954, edges-pos-ontonotes_loss: 0.0124
09/16 02:58:44 PM: Update 44710: task edges-pos-ontonotes, batch 710 (44710): mcc: 0.8900, acc: 0.8210, precision: 0.9268, recall: 0.8588, f1: 0.8915, edges-pos-ontonotes_loss: 0.0127
09/16 02:58:54 PM: Update 44773: task edges-pos-ontonotes, batch 773 (44773): mcc: 0.8874, acc: 0.8175, precision: 0.9239, recall: 0.8567, f1: 0.8890, edges-pos-ontonotes_loss: 0.0129
09/16 02:59:04 PM: Update 44833: task edges-pos-ontonotes, batch 833 (44833): mcc: 0.8860, acc: 0.8154, precision: 0.9221, recall: 0.8556, f1: 0.8876, edges-pos-ontonotes_loss: 0.0130
09/16 02:59:14 PM: Update 44886: task edges-pos-ontonotes, batch 886 (44886): mcc: 0.8845, acc: 0.8134, precision: 0.9201, recall: 0.8547, f1: 0.8862, edges-pos-ontonotes_loss: 0.0131
09/16 02:59:24 PM: Update 44949: task edges-pos-ontonotes, batch 949 (44949): mcc: 0.8830, acc: 0.8112, precision: 0.9187, recall: 0.8532, f1: 0.8847, edges-pos-ontonotes_loss: 0.0133
09/16 02:59:33 PM: ***** Step 45000 / Validation 45 *****
09/16 02:59:33 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:59:33 PM: Validating...
09/16 02:59:34 PM: Evaluate: task edges-pos-ontonotes, batch 7 (157): mcc: 0.9063, acc: 0.8585, precision: 0.9328, recall: 0.8842, f1: 0.9079, edges-pos-ontonotes_loss: 0.0110
09/16 02:59:44 PM: Evaluate: task edges-pos-ontonotes, batch 76 (157): mcc: 0.9155, acc: 0.8663, precision: 0.9481, recall: 0.8872, f1: 0.9167, edges-pos-ontonotes_loss: 0.0103
09/16 02:59:55 PM: Evaluate: task edges-pos-ontonotes, batch 121 (157): mcc: 0.9163, acc: 0.8684, precision: 0.9443, recall: 0.8924, f1: 0.9176, edges-pos-ontonotes_loss: 0.0101
09/16 03:00:03 PM: Updating LR scheduler:
09/16 03:00:03 PM: 	Best result seen so far for macro_avg: 0.919
09/16 03:00:03 PM: 	# validation passes without improvement: 1
09/16 03:00:03 PM: edges-pos-ontonotes_loss: training: 0.013374 validation: 0.009956
09/16 03:00:03 PM: macro_avg: validation: 0.918722
09/16 03:00:03 PM: micro_avg: validation: 0.000000
09/16 03:00:03 PM: edges-pos-ontonotes_mcc: training: 0.881803 validation: 0.917319
09/16 03:00:03 PM: edges-pos-ontonotes_acc: training: 0.809373 validation: 0.870874
09/16 03:00:03 PM: edges-pos-ontonotes_precision: training: 0.917724 validation: 0.941648
09/16 03:00:03 PM: edges-pos-ontonotes_recall: training: 0.851829 validation: 0.896886
09/16 03:00:03 PM: edges-pos-ontonotes_f1: training: 0.883549 validation: 0.918722
09/16 03:00:03 PM: Global learning rate: 2.5e-05
09/16 03:00:03 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 03:00:05 PM: Update 45020: task edges-pos-ontonotes, batch 20 (45020): mcc: 0.8746, acc: 0.7971, precision: 0.9272, recall: 0.8297, f1: 0.8757, edges-pos-ontonotes_loss: 0.0137
09/16 03:00:15 PM: Update 45104: task edges-pos-ontonotes, batch 104 (45104): mcc: 0.8737, acc: 0.7946, precision: 0.9212, recall: 0.8334, f1: 0.8751, edges-pos-ontonotes_loss: 0.0140
09/16 03:00:25 PM: Update 45189: task edges-pos-ontonotes, batch 189 (45189): mcc: 0.8734, acc: 0.7944, precision: 0.9202, recall: 0.8337, f1: 0.8748, edges-pos-ontonotes_loss: 0.0139
09/16 03:00:35 PM: Update 45286: task edges-pos-ontonotes, batch 286 (45286): mcc: 0.8732, acc: 0.7946, precision: 0.9198, recall: 0.8337, f1: 0.8746, edges-pos-ontonotes_loss: 0.0139
09/16 03:00:45 PM: Update 45294: task edges-pos-ontonotes, batch 294 (45294): mcc: 0.8734, acc: 0.7950, precision: 0.9198, recall: 0.8341, f1: 0.8749, edges-pos-ontonotes_loss: 0.0139
09/16 03:00:55 PM: Update 45358: task edges-pos-ontonotes, batch 358 (45358): mcc: 0.8751, acc: 0.7979, precision: 0.9175, recall: 0.8394, f1: 0.8767, edges-pos-ontonotes_loss: 0.0139
09/16 03:01:05 PM: Update 45438: task edges-pos-ontonotes, batch 438 (45438): mcc: 0.8763, acc: 0.8000, precision: 0.9167, recall: 0.8424, f1: 0.8780, edges-pos-ontonotes_loss: 0.0138
09/16 03:01:15 PM: Update 45513: task edges-pos-ontonotes, batch 513 (45513): mcc: 0.8770, acc: 0.8010, precision: 0.9157, recall: 0.8446, f1: 0.8787, edges-pos-ontonotes_loss: 0.0138
09/16 03:01:25 PM: Update 45581: task edges-pos-ontonotes, batch 581 (45581): mcc: 0.8777, acc: 0.8020, precision: 0.9156, recall: 0.8460, f1: 0.8794, edges-pos-ontonotes_loss: 0.0138
09/16 03:01:36 PM: Update 45630: task edges-pos-ontonotes, batch 630 (45630): mcc: 0.8775, acc: 0.8020, precision: 0.9145, recall: 0.8467, f1: 0.8793, edges-pos-ontonotes_loss: 0.0138
09/16 03:01:46 PM: Update 45685: task edges-pos-ontonotes, batch 685 (45685): mcc: 0.8771, acc: 0.8016, precision: 0.9132, recall: 0.8471, f1: 0.8789, edges-pos-ontonotes_loss: 0.0138
09/16 03:01:56 PM: Update 45742: task edges-pos-ontonotes, batch 742 (45742): mcc: 0.8769, acc: 0.8017, precision: 0.9123, recall: 0.8476, f1: 0.8787, edges-pos-ontonotes_loss: 0.0139
09/16 03:02:06 PM: Update 45798: task edges-pos-ontonotes, batch 798 (45798): mcc: 0.8767, acc: 0.8017, precision: 0.9115, recall: 0.8479, f1: 0.8786, edges-pos-ontonotes_loss: 0.0139
09/16 03:02:16 PM: Update 45860: task edges-pos-ontonotes, batch 860 (45860): mcc: 0.8765, acc: 0.8015, precision: 0.9111, recall: 0.8479, f1: 0.8784, edges-pos-ontonotes_loss: 0.0140
09/16 03:02:26 PM: Update 45915: task edges-pos-ontonotes, batch 915 (45915): mcc: 0.8765, acc: 0.8018, precision: 0.9108, recall: 0.8483, f1: 0.8784, edges-pos-ontonotes_loss: 0.0140
09/16 03:02:36 PM: Update 45959: task edges-pos-ontonotes, batch 959 (45959): mcc: 0.8766, acc: 0.8019, precision: 0.9106, recall: 0.8486, f1: 0.8785, edges-pos-ontonotes_loss: 0.0141
09/16 03:02:44 PM: ***** Step 46000 / Validation 46 *****
09/16 03:02:44 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:02:44 PM: Validating...
09/16 03:02:46 PM: Evaluate: task edges-pos-ontonotes, batch 17 (157): mcc: 0.9066, acc: 0.8527, precision: 0.9421, recall: 0.8760, f1: 0.9078, edges-pos-ontonotes_loss: 0.0109
09/16 03:02:56 PM: Evaluate: task edges-pos-ontonotes, batch 85 (157): mcc: 0.9164, acc: 0.8664, precision: 0.9506, recall: 0.8866, f1: 0.9175, edges-pos-ontonotes_loss: 0.0101
09/16 03:03:06 PM: Evaluate: task edges-pos-ontonotes, batch 131 (157): mcc: 0.9165, acc: 0.8679, precision: 0.9455, recall: 0.8917, f1: 0.9178, edges-pos-ontonotes_loss: 0.0100
09/16 03:03:12 PM: Updating LR scheduler:
09/16 03:03:12 PM: 	Best result seen so far for macro_avg: 0.919
09/16 03:03:12 PM: 	# validation passes without improvement: 2
09/16 03:03:12 PM: Ran out of early stopping patience. Stopping training.
09/16 03:03:12 PM: edges-pos-ontonotes_loss: training: 0.014070 validation: 0.009862
09/16 03:03:12 PM: macro_avg: validation: 0.918990
09/16 03:03:12 PM: micro_avg: validation: 0.000000
09/16 03:03:12 PM: edges-pos-ontonotes_mcc: training: 0.876678 validation: 0.917666
09/16 03:03:12 PM: edges-pos-ontonotes_acc: training: 0.802103 validation: 0.870557
09/16 03:03:12 PM: edges-pos-ontonotes_precision: training: 0.910554 validation: 0.944618
09/16 03:03:12 PM: edges-pos-ontonotes_recall: training: 0.848824 validation: 0.894716
09/16 03:03:12 PM: edges-pos-ontonotes_f1: training: 0.878606 validation: 0.918990
09/16 03:03:12 PM: Global learning rate: 2.5e-05
09/16 03:03:12 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 03:03:12 PM: Stopped training after 46 validation checks
09/16 03:03:12 PM: Trained edges-pos-ontonotes for 46000 batches or 13.318 epochs
09/16 03:03:12 PM: ***** VALIDATION RESULTS *****
09/16 03:03:12 PM: edges-pos-ontonotes_f1 (for best val pass 36): edges-pos-ontonotes_loss: 0.01003, macro_avg: 0.91923, micro_avg: 0.00000, edges-pos-ontonotes_mcc: 0.91788, edges-pos-ontonotes_acc: 0.87151, edges-pos-ontonotes_precision: 0.94372, edges-pos-ontonotes_recall: 0.89598, edges-pos-ontonotes_f1: 0.91923
09/16 03:03:12 PM: micro_avg (for best val pass 1): edges-pos-ontonotes_loss: 0.04512, macro_avg: 0.54095, micro_avg: 0.00000, edges-pos-ontonotes_mcc: 0.59069, edges-pos-ontonotes_acc: 0.37530, edges-pos-ontonotes_precision: 0.92883, edges-pos-ontonotes_recall: 0.38160, edges-pos-ontonotes_f1: 0.54095
09/16 03:03:12 PM: macro_avg (for best val pass 36): edges-pos-ontonotes_loss: 0.01003, macro_avg: 0.91923, micro_avg: 0.00000, edges-pos-ontonotes_mcc: 0.91788, edges-pos-ontonotes_acc: 0.87151, edges-pos-ontonotes_precision: 0.94372, edges-pos-ontonotes_recall: 0.89598, edges-pos-ontonotes_f1: 0.91923
09/16 03:03:12 PM: Evaluating...
09/16 03:03:12 PM: Loaded model state from ./experiments/pos-ontonotes-sts-top/run/edges-pos-ontonotes/model_state_target_train_val_36.best.th
09/16 03:03:12 PM: Evaluating on: edges-pos-ontonotes, split: val
09/16 03:03:42 PM: 	Task edges-pos-ontonotes: batch 155
09/16 03:04:12 PM: 	Task edges-pos-ontonotes: batch 281
09/16 03:04:43 PM: 	Task edges-pos-ontonotes: batch 460
09/16 03:04:45 PM: Task 'edges-pos-ontonotes': sorting predictions by 'idx'
09/16 03:04:45 PM: Finished evaluating on: edges-pos-ontonotes
09/16 03:04:46 PM: Task 'edges-pos-ontonotes': joining predictions with input split 'val'
09/16 03:04:57 PM: Task 'edges-pos-ontonotes': Wrote predictions to ./experiments/pos-ontonotes-sts-top/run
09/16 03:04:57 PM: Wrote all preds for split 'val' to ./experiments/pos-ontonotes-sts-top/run
09/16 03:04:57 PM: Evaluating on: edges-pos-ontonotes, split: test
09/16 03:05:27 PM: 	Task edges-pos-ontonotes: batch 150
09/16 03:05:57 PM: 	Task edges-pos-ontonotes: batch 251
09/16 03:06:15 PM: Task 'edges-pos-ontonotes': sorting predictions by 'idx'
09/16 03:06:15 PM: Finished evaluating on: edges-pos-ontonotes
09/16 03:06:15 PM: Task 'edges-pos-ontonotes': joining predictions with input split 'test'
09/16 03:06:24 PM: Task 'edges-pos-ontonotes': Wrote predictions to ./experiments/pos-ontonotes-sts-top/run
09/16 03:06:24 PM: Wrote all preds for split 'test' to ./experiments/pos-ontonotes-sts-top/run
09/16 03:06:24 PM: Writing results for split 'val' to ./experiments/pos-ontonotes-sts-top/results.tsv
09/16 03:06:24 PM: micro_avg: 0.000, macro_avg: 0.921, edges-pos-ontonotes_mcc: 0.920, edges-pos-ontonotes_acc: 0.875, edges-pos-ontonotes_precision: 0.942, edges-pos-ontonotes_recall: 0.901, edges-pos-ontonotes_f1: 0.921
09/16 03:06:25 PM: Done!
09/16 03:06:25 PM: Fatal error in main():
Traceback (most recent call last):
  File "main.py", line 16, in <module>
    main(sys.argv[1:])
  File "/srv/home/ericwallace/jiant/jiant/__main__.py", line 610, in main
    exit("Done exited")
  File "/home/ericwallace/miniconda3/envs/jiant/lib/python3.6/_sitebuiltins.py", line 26, in __call__
    raise SystemExit(code)
SystemExit: Done exited
=======
>>>>>>> 1ff7cb9943cafa999ead70f38407af315c736ff9
