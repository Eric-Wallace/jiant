09/16 03:11:38 AM: Git branch: master
09/16 03:11:38 AM: Git SHA: fb3796f035a61c062bc75b422b0939a7eeec20ff
09/16 03:11:38 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/pos-ontonotes-sts-b-top/",
  "exp_name": "experiments/pos-ontonotes-sts-b-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/pos-ontonotes-sts-b-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/sts-b",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/pos-ontonotes-sts-b-top__run",
  "run_dir": "./experiments/pos-ontonotes-sts-b-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-pos-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 03:11:38 AM: Saved config to ./experiments/pos-ontonotes-sts-b-top/run/params.conf
09/16 03:11:38 AM: Using random seed 1234
09/16 03:11:39 AM: Using GPU 0
09/16 03:11:39 AM: Loading tasks...
09/16 03:11:39 AM: Writing pre-preprocessed tasks to ./experiments/pos-ontonotes-sts-b-top/
09/16 03:11:39 AM: 	Creating task edges-pos-ontonotes from scratch.
09/16 03:11:56 AM: Read=110514, Skip=5298, Total=115812 from ./probing_data/edges/ontonotes/const/pos/train.json.retokenized.bert-base-uncased
09/16 03:11:57 AM: Read=15060, Skip=620, Total=15680 from ./probing_data/edges/ontonotes/const/pos/development.json.retokenized.bert-base-uncased
09/16 03:12:00 AM: Read=11462, Skip=755, Total=12217 from ./probing_data/edges/ontonotes/const/pos/test.json.retokenized.bert-base-uncased
09/16 03:12:10 AM: 	Task 'edges-pos-ontonotes': |train|=110514 |val|=15060 |test|=11462
09/16 03:12:10 AM: 	Finished loading tasks: edges-pos-ontonotes.
09/16 03:12:10 AM: 	Building vocab from scratch.
09/16 03:12:10 AM: 	Counting units for task edges-pos-ontonotes.
09/16 03:12:12 AM: 	Task 'edges-pos-ontonotes': adding vocab namespace 'edges-pos-ontonotes_labels'
09/16 03:12:13 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 03:12:13 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 03:12:13 AM: 	Saved vocab to ./experiments/pos-ontonotes-sts-b-top/vocab
09/16 03:12:13 AM: Loading token dictionary from ./experiments/pos-ontonotes-sts-b-top/vocab.
09/16 03:12:13 AM: 	Loaded vocab from ./experiments/pos-ontonotes-sts-b-top/vocab
09/16 03:12:13 AM: 	Vocab namespace bert_uncased: size 30524
09/16 03:12:13 AM: 	Vocab namespace tokens: size 24015
09/16 03:12:13 AM: 	Vocab namespace edges-pos-ontonotes_labels: size 48
09/16 03:12:13 AM: 	Vocab namespace chars: size 81
09/16 03:12:13 AM: 	Finished building vocab.
09/16 03:12:13 AM: 	Task edges-pos-ontonotes (train): Indexing from scratch.
09/16 03:12:42 AM: 	Task edges-pos-ontonotes (train): Saved 110514 instances to ./experiments/pos-ontonotes-sts-b-top/preproc/edges-pos-ontonotes__train_data
09/16 03:12:42 AM: 	Task edges-pos-ontonotes (val): Indexing from scratch.
09/16 03:12:46 AM: 	Task edges-pos-ontonotes (val): Saved 15060 instances to ./experiments/pos-ontonotes-sts-b-top/preproc/edges-pos-ontonotes__val_data
09/16 03:12:46 AM: 	Task edges-pos-ontonotes (test): Indexing from scratch.
09/16 03:12:49 AM: 	Task edges-pos-ontonotes (test): Saved 11462 instances to ./experiments/pos-ontonotes-sts-b-top/preproc/edges-pos-ontonotes__test_data
09/16 03:12:49 AM: 	Finished indexing tasks
09/16 03:12:49 AM: 	Creating trimmed target-only version of edges-pos-ontonotes train.
09/16 03:12:49 AM: 	  Training on 
09/16 03:12:49 AM: 	  Evaluating on edges-pos-ontonotes
09/16 03:12:49 AM: 	Finished loading tasks in 70.481s
09/16 03:12:49 AM: 	 Tasks: ['edges-pos-ontonotes']
09/16 03:12:49 AM: Building model...
09/16 03:12:49 AM: Using BERT model (bert-base-uncased).
09/16 03:12:49 AM: LOADING A FUNETUNED MODEL from: 
09/16 03:12:49 AM: models/sts-b
09/16 03:12:49 AM: loading configuration file models/sts-b/config.json
09/16 03:12:49 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "sts-b",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 03:12:49 AM: loading weights file models/sts-b/pytorch_model.bin
09/16 03:12:53 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp_0f4wqur
09/16 03:12:56 AM: copying /tmp/tmp_0f4wqur to cache at ./experiments/pos-ontonotes-sts-b-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 03:12:56 AM: creating metadata file for ./experiments/pos-ontonotes-sts-b-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 03:12:56 AM: removing temp file /tmp/tmp_0f4wqur
09/16 03:12:56 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/pos-ontonotes-sts-b-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 03:12:56 AM: Initializing parameters
09/16 03:12:56 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 03:12:56 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 03:12:56 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 03:12:56 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 03:12:56 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 03:12:56 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 03:12:56 AM: 	Task 'edges-pos-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-pos-ontonotes"
}
09/16 03:13:01 AM: Model specification:
09/16 03:13:01 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-pos-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=48, bias=True)
    )
  )
)
09/16 03:13:01 AM: Model parameters:
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 03:13:01 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 03:13:01 AM: 	edges-pos-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 03:13:01 AM: 	edges-pos-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 03:13:01 AM: 	edges-pos-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 24576 with torch.Size([48, 512])
09/16 03:13:01 AM: 	edges-pos-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 48 with torch.Size([48])
09/16 03:13:01 AM: Total number of parameters: 109703728 (1.09704e+08)
09/16 03:13:01 AM: Number of trainable parameters: 221488 (221488)
09/16 03:13:01 AM: Finished building model in 11.360s
09/16 03:13:01 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-pos-ontonotes 

09/16 03:14:02 AM: patience = 9
09/16 03:14:02 AM: val_interval = 1000
09/16 03:14:02 AM: max_vals = 250
09/16 03:14:02 AM: cuda_device = 0
09/16 03:14:02 AM: grad_norm = 5.0
09/16 03:14:02 AM: grad_clipping = None
09/16 03:14:02 AM: lr_decay = 0.99
09/16 03:14:02 AM: min_lr = 1e-06
09/16 03:14:02 AM: keep_all_checkpoints = 0
09/16 03:14:02 AM: val_data_limit = 5000
09/16 03:14:02 AM: max_epochs = -1
09/16 03:14:02 AM: dec_val_scale = 250
09/16 03:14:02 AM: training_data_fraction = 1
09/16 03:14:02 AM: type = adam
09/16 03:14:02 AM: parameter_groups = None
09/16 03:14:02 AM: Number of trainable parameters: 221488
09/16 03:14:02 AM: infer_type_and_cast = True
09/16 03:14:02 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 03:14:02 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 03:14:02 AM: lr = 0.0001
09/16 03:14:02 AM: amsgrad = True
09/16 03:14:02 AM: type = reduce_on_plateau
09/16 03:14:02 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 03:14:02 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 03:14:02 AM: mode = max
09/16 03:14:02 AM: factor = 0.5
09/16 03:14:02 AM: patience = 3
09/16 03:14:02 AM: threshold = 0.0001
09/16 03:14:02 AM: threshold_mode = abs
09/16 03:14:02 AM: verbose = True
09/16 03:14:02 AM: type = adam
09/16 03:14:02 AM: parameter_groups = None
09/16 03:14:02 AM: Number of trainable parameters: 221488
09/16 03:14:02 AM: infer_type_and_cast = True
09/16 03:14:02 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 03:14:02 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 03:14:02 AM: lr = 0.0001
09/16 03:14:02 AM: amsgrad = True
09/16 03:14:02 AM: type = reduce_on_plateau
09/16 03:14:02 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 03:14:02 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 03:14:02 AM: mode = max
09/16 03:14:02 AM: factor = 0.5
09/16 03:14:02 AM: patience = 3
09/16 03:14:02 AM: threshold = 0.0001
09/16 03:14:02 AM: threshold_mode = abs
09/16 03:14:02 AM: verbose = True
09/16 03:14:02 AM: Starting training without restoring from a checkpoint.
09/16 03:14:02 AM: Training examples per task, before any subsampling: {'edges-pos-ontonotes': 110514}
09/16 03:14:02 AM: Beginning training with stopping criteria based on metric: edges-pos-ontonotes_f1
09/16 03:14:12 AM: Update 71: task edges-pos-ontonotes, batch 71 (71): mcc: 0.0102, acc: 0.0017, precision: 0.0255, recall: 0.1072, f1: 0.0412, edges-pos-ontonotes_loss: 0.3182
09/16 03:14:22 AM: Update 160: task edges-pos-ontonotes, batch 160 (160): mcc: 0.0069, acc: 0.0010, precision: 0.0256, recall: 0.0495, f1: 0.0338, edges-pos-ontonotes_loss: 0.1894
09/16 03:14:32 AM: Update 242: task edges-pos-ontonotes, batch 242 (242): mcc: 0.0091, acc: 0.0047, precision: 0.0287, recall: 0.0361, f1: 0.0320, edges-pos-ontonotes_loss: 0.1517
09/16 03:14:42 AM: Update 314: task edges-pos-ontonotes, batch 314 (314): mcc: 0.0203, acc: 0.0159, precision: 0.0409, recall: 0.0401, f1: 0.0405, edges-pos-ontonotes_loss: 0.1340
09/16 03:14:53 AM: Update 382: task edges-pos-ontonotes, batch 382 (382): mcc: 0.0247, acc: 0.0184, precision: 0.0486, recall: 0.0371, f1: 0.0421, edges-pos-ontonotes_loss: 0.1235
09/16 03:15:03 AM: Update 457: task edges-pos-ontonotes, batch 457 (457): mcc: 0.0335, acc: 0.0239, precision: 0.0624, recall: 0.0392, f1: 0.0482, edges-pos-ontonotes_loss: 0.1146
09/16 03:15:13 AM: Update 523: task edges-pos-ontonotes, batch 523 (523): mcc: 0.0446, acc: 0.0303, precision: 0.0803, recall: 0.0436, f1: 0.0566, edges-pos-ontonotes_loss: 0.1085
09/16 03:15:23 AM: Update 593: task edges-pos-ontonotes, batch 593 (593): mcc: 0.0605, acc: 0.0396, precision: 0.1063, recall: 0.0516, f1: 0.0695, edges-pos-ontonotes_loss: 0.1030
09/16 03:15:33 AM: Update 641: task edges-pos-ontonotes, batch 641 (641): mcc: 0.0770, acc: 0.0492, precision: 0.1333, recall: 0.0606, f1: 0.0833, edges-pos-ontonotes_loss: 0.0998
09/16 03:15:44 AM: Update 692: task edges-pos-ontonotes, batch 692 (692): mcc: 0.1009, acc: 0.0629, precision: 0.1732, recall: 0.0738, f1: 0.1035, edges-pos-ontonotes_loss: 0.0968
09/16 03:15:54 AM: Update 743: task edges-pos-ontonotes, batch 743 (743): mcc: 0.1257, acc: 0.0771, precision: 0.2149, recall: 0.0876, f1: 0.1244, edges-pos-ontonotes_loss: 0.0941
09/16 03:16:04 AM: Update 804: task edges-pos-ontonotes, batch 804 (804): mcc: 0.1513, acc: 0.0920, precision: 0.2578, recall: 0.1021, f1: 0.1463, edges-pos-ontonotes_loss: 0.0912
09/16 03:16:14 AM: Update 863: task edges-pos-ontonotes, batch 863 (863): mcc: 0.1747, acc: 0.1056, precision: 0.2967, recall: 0.1155, f1: 0.1663, edges-pos-ontonotes_loss: 0.0885
09/16 03:16:24 AM: Update 911: task edges-pos-ontonotes, batch 911 (911): mcc: 0.1995, acc: 0.1206, precision: 0.3371, recall: 0.1303, f1: 0.1880, edges-pos-ontonotes_loss: 0.0865
09/16 03:16:34 AM: Update 951: task edges-pos-ontonotes, batch 951 (951): mcc: 0.2169, acc: 0.1310, precision: 0.3654, recall: 0.1407, f1: 0.2031, edges-pos-ontonotes_loss: 0.0849
09/16 03:16:44 AM: ***** Step 1000 / Validation 1 *****
09/16 03:16:44 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:16:44 AM: Validating...
09/16 03:16:44 AM: Evaluate: task edges-pos-ontonotes, batch 2 (157): mcc: 0.6384, acc: 0.4359, precision: 0.9387, recall: 0.4403, f1: 0.5994, edges-pos-ontonotes_loss: 0.0405
09/16 03:16:54 AM: Evaluate: task edges-pos-ontonotes, batch 68 (157): mcc: 0.5412, acc: 0.3102, precision: 0.9496, recall: 0.3135, f1: 0.4714, edges-pos-ontonotes_loss: 0.0479
09/16 03:17:05 AM: Evaluate: task edges-pos-ontonotes, batch 117 (157): mcc: 0.5781, acc: 0.3586, precision: 0.9336, recall: 0.3638, f1: 0.5235, edges-pos-ontonotes_loss: 0.0457
09/16 03:17:13 AM: Best result seen so far for edges-pos-ontonotes.
09/16 03:17:13 AM: Best result seen so far for micro.
09/16 03:17:13 AM: Best result seen so far for macro.
09/16 03:17:13 AM: Updating LR scheduler:
09/16 03:17:13 AM: 	Best result seen so far for macro_avg: 0.541
09/16 03:17:13 AM: 	# validation passes without improvement: 0
09/16 03:17:13 AM: edges-pos-ontonotes_loss: training: 0.083116 validation: 0.045122
09/16 03:17:13 AM: macro_avg: validation: 0.540954
09/16 03:17:13 AM: micro_avg: validation: 0.000000
09/16 03:17:13 AM: edges-pos-ontonotes_mcc: training: 0.238055 validation: 0.590688
09/16 03:17:13 AM: edges-pos-ontonotes_acc: training: 0.143936 validation: 0.375303
09/16 03:17:13 AM: edges-pos-ontonotes_precision: training: 0.398862 validation: 0.928831
09/16 03:17:13 AM: edges-pos-ontonotes_recall: training: 0.153633 validation: 0.381599
09/16 03:17:13 AM: edges-pos-ontonotes_f1: training: 0.221824 validation: 0.540954
09/16 03:17:13 AM: Global learning rate: 0.0001
09/16 03:17:13 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:17:15 AM: Update 1005: task edges-pos-ontonotes, batch 5 (1005): mcc: 0.5525, acc: 0.3364, precision: 0.9022, recall: 0.3444, f1: 0.4985, edges-pos-ontonotes_loss: 0.0470
09/16 03:17:25 AM: Update 1058: task edges-pos-ontonotes, batch 58 (1058): mcc: 0.5761, acc: 0.3630, precision: 0.9064, recall: 0.3723, f1: 0.5278, edges-pos-ontonotes_loss: 0.0461
09/16 03:17:35 AM: Update 1110: task edges-pos-ontonotes, batch 110 (1110): mcc: 0.5895, acc: 0.3792, precision: 0.9071, recall: 0.3894, f1: 0.5449, edges-pos-ontonotes_loss: 0.0449
09/16 03:17:45 AM: Update 1162: task edges-pos-ontonotes, batch 162 (1162): mcc: 0.5986, acc: 0.3909, precision: 0.9076, recall: 0.4013, f1: 0.5565, edges-pos-ontonotes_loss: 0.0440
09/16 03:17:55 AM: Update 1216: task edges-pos-ontonotes, batch 216 (1216): mcc: 0.6082, acc: 0.4030, precision: 0.9085, recall: 0.4136, f1: 0.5684, edges-pos-ontonotes_loss: 0.0432
09/16 03:18:12 AM: Update 1253: task edges-pos-ontonotes, batch 253 (1253): mcc: 0.6142, acc: 0.4108, precision: 0.9090, recall: 0.4215, f1: 0.5760, edges-pos-ontonotes_loss: 0.0427
09/16 03:18:22 AM: Update 1308: task edges-pos-ontonotes, batch 308 (1308): mcc: 0.6205, acc: 0.4189, precision: 0.9096, recall: 0.4298, f1: 0.5838, edges-pos-ontonotes_loss: 0.0420
09/16 03:18:32 AM: Update 1362: task edges-pos-ontonotes, batch 362 (1362): mcc: 0.6276, acc: 0.4283, precision: 0.9099, recall: 0.4395, f1: 0.5927, edges-pos-ontonotes_loss: 0.0413
09/16 03:18:43 AM: Update 1417: task edges-pos-ontonotes, batch 417 (1417): mcc: 0.6348, acc: 0.4376, precision: 0.9105, recall: 0.4492, f1: 0.6016, edges-pos-ontonotes_loss: 0.0406
09/16 03:18:53 AM: Update 1465: task edges-pos-ontonotes, batch 465 (1465): mcc: 0.6419, acc: 0.4471, precision: 0.9105, recall: 0.4592, f1: 0.6105, edges-pos-ontonotes_loss: 0.0400
09/16 03:19:03 AM: Update 1519: task edges-pos-ontonotes, batch 519 (1519): mcc: 0.6484, acc: 0.4557, precision: 0.9109, recall: 0.4682, f1: 0.6185, edges-pos-ontonotes_loss: 0.0394
09/16 03:19:13 AM: Update 1566: task edges-pos-ontonotes, batch 566 (1566): mcc: 0.6530, acc: 0.4622, precision: 0.9110, recall: 0.4748, f1: 0.6243, edges-pos-ontonotes_loss: 0.0389
09/16 03:19:24 AM: Update 1614: task edges-pos-ontonotes, batch 614 (1614): mcc: 0.6582, acc: 0.4692, precision: 0.9110, recall: 0.4823, f1: 0.6307, edges-pos-ontonotes_loss: 0.0384
09/16 03:19:34 AM: Update 1662: task edges-pos-ontonotes, batch 662 (1662): mcc: 0.6636, acc: 0.4768, precision: 0.9109, recall: 0.4903, f1: 0.6375, edges-pos-ontonotes_loss: 0.0379
09/16 03:19:44 AM: Update 1715: task edges-pos-ontonotes, batch 715 (1715): mcc: 0.6689, acc: 0.4841, precision: 0.9109, recall: 0.4981, f1: 0.6440, edges-pos-ontonotes_loss: 0.0374
09/16 03:19:54 AM: Update 1769: task edges-pos-ontonotes, batch 769 (1769): mcc: 0.6738, acc: 0.4909, precision: 0.9106, recall: 0.5054, f1: 0.6500, edges-pos-ontonotes_loss: 0.0369
09/16 03:20:04 AM: Update 1824: task edges-pos-ontonotes, batch 824 (1824): mcc: 0.6783, acc: 0.4972, precision: 0.9105, recall: 0.5121, f1: 0.6555, edges-pos-ontonotes_loss: 0.0365
09/16 03:20:14 AM: Update 1872: task edges-pos-ontonotes, batch 872 (1872): mcc: 0.6830, acc: 0.5039, precision: 0.9105, recall: 0.5192, f1: 0.6613, edges-pos-ontonotes_loss: 0.0360
09/16 03:20:24 AM: Update 1911: task edges-pos-ontonotes, batch 911 (1911): mcc: 0.6862, acc: 0.5086, precision: 0.9098, recall: 0.5244, f1: 0.6653, edges-pos-ontonotes_loss: 0.0358
09/16 03:20:34 AM: Update 1974: task edges-pos-ontonotes, batch 974 (1974): mcc: 0.6898, acc: 0.5139, precision: 0.9093, recall: 0.5302, f1: 0.6698, edges-pos-ontonotes_loss: 0.0354
09/16 03:20:38 AM: ***** Step 2000 / Validation 2 *****
09/16 03:20:38 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:20:38 AM: Validating...
09/16 03:20:44 AM: Evaluate: task edges-pos-ontonotes, batch 37 (157): mcc: 0.7276, acc: 0.5698, precision: 0.9210, recall: 0.5815, f1: 0.7129, edges-pos-ontonotes_loss: 0.0319
09/16 03:20:54 AM: Evaluate: task edges-pos-ontonotes, batch 98 (157): mcc: 0.7607, acc: 0.6227, precision: 0.9152, recall: 0.6389, f1: 0.7525, edges-pos-ontonotes_loss: 0.0298
09/16 03:21:05 AM: Evaluate: task edges-pos-ontonotes, batch 142 (157): mcc: 0.7795, acc: 0.6526, precision: 0.9093, recall: 0.6747, f1: 0.7746, edges-pos-ontonotes_loss: 0.0283
09/16 03:21:08 AM: Best result seen so far for edges-pos-ontonotes.
09/16 03:21:08 AM: Best result seen so far for macro.
09/16 03:21:08 AM: Updating LR scheduler:
09/16 03:21:08 AM: 	Best result seen so far for macro_avg: 0.779
09/16 03:21:08 AM: 	# validation passes without improvement: 0
09/16 03:21:08 AM: edges-pos-ontonotes_loss: training: 0.035201 validation: 0.027865
09/16 03:21:08 AM: macro_avg: validation: 0.778787
09/16 03:21:08 AM: micro_avg: validation: 0.000000
09/16 03:21:08 AM: edges-pos-ontonotes_mcc: training: 0.691180 validation: 0.783251
09/16 03:21:08 AM: edges-pos-ontonotes_acc: training: 0.515858 validation: 0.658084
09/16 03:21:08 AM: edges-pos-ontonotes_precision: training: 0.909249 validation: 0.909942
09/16 03:21:08 AM: edges-pos-ontonotes_recall: training: 0.532305 validation: 0.680678
09/16 03:21:08 AM: edges-pos-ontonotes_f1: training: 0.671494 validation: 0.778787
09/16 03:21:08 AM: Global learning rate: 0.0001
09/16 03:21:08 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:21:15 AM: Update 2046: task edges-pos-ontonotes, batch 46 (2046): mcc: 0.7630, acc: 0.6231, precision: 0.9104, recall: 0.6461, f1: 0.7558, edges-pos-ontonotes_loss: 0.0289
09/16 03:21:25 AM: Update 2106: task edges-pos-ontonotes, batch 106 (2106): mcc: 0.7657, acc: 0.6281, precision: 0.9060, recall: 0.6538, f1: 0.7595, edges-pos-ontonotes_loss: 0.0282
09/16 03:21:35 AM: Update 2165: task edges-pos-ontonotes, batch 165 (2165): mcc: 0.7704, acc: 0.6352, precision: 0.9059, recall: 0.6619, f1: 0.7649, edges-pos-ontonotes_loss: 0.0277
09/16 03:21:45 AM: Update 2224: task edges-pos-ontonotes, batch 224 (2224): mcc: 0.7713, acc: 0.6364, precision: 0.9066, recall: 0.6629, f1: 0.7658, edges-pos-ontonotes_loss: 0.0274
09/16 03:21:55 AM: Update 2301: task edges-pos-ontonotes, batch 301 (2301): mcc: 0.7741, acc: 0.6394, precision: 0.9100, recall: 0.6651, f1: 0.7685, edges-pos-ontonotes_loss: 0.0269
09/16 03:22:05 AM: Update 2378: task edges-pos-ontonotes, batch 378 (2378): mcc: 0.7775, acc: 0.6437, precision: 0.9122, recall: 0.6691, f1: 0.7720, edges-pos-ontonotes_loss: 0.0264
09/16 03:22:15 AM: Update 2457: task edges-pos-ontonotes, batch 457 (2457): mcc: 0.7811, acc: 0.6484, precision: 0.9142, recall: 0.6737, f1: 0.7758, edges-pos-ontonotes_loss: 0.0259
09/16 03:22:26 AM: Update 2527: task edges-pos-ontonotes, batch 527 (2527): mcc: 0.7836, acc: 0.6519, precision: 0.9154, recall: 0.6772, f1: 0.7785, edges-pos-ontonotes_loss: 0.0257
09/16 03:22:36 AM: Update 2624: task edges-pos-ontonotes, batch 624 (2624): mcc: 0.7863, acc: 0.6555, precision: 0.9172, recall: 0.6804, f1: 0.7812, edges-pos-ontonotes_loss: 0.0257
09/16 03:22:46 AM: Update 2730: task edges-pos-ontonotes, batch 730 (2730): mcc: 0.7892, acc: 0.6598, precision: 0.9182, recall: 0.6846, f1: 0.7844, edges-pos-ontonotes_loss: 0.0254
09/16 03:22:56 AM: Update 2819: task edges-pos-ontonotes, batch 819 (2819): mcc: 0.7920, acc: 0.6641, precision: 0.9188, recall: 0.6890, f1: 0.7875, edges-pos-ontonotes_loss: 0.0251
09/16 03:23:06 AM: Update 2933: task edges-pos-ontonotes, batch 933 (2933): mcc: 0.7902, acc: 0.6616, precision: 0.9176, recall: 0.6869, f1: 0.7856, edges-pos-ontonotes_loss: 0.0253
09/16 03:23:12 AM: ***** Step 3000 / Validation 3 *****
09/16 03:23:12 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:23:12 AM: Validating...
09/16 03:23:16 AM: Evaluate: task edges-pos-ontonotes, batch 23 (157): mcc: 0.8092, acc: 0.7003, precision: 0.9042, recall: 0.7305, f1: 0.8081, edges-pos-ontonotes_loss: 0.0230
09/16 03:23:26 AM: Evaluate: task edges-pos-ontonotes, batch 79 (157): mcc: 0.8247, acc: 0.7217, precision: 0.9087, recall: 0.7544, f1: 0.8244, edges-pos-ontonotes_loss: 0.0218
09/16 03:23:36 AM: Evaluate: task edges-pos-ontonotes, batch 126 (157): mcc: 0.8282, acc: 0.7295, precision: 0.8957, recall: 0.7719, f1: 0.8292, edges-pos-ontonotes_loss: 0.0218
09/16 03:23:43 AM: Best result seen so far for edges-pos-ontonotes.
09/16 03:23:43 AM: Best result seen so far for macro.
09/16 03:23:43 AM: Updating LR scheduler:
09/16 03:23:43 AM: 	Best result seen so far for macro_avg: 0.832
09/16 03:23:43 AM: 	# validation passes without improvement: 0
09/16 03:23:43 AM: edges-pos-ontonotes_loss: training: 0.025215 validation: 0.021723
09/16 03:23:43 AM: macro_avg: validation: 0.832484
09/16 03:23:43 AM: micro_avg: validation: 0.000000
09/16 03:23:43 AM: edges-pos-ontonotes_mcc: training: 0.789768 validation: 0.831127
09/16 03:23:43 AM: edges-pos-ontonotes_acc: training: 0.661002 validation: 0.734743
09/16 03:23:43 AM: edges-pos-ontonotes_precision: training: 0.917022 validation: 0.892592
09/16 03:23:43 AM: edges-pos-ontonotes_recall: training: 0.686452 validation: 0.779961
09/16 03:23:43 AM: edges-pos-ontonotes_f1: training: 0.785160 validation: 0.832484
09/16 03:23:43 AM: Global learning rate: 0.0001
09/16 03:23:43 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:23:46 AM: Update 3035: task edges-pos-ontonotes, batch 35 (3035): mcc: 0.7817, acc: 0.6530, precision: 0.8995, recall: 0.6860, f1: 0.7784, edges-pos-ontonotes_loss: 0.0253
09/16 03:23:57 AM: Update 3131: task edges-pos-ontonotes, batch 131 (3131): mcc: 0.7874, acc: 0.6608, precision: 0.9006, recall: 0.6950, f1: 0.7846, edges-pos-ontonotes_loss: 0.0242
09/16 03:24:07 AM: Update 3183: task edges-pos-ontonotes, batch 183 (3183): mcc: 0.7865, acc: 0.6620, precision: 0.8909, recall: 0.7012, f1: 0.7847, edges-pos-ontonotes_loss: 0.0247
09/16 03:24:17 AM: Update 3236: task edges-pos-ontonotes, batch 236 (3236): mcc: 0.7861, acc: 0.6619, precision: 0.8896, recall: 0.7015, f1: 0.7844, edges-pos-ontonotes_loss: 0.0251
09/16 03:24:27 AM: Update 3292: task edges-pos-ontonotes, batch 292 (3292): mcc: 0.7873, acc: 0.6640, precision: 0.8897, recall: 0.7035, f1: 0.7857, edges-pos-ontonotes_loss: 0.0253
09/16 03:24:37 AM: Update 3349: task edges-pos-ontonotes, batch 349 (3349): mcc: 0.7878, acc: 0.6650, precision: 0.8897, recall: 0.7045, f1: 0.7863, edges-pos-ontonotes_loss: 0.0254
09/16 03:24:47 AM: Update 3411: task edges-pos-ontonotes, batch 411 (3411): mcc: 0.7890, acc: 0.6668, precision: 0.8905, recall: 0.7059, f1: 0.7875, edges-pos-ontonotes_loss: 0.0252
09/16 03:25:05 AM: Update 3461: task edges-pos-ontonotes, batch 461 (3461): mcc: 0.7891, acc: 0.6671, precision: 0.8907, recall: 0.7059, f1: 0.7876, edges-pos-ontonotes_loss: 0.0251
09/16 03:25:15 AM: Update 3551: task edges-pos-ontonotes, batch 551 (3551): mcc: 0.7895, acc: 0.6670, precision: 0.8933, recall: 0.7044, f1: 0.7877, edges-pos-ontonotes_loss: 0.0249
09/16 03:25:25 AM: Update 3638: task edges-pos-ontonotes, batch 638 (3638): mcc: 0.7906, acc: 0.6684, precision: 0.8949, recall: 0.7052, f1: 0.7888, edges-pos-ontonotes_loss: 0.0245
09/16 03:25:35 AM: Update 3718: task edges-pos-ontonotes, batch 718 (3718): mcc: 0.7918, acc: 0.6698, precision: 0.8960, recall: 0.7063, f1: 0.7899, edges-pos-ontonotes_loss: 0.0242
09/16 03:25:45 AM: Update 3790: task edges-pos-ontonotes, batch 790 (3790): mcc: 0.7935, acc: 0.6724, precision: 0.8966, recall: 0.7089, f1: 0.7918, edges-pos-ontonotes_loss: 0.0239
09/16 03:25:55 AM: Update 3855: task edges-pos-ontonotes, batch 855 (3855): mcc: 0.7958, acc: 0.6760, precision: 0.8969, recall: 0.7127, f1: 0.7943, edges-pos-ontonotes_loss: 0.0237
09/16 03:26:06 AM: Update 3922: task edges-pos-ontonotes, batch 922 (3922): mcc: 0.7980, acc: 0.6794, precision: 0.8971, recall: 0.7164, f1: 0.7966, edges-pos-ontonotes_loss: 0.0235
09/16 03:26:16 AM: ***** Step 4000 / Validation 4 *****
09/16 03:26:16 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:26:16 AM: Validating...
09/16 03:26:16 AM: Evaluate: task edges-pos-ontonotes, batch 1 (157): mcc: 0.8590, acc: 0.7717, precision: 0.9393, recall: 0.7905, f1: 0.8585, edges-pos-ontonotes_loss: 0.0166
09/16 03:26:26 AM: Evaluate: task edges-pos-ontonotes, batch 65 (157): mcc: 0.8552, acc: 0.7662, precision: 0.9351, recall: 0.7870, f1: 0.8547, edges-pos-ontonotes_loss: 0.0176
09/16 03:26:36 AM: Evaluate: task edges-pos-ontonotes, batch 113 (157): mcc: 0.8593, acc: 0.7753, precision: 0.9254, recall: 0.8029, f1: 0.8598, edges-pos-ontonotes_loss: 0.0173
09/16 03:26:46 AM: Evaluate: task edges-pos-ontonotes, batch 155 (157): mcc: 0.8591, acc: 0.7765, precision: 0.9188, recall: 0.8083, f1: 0.8600, edges-pos-ontonotes_loss: 0.0175
09/16 03:26:46 AM: Best result seen so far for edges-pos-ontonotes.
09/16 03:26:46 AM: Best result seen so far for macro.
09/16 03:26:46 AM: Updating LR scheduler:
09/16 03:26:46 AM: 	Best result seen so far for macro_avg: 0.860
09/16 03:26:46 AM: 	# validation passes without improvement: 0
09/16 03:26:46 AM: edges-pos-ontonotes_loss: training: 0.023207 validation: 0.017472
09/16 03:26:46 AM: macro_avg: validation: 0.860186
09/16 03:26:46 AM: micro_avg: validation: 0.000000
09/16 03:26:46 AM: edges-pos-ontonotes_mcc: training: 0.799741 validation: 0.859237
09/16 03:26:46 AM: edges-pos-ontonotes_acc: training: 0.682009 validation: 0.776638
09/16 03:26:46 AM: edges-pos-ontonotes_precision: training: 0.897423 validation: 0.918984
09/16 03:26:46 AM: edges-pos-ontonotes_recall: training: 0.719197 validation: 0.808460
09/16 03:26:46 AM: edges-pos-ontonotes_f1: training: 0.798486 validation: 0.860186
09/16 03:26:46 AM: Global learning rate: 0.0001
09/16 03:26:46 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:26:56 AM: Update 4062: task edges-pos-ontonotes, batch 62 (4062): mcc: 0.8237, acc: 0.7184, precision: 0.9023, recall: 0.7580, f1: 0.8239, edges-pos-ontonotes_loss: 0.0203
09/16 03:27:06 AM: Update 4108: task edges-pos-ontonotes, batch 108 (4108): mcc: 0.8212, acc: 0.7166, precision: 0.8981, recall: 0.7570, f1: 0.8215, edges-pos-ontonotes_loss: 0.0207
09/16 03:27:17 AM: Update 4163: task edges-pos-ontonotes, batch 163 (4163): mcc: 0.8183, acc: 0.7136, precision: 0.8945, recall: 0.7548, f1: 0.8187, edges-pos-ontonotes_loss: 0.0213
09/16 03:27:27 AM: Update 4220: task edges-pos-ontonotes, batch 220 (4220): mcc: 0.8188, acc: 0.7144, precision: 0.8953, recall: 0.7551, f1: 0.8192, edges-pos-ontonotes_loss: 0.0214
09/16 03:27:37 AM: Update 4278: task edges-pos-ontonotes, batch 278 (4278): mcc: 0.8196, acc: 0.7154, precision: 0.8959, recall: 0.7560, f1: 0.8200, edges-pos-ontonotes_loss: 0.0213
09/16 03:27:47 AM: Update 4334: task edges-pos-ontonotes, batch 334 (4334): mcc: 0.8198, acc: 0.7157, precision: 0.8958, recall: 0.7565, f1: 0.8202, edges-pos-ontonotes_loss: 0.0213
09/16 03:27:57 AM: Update 4384: task edges-pos-ontonotes, batch 384 (4384): mcc: 0.8203, acc: 0.7165, precision: 0.8964, recall: 0.7569, f1: 0.8208, edges-pos-ontonotes_loss: 0.0212
09/16 03:28:07 AM: Update 4423: task edges-pos-ontonotes, batch 423 (4423): mcc: 0.8202, acc: 0.7162, precision: 0.8956, recall: 0.7573, f1: 0.8207, edges-pos-ontonotes_loss: 0.0212
09/16 03:28:17 AM: Update 4478: task edges-pos-ontonotes, batch 478 (4478): mcc: 0.8209, acc: 0.7173, precision: 0.8957, recall: 0.7586, f1: 0.8215, edges-pos-ontonotes_loss: 0.0211
09/16 03:28:27 AM: Update 4527: task edges-pos-ontonotes, batch 527 (4527): mcc: 0.8220, acc: 0.7189, precision: 0.8962, recall: 0.7601, f1: 0.8225, edges-pos-ontonotes_loss: 0.0210
09/16 03:28:37 AM: Update 4578: task edges-pos-ontonotes, batch 578 (4578): mcc: 0.8228, acc: 0.7203, precision: 0.8965, recall: 0.7612, f1: 0.8234, edges-pos-ontonotes_loss: 0.0209
09/16 03:28:48 AM: Update 4630: task edges-pos-ontonotes, batch 630 (4630): mcc: 0.8240, acc: 0.7220, precision: 0.8974, recall: 0.7626, f1: 0.8246, edges-pos-ontonotes_loss: 0.0208
09/16 03:28:58 AM: Update 4679: task edges-pos-ontonotes, batch 679 (4679): mcc: 0.8249, acc: 0.7235, precision: 0.8981, recall: 0.7638, f1: 0.8255, edges-pos-ontonotes_loss: 0.0207
09/16 03:29:08 AM: Update 4719: task edges-pos-ontonotes, batch 719 (4719): mcc: 0.8251, acc: 0.7239, precision: 0.8984, recall: 0.7640, f1: 0.8257, edges-pos-ontonotes_loss: 0.0206
09/16 03:29:18 AM: Update 4767: task edges-pos-ontonotes, batch 767 (4767): mcc: 0.8259, acc: 0.7251, precision: 0.8988, recall: 0.7649, f1: 0.8265, edges-pos-ontonotes_loss: 0.0206
09/16 03:29:28 AM: Update 4817: task edges-pos-ontonotes, batch 817 (4817): mcc: 0.8267, acc: 0.7265, precision: 0.8996, recall: 0.7658, f1: 0.8273, edges-pos-ontonotes_loss: 0.0205
09/16 03:29:38 AM: Update 4868: task edges-pos-ontonotes, batch 868 (4868): mcc: 0.8276, acc: 0.7277, precision: 0.9002, recall: 0.7668, f1: 0.8282, edges-pos-ontonotes_loss: 0.0204
09/16 03:29:49 AM: Update 4924: task edges-pos-ontonotes, batch 924 (4924): mcc: 0.8283, acc: 0.7288, precision: 0.9006, recall: 0.7677, f1: 0.8289, edges-pos-ontonotes_loss: 0.0203
09/16 03:29:59 AM: Update 4976: task edges-pos-ontonotes, batch 976 (4976): mcc: 0.8290, acc: 0.7300, precision: 0.9010, recall: 0.7688, f1: 0.8297, edges-pos-ontonotes_loss: 0.0202
09/16 03:30:04 AM: ***** Step 5000 / Validation 5 *****
09/16 03:30:04 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:30:04 AM: Validating...
09/16 03:30:09 AM: Evaluate: task edges-pos-ontonotes, batch 28 (157): mcc: 0.8547, acc: 0.7682, precision: 0.9358, recall: 0.7857, f1: 0.8542, edges-pos-ontonotes_loss: 0.0171
09/16 03:30:19 AM: Evaluate: task edges-pos-ontonotes, batch 89 (157): mcc: 0.8649, acc: 0.7828, precision: 0.9365, recall: 0.8035, f1: 0.8649, edges-pos-ontonotes_loss: 0.0163
09/16 03:30:29 AM: Evaluate: task edges-pos-ontonotes, batch 133 (157): mcc: 0.8691, acc: 0.7919, precision: 0.9300, recall: 0.8169, f1: 0.8698, edges-pos-ontonotes_loss: 0.0160
09/16 03:30:34 AM: Best result seen so far for edges-pos-ontonotes.
09/16 03:30:34 AM: Best result seen so far for macro.
09/16 03:30:34 AM: Updating LR scheduler:
09/16 03:30:34 AM: 	Best result seen so far for macro_avg: 0.873
09/16 03:30:34 AM: 	# validation passes without improvement: 0
09/16 03:30:34 AM: edges-pos-ontonotes_loss: training: 0.020192 validation: 0.015696
09/16 03:30:34 AM: macro_avg: validation: 0.872713
09/16 03:30:34 AM: micro_avg: validation: 0.000000
09/16 03:30:34 AM: edges-pos-ontonotes_mcc: training: 0.829430 validation: 0.871893
09/16 03:30:34 AM: edges-pos-ontonotes_acc: training: 0.730639 validation: 0.797009
09/16 03:30:34 AM: edges-pos-ontonotes_precision: training: 0.901242 validation: 0.929939
09/16 03:30:34 AM: edges-pos-ontonotes_recall: training: 0.769301 validation: 0.822121
09/16 03:30:34 AM: edges-pos-ontonotes_f1: training: 0.830061 validation: 0.872713
09/16 03:30:34 AM: Global learning rate: 0.0001
09/16 03:30:34 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:30:49 AM: Update 5026: task edges-pos-ontonotes, batch 26 (5026): mcc: 0.8416, acc: 0.7494, precision: 0.9078, recall: 0.7858, f1: 0.8424, edges-pos-ontonotes_loss: 0.0184
09/16 03:30:59 AM: Update 5086: task edges-pos-ontonotes, batch 86 (5086): mcc: 0.8408, acc: 0.7484, precision: 0.9084, recall: 0.7839, f1: 0.8416, edges-pos-ontonotes_loss: 0.0190
09/16 03:31:09 AM: Update 5139: task edges-pos-ontonotes, batch 139 (5139): mcc: 0.8418, acc: 0.7497, precision: 0.9087, recall: 0.7855, f1: 0.8426, edges-pos-ontonotes_loss: 0.0189
09/16 03:31:19 AM: Update 5194: task edges-pos-ontonotes, batch 194 (5194): mcc: 0.8426, acc: 0.7511, precision: 0.9087, recall: 0.7869, f1: 0.8434, edges-pos-ontonotes_loss: 0.0188
09/16 03:31:29 AM: Update 5246: task edges-pos-ontonotes, batch 246 (5246): mcc: 0.8433, acc: 0.7524, precision: 0.9088, recall: 0.7881, f1: 0.8441, edges-pos-ontonotes_loss: 0.0187
09/16 03:31:39 AM: Update 5297: task edges-pos-ontonotes, batch 297 (5297): mcc: 0.8439, acc: 0.7534, precision: 0.9089, recall: 0.7891, f1: 0.8448, edges-pos-ontonotes_loss: 0.0186
09/16 03:31:50 AM: Update 5339: task edges-pos-ontonotes, batch 339 (5339): mcc: 0.8442, acc: 0.7536, precision: 0.9091, recall: 0.7894, f1: 0.8451, edges-pos-ontonotes_loss: 0.0186
09/16 03:32:00 AM: Update 5399: task edges-pos-ontonotes, batch 399 (5399): mcc: 0.8449, acc: 0.7547, precision: 0.9094, recall: 0.7906, f1: 0.8458, edges-pos-ontonotes_loss: 0.0184
09/16 03:32:10 AM: Update 5462: task edges-pos-ontonotes, batch 462 (5462): mcc: 0.8454, acc: 0.7554, precision: 0.9097, recall: 0.7913, f1: 0.8463, edges-pos-ontonotes_loss: 0.0182
09/16 03:32:20 AM: Update 5527: task edges-pos-ontonotes, batch 527 (5527): mcc: 0.8464, acc: 0.7566, precision: 0.9106, recall: 0.7923, f1: 0.8473, edges-pos-ontonotes_loss: 0.0180
09/16 03:32:31 AM: Update 5583: task edges-pos-ontonotes, batch 583 (5583): mcc: 0.8469, acc: 0.7572, precision: 0.9106, recall: 0.7930, f1: 0.8478, edges-pos-ontonotes_loss: 0.0178
09/16 03:32:41 AM: Update 5633: task edges-pos-ontonotes, batch 633 (5633): mcc: 0.8471, acc: 0.7576, precision: 0.9105, recall: 0.7936, f1: 0.8480, edges-pos-ontonotes_loss: 0.0178
09/16 03:32:51 AM: Update 5694: task edges-pos-ontonotes, batch 694 (5694): mcc: 0.8482, acc: 0.7589, precision: 0.9115, recall: 0.7947, f1: 0.8491, edges-pos-ontonotes_loss: 0.0176
09/16 03:33:01 AM: Update 5777: task edges-pos-ontonotes, batch 777 (5777): mcc: 0.8502, acc: 0.7615, precision: 0.9132, recall: 0.7969, f1: 0.8511, edges-pos-ontonotes_loss: 0.0173
09/16 03:33:11 AM: Update 5865: task edges-pos-ontonotes, batch 865 (5865): mcc: 0.8522, acc: 0.7641, precision: 0.9147, recall: 0.7992, f1: 0.8531, edges-pos-ontonotes_loss: 0.0170
09/16 03:33:21 AM: Update 5948: task edges-pos-ontonotes, batch 948 (5948): mcc: 0.8539, acc: 0.7665, precision: 0.9160, recall: 0.8014, f1: 0.8548, edges-pos-ontonotes_loss: 0.0167
09/16 03:33:28 AM: ***** Step 6000 / Validation 6 *****
09/16 03:33:28 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:33:28 AM: Validating...
09/16 03:33:31 AM: Evaluate: task edges-pos-ontonotes, batch 20 (157): mcc: 0.8582, acc: 0.7770, precision: 0.9314, recall: 0.7957, f1: 0.8582, edges-pos-ontonotes_loss: 0.0163
09/16 03:33:41 AM: Evaluate: task edges-pos-ontonotes, batch 84 (157): mcc: 0.8729, acc: 0.7968, precision: 0.9353, recall: 0.8193, f1: 0.8735, edges-pos-ontonotes_loss: 0.0152
09/16 03:33:51 AM: Evaluate: task edges-pos-ontonotes, batch 129 (157): mcc: 0.8743, acc: 0.8007, precision: 0.9301, recall: 0.8264, f1: 0.8752, edges-pos-ontonotes_loss: 0.0150
09/16 03:33:57 AM: Best result seen so far for edges-pos-ontonotes.
09/16 03:33:57 AM: Best result seen so far for macro.
09/16 03:33:57 AM: Updating LR scheduler:
09/16 03:33:57 AM: 	Best result seen so far for macro_avg: 0.878
09/16 03:33:57 AM: 	# validation passes without improvement: 0
09/16 03:33:57 AM: edges-pos-ontonotes_loss: training: 0.016698 validation: 0.014800
09/16 03:33:57 AM: macro_avg: validation: 0.877837
09/16 03:33:57 AM: micro_avg: validation: 0.000000
09/16 03:33:57 AM: edges-pos-ontonotes_mcc: training: 0.854583 validation: 0.876797
09/16 03:33:57 AM: edges-pos-ontonotes_acc: training: 0.767355 validation: 0.805528
09/16 03:33:57 AM: edges-pos-ontonotes_precision: training: 0.916587 validation: 0.929515
09/16 03:33:57 AM: edges-pos-ontonotes_recall: training: 0.801995 validation: 0.831603
09/16 03:33:57 AM: edges-pos-ontonotes_f1: training: 0.855471 validation: 0.877837
09/16 03:33:57 AM: Global learning rate: 0.0001
09/16 03:33:57 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:34:01 AM: Update 6041: task edges-pos-ontonotes, batch 41 (6041): mcc: 0.8742, acc: 0.7948, precision: 0.9328, recall: 0.8239, f1: 0.8750, edges-pos-ontonotes_loss: 0.0159
09/16 03:34:11 AM: Update 6140: task edges-pos-ontonotes, batch 140 (6140): mcc: 0.8732, acc: 0.7922, precision: 0.9338, recall: 0.8210, f1: 0.8738, edges-pos-ontonotes_loss: 0.0154
09/16 03:34:21 AM: Update 6234: task edges-pos-ontonotes, batch 234 (6234): mcc: 0.8760, acc: 0.7965, precision: 0.9337, recall: 0.8265, f1: 0.8768, edges-pos-ontonotes_loss: 0.0151
09/16 03:34:31 AM: Update 6334: task edges-pos-ontonotes, batch 334 (6334): mcc: 0.8709, acc: 0.7888, precision: 0.9304, recall: 0.8198, f1: 0.8716, edges-pos-ontonotes_loss: 0.0157
09/16 03:34:41 AM: Update 6452: task edges-pos-ontonotes, batch 452 (6452): mcc: 0.8631, acc: 0.7775, precision: 0.9254, recall: 0.8100, f1: 0.8639, edges-pos-ontonotes_loss: 0.0164
09/16 03:34:51 AM: Update 6584: task edges-pos-ontonotes, batch 584 (6584): mcc: 0.8601, acc: 0.7729, precision: 0.9236, recall: 0.8060, f1: 0.8608, edges-pos-ontonotes_loss: 0.0166
09/16 03:35:02 AM: Update 6635: task edges-pos-ontonotes, batch 635 (6635): mcc: 0.8556, acc: 0.7667, precision: 0.9185, recall: 0.8022, f1: 0.8564, edges-pos-ontonotes_loss: 0.0170
09/16 03:35:12 AM: Update 6696: task edges-pos-ontonotes, batch 696 (6696): mcc: 0.8521, acc: 0.7619, precision: 0.9148, recall: 0.7990, f1: 0.8530, edges-pos-ontonotes_loss: 0.0172
09/16 03:35:22 AM: Update 6746: task edges-pos-ontonotes, batch 746 (6746): mcc: 0.8490, acc: 0.7581, precision: 0.9112, recall: 0.7964, f1: 0.8500, edges-pos-ontonotes_loss: 0.0174
09/16 03:35:32 AM: Update 6799: task edges-pos-ontonotes, batch 799 (6799): mcc: 0.8475, acc: 0.7561, precision: 0.9097, recall: 0.7950, f1: 0.8485, edges-pos-ontonotes_loss: 0.0175
09/16 03:35:42 AM: Update 6854: task edges-pos-ontonotes, batch 854 (6854): mcc: 0.8462, acc: 0.7544, precision: 0.9084, recall: 0.7937, f1: 0.8472, edges-pos-ontonotes_loss: 0.0176
09/16 03:35:52 AM: Update 6908: task edges-pos-ontonotes, batch 908 (6908): mcc: 0.8452, acc: 0.7532, precision: 0.9076, recall: 0.7927, f1: 0.8463, edges-pos-ontonotes_loss: 0.0177
09/16 03:36:02 AM: Update 6975: task edges-pos-ontonotes, batch 975 (6975): mcc: 0.8444, acc: 0.7519, precision: 0.9075, recall: 0.7912, f1: 0.8454, edges-pos-ontonotes_loss: 0.0178
09/16 03:36:06 AM: ***** Step 7000 / Validation 7 *****
09/16 03:36:06 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:36:06 AM: Validating...
09/16 03:36:12 AM: Evaluate: task edges-pos-ontonotes, batch 42 (157): mcc: 0.8804, acc: 0.8096, precision: 0.9358, recall: 0.8326, f1: 0.8812, edges-pos-ontonotes_loss: 0.0147
09/16 03:36:22 AM: Evaluate: task edges-pos-ontonotes, batch 100 (157): mcc: 0.8902, acc: 0.8261, precision: 0.9324, recall: 0.8541, f1: 0.8915, edges-pos-ontonotes_loss: 0.0137
09/16 03:36:33 AM: Evaluate: task edges-pos-ontonotes, batch 140 (157): mcc: 0.8884, acc: 0.8243, precision: 0.9245, recall: 0.8580, f1: 0.8900, edges-pos-ontonotes_loss: 0.0138
09/16 03:36:37 AM: Best result seen so far for edges-pos-ontonotes.
09/16 03:36:37 AM: Best result seen so far for macro.
09/16 03:36:37 AM: Updating LR scheduler:
09/16 03:36:37 AM: 	Best result seen so far for macro_avg: 0.891
09/16 03:36:37 AM: 	# validation passes without improvement: 0
09/16 03:36:37 AM: edges-pos-ontonotes_loss: training: 0.017812 validation: 0.013749
09/16 03:36:37 AM: macro_avg: validation: 0.890744
09/16 03:36:37 AM: micro_avg: validation: 0.000000
09/16 03:36:37 AM: edges-pos-ontonotes_mcc: training: 0.844242 validation: 0.889096
09/16 03:36:37 AM: edges-pos-ontonotes_acc: training: 0.751569 validation: 0.826079
09/16 03:36:37 AM: edges-pos-ontonotes_precision: training: 0.907578 validation: 0.923772
09/16 03:36:37 AM: edges-pos-ontonotes_recall: training: 0.790897 validation: 0.859996
09/16 03:36:37 AM: edges-pos-ontonotes_f1: training: 0.845230 validation: 0.890744
09/16 03:36:37 AM: Global learning rate: 0.0001
09/16 03:36:37 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:36:43 AM: Update 7044: task edges-pos-ontonotes, batch 44 (7044): mcc: 0.8452, acc: 0.7514, precision: 0.9155, recall: 0.7857, f1: 0.8456, edges-pos-ontonotes_loss: 0.0168
09/16 03:36:53 AM: Update 7125: task edges-pos-ontonotes, batch 125 (7125): mcc: 0.8443, acc: 0.7497, precision: 0.9155, recall: 0.7842, f1: 0.8448, edges-pos-ontonotes_loss: 0.0170
09/16 03:37:03 AM: Update 7212: task edges-pos-ontonotes, batch 212 (7212): mcc: 0.8444, acc: 0.7498, precision: 0.9149, recall: 0.7848, f1: 0.8448, edges-pos-ontonotes_loss: 0.0170
09/16 03:37:13 AM: Update 7271: task edges-pos-ontonotes, batch 271 (7271): mcc: 0.8468, acc: 0.7542, precision: 0.9118, recall: 0.7919, f1: 0.8476, edges-pos-ontonotes_loss: 0.0170
09/16 03:37:23 AM: Update 7335: task edges-pos-ontonotes, batch 335 (7335): mcc: 0.8487, acc: 0.7573, precision: 0.9102, recall: 0.7967, f1: 0.8497, edges-pos-ontonotes_loss: 0.0169
09/16 03:37:33 AM: Update 7403: task edges-pos-ontonotes, batch 403 (7403): mcc: 0.8494, acc: 0.7588, precision: 0.9093, recall: 0.7988, f1: 0.8505, edges-pos-ontonotes_loss: 0.0169
09/16 03:37:43 AM: Update 7471: task edges-pos-ontonotes, batch 471 (7471): mcc: 0.8502, acc: 0.7602, precision: 0.9088, recall: 0.8007, f1: 0.8514, edges-pos-ontonotes_loss: 0.0168
09/16 03:37:53 AM: Update 7546: task edges-pos-ontonotes, batch 546 (7546): mcc: 0.8513, acc: 0.7621, precision: 0.9090, recall: 0.8028, f1: 0.8526, edges-pos-ontonotes_loss: 0.0167
09/16 03:38:03 AM: Update 7547: task edges-pos-ontonotes, batch 547 (7547): mcc: 0.8509, acc: 0.7616, precision: 0.9086, recall: 0.8023, f1: 0.8522, edges-pos-ontonotes_loss: 0.0168
09/16 03:38:13 AM: Update 7597: task edges-pos-ontonotes, batch 597 (7597): mcc: 0.8494, acc: 0.7599, precision: 0.9063, recall: 0.8016, f1: 0.8507, edges-pos-ontonotes_loss: 0.0169
09/16 03:38:23 AM: Update 7650: task edges-pos-ontonotes, batch 650 (7650): mcc: 0.8491, acc: 0.7597, precision: 0.9053, recall: 0.8018, f1: 0.8504, edges-pos-ontonotes_loss: 0.0170
09/16 03:38:34 AM: Update 7705: task edges-pos-ontonotes, batch 705 (7705): mcc: 0.8486, acc: 0.7592, precision: 0.9045, recall: 0.8016, f1: 0.8499, edges-pos-ontonotes_loss: 0.0171
09/16 03:38:44 AM: Update 7768: task edges-pos-ontonotes, batch 768 (7768): mcc: 0.8490, acc: 0.7600, precision: 0.9048, recall: 0.8022, f1: 0.8504, edges-pos-ontonotes_loss: 0.0171
09/16 03:38:54 AM: Update 7820: task edges-pos-ontonotes, batch 820 (7820): mcc: 0.8491, acc: 0.7602, precision: 0.9045, recall: 0.8026, f1: 0.8505, edges-pos-ontonotes_loss: 0.0171
09/16 03:39:04 AM: Update 7861: task edges-pos-ontonotes, batch 861 (7861): mcc: 0.8489, acc: 0.7601, precision: 0.9042, recall: 0.8026, f1: 0.8504, edges-pos-ontonotes_loss: 0.0172
09/16 03:39:14 AM: Update 7907: task edges-pos-ontonotes, batch 907 (7907): mcc: 0.8489, acc: 0.7601, precision: 0.9037, recall: 0.8029, f1: 0.8503, edges-pos-ontonotes_loss: 0.0172
09/16 03:39:24 AM: Update 7957: task edges-pos-ontonotes, batch 957 (7957): mcc: 0.8494, acc: 0.7611, precision: 0.9039, recall: 0.8038, f1: 0.8509, edges-pos-ontonotes_loss: 0.0172
09/16 03:39:32 AM: ***** Step 8000 / Validation 8 *****
09/16 03:39:32 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:39:32 AM: Validating...
09/16 03:39:34 AM: Evaluate: task edges-pos-ontonotes, batch 12 (157): mcc: 0.8820, acc: 0.8165, precision: 0.9338, recall: 0.8374, f1: 0.8830, edges-pos-ontonotes_loss: 0.0138
09/16 03:39:44 AM: Evaluate: task edges-pos-ontonotes, batch 78 (157): mcc: 0.8909, acc: 0.8249, precision: 0.9439, recall: 0.8449, f1: 0.8917, edges-pos-ontonotes_loss: 0.0132
09/16 03:39:54 AM: Evaluate: task edges-pos-ontonotes, batch 127 (157): mcc: 0.8925, acc: 0.8290, precision: 0.9390, recall: 0.8524, f1: 0.8936, edges-pos-ontonotes_loss: 0.0130
09/16 03:40:01 AM: Best result seen so far for edges-pos-ontonotes.
09/16 03:40:01 AM: Best result seen so far for macro.
09/16 03:40:01 AM: Updating LR scheduler:
09/16 03:40:01 AM: 	Best result seen so far for macro_avg: 0.895
09/16 03:40:01 AM: 	# validation passes without improvement: 0
09/16 03:40:01 AM: edges-pos-ontonotes_loss: training: 0.017128 validation: 0.012827
09/16 03:40:01 AM: macro_avg: validation: 0.895145
09/16 03:40:01 AM: micro_avg: validation: 0.000000
09/16 03:40:01 AM: edges-pos-ontonotes_mcc: training: 0.849813 validation: 0.893939
09/16 03:40:01 AM: edges-pos-ontonotes_acc: training: 0.761693 validation: 0.832619
09/16 03:40:01 AM: edges-pos-ontonotes_precision: training: 0.903978 validation: 0.936869
09/16 03:40:01 AM: edges-pos-ontonotes_recall: training: 0.804398 validation: 0.856980
09/16 03:40:01 AM: edges-pos-ontonotes_f1: training: 0.851286 validation: 0.895145
09/16 03:40:01 AM: Global learning rate: 0.0001
09/16 03:40:01 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:40:04 AM: Update 8018: task edges-pos-ontonotes, batch 18 (8018): mcc: 0.8521, acc: 0.7665, precision: 0.9052, recall: 0.8076, f1: 0.8536, edges-pos-ontonotes_loss: 0.0171
09/16 03:40:14 AM: Update 8071: task edges-pos-ontonotes, batch 71 (8071): mcc: 0.8573, acc: 0.7749, precision: 0.9078, recall: 0.8148, f1: 0.8588, edges-pos-ontonotes_loss: 0.0167
09/16 03:40:24 AM: Update 8118: task edges-pos-ontonotes, batch 118 (8118): mcc: 0.8573, acc: 0.7757, precision: 0.9070, recall: 0.8157, f1: 0.8589, edges-pos-ontonotes_loss: 0.0166
09/16 03:40:35 AM: Update 8171: task edges-pos-ontonotes, batch 171 (8171): mcc: 0.8579, acc: 0.7763, precision: 0.9072, recall: 0.8165, f1: 0.8594, edges-pos-ontonotes_loss: 0.0166
09/16 03:40:45 AM: Update 8208: task edges-pos-ontonotes, batch 208 (8208): mcc: 0.8565, acc: 0.7744, precision: 0.9065, recall: 0.8146, f1: 0.8581, edges-pos-ontonotes_loss: 0.0167
09/16 03:40:55 AM: Update 8259: task edges-pos-ontonotes, batch 259 (8259): mcc: 0.8565, acc: 0.7744, precision: 0.9064, recall: 0.8147, f1: 0.8581, edges-pos-ontonotes_loss: 0.0168
09/16 03:41:05 AM: Update 8314: task edges-pos-ontonotes, batch 314 (8314): mcc: 0.8573, acc: 0.7754, precision: 0.9072, recall: 0.8154, f1: 0.8589, edges-pos-ontonotes_loss: 0.0168
09/16 03:41:15 AM: Update 8369: task edges-pos-ontonotes, batch 369 (8369): mcc: 0.8578, acc: 0.7761, precision: 0.9077, recall: 0.8159, f1: 0.8593, edges-pos-ontonotes_loss: 0.0167
09/16 03:41:25 AM: Update 8423: task edges-pos-ontonotes, batch 423 (8423): mcc: 0.8585, acc: 0.7772, precision: 0.9082, recall: 0.8168, f1: 0.8601, edges-pos-ontonotes_loss: 0.0166
09/16 03:41:35 AM: Update 8478: task edges-pos-ontonotes, batch 478 (8478): mcc: 0.8593, acc: 0.7783, precision: 0.9087, recall: 0.8177, f1: 0.8608, edges-pos-ontonotes_loss: 0.0166
09/16 03:41:45 AM: Update 8516: task edges-pos-ontonotes, batch 516 (8516): mcc: 0.8593, acc: 0.7784, precision: 0.9088, recall: 0.8177, f1: 0.8609, edges-pos-ontonotes_loss: 0.0166
09/16 03:41:55 AM: Update 8571: task edges-pos-ontonotes, batch 571 (8571): mcc: 0.8596, acc: 0.7787, precision: 0.9089, recall: 0.8181, f1: 0.8611, edges-pos-ontonotes_loss: 0.0165
09/16 03:42:06 AM: Update 8623: task edges-pos-ontonotes, batch 623 (8623): mcc: 0.8602, acc: 0.7796, precision: 0.9094, recall: 0.8189, f1: 0.8618, edges-pos-ontonotes_loss: 0.0165
09/16 03:42:16 AM: Update 8673: task edges-pos-ontonotes, batch 673 (8673): mcc: 0.8606, acc: 0.7802, precision: 0.9096, recall: 0.8193, f1: 0.8621, edges-pos-ontonotes_loss: 0.0165
09/16 03:42:26 AM: Update 8726: task edges-pos-ontonotes, batch 726 (8726): mcc: 0.8610, acc: 0.7808, precision: 0.9101, recall: 0.8197, f1: 0.8625, edges-pos-ontonotes_loss: 0.0164
09/16 03:42:36 AM: Update 8776: task edges-pos-ontonotes, batch 776 (8776): mcc: 0.8611, acc: 0.7810, precision: 0.9101, recall: 0.8199, f1: 0.8626, edges-pos-ontonotes_loss: 0.0165
09/16 03:42:46 AM: Update 8819: task edges-pos-ontonotes, batch 819 (8819): mcc: 0.8610, acc: 0.7809, precision: 0.9100, recall: 0.8198, f1: 0.8625, edges-pos-ontonotes_loss: 0.0164
09/16 03:42:56 AM: Update 8875: task edges-pos-ontonotes, batch 875 (8875): mcc: 0.8613, acc: 0.7813, precision: 0.9100, recall: 0.8204, f1: 0.8629, edges-pos-ontonotes_loss: 0.0163
09/16 03:43:06 AM: Update 8941: task edges-pos-ontonotes, batch 941 (8941): mcc: 0.8617, acc: 0.7818, precision: 0.9104, recall: 0.8207, f1: 0.8633, edges-pos-ontonotes_loss: 0.0162
09/16 03:43:16 AM: Update 9000: task edges-pos-ontonotes, batch 1000 (9000): mcc: 0.8619, acc: 0.7820, precision: 0.9105, recall: 0.8211, f1: 0.8635, edges-pos-ontonotes_loss: 0.0161
09/16 03:43:16 AM: ***** Step 9000 / Validation 9 *****
09/16 03:43:16 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:43:16 AM: Validating...
09/16 03:43:26 AM: Evaluate: task edges-pos-ontonotes, batch 69 (157): mcc: 0.8887, acc: 0.8217, precision: 0.9422, recall: 0.8423, f1: 0.8895, edges-pos-ontonotes_loss: 0.0135
09/16 03:43:37 AM: Evaluate: task edges-pos-ontonotes, batch 119 (157): mcc: 0.8939, acc: 0.8317, precision: 0.9387, recall: 0.8553, f1: 0.8950, edges-pos-ontonotes_loss: 0.0128
09/16 03:43:45 AM: Best result seen so far for edges-pos-ontonotes.
09/16 03:43:45 AM: Best result seen so far for macro.
09/16 03:43:45 AM: Updating LR scheduler:
09/16 03:43:45 AM: 	Best result seen so far for macro_avg: 0.898
09/16 03:43:45 AM: 	# validation passes without improvement: 0
09/16 03:43:45 AM: edges-pos-ontonotes_loss: training: 0.016066 validation: 0.012561
09/16 03:43:45 AM: macro_avg: validation: 0.898091
09/16 03:43:45 AM: micro_avg: validation: 0.000000
09/16 03:43:45 AM: edges-pos-ontonotes_mcc: training: 0.861928 validation: 0.896812
09/16 03:43:45 AM: edges-pos-ontonotes_acc: training: 0.782027 validation: 0.837550
09/16 03:43:45 AM: edges-pos-ontonotes_precision: training: 0.910465 validation: 0.936792
09/16 03:43:45 AM: edges-pos-ontonotes_recall: training: 0.821116 validation: 0.862461
09/16 03:43:45 AM: edges-pos-ontonotes_f1: training: 0.863485 validation: 0.898091
09/16 03:43:45 AM: Global learning rate: 0.0001
09/16 03:43:45 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:43:47 AM: Update 9010: task edges-pos-ontonotes, batch 10 (9010): mcc: 0.8767, acc: 0.8005, precision: 0.9218, recall: 0.8384, f1: 0.8781, edges-pos-ontonotes_loss: 0.0139
09/16 03:43:57 AM: Update 9077: task edges-pos-ontonotes, batch 77 (9077): mcc: 0.8701, acc: 0.7917, precision: 0.9157, recall: 0.8317, f1: 0.8717, edges-pos-ontonotes_loss: 0.0142
09/16 03:44:12 AM: Update 9112: task edges-pos-ontonotes, batch 112 (9112): mcc: 0.8697, acc: 0.7914, precision: 0.9155, recall: 0.8312, f1: 0.8713, edges-pos-ontonotes_loss: 0.0142
09/16 03:44:22 AM: Update 9200: task edges-pos-ontonotes, batch 200 (9200): mcc: 0.8779, acc: 0.8020, precision: 0.9228, recall: 0.8398, f1: 0.8794, edges-pos-ontonotes_loss: 0.0136
09/16 03:44:32 AM: Update 9285: task edges-pos-ontonotes, batch 285 (9285): mcc: 0.8824, acc: 0.8080, precision: 0.9266, recall: 0.8448, f1: 0.8838, edges-pos-ontonotes_loss: 0.0132
09/16 03:44:42 AM: Update 9370: task edges-pos-ontonotes, batch 370 (9370): mcc: 0.8857, acc: 0.8127, precision: 0.9290, recall: 0.8487, f1: 0.8870, edges-pos-ontonotes_loss: 0.0130
09/16 03:44:52 AM: Update 9444: task edges-pos-ontonotes, batch 444 (9444): mcc: 0.8863, acc: 0.8135, precision: 0.9299, recall: 0.8490, f1: 0.8876, edges-pos-ontonotes_loss: 0.0130
09/16 03:45:02 AM: Update 9536: task edges-pos-ontonotes, batch 536 (9536): mcc: 0.8866, acc: 0.8140, precision: 0.9307, recall: 0.8489, f1: 0.8879, edges-pos-ontonotes_loss: 0.0130
09/16 03:45:12 AM: Update 9626: task edges-pos-ontonotes, batch 626 (9626): mcc: 0.8869, acc: 0.8146, precision: 0.9313, recall: 0.8490, f1: 0.8882, edges-pos-ontonotes_loss: 0.0131
09/16 03:45:22 AM: Update 9718: task edges-pos-ontonotes, batch 718 (9718): mcc: 0.8874, acc: 0.8153, precision: 0.9319, recall: 0.8492, f1: 0.8886, edges-pos-ontonotes_loss: 0.0130
09/16 03:45:32 AM: Update 9817: task edges-pos-ontonotes, batch 817 (9817): mcc: 0.8855, acc: 0.8125, precision: 0.9310, recall: 0.8465, f1: 0.8867, edges-pos-ontonotes_loss: 0.0134
09/16 03:45:42 AM: Update 9942: task edges-pos-ontonotes, batch 942 (9942): mcc: 0.8834, acc: 0.8093, precision: 0.9298, recall: 0.8438, f1: 0.8847, edges-pos-ontonotes_loss: 0.0138
09/16 03:45:47 AM: ***** Step 10000 / Validation 10 *****
09/16 03:45:47 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:45:47 AM: Validating...
09/16 03:45:52 AM: Evaluate: task edges-pos-ontonotes, batch 37 (157): mcc: 0.8875, acc: 0.8208, precision: 0.9370, recall: 0.8447, f1: 0.8885, edges-pos-ontonotes_loss: 0.0134
09/16 03:46:02 AM: Evaluate: task edges-pos-ontonotes, batch 91 (157): mcc: 0.8955, acc: 0.8346, precision: 0.9358, recall: 0.8609, f1: 0.8968, edges-pos-ontonotes_loss: 0.0126
09/16 03:46:13 AM: Evaluate: task edges-pos-ontonotes, batch 132 (157): mcc: 0.8941, acc: 0.8337, precision: 0.9263, recall: 0.8671, f1: 0.8957, edges-pos-ontonotes_loss: 0.0127
09/16 03:46:18 AM: Updating LR scheduler:
09/16 03:46:18 AM: 	Best result seen so far for macro_avg: 0.898
09/16 03:46:18 AM: 	# validation passes without improvement: 1
09/16 03:46:18 AM: edges-pos-ontonotes_loss: training: 0.013870 validation: 0.012632
09/16 03:46:18 AM: macro_avg: validation: 0.897114
09/16 03:46:18 AM: micro_avg: validation: 0.000000
09/16 03:46:18 AM: edges-pos-ontonotes_mcc: training: 0.882301 validation: 0.895417
09/16 03:46:18 AM: edges-pos-ontonotes_acc: training: 0.807624 validation: 0.836736
09/16 03:46:18 AM: edges-pos-ontonotes_precision: training: 0.929090 validation: 0.925043
09/16 03:46:18 AM: edges-pos-ontonotes_recall: training: 0.842267 validation: 0.870821
09/16 03:46:18 AM: edges-pos-ontonotes_f1: training: 0.883551 validation: 0.897114
09/16 03:46:18 AM: Global learning rate: 0.0001
09/16 03:46:18 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:46:23 AM: Update 10039: task edges-pos-ontonotes, batch 39 (10039): mcc: 0.8569, acc: 0.7699, precision: 0.9110, recall: 0.8113, f1: 0.8582, edges-pos-ontonotes_loss: 0.0166
09/16 03:46:33 AM: Update 10083: task edges-pos-ontonotes, batch 83 (10083): mcc: 0.8476, acc: 0.7597, precision: 0.8968, recall: 0.8068, f1: 0.8494, edges-pos-ontonotes_loss: 0.0172
09/16 03:46:43 AM: Update 10143: task edges-pos-ontonotes, batch 143 (10143): mcc: 0.8471, acc: 0.7580, precision: 0.8957, recall: 0.8068, f1: 0.8490, edges-pos-ontonotes_loss: 0.0175
09/16 03:46:53 AM: Update 10202: task edges-pos-ontonotes, batch 202 (10202): mcc: 0.8482, acc: 0.7591, precision: 0.8973, recall: 0.8074, f1: 0.8500, edges-pos-ontonotes_loss: 0.0175
09/16 03:47:03 AM: Update 10263: task edges-pos-ontonotes, batch 263 (10263): mcc: 0.8486, acc: 0.7597, precision: 0.8977, recall: 0.8078, f1: 0.8504, edges-pos-ontonotes_loss: 0.0176
09/16 03:47:13 AM: Update 10321: task edges-pos-ontonotes, batch 321 (10321): mcc: 0.8492, acc: 0.7608, precision: 0.8982, recall: 0.8084, f1: 0.8509, edges-pos-ontonotes_loss: 0.0176
09/16 03:47:23 AM: Update 10376: task edges-pos-ontonotes, batch 376 (10376): mcc: 0.8493, acc: 0.7611, precision: 0.8988, recall: 0.8082, f1: 0.8511, edges-pos-ontonotes_loss: 0.0176
09/16 03:47:34 AM: Update 10443: task edges-pos-ontonotes, batch 443 (10443): mcc: 0.8496, acc: 0.7612, precision: 0.9005, recall: 0.8071, f1: 0.8512, edges-pos-ontonotes_loss: 0.0174
09/16 03:47:44 AM: Update 10526: task edges-pos-ontonotes, batch 526 (10526): mcc: 0.8500, acc: 0.7616, precision: 0.9020, recall: 0.8065, f1: 0.8516, edges-pos-ontonotes_loss: 0.0173
09/16 03:47:54 AM: Update 10601: task edges-pos-ontonotes, batch 601 (10601): mcc: 0.8507, acc: 0.7624, precision: 0.9032, recall: 0.8067, f1: 0.8522, edges-pos-ontonotes_loss: 0.0171
09/16 03:48:05 AM: Update 10694: task edges-pos-ontonotes, batch 694 (10694): mcc: 0.8514, acc: 0.7634, precision: 0.9043, recall: 0.8072, f1: 0.8530, edges-pos-ontonotes_loss: 0.0169
09/16 03:48:15 AM: Update 10757: task edges-pos-ontonotes, batch 757 (10757): mcc: 0.8525, acc: 0.7651, precision: 0.9044, recall: 0.8091, f1: 0.8541, edges-pos-ontonotes_loss: 0.0168
09/16 03:48:26 AM: Update 10827: task edges-pos-ontonotes, batch 827 (10827): mcc: 0.8536, acc: 0.7667, precision: 0.9047, recall: 0.8109, f1: 0.8552, edges-pos-ontonotes_loss: 0.0166
09/16 03:48:36 AM: Update 10895: task edges-pos-ontonotes, batch 895 (10895): mcc: 0.8547, acc: 0.7682, precision: 0.9051, recall: 0.8124, f1: 0.8563, edges-pos-ontonotes_loss: 0.0165
09/16 03:48:46 AM: Update 10965: task edges-pos-ontonotes, batch 965 (10965): mcc: 0.8554, acc: 0.7693, precision: 0.9054, recall: 0.8136, f1: 0.8570, edges-pos-ontonotes_loss: 0.0164
09/16 03:48:51 AM: ***** Step 11000 / Validation 11 *****
09/16 03:48:51 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:48:51 AM: Validating...
09/16 03:48:56 AM: Evaluate: task edges-pos-ontonotes, batch 36 (157): mcc: 0.8942, acc: 0.8321, precision: 0.9422, recall: 0.8526, f1: 0.8951, edges-pos-ontonotes_loss: 0.0126
09/16 03:49:06 AM: Evaluate: task edges-pos-ontonotes, batch 93 (157): mcc: 0.9035, acc: 0.8464, precision: 0.9426, recall: 0.8698, f1: 0.9047, edges-pos-ontonotes_loss: 0.0117
09/16 03:49:16 AM: Evaluate: task edges-pos-ontonotes, batch 132 (157): mcc: 0.9021, acc: 0.8451, precision: 0.9370, recall: 0.8723, f1: 0.9035, edges-pos-ontonotes_loss: 0.0118
09/16 03:49:22 AM: Best result seen so far for edges-pos-ontonotes.
09/16 03:49:22 AM: Best result seen so far for macro.
09/16 03:49:22 AM: Updating LR scheduler:
09/16 03:49:22 AM: 	Best result seen so far for macro_avg: 0.904
09/16 03:49:22 AM: 	# validation passes without improvement: 0
09/16 03:49:22 AM: edges-pos-ontonotes_loss: training: 0.016349 validation: 0.011793
09/16 03:49:22 AM: macro_avg: validation: 0.904040
09/16 03:49:22 AM: micro_avg: validation: 0.000000
09/16 03:49:22 AM: edges-pos-ontonotes_mcc: training: 0.855801 validation: 0.902604
09/16 03:49:22 AM: edges-pos-ontonotes_acc: training: 0.769832 validation: 0.847032
09/16 03:49:22 AM: edges-pos-ontonotes_precision: training: 0.905653 validation: 0.935604
09/16 03:49:22 AM: edges-pos-ontonotes_recall: training: 0.814038 validation: 0.874536
09/16 03:49:22 AM: edges-pos-ontonotes_f1: training: 0.857405 validation: 0.904040
09/16 03:49:22 AM: Global learning rate: 0.0001
09/16 03:49:22 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:49:27 AM: Update 11011: task edges-pos-ontonotes, batch 11 (11011): mcc: 0.8428, acc: 0.7561, precision: 0.8894, recall: 0.8045, f1: 0.8449, edges-pos-ontonotes_loss: 0.0170
09/16 03:49:37 AM: Update 11066: task edges-pos-ontonotes, batch 66 (11066): mcc: 0.8547, acc: 0.7704, precision: 0.8995, recall: 0.8175, f1: 0.8566, edges-pos-ontonotes_loss: 0.0170
09/16 03:49:47 AM: Update 11119: task edges-pos-ontonotes, batch 119 (11119): mcc: 0.8567, acc: 0.7730, precision: 0.8998, recall: 0.8210, f1: 0.8586, edges-pos-ontonotes_loss: 0.0169
09/16 03:49:57 AM: Update 11171: task edges-pos-ontonotes, batch 171 (11171): mcc: 0.8567, acc: 0.7732, precision: 0.8993, recall: 0.8215, f1: 0.8586, edges-pos-ontonotes_loss: 0.0168
09/16 03:50:07 AM: Update 11225: task edges-pos-ontonotes, batch 225 (11225): mcc: 0.8567, acc: 0.7736, precision: 0.8993, recall: 0.8217, f1: 0.8587, edges-pos-ontonotes_loss: 0.0168
09/16 03:50:17 AM: Update 11282: task edges-pos-ontonotes, batch 282 (11282): mcc: 0.8574, acc: 0.7746, precision: 0.9001, recall: 0.8221, f1: 0.8593, edges-pos-ontonotes_loss: 0.0166
09/16 03:50:34 AM: Update 11320: task edges-pos-ontonotes, batch 320 (11320): mcc: 0.8570, acc: 0.7740, precision: 0.9002, recall: 0.8212, f1: 0.8589, edges-pos-ontonotes_loss: 0.0166
09/16 03:50:44 AM: Update 11373: task edges-pos-ontonotes, batch 373 (11373): mcc: 0.8579, acc: 0.7754, precision: 0.9007, recall: 0.8225, f1: 0.8598, edges-pos-ontonotes_loss: 0.0166
09/16 03:50:54 AM: Update 11426: task edges-pos-ontonotes, batch 426 (11426): mcc: 0.8589, acc: 0.7769, precision: 0.9017, recall: 0.8235, f1: 0.8608, edges-pos-ontonotes_loss: 0.0165
09/16 03:51:05 AM: Update 11475: task edges-pos-ontonotes, batch 475 (11475): mcc: 0.8595, acc: 0.7777, precision: 0.9022, recall: 0.8242, f1: 0.8614, edges-pos-ontonotes_loss: 0.0164
09/16 03:51:15 AM: Update 11528: task edges-pos-ontonotes, batch 528 (11528): mcc: 0.8600, acc: 0.7786, precision: 0.9025, recall: 0.8248, f1: 0.8619, edges-pos-ontonotes_loss: 0.0163
09/16 03:51:25 AM: Update 11580: task edges-pos-ontonotes, batch 580 (11580): mcc: 0.8602, acc: 0.7789, precision: 0.9029, recall: 0.8249, f1: 0.8621, edges-pos-ontonotes_loss: 0.0163
09/16 03:51:35 AM: Update 11631: task edges-pos-ontonotes, batch 631 (11631): mcc: 0.8610, acc: 0.7800, precision: 0.9035, recall: 0.8258, f1: 0.8629, edges-pos-ontonotes_loss: 0.0162
09/16 03:51:45 AM: Update 11676: task edges-pos-ontonotes, batch 676 (11676): mcc: 0.8612, acc: 0.7804, precision: 0.9037, recall: 0.8259, f1: 0.8631, edges-pos-ontonotes_loss: 0.0162
09/16 03:51:55 AM: Update 11725: task edges-pos-ontonotes, batch 725 (11725): mcc: 0.8616, acc: 0.7811, precision: 0.9042, recall: 0.8263, f1: 0.8635, edges-pos-ontonotes_loss: 0.0161
09/16 03:52:05 AM: Update 11776: task edges-pos-ontonotes, batch 776 (11776): mcc: 0.8622, acc: 0.7820, precision: 0.9047, recall: 0.8269, f1: 0.8640, edges-pos-ontonotes_loss: 0.0161
09/16 03:52:16 AM: Update 11825: task edges-pos-ontonotes, batch 825 (11825): mcc: 0.8627, acc: 0.7828, precision: 0.9052, recall: 0.8274, f1: 0.8646, edges-pos-ontonotes_loss: 0.0160
09/16 03:52:26 AM: Update 11875: task edges-pos-ontonotes, batch 875 (11875): mcc: 0.8632, acc: 0.7835, precision: 0.9055, recall: 0.8280, f1: 0.8650, edges-pos-ontonotes_loss: 0.0160
09/16 03:52:36 AM: Update 11926: task edges-pos-ontonotes, batch 926 (11926): mcc: 0.8635, acc: 0.7840, precision: 0.9059, recall: 0.8283, f1: 0.8654, edges-pos-ontonotes_loss: 0.0159
09/16 03:52:46 AM: Update 11964: task edges-pos-ontonotes, batch 964 (11964): mcc: 0.8637, acc: 0.7844, precision: 0.9061, recall: 0.8286, f1: 0.8656, edges-pos-ontonotes_loss: 0.0159
09/16 03:52:53 AM: ***** Step 12000 / Validation 12 *****
09/16 03:52:53 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:52:53 AM: Validating...
09/16 03:52:56 AM: Evaluate: task edges-pos-ontonotes, batch 17 (157): mcc: 0.8922, acc: 0.8296, precision: 0.9395, recall: 0.8514, f1: 0.8933, edges-pos-ontonotes_loss: 0.0127
09/16 03:53:06 AM: Evaluate: task edges-pos-ontonotes, batch 82 (157): mcc: 0.9011, acc: 0.8415, precision: 0.9459, recall: 0.8621, f1: 0.9020, edges-pos-ontonotes_loss: 0.0121
09/16 03:53:16 AM: Evaluate: task edges-pos-ontonotes, batch 128 (157): mcc: 0.9016, acc: 0.8439, precision: 0.9412, recall: 0.8674, f1: 0.9028, edges-pos-ontonotes_loss: 0.0119
09/16 03:53:23 AM: Best result seen so far for edges-pos-ontonotes.
09/16 03:53:23 AM: Best result seen so far for macro.
09/16 03:53:23 AM: Updating LR scheduler:
09/16 03:53:23 AM: 	Best result seen so far for macro_avg: 0.905
09/16 03:53:23 AM: 	# validation passes without improvement: 0
09/16 03:53:23 AM: edges-pos-ontonotes_loss: training: 0.015911 validation: 0.011620
09/16 03:53:23 AM: macro_avg: validation: 0.905297
09/16 03:53:23 AM: micro_avg: validation: 0.000000
09/16 03:53:23 AM: edges-pos-ontonotes_mcc: training: 0.863974 validation: 0.904015
09/16 03:53:23 AM: edges-pos-ontonotes_acc: training: 0.784850 validation: 0.848937
09/16 03:53:23 AM: edges-pos-ontonotes_precision: training: 0.906202 validation: 0.940417
09/16 03:53:23 AM: edges-pos-ontonotes_recall: training: 0.828857 validation: 0.872705
09/16 03:53:23 AM: edges-pos-ontonotes_f1: training: 0.865806 validation: 0.905297
09/16 03:53:23 AM: Global learning rate: 0.0001
09/16 03:53:23 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:53:26 AM: Update 12019: task edges-pos-ontonotes, batch 19 (12019): mcc: 0.8696, acc: 0.7943, precision: 0.9156, recall: 0.8307, f1: 0.8711, edges-pos-ontonotes_loss: 0.0151
09/16 03:53:37 AM: Update 12065: task edges-pos-ontonotes, batch 65 (12065): mcc: 0.8709, acc: 0.7963, precision: 0.9123, recall: 0.8364, f1: 0.8727, edges-pos-ontonotes_loss: 0.0159
09/16 03:53:47 AM: Update 12117: task edges-pos-ontonotes, batch 117 (12117): mcc: 0.8707, acc: 0.7957, precision: 0.9127, recall: 0.8356, f1: 0.8724, edges-pos-ontonotes_loss: 0.0157
09/16 03:53:57 AM: Update 12171: task edges-pos-ontonotes, batch 171 (12171): mcc: 0.8701, acc: 0.7950, precision: 0.9123, recall: 0.8347, f1: 0.8718, edges-pos-ontonotes_loss: 0.0157
09/16 03:54:07 AM: Update 12225: task edges-pos-ontonotes, batch 225 (12225): mcc: 0.8704, acc: 0.7954, precision: 0.9121, recall: 0.8356, f1: 0.8722, edges-pos-ontonotes_loss: 0.0156
09/16 03:54:17 AM: Update 12260: task edges-pos-ontonotes, batch 260 (12260): mcc: 0.8698, acc: 0.7944, precision: 0.9119, recall: 0.8346, f1: 0.8716, edges-pos-ontonotes_loss: 0.0155
09/16 03:54:27 AM: Update 12320: task edges-pos-ontonotes, batch 320 (12320): mcc: 0.8701, acc: 0.7947, precision: 0.9122, recall: 0.8348, f1: 0.8718, edges-pos-ontonotes_loss: 0.0152
09/16 03:54:38 AM: Update 12388: task edges-pos-ontonotes, batch 388 (12388): mcc: 0.8717, acc: 0.7967, precision: 0.9134, recall: 0.8367, f1: 0.8734, edges-pos-ontonotes_loss: 0.0148
09/16 03:54:48 AM: Update 12456: task edges-pos-ontonotes, batch 456 (12456): mcc: 0.8723, acc: 0.7976, precision: 0.9137, recall: 0.8376, f1: 0.8740, edges-pos-ontonotes_loss: 0.0146
09/16 03:54:58 AM: Update 12516: task edges-pos-ontonotes, batch 516 (12516): mcc: 0.8727, acc: 0.7982, precision: 0.9137, recall: 0.8383, f1: 0.8744, edges-pos-ontonotes_loss: 0.0145
09/16 03:55:09 AM: Update 12572: task edges-pos-ontonotes, batch 572 (12572): mcc: 0.8732, acc: 0.7988, precision: 0.9141, recall: 0.8389, f1: 0.8749, edges-pos-ontonotes_loss: 0.0144
09/16 03:55:19 AM: Update 12652: task edges-pos-ontonotes, batch 652 (12652): mcc: 0.8756, acc: 0.8019, precision: 0.9162, recall: 0.8415, f1: 0.8772, edges-pos-ontonotes_loss: 0.0140
09/16 03:55:29 AM: Update 12728: task edges-pos-ontonotes, batch 728 (12728): mcc: 0.8774, acc: 0.8043, precision: 0.9178, recall: 0.8435, f1: 0.8791, edges-pos-ontonotes_loss: 0.0138
09/16 03:55:39 AM: Update 12802: task edges-pos-ontonotes, batch 802 (12802): mcc: 0.8791, acc: 0.8065, precision: 0.9192, recall: 0.8454, f1: 0.8808, edges-pos-ontonotes_loss: 0.0136
09/16 03:55:50 AM: Update 12885: task edges-pos-ontonotes, batch 885 (12885): mcc: 0.8806, acc: 0.8084, precision: 0.9205, recall: 0.8470, f1: 0.8822, edges-pos-ontonotes_loss: 0.0134
09/16 03:56:00 AM: Update 12973: task edges-pos-ontonotes, batch 973 (12973): mcc: 0.8813, acc: 0.8093, precision: 0.9215, recall: 0.8474, f1: 0.8829, edges-pos-ontonotes_loss: 0.0133
09/16 03:56:02 AM: ***** Step 13000 / Validation 13 *****
09/16 03:56:02 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:56:02 AM: Validating...
09/16 03:56:10 AM: Evaluate: task edges-pos-ontonotes, batch 52 (157): mcc: 0.8956, acc: 0.8336, precision: 0.9453, recall: 0.8523, f1: 0.8964, edges-pos-ontonotes_loss: 0.0125
09/16 03:56:20 AM: Evaluate: task edges-pos-ontonotes, batch 108 (157): mcc: 0.9010, acc: 0.8439, precision: 0.9404, recall: 0.8669, f1: 0.9022, edges-pos-ontonotes_loss: 0.0119
09/16 03:56:30 AM: Evaluate: task edges-pos-ontonotes, batch 151 (157): mcc: 0.9020, acc: 0.8468, precision: 0.9357, recall: 0.8732, f1: 0.9034, edges-pos-ontonotes_loss: 0.0118
09/16 03:56:31 AM: Updating LR scheduler:
09/16 03:56:31 AM: 	Best result seen so far for macro_avg: 0.905
09/16 03:56:31 AM: 	# validation passes without improvement: 1
09/16 03:56:31 AM: edges-pos-ontonotes_loss: training: 0.013291 validation: 0.011731
09/16 03:56:31 AM: macro_avg: validation: 0.903918
09/16 03:56:31 AM: micro_avg: validation: 0.000000
09/16 03:56:31 AM: edges-pos-ontonotes_mcc: training: 0.881582 validation: 0.902498
09/16 03:56:31 AM: edges-pos-ontonotes_acc: training: 0.809608 validation: 0.847762
09/16 03:56:31 AM: edges-pos-ontonotes_precision: training: 0.921727 validation: 0.936010
09/16 03:56:31 AM: edges-pos-ontonotes_recall: training: 0.847688 validation: 0.873954
09/16 03:56:31 AM: edges-pos-ontonotes_f1: training: 0.883158 validation: 0.903918
09/16 03:56:31 AM: Global learning rate: 0.0001
09/16 03:56:31 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:56:40 AM: Update 13085: task edges-pos-ontonotes, batch 85 (13085): mcc: 0.8978, acc: 0.8313, precision: 0.9382, recall: 0.8631, f1: 0.8991, edges-pos-ontonotes_loss: 0.0124
09/16 03:56:50 AM: Update 13175: task edges-pos-ontonotes, batch 175 (13175): mcc: 0.8976, acc: 0.8313, precision: 0.9362, recall: 0.8645, f1: 0.8989, edges-pos-ontonotes_loss: 0.0123
09/16 03:57:00 AM: Update 13270: task edges-pos-ontonotes, batch 270 (13270): mcc: 0.8902, acc: 0.8205, precision: 0.9320, recall: 0.8544, f1: 0.8915, edges-pos-ontonotes_loss: 0.0131
09/16 03:57:10 AM: Update 13388: task edges-pos-ontonotes, batch 388 (13388): mcc: 0.8824, acc: 0.8089, precision: 0.9268, recall: 0.8446, f1: 0.8838, edges-pos-ontonotes_loss: 0.0138
09/16 03:57:20 AM: Update 13498: task edges-pos-ontonotes, batch 498 (13498): mcc: 0.8791, acc: 0.8040, precision: 0.9242, recall: 0.8407, f1: 0.8805, edges-pos-ontonotes_loss: 0.0141
09/16 03:57:31 AM: Update 13511: task edges-pos-ontonotes, batch 511 (13511): mcc: 0.8784, acc: 0.8029, precision: 0.9236, recall: 0.8399, f1: 0.8798, edges-pos-ontonotes_loss: 0.0142
09/16 03:57:41 AM: Update 13568: task edges-pos-ontonotes, batch 568 (13568): mcc: 0.8739, acc: 0.7963, precision: 0.9188, recall: 0.8359, f1: 0.8754, edges-pos-ontonotes_loss: 0.0144
09/16 03:57:51 AM: Update 13625: task edges-pos-ontonotes, batch 625 (13625): mcc: 0.8712, acc: 0.7926, precision: 0.9158, recall: 0.8335, f1: 0.8728, edges-pos-ontonotes_loss: 0.0146
09/16 03:58:01 AM: Update 13684: task edges-pos-ontonotes, batch 684 (13684): mcc: 0.8693, acc: 0.7901, precision: 0.9137, recall: 0.8320, f1: 0.8709, edges-pos-ontonotes_loss: 0.0148
09/16 03:58:11 AM: Update 13743: task edges-pos-ontonotes, batch 743 (13743): mcc: 0.8680, acc: 0.7882, precision: 0.9121, recall: 0.8310, f1: 0.8697, edges-pos-ontonotes_loss: 0.0150
09/16 03:58:22 AM: Update 13797: task edges-pos-ontonotes, batch 797 (13797): mcc: 0.8666, acc: 0.7864, precision: 0.9105, recall: 0.8298, f1: 0.8683, edges-pos-ontonotes_loss: 0.0152
09/16 03:58:32 AM: Update 13843: task edges-pos-ontonotes, batch 843 (13843): mcc: 0.8655, acc: 0.7847, precision: 0.9098, recall: 0.8283, f1: 0.8672, edges-pos-ontonotes_loss: 0.0153
09/16 03:58:42 AM: Update 13936: task edges-pos-ontonotes, batch 936 (13936): mcc: 0.8650, acc: 0.7839, precision: 0.9106, recall: 0.8269, f1: 0.8667, edges-pos-ontonotes_loss: 0.0153
09/16 03:58:51 AM: ***** Step 14000 / Validation 14 *****
09/16 03:58:51 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:58:51 AM: Validating...
09/16 03:58:52 AM: Evaluate: task edges-pos-ontonotes, batch 5 (157): mcc: 0.8972, acc: 0.8441, precision: 0.9241, recall: 0.8750, f1: 0.8989, edges-pos-ontonotes_loss: 0.0123
09/16 03:59:02 AM: Evaluate: task edges-pos-ontonotes, batch 70 (157): mcc: 0.9073, acc: 0.8533, precision: 0.9413, recall: 0.8781, f1: 0.9086, edges-pos-ontonotes_loss: 0.0115
09/16 03:59:12 AM: Evaluate: task edges-pos-ontonotes, batch 115 (157): mcc: 0.9068, acc: 0.8539, precision: 0.9351, recall: 0.8830, f1: 0.9083, edges-pos-ontonotes_loss: 0.0114
09/16 03:59:22 AM: Best result seen so far for edges-pos-ontonotes.
09/16 03:59:22 AM: Best result seen so far for macro.
09/16 03:59:22 AM: Updating LR scheduler:
09/16 03:59:22 AM: 	Best result seen so far for macro_avg: 0.909
09/16 03:59:22 AM: 	# validation passes without improvement: 0
09/16 03:59:22 AM: edges-pos-ontonotes_loss: training: 0.015298 validation: 0.011338
09/16 03:59:22 AM: macro_avg: validation: 0.908917
09/16 03:59:22 AM: micro_avg: validation: 0.000000
09/16 03:59:22 AM: edges-pos-ontonotes_mcc: training: 0.864691 validation: 0.907311
09/16 03:59:22 AM: edges-pos-ontonotes_acc: training: 0.783193 validation: 0.855562
09/16 03:59:22 AM: edges-pos-ontonotes_precision: training: 0.910597 validation: 0.931710
09/16 03:59:22 AM: edges-pos-ontonotes_recall: training: 0.826168 validation: 0.887213
09/16 03:59:22 AM: edges-pos-ontonotes_f1: training: 0.866330 validation: 0.908917
09/16 03:59:22 AM: Global learning rate: 0.0001
09/16 03:59:22 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 03:59:22 AM: Update 14002: task edges-pos-ontonotes, batch 2 (14002): mcc: 0.8575, acc: 0.7669, precision: 0.9161, recall: 0.8079, f1: 0.8586, edges-pos-ontonotes_loss: 0.0172
09/16 03:59:32 AM: Update 14092: task edges-pos-ontonotes, batch 92 (14092): mcc: 0.8645, acc: 0.7804, precision: 0.9203, recall: 0.8170, f1: 0.8656, edges-pos-ontonotes_loss: 0.0150
09/16 03:59:42 AM: Update 14155: task edges-pos-ontonotes, batch 155 (14155): mcc: 0.8659, acc: 0.7829, precision: 0.9180, recall: 0.8216, f1: 0.8672, edges-pos-ontonotes_loss: 0.0150
09/16 03:59:52 AM: Update 14225: task edges-pos-ontonotes, batch 225 (14225): mcc: 0.8672, acc: 0.7860, precision: 0.9143, recall: 0.8275, f1: 0.8687, edges-pos-ontonotes_loss: 0.0150
09/16 04:00:02 AM: Update 14289: task edges-pos-ontonotes, batch 289 (14289): mcc: 0.8670, acc: 0.7861, precision: 0.9123, recall: 0.8291, f1: 0.8687, edges-pos-ontonotes_loss: 0.0150
09/16 04:00:12 AM: Update 14358: task edges-pos-ontonotes, batch 358 (14358): mcc: 0.8678, acc: 0.7875, precision: 0.9119, recall: 0.8309, f1: 0.8695, edges-pos-ontonotes_loss: 0.0149
09/16 04:00:22 AM: Update 14422: task edges-pos-ontonotes, batch 422 (14422): mcc: 0.8688, acc: 0.7889, precision: 0.9117, recall: 0.8328, f1: 0.8705, edges-pos-ontonotes_loss: 0.0148
09/16 04:00:32 AM: Update 14469: task edges-pos-ontonotes, batch 469 (14469): mcc: 0.8682, acc: 0.7882, precision: 0.9111, recall: 0.8323, f1: 0.8699, edges-pos-ontonotes_loss: 0.0148
09/16 04:00:42 AM: Update 14525: task edges-pos-ontonotes, batch 525 (14525): mcc: 0.8668, acc: 0.7865, precision: 0.9092, recall: 0.8315, f1: 0.8686, edges-pos-ontonotes_loss: 0.0150
09/16 04:00:52 AM: Update 14584: task edges-pos-ontonotes, batch 584 (14584): mcc: 0.8664, acc: 0.7860, precision: 0.9081, recall: 0.8315, f1: 0.8682, edges-pos-ontonotes_loss: 0.0151
09/16 04:01:03 AM: Update 14640: task edges-pos-ontonotes, batch 640 (14640): mcc: 0.8660, acc: 0.7858, precision: 0.9075, recall: 0.8316, f1: 0.8679, edges-pos-ontonotes_loss: 0.0152
09/16 04:01:13 AM: Update 14692: task edges-pos-ontonotes, batch 692 (14692): mcc: 0.8661, acc: 0.7859, precision: 0.9071, recall: 0.8320, f1: 0.8679, edges-pos-ontonotes_loss: 0.0152
09/16 04:01:23 AM: Update 14743: task edges-pos-ontonotes, batch 743 (14743): mcc: 0.8662, acc: 0.7861, precision: 0.9071, recall: 0.8323, f1: 0.8681, edges-pos-ontonotes_loss: 0.0152
09/16 04:01:33 AM: Update 14781: task edges-pos-ontonotes, batch 781 (14781): mcc: 0.8660, acc: 0.7859, precision: 0.9067, recall: 0.8321, f1: 0.8678, edges-pos-ontonotes_loss: 0.0153
09/16 04:01:43 AM: Update 14831: task edges-pos-ontonotes, batch 831 (14831): mcc: 0.8661, acc: 0.7861, precision: 0.9066, recall: 0.8325, f1: 0.8679, edges-pos-ontonotes_loss: 0.0152
09/16 04:01:53 AM: Update 14881: task edges-pos-ontonotes, batch 881 (14881): mcc: 0.8663, acc: 0.7865, precision: 0.9066, recall: 0.8328, f1: 0.8681, edges-pos-ontonotes_loss: 0.0152
09/16 04:02:03 AM: Update 14928: task edges-pos-ontonotes, batch 928 (14928): mcc: 0.8666, acc: 0.7870, precision: 0.9067, recall: 0.8333, f1: 0.8685, edges-pos-ontonotes_loss: 0.0152
09/16 04:02:13 AM: Update 14982: task edges-pos-ontonotes, batch 982 (14982): mcc: 0.8668, acc: 0.7874, precision: 0.9068, recall: 0.8336, f1: 0.8687, edges-pos-ontonotes_loss: 0.0152
09/16 04:02:17 AM: ***** Step 15000 / Validation 15 *****
09/16 04:02:17 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:02:17 AM: Validating...
09/16 04:02:23 AM: Evaluate: task edges-pos-ontonotes, batch 44 (157): mcc: 0.8989, acc: 0.8382, precision: 0.9473, recall: 0.8567, f1: 0.8997, edges-pos-ontonotes_loss: 0.0121
09/16 04:02:33 AM: Evaluate: task edges-pos-ontonotes, batch 104 (157): mcc: 0.9090, acc: 0.8553, precision: 0.9466, recall: 0.8764, f1: 0.9102, edges-pos-ontonotes_loss: 0.0112
09/16 04:02:44 AM: Evaluate: task edges-pos-ontonotes, batch 148 (157): mcc: 0.9090, acc: 0.8566, precision: 0.9421, recall: 0.8805, f1: 0.9103, edges-pos-ontonotes_loss: 0.0111
09/16 04:02:45 AM: Best result seen so far for edges-pos-ontonotes.
09/16 04:02:45 AM: Best result seen so far for macro.
09/16 04:02:45 AM: Updating LR scheduler:
09/16 04:02:45 AM: 	Best result seen so far for macro_avg: 0.911
09/16 04:02:45 AM: 	# validation passes without improvement: 0
09/16 04:02:45 AM: edges-pos-ontonotes_loss: training: 0.015209 validation: 0.011003
09/16 04:02:45 AM: macro_avg: validation: 0.910793
09/16 04:02:45 AM: micro_avg: validation: 0.000000
09/16 04:02:45 AM: edges-pos-ontonotes_mcc: training: 0.866915 validation: 0.909483
09/16 04:02:45 AM: edges-pos-ontonotes_acc: training: 0.787585 validation: 0.857826
09/16 04:02:45 AM: edges-pos-ontonotes_precision: training: 0.906926 validation: 0.942125
09/16 04:02:45 AM: edges-pos-ontonotes_recall: training: 0.833729 validation: 0.881478
09/16 04:02:45 AM: edges-pos-ontonotes_f1: training: 0.868788 validation: 0.910793
09/16 04:02:45 AM: Global learning rate: 0.0001
09/16 04:02:45 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:02:54 AM: Update 15042: task edges-pos-ontonotes, batch 42 (15042): mcc: 0.8703, acc: 0.7945, precision: 0.9073, recall: 0.8398, f1: 0.8722, edges-pos-ontonotes_loss: 0.0151
09/16 04:03:13 AM: Update 15093: task edges-pos-ontonotes, batch 93 (15093): mcc: 0.8707, acc: 0.7954, precision: 0.9090, recall: 0.8389, f1: 0.8726, edges-pos-ontonotes_loss: 0.0153
09/16 04:03:23 AM: Update 15149: task edges-pos-ontonotes, batch 149 (15149): mcc: 0.8705, acc: 0.7951, precision: 0.9095, recall: 0.8381, f1: 0.8723, edges-pos-ontonotes_loss: 0.0153
09/16 04:03:33 AM: Update 15202: task edges-pos-ontonotes, batch 202 (15202): mcc: 0.8718, acc: 0.7971, precision: 0.9103, recall: 0.8398, f1: 0.8736, edges-pos-ontonotes_loss: 0.0151
09/16 04:03:44 AM: Update 15254: task edges-pos-ontonotes, batch 254 (15254): mcc: 0.8719, acc: 0.7973, precision: 0.9104, recall: 0.8399, f1: 0.8737, edges-pos-ontonotes_loss: 0.0150
09/16 04:03:54 AM: Update 15304: task edges-pos-ontonotes, batch 304 (15304): mcc: 0.8723, acc: 0.7980, precision: 0.9106, recall: 0.8405, f1: 0.8742, edges-pos-ontonotes_loss: 0.0149
09/16 04:04:04 AM: Update 15361: task edges-pos-ontonotes, batch 361 (15361): mcc: 0.8730, acc: 0.7989, precision: 0.9113, recall: 0.8411, f1: 0.8748, edges-pos-ontonotes_loss: 0.0150
09/16 04:04:14 AM: Update 15406: task edges-pos-ontonotes, batch 406 (15406): mcc: 0.8731, acc: 0.7991, precision: 0.9117, recall: 0.8411, f1: 0.8750, edges-pos-ontonotes_loss: 0.0149
09/16 04:04:24 AM: Update 15455: task edges-pos-ontonotes, batch 455 (15455): mcc: 0.8730, acc: 0.7990, precision: 0.9114, recall: 0.8410, f1: 0.8748, edges-pos-ontonotes_loss: 0.0150
09/16 04:04:35 AM: Update 15506: task edges-pos-ontonotes, batch 506 (15506): mcc: 0.8733, acc: 0.7996, precision: 0.9116, recall: 0.8415, f1: 0.8752, edges-pos-ontonotes_loss: 0.0149
09/16 04:04:45 AM: Update 15554: task edges-pos-ontonotes, batch 554 (15554): mcc: 0.8738, acc: 0.8003, precision: 0.9119, recall: 0.8421, f1: 0.8756, edges-pos-ontonotes_loss: 0.0149
09/16 04:04:55 AM: Update 15600: task edges-pos-ontonotes, batch 600 (15600): mcc: 0.8738, acc: 0.8003, precision: 0.9120, recall: 0.8420, f1: 0.8756, edges-pos-ontonotes_loss: 0.0149
09/16 04:05:05 AM: Update 15649: task edges-pos-ontonotes, batch 649 (15649): mcc: 0.8740, acc: 0.8007, precision: 0.9121, recall: 0.8423, f1: 0.8758, edges-pos-ontonotes_loss: 0.0149
09/16 04:05:15 AM: Update 15703: task edges-pos-ontonotes, batch 703 (15703): mcc: 0.8741, acc: 0.8008, precision: 0.9123, recall: 0.8423, f1: 0.8759, edges-pos-ontonotes_loss: 0.0149
09/16 04:05:25 AM: Update 15746: task edges-pos-ontonotes, batch 746 (15746): mcc: 0.8737, acc: 0.8003, precision: 0.9120, recall: 0.8419, f1: 0.8756, edges-pos-ontonotes_loss: 0.0149
09/16 04:05:35 AM: Update 15808: task edges-pos-ontonotes, batch 808 (15808): mcc: 0.8740, acc: 0.8006, precision: 0.9122, recall: 0.8422, f1: 0.8758, edges-pos-ontonotes_loss: 0.0148
09/16 04:05:45 AM: Update 15870: task edges-pos-ontonotes, batch 870 (15870): mcc: 0.8743, acc: 0.8010, precision: 0.9125, recall: 0.8425, f1: 0.8761, edges-pos-ontonotes_loss: 0.0147
09/16 04:05:55 AM: Update 15938: task edges-pos-ontonotes, batch 938 (15938): mcc: 0.8749, acc: 0.8018, precision: 0.9130, recall: 0.8432, f1: 0.8767, edges-pos-ontonotes_loss: 0.0145
09/16 04:06:04 AM: ***** Step 16000 / Validation 16 *****
09/16 04:06:04 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:06:04 AM: Validating...
09/16 04:06:05 AM: Evaluate: task edges-pos-ontonotes, batch 6 (157): mcc: 0.9065, acc: 0.8589, precision: 0.9344, recall: 0.8830, f1: 0.9080, edges-pos-ontonotes_loss: 0.0112
09/16 04:06:15 AM: Evaluate: task edges-pos-ontonotes, batch 72 (157): mcc: 0.9049, acc: 0.8489, precision: 0.9448, recall: 0.8704, f1: 0.9061, edges-pos-ontonotes_loss: 0.0117
09/16 04:06:26 AM: Evaluate: task edges-pos-ontonotes, batch 123 (157): mcc: 0.9071, acc: 0.8535, precision: 0.9409, recall: 0.8782, f1: 0.9084, edges-pos-ontonotes_loss: 0.0112
09/16 04:06:33 AM: Updating LR scheduler:
09/16 04:06:33 AM: 	Best result seen so far for macro_avg: 0.911
09/16 04:06:33 AM: 	# validation passes without improvement: 1
09/16 04:06:33 AM: edges-pos-ontonotes_loss: training: 0.014407 validation: 0.011021
09/16 04:06:33 AM: macro_avg: validation: 0.910567
09/16 04:06:33 AM: micro_avg: validation: 0.000000
09/16 04:06:33 AM: edges-pos-ontonotes_mcc: training: 0.875293 validation: 0.909162
09/16 04:06:33 AM: edges-pos-ontonotes_acc: training: 0.802277 validation: 0.857879
09/16 04:06:33 AM: edges-pos-ontonotes_precision: training: 0.913311 validation: 0.939155
09/16 04:06:33 AM: edges-pos-ontonotes_recall: training: 0.843623 validation: 0.883668
09/16 04:06:33 AM: edges-pos-ontonotes_f1: training: 0.877085 validation: 0.910567
09/16 04:06:33 AM: Global learning rate: 0.0001
09/16 04:06:33 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:06:36 AM: Update 16018: task edges-pos-ontonotes, batch 18 (16018): mcc: 0.8810, acc: 0.8094, precision: 0.9124, recall: 0.8553, f1: 0.8829, edges-pos-ontonotes_loss: 0.0127
09/16 04:06:46 AM: Update 16078: task edges-pos-ontonotes, batch 78 (16078): mcc: 0.8919, acc: 0.8242, precision: 0.9256, recall: 0.8636, f1: 0.8935, edges-pos-ontonotes_loss: 0.0120
09/16 04:06:56 AM: Update 16161: task edges-pos-ontonotes, batch 161 (16161): mcc: 0.8981, acc: 0.8320, precision: 0.9317, recall: 0.8696, f1: 0.8996, edges-pos-ontonotes_loss: 0.0116
09/16 04:07:06 AM: Update 16244: task edges-pos-ontonotes, batch 244 (16244): mcc: 0.9003, acc: 0.8355, precision: 0.9337, recall: 0.8720, f1: 0.9018, edges-pos-ontonotes_loss: 0.0114
09/16 04:07:16 AM: Update 16327: task edges-pos-ontonotes, batch 327 (16327): mcc: 0.9019, acc: 0.8375, precision: 0.9351, recall: 0.8738, f1: 0.9034, edges-pos-ontonotes_loss: 0.0113
09/16 04:07:26 AM: Update 16412: task edges-pos-ontonotes, batch 412 (16412): mcc: 0.9008, acc: 0.8357, precision: 0.9352, recall: 0.8715, f1: 0.9022, edges-pos-ontonotes_loss: 0.0115
09/16 04:07:36 AM: Update 16509: task edges-pos-ontonotes, batch 509 (16509): mcc: 0.9008, acc: 0.8356, precision: 0.9358, recall: 0.8708, f1: 0.9022, edges-pos-ontonotes_loss: 0.0115
09/16 04:07:46 AM: Update 16608: task edges-pos-ontonotes, batch 608 (16608): mcc: 0.9009, acc: 0.8361, precision: 0.9360, recall: 0.8710, f1: 0.9023, edges-pos-ontonotes_loss: 0.0115
09/16 04:07:56 AM: Update 16704: task edges-pos-ontonotes, batch 704 (16704): mcc: 0.8991, acc: 0.8336, precision: 0.9350, recall: 0.8685, f1: 0.9005, edges-pos-ontonotes_loss: 0.0117
09/16 04:08:06 AM: Update 16835: task edges-pos-ontonotes, batch 835 (16835): mcc: 0.8961, acc: 0.8289, precision: 0.9332, recall: 0.8644, f1: 0.8975, edges-pos-ontonotes_loss: 0.0122
09/16 04:08:17 AM: Update 16950: task edges-pos-ontonotes, batch 950 (16950): mcc: 0.8934, acc: 0.8252, precision: 0.9314, recall: 0.8611, f1: 0.8949, edges-pos-ontonotes_loss: 0.0126
09/16 04:08:26 AM: ***** Step 17000 / Validation 17 *****
09/16 04:08:26 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:08:26 AM: Validating...
09/16 04:08:27 AM: Evaluate: task edges-pos-ontonotes, batch 2 (157): mcc: 0.9085, acc: 0.8588, precision: 0.9421, recall: 0.8797, f1: 0.9098, edges-pos-ontonotes_loss: 0.0106
09/16 04:08:37 AM: Evaluate: task edges-pos-ontonotes, batch 66 (157): mcc: 0.9032, acc: 0.8463, precision: 0.9451, recall: 0.8668, f1: 0.9043, edges-pos-ontonotes_loss: 0.0117
09/16 04:08:47 AM: Evaluate: task edges-pos-ontonotes, batch 113 (157): mcc: 0.9045, acc: 0.8494, precision: 0.9394, recall: 0.8746, f1: 0.9058, edges-pos-ontonotes_loss: 0.0114
09/16 04:08:57 AM: Evaluate: task edges-pos-ontonotes, batch 156 (157): mcc: 0.9059, acc: 0.8525, precision: 0.9347, recall: 0.8817, f1: 0.9074, edges-pos-ontonotes_loss: 0.0113
09/16 04:08:57 AM: Updating LR scheduler:
09/16 04:08:57 AM: 	Best result seen so far for macro_avg: 0.911
09/16 04:08:57 AM: 	# validation passes without improvement: 2
09/16 04:08:57 AM: edges-pos-ontonotes_loss: training: 0.012693 validation: 0.011276
09/16 04:08:57 AM: macro_avg: validation: 0.907460
09/16 04:08:57 AM: micro_avg: validation: 0.000000
09/16 04:08:57 AM: edges-pos-ontonotes_mcc: training: 0.890702 validation: 0.905953
09/16 04:08:57 AM: edges-pos-ontonotes_acc: training: 0.821281 validation: 0.852577
09/16 04:08:57 AM: edges-pos-ontonotes_precision: training: 0.928670 validation: 0.934771
09/16 04:08:57 AM: edges-pos-ontonotes_recall: training: 0.858463 validation: 0.881700
09/16 04:08:57 AM: edges-pos-ontonotes_f1: training: 0.892188 validation: 0.907460
09/16 04:08:57 AM: Global learning rate: 0.0001
09/16 04:08:57 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:09:07 AM: Update 17057: task edges-pos-ontonotes, batch 57 (17057): mcc: 0.8621, acc: 0.7798, precision: 0.9015, recall: 0.8297, f1: 0.8641, edges-pos-ontonotes_loss: 0.0160
09/16 04:09:17 AM: Update 17108: task edges-pos-ontonotes, batch 108 (17108): mcc: 0.8610, acc: 0.7776, precision: 0.9001, recall: 0.8288, f1: 0.8630, edges-pos-ontonotes_loss: 0.0163
09/16 04:09:28 AM: Update 17164: task edges-pos-ontonotes, batch 164 (17164): mcc: 0.8611, acc: 0.7780, precision: 0.9009, recall: 0.8284, f1: 0.8631, edges-pos-ontonotes_loss: 0.0164
09/16 04:09:38 AM: Update 17223: task edges-pos-ontonotes, batch 223 (17223): mcc: 0.8618, acc: 0.7791, precision: 0.9018, recall: 0.8288, f1: 0.8638, edges-pos-ontonotes_loss: 0.0164
09/16 04:09:48 AM: Update 17282: task edges-pos-ontonotes, batch 282 (17282): mcc: 0.8615, acc: 0.7791, precision: 0.9018, recall: 0.8283, f1: 0.8635, edges-pos-ontonotes_loss: 0.0164
09/16 04:10:01 AM: Update 17301: task edges-pos-ontonotes, batch 301 (17301): mcc: 0.8610, acc: 0.7782, precision: 0.9016, recall: 0.8275, f1: 0.8629, edges-pos-ontonotes_loss: 0.0165
09/16 04:10:11 AM: Update 17388: task edges-pos-ontonotes, batch 388 (17388): mcc: 0.8615, acc: 0.7786, precision: 0.9038, recall: 0.8264, f1: 0.8634, edges-pos-ontonotes_loss: 0.0162
09/16 04:10:21 AM: Update 17469: task edges-pos-ontonotes, batch 469 (17469): mcc: 0.8620, acc: 0.7793, precision: 0.9054, recall: 0.8260, f1: 0.8639, edges-pos-ontonotes_loss: 0.0160
09/16 04:10:31 AM: Update 17548: task edges-pos-ontonotes, batch 548 (17548): mcc: 0.8625, acc: 0.7799, precision: 0.9062, recall: 0.8261, f1: 0.8643, edges-pos-ontonotes_loss: 0.0158
09/16 04:10:41 AM: Update 17620: task edges-pos-ontonotes, batch 620 (17620): mcc: 0.8631, acc: 0.7807, precision: 0.9068, recall: 0.8266, f1: 0.8649, edges-pos-ontonotes_loss: 0.0156
09/16 04:10:51 AM: Update 17694: task edges-pos-ontonotes, batch 694 (17694): mcc: 0.8639, acc: 0.7819, precision: 0.9069, recall: 0.8282, f1: 0.8657, edges-pos-ontonotes_loss: 0.0156
09/16 04:11:01 AM: Update 17768: task edges-pos-ontonotes, batch 768 (17768): mcc: 0.8649, acc: 0.7833, precision: 0.9074, recall: 0.8295, f1: 0.8667, edges-pos-ontonotes_loss: 0.0154
09/16 04:11:11 AM: Update 17827: task edges-pos-ontonotes, batch 827 (17827): mcc: 0.8656, acc: 0.7843, precision: 0.9076, recall: 0.8307, f1: 0.8674, edges-pos-ontonotes_loss: 0.0154
09/16 04:11:21 AM: Update 17892: task edges-pos-ontonotes, batch 892 (17892): mcc: 0.8664, acc: 0.7854, precision: 0.9079, recall: 0.8318, f1: 0.8682, edges-pos-ontonotes_loss: 0.0153
09/16 04:11:31 AM: Update 17942: task edges-pos-ontonotes, batch 942 (17942): mcc: 0.8664, acc: 0.7855, precision: 0.9076, recall: 0.8320, f1: 0.8682, edges-pos-ontonotes_loss: 0.0153
09/16 04:11:41 AM: Update 17993: task edges-pos-ontonotes, batch 993 (17993): mcc: 0.8661, acc: 0.7853, precision: 0.9071, recall: 0.8320, f1: 0.8679, edges-pos-ontonotes_loss: 0.0153
09/16 04:11:42 AM: ***** Step 18000 / Validation 18 *****
09/16 04:11:42 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:11:42 AM: Validating...
09/16 04:11:51 AM: Evaluate: task edges-pos-ontonotes, batch 56 (157): mcc: 0.9064, acc: 0.8499, precision: 0.9503, recall: 0.8680, f1: 0.9073, edges-pos-ontonotes_loss: 0.0113
09/16 04:12:02 AM: Evaluate: task edges-pos-ontonotes, batch 106 (157): mcc: 0.9116, acc: 0.8589, precision: 0.9489, recall: 0.8790, f1: 0.9127, edges-pos-ontonotes_loss: 0.0107
09/16 04:12:12 AM: Evaluate: task edges-pos-ontonotes, batch 148 (157): mcc: 0.9104, acc: 0.8585, precision: 0.9435, recall: 0.8819, f1: 0.9117, edges-pos-ontonotes_loss: 0.0107
09/16 04:12:14 AM: Best result seen so far for edges-pos-ontonotes.
09/16 04:12:14 AM: Best result seen so far for macro.
09/16 04:12:14 AM: Updating LR scheduler:
09/16 04:12:14 AM: 	Best result seen so far for macro_avg: 0.912
09/16 04:12:14 AM: 	# validation passes without improvement: 0
09/16 04:12:14 AM: edges-pos-ontonotes_loss: training: 0.015304 validation: 0.010715
09/16 04:12:14 AM: macro_avg: validation: 0.912151
09/16 04:12:14 AM: micro_avg: validation: 0.000000
09/16 04:12:14 AM: edges-pos-ontonotes_mcc: training: 0.866055 validation: 0.910869
09/16 04:12:14 AM: edges-pos-ontonotes_acc: training: 0.785272 validation: 0.859593
09/16 04:12:14 AM: edges-pos-ontonotes_precision: training: 0.907063 validation: 0.943497
09/16 04:12:14 AM: edges-pos-ontonotes_recall: training: 0.831981 validation: 0.882822
09/16 04:12:14 AM: edges-pos-ontonotes_f1: training: 0.867901 validation: 0.912151
09/16 04:12:14 AM: Global learning rate: 0.0001
09/16 04:12:14 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:12:22 AM: Update 18044: task edges-pos-ontonotes, batch 44 (18044): mcc: 0.8669, acc: 0.7880, precision: 0.9040, recall: 0.8364, f1: 0.8689, edges-pos-ontonotes_loss: 0.0151
09/16 04:12:32 AM: Update 18099: task edges-pos-ontonotes, batch 99 (18099): mcc: 0.8670, acc: 0.7887, precision: 0.9035, recall: 0.8371, f1: 0.8691, edges-pos-ontonotes_loss: 0.0156
09/16 04:12:42 AM: Update 18154: task edges-pos-ontonotes, batch 154 (18154): mcc: 0.8671, acc: 0.7886, precision: 0.9032, recall: 0.8376, f1: 0.8692, edges-pos-ontonotes_loss: 0.0154
09/16 04:12:52 AM: Update 18210: task edges-pos-ontonotes, batch 210 (18210): mcc: 0.8680, acc: 0.7899, precision: 0.9040, recall: 0.8384, f1: 0.8700, edges-pos-ontonotes_loss: 0.0153
09/16 04:13:02 AM: Update 18253: task edges-pos-ontonotes, batch 253 (18253): mcc: 0.8677, acc: 0.7895, precision: 0.9042, recall: 0.8378, f1: 0.8697, edges-pos-ontonotes_loss: 0.0154
09/16 04:13:12 AM: Update 18306: task edges-pos-ontonotes, batch 306 (18306): mcc: 0.8686, acc: 0.7907, precision: 0.9050, recall: 0.8387, f1: 0.8706, edges-pos-ontonotes_loss: 0.0152
09/16 04:13:22 AM: Update 18356: task edges-pos-ontonotes, batch 356 (18356): mcc: 0.8691, acc: 0.7916, precision: 0.9054, recall: 0.8392, f1: 0.8711, edges-pos-ontonotes_loss: 0.0153
09/16 04:13:32 AM: Update 18408: task edges-pos-ontonotes, batch 408 (18408): mcc: 0.8692, acc: 0.7920, precision: 0.9055, recall: 0.8393, f1: 0.8712, edges-pos-ontonotes_loss: 0.0152
09/16 04:13:42 AM: Update 18458: task edges-pos-ontonotes, batch 458 (18458): mcc: 0.8697, acc: 0.7930, precision: 0.9060, recall: 0.8399, f1: 0.8717, edges-pos-ontonotes_loss: 0.0152
09/16 04:13:52 AM: Update 18515: task edges-pos-ontonotes, batch 515 (18515): mcc: 0.8703, acc: 0.7938, precision: 0.9065, recall: 0.8406, f1: 0.8723, edges-pos-ontonotes_loss: 0.0151
09/16 04:14:02 AM: Update 18554: task edges-pos-ontonotes, batch 554 (18554): mcc: 0.8702, acc: 0.7938, precision: 0.9064, recall: 0.8403, f1: 0.8721, edges-pos-ontonotes_loss: 0.0151
09/16 04:14:12 AM: Update 18612: task edges-pos-ontonotes, batch 612 (18612): mcc: 0.8708, acc: 0.7949, precision: 0.9071, recall: 0.8409, f1: 0.8728, edges-pos-ontonotes_loss: 0.0150
09/16 04:14:23 AM: Update 18663: task edges-pos-ontonotes, batch 663 (18663): mcc: 0.8711, acc: 0.7955, precision: 0.9073, recall: 0.8413, f1: 0.8731, edges-pos-ontonotes_loss: 0.0150
09/16 04:14:33 AM: Update 18718: task edges-pos-ontonotes, batch 718 (18718): mcc: 0.8715, acc: 0.7962, precision: 0.9077, recall: 0.8417, f1: 0.8735, edges-pos-ontonotes_loss: 0.0150
09/16 04:14:43 AM: Update 18766: task edges-pos-ontonotes, batch 766 (18766): mcc: 0.8719, acc: 0.7967, precision: 0.9079, recall: 0.8423, f1: 0.8738, edges-pos-ontonotes_loss: 0.0149
09/16 04:14:53 AM: Update 18816: task edges-pos-ontonotes, batch 816 (18816): mcc: 0.8722, acc: 0.7972, precision: 0.9082, recall: 0.8426, f1: 0.8741, edges-pos-ontonotes_loss: 0.0149
09/16 04:15:03 AM: Update 18862: task edges-pos-ontonotes, batch 862 (18862): mcc: 0.8725, acc: 0.7977, precision: 0.9084, recall: 0.8429, f1: 0.8744, edges-pos-ontonotes_loss: 0.0149
09/16 04:15:13 AM: Update 18899: task edges-pos-ontonotes, batch 899 (18899): mcc: 0.8725, acc: 0.7977, precision: 0.9085, recall: 0.8428, f1: 0.8744, edges-pos-ontonotes_loss: 0.0149
09/16 04:15:23 AM: Update 18952: task edges-pos-ontonotes, batch 952 (18952): mcc: 0.8729, acc: 0.7984, precision: 0.9089, recall: 0.8432, f1: 0.8748, edges-pos-ontonotes_loss: 0.0149
09/16 04:15:32 AM: ***** Step 19000 / Validation 19 *****
09/16 04:15:32 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:15:32 AM: Validating...
09/16 04:15:33 AM: Evaluate: task edges-pos-ontonotes, batch 5 (157): mcc: 0.9041, acc: 0.8510, precision: 0.9328, recall: 0.8800, f1: 0.9056, edges-pos-ontonotes_loss: 0.0115
09/16 04:15:43 AM: Evaluate: task edges-pos-ontonotes, batch 72 (157): mcc: 0.9090, acc: 0.8552, precision: 0.9459, recall: 0.8771, f1: 0.9102, edges-pos-ontonotes_loss: 0.0113
09/16 04:15:53 AM: Evaluate: task edges-pos-ontonotes, batch 123 (157): mcc: 0.9105, acc: 0.8589, precision: 0.9421, recall: 0.8834, f1: 0.9118, edges-pos-ontonotes_loss: 0.0109
09/16 04:16:01 AM: Best result seen so far for edges-pos-ontonotes.
09/16 04:16:01 AM: Best result seen so far for macro.
09/16 04:16:01 AM: Updating LR scheduler:
09/16 04:16:01 AM: 	Best result seen so far for macro_avg: 0.913
09/16 04:16:01 AM: 	# validation passes without improvement: 0
09/16 04:16:01 AM: edges-pos-ontonotes_loss: training: 0.014878 validation: 0.010728
09/16 04:16:01 AM: macro_avg: validation: 0.913409
09/16 04:16:01 AM: micro_avg: validation: 0.000000
09/16 04:16:01 AM: edges-pos-ontonotes_mcc: training: 0.872933 validation: 0.912008
09/16 04:16:01 AM: edges-pos-ontonotes_acc: training: 0.798554 validation: 0.862281
09/16 04:16:01 AM: edges-pos-ontonotes_precision: training: 0.909001 validation: 0.940248
09/16 04:16:01 AM: edges-pos-ontonotes_recall: training: 0.843176 validation: 0.888060
09/16 04:16:01 AM: edges-pos-ontonotes_f1: training: 0.874852 validation: 0.913409
09/16 04:16:01 AM: Global learning rate: 0.0001
09/16 04:16:01 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:16:03 AM: Update 19008: task edges-pos-ontonotes, batch 8 (19008): mcc: 0.8801, acc: 0.8109, precision: 0.9106, recall: 0.8552, f1: 0.8820, edges-pos-ontonotes_loss: 0.0142
09/16 04:16:14 AM: Update 19056: task edges-pos-ontonotes, batch 56 (19056): mcc: 0.8791, acc: 0.8088, precision: 0.9138, recall: 0.8504, f1: 0.8810, edges-pos-ontonotes_loss: 0.0149
09/16 04:16:24 AM: Update 19106: task edges-pos-ontonotes, batch 106 (19106): mcc: 0.8779, acc: 0.8073, precision: 0.9135, recall: 0.8485, f1: 0.8798, edges-pos-ontonotes_loss: 0.0150
09/16 04:16:34 AM: Update 19155: task edges-pos-ontonotes, batch 155 (19155): mcc: 0.8781, acc: 0.8075, precision: 0.9138, recall: 0.8485, f1: 0.8799, edges-pos-ontonotes_loss: 0.0148
09/16 04:16:48 AM: Update 19179: task edges-pos-ontonotes, batch 179 (19179): mcc: 0.8771, acc: 0.8058, precision: 0.9133, recall: 0.8470, f1: 0.8789, edges-pos-ontonotes_loss: 0.0148
09/16 04:16:58 AM: Update 19233: task edges-pos-ontonotes, batch 233 (19233): mcc: 0.8768, acc: 0.8052, precision: 0.9127, recall: 0.8470, f1: 0.8786, edges-pos-ontonotes_loss: 0.0144
09/16 04:17:08 AM: Update 19298: task edges-pos-ontonotes, batch 298 (19298): mcc: 0.8776, acc: 0.8061, precision: 0.9134, recall: 0.8480, f1: 0.8795, edges-pos-ontonotes_loss: 0.0141
09/16 04:17:19 AM: Update 19365: task edges-pos-ontonotes, batch 365 (19365): mcc: 0.8782, acc: 0.8068, precision: 0.9138, recall: 0.8487, f1: 0.8800, edges-pos-ontonotes_loss: 0.0138
09/16 04:17:29 AM: Update 19428: task edges-pos-ontonotes, batch 428 (19428): mcc: 0.8795, acc: 0.8085, precision: 0.9149, recall: 0.8501, f1: 0.8813, edges-pos-ontonotes_loss: 0.0136
09/16 04:17:39 AM: Update 19490: task edges-pos-ontonotes, batch 490 (19490): mcc: 0.8802, acc: 0.8094, precision: 0.9153, recall: 0.8510, f1: 0.8820, edges-pos-ontonotes_loss: 0.0134
09/16 04:17:49 AM: Update 19567: task edges-pos-ontonotes, batch 567 (19567): mcc: 0.8823, acc: 0.8121, precision: 0.9172, recall: 0.8532, f1: 0.8841, edges-pos-ontonotes_loss: 0.0131
09/16 04:18:00 AM: Update 19648: task edges-pos-ontonotes, batch 648 (19648): mcc: 0.8845, acc: 0.8150, precision: 0.9192, recall: 0.8556, f1: 0.8863, edges-pos-ontonotes_loss: 0.0129
09/16 04:18:10 AM: Update 19718: task edges-pos-ontonotes, batch 718 (19718): mcc: 0.8863, acc: 0.8172, precision: 0.9207, recall: 0.8575, f1: 0.8880, edges-pos-ontonotes_loss: 0.0127
09/16 04:18:20 AM: Update 19793: task edges-pos-ontonotes, batch 793 (19793): mcc: 0.8878, acc: 0.8192, precision: 0.9219, recall: 0.8592, f1: 0.8894, edges-pos-ontonotes_loss: 0.0125
09/16 04:18:30 AM: Update 19862: task edges-pos-ontonotes, batch 862 (19862): mcc: 0.8884, acc: 0.8200, precision: 0.9227, recall: 0.8597, f1: 0.8901, edges-pos-ontonotes_loss: 0.0124
09/16 04:18:40 AM: Update 19952: task edges-pos-ontonotes, batch 952 (19952): mcc: 0.8892, acc: 0.8211, precision: 0.9236, recall: 0.8604, f1: 0.8909, edges-pos-ontonotes_loss: 0.0123
09/16 04:18:44 AM: ***** Step 20000 / Validation 20 *****
09/16 04:18:44 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:18:44 AM: Validating...
09/16 04:18:50 AM: Evaluate: task edges-pos-ontonotes, batch 39 (157): mcc: 0.8987, acc: 0.8392, precision: 0.9456, recall: 0.8579, f1: 0.8996, edges-pos-ontonotes_loss: 0.0120
09/16 04:19:00 AM: Evaluate: task edges-pos-ontonotes, batch 98 (157): mcc: 0.9062, acc: 0.8527, precision: 0.9431, recall: 0.8744, f1: 0.9075, edges-pos-ontonotes_loss: 0.0113
09/16 04:19:10 AM: Evaluate: task edges-pos-ontonotes, batch 142 (157): mcc: 0.9065, acc: 0.8539, precision: 0.9373, recall: 0.8803, f1: 0.9079, edges-pos-ontonotes_loss: 0.0111
09/16 04:19:14 AM: Updating LR scheduler:
09/16 04:19:14 AM: 	Best result seen so far for macro_avg: 0.913
09/16 04:19:14 AM: 	# validation passes without improvement: 1
09/16 04:19:14 AM: edges-pos-ontonotes_loss: training: 0.012263 validation: 0.011050
09/16 04:19:14 AM: macro_avg: validation: 0.909020
09/16 04:19:14 AM: micro_avg: validation: 0.000000
09/16 04:19:14 AM: edges-pos-ontonotes_mcc: training: 0.889577 validation: 0.907576
09/16 04:19:14 AM: edges-pos-ontonotes_acc: training: 0.821571 validation: 0.856122
09/16 04:19:14 AM: edges-pos-ontonotes_precision: training: 0.924035 validation: 0.937369
09/16 04:19:14 AM: edges-pos-ontonotes_recall: training: 0.860662 validation: 0.882335
09/16 04:19:14 AM: edges-pos-ontonotes_f1: training: 0.891224 validation: 0.909020
09/16 04:19:14 AM: Global learning rate: 0.0001
09/16 04:19:14 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:19:20 AM: Update 20071: task edges-pos-ontonotes, batch 71 (20071): mcc: 0.9059, acc: 0.8432, precision: 0.9393, recall: 0.8774, f1: 0.9073, edges-pos-ontonotes_loss: 0.0113
09/16 04:19:30 AM: Update 20138: task edges-pos-ontonotes, batch 138 (20138): mcc: 0.8979, acc: 0.8326, precision: 0.9333, recall: 0.8678, f1: 0.8994, edges-pos-ontonotes_loss: 0.0120
09/16 04:19:40 AM: Update 20272: task edges-pos-ontonotes, batch 272 (20272): mcc: 0.8888, acc: 0.8191, precision: 0.9278, recall: 0.8557, f1: 0.8903, edges-pos-ontonotes_loss: 0.0131
09/16 04:19:51 AM: Update 20390: task edges-pos-ontonotes, batch 390 (20390): mcc: 0.8840, acc: 0.8115, precision: 0.9241, recall: 0.8500, f1: 0.8855, edges-pos-ontonotes_loss: 0.0135
09/16 04:20:01 AM: Update 20453: task edges-pos-ontonotes, batch 453 (20453): mcc: 0.8796, acc: 0.8052, precision: 0.9192, recall: 0.8462, f1: 0.8812, edges-pos-ontonotes_loss: 0.0139
09/16 04:20:11 AM: Update 20514: task edges-pos-ontonotes, batch 514 (20514): mcc: 0.8765, acc: 0.8007, precision: 0.9157, recall: 0.8437, f1: 0.8782, edges-pos-ontonotes_loss: 0.0141
09/16 04:20:21 AM: Update 20570: task edges-pos-ontonotes, batch 570 (20570): mcc: 0.8743, acc: 0.7977, precision: 0.9135, recall: 0.8414, f1: 0.8760, edges-pos-ontonotes_loss: 0.0144
09/16 04:20:31 AM: Update 20633: task edges-pos-ontonotes, batch 633 (20633): mcc: 0.8726, acc: 0.7955, precision: 0.9117, recall: 0.8401, f1: 0.8744, edges-pos-ontonotes_loss: 0.0146
09/16 04:20:41 AM: Update 20687: task edges-pos-ontonotes, batch 687 (20687): mcc: 0.8715, acc: 0.7939, precision: 0.9105, recall: 0.8390, f1: 0.8733, edges-pos-ontonotes_loss: 0.0147
09/16 04:20:51 AM: Update 20738: task edges-pos-ontonotes, batch 738 (20738): mcc: 0.8708, acc: 0.7929, precision: 0.9095, recall: 0.8386, f1: 0.8726, edges-pos-ontonotes_loss: 0.0147
09/16 04:21:01 AM: Update 20800: task edges-pos-ontonotes, batch 800 (20800): mcc: 0.8700, acc: 0.7916, precision: 0.9095, recall: 0.8371, f1: 0.8718, edges-pos-ontonotes_loss: 0.0148
09/16 04:21:11 AM: Update 20884: task edges-pos-ontonotes, batch 884 (20884): mcc: 0.8696, acc: 0.7909, precision: 0.9101, recall: 0.8359, f1: 0.8714, edges-pos-ontonotes_loss: 0.0148
09/16 04:21:22 AM: Update 20972: task edges-pos-ontonotes, batch 972 (20972): mcc: 0.8696, acc: 0.7907, precision: 0.9108, recall: 0.8352, f1: 0.8714, edges-pos-ontonotes_loss: 0.0147
09/16 04:21:25 AM: ***** Step 21000 / Validation 21 *****
09/16 04:21:25 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:21:25 AM: Validating...
09/16 04:21:32 AM: Evaluate: task edges-pos-ontonotes, batch 44 (157): mcc: 0.9058, acc: 0.8509, precision: 0.9432, recall: 0.8735, f1: 0.9070, edges-pos-ontonotes_loss: 0.0113
09/16 04:21:42 AM: Evaluate: task edges-pos-ontonotes, batch 100 (157): mcc: 0.9123, acc: 0.8623, precision: 0.9401, recall: 0.8888, f1: 0.9137, edges-pos-ontonotes_loss: 0.0107
09/16 04:21:52 AM: Evaluate: task edges-pos-ontonotes, batch 141 (157): mcc: 0.9113, acc: 0.8611, precision: 0.9339, recall: 0.8928, f1: 0.9129, edges-pos-ontonotes_loss: 0.0107
09/16 04:21:56 AM: Best result seen so far for edges-pos-ontonotes.
09/16 04:21:56 AM: Best result seen so far for macro.
09/16 04:21:56 AM: Updating LR scheduler:
09/16 04:21:56 AM: 	Best result seen so far for macro_avg: 0.913
09/16 04:21:56 AM: 	# validation passes without improvement: 2
09/16 04:21:56 AM: edges-pos-ontonotes_loss: training: 0.014717 validation: 0.010671
09/16 04:21:56 AM: macro_avg: validation: 0.913479
09/16 04:21:56 AM: micro_avg: validation: 0.000000
09/16 04:21:56 AM: edges-pos-ontonotes_mcc: training: 0.869552 validation: 0.911895
09/16 04:21:56 AM: edges-pos-ontonotes_acc: training: 0.790636 validation: 0.862800
09/16 04:21:56 AM: edges-pos-ontonotes_precision: training: 0.910880 validation: 0.933414
09/16 04:21:56 AM: edges-pos-ontonotes_recall: training: 0.835043 validation: 0.894378
09/16 04:21:56 AM: edges-pos-ontonotes_f1: training: 0.871315 validation: 0.913479
09/16 04:21:56 AM: Global learning rate: 0.0001
09/16 04:21:56 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:22:02 AM: Update 21045: task edges-pos-ontonotes, batch 45 (21045): mcc: 0.8735, acc: 0.7954, precision: 0.9199, recall: 0.8342, f1: 0.8749, edges-pos-ontonotes_loss: 0.0139
09/16 04:22:12 AM: Update 21103: task edges-pos-ontonotes, batch 103 (21103): mcc: 0.8721, acc: 0.7937, precision: 0.9135, recall: 0.8374, f1: 0.8738, edges-pos-ontonotes_loss: 0.0143
09/16 04:22:22 AM: Update 21164: task edges-pos-ontonotes, batch 164 (21164): mcc: 0.8726, acc: 0.7953, precision: 0.9108, recall: 0.8410, f1: 0.8745, edges-pos-ontonotes_loss: 0.0143
09/16 04:22:32 AM: Update 21238: task edges-pos-ontonotes, batch 238 (21238): mcc: 0.8735, acc: 0.7964, precision: 0.9103, recall: 0.8430, f1: 0.8754, edges-pos-ontonotes_loss: 0.0143
09/16 04:22:42 AM: Update 21314: task edges-pos-ontonotes, batch 314 (21314): mcc: 0.8740, acc: 0.7974, precision: 0.9108, recall: 0.8435, f1: 0.8759, edges-pos-ontonotes_loss: 0.0142
09/16 04:22:53 AM: Update 21384: task edges-pos-ontonotes, batch 384 (21384): mcc: 0.8745, acc: 0.7979, precision: 0.9109, recall: 0.8443, f1: 0.8763, edges-pos-ontonotes_loss: 0.0141
09/16 04:23:04 AM: Update 21387: task edges-pos-ontonotes, batch 387 (21387): mcc: 0.8740, acc: 0.7972, precision: 0.9106, recall: 0.8437, f1: 0.8759, edges-pos-ontonotes_loss: 0.0142
09/16 04:23:14 AM: Update 21431: task edges-pos-ontonotes, batch 431 (21431): mcc: 0.8728, acc: 0.7957, precision: 0.9091, recall: 0.8429, f1: 0.8747, edges-pos-ontonotes_loss: 0.0143
09/16 04:23:24 AM: Update 21484: task edges-pos-ontonotes, batch 484 (21484): mcc: 0.8720, acc: 0.7948, precision: 0.9081, recall: 0.8422, f1: 0.8739, edges-pos-ontonotes_loss: 0.0144
09/16 04:23:34 AM: Update 21533: task edges-pos-ontonotes, batch 533 (21533): mcc: 0.8714, acc: 0.7942, precision: 0.9073, recall: 0.8419, f1: 0.8734, edges-pos-ontonotes_loss: 0.0145
09/16 04:23:44 AM: Update 21587: task edges-pos-ontonotes, batch 587 (21587): mcc: 0.8712, acc: 0.7940, precision: 0.9071, recall: 0.8417, f1: 0.8732, edges-pos-ontonotes_loss: 0.0146
09/16 04:23:54 AM: Update 21644: task edges-pos-ontonotes, batch 644 (21644): mcc: 0.8712, acc: 0.7940, precision: 0.9069, recall: 0.8419, f1: 0.8731, edges-pos-ontonotes_loss: 0.0147
09/16 04:24:06 AM: Update 21700: task edges-pos-ontonotes, batch 700 (21700): mcc: 0.8712, acc: 0.7941, precision: 0.9069, recall: 0.8419, f1: 0.8732, edges-pos-ontonotes_loss: 0.0147
09/16 04:24:16 AM: Update 21744: task edges-pos-ontonotes, batch 744 (21744): mcc: 0.8712, acc: 0.7941, precision: 0.9067, recall: 0.8420, f1: 0.8731, edges-pos-ontonotes_loss: 0.0147
09/16 04:24:26 AM: Update 21792: task edges-pos-ontonotes, batch 792 (21792): mcc: 0.8713, acc: 0.7944, precision: 0.9067, recall: 0.8422, f1: 0.8733, edges-pos-ontonotes_loss: 0.0147
09/16 04:24:37 AM: Update 21841: task edges-pos-ontonotes, batch 841 (21841): mcc: 0.8715, acc: 0.7948, precision: 0.9068, recall: 0.8425, f1: 0.8734, edges-pos-ontonotes_loss: 0.0147
09/16 04:24:47 AM: Update 21889: task edges-pos-ontonotes, batch 889 (21889): mcc: 0.8718, acc: 0.7955, precision: 0.9070, recall: 0.8430, f1: 0.8738, edges-pos-ontonotes_loss: 0.0147
09/16 04:24:57 AM: Update 21945: task edges-pos-ontonotes, batch 945 (21945): mcc: 0.8719, acc: 0.7957, precision: 0.9070, recall: 0.8431, f1: 0.8739, edges-pos-ontonotes_loss: 0.0147
09/16 04:25:07 AM: ***** Step 22000 / Validation 22 *****
09/16 04:25:07 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:25:07 AM: Validating...
09/16 04:25:07 AM: Evaluate: task edges-pos-ontonotes, batch 2 (157): mcc: 0.9213, acc: 0.8797, precision: 0.9569, recall: 0.8901, f1: 0.9223, edges-pos-ontonotes_loss: 0.0098
09/16 04:25:17 AM: Evaluate: task edges-pos-ontonotes, batch 69 (157): mcc: 0.9101, acc: 0.8565, precision: 0.9493, recall: 0.8760, f1: 0.9112, edges-pos-ontonotes_loss: 0.0111
09/16 04:25:27 AM: Evaluate: task edges-pos-ontonotes, batch 120 (157): mcc: 0.9127, acc: 0.8617, precision: 0.9461, recall: 0.8840, f1: 0.9140, edges-pos-ontonotes_loss: 0.0106
09/16 04:25:35 AM: Best result seen so far for edges-pos-ontonotes.
09/16 04:25:35 AM: Best result seen so far for macro.
09/16 04:25:35 AM: Updating LR scheduler:
09/16 04:25:35 AM: 	Best result seen so far for macro_avg: 0.915
09/16 04:25:35 AM: 	# validation passes without improvement: 0
09/16 04:25:35 AM: edges-pos-ontonotes_loss: training: 0.014653 validation: 0.010462
09/16 04:25:35 AM: macro_avg: validation: 0.914926
09/16 04:25:35 AM: micro_avg: validation: 0.000000
09/16 04:25:35 AM: edges-pos-ontonotes_mcc: training: 0.872326 validation: 0.913608
09/16 04:25:35 AM: edges-pos-ontonotes_acc: training: 0.796342 validation: 0.864080
09/16 04:25:35 AM: edges-pos-ontonotes_precision: training: 0.907432 validation: 0.943492
09/16 04:25:35 AM: edges-pos-ontonotes_recall: training: 0.843494 validation: 0.888039
09/16 04:25:35 AM: edges-pos-ontonotes_f1: training: 0.874295 validation: 0.914926
09/16 04:25:35 AM: Global learning rate: 0.0001
09/16 04:25:35 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:25:37 AM: Update 22008: task edges-pos-ontonotes, batch 8 (22008): mcc: 0.8766, acc: 0.8031, precision: 0.9095, recall: 0.8497, f1: 0.8786, edges-pos-ontonotes_loss: 0.0146
09/16 04:25:47 AM: Update 22045: task edges-pos-ontonotes, batch 45 (22045): mcc: 0.8715, acc: 0.7979, precision: 0.9078, recall: 0.8416, f1: 0.8734, edges-pos-ontonotes_loss: 0.0153
09/16 04:25:58 AM: Update 22101: task edges-pos-ontonotes, batch 101 (22101): mcc: 0.8752, acc: 0.8029, precision: 0.9102, recall: 0.8464, f1: 0.8772, edges-pos-ontonotes_loss: 0.0150
09/16 04:26:08 AM: Update 22154: task edges-pos-ontonotes, batch 154 (22154): mcc: 0.8765, acc: 0.8047, precision: 0.9113, recall: 0.8478, f1: 0.8784, edges-pos-ontonotes_loss: 0.0147
09/16 04:26:18 AM: Update 22212: task edges-pos-ontonotes, batch 212 (22212): mcc: 0.8769, acc: 0.8052, precision: 0.9124, recall: 0.8475, f1: 0.8788, edges-pos-ontonotes_loss: 0.0146
09/16 04:26:28 AM: Update 22262: task edges-pos-ontonotes, batch 262 (22262): mcc: 0.8777, acc: 0.8062, precision: 0.9130, recall: 0.8485, f1: 0.8796, edges-pos-ontonotes_loss: 0.0144
09/16 04:26:38 AM: Update 22317: task edges-pos-ontonotes, batch 317 (22317): mcc: 0.8778, acc: 0.8062, precision: 0.9130, recall: 0.8487, f1: 0.8797, edges-pos-ontonotes_loss: 0.0144
09/16 04:26:48 AM: Update 22357: task edges-pos-ontonotes, batch 357 (22357): mcc: 0.8778, acc: 0.8063, precision: 0.9129, recall: 0.8488, f1: 0.8797, edges-pos-ontonotes_loss: 0.0144
09/16 04:26:58 AM: Update 22405: task edges-pos-ontonotes, batch 405 (22405): mcc: 0.8775, acc: 0.8058, precision: 0.9128, recall: 0.8484, f1: 0.8794, edges-pos-ontonotes_loss: 0.0144
09/16 04:27:08 AM: Update 22455: task edges-pos-ontonotes, batch 455 (22455): mcc: 0.8777, acc: 0.8062, precision: 0.9127, recall: 0.8488, f1: 0.8796, edges-pos-ontonotes_loss: 0.0144
09/16 04:27:18 AM: Update 22505: task edges-pos-ontonotes, batch 505 (22505): mcc: 0.8779, acc: 0.8063, precision: 0.9127, recall: 0.8491, f1: 0.8797, edges-pos-ontonotes_loss: 0.0145
09/16 04:27:29 AM: Update 22556: task edges-pos-ontonotes, batch 556 (22556): mcc: 0.8782, acc: 0.8068, precision: 0.9130, recall: 0.8495, f1: 0.8801, edges-pos-ontonotes_loss: 0.0145
09/16 04:27:39 AM: Update 22600: task edges-pos-ontonotes, batch 600 (22600): mcc: 0.8782, acc: 0.8070, precision: 0.9131, recall: 0.8494, f1: 0.8801, edges-pos-ontonotes_loss: 0.0145
09/16 04:27:50 AM: Update 22639: task edges-pos-ontonotes, batch 639 (22639): mcc: 0.8780, acc: 0.8067, precision: 0.9130, recall: 0.8490, f1: 0.8798, edges-pos-ontonotes_loss: 0.0145
09/16 04:28:00 AM: Update 22691: task edges-pos-ontonotes, batch 691 (22691): mcc: 0.8778, acc: 0.8065, precision: 0.9127, recall: 0.8489, f1: 0.8796, edges-pos-ontonotes_loss: 0.0144
09/16 04:28:10 AM: Update 22755: task edges-pos-ontonotes, batch 755 (22755): mcc: 0.8783, acc: 0.8072, precision: 0.9130, recall: 0.8495, f1: 0.8801, edges-pos-ontonotes_loss: 0.0142
09/16 04:28:20 AM: Update 22820: task edges-pos-ontonotes, batch 820 (22820): mcc: 0.8785, acc: 0.8075, precision: 0.9134, recall: 0.8497, f1: 0.8804, edges-pos-ontonotes_loss: 0.0141
09/16 04:28:30 AM: Update 22894: task edges-pos-ontonotes, batch 894 (22894): mcc: 0.8792, acc: 0.8082, precision: 0.9138, recall: 0.8505, f1: 0.8810, edges-pos-ontonotes_loss: 0.0139
09/16 04:28:41 AM: Update 22952: task edges-pos-ontonotes, batch 952 (22952): mcc: 0.8793, acc: 0.8084, precision: 0.9139, recall: 0.8507, f1: 0.8811, edges-pos-ontonotes_loss: 0.0138
09/16 04:28:47 AM: ***** Step 23000 / Validation 23 *****
09/16 04:28:47 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:28:47 AM: Validating...
09/16 04:28:51 AM: Evaluate: task edges-pos-ontonotes, batch 27 (157): mcc: 0.9008, acc: 0.8423, precision: 0.9452, recall: 0.8622, f1: 0.9018, edges-pos-ontonotes_loss: 0.0117
09/16 04:29:01 AM: Evaluate: task edges-pos-ontonotes, batch 90 (157): mcc: 0.9100, acc: 0.8565, precision: 0.9471, recall: 0.8779, f1: 0.9112, edges-pos-ontonotes_loss: 0.0109
09/16 04:29:11 AM: Evaluate: task edges-pos-ontonotes, batch 133 (157): mcc: 0.9112, acc: 0.8597, precision: 0.9425, recall: 0.8844, f1: 0.9125, edges-pos-ontonotes_loss: 0.0107
09/16 04:29:16 AM: Updating LR scheduler:
09/16 04:29:16 AM: 	Best result seen so far for macro_avg: 0.915
09/16 04:29:16 AM: 	# validation passes without improvement: 1
09/16 04:29:16 AM: edges-pos-ontonotes_loss: training: 0.013707 validation: 0.010549
09/16 04:29:16 AM: macro_avg: validation: 0.914125
09/16 04:29:16 AM: micro_avg: validation: 0.000000
09/16 04:29:16 AM: edges-pos-ontonotes_mcc: training: 0.880146 validation: 0.912778
09/16 04:29:16 AM: edges-pos-ontonotes_acc: training: 0.809511 validation: 0.863043
09/16 04:29:16 AM: edges-pos-ontonotes_precision: training: 0.914626 validation: 0.942279
09/16 04:29:16 AM: edges-pos-ontonotes_recall: training: 0.851588 validation: 0.887605
09/16 04:29:16 AM: edges-pos-ontonotes_f1: training: 0.881982 validation: 0.914125
09/16 04:29:16 AM: Global learning rate: 0.0001
09/16 04:29:16 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:29:21 AM: Update 23043: task edges-pos-ontonotes, batch 43 (23043): mcc: 0.9077, acc: 0.8472, precision: 0.9380, recall: 0.8820, f1: 0.9091, edges-pos-ontonotes_loss: 0.0109
09/16 04:29:32 AM: Update 23129: task edges-pos-ontonotes, batch 129 (23129): mcc: 0.9077, acc: 0.8460, precision: 0.9386, recall: 0.8815, f1: 0.9091, edges-pos-ontonotes_loss: 0.0108
09/16 04:29:42 AM: Update 23215: task edges-pos-ontonotes, batch 215 (23215): mcc: 0.9096, acc: 0.8485, precision: 0.9392, recall: 0.8844, f1: 0.9110, edges-pos-ontonotes_loss: 0.0106
09/16 04:29:57 AM: Update 23265: task edges-pos-ontonotes, batch 265 (23265): mcc: 0.9096, acc: 0.8484, precision: 0.9398, recall: 0.8839, f1: 0.9110, edges-pos-ontonotes_loss: 0.0106
09/16 04:30:07 AM: Update 23368: task edges-pos-ontonotes, batch 368 (23368): mcc: 0.9084, acc: 0.8464, precision: 0.9399, recall: 0.8814, f1: 0.9097, edges-pos-ontonotes_loss: 0.0109
09/16 04:30:17 AM: Update 23446: task edges-pos-ontonotes, batch 446 (23446): mcc: 0.9081, acc: 0.8463, precision: 0.9400, recall: 0.8808, f1: 0.9094, edges-pos-ontonotes_loss: 0.0109
09/16 04:30:27 AM: Update 23535: task edges-pos-ontonotes, batch 535 (23535): mcc: 0.9075, acc: 0.8457, precision: 0.9394, recall: 0.8802, f1: 0.9088, edges-pos-ontonotes_loss: 0.0109
09/16 04:30:37 AM: Update 23630: task edges-pos-ontonotes, batch 630 (23630): mcc: 0.9050, acc: 0.8424, precision: 0.9377, recall: 0.8772, f1: 0.9064, edges-pos-ontonotes_loss: 0.0113
09/16 04:30:47 AM: Update 23749: task edges-pos-ontonotes, batch 749 (23749): mcc: 0.9009, acc: 0.8362, precision: 0.9349, recall: 0.8720, f1: 0.9023, edges-pos-ontonotes_loss: 0.0118
09/16 04:30:57 AM: Update 23871: task edges-pos-ontonotes, batch 871 (23871): mcc: 0.8980, acc: 0.8319, precision: 0.9329, recall: 0.8683, f1: 0.8995, edges-pos-ontonotes_loss: 0.0122
09/16 04:31:07 AM: Update 23922: task edges-pos-ontonotes, batch 922 (23922): mcc: 0.8951, acc: 0.8278, precision: 0.9305, recall: 0.8652, f1: 0.8966, edges-pos-ontonotes_loss: 0.0123
09/16 04:31:17 AM: Update 23979: task edges-pos-ontonotes, batch 979 (23979): mcc: 0.8920, acc: 0.8231, precision: 0.9275, recall: 0.8620, f1: 0.8935, edges-pos-ontonotes_loss: 0.0126
09/16 04:31:21 AM: ***** Step 24000 / Validation 24 *****
09/16 04:31:21 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:31:21 AM: Validating...
09/16 04:31:28 AM: Evaluate: task edges-pos-ontonotes, batch 47 (157): mcc: 0.9029, acc: 0.8443, precision: 0.9427, recall: 0.8685, f1: 0.9041, edges-pos-ontonotes_loss: 0.0115
09/16 04:31:38 AM: Evaluate: task edges-pos-ontonotes, batch 99 (157): mcc: 0.9085, acc: 0.8551, precision: 0.9402, recall: 0.8813, f1: 0.9098, edges-pos-ontonotes_loss: 0.0110
09/16 04:31:48 AM: Evaluate: task edges-pos-ontonotes, batch 138 (157): mcc: 0.9075, acc: 0.8541, precision: 0.9322, recall: 0.8870, f1: 0.9090, edges-pos-ontonotes_loss: 0.0110
09/16 04:31:52 AM: Updating LR scheduler:
09/16 04:31:52 AM: 	Best result seen so far for macro_avg: 0.915
09/16 04:31:52 AM: 	# validation passes without improvement: 2
09/16 04:31:52 AM: edges-pos-ontonotes_loss: training: 0.012648 validation: 0.010899
09/16 04:31:52 AM: macro_avg: validation: 0.910192
09/16 04:31:52 AM: micro_avg: validation: 0.000000
09/16 04:31:52 AM: edges-pos-ontonotes_mcc: training: 0.891247 validation: 0.908587
09/16 04:31:52 AM: edges-pos-ontonotes_acc: training: 0.822129 validation: 0.856355
09/16 04:31:52 AM: edges-pos-ontonotes_precision: training: 0.926678 validation: 0.932067
09/16 04:31:52 AM: edges-pos-ontonotes_recall: training: 0.861354 validation: 0.889319
09/16 04:31:52 AM: edges-pos-ontonotes_f1: training: 0.892823 validation: 0.910192
09/16 04:31:52 AM: Global learning rate: 0.0001
09/16 04:31:52 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:31:58 AM: Update 24028: task edges-pos-ontonotes, batch 28 (24028): mcc: 0.8669, acc: 0.7887, precision: 0.9000, recall: 0.8401, f1: 0.8690, edges-pos-ontonotes_loss: 0.0159
09/16 04:32:08 AM: Update 24079: task edges-pos-ontonotes, batch 79 (24079): mcc: 0.8676, acc: 0.7889, precision: 0.9029, recall: 0.8388, f1: 0.8696, edges-pos-ontonotes_loss: 0.0158
09/16 04:32:18 AM: Update 24139: task edges-pos-ontonotes, batch 139 (24139): mcc: 0.8670, acc: 0.7878, precision: 0.9030, recall: 0.8376, f1: 0.8691, edges-pos-ontonotes_loss: 0.0158
09/16 04:32:28 AM: Update 24201: task edges-pos-ontonotes, batch 201 (24201): mcc: 0.8667, acc: 0.7871, precision: 0.9034, recall: 0.8366, f1: 0.8687, edges-pos-ontonotes_loss: 0.0158
09/16 04:32:38 AM: Update 24264: task edges-pos-ontonotes, batch 264 (24264): mcc: 0.8665, acc: 0.7867, precision: 0.9050, recall: 0.8347, f1: 0.8684, edges-pos-ontonotes_loss: 0.0156
09/16 04:32:48 AM: Update 24350: task edges-pos-ontonotes, batch 350 (24350): mcc: 0.8671, acc: 0.7873, precision: 0.9067, recall: 0.8342, f1: 0.8690, edges-pos-ontonotes_loss: 0.0153
09/16 04:32:58 AM: Update 24428: task edges-pos-ontonotes, batch 428 (24428): mcc: 0.8674, acc: 0.7876, precision: 0.9081, recall: 0.8335, f1: 0.8692, edges-pos-ontonotes_loss: 0.0151
09/16 04:33:08 AM: Update 24517: task edges-pos-ontonotes, batch 517 (24517): mcc: 0.8682, acc: 0.7885, precision: 0.9095, recall: 0.8338, f1: 0.8700, edges-pos-ontonotes_loss: 0.0150
09/16 04:33:18 AM: Update 24573: task edges-pos-ontonotes, batch 573 (24573): mcc: 0.8687, acc: 0.7891, precision: 0.9093, recall: 0.8348, f1: 0.8705, edges-pos-ontonotes_loss: 0.0149
09/16 04:33:28 AM: Update 24641: task edges-pos-ontonotes, batch 641 (24641): mcc: 0.8696, acc: 0.7905, precision: 0.9096, recall: 0.8363, f1: 0.8714, edges-pos-ontonotes_loss: 0.0148
09/16 04:33:38 AM: Update 24719: task edges-pos-ontonotes, batch 719 (24719): mcc: 0.8702, acc: 0.7914, precision: 0.9099, recall: 0.8373, f1: 0.8721, edges-pos-ontonotes_loss: 0.0147
09/16 04:33:48 AM: Update 24788: task edges-pos-ontonotes, batch 788 (24788): mcc: 0.8710, acc: 0.7925, precision: 0.9101, recall: 0.8385, f1: 0.8729, edges-pos-ontonotes_loss: 0.0146
09/16 04:34:00 AM: Update 24847: task edges-pos-ontonotes, batch 847 (24847): mcc: 0.8713, acc: 0.7929, precision: 0.9102, recall: 0.8391, f1: 0.8732, edges-pos-ontonotes_loss: 0.0146
09/16 04:34:10 AM: Update 24905: task edges-pos-ontonotes, batch 905 (24905): mcc: 0.8710, acc: 0.7927, precision: 0.9094, recall: 0.8391, f1: 0.8729, edges-pos-ontonotes_loss: 0.0147
09/16 04:34:20 AM: Update 24953: task edges-pos-ontonotes, batch 953 (24953): mcc: 0.8709, acc: 0.7927, precision: 0.9090, recall: 0.8394, f1: 0.8728, edges-pos-ontonotes_loss: 0.0147
09/16 04:34:29 AM: ***** Step 25000 / Validation 25 *****
09/16 04:34:29 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:34:29 AM: Validating...
09/16 04:34:30 AM: Evaluate: task edges-pos-ontonotes, batch 5 (157): mcc: 0.9015, acc: 0.8491, precision: 0.9360, recall: 0.8720, f1: 0.9029, edges-pos-ontonotes_loss: 0.0113
09/16 04:34:40 AM: Evaluate: task edges-pos-ontonotes, batch 67 (157): mcc: 0.9120, acc: 0.8588, precision: 0.9512, recall: 0.8777, f1: 0.9130, edges-pos-ontonotes_loss: 0.0107
09/16 04:34:50 AM: Evaluate: task edges-pos-ontonotes, batch 115 (157): mcc: 0.9137, acc: 0.8628, precision: 0.9480, recall: 0.8840, f1: 0.9148, edges-pos-ontonotes_loss: 0.0104
09/16 04:35:00 AM: Best result seen so far for edges-pos-ontonotes.
09/16 04:35:00 AM: Best result seen so far for macro.
09/16 04:35:00 AM: Updating LR scheduler:
09/16 04:35:00 AM: 	Best result seen so far for macro_avg: 0.915
09/16 04:35:00 AM: 	# validation passes without improvement: 0
09/16 04:35:00 AM: edges-pos-ontonotes_loss: training: 0.014664 validation: 0.010298
09/16 04:35:00 AM: macro_avg: validation: 0.915164
09/16 04:35:00 AM: micro_avg: validation: 0.000000
09/16 04:35:00 AM: edges-pos-ontonotes_mcc: training: 0.870926 validation: 0.913885
09/16 04:35:00 AM: edges-pos-ontonotes_acc: training: 0.792812 validation: 0.864112
09/16 04:35:00 AM: edges-pos-ontonotes_precision: training: 0.908666 validation: 0.944789
09/16 04:35:00 AM: edges-pos-ontonotes_recall: training: 0.839689 validation: 0.887340
09/16 04:35:00 AM: edges-pos-ontonotes_f1: training: 0.872817 validation: 0.915164
09/16 04:35:00 AM: Global learning rate: 0.0001
09/16 04:35:00 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:35:00 AM: Update 25003: task edges-pos-ontonotes, batch 3 (25003): mcc: 0.8734, acc: 0.7983, precision: 0.9053, recall: 0.8476, f1: 0.8755, edges-pos-ontonotes_loss: 0.0145
09/16 04:35:10 AM: Update 25054: task edges-pos-ontonotes, batch 54 (25054): mcc: 0.8689, acc: 0.7926, precision: 0.9009, recall: 0.8431, f1: 0.8710, edges-pos-ontonotes_loss: 0.0153
09/16 04:35:21 AM: Update 25109: task edges-pos-ontonotes, batch 109 (25109): mcc: 0.8696, acc: 0.7934, precision: 0.9031, recall: 0.8424, f1: 0.8717, edges-pos-ontonotes_loss: 0.0152
09/16 04:35:39 AM: Update 25160: task edges-pos-ontonotes, batch 160 (25160): mcc: 0.8702, acc: 0.7940, precision: 0.9040, recall: 0.8426, f1: 0.8722, edges-pos-ontonotes_loss: 0.0152
09/16 04:35:49 AM: Update 25214: task edges-pos-ontonotes, batch 214 (25214): mcc: 0.8710, acc: 0.7953, precision: 0.9045, recall: 0.8437, f1: 0.8730, edges-pos-ontonotes_loss: 0.0150
09/16 04:36:00 AM: Update 25261: task edges-pos-ontonotes, batch 261 (25261): mcc: 0.8718, acc: 0.7964, precision: 0.9054, recall: 0.8443, f1: 0.8738, edges-pos-ontonotes_loss: 0.0149
09/16 04:36:10 AM: Update 25311: task edges-pos-ontonotes, batch 311 (25311): mcc: 0.8722, acc: 0.7971, precision: 0.9060, recall: 0.8446, f1: 0.8742, edges-pos-ontonotes_loss: 0.0149
09/16 04:36:20 AM: Update 25361: task edges-pos-ontonotes, batch 361 (25361): mcc: 0.8729, acc: 0.7980, precision: 0.9066, recall: 0.8454, f1: 0.8749, edges-pos-ontonotes_loss: 0.0148
09/16 04:36:30 AM: Update 25410: task edges-pos-ontonotes, batch 410 (25410): mcc: 0.8735, acc: 0.7989, precision: 0.9069, recall: 0.8462, f1: 0.8755, edges-pos-ontonotes_loss: 0.0148
09/16 04:36:40 AM: Update 25464: task edges-pos-ontonotes, batch 464 (25464): mcc: 0.8744, acc: 0.8002, precision: 0.9079, recall: 0.8470, f1: 0.8764, edges-pos-ontonotes_loss: 0.0146
09/16 04:36:50 AM: Update 25502: task edges-pos-ontonotes, batch 502 (25502): mcc: 0.8744, acc: 0.8003, precision: 0.9079, recall: 0.8470, f1: 0.8764, edges-pos-ontonotes_loss: 0.0146
09/16 04:37:00 AM: Update 25552: task edges-pos-ontonotes, batch 552 (25552): mcc: 0.8747, acc: 0.8008, precision: 0.9082, recall: 0.8473, f1: 0.8767, edges-pos-ontonotes_loss: 0.0146
09/16 04:37:10 AM: Update 25605: task edges-pos-ontonotes, batch 605 (25605): mcc: 0.8751, acc: 0.8015, precision: 0.9084, recall: 0.8477, f1: 0.8770, edges-pos-ontonotes_loss: 0.0146
09/16 04:37:20 AM: Update 25651: task edges-pos-ontonotes, batch 651 (25651): mcc: 0.8754, acc: 0.8019, precision: 0.9088, recall: 0.8480, f1: 0.8774, edges-pos-ontonotes_loss: 0.0146
09/16 04:37:31 AM: Update 25697: task edges-pos-ontonotes, batch 697 (25697): mcc: 0.8755, acc: 0.8023, precision: 0.9090, recall: 0.8481, f1: 0.8775, edges-pos-ontonotes_loss: 0.0145
09/16 04:37:41 AM: Update 25744: task edges-pos-ontonotes, batch 744 (25744): mcc: 0.8757, acc: 0.8026, precision: 0.9092, recall: 0.8483, f1: 0.8777, edges-pos-ontonotes_loss: 0.0145
09/16 04:37:51 AM: Update 25787: task edges-pos-ontonotes, batch 787 (25787): mcc: 0.8758, acc: 0.8027, precision: 0.9093, recall: 0.8483, f1: 0.8778, edges-pos-ontonotes_loss: 0.0145
09/16 04:38:01 AM: Update 25841: task edges-pos-ontonotes, batch 841 (25841): mcc: 0.8760, acc: 0.8029, precision: 0.9096, recall: 0.8484, f1: 0.8779, edges-pos-ontonotes_loss: 0.0145
09/16 04:38:11 AM: Update 25889: task edges-pos-ontonotes, batch 889 (25889): mcc: 0.8761, acc: 0.8032, precision: 0.9097, recall: 0.8486, f1: 0.8781, edges-pos-ontonotes_loss: 0.0145
09/16 04:38:21 AM: Update 25942: task edges-pos-ontonotes, batch 942 (25942): mcc: 0.8763, acc: 0.8035, precision: 0.9099, recall: 0.8487, f1: 0.8782, edges-pos-ontonotes_loss: 0.0145
09/16 04:38:31 AM: Update 25995: task edges-pos-ontonotes, batch 995 (25995): mcc: 0.8765, acc: 0.8039, precision: 0.9100, recall: 0.8490, f1: 0.8785, edges-pos-ontonotes_loss: 0.0145
09/16 04:38:32 AM: ***** Step 26000 / Validation 26 *****
09/16 04:38:32 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:38:32 AM: Validating...
09/16 04:38:41 AM: Evaluate: task edges-pos-ontonotes, batch 61 (157): mcc: 0.9089, acc: 0.8542, precision: 0.9493, recall: 0.8737, f1: 0.9099, edges-pos-ontonotes_loss: 0.0113
09/16 04:38:51 AM: Evaluate: task edges-pos-ontonotes, batch 114 (157): mcc: 0.9127, acc: 0.8622, precision: 0.9457, recall: 0.8841, f1: 0.9139, edges-pos-ontonotes_loss: 0.0106
09/16 04:39:01 AM: Best result seen so far for edges-pos-ontonotes.
09/16 04:39:01 AM: Best result seen so far for macro.
09/16 04:39:01 AM: Updating LR scheduler:
09/16 04:39:01 AM: 	Best result seen so far for macro_avg: 0.916
09/16 04:39:01 AM: 	# validation passes without improvement: 0
09/16 04:39:01 AM: edges-pos-ontonotes_loss: training: 0.014486 validation: 0.010372
09/16 04:39:01 AM: macro_avg: validation: 0.915850
09/16 04:39:01 AM: micro_avg: validation: 0.000000
09/16 04:39:01 AM: edges-pos-ontonotes_mcc: training: 0.876521 validation: 0.914523
09/16 04:39:01 AM: edges-pos-ontonotes_acc: training: 0.803883 validation: 0.866059
09/16 04:39:01 AM: edges-pos-ontonotes_precision: training: 0.910039 validation: 0.943501
09/16 04:39:01 AM: edges-pos-ontonotes_recall: training: 0.849010 validation: 0.889774
09/16 04:39:01 AM: edges-pos-ontonotes_f1: training: 0.878466 validation: 0.915850
09/16 04:39:01 AM: Global learning rate: 0.0001
09/16 04:39:01 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:39:01 AM: Update 26003: task edges-pos-ontonotes, batch 3 (26003): mcc: 0.8805, acc: 0.8116, precision: 0.9097, recall: 0.8569, f1: 0.8825, edges-pos-ontonotes_loss: 0.0141
09/16 04:39:11 AM: Update 26059: task edges-pos-ontonotes, batch 59 (26059): mcc: 0.8795, acc: 0.8100, precision: 0.9133, recall: 0.8516, f1: 0.8813, edges-pos-ontonotes_loss: 0.0143
09/16 04:39:21 AM: Update 26105: task edges-pos-ontonotes, batch 105 (26105): mcc: 0.8761, acc: 0.8054, precision: 0.9109, recall: 0.8475, f1: 0.8780, edges-pos-ontonotes_loss: 0.0145
09/16 04:39:32 AM: Update 26178: task edges-pos-ontonotes, batch 178 (26178): mcc: 0.8803, acc: 0.8099, precision: 0.9141, recall: 0.8524, f1: 0.8822, edges-pos-ontonotes_loss: 0.0136
09/16 04:39:42 AM: Update 26235: task edges-pos-ontonotes, batch 235 (26235): mcc: 0.8802, acc: 0.8100, precision: 0.9135, recall: 0.8528, f1: 0.8821, edges-pos-ontonotes_loss: 0.0134
09/16 04:39:52 AM: Update 26293: task edges-pos-ontonotes, batch 293 (26293): mcc: 0.8814, acc: 0.8116, precision: 0.9145, recall: 0.8542, f1: 0.8833, edges-pos-ontonotes_loss: 0.0131
09/16 04:40:02 AM: Update 26356: task edges-pos-ontonotes, batch 356 (26356): mcc: 0.8822, acc: 0.8126, precision: 0.9153, recall: 0.8549, f1: 0.8841, edges-pos-ontonotes_loss: 0.0129
09/16 04:40:12 AM: Update 26412: task edges-pos-ontonotes, batch 412 (26412): mcc: 0.8827, acc: 0.8130, precision: 0.9155, recall: 0.8555, f1: 0.8845, edges-pos-ontonotes_loss: 0.0128
09/16 04:40:22 AM: Update 26497: task edges-pos-ontonotes, batch 497 (26497): mcc: 0.8859, acc: 0.8173, precision: 0.9184, recall: 0.8590, f1: 0.8877, edges-pos-ontonotes_loss: 0.0125
09/16 04:40:32 AM: Update 26581: task edges-pos-ontonotes, batch 581 (26581): mcc: 0.8882, acc: 0.8204, precision: 0.9206, recall: 0.8613, f1: 0.8900, edges-pos-ontonotes_loss: 0.0122
09/16 04:40:42 AM: Update 26660: task edges-pos-ontonotes, batch 660 (26660): mcc: 0.8905, acc: 0.8235, precision: 0.9225, recall: 0.8638, f1: 0.8922, edges-pos-ontonotes_loss: 0.0120
09/16 04:40:52 AM: Update 26727: task edges-pos-ontonotes, batch 727 (26727): mcc: 0.8918, acc: 0.8253, precision: 0.9238, recall: 0.8652, f1: 0.8935, edges-pos-ontonotes_loss: 0.0119
09/16 04:41:02 AM: Update 26810: task edges-pos-ontonotes, batch 810 (26810): mcc: 0.8927, acc: 0.8265, precision: 0.9248, recall: 0.8659, f1: 0.8944, edges-pos-ontonotes_loss: 0.0118
09/16 04:41:12 AM: Update 26894: task edges-pos-ontonotes, batch 894 (26894): mcc: 0.8935, acc: 0.8275, precision: 0.9256, recall: 0.8666, f1: 0.8952, edges-pos-ontonotes_loss: 0.0118
09/16 04:41:22 AM: ***** Step 27000 / Validation 27 *****
09/16 04:41:22 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:41:22 AM: Validating...
09/16 04:41:22 AM: Evaluate: task edges-pos-ontonotes, batch 1 (157): mcc: 0.9213, acc: 0.8671, precision: 0.9595, recall: 0.8876, f1: 0.9221, edges-pos-ontonotes_loss: 0.0097
09/16 04:41:32 AM: Evaluate: task edges-pos-ontonotes, batch 67 (157): mcc: 0.9092, acc: 0.8580, precision: 0.9441, recall: 0.8791, f1: 0.9104, edges-pos-ontonotes_loss: 0.0111
09/16 04:41:43 AM: Evaluate: task edges-pos-ontonotes, batch 116 (157): mcc: 0.9103, acc: 0.8606, precision: 0.9382, recall: 0.8867, f1: 0.9117, edges-pos-ontonotes_loss: 0.0108
09/16 04:41:52 AM: Updating LR scheduler:
09/16 04:41:52 AM: 	Best result seen so far for macro_avg: 0.916
09/16 04:41:52 AM: 	# validation passes without improvement: 1
09/16 04:41:52 AM: edges-pos-ontonotes_loss: training: 0.011677 validation: 0.010634
09/16 04:41:52 AM: macro_avg: validation: 0.913461
09/16 04:41:52 AM: micro_avg: validation: 0.000000
09/16 04:41:52 AM: edges-pos-ontonotes_mcc: training: 0.894371 validation: 0.911912
09/16 04:41:52 AM: edges-pos-ontonotes_acc: training: 0.828677 validation: 0.863763
09/16 04:41:52 AM: edges-pos-ontonotes_precision: training: 0.926463 validation: 0.934880
09/16 04:41:52 AM: edges-pos-ontonotes_recall: training: 0.867488 validation: 0.893002
09/16 04:41:52 AM: edges-pos-ontonotes_f1: training: 0.896006 validation: 0.913461
09/16 04:41:52 AM: Global learning rate: 0.0001
09/16 04:41:52 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:41:53 AM: Update 27008: task edges-pos-ontonotes, batch 8 (27008): mcc: 0.9094, acc: 0.8508, precision: 0.9445, recall: 0.8791, f1: 0.9106, edges-pos-ontonotes_loss: 0.0108
09/16 04:42:03 AM: Update 27092: task edges-pos-ontonotes, batch 92 (27092): mcc: 0.8867, acc: 0.8166, precision: 0.9244, recall: 0.8549, f1: 0.8883, edges-pos-ontonotes_loss: 0.0131
09/16 04:42:13 AM: Update 27211: task edges-pos-ontonotes, batch 211 (27211): mcc: 0.8802, acc: 0.8067, precision: 0.9205, recall: 0.8462, f1: 0.8818, edges-pos-ontonotes_loss: 0.0139
09/16 04:42:23 AM: Update 27345: task edges-pos-ontonotes, batch 345 (27345): mcc: 0.8796, acc: 0.8051, precision: 0.9203, recall: 0.8453, f1: 0.8812, edges-pos-ontonotes_loss: 0.0137
09/16 04:42:33 AM: Update 27351: task edges-pos-ontonotes, batch 351 (27351): mcc: 0.8790, acc: 0.8043, precision: 0.9197, recall: 0.8447, f1: 0.8806, edges-pos-ontonotes_loss: 0.0137
09/16 04:42:44 AM: Update 27409: task edges-pos-ontonotes, batch 409 (27409): mcc: 0.8748, acc: 0.7985, precision: 0.9131, recall: 0.8429, f1: 0.8766, edges-pos-ontonotes_loss: 0.0141
09/16 04:42:54 AM: Update 27466: task edges-pos-ontonotes, batch 466 (27466): mcc: 0.8737, acc: 0.7968, precision: 0.9115, recall: 0.8422, f1: 0.8755, edges-pos-ontonotes_loss: 0.0143
09/16 04:43:04 AM: Update 27522: task edges-pos-ontonotes, batch 522 (27522): mcc: 0.8720, acc: 0.7944, precision: 0.9095, recall: 0.8409, f1: 0.8739, edges-pos-ontonotes_loss: 0.0144
09/16 04:43:14 AM: Update 27582: task edges-pos-ontonotes, batch 582 (27582): mcc: 0.8713, acc: 0.7934, precision: 0.9085, recall: 0.8405, f1: 0.8732, edges-pos-ontonotes_loss: 0.0145
09/16 04:43:24 AM: Update 27639: task edges-pos-ontonotes, batch 639 (27639): mcc: 0.8709, acc: 0.7929, precision: 0.9080, recall: 0.8401, f1: 0.8728, edges-pos-ontonotes_loss: 0.0146
09/16 04:43:34 AM: Update 27682: task edges-pos-ontonotes, batch 682 (27682): mcc: 0.8700, acc: 0.7917, precision: 0.9073, recall: 0.8392, f1: 0.8719, edges-pos-ontonotes_loss: 0.0147
09/16 04:43:44 AM: Update 27774: task edges-pos-ontonotes, batch 774 (27774): mcc: 0.8699, acc: 0.7913, precision: 0.9083, recall: 0.8380, f1: 0.8718, edges-pos-ontonotes_loss: 0.0147
09/16 04:43:55 AM: Update 27864: task edges-pos-ontonotes, batch 864 (27864): mcc: 0.8700, acc: 0.7915, precision: 0.9092, recall: 0.8376, f1: 0.8719, edges-pos-ontonotes_loss: 0.0146
09/16 04:44:05 AM: Update 27951: task edges-pos-ontonotes, batch 951 (27951): mcc: 0.8703, acc: 0.7918, precision: 0.9099, recall: 0.8373, f1: 0.8721, edges-pos-ontonotes_loss: 0.0146
09/16 04:44:13 AM: ***** Step 28000 / Validation 28 *****
09/16 04:44:13 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:44:13 AM: Validating...
09/16 04:44:15 AM: Evaluate: task edges-pos-ontonotes, batch 8 (157): mcc: 0.9029, acc: 0.8522, precision: 0.9261, recall: 0.8840, f1: 0.9046, edges-pos-ontonotes_loss: 0.0113
09/16 04:44:25 AM: Evaluate: task edges-pos-ontonotes, batch 73 (157): mcc: 0.9140, acc: 0.8638, precision: 0.9433, recall: 0.8890, f1: 0.9154, edges-pos-ontonotes_loss: 0.0104
09/16 04:44:35 AM: Evaluate: task edges-pos-ontonotes, batch 118 (157): mcc: 0.9140, acc: 0.8645, precision: 0.9383, recall: 0.8937, f1: 0.9154, edges-pos-ontonotes_loss: 0.0104
09/16 04:44:45 AM: Updating LR scheduler:
09/16 04:44:45 AM: 	Best result seen so far for macro_avg: 0.916
09/16 04:44:45 AM: 	# validation passes without improvement: 2
09/16 04:44:45 AM: edges-pos-ontonotes_loss: training: 0.014541 validation: 0.010356
09/16 04:44:45 AM: macro_avg: validation: 0.915684
09/16 04:44:45 AM: micro_avg: validation: 0.000000
09/16 04:44:45 AM: edges-pos-ontonotes_mcc: training: 0.870508 validation: 0.914125
09/16 04:44:45 AM: edges-pos-ontonotes_acc: training: 0.791999 validation: 0.865541
09/16 04:44:45 AM: edges-pos-ontonotes_precision: training: 0.910111 validation: 0.934735
09/16 04:44:45 AM: edges-pos-ontonotes_recall: training: 0.837557 validation: 0.897394
09/16 04:44:45 AM: edges-pos-ontonotes_f1: training: 0.872328 validation: 0.915684
09/16 04:44:45 AM: Global learning rate: 0.0001
09/16 04:44:45 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:44:45 AM: Update 28003: task edges-pos-ontonotes, batch 3 (28003): mcc: 0.8820, acc: 0.8163, precision: 0.9038, recall: 0.8655, f1: 0.8842, edges-pos-ontonotes_loss: 0.0122
09/16 04:44:55 AM: Update 28063: task edges-pos-ontonotes, batch 63 (28063): mcc: 0.8770, acc: 0.8014, precision: 0.9093, recall: 0.8507, f1: 0.8790, edges-pos-ontonotes_loss: 0.0139
09/16 04:45:05 AM: Update 28139: task edges-pos-ontonotes, batch 139 (28139): mcc: 0.8768, acc: 0.8007, precision: 0.9097, recall: 0.8499, f1: 0.8788, edges-pos-ontonotes_loss: 0.0140
09/16 04:45:16 AM: Update 28202: task edges-pos-ontonotes, batch 202 (28202): mcc: 0.8757, acc: 0.7993, precision: 0.9090, recall: 0.8484, f1: 0.8777, edges-pos-ontonotes_loss: 0.0140
09/16 04:45:26 AM: Update 28270: task edges-pos-ontonotes, batch 270 (28270): mcc: 0.8759, acc: 0.7996, precision: 0.9095, recall: 0.8483, f1: 0.8778, edges-pos-ontonotes_loss: 0.0139
09/16 04:45:36 AM: Update 28320: task edges-pos-ontonotes, batch 320 (28320): mcc: 0.8750, acc: 0.7985, precision: 0.9084, recall: 0.8477, f1: 0.8770, edges-pos-ontonotes_loss: 0.0140
09/16 04:45:46 AM: Update 28376: task edges-pos-ontonotes, batch 376 (28376): mcc: 0.8744, acc: 0.7978, precision: 0.9077, recall: 0.8471, f1: 0.8764, edges-pos-ontonotes_loss: 0.0141
09/16 04:45:56 AM: Update 28431: task edges-pos-ontonotes, batch 431 (28431): mcc: 0.8739, acc: 0.7975, precision: 0.9070, recall: 0.8469, f1: 0.8759, edges-pos-ontonotes_loss: 0.0142
09/16 04:46:06 AM: Update 28486: task edges-pos-ontonotes, batch 486 (28486): mcc: 0.8738, acc: 0.7975, precision: 0.9068, recall: 0.8469, f1: 0.8758, edges-pos-ontonotes_loss: 0.0144
09/16 04:46:16 AM: Update 28542: task edges-pos-ontonotes, batch 542 (28542): mcc: 0.8738, acc: 0.7977, precision: 0.9068, recall: 0.8470, f1: 0.8758, edges-pos-ontonotes_loss: 0.0144
09/16 04:46:26 AM: Update 28598: task edges-pos-ontonotes, batch 598 (28598): mcc: 0.8736, acc: 0.7975, precision: 0.9065, recall: 0.8469, f1: 0.8757, edges-pos-ontonotes_loss: 0.0144
09/16 04:46:37 AM: Update 28639: task edges-pos-ontonotes, batch 639 (28639): mcc: 0.8733, acc: 0.7971, precision: 0.9062, recall: 0.8464, f1: 0.8753, edges-pos-ontonotes_loss: 0.0145
09/16 04:46:47 AM: Update 28687: task edges-pos-ontonotes, batch 687 (28687): mcc: 0.8735, acc: 0.7975, precision: 0.9064, recall: 0.8466, f1: 0.8755, edges-pos-ontonotes_loss: 0.0145
09/16 04:46:57 AM: Update 28742: task edges-pos-ontonotes, batch 742 (28742): mcc: 0.8737, acc: 0.7980, precision: 0.9066, recall: 0.8469, f1: 0.8758, edges-pos-ontonotes_loss: 0.0144
09/16 04:47:07 AM: Update 28792: task edges-pos-ontonotes, batch 792 (28792): mcc: 0.8739, acc: 0.7983, precision: 0.9067, recall: 0.8472, f1: 0.8759, edges-pos-ontonotes_loss: 0.0144
09/16 04:47:17 AM: Update 28840: task edges-pos-ontonotes, batch 840 (28840): mcc: 0.8742, acc: 0.7987, precision: 0.9070, recall: 0.8473, f1: 0.8762, edges-pos-ontonotes_loss: 0.0144
09/16 04:47:27 AM: Update 28889: task edges-pos-ontonotes, batch 889 (28889): mcc: 0.8744, acc: 0.7992, precision: 0.9072, recall: 0.8477, f1: 0.8764, edges-pos-ontonotes_loss: 0.0144
09/16 04:47:38 AM: Update 28933: task edges-pos-ontonotes, batch 933 (28933): mcc: 0.8746, acc: 0.7996, precision: 0.9074, recall: 0.8478, f1: 0.8766, edges-pos-ontonotes_loss: 0.0144
09/16 04:47:48 AM: Update 28982: task edges-pos-ontonotes, batch 982 (28982): mcc: 0.8747, acc: 0.7999, precision: 0.9075, recall: 0.8479, f1: 0.8767, edges-pos-ontonotes_loss: 0.0144
09/16 04:47:52 AM: ***** Step 29000 / Validation 29 *****
09/16 04:47:52 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:47:52 AM: Validating...
09/16 04:47:58 AM: Evaluate: task edges-pos-ontonotes, batch 42 (157): mcc: 0.9065, acc: 0.8507, precision: 0.9480, recall: 0.8703, f1: 0.9075, edges-pos-ontonotes_loss: 0.0112
09/16 04:48:08 AM: Evaluate: task edges-pos-ontonotes, batch 101 (157): mcc: 0.9150, acc: 0.8650, precision: 0.9475, recall: 0.8869, f1: 0.9162, edges-pos-ontonotes_loss: 0.0104
09/16 04:48:19 AM: Evaluate: task edges-pos-ontonotes, batch 144 (157): mcc: 0.9150, acc: 0.8661, precision: 0.9426, recall: 0.8915, f1: 0.9163, edges-pos-ontonotes_loss: 0.0103
09/16 04:48:29 AM: Evaluate: task edges-pos-ontonotes, batch 154 (157): mcc: 0.9159, acc: 0.8679, precision: 0.9427, recall: 0.8932, f1: 0.9173, edges-pos-ontonotes_loss: 0.0102
09/16 04:48:30 AM: Best result seen so far for edges-pos-ontonotes.
09/16 04:48:30 AM: Best result seen so far for macro.
09/16 04:48:30 AM: Updating LR scheduler:
09/16 04:48:30 AM: 	Best result seen so far for macro_avg: 0.917
09/16 04:48:30 AM: 	# validation passes without improvement: 0
09/16 04:48:30 AM: edges-pos-ontonotes_loss: training: 0.014364 validation: 0.010188
09/16 04:48:30 AM: macro_avg: validation: 0.917464
09/16 04:48:30 AM: micro_avg: validation: 0.000000
09/16 04:48:30 AM: edges-pos-ontonotes_mcc: training: 0.874759 validation: 0.916100
09/16 04:48:30 AM: edges-pos-ontonotes_acc: training: 0.800103 validation: 0.868229
09/16 04:48:30 AM: edges-pos-ontonotes_precision: training: 0.907485 validation: 0.942773
09/16 04:48:30 AM: edges-pos-ontonotes_recall: training: 0.848063 validation: 0.893478
09/16 04:48:30 AM: edges-pos-ontonotes_f1: training: 0.876768 validation: 0.917464
09/16 04:48:30 AM: Global learning rate: 0.0001
09/16 04:48:30 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:48:39 AM: Update 29059: task edges-pos-ontonotes, batch 59 (29059): mcc: 0.8810, acc: 0.8112, precision: 0.9139, recall: 0.8539, f1: 0.8829, edges-pos-ontonotes_loss: 0.0145
09/16 04:48:49 AM: Update 29116: task edges-pos-ontonotes, batch 116 (29116): mcc: 0.8819, acc: 0.8120, precision: 0.9151, recall: 0.8544, f1: 0.8837, edges-pos-ontonotes_loss: 0.0144
09/16 04:48:59 AM: Update 29170: task edges-pos-ontonotes, batch 170 (29170): mcc: 0.8814, acc: 0.8112, precision: 0.9150, recall: 0.8536, f1: 0.8832, edges-pos-ontonotes_loss: 0.0142
09/16 04:49:09 AM: Update 29225: task edges-pos-ontonotes, batch 225 (29225): mcc: 0.8812, acc: 0.8112, precision: 0.9144, recall: 0.8538, f1: 0.8831, edges-pos-ontonotes_loss: 0.0141
09/16 04:49:20 AM: Update 29264: task edges-pos-ontonotes, batch 264 (29264): mcc: 0.8808, acc: 0.8105, precision: 0.9141, recall: 0.8534, f1: 0.8827, edges-pos-ontonotes_loss: 0.0141
09/16 04:49:30 AM: Update 29309: task edges-pos-ontonotes, batch 309 (29309): mcc: 0.8808, acc: 0.8107, precision: 0.9138, recall: 0.8535, f1: 0.8826, edges-pos-ontonotes_loss: 0.0141
09/16 04:49:40 AM: Update 29357: task edges-pos-ontonotes, batch 357 (29357): mcc: 0.8805, acc: 0.8103, precision: 0.9136, recall: 0.8531, f1: 0.8823, edges-pos-ontonotes_loss: 0.0141
09/16 04:49:50 AM: Update 29412: task edges-pos-ontonotes, batch 412 (29412): mcc: 0.8800, acc: 0.8096, precision: 0.9135, recall: 0.8524, f1: 0.8819, edges-pos-ontonotes_loss: 0.0143
09/16 04:50:00 AM: Update 29465: task edges-pos-ontonotes, batch 465 (29465): mcc: 0.8805, acc: 0.8103, precision: 0.9139, recall: 0.8529, f1: 0.8823, edges-pos-ontonotes_loss: 0.0142
09/16 04:50:10 AM: Update 29521: task edges-pos-ontonotes, batch 521 (29521): mcc: 0.8808, acc: 0.8108, precision: 0.9142, recall: 0.8532, f1: 0.8827, edges-pos-ontonotes_loss: 0.0142
09/16 04:50:20 AM: Update 29561: task edges-pos-ontonotes, batch 561 (29561): mcc: 0.8803, acc: 0.8102, precision: 0.9137, recall: 0.8528, f1: 0.8822, edges-pos-ontonotes_loss: 0.0142
09/16 04:50:30 AM: Update 29620: task edges-pos-ontonotes, batch 620 (29620): mcc: 0.8807, acc: 0.8107, precision: 0.9139, recall: 0.8532, f1: 0.8825, edges-pos-ontonotes_loss: 0.0140
09/16 04:50:40 AM: Update 29666: task edges-pos-ontonotes, batch 666 (29666): mcc: 0.8809, acc: 0.8110, precision: 0.9139, recall: 0.8536, f1: 0.8827, edges-pos-ontonotes_loss: 0.0139
09/16 04:50:50 AM: Update 29730: task edges-pos-ontonotes, batch 730 (29730): mcc: 0.8811, acc: 0.8113, precision: 0.9141, recall: 0.8540, f1: 0.8830, edges-pos-ontonotes_loss: 0.0138
09/16 04:51:01 AM: Update 29791: task edges-pos-ontonotes, batch 791 (29791): mcc: 0.8815, acc: 0.8119, precision: 0.9143, recall: 0.8545, f1: 0.8834, edges-pos-ontonotes_loss: 0.0136
09/16 04:51:11 AM: Update 29847: task edges-pos-ontonotes, batch 847 (29847): mcc: 0.8819, acc: 0.8125, precision: 0.9147, recall: 0.8549, f1: 0.8838, edges-pos-ontonotes_loss: 0.0135
09/16 04:51:21 AM: Update 29913: task edges-pos-ontonotes, batch 913 (29913): mcc: 0.8827, acc: 0.8134, precision: 0.9153, recall: 0.8558, f1: 0.8845, edges-pos-ontonotes_loss: 0.0134
09/16 04:51:31 AM: Update 29994: task edges-pos-ontonotes, batch 994 (29994): mcc: 0.8841, acc: 0.8152, precision: 0.9167, recall: 0.8572, f1: 0.8859, edges-pos-ontonotes_loss: 0.0131
09/16 04:51:32 AM: ***** Step 30000 / Validation 30 *****
09/16 04:51:32 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:51:32 AM: Validating...
09/16 04:51:41 AM: Evaluate: task edges-pos-ontonotes, batch 62 (157): mcc: 0.9080, acc: 0.8532, precision: 0.9486, recall: 0.8725, f1: 0.9090, edges-pos-ontonotes_loss: 0.0112
09/16 04:51:51 AM: Evaluate: task edges-pos-ontonotes, batch 114 (157): mcc: 0.9120, acc: 0.8607, precision: 0.9460, recall: 0.8825, f1: 0.9132, edges-pos-ontonotes_loss: 0.0106
09/16 04:52:01 AM: Updating LR scheduler:
09/16 04:52:01 AM: 	Best result seen so far for macro_avg: 0.917
09/16 04:52:01 AM: 	# validation passes without improvement: 1
09/16 04:52:01 AM: edges-pos-ontonotes_loss: training: 0.013111 validation: 0.010359
09/16 04:52:01 AM: macro_avg: validation: 0.915572
09/16 04:52:01 AM: micro_avg: validation: 0.000000
09/16 04:52:01 AM: edges-pos-ontonotes_mcc: training: 0.884249 validation: 0.914249
09/16 04:52:01 AM: edges-pos-ontonotes_acc: training: 0.815368 validation: 0.865689
09/16 04:52:01 AM: edges-pos-ontonotes_precision: training: 0.916800 validation: 0.943541
09/16 04:52:01 AM: edges-pos-ontonotes_recall: training: 0.857339 validation: 0.889213
09/16 04:52:01 AM: edges-pos-ontonotes_f1: training: 0.886073 validation: 0.915572
09/16 04:52:01 AM: Global learning rate: 0.0001
09/16 04:52:01 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:52:01 AM: Update 30004: task edges-pos-ontonotes, batch 4 (30004): mcc: 0.9174, acc: 0.8569, precision: 0.9432, recall: 0.8955, f1: 0.9187, edges-pos-ontonotes_loss: 0.0099
09/16 04:52:12 AM: Update 30082: task edges-pos-ontonotes, batch 82 (30082): mcc: 0.9101, acc: 0.8487, precision: 0.9400, recall: 0.8846, f1: 0.9115, edges-pos-ontonotes_loss: 0.0104
09/16 04:52:22 AM: Update 30163: task edges-pos-ontonotes, batch 163 (30163): mcc: 0.9117, acc: 0.8522, precision: 0.9406, recall: 0.8871, f1: 0.9131, edges-pos-ontonotes_loss: 0.0103
09/16 04:52:32 AM: Update 30242: task edges-pos-ontonotes, batch 242 (30242): mcc: 0.9095, acc: 0.8490, precision: 0.9394, recall: 0.8841, f1: 0.9109, edges-pos-ontonotes_loss: 0.0106
09/16 04:52:42 AM: Update 30334: task edges-pos-ontonotes, batch 334 (30334): mcc: 0.9086, acc: 0.8478, precision: 0.9398, recall: 0.8821, f1: 0.9100, edges-pos-ontonotes_loss: 0.0106
09/16 04:52:52 AM: Update 30428: task edges-pos-ontonotes, batch 428 (30428): mcc: 0.9088, acc: 0.8481, precision: 0.9398, recall: 0.8823, f1: 0.9102, edges-pos-ontonotes_loss: 0.0107
09/16 04:53:02 AM: Update 30518: task edges-pos-ontonotes, batch 518 (30518): mcc: 0.9070, acc: 0.8457, precision: 0.9383, recall: 0.8804, f1: 0.9084, edges-pos-ontonotes_loss: 0.0109
09/16 04:53:12 AM: Update 30633: task edges-pos-ontonotes, batch 633 (30633): mcc: 0.9029, acc: 0.8393, precision: 0.9357, recall: 0.8750, f1: 0.9043, edges-pos-ontonotes_loss: 0.0115
09/16 04:53:22 AM: Update 30744: task edges-pos-ontonotes, batch 744 (30744): mcc: 0.8997, acc: 0.8346, precision: 0.9335, recall: 0.8711, f1: 0.9012, edges-pos-ontonotes_loss: 0.0119
09/16 04:53:32 AM: Update 30830: task edges-pos-ontonotes, batch 830 (30830): mcc: 0.8967, acc: 0.8301, precision: 0.9308, recall: 0.8678, f1: 0.8982, edges-pos-ontonotes_loss: 0.0121
09/16 04:53:42 AM: Update 30890: task edges-pos-ontonotes, batch 890 (30890): mcc: 0.8929, acc: 0.8248, precision: 0.9271, recall: 0.8641, f1: 0.8945, edges-pos-ontonotes_loss: 0.0123
09/16 04:53:52 AM: Update 30949: task edges-pos-ontonotes, batch 949 (30949): mcc: 0.8903, acc: 0.8211, precision: 0.9244, recall: 0.8616, f1: 0.8919, edges-pos-ontonotes_loss: 0.0125
09/16 04:54:02 AM: ***** Step 31000 / Validation 31 *****
09/16 04:54:02 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:54:02 AM: Validating...
09/16 04:54:02 AM: Evaluate: task edges-pos-ontonotes, batch 2 (157): mcc: 0.9191, acc: 0.8753, precision: 0.9449, recall: 0.8971, f1: 0.9204, edges-pos-ontonotes_loss: 0.0098
09/16 04:54:12 AM: Evaluate: task edges-pos-ontonotes, batch 66 (157): mcc: 0.9111, acc: 0.8596, precision: 0.9459, recall: 0.8810, f1: 0.9123, edges-pos-ontonotes_loss: 0.0109
09/16 04:54:22 AM: Evaluate: task edges-pos-ontonotes, batch 113 (157): mcc: 0.9121, acc: 0.8619, precision: 0.9406, recall: 0.8878, f1: 0.9134, edges-pos-ontonotes_loss: 0.0105
09/16 04:54:32 AM: Evaluate: task edges-pos-ontonotes, batch 152 (157): mcc: 0.9134, acc: 0.8644, precision: 0.9369, recall: 0.8939, f1: 0.9149, edges-pos-ontonotes_loss: 0.0104
09/16 04:54:34 AM: Updating LR scheduler:
09/16 04:54:34 AM: 	Best result seen so far for macro_avg: 0.917
09/16 04:54:34 AM: 	# validation passes without improvement: 2
09/16 04:54:34 AM: edges-pos-ontonotes_loss: training: 0.012725 validation: 0.010417
09/16 04:54:34 AM: macro_avg: validation: 0.915094
09/16 04:54:34 AM: micro_avg: validation: 0.000000
09/16 04:54:34 AM: edges-pos-ontonotes_mcc: training: 0.887821 validation: 0.913590
09/16 04:54:34 AM: edges-pos-ontonotes_acc: training: 0.817689 validation: 0.864863
09/16 04:54:34 AM: edges-pos-ontonotes_precision: training: 0.922036 validation: 0.936944
09/16 04:54:34 AM: edges-pos-ontonotes_recall: training: 0.859204 validation: 0.894240
09/16 04:54:34 AM: edges-pos-ontonotes_f1: training: 0.889512 validation: 0.915094
09/16 04:54:34 AM: Global learning rate: 0.0001
09/16 04:54:34 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:54:43 AM: Update 31049: task edges-pos-ontonotes, batch 49 (31049): mcc: 0.8700, acc: 0.7910, precision: 0.9049, recall: 0.8415, f1: 0.8721, edges-pos-ontonotes_loss: 0.0153
09/16 04:54:53 AM: Update 31103: task edges-pos-ontonotes, batch 103 (31103): mcc: 0.8698, acc: 0.7918, precision: 0.9050, recall: 0.8409, f1: 0.8718, edges-pos-ontonotes_loss: 0.0154
09/16 04:55:03 AM: Update 31154: task edges-pos-ontonotes, batch 154 (31154): mcc: 0.8687, acc: 0.7899, precision: 0.9061, recall: 0.8379, f1: 0.8707, edges-pos-ontonotes_loss: 0.0153
09/16 04:55:13 AM: Update 31247: task edges-pos-ontonotes, batch 247 (31247): mcc: 0.8694, acc: 0.7906, precision: 0.9090, recall: 0.8365, f1: 0.8712, edges-pos-ontonotes_loss: 0.0150
09/16 04:55:23 AM: Update 31332: task edges-pos-ontonotes, batch 332 (31332): mcc: 0.8700, acc: 0.7915, precision: 0.9105, recall: 0.8363, f1: 0.8718, edges-pos-ontonotes_loss: 0.0147
09/16 04:55:33 AM: Update 31413: task edges-pos-ontonotes, batch 413 (31413): mcc: 0.8707, acc: 0.7924, precision: 0.9119, recall: 0.8363, f1: 0.8725, edges-pos-ontonotes_loss: 0.0145
09/16 04:55:47 AM: Update 31454: task edges-pos-ontonotes, batch 454 (31454): mcc: 0.8711, acc: 0.7929, precision: 0.9122, recall: 0.8366, f1: 0.8728, edges-pos-ontonotes_loss: 0.0145
09/16 04:55:58 AM: Update 31524: task edges-pos-ontonotes, batch 524 (31524): mcc: 0.8721, acc: 0.7941, precision: 0.9120, recall: 0.8388, f1: 0.8739, edges-pos-ontonotes_loss: 0.0144
09/16 04:56:08 AM: Update 31592: task edges-pos-ontonotes, batch 592 (31592): mcc: 0.8728, acc: 0.7953, precision: 0.9118, recall: 0.8403, f1: 0.8746, edges-pos-ontonotes_loss: 0.0143
09/16 04:56:18 AM: Update 31663: task edges-pos-ontonotes, batch 663 (31663): mcc: 0.8734, acc: 0.7960, precision: 0.9118, recall: 0.8415, f1: 0.8752, edges-pos-ontonotes_loss: 0.0142
09/16 04:56:28 AM: Update 31732: task edges-pos-ontonotes, batch 732 (31732): mcc: 0.8739, acc: 0.7966, precision: 0.9119, recall: 0.8422, f1: 0.8757, edges-pos-ontonotes_loss: 0.0142
09/16 04:56:38 AM: Update 31781: task edges-pos-ontonotes, batch 781 (31781): mcc: 0.8738, acc: 0.7966, precision: 0.9113, recall: 0.8427, f1: 0.8756, edges-pos-ontonotes_loss: 0.0142
09/16 04:56:48 AM: Update 31833: task edges-pos-ontonotes, batch 833 (31833): mcc: 0.8736, acc: 0.7965, precision: 0.9105, recall: 0.8430, f1: 0.8755, edges-pos-ontonotes_loss: 0.0142
09/16 04:56:58 AM: Update 31892: task edges-pos-ontonotes, batch 892 (31892): mcc: 0.8735, acc: 0.7964, precision: 0.9100, recall: 0.8433, f1: 0.8754, edges-pos-ontonotes_loss: 0.0143
09/16 04:57:08 AM: Update 31941: task edges-pos-ontonotes, batch 941 (31941): mcc: 0.8734, acc: 0.7966, precision: 0.9095, recall: 0.8436, f1: 0.8753, edges-pos-ontonotes_loss: 0.0143
09/16 04:57:18 AM: Update 31991: task edges-pos-ontonotes, batch 991 (31991): mcc: 0.8735, acc: 0.7967, precision: 0.9093, recall: 0.8439, f1: 0.8754, edges-pos-ontonotes_loss: 0.0143
09/16 04:57:21 AM: ***** Step 32000 / Validation 32 *****
09/16 04:57:21 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 04:57:21 AM: Validating...
09/16 04:57:28 AM: Evaluate: task edges-pos-ontonotes, batch 49 (157): mcc: 0.9111, acc: 0.8584, precision: 0.9508, recall: 0.8765, f1: 0.9122, edges-pos-ontonotes_loss: 0.0108
09/16 04:57:39 AM: Evaluate: task edges-pos-ontonotes, batch 106 (157): mcc: 0.9171, acc: 0.8682, precision: 0.9495, recall: 0.8889, f1: 0.9182, edges-pos-ontonotes_loss: 0.0101
09/16 04:57:49 AM: Evaluate: task edges-pos-ontonotes, batch 150 (157): mcc: 0.9163, acc: 0.8685, precision: 0.9440, recall: 0.8926, f1: 0.9176, edges-pos-ontonotes_loss: 0.0101
09/16 04:57:50 AM: Best result seen so far for edges-pos-ontonotes.
09/16 04:57:50 AM: Best result seen so far for macro.
09/16 04:57:50 AM: Updating LR scheduler:
09/16 04:57:50 AM: 	Best result seen so far for macro_avg: 0.918
09/16 04:57:50 AM: 	# validation passes without improvement: 0
09/16 04:57:50 AM: edges-pos-ontonotes_loss: training: 0.014307 validation: 0.010070
09/16 04:57:50 AM: macro_avg: validation: 0.917905
09/16 04:57:50 AM: micro_avg: validation: 0.000000
09/16 04:57:50 AM: edges-pos-ontonotes_mcc: training: 0.873412 validation: 0.916575
09/16 04:57:50 AM: edges-pos-ontonotes_acc: training: 0.796647 validation: 0.869139
09/16 04:57:50 AM: edges-pos-ontonotes_precision: training: 0.909126 validation: 0.944072
09/16 04:57:50 AM: edges-pos-ontonotes_recall: training: 0.843967 validation: 0.893150
09/16 04:57:50 AM: edges-pos-ontonotes_f1: training: 0.875336 validation: 0.917905
09/16 04:57:50 AM: Global learning rate: 0.0001
09/16 04:57:50 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 04:57:59 AM: Update 32048: task edges-pos-ontonotes, batch 48 (32048): mcc: 0.8749, acc: 0.8007, precision: 0.9067, recall: 0.8490, f1: 0.8769, edges-pos-ontonotes_loss: 0.0145
09/16 04:58:09 AM: Update 32093: task edges-pos-ontonotes, batch 93 (32093): mcc: 0.8714, acc: 0.7964, precision: 0.9040, recall: 0.8451, f1: 0.8735, edges-pos-ontonotes_loss: 0.0151
09/16 04:58:19 AM: Update 32145: task edges-pos-ontonotes, batch 145 (32145): mcc: 0.8725, acc: 0.7973, precision: 0.9051, recall: 0.8461, f1: 0.8746, edges-pos-ontonotes_loss: 0.0148
09/16 04:58:29 AM: Update 32197: task edges-pos-ontonotes, batch 197 (32197): mcc: 0.8739, acc: 0.7996, precision: 0.9064, recall: 0.8475, f1: 0.8760, edges-pos-ontonotes_loss: 0.0147
09/16 04:58:39 AM: Update 32250: task edges-pos-ontonotes, batch 250 (32250): mcc: 0.8746, acc: 0.8009, precision: 0.9067, recall: 0.8486, f1: 0.8767, edges-pos-ontonotes_loss: 0.0146
09/16 04:58:49 AM: Update 32307: task edges-pos-ontonotes, batch 307 (32307): mcc: 0.8752, acc: 0.8019, precision: 0.9076, recall: 0.8488, f1: 0.8772, edges-pos-ontonotes_loss: 0.0145
09/16 04:59:00 AM: Update 32357: task edges-pos-ontonotes, batch 357 (32357): mcc: 0.8762, acc: 0.8031, precision: 0.9083, recall: 0.8500, f1: 0.8782, edges-pos-ontonotes_loss: 0.0144
09/16 04:59:10 AM: Update 32397: task edges-pos-ontonotes, batch 397 (32397): mcc: 0.8764, acc: 0.8036, precision: 0.9089, recall: 0.8499, f1: 0.8784, edges-pos-ontonotes_loss: 0.0144
09/16 04:59:20 AM: Update 32454: task edges-pos-ontonotes, batch 454 (32454): mcc: 0.8767, acc: 0.8040, precision: 0.9092, recall: 0.8501, f1: 0.8787, edges-pos-ontonotes_loss: 0.0144
09/16 04:59:30 AM: Update 32506: task edges-pos-ontonotes, batch 506 (32506): mcc: 0.8769, acc: 0.8043, precision: 0.9093, recall: 0.8504, f1: 0.8789, edges-pos-ontonotes_loss: 0.0144
09/16 04:59:40 AM: Update 32553: task edges-pos-ontonotes, batch 553 (32553): mcc: 0.8774, acc: 0.8052, precision: 0.9099, recall: 0.8508, f1: 0.8794, edges-pos-ontonotes_loss: 0.0143
09/16 04:59:50 AM: Update 32608: task edges-pos-ontonotes, batch 608 (32608): mcc: 0.8777, acc: 0.8057, precision: 0.9103, recall: 0.8511, f1: 0.8797, edges-pos-ontonotes_loss: 0.0143
09/16 05:00:00 AM: Update 32660: task edges-pos-ontonotes, batch 660 (32660): mcc: 0.8782, acc: 0.8064, precision: 0.9107, recall: 0.8515, f1: 0.8801, edges-pos-ontonotes_loss: 0.0143
09/16 05:00:10 AM: Update 32703: task edges-pos-ontonotes, batch 703 (32703): mcc: 0.8784, acc: 0.8067, precision: 0.9109, recall: 0.8518, f1: 0.8804, edges-pos-ontonotes_loss: 0.0142
09/16 05:00:21 AM: Update 32741: task edges-pos-ontonotes, batch 741 (32741): mcc: 0.8784, acc: 0.8068, precision: 0.9110, recall: 0.8518, f1: 0.8804, edges-pos-ontonotes_loss: 0.0142
09/16 05:00:31 AM: Update 32794: task edges-pos-ontonotes, batch 794 (32794): mcc: 0.8788, acc: 0.8074, precision: 0.9113, recall: 0.8521, f1: 0.8807, edges-pos-ontonotes_loss: 0.0142
09/16 05:00:41 AM: Update 32845: task edges-pos-ontonotes, batch 845 (32845): mcc: 0.8790, acc: 0.8076, precision: 0.9116, recall: 0.8522, f1: 0.8809, edges-pos-ontonotes_loss: 0.0142
09/16 05:00:51 AM: Update 32897: task edges-pos-ontonotes, batch 897 (32897): mcc: 0.8790, acc: 0.8077, precision: 0.9116, recall: 0.8523, f1: 0.8809, edges-pos-ontonotes_loss: 0.0142
09/16 05:01:01 AM: Update 32943: task edges-pos-ontonotes, batch 943 (32943): mcc: 0.8790, acc: 0.8078, precision: 0.9115, recall: 0.8524, f1: 0.8809, edges-pos-ontonotes_loss: 0.0142
09/16 05:01:11 AM: Update 32991: task edges-pos-ontonotes, batch 991 (32991): mcc: 0.8791, acc: 0.8080, precision: 0.9116, recall: 0.8524, f1: 0.8810, edges-pos-ontonotes_loss: 0.0142
09/16 05:01:12 AM: ***** Step 33000 / Validation 33 *****
09/16 05:01:12 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:01:12 AM: Validating...
09/16 05:01:21 AM: Evaluate: task edges-pos-ontonotes, batch 54 (157): mcc: 0.9097, acc: 0.8548, precision: 0.9503, recall: 0.8742, f1: 0.9107, edges-pos-ontonotes_loss: 0.0110
09/16 05:01:31 AM: Evaluate: task edges-pos-ontonotes, batch 109 (157): mcc: 0.9146, acc: 0.8643, precision: 0.9481, recall: 0.8856, f1: 0.9158, edges-pos-ontonotes_loss: 0.0104
09/16 05:01:41 AM: Evaluate: task edges-pos-ontonotes, batch 152 (157): mcc: 0.9163, acc: 0.8682, precision: 0.9449, recall: 0.8918, f1: 0.9176, edges-pos-ontonotes_loss: 0.0102
09/16 05:01:42 AM: Updating LR scheduler:
09/16 05:01:42 AM: 	Best result seen so far for macro_avg: 0.918
09/16 05:01:42 AM: 	# validation passes without improvement: 1
09/16 05:01:42 AM: edges-pos-ontonotes_loss: training: 0.014190 validation: 0.010176
09/16 05:01:42 AM: macro_avg: validation: 0.917855
09/16 05:01:42 AM: micro_avg: validation: 0.000000
09/16 05:01:42 AM: edges-pos-ontonotes_mcc: training: 0.879149 validation: 0.916551
09/16 05:01:42 AM: edges-pos-ontonotes_acc: training: 0.808031 validation: 0.868800
09/16 05:01:42 AM: edges-pos-ontonotes_precision: training: 0.911662 validation: 0.944961
09/16 05:01:42 AM: edges-pos-ontonotes_recall: training: 0.852478 validation: 0.892261
09/16 05:01:42 AM: edges-pos-ontonotes_f1: training: 0.881077 validation: 0.917855
09/16 05:01:42 AM: Global learning rate: 0.0001
09/16 05:01:42 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:01:56 AM: Update 33019: task edges-pos-ontonotes, batch 19 (33019): mcc: 0.8726, acc: 0.8005, precision: 0.9086, recall: 0.8428, f1: 0.8745, edges-pos-ontonotes_loss: 0.0144
09/16 05:02:06 AM: Update 33071: task edges-pos-ontonotes, batch 71 (33071): mcc: 0.8781, acc: 0.8074, precision: 0.9112, recall: 0.8509, f1: 0.8800, edges-pos-ontonotes_loss: 0.0129
09/16 05:02:16 AM: Update 33137: task edges-pos-ontonotes, batch 137 (33137): mcc: 0.8813, acc: 0.8113, precision: 0.9140, recall: 0.8543, f1: 0.8832, edges-pos-ontonotes_loss: 0.0126
09/16 05:02:27 AM: Update 33201: task edges-pos-ontonotes, batch 201 (33201): mcc: 0.8832, acc: 0.8136, precision: 0.9155, recall: 0.8566, f1: 0.8851, edges-pos-ontonotes_loss: 0.0124
09/16 05:02:37 AM: Update 33266: task edges-pos-ontonotes, batch 266 (33266): mcc: 0.8847, acc: 0.8161, precision: 0.9167, recall: 0.8584, f1: 0.8866, edges-pos-ontonotes_loss: 0.0122
09/16 05:02:47 AM: Update 33325: task edges-pos-ontonotes, batch 325 (33325): mcc: 0.8850, acc: 0.8165, precision: 0.9169, recall: 0.8587, f1: 0.8868, edges-pos-ontonotes_loss: 0.0122
09/16 05:02:57 AM: Update 33397: task edges-pos-ontonotes, batch 397 (33397): mcc: 0.8879, acc: 0.8203, precision: 0.9194, recall: 0.8618, f1: 0.8897, edges-pos-ontonotes_loss: 0.0119
09/16 05:03:07 AM: Update 33477: task edges-pos-ontonotes, batch 477 (33477): mcc: 0.8912, acc: 0.8247, precision: 0.9223, recall: 0.8654, f1: 0.8930, edges-pos-ontonotes_loss: 0.0117
09/16 05:03:17 AM: Update 33563: task edges-pos-ontonotes, batch 563 (33563): mcc: 0.8937, acc: 0.8280, precision: 0.9245, recall: 0.8681, f1: 0.8954, edges-pos-ontonotes_loss: 0.0114
09/16 05:03:28 AM: Update 33645: task edges-pos-ontonotes, batch 645 (33645): mcc: 0.8957, acc: 0.8307, precision: 0.9263, recall: 0.8701, f1: 0.8973, edges-pos-ontonotes_loss: 0.0113
09/16 05:03:38 AM: Update 33739: task edges-pos-ontonotes, batch 739 (33739): mcc: 0.8963, acc: 0.8315, precision: 0.9273, recall: 0.8704, f1: 0.8980, edges-pos-ontonotes_loss: 0.0113
09/16 05:03:48 AM: Update 33827: task edges-pos-ontonotes, batch 827 (33827): mcc: 0.8970, acc: 0.8325, precision: 0.9282, recall: 0.8709, f1: 0.8987, edges-pos-ontonotes_loss: 0.0112
09/16 05:03:58 AM: Update 33917: task edges-pos-ontonotes, batch 917 (33917): mcc: 0.8980, acc: 0.8338, precision: 0.9291, recall: 0.8719, f1: 0.8996, edges-pos-ontonotes_loss: 0.0112
09/16 05:04:07 AM: ***** Step 34000 / Validation 34 *****
09/16 05:04:07 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:04:07 AM: Validating...
09/16 05:04:08 AM: Evaluate: task edges-pos-ontonotes, batch 4 (157): mcc: 0.9067, acc: 0.8616, precision: 0.9305, recall: 0.8873, f1: 0.9084, edges-pos-ontonotes_loss: 0.0110
09/16 05:04:18 AM: Evaluate: task edges-pos-ontonotes, batch 68 (157): mcc: 0.9124, acc: 0.8639, precision: 0.9413, recall: 0.8878, f1: 0.9138, edges-pos-ontonotes_loss: 0.0109
09/16 05:04:28 AM: Evaluate: task edges-pos-ontonotes, batch 119 (157): mcc: 0.9128, acc: 0.8653, precision: 0.9355, recall: 0.8942, f1: 0.9144, edges-pos-ontonotes_loss: 0.0106
09/16 05:04:36 AM: Updating LR scheduler:
09/16 05:04:36 AM: 	Best result seen so far for macro_avg: 0.918
09/16 05:04:36 AM: 	# validation passes without improvement: 2
09/16 05:04:36 AM: edges-pos-ontonotes_loss: training: 0.011338 validation: 0.010477
09/16 05:04:36 AM: macro_avg: validation: 0.915113
09/16 05:04:36 AM: micro_avg: validation: 0.000000
09/16 05:04:36 AM: edges-pos-ontonotes_mcc: training: 0.897666 validation: 0.913499
09/16 05:04:36 AM: edges-pos-ontonotes_acc: training: 0.833159 validation: 0.866800
09/16 05:04:36 AM: edges-pos-ontonotes_precision: training: 0.928923 validation: 0.932097
09/16 05:04:36 AM: edges-pos-ontonotes_recall: training: 0.871438 validation: 0.898738
09/16 05:04:36 AM: edges-pos-ontonotes_f1: training: 0.899263 validation: 0.915113
09/16 05:04:36 AM: Global learning rate: 0.0001
09/16 05:04:36 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:04:38 AM: Update 34031: task edges-pos-ontonotes, batch 31 (34031): mcc: 0.8872, acc: 0.8123, precision: 0.9331, recall: 0.8477, f1: 0.8884, edges-pos-ontonotes_loss: 0.0133
09/16 05:04:48 AM: Update 34143: task edges-pos-ontonotes, batch 143 (34143): mcc: 0.8770, acc: 0.8011, precision: 0.9204, recall: 0.8402, f1: 0.8785, edges-pos-ontonotes_loss: 0.0135
09/16 05:05:00 AM: Update 34271: task edges-pos-ontonotes, batch 271 (34271): mcc: 0.8762, acc: 0.8004, precision: 0.9177, recall: 0.8413, f1: 0.8778, edges-pos-ontonotes_loss: 0.0137
09/16 05:05:10 AM: Update 34329: task edges-pos-ontonotes, batch 329 (34329): mcc: 0.8730, acc: 0.7960, precision: 0.9113, recall: 0.8412, f1: 0.8749, edges-pos-ontonotes_loss: 0.0140
09/16 05:05:20 AM: Update 34390: task edges-pos-ontonotes, batch 390 (34390): mcc: 0.8714, acc: 0.7938, precision: 0.9084, recall: 0.8408, f1: 0.8733, edges-pos-ontonotes_loss: 0.0144
09/16 05:05:30 AM: Update 34447: task edges-pos-ontonotes, batch 447 (34447): mcc: 0.8710, acc: 0.7936, precision: 0.9076, recall: 0.8408, f1: 0.8729, edges-pos-ontonotes_loss: 0.0144
09/16 05:05:41 AM: Update 34504: task edges-pos-ontonotes, batch 504 (34504): mcc: 0.8710, acc: 0.7934, precision: 0.9070, recall: 0.8414, f1: 0.8730, edges-pos-ontonotes_loss: 0.0145
09/16 05:05:51 AM: Update 34558: task edges-pos-ontonotes, batch 558 (34558): mcc: 0.8706, acc: 0.7929, precision: 0.9065, recall: 0.8411, f1: 0.8726, edges-pos-ontonotes_loss: 0.0147
09/16 05:06:01 AM: Update 34607: task edges-pos-ontonotes, batch 607 (34607): mcc: 0.8700, acc: 0.7921, precision: 0.9062, recall: 0.8403, f1: 0.8720, edges-pos-ontonotes_loss: 0.0147
09/16 05:06:11 AM: Update 34696: task edges-pos-ontonotes, batch 696 (34696): mcc: 0.8700, acc: 0.7918, precision: 0.9075, recall: 0.8390, f1: 0.8719, edges-pos-ontonotes_loss: 0.0147
09/16 05:06:21 AM: Update 34777: task edges-pos-ontonotes, batch 777 (34777): mcc: 0.8703, acc: 0.7920, precision: 0.9085, recall: 0.8387, f1: 0.8722, edges-pos-ontonotes_loss: 0.0146
09/16 05:06:31 AM: Update 34871: task edges-pos-ontonotes, batch 871 (34871): mcc: 0.8708, acc: 0.7927, precision: 0.9094, recall: 0.8388, f1: 0.8727, edges-pos-ontonotes_loss: 0.0145
09/16 05:06:41 AM: Update 34935: task edges-pos-ontonotes, batch 935 (34935): mcc: 0.8713, acc: 0.7934, precision: 0.9096, recall: 0.8395, f1: 0.8731, edges-pos-ontonotes_loss: 0.0145
09/16 05:06:51 AM: Update 34998: task edges-pos-ontonotes, batch 998 (34998): mcc: 0.8720, acc: 0.7944, precision: 0.9096, recall: 0.8407, f1: 0.8738, edges-pos-ontonotes_loss: 0.0144
09/16 05:06:52 AM: ***** Step 35000 / Validation 35 *****
09/16 05:06:52 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:06:52 AM: Validating...
09/16 05:07:01 AM: Evaluate: task edges-pos-ontonotes, batch 66 (157): mcc: 0.9142, acc: 0.8635, precision: 0.9483, recall: 0.8847, f1: 0.9154, edges-pos-ontonotes_loss: 0.0104
09/16 05:07:12 AM: Evaluate: task edges-pos-ontonotes, batch 116 (157): mcc: 0.9153, acc: 0.8661, precision: 0.9432, recall: 0.8915, f1: 0.9166, edges-pos-ontonotes_loss: 0.0102
09/16 05:07:21 AM: Updating LR scheduler:
09/16 05:07:21 AM: 	Best result seen so far for macro_avg: 0.918
09/16 05:07:21 AM: 	# validation passes without improvement: 3
09/16 05:07:21 AM: edges-pos-ontonotes_loss: training: 0.014414 validation: 0.010100
09/16 05:07:21 AM: macro_avg: validation: 0.917072
09/16 05:07:21 AM: micro_avg: validation: 0.000000
09/16 05:07:21 AM: edges-pos-ontonotes_mcc: training: 0.871967 validation: 0.915636
09/16 05:07:21 AM: edges-pos-ontonotes_acc: training: 0.794391 validation: 0.867403
09/16 05:07:21 AM: edges-pos-ontonotes_precision: training: 0.909632 validation: 0.940048
09/16 05:07:21 AM: edges-pos-ontonotes_recall: training: 0.840759 validation: 0.895192
09/16 05:07:21 AM: edges-pos-ontonotes_f1: training: 0.873840 validation: 0.917072
09/16 05:07:21 AM: Global learning rate: 0.0001
09/16 05:07:21 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:07:22 AM: Update 35001: task edges-pos-ontonotes, batch 1 (35001): mcc: 0.8667, acc: 0.7922, precision: 0.9080, recall: 0.8323, f1: 0.8685, edges-pos-ontonotes_loss: 0.0149
09/16 05:07:32 AM: Update 35070: task edges-pos-ontonotes, batch 70 (35070): mcc: 0.8758, acc: 0.7998, precision: 0.9093, recall: 0.8484, f1: 0.8778, edges-pos-ontonotes_loss: 0.0140
09/16 05:07:42 AM: Update 35132: task edges-pos-ontonotes, batch 132 (35132): mcc: 0.8774, acc: 0.8022, precision: 0.9119, recall: 0.8490, f1: 0.8793, edges-pos-ontonotes_loss: 0.0138
09/16 05:07:52 AM: Update 35203: task edges-pos-ontonotes, batch 203 (35203): mcc: 0.8788, acc: 0.8040, precision: 0.9132, recall: 0.8504, f1: 0.8807, edges-pos-ontonotes_loss: 0.0135
09/16 05:08:06 AM: Update 35227: task edges-pos-ontonotes, batch 227 (35227): mcc: 0.8782, acc: 0.8030, precision: 0.9126, recall: 0.8499, f1: 0.8801, edges-pos-ontonotes_loss: 0.0136
09/16 05:08:16 AM: Update 35277: task edges-pos-ontonotes, batch 277 (35277): mcc: 0.8764, acc: 0.8010, precision: 0.9097, recall: 0.8491, f1: 0.8784, edges-pos-ontonotes_loss: 0.0139
09/16 05:08:26 AM: Update 35332: task edges-pos-ontonotes, batch 332 (35332): mcc: 0.8756, acc: 0.8001, precision: 0.9087, recall: 0.8485, f1: 0.8776, edges-pos-ontonotes_loss: 0.0141
09/16 05:08:36 AM: Update 35388: task edges-pos-ontonotes, batch 388 (35388): mcc: 0.8751, acc: 0.7995, precision: 0.9081, recall: 0.8482, f1: 0.8771, edges-pos-ontonotes_loss: 0.0142
09/16 05:08:46 AM: Update 35445: task edges-pos-ontonotes, batch 445 (35445): mcc: 0.8751, acc: 0.7996, precision: 0.9078, recall: 0.8484, f1: 0.8771, edges-pos-ontonotes_loss: 0.0142
09/16 05:08:56 AM: Update 35495: task edges-pos-ontonotes, batch 495 (35495): mcc: 0.8750, acc: 0.7995, precision: 0.9075, recall: 0.8485, f1: 0.8770, edges-pos-ontonotes_loss: 0.0142
09/16 05:09:06 AM: Update 35540: task edges-pos-ontonotes, batch 540 (35540): mcc: 0.8747, acc: 0.7992, precision: 0.9073, recall: 0.8482, f1: 0.8768, edges-pos-ontonotes_loss: 0.0143
09/16 05:09:16 AM: Update 35583: task edges-pos-ontonotes, batch 583 (35583): mcc: 0.8750, acc: 0.7996, precision: 0.9072, recall: 0.8488, f1: 0.8770, edges-pos-ontonotes_loss: 0.0143
09/16 05:09:26 AM: Update 35628: task edges-pos-ontonotes, batch 628 (35628): mcc: 0.8750, acc: 0.7997, precision: 0.9073, recall: 0.8488, f1: 0.8771, edges-pos-ontonotes_loss: 0.0143
09/16 05:09:37 AM: Update 35677: task edges-pos-ontonotes, batch 677 (35677): mcc: 0.8756, acc: 0.8007, precision: 0.9077, recall: 0.8495, f1: 0.8776, edges-pos-ontonotes_loss: 0.0143
09/16 05:09:47 AM: Update 35718: task edges-pos-ontonotes, batch 718 (35718): mcc: 0.8756, acc: 0.8009, precision: 0.9077, recall: 0.8496, f1: 0.8777, edges-pos-ontonotes_loss: 0.0143
09/16 05:09:57 AM: Update 35768: task edges-pos-ontonotes, batch 768 (35768): mcc: 0.8758, acc: 0.8013, precision: 0.9079, recall: 0.8498, f1: 0.8779, edges-pos-ontonotes_loss: 0.0143
09/16 05:10:07 AM: Update 35816: task edges-pos-ontonotes, batch 816 (35816): mcc: 0.8763, acc: 0.8021, precision: 0.9083, recall: 0.8503, f1: 0.8783, edges-pos-ontonotes_loss: 0.0142
09/16 05:10:17 AM: Update 35854: task edges-pos-ontonotes, batch 854 (35854): mcc: 0.8763, acc: 0.8021, precision: 0.9083, recall: 0.8502, f1: 0.8783, edges-pos-ontonotes_loss: 0.0142
09/16 05:10:27 AM: Update 35900: task edges-pos-ontonotes, batch 900 (35900): mcc: 0.8765, acc: 0.8025, precision: 0.9085, recall: 0.8504, f1: 0.8785, edges-pos-ontonotes_loss: 0.0142
09/16 05:10:37 AM: Update 35952: task edges-pos-ontonotes, batch 952 (35952): mcc: 0.8767, acc: 0.8030, precision: 0.9088, recall: 0.8506, f1: 0.8787, edges-pos-ontonotes_loss: 0.0142
09/16 05:10:47 AM: ***** Step 36000 / Validation 36 *****
09/16 05:10:47 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:10:47 AM: Validating...
09/16 05:10:47 AM: Evaluate: task edges-pos-ontonotes, batch 4 (157): mcc: 0.9136, acc: 0.8694, precision: 0.9448, recall: 0.8868, f1: 0.9149, edges-pos-ontonotes_loss: 0.0105
09/16 05:10:57 AM: Evaluate: task edges-pos-ontonotes, batch 68 (157): mcc: 0.9143, acc: 0.8634, precision: 0.9491, recall: 0.8841, f1: 0.9155, edges-pos-ontonotes_loss: 0.0107
09/16 05:11:08 AM: Evaluate: task edges-pos-ontonotes, batch 118 (157): mcc: 0.9168, acc: 0.8686, precision: 0.9462, recall: 0.8916, f1: 0.9181, edges-pos-ontonotes_loss: 0.0102
09/16 05:11:16 AM: Best result seen so far for edges-pos-ontonotes.
09/16 05:11:16 AM: Best result seen so far for macro.
09/16 05:11:16 AM: Updating LR scheduler:
09/16 05:11:16 AM: 	Best result seen so far for macro_avg: 0.919
09/16 05:11:16 AM: 	# validation passes without improvement: 0
09/16 05:11:16 AM: edges-pos-ontonotes_loss: training: 0.014196 validation: 0.010028
09/16 05:11:16 AM: macro_avg: validation: 0.919229
09/16 05:11:16 AM: micro_avg: validation: 0.000000
09/16 05:11:16 AM: edges-pos-ontonotes_mcc: training: 0.876908 validation: 0.917879
09/16 05:11:16 AM: edges-pos-ontonotes_acc: training: 0.803338 validation: 0.871509
09/16 05:11:16 AM: edges-pos-ontonotes_precision: training: 0.908963 validation: 0.943722
09/16 05:11:16 AM: edges-pos-ontonotes_recall: training: 0.850759 validation: 0.895976
09/16 05:11:16 AM: edges-pos-ontonotes_f1: training: 0.878898 validation: 0.919229
09/16 05:11:16 AM: Global learning rate: 0.0001
09/16 05:11:16 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:11:18 AM: Update 36006: task edges-pos-ontonotes, batch 6 (36006): mcc: 0.8840, acc: 0.8158, precision: 0.9150, recall: 0.8586, f1: 0.8859, edges-pos-ontonotes_loss: 0.0131
09/16 05:11:28 AM: Update 36066: task edges-pos-ontonotes, batch 66 (36066): mcc: 0.8837, acc: 0.8139, precision: 0.9166, recall: 0.8565, f1: 0.8856, edges-pos-ontonotes_loss: 0.0136
09/16 05:11:38 AM: Update 36120: task edges-pos-ontonotes, batch 120 (36120): mcc: 0.8829, acc: 0.8135, precision: 0.9149, recall: 0.8565, f1: 0.8848, edges-pos-ontonotes_loss: 0.0137
09/16 05:11:49 AM: Update 36166: task edges-pos-ontonotes, batch 166 (36166): mcc: 0.8827, acc: 0.8131, precision: 0.9147, recall: 0.8563, f1: 0.8846, edges-pos-ontonotes_loss: 0.0137
09/16 05:12:00 AM: Update 36221: task edges-pos-ontonotes, batch 221 (36221): mcc: 0.8822, acc: 0.8127, precision: 0.9149, recall: 0.8553, f1: 0.8841, edges-pos-ontonotes_loss: 0.0138
09/16 05:12:10 AM: Update 36275: task edges-pos-ontonotes, batch 275 (36275): mcc: 0.8819, acc: 0.8124, precision: 0.9146, recall: 0.8550, f1: 0.8838, edges-pos-ontonotes_loss: 0.0140
09/16 05:12:20 AM: Update 36328: task edges-pos-ontonotes, batch 328 (36328): mcc: 0.8819, acc: 0.8122, precision: 0.9146, recall: 0.8550, f1: 0.8838, edges-pos-ontonotes_loss: 0.0140
09/16 05:12:30 AM: Update 36372: task edges-pos-ontonotes, batch 372 (36372): mcc: 0.8819, acc: 0.8123, precision: 0.9143, recall: 0.8552, f1: 0.8838, edges-pos-ontonotes_loss: 0.0140
09/16 05:12:40 AM: Update 36424: task edges-pos-ontonotes, batch 424 (36424): mcc: 0.8820, acc: 0.8125, precision: 0.9144, recall: 0.8553, f1: 0.8839, edges-pos-ontonotes_loss: 0.0140
09/16 05:12:50 AM: Update 36474: task edges-pos-ontonotes, batch 474 (36474): mcc: 0.8821, acc: 0.8126, precision: 0.9145, recall: 0.8554, f1: 0.8840, edges-pos-ontonotes_loss: 0.0140
09/16 05:13:00 AM: Update 36518: task edges-pos-ontonotes, batch 518 (36518): mcc: 0.8815, acc: 0.8119, precision: 0.9139, recall: 0.8549, f1: 0.8834, edges-pos-ontonotes_loss: 0.0139
09/16 05:13:10 AM: Update 36580: task edges-pos-ontonotes, batch 580 (36580): mcc: 0.8818, acc: 0.8122, precision: 0.9141, recall: 0.8551, f1: 0.8837, edges-pos-ontonotes_loss: 0.0137
09/16 05:13:20 AM: Update 36636: task edges-pos-ontonotes, batch 636 (36636): mcc: 0.8822, acc: 0.8128, precision: 0.9145, recall: 0.8557, f1: 0.8841, edges-pos-ontonotes_loss: 0.0136
09/16 05:13:30 AM: Update 36708: task edges-pos-ontonotes, batch 708 (36708): mcc: 0.8832, acc: 0.8142, precision: 0.9152, recall: 0.8569, f1: 0.8851, edges-pos-ontonotes_loss: 0.0133
09/16 05:13:40 AM: Update 36762: task edges-pos-ontonotes, batch 762 (36762): mcc: 0.8834, acc: 0.8146, precision: 0.9154, recall: 0.8571, f1: 0.8853, edges-pos-ontonotes_loss: 0.0132
09/16 05:13:50 AM: Update 36822: task edges-pos-ontonotes, batch 822 (36822): mcc: 0.8842, acc: 0.8155, precision: 0.9160, recall: 0.8579, f1: 0.8860, edges-pos-ontonotes_loss: 0.0131
09/16 05:14:00 AM: Update 36904: task edges-pos-ontonotes, batch 904 (36904): mcc: 0.8857, acc: 0.8176, precision: 0.9174, recall: 0.8596, f1: 0.8875, edges-pos-ontonotes_loss: 0.0129
09/16 05:14:10 AM: Update 36984: task edges-pos-ontonotes, batch 984 (36984): mcc: 0.8871, acc: 0.8193, precision: 0.9187, recall: 0.8609, f1: 0.8889, edges-pos-ontonotes_loss: 0.0127
09/16 05:14:12 AM: ***** Step 37000 / Validation 37 *****
09/16 05:14:12 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:14:12 AM: Validating...
09/16 05:14:21 AM: Evaluate: task edges-pos-ontonotes, batch 52 (157): mcc: 0.9089, acc: 0.8549, precision: 0.9486, recall: 0.8744, f1: 0.9100, edges-pos-ontonotes_loss: 0.0109
09/16 05:14:31 AM: Evaluate: task edges-pos-ontonotes, batch 109 (157): mcc: 0.9139, acc: 0.8641, precision: 0.9463, recall: 0.8858, f1: 0.9151, edges-pos-ontonotes_loss: 0.0104
09/16 05:14:41 AM: Evaluate: task edges-pos-ontonotes, batch 152 (157): mcc: 0.9157, acc: 0.8681, precision: 0.9429, recall: 0.8926, f1: 0.9170, edges-pos-ontonotes_loss: 0.0102
09/16 05:14:42 AM: Updating LR scheduler:
09/16 05:14:42 AM: 	Best result seen so far for macro_avg: 0.919
09/16 05:14:42 AM: 	# validation passes without improvement: 1
09/16 05:14:42 AM: edges-pos-ontonotes_loss: training: 0.012631 validation: 0.010143
09/16 05:14:42 AM: macro_avg: validation: 0.917279
09/16 05:14:42 AM: micro_avg: validation: 0.000000
09/16 05:14:42 AM: edges-pos-ontonotes_mcc: training: 0.887319 validation: 0.915922
09/16 05:14:42 AM: edges-pos-ontonotes_acc: training: 0.819669 validation: 0.868588
09/16 05:14:42 AM: edges-pos-ontonotes_precision: training: 0.918882 validation: 0.942983
09/16 05:14:42 AM: edges-pos-ontonotes_recall: training: 0.861217 validation: 0.892938
09/16 05:14:42 AM: edges-pos-ontonotes_f1: training: 0.889116 validation: 0.917279
09/16 05:14:42 AM: Global learning rate: 0.0001
09/16 05:14:42 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:14:51 AM: Update 37063: task edges-pos-ontonotes, batch 63 (37063): mcc: 0.9152, acc: 0.8571, precision: 0.9429, recall: 0.8916, f1: 0.9165, edges-pos-ontonotes_loss: 0.0100
09/16 05:15:05 AM: Update 37105: task edges-pos-ontonotes, batch 105 (37105): mcc: 0.9140, acc: 0.8558, precision: 0.9429, recall: 0.8894, f1: 0.9154, edges-pos-ontonotes_loss: 0.0101
09/16 05:15:15 AM: Update 37209: task edges-pos-ontonotes, batch 209 (37209): mcc: 0.9115, acc: 0.8519, precision: 0.9427, recall: 0.8848, f1: 0.9128, edges-pos-ontonotes_loss: 0.0106
09/16 05:15:25 AM: Update 37307: task edges-pos-ontonotes, batch 307 (37307): mcc: 0.9109, acc: 0.8512, precision: 0.9417, recall: 0.8846, f1: 0.9123, edges-pos-ontonotes_loss: 0.0106
09/16 05:15:35 AM: Update 37393: task edges-pos-ontonotes, batch 393 (37393): mcc: 0.9103, acc: 0.8505, precision: 0.9408, recall: 0.8843, f1: 0.9117, edges-pos-ontonotes_loss: 0.0107
09/16 05:15:45 AM: Update 37492: task edges-pos-ontonotes, batch 492 (37492): mcc: 0.9067, acc: 0.8451, precision: 0.9381, recall: 0.8799, f1: 0.9081, edges-pos-ontonotes_loss: 0.0111
09/16 05:15:55 AM: Update 37616: task edges-pos-ontonotes, batch 616 (37616): mcc: 0.9022, acc: 0.8385, precision: 0.9350, recall: 0.8744, f1: 0.9037, edges-pos-ontonotes_loss: 0.0117
09/16 05:16:07 AM: Update 37731: task edges-pos-ontonotes, batch 731 (37731): mcc: 0.8983, acc: 0.8329, precision: 0.9319, recall: 0.8699, f1: 0.8998, edges-pos-ontonotes_loss: 0.0120
09/16 05:16:17 AM: Update 37783: task edges-pos-ontonotes, batch 783 (37783): mcc: 0.8939, acc: 0.8265, precision: 0.9271, recall: 0.8659, f1: 0.8955, edges-pos-ontonotes_loss: 0.0123
09/16 05:16:27 AM: Update 37842: task edges-pos-ontonotes, batch 842 (37842): mcc: 0.8912, acc: 0.8227, precision: 0.9245, recall: 0.8633, f1: 0.8929, edges-pos-ontonotes_loss: 0.0125
09/16 05:16:37 AM: Update 37898: task edges-pos-ontonotes, batch 898 (37898): mcc: 0.8890, acc: 0.8195, precision: 0.9225, recall: 0.8610, f1: 0.8907, edges-pos-ontonotes_loss: 0.0127
09/16 05:16:47 AM: Update 37957: task edges-pos-ontonotes, batch 957 (37957): mcc: 0.8874, acc: 0.8173, precision: 0.9209, recall: 0.8595, f1: 0.8892, edges-pos-ontonotes_loss: 0.0128
09/16 05:16:54 AM: ***** Step 38000 / Validation 38 *****
09/16 05:16:54 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:16:54 AM: Validating...
09/16 05:16:57 AM: Evaluate: task edges-pos-ontonotes, batch 19 (157): mcc: 0.9016, acc: 0.8451, precision: 0.9410, recall: 0.8676, f1: 0.9028, edges-pos-ontonotes_loss: 0.0115
09/16 05:17:07 AM: Evaluate: task edges-pos-ontonotes, batch 84 (157): mcc: 0.9139, acc: 0.8638, precision: 0.9479, recall: 0.8844, f1: 0.9151, edges-pos-ontonotes_loss: 0.0104
09/16 05:17:17 AM: Evaluate: task edges-pos-ontonotes, batch 128 (157): mcc: 0.9138, acc: 0.8641, precision: 0.9427, recall: 0.8891, f1: 0.9151, edges-pos-ontonotes_loss: 0.0103
09/16 05:17:24 AM: Updating LR scheduler:
09/16 05:17:24 AM: 	Best result seen so far for macro_avg: 0.919
09/16 05:17:24 AM: 	# validation passes without improvement: 2
09/16 05:17:24 AM: edges-pos-ontonotes_loss: training: 0.012908 validation: 0.010232
09/16 05:17:24 AM: macro_avg: validation: 0.916520
09/16 05:17:24 AM: micro_avg: validation: 0.000000
09/16 05:17:24 AM: edges-pos-ontonotes_mcc: training: 0.886507 validation: 0.915119
09/16 05:17:24 AM: edges-pos-ontonotes_acc: training: 0.816018 validation: 0.867276
09/16 05:17:24 AM: edges-pos-ontonotes_precision: training: 0.920050 validation: 0.941205
09/16 05:17:24 AM: edges-pos-ontonotes_recall: training: 0.858573 validation: 0.893097
09/16 05:17:24 AM: edges-pos-ontonotes_f1: training: 0.888249 validation: 0.916520
09/16 05:17:24 AM: Global learning rate: 0.0001
09/16 05:17:24 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:17:27 AM: Update 38016: task edges-pos-ontonotes, batch 16 (38016): mcc: 0.8686, acc: 0.7916, precision: 0.9044, recall: 0.8393, f1: 0.8706, edges-pos-ontonotes_loss: 0.0152
09/16 05:17:38 AM: Update 38061: task edges-pos-ontonotes, batch 61 (38061): mcc: 0.8679, acc: 0.7902, precision: 0.9031, recall: 0.8392, f1: 0.8700, edges-pos-ontonotes_loss: 0.0157
09/16 05:17:48 AM: Update 38142: task edges-pos-ontonotes, batch 142 (38142): mcc: 0.8689, acc: 0.7902, precision: 0.9092, recall: 0.8354, f1: 0.8707, edges-pos-ontonotes_loss: 0.0149
09/16 05:17:58 AM: Update 38229: task edges-pos-ontonotes, batch 229 (38229): mcc: 0.8696, acc: 0.7907, precision: 0.9113, recall: 0.8348, f1: 0.8714, edges-pos-ontonotes_loss: 0.0145
09/16 05:18:08 AM: Update 38329: task edges-pos-ontonotes, batch 329 (38329): mcc: 0.8711, acc: 0.7925, precision: 0.9130, recall: 0.8359, f1: 0.8728, edges-pos-ontonotes_loss: 0.0143
09/16 05:18:18 AM: Update 38402: task edges-pos-ontonotes, batch 402 (38402): mcc: 0.8720, acc: 0.7939, precision: 0.9130, recall: 0.8377, f1: 0.8737, edges-pos-ontonotes_loss: 0.0143
09/16 05:18:28 AM: Update 38477: task edges-pos-ontonotes, batch 477 (38477): mcc: 0.8731, acc: 0.7955, precision: 0.9126, recall: 0.8400, f1: 0.8748, edges-pos-ontonotes_loss: 0.0142
09/16 05:18:39 AM: Update 38546: task edges-pos-ontonotes, batch 546 (38546): mcc: 0.8741, acc: 0.7969, precision: 0.9127, recall: 0.8420, f1: 0.8759, edges-pos-ontonotes_loss: 0.0141
09/16 05:18:49 AM: Update 38623: task edges-pos-ontonotes, batch 623 (38623): mcc: 0.8750, acc: 0.7982, precision: 0.9130, recall: 0.8432, f1: 0.8767, edges-pos-ontonotes_loss: 0.0141
09/16 05:18:59 AM: Update 38687: task edges-pos-ontonotes, batch 687 (38687): mcc: 0.8753, acc: 0.7988, precision: 0.9130, recall: 0.8439, f1: 0.8771, edges-pos-ontonotes_loss: 0.0140
09/16 05:19:10 AM: Update 38739: task edges-pos-ontonotes, batch 739 (38739): mcc: 0.8747, acc: 0.7983, precision: 0.9118, recall: 0.8439, f1: 0.8766, edges-pos-ontonotes_loss: 0.0141
09/16 05:19:20 AM: Update 38795: task edges-pos-ontonotes, batch 795 (38795): mcc: 0.8744, acc: 0.7980, precision: 0.9110, recall: 0.8441, f1: 0.8763, edges-pos-ontonotes_loss: 0.0141
09/16 05:19:30 AM: Update 38857: task edges-pos-ontonotes, batch 857 (38857): mcc: 0.8744, acc: 0.7981, precision: 0.9105, recall: 0.8445, f1: 0.8763, edges-pos-ontonotes_loss: 0.0142
09/16 05:19:40 AM: Update 38911: task edges-pos-ontonotes, batch 911 (38911): mcc: 0.8745, acc: 0.7984, precision: 0.9102, recall: 0.8450, f1: 0.8764, edges-pos-ontonotes_loss: 0.0142
09/16 05:19:50 AM: Update 38970: task edges-pos-ontonotes, batch 970 (38970): mcc: 0.8747, acc: 0.7988, precision: 0.9100, recall: 0.8455, f1: 0.8766, edges-pos-ontonotes_loss: 0.0142
09/16 05:19:57 AM: ***** Step 39000 / Validation 39 *****
09/16 05:19:57 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:19:57 AM: Validating...
09/16 05:20:00 AM: Evaluate: task edges-pos-ontonotes, batch 22 (157): mcc: 0.9022, acc: 0.8448, precision: 0.9444, recall: 0.8657, f1: 0.9033, edges-pos-ontonotes_loss: 0.0112
09/16 05:20:15 AM: Evaluate: task edges-pos-ontonotes, batch 68 (157): mcc: 0.9144, acc: 0.8626, precision: 0.9523, recall: 0.8813, f1: 0.9154, edges-pos-ontonotes_loss: 0.0104
09/16 05:20:25 AM: Evaluate: task edges-pos-ontonotes, batch 122 (157): mcc: 0.9167, acc: 0.8672, precision: 0.9495, recall: 0.8883, f1: 0.9179, edges-pos-ontonotes_loss: 0.0100
09/16 05:20:32 AM: Updating LR scheduler:
09/16 05:20:32 AM: 	Best result seen so far for macro_avg: 0.919
09/16 05:20:32 AM: 	# validation passes without improvement: 3
09/16 05:20:32 AM: edges-pos-ontonotes_loss: training: 0.014224 validation: 0.009937
09/16 05:20:32 AM: macro_avg: validation: 0.918142
09/16 05:20:32 AM: micro_avg: validation: 0.000000
09/16 05:20:32 AM: edges-pos-ontonotes_mcc: training: 0.874538 validation: 0.916890
09/16 05:20:32 AM: edges-pos-ontonotes_acc: training: 0.798698 validation: 0.868546
09/16 05:20:32 AM: edges-pos-ontonotes_precision: training: 0.909819 validation: 0.946738
09/16 05:20:32 AM: edges-pos-ontonotes_recall: training: 0.845453 validation: 0.891224
09/16 05:20:32 AM: edges-pos-ontonotes_f1: training: 0.876456 validation: 0.918142
09/16 05:20:32 AM: Global learning rate: 0.0001
09/16 05:20:32 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:20:35 AM: Update 39012: task edges-pos-ontonotes, batch 12 (39012): mcc: 0.8749, acc: 0.7996, precision: 0.9117, recall: 0.8444, f1: 0.8768, edges-pos-ontonotes_loss: 0.0140
09/16 05:20:45 AM: Update 39066: task edges-pos-ontonotes, batch 66 (39066): mcc: 0.8780, acc: 0.8053, precision: 0.9092, recall: 0.8527, f1: 0.8800, edges-pos-ontonotes_loss: 0.0143
09/16 05:20:55 AM: Update 39121: task edges-pos-ontonotes, batch 121 (39121): mcc: 0.8783, acc: 0.8058, precision: 0.9089, recall: 0.8535, f1: 0.8803, edges-pos-ontonotes_loss: 0.0142
09/16 05:21:05 AM: Update 39182: task edges-pos-ontonotes, batch 182 (39182): mcc: 0.8789, acc: 0.8064, precision: 0.9097, recall: 0.8538, f1: 0.8808, edges-pos-ontonotes_loss: 0.0142
09/16 05:21:15 AM: Update 39239: task edges-pos-ontonotes, batch 239 (39239): mcc: 0.8788, acc: 0.8062, precision: 0.9099, recall: 0.8534, f1: 0.8807, edges-pos-ontonotes_loss: 0.0142
09/16 05:21:25 AM: Update 39288: task edges-pos-ontonotes, batch 288 (39288): mcc: 0.8794, acc: 0.8074, precision: 0.9100, recall: 0.8544, f1: 0.8814, edges-pos-ontonotes_loss: 0.0141
09/16 05:21:35 AM: Update 39324: task edges-pos-ontonotes, batch 324 (39324): mcc: 0.8790, acc: 0.8071, precision: 0.9100, recall: 0.8537, f1: 0.8810, edges-pos-ontonotes_loss: 0.0141
09/16 05:21:45 AM: Update 39383: task edges-pos-ontonotes, batch 383 (39383): mcc: 0.8795, acc: 0.8079, precision: 0.9108, recall: 0.8540, f1: 0.8815, edges-pos-ontonotes_loss: 0.0140
09/16 05:21:55 AM: Update 39442: task edges-pos-ontonotes, batch 442 (39442): mcc: 0.8796, acc: 0.8082, precision: 0.9110, recall: 0.8539, f1: 0.8815, edges-pos-ontonotes_loss: 0.0141
09/16 05:22:05 AM: Update 39495: task edges-pos-ontonotes, batch 495 (39495): mcc: 0.8798, acc: 0.8086, precision: 0.9113, recall: 0.8540, f1: 0.8817, edges-pos-ontonotes_loss: 0.0141
09/16 05:22:16 AM: Update 39552: task edges-pos-ontonotes, batch 552 (39552): mcc: 0.8802, acc: 0.8092, precision: 0.9116, recall: 0.8544, f1: 0.8821, edges-pos-ontonotes_loss: 0.0140
09/16 05:22:26 AM: Update 39606: task edges-pos-ontonotes, batch 606 (39606): mcc: 0.8803, acc: 0.8095, precision: 0.9117, recall: 0.8547, f1: 0.8823, edges-pos-ontonotes_loss: 0.0140
09/16 05:22:36 AM: Update 39649: task edges-pos-ontonotes, batch 649 (39649): mcc: 0.8804, acc: 0.8096, precision: 0.9118, recall: 0.8548, f1: 0.8823, edges-pos-ontonotes_loss: 0.0140
09/16 05:22:46 AM: Update 39707: task edges-pos-ontonotes, batch 707 (39707): mcc: 0.8803, acc: 0.8095, precision: 0.9118, recall: 0.8545, f1: 0.8822, edges-pos-ontonotes_loss: 0.0140
09/16 05:22:56 AM: Update 39761: task edges-pos-ontonotes, batch 761 (39761): mcc: 0.8808, acc: 0.8103, precision: 0.9124, recall: 0.8550, f1: 0.8828, edges-pos-ontonotes_loss: 0.0140
09/16 05:23:06 AM: Update 39817: task edges-pos-ontonotes, batch 817 (39817): mcc: 0.8810, acc: 0.8107, precision: 0.9125, recall: 0.8553, f1: 0.8830, edges-pos-ontonotes_loss: 0.0140
09/16 05:23:16 AM: Update 39871: task edges-pos-ontonotes, batch 871 (39871): mcc: 0.8812, acc: 0.8109, precision: 0.9127, recall: 0.8554, f1: 0.8831, edges-pos-ontonotes_loss: 0.0140
09/16 05:23:26 AM: Update 39932: task edges-pos-ontonotes, batch 932 (39932): mcc: 0.8812, acc: 0.8110, precision: 0.9127, recall: 0.8554, f1: 0.8831, edges-pos-ontonotes_loss: 0.0140
09/16 05:23:36 AM: Update 39987: task edges-pos-ontonotes, batch 987 (39987): mcc: 0.8812, acc: 0.8110, precision: 0.9128, recall: 0.8554, f1: 0.8831, edges-pos-ontonotes_loss: 0.0139
09/16 05:23:38 AM: ***** Step 40000 / Validation 40 *****
09/16 05:23:38 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:23:38 AM: Validating...
09/16 05:23:46 AM: Evaluate: task edges-pos-ontonotes, batch 58 (157): mcc: 0.9098, acc: 0.8553, precision: 0.9514, recall: 0.8735, f1: 0.9108, edges-pos-ontonotes_loss: 0.0109
09/16 05:23:56 AM: Evaluate: task edges-pos-ontonotes, batch 114 (157): mcc: 0.9145, acc: 0.8643, precision: 0.9482, recall: 0.8853, f1: 0.9157, edges-pos-ontonotes_loss: 0.0103
09/16 05:24:05 AM: Updating LR scheduler:
09/16 05:24:05 AM: 	Best result seen so far for macro_avg: 0.919
09/16 05:24:05 AM: 	# validation passes without improvement: 0
09/16 05:24:05 AM: edges-pos-ontonotes_loss: training: 0.013892 validation: 0.010047
09/16 05:24:05 AM: macro_avg: validation: 0.917772
09/16 05:24:05 AM: micro_avg: validation: 0.000000
09/16 05:24:05 AM: edges-pos-ontonotes_mcc: training: 0.881264 validation: 0.916508
09/16 05:24:05 AM: edges-pos-ontonotes_acc: training: 0.811107 validation: 0.868504
09/16 05:24:05 AM: edges-pos-ontonotes_precision: training: 0.912780 validation: 0.946224
09/16 05:24:05 AM: edges-pos-ontonotes_recall: training: 0.855449 validation: 0.890981
09/16 05:24:05 AM: edges-pos-ontonotes_f1: training: 0.883185 validation: 0.917772
09/16 05:24:05 AM: Global learning rate: 5e-05
09/16 05:24:05 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:24:07 AM: Update 40007: task edges-pos-ontonotes, batch 7 (40007): mcc: 0.8953, acc: 0.8288, precision: 0.9276, recall: 0.8682, f1: 0.8969, edges-pos-ontonotes_loss: 0.0115
09/16 05:24:17 AM: Update 40062: task edges-pos-ontonotes, batch 62 (40062): mcc: 0.8831, acc: 0.8145, precision: 0.9151, recall: 0.8567, f1: 0.8850, edges-pos-ontonotes_loss: 0.0123
09/16 05:24:27 AM: Update 40134: task edges-pos-ontonotes, batch 134 (40134): mcc: 0.8853, acc: 0.8169, precision: 0.9171, recall: 0.8590, f1: 0.8871, edges-pos-ontonotes_loss: 0.0121
09/16 05:24:37 AM: Update 40209: task edges-pos-ontonotes, batch 209 (40209): mcc: 0.8864, acc: 0.8181, precision: 0.9178, recall: 0.8604, f1: 0.8882, edges-pos-ontonotes_loss: 0.0120
09/16 05:24:47 AM: Update 40272: task edges-pos-ontonotes, batch 272 (40272): mcc: 0.8886, acc: 0.8211, precision: 0.9197, recall: 0.8629, f1: 0.8904, edges-pos-ontonotes_loss: 0.0118
09/16 05:24:57 AM: Update 40368: task edges-pos-ontonotes, batch 368 (40368): mcc: 0.8930, acc: 0.8270, precision: 0.9239, recall: 0.8673, f1: 0.8947, edges-pos-ontonotes_loss: 0.0115
09/16 05:25:07 AM: Update 40463: task edges-pos-ontonotes, batch 463 (40463): mcc: 0.8960, acc: 0.8307, precision: 0.9265, recall: 0.8705, f1: 0.8976, edges-pos-ontonotes_loss: 0.0113
09/16 05:25:17 AM: Update 40562: task edges-pos-ontonotes, batch 562 (40562): mcc: 0.8979, acc: 0.8333, precision: 0.9284, recall: 0.8724, f1: 0.8995, edges-pos-ontonotes_loss: 0.0111
09/16 05:25:27 AM: Update 40658: task edges-pos-ontonotes, batch 658 (40658): mcc: 0.8987, acc: 0.8344, precision: 0.9296, recall: 0.8728, f1: 0.9003, edges-pos-ontonotes_loss: 0.0112
09/16 05:25:37 AM: Update 40772: task edges-pos-ontonotes, batch 772 (40772): mcc: 0.8995, acc: 0.8353, precision: 0.9307, recall: 0.8732, f1: 0.9011, edges-pos-ontonotes_loss: 0.0111
09/16 05:25:48 AM: Update 40878: task edges-pos-ontonotes, batch 878 (40878): mcc: 0.9002, acc: 0.8363, precision: 0.9314, recall: 0.8738, f1: 0.9017, edges-pos-ontonotes_loss: 0.0111
09/16 05:25:57 AM: ***** Step 41000 / Validation 41 *****
09/16 05:25:57 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:25:57 AM: Validating...
09/16 05:25:58 AM: Evaluate: task edges-pos-ontonotes, batch 8 (157): mcc: 0.9029, acc: 0.8544, precision: 0.9295, recall: 0.8809, f1: 0.9045, edges-pos-ontonotes_loss: 0.0113
09/16 05:26:08 AM: Evaluate: task edges-pos-ontonotes, batch 78 (157): mcc: 0.9140, acc: 0.8646, precision: 0.9464, recall: 0.8861, f1: 0.9152, edges-pos-ontonotes_loss: 0.0105
09/16 05:26:18 AM: Evaluate: task edges-pos-ontonotes, batch 129 (157): mcc: 0.9137, acc: 0.8649, precision: 0.9396, recall: 0.8919, f1: 0.9151, edges-pos-ontonotes_loss: 0.0103
09/16 05:26:24 AM: Updating LR scheduler:
09/16 05:26:24 AM: 	Best result seen so far for macro_avg: 0.919
09/16 05:26:24 AM: 	# validation passes without improvement: 1
09/16 05:26:24 AM: edges-pos-ontonotes_loss: training: 0.011457 validation: 0.010181
09/16 05:26:24 AM: macro_avg: validation: 0.916487
09/16 05:26:24 AM: micro_avg: validation: 0.000000
09/16 05:26:24 AM: edges-pos-ontonotes_mcc: training: 0.898326 validation: 0.915009
09/16 05:26:24 AM: edges-pos-ontonotes_acc: training: 0.833502 validation: 0.868038
09/16 05:26:24 AM: edges-pos-ontonotes_precision: training: 0.930444 validation: 0.938295
09/16 05:26:24 AM: edges-pos-ontonotes_recall: training: 0.871260 validation: 0.895669
09/16 05:26:24 AM: edges-pos-ontonotes_f1: training: 0.899880 validation: 0.916487
09/16 05:26:24 AM: Global learning rate: 5e-05
09/16 05:26:24 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:26:29 AM: Update 41063: task edges-pos-ontonotes, batch 63 (41063): mcc: 0.8776, acc: 0.8000, precision: 0.9204, recall: 0.8414, f1: 0.8791, edges-pos-ontonotes_loss: 0.0136
09/16 05:26:48 AM: Update 41191: task edges-pos-ontonotes, batch 191 (41191): mcc: 0.8759, acc: 0.7993, precision: 0.9180, recall: 0.8404, f1: 0.8775, edges-pos-ontonotes_loss: 0.0141
09/16 05:26:58 AM: Update 41250: task edges-pos-ontonotes, batch 250 (41250): mcc: 0.8738, acc: 0.7974, precision: 0.9115, recall: 0.8424, f1: 0.8756, edges-pos-ontonotes_loss: 0.0143
09/16 05:27:08 AM: Update 41313: task edges-pos-ontonotes, batch 313 (41313): mcc: 0.8737, acc: 0.7969, precision: 0.9104, recall: 0.8434, f1: 0.8756, edges-pos-ontonotes_loss: 0.0145
09/16 05:27:18 AM: Update 41374: task edges-pos-ontonotes, batch 374 (41374): mcc: 0.8736, acc: 0.7970, precision: 0.9098, recall: 0.8436, f1: 0.8755, edges-pos-ontonotes_loss: 0.0145
09/16 05:27:28 AM: Update 41444: task edges-pos-ontonotes, batch 444 (41444): mcc: 0.8731, acc: 0.7964, precision: 0.9088, recall: 0.8437, f1: 0.8750, edges-pos-ontonotes_loss: 0.0146
09/16 05:27:38 AM: Update 41500: task edges-pos-ontonotes, batch 500 (41500): mcc: 0.8726, acc: 0.7956, precision: 0.9080, recall: 0.8435, f1: 0.8745, edges-pos-ontonotes_loss: 0.0148
09/16 05:27:48 AM: Update 41565: task edges-pos-ontonotes, batch 565 (41565): mcc: 0.8721, acc: 0.7948, precision: 0.9084, recall: 0.8422, f1: 0.8741, edges-pos-ontonotes_loss: 0.0147
09/16 05:27:58 AM: Update 41660: task edges-pos-ontonotes, batch 660 (41660): mcc: 0.8719, acc: 0.7943, precision: 0.9096, recall: 0.8407, f1: 0.8738, edges-pos-ontonotes_loss: 0.0146
09/16 05:28:08 AM: Update 41756: task edges-pos-ontonotes, batch 756 (41756): mcc: 0.8720, acc: 0.7943, precision: 0.9103, recall: 0.8402, f1: 0.8739, edges-pos-ontonotes_loss: 0.0146
09/16 05:28:19 AM: Update 41834: task edges-pos-ontonotes, batch 834 (41834): mcc: 0.8722, acc: 0.7944, precision: 0.9108, recall: 0.8401, f1: 0.8740, edges-pos-ontonotes_loss: 0.0145
09/16 05:28:29 AM: Update 41906: task edges-pos-ontonotes, batch 906 (41906): mcc: 0.8731, acc: 0.7958, precision: 0.9110, recall: 0.8417, f1: 0.8750, edges-pos-ontonotes_loss: 0.0144
09/16 05:28:39 AM: Update 41978: task edges-pos-ontonotes, batch 978 (41978): mcc: 0.8738, acc: 0.7968, precision: 0.9111, recall: 0.8429, f1: 0.8757, edges-pos-ontonotes_loss: 0.0143
09/16 05:28:42 AM: ***** Step 42000 / Validation 42 *****
09/16 05:28:42 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:28:42 AM: Validating...
09/16 05:28:49 AM: Evaluate: task edges-pos-ontonotes, batch 48 (157): mcc: 0.9114, acc: 0.8586, precision: 0.9485, recall: 0.8790, f1: 0.9125, edges-pos-ontonotes_loss: 0.0105
09/16 05:28:59 AM: Evaluate: task edges-pos-ontonotes, batch 107 (157): mcc: 0.9168, acc: 0.8678, precision: 0.9461, recall: 0.8916, f1: 0.9181, edges-pos-ontonotes_loss: 0.0100
09/16 05:29:10 AM: Evaluate: task edges-pos-ontonotes, batch 154 (157): mcc: 0.9169, acc: 0.8695, precision: 0.9412, recall: 0.8964, f1: 0.9183, edges-pos-ontonotes_loss: 0.0099
09/16 05:29:10 AM: Updating LR scheduler:
09/16 05:29:10 AM: 	Best result seen so far for macro_avg: 0.919
09/16 05:29:10 AM: 	# validation passes without improvement: 2
09/16 05:29:10 AM: edges-pos-ontonotes_loss: training: 0.014313 validation: 0.009912
09/16 05:29:10 AM: macro_avg: validation: 0.918442
09/16 05:29:10 AM: micro_avg: validation: 0.000000
09/16 05:29:10 AM: edges-pos-ontonotes_mcc: training: 0.873962 validation: 0.917032
09/16 05:29:10 AM: edges-pos-ontonotes_acc: training: 0.796983 validation: 0.869710
09/16 05:29:10 AM: edges-pos-ontonotes_precision: training: 0.911118 validation: 0.941339
09/16 05:29:10 AM: edges-pos-ontonotes_recall: training: 0.843149 validation: 0.896632
09/16 05:29:10 AM: edges-pos-ontonotes_f1: training: 0.875816 validation: 0.918442
09/16 05:29:10 AM: Global learning rate: 5e-05
09/16 05:29:10 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:29:20 AM: Update 42064: task edges-pos-ontonotes, batch 64 (42064): mcc: 0.8802, acc: 0.8064, precision: 0.9126, recall: 0.8536, f1: 0.8821, edges-pos-ontonotes_loss: 0.0137
09/16 05:29:30 AM: Update 42143: task edges-pos-ontonotes, batch 143 (42143): mcc: 0.8806, acc: 0.8066, precision: 0.9135, recall: 0.8534, f1: 0.8825, edges-pos-ontonotes_loss: 0.0136
09/16 05:29:40 AM: Update 42187: task edges-pos-ontonotes, batch 187 (42187): mcc: 0.8777, acc: 0.8036, precision: 0.9096, recall: 0.8516, f1: 0.8796, edges-pos-ontonotes_loss: 0.0138
09/16 05:29:50 AM: Update 42245: task edges-pos-ontonotes, batch 245 (42245): mcc: 0.8761, acc: 0.8016, precision: 0.9080, recall: 0.8501, f1: 0.8781, edges-pos-ontonotes_loss: 0.0140
09/16 05:30:01 AM: Update 42302: task edges-pos-ontonotes, batch 302 (42302): mcc: 0.8765, acc: 0.8021, precision: 0.9078, recall: 0.8510, f1: 0.8785, edges-pos-ontonotes_loss: 0.0141
09/16 05:30:11 AM: Update 42363: task edges-pos-ontonotes, batch 363 (42363): mcc: 0.8762, acc: 0.8018, precision: 0.9077, recall: 0.8507, f1: 0.8783, edges-pos-ontonotes_loss: 0.0142
09/16 05:30:21 AM: Update 42423: task edges-pos-ontonotes, batch 423 (42423): mcc: 0.8759, acc: 0.8014, precision: 0.9074, recall: 0.8503, f1: 0.8779, edges-pos-ontonotes_loss: 0.0143
09/16 05:30:31 AM: Update 42471: task edges-pos-ontonotes, batch 471 (42471): mcc: 0.8759, acc: 0.8014, precision: 0.9073, recall: 0.8504, f1: 0.8779, edges-pos-ontonotes_loss: 0.0143
09/16 05:30:41 AM: Update 42528: task edges-pos-ontonotes, batch 528 (42528): mcc: 0.8763, acc: 0.8021, precision: 0.9077, recall: 0.8509, f1: 0.8784, edges-pos-ontonotes_loss: 0.0142
09/16 05:30:51 AM: Update 42585: task edges-pos-ontonotes, batch 585 (42585): mcc: 0.8766, acc: 0.8027, precision: 0.9080, recall: 0.8511, f1: 0.8787, edges-pos-ontonotes_loss: 0.0142
09/16 05:31:01 AM: Update 42643: task edges-pos-ontonotes, batch 643 (42643): mcc: 0.8769, acc: 0.8031, precision: 0.9082, recall: 0.8514, f1: 0.8789, edges-pos-ontonotes_loss: 0.0142
09/16 05:31:11 AM: Update 42698: task edges-pos-ontonotes, batch 698 (42698): mcc: 0.8773, acc: 0.8038, precision: 0.9086, recall: 0.8519, f1: 0.8793, edges-pos-ontonotes_loss: 0.0142
09/16 05:31:21 AM: Update 42752: task edges-pos-ontonotes, batch 752 (42752): mcc: 0.8777, acc: 0.8045, precision: 0.9090, recall: 0.8523, f1: 0.8797, edges-pos-ontonotes_loss: 0.0142
09/16 05:31:32 AM: Update 42792: task edges-pos-ontonotes, batch 792 (42792): mcc: 0.8777, acc: 0.8045, precision: 0.9089, recall: 0.8523, f1: 0.8797, edges-pos-ontonotes_loss: 0.0141
09/16 05:31:42 AM: Update 42851: task edges-pos-ontonotes, batch 851 (42851): mcc: 0.8780, acc: 0.8051, precision: 0.9092, recall: 0.8526, f1: 0.8800, edges-pos-ontonotes_loss: 0.0141
09/16 05:31:52 AM: Update 42909: task edges-pos-ontonotes, batch 909 (42909): mcc: 0.8782, acc: 0.8055, precision: 0.9094, recall: 0.8528, f1: 0.8802, edges-pos-ontonotes_loss: 0.0141
09/16 05:32:02 AM: Update 42967: task edges-pos-ontonotes, batch 967 (42967): mcc: 0.8785, acc: 0.8059, precision: 0.9097, recall: 0.8531, f1: 0.8805, edges-pos-ontonotes_loss: 0.0141
09/16 05:32:08 AM: ***** Step 43000 / Validation 43 *****
09/16 05:32:08 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:32:08 AM: Validating...
09/16 05:32:12 AM: Evaluate: task edges-pos-ontonotes, batch 29 (157): mcc: 0.9083, acc: 0.8525, precision: 0.9497, recall: 0.8722, f1: 0.9093, edges-pos-ontonotes_loss: 0.0108
09/16 05:32:22 AM: Evaluate: task edges-pos-ontonotes, batch 95 (157): mcc: 0.9162, acc: 0.8661, precision: 0.9508, recall: 0.8860, f1: 0.9173, edges-pos-ontonotes_loss: 0.0102
09/16 05:32:32 AM: Evaluate: task edges-pos-ontonotes, batch 142 (157): mcc: 0.9169, acc: 0.8685, precision: 0.9466, recall: 0.8915, f1: 0.9182, edges-pos-ontonotes_loss: 0.0100
09/16 05:32:35 AM: Updating LR scheduler:
09/16 05:32:35 AM: 	Best result seen so far for macro_avg: 0.919
09/16 05:32:35 AM: 	# validation passes without improvement: 3
09/16 05:32:35 AM: edges-pos-ontonotes_loss: training: 0.014075 validation: 0.009907
09/16 05:32:35 AM: macro_avg: validation: 0.919202
09/16 05:32:35 AM: micro_avg: validation: 0.000000
09/16 05:32:35 AM: edges-pos-ontonotes_mcc: training: 0.878667 validation: 0.917928
09/16 05:32:35 AM: edges-pos-ontonotes_acc: training: 0.806198 validation: 0.870620
09/16 05:32:35 AM: edges-pos-ontonotes_precision: training: 0.909771 validation: 0.946380
09/16 05:32:35 AM: edges-pos-ontonotes_recall: training: 0.853344 validation: 0.893542
09/16 05:32:35 AM: edges-pos-ontonotes_f1: training: 0.880655 validation: 0.919202
09/16 05:32:35 AM: Global learning rate: 5e-05
09/16 05:32:35 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:32:42 AM: Update 43038: task edges-pos-ontonotes, batch 38 (43038): mcc: 0.8829, acc: 0.8139, precision: 0.9172, recall: 0.8544, f1: 0.8847, edges-pos-ontonotes_loss: 0.0134
09/16 05:33:00 AM: Update 43086: task edges-pos-ontonotes, batch 86 (43086): mcc: 0.8816, acc: 0.8122, precision: 0.9149, recall: 0.8541, f1: 0.8835, edges-pos-ontonotes_loss: 0.0137
09/16 05:33:10 AM: Update 43142: task edges-pos-ontonotes, batch 142 (43142): mcc: 0.8817, acc: 0.8119, precision: 0.9139, recall: 0.8553, f1: 0.8836, edges-pos-ontonotes_loss: 0.0137
09/16 05:33:21 AM: Update 43199: task edges-pos-ontonotes, batch 199 (43199): mcc: 0.8815, acc: 0.8120, precision: 0.9136, recall: 0.8551, f1: 0.8834, edges-pos-ontonotes_loss: 0.0138
09/16 05:33:31 AM: Update 43256: task edges-pos-ontonotes, batch 256 (43256): mcc: 0.8815, acc: 0.8117, precision: 0.9138, recall: 0.8550, f1: 0.8834, edges-pos-ontonotes_loss: 0.0139
09/16 05:33:41 AM: Update 43310: task edges-pos-ontonotes, batch 310 (43310): mcc: 0.8817, acc: 0.8121, precision: 0.9137, recall: 0.8554, f1: 0.8836, edges-pos-ontonotes_loss: 0.0139
09/16 05:33:51 AM: Update 43365: task edges-pos-ontonotes, batch 365 (43365): mcc: 0.8817, acc: 0.8121, precision: 0.9135, recall: 0.8555, f1: 0.8836, edges-pos-ontonotes_loss: 0.0140
09/16 05:34:01 AM: Update 43411: task edges-pos-ontonotes, batch 411 (43411): mcc: 0.8813, acc: 0.8116, precision: 0.9133, recall: 0.8550, f1: 0.8832, edges-pos-ontonotes_loss: 0.0140
09/16 05:34:11 AM: Update 43482: task edges-pos-ontonotes, batch 482 (43482): mcc: 0.8819, acc: 0.8124, precision: 0.9137, recall: 0.8557, f1: 0.8838, edges-pos-ontonotes_loss: 0.0137
09/16 05:34:21 AM: Update 43554: task edges-pos-ontonotes, batch 554 (43554): mcc: 0.8825, acc: 0.8132, precision: 0.9143, recall: 0.8564, f1: 0.8844, edges-pos-ontonotes_loss: 0.0135
09/16 05:34:31 AM: Update 43617: task edges-pos-ontonotes, batch 617 (43617): mcc: 0.8831, acc: 0.8139, precision: 0.9147, recall: 0.8571, f1: 0.8849, edges-pos-ontonotes_loss: 0.0133
09/16 05:34:41 AM: Update 43684: task edges-pos-ontonotes, batch 684 (43684): mcc: 0.8835, acc: 0.8145, precision: 0.9150, recall: 0.8576, f1: 0.8854, edges-pos-ontonotes_loss: 0.0131
09/16 05:34:51 AM: Update 43753: task edges-pos-ontonotes, batch 753 (43753): mcc: 0.8846, acc: 0.8160, precision: 0.9160, recall: 0.8588, f1: 0.8865, edges-pos-ontonotes_loss: 0.0129
09/16 05:35:01 AM: Update 43847: task edges-pos-ontonotes, batch 847 (43847): mcc: 0.8865, acc: 0.8184, precision: 0.9177, recall: 0.8608, f1: 0.8884, edges-pos-ontonotes_loss: 0.0127
09/16 05:35:11 AM: Update 43937: task edges-pos-ontonotes, batch 937 (43937): mcc: 0.8882, acc: 0.8206, precision: 0.9193, recall: 0.8626, f1: 0.8900, edges-pos-ontonotes_loss: 0.0124
09/16 05:35:19 AM: ***** Step 44000 / Validation 44 *****
09/16 05:35:19 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:35:19 AM: Validating...
09/16 05:35:21 AM: Evaluate: task edges-pos-ontonotes, batch 19 (157): mcc: 0.9030, acc: 0.8466, precision: 0.9435, recall: 0.8679, f1: 0.9041, edges-pos-ontonotes_loss: 0.0113
09/16 05:35:32 AM: Evaluate: task edges-pos-ontonotes, batch 88 (157): mcc: 0.9148, acc: 0.8644, precision: 0.9497, recall: 0.8845, f1: 0.9160, edges-pos-ontonotes_loss: 0.0103
09/16 05:35:42 AM: Evaluate: task edges-pos-ontonotes, batch 135 (157): mcc: 0.9157, acc: 0.8672, precision: 0.9448, recall: 0.8907, f1: 0.9170, edges-pos-ontonotes_loss: 0.0101
09/16 05:35:46 AM: Updating LR scheduler:
09/16 05:35:46 AM: 	Best result seen so far for macro_avg: 0.919
09/16 05:35:46 AM: 	# validation passes without improvement: 0
09/16 05:35:46 AM: edges-pos-ontonotes_loss: training: 0.012281 validation: 0.009990
09/16 05:35:46 AM: macro_avg: validation: 0.918470
09/16 05:35:46 AM: micro_avg: validation: 0.000000
09/16 05:35:46 AM: edges-pos-ontonotes_mcc: training: 0.889362 validation: 0.917154
09/16 05:35:46 AM: edges-pos-ontonotes_acc: training: 0.822191 validation: 0.870377
09/16 05:35:46 AM: edges-pos-ontonotes_precision: training: 0.920290 validation: 0.944723
09/16 05:35:46 AM: edges-pos-ontonotes_recall: training: 0.863777 validation: 0.893637
09/16 05:35:46 AM: edges-pos-ontonotes_f1: training: 0.891139 validation: 0.918470
09/16 05:35:46 AM: Global learning rate: 2.5e-05
09/16 05:35:46 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:35:52 AM: Update 44044: task edges-pos-ontonotes, batch 44 (44044): mcc: 0.9062, acc: 0.8440, precision: 0.9393, recall: 0.8779, f1: 0.9076, edges-pos-ontonotes_loss: 0.0108
09/16 05:36:02 AM: Update 44158: task edges-pos-ontonotes, batch 158 (44158): mcc: 0.9069, acc: 0.8451, precision: 0.9414, recall: 0.8773, f1: 0.9082, edges-pos-ontonotes_loss: 0.0109
09/16 05:36:12 AM: Update 44261: task edges-pos-ontonotes, batch 261 (44261): mcc: 0.9073, acc: 0.8459, precision: 0.9407, recall: 0.8787, f1: 0.9087, edges-pos-ontonotes_loss: 0.0108
09/16 05:36:22 AM: Update 44357: task edges-pos-ontonotes, batch 357 (44357): mcc: 0.9045, acc: 0.8422, precision: 0.9386, recall: 0.8754, f1: 0.9059, edges-pos-ontonotes_loss: 0.0111
09/16 05:36:32 AM: Update 44503: task edges-pos-ontonotes, batch 503 (44503): mcc: 0.8987, acc: 0.8333, precision: 0.9349, recall: 0.8677, f1: 0.9001, edges-pos-ontonotes_loss: 0.0119
09/16 05:36:42 AM: Update 44642: task edges-pos-ontonotes, batch 642 (44642): mcc: 0.8947, acc: 0.8275, precision: 0.9323, recall: 0.8627, f1: 0.8962, edges-pos-ontonotes_loss: 0.0124
09/16 05:36:52 AM: Update 44690: task edges-pos-ontonotes, batch 690 (44690): mcc: 0.8907, acc: 0.8222, precision: 0.9275, recall: 0.8596, f1: 0.8923, edges-pos-ontonotes_loss: 0.0126
09/16 05:37:02 AM: Update 44755: task edges-pos-ontonotes, batch 755 (44755): mcc: 0.8879, acc: 0.8182, precision: 0.9244, recall: 0.8572, f1: 0.8895, edges-pos-ontonotes_loss: 0.0128
09/16 05:37:12 AM: Update 44820: task edges-pos-ontonotes, batch 820 (44820): mcc: 0.8862, acc: 0.8157, precision: 0.9223, recall: 0.8557, f1: 0.8878, edges-pos-ontonotes_loss: 0.0130
09/16 05:37:23 AM: Update 44877: task edges-pos-ontonotes, batch 877 (44877): mcc: 0.8849, acc: 0.8138, precision: 0.9206, recall: 0.8549, f1: 0.8866, edges-pos-ontonotes_loss: 0.0131
09/16 05:37:33 AM: Update 44936: task edges-pos-ontonotes, batch 936 (44936): mcc: 0.8833, acc: 0.8116, precision: 0.9189, recall: 0.8536, f1: 0.8850, edges-pos-ontonotes_loss: 0.0132
09/16 05:37:43 AM: Update 44989: task edges-pos-ontonotes, batch 989 (44989): mcc: 0.8818, acc: 0.8094, precision: 0.9177, recall: 0.8519, f1: 0.8835, edges-pos-ontonotes_loss: 0.0134
09/16 05:37:44 AM: ***** Step 45000 / Validation 45 *****
09/16 05:37:44 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:37:44 AM: Validating...
09/16 05:37:53 AM: Evaluate: task edges-pos-ontonotes, batch 65 (157): mcc: 0.9133, acc: 0.8632, precision: 0.9479, recall: 0.8834, f1: 0.9145, edges-pos-ontonotes_loss: 0.0106
09/16 05:38:03 AM: Evaluate: task edges-pos-ontonotes, batch 118 (157): mcc: 0.9161, acc: 0.8682, precision: 0.9444, recall: 0.8919, f1: 0.9174, edges-pos-ontonotes_loss: 0.0101
09/16 05:38:11 AM: Updating LR scheduler:
09/16 05:38:11 AM: 	Best result seen so far for macro_avg: 0.919
09/16 05:38:11 AM: 	# validation passes without improvement: 1
09/16 05:38:11 AM: edges-pos-ontonotes_loss: training: 0.013374 validation: 0.009956
09/16 05:38:11 AM: macro_avg: validation: 0.918722
09/16 05:38:11 AM: micro_avg: validation: 0.000000
09/16 05:38:11 AM: edges-pos-ontonotes_mcc: training: 0.881803 validation: 0.917319
09/16 05:38:11 AM: edges-pos-ontonotes_acc: training: 0.809373 validation: 0.870874
09/16 05:38:11 AM: edges-pos-ontonotes_precision: training: 0.917724 validation: 0.941648
09/16 05:38:11 AM: edges-pos-ontonotes_recall: training: 0.851829 validation: 0.896886
09/16 05:38:11 AM: edges-pos-ontonotes_f1: training: 0.883549 validation: 0.918722
09/16 05:38:11 AM: Global learning rate: 2.5e-05
09/16 05:38:11 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:38:13 AM: Update 45016: task edges-pos-ontonotes, batch 16 (45016): mcc: 0.8746, acc: 0.7965, precision: 0.9266, recall: 0.8300, f1: 0.8757, edges-pos-ontonotes_loss: 0.0140
09/16 05:38:23 AM: Update 45106: task edges-pos-ontonotes, batch 106 (45106): mcc: 0.8739, acc: 0.7946, precision: 0.9212, recall: 0.8337, f1: 0.8752, edges-pos-ontonotes_loss: 0.0140
09/16 05:38:33 AM: Update 45190: task edges-pos-ontonotes, batch 190 (45190): mcc: 0.8733, acc: 0.7943, precision: 0.9201, recall: 0.8336, f1: 0.8747, edges-pos-ontonotes_loss: 0.0140
09/16 05:38:43 AM: Update 45286: task edges-pos-ontonotes, batch 286 (45286): mcc: 0.8732, acc: 0.7946, precision: 0.9198, recall: 0.8337, f1: 0.8746, edges-pos-ontonotes_loss: 0.0139
09/16 05:38:53 AM: Update 45294: task edges-pos-ontonotes, batch 294 (45294): mcc: 0.8734, acc: 0.7950, precision: 0.9198, recall: 0.8341, f1: 0.8749, edges-pos-ontonotes_loss: 0.0139
09/16 05:39:03 AM: Update 45360: task edges-pos-ontonotes, batch 360 (45360): mcc: 0.8752, acc: 0.7980, precision: 0.9175, recall: 0.8395, f1: 0.8768, edges-pos-ontonotes_loss: 0.0139
09/16 05:39:13 AM: Update 45433: task edges-pos-ontonotes, batch 433 (45433): mcc: 0.8762, acc: 0.7998, precision: 0.9167, recall: 0.8422, f1: 0.8779, edges-pos-ontonotes_loss: 0.0138
09/16 05:39:24 AM: Update 45510: task edges-pos-ontonotes, batch 510 (45510): mcc: 0.8770, acc: 0.8010, precision: 0.9158, recall: 0.8446, f1: 0.8787, edges-pos-ontonotes_loss: 0.0138
09/16 05:39:34 AM: Update 45581: task edges-pos-ontonotes, batch 581 (45581): mcc: 0.8777, acc: 0.8020, precision: 0.9156, recall: 0.8460, f1: 0.8794, edges-pos-ontonotes_loss: 0.0138
09/16 05:39:44 AM: Update 45632: task edges-pos-ontonotes, batch 632 (45632): mcc: 0.8775, acc: 0.8020, precision: 0.9144, recall: 0.8467, f1: 0.8793, edges-pos-ontonotes_loss: 0.0138
09/16 05:39:54 AM: Update 45687: task edges-pos-ontonotes, batch 687 (45687): mcc: 0.8771, acc: 0.8017, precision: 0.9132, recall: 0.8472, f1: 0.8789, edges-pos-ontonotes_loss: 0.0138
09/16 05:40:04 AM: Update 45747: task edges-pos-ontonotes, batch 747 (45747): mcc: 0.8770, acc: 0.8018, precision: 0.9123, recall: 0.8477, f1: 0.8788, edges-pos-ontonotes_loss: 0.0139
09/16 05:40:14 AM: Update 45806: task edges-pos-ontonotes, batch 806 (45806): mcc: 0.8767, acc: 0.8016, precision: 0.9115, recall: 0.8479, f1: 0.8786, edges-pos-ontonotes_loss: 0.0139
09/16 05:40:24 AM: Update 45868: task edges-pos-ontonotes, batch 868 (45868): mcc: 0.8765, acc: 0.8015, precision: 0.9111, recall: 0.8480, f1: 0.8784, edges-pos-ontonotes_loss: 0.0140
09/16 05:40:36 AM: Update 45920: task edges-pos-ontonotes, batch 920 (45920): mcc: 0.8764, acc: 0.8016, precision: 0.9107, recall: 0.8482, f1: 0.8783, edges-pos-ontonotes_loss: 0.0140
09/16 05:40:46 AM: Update 45976: task edges-pos-ontonotes, batch 976 (45976): mcc: 0.8766, acc: 0.8020, precision: 0.9106, recall: 0.8487, f1: 0.8786, edges-pos-ontonotes_loss: 0.0141
09/16 05:40:51 AM: ***** Step 46000 / Validation 46 *****
09/16 05:40:51 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 05:40:51 AM: Validating...
09/16 05:40:56 AM: Evaluate: task edges-pos-ontonotes, batch 38 (157): mcc: 0.9093, acc: 0.8557, precision: 0.9491, recall: 0.8745, f1: 0.9103, edges-pos-ontonotes_loss: 0.0107
09/16 05:41:06 AM: Evaluate: task edges-pos-ontonotes, batch 101 (157): mcc: 0.9169, acc: 0.8678, precision: 0.9499, recall: 0.8883, f1: 0.9181, edges-pos-ontonotes_loss: 0.0100
09/16 05:41:16 AM: Evaluate: task edges-pos-ontonotes, batch 148 (157): mcc: 0.9172, acc: 0.8695, precision: 0.9445, recall: 0.8939, f1: 0.9185, edges-pos-ontonotes_loss: 0.0099
09/16 05:41:18 AM: Updating LR scheduler:
09/16 05:41:18 AM: 	Best result seen so far for macro_avg: 0.919
09/16 05:41:18 AM: 	# validation passes without improvement: 2
09/16 05:41:18 AM: Ran out of early stopping patience. Stopping training.
09/16 05:41:18 AM: edges-pos-ontonotes_loss: training: 0.014070 validation: 0.009862
09/16 05:41:18 AM: macro_avg: validation: 0.918990
09/16 05:41:18 AM: micro_avg: validation: 0.000000
09/16 05:41:18 AM: edges-pos-ontonotes_mcc: training: 0.876678 validation: 0.917666
09/16 05:41:18 AM: edges-pos-ontonotes_acc: training: 0.802103 validation: 0.870557
09/16 05:41:18 AM: edges-pos-ontonotes_precision: training: 0.910554 validation: 0.944618
09/16 05:41:18 AM: edges-pos-ontonotes_recall: training: 0.848824 validation: 0.894716
09/16 05:41:18 AM: edges-pos-ontonotes_f1: training: 0.878606 validation: 0.918990
09/16 05:41:18 AM: Global learning rate: 2.5e-05
09/16 05:41:18 AM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:41:18 AM: Stopped training after 46 validation checks
09/16 05:41:18 AM: Trained edges-pos-ontonotes for 46000 batches or 13.318 epochs
09/16 05:41:18 AM: ***** VALIDATION RESULTS *****
09/16 05:41:18 AM: edges-pos-ontonotes_f1 (for best val pass 36): edges-pos-ontonotes_loss: 0.01003, macro_avg: 0.91923, micro_avg: 0.00000, edges-pos-ontonotes_mcc: 0.91788, edges-pos-ontonotes_acc: 0.87151, edges-pos-ontonotes_precision: 0.94372, edges-pos-ontonotes_recall: 0.89598, edges-pos-ontonotes_f1: 0.91923
09/16 05:41:18 AM: micro_avg (for best val pass 1): edges-pos-ontonotes_loss: 0.04512, macro_avg: 0.54095, micro_avg: 0.00000, edges-pos-ontonotes_mcc: 0.59069, edges-pos-ontonotes_acc: 0.37530, edges-pos-ontonotes_precision: 0.92883, edges-pos-ontonotes_recall: 0.38160, edges-pos-ontonotes_f1: 0.54095
09/16 05:41:18 AM: macro_avg (for best val pass 36): edges-pos-ontonotes_loss: 0.01003, macro_avg: 0.91923, micro_avg: 0.00000, edges-pos-ontonotes_mcc: 0.91788, edges-pos-ontonotes_acc: 0.87151, edges-pos-ontonotes_precision: 0.94372, edges-pos-ontonotes_recall: 0.89598, edges-pos-ontonotes_f1: 0.91923
09/16 05:41:18 AM: Evaluating...
09/16 05:41:18 AM: Loaded model state from ./experiments/pos-ontonotes-sts-b-top/run/edges-pos-ontonotes/model_state_target_train_val_36.best.th
09/16 05:41:18 AM: Evaluating on: edges-pos-ontonotes, split: val
09/16 05:41:48 AM: 	Task edges-pos-ontonotes: batch 156
09/16 05:42:18 AM: 	Task edges-pos-ontonotes: batch 282
09/16 05:42:48 AM: 	Task edges-pos-ontonotes: batch 460
09/16 05:42:51 AM: Task 'edges-pos-ontonotes': sorting predictions by 'idx'
09/16 05:42:51 AM: Finished evaluating on: edges-pos-ontonotes
09/16 05:42:51 AM: Task 'edges-pos-ontonotes': joining predictions with input split 'val'
09/16 05:43:03 AM: Task 'edges-pos-ontonotes': Wrote predictions to ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:43:03 AM: Wrote all preds for split 'val' to ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:43:03 AM: Evaluating on: edges-pos-ontonotes, split: test
09/16 05:43:34 AM: 	Task edges-pos-ontonotes: batch 146
09/16 05:44:04 AM: 	Task edges-pos-ontonotes: batch 249
09/16 05:44:21 AM: Task 'edges-pos-ontonotes': sorting predictions by 'idx'
09/16 05:44:21 AM: Finished evaluating on: edges-pos-ontonotes
09/16 05:44:21 AM: Task 'edges-pos-ontonotes': joining predictions with input split 'test'
09/16 05:44:30 AM: Task 'edges-pos-ontonotes': Wrote predictions to ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:44:30 AM: Wrote all preds for split 'test' to ./experiments/pos-ontonotes-sts-b-top/run
09/16 05:44:30 AM: Writing results for split 'val' to ./experiments/pos-ontonotes-sts-b-top/results.tsv
09/16 05:44:30 AM: micro_avg: 0.000, macro_avg: 0.921, edges-pos-ontonotes_mcc: 0.920, edges-pos-ontonotes_acc: 0.875, edges-pos-ontonotes_precision: 0.942, edges-pos-ontonotes_recall: 0.901, edges-pos-ontonotes_f1: 0.921
09/16 05:44:30 AM: Done!
