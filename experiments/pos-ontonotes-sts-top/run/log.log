<<<<<<< HEAD
09/16 12:22:32 PM: Git branch: master
09/16 12:22:32 PM: Git SHA: ce97551376ebcff91ec7c178ddad0ca53f8fcb03
09/16 12:22:33 PM: Parsed args: 
=======
09/16 09:39:17 AM: Git branch: master
09/16 09:39:17 AM: Git SHA: 0869c6f0712662a0adcfe16ed0072c1997d1c5da
09/16 09:39:17 AM: Parsed args: 
>>>>>>> c9d1f3d70352f2e7d47f7ef89b434d6d01abf5d2
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/pos-ontonotes-sts-top/",
  "exp_name": "experiments/pos-ontonotes-sts-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/pos-ontonotes-sts-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/sts",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/pos-ontonotes-sts-top__run",
  "run_dir": "./experiments/pos-ontonotes-sts-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-pos-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
<<<<<<< HEAD
09/16 12:22:33 PM: Saved config to ./experiments/pos-ontonotes-sts-top/run/params.conf
09/16 12:22:33 PM: Using random seed 1234
09/16 12:22:33 PM: Using GPU 0
09/16 12:22:33 PM: Loading tasks...
09/16 12:22:33 PM: Writing pre-preprocessed tasks to ./experiments/pos-ontonotes-sts-top/
09/16 12:22:33 PM: 	Creating task edges-pos-ontonotes from scratch.
09/16 12:22:54 PM: Read=110514, Skip=5298, Total=115812 from ./probing_data/edges/ontonotes/const/pos/train.json.retokenized.bert-base-uncased
09/16 12:22:54 PM: Read=15060, Skip=620, Total=15680 from ./probing_data/edges/ontonotes/const/pos/development.json.retokenized.bert-base-uncased
09/16 12:22:58 PM: Read=11462, Skip=755, Total=12217 from ./probing_data/edges/ontonotes/const/pos/test.json.retokenized.bert-base-uncased
09/16 12:23:10 PM: 	Task 'edges-pos-ontonotes': |train|=110514 |val|=15060 |test|=11462
09/16 12:23:10 PM: 	Finished loading tasks: edges-pos-ontonotes.
09/16 12:23:10 PM: 	Building vocab from scratch.
09/16 12:23:10 PM: 	Counting units for task edges-pos-ontonotes.
09/16 12:23:13 PM: 	Task 'edges-pos-ontonotes': adding vocab namespace 'edges-pos-ontonotes_labels'
09/16 12:23:14 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:23:14 PM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 12:23:14 PM: 	Saved vocab to ./experiments/pos-ontonotes-sts-top/vocab
09/16 12:23:14 PM: Loading token dictionary from ./experiments/pos-ontonotes-sts-top/vocab.
09/16 12:23:14 PM: 	Loaded vocab from ./experiments/pos-ontonotes-sts-top/vocab
09/16 12:23:14 PM: 	Vocab namespace bert_uncased: size 30524
09/16 12:23:14 PM: 	Vocab namespace tokens: size 24015
09/16 12:23:14 PM: 	Vocab namespace edges-pos-ontonotes_labels: size 48
09/16 12:23:14 PM: 	Vocab namespace chars: size 81
09/16 12:23:14 PM: 	Finished building vocab.
09/16 12:23:14 PM: 	Task edges-pos-ontonotes (train): Indexing from scratch.
09/16 12:23:45 PM: 	Task edges-pos-ontonotes (train): Saved 110514 instances to ./experiments/pos-ontonotes-sts-top/preproc/edges-pos-ontonotes__train_data
09/16 12:23:45 PM: 	Task edges-pos-ontonotes (val): Indexing from scratch.
09/16 12:23:49 PM: 	Task edges-pos-ontonotes (val): Saved 15060 instances to ./experiments/pos-ontonotes-sts-top/preproc/edges-pos-ontonotes__val_data
09/16 12:23:49 PM: 	Task edges-pos-ontonotes (test): Indexing from scratch.
09/16 12:23:52 PM: 	Task edges-pos-ontonotes (test): Saved 11462 instances to ./experiments/pos-ontonotes-sts-top/preproc/edges-pos-ontonotes__test_data
09/16 12:23:52 PM: 	Finished indexing tasks
09/16 12:23:52 PM: 	Creating trimmed target-only version of edges-pos-ontonotes train.
09/16 12:23:52 PM: 	  Training on 
09/16 12:23:52 PM: 	  Evaluating on edges-pos-ontonotes
09/16 12:23:52 PM: 	Finished loading tasks in 78.594s
09/16 12:23:52 PM: 	 Tasks: ['edges-pos-ontonotes']
09/16 12:23:52 PM: Building model...
09/16 12:23:52 PM: Using BERT model (bert-base-uncased).
09/16 12:23:52 PM: LOADING A FUNETUNED MODEL from: 
09/16 12:23:52 PM: models/sts
09/16 12:23:52 PM: loading configuration file models/sts/config.json
09/16 12:23:52 PM: Model config {
=======
09/16 09:39:17 AM: Saved config to ./experiments/pos-ontonotes-sts-top/run/params.conf
09/16 09:39:17 AM: Using random seed 1234
09/16 09:39:18 AM: Using GPU 0
09/16 09:39:18 AM: Loading tasks...
09/16 09:39:18 AM: Writing pre-preprocessed tasks to ./experiments/pos-ontonotes-sts-top/
09/16 09:39:18 AM: 	Creating task edges-pos-ontonotes from scratch.
09/16 09:39:37 AM: Read=110514, Skip=5298, Total=115812 from ./probing_data/edges/ontonotes/const/pos/train.json.retokenized.bert-base-uncased
09/16 09:39:38 AM: Read=15060, Skip=620, Total=15680 from ./probing_data/edges/ontonotes/const/pos/development.json.retokenized.bert-base-uncased
09/16 09:39:41 AM: Read=11462, Skip=755, Total=12217 from ./probing_data/edges/ontonotes/const/pos/test.json.retokenized.bert-base-uncased
09/16 09:39:53 AM: 	Task 'edges-pos-ontonotes': |train|=110514 |val|=15060 |test|=11462
09/16 09:39:53 AM: 	Finished loading tasks: edges-pos-ontonotes.
09/16 09:39:53 AM: 	Building vocab from scratch.
09/16 09:39:53 AM: 	Counting units for task edges-pos-ontonotes.
09/16 09:39:56 AM: 	Task 'edges-pos-ontonotes': adding vocab namespace 'edges-pos-ontonotes_labels'
09/16 09:39:57 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:39:57 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 09:39:57 AM: 	Saved vocab to ./experiments/pos-ontonotes-sts-top/vocab
09/16 09:39:57 AM: Loading token dictionary from ./experiments/pos-ontonotes-sts-top/vocab.
09/16 09:39:57 AM: 	Loaded vocab from ./experiments/pos-ontonotes-sts-top/vocab
09/16 09:39:57 AM: 	Vocab namespace bert_uncased: size 30524
09/16 09:39:57 AM: 	Vocab namespace tokens: size 24015
09/16 09:39:57 AM: 	Vocab namespace chars: size 81
09/16 09:39:57 AM: 	Vocab namespace edges-pos-ontonotes_labels: size 48
09/16 09:39:57 AM: 	Finished building vocab.
09/16 09:39:57 AM: 	Task edges-pos-ontonotes (train): Indexing from scratch.
09/16 09:40:41 AM: 	Task edges-pos-ontonotes (train): Saved 110514 instances to ./experiments/pos-ontonotes-sts-top/preproc/edges-pos-ontonotes__train_data
09/16 09:40:41 AM: 	Task edges-pos-ontonotes (val): Indexing from scratch.
09/16 09:40:47 AM: 	Task edges-pos-ontonotes (val): Saved 15060 instances to ./experiments/pos-ontonotes-sts-top/preproc/edges-pos-ontonotes__val_data
09/16 09:40:47 AM: 	Task edges-pos-ontonotes (test): Indexing from scratch.
09/16 09:40:51 AM: 	Task edges-pos-ontonotes (test): Saved 11462 instances to ./experiments/pos-ontonotes-sts-top/preproc/edges-pos-ontonotes__test_data
09/16 09:40:51 AM: 	Finished indexing tasks
09/16 09:40:51 AM: 	Creating trimmed target-only version of edges-pos-ontonotes train.
09/16 09:40:51 AM: 	  Training on 
09/16 09:40:51 AM: 	  Evaluating on edges-pos-ontonotes
09/16 09:40:51 AM: 	Finished loading tasks in 93.758s
09/16 09:40:51 AM: 	 Tasks: ['edges-pos-ontonotes']
09/16 09:40:51 AM: Building model...
09/16 09:40:51 AM: Using BERT model (bert-base-uncased).
09/16 09:40:51 AM: LOADING A FUNETUNED MODEL from: 
09/16 09:40:51 AM: models/sts
09/16 09:40:51 AM: loading configuration file models/sts/config.json
09/16 09:40:51 AM: Model config {
>>>>>>> c9d1f3d70352f2e7d47f7ef89b434d6d01abf5d2
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "sts-b",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

<<<<<<< HEAD
09/16 12:23:52 PM: loading weights file models/sts/pytorch_model.bin
09/16 12:23:55 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp9kpfsccr
09/16 12:23:57 PM: copying /tmp/tmp9kpfsccr to cache at ./experiments/pos-ontonotes-sts-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:23:57 PM: creating metadata file for ./experiments/pos-ontonotes-sts-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:23:57 PM: removing temp file /tmp/tmp9kpfsccr
09/16 12:23:57 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/pos-ontonotes-sts-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:23:57 PM: Initializing parameters
09/16 12:23:57 PM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 12:23:57 PM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 12:23:57 PM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 12:23:57 PM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 12:23:57 PM:    _text_field_embedder.model.pooler.dense.bias
09/16 12:23:57 PM:    _text_field_embedder.model.pooler.dense.weight
09/16 12:23:57 PM: 	Task 'edges-pos-ontonotes' params: {
=======
09/16 09:40:51 AM: loading weights file models/sts/pytorch_model.bin
09/16 09:40:56 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp201m373h
09/16 09:41:00 AM: copying /tmp/tmp201m373h to cache at ./experiments/pos-ontonotes-sts-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:41:00 AM: creating metadata file for ./experiments/pos-ontonotes-sts-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:41:00 AM: removing temp file /tmp/tmp201m373h
09/16 09:41:00 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/pos-ontonotes-sts-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:41:00 AM: Initializing parameters
09/16 09:41:00 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 09:41:00 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 09:41:00 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 09:41:00 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 09:41:00 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 09:41:00 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 09:41:00 AM: 	Task 'edges-pos-ontonotes' params: {
>>>>>>> c9d1f3d70352f2e7d47f7ef89b434d6d01abf5d2
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-pos-ontonotes"
}
<<<<<<< HEAD
09/16 12:24:02 PM: Model specification:
09/16 12:24:02 PM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-pos-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=48, bias=True)
    )
  )
)
09/16 12:24:02 PM: Model parameters:
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:24:02 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:24:02 PM: 	edges-pos-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 12:24:02 PM: 	edges-pos-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 12:24:02 PM: 	edges-pos-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 24576 with torch.Size([48, 512])
09/16 12:24:02 PM: 	edges-pos-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 48 with torch.Size([48])
09/16 12:24:02 PM: Total number of parameters: 109703728 (1.09704e+08)
09/16 12:24:02 PM: Number of trainable parameters: 221488 (221488)
09/16 12:24:02 PM: Finished building model in 9.508s
09/16 12:24:02 PM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-pos-ontonotes 

09/16 12:25:12 PM: patience = 9
09/16 12:25:12 PM: val_interval = 1000
09/16 12:25:12 PM: max_vals = 250
09/16 12:25:12 PM: cuda_device = 0
09/16 12:25:12 PM: grad_norm = 5.0
09/16 12:25:12 PM: grad_clipping = None
09/16 12:25:12 PM: lr_decay = 0.99
09/16 12:25:12 PM: min_lr = 1e-06
09/16 12:25:12 PM: keep_all_checkpoints = 0
09/16 12:25:12 PM: val_data_limit = 5000
09/16 12:25:12 PM: max_epochs = -1
09/16 12:25:12 PM: dec_val_scale = 250
09/16 12:25:12 PM: training_data_fraction = 1
09/16 12:25:12 PM: type = adam
09/16 12:25:12 PM: parameter_groups = None
09/16 12:25:12 PM: Number of trainable parameters: 221488
09/16 12:25:12 PM: infer_type_and_cast = True
09/16 12:25:12 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:25:12 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:25:12 PM: lr = 0.0001
09/16 12:25:12 PM: amsgrad = True
09/16 12:25:12 PM: type = reduce_on_plateau
09/16 12:25:12 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:25:12 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:25:12 PM: mode = max
09/16 12:25:12 PM: factor = 0.5
09/16 12:25:12 PM: patience = 3
09/16 12:25:12 PM: threshold = 0.0001
09/16 12:25:12 PM: threshold_mode = abs
09/16 12:25:12 PM: verbose = True
09/16 12:25:12 PM: type = adam
09/16 12:25:12 PM: parameter_groups = None
09/16 12:25:12 PM: Number of trainable parameters: 221488
09/16 12:25:12 PM: infer_type_and_cast = True
09/16 12:25:12 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:25:12 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:25:12 PM: lr = 0.0001
09/16 12:25:12 PM: amsgrad = True
09/16 12:25:12 PM: type = reduce_on_plateau
09/16 12:25:12 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:25:12 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:25:12 PM: mode = max
09/16 12:25:12 PM: factor = 0.5
09/16 12:25:12 PM: patience = 3
09/16 12:25:12 PM: threshold = 0.0001
09/16 12:25:12 PM: threshold_mode = abs
09/16 12:25:12 PM: verbose = True
09/16 12:25:12 PM: Starting training without restoring from a checkpoint.
09/16 12:25:12 PM: Training examples per task, before any subsampling: {'edges-pos-ontonotes': 110514}
09/16 12:25:12 PM: Beginning training with stopping criteria based on metric: edges-pos-ontonotes_f1
09/16 12:25:22 PM: Update 46: task edges-pos-ontonotes, batch 46 (46): mcc: 0.0122, acc: 0.0024, precision: 0.0255, recall: 0.1488, f1: 0.0436, edges-pos-ontonotes_loss: 0.4246
09/16 12:25:32 PM: Update 118: task edges-pos-ontonotes, batch 118 (118): mcc: 0.0077, acc: 0.0010, precision: 0.0255, recall: 0.0638, f1: 0.0365, edges-pos-ontonotes_loss: 0.2276
09/16 12:25:43 PM: Update 199: task edges-pos-ontonotes, batch 199 (199): mcc: 0.0082, acc: 0.0035, precision: 0.0274, recall: 0.0406, f1: 0.0327, edges-pos-ontonotes_loss: 0.1680
09/16 12:25:53 PM: Update 263: task edges-pos-ontonotes, batch 263 (263): mcc: 0.0128, acc: 0.0088, precision: 0.0325, recall: 0.0378, f1: 0.0349, edges-pos-ontonotes_loss: 0.1457
09/16 12:26:03 PM: Update 317: task edges-pos-ontonotes, batch 317 (317): mcc: 0.0202, acc: 0.0156, precision: 0.0410, recall: 0.0394, f1: 0.0402, edges-pos-ontonotes_loss: 0.1335
09/16 12:26:13 PM: Update 383: task edges-pos-ontonotes, batch 383 (383): mcc: 0.0248, acc: 0.0185, precision: 0.0488, recall: 0.0370, f1: 0.0421, edges-pos-ontonotes_loss: 0.1234
09/16 12:26:23 PM: Update 435: task edges-pos-ontonotes, batch 435 (435): mcc: 0.0309, acc: 0.0224, precision: 0.0581, recall: 0.0386, f1: 0.0463, edges-pos-ontonotes_loss: 0.1170
09/16 12:26:33 PM: Update 492: task edges-pos-ontonotes, batch 492 (492): mcc: 0.0389, acc: 0.0270, precision: 0.0710, recall: 0.0413, f1: 0.0522, edges-pos-ontonotes_loss: 0.1112
09/16 12:26:43 PM: Update 551: task edges-pos-ontonotes, batch 551 (551): mcc: 0.0503, acc: 0.0336, precision: 0.0896, recall: 0.0464, f1: 0.0611, edges-pos-ontonotes_loss: 0.1062
09/16 12:26:53 PM: Update 603: task edges-pos-ontonotes, batch 603 (603): mcc: 0.0629, acc: 0.0410, precision: 0.1102, recall: 0.0529, f1: 0.0715, edges-pos-ontonotes_loss: 0.1023
09/16 12:27:03 PM: Update 642: task edges-pos-ontonotes, batch 642 (642): mcc: 0.0771, acc: 0.0492, precision: 0.1335, recall: 0.0607, f1: 0.0834, edges-pos-ontonotes_loss: 0.0998
09/16 12:27:13 PM: Update 693: task edges-pos-ontonotes, batch 693 (693): mcc: 0.1018, acc: 0.0634, precision: 0.1746, recall: 0.0742, f1: 0.1042, edges-pos-ontonotes_loss: 0.0968
09/16 12:27:23 PM: Update 731: task edges-pos-ontonotes, batch 731 (731): mcc: 0.1192, acc: 0.0734, precision: 0.2040, recall: 0.0838, f1: 0.1188, edges-pos-ontonotes_loss: 0.0947
09/16 12:27:34 PM: Update 770: task edges-pos-ontonotes, batch 770 (770): mcc: 0.1354, acc: 0.0827, precision: 0.2312, recall: 0.0930, f1: 0.1326, edges-pos-ontonotes_loss: 0.0928
09/16 12:27:44 PM: Update 822: task edges-pos-ontonotes, batch 822 (822): mcc: 0.1589, acc: 0.0963, precision: 0.2706, recall: 0.1063, f1: 0.1527, edges-pos-ontonotes_loss: 0.0903
09/16 12:27:54 PM: Update 865: task edges-pos-ontonotes, batch 865 (865): mcc: 0.1752, acc: 0.1059, precision: 0.2976, recall: 0.1159, f1: 0.1668, edges-pos-ontonotes_loss: 0.0885
09/16 12:28:04 PM: Update 901: task edges-pos-ontonotes, batch 901 (901): mcc: 0.1932, acc: 0.1167, precision: 0.3271, recall: 0.1265, f1: 0.1824, edges-pos-ontonotes_loss: 0.0869
09/16 12:28:15 PM: Update 942: task edges-pos-ontonotes, batch 942 (942): mcc: 0.2129, acc: 0.1286, precision: 0.3588, recall: 0.1383, f1: 0.1996, edges-pos-ontonotes_loss: 0.0853
09/16 12:28:25 PM: Update 994: task edges-pos-ontonotes, batch 994 (994): mcc: 0.2355, acc: 0.1424, precision: 0.3950, recall: 0.1520, f1: 0.2196, edges-pos-ontonotes_loss: 0.0833
09/16 12:28:26 PM: ***** Step 1000 / Validation 1 *****
09/16 12:28:26 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:28:26 PM: Validating...
09/16 12:28:35 PM: Evaluate: task edges-pos-ontonotes, batch 45 (157): mcc: 0.5067, acc: 0.2718, precision: 0.9512, recall: 0.2746, f1: 0.4262, edges-pos-ontonotes_loss: 0.0495
09/16 12:28:45 PM: Evaluate: task edges-pos-ontonotes, batch 92 (157): mcc: 0.5601, acc: 0.3332, precision: 0.9459, recall: 0.3370, f1: 0.4970, edges-pos-ontonotes_loss: 0.0466
09/16 12:28:55 PM: Evaluate: task edges-pos-ontonotes, batch 133 (157): mcc: 0.5864, acc: 0.3700, precision: 0.9290, recall: 0.3761, f1: 0.5354, edges-pos-ontonotes_loss: 0.0454
09/16 12:29:00 PM: Best result seen so far for edges-pos-ontonotes.
09/16 12:29:00 PM: Best result seen so far for micro.
09/16 12:29:00 PM: Best result seen so far for macro.
09/16 12:29:00 PM: Updating LR scheduler:
09/16 12:29:00 PM: 	Best result seen so far for macro_avg: 0.541
09/16 12:29:00 PM: 	# validation passes without improvement: 0
09/16 12:29:00 PM: edges-pos-ontonotes_loss: training: 0.083116 validation: 0.045122
09/16 12:29:00 PM: macro_avg: validation: 0.540954
09/16 12:29:00 PM: micro_avg: validation: 0.000000
09/16 12:29:00 PM: edges-pos-ontonotes_mcc: training: 0.238055 validation: 0.590688
09/16 12:29:00 PM: edges-pos-ontonotes_acc: training: 0.143936 validation: 0.375303
09/16 12:29:00 PM: edges-pos-ontonotes_precision: training: 0.398862 validation: 0.928831
09/16 12:29:00 PM: edges-pos-ontonotes_recall: training: 0.153633 validation: 0.381599
09/16 12:29:00 PM: edges-pos-ontonotes_f1: training: 0.221824 validation: 0.540954
09/16 12:29:00 PM: Global learning rate: 0.0001
09/16 12:29:00 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 12:29:05 PM: Update 1026: task edges-pos-ontonotes, batch 26 (1026): mcc: 0.5656, acc: 0.3503, precision: 0.9050, recall: 0.3596, f1: 0.5147, edges-pos-ontonotes_loss: 0.0469
09/16 12:29:15 PM: Update 1062: task edges-pos-ontonotes, batch 62 (1062): mcc: 0.5771, acc: 0.3642, precision: 0.9063, recall: 0.3737, f1: 0.5292, edges-pos-ontonotes_loss: 0.0460
09/16 12:29:25 PM: Update 1109: task edges-pos-ontonotes, batch 109 (1109): mcc: 0.5894, acc: 0.3791, precision: 0.9072, recall: 0.3893, f1: 0.5448, edges-pos-ontonotes_loss: 0.0449
09/16 12:29:35 PM: Update 1162: task edges-pos-ontonotes, batch 162 (1162): mcc: 0.5986, acc: 0.3909, precision: 0.9076, recall: 0.4013, f1: 0.5565, edges-pos-ontonotes_loss: 0.0440
09/16 12:29:46 PM: Update 1199: task edges-pos-ontonotes, batch 199 (1199): mcc: 0.6052, acc: 0.3991, precision: 0.9086, recall: 0.4096, f1: 0.5646, edges-pos-ontonotes_loss: 0.0435
09/16 12:29:56 PM: Update 1251: task edges-pos-ontonotes, batch 251 (1251): mcc: 0.6142, acc: 0.4107, precision: 0.9092, recall: 0.4214, f1: 0.5759, edges-pos-ontonotes_loss: 0.0427
09/16 12:30:08 PM: Update 1253: task edges-pos-ontonotes, batch 253 (1253): mcc: 0.6142, acc: 0.4108, precision: 0.9090, recall: 0.4215, f1: 0.5760, edges-pos-ontonotes_loss: 0.0427
09/16 12:30:18 PM: Update 1310: task edges-pos-ontonotes, batch 310 (1310): mcc: 0.6209, acc: 0.4195, precision: 0.9095, recall: 0.4305, f1: 0.5844, edges-pos-ontonotes_loss: 0.0420
09/16 12:30:28 PM: Update 1366: task edges-pos-ontonotes, batch 366 (1366): mcc: 0.6282, acc: 0.4290, precision: 0.9101, recall: 0.4403, f1: 0.5934, edges-pos-ontonotes_loss: 0.0413
09/16 12:30:39 PM: Update 1422: task edges-pos-ontonotes, batch 422 (1422): mcc: 0.6356, acc: 0.4387, precision: 0.9104, recall: 0.4504, f1: 0.6027, edges-pos-ontonotes_loss: 0.0405
09/16 12:30:49 PM: Update 1474: task edges-pos-ontonotes, batch 474 (1474): mcc: 0.6428, acc: 0.4483, precision: 0.9105, recall: 0.4604, f1: 0.6116, edges-pos-ontonotes_loss: 0.0400
09/16 12:30:59 PM: Update 1526: task edges-pos-ontonotes, batch 526 (1526): mcc: 0.6491, acc: 0.4568, precision: 0.9109, recall: 0.4693, f1: 0.6194, edges-pos-ontonotes_loss: 0.0394
09/16 12:31:09 PM: Update 1571: task edges-pos-ontonotes, batch 571 (1571): mcc: 0.6537, acc: 0.4631, precision: 0.9109, recall: 0.4758, f1: 0.6251, edges-pos-ontonotes_loss: 0.0389
09/16 12:31:19 PM: Update 1609: task edges-pos-ontonotes, batch 609 (1609): mcc: 0.6575, acc: 0.4682, precision: 0.9111, recall: 0.4812, f1: 0.6298, edges-pos-ontonotes_loss: 0.0385
09/16 12:31:29 PM: Update 1658: task edges-pos-ontonotes, batch 658 (1658): mcc: 0.6630, acc: 0.4759, precision: 0.9109, recall: 0.4894, f1: 0.6367, edges-pos-ontonotes_loss: 0.0380
09/16 12:31:40 PM: Update 1713: task edges-pos-ontonotes, batch 713 (1713): mcc: 0.6686, acc: 0.4837, precision: 0.9108, recall: 0.4976, f1: 0.6436, edges-pos-ontonotes_loss: 0.0374
09/16 12:31:50 PM: Update 1768: task edges-pos-ontonotes, batch 768 (1768): mcc: 0.6737, acc: 0.4908, precision: 0.9106, recall: 0.5053, f1: 0.6500, edges-pos-ontonotes_loss: 0.0369
09/16 12:32:00 PM: Update 1828: task edges-pos-ontonotes, batch 828 (1828): mcc: 0.6787, acc: 0.4978, precision: 0.9105, recall: 0.5127, f1: 0.6560, edges-pos-ontonotes_loss: 0.0365
09/16 12:32:12 PM: Update 1879: task edges-pos-ontonotes, batch 879 (1879): mcc: 0.6835, acc: 0.5047, precision: 0.9103, recall: 0.5201, f1: 0.6620, edges-pos-ontonotes_loss: 0.0360
09/16 12:32:22 PM: Update 1926: task edges-pos-ontonotes, batch 926 (1926): mcc: 0.6871, acc: 0.5099, precision: 0.9098, recall: 0.5258, f1: 0.6664, edges-pos-ontonotes_loss: 0.0357
09/16 12:32:32 PM: Update 1994: task edges-pos-ontonotes, batch 994 (1994): mcc: 0.6909, acc: 0.5156, precision: 0.9092, recall: 0.5320, f1: 0.6712, edges-pos-ontonotes_loss: 0.0352
09/16 12:32:32 PM: ***** Step 2000 / Validation 2 *****
09/16 12:32:32 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:32:32 PM: Validating...
09/16 12:32:42 PM: Evaluate: task edges-pos-ontonotes, batch 66 (157): mcc: 0.7396, acc: 0.5908, precision: 0.9160, recall: 0.6039, f1: 0.7279, edges-pos-ontonotes_loss: 0.0318
09/16 12:32:52 PM: Evaluate: task edges-pos-ontonotes, batch 118 (157): mcc: 0.7711, acc: 0.6391, precision: 0.9119, recall: 0.6585, f1: 0.7648, edges-pos-ontonotes_loss: 0.0291
09/16 12:33:01 PM: Best result seen so far for edges-pos-ontonotes.
09/16 12:33:01 PM: Best result seen so far for macro.
09/16 12:33:01 PM: Updating LR scheduler:
09/16 12:33:01 PM: 	Best result seen so far for macro_avg: 0.779
09/16 12:33:01 PM: 	# validation passes without improvement: 0
09/16 12:33:01 PM: edges-pos-ontonotes_loss: training: 0.035201 validation: 0.027865
09/16 12:33:01 PM: macro_avg: validation: 0.778787
09/16 12:33:01 PM: micro_avg: validation: 0.000000
09/16 12:33:01 PM: edges-pos-ontonotes_mcc: training: 0.691180 validation: 0.783251
09/16 12:33:01 PM: edges-pos-ontonotes_acc: training: 0.515858 validation: 0.658084
09/16 12:33:01 PM: edges-pos-ontonotes_precision: training: 0.909249 validation: 0.909942
09/16 12:33:01 PM: edges-pos-ontonotes_recall: training: 0.532305 validation: 0.680678
09/16 12:33:01 PM: edges-pos-ontonotes_f1: training: 0.671494 validation: 0.778787
09/16 12:33:01 PM: Global learning rate: 0.0001
09/16 12:33:01 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 12:33:02 PM: Update 2009: task edges-pos-ontonotes, batch 9 (2009): mcc: 0.7578, acc: 0.6228, precision: 0.9022, recall: 0.6434, f1: 0.7511, edges-pos-ontonotes_loss: 0.0289
09/16 12:33:12 PM: Update 2082: task edges-pos-ontonotes, batch 82 (2082): mcc: 0.7653, acc: 0.6272, precision: 0.9083, recall: 0.6515, f1: 0.7587, edges-pos-ontonotes_loss: 0.0283
09/16 12:33:22 PM: Update 2143: task edges-pos-ontonotes, batch 143 (2143): mcc: 0.7692, acc: 0.6336, precision: 0.9054, recall: 0.6602, f1: 0.7636, edges-pos-ontonotes_loss: 0.0278
09/16 12:33:33 PM: Update 2204: task edges-pos-ontonotes, batch 204 (2204): mcc: 0.7713, acc: 0.6366, precision: 0.9060, recall: 0.6633, f1: 0.7658, edges-pos-ontonotes_loss: 0.0275
09/16 12:33:43 PM: Update 2298: task edges-pos-ontonotes, batch 298 (2298): mcc: 0.7740, acc: 0.6392, precision: 0.9100, recall: 0.6649, f1: 0.7684, edges-pos-ontonotes_loss: 0.0269
09/16 12:33:53 PM: Update 2390: task edges-pos-ontonotes, batch 390 (2390): mcc: 0.7779, acc: 0.6442, precision: 0.9125, recall: 0.6696, f1: 0.7724, edges-pos-ontonotes_loss: 0.0263
09/16 12:34:03 PM: Update 2476: task edges-pos-ontonotes, batch 476 (2476): mcc: 0.7822, acc: 0.6498, precision: 0.9148, recall: 0.6752, f1: 0.7769, edges-pos-ontonotes_loss: 0.0257
09/16 12:34:13 PM: Update 2563: task edges-pos-ontonotes, batch 563 (2563): mcc: 0.7846, acc: 0.6532, precision: 0.9159, recall: 0.6785, f1: 0.7795, edges-pos-ontonotes_loss: 0.0257
09/16 12:34:23 PM: Update 2643: task edges-pos-ontonotes, batch 643 (2643): mcc: 0.7870, acc: 0.6566, precision: 0.9174, recall: 0.6815, f1: 0.7820, edges-pos-ontonotes_loss: 0.0256
09/16 12:34:33 PM: Update 2756: task edges-pos-ontonotes, batch 756 (2756): mcc: 0.7902, acc: 0.6612, precision: 0.9184, recall: 0.6860, f1: 0.7854, edges-pos-ontonotes_loss: 0.0253
09/16 12:34:43 PM: Update 2851: task edges-pos-ontonotes, batch 851 (2851): mcc: 0.7912, acc: 0.6630, precision: 0.9183, recall: 0.6880, f1: 0.7866, edges-pos-ontonotes_loss: 0.0252
09/16 12:34:53 PM: Update 2975: task edges-pos-ontonotes, batch 975 (2975): mcc: 0.7900, acc: 0.6613, precision: 0.9173, recall: 0.6867, f1: 0.7854, edges-pos-ontonotes_loss: 0.0252
09/16 12:34:55 PM: ***** Step 3000 / Validation 3 *****
09/16 12:34:55 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:34:55 PM: Validating...
09/16 12:35:03 PM: Evaluate: task edges-pos-ontonotes, batch 39 (157): mcc: 0.8075, acc: 0.6938, precision: 0.9120, recall: 0.7211, f1: 0.8054, edges-pos-ontonotes_loss: 0.0231
09/16 12:35:13 PM: Evaluate: task edges-pos-ontonotes, batch 95 (157): mcc: 0.8258, acc: 0.7247, precision: 0.9055, recall: 0.7591, f1: 0.8259, edges-pos-ontonotes_loss: 0.0217
09/16 12:35:23 PM: Evaluate: task edges-pos-ontonotes, batch 141 (157): mcc: 0.8299, acc: 0.7324, precision: 0.8930, recall: 0.7774, f1: 0.8312, edges-pos-ontonotes_loss: 0.0218
09/16 12:35:27 PM: Best result seen so far for edges-pos-ontonotes.
09/16 12:35:27 PM: Best result seen so far for macro.
09/16 12:35:27 PM: Updating LR scheduler:
09/16 12:35:27 PM: 	Best result seen so far for macro_avg: 0.832
09/16 12:35:27 PM: 	# validation passes without improvement: 0
09/16 12:35:27 PM: edges-pos-ontonotes_loss: training: 0.025215 validation: 0.021723
09/16 12:35:27 PM: macro_avg: validation: 0.832484
09/16 12:35:27 PM: micro_avg: validation: 0.000000
09/16 12:35:27 PM: edges-pos-ontonotes_mcc: training: 0.789768 validation: 0.831127
09/16 12:35:27 PM: edges-pos-ontonotes_acc: training: 0.661002 validation: 0.734743
09/16 12:35:27 PM: edges-pos-ontonotes_precision: training: 0.917022 validation: 0.892592
09/16 12:35:27 PM: edges-pos-ontonotes_recall: training: 0.686452 validation: 0.779961
09/16 12:35:27 PM: edges-pos-ontonotes_f1: training: 0.785160 validation: 0.832484
09/16 12:35:27 PM: Global learning rate: 0.0001
09/16 12:35:27 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 12:35:33 PM: Update 3075: task edges-pos-ontonotes, batch 75 (3075): mcc: 0.7843, acc: 0.6563, precision: 0.9011, recall: 0.6892, f1: 0.7810, edges-pos-ontonotes_loss: 0.0246
09/16 12:35:43 PM: Update 3137: task edges-pos-ontonotes, batch 137 (3137): mcc: 0.7865, acc: 0.6605, precision: 0.8953, recall: 0.6976, f1: 0.7842, edges-pos-ontonotes_loss: 0.0243
09/16 12:35:54 PM: Update 3182: task edges-pos-ontonotes, batch 182 (3182): mcc: 0.7872, acc: 0.6627, precision: 0.8916, recall: 0.7018, f1: 0.7854, edges-pos-ontonotes_loss: 0.0247
09/16 12:36:04 PM: Update 3231: task edges-pos-ontonotes, batch 231 (3231): mcc: 0.7860, acc: 0.6616, precision: 0.8898, recall: 0.7012, f1: 0.7843, edges-pos-ontonotes_loss: 0.0251
09/16 12:36:14 PM: Update 3282: task edges-pos-ontonotes, batch 282 (3282): mcc: 0.7872, acc: 0.6638, precision: 0.8895, recall: 0.7034, f1: 0.7856, edges-pos-ontonotes_loss: 0.0252
09/16 12:36:24 PM: Update 3329: task edges-pos-ontonotes, batch 329 (3329): mcc: 0.7876, acc: 0.6647, precision: 0.8891, recall: 0.7044, f1: 0.7861, edges-pos-ontonotes_loss: 0.0254
09/16 12:36:34 PM: Update 3389: task edges-pos-ontonotes, batch 389 (3389): mcc: 0.7885, acc: 0.6662, precision: 0.8902, recall: 0.7053, f1: 0.7870, edges-pos-ontonotes_loss: 0.0252
09/16 12:36:44 PM: Update 3446: task edges-pos-ontonotes, batch 446 (3446): mcc: 0.7892, acc: 0.6673, precision: 0.8906, recall: 0.7062, f1: 0.7877, edges-pos-ontonotes_loss: 0.0251
09/16 12:36:58 PM: Update 3461: task edges-pos-ontonotes, batch 461 (3461): mcc: 0.7891, acc: 0.6671, precision: 0.8907, recall: 0.7059, f1: 0.7876, edges-pos-ontonotes_loss: 0.0251
09/16 12:37:08 PM: Update 3534: task edges-pos-ontonotes, batch 534 (3534): mcc: 0.7893, acc: 0.6669, precision: 0.8928, recall: 0.7045, f1: 0.7875, edges-pos-ontonotes_loss: 0.0249
09/16 12:37:18 PM: Update 3626: task edges-pos-ontonotes, batch 626 (3626): mcc: 0.7905, acc: 0.6682, precision: 0.8948, recall: 0.7050, f1: 0.7886, edges-pos-ontonotes_loss: 0.0246
09/16 12:37:28 PM: Update 3712: task edges-pos-ontonotes, batch 712 (3712): mcc: 0.7917, acc: 0.6697, precision: 0.8960, recall: 0.7061, f1: 0.7898, edges-pos-ontonotes_loss: 0.0242
09/16 12:37:38 PM: Update 3774: task edges-pos-ontonotes, batch 774 (3774): mcc: 0.7929, acc: 0.6714, precision: 0.8968, recall: 0.7076, f1: 0.7911, edges-pos-ontonotes_loss: 0.0239
09/16 12:37:49 PM: Update 3838: task edges-pos-ontonotes, batch 838 (3838): mcc: 0.7952, acc: 0.6751, precision: 0.8967, recall: 0.7118, f1: 0.7936, edges-pos-ontonotes_loss: 0.0238
09/16 12:37:59 PM: Update 3895: task edges-pos-ontonotes, batch 895 (3895): mcc: 0.7973, acc: 0.6783, precision: 0.8970, recall: 0.7153, f1: 0.7959, edges-pos-ontonotes_loss: 0.0236
09/16 12:38:09 PM: Update 3976: task edges-pos-ontonotes, batch 976 (3976): mcc: 0.7993, acc: 0.6813, precision: 0.8974, recall: 0.7185, f1: 0.7980, edges-pos-ontonotes_loss: 0.0233
09/16 12:38:12 PM: ***** Step 4000 / Validation 4 *****
09/16 12:38:12 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:38:12 PM: Validating...
09/16 12:38:19 PM: Evaluate: task edges-pos-ontonotes, batch 48 (157): mcc: 0.8479, acc: 0.7545, precision: 0.9358, recall: 0.7733, f1: 0.8468, edges-pos-ontonotes_loss: 0.0182
09/16 12:38:29 PM: Evaluate: task edges-pos-ontonotes, batch 107 (157): mcc: 0.8603, acc: 0.7759, precision: 0.9283, recall: 0.8022, f1: 0.8607, edges-pos-ontonotes_loss: 0.0172
09/16 12:38:39 PM: Evaluate: task edges-pos-ontonotes, batch 152 (157): mcc: 0.8591, acc: 0.7763, precision: 0.9191, recall: 0.8081, f1: 0.8601, edges-pos-ontonotes_loss: 0.0175
09/16 12:38:40 PM: Best result seen so far for edges-pos-ontonotes.
09/16 12:38:40 PM: Best result seen so far for macro.
09/16 12:38:40 PM: Updating LR scheduler:
09/16 12:38:40 PM: 	Best result seen so far for macro_avg: 0.860
09/16 12:38:40 PM: 	# validation passes without improvement: 0
09/16 12:38:40 PM: edges-pos-ontonotes_loss: training: 0.023207 validation: 0.017472
09/16 12:38:40 PM: macro_avg: validation: 0.860186
09/16 12:38:40 PM: micro_avg: validation: 0.000000
09/16 12:38:40 PM: edges-pos-ontonotes_mcc: training: 0.799741 validation: 0.859237
09/16 12:38:40 PM: edges-pos-ontonotes_acc: training: 0.682009 validation: 0.776638
09/16 12:38:40 PM: edges-pos-ontonotes_precision: training: 0.897423 validation: 0.918984
09/16 12:38:40 PM: edges-pos-ontonotes_recall: training: 0.719197 validation: 0.808460
09/16 12:38:40 PM: edges-pos-ontonotes_f1: training: 0.798486 validation: 0.860186
09/16 12:38:40 PM: Global learning rate: 0.0001
09/16 12:38:40 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 12:38:49 PM: Update 4061: task edges-pos-ontonotes, batch 61 (4061): mcc: 0.8229, acc: 0.7176, precision: 0.9021, recall: 0.7568, f1: 0.8231, edges-pos-ontonotes_loss: 0.0204
09/16 12:39:00 PM: Update 4092: task edges-pos-ontonotes, batch 92 (4092): mcc: 0.8221, acc: 0.7171, precision: 0.8991, recall: 0.7578, f1: 0.8224, edges-pos-ontonotes_loss: 0.0204
09/16 12:39:10 PM: Update 4137: task edges-pos-ontonotes, batch 137 (4137): mcc: 0.8192, acc: 0.7145, precision: 0.8956, recall: 0.7556, f1: 0.8196, edges-pos-ontonotes_loss: 0.0212
09/16 12:39:20 PM: Update 4193: task edges-pos-ontonotes, batch 193 (4193): mcc: 0.8183, acc: 0.7137, precision: 0.8947, recall: 0.7546, f1: 0.8187, edges-pos-ontonotes_loss: 0.0213
09/16 12:39:30 PM: Update 4253: task edges-pos-ontonotes, batch 253 (4253): mcc: 0.8192, acc: 0.7148, precision: 0.8955, recall: 0.7556, f1: 0.8196, edges-pos-ontonotes_loss: 0.0213
09/16 12:39:40 PM: Update 4309: task edges-pos-ontonotes, batch 309 (4309): mcc: 0.8193, acc: 0.7151, precision: 0.8954, recall: 0.7559, f1: 0.8198, edges-pos-ontonotes_loss: 0.0213
09/16 12:39:50 PM: Update 4366: task edges-pos-ontonotes, batch 366 (4366): mcc: 0.8201, acc: 0.7162, precision: 0.8961, recall: 0.7567, f1: 0.8205, edges-pos-ontonotes_loss: 0.0212
09/16 12:40:02 PM: Update 4400: task edges-pos-ontonotes, batch 400 (4400): mcc: 0.8202, acc: 0.7164, precision: 0.8962, recall: 0.7568, f1: 0.8206, edges-pos-ontonotes_loss: 0.0212
09/16 12:40:12 PM: Update 4452: task edges-pos-ontonotes, batch 452 (4452): mcc: 0.8205, acc: 0.7166, precision: 0.8956, recall: 0.7580, f1: 0.8211, edges-pos-ontonotes_loss: 0.0211
09/16 12:40:22 PM: Update 4507: task edges-pos-ontonotes, batch 507 (4507): mcc: 0.8216, acc: 0.7184, precision: 0.8961, recall: 0.7595, f1: 0.8222, edges-pos-ontonotes_loss: 0.0210
09/16 12:40:32 PM: Update 4536: task edges-pos-ontonotes, batch 536 (4536): mcc: 0.8221, acc: 0.7191, precision: 0.8963, recall: 0.7603, f1: 0.8227, edges-pos-ontonotes_loss: 0.0210
09/16 12:40:42 PM: Update 4569: task edges-pos-ontonotes, batch 569 (4569): mcc: 0.8226, acc: 0.7201, precision: 0.8965, recall: 0.7611, f1: 0.8232, edges-pos-ontonotes_loss: 0.0210
09/16 12:40:52 PM: Update 4623: task edges-pos-ontonotes, batch 623 (4623): mcc: 0.8237, acc: 0.7217, precision: 0.8973, recall: 0.7623, f1: 0.8243, edges-pos-ontonotes_loss: 0.0208
09/16 12:41:02 PM: Update 4668: task edges-pos-ontonotes, batch 668 (4668): mcc: 0.8248, acc: 0.7233, precision: 0.8980, recall: 0.7637, f1: 0.8254, edges-pos-ontonotes_loss: 0.0207
09/16 12:41:12 PM: Update 4709: task edges-pos-ontonotes, batch 709 (4709): mcc: 0.8253, acc: 0.7241, precision: 0.8985, recall: 0.7643, f1: 0.8259, edges-pos-ontonotes_loss: 0.0206
09/16 12:41:23 PM: Update 4748: task edges-pos-ontonotes, batch 748 (4748): mcc: 0.8257, acc: 0.7248, precision: 0.8987, recall: 0.7647, f1: 0.8263, edges-pos-ontonotes_loss: 0.0206
09/16 12:41:33 PM: Update 4805: task edges-pos-ontonotes, batch 805 (4805): mcc: 0.8266, acc: 0.7262, precision: 0.8994, recall: 0.7657, f1: 0.8272, edges-pos-ontonotes_loss: 0.0205
09/16 12:41:43 PM: Update 4851: task edges-pos-ontonotes, batch 851 (4851): mcc: 0.8273, acc: 0.7273, precision: 0.9000, recall: 0.7665, f1: 0.8279, edges-pos-ontonotes_loss: 0.0204
09/16 12:41:53 PM: Update 4902: task edges-pos-ontonotes, batch 902 (4902): mcc: 0.8280, acc: 0.7283, precision: 0.9005, recall: 0.7674, f1: 0.8286, edges-pos-ontonotes_loss: 0.0203
09/16 12:42:03 PM: Update 4951: task edges-pos-ontonotes, batch 951 (4951): mcc: 0.8286, acc: 0.7294, precision: 0.9008, recall: 0.7682, f1: 0.8292, edges-pos-ontonotes_loss: 0.0203
09/16 12:42:14 PM: Update 4995: task edges-pos-ontonotes, batch 995 (4995): mcc: 0.8294, acc: 0.7306, precision: 0.9012, recall: 0.7692, f1: 0.8300, edges-pos-ontonotes_loss: 0.0202
09/16 12:42:15 PM: ***** Step 5000 / Validation 5 *****
09/16 12:42:15 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:42:15 PM: Validating...
09/16 12:42:24 PM: Evaluate: task edges-pos-ontonotes, batch 53 (157): mcc: 0.8561, acc: 0.7683, precision: 0.9378, recall: 0.7864, f1: 0.8554, edges-pos-ontonotes_loss: 0.0172
09/16 12:42:34 PM: Evaluate: task edges-pos-ontonotes, batch 111 (157): mcc: 0.8680, acc: 0.7892, precision: 0.9332, recall: 0.8120, f1: 0.8684, edges-pos-ontonotes_loss: 0.0161
09/16 12:42:44 PM: Evaluate: task edges-pos-ontonotes, batch 156 (157): mcc: 0.8718, acc: 0.7969, precision: 0.9299, recall: 0.8221, f1: 0.8726, edges-pos-ontonotes_loss: 0.0157
09/16 12:42:44 PM: Best result seen so far for edges-pos-ontonotes.
09/16 12:42:44 PM: Best result seen so far for macro.
09/16 12:42:44 PM: Updating LR scheduler:
09/16 12:42:44 PM: 	Best result seen so far for macro_avg: 0.873
09/16 12:42:44 PM: 	# validation passes without improvement: 0
09/16 12:42:44 PM: edges-pos-ontonotes_loss: training: 0.020192 validation: 0.015696
09/16 12:42:44 PM: macro_avg: validation: 0.872713
09/16 12:42:44 PM: micro_avg: validation: 0.000000
09/16 12:42:44 PM: edges-pos-ontonotes_mcc: training: 0.829430 validation: 0.871893
09/16 12:42:44 PM: edges-pos-ontonotes_acc: training: 0.730639 validation: 0.797009
09/16 12:42:44 PM: edges-pos-ontonotes_precision: training: 0.901242 validation: 0.929939
09/16 12:42:44 PM: edges-pos-ontonotes_recall: training: 0.769301 validation: 0.822121
09/16 12:42:44 PM: edges-pos-ontonotes_f1: training: 0.830061 validation: 0.872713
09/16 12:42:44 PM: Global learning rate: 0.0001
09/16 12:42:44 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 12:43:01 PM: Update 5026: task edges-pos-ontonotes, batch 26 (5026): mcc: 0.8416, acc: 0.7494, precision: 0.9078, recall: 0.7858, f1: 0.8424, edges-pos-ontonotes_loss: 0.0184
09/16 12:43:11 PM: Update 5084: task edges-pos-ontonotes, batch 84 (5084): mcc: 0.8412, acc: 0.7486, precision: 0.9090, recall: 0.7841, f1: 0.8419, edges-pos-ontonotes_loss: 0.0190
09/16 12:43:21 PM: Update 5138: task edges-pos-ontonotes, batch 138 (5138): mcc: 0.8419, acc: 0.7497, precision: 0.9087, recall: 0.7855, f1: 0.8426, edges-pos-ontonotes_loss: 0.0189
09/16 12:43:31 PM: Update 5196: task edges-pos-ontonotes, batch 196 (5196): mcc: 0.8427, acc: 0.7513, precision: 0.9087, recall: 0.7871, f1: 0.8435, edges-pos-ontonotes_loss: 0.0188
09/16 12:43:42 PM: Update 5245: task edges-pos-ontonotes, batch 245 (5245): mcc: 0.8432, acc: 0.7523, precision: 0.9086, recall: 0.7880, f1: 0.8440, edges-pos-ontonotes_loss: 0.0187
09/16 12:43:52 PM: Update 5298: task edges-pos-ontonotes, batch 298 (5298): mcc: 0.8440, acc: 0.7535, precision: 0.9090, recall: 0.7892, f1: 0.8448, edges-pos-ontonotes_loss: 0.0186
09/16 12:44:02 PM: Update 5339: task edges-pos-ontonotes, batch 339 (5339): mcc: 0.8442, acc: 0.7536, precision: 0.9091, recall: 0.7894, f1: 0.8451, edges-pos-ontonotes_loss: 0.0186
09/16 12:44:12 PM: Update 5402: task edges-pos-ontonotes, batch 402 (5402): mcc: 0.8450, acc: 0.7548, precision: 0.9094, recall: 0.7907, f1: 0.8459, edges-pos-ontonotes_loss: 0.0184
09/16 12:44:22 PM: Update 5468: task edges-pos-ontonotes, batch 468 (5468): mcc: 0.8455, acc: 0.7555, precision: 0.9097, recall: 0.7914, f1: 0.8464, edges-pos-ontonotes_loss: 0.0182
09/16 12:44:32 PM: Update 5543: task edges-pos-ontonotes, batch 543 (5543): mcc: 0.8467, acc: 0.7569, precision: 0.9108, recall: 0.7926, f1: 0.8476, edges-pos-ontonotes_loss: 0.0179
09/16 12:44:42 PM: Update 5603: task edges-pos-ontonotes, batch 603 (5603): mcc: 0.8470, acc: 0.7574, precision: 0.9105, recall: 0.7934, f1: 0.8479, edges-pos-ontonotes_loss: 0.0178
09/16 12:44:53 PM: Update 5658: task edges-pos-ontonotes, batch 658 (5658): mcc: 0.8474, acc: 0.7579, precision: 0.9108, recall: 0.7938, f1: 0.8483, edges-pos-ontonotes_loss: 0.0177
09/16 12:45:03 PM: Update 5749: task edges-pos-ontonotes, batch 749 (5749): mcc: 0.8495, acc: 0.7606, precision: 0.9126, recall: 0.7961, f1: 0.8504, edges-pos-ontonotes_loss: 0.0174
09/16 12:45:13 PM: Update 5840: task edges-pos-ontonotes, batch 840 (5840): mcc: 0.8516, acc: 0.7634, precision: 0.9143, recall: 0.7986, f1: 0.8525, edges-pos-ontonotes_loss: 0.0171
09/16 12:45:23 PM: Update 5907: task edges-pos-ontonotes, batch 907 (5907): mcc: 0.8531, acc: 0.7653, precision: 0.9153, recall: 0.8003, f1: 0.8539, edges-pos-ontonotes_loss: 0.0169
09/16 12:45:34 PM: Update 5965: task edges-pos-ontonotes, batch 965 (5965): mcc: 0.8542, acc: 0.7669, precision: 0.9162, recall: 0.8017, f1: 0.8551, edges-pos-ontonotes_loss: 0.0167
09/16 12:45:38 PM: ***** Step 6000 / Validation 6 *****
09/16 12:45:38 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:45:38 PM: Validating...
09/16 12:45:44 PM: Evaluate: task edges-pos-ontonotes, batch 39 (157): mcc: 0.8610, acc: 0.7773, precision: 0.9361, recall: 0.7967, f1: 0.8608, edges-pos-ontonotes_loss: 0.0163
09/16 12:45:54 PM: Evaluate: task edges-pos-ontonotes, batch 99 (157): mcc: 0.8741, acc: 0.7998, precision: 0.9339, recall: 0.8227, f1: 0.8748, edges-pos-ontonotes_loss: 0.0151
09/16 12:46:04 PM: Evaluate: task edges-pos-ontonotes, batch 144 (157): mcc: 0.8752, acc: 0.8028, precision: 0.9289, recall: 0.8292, f1: 0.8762, edges-pos-ontonotes_loss: 0.0149
09/16 12:46:07 PM: Best result seen so far for edges-pos-ontonotes.
09/16 12:46:07 PM: Best result seen so far for macro.
09/16 12:46:07 PM: Updating LR scheduler:
09/16 12:46:07 PM: 	Best result seen so far for macro_avg: 0.878
09/16 12:46:07 PM: 	# validation passes without improvement: 0
09/16 12:46:07 PM: edges-pos-ontonotes_loss: training: 0.016698 validation: 0.014800
09/16 12:46:07 PM: macro_avg: validation: 0.877837
09/16 12:46:07 PM: micro_avg: validation: 0.000000
09/16 12:46:07 PM: edges-pos-ontonotes_mcc: training: 0.854583 validation: 0.876797
09/16 12:46:07 PM: edges-pos-ontonotes_acc: training: 0.767355 validation: 0.805528
09/16 12:46:07 PM: edges-pos-ontonotes_precision: training: 0.916587 validation: 0.929515
09/16 12:46:07 PM: edges-pos-ontonotes_recall: training: 0.801995 validation: 0.831603
09/16 12:46:07 PM: edges-pos-ontonotes_f1: training: 0.855471 validation: 0.877837
09/16 12:46:07 PM: Global learning rate: 0.0001
09/16 12:46:07 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 12:46:14 PM: Update 6054: task edges-pos-ontonotes, batch 54 (6054): mcc: 0.8730, acc: 0.7920, precision: 0.9335, recall: 0.8210, f1: 0.8736, edges-pos-ontonotes_loss: 0.0157
09/16 12:46:24 PM: Update 6134: task edges-pos-ontonotes, batch 134 (6134): mcc: 0.8732, acc: 0.7919, precision: 0.9340, recall: 0.8209, f1: 0.8738, edges-pos-ontonotes_loss: 0.0155
09/16 12:46:35 PM: Update 6223: task edges-pos-ontonotes, batch 223 (6223): mcc: 0.8758, acc: 0.7959, precision: 0.9339, recall: 0.8258, f1: 0.8766, edges-pos-ontonotes_loss: 0.0152
09/16 12:46:45 PM: Update 6319: task edges-pos-ontonotes, batch 319 (6319): mcc: 0.8719, acc: 0.7903, precision: 0.9311, recall: 0.8210, f1: 0.8726, edges-pos-ontonotes_loss: 0.0156
09/16 12:46:55 PM: Update 6443: task edges-pos-ontonotes, batch 443 (6443): mcc: 0.8637, acc: 0.7782, precision: 0.9259, recall: 0.8106, f1: 0.8644, edges-pos-ontonotes_loss: 0.0164
09/16 12:47:05 PM: Update 6565: task edges-pos-ontonotes, batch 565 (6565): mcc: 0.8603, acc: 0.7730, precision: 0.9237, recall: 0.8062, f1: 0.8609, edges-pos-ontonotes_loss: 0.0166
09/16 12:47:15 PM: Update 6628: task edges-pos-ontonotes, batch 628 (6628): mcc: 0.8561, acc: 0.7674, precision: 0.9190, recall: 0.8027, f1: 0.8569, edges-pos-ontonotes_loss: 0.0169
09/16 12:47:25 PM: Update 6692: task edges-pos-ontonotes, batch 692 (6692): mcc: 0.8523, acc: 0.7621, precision: 0.9149, recall: 0.7992, f1: 0.8532, edges-pos-ontonotes_loss: 0.0172
09/16 12:47:36 PM: Update 6740: task edges-pos-ontonotes, batch 740 (6740): mcc: 0.8491, acc: 0.7583, precision: 0.9113, recall: 0.7966, f1: 0.8501, edges-pos-ontonotes_loss: 0.0174
09/16 12:47:46 PM: Update 6791: task edges-pos-ontonotes, batch 791 (6791): mcc: 0.8476, acc: 0.7562, precision: 0.9097, recall: 0.7952, f1: 0.8486, edges-pos-ontonotes_loss: 0.0175
09/16 12:47:56 PM: Update 6835: task edges-pos-ontonotes, batch 835 (6835): mcc: 0.8466, acc: 0.7549, precision: 0.9088, recall: 0.7942, f1: 0.8476, edges-pos-ontonotes_loss: 0.0176
09/16 12:48:06 PM: Update 6891: task edges-pos-ontonotes, batch 891 (6891): mcc: 0.8457, acc: 0.7537, precision: 0.9079, recall: 0.7932, f1: 0.8467, edges-pos-ontonotes_loss: 0.0177
09/16 12:48:16 PM: Update 6956: task edges-pos-ontonotes, batch 956 (6956): mcc: 0.8446, acc: 0.7522, precision: 0.9075, recall: 0.7916, f1: 0.8456, edges-pos-ontonotes_loss: 0.0178
09/16 12:48:21 PM: ***** Step 7000 / Validation 7 *****
09/16 12:48:21 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:48:21 PM: Validating...
09/16 12:48:26 PM: Evaluate: task edges-pos-ontonotes, batch 33 (157): mcc: 0.8795, acc: 0.8095, precision: 0.9339, recall: 0.8326, f1: 0.8804, edges-pos-ontonotes_loss: 0.0147
09/16 12:48:36 PM: Evaluate: task edges-pos-ontonotes, batch 95 (157): mcc: 0.8894, acc: 0.8246, precision: 0.9321, recall: 0.8528, f1: 0.8907, edges-pos-ontonotes_loss: 0.0138
09/16 12:48:46 PM: Evaluate: task edges-pos-ontonotes, batch 140 (157): mcc: 0.8884, acc: 0.8243, precision: 0.9245, recall: 0.8580, f1: 0.8900, edges-pos-ontonotes_loss: 0.0138
09/16 12:48:50 PM: Best result seen so far for edges-pos-ontonotes.
09/16 12:48:50 PM: Best result seen so far for macro.
09/16 12:48:50 PM: Updating LR scheduler:
09/16 12:48:50 PM: 	Best result seen so far for macro_avg: 0.891
09/16 12:48:50 PM: 	# validation passes without improvement: 0
09/16 12:48:50 PM: edges-pos-ontonotes_loss: training: 0.017812 validation: 0.013749
09/16 12:48:50 PM: macro_avg: validation: 0.890744
09/16 12:48:50 PM: micro_avg: validation: 0.000000
09/16 12:48:50 PM: edges-pos-ontonotes_mcc: training: 0.844242 validation: 0.889096
09/16 12:48:50 PM: edges-pos-ontonotes_acc: training: 0.751569 validation: 0.826079
09/16 12:48:50 PM: edges-pos-ontonotes_precision: training: 0.907578 validation: 0.923772
09/16 12:48:50 PM: edges-pos-ontonotes_recall: training: 0.790897 validation: 0.859996
09/16 12:48:50 PM: edges-pos-ontonotes_f1: training: 0.845230 validation: 0.890744
09/16 12:48:50 PM: Global learning rate: 0.0001
09/16 12:48:50 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 12:48:56 PM: Update 7058: task edges-pos-ontonotes, batch 58 (7058): mcc: 0.8446, acc: 0.7503, precision: 0.9170, recall: 0.7834, f1: 0.8449, edges-pos-ontonotes_loss: 0.0169
09/16 12:49:06 PM: Update 7139: task edges-pos-ontonotes, batch 139 (7139): mcc: 0.8439, acc: 0.7488, precision: 0.9152, recall: 0.7835, f1: 0.8443, edges-pos-ontonotes_loss: 0.0171
09/16 12:49:16 PM: Update 7232: task edges-pos-ontonotes, batch 232 (7232): mcc: 0.8449, acc: 0.7505, precision: 0.9147, recall: 0.7859, f1: 0.8454, edges-pos-ontonotes_loss: 0.0170
09/16 12:49:26 PM: Update 7289: task edges-pos-ontonotes, batch 289 (7289): mcc: 0.8476, acc: 0.7553, precision: 0.9115, recall: 0.7936, f1: 0.8484, edges-pos-ontonotes_loss: 0.0170
09/16 12:49:37 PM: Update 7356: task edges-pos-ontonotes, batch 356 (7356): mcc: 0.8488, acc: 0.7577, precision: 0.9098, recall: 0.7973, f1: 0.8499, edges-pos-ontonotes_loss: 0.0169
09/16 12:49:47 PM: Update 7427: task edges-pos-ontonotes, batch 427 (7427): mcc: 0.8498, acc: 0.7596, precision: 0.9090, recall: 0.8000, f1: 0.8510, edges-pos-ontonotes_loss: 0.0169
09/16 12:49:57 PM: Update 7497: task edges-pos-ontonotes, batch 497 (7497): mcc: 0.8504, acc: 0.7605, precision: 0.9087, recall: 0.8012, f1: 0.8516, edges-pos-ontonotes_loss: 0.0168
09/16 12:50:16 PM: Update 7547: task edges-pos-ontonotes, batch 547 (7547): mcc: 0.8509, acc: 0.7616, precision: 0.9086, recall: 0.8023, f1: 0.8522, edges-pos-ontonotes_loss: 0.0168
09/16 12:50:26 PM: Update 7598: task edges-pos-ontonotes, batch 598 (7598): mcc: 0.8494, acc: 0.7598, precision: 0.9062, recall: 0.8016, f1: 0.8507, edges-pos-ontonotes_loss: 0.0169
09/16 12:50:36 PM: Update 7652: task edges-pos-ontonotes, batch 652 (7652): mcc: 0.8490, acc: 0.7597, precision: 0.9052, recall: 0.8018, f1: 0.8504, edges-pos-ontonotes_loss: 0.0170
09/16 12:50:46 PM: Update 7702: task edges-pos-ontonotes, batch 702 (7702): mcc: 0.8487, acc: 0.7594, precision: 0.9046, recall: 0.8017, f1: 0.8500, edges-pos-ontonotes_loss: 0.0171
09/16 12:50:57 PM: Update 7763: task edges-pos-ontonotes, batch 763 (7763): mcc: 0.8489, acc: 0.7599, precision: 0.9047, recall: 0.8021, f1: 0.8503, edges-pos-ontonotes_loss: 0.0171
09/16 12:51:07 PM: Update 7816: task edges-pos-ontonotes, batch 816 (7816): mcc: 0.8491, acc: 0.7603, precision: 0.9046, recall: 0.8026, f1: 0.8505, edges-pos-ontonotes_loss: 0.0171
09/16 12:51:18 PM: Update 7860: task edges-pos-ontonotes, batch 860 (7860): mcc: 0.8490, acc: 0.7602, precision: 0.9042, recall: 0.8027, f1: 0.8505, edges-pos-ontonotes_loss: 0.0172
09/16 12:51:28 PM: Update 7904: task edges-pos-ontonotes, batch 904 (7904): mcc: 0.8489, acc: 0.7601, precision: 0.9037, recall: 0.8029, f1: 0.8503, edges-pos-ontonotes_loss: 0.0172
09/16 12:51:38 PM: Update 7956: task edges-pos-ontonotes, batch 956 (7956): mcc: 0.8494, acc: 0.7611, precision: 0.9039, recall: 0.8037, f1: 0.8509, edges-pos-ontonotes_loss: 0.0172
09/16 12:51:48 PM: ***** Step 8000 / Validation 8 *****
09/16 12:51:48 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:51:48 PM: Validating...
09/16 12:51:48 PM: Evaluate: task edges-pos-ontonotes, batch 1 (157): mcc: 0.8977, acc: 0.8365, precision: 0.9540, recall: 0.8484, f1: 0.8981, edges-pos-ontonotes_loss: 0.0123
09/16 12:51:58 PM: Evaluate: task edges-pos-ontonotes, batch 70 (157): mcc: 0.8892, acc: 0.8221, precision: 0.9444, recall: 0.8412, f1: 0.8898, edges-pos-ontonotes_loss: 0.0134
09/16 12:52:08 PM: Evaluate: task edges-pos-ontonotes, batch 122 (157): mcc: 0.8931, acc: 0.8297, precision: 0.9402, recall: 0.8524, f1: 0.8942, edges-pos-ontonotes_loss: 0.0129
09/16 12:52:16 PM: Best result seen so far for edges-pos-ontonotes.
09/16 12:52:16 PM: Best result seen so far for macro.
09/16 12:52:16 PM: Updating LR scheduler:
09/16 12:52:16 PM: 	Best result seen so far for macro_avg: 0.895
09/16 12:52:16 PM: 	# validation passes without improvement: 0
09/16 12:52:16 PM: edges-pos-ontonotes_loss: training: 0.017128 validation: 0.012827
09/16 12:52:16 PM: macro_avg: validation: 0.895145
09/16 12:52:16 PM: micro_avg: validation: 0.000000
09/16 12:52:16 PM: edges-pos-ontonotes_mcc: training: 0.849813 validation: 0.893939
09/16 12:52:16 PM: edges-pos-ontonotes_acc: training: 0.761693 validation: 0.832619
09/16 12:52:16 PM: edges-pos-ontonotes_precision: training: 0.903978 validation: 0.936869
09/16 12:52:16 PM: edges-pos-ontonotes_recall: training: 0.804398 validation: 0.856980
09/16 12:52:16 PM: edges-pos-ontonotes_f1: training: 0.851286 validation: 0.895145
09/16 12:52:16 PM: Global learning rate: 0.0001
09/16 12:52:16 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 12:52:18 PM: Update 8013: task edges-pos-ontonotes, batch 13 (8013): mcc: 0.8479, acc: 0.7609, precision: 0.9006, recall: 0.8039, f1: 0.8495, edges-pos-ontonotes_loss: 0.0175
09/16 12:52:28 PM: Update 8059: task edges-pos-ontonotes, batch 59 (8059): mcc: 0.8564, acc: 0.7735, precision: 0.9082, recall: 0.8128, f1: 0.8579, edges-pos-ontonotes_loss: 0.0168
09/16 12:52:39 PM: Update 8111: task edges-pos-ontonotes, batch 111 (8111): mcc: 0.8573, acc: 0.7758, precision: 0.9072, recall: 0.8155, f1: 0.8589, edges-pos-ontonotes_loss: 0.0166
09/16 12:52:49 PM: Update 8166: task edges-pos-ontonotes, batch 166 (8166): mcc: 0.8578, acc: 0.7763, precision: 0.9070, recall: 0.8165, f1: 0.8594, edges-pos-ontonotes_loss: 0.0166
09/16 12:52:59 PM: Update 8206: task edges-pos-ontonotes, batch 206 (8206): mcc: 0.8564, acc: 0.7743, precision: 0.9065, recall: 0.8144, f1: 0.8580, edges-pos-ontonotes_loss: 0.0168
09/16 12:53:09 PM: Update 8261: task edges-pos-ontonotes, batch 261 (8261): mcc: 0.8566, acc: 0.7744, precision: 0.9065, recall: 0.8148, f1: 0.8582, edges-pos-ontonotes_loss: 0.0168
09/16 12:53:19 PM: Update 8317: task edges-pos-ontonotes, batch 317 (8317): mcc: 0.8574, acc: 0.7755, precision: 0.9074, recall: 0.8154, f1: 0.8589, edges-pos-ontonotes_loss: 0.0168
09/16 12:53:29 PM: Update 8375: task edges-pos-ontonotes, batch 375 (8375): mcc: 0.8578, acc: 0.7761, precision: 0.9077, recall: 0.8160, f1: 0.8594, edges-pos-ontonotes_loss: 0.0167
09/16 12:53:39 PM: Update 8428: task edges-pos-ontonotes, batch 428 (8428): mcc: 0.8586, acc: 0.7774, precision: 0.9083, recall: 0.8170, f1: 0.8602, edges-pos-ontonotes_loss: 0.0166
09/16 12:53:49 PM: Update 8484: task edges-pos-ontonotes, batch 484 (8484): mcc: 0.8594, acc: 0.7784, precision: 0.9089, recall: 0.8177, f1: 0.8609, edges-pos-ontonotes_loss: 0.0166
09/16 12:53:59 PM: Update 8522: task edges-pos-ontonotes, batch 522 (8522): mcc: 0.8594, acc: 0.7785, precision: 0.9089, recall: 0.8179, f1: 0.8610, edges-pos-ontonotes_loss: 0.0166
09/16 12:54:09 PM: Update 8579: task edges-pos-ontonotes, batch 579 (8579): mcc: 0.8596, acc: 0.7788, precision: 0.9089, recall: 0.8182, f1: 0.8612, edges-pos-ontonotes_loss: 0.0165
09/16 12:54:19 PM: Update 8636: task edges-pos-ontonotes, batch 636 (8636): mcc: 0.8603, acc: 0.7797, precision: 0.9094, recall: 0.8190, f1: 0.8618, edges-pos-ontonotes_loss: 0.0165
09/16 12:54:30 PM: Update 8692: task edges-pos-ontonotes, batch 692 (8692): mcc: 0.8607, acc: 0.7805, precision: 0.9098, recall: 0.8195, f1: 0.8623, edges-pos-ontonotes_loss: 0.0165
09/16 12:54:40 PM: Update 8752: task edges-pos-ontonotes, batch 752 (8752): mcc: 0.8609, acc: 0.7807, precision: 0.9100, recall: 0.8196, f1: 0.8624, edges-pos-ontonotes_loss: 0.0165
09/16 12:54:51 PM: Update 8799: task edges-pos-ontonotes, batch 799 (8799): mcc: 0.8610, acc: 0.7810, precision: 0.9100, recall: 0.8198, f1: 0.8626, edges-pos-ontonotes_loss: 0.0165
09/16 12:55:01 PM: Update 8859: task edges-pos-ontonotes, batch 859 (8859): mcc: 0.8613, acc: 0.7813, precision: 0.9102, recall: 0.8203, f1: 0.8629, edges-pos-ontonotes_loss: 0.0163
09/16 12:55:11 PM: Update 8930: task edges-pos-ontonotes, batch 930 (8930): mcc: 0.8616, acc: 0.7817, precision: 0.9103, recall: 0.8207, f1: 0.8632, edges-pos-ontonotes_loss: 0.0162
09/16 12:55:21 PM: Update 8993: task edges-pos-ontonotes, batch 993 (8993): mcc: 0.8619, acc: 0.7820, precision: 0.9104, recall: 0.8211, f1: 0.8634, edges-pos-ontonotes_loss: 0.0161
09/16 12:55:22 PM: ***** Step 9000 / Validation 9 *****
09/16 12:55:22 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:55:22 PM: Validating...
09/16 12:55:31 PM: Evaluate: task edges-pos-ontonotes, batch 60 (157): mcc: 0.8862, acc: 0.8174, precision: 0.9423, recall: 0.8376, f1: 0.8869, edges-pos-ontonotes_loss: 0.0137
09/16 12:55:41 PM: Evaluate: task edges-pos-ontonotes, batch 114 (157): mcc: 0.8938, acc: 0.8315, precision: 0.9390, recall: 0.8547, f1: 0.8949, edges-pos-ontonotes_loss: 0.0129
09/16 12:55:51 PM: Best result seen so far for edges-pos-ontonotes.
09/16 12:55:51 PM: Best result seen so far for macro.
09/16 12:55:51 PM: Updating LR scheduler:
09/16 12:55:51 PM: 	Best result seen so far for macro_avg: 0.898
09/16 12:55:51 PM: 	# validation passes without improvement: 0
09/16 12:55:51 PM: edges-pos-ontonotes_loss: training: 0.016066 validation: 0.012561
09/16 12:55:51 PM: macro_avg: validation: 0.898091
09/16 12:55:51 PM: micro_avg: validation: 0.000000
09/16 12:55:51 PM: edges-pos-ontonotes_mcc: training: 0.861928 validation: 0.896812
09/16 12:55:51 PM: edges-pos-ontonotes_acc: training: 0.782027 validation: 0.837550
09/16 12:55:51 PM: edges-pos-ontonotes_precision: training: 0.910465 validation: 0.936792
09/16 12:55:51 PM: edges-pos-ontonotes_recall: training: 0.821116 validation: 0.862461
09/16 12:55:51 PM: edges-pos-ontonotes_f1: training: 0.863485 validation: 0.898091
09/16 12:55:51 PM: Global learning rate: 0.0001
09/16 12:55:51 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 12:55:51 PM: Update 9006: task edges-pos-ontonotes, batch 6 (9006): mcc: 0.8713, acc: 0.7913, precision: 0.9182, recall: 0.8316, f1: 0.8727, edges-pos-ontonotes_loss: 0.0140
09/16 12:56:02 PM: Update 9077: task edges-pos-ontonotes, batch 77 (9077): mcc: 0.8701, acc: 0.7917, precision: 0.9157, recall: 0.8317, f1: 0.8717, edges-pos-ontonotes_loss: 0.0142
09/16 12:56:20 PM: Update 9112: task edges-pos-ontonotes, batch 112 (9112): mcc: 0.8697, acc: 0.7914, precision: 0.9155, recall: 0.8312, f1: 0.8713, edges-pos-ontonotes_loss: 0.0142
09/16 12:56:30 PM: Update 9206: task edges-pos-ontonotes, batch 206 (9206): mcc: 0.8786, acc: 0.8029, precision: 0.9232, recall: 0.8406, f1: 0.8800, edges-pos-ontonotes_loss: 0.0135
09/16 12:56:40 PM: Update 9299: task edges-pos-ontonotes, batch 299 (9299): mcc: 0.8831, acc: 0.8090, precision: 0.9271, recall: 0.8456, f1: 0.8845, edges-pos-ontonotes_loss: 0.0132
09/16 12:56:50 PM: Update 9387: task edges-pos-ontonotes, batch 387 (9387): mcc: 0.8859, acc: 0.8130, precision: 0.9292, recall: 0.8490, f1: 0.8873, edges-pos-ontonotes_loss: 0.0130
09/16 12:57:00 PM: Update 9468: task edges-pos-ontonotes, batch 468 (9468): mcc: 0.8865, acc: 0.8138, precision: 0.9302, recall: 0.8492, f1: 0.8878, edges-pos-ontonotes_loss: 0.0130
09/16 12:57:10 PM: Update 9571: task edges-pos-ontonotes, batch 571 (9571): mcc: 0.8867, acc: 0.8142, precision: 0.9310, recall: 0.8488, f1: 0.8880, edges-pos-ontonotes_loss: 0.0130
09/16 12:57:20 PM: Update 9691: task edges-pos-ontonotes, batch 691 (9691): mcc: 0.8873, acc: 0.8151, precision: 0.9317, recall: 0.8492, f1: 0.8885, edges-pos-ontonotes_loss: 0.0130
09/16 12:57:30 PM: Update 9790: task edges-pos-ontonotes, batch 790 (9790): mcc: 0.8859, acc: 0.8131, precision: 0.9312, recall: 0.8471, f1: 0.8872, edges-pos-ontonotes_loss: 0.0133
09/16 12:57:40 PM: Update 9938: task edges-pos-ontonotes, batch 938 (9938): mcc: 0.8835, acc: 0.8094, precision: 0.9298, recall: 0.8438, f1: 0.8847, edges-pos-ontonotes_loss: 0.0137
09/16 12:57:45 PM: ***** Step 10000 / Validation 10 *****
09/16 12:57:45 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 12:57:45 PM: Validating...
09/16 12:57:50 PM: Evaluate: task edges-pos-ontonotes, batch 36 (157): mcc: 0.8873, acc: 0.8206, precision: 0.9372, recall: 0.8443, f1: 0.8883, edges-pos-ontonotes_loss: 0.0134
09/16 12:58:00 PM: Evaluate: task edges-pos-ontonotes, batch 98 (157): mcc: 0.8955, acc: 0.8354, precision: 0.9340, recall: 0.8626, f1: 0.8969, edges-pos-ontonotes_loss: 0.0127
09/16 12:58:10 PM: Evaluate: task edges-pos-ontonotes, batch 141 (157): mcc: 0.8944, acc: 0.8345, precision: 0.9254, recall: 0.8686, f1: 0.8961, edges-pos-ontonotes_loss: 0.0127
09/16 12:58:14 PM: Updating LR scheduler:
09/16 12:58:14 PM: 	Best result seen so far for macro_avg: 0.898
09/16 12:58:14 PM: 	# validation passes without improvement: 1
09/16 12:58:14 PM: edges-pos-ontonotes_loss: training: 0.013870 validation: 0.012632
09/16 12:58:14 PM: macro_avg: validation: 0.897114
09/16 12:58:14 PM: micro_avg: validation: 0.000000
09/16 12:58:14 PM: edges-pos-ontonotes_mcc: training: 0.882301 validation: 0.895417
09/16 12:58:14 PM: edges-pos-ontonotes_acc: training: 0.807624 validation: 0.836736
09/16 12:58:14 PM: edges-pos-ontonotes_precision: training: 0.929090 validation: 0.925043
09/16 12:58:14 PM: edges-pos-ontonotes_recall: training: 0.842267 validation: 0.870821
09/16 12:58:14 PM: edges-pos-ontonotes_f1: training: 0.883551 validation: 0.897114
09/16 12:58:14 PM: Global learning rate: 0.0001
09/16 12:58:14 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 12:58:22 PM: Update 10051: task edges-pos-ontonotes, batch 51 (10051): mcc: 0.8542, acc: 0.7668, precision: 0.9078, recall: 0.8091, f1: 0.8556, edges-pos-ontonotes_loss: 0.0164
09/16 12:58:32 PM: Update 10095: task edges-pos-ontonotes, batch 95 (10095): mcc: 0.8481, acc: 0.7599, precision: 0.8975, recall: 0.8072, f1: 0.8499, edges-pos-ontonotes_loss: 0.0172
09/16 12:58:42 PM: Update 10156: task edges-pos-ontonotes, batch 156 (10156): mcc: 0.8468, acc: 0.7574, precision: 0.8960, recall: 0.8060, f1: 0.8487, edges-pos-ontonotes_loss: 0.0175
09/16 12:58:52 PM: Update 10214: task edges-pos-ontonotes, batch 214 (10214): mcc: 0.8479, acc: 0.7586, precision: 0.8972, recall: 0.8070, f1: 0.8497, edges-pos-ontonotes_loss: 0.0176
09/16 12:59:03 PM: Update 10274: task edges-pos-ontonotes, batch 274 (10274): mcc: 0.8487, acc: 0.7599, precision: 0.8979, recall: 0.8078, f1: 0.8505, edges-pos-ontonotes_loss: 0.0176
09/16 12:59:13 PM: Update 10323: task edges-pos-ontonotes, batch 323 (10323): mcc: 0.8492, acc: 0.7610, precision: 0.8983, recall: 0.8085, f1: 0.8510, edges-pos-ontonotes_loss: 0.0176
09/16 12:59:23 PM: Update 10372: task edges-pos-ontonotes, batch 372 (10372): mcc: 0.8494, acc: 0.7612, precision: 0.8988, recall: 0.8083, f1: 0.8511, edges-pos-ontonotes_loss: 0.0176
09/16 12:59:33 PM: Update 10444: task edges-pos-ontonotes, batch 444 (10444): mcc: 0.8496, acc: 0.7612, precision: 0.9005, recall: 0.8071, f1: 0.8513, edges-pos-ontonotes_loss: 0.0174
09/16 12:59:43 PM: Update 10522: task edges-pos-ontonotes, batch 522 (10522): mcc: 0.8500, acc: 0.7616, precision: 0.9020, recall: 0.8066, f1: 0.8516, edges-pos-ontonotes_loss: 0.0173
09/16 12:59:53 PM: Update 10602: task edges-pos-ontonotes, batch 602 (10602): mcc: 0.8506, acc: 0.7624, precision: 0.9032, recall: 0.8067, f1: 0.8522, edges-pos-ontonotes_loss: 0.0171
09/16 01:00:04 PM: Update 10694: task edges-pos-ontonotes, batch 694 (10694): mcc: 0.8514, acc: 0.7634, precision: 0.9043, recall: 0.8072, f1: 0.8530, edges-pos-ontonotes_loss: 0.0169
09/16 01:00:14 PM: Update 10759: task edges-pos-ontonotes, batch 759 (10759): mcc: 0.8525, acc: 0.7651, precision: 0.9044, recall: 0.8091, f1: 0.8541, edges-pos-ontonotes_loss: 0.0168
09/16 01:00:24 PM: Update 10829: task edges-pos-ontonotes, batch 829 (10829): mcc: 0.8537, acc: 0.7667, precision: 0.9047, recall: 0.8109, f1: 0.8553, edges-pos-ontonotes_loss: 0.0166
09/16 01:00:35 PM: Update 10901: task edges-pos-ontonotes, batch 901 (10901): mcc: 0.8548, acc: 0.7684, precision: 0.9052, recall: 0.8126, f1: 0.8564, edges-pos-ontonotes_loss: 0.0165
09/16 01:00:45 PM: Update 10955: task edges-pos-ontonotes, batch 955 (10955): mcc: 0.8554, acc: 0.7693, precision: 0.9054, recall: 0.8135, f1: 0.8570, edges-pos-ontonotes_loss: 0.0164
09/16 01:00:51 PM: ***** Step 11000 / Validation 11 *****
09/16 01:00:51 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:00:51 PM: Validating...
09/16 01:00:55 PM: Evaluate: task edges-pos-ontonotes, batch 22 (157): mcc: 0.8896, acc: 0.8266, precision: 0.9362, recall: 0.8496, f1: 0.8908, edges-pos-ontonotes_loss: 0.0130
09/16 01:01:05 PM: Evaluate: task edges-pos-ontonotes, batch 89 (157): mcc: 0.9036, acc: 0.8461, precision: 0.9436, recall: 0.8690, f1: 0.9048, edges-pos-ontonotes_loss: 0.0118
09/16 01:01:15 PM: Evaluate: task edges-pos-ontonotes, batch 134 (157): mcc: 0.9021, acc: 0.8451, precision: 0.9367, recall: 0.8725, f1: 0.9034, edges-pos-ontonotes_loss: 0.0118
09/16 01:01:20 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:01:20 PM: Best result seen so far for macro.
09/16 01:01:20 PM: Updating LR scheduler:
09/16 01:01:20 PM: 	Best result seen so far for macro_avg: 0.904
09/16 01:01:20 PM: 	# validation passes without improvement: 0
09/16 01:01:20 PM: edges-pos-ontonotes_loss: training: 0.016349 validation: 0.011793
09/16 01:01:20 PM: macro_avg: validation: 0.904040
09/16 01:01:20 PM: micro_avg: validation: 0.000000
09/16 01:01:20 PM: edges-pos-ontonotes_mcc: training: 0.855801 validation: 0.902604
09/16 01:01:20 PM: edges-pos-ontonotes_acc: training: 0.769832 validation: 0.847032
09/16 01:01:20 PM: edges-pos-ontonotes_precision: training: 0.905653 validation: 0.935604
09/16 01:01:20 PM: edges-pos-ontonotes_recall: training: 0.814038 validation: 0.874536
09/16 01:01:20 PM: edges-pos-ontonotes_f1: training: 0.857405 validation: 0.904040
09/16 01:01:20 PM: Global learning rate: 0.0001
09/16 01:01:20 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:01:25 PM: Update 11018: task edges-pos-ontonotes, batch 18 (11018): mcc: 0.8496, acc: 0.7651, precision: 0.8942, recall: 0.8129, f1: 0.8516, edges-pos-ontonotes_loss: 0.0179
09/16 01:01:35 PM: Update 11076: task edges-pos-ontonotes, batch 76 (11076): mcc: 0.8556, acc: 0.7719, precision: 0.8997, recall: 0.8191, f1: 0.8575, edges-pos-ontonotes_loss: 0.0169
09/16 01:01:45 PM: Update 11130: task edges-pos-ontonotes, batch 130 (11130): mcc: 0.8567, acc: 0.7730, precision: 0.8994, recall: 0.8213, f1: 0.8586, edges-pos-ontonotes_loss: 0.0168
09/16 01:01:55 PM: Update 11176: task edges-pos-ontonotes, batch 176 (11176): mcc: 0.8565, acc: 0.7730, precision: 0.8993, recall: 0.8212, f1: 0.8585, edges-pos-ontonotes_loss: 0.0168
09/16 01:02:05 PM: Update 11221: task edges-pos-ontonotes, batch 221 (11221): mcc: 0.8568, acc: 0.7737, precision: 0.8993, recall: 0.8217, f1: 0.8587, edges-pos-ontonotes_loss: 0.0168
09/16 01:02:15 PM: Update 11280: task edges-pos-ontonotes, batch 280 (11280): mcc: 0.8573, acc: 0.7745, precision: 0.9000, recall: 0.8221, f1: 0.8593, edges-pos-ontonotes_loss: 0.0166
09/16 01:02:35 PM: Update 11320: task edges-pos-ontonotes, batch 320 (11320): mcc: 0.8570, acc: 0.7740, precision: 0.9002, recall: 0.8212, f1: 0.8589, edges-pos-ontonotes_loss: 0.0166
09/16 01:02:46 PM: Update 11372: task edges-pos-ontonotes, batch 372 (11372): mcc: 0.8579, acc: 0.7754, precision: 0.9006, recall: 0.8225, f1: 0.8598, edges-pos-ontonotes_loss: 0.0166
09/16 01:02:56 PM: Update 11414: task edges-pos-ontonotes, batch 414 (11414): mcc: 0.8586, acc: 0.7765, precision: 0.9015, recall: 0.8232, f1: 0.8606, edges-pos-ontonotes_loss: 0.0165
09/16 01:03:06 PM: Update 11454: task edges-pos-ontonotes, batch 454 (11454): mcc: 0.8594, acc: 0.7774, precision: 0.9020, recall: 0.8241, f1: 0.8613, edges-pos-ontonotes_loss: 0.0164
09/16 01:03:16 PM: Update 11507: task edges-pos-ontonotes, batch 507 (11507): mcc: 0.8597, acc: 0.7781, precision: 0.9023, recall: 0.8244, f1: 0.8616, edges-pos-ontonotes_loss: 0.0163
09/16 01:03:26 PM: Update 11563: task edges-pos-ontonotes, batch 563 (11563): mcc: 0.8600, acc: 0.7787, precision: 0.9027, recall: 0.8247, f1: 0.8619, edges-pos-ontonotes_loss: 0.0163
09/16 01:03:36 PM: Update 11614: task edges-pos-ontonotes, batch 614 (11614): mcc: 0.8608, acc: 0.7797, precision: 0.9033, recall: 0.8256, f1: 0.8627, edges-pos-ontonotes_loss: 0.0162
09/16 01:03:46 PM: Update 11658: task edges-pos-ontonotes, batch 658 (11658): mcc: 0.8610, acc: 0.7801, precision: 0.9036, recall: 0.8257, f1: 0.8629, edges-pos-ontonotes_loss: 0.0162
09/16 01:03:56 PM: Update 11716: task edges-pos-ontonotes, batch 716 (11716): mcc: 0.8615, acc: 0.7809, precision: 0.9040, recall: 0.8262, f1: 0.8633, edges-pos-ontonotes_loss: 0.0162
09/16 01:04:07 PM: Update 11773: task edges-pos-ontonotes, batch 773 (11773): mcc: 0.8622, acc: 0.7819, precision: 0.9046, recall: 0.8269, f1: 0.8640, edges-pos-ontonotes_loss: 0.0161
09/16 01:04:17 PM: Update 11827: task edges-pos-ontonotes, batch 827 (11827): mcc: 0.8627, acc: 0.7828, precision: 0.9052, recall: 0.8274, f1: 0.8646, edges-pos-ontonotes_loss: 0.0160
09/16 01:04:27 PM: Update 11877: task edges-pos-ontonotes, batch 877 (11877): mcc: 0.8632, acc: 0.7835, precision: 0.9056, recall: 0.8280, f1: 0.8650, edges-pos-ontonotes_loss: 0.0160
09/16 01:04:37 PM: Update 11929: task edges-pos-ontonotes, batch 929 (11929): mcc: 0.8636, acc: 0.7841, precision: 0.9060, recall: 0.8283, f1: 0.8654, edges-pos-ontonotes_loss: 0.0159
09/16 01:04:47 PM: Update 11969: task edges-pos-ontonotes, batch 969 (11969): mcc: 0.8638, acc: 0.7845, precision: 0.9061, recall: 0.8286, f1: 0.8656, edges-pos-ontonotes_loss: 0.0159
09/16 01:04:52 PM: ***** Step 12000 / Validation 12 *****
09/16 01:04:52 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:04:52 PM: Validating...
09/16 01:04:57 PM: Evaluate: task edges-pos-ontonotes, batch 31 (157): mcc: 0.8924, acc: 0.8271, precision: 0.9446, recall: 0.8471, f1: 0.8932, edges-pos-ontonotes_loss: 0.0128
09/16 01:05:07 PM: Evaluate: task edges-pos-ontonotes, batch 95 (157): mcc: 0.9015, acc: 0.8426, precision: 0.9447, recall: 0.8639, f1: 0.9025, edges-pos-ontonotes_loss: 0.0120
09/16 01:05:17 PM: Evaluate: task edges-pos-ontonotes, batch 141 (157): mcc: 0.9028, acc: 0.8463, precision: 0.9406, recall: 0.8702, f1: 0.9040, edges-pos-ontonotes_loss: 0.0117
09/16 01:05:20 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:05:20 PM: Best result seen so far for macro.
09/16 01:05:20 PM: Updating LR scheduler:
09/16 01:05:20 PM: 	Best result seen so far for macro_avg: 0.905
09/16 01:05:20 PM: 	# validation passes without improvement: 0
09/16 01:05:20 PM: edges-pos-ontonotes_loss: training: 0.015911 validation: 0.011620
09/16 01:05:20 PM: macro_avg: validation: 0.905297
09/16 01:05:20 PM: micro_avg: validation: 0.000000
09/16 01:05:20 PM: edges-pos-ontonotes_mcc: training: 0.863974 validation: 0.904015
09/16 01:05:20 PM: edges-pos-ontonotes_acc: training: 0.784850 validation: 0.848937
09/16 01:05:20 PM: edges-pos-ontonotes_precision: training: 0.906202 validation: 0.940417
09/16 01:05:20 PM: edges-pos-ontonotes_recall: training: 0.828857 validation: 0.872705
09/16 01:05:20 PM: edges-pos-ontonotes_f1: training: 0.865806 validation: 0.905297
09/16 01:05:20 PM: Global learning rate: 0.0001
09/16 01:05:20 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:05:27 PM: Update 12038: task edges-pos-ontonotes, batch 38 (12038): mcc: 0.8701, acc: 0.7943, precision: 0.9109, recall: 0.8361, f1: 0.8719, edges-pos-ontonotes_loss: 0.0154
09/16 01:05:37 PM: Update 12094: task edges-pos-ontonotes, batch 94 (12094): mcc: 0.8705, acc: 0.7958, precision: 0.9122, recall: 0.8356, f1: 0.8722, edges-pos-ontonotes_loss: 0.0158
09/16 01:05:48 PM: Update 12149: task edges-pos-ontonotes, batch 149 (12149): mcc: 0.8709, acc: 0.7960, precision: 0.9129, recall: 0.8357, f1: 0.8726, edges-pos-ontonotes_loss: 0.0156
09/16 01:05:58 PM: Update 12193: task edges-pos-ontonotes, batch 193 (12193): mcc: 0.8699, acc: 0.7947, precision: 0.9118, recall: 0.8348, f1: 0.8716, edges-pos-ontonotes_loss: 0.0157
09/16 01:06:08 PM: Update 12246: task edges-pos-ontonotes, batch 246 (12246): mcc: 0.8706, acc: 0.7955, precision: 0.9122, recall: 0.8357, f1: 0.8723, edges-pos-ontonotes_loss: 0.0155
09/16 01:06:18 PM: Update 12289: task edges-pos-ontonotes, batch 289 (12289): mcc: 0.8701, acc: 0.7949, precision: 0.9120, recall: 0.8350, f1: 0.8718, edges-pos-ontonotes_loss: 0.0153
09/16 01:06:28 PM: Update 12357: task edges-pos-ontonotes, batch 357 (12357): mcc: 0.8710, acc: 0.7958, precision: 0.9129, recall: 0.8359, f1: 0.8727, edges-pos-ontonotes_loss: 0.0150
09/16 01:06:38 PM: Update 12428: task edges-pos-ontonotes, batch 428 (12428): mcc: 0.8721, acc: 0.7973, precision: 0.9137, recall: 0.8373, f1: 0.8738, edges-pos-ontonotes_loss: 0.0147
09/16 01:06:48 PM: Update 12494: task edges-pos-ontonotes, batch 494 (12494): mcc: 0.8725, acc: 0.7980, precision: 0.9136, recall: 0.8380, f1: 0.8742, edges-pos-ontonotes_loss: 0.0145
09/16 01:06:58 PM: Update 12557: task edges-pos-ontonotes, batch 557 (12557): mcc: 0.8730, acc: 0.7986, precision: 0.9138, recall: 0.8388, f1: 0.8747, edges-pos-ontonotes_loss: 0.0144
09/16 01:07:08 PM: Update 12623: task edges-pos-ontonotes, batch 623 (12623): mcc: 0.8749, acc: 0.8010, precision: 0.9155, recall: 0.8408, f1: 0.8765, edges-pos-ontonotes_loss: 0.0142
09/16 01:07:18 PM: Update 12714: task edges-pos-ontonotes, batch 714 (12714): mcc: 0.8771, acc: 0.8039, precision: 0.9175, recall: 0.8432, f1: 0.8788, edges-pos-ontonotes_loss: 0.0138
09/16 01:07:28 PM: Update 12794: task edges-pos-ontonotes, batch 794 (12794): mcc: 0.8790, acc: 0.8063, precision: 0.9191, recall: 0.8453, f1: 0.8807, edges-pos-ontonotes_loss: 0.0136
09/16 01:07:39 PM: Update 12885: task edges-pos-ontonotes, batch 885 (12885): mcc: 0.8806, acc: 0.8084, precision: 0.9205, recall: 0.8470, f1: 0.8822, edges-pos-ontonotes_loss: 0.0134
09/16 01:07:49 PM: Update 12990: task edges-pos-ontonotes, batch 990 (12990): mcc: 0.8815, acc: 0.8095, precision: 0.9217, recall: 0.8476, f1: 0.8831, edges-pos-ontonotes_loss: 0.0133
09/16 01:07:50 PM: ***** Step 13000 / Validation 13 *****
09/16 01:07:50 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:07:50 PM: Validating...
09/16 01:07:59 PM: Evaluate: task edges-pos-ontonotes, batch 62 (157): mcc: 0.8974, acc: 0.8369, precision: 0.9443, recall: 0.8568, f1: 0.8984, edges-pos-ontonotes_loss: 0.0124
09/16 01:08:10 PM: Evaluate: task edges-pos-ontonotes, batch 108 (157): mcc: 0.9010, acc: 0.8439, precision: 0.9404, recall: 0.8669, f1: 0.9022, edges-pos-ontonotes_loss: 0.0119
09/16 01:08:20 PM: Evaluate: task edges-pos-ontonotes, batch 153 (157): mcc: 0.9024, acc: 0.8475, precision: 0.9360, recall: 0.8738, f1: 0.9039, edges-pos-ontonotes_loss: 0.0117
09/16 01:08:20 PM: Updating LR scheduler:
09/16 01:08:20 PM: 	Best result seen so far for macro_avg: 0.905
09/16 01:08:20 PM: 	# validation passes without improvement: 1
09/16 01:08:20 PM: edges-pos-ontonotes_loss: training: 0.013291 validation: 0.011731
09/16 01:08:20 PM: macro_avg: validation: 0.903918
09/16 01:08:20 PM: micro_avg: validation: 0.000000
09/16 01:08:20 PM: edges-pos-ontonotes_mcc: training: 0.881582 validation: 0.902498
09/16 01:08:20 PM: edges-pos-ontonotes_acc: training: 0.809608 validation: 0.847762
09/16 01:08:20 PM: edges-pos-ontonotes_precision: training: 0.921727 validation: 0.936010
09/16 01:08:20 PM: edges-pos-ontonotes_recall: training: 0.847688 validation: 0.873954
09/16 01:08:20 PM: edges-pos-ontonotes_f1: training: 0.883158 validation: 0.903918
09/16 01:08:20 PM: Global learning rate: 0.0001
09/16 01:08:20 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:08:30 PM: Update 13094: task edges-pos-ontonotes, batch 94 (13094): mcc: 0.8973, acc: 0.8308, precision: 0.9371, recall: 0.8630, f1: 0.8985, edges-pos-ontonotes_loss: 0.0124
09/16 01:08:40 PM: Update 13198: task edges-pos-ontonotes, batch 198 (13198): mcc: 0.8973, acc: 0.8311, precision: 0.9362, recall: 0.8640, f1: 0.8987, edges-pos-ontonotes_loss: 0.0122
09/16 01:08:50 PM: Update 13299: task edges-pos-ontonotes, batch 299 (13299): mcc: 0.8881, acc: 0.8176, precision: 0.9303, recall: 0.8521, f1: 0.8895, edges-pos-ontonotes_loss: 0.0133
09/16 01:09:00 PM: Update 13423: task edges-pos-ontonotes, batch 423 (13423): mcc: 0.8815, acc: 0.8075, precision: 0.9260, recall: 0.8437, f1: 0.8829, edges-pos-ontonotes_loss: 0.0139
09/16 01:09:20 PM: Update 13511: task edges-pos-ontonotes, batch 511 (13511): mcc: 0.8784, acc: 0.8029, precision: 0.9236, recall: 0.8399, f1: 0.8798, edges-pos-ontonotes_loss: 0.0142
09/16 01:09:30 PM: Update 13570: task edges-pos-ontonotes, batch 570 (13570): mcc: 0.8737, acc: 0.7961, precision: 0.9187, recall: 0.8357, f1: 0.8752, edges-pos-ontonotes_loss: 0.0144
09/16 01:09:40 PM: Update 13626: task edges-pos-ontonotes, batch 626 (13626): mcc: 0.8712, acc: 0.7926, precision: 0.9159, recall: 0.8336, f1: 0.8728, edges-pos-ontonotes_loss: 0.0146
09/16 01:09:50 PM: Update 13686: task edges-pos-ontonotes, batch 686 (13686): mcc: 0.8692, acc: 0.7900, precision: 0.9135, recall: 0.8320, f1: 0.8709, edges-pos-ontonotes_loss: 0.0148
09/16 01:10:00 PM: Update 13746: task edges-pos-ontonotes, batch 746 (13746): mcc: 0.8678, acc: 0.7879, precision: 0.9119, recall: 0.8308, f1: 0.8695, edges-pos-ontonotes_loss: 0.0150
09/16 01:10:10 PM: Update 13805: task edges-pos-ontonotes, batch 805 (13805): mcc: 0.8664, acc: 0.7862, precision: 0.9103, recall: 0.8296, f1: 0.8681, edges-pos-ontonotes_loss: 0.0152
09/16 01:10:20 PM: Update 13841: task edges-pos-ontonotes, batch 841 (13841): mcc: 0.8655, acc: 0.7848, precision: 0.9098, recall: 0.8284, f1: 0.8672, edges-pos-ontonotes_loss: 0.0153
09/16 01:10:30 PM: Update 13927: task edges-pos-ontonotes, batch 927 (13927): mcc: 0.8651, acc: 0.7839, precision: 0.9105, recall: 0.8270, f1: 0.8668, edges-pos-ontonotes_loss: 0.0153
09/16 01:10:40 PM: ***** Step 14000 / Validation 14 *****
09/16 01:10:40 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:10:40 PM: Validating...
09/16 01:10:40 PM: Evaluate: task edges-pos-ontonotes, batch 4 (157): mcc: 0.9058, acc: 0.8578, precision: 0.9326, recall: 0.8834, f1: 0.9073, edges-pos-ontonotes_loss: 0.0116
09/16 01:10:50 PM: Evaluate: task edges-pos-ontonotes, batch 70 (157): mcc: 0.9073, acc: 0.8533, precision: 0.9413, recall: 0.8781, f1: 0.9086, edges-pos-ontonotes_loss: 0.0115
09/16 01:11:01 PM: Evaluate: task edges-pos-ontonotes, batch 117 (157): mcc: 0.9068, acc: 0.8539, precision: 0.9350, recall: 0.8832, f1: 0.9083, edges-pos-ontonotes_loss: 0.0114
09/16 01:11:09 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:11:09 PM: Best result seen so far for macro.
09/16 01:11:09 PM: Updating LR scheduler:
09/16 01:11:09 PM: 	Best result seen so far for macro_avg: 0.909
09/16 01:11:09 PM: 	# validation passes without improvement: 0
09/16 01:11:09 PM: edges-pos-ontonotes_loss: training: 0.015298 validation: 0.011338
09/16 01:11:09 PM: macro_avg: validation: 0.908917
09/16 01:11:09 PM: micro_avg: validation: 0.000000
09/16 01:11:09 PM: edges-pos-ontonotes_mcc: training: 0.864691 validation: 0.907311
09/16 01:11:09 PM: edges-pos-ontonotes_acc: training: 0.783193 validation: 0.855562
09/16 01:11:09 PM: edges-pos-ontonotes_precision: training: 0.910597 validation: 0.931710
09/16 01:11:09 PM: edges-pos-ontonotes_recall: training: 0.826168 validation: 0.887213
09/16 01:11:09 PM: edges-pos-ontonotes_f1: training: 0.866330 validation: 0.908917
09/16 01:11:09 PM: Global learning rate: 0.0001
09/16 01:11:09 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:11:11 PM: Update 14011: task edges-pos-ontonotes, batch 11 (14011): mcc: 0.8676, acc: 0.7852, precision: 0.9260, recall: 0.8176, f1: 0.8684, edges-pos-ontonotes_loss: 0.0152
09/16 01:11:21 PM: Update 14105: task edges-pos-ontonotes, batch 105 (14105): mcc: 0.8647, acc: 0.7807, precision: 0.9202, recall: 0.8174, f1: 0.8658, edges-pos-ontonotes_loss: 0.0150
09/16 01:11:31 PM: Update 14155: task edges-pos-ontonotes, batch 155 (14155): mcc: 0.8659, acc: 0.7829, precision: 0.9180, recall: 0.8216, f1: 0.8672, edges-pos-ontonotes_loss: 0.0150
09/16 01:11:41 PM: Update 14229: task edges-pos-ontonotes, batch 229 (14229): mcc: 0.8673, acc: 0.7862, precision: 0.9144, recall: 0.8277, f1: 0.8689, edges-pos-ontonotes_loss: 0.0149
09/16 01:11:51 PM: Update 14297: task edges-pos-ontonotes, batch 297 (14297): mcc: 0.8671, acc: 0.7863, precision: 0.9122, recall: 0.8293, f1: 0.8688, edges-pos-ontonotes_loss: 0.0150
09/16 01:12:01 PM: Update 14369: task edges-pos-ontonotes, batch 369 (14369): mcc: 0.8680, acc: 0.7878, precision: 0.9118, recall: 0.8313, f1: 0.8697, edges-pos-ontonotes_loss: 0.0149
09/16 01:12:11 PM: Update 14442: task edges-pos-ontonotes, batch 442 (14442): mcc: 0.8689, acc: 0.7891, precision: 0.9120, recall: 0.8327, f1: 0.8705, edges-pos-ontonotes_loss: 0.0148
09/16 01:12:21 PM: Update 14483: task edges-pos-ontonotes, batch 483 (14483): mcc: 0.8678, acc: 0.7878, precision: 0.9104, recall: 0.8322, f1: 0.8696, edges-pos-ontonotes_loss: 0.0148
09/16 01:12:31 PM: Update 14543: task edges-pos-ontonotes, batch 543 (14543): mcc: 0.8668, acc: 0.7865, precision: 0.9090, recall: 0.8316, f1: 0.8686, edges-pos-ontonotes_loss: 0.0150
09/16 01:12:42 PM: Update 14603: task edges-pos-ontonotes, batch 603 (14603): mcc: 0.8660, acc: 0.7857, precision: 0.9078, recall: 0.8313, f1: 0.8679, edges-pos-ontonotes_loss: 0.0152
09/16 01:12:52 PM: Update 14659: task edges-pos-ontonotes, batch 659 (14659): mcc: 0.8661, acc: 0.7859, precision: 0.9074, recall: 0.8318, f1: 0.8680, edges-pos-ontonotes_loss: 0.0152
09/16 01:13:02 PM: Update 14715: task edges-pos-ontonotes, batch 715 (14715): mcc: 0.8661, acc: 0.7860, precision: 0.9071, recall: 0.8320, f1: 0.8679, edges-pos-ontonotes_loss: 0.0152
09/16 01:13:12 PM: Update 14768: task edges-pos-ontonotes, batch 768 (14768): mcc: 0.8661, acc: 0.7861, precision: 0.9070, recall: 0.8322, f1: 0.8680, edges-pos-ontonotes_loss: 0.0152
09/16 01:13:22 PM: Update 14810: task edges-pos-ontonotes, batch 810 (14810): mcc: 0.8661, acc: 0.7862, precision: 0.9067, recall: 0.8324, f1: 0.8680, edges-pos-ontonotes_loss: 0.0152
09/16 01:13:32 PM: Update 14853: task edges-pos-ontonotes, batch 853 (14853): mcc: 0.8662, acc: 0.7863, precision: 0.9067, recall: 0.8326, f1: 0.8681, edges-pos-ontonotes_loss: 0.0152
09/16 01:13:42 PM: Update 14900: task edges-pos-ontonotes, batch 900 (14900): mcc: 0.8664, acc: 0.7866, precision: 0.9067, recall: 0.8329, f1: 0.8682, edges-pos-ontonotes_loss: 0.0152
09/16 01:13:52 PM: Update 14940: task edges-pos-ontonotes, batch 940 (14940): mcc: 0.8666, acc: 0.7871, precision: 0.9068, recall: 0.8333, f1: 0.8685, edges-pos-ontonotes_loss: 0.0152
09/16 01:14:03 PM: Update 14996: task edges-pos-ontonotes, batch 996 (14996): mcc: 0.8669, acc: 0.7875, precision: 0.9069, recall: 0.8337, f1: 0.8687, edges-pos-ontonotes_loss: 0.0152
09/16 01:14:03 PM: ***** Step 15000 / Validation 15 *****
09/16 01:14:03 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:14:03 PM: Validating...
09/16 01:14:13 PM: Evaluate: task edges-pos-ontonotes, batch 63 (157): mcc: 0.9048, acc: 0.8482, precision: 0.9477, recall: 0.8674, f1: 0.9058, edges-pos-ontonotes_loss: 0.0117
09/16 01:14:23 PM: Evaluate: task edges-pos-ontonotes, batch 109 (157): mcc: 0.9088, acc: 0.8552, precision: 0.9460, recall: 0.8765, f1: 0.9099, edges-pos-ontonotes_loss: 0.0112
09/16 01:14:33 PM: Evaluate: task edges-pos-ontonotes, batch 154 (157): mcc: 0.9093, acc: 0.8575, precision: 0.9420, recall: 0.8812, f1: 0.9106, edges-pos-ontonotes_loss: 0.0110
09/16 01:14:33 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:14:33 PM: Best result seen so far for macro.
09/16 01:14:33 PM: Updating LR scheduler:
09/16 01:14:33 PM: 	Best result seen so far for macro_avg: 0.911
09/16 01:14:33 PM: 	# validation passes without improvement: 0
09/16 01:14:33 PM: edges-pos-ontonotes_loss: training: 0.015209 validation: 0.011003
09/16 01:14:33 PM: macro_avg: validation: 0.910793
09/16 01:14:33 PM: micro_avg: validation: 0.000000
09/16 01:14:33 PM: edges-pos-ontonotes_mcc: training: 0.866915 validation: 0.909483
09/16 01:14:33 PM: edges-pos-ontonotes_acc: training: 0.787585 validation: 0.857826
09/16 01:14:33 PM: edges-pos-ontonotes_precision: training: 0.906926 validation: 0.942125
09/16 01:14:33 PM: edges-pos-ontonotes_recall: training: 0.833729 validation: 0.881478
09/16 01:14:33 PM: edges-pos-ontonotes_f1: training: 0.868788 validation: 0.910793
09/16 01:14:33 PM: Global learning rate: 0.0001
09/16 01:14:33 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:14:43 PM: Update 15047: task edges-pos-ontonotes, batch 47 (15047): mcc: 0.8709, acc: 0.7953, precision: 0.9078, recall: 0.8405, f1: 0.8729, edges-pos-ontonotes_loss: 0.0150
09/16 01:15:04 PM: Update 15093: task edges-pos-ontonotes, batch 93 (15093): mcc: 0.8707, acc: 0.7954, precision: 0.9090, recall: 0.8389, f1: 0.8726, edges-pos-ontonotes_loss: 0.0153
09/16 01:15:14 PM: Update 15142: task edges-pos-ontonotes, batch 142 (15142): mcc: 0.8703, acc: 0.7949, precision: 0.9094, recall: 0.8379, f1: 0.8722, edges-pos-ontonotes_loss: 0.0153
09/16 01:15:24 PM: Update 15176: task edges-pos-ontonotes, batch 176 (15176): mcc: 0.8713, acc: 0.7963, precision: 0.9101, recall: 0.8391, f1: 0.8732, edges-pos-ontonotes_loss: 0.0152
09/16 01:15:34 PM: Update 15210: task edges-pos-ontonotes, batch 210 (15210): mcc: 0.8720, acc: 0.7975, precision: 0.9106, recall: 0.8399, f1: 0.8738, edges-pos-ontonotes_loss: 0.0151
09/16 01:15:45 PM: Update 15261: task edges-pos-ontonotes, batch 261 (15261): mcc: 0.8718, acc: 0.7972, precision: 0.9104, recall: 0.8398, f1: 0.8737, edges-pos-ontonotes_loss: 0.0150
09/16 01:15:55 PM: Update 15316: task edges-pos-ontonotes, batch 316 (15316): mcc: 0.8724, acc: 0.7980, precision: 0.9107, recall: 0.8406, f1: 0.8742, edges-pos-ontonotes_loss: 0.0149
09/16 01:16:05 PM: Update 15374: task edges-pos-ontonotes, batch 374 (15374): mcc: 0.8730, acc: 0.7989, precision: 0.9114, recall: 0.8412, f1: 0.8749, edges-pos-ontonotes_loss: 0.0150
09/16 01:16:16 PM: Update 15406: task edges-pos-ontonotes, batch 406 (15406): mcc: 0.8731, acc: 0.7991, precision: 0.9117, recall: 0.8411, f1: 0.8750, edges-pos-ontonotes_loss: 0.0149
09/16 01:16:26 PM: Update 15445: task edges-pos-ontonotes, batch 445 (15445): mcc: 0.8731, acc: 0.7991, precision: 0.9115, recall: 0.8412, f1: 0.8749, edges-pos-ontonotes_loss: 0.0150
09/16 01:16:36 PM: Update 15485: task edges-pos-ontonotes, batch 485 (15485): mcc: 0.8733, acc: 0.7994, precision: 0.9116, recall: 0.8414, f1: 0.8751, edges-pos-ontonotes_loss: 0.0150
09/16 01:16:46 PM: Update 15525: task edges-pos-ontonotes, batch 525 (15525): mcc: 0.8734, acc: 0.7998, precision: 0.9117, recall: 0.8416, f1: 0.8752, edges-pos-ontonotes_loss: 0.0149
09/16 01:16:56 PM: Update 15574: task edges-pos-ontonotes, batch 574 (15574): mcc: 0.8738, acc: 0.8003, precision: 0.9119, recall: 0.8421, f1: 0.8756, edges-pos-ontonotes_loss: 0.0149
09/16 01:17:06 PM: Update 15610: task edges-pos-ontonotes, batch 610 (15610): mcc: 0.8738, acc: 0.8004, precision: 0.9120, recall: 0.8420, f1: 0.8756, edges-pos-ontonotes_loss: 0.0149
09/16 01:17:17 PM: Update 15653: task edges-pos-ontonotes, batch 653 (15653): mcc: 0.8741, acc: 0.8008, precision: 0.9121, recall: 0.8424, f1: 0.8759, edges-pos-ontonotes_loss: 0.0149
09/16 01:17:27 PM: Update 15701: task edges-pos-ontonotes, batch 701 (15701): mcc: 0.8741, acc: 0.8008, precision: 0.9123, recall: 0.8423, f1: 0.8759, edges-pos-ontonotes_loss: 0.0149
09/16 01:17:37 PM: Update 15740: task edges-pos-ontonotes, batch 740 (15740): mcc: 0.8739, acc: 0.8005, precision: 0.9121, recall: 0.8421, f1: 0.8757, edges-pos-ontonotes_loss: 0.0149
09/16 01:17:47 PM: Update 15790: task edges-pos-ontonotes, batch 790 (15790): mcc: 0.8740, acc: 0.8007, precision: 0.9123, recall: 0.8422, f1: 0.8758, edges-pos-ontonotes_loss: 0.0148
09/16 01:17:57 PM: Update 15838: task edges-pos-ontonotes, batch 838 (15838): mcc: 0.8742, acc: 0.8009, precision: 0.9124, recall: 0.8424, f1: 0.8760, edges-pos-ontonotes_loss: 0.0147
09/16 01:18:07 PM: Update 15895: task edges-pos-ontonotes, batch 895 (15895): mcc: 0.8745, acc: 0.8013, precision: 0.9127, recall: 0.8428, f1: 0.8763, edges-pos-ontonotes_loss: 0.0146
09/16 01:18:17 PM: Update 15966: task edges-pos-ontonotes, batch 966 (15966): mcc: 0.8751, acc: 0.8020, precision: 0.9131, recall: 0.8434, f1: 0.8769, edges-pos-ontonotes_loss: 0.0145
09/16 01:18:22 PM: ***** Step 16000 / Validation 16 *****
09/16 01:18:22 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:18:22 PM: Validating...
09/16 01:18:27 PM: Evaluate: task edges-pos-ontonotes, batch 36 (157): mcc: 0.8973, acc: 0.8373, precision: 0.9434, recall: 0.8573, f1: 0.8983, edges-pos-ontonotes_loss: 0.0122
09/16 01:18:37 PM: Evaluate: task edges-pos-ontonotes, batch 99 (157): mcc: 0.9064, acc: 0.8520, precision: 0.9433, recall: 0.8745, f1: 0.9076, edges-pos-ontonotes_loss: 0.0114
09/16 01:18:48 PM: Evaluate: task edges-pos-ontonotes, batch 144 (157): mcc: 0.9079, acc: 0.8555, precision: 0.9387, recall: 0.8816, f1: 0.9093, edges-pos-ontonotes_loss: 0.0111
09/16 01:18:50 PM: Updating LR scheduler:
09/16 01:18:50 PM: 	Best result seen so far for macro_avg: 0.911
09/16 01:18:50 PM: 	# validation passes without improvement: 1
09/16 01:18:50 PM: edges-pos-ontonotes_loss: training: 0.014407 validation: 0.011021
09/16 01:18:50 PM: macro_avg: validation: 0.910567
09/16 01:18:50 PM: micro_avg: validation: 0.000000
09/16 01:18:50 PM: edges-pos-ontonotes_mcc: training: 0.875293 validation: 0.909162
09/16 01:18:50 PM: edges-pos-ontonotes_acc: training: 0.802277 validation: 0.857879
09/16 01:18:50 PM: edges-pos-ontonotes_precision: training: 0.913311 validation: 0.939155
09/16 01:18:50 PM: edges-pos-ontonotes_recall: training: 0.843623 validation: 0.883668
09/16 01:18:50 PM: edges-pos-ontonotes_f1: training: 0.877085 validation: 0.910567
09/16 01:18:50 PM: Global learning rate: 0.0001
09/16 01:18:50 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:18:58 PM: Update 16037: task edges-pos-ontonotes, batch 37 (16037): mcc: 0.8815, acc: 0.8101, precision: 0.9151, recall: 0.8538, f1: 0.8834, edges-pos-ontonotes_loss: 0.0128
09/16 01:19:08 PM: Update 16106: task edges-pos-ontonotes, batch 106 (16106): mcc: 0.8944, acc: 0.8272, precision: 0.9281, recall: 0.8659, f1: 0.8959, edges-pos-ontonotes_loss: 0.0119
09/16 01:19:18 PM: Update 16171: task edges-pos-ontonotes, batch 171 (16171): mcc: 0.8982, acc: 0.8321, precision: 0.9319, recall: 0.8696, f1: 0.8997, edges-pos-ontonotes_loss: 0.0116
09/16 01:19:28 PM: Update 16242: task edges-pos-ontonotes, batch 242 (16242): mcc: 0.9002, acc: 0.8353, precision: 0.9336, recall: 0.8719, f1: 0.9017, edges-pos-ontonotes_loss: 0.0114
09/16 01:19:38 PM: Update 16308: task edges-pos-ontonotes, batch 308 (16308): mcc: 0.9018, acc: 0.8374, precision: 0.9349, recall: 0.8736, f1: 0.9032, edges-pos-ontonotes_loss: 0.0113
09/16 01:19:48 PM: Update 16365: task edges-pos-ontonotes, batch 365 (16365): mcc: 0.9014, acc: 0.8365, precision: 0.9351, recall: 0.8726, f1: 0.9028, edges-pos-ontonotes_loss: 0.0114
09/16 01:19:58 PM: Update 16442: task edges-pos-ontonotes, batch 442 (16442): mcc: 0.9009, acc: 0.8359, precision: 0.9356, recall: 0.8714, f1: 0.9023, edges-pos-ontonotes_loss: 0.0114
09/16 01:20:08 PM: Update 16523: task edges-pos-ontonotes, batch 523 (16523): mcc: 0.9007, acc: 0.8356, precision: 0.9359, recall: 0.8708, f1: 0.9021, edges-pos-ontonotes_loss: 0.0115
09/16 01:20:18 PM: Update 16603: task edges-pos-ontonotes, batch 603 (16603): mcc: 0.9008, acc: 0.8359, precision: 0.9359, recall: 0.8709, f1: 0.9022, edges-pos-ontonotes_loss: 0.0115
09/16 01:20:28 PM: Update 16673: task edges-pos-ontonotes, batch 673 (16673): mcc: 0.9003, acc: 0.8353, precision: 0.9357, recall: 0.8701, f1: 0.9017, edges-pos-ontonotes_loss: 0.0116
09/16 01:20:38 PM: Update 16778: task edges-pos-ontonotes, batch 778 (16778): mcc: 0.8975, acc: 0.8311, precision: 0.9340, recall: 0.8663, f1: 0.8989, edges-pos-ontonotes_loss: 0.0120
09/16 01:20:48 PM: Update 16892: task edges-pos-ontonotes, batch 892 (16892): mcc: 0.8946, acc: 0.8269, precision: 0.9322, recall: 0.8626, f1: 0.8960, edges-pos-ontonotes_loss: 0.0124
09/16 01:20:59 PM: Update 16971: task edges-pos-ontonotes, batch 971 (16971): mcc: 0.8930, acc: 0.8245, precision: 0.9310, recall: 0.8606, f1: 0.8944, edges-pos-ontonotes_loss: 0.0126
09/16 01:21:05 PM: ***** Step 17000 / Validation 17 *****
09/16 01:21:05 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:21:05 PM: Validating...
09/16 01:21:09 PM: Evaluate: task edges-pos-ontonotes, batch 28 (157): mcc: 0.8941, acc: 0.8310, precision: 0.9407, recall: 0.8538, f1: 0.8952, edges-pos-ontonotes_loss: 0.0123
09/16 01:21:20 PM: Evaluate: task edges-pos-ontonotes, batch 93 (157): mcc: 0.9048, acc: 0.8490, precision: 0.9430, recall: 0.8717, f1: 0.9060, edges-pos-ontonotes_loss: 0.0114
09/16 01:21:30 PM: Evaluate: task edges-pos-ontonotes, batch 139 (157): mcc: 0.9048, acc: 0.8501, precision: 0.9352, recall: 0.8791, f1: 0.9063, edges-pos-ontonotes_loss: 0.0114
09/16 01:21:33 PM: Updating LR scheduler:
09/16 01:21:33 PM: 	Best result seen so far for macro_avg: 0.911
09/16 01:21:33 PM: 	# validation passes without improvement: 2
09/16 01:21:33 PM: edges-pos-ontonotes_loss: training: 0.012693 validation: 0.011276
09/16 01:21:33 PM: macro_avg: validation: 0.907460
09/16 01:21:33 PM: micro_avg: validation: 0.000000
09/16 01:21:33 PM: edges-pos-ontonotes_mcc: training: 0.890702 validation: 0.905953
09/16 01:21:33 PM: edges-pos-ontonotes_acc: training: 0.821281 validation: 0.852577
09/16 01:21:33 PM: edges-pos-ontonotes_precision: training: 0.928670 validation: 0.934771
09/16 01:21:33 PM: edges-pos-ontonotes_recall: training: 0.858463 validation: 0.881700
09/16 01:21:33 PM: edges-pos-ontonotes_f1: training: 0.892188 validation: 0.907460
09/16 01:21:33 PM: Global learning rate: 0.0001
09/16 01:21:33 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:21:40 PM: Update 17035: task edges-pos-ontonotes, batch 35 (17035): mcc: 0.8628, acc: 0.7813, precision: 0.9018, recall: 0.8308, f1: 0.8648, edges-pos-ontonotes_loss: 0.0161
09/16 01:21:50 PM: Update 17076: task edges-pos-ontonotes, batch 76 (17076): mcc: 0.8616, acc: 0.7790, precision: 0.9006, recall: 0.8296, f1: 0.8636, edges-pos-ontonotes_loss: 0.0162
09/16 01:22:00 PM: Update 17122: task edges-pos-ontonotes, batch 122 (17122): mcc: 0.8601, acc: 0.7764, precision: 0.9000, recall: 0.8272, f1: 0.8621, edges-pos-ontonotes_loss: 0.0165
09/16 01:22:10 PM: Update 17172: task edges-pos-ontonotes, batch 172 (17172): mcc: 0.8610, acc: 0.7778, precision: 0.9010, recall: 0.8280, f1: 0.8629, edges-pos-ontonotes_loss: 0.0163
09/16 01:22:20 PM: Update 17234: task edges-pos-ontonotes, batch 234 (17234): mcc: 0.8616, acc: 0.7789, precision: 0.9017, recall: 0.8286, f1: 0.8636, edges-pos-ontonotes_loss: 0.0164
09/16 01:22:30 PM: Update 17279: task edges-pos-ontonotes, batch 279 (17279): mcc: 0.8616, acc: 0.7792, precision: 0.9018, recall: 0.8285, f1: 0.8636, edges-pos-ontonotes_loss: 0.0164
09/16 01:22:48 PM: Update 17301: task edges-pos-ontonotes, batch 301 (17301): mcc: 0.8610, acc: 0.7782, precision: 0.9016, recall: 0.8275, f1: 0.8629, edges-pos-ontonotes_loss: 0.0165
09/16 01:22:58 PM: Update 17387: task edges-pos-ontonotes, batch 387 (17387): mcc: 0.8615, acc: 0.7786, precision: 0.9037, recall: 0.8264, f1: 0.8633, edges-pos-ontonotes_loss: 0.0162
09/16 01:23:08 PM: Update 17466: task edges-pos-ontonotes, batch 466 (17466): mcc: 0.8620, acc: 0.7793, precision: 0.9053, recall: 0.8260, f1: 0.8639, edges-pos-ontonotes_loss: 0.0160
09/16 01:23:18 PM: Update 17533: task edges-pos-ontonotes, batch 533 (17533): mcc: 0.8623, acc: 0.7796, precision: 0.9061, recall: 0.8259, f1: 0.8641, edges-pos-ontonotes_loss: 0.0158
09/16 01:23:28 PM: Update 17594: task edges-pos-ontonotes, batch 594 (17594): mcc: 0.8627, acc: 0.7801, precision: 0.9067, recall: 0.8260, f1: 0.8645, edges-pos-ontonotes_loss: 0.0157
09/16 01:23:38 PM: Update 17654: task edges-pos-ontonotes, batch 654 (17654): mcc: 0.8635, acc: 0.7812, precision: 0.9067, recall: 0.8274, f1: 0.8653, edges-pos-ontonotes_loss: 0.0156
09/16 01:23:48 PM: Update 17711: task edges-pos-ontonotes, batch 711 (17711): mcc: 0.8642, acc: 0.7824, precision: 0.9070, recall: 0.8286, f1: 0.8660, edges-pos-ontonotes_loss: 0.0155
09/16 01:23:59 PM: Update 17768: task edges-pos-ontonotes, batch 768 (17768): mcc: 0.8649, acc: 0.7833, precision: 0.9074, recall: 0.8295, f1: 0.8667, edges-pos-ontonotes_loss: 0.0154
09/16 01:24:09 PM: Update 17816: task edges-pos-ontonotes, batch 816 (17816): mcc: 0.8655, acc: 0.7841, precision: 0.9075, recall: 0.8304, f1: 0.8673, edges-pos-ontonotes_loss: 0.0154
09/16 01:24:19 PM: Update 17863: task edges-pos-ontonotes, batch 863 (17863): mcc: 0.8662, acc: 0.7851, precision: 0.9079, recall: 0.8314, f1: 0.8680, edges-pos-ontonotes_loss: 0.0153
09/16 01:24:29 PM: Update 17917: task edges-pos-ontonotes, batch 917 (17917): mcc: 0.8666, acc: 0.7857, precision: 0.9081, recall: 0.8321, f1: 0.8684, edges-pos-ontonotes_loss: 0.0152
09/16 01:24:39 PM: Update 17944: task edges-pos-ontonotes, batch 944 (17944): mcc: 0.8663, acc: 0.7855, precision: 0.9076, recall: 0.8320, f1: 0.8681, edges-pos-ontonotes_loss: 0.0153
09/16 01:24:50 PM: Update 17985: task edges-pos-ontonotes, batch 985 (17985): mcc: 0.8662, acc: 0.7854, precision: 0.9072, recall: 0.8320, f1: 0.8680, edges-pos-ontonotes_loss: 0.0153
09/16 01:24:53 PM: ***** Step 18000 / Validation 18 *****
09/16 01:24:53 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:24:53 PM: Validating...
09/16 01:25:00 PM: Evaluate: task edges-pos-ontonotes, batch 41 (157): mcc: 0.9025, acc: 0.8440, precision: 0.9496, recall: 0.8614, f1: 0.9033, edges-pos-ontonotes_loss: 0.0116
09/16 01:25:10 PM: Evaluate: task edges-pos-ontonotes, batch 102 (157): mcc: 0.9113, acc: 0.8585, precision: 0.9491, recall: 0.8784, f1: 0.9124, edges-pos-ontonotes_loss: 0.0107
09/16 01:25:20 PM: Evaluate: task edges-pos-ontonotes, batch 147 (157): mcc: 0.9102, acc: 0.8582, precision: 0.9434, recall: 0.8816, f1: 0.9114, edges-pos-ontonotes_loss: 0.0108
09/16 01:25:22 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:25:22 PM: Best result seen so far for macro.
09/16 01:25:22 PM: Updating LR scheduler:
09/16 01:25:22 PM: 	Best result seen so far for macro_avg: 0.912
09/16 01:25:22 PM: 	# validation passes without improvement: 0
09/16 01:25:22 PM: edges-pos-ontonotes_loss: training: 0.015304 validation: 0.010715
09/16 01:25:22 PM: macro_avg: validation: 0.912151
09/16 01:25:22 PM: micro_avg: validation: 0.000000
09/16 01:25:22 PM: edges-pos-ontonotes_mcc: training: 0.866055 validation: 0.910869
09/16 01:25:22 PM: edges-pos-ontonotes_acc: training: 0.785272 validation: 0.859593
09/16 01:25:22 PM: edges-pos-ontonotes_precision: training: 0.907063 validation: 0.943497
09/16 01:25:22 PM: edges-pos-ontonotes_recall: training: 0.831981 validation: 0.882822
09/16 01:25:22 PM: edges-pos-ontonotes_f1: training: 0.867901 validation: 0.912151
09/16 01:25:22 PM: Global learning rate: 0.0001
09/16 01:25:22 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:25:30 PM: Update 18042: task edges-pos-ontonotes, batch 42 (18042): mcc: 0.8666, acc: 0.7876, precision: 0.9040, recall: 0.8360, f1: 0.8686, edges-pos-ontonotes_loss: 0.0151
09/16 01:25:40 PM: Update 18085: task edges-pos-ontonotes, batch 85 (18085): mcc: 0.8660, acc: 0.7876, precision: 0.9020, recall: 0.8365, f1: 0.8680, edges-pos-ontonotes_loss: 0.0156
09/16 01:25:50 PM: Update 18125: task edges-pos-ontonotes, batch 125 (18125): mcc: 0.8667, acc: 0.7883, precision: 0.9025, recall: 0.8373, f1: 0.8687, edges-pos-ontonotes_loss: 0.0155
09/16 01:26:00 PM: Update 18167: task edges-pos-ontonotes, batch 167 (18167): mcc: 0.8672, acc: 0.7887, precision: 0.9030, recall: 0.8378, f1: 0.8692, edges-pos-ontonotes_loss: 0.0154
09/16 01:26:11 PM: Update 18212: task edges-pos-ontonotes, batch 212 (18212): mcc: 0.8680, acc: 0.7900, precision: 0.9041, recall: 0.8384, f1: 0.8700, edges-pos-ontonotes_loss: 0.0153
09/16 01:26:21 PM: Update 18241: task edges-pos-ontonotes, batch 241 (18241): mcc: 0.8677, acc: 0.7893, precision: 0.9042, recall: 0.8377, f1: 0.8697, edges-pos-ontonotes_loss: 0.0154
09/16 01:26:31 PM: Update 18285: task edges-pos-ontonotes, batch 285 (18285): mcc: 0.8684, acc: 0.7904, precision: 0.9048, recall: 0.8385, f1: 0.8704, edges-pos-ontonotes_loss: 0.0153
09/16 01:26:41 PM: Update 18338: task edges-pos-ontonotes, batch 338 (18338): mcc: 0.8687, acc: 0.7909, precision: 0.9050, recall: 0.8388, f1: 0.8707, edges-pos-ontonotes_loss: 0.0153
09/16 01:26:52 PM: Update 18388: task edges-pos-ontonotes, batch 388 (18388): mcc: 0.8692, acc: 0.7921, precision: 0.9054, recall: 0.8395, f1: 0.8712, edges-pos-ontonotes_loss: 0.0152
09/16 01:27:02 PM: Update 18444: task edges-pos-ontonotes, batch 444 (18444): mcc: 0.8697, acc: 0.7928, precision: 0.9060, recall: 0.8399, f1: 0.8717, edges-pos-ontonotes_loss: 0.0152
09/16 01:27:12 PM: Update 18481: task edges-pos-ontonotes, batch 481 (18481): mcc: 0.8701, acc: 0.7936, precision: 0.9063, recall: 0.8404, f1: 0.8721, edges-pos-ontonotes_loss: 0.0151
09/16 01:27:22 PM: Update 18524: task edges-pos-ontonotes, batch 524 (18524): mcc: 0.8703, acc: 0.7938, precision: 0.9065, recall: 0.8406, f1: 0.8723, edges-pos-ontonotes_loss: 0.0151
09/16 01:27:33 PM: Update 18553: task edges-pos-ontonotes, batch 553 (18553): mcc: 0.8703, acc: 0.7940, precision: 0.9065, recall: 0.8406, f1: 0.8723, edges-pos-ontonotes_loss: 0.0151
09/16 01:27:43 PM: Update 18594: task edges-pos-ontonotes, batch 594 (18594): mcc: 0.8706, acc: 0.7946, precision: 0.9068, recall: 0.8408, f1: 0.8726, edges-pos-ontonotes_loss: 0.0150
09/16 01:27:53 PM: Update 18634: task edges-pos-ontonotes, batch 634 (18634): mcc: 0.8708, acc: 0.7950, precision: 0.9070, recall: 0.8411, f1: 0.8728, edges-pos-ontonotes_loss: 0.0150
09/16 01:28:03 PM: Update 18677: task edges-pos-ontonotes, batch 677 (18677): mcc: 0.8712, acc: 0.7956, precision: 0.9074, recall: 0.8414, f1: 0.8731, edges-pos-ontonotes_loss: 0.0150
09/16 01:28:13 PM: Update 18720: task edges-pos-ontonotes, batch 720 (18720): mcc: 0.8716, acc: 0.7962, precision: 0.9077, recall: 0.8418, f1: 0.8735, edges-pos-ontonotes_loss: 0.0150
09/16 01:28:23 PM: Update 18761: task edges-pos-ontonotes, batch 761 (18761): mcc: 0.8718, acc: 0.7966, precision: 0.9079, recall: 0.8422, f1: 0.8738, edges-pos-ontonotes_loss: 0.0149
09/16 01:28:34 PM: Update 18801: task edges-pos-ontonotes, batch 801 (18801): mcc: 0.8721, acc: 0.7971, precision: 0.9081, recall: 0.8425, f1: 0.8741, edges-pos-ontonotes_loss: 0.0150
09/16 01:28:44 PM: Update 18837: task edges-pos-ontonotes, batch 837 (18837): mcc: 0.8724, acc: 0.7975, precision: 0.9083, recall: 0.8428, f1: 0.8743, edges-pos-ontonotes_loss: 0.0149
09/16 01:28:54 PM: Update 18871: task edges-pos-ontonotes, batch 871 (18871): mcc: 0.8724, acc: 0.7977, precision: 0.9084, recall: 0.8428, f1: 0.8744, edges-pos-ontonotes_loss: 0.0149
09/16 01:29:04 PM: Update 18927: task edges-pos-ontonotes, batch 927 (18927): mcc: 0.8727, acc: 0.7981, precision: 0.9087, recall: 0.8430, f1: 0.8746, edges-pos-ontonotes_loss: 0.0149
09/16 01:29:14 PM: Update 18975: task edges-pos-ontonotes, batch 975 (18975): mcc: 0.8729, acc: 0.7984, precision: 0.9089, recall: 0.8432, f1: 0.8748, edges-pos-ontonotes_loss: 0.0149
09/16 01:29:18 PM: ***** Step 19000 / Validation 19 *****
09/16 01:29:18 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:29:18 PM: Validating...
09/16 01:29:24 PM: Evaluate: task edges-pos-ontonotes, batch 40 (157): mcc: 0.9029, acc: 0.8450, precision: 0.9449, recall: 0.8664, f1: 0.9040, edges-pos-ontonotes_loss: 0.0118
09/16 01:29:34 PM: Evaluate: task edges-pos-ontonotes, batch 101 (157): mcc: 0.9104, acc: 0.8581, precision: 0.9446, recall: 0.8808, f1: 0.9116, edges-pos-ontonotes_loss: 0.0110
09/16 01:29:45 PM: Evaluate: task edges-pos-ontonotes, batch 146 (157): mcc: 0.9108, acc: 0.8603, precision: 0.9398, recall: 0.8862, f1: 0.9122, edges-pos-ontonotes_loss: 0.0108
09/16 01:29:47 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:29:47 PM: Best result seen so far for macro.
09/16 01:29:47 PM: Updating LR scheduler:
09/16 01:29:47 PM: 	Best result seen so far for macro_avg: 0.913
09/16 01:29:47 PM: 	# validation passes without improvement: 0
09/16 01:29:47 PM: edges-pos-ontonotes_loss: training: 0.014878 validation: 0.010728
09/16 01:29:47 PM: macro_avg: validation: 0.913409
09/16 01:29:47 PM: micro_avg: validation: 0.000000
09/16 01:29:47 PM: edges-pos-ontonotes_mcc: training: 0.872933 validation: 0.912008
09/16 01:29:47 PM: edges-pos-ontonotes_acc: training: 0.798554 validation: 0.862281
09/16 01:29:47 PM: edges-pos-ontonotes_precision: training: 0.909001 validation: 0.940248
09/16 01:29:47 PM: edges-pos-ontonotes_recall: training: 0.843176 validation: 0.888060
09/16 01:29:47 PM: edges-pos-ontonotes_f1: training: 0.874852 validation: 0.913409
09/16 01:29:47 PM: Global learning rate: 0.0001
09/16 01:29:47 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:29:55 PM: Update 19038: task edges-pos-ontonotes, batch 38 (19038): mcc: 0.8823, acc: 0.8137, precision: 0.9169, recall: 0.8535, f1: 0.8841, edges-pos-ontonotes_loss: 0.0140
09/16 01:30:05 PM: Update 19087: task edges-pos-ontonotes, batch 87 (19087): mcc: 0.8783, acc: 0.8077, precision: 0.9138, recall: 0.8489, f1: 0.8801, edges-pos-ontonotes_loss: 0.0151
09/16 01:30:15 PM: Update 19140: task edges-pos-ontonotes, batch 140 (19140): mcc: 0.8779, acc: 0.8072, precision: 0.9139, recall: 0.8479, f1: 0.8797, edges-pos-ontonotes_loss: 0.0148
09/16 01:30:35 PM: Update 19179: task edges-pos-ontonotes, batch 179 (19179): mcc: 0.8771, acc: 0.8058, precision: 0.9133, recall: 0.8470, f1: 0.8789, edges-pos-ontonotes_loss: 0.0148
09/16 01:30:45 PM: Update 19234: task edges-pos-ontonotes, batch 234 (19234): mcc: 0.8768, acc: 0.8053, precision: 0.9127, recall: 0.8470, f1: 0.8786, edges-pos-ontonotes_loss: 0.0144
09/16 01:30:55 PM: Update 19285: task edges-pos-ontonotes, batch 285 (19285): mcc: 0.8775, acc: 0.8059, precision: 0.9133, recall: 0.8478, f1: 0.8793, edges-pos-ontonotes_loss: 0.0142
09/16 01:31:05 PM: Update 19338: task edges-pos-ontonotes, batch 338 (19338): mcc: 0.8783, acc: 0.8068, precision: 0.9139, recall: 0.8487, f1: 0.8801, edges-pos-ontonotes_loss: 0.0139
09/16 01:31:15 PM: Update 19387: task edges-pos-ontonotes, batch 387 (19387): mcc: 0.8787, acc: 0.8075, precision: 0.9142, recall: 0.8493, f1: 0.8805, edges-pos-ontonotes_loss: 0.0138
09/16 01:31:25 PM: Update 19438: task edges-pos-ontonotes, batch 438 (19438): mcc: 0.8796, acc: 0.8086, precision: 0.9149, recall: 0.8503, f1: 0.8814, edges-pos-ontonotes_loss: 0.0136
09/16 01:31:36 PM: Update 19498: task edges-pos-ontonotes, batch 498 (19498): mcc: 0.8804, acc: 0.8097, precision: 0.9156, recall: 0.8512, f1: 0.8822, edges-pos-ontonotes_loss: 0.0134
09/16 01:31:46 PM: Update 19588: task edges-pos-ontonotes, batch 588 (19588): mcc: 0.8828, acc: 0.8128, precision: 0.9177, recall: 0.8537, f1: 0.8846, edges-pos-ontonotes_loss: 0.0131
09/16 01:31:56 PM: Update 19655: task edges-pos-ontonotes, batch 655 (19655): mcc: 0.8847, acc: 0.8152, precision: 0.9194, recall: 0.8558, f1: 0.8865, edges-pos-ontonotes_loss: 0.0128
09/16 01:32:06 PM: Update 19734: task edges-pos-ontonotes, batch 734 (19734): mcc: 0.8866, acc: 0.8177, precision: 0.9210, recall: 0.8579, f1: 0.8883, edges-pos-ontonotes_loss: 0.0126
09/16 01:32:16 PM: Update 19804: task edges-pos-ontonotes, batch 804 (19804): mcc: 0.8879, acc: 0.8194, precision: 0.9220, recall: 0.8594, f1: 0.8896, edges-pos-ontonotes_loss: 0.0125
09/16 01:32:26 PM: Update 19891: task edges-pos-ontonotes, batch 891 (19891): mcc: 0.8886, acc: 0.8203, precision: 0.9230, recall: 0.8598, f1: 0.8903, edges-pos-ontonotes_loss: 0.0124
09/16 01:32:36 PM: Update 19988: task edges-pos-ontonotes, batch 988 (19988): mcc: 0.8895, acc: 0.8215, precision: 0.9239, recall: 0.8606, f1: 0.8911, edges-pos-ontonotes_loss: 0.0123
09/16 01:32:37 PM: ***** Step 20000 / Validation 20 *****
09/16 01:32:37 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:32:37 PM: Validating...
09/16 01:32:46 PM: Evaluate: task edges-pos-ontonotes, batch 46 (157): mcc: 0.8987, acc: 0.8389, precision: 0.9461, recall: 0.8575, f1: 0.8996, edges-pos-ontonotes_loss: 0.0120
09/16 01:32:56 PM: Evaluate: task edges-pos-ontonotes, batch 93 (157): mcc: 0.9061, acc: 0.8522, precision: 0.9435, recall: 0.8737, f1: 0.9073, edges-pos-ontonotes_loss: 0.0113
09/16 01:33:07 PM: Evaluate: task edges-pos-ontonotes, batch 128 (157): mcc: 0.9061, acc: 0.8526, precision: 0.9386, recall: 0.8782, f1: 0.9074, edges-pos-ontonotes_loss: 0.0112
09/16 01:33:14 PM: Updating LR scheduler:
09/16 01:33:14 PM: 	Best result seen so far for macro_avg: 0.913
09/16 01:33:14 PM: 	# validation passes without improvement: 1
09/16 01:33:14 PM: edges-pos-ontonotes_loss: training: 0.012263 validation: 0.011050
09/16 01:33:14 PM: macro_avg: validation: 0.909020
09/16 01:33:14 PM: micro_avg: validation: 0.000000
09/16 01:33:14 PM: edges-pos-ontonotes_mcc: training: 0.889577 validation: 0.907576
09/16 01:33:14 PM: edges-pos-ontonotes_acc: training: 0.821571 validation: 0.856122
09/16 01:33:14 PM: edges-pos-ontonotes_precision: training: 0.924035 validation: 0.937369
09/16 01:33:14 PM: edges-pos-ontonotes_recall: training: 0.860662 validation: 0.882335
09/16 01:33:14 PM: edges-pos-ontonotes_f1: training: 0.891224 validation: 0.909020
09/16 01:33:14 PM: Global learning rate: 0.0001
09/16 01:33:14 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:33:17 PM: Update 20035: task edges-pos-ontonotes, batch 35 (20035): mcc: 0.9058, acc: 0.8415, precision: 0.9412, recall: 0.8753, f1: 0.9071, edges-pos-ontonotes_loss: 0.0112
09/16 01:33:27 PM: Update 20103: task edges-pos-ontonotes, batch 103 (20103): mcc: 0.9057, acc: 0.8433, precision: 0.9391, recall: 0.8770, f1: 0.9070, edges-pos-ontonotes_loss: 0.0114
09/16 01:33:37 PM: Update 20196: task edges-pos-ontonotes, batch 196 (20196): mcc: 0.8940, acc: 0.8265, precision: 0.9316, recall: 0.8619, f1: 0.8954, edges-pos-ontonotes_loss: 0.0125
09/16 01:33:47 PM: Update 20298: task edges-pos-ontonotes, batch 298 (20298): mcc: 0.8875, acc: 0.8171, precision: 0.9268, recall: 0.8543, f1: 0.8890, edges-pos-ontonotes_loss: 0.0132
09/16 01:33:57 PM: Update 20414: task edges-pos-ontonotes, batch 414 (20414): mcc: 0.8830, acc: 0.8099, precision: 0.9234, recall: 0.8488, f1: 0.8845, edges-pos-ontonotes_loss: 0.0137
09/16 01:34:07 PM: Update 20468: task edges-pos-ontonotes, batch 468 (20468): mcc: 0.8785, acc: 0.8035, precision: 0.9181, recall: 0.8453, f1: 0.8802, edges-pos-ontonotes_loss: 0.0139
09/16 01:34:17 PM: Update 20516: task edges-pos-ontonotes, batch 516 (20516): mcc: 0.8764, acc: 0.8005, precision: 0.9157, recall: 0.8435, f1: 0.8781, edges-pos-ontonotes_loss: 0.0141
09/16 01:34:27 PM: Update 20559: task edges-pos-ontonotes, batch 559 (20559): mcc: 0.8745, acc: 0.7980, precision: 0.9139, recall: 0.8416, f1: 0.8762, edges-pos-ontonotes_loss: 0.0144
09/16 01:34:37 PM: Update 20607: task edges-pos-ontonotes, batch 607 (20607): mcc: 0.8733, acc: 0.7963, precision: 0.9124, recall: 0.8406, f1: 0.8750, edges-pos-ontonotes_loss: 0.0145
09/16 01:34:47 PM: Update 20651: task edges-pos-ontonotes, batch 651 (20651): mcc: 0.8723, acc: 0.7951, precision: 0.9112, recall: 0.8399, f1: 0.8741, edges-pos-ontonotes_loss: 0.0146
09/16 01:34:58 PM: Update 20696: task edges-pos-ontonotes, batch 696 (20696): mcc: 0.8713, acc: 0.7935, precision: 0.9102, recall: 0.8388, f1: 0.8731, edges-pos-ontonotes_loss: 0.0147
09/16 01:35:08 PM: Update 20734: task edges-pos-ontonotes, batch 734 (20734): mcc: 0.8707, acc: 0.7927, precision: 0.9095, recall: 0.8384, f1: 0.8725, edges-pos-ontonotes_loss: 0.0147
09/16 01:35:18 PM: Update 20768: task edges-pos-ontonotes, batch 768 (20768): mcc: 0.8701, acc: 0.7918, precision: 0.9092, recall: 0.8376, f1: 0.8719, edges-pos-ontonotes_loss: 0.0148
09/16 01:35:28 PM: Update 20839: task edges-pos-ontonotes, batch 839 (20839): mcc: 0.8698, acc: 0.7912, precision: 0.9098, recall: 0.8364, f1: 0.8716, edges-pos-ontonotes_loss: 0.0148
09/16 01:35:38 PM: Update 20903: task edges-pos-ontonotes, batch 903 (20903): mcc: 0.8696, acc: 0.7908, precision: 0.9102, recall: 0.8357, f1: 0.8714, edges-pos-ontonotes_loss: 0.0148
09/16 01:35:48 PM: Update 20976: task edges-pos-ontonotes, batch 976 (20976): mcc: 0.8696, acc: 0.7907, precision: 0.9108, recall: 0.8352, f1: 0.8714, edges-pos-ontonotes_loss: 0.0147
09/16 01:35:52 PM: ***** Step 21000 / Validation 21 *****
09/16 01:35:52 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:35:52 PM: Validating...
09/16 01:35:58 PM: Evaluate: task edges-pos-ontonotes, batch 31 (157): mcc: 0.9041, acc: 0.8489, precision: 0.9407, recall: 0.8726, f1: 0.9054, edges-pos-ontonotes_loss: 0.0113
09/16 01:36:08 PM: Evaluate: task edges-pos-ontonotes, batch 81 (157): mcc: 0.9120, acc: 0.8616, precision: 0.9414, recall: 0.8870, f1: 0.9134, edges-pos-ontonotes_loss: 0.0107
09/16 01:36:18 PM: Evaluate: task edges-pos-ontonotes, batch 121 (157): mcc: 0.9117, acc: 0.8616, precision: 0.9364, recall: 0.8911, f1: 0.9132, edges-pos-ontonotes_loss: 0.0107
09/16 01:36:26 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:36:26 PM: Best result seen so far for macro.
09/16 01:36:26 PM: Updating LR scheduler:
09/16 01:36:26 PM: 	Best result seen so far for macro_avg: 0.913
09/16 01:36:26 PM: 	# validation passes without improvement: 2
09/16 01:36:26 PM: edges-pos-ontonotes_loss: training: 0.014717 validation: 0.010671
09/16 01:36:26 PM: macro_avg: validation: 0.913479
09/16 01:36:26 PM: micro_avg: validation: 0.000000
09/16 01:36:26 PM: edges-pos-ontonotes_mcc: training: 0.869552 validation: 0.911895
09/16 01:36:26 PM: edges-pos-ontonotes_acc: training: 0.790636 validation: 0.862800
09/16 01:36:26 PM: edges-pos-ontonotes_precision: training: 0.910880 validation: 0.933414
09/16 01:36:26 PM: edges-pos-ontonotes_recall: training: 0.835043 validation: 0.894378
09/16 01:36:26 PM: edges-pos-ontonotes_f1: training: 0.871315 validation: 0.913479
09/16 01:36:26 PM: Global learning rate: 0.0001
09/16 01:36:26 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:36:28 PM: Update 21021: task edges-pos-ontonotes, batch 21 (21021): mcc: 0.8732, acc: 0.7924, precision: 0.9254, recall: 0.8286, f1: 0.8743, edges-pos-ontonotes_loss: 0.0140
09/16 01:36:38 PM: Update 21088: task edges-pos-ontonotes, batch 88 (21088): mcc: 0.8713, acc: 0.7920, precision: 0.9145, recall: 0.8350, f1: 0.8729, edges-pos-ontonotes_loss: 0.0144
09/16 01:36:48 PM: Update 21149: task edges-pos-ontonotes, batch 149 (21149): mcc: 0.8722, acc: 0.7946, precision: 0.9108, recall: 0.8401, f1: 0.8740, edges-pos-ontonotes_loss: 0.0143
09/16 01:36:59 PM: Update 21214: task edges-pos-ontonotes, batch 214 (21214): mcc: 0.8736, acc: 0.7966, precision: 0.9109, recall: 0.8427, f1: 0.8754, edges-pos-ontonotes_loss: 0.0143
09/16 01:37:09 PM: Update 21262: task edges-pos-ontonotes, batch 262 (21262): mcc: 0.8736, acc: 0.7965, precision: 0.9105, recall: 0.8430, f1: 0.8755, edges-pos-ontonotes_loss: 0.0142
09/16 01:37:19 PM: Update 21308: task edges-pos-ontonotes, batch 308 (21308): mcc: 0.8740, acc: 0.7973, precision: 0.9107, recall: 0.8437, f1: 0.8759, edges-pos-ontonotes_loss: 0.0142
09/16 01:37:29 PM: Update 21363: task edges-pos-ontonotes, batch 363 (21363): mcc: 0.8742, acc: 0.7975, precision: 0.9107, recall: 0.8440, f1: 0.8761, edges-pos-ontonotes_loss: 0.0142
09/16 01:37:43 PM: Update 21387: task edges-pos-ontonotes, batch 387 (21387): mcc: 0.8740, acc: 0.7972, precision: 0.9106, recall: 0.8437, f1: 0.8759, edges-pos-ontonotes_loss: 0.0142
09/16 01:37:53 PM: Update 21440: task edges-pos-ontonotes, batch 440 (21440): mcc: 0.8728, acc: 0.7958, precision: 0.9089, recall: 0.8429, f1: 0.8747, edges-pos-ontonotes_loss: 0.0143
09/16 01:38:03 PM: Update 21474: task edges-pos-ontonotes, batch 474 (21474): mcc: 0.8723, acc: 0.7952, precision: 0.9083, recall: 0.8426, f1: 0.8742, edges-pos-ontonotes_loss: 0.0144
09/16 01:38:13 PM: Update 21505: task edges-pos-ontonotes, batch 505 (21505): mcc: 0.8715, acc: 0.7943, precision: 0.9075, recall: 0.8419, f1: 0.8735, edges-pos-ontonotes_loss: 0.0145
09/16 01:38:23 PM: Update 21538: task edges-pos-ontonotes, batch 538 (21538): mcc: 0.8715, acc: 0.7944, precision: 0.9073, recall: 0.8421, f1: 0.8735, edges-pos-ontonotes_loss: 0.0145
09/16 01:38:33 PM: Update 21579: task edges-pos-ontonotes, batch 579 (21579): mcc: 0.8712, acc: 0.7939, precision: 0.9071, recall: 0.8417, f1: 0.8731, edges-pos-ontonotes_loss: 0.0146
09/16 01:38:43 PM: Update 21616: task edges-pos-ontonotes, batch 616 (21616): mcc: 0.8713, acc: 0.7941, precision: 0.9071, recall: 0.8419, f1: 0.8733, edges-pos-ontonotes_loss: 0.0147
09/16 01:38:54 PM: Update 21652: task edges-pos-ontonotes, batch 652 (21652): mcc: 0.8712, acc: 0.7940, precision: 0.9070, recall: 0.8418, f1: 0.8732, edges-pos-ontonotes_loss: 0.0147
09/16 01:39:04 PM: Update 21685: task edges-pos-ontonotes, batch 685 (21685): mcc: 0.8713, acc: 0.7941, precision: 0.9069, recall: 0.8420, f1: 0.8733, edges-pos-ontonotes_loss: 0.0147
09/16 01:39:14 PM: Update 21707: task edges-pos-ontonotes, batch 707 (21707): mcc: 0.8712, acc: 0.7941, precision: 0.9069, recall: 0.8419, f1: 0.8732, edges-pos-ontonotes_loss: 0.0147
09/16 01:39:24 PM: Update 21737: task edges-pos-ontonotes, batch 737 (21737): mcc: 0.8711, acc: 0.7939, precision: 0.9067, recall: 0.8418, f1: 0.8731, edges-pos-ontonotes_loss: 0.0147
09/16 01:39:34 PM: Update 21769: task edges-pos-ontonotes, batch 769 (21769): mcc: 0.8713, acc: 0.7942, precision: 0.9067, recall: 0.8421, f1: 0.8732, edges-pos-ontonotes_loss: 0.0147
09/16 01:39:44 PM: Update 21802: task edges-pos-ontonotes, batch 802 (21802): mcc: 0.8714, acc: 0.7945, precision: 0.9067, recall: 0.8423, f1: 0.8733, edges-pos-ontonotes_loss: 0.0147
09/16 01:39:54 PM: Update 21837: task edges-pos-ontonotes, batch 837 (21837): mcc: 0.8715, acc: 0.7948, precision: 0.9068, recall: 0.8426, f1: 0.8735, edges-pos-ontonotes_loss: 0.0147
09/16 01:40:05 PM: Update 21871: task edges-pos-ontonotes, batch 871 (21871): mcc: 0.8717, acc: 0.7953, precision: 0.9068, recall: 0.8428, f1: 0.8737, edges-pos-ontonotes_loss: 0.0147
09/16 01:40:15 PM: Update 21916: task edges-pos-ontonotes, batch 916 (21916): mcc: 0.8719, acc: 0.7957, precision: 0.9071, recall: 0.8431, f1: 0.8739, edges-pos-ontonotes_loss: 0.0146
09/16 01:40:25 PM: Update 21969: task edges-pos-ontonotes, batch 969 (21969): mcc: 0.8722, acc: 0.7961, precision: 0.9072, recall: 0.8434, f1: 0.8742, edges-pos-ontonotes_loss: 0.0147
09/16 01:40:30 PM: ***** Step 22000 / Validation 22 *****
09/16 01:40:30 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:40:30 PM: Validating...
09/16 01:40:35 PM: Evaluate: task edges-pos-ontonotes, batch 27 (157): mcc: 0.9025, acc: 0.8444, precision: 0.9461, recall: 0.8645, f1: 0.9035, edges-pos-ontonotes_loss: 0.0115
09/16 01:40:45 PM: Evaluate: task edges-pos-ontonotes, batch 84 (157): mcc: 0.9118, acc: 0.8590, precision: 0.9491, recall: 0.8792, f1: 0.9128, edges-pos-ontonotes_loss: 0.0108
09/16 01:40:55 PM: Evaluate: task edges-pos-ontonotes, batch 130 (157): mcc: 0.9123, acc: 0.8611, precision: 0.9444, recall: 0.8847, f1: 0.9136, edges-pos-ontonotes_loss: 0.0106
09/16 01:41:01 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:41:01 PM: Best result seen so far for macro.
09/16 01:41:01 PM: Updating LR scheduler:
09/16 01:41:01 PM: 	Best result seen so far for macro_avg: 0.915
09/16 01:41:01 PM: 	# validation passes without improvement: 0
09/16 01:41:01 PM: edges-pos-ontonotes_loss: training: 0.014653 validation: 0.010462
09/16 01:41:01 PM: macro_avg: validation: 0.914926
09/16 01:41:01 PM: micro_avg: validation: 0.000000
09/16 01:41:01 PM: edges-pos-ontonotes_mcc: training: 0.872326 validation: 0.913608
09/16 01:41:01 PM: edges-pos-ontonotes_acc: training: 0.796342 validation: 0.864080
09/16 01:41:01 PM: edges-pos-ontonotes_precision: training: 0.907432 validation: 0.943492
09/16 01:41:01 PM: edges-pos-ontonotes_recall: training: 0.843494 validation: 0.888039
09/16 01:41:01 PM: edges-pos-ontonotes_f1: training: 0.874295 validation: 0.914926
09/16 01:41:01 PM: Global learning rate: 0.0001
09/16 01:41:01 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:41:05 PM: Update 22013: task edges-pos-ontonotes, batch 13 (22013): mcc: 0.8725, acc: 0.7977, precision: 0.9076, recall: 0.8437, f1: 0.8745, edges-pos-ontonotes_loss: 0.0146
09/16 01:41:16 PM: Update 22043: task edges-pos-ontonotes, batch 43 (22043): mcc: 0.8711, acc: 0.7974, precision: 0.9078, recall: 0.8408, f1: 0.8730, edges-pos-ontonotes_loss: 0.0153
09/16 01:41:26 PM: Update 22079: task edges-pos-ontonotes, batch 79 (22079): mcc: 0.8733, acc: 0.8004, precision: 0.9092, recall: 0.8437, f1: 0.8752, edges-pos-ontonotes_loss: 0.0153
09/16 01:41:36 PM: Update 22116: task edges-pos-ontonotes, batch 116 (22116): mcc: 0.8754, acc: 0.8029, precision: 0.9104, recall: 0.8465, f1: 0.8773, edges-pos-ontonotes_loss: 0.0149
09/16 01:41:46 PM: Update 22162: task edges-pos-ontonotes, batch 162 (22162): mcc: 0.8766, acc: 0.8048, precision: 0.9115, recall: 0.8478, f1: 0.8785, edges-pos-ontonotes_loss: 0.0147
09/16 01:41:56 PM: Update 22221: task edges-pos-ontonotes, batch 221 (22221): mcc: 0.8772, acc: 0.8055, precision: 0.9126, recall: 0.8479, f1: 0.8791, edges-pos-ontonotes_loss: 0.0145
09/16 01:42:06 PM: Update 22271: task edges-pos-ontonotes, batch 271 (22271): mcc: 0.8778, acc: 0.8064, precision: 0.9130, recall: 0.8487, f1: 0.8797, edges-pos-ontonotes_loss: 0.0144
09/16 01:42:17 PM: Update 22320: task edges-pos-ontonotes, batch 320 (22320): mcc: 0.8778, acc: 0.8062, precision: 0.9130, recall: 0.8487, f1: 0.8797, edges-pos-ontonotes_loss: 0.0144
09/16 01:42:27 PM: Update 22340: task edges-pos-ontonotes, batch 340 (22340): mcc: 0.8776, acc: 0.8059, precision: 0.9127, recall: 0.8486, f1: 0.8795, edges-pos-ontonotes_loss: 0.0144
09/16 01:42:37 PM: Update 22374: task edges-pos-ontonotes, batch 374 (22374): mcc: 0.8778, acc: 0.8061, precision: 0.9130, recall: 0.8486, f1: 0.8797, edges-pos-ontonotes_loss: 0.0144
09/16 01:42:47 PM: Update 22416: task edges-pos-ontonotes, batch 416 (22416): mcc: 0.8777, acc: 0.8059, precision: 0.9128, recall: 0.8485, f1: 0.8795, edges-pos-ontonotes_loss: 0.0145
09/16 01:42:57 PM: Update 22455: task edges-pos-ontonotes, batch 455 (22455): mcc: 0.8777, acc: 0.8062, precision: 0.9127, recall: 0.8488, f1: 0.8796, edges-pos-ontonotes_loss: 0.0144
09/16 01:43:07 PM: Update 22502: task edges-pos-ontonotes, batch 502 (22502): mcc: 0.8779, acc: 0.8063, precision: 0.9127, recall: 0.8491, f1: 0.8797, edges-pos-ontonotes_loss: 0.0145
09/16 01:43:18 PM: Update 22554: task edges-pos-ontonotes, batch 554 (22554): mcc: 0.8782, acc: 0.8069, precision: 0.9130, recall: 0.8495, f1: 0.8801, edges-pos-ontonotes_loss: 0.0145
09/16 01:43:28 PM: Update 22606: task edges-pos-ontonotes, batch 606 (22606): mcc: 0.8783, acc: 0.8070, precision: 0.9131, recall: 0.8494, f1: 0.8801, edges-pos-ontonotes_loss: 0.0145
09/16 01:43:38 PM: Update 22644: task edges-pos-ontonotes, batch 644 (22644): mcc: 0.8778, acc: 0.8064, precision: 0.9127, recall: 0.8488, f1: 0.8796, edges-pos-ontonotes_loss: 0.0145
09/16 01:43:48 PM: Update 22702: task edges-pos-ontonotes, batch 702 (22702): mcc: 0.8779, acc: 0.8067, precision: 0.9128, recall: 0.8491, f1: 0.8798, edges-pos-ontonotes_loss: 0.0144
09/16 01:43:58 PM: Update 22756: task edges-pos-ontonotes, batch 756 (22756): mcc: 0.8782, acc: 0.8071, precision: 0.9130, recall: 0.8495, f1: 0.8801, edges-pos-ontonotes_loss: 0.0142
09/16 01:44:09 PM: Update 22814: task edges-pos-ontonotes, batch 814 (22814): mcc: 0.8785, acc: 0.8075, precision: 0.9134, recall: 0.8497, f1: 0.8804, edges-pos-ontonotes_loss: 0.0141
09/16 01:44:19 PM: Update 22882: task edges-pos-ontonotes, batch 882 (22882): mcc: 0.8791, acc: 0.8082, precision: 0.9138, recall: 0.8504, f1: 0.8810, edges-pos-ontonotes_loss: 0.0140
09/16 01:44:29 PM: Update 22943: task edges-pos-ontonotes, batch 943 (22943): mcc: 0.8793, acc: 0.8084, precision: 0.9139, recall: 0.8507, f1: 0.8812, edges-pos-ontonotes_loss: 0.0139
09/16 01:44:39 PM: Update 22991: task edges-pos-ontonotes, batch 991 (22991): mcc: 0.8800, acc: 0.8093, precision: 0.9145, recall: 0.8514, f1: 0.8818, edges-pos-ontonotes_loss: 0.0137
09/16 01:44:40 PM: ***** Step 23000 / Validation 23 *****
09/16 01:44:40 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:44:40 PM: Validating...
09/16 01:44:49 PM: Evaluate: task edges-pos-ontonotes, batch 46 (157): mcc: 0.9022, acc: 0.8434, precision: 0.9475, recall: 0.8627, f1: 0.9031, edges-pos-ontonotes_loss: 0.0117
09/16 01:44:59 PM: Evaluate: task edges-pos-ontonotes, batch 93 (157): mcc: 0.9098, acc: 0.8567, precision: 0.9460, recall: 0.8784, f1: 0.9110, edges-pos-ontonotes_loss: 0.0109
09/16 01:45:09 PM: Evaluate: task edges-pos-ontonotes, batch 138 (157): mcc: 0.9115, acc: 0.8604, precision: 0.9423, recall: 0.8852, f1: 0.9129, edges-pos-ontonotes_loss: 0.0107
09/16 01:45:13 PM: Updating LR scheduler:
09/16 01:45:13 PM: 	Best result seen so far for macro_avg: 0.915
09/16 01:45:13 PM: 	# validation passes without improvement: 1
09/16 01:45:13 PM: edges-pos-ontonotes_loss: training: 0.013707 validation: 0.010549
09/16 01:45:13 PM: macro_avg: validation: 0.914125
09/16 01:45:13 PM: micro_avg: validation: 0.000000
09/16 01:45:13 PM: edges-pos-ontonotes_mcc: training: 0.880146 validation: 0.912778
09/16 01:45:13 PM: edges-pos-ontonotes_acc: training: 0.809511 validation: 0.863043
09/16 01:45:13 PM: edges-pos-ontonotes_precision: training: 0.914626 validation: 0.942279
09/16 01:45:13 PM: edges-pos-ontonotes_recall: training: 0.851588 validation: 0.887605
09/16 01:45:13 PM: edges-pos-ontonotes_f1: training: 0.881982 validation: 0.914125
09/16 01:45:13 PM: Global learning rate: 0.0001
09/16 01:45:13 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:45:19 PM: Update 23057: task edges-pos-ontonotes, batch 57 (23057): mcc: 0.9068, acc: 0.8460, precision: 0.9376, recall: 0.8807, f1: 0.9083, edges-pos-ontonotes_loss: 0.0111
09/16 01:45:29 PM: Update 23146: task edges-pos-ontonotes, batch 146 (23146): mcc: 0.9080, acc: 0.8465, precision: 0.9381, recall: 0.8825, f1: 0.9094, edges-pos-ontonotes_loss: 0.0108
09/16 01:45:39 PM: Update 23213: task edges-pos-ontonotes, batch 213 (23213): mcc: 0.9096, acc: 0.8485, precision: 0.9392, recall: 0.8844, f1: 0.9110, edges-pos-ontonotes_loss: 0.0106
09/16 01:45:58 PM: Update 23265: task edges-pos-ontonotes, batch 265 (23265): mcc: 0.9096, acc: 0.8484, precision: 0.9398, recall: 0.8839, f1: 0.9110, edges-pos-ontonotes_loss: 0.0106
09/16 01:46:08 PM: Update 23348: task edges-pos-ontonotes, batch 348 (23348): mcc: 0.9085, acc: 0.8466, precision: 0.9400, recall: 0.8816, f1: 0.9099, edges-pos-ontonotes_loss: 0.0109
09/16 01:46:18 PM: Update 23432: task edges-pos-ontonotes, batch 432 (23432): mcc: 0.9082, acc: 0.8463, precision: 0.9401, recall: 0.8809, f1: 0.9095, edges-pos-ontonotes_loss: 0.0109
09/16 01:46:28 PM: Update 23508: task edges-pos-ontonotes, batch 508 (23508): mcc: 0.9076, acc: 0.8458, precision: 0.9395, recall: 0.8805, f1: 0.9090, edges-pos-ontonotes_loss: 0.0109
09/16 01:46:39 PM: Update 23578: task edges-pos-ontonotes, batch 578 (23578): mcc: 0.9072, acc: 0.8454, precision: 0.9393, recall: 0.8798, f1: 0.9086, edges-pos-ontonotes_loss: 0.0109
09/16 01:46:49 PM: Update 23687: task edges-pos-ontonotes, batch 687 (23687): mcc: 0.9028, acc: 0.8391, precision: 0.9363, recall: 0.8744, f1: 0.9043, edges-pos-ontonotes_loss: 0.0116
09/16 01:46:59 PM: Update 23799: task edges-pos-ontonotes, batch 799 (23799): mcc: 0.8998, acc: 0.8346, precision: 0.9343, recall: 0.8705, f1: 0.9013, edges-pos-ontonotes_loss: 0.0120
09/16 01:47:10 PM: Update 23891: task edges-pos-ontonotes, batch 891 (23891): mcc: 0.8975, acc: 0.8311, precision: 0.9326, recall: 0.8676, f1: 0.8989, edges-pos-ontonotes_loss: 0.0122
09/16 01:47:20 PM: Update 23948: task edges-pos-ontonotes, batch 948 (23948): mcc: 0.8937, acc: 0.8257, precision: 0.9292, recall: 0.8636, f1: 0.8952, edges-pos-ontonotes_loss: 0.0124
09/16 01:47:29 PM: ***** Step 24000 / Validation 24 *****
09/16 01:47:29 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:47:29 PM: Validating...
09/16 01:47:30 PM: Evaluate: task edges-pos-ontonotes, batch 6 (157): mcc: 0.9096, acc: 0.8573, precision: 0.9302, recall: 0.8930, f1: 0.9112, edges-pos-ontonotes_loss: 0.0110
09/16 01:47:40 PM: Evaluate: task edges-pos-ontonotes, batch 75 (157): mcc: 0.9085, acc: 0.8547, precision: 0.9419, recall: 0.8798, f1: 0.9098, edges-pos-ontonotes_loss: 0.0111
09/16 01:47:50 PM: Evaluate: task edges-pos-ontonotes, batch 125 (157): mcc: 0.9073, acc: 0.8536, precision: 0.9342, recall: 0.8849, f1: 0.9089, edges-pos-ontonotes_loss: 0.0110
09/16 01:47:57 PM: Updating LR scheduler:
09/16 01:47:57 PM: 	Best result seen so far for macro_avg: 0.915
09/16 01:47:57 PM: 	# validation passes without improvement: 2
09/16 01:47:57 PM: edges-pos-ontonotes_loss: training: 0.012648 validation: 0.010899
09/16 01:47:57 PM: macro_avg: validation: 0.910192
09/16 01:47:57 PM: micro_avg: validation: 0.000000
09/16 01:47:57 PM: edges-pos-ontonotes_mcc: training: 0.891247 validation: 0.908587
09/16 01:47:57 PM: edges-pos-ontonotes_acc: training: 0.822129 validation: 0.856355
09/16 01:47:57 PM: edges-pos-ontonotes_precision: training: 0.926678 validation: 0.932067
09/16 01:47:57 PM: edges-pos-ontonotes_recall: training: 0.861354 validation: 0.889319
09/16 01:47:57 PM: edges-pos-ontonotes_f1: training: 0.892823 validation: 0.910192
09/16 01:47:57 PM: Global learning rate: 0.0001
09/16 01:47:57 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:48:00 PM: Update 24019: task edges-pos-ontonotes, batch 19 (24019): mcc: 0.8611, acc: 0.7801, precision: 0.8991, recall: 0.8300, f1: 0.8632, edges-pos-ontonotes_loss: 0.0167
09/16 01:48:10 PM: Update 24064: task edges-pos-ontonotes, batch 64 (24064): mcc: 0.8659, acc: 0.7863, precision: 0.9018, recall: 0.8366, f1: 0.8680, edges-pos-ontonotes_loss: 0.0160
09/16 01:48:21 PM: Update 24112: task edges-pos-ontonotes, batch 112 (24112): mcc: 0.8670, acc: 0.7879, precision: 0.9027, recall: 0.8379, f1: 0.8691, edges-pos-ontonotes_loss: 0.0158
09/16 01:48:31 PM: Update 24171: task edges-pos-ontonotes, batch 171 (24171): mcc: 0.8666, acc: 0.7871, precision: 0.9029, recall: 0.8369, f1: 0.8686, edges-pos-ontonotes_loss: 0.0158
09/16 01:48:41 PM: Update 24221: task edges-pos-ontonotes, batch 221 (24221): mcc: 0.8660, acc: 0.7861, precision: 0.9029, recall: 0.8357, f1: 0.8680, edges-pos-ontonotes_loss: 0.0158
09/16 01:48:51 PM: Update 24291: task edges-pos-ontonotes, batch 291 (24291): mcc: 0.8664, acc: 0.7865, precision: 0.9055, recall: 0.8341, f1: 0.8683, edges-pos-ontonotes_loss: 0.0155
09/16 01:49:01 PM: Update 24361: task edges-pos-ontonotes, batch 361 (24361): mcc: 0.8672, acc: 0.7874, precision: 0.9071, recall: 0.8340, f1: 0.8691, edges-pos-ontonotes_loss: 0.0153
09/16 01:49:11 PM: Update 24412: task edges-pos-ontonotes, batch 412 (24412): mcc: 0.8673, acc: 0.7874, precision: 0.9079, recall: 0.8335, f1: 0.8691, edges-pos-ontonotes_loss: 0.0152
09/16 01:49:22 PM: Update 24473: task edges-pos-ontonotes, batch 473 (24473): mcc: 0.8678, acc: 0.7881, precision: 0.9089, recall: 0.8337, f1: 0.8697, edges-pos-ontonotes_loss: 0.0150
09/16 01:49:34 PM: Update 24534: task edges-pos-ontonotes, batch 534 (24534): mcc: 0.8683, acc: 0.7885, precision: 0.9096, recall: 0.8339, f1: 0.8701, edges-pos-ontonotes_loss: 0.0149
09/16 01:49:44 PM: Update 24583: task edges-pos-ontonotes, batch 583 (24583): mcc: 0.8688, acc: 0.7893, precision: 0.9093, recall: 0.8350, f1: 0.8706, edges-pos-ontonotes_loss: 0.0149
09/16 01:49:54 PM: Update 24632: task edges-pos-ontonotes, batch 632 (24632): mcc: 0.8695, acc: 0.7903, precision: 0.9095, recall: 0.8361, f1: 0.8713, edges-pos-ontonotes_loss: 0.0148
09/16 01:50:05 PM: Update 24697: task edges-pos-ontonotes, batch 697 (24697): mcc: 0.8700, acc: 0.7911, precision: 0.9098, recall: 0.8369, f1: 0.8718, edges-pos-ontonotes_loss: 0.0147
09/16 01:50:15 PM: Update 24754: task edges-pos-ontonotes, batch 754 (24754): mcc: 0.8708, acc: 0.7921, precision: 0.9101, recall: 0.8381, f1: 0.8726, edges-pos-ontonotes_loss: 0.0146
09/16 01:50:25 PM: Update 24818: task edges-pos-ontonotes, batch 818 (24818): mcc: 0.8713, acc: 0.7929, precision: 0.9102, recall: 0.8389, f1: 0.8731, edges-pos-ontonotes_loss: 0.0146
09/16 01:50:35 PM: Update 24870: task edges-pos-ontonotes, batch 870 (24870): mcc: 0.8710, acc: 0.7927, precision: 0.9096, recall: 0.8390, f1: 0.8729, edges-pos-ontonotes_loss: 0.0146
09/16 01:50:45 PM: Update 24926: task edges-pos-ontonotes, batch 926 (24926): mcc: 0.8710, acc: 0.7927, precision: 0.9092, recall: 0.8393, f1: 0.8729, edges-pos-ontonotes_loss: 0.0146
09/16 01:50:55 PM: Update 24980: task edges-pos-ontonotes, batch 980 (24980): mcc: 0.8709, acc: 0.7927, precision: 0.9088, recall: 0.8394, f1: 0.8727, edges-pos-ontonotes_loss: 0.0147
09/16 01:50:58 PM: ***** Step 25000 / Validation 25 *****
09/16 01:50:58 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:50:58 PM: Validating...
09/16 01:51:05 PM: Evaluate: task edges-pos-ontonotes, batch 47 (157): mcc: 0.9070, acc: 0.8506, precision: 0.9514, recall: 0.8682, f1: 0.9079, edges-pos-ontonotes_loss: 0.0111
09/16 01:51:15 PM: Evaluate: task edges-pos-ontonotes, batch 105 (157): mcc: 0.9147, acc: 0.8636, precision: 0.9502, recall: 0.8839, f1: 0.9158, edges-pos-ontonotes_loss: 0.0103
09/16 01:51:26 PM: Evaluate: task edges-pos-ontonotes, batch 149 (157): mcc: 0.9135, acc: 0.8632, precision: 0.9447, recall: 0.8867, f1: 0.9148, edges-pos-ontonotes_loss: 0.0103
09/16 01:51:27 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:51:27 PM: Best result seen so far for macro.
09/16 01:51:27 PM: Updating LR scheduler:
09/16 01:51:27 PM: 	Best result seen so far for macro_avg: 0.915
09/16 01:51:27 PM: 	# validation passes without improvement: 0
09/16 01:51:27 PM: edges-pos-ontonotes_loss: training: 0.014664 validation: 0.010298
09/16 01:51:27 PM: macro_avg: validation: 0.915164
09/16 01:51:27 PM: micro_avg: validation: 0.000000
09/16 01:51:27 PM: edges-pos-ontonotes_mcc: training: 0.870926 validation: 0.913885
09/16 01:51:27 PM: edges-pos-ontonotes_acc: training: 0.792812 validation: 0.864112
09/16 01:51:27 PM: edges-pos-ontonotes_precision: training: 0.908666 validation: 0.944789
09/16 01:51:27 PM: edges-pos-ontonotes_recall: training: 0.839689 validation: 0.887340
09/16 01:51:27 PM: edges-pos-ontonotes_f1: training: 0.872817 validation: 0.915164
09/16 01:51:27 PM: Global learning rate: 0.0001
09/16 01:51:27 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:51:36 PM: Update 25045: task edges-pos-ontonotes, batch 45 (25045): mcc: 0.8692, acc: 0.7940, precision: 0.9003, recall: 0.8442, f1: 0.8714, edges-pos-ontonotes_loss: 0.0153
09/16 01:51:46 PM: Update 25088: task edges-pos-ontonotes, batch 88 (25088): mcc: 0.8697, acc: 0.7936, precision: 0.9027, recall: 0.8430, f1: 0.8718, edges-pos-ontonotes_loss: 0.0151
09/16 01:51:56 PM: Update 25138: task edges-pos-ontonotes, batch 138 (25138): mcc: 0.8704, acc: 0.7943, precision: 0.9035, recall: 0.8436, f1: 0.8725, edges-pos-ontonotes_loss: 0.0152
09/16 01:52:11 PM: Update 25160: task edges-pos-ontonotes, batch 160 (25160): mcc: 0.8702, acc: 0.7940, precision: 0.9040, recall: 0.8426, f1: 0.8722, edges-pos-ontonotes_loss: 0.0152
09/16 01:52:22 PM: Update 25210: task edges-pos-ontonotes, batch 210 (25210): mcc: 0.8709, acc: 0.7952, precision: 0.9045, recall: 0.8435, f1: 0.8729, edges-pos-ontonotes_loss: 0.0150
09/16 01:52:32 PM: Update 25257: task edges-pos-ontonotes, batch 257 (25257): mcc: 0.8717, acc: 0.7963, precision: 0.9054, recall: 0.8443, f1: 0.8738, edges-pos-ontonotes_loss: 0.0149
09/16 01:52:42 PM: Update 25307: task edges-pos-ontonotes, batch 307 (25307): mcc: 0.8722, acc: 0.7971, precision: 0.9059, recall: 0.8446, f1: 0.8742, edges-pos-ontonotes_loss: 0.0149
09/16 01:52:52 PM: Update 25356: task edges-pos-ontonotes, batch 356 (25356): mcc: 0.8728, acc: 0.7980, precision: 0.9065, recall: 0.8453, f1: 0.8748, edges-pos-ontonotes_loss: 0.0149
09/16 01:53:03 PM: Update 25398: task edges-pos-ontonotes, batch 398 (25398): mcc: 0.8734, acc: 0.7988, precision: 0.9069, recall: 0.8461, f1: 0.8754, edges-pos-ontonotes_loss: 0.0148
09/16 01:53:13 PM: Update 25438: task edges-pos-ontonotes, batch 438 (25438): mcc: 0.8739, acc: 0.7997, precision: 0.9074, recall: 0.8466, f1: 0.8759, edges-pos-ontonotes_loss: 0.0147
09/16 01:53:24 PM: Update 25473: task edges-pos-ontonotes, batch 473 (25473): mcc: 0.8743, acc: 0.8001, precision: 0.9078, recall: 0.8470, f1: 0.8763, edges-pos-ontonotes_loss: 0.0146
09/16 01:53:34 PM: Update 25511: task edges-pos-ontonotes, batch 511 (25511): mcc: 0.8745, acc: 0.8004, precision: 0.9080, recall: 0.8471, f1: 0.8765, edges-pos-ontonotes_loss: 0.0146
09/16 01:53:44 PM: Update 25564: task edges-pos-ontonotes, batch 564 (25564): mcc: 0.8748, acc: 0.8010, precision: 0.9082, recall: 0.8475, f1: 0.8768, edges-pos-ontonotes_loss: 0.0146
09/16 01:53:54 PM: Update 25607: task edges-pos-ontonotes, batch 607 (25607): mcc: 0.8751, acc: 0.8015, precision: 0.9085, recall: 0.8477, f1: 0.8770, edges-pos-ontonotes_loss: 0.0146
09/16 01:54:04 PM: Update 25651: task edges-pos-ontonotes, batch 651 (25651): mcc: 0.8754, acc: 0.8019, precision: 0.9088, recall: 0.8480, f1: 0.8774, edges-pos-ontonotes_loss: 0.0146
09/16 01:54:14 PM: Update 25695: task edges-pos-ontonotes, batch 695 (25695): mcc: 0.8755, acc: 0.8023, precision: 0.9090, recall: 0.8481, f1: 0.8775, edges-pos-ontonotes_loss: 0.0145
09/16 01:54:24 PM: Update 25750: task edges-pos-ontonotes, batch 750 (25750): mcc: 0.8758, acc: 0.8026, precision: 0.9092, recall: 0.8483, f1: 0.8777, edges-pos-ontonotes_loss: 0.0145
09/16 01:54:37 PM: Update 25786: task edges-pos-ontonotes, batch 786 (25786): mcc: 0.8759, acc: 0.8027, precision: 0.9094, recall: 0.8484, f1: 0.8778, edges-pos-ontonotes_loss: 0.0145
09/16 01:54:47 PM: Update 25819: task edges-pos-ontonotes, batch 819 (25819): mcc: 0.8760, acc: 0.8029, precision: 0.9095, recall: 0.8484, f1: 0.8779, edges-pos-ontonotes_loss: 0.0145
09/16 01:54:58 PM: Update 25851: task edges-pos-ontonotes, batch 851 (25851): mcc: 0.8760, acc: 0.8030, precision: 0.9096, recall: 0.8485, f1: 0.8779, edges-pos-ontonotes_loss: 0.0145
09/16 01:55:08 PM: Update 25881: task edges-pos-ontonotes, batch 881 (25881): mcc: 0.8760, acc: 0.8030, precision: 0.9096, recall: 0.8485, f1: 0.8780, edges-pos-ontonotes_loss: 0.0145
09/16 01:55:18 PM: Update 25911: task edges-pos-ontonotes, batch 911 (25911): mcc: 0.8762, acc: 0.8033, precision: 0.9097, recall: 0.8486, f1: 0.8781, edges-pos-ontonotes_loss: 0.0145
09/16 01:55:28 PM: Update 25945: task edges-pos-ontonotes, batch 945 (25945): mcc: 0.8763, acc: 0.8036, precision: 0.9099, recall: 0.8488, f1: 0.8783, edges-pos-ontonotes_loss: 0.0145
09/16 01:55:38 PM: Update 25979: task edges-pos-ontonotes, batch 979 (25979): mcc: 0.8765, acc: 0.8038, precision: 0.9100, recall: 0.8489, f1: 0.8784, edges-pos-ontonotes_loss: 0.0145
09/16 01:55:43 PM: ***** Step 26000 / Validation 26 *****
09/16 01:55:43 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:55:43 PM: Validating...
09/16 01:55:49 PM: Evaluate: task edges-pos-ontonotes, batch 42 (157): mcc: 0.9045, acc: 0.8469, precision: 0.9488, recall: 0.8659, f1: 0.9054, edges-pos-ontonotes_loss: 0.0115
09/16 01:55:59 PM: Evaluate: task edges-pos-ontonotes, batch 103 (157): mcc: 0.9127, acc: 0.8617, precision: 0.9473, recall: 0.8828, f1: 0.9139, edges-pos-ontonotes_loss: 0.0106
09/16 01:56:09 PM: Evaluate: task edges-pos-ontonotes, batch 148 (157): mcc: 0.9139, acc: 0.8649, precision: 0.9435, recall: 0.8887, f1: 0.9153, edges-pos-ontonotes_loss: 0.0104
09/16 01:56:11 PM: Best result seen so far for edges-pos-ontonotes.
09/16 01:56:11 PM: Best result seen so far for macro.
09/16 01:56:11 PM: Updating LR scheduler:
09/16 01:56:11 PM: 	Best result seen so far for macro_avg: 0.916
09/16 01:56:11 PM: 	# validation passes without improvement: 0
09/16 01:56:11 PM: edges-pos-ontonotes_loss: training: 0.014486 validation: 0.010372
09/16 01:56:11 PM: macro_avg: validation: 0.915850
09/16 01:56:11 PM: micro_avg: validation: 0.000000
09/16 01:56:11 PM: edges-pos-ontonotes_mcc: training: 0.876521 validation: 0.914523
09/16 01:56:11 PM: edges-pos-ontonotes_acc: training: 0.803883 validation: 0.866059
09/16 01:56:11 PM: edges-pos-ontonotes_precision: training: 0.910039 validation: 0.943501
09/16 01:56:11 PM: edges-pos-ontonotes_recall: training: 0.849010 validation: 0.889774
09/16 01:56:11 PM: edges-pos-ontonotes_f1: training: 0.878466 validation: 0.915850
09/16 01:56:11 PM: Global learning rate: 0.0001
09/16 01:56:11 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:56:19 PM: Update 26032: task edges-pos-ontonotes, batch 32 (26032): mcc: 0.8783, acc: 0.8079, precision: 0.9121, recall: 0.8505, f1: 0.8802, edges-pos-ontonotes_loss: 0.0145
09/16 01:56:29 PM: Update 26076: task edges-pos-ontonotes, batch 76 (26076): mcc: 0.8788, acc: 0.8091, precision: 0.9126, recall: 0.8510, f1: 0.8807, edges-pos-ontonotes_loss: 0.0143
09/16 01:56:40 PM: Update 26118: task edges-pos-ontonotes, batch 118 (26118): mcc: 0.8766, acc: 0.8058, precision: 0.9106, recall: 0.8486, f1: 0.8785, edges-pos-ontonotes_loss: 0.0143
09/16 01:56:50 PM: Update 26181: task edges-pos-ontonotes, batch 181 (26181): mcc: 0.8798, acc: 0.8094, precision: 0.9135, recall: 0.8521, f1: 0.8817, edges-pos-ontonotes_loss: 0.0136
09/16 01:57:00 PM: Update 26244: task edges-pos-ontonotes, batch 244 (26244): mcc: 0.8801, acc: 0.8097, precision: 0.9132, recall: 0.8528, f1: 0.8820, edges-pos-ontonotes_loss: 0.0134
09/16 01:57:10 PM: Update 26308: task edges-pos-ontonotes, batch 308 (26308): mcc: 0.8814, acc: 0.8116, precision: 0.9145, recall: 0.8541, f1: 0.8833, edges-pos-ontonotes_loss: 0.0131
09/16 01:57:20 PM: Update 26376: task edges-pos-ontonotes, batch 376 (26376): mcc: 0.8824, acc: 0.8127, precision: 0.9154, recall: 0.8551, f1: 0.8842, edges-pos-ontonotes_loss: 0.0129
09/16 01:57:30 PM: Update 26439: task edges-pos-ontonotes, batch 439 (26439): mcc: 0.8837, acc: 0.8144, precision: 0.9164, recall: 0.8568, f1: 0.8856, edges-pos-ontonotes_loss: 0.0127
09/16 01:57:40 PM: Update 26503: task edges-pos-ontonotes, batch 503 (26503): mcc: 0.8861, acc: 0.8176, precision: 0.9186, recall: 0.8592, f1: 0.8879, edges-pos-ontonotes_loss: 0.0125
09/16 01:57:50 PM: Update 26579: task edges-pos-ontonotes, batch 579 (26579): mcc: 0.8881, acc: 0.8203, precision: 0.9205, recall: 0.8612, f1: 0.8899, edges-pos-ontonotes_loss: 0.0122
09/16 01:58:00 PM: Update 26649: task edges-pos-ontonotes, batch 649 (26649): mcc: 0.8902, acc: 0.8232, precision: 0.9223, recall: 0.8635, f1: 0.8919, edges-pos-ontonotes_loss: 0.0120
09/16 01:58:10 PM: Update 26723: task edges-pos-ontonotes, batch 723 (26723): mcc: 0.8919, acc: 0.8254, precision: 0.9237, recall: 0.8653, f1: 0.8936, edges-pos-ontonotes_loss: 0.0119
09/16 01:58:20 PM: Update 26789: task edges-pos-ontonotes, batch 789 (26789): mcc: 0.8925, acc: 0.8261, precision: 0.9245, recall: 0.8657, f1: 0.8942, edges-pos-ontonotes_loss: 0.0118
09/16 01:58:31 PM: Update 26874: task edges-pos-ontonotes, batch 874 (26874): mcc: 0.8934, acc: 0.8273, precision: 0.9255, recall: 0.8665, f1: 0.8950, edges-pos-ontonotes_loss: 0.0118
09/16 01:58:41 PM: Update 26944: task edges-pos-ontonotes, batch 944 (26944): mcc: 0.8939, acc: 0.8281, precision: 0.9260, recall: 0.8671, f1: 0.8956, edges-pos-ontonotes_loss: 0.0117
09/16 01:58:49 PM: ***** Step 27000 / Validation 27 *****
09/16 01:58:49 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 01:58:49 PM: Validating...
09/16 01:58:51 PM: Evaluate: task edges-pos-ontonotes, batch 9 (157): mcc: 0.8996, acc: 0.8494, precision: 0.9285, recall: 0.8756, f1: 0.9012, edges-pos-ontonotes_loss: 0.0117
09/16 01:59:01 PM: Evaluate: task edges-pos-ontonotes, batch 52 (157): mcc: 0.9071, acc: 0.8538, precision: 0.9454, recall: 0.8739, f1: 0.9082, edges-pos-ontonotes_loss: 0.0112
09/16 01:59:11 PM: Evaluate: task edges-pos-ontonotes, batch 92 (157): mcc: 0.9108, acc: 0.8604, precision: 0.9425, recall: 0.8835, f1: 0.9121, edges-pos-ontonotes_loss: 0.0108
09/16 01:59:21 PM: Evaluate: task edges-pos-ontonotes, batch 121 (157): mcc: 0.9108, acc: 0.8611, precision: 0.9380, recall: 0.8879, f1: 0.9123, edges-pos-ontonotes_loss: 0.0107
09/16 01:59:31 PM: Evaluate: task edges-pos-ontonotes, batch 148 (157): mcc: 0.9112, acc: 0.8624, precision: 0.9346, recall: 0.8919, f1: 0.9128, edges-pos-ontonotes_loss: 0.0107
09/16 01:59:34 PM: Updating LR scheduler:
09/16 01:59:34 PM: 	Best result seen so far for macro_avg: 0.916
09/16 01:59:34 PM: 	# validation passes without improvement: 1
09/16 01:59:34 PM: edges-pos-ontonotes_loss: training: 0.011677 validation: 0.010634
09/16 01:59:34 PM: macro_avg: validation: 0.913461
09/16 01:59:34 PM: micro_avg: validation: 0.000000
09/16 01:59:34 PM: edges-pos-ontonotes_mcc: training: 0.894371 validation: 0.911912
09/16 01:59:34 PM: edges-pos-ontonotes_acc: training: 0.828677 validation: 0.863763
09/16 01:59:34 PM: edges-pos-ontonotes_precision: training: 0.926463 validation: 0.934880
09/16 01:59:34 PM: edges-pos-ontonotes_recall: training: 0.867488 validation: 0.893002
09/16 01:59:34 PM: edges-pos-ontonotes_f1: training: 0.896006 validation: 0.913461
09/16 01:59:34 PM: Global learning rate: 0.0001
09/16 01:59:34 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 01:59:42 PM: Update 27038: task edges-pos-ontonotes, batch 38 (27038): mcc: 0.9092, acc: 0.8509, precision: 0.9406, recall: 0.8823, f1: 0.9105, edges-pos-ontonotes_loss: 0.0104
09/16 01:59:53 PM: Update 27112: task edges-pos-ontonotes, batch 112 (27112): mcc: 0.8862, acc: 0.8155, precision: 0.9239, recall: 0.8544, f1: 0.8878, edges-pos-ontonotes_loss: 0.0133
09/16 02:00:03 PM: Update 27190: task edges-pos-ontonotes, batch 190 (27190): mcc: 0.8809, acc: 0.8080, precision: 0.9207, recall: 0.8473, f1: 0.8825, edges-pos-ontonotes_loss: 0.0138
09/16 02:00:13 PM: Update 27309: task edges-pos-ontonotes, batch 309 (27309): mcc: 0.8798, acc: 0.8053, precision: 0.9203, recall: 0.8456, f1: 0.8814, edges-pos-ontonotes_loss: 0.0138
09/16 02:00:26 PM: Update 27351: task edges-pos-ontonotes, batch 351 (27351): mcc: 0.8790, acc: 0.8043, precision: 0.9197, recall: 0.8447, f1: 0.8806, edges-pos-ontonotes_loss: 0.0137
09/16 02:00:36 PM: Update 27410: task edges-pos-ontonotes, batch 410 (27410): mcc: 0.8747, acc: 0.7985, precision: 0.9131, recall: 0.8428, f1: 0.8765, edges-pos-ontonotes_loss: 0.0141
09/16 02:00:46 PM: Update 27462: task edges-pos-ontonotes, batch 462 (27462): mcc: 0.8738, acc: 0.7969, precision: 0.9115, recall: 0.8424, f1: 0.8756, edges-pos-ontonotes_loss: 0.0143
09/16 02:00:56 PM: Update 27507: task edges-pos-ontonotes, batch 507 (27507): mcc: 0.8725, acc: 0.7951, precision: 0.9098, recall: 0.8415, f1: 0.8743, edges-pos-ontonotes_loss: 0.0144
09/16 02:01:06 PM: Update 27554: task edges-pos-ontonotes, batch 554 (27554): mcc: 0.8717, acc: 0.7940, precision: 0.9091, recall: 0.8408, f1: 0.8736, edges-pos-ontonotes_loss: 0.0145
09/16 02:01:16 PM: Update 27601: task edges-pos-ontonotes, batch 601 (27601): mcc: 0.8711, acc: 0.7932, precision: 0.9083, recall: 0.8404, f1: 0.8731, edges-pos-ontonotes_loss: 0.0146
09/16 02:01:27 PM: Update 27645: task edges-pos-ontonotes, batch 645 (27645): mcc: 0.8708, acc: 0.7927, precision: 0.9080, recall: 0.8400, f1: 0.8727, edges-pos-ontonotes_loss: 0.0147
09/16 02:01:37 PM: Update 27698: task edges-pos-ontonotes, batch 698 (27698): mcc: 0.8699, acc: 0.7915, precision: 0.9075, recall: 0.8389, f1: 0.8718, edges-pos-ontonotes_loss: 0.0148
09/16 02:01:47 PM: Update 27794: task edges-pos-ontonotes, batch 794 (27794): mcc: 0.8698, acc: 0.7913, precision: 0.9085, recall: 0.8378, f1: 0.8717, edges-pos-ontonotes_loss: 0.0147
09/16 02:01:57 PM: Update 27871: task edges-pos-ontonotes, batch 871 (27871): mcc: 0.8701, acc: 0.7915, precision: 0.9093, recall: 0.8375, f1: 0.8719, edges-pos-ontonotes_loss: 0.0146
09/16 02:02:07 PM: Update 27938: task edges-pos-ontonotes, batch 938 (27938): mcc: 0.8702, acc: 0.7917, precision: 0.9099, recall: 0.8373, f1: 0.8721, edges-pos-ontonotes_loss: 0.0146
09/16 02:02:17 PM: Update 27998: task edges-pos-ontonotes, batch 998 (27998): mcc: 0.8705, acc: 0.7920, precision: 0.9101, recall: 0.8375, f1: 0.8723, edges-pos-ontonotes_loss: 0.0145
09/16 02:02:17 PM: ***** Step 28000 / Validation 28 *****
09/16 02:02:17 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:02:17 PM: Validating...
09/16 02:02:27 PM: Evaluate: task edges-pos-ontonotes, batch 68 (157): mcc: 0.9131, acc: 0.8625, precision: 0.9438, recall: 0.8867, f1: 0.9144, edges-pos-ontonotes_loss: 0.0106
09/16 02:02:37 PM: Evaluate: task edges-pos-ontonotes, batch 120 (157): mcc: 0.9141, acc: 0.8648, precision: 0.9381, recall: 0.8941, f1: 0.9156, edges-pos-ontonotes_loss: 0.0104
09/16 02:02:45 PM: Updating LR scheduler:
09/16 02:02:45 PM: 	Best result seen so far for macro_avg: 0.916
09/16 02:02:45 PM: 	# validation passes without improvement: 2
09/16 02:02:45 PM: edges-pos-ontonotes_loss: training: 0.014541 validation: 0.010356
09/16 02:02:45 PM: macro_avg: validation: 0.915684
09/16 02:02:45 PM: micro_avg: validation: 0.000000
09/16 02:02:45 PM: edges-pos-ontonotes_mcc: training: 0.870508 validation: 0.914125
09/16 02:02:45 PM: edges-pos-ontonotes_acc: training: 0.791999 validation: 0.865541
09/16 02:02:45 PM: edges-pos-ontonotes_precision: training: 0.910111 validation: 0.934735
09/16 02:02:45 PM: edges-pos-ontonotes_recall: training: 0.837557 validation: 0.897394
09/16 02:02:45 PM: edges-pos-ontonotes_f1: training: 0.872328 validation: 0.915684
09/16 02:02:45 PM: Global learning rate: 0.0001
09/16 02:02:45 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:02:47 PM: Update 28017: task edges-pos-ontonotes, batch 17 (28017): mcc: 0.8743, acc: 0.8007, precision: 0.9011, recall: 0.8532, f1: 0.8765, edges-pos-ontonotes_loss: 0.0141
09/16 02:02:57 PM: Update 28082: task edges-pos-ontonotes, batch 82 (28082): mcc: 0.8760, acc: 0.7995, precision: 0.9082, recall: 0.8497, f1: 0.8780, edges-pos-ontonotes_loss: 0.0141
09/16 02:03:07 PM: Update 28161: task edges-pos-ontonotes, batch 161 (28161): mcc: 0.8768, acc: 0.8007, precision: 0.9102, recall: 0.8494, f1: 0.8787, edges-pos-ontonotes_loss: 0.0139
09/16 02:03:18 PM: Update 28221: task edges-pos-ontonotes, batch 221 (28221): mcc: 0.8759, acc: 0.7994, precision: 0.9091, recall: 0.8486, f1: 0.8778, edges-pos-ontonotes_loss: 0.0140
09/16 02:03:28 PM: Update 28279: task edges-pos-ontonotes, batch 279 (28279): mcc: 0.8760, acc: 0.7999, precision: 0.9097, recall: 0.8484, f1: 0.8780, edges-pos-ontonotes_loss: 0.0139
09/16 02:03:38 PM: Update 28310: task edges-pos-ontonotes, batch 310 (28310): mcc: 0.8753, acc: 0.7989, precision: 0.9088, recall: 0.8478, f1: 0.8773, edges-pos-ontonotes_loss: 0.0139
09/16 02:03:48 PM: Update 28345: task edges-pos-ontonotes, batch 345 (28345): mcc: 0.8745, acc: 0.7978, precision: 0.9078, recall: 0.8472, f1: 0.8765, edges-pos-ontonotes_loss: 0.0140
09/16 02:03:58 PM: Update 28380: task edges-pos-ontonotes, batch 380 (28380): mcc: 0.8744, acc: 0.7979, precision: 0.9076, recall: 0.8472, f1: 0.8764, edges-pos-ontonotes_loss: 0.0141
09/16 02:04:08 PM: Update 28431: task edges-pos-ontonotes, batch 431 (28431): mcc: 0.8739, acc: 0.7975, precision: 0.9070, recall: 0.8469, f1: 0.8759, edges-pos-ontonotes_loss: 0.0142
09/16 02:04:19 PM: Update 28487: task edges-pos-ontonotes, batch 487 (28487): mcc: 0.8738, acc: 0.7976, precision: 0.9068, recall: 0.8470, f1: 0.8759, edges-pos-ontonotes_loss: 0.0144
09/16 02:04:29 PM: Update 28527: task edges-pos-ontonotes, batch 527 (28527): mcc: 0.8739, acc: 0.7977, precision: 0.9068, recall: 0.8470, f1: 0.8759, edges-pos-ontonotes_loss: 0.0144
09/16 02:04:39 PM: Update 28562: task edges-pos-ontonotes, batch 562 (28562): mcc: 0.8738, acc: 0.7976, precision: 0.9066, recall: 0.8471, f1: 0.8758, edges-pos-ontonotes_loss: 0.0144
09/16 02:04:51 PM: Update 28620: task edges-pos-ontonotes, batch 620 (28620): mcc: 0.8736, acc: 0.7975, precision: 0.9064, recall: 0.8468, f1: 0.8756, edges-pos-ontonotes_loss: 0.0144
09/16 02:05:01 PM: Update 28669: task edges-pos-ontonotes, batch 669 (28669): mcc: 0.8734, acc: 0.7973, precision: 0.9063, recall: 0.8465, f1: 0.8754, edges-pos-ontonotes_loss: 0.0145
09/16 02:05:11 PM: Update 28724: task edges-pos-ontonotes, batch 724 (28724): mcc: 0.8737, acc: 0.7979, precision: 0.9067, recall: 0.8469, f1: 0.8757, edges-pos-ontonotes_loss: 0.0144
09/16 02:05:21 PM: Update 28759: task edges-pos-ontonotes, batch 759 (28759): mcc: 0.8738, acc: 0.7981, precision: 0.9067, recall: 0.8470, f1: 0.8758, edges-pos-ontonotes_loss: 0.0144
09/16 02:05:31 PM: Update 28803: task edges-pos-ontonotes, batch 803 (28803): mcc: 0.8740, acc: 0.7984, precision: 0.9068, recall: 0.8472, f1: 0.8760, edges-pos-ontonotes_loss: 0.0144
09/16 02:05:42 PM: Update 28848: task edges-pos-ontonotes, batch 848 (28848): mcc: 0.8742, acc: 0.7988, precision: 0.9070, recall: 0.8474, f1: 0.8762, edges-pos-ontonotes_loss: 0.0144
09/16 02:05:52 PM: Update 28888: task edges-pos-ontonotes, batch 888 (28888): mcc: 0.8744, acc: 0.7993, precision: 0.9072, recall: 0.8477, f1: 0.8764, edges-pos-ontonotes_loss: 0.0144
09/16 02:06:02 PM: Update 28921: task edges-pos-ontonotes, batch 921 (28921): mcc: 0.8746, acc: 0.7995, precision: 0.9074, recall: 0.8478, f1: 0.8766, edges-pos-ontonotes_loss: 0.0144
09/16 02:06:12 PM: Update 28937: task edges-pos-ontonotes, batch 937 (28937): mcc: 0.8745, acc: 0.7996, precision: 0.9073, recall: 0.8478, f1: 0.8765, edges-pos-ontonotes_loss: 0.0144
09/16 02:06:23 PM: Update 28973: task edges-pos-ontonotes, batch 973 (28973): mcc: 0.8747, acc: 0.7998, precision: 0.9075, recall: 0.8479, f1: 0.8767, edges-pos-ontonotes_loss: 0.0144
09/16 02:06:29 PM: ***** Step 29000 / Validation 29 *****
09/16 02:06:29 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:06:29 PM: Validating...
09/16 02:06:33 PM: Evaluate: task edges-pos-ontonotes, batch 17 (157): mcc: 0.9048, acc: 0.8504, precision: 0.9407, recall: 0.8740, f1: 0.9061, edges-pos-ontonotes_loss: 0.0112
09/16 02:06:43 PM: Evaluate: task edges-pos-ontonotes, batch 70 (157): mcc: 0.9132, acc: 0.8619, precision: 0.9487, recall: 0.8825, f1: 0.9144, edges-pos-ontonotes_loss: 0.0107
09/16 02:06:53 PM: Evaluate: task edges-pos-ontonotes, batch 113 (157): mcc: 0.9149, acc: 0.8655, precision: 0.9457, recall: 0.8884, f1: 0.9162, edges-pos-ontonotes_loss: 0.0104
09/16 02:07:10 PM: Evaluate: task edges-pos-ontonotes, batch 154 (157): mcc: 0.9159, acc: 0.8679, precision: 0.9427, recall: 0.8932, f1: 0.9173, edges-pos-ontonotes_loss: 0.0102
09/16 02:07:10 PM: Best result seen so far for edges-pos-ontonotes.
09/16 02:07:10 PM: Best result seen so far for macro.
09/16 02:07:10 PM: Updating LR scheduler:
09/16 02:07:10 PM: 	Best result seen so far for macro_avg: 0.917
09/16 02:07:10 PM: 	# validation passes without improvement: 0
09/16 02:07:10 PM: edges-pos-ontonotes_loss: training: 0.014364 validation: 0.010188
09/16 02:07:10 PM: macro_avg: validation: 0.917464
09/16 02:07:10 PM: micro_avg: validation: 0.000000
09/16 02:07:10 PM: edges-pos-ontonotes_mcc: training: 0.874759 validation: 0.916100
09/16 02:07:10 PM: edges-pos-ontonotes_acc: training: 0.800103 validation: 0.868229
09/16 02:07:10 PM: edges-pos-ontonotes_precision: training: 0.907485 validation: 0.942773
09/16 02:07:10 PM: edges-pos-ontonotes_recall: training: 0.848063 validation: 0.893478
09/16 02:07:10 PM: edges-pos-ontonotes_f1: training: 0.876768 validation: 0.917464
09/16 02:07:10 PM: Global learning rate: 0.0001
09/16 02:07:10 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:07:20 PM: Update 29059: task edges-pos-ontonotes, batch 59 (29059): mcc: 0.8810, acc: 0.8112, precision: 0.9139, recall: 0.8539, f1: 0.8829, edges-pos-ontonotes_loss: 0.0145
09/16 02:07:30 PM: Update 29117: task edges-pos-ontonotes, batch 117 (29117): mcc: 0.8818, acc: 0.8118, precision: 0.9150, recall: 0.8543, f1: 0.8836, edges-pos-ontonotes_loss: 0.0144
09/16 02:07:41 PM: Update 29163: task edges-pos-ontonotes, batch 163 (29163): mcc: 0.8817, acc: 0.8116, precision: 0.9150, recall: 0.8543, f1: 0.8836, edges-pos-ontonotes_loss: 0.0142
09/16 02:07:51 PM: Update 29216: task edges-pos-ontonotes, batch 216 (29216): mcc: 0.8810, acc: 0.8109, precision: 0.9146, recall: 0.8533, f1: 0.8829, edges-pos-ontonotes_loss: 0.0141
09/16 02:08:01 PM: Update 29255: task edges-pos-ontonotes, batch 255 (29255): mcc: 0.8808, acc: 0.8105, precision: 0.9142, recall: 0.8533, f1: 0.8827, edges-pos-ontonotes_loss: 0.0141
09/16 02:08:11 PM: Update 29305: task edges-pos-ontonotes, batch 305 (29305): mcc: 0.8807, acc: 0.8107, precision: 0.9137, recall: 0.8535, f1: 0.8826, edges-pos-ontonotes_loss: 0.0141
09/16 02:08:21 PM: Update 29360: task edges-pos-ontonotes, batch 360 (29360): mcc: 0.8804, acc: 0.8103, precision: 0.9136, recall: 0.8531, f1: 0.8823, edges-pos-ontonotes_loss: 0.0141
09/16 02:08:31 PM: Update 29417: task edges-pos-ontonotes, batch 417 (29417): mcc: 0.8800, acc: 0.8096, precision: 0.9135, recall: 0.8523, f1: 0.8818, edges-pos-ontonotes_loss: 0.0143
09/16 02:08:41 PM: Update 29473: task edges-pos-ontonotes, batch 473 (29473): mcc: 0.8805, acc: 0.8105, precision: 0.9139, recall: 0.8530, f1: 0.8824, edges-pos-ontonotes_loss: 0.0142
09/16 02:08:51 PM: Update 29531: task edges-pos-ontonotes, batch 531 (29531): mcc: 0.8808, acc: 0.8109, precision: 0.9142, recall: 0.8533, f1: 0.8827, edges-pos-ontonotes_loss: 0.0142
09/16 02:09:02 PM: Update 29575: task edges-pos-ontonotes, batch 575 (29575): mcc: 0.8804, acc: 0.8104, precision: 0.9137, recall: 0.8529, f1: 0.8823, edges-pos-ontonotes_loss: 0.0141
09/16 02:09:12 PM: Update 29628: task edges-pos-ontonotes, batch 628 (29628): mcc: 0.8806, acc: 0.8107, precision: 0.9138, recall: 0.8533, f1: 0.8825, edges-pos-ontonotes_loss: 0.0140
09/16 02:09:22 PM: Update 29676: task edges-pos-ontonotes, batch 676 (29676): mcc: 0.8810, acc: 0.8111, precision: 0.9141, recall: 0.8537, f1: 0.8828, edges-pos-ontonotes_loss: 0.0139
09/16 02:09:32 PM: Update 29729: task edges-pos-ontonotes, batch 729 (29729): mcc: 0.8811, acc: 0.8113, precision: 0.9141, recall: 0.8540, f1: 0.8830, edges-pos-ontonotes_loss: 0.0138
09/16 02:09:42 PM: Update 29791: task edges-pos-ontonotes, batch 791 (29791): mcc: 0.8815, acc: 0.8119, precision: 0.9143, recall: 0.8545, f1: 0.8834, edges-pos-ontonotes_loss: 0.0136
09/16 02:09:52 PM: Update 29853: task edges-pos-ontonotes, batch 853 (29853): mcc: 0.8819, acc: 0.8125, precision: 0.9147, recall: 0.8549, f1: 0.8838, edges-pos-ontonotes_loss: 0.0135
09/16 02:10:03 PM: Update 29926: task edges-pos-ontonotes, batch 926 (29926): mcc: 0.8828, acc: 0.8136, precision: 0.9154, recall: 0.8559, f1: 0.8847, edges-pos-ontonotes_loss: 0.0133
09/16 02:10:11 PM: ***** Step 30000 / Validation 30 *****
09/16 02:10:11 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:10:11 PM: Validating...
09/16 02:10:13 PM: Evaluate: task edges-pos-ontonotes, batch 7 (157): mcc: 0.9033, acc: 0.8552, precision: 0.9335, recall: 0.8779, f1: 0.9048, edges-pos-ontonotes_loss: 0.0114
09/16 02:10:23 PM: Evaluate: task edges-pos-ontonotes, batch 75 (157): mcc: 0.9104, acc: 0.8571, precision: 0.9487, recall: 0.8770, f1: 0.9115, edges-pos-ontonotes_loss: 0.0109
09/16 02:10:33 PM: Evaluate: task edges-pos-ontonotes, batch 125 (157): mcc: 0.9123, acc: 0.8613, precision: 0.9451, recall: 0.8842, f1: 0.9136, edges-pos-ontonotes_loss: 0.0105
09/16 02:10:40 PM: Updating LR scheduler:
09/16 02:10:40 PM: 	Best result seen so far for macro_avg: 0.917
09/16 02:10:40 PM: 	# validation passes without improvement: 1
09/16 02:10:40 PM: edges-pos-ontonotes_loss: training: 0.013111 validation: 0.010359
09/16 02:10:40 PM: macro_avg: validation: 0.915572
09/16 02:10:40 PM: micro_avg: validation: 0.000000
09/16 02:10:40 PM: edges-pos-ontonotes_mcc: training: 0.884249 validation: 0.914249
09/16 02:10:40 PM: edges-pos-ontonotes_acc: training: 0.815368 validation: 0.865689
09/16 02:10:40 PM: edges-pos-ontonotes_precision: training: 0.916800 validation: 0.943541
09/16 02:10:40 PM: edges-pos-ontonotes_recall: training: 0.857339 validation: 0.889213
09/16 02:10:40 PM: edges-pos-ontonotes_f1: training: 0.886073 validation: 0.915572
09/16 02:10:40 PM: Global learning rate: 0.0001
09/16 02:10:40 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:10:43 PM: Update 30029: task edges-pos-ontonotes, batch 29 (30029): mcc: 0.9100, acc: 0.8472, precision: 0.9429, recall: 0.8818, f1: 0.9113, edges-pos-ontonotes_loss: 0.0104
09/16 02:10:53 PM: Update 30102: task edges-pos-ontonotes, batch 102 (30102): mcc: 0.9109, acc: 0.8500, precision: 0.9409, recall: 0.8854, f1: 0.9123, edges-pos-ontonotes_loss: 0.0103
09/16 02:11:03 PM: Update 30172: task edges-pos-ontonotes, batch 172 (30172): mcc: 0.9115, acc: 0.8520, precision: 0.9403, recall: 0.8870, f1: 0.9129, edges-pos-ontonotes_loss: 0.0103
09/16 02:11:13 PM: Update 30242: task edges-pos-ontonotes, batch 242 (30242): mcc: 0.9095, acc: 0.8490, precision: 0.9394, recall: 0.8841, f1: 0.9109, edges-pos-ontonotes_loss: 0.0106
09/16 02:11:24 PM: Update 30320: task edges-pos-ontonotes, batch 320 (30320): mcc: 0.9088, acc: 0.8480, precision: 0.9399, recall: 0.8823, f1: 0.9102, edges-pos-ontonotes_loss: 0.0106
09/16 02:11:34 PM: Update 30407: task edges-pos-ontonotes, batch 407 (30407): mcc: 0.9086, acc: 0.8479, precision: 0.9396, recall: 0.8822, f1: 0.9100, edges-pos-ontonotes_loss: 0.0107
09/16 02:11:44 PM: Update 30490: task edges-pos-ontonotes, batch 490 (30490): mcc: 0.9086, acc: 0.8479, precision: 0.9396, recall: 0.8823, f1: 0.9100, edges-pos-ontonotes_loss: 0.0107
09/16 02:11:54 PM: Update 30560: task edges-pos-ontonotes, batch 560 (30560): mcc: 0.9049, acc: 0.8425, precision: 0.9369, recall: 0.8777, f1: 0.9064, edges-pos-ontonotes_loss: 0.0112
09/16 02:12:04 PM: Update 30665: task edges-pos-ontonotes, batch 665 (30665): mcc: 0.9020, acc: 0.8379, precision: 0.9349, recall: 0.8739, f1: 0.9034, edges-pos-ontonotes_loss: 0.0117
09/16 02:12:14 PM: Update 30760: task edges-pos-ontonotes, batch 760 (30760): mcc: 0.8994, acc: 0.8342, precision: 0.9333, recall: 0.8707, f1: 0.9009, edges-pos-ontonotes_loss: 0.0119
09/16 02:12:24 PM: Update 30825: task edges-pos-ontonotes, batch 825 (30825): mcc: 0.8970, acc: 0.8307, precision: 0.9311, recall: 0.8682, f1: 0.8986, edges-pos-ontonotes_loss: 0.0121
09/16 02:12:34 PM: Update 30889: task edges-pos-ontonotes, batch 889 (30889): mcc: 0.8929, acc: 0.8249, precision: 0.9271, recall: 0.8641, f1: 0.8945, edges-pos-ontonotes_loss: 0.0123
09/16 02:12:44 PM: Update 30951: task edges-pos-ontonotes, batch 951 (30951): mcc: 0.8901, acc: 0.8209, precision: 0.9243, recall: 0.8615, f1: 0.8918, edges-pos-ontonotes_loss: 0.0125
09/16 02:12:53 PM: ***** Step 31000 / Validation 31 *****
09/16 02:12:53 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:12:53 PM: Validating...
09/16 02:12:54 PM: Evaluate: task edges-pos-ontonotes, batch 6 (157): mcc: 0.9086, acc: 0.8589, precision: 0.9321, recall: 0.8892, f1: 0.9102, edges-pos-ontonotes_loss: 0.0108
09/16 02:13:04 PM: Evaluate: task edges-pos-ontonotes, batch 74 (157): mcc: 0.9123, acc: 0.8615, precision: 0.9451, recall: 0.8840, f1: 0.9135, edges-pos-ontonotes_loss: 0.0107
09/16 02:13:15 PM: Evaluate: task edges-pos-ontonotes, batch 124 (157): mcc: 0.9124, acc: 0.8623, precision: 0.9395, recall: 0.8896, f1: 0.9139, edges-pos-ontonotes_loss: 0.0105
09/16 02:13:22 PM: Updating LR scheduler:
09/16 02:13:22 PM: 	Best result seen so far for macro_avg: 0.917
09/16 02:13:22 PM: 	# validation passes without improvement: 2
09/16 02:13:22 PM: edges-pos-ontonotes_loss: training: 0.012725 validation: 0.010417
09/16 02:13:22 PM: macro_avg: validation: 0.915094
09/16 02:13:22 PM: micro_avg: validation: 0.000000
09/16 02:13:22 PM: edges-pos-ontonotes_mcc: training: 0.887821 validation: 0.913590
09/16 02:13:22 PM: edges-pos-ontonotes_acc: training: 0.817689 validation: 0.864863
09/16 02:13:22 PM: edges-pos-ontonotes_precision: training: 0.922036 validation: 0.936944
09/16 02:13:22 PM: edges-pos-ontonotes_recall: training: 0.859204 validation: 0.894240
09/16 02:13:22 PM: edges-pos-ontonotes_f1: training: 0.889512 validation: 0.915094
09/16 02:13:22 PM: Global learning rate: 0.0001
09/16 02:13:22 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:13:25 PM: Update 31017: task edges-pos-ontonotes, batch 17 (31017): mcc: 0.8716, acc: 0.7941, precision: 0.9084, recall: 0.8412, f1: 0.8735, edges-pos-ontonotes_loss: 0.0150
09/16 02:13:35 PM: Update 31073: task edges-pos-ontonotes, batch 73 (31073): mcc: 0.8705, acc: 0.7914, precision: 0.9052, recall: 0.8421, f1: 0.8725, edges-pos-ontonotes_loss: 0.0152
09/16 02:13:45 PM: Update 31128: task edges-pos-ontonotes, batch 128 (31128): mcc: 0.8696, acc: 0.7915, precision: 0.9057, recall: 0.8400, f1: 0.8716, edges-pos-ontonotes_loss: 0.0153
09/16 02:13:55 PM: Update 31205: task edges-pos-ontonotes, batch 205 (31205): mcc: 0.8690, acc: 0.7901, precision: 0.9079, recall: 0.8367, f1: 0.8709, edges-pos-ontonotes_loss: 0.0151
09/16 02:14:05 PM: Update 31276: task edges-pos-ontonotes, batch 276 (31276): mcc: 0.8697, acc: 0.7910, precision: 0.9098, recall: 0.8364, f1: 0.8715, edges-pos-ontonotes_loss: 0.0149
09/16 02:14:15 PM: Update 31341: task edges-pos-ontonotes, batch 341 (31341): mcc: 0.8699, acc: 0.7914, precision: 0.9104, recall: 0.8362, f1: 0.8717, edges-pos-ontonotes_loss: 0.0147
09/16 02:14:25 PM: Update 31408: task edges-pos-ontonotes, batch 408 (31408): mcc: 0.8707, acc: 0.7924, precision: 0.9119, recall: 0.8363, f1: 0.8725, edges-pos-ontonotes_loss: 0.0145
09/16 02:14:43 PM: Update 31454: task edges-pos-ontonotes, batch 454 (31454): mcc: 0.8711, acc: 0.7929, precision: 0.9122, recall: 0.8366, f1: 0.8728, edges-pos-ontonotes_loss: 0.0145
09/16 02:14:53 PM: Update 31504: task edges-pos-ontonotes, batch 504 (31504): mcc: 0.8718, acc: 0.7938, precision: 0.9118, recall: 0.8385, f1: 0.8736, edges-pos-ontonotes_loss: 0.0144
09/16 02:15:03 PM: Update 31562: task edges-pos-ontonotes, batch 562 (31562): mcc: 0.8724, acc: 0.7947, precision: 0.9119, recall: 0.8396, f1: 0.8742, edges-pos-ontonotes_loss: 0.0143
09/16 02:15:13 PM: Update 31617: task edges-pos-ontonotes, batch 617 (31617): mcc: 0.8730, acc: 0.7955, precision: 0.9117, recall: 0.8408, f1: 0.8748, edges-pos-ontonotes_loss: 0.0143
09/16 02:15:23 PM: Update 31691: task edges-pos-ontonotes, batch 691 (31691): mcc: 0.8736, acc: 0.7962, precision: 0.9119, recall: 0.8418, f1: 0.8754, edges-pos-ontonotes_loss: 0.0142
09/16 02:15:34 PM: Update 31760: task edges-pos-ontonotes, batch 760 (31760): mcc: 0.8742, acc: 0.7970, precision: 0.9119, recall: 0.8428, f1: 0.8760, edges-pos-ontonotes_loss: 0.0141
09/16 02:15:44 PM: Update 31807: task edges-pos-ontonotes, batch 807 (31807): mcc: 0.8737, acc: 0.7966, precision: 0.9111, recall: 0.8428, f1: 0.8756, edges-pos-ontonotes_loss: 0.0142
09/16 02:15:54 PM: Update 31862: task edges-pos-ontonotes, batch 862 (31862): mcc: 0.8735, acc: 0.7964, precision: 0.9103, recall: 0.8431, f1: 0.8754, edges-pos-ontonotes_loss: 0.0142
09/16 02:16:04 PM: Update 31917: task edges-pos-ontonotes, batch 917 (31917): mcc: 0.8736, acc: 0.7967, precision: 0.9098, recall: 0.8436, f1: 0.8755, edges-pos-ontonotes_loss: 0.0143
09/16 02:16:14 PM: Update 31972: task edges-pos-ontonotes, batch 972 (31972): mcc: 0.8735, acc: 0.7966, precision: 0.9093, recall: 0.8439, f1: 0.8754, edges-pos-ontonotes_loss: 0.0143
09/16 02:16:20 PM: ***** Step 32000 / Validation 32 *****
09/16 02:16:20 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:16:20 PM: Validating...
09/16 02:16:24 PM: Evaluate: task edges-pos-ontonotes, batch 31 (157): mcc: 0.9076, acc: 0.8536, precision: 0.9478, recall: 0.8726, f1: 0.9087, edges-pos-ontonotes_loss: 0.0109
09/16 02:16:34 PM: Evaluate: task edges-pos-ontonotes, batch 95 (157): mcc: 0.9163, acc: 0.8670, precision: 0.9496, recall: 0.8874, f1: 0.9174, edges-pos-ontonotes_loss: 0.0102
09/16 02:16:45 PM: Evaluate: task edges-pos-ontonotes, batch 141 (157): mcc: 0.9162, acc: 0.8677, precision: 0.9448, recall: 0.8917, f1: 0.9175, edges-pos-ontonotes_loss: 0.0101
09/16 02:16:48 PM: Best result seen so far for edges-pos-ontonotes.
09/16 02:16:48 PM: Best result seen so far for macro.
09/16 02:16:48 PM: Updating LR scheduler:
09/16 02:16:48 PM: 	Best result seen so far for macro_avg: 0.918
09/16 02:16:48 PM: 	# validation passes without improvement: 0
09/16 02:16:48 PM: edges-pos-ontonotes_loss: training: 0.014307 validation: 0.010070
09/16 02:16:48 PM: macro_avg: validation: 0.917905
09/16 02:16:48 PM: micro_avg: validation: 0.000000
09/16 02:16:48 PM: edges-pos-ontonotes_mcc: training: 0.873412 validation: 0.916575
09/16 02:16:48 PM: edges-pos-ontonotes_acc: training: 0.796647 validation: 0.869139
09/16 02:16:48 PM: edges-pos-ontonotes_precision: training: 0.909126 validation: 0.944072
09/16 02:16:48 PM: edges-pos-ontonotes_recall: training: 0.843967 validation: 0.893150
09/16 02:16:48 PM: edges-pos-ontonotes_f1: training: 0.875336 validation: 0.917905
09/16 02:16:48 PM: Global learning rate: 0.0001
09/16 02:16:48 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:16:55 PM: Update 32040: task edges-pos-ontonotes, batch 40 (32040): mcc: 0.8743, acc: 0.7999, precision: 0.9069, recall: 0.8477, f1: 0.8763, edges-pos-ontonotes_loss: 0.0145
09/16 02:17:06 PM: Update 32080: task edges-pos-ontonotes, batch 80 (32080): mcc: 0.8725, acc: 0.7979, precision: 0.9048, recall: 0.8462, f1: 0.8746, edges-pos-ontonotes_loss: 0.0150
09/16 02:17:16 PM: Update 32119: task edges-pos-ontonotes, batch 119 (32119): mcc: 0.8715, acc: 0.7960, precision: 0.9041, recall: 0.8450, f1: 0.8736, edges-pos-ontonotes_loss: 0.0149
09/16 02:17:26 PM: Update 32166: task edges-pos-ontonotes, batch 166 (32166): mcc: 0.8732, acc: 0.7983, precision: 0.9056, recall: 0.8469, f1: 0.8753, edges-pos-ontonotes_loss: 0.0147
09/16 02:17:36 PM: Update 32204: task edges-pos-ontonotes, batch 204 (32204): mcc: 0.8740, acc: 0.7997, precision: 0.9065, recall: 0.8476, f1: 0.8761, edges-pos-ontonotes_loss: 0.0146
09/16 02:17:47 PM: Update 32242: task edges-pos-ontonotes, batch 242 (32242): mcc: 0.8743, acc: 0.8002, precision: 0.9065, recall: 0.8480, f1: 0.8763, edges-pos-ontonotes_loss: 0.0147
09/16 02:17:57 PM: Update 32285: task edges-pos-ontonotes, batch 285 (32285): mcc: 0.8747, acc: 0.8012, precision: 0.9071, recall: 0.8484, f1: 0.8768, edges-pos-ontonotes_loss: 0.0146
09/16 02:18:07 PM: Update 32327: task edges-pos-ontonotes, batch 327 (32327): mcc: 0.8757, acc: 0.8026, precision: 0.9079, recall: 0.8495, f1: 0.8777, edges-pos-ontonotes_loss: 0.0145
09/16 02:18:17 PM: Update 32366: task edges-pos-ontonotes, batch 366 (32366): mcc: 0.8762, acc: 0.8032, precision: 0.9084, recall: 0.8499, f1: 0.8782, edges-pos-ontonotes_loss: 0.0144
09/16 02:18:27 PM: Update 32398: task edges-pos-ontonotes, batch 398 (32398): mcc: 0.8765, acc: 0.8036, precision: 0.9090, recall: 0.8499, f1: 0.8784, edges-pos-ontonotes_loss: 0.0144
09/16 02:18:37 PM: Update 32445: task edges-pos-ontonotes, batch 445 (32445): mcc: 0.8767, acc: 0.8039, precision: 0.9092, recall: 0.8501, f1: 0.8787, edges-pos-ontonotes_loss: 0.0144
09/16 02:18:47 PM: Update 32488: task edges-pos-ontonotes, batch 488 (32488): mcc: 0.8769, acc: 0.8044, precision: 0.9094, recall: 0.8504, f1: 0.8789, edges-pos-ontonotes_loss: 0.0144
09/16 02:18:57 PM: Update 32529: task edges-pos-ontonotes, batch 529 (32529): mcc: 0.8772, acc: 0.8049, precision: 0.9096, recall: 0.8508, f1: 0.8792, edges-pos-ontonotes_loss: 0.0144
09/16 02:19:08 PM: Update 32576: task edges-pos-ontonotes, batch 576 (32576): mcc: 0.8775, acc: 0.8054, precision: 0.9100, recall: 0.8509, f1: 0.8795, edges-pos-ontonotes_loss: 0.0143
09/16 02:19:18 PM: Update 32627: task edges-pos-ontonotes, batch 627 (32627): mcc: 0.8779, acc: 0.8060, precision: 0.9103, recall: 0.8514, f1: 0.8799, edges-pos-ontonotes_loss: 0.0143
09/16 02:19:28 PM: Update 32680: task edges-pos-ontonotes, batch 680 (32680): mcc: 0.8783, acc: 0.8065, precision: 0.9109, recall: 0.8516, f1: 0.8802, edges-pos-ontonotes_loss: 0.0142
09/16 02:19:38 PM: Update 32713: task edges-pos-ontonotes, batch 713 (32713): mcc: 0.8783, acc: 0.8066, precision: 0.9109, recall: 0.8517, f1: 0.8803, edges-pos-ontonotes_loss: 0.0142
09/16 02:19:48 PM: Update 32772: task edges-pos-ontonotes, batch 772 (32772): mcc: 0.8786, acc: 0.8071, precision: 0.9111, recall: 0.8520, f1: 0.8805, edges-pos-ontonotes_loss: 0.0142
09/16 02:19:58 PM: Update 32831: task edges-pos-ontonotes, batch 831 (32831): mcc: 0.8789, acc: 0.8076, precision: 0.9115, recall: 0.8522, f1: 0.8809, edges-pos-ontonotes_loss: 0.0142
09/16 02:20:08 PM: Update 32890: task edges-pos-ontonotes, batch 890 (32890): mcc: 0.8789, acc: 0.8077, precision: 0.9115, recall: 0.8522, f1: 0.8809, edges-pos-ontonotes_loss: 0.0142
09/16 02:20:18 PM: Update 32941: task edges-pos-ontonotes, batch 941 (32941): mcc: 0.8790, acc: 0.8078, precision: 0.9115, recall: 0.8524, f1: 0.8810, edges-pos-ontonotes_loss: 0.0142
09/16 02:20:28 PM: Update 32993: task edges-pos-ontonotes, batch 993 (32993): mcc: 0.8791, acc: 0.8080, precision: 0.9116, recall: 0.8524, f1: 0.8810, edges-pos-ontonotes_loss: 0.0142
09/16 02:20:29 PM: ***** Step 33000 / Validation 33 *****
09/16 02:20:29 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:20:29 PM: Validating...
09/16 02:20:38 PM: Evaluate: task edges-pos-ontonotes, batch 62 (157): mcc: 0.9106, acc: 0.8568, precision: 0.9499, recall: 0.8763, f1: 0.9116, edges-pos-ontonotes_loss: 0.0111
09/16 02:20:48 PM: Evaluate: task edges-pos-ontonotes, batch 115 (157): mcc: 0.9147, acc: 0.8649, precision: 0.9471, recall: 0.8867, f1: 0.9159, edges-pos-ontonotes_loss: 0.0104
09/16 02:20:58 PM: Updating LR scheduler:
09/16 02:20:58 PM: 	Best result seen so far for macro_avg: 0.918
09/16 02:20:58 PM: 	# validation passes without improvement: 1
09/16 02:20:58 PM: edges-pos-ontonotes_loss: training: 0.014190 validation: 0.010176
09/16 02:20:58 PM: macro_avg: validation: 0.917855
09/16 02:20:58 PM: micro_avg: validation: 0.000000
09/16 02:20:58 PM: edges-pos-ontonotes_mcc: training: 0.879149 validation: 0.916551
09/16 02:20:58 PM: edges-pos-ontonotes_acc: training: 0.808031 validation: 0.868800
09/16 02:20:58 PM: edges-pos-ontonotes_precision: training: 0.911662 validation: 0.944961
09/16 02:20:58 PM: edges-pos-ontonotes_recall: training: 0.852478 validation: 0.892261
09/16 02:20:58 PM: edges-pos-ontonotes_f1: training: 0.881077 validation: 0.917855
09/16 02:20:58 PM: Global learning rate: 0.0001
09/16 02:20:58 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:20:59 PM: Update 33006: task edges-pos-ontonotes, batch 6 (33006): mcc: 0.8814, acc: 0.8129, precision: 0.9196, recall: 0.8493, f1: 0.8830, edges-pos-ontonotes_loss: 0.0144
09/16 02:21:11 PM: Update 33019: task edges-pos-ontonotes, batch 19 (33019): mcc: 0.8726, acc: 0.8005, precision: 0.9086, recall: 0.8428, f1: 0.8745, edges-pos-ontonotes_loss: 0.0144
09/16 02:21:21 PM: Update 33079: task edges-pos-ontonotes, batch 79 (33079): mcc: 0.8789, acc: 0.8083, precision: 0.9119, recall: 0.8518, f1: 0.8808, edges-pos-ontonotes_loss: 0.0129
09/16 02:21:32 PM: Update 33137: task edges-pos-ontonotes, batch 137 (33137): mcc: 0.8813, acc: 0.8113, precision: 0.9140, recall: 0.8543, f1: 0.8832, edges-pos-ontonotes_loss: 0.0126
09/16 02:21:42 PM: Update 33188: task edges-pos-ontonotes, batch 188 (33188): mcc: 0.8828, acc: 0.8129, precision: 0.9151, recall: 0.8562, f1: 0.8846, edges-pos-ontonotes_loss: 0.0124
09/16 02:21:52 PM: Update 33239: task edges-pos-ontonotes, batch 239 (33239): mcc: 0.8840, acc: 0.8150, precision: 0.9161, recall: 0.8576, f1: 0.8859, edges-pos-ontonotes_loss: 0.0124
09/16 02:22:02 PM: Update 33293: task edges-pos-ontonotes, batch 293 (33293): mcc: 0.8847, acc: 0.8161, precision: 0.9166, recall: 0.8584, f1: 0.8865, edges-pos-ontonotes_loss: 0.0122
09/16 02:22:12 PM: Update 33341: task edges-pos-ontonotes, batch 341 (33341): mcc: 0.8857, acc: 0.8175, precision: 0.9176, recall: 0.8594, f1: 0.8875, edges-pos-ontonotes_loss: 0.0121
09/16 02:22:23 PM: Update 33421: task edges-pos-ontonotes, batch 421 (33421): mcc: 0.8890, acc: 0.8218, precision: 0.9204, recall: 0.8629, f1: 0.8908, edges-pos-ontonotes_loss: 0.0119
09/16 02:22:33 PM: Update 33507: task edges-pos-ontonotes, batch 507 (33507): mcc: 0.8923, acc: 0.8262, precision: 0.9233, recall: 0.8666, f1: 0.8940, edges-pos-ontonotes_loss: 0.0116
09/16 02:22:43 PM: Update 33595: task edges-pos-ontonotes, batch 595 (33595): mcc: 0.8947, acc: 0.8293, precision: 0.9254, recall: 0.8691, f1: 0.8964, edges-pos-ontonotes_loss: 0.0114
09/16 02:22:53 PM: Update 33667: task edges-pos-ontonotes, batch 667 (33667): mcc: 0.8959, acc: 0.8309, precision: 0.9266, recall: 0.8701, f1: 0.8975, edges-pos-ontonotes_loss: 0.0113
09/16 02:23:03 PM: Update 33772: task edges-pos-ontonotes, batch 772 (33772): mcc: 0.8967, acc: 0.8320, precision: 0.9278, recall: 0.8706, f1: 0.8983, edges-pos-ontonotes_loss: 0.0113
09/16 02:23:13 PM: Update 33876: task edges-pos-ontonotes, batch 876 (33876): mcc: 0.8975, acc: 0.8331, precision: 0.9286, recall: 0.8714, f1: 0.8991, edges-pos-ontonotes_loss: 0.0112
09/16 02:23:23 PM: Update 33958: task edges-pos-ontonotes, batch 958 (33958): mcc: 0.8983, acc: 0.8342, precision: 0.9293, recall: 0.8723, f1: 0.8999, edges-pos-ontonotes_loss: 0.0112
09/16 02:23:27 PM: ***** Step 34000 / Validation 34 *****
09/16 02:23:27 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:23:27 PM: Validating...
09/16 02:23:33 PM: Evaluate: task edges-pos-ontonotes, batch 46 (157): mcc: 0.9068, acc: 0.8537, precision: 0.9417, recall: 0.8768, f1: 0.9081, edges-pos-ontonotes_loss: 0.0112
09/16 02:23:43 PM: Evaluate: task edges-pos-ontonotes, batch 105 (157): mcc: 0.9134, acc: 0.8658, precision: 0.9384, recall: 0.8925, f1: 0.9149, edges-pos-ontonotes_loss: 0.0105
09/16 02:23:53 PM: Evaluate: task edges-pos-ontonotes, batch 150 (157): mcc: 0.9130, acc: 0.8658, precision: 0.9318, recall: 0.8980, f1: 0.9146, edges-pos-ontonotes_loss: 0.0105
09/16 02:23:55 PM: Updating LR scheduler:
09/16 02:23:55 PM: 	Best result seen so far for macro_avg: 0.918
09/16 02:23:55 PM: 	# validation passes without improvement: 2
09/16 02:23:55 PM: edges-pos-ontonotes_loss: training: 0.011338 validation: 0.010477
09/16 02:23:55 PM: macro_avg: validation: 0.915113
09/16 02:23:55 PM: micro_avg: validation: 0.000000
09/16 02:23:55 PM: edges-pos-ontonotes_mcc: training: 0.897666 validation: 0.913499
09/16 02:23:55 PM: edges-pos-ontonotes_acc: training: 0.833159 validation: 0.866800
09/16 02:23:55 PM: edges-pos-ontonotes_precision: training: 0.928923 validation: 0.932097
09/16 02:23:55 PM: edges-pos-ontonotes_recall: training: 0.871438 validation: 0.898738
09/16 02:23:55 PM: edges-pos-ontonotes_f1: training: 0.899263 validation: 0.915113
09/16 02:23:55 PM: Global learning rate: 0.0001
09/16 02:23:55 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:24:03 PM: Update 34114: task edges-pos-ontonotes, batch 114 (34114): mcc: 0.8768, acc: 0.8012, precision: 0.9197, recall: 0.8406, f1: 0.8784, edges-pos-ontonotes_loss: 0.0135
09/16 02:24:13 PM: Update 34219: task edges-pos-ontonotes, batch 219 (34219): mcc: 0.8775, acc: 0.8020, precision: 0.9192, recall: 0.8423, f1: 0.8791, edges-pos-ontonotes_loss: 0.0136
09/16 02:24:24 PM: Update 34280: task edges-pos-ontonotes, batch 280 (34280): mcc: 0.8753, acc: 0.7995, precision: 0.9144, recall: 0.8426, f1: 0.8771, edges-pos-ontonotes_loss: 0.0138
09/16 02:24:34 PM: Update 34328: task edges-pos-ontonotes, batch 328 (34328): mcc: 0.8730, acc: 0.7961, precision: 0.9114, recall: 0.8412, f1: 0.8749, edges-pos-ontonotes_loss: 0.0140
09/16 02:24:44 PM: Update 34380: task edges-pos-ontonotes, batch 380 (34380): mcc: 0.8715, acc: 0.7940, precision: 0.9088, recall: 0.8406, f1: 0.8734, edges-pos-ontonotes_loss: 0.0143
09/16 02:24:54 PM: Update 34420: task edges-pos-ontonotes, batch 420 (34420): mcc: 0.8710, acc: 0.7934, precision: 0.9076, recall: 0.8407, f1: 0.8729, edges-pos-ontonotes_loss: 0.0144
09/16 02:25:04 PM: Update 34465: task edges-pos-ontonotes, batch 465 (34465): mcc: 0.8709, acc: 0.7933, precision: 0.9074, recall: 0.8408, f1: 0.8728, edges-pos-ontonotes_loss: 0.0145
09/16 02:25:15 PM: Update 34505: task edges-pos-ontonotes, batch 505 (34505): mcc: 0.8710, acc: 0.7935, precision: 0.9070, recall: 0.8414, f1: 0.8730, edges-pos-ontonotes_loss: 0.0145
09/16 02:25:25 PM: Update 34552: task edges-pos-ontonotes, batch 552 (34552): mcc: 0.8706, acc: 0.7928, precision: 0.9065, recall: 0.8410, f1: 0.8725, edges-pos-ontonotes_loss: 0.0147
09/16 02:25:35 PM: Update 34597: task edges-pos-ontonotes, batch 597 (34597): mcc: 0.8702, acc: 0.7923, precision: 0.9062, recall: 0.8406, f1: 0.8722, edges-pos-ontonotes_loss: 0.0147
09/16 02:25:45 PM: Update 34641: task edges-pos-ontonotes, batch 641 (34641): mcc: 0.8702, acc: 0.7922, precision: 0.9069, recall: 0.8400, f1: 0.8721, edges-pos-ontonotes_loss: 0.0147
09/16 02:25:56 PM: Update 34710: task edges-pos-ontonotes, batch 710 (34710): mcc: 0.8700, acc: 0.7917, precision: 0.9076, recall: 0.8389, f1: 0.8719, edges-pos-ontonotes_loss: 0.0147
09/16 02:26:06 PM: Update 34788: task edges-pos-ontonotes, batch 788 (34788): mcc: 0.8704, acc: 0.7921, precision: 0.9086, recall: 0.8387, f1: 0.8722, edges-pos-ontonotes_loss: 0.0146
09/16 02:26:16 PM: Update 34880: task edges-pos-ontonotes, batch 880 (34880): mcc: 0.8709, acc: 0.7928, precision: 0.9095, recall: 0.8388, f1: 0.8727, edges-pos-ontonotes_loss: 0.0145
09/16 02:26:26 PM: Update 34936: task edges-pos-ontonotes, batch 936 (34936): mcc: 0.8713, acc: 0.7934, precision: 0.9096, recall: 0.8395, f1: 0.8732, edges-pos-ontonotes_loss: 0.0145
09/16 02:26:36 PM: Update 34998: task edges-pos-ontonotes, batch 998 (34998): mcc: 0.8720, acc: 0.7944, precision: 0.9096, recall: 0.8407, f1: 0.8738, edges-pos-ontonotes_loss: 0.0144
09/16 02:26:37 PM: ***** Step 35000 / Validation 35 *****
09/16 02:26:37 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:26:37 PM: Validating...
09/16 02:26:46 PM: Evaluate: task edges-pos-ontonotes, batch 67 (157): mcc: 0.9144, acc: 0.8638, precision: 0.9481, recall: 0.8852, f1: 0.9156, edges-pos-ontonotes_loss: 0.0104
09/16 02:26:56 PM: Evaluate: task edges-pos-ontonotes, batch 119 (157): mcc: 0.9155, acc: 0.8664, precision: 0.9432, recall: 0.8920, f1: 0.9169, edges-pos-ontonotes_loss: 0.0101
09/16 02:27:05 PM: Updating LR scheduler:
09/16 02:27:05 PM: 	Best result seen so far for macro_avg: 0.918
09/16 02:27:05 PM: 	# validation passes without improvement: 3
09/16 02:27:05 PM: edges-pos-ontonotes_loss: training: 0.014414 validation: 0.010100
09/16 02:27:05 PM: macro_avg: validation: 0.917072
09/16 02:27:05 PM: micro_avg: validation: 0.000000
09/16 02:27:05 PM: edges-pos-ontonotes_mcc: training: 0.871967 validation: 0.915636
09/16 02:27:05 PM: edges-pos-ontonotes_acc: training: 0.794391 validation: 0.867403
09/16 02:27:05 PM: edges-pos-ontonotes_precision: training: 0.909632 validation: 0.940048
09/16 02:27:05 PM: edges-pos-ontonotes_recall: training: 0.840759 validation: 0.895192
09/16 02:27:05 PM: edges-pos-ontonotes_f1: training: 0.873840 validation: 0.917072
09/16 02:27:05 PM: Global learning rate: 0.0001
09/16 02:27:05 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:27:06 PM: Update 35013: task edges-pos-ontonotes, batch 13 (35013): mcc: 0.8683, acc: 0.7899, precision: 0.9047, recall: 0.8383, f1: 0.8703, edges-pos-ontonotes_loss: 0.0150
09/16 02:27:17 PM: Update 35083: task edges-pos-ontonotes, batch 83 (35083): mcc: 0.8754, acc: 0.7990, precision: 0.9100, recall: 0.8469, f1: 0.8773, edges-pos-ontonotes_loss: 0.0140
09/16 02:27:27 PM: Update 35144: task edges-pos-ontonotes, batch 144 (35144): mcc: 0.8768, acc: 0.8012, precision: 0.9118, recall: 0.8480, f1: 0.8787, edges-pos-ontonotes_loss: 0.0138
09/16 02:27:37 PM: Update 35213: task edges-pos-ontonotes, batch 213 (35213): mcc: 0.8789, acc: 0.8042, precision: 0.9130, recall: 0.8508, f1: 0.8808, edges-pos-ontonotes_loss: 0.0135
09/16 02:27:49 PM: Update 35227: task edges-pos-ontonotes, batch 227 (35227): mcc: 0.8782, acc: 0.8030, precision: 0.9126, recall: 0.8499, f1: 0.8801, edges-pos-ontonotes_loss: 0.0136
09/16 02:27:59 PM: Update 35280: task edges-pos-ontonotes, batch 280 (35280): mcc: 0.8764, acc: 0.8011, precision: 0.9097, recall: 0.8491, f1: 0.8784, edges-pos-ontonotes_loss: 0.0139
09/16 02:28:09 PM: Update 35336: task edges-pos-ontonotes, batch 336 (35336): mcc: 0.8756, acc: 0.8000, precision: 0.9087, recall: 0.8485, f1: 0.8776, edges-pos-ontonotes_loss: 0.0141
09/16 02:28:19 PM: Update 35385: task edges-pos-ontonotes, batch 385 (35385): mcc: 0.8752, acc: 0.7996, precision: 0.9081, recall: 0.8483, f1: 0.8772, edges-pos-ontonotes_loss: 0.0142
09/16 02:28:30 PM: Update 35428: task edges-pos-ontonotes, batch 428 (35428): mcc: 0.8751, acc: 0.7995, precision: 0.9079, recall: 0.8483, f1: 0.8771, edges-pos-ontonotes_loss: 0.0142
09/16 02:28:40 PM: Update 35481: task edges-pos-ontonotes, batch 481 (35481): mcc: 0.8750, acc: 0.7994, precision: 0.9077, recall: 0.8483, f1: 0.8770, edges-pos-ontonotes_loss: 0.0142
09/16 02:28:50 PM: Update 35535: task edges-pos-ontonotes, batch 535 (35535): mcc: 0.8750, acc: 0.7995, precision: 0.9074, recall: 0.8486, f1: 0.8770, edges-pos-ontonotes_loss: 0.0143
09/16 02:29:00 PM: Update 35571: task edges-pos-ontonotes, batch 571 (35571): mcc: 0.8749, acc: 0.7995, precision: 0.9071, recall: 0.8486, f1: 0.8769, edges-pos-ontonotes_loss: 0.0143
09/16 02:29:10 PM: Update 35624: task edges-pos-ontonotes, batch 624 (35624): mcc: 0.8750, acc: 0.7997, precision: 0.9072, recall: 0.8488, f1: 0.8770, edges-pos-ontonotes_loss: 0.0143
09/16 02:29:21 PM: Update 35681: task edges-pos-ontonotes, batch 681 (35681): mcc: 0.8757, acc: 0.8007, precision: 0.9077, recall: 0.8496, f1: 0.8777, edges-pos-ontonotes_loss: 0.0143
09/16 02:29:31 PM: Update 35731: task edges-pos-ontonotes, batch 731 (35731): mcc: 0.8757, acc: 0.8009, precision: 0.9077, recall: 0.8496, f1: 0.8777, edges-pos-ontonotes_loss: 0.0142
09/16 02:29:41 PM: Update 35787: task edges-pos-ontonotes, batch 787 (35787): mcc: 0.8761, acc: 0.8017, precision: 0.9081, recall: 0.8500, f1: 0.8781, edges-pos-ontonotes_loss: 0.0142
09/16 02:29:51 PM: Update 35843: task edges-pos-ontonotes, batch 843 (35843): mcc: 0.8764, acc: 0.8023, precision: 0.9083, recall: 0.8503, f1: 0.8784, edges-pos-ontonotes_loss: 0.0142
09/16 02:30:01 PM: Update 35886: task edges-pos-ontonotes, batch 886 (35886): mcc: 0.8765, acc: 0.8025, precision: 0.9085, recall: 0.8504, f1: 0.8785, edges-pos-ontonotes_loss: 0.0142
09/16 02:30:11 PM: Update 35940: task edges-pos-ontonotes, batch 940 (35940): mcc: 0.8766, acc: 0.8028, precision: 0.9087, recall: 0.8505, f1: 0.8786, edges-pos-ontonotes_loss: 0.0142
09/16 02:30:21 PM: Update 35989: task edges-pos-ontonotes, batch 989 (35989): mcc: 0.8768, acc: 0.8032, precision: 0.9089, recall: 0.8506, f1: 0.8788, edges-pos-ontonotes_loss: 0.0142
09/16 02:30:24 PM: ***** Step 36000 / Validation 36 *****
09/16 02:30:24 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:30:24 PM: Validating...
09/16 02:30:31 PM: Evaluate: task edges-pos-ontonotes, batch 38 (157): mcc: 0.9085, acc: 0.8547, precision: 0.9475, recall: 0.8746, f1: 0.9096, edges-pos-ontonotes_loss: 0.0110
09/16 02:30:41 PM: Evaluate: task edges-pos-ontonotes, batch 91 (157): mcc: 0.9168, acc: 0.8670, precision: 0.9495, recall: 0.8884, f1: 0.9179, edges-pos-ontonotes_loss: 0.0103
09/16 02:30:51 PM: Evaluate: task edges-pos-ontonotes, batch 128 (157): mcc: 0.9165, acc: 0.8681, precision: 0.9450, recall: 0.8922, f1: 0.9178, edges-pos-ontonotes_loss: 0.0102
09/16 02:30:59 PM: Best result seen so far for edges-pos-ontonotes.
09/16 02:30:59 PM: Best result seen so far for macro.
09/16 02:30:59 PM: Updating LR scheduler:
09/16 02:30:59 PM: 	Best result seen so far for macro_avg: 0.919
09/16 02:30:59 PM: 	# validation passes without improvement: 0
09/16 02:30:59 PM: edges-pos-ontonotes_loss: training: 0.014196 validation: 0.010028
09/16 02:30:59 PM: macro_avg: validation: 0.919229
09/16 02:30:59 PM: micro_avg: validation: 0.000000
09/16 02:30:59 PM: edges-pos-ontonotes_mcc: training: 0.876908 validation: 0.917879
09/16 02:30:59 PM: edges-pos-ontonotes_acc: training: 0.803338 validation: 0.871509
09/16 02:30:59 PM: edges-pos-ontonotes_precision: training: 0.908963 validation: 0.943722
09/16 02:30:59 PM: edges-pos-ontonotes_recall: training: 0.850759 validation: 0.895976
09/16 02:30:59 PM: edges-pos-ontonotes_f1: training: 0.878898 validation: 0.919229
09/16 02:30:59 PM: Global learning rate: 0.0001
09/16 02:30:59 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:31:02 PM: Update 36012: task edges-pos-ontonotes, batch 12 (36012): mcc: 0.8845, acc: 0.8156, precision: 0.9147, recall: 0.8599, f1: 0.8864, edges-pos-ontonotes_loss: 0.0139
09/16 02:31:12 PM: Update 36059: task edges-pos-ontonotes, batch 59 (36059): mcc: 0.8846, acc: 0.8152, precision: 0.9174, recall: 0.8574, f1: 0.8864, edges-pos-ontonotes_loss: 0.0136
09/16 02:31:22 PM: Update 36102: task edges-pos-ontonotes, batch 102 (36102): mcc: 0.8828, acc: 0.8134, precision: 0.9151, recall: 0.8562, f1: 0.8846, edges-pos-ontonotes_loss: 0.0139
09/16 02:31:32 PM: Update 36138: task edges-pos-ontonotes, batch 138 (36138): mcc: 0.8831, acc: 0.8137, precision: 0.9147, recall: 0.8570, f1: 0.8849, edges-pos-ontonotes_loss: 0.0137
09/16 02:31:42 PM: Update 36168: task edges-pos-ontonotes, batch 168 (36168): mcc: 0.8825, acc: 0.8127, precision: 0.9146, recall: 0.8561, f1: 0.8844, edges-pos-ontonotes_loss: 0.0137
09/16 02:31:52 PM: Update 36222: task edges-pos-ontonotes, batch 222 (36222): mcc: 0.8823, acc: 0.8127, precision: 0.9149, recall: 0.8553, f1: 0.8841, edges-pos-ontonotes_loss: 0.0138
09/16 02:32:02 PM: Update 36270: task edges-pos-ontonotes, batch 270 (36270): mcc: 0.8819, acc: 0.8124, precision: 0.9145, recall: 0.8550, f1: 0.8838, edges-pos-ontonotes_loss: 0.0140
09/16 02:32:13 PM: Update 36321: task edges-pos-ontonotes, batch 321 (36321): mcc: 0.8820, acc: 0.8124, precision: 0.9145, recall: 0.8551, f1: 0.8838, edges-pos-ontonotes_loss: 0.0140
09/16 02:32:23 PM: Update 36373: task edges-pos-ontonotes, batch 373 (36373): mcc: 0.8819, acc: 0.8123, precision: 0.9143, recall: 0.8552, f1: 0.8838, edges-pos-ontonotes_loss: 0.0140
09/16 02:32:33 PM: Update 36429: task edges-pos-ontonotes, batch 429 (36429): mcc: 0.8820, acc: 0.8126, precision: 0.9144, recall: 0.8554, f1: 0.8839, edges-pos-ontonotes_loss: 0.0140
09/16 02:32:43 PM: Update 36474: task edges-pos-ontonotes, batch 474 (36474): mcc: 0.8821, acc: 0.8126, precision: 0.9145, recall: 0.8554, f1: 0.8840, edges-pos-ontonotes_loss: 0.0140
09/16 02:32:53 PM: Update 36518: task edges-pos-ontonotes, batch 518 (36518): mcc: 0.8815, acc: 0.8119, precision: 0.9139, recall: 0.8549, f1: 0.8834, edges-pos-ontonotes_loss: 0.0139
09/16 02:33:03 PM: Update 36571: task edges-pos-ontonotes, batch 571 (36571): mcc: 0.8819, acc: 0.8124, precision: 0.9142, recall: 0.8553, f1: 0.8838, edges-pos-ontonotes_loss: 0.0138
09/16 02:33:14 PM: Update 36608: task edges-pos-ontonotes, batch 608 (36608): mcc: 0.8821, acc: 0.8127, precision: 0.9145, recall: 0.8555, f1: 0.8840, edges-pos-ontonotes_loss: 0.0136
09/16 02:33:24 PM: Update 36648: task edges-pos-ontonotes, batch 648 (36648): mcc: 0.8823, acc: 0.8130, precision: 0.9145, recall: 0.8559, f1: 0.8842, edges-pos-ontonotes_loss: 0.0135
09/16 02:33:34 PM: Update 36712: task edges-pos-ontonotes, batch 712 (36712): mcc: 0.8833, acc: 0.8143, precision: 0.9152, recall: 0.8569, f1: 0.8851, edges-pos-ontonotes_loss: 0.0133
09/16 02:33:44 PM: Update 36770: task edges-pos-ontonotes, batch 770 (36770): mcc: 0.8836, acc: 0.8147, precision: 0.9155, recall: 0.8573, f1: 0.8854, edges-pos-ontonotes_loss: 0.0132
09/16 02:33:54 PM: Update 36836: task edges-pos-ontonotes, batch 836 (36836): mcc: 0.8844, acc: 0.8159, precision: 0.9162, recall: 0.8582, f1: 0.8863, edges-pos-ontonotes_loss: 0.0131
09/16 02:34:04 PM: Update 36926: task edges-pos-ontonotes, batch 926 (36926): mcc: 0.8861, acc: 0.8181, precision: 0.9177, recall: 0.8600, f1: 0.8879, edges-pos-ontonotes_loss: 0.0128
09/16 02:34:13 PM: ***** Step 37000 / Validation 37 *****
09/16 02:34:13 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:34:13 PM: Validating...
09/16 02:34:14 PM: Evaluate: task edges-pos-ontonotes, batch 5 (157): mcc: 0.9051, acc: 0.8563, precision: 0.9368, recall: 0.8781, f1: 0.9065, edges-pos-ontonotes_loss: 0.0111
09/16 02:34:24 PM: Evaluate: task edges-pos-ontonotes, batch 73 (157): mcc: 0.9128, acc: 0.8613, precision: 0.9483, recall: 0.8820, f1: 0.9139, edges-pos-ontonotes_loss: 0.0106
09/16 02:34:34 PM: Evaluate: task edges-pos-ontonotes, batch 123 (157): mcc: 0.9145, acc: 0.8653, precision: 0.9450, recall: 0.8884, f1: 0.9158, edges-pos-ontonotes_loss: 0.0103
09/16 02:34:42 PM: Updating LR scheduler:
09/16 02:34:42 PM: 	Best result seen so far for macro_avg: 0.919
09/16 02:34:42 PM: 	# validation passes without improvement: 1
09/16 02:34:42 PM: edges-pos-ontonotes_loss: training: 0.012631 validation: 0.010143
09/16 02:34:42 PM: macro_avg: validation: 0.917279
09/16 02:34:42 PM: micro_avg: validation: 0.000000
09/16 02:34:42 PM: edges-pos-ontonotes_mcc: training: 0.887319 validation: 0.915922
09/16 02:34:42 PM: edges-pos-ontonotes_acc: training: 0.819669 validation: 0.868588
09/16 02:34:42 PM: edges-pos-ontonotes_precision: training: 0.918882 validation: 0.942983
09/16 02:34:42 PM: edges-pos-ontonotes_recall: training: 0.861217 validation: 0.892938
09/16 02:34:42 PM: edges-pos-ontonotes_f1: training: 0.889116 validation: 0.917279
09/16 02:34:42 PM: Global learning rate: 0.0001
09/16 02:34:42 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:34:44 PM: Update 37019: task edges-pos-ontonotes, batch 19 (37019): mcc: 0.9166, acc: 0.8594, precision: 0.9436, recall: 0.8937, f1: 0.9180, edges-pos-ontonotes_loss: 0.0101
09/16 02:34:54 PM: Update 37093: task edges-pos-ontonotes, batch 93 (37093): mcc: 0.9157, acc: 0.8585, precision: 0.9435, recall: 0.8921, f1: 0.9171, edges-pos-ontonotes_loss: 0.0099
09/16 02:35:05 PM: Update 37105: task edges-pos-ontonotes, batch 105 (37105): mcc: 0.9140, acc: 0.8558, precision: 0.9429, recall: 0.8894, f1: 0.9154, edges-pos-ontonotes_loss: 0.0101
09/16 02:35:15 PM: Update 37200: task edges-pos-ontonotes, batch 200 (37200): mcc: 0.9114, acc: 0.8516, precision: 0.9428, recall: 0.8844, f1: 0.9127, edges-pos-ontonotes_loss: 0.0106
09/16 02:35:25 PM: Update 37271: task edges-pos-ontonotes, batch 271 (37271): mcc: 0.9110, acc: 0.8512, precision: 0.9418, recall: 0.8847, f1: 0.9124, edges-pos-ontonotes_loss: 0.0106
09/16 02:35:36 PM: Update 37365: task edges-pos-ontonotes, batch 365 (37365): mcc: 0.9105, acc: 0.8506, precision: 0.9412, recall: 0.8843, f1: 0.9119, edges-pos-ontonotes_loss: 0.0107
09/16 02:35:46 PM: Update 37449: task edges-pos-ontonotes, batch 449 (37449): mcc: 0.9079, acc: 0.8471, precision: 0.9388, recall: 0.8817, f1: 0.9093, edges-pos-ontonotes_loss: 0.0109
09/16 02:35:56 PM: Update 37587: task edges-pos-ontonotes, batch 587 (37587): mcc: 0.9031, acc: 0.8397, precision: 0.9356, recall: 0.8755, f1: 0.9045, edges-pos-ontonotes_loss: 0.0116
09/16 02:36:06 PM: Update 37719: task edges-pos-ontonotes, batch 719 (37719): mcc: 0.8991, acc: 0.8339, precision: 0.9326, recall: 0.8707, f1: 0.9006, edges-pos-ontonotes_loss: 0.0120
09/16 02:36:16 PM: Update 37769: task edges-pos-ontonotes, batch 769 (37769): mcc: 0.8950, acc: 0.8281, precision: 0.9285, recall: 0.8667, f1: 0.8966, edges-pos-ontonotes_loss: 0.0122
09/16 02:36:26 PM: Update 37831: task edges-pos-ontonotes, batch 831 (37831): mcc: 0.8916, acc: 0.8233, precision: 0.9249, recall: 0.8638, f1: 0.8933, edges-pos-ontonotes_loss: 0.0125
09/16 02:36:36 PM: Update 37890: task edges-pos-ontonotes, batch 890 (37890): mcc: 0.8892, acc: 0.8199, precision: 0.9227, recall: 0.8613, f1: 0.8909, edges-pos-ontonotes_loss: 0.0126
09/16 02:36:46 PM: Update 37952: task edges-pos-ontonotes, batch 952 (37952): mcc: 0.8875, acc: 0.8175, precision: 0.9210, recall: 0.8596, f1: 0.8893, edges-pos-ontonotes_loss: 0.0128
09/16 02:36:54 PM: ***** Step 38000 / Validation 38 *****
09/16 02:36:54 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:36:54 PM: Validating...
09/16 02:36:56 PM: Evaluate: task edges-pos-ontonotes, batch 17 (157): mcc: 0.9032, acc: 0.8480, precision: 0.9393, recall: 0.8722, f1: 0.9045, edges-pos-ontonotes_loss: 0.0113
09/16 02:37:06 PM: Evaluate: task edges-pos-ontonotes, batch 85 (157): mcc: 0.9139, acc: 0.8638, precision: 0.9479, recall: 0.8845, f1: 0.9151, edges-pos-ontonotes_loss: 0.0105
09/16 02:37:16 PM: Evaluate: task edges-pos-ontonotes, batch 131 (157): mcc: 0.9139, acc: 0.8645, precision: 0.9422, recall: 0.8899, f1: 0.9153, edges-pos-ontonotes_loss: 0.0103
09/16 02:37:22 PM: Updating LR scheduler:
09/16 02:37:22 PM: 	Best result seen so far for macro_avg: 0.919
09/16 02:37:22 PM: 	# validation passes without improvement: 2
09/16 02:37:22 PM: edges-pos-ontonotes_loss: training: 0.012908 validation: 0.010232
09/16 02:37:22 PM: macro_avg: validation: 0.916520
09/16 02:37:22 PM: micro_avg: validation: 0.000000
09/16 02:37:22 PM: edges-pos-ontonotes_mcc: training: 0.886507 validation: 0.915119
09/16 02:37:22 PM: edges-pos-ontonotes_acc: training: 0.816018 validation: 0.867276
09/16 02:37:22 PM: edges-pos-ontonotes_precision: training: 0.920050 validation: 0.941205
09/16 02:37:22 PM: edges-pos-ontonotes_recall: training: 0.858573 validation: 0.893097
09/16 02:37:22 PM: edges-pos-ontonotes_f1: training: 0.888249 validation: 0.916520
09/16 02:37:22 PM: Global learning rate: 0.0001
09/16 02:37:22 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:37:27 PM: Update 38019: task edges-pos-ontonotes, batch 19 (38019): mcc: 0.8704, acc: 0.7950, precision: 0.9062, recall: 0.8411, f1: 0.8724, edges-pos-ontonotes_loss: 0.0150
09/16 02:37:37 PM: Update 38061: task edges-pos-ontonotes, batch 61 (38061): mcc: 0.8679, acc: 0.7902, precision: 0.9031, recall: 0.8392, f1: 0.8700, edges-pos-ontonotes_loss: 0.0157
09/16 02:37:47 PM: Update 38130: task edges-pos-ontonotes, batch 130 (38130): mcc: 0.8685, acc: 0.7897, precision: 0.9086, recall: 0.8352, f1: 0.8704, edges-pos-ontonotes_loss: 0.0149
09/16 02:37:57 PM: Update 38213: task edges-pos-ontonotes, batch 213 (38213): mcc: 0.8698, acc: 0.7910, precision: 0.9111, recall: 0.8353, f1: 0.8716, edges-pos-ontonotes_loss: 0.0146
09/16 02:38:07 PM: Update 38308: task edges-pos-ontonotes, batch 308 (38308): mcc: 0.8709, acc: 0.7925, precision: 0.9131, recall: 0.8356, f1: 0.8726, edges-pos-ontonotes_loss: 0.0143
09/16 02:38:17 PM: Update 38380: task edges-pos-ontonotes, batch 380 (38380): mcc: 0.8717, acc: 0.7936, precision: 0.9134, recall: 0.8368, f1: 0.8734, edges-pos-ontonotes_loss: 0.0142
09/16 02:38:27 PM: Update 38449: task edges-pos-ontonotes, batch 449 (38449): mcc: 0.8726, acc: 0.7948, precision: 0.9128, recall: 0.8391, f1: 0.8744, edges-pos-ontonotes_loss: 0.0142
09/16 02:38:37 PM: Update 38516: task edges-pos-ontonotes, batch 516 (38516): mcc: 0.8738, acc: 0.7965, precision: 0.9125, recall: 0.8415, f1: 0.8756, edges-pos-ontonotes_loss: 0.0142
09/16 02:38:47 PM: Update 38596: task edges-pos-ontonotes, batch 596 (38596): mcc: 0.8745, acc: 0.7975, precision: 0.9128, recall: 0.8426, f1: 0.8763, edges-pos-ontonotes_loss: 0.0141
09/16 02:38:57 PM: Update 38661: task edges-pos-ontonotes, batch 661 (38661): mcc: 0.8754, acc: 0.7989, precision: 0.9132, recall: 0.8439, f1: 0.8772, edges-pos-ontonotes_loss: 0.0140
09/16 02:39:08 PM: Update 38703: task edges-pos-ontonotes, batch 703 (38703): mcc: 0.8751, acc: 0.7986, precision: 0.9125, recall: 0.8439, f1: 0.8769, edges-pos-ontonotes_loss: 0.0140
09/16 02:39:18 PM: Update 38745: task edges-pos-ontonotes, batch 745 (38745): mcc: 0.8747, acc: 0.7983, precision: 0.9118, recall: 0.8440, f1: 0.8766, edges-pos-ontonotes_loss: 0.0141
09/16 02:39:28 PM: Update 38784: task edges-pos-ontonotes, batch 784 (38784): mcc: 0.8744, acc: 0.7981, precision: 0.9111, recall: 0.8440, f1: 0.8763, edges-pos-ontonotes_loss: 0.0141
09/16 02:39:38 PM: Update 38826: task edges-pos-ontonotes, batch 826 (38826): mcc: 0.8742, acc: 0.7978, precision: 0.9105, recall: 0.8441, f1: 0.8760, edges-pos-ontonotes_loss: 0.0142
09/16 02:39:48 PM: Update 38884: task edges-pos-ontonotes, batch 884 (38884): mcc: 0.8744, acc: 0.7983, precision: 0.9104, recall: 0.8447, f1: 0.8763, edges-pos-ontonotes_loss: 0.0142
09/16 02:39:58 PM: Update 38937: task edges-pos-ontonotes, batch 937 (38937): mcc: 0.8745, acc: 0.7986, precision: 0.9100, recall: 0.8452, f1: 0.8764, edges-pos-ontonotes_loss: 0.0142
09/16 02:40:10 PM: Update 39000: task edges-pos-ontonotes, batch 1000 (39000): mcc: 0.8745, acc: 0.7987, precision: 0.9098, recall: 0.8455, f1: 0.8765, edges-pos-ontonotes_loss: 0.0142
09/16 02:40:10 PM: ***** Step 39000 / Validation 39 *****
09/16 02:40:10 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:40:10 PM: Validating...
09/16 02:40:28 PM: Evaluate: task edges-pos-ontonotes, batch 68 (157): mcc: 0.9144, acc: 0.8626, precision: 0.9523, recall: 0.8813, f1: 0.9154, edges-pos-ontonotes_loss: 0.0104
09/16 02:40:38 PM: Evaluate: task edges-pos-ontonotes, batch 119 (157): mcc: 0.9166, acc: 0.8670, precision: 0.9495, recall: 0.8880, f1: 0.9177, edges-pos-ontonotes_loss: 0.0100
09/16 02:40:47 PM: Updating LR scheduler:
09/16 02:40:47 PM: 	Best result seen so far for macro_avg: 0.919
09/16 02:40:47 PM: 	# validation passes without improvement: 3
09/16 02:40:47 PM: edges-pos-ontonotes_loss: training: 0.014224 validation: 0.009937
09/16 02:40:47 PM: macro_avg: validation: 0.918142
09/16 02:40:47 PM: micro_avg: validation: 0.000000
09/16 02:40:47 PM: edges-pos-ontonotes_mcc: training: 0.874538 validation: 0.916890
09/16 02:40:47 PM: edges-pos-ontonotes_acc: training: 0.798698 validation: 0.868546
09/16 02:40:47 PM: edges-pos-ontonotes_precision: training: 0.909819 validation: 0.946738
09/16 02:40:47 PM: edges-pos-ontonotes_recall: training: 0.845453 validation: 0.891224
09/16 02:40:47 PM: edges-pos-ontonotes_f1: training: 0.876456 validation: 0.918142
09/16 02:40:47 PM: Global learning rate: 0.0001
09/16 02:40:47 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:40:48 PM: Update 39007: task edges-pos-ontonotes, batch 7 (39007): mcc: 0.8735, acc: 0.7966, precision: 0.9106, recall: 0.8427, f1: 0.8753, edges-pos-ontonotes_loss: 0.0139
09/16 02:40:59 PM: Update 39059: task edges-pos-ontonotes, batch 59 (39059): mcc: 0.8780, acc: 0.8053, precision: 0.9095, recall: 0.8524, f1: 0.8800, edges-pos-ontonotes_loss: 0.0143
09/16 02:41:09 PM: Update 39114: task edges-pos-ontonotes, batch 114 (39114): mcc: 0.8781, acc: 0.8056, precision: 0.9086, recall: 0.8534, f1: 0.8801, edges-pos-ontonotes_loss: 0.0143
09/16 02:41:19 PM: Update 39173: task edges-pos-ontonotes, batch 173 (39173): mcc: 0.8789, acc: 0.8065, precision: 0.9097, recall: 0.8538, f1: 0.8809, edges-pos-ontonotes_loss: 0.0142
09/16 02:41:29 PM: Update 39232: task edges-pos-ontonotes, batch 232 (39232): mcc: 0.8786, acc: 0.8060, precision: 0.9097, recall: 0.8533, f1: 0.8806, edges-pos-ontonotes_loss: 0.0142
09/16 02:41:39 PM: Update 39281: task edges-pos-ontonotes, batch 281 (39281): mcc: 0.8794, acc: 0.8075, precision: 0.9103, recall: 0.8544, f1: 0.8814, edges-pos-ontonotes_loss: 0.0141
09/16 02:41:49 PM: Update 39319: task edges-pos-ontonotes, batch 319 (39319): mcc: 0.8789, acc: 0.8070, precision: 0.9098, recall: 0.8538, f1: 0.8809, edges-pos-ontonotes_loss: 0.0142
09/16 02:42:00 PM: Update 39377: task edges-pos-ontonotes, batch 377 (39377): mcc: 0.8795, acc: 0.8079, precision: 0.9108, recall: 0.8541, f1: 0.8815, edges-pos-ontonotes_loss: 0.0140
09/16 02:42:10 PM: Update 39434: task edges-pos-ontonotes, batch 434 (39434): mcc: 0.8796, acc: 0.8082, precision: 0.9109, recall: 0.8542, f1: 0.8816, edges-pos-ontonotes_loss: 0.0141
09/16 02:42:20 PM: Update 39488: task edges-pos-ontonotes, batch 488 (39488): mcc: 0.8797, acc: 0.8085, precision: 0.9112, recall: 0.8540, f1: 0.8817, edges-pos-ontonotes_loss: 0.0141
09/16 02:42:30 PM: Update 39542: task edges-pos-ontonotes, batch 542 (39542): mcc: 0.8801, acc: 0.8091, precision: 0.9116, recall: 0.8543, f1: 0.8820, edges-pos-ontonotes_loss: 0.0140
09/16 02:42:40 PM: Update 39591: task edges-pos-ontonotes, batch 591 (39591): mcc: 0.8803, acc: 0.8094, precision: 0.9117, recall: 0.8546, f1: 0.8822, edges-pos-ontonotes_loss: 0.0140
09/16 02:42:50 PM: Update 39633: task edges-pos-ontonotes, batch 633 (39633): mcc: 0.8804, acc: 0.8096, precision: 0.9117, recall: 0.8548, f1: 0.8823, edges-pos-ontonotes_loss: 0.0140
09/16 02:43:00 PM: Update 39689: task edges-pos-ontonotes, batch 689 (39689): mcc: 0.8804, acc: 0.8095, precision: 0.9119, recall: 0.8546, f1: 0.8823, edges-pos-ontonotes_loss: 0.0140
09/16 02:43:10 PM: Update 39743: task edges-pos-ontonotes, batch 743 (39743): mcc: 0.8807, acc: 0.8100, precision: 0.9122, recall: 0.8548, f1: 0.8826, edges-pos-ontonotes_loss: 0.0140
09/16 02:43:21 PM: Update 39795: task edges-pos-ontonotes, batch 795 (39795): mcc: 0.8810, acc: 0.8105, precision: 0.9125, recall: 0.8552, f1: 0.8829, edges-pos-ontonotes_loss: 0.0140
09/16 02:43:31 PM: Update 39845: task edges-pos-ontonotes, batch 845 (39845): mcc: 0.8811, acc: 0.8107, precision: 0.9125, recall: 0.8553, f1: 0.8830, edges-pos-ontonotes_loss: 0.0140
09/16 02:43:41 PM: Update 39890: task edges-pos-ontonotes, batch 890 (39890): mcc: 0.8813, acc: 0.8110, precision: 0.9127, recall: 0.8556, f1: 0.8832, edges-pos-ontonotes_loss: 0.0140
09/16 02:43:53 PM: Update 39939: task edges-pos-ontonotes, batch 939 (39939): mcc: 0.8811, acc: 0.8108, precision: 0.9126, recall: 0.8552, f1: 0.8830, edges-pos-ontonotes_loss: 0.0140
09/16 02:44:03 PM: Update 39992: task edges-pos-ontonotes, batch 992 (39992): mcc: 0.8812, acc: 0.8110, precision: 0.9127, recall: 0.8554, f1: 0.8831, edges-pos-ontonotes_loss: 0.0139
09/16 02:44:05 PM: ***** Step 40000 / Validation 40 *****
09/16 02:44:05 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:44:05 PM: Validating...
09/16 02:44:14 PM: Evaluate: task edges-pos-ontonotes, batch 48 (157): mcc: 0.9075, acc: 0.8514, precision: 0.9513, recall: 0.8692, f1: 0.9084, edges-pos-ontonotes_loss: 0.0110
09/16 02:44:24 PM: Evaluate: task edges-pos-ontonotes, batch 98 (157): mcc: 0.9139, acc: 0.8625, precision: 0.9496, recall: 0.8827, f1: 0.9150, edges-pos-ontonotes_loss: 0.0104
09/16 02:44:34 PM: Evaluate: task edges-pos-ontonotes, batch 133 (157): mcc: 0.9148, acc: 0.8650, precision: 0.9463, recall: 0.8877, f1: 0.9160, edges-pos-ontonotes_loss: 0.0102
09/16 02:44:40 PM: Updating LR scheduler:
09/16 02:44:40 PM: 	Best result seen so far for macro_avg: 0.919
09/16 02:44:40 PM: 	# validation passes without improvement: 0
09/16 02:44:40 PM: edges-pos-ontonotes_loss: training: 0.013892 validation: 0.010047
09/16 02:44:40 PM: macro_avg: validation: 0.917772
09/16 02:44:40 PM: micro_avg: validation: 0.000000
09/16 02:44:40 PM: edges-pos-ontonotes_mcc: training: 0.881264 validation: 0.916508
09/16 02:44:40 PM: edges-pos-ontonotes_acc: training: 0.811107 validation: 0.868504
09/16 02:44:40 PM: edges-pos-ontonotes_precision: training: 0.912780 validation: 0.946224
09/16 02:44:40 PM: edges-pos-ontonotes_recall: training: 0.855449 validation: 0.890981
09/16 02:44:40 PM: edges-pos-ontonotes_f1: training: 0.883185 validation: 0.917772
09/16 02:44:40 PM: Global learning rate: 5e-05
09/16 02:44:40 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:44:44 PM: Update 40016: task edges-pos-ontonotes, batch 16 (40016): mcc: 0.8847, acc: 0.8156, precision: 0.9198, recall: 0.8554, f1: 0.8864, edges-pos-ontonotes_loss: 0.0123
09/16 02:44:54 PM: Update 40060: task edges-pos-ontonotes, batch 60 (40060): mcc: 0.8835, acc: 0.8150, precision: 0.9155, recall: 0.8572, f1: 0.8854, edges-pos-ontonotes_loss: 0.0122
09/16 02:45:04 PM: Update 40114: task edges-pos-ontonotes, batch 114 (40114): mcc: 0.8851, acc: 0.8170, precision: 0.9167, recall: 0.8591, f1: 0.8870, edges-pos-ontonotes_loss: 0.0121
09/16 02:45:14 PM: Update 40170: task edges-pos-ontonotes, batch 170 (40170): mcc: 0.8864, acc: 0.8182, precision: 0.9180, recall: 0.8603, f1: 0.8882, edges-pos-ontonotes_loss: 0.0119
09/16 02:45:24 PM: Update 40240: task edges-pos-ontonotes, batch 240 (40240): mcc: 0.8870, acc: 0.8191, precision: 0.9183, recall: 0.8612, f1: 0.8889, edges-pos-ontonotes_loss: 0.0119
09/16 02:45:34 PM: Update 40310: task edges-pos-ontonotes, batch 310 (40310): mcc: 0.8907, acc: 0.8239, precision: 0.9217, recall: 0.8650, f1: 0.8924, edges-pos-ontonotes_loss: 0.0117
09/16 02:45:44 PM: Update 40404: task edges-pos-ontonotes, batch 404 (40404): mcc: 0.8941, acc: 0.8284, precision: 0.9249, recall: 0.8684, f1: 0.8958, edges-pos-ontonotes_loss: 0.0114
09/16 02:45:54 PM: Update 40493: task edges-pos-ontonotes, batch 493 (40493): mcc: 0.8966, acc: 0.8315, precision: 0.9270, recall: 0.8712, f1: 0.8982, edges-pos-ontonotes_loss: 0.0112
09/16 02:46:05 PM: Update 40567: task edges-pos-ontonotes, batch 567 (40567): mcc: 0.8979, acc: 0.8333, precision: 0.9285, recall: 0.8723, f1: 0.8995, edges-pos-ontonotes_loss: 0.0111
09/16 02:46:15 PM: Update 40667: task edges-pos-ontonotes, batch 667 (40667): mcc: 0.8988, acc: 0.8344, precision: 0.9297, recall: 0.8728, f1: 0.9004, edges-pos-ontonotes_loss: 0.0112
09/16 02:46:25 PM: Update 40744: task edges-pos-ontonotes, batch 744 (40744): mcc: 0.8993, acc: 0.8351, precision: 0.9305, recall: 0.8731, f1: 0.9009, edges-pos-ontonotes_loss: 0.0111
09/16 02:46:35 PM: Update 40829: task edges-pos-ontonotes, batch 829 (40829): mcc: 0.9000, acc: 0.8360, precision: 0.9312, recall: 0.8736, f1: 0.9015, edges-pos-ontonotes_loss: 0.0111
09/16 02:46:45 PM: Update 40895: task edges-pos-ontonotes, batch 895 (40895): mcc: 0.8998, acc: 0.8358, precision: 0.9312, recall: 0.8734, f1: 0.9014, edges-pos-ontonotes_loss: 0.0111
09/16 02:46:55 PM: Update 40999: task edges-pos-ontonotes, batch 999 (40999): mcc: 0.8983, acc: 0.8335, precision: 0.9304, recall: 0.8713, f1: 0.8999, edges-pos-ontonotes_loss: 0.0115
09/16 02:46:55 PM: ***** Step 41000 / Validation 41 *****
09/16 02:46:55 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:46:55 PM: Validating...
09/16 02:47:05 PM: Evaluate: task edges-pos-ontonotes, batch 52 (157): mcc: 0.9107, acc: 0.8585, precision: 0.9478, recall: 0.8785, f1: 0.9118, edges-pos-ontonotes_loss: 0.0108
09/16 02:47:15 PM: Evaluate: task edges-pos-ontonotes, batch 104 (157): mcc: 0.9144, acc: 0.8658, precision: 0.9443, recall: 0.8888, f1: 0.9157, edges-pos-ontonotes_loss: 0.0103
09/16 02:47:25 PM: Evaluate: task edges-pos-ontonotes, batch 149 (157): mcc: 0.9144, acc: 0.8669, precision: 0.9382, recall: 0.8947, f1: 0.9159, edges-pos-ontonotes_loss: 0.0102
09/16 02:47:27 PM: Updating LR scheduler:
09/16 02:47:27 PM: 	Best result seen so far for macro_avg: 0.919
09/16 02:47:27 PM: 	# validation passes without improvement: 1
09/16 02:47:27 PM: edges-pos-ontonotes_loss: training: 0.011457 validation: 0.010181
09/16 02:47:27 PM: macro_avg: validation: 0.916487
09/16 02:47:27 PM: micro_avg: validation: 0.000000
09/16 02:47:27 PM: edges-pos-ontonotes_mcc: training: 0.898326 validation: 0.915009
09/16 02:47:27 PM: edges-pos-ontonotes_acc: training: 0.833502 validation: 0.868038
09/16 02:47:27 PM: edges-pos-ontonotes_precision: training: 0.930444 validation: 0.938295
09/16 02:47:27 PM: edges-pos-ontonotes_recall: training: 0.871260 validation: 0.895669
09/16 02:47:27 PM: edges-pos-ontonotes_f1: training: 0.899880 validation: 0.916487
09/16 02:47:27 PM: Global learning rate: 5e-05
09/16 02:47:27 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:47:35 PM: Update 41117: task edges-pos-ontonotes, batch 117 (41117): mcc: 0.8767, acc: 0.8001, precision: 0.9189, recall: 0.8410, f1: 0.8782, edges-pos-ontonotes_loss: 0.0141
09/16 02:47:55 PM: Update 41191: task edges-pos-ontonotes, batch 191 (41191): mcc: 0.8759, acc: 0.7993, precision: 0.9180, recall: 0.8404, f1: 0.8775, edges-pos-ontonotes_loss: 0.0141
09/16 02:48:05 PM: Update 41237: task edges-pos-ontonotes, batch 237 (41237): mcc: 0.8737, acc: 0.7969, precision: 0.9126, recall: 0.8412, f1: 0.8755, edges-pos-ontonotes_loss: 0.0143
09/16 02:48:15 PM: Update 41289: task edges-pos-ontonotes, batch 289 (41289): mcc: 0.8741, acc: 0.7975, precision: 0.9111, recall: 0.8434, f1: 0.8759, edges-pos-ontonotes_loss: 0.0144
09/16 02:48:25 PM: Update 41352: task edges-pos-ontonotes, batch 352 (41352): mcc: 0.8737, acc: 0.7969, precision: 0.9102, recall: 0.8435, f1: 0.8756, edges-pos-ontonotes_loss: 0.0145
09/16 02:48:36 PM: Update 41420: task edges-pos-ontonotes, batch 420 (41420): mcc: 0.8735, acc: 0.7970, precision: 0.9092, recall: 0.8441, f1: 0.8754, edges-pos-ontonotes_loss: 0.0146
09/16 02:48:46 PM: Update 41479: task edges-pos-ontonotes, batch 479 (41479): mcc: 0.8727, acc: 0.7959, precision: 0.9079, recall: 0.8438, f1: 0.8747, edges-pos-ontonotes_loss: 0.0148
09/16 02:48:56 PM: Update 41525: task edges-pos-ontonotes, batch 525 (41525): mcc: 0.8721, acc: 0.7948, precision: 0.9077, recall: 0.8428, f1: 0.8740, edges-pos-ontonotes_loss: 0.0148
09/16 02:49:06 PM: Update 41605: task edges-pos-ontonotes, batch 605 (41605): mcc: 0.8720, acc: 0.7947, precision: 0.9088, recall: 0.8417, f1: 0.8739, edges-pos-ontonotes_loss: 0.0147
09/16 02:49:16 PM: Update 41673: task edges-pos-ontonotes, batch 673 (41673): mcc: 0.8720, acc: 0.7943, precision: 0.9096, recall: 0.8408, f1: 0.8738, edges-pos-ontonotes_loss: 0.0146
09/16 02:49:27 PM: Update 41747: task edges-pos-ontonotes, batch 747 (41747): mcc: 0.8720, acc: 0.7942, precision: 0.9103, recall: 0.8402, f1: 0.8738, edges-pos-ontonotes_loss: 0.0146
09/16 02:49:37 PM: Update 41809: task edges-pos-ontonotes, batch 809 (41809): mcc: 0.8720, acc: 0.7942, precision: 0.9106, recall: 0.8400, f1: 0.8739, edges-pos-ontonotes_loss: 0.0145
09/16 02:49:47 PM: Update 41860: task edges-pos-ontonotes, batch 860 (41860): mcc: 0.8726, acc: 0.7950, precision: 0.9108, recall: 0.8409, f1: 0.8744, edges-pos-ontonotes_loss: 0.0145
09/16 02:49:57 PM: Update 41932: task edges-pos-ontonotes, batch 932 (41932): mcc: 0.8735, acc: 0.7963, precision: 0.9110, recall: 0.8423, f1: 0.8753, edges-pos-ontonotes_loss: 0.0144
09/16 02:50:07 PM: ***** Step 42000 / Validation 42 *****
09/16 02:50:07 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:50:07 PM: Validating...
09/16 02:50:07 PM: Evaluate: task edges-pos-ontonotes, batch 3 (157): mcc: 0.9165, acc: 0.8723, precision: 0.9405, recall: 0.8963, f1: 0.9179, edges-pos-ontonotes_loss: 0.0101
09/16 02:50:17 PM: Evaluate: task edges-pos-ontonotes, batch 65 (157): mcc: 0.9141, acc: 0.8633, precision: 0.9482, recall: 0.8845, f1: 0.9152, edges-pos-ontonotes_loss: 0.0104
09/16 02:50:27 PM: Evaluate: task edges-pos-ontonotes, batch 116 (157): mcc: 0.9162, acc: 0.8676, precision: 0.9442, recall: 0.8923, f1: 0.9175, edges-pos-ontonotes_loss: 0.0100
09/16 02:50:36 PM: Updating LR scheduler:
09/16 02:50:36 PM: 	Best result seen so far for macro_avg: 0.919
09/16 02:50:36 PM: 	# validation passes without improvement: 2
09/16 02:50:36 PM: edges-pos-ontonotes_loss: training: 0.014313 validation: 0.009912
09/16 02:50:36 PM: macro_avg: validation: 0.918442
09/16 02:50:36 PM: micro_avg: validation: 0.000000
09/16 02:50:36 PM: edges-pos-ontonotes_mcc: training: 0.873962 validation: 0.917032
09/16 02:50:36 PM: edges-pos-ontonotes_acc: training: 0.796983 validation: 0.869710
09/16 02:50:36 PM: edges-pos-ontonotes_precision: training: 0.911118 validation: 0.941339
09/16 02:50:36 PM: edges-pos-ontonotes_recall: training: 0.843149 validation: 0.896632
09/16 02:50:36 PM: edges-pos-ontonotes_f1: training: 0.875816 validation: 0.918442
09/16 02:50:36 PM: Global learning rate: 5e-05
09/16 02:50:36 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:50:38 PM: Update 42004: task edges-pos-ontonotes, batch 4 (42004): mcc: 0.8801, acc: 0.8046, precision: 0.9134, recall: 0.8526, f1: 0.8819, edges-pos-ontonotes_loss: 0.0141
09/16 02:50:48 PM: Update 42069: task edges-pos-ontonotes, batch 69 (42069): mcc: 0.8803, acc: 0.8067, precision: 0.9128, recall: 0.8536, f1: 0.8822, edges-pos-ontonotes_loss: 0.0136
09/16 02:50:58 PM: Update 42143: task edges-pos-ontonotes, batch 143 (42143): mcc: 0.8806, acc: 0.8066, precision: 0.9135, recall: 0.8534, f1: 0.8825, edges-pos-ontonotes_loss: 0.0136
09/16 02:51:08 PM: Update 42184: task edges-pos-ontonotes, batch 184 (42184): mcc: 0.8777, acc: 0.8036, precision: 0.9097, recall: 0.8516, f1: 0.8797, edges-pos-ontonotes_loss: 0.0138
09/16 02:51:18 PM: Update 42239: task edges-pos-ontonotes, batch 239 (42239): mcc: 0.8764, acc: 0.8020, precision: 0.9084, recall: 0.8504, f1: 0.8784, edges-pos-ontonotes_loss: 0.0139
09/16 02:51:28 PM: Update 42295: task edges-pos-ontonotes, batch 295 (42295): mcc: 0.8766, acc: 0.8022, precision: 0.9080, recall: 0.8510, f1: 0.8786, edges-pos-ontonotes_loss: 0.0141
09/16 02:51:38 PM: Update 42354: task edges-pos-ontonotes, batch 354 (42354): mcc: 0.8762, acc: 0.8018, precision: 0.9077, recall: 0.8507, f1: 0.8783, edges-pos-ontonotes_loss: 0.0142
09/16 02:51:49 PM: Update 42409: task edges-pos-ontonotes, batch 409 (42409): mcc: 0.8759, acc: 0.8015, precision: 0.9074, recall: 0.8504, f1: 0.8780, edges-pos-ontonotes_loss: 0.0143
09/16 02:51:59 PM: Update 42460: task edges-pos-ontonotes, batch 460 (42460): mcc: 0.8759, acc: 0.8014, precision: 0.9074, recall: 0.8503, f1: 0.8779, edges-pos-ontonotes_loss: 0.0143
09/16 02:52:09 PM: Update 42513: task edges-pos-ontonotes, batch 513 (42513): mcc: 0.8763, acc: 0.8019, precision: 0.9076, recall: 0.8508, f1: 0.8783, edges-pos-ontonotes_loss: 0.0142
09/16 02:52:19 PM: Update 42566: task edges-pos-ontonotes, batch 566 (42566): mcc: 0.8765, acc: 0.8025, precision: 0.9078, recall: 0.8510, f1: 0.8785, edges-pos-ontonotes_loss: 0.0143
09/16 02:52:29 PM: Update 42625: task edges-pos-ontonotes, batch 625 (42625): mcc: 0.8768, acc: 0.8029, precision: 0.9080, recall: 0.8514, f1: 0.8788, edges-pos-ontonotes_loss: 0.0142
09/16 02:52:39 PM: Update 42679: task edges-pos-ontonotes, batch 679 (42679): mcc: 0.8772, acc: 0.8036, precision: 0.9085, recall: 0.8517, f1: 0.8792, edges-pos-ontonotes_loss: 0.0142
09/16 02:52:50 PM: Update 42730: task edges-pos-ontonotes, batch 730 (42730): mcc: 0.8775, acc: 0.8042, precision: 0.9088, recall: 0.8521, f1: 0.8796, edges-pos-ontonotes_loss: 0.0142
09/16 02:53:00 PM: Update 42771: task edges-pos-ontonotes, batch 771 (42771): mcc: 0.8778, acc: 0.8047, precision: 0.9089, recall: 0.8525, f1: 0.8798, edges-pos-ontonotes_loss: 0.0141
09/16 02:53:10 PM: Update 42804: task edges-pos-ontonotes, batch 804 (42804): mcc: 0.8778, acc: 0.8047, precision: 0.9090, recall: 0.8524, f1: 0.8798, edges-pos-ontonotes_loss: 0.0141
09/16 02:53:20 PM: Update 42855: task edges-pos-ontonotes, batch 855 (42855): mcc: 0.8781, acc: 0.8051, precision: 0.9093, recall: 0.8527, f1: 0.8801, edges-pos-ontonotes_loss: 0.0141
09/16 02:53:30 PM: Update 42911: task edges-pos-ontonotes, batch 911 (42911): mcc: 0.8782, acc: 0.8055, precision: 0.9094, recall: 0.8528, f1: 0.8802, edges-pos-ontonotes_loss: 0.0141
09/16 02:53:40 PM: Update 42968: task edges-pos-ontonotes, batch 968 (42968): mcc: 0.8785, acc: 0.8059, precision: 0.9097, recall: 0.8531, f1: 0.8805, edges-pos-ontonotes_loss: 0.0141
09/16 02:53:46 PM: ***** Step 43000 / Validation 43 *****
09/16 02:53:46 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:53:46 PM: Validating...
09/16 02:53:50 PM: Evaluate: task edges-pos-ontonotes, batch 29 (157): mcc: 0.9083, acc: 0.8525, precision: 0.9497, recall: 0.8722, f1: 0.9093, edges-pos-ontonotes_loss: 0.0108
09/16 02:54:00 PM: Evaluate: task edges-pos-ontonotes, batch 94 (157): mcc: 0.9162, acc: 0.8661, precision: 0.9510, recall: 0.8859, f1: 0.9173, edges-pos-ontonotes_loss: 0.0102
09/16 02:54:11 PM: Evaluate: task edges-pos-ontonotes, batch 140 (157): mcc: 0.9170, acc: 0.8685, precision: 0.9467, recall: 0.8915, f1: 0.9183, edges-pos-ontonotes_loss: 0.0100
09/16 02:54:14 PM: Updating LR scheduler:
09/16 02:54:14 PM: 	Best result seen so far for macro_avg: 0.919
09/16 02:54:14 PM: 	# validation passes without improvement: 3
09/16 02:54:14 PM: edges-pos-ontonotes_loss: training: 0.014075 validation: 0.009907
09/16 02:54:14 PM: macro_avg: validation: 0.919202
09/16 02:54:14 PM: micro_avg: validation: 0.000000
09/16 02:54:14 PM: edges-pos-ontonotes_mcc: training: 0.878667 validation: 0.917928
09/16 02:54:14 PM: edges-pos-ontonotes_acc: training: 0.806198 validation: 0.870620
09/16 02:54:14 PM: edges-pos-ontonotes_precision: training: 0.909771 validation: 0.946380
09/16 02:54:14 PM: edges-pos-ontonotes_recall: training: 0.853344 validation: 0.893542
09/16 02:54:14 PM: edges-pos-ontonotes_f1: training: 0.880655 validation: 0.919202
09/16 02:54:14 PM: Global learning rate: 5e-05
09/16 02:54:14 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:54:21 PM: Update 43035: task edges-pos-ontonotes, batch 35 (43035): mcc: 0.8826, acc: 0.8137, precision: 0.9172, recall: 0.8538, f1: 0.8844, edges-pos-ontonotes_loss: 0.0133
09/16 02:54:40 PM: Update 43086: task edges-pos-ontonotes, batch 86 (43086): mcc: 0.8816, acc: 0.8122, precision: 0.9149, recall: 0.8541, f1: 0.8835, edges-pos-ontonotes_loss: 0.0137
09/16 02:54:50 PM: Update 43125: task edges-pos-ontonotes, batch 125 (43125): mcc: 0.8821, acc: 0.8125, precision: 0.9145, recall: 0.8554, f1: 0.8840, edges-pos-ontonotes_loss: 0.0136
09/16 02:55:00 PM: Update 43178: task edges-pos-ontonotes, batch 178 (43178): mcc: 0.8818, acc: 0.8123, precision: 0.9141, recall: 0.8552, f1: 0.8837, edges-pos-ontonotes_loss: 0.0137
09/16 02:55:10 PM: Update 43233: task edges-pos-ontonotes, batch 233 (43233): mcc: 0.8815, acc: 0.8116, precision: 0.9137, recall: 0.8550, f1: 0.8833, edges-pos-ontonotes_loss: 0.0139
09/16 02:55:20 PM: Update 43287: task edges-pos-ontonotes, batch 287 (43287): mcc: 0.8817, acc: 0.8120, precision: 0.9137, recall: 0.8553, f1: 0.8835, edges-pos-ontonotes_loss: 0.0139
09/16 02:55:31 PM: Update 43343: task edges-pos-ontonotes, batch 343 (43343): mcc: 0.8818, acc: 0.8122, precision: 0.9139, recall: 0.8555, f1: 0.8837, edges-pos-ontonotes_loss: 0.0140
09/16 02:55:41 PM: Update 43396: task edges-pos-ontonotes, batch 396 (43396): mcc: 0.8820, acc: 0.8126, precision: 0.9139, recall: 0.8558, f1: 0.8839, edges-pos-ontonotes_loss: 0.0140
09/16 02:55:51 PM: Update 43445: task edges-pos-ontonotes, batch 445 (43445): mcc: 0.8818, acc: 0.8122, precision: 0.9137, recall: 0.8556, f1: 0.8837, edges-pos-ontonotes_loss: 0.0138
09/16 02:56:01 PM: Update 43508: task edges-pos-ontonotes, batch 508 (43508): mcc: 0.8818, acc: 0.8124, precision: 0.9137, recall: 0.8557, f1: 0.8837, edges-pos-ontonotes_loss: 0.0136
09/16 02:56:11 PM: Update 43579: task edges-pos-ontonotes, batch 579 (43579): mcc: 0.8827, acc: 0.8134, precision: 0.9145, recall: 0.8566, f1: 0.8846, edges-pos-ontonotes_loss: 0.0134
09/16 02:56:21 PM: Update 43639: task edges-pos-ontonotes, batch 639 (43639): mcc: 0.8830, acc: 0.8138, precision: 0.9147, recall: 0.8571, f1: 0.8849, edges-pos-ontonotes_loss: 0.0133
09/16 02:56:31 PM: Update 43710: task edges-pos-ontonotes, batch 710 (43710): mcc: 0.8837, acc: 0.8147, precision: 0.9152, recall: 0.8578, f1: 0.8856, edges-pos-ontonotes_loss: 0.0131
09/16 02:56:41 PM: Update 43785: task edges-pos-ontonotes, batch 785 (43785): mcc: 0.8855, acc: 0.8171, precision: 0.9167, recall: 0.8598, f1: 0.8873, edges-pos-ontonotes_loss: 0.0128
09/16 02:56:51 PM: Update 43880: task edges-pos-ontonotes, batch 880 (43880): mcc: 0.8871, acc: 0.8192, precision: 0.9182, recall: 0.8615, f1: 0.8890, edges-pos-ontonotes_loss: 0.0126
09/16 02:57:01 PM: Update 43967: task edges-pos-ontonotes, batch 967 (43967): mcc: 0.8888, acc: 0.8214, precision: 0.9198, recall: 0.8631, f1: 0.8906, edges-pos-ontonotes_loss: 0.0124
09/16 02:57:05 PM: ***** Step 44000 / Validation 44 *****
09/16 02:57:05 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:57:05 PM: Validating...
09/16 02:57:11 PM: Evaluate: task edges-pos-ontonotes, batch 43 (157): mcc: 0.9073, acc: 0.8522, precision: 0.9498, recall: 0.8702, f1: 0.9082, edges-pos-ontonotes_loss: 0.0110
09/16 02:57:21 PM: Evaluate: task edges-pos-ontonotes, batch 102 (157): mcc: 0.9156, acc: 0.8663, precision: 0.9488, recall: 0.8868, f1: 0.9168, edges-pos-ontonotes_loss: 0.0102
09/16 02:57:31 PM: Evaluate: task edges-pos-ontonotes, batch 146 (157): mcc: 0.9160, acc: 0.8683, precision: 0.9442, recall: 0.8919, f1: 0.9173, edges-pos-ontonotes_loss: 0.0101
09/16 02:57:34 PM: Updating LR scheduler:
09/16 02:57:34 PM: 	Best result seen so far for macro_avg: 0.919
09/16 02:57:34 PM: 	# validation passes without improvement: 0
09/16 02:57:34 PM: edges-pos-ontonotes_loss: training: 0.012281 validation: 0.009990
09/16 02:57:34 PM: macro_avg: validation: 0.918470
09/16 02:57:34 PM: micro_avg: validation: 0.000000
09/16 02:57:34 PM: edges-pos-ontonotes_mcc: training: 0.889362 validation: 0.917154
09/16 02:57:34 PM: edges-pos-ontonotes_acc: training: 0.822191 validation: 0.870377
09/16 02:57:34 PM: edges-pos-ontonotes_precision: training: 0.920290 validation: 0.944723
09/16 02:57:34 PM: edges-pos-ontonotes_recall: training: 0.863777 validation: 0.893637
09/16 02:57:34 PM: edges-pos-ontonotes_f1: training: 0.891139 validation: 0.918470
09/16 02:57:34 PM: Global learning rate: 2.5e-05
09/16 02:57:34 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 02:57:41 PM: Update 44069: task edges-pos-ontonotes, batch 69 (44069): mcc: 0.9068, acc: 0.8447, precision: 0.9396, recall: 0.8787, f1: 0.9081, edges-pos-ontonotes_loss: 0.0108
09/16 02:57:51 PM: Update 44175: task edges-pos-ontonotes, batch 175 (44175): mcc: 0.9068, acc: 0.8449, precision: 0.9413, recall: 0.8772, f1: 0.9081, edges-pos-ontonotes_loss: 0.0109
09/16 02:58:02 PM: Update 44272: task edges-pos-ontonotes, batch 272 (44272): mcc: 0.9072, acc: 0.8456, precision: 0.9407, recall: 0.8785, f1: 0.9086, edges-pos-ontonotes_loss: 0.0108
09/16 02:58:12 PM: Update 44369: task edges-pos-ontonotes, batch 369 (44369): mcc: 0.9038, acc: 0.8411, precision: 0.9382, recall: 0.8743, f1: 0.9051, edges-pos-ontonotes_loss: 0.0112
09/16 02:58:22 PM: Update 44521: task edges-pos-ontonotes, batch 521 (44521): mcc: 0.8980, acc: 0.8323, precision: 0.9345, recall: 0.8669, f1: 0.8994, edges-pos-ontonotes_loss: 0.0120
09/16 02:58:34 PM: Update 44651: task edges-pos-ontonotes, batch 651 (44651): mcc: 0.8939, acc: 0.8265, precision: 0.9316, recall: 0.8619, f1: 0.8954, edges-pos-ontonotes_loss: 0.0124
09/16 02:58:44 PM: Update 44710: task edges-pos-ontonotes, batch 710 (44710): mcc: 0.8900, acc: 0.8210, precision: 0.9268, recall: 0.8588, f1: 0.8915, edges-pos-ontonotes_loss: 0.0127
09/16 02:58:54 PM: Update 44773: task edges-pos-ontonotes, batch 773 (44773): mcc: 0.8874, acc: 0.8175, precision: 0.9239, recall: 0.8567, f1: 0.8890, edges-pos-ontonotes_loss: 0.0129
09/16 02:59:04 PM: Update 44833: task edges-pos-ontonotes, batch 833 (44833): mcc: 0.8860, acc: 0.8154, precision: 0.9221, recall: 0.8556, f1: 0.8876, edges-pos-ontonotes_loss: 0.0130
09/16 02:59:14 PM: Update 44886: task edges-pos-ontonotes, batch 886 (44886): mcc: 0.8845, acc: 0.8134, precision: 0.9201, recall: 0.8547, f1: 0.8862, edges-pos-ontonotes_loss: 0.0131
09/16 02:59:24 PM: Update 44949: task edges-pos-ontonotes, batch 949 (44949): mcc: 0.8830, acc: 0.8112, precision: 0.9187, recall: 0.8532, f1: 0.8847, edges-pos-ontonotes_loss: 0.0133
09/16 02:59:33 PM: ***** Step 45000 / Validation 45 *****
09/16 02:59:33 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 02:59:33 PM: Validating...
09/16 02:59:34 PM: Evaluate: task edges-pos-ontonotes, batch 7 (157): mcc: 0.9063, acc: 0.8585, precision: 0.9328, recall: 0.8842, f1: 0.9079, edges-pos-ontonotes_loss: 0.0110
09/16 02:59:44 PM: Evaluate: task edges-pos-ontonotes, batch 76 (157): mcc: 0.9155, acc: 0.8663, precision: 0.9481, recall: 0.8872, f1: 0.9167, edges-pos-ontonotes_loss: 0.0103
09/16 02:59:55 PM: Evaluate: task edges-pos-ontonotes, batch 121 (157): mcc: 0.9163, acc: 0.8684, precision: 0.9443, recall: 0.8924, f1: 0.9176, edges-pos-ontonotes_loss: 0.0101
09/16 03:00:03 PM: Updating LR scheduler:
09/16 03:00:03 PM: 	Best result seen so far for macro_avg: 0.919
09/16 03:00:03 PM: 	# validation passes without improvement: 1
09/16 03:00:03 PM: edges-pos-ontonotes_loss: training: 0.013374 validation: 0.009956
09/16 03:00:03 PM: macro_avg: validation: 0.918722
09/16 03:00:03 PM: micro_avg: validation: 0.000000
09/16 03:00:03 PM: edges-pos-ontonotes_mcc: training: 0.881803 validation: 0.917319
09/16 03:00:03 PM: edges-pos-ontonotes_acc: training: 0.809373 validation: 0.870874
09/16 03:00:03 PM: edges-pos-ontonotes_precision: training: 0.917724 validation: 0.941648
09/16 03:00:03 PM: edges-pos-ontonotes_recall: training: 0.851829 validation: 0.896886
09/16 03:00:03 PM: edges-pos-ontonotes_f1: training: 0.883549 validation: 0.918722
09/16 03:00:03 PM: Global learning rate: 2.5e-05
09/16 03:00:03 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 03:00:05 PM: Update 45020: task edges-pos-ontonotes, batch 20 (45020): mcc: 0.8746, acc: 0.7971, precision: 0.9272, recall: 0.8297, f1: 0.8757, edges-pos-ontonotes_loss: 0.0137
09/16 03:00:15 PM: Update 45104: task edges-pos-ontonotes, batch 104 (45104): mcc: 0.8737, acc: 0.7946, precision: 0.9212, recall: 0.8334, f1: 0.8751, edges-pos-ontonotes_loss: 0.0140
09/16 03:00:25 PM: Update 45189: task edges-pos-ontonotes, batch 189 (45189): mcc: 0.8734, acc: 0.7944, precision: 0.9202, recall: 0.8337, f1: 0.8748, edges-pos-ontonotes_loss: 0.0139
09/16 03:00:35 PM: Update 45286: task edges-pos-ontonotes, batch 286 (45286): mcc: 0.8732, acc: 0.7946, precision: 0.9198, recall: 0.8337, f1: 0.8746, edges-pos-ontonotes_loss: 0.0139
09/16 03:00:45 PM: Update 45294: task edges-pos-ontonotes, batch 294 (45294): mcc: 0.8734, acc: 0.7950, precision: 0.9198, recall: 0.8341, f1: 0.8749, edges-pos-ontonotes_loss: 0.0139
09/16 03:00:55 PM: Update 45358: task edges-pos-ontonotes, batch 358 (45358): mcc: 0.8751, acc: 0.7979, precision: 0.9175, recall: 0.8394, f1: 0.8767, edges-pos-ontonotes_loss: 0.0139
09/16 03:01:05 PM: Update 45438: task edges-pos-ontonotes, batch 438 (45438): mcc: 0.8763, acc: 0.8000, precision: 0.9167, recall: 0.8424, f1: 0.8780, edges-pos-ontonotes_loss: 0.0138
09/16 03:01:15 PM: Update 45513: task edges-pos-ontonotes, batch 513 (45513): mcc: 0.8770, acc: 0.8010, precision: 0.9157, recall: 0.8446, f1: 0.8787, edges-pos-ontonotes_loss: 0.0138
09/16 03:01:25 PM: Update 45581: task edges-pos-ontonotes, batch 581 (45581): mcc: 0.8777, acc: 0.8020, precision: 0.9156, recall: 0.8460, f1: 0.8794, edges-pos-ontonotes_loss: 0.0138
09/16 03:01:36 PM: Update 45630: task edges-pos-ontonotes, batch 630 (45630): mcc: 0.8775, acc: 0.8020, precision: 0.9145, recall: 0.8467, f1: 0.8793, edges-pos-ontonotes_loss: 0.0138
09/16 03:01:46 PM: Update 45685: task edges-pos-ontonotes, batch 685 (45685): mcc: 0.8771, acc: 0.8016, precision: 0.9132, recall: 0.8471, f1: 0.8789, edges-pos-ontonotes_loss: 0.0138
09/16 03:01:56 PM: Update 45742: task edges-pos-ontonotes, batch 742 (45742): mcc: 0.8769, acc: 0.8017, precision: 0.9123, recall: 0.8476, f1: 0.8787, edges-pos-ontonotes_loss: 0.0139
09/16 03:02:06 PM: Update 45798: task edges-pos-ontonotes, batch 798 (45798): mcc: 0.8767, acc: 0.8017, precision: 0.9115, recall: 0.8479, f1: 0.8786, edges-pos-ontonotes_loss: 0.0139
09/16 03:02:16 PM: Update 45860: task edges-pos-ontonotes, batch 860 (45860): mcc: 0.8765, acc: 0.8015, precision: 0.9111, recall: 0.8479, f1: 0.8784, edges-pos-ontonotes_loss: 0.0140
09/16 03:02:26 PM: Update 45915: task edges-pos-ontonotes, batch 915 (45915): mcc: 0.8765, acc: 0.8018, precision: 0.9108, recall: 0.8483, f1: 0.8784, edges-pos-ontonotes_loss: 0.0140
09/16 03:02:36 PM: Update 45959: task edges-pos-ontonotes, batch 959 (45959): mcc: 0.8766, acc: 0.8019, precision: 0.9106, recall: 0.8486, f1: 0.8785, edges-pos-ontonotes_loss: 0.0141
09/16 03:02:44 PM: ***** Step 46000 / Validation 46 *****
09/16 03:02:44 PM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/16 03:02:44 PM: Validating...
09/16 03:02:46 PM: Evaluate: task edges-pos-ontonotes, batch 17 (157): mcc: 0.9066, acc: 0.8527, precision: 0.9421, recall: 0.8760, f1: 0.9078, edges-pos-ontonotes_loss: 0.0109
09/16 03:02:56 PM: Evaluate: task edges-pos-ontonotes, batch 85 (157): mcc: 0.9164, acc: 0.8664, precision: 0.9506, recall: 0.8866, f1: 0.9175, edges-pos-ontonotes_loss: 0.0101
09/16 03:03:06 PM: Evaluate: task edges-pos-ontonotes, batch 131 (157): mcc: 0.9165, acc: 0.8679, precision: 0.9455, recall: 0.8917, f1: 0.9178, edges-pos-ontonotes_loss: 0.0100
09/16 03:03:12 PM: Updating LR scheduler:
09/16 03:03:12 PM: 	Best result seen so far for macro_avg: 0.919
09/16 03:03:12 PM: 	# validation passes without improvement: 2
09/16 03:03:12 PM: Ran out of early stopping patience. Stopping training.
09/16 03:03:12 PM: edges-pos-ontonotes_loss: training: 0.014070 validation: 0.009862
09/16 03:03:12 PM: macro_avg: validation: 0.918990
09/16 03:03:12 PM: micro_avg: validation: 0.000000
09/16 03:03:12 PM: edges-pos-ontonotes_mcc: training: 0.876678 validation: 0.917666
09/16 03:03:12 PM: edges-pos-ontonotes_acc: training: 0.802103 validation: 0.870557
09/16 03:03:12 PM: edges-pos-ontonotes_precision: training: 0.910554 validation: 0.944618
09/16 03:03:12 PM: edges-pos-ontonotes_recall: training: 0.848824 validation: 0.894716
09/16 03:03:12 PM: edges-pos-ontonotes_f1: training: 0.878606 validation: 0.918990
09/16 03:03:12 PM: Global learning rate: 2.5e-05
09/16 03:03:12 PM: Saving checkpoints to: ./experiments/pos-ontonotes-sts-top/run
09/16 03:03:12 PM: Stopped training after 46 validation checks
09/16 03:03:12 PM: Trained edges-pos-ontonotes for 46000 batches or 13.318 epochs
09/16 03:03:12 PM: ***** VALIDATION RESULTS *****
09/16 03:03:12 PM: edges-pos-ontonotes_f1 (for best val pass 36): edges-pos-ontonotes_loss: 0.01003, macro_avg: 0.91923, micro_avg: 0.00000, edges-pos-ontonotes_mcc: 0.91788, edges-pos-ontonotes_acc: 0.87151, edges-pos-ontonotes_precision: 0.94372, edges-pos-ontonotes_recall: 0.89598, edges-pos-ontonotes_f1: 0.91923
09/16 03:03:12 PM: micro_avg (for best val pass 1): edges-pos-ontonotes_loss: 0.04512, macro_avg: 0.54095, micro_avg: 0.00000, edges-pos-ontonotes_mcc: 0.59069, edges-pos-ontonotes_acc: 0.37530, edges-pos-ontonotes_precision: 0.92883, edges-pos-ontonotes_recall: 0.38160, edges-pos-ontonotes_f1: 0.54095
09/16 03:03:12 PM: macro_avg (for best val pass 36): edges-pos-ontonotes_loss: 0.01003, macro_avg: 0.91923, micro_avg: 0.00000, edges-pos-ontonotes_mcc: 0.91788, edges-pos-ontonotes_acc: 0.87151, edges-pos-ontonotes_precision: 0.94372, edges-pos-ontonotes_recall: 0.89598, edges-pos-ontonotes_f1: 0.91923
09/16 03:03:12 PM: Evaluating...
09/16 03:03:12 PM: Loaded model state from ./experiments/pos-ontonotes-sts-top/run/edges-pos-ontonotes/model_state_target_train_val_36.best.th
09/16 03:03:12 PM: Evaluating on: edges-pos-ontonotes, split: val
09/16 03:03:42 PM: 	Task edges-pos-ontonotes: batch 155
09/16 03:04:12 PM: 	Task edges-pos-ontonotes: batch 281
09/16 03:04:43 PM: 	Task edges-pos-ontonotes: batch 460
09/16 03:04:45 PM: Task 'edges-pos-ontonotes': sorting predictions by 'idx'
09/16 03:04:45 PM: Finished evaluating on: edges-pos-ontonotes
09/16 03:04:46 PM: Task 'edges-pos-ontonotes': joining predictions with input split 'val'
09/16 03:04:57 PM: Task 'edges-pos-ontonotes': Wrote predictions to ./experiments/pos-ontonotes-sts-top/run
09/16 03:04:57 PM: Wrote all preds for split 'val' to ./experiments/pos-ontonotes-sts-top/run
09/16 03:04:57 PM: Evaluating on: edges-pos-ontonotes, split: test
09/16 03:05:27 PM: 	Task edges-pos-ontonotes: batch 150
09/16 03:05:57 PM: 	Task edges-pos-ontonotes: batch 251
09/16 03:06:15 PM: Task 'edges-pos-ontonotes': sorting predictions by 'idx'
09/16 03:06:15 PM: Finished evaluating on: edges-pos-ontonotes
09/16 03:06:15 PM: Task 'edges-pos-ontonotes': joining predictions with input split 'test'
09/16 03:06:24 PM: Task 'edges-pos-ontonotes': Wrote predictions to ./experiments/pos-ontonotes-sts-top/run
09/16 03:06:24 PM: Wrote all preds for split 'test' to ./experiments/pos-ontonotes-sts-top/run
09/16 03:06:24 PM: Writing results for split 'val' to ./experiments/pos-ontonotes-sts-top/results.tsv
09/16 03:06:24 PM: micro_avg: 0.000, macro_avg: 0.921, edges-pos-ontonotes_mcc: 0.920, edges-pos-ontonotes_acc: 0.875, edges-pos-ontonotes_precision: 0.942, edges-pos-ontonotes_recall: 0.901, edges-pos-ontonotes_f1: 0.921
09/16 03:06:25 PM: Done!
09/16 03:06:25 PM: Fatal error in main():
Traceback (most recent call last):
  File "main.py", line 16, in <module>
    main(sys.argv[1:])
  File "/srv/home/ericwallace/jiant/jiant/__main__.py", line 610, in main
    exit("Done exited")
  File "/home/ericwallace/miniconda3/envs/jiant/lib/python3.6/_sitebuiltins.py", line 26, in __call__
    raise SystemExit(code)
SystemExit: Done exited
=======
