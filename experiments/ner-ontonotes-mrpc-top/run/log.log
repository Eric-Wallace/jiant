09/16 05:59:29 AM: Git branch: master
09/16 05:59:29 AM: Git SHA: 03401462a9f5f9b569ed41ceca48ecd81700406f
09/16 05:59:30 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/ner-ontonotes-mrpc-top/",
  "exp_name": "experiments/ner-ontonotes-mrpc-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/ner-ontonotes-mrpc-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/mrpc",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/ner-ontonotes-mrpc-top__run",
  "run_dir": "./experiments/ner-ontonotes-mrpc-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-ner-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 05:59:30 AM: Saved config to ./experiments/ner-ontonotes-mrpc-top/run/params.conf
09/16 05:59:30 AM: Using random seed 1234
09/16 05:59:53 AM: Git branch: master
09/16 05:59:53 AM: Git SHA: 03401462a9f5f9b569ed41ceca48ecd81700406f
09/16 05:59:54 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/ner-ontonotes-mrpc-top/",
  "exp_name": "experiments/ner-ontonotes-mrpc-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/ner-ontonotes-mrpc-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/mrpc",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/ner-ontonotes-mrpc-top__run",
  "run_dir": "./experiments/ner-ontonotes-mrpc-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-ner-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 05:59:54 AM: Saved config to ./experiments/ner-ontonotes-mrpc-top/run/params.conf
09/16 05:59:54 AM: Using random seed 1234
09/16 06:00:33 AM: Using GPU 0
09/16 06:00:33 AM: Loading tasks...
09/16 06:00:33 AM: Writing pre-preprocessed tasks to ./experiments/ner-ontonotes-mrpc-top/
09/16 06:00:33 AM: 	Creating task edges-ner-ontonotes from scratch.
09/16 06:00:33 AM: Using GPU 0
09/16 06:00:33 AM: Loading tasks...
09/16 06:00:33 AM: Writing pre-preprocessed tasks to ./experiments/ner-ontonotes-mrpc-top/
09/16 06:00:33 AM: 	Creating task edges-ner-ontonotes from scratch.
09/16 06:00:35 AM: Read=49706, Skip=66106, Total=115812 from ./probing_data/edges/ontonotes/ner/train.json.retokenized.bert-base-uncased
09/16 06:00:35 AM: Read=49706, Skip=66106, Total=115812 from ./probing_data/edges/ontonotes/ner/train.json.retokenized.bert-base-uncased
09/16 06:00:36 AM: Read=7610, Skip=8070, Total=15680 from ./probing_data/edges/ontonotes/ner/development.json.retokenized.bert-base-uncased
09/16 06:00:36 AM: Read=7610, Skip=8070, Total=15680 from ./probing_data/edges/ontonotes/ner/development.json.retokenized.bert-base-uncased
09/16 06:00:36 AM: Read=5099, Skip=7118, Total=12217 from ./probing_data/edges/ontonotes/ner/test.json.retokenized.bert-base-uncased
09/16 06:00:36 AM: Read=5099, Skip=7118, Total=12217 from ./probing_data/edges/ontonotes/ner/test.json.retokenized.bert-base-uncased
09/16 06:00:38 AM: 	Task 'edges-ner-ontonotes': |train|=49706 |val|=7610 |test|=5099
09/16 06:00:38 AM: 	Finished loading tasks: edges-ner-ontonotes.
09/16 06:00:38 AM: 	Building vocab from scratch.
09/16 06:00:38 AM: 	Counting units for task edges-ner-ontonotes.
09/16 06:00:39 AM: 	Task 'edges-ner-ontonotes': |train|=49706 |val|=7610 |test|=5099
09/16 06:00:39 AM: 	Finished loading tasks: edges-ner-ontonotes.
09/16 06:00:39 AM: 	Building vocab from scratch.
09/16 06:00:39 AM: 	Counting units for task edges-ner-ontonotes.
09/16 06:00:41 AM: 	Task 'edges-ner-ontonotes': adding vocab namespace 'edges-ner-ontonotes_labels'
09/16 06:00:41 AM: 	Task 'edges-ner-ontonotes': adding vocab namespace 'edges-ner-ontonotes_labels'
09/16 06:00:42 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:42 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 06:00:43 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:43 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 06:00:43 AM: 	Saved vocab to ./experiments/ner-ontonotes-mrpc-top/vocab
09/16 06:00:43 AM: Loading token dictionary from ./experiments/ner-ontonotes-mrpc-top/vocab.
09/16 06:00:43 AM: vocabulary serialization directory ./experiments/ner-ontonotes-mrpc-top/vocab is not empty
09/16 06:00:43 AM: 	Loaded vocab from ./experiments/ner-ontonotes-mrpc-top/vocab
09/16 06:00:43 AM: 	Vocab namespace edges-ner-ontonotes_labels: size 18
09/16 06:00:43 AM: 	Vocab namespace tokens: size 22840
09/16 06:00:43 AM: 	Vocab namespace bert_uncased: size 30524
09/16 06:00:43 AM: 	Vocab namespace chars: size 77
09/16 06:00:43 AM: 	Finished building vocab.
09/16 06:00:43 AM: 	Task edges-ner-ontonotes (train): Indexing from scratch.
09/16 06:00:43 AM: 	Saved vocab to ./experiments/ner-ontonotes-mrpc-top/vocab
09/16 06:00:43 AM: Loading token dictionary from ./experiments/ner-ontonotes-mrpc-top/vocab.
09/16 06:00:43 AM: 	Loaded vocab from ./experiments/ner-ontonotes-mrpc-top/vocab
09/16 06:00:43 AM: 	Vocab namespace edges-ner-ontonotes_labels: size 18
09/16 06:00:43 AM: 	Vocab namespace tokens: size 22840
09/16 06:00:43 AM: 	Vocab namespace bert_uncased: size 30524
09/16 06:00:43 AM: 	Vocab namespace chars: size 77
09/16 06:00:43 AM: 	Finished building vocab.
09/16 06:00:43 AM: 	Task 'edges-ner-ontonotes', split 'train': Found preprocessed copy in ./experiments/ner-ontonotes-mrpc-top/preproc/edges-ner-ontonotes__train_data
09/16 06:00:43 AM: 	Task edges-ner-ontonotes (val): Indexing from scratch.
09/16 06:00:46 AM: 	Task edges-ner-ontonotes (val): Saved 7610 instances to ./experiments/ner-ontonotes-mrpc-top/preproc/edges-ner-ontonotes__val_data
09/16 06:00:46 AM: 	Task edges-ner-ontonotes (test): Indexing from scratch.
09/16 06:00:48 AM: 	Task edges-ner-ontonotes (test): Saved 5099 instances to ./experiments/ner-ontonotes-mrpc-top/preproc/edges-ner-ontonotes__test_data
09/16 06:00:48 AM: 	Finished indexing tasks
09/16 06:00:48 AM: 	Creating trimmed target-only version of edges-ner-ontonotes train.
09/16 06:00:48 AM: 	  Training on 
09/16 06:00:48 AM: 	  Evaluating on edges-ner-ontonotes
09/16 06:00:48 AM: 	Finished loading tasks in 14.574s
09/16 06:00:48 AM: 	 Tasks: ['edges-ner-ontonotes']
09/16 06:00:48 AM: Building model...
09/16 06:00:48 AM: Using BERT model (bert-base-uncased).
09/16 06:00:48 AM: LOADING A FUNETUNED MODEL from: 
09/16 06:00:48 AM: models/mrpc
09/16 06:00:48 AM: loading configuration file models/mrpc/config.json
09/16 06:00:48 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "mrpc",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 06:00:48 AM: loading weights file models/mrpc/pytorch_model.bin
09/16 06:00:54 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpcip8zc4c
09/16 06:00:56 AM: copying /tmp/tmpcip8zc4c to cache at ./experiments/ner-ontonotes-mrpc-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:56 AM: creating metadata file for ./experiments/ner-ontonotes-mrpc-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:56 AM: removing temp file /tmp/tmpcip8zc4c
09/16 06:00:56 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/ner-ontonotes-mrpc-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:56 AM: Initializing parameters
09/16 06:00:56 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 06:00:56 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 06:00:56 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 06:00:56 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 06:00:56 AM: 	Task 'edges-ner-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-ner-ontonotes"
}
09/16 06:01:01 AM: 	Task edges-ner-ontonotes (train): Saved 49706 instances to ./experiments/ner-ontonotes-mrpc-top/preproc/edges-ner-ontonotes__train_data
09/16 06:01:01 AM: 	Task 'edges-ner-ontonotes', split 'val': Found preprocessed copy in ./experiments/ner-ontonotes-mrpc-top/preproc/edges-ner-ontonotes__val_data
09/16 06:01:01 AM: 	Task 'edges-ner-ontonotes', split 'test': Found preprocessed copy in ./experiments/ner-ontonotes-mrpc-top/preproc/edges-ner-ontonotes__test_data
09/16 06:01:01 AM: 	Finished indexing tasks
09/16 06:01:01 AM: 	Creating trimmed target-only version of edges-ner-ontonotes train.
09/16 06:01:01 AM: 	  Training on 
09/16 06:01:01 AM: 	  Evaluating on edges-ner-ontonotes
09/16 06:01:01 AM: 	Finished loading tasks in 27.788s
09/16 06:01:01 AM: 	 Tasks: ['edges-ner-ontonotes']
09/16 06:01:01 AM: Building model...
09/16 06:01:01 AM: Using BERT model (bert-base-uncased).
09/16 06:01:01 AM: LOADING A FUNETUNED MODEL from: 
09/16 06:01:01 AM: models/mrpc
09/16 06:01:01 AM: loading configuration file models/mrpc/config.json
09/16 06:01:01 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "mrpc",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 06:01:01 AM: loading weights file models/mrpc/pytorch_model.bin
09/16 06:01:07 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/ner-ontonotes-mrpc-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:01:07 AM: Initializing parameters
09/16 06:01:07 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 06:01:07 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 06:01:07 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 06:01:07 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 06:01:07 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 06:01:07 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 06:01:07 AM: 	Task 'edges-ner-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-ner-ontonotes"
}
09/16 06:01:25 AM: Model specification:
09/16 06:01:25 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-ner-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=18, bias=True)
    )
  )
)
09/16 06:01:25 AM: Model parameters:
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:25 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:25 AM: 	edges-ner-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 06:01:25 AM: 	edges-ner-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 06:01:25 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 9216 with torch.Size([18, 512])
09/16 06:01:25 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 18 with torch.Size([18])
09/16 06:01:25 AM: Total number of parameters: 109688338 (1.09688e+08)
09/16 06:01:25 AM: Number of trainable parameters: 206098 (206098)
09/16 06:01:25 AM: Finished building model in 37.270s
09/16 06:01:25 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-ner-ontonotes 

09/16 06:01:29 AM: patience = 9
09/16 06:01:29 AM: val_interval = 1000
09/16 06:01:30 AM: max_vals = 250
09/16 06:01:30 AM: cuda_device = 0
09/16 06:01:30 AM: grad_norm = 5.0
09/16 06:01:30 AM: grad_clipping = None
09/16 06:01:30 AM: lr_decay = 0.99
09/16 06:01:30 AM: min_lr = 1e-06
09/16 06:01:30 AM: keep_all_checkpoints = 0
09/16 06:01:30 AM: val_data_limit = 5000
09/16 06:01:30 AM: max_epochs = -1
09/16 06:01:30 AM: dec_val_scale = 250
09/16 06:01:30 AM: training_data_fraction = 1
09/16 06:01:30 AM: type = adam
09/16 06:01:30 AM: parameter_groups = None
09/16 06:01:30 AM: Number of trainable parameters: 206098
09/16 06:01:30 AM: infer_type_and_cast = True
09/16 06:01:30 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:30 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:30 AM: lr = 0.0001
09/16 06:01:30 AM: amsgrad = True
09/16 06:01:30 AM: type = reduce_on_plateau
09/16 06:01:30 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:30 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:30 AM: mode = max
09/16 06:01:30 AM: factor = 0.5
09/16 06:01:30 AM: patience = 3
09/16 06:01:30 AM: threshold = 0.0001
09/16 06:01:30 AM: threshold_mode = abs
09/16 06:01:30 AM: verbose = True
09/16 06:01:30 AM: type = adam
09/16 06:01:30 AM: parameter_groups = None
09/16 06:01:30 AM: Number of trainable parameters: 206098
09/16 06:01:30 AM: infer_type_and_cast = True
09/16 06:01:30 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:30 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:30 AM: lr = 0.0001
09/16 06:01:30 AM: amsgrad = True
09/16 06:01:30 AM: type = reduce_on_plateau
09/16 06:01:30 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:30 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:30 AM: mode = max
09/16 06:01:30 AM: factor = 0.5
09/16 06:01:30 AM: patience = 3
09/16 06:01:30 AM: threshold = 0.0001
09/16 06:01:30 AM: threshold_mode = abs
09/16 06:01:30 AM: verbose = True
09/16 06:01:30 AM: Starting training without restoring from a checkpoint.
09/16 06:01:30 AM: Training examples per task, before any subsampling: {'edges-ner-ontonotes': 49706}
09/16 06:01:30 AM: Beginning training with stopping criteria based on metric: edges-ner-ontonotes_f1
09/16 06:01:37 AM: Model specification:
09/16 06:01:37 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-ner-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=18, bias=True)
    )
  )
)
09/16 06:01:37 AM: Model parameters:
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:37 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:37 AM: 	edges-ner-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 06:01:37 AM: 	edges-ner-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 06:01:37 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 9216 with torch.Size([18, 512])
09/16 06:01:37 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 18 with torch.Size([18])
09/16 06:01:37 AM: Total number of parameters: 109688338 (1.09688e+08)
09/16 06:01:37 AM: Number of trainable parameters: 206098 (206098)
09/16 06:01:37 AM: Finished building model in 35.598s
09/16 06:01:37 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-ner-ontonotes 

09/16 06:01:43 AM: patience = 9
09/16 06:01:43 AM: val_interval = 1000
09/16 06:01:43 AM: max_vals = 250
09/16 06:01:43 AM: cuda_device = 0
09/16 06:01:43 AM: grad_norm = 5.0
09/16 06:01:43 AM: grad_clipping = None
09/16 06:01:43 AM: lr_decay = 0.99
09/16 06:01:43 AM: min_lr = 1e-06
09/16 06:01:43 AM: keep_all_checkpoints = 0
09/16 06:01:43 AM: val_data_limit = 5000
09/16 06:01:43 AM: max_epochs = -1
09/16 06:01:43 AM: dec_val_scale = 250
09/16 06:01:43 AM: training_data_fraction = 1
09/16 06:01:43 AM: type = adam
09/16 06:01:43 AM: parameter_groups = None
09/16 06:01:43 AM: Number of trainable parameters: 206098
09/16 06:01:43 AM: infer_type_and_cast = True
09/16 06:01:43 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:43 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:43 AM: lr = 0.0001
09/16 06:01:43 AM: amsgrad = True
09/16 06:01:43 AM: type = reduce_on_plateau
09/16 06:01:43 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:43 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:43 AM: mode = max
09/16 06:01:43 AM: factor = 0.5
09/16 06:01:43 AM: patience = 3
09/16 06:01:43 AM: threshold = 0.0001
09/16 06:01:43 AM: threshold_mode = abs
09/16 06:01:43 AM: verbose = True
09/16 06:01:43 AM: type = adam
09/16 06:01:43 AM: parameter_groups = None
09/16 06:01:43 AM: Number of trainable parameters: 206098
09/16 06:01:43 AM: infer_type_and_cast = True
09/16 06:01:43 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:43 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:43 AM: lr = 0.0001
09/16 06:01:43 AM: amsgrad = True
09/16 06:01:43 AM: type = reduce_on_plateau
09/16 06:01:43 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:43 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:43 AM: mode = max
09/16 06:01:43 AM: factor = 0.5
09/16 06:01:43 AM: patience = 3
09/16 06:01:43 AM: threshold = 0.0001
09/16 06:01:43 AM: threshold_mode = abs
09/16 06:01:43 AM: verbose = True
09/16 06:01:43 AM: Starting training without restoring from a checkpoint.
09/16 06:01:43 AM: Training examples per task, before any subsampling: {'edges-ner-ontonotes': 49706}
09/16 06:01:43 AM: Beginning training with stopping criteria based on metric: edges-ner-ontonotes_f1
09/16 06:01:46 AM: Update 27: task edges-ner-ontonotes, batch 27 (27): mcc: 0.0150, acc: 0.0199, precision: 0.0648, recall: 0.1422, f1: 0.0890, edges-ner-ontonotes_loss: 0.5356
09/16 06:01:56 AM: Update 156: task edges-ner-ontonotes, batch 156 (156): mcc: 0.0291, acc: 0.0197, precision: 0.0967, recall: 0.0444, f1: 0.0609, edges-ner-ontonotes_loss: 0.2452
09/16 06:01:57 AM: Update 27: task edges-ner-ontonotes, batch 27 (27): mcc: 0.0150, acc: 0.0199, precision: 0.0648, recall: 0.1422, f1: 0.0890, edges-ner-ontonotes_loss: 0.5356
09/16 06:02:06 AM: Update 251: task edges-ner-ontonotes, batch 251 (251): mcc: 0.1526, acc: 0.0942, precision: 0.2975, recall: 0.1095, f1: 0.1601, edges-ner-ontonotes_loss: 0.2007
09/16 06:02:07 AM: Update 121: task edges-ner-ontonotes, batch 121 (121): mcc: 0.0124, acc: 0.0091, precision: 0.0714, recall: 0.0403, f1: 0.0515, edges-ner-ontonotes_loss: 0.2735
09/16 06:02:17 AM: Update 314: task edges-ner-ontonotes, batch 314 (314): mcc: 0.2385, acc: 0.1479, precision: 0.4322, recall: 0.1604, f1: 0.2339, edges-ner-ontonotes_loss: 0.1824
09/16 06:02:17 AM: Update 229: task edges-ner-ontonotes, batch 229 (229): mcc: 0.1211, acc: 0.0752, precision: 0.2462, recall: 0.0918, f1: 0.1338, edges-ner-ontonotes_loss: 0.2088
09/16 06:02:27 AM: Update 378: task edges-ner-ontonotes, batch 378 (378): mcc: 0.3354, acc: 0.2151, precision: 0.5655, recall: 0.2259, f1: 0.3228, edges-ner-ontonotes_loss: 0.1680
09/16 06:02:29 AM: Update 314: task edges-ner-ontonotes, batch 314 (314): mcc: 0.2385, acc: 0.1479, precision: 0.4322, recall: 0.1604, f1: 0.2339, edges-ner-ontonotes_loss: 0.1824
09/16 06:02:37 AM: Update 466: task edges-ner-ontonotes, batch 466 (466): mcc: 0.4302, acc: 0.2914, precision: 0.6724, recall: 0.3012, f1: 0.4161, edges-ner-ontonotes_loss: 0.1520
09/16 06:02:40 AM: Update 381: task edges-ner-ontonotes, batch 381 (381): mcc: 0.3397, acc: 0.2183, precision: 0.5707, recall: 0.2291, f1: 0.3269, edges-ner-ontonotes_loss: 0.1672
09/16 06:02:47 AM: Update 538: task edges-ner-ontonotes, batch 538 (538): mcc: 0.4923, acc: 0.3469, precision: 0.7309, recall: 0.3569, f1: 0.4796, edges-ner-ontonotes_loss: 0.1416
09/16 06:02:50 AM: Update 458: task edges-ner-ontonotes, batch 458 (458): mcc: 0.4238, acc: 0.2859, precision: 0.6657, recall: 0.2958, f1: 0.4096, edges-ner-ontonotes_loss: 0.1534
09/16 06:02:57 AM: Update 609: task edges-ner-ontonotes, batch 609 (609): mcc: 0.5354, acc: 0.3892, precision: 0.7661, recall: 0.3989, f1: 0.5246, edges-ner-ontonotes_loss: 0.1330
09/16 06:03:00 AM: Update 534: task edges-ner-ontonotes, batch 534 (534): mcc: 0.4893, acc: 0.3440, precision: 0.7284, recall: 0.3539, f1: 0.4764, edges-ner-ontonotes_loss: 0.1421
09/16 06:03:07 AM: Update 667: task edges-ner-ontonotes, batch 667 (667): mcc: 0.5645, acc: 0.4181, precision: 0.7897, recall: 0.4277, f1: 0.5549, edges-ner-ontonotes_loss: 0.1270
09/16 06:03:10 AM: Update 610: task edges-ner-ontonotes, batch 610 (610): mcc: 0.5357, acc: 0.3895, precision: 0.7663, recall: 0.3992, f1: 0.5250, edges-ner-ontonotes_loss: 0.1329
09/16 06:03:17 AM: Update 739: task edges-ner-ontonotes, batch 739 (739): mcc: 0.5993, acc: 0.4548, precision: 0.8150, recall: 0.4642, f1: 0.5915, edges-ner-ontonotes_loss: 0.1203
09/16 06:03:20 AM: Update 672: task edges-ner-ontonotes, batch 672 (672): mcc: 0.5676, acc: 0.4213, precision: 0.7922, recall: 0.4308, f1: 0.5581, edges-ner-ontonotes_loss: 0.1265
09/16 06:03:28 AM: Update 812: task edges-ner-ontonotes, batch 812 (812): mcc: 0.6255, acc: 0.4840, precision: 0.8314, recall: 0.4936, f1: 0.6194, edges-ner-ontonotes_loss: 0.1144
09/16 06:03:30 AM: Update 741: task edges-ner-ontonotes, batch 741 (741): mcc: 0.6000, acc: 0.4556, precision: 0.8154, recall: 0.4650, f1: 0.5922, edges-ner-ontonotes_loss: 0.1201
09/16 06:03:38 AM: Update 885: task edges-ner-ontonotes, batch 885 (885): mcc: 0.6486, acc: 0.5108, precision: 0.8445, recall: 0.5206, f1: 0.6441, edges-ner-ontonotes_loss: 0.1089
09/16 06:03:40 AM: Update 818: task edges-ner-ontonotes, batch 818 (818): mcc: 0.6276, acc: 0.4864, precision: 0.8325, recall: 0.4960, f1: 0.6216, edges-ner-ontonotes_loss: 0.1139
09/16 06:03:48 AM: Update 940: task edges-ner-ontonotes, batch 940 (940): mcc: 0.6641, acc: 0.5293, precision: 0.8528, recall: 0.5392, f1: 0.6607, edges-ner-ontonotes_loss: 0.1053
09/16 06:03:50 AM: Update 900: task edges-ner-ontonotes, batch 900 (900): mcc: 0.6531, acc: 0.5161, precision: 0.8469, recall: 0.5259, f1: 0.6489, edges-ner-ontonotes_loss: 0.1079
09/16 06:03:56 AM: ***** Step 1000 / Validation 1 *****
09/16 06:03:56 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:03:56 AM: Validating...
09/16 06:03:58 AM: Evaluate: task edges-ner-ontonotes, batch 18 (157): mcc: 0.7401, acc: 0.6655, precision: 0.8423, recall: 0.6727, f1: 0.7480, edges-ner-ontonotes_loss: 0.0783
09/16 06:04:00 AM: Update 949: task edges-ner-ontonotes, batch 949 (949): mcc: 0.6666, acc: 0.5324, precision: 0.8542, recall: 0.5423, f1: 0.6634, edges-ner-ontonotes_loss: 0.1048
09/16 06:04:06 AM: ***** Step 1000 / Validation 1 *****
09/16 06:04:06 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:04:06 AM: Validating...
09/16 06:04:10 AM: Evaluate: task edges-ner-ontonotes, batch 36 (157): mcc: 0.7827, acc: 0.7141, precision: 0.8669, recall: 0.7265, f1: 0.7905, edges-ner-ontonotes_loss: 0.0703
09/16 06:04:11 AM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.8079, acc: 0.7440, precision: 0.8825, recall: 0.7576, f1: 0.8153, edges-ner-ontonotes_loss: 0.0650
09/16 06:04:20 AM: Evaluate: task edges-ner-ontonotes, batch 70 (157): mcc: 0.8224, acc: 0.7593, precision: 0.8929, recall: 0.7744, f1: 0.8294, edges-ner-ontonotes_loss: 0.0612
09/16 06:04:21 AM: Evaluate: task edges-ner-ontonotes, batch 100 (157): mcc: 0.8395, acc: 0.7800, precision: 0.9034, recall: 0.7956, f1: 0.8461, edges-ner-ontonotes_loss: 0.0565
09/16 06:04:31 AM: Evaluate: task edges-ner-ontonotes, batch 145 (157): mcc: 0.8612, acc: 0.8063, precision: 0.9194, recall: 0.8203, f1: 0.8670, edges-ner-ontonotes_loss: 0.0509
09/16 06:04:33 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:04:33 AM: Best result seen so far for micro.
09/16 06:04:33 AM: Best result seen so far for macro.
09/16 06:04:33 AM: Updating LR scheduler:
09/16 06:04:33 AM: 	Best result seen so far for macro_avg: 0.867
09/16 06:04:33 AM: 	# validation passes without improvement: 0
09/16 06:04:33 AM: edges-ner-ontonotes_loss: training: 0.101927 validation: 0.050454
09/16 06:04:33 AM: macro_avg: validation: 0.866875
09/16 06:04:33 AM: micro_avg: validation: 0.000000
09/16 06:04:33 AM: edges-ner-ontonotes_mcc: training: 0.678520 validation: 0.861073
09/16 06:04:33 AM: edges-ner-ontonotes_acc: training: 0.546800 validation: 0.806112
09/16 06:04:33 AM: edges-ner-ontonotes_precision: training: 0.859992 validation: 0.919259
09/16 06:04:33 AM: edges-ner-ontonotes_recall: training: 0.557052 validation: 0.820140
09/16 06:04:33 AM: edges-ner-ontonotes_f1: training: 0.676140 validation: 0.866875
09/16 06:04:33 AM: Global learning rate: 0.0001
09/16 06:04:33 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:04:34 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.8503, acc: 0.7932, precision: 0.9110, recall: 0.8081, f1: 0.8565, edges-ner-ontonotes_loss: 0.0537
09/16 06:04:41 AM: Update 1056: task edges-ner-ontonotes, batch 56 (1056): mcc: 0.8650, acc: 0.7984, precision: 0.9379, recall: 0.8105, f1: 0.8695, edges-ner-ontonotes_loss: 0.0454
09/16 06:04:43 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:04:43 AM: Best result seen so far for micro.
09/16 06:04:43 AM: Best result seen so far for macro.
09/16 06:04:43 AM: Updating LR scheduler:
09/16 06:04:43 AM: 	Best result seen so far for macro_avg: 0.867
09/16 06:04:43 AM: 	# validation passes without improvement: 0
09/16 06:04:43 AM: edges-ner-ontonotes_loss: training: 0.101927 validation: 0.050454
09/16 06:04:43 AM: macro_avg: validation: 0.866875
09/16 06:04:43 AM: micro_avg: validation: 0.000000
09/16 06:04:43 AM: edges-ner-ontonotes_mcc: training: 0.678520 validation: 0.861073
09/16 06:04:43 AM: edges-ner-ontonotes_acc: training: 0.546800 validation: 0.806112
09/16 06:04:43 AM: edges-ner-ontonotes_precision: training: 0.859992 validation: 0.919259
09/16 06:04:43 AM: edges-ner-ontonotes_recall: training: 0.557052 validation: 0.820140
09/16 06:04:43 AM: edges-ner-ontonotes_f1: training: 0.676140 validation: 0.866875
09/16 06:04:43 AM: Global learning rate: 0.0001
09/16 06:04:43 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:04:45 AM: Update 1001: task edges-ner-ontonotes, batch 1 (1001): mcc: 0.9361, acc: 0.8922, precision: 0.9891, recall: 0.8922, f1: 0.9381, edges-ner-ontonotes_loss: 0.0376
09/16 06:04:51 AM: Update 1135: task edges-ner-ontonotes, batch 135 (1135): mcc: 0.8677, acc: 0.8045, precision: 0.9360, recall: 0.8170, f1: 0.8724, edges-ner-ontonotes_loss: 0.0455
09/16 06:04:55 AM: Update 1076: task edges-ner-ontonotes, batch 76 (1076): mcc: 0.8671, acc: 0.8033, precision: 0.9367, recall: 0.8153, f1: 0.8718, edges-ner-ontonotes_loss: 0.0451
09/16 06:05:02 AM: Update 1208: task edges-ner-ontonotes, batch 208 (1208): mcc: 0.8725, acc: 0.8103, precision: 0.9393, recall: 0.8226, f1: 0.8771, edges-ner-ontonotes_loss: 0.0441
09/16 06:05:05 AM: Update 1151: task edges-ner-ontonotes, batch 151 (1151): mcc: 0.8690, acc: 0.8054, precision: 0.9375, recall: 0.8179, f1: 0.8736, edges-ner-ontonotes_loss: 0.0451
09/16 06:05:13 AM: Update 1256: task edges-ner-ontonotes, batch 256 (1256): mcc: 0.8690, acc: 0.8057, precision: 0.9366, recall: 0.8187, f1: 0.8737, edges-ner-ontonotes_loss: 0.0440
09/16 06:05:15 AM: Update 1235: task edges-ner-ontonotes, batch 235 (1235): mcc: 0.8711, acc: 0.8085, precision: 0.9379, recall: 0.8213, f1: 0.8758, edges-ner-ontonotes_loss: 0.0439
09/16 06:05:23 AM: Update 1334: task edges-ner-ontonotes, batch 334 (1334): mcc: 0.8603, acc: 0.7938, precision: 0.9317, recall: 0.8076, f1: 0.8652, edges-ner-ontonotes_loss: 0.0474
09/16 06:05:25 AM: Update 1299: task edges-ner-ontonotes, batch 299 (1299): mcc: 0.8640, acc: 0.7990, precision: 0.9334, recall: 0.8127, f1: 0.8689, edges-ner-ontonotes_loss: 0.0460
09/16 06:05:35 AM: Update 1412: task edges-ner-ontonotes, batch 412 (1412): mcc: 0.8564, acc: 0.7877, precision: 0.9307, recall: 0.8015, f1: 0.8613, edges-ner-ontonotes_loss: 0.0489
09/16 06:05:35 AM: Update 1372: task edges-ner-ontonotes, batch 372 (1372): mcc: 0.8580, acc: 0.7902, precision: 0.9312, recall: 0.8038, f1: 0.8628, edges-ner-ontonotes_loss: 0.0485
09/16 06:05:45 AM: Update 1486: task edges-ner-ontonotes, batch 486 (1486): mcc: 0.8548, acc: 0.7855, precision: 0.9303, recall: 0.7990, f1: 0.8597, edges-ner-ontonotes_loss: 0.0491
09/16 06:05:45 AM: Update 1446: task edges-ner-ontonotes, batch 446 (1446): mcc: 0.8559, acc: 0.7869, precision: 0.9307, recall: 0.8006, f1: 0.8608, edges-ner-ontonotes_loss: 0.0490
09/16 06:05:55 AM: Update 1530: task edges-ner-ontonotes, batch 530 (1530): mcc: 0.8532, acc: 0.7837, precision: 0.9291, recall: 0.7972, f1: 0.8581, edges-ner-ontonotes_loss: 0.0499
09/16 06:05:56 AM: Update 1557: task edges-ner-ontonotes, batch 557 (1557): mcc: 0.8530, acc: 0.7834, precision: 0.9291, recall: 0.7969, f1: 0.8579, edges-ner-ontonotes_loss: 0.0498
09/16 06:06:07 AM: Update 1602: task edges-ner-ontonotes, batch 602 (1602): mcc: 0.8522, acc: 0.7828, precision: 0.9280, recall: 0.7964, f1: 0.8572, edges-ner-ontonotes_loss: 0.0498
09/16 06:06:07 AM: Update 1650: task edges-ner-ontonotes, batch 650 (1650): mcc: 0.8512, acc: 0.7815, precision: 0.9274, recall: 0.7952, f1: 0.8562, edges-ner-ontonotes_loss: 0.0499
09/16 06:06:20 AM: Update 1691: task edges-ner-ontonotes, batch 691 (1691): mcc: 0.8513, acc: 0.7815, precision: 0.9273, recall: 0.7954, f1: 0.8563, edges-ner-ontonotes_loss: 0.0496
09/16 06:06:20 AM: Update 1741: task edges-ner-ontonotes, batch 741 (1741): mcc: 0.8506, acc: 0.7807, precision: 0.9267, recall: 0.7947, f1: 0.8556, edges-ner-ontonotes_loss: 0.0496
09/16 06:06:30 AM: Update 1828: task edges-ner-ontonotes, batch 828 (1828): mcc: 0.8514, acc: 0.7818, precision: 0.9268, recall: 0.7959, f1: 0.8564, edges-ner-ontonotes_loss: 0.0491
09/16 06:06:30 AM: Update 1779: task edges-ner-ontonotes, batch 779 (1779): mcc: 0.8505, acc: 0.7809, precision: 0.9260, recall: 0.7951, f1: 0.8556, edges-ner-ontonotes_loss: 0.0496
09/16 06:06:40 AM: Update 1888: task edges-ner-ontonotes, batch 888 (1888): mcc: 0.8521, acc: 0.7828, precision: 0.9268, recall: 0.7972, f1: 0.8572, edges-ner-ontonotes_loss: 0.0487
09/16 06:06:43 AM: Update 1870: task edges-ner-ontonotes, batch 870 (1870): mcc: 0.8519, acc: 0.7826, precision: 0.9270, recall: 0.7967, f1: 0.8569, edges-ner-ontonotes_loss: 0.0488
09/16 06:06:50 AM: Update 1975: task edges-ner-ontonotes, batch 975 (1975): mcc: 0.8545, acc: 0.7863, precision: 0.9276, recall: 0.8009, f1: 0.8596, edges-ner-ontonotes_loss: 0.0478
09/16 06:06:53 AM: Update 1943: task edges-ner-ontonotes, batch 943 (1943): mcc: 0.8537, acc: 0.7850, precision: 0.9275, recall: 0.7994, f1: 0.8587, edges-ner-ontonotes_loss: 0.0482
09/16 06:06:54 AM: ***** Step 2000 / Validation 2 *****
09/16 06:06:54 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:06:54 AM: Validating...
09/16 06:07:00 AM: Evaluate: task edges-ner-ontonotes, batch 44 (157): mcc: 0.8551, acc: 0.8033, precision: 0.9137, recall: 0.8144, f1: 0.8612, edges-ner-ontonotes_loss: 0.0440
09/16 06:07:03 AM: ***** Step 2000 / Validation 2 *****
09/16 06:07:04 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:07:04 AM: Validating...
09/16 06:07:05 AM: Evaluate: task edges-ner-ontonotes, batch 1 (157): mcc: 0.7233, acc: 0.6230, precision: 0.8478, recall: 0.6393, f1: 0.7290, edges-ner-ontonotes_loss: 0.0721
09/16 06:07:10 AM: Evaluate: task edges-ner-ontonotes, batch 98 (157): mcc: 0.8862, acc: 0.8396, precision: 0.9347, recall: 0.8516, f1: 0.8912, edges-ner-ontonotes_loss: 0.0370
09/16 06:07:15 AM: Evaluate: task edges-ner-ontonotes, batch 54 (157): mcc: 0.8653, acc: 0.8161, precision: 0.9201, recall: 0.8269, f1: 0.8710, edges-ner-ontonotes_loss: 0.0421
09/16 06:07:21 AM: Evaluate: task edges-ner-ontonotes, batch 139 (157): mcc: 0.8963, acc: 0.8509, precision: 0.9425, recall: 0.8628, f1: 0.9009, edges-ner-ontonotes_loss: 0.0347
09/16 06:07:25 AM: Evaluate: task edges-ner-ontonotes, batch 99 (157): mcc: 0.8817, acc: 0.8337, precision: 0.9310, recall: 0.8467, f1: 0.8869, edges-ner-ontonotes_loss: 0.0378
09/16 06:07:25 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:07:25 AM: Best result seen so far for macro.
09/16 06:07:25 AM: Updating LR scheduler:
09/16 06:07:25 AM: 	Best result seen so far for macro_avg: 0.900
09/16 06:07:25 AM: 	# validation passes without improvement: 0
09/16 06:07:25 AM: edges-ner-ontonotes_loss: training: 0.047637 validation: 0.034567
09/16 06:07:25 AM: macro_avg: validation: 0.899770
09/16 06:07:25 AM: micro_avg: validation: 0.000000
09/16 06:07:25 AM: edges-ner-ontonotes_mcc: training: 0.855164 validation: 0.895120
09/16 06:07:25 AM: edges-ner-ontonotes_acc: training: 0.787368 validation: 0.848954
09/16 06:07:25 AM: edges-ner-ontonotes_precision: training: 0.927703 validation: 0.941279
09/16 06:07:25 AM: edges-ner-ontonotes_recall: training: 0.801920 validation: 0.861768
09/16 06:07:25 AM: edges-ner-ontonotes_f1: training: 0.860238 validation: 0.899770
09/16 06:07:25 AM: Global learning rate: 0.0001
09/16 06:07:25 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:07:31 AM: Update 2033: task edges-ner-ontonotes, batch 33 (2033): mcc: 0.8878, acc: 0.8347, precision: 0.9387, recall: 0.8509, f1: 0.8926, edges-ner-ontonotes_loss: 0.0350
09/16 06:07:35 AM: Evaluate: task edges-ner-ontonotes, batch 157 (157): mcc: 0.8951, acc: 0.8490, precision: 0.9413, recall: 0.8618, f1: 0.8998, edges-ner-ontonotes_loss: 0.0346
09/16 06:07:35 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:07:35 AM: Best result seen so far for macro.
09/16 06:07:35 AM: Updating LR scheduler:
09/16 06:07:35 AM: 	Best result seen so far for macro_avg: 0.900
09/16 06:07:35 AM: 	# validation passes without improvement: 0
09/16 06:07:35 AM: edges-ner-ontonotes_loss: training: 0.047637 validation: 0.034567
09/16 06:07:35 AM: macro_avg: validation: 0.899770
09/16 06:07:35 AM: micro_avg: validation: 0.000000
09/16 06:07:35 AM: edges-ner-ontonotes_mcc: training: 0.855164 validation: 0.895120
09/16 06:07:35 AM: edges-ner-ontonotes_acc: training: 0.787368 validation: 0.848954
09/16 06:07:35 AM: edges-ner-ontonotes_precision: training: 0.927703 validation: 0.941279
09/16 06:07:35 AM: edges-ner-ontonotes_recall: training: 0.801920 validation: 0.861768
09/16 06:07:35 AM: edges-ner-ontonotes_f1: training: 0.860238 validation: 0.899770
09/16 06:07:35 AM: Global learning rate: 0.0001
09/16 06:07:35 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:07:43 AM: Update 2111: task edges-ner-ontonotes, batch 111 (2111): mcc: 0.8883, acc: 0.8341, precision: 0.9417, recall: 0.8490, f1: 0.8930, edges-ner-ontonotes_loss: 0.0355
09/16 06:07:45 AM: Update 2072: task edges-ner-ontonotes, batch 72 (2072): mcc: 0.8893, acc: 0.8358, precision: 0.9413, recall: 0.8511, f1: 0.8939, edges-ner-ontonotes_loss: 0.0351
09/16 06:07:54 AM: Update 2183: task edges-ner-ontonotes, batch 183 (2183): mcc: 0.8877, acc: 0.8354, precision: 0.9402, recall: 0.8493, f1: 0.8924, edges-ner-ontonotes_loss: 0.0355
09/16 06:07:55 AM: Update 2147: task edges-ner-ontonotes, batch 147 (2147): mcc: 0.8887, acc: 0.8365, precision: 0.9405, recall: 0.8509, f1: 0.8934, edges-ner-ontonotes_loss: 0.0354
09/16 06:08:04 AM: Update 2277: task edges-ner-ontonotes, batch 277 (2277): mcc: 0.8929, acc: 0.8424, precision: 0.9422, recall: 0.8569, f1: 0.8975, edges-ner-ontonotes_loss: 0.0341
09/16 06:08:05 AM: Update 2196: task edges-ner-ontonotes, batch 196 (2196): mcc: 0.8876, acc: 0.8350, precision: 0.9399, recall: 0.8493, f1: 0.8923, edges-ner-ontonotes_loss: 0.0355
09/16 06:08:14 AM: Update 2353: task edges-ner-ontonotes, batch 353 (2353): mcc: 0.8957, acc: 0.8461, precision: 0.9434, recall: 0.8608, f1: 0.9002, edges-ner-ontonotes_loss: 0.0330
09/16 06:08:15 AM: Update 2267: task edges-ner-ontonotes, batch 267 (2267): mcc: 0.8922, acc: 0.8414, precision: 0.9417, recall: 0.8561, f1: 0.8969, edges-ner-ontonotes_loss: 0.0343
09/16 06:08:24 AM: Update 2424: task edges-ner-ontonotes, batch 424 (2424): mcc: 0.8974, acc: 0.8486, precision: 0.9440, recall: 0.8634, f1: 0.9019, edges-ner-ontonotes_loss: 0.0325
09/16 06:08:25 AM: Update 2337: task edges-ner-ontonotes, batch 337 (2337): mcc: 0.8950, acc: 0.8451, precision: 0.9431, recall: 0.8599, f1: 0.8996, edges-ner-ontonotes_loss: 0.0333
09/16 06:08:35 AM: Update 2494: task edges-ner-ontonotes, batch 494 (2494): mcc: 0.8987, acc: 0.8503, precision: 0.9444, recall: 0.8654, f1: 0.9032, edges-ner-ontonotes_loss: 0.0320
09/16 06:08:35 AM: Update 2412: task edges-ner-ontonotes, batch 412 (2412): mcc: 0.8966, acc: 0.8475, precision: 0.9436, recall: 0.8622, f1: 0.9011, edges-ner-ontonotes_loss: 0.0327
09/16 06:08:45 AM: Update 2543: task edges-ner-ontonotes, batch 543 (2543): mcc: 0.8985, acc: 0.8497, precision: 0.9447, recall: 0.8648, f1: 0.9030, edges-ner-ontonotes_loss: 0.0320
09/16 06:08:45 AM: Update 2487: task edges-ner-ontonotes, batch 487 (2487): mcc: 0.8986, acc: 0.8503, precision: 0.9445, recall: 0.8652, f1: 0.9031, edges-ner-ontonotes_loss: 0.0321
09/16 06:08:55 AM: Update 2625: task edges-ner-ontonotes, batch 625 (2625): mcc: 0.8998, acc: 0.8508, precision: 0.9451, recall: 0.8667, f1: 0.9042, edges-ner-ontonotes_loss: 0.0317
09/16 06:08:56 AM: Update 2535: task edges-ner-ontonotes, batch 535 (2535): mcc: 0.8984, acc: 0.8496, precision: 0.9446, recall: 0.8646, f1: 0.9029, edges-ner-ontonotes_loss: 0.0321
09/16 06:09:05 AM: Update 2703: task edges-ner-ontonotes, batch 703 (2703): mcc: 0.9000, acc: 0.8512, precision: 0.9447, recall: 0.8674, f1: 0.9044, edges-ner-ontonotes_loss: 0.0316
09/16 06:09:06 AM: Update 2607: task edges-ner-ontonotes, batch 607 (2607): mcc: 0.8992, acc: 0.8501, precision: 0.9448, recall: 0.8660, f1: 0.9037, edges-ner-ontonotes_loss: 0.0318
09/16 06:09:15 AM: Update 2776: task edges-ner-ontonotes, batch 776 (2776): mcc: 0.9011, acc: 0.8525, precision: 0.9453, recall: 0.8689, f1: 0.9055, edges-ner-ontonotes_loss: 0.0312
09/16 06:09:16 AM: Update 2678: task edges-ner-ontonotes, batch 678 (2678): mcc: 0.8998, acc: 0.8510, precision: 0.9447, recall: 0.8672, f1: 0.9043, edges-ner-ontonotes_loss: 0.0317
09/16 06:09:25 AM: Update 2825: task edges-ner-ontonotes, batch 825 (2825): mcc: 0.9006, acc: 0.8519, precision: 0.9447, recall: 0.8686, f1: 0.9051, edges-ner-ontonotes_loss: 0.0313
09/16 06:09:26 AM: Update 2759: task edges-ner-ontonotes, batch 759 (2759): mcc: 0.9008, acc: 0.8522, precision: 0.9452, recall: 0.8685, f1: 0.9052, edges-ner-ontonotes_loss: 0.0313
09/16 06:09:35 AM: Update 2902: task edges-ner-ontonotes, batch 902 (2902): mcc: 0.8981, acc: 0.8483, precision: 0.9434, recall: 0.8652, f1: 0.9026, edges-ner-ontonotes_loss: 0.0323
09/16 06:09:36 AM: Update 2810: task edges-ner-ontonotes, batch 810 (2810): mcc: 0.9012, acc: 0.8527, precision: 0.9452, recall: 0.8693, f1: 0.9057, edges-ner-ontonotes_loss: 0.0310
09/16 06:09:45 AM: Update 2973: task edges-ner-ontonotes, batch 973 (2973): mcc: 0.8963, acc: 0.8458, precision: 0.9422, recall: 0.8629, f1: 0.9009, edges-ner-ontonotes_loss: 0.0331
09/16 06:09:46 AM: Update 2880: task edges-ner-ontonotes, batch 880 (2880): mcc: 0.8989, acc: 0.8495, precision: 0.9438, recall: 0.8662, f1: 0.9034, edges-ner-ontonotes_loss: 0.0321
09/16 06:09:48 AM: ***** Step 3000 / Validation 3 *****
09/16 06:09:49 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:09:49 AM: Validating...
09/16 06:09:55 AM: Evaluate: task edges-ner-ontonotes, batch 40 (157): mcc: 0.8611, acc: 0.8119, precision: 0.9113, recall: 0.8274, f1: 0.8673, edges-ner-ontonotes_loss: 0.0418
09/16 06:09:59 AM: Update 2943: task edges-ner-ontonotes, batch 943 (2943): mcc: 0.8969, acc: 0.8466, precision: 0.9428, recall: 0.8636, f1: 0.9015, edges-ner-ontonotes_loss: 0.0329
09/16 06:10:06 AM: Evaluate: task edges-ner-ontonotes, batch 97 (157): mcc: 0.8969, acc: 0.8524, precision: 0.9373, recall: 0.8688, f1: 0.9017, edges-ner-ontonotes_loss: 0.0335
09/16 06:10:10 AM: Update 2999: task edges-ner-ontonotes, batch 999 (2999): mcc: 0.8955, acc: 0.8449, precision: 0.9418, recall: 0.8620, f1: 0.9002, edges-ner-ontonotes_loss: 0.0335
09/16 06:10:11 AM: ***** Step 3000 / Validation 3 *****
09/16 06:10:12 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:10:12 AM: Validating...
09/16 06:10:16 AM: Evaluate: task edges-ner-ontonotes, batch 148 (157): mcc: 0.9068, acc: 0.8633, precision: 0.9464, recall: 0.8785, f1: 0.9112, edges-ner-ontonotes_loss: 0.0303
09/16 06:10:21 AM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.8714, acc: 0.8224, precision: 0.9174, recall: 0.8406, f1: 0.8773, edges-ner-ontonotes_loss: 0.0392
09/16 06:10:21 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:10:21 AM: Best result seen so far for macro.
09/16 06:10:21 AM: Updating LR scheduler:
09/16 06:10:21 AM: 	Best result seen so far for macro_avg: 0.912
09/16 06:10:21 AM: 	# validation passes without improvement: 0
09/16 06:10:21 AM: edges-ner-ontonotes_loss: training: 0.033504 validation: 0.029887
09/16 06:10:21 AM: macro_avg: validation: 0.912100
09/16 06:10:21 AM: micro_avg: validation: 0.000000
09/16 06:10:21 AM: edges-ner-ontonotes_mcc: training: 0.895550 validation: 0.907820
09/16 06:10:21 AM: edges-ner-ontonotes_acc: training: 0.844914 validation: 0.864346
09/16 06:10:21 AM: edges-ner-ontonotes_precision: training: 0.941823 validation: 0.947020
09/16 06:10:21 AM: edges-ner-ontonotes_recall: training: 0.862048 validation: 0.879663
09/16 06:10:21 AM: edges-ner-ontonotes_f1: training: 0.900171 validation: 0.912100
09/16 06:10:21 AM: Global learning rate: 0.0001
09/16 06:10:21 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:10:29 AM: Update 3047: task edges-ner-ontonotes, batch 47 (3047): mcc: 0.8695, acc: 0.8126, precision: 0.9256, recall: 0.8296, f1: 0.8750, edges-ner-ontonotes_loss: 0.0437
09/16 06:10:31 AM: Evaluate: task edges-ner-ontonotes, batch 112 (157): mcc: 0.8985, acc: 0.8537, precision: 0.9389, recall: 0.8703, f1: 0.9033, edges-ner-ontonotes_loss: 0.0325
09/16 06:10:39 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:10:40 AM: Update 3109: task edges-ner-ontonotes, batch 109 (3109): mcc: 0.8668, acc: 0.8088, precision: 0.9244, recall: 0.8259, f1: 0.8724, edges-ner-ontonotes_loss: 0.0451
09/16 06:10:41 AM: Best result seen so far for macro.
09/16 06:10:41 AM: Updating LR scheduler:
09/16 06:10:41 AM: 	Best result seen so far for macro_avg: 0.912
09/16 06:10:41 AM: 	# validation passes without improvement: 0
09/16 06:10:41 AM: edges-ner-ontonotes_loss: training: 0.033504 validation: 0.029887
09/16 06:10:41 AM: macro_avg: validation: 0.912100
09/16 06:10:41 AM: micro_avg: validation: 0.000000
09/16 06:10:41 AM: edges-ner-ontonotes_mcc: training: 0.895550 validation: 0.907820
09/16 06:10:41 AM: edges-ner-ontonotes_acc: training: 0.844914 validation: 0.864346
09/16 06:10:41 AM: edges-ner-ontonotes_precision: training: 0.941823 validation: 0.947020
09/16 06:10:41 AM: edges-ner-ontonotes_recall: training: 0.862048 validation: 0.879663
09/16 06:10:41 AM: edges-ner-ontonotes_f1: training: 0.900171 validation: 0.912100
09/16 06:10:41 AM: Global learning rate: 0.0001
09/16 06:10:41 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:10:41 AM: Update 3001: task edges-ner-ontonotes, batch 1 (3001): mcc: 0.8526, acc: 0.7761, precision: 0.9016, recall: 0.8209, f1: 0.8594, edges-ner-ontonotes_loss: 0.0354
09/16 06:10:51 AM: Update 3164: task edges-ner-ontonotes, batch 164 (3164): mcc: 0.8674, acc: 0.8100, precision: 0.9237, recall: 0.8275, f1: 0.8729, edges-ner-ontonotes_loss: 0.0439
09/16 06:10:51 AM: Update 3091: task edges-ner-ontonotes, batch 91 (3091): mcc: 0.8681, acc: 0.8098, precision: 0.9258, recall: 0.8269, f1: 0.8736, edges-ner-ontonotes_loss: 0.0442
09/16 06:11:01 AM: Update 3260: task edges-ner-ontonotes, batch 260 (3260): mcc: 0.8705, acc: 0.8127, precision: 0.9262, recall: 0.8309, f1: 0.8760, edges-ner-ontonotes_loss: 0.0418
09/16 06:11:01 AM: Update 3152: task edges-ner-ontonotes, batch 152 (3152): mcc: 0.8666, acc: 0.8090, precision: 0.9238, recall: 0.8259, f1: 0.8721, edges-ner-ontonotes_loss: 0.0443
09/16 06:11:11 AM: Update 3345: task edges-ner-ontonotes, batch 345 (3345): mcc: 0.8732, acc: 0.8159, precision: 0.9268, recall: 0.8352, f1: 0.8786, edges-ner-ontonotes_loss: 0.0406
09/16 06:11:11 AM: Update 3243: task edges-ner-ontonotes, batch 243 (3243): mcc: 0.8697, acc: 0.8121, precision: 0.9257, recall: 0.8300, f1: 0.8752, edges-ner-ontonotes_loss: 0.0422
09/16 06:11:22 AM: Update 3334: task edges-ner-ontonotes, batch 334 (3334): mcc: 0.8729, acc: 0.8155, precision: 0.9269, recall: 0.8346, f1: 0.8783, edges-ner-ontonotes_loss: 0.0408
09/16 06:11:23 AM: Update 3426: task edges-ner-ontonotes, batch 426 (3426): mcc: 0.8742, acc: 0.8176, precision: 0.9271, recall: 0.8369, f1: 0.8797, edges-ner-ontonotes_loss: 0.0400
09/16 06:11:32 AM: Update 3421: task edges-ner-ontonotes, batch 421 (3421): mcc: 0.8744, acc: 0.8179, precision: 0.9271, recall: 0.8371, f1: 0.8798, edges-ner-ontonotes_loss: 0.0400
09/16 06:11:33 AM: Update 3510: task edges-ner-ontonotes, batch 510 (3510): mcc: 0.8784, acc: 0.8240, precision: 0.9294, recall: 0.8424, f1: 0.8837, edges-ner-ontonotes_loss: 0.0388
09/16 06:11:42 AM: Update 3474: task edges-ner-ontonotes, batch 474 (3474): mcc: 0.8766, acc: 0.8213, precision: 0.9284, recall: 0.8401, f1: 0.8820, edges-ner-ontonotes_loss: 0.0393
09/16 06:11:43 AM: Update 3589: task edges-ner-ontonotes, batch 589 (3589): mcc: 0.8826, acc: 0.8299, precision: 0.9313, recall: 0.8481, f1: 0.8878, edges-ner-ontonotes_loss: 0.0377
09/16 06:11:52 AM: Update 3547: task edges-ner-ontonotes, batch 547 (3547): mcc: 0.8804, acc: 0.8270, precision: 0.9301, recall: 0.8453, f1: 0.8857, edges-ner-ontonotes_loss: 0.0383
09/16 06:11:53 AM: Update 3663: task edges-ner-ontonotes, batch 663 (3663): mcc: 0.8854, acc: 0.8339, precision: 0.9328, recall: 0.8519, f1: 0.8905, edges-ner-ontonotes_loss: 0.0368
09/16 06:12:02 AM: Update 3620: task edges-ner-ontonotes, batch 620 (3620): mcc: 0.8841, acc: 0.8321, precision: 0.9321, recall: 0.8501, f1: 0.8892, edges-ner-ontonotes_loss: 0.0372
09/16 06:12:04 AM: Update 3736: task edges-ner-ontonotes, batch 736 (3736): mcc: 0.8881, acc: 0.8372, precision: 0.9345, recall: 0.8552, f1: 0.8931, edges-ner-ontonotes_loss: 0.0361
09/16 06:12:12 AM: Update 3702: task edges-ner-ontonotes, batch 702 (3702): mcc: 0.8870, acc: 0.8359, precision: 0.9338, recall: 0.8539, f1: 0.8921, edges-ner-ontonotes_loss: 0.0364
09/16 06:12:14 AM: Update 3785: task edges-ner-ontonotes, batch 785 (3785): mcc: 0.8901, acc: 0.8400, precision: 0.9357, recall: 0.8579, f1: 0.8951, edges-ner-ontonotes_loss: 0.0355
09/16 06:12:22 AM: Update 3748: task edges-ner-ontonotes, batch 748 (3748): mcc: 0.8883, acc: 0.8376, precision: 0.9348, recall: 0.8555, f1: 0.8934, edges-ner-ontonotes_loss: 0.0360
09/16 06:12:24 AM: Update 3865: task edges-ner-ontonotes, batch 865 (3865): mcc: 0.8933, acc: 0.8443, precision: 0.9372, recall: 0.8622, f1: 0.8982, edges-ner-ontonotes_loss: 0.0347
09/16 06:12:32 AM: Update 3819: task edges-ner-ontonotes, batch 819 (3819): mcc: 0.8917, acc: 0.8420, precision: 0.9365, recall: 0.8599, f1: 0.8966, edges-ner-ontonotes_loss: 0.0352
09/16 06:12:34 AM: Update 3937: task edges-ner-ontonotes, batch 937 (3937): mcc: 0.8960, acc: 0.8478, precision: 0.9388, recall: 0.8656, f1: 0.9007, edges-ner-ontonotes_loss: 0.0339
09/16 06:12:42 AM: ***** Step 4000 / Validation 4 *****
09/16 06:12:42 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:12:42 AM: Validating...
09/16 06:12:42 AM: Update 3894: task edges-ner-ontonotes, batch 894 (3894): mcc: 0.8945, acc: 0.8459, precision: 0.9380, recall: 0.8636, f1: 0.8993, edges-ner-ontonotes_loss: 0.0344
09/16 06:12:44 AM: Evaluate: task edges-ner-ontonotes, batch 10 (157): mcc: 0.8251, acc: 0.7655, precision: 0.8806, recall: 0.7904, f1: 0.8331, edges-ner-ontonotes_loss: 0.0475
09/16 06:12:53 AM: Update 3951: task edges-ner-ontonotes, batch 951 (3951): mcc: 0.8963, acc: 0.8482, precision: 0.9389, recall: 0.8661, f1: 0.9010, edges-ner-ontonotes_loss: 0.0337
09/16 06:12:54 AM: Evaluate: task edges-ner-ontonotes, batch 70 (157): mcc: 0.8945, acc: 0.8551, precision: 0.9263, recall: 0.8749, f1: 0.8998, edges-ner-ontonotes_loss: 0.0339
09/16 06:13:01 AM: ***** Step 4000 / Validation 4 *****
09/16 06:13:01 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:13:01 AM: Validating...
09/16 06:13:03 AM: Evaluate: task edges-ner-ontonotes, batch 6 (157): mcc: 0.7864, acc: 0.7200, precision: 0.8647, recall: 0.7350, f1: 0.7946, edges-ner-ontonotes_loss: 0.0569
09/16 06:13:04 AM: Evaluate: task edges-ner-ontonotes, batch 119 (157): mcc: 0.9118, acc: 0.8743, precision: 0.9410, recall: 0.8928, f1: 0.9162, edges-ner-ontonotes_loss: 0.0288
09/16 06:13:12 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:13:12 AM: Best result seen so far for macro.
09/16 06:13:12 AM: Updating LR scheduler:
09/16 06:13:12 AM: 	Best result seen so far for macro_avg: 0.923
09/16 06:13:12 AM: 	# validation passes without improvement: 0
09/16 06:13:12 AM: edges-ner-ontonotes_loss: training: 0.033209 validation: 0.026436
09/16 06:13:12 AM: macro_avg: validation: 0.922945
09/16 06:13:12 AM: micro_avg: validation: 0.000000
09/16 06:13:12 AM: edges-ner-ontonotes_mcc: training: 0.897978 validation: 0.918835
09/16 06:13:12 AM: edges-ner-ontonotes_acc: training: 0.850291 validation: 0.883151
09/16 06:13:12 AM: edges-ner-ontonotes_precision: training: 0.939952 validation: 0.946019
09/16 06:13:12 AM: edges-ner-ontonotes_recall: training: 0.868242 validation: 0.900971
09/16 06:13:12 AM: edges-ner-ontonotes_f1: training: 0.902675 validation: 0.922945
09/16 06:13:12 AM: Global learning rate: 0.0001
09/16 06:13:12 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:13:13 AM: Evaluate: task edges-ner-ontonotes, batch 58 (157): mcc: 0.8925, acc: 0.8547, precision: 0.9230, recall: 0.8744, f1: 0.8980, edges-ner-ontonotes_loss: 0.0343
09/16 06:13:14 AM: Update 4011: task edges-ner-ontonotes, batch 11 (4011): mcc: 0.9105, acc: 0.8587, precision: 0.9517, recall: 0.8802, f1: 0.9146, edges-ner-ontonotes_loss: 0.0254
09/16 06:13:23 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9099, acc: 0.8720, precision: 0.9397, recall: 0.8904, f1: 0.9144, edges-ner-ontonotes_loss: 0.0293
09/16 06:13:24 AM: Update 4052: task edges-ner-ontonotes, batch 52 (4052): mcc: 0.9222, acc: 0.8813, precision: 0.9513, recall: 0.9021, f1: 0.9260, edges-ner-ontonotes_loss: 0.0236
09/16 06:13:31 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:13:31 AM: Best result seen so far for macro.
09/16 06:13:31 AM: Updating LR scheduler:
09/16 06:13:31 AM: 	Best result seen so far for macro_avg: 0.923
09/16 06:13:31 AM: 	# validation passes without improvement: 0
09/16 06:13:31 AM: edges-ner-ontonotes_loss: training: 0.033209 validation: 0.026436
09/16 06:13:31 AM: macro_avg: validation: 0.922945
09/16 06:13:31 AM: micro_avg: validation: 0.000000
09/16 06:13:31 AM: edges-ner-ontonotes_mcc: training: 0.897978 validation: 0.918835
09/16 06:13:31 AM: edges-ner-ontonotes_acc: training: 0.850291 validation: 0.883151
09/16 06:13:31 AM: edges-ner-ontonotes_precision: training: 0.939952 validation: 0.946019
09/16 06:13:31 AM: edges-ner-ontonotes_recall: training: 0.868242 validation: 0.900971
09/16 06:13:31 AM: edges-ner-ontonotes_f1: training: 0.902675 validation: 0.922945
09/16 06:13:31 AM: Global learning rate: 0.0001
09/16 06:13:31 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:13:33 AM: Update 4017: task edges-ner-ontonotes, batch 17 (4017): mcc: 0.9143, acc: 0.8672, precision: 0.9514, recall: 0.8874, f1: 0.9183, edges-ner-ontonotes_loss: 0.0249
09/16 06:13:34 AM: Update 4111: task edges-ner-ontonotes, batch 111 (4111): mcc: 0.9214, acc: 0.8809, precision: 0.9511, recall: 0.9009, f1: 0.9253, edges-ner-ontonotes_loss: 0.0240
09/16 06:13:43 AM: Update 4069: task edges-ner-ontonotes, batch 69 (4069): mcc: 0.9208, acc: 0.8794, precision: 0.9514, recall: 0.8995, f1: 0.9247, edges-ner-ontonotes_loss: 0.0238
09/16 06:13:44 AM: Update 4188: task edges-ner-ontonotes, batch 188 (4188): mcc: 0.9224, acc: 0.8830, precision: 0.9522, recall: 0.9017, f1: 0.9263, edges-ner-ontonotes_loss: 0.0244
09/16 06:13:54 AM: Update 4139: task edges-ner-ontonotes, batch 139 (4139): mcc: 0.9223, acc: 0.8819, precision: 0.9522, recall: 0.9014, f1: 0.9261, edges-ner-ontonotes_loss: 0.0244
09/16 06:13:54 AM: Update 4258: task edges-ner-ontonotes, batch 258 (4258): mcc: 0.9230, acc: 0.8834, precision: 0.9527, recall: 0.9022, f1: 0.9268, edges-ner-ontonotes_loss: 0.0245
09/16 06:14:04 AM: Update 4210: task edges-ner-ontonotes, batch 210 (4210): mcc: 0.9223, acc: 0.8827, precision: 0.9522, recall: 0.9016, f1: 0.9262, edges-ner-ontonotes_loss: 0.0246
09/16 06:14:04 AM: Update 4336: task edges-ner-ontonotes, batch 336 (4336): mcc: 0.9220, acc: 0.8822, precision: 0.9515, recall: 0.9017, f1: 0.9259, edges-ner-ontonotes_loss: 0.0247
09/16 06:14:15 AM: Update 4285: task edges-ner-ontonotes, batch 285 (4285): mcc: 0.9227, acc: 0.8829, precision: 0.9522, recall: 0.9022, f1: 0.9265, edges-ner-ontonotes_loss: 0.0246
09/16 06:14:15 AM: Update 4393: task edges-ner-ontonotes, batch 393 (4393): mcc: 0.9185, acc: 0.8775, precision: 0.9491, recall: 0.8974, f1: 0.9226, edges-ner-ontonotes_loss: 0.0259
09/16 06:14:25 AM: Update 4357: task edges-ner-ontonotes, batch 357 (4357): mcc: 0.9217, acc: 0.8818, precision: 0.9508, recall: 0.9017, f1: 0.9256, edges-ner-ontonotes_loss: 0.0247
09/16 06:14:25 AM: Update 4468: task edges-ner-ontonotes, batch 468 (4468): mcc: 0.9146, acc: 0.8723, precision: 0.9471, recall: 0.8920, f1: 0.9187, edges-ner-ontonotes_loss: 0.0276
09/16 06:14:35 AM: Update 4420: task edges-ner-ontonotes, batch 420 (4420): mcc: 0.9176, acc: 0.8763, precision: 0.9487, recall: 0.8961, f1: 0.9216, edges-ner-ontonotes_loss: 0.0264
09/16 06:14:35 AM: Update 4546: task edges-ner-ontonotes, batch 546 (4546): mcc: 0.9102, acc: 0.8663, precision: 0.9447, recall: 0.8862, f1: 0.9145, edges-ner-ontonotes_loss: 0.0299
09/16 06:14:45 AM: Update 4492: task edges-ner-ontonotes, batch 492 (4492): mcc: 0.9129, acc: 0.8700, precision: 0.9465, recall: 0.8895, f1: 0.9171, edges-ner-ontonotes_loss: 0.0283
09/16 06:14:45 AM: Update 4617: task edges-ner-ontonotes, batch 617 (4617): mcc: 0.9073, acc: 0.8627, precision: 0.9431, recall: 0.8824, f1: 0.9118, edges-ner-ontonotes_loss: 0.0310
09/16 06:14:55 AM: Update 4575: task edges-ner-ontonotes, batch 575 (4575): mcc: 0.9085, acc: 0.8644, precision: 0.9434, recall: 0.8843, f1: 0.9129, edges-ner-ontonotes_loss: 0.0305
09/16 06:14:55 AM: Update 4679: task edges-ner-ontonotes, batch 679 (4679): mcc: 0.9046, acc: 0.8595, precision: 0.9412, recall: 0.8792, f1: 0.9091, edges-ner-ontonotes_loss: 0.0321
09/16 06:15:05 AM: Update 4653: task edges-ner-ontonotes, batch 653 (4653): mcc: 0.9055, acc: 0.8606, precision: 0.9420, recall: 0.8802, f1: 0.9100, edges-ner-ontonotes_loss: 0.0317
09/16 06:15:05 AM: Update 4763: task edges-ner-ontonotes, batch 763 (4763): mcc: 0.9034, acc: 0.8577, precision: 0.9404, recall: 0.8778, f1: 0.9080, edges-ner-ontonotes_loss: 0.0325
09/16 06:15:15 AM: Update 4720: task edges-ner-ontonotes, batch 720 (4720): mcc: 0.9038, acc: 0.8586, precision: 0.9407, recall: 0.8784, f1: 0.9084, edges-ner-ontonotes_loss: 0.0323
09/16 06:15:16 AM: Update 4855: task edges-ner-ontonotes, batch 855 (4855): mcc: 0.9018, acc: 0.8557, precision: 0.9393, recall: 0.8758, f1: 0.9064, edges-ner-ontonotes_loss: 0.0329
09/16 06:15:25 AM: Update 4806: task edges-ner-ontonotes, batch 806 (4806): mcc: 0.9028, acc: 0.8568, precision: 0.9400, recall: 0.8770, f1: 0.9074, edges-ner-ontonotes_loss: 0.0327
09/16 06:15:26 AM: Update 4942: task edges-ner-ontonotes, batch 942 (4942): mcc: 0.9013, acc: 0.8553, precision: 0.9389, recall: 0.8754, f1: 0.9060, edges-ner-ontonotes_loss: 0.0329
09/16 06:15:35 AM: Update 4902: task edges-ner-ontonotes, batch 902 (4902): mcc: 0.9016, acc: 0.8555, precision: 0.9391, recall: 0.8757, f1: 0.9063, edges-ner-ontonotes_loss: 0.0329
09/16 06:15:36 AM: Update 4995: task edges-ner-ontonotes, batch 995 (4995): mcc: 0.9009, acc: 0.8547, precision: 0.9385, recall: 0.8749, f1: 0.9056, edges-ner-ontonotes_loss: 0.0330
09/16 06:15:36 AM: ***** Step 5000 / Validation 5 *****
09/16 06:15:36 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:15:36 AM: Validating...
09/16 06:15:45 AM: Update 4968: task edges-ner-ontonotes, batch 968 (4968): mcc: 0.9010, acc: 0.8549, precision: 0.9387, recall: 0.8750, f1: 0.9057, edges-ner-ontonotes_loss: 0.0330
09/16 06:15:46 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.9092, acc: 0.8746, precision: 0.9368, recall: 0.8919, f1: 0.9138, edges-ner-ontonotes_loss: 0.0297
09/16 06:15:55 AM: ***** Step 5000 / Validation 5 *****
09/16 06:15:55 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:15:55 AM: Validating...
09/16 06:15:55 AM: Evaluate: task edges-ner-ontonotes, batch 3 (157): mcc: 0.7566, acc: 0.6667, precision: 0.8545, recall: 0.6912, f1: 0.7642, edges-ner-ontonotes_loss: 0.0626
09/16 06:15:56 AM: Evaluate: task edges-ner-ontonotes, batch 118 (157): mcc: 0.9186, acc: 0.8821, precision: 0.9482, recall: 0.8984, f1: 0.9226, edges-ner-ontonotes_loss: 0.0268
09/16 06:16:04 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:16:04 AM: Best result seen so far for macro.
09/16 06:16:04 AM: Updating LR scheduler:
09/16 06:16:04 AM: 	Best result seen so far for macro_avg: 0.928
09/16 06:16:04 AM: 	# validation passes without improvement: 0
09/16 06:16:04 AM: edges-ner-ontonotes_loss: training: 0.032961 validation: 0.024929
09/16 06:16:04 AM: macro_avg: validation: 0.928469
09/16 06:16:04 AM: micro_avg: validation: 0.000000
09/16 06:16:04 AM: edges-ner-ontonotes_mcc: training: 0.900928 validation: 0.924724
09/16 06:16:04 AM: edges-ner-ontonotes_acc: training: 0.854869 validation: 0.890052
09/16 06:16:04 AM: edges-ner-ontonotes_precision: training: 0.938546 validation: 0.953199
09/16 06:16:04 AM: edges-ner-ontonotes_recall: training: 0.874989 validation: 0.904989
09/16 06:16:04 AM: edges-ner-ontonotes_f1: training: 0.905654 validation: 0.928469
09/16 06:16:04 AM: Global learning rate: 0.0001
09/16 06:16:04 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:16:06 AM: Evaluate: task edges-ner-ontonotes, batch 57 (157): mcc: 0.9075, acc: 0.8727, precision: 0.9362, recall: 0.8894, f1: 0.9122, edges-ner-ontonotes_loss: 0.0303
09/16 06:16:06 AM: Update 5011: task edges-ner-ontonotes, batch 11 (5011): mcc: 0.8965, acc: 0.8537, precision: 0.9270, recall: 0.8778, f1: 0.9017, edges-ner-ontonotes_loss: 0.0327
09/16 06:16:16 AM: Evaluate: task edges-ner-ontonotes, batch 112 (157): mcc: 0.9180, acc: 0.8823, precision: 0.9470, recall: 0.8984, f1: 0.9221, edges-ner-ontonotes_loss: 0.0270
09/16 06:16:16 AM: Update 5066: task edges-ner-ontonotes, batch 66 (5066): mcc: 0.9072, acc: 0.8651, precision: 0.9384, recall: 0.8867, f1: 0.9118, edges-ner-ontonotes_loss: 0.0295
09/16 06:16:25 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:16:25 AM: Best result seen so far for macro.
09/16 06:16:25 AM: Updating LR scheduler:
09/16 06:16:25 AM: 	Best result seen so far for macro_avg: 0.928
09/16 06:16:25 AM: 	# validation passes without improvement: 0
09/16 06:16:25 AM: edges-ner-ontonotes_loss: training: 0.032961 validation: 0.024929
09/16 06:16:25 AM: macro_avg: validation: 0.928469
09/16 06:16:25 AM: micro_avg: validation: 0.000000
09/16 06:16:25 AM: edges-ner-ontonotes_mcc: training: 0.900928 validation: 0.924724
09/16 06:16:25 AM: edges-ner-ontonotes_acc: training: 0.854869 validation: 0.890052
09/16 06:16:25 AM: edges-ner-ontonotes_precision: training: 0.938546 validation: 0.953199
09/16 06:16:25 AM: edges-ner-ontonotes_recall: training: 0.874989 validation: 0.904989
09/16 06:16:25 AM: edges-ner-ontonotes_f1: training: 0.905654 validation: 0.928469
09/16 06:16:25 AM: Global learning rate: 0.0001
09/16 06:16:25 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:16:26 AM: Update 5008: task edges-ner-ontonotes, batch 8 (5008): mcc: 0.8982, acc: 0.8491, precision: 0.9333, recall: 0.8750, f1: 0.9032, edges-ner-ontonotes_loss: 0.0314
09/16 06:16:26 AM: Update 5123: task edges-ner-ontonotes, batch 123 (5123): mcc: 0.9086, acc: 0.8670, precision: 0.9397, recall: 0.8881, f1: 0.9132, edges-ner-ontonotes_loss: 0.0297
09/16 06:16:36 AM: Update 5078: task edges-ner-ontonotes, batch 78 (5078): mcc: 0.9071, acc: 0.8639, precision: 0.9394, recall: 0.8855, f1: 0.9116, edges-ner-ontonotes_loss: 0.0295
09/16 06:16:36 AM: Update 5195: task edges-ner-ontonotes, batch 195 (5195): mcc: 0.9088, acc: 0.8669, precision: 0.9413, recall: 0.8870, f1: 0.9133, edges-ner-ontonotes_loss: 0.0290
09/16 06:16:46 AM: Update 5152: task edges-ner-ontonotes, batch 152 (5152): mcc: 0.9082, acc: 0.8668, precision: 0.9398, recall: 0.8873, f1: 0.9128, edges-ner-ontonotes_loss: 0.0295
09/16 06:16:47 AM: Update 5271: task edges-ner-ontonotes, batch 271 (5271): mcc: 0.9119, acc: 0.8711, precision: 0.9440, recall: 0.8901, f1: 0.9162, edges-ner-ontonotes_loss: 0.0282
09/16 06:16:56 AM: Update 5230: task edges-ner-ontonotes, batch 230 (5230): mcc: 0.9097, acc: 0.8679, precision: 0.9423, recall: 0.8876, f1: 0.9142, edges-ner-ontonotes_loss: 0.0287
09/16 06:16:57 AM: Update 5331: task edges-ner-ontonotes, batch 331 (5331): mcc: 0.9147, acc: 0.8741, precision: 0.9457, recall: 0.8936, f1: 0.9189, edges-ner-ontonotes_loss: 0.0272
09/16 06:17:07 AM: Update 5295: task edges-ner-ontonotes, batch 295 (5295): mcc: 0.9128, acc: 0.8723, precision: 0.9445, recall: 0.8913, f1: 0.9171, edges-ner-ontonotes_loss: 0.0278
09/16 06:17:07 AM: Update 5412: task edges-ner-ontonotes, batch 412 (5412): mcc: 0.9170, acc: 0.8773, precision: 0.9469, recall: 0.8967, f1: 0.9211, edges-ner-ontonotes_loss: 0.0264
09/16 06:17:17 AM: Update 5364: task edges-ner-ontonotes, batch 364 (5364): mcc: 0.9155, acc: 0.8753, precision: 0.9464, recall: 0.8945, f1: 0.9197, edges-ner-ontonotes_loss: 0.0269
09/16 06:17:17 AM: Update 5480: task edges-ner-ontonotes, batch 480 (5480): mcc: 0.9186, acc: 0.8796, precision: 0.9477, recall: 0.8989, f1: 0.9227, edges-ner-ontonotes_loss: 0.0261
09/16 06:17:27 AM: Update 5440: task edges-ner-ontonotes, batch 440 (5440): mcc: 0.9175, acc: 0.8780, precision: 0.9471, recall: 0.8975, f1: 0.9216, edges-ner-ontonotes_loss: 0.0263
09/16 06:17:27 AM: Update 5554: task edges-ner-ontonotes, batch 554 (5554): mcc: 0.9199, acc: 0.8813, precision: 0.9483, recall: 0.9008, f1: 0.9239, edges-ner-ontonotes_loss: 0.0256
09/16 06:17:37 AM: Update 5515: task edges-ner-ontonotes, batch 515 (5515): mcc: 0.9193, acc: 0.8807, precision: 0.9479, recall: 0.9001, f1: 0.9233, edges-ner-ontonotes_loss: 0.0258
09/16 06:17:39 AM: Update 5608: task edges-ner-ontonotes, batch 608 (5608): mcc: 0.9210, acc: 0.8826, precision: 0.9492, recall: 0.9020, f1: 0.9250, edges-ner-ontonotes_loss: 0.0253
09/16 06:17:47 AM: Update 5594: task edges-ner-ontonotes, batch 594 (5594): mcc: 0.9208, acc: 0.8823, precision: 0.9490, recall: 0.9018, f1: 0.9248, edges-ner-ontonotes_loss: 0.0254
09/16 06:17:49 AM: Update 5677: task edges-ner-ontonotes, batch 677 (5677): mcc: 0.9214, acc: 0.8830, precision: 0.9493, recall: 0.9026, f1: 0.9254, edges-ner-ontonotes_loss: 0.0252
09/16 06:17:57 AM: Update 5639: task edges-ner-ontonotes, batch 639 (5639): mcc: 0.9209, acc: 0.8824, precision: 0.9490, recall: 0.9020, f1: 0.9249, edges-ner-ontonotes_loss: 0.0253
09/16 06:17:59 AM: Update 5761: task edges-ner-ontonotes, batch 761 (5761): mcc: 0.9219, acc: 0.8835, precision: 0.9494, recall: 0.9034, f1: 0.9258, edges-ner-ontonotes_loss: 0.0249
09/16 06:18:07 AM: Update 5712: task edges-ner-ontonotes, batch 712 (5712): mcc: 0.9213, acc: 0.8827, precision: 0.9490, recall: 0.9026, f1: 0.9252, edges-ner-ontonotes_loss: 0.0252
09/16 06:18:10 AM: Update 5833: task edges-ner-ontonotes, batch 833 (5833): mcc: 0.9223, acc: 0.8840, precision: 0.9496, recall: 0.9040, f1: 0.9262, edges-ner-ontonotes_loss: 0.0248
09/16 06:18:17 AM: Update 5787: task edges-ner-ontonotes, batch 787 (5787): mcc: 0.9220, acc: 0.8837, precision: 0.9495, recall: 0.9036, f1: 0.9260, edges-ner-ontonotes_loss: 0.0249
09/16 06:18:20 AM: Update 5903: task edges-ner-ontonotes, batch 903 (5903): mcc: 0.9226, acc: 0.8844, precision: 0.9495, recall: 0.9045, f1: 0.9265, edges-ner-ontonotes_loss: 0.0248
09/16 06:18:27 AM: Update 5865: task edges-ner-ontonotes, batch 865 (5865): mcc: 0.9224, acc: 0.8841, precision: 0.9495, recall: 0.9042, f1: 0.9263, edges-ner-ontonotes_loss: 0.0249
09/16 06:18:30 AM: Update 5962: task edges-ner-ontonotes, batch 962 (5962): mcc: 0.9207, acc: 0.8818, precision: 0.9487, recall: 0.9020, f1: 0.9247, edges-ner-ontonotes_loss: 0.0255
09/16 06:18:36 AM: ***** Step 6000 / Validation 6 *****
09/16 06:18:36 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:18:36 AM: Validating...
09/16 06:18:37 AM: Update 5921: task edges-ner-ontonotes, batch 921 (5921): mcc: 0.9224, acc: 0.8841, precision: 0.9494, recall: 0.9043, f1: 0.9263, edges-ner-ontonotes_loss: 0.0248
09/16 06:18:40 AM: Evaluate: task edges-ner-ontonotes, batch 30 (157): mcc: 0.8748, acc: 0.8385, precision: 0.9063, recall: 0.8575, f1: 0.8812, edges-ner-ontonotes_loss: 0.0387
09/16 06:18:47 AM: Update 5974: task edges-ner-ontonotes, batch 974 (5974): mcc: 0.9204, acc: 0.8814, precision: 0.9485, recall: 0.9016, f1: 0.9244, edges-ner-ontonotes_loss: 0.0256
09/16 06:18:50 AM: Evaluate: task edges-ner-ontonotes, batch 84 (157): mcc: 0.9103, acc: 0.8750, precision: 0.9370, recall: 0.8939, f1: 0.9149, edges-ner-ontonotes_loss: 0.0300
09/16 06:18:52 AM: ***** Step 6000 / Validation 6 *****
09/16 06:18:52 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:18:52 AM: Validating...
09/16 06:18:57 AM: Evaluate: task edges-ner-ontonotes, batch 27 (157): mcc: 0.8682, acc: 0.8324, precision: 0.9003, recall: 0.8511, f1: 0.8750, edges-ner-ontonotes_loss: 0.0406
09/16 06:19:00 AM: Evaluate: task edges-ner-ontonotes, batch 131 (157): mcc: 0.9210, acc: 0.8872, precision: 0.9464, recall: 0.9047, f1: 0.9251, edges-ner-ontonotes_loss: 0.0261
09/16 06:19:06 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:19:06 AM: Best result seen so far for macro.
09/16 06:19:06 AM: Updating LR scheduler:
09/16 06:19:06 AM: 	Best result seen so far for macro_avg: 0.929
09/16 06:19:06 AM: 	# validation passes without improvement: 0
09/16 06:19:06 AM: edges-ner-ontonotes_loss: training: 0.025991 validation: 0.024722
09/16 06:19:06 AM: macro_avg: validation: 0.929393
09/16 06:19:06 AM: micro_avg: validation: 0.000000
09/16 06:19:06 AM: edges-ner-ontonotes_mcc: training: 0.919385 validation: 0.925575
09/16 06:19:06 AM: edges-ner-ontonotes_acc: training: 0.880008 validation: 0.892781
09/16 06:19:06 AM: edges-ner-ontonotes_precision: training: 0.947824 validation: 0.949885
09/16 06:19:06 AM: edges-ner-ontonotes_recall: training: 0.900253 validation: 0.909766
09/16 06:19:06 AM: edges-ner-ontonotes_f1: training: 0.923427 validation: 0.929393
09/16 06:19:06 AM: Global learning rate: 0.0001
09/16 06:19:06 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:19:09 AM: Evaluate: task edges-ner-ontonotes, batch 78 (157): mcc: 0.9070, acc: 0.8706, precision: 0.9343, recall: 0.8902, f1: 0.9117, edges-ner-ontonotes_loss: 0.0310
09/16 06:19:11 AM: Update 6031: task edges-ner-ontonotes, batch 31 (6031): mcc: 0.8993, acc: 0.8529, precision: 0.9339, recall: 0.8763, f1: 0.9042, edges-ner-ontonotes_loss: 0.0343
09/16 06:19:20 AM: Evaluate: task edges-ner-ontonotes, batch 128 (157): mcc: 0.9204, acc: 0.8865, precision: 0.9462, recall: 0.9038, f1: 0.9245, edges-ner-ontonotes_loss: 0.0264
09/16 06:19:21 AM: Update 6089: task edges-ner-ontonotes, batch 89 (6089): mcc: 0.8892, acc: 0.8406, precision: 0.9281, recall: 0.8634, f1: 0.8946, edges-ner-ontonotes_loss: 0.0382
09/16 06:19:25 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:19:25 AM: Best result seen so far for macro.
09/16 06:19:25 AM: Updating LR scheduler:
09/16 06:19:25 AM: 	Best result seen so far for macro_avg: 0.929
09/16 06:19:25 AM: 	# validation passes without improvement: 0
09/16 06:19:25 AM: edges-ner-ontonotes_loss: training: 0.025991 validation: 0.024722
09/16 06:19:25 AM: macro_avg: validation: 0.929393
09/16 06:19:25 AM: micro_avg: validation: 0.000000
09/16 06:19:25 AM: edges-ner-ontonotes_mcc: training: 0.919385 validation: 0.925575
09/16 06:19:25 AM: edges-ner-ontonotes_acc: training: 0.880008 validation: 0.892781
09/16 06:19:25 AM: edges-ner-ontonotes_precision: training: 0.947824 validation: 0.949885
09/16 06:19:25 AM: edges-ner-ontonotes_recall: training: 0.900253 validation: 0.909766
09/16 06:19:25 AM: edges-ner-ontonotes_f1: training: 0.923427 validation: 0.929393
09/16 06:19:25 AM: Global learning rate: 0.0001
09/16 06:19:25 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:19:30 AM: Update 6030: task edges-ner-ontonotes, batch 30 (6030): mcc: 0.8987, acc: 0.8525, precision: 0.9330, recall: 0.8762, f1: 0.9037, edges-ner-ontonotes_loss: 0.0344
09/16 06:19:31 AM: Update 6158: task edges-ner-ontonotes, batch 158 (6158): mcc: 0.8880, acc: 0.8398, precision: 0.9291, recall: 0.8601, f1: 0.8933, edges-ner-ontonotes_loss: 0.0391
09/16 06:19:40 AM: Update 6114: task edges-ner-ontonotes, batch 114 (6114): mcc: 0.8885, acc: 0.8407, precision: 0.9279, recall: 0.8622, f1: 0.8938, edges-ner-ontonotes_loss: 0.0382
09/16 06:19:44 AM: Update 6225: task edges-ner-ontonotes, batch 225 (6225): mcc: 0.8882, acc: 0.8399, precision: 0.9277, recall: 0.8618, f1: 0.8936, edges-ner-ontonotes_loss: 0.0390
09/16 06:19:50 AM: Update 6203: task edges-ner-ontonotes, batch 203 (6203): mcc: 0.8895, acc: 0.8417, precision: 0.9294, recall: 0.8626, f1: 0.8947, edges-ner-ontonotes_loss: 0.0386
09/16 06:19:54 AM: Update 6312: task edges-ner-ontonotes, batch 312 (6312): mcc: 0.8910, acc: 0.8425, precision: 0.9297, recall: 0.8652, f1: 0.8963, edges-ner-ontonotes_loss: 0.0372
09/16 06:20:00 AM: Update 6268: task edges-ner-ontonotes, batch 268 (6268): mcc: 0.8902, acc: 0.8418, precision: 0.9293, recall: 0.8640, f1: 0.8955, edges-ner-ontonotes_loss: 0.0378
09/16 06:20:04 AM: Update 6403: task edges-ner-ontonotes, batch 403 (6403): mcc: 0.8911, acc: 0.8430, precision: 0.9293, recall: 0.8656, f1: 0.8963, edges-ner-ontonotes_loss: 0.0367
09/16 06:20:10 AM: Update 6358: task edges-ner-ontonotes, batch 358 (6358): mcc: 0.8918, acc: 0.8438, precision: 0.9300, recall: 0.8663, f1: 0.8970, edges-ner-ontonotes_loss: 0.0369
09/16 06:20:14 AM: Update 6494: task edges-ner-ontonotes, batch 494 (6494): mcc: 0.8929, acc: 0.8451, precision: 0.9303, recall: 0.8680, f1: 0.8981, edges-ner-ontonotes_loss: 0.0358
09/16 06:20:20 AM: Update 6452: task edges-ner-ontonotes, batch 452 (6452): mcc: 0.8923, acc: 0.8445, precision: 0.9300, recall: 0.8671, f1: 0.8974, edges-ner-ontonotes_loss: 0.0362
09/16 06:20:24 AM: Update 6555: task edges-ner-ontonotes, batch 555 (6555): mcc: 0.8945, acc: 0.8471, precision: 0.9317, recall: 0.8696, f1: 0.8996, edges-ner-ontonotes_loss: 0.0351
09/16 06:20:34 AM: Update 6538: task edges-ner-ontonotes, batch 538 (6538): mcc: 0.8940, acc: 0.8466, precision: 0.9314, recall: 0.8689, f1: 0.8991, edges-ner-ontonotes_loss: 0.0353
09/16 06:20:34 AM: Update 6642: task edges-ner-ontonotes, batch 642 (6642): mcc: 0.8979, acc: 0.8517, precision: 0.9339, recall: 0.8739, f1: 0.9029, edges-ner-ontonotes_loss: 0.0340
09/16 06:20:44 AM: Update 6612: task edges-ner-ontonotes, batch 612 (6612): mcc: 0.8969, acc: 0.8502, precision: 0.9332, recall: 0.8726, f1: 0.9019, edges-ner-ontonotes_loss: 0.0344
09/16 06:20:44 AM: Update 6718: task edges-ner-ontonotes, batch 718 (6718): mcc: 0.8994, acc: 0.8539, precision: 0.9347, recall: 0.8759, f1: 0.9044, edges-ner-ontonotes_loss: 0.0334
09/16 06:20:54 AM: Update 6686: task edges-ner-ontonotes, batch 686 (6686): mcc: 0.8987, acc: 0.8529, precision: 0.9343, recall: 0.8750, f1: 0.9036, edges-ner-ontonotes_loss: 0.0336
09/16 06:20:54 AM: Update 6792: task edges-ner-ontonotes, batch 792 (6792): mcc: 0.9017, acc: 0.8569, precision: 0.9363, recall: 0.8786, f1: 0.9065, edges-ner-ontonotes_loss: 0.0326
09/16 06:21:05 AM: Update 6770: task edges-ner-ontonotes, batch 770 (6770): mcc: 0.9009, acc: 0.8557, precision: 0.9358, recall: 0.8775, f1: 0.9057, edges-ner-ontonotes_loss: 0.0328
09/16 06:21:05 AM: Update 6851: task edges-ner-ontonotes, batch 851 (6851): mcc: 0.9026, acc: 0.8583, precision: 0.9369, recall: 0.8796, f1: 0.9074, edges-ner-ontonotes_loss: 0.0323
09/16 06:21:15 AM: Update 6842: task edges-ner-ontonotes, batch 842 (6842): mcc: 0.9023, acc: 0.8579, precision: 0.9367, recall: 0.8793, f1: 0.9071, edges-ner-ontonotes_loss: 0.0323
09/16 06:21:15 AM: Update 6922: task edges-ner-ontonotes, batch 922 (6922): mcc: 0.9049, acc: 0.8613, precision: 0.9385, recall: 0.8824, f1: 0.9096, edges-ner-ontonotes_loss: 0.0315
09/16 06:21:25 AM: Update 6899: task edges-ner-ontonotes, batch 899 (6899): mcc: 0.9043, acc: 0.8605, precision: 0.9381, recall: 0.8817, f1: 0.9090, edges-ner-ontonotes_loss: 0.0317
09/16 06:21:25 AM: Update 6999: task edges-ner-ontonotes, batch 999 (6999): mcc: 0.9075, acc: 0.8645, precision: 0.9400, recall: 0.8856, f1: 0.9120, edges-ner-ontonotes_loss: 0.0307
09/16 06:21:26 AM: ***** Step 7000 / Validation 7 *****
09/16 06:21:26 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:21:26 AM: Validating...
09/16 06:21:35 AM: Update 6957: task edges-ner-ontonotes, batch 957 (6957): mcc: 0.9061, acc: 0.8628, precision: 0.9391, recall: 0.8840, f1: 0.9107, edges-ner-ontonotes_loss: 0.0312
09/16 06:21:36 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.9104, acc: 0.8798, precision: 0.9286, recall: 0.9023, f1: 0.9152, edges-ner-ontonotes_loss: 0.0302
09/16 06:21:43 AM: ***** Step 7000 / Validation 7 *****
09/16 06:21:43 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:21:43 AM: Validating...
09/16 06:21:45 AM: Evaluate: task edges-ner-ontonotes, batch 13 (157): mcc: 0.8413, acc: 0.7874, precision: 0.8842, recall: 0.8165, f1: 0.8490, edges-ner-ontonotes_loss: 0.0434
09/16 06:21:47 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9200, acc: 0.8862, precision: 0.9423, recall: 0.9067, f1: 0.9242, edges-ner-ontonotes_loss: 0.0265
09/16 06:21:55 AM: Evaluate: task edges-ner-ontonotes, batch 62 (157): mcc: 0.9107, acc: 0.8794, precision: 0.9280, recall: 0.9034, f1: 0.9155, edges-ner-ontonotes_loss: 0.0302
09/16 06:21:56 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:21:56 AM: Best result seen so far for macro.
09/16 06:21:56 AM: Updating LR scheduler:
09/16 06:21:56 AM: 	Best result seen so far for macro_avg: 0.933
09/16 06:21:56 AM: 	# validation passes without improvement: 0
09/16 06:21:56 AM: edges-ner-ontonotes_loss: training: 0.030745 validation: 0.023541
09/16 06:21:56 AM: macro_avg: validation: 0.933405
09/16 06:21:56 AM: micro_avg: validation: 0.000000
09/16 06:21:56 AM: edges-ner-ontonotes_mcc: training: 0.907441 validation: 0.929685
09/16 06:21:56 AM: edges-ner-ontonotes_acc: training: 0.864531 validation: 0.899302
09/16 06:21:56 AM: edges-ner-ontonotes_precision: training: 0.939995 validation: 0.948493
09/16 06:21:56 AM: edges-ner-ontonotes_recall: training: 0.885634 validation: 0.918790
09/16 06:21:56 AM: edges-ner-ontonotes_f1: training: 0.912005 validation: 0.933405
09/16 06:21:56 AM: Global learning rate: 0.0001
09/16 06:21:56 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:21:57 AM: Update 7002: task edges-ner-ontonotes, batch 2 (7002): mcc: 0.9493, acc: 0.9234, precision: 0.9674, recall: 0.9369, f1: 0.9519, edges-ner-ontonotes_loss: 0.0153
09/16 06:22:06 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9200, acc: 0.8862, precision: 0.9423, recall: 0.9067, f1: 0.9242, edges-ner-ontonotes_loss: 0.0265
09/16 06:22:07 AM: Update 7059: task edges-ner-ontonotes, batch 59 (7059): mcc: 0.9339, acc: 0.9011, precision: 0.9524, recall: 0.9230, f1: 0.9374, edges-ner-ontonotes_loss: 0.0213
09/16 06:22:14 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:22:14 AM: Best result seen so far for macro.
09/16 06:22:14 AM: Updating LR scheduler:
09/16 06:22:14 AM: 	Best result seen so far for macro_avg: 0.933
09/16 06:22:14 AM: 	# validation passes without improvement: 0
09/16 06:22:14 AM: edges-ner-ontonotes_loss: training: 0.030745 validation: 0.023541
09/16 06:22:14 AM: macro_avg: validation: 0.933405
09/16 06:22:14 AM: micro_avg: validation: 0.000000
09/16 06:22:14 AM: edges-ner-ontonotes_mcc: training: 0.907441 validation: 0.929685
09/16 06:22:14 AM: edges-ner-ontonotes_acc: training: 0.864531 validation: 0.899302
09/16 06:22:14 AM: edges-ner-ontonotes_precision: training: 0.939995 validation: 0.948493
09/16 06:22:14 AM: edges-ner-ontonotes_recall: training: 0.885634 validation: 0.918790
09/16 06:22:14 AM: edges-ner-ontonotes_f1: training: 0.912005 validation: 0.933405
09/16 06:22:14 AM: Global learning rate: 0.0001
09/16 06:22:14 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:22:16 AM: Update 7014: task edges-ner-ontonotes, batch 14 (7014): mcc: 0.9382, acc: 0.9092, precision: 0.9534, recall: 0.9299, f1: 0.9415, edges-ner-ontonotes_loss: 0.0209
09/16 06:22:17 AM: Update 7119: task edges-ner-ontonotes, batch 119 (7119): mcc: 0.9333, acc: 0.8991, precision: 0.9552, recall: 0.9190, f1: 0.9367, edges-ner-ontonotes_loss: 0.0215
09/16 06:22:26 AM: Update 7093: task edges-ner-ontonotes, batch 93 (7093): mcc: 0.9339, acc: 0.9007, precision: 0.9537, recall: 0.9215, f1: 0.9373, edges-ner-ontonotes_loss: 0.0214
09/16 06:22:27 AM: Update 7174: task edges-ner-ontonotes, batch 174 (7174): mcc: 0.9336, acc: 0.8997, precision: 0.9557, recall: 0.9190, f1: 0.9370, edges-ner-ontonotes_loss: 0.0212
09/16 06:22:36 AM: Update 7160: task edges-ner-ontonotes, batch 160 (7160): mcc: 0.9342, acc: 0.9007, precision: 0.9557, recall: 0.9202, f1: 0.9376, edges-ner-ontonotes_loss: 0.0211
09/16 06:22:37 AM: Update 7248: task edges-ner-ontonotes, batch 248 (7248): mcc: 0.9311, acc: 0.8960, precision: 0.9532, recall: 0.9169, f1: 0.9347, edges-ner-ontonotes_loss: 0.0218
09/16 06:22:47 AM: Update 7205: task edges-ner-ontonotes, batch 205 (7205): mcc: 0.9328, acc: 0.8984, precision: 0.9544, recall: 0.9187, f1: 0.9362, edges-ner-ontonotes_loss: 0.0216
09/16 06:22:47 AM: Update 7335: task edges-ner-ontonotes, batch 335 (7335): mcc: 0.9319, acc: 0.8968, precision: 0.9540, recall: 0.9175, f1: 0.9354, edges-ner-ontonotes_loss: 0.0217
09/16 06:22:57 AM: Update 7405: task edges-ner-ontonotes, batch 405 (7405): mcc: 0.9315, acc: 0.8963, precision: 0.9532, recall: 0.9176, f1: 0.9351, edges-ner-ontonotes_loss: 0.0216
09/16 06:22:58 AM: Update 7276: task edges-ner-ontonotes, batch 276 (7276): mcc: 0.9312, acc: 0.8960, precision: 0.9534, recall: 0.9168, f1: 0.9348, edges-ner-ontonotes_loss: 0.0219
09/16 06:23:08 AM: Update 7348: task edges-ner-ontonotes, batch 348 (7348): mcc: 0.9318, acc: 0.8965, precision: 0.9536, recall: 0.9177, f1: 0.9353, edges-ner-ontonotes_loss: 0.0216
09/16 06:23:10 AM: Update 7477: task edges-ner-ontonotes, batch 477 (7477): mcc: 0.9304, acc: 0.8948, precision: 0.9527, recall: 0.9161, f1: 0.9340, edges-ner-ontonotes_loss: 0.0221
09/16 06:23:18 AM: Update 7429: task edges-ner-ontonotes, batch 429 (7429): mcc: 0.9312, acc: 0.8960, precision: 0.9531, recall: 0.9171, f1: 0.9348, edges-ner-ontonotes_loss: 0.0218
09/16 06:23:20 AM: Update 7552: task edges-ner-ontonotes, batch 552 (7552): mcc: 0.9248, acc: 0.8874, precision: 0.9491, recall: 0.9090, f1: 0.9286, edges-ner-ontonotes_loss: 0.0246
09/16 06:23:28 AM: Update 7487: task edges-ner-ontonotes, batch 487 (7487): mcc: 0.9290, acc: 0.8928, precision: 0.9518, recall: 0.9143, f1: 0.9327, edges-ner-ontonotes_loss: 0.0227
09/16 06:23:30 AM: Update 7627: task edges-ner-ontonotes, batch 627 (7627): mcc: 0.9212, acc: 0.8829, precision: 0.9470, recall: 0.9045, f1: 0.9253, edges-ner-ontonotes_loss: 0.0258
09/16 06:23:38 AM: Update 7562: task edges-ner-ontonotes, batch 562 (7562): mcc: 0.9239, acc: 0.8864, precision: 0.9487, recall: 0.9079, f1: 0.9278, edges-ner-ontonotes_loss: 0.0248
09/16 06:23:40 AM: Update 7706: task edges-ner-ontonotes, batch 706 (7706): mcc: 0.9179, acc: 0.8786, precision: 0.9448, recall: 0.9003, f1: 0.9220, edges-ner-ontonotes_loss: 0.0274
09/16 06:23:51 AM: Update 7638: task edges-ner-ontonotes, batch 638 (7638): mcc: 0.9208, acc: 0.8823, precision: 0.9468, recall: 0.9039, f1: 0.9248, edges-ner-ontonotes_loss: 0.0261
09/16 06:23:53 AM: Update 7781: task edges-ner-ontonotes, batch 781 (7781): mcc: 0.9159, acc: 0.8761, precision: 0.9437, recall: 0.8977, f1: 0.9202, edges-ner-ontonotes_loss: 0.0283
09/16 06:24:01 AM: Update 7722: task edges-ner-ontonotes, batch 722 (7722): mcc: 0.9174, acc: 0.8780, precision: 0.9446, recall: 0.8997, f1: 0.9216, edges-ner-ontonotes_loss: 0.0276
09/16 06:24:03 AM: Update 7863: task edges-ner-ontonotes, batch 863 (7863): mcc: 0.9142, acc: 0.8740, precision: 0.9424, recall: 0.8959, f1: 0.9186, edges-ner-ontonotes_loss: 0.0290
09/16 06:24:11 AM: Update 7781: task edges-ner-ontonotes, batch 781 (7781): mcc: 0.9159, acc: 0.8761, precision: 0.9437, recall: 0.8977, f1: 0.9202, edges-ner-ontonotes_loss: 0.0283
09/16 06:24:13 AM: Update 7971: task edges-ner-ontonotes, batch 971 (7971): mcc: 0.9131, acc: 0.8726, precision: 0.9416, recall: 0.8947, f1: 0.9175, edges-ner-ontonotes_loss: 0.0293
09/16 06:24:18 AM: ***** Step 8000 / Validation 8 *****
09/16 06:24:19 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:24:19 AM: Validating...
09/16 06:24:25 AM: Evaluate: task edges-ner-ontonotes, batch 39 (157): mcc: 0.9003, acc: 0.8686, precision: 0.9258, recall: 0.8861, f1: 0.9055, edges-ner-ontonotes_loss: 0.0321
09/16 06:24:25 AM: Update 7860: task edges-ner-ontonotes, batch 860 (7860): mcc: 0.9142, acc: 0.8740, precision: 0.9424, recall: 0.8958, f1: 0.9185, edges-ner-ontonotes_loss: 0.0290
09/16 06:24:35 AM: Evaluate: task edges-ner-ontonotes, batch 97 (157): mcc: 0.9230, acc: 0.8915, precision: 0.9470, recall: 0.9078, f1: 0.9270, edges-ner-ontonotes_loss: 0.0260
09/16 06:24:35 AM: Update 7925: task edges-ner-ontonotes, batch 925 (7925): mcc: 0.9137, acc: 0.8734, precision: 0.9419, recall: 0.8954, f1: 0.9181, edges-ner-ontonotes_loss: 0.0291
09/16 06:24:45 AM: Evaluate: task edges-ner-ontonotes, batch 150 (157): mcc: 0.9297, acc: 0.8988, precision: 0.9539, recall: 0.9136, f1: 0.9333, edges-ner-ontonotes_loss: 0.0235
09/16 06:24:45 AM: Update 7986: task edges-ner-ontonotes, batch 986 (7986): mcc: 0.9131, acc: 0.8726, precision: 0.9415, recall: 0.8947, f1: 0.9175, edges-ner-ontonotes_loss: 0.0293
09/16 06:24:46 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:24:46 AM: Best result seen so far for macro.
09/16 06:24:46 AM: Updating LR scheduler:
09/16 06:24:46 AM: 	Best result seen so far for macro_avg: 0.934
09/16 06:24:46 AM: 	# validation passes without improvement: 0
09/16 06:24:46 AM: edges-ner-ontonotes_loss: training: 0.029313 validation: 0.023132
09/16 06:24:46 AM: macro_avg: validation: 0.933932
09/16 06:24:46 AM: micro_avg: validation: 0.000000
09/16 06:24:46 AM: edges-ner-ontonotes_mcc: training: 0.913034 validation: 0.930374
09/16 06:24:46 AM: edges-ner-ontonotes_acc: training: 0.872496 validation: 0.899757
09/16 06:24:46 AM: edges-ner-ontonotes_precision: training: 0.941594 validation: 0.954409
09/16 06:24:46 AM: edges-ner-ontonotes_recall: training: 0.894463 validation: 0.914316
09/16 06:24:46 AM: edges-ner-ontonotes_f1: training: 0.917423 validation: 0.933932
09/16 06:24:46 AM: Global learning rate: 0.0001
09/16 06:24:46 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:24:47 AM: ***** Step 8000 / Validation 8 *****
09/16 06:24:47 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:24:47 AM: Validating...
09/16 06:24:55 AM: Update 8058: task edges-ner-ontonotes, batch 58 (8058): mcc: 0.9036, acc: 0.8568, precision: 0.9385, recall: 0.8799, f1: 0.9083, edges-ner-ontonotes_loss: 0.0306
09/16 06:24:55 AM: Evaluate: task edges-ner-ontonotes, batch 54 (157): mcc: 0.9105, acc: 0.8792, precision: 0.9341, recall: 0.8971, f1: 0.9152, edges-ner-ontonotes_loss: 0.0294
09/16 06:25:05 AM: Update 8099: task edges-ner-ontonotes, batch 99 (8099): mcc: 0.9012, acc: 0.8549, precision: 0.9343, recall: 0.8795, f1: 0.9061, edges-ner-ontonotes_loss: 0.0309
09/16 06:25:06 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9228, acc: 0.8897, precision: 0.9487, recall: 0.9056, f1: 0.9267, edges-ner-ontonotes_loss: 0.0254
09/16 06:25:14 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:25:14 AM: Best result seen so far for macro.
09/16 06:25:14 AM: Updating LR scheduler:
09/16 06:25:14 AM: 	Best result seen so far for macro_avg: 0.934
09/16 06:25:14 AM: 	# validation passes without improvement: 0
09/16 06:25:14 AM: edges-ner-ontonotes_loss: training: 0.029313 validation: 0.023132
09/16 06:25:14 AM: macro_avg: validation: 0.933932
09/16 06:25:14 AM: micro_avg: validation: 0.000000
09/16 06:25:14 AM: edges-ner-ontonotes_mcc: training: 0.913034 validation: 0.930374
09/16 06:25:14 AM: edges-ner-ontonotes_acc: training: 0.872496 validation: 0.899757
09/16 06:25:14 AM: edges-ner-ontonotes_precision: training: 0.941594 validation: 0.954409
09/16 06:25:14 AM: edges-ner-ontonotes_recall: training: 0.894463 validation: 0.914316
09/16 06:25:14 AM: edges-ner-ontonotes_f1: training: 0.917423 validation: 0.933932
09/16 06:25:14 AM: Global learning rate: 0.0001
09/16 06:25:14 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:25:15 AM: Update 8159: task edges-ner-ontonotes, batch 159 (8159): mcc: 0.9070, acc: 0.8632, precision: 0.9364, recall: 0.8884, f1: 0.9117, edges-ner-ontonotes_loss: 0.0294
09/16 06:25:16 AM: Update 8017: task edges-ner-ontonotes, batch 17 (8017): mcc: 0.9033, acc: 0.8578, precision: 0.9419, recall: 0.8761, f1: 0.9078, edges-ner-ontonotes_loss: 0.0293
09/16 06:25:25 AM: Update 8240: task edges-ner-ontonotes, batch 240 (8240): mcc: 0.9127, acc: 0.8711, precision: 0.9405, recall: 0.8949, f1: 0.9171, edges-ner-ontonotes_loss: 0.0280
09/16 06:25:28 AM: Update 8094: task edges-ner-ontonotes, batch 94 (8094): mcc: 0.9003, acc: 0.8539, precision: 0.9341, recall: 0.8780, f1: 0.9052, edges-ner-ontonotes_loss: 0.0312
09/16 06:25:35 AM: Update 8319: task edges-ner-ontonotes, batch 319 (8319): mcc: 0.9129, acc: 0.8719, precision: 0.9405, recall: 0.8953, f1: 0.9174, edges-ner-ontonotes_loss: 0.0276
09/16 06:25:38 AM: Update 8170: task edges-ner-ontonotes, batch 170 (8170): mcc: 0.9082, acc: 0.8650, precision: 0.9367, recall: 0.8902, f1: 0.9129, edges-ner-ontonotes_loss: 0.0293
09/16 06:25:46 AM: Update 8390: task edges-ner-ontonotes, batch 390 (8390): mcc: 0.9150, acc: 0.8746, precision: 0.9425, recall: 0.8972, f1: 0.9193, edges-ner-ontonotes_loss: 0.0271
09/16 06:25:48 AM: Update 8247: task edges-ner-ontonotes, batch 247 (8247): mcc: 0.9127, acc: 0.8712, precision: 0.9405, recall: 0.8949, f1: 0.9172, edges-ner-ontonotes_loss: 0.0279
09/16 06:25:56 AM: Update 8444: task edges-ner-ontonotes, batch 444 (8444): mcc: 0.9157, acc: 0.8756, precision: 0.9426, recall: 0.8984, f1: 0.9200, edges-ner-ontonotes_loss: 0.0270
09/16 06:25:58 AM: Update 8327: task edges-ner-ontonotes, batch 327 (8327): mcc: 0.9132, acc: 0.8724, precision: 0.9408, recall: 0.8956, f1: 0.9177, edges-ner-ontonotes_loss: 0.0276
09/16 06:26:06 AM: Update 8516: task edges-ner-ontonotes, batch 516 (8516): mcc: 0.9187, acc: 0.8795, precision: 0.9449, recall: 0.9018, f1: 0.9228, edges-ner-ontonotes_loss: 0.0262
09/16 06:26:08 AM: Update 8401: task edges-ner-ontonotes, batch 401 (8401): mcc: 0.9150, acc: 0.8748, precision: 0.9423, recall: 0.8974, f1: 0.9193, edges-ner-ontonotes_loss: 0.0272
09/16 06:26:16 AM: Update 8596: task edges-ner-ontonotes, batch 596 (8596): mcc: 0.9211, acc: 0.8829, precision: 0.9462, recall: 0.9050, f1: 0.9252, edges-ner-ontonotes_loss: 0.0255
09/16 06:26:19 AM: Update 8456: task edges-ner-ontonotes, batch 456 (8456): mcc: 0.9164, acc: 0.8766, precision: 0.9433, recall: 0.8991, f1: 0.9207, edges-ner-ontonotes_loss: 0.0268
09/16 06:26:26 AM: Update 8669: task edges-ner-ontonotes, batch 669 (8669): mcc: 0.9229, acc: 0.8851, precision: 0.9473, recall: 0.9074, f1: 0.9269, edges-ner-ontonotes_loss: 0.0249
09/16 06:26:29 AM: Update 8528: task edges-ner-ontonotes, batch 528 (8528): mcc: 0.9192, acc: 0.8802, precision: 0.9452, recall: 0.9024, f1: 0.9233, edges-ner-ontonotes_loss: 0.0260
09/16 06:26:36 AM: Update 8727: task edges-ner-ontonotes, batch 727 (8727): mcc: 0.9237, acc: 0.8861, precision: 0.9478, recall: 0.9082, f1: 0.9276, edges-ner-ontonotes_loss: 0.0246
09/16 06:26:41 AM: Update 8605: task edges-ner-ontonotes, batch 605 (8605): mcc: 0.9214, acc: 0.8832, precision: 0.9464, recall: 0.9054, f1: 0.9254, edges-ner-ontonotes_loss: 0.0254
09/16 06:26:46 AM: Update 8799: task edges-ner-ontonotes, batch 799 (8799): mcc: 0.9249, acc: 0.8878, precision: 0.9486, recall: 0.9099, f1: 0.9288, edges-ner-ontonotes_loss: 0.0243
09/16 06:26:52 AM: Update 8677: task edges-ner-ontonotes, batch 677 (8677): mcc: 0.9231, acc: 0.8853, precision: 0.9473, recall: 0.9076, f1: 0.9270, edges-ner-ontonotes_loss: 0.0249
09/16 06:26:56 AM: Update 8875: task edges-ner-ontonotes, batch 875 (8875): mcc: 0.9254, acc: 0.8886, precision: 0.9487, recall: 0.9106, f1: 0.9293, edges-ner-ontonotes_loss: 0.0242
09/16 06:27:03 AM: Update 8733: task edges-ner-ontonotes, batch 733 (8733): mcc: 0.9240, acc: 0.8865, precision: 0.9480, recall: 0.9086, f1: 0.9279, edges-ner-ontonotes_loss: 0.0246
09/16 06:27:06 AM: Update 8958: task edges-ner-ontonotes, batch 958 (8958): mcc: 0.9260, acc: 0.8891, precision: 0.9491, recall: 0.9113, f1: 0.9298, edges-ner-ontonotes_loss: 0.0239
09/16 06:27:12 AM: ***** Step 9000 / Validation 9 *****
09/16 06:27:12 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:27:12 AM: Validating...
09/16 06:27:14 AM: Update 8803: task edges-ner-ontonotes, batch 803 (8803): mcc: 0.9251, acc: 0.8881, precision: 0.9487, recall: 0.9101, f1: 0.9290, edges-ner-ontonotes_loss: 0.0243
09/16 06:27:16 AM: Evaluate: task edges-ner-ontonotes, batch 29 (157): mcc: 0.8710, acc: 0.8376, precision: 0.8939, recall: 0.8624, f1: 0.8779, edges-ner-ontonotes_loss: 0.0405
09/16 06:27:26 AM: Update 8864: task edges-ner-ontonotes, batch 864 (8864): mcc: 0.9253, acc: 0.8884, precision: 0.9486, recall: 0.9105, f1: 0.9292, edges-ner-ontonotes_loss: 0.0242
09/16 06:27:26 AM: Evaluate: task edges-ner-ontonotes, batch 81 (157): mcc: 0.9150, acc: 0.8835, precision: 0.9355, recall: 0.9041, f1: 0.9195, edges-ner-ontonotes_loss: 0.0295
09/16 06:27:36 AM: Update 8919: task edges-ner-ontonotes, batch 919 (8919): mcc: 0.9259, acc: 0.8889, precision: 0.9490, recall: 0.9112, f1: 0.9297, edges-ner-ontonotes_loss: 0.0239
09/16 06:27:37 AM: Evaluate: task edges-ner-ontonotes, batch 131 (157): mcc: 0.9273, acc: 0.8981, precision: 0.9467, recall: 0.9161, f1: 0.9311, edges-ner-ontonotes_loss: 0.0247
09/16 06:27:43 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:27:43 AM: Best result seen so far for macro.
09/16 06:27:43 AM: Updating LR scheduler:
09/16 06:27:43 AM: 	Best result seen so far for macro_avg: 0.935
09/16 06:27:43 AM: 	# validation passes without improvement: 0
09/16 06:27:43 AM: edges-ner-ontonotes_loss: training: 0.023740 validation: 0.023155
09/16 06:27:43 AM: macro_avg: validation: 0.935401
09/16 06:27:43 AM: micro_avg: validation: 0.000000
09/16 06:27:43 AM: edges-ner-ontonotes_mcc: training: 0.926341 validation: 0.931775
09/16 06:27:43 AM: edges-ner-ontonotes_acc: training: 0.889607 validation: 0.903625
09/16 06:27:43 AM: edges-ner-ontonotes_precision: training: 0.949431 validation: 0.949465
09/16 06:27:43 AM: edges-ner-ontonotes_recall: training: 0.911633 validation: 0.921747
09/16 06:27:43 AM: edges-ner-ontonotes_f1: training: 0.930148 validation: 0.935401
09/16 06:27:43 AM: Global learning rate: 0.0001
09/16 06:27:43 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:27:46 AM: Update 8992: task edges-ner-ontonotes, batch 992 (8992): mcc: 0.9263, acc: 0.8895, precision: 0.9494, recall: 0.9116, f1: 0.9301, edges-ner-ontonotes_loss: 0.0238
09/16 06:27:47 AM: ***** Step 9000 / Validation 9 *****
09/16 06:27:47 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:27:47 AM: Validating...
09/16 06:27:51 AM: Update 9033: task edges-ner-ontonotes, batch 33 (9033): mcc: 0.9303, acc: 0.8920, precision: 0.9530, recall: 0.9156, f1: 0.9339, edges-ner-ontonotes_loss: 0.0227
09/16 06:27:56 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.9092, acc: 0.8798, precision: 0.9260, recall: 0.9025, f1: 0.9141, edges-ner-ontonotes_loss: 0.0308
09/16 06:28:01 AM: Update 9086: task edges-ner-ontonotes, batch 86 (9086): mcc: 0.9050, acc: 0.8617, precision: 0.9353, recall: 0.8856, f1: 0.9098, edges-ner-ontonotes_loss: 0.0334
09/16 06:28:06 AM: Evaluate: task edges-ner-ontonotes, batch 114 (157): mcc: 0.9214, acc: 0.8898, precision: 0.9427, recall: 0.9090, f1: 0.9255, edges-ner-ontonotes_loss: 0.0264
09/16 06:28:11 AM: Update 9142: task edges-ner-ontonotes, batch 142 (9142): mcc: 0.9030, acc: 0.8591, precision: 0.9343, recall: 0.8828, f1: 0.9078, edges-ner-ontonotes_loss: 0.0341
09/16 06:28:15 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:28:15 AM: Best result seen so far for macro.
09/16 06:28:15 AM: Updating LR scheduler:
09/16 06:28:15 AM: 	Best result seen so far for macro_avg: 0.935
09/16 06:28:15 AM: 	# validation passes without improvement: 0
09/16 06:28:15 AM: edges-ner-ontonotes_loss: training: 0.023740 validation: 0.023155
09/16 06:28:15 AM: macro_avg: validation: 0.935401
09/16 06:28:15 AM: micro_avg: validation: 0.000000
09/16 06:28:15 AM: edges-ner-ontonotes_mcc: training: 0.926341 validation: 0.931775
09/16 06:28:15 AM: edges-ner-ontonotes_acc: training: 0.889607 validation: 0.903625
09/16 06:28:15 AM: edges-ner-ontonotes_precision: training: 0.949431 validation: 0.949465
09/16 06:28:15 AM: edges-ner-ontonotes_recall: training: 0.911633 validation: 0.921747
09/16 06:28:15 AM: edges-ner-ontonotes_f1: training: 0.930148 validation: 0.935401
09/16 06:28:15 AM: Global learning rate: 0.0001
09/16 06:28:15 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:28:17 AM: Update 9001: task edges-ner-ontonotes, batch 1 (9001): mcc: 0.9284, acc: 0.9104, precision: 0.9394, recall: 0.9254, f1: 0.9323, edges-ner-ontonotes_loss: 0.0279
09/16 06:28:21 AM: Update 9221: task edges-ner-ontonotes, batch 221 (9221): mcc: 0.8998, acc: 0.8552, precision: 0.9322, recall: 0.8790, f1: 0.9048, edges-ner-ontonotes_loss: 0.0354
09/16 06:28:27 AM: Update 9055: task edges-ner-ontonotes, batch 55 (9055): mcc: 0.9107, acc: 0.8674, precision: 0.9409, recall: 0.8908, f1: 0.9151, edges-ner-ontonotes_loss: 0.0301
09/16 06:28:31 AM: Update 9305: task edges-ner-ontonotes, batch 305 (9305): mcc: 0.8978, acc: 0.8528, precision: 0.9308, recall: 0.8766, f1: 0.9029, edges-ner-ontonotes_loss: 0.0361
09/16 06:28:37 AM: Update 9134: task edges-ner-ontonotes, batch 134 (9134): mcc: 0.9028, acc: 0.8584, precision: 0.9338, recall: 0.8829, f1: 0.9076, edges-ner-ontonotes_loss: 0.0341
09/16 06:28:41 AM: Update 9367: task edges-ner-ontonotes, batch 367 (9367): mcc: 0.8973, acc: 0.8526, precision: 0.9301, recall: 0.8763, f1: 0.9024, edges-ner-ontonotes_loss: 0.0361
09/16 06:28:47 AM: Update 9209: task edges-ner-ontonotes, batch 209 (9209): mcc: 0.9008, acc: 0.8567, precision: 0.9325, recall: 0.8806, f1: 0.9058, edges-ner-ontonotes_loss: 0.0348
09/16 06:28:51 AM: Update 9447: task edges-ner-ontonotes, batch 447 (9447): mcc: 0.8980, acc: 0.8534, precision: 0.9304, recall: 0.8774, f1: 0.9031, edges-ner-ontonotes_loss: 0.0353
09/16 06:28:57 AM: Update 9290: task edges-ner-ontonotes, batch 290 (9290): mcc: 0.8980, acc: 0.8531, precision: 0.9310, recall: 0.8768, f1: 0.9031, edges-ner-ontonotes_loss: 0.0361
09/16 06:29:02 AM: Update 9530: task edges-ner-ontonotes, batch 530 (9530): mcc: 0.8988, acc: 0.8541, precision: 0.9310, recall: 0.8782, f1: 0.9038, edges-ner-ontonotes_loss: 0.0347
09/16 06:29:07 AM: Update 9346: task edges-ner-ontonotes, batch 346 (9346): mcc: 0.8978, acc: 0.8531, precision: 0.9309, recall: 0.8766, f1: 0.9029, edges-ner-ontonotes_loss: 0.0360
09/16 06:29:12 AM: Update 9634: task edges-ner-ontonotes, batch 634 (9634): mcc: 0.9000, acc: 0.8556, precision: 0.9318, recall: 0.8796, f1: 0.9050, edges-ner-ontonotes_loss: 0.0341
09/16 06:29:19 AM: Update 9441: task edges-ner-ontonotes, batch 441 (9441): mcc: 0.8975, acc: 0.8527, precision: 0.9299, recall: 0.8769, f1: 0.9026, edges-ner-ontonotes_loss: 0.0355
09/16 06:29:22 AM: Update 9690: task edges-ner-ontonotes, batch 690 (9690): mcc: 0.9015, acc: 0.8577, precision: 0.9328, recall: 0.8815, f1: 0.9064, edges-ner-ontonotes_loss: 0.0335
09/16 06:29:30 AM: Update 9522: task edges-ner-ontonotes, batch 522 (9522): mcc: 0.8987, acc: 0.8541, precision: 0.9310, recall: 0.8782, f1: 0.9038, edges-ner-ontonotes_loss: 0.0348
09/16 06:29:32 AM: Update 9769: task edges-ner-ontonotes, batch 769 (9769): mcc: 0.9035, acc: 0.8606, precision: 0.9342, recall: 0.8839, f1: 0.9084, edges-ner-ontonotes_loss: 0.0327
09/16 06:29:40 AM: Update 9606: task edges-ner-ontonotes, batch 606 (9606): mcc: 0.8996, acc: 0.8551, precision: 0.9317, recall: 0.8792, f1: 0.9047, edges-ner-ontonotes_loss: 0.0343
09/16 06:29:42 AM: Update 9852: task edges-ner-ontonotes, batch 852 (9852): mcc: 0.9054, acc: 0.8632, precision: 0.9355, recall: 0.8862, f1: 0.9102, edges-ner-ontonotes_loss: 0.0319
09/16 06:29:50 AM: Update 9665: task edges-ner-ontonotes, batch 665 (9665): mcc: 0.9006, acc: 0.8564, precision: 0.9325, recall: 0.8801, f1: 0.9055, edges-ner-ontonotes_loss: 0.0338
09/16 06:29:53 AM: Update 9936: task edges-ner-ontonotes, batch 936 (9936): mcc: 0.9071, acc: 0.8655, precision: 0.9365, recall: 0.8883, f1: 0.9118, edges-ner-ontonotes_loss: 0.0313
09/16 06:30:00 AM: Update 9747: task edges-ner-ontonotes, batch 747 (9747): mcc: 0.9033, acc: 0.8601, precision: 0.9342, recall: 0.8836, f1: 0.9082, edges-ner-ontonotes_loss: 0.0328
09/16 06:30:04 AM: Update 9989: task edges-ner-ontonotes, batch 989 (9989): mcc: 0.9083, acc: 0.8670, precision: 0.9374, recall: 0.8898, f1: 0.9130, edges-ner-ontonotes_loss: 0.0309
09/16 06:30:06 AM: ***** Step 10000 / Validation 10 *****
09/16 06:30:06 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:30:06 AM: Validating...
09/16 06:30:10 AM: Update 9822: task edges-ner-ontonotes, batch 822 (9822): mcc: 0.9049, acc: 0.8627, precision: 0.9351, recall: 0.8857, f1: 0.9097, edges-ner-ontonotes_loss: 0.0321
09/16 06:30:15 AM: Evaluate: task edges-ner-ontonotes, batch 55 (157): mcc: 0.9131, acc: 0.8836, precision: 0.9346, recall: 0.9013, f1: 0.9177, edges-ner-ontonotes_loss: 0.0295
09/16 06:30:20 AM: Update 9884: task edges-ner-ontonotes, batch 884 (9884): mcc: 0.9061, acc: 0.8643, precision: 0.9358, recall: 0.8873, f1: 0.9109, edges-ner-ontonotes_loss: 0.0317
09/16 06:30:26 AM: Evaluate: task edges-ner-ontonotes, batch 112 (157): mcc: 0.9259, acc: 0.8951, precision: 0.9473, recall: 0.9129, f1: 0.9298, edges-ner-ontonotes_loss: 0.0247
09/16 06:30:31 AM: Update 9939: task edges-ner-ontonotes, batch 939 (9939): mcc: 0.9071, acc: 0.8655, precision: 0.9365, recall: 0.8882, f1: 0.9118, edges-ner-ontonotes_loss: 0.0313
09/16 06:30:35 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:30:35 AM: Best result seen so far for macro.
09/16 06:30:35 AM: Updating LR scheduler:
09/16 06:30:35 AM: 	Best result seen so far for macro_avg: 0.938
09/16 06:30:35 AM: 	# validation passes without improvement: 0
09/16 06:30:35 AM: edges-ner-ontonotes_loss: training: 0.030711 validation: 0.022143
09/16 06:30:35 AM: macro_avg: validation: 0.937681
09/16 06:30:35 AM: micro_avg: validation: 0.000000
09/16 06:30:35 AM: edges-ner-ontonotes_mcc: training: 0.908770 validation: 0.934222
09/16 06:30:35 AM: edges-ner-ontonotes_acc: training: 0.867522 validation: 0.905748
09/16 06:30:35 AM: edges-ner-ontonotes_precision: training: 0.937671 validation: 0.953445
09/16 06:30:35 AM: edges-ner-ontonotes_recall: training: 0.890325 validation: 0.922430
09/16 06:30:35 AM: edges-ner-ontonotes_f1: training: 0.913385 validation: 0.937681
09/16 06:30:35 AM: Global learning rate: 0.0001
09/16 06:30:35 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:30:36 AM: Update 10013: task edges-ner-ontonotes, batch 13 (10013): mcc: 0.9345, acc: 0.8971, precision: 0.9511, recall: 0.9252, f1: 0.9380, edges-ner-ontonotes_loss: 0.0206
09/16 06:30:41 AM: Update 9985: task edges-ner-ontonotes, batch 985 (9985): mcc: 0.9082, acc: 0.8668, precision: 0.9373, recall: 0.8896, f1: 0.9128, edges-ner-ontonotes_loss: 0.0309
09/16 06:30:43 AM: ***** Step 10000 / Validation 10 *****
09/16 06:30:43 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:30:43 AM: Validating...
09/16 06:30:47 AM: Update 10081: task edges-ner-ontonotes, batch 81 (10081): mcc: 0.9342, acc: 0.9022, precision: 0.9546, recall: 0.9211, f1: 0.9376, edges-ner-ontonotes_loss: 0.0214
09/16 06:30:51 AM: Evaluate: task edges-ner-ontonotes, batch 50 (157): mcc: 0.9045, acc: 0.8731, precision: 0.9280, recall: 0.8917, f1: 0.9095, edges-ner-ontonotes_loss: 0.0312
09/16 06:30:57 AM: Update 10137: task edges-ner-ontonotes, batch 137 (10137): mcc: 0.9353, acc: 0.9036, precision: 0.9556, recall: 0.9223, f1: 0.9387, edges-ner-ontonotes_loss: 0.0211
09/16 06:31:01 AM: Evaluate: task edges-ner-ontonotes, batch 103 (157): mcc: 0.9240, acc: 0.8929, precision: 0.9461, recall: 0.9105, f1: 0.9280, edges-ner-ontonotes_loss: 0.0256
09/16 06:31:07 AM: Update 10193: task edges-ner-ontonotes, batch 193 (10193): mcc: 0.9363, acc: 0.9051, precision: 0.9566, recall: 0.9232, f1: 0.9396, edges-ner-ontonotes_loss: 0.0207
09/16 06:31:12 AM: Evaluate: task edges-ner-ontonotes, batch 152 (157): mcc: 0.9337, acc: 0.9049, precision: 0.9533, recall: 0.9216, f1: 0.9372, edges-ner-ontonotes_loss: 0.0224
09/16 06:31:14 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:31:14 AM: Best result seen so far for macro.
09/16 06:31:14 AM: Updating LR scheduler:
09/16 06:31:14 AM: 	Best result seen so far for macro_avg: 0.938
09/16 06:31:14 AM: 	# validation passes without improvement: 0
09/16 06:31:14 AM: edges-ner-ontonotes_loss: training: 0.030711 validation: 0.022143
09/16 06:31:14 AM: macro_avg: validation: 0.937681
09/16 06:31:14 AM: micro_avg: validation: 0.000000
09/16 06:31:14 AM: edges-ner-ontonotes_mcc: training: 0.908770 validation: 0.934222
09/16 06:31:14 AM: edges-ner-ontonotes_acc: training: 0.867522 validation: 0.905748
09/16 06:31:14 AM: edges-ner-ontonotes_precision: training: 0.937671 validation: 0.953445
09/16 06:31:14 AM: edges-ner-ontonotes_recall: training: 0.890325 validation: 0.922430
09/16 06:31:14 AM: edges-ner-ontonotes_f1: training: 0.913385 validation: 0.937681
09/16 06:31:14 AM: Global learning rate: 0.0001
09/16 06:31:14 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:31:17 AM: Update 10266: task edges-ner-ontonotes, batch 266 (10266): mcc: 0.9362, acc: 0.9045, precision: 0.9561, recall: 0.9234, f1: 0.9395, edges-ner-ontonotes_loss: 0.0206
09/16 06:31:23 AM: Update 10059: task edges-ner-ontonotes, batch 59 (10059): mcc: 0.9383, acc: 0.9066, precision: 0.9581, recall: 0.9255, f1: 0.9415, edges-ner-ontonotes_loss: 0.0200
09/16 06:31:27 AM: Update 10324: task edges-ner-ontonotes, batch 324 (10324): mcc: 0.9356, acc: 0.9034, precision: 0.9556, recall: 0.9230, f1: 0.9390, edges-ner-ontonotes_loss: 0.0206
09/16 06:31:34 AM: Update 10128: task edges-ner-ontonotes, batch 128 (10128): mcc: 0.9348, acc: 0.9030, precision: 0.9554, recall: 0.9215, f1: 0.9382, edges-ner-ontonotes_loss: 0.0212
09/16 06:31:37 AM: Update 10395: task edges-ner-ontonotes, batch 395 (10395): mcc: 0.9353, acc: 0.9031, precision: 0.9554, recall: 0.9225, f1: 0.9387, edges-ner-ontonotes_loss: 0.0206
09/16 06:31:44 AM: Update 10198: task edges-ner-ontonotes, batch 198 (10198): mcc: 0.9365, acc: 0.9054, precision: 0.9567, recall: 0.9234, f1: 0.9398, edges-ner-ontonotes_loss: 0.0207
09/16 06:31:47 AM: Update 10466: task edges-ner-ontonotes, batch 466 (10466): mcc: 0.9352, acc: 0.9026, precision: 0.9551, recall: 0.9226, f1: 0.9386, edges-ner-ontonotes_loss: 0.0206
09/16 06:31:54 AM: Update 10268: task edges-ner-ontonotes, batch 268 (10268): mcc: 0.9361, acc: 0.9042, precision: 0.9560, recall: 0.9233, f1: 0.9394, edges-ner-ontonotes_loss: 0.0206
09/16 06:31:57 AM: Update 10546: task edges-ner-ontonotes, batch 546 (10546): mcc: 0.9351, acc: 0.9024, precision: 0.9549, recall: 0.9226, f1: 0.9385, edges-ner-ontonotes_loss: 0.0210
09/16 06:32:04 AM: Update 10323: task edges-ner-ontonotes, batch 323 (10323): mcc: 0.9355, acc: 0.9033, precision: 0.9554, recall: 0.9229, f1: 0.9388, edges-ner-ontonotes_loss: 0.0206
09/16 06:32:07 AM: Update 10595: task edges-ner-ontonotes, batch 595 (10595): mcc: 0.9341, acc: 0.9008, precision: 0.9546, recall: 0.9212, f1: 0.9376, edges-ner-ontonotes_loss: 0.0210
09/16 06:32:14 AM: Update 10396: task edges-ner-ontonotes, batch 396 (10396): mcc: 0.9354, acc: 0.9031, precision: 0.9556, recall: 0.9225, f1: 0.9387, edges-ner-ontonotes_loss: 0.0206
09/16 06:32:17 AM: Update 10668: task edges-ner-ontonotes, batch 668 (10668): mcc: 0.9301, acc: 0.8952, precision: 0.9521, recall: 0.9160, f1: 0.9337, edges-ner-ontonotes_loss: 0.0229
09/16 06:32:25 AM: Update 10469: task edges-ner-ontonotes, batch 469 (10469): mcc: 0.9352, acc: 0.9027, precision: 0.9551, recall: 0.9227, f1: 0.9386, edges-ner-ontonotes_loss: 0.0206
09/16 06:32:27 AM: Update 10740: task edges-ner-ontonotes, batch 740 (10740): mcc: 0.9274, acc: 0.8918, precision: 0.9502, recall: 0.9128, f1: 0.9311, edges-ner-ontonotes_loss: 0.0241
09/16 06:32:35 AM: Update 10544: task edges-ner-ontonotes, batch 544 (10544): mcc: 0.9352, acc: 0.9025, precision: 0.9550, recall: 0.9227, f1: 0.9386, edges-ner-ontonotes_loss: 0.0209
09/16 06:32:38 AM: Update 10825: task edges-ner-ontonotes, batch 825 (10825): mcc: 0.9246, acc: 0.8882, precision: 0.9485, recall: 0.9093, f1: 0.9285, edges-ner-ontonotes_loss: 0.0254
09/16 06:32:46 AM: Update 10594: task edges-ner-ontonotes, batch 594 (10594): mcc: 0.9342, acc: 0.9009, precision: 0.9546, recall: 0.9213, f1: 0.9376, edges-ner-ontonotes_loss: 0.0210
09/16 06:32:49 AM: Update 10893: task edges-ner-ontonotes, batch 893 (10893): mcc: 0.9225, acc: 0.8855, precision: 0.9470, recall: 0.9069, f1: 0.9265, edges-ner-ontonotes_loss: 0.0263
09/16 06:32:58 AM: Update 10678: task edges-ner-ontonotes, batch 678 (10678): mcc: 0.9296, acc: 0.8945, precision: 0.9519, recall: 0.9153, f1: 0.9333, edges-ner-ontonotes_loss: 0.0231
09/16 06:32:59 AM: Update 10977: task edges-ner-ontonotes, batch 977 (10977): mcc: 0.9209, acc: 0.8832, precision: 0.9458, recall: 0.9050, f1: 0.9249, edges-ner-ontonotes_loss: 0.0268
09/16 06:33:03 AM: ***** Step 11000 / Validation 11 *****
09/16 06:33:03 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:33:03 AM: Validating...
09/16 06:33:08 AM: Update 10747: task edges-ner-ontonotes, batch 747 (10747): mcc: 0.9273, acc: 0.8917, precision: 0.9502, recall: 0.9126, f1: 0.9310, edges-ner-ontonotes_loss: 0.0242
09/16 06:33:09 AM: Evaluate: task edges-ner-ontonotes, batch 44 (157): mcc: 0.9073, acc: 0.8757, precision: 0.9252, recall: 0.8997, f1: 0.9123, edges-ner-ontonotes_loss: 0.0302
09/16 06:33:18 AM: Update 10805: task edges-ner-ontonotes, batch 805 (10805): mcc: 0.9254, acc: 0.8894, precision: 0.9491, recall: 0.9102, f1: 0.9293, edges-ner-ontonotes_loss: 0.0251
09/16 06:33:19 AM: Evaluate: task edges-ner-ontonotes, batch 99 (157): mcc: 0.9222, acc: 0.8898, precision: 0.9421, recall: 0.9111, f1: 0.9263, edges-ner-ontonotes_loss: 0.0256
09/16 06:33:28 AM: Update 10857: task edges-ner-ontonotes, batch 857 (10857): mcc: 0.9237, acc: 0.8870, precision: 0.9477, recall: 0.9084, f1: 0.9276, edges-ner-ontonotes_loss: 0.0258
09/16 06:33:30 AM: Evaluate: task edges-ner-ontonotes, batch 151 (157): mcc: 0.9324, acc: 0.9026, precision: 0.9512, recall: 0.9212, f1: 0.9360, edges-ner-ontonotes_loss: 0.0225
09/16 06:33:31 AM: Updating LR scheduler:
09/16 06:33:31 AM: 	Best result seen so far for macro_avg: 0.938
09/16 06:33:31 AM: 	# validation passes without improvement: 1
09/16 06:33:31 AM: edges-ner-ontonotes_loss: training: 0.026940 validation: 0.022279
09/16 06:33:31 AM: macro_avg: validation: 0.936287
09/16 06:33:31 AM: micro_avg: validation: 0.000000
09/16 06:33:31 AM: edges-ner-ontonotes_mcc: training: 0.920630 validation: 0.932736
09/16 06:33:31 AM: edges-ner-ontonotes_acc: training: 0.882947 validation: 0.903170
09/16 06:33:31 AM: edges-ner-ontonotes_precision: training: 0.945685 validation: 0.951535
09/16 06:33:31 AM: edges-ner-ontonotes_recall: training: 0.904630 validation: 0.921520
09/16 06:33:31 AM: edges-ner-ontonotes_f1: training: 0.924702 validation: 0.936287
09/16 06:33:31 AM: Global learning rate: 0.0001
09/16 06:33:31 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:33:38 AM: Update 10916: task edges-ner-ontonotes, batch 916 (10916): mcc: 0.9219, acc: 0.8847, precision: 0.9465, recall: 0.9063, f1: 0.9260, edges-ner-ontonotes_loss: 0.0265
09/16 06:33:40 AM: Update 11084: task edges-ner-ontonotes, batch 84 (11084): mcc: 0.9074, acc: 0.8656, precision: 0.9371, recall: 0.8884, f1: 0.9121, edges-ner-ontonotes_loss: 0.0305
09/16 06:33:48 AM: ***** Step 11000 / Validation 11 *****
09/16 06:33:48 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:33:48 AM: Validating...
09/16 06:33:48 AM: Evaluate: task edges-ner-ontonotes, batch 3 (157): mcc: 0.7804, acc: 0.6863, precision: 0.8361, recall: 0.7500, f1: 0.7907, edges-ner-ontonotes_loss: 0.0564
09/16 06:33:50 AM: Update 11171: task edges-ner-ontonotes, batch 171 (11171): mcc: 0.9041, acc: 0.8604, precision: 0.9340, recall: 0.8851, f1: 0.9089, edges-ner-ontonotes_loss: 0.0305
09/16 06:33:59 AM: Evaluate: task edges-ner-ontonotes, batch 72 (157): mcc: 0.9156, acc: 0.8823, precision: 0.9349, recall: 0.9057, f1: 0.9201, edges-ner-ontonotes_loss: 0.0280
09/16 06:34:00 AM: Update 11214: task edges-ner-ontonotes, batch 214 (11214): mcc: 0.9034, acc: 0.8598, precision: 0.9338, recall: 0.8841, f1: 0.9083, edges-ner-ontonotes_loss: 0.0307
09/16 06:34:09 AM: Evaluate: task edges-ner-ontonotes, batch 119 (157): mcc: 0.9263, acc: 0.8940, precision: 0.9460, recall: 0.9149, f1: 0.9302, edges-ner-ontonotes_loss: 0.0243
09/16 06:34:10 AM: Update 11276: task edges-ner-ontonotes, batch 276 (11276): mcc: 0.9081, acc: 0.8664, precision: 0.9371, recall: 0.8896, f1: 0.9127, edges-ner-ontonotes_loss: 0.0295
09/16 06:34:16 AM: Updating LR scheduler:
09/16 06:34:16 AM: 	Best result seen so far for macro_avg: 0.938
09/16 06:34:16 AM: 	# validation passes without improvement: 1
09/16 06:34:16 AM: edges-ner-ontonotes_loss: training: 0.026940 validation: 0.022279
09/16 06:34:16 AM: macro_avg: validation: 0.936287
09/16 06:34:16 AM: micro_avg: validation: 0.000000
09/16 06:34:16 AM: edges-ner-ontonotes_mcc: training: 0.920630 validation: 0.932736
09/16 06:34:16 AM: edges-ner-ontonotes_acc: training: 0.882947 validation: 0.903170
09/16 06:34:16 AM: edges-ner-ontonotes_precision: training: 0.945685 validation: 0.951535
09/16 06:34:16 AM: edges-ner-ontonotes_recall: training: 0.904630 validation: 0.921520
09/16 06:34:16 AM: edges-ner-ontonotes_f1: training: 0.924702 validation: 0.936287
09/16 06:34:16 AM: Global learning rate: 0.0001
09/16 06:34:16 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:34:19 AM: Update 11007: task edges-ner-ontonotes, batch 7 (11007): mcc: 0.9185, acc: 0.8801, precision: 0.9512, recall: 0.8954, f1: 0.9225, edges-ner-ontonotes_loss: 0.0282
09/16 06:34:20 AM: Update 11348: task edges-ner-ontonotes, batch 348 (11348): mcc: 0.9108, acc: 0.8698, precision: 0.9384, recall: 0.8935, f1: 0.9154, edges-ner-ontonotes_loss: 0.0287
09/16 06:34:29 AM: Update 11088: task edges-ner-ontonotes, batch 88 (11088): mcc: 0.9074, acc: 0.8656, precision: 0.9375, recall: 0.8879, f1: 0.9121, edges-ner-ontonotes_loss: 0.0304
09/16 06:34:30 AM: Update 11427: task edges-ner-ontonotes, batch 427 (11427): mcc: 0.9128, acc: 0.8728, precision: 0.9398, recall: 0.8958, f1: 0.9173, edges-ner-ontonotes_loss: 0.0281
09/16 06:34:39 AM: Update 11172: task edges-ner-ontonotes, batch 172 (11172): mcc: 0.9038, acc: 0.8600, precision: 0.9338, recall: 0.8849, f1: 0.9087, edges-ner-ontonotes_loss: 0.0306
09/16 06:34:40 AM: Update 11510: task edges-ner-ontonotes, batch 510 (11510): mcc: 0.9148, acc: 0.8760, precision: 0.9409, recall: 0.8985, f1: 0.9192, edges-ner-ontonotes_loss: 0.0276
09/16 06:34:49 AM: Update 11234: task edges-ner-ontonotes, batch 234 (11234): mcc: 0.9050, acc: 0.8621, precision: 0.9350, recall: 0.8860, f1: 0.9098, edges-ner-ontonotes_loss: 0.0303
09/16 06:34:50 AM: Update 11566: task edges-ner-ontonotes, batch 566 (11566): mcc: 0.9172, acc: 0.8789, precision: 0.9428, recall: 0.9011, f1: 0.9215, edges-ner-ontonotes_loss: 0.0270
09/16 06:34:59 AM: Update 11315: task edges-ner-ontonotes, batch 315 (11315): mcc: 0.9103, acc: 0.8689, precision: 0.9384, recall: 0.8924, f1: 0.9148, edges-ner-ontonotes_loss: 0.0290
09/16 06:35:02 AM: Update 11638: task edges-ner-ontonotes, batch 638 (11638): mcc: 0.9193, acc: 0.8815, precision: 0.9441, recall: 0.9036, f1: 0.9234, edges-ner-ontonotes_loss: 0.0262
09/16 06:35:09 AM: Update 11386: task edges-ner-ontonotes, batch 386 (11386): mcc: 0.9117, acc: 0.8711, precision: 0.9389, recall: 0.8946, f1: 0.9162, edges-ner-ontonotes_loss: 0.0284
09/16 06:35:12 AM: Update 11712: task edges-ner-ontonotes, batch 712 (11712): mcc: 0.9211, acc: 0.8839, precision: 0.9453, recall: 0.9059, f1: 0.9251, edges-ner-ontonotes_loss: 0.0255
09/16 06:35:20 AM: Update 11456: task edges-ner-ontonotes, batch 456 (11456): mcc: 0.9136, acc: 0.8741, precision: 0.9404, recall: 0.8967, f1: 0.9180, edges-ner-ontonotes_loss: 0.0279
09/16 06:35:22 AM: Update 11788: task edges-ner-ontonotes, batch 788 (11788): mcc: 0.9230, acc: 0.8863, precision: 0.9463, recall: 0.9084, f1: 0.9270, edges-ner-ontonotes_loss: 0.0250
09/16 06:35:30 AM: Update 11520: task edges-ner-ontonotes, batch 520 (11520): mcc: 0.9150, acc: 0.8761, precision: 0.9411, recall: 0.8985, f1: 0.9193, edges-ner-ontonotes_loss: 0.0276
09/16 06:35:32 AM: Update 11846: task edges-ner-ontonotes, batch 846 (11846): mcc: 0.9242, acc: 0.8877, precision: 0.9472, recall: 0.9098, f1: 0.9281, edges-ner-ontonotes_loss: 0.0246
09/16 06:35:40 AM: Update 11589: task edges-ner-ontonotes, batch 589 (11589): mcc: 0.9180, acc: 0.8799, precision: 0.9433, recall: 0.9021, f1: 0.9223, edges-ner-ontonotes_loss: 0.0267
09/16 06:35:42 AM: Update 11921: task edges-ner-ontonotes, batch 921 (11921): mcc: 0.9251, acc: 0.8887, precision: 0.9478, recall: 0.9109, f1: 0.9290, edges-ner-ontonotes_loss: 0.0243
09/16 06:35:50 AM: Update 11665: task edges-ner-ontonotes, batch 665 (11665): mcc: 0.9198, acc: 0.8823, precision: 0.9443, recall: 0.9045, f1: 0.9240, edges-ner-ontonotes_loss: 0.0260
09/16 06:35:54 AM: Update 11993: task edges-ner-ontonotes, batch 993 (11993): mcc: 0.9258, acc: 0.8898, precision: 0.9481, recall: 0.9119, f1: 0.9297, edges-ner-ontonotes_loss: 0.0241
09/16 06:35:55 AM: ***** Step 12000 / Validation 12 *****
09/16 06:35:55 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:35:55 AM: Validating...
09/16 06:36:00 AM: Update 11729: task edges-ner-ontonotes, batch 729 (11729): mcc: 0.9216, acc: 0.8846, precision: 0.9456, recall: 0.9065, f1: 0.9256, edges-ner-ontonotes_loss: 0.0254
09/16 06:36:04 AM: Evaluate: task edges-ner-ontonotes, batch 56 (157): mcc: 0.9084, acc: 0.8792, precision: 0.9241, recall: 0.9029, f1: 0.9134, edges-ner-ontonotes_loss: 0.0310
09/16 06:36:10 AM: Update 11786: task edges-ner-ontonotes, batch 786 (11786): mcc: 0.9230, acc: 0.8864, precision: 0.9463, recall: 0.9084, f1: 0.9270, edges-ner-ontonotes_loss: 0.0250
09/16 06:36:14 AM: Evaluate: task edges-ner-ontonotes, batch 110 (157): mcc: 0.9249, acc: 0.8965, precision: 0.9410, recall: 0.9172, f1: 0.9290, edges-ner-ontonotes_loss: 0.0256
09/16 06:36:22 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:36:22 AM: Best result seen so far for macro.
09/16 06:36:22 AM: Updating LR scheduler:
09/16 06:36:22 AM: 	Best result seen so far for macro_avg: 0.938
09/16 06:36:22 AM: 	# validation passes without improvement: 0
09/16 06:36:22 AM: edges-ner-ontonotes_loss: training: 0.024078 validation: 0.022187
09/16 06:36:22 AM: macro_avg: validation: 0.938082
09/16 06:36:22 AM: micro_avg: validation: 0.000000
09/16 06:36:22 AM: edges-ner-ontonotes_mcc: training: 0.925811 validation: 0.934549
09/16 06:36:22 AM: edges-ner-ontonotes_acc: training: 0.889772 validation: 0.908250
09/16 06:36:22 AM: edges-ner-ontonotes_precision: training: 0.948138 validation: 0.948740
09/16 06:36:22 AM: edges-ner-ontonotes_recall: training: 0.911901 validation: 0.927662
09/16 06:36:22 AM: edges-ner-ontonotes_f1: training: 0.929666 validation: 0.938082
09/16 06:36:22 AM: Global learning rate: 0.0001
09/16 06:36:22 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:36:22 AM: Update 11832: task edges-ner-ontonotes, batch 832 (11832): mcc: 0.9240, acc: 0.8876, precision: 0.9469, recall: 0.9098, f1: 0.9280, edges-ner-ontonotes_loss: 0.0246
09/16 06:36:24 AM: Update 12018: task edges-ner-ontonotes, batch 18 (12018): mcc: 0.9299, acc: 0.8939, precision: 0.9495, recall: 0.9183, f1: 0.9336, edges-ner-ontonotes_loss: 0.0212
09/16 06:36:33 AM: Update 11904: task edges-ner-ontonotes, batch 904 (11904): mcc: 0.9248, acc: 0.8883, precision: 0.9475, recall: 0.9107, f1: 0.9287, edges-ner-ontonotes_loss: 0.0243
09/16 06:36:34 AM: Update 12089: task edges-ner-ontonotes, batch 89 (12089): mcc: 0.9367, acc: 0.9046, precision: 0.9524, recall: 0.9281, f1: 0.9401, edges-ner-ontonotes_loss: 0.0203
09/16 06:36:43 AM: Update 11979: task edges-ner-ontonotes, batch 979 (11979): mcc: 0.9257, acc: 0.8896, precision: 0.9480, recall: 0.9117, f1: 0.9295, edges-ner-ontonotes_loss: 0.0241
09/16 06:36:45 AM: Update 12145: task edges-ner-ontonotes, batch 145 (12145): mcc: 0.9367, acc: 0.9040, precision: 0.9559, recall: 0.9247, f1: 0.9401, edges-ner-ontonotes_loss: 0.0204
09/16 06:36:46 AM: ***** Step 12000 / Validation 12 *****
09/16 06:36:46 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:36:46 AM: Validating...
09/16 06:36:53 AM: Evaluate: task edges-ner-ontonotes, batch 50 (157): mcc: 0.8981, acc: 0.8672, precision: 0.9159, recall: 0.8917, f1: 0.9036, edges-ner-ontonotes_loss: 0.0330
09/16 06:36:55 AM: Update 12207: task edges-ner-ontonotes, batch 207 (12207): mcc: 0.9249, acc: 0.8883, precision: 0.9481, recall: 0.9101, f1: 0.9287, edges-ner-ontonotes_loss: 0.0257
09/16 06:37:03 AM: Evaluate: task edges-ner-ontonotes, batch 103 (157): mcc: 0.9227, acc: 0.8936, precision: 0.9397, recall: 0.9143, f1: 0.9269, edges-ner-ontonotes_loss: 0.0264
09/16 06:37:05 AM: Update 12261: task edges-ner-ontonotes, batch 261 (12261): mcc: 0.9191, acc: 0.8818, precision: 0.9433, recall: 0.9041, f1: 0.9233, edges-ner-ontonotes_loss: 0.0278
09/16 06:37:13 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:37:13 AM: Best result seen so far for macro.
09/16 06:37:13 AM: Updating LR scheduler:
09/16 06:37:13 AM: 	Best result seen so far for macro_avg: 0.938
09/16 06:37:13 AM: 	# validation passes without improvement: 0
09/16 06:37:13 AM: edges-ner-ontonotes_loss: training: 0.024078 validation: 0.022187
09/16 06:37:13 AM: macro_avg: validation: 0.938082
09/16 06:37:13 AM: micro_avg: validation: 0.000000
09/16 06:37:13 AM: edges-ner-ontonotes_mcc: training: 0.925811 validation: 0.934549
09/16 06:37:13 AM: edges-ner-ontonotes_acc: training: 0.889772 validation: 0.908250
09/16 06:37:13 AM: edges-ner-ontonotes_precision: training: 0.948138 validation: 0.948740
09/16 06:37:13 AM: edges-ner-ontonotes_recall: training: 0.911901 validation: 0.927662
09/16 06:37:13 AM: edges-ner-ontonotes_f1: training: 0.929666 validation: 0.938082
09/16 06:37:13 AM: Global learning rate: 0.0001
09/16 06:37:13 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:37:14 AM: Update 12001: task edges-ner-ontonotes, batch 1 (12001): mcc: 0.9479, acc: 0.9341, precision: 0.9457, recall: 0.9560, f1: 0.9508, edges-ner-ontonotes_loss: 0.0178
09/16 06:37:17 AM: Update 12325: task edges-ner-ontonotes, batch 325 (12325): mcc: 0.9152, acc: 0.8764, precision: 0.9412, recall: 0.8989, f1: 0.9195, edges-ner-ontonotes_loss: 0.0293
09/16 06:37:24 AM: Update 12083: task edges-ner-ontonotes, batch 83 (12083): mcc: 0.9371, acc: 0.9050, precision: 0.9538, recall: 0.9276, f1: 0.9405, edges-ner-ontonotes_loss: 0.0202
09/16 06:37:28 AM: Update 12398: task edges-ner-ontonotes, batch 398 (12398): mcc: 0.9121, acc: 0.8721, precision: 0.9393, recall: 0.8950, f1: 0.9166, edges-ner-ontonotes_loss: 0.0307
09/16 06:37:35 AM: Update 12145: task edges-ner-ontonotes, batch 145 (12145): mcc: 0.9367, acc: 0.9040, precision: 0.9559, recall: 0.9247, f1: 0.9401, edges-ner-ontonotes_loss: 0.0204
09/16 06:37:38 AM: Update 12455: task edges-ner-ontonotes, batch 455 (12455): mcc: 0.9101, acc: 0.8694, precision: 0.9377, recall: 0.8927, f1: 0.9146, edges-ner-ontonotes_loss: 0.0313
09/16 06:37:45 AM: Update 12230: task edges-ner-ontonotes, batch 230 (12230): mcc: 0.9222, acc: 0.8854, precision: 0.9459, recall: 0.9074, f1: 0.9262, edges-ner-ontonotes_loss: 0.0269
09/16 06:37:49 AM: Update 12539: task edges-ner-ontonotes, batch 539 (12539): mcc: 0.9099, acc: 0.8691, precision: 0.9376, recall: 0.8925, f1: 0.9145, edges-ner-ontonotes_loss: 0.0311
09/16 06:37:55 AM: Update 12307: task edges-ner-ontonotes, batch 307 (12307): mcc: 0.9158, acc: 0.8775, precision: 0.9414, recall: 0.8999, f1: 0.9202, edges-ner-ontonotes_loss: 0.0291
09/16 06:37:59 AM: Update 12621: task edges-ner-ontonotes, batch 621 (12621): mcc: 0.9095, acc: 0.8686, precision: 0.9373, recall: 0.8921, f1: 0.9141, edges-ner-ontonotes_loss: 0.0309
09/16 06:38:05 AM: Update 12388: task edges-ner-ontonotes, batch 388 (12388): mcc: 0.9127, acc: 0.8728, precision: 0.9398, recall: 0.8955, f1: 0.9172, edges-ner-ontonotes_loss: 0.0305
09/16 06:38:09 AM: Update 12706: task edges-ner-ontonotes, batch 706 (12706): mcc: 0.9088, acc: 0.8675, precision: 0.9370, recall: 0.8910, f1: 0.9134, edges-ner-ontonotes_loss: 0.0310
09/16 06:38:16 AM: Update 12449: task edges-ner-ontonotes, batch 449 (12449): mcc: 0.9103, acc: 0.8697, precision: 0.9379, recall: 0.8929, f1: 0.9149, edges-ner-ontonotes_loss: 0.0312
09/16 06:38:19 AM: Update 12773: task edges-ner-ontonotes, batch 773 (12773): mcc: 0.9084, acc: 0.8671, precision: 0.9364, recall: 0.8909, f1: 0.9130, edges-ner-ontonotes_loss: 0.0310
09/16 06:38:26 AM: Update 12532: task edges-ner-ontonotes, batch 532 (12532): mcc: 0.9098, acc: 0.8690, precision: 0.9376, recall: 0.8923, f1: 0.9144, edges-ner-ontonotes_loss: 0.0311
09/16 06:38:29 AM: Update 12853: task edges-ner-ontonotes, batch 853 (12853): mcc: 0.9095, acc: 0.8685, precision: 0.9369, recall: 0.8924, f1: 0.9141, edges-ner-ontonotes_loss: 0.0304
09/16 06:38:36 AM: Update 12612: task edges-ner-ontonotes, batch 612 (12612): mcc: 0.9094, acc: 0.8684, precision: 0.9372, recall: 0.8920, f1: 0.9140, edges-ner-ontonotes_loss: 0.0310
09/16 06:38:39 AM: Update 12930: task edges-ner-ontonotes, batch 930 (12930): mcc: 0.9106, acc: 0.8699, precision: 0.9375, recall: 0.8938, f1: 0.9151, edges-ner-ontonotes_loss: 0.0300
09/16 06:38:46 AM: Update 12694: task edges-ner-ontonotes, batch 694 (12694): mcc: 0.9088, acc: 0.8677, precision: 0.9371, recall: 0.8910, f1: 0.9135, edges-ner-ontonotes_loss: 0.0310
09/16 06:38:48 AM: ***** Step 13000 / Validation 13 *****
09/16 06:38:48 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:38:48 AM: Validating...
09/16 06:38:49 AM: Evaluate: task edges-ner-ontonotes, batch 9 (157): mcc: 0.8472, acc: 0.7976, precision: 0.8852, recall: 0.8265, f1: 0.8549, edges-ner-ontonotes_loss: 0.0397
09/16 06:38:56 AM: Update 12760: task edges-ner-ontonotes, batch 760 (12760): mcc: 0.9086, acc: 0.8674, precision: 0.9367, recall: 0.8910, f1: 0.9133, edges-ner-ontonotes_loss: 0.0310
09/16 06:38:59 AM: Evaluate: task edges-ner-ontonotes, batch 75 (157): mcc: 0.9212, acc: 0.8918, precision: 0.9410, recall: 0.9103, f1: 0.9254, edges-ner-ontonotes_loss: 0.0269
09/16 06:39:06 AM: Update 12800: task edges-ner-ontonotes, batch 800 (12800): mcc: 0.9088, acc: 0.8676, precision: 0.9368, recall: 0.8912, f1: 0.9134, edges-ner-ontonotes_loss: 0.0308
09/16 06:39:09 AM: Evaluate: task edges-ner-ontonotes, batch 123 (157): mcc: 0.9306, acc: 0.9016, precision: 0.9496, recall: 0.9193, f1: 0.9342, edges-ner-ontonotes_loss: 0.0232
09/16 06:39:15 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:39:15 AM: Best result seen so far for macro.
09/16 06:39:16 AM: Update 12863: task edges-ner-ontonotes, batch 863 (12863): mcc: 0.9097, acc: 0.8687, precision: 0.9371, recall: 0.8926, f1: 0.9143, edges-ner-ontonotes_loss: 0.0303
09/16 06:39:18 AM: Updating LR scheduler:
09/16 06:39:18 AM: 	Best result seen so far for macro_avg: 0.939
09/16 06:39:18 AM: 	# validation passes without improvement: 0
09/16 06:39:18 AM: edges-ner-ontonotes_loss: training: 0.029541 validation: 0.021432
09/16 06:39:18 AM: macro_avg: validation: 0.939234
09/16 06:39:18 AM: micro_avg: validation: 0.000000
09/16 06:39:18 AM: edges-ner-ontonotes_mcc: training: 0.911793 validation: 0.935835
09/16 06:39:18 AM: edges-ner-ontonotes_acc: training: 0.871595 validation: 0.908857
09/16 06:39:18 AM: edges-ner-ontonotes_precision: training: 0.938366 validation: 0.953583
09/16 06:39:18 AM: edges-ner-ontonotes_recall: training: 0.895270 validation: 0.925311
09/16 06:39:18 AM: edges-ner-ontonotes_f1: training: 0.916311 validation: 0.939234
09/16 06:39:18 AM: Global learning rate: 0.0001
09/16 06:39:18 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:39:19 AM: Update 13009: task edges-ner-ontonotes, batch 9 (13009): mcc: 0.9430, acc: 0.9175, precision: 0.9678, recall: 0.9249, f1: 0.9458, edges-ner-ontonotes_loss: 0.0201
09/16 06:39:28 AM: Update 12934: task edges-ner-ontonotes, batch 934 (12934): mcc: 0.9106, acc: 0.8700, precision: 0.9375, recall: 0.8938, f1: 0.9152, edges-ner-ontonotes_loss: 0.0300
09/16 06:39:31 AM: Update 13075: task edges-ner-ontonotes, batch 75 (13075): mcc: 0.9242, acc: 0.8884, precision: 0.9470, recall: 0.9101, f1: 0.9282, edges-ner-ontonotes_loss: 0.0246
09/16 06:39:36 AM: ***** Step 13000 / Validation 13 *****
09/16 06:39:36 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:39:36 AM: Validating...
09/16 06:39:38 AM: Evaluate: task edges-ner-ontonotes, batch 13 (157): mcc: 0.8591, acc: 0.8153, precision: 0.8971, recall: 0.8372, f1: 0.8661, edges-ner-ontonotes_loss: 0.0380
09/16 06:39:41 AM: Update 13138: task edges-ner-ontonotes, batch 138 (13138): mcc: 0.9303, acc: 0.8948, precision: 0.9510, recall: 0.9175, f1: 0.9340, edges-ner-ontonotes_loss: 0.0223
09/16 06:39:48 AM: Evaluate: task edges-ner-ontonotes, batch 72 (157): mcc: 0.9197, acc: 0.8896, precision: 0.9394, recall: 0.9089, f1: 0.9239, edges-ner-ontonotes_loss: 0.0272
09/16 06:39:51 AM: Update 13193: task edges-ner-ontonotes, batch 193 (13193): mcc: 0.9323, acc: 0.8971, precision: 0.9529, recall: 0.9194, f1: 0.9359, edges-ner-ontonotes_loss: 0.0216
09/16 06:39:58 AM: Evaluate: task edges-ner-ontonotes, batch 122 (157): mcc: 0.9302, acc: 0.9011, precision: 0.9494, recall: 0.9188, f1: 0.9339, edges-ner-ontonotes_loss: 0.0233
09/16 06:40:01 AM: Update 13248: task edges-ner-ontonotes, batch 248 (13248): mcc: 0.9336, acc: 0.8989, precision: 0.9533, recall: 0.9214, f1: 0.9371, edges-ner-ontonotes_loss: 0.0211
09/16 06:40:05 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:40:05 AM: Best result seen so far for macro.
09/16 06:40:05 AM: Updating LR scheduler:
09/16 06:40:05 AM: 	Best result seen so far for macro_avg: 0.939
09/16 06:40:05 AM: 	# validation passes without improvement: 0
09/16 06:40:05 AM: edges-ner-ontonotes_loss: training: 0.029541 validation: 0.021432
09/16 06:40:05 AM: macro_avg: validation: 0.939234
09/16 06:40:05 AM: micro_avg: validation: 0.000000
09/16 06:40:05 AM: edges-ner-ontonotes_mcc: training: 0.911793 validation: 0.935835
09/16 06:40:05 AM: edges-ner-ontonotes_acc: training: 0.871595 validation: 0.908857
09/16 06:40:05 AM: edges-ner-ontonotes_precision: training: 0.938366 validation: 0.953583
09/16 06:40:05 AM: edges-ner-ontonotes_recall: training: 0.895270 validation: 0.925311
09/16 06:40:05 AM: edges-ner-ontonotes_f1: training: 0.916311 validation: 0.939234
09/16 06:40:05 AM: Global learning rate: 0.0001
09/16 06:40:05 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:40:09 AM: Update 13004: task edges-ner-ontonotes, batch 4 (13004): mcc: 0.9546, acc: 0.9269, precision: 0.9728, recall: 0.9415, f1: 0.9569, edges-ner-ontonotes_loss: 0.0149
09/16 06:40:11 AM: Update 13326: task edges-ner-ontonotes, batch 326 (13326): mcc: 0.9337, acc: 0.8992, precision: 0.9537, recall: 0.9213, f1: 0.9372, edges-ner-ontonotes_loss: 0.0209
09/16 06:40:20 AM: Update 13075: task edges-ner-ontonotes, batch 75 (13075): mcc: 0.9242, acc: 0.8884, precision: 0.9470, recall: 0.9101, f1: 0.9282, edges-ner-ontonotes_loss: 0.0246
09/16 06:40:21 AM: Update 13388: task edges-ner-ontonotes, batch 388 (13388): mcc: 0.9349, acc: 0.9009, precision: 0.9545, recall: 0.9227, f1: 0.9383, edges-ner-ontonotes_loss: 0.0206
09/16 06:40:30 AM: Update 13151: task edges-ner-ontonotes, batch 151 (13151): mcc: 0.9301, acc: 0.8944, precision: 0.9510, recall: 0.9171, f1: 0.9337, edges-ner-ontonotes_loss: 0.0223
09/16 06:40:31 AM: Update 13458: task edges-ner-ontonotes, batch 458 (13458): mcc: 0.9343, acc: 0.9000, precision: 0.9537, recall: 0.9223, f1: 0.9377, edges-ner-ontonotes_loss: 0.0207
09/16 06:40:40 AM: Update 13222: task edges-ner-ontonotes, batch 222 (13222): mcc: 0.9325, acc: 0.8978, precision: 0.9526, recall: 0.9201, f1: 0.9361, edges-ner-ontonotes_loss: 0.0215
09/16 06:40:41 AM: Update 13530: task edges-ner-ontonotes, batch 530 (13530): mcc: 0.9347, acc: 0.9004, precision: 0.9538, recall: 0.9229, f1: 0.9381, edges-ner-ontonotes_loss: 0.0206
09/16 06:40:50 AM: Update 13293: task edges-ner-ontonotes, batch 293 (13293): mcc: 0.9337, acc: 0.8994, precision: 0.9530, recall: 0.9219, f1: 0.9372, edges-ner-ontonotes_loss: 0.0210
09/16 06:40:51 AM: Update 13599: task edges-ner-ontonotes, batch 599 (13599): mcc: 0.9346, acc: 0.9001, precision: 0.9536, recall: 0.9229, f1: 0.9380, edges-ner-ontonotes_loss: 0.0206
09/16 06:41:00 AM: Update 13364: task edges-ner-ontonotes, batch 364 (13364): mcc: 0.9345, acc: 0.9004, precision: 0.9542, recall: 0.9222, f1: 0.9380, edges-ner-ontonotes_loss: 0.0207
09/16 06:41:01 AM: Update 13669: task edges-ner-ontonotes, batch 669 (13669): mcc: 0.9349, acc: 0.9006, precision: 0.9537, recall: 0.9234, f1: 0.9383, edges-ner-ontonotes_loss: 0.0205
09/16 06:41:10 AM: Update 13436: task edges-ner-ontonotes, batch 436 (13436): mcc: 0.9346, acc: 0.9004, precision: 0.9538, recall: 0.9228, f1: 0.9381, edges-ner-ontonotes_loss: 0.0207
09/16 06:41:11 AM: Update 13731: task edges-ner-ontonotes, batch 731 (13731): mcc: 0.9331, acc: 0.8984, precision: 0.9526, recall: 0.9211, f1: 0.9366, edges-ner-ontonotes_loss: 0.0212
09/16 06:41:20 AM: Update 13510: task edges-ner-ontonotes, batch 510 (13510): mcc: 0.9338, acc: 0.8992, precision: 0.9532, recall: 0.9219, f1: 0.9373, edges-ner-ontonotes_loss: 0.0208
09/16 06:41:21 AM: Update 13808: task edges-ner-ontonotes, batch 808 (13808): mcc: 0.9299, acc: 0.8943, precision: 0.9504, recall: 0.9173, f1: 0.9335, edges-ner-ontonotes_loss: 0.0227
09/16 06:41:33 AM: Update 13585: task edges-ner-ontonotes, batch 585 (13585): mcc: 0.9345, acc: 0.9001, precision: 0.9535, recall: 0.9228, f1: 0.9379, edges-ner-ontonotes_loss: 0.0206
09/16 06:41:33 AM: Update 13879: task edges-ner-ontonotes, batch 879 (13879): mcc: 0.9276, acc: 0.8916, precision: 0.9489, recall: 0.9145, f1: 0.9314, edges-ner-ontonotes_loss: 0.0237
09/16 06:41:43 AM: Update 13655: task edges-ner-ontonotes, batch 655 (13655): mcc: 0.9346, acc: 0.9003, precision: 0.9536, recall: 0.9231, f1: 0.9381, edges-ner-ontonotes_loss: 0.0206
09/16 06:41:43 AM: Update 13949: task edges-ner-ontonotes, batch 949 (13949): mcc: 0.9253, acc: 0.8886, precision: 0.9473, recall: 0.9117, f1: 0.9291, edges-ner-ontonotes_loss: 0.0248
09/16 06:41:52 AM: ***** Step 14000 / Validation 14 *****
09/16 06:41:52 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:41:52 AM: Validating...
09/16 06:41:55 AM: Update 13702: task edges-ner-ontonotes, batch 702 (13702): mcc: 0.9345, acc: 0.9001, precision: 0.9537, recall: 0.9227, f1: 0.9379, edges-ner-ontonotes_loss: 0.0206
09/16 06:41:55 AM: Evaluate: task edges-ner-ontonotes, batch 29 (157): mcc: 0.8860, acc: 0.8542, precision: 0.9007, recall: 0.8839, f1: 0.8922, edges-ner-ontonotes_loss: 0.0363
09/16 06:42:05 AM: Evaluate: task edges-ner-ontonotes, batch 86 (157): mcc: 0.9239, acc: 0.8957, precision: 0.9395, recall: 0.9168, f1: 0.9280, edges-ner-ontonotes_loss: 0.0263
09/16 06:42:05 AM: Update 13762: task edges-ner-ontonotes, batch 762 (13762): mcc: 0.9315, acc: 0.8965, precision: 0.9514, recall: 0.9194, f1: 0.9351, edges-ner-ontonotes_loss: 0.0219
09/16 06:42:18 AM: Update 13816: task edges-ner-ontonotes, batch 816 (13816): mcc: 0.9296, acc: 0.8941, precision: 0.9501, recall: 0.9171, f1: 0.9333, edges-ner-ontonotes_loss: 0.0228
09/16 06:42:18 AM: Evaluate: task edges-ner-ontonotes, batch 137 (157): mcc: 0.9326, acc: 0.9054, precision: 0.9490, recall: 0.9238, f1: 0.9362, edges-ner-ontonotes_loss: 0.0230
09/16 06:42:21 AM: Updating LR scheduler:
09/16 06:42:21 AM: 	Best result seen so far for macro_avg: 0.939
09/16 06:42:21 AM: 	# validation passes without improvement: 1
09/16 06:42:21 AM: edges-ner-ontonotes_loss: training: 0.025331 validation: 0.022212
09/16 06:42:21 AM: macro_avg: validation: 0.937742
09/16 06:42:21 AM: micro_avg: validation: 0.000000
09/16 06:42:21 AM: edges-ner-ontonotes_mcc: training: 0.924208 validation: 0.934219
09/16 06:42:21 AM: edges-ner-ontonotes_acc: training: 0.887222 validation: 0.907037
09/16 06:42:21 AM: edges-ner-ontonotes_precision: training: 0.946714 validation: 0.950113
09/16 06:42:21 AM: edges-ner-ontonotes_recall: training: 0.910296 validation: 0.925690
09/16 06:42:21 AM: edges-ner-ontonotes_f1: training: 0.928148 validation: 0.937742
09/16 06:42:21 AM: Global learning rate: 0.0001
09/16 06:42:21 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:42:28 AM: Update 14035: task edges-ner-ontonotes, batch 35 (14035): mcc: 0.9043, acc: 0.8590, precision: 0.9284, recall: 0.8909, f1: 0.9093, edges-ner-ontonotes_loss: 0.0306
09/16 06:42:28 AM: Update 13899: task edges-ner-ontonotes, batch 899 (13899): mcc: 0.9270, acc: 0.8910, precision: 0.9484, recall: 0.9139, f1: 0.9308, edges-ner-ontonotes_loss: 0.0240
09/16 06:42:38 AM: Update 13982: task edges-ner-ontonotes, batch 982 (13982): mcc: 0.9247, acc: 0.8879, precision: 0.9469, recall: 0.9110, f1: 0.9286, edges-ner-ontonotes_loss: 0.0251
09/16 06:42:38 AM: Update 14114: task edges-ner-ontonotes, batch 114 (14114): mcc: 0.9033, acc: 0.8584, precision: 0.9303, recall: 0.8872, f1: 0.9083, edges-ner-ontonotes_loss: 0.0307
09/16 06:42:40 AM: ***** Step 14000 / Validation 14 *****
09/16 06:42:40 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:42:40 AM: Validating...
09/16 06:42:48 AM: Evaluate: task edges-ner-ontonotes, batch 51 (157): mcc: 0.9087, acc: 0.8794, precision: 0.9226, recall: 0.9048, f1: 0.9136, edges-ner-ontonotes_loss: 0.0306
09/16 06:42:48 AM: Update 14181: task edges-ner-ontonotes, batch 181 (14181): mcc: 0.9055, acc: 0.8615, precision: 0.9332, recall: 0.8885, f1: 0.9103, edges-ner-ontonotes_loss: 0.0301
09/16 06:42:58 AM: Update 14242: task edges-ner-ontonotes, batch 242 (14242): mcc: 0.9063, acc: 0.8634, precision: 0.9335, recall: 0.8898, f1: 0.9111, edges-ner-ontonotes_loss: 0.0297
09/16 06:42:58 AM: Evaluate: task edges-ner-ontonotes, batch 108 (157): mcc: 0.9252, acc: 0.8961, precision: 0.9416, recall: 0.9173, f1: 0.9293, edges-ner-ontonotes_loss: 0.0252
09/16 06:43:07 AM: Updating LR scheduler:
09/16 06:43:07 AM: 	Best result seen so far for macro_avg: 0.939
09/16 06:43:07 AM: 	# validation passes without improvement: 1
09/16 06:43:07 AM: edges-ner-ontonotes_loss: training: 0.025331 validation: 0.022212
09/16 06:43:07 AM: macro_avg: validation: 0.937742
09/16 06:43:07 AM: micro_avg: validation: 0.000000
09/16 06:43:07 AM: edges-ner-ontonotes_mcc: training: 0.924208 validation: 0.934219
09/16 06:43:07 AM: edges-ner-ontonotes_acc: training: 0.887222 validation: 0.907037
09/16 06:43:07 AM: edges-ner-ontonotes_precision: training: 0.946714 validation: 0.950113
09/16 06:43:07 AM: edges-ner-ontonotes_recall: training: 0.910296 validation: 0.925690
09/16 06:43:07 AM: edges-ner-ontonotes_f1: training: 0.928148 validation: 0.937742
09/16 06:43:07 AM: Global learning rate: 0.0001
09/16 06:43:07 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:43:08 AM: Update 14308: task edges-ner-ontonotes, batch 308 (14308): mcc: 0.9058, acc: 0.8630, precision: 0.9333, recall: 0.8891, f1: 0.9106, edges-ner-ontonotes_loss: 0.0301
09/16 06:43:09 AM: Update 14001: task edges-ner-ontonotes, batch 1 (14001): mcc: 0.9398, acc: 0.8889, precision: 0.9800, recall: 0.9074, f1: 0.9423, edges-ner-ontonotes_loss: 0.0216
09/16 06:43:18 AM: Update 14370: task edges-ner-ontonotes, batch 370 (14370): mcc: 0.9073, acc: 0.8648, precision: 0.9338, recall: 0.8913, f1: 0.9120, edges-ner-ontonotes_loss: 0.0296
09/16 06:43:19 AM: Update 14065: task edges-ner-ontonotes, batch 65 (14065): mcc: 0.9002, acc: 0.8546, precision: 0.9289, recall: 0.8829, f1: 0.9053, edges-ner-ontonotes_loss: 0.0313
09/16 06:43:28 AM: Update 14451: task edges-ner-ontonotes, batch 451 (14451): mcc: 0.9105, acc: 0.8696, precision: 0.9361, recall: 0.8949, f1: 0.9151, edges-ner-ontonotes_loss: 0.0288
09/16 06:43:30 AM: Update 14148: task edges-ner-ontonotes, batch 148 (14148): mcc: 0.9045, acc: 0.8607, precision: 0.9316, recall: 0.8882, f1: 0.9094, edges-ner-ontonotes_loss: 0.0303
09/16 06:43:38 AM: Update 14527: task edges-ner-ontonotes, batch 527 (14527): mcc: 0.9122, acc: 0.8721, precision: 0.9371, recall: 0.8972, f1: 0.9167, edges-ner-ontonotes_loss: 0.0282
09/16 06:43:40 AM: Update 14236: task edges-ner-ontonotes, batch 236 (14236): mcc: 0.9054, acc: 0.8619, precision: 0.9330, recall: 0.8886, f1: 0.9102, edges-ner-ontonotes_loss: 0.0300
09/16 06:43:49 AM: Update 14605: task edges-ner-ontonotes, batch 605 (14605): mcc: 0.9152, acc: 0.8758, precision: 0.9395, recall: 0.9005, f1: 0.9196, edges-ner-ontonotes_loss: 0.0274
09/16 06:43:52 AM: Update 14318: task edges-ner-ontonotes, batch 318 (14318): mcc: 0.9058, acc: 0.8629, precision: 0.9328, recall: 0.8894, f1: 0.9106, edges-ner-ontonotes_loss: 0.0300
09/16 06:44:00 AM: Update 14662: task edges-ner-ontonotes, batch 662 (14662): mcc: 0.9164, acc: 0.8774, precision: 0.9405, recall: 0.9018, f1: 0.9207, edges-ner-ontonotes_loss: 0.0271
09/16 06:44:02 AM: Update 14396: task edges-ner-ontonotes, batch 396 (14396): mcc: 0.9078, acc: 0.8660, precision: 0.9341, recall: 0.8920, f1: 0.9126, edges-ner-ontonotes_loss: 0.0295
09/16 06:44:10 AM: Update 14737: task edges-ner-ontonotes, batch 737 (14737): mcc: 0.9194, acc: 0.8812, precision: 0.9428, recall: 0.9051, f1: 0.9235, edges-ner-ontonotes_loss: 0.0262
09/16 06:44:13 AM: Update 14470: task edges-ner-ontonotes, batch 470 (14470): mcc: 0.9112, acc: 0.8706, precision: 0.9367, recall: 0.8958, f1: 0.9158, edges-ner-ontonotes_loss: 0.0285
09/16 06:44:20 AM: Update 14810: task edges-ner-ontonotes, batch 810 (14810): mcc: 0.9215, acc: 0.8841, precision: 0.9443, recall: 0.9076, f1: 0.9256, edges-ner-ontonotes_loss: 0.0256
09/16 06:44:23 AM: Update 14557: task edges-ner-ontonotes, batch 557 (14557): mcc: 0.9135, acc: 0.8738, precision: 0.9382, recall: 0.8986, f1: 0.9180, edges-ner-ontonotes_loss: 0.0278
09/16 06:44:34 AM: Update 14628: task edges-ner-ontonotes, batch 628 (14628): mcc: 0.9155, acc: 0.8763, precision: 0.9397, recall: 0.9009, f1: 0.9199, edges-ner-ontonotes_loss: 0.0274
09/16 06:44:34 AM: Update 14883: task edges-ner-ontonotes, batch 883 (14883): mcc: 0.9234, acc: 0.8868, precision: 0.9457, recall: 0.9098, f1: 0.9274, edges-ner-ontonotes_loss: 0.0250
09/16 06:44:44 AM: Update 14686: task edges-ner-ontonotes, batch 686 (14686): mcc: 0.9173, acc: 0.8786, precision: 0.9411, recall: 0.9029, f1: 0.9216, edges-ner-ontonotes_loss: 0.0268
09/16 06:44:44 AM: Update 14949: task edges-ner-ontonotes, batch 949 (14949): mcc: 0.9246, acc: 0.8882, precision: 0.9464, recall: 0.9114, f1: 0.9285, edges-ner-ontonotes_loss: 0.0246
09/16 06:44:52 AM: ***** Step 15000 / Validation 15 *****
09/16 06:44:52 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:44:52 AM: Validating...
09/16 06:44:54 AM: Update 14758: task edges-ner-ontonotes, batch 758 (14758): mcc: 0.9198, acc: 0.8818, precision: 0.9431, recall: 0.9056, f1: 0.9240, edges-ner-ontonotes_loss: 0.0261
09/16 06:44:54 AM: Evaluate: task edges-ner-ontonotes, batch 10 (157): mcc: 0.8525, acc: 0.8059, precision: 0.8943, recall: 0.8276, f1: 0.8597, edges-ner-ontonotes_loss: 0.0410
09/16 06:45:04 AM: Update 14817: task edges-ner-ontonotes, batch 817 (14817): mcc: 0.9218, acc: 0.8844, precision: 0.9445, recall: 0.9079, f1: 0.9258, edges-ner-ontonotes_loss: 0.0255
09/16 06:45:04 AM: Evaluate: task edges-ner-ontonotes, batch 69 (157): mcc: 0.9175, acc: 0.8873, precision: 0.9376, recall: 0.9066, f1: 0.9219, edges-ner-ontonotes_loss: 0.0294
09/16 06:45:14 AM: Update 14873: task edges-ner-ontonotes, batch 873 (14873): mcc: 0.9232, acc: 0.8864, precision: 0.9456, recall: 0.9096, f1: 0.9272, edges-ner-ontonotes_loss: 0.0250
09/16 06:45:14 AM: Evaluate: task edges-ner-ontonotes, batch 119 (157): mcc: 0.9304, acc: 0.9016, precision: 0.9485, recall: 0.9201, f1: 0.9341, edges-ner-ontonotes_loss: 0.0243
09/16 06:45:21 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:45:21 AM: Best result seen so far for macro.
09/16 06:45:21 AM: Updating LR scheduler:
09/16 06:45:21 AM: 	Best result seen so far for macro_avg: 0.941
09/16 06:45:21 AM: 	# validation passes without improvement: 0
09/16 06:45:21 AM: edges-ner-ontonotes_loss: training: 0.024473 validation: 0.021717
09/16 06:45:21 AM: macro_avg: validation: 0.941149
09/16 06:45:21 AM: micro_avg: validation: 0.000000
09/16 06:45:21 AM: edges-ner-ontonotes_mcc: training: 0.924905 validation: 0.937816
09/16 06:45:21 AM: edges-ner-ontonotes_acc: training: 0.888531 validation: 0.911890
09/16 06:45:21 AM: edges-ner-ontonotes_precision: training: 0.946427 validation: 0.953114
09/16 06:45:21 AM: edges-ner-ontonotes_recall: training: 0.911876 validation: 0.929481
09/16 06:45:21 AM: edges-ner-ontonotes_f1: training: 0.928830 validation: 0.941149
09/16 06:45:21 AM: Global learning rate: 0.0001
09/16 06:45:21 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:45:24 AM: Update 14932: task edges-ner-ontonotes, batch 932 (14932): mcc: 0.9245, acc: 0.8881, precision: 0.9463, recall: 0.9113, f1: 0.9284, edges-ner-ontonotes_loss: 0.0247
09/16 06:45:24 AM: Update 15022: task edges-ner-ontonotes, batch 22 (15022): mcc: 0.9384, acc: 0.9048, precision: 0.9556, recall: 0.9281, f1: 0.9416, edges-ner-ontonotes_loss: 0.0205
09/16 06:45:34 AM: Update 14988: task edges-ner-ontonotes, batch 988 (14988): mcc: 0.9247, acc: 0.8883, precision: 0.9463, recall: 0.9116, f1: 0.9286, edges-ner-ontonotes_loss: 0.0245
09/16 06:45:34 AM: Update 15105: task edges-ner-ontonotes, batch 105 (15105): mcc: 0.9361, acc: 0.9034, precision: 0.9530, recall: 0.9264, f1: 0.9395, edges-ner-ontonotes_loss: 0.0204
09/16 06:45:36 AM: ***** Step 15000 / Validation 15 *****
09/16 06:45:36 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:45:36 AM: Validating...
09/16 06:45:44 AM: Evaluate: task edges-ner-ontonotes, batch 52 (157): mcc: 0.9077, acc: 0.8780, precision: 0.9281, recall: 0.8976, f1: 0.9126, edges-ner-ontonotes_loss: 0.0317
09/16 06:45:45 AM: Update 15165: task edges-ner-ontonotes, batch 165 (15165): mcc: 0.9346, acc: 0.9006, precision: 0.9522, recall: 0.9243, f1: 0.9381, edges-ner-ontonotes_loss: 0.0206
09/16 06:45:54 AM: Evaluate: task edges-ner-ontonotes, batch 105 (157): mcc: 0.9276, acc: 0.8991, precision: 0.9462, recall: 0.9172, f1: 0.9315, edges-ner-ontonotes_loss: 0.0255
09/16 06:45:55 AM: Update 15219: task edges-ner-ontonotes, batch 219 (15219): mcc: 0.9353, acc: 0.9016, precision: 0.9531, recall: 0.9247, f1: 0.9387, edges-ner-ontonotes_loss: 0.0204
09/16 06:46:04 AM: Evaluate: task edges-ner-ontonotes, batch 157 (157): mcc: 0.9378, acc: 0.9119, precision: 0.9531, recall: 0.9295, f1: 0.9411, edges-ner-ontonotes_loss: 0.0217
09/16 06:46:04 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:46:04 AM: Best result seen so far for macro.
09/16 06:46:04 AM: Updating LR scheduler:
09/16 06:46:04 AM: 	Best result seen so far for macro_avg: 0.941
09/16 06:46:04 AM: 	# validation passes without improvement: 0
09/16 06:46:04 AM: edges-ner-ontonotes_loss: training: 0.024473 validation: 0.021717
09/16 06:46:04 AM: macro_avg: validation: 0.941149
09/16 06:46:04 AM: micro_avg: validation: 0.000000
09/16 06:46:04 AM: edges-ner-ontonotes_mcc: training: 0.924905 validation: 0.937816
09/16 06:46:04 AM: edges-ner-ontonotes_acc: training: 0.888531 validation: 0.911890
09/16 06:46:04 AM: edges-ner-ontonotes_precision: training: 0.946427 validation: 0.953114
09/16 06:46:04 AM: edges-ner-ontonotes_recall: training: 0.911876 validation: 0.929481
09/16 06:46:04 AM: edges-ner-ontonotes_f1: training: 0.928830 validation: 0.941149
09/16 06:46:04 AM: Global learning rate: 0.0001
09/16 06:46:04 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:46:05 AM: Update 15261: task edges-ner-ontonotes, batch 261 (15261): mcc: 0.9339, acc: 0.8999, precision: 0.9522, recall: 0.9231, f1: 0.9374, edges-ner-ontonotes_loss: 0.0204
09/16 06:46:14 AM: Update 15068: task edges-ner-ontonotes, batch 68 (15068): mcc: 0.9374, acc: 0.9049, precision: 0.9548, recall: 0.9271, f1: 0.9408, edges-ner-ontonotes_loss: 0.0207
09/16 06:46:15 AM: Update 15331: task edges-ner-ontonotes, batch 331 (15331): mcc: 0.9274, acc: 0.8912, precision: 0.9483, recall: 0.9147, f1: 0.9312, edges-ner-ontonotes_loss: 0.0233
09/16 06:46:25 AM: Update 15143: task edges-ner-ontonotes, batch 143 (15143): mcc: 0.9353, acc: 0.9020, precision: 0.9530, recall: 0.9250, f1: 0.9388, edges-ner-ontonotes_loss: 0.0204
09/16 06:46:25 AM: Update 15407: task edges-ner-ontonotes, batch 407 (15407): mcc: 0.9229, acc: 0.8853, precision: 0.9454, recall: 0.9091, f1: 0.9269, edges-ner-ontonotes_loss: 0.0256
09/16 06:46:37 AM: Update 15212: task edges-ner-ontonotes, batch 212 (15212): mcc: 0.9358, acc: 0.9024, precision: 0.9533, recall: 0.9254, f1: 0.9392, edges-ner-ontonotes_loss: 0.0203
09/16 06:46:37 AM: Update 15481: task edges-ner-ontonotes, batch 481 (15481): mcc: 0.9194, acc: 0.8813, precision: 0.9429, recall: 0.9050, f1: 0.9236, edges-ner-ontonotes_loss: 0.0272
09/16 06:46:47 AM: Update 15264: task edges-ner-ontonotes, batch 264 (15264): mcc: 0.9336, acc: 0.8994, precision: 0.9521, recall: 0.9226, f1: 0.9371, edges-ner-ontonotes_loss: 0.0207
09/16 06:46:49 AM: Update 15561: task edges-ner-ontonotes, batch 561 (15561): mcc: 0.9164, acc: 0.8776, precision: 0.9412, recall: 0.9011, f1: 0.9207, edges-ner-ontonotes_loss: 0.0287
09/16 06:46:57 AM: Update 15347: task edges-ner-ontonotes, batch 347 (15347): mcc: 0.9257, acc: 0.8889, precision: 0.9471, recall: 0.9126, f1: 0.9295, edges-ner-ontonotes_loss: 0.0243
09/16 06:47:00 AM: Update 15646: task edges-ner-ontonotes, batch 646 (15646): mcc: 0.9149, acc: 0.8761, precision: 0.9396, recall: 0.8999, f1: 0.9193, edges-ner-ontonotes_loss: 0.0290
09/16 06:47:07 AM: Update 15427: task edges-ner-ontonotes, batch 427 (15427): mcc: 0.9221, acc: 0.8846, precision: 0.9448, recall: 0.9082, f1: 0.9261, edges-ner-ontonotes_loss: 0.0259
09/16 06:47:10 AM: Update 15732: task edges-ner-ontonotes, batch 732 (15732): mcc: 0.9139, acc: 0.8748, precision: 0.9389, recall: 0.8987, f1: 0.9183, edges-ner-ontonotes_loss: 0.0291
09/16 06:47:18 AM: Update 15519: task edges-ner-ontonotes, batch 519 (15519): mcc: 0.9177, acc: 0.8791, precision: 0.9418, recall: 0.9029, f1: 0.9219, edges-ner-ontonotes_loss: 0.0281
09/16 06:47:23 AM: Update 15814: task edges-ner-ontonotes, batch 814 (15814): mcc: 0.9136, acc: 0.8744, precision: 0.9387, recall: 0.8983, f1: 0.9180, edges-ner-ontonotes_loss: 0.0292
09/16 06:47:28 AM: Update 15591: task edges-ner-ontonotes, batch 591 (15591): mcc: 0.9156, acc: 0.8768, precision: 0.9403, recall: 0.9005, f1: 0.9200, edges-ner-ontonotes_loss: 0.0289
09/16 06:47:34 AM: Update 15877: task edges-ner-ontonotes, batch 877 (15877): mcc: 0.9131, acc: 0.8737, precision: 0.9385, recall: 0.8976, f1: 0.9176, edges-ner-ontonotes_loss: 0.0291
09/16 06:47:38 AM: Update 15693: task edges-ner-ontonotes, batch 693 (15693): mcc: 0.9147, acc: 0.8758, precision: 0.9394, recall: 0.8997, f1: 0.9191, edges-ner-ontonotes_loss: 0.0290
09/16 06:47:45 AM: Update 15959: task edges-ner-ontonotes, batch 959 (15959): mcc: 0.9137, acc: 0.8747, precision: 0.9389, recall: 0.8983, f1: 0.9182, edges-ner-ontonotes_loss: 0.0288
09/16 06:47:49 AM: Update 15785: task edges-ner-ontonotes, batch 785 (15785): mcc: 0.9136, acc: 0.8745, precision: 0.9389, recall: 0.8981, f1: 0.9181, edges-ner-ontonotes_loss: 0.0292
09/16 06:47:52 AM: ***** Step 16000 / Validation 16 *****
09/16 06:47:52 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:47:52 AM: Validating...
09/16 06:47:56 AM: Evaluate: task edges-ner-ontonotes, batch 31 (157): mcc: 0.8944, acc: 0.8643, precision: 0.9161, recall: 0.8844, f1: 0.9000, edges-ner-ontonotes_loss: 0.0341
09/16 06:47:59 AM: Update 15863: task edges-ner-ontonotes, batch 863 (15863): mcc: 0.9133, acc: 0.8742, precision: 0.9385, recall: 0.8980, f1: 0.9178, edges-ner-ontonotes_loss: 0.0291
09/16 06:48:08 AM: Evaluate: task edges-ner-ontonotes, batch 98 (157): mcc: 0.9315, acc: 0.9051, precision: 0.9486, recall: 0.9221, f1: 0.9351, edges-ner-ontonotes_loss: 0.0241
09/16 06:48:09 AM: Update 15904: task edges-ner-ontonotes, batch 904 (15904): mcc: 0.9132, acc: 0.8739, precision: 0.9386, recall: 0.8977, f1: 0.9177, edges-ner-ontonotes_loss: 0.0291
09/16 06:48:18 AM: Evaluate: task edges-ner-ontonotes, batch 150 (157): mcc: 0.9369, acc: 0.9107, precision: 0.9536, recall: 0.9272, f1: 0.9402, edges-ner-ontonotes_loss: 0.0214
09/16 06:48:19 AM: Update 15966: task edges-ner-ontonotes, batch 966 (15966): mcc: 0.9139, acc: 0.8750, precision: 0.9391, recall: 0.8985, f1: 0.9183, edges-ner-ontonotes_loss: 0.0288
09/16 06:48:21 AM: Updating LR scheduler:
09/16 06:48:21 AM: 	Best result seen so far for macro_avg: 0.941
09/16 06:48:21 AM: 	# validation passes without improvement: 1
09/16 06:48:21 AM: edges-ner-ontonotes_loss: training: 0.028539 validation: 0.021012
09/16 06:48:21 AM: macro_avg: validation: 0.940842
09/16 06:48:21 AM: micro_avg: validation: 0.000000
09/16 06:48:21 AM: edges-ner-ontonotes_mcc: training: 0.914482 validation: 0.937514
09/16 06:48:21 AM: edges-ner-ontonotes_acc: training: 0.875697 validation: 0.911738
09/16 06:48:21 AM: edges-ner-ontonotes_precision: training: 0.939544 validation: 0.954081
09/16 06:48:21 AM: edges-ner-ontonotes_recall: training: 0.899135 validation: 0.927965
09/16 06:48:21 AM: edges-ner-ontonotes_f1: training: 0.918895 validation: 0.940842
09/16 06:48:21 AM: Global learning rate: 0.0001
09/16 06:48:21 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:48:25 AM: ***** Step 16000 / Validation 16 *****
09/16 06:48:25 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:48:25 AM: Validating...
09/16 06:48:30 AM: Evaluate: task edges-ner-ontonotes, batch 32 (157): mcc: 0.8975, acc: 0.8684, precision: 0.9187, recall: 0.8877, f1: 0.9029, edges-ner-ontonotes_loss: 0.0333
09/16 06:48:30 AM: Update 16058: task edges-ner-ontonotes, batch 58 (16058): mcc: 0.9214, acc: 0.8842, precision: 0.9461, recall: 0.9056, f1: 0.9254, edges-ner-ontonotes_loss: 0.0243
09/16 06:48:40 AM: Evaluate: task edges-ner-ontonotes, batch 85 (157): mcc: 0.9286, acc: 0.9016, precision: 0.9456, recall: 0.9197, f1: 0.9325, edges-ner-ontonotes_loss: 0.0250
09/16 06:48:40 AM: Update 16111: task edges-ner-ontonotes, batch 111 (16111): mcc: 0.9187, acc: 0.8822, precision: 0.9419, recall: 0.9047, f1: 0.9229, edges-ner-ontonotes_loss: 0.0259
09/16 06:48:53 AM: Evaluate: task edges-ner-ontonotes, batch 136 (157): mcc: 0.9366, acc: 0.9103, precision: 0.9532, recall: 0.9271, f1: 0.9399, edges-ner-ontonotes_loss: 0.0217
09/16 06:48:53 AM: Update 16168: task edges-ner-ontonotes, batch 168 (16168): mcc: 0.9201, acc: 0.8836, precision: 0.9429, recall: 0.9064, f1: 0.9243, edges-ner-ontonotes_loss: 0.0254
09/16 06:48:57 AM: Updating LR scheduler:
09/16 06:48:57 AM: 	Best result seen so far for macro_avg: 0.941
09/16 06:48:57 AM: 	# validation passes without improvement: 1
09/16 06:48:57 AM: edges-ner-ontonotes_loss: training: 0.028539 validation: 0.021012
09/16 06:48:57 AM: macro_avg: validation: 0.940842
09/16 06:48:57 AM: micro_avg: validation: 0.000000
09/16 06:48:57 AM: edges-ner-ontonotes_mcc: training: 0.914482 validation: 0.937514
09/16 06:48:57 AM: edges-ner-ontonotes_acc: training: 0.875697 validation: 0.911738
09/16 06:48:57 AM: edges-ner-ontonotes_precision: training: 0.939544 validation: 0.954081
09/16 06:48:57 AM: edges-ner-ontonotes_recall: training: 0.899135 validation: 0.927965
09/16 06:48:57 AM: edges-ner-ontonotes_f1: training: 0.918895 validation: 0.940842
09/16 06:48:57 AM: Global learning rate: 0.0001
09/16 06:48:57 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:49:04 AM: Update 16218: task edges-ner-ontonotes, batch 218 (16218): mcc: 0.9231, acc: 0.8865, precision: 0.9443, recall: 0.9106, f1: 0.9272, edges-ner-ontonotes_loss: 0.0243
09/16 06:49:04 AM: Update 16042: task edges-ner-ontonotes, batch 42 (16042): mcc: 0.9238, acc: 0.8869, precision: 0.9481, recall: 0.9082, f1: 0.9277, edges-ner-ontonotes_loss: 0.0234
09/16 06:49:15 AM: Update 16294: task edges-ner-ontonotes, batch 294 (16294): mcc: 0.9263, acc: 0.8908, precision: 0.9462, recall: 0.9146, f1: 0.9302, edges-ner-ontonotes_loss: 0.0232
09/16 06:49:15 AM: Update 16111: task edges-ner-ontonotes, batch 111 (16111): mcc: 0.9187, acc: 0.8822, precision: 0.9419, recall: 0.9047, f1: 0.9229, edges-ner-ontonotes_loss: 0.0259
09/16 06:49:25 AM: Update 16370: task edges-ner-ontonotes, batch 370 (16370): mcc: 0.9297, acc: 0.8951, precision: 0.9485, recall: 0.9187, f1: 0.9334, edges-ner-ontonotes_loss: 0.0222
09/16 06:49:25 AM: Update 16186: task edges-ner-ontonotes, batch 186 (16186): mcc: 0.9207, acc: 0.8842, precision: 0.9429, recall: 0.9074, f1: 0.9248, edges-ner-ontonotes_loss: 0.0251
09/16 06:49:35 AM: Update 16446: task edges-ner-ontonotes, batch 446 (16446): mcc: 0.9318, acc: 0.8977, precision: 0.9506, recall: 0.9207, f1: 0.9354, edges-ner-ontonotes_loss: 0.0216
09/16 06:49:35 AM: Update 16236: task edges-ner-ontonotes, batch 236 (16236): mcc: 0.9247, acc: 0.8889, precision: 0.9453, recall: 0.9125, f1: 0.9286, edges-ner-ontonotes_loss: 0.0238
09/16 06:49:45 AM: Update 16319: task edges-ner-ontonotes, batch 319 (16319): mcc: 0.9277, acc: 0.8924, precision: 0.9472, recall: 0.9163, f1: 0.9315, edges-ner-ontonotes_loss: 0.0228
09/16 06:49:47 AM: Update 16500: task edges-ner-ontonotes, batch 500 (16500): mcc: 0.9330, acc: 0.8990, precision: 0.9514, recall: 0.9221, f1: 0.9365, edges-ner-ontonotes_loss: 0.0213
09/16 06:49:56 AM: Update 16399: task edges-ner-ontonotes, batch 399 (16399): mcc: 0.9305, acc: 0.8959, precision: 0.9494, recall: 0.9194, f1: 0.9342, edges-ner-ontonotes_loss: 0.0219
09/16 06:49:57 AM: Update 16570: task edges-ner-ontonotes, batch 570 (16570): mcc: 0.9333, acc: 0.8995, precision: 0.9516, recall: 0.9225, f1: 0.9368, edges-ner-ontonotes_loss: 0.0211
09/16 06:50:06 AM: Update 16469: task edges-ner-ontonotes, batch 469 (16469): mcc: 0.9325, acc: 0.8985, precision: 0.9509, recall: 0.9216, f1: 0.9360, edges-ner-ontonotes_loss: 0.0214
09/16 06:50:07 AM: Update 16638: task edges-ner-ontonotes, batch 638 (16638): mcc: 0.9342, acc: 0.9007, precision: 0.9522, recall: 0.9236, f1: 0.9377, edges-ner-ontonotes_loss: 0.0209
09/16 06:50:16 AM: Update 16517: task edges-ner-ontonotes, batch 517 (16517): mcc: 0.9331, acc: 0.8991, precision: 0.9515, recall: 0.9223, f1: 0.9366, edges-ner-ontonotes_loss: 0.0212
09/16 06:50:17 AM: Update 16716: task edges-ner-ontonotes, batch 716 (16716): mcc: 0.9343, acc: 0.9006, precision: 0.9526, recall: 0.9233, f1: 0.9377, edges-ner-ontonotes_loss: 0.0209
09/16 06:50:26 AM: Update 16590: task edges-ner-ontonotes, batch 590 (16590): mcc: 0.9336, acc: 0.9001, precision: 0.9518, recall: 0.9229, f1: 0.9371, edges-ner-ontonotes_loss: 0.0210
09/16 06:50:28 AM: Update 16787: task edges-ner-ontonotes, batch 787 (16787): mcc: 0.9347, acc: 0.9014, precision: 0.9529, recall: 0.9239, f1: 0.9382, edges-ner-ontonotes_loss: 0.0207
09/16 06:50:36 AM: Update 16665: task edges-ner-ontonotes, batch 665 (16665): mcc: 0.9341, acc: 0.9006, precision: 0.9523, recall: 0.9234, f1: 0.9376, edges-ner-ontonotes_loss: 0.0209
09/16 06:50:38 AM: Update 16846: task edges-ner-ontonotes, batch 846 (16846): mcc: 0.9331, acc: 0.8993, precision: 0.9518, recall: 0.9220, f1: 0.9367, edges-ner-ontonotes_loss: 0.0212
09/16 06:50:46 AM: Update 16736: task edges-ner-ontonotes, batch 736 (16736): mcc: 0.9344, acc: 0.9008, precision: 0.9527, recall: 0.9235, f1: 0.9379, edges-ner-ontonotes_loss: 0.0209
09/16 06:50:48 AM: Update 16915: task edges-ner-ontonotes, batch 915 (16915): mcc: 0.9307, acc: 0.8963, precision: 0.9502, recall: 0.9190, f1: 0.9343, edges-ner-ontonotes_loss: 0.0224
09/16 06:50:56 AM: Update 16809: task edges-ner-ontonotes, batch 809 (16809): mcc: 0.9348, acc: 0.9015, precision: 0.9529, recall: 0.9239, f1: 0.9382, edges-ner-ontonotes_loss: 0.0207
09/16 06:50:58 AM: Update 16991: task edges-ner-ontonotes, batch 991 (16991): mcc: 0.9285, acc: 0.8935, precision: 0.9489, recall: 0.9163, f1: 0.9323, edges-ner-ontonotes_loss: 0.0233
09/16 06:51:00 AM: ***** Step 17000 / Validation 17 *****
09/16 06:51:00 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:51:00 AM: Validating...
09/16 06:51:06 AM: Update 16854: task edges-ner-ontonotes, batch 854 (16854): mcc: 0.9330, acc: 0.8991, precision: 0.9518, recall: 0.9218, f1: 0.9365, edges-ner-ontonotes_loss: 0.0213
09/16 06:51:09 AM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.9103, acc: 0.8802, precision: 0.9250, recall: 0.9056, f1: 0.9152, edges-ner-ontonotes_loss: 0.0306
09/16 06:51:16 AM: Update 16912: task edges-ner-ontonotes, batch 912 (16912): mcc: 0.9307, acc: 0.8963, precision: 0.9502, recall: 0.9191, f1: 0.9344, edges-ner-ontonotes_loss: 0.0223
09/16 06:51:19 AM: Evaluate: task edges-ner-ontonotes, batch 108 (157): mcc: 0.9239, acc: 0.8933, precision: 0.9416, recall: 0.9146, f1: 0.9279, edges-ner-ontonotes_loss: 0.0257
09/16 06:51:26 AM: Update 16978: task edges-ner-ontonotes, batch 978 (16978): mcc: 0.9291, acc: 0.8942, precision: 0.9493, recall: 0.9169, f1: 0.9329, edges-ner-ontonotes_loss: 0.0231
09/16 06:51:30 AM: ***** Step 17000 / Validation 17 *****
09/16 06:51:30 AM: Updating LR scheduler:
09/16 06:51:32 AM: 	Best result seen so far for macro_avg: 0.941
09/16 06:51:32 AM: 	# validation passes without improvement: 2
09/16 06:51:32 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:51:32 AM: edges-ner-ontonotes_loss: training: 0.023447 validation: 0.022428
09/16 06:51:32 AM: Validating...
09/16 06:51:32 AM: macro_avg: validation: 0.936510
09/16 06:51:32 AM: micro_avg: validation: 0.000000
09/16 06:51:32 AM: edges-ner-ontonotes_mcc: training: 0.928351 validation: 0.932927
09/16 06:51:32 AM: edges-ner-ontonotes_acc: training: 0.893248 validation: 0.905293
09/16 06:51:32 AM: edges-ner-ontonotes_precision: training: 0.948763 validation: 0.949501
09/16 06:51:32 AM: edges-ner-ontonotes_recall: training: 0.916032 validation: 0.923870
09/16 06:51:32 AM: edges-ner-ontonotes_f1: training: 0.932111 validation: 0.936510
09/16 06:51:32 AM: Global learning rate: 0.0001
09/16 06:51:32 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:51:32 AM: Update 17001: task edges-ner-ontonotes, batch 1 (17001): mcc: 0.7684, acc: 0.7188, precision: 0.7812, recall: 0.7812, f1: 0.7812, edges-ner-ontonotes_loss: 0.0678
09/16 06:51:36 AM: Evaluate: task edges-ner-ontonotes, batch 26 (157): mcc: 0.8777, acc: 0.8459, precision: 0.9005, recall: 0.8686, f1: 0.8842, edges-ner-ontonotes_loss: 0.0396
09/16 06:51:43 AM: Update 17064: task edges-ner-ontonotes, batch 64 (17064): mcc: 0.8994, acc: 0.8558, precision: 0.9287, recall: 0.8817, f1: 0.9045, edges-ner-ontonotes_loss: 0.0344
09/16 06:51:47 AM: Evaluate: task edges-ner-ontonotes, batch 88 (157): mcc: 0.9234, acc: 0.8938, precision: 0.9401, recall: 0.9154, f1: 0.9276, edges-ner-ontonotes_loss: 0.0267
09/16 06:51:55 AM: Update 17117: task edges-ner-ontonotes, batch 117 (17117): mcc: 0.8996, acc: 0.8570, precision: 0.9285, recall: 0.8822, f1: 0.9048, edges-ner-ontonotes_loss: 0.0350
09/16 06:51:57 AM: Evaluate: task edges-ner-ontonotes, batch 143 (157): mcc: 0.9324, acc: 0.9049, precision: 0.9496, recall: 0.9228, f1: 0.9360, edges-ner-ontonotes_loss: 0.0229
09/16 06:51:59 AM: Updating LR scheduler:
09/16 06:51:59 AM: 	Best result seen so far for macro_avg: 0.941
09/16 06:51:59 AM: 	# validation passes without improvement: 2
09/16 06:51:59 AM: edges-ner-ontonotes_loss: training: 0.023447 validation: 0.022428
09/16 06:51:59 AM: macro_avg: validation: 0.936510
09/16 06:51:59 AM: micro_avg: validation: 0.000000
09/16 06:51:59 AM: edges-ner-ontonotes_mcc: training: 0.928351 validation: 0.932927
09/16 06:51:59 AM: edges-ner-ontonotes_acc: training: 0.893248 validation: 0.905293
09/16 06:51:59 AM: edges-ner-ontonotes_precision: training: 0.948763 validation: 0.949501
09/16 06:51:59 AM: edges-ner-ontonotes_recall: training: 0.916032 validation: 0.923870
09/16 06:51:59 AM: edges-ner-ontonotes_f1: training: 0.932111 validation: 0.936510
09/16 06:51:59 AM: Global learning rate: 0.0001
09/16 06:51:59 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:52:05 AM: Update 17191: task edges-ner-ontonotes, batch 191 (17191): mcc: 0.9032, acc: 0.8615, precision: 0.9300, recall: 0.8874, f1: 0.9082, edges-ner-ontonotes_loss: 0.0328
09/16 06:52:07 AM: Update 17065: task edges-ner-ontonotes, batch 65 (17065): mcc: 0.9007, acc: 0.8573, precision: 0.9295, recall: 0.8831, f1: 0.9057, edges-ner-ontonotes_loss: 0.0342
09/16 06:52:16 AM: Update 17285: task edges-ner-ontonotes, batch 285 (17285): mcc: 0.9042, acc: 0.8627, precision: 0.9309, recall: 0.8883, f1: 0.9091, edges-ner-ontonotes_loss: 0.0319
09/16 06:52:17 AM: Update 17131: task edges-ner-ontonotes, batch 131 (17131): mcc: 0.9003, acc: 0.8586, precision: 0.9281, recall: 0.8838, f1: 0.9054, edges-ner-ontonotes_loss: 0.0344
09/16 06:52:26 AM: Update 17372: task edges-ner-ontonotes, batch 372 (17372): mcc: 0.9053, acc: 0.8633, precision: 0.9326, recall: 0.8888, f1: 0.9102, edges-ner-ontonotes_loss: 0.0313
09/16 06:52:27 AM: Update 17218: task edges-ner-ontonotes, batch 218 (17218): mcc: 0.9030, acc: 0.8614, precision: 0.9296, recall: 0.8875, f1: 0.9081, edges-ner-ontonotes_loss: 0.0325
09/16 06:52:39 AM: Update 17434: task edges-ner-ontonotes, batch 434 (17434): mcc: 0.9053, acc: 0.8633, precision: 0.9328, recall: 0.8886, f1: 0.9101, edges-ner-ontonotes_loss: 0.0311
09/16 06:52:39 AM: Update 17319: task edges-ner-ontonotes, batch 319 (17319): mcc: 0.9042, acc: 0.8621, precision: 0.9316, recall: 0.8876, f1: 0.9091, edges-ner-ontonotes_loss: 0.0318
09/16 06:52:49 AM: Update 17401: task edges-ner-ontonotes, batch 401 (17401): mcc: 0.9057, acc: 0.8638, precision: 0.9328, recall: 0.8893, f1: 0.9105, edges-ner-ontonotes_loss: 0.0312
09/16 06:52:49 AM: Update 17512: task edges-ner-ontonotes, batch 512 (17512): mcc: 0.9083, acc: 0.8672, precision: 0.9344, recall: 0.8925, f1: 0.9130, edges-ner-ontonotes_loss: 0.0301
09/16 06:52:59 AM: Update 17457: task edges-ner-ontonotes, batch 457 (17457): mcc: 0.9059, acc: 0.8642, precision: 0.9333, recall: 0.8893, f1: 0.9107, edges-ner-ontonotes_loss: 0.0308
09/16 06:52:59 AM: Update 17597: task edges-ner-ontonotes, batch 597 (17597): mcc: 0.9105, acc: 0.8704, precision: 0.9359, recall: 0.8953, f1: 0.9152, edges-ner-ontonotes_loss: 0.0293
09/16 06:53:09 AM: Update 17528: task edges-ner-ontonotes, batch 528 (17528): mcc: 0.9084, acc: 0.8673, precision: 0.9346, recall: 0.8926, f1: 0.9131, edges-ner-ontonotes_loss: 0.0301
09/16 06:53:09 AM: Update 17671: task edges-ner-ontonotes, batch 671 (17671): mcc: 0.9129, acc: 0.8735, precision: 0.9379, recall: 0.8978, f1: 0.9174, edges-ner-ontonotes_loss: 0.0285
09/16 06:53:19 AM: Update 17603: task edges-ner-ontonotes, batch 603 (17603): mcc: 0.9106, acc: 0.8705, precision: 0.9360, recall: 0.8954, f1: 0.9152, edges-ner-ontonotes_loss: 0.0292
09/16 06:53:21 AM: Update 17743: task edges-ner-ontonotes, batch 743 (17743): mcc: 0.9143, acc: 0.8754, precision: 0.9389, recall: 0.8994, f1: 0.9187, edges-ner-ontonotes_loss: 0.0281
09/16 06:53:29 AM: Update 17680: task edges-ner-ontonotes, batch 680 (17680): mcc: 0.9130, acc: 0.8736, precision: 0.9380, recall: 0.8979, f1: 0.9175, edges-ner-ontonotes_loss: 0.0285
09/16 06:53:31 AM: Update 17817: task edges-ner-ontonotes, batch 817 (17817): mcc: 0.9170, acc: 0.8788, precision: 0.9408, recall: 0.9026, f1: 0.9213, edges-ner-ontonotes_loss: 0.0273
09/16 06:53:41 AM: Update 17900: task edges-ner-ontonotes, batch 900 (17900): mcc: 0.9197, acc: 0.8823, precision: 0.9426, recall: 0.9058, f1: 0.9238, edges-ner-ontonotes_loss: 0.0265
09/16 06:53:41 AM: Update 17743: task edges-ner-ontonotes, batch 743 (17743): mcc: 0.9143, acc: 0.8754, precision: 0.9389, recall: 0.8994, f1: 0.9187, edges-ner-ontonotes_loss: 0.0281
09/16 06:53:51 AM: Update 17816: task edges-ner-ontonotes, batch 816 (17816): mcc: 0.9170, acc: 0.8788, precision: 0.9408, recall: 0.9027, f1: 0.9213, edges-ner-ontonotes_loss: 0.0273
09/16 06:53:51 AM: Update 17971: task edges-ner-ontonotes, batch 971 (17971): mcc: 0.9215, acc: 0.8846, precision: 0.9440, recall: 0.9079, f1: 0.9256, edges-ner-ontonotes_loss: 0.0260
09/16 06:53:55 AM: ***** Step 18000 / Validation 18 *****
09/16 06:53:55 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:53:55 AM: Validating...
09/16 06:54:01 AM: Update 17877: task edges-ner-ontonotes, batch 877 (17877): mcc: 0.9192, acc: 0.8816, precision: 0.9423, recall: 0.9052, f1: 0.9234, edges-ner-ontonotes_loss: 0.0267
09/16 06:54:01 AM: Evaluate: task edges-ner-ontonotes, batch 39 (157): mcc: 0.8976, acc: 0.8638, precision: 0.9149, recall: 0.8916, f1: 0.9031, edges-ner-ontonotes_loss: 0.0340
09/16 06:54:11 AM: Update 17938: task edges-ner-ontonotes, batch 938 (17938): mcc: 0.9207, acc: 0.8835, precision: 0.9434, recall: 0.9069, f1: 0.9248, edges-ner-ontonotes_loss: 0.0262
09/16 06:54:11 AM: Evaluate: task edges-ner-ontonotes, batch 89 (157): mcc: 0.9275, acc: 0.8972, precision: 0.9432, recall: 0.9199, f1: 0.9314, edges-ner-ontonotes_loss: 0.0259
09/16 06:54:21 AM: Update 17994: task edges-ner-ontonotes, batch 994 (17994): mcc: 0.9221, acc: 0.8853, precision: 0.9443, recall: 0.9086, f1: 0.9261, edges-ner-ontonotes_loss: 0.0258
09/16 06:54:21 AM: Evaluate: task edges-ner-ontonotes, batch 138 (157): mcc: 0.9358, acc: 0.9087, precision: 0.9506, recall: 0.9282, f1: 0.9393, edges-ner-ontonotes_loss: 0.0223
09/16 06:54:22 AM: ***** Step 18000 / Validation 18 *****
09/16 06:54:22 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:54:22 AM: Validating...
09/16 06:54:25 AM: Updating LR scheduler:
09/16 06:54:25 AM: 	Best result seen so far for macro_avg: 0.941
09/16 06:54:26 AM: 	# validation passes without improvement: 3
09/16 06:54:26 AM: edges-ner-ontonotes_loss: training: 0.025724 validation: 0.021433
09/16 06:54:26 AM: macro_avg: validation: 0.940928
09/16 06:54:26 AM: micro_avg: validation: 0.000000
09/16 06:54:26 AM: edges-ner-ontonotes_mcc: training: 0.922282 validation: 0.937559
09/16 06:54:26 AM: edges-ner-ontonotes_acc: training: 0.885627 validation: 0.910752
09/16 06:54:26 AM: edges-ner-ontonotes_precision: training: 0.944489 validation: 0.951469
09/16 06:54:26 AM: edges-ner-ontonotes_recall: training: 0.908869 validation: 0.930619
09/16 06:54:26 AM: edges-ner-ontonotes_f1: training: 0.926337 validation: 0.940928
09/16 06:54:26 AM: Global learning rate: 0.0001
09/16 06:54:26 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:54:32 AM: Evaluate: task edges-ner-ontonotes, batch 55 (157): mcc: 0.9132, acc: 0.8808, precision: 0.9280, recall: 0.9080, f1: 0.9179, edges-ner-ontonotes_loss: 0.0299
09/16 06:54:32 AM: Update 18031: task edges-ner-ontonotes, batch 31 (18031): mcc: 0.9380, acc: 0.9071, precision: 0.9543, recall: 0.9287, f1: 0.9413, edges-ner-ontonotes_loss: 0.0196
09/16 06:54:43 AM: Update 18070: task edges-ner-ontonotes, batch 70 (18070): mcc: 0.9362, acc: 0.9028, precision: 0.9534, recall: 0.9262, f1: 0.9396, edges-ner-ontonotes_loss: 0.0201
09/16 06:54:43 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9289, acc: 0.8984, precision: 0.9459, recall: 0.9198, f1: 0.9327, edges-ner-ontonotes_loss: 0.0244
09/16 06:54:51 AM: Updating LR scheduler:
09/16 06:54:51 AM: 	Best result seen so far for macro_avg: 0.941
09/16 06:54:51 AM: 	# validation passes without improvement: 3
09/16 06:54:51 AM: edges-ner-ontonotes_loss: training: 0.025724 validation: 0.021433
09/16 06:54:51 AM: macro_avg: validation: 0.940928
09/16 06:54:51 AM: micro_avg: validation: 0.000000
09/16 06:54:51 AM: edges-ner-ontonotes_mcc: training: 0.922282 validation: 0.937559
09/16 06:54:51 AM: edges-ner-ontonotes_acc: training: 0.885627 validation: 0.910752
09/16 06:54:51 AM: edges-ner-ontonotes_precision: training: 0.944489 validation: 0.951469
09/16 06:54:51 AM: edges-ner-ontonotes_recall: training: 0.908869 validation: 0.930619
09/16 06:54:51 AM: edges-ner-ontonotes_f1: training: 0.926337 validation: 0.940928
09/16 06:54:51 AM: Global learning rate: 0.0001
09/16 06:54:51 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:54:53 AM: Update 18133: task edges-ner-ontonotes, batch 133 (18133): mcc: 0.9377, acc: 0.9049, precision: 0.9545, recall: 0.9279, f1: 0.9410, edges-ner-ontonotes_loss: 0.0198
09/16 06:54:53 AM: Update 18002: task edges-ner-ontonotes, batch 2 (18002): mcc: 0.9636, acc: 0.9383, precision: 0.9871, recall: 0.9444, f1: 0.9653, edges-ner-ontonotes_loss: 0.0156
09/16 06:55:03 AM: Update 18211: task edges-ner-ontonotes, batch 211 (18211): mcc: 0.9371, acc: 0.9041, precision: 0.9542, recall: 0.9270, f1: 0.9404, edges-ner-ontonotes_loss: 0.0198
09/16 06:55:04 AM: Update 18056: task edges-ner-ontonotes, batch 56 (18056): mcc: 0.9372, acc: 0.9053, precision: 0.9542, recall: 0.9272, f1: 0.9405, edges-ner-ontonotes_loss: 0.0199
09/16 06:55:13 AM: Update 18286: task edges-ner-ontonotes, batch 286 (18286): mcc: 0.9378, acc: 0.9050, precision: 0.9543, recall: 0.9283, f1: 0.9411, edges-ner-ontonotes_loss: 0.0196
09/16 06:55:14 AM: Update 18126: task edges-ner-ontonotes, batch 126 (18126): mcc: 0.9374, acc: 0.9045, precision: 0.9540, recall: 0.9278, f1: 0.9408, edges-ner-ontonotes_loss: 0.0199
09/16 06:55:24 AM: Update 18358: task edges-ner-ontonotes, batch 358 (18358): mcc: 0.9383, acc: 0.9057, precision: 0.9549, recall: 0.9286, f1: 0.9416, edges-ner-ontonotes_loss: 0.0197
09/16 06:55:24 AM: Update 18196: task edges-ner-ontonotes, batch 196 (18196): mcc: 0.9368, acc: 0.9040, precision: 0.9542, recall: 0.9266, f1: 0.9402, edges-ner-ontonotes_loss: 0.0198
09/16 06:55:34 AM: Update 18411: task edges-ner-ontonotes, batch 411 (18411): mcc: 0.9326, acc: 0.8983, precision: 0.9514, recall: 0.9214, f1: 0.9362, edges-ner-ontonotes_loss: 0.0220
09/16 06:55:34 AM: Update 18274: task edges-ner-ontonotes, batch 274 (18274): mcc: 0.9378, acc: 0.9050, precision: 0.9545, recall: 0.9282, f1: 0.9411, edges-ner-ontonotes_loss: 0.0196
09/16 06:55:44 AM: Update 18482: task edges-ner-ontonotes, batch 482 (18482): mcc: 0.9274, acc: 0.8913, precision: 0.9480, recall: 0.9150, f1: 0.9312, edges-ner-ontonotes_loss: 0.0240
09/16 06:55:44 AM: Update 18347: task edges-ner-ontonotes, batch 347 (18347): mcc: 0.9383, acc: 0.9058, precision: 0.9549, recall: 0.9287, f1: 0.9416, edges-ner-ontonotes_loss: 0.0197
09/16 06:55:54 AM: Update 18561: task edges-ner-ontonotes, batch 561 (18561): mcc: 0.9246, acc: 0.8878, precision: 0.9464, recall: 0.9113, f1: 0.9285, edges-ner-ontonotes_loss: 0.0251
09/16 06:55:55 AM: Update 18407: task edges-ner-ontonotes, batch 407 (18407): mcc: 0.9330, acc: 0.8988, precision: 0.9515, recall: 0.9222, f1: 0.9366, edges-ner-ontonotes_loss: 0.0219
09/16 06:56:04 AM: Update 18637: task edges-ner-ontonotes, batch 637 (18637): mcc: 0.9224, acc: 0.8855, precision: 0.9450, recall: 0.9087, f1: 0.9265, edges-ner-ontonotes_loss: 0.0263
09/16 06:56:05 AM: Update 18481: task edges-ner-ontonotes, batch 481 (18481): mcc: 0.9275, acc: 0.8914, precision: 0.9480, recall: 0.9152, f1: 0.9313, edges-ner-ontonotes_loss: 0.0240
09/16 06:56:14 AM: Update 18690: task edges-ner-ontonotes, batch 690 (18690): mcc: 0.9208, acc: 0.8835, precision: 0.9439, recall: 0.9067, f1: 0.9249, edges-ner-ontonotes_loss: 0.0270
09/16 06:56:15 AM: Update 18566: task edges-ner-ontonotes, batch 566 (18566): mcc: 0.9242, acc: 0.8874, precision: 0.9462, recall: 0.9109, f1: 0.9282, edges-ner-ontonotes_loss: 0.0253
09/16 06:56:24 AM: Update 18771: task edges-ner-ontonotes, batch 771 (18771): mcc: 0.9195, acc: 0.8817, precision: 0.9430, recall: 0.9051, f1: 0.9237, edges-ner-ontonotes_loss: 0.0274
09/16 06:56:25 AM: Update 18645: task edges-ner-ontonotes, batch 645 (18645): mcc: 0.9223, acc: 0.8853, precision: 0.9449, recall: 0.9085, f1: 0.9263, edges-ner-ontonotes_loss: 0.0264
09/16 06:56:34 AM: Update 18868: task edges-ner-ontonotes, batch 868 (18868): mcc: 0.9189, acc: 0.8808, precision: 0.9428, recall: 0.9042, f1: 0.9231, edges-ner-ontonotes_loss: 0.0274
09/16 06:56:35 AM: Update 18711: task edges-ner-ontonotes, batch 711 (18711): mcc: 0.9204, acc: 0.8828, precision: 0.9436, recall: 0.9062, f1: 0.9245, edges-ner-ontonotes_loss: 0.0271
09/16 06:56:44 AM: Update 18957: task edges-ner-ontonotes, batch 957 (18957): mcc: 0.9183, acc: 0.8799, precision: 0.9423, recall: 0.9036, f1: 0.9225, edges-ner-ontonotes_loss: 0.0275
09/16 06:56:45 AM: Update 18795: task edges-ner-ontonotes, batch 795 (18795): mcc: 0.9192, acc: 0.8812, precision: 0.9430, recall: 0.9046, f1: 0.9234, edges-ner-ontonotes_loss: 0.0274
09/16 06:56:52 AM: ***** Step 19000 / Validation 19 *****
09/16 06:56:52 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:56:52 AM: Validating...
09/16 06:56:54 AM: Evaluate: task edges-ner-ontonotes, batch 15 (157): mcc: 0.8742, acc: 0.8303, precision: 0.9035, recall: 0.8591, f1: 0.8807, edges-ner-ontonotes_loss: 0.0357
09/16 06:56:56 AM: Update 18888: task edges-ner-ontonotes, batch 888 (18888): mcc: 0.9189, acc: 0.8806, precision: 0.9428, recall: 0.9041, f1: 0.9231, edges-ner-ontonotes_loss: 0.0274
09/16 06:57:04 AM: Evaluate: task edges-ner-ontonotes, batch 82 (157): mcc: 0.9275, acc: 0.8983, precision: 0.9428, recall: 0.9202, f1: 0.9314, edges-ner-ontonotes_loss: 0.0252
09/16 06:57:07 AM: Update 18951: task edges-ner-ontonotes, batch 951 (18951): mcc: 0.9185, acc: 0.8801, precision: 0.9425, recall: 0.9037, f1: 0.9227, edges-ner-ontonotes_loss: 0.0275
09/16 06:57:14 AM: Evaluate: task edges-ner-ontonotes, batch 137 (157): mcc: 0.9360, acc: 0.9085, precision: 0.9514, recall: 0.9277, f1: 0.9394, edges-ner-ontonotes_loss: 0.0217
09/16 06:57:17 AM: Update 18994: task edges-ner-ontonotes, batch 994 (18994): mcc: 0.9181, acc: 0.8796, precision: 0.9423, recall: 0.9032, f1: 0.9223, edges-ner-ontonotes_loss: 0.0276
09/16 06:57:17 AM: Updating LR scheduler:
09/16 06:57:17 AM: 	Best result seen so far for macro_avg: 0.941
09/16 06:57:17 AM: 	# validation passes without improvement: 0
09/16 06:57:17 AM: edges-ner-ontonotes_loss: training: 0.027587 validation: 0.020950
09/16 06:57:17 AM: macro_avg: validation: 0.940328
09/16 06:57:17 AM: micro_avg: validation: 0.000000
09/16 06:57:17 AM: edges-ner-ontonotes_mcc: training: 0.918161 validation: 0.936940
09/16 06:57:17 AM: edges-ner-ontonotes_acc: training: 0.879692 validation: 0.909842
09/16 06:57:17 AM: edges-ner-ontonotes_precision: training: 0.942325 validation: 0.951907
09/16 06:57:17 AM: edges-ner-ontonotes_recall: training: 0.903290 validation: 0.929026
09/16 06:57:17 AM: edges-ner-ontonotes_f1: training: 0.922394 validation: 0.940328
09/16 06:57:17 AM: Global learning rate: 5e-05
09/16 06:57:17 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:57:18 AM: ***** Step 19000 / Validation 19 *****
09/16 06:57:18 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:57:18 AM: Validating...
09/16 06:57:25 AM: Update 19041: task edges-ner-ontonotes, batch 41 (19041): mcc: 0.9254, acc: 0.8905, precision: 0.9428, recall: 0.9163, f1: 0.9294, edges-ner-ontonotes_loss: 0.0234
09/16 06:57:27 AM: Evaluate: task edges-ner-ontonotes, batch 58 (157): mcc: 0.9233, acc: 0.8957, precision: 0.9368, recall: 0.9184, f1: 0.9275, edges-ner-ontonotes_loss: 0.0265
09/16 06:57:35 AM: Update 19097: task edges-ner-ontonotes, batch 97 (19097): mcc: 0.9250, acc: 0.8898, precision: 0.9443, recall: 0.9142, f1: 0.9290, edges-ner-ontonotes_loss: 0.0240
09/16 06:57:38 AM: Evaluate: task edges-ner-ontonotes, batch 112 (157): mcc: 0.9302, acc: 0.9012, precision: 0.9460, recall: 0.9223, f1: 0.9340, edges-ner-ontonotes_loss: 0.0233
09/16 06:57:45 AM: Update 19152: task edges-ner-ontonotes, batch 152 (19152): mcc: 0.9220, acc: 0.8855, precision: 0.9428, recall: 0.9100, f1: 0.9261, edges-ner-ontonotes_loss: 0.0244
09/16 06:57:47 AM: Updating LR scheduler:
09/16 06:57:47 AM: 	Best result seen so far for macro_avg: 0.941
09/16 06:57:47 AM: 	# validation passes without improvement: 0
09/16 06:57:47 AM: edges-ner-ontonotes_loss: training: 0.027587 validation: 0.020950
09/16 06:57:47 AM: macro_avg: validation: 0.940328
09/16 06:57:47 AM: micro_avg: validation: 0.000000
09/16 06:57:47 AM: edges-ner-ontonotes_mcc: training: 0.918161 validation: 0.936940
09/16 06:57:47 AM: edges-ner-ontonotes_acc: training: 0.879692 validation: 0.909842
09/16 06:57:47 AM: edges-ner-ontonotes_precision: training: 0.942325 validation: 0.951907
09/16 06:57:47 AM: edges-ner-ontonotes_recall: training: 0.903290 validation: 0.929026
09/16 06:57:47 AM: edges-ner-ontonotes_f1: training: 0.922394 validation: 0.940328
09/16 06:57:47 AM: Global learning rate: 5e-05
09/16 06:57:47 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 06:57:50 AM: Update 19001: task edges-ner-ontonotes, batch 1 (19001): mcc: 0.9403, acc: 0.9184, precision: 0.9485, recall: 0.9388, f1: 0.9436, edges-ner-ontonotes_loss: 0.0224
09/16 06:57:55 AM: Update 19230: task edges-ner-ontonotes, batch 230 (19230): mcc: 0.9233, acc: 0.8870, precision: 0.9444, recall: 0.9108, f1: 0.9273, edges-ner-ontonotes_loss: 0.0241
09/16 06:58:00 AM: Update 19079: task edges-ner-ontonotes, batch 79 (19079): mcc: 0.9242, acc: 0.8874, precision: 0.9435, recall: 0.9134, f1: 0.9282, edges-ner-ontonotes_loss: 0.0239
09/16 06:58:06 AM: Update 19299: task edges-ner-ontonotes, batch 299 (19299): mcc: 0.9238, acc: 0.8874, precision: 0.9449, recall: 0.9113, f1: 0.9278, edges-ner-ontonotes_loss: 0.0242
09/16 06:58:11 AM: Update 19156: task edges-ner-ontonotes, batch 156 (19156): mcc: 0.9218, acc: 0.8852, precision: 0.9428, recall: 0.9096, f1: 0.9259, edges-ner-ontonotes_loss: 0.0245
09/16 06:58:17 AM: Update 19369: task edges-ner-ontonotes, batch 369 (19369): mcc: 0.9274, acc: 0.8923, precision: 0.9475, recall: 0.9154, f1: 0.9312, edges-ner-ontonotes_loss: 0.0231
09/16 06:58:21 AM: Update 19228: task edges-ner-ontonotes, batch 228 (19228): mcc: 0.9231, acc: 0.8868, precision: 0.9443, recall: 0.9105, f1: 0.9271, edges-ner-ontonotes_loss: 0.0242
09/16 06:58:27 AM: Update 19443: task edges-ner-ontonotes, batch 443 (19443): mcc: 0.9294, acc: 0.8947, precision: 0.9487, recall: 0.9179, f1: 0.9331, edges-ner-ontonotes_loss: 0.0225
09/16 06:58:34 AM: Update 19299: task edges-ner-ontonotes, batch 299 (19299): mcc: 0.9238, acc: 0.8874, precision: 0.9449, recall: 0.9113, f1: 0.9278, edges-ner-ontonotes_loss: 0.0242
09/16 06:58:37 AM: Update 19525: task edges-ner-ontonotes, batch 525 (19525): mcc: 0.9313, acc: 0.8970, precision: 0.9503, recall: 0.9199, f1: 0.9349, edges-ner-ontonotes_loss: 0.0219
09/16 06:58:44 AM: Update 19369: task edges-ner-ontonotes, batch 369 (19369): mcc: 0.9274, acc: 0.8923, precision: 0.9475, recall: 0.9154, f1: 0.9312, edges-ner-ontonotes_loss: 0.0231
09/16 06:58:47 AM: Update 19597: task edges-ner-ontonotes, batch 597 (19597): mcc: 0.9322, acc: 0.8981, precision: 0.9506, recall: 0.9214, f1: 0.9357, edges-ner-ontonotes_loss: 0.0216
09/16 06:58:54 AM: Update 19464: task edges-ner-ontonotes, batch 464 (19464): mcc: 0.9296, acc: 0.8948, precision: 0.9490, recall: 0.9182, f1: 0.9333, edges-ner-ontonotes_loss: 0.0223
09/16 06:59:01 AM: Update 19656: task edges-ner-ontonotes, batch 656 (19656): mcc: 0.9329, acc: 0.8988, precision: 0.9513, recall: 0.9220, f1: 0.9364, edges-ner-ontonotes_loss: 0.0214
09/16 06:59:04 AM: Update 19533: task edges-ner-ontonotes, batch 533 (19533): mcc: 0.9315, acc: 0.8974, precision: 0.9504, recall: 0.9203, f1: 0.9351, edges-ner-ontonotes_loss: 0.0218
09/16 06:59:11 AM: Update 19728: task edges-ner-ontonotes, batch 728 (19728): mcc: 0.9331, acc: 0.8991, precision: 0.9514, recall: 0.9223, f1: 0.9366, edges-ner-ontonotes_loss: 0.0213
09/16 06:59:15 AM: Update 19606: task edges-ner-ontonotes, batch 606 (19606): mcc: 0.9323, acc: 0.8983, precision: 0.9507, recall: 0.9214, f1: 0.9358, edges-ner-ontonotes_loss: 0.0216
09/16 06:59:21 AM: Update 19807: task edges-ner-ontonotes, batch 807 (19807): mcc: 0.9333, acc: 0.8995, precision: 0.9517, recall: 0.9224, f1: 0.9368, edges-ner-ontonotes_loss: 0.0212
09/16 06:59:25 AM: Update 19662: task edges-ner-ontonotes, batch 662 (19662): mcc: 0.9328, acc: 0.8988, precision: 0.9513, recall: 0.9219, f1: 0.9363, edges-ner-ontonotes_loss: 0.0214
09/16 06:59:31 AM: Update 19880: task edges-ner-ontonotes, batch 880 (19880): mcc: 0.9338, acc: 0.9001, precision: 0.9520, recall: 0.9230, f1: 0.9373, edges-ner-ontonotes_loss: 0.0210
09/16 06:59:35 AM: Update 19735: task edges-ner-ontonotes, batch 735 (19735): mcc: 0.9332, acc: 0.8993, precision: 0.9515, recall: 0.9224, f1: 0.9367, edges-ner-ontonotes_loss: 0.0212
09/16 06:59:41 AM: Update 19932: task edges-ner-ontonotes, batch 932 (19932): mcc: 0.9332, acc: 0.8994, precision: 0.9515, recall: 0.9224, f1: 0.9368, edges-ner-ontonotes_loss: 0.0211
09/16 06:59:45 AM: Update 19818: task edges-ner-ontonotes, batch 818 (19818): mcc: 0.9334, acc: 0.8996, precision: 0.9519, recall: 0.9224, f1: 0.9369, edges-ner-ontonotes_loss: 0.0212
09/16 06:59:50 AM: ***** Step 20000 / Validation 20 *****
09/16 06:59:50 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:59:50 AM: Validating...
09/16 06:59:51 AM: Evaluate: task edges-ner-ontonotes, batch 6 (157): mcc: 0.8364, acc: 0.7800, precision: 0.8763, recall: 0.8150, f1: 0.8446, edges-ner-ontonotes_loss: 0.0425
09/16 06:59:55 AM: Update 19881: task edges-ner-ontonotes, batch 881 (19881): mcc: 0.9338, acc: 0.9001, precision: 0.9520, recall: 0.9231, f1: 0.9373, edges-ner-ontonotes_loss: 0.0210
09/16 07:00:01 AM: Evaluate: task edges-ner-ontonotes, batch 65 (157): mcc: 0.9201, acc: 0.8900, precision: 0.9384, recall: 0.9107, f1: 0.9244, edges-ner-ontonotes_loss: 0.0279
09/16 07:00:05 AM: Update 19925: task edges-ner-ontonotes, batch 925 (19925): mcc: 0.9337, acc: 0.9001, precision: 0.9519, recall: 0.9230, f1: 0.9372, edges-ner-ontonotes_loss: 0.0210
09/16 07:00:11 AM: Evaluate: task edges-ner-ontonotes, batch 120 (157): mcc: 0.9317, acc: 0.9030, precision: 0.9508, recall: 0.9202, f1: 0.9353, edges-ner-ontonotes_loss: 0.0236
09/16 07:00:16 AM: Update 19982: task edges-ner-ontonotes, batch 982 (19982): mcc: 0.9317, acc: 0.8975, precision: 0.9507, recall: 0.9204, f1: 0.9353, edges-ner-ontonotes_loss: 0.0220
09/16 07:00:18 AM: Updating LR scheduler:
09/16 07:00:18 AM: 	Best result seen so far for macro_avg: 0.941
09/16 07:00:18 AM: 	# validation passes without improvement: 1
09/16 07:00:18 AM: edges-ner-ontonotes_loss: training: 0.022311 validation: 0.021380
09/16 07:00:18 AM: macro_avg: validation: 0.940593
09/16 07:00:18 AM: micro_avg: validation: 0.000000
09/16 07:00:18 AM: edges-ner-ontonotes_mcc: training: 0.930717 validation: 0.937269
09/16 07:00:18 AM: edges-ner-ontonotes_acc: training: 0.896283 validation: 0.910828
09/16 07:00:18 AM: edges-ner-ontonotes_precision: training: 0.949998 validation: 0.954773
09/16 07:00:18 AM: edges-ner-ontonotes_recall: training: 0.919247 validation: 0.926827
09/16 07:00:18 AM: edges-ner-ontonotes_f1: training: 0.934369 validation: 0.940593
09/16 07:00:18 AM: Global learning rate: 5e-05
09/16 07:00:18 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:00:19 AM: ***** Step 20000 / Validation 20 *****
09/16 07:00:19 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:00:19 AM: Validating...
09/16 07:00:21 AM: Update 20025: task edges-ner-ontonotes, batch 25 (20025): mcc: 0.9030, acc: 0.8619, precision: 0.9341, recall: 0.8830, f1: 0.9078, edges-ner-ontonotes_loss: 0.0350
09/16 07:00:26 AM: Evaluate: task edges-ner-ontonotes, batch 47 (157): mcc: 0.9095, acc: 0.8795, precision: 0.9285, recall: 0.9006, f1: 0.9143, edges-ner-ontonotes_loss: 0.0308
09/16 07:00:32 AM: Update 20082: task edges-ner-ontonotes, batch 82 (20082): mcc: 0.9049, acc: 0.8629, precision: 0.9357, recall: 0.8851, f1: 0.9097, edges-ner-ontonotes_loss: 0.0331
09/16 07:00:36 AM: Evaluate: task edges-ner-ontonotes, batch 102 (157): mcc: 0.9276, acc: 0.8982, precision: 0.9481, recall: 0.9152, f1: 0.9314, edges-ner-ontonotes_loss: 0.0250
09/16 07:00:42 AM: Update 20136: task edges-ner-ontonotes, batch 136 (20136): mcc: 0.9065, acc: 0.8647, precision: 0.9342, recall: 0.8894, f1: 0.9113, edges-ner-ontonotes_loss: 0.0322
09/16 07:00:46 AM: Evaluate: task edges-ner-ontonotes, batch 153 (157): mcc: 0.9367, acc: 0.9100, precision: 0.9547, recall: 0.9258, f1: 0.9400, edges-ner-ontonotes_loss: 0.0217
09/16 07:00:47 AM: Updating LR scheduler:
09/16 07:00:47 AM: 	Best result seen so far for macro_avg: 0.941
09/16 07:00:47 AM: 	# validation passes without improvement: 1
09/16 07:00:47 AM: edges-ner-ontonotes_loss: training: 0.022311 validation: 0.021380
09/16 07:00:47 AM: macro_avg: validation: 0.940593
09/16 07:00:47 AM: micro_avg: validation: 0.000000
09/16 07:00:47 AM: edges-ner-ontonotes_mcc: training: 0.930717 validation: 0.937269
09/16 07:00:47 AM: edges-ner-ontonotes_acc: training: 0.896283 validation: 0.910828
09/16 07:00:47 AM: edges-ner-ontonotes_precision: training: 0.949998 validation: 0.954773
09/16 07:00:47 AM: edges-ner-ontonotes_recall: training: 0.919247 validation: 0.926827
09/16 07:00:47 AM: edges-ner-ontonotes_f1: training: 0.934369 validation: 0.940593
09/16 07:00:47 AM: Global learning rate: 5e-05
09/16 07:00:47 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:00:52 AM: Update 20198: task edges-ner-ontonotes, batch 198 (20198): mcc: 0.9043, acc: 0.8625, precision: 0.9330, recall: 0.8866, f1: 0.9092, edges-ner-ontonotes_loss: 0.0329
09/16 07:00:56 AM: Update 20074: task edges-ner-ontonotes, batch 74 (20074): mcc: 0.9020, acc: 0.8586, precision: 0.9338, recall: 0.8816, f1: 0.9069, edges-ner-ontonotes_loss: 0.0337
09/16 07:01:02 AM: Update 20254: task edges-ner-ontonotes, batch 254 (20254): mcc: 0.9028, acc: 0.8605, precision: 0.9318, recall: 0.8849, f1: 0.9077, edges-ner-ontonotes_loss: 0.0333
09/16 07:01:06 AM: Update 20157: task edges-ner-ontonotes, batch 157 (20157): mcc: 0.9059, acc: 0.8641, precision: 0.9337, recall: 0.8889, f1: 0.9107, edges-ner-ontonotes_loss: 0.0322
09/16 07:01:12 AM: Update 20335: task edges-ner-ontonotes, batch 335 (20335): mcc: 0.9048, acc: 0.8634, precision: 0.9327, recall: 0.8879, f1: 0.9097, edges-ner-ontonotes_loss: 0.0320
09/16 07:01:19 AM: Update 20229: task edges-ner-ontonotes, batch 229 (20229): mcc: 0.9021, acc: 0.8599, precision: 0.9313, recall: 0.8840, f1: 0.9070, edges-ner-ontonotes_loss: 0.0339
09/16 07:01:22 AM: Update 20437: task edges-ner-ontonotes, batch 437 (20437): mcc: 0.9063, acc: 0.8654, precision: 0.9340, recall: 0.8892, f1: 0.9111, edges-ner-ontonotes_loss: 0.0314
09/16 07:01:29 AM: Update 20313: task edges-ner-ontonotes, batch 313 (20313): mcc: 0.9040, acc: 0.8623, precision: 0.9322, recall: 0.8867, f1: 0.9089, edges-ner-ontonotes_loss: 0.0325
09/16 07:01:32 AM: Update 20523: task edges-ner-ontonotes, batch 523 (20523): mcc: 0.9075, acc: 0.8666, precision: 0.9350, recall: 0.8905, f1: 0.9122, edges-ner-ontonotes_loss: 0.0307
09/16 07:01:39 AM: Update 20405: task edges-ner-ontonotes, batch 405 (20405): mcc: 0.9063, acc: 0.8654, precision: 0.9338, recall: 0.8894, f1: 0.9111, edges-ner-ontonotes_loss: 0.0314
09/16 07:01:42 AM: Update 20584: task edges-ner-ontonotes, batch 584 (20584): mcc: 0.9089, acc: 0.8686, precision: 0.9357, recall: 0.8924, f1: 0.9135, edges-ner-ontonotes_loss: 0.0303
09/16 07:01:49 AM: Update 20485: task edges-ner-ontonotes, batch 485 (20485): mcc: 0.9071, acc: 0.8662, precision: 0.9348, recall: 0.8899, f1: 0.9118, edges-ner-ontonotes_loss: 0.0309
09/16 07:01:52 AM: Update 20663: task edges-ner-ontonotes, batch 663 (20663): mcc: 0.9114, acc: 0.8718, precision: 0.9375, recall: 0.8954, f1: 0.9160, edges-ner-ontonotes_loss: 0.0294
09/16 07:01:59 AM: Update 20544: task edges-ner-ontonotes, batch 544 (20544): mcc: 0.9074, acc: 0.8663, precision: 0.9350, recall: 0.8903, f1: 0.9121, edges-ner-ontonotes_loss: 0.0307
09/16 07:02:03 AM: Update 20747: task edges-ner-ontonotes, batch 747 (20747): mcc: 0.9129, acc: 0.8741, precision: 0.9382, recall: 0.8975, f1: 0.9174, edges-ner-ontonotes_loss: 0.0289
09/16 07:02:09 AM: Update 20619: task edges-ner-ontonotes, batch 619 (20619): mcc: 0.9100, acc: 0.8701, precision: 0.9364, recall: 0.8938, f1: 0.9146, edges-ner-ontonotes_loss: 0.0299
09/16 07:02:13 AM: Update 20820: task edges-ner-ontonotes, batch 820 (20820): mcc: 0.9141, acc: 0.8756, precision: 0.9391, recall: 0.8988, f1: 0.9185, edges-ner-ontonotes_loss: 0.0284
09/16 07:02:19 AM: Update 20701: task edges-ner-ontonotes, batch 701 (20701): mcc: 0.9122, acc: 0.8731, precision: 0.9378, recall: 0.8966, f1: 0.9167, edges-ner-ontonotes_loss: 0.0291
09/16 07:02:23 AM: Update 20881: task edges-ner-ontonotes, batch 881 (20881): mcc: 0.9152, acc: 0.8770, precision: 0.9398, recall: 0.9002, f1: 0.9196, edges-ner-ontonotes_loss: 0.0280
09/16 07:02:31 AM: Update 20771: task edges-ner-ontonotes, batch 771 (20771): mcc: 0.9133, acc: 0.8746, precision: 0.9384, recall: 0.8980, f1: 0.9178, edges-ner-ontonotes_loss: 0.0287
09/16 07:02:33 AM: Update 20952: task edges-ner-ontonotes, batch 952 (20952): mcc: 0.9178, acc: 0.8802, precision: 0.9414, recall: 0.9035, f1: 0.9220, edges-ner-ontonotes_loss: 0.0272
09/16 07:02:39 AM: ***** Step 21000 / Validation 21 *****
09/16 07:02:39 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:02:39 AM: Validating...
09/16 07:02:41 AM: Update 20841: task edges-ner-ontonotes, batch 841 (20841): mcc: 0.9144, acc: 0.8759, precision: 0.9393, recall: 0.8992, f1: 0.9188, edges-ner-ontonotes_loss: 0.0283
09/16 07:02:43 AM: Evaluate: task edges-ner-ontonotes, batch 30 (157): mcc: 0.8900, acc: 0.8591, precision: 0.9115, recall: 0.8807, f1: 0.8959, edges-ner-ontonotes_loss: 0.0358
09/16 07:02:54 AM: Update 20881: task edges-ner-ontonotes, batch 881 (20881): mcc: 0.9152, acc: 0.8770, precision: 0.9398, recall: 0.9002, f1: 0.9196, edges-ner-ontonotes_loss: 0.0280
09/16 07:02:54 AM: Evaluate: task edges-ner-ontonotes, batch 92 (157): mcc: 0.9293, acc: 0.9009, precision: 0.9478, recall: 0.9188, f1: 0.9330, edges-ner-ontonotes_loss: 0.0251
09/16 07:03:04 AM: Update 20937: task edges-ner-ontonotes, batch 937 (20937): mcc: 0.9173, acc: 0.8797, precision: 0.9412, recall: 0.9028, f1: 0.9216, edges-ner-ontonotes_loss: 0.0273
09/16 07:03:04 AM: Evaluate: task edges-ner-ontonotes, batch 142 (157): mcc: 0.9376, acc: 0.9119, precision: 0.9542, recall: 0.9280, f1: 0.9409, edges-ner-ontonotes_loss: 0.0216
09/16 07:03:07 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:03:07 AM: Best result seen so far for macro.
09/16 07:03:07 AM: Updating LR scheduler:
09/16 07:03:07 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:03:07 AM: 	# validation passes without improvement: 0
09/16 07:03:07 AM: edges-ner-ontonotes_loss: training: 0.026767 validation: 0.020996
09/16 07:03:07 AM: macro_avg: validation: 0.941899
09/16 07:03:07 AM: micro_avg: validation: 0.000000
09/16 07:03:07 AM: edges-ner-ontonotes_mcc: training: 0.919042 validation: 0.938615
09/16 07:03:07 AM: edges-ner-ontonotes_acc: training: 0.881896 validation: 0.913330
09/16 07:03:07 AM: edges-ner-ontonotes_precision: training: 0.942282 validation: 0.954174
09/16 07:03:07 AM: edges-ner-ontonotes_recall: training: 0.904973 validation: 0.929936
09/16 07:03:07 AM: edges-ner-ontonotes_f1: training: 0.923251 validation: 0.941899
09/16 07:03:07 AM: Global learning rate: 5e-05
09/16 07:03:07 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:03:14 AM: ***** Step 21000 / Validation 21 *****
09/16 07:03:14 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:03:14 AM: Validating...
09/16 07:03:14 AM: Evaluate: task edges-ner-ontonotes, batch 2 (157): mcc: 0.8015, acc: 0.7462, precision: 0.8487, recall: 0.7769, f1: 0.8112, edges-ner-ontonotes_loss: 0.0540
09/16 07:03:14 AM: Update 21054: task edges-ner-ontonotes, batch 54 (21054): mcc: 0.9383, acc: 0.9075, precision: 0.9540, recall: 0.9294, f1: 0.9416, edges-ner-ontonotes_loss: 0.0191
09/16 07:03:24 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.9220, acc: 0.8962, precision: 0.9374, recall: 0.9153, f1: 0.9262, edges-ner-ontonotes_loss: 0.0274
09/16 07:03:24 AM: Update 21111: task edges-ner-ontonotes, batch 111 (21111): mcc: 0.9391, acc: 0.9076, precision: 0.9543, recall: 0.9308, f1: 0.9424, edges-ner-ontonotes_loss: 0.0190
09/16 07:03:34 AM: Update 21167: task edges-ner-ontonotes, batch 167 (21167): mcc: 0.9381, acc: 0.9060, precision: 0.9541, recall: 0.9290, f1: 0.9414, edges-ner-ontonotes_loss: 0.0194
09/16 07:03:34 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9302, acc: 0.9017, precision: 0.9485, recall: 0.9197, f1: 0.9339, edges-ner-ontonotes_loss: 0.0238
09/16 07:03:41 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:03:41 AM: Best result seen so far for macro.
09/16 07:03:41 AM: Updating LR scheduler:
09/16 07:03:41 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:03:41 AM: 	# validation passes without improvement: 0
09/16 07:03:41 AM: edges-ner-ontonotes_loss: training: 0.026767 validation: 0.020996
09/16 07:03:41 AM: macro_avg: validation: 0.941899
09/16 07:03:41 AM: micro_avg: validation: 0.000000
09/16 07:03:41 AM: edges-ner-ontonotes_mcc: training: 0.919042 validation: 0.938615
09/16 07:03:41 AM: edges-ner-ontonotes_acc: training: 0.881896 validation: 0.913330
09/16 07:03:41 AM: edges-ner-ontonotes_precision: training: 0.942282 validation: 0.954174
09/16 07:03:41 AM: edges-ner-ontonotes_recall: training: 0.904973 validation: 0.929936
09/16 07:03:41 AM: edges-ner-ontonotes_f1: training: 0.923251 validation: 0.941899
09/16 07:03:41 AM: Global learning rate: 5e-05
09/16 07:03:41 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:03:44 AM: Update 21220: task edges-ner-ontonotes, batch 220 (21220): mcc: 0.9372, acc: 0.9046, precision: 0.9537, recall: 0.9277, f1: 0.9405, edges-ner-ontonotes_loss: 0.0197
09/16 07:03:44 AM: Update 21010: task edges-ner-ontonotes, batch 10 (21010): mcc: 0.9348, acc: 0.8982, precision: 0.9557, recall: 0.9212, f1: 0.9382, edges-ner-ontonotes_loss: 0.0197
09/16 07:03:54 AM: Update 21289: task edges-ner-ontonotes, batch 289 (21289): mcc: 0.9388, acc: 0.9067, precision: 0.9554, recall: 0.9290, f1: 0.9420, edges-ner-ontonotes_loss: 0.0194
09/16 07:03:54 AM: Update 21083: task edges-ner-ontonotes, batch 83 (21083): mcc: 0.9395, acc: 0.9089, precision: 0.9553, recall: 0.9305, f1: 0.9427, edges-ner-ontonotes_loss: 0.0189
09/16 07:04:04 AM: Update 21362: task edges-ner-ontonotes, batch 362 (21362): mcc: 0.9380, acc: 0.9059, precision: 0.9545, recall: 0.9285, f1: 0.9413, edges-ner-ontonotes_loss: 0.0198
09/16 07:04:04 AM: Update 21154: task edges-ner-ontonotes, batch 154 (21154): mcc: 0.9377, acc: 0.9054, precision: 0.9536, recall: 0.9289, f1: 0.9410, edges-ner-ontonotes_loss: 0.0196
09/16 07:04:18 AM: Update 21205: task edges-ner-ontonotes, batch 205 (21205): mcc: 0.9373, acc: 0.9051, precision: 0.9535, recall: 0.9283, f1: 0.9407, edges-ner-ontonotes_loss: 0.0196
09/16 07:04:18 AM: Update 21443: task edges-ner-ontonotes, batch 443 (21443): mcc: 0.9380, acc: 0.9059, precision: 0.9549, recall: 0.9281, f1: 0.9413, edges-ner-ontonotes_loss: 0.0198
09/16 07:04:28 AM: Update 21281: task edges-ner-ontonotes, batch 281 (21281): mcc: 0.9387, acc: 0.9065, precision: 0.9551, recall: 0.9291, f1: 0.9419, edges-ner-ontonotes_loss: 0.0194
09/16 07:04:28 AM: Update 21500: task edges-ner-ontonotes, batch 500 (21500): mcc: 0.9366, acc: 0.9045, precision: 0.9539, recall: 0.9264, f1: 0.9399, edges-ner-ontonotes_loss: 0.0206
09/16 07:04:38 AM: Update 21356: task edges-ner-ontonotes, batch 356 (21356): mcc: 0.9384, acc: 0.9064, precision: 0.9549, recall: 0.9289, f1: 0.9417, edges-ner-ontonotes_loss: 0.0195
09/16 07:04:38 AM: Update 21577: task edges-ner-ontonotes, batch 577 (21577): mcc: 0.9327, acc: 0.8995, precision: 0.9513, recall: 0.9216, f1: 0.9362, edges-ner-ontonotes_loss: 0.0224
09/16 07:04:48 AM: Update 21428: task edges-ner-ontonotes, batch 428 (21428): mcc: 0.9382, acc: 0.9061, precision: 0.9549, recall: 0.9284, f1: 0.9415, edges-ner-ontonotes_loss: 0.0197
09/16 07:04:48 AM: Update 21649: task edges-ner-ontonotes, batch 649 (21649): mcc: 0.9292, acc: 0.8950, precision: 0.9488, recall: 0.9176, f1: 0.9329, edges-ner-ontonotes_loss: 0.0237
09/16 07:04:58 AM: Update 21482: task edges-ner-ontonotes, batch 482 (21482): mcc: 0.9380, acc: 0.9062, precision: 0.9551, recall: 0.9279, f1: 0.9413, edges-ner-ontonotes_loss: 0.0199
09/16 07:04:58 AM: Update 21726: task edges-ner-ontonotes, batch 726 (21726): mcc: 0.9266, acc: 0.8917, precision: 0.9471, recall: 0.9144, f1: 0.9305, edges-ner-ontonotes_loss: 0.0250
09/16 07:05:08 AM: Update 21567: task edges-ner-ontonotes, batch 567 (21567): mcc: 0.9331, acc: 0.9000, precision: 0.9518, recall: 0.9220, f1: 0.9367, edges-ner-ontonotes_loss: 0.0222
09/16 07:05:08 AM: Update 21786: task edges-ner-ontonotes, batch 786 (21786): mcc: 0.9251, acc: 0.8899, precision: 0.9462, recall: 0.9125, f1: 0.9290, edges-ner-ontonotes_loss: 0.0256
09/16 07:05:18 AM: Update 21643: task edges-ner-ontonotes, batch 643 (21643): mcc: 0.9293, acc: 0.8952, precision: 0.9489, recall: 0.9178, f1: 0.9331, edges-ner-ontonotes_loss: 0.0236
09/16 07:05:18 AM: Update 21869: task edges-ner-ontonotes, batch 869 (21869): mcc: 0.9241, acc: 0.8884, precision: 0.9454, recall: 0.9113, f1: 0.9281, edges-ner-ontonotes_loss: 0.0260
09/16 07:05:28 AM: Update 21721: task edges-ner-ontonotes, batch 721 (21721): mcc: 0.9267, acc: 0.8919, precision: 0.9472, recall: 0.9145, f1: 0.9306, edges-ner-ontonotes_loss: 0.0249
09/16 07:05:28 AM: Update 21954: task edges-ner-ontonotes, batch 954 (21954): mcc: 0.9231, acc: 0.8872, precision: 0.9446, recall: 0.9103, f1: 0.9271, edges-ner-ontonotes_loss: 0.0262
09/16 07:05:34 AM: ***** Step 22000 / Validation 22 *****
09/16 07:05:34 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:05:34 AM: Validating...
09/16 07:05:38 AM: Evaluate: task edges-ner-ontonotes, batch 34 (157): mcc: 0.9009, acc: 0.8721, precision: 0.9203, recall: 0.8925, f1: 0.9062, edges-ner-ontonotes_loss: 0.0314
09/16 07:05:39 AM: Update 21785: task edges-ner-ontonotes, batch 785 (21785): mcc: 0.9252, acc: 0.8901, precision: 0.9463, recall: 0.9126, f1: 0.9292, edges-ner-ontonotes_loss: 0.0256
09/16 07:05:49 AM: Evaluate: task edges-ner-ontonotes, batch 94 (157): mcc: 0.9302, acc: 0.9029, precision: 0.9490, recall: 0.9192, f1: 0.9339, edges-ner-ontonotes_loss: 0.0239
09/16 07:05:49 AM: Update 21844: task edges-ner-ontonotes, batch 844 (21844): mcc: 0.9246, acc: 0.8891, precision: 0.9458, recall: 0.9119, f1: 0.9285, edges-ner-ontonotes_loss: 0.0258
09/16 07:05:59 AM: Evaluate: task edges-ner-ontonotes, batch 147 (157): mcc: 0.9369, acc: 0.9109, precision: 0.9550, recall: 0.9259, f1: 0.9402, edges-ner-ontonotes_loss: 0.0212
09/16 07:06:00 AM: Update 21908: task edges-ner-ontonotes, batch 908 (21908): mcc: 0.9235, acc: 0.8876, precision: 0.9451, recall: 0.9106, f1: 0.9275, edges-ner-ontonotes_loss: 0.0261
09/16 07:06:00 AM: Updating LR scheduler:
09/16 07:06:00 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:06:00 AM: 	# validation passes without improvement: 1
09/16 07:06:00 AM: edges-ner-ontonotes_loss: training: 0.026335 validation: 0.020664
09/16 07:06:00 AM: macro_avg: validation: 0.941199
09/16 07:06:00 AM: micro_avg: validation: 0.000000
09/16 07:06:00 AM: edges-ner-ontonotes_mcc: training: 0.922768 validation: 0.937913
09/16 07:06:00 AM: edges-ner-ontonotes_acc: training: 0.886709 validation: 0.912269
09/16 07:06:00 AM: edges-ner-ontonotes_precision: training: 0.944417 validation: 0.955540
09/16 07:06:00 AM: edges-ner-ontonotes_recall: training: 0.909846 validation: 0.927282
09/16 07:06:00 AM: edges-ner-ontonotes_f1: training: 0.926809 validation: 0.941199
09/16 07:06:00 AM: Global learning rate: 5e-05
09/16 07:06:00 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:06:09 AM: Update 22074: task edges-ner-ontonotes, batch 74 (22074): mcc: 0.9172, acc: 0.8807, precision: 0.9430, recall: 0.9009, f1: 0.9215, edges-ner-ontonotes_loss: 0.0271
09/16 07:06:10 AM: Update 21993: task edges-ner-ontonotes, batch 993 (21993): mcc: 0.9228, acc: 0.8867, precision: 0.9445, recall: 0.9099, f1: 0.9269, edges-ner-ontonotes_loss: 0.0263
09/16 07:06:11 AM: ***** Step 22000 / Validation 22 *****
09/16 07:06:11 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:06:11 AM: Validating...
09/16 07:06:19 AM: Update 22118: task edges-ner-ontonotes, batch 118 (22118): mcc: 0.9171, acc: 0.8795, precision: 0.9422, recall: 0.9013, f1: 0.9213, edges-ner-ontonotes_loss: 0.0268
09/16 07:06:20 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.9239, acc: 0.8980, precision: 0.9399, recall: 0.9164, f1: 0.9280, edges-ner-ontonotes_loss: 0.0260
09/16 07:06:29 AM: Update 22177: task edges-ner-ontonotes, batch 177 (22177): mcc: 0.9190, acc: 0.8820, precision: 0.9424, recall: 0.9048, f1: 0.9232, edges-ner-ontonotes_loss: 0.0261
09/16 07:06:30 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9301, acc: 0.9018, precision: 0.9498, recall: 0.9183, f1: 0.9338, edges-ner-ontonotes_loss: 0.0231
09/16 07:06:38 AM: Updating LR scheduler:
09/16 07:06:38 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:06:38 AM: 	# validation passes without improvement: 1
09/16 07:06:38 AM: edges-ner-ontonotes_loss: training: 0.026335 validation: 0.020664
09/16 07:06:38 AM: macro_avg: validation: 0.941199
09/16 07:06:38 AM: micro_avg: validation: 0.000000
09/16 07:06:38 AM: edges-ner-ontonotes_mcc: training: 0.922768 validation: 0.937913
09/16 07:06:38 AM: edges-ner-ontonotes_acc: training: 0.886709 validation: 0.912269
09/16 07:06:38 AM: edges-ner-ontonotes_precision: training: 0.944417 validation: 0.955540
09/16 07:06:38 AM: edges-ner-ontonotes_recall: training: 0.909846 validation: 0.927282
09/16 07:06:38 AM: edges-ner-ontonotes_f1: training: 0.926809 validation: 0.941199
09/16 07:06:38 AM: Global learning rate: 5e-05
09/16 07:06:38 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:06:39 AM: Update 22239: task edges-ner-ontonotes, batch 239 (22239): mcc: 0.9190, acc: 0.8821, precision: 0.9418, recall: 0.9054, f1: 0.9233, edges-ner-ontonotes_loss: 0.0257
09/16 07:06:40 AM: Update 22001: task edges-ner-ontonotes, batch 1 (22001): mcc: 0.9690, acc: 0.9565, precision: 0.9851, recall: 0.9565, f1: 0.9706, edges-ner-ontonotes_loss: 0.0138
09/16 07:06:49 AM: Update 22320: task edges-ner-ontonotes, batch 320 (22320): mcc: 0.9214, acc: 0.8854, precision: 0.9434, recall: 0.9083, f1: 0.9256, edges-ner-ontonotes_loss: 0.0251
09/16 07:06:50 AM: Update 22085: task edges-ner-ontonotes, batch 85 (22085): mcc: 0.9180, acc: 0.8818, precision: 0.9435, recall: 0.9019, f1: 0.9222, edges-ner-ontonotes_loss: 0.0268
09/16 07:06:59 AM: Update 22403: task edges-ner-ontonotes, batch 403 (22403): mcc: 0.9227, acc: 0.8878, precision: 0.9444, recall: 0.9098, f1: 0.9268, edges-ner-ontonotes_loss: 0.0247
09/16 07:07:00 AM: Update 22136: task edges-ner-ontonotes, batch 136 (22136): mcc: 0.9172, acc: 0.8797, precision: 0.9425, recall: 0.9013, f1: 0.9215, edges-ner-ontonotes_loss: 0.0267
09/16 07:07:09 AM: Update 22457: task edges-ner-ontonotes, batch 457 (22457): mcc: 0.9245, acc: 0.8896, precision: 0.9455, recall: 0.9119, f1: 0.9284, edges-ner-ontonotes_loss: 0.0242
09/16 07:07:10 AM: Update 22217: task edges-ner-ontonotes, batch 217 (22217): mcc: 0.9208, acc: 0.8848, precision: 0.9432, recall: 0.9074, f1: 0.9250, edges-ner-ontonotes_loss: 0.0257
09/16 07:07:19 AM: Update 22528: task edges-ner-ontonotes, batch 528 (22528): mcc: 0.9268, acc: 0.8923, precision: 0.9474, recall: 0.9146, f1: 0.9307, edges-ner-ontonotes_loss: 0.0235
09/16 07:07:20 AM: Update 22288: task edges-ner-ontonotes, batch 288 (22288): mcc: 0.9213, acc: 0.8851, precision: 0.9438, recall: 0.9077, f1: 0.9254, edges-ner-ontonotes_loss: 0.0252
09/16 07:07:29 AM: Update 22600: task edges-ner-ontonotes, batch 600 (22600): mcc: 0.9287, acc: 0.8946, precision: 0.9486, recall: 0.9168, f1: 0.9324, edges-ner-ontonotes_loss: 0.0229
09/16 07:07:30 AM: Update 22359: task edges-ner-ontonotes, batch 359 (22359): mcc: 0.9209, acc: 0.8852, precision: 0.9429, recall: 0.9078, f1: 0.9250, edges-ner-ontonotes_loss: 0.0252
09/16 07:07:40 AM: Update 22678: task edges-ner-ontonotes, batch 678 (22678): mcc: 0.9308, acc: 0.8972, precision: 0.9501, recall: 0.9194, f1: 0.9345, edges-ner-ontonotes_loss: 0.0223
09/16 07:07:42 AM: Update 22417: task edges-ner-ontonotes, batch 417 (22417): mcc: 0.9227, acc: 0.8877, precision: 0.9443, recall: 0.9099, f1: 0.9268, edges-ner-ontonotes_loss: 0.0246
09/16 07:07:50 AM: Update 22738: task edges-ner-ontonotes, batch 738 (22738): mcc: 0.9320, acc: 0.8988, precision: 0.9507, recall: 0.9209, f1: 0.9356, edges-ner-ontonotes_loss: 0.0219
09/16 07:07:53 AM: Update 22491: task edges-ner-ontonotes, batch 491 (22491): mcc: 0.9257, acc: 0.8910, precision: 0.9464, recall: 0.9134, f1: 0.9296, edges-ner-ontonotes_loss: 0.0239
09/16 07:08:00 AM: Update 22816: task edges-ner-ontonotes, batch 816 (22816): mcc: 0.9324, acc: 0.8995, precision: 0.9510, recall: 0.9214, f1: 0.9360, edges-ner-ontonotes_loss: 0.0218
09/16 07:08:04 AM: Update 22564: task edges-ner-ontonotes, batch 564 (22564): mcc: 0.9279, acc: 0.8936, precision: 0.9482, recall: 0.9157, f1: 0.9317, edges-ner-ontonotes_loss: 0.0232
09/16 07:08:10 AM: Update 22888: task edges-ner-ontonotes, batch 888 (22888): mcc: 0.9328, acc: 0.8999, precision: 0.9513, recall: 0.9219, f1: 0.9364, edges-ner-ontonotes_loss: 0.0216
09/16 07:08:14 AM: Update 22636: task edges-ner-ontonotes, batch 636 (22636): mcc: 0.9297, acc: 0.8958, precision: 0.9495, recall: 0.9179, f1: 0.9334, edges-ner-ontonotes_loss: 0.0227
09/16 07:08:20 AM: Update 22958: task edges-ner-ontonotes, batch 958 (22958): mcc: 0.9334, acc: 0.9005, precision: 0.9518, recall: 0.9225, f1: 0.9369, edges-ner-ontonotes_loss: 0.0214
09/16 07:08:24 AM: Update 22709: task edges-ner-ontonotes, batch 709 (22709): mcc: 0.9315, acc: 0.8981, precision: 0.9504, recall: 0.9203, f1: 0.9351, edges-ner-ontonotes_loss: 0.0221
09/16 07:08:26 AM: ***** Step 23000 / Validation 23 *****
09/16 07:08:26 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:08:26 AM: Validating...
09/16 07:08:30 AM: Evaluate: task edges-ner-ontonotes, batch 36 (157): mcc: 0.9002, acc: 0.8714, precision: 0.9183, recall: 0.8932, f1: 0.9055, edges-ner-ontonotes_loss: 0.0334
09/16 07:08:35 AM: Update 22750: task edges-ner-ontonotes, batch 750 (22750): mcc: 0.9318, acc: 0.8986, precision: 0.9505, recall: 0.9208, f1: 0.9354, edges-ner-ontonotes_loss: 0.0219
09/16 07:08:40 AM: Evaluate: task edges-ner-ontonotes, batch 92 (157): mcc: 0.9283, acc: 0.9005, precision: 0.9450, recall: 0.9197, f1: 0.9322, edges-ner-ontonotes_loss: 0.0256
09/16 07:08:45 AM: Update 22806: task edges-ner-ontonotes, batch 806 (22806): mcc: 0.9322, acc: 0.8992, precision: 0.9508, recall: 0.9212, f1: 0.9358, edges-ner-ontonotes_loss: 0.0218
09/16 07:08:50 AM: Evaluate: task edges-ner-ontonotes, batch 142 (157): mcc: 0.9375, acc: 0.9126, precision: 0.9515, recall: 0.9305, f1: 0.9409, edges-ner-ontonotes_loss: 0.0217
09/16 07:08:53 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:08:53 AM: Best result seen so far for macro.
09/16 07:08:53 AM: Updating LR scheduler:
09/16 07:08:53 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:08:53 AM: 	# validation passes without improvement: 2
09/16 07:08:53 AM: edges-ner-ontonotes_loss: training: 0.021376 validation: 0.021042
09/16 07:08:53 AM: macro_avg: validation: 0.941942
09/16 07:08:53 AM: micro_avg: validation: 0.000000
09/16 07:08:53 AM: edges-ner-ontonotes_mcc: training: 0.933754 validation: 0.938618
09/16 07:08:53 AM: edges-ner-ontonotes_acc: training: 0.900781 validation: 0.913861
09/16 07:08:53 AM: edges-ner-ontonotes_precision: training: 0.952273 validation: 0.951563
09/16 07:08:53 AM: edges-ner-ontonotes_recall: training: 0.922699 validation: 0.932514
09/16 07:08:53 AM: edges-ner-ontonotes_f1: training: 0.937253 validation: 0.941942
09/16 07:08:53 AM: Global learning rate: 5e-05
09/16 07:08:53 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:08:55 AM: Update 22864: task edges-ner-ontonotes, batch 864 (22864): mcc: 0.9328, acc: 0.8997, precision: 0.9513, recall: 0.9218, f1: 0.9363, edges-ner-ontonotes_loss: 0.0216
09/16 07:09:01 AM: Update 23037: task edges-ner-ontonotes, batch 37 (23037): mcc: 0.9353, acc: 0.8990, precision: 0.9542, recall: 0.9237, f1: 0.9387, edges-ner-ontonotes_loss: 0.0202
09/16 07:09:05 AM: Update 22942: task edges-ner-ontonotes, batch 942 (22942): mcc: 0.9333, acc: 0.9003, precision: 0.9518, recall: 0.9223, f1: 0.9368, edges-ner-ontonotes_loss: 0.0215
09/16 07:09:11 AM: Update 23106: task edges-ner-ontonotes, batch 106 (23106): mcc: 0.9093, acc: 0.8673, precision: 0.9370, recall: 0.8920, f1: 0.9139, edges-ner-ontonotes_loss: 0.0311
09/16 07:09:13 AM: ***** Step 23000 / Validation 23 *****
09/16 07:09:14 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:09:14 AM: Validating...
09/16 07:09:15 AM: Evaluate: task edges-ner-ontonotes, batch 8 (157): mcc: 0.8358, acc: 0.7909, precision: 0.8707, recall: 0.8194, f1: 0.8443, edges-ner-ontonotes_loss: 0.0440
09/16 07:09:21 AM: Update 23175: task edges-ner-ontonotes, batch 175 (23175): mcc: 0.9085, acc: 0.8666, precision: 0.9365, recall: 0.8909, f1: 0.9131, edges-ner-ontonotes_loss: 0.0315
09/16 07:09:25 AM: Evaluate: task edges-ner-ontonotes, batch 65 (157): mcc: 0.9198, acc: 0.8919, precision: 0.9350, recall: 0.9137, f1: 0.9242, edges-ner-ontonotes_loss: 0.0284
09/16 07:09:31 AM: Update 23230: task edges-ner-ontonotes, batch 230 (23230): mcc: 0.9065, acc: 0.8644, precision: 0.9350, recall: 0.8887, f1: 0.9112, edges-ner-ontonotes_loss: 0.0322
09/16 07:09:35 AM: Evaluate: task edges-ner-ontonotes, batch 116 (157): mcc: 0.9307, acc: 0.9031, precision: 0.9463, recall: 0.9229, f1: 0.9344, edges-ner-ontonotes_loss: 0.0239
09/16 07:09:41 AM: Update 23289: task edges-ner-ontonotes, batch 289 (23289): mcc: 0.9064, acc: 0.8648, precision: 0.9343, recall: 0.8891, f1: 0.9111, edges-ner-ontonotes_loss: 0.0322
09/16 07:09:42 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:09:42 AM: Best result seen so far for macro.
09/16 07:09:42 AM: Updating LR scheduler:
09/16 07:09:42 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:09:42 AM: 	# validation passes without improvement: 2
09/16 07:09:42 AM: edges-ner-ontonotes_loss: training: 0.021376 validation: 0.021042
09/16 07:09:42 AM: macro_avg: validation: 0.941942
09/16 07:09:42 AM: micro_avg: validation: 0.000000
09/16 07:09:42 AM: edges-ner-ontonotes_mcc: training: 0.933754 validation: 0.938618
09/16 07:09:42 AM: edges-ner-ontonotes_acc: training: 0.900781 validation: 0.913861
09/16 07:09:42 AM: edges-ner-ontonotes_precision: training: 0.952273 validation: 0.951563
09/16 07:09:42 AM: edges-ner-ontonotes_recall: training: 0.922699 validation: 0.932514
09/16 07:09:42 AM: edges-ner-ontonotes_f1: training: 0.937253 validation: 0.941942
09/16 07:09:42 AM: Global learning rate: 5e-05
09/16 07:09:42 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:09:45 AM: Update 23024: task edges-ner-ontonotes, batch 24 (23024): mcc: 0.9381, acc: 0.9050, precision: 0.9539, recall: 0.9293, f1: 0.9414, edges-ner-ontonotes_loss: 0.0195
09/16 07:09:51 AM: Update 23344: task edges-ner-ontonotes, batch 344 (23344): mcc: 0.9050, acc: 0.8628, precision: 0.9336, recall: 0.8873, f1: 0.9099, edges-ner-ontonotes_loss: 0.0327
09/16 07:09:55 AM: Update 23079: task edges-ner-ontonotes, batch 79 (23079): mcc: 0.9144, acc: 0.8740, precision: 0.9404, recall: 0.8982, f1: 0.9188, edges-ner-ontonotes_loss: 0.0294
09/16 07:10:01 AM: Update 23428: task edges-ner-ontonotes, batch 428 (23428): mcc: 0.9056, acc: 0.8634, precision: 0.9336, recall: 0.8883, f1: 0.9104, edges-ner-ontonotes_loss: 0.0319
09/16 07:10:05 AM: Update 23159: task edges-ner-ontonotes, batch 159 (23159): mcc: 0.9093, acc: 0.8680, precision: 0.9369, recall: 0.8919, f1: 0.9139, edges-ner-ontonotes_loss: 0.0312
09/16 07:10:11 AM: Update 23512: task edges-ner-ontonotes, batch 512 (23512): mcc: 0.9058, acc: 0.8642, precision: 0.9335, recall: 0.8888, f1: 0.9106, edges-ner-ontonotes_loss: 0.0315
09/16 07:10:15 AM: Update 23236: task edges-ner-ontonotes, batch 236 (23236): mcc: 0.9070, acc: 0.8652, precision: 0.9353, recall: 0.8892, f1: 0.9117, edges-ner-ontonotes_loss: 0.0321
09/16 07:10:21 AM: Update 23597: task edges-ner-ontonotes, batch 597 (23597): mcc: 0.9060, acc: 0.8640, precision: 0.9339, recall: 0.8888, f1: 0.9108, edges-ner-ontonotes_loss: 0.0311
09/16 07:10:26 AM: Update 23322: task edges-ner-ontonotes, batch 322 (23322): mcc: 0.9064, acc: 0.8646, precision: 0.9342, recall: 0.8892, f1: 0.9112, edges-ner-ontonotes_loss: 0.0325
09/16 07:10:31 AM: Update 23660: task edges-ner-ontonotes, batch 660 (23660): mcc: 0.9065, acc: 0.8648, precision: 0.9341, recall: 0.8897, f1: 0.9113, edges-ner-ontonotes_loss: 0.0309
09/16 07:10:36 AM: Update 23375: task edges-ner-ontonotes, batch 375 (23375): mcc: 0.9048, acc: 0.8624, precision: 0.9333, recall: 0.8872, f1: 0.9097, edges-ner-ontonotes_loss: 0.0325
09/16 07:10:42 AM: Update 23745: task edges-ner-ontonotes, batch 745 (23745): mcc: 0.9093, acc: 0.8684, precision: 0.9358, recall: 0.8931, f1: 0.9140, edges-ner-ontonotes_loss: 0.0300
09/16 07:10:47 AM: Update 23468: task edges-ner-ontonotes, batch 468 (23468): mcc: 0.9056, acc: 0.8636, precision: 0.9337, recall: 0.8883, f1: 0.9104, edges-ner-ontonotes_loss: 0.0318
09/16 07:10:54 AM: Update 23828: task edges-ner-ontonotes, batch 828 (23828): mcc: 0.9110, acc: 0.8707, precision: 0.9372, recall: 0.8950, f1: 0.9156, edges-ner-ontonotes_loss: 0.0294
09/16 07:10:57 AM: Update 23552: task edges-ner-ontonotes, batch 552 (23552): mcc: 0.9059, acc: 0.8642, precision: 0.9337, recall: 0.8888, f1: 0.9107, edges-ner-ontonotes_loss: 0.0313
09/16 07:11:04 AM: Update 23910: task edges-ner-ontonotes, batch 910 (23910): mcc: 0.9121, acc: 0.8723, precision: 0.9379, recall: 0.8964, f1: 0.9167, edges-ner-ontonotes_loss: 0.0289
09/16 07:11:07 AM: Update 23634: task edges-ner-ontonotes, batch 634 (23634): mcc: 0.9060, acc: 0.8640, precision: 0.9338, recall: 0.8888, f1: 0.9108, edges-ner-ontonotes_loss: 0.0311
09/16 07:11:14 AM: Update 23968: task edges-ner-ontonotes, batch 968 (23968): mcc: 0.9132, acc: 0.8738, precision: 0.9384, recall: 0.8978, f1: 0.9177, edges-ner-ontonotes_loss: 0.0286
09/16 07:11:17 AM: Update 23694: task edges-ner-ontonotes, batch 694 (23694): mcc: 0.9077, acc: 0.8663, precision: 0.9350, recall: 0.8909, f1: 0.9124, edges-ner-ontonotes_loss: 0.0306
09/16 07:11:19 AM: ***** Step 24000 / Validation 24 *****
09/16 07:11:19 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:11:19 AM: Validating...
09/16 07:11:24 AM: Evaluate: task edges-ner-ontonotes, batch 36 (157): mcc: 0.9015, acc: 0.8718, precision: 0.9203, recall: 0.8936, f1: 0.9068, edges-ner-ontonotes_loss: 0.0318
09/16 07:11:27 AM: Update 23753: task edges-ner-ontonotes, batch 753 (23753): mcc: 0.9094, acc: 0.8686, precision: 0.9360, recall: 0.8931, f1: 0.9140, edges-ner-ontonotes_loss: 0.0300
09/16 07:11:34 AM: Evaluate: task edges-ner-ontonotes, batch 92 (157): mcc: 0.9290, acc: 0.9008, precision: 0.9450, recall: 0.9209, f1: 0.9328, edges-ner-ontonotes_loss: 0.0248
09/16 07:11:37 AM: Update 23810: task edges-ner-ontonotes, batch 810 (23810): mcc: 0.9106, acc: 0.8702, precision: 0.9368, recall: 0.8946, f1: 0.9152, edges-ner-ontonotes_loss: 0.0296
09/16 07:11:44 AM: Evaluate: task edges-ner-ontonotes, batch 143 (157): mcc: 0.9374, acc: 0.9119, precision: 0.9519, recall: 0.9300, f1: 0.9408, edges-ner-ontonotes_loss: 0.0213
09/16 07:11:46 AM: Updating LR scheduler:
09/16 07:11:46 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:11:46 AM: 	# validation passes without improvement: 3
09/16 07:11:46 AM: edges-ner-ontonotes_loss: training: 0.028251 validation: 0.020787
09/16 07:11:46 AM: macro_avg: validation: 0.941357
09/16 07:11:46 AM: micro_avg: validation: 0.000000
09/16 07:11:46 AM: edges-ner-ontonotes_mcc: training: 0.914243 validation: 0.938010
09/16 07:11:46 AM: edges-ner-ontonotes_acc: training: 0.875157 validation: 0.912572
09/16 07:11:46 AM: edges-ner-ontonotes_precision: training: 0.939182 validation: 0.951790
09/16 07:11:46 AM: edges-ner-ontonotes_recall: training: 0.899040 validation: 0.931150
09/16 07:11:46 AM: edges-ner-ontonotes_f1: training: 0.918673 validation: 0.941357
09/16 07:11:46 AM: Global learning rate: 5e-05
09/16 07:11:46 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:11:47 AM: Update 23869: task edges-ner-ontonotes, batch 869 (23869): mcc: 0.9116, acc: 0.8714, precision: 0.9374, recall: 0.8958, f1: 0.9161, edges-ner-ontonotes_loss: 0.0291
09/16 07:11:54 AM: Update 24072: task edges-ner-ontonotes, batch 72 (24072): mcc: 0.9420, acc: 0.9121, precision: 0.9565, recall: 0.9340, f1: 0.9451, edges-ner-ontonotes_loss: 0.0190
09/16 07:12:01 AM: Update 23945: task edges-ner-ontonotes, batch 945 (23945): mcc: 0.9130, acc: 0.8734, precision: 0.9383, recall: 0.8976, f1: 0.9175, edges-ner-ontonotes_loss: 0.0286
09/16 07:12:05 AM: Update 24151: task edges-ner-ontonotes, batch 151 (24151): mcc: 0.9438, acc: 0.9145, precision: 0.9575, recall: 0.9363, f1: 0.9468, edges-ner-ontonotes_loss: 0.0185
09/16 07:12:12 AM: Update 23995: task edges-ner-ontonotes, batch 995 (23995): mcc: 0.9141, acc: 0.8750, precision: 0.9391, recall: 0.8988, f1: 0.9185, edges-ner-ontonotes_loss: 0.0283
09/16 07:12:13 AM: ***** Step 24000 / Validation 24 *****
09/16 07:12:13 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:12:13 AM: Validating...
09/16 07:12:15 AM: Update 24230: task edges-ner-ontonotes, batch 230 (24230): mcc: 0.9420, acc: 0.9121, precision: 0.9567, recall: 0.9338, f1: 0.9451, edges-ner-ontonotes_loss: 0.0187
09/16 07:12:22 AM: Evaluate: task edges-ner-ontonotes, batch 54 (157): mcc: 0.9160, acc: 0.8881, precision: 0.9314, recall: 0.9100, f1: 0.9206, edges-ner-ontonotes_loss: 0.0285
09/16 07:12:27 AM: Update 24280: task edges-ner-ontonotes, batch 280 (24280): mcc: 0.9417, acc: 0.9119, precision: 0.9567, recall: 0.9332, f1: 0.9448, edges-ner-ontonotes_loss: 0.0188
09/16 07:12:33 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9299, acc: 0.9013, precision: 0.9460, recall: 0.9216, f1: 0.9336, edges-ner-ontonotes_loss: 0.0235
09/16 07:12:37 AM: Update 24331: task edges-ner-ontonotes, batch 331 (24331): mcc: 0.9400, acc: 0.9090, precision: 0.9556, recall: 0.9310, f1: 0.9432, edges-ner-ontonotes_loss: 0.0191
09/16 07:12:41 AM: Updating LR scheduler:
09/16 07:12:41 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:12:41 AM: 	# validation passes without improvement: 3
09/16 07:12:41 AM: edges-ner-ontonotes_loss: training: 0.028251 validation: 0.020787
09/16 07:12:41 AM: macro_avg: validation: 0.941357
09/16 07:12:41 AM: micro_avg: validation: 0.000000
09/16 07:12:41 AM: edges-ner-ontonotes_mcc: training: 0.914243 validation: 0.938010
09/16 07:12:41 AM: edges-ner-ontonotes_acc: training: 0.875157 validation: 0.912572
09/16 07:12:41 AM: edges-ner-ontonotes_precision: training: 0.939182 validation: 0.951790
09/16 07:12:41 AM: edges-ner-ontonotes_recall: training: 0.899040 validation: 0.931150
09/16 07:12:41 AM: edges-ner-ontonotes_f1: training: 0.918673 validation: 0.941357
09/16 07:12:41 AM: Global learning rate: 5e-05
09/16 07:12:41 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:12:43 AM: Update 24018: task edges-ner-ontonotes, batch 18 (24018): mcc: 0.9451, acc: 0.9205, precision: 0.9545, recall: 0.9419, f1: 0.9481, edges-ner-ontonotes_loss: 0.0180
09/16 07:12:47 AM: Update 24398: task edges-ner-ontonotes, batch 398 (24398): mcc: 0.9407, acc: 0.9101, precision: 0.9560, recall: 0.9320, f1: 0.9438, edges-ner-ontonotes_loss: 0.0189
09/16 07:12:53 AM: Update 24089: task edges-ner-ontonotes, batch 89 (24089): mcc: 0.9442, acc: 0.9156, precision: 0.9578, recall: 0.9369, f1: 0.9472, edges-ner-ontonotes_loss: 0.0183
09/16 07:12:57 AM: Update 24471: task edges-ner-ontonotes, batch 471 (24471): mcc: 0.9396, acc: 0.9084, precision: 0.9554, recall: 0.9306, f1: 0.9428, edges-ner-ontonotes_loss: 0.0192
09/16 07:13:03 AM: Update 24167: task edges-ner-ontonotes, batch 167 (24167): mcc: 0.9428, acc: 0.9139, precision: 0.9570, recall: 0.9350, f1: 0.9459, edges-ner-ontonotes_loss: 0.0187
09/16 07:13:08 AM: Update 24544: task edges-ner-ontonotes, batch 544 (24544): mcc: 0.9396, acc: 0.9084, precision: 0.9556, recall: 0.9304, f1: 0.9428, edges-ner-ontonotes_loss: 0.0192
09/16 07:13:13 AM: Update 24247: task edges-ner-ontonotes, batch 247 (24247): mcc: 0.9419, acc: 0.9119, precision: 0.9570, recall: 0.9332, f1: 0.9450, edges-ner-ontonotes_loss: 0.0186
09/16 07:13:19 AM: Update 24615: task edges-ner-ontonotes, batch 615 (24615): mcc: 0.9376, acc: 0.9061, precision: 0.9546, recall: 0.9276, f1: 0.9409, edges-ner-ontonotes_loss: 0.0200
09/16 07:13:24 AM: Update 24307: task edges-ner-ontonotes, batch 307 (24307): mcc: 0.9404, acc: 0.9099, precision: 0.9561, recall: 0.9314, f1: 0.9436, edges-ner-ontonotes_loss: 0.0190
09/16 07:13:31 AM: Update 24687: task edges-ner-ontonotes, batch 687 (24687): mcc: 0.9343, acc: 0.9018, precision: 0.9524, recall: 0.9236, f1: 0.9378, edges-ner-ontonotes_loss: 0.0217
09/16 07:13:34 AM: Update 24385: task edges-ner-ontonotes, batch 385 (24385): mcc: 0.9405, acc: 0.9098, precision: 0.9558, recall: 0.9319, f1: 0.9437, edges-ner-ontonotes_loss: 0.0189
09/16 07:13:42 AM: Update 24765: task edges-ner-ontonotes, batch 765 (24765): mcc: 0.9318, acc: 0.8986, precision: 0.9510, recall: 0.9203, f1: 0.9354, edges-ner-ontonotes_loss: 0.0230
09/16 07:13:44 AM: Update 24466: task edges-ner-ontonotes, batch 466 (24466): mcc: 0.9396, acc: 0.9085, precision: 0.9553, recall: 0.9307, f1: 0.9429, edges-ner-ontonotes_loss: 0.0192
09/16 07:13:53 AM: Update 24837: task edges-ner-ontonotes, batch 837 (24837): mcc: 0.9296, acc: 0.8957, precision: 0.9497, recall: 0.9175, f1: 0.9333, edges-ner-ontonotes_loss: 0.0239
09/16 07:13:54 AM: Update 24540: task edges-ner-ontonotes, batch 540 (24540): mcc: 0.9396, acc: 0.9085, precision: 0.9555, recall: 0.9304, f1: 0.9428, edges-ner-ontonotes_loss: 0.0192
09/16 07:14:03 AM: Update 24897: task edges-ner-ontonotes, batch 897 (24897): mcc: 0.9279, acc: 0.8935, precision: 0.9486, recall: 0.9154, f1: 0.9317, edges-ner-ontonotes_loss: 0.0246
09/16 07:14:04 AM: Update 24604: task edges-ner-ontonotes, batch 604 (24604): mcc: 0.9381, acc: 0.9066, precision: 0.9549, recall: 0.9281, f1: 0.9413, edges-ner-ontonotes_loss: 0.0197
09/16 07:14:13 AM: Update 24978: task edges-ner-ontonotes, batch 978 (24978): mcc: 0.9268, acc: 0.8922, precision: 0.9475, recall: 0.9144, f1: 0.9307, edges-ner-ontonotes_loss: 0.0250
09/16 07:14:14 AM: Update 24684: task edges-ner-ontonotes, batch 684 (24684): mcc: 0.9344, acc: 0.9020, precision: 0.9525, recall: 0.9237, f1: 0.9379, edges-ner-ontonotes_loss: 0.0216
09/16 07:14:16 AM: ***** Step 25000 / Validation 25 *****
09/16 07:14:16 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:14:16 AM: Validating...
09/16 07:14:23 AM: Evaluate: task edges-ner-ontonotes, batch 45 (157): mcc: 0.9115, acc: 0.8848, precision: 0.9268, recall: 0.9060, f1: 0.9163, edges-ner-ontonotes_loss: 0.0293
09/16 07:14:24 AM: Update 24750: task edges-ner-ontonotes, batch 750 (24750): mcc: 0.9320, acc: 0.8987, precision: 0.9510, recall: 0.9206, f1: 0.9355, edges-ner-ontonotes_loss: 0.0229
09/16 07:14:34 AM: Evaluate: task edges-ner-ontonotes, batch 100 (157): mcc: 0.9276, acc: 0.8998, precision: 0.9454, recall: 0.9180, f1: 0.9315, edges-ner-ontonotes_loss: 0.0244
09/16 07:14:34 AM: Update 24804: task edges-ner-ontonotes, batch 804 (24804): mcc: 0.9304, acc: 0.8968, precision: 0.9501, recall: 0.9184, f1: 0.9340, edges-ner-ontonotes_loss: 0.0236
09/16 07:14:44 AM: Evaluate: task edges-ner-ontonotes, batch 154 (157): mcc: 0.9380, acc: 0.9128, precision: 0.9538, recall: 0.9292, f1: 0.9413, edges-ner-ontonotes_loss: 0.0209
09/16 07:14:44 AM: Updating LR scheduler:
09/16 07:14:44 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:14:44 AM: 	# validation passes without improvement: 0
09/16 07:14:44 AM: edges-ner-ontonotes_loss: training: 0.025026 validation: 0.020617
09/16 07:14:44 AM: macro_avg: validation: 0.941827
09/16 07:14:44 AM: micro_avg: validation: 0.000000
09/16 07:14:44 AM: edges-ner-ontonotes_mcc: training: 0.926707 validation: 0.938537
09/16 07:14:44 AM: edges-ner-ontonotes_acc: training: 0.892012 validation: 0.913558
09/16 07:14:44 AM: edges-ner-ontonotes_precision: training: 0.947596 validation: 0.954026
09/16 07:14:44 AM: edges-ner-ontonotes_recall: training: 0.914099 validation: 0.929936
09/16 07:14:44 AM: edges-ner-ontonotes_f1: training: 0.930546 validation: 0.941827
09/16 07:14:44 AM: Global learning rate: 2.5e-05
09/16 07:14:44 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:14:45 AM: Update 24861: task edges-ner-ontonotes, batch 861 (24861): mcc: 0.9290, acc: 0.8950, precision: 0.9492, recall: 0.9167, f1: 0.9327, edges-ner-ontonotes_loss: 0.0243
09/16 07:14:54 AM: Update 25093: task edges-ner-ontonotes, batch 93 (25093): mcc: 0.9108, acc: 0.8716, precision: 0.9363, recall: 0.8954, f1: 0.9154, edges-ner-ontonotes_loss: 0.0281
09/16 07:14:55 AM: Update 24917: task edges-ner-ontonotes, batch 917 (24917): mcc: 0.9275, acc: 0.8930, precision: 0.9482, recall: 0.9149, f1: 0.9313, edges-ner-ontonotes_loss: 0.0247
09/16 07:15:04 AM: ***** Step 25000 / Validation 25 *****
09/16 07:15:04 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:15:04 AM: Validating...
09/16 07:15:04 AM: Update 25183: task edges-ner-ontonotes, batch 183 (25183): mcc: 0.9106, acc: 0.8701, precision: 0.9373, recall: 0.8941, f1: 0.9152, edges-ner-ontonotes_loss: 0.0282
09/16 07:15:05 AM: Evaluate: task edges-ner-ontonotes, batch 5 (157): mcc: 0.8072, acc: 0.7433, precision: 0.8418, recall: 0.7940, f1: 0.8172, edges-ner-ontonotes_loss: 0.0480
09/16 07:15:14 AM: Update 25226: task edges-ner-ontonotes, batch 226 (25226): mcc: 0.9103, acc: 0.8696, precision: 0.9367, recall: 0.8940, f1: 0.9149, edges-ner-ontonotes_loss: 0.0280
09/16 07:15:15 AM: Evaluate: task edges-ner-ontonotes, batch 72 (157): mcc: 0.9224, acc: 0.8948, precision: 0.9392, recall: 0.9142, f1: 0.9265, edges-ner-ontonotes_loss: 0.0267
09/16 07:15:24 AM: Update 25279: task edges-ner-ontonotes, batch 279 (25279): mcc: 0.9136, acc: 0.8741, precision: 0.9384, recall: 0.8986, f1: 0.9181, edges-ner-ontonotes_loss: 0.0274
09/16 07:15:25 AM: Evaluate: task edges-ner-ontonotes, batch 122 (157): mcc: 0.9328, acc: 0.9058, precision: 0.9496, recall: 0.9236, f1: 0.9364, edges-ner-ontonotes_loss: 0.0226
09/16 07:15:31 AM: Updating LR scheduler:
09/16 07:15:31 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:15:31 AM: 	# validation passes without improvement: 0
09/16 07:15:31 AM: edges-ner-ontonotes_loss: training: 0.025026 validation: 0.020617
09/16 07:15:31 AM: macro_avg: validation: 0.941827
09/16 07:15:31 AM: micro_avg: validation: 0.000000
09/16 07:15:31 AM: edges-ner-ontonotes_mcc: training: 0.926707 validation: 0.938537
09/16 07:15:31 AM: edges-ner-ontonotes_acc: training: 0.892012 validation: 0.913558
09/16 07:15:31 AM: edges-ner-ontonotes_precision: training: 0.947596 validation: 0.954026
09/16 07:15:31 AM: edges-ner-ontonotes_recall: training: 0.914099 validation: 0.929936
09/16 07:15:31 AM: edges-ner-ontonotes_f1: training: 0.930546 validation: 0.941827
09/16 07:15:31 AM: Global learning rate: 2.5e-05
09/16 07:15:31 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:15:34 AM: Update 25343: task edges-ner-ontonotes, batch 343 (25343): mcc: 0.9156, acc: 0.8765, precision: 0.9396, recall: 0.9012, f1: 0.9200, edges-ner-ontonotes_loss: 0.0266
09/16 07:15:35 AM: Update 25033: task edges-ner-ontonotes, batch 33 (25033): mcc: 0.9154, acc: 0.8773, precision: 0.9399, recall: 0.9004, f1: 0.9197, edges-ner-ontonotes_loss: 0.0272
09/16 07:15:44 AM: Update 25427: task edges-ner-ontonotes, batch 427 (25427): mcc: 0.9189, acc: 0.8813, precision: 0.9418, recall: 0.9052, f1: 0.9231, edges-ner-ontonotes_loss: 0.0259
09/16 07:15:45 AM: Update 25119: task edges-ner-ontonotes, batch 119 (25119): mcc: 0.9095, acc: 0.8690, precision: 0.9357, recall: 0.8937, f1: 0.9142, edges-ner-ontonotes_loss: 0.0285
09/16 07:15:55 AM: Update 25509: task edges-ner-ontonotes, batch 509 (25509): mcc: 0.9199, acc: 0.8829, precision: 0.9424, recall: 0.9064, f1: 0.9240, edges-ner-ontonotes_loss: 0.0256
09/16 07:15:55 AM: Update 25202: task edges-ner-ontonotes, batch 202 (25202): mcc: 0.9094, acc: 0.8683, precision: 0.9360, recall: 0.8930, f1: 0.9140, edges-ner-ontonotes_loss: 0.0284
09/16 07:16:05 AM: Update 25559: task edges-ner-ontonotes, batch 559 (25559): mcc: 0.9214, acc: 0.8853, precision: 0.9433, recall: 0.9084, f1: 0.9255, edges-ner-ontonotes_loss: 0.0252
09/16 07:16:05 AM: Update 25256: task edges-ner-ontonotes, batch 256 (25256): mcc: 0.9122, acc: 0.8721, precision: 0.9379, recall: 0.8966, f1: 0.9167, edges-ner-ontonotes_loss: 0.0277
09/16 07:16:15 AM: Update 25631: task edges-ner-ontonotes, batch 631 (25631): mcc: 0.9236, acc: 0.8880, precision: 0.9446, recall: 0.9113, f1: 0.9276, edges-ner-ontonotes_loss: 0.0246
09/16 07:16:15 AM: Update 25326: task edges-ner-ontonotes, batch 326 (25326): mcc: 0.9150, acc: 0.8757, precision: 0.9389, recall: 0.9007, f1: 0.9194, edges-ner-ontonotes_loss: 0.0270
09/16 07:16:25 AM: Update 25708: task edges-ner-ontonotes, batch 708 (25708): mcc: 0.9260, acc: 0.8909, precision: 0.9462, recall: 0.9141, f1: 0.9299, edges-ner-ontonotes_loss: 0.0238
09/16 07:16:25 AM: Update 25404: task edges-ner-ontonotes, batch 404 (25404): mcc: 0.9183, acc: 0.8805, precision: 0.9415, recall: 0.9044, f1: 0.9226, edges-ner-ontonotes_loss: 0.0261
09/16 07:16:35 AM: Update 25781: task edges-ner-ontonotes, batch 781 (25781): mcc: 0.9277, acc: 0.8931, precision: 0.9476, recall: 0.9161, f1: 0.9315, edges-ner-ontonotes_loss: 0.0233
09/16 07:16:35 AM: Update 25479: task edges-ner-ontonotes, batch 479 (25479): mcc: 0.9199, acc: 0.8826, precision: 0.9425, recall: 0.9063, f1: 0.9240, edges-ner-ontonotes_loss: 0.0256
09/16 07:16:45 AM: Update 25843: task edges-ner-ontonotes, batch 843 (25843): mcc: 0.9293, acc: 0.8950, precision: 0.9488, recall: 0.9177, f1: 0.9330, edges-ner-ontonotes_loss: 0.0229
09/16 07:16:45 AM: Update 25536: task edges-ner-ontonotes, batch 536 (25536): mcc: 0.9204, acc: 0.8838, precision: 0.9426, recall: 0.9071, f1: 0.9245, edges-ner-ontonotes_loss: 0.0255
09/16 07:16:55 AM: Update 25916: task edges-ner-ontonotes, batch 916 (25916): mcc: 0.9302, acc: 0.8961, precision: 0.9493, recall: 0.9189, f1: 0.9338, edges-ner-ontonotes_loss: 0.0226
09/16 07:16:55 AM: Update 25606: task edges-ner-ontonotes, batch 606 (25606): mcc: 0.9227, acc: 0.8867, precision: 0.9440, recall: 0.9102, f1: 0.9268, edges-ner-ontonotes_loss: 0.0248
09/16 07:17:05 AM: Update 25989: task edges-ner-ontonotes, batch 989 (25989): mcc: 0.9304, acc: 0.8966, precision: 0.9493, recall: 0.9194, f1: 0.9341, edges-ner-ontonotes_loss: 0.0225
09/16 07:17:05 AM: Update 25680: task edges-ner-ontonotes, batch 680 (25680): mcc: 0.9255, acc: 0.8904, precision: 0.9460, recall: 0.9135, f1: 0.9294, edges-ner-ontonotes_loss: 0.0241
09/16 07:17:07 AM: ***** Step 26000 / Validation 26 *****
09/16 07:17:07 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:17:07 AM: Validating...
09/16 07:17:15 AM: Evaluate: task edges-ner-ontonotes, batch 56 (157): mcc: 0.9172, acc: 0.8879, precision: 0.9320, recall: 0.9116, f1: 0.9217, edges-ner-ontonotes_loss: 0.0290
09/16 07:17:16 AM: Update 25741: task edges-ner-ontonotes, batch 741 (25741): mcc: 0.9266, acc: 0.8918, precision: 0.9467, recall: 0.9148, f1: 0.9305, edges-ner-ontonotes_loss: 0.0237
09/16 07:17:25 AM: Evaluate: task edges-ner-ontonotes, batch 110 (157): mcc: 0.9295, acc: 0.9008, precision: 0.9449, recall: 0.9219, f1: 0.9333, edges-ner-ontonotes_loss: 0.0242
09/16 07:17:26 AM: Update 25797: task edges-ner-ontonotes, batch 797 (25797): mcc: 0.9280, acc: 0.8934, precision: 0.9478, recall: 0.9163, f1: 0.9318, edges-ner-ontonotes_loss: 0.0232
09/16 07:17:34 AM: Updating LR scheduler:
09/16 07:17:34 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:17:34 AM: 	# validation passes without improvement: 1
09/16 07:17:34 AM: edges-ner-ontonotes_loss: training: 0.022430 validation: 0.020968
09/16 07:17:34 AM: macro_avg: validation: 0.941826
09/16 07:17:34 AM: micro_avg: validation: 0.000000
09/16 07:17:34 AM: edges-ner-ontonotes_mcc: training: 0.930609 validation: 0.938504
09/16 07:17:34 AM: edges-ner-ontonotes_acc: training: 0.896873 validation: 0.912800
09/16 07:17:34 AM: edges-ner-ontonotes_precision: training: 0.949416 validation: 0.952115
09/16 07:17:34 AM: edges-ner-ontonotes_recall: training: 0.919614 validation: 0.931756
09/16 07:17:34 AM: edges-ner-ontonotes_f1: training: 0.934277 validation: 0.941826
09/16 07:17:34 AM: Global learning rate: 2.5e-05
09/16 07:17:34 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:17:36 AM: Update 26008: task edges-ner-ontonotes, batch 8 (26008): mcc: 0.9418, acc: 0.9025, precision: 0.9596, recall: 0.9307, f1: 0.9449, edges-ner-ontonotes_loss: 0.0162
09/16 07:17:36 AM: Update 25842: task edges-ner-ontonotes, batch 842 (25842): mcc: 0.9293, acc: 0.8951, precision: 0.9488, recall: 0.9177, f1: 0.9330, edges-ner-ontonotes_loss: 0.0229
09/16 07:17:46 AM: Update 26079: task edges-ner-ontonotes, batch 79 (26079): mcc: 0.9369, acc: 0.9038, precision: 0.9532, recall: 0.9276, f1: 0.9402, edges-ner-ontonotes_loss: 0.0197
09/16 07:17:46 AM: Update 25913: task edges-ner-ontonotes, batch 913 (25913): mcc: 0.9301, acc: 0.8961, precision: 0.9493, recall: 0.9189, f1: 0.9338, edges-ner-ontonotes_loss: 0.0226
09/16 07:17:56 AM: Update 25992: task edges-ner-ontonotes, batch 992 (25992): mcc: 0.9304, acc: 0.8966, precision: 0.9493, recall: 0.9194, f1: 0.9341, edges-ner-ontonotes_loss: 0.0225
09/16 07:17:57 AM: ***** Step 26000 / Validation 26 *****
09/16 07:17:57 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:17:57 AM: Validating...
09/16 07:17:58 AM: Update 26149: task edges-ner-ontonotes, batch 149 (26149): mcc: 0.9362, acc: 0.9036, precision: 0.9528, recall: 0.9269, f1: 0.9396, edges-ner-ontonotes_loss: 0.0197
09/16 07:18:06 AM: Evaluate: task edges-ner-ontonotes, batch 59 (157): mcc: 0.9193, acc: 0.8907, precision: 0.9342, recall: 0.9135, f1: 0.9237, edges-ner-ontonotes_loss: 0.0282
09/16 07:18:08 AM: Update 26204: task edges-ner-ontonotes, batch 204 (26204): mcc: 0.9273, acc: 0.8920, precision: 0.9479, recall: 0.9150, f1: 0.9311, edges-ner-ontonotes_loss: 0.0238
09/16 07:18:16 AM: Evaluate: task edges-ner-ontonotes, batch 108 (157): mcc: 0.9285, acc: 0.8994, precision: 0.9442, recall: 0.9208, f1: 0.9324, edges-ner-ontonotes_loss: 0.0244
09/16 07:18:18 AM: Update 26264: task edges-ner-ontonotes, batch 264 (26264): mcc: 0.9211, acc: 0.8841, precision: 0.9437, recall: 0.9075, f1: 0.9253, edges-ner-ontonotes_loss: 0.0264
09/16 07:18:26 AM: Updating LR scheduler:
09/16 07:18:26 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:18:26 AM: 	# validation passes without improvement: 1
09/16 07:18:26 AM: edges-ner-ontonotes_loss: training: 0.022430 validation: 0.020968
09/16 07:18:26 AM: macro_avg: validation: 0.941826
09/16 07:18:26 AM: micro_avg: validation: 0.000000
09/16 07:18:26 AM: edges-ner-ontonotes_mcc: training: 0.930609 validation: 0.938504
09/16 07:18:26 AM: edges-ner-ontonotes_acc: training: 0.896873 validation: 0.912800
09/16 07:18:26 AM: edges-ner-ontonotes_precision: training: 0.949416 validation: 0.952115
09/16 07:18:26 AM: edges-ner-ontonotes_recall: training: 0.919614 validation: 0.931756
09/16 07:18:26 AM: edges-ner-ontonotes_f1: training: 0.934277 validation: 0.941826
09/16 07:18:26 AM: Global learning rate: 2.5e-05
09/16 07:18:26 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:18:27 AM: Update 26001: task edges-ner-ontonotes, batch 1 (26001): mcc: 0.9386, acc: 0.9130, precision: 0.9175, recall: 0.9674, f1: 0.9418, edges-ner-ontonotes_loss: 0.0122
09/16 07:18:28 AM: Update 26329: task edges-ner-ontonotes, batch 329 (26329): mcc: 0.9178, acc: 0.8792, precision: 0.9423, recall: 0.9027, f1: 0.9221, edges-ner-ontonotes_loss: 0.0275
09/16 07:18:37 AM: Update 26071: task edges-ner-ontonotes, batch 71 (26071): mcc: 0.9359, acc: 0.9027, precision: 0.9529, recall: 0.9262, f1: 0.9393, edges-ner-ontonotes_loss: 0.0203
09/16 07:18:38 AM: Update 26403: task edges-ner-ontonotes, batch 403 (26403): mcc: 0.9162, acc: 0.8776, precision: 0.9417, recall: 0.9002, f1: 0.9205, edges-ner-ontonotes_loss: 0.0285
09/16 07:18:48 AM: Update 26463: task edges-ner-ontonotes, batch 463 (26463): mcc: 0.9150, acc: 0.8760, precision: 0.9411, recall: 0.8986, f1: 0.9193, edges-ner-ontonotes_loss: 0.0292
09/16 07:18:49 AM: Update 26149: task edges-ner-ontonotes, batch 149 (26149): mcc: 0.9362, acc: 0.9036, precision: 0.9528, recall: 0.9269, f1: 0.9396, edges-ner-ontonotes_loss: 0.0197
09/16 07:18:58 AM: Update 26547: task edges-ner-ontonotes, batch 547 (26547): mcc: 0.9141, acc: 0.8749, precision: 0.9399, recall: 0.8981, f1: 0.9185, edges-ner-ontonotes_loss: 0.0292
09/16 07:18:59 AM: Update 26224: task edges-ner-ontonotes, batch 224 (26224): mcc: 0.9245, acc: 0.8880, precision: 0.9464, recall: 0.9112, f1: 0.9284, edges-ner-ontonotes_loss: 0.0250
09/16 07:19:08 AM: Update 26631: task edges-ner-ontonotes, batch 631 (26631): mcc: 0.9135, acc: 0.8742, precision: 0.9397, recall: 0.8972, f1: 0.9180, edges-ner-ontonotes_loss: 0.0291
09/16 07:19:09 AM: Update 26305: task edges-ner-ontonotes, batch 305 (26305): mcc: 0.9194, acc: 0.8815, precision: 0.9430, recall: 0.9049, f1: 0.9236, edges-ner-ontonotes_loss: 0.0272
09/16 07:19:19 AM: Update 26715: task edges-ner-ontonotes, batch 715 (26715): mcc: 0.9134, acc: 0.8742, precision: 0.9393, recall: 0.8974, f1: 0.9179, edges-ner-ontonotes_loss: 0.0290
09/16 07:19:19 AM: Update 26381: task edges-ner-ontonotes, batch 381 (26381): mcc: 0.9164, acc: 0.8774, precision: 0.9419, recall: 0.9004, f1: 0.9207, edges-ner-ontonotes_loss: 0.0282
09/16 07:19:29 AM: Update 26785: task edges-ner-ontonotes, batch 785 (26785): mcc: 0.9136, acc: 0.8742, precision: 0.9396, recall: 0.8974, f1: 0.9180, edges-ner-ontonotes_loss: 0.0288
09/16 07:19:30 AM: Update 26457: task edges-ner-ontonotes, batch 457 (26457): mcc: 0.9150, acc: 0.8760, precision: 0.9412, recall: 0.8986, f1: 0.9194, edges-ner-ontonotes_loss: 0.0292
09/16 07:19:39 AM: Update 26866: task edges-ner-ontonotes, batch 866 (26866): mcc: 0.9150, acc: 0.8761, precision: 0.9402, recall: 0.8994, f1: 0.9193, edges-ner-ontonotes_loss: 0.0283
09/16 07:19:40 AM: Update 26538: task edges-ner-ontonotes, batch 538 (26538): mcc: 0.9141, acc: 0.8748, precision: 0.9399, recall: 0.8980, f1: 0.9185, edges-ner-ontonotes_loss: 0.0292
09/16 07:19:49 AM: Update 26949: task edges-ner-ontonotes, batch 949 (26949): mcc: 0.9157, acc: 0.8770, precision: 0.9405, recall: 0.9004, f1: 0.9200, edges-ner-ontonotes_loss: 0.0279
09/16 07:19:50 AM: Update 26620: task edges-ner-ontonotes, batch 620 (26620): mcc: 0.9135, acc: 0.8743, precision: 0.9395, recall: 0.8974, f1: 0.9180, edges-ner-ontonotes_loss: 0.0291
09/16 07:19:55 AM: ***** Step 27000 / Validation 27 *****
09/16 07:19:56 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:19:56 AM: Validating...
09/16 07:19:59 AM: Evaluate: task edges-ner-ontonotes, batch 22 (157): mcc: 0.8887, acc: 0.8541, precision: 0.9129, recall: 0.8770, f1: 0.8946, edges-ner-ontonotes_loss: 0.0316
09/16 07:20:00 AM: Update 26695: task edges-ner-ontonotes, batch 695 (26695): mcc: 0.9133, acc: 0.8741, precision: 0.9393, recall: 0.8972, f1: 0.9178, edges-ner-ontonotes_loss: 0.0291
09/16 07:20:09 AM: Evaluate: task edges-ner-ontonotes, batch 86 (157): mcc: 0.9294, acc: 0.9022, precision: 0.9457, recall: 0.9209, f1: 0.9331, edges-ner-ontonotes_loss: 0.0244
09/16 07:20:10 AM: Update 26757: task edges-ner-ontonotes, batch 757 (26757): mcc: 0.9136, acc: 0.8744, precision: 0.9394, recall: 0.8976, f1: 0.9180, edges-ner-ontonotes_loss: 0.0289
09/16 07:20:19 AM: Evaluate: task edges-ner-ontonotes, batch 142 (157): mcc: 0.9376, acc: 0.9122, precision: 0.9539, recall: 0.9283, f1: 0.9410, edges-ner-ontonotes_loss: 0.0210
09/16 07:20:20 AM: Update 26805: task edges-ner-ontonotes, batch 805 (26805): mcc: 0.9140, acc: 0.8749, precision: 0.9398, recall: 0.8979, f1: 0.9184, edges-ner-ontonotes_loss: 0.0286
09/16 07:20:23 AM: Updating LR scheduler:
09/16 07:20:23 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:20:23 AM: 	# validation passes without improvement: 2
09/16 07:20:23 AM: edges-ner-ontonotes_loss: training: 0.027503 validation: 0.020389
09/16 07:20:23 AM: macro_avg: validation: 0.941841
09/16 07:20:23 AM: micro_avg: validation: 0.000000
09/16 07:20:23 AM: edges-ner-ontonotes_mcc: training: 0.916668 validation: 0.938559
09/16 07:20:23 AM: edges-ner-ontonotes_acc: training: 0.878238 validation: 0.913558
09/16 07:20:23 AM: edges-ner-ontonotes_precision: training: 0.940903 validation: 0.954453
09/16 07:20:23 AM: edges-ner-ontonotes_recall: training: 0.901887 validation: 0.929557
09/16 07:20:23 AM: edges-ner-ontonotes_f1: training: 0.920982 validation: 0.941841
09/16 07:20:23 AM: Global learning rate: 2.5e-05
09/16 07:20:23 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:20:30 AM: Update 26877: task edges-ner-ontonotes, batch 877 (26877): mcc: 0.9152, acc: 0.8765, precision: 0.9404, recall: 0.8998, f1: 0.9196, edges-ner-ontonotes_loss: 0.0282
09/16 07:20:30 AM: Update 27053: task edges-ner-ontonotes, batch 53 (27053): mcc: 0.9209, acc: 0.8858, precision: 0.9416, recall: 0.9091, f1: 0.9251, edges-ner-ontonotes_loss: 0.0260
09/16 07:20:41 AM: Update 26970: task edges-ner-ontonotes, batch 970 (26970): mcc: 0.9161, acc: 0.8775, precision: 0.9406, recall: 0.9010, f1: 0.9204, edges-ner-ontonotes_loss: 0.0277
09/16 07:20:42 AM: Update 27104: task edges-ner-ontonotes, batch 104 (27104): mcc: 0.9257, acc: 0.8907, precision: 0.9457, recall: 0.9140, f1: 0.9296, edges-ner-ontonotes_loss: 0.0239
09/16 07:20:44 AM: ***** Step 27000 / Validation 27 *****
09/16 07:20:44 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:20:44 AM: Validating...
09/16 07:20:51 AM: Evaluate: task edges-ner-ontonotes, batch 44 (157): mcc: 0.9120, acc: 0.8854, precision: 0.9289, recall: 0.9049, f1: 0.9168, edges-ner-ontonotes_loss: 0.0292
09/16 07:20:53 AM: Update 27163: task edges-ner-ontonotes, batch 163 (27163): mcc: 0.9309, acc: 0.8967, precision: 0.9490, recall: 0.9206, f1: 0.9346, edges-ner-ontonotes_loss: 0.0220
09/16 07:21:01 AM: Evaluate: task edges-ner-ontonotes, batch 100 (157): mcc: 0.9274, acc: 0.8989, precision: 0.9461, recall: 0.9170, f1: 0.9313, edges-ner-ontonotes_loss: 0.0243
09/16 07:21:04 AM: Update 27218: task edges-ner-ontonotes, batch 218 (27218): mcc: 0.9344, acc: 0.9010, precision: 0.9519, recall: 0.9244, f1: 0.9379, edges-ner-ontonotes_loss: 0.0211
09/16 07:21:11 AM: Evaluate: task edges-ner-ontonotes, batch 152 (157): mcc: 0.9381, acc: 0.9127, precision: 0.9544, recall: 0.9287, f1: 0.9414, edges-ner-ontonotes_loss: 0.0207
09/16 07:21:12 AM: Updating LR scheduler:
09/16 07:21:12 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:21:12 AM: 	# validation passes without improvement: 2
09/16 07:21:12 AM: edges-ner-ontonotes_loss: training: 0.027503 validation: 0.020389
09/16 07:21:12 AM: macro_avg: validation: 0.941841
09/16 07:21:12 AM: micro_avg: validation: 0.000000
09/16 07:21:12 AM: edges-ner-ontonotes_mcc: training: 0.916668 validation: 0.938559
09/16 07:21:12 AM: edges-ner-ontonotes_acc: training: 0.878238 validation: 0.913558
09/16 07:21:12 AM: edges-ner-ontonotes_precision: training: 0.940903 validation: 0.954453
09/16 07:21:12 AM: edges-ner-ontonotes_recall: training: 0.901887 validation: 0.929557
09/16 07:21:12 AM: edges-ner-ontonotes_f1: training: 0.920982 validation: 0.941841
09/16 07:21:12 AM: Global learning rate: 2.5e-05
09/16 07:21:12 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:21:14 AM: Update 27276: task edges-ner-ontonotes, batch 276 (27276): mcc: 0.9371, acc: 0.9052, precision: 0.9540, recall: 0.9273, f1: 0.9404, edges-ner-ontonotes_loss: 0.0203
09/16 07:21:21 AM: Update 27061: task edges-ner-ontonotes, batch 61 (27061): mcc: 0.9221, acc: 0.8875, precision: 0.9425, recall: 0.9104, f1: 0.9262, edges-ner-ontonotes_loss: 0.0257
09/16 07:21:24 AM: Update 27352: task edges-ner-ontonotes, batch 352 (27352): mcc: 0.9386, acc: 0.9068, precision: 0.9551, recall: 0.9289, f1: 0.9418, edges-ner-ontonotes_loss: 0.0197
09/16 07:21:31 AM: Update 27122: task edges-ner-ontonotes, batch 122 (27122): mcc: 0.9278, acc: 0.8933, precision: 0.9476, recall: 0.9162, f1: 0.9316, edges-ner-ontonotes_loss: 0.0231
09/16 07:21:34 AM: Update 27418: task edges-ner-ontonotes, batch 418 (27418): mcc: 0.9389, acc: 0.9076, precision: 0.9551, recall: 0.9296, f1: 0.9422, edges-ner-ontonotes_loss: 0.0197
09/16 07:21:41 AM: Update 27193: task edges-ner-ontonotes, batch 193 (27193): mcc: 0.9340, acc: 0.9005, precision: 0.9516, recall: 0.9239, f1: 0.9375, edges-ner-ontonotes_loss: 0.0214
09/16 07:21:44 AM: Update 27487: task edges-ner-ontonotes, batch 487 (27487): mcc: 0.9395, acc: 0.9080, precision: 0.9557, recall: 0.9302, f1: 0.9427, edges-ner-ontonotes_loss: 0.0194
09/16 07:21:51 AM: Update 27264: task edges-ner-ontonotes, batch 264 (27264): mcc: 0.9365, acc: 0.9042, precision: 0.9533, recall: 0.9268, f1: 0.9398, edges-ner-ontonotes_loss: 0.0205
09/16 07:21:55 AM: Update 27561: task edges-ner-ontonotes, batch 561 (27561): mcc: 0.9398, acc: 0.9081, precision: 0.9561, recall: 0.9302, f1: 0.9430, edges-ner-ontonotes_loss: 0.0193
09/16 07:22:02 AM: Update 27345: task edges-ner-ontonotes, batch 345 (27345): mcc: 0.9383, acc: 0.9063, precision: 0.9549, recall: 0.9287, f1: 0.9416, edges-ner-ontonotes_loss: 0.0198
09/16 07:22:07 AM: Update 27632: task edges-ner-ontonotes, batch 632 (27632): mcc: 0.9391, acc: 0.9076, precision: 0.9554, recall: 0.9297, f1: 0.9424, edges-ner-ontonotes_loss: 0.0195
09/16 07:22:12 AM: Update 27405: task edges-ner-ontonotes, batch 405 (27405): mcc: 0.9388, acc: 0.9074, precision: 0.9552, recall: 0.9293, f1: 0.9421, edges-ner-ontonotes_loss: 0.0197
09/16 07:22:20 AM: Update 27705: task edges-ner-ontonotes, batch 705 (27705): mcc: 0.9388, acc: 0.9071, precision: 0.9554, recall: 0.9291, f1: 0.9421, edges-ner-ontonotes_loss: 0.0196
09/16 07:22:22 AM: Update 27484: task edges-ner-ontonotes, batch 484 (27484): mcc: 0.9396, acc: 0.9081, precision: 0.9557, recall: 0.9302, f1: 0.9428, edges-ner-ontonotes_loss: 0.0194
09/16 07:22:30 AM: Update 27774: task edges-ner-ontonotes, batch 774 (27774): mcc: 0.9361, acc: 0.9036, precision: 0.9538, recall: 0.9257, f1: 0.9395, edges-ner-ontonotes_loss: 0.0206
09/16 07:22:32 AM: Update 27553: task edges-ner-ontonotes, batch 553 (27553): mcc: 0.9397, acc: 0.9081, precision: 0.9560, recall: 0.9302, f1: 0.9429, edges-ner-ontonotes_loss: 0.0193
09/16 07:22:40 AM: Update 27850: task edges-ner-ontonotes, batch 850 (27850): mcc: 0.9328, acc: 0.8993, precision: 0.9518, recall: 0.9214, f1: 0.9364, edges-ner-ontonotes_loss: 0.0220
09/16 07:22:42 AM: Update 27627: task edges-ner-ontonotes, batch 627 (27627): mcc: 0.9391, acc: 0.9076, precision: 0.9553, recall: 0.9298, f1: 0.9424, edges-ner-ontonotes_loss: 0.0195
09/16 07:22:50 AM: Update 27927: task edges-ner-ontonotes, batch 927 (27927): mcc: 0.9302, acc: 0.8960, precision: 0.9499, recall: 0.9185, f1: 0.9339, edges-ner-ontonotes_loss: 0.0231
09/16 07:22:54 AM: Update 27705: task edges-ner-ontonotes, batch 705 (27705): mcc: 0.9388, acc: 0.9071, precision: 0.9554, recall: 0.9291, f1: 0.9421, edges-ner-ontonotes_loss: 0.0196
09/16 07:23:02 AM: ***** Step 28000 / Validation 28 *****
09/16 07:23:04 AM: Update 27780: task edges-ner-ontonotes, batch 780 (27780): mcc: 0.9359, acc: 0.9033, precision: 0.9536, recall: 0.9254, f1: 0.9393, edges-ner-ontonotes_loss: 0.0207
09/16 07:23:04 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:23:04 AM: Validating...
09/16 07:23:04 AM: Evaluate: task edges-ner-ontonotes, batch 1 (157): mcc: 0.8243, acc: 0.7213, precision: 0.9200, recall: 0.7541, f1: 0.8288, edges-ner-ontonotes_loss: 0.0432
09/16 07:23:14 AM: Update 27839: task edges-ner-ontonotes, batch 839 (27839): mcc: 0.9332, acc: 0.8998, precision: 0.9519, recall: 0.9220, f1: 0.9367, edges-ner-ontonotes_loss: 0.0218
09/16 07:23:14 AM: Evaluate: task edges-ner-ontonotes, batch 65 (157): mcc: 0.9208, acc: 0.8925, precision: 0.9370, recall: 0.9134, f1: 0.9250, edges-ner-ontonotes_loss: 0.0274
09/16 07:23:25 AM: Update 27895: task edges-ner-ontonotes, batch 895 (27895): mcc: 0.9312, acc: 0.8971, precision: 0.9506, recall: 0.9195, f1: 0.9348, edges-ner-ontonotes_loss: 0.0227
09/16 07:23:25 AM: Evaluate: task edges-ner-ontonotes, batch 118 (157): mcc: 0.9312, acc: 0.9036, precision: 0.9485, recall: 0.9216, f1: 0.9348, edges-ner-ontonotes_loss: 0.0234
09/16 07:23:32 AM: Updating LR scheduler:
09/16 07:23:32 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:23:32 AM: 	# validation passes without improvement: 3
09/16 07:23:32 AM: edges-ner-ontonotes_loss: training: 0.023965 validation: 0.021021
09/16 07:23:32 AM: macro_avg: validation: 0.941339
09/16 07:23:32 AM: micro_avg: validation: 0.000000
09/16 07:23:32 AM: edges-ner-ontonotes_mcc: training: 0.928519 validation: 0.938029
09/16 07:23:32 AM: edges-ner-ontonotes_acc: training: 0.893689 validation: 0.912875
09/16 07:23:32 AM: edges-ner-ontonotes_precision: training: 0.948734 validation: 0.953983
09/16 07:23:32 AM: edges-ner-ontonotes_recall: training: 0.916375 validation: 0.929026
09/16 07:23:32 AM: edges-ner-ontonotes_f1: training: 0.932273 validation: 0.941339
09/16 07:23:32 AM: Global learning rate: 2.5e-05
09/16 07:23:32 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:23:35 AM: Update 27969: task edges-ner-ontonotes, batch 969 (27969): mcc: 0.9293, acc: 0.8948, precision: 0.9493, recall: 0.9174, f1: 0.9331, edges-ner-ontonotes_loss: 0.0236
09/16 07:23:36 AM: Update 28009: task edges-ner-ontonotes, batch 9 (28009): mcc: 0.9029, acc: 0.8652, precision: 0.9307, recall: 0.8862, f1: 0.9079, edges-ner-ontonotes_loss: 0.0391
09/16 07:23:39 AM: ***** Step 28000 / Validation 28 *****
09/16 07:23:39 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:23:39 AM: Validating...
09/16 07:23:46 AM: Evaluate: task edges-ner-ontonotes, batch 45 (157): mcc: 0.9105, acc: 0.8821, precision: 0.9273, recall: 0.9036, f1: 0.9153, edges-ner-ontonotes_loss: 0.0301
09/16 07:23:46 AM: Update 28074: task edges-ner-ontonotes, batch 74 (28074): mcc: 0.9058, acc: 0.8651, precision: 0.9323, recall: 0.8901, f1: 0.9107, edges-ner-ontonotes_loss: 0.0303
09/16 07:23:56 AM: Evaluate: task edges-ner-ontonotes, batch 102 (157): mcc: 0.9281, acc: 0.9002, precision: 0.9465, recall: 0.9178, f1: 0.9319, edges-ner-ontonotes_loss: 0.0246
09/16 07:23:56 AM: Update 28139: task edges-ner-ontonotes, batch 139 (28139): mcc: 0.9092, acc: 0.8693, precision: 0.9340, recall: 0.8947, f1: 0.9139, edges-ner-ontonotes_loss: 0.0296
09/16 07:24:05 AM: Updating LR scheduler:
09/16 07:24:05 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:24:05 AM: 	# validation passes without improvement: 3
09/16 07:24:05 AM: edges-ner-ontonotes_loss: training: 0.023965 validation: 0.021021
09/16 07:24:05 AM: macro_avg: validation: 0.941339
09/16 07:24:05 AM: micro_avg: validation: 0.000000
09/16 07:24:05 AM: edges-ner-ontonotes_mcc: training: 0.928519 validation: 0.938029
09/16 07:24:05 AM: edges-ner-ontonotes_acc: training: 0.893689 validation: 0.912875
09/16 07:24:05 AM: edges-ner-ontonotes_precision: training: 0.948734 validation: 0.953983
09/16 07:24:05 AM: edges-ner-ontonotes_recall: training: 0.916375 validation: 0.929026
09/16 07:24:05 AM: edges-ner-ontonotes_f1: training: 0.932273 validation: 0.941339
09/16 07:24:05 AM: Global learning rate: 2.5e-05
09/16 07:24:05 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:24:06 AM: Update 28003: task edges-ner-ontonotes, batch 3 (28003): mcc: 0.9119, acc: 0.8673, precision: 0.9355, recall: 0.8982, f1: 0.9165, edges-ner-ontonotes_loss: 0.0302
09/16 07:24:06 AM: Update 28205: task edges-ner-ontonotes, batch 205 (28205): mcc: 0.9099, acc: 0.8701, precision: 0.9343, recall: 0.8956, f1: 0.9146, edges-ner-ontonotes_loss: 0.0297
09/16 07:24:16 AM: Update 28064: task edges-ner-ontonotes, batch 64 (28064): mcc: 0.9081, acc: 0.8678, precision: 0.9341, recall: 0.8924, f1: 0.9128, edges-ner-ontonotes_loss: 0.0295
09/16 07:24:16 AM: Update 28301: task edges-ner-ontonotes, batch 301 (28301): mcc: 0.9107, acc: 0.8705, precision: 0.9355, recall: 0.8961, f1: 0.9154, edges-ner-ontonotes_loss: 0.0291
09/16 07:24:26 AM: Update 28158: task edges-ner-ontonotes, batch 158 (28158): mcc: 0.9078, acc: 0.8670, precision: 0.9326, recall: 0.8934, f1: 0.9126, edges-ner-ontonotes_loss: 0.0300
09/16 07:24:27 AM: Update 28361: task edges-ner-ontonotes, batch 361 (28361): mcc: 0.9124, acc: 0.8726, precision: 0.9370, recall: 0.8978, f1: 0.9170, edges-ner-ontonotes_loss: 0.0286
09/16 07:24:36 AM: Update 28240: task edges-ner-ontonotes, batch 240 (28240): mcc: 0.9101, acc: 0.8699, precision: 0.9353, recall: 0.8950, f1: 0.9147, edges-ner-ontonotes_loss: 0.0295
09/16 07:24:37 AM: Update 28442: task edges-ner-ontonotes, batch 442 (28442): mcc: 0.9148, acc: 0.8757, precision: 0.9389, recall: 0.9003, f1: 0.9192, edges-ner-ontonotes_loss: 0.0277
09/16 07:24:46 AM: Update 28320: task edges-ner-ontonotes, batch 320 (28320): mcc: 0.9108, acc: 0.8706, precision: 0.9355, recall: 0.8962, f1: 0.9154, edges-ner-ontonotes_loss: 0.0291
09/16 07:24:47 AM: Update 28522: task edges-ner-ontonotes, batch 522 (28522): mcc: 0.9163, acc: 0.8778, precision: 0.9395, recall: 0.9025, f1: 0.9206, edges-ner-ontonotes_loss: 0.0272
09/16 07:24:56 AM: Update 28375: task edges-ner-ontonotes, batch 375 (28375): mcc: 0.9131, acc: 0.8734, precision: 0.9377, recall: 0.8984, f1: 0.9176, edges-ner-ontonotes_loss: 0.0284
09/16 07:24:57 AM: Update 28605: task edges-ner-ontonotes, batch 605 (28605): mcc: 0.9183, acc: 0.8806, precision: 0.9409, recall: 0.9050, f1: 0.9226, edges-ner-ontonotes_loss: 0.0265
09/16 07:25:07 AM: Update 28663: task edges-ner-ontonotes, batch 663 (28663): mcc: 0.9201, acc: 0.8828, precision: 0.9426, recall: 0.9067, f1: 0.9243, edges-ner-ontonotes_loss: 0.0260
09/16 07:25:07 AM: Update 28453: task edges-ner-ontonotes, batch 453 (28453): mcc: 0.9154, acc: 0.8766, precision: 0.9392, recall: 0.9012, f1: 0.9198, edges-ner-ontonotes_loss: 0.0276
09/16 07:25:17 AM: Update 28736: task edges-ner-ontonotes, batch 736 (28736): mcc: 0.9229, acc: 0.8865, precision: 0.9446, recall: 0.9098, f1: 0.9269, edges-ner-ontonotes_loss: 0.0252
09/16 07:25:17 AM: Update 28524: task edges-ner-ontonotes, batch 524 (28524): mcc: 0.9162, acc: 0.8777, precision: 0.9394, recall: 0.9024, f1: 0.9206, edges-ner-ontonotes_loss: 0.0273
09/16 07:25:27 AM: Update 28808: task edges-ner-ontonotes, batch 808 (28808): mcc: 0.9246, acc: 0.8887, precision: 0.9455, recall: 0.9121, f1: 0.9285, edges-ner-ontonotes_loss: 0.0247
09/16 07:25:27 AM: Update 28598: task edges-ner-ontonotes, batch 598 (28598): mcc: 0.9181, acc: 0.8802, precision: 0.9408, recall: 0.9047, f1: 0.9224, edges-ner-ontonotes_loss: 0.0265
09/16 07:25:37 AM: Update 28652: task edges-ner-ontonotes, batch 652 (28652): mcc: 0.9196, acc: 0.8821, precision: 0.9420, recall: 0.9062, f1: 0.9238, edges-ner-ontonotes_loss: 0.0261
09/16 07:25:37 AM: Update 28893: task edges-ner-ontonotes, batch 893 (28893): mcc: 0.9269, acc: 0.8916, precision: 0.9472, recall: 0.9148, f1: 0.9307, edges-ner-ontonotes_loss: 0.0239
09/16 07:25:47 AM: Update 28735: task edges-ner-ontonotes, batch 735 (28735): mcc: 0.9229, acc: 0.8865, precision: 0.9446, recall: 0.9098, f1: 0.9269, edges-ner-ontonotes_loss: 0.0252
09/16 07:25:48 AM: Update 28948: task edges-ner-ontonotes, batch 948 (28948): mcc: 0.9277, acc: 0.8927, precision: 0.9476, recall: 0.9160, f1: 0.9315, edges-ner-ontonotes_loss: 0.0236
09/16 07:25:56 AM: ***** Step 29000 / Validation 29 *****
09/16 07:25:56 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:25:56 AM: Validating...
09/16 07:25:57 AM: Update 28806: task edges-ner-ontonotes, batch 806 (28806): mcc: 0.9247, acc: 0.8888, precision: 0.9456, recall: 0.9122, f1: 0.9286, edges-ner-ontonotes_loss: 0.0247
09/16 07:25:58 AM: Evaluate: task edges-ner-ontonotes, batch 17 (157): mcc: 0.8757, acc: 0.8359, precision: 0.9076, recall: 0.8580, f1: 0.8821, edges-ner-ontonotes_loss: 0.0368
09/16 07:26:07 AM: Update 28864: task edges-ner-ontonotes, batch 864 (28864): mcc: 0.9261, acc: 0.8906, precision: 0.9467, recall: 0.9138, f1: 0.9300, edges-ner-ontonotes_loss: 0.0241
09/16 07:26:08 AM: Evaluate: task edges-ner-ontonotes, batch 77 (157): mcc: 0.9229, acc: 0.8937, precision: 0.9414, recall: 0.9131, f1: 0.9270, edges-ner-ontonotes_loss: 0.0274
09/16 07:26:17 AM: Update 28918: task edges-ner-ontonotes, batch 918 (28918): mcc: 0.9274, acc: 0.8922, precision: 0.9475, recall: 0.9155, f1: 0.9312, edges-ner-ontonotes_loss: 0.0238
09/16 07:26:18 AM: Evaluate: task edges-ner-ontonotes, batch 128 (157): mcc: 0.9338, acc: 0.9064, precision: 0.9505, recall: 0.9245, f1: 0.9373, edges-ner-ontonotes_loss: 0.0228
09/16 07:26:23 AM: Updating LR scheduler:
09/16 07:26:23 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:26:23 AM: 	# validation passes without improvement: 0
09/16 07:26:23 AM: edges-ner-ontonotes_loss: training: 0.023380 validation: 0.021049
09/16 07:26:23 AM: macro_avg: validation: 0.941678
09/16 07:26:23 AM: micro_avg: validation: 0.000000
09/16 07:26:23 AM: edges-ner-ontonotes_mcc: training: 0.928373 validation: 0.938367
09/16 07:26:23 AM: edges-ner-ontonotes_acc: training: 0.893480 validation: 0.912496
09/16 07:26:23 AM: edges-ner-ontonotes_precision: training: 0.948151 validation: 0.953161
09/16 07:26:23 AM: edges-ner-ontonotes_recall: training: 0.916671 validation: 0.930467
09/16 07:26:23 AM: edges-ner-ontonotes_f1: training: 0.932145 validation: 0.941678
09/16 07:26:23 AM: Global learning rate: 1.25e-05
09/16 07:26:23 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:26:28 AM: Update 28963: task edges-ner-ontonotes, batch 963 (28963): mcc: 0.9280, acc: 0.8929, precision: 0.9477, recall: 0.9163, f1: 0.9317, edges-ner-ontonotes_loss: 0.0236
09/16 07:26:28 AM: Update 29045: task edges-ner-ontonotes, batch 45 (29045): mcc: 0.9371, acc: 0.9034, precision: 0.9551, recall: 0.9262, f1: 0.9404, edges-ner-ontonotes_loss: 0.0213
09/16 07:26:32 AM: ***** Step 29000 / Validation 29 *****
09/16 07:26:32 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:26:32 AM: Validating...
09/16 07:26:38 AM: Evaluate: task edges-ner-ontonotes, batch 35 (157): mcc: 0.8970, acc: 0.8660, precision: 0.9180, recall: 0.8876, f1: 0.9025, edges-ner-ontonotes_loss: 0.0339
09/16 07:26:39 AM: Update 29112: task edges-ner-ontonotes, batch 112 (29112): mcc: 0.9366, acc: 0.9028, precision: 0.9545, recall: 0.9259, f1: 0.9400, edges-ner-ontonotes_loss: 0.0207
09/16 07:26:48 AM: Evaluate: task edges-ner-ontonotes, batch 92 (157): mcc: 0.9277, acc: 0.8985, precision: 0.9461, recall: 0.9175, f1: 0.9316, edges-ner-ontonotes_loss: 0.0257
09/16 07:26:49 AM: Update 29169: task edges-ner-ontonotes, batch 169 (29169): mcc: 0.9362, acc: 0.9026, precision: 0.9539, recall: 0.9257, f1: 0.9396, edges-ner-ontonotes_loss: 0.0203
09/16 07:26:58 AM: Evaluate: task edges-ner-ontonotes, batch 145 (157): mcc: 0.9371, acc: 0.9109, precision: 0.9526, recall: 0.9286, f1: 0.9405, edges-ner-ontonotes_loss: 0.0217
09/16 07:27:00 AM: Update 29225: task edges-ner-ontonotes, batch 225 (29225): mcc: 0.9377, acc: 0.9051, precision: 0.9557, recall: 0.9268, f1: 0.9410, edges-ner-ontonotes_loss: 0.0200
09/16 07:27:00 AM: Updating LR scheduler:
09/16 07:27:01 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:27:01 AM: 	# validation passes without improvement: 0
09/16 07:27:01 AM: edges-ner-ontonotes_loss: training: 0.023380 validation: 0.021049
09/16 07:27:01 AM: macro_avg: validation: 0.941678
09/16 07:27:01 AM: micro_avg: validation: 0.000000
09/16 07:27:01 AM: edges-ner-ontonotes_mcc: training: 0.928373 validation: 0.938367
09/16 07:27:01 AM: edges-ner-ontonotes_acc: training: 0.893480 validation: 0.912496
09/16 07:27:01 AM: edges-ner-ontonotes_precision: training: 0.948151 validation: 0.953161
09/16 07:27:01 AM: edges-ner-ontonotes_recall: training: 0.916671 validation: 0.930467
09/16 07:27:01 AM: edges-ner-ontonotes_f1: training: 0.932145 validation: 0.941678
09/16 07:27:01 AM: Global learning rate: 1.25e-05
09/16 07:27:01 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:27:08 AM: Update 29059: task edges-ner-ontonotes, batch 59 (29059): mcc: 0.9386, acc: 0.9051, precision: 0.9556, recall: 0.9285, f1: 0.9419, edges-ner-ontonotes_loss: 0.0211
09/16 07:27:11 AM: Update 29279: task edges-ner-ontonotes, batch 279 (29279): mcc: 0.9362, acc: 0.9031, precision: 0.9552, recall: 0.9244, f1: 0.9396, edges-ner-ontonotes_loss: 0.0204
09/16 07:27:18 AM: Update 29133: task edges-ner-ontonotes, batch 133 (29133): mcc: 0.9367, acc: 0.9032, precision: 0.9542, recall: 0.9263, f1: 0.9400, edges-ner-ontonotes_loss: 0.0203
09/16 07:27:21 AM: Update 29358: task edges-ner-ontonotes, batch 358 (29358): mcc: 0.9291, acc: 0.8945, precision: 0.9504, recall: 0.9158, f1: 0.9328, edges-ner-ontonotes_loss: 0.0236
09/16 07:27:28 AM: Update 29205: task edges-ner-ontonotes, batch 205 (29205): mcc: 0.9370, acc: 0.9040, precision: 0.9548, recall: 0.9264, f1: 0.9404, edges-ner-ontonotes_loss: 0.0201
09/16 07:27:31 AM: Update 29432: task edges-ner-ontonotes, batch 432 (29432): mcc: 0.9251, acc: 0.8893, precision: 0.9479, recall: 0.9107, f1: 0.9289, edges-ner-ontonotes_loss: 0.0256
09/16 07:27:39 AM: Update 29262: task edges-ner-ontonotes, batch 262 (29262): mcc: 0.9376, acc: 0.9049, precision: 0.9559, recall: 0.9262, f1: 0.9408, edges-ner-ontonotes_loss: 0.0200
09/16 07:27:41 AM: Update 29507: task edges-ner-ontonotes, batch 507 (29507): mcc: 0.9224, acc: 0.8858, precision: 0.9466, recall: 0.9071, f1: 0.9264, edges-ner-ontonotes_loss: 0.0265
09/16 07:27:49 AM: Update 29340: task edges-ner-ontonotes, batch 340 (29340): mcc: 0.9304, acc: 0.8963, precision: 0.9512, recall: 0.9175, f1: 0.9340, edges-ner-ontonotes_loss: 0.0233
09/16 07:27:51 AM: Update 29565: task edges-ner-ontonotes, batch 565 (29565): mcc: 0.9209, acc: 0.8840, precision: 0.9455, recall: 0.9054, f1: 0.9250, edges-ner-ontonotes_loss: 0.0274
09/16 07:27:59 AM: Update 29425: task edges-ner-ontonotes, batch 425 (29425): mcc: 0.9254, acc: 0.8897, precision: 0.9483, recall: 0.9110, f1: 0.9293, edges-ner-ontonotes_loss: 0.0254
09/16 07:28:01 AM: Update 29651: task edges-ner-ontonotes, batch 651 (29651): mcc: 0.9196, acc: 0.8822, precision: 0.9442, recall: 0.9041, f1: 0.9237, edges-ner-ontonotes_loss: 0.0276
09/16 07:28:09 AM: Update 29503: task edges-ner-ontonotes, batch 503 (29503): mcc: 0.9226, acc: 0.8860, precision: 0.9467, recall: 0.9072, f1: 0.9266, edges-ner-ontonotes_loss: 0.0265
09/16 07:28:11 AM: Update 29732: task edges-ner-ontonotes, batch 732 (29732): mcc: 0.9188, acc: 0.8814, precision: 0.9433, recall: 0.9035, f1: 0.9230, edges-ner-ontonotes_loss: 0.0279
09/16 07:28:19 AM: Update 29565: task edges-ner-ontonotes, batch 565 (29565): mcc: 0.9209, acc: 0.8840, precision: 0.9455, recall: 0.9054, f1: 0.9250, edges-ner-ontonotes_loss: 0.0274
09/16 07:28:21 AM: Update 29829: task edges-ner-ontonotes, batch 829 (29829): mcc: 0.9179, acc: 0.8802, precision: 0.9426, recall: 0.9026, f1: 0.9222, edges-ner-ontonotes_loss: 0.0280
09/16 07:28:30 AM: Update 29664: task edges-ner-ontonotes, batch 664 (29664): mcc: 0.9195, acc: 0.8822, precision: 0.9440, recall: 0.9041, f1: 0.9236, edges-ner-ontonotes_loss: 0.0277
09/16 07:28:31 AM: Update 29893: task edges-ner-ontonotes, batch 893 (29893): mcc: 0.9180, acc: 0.8802, precision: 0.9427, recall: 0.9027, f1: 0.9223, edges-ner-ontonotes_loss: 0.0279
09/16 07:28:41 AM: Update 29746: task edges-ner-ontonotes, batch 746 (29746): mcc: 0.9186, acc: 0.8811, precision: 0.9432, recall: 0.9033, f1: 0.9228, edges-ner-ontonotes_loss: 0.0279
09/16 07:28:41 AM: Update 29970: task edges-ner-ontonotes, batch 970 (29970): mcc: 0.9185, acc: 0.8807, precision: 0.9428, recall: 0.9035, f1: 0.9228, edges-ner-ontonotes_loss: 0.0275
09/16 07:28:45 AM: ***** Step 30000 / Validation 30 *****
09/16 07:28:45 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:28:45 AM: Validating...
09/16 07:28:51 AM: Update 29820: task edges-ner-ontonotes, batch 820 (29820): mcc: 0.9181, acc: 0.8804, precision: 0.9428, recall: 0.9027, f1: 0.9223, edges-ner-ontonotes_loss: 0.0280
09/16 07:28:52 AM: Evaluate: task edges-ner-ontonotes, batch 46 (157): mcc: 0.9113, acc: 0.8830, precision: 0.9278, recall: 0.9047, f1: 0.9161, edges-ner-ontonotes_loss: 0.0295
09/16 07:29:02 AM: Evaluate: task edges-ner-ontonotes, batch 106 (157): mcc: 0.9306, acc: 0.9036, precision: 0.9469, recall: 0.9220, f1: 0.9343, edges-ner-ontonotes_loss: 0.0234
09/16 07:29:03 AM: Update 29878: task edges-ner-ontonotes, batch 878 (29878): mcc: 0.9180, acc: 0.8802, precision: 0.9426, recall: 0.9027, f1: 0.9222, edges-ner-ontonotes_loss: 0.0279
09/16 07:29:12 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:29:12 AM: Best result seen so far for macro.
09/16 07:29:12 AM: Updating LR scheduler:
09/16 07:29:12 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:29:12 AM: 	# validation passes without improvement: 0
09/16 07:29:12 AM: edges-ner-ontonotes_loss: training: 0.027399 validation: 0.020386
09/16 07:29:12 AM: macro_avg: validation: 0.942210
09/16 07:29:12 AM: micro_avg: validation: 0.000000
09/16 07:29:12 AM: edges-ner-ontonotes_mcc: training: 0.918819 validation: 0.938932
09/16 07:29:12 AM: edges-ner-ontonotes_acc: training: 0.881109 validation: 0.914392
09/16 07:29:12 AM: edges-ner-ontonotes_precision: training: 0.942813 validation: 0.953776
09/16 07:29:12 AM: edges-ner-ontonotes_recall: training: 0.904042 validation: 0.930922
09/16 07:29:12 AM: edges-ner-ontonotes_f1: training: 0.923021 validation: 0.942210
09/16 07:29:12 AM: Global learning rate: 1.25e-05
09/16 07:29:12 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:29:12 AM: Update 30001: task edges-ner-ontonotes, batch 1 (30001): mcc: 0.9511, acc: 0.9205, precision: 0.9762, recall: 0.9318, f1: 0.9535, edges-ner-ontonotes_loss: 0.0179
09/16 07:29:13 AM: Update 29933: task edges-ner-ontonotes, batch 933 (29933): mcc: 0.9184, acc: 0.8805, precision: 0.9429, recall: 0.9031, f1: 0.9226, edges-ner-ontonotes_loss: 0.0277
09/16 07:29:22 AM: Update 30078: task edges-ner-ontonotes, batch 78 (30078): mcc: 0.9298, acc: 0.8969, precision: 0.9503, recall: 0.9172, f1: 0.9335, edges-ner-ontonotes_loss: 0.0234
09/16 07:29:22 AM: ***** Step 30000 / Validation 30 *****
09/16 07:29:22 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:29:22 AM: Validating...
09/16 07:29:23 AM: Evaluate: task edges-ner-ontonotes, batch 8 (157): mcc: 0.8401, acc: 0.7890, precision: 0.8671, recall: 0.8308, f1: 0.8485, edges-ner-ontonotes_loss: 0.0415
09/16 07:29:32 AM: Update 30136: task edges-ner-ontonotes, batch 136 (30136): mcc: 0.9273, acc: 0.8949, precision: 0.9493, recall: 0.9137, f1: 0.9311, edges-ner-ontonotes_loss: 0.0236
09/16 07:29:33 AM: Evaluate: task edges-ner-ontonotes, batch 69 (157): mcc: 0.9229, acc: 0.8948, precision: 0.9395, recall: 0.9149, f1: 0.9270, edges-ner-ontonotes_loss: 0.0265
09/16 07:29:43 AM: Evaluate: task edges-ner-ontonotes, batch 120 (157): mcc: 0.9329, acc: 0.9057, precision: 0.9495, recall: 0.9237, f1: 0.9364, edges-ner-ontonotes_loss: 0.0225
09/16 07:29:45 AM: Update 30191: task edges-ner-ontonotes, batch 191 (30191): mcc: 0.9261, acc: 0.8926, precision: 0.9465, recall: 0.9141, f1: 0.9300, edges-ner-ontonotes_loss: 0.0233
09/16 07:29:49 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:29:49 AM: Best result seen so far for macro.
09/16 07:29:49 AM: Updating LR scheduler:
09/16 07:29:49 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:29:49 AM: 	# validation passes without improvement: 0
09/16 07:29:49 AM: edges-ner-ontonotes_loss: training: 0.027399 validation: 0.020386
09/16 07:29:49 AM: macro_avg: validation: 0.942210
09/16 07:29:49 AM: micro_avg: validation: 0.000000
09/16 07:29:49 AM: edges-ner-ontonotes_mcc: training: 0.918819 validation: 0.938932
09/16 07:29:49 AM: edges-ner-ontonotes_acc: training: 0.881109 validation: 0.914392
09/16 07:29:49 AM: edges-ner-ontonotes_precision: training: 0.942813 validation: 0.953776
09/16 07:29:49 AM: edges-ner-ontonotes_recall: training: 0.904042 validation: 0.930922
09/16 07:29:49 AM: edges-ner-ontonotes_f1: training: 0.923021 validation: 0.942210
09/16 07:29:49 AM: Global learning rate: 1.25e-05
09/16 07:29:49 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:29:54 AM: Update 30029: task edges-ner-ontonotes, batch 29 (30029): mcc: 0.9252, acc: 0.8932, precision: 0.9484, recall: 0.9105, f1: 0.9291, edges-ner-ontonotes_loss: 0.0254
09/16 07:29:55 AM: Update 30259: task edges-ner-ontonotes, batch 259 (30259): mcc: 0.9295, acc: 0.8966, precision: 0.9493, recall: 0.9177, f1: 0.9332, edges-ner-ontonotes_loss: 0.0222
09/16 07:30:04 AM: Update 30107: task edges-ner-ontonotes, batch 107 (30107): mcc: 0.9300, acc: 0.8982, precision: 0.9504, recall: 0.9174, f1: 0.9336, edges-ner-ontonotes_loss: 0.0229
09/16 07:30:05 AM: Update 30333: task edges-ner-ontonotes, batch 333 (30333): mcc: 0.9328, acc: 0.9008, precision: 0.9505, recall: 0.9226, f1: 0.9363, edges-ner-ontonotes_loss: 0.0214
09/16 07:30:14 AM: Update 30177: task edges-ner-ontonotes, batch 177 (30177): mcc: 0.9270, acc: 0.8942, precision: 0.9477, recall: 0.9145, f1: 0.9308, edges-ner-ontonotes_loss: 0.0233
09/16 07:30:15 AM: Update 30405: task edges-ner-ontonotes, batch 405 (30405): mcc: 0.9351, acc: 0.9034, precision: 0.9522, recall: 0.9252, f1: 0.9385, edges-ner-ontonotes_loss: 0.0206
09/16 07:30:24 AM: Update 30230: task edges-ner-ontonotes, batch 230 (30230): mcc: 0.9284, acc: 0.8953, precision: 0.9488, recall: 0.9161, f1: 0.9321, edges-ner-ontonotes_loss: 0.0227
09/16 07:30:25 AM: Update 30485: task edges-ner-ontonotes, batch 485 (30485): mcc: 0.9363, acc: 0.9045, precision: 0.9533, recall: 0.9265, f1: 0.9397, edges-ner-ontonotes_loss: 0.0203
09/16 07:30:34 AM: Update 30311: task edges-ner-ontonotes, batch 311 (30311): mcc: 0.9322, acc: 0.9000, precision: 0.9505, recall: 0.9215, f1: 0.9358, edges-ner-ontonotes_loss: 0.0216
09/16 07:30:35 AM: Update 30543: task edges-ner-ontonotes, batch 543 (30543): mcc: 0.9361, acc: 0.9041, precision: 0.9535, recall: 0.9259, f1: 0.9395, edges-ner-ontonotes_loss: 0.0203
09/16 07:30:44 AM: Update 30382: task edges-ner-ontonotes, batch 382 (30382): mcc: 0.9346, acc: 0.9031, precision: 0.9517, recall: 0.9249, f1: 0.9381, edges-ner-ontonotes_loss: 0.0208
09/16 07:30:45 AM: Update 30621: task edges-ner-ontonotes, batch 621 (30621): mcc: 0.9370, acc: 0.9052, precision: 0.9540, recall: 0.9271, f1: 0.9404, edges-ner-ontonotes_loss: 0.0201
09/16 07:30:55 AM: Update 30465: task edges-ner-ontonotes, batch 465 (30465): mcc: 0.9359, acc: 0.9040, precision: 0.9529, recall: 0.9261, f1: 0.9393, edges-ner-ontonotes_loss: 0.0204
09/16 07:30:55 AM: Update 30686: task edges-ner-ontonotes, batch 686 (30686): mcc: 0.9371, acc: 0.9052, precision: 0.9541, recall: 0.9272, f1: 0.9405, edges-ner-ontonotes_loss: 0.0201
09/16 07:31:07 AM: Update 30762: task edges-ner-ontonotes, batch 762 (30762): mcc: 0.9372, acc: 0.9051, precision: 0.9541, recall: 0.9272, f1: 0.9405, edges-ner-ontonotes_loss: 0.0201
09/16 07:31:07 AM: Update 30526: task edges-ner-ontonotes, batch 526 (30526): mcc: 0.9363, acc: 0.9043, precision: 0.9534, recall: 0.9263, f1: 0.9396, edges-ner-ontonotes_loss: 0.0202
09/16 07:31:18 AM: Update 30609: task edges-ner-ontonotes, batch 609 (30609): mcc: 0.9368, acc: 0.9050, precision: 0.9539, recall: 0.9268, f1: 0.9402, edges-ner-ontonotes_loss: 0.0202
09/16 07:31:18 AM: Update 30817: task edges-ner-ontonotes, batch 817 (30817): mcc: 0.9370, acc: 0.9049, precision: 0.9541, recall: 0.9270, f1: 0.9404, edges-ner-ontonotes_loss: 0.0201
09/16 07:31:29 AM: Update 30681: task edges-ner-ontonotes, batch 681 (30681): mcc: 0.9374, acc: 0.9055, precision: 0.9544, recall: 0.9274, f1: 0.9407, edges-ner-ontonotes_loss: 0.0201
09/16 07:31:29 AM: Update 30880: task edges-ner-ontonotes, batch 880 (30880): mcc: 0.9345, acc: 0.9015, precision: 0.9527, recall: 0.9237, f1: 0.9380, edges-ner-ontonotes_loss: 0.0211
09/16 07:31:40 AM: Update 30758: task edges-ner-ontonotes, batch 758 (30758): mcc: 0.9372, acc: 0.9051, precision: 0.9542, recall: 0.9272, f1: 0.9405, edges-ner-ontonotes_loss: 0.0201
09/16 07:31:40 AM: Update 30957: task edges-ner-ontonotes, batch 957 (30957): mcc: 0.9318, acc: 0.8981, precision: 0.9510, recall: 0.9204, f1: 0.9354, edges-ner-ontonotes_loss: 0.0223
09/16 07:31:46 AM: ***** Step 31000 / Validation 31 *****
09/16 07:31:46 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:31:46 AM: Validating...
09/16 07:31:50 AM: Update 30817: task edges-ner-ontonotes, batch 817 (30817): mcc: 0.9370, acc: 0.9049, precision: 0.9541, recall: 0.9270, f1: 0.9404, edges-ner-ontonotes_loss: 0.0201
09/16 07:31:51 AM: Evaluate: task edges-ner-ontonotes, batch 34 (157): mcc: 0.9006, acc: 0.8712, precision: 0.9199, recall: 0.8925, f1: 0.9060, edges-ner-ontonotes_loss: 0.0327
09/16 07:32:00 AM: Update 30874: task edges-ner-ontonotes, batch 874 (30874): mcc: 0.9348, acc: 0.9019, precision: 0.9529, recall: 0.9240, f1: 0.9382, edges-ner-ontonotes_loss: 0.0210
09/16 07:32:01 AM: Evaluate: task edges-ner-ontonotes, batch 87 (157): mcc: 0.9297, acc: 0.9032, precision: 0.9459, recall: 0.9214, f1: 0.9335, edges-ner-ontonotes_loss: 0.0248
09/16 07:32:14 AM: Evaluate: task edges-ner-ontonotes, batch 138 (157): mcc: 0.9367, acc: 0.9110, precision: 0.9532, recall: 0.9274, f1: 0.9401, edges-ner-ontonotes_loss: 0.0217
09/16 07:32:14 AM: Update 30934: task edges-ner-ontonotes, batch 934 (30934): mcc: 0.9326, acc: 0.8991, precision: 0.9514, recall: 0.9214, f1: 0.9361, edges-ner-ontonotes_loss: 0.0220
09/16 07:32:19 AM: Updating LR scheduler:
09/16 07:32:19 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:32:19 AM: 	# validation passes without improvement: 1
09/16 07:32:19 AM: edges-ner-ontonotes_loss: training: 0.022693 validation: 0.020835
09/16 07:32:19 AM: macro_avg: validation: 0.941827
09/16 07:32:19 AM: micro_avg: validation: 0.000000
09/16 07:32:19 AM: edges-ner-ontonotes_mcc: training: 0.931001 validation: 0.938549
09/16 07:32:19 AM: edges-ner-ontonotes_acc: training: 0.897083 validation: 0.913330
09/16 07:32:19 AM: edges-ner-ontonotes_precision: training: 0.950579 validation: 0.954666
09/16 07:32:19 AM: edges-ner-ontonotes_recall: training: 0.919209 validation: 0.929330
09/16 07:32:19 AM: edges-ner-ontonotes_f1: training: 0.934631 validation: 0.941827
09/16 07:32:19 AM: Global learning rate: 1.25e-05
09/16 07:32:19 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:32:24 AM: ***** Step 31000 / Validation 31 *****
09/16 07:32:24 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:32:24 AM: Validating...
09/16 07:32:25 AM: Update 31052: task edges-ner-ontonotes, batch 52 (31052): mcc: 0.9040, acc: 0.8597, precision: 0.9374, recall: 0.8817, f1: 0.9087, edges-ner-ontonotes_loss: 0.0347
09/16 07:32:25 AM: Evaluate: task edges-ner-ontonotes, batch 6 (157): mcc: 0.8324, acc: 0.7750, precision: 0.8713, recall: 0.8125, f1: 0.8409, edges-ner-ontonotes_loss: 0.0438
09/16 07:32:37 AM: Update 31109: task edges-ner-ontonotes, batch 109 (31109): mcc: 0.9010, acc: 0.8595, precision: 0.9330, recall: 0.8803, f1: 0.9059, edges-ner-ontonotes_loss: 0.0347
09/16 07:32:37 AM: Evaluate: task edges-ner-ontonotes, batch 69 (157): mcc: 0.9220, acc: 0.8936, precision: 0.9398, recall: 0.9129, f1: 0.9261, edges-ner-ontonotes_loss: 0.0272
09/16 07:32:47 AM: Update 31161: task edges-ner-ontonotes, batch 161 (31161): mcc: 0.9030, acc: 0.8626, precision: 0.9339, recall: 0.8832, f1: 0.9078, edges-ner-ontonotes_loss: 0.0329
09/16 07:32:47 AM: Evaluate: task edges-ner-ontonotes, batch 121 (157): mcc: 0.9328, acc: 0.9054, precision: 0.9503, recall: 0.9228, f1: 0.9363, edges-ner-ontonotes_loss: 0.0230
09/16 07:32:53 AM: Updating LR scheduler:
09/16 07:32:53 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:32:53 AM: 	# validation passes without improvement: 1
09/16 07:32:53 AM: edges-ner-ontonotes_loss: training: 0.022693 validation: 0.020835
09/16 07:32:53 AM: macro_avg: validation: 0.941827
09/16 07:32:53 AM: micro_avg: validation: 0.000000
09/16 07:32:53 AM: edges-ner-ontonotes_mcc: training: 0.931001 validation: 0.938549
09/16 07:32:53 AM: edges-ner-ontonotes_acc: training: 0.897083 validation: 0.913330
09/16 07:32:53 AM: edges-ner-ontonotes_precision: training: 0.950579 validation: 0.954666
09/16 07:32:53 AM: edges-ner-ontonotes_recall: training: 0.919209 validation: 0.929330
09/16 07:32:53 AM: edges-ner-ontonotes_f1: training: 0.934631 validation: 0.941827
09/16 07:32:53 AM: Global learning rate: 1.25e-05
09/16 07:32:53 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:32:57 AM: Update 31238: task edges-ner-ontonotes, batch 238 (31238): mcc: 0.9037, acc: 0.8624, precision: 0.9342, recall: 0.8843, f1: 0.9086, edges-ner-ontonotes_loss: 0.0319
09/16 07:32:57 AM: Update 31030: task edges-ner-ontonotes, batch 30 (31030): mcc: 0.9032, acc: 0.8594, precision: 0.9383, recall: 0.8795, f1: 0.9079, edges-ner-ontonotes_loss: 0.0356
09/16 07:33:07 AM: Update 31323: task edges-ner-ontonotes, batch 323 (31323): mcc: 0.9063, acc: 0.8657, precision: 0.9355, recall: 0.8878, f1: 0.9110, edges-ner-ontonotes_loss: 0.0308
09/16 07:33:07 AM: Update 31111: task edges-ner-ontonotes, batch 111 (31111): mcc: 0.9012, acc: 0.8599, precision: 0.9330, recall: 0.8808, f1: 0.9062, edges-ner-ontonotes_loss: 0.0346
09/16 07:33:17 AM: Update 31417: task edges-ner-ontonotes, batch 417 (31417): mcc: 0.9084, acc: 0.8679, precision: 0.9365, recall: 0.8908, f1: 0.9131, edges-ner-ontonotes_loss: 0.0300
09/16 07:33:17 AM: Update 31175: task edges-ner-ontonotes, batch 175 (31175): mcc: 0.9037, acc: 0.8635, precision: 0.9345, recall: 0.8839, f1: 0.9085, edges-ner-ontonotes_loss: 0.0326
09/16 07:33:27 AM: Update 31476: task edges-ner-ontonotes, batch 476 (31476): mcc: 0.9106, acc: 0.8707, precision: 0.9377, recall: 0.8936, f1: 0.9151, edges-ner-ontonotes_loss: 0.0293
09/16 07:33:27 AM: Update 31269: task edges-ner-ontonotes, batch 269 (31269): mcc: 0.9041, acc: 0.8629, precision: 0.9339, recall: 0.8853, f1: 0.9090, edges-ner-ontonotes_loss: 0.0316
09/16 07:33:37 AM: Update 31555: task edges-ner-ontonotes, batch 555 (31555): mcc: 0.9128, acc: 0.8737, precision: 0.9387, recall: 0.8969, f1: 0.9173, edges-ner-ontonotes_loss: 0.0284
09/16 07:33:37 AM: Update 31352: task edges-ner-ontonotes, batch 352 (31352): mcc: 0.9071, acc: 0.8665, precision: 0.9362, recall: 0.8886, f1: 0.9118, edges-ner-ontonotes_loss: 0.0304
09/16 07:33:47 AM: Update 31636: task edges-ner-ontonotes, batch 636 (31636): mcc: 0.9150, acc: 0.8764, precision: 0.9403, recall: 0.8993, f1: 0.9194, edges-ner-ontonotes_loss: 0.0278
09/16 07:33:50 AM: Update 31434: task edges-ner-ontonotes, batch 434 (31434): mcc: 0.9084, acc: 0.8680, precision: 0.9363, recall: 0.8910, f1: 0.9131, edges-ner-ontonotes_loss: 0.0299
09/16 07:33:57 AM: Update 31721: task edges-ner-ontonotes, batch 721 (31721): mcc: 0.9168, acc: 0.8785, precision: 0.9413, recall: 0.9018, f1: 0.9211, edges-ner-ontonotes_loss: 0.0272
09/16 07:34:00 AM: Update 31506: task edges-ner-ontonotes, batch 506 (31506): mcc: 0.9118, acc: 0.8723, precision: 0.9384, recall: 0.8952, f1: 0.9163, edges-ner-ontonotes_loss: 0.0289
09/16 07:34:07 AM: Update 31777: task edges-ner-ontonotes, batch 777 (31777): mcc: 0.9180, acc: 0.8799, precision: 0.9422, recall: 0.9032, f1: 0.9223, edges-ner-ontonotes_loss: 0.0268
09/16 07:34:10 AM: Update 31592: task edges-ner-ontonotes, batch 592 (31592): mcc: 0.9141, acc: 0.8751, precision: 0.9397, recall: 0.8983, f1: 0.9185, edges-ner-ontonotes_loss: 0.0280
09/16 07:34:18 AM: Update 31857: task edges-ner-ontonotes, batch 857 (31857): mcc: 0.9210, acc: 0.8837, precision: 0.9443, recall: 0.9066, f1: 0.9251, edges-ner-ontonotes_loss: 0.0260
09/16 07:34:22 AM: Update 31671: task edges-ner-ontonotes, batch 671 (31671): mcc: 0.9161, acc: 0.8778, precision: 0.9411, recall: 0.9007, f1: 0.9204, edges-ner-ontonotes_loss: 0.0275
09/16 07:34:29 AM: Update 31933: task edges-ner-ontonotes, batch 933 (31933): mcc: 0.9230, acc: 0.8865, precision: 0.9456, recall: 0.9092, f1: 0.9270, edges-ner-ontonotes_loss: 0.0254
09/16 07:34:33 AM: Update 31747: task edges-ner-ontonotes, batch 747 (31747): mcc: 0.9170, acc: 0.8787, precision: 0.9415, recall: 0.9020, f1: 0.9213, edges-ner-ontonotes_loss: 0.0271
09/16 07:34:39 AM: ***** Step 32000 / Validation 32 *****
09/16 07:34:39 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:34:39 AM: Validating...
09/16 07:34:40 AM: Evaluate: task edges-ner-ontonotes, batch 7 (157): mcc: 0.8376, acc: 0.7909, precision: 0.8702, recall: 0.8233, f1: 0.8461, edges-ner-ontonotes_loss: 0.0425
09/16 07:34:44 AM: Update 31821: task edges-ner-ontonotes, batch 821 (31821): mcc: 0.9197, acc: 0.8821, precision: 0.9435, recall: 0.9051, f1: 0.9239, edges-ner-ontonotes_loss: 0.0263
09/16 07:34:51 AM: Evaluate: task edges-ner-ontonotes, batch 67 (157): mcc: 0.9207, acc: 0.8919, precision: 0.9374, recall: 0.9129, f1: 0.9250, edges-ner-ontonotes_loss: 0.0275
09/16 07:34:54 AM: Update 31878: task edges-ner-ontonotes, batch 878 (31878): mcc: 0.9215, acc: 0.8845, precision: 0.9446, recall: 0.9073, f1: 0.9256, edges-ner-ontonotes_loss: 0.0258
09/16 07:35:01 AM: Evaluate: task edges-ner-ontonotes, batch 118 (157): mcc: 0.9316, acc: 0.9031, precision: 0.9479, recall: 0.9229, f1: 0.9352, edges-ner-ontonotes_loss: 0.0231
09/16 07:35:04 AM: Update 31935: task edges-ner-ontonotes, batch 935 (31935): mcc: 0.9230, acc: 0.8865, precision: 0.9456, recall: 0.9092, f1: 0.9270, edges-ner-ontonotes_loss: 0.0253
09/16 07:35:08 AM: Updating LR scheduler:
09/16 07:35:08 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:35:08 AM: 	# validation passes without improvement: 2
09/16 07:35:08 AM: edges-ner-ontonotes_loss: training: 0.024812 validation: 0.020623
09/16 07:35:08 AM: macro_avg: validation: 0.941988
09/16 07:35:08 AM: micro_avg: validation: 0.000000
09/16 07:35:08 AM: edges-ner-ontonotes_mcc: training: 0.924678 validation: 0.938684
09/16 07:35:08 AM: edges-ner-ontonotes_acc: training: 0.888477 validation: 0.913330
09/16 07:35:08 AM: edges-ner-ontonotes_precision: training: 0.946584 validation: 0.952765
09/16 07:35:08 AM: edges-ner-ontonotes_recall: training: 0.911300 validation: 0.931453
09/16 07:35:08 AM: edges-ner-ontonotes_f1: training: 0.928607 validation: 0.941988
09/16 07:35:08 AM: Global learning rate: 1.25e-05
09/16 07:35:08 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:35:11 AM: Update 32023: task edges-ner-ontonotes, batch 23 (32023): mcc: 0.9463, acc: 0.9188, precision: 0.9605, recall: 0.9381, f1: 0.9492, edges-ner-ontonotes_loss: 0.0169
09/16 07:35:14 AM: Update 31999: task edges-ner-ontonotes, batch 999 (31999): mcc: 0.9247, acc: 0.8884, precision: 0.9465, recall: 0.9113, f1: 0.9286, edges-ner-ontonotes_loss: 0.0248
09/16 07:35:15 AM: ***** Step 32000 / Validation 32 *****
09/16 07:35:15 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:35:15 AM: Validating...
09/16 07:35:21 AM: Update 32073: task edges-ner-ontonotes, batch 73 (32073): mcc: 0.9418, acc: 0.9118, precision: 0.9569, recall: 0.9332, f1: 0.9449, edges-ner-ontonotes_loss: 0.0181
09/16 07:35:25 AM: Evaluate: task edges-ner-ontonotes, batch 67 (157): mcc: 0.9207, acc: 0.8919, precision: 0.9374, recall: 0.9129, f1: 0.9250, edges-ner-ontonotes_loss: 0.0275
09/16 07:35:32 AM: Update 32137: task edges-ner-ontonotes, batch 137 (32137): mcc: 0.9377, acc: 0.9066, precision: 0.9557, recall: 0.9268, f1: 0.9410, edges-ner-ontonotes_loss: 0.0194
09/16 07:35:37 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9301, acc: 0.9012, precision: 0.9468, recall: 0.9212, f1: 0.9338, edges-ner-ontonotes_loss: 0.0235
09/16 07:35:42 AM: Update 32199: task edges-ner-ontonotes, batch 199 (32199): mcc: 0.9388, acc: 0.9077, precision: 0.9558, recall: 0.9287, f1: 0.9421, edges-ner-ontonotes_loss: 0.0190
09/16 07:35:45 AM: Updating LR scheduler:
09/16 07:35:45 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:35:45 AM: 	# validation passes without improvement: 2
09/16 07:35:45 AM: edges-ner-ontonotes_loss: training: 0.024812 validation: 0.020623
09/16 07:35:45 AM: macro_avg: validation: 0.941988
09/16 07:35:45 AM: micro_avg: validation: 0.000000
09/16 07:35:45 AM: edges-ner-ontonotes_mcc: training: 0.924678 validation: 0.938684
09/16 07:35:45 AM: edges-ner-ontonotes_acc: training: 0.888477 validation: 0.913330
09/16 07:35:45 AM: edges-ner-ontonotes_precision: training: 0.946584 validation: 0.952765
09/16 07:35:45 AM: edges-ner-ontonotes_recall: training: 0.911300 validation: 0.931453
09/16 07:35:45 AM: edges-ner-ontonotes_f1: training: 0.928607 validation: 0.941988
09/16 07:35:45 AM: Global learning rate: 1.25e-05
09/16 07:35:45 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:35:49 AM: Update 32001: task edges-ner-ontonotes, batch 1 (32001): mcc: 0.9443, acc: 0.9130, precision: 0.9558, recall: 0.9391, f1: 0.9474, edges-ner-ontonotes_loss: 0.0197
09/16 07:35:52 AM: Update 32283: task edges-ner-ontonotes, batch 283 (32283): mcc: 0.9384, acc: 0.9071, precision: 0.9560, recall: 0.9277, f1: 0.9417, edges-ner-ontonotes_loss: 0.0194
09/16 07:36:00 AM: Update 32060: task edges-ner-ontonotes, batch 60 (32060): mcc: 0.9418, acc: 0.9113, precision: 0.9577, recall: 0.9324, f1: 0.9449, edges-ner-ontonotes_loss: 0.0179
09/16 07:36:02 AM: Update 32364: task edges-ner-ontonotes, batch 364 (32364): mcc: 0.9389, acc: 0.9074, precision: 0.9561, recall: 0.9286, f1: 0.9422, edges-ner-ontonotes_loss: 0.0194
09/16 07:36:10 AM: Update 32143: task edges-ner-ontonotes, batch 143 (32143): mcc: 0.9377, acc: 0.9066, precision: 0.9557, recall: 0.9268, f1: 0.9410, edges-ner-ontonotes_loss: 0.0193
09/16 07:36:12 AM: Update 32419: task edges-ner-ontonotes, batch 419 (32419): mcc: 0.9340, acc: 0.9008, precision: 0.9532, recall: 0.9223, f1: 0.9375, edges-ner-ontonotes_loss: 0.0213
09/16 07:36:20 AM: Update 32211: task edges-ner-ontonotes, batch 211 (32211): mcc: 0.9388, acc: 0.9076, precision: 0.9556, recall: 0.9289, f1: 0.9421, edges-ner-ontonotes_loss: 0.0191
09/16 07:36:22 AM: Update 32493: task edges-ner-ontonotes, batch 493 (32493): mcc: 0.9300, acc: 0.8958, precision: 0.9506, recall: 0.9172, f1: 0.9336, edges-ner-ontonotes_loss: 0.0230
09/16 07:36:30 AM: Update 32290: task edges-ner-ontonotes, batch 290 (32290): mcc: 0.9385, acc: 0.9073, precision: 0.9561, recall: 0.9279, f1: 0.9418, edges-ner-ontonotes_loss: 0.0194
09/16 07:36:32 AM: Update 32566: task edges-ner-ontonotes, batch 566 (32566): mcc: 0.9262, acc: 0.8913, precision: 0.9480, recall: 0.9128, f1: 0.9301, edges-ner-ontonotes_loss: 0.0248
09/16 07:36:40 AM: Update 32361: task edges-ner-ontonotes, batch 361 (32361): mcc: 0.9388, acc: 0.9072, precision: 0.9560, recall: 0.9284, f1: 0.9420, edges-ner-ontonotes_loss: 0.0194
09/16 07:36:42 AM: Update 32644: task edges-ner-ontonotes, batch 644 (32644): mcc: 0.9245, acc: 0.8888, precision: 0.9471, recall: 0.9104, f1: 0.9284, edges-ner-ontonotes_loss: 0.0257
09/16 07:36:50 AM: Update 32430: task edges-ner-ontonotes, batch 430 (32430): mcc: 0.9335, acc: 0.9002, precision: 0.9528, recall: 0.9217, f1: 0.9370, edges-ner-ontonotes_loss: 0.0216
09/16 07:36:52 AM: Update 32704: task edges-ner-ontonotes, batch 704 (32704): mcc: 0.9228, acc: 0.8868, precision: 0.9460, recall: 0.9083, f1: 0.9268, edges-ner-ontonotes_loss: 0.0264
09/16 07:37:00 AM: Update 32505: task edges-ner-ontonotes, batch 505 (32505): mcc: 0.9290, acc: 0.8948, precision: 0.9498, recall: 0.9163, f1: 0.9328, edges-ner-ontonotes_loss: 0.0234
09/16 07:37:02 AM: Update 32792: task edges-ner-ontonotes, batch 792 (32792): mcc: 0.9222, acc: 0.8859, precision: 0.9455, recall: 0.9077, f1: 0.9262, edges-ner-ontonotes_loss: 0.0264
09/16 07:37:10 AM: Update 32585: task edges-ner-ontonotes, batch 585 (32585): mcc: 0.9258, acc: 0.8907, precision: 0.9477, recall: 0.9123, f1: 0.9296, edges-ner-ontonotes_loss: 0.0251
09/16 07:37:12 AM: Update 32873: task edges-ner-ontonotes, batch 873 (32873): mcc: 0.9214, acc: 0.8850, precision: 0.9448, recall: 0.9069, f1: 0.9255, edges-ner-ontonotes_loss: 0.0265
09/16 07:37:20 AM: Update 32665: task edges-ner-ontonotes, batch 665 (32665): mcc: 0.9238, acc: 0.8881, precision: 0.9467, recall: 0.9096, f1: 0.9278, edges-ner-ontonotes_loss: 0.0259
09/16 07:37:23 AM: Update 32962: task edges-ner-ontonotes, batch 962 (32962): mcc: 0.9204, acc: 0.8837, precision: 0.9438, recall: 0.9060, f1: 0.9245, edges-ner-ontonotes_loss: 0.0269
09/16 07:37:29 AM: ***** Step 33000 / Validation 33 *****
09/16 07:37:29 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:37:29 AM: Validating...
09/16 07:37:31 AM: Update 32734: task edges-ner-ontonotes, batch 734 (32734): mcc: 0.9227, acc: 0.8866, precision: 0.9457, recall: 0.9084, f1: 0.9267, edges-ner-ontonotes_loss: 0.0264
09/16 07:37:33 AM: Evaluate: task edges-ner-ontonotes, batch 24 (157): mcc: 0.8765, acc: 0.8449, precision: 0.8989, recall: 0.8679, f1: 0.8831, edges-ner-ontonotes_loss: 0.0370
09/16 07:37:41 AM: Update 32802: task edges-ner-ontonotes, batch 802 (32802): mcc: 0.9222, acc: 0.8860, precision: 0.9455, recall: 0.9078, f1: 0.9263, edges-ner-ontonotes_loss: 0.0264
09/16 07:37:44 AM: Evaluate: task edges-ner-ontonotes, batch 87 (157): mcc: 0.9298, acc: 0.9036, precision: 0.9455, recall: 0.9220, f1: 0.9336, edges-ner-ontonotes_loss: 0.0243
09/16 07:37:51 AM: Update 32861: task edges-ner-ontonotes, batch 861 (32861): mcc: 0.9216, acc: 0.8854, precision: 0.9449, recall: 0.9071, f1: 0.9256, edges-ner-ontonotes_loss: 0.0265
09/16 07:37:54 AM: Evaluate: task edges-ner-ontonotes, batch 140 (157): mcc: 0.9369, acc: 0.9116, precision: 0.9531, recall: 0.9278, f1: 0.9403, edges-ner-ontonotes_loss: 0.0212
09/16 07:37:57 AM: Updating LR scheduler:
09/16 07:37:57 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:37:57 AM: 	# validation passes without improvement: 3
09/16 07:37:57 AM: edges-ner-ontonotes_loss: training: 0.026878 validation: 0.020508
09/16 07:37:57 AM: macro_avg: validation: 0.941660
09/16 07:37:57 AM: micro_avg: validation: 0.000000
09/16 07:37:57 AM: edges-ner-ontonotes_mcc: training: 0.920139 validation: 0.938364
09/16 07:37:57 AM: edges-ner-ontonotes_acc: training: 0.883346 validation: 0.913634
09/16 07:37:57 AM: edges-ner-ontonotes_precision: training: 0.943624 validation: 0.954082
09/16 07:37:57 AM: edges-ner-ontonotes_recall: training: 0.905713 validation: 0.929557
09/16 07:37:57 AM: edges-ner-ontonotes_f1: training: 0.924280 validation: 0.941660
09/16 07:37:57 AM: Global learning rate: 1.25e-05
09/16 07:37:57 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:38:01 AM: Update 32935: task edges-ner-ontonotes, batch 935 (32935): mcc: 0.9206, acc: 0.8841, precision: 0.9439, recall: 0.9062, f1: 0.9247, edges-ner-ontonotes_loss: 0.0268
09/16 07:38:04 AM: Update 33057: task edges-ner-ontonotes, batch 57 (33057): mcc: 0.9172, acc: 0.8778, precision: 0.9386, recall: 0.9051, f1: 0.9215, edges-ner-ontonotes_loss: 0.0268
09/16 07:38:11 AM: Update 32993: task edges-ner-ontonotes, batch 993 (32993): mcc: 0.9201, acc: 0.8834, precision: 0.9436, recall: 0.9057, f1: 0.9243, edges-ner-ontonotes_loss: 0.0269
09/16 07:38:12 AM: ***** Step 33000 / Validation 33 *****
09/16 07:38:12 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:38:12 AM: Validating...
09/16 07:38:14 AM: Update 33136: task edges-ner-ontonotes, batch 136 (33136): mcc: 0.9244, acc: 0.8906, precision: 0.9470, recall: 0.9105, f1: 0.9284, edges-ner-ontonotes_loss: 0.0246
09/16 07:38:21 AM: Evaluate: task edges-ner-ontonotes, batch 58 (157): mcc: 0.9215, acc: 0.8952, precision: 0.9357, recall: 0.9160, f1: 0.9258, edges-ner-ontonotes_loss: 0.0265
09/16 07:38:25 AM: Update 33195: task edges-ner-ontonotes, batch 195 (33195): mcc: 0.9261, acc: 0.8926, precision: 0.9477, recall: 0.9129, f1: 0.9300, edges-ner-ontonotes_loss: 0.0237
09/16 07:38:32 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9302, acc: 0.9024, precision: 0.9479, recall: 0.9203, f1: 0.9339, edges-ner-ontonotes_loss: 0.0231
09/16 07:38:35 AM: Update 33254: task edges-ner-ontonotes, batch 254 (33254): mcc: 0.9266, acc: 0.8929, precision: 0.9470, recall: 0.9145, f1: 0.9305, edges-ner-ontonotes_loss: 0.0235
09/16 07:38:39 AM: Updating LR scheduler:
09/16 07:38:39 AM: 	Best result seen so far for macro_avg: 0.942
09/16 07:38:39 AM: 	# validation passes without improvement: 3
09/16 07:38:39 AM: edges-ner-ontonotes_loss: training: 0.026878 validation: 0.020508
09/16 07:38:39 AM: macro_avg: validation: 0.941660
09/16 07:38:39 AM: micro_avg: validation: 0.000000
09/16 07:38:39 AM: edges-ner-ontonotes_mcc: training: 0.920139 validation: 0.938364
09/16 07:38:39 AM: edges-ner-ontonotes_acc: training: 0.883346 validation: 0.913634
09/16 07:38:39 AM: edges-ner-ontonotes_precision: training: 0.943624 validation: 0.954082
09/16 07:38:39 AM: edges-ner-ontonotes_recall: training: 0.905713 validation: 0.929557
09/16 07:38:39 AM: edges-ner-ontonotes_f1: training: 0.924280 validation: 0.941660
09/16 07:38:39 AM: Global learning rate: 1.25e-05
09/16 07:38:39 AM: Saving checkpoints to: ./experiments/ner-ontonotes-mrpc-top/run
09/16 07:38:42 AM: Update 33017: task edges-ner-ontonotes, batch 17 (33017): mcc: 0.9149, acc: 0.8794, precision: 0.9401, recall: 0.8994, f1: 0.9193, edges-ner-ontonotes_loss: 0.0280
09/16 07:38:46 AM: Update 33303: task edges-ner-ontonotes, batch 303 (33303): mcc: 0.9266, acc: 0.8927, precision: 0.9466, recall: 0.9149, f1: 0.9305, edges-ner-ontonotes_loss: 0.0235
09/16 07:38:52 AM: Update 33112: task edges-ner-ontonotes, batch 112 (33112): mcc: 0.9227, acc: 0.8878, precision: 0.9455, recall: 0.9086, f1: 0.9267, edges-ner-ontonotes_loss: 0.0251
