09/16 12:14:42 PM: Git branch: master
09/16 12:14:42 PM: Git SHA: 93c1dfd555f3458ddbb66d458dfeca984f2d8527
09/16 12:14:42 PM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/ner-ontonotes-sts-only/",
  "exp_name": "experiments/ner-ontonotes-sts-only",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/ner-ontonotes-sts-only/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/sts",
  "pytorch_transformers_output_mode": "only",
  "remote_log_name": "experiments/ner-ontonotes-sts-only__run",
  "run_dir": "./experiments/ner-ontonotes-sts-only/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-ner-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 12:14:42 PM: Saved config to ./experiments/ner-ontonotes-sts-only/run/params.conf
09/16 12:14:42 PM: Using random seed 1234
09/16 12:15:22 PM: Using GPU 0
09/16 12:15:22 PM: Loading tasks...
09/16 12:15:22 PM: Writing pre-preprocessed tasks to ./experiments/ner-ontonotes-sts-only/
09/16 12:15:22 PM: 	Creating task edges-ner-ontonotes from scratch.
09/16 12:15:23 PM: Read=49706, Skip=66106, Total=115812 from ./probing_data/edges/ontonotes/ner/train.json.retokenized.bert-base-uncased
09/16 12:15:24 PM: Read=7610, Skip=8070, Total=15680 from ./probing_data/edges/ontonotes/ner/development.json.retokenized.bert-base-uncased
09/16 12:15:24 PM: Read=5099, Skip=7118, Total=12217 from ./probing_data/edges/ontonotes/ner/test.json.retokenized.bert-base-uncased
09/16 12:15:25 PM: 	Task 'edges-ner-ontonotes': |train|=49706 |val|=7610 |test|=5099
09/16 12:15:25 PM: 	Finished loading tasks: edges-ner-ontonotes.
09/16 12:15:25 PM: 	Building vocab from scratch.
09/16 12:15:25 PM: 	Counting units for task edges-ner-ontonotes.
09/16 12:15:27 PM: 	Task 'edges-ner-ontonotes': adding vocab namespace 'edges-ner-ontonotes_labels'
09/16 12:15:28 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:15:28 PM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 12:15:29 PM: 	Saved vocab to ./experiments/ner-ontonotes-sts-only/vocab
09/16 12:15:29 PM: Loading token dictionary from ./experiments/ner-ontonotes-sts-only/vocab.
09/16 12:15:29 PM: 	Loaded vocab from ./experiments/ner-ontonotes-sts-only/vocab
09/16 12:15:29 PM: 	Vocab namespace edges-ner-ontonotes_labels: size 18
09/16 12:15:29 PM: 	Vocab namespace tokens: size 22840
09/16 12:15:29 PM: 	Vocab namespace bert_uncased: size 30524
09/16 12:15:29 PM: 	Vocab namespace chars: size 77
09/16 12:15:29 PM: 	Finished building vocab.
09/16 12:15:29 PM: 	Task edges-ner-ontonotes (train): Indexing from scratch.
09/16 12:15:43 PM: 	Task edges-ner-ontonotes (train): Saved 49706 instances to ./experiments/ner-ontonotes-sts-only/preproc/edges-ner-ontonotes__train_data
09/16 12:15:43 PM: 	Task edges-ner-ontonotes (val): Indexing from scratch.
09/16 12:15:45 PM: 	Task edges-ner-ontonotes (val): Saved 7610 instances to ./experiments/ner-ontonotes-sts-only/preproc/edges-ner-ontonotes__val_data
09/16 12:15:45 PM: 	Task edges-ner-ontonotes (test): Indexing from scratch.
09/16 12:15:46 PM: 	Task edges-ner-ontonotes (test): Saved 5099 instances to ./experiments/ner-ontonotes-sts-only/preproc/edges-ner-ontonotes__test_data
09/16 12:15:46 PM: 	Finished indexing tasks
09/16 12:15:46 PM: 	Creating trimmed target-only version of edges-ner-ontonotes train.
09/16 12:15:46 PM: 	  Training on 
09/16 12:15:46 PM: 	  Evaluating on edges-ner-ontonotes
09/16 12:15:46 PM: 	Finished loading tasks in 24.561s
09/16 12:15:46 PM: 	 Tasks: ['edges-ner-ontonotes']
09/16 12:15:46 PM: Building model...
09/16 12:15:46 PM: Using BERT model (bert-base-uncased).
09/16 12:15:46 PM: LOADING A FUNETUNED MODEL from: 
09/16 12:15:46 PM: models/sts
09/16 12:15:46 PM: loading configuration file models/sts/config.json
09/16 12:15:46 PM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "sts-b",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 12:15:46 PM: loading weights file models/sts/pytorch_model.bin
09/16 12:15:52 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpou5k63h1
09/16 12:15:55 PM: copying /tmp/tmpou5k63h1 to cache at ./experiments/ner-ontonotes-sts-only/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:15:55 PM: creating metadata file for ./experiments/ner-ontonotes-sts-only/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:15:55 PM: removing temp file /tmp/tmpou5k63h1
09/16 12:15:55 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/ner-ontonotes-sts-only/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 12:15:56 PM: Initializing parameters
09/16 12:15:56 PM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 12:15:56 PM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 12:15:56 PM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 12:15:56 PM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 12:15:56 PM:    _text_field_embedder.model.pooler.dense.bias
09/16 12:15:56 PM:    _text_field_embedder.model.pooler.dense.weight
09/16 12:15:56 PM: 	Task 'edges-ner-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-ner-ontonotes"
}
09/16 12:17:37 PM: Model specification:
09/16 12:17:37 PM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-ner-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=18, bias=True)
    )
  )
)
09/16 12:17:37 PM: Model parameters:
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 12:17:37 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 12:17:37 PM: 	edges-ner-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 12:17:37 PM: 	edges-ner-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 12:17:37 PM: 	edges-ner-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 9216 with torch.Size([18, 512])
09/16 12:17:37 PM: 	edges-ner-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 18 with torch.Size([18])
09/16 12:17:37 PM: Total number of parameters: 109688338 (1.09688e+08)
09/16 12:17:37 PM: Number of trainable parameters: 206098 (206098)
09/16 12:17:37 PM: Finished building model in 110.489s
09/16 12:17:37 PM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-ner-ontonotes 

09/16 12:17:50 PM: patience = 9
09/16 12:17:50 PM: val_interval = 1000
09/16 12:17:50 PM: max_vals = 250
09/16 12:17:50 PM: cuda_device = 0
09/16 12:17:50 PM: grad_norm = 5.0
09/16 12:17:50 PM: grad_clipping = None
09/16 12:17:50 PM: lr_decay = 0.99
09/16 12:17:50 PM: min_lr = 1e-06
09/16 12:17:50 PM: keep_all_checkpoints = 0
09/16 12:17:50 PM: val_data_limit = 5000
09/16 12:17:50 PM: max_epochs = -1
09/16 12:17:50 PM: dec_val_scale = 250
09/16 12:17:50 PM: training_data_fraction = 1
09/16 12:17:50 PM: type = adam
09/16 12:17:50 PM: parameter_groups = None
09/16 12:17:50 PM: Number of trainable parameters: 206098
09/16 12:17:50 PM: infer_type_and_cast = True
09/16 12:17:50 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:17:50 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:17:50 PM: lr = 0.0001
09/16 12:17:50 PM: amsgrad = True
09/16 12:17:50 PM: type = reduce_on_plateau
09/16 12:17:50 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:17:50 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:17:50 PM: mode = max
09/16 12:17:50 PM: factor = 0.5
09/16 12:17:50 PM: patience = 3
09/16 12:17:50 PM: threshold = 0.0001
09/16 12:17:50 PM: threshold_mode = abs
09/16 12:17:50 PM: verbose = True
09/16 12:17:50 PM: type = adam
09/16 12:17:50 PM: parameter_groups = None
09/16 12:17:50 PM: Number of trainable parameters: 206098
09/16 12:17:50 PM: infer_type_and_cast = True
09/16 12:17:50 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:17:50 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:17:50 PM: lr = 0.0001
09/16 12:17:50 PM: amsgrad = True
09/16 12:17:50 PM: type = reduce_on_plateau
09/16 12:17:50 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 12:17:50 PM: CURRENTLY DEFINED PARAMETERS: 
09/16 12:17:50 PM: mode = max
09/16 12:17:50 PM: factor = 0.5
09/16 12:17:50 PM: patience = 3
09/16 12:17:50 PM: threshold = 0.0001
09/16 12:17:50 PM: threshold_mode = abs
09/16 12:17:50 PM: verbose = True
09/16 12:17:50 PM: Starting training without restoring from a checkpoint.
09/16 12:17:50 PM: Training examples per task, before any subsampling: {'edges-ner-ontonotes': 49706}
09/16 12:17:50 PM: Beginning training with stopping criteria based on metric: edges-ner-ontonotes_f1
09/16 12:18:00 PM: Update 9: task edges-ner-ontonotes, batch 9 (9): mcc: 0.0154, acc: 0.0025, precision: 0.0600, recall: 0.4114, f1: 0.1048, edges-ner-ontonotes_loss: 0.6551
09/16 12:18:10 PM: Update 132: task edges-ner-ontonotes, batch 132 (132): mcc: 0.1899, acc: 0.1723, precision: 0.2199, recall: 0.2591, f1: 0.2379, edges-ner-ontonotes_loss: 0.2823
09/16 12:18:20 PM: Update 223: task edges-ner-ontonotes, batch 223 (223): mcc: 0.3381, acc: 0.3071, precision: 0.3885, recall: 0.3589, f1: 0.3732, edges-ner-ontonotes_loss: 0.2094
09/16 12:18:33 PM: Update 314: task edges-ner-ontonotes, batch 314 (314): mcc: 0.4460, acc: 0.4023, precision: 0.5120, recall: 0.4398, f1: 0.4731, edges-ner-ontonotes_loss: 0.1725
09/16 12:18:43 PM: Update 398: task edges-ner-ontonotes, batch 398 (398): mcc: 0.5097, acc: 0.4552, precision: 0.5890, recall: 0.4846, f1: 0.5317, edges-ner-ontonotes_loss: 0.1534
09/16 12:18:53 PM: Update 504: task edges-ner-ontonotes, batch 504 (504): mcc: 0.5719, acc: 0.5107, precision: 0.6579, recall: 0.5349, f1: 0.5901, edges-ner-ontonotes_loss: 0.1358
09/16 12:19:03 PM: Update 576: task edges-ner-ontonotes, batch 576 (576): mcc: 0.6038, acc: 0.5396, precision: 0.6919, recall: 0.5617, f1: 0.6201, edges-ner-ontonotes_loss: 0.1266
09/16 12:19:13 PM: Update 650: task edges-ner-ontonotes, batch 650 (650): mcc: 0.6285, acc: 0.5628, precision: 0.7175, recall: 0.5834, f1: 0.6435, edges-ner-ontonotes_loss: 0.1190
09/16 12:19:23 PM: Update 735: task edges-ner-ontonotes, batch 735 (735): mcc: 0.6521, acc: 0.5837, precision: 0.7413, recall: 0.6043, f1: 0.6659, edges-ner-ontonotes_loss: 0.1122
09/16 12:19:33 PM: Update 824: task edges-ner-ontonotes, batch 824 (824): mcc: 0.6698, acc: 0.6002, precision: 0.7580, recall: 0.6212, f1: 0.6829, edges-ner-ontonotes_loss: 0.1061
09/16 12:19:43 PM: Update 900: task edges-ner-ontonotes, batch 900 (900): mcc: 0.6843, acc: 0.6146, precision: 0.7708, recall: 0.6358, f1: 0.6968, edges-ner-ontonotes_loss: 0.1015
09/16 12:19:56 PM: Update 940: task edges-ner-ontonotes, batch 940 (940): mcc: 0.6908, acc: 0.6212, precision: 0.7764, recall: 0.6425, f1: 0.7031, edges-ner-ontonotes_loss: 0.0994
09/16 12:20:01 PM: ***** Step 1000 / Validation 1 *****
09/16 12:20:01 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:20:01 PM: Validating...
09/16 12:20:08 PM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.7977, acc: 0.7256, precision: 0.8701, recall: 0.7503, f1: 0.8058, edges-ner-ontonotes_loss: 0.0672
09/16 12:20:17 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:20:17 PM: Best result seen so far for micro.
09/16 12:20:17 PM: Best result seen so far for macro.
09/16 12:20:17 PM: Updating LR scheduler:
09/16 12:20:17 PM: 	Best result seen so far for macro_avg: 0.821
09/16 12:20:17 PM: 	# validation passes without improvement: 0
09/16 12:20:17 PM: edges-ner-ontonotes_loss: training: 0.096765 validation: 0.058286
09/16 12:20:17 PM: macro_avg: validation: 0.821054
09/16 12:20:17 PM: micro_avg: validation: 0.000000
09/16 12:20:17 PM: edges-ner-ontonotes_mcc: training: 0.698325 validation: 0.813617
09/16 12:20:17 PM: edges-ner-ontonotes_acc: training: 0.628338 validation: 0.744844
09/16 12:20:17 PM: edges-ner-ontonotes_precision: training: 0.783009 validation: 0.884030
09/16 12:20:17 PM: edges-ner-ontonotes_recall: training: 0.650041 validation: 0.766454
09/16 12:20:17 PM: edges-ner-ontonotes_f1: training: 0.710356 validation: 0.821054
09/16 12:20:17 PM: Global learning rate: 0.0001
09/16 12:20:17 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 12:20:18 PM: Update 1013: task edges-ner-ontonotes, batch 13 (1013): mcc: 0.8311, acc: 0.7706, precision: 0.8809, recall: 0.8009, f1: 0.8390, edges-ner-ontonotes_loss: 0.0493
09/16 12:20:28 PM: Update 1132: task edges-ner-ontonotes, batch 132 (1132): mcc: 0.8284, acc: 0.7634, precision: 0.8893, recall: 0.7884, f1: 0.8358, edges-ner-ontonotes_loss: 0.0493
09/16 12:20:40 PM: Update 1253: task edges-ner-ontonotes, batch 253 (1253): mcc: 0.8302, acc: 0.7649, precision: 0.8916, recall: 0.7894, f1: 0.8374, edges-ner-ontonotes_loss: 0.0486
09/16 12:20:50 PM: Update 1427: task edges-ner-ontonotes, batch 427 (1427): mcc: 0.8193, acc: 0.7532, precision: 0.8867, recall: 0.7743, f1: 0.8267, edges-ner-ontonotes_loss: 0.0541
09/16 12:21:02 PM: Update 1557: task edges-ner-ontonotes, batch 557 (1557): mcc: 0.8194, acc: 0.7536, precision: 0.8878, recall: 0.7734, f1: 0.8267, edges-ner-ontonotes_loss: 0.0549
09/16 12:21:12 PM: Update 1681: task edges-ner-ontonotes, batch 681 (1681): mcc: 0.8241, acc: 0.7603, precision: 0.8913, recall: 0.7787, f1: 0.8312, edges-ner-ontonotes_loss: 0.0534
09/16 12:21:22 PM: Update 1853: task edges-ner-ontonotes, batch 853 (1853): mcc: 0.8310, acc: 0.7705, precision: 0.8959, recall: 0.7871, f1: 0.8380, edges-ner-ontonotes_loss: 0.0514
09/16 12:21:32 PM: Update 1893: task edges-ner-ontonotes, batch 893 (1893): mcc: 0.8316, acc: 0.7714, precision: 0.8962, recall: 0.7878, f1: 0.8385, edges-ner-ontonotes_loss: 0.0511
09/16 12:21:38 PM: ***** Step 2000 / Validation 2 *****
09/16 12:21:38 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:21:38 PM: Validating...
09/16 12:21:42 PM: Evaluate: task edges-ner-ontonotes, batch 65 (157): mcc: 0.8465, acc: 0.7978, precision: 0.9077, recall: 0.8043, f1: 0.8529, edges-ner-ontonotes_loss: 0.0500
09/16 12:21:50 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:21:50 PM: Best result seen so far for macro.
09/16 12:21:50 PM: Updating LR scheduler:
09/16 12:21:50 PM: 	Best result seen so far for macro_avg: 0.842
09/16 12:21:50 PM: 	# validation passes without improvement: 0
09/16 12:21:50 PM: edges-ner-ontonotes_loss: training: 0.050693 validation: 0.049470
09/16 12:21:50 PM: macro_avg: validation: 0.842451
09/16 12:21:50 PM: micro_avg: validation: 0.000000
09/16 12:21:50 PM: edges-ner-ontonotes_mcc: training: 0.832638 validation: 0.835261
09/16 12:21:50 PM: edges-ner-ontonotes_acc: training: 0.773369 validation: 0.783970
09/16 12:21:50 PM: edges-ner-ontonotes_precision: training: 0.896205 validation: 0.893480
09/16 12:21:50 PM: edges-ner-ontonotes_recall: training: 0.789711 validation: 0.796937
09/16 12:21:50 PM: edges-ner-ontonotes_f1: training: 0.839595 validation: 0.842451
09/16 12:21:50 PM: Global learning rate: 0.0001
09/16 12:21:50 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 12:21:52 PM: Update 2029: task edges-ner-ontonotes, batch 29 (2029): mcc: 0.8507, acc: 0.7976, precision: 0.9067, recall: 0.8129, f1: 0.8572, edges-ner-ontonotes_loss: 0.0423
09/16 12:22:02 PM: Update 2152: task edges-ner-ontonotes, batch 152 (2152): mcc: 0.8575, acc: 0.8073, precision: 0.9118, recall: 0.8205, f1: 0.8638, edges-ner-ontonotes_loss: 0.0422
09/16 12:22:12 PM: Update 2257: task edges-ner-ontonotes, batch 257 (2257): mcc: 0.8517, acc: 0.7999, precision: 0.9031, recall: 0.8180, f1: 0.8585, edges-ner-ontonotes_loss: 0.0429
09/16 12:22:23 PM: Update 2405: task edges-ner-ontonotes, batch 405 (2405): mcc: 0.8512, acc: 0.7979, precision: 0.9003, recall: 0.8196, f1: 0.8581, edges-ner-ontonotes_loss: 0.0427
09/16 12:22:36 PM: Update 2496: task edges-ner-ontonotes, batch 496 (2496): mcc: 0.8535, acc: 0.8009, precision: 0.9006, recall: 0.8235, f1: 0.8604, edges-ner-ontonotes_loss: 0.0419
09/16 12:22:46 PM: Update 2657: task edges-ner-ontonotes, batch 657 (2657): mcc: 0.8522, acc: 0.7989, precision: 0.8988, recall: 0.8229, f1: 0.8592, edges-ner-ontonotes_loss: 0.0420
09/16 12:22:56 PM: Update 2744: task edges-ner-ontonotes, batch 744 (2744): mcc: 0.8526, acc: 0.7991, precision: 0.8989, recall: 0.8236, f1: 0.8596, edges-ner-ontonotes_loss: 0.0419
09/16 12:23:06 PM: Update 2839: task edges-ner-ontonotes, batch 839 (2839): mcc: 0.8529, acc: 0.7997, precision: 0.8993, recall: 0.8236, f1: 0.8598, edges-ner-ontonotes_loss: 0.0421
09/16 12:23:16 PM: Update 2933: task edges-ner-ontonotes, batch 933 (2933): mcc: 0.8511, acc: 0.7980, precision: 0.8985, recall: 0.8213, f1: 0.8581, edges-ner-ontonotes_loss: 0.0431
09/16 12:23:21 PM: ***** Step 3000 / Validation 3 *****
09/16 12:23:21 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:23:21 PM: Validating...
09/16 12:23:26 PM: Evaluate: task edges-ner-ontonotes, batch 91 (157): mcc: 0.8514, acc: 0.8012, precision: 0.9093, recall: 0.8117, f1: 0.8577, edges-ner-ontonotes_loss: 0.0494
09/16 12:23:30 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:23:30 PM: Best result seen so far for macro.
09/16 12:23:30 PM: Updating LR scheduler:
09/16 12:23:30 PM: 	Best result seen so far for macro_avg: 0.852
09/16 12:23:30 PM: 	# validation passes without improvement: 0
09/16 12:23:30 PM: edges-ner-ontonotes_loss: training: 0.043663 validation: 0.047364
09/16 12:23:30 PM: macro_avg: validation: 0.852115
09/16 12:23:30 PM: micro_avg: validation: 0.000000
09/16 12:23:30 PM: edges-ner-ontonotes_mcc: training: 0.850522 validation: 0.845334
09/16 12:23:30 PM: edges-ner-ontonotes_acc: training: 0.797372 validation: 0.796557
09/16 12:23:30 PM: edges-ner-ontonotes_precision: training: 0.898175 validation: 0.901506
09/16 12:23:30 PM: edges-ner-ontonotes_recall: training: 0.820406 validation: 0.807856
09/16 12:23:30 PM: edges-ner-ontonotes_f1: training: 0.857531 validation: 0.852115
09/16 12:23:30 PM: Global learning rate: 0.0001
09/16 12:23:30 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 12:23:36 PM: Update 3069: task edges-ner-ontonotes, batch 69 (3069): mcc: 0.8416, acc: 0.7863, precision: 0.8990, recall: 0.8034, f1: 0.8485, edges-ner-ontonotes_loss: 0.0516
09/16 12:23:46 PM: Update 3120: task edges-ner-ontonotes, batch 120 (3120): mcc: 0.8387, acc: 0.7851, precision: 0.8957, recall: 0.8011, f1: 0.8458, edges-ner-ontonotes_loss: 0.0511
09/16 12:23:56 PM: Update 3239: task edges-ner-ontonotes, batch 239 (3239): mcc: 0.8554, acc: 0.8086, precision: 0.9057, recall: 0.8224, f1: 0.8620, edges-ner-ontonotes_loss: 0.0456
09/16 12:24:06 PM: Update 3347: task edges-ner-ontonotes, batch 347 (3347): mcc: 0.8624, acc: 0.8183, precision: 0.9095, recall: 0.8316, f1: 0.8688, edges-ner-ontonotes_loss: 0.0432
09/16 12:24:18 PM: Update 3426: task edges-ner-ontonotes, batch 426 (3426): mcc: 0.8650, acc: 0.8220, precision: 0.9107, recall: 0.8352, f1: 0.8714, edges-ner-ontonotes_loss: 0.0421
09/16 12:24:28 PM: Update 3543: task edges-ner-ontonotes, batch 543 (3543): mcc: 0.8628, acc: 0.8185, precision: 0.9092, recall: 0.8325, f1: 0.8692, edges-ner-ontonotes_loss: 0.0422
09/16 12:24:39 PM: Update 3702: task edges-ner-ontonotes, batch 702 (3702): mcc: 0.8650, acc: 0.8208, precision: 0.9106, recall: 0.8353, f1: 0.8714, edges-ner-ontonotes_loss: 0.0414
09/16 12:24:49 PM: Update 3764: task edges-ner-ontonotes, batch 764 (3764): mcc: 0.8647, acc: 0.8203, precision: 0.9101, recall: 0.8352, f1: 0.8711, edges-ner-ontonotes_loss: 0.0414
09/16 12:24:59 PM: Update 3882: task edges-ner-ontonotes, batch 882 (3882): mcc: 0.8638, acc: 0.8186, precision: 0.9079, recall: 0.8357, f1: 0.8703, edges-ner-ontonotes_loss: 0.0411
09/16 12:25:09 PM: Update 3994: task edges-ner-ontonotes, batch 994 (3994): mcc: 0.8642, acc: 0.8188, precision: 0.9074, recall: 0.8368, f1: 0.8707, edges-ner-ontonotes_loss: 0.0406
09/16 12:25:09 PM: ***** Step 4000 / Validation 4 *****
09/16 12:25:09 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:25:09 PM: Validating...
09/16 12:25:18 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:25:18 PM: Best result seen so far for macro.
09/16 12:25:18 PM: Updating LR scheduler:
09/16 12:25:18 PM: 	Best result seen so far for macro_avg: 0.859
09/16 12:25:18 PM: 	# validation passes without improvement: 0
09/16 12:25:18 PM: edges-ner-ontonotes_loss: training: 0.040590 validation: 0.045570
09/16 12:25:18 PM: macro_avg: validation: 0.858562
09/16 12:25:18 PM: micro_avg: validation: 0.000000
09/16 12:25:18 PM: edges-ner-ontonotes_mcc: training: 0.864367 validation: 0.851328
09/16 12:25:18 PM: edges-ner-ontonotes_acc: training: 0.818889 validation: 0.809524
09/16 12:25:18 PM: edges-ner-ontonotes_precision: training: 0.907603 validation: 0.893821
09/16 12:25:18 PM: edges-ner-ontonotes_recall: training: 0.836953 validation: 0.825978
09/16 12:25:18 PM: edges-ner-ontonotes_f1: training: 0.870848 validation: 0.858562
09/16 12:25:18 PM: Global learning rate: 0.0001
09/16 12:25:18 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 12:25:19 PM: Update 4001: task edges-ner-ontonotes, batch 1 (4001): mcc: 0.8104, acc: 0.7395, precision: 0.8611, recall: 0.7815, f1: 0.8194, edges-ner-ontonotes_loss: 0.0516
09/16 12:25:29 PM: Update 4144: task edges-ner-ontonotes, batch 144 (4144): mcc: 0.8654, acc: 0.8175, precision: 0.8997, recall: 0.8464, f1: 0.8722, edges-ner-ontonotes_loss: 0.0372
09/16 12:25:39 PM: Update 4317: task edges-ner-ontonotes, batch 317 (4317): mcc: 0.8677, acc: 0.8206, precision: 0.9034, recall: 0.8470, f1: 0.8743, edges-ner-ontonotes_loss: 0.0370
09/16 12:25:49 PM: Update 4390: task edges-ner-ontonotes, batch 390 (4390): mcc: 0.8644, acc: 0.8166, precision: 0.9015, recall: 0.8429, f1: 0.8712, edges-ner-ontonotes_loss: 0.0384
09/16 12:25:59 PM: Update 4497: task edges-ner-ontonotes, batch 497 (4497): mcc: 0.8609, acc: 0.8125, precision: 0.9010, recall: 0.8369, f1: 0.8678, edges-ner-ontonotes_loss: 0.0406
09/16 12:26:09 PM: Update 4614: task edges-ner-ontonotes, batch 614 (4614): mcc: 0.8583, acc: 0.8096, precision: 0.8999, recall: 0.8330, f1: 0.8652, edges-ner-ontonotes_loss: 0.0424
09/16 12:26:19 PM: Update 4671: task edges-ner-ontonotes, batch 671 (4671): mcc: 0.8577, acc: 0.8089, precision: 0.9000, recall: 0.8319, f1: 0.8646, edges-ner-ontonotes_loss: 0.0430
09/16 12:26:29 PM: Update 4859: task edges-ner-ontonotes, batch 859 (4859): mcc: 0.8619, acc: 0.8154, precision: 0.9032, recall: 0.8366, f1: 0.8686, edges-ner-ontonotes_loss: 0.0418
09/16 12:26:44 PM: Update 4982: task edges-ner-ontonotes, batch 982 (4982): mcc: 0.8645, acc: 0.8189, precision: 0.9053, recall: 0.8393, f1: 0.8711, edges-ner-ontonotes_loss: 0.0409
09/16 12:26:46 PM: ***** Step 5000 / Validation 5 *****
09/16 12:26:46 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:26:46 PM: Validating...
09/16 12:26:54 PM: Evaluate: task edges-ner-ontonotes, batch 94 (157): mcc: 0.8580, acc: 0.8136, precision: 0.9103, recall: 0.8227, f1: 0.8643, edges-ner-ontonotes_loss: 0.0450
09/16 12:27:00 PM: Updating LR scheduler:
09/16 12:27:00 PM: 	Best result seen so far for macro_avg: 0.859
09/16 12:27:00 PM: 	# validation passes without improvement: 1
09/16 12:27:00 PM: edges-ner-ontonotes_loss: training: 0.041016 validation: 0.044553
09/16 12:27:00 PM: macro_avg: validation: 0.853227
09/16 12:27:00 PM: micro_avg: validation: 0.000000
09/16 12:27:00 PM: edges-ner-ontonotes_mcc: training: 0.864022 validation: 0.846103
09/16 12:27:00 PM: edges-ner-ontonotes_acc: training: 0.818343 validation: 0.804519
09/16 12:27:00 PM: edges-ner-ontonotes_precision: training: 0.905042 validation: 0.895971
09/16 12:27:00 PM: edges-ner-ontonotes_recall: training: 0.838737 validation: 0.814377
09/16 12:27:00 PM: edges-ner-ontonotes_f1: training: 0.870629 validation: 0.853227
09/16 12:27:00 PM: Global learning rate: 0.0001
09/16 12:27:00 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 12:27:04 PM: Update 5023: task edges-ner-ontonotes, batch 23 (5023): mcc: 0.8398, acc: 0.7910, precision: 0.8885, recall: 0.8098, f1: 0.8474, edges-ner-ontonotes_loss: 0.0446
09/16 12:27:14 PM: Update 5150: task edges-ner-ontonotes, batch 150 (5150): mcc: 0.8645, acc: 0.8193, precision: 0.9062, recall: 0.8386, f1: 0.8711, edges-ner-ontonotes_loss: 0.0405
09/16 12:27:24 PM: Update 5288: task edges-ner-ontonotes, batch 288 (5288): mcc: 0.8728, acc: 0.8312, precision: 0.9115, recall: 0.8488, f1: 0.8790, edges-ner-ontonotes_loss: 0.0377
09/16 12:27:34 PM: Update 5358: task edges-ner-ontonotes, batch 358 (5358): mcc: 0.8688, acc: 0.8259, precision: 0.9066, recall: 0.8460, f1: 0.8753, edges-ner-ontonotes_loss: 0.0384
09/16 12:27:44 PM: Update 5496: task edges-ner-ontonotes, batch 496 (5496): mcc: 0.8690, acc: 0.8250, precision: 0.9057, recall: 0.8474, f1: 0.8756, edges-ner-ontonotes_loss: 0.0380
09/16 12:27:56 PM: Update 5608: task edges-ner-ontonotes, batch 608 (5608): mcc: 0.8699, acc: 0.8252, precision: 0.9058, recall: 0.8489, f1: 0.8764, edges-ner-ontonotes_loss: 0.0374
09/16 12:28:06 PM: Update 5719: task edges-ner-ontonotes, batch 719 (5719): mcc: 0.8690, acc: 0.8236, precision: 0.9048, recall: 0.8481, f1: 0.8755, edges-ner-ontonotes_loss: 0.0374
09/16 12:28:16 PM: Update 5828: task edges-ner-ontonotes, batch 828 (5828): mcc: 0.8699, acc: 0.8245, precision: 0.9054, recall: 0.8492, f1: 0.8764, edges-ner-ontonotes_loss: 0.0371
09/16 12:28:26 PM: Update 5921: task edges-ner-ontonotes, batch 921 (5921): mcc: 0.8703, acc: 0.8248, precision: 0.9055, recall: 0.8499, f1: 0.8768, edges-ner-ontonotes_loss: 0.0370
09/16 12:28:33 PM: ***** Step 6000 / Validation 6 *****
09/16 12:28:33 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:28:33 PM: Validating...
09/16 12:28:36 PM: Evaluate: task edges-ner-ontonotes, batch 45 (157): mcc: 0.8587, acc: 0.8230, precision: 0.9000, recall: 0.8338, f1: 0.8656, edges-ner-ontonotes_loss: 0.0472
09/16 12:28:46 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:28:46 PM: Best result seen so far for macro.
09/16 12:28:46 PM: Updating LR scheduler:
09/16 12:28:46 PM: 	Best result seen so far for macro_avg: 0.861
09/16 12:28:46 PM: 	# validation passes without improvement: 0
09/16 12:28:46 PM: edges-ner-ontonotes_loss: training: 0.038023 validation: 0.044729
09/16 12:28:46 PM: macro_avg: validation: 0.861007
09/16 12:28:46 PM: micro_avg: validation: 0.000000
09/16 12:28:46 PM: edges-ner-ontonotes_mcc: training: 0.868154 validation: 0.854412
09/16 12:28:46 PM: edges-ner-ontonotes_acc: training: 0.822108 validation: 0.812860
09/16 12:28:46 PM: edges-ner-ontonotes_precision: training: 0.904372 validation: 0.905607
09/16 12:28:46 PM: edges-ner-ontonotes_recall: training: 0.847000 validation: 0.820594
09/16 12:28:46 PM: edges-ner-ontonotes_f1: training: 0.874746 validation: 0.861007
09/16 12:28:46 PM: Global learning rate: 0.0001
09/16 12:28:46 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 12:28:48 PM: Update 6019: task edges-ner-ontonotes, batch 19 (6019): mcc: 0.8659, acc: 0.8205, precision: 0.9071, recall: 0.8402, f1: 0.8724, edges-ner-ontonotes_loss: 0.0456
09/16 12:28:58 PM: Update 6151: task edges-ner-ontonotes, batch 151 (6151): mcc: 0.8501, acc: 0.8044, precision: 0.8945, recall: 0.8231, f1: 0.8573, edges-ner-ontonotes_loss: 0.0479
09/16 12:29:10 PM: Update 6225: task edges-ner-ontonotes, batch 225 (6225): mcc: 0.8505, acc: 0.8048, precision: 0.8954, recall: 0.8230, f1: 0.8577, edges-ner-ontonotes_loss: 0.0475
09/16 12:29:20 PM: Update 6381: task edges-ner-ontonotes, batch 381 (6381): mcc: 0.8621, acc: 0.8190, precision: 0.9038, recall: 0.8363, f1: 0.8688, edges-ner-ontonotes_loss: 0.0430
09/16 12:29:30 PM: Update 6510: task edges-ner-ontonotes, batch 510 (6510): mcc: 0.8690, acc: 0.8281, precision: 0.9083, recall: 0.8448, f1: 0.8754, edges-ner-ontonotes_loss: 0.0409
09/16 12:29:41 PM: Update 6596: task edges-ner-ontonotes, batch 596 (6596): mcc: 0.8693, acc: 0.8284, precision: 0.9087, recall: 0.8449, f1: 0.8756, edges-ner-ontonotes_loss: 0.0403
09/16 12:29:51 PM: Update 6703: task edges-ner-ontonotes, batch 703 (6703): mcc: 0.8698, acc: 0.8286, precision: 0.9089, recall: 0.8456, f1: 0.8761, edges-ner-ontonotes_loss: 0.0399
09/16 12:30:01 PM: Update 6821: task edges-ner-ontonotes, batch 821 (6821): mcc: 0.8725, acc: 0.8317, precision: 0.9106, recall: 0.8491, f1: 0.8788, edges-ner-ontonotes_loss: 0.0392
09/16 12:30:11 PM: Update 6873: task edges-ner-ontonotes, batch 873 (6873): mcc: 0.8716, acc: 0.8307, precision: 0.9093, recall: 0.8486, f1: 0.8779, edges-ner-ontonotes_loss: 0.0392
09/16 12:30:20 PM: ***** Step 7000 / Validation 7 *****
09/16 12:30:20 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:30:20 PM: Validating...
09/16 12:30:21 PM: Evaluate: task edges-ner-ontonotes, batch 29 (157): mcc: 0.8026, acc: 0.7633, precision: 0.8488, recall: 0.7788, f1: 0.8123, edges-ner-ontonotes_loss: 0.0591
09/16 12:30:28 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:30:28 PM: Best result seen so far for macro.
09/16 12:30:28 PM: Updating LR scheduler:
09/16 12:30:28 PM: 	Best result seen so far for macro_avg: 0.862
09/16 12:30:28 PM: 	# validation passes without improvement: 0
09/16 12:30:28 PM: edges-ner-ontonotes_loss: training: 0.038845 validation: 0.044230
09/16 12:30:28 PM: macro_avg: validation: 0.862095
09/16 12:30:28 PM: micro_avg: validation: 0.000000
09/16 12:30:28 PM: edges-ner-ontonotes_mcc: training: 0.871411 validation: 0.854741
09/16 12:30:28 PM: edges-ner-ontonotes_acc: training: 0.829632 validation: 0.815287
09/16 12:30:28 PM: edges-ner-ontonotes_precision: training: 0.908140 validation: 0.890487
09/16 12:30:28 PM: edges-ner-ontonotes_recall: training: 0.849426 validation: 0.835456
09/16 12:30:28 PM: edges-ner-ontonotes_f1: training: 0.877802 validation: 0.862095
09/16 12:30:28 PM: Global learning rate: 0.0001
09/16 12:30:28 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 12:30:31 PM: Update 7054: task edges-ner-ontonotes, batch 54 (7054): mcc: 0.8694, acc: 0.8223, precision: 0.8982, recall: 0.8553, f1: 0.8762, edges-ner-ontonotes_loss: 0.0365
09/16 12:30:41 PM: Update 7165: task edges-ner-ontonotes, batch 165 (7165): mcc: 0.8731, acc: 0.8284, precision: 0.9032, recall: 0.8572, f1: 0.8796, edges-ner-ontonotes_loss: 0.0354
09/16 12:30:51 PM: Update 7352: task edges-ner-ontonotes, batch 352 (7352): mcc: 0.8728, acc: 0.8270, precision: 0.9045, recall: 0.8555, f1: 0.8793, edges-ner-ontonotes_loss: 0.0354
09/16 12:31:01 PM: Update 7455: task edges-ner-ontonotes, batch 455 (7455): mcc: 0.8732, acc: 0.8276, precision: 0.9046, recall: 0.8560, f1: 0.8797, edges-ner-ontonotes_loss: 0.0355
09/16 12:31:11 PM: Update 7500: task edges-ner-ontonotes, batch 500 (7500): mcc: 0.8713, acc: 0.8257, precision: 0.9034, recall: 0.8538, f1: 0.8779, edges-ner-ontonotes_loss: 0.0364
09/16 12:31:21 PM: Update 7659: task edges-ner-ontonotes, batch 659 (7659): mcc: 0.8673, acc: 0.8210, precision: 0.9024, recall: 0.8474, f1: 0.8740, edges-ner-ontonotes_loss: 0.0390
09/16 12:31:31 PM: Update 7769: task edges-ner-ontonotes, batch 769 (7769): mcc: 0.8658, acc: 0.8194, precision: 0.9019, recall: 0.8450, f1: 0.8726, edges-ner-ontonotes_loss: 0.0399
09/16 12:31:41 PM: Update 7810: task edges-ner-ontonotes, batch 810 (7810): mcc: 0.8658, acc: 0.8195, precision: 0.9021, recall: 0.8449, f1: 0.8726, edges-ner-ontonotes_loss: 0.0399
09/16 12:31:51 PM: Update 7922: task edges-ner-ontonotes, batch 922 (7922): mcc: 0.8682, acc: 0.8233, precision: 0.9038, recall: 0.8477, f1: 0.8748, edges-ner-ontonotes_loss: 0.0392
09/16 12:31:58 PM: ***** Step 8000 / Validation 8 *****
09/16 12:31:58 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:31:58 PM: Validating...
09/16 12:32:01 PM: Evaluate: task edges-ner-ontonotes, batch 36 (157): mcc: 0.8609, acc: 0.8286, precision: 0.8962, recall: 0.8415, f1: 0.8680, edges-ner-ontonotes_loss: 0.0461
09/16 12:32:11 PM: Evaluate: task edges-ner-ontonotes, batch 139 (157): mcc: 0.8487, acc: 0.8084, precision: 0.8972, recall: 0.8179, f1: 0.8557, edges-ner-ontonotes_loss: 0.0456
09/16 12:32:13 PM: Updating LR scheduler:
09/16 12:32:13 PM: 	Best result seen so far for macro_avg: 0.862
09/16 12:32:13 PM: 	# validation passes without improvement: 1
09/16 12:32:13 PM: edges-ner-ontonotes_loss: training: 0.038752 validation: 0.045156
09/16 12:32:13 PM: macro_avg: validation: 0.855772
09/16 12:32:13 PM: micro_avg: validation: 0.000000
09/16 12:32:13 PM: edges-ner-ontonotes_mcc: training: 0.869991 validation: 0.848715
09/16 12:32:13 PM: edges-ner-ontonotes_acc: training: 0.825630 validation: 0.808993
09/16 12:32:13 PM: edges-ner-ontonotes_precision: training: 0.905268 validation: 0.897272
09/16 12:32:13 PM: edges-ner-ontonotes_recall: training: 0.849544 validation: 0.817941
09/16 12:32:13 PM: edges-ner-ontonotes_f1: training: 0.876521 validation: 0.855772
09/16 12:32:13 PM: Global learning rate: 0.0001
09/16 12:32:13 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 12:32:21 PM: Update 8084: task edges-ner-ontonotes, batch 84 (8084): mcc: 0.8914, acc: 0.8568, precision: 0.9185, recall: 0.8766, f1: 0.8971, edges-ner-ontonotes_loss: 0.0333
09/16 12:32:31 PM: Update 8110: task edges-ner-ontonotes, batch 110 (8110): mcc: 0.8861, acc: 0.8509, precision: 0.9151, recall: 0.8700, f1: 0.8920, edges-ner-ontonotes_loss: 0.0339
09/16 12:32:42 PM: Update 8253: task edges-ner-ontonotes, batch 253 (8253): mcc: 0.8796, acc: 0.8408, precision: 0.9139, recall: 0.8591, f1: 0.8857, edges-ner-ontonotes_loss: 0.0355
09/16 12:32:52 PM: Update 8379: task edges-ner-ontonotes, batch 379 (8379): mcc: 0.8803, acc: 0.8402, precision: 0.9146, recall: 0.8597, f1: 0.8863, edges-ner-ontonotes_loss: 0.0357
09/16 12:33:02 PM: Update 8454: task edges-ner-ontonotes, batch 454 (8454): mcc: 0.8779, acc: 0.8366, precision: 0.9124, recall: 0.8574, f1: 0.8841, edges-ner-ontonotes_loss: 0.0360
09/16 12:33:12 PM: Update 8566: task edges-ner-ontonotes, batch 566 (8566): mcc: 0.8769, acc: 0.8347, precision: 0.9103, recall: 0.8575, f1: 0.8831, edges-ner-ontonotes_loss: 0.0359
09/16 12:33:22 PM: Update 8677: task edges-ner-ontonotes, batch 677 (8677): mcc: 0.8774, acc: 0.8348, precision: 0.9101, recall: 0.8586, f1: 0.8836, edges-ner-ontonotes_loss: 0.0354
09/16 12:33:32 PM: Update 8731: task edges-ner-ontonotes, batch 731 (8731): mcc: 0.8768, acc: 0.8339, precision: 0.9097, recall: 0.8580, f1: 0.8831, edges-ner-ontonotes_loss: 0.0354
09/16 12:33:42 PM: Update 8863: task edges-ner-ontonotes, batch 863 (8863): mcc: 0.8764, acc: 0.8330, precision: 0.9089, recall: 0.8580, f1: 0.8827, edges-ner-ontonotes_loss: 0.0354
09/16 12:33:52 PM: Update 8960: task edges-ner-ontonotes, batch 960 (8960): mcc: 0.8766, acc: 0.8330, precision: 0.9086, recall: 0.8586, f1: 0.8829, edges-ner-ontonotes_loss: 0.0353
09/16 12:33:55 PM: ***** Step 9000 / Validation 9 *****
09/16 12:33:55 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:33:55 PM: Validating...
09/16 12:34:02 PM: Evaluate: task edges-ner-ontonotes, batch 78 (157): mcc: 0.8527, acc: 0.8109, precision: 0.9014, recall: 0.8214, f1: 0.8595, edges-ner-ontonotes_loss: 0.0501
09/16 12:34:08 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:34:08 PM: Best result seen so far for macro.
09/16 12:34:08 PM: Updating LR scheduler:
09/16 12:34:08 PM: 	Best result seen so far for macro_avg: 0.868
09/16 12:34:08 PM: 	# validation passes without improvement: 0
09/16 12:34:08 PM: edges-ner-ontonotes_loss: training: 0.035278 validation: 0.043986
09/16 12:34:08 PM: macro_avg: validation: 0.868303
09/16 12:34:08 PM: micro_avg: validation: 0.000000
09/16 12:34:08 PM: edges-ner-ontonotes_mcc: training: 0.876321 validation: 0.861409
09/16 12:34:08 PM: edges-ner-ontonotes_acc: training: 0.832562 validation: 0.819230
09/16 12:34:08 PM: edges-ner-ontonotes_precision: training: 0.908469 validation: 0.899269
09/16 12:34:08 PM: edges-ner-ontonotes_recall: training: 0.858204 validation: 0.839399
09/16 12:34:08 PM: edges-ner-ontonotes_f1: training: 0.882622 validation: 0.868303
09/16 12:34:08 PM: Global learning rate: 0.0001
09/16 12:34:08 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 12:34:15 PM: Update 9033: task edges-ner-ontonotes, batch 33 (9033): mcc: 0.8737, acc: 0.8276, precision: 0.9050, recall: 0.8566, f1: 0.8801, edges-ner-ontonotes_loss: 0.0349
09/16 12:34:25 PM: Update 9161: task edges-ner-ontonotes, batch 161 (9161): mcc: 0.8569, acc: 0.8095, precision: 0.8949, recall: 0.8353, f1: 0.8641, edges-ner-ontonotes_loss: 0.0438
09/16 12:34:35 PM: Update 9297: task edges-ner-ontonotes, batch 297 (9297): mcc: 0.8563, acc: 0.8089, precision: 0.8964, recall: 0.8328, f1: 0.8634, edges-ner-ontonotes_loss: 0.0453
09/16 12:34:45 PM: Update 9390: task edges-ner-ontonotes, batch 390 (9390): mcc: 0.8593, acc: 0.8131, precision: 0.8990, recall: 0.8357, f1: 0.8662, edges-ner-ontonotes_loss: 0.0440
09/16 12:34:55 PM: Update 9529: task edges-ner-ontonotes, batch 529 (9529): mcc: 0.8677, acc: 0.8246, precision: 0.9050, recall: 0.8456, f1: 0.8743, edges-ner-ontonotes_loss: 0.0411
09/16 12:35:05 PM: Update 9647: task edges-ner-ontonotes, batch 647 (9647): mcc: 0.8723, acc: 0.8307, precision: 0.9084, recall: 0.8508, f1: 0.8787, edges-ner-ontonotes_loss: 0.0397
09/16 12:35:15 PM: Update 9703: task edges-ner-ontonotes, batch 703 (9703): mcc: 0.8714, acc: 0.8294, precision: 0.9079, recall: 0.8496, f1: 0.8778, edges-ner-ontonotes_loss: 0.0397
09/16 12:35:25 PM: Update 9828: task edges-ner-ontonotes, batch 828 (9828): mcc: 0.8732, acc: 0.8315, precision: 0.9092, recall: 0.8517, f1: 0.8795, edges-ner-ontonotes_loss: 0.0390
09/16 12:35:38 PM: Update 9963: task edges-ner-ontonotes, batch 963 (9963): mcc: 0.8745, acc: 0.8332, precision: 0.9099, recall: 0.8536, f1: 0.8808, edges-ner-ontonotes_loss: 0.0385
09/16 12:35:41 PM: ***** Step 10000 / Validation 10 *****
09/16 12:35:41 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:35:41 PM: Validating...
09/16 12:35:48 PM: Evaluate: task edges-ner-ontonotes, batch 154 (157): mcc: 0.8539, acc: 0.8154, precision: 0.8916, recall: 0.8328, f1: 0.8612, edges-ner-ontonotes_loss: 0.0441
09/16 12:35:48 PM: Updating LR scheduler:
09/16 12:35:48 PM: 	Best result seen so far for macro_avg: 0.868
09/16 12:35:48 PM: 	# validation passes without improvement: 1
09/16 12:35:48 PM: edges-ner-ontonotes_loss: training: 0.038396 validation: 0.043839
09/16 12:35:48 PM: macro_avg: validation: 0.862161
09/16 12:35:48 PM: micro_avg: validation: 0.000000
09/16 12:35:48 PM: edges-ner-ontonotes_mcc: training: 0.874312 validation: 0.854897
09/16 12:35:48 PM: edges-ner-ontonotes_acc: training: 0.832929 validation: 0.816500
09/16 12:35:48 PM: edges-ner-ontonotes_precision: training: 0.909280 validation: 0.892532
09/16 12:35:48 PM: edges-ner-ontonotes_recall: training: 0.853703 validation: 0.833788
09/16 12:35:48 PM: edges-ner-ontonotes_f1: training: 0.880615 validation: 0.862161
09/16 12:35:48 PM: Global learning rate: 0.0001
09/16 12:35:48 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 12:35:58 PM: Update 10150: task edges-ner-ontonotes, batch 150 (10150): mcc: 0.8745, acc: 0.8297, precision: 0.9030, recall: 0.8601, f1: 0.8810, edges-ner-ontonotes_loss: 0.0353
09/16 12:36:09 PM: Update 10276: task edges-ner-ontonotes, batch 276 (10276): mcc: 0.8732, acc: 0.8278, precision: 0.9023, recall: 0.8585, f1: 0.8798, edges-ner-ontonotes_loss: 0.0348
09/16 12:36:19 PM: Update 10401: task edges-ner-ontonotes, batch 401 (10401): mcc: 0.8731, acc: 0.8275, precision: 0.9025, recall: 0.8579, f1: 0.8796, edges-ner-ontonotes_loss: 0.0347
09/16 12:36:29 PM: Update 10573: task edges-ner-ontonotes, batch 573 (10573): mcc: 0.8750, acc: 0.8298, precision: 0.9044, recall: 0.8597, f1: 0.8815, edges-ner-ontonotes_loss: 0.0346
09/16 12:36:39 PM: Update 10659: task edges-ner-ontonotes, batch 659 (10659): mcc: 0.8714, acc: 0.8258, precision: 0.9020, recall: 0.8553, f1: 0.8780, edges-ner-ontonotes_loss: 0.0361
09/16 12:36:49 PM: Update 10833: task edges-ner-ontonotes, batch 833 (10833): mcc: 0.8688, acc: 0.8230, precision: 0.9011, recall: 0.8514, f1: 0.8755, edges-ner-ontonotes_loss: 0.0380
09/16 12:37:00 PM: Update 10893: task edges-ner-ontonotes, batch 893 (10893): mcc: 0.8684, acc: 0.8227, precision: 0.9011, recall: 0.8507, f1: 0.8752, edges-ner-ontonotes_loss: 0.0385
09/16 12:37:06 PM: ***** Step 11000 / Validation 11 *****
09/16 12:37:08 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:37:08 PM: Validating...
09/16 12:37:10 PM: Evaluate: task edges-ner-ontonotes, batch 23 (157): mcc: 0.8252, acc: 0.7848, precision: 0.8685, recall: 0.8018, f1: 0.8338, edges-ner-ontonotes_loss: 0.0541
09/16 12:37:20 PM: Evaluate: task edges-ner-ontonotes, batch 137 (157): mcc: 0.8508, acc: 0.8094, precision: 0.8997, recall: 0.8194, f1: 0.8577, edges-ner-ontonotes_loss: 0.0448
09/16 12:37:21 PM: Updating LR scheduler:
09/16 12:37:21 PM: 	Best result seen so far for macro_avg: 0.868
09/16 12:37:21 PM: 	# validation passes without improvement: 2
09/16 12:37:21 PM: edges-ner-ontonotes_loss: training: 0.038255 validation: 0.044147
09/16 12:37:21 PM: macro_avg: validation: 0.859150
09/16 12:37:21 PM: micro_avg: validation: 0.000000
09/16 12:37:21 PM: edges-ner-ontonotes_mcc: training: 0.869836 validation: 0.852315
09/16 12:37:21 PM: edges-ner-ontonotes_acc: training: 0.825068 validation: 0.810965
09/16 12:37:21 PM: edges-ner-ontonotes_precision: training: 0.902319 validation: 0.901324
09/16 12:37:21 PM: edges-ner-ontonotes_recall: training: 0.852086 validation: 0.820746
09/16 12:37:21 PM: edges-ner-ontonotes_f1: training: 0.876483 validation: 0.859150
09/16 12:37:21 PM: Global learning rate: 0.0001
09/16 12:37:21 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 12:37:30 PM: Update 11110: task edges-ner-ontonotes, batch 110 (11110): mcc: 0.8991, acc: 0.8661, precision: 0.9266, recall: 0.8831, f1: 0.9043, edges-ner-ontonotes_loss: 0.0312
09/16 12:37:43 PM: Update 11206: task edges-ner-ontonotes, batch 206 (11206): mcc: 0.8957, acc: 0.8622, precision: 0.9247, recall: 0.8786, f1: 0.9010, edges-ner-ontonotes_loss: 0.0319
09/16 12:37:53 PM: Update 11344: task edges-ner-ontonotes, batch 344 (11344): mcc: 0.8842, acc: 0.8464, precision: 0.9161, recall: 0.8654, f1: 0.8900, edges-ner-ontonotes_loss: 0.0338
09/16 12:38:04 PM: Update 11513: task edges-ner-ontonotes, batch 513 (11513): mcc: 0.8843, acc: 0.8467, precision: 0.9155, recall: 0.8662, f1: 0.8902, edges-ner-ontonotes_loss: 0.0341
09/16 12:38:14 PM: Update 11571: task edges-ner-ontonotes, batch 571 (11571): mcc: 0.8823, acc: 0.8437, precision: 0.9131, recall: 0.8649, f1: 0.8883, edges-ner-ontonotes_loss: 0.0343
09/16 12:38:24 PM: Update 11675: task edges-ner-ontonotes, batch 675 (11675): mcc: 0.8808, acc: 0.8408, precision: 0.9114, recall: 0.8636, f1: 0.8869, edges-ner-ontonotes_loss: 0.0345
09/16 12:38:34 PM: Update 11803: task edges-ner-ontonotes, batch 803 (11803): mcc: 0.8802, acc: 0.8398, precision: 0.9103, recall: 0.8637, f1: 0.8864, edges-ner-ontonotes_loss: 0.0344
09/16 12:38:44 PM: Update 11863: task edges-ner-ontonotes, batch 863 (11863): mcc: 0.8795, acc: 0.8387, precision: 0.9097, recall: 0.8629, f1: 0.8857, edges-ner-ontonotes_loss: 0.0343
09/16 12:38:54 PM: Update 11975: task edges-ner-ontonotes, batch 975 (11975): mcc: 0.8791, acc: 0.8379, precision: 0.9090, recall: 0.8628, f1: 0.8853, edges-ner-ontonotes_loss: 0.0344
09/16 12:38:56 PM: ***** Step 12000 / Validation 12 *****
09/16 12:38:56 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:38:58 PM: Validating...
09/16 12:39:04 PM: Evaluate: task edges-ner-ontonotes, batch 66 (157): mcc: 0.8557, acc: 0.8192, precision: 0.8989, recall: 0.8293, f1: 0.8627, edges-ner-ontonotes_loss: 0.0505
09/16 12:39:14 PM: Updating LR scheduler:
09/16 12:39:14 PM: 	Best result seen so far for macro_avg: 0.868
09/16 12:39:14 PM: 	# validation passes without improvement: 3
09/16 12:39:14 PM: edges-ner-ontonotes_loss: training: 0.034353 validation: 0.043709
09/16 12:39:14 PM: macro_avg: validation: 0.867475
09/16 12:39:14 PM: micro_avg: validation: 0.000000
09/16 12:39:14 PM: edges-ner-ontonotes_mcc: training: 0.879224 validation: 0.860534
09/16 12:39:14 PM: edges-ner-ontonotes_acc: training: 0.837962 validation: 0.822869
09/16 12:39:14 PM: edges-ner-ontonotes_precision: training: 0.909017 validation: 0.898448
09/16 12:39:14 PM: edges-ner-ontonotes_recall: training: 0.863069 validation: 0.838565
09/16 12:39:14 PM: edges-ner-ontonotes_f1: training: 0.885447 validation: 0.867475
09/16 12:39:14 PM: Global learning rate: 0.0001
09/16 12:39:14 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 12:39:14 PM: Update 12006: task edges-ner-ontonotes, batch 6 (12006): mcc: 0.8753, acc: 0.8342, precision: 0.9099, recall: 0.8549, f1: 0.8816, edges-ner-ontonotes_loss: 0.0355
09/16 12:39:30 PM: Update 12145: task edges-ner-ontonotes, batch 145 (12145): mcc: 0.8757, acc: 0.8303, precision: 0.9054, recall: 0.8599, f1: 0.8821, edges-ner-ontonotes_loss: 0.0338
09/16 12:39:40 PM: Update 12278: task edges-ner-ontonotes, batch 278 (12278): mcc: 0.8649, acc: 0.8189, precision: 0.8998, recall: 0.8454, f1: 0.8717, edges-ner-ontonotes_loss: 0.0401
09/16 12:39:50 PM: Update 12423: task edges-ner-ontonotes, batch 423 (12423): mcc: 0.8644, acc: 0.8186, precision: 0.9004, recall: 0.8438, f1: 0.8712, edges-ner-ontonotes_loss: 0.0415
09/16 12:40:00 PM: Update 12502: task edges-ner-ontonotes, batch 502 (12502): mcc: 0.8653, acc: 0.8201, precision: 0.9013, recall: 0.8447, f1: 0.8721, edges-ner-ontonotes_loss: 0.0412
09/16 12:40:10 PM: Update 12676: task edges-ner-ontonotes, batch 676 (12676): mcc: 0.8714, acc: 0.8290, precision: 0.9053, recall: 0.8521, f1: 0.8779, edges-ner-ontonotes_loss: 0.0389
09/16 12:40:23 PM: Update 12762: task edges-ner-ontonotes, batch 762 (12762): mcc: 0.8744, acc: 0.8332, precision: 0.9075, recall: 0.8557, f1: 0.8808, edges-ner-ontonotes_loss: 0.0381
09/16 12:40:33 PM: Update 12896: task edges-ner-ontonotes, batch 896 (12896): mcc: 0.8743, acc: 0.8333, precision: 0.9074, recall: 0.8555, f1: 0.8807, edges-ner-ontonotes_loss: 0.0379
09/16 12:40:40 PM: ***** Step 13000 / Validation 13 *****
09/16 12:40:40 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:40:40 PM: Validating...
09/16 12:40:43 PM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.8725, acc: 0.8454, precision: 0.9026, recall: 0.8568, f1: 0.8791, edges-ner-ontonotes_loss: 0.0421
09/16 12:40:49 PM: Updating LR scheduler:
09/16 12:40:49 PM: 	Best result seen so far for macro_avg: 0.868
09/16 12:40:49 PM: 	# validation passes without improvement: 0
09/16 12:40:49 PM: edges-ner-ontonotes_loss: training: 0.037550 validation: 0.043233
09/16 12:40:49 PM: macro_avg: validation: 0.864869
09/16 12:40:49 PM: micro_avg: validation: 0.000000
09/16 12:40:49 PM: edges-ner-ontonotes_mcc: training: 0.875029 validation: 0.857748
09/16 12:40:49 PM: edges-ner-ontonotes_acc: training: 0.834098 validation: 0.820594
09/16 12:40:49 PM: edges-ner-ontonotes_precision: training: 0.907696 validation: 0.895036
09/16 12:40:49 PM: edges-ner-ontonotes_recall: training: 0.856551 validation: 0.836670
09/16 12:40:49 PM: edges-ner-ontonotes_f1: training: 0.881382 validation: 0.864869
09/16 12:40:49 PM: Global learning rate: 5e-05
09/16 12:40:49 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 12:40:53 PM: Update 13064: task edges-ner-ontonotes, batch 64 (13064): mcc: 0.8865, acc: 0.8496, precision: 0.9172, recall: 0.8687, f1: 0.8923, edges-ner-ontonotes_loss: 0.0331
09/16 12:41:03 PM: Update 13151: task edges-ner-ontonotes, batch 151 (13151): mcc: 0.8779, acc: 0.8363, precision: 0.9074, recall: 0.8622, f1: 0.8842, edges-ner-ontonotes_loss: 0.0340
09/16 12:41:13 PM: Update 13348: task edges-ner-ontonotes, batch 348 (13348): mcc: 0.8743, acc: 0.8310, precision: 0.9040, recall: 0.8588, f1: 0.8808, edges-ner-ontonotes_loss: 0.0348
09/16 12:41:26 PM: Update 13389: task edges-ner-ontonotes, batch 389 (13389): mcc: 0.8738, acc: 0.8297, precision: 0.9028, recall: 0.8590, f1: 0.8803, edges-ner-ontonotes_loss: 0.0348
09/16 12:41:36 PM: Update 13537: task edges-ner-ontonotes, batch 537 (13537): mcc: 0.8740, acc: 0.8292, precision: 0.9032, recall: 0.8590, f1: 0.8805, edges-ner-ontonotes_loss: 0.0349
09/16 12:41:47 PM: Update 13674: task edges-ner-ontonotes, batch 674 (13674): mcc: 0.8742, acc: 0.8288, precision: 0.9037, recall: 0.8588, f1: 0.8807, edges-ner-ontonotes_loss: 0.0347
09/16 12:41:57 PM: Update 13724: task edges-ner-ontonotes, batch 724 (13724): mcc: 0.8733, acc: 0.8279, precision: 0.9030, recall: 0.8578, f1: 0.8798, edges-ner-ontonotes_loss: 0.0351
09/16 12:42:07 PM: Update 13860: task edges-ner-ontonotes, batch 860 (13860): mcc: 0.8709, acc: 0.8252, precision: 0.9020, recall: 0.8544, f1: 0.8776, edges-ner-ontonotes_loss: 0.0367
09/16 12:42:15 PM: ***** Step 14000 / Validation 14 *****
09/16 12:42:15 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:42:15 PM: Validating...
09/16 12:42:17 PM: Evaluate: task edges-ner-ontonotes, batch 20 (157): mcc: 0.8372, acc: 0.7945, precision: 0.8773, recall: 0.8155, f1: 0.8453, edges-ner-ontonotes_loss: 0.0503
09/16 12:42:25 PM: Updating LR scheduler:
09/16 12:42:25 PM: 	Best result seen so far for macro_avg: 0.868
09/16 12:42:25 PM: 	# validation passes without improvement: 1
09/16 12:42:25 PM: edges-ner-ontonotes_loss: training: 0.037762 validation: 0.043717
09/16 12:42:25 PM: macro_avg: validation: 0.863367
09/16 12:42:25 PM: micro_avg: validation: 0.000000
09/16 12:42:25 PM: edges-ner-ontonotes_mcc: training: 0.869215 validation: 0.856567
09/16 12:42:25 PM: edges-ner-ontonotes_acc: training: 0.823564 validation: 0.819305
09/16 12:42:25 PM: edges-ner-ontonotes_precision: training: 0.901302 validation: 0.901949
09/16 12:42:25 PM: edges-ner-ontonotes_recall: training: 0.851912 validation: 0.827950
09/16 12:42:25 PM: edges-ner-ontonotes_f1: training: 0.875911 validation: 0.863367
09/16 12:42:25 PM: Global learning rate: 5e-05
09/16 12:42:25 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 12:42:30 PM: Update 14005: task edges-ner-ontonotes, batch 5 (14005): mcc: 0.8500, acc: 0.7957, precision: 0.8746, recall: 0.8421, f1: 0.8580, edges-ner-ontonotes_loss: 0.0450
09/16 12:42:40 PM: Update 14162: task edges-ner-ontonotes, batch 162 (14162): mcc: 0.8955, acc: 0.8615, precision: 0.9218, recall: 0.8811, f1: 0.9010, edges-ner-ontonotes_loss: 0.0331
09/16 12:42:55 PM: Update 14318: task edges-ner-ontonotes, batch 318 (14318): mcc: 0.8976, acc: 0.8645, precision: 0.9237, recall: 0.8829, f1: 0.9029, edges-ner-ontonotes_loss: 0.0322
09/16 12:43:05 PM: Update 14436: task edges-ner-ontonotes, batch 436 (14436): mcc: 0.8898, acc: 0.8541, precision: 0.9186, recall: 0.8734, f1: 0.8954, edges-ner-ontonotes_loss: 0.0335
09/16 12:43:15 PM: Update 14567: task edges-ner-ontonotes, batch 567 (14567): mcc: 0.8899, acc: 0.8542, precision: 0.9189, recall: 0.8735, f1: 0.8956, edges-ner-ontonotes_loss: 0.0332
09/16 12:43:25 PM: Update 14632: task edges-ner-ontonotes, batch 632 (14632): mcc: 0.8889, acc: 0.8528, precision: 0.9184, recall: 0.8721, f1: 0.8946, edges-ner-ontonotes_loss: 0.0333
09/16 12:43:35 PM: Update 14769: task edges-ner-ontonotes, batch 769 (14769): mcc: 0.8852, acc: 0.8470, precision: 0.9146, recall: 0.8689, f1: 0.8911, edges-ner-ontonotes_loss: 0.0337
09/16 12:43:46 PM: Update 14888: task edges-ner-ontonotes, batch 888 (14888): mcc: 0.8853, acc: 0.8463, precision: 0.9143, recall: 0.8693, f1: 0.8912, edges-ner-ontonotes_loss: 0.0335
09/16 12:43:56 PM: Update 14964: task edges-ner-ontonotes, batch 964 (14964): mcc: 0.8838, acc: 0.8443, precision: 0.9127, recall: 0.8681, f1: 0.8898, edges-ner-ontonotes_loss: 0.0337
09/16 12:43:59 PM: ***** Step 15000 / Validation 15 *****
09/16 12:43:59 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:43:59 PM: Validating...
09/16 12:44:06 PM: Evaluate: task edges-ner-ontonotes, batch 137 (157): mcc: 0.8588, acc: 0.8182, precision: 0.8946, recall: 0.8391, f1: 0.8660, edges-ner-ontonotes_loss: 0.0446
09/16 12:44:07 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:44:07 PM: Best result seen so far for macro.
09/16 12:44:07 PM: Updating LR scheduler:
09/16 12:44:07 PM: 	Best result seen so far for macro_avg: 0.869
09/16 12:44:07 PM: 	# validation passes without improvement: 0
09/16 12:44:07 PM: edges-ner-ontonotes_loss: training: 0.033649 validation: 0.043397
09/16 12:44:07 PM: macro_avg: validation: 0.868936
09/16 12:44:07 PM: micro_avg: validation: 0.000000
09/16 12:44:07 PM: edges-ner-ontonotes_mcc: training: 0.883459 validation: 0.861977
09/16 12:44:07 PM: edges-ner-ontonotes_acc: training: 0.843593 validation: 0.822035
09/16 12:44:07 PM: edges-ner-ontonotes_precision: training: 0.912517 validation: 0.897591
09/16 12:44:07 PM: edges-ner-ontonotes_recall: training: 0.867563 validation: 0.842053
09/16 12:44:07 PM: edges-ner-ontonotes_f1: training: 0.889472 validation: 0.868936
09/16 12:44:07 PM: Global learning rate: 5e-05
09/16 12:44:07 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 12:44:16 PM: Update 15089: task edges-ner-ontonotes, batch 89 (15089): mcc: 0.8731, acc: 0.8284, precision: 0.9020, recall: 0.8585, f1: 0.8797, edges-ner-ontonotes_loss: 0.0348
09/16 12:44:26 PM: Update 15204: task edges-ner-ontonotes, batch 204 (15204): mcc: 0.8746, acc: 0.8299, precision: 0.9027, recall: 0.8605, f1: 0.8811, edges-ner-ontonotes_loss: 0.0343
09/16 12:44:36 PM: Update 15273: task edges-ner-ontonotes, batch 273 (15273): mcc: 0.8733, acc: 0.8283, precision: 0.9025, recall: 0.8583, f1: 0.8798, edges-ner-ontonotes_loss: 0.0352
09/16 12:44:46 PM: Update 15404: task edges-ner-ontonotes, batch 404 (15404): mcc: 0.8686, acc: 0.8230, precision: 0.9009, recall: 0.8511, f1: 0.8753, edges-ner-ontonotes_loss: 0.0383
09/16 12:44:56 PM: Update 15519: task edges-ner-ontonotes, batch 519 (15519): mcc: 0.8670, acc: 0.8214, precision: 0.9008, recall: 0.8483, f1: 0.8738, edges-ner-ontonotes_loss: 0.0397
09/16 12:45:06 PM: Update 15581: task edges-ner-ontonotes, batch 581 (15581): mcc: 0.8671, acc: 0.8218, precision: 0.9010, recall: 0.8482, f1: 0.8738, edges-ner-ontonotes_loss: 0.0398
09/16 12:45:16 PM: Update 15706: task edges-ner-ontonotes, batch 706 (15706): mcc: 0.8713, acc: 0.8278, precision: 0.9040, recall: 0.8531, f1: 0.8778, edges-ner-ontonotes_loss: 0.0385
09/16 12:45:26 PM: Update 15871: task edges-ner-ontonotes, batch 871 (15871): mcc: 0.8760, acc: 0.8347, precision: 0.9078, recall: 0.8584, f1: 0.8824, edges-ner-ontonotes_loss: 0.0372
09/16 12:45:36 PM: Update 15970: task edges-ner-ontonotes, batch 970 (15970): mcc: 0.8765, acc: 0.8355, precision: 0.9084, recall: 0.8586, f1: 0.8828, edges-ner-ontonotes_loss: 0.0369
09/16 12:45:39 PM: ***** Step 16000 / Validation 16 *****
09/16 12:45:39 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:45:39 PM: Validating...
09/16 12:45:46 PM: Evaluate: task edges-ner-ontonotes, batch 101 (157): mcc: 0.8597, acc: 0.8227, precision: 0.9011, recall: 0.8345, f1: 0.8665, edges-ner-ontonotes_loss: 0.0455
09/16 12:45:51 PM: Updating LR scheduler:
09/16 12:45:52 PM: 	Best result seen so far for macro_avg: 0.869
09/16 12:45:52 PM: 	# validation passes without improvement: 1
09/16 12:45:52 PM: edges-ner-ontonotes_loss: training: 0.036757 validation: 0.042767
09/16 12:45:52 PM: macro_avg: validation: 0.866344
09/16 12:45:52 PM: micro_avg: validation: 0.000000
09/16 12:45:52 PM: edges-ner-ontonotes_mcc: training: 0.877126 validation: 0.859507
09/16 12:45:52 PM: edges-ner-ontonotes_acc: training: 0.836237 validation: 0.823552
09/16 12:45:52 PM: edges-ner-ontonotes_precision: training: 0.908861 validation: 0.900925
09/16 12:45:52 PM: edges-ner-ontonotes_recall: training: 0.859321 validation: 0.834319
09/16 12:45:52 PM: edges-ner-ontonotes_f1: training: 0.883397 validation: 0.866344
09/16 12:45:52 PM: Global learning rate: 5e-05
09/16 12:45:52 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 12:45:56 PM: Update 16049: task edges-ner-ontonotes, batch 49 (16049): mcc: 0.8895, acc: 0.8519, precision: 0.9206, recall: 0.8710, f1: 0.8951, edges-ner-ontonotes_loss: 0.0326
09/16 12:46:11 PM: Update 16187: task edges-ner-ontonotes, batch 187 (16187): mcc: 0.8814, acc: 0.8438, precision: 0.9129, recall: 0.8635, f1: 0.8875, edges-ner-ontonotes_loss: 0.0351
09/16 12:46:21 PM: Update 16350: task edges-ner-ontonotes, batch 350 (16350): mcc: 0.8773, acc: 0.8354, precision: 0.9072, recall: 0.8612, f1: 0.8836, edges-ner-ontonotes_loss: 0.0351
09/16 12:46:31 PM: Update 16470: task edges-ner-ontonotes, batch 470 (16470): mcc: 0.8778, acc: 0.8359, precision: 0.9066, recall: 0.8628, f1: 0.8841, edges-ner-ontonotes_loss: 0.0347
09/16 12:46:41 PM: Update 16594: task edges-ner-ontonotes, batch 594 (16594): mcc: 0.8776, acc: 0.8349, precision: 0.9061, recall: 0.8629, f1: 0.8840, edges-ner-ontonotes_loss: 0.0344
09/16 12:46:51 PM: Update 16698: task edges-ner-ontonotes, batch 698 (16698): mcc: 0.8766, acc: 0.8334, precision: 0.9055, recall: 0.8617, f1: 0.8830, edges-ner-ontonotes_loss: 0.0346
09/16 12:47:04 PM: Update 16813: task edges-ner-ontonotes, batch 813 (16813): mcc: 0.8775, acc: 0.8341, precision: 0.9064, recall: 0.8625, f1: 0.8839, edges-ner-ontonotes_loss: 0.0343
09/16 12:47:14 PM: Update 16934: task edges-ner-ontonotes, batch 934 (16934): mcc: 0.8742, acc: 0.8300, precision: 0.9042, recall: 0.8583, f1: 0.8807, edges-ner-ontonotes_loss: 0.0358
09/16 12:47:19 PM: ***** Step 17000 / Validation 17 *****
09/16 12:47:21 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:47:21 PM: Validating...
09/16 12:47:24 PM: Evaluate: task edges-ner-ontonotes, batch 36 (157): mcc: 0.8631, acc: 0.8321, precision: 0.8955, recall: 0.8462, f1: 0.8701, edges-ner-ontonotes_loss: 0.0473
09/16 12:47:30 PM: Updating LR scheduler:
09/16 12:47:30 PM: 	Best result seen so far for macro_avg: 0.869
09/16 12:47:30 PM: 	# validation passes without improvement: 2
09/16 12:47:30 PM: edges-ner-ontonotes_loss: training: 0.036299 validation: 0.043570
09/16 12:47:30 PM: macro_avg: validation: 0.864228
09/16 12:47:30 PM: micro_avg: validation: 0.000000
09/16 12:47:30 PM: edges-ner-ontonotes_mcc: training: 0.873710 validation: 0.857496
09/16 12:47:30 PM: edges-ner-ontonotes_acc: training: 0.829634 validation: 0.819533
09/16 12:47:30 PM: edges-ner-ontonotes_precision: training: 0.904068 validation: 0.903199
09/16 12:47:30 PM: edges-ner-ontonotes_recall: training: 0.857597 validation: 0.828480
09/16 12:47:30 PM: edges-ner-ontonotes_f1: training: 0.880220 validation: 0.864228
09/16 12:47:30 PM: Global learning rate: 5e-05
09/16 12:47:30 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 12:47:34 PM: Update 17046: task edges-ner-ontonotes, batch 46 (17046): mcc: 0.8608, acc: 0.8116, precision: 0.9021, recall: 0.8356, f1: 0.8676, edges-ner-ontonotes_loss: 0.0446
09/16 12:47:44 PM: Update 17130: task edges-ner-ontonotes, batch 130 (17130): mcc: 0.8642, acc: 0.8172, precision: 0.9039, recall: 0.8401, f1: 0.8709, edges-ner-ontonotes_loss: 0.0421
09/16 12:47:54 PM: Update 17249: task edges-ner-ontonotes, batch 249 (17249): mcc: 0.8787, acc: 0.8378, precision: 0.9126, recall: 0.8588, f1: 0.8848, edges-ner-ontonotes_loss: 0.0374
09/16 12:48:04 PM: Update 17413: task edges-ner-ontonotes, batch 413 (17413): mcc: 0.8872, acc: 0.8500, precision: 0.9172, recall: 0.8700, f1: 0.8930, edges-ner-ontonotes_loss: 0.0349
09/16 12:48:14 PM: Update 17470: task edges-ner-ontonotes, batch 470 (17470): mcc: 0.8866, acc: 0.8490, precision: 0.9172, recall: 0.8688, f1: 0.8923, edges-ner-ontonotes_loss: 0.0349
09/16 12:48:24 PM: Update 17577: task edges-ner-ontonotes, batch 577 (17577): mcc: 0.8856, acc: 0.8478, precision: 0.9164, recall: 0.8678, f1: 0.8915, edges-ner-ontonotes_loss: 0.0349
09/16 12:48:34 PM: Update 17700: task edges-ner-ontonotes, batch 700 (17700): mcc: 0.8850, acc: 0.8467, precision: 0.9165, recall: 0.8666, f1: 0.8908, edges-ner-ontonotes_loss: 0.0346
09/16 12:48:44 PM: Update 17788: task edges-ner-ontonotes, batch 788 (17788): mcc: 0.8835, acc: 0.8449, precision: 0.9146, recall: 0.8657, f1: 0.8895, edges-ner-ontonotes_loss: 0.0347
09/16 12:48:55 PM: Update 17901: task edges-ner-ontonotes, batch 901 (17901): mcc: 0.8820, acc: 0.8425, precision: 0.9125, recall: 0.8648, f1: 0.8880, edges-ner-ontonotes_loss: 0.0348
09/16 12:49:02 PM: ***** Step 18000 / Validation 18 *****
09/16 12:49:04 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:49:04 PM: Validating...
09/16 12:49:05 PM: Evaluate: task edges-ner-ontonotes, batch 6 (157): mcc: 0.7490, acc: 0.7075, precision: 0.8067, recall: 0.7200, f1: 0.7609, edges-ner-ontonotes_loss: 0.0710
09/16 12:49:15 PM: Evaluate: task edges-ner-ontonotes, batch 131 (157): mcc: 0.8550, acc: 0.8149, precision: 0.8906, recall: 0.8359, f1: 0.8624, edges-ner-ontonotes_loss: 0.0455
09/16 12:49:17 PM: Updating LR scheduler:
09/16 12:49:17 PM: 	Best result seen so far for macro_avg: 0.869
09/16 12:49:17 PM: 	# validation passes without improvement: 3
09/16 12:49:17 PM: edges-ner-ontonotes_loss: training: 0.034437 validation: 0.043315
09/16 12:49:17 PM: macro_avg: validation: 0.868801
09/16 12:49:17 PM: micro_avg: validation: 0.000000
09/16 12:49:17 PM: edges-ner-ontonotes_mcc: training: 0.882161 validation: 0.861792
09/16 12:49:17 PM: edges-ner-ontonotes_acc: training: 0.842465 validation: 0.822414
09/16 12:49:17 PM: edges-ner-ontonotes_precision: training: 0.912331 validation: 0.896443
09/16 12:49:17 PM: edges-ner-ontonotes_recall: training: 0.865329 validation: 0.842812
09/16 12:49:17 PM: edges-ner-ontonotes_f1: training: 0.888209 validation: 0.868801
09/16 12:49:17 PM: Global learning rate: 5e-05
09/16 12:49:17 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 12:49:26 PM: Update 18056: task edges-ner-ontonotes, batch 56 (18056): mcc: 0.8748, acc: 0.8292, precision: 0.9043, recall: 0.8594, f1: 0.8813, edges-ner-ontonotes_loss: 0.0333
09/16 12:49:36 PM: Update 18187: task edges-ner-ontonotes, batch 187 (18187): mcc: 0.8745, acc: 0.8279, precision: 0.9035, recall: 0.8597, f1: 0.8811, edges-ner-ontonotes_loss: 0.0338
09/16 12:49:46 PM: Update 18312: task edges-ner-ontonotes, batch 312 (18312): mcc: 0.8758, acc: 0.8309, precision: 0.9040, recall: 0.8616, f1: 0.8823, edges-ner-ontonotes_loss: 0.0338
09/16 12:49:56 PM: Update 18373: task edges-ner-ontonotes, batch 373 (18373): mcc: 0.8749, acc: 0.8296, precision: 0.9035, recall: 0.8604, f1: 0.8814, edges-ner-ontonotes_loss: 0.0339
09/16 12:50:06 PM: Update 18498: task edges-ner-ontonotes, batch 498 (18498): mcc: 0.8690, acc: 0.8228, precision: 0.9003, recall: 0.8525, f1: 0.8757, edges-ner-ontonotes_loss: 0.0372
09/16 12:50:16 PM: Update 18666: task edges-ner-ontonotes, batch 666 (18666): mcc: 0.8675, acc: 0.8213, precision: 0.9003, recall: 0.8496, f1: 0.8742, edges-ner-ontonotes_loss: 0.0386
09/16 12:50:26 PM: Update 18699: task edges-ner-ontonotes, batch 699 (18699): mcc: 0.8680, acc: 0.8222, precision: 0.9008, recall: 0.8502, f1: 0.8748, edges-ner-ontonotes_loss: 0.0385
09/16 12:50:36 PM: Update 18836: task edges-ner-ontonotes, batch 836 (18836): mcc: 0.8718, acc: 0.8279, precision: 0.9037, recall: 0.8544, f1: 0.8784, edges-ner-ontonotes_loss: 0.0375
09/16 12:50:46 PM: Update 18969: task edges-ner-ontonotes, batch 969 (18969): mcc: 0.8753, acc: 0.8329, precision: 0.9064, recall: 0.8583, f1: 0.8817, edges-ner-ontonotes_loss: 0.0365
09/16 12:50:54 PM: ***** Step 19000 / Validation 19 *****
09/16 12:50:54 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:50:54 PM: Validating...
09/16 12:50:56 PM: Evaluate: task edges-ner-ontonotes, batch 59 (157): mcc: 0.8775, acc: 0.8463, precision: 0.9109, recall: 0.8580, f1: 0.8837, edges-ner-ontonotes_loss: 0.0401
09/16 12:51:01 PM: Updating LR scheduler:
09/16 12:51:01 PM: 	Best result seen so far for macro_avg: 0.869
09/16 12:51:01 PM: 	# validation passes without improvement: 0
09/16 12:51:01 PM: edges-ner-ontonotes_loss: training: 0.036430 validation: 0.043337
09/16 12:51:01 PM: macro_avg: validation: 0.862322
09/16 12:51:01 PM: micro_avg: validation: 0.000000
09/16 12:51:01 PM: edges-ner-ontonotes_mcc: training: 0.875491 validation: 0.855638
09/16 12:51:01 PM: edges-ner-ontonotes_acc: training: 0.833306 validation: 0.815211
09/16 12:51:01 PM: edges-ner-ontonotes_precision: training: 0.906498 validation: 0.904100
09/16 12:51:01 PM: edges-ner-ontonotes_recall: training: 0.858562 validation: 0.824234
09/16 12:51:01 PM: edges-ner-ontonotes_f1: training: 0.881879 validation: 0.862322
09/16 12:51:01 PM: Global learning rate: 2.5e-05
09/16 12:51:01 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 12:51:06 PM: Update 19095: task edges-ner-ontonotes, batch 95 (19095): mcc: 0.8811, acc: 0.8387, precision: 0.9143, recall: 0.8614, f1: 0.8871, edges-ner-ontonotes_loss: 0.0345
09/16 12:51:17 PM: Update 19277: task edges-ner-ontonotes, batch 277 (19277): mcc: 0.8807, acc: 0.8404, precision: 0.9137, recall: 0.8614, f1: 0.8868, edges-ner-ontonotes_loss: 0.0351
09/16 12:51:27 PM: Update 19349: task edges-ner-ontonotes, batch 349 (19349): mcc: 0.8787, acc: 0.8375, precision: 0.9114, recall: 0.8598, f1: 0.8849, edges-ner-ontonotes_loss: 0.0352
09/16 12:51:37 PM: Update 19468: task edges-ner-ontonotes, batch 468 (19468): mcc: 0.8793, acc: 0.8379, precision: 0.9103, recall: 0.8619, f1: 0.8854, edges-ner-ontonotes_loss: 0.0347
09/16 12:51:48 PM: Update 19579: task edges-ner-ontonotes, batch 579 (19579): mcc: 0.8784, acc: 0.8364, precision: 0.9086, recall: 0.8620, f1: 0.8847, edges-ner-ontonotes_loss: 0.0347
09/16 12:51:58 PM: Update 19650: task edges-ner-ontonotes, batch 650 (19650): mcc: 0.8779, acc: 0.8353, precision: 0.9081, recall: 0.8615, f1: 0.8842, edges-ner-ontonotes_loss: 0.0347
09/16 12:52:08 PM: Update 19816: task edges-ner-ontonotes, batch 816 (19816): mcc: 0.8772, acc: 0.8340, precision: 0.9071, recall: 0.8611, f1: 0.8835, edges-ner-ontonotes_loss: 0.0347
09/16 12:52:21 PM: Update 19925: task edges-ner-ontonotes, batch 925 (19925): mcc: 0.8773, acc: 0.8340, precision: 0.9071, recall: 0.8615, f1: 0.8837, edges-ner-ontonotes_loss: 0.0345
09/16 12:52:27 PM: ***** Step 20000 / Validation 20 *****
09/16 12:52:27 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:52:27 PM: Validating...
09/16 12:52:31 PM: Evaluate: task edges-ner-ontonotes, batch 48 (157): mcc: 0.8647, acc: 0.8354, precision: 0.8993, recall: 0.8455, f1: 0.8715, edges-ner-ontonotes_loss: 0.0449
09/16 12:52:41 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:52:41 PM: Best result seen so far for macro.
09/16 12:52:41 PM: Updating LR scheduler:
09/16 12:52:41 PM: 	Best result seen so far for macro_avg: 0.869
09/16 12:52:41 PM: 	# validation passes without improvement: 0
09/16 12:52:41 PM: edges-ner-ontonotes_loss: training: 0.035439 validation: 0.042189
09/16 12:52:41 PM: macro_avg: validation: 0.869335
09/16 12:52:41 PM: micro_avg: validation: 0.000000
09/16 12:52:41 PM: edges-ner-ontonotes_mcc: training: 0.875551 validation: 0.862847
09/16 12:52:41 PM: edges-ner-ontonotes_acc: training: 0.832033 validation: 0.822869
09/16 12:52:41 PM: edges-ner-ontonotes_precision: training: 0.905984 validation: 0.907598
09/16 12:52:41 PM: edges-ner-ontonotes_recall: training: 0.859171 validation: 0.834167
09/16 12:52:41 PM: edges-ner-ontonotes_f1: training: 0.881956 validation: 0.869335
09/16 12:52:41 PM: Global learning rate: 2.5e-05
09/16 12:52:41 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 12:52:41 PM: Update 20004: task edges-ner-ontonotes, batch 4 (20004): mcc: 0.8458, acc: 0.7963, precision: 0.8949, recall: 0.8148, f1: 0.8530, edges-ner-ontonotes_loss: 0.0426
09/16 12:52:54 PM: Update 20134: task edges-ner-ontonotes, batch 134 (20134): mcc: 0.8614, acc: 0.8146, precision: 0.9003, recall: 0.8384, f1: 0.8682, edges-ner-ontonotes_loss: 0.0421
09/16 12:53:05 PM: Update 20229: task edges-ner-ontonotes, batch 229 (20229): mcc: 0.8616, acc: 0.8152, precision: 0.9011, recall: 0.8380, f1: 0.8684, edges-ner-ontonotes_loss: 0.0430
09/16 12:53:15 PM: Update 20366: task edges-ner-ontonotes, batch 366 (20366): mcc: 0.8750, acc: 0.8328, precision: 0.9099, recall: 0.8543, f1: 0.8812, edges-ner-ontonotes_loss: 0.0385
09/16 12:53:25 PM: Update 20497: task edges-ner-ontonotes, batch 497 (20497): mcc: 0.8803, acc: 0.8405, precision: 0.9127, recall: 0.8614, f1: 0.8864, edges-ner-ontonotes_loss: 0.0366
09/16 12:53:35 PM: Update 20610: task edges-ner-ontonotes, batch 610 (20610): mcc: 0.8810, acc: 0.8417, precision: 0.9136, recall: 0.8620, f1: 0.8870, edges-ner-ontonotes_loss: 0.0361
09/16 12:53:45 PM: Update 20753: task edges-ner-ontonotes, batch 753 (20753): mcc: 0.8811, acc: 0.8421, precision: 0.9133, recall: 0.8624, f1: 0.8871, edges-ner-ontonotes_loss: 0.0359
09/16 12:53:56 PM: Update 20855: task edges-ner-ontonotes, batch 855 (20855): mcc: 0.8811, acc: 0.8420, precision: 0.9133, recall: 0.8624, f1: 0.8871, edges-ner-ontonotes_loss: 0.0358
09/16 12:54:06 PM: Update 20976: task edges-ner-ontonotes, batch 976 (20976): mcc: 0.8803, acc: 0.8407, precision: 0.9121, recall: 0.8620, f1: 0.8864, edges-ner-ontonotes_loss: 0.0355
09/16 12:54:09 PM: ***** Step 21000 / Validation 21 *****
09/16 12:54:09 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:54:09 PM: Validating...
09/16 12:54:17 PM: Evaluate: task edges-ner-ontonotes, batch 115 (157): mcc: 0.8525, acc: 0.8093, precision: 0.8865, recall: 0.8350, f1: 0.8600, edges-ner-ontonotes_loss: 0.0459
09/16 12:54:21 PM: Updating LR scheduler:
09/16 12:54:21 PM: 	Best result seen so far for macro_avg: 0.869
09/16 12:54:21 PM: 	# validation passes without improvement: 1
09/16 12:54:21 PM: edges-ner-ontonotes_loss: training: 0.035487 validation: 0.042563
09/16 12:54:21 PM: macro_avg: validation: 0.868857
09/16 12:54:21 PM: micro_avg: validation: 0.000000
09/16 12:54:21 PM: edges-ner-ontonotes_mcc: training: 0.880307 validation: 0.861747
09/16 12:54:21 PM: edges-ner-ontonotes_acc: training: 0.840589 validation: 0.819381
09/16 12:54:21 PM: edges-ner-ontonotes_precision: training: 0.911868 validation: 0.893834
09/16 12:54:21 PM: edges-ner-ontonotes_recall: training: 0.862332 validation: 0.845238
09/16 12:54:21 PM: edges-ner-ontonotes_f1: training: 0.886409 validation: 0.868857
09/16 12:54:21 PM: Global learning rate: 2.5e-05
09/16 12:54:21 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 12:54:27 PM: Update 21071: task edges-ner-ontonotes, batch 71 (21071): mcc: 0.8820, acc: 0.8347, precision: 0.9099, recall: 0.8674, f1: 0.8882, edges-ner-ontonotes_loss: 0.0327
09/16 12:54:38 PM: Update 21168: task edges-ner-ontonotes, batch 168 (21168): mcc: 0.8778, acc: 0.8336, precision: 0.9059, recall: 0.8634, f1: 0.8841, edges-ner-ontonotes_loss: 0.0336
09/16 12:54:48 PM: Update 21276: task edges-ner-ontonotes, batch 276 (21276): mcc: 0.8773, acc: 0.8325, precision: 0.9047, recall: 0.8637, f1: 0.8837, edges-ner-ontonotes_loss: 0.0337
09/16 12:54:59 PM: Update 21471: task edges-ner-ontonotes, batch 471 (21471): mcc: 0.8785, acc: 0.8333, precision: 0.9060, recall: 0.8646, f1: 0.8848, edges-ner-ontonotes_loss: 0.0337
09/16 12:55:09 PM: Update 21546: task edges-ner-ontonotes, batch 546 (21546): mcc: 0.8757, acc: 0.8303, precision: 0.9047, recall: 0.8608, f1: 0.8822, edges-ner-ontonotes_loss: 0.0350
09/16 12:55:19 PM: Update 21685: task edges-ner-ontonotes, batch 685 (21685): mcc: 0.8725, acc: 0.8272, precision: 0.9030, recall: 0.8563, f1: 0.8790, edges-ner-ontonotes_loss: 0.0368
09/16 12:55:34 PM: Update 21785: task edges-ner-ontonotes, batch 785 (21785): mcc: 0.8709, acc: 0.8252, precision: 0.9027, recall: 0.8537, f1: 0.8775, edges-ner-ontonotes_loss: 0.0376
09/16 12:55:44 PM: Update 21892: task edges-ner-ontonotes, batch 892 (21892): mcc: 0.8730, acc: 0.8283, precision: 0.9042, recall: 0.8561, f1: 0.8795, edges-ner-ontonotes_loss: 0.0371
09/16 12:55:52 PM: ***** Step 22000 / Validation 22 *****
09/16 12:55:52 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:55:52 PM: Validating...
09/16 12:55:54 PM: Evaluate: task edges-ner-ontonotes, batch 40 (157): mcc: 0.8638, acc: 0.8293, precision: 0.8990, recall: 0.8440, f1: 0.8707, edges-ner-ontonotes_loss: 0.0442
09/16 12:56:00 PM: Updating LR scheduler:
09/16 12:56:00 PM: 	Best result seen so far for macro_avg: 0.869
09/16 12:56:00 PM: 	# validation passes without improvement: 2
09/16 12:56:00 PM: edges-ner-ontonotes_loss: training: 0.036400 validation: 0.042806
09/16 12:56:00 PM: macro_avg: validation: 0.863660
09/16 12:56:00 PM: micro_avg: validation: 0.000000
09/16 12:56:00 PM: edges-ner-ontonotes_mcc: training: 0.875416 validation: 0.857056
09/16 12:56:00 PM: edges-ner-ontonotes_acc: training: 0.832007 validation: 0.816879
09/16 12:56:00 PM: edges-ner-ontonotes_precision: training: 0.906120 validation: 0.905582
09/16 12:56:00 PM: edges-ner-ontonotes_recall: training: 0.858788 validation: 0.825447
09/16 12:56:00 PM: edges-ner-ontonotes_f1: training: 0.881819 validation: 0.863660
09/16 12:56:00 PM: Global learning rate: 2.5e-05
09/16 12:56:00 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 12:56:04 PM: Update 22069: task edges-ner-ontonotes, batch 69 (22069): mcc: 0.9036, acc: 0.8700, precision: 0.9317, recall: 0.8865, f1: 0.9086, edges-ner-ontonotes_loss: 0.0298
09/16 12:56:14 PM: Update 22169: task edges-ner-ontonotes, batch 169 (22169): mcc: 0.8912, acc: 0.8562, precision: 0.9209, recall: 0.8738, f1: 0.8967, edges-ner-ontonotes_loss: 0.0320
09/16 12:56:24 PM: Update 22330: task edges-ner-ontonotes, batch 330 (22330): mcc: 0.8870, acc: 0.8490, precision: 0.9184, recall: 0.8684, f1: 0.8927, edges-ner-ontonotes_loss: 0.0332
09/16 12:56:39 PM: Update 22411: task edges-ner-ontonotes, batch 411 (22411): mcc: 0.8851, acc: 0.8470, precision: 0.9160, recall: 0.8672, f1: 0.8910, edges-ner-ontonotes_loss: 0.0337
09/16 12:56:49 PM: Update 22577: task edges-ner-ontonotes, batch 577 (22577): mcc: 0.8812, acc: 0.8407, precision: 0.9113, recall: 0.8646, f1: 0.8873, edges-ner-ontonotes_loss: 0.0341
09/16 12:56:59 PM: Update 22675: task edges-ner-ontonotes, batch 675 (22675): mcc: 0.8811, acc: 0.8401, precision: 0.9104, recall: 0.8653, f1: 0.8872, edges-ner-ontonotes_loss: 0.0339
09/16 12:57:09 PM: Update 22725: task edges-ner-ontonotes, batch 725 (22725): mcc: 0.8808, acc: 0.8396, precision: 0.9098, recall: 0.8652, f1: 0.8869, edges-ner-ontonotes_loss: 0.0338
09/16 12:57:19 PM: Update 22833: task edges-ner-ontonotes, batch 833 (22833): mcc: 0.8801, acc: 0.8384, precision: 0.9091, recall: 0.8646, f1: 0.8863, edges-ner-ontonotes_loss: 0.0338
09/16 12:57:29 PM: Update 22973: task edges-ner-ontonotes, batch 973 (22973): mcc: 0.8797, acc: 0.8375, precision: 0.9087, recall: 0.8643, f1: 0.8860, edges-ner-ontonotes_loss: 0.0338
09/16 12:57:32 PM: ***** Step 23000 / Validation 23 *****
09/16 12:57:32 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:57:32 PM: Validating...
09/16 12:57:39 PM: Evaluate: task edges-ner-ontonotes, batch 99 (157): mcc: 0.8556, acc: 0.8170, precision: 0.8951, recall: 0.8326, f1: 0.8627, edges-ner-ontonotes_loss: 0.0473
09/16 12:57:44 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:57:44 PM: Best result seen so far for macro.
09/16 12:57:44 PM: Updating LR scheduler:
09/16 12:57:44 PM: 	Best result seen so far for macro_avg: 0.871
09/16 12:57:44 PM: 	# validation passes without improvement: 0
09/16 12:57:44 PM: edges-ner-ontonotes_loss: training: 0.033712 validation: 0.042521
09/16 12:57:44 PM: macro_avg: validation: 0.871454
09/16 12:57:44 PM: micro_avg: validation: 0.000000
09/16 12:57:44 PM: edges-ner-ontonotes_mcc: training: 0.879958 validation: 0.864647
09/16 12:57:44 PM: edges-ner-ontonotes_acc: training: 0.837747 validation: 0.824386
09/16 12:57:44 PM: edges-ner-ontonotes_precision: training: 0.908766 validation: 0.900380
09/16 12:57:44 PM: edges-ner-ontonotes_recall: training: 0.864678 validation: 0.844328
09/16 12:57:44 PM: edges-ner-ontonotes_f1: training: 0.886174 validation: 0.871454
09/16 12:57:44 PM: Global learning rate: 2.5e-05
09/16 12:57:44 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 12:57:50 PM: Update 23037: task edges-ner-ontonotes, batch 37 (23037): mcc: 0.8714, acc: 0.8230, precision: 0.9013, recall: 0.8559, f1: 0.8780, edges-ner-ontonotes_loss: 0.0339
09/16 12:58:00 PM: Update 23164: task edges-ner-ontonotes, batch 164 (23164): mcc: 0.8587, acc: 0.8135, precision: 0.8955, recall: 0.8380, f1: 0.8658, edges-ner-ontonotes_loss: 0.0427
09/16 12:58:10 PM: Update 23288: task edges-ner-ontonotes, batch 288 (23288): mcc: 0.8602, acc: 0.8147, precision: 0.8969, recall: 0.8394, f1: 0.8672, edges-ner-ontonotes_loss: 0.0427
09/16 12:58:20 PM: Update 23427: task edges-ner-ontonotes, batch 427 (23427): mcc: 0.8682, acc: 0.8255, precision: 0.9027, recall: 0.8488, f1: 0.8749, edges-ner-ontonotes_loss: 0.0404
09/16 12:58:30 PM: Update 23582: task edges-ner-ontonotes, batch 582 (23582): mcc: 0.8753, acc: 0.8351, precision: 0.9075, recall: 0.8573, f1: 0.8817, edges-ner-ontonotes_loss: 0.0379
09/16 12:58:41 PM: Update 23654: task edges-ner-ontonotes, batch 654 (23654): mcc: 0.8769, acc: 0.8373, precision: 0.9083, recall: 0.8593, f1: 0.8832, edges-ner-ontonotes_loss: 0.0373
09/16 12:58:51 PM: Update 23755: task edges-ner-ontonotes, batch 755 (23755): mcc: 0.8773, acc: 0.8375, precision: 0.9092, recall: 0.8592, f1: 0.8835, edges-ner-ontonotes_loss: 0.0370
09/16 12:59:01 PM: Update 23894: task edges-ner-ontonotes, batch 894 (23894): mcc: 0.8780, acc: 0.8388, precision: 0.9097, recall: 0.8602, f1: 0.8842, edges-ner-ontonotes_loss: 0.0366
09/16 12:59:12 PM: Update 23967: task edges-ner-ontonotes, batch 967 (23967): mcc: 0.8783, acc: 0.8393, precision: 0.9098, recall: 0.8605, f1: 0.8845, edges-ner-ontonotes_loss: 0.0364
09/16 12:59:15 PM: ***** Step 24000 / Validation 24 *****
09/16 12:59:15 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 12:59:15 PM: Validating...
09/16 12:59:22 PM: Evaluate: task edges-ner-ontonotes, batch 103 (157): mcc: 0.8610, acc: 0.8257, precision: 0.8990, recall: 0.8389, f1: 0.8679, edges-ner-ontonotes_loss: 0.0453
09/16 12:59:27 PM: Best result seen so far for edges-ner-ontonotes.
09/16 12:59:28 PM: Best result seen so far for macro.
09/16 12:59:28 PM: Updating LR scheduler:
09/16 12:59:28 PM: 	Best result seen so far for macro_avg: 0.871
09/16 12:59:28 PM: 	# validation passes without improvement: 1
09/16 12:59:28 PM: edges-ner-ontonotes_loss: training: 0.036357 validation: 0.042051
09/16 12:59:28 PM: macro_avg: validation: 0.871536
09/16 12:59:28 PM: micro_avg: validation: 0.000000
09/16 12:59:28 PM: edges-ner-ontonotes_mcc: training: 0.878108 validation: 0.864745
09/16 12:59:28 PM: edges-ner-ontonotes_acc: training: 0.838901 validation: 0.830073
09/16 12:59:28 PM: edges-ner-ontonotes_precision: training: 0.909615 validation: 0.900728
09/16 12:59:28 PM: edges-ner-ontonotes_recall: training: 0.860418 validation: 0.844177
09/16 12:59:28 PM: edges-ner-ontonotes_f1: training: 0.884333 validation: 0.871536
09/16 12:59:28 PM: Global learning rate: 2.5e-05
09/16 12:59:28 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 12:59:32 PM: Update 24060: task edges-ner-ontonotes, batch 60 (24060): mcc: 0.8750, acc: 0.8311, precision: 0.9036, recall: 0.8605, f1: 0.8815, edges-ner-ontonotes_loss: 0.0345
09/16 12:59:42 PM: Update 24177: task edges-ner-ontonotes, batch 177 (24177): mcc: 0.8766, acc: 0.8311, precision: 0.9032, recall: 0.8637, f1: 0.8830, edges-ner-ontonotes_loss: 0.0344
09/16 12:59:53 PM: Update 24280: task edges-ner-ontonotes, batch 280 (24280): mcc: 0.8781, acc: 0.8337, precision: 0.9045, recall: 0.8654, f1: 0.8845, edges-ner-ontonotes_loss: 0.0336
09/16 01:00:03 PM: Update 24381: task edges-ner-ontonotes, batch 381 (24381): mcc: 0.8769, acc: 0.8319, precision: 0.9040, recall: 0.8636, f1: 0.8833, edges-ner-ontonotes_loss: 0.0337
09/16 01:00:13 PM: Update 24473: task edges-ner-ontonotes, batch 473 (24473): mcc: 0.8773, acc: 0.8323, precision: 0.9047, recall: 0.8637, f1: 0.8837, edges-ner-ontonotes_loss: 0.0336
09/16 01:00:26 PM: Update 24593: task edges-ner-ontonotes, batch 593 (24593): mcc: 0.8780, acc: 0.8332, precision: 0.9058, recall: 0.8640, f1: 0.8844, edges-ner-ontonotes_loss: 0.0335
09/16 01:00:36 PM: Update 24731: task edges-ner-ontonotes, batch 731 (24731): mcc: 0.8737, acc: 0.8284, precision: 0.9037, recall: 0.8580, f1: 0.8803, edges-ner-ontonotes_loss: 0.0357
09/16 01:00:46 PM: Update 24854: task edges-ner-ontonotes, batch 854 (24854): mcc: 0.8722, acc: 0.8270, precision: 0.9034, recall: 0.8555, f1: 0.8788, edges-ner-ontonotes_loss: 0.0368
09/16 01:00:56 PM: Update 24913: task edges-ner-ontonotes, batch 913 (24913): mcc: 0.8722, acc: 0.8270, precision: 0.9036, recall: 0.8552, f1: 0.8787, edges-ner-ontonotes_loss: 0.0370
09/16 01:01:01 PM: ***** Step 25000 / Validation 25 *****
09/16 01:01:01 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:01:01 PM: Validating...
09/16 01:01:06 PM: Evaluate: task edges-ner-ontonotes, batch 84 (157): mcc: 0.8699, acc: 0.8326, precision: 0.9121, recall: 0.8429, f1: 0.8761, edges-ner-ontonotes_loss: 0.0432
09/16 01:01:09 PM: Updating LR scheduler:
09/16 01:01:09 PM: 	Best result seen so far for macro_avg: 0.871
09/16 01:01:09 PM: 	# validation passes without improvement: 2
09/16 01:01:09 PM: edges-ner-ontonotes_loss: training: 0.036588 validation: 0.042802
09/16 01:01:09 PM: macro_avg: validation: 0.864467
09/16 01:01:09 PM: micro_avg: validation: 0.000000
09/16 01:01:09 PM: edges-ner-ontonotes_mcc: training: 0.873858 validation: 0.857840
09/16 01:01:09 PM: edges-ner-ontonotes_acc: training: 0.829571 validation: 0.818775
09/16 01:01:09 PM: edges-ner-ontonotes_precision: training: 0.904670 validation: 0.905169
09/16 01:01:09 PM: edges-ner-ontonotes_recall: training: 0.857290 validation: 0.827267
09/16 01:01:09 PM: edges-ner-ontonotes_f1: training: 0.880343 validation: 0.864467
09/16 01:01:09 PM: Global learning rate: 2.5e-05
09/16 01:01:09 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 01:01:16 PM: Update 25138: task edges-ner-ontonotes, batch 138 (25138): mcc: 0.9000, acc: 0.8675, precision: 0.9278, recall: 0.8835, f1: 0.9051, edges-ner-ontonotes_loss: 0.0313
09/16 01:01:26 PM: Update 25282: task edges-ner-ontonotes, batch 282 (25282): mcc: 0.8900, acc: 0.8549, precision: 0.9198, recall: 0.8726, f1: 0.8956, edges-ner-ontonotes_loss: 0.0325
09/16 01:01:36 PM: Update 25450: task edges-ner-ontonotes, batch 450 (25450): mcc: 0.8885, acc: 0.8524, precision: 0.9184, recall: 0.8712, f1: 0.8942, edges-ner-ontonotes_loss: 0.0328
09/16 01:01:46 PM: Update 25573: task edges-ner-ontonotes, batch 573 (25573): mcc: 0.8855, acc: 0.8484, precision: 0.9151, recall: 0.8688, f1: 0.8914, edges-ner-ontonotes_loss: 0.0334
09/16 01:01:56 PM: Update 25683: task edges-ner-ontonotes, batch 683 (25683): mcc: 0.8839, acc: 0.8459, precision: 0.9131, recall: 0.8678, f1: 0.8899, edges-ner-ontonotes_loss: 0.0335
09/16 01:02:06 PM: Update 25809: task edges-ner-ontonotes, batch 809 (25809): mcc: 0.8832, acc: 0.8438, precision: 0.9117, recall: 0.8678, f1: 0.8892, edges-ner-ontonotes_loss: 0.0334
09/16 01:02:16 PM: Update 25876: task edges-ner-ontonotes, batch 876 (25876): mcc: 0.8826, acc: 0.8427, precision: 0.9110, recall: 0.8675, f1: 0.8887, edges-ner-ontonotes_loss: 0.0334
09/16 01:02:26 PM: Update 25982: task edges-ner-ontonotes, batch 982 (25982): mcc: 0.8823, acc: 0.8417, precision: 0.9108, recall: 0.8670, f1: 0.8884, edges-ner-ontonotes_loss: 0.0334
09/16 01:02:27 PM: ***** Step 26000 / Validation 26 *****
09/16 01:02:28 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:02:28 PM: Validating...
09/16 01:02:36 PM: Evaluate: task edges-ner-ontonotes, batch 121 (157): mcc: 0.8562, acc: 0.8155, precision: 0.8954, recall: 0.8335, f1: 0.8633, edges-ner-ontonotes_loss: 0.0456
09/16 01:02:40 PM: Best result seen so far for edges-ner-ontonotes.
09/16 01:02:40 PM: Best result seen so far for macro.
09/16 01:02:40 PM: Updating LR scheduler:
09/16 01:02:40 PM: 	Best result seen so far for macro_avg: 0.872
09/16 01:02:40 PM: 	# validation passes without improvement: 0
09/16 01:02:40 PM: edges-ner-ontonotes_loss: training: 0.033444 validation: 0.042564
09/16 01:02:40 PM: macro_avg: validation: 0.871578
09/16 01:02:40 PM: micro_avg: validation: 0.000000
09/16 01:02:40 PM: edges-ner-ontonotes_mcc: training: 0.882180 validation: 0.864878
09/16 01:02:40 PM: edges-ner-ontonotes_acc: training: 0.841599 validation: 0.825751
09/16 01:02:40 PM: edges-ner-ontonotes_precision: training: 0.910617 validation: 0.902812
09/16 01:02:40 PM: edges-ner-ontonotes_recall: training: 0.867020 validation: 0.842432
09/16 01:02:40 PM: edges-ner-ontonotes_f1: training: 0.888284 validation: 0.871578
09/16 01:02:40 PM: Global learning rate: 2.5e-05
09/16 01:02:40 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 01:02:46 PM: Update 26093: task edges-ner-ontonotes, batch 93 (26093): mcc: 0.8766, acc: 0.8315, precision: 0.9036, recall: 0.8634, f1: 0.8830, edges-ner-ontonotes_loss: 0.0342
09/16 01:02:56 PM: Update 26177: task edges-ner-ontonotes, batch 177 (26177): mcc: 0.8738, acc: 0.8296, precision: 0.9023, recall: 0.8595, f1: 0.8804, edges-ner-ontonotes_loss: 0.0352
09/16 01:03:06 PM: Update 26314: task edges-ner-ontonotes, batch 314 (26314): mcc: 0.8676, acc: 0.8221, precision: 0.8992, recall: 0.8510, f1: 0.8744, edges-ner-ontonotes_loss: 0.0393
09/16 01:03:18 PM: Update 26453: task edges-ner-ontonotes, batch 453 (26453): mcc: 0.8658, acc: 0.8197, precision: 0.8991, recall: 0.8476, f1: 0.8726, edges-ner-ontonotes_loss: 0.0405
09/16 01:03:28 PM: Update 26583: task edges-ner-ontonotes, batch 583 (26583): mcc: 0.8711, acc: 0.8275, precision: 0.9030, recall: 0.8538, f1: 0.8777, edges-ner-ontonotes_loss: 0.0387
09/16 01:03:38 PM: Update 26723: task edges-ner-ontonotes, batch 723 (26723): mcc: 0.8761, acc: 0.8345, precision: 0.9066, recall: 0.8596, f1: 0.8825, edges-ner-ontonotes_loss: 0.0371
09/16 01:03:48 PM: Update 26799: task edges-ner-ontonotes, batch 799 (26799): mcc: 0.8774, acc: 0.8361, precision: 0.9079, recall: 0.8607, f1: 0.8837, edges-ner-ontonotes_loss: 0.0367
09/16 01:03:58 PM: Update 26907: task edges-ner-ontonotes, batch 907 (26907): mcc: 0.8780, acc: 0.8370, precision: 0.9088, recall: 0.8610, f1: 0.8842, edges-ner-ontonotes_loss: 0.0365
09/16 01:04:06 PM: ***** Step 27000 / Validation 27 *****
09/16 01:04:06 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:04:06 PM: Validating...
09/16 01:04:09 PM: Evaluate: task edges-ner-ontonotes, batch 46 (157): mcc: 0.8629, acc: 0.8350, precision: 0.8928, recall: 0.8485, f1: 0.8700, edges-ner-ontonotes_loss: 0.0433
09/16 01:04:16 PM: Updating LR scheduler:
09/16 01:04:16 PM: 	Best result seen so far for macro_avg: 0.872
09/16 01:04:16 PM: 	# validation passes without improvement: 1
09/16 01:04:16 PM: edges-ner-ontonotes_loss: training: 0.036170 validation: 0.042403
09/16 01:04:16 PM: macro_avg: validation: 0.867696
09/16 01:04:16 PM: micro_avg: validation: 0.000000
09/16 01:04:16 PM: edges-ner-ontonotes_mcc: training: 0.879006 validation: 0.860851
09/16 01:04:16 PM: edges-ner-ontonotes_acc: training: 0.838517 validation: 0.824841
09/16 01:04:16 PM: edges-ner-ontonotes_precision: training: 0.909664 validation: 0.900497
09/16 01:04:16 PM: edges-ner-ontonotes_recall: training: 0.862039 validation: 0.837200
09/16 01:04:16 PM: edges-ner-ontonotes_f1: training: 0.885211 validation: 0.867696
09/16 01:04:16 PM: Global learning rate: 2.5e-05
09/16 01:04:16 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 01:04:20 PM: Update 27032: task edges-ner-ontonotes, batch 32 (27032): mcc: 0.8813, acc: 0.8426, precision: 0.9125, recall: 0.8635, f1: 0.8874, edges-ner-ontonotes_loss: 0.0351
09/16 01:04:30 PM: Update 27104: task edges-ner-ontonotes, batch 104 (27104): mcc: 0.8797, acc: 0.8407, precision: 0.9107, recall: 0.8623, f1: 0.8858, edges-ner-ontonotes_loss: 0.0346
09/16 01:04:40 PM: Update 27271: task edges-ner-ontonotes, batch 271 (27271): mcc: 0.8784, acc: 0.8362, precision: 0.9065, recall: 0.8640, f1: 0.8847, edges-ner-ontonotes_loss: 0.0342
09/16 01:04:51 PM: Update 27392: task edges-ner-ontonotes, batch 392 (27392): mcc: 0.8783, acc: 0.8351, precision: 0.9060, recall: 0.8643, f1: 0.8847, edges-ner-ontonotes_loss: 0.0340
09/16 01:05:01 PM: Update 27509: task edges-ner-ontonotes, batch 509 (27509): mcc: 0.8797, acc: 0.8365, precision: 0.9068, recall: 0.8660, f1: 0.8860, edges-ner-ontonotes_loss: 0.0336
09/16 01:05:11 PM: Update 27611: task edges-ner-ontonotes, batch 611 (27611): mcc: 0.8794, acc: 0.8362, precision: 0.9064, recall: 0.8660, f1: 0.8857, edges-ner-ontonotes_loss: 0.0337
09/16 01:05:23 PM: Update 27705: task edges-ner-ontonotes, batch 705 (27705): mcc: 0.8788, acc: 0.8349, precision: 0.9061, recall: 0.8652, f1: 0.8852, edges-ner-ontonotes_loss: 0.0337
09/16 01:05:33 PM: Update 27862: task edges-ner-ontonotes, batch 862 (27862): mcc: 0.8757, acc: 0.8311, precision: 0.9049, recall: 0.8604, f1: 0.8821, edges-ner-ontonotes_loss: 0.0355
09/16 01:05:43 PM: Update 27973: task edges-ner-ontonotes, batch 973 (27973): mcc: 0.8742, acc: 0.8296, precision: 0.9040, recall: 0.8586, f1: 0.8807, edges-ner-ontonotes_loss: 0.0365
09/16 01:05:45 PM: ***** Step 28000 / Validation 28 *****
09/16 01:05:45 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:05:45 PM: Validating...
09/16 01:05:53 PM: Evaluate: task edges-ner-ontonotes, batch 107 (157): mcc: 0.8583, acc: 0.8196, precision: 0.9049, recall: 0.8284, f1: 0.8650, edges-ner-ontonotes_loss: 0.0456
09/16 01:05:57 PM: Updating LR scheduler:
09/16 01:06:00 PM: 	Best result seen so far for macro_avg: 0.872
09/16 01:06:00 PM: 	# validation passes without improvement: 2
09/16 01:06:00 PM: edges-ner-ontonotes_loss: training: 0.036733 validation: 0.042818
09/16 01:06:00 PM: macro_avg: validation: 0.865708
09/16 01:06:00 PM: micro_avg: validation: 0.000000
09/16 01:06:00 PM: edges-ner-ontonotes_mcc: training: 0.873729 validation: 0.859132
09/16 01:06:00 PM: edges-ner-ontonotes_acc: training: 0.829197 validation: 0.820443
09/16 01:06:00 PM: edges-ner-ontonotes_precision: training: 0.903711 validation: 0.906076
09/16 01:06:00 PM: edges-ner-ontonotes_recall: training: 0.857978 validation: 0.828784
09/16 01:06:00 PM: edges-ner-ontonotes_f1: training: 0.880251 validation: 0.865708
09/16 01:06:00 PM: Global learning rate: 2.5e-05
09/16 01:06:00 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 01:06:03 PM: Update 28015: task edges-ner-ontonotes, batch 15 (28015): mcc: 0.8629, acc: 0.8164, precision: 0.9000, recall: 0.8414, f1: 0.8697, edges-ner-ontonotes_loss: 0.0416
09/16 01:06:13 PM: Update 28179: task edges-ner-ontonotes, batch 179 (28179): mcc: 0.8926, acc: 0.8592, precision: 0.9184, recall: 0.8789, f1: 0.8982, edges-ner-ontonotes_loss: 0.0328
09/16 01:06:23 PM: Update 28322: task edges-ner-ontonotes, batch 322 (28322): mcc: 0.8962, acc: 0.8632, precision: 0.9221, recall: 0.8821, f1: 0.9016, edges-ner-ontonotes_loss: 0.0318
09/16 01:06:34 PM: Update 28514: task edges-ner-ontonotes, batch 514 (28514): mcc: 0.8892, acc: 0.8543, precision: 0.9174, recall: 0.8736, f1: 0.8950, edges-ner-ontonotes_loss: 0.0332
09/16 01:06:44 PM: Update 28635: task edges-ner-ontonotes, batch 635 (28635): mcc: 0.8883, acc: 0.8524, precision: 0.9167, recall: 0.8725, f1: 0.8941, edges-ner-ontonotes_loss: 0.0331
09/16 01:06:54 PM: Update 28755: task edges-ner-ontonotes, batch 755 (28755): mcc: 0.8855, acc: 0.8483, precision: 0.9139, recall: 0.8700, f1: 0.8914, edges-ner-ontonotes_loss: 0.0334
09/16 01:07:04 PM: Update 28882: task edges-ner-ontonotes, batch 882 (28882): mcc: 0.8850, acc: 0.8469, precision: 0.9129, recall: 0.8701, f1: 0.8910, edges-ner-ontonotes_loss: 0.0333
09/16 01:07:18 PM: Update 28948: task edges-ner-ontonotes, batch 948 (28948): mcc: 0.8847, acc: 0.8460, precision: 0.9126, recall: 0.8698, f1: 0.8907, edges-ner-ontonotes_loss: 0.0333
09/16 01:07:22 PM: ***** Step 29000 / Validation 29 *****
09/16 01:07:22 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:07:22 PM: Validating...
09/16 01:07:28 PM: Evaluate: task edges-ner-ontonotes, batch 87 (157): mcc: 0.8643, acc: 0.8291, precision: 0.8993, recall: 0.8448, f1: 0.8712, edges-ner-ontonotes_loss: 0.0449
09/16 01:07:33 PM: Updating LR scheduler:
09/16 01:07:34 PM: 	Best result seen so far for macro_avg: 0.872
09/16 01:07:34 PM: 	# validation passes without improvement: 3
09/16 01:07:34 PM: edges-ner-ontonotes_loss: training: 0.033374 validation: 0.042746
09/16 01:07:34 PM: macro_avg: validation: 0.870007
09/16 01:07:34 PM: micro_avg: validation: 0.000000
09/16 01:07:34 PM: edges-ner-ontonotes_mcc: training: 0.884222 validation: 0.863106
09/16 01:07:34 PM: edges-ner-ontonotes_acc: training: 0.845102 validation: 0.824310
09/16 01:07:34 PM: edges-ner-ontonotes_precision: training: 0.912306 validation: 0.898586
09/16 01:07:34 PM: edges-ner-ontonotes_recall: training: 0.869187 validation: 0.843191
09/16 01:07:34 PM: edges-ner-ontonotes_f1: training: 0.890224 validation: 0.870007
09/16 01:07:34 PM: Global learning rate: 2.5e-05
09/16 01:07:34 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 01:07:38 PM: Update 29053: task edges-ner-ontonotes, batch 53 (29053): mcc: 0.8763, acc: 0.8307, precision: 0.9069, recall: 0.8596, f1: 0.8826, edges-ner-ontonotes_loss: 0.0357
09/16 01:07:49 PM: Update 29152: task edges-ner-ontonotes, batch 152 (29152): mcc: 0.8760, acc: 0.8310, precision: 0.9053, recall: 0.8607, f1: 0.8824, edges-ner-ontonotes_loss: 0.0341
09/16 01:08:03 PM: Update 29261: task edges-ner-ontonotes, batch 261 (29261): mcc: 0.8778, acc: 0.8327, precision: 0.9062, recall: 0.8632, f1: 0.8842, edges-ner-ontonotes_loss: 0.0336
09/16 01:08:13 PM: Update 29467: task edges-ner-ontonotes, batch 467 (29467): mcc: 0.8697, acc: 0.8254, precision: 0.9018, recall: 0.8524, f1: 0.8764, edges-ner-ontonotes_loss: 0.0383
09/16 01:08:25 PM: Update 29565: task edges-ner-ontonotes, batch 565 (29565): mcc: 0.8682, acc: 0.8239, precision: 0.9011, recall: 0.8502, f1: 0.8749, edges-ner-ontonotes_loss: 0.0390
09/16 01:08:35 PM: Update 29702: task edges-ner-ontonotes, batch 702 (29702): mcc: 0.8727, acc: 0.8306, precision: 0.9043, recall: 0.8555, f1: 0.8792, edges-ner-ontonotes_loss: 0.0376
09/16 01:08:45 PM: Update 29820: task edges-ner-ontonotes, batch 820 (29820): mcc: 0.8763, acc: 0.8354, precision: 0.9073, recall: 0.8593, f1: 0.8826, edges-ner-ontonotes_loss: 0.0366
09/16 01:08:55 PM: Update 29884: task edges-ner-ontonotes, batch 884 (29884): mcc: 0.8776, acc: 0.8371, precision: 0.9083, recall: 0.8608, f1: 0.8839, edges-ner-ontonotes_loss: 0.0362
09/16 01:09:05 PM: ***** Step 30000 / Validation 30 *****
09/16 01:09:05 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:09:05 PM: Validating...
09/16 01:09:05 PM: Evaluate: task edges-ner-ontonotes, batch 1 (157): mcc: 0.7639, acc: 0.7377, precision: 0.7833, recall: 0.7705, f1: 0.7769, edges-ner-ontonotes_loss: 0.0845
09/16 01:09:12 PM: Updating LR scheduler:
09/16 01:09:12 PM: 	Best result seen so far for macro_avg: 0.872
09/16 01:09:12 PM: 	# validation passes without improvement: 0
09/16 01:09:12 PM: edges-ner-ontonotes_loss: training: 0.036008 validation: 0.042196
09/16 01:09:12 PM: macro_avg: validation: 0.869192
09/16 01:09:12 PM: micro_avg: validation: 0.000000
09/16 01:09:12 PM: edges-ner-ontonotes_mcc: training: 0.878265 validation: 0.862486
09/16 01:09:12 PM: edges-ner-ontonotes_acc: training: 0.837923 validation: 0.826054
09/16 01:09:12 PM: edges-ner-ontonotes_precision: training: 0.909412 validation: 0.903197
09/16 01:09:12 PM: edges-ner-ontonotes_recall: training: 0.860906 validation: 0.837655
09/16 01:09:12 PM: edges-ner-ontonotes_f1: training: 0.884495 validation: 0.869192
09/16 01:09:12 PM: Global learning rate: 1.25e-05
09/16 01:09:12 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 01:09:15 PM: Update 30025: task edges-ner-ontonotes, batch 25 (30025): mcc: 0.8866, acc: 0.8537, precision: 0.9136, recall: 0.8724, f1: 0.8925, edges-ner-ontonotes_loss: 0.0353
09/16 01:09:25 PM: Update 30160: task edges-ner-ontonotes, batch 160 (30160): mcc: 0.8836, acc: 0.8460, precision: 0.9129, recall: 0.8673, f1: 0.8896, edges-ner-ontonotes_loss: 0.0336
09/16 01:09:35 PM: Update 30265: task edges-ner-ontonotes, batch 265 (30265): mcc: 0.8798, acc: 0.8400, precision: 0.9104, recall: 0.8628, f1: 0.8860, edges-ner-ontonotes_loss: 0.0344
09/16 01:09:45 PM: Update 30363: task edges-ner-ontonotes, batch 363 (30363): mcc: 0.8792, acc: 0.8384, precision: 0.9095, recall: 0.8626, f1: 0.8854, edges-ner-ontonotes_loss: 0.0341
09/16 01:09:55 PM: Update 30475: task edges-ner-ontonotes, batch 475 (30475): mcc: 0.8805, acc: 0.8389, precision: 0.9096, recall: 0.8648, f1: 0.8866, edges-ner-ontonotes_loss: 0.0338
09/16 01:10:05 PM: Update 30531: task edges-ner-ontonotes, batch 531 (30531): mcc: 0.8794, acc: 0.8375, precision: 0.9081, recall: 0.8644, f1: 0.8857, edges-ner-ontonotes_loss: 0.0339
09/16 01:10:15 PM: Update 30650: task edges-ner-ontonotes, batch 650 (30650): mcc: 0.8789, acc: 0.8360, precision: 0.9076, recall: 0.8638, f1: 0.8852, edges-ner-ontonotes_loss: 0.0339
09/16 01:10:25 PM: Update 30766: task edges-ner-ontonotes, batch 766 (30766): mcc: 0.8785, acc: 0.8349, precision: 0.9072, recall: 0.8635, f1: 0.8848, edges-ner-ontonotes_loss: 0.0338
09/16 01:10:35 PM: Update 30836: task edges-ner-ontonotes, batch 836 (30836): mcc: 0.8780, acc: 0.8343, precision: 0.9070, recall: 0.8629, f1: 0.8844, edges-ner-ontonotes_loss: 0.0340
09/16 01:10:45 PM: Update 30957: task edges-ner-ontonotes, batch 957 (30957): mcc: 0.8758, acc: 0.8317, precision: 0.9060, recall: 0.8597, f1: 0.8822, edges-ner-ontonotes_loss: 0.0354
09/16 01:10:48 PM: ***** Step 31000 / Validation 31 *****
09/16 01:10:48 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:10:48 PM: Validating...
09/16 01:10:55 PM: Updating LR scheduler:
09/16 01:10:55 PM: 	Best result seen so far for macro_avg: 0.872
09/16 01:10:55 PM: 	# validation passes without improvement: 1
09/16 01:10:55 PM: edges-ner-ontonotes_loss: training: 0.035484 validation: 0.042073
09/16 01:10:55 PM: macro_avg: validation: 0.869929
09/16 01:10:55 PM: micro_avg: validation: 0.000000
09/16 01:10:55 PM: edges-ner-ontonotes_mcc: training: 0.875619 validation: 0.863369
09/16 01:10:55 PM: edges-ner-ontonotes_acc: training: 0.831549 validation: 0.826585
09/16 01:10:55 PM: edges-ner-ontonotes_precision: training: 0.905978 validation: 0.906119
09/16 01:10:55 PM: edges-ner-ontonotes_recall: training: 0.859301 validation: 0.836518
09/16 01:10:55 PM: edges-ner-ontonotes_f1: training: 0.882023 validation: 0.869929
09/16 01:10:55 PM: Global learning rate: 1.25e-05
09/16 01:10:55 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 01:10:55 PM: Update 31010: task edges-ner-ontonotes, batch 10 (31010): mcc: 0.8529, acc: 0.7997, precision: 0.9076, recall: 0.8160, f1: 0.8593, edges-ner-ontonotes_loss: 0.0459
09/16 01:11:05 PM: Update 31112: task edges-ner-ontonotes, batch 112 (31112): mcc: 0.8586, acc: 0.8120, precision: 0.8963, recall: 0.8369, f1: 0.8656, edges-ner-ontonotes_loss: 0.0446
09/16 01:11:16 PM: Update 31131: task edges-ner-ontonotes, batch 131 (31131): mcc: 0.8601, acc: 0.8142, precision: 0.8972, recall: 0.8389, f1: 0.8671, edges-ner-ontonotes_loss: 0.0437
09/16 01:11:26 PM: Update 31271: task edges-ner-ontonotes, batch 271 (31271): mcc: 0.8794, acc: 0.8393, precision: 0.9110, recall: 0.8615, f1: 0.8855, edges-ner-ontonotes_loss: 0.0376
09/16 01:11:38 PM: Update 31434: task edges-ner-ontonotes, batch 434 (31434): mcc: 0.8876, acc: 0.8508, precision: 0.9168, recall: 0.8712, f1: 0.8934, edges-ner-ontonotes_loss: 0.0348
09/16 01:11:48 PM: Update 31614: task edges-ner-ontonotes, batch 614 (31614): mcc: 0.8858, acc: 0.8480, precision: 0.9169, recall: 0.8677, f1: 0.8916, edges-ner-ontonotes_loss: 0.0345
09/16 01:12:03 PM: Update 31747: task edges-ner-ontonotes, batch 747 (31747): mcc: 0.8858, acc: 0.8481, precision: 0.9165, recall: 0.8681, f1: 0.8916, edges-ner-ontonotes_loss: 0.0344
09/16 01:12:13 PM: Update 31851: task edges-ner-ontonotes, batch 851 (31851): mcc: 0.8833, acc: 0.8445, precision: 0.9143, recall: 0.8656, f1: 0.8893, edges-ner-ontonotes_loss: 0.0346
09/16 01:12:23 PM: Update 31974: task edges-ner-ontonotes, batch 974 (31974): mcc: 0.8833, acc: 0.8440, precision: 0.9137, recall: 0.8661, f1: 0.8892, edges-ner-ontonotes_loss: 0.0343
09/16 01:12:25 PM: ***** Step 32000 / Validation 32 *****
09/16 01:12:25 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:12:25 PM: Validating...
09/16 01:12:33 PM: Evaluate: task edges-ner-ontonotes, batch 104 (157): mcc: 0.8587, acc: 0.8185, precision: 0.8959, recall: 0.8376, f1: 0.8657, edges-ner-ontonotes_loss: 0.0460
09/16 01:12:36 PM: Updating LR scheduler:
09/16 01:12:36 PM: 	Best result seen so far for macro_avg: 0.872
09/16 01:12:36 PM: 	# validation passes without improvement: 2
09/16 01:12:36 PM: edges-ner-ontonotes_loss: training: 0.034386 validation: 0.042354
09/16 01:12:36 PM: macro_avg: validation: 0.869589
09/16 01:12:36 PM: micro_avg: validation: 0.000000
09/16 01:12:36 PM: edges-ner-ontonotes_mcc: training: 0.882833 validation: 0.862545
09/16 01:12:36 PM: edges-ner-ontonotes_acc: training: 0.843657 validation: 0.822869
09/16 01:12:36 PM: edges-ner-ontonotes_precision: training: 0.912950 validation: 0.895214
09/16 01:12:36 PM: edges-ner-ontonotes_recall: training: 0.865979 validation: 0.845390
09/16 01:12:36 PM: edges-ner-ontonotes_f1: training: 0.888845 validation: 0.869589
09/16 01:12:36 PM: Global learning rate: 1.25e-05
09/16 01:12:36 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 01:12:45 PM: Update 32060: task edges-ner-ontonotes, batch 60 (32060): mcc: 0.8830, acc: 0.8412, precision: 0.9112, recall: 0.8681, f1: 0.8891, edges-ner-ontonotes_loss: 0.0325
09/16 01:12:55 PM: Update 32181: task edges-ner-ontonotes, batch 181 (32181): mcc: 0.8782, acc: 0.8335, precision: 0.9070, recall: 0.8630, f1: 0.8845, edges-ner-ontonotes_loss: 0.0335
09/16 01:13:05 PM: Update 32292: task edges-ner-ontonotes, batch 292 (32292): mcc: 0.8783, acc: 0.8339, precision: 0.9064, recall: 0.8639, f1: 0.8846, edges-ner-ontonotes_loss: 0.0335
09/16 01:13:15 PM: Update 32374: task edges-ner-ontonotes, batch 374 (32374): mcc: 0.8775, acc: 0.8331, precision: 0.9053, recall: 0.8634, f1: 0.8839, edges-ner-ontonotes_loss: 0.0335
09/16 01:13:25 PM: Update 32489: task edges-ner-ontonotes, batch 489 (32489): mcc: 0.8726, acc: 0.8274, precision: 0.9025, recall: 0.8570, f1: 0.8792, edges-ner-ontonotes_loss: 0.0361
09/16 01:13:35 PM: Update 32628: task edges-ner-ontonotes, batch 628 (32628): mcc: 0.8704, acc: 0.8250, precision: 0.9018, recall: 0.8537, f1: 0.8771, edges-ner-ontonotes_loss: 0.0378
09/16 01:13:45 PM: Update 32704: task edges-ner-ontonotes, batch 704 (32704): mcc: 0.8707, acc: 0.8258, precision: 0.9023, recall: 0.8538, f1: 0.8774, edges-ner-ontonotes_loss: 0.0379
09/16 01:13:55 PM: Update 32856: task edges-ner-ontonotes, batch 856 (32856): mcc: 0.8749, acc: 0.8321, precision: 0.9055, recall: 0.8585, f1: 0.8814, edges-ner-ontonotes_loss: 0.0366
09/16 01:14:07 PM: Update 32990: task edges-ner-ontonotes, batch 990 (32990): mcc: 0.8776, acc: 0.8358, precision: 0.9079, recall: 0.8611, f1: 0.8839, edges-ner-ontonotes_loss: 0.0359
09/16 01:14:08 PM: ***** Step 33000 / Validation 33 *****
09/16 01:14:08 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:14:08 PM: Validating...
09/16 01:14:16 PM: Updating LR scheduler:
09/16 01:14:16 PM: 	Best result seen so far for macro_avg: 0.872
09/16 01:14:16 PM: 	# validation passes without improvement: 3
09/16 01:14:16 PM: edges-ner-ontonotes_loss: training: 0.035951 validation: 0.042470
09/16 01:14:16 PM: macro_avg: validation: 0.865572
09/16 01:14:16 PM: micro_avg: validation: 0.000000
09/16 01:14:16 PM: edges-ner-ontonotes_mcc: training: 0.877486 validation: 0.859059
09/16 01:14:16 PM: edges-ner-ontonotes_acc: training: 0.835805 validation: 0.818699
09/16 01:14:16 PM: edges-ner-ontonotes_precision: training: 0.907836 validation: 0.907232
09/16 01:14:16 PM: edges-ner-ontonotes_recall: training: 0.860979 validation: 0.827570
09/16 01:14:16 PM: edges-ner-ontonotes_f1: training: 0.883787 validation: 0.865572
09/16 01:14:16 PM: Global learning rate: 1.25e-05
09/16 01:14:16 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 01:14:17 PM: Update 33017: task edges-ner-ontonotes, batch 17 (33017): mcc: 0.8709, acc: 0.8294, precision: 0.9092, recall: 0.8474, f1: 0.8772, edges-ner-ontonotes_loss: 0.0379
09/16 01:14:27 PM: Update 33130: task edges-ner-ontonotes, batch 130 (33130): mcc: 0.8755, acc: 0.8330, precision: 0.9128, recall: 0.8525, f1: 0.8816, edges-ner-ontonotes_loss: 0.0360
09/16 01:14:38 PM: Update 33243: task edges-ner-ontonotes, batch 243 (33243): mcc: 0.8807, acc: 0.8409, precision: 0.9149, recall: 0.8602, f1: 0.8867, edges-ner-ontonotes_loss: 0.0347
09/16 01:14:48 PM: Update 33311: task edges-ner-ontonotes, batch 311 (33311): mcc: 0.8825, acc: 0.8434, precision: 0.9156, recall: 0.8628, f1: 0.8884, edges-ner-ontonotes_loss: 0.0343
09/16 01:14:58 PM: Update 33413: task edges-ner-ontonotes, batch 413 (33413): mcc: 0.8813, acc: 0.8411, precision: 0.9132, recall: 0.8628, f1: 0.8873, edges-ner-ontonotes_loss: 0.0341
09/16 01:15:08 PM: Update 33527: task edges-ner-ontonotes, batch 527 (33527): mcc: 0.8805, acc: 0.8401, precision: 0.9110, recall: 0.8636, f1: 0.8867, edges-ner-ontonotes_loss: 0.0341
09/16 01:15:18 PM: Update 33608: task edges-ner-ontonotes, batch 608 (33608): mcc: 0.8809, acc: 0.8401, precision: 0.9108, recall: 0.8644, f1: 0.8870, edges-ner-ontonotes_loss: 0.0340
09/16 01:15:28 PM: Update 33668: task edges-ner-ontonotes, batch 668 (33668): mcc: 0.8804, acc: 0.8391, precision: 0.9102, recall: 0.8641, f1: 0.8865, edges-ner-ontonotes_loss: 0.0341
09/16 01:15:38 PM: Update 33817: task edges-ner-ontonotes, batch 817 (33817): mcc: 0.8802, acc: 0.8379, precision: 0.9095, recall: 0.8644, f1: 0.8864, edges-ner-ontonotes_loss: 0.0339
09/16 01:15:49 PM: Update 33929: task edges-ner-ontonotes, batch 929 (33929): mcc: 0.8795, acc: 0.8373, precision: 0.9083, recall: 0.8643, f1: 0.8858, edges-ner-ontonotes_loss: 0.0339
09/16 01:15:56 PM: ***** Step 34000 / Validation 34 *****
09/16 01:15:56 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:15:56 PM: Validating...
09/16 01:15:59 PM: Evaluate: task edges-ner-ontonotes, batch 60 (157): mcc: 0.8740, acc: 0.8456, precision: 0.9071, recall: 0.8553, f1: 0.8804, edges-ner-ontonotes_loss: 0.0419
09/16 01:16:05 PM: Best result seen so far for edges-ner-ontonotes.
09/16 01:16:05 PM: Best result seen so far for macro.
09/16 01:16:05 PM: Updating LR scheduler:
09/16 01:16:05 PM: 	Best result seen so far for macro_avg: 0.872
09/16 01:16:05 PM: 	# validation passes without improvement: 0
09/16 01:16:05 PM: edges-ner-ontonotes_loss: training: 0.034754 validation: 0.041855
09/16 01:16:05 PM: macro_avg: validation: 0.872290
09/16 01:16:05 PM: micro_avg: validation: 0.000000
09/16 01:16:05 PM: edges-ner-ontonotes_mcc: training: 0.877537 validation: 0.865682
09/16 01:16:05 PM: edges-ner-ontonotes_acc: training: 0.834898 validation: 0.828329
09/16 01:16:05 PM: edges-ner-ontonotes_precision: training: 0.906930 validation: 0.904692
09/16 01:16:05 PM: edges-ner-ontonotes_recall: training: 0.861948 validation: 0.842129
09/16 01:16:05 PM: edges-ner-ontonotes_f1: training: 0.883867 validation: 0.872290
09/16 01:16:05 PM: Global learning rate: 1.25e-05
09/16 01:16:05 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 01:16:09 PM: Update 34074: task edges-ner-ontonotes, batch 74 (34074): mcc: 0.8562, acc: 0.8075, precision: 0.8957, recall: 0.8331, f1: 0.8633, edges-ner-ontonotes_loss: 0.0454
09/16 01:16:22 PM: Update 34233: task edges-ner-ontonotes, batch 233 (34233): mcc: 0.8625, acc: 0.8172, precision: 0.9000, recall: 0.8408, f1: 0.8694, edges-ner-ontonotes_loss: 0.0432
09/16 01:16:32 PM: Update 34399: task edges-ner-ontonotes, batch 399 (34399): mcc: 0.8752, acc: 0.8350, precision: 0.9081, recall: 0.8565, f1: 0.8815, edges-ner-ontonotes_loss: 0.0385
09/16 01:16:44 PM: Update 34546: task edges-ner-ontonotes, batch 546 (34546): mcc: 0.8818, acc: 0.8433, precision: 0.9128, recall: 0.8642, f1: 0.8878, edges-ner-ontonotes_loss: 0.0365
09/16 01:16:54 PM: Update 34728: task edges-ner-ontonotes, batch 728 (34728): mcc: 0.8820, acc: 0.8433, precision: 0.9137, recall: 0.8637, f1: 0.8880, edges-ner-ontonotes_loss: 0.0359
09/16 01:17:04 PM: Update 34838: task edges-ner-ontonotes, batch 838 (34838): mcc: 0.8821, acc: 0.8432, precision: 0.9136, recall: 0.8639, f1: 0.8881, edges-ner-ontonotes_loss: 0.0357
09/16 01:17:14 PM: Update 34924: task edges-ner-ontonotes, batch 924 (34924): mcc: 0.8815, acc: 0.8423, precision: 0.9131, recall: 0.8634, f1: 0.8875, edges-ner-ontonotes_loss: 0.0355
09/16 01:17:19 PM: ***** Step 35000 / Validation 35 *****
09/16 01:17:19 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:17:19 PM: Validating...
09/16 01:17:25 PM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.8723, acc: 0.8439, precision: 0.9019, recall: 0.8571, f1: 0.8789, edges-ner-ontonotes_loss: 0.0416
09/16 01:17:30 PM: Updating LR scheduler:
09/16 01:17:30 PM: 	Best result seen so far for macro_avg: 0.872
09/16 01:17:30 PM: 	# validation passes without improvement: 1
09/16 01:17:30 PM: edges-ner-ontonotes_loss: training: 0.035410 validation: 0.041982
09/16 01:17:30 PM: macro_avg: validation: 0.870320
09/16 01:17:30 PM: micro_avg: validation: 0.000000
09/16 01:17:30 PM: edges-ner-ontonotes_mcc: training: 0.881227 validation: 0.863400
09/16 01:17:30 PM: edges-ner-ontonotes_acc: training: 0.841737 validation: 0.827419
09/16 01:17:30 PM: edges-ner-ontonotes_precision: training: 0.912378 validation: 0.898048
09/16 01:17:30 PM: edges-ner-ontonotes_recall: training: 0.863548 validation: 0.844252
09/16 01:17:30 PM: edges-ner-ontonotes_f1: training: 0.887291 validation: 0.870320
09/16 01:17:30 PM: Global learning rate: 1.25e-05
09/16 01:17:30 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 01:17:35 PM: Update 35021: task edges-ner-ontonotes, batch 21 (35021): mcc: 0.8761, acc: 0.8319, precision: 0.9023, recall: 0.8637, f1: 0.8826, edges-ner-ontonotes_loss: 0.0321
09/16 01:17:49 PM: Update 35172: task edges-ner-ontonotes, batch 172 (35172): mcc: 0.8802, acc: 0.8364, precision: 0.9058, recall: 0.8680, f1: 0.8865, edges-ner-ontonotes_loss: 0.0335
09/16 01:17:59 PM: Update 35269: task edges-ner-ontonotes, batch 269 (35269): mcc: 0.8777, acc: 0.8322, precision: 0.9043, recall: 0.8649, f1: 0.8842, edges-ner-ontonotes_loss: 0.0336
09/16 01:18:09 PM: Update 35381: task edges-ner-ontonotes, batch 381 (35381): mcc: 0.8788, acc: 0.8343, precision: 0.9052, recall: 0.8659, f1: 0.8851, edges-ner-ontonotes_loss: 0.0334
09/16 01:18:21 PM: Update 35485: task edges-ner-ontonotes, batch 485 (35485): mcc: 0.8789, acc: 0.8345, precision: 0.9056, recall: 0.8658, f1: 0.8852, edges-ner-ontonotes_loss: 0.0335
09/16 01:18:31 PM: Update 35603: task edges-ner-ontonotes, batch 603 (35603): mcc: 0.8745, acc: 0.8299, precision: 0.9035, recall: 0.8596, f1: 0.8810, edges-ner-ontonotes_loss: 0.0357
09/16 01:18:41 PM: Update 35716: task edges-ner-ontonotes, batch 716 (35716): mcc: 0.8723, acc: 0.8277, precision: 0.9022, recall: 0.8568, f1: 0.8789, edges-ner-ontonotes_loss: 0.0368
09/16 01:18:54 PM: Update 35789: task edges-ner-ontonotes, batch 789 (35789): mcc: 0.8714, acc: 0.8265, precision: 0.9022, recall: 0.8552, f1: 0.8781, edges-ner-ontonotes_loss: 0.0373
09/16 01:19:04 PM: Update 35952: task edges-ner-ontonotes, batch 952 (35952): mcc: 0.8748, acc: 0.8316, precision: 0.9047, recall: 0.8589, f1: 0.8812, edges-ner-ontonotes_loss: 0.0365
09/16 01:19:07 PM: ***** Step 36000 / Validation 36 *****
09/16 01:19:07 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:19:07 PM: Validating...
09/16 01:19:14 PM: Evaluate: task edges-ner-ontonotes, batch 98 (157): mcc: 0.8659, acc: 0.8264, precision: 0.9116, recall: 0.8359, f1: 0.8721, edges-ner-ontonotes_loss: 0.0443
09/16 01:19:20 PM: Updating LR scheduler:
09/16 01:19:20 PM: 	Best result seen so far for macro_avg: 0.872
09/16 01:19:20 PM: 	# validation passes without improvement: 2
09/16 01:19:20 PM: edges-ner-ontonotes_loss: training: 0.036053 validation: 0.042498
09/16 01:19:20 PM: macro_avg: validation: 0.866154
09/16 01:19:20 PM: micro_avg: validation: 0.000000
09/16 01:19:20 PM: edges-ner-ontonotes_mcc: training: 0.875863 validation: 0.859631
09/16 01:19:20 PM: edges-ner-ontonotes_acc: training: 0.833055 validation: 0.820215
09/16 01:19:20 PM: edges-ner-ontonotes_precision: training: 0.905711 validation: 0.907054
09/16 01:19:20 PM: edges-ner-ontonotes_recall: training: 0.860013 validation: 0.828784
09/16 01:19:20 PM: edges-ner-ontonotes_f1: training: 0.882270 validation: 0.866154
09/16 01:19:20 PM: Global learning rate: 1.25e-05
09/16 01:19:20 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 01:19:24 PM: Update 36041: task edges-ner-ontonotes, batch 41 (36041): mcc: 0.8972, acc: 0.8686, precision: 0.9213, recall: 0.8846, f1: 0.9026, edges-ner-ontonotes_loss: 0.0318
09/16 01:19:35 PM: Update 36102: task edges-ner-ontonotes, batch 102 (36102): mcc: 0.8965, acc: 0.8653, precision: 0.9215, recall: 0.8833, f1: 0.9020, edges-ner-ontonotes_loss: 0.0313
09/16 01:19:45 PM: Update 36219: task edges-ner-ontonotes, batch 219 (36219): mcc: 0.8902, acc: 0.8542, precision: 0.9190, recall: 0.8739, f1: 0.8959, edges-ner-ontonotes_loss: 0.0327
09/16 01:19:55 PM: Update 36341: task edges-ner-ontonotes, batch 341 (36341): mcc: 0.8858, acc: 0.8490, precision: 0.9159, recall: 0.8687, f1: 0.8917, edges-ner-ontonotes_loss: 0.0334
09/16 01:20:09 PM: Update 36415: task edges-ner-ontonotes, batch 415 (36415): mcc: 0.8840, acc: 0.8462, precision: 0.9146, recall: 0.8665, f1: 0.8899, edges-ner-ontonotes_loss: 0.0337
09/16 01:20:19 PM: Update 36620: task edges-ner-ontonotes, batch 620 (36620): mcc: 0.8825, acc: 0.8429, precision: 0.9117, recall: 0.8666, f1: 0.8886, edges-ner-ontonotes_loss: 0.0334
09/16 01:20:29 PM: Update 36720: task edges-ner-ontonotes, batch 720 (36720): mcc: 0.8819, acc: 0.8418, precision: 0.9107, recall: 0.8664, f1: 0.8880, edges-ner-ontonotes_loss: 0.0336
09/16 01:20:39 PM: Update 36791: task edges-ner-ontonotes, batch 791 (36791): mcc: 0.8810, acc: 0.8405, precision: 0.9096, recall: 0.8658, f1: 0.8871, edges-ner-ontonotes_loss: 0.0336
09/16 01:20:49 PM: Update 36911: task edges-ner-ontonotes, batch 911 (36911): mcc: 0.8810, acc: 0.8399, precision: 0.9093, recall: 0.8662, f1: 0.8872, edges-ner-ontonotes_loss: 0.0337
09/16 01:20:56 PM: ***** Step 37000 / Validation 37 *****
09/16 01:20:56 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:20:56 PM: Validating...
09/16 01:20:59 PM: Evaluate: task edges-ner-ontonotes, batch 52 (157): mcc: 0.8584, acc: 0.8295, precision: 0.8886, recall: 0.8440, f1: 0.8657, edges-ner-ontonotes_loss: 0.0454
09/16 01:21:08 PM: Updating LR scheduler:
09/16 01:21:08 PM: 	Best result seen so far for macro_avg: 0.872
09/16 01:21:08 PM: 	# validation passes without improvement: 3
09/16 01:21:08 PM: edges-ner-ontonotes_loss: training: 0.033604 validation: 0.042473
09/16 01:21:08 PM: macro_avg: validation: 0.870980
09/16 01:21:08 PM: micro_avg: validation: 0.000000
09/16 01:21:08 PM: edges-ner-ontonotes_mcc: training: 0.881178 validation: 0.864136
09/16 01:21:08 PM: edges-ner-ontonotes_acc: training: 0.839855 validation: 0.823400
09/16 01:21:08 PM: edges-ner-ontonotes_precision: training: 0.909407 validation: 0.899628
09/16 01:21:08 PM: edges-ner-ontonotes_recall: training: 0.866329 validation: 0.844101
09/16 01:21:08 PM: edges-ner-ontonotes_f1: training: 0.887345 validation: 0.870980
09/16 01:21:08 PM: Global learning rate: 1.25e-05
09/16 01:21:08 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 01:21:09 PM: Update 37008: task edges-ner-ontonotes, batch 8 (37008): mcc: 0.8589, acc: 0.8122, precision: 0.8817, recall: 0.8517, f1: 0.8664, edges-ner-ontonotes_loss: 0.0380
09/16 01:21:19 PM: Update 37071: task edges-ner-ontonotes, batch 71 (37071): mcc: 0.8647, acc: 0.8197, precision: 0.8967, recall: 0.8479, f1: 0.8716, edges-ner-ontonotes_loss: 0.0390
09/16 01:21:29 PM: Update 37237: task edges-ner-ontonotes, batch 237 (37237): mcc: 0.8598, acc: 0.8126, precision: 0.8959, recall: 0.8397, f1: 0.8669, edges-ner-ontonotes_loss: 0.0420
09/16 01:21:39 PM: Update 37356: task edges-ner-ontonotes, batch 356 (37356): mcc: 0.8615, acc: 0.8150, precision: 0.8974, recall: 0.8414, f1: 0.8685, edges-ner-ontonotes_loss: 0.0422
09/16 01:21:49 PM: Update 37528: task edges-ner-ontonotes, batch 528 (37528): mcc: 0.8731, acc: 0.8309, precision: 0.9056, recall: 0.8550, f1: 0.8796, edges-ner-ontonotes_loss: 0.0385
09/16 01:22:00 PM: Update 37658: task edges-ner-ontonotes, batch 658 (37658): mcc: 0.8770, acc: 0.8363, precision: 0.9080, recall: 0.8599, f1: 0.8833, edges-ner-ontonotes_loss: 0.0372
09/16 01:22:10 PM: Update 37835: task edges-ner-ontonotes, batch 835 (37835): mcc: 0.8781, acc: 0.8376, precision: 0.9100, recall: 0.8600, f1: 0.8843, edges-ner-ontonotes_loss: 0.0365
09/16 01:22:20 PM: Update 37949: task edges-ner-ontonotes, batch 949 (37949): mcc: 0.8789, acc: 0.8387, precision: 0.9110, recall: 0.8606, f1: 0.8851, edges-ner-ontonotes_loss: 0.0362
09/16 01:22:30 PM: Update 37984: task edges-ner-ontonotes, batch 984 (37984): mcc: 0.8787, acc: 0.8385, precision: 0.9107, recall: 0.8605, f1: 0.8849, edges-ner-ontonotes_loss: 0.0362
09/16 01:22:32 PM: ***** Step 38000 / Validation 38 *****
09/16 01:22:32 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:22:32 PM: Validating...
09/16 01:22:40 PM: Evaluate: task edges-ner-ontonotes, batch 106 (157): mcc: 0.8629, acc: 0.8267, precision: 0.9012, recall: 0.8403, f1: 0.8697, edges-ner-ontonotes_loss: 0.0448
09/16 01:22:44 PM: Updating LR scheduler:
09/16 01:22:44 PM: 	Best result seen so far for macro_avg: 0.872
09/16 01:22:44 PM: 	# validation passes without improvement: 0
09/16 01:22:44 PM: edges-ner-ontonotes_loss: training: 0.036180 validation: 0.041883
09/16 01:22:44 PM: macro_avg: validation: 0.870793
09/16 01:22:44 PM: micro_avg: validation: 0.000000
09/16 01:22:44 PM: edges-ner-ontonotes_mcc: training: 0.878551 validation: 0.864048
09/16 01:22:44 PM: edges-ner-ontonotes_acc: training: 0.838347 validation: 0.828556
09/16 01:22:44 PM: edges-ner-ontonotes_precision: training: 0.910371 validation: 0.901999
09/16 01:22:44 PM: edges-ner-ontonotes_recall: training: 0.860513 validation: 0.841674
09/16 01:22:44 PM: edges-ner-ontonotes_f1: training: 0.884740 validation: 0.870793
09/16 01:22:44 PM: Global learning rate: 6.25e-06
09/16 01:22:44 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 01:22:50 PM: Update 38076: task edges-ner-ontonotes, batch 76 (38076): mcc: 0.8715, acc: 0.8288, precision: 0.9003, recall: 0.8572, f1: 0.8782, edges-ner-ontonotes_loss: 0.0350
09/16 01:23:00 PM: Update 38205: task edges-ner-ontonotes, batch 205 (38205): mcc: 0.8773, acc: 0.8355, precision: 0.9047, recall: 0.8637, f1: 0.8837, edges-ner-ontonotes_loss: 0.0337
09/16 01:23:13 PM: Update 38284: task edges-ner-ontonotes, batch 284 (38284): mcc: 0.8778, acc: 0.8360, precision: 0.9047, recall: 0.8646, f1: 0.8842, edges-ner-ontonotes_loss: 0.0337
09/16 01:23:23 PM: Update 38385: task edges-ner-ontonotes, batch 385 (38385): mcc: 0.8776, acc: 0.8351, precision: 0.9046, recall: 0.8644, f1: 0.8840, edges-ner-ontonotes_loss: 0.0337
09/16 01:23:33 PM: Update 38520: task edges-ner-ontonotes, batch 520 (38520): mcc: 0.8775, acc: 0.8345, precision: 0.9043, recall: 0.8645, f1: 0.8840, edges-ner-ontonotes_loss: 0.0337
09/16 01:23:44 PM: Update 38597: task edges-ner-ontonotes, batch 597 (38597): mcc: 0.8782, acc: 0.8350, precision: 0.9053, recall: 0.8649, f1: 0.8846, edges-ner-ontonotes_loss: 0.0337
09/16 01:23:54 PM: Update 38742: task edges-ner-ontonotes, batch 742 (38742): mcc: 0.8736, acc: 0.8297, precision: 0.9023, recall: 0.8591, f1: 0.8801, edges-ner-ontonotes_loss: 0.0361
09/16 01:24:04 PM: Update 38883: task edges-ner-ontonotes, batch 883 (38883): mcc: 0.8722, acc: 0.8283, precision: 0.9018, recall: 0.8570, f1: 0.8788, edges-ner-ontonotes_loss: 0.0369
09/16 01:24:14 PM: Update 38951: task edges-ner-ontonotes, batch 951 (38951): mcc: 0.8731, acc: 0.8296, precision: 0.9024, recall: 0.8580, f1: 0.8796, edges-ner-ontonotes_loss: 0.0367
09/16 01:24:18 PM: ***** Step 39000 / Validation 39 *****
09/16 01:24:18 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:24:18 PM: Validating...
09/16 01:24:25 PM: Evaluate: task edges-ner-ontonotes, batch 92 (157): mcc: 0.8689, acc: 0.8303, precision: 0.9130, recall: 0.8403, f1: 0.8751, edges-ner-ontonotes_loss: 0.0442
09/16 01:24:28 PM: Updating LR scheduler:
09/16 01:24:28 PM: 	Best result seen so far for macro_avg: 0.872
09/16 01:24:28 PM: 	# validation passes without improvement: 1
09/16 01:24:28 PM: edges-ner-ontonotes_loss: training: 0.036638 validation: 0.042013
09/16 01:24:28 PM: macro_avg: validation: 0.868824
09/16 01:24:28 PM: micro_avg: validation: 0.000000
09/16 01:24:28 PM: edges-ner-ontonotes_mcc: training: 0.873726 validation: 0.862245
09/16 01:24:28 PM: edges-ner-ontonotes_acc: training: 0.830591 validation: 0.823779
09/16 01:24:28 PM: edges-ner-ontonotes_precision: training: 0.903122 validation: 0.905859
09/16 01:24:28 PM: edges-ner-ontonotes_recall: training: 0.858541 validation: 0.834698
09/16 01:24:28 PM: edges-ner-ontonotes_f1: training: 0.880268 validation: 0.868824
09/16 01:24:28 PM: Global learning rate: 6.25e-06
09/16 01:24:28 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 01:24:35 PM: Update 39117: task edges-ner-ontonotes, batch 117 (39117): mcc: 0.9022, acc: 0.8701, precision: 0.9254, recall: 0.8900, f1: 0.9074, edges-ner-ontonotes_loss: 0.0302
09/16 01:24:45 PM: Update 39220: task edges-ner-ontonotes, batch 220 (39220): mcc: 0.8993, acc: 0.8668, precision: 0.9234, recall: 0.8864, f1: 0.9046, edges-ner-ontonotes_loss: 0.0304
09/16 01:24:55 PM: Update 39355: task edges-ner-ontonotes, batch 355 (39355): mcc: 0.8915, acc: 0.8559, precision: 0.9199, recall: 0.8753, f1: 0.8970, edges-ner-ontonotes_loss: 0.0320
09/16 01:25:05 PM: Update 39482: task edges-ner-ontonotes, batch 482 (39482): mcc: 0.8887, acc: 0.8516, precision: 0.9187, recall: 0.8714, f1: 0.8944, edges-ner-ontonotes_loss: 0.0326
09/16 01:25:15 PM: Update 39591: task edges-ner-ontonotes, batch 591 (39591): mcc: 0.8873, acc: 0.8493, precision: 0.9181, recall: 0.8692, f1: 0.8930, edges-ner-ontonotes_loss: 0.0327
09/16 01:25:25 PM: Update 39719: task edges-ner-ontonotes, batch 719 (39719): mcc: 0.8852, acc: 0.8464, precision: 0.9154, recall: 0.8680, f1: 0.8910, edges-ner-ontonotes_loss: 0.0329
09/16 01:25:35 PM: Update 39838: task edges-ner-ontonotes, batch 838 (39838): mcc: 0.8842, acc: 0.8448, precision: 0.9141, recall: 0.8674, f1: 0.8901, edges-ner-ontonotes_loss: 0.0330
09/16 01:25:45 PM: Update 39886: task edges-ner-ontonotes, batch 886 (39886): mcc: 0.8835, acc: 0.8438, precision: 0.9135, recall: 0.8667, f1: 0.8895, edges-ner-ontonotes_loss: 0.0330
09/16 01:25:55 PM: Update 39982: task edges-ner-ontonotes, batch 982 (39982): mcc: 0.8833, acc: 0.8432, precision: 0.9126, recall: 0.8671, f1: 0.8893, edges-ner-ontonotes_loss: 0.0331
09/16 01:25:57 PM: ***** Step 40000 / Validation 40 *****
09/16 01:25:58 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:25:58 PM: Validating...
09/16 01:26:05 PM: Evaluate: task edges-ner-ontonotes, batch 121 (157): mcc: 0.8552, acc: 0.8155, precision: 0.8899, recall: 0.8369, f1: 0.8626, edges-ner-ontonotes_loss: 0.0450
09/16 01:26:08 PM: Updating LR scheduler:
09/16 01:26:08 PM: 	Best result seen so far for macro_avg: 0.872
09/16 01:26:08 PM: 	# validation passes without improvement: 2
09/16 01:26:08 PM: edges-ner-ontonotes_loss: training: 0.033122 validation: 0.042170
09/16 01:26:08 PM: macro_avg: validation: 0.871474
09/16 01:26:08 PM: micro_avg: validation: 0.000000
09/16 01:26:08 PM: edges-ner-ontonotes_mcc: training: 0.882960 validation: 0.864603
09/16 01:26:08 PM: edges-ner-ontonotes_acc: training: 0.842551 validation: 0.826130
09/16 01:26:08 PM: edges-ner-ontonotes_precision: training: 0.912383 validation: 0.898791
09/16 01:26:08 PM: edges-ner-ontonotes_recall: training: 0.866763 validation: 0.845769
09/16 01:26:08 PM: edges-ner-ontonotes_f1: training: 0.888988 validation: 0.871474
09/16 01:26:08 PM: Global learning rate: 6.25e-06
09/16 01:26:08 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 01:26:15 PM: Update 40089: task edges-ner-ontonotes, batch 89 (40089): mcc: 0.8788, acc: 0.8364, precision: 0.9061, recall: 0.8652, f1: 0.8851, edges-ner-ontonotes_loss: 0.0330
09/16 01:26:25 PM: Update 40170: task edges-ner-ontonotes, batch 170 (40170): mcc: 0.8716, acc: 0.8284, precision: 0.9003, recall: 0.8573, f1: 0.8783, edges-ner-ontonotes_loss: 0.0358
09/16 01:26:35 PM: Update 40307: task edges-ner-ontonotes, batch 307 (40307): mcc: 0.8659, acc: 0.8219, precision: 0.8970, recall: 0.8499, f1: 0.8728, edges-ner-ontonotes_loss: 0.0394
09/16 01:26:46 PM: Update 40457: task edges-ner-ontonotes, batch 457 (40457): mcc: 0.8639, acc: 0.8193, precision: 0.8973, recall: 0.8458, f1: 0.8708, edges-ner-ontonotes_loss: 0.0406
09/16 01:26:56 PM: Update 40664: task edges-ner-ontonotes, batch 664 (40664): mcc: 0.8729, acc: 0.8313, precision: 0.9035, recall: 0.8566, f1: 0.8794, edges-ner-ontonotes_loss: 0.0378
09/16 01:27:07 PM: Update 40770: task edges-ner-ontonotes, batch 770 (40770): mcc: 0.8760, acc: 0.8356, precision: 0.9058, recall: 0.8602, f1: 0.8824, edges-ner-ontonotes_loss: 0.0368
09/16 01:27:17 PM: Update 40958: task edges-ner-ontonotes, batch 958 (40958): mcc: 0.8778, acc: 0.8378, precision: 0.9082, recall: 0.8612, f1: 0.8841, edges-ner-ontonotes_loss: 0.0361
09/16 01:27:21 PM: ***** Step 41000 / Validation 41 *****
09/16 01:27:21 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:27:21 PM: Validating...
09/16 01:27:27 PM: Evaluate: task edges-ner-ontonotes, batch 78 (157): mcc: 0.8721, acc: 0.8364, precision: 0.9100, recall: 0.8489, f1: 0.8784, edges-ner-ontonotes_loss: 0.0436
09/16 01:27:35 PM: Updating LR scheduler:
09/16 01:27:35 PM: 	Best result seen so far for macro_avg: 0.872
09/16 01:27:35 PM: 	# validation passes without improvement: 3
09/16 01:27:35 PM: edges-ner-ontonotes_loss: training: 0.036119 validation: 0.041908
09/16 01:27:35 PM: macro_avg: validation: 0.871119
09/16 01:27:35 PM: micro_avg: validation: 0.000000
09/16 01:27:35 PM: edges-ner-ontonotes_mcc: training: 0.877598 validation: 0.864538
09/16 01:27:35 PM: edges-ner-ontonotes_acc: training: 0.837503 validation: 0.827798
09/16 01:27:35 PM: edges-ner-ontonotes_precision: training: 0.908264 validation: 0.905506
09/16 01:27:35 PM: edges-ner-ontonotes_recall: training: 0.860775 validation: 0.839248
09/16 01:27:35 PM: edges-ner-ontonotes_f1: training: 0.883882 validation: 0.871119
09/16 01:27:35 PM: Global learning rate: 6.25e-06
09/16 01:27:35 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 01:27:37 PM: Update 41041: task edges-ner-ontonotes, batch 41 (41041): mcc: 0.8825, acc: 0.8437, precision: 0.9143, recall: 0.8640, f1: 0.8884, edges-ner-ontonotes_loss: 0.0335
09/16 01:27:47 PM: Update 41100: task edges-ner-ontonotes, batch 100 (41100): mcc: 0.8781, acc: 0.8367, precision: 0.9098, recall: 0.8603, f1: 0.8843, edges-ner-ontonotes_loss: 0.0347
09/16 01:27:57 PM: Update 41204: task edges-ner-ontonotes, batch 204 (41204): mcc: 0.8764, acc: 0.8341, precision: 0.9090, recall: 0.8577, f1: 0.8826, edges-ner-ontonotes_loss: 0.0344
09/16 01:28:07 PM: Update 41319: task edges-ner-ontonotes, batch 319 (41319): mcc: 0.8774, acc: 0.8347, precision: 0.9092, recall: 0.8595, f1: 0.8836, edges-ner-ontonotes_loss: 0.0342
09/16 01:28:19 PM: Update 41396: task edges-ner-ontonotes, batch 396 (41396): mcc: 0.8781, acc: 0.8356, precision: 0.9089, recall: 0.8611, f1: 0.8844, edges-ner-ontonotes_loss: 0.0340
09/16 01:28:29 PM: Update 41510: task edges-ner-ontonotes, batch 510 (41510): mcc: 0.8784, acc: 0.8358, precision: 0.9082, recall: 0.8622, f1: 0.8846, edges-ner-ontonotes_loss: 0.0338
09/16 01:28:39 PM: Update 41629: task edges-ner-ontonotes, batch 629 (41629): mcc: 0.8776, acc: 0.8350, precision: 0.9074, recall: 0.8617, f1: 0.8839, edges-ner-ontonotes_loss: 0.0339
09/16 01:28:52 PM: Update 41709: task edges-ner-ontonotes, batch 709 (41709): mcc: 0.8776, acc: 0.8345, precision: 0.9070, recall: 0.8620, f1: 0.8839, edges-ner-ontonotes_loss: 0.0338
09/16 01:29:02 PM: Update 41837: task edges-ner-ontonotes, batch 837 (41837): mcc: 0.8745, acc: 0.8311, precision: 0.9048, recall: 0.8584, f1: 0.8810, edges-ner-ontonotes_loss: 0.0355
09/16 01:29:12 PM: Update 41952: task edges-ner-ontonotes, batch 952 (41952): mcc: 0.8733, acc: 0.8296, precision: 0.9041, recall: 0.8568, f1: 0.8798, edges-ner-ontonotes_loss: 0.0364
09/16 01:29:15 PM: ***** Step 42000 / Validation 42 *****
09/16 01:29:15 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:29:15 PM: Validating...
09/16 01:29:22 PM: Evaluate: task edges-ner-ontonotes, batch 96 (157): mcc: 0.8708, acc: 0.8349, precision: 0.9114, recall: 0.8452, f1: 0.8770, edges-ner-ontonotes_loss: 0.0443
09/16 01:29:25 PM: Updating LR scheduler:
09/16 01:29:25 PM: 	Best result seen so far for macro_avg: 0.872
09/16 01:29:25 PM: 	# validation passes without improvement: 0
09/16 01:29:25 PM: edges-ner-ontonotes_loss: training: 0.036700 validation: 0.041857
09/16 01:29:25 PM: macro_avg: validation: 0.871538
09/16 01:29:25 PM: micro_avg: validation: 0.000000
09/16 01:29:25 PM: edges-ner-ontonotes_mcc: training: 0.873025 validation: 0.865029
09/16 01:29:25 PM: edges-ner-ontonotes_acc: training: 0.829335 validation: 0.828556
09/16 01:29:25 PM: edges-ner-ontonotes_precision: training: 0.904104 validation: 0.906944
09/16 01:29:25 PM: edges-ner-ontonotes_recall: training: 0.856289 validation: 0.838793
09/16 01:29:25 PM: edges-ner-ontonotes_f1: training: 0.879547 validation: 0.871538
09/16 01:29:25 PM: Global learning rate: 3.125e-06
09/16 01:29:25 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 01:29:32 PM: Update 42027: task edges-ner-ontonotes, batch 27 (42027): mcc: 0.8727, acc: 0.8284, precision: 0.9065, recall: 0.8534, f1: 0.8791, edges-ner-ontonotes_loss: 0.0394
09/16 01:29:42 PM: Update 42224: task edges-ner-ontonotes, batch 224 (42224): mcc: 0.8935, acc: 0.8613, precision: 0.9194, recall: 0.8795, f1: 0.8990, edges-ner-ontonotes_loss: 0.0328
09/16 01:29:55 PM: Update 42326: task edges-ner-ontonotes, batch 326 (42326): mcc: 0.8950, acc: 0.8627, precision: 0.9200, recall: 0.8818, f1: 0.9005, edges-ner-ontonotes_loss: 0.0320
09/16 01:30:05 PM: Update 42451: task edges-ner-ontonotes, batch 451 (42451): mcc: 0.8916, acc: 0.8568, precision: 0.9191, recall: 0.8763, f1: 0.8972, edges-ner-ontonotes_loss: 0.0325
09/16 01:30:15 PM: Update 42593: task edges-ner-ontonotes, batch 593 (42593): mcc: 0.8885, acc: 0.8525, precision: 0.9174, recall: 0.8723, f1: 0.8942, edges-ner-ontonotes_loss: 0.0329
09/16 01:30:25 PM: Update 42659: task edges-ner-ontonotes, batch 659 (42659): mcc: 0.8873, acc: 0.8504, precision: 0.9170, recall: 0.8704, f1: 0.8931, edges-ner-ontonotes_loss: 0.0331
09/16 01:30:35 PM: Update 42763: task edges-ner-ontonotes, batch 763 (42763): mcc: 0.8865, acc: 0.8490, precision: 0.9165, recall: 0.8693, f1: 0.8923, edges-ner-ontonotes_loss: 0.0330
09/16 01:30:45 PM: Update 42871: task edges-ner-ontonotes, batch 871 (42871): mcc: 0.8848, acc: 0.8463, precision: 0.9152, recall: 0.8675, f1: 0.8907, edges-ner-ontonotes_loss: 0.0332
09/16 01:30:55 PM: Update 42993: task edges-ner-ontonotes, batch 993 (42993): mcc: 0.8838, acc: 0.8443, precision: 0.9142, recall: 0.8665, f1: 0.8897, edges-ner-ontonotes_loss: 0.0333
09/16 01:30:55 PM: ***** Step 43000 / Validation 43 *****
09/16 01:30:55 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:30:55 PM: Validating...
09/16 01:31:03 PM: Updating LR scheduler:
09/16 01:31:03 PM: 	Best result seen so far for macro_avg: 0.872
09/16 01:31:03 PM: 	# validation passes without improvement: 1
09/16 01:31:03 PM: edges-ner-ontonotes_loss: training: 0.033314 validation: 0.041768
09/16 01:31:03 PM: macro_avg: validation: 0.871287
09/16 01:31:03 PM: micro_avg: validation: 0.000000
09/16 01:31:03 PM: edges-ner-ontonotes_mcc: training: 0.883719 validation: 0.864474
09/16 01:31:03 PM: edges-ner-ontonotes_acc: training: 0.844293 validation: 0.829618
09/16 01:31:03 PM: edges-ner-ontonotes_precision: training: 0.914201 validation: 0.900283
09/16 01:31:03 PM: edges-ner-ontonotes_recall: training: 0.866420 validation: 0.844101
09/16 01:31:03 PM: edges-ner-ontonotes_f1: training: 0.889669 validation: 0.871287
09/16 01:31:03 PM: Global learning rate: 3.125e-06
09/16 01:31:03 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 01:31:05 PM: Update 43047: task edges-ner-ontonotes, batch 47 (43047): mcc: 0.8772, acc: 0.8333, precision: 0.9017, recall: 0.8664, f1: 0.8837, edges-ner-ontonotes_loss: 0.0339
09/16 01:31:15 PM: Update 43182: task edges-ner-ontonotes, batch 182 (43182): mcc: 0.8769, acc: 0.8323, precision: 0.9043, recall: 0.8634, f1: 0.8834, edges-ner-ontonotes_loss: 0.0341
09/16 01:31:27 PM: Update 43265: task edges-ner-ontonotes, batch 265 (43265): mcc: 0.8777, acc: 0.8331, precision: 0.9048, recall: 0.8644, f1: 0.8841, edges-ner-ontonotes_loss: 0.0339
09/16 01:31:37 PM: Update 43459: task edges-ner-ontonotes, batch 459 (43459): mcc: 0.8705, acc: 0.8266, precision: 0.9001, recall: 0.8554, f1: 0.8772, edges-ner-ontonotes_loss: 0.0379
09/16 01:31:48 PM: Update 43569: task edges-ner-ontonotes, batch 569 (43569): mcc: 0.8676, acc: 0.8231, precision: 0.8989, recall: 0.8513, f1: 0.8744, edges-ner-ontonotes_loss: 0.0392
09/16 01:31:58 PM: Update 43681: task edges-ner-ontonotes, batch 681 (43681): mcc: 0.8716, acc: 0.8290, precision: 0.9017, recall: 0.8560, f1: 0.8783, edges-ner-ontonotes_loss: 0.0380
09/16 01:32:08 PM: Update 43828: task edges-ner-ontonotes, batch 828 (43828): mcc: 0.8758, acc: 0.8349, precision: 0.9045, recall: 0.8610, f1: 0.8822, edges-ner-ontonotes_loss: 0.0368
09/16 01:32:19 PM: Update 43912: task edges-ner-ontonotes, batch 912 (43912): mcc: 0.8770, acc: 0.8367, precision: 0.9058, recall: 0.8621, f1: 0.8834, edges-ner-ontonotes_loss: 0.0365
09/16 01:32:26 PM: ***** Step 44000 / Validation 44 *****
09/16 01:32:26 PM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 01:32:26 PM: Validating...
09/16 01:32:29 PM: Evaluate: task edges-ner-ontonotes, batch 35 (157): mcc: 0.8563, acc: 0.8250, precision: 0.8879, recall: 0.8409, f1: 0.8637, edges-ner-ontonotes_loss: 0.0469
09/16 01:32:36 PM: Updating LR scheduler:
09/16 01:32:36 PM: 	Best result seen so far for macro_avg: 0.872
09/16 01:32:36 PM: 	# validation passes without improvement: 2
09/16 01:32:36 PM: Ran out of early stopping patience. Stopping training.
09/16 01:32:36 PM: edges-ner-ontonotes_loss: training: 0.036519 validation: 0.041844
09/16 01:32:36 PM: macro_avg: validation: 0.870922
09/16 01:32:36 PM: micro_avg: validation: 0.000000
09/16 01:32:36 PM: edges-ner-ontonotes_mcc: training: 0.876443 validation: 0.864387
09/16 01:32:36 PM: edges-ner-ontonotes_acc: training: 0.835882 validation: 0.827571
09/16 01:32:36 PM: edges-ner-ontonotes_precision: training: 0.905778 validation: 0.906496
09/16 01:32:36 PM: edges-ner-ontonotes_recall: training: 0.861027 validation: 0.838035
09/16 01:32:36 PM: edges-ner-ontonotes_f1: training: 0.882836 validation: 0.870922
09/16 01:32:36 PM: Global learning rate: 3.125e-06
09/16 01:32:36 PM: Saving checkpoints to: ./experiments/ner-ontonotes-sts-only/run
09/16 01:32:36 PM: Stopped training after 44 validation checks
09/16 01:32:36 PM: Trained edges-ner-ontonotes for 44000 batches or 28.314 epochs
09/16 01:32:36 PM: ***** VALIDATION RESULTS *****
09/16 01:32:36 PM: edges-ner-ontonotes_f1 (for best val pass 34): edges-ner-ontonotes_loss: 0.04186, macro_avg: 0.87229, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.86568, edges-ner-ontonotes_acc: 0.82833, edges-ner-ontonotes_precision: 0.90469, edges-ner-ontonotes_recall: 0.84213, edges-ner-ontonotes_f1: 0.87229
09/16 01:32:36 PM: micro_avg (for best val pass 1): edges-ner-ontonotes_loss: 0.05829, macro_avg: 0.82105, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.81362, edges-ner-ontonotes_acc: 0.74484, edges-ner-ontonotes_precision: 0.88403, edges-ner-ontonotes_recall: 0.76645, edges-ner-ontonotes_f1: 0.82105
09/16 01:32:36 PM: macro_avg (for best val pass 34): edges-ner-ontonotes_loss: 0.04186, macro_avg: 0.87229, micro_avg: 0.00000, edges-ner-ontonotes_mcc: 0.86568, edges-ner-ontonotes_acc: 0.82833, edges-ner-ontonotes_precision: 0.90469, edges-ner-ontonotes_recall: 0.84213, edges-ner-ontonotes_f1: 0.87229
09/16 01:32:36 PM: Evaluating...
09/16 01:32:36 PM: Loaded model state from ./experiments/ner-ontonotes-sts-only/run/edges-ner-ontonotes/model_state_target_train_val_34.best.th
09/16 01:32:36 PM: Evaluating on: edges-ner-ontonotes, split: val
09/16 01:32:51 PM: Task 'edges-ner-ontonotes': sorting predictions by 'idx'
09/16 01:32:51 PM: Finished evaluating on: edges-ner-ontonotes
09/16 01:32:51 PM: Task 'edges-ner-ontonotes': joining predictions with input split 'val'
09/16 01:32:52 PM: Task 'edges-ner-ontonotes': Wrote predictions to ./experiments/ner-ontonotes-sts-only/run
09/16 01:32:52 PM: Wrote all preds for split 'val' to ./experiments/ner-ontonotes-sts-only/run
09/16 01:32:52 PM: Evaluating on: edges-ner-ontonotes, split: test
09/16 01:33:06 PM: Task 'edges-ner-ontonotes': sorting predictions by 'idx'
09/16 01:33:06 PM: Finished evaluating on: edges-ner-ontonotes
09/16 01:33:06 PM: Task 'edges-ner-ontonotes': joining predictions with input split 'test'
09/16 01:33:08 PM: Task 'edges-ner-ontonotes': Wrote predictions to ./experiments/ner-ontonotes-sts-only/run
09/16 01:33:08 PM: Wrote all preds for split 'test' to ./experiments/ner-ontonotes-sts-only/run
09/16 01:33:08 PM: Writing results for split 'val' to ./experiments/ner-ontonotes-sts-only/results.tsv
09/16 01:33:08 PM: micro_avg: 0.000, macro_avg: 0.874, edges-ner-ontonotes_mcc: 0.868, edges-ner-ontonotes_acc: 0.831, edges-ner-ontonotes_precision: 0.906, edges-ner-ontonotes_recall: 0.845, edges-ner-ontonotes_f1: 0.874
09/16 01:33:08 PM: Done!
09/16 01:33:08 PM: Fatal error in main():
Traceback (most recent call last):
  File "main.py", line 16, in <module>
    main(sys.argv[1:])
  File "/srv/home/ericwallace/jiant/jiant/__main__.py", line 610, in main
    exit("Done exited")
  File "/home/ericwallace/miniconda3/envs/jiant/lib/python3.6/_sitebuiltins.py", line 26, in __call__
    raise SystemExit(code)
SystemExit: Done exited
