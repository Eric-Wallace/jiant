09/07 09:16:38 PM: Git branch: master
09/07 09:16:38 PM: Git SHA: 117419dc9116809c203f878fb83f7aaddafbbcb0
09/07 09:16:39 PM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "/scratch0/new/jiant/experiments/srl-ontonotes-None-only/",
  "exp_name": "experiments/srl-ontonotes-None-only",
  "input_module": "bert-base-uncased",
  "local_log_path": "/scratch0/new/jiant/experiments/srl-ontonotes-None-only/run/log.log",
  "lr_patience": 5,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 20,
  "pretrain_tasks": "",
  "pretrained_dir": "None",
  "pytorch_transformers_output_mode": "only",
  "remote_log_name": "experiments/srl-ontonotes-None-only__run",
  "run_dir": "/scratch0/new/jiant/experiments/srl-ontonotes-None-only/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-srl-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/07 09:16:39 PM: Saved config to /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run/params.conf
09/07 09:16:39 PM: Using random seed 1234
09/07 09:16:40 PM: Using GPU 0
09/07 09:16:40 PM: Loading tasks...
09/07 09:16:40 PM: Writing pre-preprocessed tasks to /scratch0/new/jiant/experiments/srl-ontonotes-None-only/
09/07 09:16:40 PM: 	Creating task edges-srl-ontonotes from scratch.
09/07 09:16:45 PM: Read=231480, Skip=21590, Total=253070 from /scratch0/new/jiant/probing_data/edges/ontonotes/srl/train.json.retokenized.bert-base-uncased
09/07 09:16:45 PM: Read=32486, Skip=2811, Total=35297 from /scratch0/new/jiant/probing_data/edges/ontonotes/srl/development.json.retokenized.bert-base-uncased
09/07 09:16:46 PM: Read=23800, Skip=2915, Total=26715 from /scratch0/new/jiant/probing_data/edges/ontonotes/srl/test.json.retokenized.bert-base-uncased
09/07 09:16:48 PM: 	Task 'edges-srl-ontonotes': |train|=231480 |val|=32486 |test|=23800
09/07 09:16:48 PM: 	Finished loading tasks: edges-srl-ontonotes.
09/07 09:16:48 PM: 	Building vocab from scratch.
09/07 09:16:48 PM: 	Counting units for task edges-srl-ontonotes.
09/07 09:16:56 PM: 	Task 'edges-srl-ontonotes': adding vocab namespace 'edges-srl-ontonotes_labels'
09/07 09:16:56 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /cliphomes/ewallac2/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:16:56 PM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/07 09:16:57 PM: 	Saved vocab to /scratch0/new/jiant/experiments/srl-ontonotes-None-only/vocab
09/07 09:16:57 PM: Loading token dictionary from /scratch0/new/jiant/experiments/srl-ontonotes-None-only/vocab.
09/07 09:16:57 PM: 	Loaded vocab from /scratch0/new/jiant/experiments/srl-ontonotes-None-only/vocab
09/07 09:16:57 PM: 	Vocab namespace tokens: size 23662
09/07 09:16:57 PM: 	Vocab namespace chars: size 76
09/07 09:16:57 PM: 	Vocab namespace edges-srl-ontonotes_labels: size 66
09/07 09:16:57 PM: 	Vocab namespace bert_uncased: size 30524
09/07 09:16:57 PM: 	Finished building vocab.
09/07 09:16:57 PM: 	Task edges-srl-ontonotes (train): Indexing from scratch.
09/07 09:17:44 PM: 	Task edges-srl-ontonotes (train): Saved 231480 instances to /scratch0/new/jiant/experiments/srl-ontonotes-None-only/preproc/edges-srl-ontonotes__train_data
09/07 09:17:44 PM: 	Task edges-srl-ontonotes (val): Indexing from scratch.
09/07 09:17:50 PM: 	Task edges-srl-ontonotes (val): Saved 32486 instances to /scratch0/new/jiant/experiments/srl-ontonotes-None-only/preproc/edges-srl-ontonotes__val_data
09/07 09:17:50 PM: 	Task edges-srl-ontonotes (test): Indexing from scratch.
09/07 09:17:55 PM: 	Task edges-srl-ontonotes (test): Saved 23800 instances to /scratch0/new/jiant/experiments/srl-ontonotes-None-only/preproc/edges-srl-ontonotes__test_data
09/07 09:17:55 PM: 	Finished indexing tasks
09/07 09:17:55 PM: 	Creating trimmed target-only version of edges-srl-ontonotes train.
09/07 09:17:55 PM: 	  Training on 
09/07 09:17:55 PM: 	  Evaluating on edges-srl-ontonotes
09/07 09:17:55 PM: 	Finished loading tasks in 75.456s
09/07 09:17:55 PM: 	 Tasks: ['edges-srl-ontonotes']
09/07 09:17:55 PM: Building model...
09/07 09:17:55 PM: Using BERT model (bert-base-uncased).
09/07 09:17:55 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache, downloading to /tmp/tmpgatu37zv
09/07 09:17:56 PM: copying /tmp/tmpgatu37zv to cache at /scratch0/new/jiant/experiments/srl-ontonotes-None-only/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/07 09:17:56 PM: creating metadata file for /scratch0/new/jiant/experiments/srl-ontonotes-None-only/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/07 09:17:56 PM: removing temp file /tmp/tmpgatu37zv
09/07 09:17:56 PM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /scratch0/new/jiant/experiments/srl-ontonotes-None-only/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/07 09:17:56 PM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/07 09:17:56 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache, downloading to /tmp/tmpe77lw85f
09/07 09:18:24 PM: copying /tmp/tmpe77lw85f to cache at /scratch0/new/jiant/experiments/srl-ontonotes-None-only/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/07 09:18:25 PM: creating metadata file for /scratch0/new/jiant/experiments/srl-ontonotes-None-only/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/07 09:18:25 PM: removing temp file /tmp/tmpe77lw85f
09/07 09:18:25 PM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /scratch0/new/jiant/experiments/srl-ontonotes-None-only/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/07 09:18:28 PM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache, downloading to /tmp/tmpl068hpgz
09/07 09:18:28 PM: copying /tmp/tmpl068hpgz to cache at /scratch0/new/jiant/experiments/srl-ontonotes-None-only/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:18:28 PM: creating metadata file for /scratch0/new/jiant/experiments/srl-ontonotes-None-only/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:18:28 PM: removing temp file /tmp/tmpl068hpgz
09/07 09:18:28 PM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /scratch0/new/jiant/experiments/srl-ontonotes-None-only/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/07 09:18:28 PM: Initializing parameters
09/07 09:18:28 PM: Done initializing parameters; the following parameters are using their default initialization from their code
09/07 09:18:28 PM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/07 09:18:28 PM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/07 09:18:28 PM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/07 09:18:28 PM:    _text_field_embedder.model.pooler.dense.bias
09/07 09:18:28 PM:    _text_field_embedder.model.pooler.dense.weight
09/07 09:18:28 PM: 	Task 'edges-srl-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-srl-ontonotes"
}
09/07 09:18:33 PM: Model specification:
09/07 09:18:33 PM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): BertLayerNorm()
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): BertLayerNorm()
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): BertLayerNorm()
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-srl-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (proj2): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (span_extractor2): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Sequential(
        (0): Linear(in_features=1024, out_features=256, bias=True)
        (1): Tanh()
        (2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)
        (3): Dropout(p=0.3)
        (4): Linear(in_features=256, out_features=66, bias=True)
      )
    )
  )
)
09/07 09:18:33 PM: Model parameters:
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/07 09:18:33 PM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/07 09:18:33 PM: 	edges-srl-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/07 09:18:33 PM: 	edges-srl-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:33 PM: 	edges-srl-ontonotes_mdl.proj2.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/07 09:18:33 PM: 	edges-srl-ontonotes_mdl.proj2.bias: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:33 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.0.weight: Trainable parameter, count 262144 with torch.Size([256, 1024])
09/07 09:18:33 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.0.bias: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:33 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.2.weight: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:33 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.2.bias: Trainable parameter, count 256 with torch.Size([256])
09/07 09:18:33 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.4.weight: Trainable parameter, count 16896 with torch.Size([66, 256])
09/07 09:18:33 PM: 	edges-srl-ontonotes_mdl.classifier.classifier.4.bias: Trainable parameter, count 66 with torch.Size([66])
09/07 09:18:33 PM: Total number of parameters: 110155842 (1.10156e+08)
09/07 09:18:33 PM: Number of trainable parameters: 673602 (673602)
09/07 09:18:33 PM: Finished building model in 37.167s
09/07 09:18:33 PM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-srl-ontonotes 

09/07 09:18:49 PM: patience = 20
09/07 09:18:49 PM: val_interval = 1000
09/07 09:18:49 PM: max_vals = 250
09/07 09:18:49 PM: cuda_device = 0
09/07 09:18:49 PM: grad_norm = 5.0
09/07 09:18:49 PM: grad_clipping = None
09/07 09:18:49 PM: lr_decay = 0.99
09/07 09:18:49 PM: min_lr = 1e-06
09/07 09:18:49 PM: keep_all_checkpoints = 0
09/07 09:18:49 PM: val_data_limit = 5000
09/07 09:18:49 PM: max_epochs = -1
09/07 09:18:49 PM: dec_val_scale = 250
09/07 09:18:49 PM: training_data_fraction = 1
09/07 09:18:49 PM: type = adam
09/07 09:18:49 PM: parameter_groups = None
09/07 09:18:49 PM: Number of trainable parameters: 673602
09/07 09:18:49 PM: infer_type_and_cast = True
09/07 09:18:49 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/07 09:18:49 PM: CURRENTLY DEFINED PARAMETERS: 
09/07 09:18:49 PM: lr = 0.0001
09/07 09:18:49 PM: amsgrad = True
09/07 09:18:49 PM: type = reduce_on_plateau
09/07 09:18:49 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/07 09:18:49 PM: CURRENTLY DEFINED PARAMETERS: 
09/07 09:18:49 PM: mode = max
09/07 09:18:49 PM: factor = 0.5
09/07 09:18:49 PM: patience = 5
09/07 09:18:49 PM: threshold = 0.0001
09/07 09:18:49 PM: threshold_mode = abs
09/07 09:18:49 PM: verbose = True
09/07 09:18:49 PM: type = adam
09/07 09:18:49 PM: parameter_groups = None
09/07 09:18:49 PM: Number of trainable parameters: 673602
09/07 09:18:49 PM: infer_type_and_cast = True
09/07 09:18:49 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/07 09:18:49 PM: CURRENTLY DEFINED PARAMETERS: 
09/07 09:18:49 PM: lr = 0.0001
09/07 09:18:49 PM: amsgrad = True
09/07 09:18:49 PM: type = reduce_on_plateau
09/07 09:18:49 PM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/07 09:18:49 PM: CURRENTLY DEFINED PARAMETERS: 
09/07 09:18:49 PM: mode = max
09/07 09:18:49 PM: factor = 0.5
09/07 09:18:49 PM: patience = 5
09/07 09:18:49 PM: threshold = 0.0001
09/07 09:18:49 PM: threshold_mode = abs
09/07 09:18:49 PM: verbose = True
09/07 09:18:49 PM: Starting training without restoring from a checkpoint.
09/07 09:18:49 PM: Training examples per task, before any subsampling: {'edges-srl-ontonotes': 231480}
09/07 09:18:49 PM: Beginning training with stopping criteria based on metric: edges-srl-ontonotes_f1
09/07 09:18:59 PM: Update 177: task edges-srl-ontonotes, batch 177 (177): mcc: 0.0520, acc: 0.0444, precision: 0.0518, recall: 0.0997, f1: 0.0682, edges-srl-ontonotes_loss: 0.1757
09/07 09:19:09 PM: Update 352: task edges-srl-ontonotes, batch 352 (352): mcc: 0.1192, acc: 0.1098, precision: 0.1278, recall: 0.1386, f1: 0.1330, edges-srl-ontonotes_loss: 0.1147
09/07 09:19:19 PM: Update 552: task edges-srl-ontonotes, batch 552 (552): mcc: 0.2310, acc: 0.2051, precision: 0.2587, recall: 0.2262, f1: 0.2413, edges-srl-ontonotes_loss: 0.0872
09/07 09:19:29 PM: Update 694: task edges-srl-ontonotes, batch 694 (694): mcc: 0.2906, acc: 0.2506, precision: 0.3326, recall: 0.2711, f1: 0.2988, edges-srl-ontonotes_loss: 0.0763
09/07 09:19:39 PM: Update 895: task edges-srl-ontonotes, batch 895 (895): mcc: 0.3485, acc: 0.2922, precision: 0.4054, recall: 0.3147, f1: 0.3544, edges-srl-ontonotes_loss: 0.0663
09/07 09:19:45 PM: ***** Step 1000 / Validation 1 *****
09/07 09:19:45 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:19:45 PM: Validating...
09/07 09:19:49 PM: Evaluate: task edges-srl-ontonotes, batch 82 (157): mcc: 0.6478, acc: 0.5210, precision: 0.7939, recall: 0.5355, f1: 0.6396, edges-srl-ontonotes_loss: 0.0279
09/07 09:19:52 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:19:52 PM: Best result seen so far for micro.
09/07 09:19:52 PM: Best result seen so far for macro.
09/07 09:19:52 PM: Updating LR scheduler:
09/07 09:19:52 PM: 	Best result seen so far for macro_avg: 0.638
09/07 09:19:52 PM: 	# validation passes without improvement: 0
09/07 09:19:52 PM: edges-srl-ontonotes_loss: training: 0.062516 validation: 0.027540
09/07 09:19:52 PM: macro_avg: validation: 0.638331
09/07 09:19:52 PM: micro_avg: validation: 0.000000
09/07 09:19:52 PM: edges-srl-ontonotes_mcc: training: 0.371878 validation: 0.646431
09/07 09:19:52 PM: edges-srl-ontonotes_acc: training: 0.309197 validation: 0.519898
09/07 09:19:52 PM: edges-srl-ontonotes_precision: training: 0.434354 validation: 0.791838
09/07 09:19:52 PM: edges-srl-ontonotes_recall: training: 0.332734 validation: 0.534678
09/07 09:19:52 PM: edges-srl-ontonotes_f1: training: 0.376813 validation: 0.638331
09/07 09:19:52 PM: Global learning rate: 0.0001
09/07 09:19:52 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:19:59 PM: Update 1138: task edges-srl-ontonotes, batch 138 (1138): mcc: 0.5987, acc: 0.4625, precision: 0.7352, recall: 0.4955, f1: 0.5920, edges-srl-ontonotes_loss: 0.0300
09/07 09:20:09 PM: Update 1324: task edges-srl-ontonotes, batch 324 (1324): mcc: 0.6039, acc: 0.4693, precision: 0.7321, recall: 0.5062, f1: 0.5985, edges-srl-ontonotes_loss: 0.0293
09/07 09:20:19 PM: Update 1533: task edges-srl-ontonotes, batch 533 (1533): mcc: 0.6135, acc: 0.4801, precision: 0.7358, recall: 0.5196, f1: 0.6090, edges-srl-ontonotes_loss: 0.0285
09/07 09:20:29 PM: Update 1717: task edges-srl-ontonotes, batch 717 (1717): mcc: 0.6132, acc: 0.4800, precision: 0.7333, recall: 0.5208, f1: 0.6091, edges-srl-ontonotes_loss: 0.0283
09/07 09:20:40 PM: Update 1879: task edges-srl-ontonotes, batch 879 (1879): mcc: 0.6124, acc: 0.4794, precision: 0.7323, recall: 0.5202, f1: 0.6083, edges-srl-ontonotes_loss: 0.0283
09/07 09:20:46 PM: ***** Step 2000 / Validation 2 *****
09/07 09:20:46 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:20:46 PM: Validating...
09/07 09:20:50 PM: Evaluate: task edges-srl-ontonotes, batch 84 (157): mcc: 0.6708, acc: 0.5565, precision: 0.7941, recall: 0.5737, f1: 0.6661, edges-srl-ontonotes_loss: 0.0244
09/07 09:20:53 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:20:53 PM: Best result seen so far for macro.
09/07 09:20:53 PM: Updating LR scheduler:
09/07 09:20:53 PM: 	Best result seen so far for macro_avg: 0.670
09/07 09:20:53 PM: 	# validation passes without improvement: 0
09/07 09:20:53 PM: edges-srl-ontonotes_loss: training: 0.028126 validation: 0.023904
09/07 09:20:53 PM: macro_avg: validation: 0.670002
09/07 09:20:53 PM: micro_avg: validation: 0.000000
09/07 09:20:53 PM: edges-srl-ontonotes_mcc: training: 0.614052 validation: 0.674749
09/07 09:20:53 PM: edges-srl-ontonotes_acc: training: 0.481760 validation: 0.561620
09/07 09:20:53 PM: edges-srl-ontonotes_precision: training: 0.733239 validation: 0.798275
09/07 09:20:53 PM: edges-srl-ontonotes_recall: training: 0.522346 validation: 0.577246
09/07 09:20:53 PM: edges-srl-ontonotes_f1: training: 0.610081 validation: 0.670002
09/07 09:20:53 PM: Global learning rate: 0.0001
09/07 09:20:53 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:21:00 PM: Update 2136: task edges-srl-ontonotes, batch 136 (2136): mcc: 0.6335, acc: 0.5060, precision: 0.7464, recall: 0.5456, f1: 0.6304, edges-srl-ontonotes_loss: 0.0269
09/07 09:21:10 PM: Update 2310: task edges-srl-ontonotes, batch 310 (2310): mcc: 0.6317, acc: 0.5057, precision: 0.7387, recall: 0.5484, f1: 0.6294, edges-srl-ontonotes_loss: 0.0266
09/07 09:21:21 PM: Update 2505: task edges-srl-ontonotes, batch 505 (2505): mcc: 0.6388, acc: 0.5155, precision: 0.7409, recall: 0.5589, f1: 0.6371, edges-srl-ontonotes_loss: 0.0260
09/07 09:21:31 PM: Update 2707: task edges-srl-ontonotes, batch 707 (2707): mcc: 0.6441, acc: 0.5226, precision: 0.7429, recall: 0.5664, f1: 0.6428, edges-srl-ontonotes_loss: 0.0256
09/07 09:21:41 PM: Update 2849: task edges-srl-ontonotes, batch 849 (2849): mcc: 0.6479, acc: 0.5279, precision: 0.7449, recall: 0.5715, f1: 0.6468, edges-srl-ontonotes_loss: 0.0254
09/07 09:21:49 PM: ***** Step 3000 / Validation 3 *****
09/07 09:21:49 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:21:49 PM: Validating...
09/07 09:21:51 PM: Evaluate: task edges-srl-ontonotes, batch 51 (157): mcc: 0.6725, acc: 0.5771, precision: 0.7734, recall: 0.5921, f1: 0.6707, edges-srl-ontonotes_loss: 0.0241
09/07 09:21:56 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:21:56 PM: Best result seen so far for macro.
09/07 09:21:56 PM: Updating LR scheduler:
09/07 09:21:56 PM: 	Best result seen so far for macro_avg: 0.683
09/07 09:21:56 PM: 	# validation passes without improvement: 0
09/07 09:21:56 PM: edges-srl-ontonotes_loss: training: 0.025239 validation: 0.023145
09/07 09:21:56 PM: macro_avg: validation: 0.682999
09/07 09:21:56 PM: micro_avg: validation: 0.000000
09/07 09:21:56 PM: edges-srl-ontonotes_mcc: training: 0.651016 validation: 0.684790
09/07 09:21:56 PM: edges-srl-ontonotes_acc: training: 0.532213 validation: 0.591948
09/07 09:21:56 PM: edges-srl-ontonotes_precision: training: 0.746487 validation: 0.785586
09/07 09:21:56 PM: edges-srl-ontonotes_recall: training: 0.575753 validation: 0.604111
09/07 09:21:56 PM: edges-srl-ontonotes_f1: training: 0.650097 validation: 0.682999
09/07 09:21:56 PM: Global learning rate: 0.0001
09/07 09:21:56 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:22:01 PM: Update 3101: task edges-srl-ontonotes, batch 101 (3101): mcc: 0.6841, acc: 0.5796, precision: 0.7663, recall: 0.6183, f1: 0.6844, edges-srl-ontonotes_loss: 0.0233
09/07 09:22:11 PM: Update 3277: task edges-srl-ontonotes, batch 277 (3277): mcc: 0.6682, acc: 0.5585, precision: 0.7541, recall: 0.6000, f1: 0.6683, edges-srl-ontonotes_loss: 0.0240
09/07 09:22:21 PM: Update 3456: task edges-srl-ontonotes, batch 456 (3456): mcc: 0.6655, acc: 0.5557, precision: 0.7535, recall: 0.5956, f1: 0.6653, edges-srl-ontonotes_loss: 0.0242
09/07 09:22:31 PM: Update 3662: task edges-srl-ontonotes, batch 662 (3662): mcc: 0.6654, acc: 0.5554, precision: 0.7541, recall: 0.5950, f1: 0.6652, edges-srl-ontonotes_loss: 0.0241
09/07 09:22:41 PM: Update 3847: task edges-srl-ontonotes, batch 847 (3847): mcc: 0.6665, acc: 0.5564, precision: 0.7546, recall: 0.5965, f1: 0.6663, edges-srl-ontonotes_loss: 0.0240
09/07 09:22:49 PM: ***** Step 4000 / Validation 4 *****
09/07 09:22:49 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:22:49 PM: Validating...
09/07 09:22:51 PM: Evaluate: task edges-srl-ontonotes, batch 52 (157): mcc: 0.6803, acc: 0.5900, precision: 0.7781, recall: 0.6022, f1: 0.6790, edges-srl-ontonotes_loss: 0.0237
09/07 09:22:58 PM: Updating LR scheduler:
09/07 09:22:58 PM: 	Best result seen so far for macro_avg: 0.683
09/07 09:22:58 PM: 	# validation passes without improvement: 1
09/07 09:22:58 PM: edges-srl-ontonotes_loss: training: 0.024007 validation: 0.022889
09/07 09:22:58 PM: macro_avg: validation: 0.681012
09/07 09:22:58 PM: micro_avg: validation: 0.000000
09/07 09:22:58 PM: edges-srl-ontonotes_mcc: training: 0.666257 validation: 0.682426
09/07 09:22:58 PM: edges-srl-ontonotes_acc: training: 0.557068 validation: 0.591409
09/07 09:22:58 PM: edges-srl-ontonotes_precision: training: 0.754057 validation: 0.780219
09/07 09:22:58 PM: edges-srl-ontonotes_recall: training: 0.596543 validation: 0.604187
09/07 09:22:58 PM: edges-srl-ontonotes_f1: training: 0.666115 validation: 0.681012
09/07 09:22:58 PM: Global learning rate: 0.0001
09/07 09:22:58 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:23:02 PM: Update 4070: task edges-srl-ontonotes, batch 70 (4070): mcc: 0.6637, acc: 0.5554, precision: 0.7532, recall: 0.5926, f1: 0.6633, edges-srl-ontonotes_loss: 0.0241
09/07 09:23:12 PM: Update 4270: task edges-srl-ontonotes, batch 270 (4270): mcc: 0.6698, acc: 0.5650, precision: 0.7540, recall: 0.6029, f1: 0.6701, edges-srl-ontonotes_loss: 0.0237
09/07 09:23:22 PM: Update 4451: task edges-srl-ontonotes, batch 451 (4451): mcc: 0.6764, acc: 0.5734, precision: 0.7596, recall: 0.6100, f1: 0.6766, edges-srl-ontonotes_loss: 0.0234
09/07 09:23:32 PM: Update 4651: task edges-srl-ontonotes, batch 651 (4651): mcc: 0.6813, acc: 0.5792, precision: 0.7624, recall: 0.6166, f1: 0.6818, edges-srl-ontonotes_loss: 0.0231
09/07 09:23:42 PM: Update 4833: task edges-srl-ontonotes, batch 833 (4833): mcc: 0.6792, acc: 0.5765, precision: 0.7612, recall: 0.6138, f1: 0.6796, edges-srl-ontonotes_loss: 0.0233
09/07 09:23:50 PM: ***** Step 5000 / Validation 5 *****
09/07 09:23:50 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:23:50 PM: Validating...
09/07 09:23:52 PM: Evaluate: task edges-srl-ontonotes, batch 41 (157): mcc: 0.6891, acc: 0.6022, precision: 0.7696, recall: 0.6246, f1: 0.6895, edges-srl-ontonotes_loss: 0.0228
09/07 09:23:58 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:23:58 PM: Best result seen so far for macro.
09/07 09:23:58 PM: Updating LR scheduler:
09/07 09:23:58 PM: 	Best result seen so far for macro_avg: 0.685
09/07 09:23:58 PM: 	# validation passes without improvement: 0
09/07 09:23:58 PM: edges-srl-ontonotes_loss: training: 0.023248 validation: 0.022608
09/07 09:23:58 PM: macro_avg: validation: 0.684904
09/07 09:23:58 PM: micro_avg: validation: 0.000000
09/07 09:23:58 PM: edges-srl-ontonotes_mcc: training: 0.679675 validation: 0.684090
09/07 09:23:58 PM: edges-srl-ontonotes_acc: training: 0.576371 validation: 0.600416
09/07 09:23:58 PM: edges-srl-ontonotes_precision: training: 0.762146 validation: 0.761201
09/07 09:23:58 PM: edges-srl-ontonotes_recall: training: 0.613823 validation: 0.622508
09/07 09:23:58 PM: edges-srl-ontonotes_f1: training: 0.679990 validation: 0.684904
09/07 09:23:58 PM: Global learning rate: 0.0001
09/07 09:23:58 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:24:02 PM: Update 5035: task edges-srl-ontonotes, batch 35 (5035): mcc: 0.6896, acc: 0.5938, precision: 0.7712, recall: 0.6241, f1: 0.6899, edges-srl-ontonotes_loss: 0.0229
09/07 09:24:12 PM: Update 5235: task edges-srl-ontonotes, batch 235 (5235): mcc: 0.7080, acc: 0.6117, precision: 0.7809, recall: 0.6491, f1: 0.7089, edges-srl-ontonotes_loss: 0.0211
09/07 09:24:22 PM: Update 5415: task edges-srl-ontonotes, batch 415 (5415): mcc: 0.7217, acc: 0.6287, precision: 0.7906, recall: 0.6658, f1: 0.7229, edges-srl-ontonotes_loss: 0.0204
09/07 09:24:32 PM: Update 5614: task edges-srl-ontonotes, batch 614 (5614): mcc: 0.7376, acc: 0.6479, precision: 0.8020, recall: 0.6851, f1: 0.7390, edges-srl-ontonotes_loss: 0.0195
09/07 09:24:42 PM: Update 5788: task edges-srl-ontonotes, batch 788 (5788): mcc: 0.7430, acc: 0.6551, precision: 0.8053, recall: 0.6921, f1: 0.7444, edges-srl-ontonotes_loss: 0.0191
09/07 09:24:54 PM: Update 5948: task edges-srl-ontonotes, batch 948 (5948): mcc: 0.7473, acc: 0.6606, precision: 0.8085, recall: 0.6972, f1: 0.7487, edges-srl-ontonotes_loss: 0.0189
09/07 09:24:57 PM: ***** Step 6000 / Validation 6 *****
09/07 09:24:57 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:24:57 PM: Validating...
09/07 09:25:04 PM: Evaluate: task edges-srl-ontonotes, batch 157 (157): mcc: 0.7201, acc: 0.6451, precision: 0.8016, recall: 0.6537, f1: 0.7201, edges-srl-ontonotes_loss: 0.0212
09/07 09:25:04 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:25:04 PM: Best result seen so far for macro.
09/07 09:25:04 PM: Updating LR scheduler:
09/07 09:25:04 PM: 	Best result seen so far for macro_avg: 0.720
09/07 09:25:04 PM: 	# validation passes without improvement: 0
09/07 09:25:04 PM: edges-srl-ontonotes_loss: training: 0.018788 validation: 0.021202
09/07 09:25:04 PM: macro_avg: validation: 0.720119
09/07 09:25:04 PM: micro_avg: validation: 0.000000
09/07 09:25:04 PM: edges-srl-ontonotes_mcc: training: 0.748954 validation: 0.720089
09/07 09:25:04 PM: edges-srl-ontonotes_acc: training: 0.662835 validation: 0.645139
09/07 09:25:04 PM: edges-srl-ontonotes_precision: training: 0.809835 validation: 0.801586
09/07 09:25:04 PM: edges-srl-ontonotes_recall: training: 0.699148 validation: 0.653683
09/07 09:25:04 PM: edges-srl-ontonotes_f1: training: 0.750432 validation: 0.720119
09/07 09:25:04 PM: Global learning rate: 0.0001
09/07 09:25:04 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:25:14 PM: Update 6198: task edges-srl-ontonotes, batch 198 (6198): mcc: 0.7817, acc: 0.7074, precision: 0.8312, recall: 0.7410, f1: 0.7835, edges-srl-ontonotes_loss: 0.0168
09/07 09:25:24 PM: Update 6375: task edges-srl-ontonotes, batch 375 (6375): mcc: 0.7925, acc: 0.7217, precision: 0.8413, recall: 0.7520, f1: 0.7942, edges-srl-ontonotes_loss: 0.0165
09/07 09:25:34 PM: Update 6572: task edges-srl-ontonotes, batch 572 (6572): mcc: 0.8038, acc: 0.7371, precision: 0.8499, recall: 0.7655, f1: 0.8055, edges-srl-ontonotes_loss: 0.0158
09/07 09:25:44 PM: Update 6752: task edges-srl-ontonotes, batch 752 (6752): mcc: 0.7845, acc: 0.7127, precision: 0.8343, recall: 0.7434, f1: 0.7862, edges-srl-ontonotes_loss: 0.0170
09/07 09:25:54 PM: Update 6929: task edges-srl-ontonotes, batch 929 (6929): mcc: 0.7707, acc: 0.6958, precision: 0.8235, recall: 0.7274, f1: 0.7725, edges-srl-ontonotes_loss: 0.0178
09/07 09:25:58 PM: ***** Step 7000 / Validation 7 *****
09/07 09:25:58 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:25:58 PM: Validating...
09/07 09:26:04 PM: Evaluate: task edges-srl-ontonotes, batch 97 (157): mcc: 0.7385, acc: 0.6663, precision: 0.8131, recall: 0.6773, f1: 0.7390, edges-srl-ontonotes_loss: 0.0199
09/07 09:26:07 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:26:07 PM: Best result seen so far for macro.
09/07 09:26:07 PM: Updating LR scheduler:
09/07 09:26:07 PM: 	Best result seen so far for macro_avg: 0.732
09/07 09:26:07 PM: 	# validation passes without improvement: 0
09/07 09:26:07 PM: edges-srl-ontonotes_loss: training: 0.018220 validation: 0.020163
09/07 09:26:07 PM: macro_avg: validation: 0.731867
09/07 09:26:07 PM: micro_avg: validation: 0.000000
09/07 09:26:07 PM: edges-srl-ontonotes_mcc: training: 0.764049 validation: 0.731350
09/07 09:26:07 PM: edges-srl-ontonotes_acc: training: 0.687157 validation: 0.658533
09/07 09:26:07 PM: edges-srl-ontonotes_precision: training: 0.818578 validation: 0.806431
09/07 09:26:07 PM: edges-srl-ontonotes_recall: training: 0.719378 validation: 0.669925
09/07 09:26:07 PM: edges-srl-ontonotes_f1: training: 0.765779 validation: 0.731867
09/07 09:26:07 PM: Global learning rate: 0.0001
09/07 09:26:07 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:26:14 PM: Update 7147: task edges-srl-ontonotes, batch 147 (7147): mcc: 0.6963, acc: 0.6006, precision: 0.7650, recall: 0.6414, f1: 0.6978, edges-srl-ontonotes_loss: 0.0222
09/07 09:26:24 PM: Update 7318: task edges-srl-ontonotes, batch 318 (7318): mcc: 0.7053, acc: 0.6105, precision: 0.7774, recall: 0.6472, f1: 0.7063, edges-srl-ontonotes_loss: 0.0217
09/07 09:26:34 PM: Update 7509: task edges-srl-ontonotes, batch 509 (7509): mcc: 0.7168, acc: 0.6251, precision: 0.7855, recall: 0.6613, f1: 0.7181, edges-srl-ontonotes_loss: 0.0208
09/07 09:26:44 PM: Update 7683: task edges-srl-ontonotes, batch 683 (7683): mcc: 0.7253, acc: 0.6361, precision: 0.7914, recall: 0.6716, f1: 0.7266, edges-srl-ontonotes_loss: 0.0203
09/07 09:26:55 PM: Update 7873: task edges-srl-ontonotes, batch 873 (7873): mcc: 0.7316, acc: 0.6437, precision: 0.7962, recall: 0.6790, f1: 0.7330, edges-srl-ontonotes_loss: 0.0198
09/07 09:27:01 PM: ***** Step 8000 / Validation 8 *****
09/07 09:27:01 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:27:01 PM: Validating...
09/07 09:27:05 PM: Evaluate: task edges-srl-ontonotes, batch 80 (157): mcc: 0.7496, acc: 0.6815, precision: 0.8203, recall: 0.6914, f1: 0.7503, edges-srl-ontonotes_loss: 0.0189
09/07 09:27:09 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:27:09 PM: Best result seen so far for macro.
09/07 09:27:09 PM: Updating LR scheduler:
09/07 09:27:09 PM: 	Best result seen so far for macro_avg: 0.748
09/07 09:27:09 PM: 	# validation passes without improvement: 0
09/07 09:27:09 PM: edges-srl-ontonotes_loss: training: 0.019961 validation: 0.018777
09/07 09:27:09 PM: macro_avg: validation: 0.748225
09/07 09:27:09 PM: micro_avg: validation: 0.000000
09/07 09:27:09 PM: edges-srl-ontonotes_mcc: training: 0.729568 validation: 0.747482
09/07 09:27:09 PM: edges-srl-ontonotes_acc: training: 0.641577 validation: 0.678932
09/07 09:27:09 PM: edges-srl-ontonotes_precision: training: 0.794132 validation: 0.817916
09/07 09:27:09 PM: edges-srl-ontonotes_recall: training: 0.677162 validation: 0.689477
09/07 09:27:09 PM: edges-srl-ontonotes_f1: training: 0.730997 validation: 0.748225
09/07 09:27:09 PM: Global learning rate: 0.0001
09/07 09:27:09 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:27:15 PM: Update 8132: task edges-srl-ontonotes, batch 132 (8132): mcc: 0.7146, acc: 0.6270, precision: 0.7781, recall: 0.6636, f1: 0.7163, edges-srl-ontonotes_loss: 0.0208
09/07 09:27:25 PM: Update 8278: task edges-srl-ontonotes, batch 278 (8278): mcc: 0.7074, acc: 0.6166, precision: 0.7740, recall: 0.6540, f1: 0.7090, edges-srl-ontonotes_loss: 0.0212
09/07 09:27:35 PM: Update 8483: task edges-srl-ontonotes, batch 483 (8483): mcc: 0.7029, acc: 0.6114, precision: 0.7711, recall: 0.6483, f1: 0.7044, edges-srl-ontonotes_loss: 0.0215
09/07 09:27:45 PM: Update 8666: task edges-srl-ontonotes, batch 666 (8666): mcc: 0.7010, acc: 0.6082, precision: 0.7699, recall: 0.6458, f1: 0.7024, edges-srl-ontonotes_loss: 0.0216
09/07 09:27:55 PM: Update 8851: task edges-srl-ontonotes, batch 851 (8851): mcc: 0.7006, acc: 0.6073, precision: 0.7693, recall: 0.6456, f1: 0.7020, edges-srl-ontonotes_loss: 0.0215
09/07 09:28:03 PM: ***** Step 9000 / Validation 9 *****
09/07 09:28:03 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:28:03 PM: Validating...
09/07 09:28:05 PM: Evaluate: task edges-srl-ontonotes, batch 54 (157): mcc: 0.7291, acc: 0.6514, precision: 0.8141, recall: 0.6595, f1: 0.7287, edges-srl-ontonotes_loss: 0.0196
09/07 09:28:10 PM: Updating LR scheduler:
09/07 09:28:10 PM: 	Best result seen so far for macro_avg: 0.748
09/07 09:28:10 PM: 	# validation passes without improvement: 1
09/07 09:28:10 PM: edges-srl-ontonotes_loss: training: 0.021825 validation: 0.018743
09/07 09:28:10 PM: macro_avg: validation: 0.742375
09/07 09:28:10 PM: micro_avg: validation: 0.000000
09/07 09:28:10 PM: edges-srl-ontonotes_mcc: training: 0.695911 validation: 0.742326
09/07 09:28:10 PM: edges-srl-ontonotes_acc: training: 0.601354 validation: 0.666846
09/07 09:28:10 PM: edges-srl-ontonotes_precision: training: 0.766174 validation: 0.821262
09/07 09:28:10 PM: edges-srl-ontonotes_recall: training: 0.639690 validation: 0.677315
09/07 09:28:10 PM: edges-srl-ontonotes_f1: training: 0.697242 validation: 0.742375
09/07 09:28:10 PM: Global learning rate: 0.0001
09/07 09:28:10 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:28:15 PM: Update 9106: task edges-srl-ontonotes, batch 106 (9106): mcc: 0.6758, acc: 0.5776, precision: 0.7548, recall: 0.6130, f1: 0.6765, edges-srl-ontonotes_loss: 0.0230
09/07 09:28:25 PM: Update 9251: task edges-srl-ontonotes, batch 251 (9251): mcc: 0.6760, acc: 0.5770, precision: 0.7553, recall: 0.6128, f1: 0.6767, edges-srl-ontonotes_loss: 0.0230
09/07 09:28:36 PM: Update 9438: task edges-srl-ontonotes, batch 438 (9438): mcc: 0.6815, acc: 0.5831, precision: 0.7607, recall: 0.6184, f1: 0.6822, edges-srl-ontonotes_loss: 0.0228
09/07 09:28:46 PM: Update 9636: task edges-srl-ontonotes, batch 636 (9636): mcc: 0.6858, acc: 0.5892, precision: 0.7619, recall: 0.6250, f1: 0.6867, edges-srl-ontonotes_loss: 0.0224
09/07 09:28:56 PM: Update 9817: task edges-srl-ontonotes, batch 817 (9817): mcc: 0.6869, acc: 0.5901, precision: 0.7620, recall: 0.6269, f1: 0.6879, edges-srl-ontonotes_loss: 0.0223
09/07 09:29:05 PM: ***** Step 10000 / Validation 10 *****
09/07 09:29:05 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:29:05 PM: Validating...
09/07 09:29:06 PM: Evaluate: task edges-srl-ontonotes, batch 15 (157): mcc: 0.7263, acc: 0.6480, precision: 0.8108, recall: 0.6573, f1: 0.7260, edges-srl-ontonotes_loss: 0.0193
09/07 09:29:12 PM: Updating LR scheduler:
09/07 09:29:12 PM: 	Best result seen so far for macro_avg: 0.748
09/07 09:29:12 PM: 	# validation passes without improvement: 2
09/07 09:29:12 PM: edges-srl-ontonotes_loss: training: 0.022096 validation: 0.019618
09/07 09:29:12 PM: macro_avg: validation: 0.724981
09/07 09:29:12 PM: micro_avg: validation: 0.000000
09/07 09:29:12 PM: edges-srl-ontonotes_mcc: training: 0.689887 validation: 0.724273
09/07 09:29:12 PM: edges-srl-ontonotes_acc: training: 0.593575 validation: 0.653683
09/07 09:29:12 PM: edges-srl-ontonotes_precision: training: 0.763474 validation: 0.798076
09/07 09:29:12 PM: edges-srl-ontonotes_recall: training: 0.631059 validation: 0.664152
09/07 09:29:12 PM: edges-srl-ontonotes_f1: training: 0.690979 validation: 0.724981
09/07 09:29:12 PM: Global learning rate: 0.0001
09/07 09:29:12 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:29:18 PM: Update 10064: task edges-srl-ontonotes, batch 64 (10064): mcc: 0.7121, acc: 0.6210, precision: 0.7783, recall: 0.6588, f1: 0.7136, edges-srl-ontonotes_loss: 0.0213
09/07 09:29:28 PM: Update 10261: task edges-srl-ontonotes, batch 261 (10261): mcc: 0.7127, acc: 0.6230, precision: 0.7800, recall: 0.6585, f1: 0.7141, edges-srl-ontonotes_loss: 0.0209
09/07 09:29:38 PM: Update 10441: task edges-srl-ontonotes, batch 441 (10441): mcc: 0.7118, acc: 0.6219, precision: 0.7796, recall: 0.6572, f1: 0.7132, edges-srl-ontonotes_loss: 0.0210
09/07 09:29:48 PM: Update 10645: task edges-srl-ontonotes, batch 645 (10645): mcc: 0.7071, acc: 0.6160, precision: 0.7759, recall: 0.6518, f1: 0.7084, edges-srl-ontonotes_loss: 0.0213
09/07 09:29:58 PM: Update 10830: task edges-srl-ontonotes, batch 830 (10830): mcc: 0.7054, acc: 0.6140, precision: 0.7742, recall: 0.6501, f1: 0.7068, edges-srl-ontonotes_loss: 0.0213
09/07 09:30:07 PM: ***** Step 11000 / Validation 11 *****
09/07 09:30:07 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:30:07 PM: Validating...
09/07 09:30:08 PM: Evaluate: task edges-srl-ontonotes, batch 35 (157): mcc: 0.7230, acc: 0.6515, precision: 0.7986, recall: 0.6613, f1: 0.7235, edges-srl-ontonotes_loss: 0.0205
09/07 09:30:14 PM: Updating LR scheduler:
09/07 09:30:14 PM: 	Best result seen so far for macro_avg: 0.748
09/07 09:30:14 PM: 	# validation passes without improvement: 3
09/07 09:30:14 PM: edges-srl-ontonotes_loss: training: 0.021310 validation: 0.020085
09/07 09:30:14 PM: macro_avg: validation: 0.722358
09/07 09:30:14 PM: micro_avg: validation: 0.000000
09/07 09:30:14 PM: edges-srl-ontonotes_mcc: training: 0.705835 validation: 0.721655
09/07 09:30:14 PM: edges-srl-ontonotes_acc: training: 0.614604 validation: 0.650527
09/07 09:30:14 PM: edges-srl-ontonotes_precision: training: 0.775110 validation: 0.795831
09/07 09:30:14 PM: edges-srl-ontonotes_recall: training: 0.650137 validation: 0.661304
09/07 09:30:14 PM: edges-srl-ontonotes_f1: training: 0.707144 validation: 0.722358
09/07 09:30:14 PM: Global learning rate: 0.0001
09/07 09:30:14 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:30:18 PM: Update 11070: task edges-srl-ontonotes, batch 70 (11070): mcc: 0.6958, acc: 0.6052, precision: 0.7621, recall: 0.6429, f1: 0.6975, edges-srl-ontonotes_loss: 0.0213
09/07 09:30:28 PM: Update 11274: task edges-srl-ontonotes, batch 274 (11274): mcc: 0.7009, acc: 0.6099, precision: 0.7700, recall: 0.6455, f1: 0.7023, edges-srl-ontonotes_loss: 0.0214
09/07 09:30:39 PM: Update 11419: task edges-srl-ontonotes, batch 419 (11419): mcc: 0.7036, acc: 0.6124, precision: 0.7727, recall: 0.6481, f1: 0.7049, edges-srl-ontonotes_loss: 0.0213
09/07 09:30:49 PM: Update 11615: task edges-srl-ontonotes, batch 615 (11615): mcc: 0.7050, acc: 0.6154, precision: 0.7726, recall: 0.6507, f1: 0.7064, edges-srl-ontonotes_loss: 0.0212
09/07 09:30:59 PM: Update 11793: task edges-srl-ontonotes, batch 793 (11793): mcc: 0.7062, acc: 0.6163, precision: 0.7739, recall: 0.6519, f1: 0.7077, edges-srl-ontonotes_loss: 0.0211
09/07 09:31:09 PM: Update 11971: task edges-srl-ontonotes, batch 971 (11971): mcc: 0.7062, acc: 0.6166, precision: 0.7739, recall: 0.6517, f1: 0.7076, edges-srl-ontonotes_loss: 0.0211
09/07 09:31:10 PM: ***** Step 12000 / Validation 12 *****
09/07 09:31:10 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:31:10 PM: Validating...
09/07 09:31:17 PM: Updating LR scheduler:
09/07 09:31:17 PM: 	Best result seen so far for macro_avg: 0.748
09/07 09:31:17 PM: 	# validation passes without improvement: 4
09/07 09:31:17 PM: edges-srl-ontonotes_loss: training: 0.021168 validation: 0.020072
09/07 09:31:17 PM: macro_avg: validation: 0.715797
09/07 09:31:17 PM: micro_avg: validation: 0.000000
09/07 09:31:17 PM: edges-srl-ontonotes_mcc: training: 0.705579 validation: 0.715541
09/07 09:31:17 PM: edges-srl-ontonotes_acc: training: 0.615830 validation: 0.643522
09/07 09:31:17 PM: edges-srl-ontonotes_precision: training: 0.773637 validation: 0.795166
09/07 09:31:17 PM: edges-srl-ontonotes_recall: training: 0.650926 validation: 0.650835
09/07 09:31:17 PM: edges-srl-ontonotes_f1: training: 0.706997 validation: 0.715797
09/07 09:31:17 PM: Global learning rate: 0.0001
09/07 09:31:17 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:31:19 PM: Update 12026: task edges-srl-ontonotes, batch 26 (12026): mcc: 0.7018, acc: 0.6122, precision: 0.7768, recall: 0.6414, f1: 0.7026, edges-srl-ontonotes_loss: 0.0219
09/07 09:31:29 PM: Update 12227: task edges-srl-ontonotes, batch 227 (12227): mcc: 0.7008, acc: 0.6073, precision: 0.7728, recall: 0.6429, f1: 0.7019, edges-srl-ontonotes_loss: 0.0215
09/07 09:31:39 PM: Update 12369: task edges-srl-ontonotes, batch 369 (12369): mcc: 0.7133, acc: 0.6232, precision: 0.7812, recall: 0.6585, f1: 0.7146, edges-srl-ontonotes_loss: 0.0208
09/07 09:31:50 PM: Update 12568: task edges-srl-ontonotes, batch 568 (12568): mcc: 0.7279, acc: 0.6406, precision: 0.7906, recall: 0.6772, f1: 0.7295, edges-srl-ontonotes_loss: 0.0198
09/07 09:32:00 PM: Update 12765: task edges-srl-ontonotes, batch 765 (12765): mcc: 0.7430, acc: 0.6586, precision: 0.8016, recall: 0.6954, f1: 0.7448, edges-srl-ontonotes_loss: 0.0189
09/07 09:32:10 PM: Update 12941: task edges-srl-ontonotes, batch 941 (12941): mcc: 0.7527, acc: 0.6708, precision: 0.8084, recall: 0.7073, f1: 0.7545, edges-srl-ontonotes_loss: 0.0183
09/07 09:32:13 PM: ***** Step 13000 / Validation 13 *****
09/07 09:32:13 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:32:13 PM: Validating...
09/07 09:32:20 PM: Evaluate: task edges-srl-ontonotes, batch 152 (157): mcc: 0.7369, acc: 0.6709, precision: 0.8036, recall: 0.6825, f1: 0.7381, edges-srl-ontonotes_loss: 0.0197
09/07 09:32:20 PM: Updating LR scheduler:
09/07 09:32:20 PM: 	Best result seen so far for macro_avg: 0.748
09/07 09:32:20 PM: 	# validation passes without improvement: 5
09/07 09:32:20 PM: edges-srl-ontonotes_loss: training: 0.018158 validation: 0.019769
09/07 09:32:20 PM: macro_avg: validation: 0.738262
09/07 09:32:20 PM: micro_avg: validation: 0.000000
09/07 09:32:20 PM: edges-srl-ontonotes_mcc: training: 0.754399 validation: 0.737090
09/07 09:32:20 PM: edges-srl-ontonotes_acc: training: 0.673130 validation: 0.671157
09/07 09:32:20 PM: edges-srl-ontonotes_precision: training: 0.809524 validation: 0.803770
09/07 09:32:20 PM: edges-srl-ontonotes_recall: training: 0.709491 validation: 0.682626
09/07 09:32:20 PM: edges-srl-ontonotes_f1: training: 0.756214 validation: 0.738262
09/07 09:32:20 PM: Global learning rate: 0.0001
09/07 09:32:20 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:32:30 PM: Update 13189: task edges-srl-ontonotes, batch 189 (13189): mcc: 0.7864, acc: 0.7150, precision: 0.8322, recall: 0.7489, f1: 0.7883, edges-srl-ontonotes_loss: 0.0159
09/07 09:32:40 PM: Update 13326: task edges-srl-ontonotes, batch 326 (13326): mcc: 0.7900, acc: 0.7206, precision: 0.8345, recall: 0.7535, f1: 0.7920, edges-srl-ontonotes_loss: 0.0157
09/07 09:32:50 PM: Update 13507: task edges-srl-ontonotes, batch 507 (13507): mcc: 0.7946, acc: 0.7268, precision: 0.8378, recall: 0.7593, f1: 0.7966, edges-srl-ontonotes_loss: 0.0155
09/07 09:33:00 PM: Update 13702: task edges-srl-ontonotes, batch 702 (13702): mcc: 0.8040, acc: 0.7396, precision: 0.8459, recall: 0.7695, f1: 0.8059, edges-srl-ontonotes_loss: 0.0151
09/07 09:33:10 PM: Update 13878: task edges-srl-ontonotes, batch 878 (13878): mcc: 0.8040, acc: 0.7401, precision: 0.8460, recall: 0.7695, f1: 0.8060, edges-srl-ontonotes_loss: 0.0152
09/07 09:33:16 PM: ***** Step 14000 / Validation 14 *****
09/07 09:33:16 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:33:16 PM: Validating...
09/07 09:33:20 PM: Evaluate: task edges-srl-ontonotes, batch 82 (157): mcc: 0.7523, acc: 0.6871, precision: 0.8177, recall: 0.6986, f1: 0.7534, edges-srl-ontonotes_loss: 0.0187
09/07 09:33:23 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:33:23 PM: Best result seen so far for macro.
09/07 09:33:23 PM: Updating LR scheduler:
09/07 09:33:23 PM: 	Best result seen so far for macro_avg: 0.753
09/07 09:33:23 PM: 	# validation passes without improvement: 0
09/07 09:33:23 PM: edges-srl-ontonotes_loss: training: 0.015710 validation: 0.018601
09/07 09:33:23 PM: macro_avg: validation: 0.752588
09/07 09:33:23 PM: micro_avg: validation: 0.000000
09/07 09:33:23 PM: edges-srl-ontonotes_mcc: training: 0.795666 validation: 0.751313
09/07 09:33:23 PM: edges-srl-ontonotes_acc: training: 0.729364 validation: 0.686783
09/07 09:33:23 PM: edges-srl-ontonotes_precision: training: 0.839544 validation: 0.814523
09/07 09:33:23 PM: edges-srl-ontonotes_recall: training: 0.759647 validation: 0.699407
09/07 09:33:23 PM: edges-srl-ontonotes_f1: training: 0.797600 validation: 0.752588
09/07 09:33:23 PM: Global learning rate: 0.0001
09/07 09:33:23 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:33:30 PM: Update 14124: task edges-srl-ontonotes, batch 124 (14124): mcc: 0.7445, acc: 0.6661, precision: 0.7995, recall: 0.7001, f1: 0.7465, edges-srl-ontonotes_loss: 0.0187
09/07 09:33:40 PM: Update 14300: task edges-srl-ontonotes, batch 300 (14300): mcc: 0.7196, acc: 0.6360, precision: 0.7810, recall: 0.6701, f1: 0.7213, edges-srl-ontonotes_loss: 0.0202
09/07 09:33:50 PM: Update 14490: task edges-srl-ontonotes, batch 490 (14490): mcc: 0.7164, acc: 0.6310, precision: 0.7796, recall: 0.6655, f1: 0.7181, edges-srl-ontonotes_loss: 0.0205
09/07 09:34:00 PM: Update 14633: task edges-srl-ontonotes, batch 633 (14633): mcc: 0.7251, acc: 0.6408, precision: 0.7871, recall: 0.6750, f1: 0.7268, edges-srl-ontonotes_loss: 0.0199
09/07 09:34:10 PM: Update 14806: task edges-srl-ontonotes, batch 806 (14806): mcc: 0.7314, acc: 0.6483, precision: 0.7922, recall: 0.6822, f1: 0.7331, edges-srl-ontonotes_loss: 0.0195
09/07 09:34:20 PM: ***** Step 15000 / Validation 15 *****
09/07 09:34:20 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:34:20 PM: Validating...
09/07 09:34:20 PM: Evaluate: task edges-srl-ontonotes, batch 5 (157): mcc: 0.7689, acc: 0.7016, precision: 0.8387, recall: 0.7107, f1: 0.7694, edges-srl-ontonotes_loss: 0.0179
09/07 09:34:27 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:34:27 PM: Best result seen so far for macro.
09/07 09:34:27 PM: Updating LR scheduler:
09/07 09:34:27 PM: 	Best result seen so far for macro_avg: 0.761
09/07 09:34:27 PM: 	# validation passes without improvement: 0
09/07 09:34:27 PM: edges-srl-ontonotes_loss: training: 0.019099 validation: 0.017671
09/07 09:34:27 PM: macro_avg: validation: 0.761165
09/07 09:34:27 PM: micro_avg: validation: 0.000000
09/07 09:34:27 PM: edges-srl-ontonotes_mcc: training: 0.737789 validation: 0.760193
09/07 09:34:27 PM: edges-srl-ontonotes_acc: training: 0.655944 validation: 0.695405
09/07 09:34:27 PM: edges-srl-ontonotes_precision: training: 0.797475 validation: 0.825962
09/07 09:34:27 PM: edges-srl-ontonotes_recall: training: 0.689369 validation: 0.705796
09/07 09:34:27 PM: edges-srl-ontonotes_f1: training: 0.739492 validation: 0.761165
09/07 09:34:27 PM: Global learning rate: 0.0001
09/07 09:34:27 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:34:30 PM: Update 15060: task edges-srl-ontonotes, batch 60 (15060): mcc: 0.7657, acc: 0.6900, precision: 0.8197, recall: 0.7215, f1: 0.7675, edges-srl-ontonotes_loss: 0.0176
09/07 09:34:40 PM: Update 15241: task edges-srl-ontonotes, batch 241 (15241): mcc: 0.7487, acc: 0.6683, precision: 0.8042, recall: 0.7036, f1: 0.7505, edges-srl-ontonotes_loss: 0.0186
09/07 09:34:53 PM: Update 15432: task edges-srl-ontonotes, batch 432 (15432): mcc: 0.7408, acc: 0.6597, precision: 0.7973, recall: 0.6952, f1: 0.7427, edges-srl-ontonotes_loss: 0.0190
09/07 09:35:03 PM: Update 15639: task edges-srl-ontonotes, batch 639 (15639): mcc: 0.7314, acc: 0.6484, precision: 0.7904, recall: 0.6837, f1: 0.7332, edges-srl-ontonotes_loss: 0.0196
09/07 09:35:13 PM: Update 15826: task edges-srl-ontonotes, batch 826 (15826): mcc: 0.7286, acc: 0.6444, precision: 0.7882, recall: 0.6806, f1: 0.7304, edges-srl-ontonotes_loss: 0.0197
09/07 09:35:21 PM: ***** Step 16000 / Validation 16 *****
09/07 09:35:21 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:35:21 PM: Validating...
09/07 09:35:23 PM: Evaluate: task edges-srl-ontonotes, batch 36 (157): mcc: 0.7586, acc: 0.7002, precision: 0.8151, recall: 0.7124, f1: 0.7603, edges-srl-ontonotes_loss: 0.0181
09/07 09:35:28 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:35:28 PM: Best result seen so far for macro.
09/07 09:35:28 PM: Updating LR scheduler:
09/07 09:35:28 PM: 	Best result seen so far for macro_avg: 0.763
09/07 09:35:28 PM: 	# validation passes without improvement: 0
09/07 09:35:28 PM: edges-srl-ontonotes_loss: training: 0.019825 validation: 0.017618
09/07 09:35:28 PM: macro_avg: validation: 0.762996
09/07 09:35:28 PM: micro_avg: validation: 0.000000
09/07 09:35:28 PM: edges-srl-ontonotes_mcc: training: 0.726207 validation: 0.761349
09/07 09:35:28 PM: edges-srl-ontonotes_acc: training: 0.641525 validation: 0.702024
09/07 09:35:28 PM: edges-srl-ontonotes_precision: training: 0.785829 validation: 0.817654
09/07 09:35:28 PM: edges-srl-ontonotes_recall: training: 0.678199 validation: 0.715187
09/07 09:35:28 PM: edges-srl-ontonotes_f1: training: 0.728057 validation: 0.762996
09/07 09:35:28 PM: Global learning rate: 0.0001
09/07 09:35:28 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:35:33 PM: Update 16070: task edges-srl-ontonotes, batch 70 (16070): mcc: 0.7227, acc: 0.6336, precision: 0.7826, recall: 0.6747, f1: 0.7246, edges-srl-ontonotes_loss: 0.0202
09/07 09:35:43 PM: Update 16271: task edges-srl-ontonotes, batch 271 (16271): mcc: 0.6940, acc: 0.6024, precision: 0.7622, recall: 0.6395, f1: 0.6955, edges-srl-ontonotes_loss: 0.0218
09/07 09:35:53 PM: Update 16452: task edges-srl-ontonotes, batch 452 (16452): mcc: 0.6939, acc: 0.6010, precision: 0.7643, recall: 0.6376, f1: 0.6952, edges-srl-ontonotes_loss: 0.0218
09/07 09:36:03 PM: Update 16655: task edges-srl-ontonotes, batch 655 (16655): mcc: 0.6955, acc: 0.6031, precision: 0.7670, recall: 0.6382, f1: 0.6967, edges-srl-ontonotes_loss: 0.0217
09/07 09:36:13 PM: Update 16798: task edges-srl-ontonotes, batch 798 (16798): mcc: 0.6971, acc: 0.6054, precision: 0.7675, recall: 0.6407, f1: 0.6984, edges-srl-ontonotes_loss: 0.0216
09/07 09:36:24 PM: Update 16997: task edges-srl-ontonotes, batch 997 (16997): mcc: 0.6992, acc: 0.6083, precision: 0.7679, recall: 0.6441, f1: 0.7006, edges-srl-ontonotes_loss: 0.0214
09/07 09:36:24 PM: ***** Step 17000 / Validation 17 *****
09/07 09:36:24 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:36:24 PM: Validating...
09/07 09:36:31 PM: Updating LR scheduler:
09/07 09:36:31 PM: 	Best result seen so far for macro_avg: 0.763
09/07 09:36:31 PM: 	# validation passes without improvement: 1
09/07 09:36:31 PM: edges-srl-ontonotes_loss: training: 0.021374 validation: 0.018403
09/07 09:36:31 PM: macro_avg: validation: 0.743217
09/07 09:36:31 PM: micro_avg: validation: 0.000000
09/07 09:36:31 PM: edges-srl-ontonotes_mcc: training: 0.699068 validation: 0.742816
09/07 09:36:31 PM: edges-srl-ontonotes_acc: training: 0.608141 validation: 0.670387
09/07 09:36:31 PM: edges-srl-ontonotes_precision: training: 0.767805 validation: 0.817820
09/07 09:36:31 PM: edges-srl-ontonotes_recall: training: 0.644042 validation: 0.681087
09/07 09:36:31 PM: edges-srl-ontonotes_f1: training: 0.700499 validation: 0.743217
09/07 09:36:31 PM: Global learning rate: 0.0001
09/07 09:36:31 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:36:34 PM: Update 17053: task edges-srl-ontonotes, batch 53 (17053): mcc: 0.7110, acc: 0.6265, precision: 0.7739, recall: 0.6605, f1: 0.7127, edges-srl-ontonotes_loss: 0.0206
09/07 09:36:44 PM: Update 17251: task edges-srl-ontonotes, batch 251 (17251): mcc: 0.7172, acc: 0.6330, precision: 0.7779, recall: 0.6686, f1: 0.7191, edges-srl-ontonotes_loss: 0.0203
09/07 09:36:54 PM: Update 17430: task edges-srl-ontonotes, batch 430 (17430): mcc: 0.7192, acc: 0.6346, precision: 0.7798, recall: 0.6704, f1: 0.7210, edges-srl-ontonotes_loss: 0.0202
09/07 09:37:07 PM: Update 17623: task edges-srl-ontonotes, batch 623 (17623): mcc: 0.7228, acc: 0.6389, precision: 0.7836, recall: 0.6738, f1: 0.7246, edges-srl-ontonotes_loss: 0.0200
09/07 09:37:17 PM: Update 17825: task edges-srl-ontonotes, batch 825 (17825): mcc: 0.7184, acc: 0.6334, precision: 0.7804, recall: 0.6686, f1: 0.7202, edges-srl-ontonotes_loss: 0.0203
09/07 09:37:26 PM: ***** Step 18000 / Validation 18 *****
09/07 09:37:26 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:37:26 PM: Validating...
09/07 09:37:27 PM: Evaluate: task edges-srl-ontonotes, batch 6 (157): mcc: 0.7314, acc: 0.6551, precision: 0.8152, recall: 0.6628, f1: 0.7311, edges-srl-ontonotes_loss: 0.0191
09/07 09:37:34 PM: Updating LR scheduler:
09/07 09:37:34 PM: 	Best result seen so far for macro_avg: 0.763
09/07 09:37:34 PM: 	# validation passes without improvement: 2
09/07 09:37:34 PM: edges-srl-ontonotes_loss: training: 0.020371 validation: 0.018736
09/07 09:37:34 PM: macro_avg: validation: 0.740936
09/07 09:37:34 PM: micro_avg: validation: 0.000000
09/07 09:37:34 PM: edges-srl-ontonotes_mcc: training: 0.717376 validation: 0.740154
09/07 09:37:34 PM: edges-srl-ontonotes_acc: training: 0.631541 validation: 0.673312
09/07 09:37:34 PM: edges-srl-ontonotes_precision: training: 0.780034 validation: 0.811115
09/07 09:37:34 PM: edges-srl-ontonotes_recall: training: 0.666997 validation: 0.681934
09/07 09:37:34 PM: edges-srl-ontonotes_f1: training: 0.719101 validation: 0.740936
09/07 09:37:34 PM: Global learning rate: 0.0001
09/07 09:37:34 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:37:37 PM: Update 18064: task edges-srl-ontonotes, batch 64 (18064): mcc: 0.7163, acc: 0.6296, precision: 0.7865, recall: 0.6594, f1: 0.7174, edges-srl-ontonotes_loss: 0.0206
09/07 09:37:47 PM: Update 18249: task edges-srl-ontonotes, batch 249 (18249): mcc: 0.7189, acc: 0.6316, precision: 0.7844, recall: 0.6661, f1: 0.7204, edges-srl-ontonotes_loss: 0.0202
09/07 09:37:57 PM: Update 18452: task edges-srl-ontonotes, batch 452 (18452): mcc: 0.7143, acc: 0.6269, precision: 0.7795, recall: 0.6618, f1: 0.7158, edges-srl-ontonotes_loss: 0.0205
09/07 09:38:07 PM: Update 18596: task edges-srl-ontonotes, batch 596 (18596): mcc: 0.7156, acc: 0.6292, precision: 0.7807, recall: 0.6633, f1: 0.7172, edges-srl-ontonotes_loss: 0.0204
09/07 09:38:17 PM: Update 18798: task edges-srl-ontonotes, batch 798 (18798): mcc: 0.7170, acc: 0.6314, precision: 0.7810, recall: 0.6655, f1: 0.7187, edges-srl-ontonotes_loss: 0.0203
09/07 09:38:27 PM: Update 18978: task edges-srl-ontonotes, batch 978 (18978): mcc: 0.7179, acc: 0.6325, precision: 0.7817, recall: 0.6666, f1: 0.7196, edges-srl-ontonotes_loss: 0.0203
09/07 09:38:28 PM: ***** Step 19000 / Validation 19 *****
09/07 09:38:28 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:38:28 PM: Validating...
09/07 09:38:35 PM: Updating LR scheduler:
09/07 09:38:35 PM: 	Best result seen so far for macro_avg: 0.763
09/07 09:38:35 PM: 	# validation passes without improvement: 3
09/07 09:38:35 PM: edges-srl-ontonotes_loss: training: 0.020289 validation: 0.018978
09/07 09:38:35 PM: macro_avg: validation: 0.741389
09/07 09:38:35 PM: micro_avg: validation: 0.000000
09/07 09:38:35 PM: edges-srl-ontonotes_mcc: training: 0.718152 validation: 0.740056
09/07 09:38:35 PM: edges-srl-ontonotes_acc: training: 0.632772 validation: 0.675622
09/07 09:38:35 PM: edges-srl-ontonotes_precision: training: 0.781773 validation: 0.804268
09/07 09:38:35 PM: edges-srl-ontonotes_recall: training: 0.666915 validation: 0.687630
09/07 09:38:35 PM: edges-srl-ontonotes_f1: training: 0.719791 validation: 0.741389
09/07 09:38:35 PM: Global learning rate: 0.0001
09/07 09:38:35 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:38:37 PM: Update 19031: task edges-srl-ontonotes, batch 31 (19031): mcc: 0.7213, acc: 0.6416, precision: 0.7807, recall: 0.6736, f1: 0.7232, edges-srl-ontonotes_loss: 0.0202
09/07 09:38:47 PM: Update 19210: task edges-srl-ontonotes, batch 210 (19210): mcc: 0.7212, acc: 0.6381, precision: 0.7834, recall: 0.6712, f1: 0.7230, edges-srl-ontonotes_loss: 0.0201
09/07 09:38:57 PM: Update 19415: task edges-srl-ontonotes, batch 415 (19415): mcc: 0.7140, acc: 0.6284, precision: 0.7802, recall: 0.6606, f1: 0.7154, edges-srl-ontonotes_loss: 0.0206
09/07 09:39:07 PM: Update 19597: task edges-srl-ontonotes, batch 597 (19597): mcc: 0.7220, acc: 0.6371, precision: 0.7873, recall: 0.6692, f1: 0.7234, edges-srl-ontonotes_loss: 0.0201
09/07 09:39:17 PM: Update 19799: task edges-srl-ontonotes, batch 799 (19799): mcc: 0.7325, acc: 0.6492, precision: 0.7948, recall: 0.6820, f1: 0.7341, edges-srl-ontonotes_loss: 0.0195
09/07 09:39:27 PM: Update 19943: task edges-srl-ontonotes, batch 943 (19943): mcc: 0.7413, acc: 0.6601, precision: 0.8009, recall: 0.6929, f1: 0.7430, edges-srl-ontonotes_loss: 0.0189
09/07 09:39:30 PM: ***** Step 20000 / Validation 20 *****
09/07 09:39:30 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:39:30 PM: Validating...
09/07 09:39:37 PM: Evaluate: task edges-srl-ontonotes, batch 156 (157): mcc: 0.7479, acc: 0.6879, precision: 0.8054, recall: 0.7011, f1: 0.7496, edges-srl-ontonotes_loss: 0.0188
09/07 09:39:37 PM: Updating LR scheduler:
09/07 09:39:37 PM: 	Best result seen so far for macro_avg: 0.763
09/07 09:39:37 PM: 	# validation passes without improvement: 4
09/07 09:39:37 PM: edges-srl-ontonotes_loss: training: 0.018672 validation: 0.018796
09/07 09:39:37 PM: macro_avg: validation: 0.749599
09/07 09:39:37 PM: micro_avg: validation: 0.000000
09/07 09:39:37 PM: edges-srl-ontonotes_mcc: training: 0.745066 validation: 0.747860
09/07 09:39:37 PM: edges-srl-ontonotes_acc: training: 0.664442 validation: 0.687938
09/07 09:39:37 PM: edges-srl-ontonotes_precision: training: 0.803497 validation: 0.805305
09/07 09:39:37 PM: edges-srl-ontonotes_recall: training: 0.697526 validation: 0.701101
09/07 09:39:37 PM: edges-srl-ontonotes_f1: training: 0.746771 validation: 0.749599
09/07 09:39:37 PM: Global learning rate: 0.0001
09/07 09:39:37 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:39:47 PM: Update 20179: task edges-srl-ontonotes, batch 179 (20179): mcc: 0.8040, acc: 0.7367, precision: 0.8462, recall: 0.7693, f1: 0.8059, edges-srl-ontonotes_loss: 0.0148
09/07 09:39:57 PM: Update 20374: task edges-srl-ontonotes, batch 374 (20374): mcc: 0.7987, acc: 0.7299, precision: 0.8414, recall: 0.7637, f1: 0.8007, edges-srl-ontonotes_loss: 0.0150
09/07 09:40:07 PM: Update 20553: task edges-srl-ontonotes, batch 553 (20553): mcc: 0.7998, acc: 0.7323, precision: 0.8416, recall: 0.7656, f1: 0.8018, edges-srl-ontonotes_loss: 0.0150
09/07 09:40:17 PM: Update 20752: task edges-srl-ontonotes, batch 752 (20752): mcc: 0.8031, acc: 0.7371, precision: 0.8441, recall: 0.7695, f1: 0.8051, edges-srl-ontonotes_loss: 0.0148
09/07 09:40:27 PM: Update 20895: task edges-srl-ontonotes, batch 895 (20895): mcc: 0.8082, acc: 0.7440, precision: 0.8482, recall: 0.7753, f1: 0.8101, edges-srl-ontonotes_loss: 0.0146
09/07 09:40:33 PM: ***** Step 21000 / Validation 21 *****
09/07 09:40:33 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:40:33 PM: Validating...
09/07 09:40:37 PM: Evaluate: task edges-srl-ontonotes, batch 100 (157): mcc: 0.7603, acc: 0.7010, precision: 0.8194, recall: 0.7117, f1: 0.7618, edges-srl-ontonotes_loss: 0.0182
09/07 09:40:40 PM: Updating LR scheduler:
09/07 09:40:40 PM: 	Best result seen so far for macro_avg: 0.763
09/07 09:40:40 PM: 	# validation passes without improvement: 5
09/07 09:40:40 PM: edges-srl-ontonotes_loss: training: 0.014481 validation: 0.018608
09/07 09:40:40 PM: macro_avg: validation: 0.753620
09/07 09:40:40 PM: micro_avg: validation: 0.000000
09/07 09:40:40 PM: edges-srl-ontonotes_mcc: training: 0.811423 validation: 0.752098
09/07 09:40:40 PM: edges-srl-ontonotes_acc: training: 0.748565 validation: 0.691479
09/07 09:40:40 PM: edges-srl-ontonotes_precision: training: 0.850916 validation: 0.811856
09/07 09:40:40 PM: edges-srl-ontonotes_recall: training: 0.778964 validation: 0.703179
09/07 09:40:40 PM: edges-srl-ontonotes_f1: training: 0.813351 validation: 0.753620
09/07 09:40:40 PM: Global learning rate: 0.0001
09/07 09:40:40 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:40:47 PM: Update 21130: task edges-srl-ontonotes, batch 130 (21130): mcc: 0.7995, acc: 0.7367, precision: 0.8440, recall: 0.7629, f1: 0.8014, edges-srl-ontonotes_loss: 0.0155
09/07 09:40:57 PM: Update 21329: task edges-srl-ontonotes, batch 329 (21329): mcc: 0.7685, acc: 0.6981, precision: 0.8178, recall: 0.7284, f1: 0.7705, edges-srl-ontonotes_loss: 0.0173
09/07 09:41:07 PM: Update 21508: task edges-srl-ontonotes, batch 508 (21508): mcc: 0.7517, acc: 0.6767, precision: 0.8039, recall: 0.7094, f1: 0.7537, edges-srl-ontonotes_loss: 0.0184
09/07 09:41:18 PM: Update 21703: task edges-srl-ontonotes, batch 703 (21703): mcc: 0.7424, acc: 0.6642, precision: 0.7980, recall: 0.6974, f1: 0.7443, edges-srl-ontonotes_loss: 0.0189
09/07 09:41:28 PM: Update 21844: task edges-srl-ontonotes, batch 844 (21844): mcc: 0.7434, acc: 0.6648, precision: 0.8000, recall: 0.6975, f1: 0.7452, edges-srl-ontonotes_loss: 0.0188
09/07 09:41:36 PM: ***** Step 22000 / Validation 22 *****
09/07 09:41:36 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:41:36 PM: Validating...
09/07 09:41:38 PM: Evaluate: task edges-srl-ontonotes, batch 42 (157): mcc: 0.7603, acc: 0.6921, precision: 0.8290, recall: 0.7034, f1: 0.7611, edges-srl-ontonotes_loss: 0.0180
09/07 09:41:43 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:41:43 PM: Best result seen so far for macro.
09/07 09:41:43 PM: Updating LR scheduler:
09/07 09:41:43 PM: 	Best result seen so far for macro_avg: 0.770
09/07 09:41:43 PM: 	# validation passes without improvement: 0
09/07 09:41:43 PM: edges-srl-ontonotes_loss: training: 0.018526 validation: 0.017105
09/07 09:41:43 PM: macro_avg: validation: 0.770129
09/07 09:41:43 PM: micro_avg: validation: 0.000000
09/07 09:41:43 PM: edges-srl-ontonotes_mcc: training: 0.747566 validation: 0.769162
09/07 09:41:43 PM: edges-srl-ontonotes_acc: training: 0.669356 validation: 0.705181
09/07 09:41:43 PM: edges-srl-ontonotes_precision: training: 0.803548 validation: 0.833587
09/07 09:41:43 PM: edges-srl-ontonotes_recall: training: 0.702106 validation: 0.715649
09/07 09:41:43 PM: edges-srl-ontonotes_f1: training: 0.749410 validation: 0.770129
09/07 09:41:43 PM: Global learning rate: 0.0001
09/07 09:41:43 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:41:48 PM: Update 22072: task edges-srl-ontonotes, batch 72 (22072): mcc: 0.7646, acc: 0.6897, precision: 0.8166, recall: 0.7222, f1: 0.7665, edges-srl-ontonotes_loss: 0.0176
09/07 09:41:58 PM: Update 22268: task edges-srl-ontonotes, batch 268 (22268): mcc: 0.7746, acc: 0.7003, precision: 0.8255, recall: 0.7329, f1: 0.7764, edges-srl-ontonotes_loss: 0.0167
09/07 09:42:08 PM: Update 22446: task edges-srl-ontonotes, batch 446 (22446): mcc: 0.7689, acc: 0.6936, precision: 0.8214, recall: 0.7259, f1: 0.7707, edges-srl-ontonotes_loss: 0.0172
09/07 09:42:18 PM: Update 22647: task edges-srl-ontonotes, batch 647 (22647): mcc: 0.7608, acc: 0.6844, precision: 0.8148, recall: 0.7167, f1: 0.7626, edges-srl-ontonotes_loss: 0.0177
09/07 09:42:28 PM: Update 22795: task edges-srl-ontonotes, batch 795 (22795): mcc: 0.7541, acc: 0.6763, precision: 0.8092, recall: 0.7092, f1: 0.7559, edges-srl-ontonotes_loss: 0.0181
09/07 09:42:38 PM: Update 22991: task edges-srl-ontonotes, batch 991 (22991): mcc: 0.7480, acc: 0.6692, precision: 0.8042, recall: 0.7023, f1: 0.7498, edges-srl-ontonotes_loss: 0.0185
09/07 09:42:39 PM: ***** Step 23000 / Validation 23 *****
09/07 09:42:39 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:42:39 PM: Validating...
09/07 09:42:46 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:42:46 PM: Best result seen so far for macro.
09/07 09:42:46 PM: Updating LR scheduler:
09/07 09:42:46 PM: 	Best result seen so far for macro_avg: 0.773
09/07 09:42:46 PM: 	# validation passes without improvement: 0
09/07 09:42:46 PM: edges-srl-ontonotes_loss: training: 0.018528 validation: 0.016785
09/07 09:42:46 PM: macro_avg: validation: 0.772744
09/07 09:42:46 PM: micro_avg: validation: 0.000000
09/07 09:42:46 PM: edges-srl-ontonotes_mcc: training: 0.747752 validation: 0.771745
09/07 09:42:46 PM: edges-srl-ontonotes_acc: training: 0.668877 validation: 0.708644
09/07 09:42:46 PM: edges-srl-ontonotes_precision: training: 0.804042 validation: 0.835331
09/07 09:42:46 PM: edges-srl-ontonotes_recall: training: 0.702014 validation: 0.718882
09/07 09:42:46 PM: edges-srl-ontonotes_f1: training: 0.749572 validation: 0.772744
09/07 09:42:46 PM: Global learning rate: 0.0001
09/07 09:42:46 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:42:48 PM: Update 23049: task edges-srl-ontonotes, batch 49 (23049): mcc: 0.7184, acc: 0.6331, precision: 0.7790, recall: 0.6698, f1: 0.7203, edges-srl-ontonotes_loss: 0.0197
09/07 09:42:58 PM: Update 23255: task edges-srl-ontonotes, batch 255 (23255): mcc: 0.7241, acc: 0.6397, precision: 0.7841, recall: 0.6758, f1: 0.7260, edges-srl-ontonotes_loss: 0.0196
09/07 09:43:08 PM: Update 23435: task edges-srl-ontonotes, batch 435 (23435): mcc: 0.7161, acc: 0.6306, precision: 0.7770, recall: 0.6673, f1: 0.7180, edges-srl-ontonotes_loss: 0.0202
09/07 09:43:18 PM: Update 23617: task edges-srl-ontonotes, batch 617 (23617): mcc: 0.7114, acc: 0.6250, precision: 0.7751, recall: 0.6604, f1: 0.7131, edges-srl-ontonotes_loss: 0.0206
09/07 09:43:28 PM: Update 23820: task edges-srl-ontonotes, batch 820 (23820): mcc: 0.7103, acc: 0.6233, precision: 0.7757, recall: 0.6577, f1: 0.7119, edges-srl-ontonotes_loss: 0.0207
09/07 09:43:38 PM: Update 23963: task edges-srl-ontonotes, batch 963 (23963): mcc: 0.7087, acc: 0.6214, precision: 0.7747, recall: 0.6556, f1: 0.7102, edges-srl-ontonotes_loss: 0.0208
09/07 09:43:40 PM: ***** Step 24000 / Validation 24 *****
09/07 09:43:40 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:43:40 PM: Validating...
09/07 09:43:47 PM: Updating LR scheduler:
09/07 09:43:47 PM: 	Best result seen so far for macro_avg: 0.773
09/07 09:43:47 PM: 	# validation passes without improvement: 1
09/07 09:43:47 PM: edges-srl-ontonotes_loss: training: 0.020780 validation: 0.017713
09/07 09:43:47 PM: macro_avg: validation: 0.754154
09/07 09:43:47 PM: micro_avg: validation: 0.000000
09/07 09:43:47 PM: edges-srl-ontonotes_mcc: training: 0.708638 validation: 0.753492
09/07 09:43:47 PM: edges-srl-ontonotes_acc: training: 0.621467 validation: 0.686090
09/07 09:43:47 PM: edges-srl-ontonotes_precision: training: 0.774382 validation: 0.824072
09/07 09:43:47 PM: edges-srl-ontonotes_recall: training: 0.655869 validation: 0.695174
09/07 09:43:47 PM: edges-srl-ontonotes_f1: training: 0.710215 validation: 0.754154
09/07 09:43:47 PM: Global learning rate: 0.0001
09/07 09:43:47 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:43:48 PM: Update 24019: task edges-srl-ontonotes, batch 19 (24019): mcc: 0.7327, acc: 0.6462, precision: 0.7988, recall: 0.6788, f1: 0.7339, edges-srl-ontonotes_loss: 0.0192
09/07 09:43:58 PM: Update 24219: task edges-srl-ontonotes, batch 219 (24219): mcc: 0.7182, acc: 0.6336, precision: 0.7803, recall: 0.6683, f1: 0.7200, edges-srl-ontonotes_loss: 0.0200
09/07 09:44:08 PM: Update 24398: task edges-srl-ontonotes, batch 398 (24398): mcc: 0.7207, acc: 0.6368, precision: 0.7817, recall: 0.6717, f1: 0.7226, edges-srl-ontonotes_loss: 0.0199
09/07 09:44:18 PM: Update 24577: task edges-srl-ontonotes, batch 577 (24577): mcc: 0.7250, acc: 0.6419, precision: 0.7856, recall: 0.6762, f1: 0.7268, edges-srl-ontonotes_loss: 0.0198
09/07 09:44:28 PM: Update 24775: task edges-srl-ontonotes, batch 775 (24775): mcc: 0.7272, acc: 0.6451, precision: 0.7871, recall: 0.6789, f1: 0.7290, edges-srl-ontonotes_loss: 0.0197
09/07 09:44:39 PM: Update 24918: task edges-srl-ontonotes, batch 918 (24918): mcc: 0.7281, acc: 0.6460, precision: 0.7881, recall: 0.6798, f1: 0.7299, edges-srl-ontonotes_loss: 0.0197
09/07 09:44:43 PM: ***** Step 25000 / Validation 25 *****
09/07 09:44:43 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:44:43 PM: Validating...
09/07 09:44:49 PM: Evaluate: task edges-srl-ontonotes, batch 128 (157): mcc: 0.7593, acc: 0.6964, precision: 0.8245, recall: 0.7053, f1: 0.7603, edges-srl-ontonotes_loss: 0.0176
09/07 09:44:50 PM: Updating LR scheduler:
09/07 09:44:50 PM: 	Best result seen so far for macro_avg: 0.773
09/07 09:44:50 PM: 	# validation passes without improvement: 2
09/07 09:44:50 PM: edges-srl-ontonotes_loss: training: 0.019762 validation: 0.018010
09/07 09:44:50 PM: macro_avg: validation: 0.754690
09/07 09:44:50 PM: micro_avg: validation: 0.000000
09/07 09:44:50 PM: edges-srl-ontonotes_mcc: training: 0.726917 validation: 0.753605
09/07 09:44:50 PM: edges-srl-ontonotes_acc: training: 0.644511 validation: 0.689939
09/07 09:44:50 PM: edges-srl-ontonotes_precision: training: 0.787358 validation: 0.818935
09/07 09:44:50 PM: edges-srl-ontonotes_recall: training: 0.678172 validation: 0.699792
09/07 09:44:50 PM: edges-srl-ontonotes_f1: training: 0.728698 validation: 0.754690
09/07 09:44:50 PM: Global learning rate: 0.0001
09/07 09:44:50 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:44:59 PM: Update 25177: task edges-srl-ontonotes, batch 177 (25177): mcc: 0.7230, acc: 0.6403, precision: 0.7834, recall: 0.6744, f1: 0.7248, edges-srl-ontonotes_loss: 0.0200
09/07 09:45:09 PM: Update 25357: task edges-srl-ontonotes, batch 357 (25357): mcc: 0.7246, acc: 0.6420, precision: 0.7857, recall: 0.6753, f1: 0.7264, edges-srl-ontonotes_loss: 0.0199
09/07 09:45:19 PM: Update 25540: task edges-srl-ontonotes, batch 540 (25540): mcc: 0.7240, acc: 0.6406, precision: 0.7854, recall: 0.6745, f1: 0.7257, edges-srl-ontonotes_loss: 0.0199
09/07 09:45:29 PM: Update 25745: task edges-srl-ontonotes, batch 745 (25745): mcc: 0.7246, acc: 0.6417, precision: 0.7862, recall: 0.6748, f1: 0.7263, edges-srl-ontonotes_loss: 0.0199
09/07 09:45:39 PM: Update 25924: task edges-srl-ontonotes, batch 924 (25924): mcc: 0.7254, acc: 0.6423, precision: 0.7867, recall: 0.6759, f1: 0.7271, edges-srl-ontonotes_loss: 0.0199
09/07 09:45:42 PM: ***** Step 26000 / Validation 26 *****
09/07 09:45:42 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:45:42 PM: Validating...
09/07 09:45:49 PM: Evaluate: task edges-srl-ontonotes, batch 134 (157): mcc: 0.7496, acc: 0.6895, precision: 0.8121, recall: 0.6983, f1: 0.7509, edges-srl-ontonotes_loss: 0.0181
09/07 09:45:50 PM: Updating LR scheduler:
09/07 09:45:50 PM: 	Best result seen so far for macro_avg: 0.773
09/07 09:45:50 PM: 	# validation passes without improvement: 3
09/07 09:45:50 PM: edges-srl-ontonotes_loss: training: 0.019830 validation: 0.018414
09/07 09:45:50 PM: macro_avg: validation: 0.747919
09/07 09:45:50 PM: micro_avg: validation: 0.000000
09/07 09:45:50 PM: edges-srl-ontonotes_mcc: training: 0.725785 validation: 0.746560
09/07 09:45:50 PM: edges-srl-ontonotes_acc: training: 0.642937 validation: 0.686090
09/07 09:45:50 PM: edges-srl-ontonotes_precision: training: 0.786738 validation: 0.809430
09/07 09:45:50 PM: edges-srl-ontonotes_recall: training: 0.676628 validation: 0.695097
09/07 09:45:50 PM: edges-srl-ontonotes_f1: training: 0.727540 validation: 0.747919
09/07 09:45:50 PM: Global learning rate: 0.0001
09/07 09:45:50 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:45:59 PM: Update 26121: task edges-srl-ontonotes, batch 121 (26121): mcc: 0.7267, acc: 0.6460, precision: 0.7855, recall: 0.6795, f1: 0.7287, edges-srl-ontonotes_loss: 0.0199
09/07 09:46:09 PM: Update 26319: task edges-srl-ontonotes, batch 319 (26319): mcc: 0.7305, acc: 0.6497, precision: 0.7887, recall: 0.6836, f1: 0.7324, edges-srl-ontonotes_loss: 0.0196
09/07 09:46:19 PM: Update 26496: task edges-srl-ontonotes, batch 496 (26496): mcc: 0.7276, acc: 0.6459, precision: 0.7882, recall: 0.6788, f1: 0.7294, edges-srl-ontonotes_loss: 0.0198
09/07 09:46:29 PM: Update 26698: task edges-srl-ontonotes, batch 698 (26698): mcc: 0.7264, acc: 0.6440, precision: 0.7875, recall: 0.6771, f1: 0.7281, edges-srl-ontonotes_loss: 0.0199
09/07 09:46:39 PM: Update 26877: task edges-srl-ontonotes, batch 877 (26877): mcc: 0.7321, acc: 0.6506, precision: 0.7925, recall: 0.6833, f1: 0.7338, edges-srl-ontonotes_loss: 0.0195
09/07 09:46:45 PM: ***** Step 27000 / Validation 27 *****
09/07 09:46:45 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:46:45 PM: Validating...
09/07 09:46:49 PM: Evaluate: task edges-srl-ontonotes, batch 80 (157): mcc: 0.7565, acc: 0.6943, precision: 0.8185, recall: 0.7054, f1: 0.7578, edges-srl-ontonotes_loss: 0.0183
09/07 09:46:52 PM: Updating LR scheduler:
09/07 09:46:52 PM: 	Best result seen so far for macro_avg: 0.773
09/07 09:46:52 PM: 	# validation passes without improvement: 4
09/07 09:46:52 PM: edges-srl-ontonotes_loss: training: 0.019150 validation: 0.018107
09/07 09:46:52 PM: macro_avg: validation: 0.758837
09/07 09:46:52 PM: micro_avg: validation: 0.000000
09/07 09:46:52 PM: edges-srl-ontonotes_mcc: training: 0.738024 validation: 0.757399
09/07 09:46:52 PM: edges-srl-ontonotes_acc: training: 0.657208 validation: 0.696482
09/07 09:46:52 PM: edges-srl-ontonotes_precision: training: 0.796979 validation: 0.817398
09/07 09:46:52 PM: edges-srl-ontonotes_recall: training: 0.690239 validation: 0.708106
09/07 09:46:52 PM: edges-srl-ontonotes_f1: training: 0.739778 validation: 0.758837
09/07 09:46:52 PM: Global learning rate: 0.0001
09/07 09:46:52 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:46:59 PM: Update 27073: task edges-srl-ontonotes, batch 73 (27073): mcc: 0.7796, acc: 0.7058, precision: 0.8243, recall: 0.7434, f1: 0.7818, edges-srl-ontonotes_loss: 0.0165
09/07 09:47:09 PM: Update 27270: task edges-srl-ontonotes, batch 270 (27270): mcc: 0.7981, acc: 0.7307, precision: 0.8394, recall: 0.7643, f1: 0.8001, edges-srl-ontonotes_loss: 0.0150
09/07 09:47:19 PM: Update 27446: task edges-srl-ontonotes, batch 446 (27446): mcc: 0.7998, acc: 0.7331, precision: 0.8400, recall: 0.7671, f1: 0.8019, edges-srl-ontonotes_loss: 0.0149
09/07 09:47:29 PM: Update 27640: task edges-srl-ontonotes, batch 640 (27640): mcc: 0.8013, acc: 0.7347, precision: 0.8417, recall: 0.7684, f1: 0.8034, edges-srl-ontonotes_loss: 0.0148
09/07 09:47:39 PM: Update 27817: task edges-srl-ontonotes, batch 817 (27817): mcc: 0.8031, acc: 0.7374, precision: 0.8434, recall: 0.7702, f1: 0.8052, edges-srl-ontonotes_loss: 0.0147
09/07 09:47:49 PM: Update 27999: task edges-srl-ontonotes, batch 999 (27999): mcc: 0.8059, acc: 0.7415, precision: 0.8449, recall: 0.7740, f1: 0.8079, edges-srl-ontonotes_loss: 0.0145
09/07 09:47:49 PM: ***** Step 28000 / Validation 28 *****
09/07 09:47:49 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:47:49 PM: Validating...
09/07 09:47:58 PM: Updating LR scheduler:
09/07 09:47:58 PM: 	Best result seen so far for macro_avg: 0.773
09/07 09:47:58 PM: 	# validation passes without improvement: 5
09/07 09:47:58 PM: edges-srl-ontonotes_loss: training: 0.014518 validation: 0.017982
09/07 09:47:58 PM: macro_avg: validation: 0.760444
09/07 09:47:58 PM: micro_avg: validation: 0.000000
09/07 09:47:58 PM: edges-srl-ontonotes_mcc: training: 0.805849 validation: 0.758665
09/07 09:47:58 PM: edges-srl-ontonotes_acc: training: 0.741437 validation: 0.700100
09/07 09:47:58 PM: edges-srl-ontonotes_precision: training: 0.844902 validation: 0.813509
09/07 09:47:58 PM: edges-srl-ontonotes_recall: training: 0.773959 validation: 0.713879
09/07 09:47:58 PM: edges-srl-ontonotes_f1: training: 0.807876 validation: 0.760444
09/07 09:47:58 PM: Global learning rate: 0.0001
09/07 09:47:58 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:47:59 PM: Update 28019: task edges-srl-ontonotes, batch 19 (28019): mcc: 0.8156, acc: 0.7533, precision: 0.8626, recall: 0.7761, f1: 0.8171, edges-srl-ontonotes_loss: 0.0146
09/07 09:48:09 PM: Update 28214: task edges-srl-ontonotes, batch 214 (28214): mcc: 0.8350, acc: 0.7824, precision: 0.8707, recall: 0.8054, f1: 0.8368, edges-srl-ontonotes_loss: 0.0133
09/07 09:48:19 PM: Update 28393: task edges-srl-ontonotes, batch 393 (28393): mcc: 0.8201, acc: 0.7636, precision: 0.8588, recall: 0.7881, f1: 0.8220, edges-srl-ontonotes_loss: 0.0142
09/07 09:48:29 PM: Update 28596: task edges-srl-ontonotes, batch 596 (28596): mcc: 0.7989, acc: 0.7365, precision: 0.8420, recall: 0.7634, f1: 0.8008, edges-srl-ontonotes_loss: 0.0154
09/07 09:48:39 PM: Update 28772: task edges-srl-ontonotes, batch 772 (28772): mcc: 0.7823, acc: 0.7157, precision: 0.8288, recall: 0.7442, f1: 0.7842, edges-srl-ontonotes_loss: 0.0165
09/07 09:48:50 PM: Update 28963: task edges-srl-ontonotes, batch 963 (28963): mcc: 0.7705, acc: 0.7002, precision: 0.8203, recall: 0.7299, f1: 0.7724, edges-srl-ontonotes_loss: 0.0172
09/07 09:48:52 PM: ***** Step 29000 / Validation 29 *****
09/07 09:48:52 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:48:52 PM: Validating...
09/07 09:49:00 PM: Evaluate: task edges-srl-ontonotes, batch 155 (157): mcc: 0.7675, acc: 0.7112, precision: 0.8232, recall: 0.7216, f1: 0.7691, edges-srl-ontonotes_loss: 0.0173
09/07 09:49:00 PM: Updating LR scheduler:
09/07 09:49:00 PM: 	Best result seen so far for macro_avg: 0.773
09/07 09:49:00 PM: 	# validation passes without improvement: 0
09/07 09:49:00 PM: edges-srl-ontonotes_loss: training: 0.017209 validation: 0.017343
09/07 09:49:00 PM: macro_avg: validation: 0.768909
09/07 09:49:00 PM: micro_avg: validation: 0.000000
09/07 09:49:00 PM: edges-srl-ontonotes_mcc: training: 0.769722 validation: 0.767297
09/07 09:49:00 PM: edges-srl-ontonotes_acc: training: 0.699140 validation: 0.711108
09/07 09:49:00 PM: edges-srl-ontonotes_precision: training: 0.819926 validation: 0.822987
09/07 09:49:00 PM: edges-srl-ontonotes_recall: training: 0.728744 validation: 0.721500
09/07 09:49:00 PM: edges-srl-ontonotes_f1: training: 0.771651 validation: 0.768909
09/07 09:49:00 PM: Global learning rate: 5e-05
09/07 09:49:00 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:49:10 PM: Update 29194: task edges-srl-ontonotes, batch 194 (29194): mcc: 0.7665, acc: 0.6918, precision: 0.8212, recall: 0.7217, f1: 0.7682, edges-srl-ontonotes_loss: 0.0172
09/07 09:49:20 PM: Update 29333: task edges-srl-ontonotes, batch 333 (29333): mcc: 0.7687, acc: 0.6949, precision: 0.8225, recall: 0.7246, f1: 0.7704, edges-srl-ontonotes_loss: 0.0171
09/07 09:49:30 PM: Update 29532: task edges-srl-ontonotes, batch 532 (29532): mcc: 0.7719, acc: 0.6989, precision: 0.8240, recall: 0.7292, f1: 0.7737, edges-srl-ontonotes_loss: 0.0168
09/07 09:49:40 PM: Update 29712: task edges-srl-ontonotes, batch 712 (29712): mcc: 0.7662, acc: 0.6922, precision: 0.8193, recall: 0.7228, f1: 0.7680, edges-srl-ontonotes_loss: 0.0172
09/07 09:49:50 PM: Update 29916: task edges-srl-ontonotes, batch 916 (29916): mcc: 0.7619, acc: 0.6873, precision: 0.8151, recall: 0.7184, f1: 0.7637, edges-srl-ontonotes_loss: 0.0175
09/07 09:49:55 PM: ***** Step 30000 / Validation 30 *****
09/07 09:49:55 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:49:55 PM: Validating...
09/07 09:50:00 PM: Evaluate: task edges-srl-ontonotes, batch 105 (157): mcc: 0.7885, acc: 0.7304, precision: 0.8460, recall: 0.7405, f1: 0.7897, edges-srl-ontonotes_loss: 0.0161
09/07 09:50:02 PM: Best result seen so far for edges-srl-ontonotes.
09/07 09:50:02 PM: Best result seen so far for macro.
09/07 09:50:02 PM: Updating LR scheduler:
09/07 09:50:02 PM: 	Best result seen so far for macro_avg: 0.780
09/07 09:50:02 PM: 	# validation passes without improvement: 0
09/07 09:50:02 PM: edges-srl-ontonotes_loss: training: 0.017665 validation: 0.016556
09/07 09:50:02 PM: macro_avg: validation: 0.779724
09/07 09:50:02 PM: micro_avg: validation: 0.000000
09/07 09:50:02 PM: edges-srl-ontonotes_mcc: training: 0.759169 validation: 0.778432
09/07 09:50:02 PM: edges-srl-ontonotes_acc: training: 0.684255 validation: 0.719575
09/07 09:50:02 PM: edges-srl-ontonotes_precision: training: 0.812627 validation: 0.836760
09/07 09:50:02 PM: edges-srl-ontonotes_recall: training: 0.715599 validation: 0.729967
09/07 09:50:02 PM: edges-srl-ontonotes_f1: training: 0.761033 validation: 0.779724
09/07 09:50:02 PM: Global learning rate: 5e-05
09/07 09:50:02 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:50:10 PM: Update 30160: task edges-srl-ontonotes, batch 160 (30160): mcc: 0.7281, acc: 0.6434, precision: 0.7872, recall: 0.6804, f1: 0.7299, edges-srl-ontonotes_loss: 0.0194
09/07 09:50:20 PM: Update 30308: task edges-srl-ontonotes, batch 308 (30308): mcc: 0.7243, acc: 0.6404, precision: 0.7837, recall: 0.6765, f1: 0.7262, edges-srl-ontonotes_loss: 0.0197
09/07 09:50:30 PM: Update 30515: task edges-srl-ontonotes, batch 515 (30515): mcc: 0.7273, acc: 0.6429, precision: 0.7853, recall: 0.6807, f1: 0.7292, edges-srl-ontonotes_loss: 0.0195
09/07 09:50:40 PM: Update 30696: task edges-srl-ontonotes, batch 696 (30696): mcc: 0.7216, acc: 0.6361, precision: 0.7814, recall: 0.6736, f1: 0.7235, edges-srl-ontonotes_loss: 0.0199
09/07 09:50:50 PM: Update 30876: task edges-srl-ontonotes, batch 876 (30876): mcc: 0.7174, acc: 0.6316, precision: 0.7784, recall: 0.6685, f1: 0.7193, edges-srl-ontonotes_loss: 0.0201
09/07 09:50:56 PM: ***** Step 31000 / Validation 31 *****
09/07 09:50:56 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:50:56 PM: Validating...
09/07 09:51:00 PM: Evaluate: task edges-srl-ontonotes, batch 84 (157): mcc: 0.7674, acc: 0.7019, precision: 0.8348, recall: 0.7113, f1: 0.7681, edges-srl-ontonotes_loss: 0.0170
09/07 09:51:03 PM: Updating LR scheduler:
09/07 09:51:03 PM: 	Best result seen so far for macro_avg: 0.780
09/07 09:51:03 PM: 	# validation passes without improvement: 1
09/07 09:51:03 PM: edges-srl-ontonotes_loss: training: 0.020223 validation: 0.016855
09/07 09:51:03 PM: macro_avg: validation: 0.769696
09/07 09:51:03 PM: micro_avg: validation: 0.000000
09/07 09:51:03 PM: edges-srl-ontonotes_mcc: training: 0.716975 validation: 0.768764
09/07 09:51:03 PM: edges-srl-ontonotes_acc: training: 0.631150 validation: 0.704488
09/07 09:51:03 PM: edges-srl-ontonotes_precision: training: 0.778522 validation: 0.833722
09/07 09:51:03 PM: edges-srl-ontonotes_recall: training: 0.667573 validation: 0.714803
09/07 09:51:03 PM: edges-srl-ontonotes_f1: training: 0.718791 validation: 0.769696
09/07 09:51:03 PM: Global learning rate: 5e-05
09/07 09:51:03 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:51:10 PM: Update 31137: task edges-srl-ontonotes, batch 137 (31137): mcc: 0.7157, acc: 0.6299, precision: 0.7825, recall: 0.6618, f1: 0.7171, edges-srl-ontonotes_loss: 0.0205
09/07 09:51:20 PM: Update 31280: task edges-srl-ontonotes, batch 280 (31280): mcc: 0.7182, acc: 0.6339, precision: 0.7829, recall: 0.6661, f1: 0.7198, edges-srl-ontonotes_loss: 0.0202
09/07 09:51:30 PM: Update 31480: task edges-srl-ontonotes, batch 480 (31480): mcc: 0.7215, acc: 0.6376, precision: 0.7834, recall: 0.6716, f1: 0.7232, edges-srl-ontonotes_loss: 0.0199
09/07 09:51:40 PM: Update 31657: task edges-srl-ontonotes, batch 657 (31657): mcc: 0.7229, acc: 0.6393, precision: 0.7843, recall: 0.6735, f1: 0.7247, edges-srl-ontonotes_loss: 0.0198
09/07 09:51:50 PM: Update 31837: task edges-srl-ontonotes, batch 837 (31837): mcc: 0.7256, acc: 0.6428, precision: 0.7852, recall: 0.6776, f1: 0.7274, edges-srl-ontonotes_loss: 0.0197
09/07 09:51:58 PM: ***** Step 32000 / Validation 32 *****
09/07 09:51:58 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:51:58 PM: Validating...
09/07 09:52:00 PM: Evaluate: task edges-srl-ontonotes, batch 41 (157): mcc: 0.7543, acc: 0.6916, precision: 0.8170, recall: 0.7027, f1: 0.7555, edges-srl-ontonotes_loss: 0.0180
09/07 09:52:05 PM: Updating LR scheduler:
09/07 09:52:05 PM: 	Best result seen so far for macro_avg: 0.780
09/07 09:52:05 PM: 	# validation passes without improvement: 2
09/07 09:52:05 PM: edges-srl-ontonotes_loss: training: 0.019585 validation: 0.017355
09/07 09:52:05 PM: macro_avg: validation: 0.762800
09/07 09:52:05 PM: micro_avg: validation: 0.000000
09/07 09:52:05 PM: edges-srl-ontonotes_mcc: training: 0.727407 validation: 0.761394
09/07 09:52:05 PM: edges-srl-ontonotes_acc: training: 0.644955 validation: 0.701178
09/07 09:52:05 PM: edges-srl-ontonotes_precision: training: 0.786896 validation: 0.821159
09/07 09:52:05 PM: edges-srl-ontonotes_recall: training: 0.679478 validation: 0.712185
09/07 09:52:05 PM: edges-srl-ontonotes_f1: training: 0.729253 validation: 0.762800
09/07 09:52:05 PM: Global learning rate: 5e-05
09/07 09:52:05 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:52:10 PM: Update 32094: task edges-srl-ontonotes, batch 94 (32094): mcc: 0.7409, acc: 0.6603, precision: 0.7959, recall: 0.6965, f1: 0.7429, edges-srl-ontonotes_loss: 0.0189
09/07 09:52:20 PM: Update 32274: task edges-srl-ontonotes, batch 274 (32274): mcc: 0.7307, acc: 0.6494, precision: 0.7882, recall: 0.6844, f1: 0.7327, edges-srl-ontonotes_loss: 0.0196
09/07 09:52:31 PM: Update 32428: task edges-srl-ontonotes, batch 428 (32428): mcc: 0.7289, acc: 0.6469, precision: 0.7871, recall: 0.6820, f1: 0.7308, edges-srl-ontonotes_loss: 0.0197
09/07 09:52:41 PM: Update 32629: task edges-srl-ontonotes, batch 629 (32629): mcc: 0.7290, acc: 0.6474, precision: 0.7880, recall: 0.6814, f1: 0.7308, edges-srl-ontonotes_loss: 0.0197
09/07 09:52:51 PM: Update 32807: task edges-srl-ontonotes, batch 807 (32807): mcc: 0.7287, acc: 0.6473, precision: 0.7878, recall: 0.6811, f1: 0.7306, edges-srl-ontonotes_loss: 0.0196
09/07 09:53:00 PM: ***** Step 33000 / Validation 33 *****
09/07 09:53:00 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:53:00 PM: Validating...
09/07 09:53:01 PM: Evaluate: task edges-srl-ontonotes, batch 11 (157): mcc: 0.7569, acc: 0.6883, precision: 0.8287, recall: 0.6975, f1: 0.7574, edges-srl-ontonotes_loss: 0.0181
09/07 09:53:07 PM: Updating LR scheduler:
09/07 09:53:07 PM: 	Best result seen so far for macro_avg: 0.780
09/07 09:53:07 PM: 	# validation passes without improvement: 3
09/07 09:53:07 PM: edges-srl-ontonotes_loss: training: 0.019584 validation: 0.017842
09/07 09:53:07 PM: macro_avg: validation: 0.757593
09/07 09:53:07 PM: micro_avg: validation: 0.000000
09/07 09:53:07 PM: edges-srl-ontonotes_mcc: training: 0.729082 validation: 0.756348
09/07 09:53:07 PM: edges-srl-ontonotes_acc: training: 0.647705 validation: 0.696097
09/07 09:53:07 PM: edges-srl-ontonotes_precision: training: 0.788196 validation: 0.819150
09/07 09:53:07 PM: edges-srl-ontonotes_recall: training: 0.681429 validation: 0.704642
09/07 09:53:07 PM: edges-srl-ontonotes_f1: training: 0.730934 validation: 0.757593
09/07 09:53:07 PM: Global learning rate: 5e-05
09/07 09:53:07 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:53:11 PM: Update 33054: task edges-srl-ontonotes, batch 54 (33054): mcc: 0.7184, acc: 0.6371, precision: 0.7793, recall: 0.6696, f1: 0.7203, edges-srl-ontonotes_loss: 0.0202
09/07 09:53:21 PM: Update 33253: task edges-srl-ontonotes, batch 253 (33253): mcc: 0.7289, acc: 0.6486, precision: 0.7882, recall: 0.6810, f1: 0.7307, edges-srl-ontonotes_loss: 0.0195
09/07 09:53:31 PM: Update 33395: task edges-srl-ontonotes, batch 395 (33395): mcc: 0.7301, acc: 0.6502, precision: 0.7894, recall: 0.6822, f1: 0.7319, edges-srl-ontonotes_loss: 0.0194
09/07 09:53:41 PM: Update 33594: task edges-srl-ontonotes, batch 594 (33594): mcc: 0.7323, acc: 0.6520, precision: 0.7919, recall: 0.6840, f1: 0.7340, edges-srl-ontonotes_loss: 0.0194
09/07 09:53:51 PM: Update 33772: task edges-srl-ontonotes, batch 772 (33772): mcc: 0.7301, acc: 0.6496, precision: 0.7908, recall: 0.6810, f1: 0.7318, edges-srl-ontonotes_loss: 0.0196
09/07 09:54:01 PM: Update 33974: task edges-srl-ontonotes, batch 974 (33974): mcc: 0.7304, acc: 0.6495, precision: 0.7915, recall: 0.6809, f1: 0.7320, edges-srl-ontonotes_loss: 0.0195
09/07 09:54:04 PM: ***** Step 34000 / Validation 34 *****
09/07 09:54:04 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:54:04 PM: Validating...
09/07 09:54:11 PM: Updating LR scheduler:
09/07 09:54:11 PM: 	Best result seen so far for macro_avg: 0.780
09/07 09:54:11 PM: 	# validation passes without improvement: 4
09/07 09:54:11 PM: edges-srl-ontonotes_loss: training: 0.019533 validation: 0.017906
09/07 09:54:11 PM: macro_avg: validation: 0.752318
09/07 09:54:11 PM: micro_avg: validation: 0.000000
09/07 09:54:11 PM: edges-srl-ontonotes_mcc: training: 0.730470 validation: 0.750999
09/07 09:54:11 PM: edges-srl-ontonotes_acc: training: 0.649751 validation: 0.688938
09/07 09:54:11 PM: edges-srl-ontonotes_precision: training: 0.791471 validation: 0.813681
09/07 09:54:11 PM: edges-srl-ontonotes_recall: training: 0.681127 validation: 0.699561
09/07 09:54:11 PM: edges-srl-ontonotes_f1: training: 0.732165 validation: 0.752318
09/07 09:54:11 PM: Global learning rate: 5e-05
09/07 09:54:11 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:54:11 PM: Update 34009: task edges-srl-ontonotes, batch 9 (34009): mcc: 0.7466, acc: 0.6719, precision: 0.8006, recall: 0.7030, f1: 0.7486, edges-srl-ontonotes_loss: 0.0183
09/07 09:54:21 PM: Update 34209: task edges-srl-ontonotes, batch 209 (34209): mcc: 0.7707, acc: 0.6952, precision: 0.8227, recall: 0.7281, f1: 0.7725, edges-srl-ontonotes_loss: 0.0166
09/07 09:54:31 PM: Update 34388: task edges-srl-ontonotes, batch 388 (34388): mcc: 0.7783, acc: 0.7058, precision: 0.8270, recall: 0.7384, f1: 0.7802, edges-srl-ontonotes_loss: 0.0162
09/07 09:54:41 PM: Update 34582: task edges-srl-ontonotes, batch 582 (34582): mcc: 0.7893, acc: 0.7201, precision: 0.8342, recall: 0.7524, f1: 0.7912, edges-srl-ontonotes_loss: 0.0155
09/07 09:54:51 PM: Update 34722: task edges-srl-ontonotes, batch 722 (34722): mcc: 0.7911, acc: 0.7227, precision: 0.8354, recall: 0.7548, f1: 0.7931, edges-srl-ontonotes_loss: 0.0154
09/07 09:55:01 PM: Update 34918: task edges-srl-ontonotes, batch 918 (34918): mcc: 0.7944, acc: 0.7270, precision: 0.8381, recall: 0.7586, f1: 0.7964, edges-srl-ontonotes_loss: 0.0152
09/07 09:55:07 PM: ***** Step 35000 / Validation 35 *****
09/07 09:55:07 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:55:07 PM: Validating...
09/07 09:55:11 PM: Evaluate: task edges-srl-ontonotes, batch 103 (157): mcc: 0.7695, acc: 0.7095, precision: 0.8258, recall: 0.7231, f1: 0.7710, edges-srl-ontonotes_loss: 0.0171
09/07 09:55:14 PM: Updating LR scheduler:
09/07 09:55:14 PM: 	Best result seen so far for macro_avg: 0.780
09/07 09:55:14 PM: 	# validation passes without improvement: 5
09/07 09:55:14 PM: edges-srl-ontonotes_loss: training: 0.015050 validation: 0.017486
09/07 09:55:14 PM: macro_avg: validation: 0.764841
09/07 09:55:14 PM: micro_avg: validation: 0.000000
09/07 09:55:14 PM: edges-srl-ontonotes_mcc: training: 0.796242 validation: 0.763300
09/07 09:55:14 PM: edges-srl-ontonotes_acc: training: 0.729281 validation: 0.703179
09/07 09:55:14 PM: edges-srl-ontonotes_precision: training: 0.839676 validation: 0.820789
09/07 09:55:14 PM: edges-srl-ontonotes_recall: training: 0.760610 validation: 0.716034
09/07 09:55:14 PM: edges-srl-ontonotes_f1: training: 0.798190 validation: 0.764841
09/07 09:55:14 PM: Global learning rate: 5e-05
09/07 09:55:14 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:55:22 PM: Update 35146: task edges-srl-ontonotes, batch 146 (35146): mcc: 0.8188, acc: 0.7594, precision: 0.8575, recall: 0.7869, f1: 0.8207, edges-srl-ontonotes_loss: 0.0138
09/07 09:55:32 PM: Update 35323: task edges-srl-ontonotes, batch 323 (35323): mcc: 0.8236, acc: 0.7661, precision: 0.8610, recall: 0.7928, f1: 0.8255, edges-srl-ontonotes_loss: 0.0135
09/07 09:55:42 PM: Update 35519: task edges-srl-ontonotes, batch 519 (35519): mcc: 0.8308, acc: 0.7758, precision: 0.8669, recall: 0.8010, f1: 0.8326, edges-srl-ontonotes_loss: 0.0133
09/07 09:55:52 PM: Update 35661: task edges-srl-ontonotes, batch 661 (35661): mcc: 0.8190, acc: 0.7609, precision: 0.8577, recall: 0.7869, f1: 0.8208, edges-srl-ontonotes_loss: 0.0141
09/07 09:56:02 PM: Update 35860: task edges-srl-ontonotes, batch 860 (35860): mcc: 0.8062, acc: 0.7450, precision: 0.8471, recall: 0.7726, f1: 0.8082, edges-srl-ontonotes_loss: 0.0148
09/07 09:56:10 PM: ***** Step 36000 / Validation 36 *****
09/07 09:56:10 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:56:10 PM: Validating...
09/07 09:56:12 PM: Evaluate: task edges-srl-ontonotes, batch 40 (157): mcc: 0.7662, acc: 0.7059, precision: 0.8296, recall: 0.7136, f1: 0.7673, edges-srl-ontonotes_loss: 0.0175
09/07 09:56:17 PM: Updating LR scheduler:
09/07 09:56:17 PM: 	Best result seen so far for macro_avg: 0.780
09/07 09:56:17 PM: 	# validation passes without improvement: 0
09/07 09:56:17 PM: edges-srl-ontonotes_loss: training: 0.015490 validation: 0.017051
09/07 09:56:17 PM: macro_avg: validation: 0.773394
09/07 09:56:17 PM: micro_avg: validation: 0.000000
09/07 09:56:17 PM: edges-srl-ontonotes_mcc: training: 0.795909 validation: 0.772109
09/07 09:56:17 PM: edges-srl-ontonotes_acc: training: 0.732007 validation: 0.714187
09/07 09:56:17 PM: edges-srl-ontonotes_precision: training: 0.838966 validation: 0.831695
09/07 09:56:17 PM: edges-srl-ontonotes_recall: training: 0.760631 validation: 0.722731
09/07 09:56:17 PM: edges-srl-ontonotes_f1: training: 0.797881 validation: 0.773394
09/07 09:56:17 PM: Global learning rate: 2.5e-05
09/07 09:56:17 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:56:22 PM: Update 36092: task edges-srl-ontonotes, batch 92 (36092): mcc: 0.7225, acc: 0.6425, precision: 0.7803, recall: 0.6762, f1: 0.7245, edges-srl-ontonotes_loss: 0.0203
09/07 09:56:32 PM: Update 36263: task edges-srl-ontonotes, batch 263 (36263): mcc: 0.7354, acc: 0.6560, precision: 0.7936, recall: 0.6883, f1: 0.7372, edges-srl-ontonotes_loss: 0.0195
09/07 09:56:42 PM: Update 36455: task edges-srl-ontonotes, batch 455 (36455): mcc: 0.7498, acc: 0.6738, precision: 0.8046, recall: 0.7053, f1: 0.7517, edges-srl-ontonotes_loss: 0.0185
09/07 09:56:52 PM: Update 36596: task edges-srl-ontonotes, batch 596 (36596): mcc: 0.7557, acc: 0.6807, precision: 0.8095, recall: 0.7120, f1: 0.7576, edges-srl-ontonotes_loss: 0.0180
09/07 09:57:02 PM: Update 36789: task edges-srl-ontonotes, batch 789 (36789): mcc: 0.7614, acc: 0.6876, precision: 0.8140, recall: 0.7184, f1: 0.7632, edges-srl-ontonotes_loss: 0.0176
09/07 09:57:12 PM: Update 36968: task edges-srl-ontonotes, batch 968 (36968): mcc: 0.7602, acc: 0.6864, precision: 0.8129, recall: 0.7173, f1: 0.7621, edges-srl-ontonotes_loss: 0.0177
09/07 09:57:13 PM: ***** Step 37000 / Validation 37 *****
09/07 09:57:13 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:57:13 PM: Validating...
09/07 09:57:21 PM: Updating LR scheduler:
09/07 09:57:21 PM: 	Best result seen so far for macro_avg: 0.780
09/07 09:57:21 PM: 	# validation passes without improvement: 1
09/07 09:57:21 PM: edges-srl-ontonotes_loss: training: 0.017700 validation: 0.016502
09/07 09:57:21 PM: macro_avg: validation: 0.778107
09/07 09:57:21 PM: micro_avg: validation: 0.000000
09/07 09:57:21 PM: edges-srl-ontonotes_mcc: training: 0.760238 validation: 0.776803
09/07 09:57:21 PM: edges-srl-ontonotes_acc: training: 0.686515 validation: 0.717959
09/07 09:57:21 PM: edges-srl-ontonotes_precision: training: 0.813058 validation: 0.835261
09/07 09:57:21 PM: edges-srl-ontonotes_recall: training: 0.717204 validation: 0.728273
09/07 09:57:21 PM: edges-srl-ontonotes_f1: training: 0.762129 validation: 0.778107
09/07 09:57:21 PM: Global learning rate: 2.5e-05
09/07 09:57:21 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:57:22 PM: Update 37023: task edges-srl-ontonotes, batch 23 (37023): mcc: 0.7508, acc: 0.6730, precision: 0.8052, recall: 0.7066, f1: 0.7527, edges-srl-ontonotes_loss: 0.0182
09/07 09:57:32 PM: Update 37206: task edges-srl-ontonotes, batch 206 (37206): mcc: 0.7446, acc: 0.6656, precision: 0.7998, recall: 0.7000, f1: 0.7466, edges-srl-ontonotes_loss: 0.0185
09/07 09:57:42 PM: Update 37413: task edges-srl-ontonotes, batch 413 (37413): mcc: 0.7368, acc: 0.6563, precision: 0.7931, recall: 0.6913, f1: 0.7387, edges-srl-ontonotes_loss: 0.0190
09/07 09:57:52 PM: Update 37597: task edges-srl-ontonotes, batch 597 (37597): mcc: 0.7341, acc: 0.6531, precision: 0.7907, recall: 0.6885, f1: 0.7361, edges-srl-ontonotes_loss: 0.0192
09/07 09:58:04 PM: Update 37796: task edges-srl-ontonotes, batch 796 (37796): mcc: 0.7347, acc: 0.6532, precision: 0.7912, recall: 0.6891, f1: 0.7366, edges-srl-ontonotes_loss: 0.0192
09/07 09:58:15 PM: Update 37997: task edges-srl-ontonotes, batch 997 (37997): mcc: 0.7291, acc: 0.6463, precision: 0.7868, recall: 0.6826, f1: 0.7310, edges-srl-ontonotes_loss: 0.0195
09/07 09:58:15 PM: ***** Step 38000 / Validation 38 *****
09/07 09:58:15 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:58:15 PM: Validating...
09/07 09:58:22 PM: Updating LR scheduler:
09/07 09:58:22 PM: 	Best result seen so far for macro_avg: 0.780
09/07 09:58:22 PM: 	# validation passes without improvement: 2
09/07 09:58:22 PM: edges-srl-ontonotes_loss: training: 0.019522 validation: 0.016556
09/07 09:58:22 PM: macro_avg: validation: 0.775721
09/07 09:58:22 PM: micro_avg: validation: 0.000000
09/07 09:58:22 PM: edges-srl-ontonotes_mcc: training: 0.728997 validation: 0.774686
09/07 09:58:22 PM: edges-srl-ontonotes_acc: training: 0.646199 validation: 0.712108
09/07 09:58:22 PM: edges-srl-ontonotes_precision: training: 0.786789 validation: 0.837303
09/07 09:58:22 PM: edges-srl-ontonotes_recall: training: 0.682506 validation: 0.722577
09/07 09:58:22 PM: edges-srl-ontonotes_f1: training: 0.730946 validation: 0.775721
09/07 09:58:22 PM: Global learning rate: 2.5e-05
09/07 09:58:22 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:58:25 PM: Update 38053: task edges-srl-ontonotes, batch 53 (38053): mcc: 0.7059, acc: 0.6201, precision: 0.7705, recall: 0.6542, f1: 0.7076, edges-srl-ontonotes_loss: 0.0212
09/07 09:58:35 PM: Update 38234: task edges-srl-ontonotes, batch 234 (38234): mcc: 0.7009, acc: 0.6129, precision: 0.7670, recall: 0.6480, f1: 0.7025, edges-srl-ontonotes_loss: 0.0212
09/07 09:58:45 PM: Update 38422: task edges-srl-ontonotes, batch 422 (38422): mcc: 0.7086, acc: 0.6219, precision: 0.7736, recall: 0.6565, f1: 0.7103, edges-srl-ontonotes_loss: 0.0208
09/07 09:58:55 PM: Update 38618: task edges-srl-ontonotes, batch 618 (38618): mcc: 0.7173, acc: 0.6319, precision: 0.7809, recall: 0.6661, f1: 0.7189, edges-srl-ontonotes_loss: 0.0203
09/07 09:59:05 PM: Update 38760: task edges-srl-ontonotes, batch 760 (38760): mcc: 0.7196, acc: 0.6350, precision: 0.7819, recall: 0.6694, f1: 0.7213, edges-srl-ontonotes_loss: 0.0201
09/07 09:59:15 PM: Update 38962: task edges-srl-ontonotes, batch 962 (38962): mcc: 0.7221, acc: 0.6379, precision: 0.7833, recall: 0.6728, f1: 0.7239, edges-srl-ontonotes_loss: 0.0199
09/07 09:59:17 PM: ***** Step 39000 / Validation 39 *****
09/07 09:59:17 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 09:59:17 PM: Validating...
09/07 09:59:24 PM: Updating LR scheduler:
09/07 09:59:24 PM: 	Best result seen so far for macro_avg: 0.780
09/07 09:59:24 PM: 	# validation passes without improvement: 3
09/07 09:59:24 PM: edges-srl-ontonotes_loss: training: 0.019895 validation: 0.016992
09/07 09:59:24 PM: macro_avg: validation: 0.769079
09/07 09:59:24 PM: micro_avg: validation: 0.000000
09/07 09:59:24 PM: edges-srl-ontonotes_mcc: training: 0.722622 validation: 0.767619
09/07 09:59:24 PM: edges-srl-ontonotes_acc: training: 0.638514 validation: 0.709645
09/07 09:59:24 PM: edges-srl-ontonotes_precision: training: 0.783579 validation: 0.825492
09/07 09:59:24 PM: edges-srl-ontonotes_recall: training: 0.673559 validation: 0.719883
09/07 09:59:24 PM: edges-srl-ontonotes_f1: training: 0.724415 validation: 0.769079
09/07 09:59:24 PM: Global learning rate: 2.5e-05
09/07 09:59:24 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 09:59:25 PM: Update 39020: task edges-srl-ontonotes, batch 20 (39020): mcc: 0.7298, acc: 0.6454, precision: 0.7864, recall: 0.6844, f1: 0.7319, edges-srl-ontonotes_loss: 0.0191
09/07 09:59:35 PM: Update 39198: task edges-srl-ontonotes, batch 198 (39198): mcc: 0.7424, acc: 0.6622, precision: 0.7993, recall: 0.6962, f1: 0.7442, edges-srl-ontonotes_loss: 0.0188
09/07 09:59:45 PM: Update 39375: task edges-srl-ontonotes, batch 375 (39375): mcc: 0.7430, acc: 0.6642, precision: 0.7990, recall: 0.6977, f1: 0.7449, edges-srl-ontonotes_loss: 0.0188
09/07 09:59:55 PM: Update 39575: task edges-srl-ontonotes, batch 575 (39575): mcc: 0.7386, acc: 0.6591, precision: 0.7958, recall: 0.6924, f1: 0.7405, edges-srl-ontonotes_loss: 0.0191
09/07 10:00:05 PM: Update 39755: task edges-srl-ontonotes, batch 755 (39755): mcc: 0.7358, acc: 0.6555, precision: 0.7938, recall: 0.6890, f1: 0.7377, edges-srl-ontonotes_loss: 0.0193
09/07 10:00:15 PM: Update 39958: task edges-srl-ontonotes, batch 958 (39958): mcc: 0.7350, acc: 0.6545, precision: 0.7932, recall: 0.6879, f1: 0.7368, edges-srl-ontonotes_loss: 0.0193
09/07 10:00:21 PM: ***** Step 40000 / Validation 40 *****
09/07 10:00:21 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:00:21 PM: Validating...
09/07 10:00:25 PM: Evaluate: task edges-srl-ontonotes, batch 89 (157): mcc: 0.7616, acc: 0.6999, precision: 0.8237, recall: 0.7104, f1: 0.7629, edges-srl-ontonotes_loss: 0.0172
09/07 10:00:29 PM: Updating LR scheduler:
09/07 10:00:29 PM: 	Best result seen so far for macro_avg: 0.780
09/07 10:00:29 PM: 	# validation passes without improvement: 4
09/07 10:00:29 PM: edges-srl-ontonotes_loss: training: 0.019330 validation: 0.017207
09/07 10:00:29 PM: macro_avg: validation: 0.763895
09/07 10:00:29 PM: micro_avg: validation: 0.000000
09/07 10:00:29 PM: edges-srl-ontonotes_mcc: training: 0.734674 validation: 0.762614
09/07 10:00:29 PM: edges-srl-ontonotes_acc: training: 0.654070 validation: 0.702563
09/07 10:00:29 PM: edges-srl-ontonotes_precision: training: 0.793013 validation: 0.823907
09/07 10:00:29 PM: edges-srl-ontonotes_recall: training: 0.687530 validation: 0.712031
09/07 10:00:29 PM: edges-srl-ontonotes_f1: training: 0.736514 validation: 0.763895
09/07 10:00:29 PM: Global learning rate: 2.5e-05
09/07 10:00:29 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 10:00:35 PM: Update 40124: task edges-srl-ontonotes, batch 124 (40124): mcc: 0.7266, acc: 0.6444, precision: 0.7849, recall: 0.6797, f1: 0.7285, edges-srl-ontonotes_loss: 0.0197
09/07 10:00:45 PM: Update 40303: task edges-srl-ontonotes, batch 303 (40303): mcc: 0.7297, acc: 0.6470, precision: 0.7892, recall: 0.6816, f1: 0.7315, edges-srl-ontonotes_loss: 0.0196
09/07 10:00:56 PM: Update 40500: task edges-srl-ontonotes, batch 500 (40500): mcc: 0.7320, acc: 0.6509, precision: 0.7899, recall: 0.6853, f1: 0.7339, edges-srl-ontonotes_loss: 0.0193
09/07 10:01:06 PM: Update 40678: task edges-srl-ontonotes, batch 678 (40678): mcc: 0.7331, acc: 0.6530, precision: 0.7903, recall: 0.6871, f1: 0.7351, edges-srl-ontonotes_loss: 0.0193
09/07 10:01:16 PM: Update 40877: task edges-srl-ontonotes, batch 877 (40877): mcc: 0.7340, acc: 0.6537, precision: 0.7915, recall: 0.6876, f1: 0.7359, edges-srl-ontonotes_loss: 0.0192
09/07 10:01:25 PM: ***** Step 41000 / Validation 41 *****
09/07 10:01:25 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:01:25 PM: Validating...
09/07 10:01:26 PM: Evaluate: task edges-srl-ontonotes, batch 19 (157): mcc: 0.7566, acc: 0.6919, precision: 0.8187, recall: 0.7054, f1: 0.7578, edges-srl-ontonotes_loss: 0.0169
09/07 10:01:32 PM: Updating LR scheduler:
09/07 10:01:32 PM: 	Best result seen so far for macro_avg: 0.780
09/07 10:01:32 PM: 	# validation passes without improvement: 5
09/07 10:01:32 PM: edges-srl-ontonotes_loss: training: 0.019277 validation: 0.017411
09/07 10:01:32 PM: macro_avg: validation: 0.760221
09/07 10:01:32 PM: micro_avg: validation: 0.000000
09/07 10:01:32 PM: edges-srl-ontonotes_mcc: training: 0.733502 validation: 0.758756
09/07 10:01:32 PM: edges-srl-ontonotes_acc: training: 0.653077 validation: 0.699099
09/07 10:01:32 PM: edges-srl-ontonotes_precision: training: 0.791275 validation: 0.818150
09/07 10:01:32 PM: edges-srl-ontonotes_recall: training: 0.686891 validation: 0.709953
09/07 10:01:32 PM: edges-srl-ontonotes_f1: training: 0.735397 validation: 0.760221
09/07 10:01:32 PM: Global learning rate: 2.5e-05
09/07 10:01:32 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 10:01:36 PM: Update 41075: task edges-srl-ontonotes, batch 75 (41075): mcc: 0.7273, acc: 0.6439, precision: 0.7881, recall: 0.6782, f1: 0.7290, edges-srl-ontonotes_loss: 0.0201
09/07 10:01:46 PM: Update 41256: task edges-srl-ontonotes, batch 256 (41256): mcc: 0.7307, acc: 0.6471, precision: 0.7914, recall: 0.6815, f1: 0.7324, edges-srl-ontonotes_loss: 0.0196
09/07 10:01:56 PM: Update 41456: task edges-srl-ontonotes, batch 456 (41456): mcc: 0.7528, acc: 0.6746, precision: 0.8090, recall: 0.7069, f1: 0.7545, edges-srl-ontonotes_loss: 0.0180
09/07 10:02:06 PM: Update 41634: task edges-srl-ontonotes, batch 634 (41634): mcc: 0.7632, acc: 0.6870, precision: 0.8164, recall: 0.7197, f1: 0.7650, edges-srl-ontonotes_loss: 0.0174
09/07 10:02:16 PM: Update 41834: task edges-srl-ontonotes, batch 834 (41834): mcc: 0.7754, acc: 0.7020, precision: 0.8249, recall: 0.7348, f1: 0.7773, edges-srl-ontonotes_loss: 0.0166
09/07 10:02:26 PM: Update 41973: task edges-srl-ontonotes, batch 973 (41973): mcc: 0.7797, acc: 0.7078, precision: 0.8281, recall: 0.7401, f1: 0.7816, edges-srl-ontonotes_loss: 0.0163
09/07 10:02:27 PM: ***** Step 42000 / Validation 42 *****
09/07 10:02:27 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:02:27 PM: Validating...
09/07 10:02:34 PM: Updating LR scheduler:
09/07 10:02:34 PM: 	Best result seen so far for macro_avg: 0.780
09/07 10:02:34 PM: 	# validation passes without improvement: 0
09/07 10:02:34 PM: edges-srl-ontonotes_loss: training: 0.016232 validation: 0.017163
09/07 10:02:34 PM: macro_avg: validation: 0.770514
09/07 10:02:34 PM: micro_avg: validation: 0.000000
09/07 10:02:34 PM: edges-srl-ontonotes_mcc: training: 0.780465 validation: 0.769035
09/07 10:02:34 PM: edges-srl-ontonotes_acc: training: 0.708605 validation: 0.711185
09/07 10:02:34 PM: edges-srl-ontonotes_precision: training: 0.828639 validation: 0.826371
09/07 10:02:34 PM: edges-srl-ontonotes_recall: training: 0.740996 validation: 0.721730
09/07 10:02:34 PM: edges-srl-ontonotes_f1: training: 0.782371 validation: 0.770514
09/07 10:02:34 PM: Global learning rate: 1.25e-05
09/07 10:02:34 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 10:02:36 PM: Update 42026: task edges-srl-ontonotes, batch 26 (42026): mcc: 0.8023, acc: 0.7402, precision: 0.8433, recall: 0.7688, f1: 0.8043, edges-srl-ontonotes_loss: 0.0147
09/07 10:02:46 PM: Update 42201: task edges-srl-ontonotes, batch 201 (42201): mcc: 0.8053, acc: 0.7422, precision: 0.8457, recall: 0.7723, f1: 0.8073, edges-srl-ontonotes_loss: 0.0143
09/07 10:02:56 PM: Update 42398: task edges-srl-ontonotes, batch 398 (42398): mcc: 0.8107, acc: 0.7489, precision: 0.8509, recall: 0.7777, f1: 0.8127, edges-srl-ontonotes_loss: 0.0141
09/07 10:03:06 PM: Update 42575: task edges-srl-ontonotes, batch 575 (42575): mcc: 0.8156, acc: 0.7549, precision: 0.8556, recall: 0.7825, f1: 0.8174, edges-srl-ontonotes_loss: 0.0139
09/07 10:03:16 PM: Update 42774: task edges-srl-ontonotes, batch 774 (42774): mcc: 0.8210, acc: 0.7626, precision: 0.8600, recall: 0.7886, f1: 0.8228, edges-srl-ontonotes_loss: 0.0137
09/07 10:03:26 PM: Update 42955: task edges-srl-ontonotes, batch 955 (42955): mcc: 0.8111, acc: 0.7505, precision: 0.8519, recall: 0.7775, f1: 0.8130, edges-srl-ontonotes_loss: 0.0143
09/07 10:03:28 PM: ***** Step 43000 / Validation 43 *****
09/07 10:03:28 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:03:28 PM: Validating...
09/07 10:03:35 PM: Updating LR scheduler:
09/07 10:03:35 PM: 	Best result seen so far for macro_avg: 0.780
09/07 10:03:35 PM: 	# validation passes without improvement: 1
09/07 10:03:35 PM: edges-srl-ontonotes_loss: training: 0.014441 validation: 0.016849
09/07 10:03:35 PM: macro_avg: validation: 0.773537
09/07 10:03:35 PM: micro_avg: validation: 0.000000
09/07 10:03:35 PM: edges-srl-ontonotes_mcc: training: 0.809355 validation: 0.772036
09/07 10:03:35 PM: edges-srl-ontonotes_acc: training: 0.748461 validation: 0.714649
09/07 10:03:35 PM: edges-srl-ontonotes_precision: training: 0.850281 validation: 0.828484
09/07 10:03:35 PM: edges-srl-ontonotes_recall: training: 0.775637 validation: 0.725425
09/07 10:03:35 PM: edges-srl-ontonotes_f1: training: 0.811245 validation: 0.773537
09/07 10:03:35 PM: Global learning rate: 1.25e-05
09/07 10:03:35 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 10:03:36 PM: Update 43011: task edges-srl-ontonotes, batch 11 (43011): mcc: 0.7604, acc: 0.6903, precision: 0.8058, recall: 0.7241, f1: 0.7628, edges-srl-ontonotes_loss: 0.0180
09/07 10:03:46 PM: Update 43153: task edges-srl-ontonotes, batch 153 (43153): mcc: 0.7519, acc: 0.6757, precision: 0.8035, recall: 0.7103, f1: 0.7540, edges-srl-ontonotes_loss: 0.0182
09/07 10:03:56 PM: Update 43353: task edges-srl-ontonotes, batch 353 (43353): mcc: 0.7388, acc: 0.6615, precision: 0.7938, recall: 0.6944, f1: 0.7408, edges-srl-ontonotes_loss: 0.0192
09/07 10:04:06 PM: Update 43524: task edges-srl-ontonotes, batch 524 (43524): mcc: 0.7397, acc: 0.6622, precision: 0.7962, recall: 0.6941, f1: 0.7416, edges-srl-ontonotes_loss: 0.0190
09/07 10:04:16 PM: Update 43717: task edges-srl-ontonotes, batch 717 (43717): mcc: 0.7495, acc: 0.6744, precision: 0.8041, recall: 0.7053, f1: 0.7514, edges-srl-ontonotes_loss: 0.0184
09/07 10:04:26 PM: Update 43890: task edges-srl-ontonotes, batch 890 (43890): mcc: 0.7539, acc: 0.6794, precision: 0.8081, recall: 0.7099, f1: 0.7558, edges-srl-ontonotes_loss: 0.0181
09/07 10:04:32 PM: ***** Step 44000 / Validation 44 *****
09/07 10:04:32 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:04:32 PM: Validating...
09/07 10:04:36 PM: Evaluate: task edges-srl-ontonotes, batch 94 (157): mcc: 0.7834, acc: 0.7253, precision: 0.8403, recall: 0.7361, f1: 0.7848, edges-srl-ontonotes_loss: 0.0162
09/07 10:04:39 PM: Updating LR scheduler:
09/07 10:04:39 PM: 	Best result seen so far for macro_avg: 0.780
09/07 10:04:39 PM: 	# validation passes without improvement: 2
09/07 10:04:39 PM: edges-srl-ontonotes_loss: training: 0.017913 validation: 0.016483
09/07 10:04:39 PM: macro_avg: validation: 0.778890
09/07 10:04:39 PM: micro_avg: validation: 0.000000
09/07 10:04:39 PM: edges-srl-ontonotes_mcc: training: 0.757061 validation: 0.777474
09/07 10:04:39 PM: edges-srl-ontonotes_acc: training: 0.683139 validation: 0.719344
09/07 10:04:39 PM: edges-srl-ontonotes_precision: training: 0.810611 validation: 0.834139
09/07 10:04:39 PM: edges-srl-ontonotes_recall: training: 0.713473 validation: 0.730506
09/07 10:04:39 PM: edges-srl-ontonotes_f1: training: 0.758946 validation: 0.778890
09/07 10:04:39 PM: Global learning rate: 1.25e-05
09/07 10:04:39 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 10:04:47 PM: Update 44103: task edges-srl-ontonotes, batch 103 (44103): mcc: 0.7907, acc: 0.7221, precision: 0.8380, recall: 0.7517, f1: 0.7925, edges-srl-ontonotes_loss: 0.0158
09/07 10:04:57 PM: Update 44302: task edges-srl-ontonotes, batch 302 (44302): mcc: 0.7660, acc: 0.6917, precision: 0.8189, recall: 0.7226, f1: 0.7678, edges-srl-ontonotes_loss: 0.0173
09/07 10:05:07 PM: Update 44481: task edges-srl-ontonotes, batch 481 (44481): mcc: 0.7564, acc: 0.6805, precision: 0.8102, recall: 0.7127, f1: 0.7583, edges-srl-ontonotes_loss: 0.0180
09/07 10:05:17 PM: Update 44688: task edges-srl-ontonotes, batch 688 (44688): mcc: 0.7490, acc: 0.6719, precision: 0.8036, recall: 0.7048, f1: 0.7509, edges-srl-ontonotes_loss: 0.0184
09/07 10:05:27 PM: Update 44873: task edges-srl-ontonotes, batch 873 (44873): mcc: 0.7457, acc: 0.6679, precision: 0.8007, recall: 0.7012, f1: 0.7476, edges-srl-ontonotes_loss: 0.0185
09/07 10:05:34 PM: ***** Step 45000 / Validation 45 *****
09/07 10:05:34 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:05:34 PM: Validating...
09/07 10:05:37 PM: Evaluate: task edges-srl-ontonotes, batch 80 (157): mcc: 0.7818, acc: 0.7233, precision: 0.8373, recall: 0.7358, f1: 0.7833, edges-srl-ontonotes_loss: 0.0164
09/07 10:05:41 PM: Best result seen so far for edges-srl-ontonotes.
09/07 10:05:41 PM: Best result seen so far for macro.
09/07 10:05:41 PM: Updating LR scheduler:
09/07 10:05:41 PM: 	Best result seen so far for macro_avg: 0.782
09/07 10:05:41 PM: 	# validation passes without improvement: 0
09/07 10:05:41 PM: edges-srl-ontonotes_loss: training: 0.018654 validation: 0.016408
09/07 10:05:41 PM: macro_avg: validation: 0.781662
09/07 10:05:41 PM: micro_avg: validation: 0.000000
09/07 10:05:41 PM: edges-srl-ontonotes_mcc: training: 0.743087 validation: 0.780141
09/07 10:05:41 PM: edges-srl-ontonotes_acc: training: 0.664640 validation: 0.722577
09/07 10:05:41 PM: edges-srl-ontonotes_precision: training: 0.798150 validation: 0.834688
09/07 10:05:41 PM: edges-srl-ontonotes_recall: training: 0.698576 validation: 0.734970
09/07 10:05:41 PM: edges-srl-ontonotes_f1: training: 0.745051 validation: 0.781662
09/07 10:05:41 PM: Global learning rate: 1.25e-05
09/07 10:05:41 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 10:05:47 PM: Update 45075: task edges-srl-ontonotes, batch 75 (45075): mcc: 0.7256, acc: 0.6444, precision: 0.7848, recall: 0.6781, f1: 0.7275, edges-srl-ontonotes_loss: 0.0198
09/07 10:05:57 PM: Update 45276: task edges-srl-ontonotes, batch 276 (45276): mcc: 0.7110, acc: 0.6241, precision: 0.7733, recall: 0.6612, f1: 0.7128, edges-srl-ontonotes_loss: 0.0207
09/07 10:06:07 PM: Update 45456: task edges-srl-ontonotes, batch 456 (45456): mcc: 0.7096, acc: 0.6227, precision: 0.7722, recall: 0.6596, f1: 0.7115, edges-srl-ontonotes_loss: 0.0209
09/07 10:06:17 PM: Update 45658: task edges-srl-ontonotes, batch 658 (45658): mcc: 0.7116, acc: 0.6247, precision: 0.7749, recall: 0.6608, f1: 0.7133, edges-srl-ontonotes_loss: 0.0207
09/07 10:06:27 PM: Update 45835: task edges-srl-ontonotes, batch 835 (45835): mcc: 0.7158, acc: 0.6302, precision: 0.7774, recall: 0.6664, f1: 0.7176, edges-srl-ontonotes_loss: 0.0204
09/07 10:06:37 PM: ***** Step 46000 / Validation 46 *****
09/07 10:06:37 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:06:37 PM: Validating...
09/07 10:06:38 PM: Evaluate: task edges-srl-ontonotes, batch 11 (157): mcc: 0.7804, acc: 0.7137, precision: 0.8443, recall: 0.7269, f1: 0.7812, edges-srl-ontonotes_loss: 0.0160
09/07 10:06:44 PM: Updating LR scheduler:
09/07 10:06:44 PM: 	Best result seen so far for macro_avg: 0.782
09/07 10:06:44 PM: 	# validation passes without improvement: 1
09/07 10:06:44 PM: edges-srl-ontonotes_loss: training: 0.020188 validation: 0.016625
09/07 10:06:44 PM: macro_avg: validation: 0.775675
09/07 10:06:44 PM: micro_avg: validation: 0.000000
09/07 10:06:44 PM: edges-srl-ontonotes_mcc: training: 0.718522 validation: 0.774366
09/07 10:06:44 PM: edges-srl-ontonotes_acc: training: 0.633258 validation: 0.714880
09/07 10:06:44 PM: edges-srl-ontonotes_precision: training: 0.779844 validation: 0.833201
09/07 10:06:44 PM: edges-srl-ontonotes_recall: training: 0.669268 validation: 0.725579
09/07 10:06:44 PM: edges-srl-ontonotes_f1: training: 0.720337 validation: 0.775675
09/07 10:06:44 PM: Global learning rate: 1.25e-05
09/07 10:06:44 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 10:06:48 PM: Update 46066: task edges-srl-ontonotes, batch 66 (46066): mcc: 0.7258, acc: 0.6387, precision: 0.7832, recall: 0.6797, f1: 0.7278, edges-srl-ontonotes_loss: 0.0197
09/07 10:06:58 PM: Update 46267: task edges-srl-ontonotes, batch 267 (46267): mcc: 0.7363, acc: 0.6528, precision: 0.7932, recall: 0.6904, f1: 0.7382, edges-srl-ontonotes_loss: 0.0190
09/07 10:07:08 PM: Update 46410: task edges-srl-ontonotes, batch 410 (46410): mcc: 0.7392, acc: 0.6580, precision: 0.7957, recall: 0.6936, f1: 0.7411, edges-srl-ontonotes_loss: 0.0189
09/07 10:07:18 PM: Update 46607: task edges-srl-ontonotes, batch 607 (46607): mcc: 0.7417, acc: 0.6610, precision: 0.7977, recall: 0.6963, f1: 0.7436, edges-srl-ontonotes_loss: 0.0188
09/07 10:07:29 PM: Update 46810: task edges-srl-ontonotes, batch 810 (46810): mcc: 0.7384, acc: 0.6582, precision: 0.7949, recall: 0.6928, f1: 0.7404, edges-srl-ontonotes_loss: 0.0190
09/07 10:07:39 PM: Update 46991: task edges-srl-ontonotes, batch 991 (46991): mcc: 0.7366, acc: 0.6562, precision: 0.7941, recall: 0.6901, f1: 0.7385, edges-srl-ontonotes_loss: 0.0191
09/07 10:07:39 PM: ***** Step 47000 / Validation 47 *****
09/07 10:07:39 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:07:39 PM: Validating...
09/07 10:07:46 PM: Updating LR scheduler:
09/07 10:07:46 PM: 	Best result seen so far for macro_avg: 0.782
09/07 10:07:46 PM: 	# validation passes without improvement: 2
09/07 10:07:46 PM: edges-srl-ontonotes_loss: training: 0.019122 validation: 0.016840
09/07 10:07:46 PM: macro_avg: validation: 0.771731
09/07 10:07:46 PM: micro_avg: validation: 0.000000
09/07 10:07:46 PM: edges-srl-ontonotes_mcc: training: 0.736940 validation: 0.770343
09/07 10:07:46 PM: edges-srl-ontonotes_acc: training: 0.656588 validation: 0.713340
09/07 10:07:46 PM: edges-srl-ontonotes_precision: training: 0.794443 validation: 0.828768
09/07 10:07:46 PM: edges-srl-ontonotes_recall: training: 0.690461 validation: 0.722038
09/07 10:07:46 PM: edges-srl-ontonotes_f1: training: 0.738811 validation: 0.771731
09/07 10:07:46 PM: Global learning rate: 1.25e-05
09/07 10:07:46 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 10:07:49 PM: Update 47048: task edges-srl-ontonotes, batch 48 (47048): mcc: 0.7279, acc: 0.6458, precision: 0.7861, recall: 0.6811, f1: 0.7298, edges-srl-ontonotes_loss: 0.0196
09/07 10:08:00 PM: Update 47233: task edges-srl-ontonotes, batch 233 (47233): mcc: 0.7286, acc: 0.6459, precision: 0.7882, recall: 0.6806, f1: 0.7305, edges-srl-ontonotes_loss: 0.0196
09/07 10:08:11 PM: Update 47437: task edges-srl-ontonotes, batch 437 (47437): mcc: 0.7296, acc: 0.6488, precision: 0.7877, recall: 0.6828, f1: 0.7315, edges-srl-ontonotes_loss: 0.0196
09/07 10:08:21 PM: Update 47617: task edges-srl-ontonotes, batch 617 (47617): mcc: 0.7305, acc: 0.6493, precision: 0.7891, recall: 0.6833, f1: 0.7324, edges-srl-ontonotes_loss: 0.0195
09/07 10:08:31 PM: Update 47818: task edges-srl-ontonotes, batch 818 (47818): mcc: 0.7323, acc: 0.6515, precision: 0.7900, recall: 0.6857, f1: 0.7342, edges-srl-ontonotes_loss: 0.0194
09/07 10:08:41 PM: Update 47998: task edges-srl-ontonotes, batch 998 (47998): mcc: 0.7332, acc: 0.6530, precision: 0.7909, recall: 0.6867, f1: 0.7352, edges-srl-ontonotes_loss: 0.0193
09/07 10:08:41 PM: ***** Step 48000 / Validation 48 *****
09/07 10:08:41 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:08:41 PM: Validating...
09/07 10:08:48 PM: Updating LR scheduler:
09/07 10:08:48 PM: 	Best result seen so far for macro_avg: 0.782
09/07 10:08:48 PM: 	# validation passes without improvement: 3
09/07 10:08:48 PM: edges-srl-ontonotes_loss: training: 0.019334 validation: 0.017005
09/07 10:08:48 PM: macro_avg: validation: 0.770027
09/07 10:08:48 PM: micro_avg: validation: 0.000000
09/07 10:08:48 PM: edges-srl-ontonotes_mcc: training: 0.733335 validation: 0.768528
09/07 10:08:48 PM: edges-srl-ontonotes_acc: training: 0.653044 validation: 0.710569
09/07 10:08:48 PM: edges-srl-ontonotes_precision: training: 0.791030 validation: 0.825654
09/07 10:08:48 PM: edges-srl-ontonotes_recall: training: 0.686798 validation: 0.721423
09/07 10:08:48 PM: edges-srl-ontonotes_f1: training: 0.735238 validation: 0.770027
09/07 10:08:48 PM: Global learning rate: 1.25e-05
09/07 10:08:48 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 10:08:51 PM: Update 48053: task edges-srl-ontonotes, batch 53 (48053): mcc: 0.7349, acc: 0.6618, precision: 0.7867, recall: 0.6936, f1: 0.7372, edges-srl-ontonotes_loss: 0.0192
09/07 10:09:01 PM: Update 48233: task edges-srl-ontonotes, batch 233 (48233): mcc: 0.7348, acc: 0.6568, precision: 0.7907, recall: 0.6898, f1: 0.7368, edges-srl-ontonotes_loss: 0.0192
09/07 10:09:11 PM: Update 48435: task edges-srl-ontonotes, batch 435 (48435): mcc: 0.7337, acc: 0.6533, precision: 0.7934, recall: 0.6854, f1: 0.7354, edges-srl-ontonotes_loss: 0.0193
09/07 10:09:21 PM: Update 48577: task edges-srl-ontonotes, batch 577 (48577): mcc: 0.7398, acc: 0.6604, precision: 0.7991, recall: 0.6916, f1: 0.7415, edges-srl-ontonotes_loss: 0.0190
09/07 10:09:31 PM: Update 48777: task edges-srl-ontonotes, batch 777 (48777): mcc: 0.7513, acc: 0.6737, precision: 0.8074, recall: 0.7056, f1: 0.7530, edges-srl-ontonotes_loss: 0.0182
09/07 10:09:41 PM: Update 48955: task edges-srl-ontonotes, batch 955 (48955): mcc: 0.7609, acc: 0.6854, precision: 0.8142, recall: 0.7174, f1: 0.7627, edges-srl-ontonotes_loss: 0.0175
09/07 10:09:43 PM: ***** Step 49000 / Validation 49 *****
09/07 10:09:43 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:09:43 PM: Validating...
09/07 10:09:50 PM: Updating LR scheduler:
09/07 10:09:50 PM: 	Best result seen so far for macro_avg: 0.782
09/07 10:09:50 PM: 	# validation passes without improvement: 4
09/07 10:09:50 PM: edges-srl-ontonotes_loss: training: 0.017392 validation: 0.016890
09/07 10:09:50 PM: macro_avg: validation: 0.774386
09/07 10:09:50 PM: micro_avg: validation: 0.000000
09/07 10:09:50 PM: edges-srl-ontonotes_mcc: training: 0.762803 validation: 0.772795
09/07 10:09:50 PM: edges-srl-ontonotes_acc: training: 0.687601 validation: 0.715880
09/07 10:09:50 PM: edges-srl-ontonotes_precision: training: 0.815523 validation: 0.827728
09/07 10:09:50 PM: edges-srl-ontonotes_recall: training: 0.719781 validation: 0.727504
09/07 10:09:50 PM: edges-srl-ontonotes_f1: training: 0.764667 validation: 0.774386
09/07 10:09:50 PM: Global learning rate: 1.25e-05
09/07 10:09:50 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 10:09:51 PM: Update 49010: task edges-srl-ontonotes, batch 10 (49010): mcc: 0.7965, acc: 0.7236, precision: 0.8506, recall: 0.7511, f1: 0.7978, edges-srl-ontonotes_loss: 0.0151
09/07 10:10:01 PM: Update 49186: task edges-srl-ontonotes, batch 186 (49186): mcc: 0.8085, acc: 0.7427, precision: 0.8487, recall: 0.7753, f1: 0.8104, edges-srl-ontonotes_loss: 0.0142
09/07 10:10:11 PM: Update 49377: task edges-srl-ontonotes, batch 377 (49377): mcc: 0.8063, acc: 0.7399, precision: 0.8470, recall: 0.7728, f1: 0.8082, edges-srl-ontonotes_loss: 0.0144
09/07 10:10:21 PM: Update 49516: task edges-srl-ontonotes, batch 516 (49516): mcc: 0.8078, acc: 0.7427, precision: 0.8486, recall: 0.7742, f1: 0.8097, edges-srl-ontonotes_loss: 0.0143
09/07 10:10:31 PM: Update 49704: task edges-srl-ontonotes, batch 704 (49704): mcc: 0.8088, acc: 0.7450, precision: 0.8487, recall: 0.7761, f1: 0.8108, edges-srl-ontonotes_loss: 0.0142
09/07 10:10:41 PM: Update 49869: task edges-srl-ontonotes, batch 869 (49869): mcc: 0.8132, acc: 0.7508, precision: 0.8526, recall: 0.7807, f1: 0.8151, edges-srl-ontonotes_loss: 0.0140
09/07 10:10:48 PM: ***** Step 50000 / Validation 50 *****
09/07 10:10:48 PM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/07 10:10:48 PM: Validating...
09/07 10:10:51 PM: Evaluate: task edges-srl-ontonotes, batch 69 (157): mcc: 0.7696, acc: 0.7096, precision: 0.8275, recall: 0.7218, f1: 0.7711, edges-srl-ontonotes_loss: 0.0171
09/07 10:10:55 PM: Updating LR scheduler:
09/07 10:10:55 PM: 	Best result seen so far for macro_avg: 0.782
09/07 10:10:55 PM: 	# validation passes without improvement: 5
09/07 10:10:55 PM: edges-srl-ontonotes_loss: training: 0.013900 validation: 0.016851
09/07 10:10:55 PM: macro_avg: validation: 0.772232
09/07 10:10:55 PM: micro_avg: validation: 0.000000
09/07 10:10:55 PM: edges-srl-ontonotes_mcc: training: 0.816819 validation: 0.770762
09/07 10:10:55 PM: edges-srl-ontonotes_acc: training: 0.755442 validation: 0.711954
09/07 10:10:55 PM: edges-srl-ontonotes_precision: training: 0.856003 validation: 0.827902
09/07 10:10:55 PM: edges-srl-ontonotes_recall: training: 0.784486 validation: 0.723578
09/07 10:10:55 PM: edges-srl-ontonotes_f1: training: 0.818686 validation: 0.772232
09/07 10:10:55 PM: Global learning rate: 1.25e-05
09/07 10:10:55 PM: Saving checkpoints to: /scratch0/new/jiant/experiments/srl-ontonotes-None-only/run
09/07 10:11:01 PM: Update 50098: task edges-srl-ontonotes, batch 98 (50098): mcc: 0.7988, acc: 0.7344, precision: 0.8435, recall: 0.7619, f1: 0.8007, edges-srl-ontonotes_loss: 0.0151
