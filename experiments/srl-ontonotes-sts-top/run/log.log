09/16 09:10:58 AM: Git branch: master
09/16 09:10:58 AM: Git SHA: 1a42459c6cbb693793b9c0d01bca567d99b0baac
09/16 09:10:59 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/srl-ontonotes-sts-top/",
  "exp_name": "experiments/srl-ontonotes-sts-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/srl-ontonotes-sts-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/sts",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/srl-ontonotes-sts-top__run",
  "run_dir": "./experiments/srl-ontonotes-sts-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-srl-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 09:10:59 AM: Saved config to ./experiments/srl-ontonotes-sts-top/run/params.conf
09/16 09:10:59 AM: Using random seed 1234
09/16 09:10:59 AM: Using GPU 0
09/16 09:10:59 AM: Loading tasks...
09/16 09:10:59 AM: Writing pre-preprocessed tasks to ./experiments/srl-ontonotes-sts-top/
09/16 09:10:59 AM: 	Creating task edges-srl-ontonotes from scratch.
09/16 09:11:05 AM: Read=231480, Skip=21590, Total=253070 from ./probing_data/edges/ontonotes/srl/train.json.retokenized.bert-base-uncased
09/16 09:11:05 AM: Read=32486, Skip=2811, Total=35297 from ./probing_data/edges/ontonotes/srl/development.json.retokenized.bert-base-uncased
09/16 09:11:06 AM: Read=23800, Skip=2915, Total=26715 from ./probing_data/edges/ontonotes/srl/test.json.retokenized.bert-base-uncased
09/16 09:11:10 AM: 	Task 'edges-srl-ontonotes': |train|=231480 |val|=32486 |test|=23800
09/16 09:11:10 AM: 	Finished loading tasks: edges-srl-ontonotes.
09/16 09:11:10 AM: 	Building vocab from scratch.
09/16 09:11:10 AM: 	Counting units for task edges-srl-ontonotes.
09/16 09:11:18 AM: 	Task 'edges-srl-ontonotes': adding vocab namespace 'edges-srl-ontonotes_labels'
09/16 09:11:19 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:11:19 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 09:11:19 AM: 	Saved vocab to ./experiments/srl-ontonotes-sts-top/vocab
09/16 09:11:19 AM: Loading token dictionary from ./experiments/srl-ontonotes-sts-top/vocab.
09/16 09:11:20 AM: 	Loaded vocab from ./experiments/srl-ontonotes-sts-top/vocab
09/16 09:11:20 AM: 	Vocab namespace bert_uncased: size 30524
09/16 09:11:20 AM: 	Vocab namespace tokens: size 23662
09/16 09:11:20 AM: 	Vocab namespace edges-srl-ontonotes_labels: size 66
09/16 09:11:20 AM: 	Vocab namespace chars: size 76
09/16 09:11:20 AM: 	Finished building vocab.
09/16 09:11:20 AM: 	Task edges-srl-ontonotes (train): Indexing from scratch.
09/16 09:11:55 AM: 	Task edges-srl-ontonotes (train): Saved 231480 instances to ./experiments/srl-ontonotes-sts-top/preproc/edges-srl-ontonotes__train_data
09/16 09:11:55 AM: 	Task edges-srl-ontonotes (val): Indexing from scratch.
09/16 09:11:59 AM: 	Task edges-srl-ontonotes (val): Saved 32486 instances to ./experiments/srl-ontonotes-sts-top/preproc/edges-srl-ontonotes__val_data
09/16 09:11:59 AM: 	Task edges-srl-ontonotes (test): Indexing from scratch.
09/16 09:12:03 AM: 	Task edges-srl-ontonotes (test): Saved 23800 instances to ./experiments/srl-ontonotes-sts-top/preproc/edges-srl-ontonotes__test_data
09/16 09:12:03 AM: 	Finished indexing tasks
09/16 09:12:03 AM: 	Creating trimmed target-only version of edges-srl-ontonotes train.
09/16 09:12:03 AM: 	  Training on 
09/16 09:12:03 AM: 	  Evaluating on edges-srl-ontonotes
09/16 09:12:03 AM: 	Finished loading tasks in 63.540s
09/16 09:12:03 AM: 	 Tasks: ['edges-srl-ontonotes']
09/16 09:12:03 AM: Building model...
09/16 09:12:03 AM: Using BERT model (bert-base-uncased).
09/16 09:12:03 AM: LOADING A FUNETUNED MODEL from: 
09/16 09:12:03 AM: models/sts
09/16 09:12:03 AM: loading configuration file models/sts/config.json
09/16 09:12:03 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "sts-b",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 09:12:03 AM: loading weights file models/sts/pytorch_model.bin
09/16 09:12:06 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmp46nqliv4
09/16 09:12:08 AM: copying /tmp/tmp46nqliv4 to cache at ./experiments/srl-ontonotes-sts-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:12:08 AM: creating metadata file for ./experiments/srl-ontonotes-sts-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:12:08 AM: removing temp file /tmp/tmp46nqliv4
09/16 09:12:08 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/srl-ontonotes-sts-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:12:08 AM: Initializing parameters
09/16 09:12:08 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 09:12:08 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 09:12:08 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 09:12:08 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 09:12:08 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 09:12:08 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 09:12:08 AM: 	Task 'edges-srl-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-srl-ontonotes"
}
09/16 09:12:12 AM: Model specification:
09/16 09:12:12 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-srl-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (proj2): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (span_extractor2): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Sequential(
        (0): Linear(in_features=1024, out_features=256, bias=True)
        (1): Tanh()
        (2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)
        (3): Dropout(p=0.3)
        (4): Linear(in_features=256, out_features=66, bias=True)
      )
    )
  )
)
09/16 09:12:12 AM: Model parameters:
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:12 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:12 AM: 	edges-srl-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 09:12:12 AM: 	edges-srl-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 09:12:12 AM: 	edges-srl-ontonotes_mdl.proj2.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 09:12:12 AM: 	edges-srl-ontonotes_mdl.proj2.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 09:12:12 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.0.weight: Trainable parameter, count 262144 with torch.Size([256, 1024])
09/16 09:12:12 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.0.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 09:12:12 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.2.weight: Trainable parameter, count 256 with torch.Size([256])
09/16 09:12:12 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.2.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 09:12:12 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.4.weight: Trainable parameter, count 16896 with torch.Size([66, 256])
09/16 09:12:12 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.4.bias: Trainable parameter, count 66 with torch.Size([66])
09/16 09:12:12 AM: Total number of parameters: 110155842 (1.10156e+08)
09/16 09:12:12 AM: Number of trainable parameters: 673602 (673602)
09/16 09:12:12 AM: Finished building model in 9.013s
09/16 09:12:12 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-srl-ontonotes 

09/16 09:12:26 AM: patience = 9
09/16 09:12:26 AM: val_interval = 1000
09/16 09:12:26 AM: max_vals = 250
09/16 09:12:26 AM: cuda_device = 0
09/16 09:12:26 AM: grad_norm = 5.0
09/16 09:12:26 AM: grad_clipping = None
09/16 09:12:26 AM: lr_decay = 0.99
09/16 09:12:26 AM: min_lr = 1e-06
09/16 09:12:26 AM: keep_all_checkpoints = 0
09/16 09:12:26 AM: val_data_limit = 5000
09/16 09:12:26 AM: max_epochs = -1
09/16 09:12:26 AM: dec_val_scale = 250
09/16 09:12:26 AM: training_data_fraction = 1
09/16 09:12:26 AM: type = adam
09/16 09:12:26 AM: parameter_groups = None
09/16 09:12:26 AM: Number of trainable parameters: 673602
09/16 09:12:26 AM: infer_type_and_cast = True
09/16 09:12:26 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:12:26 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:12:26 AM: lr = 0.0001
09/16 09:12:26 AM: amsgrad = True
09/16 09:12:26 AM: type = reduce_on_plateau
09/16 09:12:26 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:12:26 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:12:26 AM: mode = max
09/16 09:12:26 AM: factor = 0.5
09/16 09:12:26 AM: patience = 3
09/16 09:12:26 AM: threshold = 0.0001
09/16 09:12:26 AM: threshold_mode = abs
09/16 09:12:26 AM: verbose = True
09/16 09:12:26 AM: type = adam
09/16 09:12:26 AM: parameter_groups = None
09/16 09:12:26 AM: Number of trainable parameters: 673602
09/16 09:12:26 AM: infer_type_and_cast = True
09/16 09:12:26 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:12:26 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:12:26 AM: lr = 0.0001
09/16 09:12:26 AM: amsgrad = True
09/16 09:12:26 AM: type = reduce_on_plateau
09/16 09:12:26 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:12:26 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:12:26 AM: mode = max
09/16 09:12:26 AM: factor = 0.5
09/16 09:12:26 AM: patience = 3
09/16 09:12:26 AM: threshold = 0.0001
09/16 09:12:26 AM: threshold_mode = abs
09/16 09:12:26 AM: verbose = True
09/16 09:12:26 AM: Starting training without restoring from a checkpoint.
09/16 09:12:26 AM: Training examples per task, before any subsampling: {'edges-srl-ontonotes': 231480}
09/16 09:12:26 AM: Beginning training with stopping criteria based on metric: edges-srl-ontonotes_f1
09/16 09:12:36 AM: Update 138: task edges-srl-ontonotes, batch 138 (138): mcc: 0.0534, acc: 0.0352, precision: 0.0661, recall: 0.0703, f1: 0.0681, edges-srl-ontonotes_loss: 0.1823
09/16 09:12:46 AM: Update 273: task edges-srl-ontonotes, batch 273 (273): mcc: 0.0470, acc: 0.0251, precision: 0.0779, recall: 0.0426, f1: 0.0551, edges-srl-ontonotes_loss: 0.1255
09/16 09:12:56 AM: Update 398: task edges-srl-ontonotes, batch 398 (398): mcc: 0.0634, acc: 0.0337, precision: 0.1143, recall: 0.0458, f1: 0.0654, edges-srl-ontonotes_loss: 0.1027
09/16 09:13:06 AM: Update 544: task edges-srl-ontonotes, batch 544 (544): mcc: 0.1550, acc: 0.0902, precision: 0.2630, recall: 0.1007, f1: 0.1457, edges-srl-ontonotes_loss: 0.0867
09/16 09:13:16 AM: Update 645: task edges-srl-ontonotes, batch 645 (645): mcc: 0.2213, acc: 0.1330, precision: 0.3609, recall: 0.1448, f1: 0.2066, edges-srl-ontonotes_loss: 0.0790
09/16 09:13:26 AM: Update 789: task edges-srl-ontonotes, batch 789 (789): mcc: 0.2941, acc: 0.1836, precision: 0.4587, recall: 0.1974, f1: 0.2760, edges-srl-ontonotes_loss: 0.0709
09/16 09:13:36 AM: Update 931: task edges-srl-ontonotes, batch 931 (931): mcc: 0.3517, acc: 0.2272, precision: 0.5279, recall: 0.2429, f1: 0.3327, edges-srl-ontonotes_loss: 0.0649
09/16 09:13:42 AM: ***** Step 1000 / Validation 1 *****
09/16 09:13:42 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:13:42 AM: Validating...
09/16 09:13:46 AM: Evaluate: task edges-srl-ontonotes, batch 56 (157): mcc: 0.6591, acc: 0.5070, precision: 0.8472, recall: 0.5188, f1: 0.6435, edges-srl-ontonotes_loss: 0.0284
09/16 09:13:53 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:13:53 AM: Best result seen so far for micro.
09/16 09:13:53 AM: Best result seen so far for macro.
09/16 09:13:53 AM: Updating LR scheduler:
09/16 09:13:53 AM: 	Best result seen so far for macro_avg: 0.672
09/16 09:13:53 AM: 	# validation passes without improvement: 0
09/16 09:13:53 AM: edges-srl-ontonotes_loss: training: 0.062488 validation: 0.026883
09/16 09:13:53 AM: macro_avg: validation: 0.672346
09/16 09:13:53 AM: micro_avg: validation: 0.000000
09/16 09:13:53 AM: edges-srl-ontonotes_mcc: training: 0.372667 validation: 0.684999
09/16 09:13:53 AM: edges-srl-ontonotes_acc: training: 0.243849 validation: 0.540220
09/16 09:13:53 AM: edges-srl-ontonotes_precision: training: 0.551514 validation: 0.857757
09/16 09:13:53 AM: edges-srl-ontonotes_recall: training: 0.260336 validation: 0.552844
09/16 09:13:53 AM: edges-srl-ontonotes_f1: training: 0.353708 validation: 0.672346
09/16 09:13:53 AM: Global learning rate: 0.0001
09/16 09:13:53 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:13:56 AM: Update 1034: task edges-srl-ontonotes, batch 34 (1034): mcc: 0.6265, acc: 0.4815, precision: 0.7789, recall: 0.5111, f1: 0.6172, edges-srl-ontonotes_loss: 0.0308
09/16 09:14:06 AM: Update 1174: task edges-srl-ontonotes, batch 174 (1174): mcc: 0.6472, acc: 0.5017, precision: 0.7962, recall: 0.5329, f1: 0.6385, edges-srl-ontonotes_loss: 0.0292
09/16 09:14:16 AM: Update 1295: task edges-srl-ontonotes, batch 295 (1295): mcc: 0.6548, acc: 0.5118, precision: 0.7959, recall: 0.5455, f1: 0.6473, edges-srl-ontonotes_loss: 0.0284
09/16 09:14:26 AM: Update 1429: task edges-srl-ontonotes, batch 429 (1429): mcc: 0.6608, acc: 0.5207, precision: 0.7963, recall: 0.5552, f1: 0.6543, edges-srl-ontonotes_loss: 0.0277
09/16 09:14:36 AM: Update 1561: task edges-srl-ontonotes, batch 561 (1561): mcc: 0.6693, acc: 0.5320, precision: 0.7987, recall: 0.5677, f1: 0.6637, edges-srl-ontonotes_loss: 0.0270
09/16 09:14:46 AM: Update 1660: task edges-srl-ontonotes, batch 660 (1660): mcc: 0.6684, acc: 0.5310, precision: 0.7962, recall: 0.5680, f1: 0.6630, edges-srl-ontonotes_loss: 0.0269
09/16 09:14:56 AM: Update 1796: task edges-srl-ontonotes, batch 796 (1796): mcc: 0.6691, acc: 0.5322, precision: 0.7953, recall: 0.5699, f1: 0.6640, edges-srl-ontonotes_loss: 0.0268
09/16 09:15:06 AM: Update 1880: task edges-srl-ontonotes, batch 880 (1880): mcc: 0.6697, acc: 0.5331, precision: 0.7938, recall: 0.5719, f1: 0.6648, edges-srl-ontonotes_loss: 0.0266
09/16 09:15:16 AM: Update 1999: task edges-srl-ontonotes, batch 999 (1999): mcc: 0.6718, acc: 0.5358, precision: 0.7939, recall: 0.5755, f1: 0.6673, edges-srl-ontonotes_loss: 0.0264
09/16 09:15:16 AM: ***** Step 2000 / Validation 2 *****
09/16 09:15:16 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:15:16 AM: Validating...
09/16 09:15:26 AM: Evaluate: task edges-srl-ontonotes, batch 130 (157): mcc: 0.7435, acc: 0.6217, precision: 0.8680, recall: 0.6424, f1: 0.7384, edges-srl-ontonotes_loss: 0.0207
09/16 09:15:28 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:15:28 AM: Best result seen so far for macro.
09/16 09:15:28 AM: Updating LR scheduler:
09/16 09:15:28 AM: 	Best result seen so far for macro_avg: 0.737
09/16 09:15:28 AM: 	# validation passes without improvement: 0
09/16 09:15:28 AM: edges-srl-ontonotes_loss: training: 0.026400 validation: 0.020825
09/16 09:15:28 AM: macro_avg: validation: 0.736595
09/16 09:15:28 AM: micro_avg: validation: 0.000000
09/16 09:15:28 AM: edges-srl-ontonotes_mcc: training: 0.671825 validation: 0.741822
09/16 09:15:28 AM: edges-srl-ontonotes_acc: training: 0.535799 validation: 0.619891
09/16 09:15:28 AM: edges-srl-ontonotes_precision: training: 0.793905 validation: 0.867000
09/16 09:15:28 AM: edges-srl-ontonotes_recall: training: 0.575511 validation: 0.640289
09/16 09:15:28 AM: edges-srl-ontonotes_f1: training: 0.667294 validation: 0.736595
09/16 09:15:28 AM: Global learning rate: 0.0001
09/16 09:15:28 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:15:36 AM: Update 2103: task edges-srl-ontonotes, batch 103 (2103): mcc: 0.6864, acc: 0.5553, precision: 0.7966, recall: 0.5985, f1: 0.6834, edges-srl-ontonotes_loss: 0.0248
09/16 09:15:47 AM: Update 2216: task edges-srl-ontonotes, batch 216 (2216): mcc: 0.6884, acc: 0.5580, precision: 0.7937, recall: 0.6041, f1: 0.6860, edges-srl-ontonotes_loss: 0.0246
09/16 09:15:57 AM: Update 2329: task edges-srl-ontonotes, batch 329 (2329): mcc: 0.6984, acc: 0.5710, precision: 0.7992, recall: 0.6173, f1: 0.6966, edges-srl-ontonotes_loss: 0.0239
09/16 09:16:07 AM: Update 2444: task edges-srl-ontonotes, batch 444 (2444): mcc: 0.7055, acc: 0.5810, precision: 0.8031, recall: 0.6266, f1: 0.7040, edges-srl-ontonotes_loss: 0.0234
09/16 09:16:17 AM: Update 2558: task edges-srl-ontonotes, batch 558 (2558): mcc: 0.7086, acc: 0.5854, precision: 0.8048, recall: 0.6306, f1: 0.7071, edges-srl-ontonotes_loss: 0.0231
09/16 09:16:27 AM: Update 2681: task edges-srl-ontonotes, batch 681 (2681): mcc: 0.7117, acc: 0.5904, precision: 0.8060, recall: 0.6351, f1: 0.7104, edges-srl-ontonotes_loss: 0.0229
09/16 09:16:37 AM: Update 2796: task edges-srl-ontonotes, batch 796 (2796): mcc: 0.7135, acc: 0.5934, precision: 0.8062, recall: 0.6382, f1: 0.7124, edges-srl-ontonotes_loss: 0.0227
09/16 09:16:47 AM: Update 2884: task edges-srl-ontonotes, batch 884 (2884): mcc: 0.7156, acc: 0.5961, precision: 0.8071, recall: 0.6412, f1: 0.7146, edges-srl-ontonotes_loss: 0.0225
09/16 09:16:56 AM: ***** Step 3000 / Validation 3 *****
09/16 09:16:56 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:16:56 AM: Validating...
09/16 09:16:57 AM: Evaluate: task edges-srl-ontonotes, batch 11 (157): mcc: 0.7644, acc: 0.6701, precision: 0.8269, recall: 0.7127, f1: 0.7655, edges-srl-ontonotes_loss: 0.0186
09/16 09:17:07 AM: Evaluate: task edges-srl-ontonotes, batch 144 (157): mcc: 0.7548, acc: 0.6495, precision: 0.8462, recall: 0.6791, f1: 0.7535, edges-srl-ontonotes_loss: 0.0196
09/16 09:17:08 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:17:08 AM: Best result seen so far for macro.
09/16 09:17:08 AM: Updating LR scheduler:
09/16 09:17:08 AM: 	Best result seen so far for macro_avg: 0.754
09/16 09:17:08 AM: 	# validation passes without improvement: 0
09/16 09:17:08 AM: edges-srl-ontonotes_loss: training: 0.022383 validation: 0.019686
09/16 09:17:08 AM: macro_avg: validation: 0.754013
09/16 09:17:08 AM: micro_avg: validation: 0.000000
09/16 09:17:08 AM: edges-srl-ontonotes_mcc: training: 0.717830 validation: 0.755289
09/16 09:17:08 AM: edges-srl-ontonotes_acc: training: 0.598625 validation: 0.650219
09/16 09:17:08 AM: edges-srl-ontonotes_precision: training: 0.808143 validation: 0.846449
09/16 09:17:08 AM: edges-srl-ontonotes_recall: training: 0.644295 validation: 0.679778
09/16 09:17:08 AM: edges-srl-ontonotes_f1: training: 0.716978 validation: 0.754013
09/16 09:17:08 AM: Global learning rate: 0.0001
09/16 09:17:08 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:17:17 AM: Update 3116: task edges-srl-ontonotes, batch 116 (3116): mcc: 0.7419, acc: 0.6322, precision: 0.8216, recall: 0.6762, f1: 0.7418, edges-srl-ontonotes_loss: 0.0206
09/16 09:17:27 AM: Update 3230: task edges-srl-ontonotes, batch 230 (3230): mcc: 0.7370, acc: 0.6247, precision: 0.8180, recall: 0.6705, f1: 0.7369, edges-srl-ontonotes_loss: 0.0210
09/16 09:17:37 AM: Update 3361: task edges-srl-ontonotes, batch 361 (3361): mcc: 0.7335, acc: 0.6213, precision: 0.8152, recall: 0.6665, f1: 0.7334, edges-srl-ontonotes_loss: 0.0211
09/16 09:17:47 AM: Update 3459: task edges-srl-ontonotes, batch 459 (3459): mcc: 0.7325, acc: 0.6195, precision: 0.8146, recall: 0.6651, f1: 0.7323, edges-srl-ontonotes_loss: 0.0212
09/16 09:17:57 AM: Update 3580: task edges-srl-ontonotes, batch 580 (3580): mcc: 0.7319, acc: 0.6186, precision: 0.8139, recall: 0.6647, f1: 0.7317, edges-srl-ontonotes_loss: 0.0212
09/16 09:18:07 AM: Update 3690: task edges-srl-ontonotes, batch 690 (3690): mcc: 0.7305, acc: 0.6167, precision: 0.8129, recall: 0.6630, f1: 0.7303, edges-srl-ontonotes_loss: 0.0212
09/16 09:18:17 AM: Update 3806: task edges-srl-ontonotes, batch 806 (3806): mcc: 0.7310, acc: 0.6171, precision: 0.8130, recall: 0.6638, f1: 0.7308, edges-srl-ontonotes_loss: 0.0211
09/16 09:18:27 AM: Update 3940: task edges-srl-ontonotes, batch 940 (3940): mcc: 0.7305, acc: 0.6169, precision: 0.8117, recall: 0.6640, f1: 0.7304, edges-srl-ontonotes_loss: 0.0211
09/16 09:18:32 AM: ***** Step 4000 / Validation 4 *****
09/16 09:18:32 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:18:32 AM: Validating...
09/16 09:18:37 AM: Evaluate: task edges-srl-ontonotes, batch 69 (157): mcc: 0.7411, acc: 0.6353, precision: 0.8465, recall: 0.6548, f1: 0.7384, edges-srl-ontonotes_loss: 0.0200
09/16 09:18:46 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:18:46 AM: Best result seen so far for macro.
09/16 09:18:46 AM: Updating LR scheduler:
09/16 09:18:46 AM: 	Best result seen so far for macro_avg: 0.754
09/16 09:18:46 AM: 	# validation passes without improvement: 1
09/16 09:18:46 AM: edges-srl-ontonotes_loss: training: 0.021126 validation: 0.018997
09/16 09:18:46 AM: macro_avg: validation: 0.754040
09/16 09:18:46 AM: micro_avg: validation: 0.000000
09/16 09:18:46 AM: edges-srl-ontonotes_mcc: training: 0.730006 validation: 0.756309
09/16 09:18:46 AM: edges-srl-ontonotes_acc: training: 0.616304 validation: 0.650989
09/16 09:18:46 AM: edges-srl-ontonotes_precision: training: 0.810964 validation: 0.856639
09/16 09:18:46 AM: edges-srl-ontonotes_recall: training: 0.663718 validation: 0.673389
09/16 09:18:46 AM: edges-srl-ontonotes_f1: training: 0.729990 validation: 0.754040
09/16 09:18:46 AM: Global learning rate: 0.0001
09/16 09:18:46 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:18:47 AM: Update 4018: task edges-srl-ontonotes, batch 18 (4018): mcc: 0.7319, acc: 0.6296, precision: 0.8140, recall: 0.6646, f1: 0.7317, edges-srl-ontonotes_loss: 0.0209
09/16 09:18:57 AM: Update 4131: task edges-srl-ontonotes, batch 131 (4131): mcc: 0.7282, acc: 0.6166, precision: 0.8085, recall: 0.6625, f1: 0.7283, edges-srl-ontonotes_loss: 0.0210
09/16 09:19:07 AM: Update 4248: task edges-srl-ontonotes, batch 248 (4248): mcc: 0.7348, acc: 0.6235, precision: 0.8115, recall: 0.6719, f1: 0.7351, edges-srl-ontonotes_loss: 0.0207
09/16 09:19:17 AM: Update 4376: task edges-srl-ontonotes, batch 376 (4376): mcc: 0.7412, acc: 0.6321, precision: 0.8162, recall: 0.6795, f1: 0.7416, edges-srl-ontonotes_loss: 0.0204
09/16 09:19:27 AM: Update 4491: task edges-srl-ontonotes, batch 491 (4491): mcc: 0.7413, acc: 0.6327, precision: 0.8158, recall: 0.6801, f1: 0.7418, edges-srl-ontonotes_loss: 0.0203
09/16 09:19:38 AM: Update 4603: task edges-srl-ontonotes, batch 603 (4603): mcc: 0.7419, acc: 0.6334, precision: 0.8158, recall: 0.6812, f1: 0.7424, edges-srl-ontonotes_loss: 0.0202
09/16 09:19:48 AM: Update 4721: task edges-srl-ontonotes, batch 721 (4721): mcc: 0.7407, acc: 0.6323, precision: 0.8143, recall: 0.6802, f1: 0.7413, edges-srl-ontonotes_loss: 0.0203
09/16 09:19:58 AM: Update 4820: task edges-srl-ontonotes, batch 820 (4820): mcc: 0.7375, acc: 0.6291, precision: 0.8121, recall: 0.6763, f1: 0.7380, edges-srl-ontonotes_loss: 0.0205
09/16 09:20:08 AM: Update 4919: task edges-srl-ontonotes, batch 919 (4919): mcc: 0.7364, acc: 0.6277, precision: 0.8117, recall: 0.6747, f1: 0.7369, edges-srl-ontonotes_loss: 0.0205
09/16 09:20:15 AM: ***** Step 5000 / Validation 5 *****
09/16 09:20:15 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:20:15 AM: Validating...
09/16 09:20:18 AM: Evaluate: task edges-srl-ontonotes, batch 32 (157): mcc: 0.7491, acc: 0.6426, precision: 0.8447, recall: 0.6702, f1: 0.7474, edges-srl-ontonotes_loss: 0.0191
09/16 09:20:28 AM: Updating LR scheduler:
09/16 09:20:28 AM: 	Best result seen so far for macro_avg: 0.754
09/16 09:20:28 AM: 	# validation passes without improvement: 2
09/16 09:20:28 AM: edges-srl-ontonotes_loss: training: 0.020525 validation: 0.019076
09/16 09:20:28 AM: macro_avg: validation: 0.747094
09/16 09:20:28 AM: micro_avg: validation: 0.000000
09/16 09:20:28 AM: edges-srl-ontonotes_mcc: training: 0.736434 validation: 0.749502
09/16 09:20:28 AM: edges-srl-ontonotes_acc: training: 0.627347 validation: 0.639058
09/16 09:20:28 AM: edges-srl-ontonotes_precision: training: 0.811994 validation: 0.851556
09/16 09:20:28 AM: edges-srl-ontonotes_recall: training: 0.674443 validation: 0.665461
09/16 09:20:28 AM: edges-srl-ontonotes_f1: training: 0.736854 validation: 0.747094
09/16 09:20:28 AM: Global learning rate: 0.0001
09/16 09:20:28 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:20:28 AM: Update 5002: task edges-srl-ontonotes, batch 2 (5002): mcc: 0.7234, acc: 0.6087, precision: 0.8030, recall: 0.6584, f1: 0.7235, edges-srl-ontonotes_loss: 0.0226
09/16 09:20:38 AM: Update 5099: task edges-srl-ontonotes, batch 99 (5099): mcc: 0.7373, acc: 0.6276, precision: 0.8141, recall: 0.6742, f1: 0.7376, edges-srl-ontonotes_loss: 0.0203
09/16 09:20:48 AM: Update 5236: task edges-srl-ontonotes, batch 236 (5236): mcc: 0.7476, acc: 0.6394, precision: 0.8209, recall: 0.6872, f1: 0.7481, edges-srl-ontonotes_loss: 0.0196
09/16 09:20:58 AM: Update 5358: task edges-srl-ontonotes, batch 358 (5358): mcc: 0.7535, acc: 0.6465, precision: 0.8245, recall: 0.6948, f1: 0.7541, edges-srl-ontonotes_loss: 0.0192
09/16 09:21:08 AM: Update 5498: task edges-srl-ontonotes, batch 498 (5498): mcc: 0.7623, acc: 0.6567, precision: 0.8302, recall: 0.7061, f1: 0.7631, edges-srl-ontonotes_loss: 0.0186
09/16 09:21:18 AM: Update 5640: task edges-srl-ontonotes, batch 640 (5640): mcc: 0.7705, acc: 0.6665, precision: 0.8352, recall: 0.7166, f1: 0.7714, edges-srl-ontonotes_loss: 0.0181
09/16 09:21:28 AM: Update 5787: task edges-srl-ontonotes, batch 787 (5787): mcc: 0.7729, acc: 0.6694, precision: 0.8358, recall: 0.7207, f1: 0.7740, edges-srl-ontonotes_loss: 0.0179
09/16 09:21:38 AM: Update 5940: task edges-srl-ontonotes, batch 940 (5940): mcc: 0.7764, acc: 0.6731, precision: 0.8376, recall: 0.7255, f1: 0.7775, edges-srl-ontonotes_loss: 0.0177
09/16 09:21:45 AM: ***** Step 6000 / Validation 6 *****
09/16 09:21:45 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:21:45 AM: Validating...
09/16 09:21:48 AM: Evaluate: task edges-srl-ontonotes, batch 43 (157): mcc: 0.7624, acc: 0.6623, precision: 0.8508, recall: 0.6889, f1: 0.7613, edges-srl-ontonotes_loss: 0.0184
09/16 09:21:57 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:21:57 AM: Best result seen so far for macro.
09/16 09:21:57 AM: Updating LR scheduler:
09/16 09:21:57 AM: 	Best result seen so far for macro_avg: 0.784
09/16 09:21:57 AM: 	# validation passes without improvement: 0
09/16 09:21:57 AM: edges-srl-ontonotes_loss: training: 0.017660 validation: 0.017231
09/16 09:21:57 AM: macro_avg: validation: 0.784360
09/16 09:21:57 AM: micro_avg: validation: 0.000000
09/16 09:21:57 AM: edges-srl-ontonotes_mcc: training: 0.777185 validation: 0.784803
09/16 09:21:57 AM: edges-srl-ontonotes_acc: training: 0.673658 validation: 0.689323
09/16 09:21:57 AM: edges-srl-ontonotes_precision: training: 0.838016 validation: 0.864184
09/16 09:21:57 AM: edges-srl-ontonotes_recall: training: 0.726559 validation: 0.718036
09/16 09:21:57 AM: edges-srl-ontonotes_f1: training: 0.778317 validation: 0.784360
09/16 09:21:57 AM: Global learning rate: 0.0001
09/16 09:21:57 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:21:58 AM: Update 6023: task edges-srl-ontonotes, batch 23 (6023): mcc: 0.7956, acc: 0.6875, precision: 0.8555, recall: 0.7452, f1: 0.7966, edges-srl-ontonotes_loss: 0.0166
09/16 09:22:08 AM: Update 6175: task edges-srl-ontonotes, batch 175 (6175): mcc: 0.7897, acc: 0.6855, precision: 0.8441, recall: 0.7443, f1: 0.7911, edges-srl-ontonotes_loss: 0.0169
09/16 09:22:18 AM: Update 6296: task edges-srl-ontonotes, batch 296 (6296): mcc: 0.7947, acc: 0.6935, precision: 0.8490, recall: 0.7493, f1: 0.7961, edges-srl-ontonotes_loss: 0.0166
09/16 09:22:28 AM: Update 6457: task edges-srl-ontonotes, batch 457 (6457): mcc: 0.7983, acc: 0.6999, precision: 0.8517, recall: 0.7536, f1: 0.7997, edges-srl-ontonotes_loss: 0.0162
09/16 09:22:38 AM: Update 6606: task edges-srl-ontonotes, batch 606 (6606): mcc: 0.7988, acc: 0.7016, precision: 0.8521, recall: 0.7542, f1: 0.8002, edges-srl-ontonotes_loss: 0.0162
09/16 09:22:48 AM: Update 6744: task edges-srl-ontonotes, batch 744 (6744): mcc: 0.7921, acc: 0.6931, precision: 0.8464, recall: 0.7468, f1: 0.7935, edges-srl-ontonotes_loss: 0.0167
09/16 09:22:58 AM: Update 6878: task edges-srl-ontonotes, batch 878 (6878): mcc: 0.7876, acc: 0.6876, precision: 0.8428, recall: 0.7417, f1: 0.7890, edges-srl-ontonotes_loss: 0.0170
09/16 09:23:08 AM: Update 6995: task edges-srl-ontonotes, batch 995 (6995): mcc: 0.7815, acc: 0.6799, precision: 0.8380, recall: 0.7345, f1: 0.7829, edges-srl-ontonotes_loss: 0.0174
09/16 09:23:09 AM: ***** Step 7000 / Validation 7 *****
09/16 09:23:09 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:23:09 AM: Validating...
09/16 09:23:19 AM: Evaluate: task edges-srl-ontonotes, batch 104 (157): mcc: 0.7966, acc: 0.7120, precision: 0.8584, recall: 0.7445, f1: 0.7974, edges-srl-ontonotes_loss: 0.0164
09/16 09:23:23 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:23:23 AM: Best result seen so far for macro.
09/16 09:23:23 AM: Updating LR scheduler:
09/16 09:23:23 AM: 	Best result seen so far for macro_avg: 0.799
09/16 09:23:23 AM: 	# validation passes without improvement: 0
09/16 09:23:23 AM: edges-srl-ontonotes_loss: training: 0.017376 validation: 0.016513
09/16 09:23:23 AM: macro_avg: validation: 0.799245
09/16 09:23:23 AM: micro_avg: validation: 0.000000
09/16 09:23:23 AM: edges-srl-ontonotes_mcc: training: 0.781280 validation: 0.798167
09/16 09:23:23 AM: edges-srl-ontonotes_acc: training: 0.679695 validation: 0.715341
09/16 09:23:23 AM: edges-srl-ontonotes_precision: training: 0.837815 validation: 0.855937
09/16 09:23:23 AM: edges-srl-ontonotes_recall: training: 0.734313 validation: 0.749596
09/16 09:23:23 AM: edges-srl-ontonotes_f1: training: 0.782657 validation: 0.799245
09/16 09:23:23 AM: Global learning rate: 0.0001
09/16 09:23:23 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:23:29 AM: Update 7067: task edges-srl-ontonotes, batch 67 (7067): mcc: 0.7494, acc: 0.6413, precision: 0.8083, recall: 0.7014, f1: 0.7510, edges-srl-ontonotes_loss: 0.0195
09/16 09:23:39 AM: Update 7200: task edges-srl-ontonotes, batch 200 (7200): mcc: 0.7485, acc: 0.6393, precision: 0.8095, recall: 0.6985, f1: 0.7499, edges-srl-ontonotes_loss: 0.0196
09/16 09:23:49 AM: Update 7332: task edges-srl-ontonotes, batch 332 (7332): mcc: 0.7551, acc: 0.6495, precision: 0.8179, recall: 0.7035, f1: 0.7564, edges-srl-ontonotes_loss: 0.0192
09/16 09:23:59 AM: Update 7466: task edges-srl-ontonotes, batch 466 (7466): mcc: 0.7581, acc: 0.6522, precision: 0.8206, recall: 0.7067, f1: 0.7594, edges-srl-ontonotes_loss: 0.0189
09/16 09:24:09 AM: Update 7594: task edges-srl-ontonotes, batch 594 (7594): mcc: 0.7614, acc: 0.6564, precision: 0.8237, recall: 0.7099, f1: 0.7626, edges-srl-ontonotes_loss: 0.0187
09/16 09:24:19 AM: Update 7741: task edges-srl-ontonotes, batch 741 (7741): mcc: 0.7635, acc: 0.6587, precision: 0.8256, recall: 0.7121, f1: 0.7647, edges-srl-ontonotes_loss: 0.0185
09/16 09:24:30 AM: Update 7873: task edges-srl-ontonotes, batch 873 (7873): mcc: 0.7666, acc: 0.6620, precision: 0.8281, recall: 0.7157, f1: 0.7678, edges-srl-ontonotes_loss: 0.0183
09/16 09:24:40 AM: ***** Step 8000 / Validation 8 *****
09/16 09:24:40 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:24:40 AM: Validating...
09/16 09:24:40 AM: Evaluate: task edges-srl-ontonotes, batch 1 (157): mcc: 0.7821, acc: 0.7079, precision: 0.8442, recall: 0.7303, f1: 0.7831, edges-srl-ontonotes_loss: 0.0164
09/16 09:24:50 AM: Evaluate: task edges-srl-ontonotes, batch 133 (157): mcc: 0.8111, acc: 0.7343, precision: 0.8639, recall: 0.7666, f1: 0.8123, edges-srl-ontonotes_loss: 0.0151
09/16 09:24:52 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:24:52 AM: Best result seen so far for macro.
09/16 09:24:52 AM: Updating LR scheduler:
09/16 09:24:52 AM: 	Best result seen so far for macro_avg: 0.808
09/16 09:24:52 AM: 	# validation passes without improvement: 0
09/16 09:24:52 AM: edges-srl-ontonotes_loss: training: 0.018324 validation: 0.015526
09/16 09:24:52 AM: macro_avg: validation: 0.807631
09/16 09:24:52 AM: micro_avg: validation: 0.000000
09/16 09:24:52 AM: edges-srl-ontonotes_mcc: training: 0.766432 validation: 0.806546
09/16 09:24:52 AM: edges-srl-ontonotes_acc: training: 0.662059 validation: 0.727812
09/16 09:24:52 AM: edges-srl-ontonotes_precision: training: 0.827602 validation: 0.862539
09/16 09:24:52 AM: edges-srl-ontonotes_recall: training: 0.715839 validation: 0.759295
09/16 09:24:52 AM: edges-srl-ontonotes_f1: training: 0.767674 validation: 0.807631
09/16 09:24:52 AM: Global learning rate: 0.0001
09/16 09:24:52 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:25:00 AM: Update 8114: task edges-srl-ontonotes, batch 114 (8114): mcc: 0.7645, acc: 0.6656, precision: 0.8253, recall: 0.7144, f1: 0.7658, edges-srl-ontonotes_loss: 0.0182
09/16 09:25:10 AM: Update 8206: task edges-srl-ontonotes, batch 206 (8206): mcc: 0.7580, acc: 0.6567, precision: 0.8187, recall: 0.7082, f1: 0.7594, edges-srl-ontonotes_loss: 0.0187
09/16 09:25:20 AM: Update 8341: task edges-srl-ontonotes, batch 341 (8341): mcc: 0.7540, acc: 0.6515, precision: 0.8151, recall: 0.7039, f1: 0.7554, edges-srl-ontonotes_loss: 0.0190
09/16 09:25:30 AM: Update 8471: task edges-srl-ontonotes, batch 471 (8471): mcc: 0.7518, acc: 0.6485, precision: 0.8142, recall: 0.7006, f1: 0.7531, edges-srl-ontonotes_loss: 0.0192
09/16 09:25:40 AM: Update 8591: task edges-srl-ontonotes, batch 591 (8591): mcc: 0.7508, acc: 0.6469, precision: 0.8135, recall: 0.6993, f1: 0.7521, edges-srl-ontonotes_loss: 0.0192
09/16 09:25:50 AM: Update 8721: task edges-srl-ontonotes, batch 721 (8721): mcc: 0.7512, acc: 0.6471, precision: 0.8142, recall: 0.6996, f1: 0.7525, edges-srl-ontonotes_loss: 0.0192
09/16 09:26:00 AM: Update 8854: task edges-srl-ontonotes, batch 854 (8854): mcc: 0.7499, acc: 0.6459, precision: 0.8130, recall: 0.6982, f1: 0.7512, edges-srl-ontonotes_loss: 0.0192
09/16 09:26:10 AM: Update 8980: task edges-srl-ontonotes, batch 980 (8980): mcc: 0.7462, acc: 0.6409, precision: 0.8101, recall: 0.6938, f1: 0.7474, edges-srl-ontonotes_loss: 0.0195
09/16 09:26:12 AM: ***** Step 9000 / Validation 9 *****
09/16 09:26:12 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:26:12 AM: Validating...
09/16 09:26:20 AM: Evaluate: task edges-srl-ontonotes, batch 106 (157): mcc: 0.8056, acc: 0.7273, precision: 0.8575, recall: 0.7621, f1: 0.8070, edges-srl-ontonotes_loss: 0.0154
09/16 09:26:24 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:26:24 AM: Best result seen so far for macro.
09/16 09:26:24 AM: Updating LR scheduler:
09/16 09:26:24 AM: 	Best result seen so far for macro_avg: 0.809
09/16 09:26:24 AM: 	# validation passes without improvement: 0
09/16 09:26:24 AM: edges-srl-ontonotes_loss: training: 0.019534 validation: 0.015443
09/16 09:26:24 AM: macro_avg: validation: 0.808557
09/16 09:26:24 AM: micro_avg: validation: 0.000000
09/16 09:26:24 AM: edges-srl-ontonotes_mcc: training: 0.745777 validation: 0.807120
09/16 09:26:24 AM: edges-srl-ontonotes_acc: training: 0.640552 validation: 0.729428
09/16 09:26:24 AM: edges-srl-ontonotes_precision: training: 0.809936 validation: 0.857192
09/16 09:26:24 AM: edges-srl-ontonotes_recall: training: 0.693219 validation: 0.765145
09/16 09:26:24 AM: edges-srl-ontonotes_f1: training: 0.747046 validation: 0.808557
09/16 09:26:24 AM: Global learning rate: 0.0001
09/16 09:26:24 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:26:30 AM: Update 9076: task edges-srl-ontonotes, batch 76 (9076): mcc: 0.7403, acc: 0.6352, precision: 0.8057, recall: 0.6868, f1: 0.7415, edges-srl-ontonotes_loss: 0.0202
09/16 09:26:40 AM: Update 9164: task edges-srl-ontonotes, batch 164 (9164): mcc: 0.7368, acc: 0.6289, precision: 0.8009, recall: 0.6845, f1: 0.7381, edges-srl-ontonotes_loss: 0.0203
09/16 09:26:50 AM: Update 9294: task edges-srl-ontonotes, batch 294 (9294): mcc: 0.7347, acc: 0.6243, precision: 0.8010, recall: 0.6807, f1: 0.7360, edges-srl-ontonotes_loss: 0.0204
09/16 09:27:00 AM: Update 9432: task edges-srl-ontonotes, batch 432 (9432): mcc: 0.7348, acc: 0.6247, precision: 0.8023, recall: 0.6797, f1: 0.7359, edges-srl-ontonotes_loss: 0.0203
09/16 09:27:10 AM: Update 9545: task edges-srl-ontonotes, batch 545 (9545): mcc: 0.7402, acc: 0.6319, precision: 0.8064, recall: 0.6861, f1: 0.7414, edges-srl-ontonotes_loss: 0.0200
09/16 09:27:20 AM: Update 9668: task edges-srl-ontonotes, batch 668 (9668): mcc: 0.7434, acc: 0.6368, precision: 0.8079, recall: 0.6906, f1: 0.7446, edges-srl-ontonotes_loss: 0.0197
09/16 09:27:30 AM: Update 9781: task edges-srl-ontonotes, batch 781 (9781): mcc: 0.7449, acc: 0.6394, precision: 0.8092, recall: 0.6923, f1: 0.7462, edges-srl-ontonotes_loss: 0.0196
09/16 09:27:40 AM: Update 9918: task edges-srl-ontonotes, batch 918 (9918): mcc: 0.7469, acc: 0.6424, precision: 0.8103, recall: 0.6949, f1: 0.7482, edges-srl-ontonotes_loss: 0.0195
09/16 09:27:47 AM: ***** Step 10000 / Validation 10 *****
09/16 09:27:47 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:27:47 AM: Validating...
09/16 09:27:50 AM: Evaluate: task edges-srl-ontonotes, batch 34 (157): mcc: 0.7925, acc: 0.7164, precision: 0.8532, recall: 0.7416, f1: 0.7935, edges-srl-ontonotes_loss: 0.0162
09/16 09:28:00 AM: Updating LR scheduler:
09/16 09:28:00 AM: 	Best result seen so far for macro_avg: 0.809
09/16 09:28:00 AM: 	# validation passes without improvement: 1
09/16 09:28:00 AM: edges-srl-ontonotes_loss: training: 0.019387 validation: 0.015764
09/16 09:28:00 AM: macro_avg: validation: 0.802832
09/16 09:28:00 AM: micro_avg: validation: 0.000000
09/16 09:28:00 AM: edges-srl-ontonotes_mcc: training: 0.747839 validation: 0.802007
09/16 09:28:00 AM: edges-srl-ontonotes_acc: training: 0.643419 validation: 0.725502
09/16 09:28:00 AM: edges-srl-ontonotes_precision: training: 0.811317 validation: 0.862780
09/16 09:28:00 AM: edges-srl-ontonotes_recall: training: 0.695808 validation: 0.750674
09/16 09:28:00 AM: edges-srl-ontonotes_f1: training: 0.749136 validation: 0.802832
09/16 09:28:00 AM: Global learning rate: 0.0001
09/16 09:28:00 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:28:00 AM: Update 10001: task edges-srl-ontonotes, batch 1 (10001): mcc: 0.7956, acc: 0.7229, precision: 0.8400, recall: 0.7590, f1: 0.7975, edges-srl-ontonotes_loss: 0.0166
09/16 09:28:11 AM: Update 10094: task edges-srl-ontonotes, batch 94 (10094): mcc: 0.7728, acc: 0.6799, precision: 0.8337, recall: 0.7223, f1: 0.7740, edges-srl-ontonotes_loss: 0.0180
09/16 09:28:21 AM: Update 10222: task edges-srl-ontonotes, batch 222 (10222): mcc: 0.7697, acc: 0.6738, precision: 0.8294, recall: 0.7203, f1: 0.7710, edges-srl-ontonotes_loss: 0.0182
09/16 09:28:31 AM: Update 10357: task edges-srl-ontonotes, batch 357 (10357): mcc: 0.7678, acc: 0.6711, precision: 0.8274, recall: 0.7184, f1: 0.7691, edges-srl-ontonotes_loss: 0.0182
09/16 09:28:41 AM: Update 10477: task edges-srl-ontonotes, batch 477 (10477): mcc: 0.7652, acc: 0.6678, precision: 0.8250, recall: 0.7159, f1: 0.7666, edges-srl-ontonotes_loss: 0.0184
09/16 09:28:51 AM: Update 10598: task edges-srl-ontonotes, batch 598 (10598): mcc: 0.7641, acc: 0.6661, precision: 0.8248, recall: 0.7141, f1: 0.7655, edges-srl-ontonotes_loss: 0.0184
09/16 09:29:01 AM: Update 10713: task edges-srl-ontonotes, batch 713 (10713): mcc: 0.7630, acc: 0.6648, precision: 0.8244, recall: 0.7124, f1: 0.7643, edges-srl-ontonotes_loss: 0.0185
09/16 09:29:11 AM: Update 10845: task edges-srl-ontonotes, batch 845 (10845): mcc: 0.7621, acc: 0.6630, precision: 0.8242, recall: 0.7109, f1: 0.7633, edges-srl-ontonotes_loss: 0.0185
09/16 09:29:21 AM: Update 10971: task edges-srl-ontonotes, batch 971 (10971): mcc: 0.7612, acc: 0.6618, precision: 0.8236, recall: 0.7096, f1: 0.7624, edges-srl-ontonotes_loss: 0.0186
09/16 09:29:23 AM: ***** Step 11000 / Validation 11 *****
09/16 09:29:23 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:29:23 AM: Validating...
09/16 09:29:31 AM: Evaluate: task edges-srl-ontonotes, batch 102 (157): mcc: 0.7900, acc: 0.7104, precision: 0.8525, recall: 0.7375, f1: 0.7908, edges-srl-ontonotes_loss: 0.0165
09/16 09:29:35 AM: Updating LR scheduler:
09/16 09:29:35 AM: 	Best result seen so far for macro_avg: 0.809
09/16 09:29:35 AM: 	# validation passes without improvement: 2
09/16 09:29:35 AM: edges-srl-ontonotes_loss: training: 0.018573 validation: 0.016150
09/16 09:29:35 AM: macro_avg: validation: 0.799442
09/16 09:29:35 AM: micro_avg: validation: 0.000000
09/16 09:29:35 AM: edges-srl-ontonotes_mcc: training: 0.761103 validation: 0.798345
09/16 09:29:35 AM: edges-srl-ontonotes_acc: training: 0.661738 validation: 0.721576
09/16 09:29:35 AM: edges-srl-ontonotes_precision: training: 0.823628 validation: 0.855788
09/16 09:29:35 AM: edges-srl-ontonotes_recall: training: 0.709491 validation: 0.750058
09/16 09:29:35 AM: edges-srl-ontonotes_f1: training: 0.762311 validation: 0.799442
09/16 09:29:35 AM: Global learning rate: 0.0001
09/16 09:29:35 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:29:41 AM: Update 11057: task edges-srl-ontonotes, batch 57 (11057): mcc: 0.7538, acc: 0.6493, precision: 0.8198, recall: 0.6995, f1: 0.7549, edges-srl-ontonotes_loss: 0.0190
09/16 09:29:51 AM: Update 11187: task edges-srl-ontonotes, batch 187 (11187): mcc: 0.7527, acc: 0.6536, precision: 0.8187, recall: 0.6984, f1: 0.7538, edges-srl-ontonotes_loss: 0.0192
09/16 09:30:01 AM: Update 11312: task edges-srl-ontonotes, batch 312 (11312): mcc: 0.7530, acc: 0.6537, precision: 0.8192, recall: 0.6985, f1: 0.7541, edges-srl-ontonotes_loss: 0.0190
09/16 09:30:11 AM: Update 11402: task edges-srl-ontonotes, batch 402 (11402): mcc: 0.7548, acc: 0.6566, precision: 0.8199, recall: 0.7012, f1: 0.7559, edges-srl-ontonotes_loss: 0.0189
09/16 09:30:21 AM: Update 11537: task edges-srl-ontonotes, batch 537 (11537): mcc: 0.7595, acc: 0.6626, precision: 0.8226, recall: 0.7073, f1: 0.7606, edges-srl-ontonotes_loss: 0.0187
09/16 09:30:31 AM: Update 11655: task edges-srl-ontonotes, batch 655 (11655): mcc: 0.7609, acc: 0.6646, precision: 0.8234, recall: 0.7094, f1: 0.7621, edges-srl-ontonotes_loss: 0.0186
09/16 09:30:41 AM: Update 11793: task edges-srl-ontonotes, batch 793 (11793): mcc: 0.7625, acc: 0.6667, precision: 0.8246, recall: 0.7112, f1: 0.7637, edges-srl-ontonotes_loss: 0.0185
09/16 09:30:51 AM: Update 11922: task edges-srl-ontonotes, batch 922 (11922): mcc: 0.7637, acc: 0.6682, precision: 0.8253, recall: 0.7128, f1: 0.7649, edges-srl-ontonotes_loss: 0.0184
09/16 09:30:59 AM: ***** Step 12000 / Validation 12 *****
09/16 09:30:59 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:30:59 AM: Validating...
09/16 09:31:01 AM: Evaluate: task edges-srl-ontonotes, batch 30 (157): mcc: 0.7966, acc: 0.7187, precision: 0.8584, recall: 0.7445, f1: 0.7974, edges-srl-ontonotes_loss: 0.0162
09/16 09:31:11 AM: Evaluate: task edges-srl-ontonotes, batch 154 (157): mcc: 0.7969, acc: 0.7169, precision: 0.8626, recall: 0.7415, f1: 0.7975, edges-srl-ontonotes_loss: 0.0162
09/16 09:31:11 AM: Updating LR scheduler:
09/16 09:31:11 AM: 	Best result seen so far for macro_avg: 0.809
09/16 09:31:11 AM: 	# validation passes without improvement: 3
09/16 09:31:11 AM: edges-srl-ontonotes_loss: training: 0.018577 validation: 0.016323
09/16 09:31:11 AM: macro_avg: validation: 0.797036
09/16 09:31:11 AM: micro_avg: validation: 0.000000
09/16 09:31:11 AM: edges-srl-ontonotes_mcc: training: 0.761320 validation: 0.796494
09/16 09:31:11 AM: edges-srl-ontonotes_acc: training: 0.665306 validation: 0.716265
09/16 09:31:11 AM: edges-srl-ontonotes_precision: training: 0.823524 validation: 0.862171
09/16 09:31:11 AM: edges-srl-ontonotes_recall: training: 0.709980 validation: 0.741051
09/16 09:31:11 AM: edges-srl-ontonotes_f1: training: 0.762549 validation: 0.797036
09/16 09:31:11 AM: Global learning rate: 0.0001
09/16 09:31:11 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:31:21 AM: Update 12105: task edges-srl-ontonotes, batch 105 (12105): mcc: 0.7442, acc: 0.6448, precision: 0.8169, recall: 0.6844, f1: 0.7448, edges-srl-ontonotes_loss: 0.0197
09/16 09:31:31 AM: Update 12222: task edges-srl-ontonotes, batch 222 (12222): mcc: 0.7481, acc: 0.6487, precision: 0.8193, recall: 0.6895, f1: 0.7488, edges-srl-ontonotes_loss: 0.0194
09/16 09:31:41 AM: Update 12320: task edges-srl-ontonotes, batch 320 (12320): mcc: 0.7533, acc: 0.6551, precision: 0.8223, recall: 0.6962, f1: 0.7540, edges-srl-ontonotes_loss: 0.0191
09/16 09:31:51 AM: Update 12459: task edges-srl-ontonotes, batch 459 (12459): mcc: 0.7596, acc: 0.6617, precision: 0.8264, recall: 0.7044, f1: 0.7605, edges-srl-ontonotes_loss: 0.0185
09/16 09:32:01 AM: Update 12596: task edges-srl-ontonotes, batch 596 (12596): mcc: 0.7670, acc: 0.6708, precision: 0.8302, recall: 0.7145, f1: 0.7681, edges-srl-ontonotes_loss: 0.0180
09/16 09:32:12 AM: Update 12753: task edges-srl-ontonotes, batch 753 (12753): mcc: 0.7771, acc: 0.6829, precision: 0.8371, recall: 0.7273, f1: 0.7783, edges-srl-ontonotes_loss: 0.0174
09/16 09:32:22 AM: Update 12897: task edges-srl-ontonotes, batch 897 (12897): mcc: 0.7833, acc: 0.6908, precision: 0.8410, recall: 0.7353, f1: 0.7846, edges-srl-ontonotes_loss: 0.0170
09/16 09:32:29 AM: ***** Step 13000 / Validation 13 *****
09/16 09:32:29 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:32:29 AM: Validating...
09/16 09:32:32 AM: Evaluate: task edges-srl-ontonotes, batch 38 (157): mcc: 0.7950, acc: 0.7146, precision: 0.8584, recall: 0.7416, f1: 0.7957, edges-srl-ontonotes_loss: 0.0164
09/16 09:32:40 AM: Updating LR scheduler:
09/16 09:32:40 AM: 	Best result seen so far for macro_avg: 0.809
09/16 09:32:40 AM: 	# validation passes without improvement: 0
09/16 09:32:40 AM: edges-srl-ontonotes_loss: training: 0.016767 validation: 0.015660
09/16 09:32:40 AM: macro_avg: validation: 0.807355
09/16 09:32:40 AM: micro_avg: validation: 0.000000
09/16 09:32:40 AM: edges-srl-ontonotes_mcc: training: 0.785920 validation: 0.806288
09/16 09:32:40 AM: edges-srl-ontonotes_acc: training: 0.693961 validation: 0.729197
09/16 09:32:40 AM: edges-srl-ontonotes_precision: training: 0.842525 validation: 0.862606
09/16 09:32:40 AM: edges-srl-ontonotes_recall: training: 0.738749 validation: 0.758756
09/16 09:32:40 AM: edges-srl-ontonotes_f1: training: 0.787232 validation: 0.807355
09/16 09:32:40 AM: Global learning rate: 5e-05
09/16 09:32:40 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:32:42 AM: Update 13021: task edges-srl-ontonotes, batch 21 (13021): mcc: 0.7945, acc: 0.7095, precision: 0.8394, recall: 0.7577, f1: 0.7964, edges-srl-ontonotes_loss: 0.0162
09/16 09:32:52 AM: Update 13182: task edges-srl-ontonotes, batch 182 (13182): mcc: 0.8133, acc: 0.7278, precision: 0.8586, recall: 0.7755, f1: 0.8149, edges-srl-ontonotes_loss: 0.0150
09/16 09:33:02 AM: Update 13340: task edges-srl-ontonotes, batch 340 (13340): mcc: 0.8127, acc: 0.7272, precision: 0.8580, recall: 0.7749, f1: 0.8143, edges-srl-ontonotes_loss: 0.0151
09/16 09:33:12 AM: Update 13506: task edges-srl-ontonotes, batch 506 (13506): mcc: 0.8156, acc: 0.7315, precision: 0.8600, recall: 0.7786, f1: 0.8172, edges-srl-ontonotes_loss: 0.0149
09/16 09:33:22 AM: Update 13631: task edges-srl-ontonotes, batch 631 (13631): mcc: 0.8169, acc: 0.7329, precision: 0.8617, recall: 0.7795, f1: 0.8185, edges-srl-ontonotes_loss: 0.0149
09/16 09:33:32 AM: Update 13803: task edges-srl-ontonotes, batch 803 (13803): mcc: 0.8197, acc: 0.7367, precision: 0.8640, recall: 0.7826, f1: 0.8213, edges-srl-ontonotes_loss: 0.0147
09/16 09:33:42 AM: Update 13922: task edges-srl-ontonotes, batch 922 (13922): mcc: 0.8152, acc: 0.7311, precision: 0.8607, recall: 0.7772, f1: 0.8168, edges-srl-ontonotes_loss: 0.0151
09/16 09:33:48 AM: ***** Step 14000 / Validation 14 *****
09/16 09:33:48 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:33:48 AM: Validating...
09/16 09:33:52 AM: Evaluate: task edges-srl-ontonotes, batch 54 (157): mcc: 0.8013, acc: 0.7260, precision: 0.8692, recall: 0.7439, f1: 0.8017, edges-srl-ontonotes_loss: 0.0160
09/16 09:34:00 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:34:00 AM: Best result seen so far for macro.
09/16 09:34:00 AM: Updating LR scheduler:
09/16 09:34:00 AM: 	Best result seen so far for macro_avg: 0.819
09/16 09:34:00 AM: 	# validation passes without improvement: 0
09/16 09:34:00 AM: edges-srl-ontonotes_loss: training: 0.015211 validation: 0.014882
09/16 09:34:00 AM: macro_avg: validation: 0.818638
09/16 09:34:00 AM: micro_avg: validation: 0.000000
09/16 09:34:00 AM: edges-srl-ontonotes_mcc: training: 0.813127 validation: 0.818079
09/16 09:34:00 AM: edges-srl-ontonotes_acc: training: 0.728503 validation: 0.746517
09/16 09:34:00 AM: edges-srl-ontonotes_precision: training: 0.859366 validation: 0.879766
09/16 09:34:00 AM: edges-srl-ontonotes_recall: training: 0.774441 validation: 0.765453
09/16 09:34:00 AM: edges-srl-ontonotes_f1: training: 0.814696 validation: 0.818638
09/16 09:34:00 AM: Global learning rate: 5e-05
09/16 09:34:00 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:34:02 AM: Update 14020: task edges-srl-ontonotes, batch 20 (14020): mcc: 0.7825, acc: 0.6910, precision: 0.8354, recall: 0.7387, f1: 0.7841, edges-srl-ontonotes_loss: 0.0175
09/16 09:34:12 AM: Update 14143: task edges-srl-ontonotes, batch 143 (14143): mcc: 0.7867, acc: 0.6961, precision: 0.8412, recall: 0.7413, f1: 0.7881, edges-srl-ontonotes_loss: 0.0171
09/16 09:34:22 AM: Update 14265: task edges-srl-ontonotes, batch 265 (14265): mcc: 0.7748, acc: 0.6814, precision: 0.8305, recall: 0.7288, f1: 0.7763, edges-srl-ontonotes_loss: 0.0178
09/16 09:34:32 AM: Update 14397: task edges-srl-ontonotes, batch 397 (14397): mcc: 0.7739, acc: 0.6807, precision: 0.8298, recall: 0.7277, f1: 0.7754, edges-srl-ontonotes_loss: 0.0179
09/16 09:34:42 AM: Update 14493: task edges-srl-ontonotes, batch 493 (14493): mcc: 0.7734, acc: 0.6803, precision: 0.8303, recall: 0.7264, f1: 0.7749, edges-srl-ontonotes_loss: 0.0179
09/16 09:34:52 AM: Update 14645: task edges-srl-ontonotes, batch 645 (14645): mcc: 0.7772, acc: 0.6843, precision: 0.8340, recall: 0.7301, f1: 0.7786, edges-srl-ontonotes_loss: 0.0176
09/16 09:35:02 AM: Update 14777: task edges-srl-ontonotes, batch 777 (14777): mcc: 0.7794, acc: 0.6866, precision: 0.8362, recall: 0.7322, f1: 0.7807, edges-srl-ontonotes_loss: 0.0175
09/16 09:35:12 AM: Update 14901: task edges-srl-ontonotes, batch 901 (14901): mcc: 0.7809, acc: 0.6885, precision: 0.8374, recall: 0.7340, f1: 0.7823, edges-srl-ontonotes_loss: 0.0173
09/16 09:35:21 AM: ***** Step 15000 / Validation 15 *****
09/16 09:35:21 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:35:21 AM: Validating...
09/16 09:35:23 AM: Evaluate: task edges-srl-ontonotes, batch 23 (157): mcc: 0.8259, acc: 0.7581, precision: 0.8771, recall: 0.7823, f1: 0.8270, edges-srl-ontonotes_loss: 0.0140
09/16 09:35:32 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:35:32 AM: Best result seen so far for macro.
09/16 09:35:32 AM: Updating LR scheduler:
09/16 09:35:32 AM: 	Best result seen so far for macro_avg: 0.828
09/16 09:35:32 AM: 	# validation passes without improvement: 0
09/16 09:35:32 AM: edges-srl-ontonotes_loss: training: 0.017273 validation: 0.014171
09/16 09:35:32 AM: macro_avg: validation: 0.828268
09/16 09:35:32 AM: micro_avg: validation: 0.000000
09/16 09:35:32 AM: edges-srl-ontonotes_mcc: training: 0.782145 validation: 0.826957
09/16 09:35:32 AM: edges-srl-ontonotes_acc: training: 0.689998 validation: 0.761142
09/16 09:35:32 AM: edges-srl-ontonotes_precision: training: 0.838571 validation: 0.874476
09/16 09:35:32 AM: edges-srl-ontonotes_recall: training: 0.735248 validation: 0.786698
09/16 09:35:32 AM: edges-srl-ontonotes_f1: training: 0.783518 validation: 0.828268
09/16 09:35:32 AM: Global learning rate: 5e-05
09/16 09:35:32 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:35:33 AM: Update 15002: task edges-srl-ontonotes, batch 2 (15002): mcc: 0.8197, acc: 0.7605, precision: 0.8428, recall: 0.8024, f1: 0.8221, edges-srl-ontonotes_loss: 0.0137
09/16 09:35:43 AM: Update 15120: task edges-srl-ontonotes, batch 120 (15120): mcc: 0.7946, acc: 0.7053, precision: 0.8465, recall: 0.7513, f1: 0.7961, edges-srl-ontonotes_loss: 0.0162
09/16 09:35:53 AM: Update 15251: task edges-srl-ontonotes, batch 251 (15251): mcc: 0.7864, acc: 0.6972, precision: 0.8405, recall: 0.7415, f1: 0.7879, edges-srl-ontonotes_loss: 0.0169
09/16 09:36:03 AM: Update 15393: task edges-srl-ontonotes, batch 393 (15393): mcc: 0.7851, acc: 0.6974, precision: 0.8391, recall: 0.7403, f1: 0.7866, edges-srl-ontonotes_loss: 0.0170
09/16 09:36:13 AM: Update 15497: task edges-srl-ontonotes, batch 497 (15497): mcc: 0.7833, acc: 0.6941, precision: 0.8377, recall: 0.7381, f1: 0.7847, edges-srl-ontonotes_loss: 0.0172
09/16 09:36:23 AM: Update 15633: task edges-srl-ontonotes, batch 633 (15633): mcc: 0.7792, acc: 0.6891, precision: 0.8355, recall: 0.7325, f1: 0.7806, edges-srl-ontonotes_loss: 0.0175
09/16 09:36:33 AM: Update 15756: task edges-srl-ontonotes, batch 756 (15756): mcc: 0.7777, acc: 0.6868, precision: 0.8349, recall: 0.7303, f1: 0.7791, edges-srl-ontonotes_loss: 0.0176
09/16 09:36:43 AM: Update 15902: task edges-srl-ontonotes, batch 902 (15902): mcc: 0.7754, acc: 0.6849, precision: 0.8333, recall: 0.7275, f1: 0.7768, edges-srl-ontonotes_loss: 0.0177
09/16 09:36:50 AM: ***** Step 16000 / Validation 16 *****
09/16 09:36:50 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:36:50 AM: Validating...
09/16 09:36:53 AM: Evaluate: task edges-srl-ontonotes, batch 36 (157): mcc: 0.8113, acc: 0.7441, precision: 0.8688, recall: 0.7625, f1: 0.8122, edges-srl-ontonotes_loss: 0.0148
09/16 09:37:02 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:37:02 AM: Best result seen so far for macro.
09/16 09:37:02 AM: Updating LR scheduler:
09/16 09:37:02 AM: 	Best result seen so far for macro_avg: 0.829
09/16 09:37:02 AM: 	# validation passes without improvement: 0
09/16 09:37:02 AM: edges-srl-ontonotes_loss: training: 0.017721 validation: 0.014017
09/16 09:37:02 AM: macro_avg: validation: 0.828996
09/16 09:37:02 AM: micro_avg: validation: 0.000000
09/16 09:37:02 AM: edges-srl-ontonotes_mcc: training: 0.774912 validation: 0.828054
09/16 09:37:02 AM: edges-srl-ontonotes_acc: training: 0.684334 validation: 0.762682
09/16 09:37:02 AM: edges-srl-ontonotes_precision: training: 0.832728 validation: 0.881802
09/16 09:37:02 AM: edges-srl-ontonotes_recall: training: 0.727006 validation: 0.782157
09/16 09:37:02 AM: edges-srl-ontonotes_f1: training: 0.776284 validation: 0.828996
09/16 09:37:02 AM: Global learning rate: 5e-05
09/16 09:37:02 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:37:03 AM: Update 16017: task edges-srl-ontonotes, batch 17 (16017): mcc: 0.7848, acc: 0.6984, precision: 0.8437, recall: 0.7357, f1: 0.7860, edges-srl-ontonotes_loss: 0.0166
09/16 09:37:13 AM: Update 16129: task edges-srl-ontonotes, batch 129 (16129): mcc: 0.7566, acc: 0.6617, precision: 0.8172, recall: 0.7068, f1: 0.7580, edges-srl-ontonotes_loss: 0.0187
09/16 09:37:23 AM: Update 16250: task edges-srl-ontonotes, batch 250 (16250): mcc: 0.7523, acc: 0.6565, precision: 0.8147, recall: 0.7012, f1: 0.7537, edges-srl-ontonotes_loss: 0.0191
09/16 09:37:35 AM: Update 16371: task edges-srl-ontonotes, batch 371 (16371): mcc: 0.7515, acc: 0.6545, precision: 0.8145, recall: 0.6997, f1: 0.7527, edges-srl-ontonotes_loss: 0.0192
09/16 09:37:45 AM: Update 16505: task edges-srl-ontonotes, batch 505 (16505): mcc: 0.7510, acc: 0.6543, precision: 0.8144, recall: 0.6990, f1: 0.7523, edges-srl-ontonotes_loss: 0.0192
09/16 09:37:56 AM: Update 16641: task edges-srl-ontonotes, batch 641 (16641): mcc: 0.7517, acc: 0.6548, precision: 0.8155, recall: 0.6993, f1: 0.7529, edges-srl-ontonotes_loss: 0.0192
09/16 09:38:06 AM: Update 16754: task edges-srl-ontonotes, batch 754 (16754): mcc: 0.7548, acc: 0.6585, precision: 0.8179, recall: 0.7030, f1: 0.7561, edges-srl-ontonotes_loss: 0.0190
09/16 09:38:16 AM: Update 16875: task edges-srl-ontonotes, batch 875 (16875): mcc: 0.7581, acc: 0.6630, precision: 0.8203, recall: 0.7069, f1: 0.7594, edges-srl-ontonotes_loss: 0.0188
09/16 09:38:26 AM: Update 16993: task edges-srl-ontonotes, batch 993 (16993): mcc: 0.7603, acc: 0.6661, precision: 0.8218, recall: 0.7096, f1: 0.7616, edges-srl-ontonotes_loss: 0.0186
09/16 09:38:27 AM: ***** Step 17000 / Validation 17 *****
09/16 09:38:27 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:38:27 AM: Validating...
09/16 09:38:36 AM: Evaluate: task edges-srl-ontonotes, batch 115 (157): mcc: 0.8216, acc: 0.7587, precision: 0.8701, recall: 0.7806, f1: 0.8230, edges-srl-ontonotes_loss: 0.0143
09/16 09:38:39 AM: Updating LR scheduler:
09/16 09:38:39 AM: 	Best result seen so far for macro_avg: 0.829
09/16 09:38:39 AM: 	# validation passes without improvement: 1
09/16 09:38:39 AM: edges-srl-ontonotes_loss: training: 0.018626 validation: 0.014337
09/16 09:38:39 AM: macro_avg: validation: 0.824349
09/16 09:38:39 AM: micro_avg: validation: 0.000000
09/16 09:38:39 AM: edges-srl-ontonotes_mcc: training: 0.760391 validation: 0.822949
09/16 09:38:39 AM: edges-srl-ontonotes_acc: training: 0.666120 validation: 0.761142
09/16 09:38:39 AM: edges-srl-ontonotes_precision: training: 0.821924 validation: 0.869829
09/16 09:38:39 AM: edges-srl-ontonotes_recall: training: 0.709666 validation: 0.783388
09/16 09:38:39 AM: edges-srl-ontonotes_f1: training: 0.761681 validation: 0.824349
09/16 09:38:39 AM: Global learning rate: 5e-05
09/16 09:38:39 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:38:46 AM: Update 17096: task edges-srl-ontonotes, batch 96 (17096): mcc: 0.7834, acc: 0.6999, precision: 0.8358, recall: 0.7401, f1: 0.7850, edges-srl-ontonotes_loss: 0.0171
09/16 09:38:56 AM: Update 17234: task edges-srl-ontonotes, batch 234 (17234): mcc: 0.7835, acc: 0.6987, precision: 0.8371, recall: 0.7392, f1: 0.7851, edges-srl-ontonotes_loss: 0.0171
09/16 09:39:06 AM: Update 17348: task edges-srl-ontonotes, batch 348 (17348): mcc: 0.7821, acc: 0.6970, precision: 0.8369, recall: 0.7366, f1: 0.7836, edges-srl-ontonotes_loss: 0.0172
09/16 09:39:16 AM: Update 17478: task edges-srl-ontonotes, batch 478 (17478): mcc: 0.7830, acc: 0.6975, precision: 0.8384, recall: 0.7369, f1: 0.7844, edges-srl-ontonotes_loss: 0.0171
09/16 09:39:26 AM: Update 17605: task edges-srl-ontonotes, batch 605 (17605): mcc: 0.7852, acc: 0.7001, precision: 0.8408, recall: 0.7389, f1: 0.7866, edges-srl-ontonotes_loss: 0.0170
09/16 09:39:36 AM: Update 17702: task edges-srl-ontonotes, batch 702 (17702): mcc: 0.7833, acc: 0.6974, precision: 0.8396, recall: 0.7364, f1: 0.7846, edges-srl-ontonotes_loss: 0.0171
09/16 09:39:46 AM: Update 17831: task edges-srl-ontonotes, batch 831 (17831): mcc: 0.7817, acc: 0.6957, precision: 0.8389, recall: 0.7342, f1: 0.7831, edges-srl-ontonotes_loss: 0.0172
09/16 09:39:56 AM: Update 17941: task edges-srl-ontonotes, batch 941 (17941): mcc: 0.7809, acc: 0.6947, precision: 0.8385, recall: 0.7330, f1: 0.7822, edges-srl-ontonotes_loss: 0.0173
09/16 09:40:01 AM: ***** Step 18000 / Validation 18 *****
09/16 09:40:01 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:40:01 AM: Validating...
09/16 09:40:06 AM: Evaluate: task edges-srl-ontonotes, batch 69 (157): mcc: 0.8081, acc: 0.7375, precision: 0.8670, recall: 0.7582, f1: 0.8089, edges-srl-ontonotes_loss: 0.0152
09/16 09:40:13 AM: Updating LR scheduler:
09/16 09:40:13 AM: 	Best result seen so far for macro_avg: 0.829
09/16 09:40:13 AM: 	# validation passes without improvement: 2
09/16 09:40:13 AM: edges-srl-ontonotes_loss: training: 0.017369 validation: 0.014381
09/16 09:40:13 AM: macro_avg: validation: 0.824052
09/16 09:40:13 AM: micro_avg: validation: 0.000000
09/16 09:40:13 AM: edges-srl-ontonotes_mcc: training: 0.779637 validation: 0.822954
09/16 09:40:13 AM: edges-srl-ontonotes_acc: training: 0.693100 validation: 0.756216
09/16 09:40:13 AM: edges-srl-ontonotes_precision: training: 0.837664 validation: 0.875216
09/16 09:40:13 AM: edges-srl-ontonotes_recall: training: 0.731400 validation: 0.778539
09/16 09:40:13 AM: edges-srl-ontonotes_f1: training: 0.780934 validation: 0.824052
09/16 09:40:13 AM: Global learning rate: 5e-05
09/16 09:40:13 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:40:16 AM: Update 18041: task edges-srl-ontonotes, batch 41 (18041): mcc: 0.7711, acc: 0.6838, precision: 0.8329, recall: 0.7197, f1: 0.7722, edges-srl-ontonotes_loss: 0.0179
09/16 09:40:26 AM: Update 18172: task edges-srl-ontonotes, batch 172 (18172): mcc: 0.7744, acc: 0.6842, precision: 0.8360, recall: 0.7232, f1: 0.7755, edges-srl-ontonotes_loss: 0.0177
09/16 09:40:36 AM: Update 18294: task edges-srl-ontonotes, batch 294 (18294): mcc: 0.7738, acc: 0.6831, precision: 0.8353, recall: 0.7228, f1: 0.7750, edges-srl-ontonotes_loss: 0.0178
09/16 09:40:46 AM: Update 18428: task edges-srl-ontonotes, batch 428 (18428): mcc: 0.7693, acc: 0.6788, precision: 0.8313, recall: 0.7179, f1: 0.7704, edges-srl-ontonotes_loss: 0.0180
09/16 09:40:56 AM: Update 18553: task edges-srl-ontonotes, batch 553 (18553): mcc: 0.7704, acc: 0.6796, precision: 0.8319, recall: 0.7194, f1: 0.7716, edges-srl-ontonotes_loss: 0.0180
09/16 09:41:07 AM: Update 18648: task edges-srl-ontonotes, batch 648 (18648): mcc: 0.7726, acc: 0.6825, precision: 0.8334, recall: 0.7221, f1: 0.7738, edges-srl-ontonotes_loss: 0.0178
09/16 09:41:17 AM: Update 18777: task edges-srl-ontonotes, batch 777 (18777): mcc: 0.7729, acc: 0.6834, precision: 0.8337, recall: 0.7224, f1: 0.7741, edges-srl-ontonotes_loss: 0.0178
09/16 09:41:27 AM: Update 18890: task edges-srl-ontonotes, batch 890 (18890): mcc: 0.7743, acc: 0.6855, precision: 0.8344, recall: 0.7244, f1: 0.7755, edges-srl-ontonotes_loss: 0.0177
09/16 09:41:35 AM: ***** Step 19000 / Validation 19 *****
09/16 09:41:35 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:41:35 AM: Validating...
09/16 09:41:37 AM: Evaluate: task edges-srl-ontonotes, batch 18 (157): mcc: 0.8193, acc: 0.7482, precision: 0.8761, recall: 0.7709, f1: 0.8202, edges-srl-ontonotes_loss: 0.0143
09/16 09:41:47 AM: Evaluate: task edges-srl-ontonotes, batch 153 (157): mcc: 0.8173, acc: 0.7473, precision: 0.8766, recall: 0.7668, f1: 0.8180, edges-srl-ontonotes_loss: 0.0146
09/16 09:41:47 AM: Updating LR scheduler:
09/16 09:41:47 AM: 	Best result seen so far for macro_avg: 0.829
09/16 09:41:47 AM: 	# validation passes without improvement: 3
09/16 09:41:47 AM: edges-srl-ontonotes_loss: training: 0.017657 validation: 0.014722
09/16 09:41:47 AM: macro_avg: validation: 0.817361
09/16 09:41:47 AM: micro_avg: validation: 0.000000
09/16 09:41:47 AM: edges-srl-ontonotes_mcc: training: 0.775538 validation: 0.816621
09/16 09:41:47 AM: edges-srl-ontonotes_acc: training: 0.687196 validation: 0.746594
09/16 09:41:47 AM: edges-srl-ontonotes_precision: training: 0.835645 validation: 0.875913
09/16 09:41:47 AM: edges-srl-ontonotes_recall: training: 0.725598 validation: 0.766146
09/16 09:41:47 AM: edges-srl-ontonotes_f1: training: 0.776743 validation: 0.817361
09/16 09:41:47 AM: Global learning rate: 5e-05
09/16 09:41:47 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:41:57 AM: Update 19119: task edges-srl-ontonotes, batch 119 (19119): mcc: 0.7805, acc: 0.6959, precision: 0.8352, recall: 0.7352, f1: 0.7820, edges-srl-ontonotes_loss: 0.0172
09/16 09:42:07 AM: Update 19227: task edges-srl-ontonotes, batch 227 (19227): mcc: 0.7731, acc: 0.6860, precision: 0.8319, recall: 0.7243, f1: 0.7744, edges-srl-ontonotes_loss: 0.0177
09/16 09:42:17 AM: Update 19347: task edges-srl-ontonotes, batch 347 (19347): mcc: 0.7657, acc: 0.6767, precision: 0.8276, recall: 0.7146, f1: 0.7669, edges-srl-ontonotes_loss: 0.0181
09/16 09:42:27 AM: Update 19464: task edges-srl-ontonotes, batch 464 (19464): mcc: 0.7640, acc: 0.6736, precision: 0.8281, recall: 0.7109, f1: 0.7650, edges-srl-ontonotes_loss: 0.0183
09/16 09:42:37 AM: Update 19589: task edges-srl-ontonotes, batch 589 (19589): mcc: 0.7695, acc: 0.6803, precision: 0.8316, recall: 0.7180, f1: 0.7706, edges-srl-ontonotes_loss: 0.0179
09/16 09:42:47 AM: Update 19726: task edges-srl-ontonotes, batch 726 (19726): mcc: 0.7738, acc: 0.6849, precision: 0.8346, recall: 0.7233, f1: 0.7750, edges-srl-ontonotes_loss: 0.0176
09/16 09:42:57 AM: Update 19835: task edges-srl-ontonotes, batch 835 (19835): mcc: 0.7768, acc: 0.6882, precision: 0.8362, recall: 0.7273, f1: 0.7780, edges-srl-ontonotes_loss: 0.0174
09/16 09:43:07 AM: Update 19999: task edges-srl-ontonotes, batch 999 (19999): mcc: 0.7846, acc: 0.6978, precision: 0.8412, recall: 0.7375, f1: 0.7860, edges-srl-ontonotes_loss: 0.0169
09/16 09:43:07 AM: ***** Step 20000 / Validation 20 *****
09/16 09:43:07 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:43:07 AM: Validating...
09/16 09:43:17 AM: Evaluate: task edges-srl-ontonotes, batch 134 (157): mcc: 0.8210, acc: 0.7504, precision: 0.8774, recall: 0.7729, f1: 0.8218, edges-srl-ontonotes_loss: 0.0144
09/16 09:43:19 AM: Updating LR scheduler:
09/16 09:43:19 AM: 	Best result seen so far for macro_avg: 0.829
09/16 09:43:19 AM: 	# validation passes without improvement: 0
09/16 09:43:19 AM: edges-srl-ontonotes_loss: training: 0.016864 validation: 0.014532
09/16 09:43:19 AM: macro_avg: validation: 0.819121
09/16 09:43:19 AM: micro_avg: validation: 0.000000
09/16 09:43:19 AM: edges-srl-ontonotes_mcc: training: 0.784637 validation: 0.818313
09/16 09:43:19 AM: edges-srl-ontonotes_acc: training: 0.697757 validation: 0.747210
09/16 09:43:19 AM: edges-srl-ontonotes_precision: training: 0.841270 validation: 0.876239
09/16 09:43:19 AM: edges-srl-ontonotes_recall: training: 0.737481 validation: 0.768994
09/16 09:43:19 AM: edges-srl-ontonotes_f1: training: 0.785964 validation: 0.819121
09/16 09:43:19 AM: Global learning rate: 2.5e-05
09/16 09:43:19 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:43:27 AM: Update 20128: task edges-srl-ontonotes, batch 128 (20128): mcc: 0.8248, acc: 0.7463, precision: 0.8692, recall: 0.7875, f1: 0.8263, edges-srl-ontonotes_loss: 0.0138
09/16 09:43:37 AM: Update 20285: task edges-srl-ontonotes, batch 285 (20285): mcc: 0.8209, acc: 0.7416, precision: 0.8669, recall: 0.7822, f1: 0.8223, edges-srl-ontonotes_loss: 0.0142
09/16 09:43:48 AM: Update 20440: task edges-srl-ontonotes, batch 440 (20440): mcc: 0.8203, acc: 0.7407, precision: 0.8666, recall: 0.7813, f1: 0.8217, edges-srl-ontonotes_loss: 0.0143
09/16 09:43:58 AM: Update 20598: task edges-srl-ontonotes, batch 598 (20598): mcc: 0.8210, acc: 0.7411, precision: 0.8669, recall: 0.7824, f1: 0.8225, edges-srl-ontonotes_loss: 0.0143
09/16 09:44:10 AM: Update 20753: task edges-srl-ontonotes, batch 753 (20753): mcc: 0.8210, acc: 0.7406, precision: 0.8667, recall: 0.7826, f1: 0.8225, edges-srl-ontonotes_loss: 0.0144
09/16 09:44:20 AM: Update 20929: task edges-srl-ontonotes, batch 929 (20929): mcc: 0.8220, acc: 0.7421, precision: 0.8678, recall: 0.7835, f1: 0.8235, edges-srl-ontonotes_loss: 0.0144
09/16 09:44:24 AM: ***** Step 21000 / Validation 21 *****
09/16 09:44:24 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:44:24 AM: Validating...
09/16 09:44:30 AM: Evaluate: task edges-srl-ontonotes, batch 77 (157): mcc: 0.8126, acc: 0.7422, precision: 0.8761, recall: 0.7586, f1: 0.8131, edges-srl-ontonotes_loss: 0.0148
09/16 09:44:36 AM: Updating LR scheduler:
09/16 09:44:36 AM: 	Best result seen so far for macro_avg: 0.829
09/16 09:44:36 AM: 	# validation passes without improvement: 1
09/16 09:44:36 AM: edges-srl-ontonotes_loss: training: 0.014269 validation: 0.014083
09/16 09:44:36 AM: macro_avg: validation: 0.826507
09/16 09:44:36 AM: micro_avg: validation: 0.000000
09/16 09:44:36 AM: edges-srl-ontonotes_mcc: training: 0.823402 validation: 0.825761
09/16 09:44:36 AM: edges-srl-ontonotes_acc: training: 0.744039 validation: 0.758987
09/16 09:44:36 AM: edges-srl-ontonotes_precision: training: 0.868770 validation: 0.883151
09/16 09:44:36 AM: edges-srl-ontonotes_recall: training: 0.785204 validation: 0.776692
09/16 09:44:36 AM: edges-srl-ontonotes_f1: training: 0.824876 validation: 0.826507
09/16 09:44:36 AM: Global learning rate: 2.5e-05
09/16 09:44:36 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:44:41 AM: Update 21066: task edges-srl-ontonotes, batch 66 (21066): mcc: 0.8275, acc: 0.7464, precision: 0.8663, recall: 0.7952, f1: 0.8292, edges-srl-ontonotes_loss: 0.0138
09/16 09:44:51 AM: Update 21210: task edges-srl-ontonotes, batch 210 (21210): mcc: 0.8072, acc: 0.7226, precision: 0.8550, recall: 0.7672, f1: 0.8087, edges-srl-ontonotes_loss: 0.0155
09/16 09:45:01 AM: Update 21332: task edges-srl-ontonotes, batch 332 (21332): mcc: 0.8014, acc: 0.7167, precision: 0.8495, recall: 0.7614, f1: 0.8031, edges-srl-ontonotes_loss: 0.0160
09/16 09:45:11 AM: Update 21447: task edges-srl-ontonotes, batch 447 (21447): mcc: 0.7951, acc: 0.7088, precision: 0.8453, recall: 0.7534, f1: 0.7967, edges-srl-ontonotes_loss: 0.0165
09/16 09:45:21 AM: Update 21578: task edges-srl-ontonotes, batch 578 (21578): mcc: 0.7920, acc: 0.7048, precision: 0.8438, recall: 0.7489, f1: 0.7935, edges-srl-ontonotes_loss: 0.0167
09/16 09:45:31 AM: Update 21700: task edges-srl-ontonotes, batch 700 (21700): mcc: 0.7890, acc: 0.7017, precision: 0.8421, recall: 0.7448, f1: 0.7905, edges-srl-ontonotes_loss: 0.0169
09/16 09:45:41 AM: Update 21807: task edges-srl-ontonotes, batch 807 (21807): mcc: 0.7892, acc: 0.7017, precision: 0.8426, recall: 0.7447, f1: 0.7906, edges-srl-ontonotes_loss: 0.0169
09/16 09:45:51 AM: Update 21972: task edges-srl-ontonotes, batch 972 (21972): mcc: 0.7905, acc: 0.7029, precision: 0.8440, recall: 0.7460, f1: 0.7920, edges-srl-ontonotes_loss: 0.0168
09/16 09:45:53 AM: ***** Step 22000 / Validation 22 *****
09/16 09:45:53 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:45:53 AM: Validating...
09/16 09:46:01 AM: Evaluate: task edges-srl-ontonotes, batch 111 (157): mcc: 0.8296, acc: 0.7666, precision: 0.8784, recall: 0.7881, f1: 0.8308, edges-srl-ontonotes_loss: 0.0137
09/16 09:46:05 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:46:05 AM: Best result seen so far for macro.
09/16 09:46:05 AM: Updating LR scheduler:
09/16 09:46:05 AM: 	Best result seen so far for macro_avg: 0.831
09/16 09:46:05 AM: 	# validation passes without improvement: 0
09/16 09:46:05 AM: edges-srl-ontonotes_loss: training: 0.016746 validation: 0.013793
09/16 09:46:05 AM: macro_avg: validation: 0.831138
09/16 09:46:05 AM: micro_avg: validation: 0.000000
09/16 09:46:05 AM: edges-srl-ontonotes_mcc: training: 0.790698 validation: 0.829875
09/16 09:46:05 AM: edges-srl-ontonotes_acc: training: 0.703062 validation: 0.768224
09/16 09:46:05 AM: edges-srl-ontonotes_precision: training: 0.844188 validation: 0.877546
09/16 09:46:05 AM: edges-srl-ontonotes_recall: training: 0.746151 validation: 0.789393
09/16 09:46:05 AM: edges-srl-ontonotes_f1: training: 0.792148 validation: 0.831138
09/16 09:46:05 AM: Global learning rate: 2.5e-05
09/16 09:46:05 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:46:11 AM: Update 22086: task edges-srl-ontonotes, batch 86 (22086): mcc: 0.8007, acc: 0.7152, precision: 0.8543, recall: 0.7557, f1: 0.8020, edges-srl-ontonotes_loss: 0.0163
09/16 09:46:21 AM: Update 22239: task edges-srl-ontonotes, batch 239 (22239): mcc: 0.7987, acc: 0.7118, precision: 0.8518, recall: 0.7542, f1: 0.8001, edges-srl-ontonotes_loss: 0.0161
09/16 09:46:31 AM: Update 22381: task edges-srl-ontonotes, batch 381 (22381): mcc: 0.8002, acc: 0.7146, precision: 0.8532, recall: 0.7558, f1: 0.8015, edges-srl-ontonotes_loss: 0.0161
09/16 09:46:41 AM: Update 22521: task edges-srl-ontonotes, batch 521 (22521): mcc: 0.7953, acc: 0.7089, precision: 0.8493, recall: 0.7501, f1: 0.7967, edges-srl-ontonotes_loss: 0.0164
09/16 09:46:52 AM: Update 22664: task edges-srl-ontonotes, batch 664 (22664): mcc: 0.7950, acc: 0.7090, precision: 0.8486, recall: 0.7503, f1: 0.7964, edges-srl-ontonotes_loss: 0.0164
09/16 09:47:02 AM: Update 22765: task edges-srl-ontonotes, batch 765 (22765): mcc: 0.7927, acc: 0.7064, precision: 0.8470, recall: 0.7474, f1: 0.7941, edges-srl-ontonotes_loss: 0.0166
09/16 09:47:12 AM: Update 22915: task edges-srl-ontonotes, batch 915 (22915): mcc: 0.7890, acc: 0.7021, precision: 0.8441, recall: 0.7431, f1: 0.7904, edges-srl-ontonotes_loss: 0.0168
09/16 09:47:18 AM: ***** Step 23000 / Validation 23 *****
09/16 09:47:18 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:47:18 AM: Validating...
09/16 09:47:22 AM: Evaluate: task edges-srl-ontonotes, batch 42 (157): mcc: 0.8136, acc: 0.7448, precision: 0.8740, recall: 0.7623, f1: 0.8143, edges-srl-ontonotes_loss: 0.0147
09/16 09:47:31 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:47:31 AM: Best result seen so far for macro.
09/16 09:47:31 AM: Updating LR scheduler:
09/16 09:47:31 AM: 	Best result seen so far for macro_avg: 0.833
09/16 09:47:31 AM: 	# validation passes without improvement: 0
09/16 09:47:31 AM: edges-srl-ontonotes_loss: training: 0.016910 validation: 0.013552
09/16 09:47:31 AM: macro_avg: validation: 0.832851
09/16 09:47:31 AM: micro_avg: validation: 0.000000
09/16 09:47:31 AM: edges-srl-ontonotes_mcc: training: 0.787786 validation: 0.831896
09/16 09:47:31 AM: edges-srl-ontonotes_acc: training: 0.700301 validation: 0.768455
09/16 09:47:31 AM: edges-srl-ontonotes_precision: training: 0.843162 validation: 0.884562
09/16 09:47:31 AM: edges-srl-ontonotes_recall: training: 0.741648 validation: 0.786852
09/16 09:47:31 AM: edges-srl-ontonotes_f1: training: 0.789154 validation: 0.832851
09/16 09:47:31 AM: Global learning rate: 2.5e-05
09/16 09:47:31 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:47:32 AM: Update 23010: task edges-srl-ontonotes, batch 10 (23010): mcc: 0.7699, acc: 0.6780, precision: 0.8324, recall: 0.7181, f1: 0.7710, edges-srl-ontonotes_loss: 0.0175
09/16 09:47:42 AM: Update 23154: task edges-srl-ontonotes, batch 154 (23154): mcc: 0.7751, acc: 0.6865, precision: 0.8345, recall: 0.7259, f1: 0.7764, edges-srl-ontonotes_loss: 0.0174
09/16 09:47:52 AM: Update 23282: task edges-srl-ontonotes, batch 282 (23282): mcc: 0.7720, acc: 0.6827, precision: 0.8305, recall: 0.7235, f1: 0.7733, edges-srl-ontonotes_loss: 0.0175
09/16 09:48:02 AM: Update 23399: task edges-srl-ontonotes, batch 399 (23399): mcc: 0.7670, acc: 0.6772, precision: 0.8266, recall: 0.7178, f1: 0.7683, edges-srl-ontonotes_loss: 0.0179
09/16 09:48:12 AM: Update 23530: task edges-srl-ontonotes, batch 530 (23530): mcc: 0.7641, acc: 0.6739, precision: 0.8243, recall: 0.7144, f1: 0.7654, edges-srl-ontonotes_loss: 0.0182
09/16 09:48:22 AM: Update 23649: task edges-srl-ontonotes, batch 649 (23649): mcc: 0.7632, acc: 0.6726, precision: 0.8233, recall: 0.7136, f1: 0.7645, edges-srl-ontonotes_loss: 0.0182
09/16 09:48:32 AM: Update 23770: task edges-srl-ontonotes, batch 770 (23770): mcc: 0.7622, acc: 0.6712, precision: 0.8226, recall: 0.7124, f1: 0.7635, edges-srl-ontonotes_loss: 0.0183
09/16 09:48:42 AM: Update 23900: task edges-srl-ontonotes, batch 900 (23900): mcc: 0.7617, acc: 0.6706, precision: 0.8225, recall: 0.7115, f1: 0.7630, edges-srl-ontonotes_loss: 0.0184
09/16 09:48:52 AM: Update 23995: task edges-srl-ontonotes, batch 995 (23995): mcc: 0.7630, acc: 0.6722, precision: 0.8235, recall: 0.7130, f1: 0.7643, edges-srl-ontonotes_loss: 0.0183
09/16 09:48:52 AM: ***** Step 24000 / Validation 24 *****
09/16 09:48:52 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:48:52 AM: Validating...
09/16 09:49:02 AM: Evaluate: task edges-srl-ontonotes, batch 130 (157): mcc: 0.8349, acc: 0.7745, precision: 0.8818, recall: 0.7950, f1: 0.8361, edges-srl-ontonotes_loss: 0.0134
09/16 09:49:04 AM: Updating LR scheduler:
09/16 09:49:04 AM: 	Best result seen so far for macro_avg: 0.833
09/16 09:49:04 AM: 	# validation passes without improvement: 1
09/16 09:49:04 AM: edges-srl-ontonotes_loss: training: 0.018277 validation: 0.013699
09/16 09:49:04 AM: macro_avg: validation: 0.832096
09/16 09:49:04 AM: micro_avg: validation: 0.000000
09/16 09:49:04 AM: edges-srl-ontonotes_mcc: training: 0.762849 validation: 0.830902
09/16 09:49:04 AM: edges-srl-ontonotes_acc: training: 0.672047 validation: 0.769225
09/16 09:49:04 AM: edges-srl-ontonotes_precision: training: 0.823357 validation: 0.879588
09/16 09:49:04 AM: edges-srl-ontonotes_recall: training: 0.712945 validation: 0.789470
09/16 09:49:04 AM: edges-srl-ontonotes_f1: training: 0.764183 validation: 0.832096
09/16 09:49:04 AM: Global learning rate: 2.5e-05
09/16 09:49:04 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:49:12 AM: Update 24095: task edges-srl-ontonotes, batch 95 (24095): mcc: 0.7849, acc: 0.7012, precision: 0.8414, recall: 0.7379, f1: 0.7863, edges-srl-ontonotes_loss: 0.0172
09/16 09:49:22 AM: Update 24210: task edges-srl-ontonotes, batch 210 (24210): mcc: 0.7835, acc: 0.6985, precision: 0.8388, recall: 0.7376, f1: 0.7850, edges-srl-ontonotes_loss: 0.0170
09/16 09:49:32 AM: Update 24328: task edges-srl-ontonotes, batch 328 (24328): mcc: 0.7839, acc: 0.6988, precision: 0.8390, recall: 0.7381, f1: 0.7853, edges-srl-ontonotes_loss: 0.0169
09/16 09:49:42 AM: Update 24447: task edges-srl-ontonotes, batch 447 (24447): mcc: 0.7833, acc: 0.6980, precision: 0.8386, recall: 0.7373, f1: 0.7847, edges-srl-ontonotes_loss: 0.0170
09/16 09:49:52 AM: Update 24564: task edges-srl-ontonotes, batch 564 (24564): mcc: 0.7843, acc: 0.6993, precision: 0.8396, recall: 0.7383, f1: 0.7857, edges-srl-ontonotes_loss: 0.0169
09/16 09:50:02 AM: Update 24689: task edges-srl-ontonotes, batch 689 (24689): mcc: 0.7855, acc: 0.7004, precision: 0.8404, recall: 0.7398, f1: 0.7869, edges-srl-ontonotes_loss: 0.0169
09/16 09:50:12 AM: Update 24809: task edges-srl-ontonotes, batch 809 (24809): mcc: 0.7864, acc: 0.7018, precision: 0.8414, recall: 0.7407, f1: 0.7878, edges-srl-ontonotes_loss: 0.0168
09/16 09:50:22 AM: Update 24895: task edges-srl-ontonotes, batch 895 (24895): mcc: 0.7868, acc: 0.7022, precision: 0.8416, recall: 0.7412, f1: 0.7882, edges-srl-ontonotes_loss: 0.0168
09/16 09:50:31 AM: ***** Step 25000 / Validation 25 *****
09/16 09:50:31 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:50:31 AM: Validating...
09/16 09:50:32 AM: Evaluate: task edges-srl-ontonotes, batch 19 (157): mcc: 0.8350, acc: 0.7737, precision: 0.8885, recall: 0.7891, f1: 0.8358, edges-srl-ontonotes_loss: 0.0133
09/16 09:50:42 AM: Evaluate: task edges-srl-ontonotes, batch 154 (157): mcc: 0.8294, acc: 0.7664, precision: 0.8824, recall: 0.7841, f1: 0.8303, edges-srl-ontonotes_loss: 0.0137
09/16 09:50:42 AM: Updating LR scheduler:
09/16 09:50:42 AM: 	Best result seen so far for macro_avg: 0.833
09/16 09:50:42 AM: 	# validation passes without improvement: 2
09/16 09:50:42 AM: edges-srl-ontonotes_loss: training: 0.016890 validation: 0.013794
09/16 09:50:42 AM: macro_avg: validation: 0.829767
09/16 09:50:42 AM: micro_avg: validation: 0.000000
09/16 09:50:42 AM: edges-srl-ontonotes_mcc: training: 0.785782 validation: 0.828785
09/16 09:50:42 AM: edges-srl-ontonotes_acc: training: 0.700688 validation: 0.765761
09/16 09:50:42 AM: edges-srl-ontonotes_precision: training: 0.840929 validation: 0.881691
09/16 09:50:42 AM: edges-srl-ontonotes_recall: training: 0.739909 validation: 0.783619
09/16 09:50:42 AM: edges-srl-ontonotes_f1: training: 0.787191 validation: 0.829767
09/16 09:50:42 AM: Global learning rate: 2.5e-05
09/16 09:50:42 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:50:52 AM: Update 25128: task edges-srl-ontonotes, batch 128 (25128): mcc: 0.7710, acc: 0.6865, precision: 0.8278, recall: 0.7241, f1: 0.7725, edges-srl-ontonotes_loss: 0.0177
09/16 09:51:02 AM: Update 25254: task edges-srl-ontonotes, batch 254 (25254): mcc: 0.7742, acc: 0.6880, precision: 0.8318, recall: 0.7265, f1: 0.7756, edges-srl-ontonotes_loss: 0.0176
09/16 09:51:12 AM: Update 25396: task edges-srl-ontonotes, batch 396 (25396): mcc: 0.7761, acc: 0.6905, precision: 0.8336, recall: 0.7285, f1: 0.7775, edges-srl-ontonotes_loss: 0.0175
09/16 09:51:22 AM: Update 25516: task edges-srl-ontonotes, batch 516 (25516): mcc: 0.7756, acc: 0.6895, precision: 0.8334, recall: 0.7276, f1: 0.7769, edges-srl-ontonotes_loss: 0.0176
09/16 09:51:32 AM: Update 25652: task edges-srl-ontonotes, batch 652 (25652): mcc: 0.7751, acc: 0.6884, precision: 0.8331, recall: 0.7271, f1: 0.7765, edges-srl-ontonotes_loss: 0.0176
09/16 09:51:43 AM: Update 25789: task edges-srl-ontonotes, batch 789 (25789): mcc: 0.7743, acc: 0.6873, precision: 0.8329, recall: 0.7259, f1: 0.7757, edges-srl-ontonotes_loss: 0.0176
09/16 09:51:53 AM: Update 25882: task edges-srl-ontonotes, batch 882 (25882): mcc: 0.7747, acc: 0.6874, precision: 0.8335, recall: 0.7260, f1: 0.7760, edges-srl-ontonotes_loss: 0.0176
09/16 09:52:01 AM: ***** Step 26000 / Validation 26 *****
09/16 09:52:01 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:52:01 AM: Validating...
09/16 09:52:03 AM: Evaluate: task edges-srl-ontonotes, batch 18 (157): mcc: 0.8275, acc: 0.7625, precision: 0.8808, recall: 0.7820, f1: 0.8285, edges-srl-ontonotes_loss: 0.0139
09/16 09:52:13 AM: Evaluate: task edges-srl-ontonotes, batch 153 (157): mcc: 0.8266, acc: 0.7642, precision: 0.8770, recall: 0.7838, f1: 0.8278, edges-srl-ontonotes_loss: 0.0140
09/16 09:52:13 AM: Updating LR scheduler:
09/16 09:52:13 AM: 	Best result seen so far for macro_avg: 0.833
09/16 09:52:13 AM: 	# validation passes without improvement: 3
09/16 09:52:13 AM: edges-srl-ontonotes_loss: training: 0.017524 validation: 0.014084
09/16 09:52:13 AM: macro_avg: validation: 0.827183
09/16 09:52:13 AM: micro_avg: validation: 0.000000
09/16 09:52:13 AM: edges-srl-ontonotes_mcc: training: 0.776064 validation: 0.826009
09/16 09:52:13 AM: edges-srl-ontonotes_acc: training: 0.689180 validation: 0.763452
09/16 09:52:13 AM: edges-srl-ontonotes_precision: training: 0.834138 validation: 0.876259
09/16 09:52:13 AM: edges-srl-ontonotes_recall: training: 0.727895 validation: 0.783312
09/16 09:52:13 AM: edges-srl-ontonotes_f1: training: 0.777403 validation: 0.827183
09/16 09:52:13 AM: Global learning rate: 2.5e-05
09/16 09:52:13 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:52:23 AM: Update 26121: task edges-srl-ontonotes, batch 121 (26121): mcc: 0.7856, acc: 0.7004, precision: 0.8437, recall: 0.7372, f1: 0.7868, edges-srl-ontonotes_loss: 0.0170
09/16 09:52:34 AM: Update 26255: task edges-srl-ontonotes, batch 255 (26255): mcc: 0.7877, acc: 0.7045, precision: 0.8443, recall: 0.7406, f1: 0.7890, edges-srl-ontonotes_loss: 0.0169
09/16 09:52:44 AM: Update 26387: task edges-srl-ontonotes, batch 387 (26387): mcc: 0.7890, acc: 0.7063, precision: 0.8449, recall: 0.7422, f1: 0.7903, edges-srl-ontonotes_loss: 0.0167
09/16 09:52:54 AM: Update 26487: task edges-srl-ontonotes, batch 487 (26487): mcc: 0.7837, acc: 0.6995, precision: 0.8419, recall: 0.7352, f1: 0.7849, edges-srl-ontonotes_loss: 0.0171
09/16 09:53:04 AM: Update 26601: task edges-srl-ontonotes, batch 601 (26601): mcc: 0.7791, acc: 0.6936, precision: 0.8388, recall: 0.7294, f1: 0.7802, edges-srl-ontonotes_loss: 0.0175
09/16 09:53:14 AM: Update 26724: task edges-srl-ontonotes, batch 724 (26724): mcc: 0.7772, acc: 0.6907, precision: 0.8382, recall: 0.7265, f1: 0.7784, edges-srl-ontonotes_loss: 0.0176
09/16 09:53:24 AM: Update 26863: task edges-srl-ontonotes, batch 863 (26863): mcc: 0.7800, acc: 0.6944, precision: 0.8397, recall: 0.7302, f1: 0.7811, edges-srl-ontonotes_loss: 0.0174
09/16 09:53:34 AM: ***** Step 27000 / Validation 27 *****
09/16 09:53:34 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:53:34 AM: Validating...
09/16 09:53:34 AM: Evaluate: task edges-srl-ontonotes, batch 3 (157): mcc: 0.8529, acc: 0.7774, precision: 0.9138, recall: 0.8000, f1: 0.8531, edges-srl-ontonotes_loss: 0.0125
09/16 09:53:44 AM: Evaluate: task edges-srl-ontonotes, batch 131 (157): mcc: 0.8285, acc: 0.7630, precision: 0.8846, recall: 0.7806, f1: 0.8293, edges-srl-ontonotes_loss: 0.0138
09/16 09:53:46 AM: Updating LR scheduler:
09/16 09:53:46 AM: 	Best result seen so far for macro_avg: 0.833
09/16 09:53:46 AM: 	# validation passes without improvement: 0
09/16 09:53:46 AM: edges-srl-ontonotes_loss: training: 0.017119 validation: 0.014010
09/16 09:53:46 AM: macro_avg: validation: 0.825920
09/16 09:53:46 AM: micro_avg: validation: 0.000000
09/16 09:53:46 AM: edges-srl-ontonotes_mcc: training: 0.783605 validation: 0.825169
09/16 09:53:46 AM: edges-srl-ontonotes_acc: training: 0.699107 validation: 0.758294
09/16 09:53:46 AM: edges-srl-ontonotes_precision: training: 0.842208 validation: 0.882605
09/16 09:53:46 AM: edges-srl-ontonotes_recall: training: 0.734740 validation: 0.776076
09/16 09:53:46 AM: edges-srl-ontonotes_f1: training: 0.784812 validation: 0.825920
09/16 09:53:46 AM: Global learning rate: 1.25e-05
09/16 09:53:46 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:53:54 AM: Update 27082: task edges-srl-ontonotes, batch 82 (27082): mcc: 0.8065, acc: 0.7245, precision: 0.8594, recall: 0.7619, f1: 0.8077, edges-srl-ontonotes_loss: 0.0154
09/16 09:54:04 AM: Update 27243: task edges-srl-ontonotes, batch 243 (27243): mcc: 0.8184, acc: 0.7409, precision: 0.8651, recall: 0.7792, f1: 0.8199, edges-srl-ontonotes_loss: 0.0145
09/16 09:54:14 AM: Update 27399: task edges-srl-ontonotes, batch 399 (27399): mcc: 0.8200, acc: 0.7423, precision: 0.8654, recall: 0.7819, f1: 0.8216, edges-srl-ontonotes_loss: 0.0143
09/16 09:54:24 AM: Update 27553: task edges-srl-ontonotes, batch 553 (27553): mcc: 0.8202, acc: 0.7423, precision: 0.8652, recall: 0.7824, f1: 0.8217, edges-srl-ontonotes_loss: 0.0144
09/16 09:54:34 AM: Update 27711: task edges-srl-ontonotes, batch 711 (27711): mcc: 0.8205, acc: 0.7426, precision: 0.8658, recall: 0.7824, f1: 0.8220, edges-srl-ontonotes_loss: 0.0143
09/16 09:54:44 AM: Update 27887: task edges-srl-ontonotes, batch 887 (27887): mcc: 0.8211, acc: 0.7433, precision: 0.8664, recall: 0.7831, f1: 0.8226, edges-srl-ontonotes_loss: 0.0143
09/16 09:54:54 AM: ***** Step 28000 / Validation 28 *****
09/16 09:54:54 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:54:54 AM: Validating...
09/16 09:54:54 AM: Evaluate: task edges-srl-ontonotes, batch 2 (157): mcc: 0.8639, acc: 0.7955, precision: 0.9226, recall: 0.8125, f1: 0.8640, edges-srl-ontonotes_loss: 0.0120
09/16 09:55:04 AM: Evaluate: task edges-srl-ontonotes, batch 139 (157): mcc: 0.8300, acc: 0.7651, precision: 0.8837, recall: 0.7841, f1: 0.8309, edges-srl-ontonotes_loss: 0.0136
09/16 09:55:05 AM: Updating LR scheduler:
09/16 09:55:05 AM: 	Best result seen so far for macro_avg: 0.833
09/16 09:55:05 AM: 	# validation passes without improvement: 1
09/16 09:55:05 AM: edges-srl-ontonotes_loss: training: 0.014285 validation: 0.013790
09/16 09:55:05 AM: macro_avg: validation: 0.829151
09/16 09:55:05 AM: micro_avg: validation: 0.000000
09/16 09:55:05 AM: edges-srl-ontonotes_mcc: training: 0.821732 validation: 0.828228
09/16 09:55:05 AM: edges-srl-ontonotes_acc: training: 0.744243 validation: 0.763144
09/16 09:55:05 AM: edges-srl-ontonotes_precision: training: 0.867009 validation: 0.882251
09/16 09:55:05 AM: edges-srl-ontonotes_recall: training: 0.783665 validation: 0.782080
09/16 09:55:05 AM: edges-srl-ontonotes_f1: training: 0.823233 validation: 0.829151
09/16 09:55:05 AM: Global learning rate: 1.25e-05
09/16 09:55:05 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:55:14 AM: Update 28146: task edges-srl-ontonotes, batch 146 (28146): mcc: 0.8303, acc: 0.7531, precision: 0.8765, recall: 0.7911, f1: 0.8316, edges-srl-ontonotes_loss: 0.0141
09/16 09:55:25 AM: Update 28312: task edges-srl-ontonotes, batch 312 (28312): mcc: 0.8310, acc: 0.7539, precision: 0.8767, recall: 0.7924, f1: 0.8324, edges-srl-ontonotes_loss: 0.0140
09/16 09:55:35 AM: Update 28444: task edges-srl-ontonotes, batch 444 (28444): mcc: 0.8207, acc: 0.7415, precision: 0.8686, recall: 0.7802, f1: 0.8221, edges-srl-ontonotes_loss: 0.0147
09/16 09:55:45 AM: Update 28583: task edges-srl-ontonotes, batch 583 (28583): mcc: 0.8157, acc: 0.7353, precision: 0.8645, recall: 0.7747, f1: 0.8171, edges-srl-ontonotes_loss: 0.0151
09/16 09:55:55 AM: Update 28696: task edges-srl-ontonotes, batch 696 (28696): mcc: 0.8091, acc: 0.7277, precision: 0.8590, recall: 0.7673, f1: 0.8106, edges-srl-ontonotes_loss: 0.0155
09/16 09:56:05 AM: Update 28825: task edges-srl-ontonotes, batch 825 (28825): mcc: 0.8037, acc: 0.7209, precision: 0.8543, recall: 0.7614, f1: 0.8052, edges-srl-ontonotes_loss: 0.0158
09/16 09:56:15 AM: Update 28948: task edges-srl-ontonotes, batch 948 (28948): mcc: 0.8014, acc: 0.7181, precision: 0.8525, recall: 0.7587, f1: 0.8029, edges-srl-ontonotes_loss: 0.0160
09/16 09:56:22 AM: ***** Step 29000 / Validation 29 *****
09/16 09:56:22 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:56:22 AM: Validating...
09/16 09:56:25 AM: Evaluate: task edges-srl-ontonotes, batch 48 (157): mcc: 0.8140, acc: 0.7456, precision: 0.8729, recall: 0.7638, f1: 0.8147, edges-srl-ontonotes_loss: 0.0148
09/16 09:56:34 AM: Updating LR scheduler:
09/16 09:56:34 AM: 	Best result seen so far for macro_avg: 0.833
09/16 09:56:34 AM: 	# validation passes without improvement: 2
09/16 09:56:34 AM: edges-srl-ontonotes_loss: training: 0.016036 validation: 0.013657
09/16 09:56:34 AM: macro_avg: validation: 0.832371
09/16 09:56:34 AM: micro_avg: validation: 0.000000
09/16 09:56:34 AM: edges-srl-ontonotes_mcc: training: 0.801083 validation: 0.831312
09/16 09:56:34 AM: edges-srl-ontonotes_acc: training: 0.717673 validation: 0.768840
09/16 09:56:34 AM: edges-srl-ontonotes_precision: training: 0.852481 validation: 0.882317
09/16 09:56:34 AM: edges-srl-ontonotes_recall: training: 0.758097 validation: 0.787776
09/16 09:56:34 AM: edges-srl-ontonotes_f1: training: 0.802524 validation: 0.832371
09/16 09:56:34 AM: Global learning rate: 1.25e-05
09/16 09:56:34 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:56:35 AM: Update 29027: task edges-srl-ontonotes, batch 27 (29027): mcc: 0.7914, acc: 0.7047, precision: 0.8400, recall: 0.7512, f1: 0.7931, edges-srl-ontonotes_loss: 0.0163
09/16 09:56:45 AM: Update 29171: task edges-srl-ontonotes, batch 171 (29171): mcc: 0.7958, acc: 0.7096, precision: 0.8508, recall: 0.7499, f1: 0.7971, edges-srl-ontonotes_loss: 0.0162
09/16 09:56:55 AM: Update 29312: task edges-srl-ontonotes, batch 312 (29312): mcc: 0.7988, acc: 0.7128, precision: 0.8522, recall: 0.7540, f1: 0.8001, edges-srl-ontonotes_loss: 0.0161
09/16 09:57:05 AM: Update 29462: task edges-srl-ontonotes, batch 462 (29462): mcc: 0.8006, acc: 0.7149, precision: 0.8543, recall: 0.7557, f1: 0.8019, edges-srl-ontonotes_loss: 0.0159
09/16 09:57:15 AM: Update 29602: task edges-srl-ontonotes, batch 602 (29602): mcc: 0.8007, acc: 0.7151, precision: 0.8533, recall: 0.7565, f1: 0.8020, edges-srl-ontonotes_loss: 0.0159
09/16 09:57:25 AM: Update 29731: task edges-srl-ontonotes, batch 731 (29731): mcc: 0.7981, acc: 0.7132, precision: 0.8512, recall: 0.7537, f1: 0.7995, edges-srl-ontonotes_loss: 0.0161
09/16 09:57:36 AM: Update 29886: task edges-srl-ontonotes, batch 886 (29886): mcc: 0.7982, acc: 0.7140, precision: 0.8510, recall: 0.7542, f1: 0.7996, edges-srl-ontonotes_loss: 0.0161
09/16 09:57:44 AM: ***** Step 30000 / Validation 30 *****
09/16 09:57:44 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:57:44 AM: Validating...
09/16 09:57:46 AM: Evaluate: task edges-srl-ontonotes, batch 22 (157): mcc: 0.8378, acc: 0.7745, precision: 0.8887, recall: 0.7941, f1: 0.8388, edges-srl-ontonotes_loss: 0.0132
09/16 09:57:56 AM: Evaluate: task edges-srl-ontonotes, batch 150 (157): mcc: 0.8357, acc: 0.7748, precision: 0.8842, recall: 0.7943, f1: 0.8368, edges-srl-ontonotes_loss: 0.0133
09/16 09:57:56 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:57:56 AM: Best result seen so far for macro.
09/16 09:57:56 AM: Updating LR scheduler:
09/16 09:57:56 AM: 	Best result seen so far for macro_avg: 0.836
09/16 09:57:56 AM: 	# validation passes without improvement: 0
09/16 09:57:56 AM: edges-srl-ontonotes_loss: training: 0.016201 validation: 0.013444
09/16 09:57:56 AM: macro_avg: validation: 0.835578
09/16 09:57:56 AM: micro_avg: validation: 0.000000
09/16 09:57:56 AM: edges-srl-ontonotes_mcc: training: 0.796922 validation: 0.834429
09/16 09:57:56 AM: edges-srl-ontonotes_acc: training: 0.712575 validation: 0.773305
09/16 09:57:56 AM: edges-srl-ontonotes_precision: training: 0.849770 validation: 0.883069
09/16 09:57:56 AM: edges-srl-ontonotes_recall: training: 0.752763 validation: 0.792934
09/16 09:57:56 AM: edges-srl-ontonotes_f1: training: 0.798330 validation: 0.835578
09/16 09:57:56 AM: Global learning rate: 1.25e-05
09/16 09:57:56 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:58:06 AM: Update 30139: task edges-srl-ontonotes, batch 139 (30139): mcc: 0.7701, acc: 0.6841, precision: 0.8273, recall: 0.7230, f1: 0.7716, edges-srl-ontonotes_loss: 0.0178
09/16 09:58:16 AM: Update 30240: task edges-srl-ontonotes, batch 240 (30240): mcc: 0.7704, acc: 0.6837, precision: 0.8286, recall: 0.7223, f1: 0.7718, edges-srl-ontonotes_loss: 0.0178
09/16 09:58:26 AM: Update 30369: task edges-srl-ontonotes, batch 369 (30369): mcc: 0.7716, acc: 0.6841, precision: 0.8300, recall: 0.7233, f1: 0.7730, edges-srl-ontonotes_loss: 0.0177
09/16 09:58:36 AM: Update 30503: task edges-srl-ontonotes, batch 503 (30503): mcc: 0.7731, acc: 0.6850, precision: 0.8313, recall: 0.7249, f1: 0.7745, edges-srl-ontonotes_loss: 0.0176
09/16 09:58:46 AM: Update 30621: task edges-srl-ontonotes, batch 621 (30621): mcc: 0.7726, acc: 0.6846, precision: 0.8309, recall: 0.7244, f1: 0.7740, edges-srl-ontonotes_loss: 0.0177
09/16 09:58:56 AM: Update 30750: task edges-srl-ontonotes, batch 750 (30750): mcc: 0.7697, acc: 0.6806, precision: 0.8290, recall: 0.7207, f1: 0.7711, edges-srl-ontonotes_loss: 0.0179
09/16 09:59:06 AM: Update 30871: task edges-srl-ontonotes, batch 871 (30871): mcc: 0.7694, acc: 0.6804, precision: 0.8287, recall: 0.7204, f1: 0.7708, edges-srl-ontonotes_loss: 0.0180
09/16 09:59:16 AM: Update 31000: task edges-srl-ontonotes, batch 1000 (31000): mcc: 0.7680, acc: 0.6787, precision: 0.8277, recall: 0.7186, f1: 0.7693, edges-srl-ontonotes_loss: 0.0181
09/16 09:59:16 AM: ***** Step 31000 / Validation 31 *****
09/16 09:59:16 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:59:16 AM: Validating...
09/16 09:59:26 AM: Evaluate: task edges-srl-ontonotes, batch 135 (157): mcc: 0.8359, acc: 0.7731, precision: 0.8861, recall: 0.7929, f1: 0.8369, edges-srl-ontonotes_loss: 0.0132
09/16 09:59:27 AM: Updating LR scheduler:
09/16 09:59:27 AM: 	Best result seen so far for macro_avg: 0.836
09/16 09:59:27 AM: 	# validation passes without improvement: 1
09/16 09:59:27 AM: edges-srl-ontonotes_loss: training: 0.018076 validation: 0.013454
09/16 09:59:27 AM: macro_avg: validation: 0.834879
09/16 09:59:27 AM: micro_avg: validation: 0.000000
09/16 09:59:27 AM: edges-srl-ontonotes_mcc: training: 0.768006 validation: 0.833865
09/16 09:59:27 AM: edges-srl-ontonotes_acc: training: 0.678679 validation: 0.770918
09/16 09:59:27 AM: edges-srl-ontonotes_precision: training: 0.827742 validation: 0.885056
09/16 09:59:27 AM: edges-srl-ontonotes_recall: training: 0.718621 validation: 0.790085
09/16 09:59:27 AM: edges-srl-ontonotes_f1: training: 0.769332 validation: 0.834879
09/16 09:59:27 AM: Global learning rate: 1.25e-05
09/16 09:59:27 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 09:59:36 AM: Update 31106: task edges-srl-ontonotes, batch 106 (31106): mcc: 0.7666, acc: 0.6818, precision: 0.8267, recall: 0.7170, f1: 0.7680, edges-srl-ontonotes_loss: 0.0184
09/16 09:59:46 AM: Update 31192: task edges-srl-ontonotes, batch 192 (31192): mcc: 0.7686, acc: 0.6809, precision: 0.8287, recall: 0.7189, f1: 0.7699, edges-srl-ontonotes_loss: 0.0181
09/16 09:59:56 AM: Update 31313: task edges-srl-ontonotes, batch 313 (31313): mcc: 0.7751, acc: 0.6882, precision: 0.8329, recall: 0.7272, f1: 0.7765, edges-srl-ontonotes_loss: 0.0176
09/16 10:00:06 AM: Update 31433: task edges-srl-ontonotes, batch 433 (31433): mcc: 0.7802, acc: 0.6943, precision: 0.8370, recall: 0.7330, f1: 0.7816, edges-srl-ontonotes_loss: 0.0172
09/16 10:00:16 AM: Update 31553: task edges-srl-ontonotes, batch 553 (31553): mcc: 0.7816, acc: 0.6962, precision: 0.8382, recall: 0.7345, f1: 0.7829, edges-srl-ontonotes_loss: 0.0171
09/16 10:00:26 AM: Update 31681: task edges-srl-ontonotes, batch 681 (31681): mcc: 0.7834, acc: 0.6982, precision: 0.8393, recall: 0.7369, f1: 0.7848, edges-srl-ontonotes_loss: 0.0170
09/16 10:00:36 AM: Update 31808: task edges-srl-ontonotes, batch 808 (31808): mcc: 0.7847, acc: 0.7001, precision: 0.8401, recall: 0.7387, f1: 0.7862, edges-srl-ontonotes_loss: 0.0169
09/16 10:00:46 AM: Update 31940: task edges-srl-ontonotes, batch 940 (31940): mcc: 0.7859, acc: 0.7014, precision: 0.8410, recall: 0.7401, f1: 0.7873, edges-srl-ontonotes_loss: 0.0168
09/16 10:00:51 AM: ***** Step 32000 / Validation 32 *****
09/16 10:00:51 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:00:51 AM: Validating...
09/16 10:00:56 AM: Evaluate: task edges-srl-ontonotes, batch 65 (157): mcc: 0.8130, acc: 0.7462, precision: 0.8727, recall: 0.7623, f1: 0.8138, edges-srl-ontonotes_loss: 0.0147
09/16 10:01:04 AM: Updating LR scheduler:
09/16 10:01:04 AM: 	Best result seen so far for macro_avg: 0.836
09/16 10:01:04 AM: 	# validation passes without improvement: 2
09/16 10:01:04 AM: edges-srl-ontonotes_loss: training: 0.016807 validation: 0.013604
09/16 10:01:04 AM: macro_avg: validation: 0.832709
09/16 10:01:04 AM: micro_avg: validation: 0.000000
09/16 10:01:04 AM: edges-srl-ontonotes_mcc: training: 0.786535 validation: 0.831705
09/16 10:01:04 AM: edges-srl-ontonotes_acc: training: 0.702401 validation: 0.769764
09/16 10:01:04 AM: edges-srl-ontonotes_precision: training: 0.841338 validation: 0.883562
09/16 10:01:04 AM: edges-srl-ontonotes_recall: training: 0.740945 validation: 0.787391
09/16 10:01:04 AM: edges-srl-ontonotes_f1: training: 0.787957 validation: 0.832709
09/16 10:01:04 AM: Global learning rate: 1.25e-05
09/16 10:01:04 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 10:01:06 AM: Update 32029: task edges-srl-ontonotes, batch 29 (32029): mcc: 0.8089, acc: 0.7291, precision: 0.8696, recall: 0.7574, f1: 0.8096, edges-srl-ontonotes_loss: 0.0159
09/16 10:01:16 AM: Update 32116: task edges-srl-ontonotes, batch 116 (32116): mcc: 0.8001, acc: 0.7167, precision: 0.8562, recall: 0.7529, f1: 0.8012, edges-srl-ontonotes_loss: 0.0162
09/16 10:01:26 AM: Update 32250: task edges-srl-ontonotes, batch 250 (32250): mcc: 0.7856, acc: 0.7000, precision: 0.8425, recall: 0.7381, f1: 0.7869, edges-srl-ontonotes_loss: 0.0170
09/16 10:01:36 AM: Update 32387: task edges-srl-ontonotes, batch 387 (32387): mcc: 0.7836, acc: 0.6983, precision: 0.8407, recall: 0.7360, f1: 0.7849, edges-srl-ontonotes_loss: 0.0171
09/16 10:01:46 AM: Update 32507: task edges-srl-ontonotes, batch 507 (32507): mcc: 0.7835, acc: 0.6977, precision: 0.8415, recall: 0.7352, f1: 0.7848, edges-srl-ontonotes_loss: 0.0171
09/16 10:01:56 AM: Update 32636: task edges-srl-ontonotes, batch 636 (32636): mcc: 0.7829, acc: 0.6965, precision: 0.8410, recall: 0.7345, f1: 0.7841, edges-srl-ontonotes_loss: 0.0172
09/16 10:02:07 AM: Update 32751: task edges-srl-ontonotes, batch 751 (32751): mcc: 0.7824, acc: 0.6964, precision: 0.8406, recall: 0.7340, f1: 0.7837, edges-srl-ontonotes_loss: 0.0172
09/16 10:02:17 AM: Update 32890: task edges-srl-ontonotes, batch 890 (32890): mcc: 0.7813, acc: 0.6957, precision: 0.8395, recall: 0.7330, f1: 0.7826, edges-srl-ontonotes_loss: 0.0173
09/16 10:02:25 AM: ***** Step 33000 / Validation 33 *****
09/16 10:02:25 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:02:25 AM: Validating...
09/16 10:02:27 AM: Evaluate: task edges-srl-ontonotes, batch 25 (157): mcc: 0.8267, acc: 0.7616, precision: 0.8846, recall: 0.7771, f1: 0.8274, edges-srl-ontonotes_loss: 0.0139
09/16 10:02:37 AM: Evaluate: task edges-srl-ontonotes, batch 153 (157): mcc: 0.8305, acc: 0.7694, precision: 0.8810, recall: 0.7874, f1: 0.8316, edges-srl-ontonotes_loss: 0.0136
09/16 10:02:37 AM: Updating LR scheduler:
09/16 10:02:37 AM: 	Best result seen so far for macro_avg: 0.836
09/16 10:02:37 AM: 	# validation passes without improvement: 3
09/16 10:02:37 AM: edges-srl-ontonotes_loss: training: 0.017277 validation: 0.013699
09/16 10:02:37 AM: macro_avg: validation: 0.830888
09/16 10:02:37 AM: micro_avg: validation: 0.000000
09/16 10:02:37 AM: edges-srl-ontonotes_mcc: training: 0.781032 validation: 0.829773
09/16 10:02:37 AM: edges-srl-ontonotes_acc: training: 0.695202 validation: 0.768609
09/16 10:02:37 AM: edges-srl-ontonotes_precision: training: 0.839481 validation: 0.880145
09/16 10:02:37 AM: edges-srl-ontonotes_recall: training: 0.732382 validation: 0.786852
09/16 10:02:37 AM: edges-srl-ontonotes_f1: training: 0.782283 validation: 0.830888
09/16 10:02:37 AM: Global learning rate: 1.25e-05
09/16 10:02:37 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 10:02:47 AM: Update 33114: task edges-srl-ontonotes, batch 114 (33114): mcc: 0.7757, acc: 0.6891, precision: 0.8335, recall: 0.7278, f1: 0.7771, edges-srl-ontonotes_loss: 0.0175
09/16 10:02:57 AM: Update 33246: task edges-srl-ontonotes, batch 246 (33246): mcc: 0.7818, acc: 0.6973, precision: 0.8387, recall: 0.7344, f1: 0.7831, edges-srl-ontonotes_loss: 0.0172
09/16 10:03:07 AM: Update 33365: task edges-srl-ontonotes, batch 365 (33365): mcc: 0.7840, acc: 0.7000, precision: 0.8403, recall: 0.7372, f1: 0.7854, edges-srl-ontonotes_loss: 0.0171
09/16 10:03:17 AM: Update 33458: task edges-srl-ontonotes, batch 458 (33458): mcc: 0.7849, acc: 0.7006, precision: 0.8415, recall: 0.7377, f1: 0.7862, edges-srl-ontonotes_loss: 0.0170
09/16 10:03:27 AM: Update 33589: task edges-srl-ontonotes, batch 589 (33589): mcc: 0.7845, acc: 0.7010, precision: 0.8406, recall: 0.7377, f1: 0.7858, edges-srl-ontonotes_loss: 0.0170
09/16 10:03:37 AM: Update 33708: task edges-srl-ontonotes, batch 708 (33708): mcc: 0.7839, acc: 0.7005, precision: 0.8404, recall: 0.7369, f1: 0.7853, edges-srl-ontonotes_loss: 0.0171
09/16 10:03:47 AM: Update 33835: task edges-srl-ontonotes, batch 835 (33835): mcc: 0.7797, acc: 0.6948, precision: 0.8375, recall: 0.7318, f1: 0.7810, edges-srl-ontonotes_loss: 0.0173
09/16 10:03:57 AM: Update 33946: task edges-srl-ontonotes, batch 946 (33946): mcc: 0.7769, acc: 0.6914, precision: 0.8356, recall: 0.7283, f1: 0.7782, edges-srl-ontonotes_loss: 0.0175
09/16 10:04:02 AM: ***** Step 34000 / Validation 34 *****
09/16 10:04:02 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:04:02 AM: Validating...
09/16 10:04:07 AM: Evaluate: task edges-srl-ontonotes, batch 66 (157): mcc: 0.8110, acc: 0.7473, precision: 0.8662, recall: 0.7642, f1: 0.8120, edges-srl-ontonotes_loss: 0.0149
09/16 10:04:14 AM: Updating LR scheduler:
09/16 10:04:14 AM: 	Best result seen so far for macro_avg: 0.836
09/16 10:04:14 AM: 	# validation passes without improvement: 0
09/16 10:04:14 AM: edges-srl-ontonotes_loss: training: 0.017484 validation: 0.013780
09/16 10:04:14 AM: macro_avg: validation: 0.830959
09/16 10:04:14 AM: micro_avg: validation: 0.000000
09/16 10:04:14 AM: edges-srl-ontonotes_mcc: training: 0.776826 validation: 0.829638
09/16 10:04:14 AM: edges-srl-ontonotes_acc: training: 0.691198 validation: 0.769687
09/16 10:04:14 AM: edges-srl-ontonotes_precision: training: 0.835458 validation: 0.876291
09/16 10:04:14 AM: edges-srl-ontonotes_recall: training: 0.728142 validation: 0.790085
09/16 10:04:14 AM: edges-srl-ontonotes_f1: training: 0.778117 validation: 0.830959
09/16 10:04:14 AM: Global learning rate: 6.25e-06
09/16 10:04:14 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 10:04:17 AM: Update 34048: task edges-srl-ontonotes, batch 48 (34048): mcc: 0.7957, acc: 0.7117, precision: 0.8418, recall: 0.7577, f1: 0.7975, edges-srl-ontonotes_loss: 0.0159
09/16 10:04:27 AM: Update 34200: task edges-srl-ontonotes, batch 200 (34200): mcc: 0.8009, acc: 0.7196, precision: 0.8491, recall: 0.7608, f1: 0.8025, edges-srl-ontonotes_loss: 0.0156
09/16 10:04:37 AM: Update 34306: task edges-srl-ontonotes, batch 306 (34306): mcc: 0.8039, acc: 0.7241, precision: 0.8515, recall: 0.7643, f1: 0.8056, edges-srl-ontonotes_loss: 0.0156
09/16 10:04:47 AM: Update 34481: task edges-srl-ontonotes, batch 481 (34481): mcc: 0.8113, acc: 0.7332, precision: 0.8567, recall: 0.7735, f1: 0.8130, edges-srl-ontonotes_loss: 0.0149
09/16 10:04:57 AM: Update 34638: task edges-srl-ontonotes, batch 638 (34638): mcc: 0.8152, acc: 0.7377, precision: 0.8603, recall: 0.7775, f1: 0.8168, edges-srl-ontonotes_loss: 0.0147
09/16 10:05:07 AM: Update 34806: task edges-srl-ontonotes, batch 806 (34806): mcc: 0.8161, acc: 0.7392, precision: 0.8614, recall: 0.7782, f1: 0.8177, edges-srl-ontonotes_loss: 0.0147
09/16 10:05:17 AM: Update 34958: task edges-srl-ontonotes, batch 958 (34958): mcc: 0.8177, acc: 0.7410, precision: 0.8634, recall: 0.7794, f1: 0.8192, edges-srl-ontonotes_loss: 0.0146
09/16 10:05:20 AM: ***** Step 35000 / Validation 35 *****
09/16 10:05:20 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:05:20 AM: Validating...
09/16 10:05:27 AM: Evaluate: task edges-srl-ontonotes, batch 94 (157): mcc: 0.8237, acc: 0.7575, precision: 0.8823, recall: 0.7737, f1: 0.8244, edges-srl-ontonotes_loss: 0.0140
09/16 10:05:33 AM: Updating LR scheduler:
09/16 10:05:33 AM: 	Best result seen so far for macro_avg: 0.836
09/16 10:05:33 AM: 	# validation passes without improvement: 1
09/16 10:05:33 AM: edges-srl-ontonotes_loss: training: 0.014549 validation: 0.013660
09/16 10:05:33 AM: macro_avg: validation: 0.832621
09/16 10:05:33 AM: micro_avg: validation: 0.000000
09/16 10:05:33 AM: edges-srl-ontonotes_mcc: training: 0.817794 validation: 0.831657
09/16 10:05:33 AM: edges-srl-ontonotes_acc: training: 0.740969 validation: 0.768532
09/16 10:05:33 AM: edges-srl-ontonotes_precision: training: 0.863348 validation: 0.884236
09/16 10:05:33 AM: edges-srl-ontonotes_recall: training: 0.779591 validation: 0.786698
09/16 10:05:33 AM: edges-srl-ontonotes_f1: training: 0.819335 validation: 0.832621
09/16 10:05:33 AM: Global learning rate: 6.25e-06
09/16 10:05:33 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 10:05:37 AM: Update 35070: task edges-srl-ontonotes, batch 70 (35070): mcc: 0.8219, acc: 0.7440, precision: 0.8643, recall: 0.7864, f1: 0.8235, edges-srl-ontonotes_loss: 0.0143
09/16 10:05:47 AM: Update 35239: task edges-srl-ontonotes, batch 239 (35239): mcc: 0.8234, acc: 0.7464, precision: 0.8677, recall: 0.7863, f1: 0.8250, edges-srl-ontonotes_loss: 0.0141
09/16 10:05:57 AM: Update 35360: task edges-srl-ontonotes, batch 360 (35360): mcc: 0.8248, acc: 0.7475, precision: 0.8694, recall: 0.7873, f1: 0.8263, edges-srl-ontonotes_loss: 0.0141
09/16 10:06:08 AM: Update 35523: task edges-srl-ontonotes, batch 523 (35523): mcc: 0.8277, acc: 0.7506, precision: 0.8725, recall: 0.7899, f1: 0.8292, edges-srl-ontonotes_loss: 0.0140
09/16 10:06:18 AM: Update 35659: task edges-srl-ontonotes, batch 659 (35659): mcc: 0.8227, acc: 0.7439, precision: 0.8689, recall: 0.7837, f1: 0.8241, edges-srl-ontonotes_loss: 0.0144
09/16 10:06:28 AM: Update 35794: task edges-srl-ontonotes, batch 794 (35794): mcc: 0.8186, acc: 0.7392, precision: 0.8655, recall: 0.7792, f1: 0.8201, edges-srl-ontonotes_loss: 0.0147
09/16 10:06:38 AM: Update 35918: task edges-srl-ontonotes, batch 918 (35918): mcc: 0.8151, acc: 0.7350, precision: 0.8626, recall: 0.7752, f1: 0.8166, edges-srl-ontonotes_loss: 0.0150
09/16 10:06:44 AM: ***** Step 36000 / Validation 36 *****
09/16 10:06:44 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:06:44 AM: Validating...
09/16 10:06:48 AM: Evaluate: task edges-srl-ontonotes, batch 55 (157): mcc: 0.8153, acc: 0.7490, precision: 0.8721, recall: 0.7670, f1: 0.8162, edges-srl-ontonotes_loss: 0.0146
09/16 10:06:56 AM: Updating LR scheduler:
09/16 10:06:56 AM: 	Best result seen so far for macro_avg: 0.836
09/16 10:06:56 AM: 	# validation passes without improvement: 2
09/16 10:06:56 AM: edges-srl-ontonotes_loss: training: 0.015171 validation: 0.013561
09/16 10:06:56 AM: macro_avg: validation: 0.834058
09/16 10:06:56 AM: micro_avg: validation: 0.000000
09/16 10:06:56 AM: edges-srl-ontonotes_mcc: training: 0.811920 validation: 0.832994
09/16 10:06:56 AM: edges-srl-ontonotes_acc: training: 0.731517 validation: 0.770841
09/16 10:06:56 AM: edges-srl-ontonotes_precision: training: 0.860338 validation: 0.883503
09/16 10:06:56 AM: edges-srl-ontonotes_recall: training: 0.771295 validation: 0.789855
09/16 10:06:56 AM: edges-srl-ontonotes_f1: training: 0.813387 validation: 0.834058
09/16 10:06:56 AM: Global learning rate: 6.25e-06
09/16 10:06:56 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 10:06:58 AM: Update 36022: task edges-srl-ontonotes, batch 22 (36022): mcc: 0.7740, acc: 0.6864, precision: 0.8317, recall: 0.7262, f1: 0.7754, edges-srl-ontonotes_loss: 0.0177
09/16 10:07:08 AM: Update 36142: task edges-srl-ontonotes, batch 142 (36142): mcc: 0.7774, acc: 0.6894, precision: 0.8334, recall: 0.7311, f1: 0.7789, edges-srl-ontonotes_loss: 0.0177
09/16 10:07:18 AM: Update 36274: task edges-srl-ontonotes, batch 274 (36274): mcc: 0.7841, acc: 0.6977, precision: 0.8402, recall: 0.7374, f1: 0.7854, edges-srl-ontonotes_loss: 0.0173
09/16 10:07:28 AM: Update 36411: task edges-srl-ontonotes, batch 411 (36411): mcc: 0.7892, acc: 0.7035, precision: 0.8448, recall: 0.7428, f1: 0.7905, edges-srl-ontonotes_loss: 0.0168
09/16 10:07:40 AM: Update 36544: task edges-srl-ontonotes, batch 544 (36544): mcc: 0.7915, acc: 0.7060, precision: 0.8471, recall: 0.7450, f1: 0.7928, edges-srl-ontonotes_loss: 0.0166
09/16 10:07:50 AM: Update 36694: task edges-srl-ontonotes, batch 694 (36694): mcc: 0.7944, acc: 0.7093, precision: 0.8493, recall: 0.7486, f1: 0.7957, edges-srl-ontonotes_loss: 0.0164
09/16 10:08:00 AM: Update 36836: task edges-srl-ontonotes, batch 836 (36836): mcc: 0.7958, acc: 0.7106, precision: 0.8506, recall: 0.7499, f1: 0.7971, edges-srl-ontonotes_loss: 0.0163
09/16 10:08:10 AM: Update 36967: task edges-srl-ontonotes, batch 967 (36967): mcc: 0.7960, acc: 0.7109, precision: 0.8505, recall: 0.7504, f1: 0.7973, edges-srl-ontonotes_loss: 0.0163
09/16 10:08:13 AM: ***** Step 37000 / Validation 37 *****
09/16 10:08:13 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:08:13 AM: Validating...
09/16 10:08:20 AM: Evaluate: task edges-srl-ontonotes, batch 94 (157): mcc: 0.8284, acc: 0.7651, precision: 0.8816, recall: 0.7831, f1: 0.8294, edges-srl-ontonotes_loss: 0.0136
09/16 10:08:25 AM: Best result seen so far for edges-srl-ontonotes.
09/16 10:08:25 AM: Best result seen so far for macro.
09/16 10:08:25 AM: Updating LR scheduler:
09/16 10:08:25 AM: 	Best result seen so far for macro_avg: 0.836
09/16 10:08:25 AM: 	# validation passes without improvement: 0
09/16 10:08:25 AM: edges-srl-ontonotes_loss: training: 0.016333 validation: 0.013380
09/16 10:08:25 AM: macro_avg: validation: 0.836111
09/16 10:08:25 AM: micro_avg: validation: 0.000000
09/16 10:08:25 AM: edges-srl-ontonotes_mcc: training: 0.795992 validation: 0.834969
09/16 10:08:25 AM: edges-srl-ontonotes_acc: training: 0.710860 validation: 0.774228
09/16 10:08:25 AM: edges-srl-ontonotes_precision: training: 0.850595 validation: 0.883593
09/16 10:08:25 AM: edges-srl-ontonotes_recall: training: 0.750296 validation: 0.793472
09/16 10:08:25 AM: edges-srl-ontonotes_f1: training: 0.797303 validation: 0.836111
09/16 10:08:25 AM: Global learning rate: 6.25e-06
09/16 10:08:25 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 10:08:30 AM: Update 37076: task edges-srl-ontonotes, batch 76 (37076): mcc: 0.7908, acc: 0.7053, precision: 0.8451, recall: 0.7456, f1: 0.7922, edges-srl-ontonotes_loss: 0.0162
09/16 10:08:40 AM: Update 37197: task edges-srl-ontonotes, batch 197 (37197): mcc: 0.7906, acc: 0.7057, precision: 0.8453, recall: 0.7450, f1: 0.7920, edges-srl-ontonotes_loss: 0.0164
09/16 10:08:50 AM: Update 37335: task edges-srl-ontonotes, batch 335 (37335): mcc: 0.7860, acc: 0.6992, precision: 0.8425, recall: 0.7388, f1: 0.7873, edges-srl-ontonotes_loss: 0.0168
09/16 10:09:00 AM: Update 37473: task edges-srl-ontonotes, batch 473 (37473): mcc: 0.7812, acc: 0.6937, precision: 0.8380, recall: 0.7341, f1: 0.7826, edges-srl-ontonotes_loss: 0.0172
09/16 10:09:11 AM: Update 37570: task edges-srl-ontonotes, batch 570 (37570): mcc: 0.7800, acc: 0.6929, precision: 0.8372, recall: 0.7326, f1: 0.7814, edges-srl-ontonotes_loss: 0.0173
09/16 10:09:21 AM: Update 37704: task edges-srl-ontonotes, batch 704 (37704): mcc: 0.7792, acc: 0.6918, precision: 0.8369, recall: 0.7313, f1: 0.7805, edges-srl-ontonotes_loss: 0.0172
09/16 10:09:31 AM: Update 37831: task edges-srl-ontonotes, batch 831 (37831): mcc: 0.7787, acc: 0.6917, precision: 0.8360, recall: 0.7312, f1: 0.7801, edges-srl-ontonotes_loss: 0.0173
09/16 10:09:41 AM: Update 37962: task edges-srl-ontonotes, batch 962 (37962): mcc: 0.7766, acc: 0.6893, precision: 0.8344, recall: 0.7287, f1: 0.7780, edges-srl-ontonotes_loss: 0.0174
09/16 10:09:44 AM: ***** Step 38000 / Validation 38 *****
09/16 10:09:44 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:09:44 AM: Validating...
09/16 10:09:51 AM: Evaluate: task edges-srl-ontonotes, batch 97 (157): mcc: 0.8290, acc: 0.7636, precision: 0.8853, recall: 0.7808, f1: 0.8298, edges-srl-ontonotes_loss: 0.0135
09/16 10:09:55 AM: Updating LR scheduler:
09/16 10:09:55 AM: 	Best result seen so far for macro_avg: 0.836
09/16 10:09:55 AM: 	# validation passes without improvement: 1
09/16 10:09:55 AM: edges-srl-ontonotes_loss: training: 0.017482 validation: 0.013404
09/16 10:09:55 AM: macro_avg: validation: 0.836004
09/16 10:09:55 AM: micro_avg: validation: 0.000000
09/16 10:09:55 AM: edges-srl-ontonotes_mcc: training: 0.775394 validation: 0.835013
09/16 10:09:55 AM: edges-srl-ontonotes_acc: training: 0.687685 validation: 0.772381
09/16 10:09:55 AM: edges-srl-ontonotes_precision: training: 0.833369 validation: 0.886330
09/16 10:09:55 AM: edges-srl-ontonotes_recall: training: 0.727333 validation: 0.791086
09/16 10:09:55 AM: edges-srl-ontonotes_f1: training: 0.776749 validation: 0.836004
09/16 10:09:55 AM: Global learning rate: 6.25e-06
09/16 10:09:55 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 10:10:01 AM: Update 38074: task edges-srl-ontonotes, batch 74 (38074): mcc: 0.7642, acc: 0.6715, precision: 0.8298, recall: 0.7098, f1: 0.7652, edges-srl-ontonotes_loss: 0.0185
09/16 10:10:11 AM: Update 38184: task edges-srl-ontonotes, batch 184 (38184): mcc: 0.7611, acc: 0.6712, precision: 0.8224, recall: 0.7106, f1: 0.7624, edges-srl-ontonotes_loss: 0.0187
09/16 10:10:21 AM: Update 38317: task edges-srl-ontonotes, batch 317 (38317): mcc: 0.7641, acc: 0.6742, precision: 0.8257, recall: 0.7131, f1: 0.7653, edges-srl-ontonotes_loss: 0.0185
09/16 10:10:31 AM: Update 38430: task edges-srl-ontonotes, batch 430 (38430): mcc: 0.7645, acc: 0.6742, precision: 0.8263, recall: 0.7134, f1: 0.7657, edges-srl-ontonotes_loss: 0.0184
09/16 10:10:41 AM: Update 38540: task edges-srl-ontonotes, batch 540 (38540): mcc: 0.7706, acc: 0.6819, precision: 0.8306, recall: 0.7209, f1: 0.7719, edges-srl-ontonotes_loss: 0.0179
09/16 10:10:51 AM: Update 38657: task edges-srl-ontonotes, batch 657 (38657): mcc: 0.7735, acc: 0.6862, precision: 0.8318, recall: 0.7252, f1: 0.7748, edges-srl-ontonotes_loss: 0.0177
09/16 10:11:01 AM: Update 38747: task edges-srl-ontonotes, batch 747 (38747): mcc: 0.7755, acc: 0.6885, precision: 0.8334, recall: 0.7276, f1: 0.7769, edges-srl-ontonotes_loss: 0.0176
09/16 10:11:11 AM: Update 38872: task edges-srl-ontonotes, batch 872 (38872): mcc: 0.7774, acc: 0.6910, precision: 0.8346, recall: 0.7299, f1: 0.7787, edges-srl-ontonotes_loss: 0.0174
09/16 10:11:21 AM: Update 38994: task edges-srl-ontonotes, batch 994 (38994): mcc: 0.7792, acc: 0.6932, precision: 0.8359, recall: 0.7322, f1: 0.7806, edges-srl-ontonotes_loss: 0.0173
09/16 10:11:21 AM: ***** Step 39000 / Validation 39 *****
09/16 10:11:21 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:11:21 AM: Validating...
09/16 10:11:31 AM: Evaluate: task edges-srl-ontonotes, batch 129 (157): mcc: 0.8368, acc: 0.7769, precision: 0.8821, recall: 0.7982, f1: 0.8381, edges-srl-ontonotes_loss: 0.0132
09/16 10:11:33 AM: Updating LR scheduler:
09/16 10:11:33 AM: 	Best result seen so far for macro_avg: 0.836
09/16 10:11:33 AM: 	# validation passes without improvement: 2
09/16 10:11:33 AM: edges-srl-ontonotes_loss: training: 0.017288 validation: 0.013456
09/16 10:11:33 AM: macro_avg: validation: 0.834831
09/16 10:11:33 AM: micro_avg: validation: 0.000000
09/16 10:11:33 AM: edges-srl-ontonotes_mcc: training: 0.779470 validation: 0.833576
09/16 10:11:33 AM: edges-srl-ontonotes_acc: training: 0.693601 validation: 0.772920
09/16 10:11:33 AM: edges-srl-ontonotes_precision: training: 0.836090 validation: 0.880454
09/16 10:11:33 AM: edges-srl-ontonotes_recall: training: 0.732481 validation: 0.793703
09/16 10:11:33 AM: edges-srl-ontonotes_f1: training: 0.780864 validation: 0.834831
09/16 10:11:33 AM: Global learning rate: 6.25e-06
09/16 10:11:33 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 10:11:41 AM: Update 39090: task edges-srl-ontonotes, batch 90 (39090): mcc: 0.7877, acc: 0.7030, precision: 0.8417, recall: 0.7428, f1: 0.7892, edges-srl-ontonotes_loss: 0.0168
09/16 10:11:51 AM: Update 39206: task edges-srl-ontonotes, batch 206 (39206): mcc: 0.7965, acc: 0.7151, precision: 0.8496, recall: 0.7522, f1: 0.7979, edges-srl-ontonotes_loss: 0.0163
09/16 10:12:01 AM: Update 39342: task edges-srl-ontonotes, batch 342 (39342): mcc: 0.7960, acc: 0.7149, precision: 0.8494, recall: 0.7514, f1: 0.7974, edges-srl-ontonotes_loss: 0.0162
09/16 10:12:11 AM: Update 39459: task edges-srl-ontonotes, batch 459 (39459): mcc: 0.7918, acc: 0.7094, precision: 0.8459, recall: 0.7467, f1: 0.7932, edges-srl-ontonotes_loss: 0.0165
09/16 10:12:21 AM: Update 39590: task edges-srl-ontonotes, batch 590 (39590): mcc: 0.7893, acc: 0.7067, precision: 0.8439, recall: 0.7437, f1: 0.7907, edges-srl-ontonotes_loss: 0.0167
09/16 10:12:31 AM: Update 39690: task edges-srl-ontonotes, batch 690 (39690): mcc: 0.7877, acc: 0.7051, precision: 0.8427, recall: 0.7420, f1: 0.7891, edges-srl-ontonotes_loss: 0.0168
09/16 10:12:41 AM: Update 39825: task edges-srl-ontonotes, batch 825 (39825): mcc: 0.7858, acc: 0.7023, precision: 0.8413, recall: 0.7396, f1: 0.7872, edges-srl-ontonotes_loss: 0.0170
09/16 10:12:51 AM: Update 39957: task edges-srl-ontonotes, batch 957 (39957): mcc: 0.7848, acc: 0.7014, precision: 0.8406, recall: 0.7384, f1: 0.7862, edges-srl-ontonotes_loss: 0.0170
09/16 10:12:56 AM: ***** Step 40000 / Validation 40 *****
09/16 10:12:56 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:12:56 AM: Validating...
09/16 10:13:01 AM: Evaluate: task edges-srl-ontonotes, batch 77 (157): mcc: 0.8178, acc: 0.7521, precision: 0.8743, recall: 0.7698, f1: 0.8187, edges-srl-ontonotes_loss: 0.0142
09/16 10:13:07 AM: Updating LR scheduler:
09/16 10:13:07 AM: 	Best result seen so far for macro_avg: 0.836
09/16 10:13:07 AM: 	# validation passes without improvement: 3
09/16 10:13:07 AM: edges-srl-ontonotes_loss: training: 0.017065 validation: 0.013493
09/16 10:13:07 AM: macro_avg: validation: 0.834308
09/16 10:13:07 AM: micro_avg: validation: 0.000000
09/16 10:13:07 AM: edges-srl-ontonotes_mcc: training: 0.784401 validation: 0.833207
09/16 10:13:07 AM: edges-srl-ontonotes_acc: training: 0.701031 validation: 0.771457
09/16 10:13:07 AM: edges-srl-ontonotes_precision: training: 0.840209 validation: 0.883005
09/16 10:13:07 AM: edges-srl-ontonotes_recall: training: 0.737983 validation: 0.790701
09/16 10:13:07 AM: edges-srl-ontonotes_f1: training: 0.785785 validation: 0.834308
09/16 10:13:07 AM: Global learning rate: 6.25e-06
09/16 10:13:07 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 10:13:11 AM: Update 40052: task edges-srl-ontonotes, batch 52 (40052): mcc: 0.7767, acc: 0.6949, precision: 0.8339, recall: 0.7292, f1: 0.7781, edges-srl-ontonotes_loss: 0.0176
09/16 10:13:21 AM: Update 40179: task edges-srl-ontonotes, batch 179 (40179): mcc: 0.7695, acc: 0.6867, precision: 0.8278, recall: 0.7213, f1: 0.7709, edges-srl-ontonotes_loss: 0.0178
09/16 10:13:32 AM: Update 40306: task edges-srl-ontonotes, batch 306 (40306): mcc: 0.7741, acc: 0.6907, precision: 0.8326, recall: 0.7257, f1: 0.7755, edges-srl-ontonotes_loss: 0.0176
09/16 10:13:42 AM: Update 40434: task edges-srl-ontonotes, batch 434 (40434): mcc: 0.7791, acc: 0.6962, precision: 0.8370, recall: 0.7311, f1: 0.7805, edges-srl-ontonotes_loss: 0.0173
09/16 10:13:52 AM: Update 40571: task edges-srl-ontonotes, batch 571 (40571): mcc: 0.7808, acc: 0.6981, precision: 0.8377, recall: 0.7335, f1: 0.7822, edges-srl-ontonotes_loss: 0.0172
09/16 10:14:02 AM: Update 40668: task edges-srl-ontonotes, batch 668 (40668): mcc: 0.7823, acc: 0.6997, precision: 0.8389, recall: 0.7353, f1: 0.7837, edges-srl-ontonotes_loss: 0.0171
09/16 10:14:12 AM: Update 40804: task edges-srl-ontonotes, batch 804 (40804): mcc: 0.7835, acc: 0.7009, precision: 0.8396, recall: 0.7368, f1: 0.7848, edges-srl-ontonotes_loss: 0.0170
09/16 10:14:22 AM: Update 40926: task edges-srl-ontonotes, batch 926 (40926): mcc: 0.7842, acc: 0.7017, precision: 0.8401, recall: 0.7378, f1: 0.7856, edges-srl-ontonotes_loss: 0.0170
09/16 10:14:28 AM: ***** Step 41000 / Validation 41 *****
09/16 10:14:28 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:14:28 AM: Validating...
09/16 10:14:32 AM: Evaluate: task edges-srl-ontonotes, batch 48 (157): mcc: 0.8131, acc: 0.7441, precision: 0.8732, recall: 0.7621, f1: 0.8139, edges-srl-ontonotes_loss: 0.0147
09/16 10:14:41 AM: Updating LR scheduler:
09/16 10:14:41 AM: 	Best result seen so far for macro_avg: 0.836
09/16 10:14:41 AM: 	# validation passes without improvement: 0
09/16 10:14:41 AM: edges-srl-ontonotes_loss: training: 0.017086 validation: 0.013527
09/16 10:14:41 AM: macro_avg: validation: 0.833624
09/16 10:14:41 AM: micro_avg: validation: 0.000000
09/16 10:14:41 AM: edges-srl-ontonotes_mcc: training: 0.782790 validation: 0.832536
09/16 10:14:41 AM: edges-srl-ontonotes_acc: training: 0.699839 validation: 0.770764
09/16 10:14:41 AM: edges-srl-ontonotes_precision: training: 0.839108 validation: 0.882722
09/16 10:14:41 AM: edges-srl-ontonotes_recall: training: 0.735968 validation: 0.789701
09/16 10:14:41 AM: edges-srl-ontonotes_f1: training: 0.784161 validation: 0.833624
09/16 10:14:41 AM: Global learning rate: 3.125e-06
09/16 10:14:41 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 10:14:42 AM: Update 41012: task edges-srl-ontonotes, batch 12 (41012): mcc: 0.7811, acc: 0.7009, precision: 0.8387, recall: 0.7331, f1: 0.7824, edges-srl-ontonotes_loss: 0.0169
09/16 10:14:52 AM: Update 41122: task edges-srl-ontonotes, batch 122 (41122): mcc: 0.7629, acc: 0.6754, precision: 0.8267, recall: 0.7101, f1: 0.7640, edges-srl-ontonotes_loss: 0.0185
09/16 10:15:02 AM: Update 41231: task edges-srl-ontonotes, batch 231 (41231): mcc: 0.7626, acc: 0.6752, precision: 0.8269, recall: 0.7094, f1: 0.7637, edges-srl-ontonotes_loss: 0.0184
09/16 10:15:12 AM: Update 41357: task edges-srl-ontonotes, batch 357 (41357): mcc: 0.7747, acc: 0.6901, precision: 0.8345, recall: 0.7251, f1: 0.7760, edges-srl-ontonotes_loss: 0.0176
09/16 10:15:22 AM: Update 41508: task edges-srl-ontonotes, batch 508 (41508): mcc: 0.7848, acc: 0.7019, precision: 0.8414, recall: 0.7378, f1: 0.7862, edges-srl-ontonotes_loss: 0.0169
09/16 10:15:32 AM: Update 41663: task edges-srl-ontonotes, batch 663 (41663): mcc: 0.7928, acc: 0.7109, precision: 0.8464, recall: 0.7480, f1: 0.7942, edges-srl-ontonotes_loss: 0.0163
09/16 10:15:42 AM: Update 41827: task edges-srl-ontonotes, batch 827 (41827): mcc: 0.7994, acc: 0.7195, precision: 0.8502, recall: 0.7571, f1: 0.8009, edges-srl-ontonotes_loss: 0.0158
09/16 10:15:52 AM: Update 41950: task edges-srl-ontonotes, batch 950 (41950): mcc: 0.8027, acc: 0.7236, precision: 0.8527, recall: 0.7608, f1: 0.8042, edges-srl-ontonotes_loss: 0.0156
09/16 10:15:55 AM: ***** Step 42000 / Validation 42 *****
09/16 10:15:55 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:15:55 AM: Validating...
09/16 10:16:02 AM: Evaluate: task edges-srl-ontonotes, batch 97 (157): mcc: 0.8254, acc: 0.7593, precision: 0.8830, recall: 0.7761, f1: 0.8261, edges-srl-ontonotes_loss: 0.0137
09/16 10:16:07 AM: Updating LR scheduler:
09/16 10:16:07 AM: 	Best result seen so far for macro_avg: 0.836
09/16 10:16:07 AM: 	# validation passes without improvement: 1
09/16 10:16:07 AM: edges-srl-ontonotes_loss: training: 0.015514 validation: 0.013540
09/16 10:16:07 AM: macro_avg: validation: 0.833462
09/16 10:16:07 AM: micro_avg: validation: 0.000000
09/16 10:16:07 AM: edges-srl-ontonotes_mcc: training: 0.803976 validation: 0.832504
09/16 10:16:07 AM: edges-srl-ontonotes_acc: training: 0.725305 validation: 0.769918
09/16 10:16:07 AM: edges-srl-ontonotes_precision: training: 0.853680 validation: 0.884968
09/16 10:16:07 AM: edges-srl-ontonotes_recall: training: 0.762426 validation: 0.787622
09/16 10:16:07 AM: edges-srl-ontonotes_f1: training: 0.805477 validation: 0.833462
09/16 10:16:07 AM: Global learning rate: 3.125e-06
09/16 10:16:07 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 10:16:12 AM: Update 42086: task edges-srl-ontonotes, batch 86 (42086): mcc: 0.8329, acc: 0.7585, precision: 0.8783, recall: 0.7944, f1: 0.8342, edges-srl-ontonotes_loss: 0.0140
09/16 10:16:22 AM: Update 42233: task edges-srl-ontonotes, batch 233 (42233): mcc: 0.8287, acc: 0.7533, precision: 0.8739, recall: 0.7906, f1: 0.8301, edges-srl-ontonotes_loss: 0.0140
09/16 10:16:32 AM: Update 42393: task edges-srl-ontonotes, batch 393 (42393): mcc: 0.8276, acc: 0.7524, precision: 0.8721, recall: 0.7901, f1: 0.8291, edges-srl-ontonotes_loss: 0.0140
09/16 10:16:42 AM: Update 42541: task edges-srl-ontonotes, batch 541 (42541): mcc: 0.8276, acc: 0.7524, precision: 0.8718, recall: 0.7903, f1: 0.8291, edges-srl-ontonotes_loss: 0.0140
09/16 10:16:52 AM: Update 42718: task edges-srl-ontonotes, batch 718 (42718): mcc: 0.8285, acc: 0.7532, precision: 0.8728, recall: 0.7912, f1: 0.8300, edges-srl-ontonotes_loss: 0.0140
09/16 10:17:02 AM: Update 42837: task edges-srl-ontonotes, batch 837 (42837): mcc: 0.8278, acc: 0.7524, precision: 0.8725, recall: 0.7901, f1: 0.8293, edges-srl-ontonotes_loss: 0.0140
09/16 10:17:12 AM: Update 42982: task edges-srl-ontonotes, batch 982 (42982): mcc: 0.8240, acc: 0.7476, precision: 0.8696, recall: 0.7856, f1: 0.8255, edges-srl-ontonotes_loss: 0.0143
09/16 10:17:14 AM: ***** Step 43000 / Validation 43 *****
09/16 10:17:14 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:17:14 AM: Validating...
09/16 10:17:22 AM: Evaluate: task edges-srl-ontonotes, batch 122 (157): mcc: 0.8343, acc: 0.7729, precision: 0.8849, recall: 0.7910, f1: 0.8353, edges-srl-ontonotes_loss: 0.0133
09/16 10:17:25 AM: Updating LR scheduler:
09/16 10:17:25 AM: 	Best result seen so far for macro_avg: 0.836
09/16 10:17:25 AM: 	# validation passes without improvement: 2
09/16 10:17:25 AM: edges-srl-ontonotes_loss: training: 0.014371 validation: 0.013448
09/16 10:17:25 AM: macro_avg: validation: 0.834715
09/16 10:17:25 AM: micro_avg: validation: 0.000000
09/16 10:17:25 AM: edges-srl-ontonotes_mcc: training: 0.823487 validation: 0.833673
09/16 10:17:25 AM: edges-srl-ontonotes_acc: training: 0.746923 validation: 0.772304
09/16 10:17:25 AM: edges-srl-ontonotes_precision: training: 0.869131 validation: 0.884400
09/16 10:17:25 AM: edges-srl-ontonotes_recall: training: 0.785035 validation: 0.790316
09/16 10:17:25 AM: edges-srl-ontonotes_f1: training: 0.824945 validation: 0.834715
09/16 10:17:25 AM: Global learning rate: 3.125e-06
09/16 10:17:25 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 10:17:33 AM: Update 43107: task edges-srl-ontonotes, batch 107 (43107): mcc: 0.7937, acc: 0.7124, precision: 0.8418, recall: 0.7540, f1: 0.7955, edges-srl-ontonotes_loss: 0.0164
09/16 10:17:43 AM: Update 43229: task edges-srl-ontonotes, batch 229 (43229): mcc: 0.7848, acc: 0.6999, precision: 0.8392, recall: 0.7396, f1: 0.7863, edges-srl-ontonotes_loss: 0.0171
09/16 10:17:53 AM: Update 43371: task edges-srl-ontonotes, batch 371 (43371): mcc: 0.7845, acc: 0.7001, precision: 0.8391, recall: 0.7392, f1: 0.7860, edges-srl-ontonotes_loss: 0.0171
09/16 10:18:03 AM: Update 43496: task edges-srl-ontonotes, batch 496 (43496): mcc: 0.7845, acc: 0.7005, precision: 0.8393, recall: 0.7390, f1: 0.7860, edges-srl-ontonotes_loss: 0.0171
09/16 10:18:13 AM: Update 43646: task edges-srl-ontonotes, batch 646 (43646): mcc: 0.7889, acc: 0.7046, precision: 0.8433, recall: 0.7436, f1: 0.7903, edges-srl-ontonotes_loss: 0.0168
09/16 10:18:25 AM: Update 43790: task edges-srl-ontonotes, batch 790 (43790): mcc: 0.7905, acc: 0.7059, precision: 0.8448, recall: 0.7452, f1: 0.7919, edges-srl-ontonotes_loss: 0.0167
09/16 10:18:35 AM: Update 43937: task edges-srl-ontonotes, batch 937 (43937): mcc: 0.7924, acc: 0.7079, precision: 0.8463, recall: 0.7474, f1: 0.7938, edges-srl-ontonotes_loss: 0.0166
09/16 10:18:39 AM: ***** Step 44000 / Validation 44 *****
09/16 10:18:39 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:18:39 AM: Validating...
09/16 10:18:45 AM: Evaluate: task edges-srl-ontonotes, batch 81 (157): mcc: 0.8257, acc: 0.7623, precision: 0.8766, recall: 0.7824, f1: 0.8268, edges-srl-ontonotes_loss: 0.0138
09/16 10:18:50 AM: Best result seen so far for edges-srl-ontonotes.
09/16 10:18:50 AM: Best result seen so far for macro.
09/16 10:18:50 AM: Updating LR scheduler:
09/16 10:18:50 AM: 	Best result seen so far for macro_avg: 0.838
09/16 10:18:50 AM: 	# validation passes without improvement: 0
09/16 10:18:50 AM: edges-srl-ontonotes_loss: training: 0.016563 validation: 0.013321
09/16 10:18:50 AM: macro_avg: validation: 0.837595
09/16 10:18:50 AM: micro_avg: validation: 0.000000
09/16 10:18:50 AM: edges-srl-ontonotes_mcc: training: 0.792388 validation: 0.836357
09/16 10:18:50 AM: edges-srl-ontonotes_acc: training: 0.707830 validation: 0.775845
09/16 10:18:50 AM: edges-srl-ontonotes_precision: training: 0.846513 validation: 0.882815
09/16 10:18:50 AM: edges-srl-ontonotes_recall: training: 0.747226 validation: 0.796782
09/16 10:18:50 AM: edges-srl-ontonotes_f1: training: 0.793776 validation: 0.837595
09/16 10:18:50 AM: Global learning rate: 3.125e-06
09/16 10:18:50 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 10:18:55 AM: Update 44064: task edges-srl-ontonotes, batch 64 (44064): mcc: 0.8085, acc: 0.7255, precision: 0.8610, recall: 0.7643, f1: 0.8098, edges-srl-ontonotes_loss: 0.0154
09/16 10:19:05 AM: Update 44195: task edges-srl-ontonotes, batch 195 (44195): mcc: 0.7992, acc: 0.7169, precision: 0.8531, recall: 0.7540, f1: 0.8005, edges-srl-ontonotes_loss: 0.0159
09/16 10:19:15 AM: Update 44323: task edges-srl-ontonotes, batch 323 (44323): mcc: 0.7994, acc: 0.7175, precision: 0.8529, recall: 0.7545, f1: 0.8007, edges-srl-ontonotes_loss: 0.0160
09/16 10:19:25 AM: Update 44454: task edges-srl-ontonotes, batch 454 (44454): mcc: 0.7964, acc: 0.7137, precision: 0.8502, recall: 0.7513, f1: 0.7977, edges-srl-ontonotes_loss: 0.0162
09/16 10:19:35 AM: Update 44598: task edges-srl-ontonotes, batch 598 (44598): mcc: 0.7914, acc: 0.7071, precision: 0.8462, recall: 0.7456, f1: 0.7927, edges-srl-ontonotes_loss: 0.0166
09/16 10:19:45 AM: Update 44729: task edges-srl-ontonotes, batch 729 (44729): mcc: 0.7892, acc: 0.7041, precision: 0.8449, recall: 0.7427, f1: 0.7905, edges-srl-ontonotes_loss: 0.0167
09/16 10:19:55 AM: Update 44863: task edges-srl-ontonotes, batch 863 (44863): mcc: 0.7893, acc: 0.7042, precision: 0.8454, recall: 0.7426, f1: 0.7906, edges-srl-ontonotes_loss: 0.0167
09/16 10:20:05 AM: ***** Step 45000 / Validation 45 *****
09/16 10:20:05 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:20:05 AM: Validating...
09/16 10:20:05 AM: Evaluate: task edges-srl-ontonotes, batch 2 (157): mcc: 0.8639, acc: 0.7955, precision: 0.9226, recall: 0.8125, f1: 0.8640, edges-srl-ontonotes_loss: 0.0118
09/16 10:20:15 AM: Evaluate: task edges-srl-ontonotes, batch 138 (157): mcc: 0.8373, acc: 0.7772, precision: 0.8843, recall: 0.7972, f1: 0.8385, edges-srl-ontonotes_loss: 0.0131
09/16 10:20:17 AM: Updating LR scheduler:
09/16 10:20:17 AM: 	Best result seen so far for macro_avg: 0.838
09/16 10:20:17 AM: 	# validation passes without improvement: 1
09/16 10:20:17 AM: edges-srl-ontonotes_loss: training: 0.016799 validation: 0.013364
09/16 10:20:17 AM: macro_avg: validation: 0.836392
09/16 10:20:17 AM: micro_avg: validation: 0.000000
09/16 10:20:17 AM: edges-srl-ontonotes_mcc: training: 0.786818 validation: 0.835192
09/16 10:20:17 AM: edges-srl-ontonotes_acc: training: 0.701155 validation: 0.774844
09/16 10:20:17 AM: edges-srl-ontonotes_precision: training: 0.843262 validation: 0.882695
09/16 10:20:17 AM: edges-srl-ontonotes_recall: training: 0.739763 validation: 0.794704
09/16 10:20:17 AM: edges-srl-ontonotes_f1: training: 0.788129 validation: 0.836392
09/16 10:20:17 AM: Global learning rate: 3.125e-06
09/16 10:20:17 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 10:20:25 AM: Update 45081: task edges-srl-ontonotes, batch 81 (45081): mcc: 0.7752, acc: 0.6887, precision: 0.8325, recall: 0.7277, f1: 0.7766, edges-srl-ontonotes_loss: 0.0174
09/16 10:20:35 AM: Update 45203: task edges-srl-ontonotes, batch 203 (45203): mcc: 0.7660, acc: 0.6786, precision: 0.8243, recall: 0.7180, f1: 0.7675, edges-srl-ontonotes_loss: 0.0182
09/16 10:20:45 AM: Update 45318: task edges-srl-ontonotes, batch 318 (45318): mcc: 0.7647, acc: 0.6762, precision: 0.8243, recall: 0.7155, f1: 0.7661, edges-srl-ontonotes_loss: 0.0184
09/16 10:20:55 AM: Update 45417: task edges-srl-ontonotes, batch 417 (45417): mcc: 0.7636, acc: 0.6750, precision: 0.8243, recall: 0.7136, f1: 0.7650, edges-srl-ontonotes_loss: 0.0185
09/16 10:21:05 AM: Update 45551: task edges-srl-ontonotes, batch 551 (45551): mcc: 0.7629, acc: 0.6743, precision: 0.8233, recall: 0.7132, f1: 0.7643, edges-srl-ontonotes_loss: 0.0186
09/16 10:21:16 AM: Update 45670: task edges-srl-ontonotes, batch 670 (45670): mcc: 0.7634, acc: 0.6752, precision: 0.8237, recall: 0.7137, f1: 0.7648, edges-srl-ontonotes_loss: 0.0185
09/16 10:21:26 AM: Update 45796: task edges-srl-ontonotes, batch 796 (45796): mcc: 0.7682, acc: 0.6808, precision: 0.8274, recall: 0.7193, f1: 0.7696, edges-srl-ontonotes_loss: 0.0182
09/16 10:21:36 AM: Update 45919: task edges-srl-ontonotes, batch 919 (45919): mcc: 0.7718, acc: 0.6853, precision: 0.8305, recall: 0.7232, f1: 0.7731, edges-srl-ontonotes_loss: 0.0179
09/16 10:21:45 AM: ***** Step 46000 / Validation 46 *****
09/16 10:21:45 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:21:45 AM: Validating...
09/16 10:21:46 AM: Evaluate: task edges-srl-ontonotes, batch 5 (157): mcc: 0.8648, acc: 0.8064, precision: 0.9160, recall: 0.8200, f1: 0.8654, edges-srl-ontonotes_loss: 0.0121
09/16 10:21:56 AM: Evaluate: task edges-srl-ontonotes, batch 140 (157): mcc: 0.8369, acc: 0.7764, precision: 0.8835, recall: 0.7972, f1: 0.8381, edges-srl-ontonotes_loss: 0.0132
09/16 10:21:57 AM: Updating LR scheduler:
09/16 10:21:57 AM: 	Best result seen so far for macro_avg: 0.838
09/16 10:21:57 AM: 	# validation passes without improvement: 2
09/16 10:21:57 AM: edges-srl-ontonotes_loss: training: 0.017784 validation: 0.013399
09/16 10:21:57 AM: macro_avg: validation: 0.836343
09/16 10:21:57 AM: micro_avg: validation: 0.000000
09/16 10:21:57 AM: edges-srl-ontonotes_mcc: training: 0.773121 validation: 0.835121
09/16 10:21:57 AM: edges-srl-ontonotes_acc: training: 0.686937 validation: 0.774613
09/16 10:21:57 AM: edges-srl-ontonotes_precision: training: 0.831480 validation: 0.882207
09/16 10:21:57 AM: edges-srl-ontonotes_recall: training: 0.724791 validation: 0.795012
09/16 10:21:57 AM: edges-srl-ontonotes_f1: training: 0.774478 validation: 0.836343
09/16 10:21:57 AM: Global learning rate: 3.125e-06
09/16 10:21:57 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 10:22:06 AM: Update 46114: task edges-srl-ontonotes, batch 114 (46114): mcc: 0.7897, acc: 0.7104, precision: 0.8424, recall: 0.7460, f1: 0.7912, edges-srl-ontonotes_loss: 0.0164
09/16 10:22:16 AM: Update 46240: task edges-srl-ontonotes, batch 240 (46240): mcc: 0.7939, acc: 0.7137, precision: 0.8482, recall: 0.7486, f1: 0.7953, edges-srl-ontonotes_loss: 0.0162
09/16 10:22:26 AM: Update 46354: task edges-srl-ontonotes, batch 354 (46354): mcc: 0.7940, acc: 0.7133, precision: 0.8476, recall: 0.7492, f1: 0.7954, edges-srl-ontonotes_loss: 0.0163
09/16 10:22:36 AM: Update 46478: task edges-srl-ontonotes, batch 478 (46478): mcc: 0.7952, acc: 0.7144, precision: 0.8490, recall: 0.7502, f1: 0.7965, edges-srl-ontonotes_loss: 0.0162
09/16 10:22:47 AM: Update 46607: task edges-srl-ontonotes, batch 607 (46607): mcc: 0.7969, acc: 0.7163, precision: 0.8506, recall: 0.7520, f1: 0.7983, edges-srl-ontonotes_loss: 0.0162
09/16 10:22:57 AM: Update 46736: task edges-srl-ontonotes, batch 736 (46736): mcc: 0.7940, acc: 0.7132, precision: 0.8483, recall: 0.7487, f1: 0.7954, edges-srl-ontonotes_loss: 0.0163
09/16 10:23:07 AM: Update 46864: task edges-srl-ontonotes, batch 864 (46864): mcc: 0.7916, acc: 0.7099, precision: 0.8467, recall: 0.7457, f1: 0.7930, edges-srl-ontonotes_loss: 0.0165
09/16 10:23:17 AM: Update 46980: task edges-srl-ontonotes, batch 980 (46980): mcc: 0.7898, acc: 0.7077, precision: 0.8453, recall: 0.7435, f1: 0.7911, edges-srl-ontonotes_loss: 0.0166
09/16 10:23:18 AM: ***** Step 47000 / Validation 47 *****
09/16 10:23:18 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:23:18 AM: Validating...
09/16 10:23:27 AM: Evaluate: task edges-srl-ontonotes, batch 115 (157): mcc: 0.8324, acc: 0.7695, precision: 0.8832, recall: 0.7889, f1: 0.8334, edges-srl-ontonotes_loss: 0.0134
09/16 10:23:30 AM: Updating LR scheduler:
09/16 10:23:30 AM: 	Best result seen so far for macro_avg: 0.838
09/16 10:23:30 AM: 	# validation passes without improvement: 3
09/16 10:23:30 AM: edges-srl-ontonotes_loss: training: 0.016621 validation: 0.013402
09/16 10:23:30 AM: macro_avg: validation: 0.835586
09/16 10:23:30 AM: micro_avg: validation: 0.000000
09/16 10:23:30 AM: edges-srl-ontonotes_mcc: training: 0.789779 validation: 0.834473
09/16 10:23:30 AM: edges-srl-ontonotes_acc: training: 0.707677 validation: 0.773151
09/16 10:23:30 AM: edges-srl-ontonotes_precision: training: 0.845258 validation: 0.883757
09/16 10:23:30 AM: edges-srl-ontonotes_recall: training: 0.743490 validation: 0.792395
09/16 10:23:30 AM: edges-srl-ontonotes_f1: training: 0.791114 validation: 0.835586
09/16 10:23:30 AM: Global learning rate: 3.125e-06
09/16 10:23:30 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 10:23:37 AM: Update 47087: task edges-srl-ontonotes, batch 87 (47087): mcc: 0.7720, acc: 0.6894, precision: 0.8300, recall: 0.7241, f1: 0.7734, edges-srl-ontonotes_loss: 0.0179
09/16 10:23:47 AM: Update 47220: task edges-srl-ontonotes, batch 220 (47220): mcc: 0.7753, acc: 0.6897, precision: 0.8342, recall: 0.7264, f1: 0.7766, edges-srl-ontonotes_loss: 0.0176
09/16 10:23:57 AM: Update 47320: task edges-srl-ontonotes, batch 320 (47320): mcc: 0.7760, acc: 0.6903, precision: 0.8352, recall: 0.7269, f1: 0.7773, edges-srl-ontonotes_loss: 0.0175
09/16 10:24:07 AM: Update 47451: task edges-srl-ontonotes, batch 451 (47451): mcc: 0.7748, acc: 0.6894, precision: 0.8335, recall: 0.7262, f1: 0.7761, edges-srl-ontonotes_loss: 0.0176
09/16 10:24:17 AM: Update 47571: task edges-srl-ontonotes, batch 571 (47571): mcc: 0.7750, acc: 0.6892, precision: 0.8333, recall: 0.7266, f1: 0.7763, edges-srl-ontonotes_loss: 0.0176
09/16 10:24:27 AM: Update 47711: task edges-srl-ontonotes, batch 711 (47711): mcc: 0.7767, acc: 0.6917, precision: 0.8340, recall: 0.7292, f1: 0.7781, edges-srl-ontonotes_loss: 0.0174
09/16 10:24:37 AM: Update 47849: task edges-srl-ontonotes, batch 849 (47849): mcc: 0.7794, acc: 0.6950, precision: 0.8361, recall: 0.7324, f1: 0.7808, edges-srl-ontonotes_loss: 0.0173
09/16 10:24:47 AM: Update 47975: task edges-srl-ontonotes, batch 975 (47975): mcc: 0.7807, acc: 0.6964, precision: 0.8369, recall: 0.7341, f1: 0.7821, edges-srl-ontonotes_loss: 0.0172
09/16 10:24:49 AM: ***** Step 48000 / Validation 48 *****
09/16 10:24:49 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:24:49 AM: Validating...
09/16 10:24:57 AM: Evaluate: task edges-srl-ontonotes, batch 106 (157): mcc: 0.8294, acc: 0.7654, precision: 0.8816, recall: 0.7848, f1: 0.8304, edges-srl-ontonotes_loss: 0.0134
09/16 10:25:01 AM: Updating LR scheduler:
09/16 10:25:01 AM: 	Best result seen so far for macro_avg: 0.838
09/16 10:25:01 AM: 	# validation passes without improvement: 0
09/16 10:25:01 AM: edges-srl-ontonotes_loss: training: 0.017179 validation: 0.013469
09/16 10:25:01 AM: macro_avg: validation: 0.834422
09/16 10:25:01 AM: micro_avg: validation: 0.000000
09/16 10:25:01 AM: edges-srl-ontonotes_mcc: training: 0.780782 validation: 0.833274
09/16 10:25:01 AM: edges-srl-ontonotes_acc: training: 0.696401 validation: 0.771765
09/16 10:25:01 AM: edges-srl-ontonotes_precision: training: 0.836864 validation: 0.882207
09/16 10:25:01 AM: edges-srl-ontonotes_recall: training: 0.734231 validation: 0.791548
09/16 10:25:01 AM: edges-srl-ontonotes_f1: training: 0.782195 validation: 0.834422
09/16 10:25:01 AM: Global learning rate: 1.5625e-06
09/16 10:25:01 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 10:25:07 AM: Update 48084: task edges-srl-ontonotes, batch 84 (48084): mcc: 0.7873, acc: 0.7060, precision: 0.8412, recall: 0.7425, f1: 0.7888, edges-srl-ontonotes_loss: 0.0165
09/16 10:25:17 AM: Update 48178: task edges-srl-ontonotes, batch 178 (48178): mcc: 0.7888, acc: 0.7073, precision: 0.8444, recall: 0.7425, f1: 0.7901, edges-srl-ontonotes_loss: 0.0168
09/16 10:25:27 AM: Update 48296: task edges-srl-ontonotes, batch 296 (48296): mcc: 0.7786, acc: 0.6932, precision: 0.8377, recall: 0.7295, f1: 0.7799, edges-srl-ontonotes_loss: 0.0176
09/16 10:25:37 AM: Update 48413: task edges-srl-ontonotes, batch 413 (48413): mcc: 0.7744, acc: 0.6881, precision: 0.8355, recall: 0.7236, f1: 0.7756, edges-srl-ontonotes_loss: 0.0178
09/16 10:25:47 AM: Update 48523: task edges-srl-ontonotes, batch 523 (48523): mcc: 0.7749, acc: 0.6890, precision: 0.8356, recall: 0.7244, f1: 0.7761, edges-srl-ontonotes_loss: 0.0178
09/16 10:25:57 AM: Update 48672: task edges-srl-ontonotes, batch 672 (48672): mcc: 0.7820, acc: 0.6984, precision: 0.8393, recall: 0.7343, f1: 0.7833, edges-srl-ontonotes_loss: 0.0172
09/16 10:26:07 AM: Update 48799: task edges-srl-ontonotes, batch 799 (48799): mcc: 0.7858, acc: 0.7028, precision: 0.8423, recall: 0.7387, f1: 0.7871, edges-srl-ontonotes_loss: 0.0169
09/16 10:26:17 AM: Update 48964: task edges-srl-ontonotes, batch 964 (48964): mcc: 0.7937, acc: 0.7126, precision: 0.8474, recall: 0.7488, f1: 0.7951, edges-srl-ontonotes_loss: 0.0164
09/16 10:26:20 AM: ***** Step 49000 / Validation 49 *****
09/16 10:26:20 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:26:20 AM: Validating...
09/16 10:26:27 AM: Evaluate: task edges-srl-ontonotes, batch 107 (157): mcc: 0.8313, acc: 0.7667, precision: 0.8857, recall: 0.7847, f1: 0.8322, edges-srl-ontonotes_loss: 0.0134
09/16 10:26:31 AM: Updating LR scheduler:
09/16 10:26:31 AM: 	Best result seen so far for macro_avg: 0.838
09/16 10:26:31 AM: 	# validation passes without improvement: 1
09/16 10:26:31 AM: edges-srl-ontonotes_loss: training: 0.016314 validation: 0.013445
09/16 10:26:31 AM: macro_avg: validation: 0.834819
09/16 10:26:31 AM: micro_avg: validation: 0.000000
09/16 10:26:31 AM: edges-srl-ontonotes_mcc: training: 0.795179 validation: 0.833837
09/16 10:26:31 AM: edges-srl-ontonotes_acc: training: 0.714553 validation: 0.771457
09/16 10:26:31 AM: edges-srl-ontonotes_precision: training: 0.848488 validation: 0.885598
09/16 10:26:31 AM: edges-srl-ontonotes_recall: training: 0.750660 validation: 0.789547
09/16 10:26:31 AM: edges-srl-ontonotes_f1: training: 0.796581 validation: 0.834819
09/16 10:26:31 AM: Global learning rate: 1.5625e-06
09/16 10:26:31 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 10:26:38 AM: Update 49111: task edges-srl-ontonotes, batch 111 (49111): mcc: 0.8284, acc: 0.7567, precision: 0.8709, recall: 0.7927, f1: 0.8300, edges-srl-ontonotes_loss: 0.0135
09/16 10:26:48 AM: Update 49281: task edges-srl-ontonotes, batch 281 (49281): mcc: 0.8274, acc: 0.7540, precision: 0.8705, recall: 0.7912, f1: 0.8290, edges-srl-ontonotes_loss: 0.0138
09/16 10:26:59 AM: Update 49424: task edges-srl-ontonotes, batch 424 (49424): mcc: 0.8262, acc: 0.7523, precision: 0.8694, recall: 0.7899, f1: 0.8277, edges-srl-ontonotes_loss: 0.0139
09/16 10:27:09 AM: Update 49605: task edges-srl-ontonotes, batch 605 (49605): mcc: 0.8256, acc: 0.7509, precision: 0.8695, recall: 0.7887, f1: 0.8271, edges-srl-ontonotes_loss: 0.0140
09/16 10:27:19 AM: Update 49771: task edges-srl-ontonotes, batch 771 (49771): mcc: 0.8271, acc: 0.7525, precision: 0.8705, recall: 0.7906, f1: 0.8286, edges-srl-ontonotes_loss: 0.0139
09/16 10:27:29 AM: Update 49958: task edges-srl-ontonotes, batch 958 (49958): mcc: 0.8277, acc: 0.7529, precision: 0.8716, recall: 0.7908, f1: 0.8292, edges-srl-ontonotes_loss: 0.0139
09/16 10:27:31 AM: ***** Step 50000 / Validation 50 *****
09/16 10:27:31 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:27:31 AM: Validating...
09/16 10:27:39 AM: Evaluate: task edges-srl-ontonotes, batch 108 (157): mcc: 0.8315, acc: 0.7665, precision: 0.8872, recall: 0.7838, f1: 0.8323, edges-srl-ontonotes_loss: 0.0134
09/16 10:27:43 AM: Updating LR scheduler:
09/16 10:27:43 AM: 	Best result seen so far for macro_avg: 0.838
09/16 10:27:43 AM: 	# validation passes without improvement: 2
09/16 10:27:43 AM: edges-srl-ontonotes_loss: training: 0.013881 validation: 0.013404
09/16 10:27:43 AM: macro_avg: validation: 0.835152
09/16 10:27:43 AM: micro_avg: validation: 0.000000
09/16 10:27:43 AM: edges-srl-ontonotes_mcc: training: 0.828744 validation: 0.834214
09/16 10:27:43 AM: edges-srl-ontonotes_acc: training: 0.754181 validation: 0.771149
09/16 10:27:43 AM: edges-srl-ontonotes_precision: training: 0.872465 validation: 0.886641
09/16 10:27:43 AM: edges-srl-ontonotes_recall: training: 0.791891 validation: 0.789316
09/16 10:27:43 AM: edges-srl-ontonotes_f1: training: 0.830227 validation: 0.835152
09/16 10:27:43 AM: Global learning rate: 1.5625e-06
09/16 10:27:43 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 10:27:49 AM: Update 50089: task edges-srl-ontonotes, batch 89 (50089): mcc: 0.8092, acc: 0.7305, precision: 0.8593, recall: 0.7671, f1: 0.8106, edges-srl-ontonotes_loss: 0.0150
09/16 10:27:59 AM: Update 50236: task edges-srl-ontonotes, batch 236 (50236): mcc: 0.8036, acc: 0.7229, precision: 0.8559, recall: 0.7597, f1: 0.8049, edges-srl-ontonotes_loss: 0.0156
09/16 10:28:12 AM: Update 50363: task edges-srl-ontonotes, batch 363 (50363): mcc: 0.8021, acc: 0.7200, precision: 0.8536, recall: 0.7590, f1: 0.8035, edges-srl-ontonotes_loss: 0.0158
09/16 10:28:22 AM: Update 50492: task edges-srl-ontonotes, batch 492 (50492): mcc: 0.7960, acc: 0.7131, precision: 0.8496, recall: 0.7513, f1: 0.7974, edges-srl-ontonotes_loss: 0.0163
09/16 10:28:32 AM: Update 50632: task edges-srl-ontonotes, batch 632 (50632): mcc: 0.7936, acc: 0.7102, precision: 0.8480, recall: 0.7481, f1: 0.7949, edges-srl-ontonotes_loss: 0.0165
09/16 10:28:42 AM: Update 50763: task edges-srl-ontonotes, batch 763 (50763): mcc: 0.7919, acc: 0.7082, precision: 0.8472, recall: 0.7457, f1: 0.7932, edges-srl-ontonotes_loss: 0.0166
09/16 10:28:52 AM: Update 50920: task edges-srl-ontonotes, batch 920 (50920): mcc: 0.7931, acc: 0.7090, precision: 0.8481, recall: 0.7471, f1: 0.7944, edges-srl-ontonotes_loss: 0.0164
09/16 10:28:58 AM: ***** Step 51000 / Validation 51 *****
09/16 10:28:58 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:28:58 AM: Validating...
09/16 10:29:02 AM: Evaluate: task edges-srl-ontonotes, batch 60 (157): mcc: 0.8174, acc: 0.7520, precision: 0.8735, recall: 0.7697, f1: 0.8183, edges-srl-ontonotes_loss: 0.0143
09/16 10:29:09 AM: Updating LR scheduler:
09/16 10:29:09 AM: 	Best result seen so far for macro_avg: 0.838
09/16 10:29:09 AM: 	# validation passes without improvement: 3
09/16 10:29:09 AM: edges-srl-ontonotes_loss: training: 0.016418 validation: 0.013338
09/16 10:29:09 AM: macro_avg: validation: 0.836551
09/16 10:29:09 AM: micro_avg: validation: 0.000000
09/16 10:29:09 AM: edges-srl-ontonotes_mcc: training: 0.793805 validation: 0.835418
09/16 10:29:09 AM: edges-srl-ontonotes_acc: training: 0.710006 validation: 0.775229
09/16 10:29:09 AM: edges-srl-ontonotes_precision: training: 0.848537 validation: 0.884098
09/16 10:29:09 AM: edges-srl-ontonotes_recall: training: 0.748060 validation: 0.793857
09/16 10:29:09 AM: edges-srl-ontonotes_f1: training: 0.795137 validation: 0.836551
09/16 10:29:09 AM: Global learning rate: 1.5625e-06
09/16 10:29:09 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 10:29:13 AM: Update 51036: task edges-srl-ontonotes, batch 36 (51036): mcc: 0.7987, acc: 0.7177, precision: 0.8559, recall: 0.7506, f1: 0.7998, edges-srl-ontonotes_loss: 0.0164
09/16 10:29:23 AM: Update 51179: task edges-srl-ontonotes, batch 179 (51179): mcc: 0.7971, acc: 0.7119, precision: 0.8535, recall: 0.7499, f1: 0.7983, edges-srl-ontonotes_loss: 0.0161
09/16 10:29:33 AM: Update 51316: task edges-srl-ontonotes, batch 316 (51316): mcc: 0.7994, acc: 0.7147, precision: 0.8550, recall: 0.7528, f1: 0.8006, edges-srl-ontonotes_loss: 0.0160
09/16 10:29:43 AM: Update 51422: task edges-srl-ontonotes, batch 422 (51422): mcc: 0.7988, acc: 0.7142, precision: 0.8542, recall: 0.7524, f1: 0.8000, edges-srl-ontonotes_loss: 0.0161
09/16 10:29:53 AM: Update 51580: task edges-srl-ontonotes, batch 580 (51580): mcc: 0.7976, acc: 0.7139, precision: 0.8521, recall: 0.7519, f1: 0.7989, edges-srl-ontonotes_loss: 0.0161
09/16 10:30:03 AM: Update 51716: task edges-srl-ontonotes, batch 716 (51716): mcc: 0.7963, acc: 0.7125, precision: 0.8505, recall: 0.7509, f1: 0.7976, edges-srl-ontonotes_loss: 0.0162
09/16 10:30:13 AM: Update 51865: task edges-srl-ontonotes, batch 865 (51865): mcc: 0.7934, acc: 0.7089, precision: 0.8485, recall: 0.7473, f1: 0.7947, edges-srl-ontonotes_loss: 0.0164
09/16 10:30:23 AM: Update 51997: task edges-srl-ontonotes, batch 997 (51997): mcc: 0.7913, acc: 0.7060, precision: 0.8467, recall: 0.7450, f1: 0.7926, edges-srl-ontonotes_loss: 0.0166
09/16 10:30:23 AM: ***** Step 52000 / Validation 52 *****
09/16 10:30:23 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:30:23 AM: Validating...
09/16 10:30:33 AM: Evaluate: task edges-srl-ontonotes, batch 133 (157): mcc: 0.8385, acc: 0.7785, precision: 0.8853, recall: 0.7985, f1: 0.8397, edges-srl-ontonotes_loss: 0.0131
09/16 10:30:35 AM: Updating LR scheduler:
09/16 10:30:35 AM: 	Best result seen so far for macro_avg: 0.838
09/16 10:30:35 AM: 	# validation passes without improvement: 0
09/16 10:30:35 AM: Minimum LR reached. Stopping training.
09/16 10:30:35 AM: edges-srl-ontonotes_loss: training: 0.016557 validation: 0.013335
09/16 10:30:35 AM: macro_avg: validation: 0.836853
09/16 10:30:35 AM: micro_avg: validation: 0.000000
09/16 10:30:35 AM: edges-srl-ontonotes_mcc: training: 0.791198 validation: 0.835694
09/16 10:30:35 AM: edges-srl-ontonotes_acc: training: 0.705970 validation: 0.775075
09/16 10:30:35 AM: edges-srl-ontonotes_precision: training: 0.846633 validation: 0.883819
09/16 10:30:35 AM: edges-srl-ontonotes_recall: training: 0.744906 validation: 0.794627
09/16 10:30:35 AM: edges-srl-ontonotes_f1: training: 0.792519 validation: 0.836853
09/16 10:30:35 AM: Global learning rate: 7.8125e-07
09/16 10:30:35 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-top/run
09/16 10:30:35 AM: Stopped training after 52 validation checks
09/16 10:30:35 AM: Trained edges-srl-ontonotes for 52000 batches or 7.188 epochs
09/16 10:30:35 AM: ***** VALIDATION RESULTS *****
09/16 10:30:35 AM: edges-srl-ontonotes_f1 (for best val pass 44): edges-srl-ontonotes_loss: 0.01332, macro_avg: 0.83760, micro_avg: 0.00000, edges-srl-ontonotes_mcc: 0.83636, edges-srl-ontonotes_acc: 0.77584, edges-srl-ontonotes_precision: 0.88281, edges-srl-ontonotes_recall: 0.79678, edges-srl-ontonotes_f1: 0.83760
09/16 10:30:35 AM: micro_avg (for best val pass 1): edges-srl-ontonotes_loss: 0.02688, macro_avg: 0.67235, micro_avg: 0.00000, edges-srl-ontonotes_mcc: 0.68500, edges-srl-ontonotes_acc: 0.54022, edges-srl-ontonotes_precision: 0.85776, edges-srl-ontonotes_recall: 0.55284, edges-srl-ontonotes_f1: 0.67235
09/16 10:30:35 AM: macro_avg (for best val pass 44): edges-srl-ontonotes_loss: 0.01332, macro_avg: 0.83760, micro_avg: 0.00000, edges-srl-ontonotes_mcc: 0.83636, edges-srl-ontonotes_acc: 0.77584, edges-srl-ontonotes_precision: 0.88281, edges-srl-ontonotes_recall: 0.79678, edges-srl-ontonotes_f1: 0.83760
09/16 10:30:35 AM: Evaluating...
09/16 10:30:35 AM: Loaded model state from ./experiments/srl-ontonotes-sts-top/run/edges-srl-ontonotes/model_state_target_train_val_44.best.th
09/16 10:30:35 AM: Evaluating on: edges-srl-ontonotes, split: val
09/16 10:31:05 AM: 	Task edges-srl-ontonotes: batch 356
09/16 10:31:35 AM: 	Task edges-srl-ontonotes: batch 689
09/16 10:32:05 AM: 	Task edges-srl-ontonotes: batch 997
09/16 10:32:07 AM: Task 'edges-srl-ontonotes': sorting predictions by 'idx'
09/16 10:32:07 AM: Finished evaluating on: edges-srl-ontonotes
09/16 10:32:07 AM: Task 'edges-srl-ontonotes': joining predictions with input split 'val'
09/16 10:32:12 AM: Task 'edges-srl-ontonotes': Wrote predictions to ./experiments/srl-ontonotes-sts-top/run
09/16 10:32:12 AM: Wrote all preds for split 'val' to ./experiments/srl-ontonotes-sts-top/run
09/16 10:32:12 AM: Evaluating on: edges-srl-ontonotes, split: test
09/16 10:32:42 AM: 	Task edges-srl-ontonotes: batch 350
09/16 10:33:12 AM: 	Task edges-srl-ontonotes: batch 711
09/16 10:33:15 AM: Task 'edges-srl-ontonotes': sorting predictions by 'idx'
09/16 10:33:15 AM: Finished evaluating on: edges-srl-ontonotes
09/16 10:33:15 AM: Task 'edges-srl-ontonotes': joining predictions with input split 'test'
09/16 10:33:19 AM: Task 'edges-srl-ontonotes': Wrote predictions to ./experiments/srl-ontonotes-sts-top/run
09/16 10:33:19 AM: Wrote all preds for split 'test' to ./experiments/srl-ontonotes-sts-top/run
09/16 10:33:19 AM: Writing results for split 'val' to ./experiments/srl-ontonotes-sts-top/results.tsv
09/16 10:33:19 AM: micro_avg: 0.000, macro_avg: 0.837, edges-srl-ontonotes_mcc: 0.835, edges-srl-ontonotes_acc: 0.775, edges-srl-ontonotes_precision: 0.879, edges-srl-ontonotes_recall: 0.798, edges-srl-ontonotes_f1: 0.837
09/16 10:33:19 AM: Done!
09/16 10:33:19 AM: Fatal error in main():
Traceback (most recent call last):
  File "main.py", line 16, in <module>
    main(sys.argv[1:])
  File "/srv/home/ericwallace/jiant/jiant/__main__.py", line 610, in main
    exit("Done exited")
  File "/home/ericwallace/miniconda3/envs/jiant/lib/python3.6/_sitebuiltins.py", line 26, in __call__
    raise SystemExit(code)
SystemExit: Done exited
