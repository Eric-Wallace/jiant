09/17 12:27:20 AM: Git branch: master
09/17 12:27:20 AM: Git SHA: 4086cd8f278243816795989a620c769378a6ab56
09/17 12:27:21 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/coref-ontonotes-memorization-only/",
  "exp_name": "experiments/coref-ontonotes-memorization-only",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/coref-ontonotes-memorization-only/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/memorization",
  "pytorch_transformers_output_mode": "only",
  "remote_log_name": "experiments/coref-ontonotes-memorization-only__run",
  "run_dir": "./experiments/coref-ontonotes-memorization-only/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-coref-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/17 12:27:21 AM: Saved config to ./experiments/coref-ontonotes-memorization-only/run/params.conf
09/17 12:27:21 AM: Using random seed 1234
09/17 12:27:25 AM: Using GPU 0
09/17 12:27:25 AM: Loading tasks...
09/17 12:27:25 AM: Writing pre-preprocessed tasks to ./experiments/coref-ontonotes-memorization-only/
09/17 12:27:25 AM: 	Creating task edges-coref-ontonotes from scratch.
09/17 12:27:27 AM: Read=41777, Skip=74035, Total=115812 from ./probing_data/edges/ontonotes/coref/train.json.retokenized.bert-base-uncased
09/17 12:27:27 AM: Read=5044, Skip=10636, Total=15680 from ./probing_data/edges/ontonotes/coref/development.json.retokenized.bert-base-uncased
09/17 12:27:27 AM: Read=5188, Skip=7029, Total=12217 from ./probing_data/edges/ontonotes/coref/test.json.retokenized.bert-base-uncased
09/17 12:27:28 AM: 	Task 'edges-coref-ontonotes': |train|=41777 |val|=5044 |test|=5188
09/17 12:27:28 AM: 	Finished loading tasks: edges-coref-ontonotes.
09/17 12:27:28 AM: 	Building vocab from scratch.
09/17 12:27:28 AM: 	Counting units for task edges-coref-ontonotes.
09/17 12:27:29 AM: 	Task 'edges-coref-ontonotes': adding vocab namespace 'edges-coref-ontonotes_labels'
09/17 12:27:30 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/17 12:27:30 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/17 12:27:30 AM: 	Saved vocab to ./experiments/coref-ontonotes-memorization-only/vocab
09/17 12:27:30 AM: Loading token dictionary from ./experiments/coref-ontonotes-memorization-only/vocab.
09/17 12:27:30 AM: 	Loaded vocab from ./experiments/coref-ontonotes-memorization-only/vocab
09/17 12:27:30 AM: 	Vocab namespace tokens: size 20434
09/17 12:27:30 AM: 	Vocab namespace bert_uncased: size 30524
09/17 12:27:30 AM: 	Vocab namespace edges-coref-ontonotes_labels: size 2
09/17 12:27:30 AM: 	Vocab namespace chars: size 72
09/17 12:27:30 AM: 	Finished building vocab.
09/17 12:27:30 AM: 	Task edges-coref-ontonotes (train): Indexing from scratch.
09/17 12:27:40 AM: 	Task edges-coref-ontonotes (train): Saved 41777 instances to ./experiments/coref-ontonotes-memorization-only/preproc/edges-coref-ontonotes__train_data
09/17 12:27:40 AM: 	Task edges-coref-ontonotes (val): Indexing from scratch.
09/17 12:27:41 AM: 	Task edges-coref-ontonotes (val): Saved 5044 instances to ./experiments/coref-ontonotes-memorization-only/preproc/edges-coref-ontonotes__val_data
09/17 12:27:41 AM: 	Task edges-coref-ontonotes (test): Indexing from scratch.
09/17 12:27:42 AM: 	Task edges-coref-ontonotes (test): Saved 5188 instances to ./experiments/coref-ontonotes-memorization-only/preproc/edges-coref-ontonotes__test_data
09/17 12:27:42 AM: 	Finished indexing tasks
09/17 12:27:42 AM: 	Creating trimmed target-only version of edges-coref-ontonotes train.
09/17 12:27:42 AM: 	  Training on 
09/17 12:27:42 AM: 	  Evaluating on edges-coref-ontonotes
09/17 12:27:42 AM: 	Finished loading tasks in 17.424s
09/17 12:27:42 AM: 	 Tasks: ['edges-coref-ontonotes']
09/17 12:27:42 AM: Building model...
09/17 12:27:42 AM: Using BERT model (bert-base-uncased).
09/17 12:27:42 AM: LOADING A FUNETUNED MODEL from: 
09/17 12:27:42 AM: models/memorization
09/17 12:27:42 AM: loading configuration file models/memorization/config.json
09/17 12:27:42 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "random-memorization",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/17 12:27:42 AM: loading weights file models/memorization/pytorch_model.bin
09/17 12:27:46 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpiwmwqv4s
09/17 12:27:49 AM: copying /tmp/tmpiwmwqv4s to cache at ./experiments/coref-ontonotes-memorization-only/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/17 12:27:49 AM: creating metadata file for ./experiments/coref-ontonotes-memorization-only/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/17 12:27:49 AM: removing temp file /tmp/tmpiwmwqv4s
09/17 12:27:49 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/coref-ontonotes-memorization-only/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/17 12:27:49 AM: Initializing parameters
09/17 12:27:49 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/17 12:27:49 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/17 12:27:49 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/17 12:27:49 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/17 12:27:49 AM:    _text_field_embedder.model.pooler.dense.bias
09/17 12:27:49 AM:    _text_field_embedder.model.pooler.dense.weight
09/17 12:27:49 AM: 	Task 'edges-coref-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-coref-ontonotes"
}
09/17 12:27:54 AM: Model specification:
09/17 12:27:54 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-coref-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (proj2): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (span_extractor2): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Sequential(
        (0): Linear(in_features=1024, out_features=256, bias=True)
        (1): Tanh()
        (2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)
        (3): Dropout(p=0.3)
        (4): Linear(in_features=256, out_features=2, bias=True)
      )
    )
  )
)
09/17 12:27:54 AM: Model parameters:
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:27:54 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:27:54 AM: 	edges-coref-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/17 12:27:54 AM: 	edges-coref-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/17 12:27:54 AM: 	edges-coref-ontonotes_mdl.proj2.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/17 12:27:54 AM: 	edges-coref-ontonotes_mdl.proj2.bias: Trainable parameter, count 256 with torch.Size([256])
09/17 12:27:54 AM: 	edges-coref-ontonotes_mdl.classifier.classifier.0.weight: Trainable parameter, count 262144 with torch.Size([256, 1024])
09/17 12:27:54 AM: 	edges-coref-ontonotes_mdl.classifier.classifier.0.bias: Trainable parameter, count 256 with torch.Size([256])
09/17 12:27:54 AM: 	edges-coref-ontonotes_mdl.classifier.classifier.2.weight: Trainable parameter, count 256 with torch.Size([256])
09/17 12:27:54 AM: 	edges-coref-ontonotes_mdl.classifier.classifier.2.bias: Trainable parameter, count 256 with torch.Size([256])
09/17 12:27:54 AM: 	edges-coref-ontonotes_mdl.classifier.classifier.4.weight: Trainable parameter, count 512 with torch.Size([2, 256])
09/17 12:27:54 AM: 	edges-coref-ontonotes_mdl.classifier.classifier.4.bias: Trainable parameter, count 2 with torch.Size([2])
09/17 12:27:54 AM: Total number of parameters: 110139394 (1.10139e+08)
09/17 12:27:54 AM: Number of trainable parameters: 657154 (657154)
09/17 12:27:54 AM: Finished building model in 11.500s
09/17 12:27:54 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-coref-ontonotes 

09/17 12:27:59 AM: patience = 9
09/17 12:27:59 AM: val_interval = 1000
09/17 12:27:59 AM: max_vals = 250
09/17 12:27:59 AM: cuda_device = 0
09/17 12:27:59 AM: grad_norm = 5.0
09/17 12:27:59 AM: grad_clipping = None
09/17 12:27:59 AM: lr_decay = 0.99
09/17 12:27:59 AM: min_lr = 1e-06
09/17 12:27:59 AM: keep_all_checkpoints = 0
09/17 12:27:59 AM: val_data_limit = 5000
09/17 12:27:59 AM: max_epochs = -1
09/17 12:27:59 AM: dec_val_scale = 250
09/17 12:27:59 AM: training_data_fraction = 1
09/17 12:27:59 AM: type = adam
09/17 12:27:59 AM: parameter_groups = None
09/17 12:27:59 AM: Number of trainable parameters: 657154
09/17 12:27:59 AM: infer_type_and_cast = True
09/17 12:27:59 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/17 12:27:59 AM: CURRENTLY DEFINED PARAMETERS: 
09/17 12:27:59 AM: lr = 0.0001
09/17 12:27:59 AM: amsgrad = True
09/17 12:27:59 AM: type = reduce_on_plateau
09/17 12:27:59 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/17 12:27:59 AM: CURRENTLY DEFINED PARAMETERS: 
09/17 12:27:59 AM: mode = max
09/17 12:27:59 AM: factor = 0.5
09/17 12:27:59 AM: patience = 3
09/17 12:27:59 AM: threshold = 0.0001
09/17 12:27:59 AM: threshold_mode = abs
09/17 12:27:59 AM: verbose = True
09/17 12:27:59 AM: type = adam
09/17 12:27:59 AM: parameter_groups = None
09/17 12:27:59 AM: Number of trainable parameters: 657154
09/17 12:27:59 AM: infer_type_and_cast = True
09/17 12:27:59 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/17 12:27:59 AM: CURRENTLY DEFINED PARAMETERS: 
09/17 12:27:59 AM: lr = 0.0001
09/17 12:27:59 AM: amsgrad = True
09/17 12:27:59 AM: type = reduce_on_plateau
09/17 12:27:59 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/17 12:27:59 AM: CURRENTLY DEFINED PARAMETERS: 
09/17 12:27:59 AM: mode = max
09/17 12:27:59 AM: factor = 0.5
09/17 12:27:59 AM: patience = 3
09/17 12:27:59 AM: threshold = 0.0001
09/17 12:27:59 AM: threshold_mode = abs
09/17 12:27:59 AM: verbose = True
09/17 12:27:59 AM: Starting training without restoring from a checkpoint.
09/17 12:27:59 AM: Training examples per task, before any subsampling: {'edges-coref-ontonotes': 41777}
09/17 12:27:59 AM: Beginning training with stopping criteria based on metric: edges-coref-ontonotes_f1
09/17 12:28:09 AM: Update 275: task edges-coref-ontonotes, batch 275 (275): mcc: 0.5879, acc: 0.7569, precision: 0.7924, recall: 0.7967, f1: 0.7945, edges-coref-ontonotes_loss: 0.4278
09/17 12:28:19 AM: Update 516: task edges-coref-ontonotes, batch 516 (516): mcc: 0.6032, acc: 0.7687, precision: 0.8013, recall: 0.8021, f1: 0.8017, edges-coref-ontonotes_loss: 0.4205
09/17 12:28:29 AM: Update 766: task edges-coref-ontonotes, batch 766 (766): mcc: 0.6220, acc: 0.7821, precision: 0.8112, recall: 0.8107, f1: 0.8109, edges-coref-ontonotes_loss: 0.4103
09/17 12:28:38 AM: ***** Step 1000 / Validation 1 *****
09/17 12:28:38 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:28:38 AM: Validating...
09/17 12:28:39 AM: Evaluate: task edges-coref-ontonotes, batch 21 (157): mcc: 0.7369, acc: 0.8648, precision: 0.8709, recall: 0.8652, f1: 0.8680, edges-coref-ontonotes_loss: 0.3559
09/17 12:28:44 AM: Best result seen so far for edges-coref-ontonotes.
09/17 12:28:44 AM: Best result seen so far for micro.
09/17 12:28:44 AM: Best result seen so far for macro.
09/17 12:28:44 AM: Updating LR scheduler:
09/17 12:28:44 AM: 	Best result seen so far for macro_avg: 0.854
09/17 12:28:44 AM: 	# validation passes without improvement: 0
09/17 12:28:44 AM: edges-coref-ontonotes_loss: training: 0.396285 validation: 0.375794
09/17 12:28:44 AM: macro_avg: validation: 0.854465
09/17 12:28:44 AM: micro_avg: validation: 0.000000
09/17 12:28:44 AM: edges-coref-ontonotes_mcc: training: 0.642654 validation: 0.709886
09/17 12:28:44 AM: edges-coref-ontonotes_acc: training: 0.795453 validation: 0.850743
09/17 12:28:44 AM: edges-coref-ontonotes_precision: training: 0.821722 validation: 0.857247
09/17 12:28:44 AM: edges-coref-ontonotes_recall: training: 0.820713 validation: 0.851700
09/17 12:28:44 AM: edges-coref-ontonotes_f1: training: 0.821217 validation: 0.854465
09/17 12:28:44 AM: Global learning rate: 0.0001
09/17 12:28:44 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:28:49 AM: Update 1181: task edges-coref-ontonotes, batch 181 (1181): mcc: 0.7651, acc: 0.8703, precision: 0.8842, recall: 0.8804, f1: 0.8823, edges-coref-ontonotes_loss: 0.2923
09/17 12:28:59 AM: Update 1425: task edges-coref-ontonotes, batch 425 (1425): mcc: 0.7417, acc: 0.8584, precision: 0.8719, recall: 0.8695, f1: 0.8707, edges-coref-ontonotes_loss: 0.3096
09/17 12:29:09 AM: Update 1695: task edges-coref-ontonotes, batch 695 (1695): mcc: 0.7411, acc: 0.8585, precision: 0.8714, recall: 0.8694, f1: 0.8704, edges-coref-ontonotes_loss: 0.3091
09/17 12:29:20 AM: Update 1935: task edges-coref-ontonotes, batch 935 (1935): mcc: 0.7314, acc: 0.8525, precision: 0.8664, recall: 0.8648, f1: 0.8656, edges-coref-ontonotes_loss: 0.3190
09/17 12:29:22 AM: ***** Step 2000 / Validation 2 *****
09/17 12:29:22 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:29:22 AM: Validating...
09/17 12:29:28 AM: Best result seen so far for edges-coref-ontonotes.
09/17 12:29:28 AM: Best result seen so far for macro.
09/17 12:29:28 AM: Updating LR scheduler:
09/17 12:29:28 AM: 	Best result seen so far for macro_avg: 0.868
09/17 12:29:28 AM: 	# validation passes without improvement: 0
09/17 12:29:28 AM: edges-coref-ontonotes_loss: training: 0.318132 validation: 0.345843
09/17 12:29:28 AM: macro_avg: validation: 0.868074
09/17 12:29:28 AM: micro_avg: validation: 0.000000
09/17 12:29:28 AM: edges-coref-ontonotes_mcc: training: 0.731635 validation: 0.736331
09/17 12:29:28 AM: edges-coref-ontonotes_acc: training: 0.852821 validation: 0.866021
09/17 12:29:28 AM: edges-coref-ontonotes_precision: training: 0.866478 validation: 0.868673
09/17 12:29:28 AM: edges-coref-ontonotes_recall: training: 0.864915 validation: 0.867476
09/17 12:29:28 AM: edges-coref-ontonotes_f1: training: 0.865696 validation: 0.868074
09/17 12:29:28 AM: Global learning rate: 0.0001
09/17 12:29:28 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:29:30 AM: Update 2063: task edges-coref-ontonotes, batch 63 (2063): mcc: 0.7510, acc: 0.8668, precision: 0.8753, recall: 0.8758, f1: 0.8755, edges-coref-ontonotes_loss: 0.3009
09/17 12:29:40 AM: Update 2345: task edges-coref-ontonotes, batch 345 (2345): mcc: 0.7645, acc: 0.8728, precision: 0.8825, recall: 0.8819, f1: 0.8822, edges-coref-ontonotes_loss: 0.2757
09/17 12:29:51 AM: Update 2617: task edges-coref-ontonotes, batch 617 (2617): mcc: 0.7713, acc: 0.8765, precision: 0.8858, recall: 0.8855, f1: 0.8856, edges-coref-ontonotes_loss: 0.2644
09/17 12:30:02 AM: Update 2930: task edges-coref-ontonotes, batch 930 (2930): mcc: 0.7715, acc: 0.8769, precision: 0.8858, recall: 0.8856, f1: 0.8857, edges-coref-ontonotes_loss: 0.2646
09/17 12:30:04 AM: ***** Step 3000 / Validation 3 *****
09/17 12:30:04 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:30:04 AM: Validating...
09/17 12:30:09 AM: Best result seen so far for edges-coref-ontonotes.
09/17 12:30:09 AM: Best result seen so far for macro.
09/17 12:30:09 AM: Updating LR scheduler:
09/17 12:30:09 AM: 	Best result seen so far for macro_avg: 0.874
09/17 12:30:09 AM: 	# validation passes without improvement: 0
09/17 12:30:09 AM: edges-coref-ontonotes_loss: training: 0.269024 validation: 0.317687
09/17 12:30:09 AM: macro_avg: validation: 0.874274
09/17 12:30:09 AM: micro_avg: validation: 0.000000
09/17 12:30:09 AM: edges-coref-ontonotes_mcc: training: 0.767835 validation: 0.748931
09/17 12:30:09 AM: edges-coref-ontonotes_acc: training: 0.874885 validation: 0.871764
09/17 12:30:09 AM: edges-coref-ontonotes_precision: training: 0.884003 validation: 0.875600
09/17 12:30:09 AM: edges-coref-ontonotes_recall: training: 0.883807 validation: 0.872951
09/17 12:30:09 AM: edges-coref-ontonotes_f1: training: 0.883905 validation: 0.874274
09/17 12:30:09 AM: Global learning rate: 0.0001
09/17 12:30:09 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:30:12 AM: Update 3071: task edges-coref-ontonotes, batch 71 (3071): mcc: 0.6938, acc: 0.8343, precision: 0.8467, recall: 0.8472, f1: 0.8469, edges-coref-ontonotes_loss: 0.3465
09/17 12:30:22 AM: Update 3327: task edges-coref-ontonotes, batch 327 (3327): mcc: 0.7300, acc: 0.8540, precision: 0.8651, recall: 0.8648, f1: 0.8650, edges-coref-ontonotes_loss: 0.3131
09/17 12:30:32 AM: Update 3557: task edges-coref-ontonotes, batch 557 (3557): mcc: 0.7435, acc: 0.8619, precision: 0.8722, recall: 0.8712, f1: 0.8717, edges-coref-ontonotes_loss: 0.2967
09/17 12:30:42 AM: Update 3889: task edges-coref-ontonotes, batch 889 (3889): mcc: 0.7646, acc: 0.8736, precision: 0.8827, recall: 0.8818, f1: 0.8823, edges-coref-ontonotes_loss: 0.2657
09/17 12:30:47 AM: ***** Step 4000 / Validation 4 *****
09/17 12:30:47 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:30:47 AM: Validating...
09/17 12:30:52 AM: Evaluate: task edges-coref-ontonotes, batch 115 (157): mcc: 0.7445, acc: 0.8703, precision: 0.8726, recall: 0.8718, f1: 0.8722, edges-coref-ontonotes_loss: 0.3330
09/17 12:30:53 AM: Best result seen so far for edges-coref-ontonotes.
09/17 12:30:53 AM: Best result seen so far for macro.
09/17 12:30:53 AM: Updating LR scheduler:
09/17 12:30:53 AM: 	Best result seen so far for macro_avg: 0.876
09/17 12:30:53 AM: 	# validation passes without improvement: 0
09/17 12:30:53 AM: edges-coref-ontonotes_loss: training: 0.267305 validation: 0.313473
09/17 12:30:53 AM: macro_avg: validation: 0.876197
09/17 12:30:53 AM: micro_avg: validation: 0.000000
09/17 12:30:53 AM: edges-coref-ontonotes_mcc: training: 0.763397 validation: 0.752489
09/17 12:30:53 AM: edges-coref-ontonotes_acc: training: 0.872943 validation: 0.874636
09/17 12:30:53 AM: edges-coref-ontonotes_precision: training: 0.882040 validation: 0.876533
09/17 12:30:53 AM: edges-coref-ontonotes_recall: training: 0.881251 validation: 0.875862
09/17 12:30:53 AM: edges-coref-ontonotes_f1: training: 0.881645 validation: 0.876197
09/17 12:30:53 AM: Global learning rate: 0.0001
09/17 12:30:53 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:31:02 AM: Update 4238: task edges-coref-ontonotes, batch 238 (4238): mcc: 0.7869, acc: 0.8862, precision: 0.8931, recall: 0.8939, f1: 0.8935, edges-coref-ontonotes_loss: 0.2467
09/17 12:31:14 AM: Update 4551: task edges-coref-ontonotes, batch 551 (4551): mcc: 0.7520, acc: 0.8668, precision: 0.8759, recall: 0.8760, f1: 0.8760, edges-coref-ontonotes_loss: 0.2852
09/17 12:31:26 AM: Update 4864: task edges-coref-ontonotes, batch 864 (4864): mcc: 0.7576, acc: 0.8704, precision: 0.8788, recall: 0.8788, f1: 0.8788, edges-coref-ontonotes_loss: 0.2774
09/17 12:31:30 AM: ***** Step 5000 / Validation 5 *****
09/17 12:31:30 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:31:30 AM: Validating...
09/17 12:31:35 AM: Best result seen so far for edges-coref-ontonotes.
09/17 12:31:35 AM: Best result seen so far for macro.
09/17 12:31:35 AM: Updating LR scheduler:
09/17 12:31:35 AM: 	Best result seen so far for macro_avg: 0.877
09/17 12:31:35 AM: 	# validation passes without improvement: 0
09/17 12:31:35 AM: edges-coref-ontonotes_loss: training: 0.266045 validation: 0.302690
09/17 12:31:35 AM: macro_avg: validation: 0.876948
09/17 12:31:35 AM: micro_avg: validation: 0.000000
09/17 12:31:35 AM: edges-coref-ontonotes_mcc: training: 0.765021 validation: 0.753867
09/17 12:31:35 AM: edges-coref-ontonotes_acc: training: 0.874490 validation: 0.875287
09/17 12:31:35 AM: edges-coref-ontonotes_precision: training: 0.882501 validation: 0.876847
09/17 12:31:35 AM: edges-coref-ontonotes_recall: training: 0.882523 validation: 0.877049
09/17 12:31:35 AM: edges-coref-ontonotes_f1: training: 0.882512 validation: 0.876948
09/17 12:31:35 AM: Global learning rate: 0.0001
09/17 12:31:35 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:31:36 AM: Update 5029: task edges-coref-ontonotes, batch 29 (5029): mcc: 0.8454, acc: 0.9177, precision: 0.9227, recall: 0.9227, f1: 0.9227, edges-coref-ontonotes_loss: 0.1883
09/17 12:31:46 AM: Update 5304: task edges-coref-ontonotes, batch 304 (5304): mcc: 0.7885, acc: 0.8880, precision: 0.8947, recall: 0.8937, f1: 0.8942, edges-coref-ontonotes_loss: 0.2295
09/17 12:31:56 AM: Update 5580: task edges-coref-ontonotes, batch 580 (5580): mcc: 0.7834, acc: 0.8853, precision: 0.8919, recall: 0.8914, f1: 0.8917, edges-coref-ontonotes_loss: 0.2390
09/17 12:32:08 AM: Update 5859: task edges-coref-ontonotes, batch 859 (5859): mcc: 0.7680, acc: 0.8768, precision: 0.8842, recall: 0.8837, f1: 0.8840, edges-coref-ontonotes_loss: 0.2591
09/17 12:32:12 AM: ***** Step 6000 / Validation 6 *****
09/17 12:32:12 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:32:12 AM: Validating...
09/17 12:32:18 AM: Evaluate: task edges-coref-ontonotes, batch 153 (157): mcc: 0.7547, acc: 0.8754, precision: 0.8782, recall: 0.8761, f1: 0.8772, edges-coref-ontonotes_loss: 0.3025
09/17 12:32:18 AM: Updating LR scheduler:
09/17 12:32:18 AM: 	Best result seen so far for macro_avg: 0.877
09/17 12:32:18 AM: 	# validation passes without improvement: 1
09/17 12:32:18 AM: edges-coref-ontonotes_loss: training: 0.259957 validation: 0.305791
09/17 12:32:18 AM: macro_avg: validation: 0.876706
09/17 12:32:18 AM: micro_avg: validation: 0.000000
09/17 12:32:18 AM: edges-coref-ontonotes_mcc: training: 0.767900 validation: 0.753716
09/17 12:32:18 AM: edges-coref-ontonotes_acc: training: 0.876770 validation: 0.874866
09/17 12:32:18 AM: edges-coref-ontonotes_precision: training: 0.884146 validation: 0.877783
09/17 12:32:18 AM: edges-coref-ontonotes_recall: training: 0.883695 validation: 0.875632
09/17 12:32:18 AM: edges-coref-ontonotes_f1: training: 0.883920 validation: 0.876706
09/17 12:32:18 AM: Global learning rate: 0.0001
09/17 12:32:18 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:32:28 AM: Update 6253: task edges-coref-ontonotes, batch 253 (6253): mcc: 0.7831, acc: 0.8853, precision: 0.8918, recall: 0.8912, f1: 0.8915, edges-coref-ontonotes_loss: 0.2334
09/17 12:32:38 AM: Update 6541: task edges-coref-ontonotes, batch 541 (6541): mcc: 0.7951, acc: 0.8917, precision: 0.8978, recall: 0.8973, f1: 0.8975, edges-coref-ontonotes_loss: 0.2197
09/17 12:32:49 AM: Update 6854: task edges-coref-ontonotes, batch 854 (6854): mcc: 0.7936, acc: 0.8911, precision: 0.8971, recall: 0.8965, f1: 0.8968, edges-coref-ontonotes_loss: 0.2246
09/17 12:32:53 AM: ***** Step 7000 / Validation 7 *****
09/17 12:32:53 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:32:53 AM: Validating...
09/17 12:32:59 AM: Evaluate: task edges-coref-ontonotes, batch 153 (157): mcc: 0.7479, acc: 0.8720, precision: 0.8738, recall: 0.8742, f1: 0.8740, edges-coref-ontonotes_loss: 0.3018
09/17 12:32:59 AM: Updating LR scheduler:
09/17 12:32:59 AM: 	Best result seen so far for macro_avg: 0.877
09/17 12:32:59 AM: 	# validation passes without improvement: 2
09/17 12:32:59 AM: edges-coref-ontonotes_loss: training: 0.235397 validation: 0.304731
09/17 12:32:59 AM: macro_avg: validation: 0.873615
09/17 12:32:59 AM: micro_avg: validation: 0.000000
09/17 12:32:59 AM: edges-coref-ontonotes_mcc: training: 0.785128 validation: 0.747167
09/17 12:32:59 AM: edges-coref-ontonotes_acc: training: 0.886698 validation: 0.871611
09/17 12:32:59 AM: edges-coref-ontonotes_precision: training: 0.892801 validation: 0.873397
09/17 12:32:59 AM: edges-coref-ontonotes_recall: training: 0.892262 validation: 0.873832
09/17 12:32:59 AM: edges-coref-ontonotes_f1: training: 0.892531 validation: 0.873615
09/17 12:32:59 AM: Global learning rate: 0.0001
09/17 12:32:59 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:33:09 AM: Update 7243: task edges-coref-ontonotes, batch 243 (7243): mcc: 0.7469, acc: 0.8658, precision: 0.8732, recall: 0.8738, f1: 0.8735, edges-coref-ontonotes_loss: 0.2880
09/17 12:33:19 AM: Update 7529: task edges-coref-ontonotes, batch 529 (7529): mcc: 0.7635, acc: 0.8749, precision: 0.8817, recall: 0.8819, f1: 0.8818, edges-coref-ontonotes_loss: 0.2614
09/17 12:33:31 AM: Update 7849: task edges-coref-ontonotes, batch 849 (7849): mcc: 0.7789, acc: 0.8834, precision: 0.8895, recall: 0.8894, f1: 0.8895, edges-coref-ontonotes_loss: 0.2401
09/17 12:33:35 AM: ***** Step 8000 / Validation 8 *****
09/17 12:33:35 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:33:35 AM: Validating...
09/17 12:33:41 AM: Evaluate: task edges-coref-ontonotes, batch 153 (157): mcc: 0.7656, acc: 0.8811, precision: 0.8829, recall: 0.8827, f1: 0.8828, edges-coref-ontonotes_loss: 0.2885
09/17 12:33:41 AM: Best result seen so far for edges-coref-ontonotes.
09/17 12:33:41 AM: Best result seen so far for macro.
09/17 12:33:41 AM: Updating LR scheduler:
09/17 12:33:41 AM: 	Best result seen so far for macro_avg: 0.883
09/17 12:33:41 AM: 	# validation passes without improvement: 0
09/17 12:33:41 AM: edges-coref-ontonotes_loss: training: 0.239000 validation: 0.290601
09/17 12:33:41 AM: macro_avg: validation: 0.882570
09/17 12:33:41 AM: micro_avg: validation: 0.000000
09/17 12:33:41 AM: edges-coref-ontonotes_mcc: training: 0.780403 validation: 0.765163
09/17 12:33:41 AM: edges-coref-ontonotes_acc: training: 0.884208 validation: 0.880839
09/17 12:33:41 AM: edges-coref-ontonotes_precision: training: 0.890318 validation: 0.882655
09/17 12:33:41 AM: edges-coref-ontonotes_recall: training: 0.890051 validation: 0.882486
09/17 12:33:41 AM: edges-coref-ontonotes_f1: training: 0.890185 validation: 0.882570
09/17 12:33:41 AM: Global learning rate: 0.0001
09/17 12:33:41 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:33:51 AM: Update 8254: task edges-coref-ontonotes, batch 254 (8254): mcc: 0.7777, acc: 0.8830, precision: 0.8889, recall: 0.8887, f1: 0.8888, edges-coref-ontonotes_loss: 0.2524
09/17 12:34:01 AM: Update 8510: task edges-coref-ontonotes, batch 510 (8510): mcc: 0.7647, acc: 0.8762, precision: 0.8825, recall: 0.8822, f1: 0.8824, edges-coref-ontonotes_loss: 0.2672
09/17 12:34:11 AM: Update 8793: task edges-coref-ontonotes, batch 793 (8793): mcc: 0.7696, acc: 0.8790, precision: 0.8850, recall: 0.8846, f1: 0.8848, edges-coref-ontonotes_loss: 0.2595
09/17 12:34:16 AM: ***** Step 9000 / Validation 9 *****
09/17 12:34:16 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:34:16 AM: Validating...
09/17 12:34:21 AM: Evaluate: task edges-coref-ontonotes, batch 107 (157): mcc: 0.7574, acc: 0.8775, precision: 0.8790, recall: 0.8783, f1: 0.8787, edges-coref-ontonotes_loss: 0.3099
09/17 12:34:22 AM: Updating LR scheduler:
09/17 12:34:22 AM: 	Best result seen so far for macro_avg: 0.883
09/17 12:34:22 AM: 	# validation passes without improvement: 1
09/17 12:34:22 AM: edges-coref-ontonotes_loss: training: 0.243253 validation: 0.293157
09/17 12:34:22 AM: macro_avg: validation: 0.881334
09/17 12:34:22 AM: micro_avg: validation: 0.000000
09/17 12:34:22 AM: edges-coref-ontonotes_mcc: training: 0.783312 validation: 0.762751
09/17 12:34:22 AM: edges-coref-ontonotes_acc: training: 0.886148 validation: 0.880227
09/17 12:34:22 AM: edges-coref-ontonotes_precision: training: 0.891816 validation: 0.881638
09/17 12:34:22 AM: edges-coref-ontonotes_recall: training: 0.891451 validation: 0.881031
09/17 12:34:22 AM: edges-coref-ontonotes_f1: training: 0.891634 validation: 0.881334
09/17 12:34:22 AM: Global learning rate: 0.0001
09/17 12:34:22 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:34:31 AM: Update 9213: task edges-coref-ontonotes, batch 213 (9213): mcc: 0.7816, acc: 0.8859, precision: 0.8908, recall: 0.8908, f1: 0.8908, edges-coref-ontonotes_loss: 0.2218
09/17 12:34:41 AM: Update 9473: task edges-coref-ontonotes, batch 473 (9473): mcc: 0.7910, acc: 0.8907, precision: 0.8956, recall: 0.8954, f1: 0.8955, edges-coref-ontonotes_loss: 0.2243
09/17 12:34:51 AM: Update 9771: task edges-coref-ontonotes, batch 771 (9771): mcc: 0.7742, acc: 0.8816, precision: 0.8872, recall: 0.8870, f1: 0.8871, edges-coref-ontonotes_loss: 0.2480
09/17 12:35:01 AM: ***** Step 10000 / Validation 10 *****
09/17 12:35:01 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:35:01 AM: Validating...
09/17 12:35:01 AM: Evaluate: task edges-coref-ontonotes, batch 4 (157): mcc: 0.7653, acc: 0.8817, precision: 0.8833, recall: 0.8817, f1: 0.8825, edges-coref-ontonotes_loss: 0.3499
09/17 12:35:07 AM: Updating LR scheduler:
09/17 12:35:07 AM: 	Best result seen so far for macro_avg: 0.883
09/17 12:35:07 AM: 	# validation passes without improvement: 2
09/17 12:35:07 AM: edges-coref-ontonotes_loss: training: 0.246371 validation: 0.294318
09/17 12:35:07 AM: macro_avg: validation: 0.880221
09/17 12:35:07 AM: micro_avg: validation: 0.000000
09/17 12:35:07 AM: edges-coref-ontonotes_mcc: training: 0.776746 validation: 0.760377
09/17 12:35:07 AM: edges-coref-ontonotes_acc: training: 0.882932 validation: 0.878657
09/17 12:35:07 AM: edges-coref-ontonotes_precision: training: 0.888393 validation: 0.879985
09/17 12:35:07 AM: edges-coref-ontonotes_recall: training: 0.888348 validation: 0.880456
09/17 12:35:07 AM: edges-coref-ontonotes_f1: training: 0.888370 validation: 0.880221
09/17 12:35:07 AM: Global learning rate: 0.0001
09/17 12:35:07 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:35:12 AM: Update 10096: task edges-coref-ontonotes, batch 96 (10096): mcc: 0.7637, acc: 0.8769, precision: 0.8820, recall: 0.8816, f1: 0.8818, edges-coref-ontonotes_loss: 0.2560
09/17 12:35:22 AM: Update 10425: task edges-coref-ontonotes, batch 425 (10425): mcc: 0.8053, acc: 0.8987, precision: 0.9029, recall: 0.9023, f1: 0.9026, edges-coref-ontonotes_loss: 0.2014
09/17 12:35:32 AM: Update 10695: task edges-coref-ontonotes, batch 695 (10695): mcc: 0.7977, acc: 0.8949, precision: 0.8991, recall: 0.8985, f1: 0.8988, edges-coref-ontonotes_loss: 0.2144
09/17 12:35:42 AM: Update 10943: task edges-coref-ontonotes, batch 943 (10943): mcc: 0.7910, acc: 0.8914, precision: 0.8957, recall: 0.8953, f1: 0.8955, edges-coref-ontonotes_loss: 0.2255
09/17 12:35:44 AM: ***** Step 11000 / Validation 11 *****
09/17 12:35:44 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:35:44 AM: Validating...
09/17 12:35:50 AM: Updating LR scheduler:
09/17 12:35:50 AM: 	Best result seen so far for macro_avg: 0.883
09/17 12:35:50 AM: 	# validation passes without improvement: 3
09/17 12:35:50 AM: edges-coref-ontonotes_loss: training: 0.228824 validation: 0.291283
09/17 12:35:50 AM: macro_avg: validation: 0.881270
09/17 12:35:50 AM: micro_avg: validation: 0.000000
09/17 12:35:50 AM: edges-coref-ontonotes_mcc: training: 0.789190 validation: 0.762521
09/17 12:35:50 AM: edges-coref-ontonotes_acc: training: 0.890376 validation: 0.880227
09/17 12:35:50 AM: edges-coref-ontonotes_precision: training: 0.894786 validation: 0.881202
09/17 12:35:50 AM: edges-coref-ontonotes_recall: training: 0.894353 validation: 0.881337
09/17 12:35:50 AM: edges-coref-ontonotes_f1: training: 0.894570 validation: 0.881270
09/17 12:35:50 AM: Global learning rate: 0.0001
09/17 12:35:50 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:35:52 AM: Update 11079: task edges-coref-ontonotes, batch 79 (11079): mcc: 0.7553, acc: 0.8718, precision: 0.8781, recall: 0.8770, f1: 0.8776, edges-coref-ontonotes_loss: 0.2722
09/17 12:36:02 AM: Update 11304: task edges-coref-ontonotes, batch 304 (11304): mcc: 0.7773, acc: 0.8839, precision: 0.8891, recall: 0.8881, f1: 0.8886, edges-coref-ontonotes_loss: 0.2510
09/17 12:36:12 AM: Update 11587: task edges-coref-ontonotes, batch 587 (11587): mcc: 0.7921, acc: 0.8917, precision: 0.8962, recall: 0.8958, f1: 0.8960, edges-coref-ontonotes_loss: 0.2263
09/17 12:36:22 AM: Update 11810: task edges-coref-ontonotes, batch 810 (11810): mcc: 0.7922, acc: 0.8918, precision: 0.8963, recall: 0.8958, f1: 0.8961, edges-coref-ontonotes_loss: 0.2231
09/17 12:36:27 AM: ***** Step 12000 / Validation 12 *****
09/17 12:36:27 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:36:27 AM: Validating...
09/17 12:36:32 AM: Evaluate: task edges-coref-ontonotes, batch 130 (157): mcc: 0.7654, acc: 0.8815, precision: 0.8831, recall: 0.8822, f1: 0.8826, edges-coref-ontonotes_loss: 0.3033
09/17 12:36:33 AM: Best result seen so far for edges-coref-ontonotes.
09/17 12:36:33 AM: Best result seen so far for macro.
09/17 12:36:33 AM: Updating LR scheduler:
09/17 12:36:33 AM: 	Best result seen so far for macro_avg: 0.883
09/17 12:36:33 AM: 	# validation passes without improvement: 0
09/17 12:36:33 AM: edges-coref-ontonotes_loss: training: 0.219071 validation: 0.293354
09/17 12:36:33 AM: macro_avg: validation: 0.882883
09/17 12:36:33 AM: micro_avg: validation: 0.000000
09/17 12:36:33 AM: edges-coref-ontonotes_mcc: training: 0.795470 validation: 0.765891
09/17 12:36:33 AM: edges-coref-ontonotes_acc: training: 0.893591 validation: 0.881643
09/17 12:36:33 AM: edges-coref-ontonotes_precision: training: 0.897937 validation: 0.883356
09/17 12:36:33 AM: edges-coref-ontonotes_recall: training: 0.897481 validation: 0.882409
09/17 12:36:33 AM: edges-coref-ontonotes_f1: training: 0.897709 validation: 0.882883
09/17 12:36:33 AM: Global learning rate: 0.0001
09/17 12:36:33 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:36:42 AM: Update 12215: task edges-coref-ontonotes, batch 215 (12215): mcc: 0.7754, acc: 0.8831, precision: 0.8876, recall: 0.8878, f1: 0.8877, edges-coref-ontonotes_loss: 0.2613
09/17 12:36:52 AM: Update 12457: task edges-coref-ontonotes, batch 457 (12457): mcc: 0.7665, acc: 0.8784, precision: 0.8834, recall: 0.8830, f1: 0.8832, edges-coref-ontonotes_loss: 0.2646
09/17 12:37:02 AM: Update 12712: task edges-coref-ontonotes, batch 712 (12712): mcc: 0.7731, acc: 0.8819, precision: 0.8867, recall: 0.8863, f1: 0.8865, edges-coref-ontonotes_loss: 0.2557
09/17 12:37:11 AM: ***** Step 13000 / Validation 13 *****
09/17 12:37:11 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:37:11 AM: Validating...
09/17 12:37:12 AM: Evaluate: task edges-coref-ontonotes, batch 46 (157): mcc: 0.7957, acc: 0.8965, precision: 0.8985, recall: 0.8970, f1: 0.8978, edges-coref-ontonotes_loss: 0.2623
09/17 12:37:16 AM: Best result seen so far for edges-coref-ontonotes.
09/17 12:37:16 AM: Best result seen so far for macro.
09/17 12:37:16 AM: Updating LR scheduler:
09/17 12:37:16 AM: 	Best result seen so far for macro_avg: 0.886
09/17 12:37:16 AM: 	# validation passes without improvement: 0
09/17 12:37:16 AM: edges-coref-ontonotes_loss: training: 0.232437 validation: 0.287216
09/17 12:37:16 AM: macro_avg: validation: 0.886258
09/17 12:37:16 AM: micro_avg: validation: 0.000000
09/17 12:37:16 AM: edges-coref-ontonotes_mcc: training: 0.787771 validation: 0.772630
09/17 12:37:16 AM: edges-coref-ontonotes_acc: training: 0.889654 validation: 0.885358
09/17 12:37:16 AM: edges-coref-ontonotes_precision: training: 0.894049 validation: 0.886700
09/17 12:37:16 AM: edges-coref-ontonotes_recall: training: 0.893678 validation: 0.885817
09/17 12:37:16 AM: edges-coref-ontonotes_f1: training: 0.893863 validation: 0.886258
09/17 12:37:16 AM: Global learning rate: 0.0001
09/17 12:37:16 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:37:22 AM: Update 13132: task edges-coref-ontonotes, batch 132 (13132): mcc: 0.7780, acc: 0.8850, precision: 0.8890, recall: 0.8889, f1: 0.8890, edges-coref-ontonotes_loss: 0.2406
09/17 12:37:32 AM: Update 13402: task edges-coref-ontonotes, batch 402 (13402): mcc: 0.7955, acc: 0.8945, precision: 0.8979, recall: 0.8976, f1: 0.8977, edges-coref-ontonotes_loss: 0.2226
09/17 12:37:42 AM: Update 13699: task edges-coref-ontonotes, batch 699 (13699): mcc: 0.7798, acc: 0.8860, precision: 0.8901, recall: 0.8896, f1: 0.8899, edges-coref-ontonotes_loss: 0.2447
09/17 12:37:52 AM: Update 13931: task edges-coref-ontonotes, batch 931 (13931): mcc: 0.7809, acc: 0.8866, precision: 0.8906, recall: 0.8902, f1: 0.8904, edges-coref-ontonotes_loss: 0.2430
09/17 12:37:55 AM: ***** Step 14000 / Validation 14 *****
09/17 12:37:55 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:37:55 AM: Validating...
09/17 12:38:01 AM: Updating LR scheduler:
09/17 12:38:01 AM: 	Best result seen so far for macro_avg: 0.886
09/17 12:38:01 AM: 	# validation passes without improvement: 1
09/17 12:38:01 AM: edges-coref-ontonotes_loss: training: 0.242650 validation: 0.292248
09/17 12:38:01 AM: macro_avg: validation: 0.880493
09/17 12:38:01 AM: micro_avg: validation: 0.000000
09/17 12:38:01 AM: edges-coref-ontonotes_mcc: training: 0.781272 validation: 0.761028
09/17 12:38:01 AM: edges-coref-ontonotes_acc: training: 0.886791 validation: 0.879193
09/17 12:38:01 AM: edges-coref-ontonotes_precision: training: 0.890861 validation: 0.880645
09/17 12:38:01 AM: edges-coref-ontonotes_recall: training: 0.890348 validation: 0.880342
09/17 12:38:01 AM: edges-coref-ontonotes_f1: training: 0.890604 validation: 0.880493
09/17 12:38:01 AM: Global learning rate: 0.0001
09/17 12:38:01 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:38:03 AM: Update 14020: task edges-coref-ontonotes, batch 20 (14020): mcc: 0.7659, acc: 0.8784, precision: 0.8827, recall: 0.8833, f1: 0.8830, edges-coref-ontonotes_loss: 0.2167
09/17 12:38:14 AM: Update 14333: task edges-coref-ontonotes, batch 333 (14333): mcc: 0.8250, acc: 0.9095, precision: 0.9127, recall: 0.9123, f1: 0.9125, edges-coref-ontonotes_loss: 0.1746
09/17 12:38:24 AM: Update 14583: task edges-coref-ontonotes, batch 583 (14583): mcc: 0.8090, acc: 0.9011, precision: 0.9047, recall: 0.9042, f1: 0.9044, edges-coref-ontonotes_loss: 0.1987
09/17 12:38:34 AM: Update 14841: task edges-coref-ontonotes, batch 841 (14841): mcc: 0.8003, acc: 0.8966, precision: 0.9003, recall: 0.9000, f1: 0.9002, edges-coref-ontonotes_loss: 0.2120
09/17 12:38:39 AM: ***** Step 15000 / Validation 15 *****
09/17 12:38:39 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:38:39 AM: Validating...
09/17 12:38:44 AM: Evaluate: task edges-coref-ontonotes, batch 135 (157): mcc: 0.7635, acc: 0.8805, precision: 0.8819, recall: 0.8815, f1: 0.8817, edges-coref-ontonotes_loss: 0.2915
09/17 12:38:44 AM: Updating LR scheduler:
09/17 12:38:44 AM: 	Best result seen so far for macro_avg: 0.886
09/17 12:38:44 AM: 	# validation passes without improvement: 2
09/17 12:38:44 AM: edges-coref-ontonotes_loss: training: 0.221339 validation: 0.289129
09/17 12:38:44 AM: macro_avg: validation: 0.881003
09/17 12:38:44 AM: micro_avg: validation: 0.000000
09/17 12:38:44 AM: edges-coref-ontonotes_mcc: training: 0.793890 validation: 0.762062
09/17 12:38:44 AM: edges-coref-ontonotes_acc: training: 0.893242 validation: 0.879767
09/17 12:38:44 AM: edges-coref-ontonotes_precision: training: 0.897006 validation: 0.881206
09/17 12:38:44 AM: edges-coref-ontonotes_recall: training: 0.896868 validation: 0.880801
09/17 12:38:44 AM: edges-coref-ontonotes_f1: training: 0.896937 validation: 0.881003
09/17 12:38:44 AM: Global learning rate: 0.0001
09/17 12:38:44 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:38:54 AM: Update 15219: task edges-coref-ontonotes, batch 219 (15219): mcc: 0.7866, acc: 0.8894, precision: 0.8929, recall: 0.8937, f1: 0.8933, edges-coref-ontonotes_loss: 0.2364
09/17 12:39:04 AM: Update 15498: task edges-coref-ontonotes, batch 498 (15498): mcc: 0.7961, acc: 0.8945, precision: 0.8981, recall: 0.8980, f1: 0.8980, edges-coref-ontonotes_loss: 0.2176
09/17 12:39:14 AM: Update 15756: task edges-coref-ontonotes, batch 756 (15756): mcc: 0.8010, acc: 0.8971, precision: 0.9005, recall: 0.9004, f1: 0.9005, edges-coref-ontonotes_loss: 0.2124
09/17 12:39:21 AM: ***** Step 16000 / Validation 16 *****
09/17 12:39:21 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:39:21 AM: Validating...
09/17 12:39:24 AM: Evaluate: task edges-coref-ontonotes, batch 79 (157): mcc: 0.7707, acc: 0.8848, precision: 0.8853, recall: 0.8854, f1: 0.8853, edges-coref-ontonotes_loss: 0.3032
09/17 12:39:27 AM: Updating LR scheduler:
09/17 12:39:27 AM: 	Best result seen so far for macro_avg: 0.886
09/17 12:39:27 AM: 	# validation passes without improvement: 3
09/17 12:39:27 AM: edges-coref-ontonotes_loss: training: 0.209707 validation: 0.293026
09/17 12:39:27 AM: macro_avg: validation: 0.885533
09/17 12:39:27 AM: micro_avg: validation: 0.000000
09/17 12:39:27 AM: edges-coref-ontonotes_mcc: training: 0.804287 validation: 0.771022
09/17 12:39:27 AM: edges-coref-ontonotes_acc: training: 0.898880 validation: 0.884745
09/17 12:39:27 AM: edges-coref-ontonotes_precision: training: 0.902207 validation: 0.885363
09/17 12:39:27 AM: edges-coref-ontonotes_recall: training: 0.902064 validation: 0.885702
09/17 12:39:27 AM: edges-coref-ontonotes_f1: training: 0.902136 validation: 0.885533
09/17 12:39:27 AM: Global learning rate: 0.0001
09/17 12:39:27 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:39:34 AM: Update 16165: task edges-coref-ontonotes, batch 165 (16165): mcc: 0.7690, acc: 0.8805, precision: 0.8849, recall: 0.8840, f1: 0.8845, edges-coref-ontonotes_loss: 0.2630
09/17 12:39:44 AM: Update 16414: task edges-coref-ontonotes, batch 414 (16414): mcc: 0.7700, acc: 0.8811, precision: 0.8852, recall: 0.8847, f1: 0.8850, edges-coref-ontonotes_loss: 0.2596
09/17 12:39:54 AM: Update 16673: task edges-coref-ontonotes, batch 673 (16673): mcc: 0.7785, acc: 0.8857, precision: 0.8894, recall: 0.8891, f1: 0.8892, edges-coref-ontonotes_loss: 0.2454
09/17 12:40:04 AM: ***** Step 17000 / Validation 17 *****
09/17 12:40:04 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:40:04 AM: Validating...
09/17 12:40:04 AM: Evaluate: task edges-coref-ontonotes, batch 10 (157): mcc: 0.8124, acc: 0.9054, precision: 0.9068, recall: 0.9054, f1: 0.9061, edges-coref-ontonotes_loss: 0.2560
09/17 12:40:09 AM: Best result seen so far for edges-coref-ontonotes.
09/17 12:40:09 AM: Best result seen so far for macro.
09/17 12:40:09 AM: Updating LR scheduler:
09/17 12:40:09 AM: 	Best result seen so far for macro_avg: 0.888
09/17 12:40:09 AM: 	# validation passes without improvement: 0
09/17 12:40:09 AM: edges-coref-ontonotes_loss: training: 0.224599 validation: 0.277546
09/17 12:40:09 AM: macro_avg: validation: 0.887885
09/17 12:40:09 AM: micro_avg: validation: 0.000000
09/17 12:40:09 AM: edges-coref-ontonotes_mcc: training: 0.792324 validation: 0.775808
09/17 12:40:09 AM: edges-coref-ontonotes_acc: training: 0.892883 validation: 0.886774
09/17 12:40:09 AM: edges-coref-ontonotes_precision: training: 0.896230 validation: 0.888038
09/17 12:40:09 AM: edges-coref-ontonotes_recall: training: 0.896077 validation: 0.887732
09/17 12:40:09 AM: edges-coref-ontonotes_f1: training: 0.896153 validation: 0.887885
09/17 12:40:09 AM: Global learning rate: 0.0001
09/17 12:40:09 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:40:14 AM: Update 17102: task edges-coref-ontonotes, batch 102 (17102): mcc: 0.8114, acc: 0.9026, precision: 0.9059, recall: 0.9054, f1: 0.9057, edges-coref-ontonotes_loss: 0.1971
09/17 12:40:24 AM: Update 17347: task edges-coref-ontonotes, batch 347 (17347): mcc: 0.8011, acc: 0.8977, precision: 0.9010, recall: 0.9000, f1: 0.9005, edges-coref-ontonotes_loss: 0.2138
09/17 12:40:34 AM: Update 17631: task edges-coref-ontonotes, batch 631 (17631): mcc: 0.7854, acc: 0.8895, precision: 0.8931, recall: 0.8922, f1: 0.8926, edges-coref-ontonotes_loss: 0.2371
09/17 12:40:46 AM: Update 17944: task edges-coref-ontonotes, batch 944 (17944): mcc: 0.7860, acc: 0.8898, precision: 0.8933, recall: 0.8926, f1: 0.8929, edges-coref-ontonotes_loss: 0.2356
09/17 12:40:48 AM: ***** Step 18000 / Validation 18 *****
09/17 12:40:48 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:40:48 AM: Validating...
09/17 12:40:54 AM: Updating LR scheduler:
09/17 12:40:54 AM: 	Best result seen so far for macro_avg: 0.888
09/17 12:40:54 AM: 	# validation passes without improvement: 1
09/17 12:40:54 AM: edges-coref-ontonotes_loss: training: 0.232894 validation: 0.283382
09/17 12:40:54 AM: macro_avg: validation: 0.887838
09/17 12:40:54 AM: micro_avg: validation: 0.000000
09/17 12:40:54 AM: edges-coref-ontonotes_mcc: training: 0.786867 validation: 0.775731
09/17 12:40:54 AM: edges-coref-ontonotes_acc: training: 0.890281 validation: 0.887157
09/17 12:40:54 AM: edges-coref-ontonotes_precision: training: 0.893722 validation: 0.888059
09/17 12:40:54 AM: edges-coref-ontonotes_recall: training: 0.893067 validation: 0.887617
09/17 12:40:54 AM: edges-coref-ontonotes_f1: training: 0.893395 validation: 0.887838
09/17 12:40:54 AM: Global learning rate: 0.0001
09/17 12:40:54 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:40:56 AM: Update 18095: task edges-coref-ontonotes, batch 95 (18095): mcc: 0.8481, acc: 0.9215, precision: 0.9240, recall: 0.9241, f1: 0.9240, edges-coref-ontonotes_loss: 0.1605
09/17 12:41:06 AM: Update 18382: task edges-coref-ontonotes, batch 382 (18382): mcc: 0.8221, acc: 0.9085, precision: 0.9110, recall: 0.9111, f1: 0.9111, edges-coref-ontonotes_loss: 0.1856
09/17 12:41:16 AM: Update 18645: task edges-coref-ontonotes, batch 645 (18645): mcc: 0.8173, acc: 0.9060, precision: 0.9086, recall: 0.9087, f1: 0.9087, edges-coref-ontonotes_loss: 0.1937
09/17 12:41:27 AM: Update 18939: task edges-coref-ontonotes, batch 939 (18939): mcc: 0.8013, acc: 0.8977, precision: 0.9006, recall: 0.9007, f1: 0.9007, edges-coref-ontonotes_loss: 0.2156
09/17 12:41:29 AM: ***** Step 19000 / Validation 19 *****
09/17 12:41:29 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:41:29 AM: Validating...
09/17 12:41:35 AM: Updating LR scheduler:
09/17 12:41:35 AM: 	Best result seen so far for macro_avg: 0.888
09/17 12:41:35 AM: 	# validation passes without improvement: 2
09/17 12:41:35 AM: edges-coref-ontonotes_loss: training: 0.215289 validation: 0.295459
09/17 12:41:35 AM: macro_avg: validation: 0.882811
09/17 12:41:35 AM: micro_avg: validation: 0.000000
09/17 12:41:35 AM: edges-coref-ontonotes_mcc: training: 0.801511 validation: 0.765699
09/17 12:41:35 AM: edges-coref-ontonotes_acc: training: 0.897770 validation: 0.882180
09/17 12:41:35 AM: edges-coref-ontonotes_precision: training: 0.900755 validation: 0.883099
09/17 12:41:35 AM: edges-coref-ontonotes_recall: training: 0.900755 validation: 0.882524
09/17 12:41:35 AM: edges-coref-ontonotes_f1: training: 0.900755 validation: 0.882811
09/17 12:41:35 AM: Global learning rate: 0.0001
09/17 12:41:35 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:41:37 AM: Update 19079: task edges-coref-ontonotes, batch 79 (19079): mcc: 0.7905, acc: 0.8915, precision: 0.8950, recall: 0.8955, f1: 0.8953, edges-coref-ontonotes_loss: 0.2341
09/17 12:41:47 AM: Update 19338: task edges-coref-ontonotes, batch 338 (19338): mcc: 0.8021, acc: 0.8981, precision: 0.9011, recall: 0.9010, f1: 0.9011, edges-coref-ontonotes_loss: 0.2137
09/17 12:41:58 AM: Update 19621: task edges-coref-ontonotes, batch 621 (19621): mcc: 0.8085, acc: 0.9015, precision: 0.9043, recall: 0.9043, f1: 0.9043, edges-coref-ontonotes_loss: 0.2031
09/17 12:42:09 AM: Update 19934: task edges-coref-ontonotes, batch 934 (19934): mcc: 0.8096, acc: 0.9022, precision: 0.9048, recall: 0.9047, f1: 0.9048, edges-coref-ontonotes_loss: 0.2028
09/17 12:42:11 AM: ***** Step 20000 / Validation 20 *****
09/17 12:42:11 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:42:11 AM: Validating...
09/17 12:42:17 AM: Updating LR scheduler:
09/17 12:42:17 AM: 	Best result seen so far for macro_avg: 0.888
09/17 12:42:17 AM: 	# validation passes without improvement: 3
09/17 12:42:17 AM: edges-coref-ontonotes_loss: training: 0.206981 validation: 0.281039
09/17 12:42:17 AM: macro_avg: validation: 0.886970
09/17 12:42:17 AM: micro_avg: validation: 0.000000
09/17 12:42:17 AM: edges-coref-ontonotes_mcc: training: 0.807062 validation: 0.774008
09/17 12:42:17 AM: edges-coref-ontonotes_acc: training: 0.900849 validation: 0.886430
09/17 12:42:17 AM: edges-coref-ontonotes_precision: training: 0.903595 validation: 0.887241
09/17 12:42:17 AM: edges-coref-ontonotes_recall: training: 0.903452 validation: 0.886698
09/17 12:42:17 AM: edges-coref-ontonotes_f1: training: 0.903523 validation: 0.886970
09/17 12:42:17 AM: Global learning rate: 0.0001
09/17 12:42:17 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:42:19 AM: Update 20077: task edges-coref-ontonotes, batch 77 (20077): mcc: 0.7764, acc: 0.8856, precision: 0.8881, recall: 0.8883, f1: 0.8882, edges-coref-ontonotes_loss: 0.2559
09/17 12:42:29 AM: Update 20325: task edges-coref-ontonotes, batch 325 (20325): mcc: 0.7738, acc: 0.8841, precision: 0.8868, recall: 0.8870, f1: 0.8869, edges-coref-ontonotes_loss: 0.2538
09/17 12:42:39 AM: Update 20587: task edges-coref-ontonotes, batch 587 (20587): mcc: 0.7834, acc: 0.8889, precision: 0.8916, recall: 0.8918, f1: 0.8917, edges-coref-ontonotes_loss: 0.2393
09/17 12:42:51 AM: Update 20929: task edges-coref-ontonotes, batch 929 (20929): mcc: 0.7976, acc: 0.8962, precision: 0.8987, recall: 0.8989, f1: 0.8988, edges-coref-ontonotes_loss: 0.2176
09/17 12:42:53 AM: ***** Step 21000 / Validation 21 *****
09/17 12:42:53 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:42:53 AM: Validating...
09/17 12:42:59 AM: Best result seen so far for edges-coref-ontonotes.
09/17 12:42:59 AM: Best result seen so far for macro.
09/17 12:42:59 AM: Updating LR scheduler:
09/17 12:42:59 AM: 	Best result seen so far for macro_avg: 0.890
09/17 12:42:59 AM: 	# validation passes without improvement: 0
09/17 12:42:59 AM: edges-coref-ontonotes_loss: training: 0.216868 validation: 0.281542
09/17 12:42:59 AM: macro_avg: validation: 0.889961
09/17 12:42:59 AM: micro_avg: validation: 0.000000
09/17 12:42:59 AM: edges-coref-ontonotes_mcc: training: 0.798222 validation: 0.779943
09/17 12:42:59 AM: edges-coref-ontonotes_acc: training: 0.896531 validation: 0.889302
09/17 12:42:59 AM: edges-coref-ontonotes_precision: training: 0.899073 validation: 0.890046
09/17 12:42:59 AM: edges-coref-ontonotes_recall: training: 0.899158 validation: 0.889876
09/17 12:42:59 AM: edges-coref-ontonotes_f1: training: 0.899116 validation: 0.889961
09/17 12:42:59 AM: Global learning rate: 0.0001
09/17 12:42:59 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:43:01 AM: Update 21076: task edges-coref-ontonotes, batch 76 (21076): mcc: 0.8143, acc: 0.9051, precision: 0.9072, recall: 0.9072, f1: 0.9072, edges-coref-ontonotes_loss: 0.1871
09/17 12:43:11 AM: Update 21335: task edges-coref-ontonotes, batch 335 (21335): mcc: 0.8012, acc: 0.8980, precision: 0.9007, recall: 0.9005, f1: 0.9006, edges-coref-ontonotes_loss: 0.2177
09/17 12:43:21 AM: Update 21592: task edges-coref-ontonotes, batch 592 (21592): mcc: 0.7908, acc: 0.8927, precision: 0.8955, recall: 0.8952, f1: 0.8954, edges-coref-ontonotes_loss: 0.2322
09/17 12:43:31 AM: Update 21874: task edges-coref-ontonotes, batch 874 (21874): mcc: 0.7917, acc: 0.8932, precision: 0.8959, recall: 0.8957, f1: 0.8958, edges-coref-ontonotes_loss: 0.2297
09/17 12:43:34 AM: ***** Step 22000 / Validation 22 *****
09/17 12:43:34 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:43:34 AM: Validating...
09/17 12:43:41 AM: Updating LR scheduler:
09/17 12:43:41 AM: 	Best result seen so far for macro_avg: 0.890
09/17 12:43:41 AM: 	# validation passes without improvement: 1
09/17 12:43:41 AM: edges-coref-ontonotes_loss: training: 0.220564 validation: 0.278657
09/17 12:43:41 AM: macro_avg: validation: 0.889621
09/17 12:43:41 AM: micro_avg: validation: 0.000000
09/17 12:43:41 AM: edges-coref-ontonotes_mcc: training: 0.798036 validation: 0.779216
09/17 12:43:41 AM: edges-coref-ontonotes_acc: training: 0.896471 validation: 0.888804
09/17 12:43:41 AM: edges-coref-ontonotes_precision: training: 0.899080 validation: 0.889518
09/17 12:43:41 AM: edges-coref-ontonotes_recall: training: 0.898940 validation: 0.889723
09/17 12:43:41 AM: edges-coref-ontonotes_f1: training: 0.899010 validation: 0.889621
09/17 12:43:41 AM: Global learning rate: 0.0001
09/17 12:43:41 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:43:41 AM: Update 22024: task edges-coref-ontonotes, batch 24 (22024): mcc: 0.8892, acc: 0.9437, precision: 0.9446, recall: 0.9446, f1: 0.9446, edges-coref-ontonotes_loss: 0.1272
09/17 12:43:51 AM: Update 22283: task edges-coref-ontonotes, batch 283 (22283): mcc: 0.8127, acc: 0.9041, precision: 0.9066, recall: 0.9061, f1: 0.9063, edges-coref-ontonotes_loss: 0.1943
09/17 12:44:02 AM: Update 22550: task edges-coref-ontonotes, batch 550 (22550): mcc: 0.8140, acc: 0.9048, precision: 0.9073, recall: 0.9066, f1: 0.9070, edges-coref-ontonotes_loss: 0.1945
09/17 12:44:12 AM: Update 22848: task edges-coref-ontonotes, batch 848 (22848): mcc: 0.8008, acc: 0.8980, precision: 0.9006, recall: 0.9002, f1: 0.9004, edges-coref-ontonotes_loss: 0.2156
09/17 12:44:18 AM: ***** Step 23000 / Validation 23 *****
09/17 12:44:18 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:44:18 AM: Validating...
09/17 12:44:22 AM: Evaluate: task edges-coref-ontonotes, batch 90 (157): mcc: 0.7664, acc: 0.8825, precision: 0.8836, recall: 0.8827, f1: 0.8831, edges-coref-ontonotes_loss: 0.3043
09/17 12:44:24 AM: Updating LR scheduler:
09/17 12:44:24 AM: 	Best result seen so far for macro_avg: 0.890
09/17 12:44:24 AM: 	# validation passes without improvement: 2
09/17 12:44:24 AM: edges-coref-ontonotes_loss: training: 0.218262 validation: 0.283450
09/17 12:44:24 AM: macro_avg: validation: 0.887088
09/17 12:44:24 AM: micro_avg: validation: 0.000000
09/17 12:44:24 AM: edges-coref-ontonotes_mcc: training: 0.799493 validation: 0.774277
09/17 12:44:24 AM: edges-coref-ontonotes_acc: training: 0.897378 validation: 0.886468
09/17 12:44:24 AM: edges-coref-ontonotes_precision: training: 0.899889 validation: 0.887479
09/17 12:44:24 AM: edges-coref-ontonotes_recall: training: 0.899568 validation: 0.886698
09/17 12:44:24 AM: edges-coref-ontonotes_f1: training: 0.899729 validation: 0.887088
09/17 12:44:24 AM: Global learning rate: 0.0001
09/17 12:44:24 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:44:32 AM: Update 23177: task edges-coref-ontonotes, batch 177 (23177): mcc: 0.7869, acc: 0.8909, precision: 0.8936, recall: 0.8933, f1: 0.8935, edges-coref-ontonotes_loss: 0.2268
09/17 12:44:42 AM: Update 23506: task edges-coref-ontonotes, batch 506 (23506): mcc: 0.8192, acc: 0.9075, precision: 0.9097, recall: 0.9095, f1: 0.9096, edges-coref-ontonotes_loss: 0.1871
09/17 12:44:52 AM: Update 23775: task edges-coref-ontonotes, batch 775 (23775): mcc: 0.8153, acc: 0.9055, precision: 0.9078, recall: 0.9076, f1: 0.9077, edges-coref-ontonotes_loss: 0.1941
09/17 12:45:01 AM: ***** Step 24000 / Validation 24 *****
09/17 12:45:01 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:45:01 AM: Validating...
09/17 12:45:02 AM: Evaluate: task edges-coref-ontonotes, batch 20 (157): mcc: 0.8125, acc: 0.9055, precision: 0.9059, recall: 0.9066, f1: 0.9063, edges-coref-ontonotes_loss: 0.2578
09/17 12:45:07 AM: Updating LR scheduler:
09/17 12:45:07 AM: 	Best result seen so far for macro_avg: 0.890
09/17 12:45:07 AM: 	# validation passes without improvement: 3
09/17 12:45:07 AM: edges-coref-ontonotes_loss: training: 0.203771 validation: 0.282075
09/17 12:45:07 AM: macro_avg: validation: 0.886570
09/17 12:45:07 AM: micro_avg: validation: 0.000000
09/17 12:45:07 AM: edges-coref-ontonotes_mcc: training: 0.809773 validation: 0.773166
09/17 12:45:07 AM: edges-coref-ontonotes_acc: training: 0.902746 validation: 0.885932
09/17 12:45:07 AM: edges-coref-ontonotes_precision: training: 0.904971 validation: 0.886672
09/17 12:45:07 AM: edges-coref-ontonotes_recall: training: 0.904782 validation: 0.886468
09/17 12:45:07 AM: edges-coref-ontonotes_f1: training: 0.904877 validation: 0.886570
09/17 12:45:07 AM: Global learning rate: 0.0001
09/17 12:45:07 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:45:12 AM: Update 24142: task edges-coref-ontonotes, batch 142 (24142): mcc: 0.7792, acc: 0.8871, precision: 0.8897, recall: 0.8894, f1: 0.8896, edges-coref-ontonotes_loss: 0.2513
09/17 12:45:22 AM: Update 24402: task edges-coref-ontonotes, batch 402 (24402): mcc: 0.7891, acc: 0.8922, precision: 0.8945, recall: 0.8946, f1: 0.8946, edges-coref-ontonotes_loss: 0.2367
09/17 12:45:32 AM: Update 24670: task edges-coref-ontonotes, batch 670 (24670): mcc: 0.8008, acc: 0.8982, precision: 0.9003, recall: 0.9004, f1: 0.9004, edges-coref-ontonotes_loss: 0.2143
09/17 12:45:42 AM: Update 24955: task edges-coref-ontonotes, batch 955 (24955): mcc: 0.8046, acc: 0.9001, precision: 0.9023, recall: 0.9023, f1: 0.9023, edges-coref-ontonotes_loss: 0.2079
09/17 12:45:43 AM: ***** Step 25000 / Validation 25 *****
09/17 12:45:43 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:45:43 AM: Validating...
09/17 12:45:49 AM: Updating LR scheduler:
09/17 12:45:49 AM: 	Best result seen so far for macro_avg: 0.890
09/17 12:45:49 AM: 	# validation passes without improvement: 0
09/17 12:45:49 AM: edges-coref-ontonotes_loss: training: 0.207050 validation: 0.279717
09/17 12:45:49 AM: macro_avg: validation: 0.889684
09/17 12:45:49 AM: micro_avg: validation: 0.000000
09/17 12:45:49 AM: edges-coref-ontonotes_mcc: training: 0.805164 validation: 0.779369
09/17 12:45:49 AM: edges-coref-ontonotes_acc: training: 0.900466 validation: 0.889110
09/17 12:45:49 AM: edges-coref-ontonotes_precision: training: 0.902551 validation: 0.889684
09/17 12:45:49 AM: edges-coref-ontonotes_recall: training: 0.902620 validation: 0.889684
09/17 12:45:49 AM: edges-coref-ontonotes_f1: training: 0.902586 validation: 0.889684
09/17 12:45:49 AM: Global learning rate: 5e-05
09/17 12:45:49 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:45:52 AM: Update 25099: task edges-coref-ontonotes, batch 99 (25099): mcc: 0.8186, acc: 0.9074, precision: 0.9095, recall: 0.9091, f1: 0.9093, edges-coref-ontonotes_loss: 0.1948
09/17 12:46:02 AM: Update 25347: task edges-coref-ontonotes, batch 347 (25347): mcc: 0.8000, acc: 0.8976, precision: 0.9000, recall: 0.9000, f1: 0.9000, edges-coref-ontonotes_loss: 0.2243
09/17 12:46:12 AM: Update 25595: task edges-coref-ontonotes, batch 595 (25595): mcc: 0.7949, acc: 0.8952, precision: 0.8974, recall: 0.8976, f1: 0.8975, edges-coref-ontonotes_loss: 0.2286
09/17 12:46:22 AM: Update 25869: task edges-coref-ontonotes, batch 869 (25869): mcc: 0.7970, acc: 0.8962, precision: 0.8985, recall: 0.8985, f1: 0.8985, edges-coref-ontonotes_loss: 0.2213
09/17 12:46:25 AM: ***** Step 26000 / Validation 26 *****
09/17 12:46:25 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:46:25 AM: Validating...
09/17 12:46:32 AM: Best result seen so far for edges-coref-ontonotes.
09/17 12:46:32 AM: Best result seen so far for macro.
09/17 12:46:32 AM: Updating LR scheduler:
09/17 12:46:32 AM: 	Best result seen so far for macro_avg: 0.891
09/17 12:46:32 AM: 	# validation passes without improvement: 0
09/17 12:46:32 AM: edges-coref-ontonotes_loss: training: 0.212553 validation: 0.281182
09/17 12:46:32 AM: macro_avg: validation: 0.890697
09/17 12:46:32 AM: micro_avg: validation: 0.000000
09/17 12:46:32 AM: edges-coref-ontonotes_mcc: training: 0.802480 validation: 0.781360
09/17 12:46:32 AM: edges-coref-ontonotes_acc: training: 0.899030 validation: 0.890259
09/17 12:46:32 AM: edges-coref-ontonotes_precision: training: 0.901227 validation: 0.890560
09/17 12:46:32 AM: edges-coref-ontonotes_recall: training: 0.901256 validation: 0.890833
09/17 12:46:32 AM: edges-coref-ontonotes_f1: training: 0.901241 validation: 0.890697
09/17 12:46:32 AM: Global learning rate: 5e-05
09/17 12:46:32 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:46:32 AM: Update 26007: task edges-coref-ontonotes, batch 7 (26007): mcc: 0.8690, acc: 0.9340, precision: 0.9350, recall: 0.9340, f1: 0.9345, edges-coref-ontonotes_loss: 0.1560
09/17 12:46:42 AM: Update 26273: task edges-coref-ontonotes, batch 273 (26273): mcc: 0.8219, acc: 0.9095, precision: 0.9110, recall: 0.9110, f1: 0.9110, edges-coref-ontonotes_loss: 0.1892
09/17 12:46:52 AM: Update 26513: task edges-coref-ontonotes, batch 513 (26513): mcc: 0.8150, acc: 0.9058, precision: 0.9076, recall: 0.9075, f1: 0.9075, edges-coref-ontonotes_loss: 0.1971
09/17 12:47:03 AM: Update 26787: task edges-coref-ontonotes, batch 787 (26787): mcc: 0.8032, acc: 0.8998, precision: 0.9016, recall: 0.9015, f1: 0.9016, edges-coref-ontonotes_loss: 0.2140
09/17 12:47:10 AM: ***** Step 27000 / Validation 27 *****
09/17 12:47:10 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:47:10 AM: Validating...
09/17 12:47:13 AM: Evaluate: task edges-coref-ontonotes, batch 92 (157): mcc: 0.7658, acc: 0.8824, precision: 0.8829, recall: 0.8828, f1: 0.8829, edges-coref-ontonotes_loss: 0.3031
09/17 12:47:15 AM: Updating LR scheduler:
09/17 12:47:15 AM: 	Best result seen so far for macro_avg: 0.891
09/17 12:47:15 AM: 	# validation passes without improvement: 1
09/17 12:47:15 AM: edges-coref-ontonotes_loss: training: 0.215274 validation: 0.284345
09/17 12:47:15 AM: macro_avg: validation: 0.886012
09/17 12:47:15 AM: micro_avg: validation: 0.000000
09/17 12:47:15 AM: edges-coref-ontonotes_mcc: training: 0.802050 validation: 0.772055
09/17 12:47:15 AM: edges-coref-ontonotes_acc: training: 0.899219 validation: 0.885549
09/17 12:47:15 AM: edges-coref-ontonotes_precision: training: 0.901008 validation: 0.886131
09/17 12:47:15 AM: edges-coref-ontonotes_recall: training: 0.901047 validation: 0.885894
09/17 12:47:15 AM: edges-coref-ontonotes_f1: training: 0.901027 validation: 0.886012
09/17 12:47:15 AM: Global learning rate: 5e-05
09/17 12:47:15 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:47:23 AM: Update 27189: task edges-coref-ontonotes, batch 189 (27189): mcc: 0.8114, acc: 0.9036, precision: 0.9056, recall: 0.9058, f1: 0.9057, edges-coref-ontonotes_loss: 0.1974
09/17 12:47:33 AM: Update 27470: task edges-coref-ontonotes, batch 470 (27470): mcc: 0.8211, acc: 0.9088, precision: 0.9104, recall: 0.9107, f1: 0.9105, edges-coref-ontonotes_loss: 0.1826
09/17 12:47:44 AM: Update 27782: task edges-coref-ontonotes, batch 782 (27782): mcc: 0.8224, acc: 0.9095, precision: 0.9111, recall: 0.9112, f1: 0.9112, edges-coref-ontonotes_loss: 0.1851
09/17 12:47:51 AM: ***** Step 28000 / Validation 28 *****
09/17 12:47:51 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:47:51 AM: Validating...
09/17 12:47:54 AM: Evaluate: task edges-coref-ontonotes, batch 91 (157): mcc: 0.7714, acc: 0.8854, precision: 0.8855, recall: 0.8859, f1: 0.8857, edges-coref-ontonotes_loss: 0.2951
09/17 12:47:56 AM: Updating LR scheduler:
09/17 12:47:56 AM: 	Best result seen so far for macro_avg: 0.891
09/17 12:47:56 AM: 	# validation passes without improvement: 2
09/17 12:47:56 AM: edges-coref-ontonotes_loss: training: 0.199001 validation: 0.278775
09/17 12:47:56 AM: macro_avg: validation: 0.888714
09/17 12:47:56 AM: micro_avg: validation: 0.000000
09/17 12:47:56 AM: edges-coref-ontonotes_mcc: training: 0.812054 validation: 0.777378
09/17 12:47:56 AM: edges-coref-ontonotes_acc: training: 0.904145 validation: 0.888268
09/17 12:47:56 AM: edges-coref-ontonotes_precision: training: 0.906024 validation: 0.888510
09/17 12:47:56 AM: edges-coref-ontonotes_recall: training: 0.906030 validation: 0.888919
09/17 12:47:56 AM: edges-coref-ontonotes_f1: training: 0.906027 validation: 0.888714
09/17 12:47:56 AM: Global learning rate: 5e-05
09/17 12:47:57 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:48:04 AM: Update 28186: task edges-coref-ontonotes, batch 186 (28186): mcc: 0.7934, acc: 0.8945, precision: 0.8968, recall: 0.8966, f1: 0.8967, edges-coref-ontonotes_loss: 0.2298
09/17 12:48:14 AM: Update 28439: task edges-coref-ontonotes, batch 439 (28439): mcc: 0.7975, acc: 0.8966, precision: 0.8989, recall: 0.8985, f1: 0.8987, edges-coref-ontonotes_loss: 0.2202
09/17 12:48:24 AM: Update 28760: task edges-coref-ontonotes, batch 760 (28760): mcc: 0.8137, acc: 0.9050, precision: 0.9070, recall: 0.9067, f1: 0.9069, edges-coref-ontonotes_loss: 0.1972
09/17 12:48:34 AM: ***** Step 29000 / Validation 29 *****
09/17 12:48:34 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:48:34 AM: Validating...
09/17 12:48:34 AM: Evaluate: task edges-coref-ontonotes, batch 13 (157): mcc: 0.8138, acc: 0.9066, precision: 0.9071, recall: 0.9066, f1: 0.9069, edges-coref-ontonotes_loss: 0.2564
09/17 12:48:40 AM: Updating LR scheduler:
09/17 12:48:40 AM: 	Best result seen so far for macro_avg: 0.891
09/17 12:48:40 AM: 	# validation passes without improvement: 3
09/17 12:48:40 AM: edges-coref-ontonotes_loss: training: 0.196051 validation: 0.280001
09/17 12:48:40 AM: macro_avg: validation: 0.890638
09/17 12:48:40 AM: micro_avg: validation: 0.000000
09/17 12:48:40 AM: edges-coref-ontonotes_mcc: training: 0.814987 validation: 0.781284
09/17 12:48:40 AM: edges-coref-ontonotes_acc: training: 0.905681 validation: 0.890297
09/17 12:48:40 AM: edges-coref-ontonotes_precision: training: 0.907613 validation: 0.890672
09/17 12:48:40 AM: edges-coref-ontonotes_recall: training: 0.907347 validation: 0.890603
09/17 12:48:40 AM: edges-coref-ontonotes_f1: training: 0.907480 validation: 0.890638
09/17 12:48:40 AM: Global learning rate: 5e-05
09/17 12:48:40 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:48:45 AM: Update 29090: task edges-coref-ontonotes, batch 90 (29090): mcc: 0.8153, acc: 0.9059, precision: 0.9079, recall: 0.9073, f1: 0.9076, edges-coref-ontonotes_loss: 0.1920
09/17 12:48:55 AM: Update 29385: task edges-coref-ontonotes, batch 385 (29385): mcc: 0.7903, acc: 0.8933, precision: 0.8953, recall: 0.8950, f1: 0.8951, edges-coref-ontonotes_loss: 0.2326
09/17 12:49:05 AM: Update 29620: task edges-coref-ontonotes, batch 620 (29620): mcc: 0.7949, acc: 0.8954, precision: 0.8976, recall: 0.8973, f1: 0.8975, edges-coref-ontonotes_loss: 0.2273
09/17 12:49:15 AM: Update 29886: task edges-coref-ontonotes, batch 886 (29886): mcc: 0.8020, acc: 0.8990, precision: 0.9011, recall: 0.9008, f1: 0.9010, edges-coref-ontonotes_loss: 0.2142
09/17 12:49:18 AM: ***** Step 30000 / Validation 30 *****
09/17 12:49:18 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:49:18 AM: Validating...
09/17 12:49:24 AM: Updating LR scheduler:
09/17 12:49:24 AM: 	Best result seen so far for macro_avg: 0.891
09/17 12:49:24 AM: 	# validation passes without improvement: 0
09/17 12:49:24 AM: edges-coref-ontonotes_loss: training: 0.207108 validation: 0.282146
09/17 12:49:24 AM: macro_avg: validation: 0.889867
09/17 12:49:24 AM: micro_avg: validation: 0.000000
09/17 12:49:24 AM: edges-coref-ontonotes_mcc: training: 0.805944 validation: 0.779752
09/17 12:49:24 AM: edges-coref-ontonotes_acc: training: 0.901093 validation: 0.889493
09/17 12:49:24 AM: edges-coref-ontonotes_precision: training: 0.903103 validation: 0.889936
09/17 12:49:24 AM: edges-coref-ontonotes_recall: training: 0.902810 validation: 0.889799
09/17 12:49:24 AM: edges-coref-ontonotes_f1: training: 0.902956 validation: 0.889867
09/17 12:49:24 AM: Global learning rate: 2.5e-05
09/17 12:49:24 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:49:25 AM: Update 30029: task edges-coref-ontonotes, batch 29 (30029): mcc: 0.8322, acc: 0.9146, precision: 0.9160, recall: 0.9162, f1: 0.9161, edges-coref-ontonotes_loss: 0.1622
09/17 12:49:35 AM: Update 30304: task edges-coref-ontonotes, batch 304 (30304): mcc: 0.8105, acc: 0.9038, precision: 0.9054, recall: 0.9051, f1: 0.9052, edges-coref-ontonotes_loss: 0.2001
09/17 12:49:45 AM: Update 30555: task edges-coref-ontonotes, batch 555 (30555): mcc: 0.8070, acc: 0.9019, precision: 0.9035, recall: 0.9035, f1: 0.9035, edges-coref-ontonotes_loss: 0.2084
09/17 12:49:55 AM: Update 30792: task edges-coref-ontonotes, batch 792 (30792): mcc: 0.8007, acc: 0.8986, precision: 0.9004, recall: 0.9003, f1: 0.9004, edges-coref-ontonotes_loss: 0.2193
09/17 12:50:01 AM: ***** Step 31000 / Validation 31 *****
09/17 12:50:01 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:50:01 AM: Validating...
09/17 12:50:05 AM: Evaluate: task edges-coref-ontonotes, batch 102 (157): mcc: 0.7654, acc: 0.8821, precision: 0.8831, recall: 0.8822, f1: 0.8826, edges-coref-ontonotes_loss: 0.2988
09/17 12:50:07 AM: Updating LR scheduler:
09/17 12:50:07 AM: 	Best result seen so far for macro_avg: 0.891
09/17 12:50:07 AM: 	# validation passes without improvement: 1
09/17 12:50:07 AM: edges-coref-ontonotes_loss: training: 0.218090 validation: 0.280944
09/17 12:50:07 AM: macro_avg: validation: 0.886774
09/17 12:50:07 AM: micro_avg: validation: 0.000000
09/17 12:50:07 AM: edges-coref-ontonotes_mcc: training: 0.801253 validation: 0.773626
09/17 12:50:07 AM: edges-coref-ontonotes_acc: training: 0.898820 validation: 0.886315
09/17 12:50:07 AM: edges-coref-ontonotes_precision: training: 0.900661 validation: 0.887079
09/17 12:50:07 AM: edges-coref-ontonotes_recall: training: 0.900583 validation: 0.886468
09/17 12:50:07 AM: edges-coref-ontonotes_f1: training: 0.900622 validation: 0.886774
09/17 12:50:07 AM: Global learning rate: 2.5e-05
09/17 12:50:07 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:50:15 AM: Update 31215: task edges-coref-ontonotes, batch 215 (31215): mcc: 0.8381, acc: 0.9174, precision: 0.9190, recall: 0.9192, f1: 0.9191, edges-coref-ontonotes_loss: 0.1608
09/17 12:50:25 AM: Update 31479: task edges-coref-ontonotes, batch 479 (31479): mcc: 0.8260, acc: 0.9115, precision: 0.9129, recall: 0.9131, f1: 0.9130, edges-coref-ontonotes_loss: 0.1757
09/17 12:50:35 AM: Update 31747: task edges-coref-ontonotes, batch 747 (31747): mcc: 0.8215, acc: 0.9093, precision: 0.9107, recall: 0.9109, f1: 0.9108, edges-coref-ontonotes_loss: 0.1844
09/17 12:50:43 AM: ***** Step 32000 / Validation 32 *****
09/17 12:50:43 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:50:43 AM: Validating...
09/17 12:50:45 AM: Evaluate: task edges-coref-ontonotes, batch 57 (157): mcc: 0.7917, acc: 0.8953, precision: 0.8956, recall: 0.8961, f1: 0.8959, edges-coref-ontonotes_loss: 0.2695
09/17 12:50:49 AM: Updating LR scheduler:
09/17 12:50:49 AM: 	Best result seen so far for macro_avg: 0.891
09/17 12:50:49 AM: 	# validation passes without improvement: 2
09/17 12:50:49 AM: edges-coref-ontonotes_loss: training: 0.198663 validation: 0.275795
09/17 12:50:49 AM: macro_avg: validation: 0.888863
09/17 12:50:49 AM: micro_avg: validation: 0.000000
09/17 12:50:49 AM: edges-coref-ontonotes_mcc: training: 0.812417 validation: 0.777722
09/17 12:50:49 AM: edges-coref-ontonotes_acc: training: 0.904539 validation: 0.888421
09/17 12:50:49 AM: edges-coref-ontonotes_precision: training: 0.906159 validation: 0.888846
09/17 12:50:49 AM: edges-coref-ontonotes_recall: training: 0.906269 validation: 0.888880
09/17 12:50:49 AM: edges-coref-ontonotes_f1: training: 0.906214 validation: 0.888863
09/17 12:50:49 AM: Global learning rate: 2.5e-05
09/17 12:50:49 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:50:55 AM: Update 32140: task edges-coref-ontonotes, batch 140 (32140): mcc: 0.7919, acc: 0.8939, precision: 0.8961, recall: 0.8957, f1: 0.8959, edges-coref-ontonotes_loss: 0.2279
09/17 12:51:05 AM: Update 32405: task edges-coref-ontonotes, batch 405 (32405): mcc: 0.8005, acc: 0.8983, precision: 0.9004, recall: 0.9001, f1: 0.9002, edges-coref-ontonotes_loss: 0.2095
09/17 12:51:16 AM: Update 32701: task edges-coref-ontonotes, batch 701 (32701): mcc: 0.8150, acc: 0.9056, precision: 0.9075, recall: 0.9074, f1: 0.9075, edges-coref-ontonotes_loss: 0.1924
09/17 12:51:25 AM: ***** Step 33000 / Validation 33 *****
09/17 12:51:25 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:51:25 AM: Validating...
09/17 12:51:26 AM: Evaluate: task edges-coref-ontonotes, batch 28 (157): mcc: 0.8279, acc: 0.9136, precision: 0.9139, recall: 0.9141, f1: 0.9140, edges-coref-ontonotes_loss: 0.2395
09/17 12:51:30 AM: Updating LR scheduler:
09/17 12:51:30 AM: 	Best result seen so far for macro_avg: 0.891
09/17 12:51:30 AM: 	# validation passes without improvement: 3
09/17 12:51:30 AM: edges-coref-ontonotes_loss: training: 0.190757 validation: 0.279469
09/17 12:51:30 AM: macro_avg: validation: 0.890522
09/17 12:51:30 AM: micro_avg: validation: 0.000000
09/17 12:51:30 AM: edges-coref-ontonotes_mcc: training: 0.817562 validation: 0.781015
09/17 12:51:30 AM: edges-coref-ontonotes_acc: training: 0.906963 validation: 0.890259
09/17 12:51:30 AM: edges-coref-ontonotes_precision: training: 0.908755 validation: 0.890403
09/17 12:51:30 AM: edges-coref-ontonotes_recall: training: 0.908812 validation: 0.890642
09/17 12:51:30 AM: edges-coref-ontonotes_f1: training: 0.908784 validation: 0.890522
09/17 12:51:30 AM: Global learning rate: 2.5e-05
09/17 12:51:30 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:51:36 AM: Update 33097: task edges-coref-ontonotes, batch 97 (33097): mcc: 0.7918, acc: 0.8938, precision: 0.8960, recall: 0.8957, f1: 0.8959, edges-coref-ontonotes_loss: 0.2363
09/17 12:51:46 AM: Update 33328: task edges-coref-ontonotes, batch 328 (33328): mcc: 0.7864, acc: 0.8909, precision: 0.8933, recall: 0.8931, f1: 0.8932, edges-coref-ontonotes_loss: 0.2399
09/17 12:51:57 AM: Update 33640: task edges-coref-ontonotes, batch 640 (33640): mcc: 0.7945, acc: 0.8951, precision: 0.8972, recall: 0.8972, f1: 0.8972, edges-coref-ontonotes_loss: 0.2288
09/17 12:52:07 AM: Update 33984: task edges-coref-ontonotes, batch 984 (33984): mcc: 0.8075, acc: 0.9018, precision: 0.9038, recall: 0.9037, f1: 0.9037, edges-coref-ontonotes_loss: 0.2068
09/17 12:52:08 AM: ***** Step 34000 / Validation 34 *****
09/17 12:52:08 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:52:08 AM: Validating...
09/17 12:52:14 AM: Updating LR scheduler:
09/17 12:52:14 AM: 	Best result seen so far for macro_avg: 0.891
09/17 12:52:14 AM: 	# validation passes without improvement: 0
09/17 12:52:14 AM: edges-coref-ontonotes_loss: training: 0.207587 validation: 0.275775
09/17 12:52:14 AM: macro_avg: validation: 0.889144
09/17 12:52:14 AM: micro_avg: validation: 0.000000
09/17 12:52:14 AM: edges-coref-ontonotes_mcc: training: 0.806588 validation: 0.778297
09/17 12:52:14 AM: edges-coref-ontonotes_acc: training: 0.901374 validation: 0.888727
09/17 12:52:14 AM: edges-coref-ontonotes_precision: training: 0.903330 validation: 0.889178
09/17 12:52:14 AM: edges-coref-ontonotes_recall: training: 0.903250 validation: 0.889110
09/17 12:52:14 AM: edges-coref-ontonotes_f1: training: 0.903290 validation: 0.889144
09/17 12:52:14 AM: Global learning rate: 1.25e-05
09/17 12:52:14 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:52:17 AM: Update 34060: task edges-coref-ontonotes, batch 60 (34060): mcc: 0.8137, acc: 0.9053, precision: 0.9068, recall: 0.9070, f1: 0.9069, edges-coref-ontonotes_loss: 0.1871
09/17 12:52:27 AM: Update 34334: task edges-coref-ontonotes, batch 334 (34334): mcc: 0.8185, acc: 0.9077, precision: 0.9093, recall: 0.9092, f1: 0.9092, edges-coref-ontonotes_loss: 0.1913
09/17 12:52:39 AM: Update 34635: task edges-coref-ontonotes, batch 635 (34635): mcc: 0.8031, acc: 0.8998, precision: 0.9017, recall: 0.9015, f1: 0.9016, edges-coref-ontonotes_loss: 0.2148
09/17 12:52:49 AM: Update 34946: task edges-coref-ontonotes, batch 946 (34946): mcc: 0.8029, acc: 0.8996, precision: 0.9015, recall: 0.9014, f1: 0.9014, edges-coref-ontonotes_loss: 0.2156
09/17 12:52:52 AM: ***** Step 35000 / Validation 35 *****
09/17 12:52:52 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:52:52 AM: Validating...
09/17 12:52:58 AM: Updating LR scheduler:
09/17 12:52:58 AM: 	Best result seen so far for macro_avg: 0.891
09/17 12:52:58 AM: 	# validation passes without improvement: 1
09/17 12:52:58 AM: edges-coref-ontonotes_loss: training: 0.213114 validation: 0.278663
09/17 12:52:58 AM: macro_avg: validation: 0.889910
09/17 12:52:58 AM: micro_avg: validation: 0.000000
09/17 12:52:58 AM: edges-coref-ontonotes_mcc: training: 0.803202 validation: 0.779828
09/17 12:52:58 AM: edges-coref-ontonotes_acc: training: 0.899742 validation: 0.889608
09/17 12:52:58 AM: edges-coref-ontonotes_precision: training: 0.901651 validation: 0.889944
09/17 12:52:58 AM: edges-coref-ontonotes_recall: training: 0.901539 validation: 0.889876
09/17 12:52:58 AM: edges-coref-ontonotes_f1: training: 0.901595 validation: 0.889910
09/17 12:52:58 AM: Global learning rate: 1.25e-05
09/17 12:52:58 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:52:59 AM: Update 35037: task edges-coref-ontonotes, batch 37 (35037): mcc: 0.8251, acc: 0.9110, precision: 0.9125, recall: 0.9126, f1: 0.9125, edges-coref-ontonotes_loss: 0.1609
09/17 12:53:09 AM: Update 35317: task edges-coref-ontonotes, batch 317 (35317): mcc: 0.8303, acc: 0.9137, precision: 0.9151, recall: 0.9153, f1: 0.9152, edges-coref-ontonotes_loss: 0.1704
09/17 12:53:20 AM: Update 35630: task edges-coref-ontonotes, batch 630 (35630): mcc: 0.8259, acc: 0.9115, precision: 0.9129, recall: 0.9130, f1: 0.9130, edges-coref-ontonotes_loss: 0.1783
09/17 12:53:32 AM: Update 35943: task edges-coref-ontonotes, batch 943 (35943): mcc: 0.8129, acc: 0.9048, precision: 0.9064, recall: 0.9065, f1: 0.9065, edges-coref-ontonotes_loss: 0.1993
09/17 12:53:34 AM: ***** Step 36000 / Validation 36 *****
09/17 12:53:34 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:53:34 AM: Validating...
09/17 12:53:40 AM: Best result seen so far for edges-coref-ontonotes.
09/17 12:53:40 AM: Best result seen so far for macro.
09/17 12:53:40 AM: Updating LR scheduler:
09/17 12:53:40 AM: 	Best result seen so far for macro_avg: 0.891
09/17 12:53:40 AM: 	# validation passes without improvement: 0
09/17 12:53:40 AM: edges-coref-ontonotes_loss: training: 0.200321 validation: 0.274865
09/17 12:53:40 AM: macro_avg: validation: 0.890978
09/17 12:53:40 AM: micro_avg: validation: 0.000000
09/17 12:53:40 AM: edges-coref-ontonotes_mcc: training: 0.812304 validation: 0.781934
09/17 12:53:40 AM: edges-coref-ontonotes_acc: training: 0.904483 validation: 0.890680
09/17 12:53:40 AM: edges-coref-ontonotes_precision: training: 0.906152 validation: 0.890892
09/17 12:53:40 AM: edges-coref-ontonotes_recall: training: 0.906152 validation: 0.891063
09/17 12:53:40 AM: edges-coref-ontonotes_f1: training: 0.906152 validation: 0.890978
09/17 12:53:40 AM: Global learning rate: 1.25e-05
09/17 12:53:40 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:53:42 AM: Update 36057: task edges-coref-ontonotes, batch 57 (36057): mcc: 0.8063, acc: 0.9015, precision: 0.9029, recall: 0.9035, f1: 0.9032, edges-coref-ontonotes_loss: 0.2137
09/17 12:53:52 AM: Update 36324: task edges-coref-ontonotes, batch 324 (36324): mcc: 0.8036, acc: 0.9000, precision: 0.9019, recall: 0.9017, f1: 0.9018, edges-coref-ontonotes_loss: 0.2074
09/17 12:54:02 AM: Update 36625: task edges-coref-ontonotes, batch 625 (36625): mcc: 0.8174, acc: 0.9071, precision: 0.9087, recall: 0.9087, f1: 0.9087, edges-coref-ontonotes_loss: 0.1898
09/17 12:54:13 AM: Update 36938: task edges-coref-ontonotes, batch 938 (36938): mcc: 0.8184, acc: 0.9077, precision: 0.9092, recall: 0.9092, f1: 0.9092, edges-coref-ontonotes_loss: 0.1888
09/17 12:54:15 AM: ***** Step 37000 / Validation 37 *****
09/17 12:54:15 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:54:15 AM: Validating...
09/17 12:54:20 AM: Best result seen so far for edges-coref-ontonotes.
09/17 12:54:20 AM: Best result seen so far for macro.
09/17 12:54:20 AM: Updating LR scheduler:
09/17 12:54:20 AM: 	Best result seen so far for macro_avg: 0.892
09/17 12:54:20 AM: 	# validation passes without improvement: 0
09/17 12:54:20 AM: edges-coref-ontonotes_loss: training: 0.192084 validation: 0.275693
09/17 12:54:20 AM: macro_avg: validation: 0.891528
09/17 12:54:20 AM: micro_avg: validation: 0.000000
09/17 12:54:20 AM: edges-coref-ontonotes_mcc: training: 0.815964 validation: 0.783122
09/17 12:54:20 AM: edges-coref-ontonotes_acc: training: 0.906436 validation: 0.891140
09/17 12:54:20 AM: edges-coref-ontonotes_precision: training: 0.907959 validation: 0.891801
09/17 12:54:20 AM: edges-coref-ontonotes_recall: training: 0.908011 validation: 0.891254
09/17 12:54:20 AM: edges-coref-ontonotes_f1: training: 0.907985 validation: 0.891528
09/17 12:54:20 AM: Global learning rate: 1.25e-05
09/17 12:54:20 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:54:23 AM: Update 37095: task edges-coref-ontonotes, batch 95 (37095): mcc: 0.7924, acc: 0.8943, precision: 0.8965, recall: 0.8958, f1: 0.8962, edges-coref-ontonotes_loss: 0.2330
09/17 12:54:33 AM: Update 37360: task edges-coref-ontonotes, batch 360 (37360): mcc: 0.7911, acc: 0.8937, precision: 0.8957, recall: 0.8953, f1: 0.8955, edges-coref-ontonotes_loss: 0.2335
09/17 12:54:43 AM: Update 37666: task edges-coref-ontonotes, batch 666 (37666): mcc: 0.8014, acc: 0.8990, precision: 0.9008, recall: 0.9006, f1: 0.9007, edges-coref-ontonotes_loss: 0.2189
09/17 12:54:53 AM: Update 37942: task edges-coref-ontonotes, batch 942 (37942): mcc: 0.8066, acc: 0.9016, precision: 0.9034, recall: 0.9032, f1: 0.9033, edges-coref-ontonotes_loss: 0.2050
09/17 12:54:55 AM: ***** Step 38000 / Validation 38 *****
09/17 12:54:55 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:54:55 AM: Validating...
09/17 12:55:00 AM: Updating LR scheduler:
09/17 12:55:00 AM: 	Best result seen so far for macro_avg: 0.892
09/17 12:55:00 AM: 	# validation passes without improvement: 1
09/17 12:55:00 AM: edges-coref-ontonotes_loss: training: 0.203385 validation: 0.276322
09/17 12:55:00 AM: macro_avg: validation: 0.891097
09/17 12:55:00 AM: micro_avg: validation: 0.000000
09/17 12:55:00 AM: edges-coref-ontonotes_mcc: training: 0.808371 validation: 0.782202
09/17 12:55:00 AM: edges-coref-ontonotes_acc: training: 0.902545 validation: 0.890757
09/17 12:55:00 AM: edges-coref-ontonotes_precision: training: 0.904292 validation: 0.891131
09/17 12:55:00 AM: edges-coref-ontonotes_recall: training: 0.904054 validation: 0.891063
09/17 12:55:00 AM: edges-coref-ontonotes_f1: training: 0.904173 validation: 0.891097
09/17 12:55:00 AM: Global learning rate: 1.25e-05
09/17 12:55:00 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:55:03 AM: Update 38118: task edges-coref-ontonotes, batch 118 (38118): mcc: 0.8388, acc: 0.9179, precision: 0.9192, recall: 0.9197, f1: 0.9194, edges-coref-ontonotes_loss: 0.1810
09/17 12:55:13 AM: Update 38380: task edges-coref-ontonotes, batch 380 (38380): mcc: 0.8069, acc: 0.9018, precision: 0.9034, recall: 0.9034, f1: 0.9034, edges-coref-ontonotes_loss: 0.2074
09/17 12:55:23 AM: Update 38643: task edges-coref-ontonotes, batch 643 (38643): mcc: 0.7981, acc: 0.8972, precision: 0.8991, recall: 0.8991, f1: 0.8991, edges-coref-ontonotes_loss: 0.2198
09/17 12:55:33 AM: Update 38926: task edges-coref-ontonotes, batch 926 (38926): mcc: 0.8018, acc: 0.8990, precision: 0.9009, recall: 0.9008, f1: 0.9009, edges-coref-ontonotes_loss: 0.2153
09/17 12:55:35 AM: ***** Step 39000 / Validation 39 *****
09/17 12:55:35 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:55:35 AM: Validating...
09/17 12:55:41 AM: Updating LR scheduler:
09/17 12:55:41 AM: 	Best result seen so far for macro_avg: 0.892
09/17 12:55:41 AM: 	# validation passes without improvement: 2
09/17 12:55:41 AM: edges-coref-ontonotes_loss: training: 0.211402 validation: 0.276577
09/17 12:55:41 AM: macro_avg: validation: 0.890331
09/17 12:55:41 AM: micro_avg: validation: 0.000000
09/17 12:55:41 AM: edges-coref-ontonotes_mcc: training: 0.804994 validation: 0.780671
09/17 12:55:41 AM: edges-coref-ontonotes_acc: training: 0.900613 validation: 0.889876
09/17 12:55:41 AM: edges-coref-ontonotes_precision: training: 0.902557 validation: 0.890365
09/17 12:55:41 AM: edges-coref-ontonotes_recall: training: 0.902423 validation: 0.890297
09/17 12:55:41 AM: edges-coref-ontonotes_f1: training: 0.902490 validation: 0.890331
09/17 12:55:41 AM: Global learning rate: 1.25e-05
09/17 12:55:41 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:55:43 AM: Update 39092: task edges-coref-ontonotes, batch 92 (39092): mcc: 0.8564, acc: 0.9267, precision: 0.9283, recall: 0.9281, f1: 0.9282, edges-coref-ontonotes_loss: 0.1502
09/17 12:55:53 AM: Update 39339: task edges-coref-ontonotes, batch 339 (39339): mcc: 0.8251, acc: 0.9110, precision: 0.9126, recall: 0.9125, f1: 0.9126, edges-coref-ontonotes_loss: 0.1767
09/17 12:56:03 AM: Update 39569: task edges-coref-ontonotes, batch 569 (39569): mcc: 0.8230, acc: 0.9101, precision: 0.9115, recall: 0.9115, f1: 0.9115, edges-coref-ontonotes_loss: 0.1834
09/17 12:56:14 AM: Update 39867: task edges-coref-ontonotes, batch 867 (39867): mcc: 0.8104, acc: 0.9036, precision: 0.9052, recall: 0.9052, f1: 0.9052, edges-coref-ontonotes_loss: 0.2030
09/17 12:56:18 AM: ***** Step 40000 / Validation 40 *****
09/17 12:56:18 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:56:18 AM: Validating...
09/17 12:56:23 AM: Updating LR scheduler:
09/17 12:56:23 AM: 	Best result seen so far for macro_avg: 0.892
09/17 12:56:23 AM: 	# validation passes without improvement: 3
09/17 12:56:23 AM: edges-coref-ontonotes_loss: training: 0.205307 validation: 0.275462
09/17 12:56:23 AM: macro_avg: validation: 0.889769
09/17 12:56:23 AM: micro_avg: validation: 0.000000
09/17 12:56:23 AM: edges-coref-ontonotes_mcc: training: 0.808463 validation: 0.779522
09/17 12:56:23 AM: edges-coref-ontonotes_acc: training: 0.902578 validation: 0.889302
09/17 12:56:23 AM: edges-coref-ontonotes_precision: training: 0.904249 validation: 0.889701
09/17 12:56:23 AM: edges-coref-ontonotes_recall: training: 0.904209 validation: 0.889838
09/17 12:56:23 AM: edges-coref-ontonotes_f1: training: 0.904229 validation: 0.889769
09/17 12:56:23 AM: Global learning rate: 1.25e-05
09/17 12:56:23 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:56:24 AM: Update 40027: task edges-coref-ontonotes, batch 27 (40027): mcc: 0.8052, acc: 0.9012, precision: 0.9030, recall: 0.9021, f1: 0.9025, edges-coref-ontonotes_loss: 0.2135
09/17 12:56:34 AM: Update 40334: task edges-coref-ontonotes, batch 334 (40334): mcc: 0.8258, acc: 0.9112, precision: 0.9132, recall: 0.9126, f1: 0.9129, edges-coref-ontonotes_loss: 0.1824
09/17 12:56:44 AM: Update 40637: task edges-coref-ontonotes, batch 637 (40637): mcc: 0.8216, acc: 0.9092, precision: 0.9110, recall: 0.9105, f1: 0.9108, edges-coref-ontonotes_loss: 0.1867
09/17 12:56:54 AM: Update 40915: task edges-coref-ontonotes, batch 915 (40915): mcc: 0.8203, acc: 0.9086, precision: 0.9103, recall: 0.9099, f1: 0.9101, edges-coref-ontonotes_loss: 0.1897
09/17 12:56:57 AM: ***** Step 41000 / Validation 41 *****
09/17 12:56:57 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:56:57 AM: Validating...
09/17 12:57:02 AM: Updating LR scheduler:
09/17 12:57:02 AM: 	Best result seen so far for macro_avg: 0.892
09/17 12:57:02 AM: 	# validation passes without improvement: 0
09/17 12:57:02 AM: edges-coref-ontonotes_loss: training: 0.194028 validation: 0.273956
09/17 12:57:02 AM: macro_avg: validation: 0.891497
09/17 12:57:02 AM: micro_avg: validation: 0.000000
09/17 12:57:02 AM: edges-coref-ontonotes_mcc: training: 0.817294 validation: 0.783007
09/17 12:57:02 AM: edges-coref-ontonotes_acc: training: 0.907077 validation: 0.891254
09/17 12:57:02 AM: edges-coref-ontonotes_precision: training: 0.908812 validation: 0.891548
09/17 12:57:02 AM: edges-coref-ontonotes_recall: training: 0.908446 validation: 0.891446
09/17 12:57:02 AM: edges-coref-ontonotes_f1: training: 0.908629 validation: 0.891497
09/17 12:57:02 AM: Global learning rate: 6.25e-06
09/17 12:57:02 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:57:04 AM: Update 41082: task edges-coref-ontonotes, batch 82 (41082): mcc: 0.7850, acc: 0.8907, precision: 0.8926, recall: 0.8923, f1: 0.8925, edges-coref-ontonotes_loss: 0.2326
09/17 12:57:14 AM: Update 41363: task edges-coref-ontonotes, batch 363 (41363): mcc: 0.7946, acc: 0.8955, precision: 0.8973, recall: 0.8973, f1: 0.8973, edges-coref-ontonotes_loss: 0.2290
09/17 12:57:24 AM: Update 41703: task edges-coref-ontonotes, batch 703 (41703): mcc: 0.8080, acc: 0.9023, precision: 0.9040, recall: 0.9039, f1: 0.9040, edges-coref-ontonotes_loss: 0.2044
09/17 12:57:34 AM: Update 41992: task edges-coref-ontonotes, batch 992 (41992): mcc: 0.8099, acc: 0.9033, precision: 0.9050, recall: 0.9049, f1: 0.9050, edges-coref-ontonotes_loss: 0.2012
09/17 12:57:34 AM: ***** Step 42000 / Validation 42 *****
09/17 12:57:34 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:57:34 AM: Validating...
09/17 12:57:40 AM: Updating LR scheduler:
09/17 12:57:40 AM: 	Best result seen so far for macro_avg: 0.892
09/17 12:57:40 AM: 	# validation passes without improvement: 1
09/17 12:57:40 AM: edges-coref-ontonotes_loss: training: 0.201313 validation: 0.275911
09/17 12:57:40 AM: macro_avg: validation: 0.891467
09/17 12:57:40 AM: micro_avg: validation: 0.000000
09/17 12:57:40 AM: edges-coref-ontonotes_mcc: training: 0.809979 validation: 0.782930
09/17 12:57:40 AM: edges-coref-ontonotes_acc: training: 0.903349 validation: 0.891178
09/17 12:57:40 AM: edges-coref-ontonotes_precision: training: 0.905058 validation: 0.891450
09/17 12:57:40 AM: edges-coref-ontonotes_recall: training: 0.904906 validation: 0.891484
09/17 12:57:40 AM: edges-coref-ontonotes_f1: training: 0.904982 validation: 0.891467
09/17 12:57:40 AM: Global learning rate: 6.25e-06
09/17 12:57:40 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:57:46 AM: Update 42170: task edges-coref-ontonotes, batch 170 (42170): mcc: 0.8338, acc: 0.9157, precision: 0.9170, recall: 0.9168, f1: 0.9169, edges-coref-ontonotes_loss: 0.1785
09/17 12:57:58 AM: Update 42483: task edges-coref-ontonotes, batch 483 (42483): mcc: 0.8025, acc: 0.8995, precision: 0.9014, recall: 0.9011, f1: 0.9012, edges-coref-ontonotes_loss: 0.2174
09/17 12:58:09 AM: Update 42796: task edges-coref-ontonotes, batch 796 (42796): mcc: 0.8020, acc: 0.8993, precision: 0.9011, recall: 0.9009, f1: 0.9010, edges-coref-ontonotes_loss: 0.2174
09/17 12:58:14 AM: ***** Step 43000 / Validation 43 *****
09/17 12:58:14 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:58:14 AM: Validating...
09/17 12:58:19 AM: Evaluate: task edges-coref-ontonotes, batch 145 (157): mcc: 0.7846, acc: 0.8919, precision: 0.8921, recall: 0.8926, f1: 0.8923, edges-coref-ontonotes_loss: 0.2728
09/17 12:58:19 AM: Updating LR scheduler:
09/17 12:58:19 AM: 	Best result seen so far for macro_avg: 0.892
09/17 12:58:19 AM: 	# validation passes without improvement: 2
09/17 12:58:19 AM: edges-coref-ontonotes_loss: training: 0.205141 validation: 0.276118
09/17 12:58:19 AM: macro_avg: validation: 0.891037
09/17 12:58:19 AM: micro_avg: validation: 0.000000
09/17 12:58:19 AM: edges-coref-ontonotes_mcc: training: 0.809634 validation: 0.782011
09/17 12:58:19 AM: edges-coref-ontonotes_acc: training: 0.903158 validation: 0.890565
09/17 12:58:19 AM: edges-coref-ontonotes_precision: training: 0.904891 validation: 0.890781
09/17 12:58:19 AM: edges-coref-ontonotes_recall: training: 0.904725 validation: 0.891293
09/17 12:58:19 AM: edges-coref-ontonotes_f1: training: 0.904808 validation: 0.891037
09/17 12:58:19 AM: Global learning rate: 6.25e-06
09/17 12:58:19 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:58:29 AM: Update 43288: task edges-coref-ontonotes, batch 288 (43288): mcc: 0.8205, acc: 0.9089, precision: 0.9103, recall: 0.9102, f1: 0.9103, edges-coref-ontonotes_loss: 0.1837
09/17 12:58:39 AM: Update 43583: task edges-coref-ontonotes, batch 583 (43583): mcc: 0.8135, acc: 0.9052, precision: 0.9067, recall: 0.9068, f1: 0.9068, edges-coref-ontonotes_loss: 0.1976
09/17 12:58:49 AM: Update 43858: task edges-coref-ontonotes, batch 858 (43858): mcc: 0.8060, acc: 0.9014, precision: 0.9030, recall: 0.9031, f1: 0.9030, edges-coref-ontonotes_loss: 0.2096
09/17 12:58:53 AM: ***** Step 44000 / Validation 44 *****
09/17 12:58:53 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:58:53 AM: Validating...
09/17 12:58:58 AM: Updating LR scheduler:
09/17 12:58:58 AM: 	Best result seen so far for macro_avg: 0.892
09/17 12:58:58 AM: 	# validation passes without improvement: 3
09/17 12:58:58 AM: edges-coref-ontonotes_loss: training: 0.210894 validation: 0.274976
09/17 12:58:58 AM: macro_avg: validation: 0.891501
09/17 12:58:58 AM: micro_avg: validation: 0.000000
09/17 12:58:58 AM: edges-coref-ontonotes_mcc: training: 0.805809 validation: 0.783007
09/17 12:58:58 AM: edges-coref-ontonotes_acc: training: 0.901281 validation: 0.890948
09/17 12:58:58 AM: edges-coref-ontonotes_precision: training: 0.902894 validation: 0.891518
09/17 12:58:58 AM: edges-coref-ontonotes_recall: training: 0.902917 validation: 0.891484
09/17 12:58:58 AM: edges-coref-ontonotes_f1: training: 0.902906 validation: 0.891501
09/17 12:58:58 AM: Global learning rate: 6.25e-06
09/17 12:58:58 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:58:59 AM: Update 44028: task edges-coref-ontonotes, batch 28 (44028): mcc: 0.8078, acc: 0.9026, precision: 0.9041, recall: 0.9037, f1: 0.9039, edges-coref-ontonotes_loss: 0.2144
09/17 12:59:09 AM: Update 44345: task edges-coref-ontonotes, batch 345 (44345): mcc: 0.8325, acc: 0.9146, precision: 0.9161, recall: 0.9164, f1: 0.9163, edges-coref-ontonotes_loss: 0.1714
09/17 12:59:19 AM: Update 44639: task edges-coref-ontonotes, batch 639 (44639): mcc: 0.8224, acc: 0.9096, precision: 0.9112, recall: 0.9112, f1: 0.9112, edges-coref-ontonotes_loss: 0.1791
09/17 12:59:29 AM: Update 44935: task edges-coref-ontonotes, batch 935 (44935): mcc: 0.8173, acc: 0.9070, precision: 0.9086, recall: 0.9087, f1: 0.9086, edges-coref-ontonotes_loss: 0.1905
09/17 12:59:31 AM: ***** Step 45000 / Validation 45 *****
09/17 12:59:31 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 12:59:31 AM: Validating...
09/17 12:59:36 AM: Updating LR scheduler:
09/17 12:59:36 AM: 	Best result seen so far for macro_avg: 0.892
09/17 12:59:36 AM: 	# validation passes without improvement: 0
09/17 12:59:36 AM: edges-coref-ontonotes_loss: training: 0.193203 validation: 0.274212
09/17 12:59:36 AM: macro_avg: validation: 0.891212
09/17 12:59:36 AM: micro_avg: validation: 0.000000
09/17 12:59:36 AM: edges-coref-ontonotes_mcc: training: 0.815732 validation: 0.782394
09/17 12:59:36 AM: edges-coref-ontonotes_acc: training: 0.906264 validation: 0.890795
09/17 12:59:36 AM: edges-coref-ontonotes_precision: training: 0.907816 validation: 0.891092
09/17 12:59:36 AM: edges-coref-ontonotes_recall: training: 0.907927 validation: 0.891331
09/17 12:59:36 AM: edges-coref-ontonotes_f1: training: 0.907872 validation: 0.891212
09/17 12:59:36 AM: Global learning rate: 3.125e-06
09/17 12:59:36 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 12:59:41 AM: Update 45099: task edges-coref-ontonotes, batch 99 (45099): mcc: 0.7798, acc: 0.8883, precision: 0.8898, recall: 0.8900, f1: 0.8899, edges-coref-ontonotes_loss: 0.2496
09/17 12:59:51 AM: Update 45412: task edges-coref-ontonotes, batch 412 (45412): mcc: 0.7965, acc: 0.8966, precision: 0.8983, recall: 0.8982, f1: 0.8982, edges-coref-ontonotes_loss: 0.2258
09/17 01:00:03 AM: Update 45781: task edges-coref-ontonotes, batch 781 (45781): mcc: 0.8124, acc: 0.9047, precision: 0.9062, recall: 0.9062, f1: 0.9062, edges-coref-ontonotes_loss: 0.1987
09/17 01:00:09 AM: ***** Step 46000 / Validation 46 *****
09/17 01:00:09 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 01:00:09 AM: Validating...
09/17 01:00:13 AM: Evaluate: task edges-coref-ontonotes, batch 128 (157): mcc: 0.7817, acc: 0.8905, precision: 0.8907, recall: 0.8910, f1: 0.8909, edges-coref-ontonotes_loss: 0.2870
09/17 01:00:14 AM: Best result seen so far for edges-coref-ontonotes.
09/17 01:00:14 AM: Best result seen so far for macro.
09/17 01:00:14 AM: Updating LR scheduler:
09/17 01:00:14 AM: 	Best result seen so far for macro_avg: 0.892
09/17 01:00:14 AM: 	# validation passes without improvement: 0
09/17 01:00:14 AM: edges-coref-ontonotes_loss: training: 0.195216 validation: 0.275866
09/17 01:00:14 AM: macro_avg: validation: 0.892075
09/17 01:00:14 AM: micro_avg: validation: 0.000000
09/17 01:00:14 AM: edges-coref-ontonotes_mcc: training: 0.815292 validation: 0.784117
09/17 01:00:14 AM: edges-coref-ontonotes_acc: training: 0.906141 validation: 0.891676
09/17 01:00:14 AM: edges-coref-ontonotes_precision: training: 0.907641 validation: 0.891938
09/17 01:00:14 AM: edges-coref-ontonotes_recall: training: 0.907652 validation: 0.892212
09/17 01:00:14 AM: edges-coref-ontonotes_f1: training: 0.907646 validation: 0.892075
09/17 01:00:14 AM: Global learning rate: 3.125e-06
09/17 01:00:14 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 01:00:23 AM: Update 46250: task edges-coref-ontonotes, batch 250 (46250): mcc: 0.7976, acc: 0.8971, precision: 0.8988, recall: 0.8988, f1: 0.8988, edges-coref-ontonotes_loss: 0.2250
09/17 01:00:33 AM: Update 46543: task edges-coref-ontonotes, batch 543 (46543): mcc: 0.7966, acc: 0.8966, precision: 0.8983, recall: 0.8983, f1: 0.8983, edges-coref-ontonotes_loss: 0.2267
09/17 01:00:43 AM: Update 46835: task edges-coref-ontonotes, batch 835 (46835): mcc: 0.8037, acc: 0.9002, precision: 0.9019, recall: 0.9018, f1: 0.9018, edges-coref-ontonotes_loss: 0.2152
09/17 01:00:47 AM: ***** Step 47000 / Validation 47 *****
09/17 01:00:47 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 01:00:47 AM: Validating...
09/17 01:00:52 AM: Updating LR scheduler:
09/17 01:00:52 AM: 	Best result seen so far for macro_avg: 0.892
09/17 01:00:52 AM: 	# validation passes without improvement: 1
09/17 01:00:52 AM: edges-coref-ontonotes_loss: training: 0.204176 validation: 0.276073
09/17 01:00:52 AM: macro_avg: validation: 0.891531
09/17 01:00:52 AM: micro_avg: validation: 0.000000
09/17 01:00:52 AM: edges-coref-ontonotes_mcc: training: 0.811391 validation: 0.783045
09/17 01:00:52 AM: edges-coref-ontonotes_acc: training: 0.904096 validation: 0.891293
09/17 01:00:52 AM: edges-coref-ontonotes_precision: training: 0.905752 validation: 0.891463
09/17 01:00:52 AM: edges-coref-ontonotes_recall: training: 0.905627 validation: 0.891599
09/17 01:00:52 AM: edges-coref-ontonotes_f1: training: 0.905689 validation: 0.891531
09/17 01:00:52 AM: Global learning rate: 3.125e-06
09/17 01:00:52 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 01:00:53 AM: Update 47033: task edges-coref-ontonotes, batch 33 (47033): mcc: 0.8199, acc: 0.9089, precision: 0.9100, recall: 0.9100, f1: 0.9100, edges-coref-ontonotes_loss: 0.1808
09/17 01:01:03 AM: Update 47347: task edges-coref-ontonotes, batch 347 (47347): mcc: 0.8153, acc: 0.9062, precision: 0.9077, recall: 0.9077, f1: 0.9077, edges-coref-ontonotes_loss: 0.1949
09/17 01:01:13 AM: Update 47644: task edges-coref-ontonotes, batch 644 (47644): mcc: 0.8059, acc: 0.9014, precision: 0.9029, recall: 0.9029, f1: 0.9029, edges-coref-ontonotes_loss: 0.2097
09/17 01:01:23 AM: Update 47930: task edges-coref-ontonotes, batch 930 (47930): mcc: 0.8029, acc: 0.8999, precision: 0.9014, recall: 0.9015, f1: 0.9015, edges-coref-ontonotes_loss: 0.2150
09/17 01:01:25 AM: ***** Step 48000 / Validation 48 *****
09/17 01:01:25 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 01:01:25 AM: Validating...
09/17 01:01:30 AM: Updating LR scheduler:
09/17 01:01:30 AM: 	Best result seen so far for macro_avg: 0.892
09/17 01:01:30 AM: 	# validation passes without improvement: 2
09/17 01:01:30 AM: edges-coref-ontonotes_loss: training: 0.215559 validation: 0.274482
09/17 01:01:30 AM: macro_avg: validation: 0.891875
09/17 01:01:30 AM: micro_avg: validation: 0.000000
09/17 01:01:30 AM: edges-coref-ontonotes_mcc: training: 0.802077 validation: 0.783734
09/17 01:01:30 AM: edges-coref-ontonotes_acc: training: 0.899470 validation: 0.891599
09/17 01:01:30 AM: edges-coref-ontonotes_precision: training: 0.901009 validation: 0.891807
09/17 01:01:30 AM: edges-coref-ontonotes_recall: training: 0.901076 validation: 0.891944
09/17 01:01:30 AM: edges-coref-ontonotes_f1: training: 0.901042 validation: 0.891875
09/17 01:01:30 AM: Global learning rate: 3.125e-06
09/17 01:01:30 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 01:01:33 AM: Update 48029: task edges-coref-ontonotes, batch 29 (48029): mcc: 0.7811, acc: 0.8888, precision: 0.8906, recall: 0.8905, f1: 0.8905, edges-coref-ontonotes_loss: 0.2191
09/17 01:01:45 AM: Update 48397: task edges-coref-ontonotes, batch 397 (48397): mcc: 0.8304, acc: 0.9137, precision: 0.9152, recall: 0.9151, f1: 0.9152, edges-coref-ontonotes_loss: 0.1726
09/17 01:01:55 AM: Update 48710: task edges-coref-ontonotes, batch 710 (48710): mcc: 0.8284, acc: 0.9127, precision: 0.9142, recall: 0.9142, f1: 0.9142, edges-coref-ontonotes_loss: 0.1775
09/17 01:02:04 AM: ***** Step 49000 / Validation 49 *****
09/17 01:02:04 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 01:02:04 AM: Validating...
09/17 01:02:05 AM: Evaluate: task edges-coref-ontonotes, batch 48 (157): mcc: 0.8008, acc: 0.9002, precision: 0.9002, recall: 0.9006, f1: 0.9004, edges-coref-ontonotes_loss: 0.2598
09/17 01:02:09 AM: Updating LR scheduler:
09/17 01:02:09 AM: 	Best result seen so far for macro_avg: 0.892
09/17 01:02:09 AM: 	# validation passes without improvement: 3
09/17 01:02:09 AM: edges-coref-ontonotes_loss: training: 0.195040 validation: 0.274181
09/17 01:02:09 AM: macro_avg: validation: 0.891165
09/17 01:02:09 AM: micro_avg: validation: 0.000000
09/17 01:02:09 AM: edges-coref-ontonotes_mcc: training: 0.816207 validation: 0.782317
09/17 01:02:09 AM: edges-coref-ontonotes_acc: training: 0.906526 validation: 0.890871
09/17 01:02:09 AM: edges-coref-ontonotes_precision: training: 0.908112 validation: 0.891114
09/17 01:02:09 AM: edges-coref-ontonotes_recall: training: 0.908094 validation: 0.891216
09/17 01:02:09 AM: edges-coref-ontonotes_f1: training: 0.908103 validation: 0.891165
09/17 01:02:09 AM: Global learning rate: 3.125e-06
09/17 01:02:09 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 01:02:15 AM: Update 49152: task edges-coref-ontonotes, batch 152 (49152): mcc: 0.7974, acc: 0.8970, precision: 0.8988, recall: 0.8986, f1: 0.8987, edges-coref-ontonotes_loss: 0.2261
09/17 01:02:25 AM: Update 49474: task edges-coref-ontonotes, batch 474 (49474): mcc: 0.8093, acc: 0.9029, precision: 0.9048, recall: 0.9045, f1: 0.9046, edges-coref-ontonotes_loss: 0.2031
09/17 01:02:35 AM: Update 49757: task edges-coref-ontonotes, batch 757 (49757): mcc: 0.8152, acc: 0.9059, precision: 0.9077, recall: 0.9075, f1: 0.9076, edges-coref-ontonotes_loss: 0.1944
09/17 01:02:42 AM: ***** Step 50000 / Validation 50 *****
09/17 01:02:42 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 01:02:42 AM: Validating...
09/17 01:02:45 AM: Evaluate: task edges-coref-ontonotes, batch 108 (157): mcc: 0.7757, acc: 0.8876, precision: 0.8878, recall: 0.8879, f1: 0.8878, edges-coref-ontonotes_loss: 0.2937
09/17 01:02:47 AM: Updating LR scheduler:
09/17 01:02:47 AM: 	Best result seen so far for macro_avg: 0.892
09/17 01:02:47 AM: 	# validation passes without improvement: 0
09/17 01:02:47 AM: edges-coref-ontonotes_loss: training: 0.192078 validation: 0.276210
09/17 01:02:47 AM: macro_avg: validation: 0.891820
09/17 01:02:47 AM: micro_avg: validation: 0.000000
09/17 01:02:47 AM: edges-coref-ontonotes_mcc: training: 0.817719 validation: 0.783619
09/17 01:02:47 AM: edges-coref-ontonotes_acc: training: 0.907224 validation: 0.891637
09/17 01:02:47 AM: edges-coref-ontonotes_precision: training: 0.908963 validation: 0.891735
09/17 01:02:47 AM: edges-coref-ontonotes_recall: training: 0.908733 validation: 0.891905
09/17 01:02:47 AM: edges-coref-ontonotes_f1: training: 0.908848 validation: 0.891820
09/17 01:02:47 AM: Global learning rate: 1.5625e-06
09/17 01:02:47 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 01:02:55 AM: Update 50230: task edges-coref-ontonotes, batch 230 (50230): mcc: 0.7867, acc: 0.8916, precision: 0.8935, recall: 0.8932, f1: 0.8933, edges-coref-ontonotes_loss: 0.2343
09/17 01:03:05 AM: Update 50515: task edges-coref-ontonotes, batch 515 (50515): mcc: 0.7941, acc: 0.8952, precision: 0.8971, recall: 0.8969, f1: 0.8970, edges-coref-ontonotes_loss: 0.2294
09/17 01:03:15 AM: Update 50818: task edges-coref-ontonotes, batch 818 (50818): mcc: 0.8037, acc: 0.9002, precision: 0.9020, recall: 0.9017, f1: 0.9018, edges-coref-ontonotes_loss: 0.2120
09/17 01:03:20 AM: ***** Step 51000 / Validation 51 *****
09/17 01:03:20 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 01:03:20 AM: Validating...
09/17 01:03:25 AM: Evaluate: task edges-coref-ontonotes, batch 155 (157): mcc: 0.7832, acc: 0.8911, precision: 0.8913, recall: 0.8919, f1: 0.8916, edges-coref-ontonotes_loss: 0.2745
09/17 01:03:25 AM: Updating LR scheduler:
09/17 01:03:25 AM: 	Best result seen so far for macro_avg: 0.892
09/17 01:03:25 AM: 	# validation passes without improvement: 1
09/17 01:03:25 AM: edges-coref-ontonotes_loss: training: 0.205158 validation: 0.275065
09/17 01:03:25 AM: macro_avg: validation: 0.891462
09/17 01:03:25 AM: micro_avg: validation: 0.000000
09/17 01:03:25 AM: edges-coref-ontonotes_mcc: training: 0.809472 validation: 0.782854
09/17 01:03:25 AM: edges-coref-ontonotes_acc: training: 0.903133 validation: 0.890910
09/17 01:03:25 AM: edges-coref-ontonotes_precision: training: 0.904797 validation: 0.891172
09/17 01:03:25 AM: edges-coref-ontonotes_recall: training: 0.904660 validation: 0.891752
09/17 01:03:25 AM: edges-coref-ontonotes_f1: training: 0.904729 validation: 0.891462
09/17 01:03:25 AM: Global learning rate: 1.5625e-06
09/17 01:03:25 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 01:03:35 AM: Update 51308: task edges-coref-ontonotes, batch 308 (51308): mcc: 0.8197, acc: 0.9084, precision: 0.9100, recall: 0.9097, f1: 0.9098, edges-coref-ontonotes_loss: 0.1897
09/17 01:03:45 AM: Update 51592: task edges-coref-ontonotes, batch 592 (51592): mcc: 0.8047, acc: 0.9008, precision: 0.9025, recall: 0.9022, f1: 0.9023, edges-coref-ontonotes_loss: 0.2127
09/17 01:03:55 AM: Update 51884: task edges-coref-ontonotes, batch 884 (51884): mcc: 0.8026, acc: 0.8997, precision: 0.9014, recall: 0.9012, f1: 0.9013, edges-coref-ontonotes_loss: 0.2166
09/17 01:04:01 AM: ***** Step 52000 / Validation 52 *****
09/17 01:04:01 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 01:04:01 AM: Validating...
09/17 01:04:05 AM: Evaluate: task edges-coref-ontonotes, batch 150 (157): mcc: 0.7846, acc: 0.8920, precision: 0.8923, recall: 0.8923, f1: 0.8923, edges-coref-ontonotes_loss: 0.2728
09/17 01:04:06 AM: Updating LR scheduler:
09/17 01:04:06 AM: 	Best result seen so far for macro_avg: 0.892
09/17 01:04:06 AM: 	# validation passes without improvement: 2
09/17 01:04:06 AM: edges-coref-ontonotes_loss: training: 0.212400 validation: 0.274622
09/17 01:04:06 AM: macro_avg: validation: 0.891846
09/17 01:04:06 AM: micro_avg: validation: 0.000000
09/17 01:04:06 AM: edges-coref-ontonotes_mcc: training: 0.804205 validation: 0.783696
09/17 01:04:06 AM: edges-coref-ontonotes_acc: training: 0.900538 validation: 0.891561
09/17 01:04:06 AM: edges-coref-ontonotes_precision: training: 0.902190 validation: 0.891863
09/17 01:04:06 AM: edges-coref-ontonotes_recall: training: 0.901995 validation: 0.891829
09/17 01:04:06 AM: edges-coref-ontonotes_f1: training: 0.902092 validation: 0.891846
09/17 01:04:06 AM: Global learning rate: 1.5625e-06
09/17 01:04:06 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 01:04:16 AM: Update 52321: task edges-coref-ontonotes, batch 321 (52321): mcc: 0.8310, acc: 0.9140, precision: 0.9156, recall: 0.9153, f1: 0.9155, edges-coref-ontonotes_loss: 0.1723
09/17 01:04:26 AM: Update 52634: task edges-coref-ontonotes, batch 634 (52634): mcc: 0.8267, acc: 0.9119, precision: 0.9134, recall: 0.9133, f1: 0.9134, edges-coref-ontonotes_loss: 0.1789
09/17 01:04:37 AM: Update 52947: task edges-coref-ontonotes, batch 947 (52947): mcc: 0.8141, acc: 0.9055, precision: 0.9071, recall: 0.9070, f1: 0.9071, edges-coref-ontonotes_loss: 0.1984
09/17 01:04:39 AM: ***** Step 53000 / Validation 53 *****
09/17 01:04:39 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 01:04:39 AM: Validating...
09/17 01:04:44 AM: Updating LR scheduler:
09/17 01:04:44 AM: 	Best result seen so far for macro_avg: 0.892
09/17 01:04:44 AM: 	# validation passes without improvement: 3
09/17 01:04:44 AM: edges-coref-ontonotes_loss: training: 0.199221 validation: 0.274344
09/17 01:04:44 AM: macro_avg: validation: 0.891352
09/17 01:04:44 AM: micro_avg: validation: 0.000000
09/17 01:04:44 AM: edges-coref-ontonotes_mcc: training: 0.813261 validation: 0.782700
09/17 01:04:44 AM: edges-coref-ontonotes_acc: training: 0.904997 validation: 0.891140
09/17 01:04:44 AM: edges-coref-ontonotes_precision: training: 0.906636 validation: 0.891335
09/17 01:04:44 AM: edges-coref-ontonotes_recall: training: 0.906624 validation: 0.891369
09/17 01:04:44 AM: edges-coref-ontonotes_f1: training: 0.906630 validation: 0.891352
09/17 01:04:44 AM: Global learning rate: 1.5625e-06
09/17 01:04:44 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 01:04:47 AM: Update 53121: task edges-coref-ontonotes, batch 121 (53121): mcc: 0.8026, acc: 0.8996, precision: 0.9016, recall: 0.9010, f1: 0.9013, edges-coref-ontonotes_loss: 0.2133
09/17 01:04:57 AM: Update 53429: task edges-coref-ontonotes, batch 429 (53429): mcc: 0.8152, acc: 0.9062, precision: 0.9078, recall: 0.9074, f1: 0.9076, edges-coref-ontonotes_loss: 0.1948
09/17 01:05:07 AM: Update 53703: task edges-coref-ontonotes, batch 703 (53703): mcc: 0.8188, acc: 0.9079, precision: 0.9094, recall: 0.9094, f1: 0.9094, edges-coref-ontonotes_loss: 0.1897
09/17 01:05:17 AM: ***** Step 54000 / Validation 54 *****
09/17 01:05:17 AM: edges-coref-ontonotes: trained on 1000 batches, 0.766 epochs
09/17 01:05:17 AM: Validating...
09/17 01:05:17 AM: Evaluate: task edges-coref-ontonotes, batch 1 (157): mcc: 0.7255, acc: 0.8627, precision: 0.8627, recall: 0.8627, f1: 0.8627, edges-coref-ontonotes_loss: 0.3360
09/17 01:05:22 AM: Updating LR scheduler:
09/17 01:05:22 AM: 	Best result seen so far for macro_avg: 0.892
09/17 01:05:22 AM: 	# validation passes without improvement: 0
09/17 01:05:22 AM: Minimum LR reached. Stopping training.
09/17 01:05:22 AM: edges-coref-ontonotes_loss: training: 0.192767 validation: 0.275183
09/17 01:05:22 AM: macro_avg: validation: 0.891862
09/17 01:05:22 AM: micro_avg: validation: 0.000000
09/17 01:05:22 AM: edges-coref-ontonotes_mcc: training: 0.816573 validation: 0.783696
09/17 01:05:22 AM: edges-coref-ontonotes_acc: training: 0.906799 validation: 0.891561
09/17 01:05:22 AM: edges-coref-ontonotes_precision: training: 0.908310 validation: 0.891743
09/17 01:05:22 AM: edges-coref-ontonotes_recall: training: 0.908258 validation: 0.891982
09/17 01:05:22 AM: edges-coref-ontonotes_f1: training: 0.908284 validation: 0.891862
09/17 01:05:22 AM: Global learning rate: 7.8125e-07
09/17 01:05:22 AM: Saving checkpoints to: ./experiments/coref-ontonotes-memorization-only/run
09/17 01:05:22 AM: Stopped training after 54 validation checks
09/17 01:05:22 AM: Trained edges-coref-ontonotes for 54000 batches or 41.348 epochs
09/17 01:05:22 AM: ***** VALIDATION RESULTS *****
09/17 01:05:22 AM: edges-coref-ontonotes_f1 (for best val pass 46): edges-coref-ontonotes_loss: 0.27587, macro_avg: 0.89208, micro_avg: 0.00000, edges-coref-ontonotes_mcc: 0.78412, edges-coref-ontonotes_acc: 0.89168, edges-coref-ontonotes_precision: 0.89194, edges-coref-ontonotes_recall: 0.89221, edges-coref-ontonotes_f1: 0.89208
09/17 01:05:22 AM: micro_avg (for best val pass 1): edges-coref-ontonotes_loss: 0.37579, macro_avg: 0.85446, micro_avg: 0.00000, edges-coref-ontonotes_mcc: 0.70989, edges-coref-ontonotes_acc: 0.85074, edges-coref-ontonotes_precision: 0.85725, edges-coref-ontonotes_recall: 0.85170, edges-coref-ontonotes_f1: 0.85446
09/17 01:05:22 AM: macro_avg (for best val pass 46): edges-coref-ontonotes_loss: 0.27587, macro_avg: 0.89208, micro_avg: 0.00000, edges-coref-ontonotes_mcc: 0.78412, edges-coref-ontonotes_acc: 0.89168, edges-coref-ontonotes_precision: 0.89194, edges-coref-ontonotes_recall: 0.89221, edges-coref-ontonotes_f1: 0.89208
09/17 01:05:22 AM: Evaluating...
09/17 01:05:22 AM: Loaded model state from ./experiments/coref-ontonotes-memorization-only/run/edges-coref-ontonotes/model_state_target_train_val_46.best.th
09/17 01:05:22 AM: Evaluating on: edges-coref-ontonotes, split: val
09/17 01:05:28 AM: Task 'edges-coref-ontonotes': sorting predictions by 'idx'
09/17 01:05:28 AM: Finished evaluating on: edges-coref-ontonotes
09/17 01:05:28 AM: Task 'edges-coref-ontonotes': joining predictions with input split 'val'
09/17 01:05:28 AM: Task 'edges-coref-ontonotes': Wrote predictions to ./experiments/coref-ontonotes-memorization-only/run
09/17 01:05:28 AM: Wrote all preds for split 'val' to ./experiments/coref-ontonotes-memorization-only/run
09/17 01:05:28 AM: Evaluating on: edges-coref-ontonotes, split: test
09/17 01:05:34 AM: Task 'edges-coref-ontonotes': sorting predictions by 'idx'
09/17 01:05:34 AM: Finished evaluating on: edges-coref-ontonotes
09/17 01:05:34 AM: Task 'edges-coref-ontonotes': joining predictions with input split 'test'
09/17 01:05:34 AM: Task 'edges-coref-ontonotes': Wrote predictions to ./experiments/coref-ontonotes-memorization-only/run
09/17 01:05:34 AM: Wrote all preds for split 'test' to ./experiments/coref-ontonotes-memorization-only/run
09/17 01:05:34 AM: Writing results for split 'val' to ./experiments/coref-ontonotes-memorization-only/results.tsv
09/17 01:05:34 AM: micro_avg: 0.000, macro_avg: 0.892, edges-coref-ontonotes_mcc: 0.785, edges-coref-ontonotes_acc: 0.892, edges-coref-ontonotes_precision: 0.892, edges-coref-ontonotes_recall: 0.892, edges-coref-ontonotes_f1: 0.892
09/17 01:05:34 AM: Done!
09/17 01:05:34 AM: Fatal error in main():
Traceback (most recent call last):
  File "main.py", line 16, in <module>
    main(sys.argv[1:])
  File "/srv/home/ericwallace/jiant/jiant/__main__.py", line 610, in main
    exit("Done exited")
  File "/home/ericwallace/miniconda3/envs/jiant/lib/python3.6/_sitebuiltins.py", line 26, in __call__
    raise SystemExit(code)
SystemExit: Done exited
