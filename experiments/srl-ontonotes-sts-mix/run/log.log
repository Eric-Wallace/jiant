09/16 09:10:58 AM: Git branch: master
09/16 09:10:58 AM: Git SHA: 1a42459c6cbb693793b9c0d01bca567d99b0baac
09/16 09:10:58 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/srl-ontonotes-sts-mix/",
  "exp_name": "experiments/srl-ontonotes-sts-mix",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/srl-ontonotes-sts-mix/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/sts",
  "pytorch_transformers_output_mode": "mix",
  "remote_log_name": "experiments/srl-ontonotes-sts-mix__run",
  "run_dir": "./experiments/srl-ontonotes-sts-mix/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-srl-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 09:10:58 AM: Saved config to ./experiments/srl-ontonotes-sts-mix/run/params.conf
09/16 09:10:58 AM: Using random seed 1234
09/16 09:10:59 AM: Using GPU 0
09/16 09:10:59 AM: Loading tasks...
09/16 09:10:59 AM: Writing pre-preprocessed tasks to ./experiments/srl-ontonotes-sts-mix/
09/16 09:10:59 AM: 	Creating task edges-srl-ontonotes from scratch.
09/16 09:11:04 AM: Read=231480, Skip=21590, Total=253070 from ./probing_data/edges/ontonotes/srl/train.json.retokenized.bert-base-uncased
09/16 09:11:04 AM: Read=32486, Skip=2811, Total=35297 from ./probing_data/edges/ontonotes/srl/development.json.retokenized.bert-base-uncased
09/16 09:11:05 AM: Read=23800, Skip=2915, Total=26715 from ./probing_data/edges/ontonotes/srl/test.json.retokenized.bert-base-uncased
09/16 09:11:08 AM: 	Task 'edges-srl-ontonotes': |train|=231480 |val|=32486 |test|=23800
09/16 09:11:08 AM: 	Finished loading tasks: edges-srl-ontonotes.
09/16 09:11:08 AM: 	Building vocab from scratch.
09/16 09:11:08 AM: 	Counting units for task edges-srl-ontonotes.
09/16 09:11:15 AM: 	Task 'edges-srl-ontonotes': adding vocab namespace 'edges-srl-ontonotes_labels'
09/16 09:11:16 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:11:16 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 09:11:16 AM: 	Saved vocab to ./experiments/srl-ontonotes-sts-mix/vocab
09/16 09:11:16 AM: Loading token dictionary from ./experiments/srl-ontonotes-sts-mix/vocab.
09/16 09:11:16 AM: 	Loaded vocab from ./experiments/srl-ontonotes-sts-mix/vocab
09/16 09:11:16 AM: 	Vocab namespace bert_uncased: size 30524
09/16 09:11:16 AM: 	Vocab namespace tokens: size 23662
09/16 09:11:16 AM: 	Vocab namespace edges-srl-ontonotes_labels: size 66
09/16 09:11:16 AM: 	Vocab namespace chars: size 76
09/16 09:11:16 AM: 	Finished building vocab.
09/16 09:11:16 AM: 	Task edges-srl-ontonotes (train): Indexing from scratch.
09/16 09:11:53 AM: 	Task edges-srl-ontonotes (train): Saved 231480 instances to ./experiments/srl-ontonotes-sts-mix/preproc/edges-srl-ontonotes__train_data
09/16 09:11:53 AM: 	Task edges-srl-ontonotes (val): Indexing from scratch.
09/16 09:11:59 AM: 	Task edges-srl-ontonotes (val): Saved 32486 instances to ./experiments/srl-ontonotes-sts-mix/preproc/edges-srl-ontonotes__val_data
09/16 09:11:59 AM: 	Task edges-srl-ontonotes (test): Indexing from scratch.
09/16 09:12:02 AM: 	Task edges-srl-ontonotes (test): Saved 23800 instances to ./experiments/srl-ontonotes-sts-mix/preproc/edges-srl-ontonotes__test_data
09/16 09:12:02 AM: 	Finished indexing tasks
09/16 09:12:02 AM: 	Creating trimmed target-only version of edges-srl-ontonotes train.
09/16 09:12:02 AM: 	  Training on 
09/16 09:12:02 AM: 	  Evaluating on edges-srl-ontonotes
09/16 09:12:02 AM: 	Finished loading tasks in 63.222s
09/16 09:12:02 AM: 	 Tasks: ['edges-srl-ontonotes']
09/16 09:12:02 AM: Building model...
09/16 09:12:02 AM: Using BERT model (bert-base-uncased).
09/16 09:12:02 AM: LOADING A FUNETUNED MODEL from: 
09/16 09:12:02 AM: models/sts
09/16 09:12:02 AM: loading configuration file models/sts/config.json
09/16 09:12:02 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "sts-b",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 09:12:02 AM: loading weights file models/sts/pytorch_model.bin
09/16 09:12:05 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpxw8ekzpq
09/16 09:12:07 AM: copying /tmp/tmpxw8ekzpq to cache at ./experiments/srl-ontonotes-sts-mix/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:12:07 AM: creating metadata file for ./experiments/srl-ontonotes-sts-mix/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:12:07 AM: removing temp file /tmp/tmpxw8ekzpq
09/16 09:12:07 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/srl-ontonotes-sts-mix/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:12:07 AM: NOTE: pytorch_transformers_output_mode='mix', so scalar mixing weights will be fine-tuned even if BERT model is frozen.
09/16 09:12:07 AM: Initializing parameters
09/16 09:12:07 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 09:12:07 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 09:12:07 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 09:12:07 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.scalar_mix.gamma
09/16 09:12:07 AM:    _text_field_embedder.scalar_mix.scalar_parameters.0
09/16 09:12:07 AM:    _text_field_embedder.scalar_mix.scalar_parameters.1
09/16 09:12:07 AM:    _text_field_embedder.scalar_mix.scalar_parameters.10
09/16 09:12:07 AM:    _text_field_embedder.scalar_mix.scalar_parameters.11
09/16 09:12:07 AM:    _text_field_embedder.scalar_mix.scalar_parameters.12
09/16 09:12:07 AM:    _text_field_embedder.scalar_mix.scalar_parameters.2
09/16 09:12:07 AM:    _text_field_embedder.scalar_mix.scalar_parameters.3
09/16 09:12:07 AM:    _text_field_embedder.scalar_mix.scalar_parameters.4
09/16 09:12:07 AM:    _text_field_embedder.scalar_mix.scalar_parameters.5
09/16 09:12:07 AM:    _text_field_embedder.scalar_mix.scalar_parameters.6
09/16 09:12:07 AM:    _text_field_embedder.scalar_mix.scalar_parameters.7
09/16 09:12:07 AM:    _text_field_embedder.scalar_mix.scalar_parameters.8
09/16 09:12:07 AM:    _text_field_embedder.scalar_mix.scalar_parameters.9
09/16 09:12:07 AM: 	Task 'edges-srl-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-srl-ontonotes"
}
09/16 09:12:11 AM: Model specification:
09/16 09:12:11 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
      (scalar_mix): ScalarMix(
        (scalar_parameters): ParameterList(
            (0): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (1): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (2): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (3): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (4): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (5): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (6): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (7): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (8): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (9): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (10): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (11): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
            (12): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 0)]
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-srl-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (proj2): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (span_extractor2): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Sequential(
        (0): Linear(in_features=1024, out_features=256, bias=True)
        (1): Tanh()
        (2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)
        (3): Dropout(p=0.3)
        (4): Linear(in_features=256, out_features=66, bias=True)
      )
    )
  )
)
09/16 09:12:11 AM: Model parameters:
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.scalar_mix.gamma: Trainable parameter, count 1 with torch.Size([1])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.0: Trainable parameter, count 1 with torch.Size([1])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.1: Trainable parameter, count 1 with torch.Size([1])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.2: Trainable parameter, count 1 with torch.Size([1])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.3: Trainable parameter, count 1 with torch.Size([1])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.4: Trainable parameter, count 1 with torch.Size([1])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.5: Trainable parameter, count 1 with torch.Size([1])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.6: Trainable parameter, count 1 with torch.Size([1])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.7: Trainable parameter, count 1 with torch.Size([1])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.8: Trainable parameter, count 1 with torch.Size([1])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.9: Trainable parameter, count 1 with torch.Size([1])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.10: Trainable parameter, count 1 with torch.Size([1])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.11: Trainable parameter, count 1 with torch.Size([1])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.scalar_mix.scalar_parameters.12: Trainable parameter, count 1 with torch.Size([1])
09/16 09:12:11 AM: 	edges-srl-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 09:12:11 AM: 	edges-srl-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 09:12:11 AM: 	edges-srl-ontonotes_mdl.proj2.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 09:12:11 AM: 	edges-srl-ontonotes_mdl.proj2.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 09:12:11 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.0.weight: Trainable parameter, count 262144 with torch.Size([256, 1024])
09/16 09:12:11 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.0.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 09:12:11 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.2.weight: Trainable parameter, count 256 with torch.Size([256])
09/16 09:12:11 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.2.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 09:12:11 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.4.weight: Trainable parameter, count 16896 with torch.Size([66, 256])
09/16 09:12:11 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.4.bias: Trainable parameter, count 66 with torch.Size([66])
09/16 09:12:11 AM: Total number of parameters: 110155856 (1.10156e+08)
09/16 09:12:11 AM: Number of trainable parameters: 673616 (673616)
09/16 09:12:11 AM: Finished building model in 9.033s
09/16 09:12:11 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-srl-ontonotes 

09/16 09:12:28 AM: patience = 9
09/16 09:12:28 AM: val_interval = 1000
09/16 09:12:28 AM: max_vals = 250
09/16 09:12:28 AM: cuda_device = 0
09/16 09:12:28 AM: grad_norm = 5.0
09/16 09:12:28 AM: grad_clipping = None
09/16 09:12:28 AM: lr_decay = 0.99
09/16 09:12:28 AM: min_lr = 1e-06
09/16 09:12:28 AM: keep_all_checkpoints = 0
09/16 09:12:28 AM: val_data_limit = 5000
09/16 09:12:28 AM: max_epochs = -1
09/16 09:12:28 AM: dec_val_scale = 250
09/16 09:12:28 AM: training_data_fraction = 1
09/16 09:12:28 AM: type = adam
09/16 09:12:28 AM: parameter_groups = None
09/16 09:12:28 AM: Number of trainable parameters: 673616
09/16 09:12:28 AM: infer_type_and_cast = True
09/16 09:12:28 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:12:28 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:12:28 AM: lr = 0.0001
09/16 09:12:28 AM: amsgrad = True
09/16 09:12:28 AM: type = reduce_on_plateau
09/16 09:12:28 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:12:28 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:12:28 AM: mode = max
09/16 09:12:28 AM: factor = 0.5
09/16 09:12:28 AM: patience = 3
09/16 09:12:28 AM: threshold = 0.0001
09/16 09:12:28 AM: threshold_mode = abs
09/16 09:12:28 AM: verbose = True
09/16 09:12:28 AM: type = adam
09/16 09:12:28 AM: parameter_groups = None
09/16 09:12:28 AM: Number of trainable parameters: 673616
09/16 09:12:28 AM: infer_type_and_cast = True
09/16 09:12:28 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:12:28 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:12:28 AM: lr = 0.0001
09/16 09:12:28 AM: amsgrad = True
09/16 09:12:28 AM: type = reduce_on_plateau
09/16 09:12:28 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:12:28 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:12:28 AM: mode = max
09/16 09:12:28 AM: factor = 0.5
09/16 09:12:28 AM: patience = 3
09/16 09:12:28 AM: threshold = 0.0001
09/16 09:12:28 AM: threshold_mode = abs
09/16 09:12:28 AM: verbose = True
09/16 09:12:28 AM: Starting training without restoring from a checkpoint.
09/16 09:12:28 AM: Training examples per task, before any subsampling: {'edges-srl-ontonotes': 231480}
09/16 09:12:28 AM: Beginning training with stopping criteria based on metric: edges-srl-ontonotes_f1
09/16 09:12:38 AM: Update 121: task edges-srl-ontonotes, batch 121 (121): mcc: 0.0667, acc: 0.0480, precision: 0.0647, recall: 0.1126, f1: 0.0822, edges-srl-ontonotes_loss: 0.2043
09/16 09:12:48 AM: Update 249: task edges-srl-ontonotes, batch 249 (249): mcc: 0.0861, acc: 0.0621, precision: 0.1053, recall: 0.0934, f1: 0.0990, edges-srl-ontonotes_loss: 0.1342
09/16 09:12:58 AM: Update 363: task edges-srl-ontonotes, batch 363 (363): mcc: 0.1644, acc: 0.1248, precision: 0.2072, recall: 0.1478, f1: 0.1726, edges-srl-ontonotes_loss: 0.1071
09/16 09:13:08 AM: Update 502: task edges-srl-ontonotes, batch 502 (502): mcc: 0.2731, acc: 0.2096, precision: 0.3459, recall: 0.2300, f1: 0.2763, edges-srl-ontonotes_loss: 0.0878
09/16 09:13:18 AM: Update 622: task edges-srl-ontonotes, batch 622 (622): mcc: 0.3531, acc: 0.2736, precision: 0.4429, recall: 0.2942, f1: 0.3536, edges-srl-ontonotes_loss: 0.0768
09/16 09:13:28 AM: Update 697: task edges-srl-ontonotes, batch 697 (697): mcc: 0.3882, acc: 0.3016, precision: 0.4857, recall: 0.3223, f1: 0.3875, edges-srl-ontonotes_loss: 0.0718
09/16 09:13:38 AM: Update 831: task edges-srl-ontonotes, batch 831 (831): mcc: 0.4424, acc: 0.3472, precision: 0.5475, recall: 0.3686, f1: 0.4406, edges-srl-ontonotes_loss: 0.0646
09/16 09:13:48 AM: Update 958: task edges-srl-ontonotes, batch 958 (958): mcc: 0.4828, acc: 0.3826, precision: 0.5913, recall: 0.4046, f1: 0.4805, edges-srl-ontonotes_loss: 0.0593
09/16 09:13:51 AM: ***** Step 1000 / Validation 1 *****
09/16 09:13:51 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:13:51 AM: Validating...
09/16 09:13:58 AM: Evaluate: task edges-srl-ontonotes, batch 93 (157): mcc: 0.7705, acc: 0.6581, precision: 0.8953, recall: 0.6681, f1: 0.7652, edges-srl-ontonotes_loss: 0.0217
09/16 09:14:03 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:14:03 AM: Best result seen so far for micro.
09/16 09:14:03 AM: Best result seen so far for macro.
09/16 09:14:03 AM: Updating LR scheduler:
09/16 09:14:03 AM: 	Best result seen so far for macro_avg: 0.777
09/16 09:14:03 AM: 	# validation passes without improvement: 0
09/16 09:14:03 AM: edges-srl-ontonotes_loss: training: 0.057838 validation: 0.021227
09/16 09:14:03 AM: macro_avg: validation: 0.776803
09/16 09:14:03 AM: micro_avg: validation: 0.000000
09/16 09:14:03 AM: edges-srl-ontonotes_mcc: training: 0.493465 validation: 0.781040
09/16 09:14:03 AM: edges-srl-ontonotes_acc: training: 0.392110 validation: 0.673851
09/16 09:14:03 AM: edges-srl-ontonotes_precision: training: 0.602721 validation: 0.896736
09/16 09:14:03 AM: edges-srl-ontonotes_recall: training: 0.414317 validation: 0.685167
09/16 09:14:03 AM: edges-srl-ontonotes_f1: training: 0.491068 validation: 0.776803
09/16 09:14:03 AM: Global learning rate: 0.0001
09/16 09:14:03 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:14:08 AM: Update 1067: task edges-srl-ontonotes, batch 67 (1067): mcc: 0.7416, acc: 0.6256, precision: 0.8467, recall: 0.6554, f1: 0.7389, edges-srl-ontonotes_loss: 0.0241
09/16 09:14:18 AM: Update 1200: task edges-srl-ontonotes, batch 200 (1200): mcc: 0.7472, acc: 0.6333, precision: 0.8504, recall: 0.6623, f1: 0.7447, edges-srl-ontonotes_loss: 0.0233
09/16 09:14:28 AM: Update 1306: task edges-srl-ontonotes, batch 306 (1306): mcc: 0.7526, acc: 0.6414, precision: 0.8517, recall: 0.6709, f1: 0.7505, edges-srl-ontonotes_loss: 0.0227
09/16 09:14:39 AM: Update 1430: task edges-srl-ontonotes, batch 430 (1430): mcc: 0.7557, acc: 0.6472, precision: 0.8512, recall: 0.6767, f1: 0.7540, edges-srl-ontonotes_loss: 0.0221
09/16 09:14:49 AM: Update 1553: task edges-srl-ontonotes, batch 553 (1553): mcc: 0.7624, acc: 0.6562, precision: 0.8537, recall: 0.6865, f1: 0.7610, edges-srl-ontonotes_loss: 0.0215
09/16 09:14:59 AM: Update 1661: task edges-srl-ontonotes, batch 661 (1661): mcc: 0.7615, acc: 0.6549, precision: 0.8523, recall: 0.6861, f1: 0.7602, edges-srl-ontonotes_loss: 0.0214
09/16 09:15:09 AM: Update 1770: task edges-srl-ontonotes, batch 770 (1770): mcc: 0.7615, acc: 0.6552, precision: 0.8512, recall: 0.6869, f1: 0.7603, edges-srl-ontonotes_loss: 0.0214
09/16 09:15:19 AM: Update 1878: task edges-srl-ontonotes, batch 878 (1878): mcc: 0.7613, acc: 0.6552, precision: 0.8504, recall: 0.6872, f1: 0.7601, edges-srl-ontonotes_loss: 0.0212
09/16 09:15:29 AM: Update 1965: task edges-srl-ontonotes, batch 965 (1965): mcc: 0.7626, acc: 0.6571, precision: 0.8508, recall: 0.6893, f1: 0.7616, edges-srl-ontonotes_loss: 0.0211
09/16 09:15:32 AM: ***** Step 2000 / Validation 2 *****
09/16 09:15:32 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:15:32 AM: Validating...
09/16 09:15:39 AM: Evaluate: task edges-srl-ontonotes, batch 85 (157): mcc: 0.8112, acc: 0.7234, precision: 0.8952, recall: 0.7397, f1: 0.8100, edges-srl-ontonotes_loss: 0.0166
09/16 09:15:44 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:15:44 AM: Best result seen so far for macro.
09/16 09:15:44 AM: Updating LR scheduler:
09/16 09:15:44 AM: 	Best result seen so far for macro_avg: 0.824
09/16 09:15:44 AM: 	# validation passes without improvement: 0
09/16 09:15:44 AM: edges-srl-ontonotes_loss: training: 0.021026 validation: 0.015941
09/16 09:15:44 AM: macro_avg: validation: 0.824496
09/16 09:15:44 AM: micro_avg: validation: 0.000000
09/16 09:15:44 AM: edges-srl-ontonotes_mcc: training: 0.763148 validation: 0.824959
09/16 09:15:44 AM: edges-srl-ontonotes_acc: training: 0.657668 validation: 0.744592
09/16 09:15:44 AM: edges-srl-ontonotes_precision: training: 0.850911 validation: 0.899245
09/16 09:15:44 AM: edges-srl-ontonotes_recall: training: 0.690142 validation: 0.761219
09/16 09:15:44 AM: edges-srl-ontonotes_f1: training: 0.762140 validation: 0.824496
09/16 09:15:44 AM: Global learning rate: 0.0001
09/16 09:15:44 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:15:49 AM: Update 2053: task edges-srl-ontonotes, batch 53 (2053): mcc: 0.7768, acc: 0.6770, precision: 0.8539, recall: 0.7121, f1: 0.7766, edges-srl-ontonotes_loss: 0.0195
09/16 09:15:59 AM: Update 2160: task edges-srl-ontonotes, batch 160 (2160): mcc: 0.7704, acc: 0.6716, precision: 0.8466, recall: 0.7067, f1: 0.7703, edges-srl-ontonotes_loss: 0.0196
09/16 09:16:09 AM: Update 2255: task edges-srl-ontonotes, batch 255 (2255): mcc: 0.7745, acc: 0.6768, precision: 0.8486, recall: 0.7125, f1: 0.7746, edges-srl-ontonotes_loss: 0.0194
09/16 09:16:19 AM: Update 2368: task edges-srl-ontonotes, batch 368 (2368): mcc: 0.7822, acc: 0.6866, precision: 0.8541, recall: 0.7218, f1: 0.7824, edges-srl-ontonotes_loss: 0.0188
09/16 09:16:29 AM: Update 2470: task edges-srl-ontonotes, batch 470 (2470): mcc: 0.7852, acc: 0.6910, precision: 0.8554, recall: 0.7263, f1: 0.7855, edges-srl-ontonotes_loss: 0.0185
09/16 09:16:39 AM: Update 2582: task edges-srl-ontonotes, batch 582 (2582): mcc: 0.7889, acc: 0.6961, precision: 0.8575, recall: 0.7311, f1: 0.7893, edges-srl-ontonotes_loss: 0.0182
09/16 09:16:49 AM: Update 2699: task edges-srl-ontonotes, batch 699 (2699): mcc: 0.7913, acc: 0.7003, precision: 0.8584, recall: 0.7349, f1: 0.7918, edges-srl-ontonotes_loss: 0.0180
09/16 09:16:59 AM: Update 2811: task edges-srl-ontonotes, batch 811 (2811): mcc: 0.7936, acc: 0.7037, precision: 0.8595, recall: 0.7382, f1: 0.7942, edges-srl-ontonotes_loss: 0.0178
09/16 09:17:09 AM: Update 2893: task edges-srl-ontonotes, batch 893 (2893): mcc: 0.7959, acc: 0.7065, precision: 0.8609, recall: 0.7411, f1: 0.7965, edges-srl-ontonotes_loss: 0.0176
09/16 09:17:18 AM: ***** Step 3000 / Validation 3 *****
09/16 09:17:18 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:17:18 AM: Validating...
09/16 09:17:19 AM: Evaluate: task edges-srl-ontonotes, batch 11 (157): mcc: 0.8505, acc: 0.7868, precision: 0.9041, recall: 0.8041, f1: 0.8512, edges-srl-ontonotes_loss: 0.0140
09/16 09:17:29 AM: Evaluate: task edges-srl-ontonotes, batch 143 (157): mcc: 0.8356, acc: 0.7663, precision: 0.8949, recall: 0.7846, f1: 0.8361, edges-srl-ontonotes_loss: 0.0145
09/16 09:17:30 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:17:30 AM: Best result seen so far for macro.
09/16 09:17:30 AM: Updating LR scheduler:
09/16 09:17:30 AM: 	Best result seen so far for macro_avg: 0.834
09/16 09:17:30 AM: 	# validation passes without improvement: 0
09/16 09:17:30 AM: edges-srl-ontonotes_loss: training: 0.017498 validation: 0.014704
09/16 09:17:30 AM: macro_avg: validation: 0.833860
09/16 09:17:30 AM: micro_avg: validation: 0.000000
09/16 09:17:30 AM: edges-srl-ontonotes_mcc: training: 0.797737 validation: 0.833319
09/16 09:17:30 AM: edges-srl-ontonotes_acc: training: 0.709036 validation: 0.763683
09/16 09:17:30 AM: edges-srl-ontonotes_precision: training: 0.862016 validation: 0.892381
09/16 09:17:30 AM: edges-srl-ontonotes_recall: training: 0.743471 validation: 0.782542
09/16 09:17:30 AM: edges-srl-ontonotes_f1: training: 0.798367 validation: 0.833860
09/16 09:17:30 AM: Global learning rate: 0.0001
09/16 09:17:30 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:17:39 AM: Update 3108: task edges-srl-ontonotes, batch 108 (3108): mcc: 0.8214, acc: 0.7413, precision: 0.8781, recall: 0.7730, f1: 0.8222, edges-srl-ontonotes_loss: 0.0155
09/16 09:17:49 AM: Update 3210: task edges-srl-ontonotes, batch 210 (3210): mcc: 0.8143, acc: 0.7338, precision: 0.8721, recall: 0.7652, f1: 0.8152, edges-srl-ontonotes_loss: 0.0161
09/16 09:17:59 AM: Update 3315: task edges-srl-ontonotes, batch 315 (3315): mcc: 0.8126, acc: 0.7305, precision: 0.8713, recall: 0.7627, f1: 0.8134, edges-srl-ontonotes_loss: 0.0162
09/16 09:18:09 AM: Update 3428: task edges-srl-ontonotes, batch 428 (3428): mcc: 0.8114, acc: 0.7287, precision: 0.8707, recall: 0.7610, f1: 0.8122, edges-srl-ontonotes_loss: 0.0163
09/16 09:18:20 AM: Update 3533: task edges-srl-ontonotes, batch 533 (3533): mcc: 0.8115, acc: 0.7288, precision: 0.8707, recall: 0.7612, f1: 0.8123, edges-srl-ontonotes_loss: 0.0162
09/16 09:18:30 AM: Update 3643: task edges-srl-ontonotes, batch 643 (3643): mcc: 0.8105, acc: 0.7271, precision: 0.8702, recall: 0.7599, f1: 0.8113, edges-srl-ontonotes_loss: 0.0163
09/16 09:18:41 AM: Update 3757: task edges-srl-ontonotes, batch 757 (3757): mcc: 0.8115, acc: 0.7287, precision: 0.8707, recall: 0.7612, f1: 0.8123, edges-srl-ontonotes_loss: 0.0162
09/16 09:18:51 AM: Update 3871: task edges-srl-ontonotes, batch 871 (3871): mcc: 0.8114, acc: 0.7292, precision: 0.8702, recall: 0.7615, f1: 0.8122, edges-srl-ontonotes_loss: 0.0161
09/16 09:19:01 AM: Update 3991: task edges-srl-ontonotes, batch 991 (3991): mcc: 0.8117, acc: 0.7304, precision: 0.8701, recall: 0.7623, f1: 0.8126, edges-srl-ontonotes_loss: 0.0161
09/16 09:19:01 AM: ***** Step 4000 / Validation 4 *****
09/16 09:19:01 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:19:01 AM: Validating...
09/16 09:19:12 AM: Evaluate: task edges-srl-ontonotes, batch 104 (157): mcc: 0.8293, acc: 0.7576, precision: 0.8975, recall: 0.7706, f1: 0.8292, edges-srl-ontonotes_loss: 0.0146
09/16 09:19:16 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:19:16 AM: Best result seen so far for macro.
09/16 09:19:16 AM: Updating LR scheduler:
09/16 09:19:16 AM: 	Best result seen so far for macro_avg: 0.835
09/16 09:19:16 AM: 	# validation passes without improvement: 0
09/16 09:19:16 AM: edges-srl-ontonotes_loss: training: 0.016083 validation: 0.014243
09/16 09:19:16 AM: macro_avg: validation: 0.834912
09/16 09:19:16 AM: micro_avg: validation: 0.000000
09/16 09:19:16 AM: edges-srl-ontonotes_mcc: training: 0.811681 validation: 0.834637
09/16 09:19:16 AM: edges-srl-ontonotes_acc: training: 0.730318 validation: 0.767377
09/16 09:19:16 AM: edges-srl-ontonotes_precision: training: 0.870035 validation: 0.897425
09/16 09:19:16 AM: edges-srl-ontonotes_recall: training: 0.762184 validation: 0.780540
09/16 09:19:16 AM: edges-srl-ontonotes_f1: training: 0.812547 validation: 0.834912
09/16 09:19:16 AM: Global learning rate: 0.0001
09/16 09:19:16 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:19:22 AM: Update 4070: task edges-srl-ontonotes, batch 70 (4070): mcc: 0.8116, acc: 0.7294, precision: 0.8709, recall: 0.7613, f1: 0.8124, edges-srl-ontonotes_loss: 0.0161
09/16 09:19:32 AM: Update 4191: task edges-srl-ontonotes, batch 191 (4191): mcc: 0.8191, acc: 0.7439, precision: 0.8726, recall: 0.7737, f1: 0.8202, edges-srl-ontonotes_loss: 0.0156
09/16 09:19:42 AM: Update 4311: task edges-srl-ontonotes, batch 311 (4311): mcc: 0.8220, acc: 0.7477, precision: 0.8752, recall: 0.7768, f1: 0.8231, edges-srl-ontonotes_loss: 0.0154
09/16 09:19:52 AM: Update 4417: task edges-srl-ontonotes, batch 417 (4417): mcc: 0.8239, acc: 0.7503, precision: 0.8767, recall: 0.7790, f1: 0.8250, edges-srl-ontonotes_loss: 0.0153
09/16 09:20:02 AM: Update 4534: task edges-srl-ontonotes, batch 534 (4534): mcc: 0.8258, acc: 0.7529, precision: 0.8778, recall: 0.7816, f1: 0.8269, edges-srl-ontonotes_loss: 0.0150
09/16 09:20:12 AM: Update 4641: task edges-srl-ontonotes, batch 641 (4641): mcc: 0.8266, acc: 0.7549, precision: 0.8778, recall: 0.7830, f1: 0.8277, edges-srl-ontonotes_loss: 0.0150
09/16 09:20:22 AM: Update 4724: task edges-srl-ontonotes, batch 724 (4724): mcc: 0.8252, acc: 0.7533, precision: 0.8768, recall: 0.7814, f1: 0.8264, edges-srl-ontonotes_loss: 0.0151
09/16 09:20:32 AM: Update 4818: task edges-srl-ontonotes, batch 818 (4818): mcc: 0.8228, acc: 0.7501, precision: 0.8748, recall: 0.7786, f1: 0.8239, edges-srl-ontonotes_loss: 0.0152
09/16 09:20:42 AM: Update 4921: task edges-srl-ontonotes, batch 921 (4921): mcc: 0.8213, acc: 0.7480, precision: 0.8739, recall: 0.7765, f1: 0.8224, edges-srl-ontonotes_loss: 0.0153
09/16 09:20:50 AM: ***** Step 5000 / Validation 5 *****
09/16 09:20:50 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:20:50 AM: Validating...
09/16 09:20:53 AM: Evaluate: task edges-srl-ontonotes, batch 29 (157): mcc: 0.8419, acc: 0.7744, precision: 0.9027, recall: 0.7894, f1: 0.8423, edges-srl-ontonotes_loss: 0.0133
09/16 09:21:03 AM: Evaluate: task edges-srl-ontonotes, batch 154 (157): mcc: 0.8434, acc: 0.7797, precision: 0.8992, recall: 0.7953, f1: 0.8441, edges-srl-ontonotes_loss: 0.0135
09/16 09:21:03 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:21:03 AM: Best result seen so far for macro.
09/16 09:21:03 AM: Updating LR scheduler:
09/16 09:21:03 AM: 	Best result seen so far for macro_avg: 0.844
09/16 09:21:03 AM: 	# validation passes without improvement: 0
09/16 09:21:03 AM: edges-srl-ontonotes_loss: training: 0.015316 validation: 0.013546
09/16 09:21:03 AM: macro_avg: validation: 0.843722
09/16 09:21:03 AM: micro_avg: validation: 0.000000
09/16 09:21:03 AM: edges-srl-ontonotes_mcc: training: 0.820880 validation: 0.843097
09/16 09:21:03 AM: edges-srl-ontonotes_acc: training: 0.747338 validation: 0.779309
09/16 09:21:03 AM: edges-srl-ontonotes_precision: training: 0.873688 validation: 0.898790
09/16 09:21:03 AM: edges-srl-ontonotes_recall: training: 0.776038 validation: 0.795012
09/16 09:21:03 AM: edges-srl-ontonotes_f1: training: 0.821973 validation: 0.843722
09/16 09:21:03 AM: Global learning rate: 0.0001
09/16 09:21:03 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:21:13 AM: Update 5089: task edges-srl-ontonotes, batch 89 (5089): mcc: 0.8353, acc: 0.7656, precision: 0.8796, recall: 0.7976, f1: 0.8366, edges-srl-ontonotes_loss: 0.0143
09/16 09:21:23 AM: Update 5214: task edges-srl-ontonotes, batch 214 (5214): mcc: 0.8443, acc: 0.7763, precision: 0.8876, recall: 0.8074, f1: 0.8456, edges-srl-ontonotes_loss: 0.0136
09/16 09:21:33 AM: Update 5325: task edges-srl-ontonotes, batch 325 (5325): mcc: 0.8500, acc: 0.7842, precision: 0.8920, recall: 0.8141, f1: 0.8512, edges-srl-ontonotes_loss: 0.0132
09/16 09:21:43 AM: Update 5467: task edges-srl-ontonotes, batch 467 (5467): mcc: 0.8607, acc: 0.7986, precision: 0.9006, recall: 0.8265, f1: 0.8620, edges-srl-ontonotes_loss: 0.0124
09/16 09:21:53 AM: Update 5619: task edges-srl-ontonotes, batch 619 (5619): mcc: 0.8688, acc: 0.8095, precision: 0.9065, recall: 0.8363, f1: 0.8700, edges-srl-ontonotes_loss: 0.0118
09/16 09:22:03 AM: Update 5739: task edges-srl-ontonotes, batch 739 (5739): mcc: 0.8716, acc: 0.8134, precision: 0.9088, recall: 0.8396, f1: 0.8728, edges-srl-ontonotes_loss: 0.0116
09/16 09:22:13 AM: Update 5885: task edges-srl-ontonotes, batch 885 (5885): mcc: 0.8759, acc: 0.8191, precision: 0.9121, recall: 0.8446, f1: 0.8771, edges-srl-ontonotes_loss: 0.0114
09/16 09:22:23 AM: Update 5968: task edges-srl-ontonotes, batch 968 (5968): mcc: 0.8771, acc: 0.8207, precision: 0.9129, recall: 0.8460, f1: 0.8782, edges-srl-ontonotes_loss: 0.0113
09/16 09:22:26 AM: ***** Step 6000 / Validation 6 *****
09/16 09:22:26 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:22:26 AM: Validating...
09/16 09:22:33 AM: Evaluate: task edges-srl-ontonotes, batch 90 (157): mcc: 0.8546, acc: 0.7963, precision: 0.9109, recall: 0.8056, f1: 0.8550, edges-srl-ontonotes_loss: 0.0128
09/16 09:22:38 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:22:38 AM: Best result seen so far for macro.
09/16 09:22:38 AM: Updating LR scheduler:
09/16 09:22:38 AM: 	Best result seen so far for macro_avg: 0.860
09/16 09:22:38 AM: 	# validation passes without improvement: 0
09/16 09:22:38 AM: edges-srl-ontonotes_loss: training: 0.011243 validation: 0.012475
09/16 09:22:38 AM: macro_avg: validation: 0.859532
09/16 09:22:38 AM: micro_avg: validation: 0.000000
09/16 09:22:38 AM: edges-srl-ontonotes_mcc: training: 0.877690 validation: 0.858820
09/16 09:22:38 AM: edges-srl-ontonotes_acc: training: 0.821490 validation: 0.804018
09/16 09:22:38 AM: edges-srl-ontonotes_precision: training: 0.913450 validation: 0.909372
09/16 09:22:38 AM: edges-srl-ontonotes_recall: training: 0.846744 validation: 0.814872
09/16 09:22:38 AM: edges-srl-ontonotes_f1: training: 0.878833 validation: 0.859532
09/16 09:22:38 AM: Global learning rate: 0.0001
09/16 09:22:38 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:22:43 AM: Update 6074: task edges-srl-ontonotes, batch 74 (6074): mcc: 0.8897, acc: 0.8405, precision: 0.9217, recall: 0.8620, f1: 0.8909, edges-srl-ontonotes_loss: 0.0103
09/16 09:22:53 AM: Update 6226: task edges-srl-ontonotes, batch 226 (6226): mcc: 0.8936, acc: 0.8467, precision: 0.9240, recall: 0.8672, f1: 0.8947, edges-srl-ontonotes_loss: 0.0100
09/16 09:23:03 AM: Update 6361: task edges-srl-ontonotes, batch 361 (6361): mcc: 0.8918, acc: 0.8441, precision: 0.9216, recall: 0.8660, f1: 0.8929, edges-srl-ontonotes_loss: 0.0101
09/16 09:23:13 AM: Update 6511: task edges-srl-ontonotes, batch 511 (6511): mcc: 0.8917, acc: 0.8447, precision: 0.9205, recall: 0.8669, f1: 0.8929, edges-srl-ontonotes_loss: 0.0100
09/16 09:23:23 AM: Update 6638: task edges-srl-ontonotes, batch 638 (6638): mcc: 0.8871, acc: 0.8386, precision: 0.9172, recall: 0.8612, f1: 0.8883, edges-srl-ontonotes_loss: 0.0104
09/16 09:23:33 AM: Update 6765: task edges-srl-ontonotes, batch 765 (6765): mcc: 0.8828, acc: 0.8327, precision: 0.9140, recall: 0.8559, f1: 0.8840, edges-srl-ontonotes_loss: 0.0107
09/16 09:23:43 AM: Update 6880: task edges-srl-ontonotes, batch 880 (6880): mcc: 0.8791, acc: 0.8277, precision: 0.9112, recall: 0.8516, f1: 0.8804, edges-srl-ontonotes_loss: 0.0110
09/16 09:23:53 AM: Update 6986: task edges-srl-ontonotes, batch 986 (6986): mcc: 0.8740, acc: 0.8213, precision: 0.9075, recall: 0.8453, f1: 0.8753, edges-srl-ontonotes_loss: 0.0113
09/16 09:23:55 AM: ***** Step 7000 / Validation 7 *****
09/16 09:23:55 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:23:55 AM: Validating...
09/16 09:24:05 AM: Evaluate: task edges-srl-ontonotes, batch 104 (157): mcc: 0.8682, acc: 0.8193, precision: 0.9144, recall: 0.8280, f1: 0.8690, edges-srl-ontonotes_loss: 0.0114
09/16 09:24:09 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:24:09 AM: Best result seen so far for macro.
09/16 09:24:09 AM: Updating LR scheduler:
09/16 09:24:09 AM: 	Best result seen so far for macro_avg: 0.869
09/16 09:24:09 AM: 	# validation passes without improvement: 0
09/16 09:24:09 AM: edges-srl-ontonotes_loss: training: 0.011380 validation: 0.011530
09/16 09:24:09 AM: macro_avg: validation: 0.869247
09/16 09:24:09 AM: micro_avg: validation: 0.000000
09/16 09:24:09 AM: edges-srl-ontonotes_mcc: training: 0.873324 validation: 0.868287
09/16 09:24:09 AM: edges-srl-ontonotes_acc: training: 0.820364 validation: 0.822339
09/16 09:24:09 AM: edges-srl-ontonotes_precision: training: 0.906945 validation: 0.911417
09/16 09:24:09 AM: edges-srl-ontonotes_recall: training: 0.844504 validation: 0.830806
09/16 09:24:09 AM: edges-srl-ontonotes_f1: training: 0.874611 validation: 0.869247
09/16 09:24:09 AM: Global learning rate: 0.0001
09/16 09:24:09 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:24:15 AM: Update 7075: task edges-srl-ontonotes, batch 75 (7075): mcc: 0.8458, acc: 0.7839, precision: 0.8872, recall: 0.8105, f1: 0.8472, edges-srl-ontonotes_loss: 0.0134
09/16 09:24:25 AM: Update 7196: task edges-srl-ontonotes, batch 196 (7196): mcc: 0.8400, acc: 0.7786, precision: 0.8813, recall: 0.8050, f1: 0.8414, edges-srl-ontonotes_loss: 0.0138
09/16 09:24:35 AM: Update 7315: task edges-srl-ontonotes, batch 315 (7315): mcc: 0.8449, acc: 0.7848, precision: 0.8870, recall: 0.8091, f1: 0.8462, edges-srl-ontonotes_loss: 0.0135
09/16 09:24:45 AM: Update 7452: task edges-srl-ontonotes, batch 452 (7452): mcc: 0.8511, acc: 0.7920, precision: 0.8915, recall: 0.8166, f1: 0.8524, edges-srl-ontonotes_loss: 0.0130
09/16 09:24:55 AM: Update 7574: task edges-srl-ontonotes, batch 574 (7574): mcc: 0.8553, acc: 0.7974, precision: 0.8949, recall: 0.8215, f1: 0.8566, edges-srl-ontonotes_loss: 0.0127
09/16 09:25:05 AM: Update 7705: task edges-srl-ontonotes, batch 705 (7705): mcc: 0.8580, acc: 0.8013, precision: 0.8964, recall: 0.8253, f1: 0.8594, edges-srl-ontonotes_loss: 0.0124
09/16 09:25:15 AM: Update 7835: task edges-srl-ontonotes, batch 835 (7835): mcc: 0.8598, acc: 0.8039, precision: 0.8978, recall: 0.8273, f1: 0.8611, edges-srl-ontonotes_loss: 0.0123
09/16 09:25:25 AM: Update 7938: task edges-srl-ontonotes, batch 938 (7938): mcc: 0.8603, acc: 0.8046, precision: 0.8981, recall: 0.8280, f1: 0.8616, edges-srl-ontonotes_loss: 0.0123
09/16 09:25:30 AM: ***** Step 8000 / Validation 8 *****
09/16 09:25:30 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:25:30 AM: Validating...
09/16 09:25:36 AM: Evaluate: task edges-srl-ontonotes, batch 66 (157): mcc: 0.8674, acc: 0.8217, precision: 0.9081, recall: 0.8322, f1: 0.8685, edges-srl-ontonotes_loss: 0.0114
09/16 09:25:43 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:25:43 AM: Best result seen so far for macro.
09/16 09:25:43 AM: Updating LR scheduler:
09/16 09:25:43 AM: 	Best result seen so far for macro_avg: 0.879
09/16 09:25:43 AM: 	# validation passes without improvement: 0
09/16 09:25:43 AM: edges-srl-ontonotes_loss: training: 0.012250 validation: 0.010612
09/16 09:25:43 AM: macro_avg: validation: 0.878708
09/16 09:25:43 AM: micro_avg: validation: 0.000000
09/16 09:25:43 AM: edges-srl-ontonotes_mcc: training: 0.860521 validation: 0.877592
09/16 09:25:43 AM: edges-srl-ontonotes_acc: training: 0.804791 validation: 0.835732
09/16 09:25:43 AM: edges-srl-ontonotes_precision: training: 0.898292 validation: 0.914081
09/16 09:25:43 AM: edges-srl-ontonotes_recall: training: 0.828210 validation: 0.845970
09/16 09:25:43 AM: edges-srl-ontonotes_f1: training: 0.861829 validation: 0.878708
09/16 09:25:43 AM: Global learning rate: 0.0001
09/16 09:25:43 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:25:46 AM: Update 8035: task edges-srl-ontonotes, batch 35 (8035): mcc: 0.8483, acc: 0.7900, precision: 0.8886, recall: 0.8140, f1: 0.8496, edges-srl-ontonotes_loss: 0.0129
09/16 09:25:56 AM: Update 8167: task edges-srl-ontonotes, batch 167 (8167): mcc: 0.8534, acc: 0.7973, precision: 0.8902, recall: 0.8222, f1: 0.8549, edges-srl-ontonotes_loss: 0.0125
09/16 09:26:06 AM: Update 8263: task edges-srl-ontonotes, batch 263 (8263): mcc: 0.8499, acc: 0.7915, precision: 0.8876, recall: 0.8179, f1: 0.8513, edges-srl-ontonotes_loss: 0.0129
09/16 09:26:16 AM: Update 8398: task edges-srl-ontonotes, batch 398 (8398): mcc: 0.8473, acc: 0.7880, precision: 0.8866, recall: 0.8141, f1: 0.8488, edges-srl-ontonotes_loss: 0.0130
09/16 09:26:26 AM: Update 8512: task edges-srl-ontonotes, batch 512 (8512): mcc: 0.8459, acc: 0.7859, precision: 0.8855, recall: 0.8123, f1: 0.8473, edges-srl-ontonotes_loss: 0.0131
09/16 09:26:36 AM: Update 8631: task edges-srl-ontonotes, batch 631 (8631): mcc: 0.8458, acc: 0.7856, precision: 0.8858, recall: 0.8118, f1: 0.8472, edges-srl-ontonotes_loss: 0.0131
09/16 09:26:46 AM: Update 8753: task edges-srl-ontonotes, batch 753 (8753): mcc: 0.8468, acc: 0.7867, precision: 0.8868, recall: 0.8129, f1: 0.8482, edges-srl-ontonotes_loss: 0.0130
09/16 09:26:56 AM: Update 8859: task edges-srl-ontonotes, batch 859 (8859): mcc: 0.8461, acc: 0.7860, precision: 0.8858, recall: 0.8123, f1: 0.8475, edges-srl-ontonotes_loss: 0.0131
09/16 09:27:06 AM: Update 8982: task edges-srl-ontonotes, batch 982 (8982): mcc: 0.8419, acc: 0.7809, precision: 0.8826, recall: 0.8074, f1: 0.8433, edges-srl-ontonotes_loss: 0.0133
09/16 09:27:07 AM: ***** Step 9000 / Validation 9 *****
09/16 09:27:07 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:27:07 AM: Validating...
09/16 09:27:16 AM: Evaluate: task edges-srl-ontonotes, batch 114 (157): mcc: 0.8753, acc: 0.8290, precision: 0.9191, recall: 0.8371, f1: 0.8762, edges-srl-ontonotes_loss: 0.0105
09/16 09:27:19 AM: Updating LR scheduler:
09/16 09:27:19 AM: 	Best result seen so far for macro_avg: 0.879
09/16 09:27:19 AM: 	# validation passes without improvement: 1
09/16 09:27:19 AM: edges-srl-ontonotes_loss: training: 0.013336 validation: 0.010530
09/16 09:27:19 AM: macro_avg: validation: 0.877735
09/16 09:27:19 AM: micro_avg: validation: 0.000000
09/16 09:27:19 AM: edges-srl-ontonotes_mcc: training: 0.841615 validation: 0.876853
09/16 09:27:19 AM: edges-srl-ontonotes_acc: training: 0.780610 validation: 0.831576
09/16 09:27:19 AM: edges-srl-ontonotes_precision: training: 0.882306 validation: 0.919060
09/16 09:27:19 AM: edges-srl-ontonotes_recall: training: 0.807162 validation: 0.839966
09/16 09:27:19 AM: edges-srl-ontonotes_f1: training: 0.843063 validation: 0.877735
09/16 09:27:19 AM: Global learning rate: 0.0001
09/16 09:27:19 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:27:26 AM: Update 9074: task edges-srl-ontonotes, batch 74 (9074): mcc: 0.8345, acc: 0.7716, precision: 0.8767, recall: 0.7988, f1: 0.8360, edges-srl-ontonotes_loss: 0.0139
09/16 09:27:36 AM: Update 9152: task edges-srl-ontonotes, batch 152 (9152): mcc: 0.8322, acc: 0.7704, precision: 0.8756, recall: 0.7955, f1: 0.8336, edges-srl-ontonotes_loss: 0.0142
09/16 09:27:46 AM: Update 9269: task edges-srl-ontonotes, batch 269 (9269): mcc: 0.8294, acc: 0.7655, precision: 0.8745, recall: 0.7912, f1: 0.8308, edges-srl-ontonotes_loss: 0.0142
09/16 09:27:56 AM: Update 9384: task edges-srl-ontonotes, batch 384 (9384): mcc: 0.8327, acc: 0.7695, precision: 0.8772, recall: 0.7949, f1: 0.8340, edges-srl-ontonotes_loss: 0.0140
09/16 09:28:06 AM: Update 9483: task edges-srl-ontonotes, batch 483 (9483): mcc: 0.8339, acc: 0.7708, precision: 0.8784, recall: 0.7961, f1: 0.8353, edges-srl-ontonotes_loss: 0.0138
09/16 09:28:16 AM: Update 9593: task edges-srl-ontonotes, batch 593 (9593): mcc: 0.8385, acc: 0.7765, precision: 0.8816, recall: 0.8019, f1: 0.8399, edges-srl-ontonotes_loss: 0.0135
09/16 09:28:26 AM: Update 9703: task edges-srl-ontonotes, batch 703 (9703): mcc: 0.8402, acc: 0.7790, precision: 0.8829, recall: 0.8040, f1: 0.8416, edges-srl-ontonotes_loss: 0.0134
09/16 09:28:36 AM: Update 9810: task edges-srl-ontonotes, batch 810 (9810): mcc: 0.8414, acc: 0.7808, precision: 0.8837, recall: 0.8055, f1: 0.8428, edges-srl-ontonotes_loss: 0.0133
09/16 09:28:46 AM: Update 9924: task edges-srl-ontonotes, batch 924 (9924): mcc: 0.8433, acc: 0.7835, precision: 0.8849, recall: 0.8080, f1: 0.8447, edges-srl-ontonotes_loss: 0.0132
09/16 09:28:53 AM: ***** Step 10000 / Validation 10 *****
09/16 09:28:53 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:28:53 AM: Validating...
09/16 09:28:56 AM: Evaluate: task edges-srl-ontonotes, batch 42 (157): mcc: 0.8677, acc: 0.8218, precision: 0.9108, recall: 0.8303, f1: 0.8687, edges-srl-ontonotes_loss: 0.0113
09/16 09:29:05 AM: Updating LR scheduler:
09/16 09:29:05 AM: 	Best result seen so far for macro_avg: 0.879
09/16 09:29:05 AM: 	# validation passes without improvement: 2
09/16 09:29:05 AM: edges-srl-ontonotes_loss: training: 0.013123 validation: 0.010507
09/16 09:29:05 AM: macro_avg: validation: 0.877864
09/16 09:29:05 AM: micro_avg: validation: 0.000000
09/16 09:29:05 AM: edges-srl-ontonotes_mcc: training: 0.843636 validation: 0.876736
09/16 09:29:05 AM: edges-srl-ontonotes_acc: training: 0.783660 validation: 0.836194
09/16 09:29:05 AM: edges-srl-ontonotes_precision: training: 0.885107 validation: 0.913242
09/16 09:29:05 AM: edges-srl-ontonotes_recall: training: 0.808405 validation: 0.845124
09/16 09:29:05 AM: edges-srl-ontonotes_f1: training: 0.845019 validation: 0.877864
09/16 09:29:05 AM: Global learning rate: 0.0001
09/16 09:29:05 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:29:06 AM: Update 10010: task edges-srl-ontonotes, batch 10 (10010): mcc: 0.8658, acc: 0.8104, precision: 0.9051, recall: 0.8319, f1: 0.8669, edges-srl-ontonotes_loss: 0.0111
09/16 09:29:16 AM: Update 10092: task edges-srl-ontonotes, batch 92 (10092): mcc: 0.8574, acc: 0.8031, precision: 0.8960, recall: 0.8244, f1: 0.8587, edges-srl-ontonotes_loss: 0.0122
09/16 09:29:26 AM: Update 10208: task edges-srl-ontonotes, batch 208 (10208): mcc: 0.8572, acc: 0.8016, precision: 0.8971, recall: 0.8231, f1: 0.8585, edges-srl-ontonotes_loss: 0.0121
09/16 09:29:37 AM: Update 10324: task edges-srl-ontonotes, batch 324 (10324): mcc: 0.8586, acc: 0.8025, precision: 0.8976, recall: 0.8251, f1: 0.8599, edges-srl-ontonotes_loss: 0.0121
09/16 09:29:47 AM: Update 10431: task edges-srl-ontonotes, batch 431 (10431): mcc: 0.8580, acc: 0.8028, precision: 0.8962, recall: 0.8254, f1: 0.8593, edges-srl-ontonotes_loss: 0.0121
09/16 09:29:57 AM: Update 10551: task edges-srl-ontonotes, batch 551 (10551): mcc: 0.8558, acc: 0.8000, precision: 0.8949, recall: 0.8225, f1: 0.8572, edges-srl-ontonotes_loss: 0.0123
09/16 09:30:07 AM: Update 10666: task edges-srl-ontonotes, batch 666 (10666): mcc: 0.8542, acc: 0.7974, precision: 0.8940, recall: 0.8203, f1: 0.8556, edges-srl-ontonotes_loss: 0.0124
09/16 09:30:17 AM: Update 10774: task edges-srl-ontonotes, batch 774 (10774): mcc: 0.8532, acc: 0.7958, precision: 0.8936, recall: 0.8188, f1: 0.8545, edges-srl-ontonotes_loss: 0.0124
09/16 09:30:27 AM: Update 10899: task edges-srl-ontonotes, batch 899 (10899): mcc: 0.8535, acc: 0.7957, precision: 0.8942, recall: 0.8187, f1: 0.8548, edges-srl-ontonotes_loss: 0.0124
09/16 09:30:35 AM: ***** Step 11000 / Validation 11 *****
09/16 09:30:35 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:30:35 AM: Validating...
09/16 09:30:37 AM: Evaluate: task edges-srl-ontonotes, batch 21 (157): mcc: 0.8700, acc: 0.8261, precision: 0.9116, recall: 0.8339, f1: 0.8710, edges-srl-ontonotes_loss: 0.0106
09/16 09:30:47 AM: Evaluate: task edges-srl-ontonotes, batch 142 (157): mcc: 0.8740, acc: 0.8300, precision: 0.9154, recall: 0.8379, f1: 0.8749, edges-srl-ontonotes_loss: 0.0107
09/16 09:30:48 AM: Updating LR scheduler:
09/16 09:30:48 AM: 	Best result seen so far for macro_avg: 0.879
09/16 09:30:48 AM: 	# validation passes without improvement: 3
09/16 09:30:48 AM: edges-srl-ontonotes_loss: training: 0.012456 validation: 0.010951
09/16 09:30:48 AM: macro_avg: validation: 0.873166
09/16 09:30:48 AM: micro_avg: validation: 0.000000
09/16 09:30:48 AM: edges-srl-ontonotes_mcc: training: 0.853214 validation: 0.872192
09/16 09:30:48 AM: edges-srl-ontonotes_acc: training: 0.795355 validation: 0.828189
09/16 09:30:48 AM: edges-srl-ontonotes_precision: training: 0.893744 validation: 0.913834
09/16 09:30:48 AM: edges-srl-ontonotes_recall: training: 0.818569 validation: 0.835963
09/16 09:30:48 AM: edges-srl-ontonotes_f1: training: 0.854506 validation: 0.873166
09/16 09:30:48 AM: Global learning rate: 0.0001
09/16 09:30:48 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:30:57 AM: Update 11096: task edges-srl-ontonotes, batch 96 (11096): mcc: 0.8521, acc: 0.7953, precision: 0.8906, recall: 0.8195, f1: 0.8535, edges-srl-ontonotes_loss: 0.0127
09/16 09:31:07 AM: Update 11209: task edges-srl-ontonotes, batch 209 (11209): mcc: 0.8493, acc: 0.7922, precision: 0.8898, recall: 0.8148, f1: 0.8507, edges-srl-ontonotes_loss: 0.0128
09/16 09:31:19 AM: Update 11316: task edges-srl-ontonotes, batch 316 (11316): mcc: 0.8500, acc: 0.7920, precision: 0.8907, recall: 0.8154, f1: 0.8514, edges-srl-ontonotes_loss: 0.0126
09/16 09:31:29 AM: Update 11432: task edges-srl-ontonotes, batch 432 (11432): mcc: 0.8505, acc: 0.7934, precision: 0.8901, recall: 0.8167, f1: 0.8518, edges-srl-ontonotes_loss: 0.0126
09/16 09:31:39 AM: Update 11550: task edges-srl-ontonotes, batch 550 (11550): mcc: 0.8527, acc: 0.7966, precision: 0.8918, recall: 0.8194, f1: 0.8541, edges-srl-ontonotes_loss: 0.0124
09/16 09:31:49 AM: Update 11656: task edges-srl-ontonotes, batch 656 (11656): mcc: 0.8541, acc: 0.7982, precision: 0.8929, recall: 0.8211, f1: 0.8555, edges-srl-ontonotes_loss: 0.0124
09/16 09:31:59 AM: Update 11773: task edges-srl-ontonotes, batch 773 (11773): mcc: 0.8555, acc: 0.7999, precision: 0.8940, recall: 0.8226, f1: 0.8568, edges-srl-ontonotes_loss: 0.0123
09/16 09:32:09 AM: Update 11888: task edges-srl-ontonotes, batch 888 (11888): mcc: 0.8571, acc: 0.8020, precision: 0.8953, recall: 0.8245, f1: 0.8584, edges-srl-ontonotes_loss: 0.0121
09/16 09:32:19 AM: Update 11987: task edges-srl-ontonotes, batch 987 (11987): mcc: 0.8555, acc: 0.7997, precision: 0.8942, recall: 0.8225, f1: 0.8568, edges-srl-ontonotes_loss: 0.0123
09/16 09:32:20 AM: ***** Step 12000 / Validation 12 *****
09/16 09:32:20 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:32:20 AM: Validating...
09/16 09:32:29 AM: Evaluate: task edges-srl-ontonotes, batch 121 (157): mcc: 0.8751, acc: 0.8326, precision: 0.9161, recall: 0.8395, f1: 0.8761, edges-srl-ontonotes_loss: 0.0107
09/16 09:32:32 AM: Updating LR scheduler:
09/16 09:32:32 AM: 	Best result seen so far for macro_avg: 0.879
09/16 09:32:32 AM: 	# validation passes without improvement: 0
09/16 09:32:32 AM: edges-srl-ontonotes_loss: training: 0.012272 validation: 0.010674
09/16 09:32:32 AM: macro_avg: validation: 0.877248
09/16 09:32:32 AM: micro_avg: validation: 0.000000
09/16 09:32:32 AM: edges-srl-ontonotes_mcc: training: 0.855347 validation: 0.876274
09/16 09:32:32 AM: edges-srl-ontonotes_acc: training: 0.799415 validation: 0.834039
09/16 09:32:32 AM: edges-srl-ontonotes_precision: training: 0.894154 validation: 0.916618
09/16 09:32:32 AM: edges-srl-ontonotes_recall: training: 0.822228 validation: 0.841121
09/16 09:32:32 AM: edges-srl-ontonotes_f1: training: 0.856684 validation: 0.877248
09/16 09:32:32 AM: Global learning rate: 5e-05
09/16 09:32:32 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:32:39 AM: Update 12075: task edges-srl-ontonotes, batch 75 (12075): mcc: 0.8326, acc: 0.7697, precision: 0.8784, recall: 0.7939, f1: 0.8340, edges-srl-ontonotes_loss: 0.0140
09/16 09:32:49 AM: Update 12182: task edges-srl-ontonotes, batch 182 (12182): mcc: 0.8379, acc: 0.7760, precision: 0.8840, recall: 0.7987, f1: 0.8392, edges-srl-ontonotes_loss: 0.0134
09/16 09:32:59 AM: Update 12263: task edges-srl-ontonotes, batch 263 (12263): mcc: 0.8401, acc: 0.7780, precision: 0.8862, recall: 0.8007, f1: 0.8413, edges-srl-ontonotes_loss: 0.0133
09/16 09:33:09 AM: Update 12391: task edges-srl-ontonotes, batch 391 (12391): mcc: 0.8492, acc: 0.7909, precision: 0.8912, recall: 0.8133, f1: 0.8505, edges-srl-ontonotes_loss: 0.0126
09/16 09:33:19 AM: Update 12518: task edges-srl-ontonotes, batch 518 (12518): mcc: 0.8567, acc: 0.8005, precision: 0.8961, recall: 0.8231, f1: 0.8580, edges-srl-ontonotes_loss: 0.0121
09/16 09:33:29 AM: Update 12654: task edges-srl-ontonotes, batch 654 (12654): mcc: 0.8644, acc: 0.8103, precision: 0.9017, recall: 0.8324, f1: 0.8657, edges-srl-ontonotes_loss: 0.0115
09/16 09:33:39 AM: Update 12803: task edges-srl-ontonotes, batch 803 (12803): mcc: 0.8734, acc: 0.8219, precision: 0.9083, recall: 0.8434, f1: 0.8746, edges-srl-ontonotes_loss: 0.0109
09/16 09:33:49 AM: Update 12945: task edges-srl-ontonotes, batch 945 (12945): mcc: 0.8784, acc: 0.8285, precision: 0.9120, recall: 0.8494, f1: 0.8796, edges-srl-ontonotes_loss: 0.0105
09/16 09:33:53 AM: ***** Step 13000 / Validation 13 *****
09/16 09:33:53 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:33:53 AM: Validating...
09/16 09:33:59 AM: Evaluate: task edges-srl-ontonotes, batch 85 (157): mcc: 0.8752, acc: 0.8302, precision: 0.9186, recall: 0.8372, f1: 0.8760, edges-srl-ontonotes_loss: 0.0108
09/16 09:34:05 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:34:05 AM: Best result seen so far for macro.
09/16 09:34:05 AM: Updating LR scheduler:
09/16 09:34:05 AM: 	Best result seen so far for macro_avg: 0.882
09/16 09:34:05 AM: 	# validation passes without improvement: 0
09/16 09:34:05 AM: edges-srl-ontonotes_loss: training: 0.010413 validation: 0.010383
09/16 09:34:05 AM: macro_avg: validation: 0.882056
09/16 09:34:05 AM: micro_avg: validation: 0.000000
09/16 09:34:05 AM: edges-srl-ontonotes_mcc: training: 0.880295 validation: 0.881049
09/16 09:34:05 AM: edges-srl-ontonotes_acc: training: 0.831114 validation: 0.840274
09/16 09:34:05 AM: edges-srl-ontonotes_precision: training: 0.913619 validation: 0.918996
09/16 09:34:05 AM: edges-srl-ontonotes_recall: training: 0.851548 validation: 0.847972
09/16 09:34:05 AM: edges-srl-ontonotes_f1: training: 0.881492 validation: 0.882056
09/16 09:34:05 AM: Global learning rate: 5e-05
09/16 09:34:05 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:34:10 AM: Update 13057: task edges-srl-ontonotes, batch 57 (13057): mcc: 0.9027, acc: 0.8655, precision: 0.9291, recall: 0.8799, f1: 0.9038, edges-srl-ontonotes_loss: 0.0090
09/16 09:34:20 AM: Update 13178: task edges-srl-ontonotes, batch 178 (13178): mcc: 0.9085, acc: 0.8692, precision: 0.9359, recall: 0.8846, f1: 0.9095, edges-srl-ontonotes_loss: 0.0084
09/16 09:34:30 AM: Update 13311: task edges-srl-ontonotes, batch 311 (13311): mcc: 0.9083, acc: 0.8686, precision: 0.9349, recall: 0.8851, f1: 0.9093, edges-srl-ontonotes_loss: 0.0085
09/16 09:34:40 AM: Update 13453: task edges-srl-ontonotes, batch 453 (13453): mcc: 0.9096, acc: 0.8707, precision: 0.9353, recall: 0.8873, f1: 0.9107, edges-srl-ontonotes_loss: 0.0084
09/16 09:34:50 AM: Update 13543: task edges-srl-ontonotes, batch 543 (13543): mcc: 0.9081, acc: 0.8690, precision: 0.9337, recall: 0.8858, f1: 0.9091, edges-srl-ontonotes_loss: 0.0085
09/16 09:35:00 AM: Update 13691: task edges-srl-ontonotes, batch 691 (13691): mcc: 0.9081, acc: 0.8694, precision: 0.9331, recall: 0.8863, f1: 0.9091, edges-srl-ontonotes_loss: 0.0085
09/16 09:35:10 AM: Update 13816: task edges-srl-ontonotes, batch 816 (13816): mcc: 0.9077, acc: 0.8695, precision: 0.9322, recall: 0.8865, f1: 0.9088, edges-srl-ontonotes_loss: 0.0086
09/16 09:35:20 AM: Update 13912: task edges-srl-ontonotes, batch 912 (13912): mcc: 0.9042, acc: 0.8646, precision: 0.9297, recall: 0.8822, f1: 0.9053, edges-srl-ontonotes_loss: 0.0088
09/16 09:35:28 AM: ***** Step 14000 / Validation 14 *****
09/16 09:35:28 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:35:28 AM: Validating...
09/16 09:35:30 AM: Evaluate: task edges-srl-ontonotes, batch 19 (157): mcc: 0.8951, acc: 0.8555, precision: 0.9310, recall: 0.8635, f1: 0.8960, edges-srl-ontonotes_loss: 0.0090
09/16 09:35:40 AM: Evaluate: task edges-srl-ontonotes, batch 139 (157): mcc: 0.8879, acc: 0.8507, precision: 0.9214, recall: 0.8587, f1: 0.8889, edges-srl-ontonotes_loss: 0.0097
09/16 09:35:41 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:35:41 AM: Best result seen so far for macro.
09/16 09:35:41 AM: Updating LR scheduler:
09/16 09:35:41 AM: 	Best result seen so far for macro_avg: 0.886
09/16 09:35:41 AM: 	# validation passes without improvement: 0
09/16 09:35:41 AM: edges-srl-ontonotes_loss: training: 0.009023 validation: 0.009974
09/16 09:35:41 AM: macro_avg: validation: 0.886090
09/16 09:35:41 AM: micro_avg: validation: 0.000000
09/16 09:35:41 AM: edges-srl-ontonotes_mcc: training: 0.901469 validation: 0.884977
09/16 09:35:41 AM: edges-srl-ontonotes_acc: training: 0.861172 validation: 0.847587
09/16 09:35:41 AM: edges-srl-ontonotes_precision: training: 0.927512 validation: 0.918754
09/16 09:35:41 AM: edges-srl-ontonotes_recall: training: 0.878974 validation: 0.855669
09/16 09:35:41 AM: edges-srl-ontonotes_f1: training: 0.902591 validation: 0.886090
09/16 09:35:41 AM: Global learning rate: 5e-05
09/16 09:35:41 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:35:50 AM: Update 14103: task edges-srl-ontonotes, batch 103 (14103): mcc: 0.8833, acc: 0.8365, precision: 0.9137, recall: 0.8571, f1: 0.8845, edges-srl-ontonotes_loss: 0.0104
09/16 09:36:00 AM: Update 14194: task edges-srl-ontonotes, batch 194 (14194): mcc: 0.8726, acc: 0.8226, precision: 0.9066, recall: 0.8435, f1: 0.8739, edges-srl-ontonotes_loss: 0.0112
09/16 09:36:10 AM: Update 14315: task edges-srl-ontonotes, batch 315 (14315): mcc: 0.8658, acc: 0.8145, precision: 0.9001, recall: 0.8366, f1: 0.8672, edges-srl-ontonotes_loss: 0.0116
09/16 09:36:20 AM: Update 14440: task edges-srl-ontonotes, batch 440 (14440): mcc: 0.8628, acc: 0.8108, precision: 0.8979, recall: 0.8330, f1: 0.8642, edges-srl-ontonotes_loss: 0.0118
09/16 09:36:30 AM: Update 14538: task edges-srl-ontonotes, batch 538 (14538): mcc: 0.8634, acc: 0.8118, precision: 0.8991, recall: 0.8330, f1: 0.8648, edges-srl-ontonotes_loss: 0.0117
09/16 09:36:40 AM: Update 14685: task edges-srl-ontonotes, batch 685 (14685): mcc: 0.8679, acc: 0.8177, precision: 0.9024, recall: 0.8383, f1: 0.8692, edges-srl-ontonotes_loss: 0.0114
09/16 09:36:50 AM: Update 14813: task edges-srl-ontonotes, batch 813 (14813): mcc: 0.8695, acc: 0.8198, precision: 0.9039, recall: 0.8401, f1: 0.8708, edges-srl-ontonotes_loss: 0.0113
09/16 09:37:00 AM: Update 14943: task edges-srl-ontonotes, batch 943 (14943): mcc: 0.8716, acc: 0.8220, precision: 0.9057, recall: 0.8424, f1: 0.8729, edges-srl-ontonotes_loss: 0.0111
09/16 09:37:05 AM: ***** Step 15000 / Validation 15 *****
09/16 09:37:05 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:37:05 AM: Validating...
09/16 09:37:10 AM: Evaluate: task edges-srl-ontonotes, batch 75 (157): mcc: 0.8890, acc: 0.8506, precision: 0.9254, recall: 0.8571, f1: 0.8899, edges-srl-ontonotes_loss: 0.0098
09/16 09:37:17 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:37:17 AM: Best result seen so far for macro.
09/16 09:37:17 AM: Updating LR scheduler:
09/16 09:37:17 AM: 	Best result seen so far for macro_avg: 0.893
09/16 09:37:17 AM: 	# validation passes without improvement: 0
09/16 09:37:17 AM: edges-srl-ontonotes_loss: training: 0.011079 validation: 0.009509
09/16 09:37:17 AM: macro_avg: validation: 0.892789
09/16 09:37:17 AM: micro_avg: validation: 0.000000
09/16 09:37:17 AM: edges-srl-ontonotes_mcc: training: 0.872339 validation: 0.891727
09/16 09:37:17 AM: edges-srl-ontonotes_acc: training: 0.823044 validation: 0.856208
09/16 09:37:17 AM: edges-srl-ontonotes_precision: training: 0.906121 validation: 0.924199
09/16 09:37:17 AM: edges-srl-ontonotes_recall: training: 0.843397 validation: 0.863444
09/16 09:37:17 AM: edges-srl-ontonotes_f1: training: 0.873635 validation: 0.892789
09/16 09:37:17 AM: Global learning rate: 5e-05
09/16 09:37:17 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:37:20 AM: Update 15044: task edges-srl-ontonotes, batch 44 (15044): mcc: 0.8781, acc: 0.8293, precision: 0.9087, recall: 0.8520, f1: 0.8794, edges-srl-ontonotes_loss: 0.0104
09/16 09:37:30 AM: Update 15162: task edges-srl-ontonotes, batch 162 (15162): mcc: 0.8775, acc: 0.8310, precision: 0.9079, recall: 0.8515, f1: 0.8788, edges-srl-ontonotes_loss: 0.0105
09/16 09:37:40 AM: Update 15293: task edges-srl-ontonotes, batch 293 (15293): mcc: 0.8735, acc: 0.8260, precision: 0.9046, recall: 0.8471, f1: 0.8749, edges-srl-ontonotes_loss: 0.0108
09/16 09:37:51 AM: Update 15420: task edges-srl-ontonotes, batch 420 (15420): mcc: 0.8726, acc: 0.8240, precision: 0.9044, recall: 0.8455, f1: 0.8740, edges-srl-ontonotes_loss: 0.0109
09/16 09:38:01 AM: Update 15513: task edges-srl-ontonotes, batch 513 (15513): mcc: 0.8707, acc: 0.8214, precision: 0.9030, recall: 0.8432, f1: 0.8721, edges-srl-ontonotes_loss: 0.0110
09/16 09:38:11 AM: Update 15640: task edges-srl-ontonotes, batch 640 (15640): mcc: 0.8684, acc: 0.8181, precision: 0.9016, recall: 0.8401, f1: 0.8697, edges-srl-ontonotes_loss: 0.0112
09/16 09:38:21 AM: Update 15753: task edges-srl-ontonotes, batch 753 (15753): mcc: 0.8670, acc: 0.8164, precision: 0.9005, recall: 0.8385, f1: 0.8684, edges-srl-ontonotes_loss: 0.0113
09/16 09:38:31 AM: Update 15882: task edges-srl-ontonotes, batch 882 (15882): mcc: 0.8660, acc: 0.8149, precision: 0.8997, recall: 0.8374, f1: 0.8674, edges-srl-ontonotes_loss: 0.0114
09/16 09:38:41 AM: ***** Step 16000 / Validation 16 *****
09/16 09:38:41 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:38:41 AM: Validating...
09/16 09:38:41 AM: Evaluate: task edges-srl-ontonotes, batch 1 (157): mcc: 0.9193, acc: 0.8876, precision: 0.9310, recall: 0.9101, f1: 0.9205, edges-srl-ontonotes_loss: 0.0072
09/16 09:38:51 AM: Evaluate: task edges-srl-ontonotes, batch 135 (157): mcc: 0.8939, acc: 0.8581, precision: 0.9263, recall: 0.8656, f1: 0.8949, edges-srl-ontonotes_loss: 0.0091
09/16 09:38:52 AM: Updating LR scheduler:
09/16 09:38:52 AM: 	Best result seen so far for macro_avg: 0.893
09/16 09:38:52 AM: 	# validation passes without improvement: 1
09/16 09:38:52 AM: edges-srl-ontonotes_loss: training: 0.011383 validation: 0.009299
09/16 09:38:52 AM: macro_avg: validation: 0.892348
09/16 09:38:52 AM: micro_avg: validation: 0.000000
09/16 09:38:52 AM: edges-srl-ontonotes_mcc: training: 0.865510 validation: 0.891293
09/16 09:38:52 AM: edges-srl-ontonotes_acc: training: 0.814366 validation: 0.855438
09/16 09:38:52 AM: edges-srl-ontonotes_precision: training: 0.899335 validation: 0.924136
09/16 09:38:52 AM: edges-srl-ontonotes_recall: training: 0.836729 validation: 0.862674
09/16 09:38:52 AM: edges-srl-ontonotes_f1: training: 0.866903 validation: 0.892348
09/16 09:38:52 AM: Global learning rate: 5e-05
09/16 09:38:52 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:39:01 AM: Update 16091: task edges-srl-ontonotes, batch 91 (16091): mcc: 0.8587, acc: 0.8072, precision: 0.8924, recall: 0.8303, f1: 0.8602, edges-srl-ontonotes_loss: 0.0118
09/16 09:39:11 AM: Update 16199: task edges-srl-ontonotes, batch 199 (16199): mcc: 0.8467, acc: 0.7911, precision: 0.8840, recall: 0.8153, f1: 0.8483, edges-srl-ontonotes_loss: 0.0128
09/16 09:39:21 AM: Update 16315: task edges-srl-ontonotes, batch 315 (16315): mcc: 0.8469, acc: 0.7901, precision: 0.8844, recall: 0.8152, f1: 0.8484, edges-srl-ontonotes_loss: 0.0128
09/16 09:39:31 AM: Update 16401: task edges-srl-ontonotes, batch 401 (16401): mcc: 0.8443, acc: 0.7869, precision: 0.8823, recall: 0.8123, f1: 0.8458, edges-srl-ontonotes_loss: 0.0130
09/16 09:39:41 AM: Update 16522: task edges-srl-ontonotes, batch 522 (16522): mcc: 0.8442, acc: 0.7864, precision: 0.8828, recall: 0.8116, f1: 0.8457, edges-srl-ontonotes_loss: 0.0129
09/16 09:39:51 AM: Update 16641: task edges-srl-ontonotes, batch 641 (16641): mcc: 0.8446, acc: 0.7868, precision: 0.8836, recall: 0.8117, f1: 0.8461, edges-srl-ontonotes_loss: 0.0129
09/16 09:40:01 AM: Update 16751: task edges-srl-ontonotes, batch 751 (16751): mcc: 0.8471, acc: 0.7897, precision: 0.8856, recall: 0.8145, f1: 0.8486, edges-srl-ontonotes_loss: 0.0127
09/16 09:40:11 AM: Update 16870: task edges-srl-ontonotes, batch 870 (16870): mcc: 0.8505, acc: 0.7938, precision: 0.8886, recall: 0.8181, f1: 0.8519, edges-srl-ontonotes_loss: 0.0124
09/16 09:40:21 AM: Update 16991: task edges-srl-ontonotes, batch 991 (16991): mcc: 0.8530, acc: 0.7967, precision: 0.8908, recall: 0.8209, f1: 0.8544, edges-srl-ontonotes_loss: 0.0122
09/16 09:40:23 AM: ***** Step 17000 / Validation 17 *****
09/16 09:40:23 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:40:23 AM: Validating...
09/16 09:40:31 AM: Evaluate: task edges-srl-ontonotes, batch 110 (157): mcc: 0.8892, acc: 0.8504, precision: 0.9255, recall: 0.8575, f1: 0.8902, edges-srl-ontonotes_loss: 0.0094
09/16 09:40:35 AM: Updating LR scheduler:
09/16 09:40:35 AM: 	Best result seen so far for macro_avg: 0.893
09/16 09:40:35 AM: 	# validation passes without improvement: 2
09/16 09:40:35 AM: edges-srl-ontonotes_loss: training: 0.012248 validation: 0.009407
09/16 09:40:35 AM: macro_avg: validation: 0.890971
09/16 09:40:35 AM: micro_avg: validation: 0.000000
09/16 09:40:35 AM: edges-srl-ontonotes_mcc: training: 0.852810 validation: 0.889940
09/16 09:40:35 AM: edges-srl-ontonotes_acc: training: 0.796499 validation: 0.852359
09/16 09:40:35 AM: edges-srl-ontonotes_precision: training: 0.890696 validation: 0.924012
09/16 09:40:35 AM: edges-srl-ontonotes_recall: training: 0.820620 validation: 0.860211
09/16 09:40:35 AM: edges-srl-ontonotes_f1: training: 0.854223 validation: 0.890971
09/16 09:40:35 AM: Global learning rate: 5e-05
09/16 09:40:35 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:40:41 AM: Update 17076: task edges-srl-ontonotes, batch 76 (17076): mcc: 0.8665, acc: 0.8164, precision: 0.9022, recall: 0.8359, f1: 0.8678, edges-srl-ontonotes_loss: 0.0114
09/16 09:40:51 AM: Update 17194: task edges-srl-ontonotes, batch 194 (17194): mcc: 0.8678, acc: 0.8173, precision: 0.9024, recall: 0.8383, f1: 0.8692, edges-srl-ontonotes_loss: 0.0111
09/16 09:41:01 AM: Update 17309: task edges-srl-ontonotes, batch 309 (17309): mcc: 0.8672, acc: 0.8161, precision: 0.9022, recall: 0.8372, f1: 0.8685, edges-srl-ontonotes_loss: 0.0112
09/16 09:41:11 AM: Update 17419: task edges-srl-ontonotes, batch 419 (17419): mcc: 0.8681, acc: 0.8171, precision: 0.9031, recall: 0.8382, f1: 0.8694, edges-srl-ontonotes_loss: 0.0111
09/16 09:41:22 AM: Update 17538: task edges-srl-ontonotes, batch 538 (17538): mcc: 0.8704, acc: 0.8198, precision: 0.9048, recall: 0.8410, f1: 0.8717, edges-srl-ontonotes_loss: 0.0110
09/16 09:41:32 AM: Update 17624: task edges-srl-ontonotes, batch 624 (17624): mcc: 0.8709, acc: 0.8207, precision: 0.9051, recall: 0.8416, f1: 0.8722, edges-srl-ontonotes_loss: 0.0110
09/16 09:41:42 AM: Update 17742: task edges-srl-ontonotes, batch 742 (17742): mcc: 0.8694, acc: 0.8186, precision: 0.9040, recall: 0.8397, f1: 0.8707, edges-srl-ontonotes_loss: 0.0111
09/16 09:41:52 AM: Update 17856: task edges-srl-ontonotes, batch 856 (17856): mcc: 0.8676, acc: 0.8163, precision: 0.9026, recall: 0.8376, f1: 0.8689, edges-srl-ontonotes_loss: 0.0112
09/16 09:42:02 AM: Update 17963: task edges-srl-ontonotes, batch 963 (17963): mcc: 0.8665, acc: 0.8149, precision: 0.9017, recall: 0.8365, f1: 0.8678, edges-srl-ontonotes_loss: 0.0113
09/16 09:42:05 AM: ***** Step 18000 / Validation 18 *****
09/16 09:42:05 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:42:05 AM: Validating...
09/16 09:42:12 AM: Evaluate: task edges-srl-ontonotes, batch 94 (157): mcc: 0.8850, acc: 0.8445, precision: 0.9232, recall: 0.8515, f1: 0.8859, edges-srl-ontonotes_loss: 0.0097
09/16 09:42:17 AM: Updating LR scheduler:
09/16 09:42:17 AM: 	Best result seen so far for macro_avg: 0.893
09/16 09:42:17 AM: 	# validation passes without improvement: 3
09/16 09:42:17 AM: edges-srl-ontonotes_loss: training: 0.011304 validation: 0.009607
09/16 09:42:17 AM: macro_avg: validation: 0.889465
09/16 09:42:17 AM: micro_avg: validation: 0.000000
09/16 09:42:17 AM: edges-srl-ontonotes_mcc: training: 0.866157 validation: 0.888421
09/16 09:42:17 AM: edges-srl-ontonotes_acc: training: 0.814258 validation: 0.851205
09/16 09:42:17 AM: edges-srl-ontonotes_precision: training: 0.901561 validation: 0.922727
09/16 09:42:17 AM: edges-srl-ontonotes_recall: training: 0.835883 validation: 0.858517
09/16 09:42:17 AM: edges-srl-ontonotes_f1: training: 0.867480 validation: 0.889465
09/16 09:42:17 AM: Global learning rate: 5e-05
09/16 09:42:17 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:42:22 AM: Update 18062: task edges-srl-ontonotes, batch 62 (18062): mcc: 0.8656, acc: 0.8134, precision: 0.9023, recall: 0.8342, f1: 0.8669, edges-srl-ontonotes_loss: 0.0117
09/16 09:42:32 AM: Update 18191: task edges-srl-ontonotes, batch 191 (18191): mcc: 0.8670, acc: 0.8145, precision: 0.9028, recall: 0.8364, f1: 0.8683, edges-srl-ontonotes_loss: 0.0114
09/16 09:42:42 AM: Update 18311: task edges-srl-ontonotes, batch 311 (18311): mcc: 0.8652, acc: 0.8117, precision: 0.9016, recall: 0.8341, f1: 0.8665, edges-srl-ontonotes_loss: 0.0115
09/16 09:42:52 AM: Update 18436: task edges-srl-ontonotes, batch 436 (18436): mcc: 0.8631, acc: 0.8091, precision: 0.9002, recall: 0.8314, f1: 0.8644, edges-srl-ontonotes_loss: 0.0116
09/16 09:43:05 AM: Update 18562: task edges-srl-ontonotes, batch 562 (18562): mcc: 0.8636, acc: 0.8096, precision: 0.9007, recall: 0.8319, f1: 0.8649, edges-srl-ontonotes_loss: 0.0116
09/16 09:43:15 AM: Update 18679: task edges-srl-ontonotes, batch 679 (18679): mcc: 0.8649, acc: 0.8117, precision: 0.9012, recall: 0.8338, f1: 0.8662, edges-srl-ontonotes_loss: 0.0115
09/16 09:43:25 AM: Update 18797: task edges-srl-ontonotes, batch 797 (18797): mcc: 0.8648, acc: 0.8118, precision: 0.9010, recall: 0.8338, f1: 0.8661, edges-srl-ontonotes_loss: 0.0115
09/16 09:43:35 AM: Update 18890: task edges-srl-ontonotes, batch 890 (18890): mcc: 0.8654, acc: 0.8125, precision: 0.9016, recall: 0.8345, f1: 0.8667, edges-srl-ontonotes_loss: 0.0114
09/16 09:43:45 AM: ***** Step 19000 / Validation 19 *****
09/16 09:43:45 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:43:45 AM: Validating...
09/16 09:43:45 AM: Evaluate: task edges-srl-ontonotes, batch 2 (157): mcc: 0.9054, acc: 0.8693, precision: 0.9337, recall: 0.8807, f1: 0.9064, edges-srl-ontonotes_loss: 0.0076
09/16 09:43:55 AM: Evaluate: task edges-srl-ontonotes, batch 132 (157): mcc: 0.8892, acc: 0.8509, precision: 0.9240, recall: 0.8588, f1: 0.8902, edges-srl-ontonotes_loss: 0.0094
09/16 09:43:57 AM: Updating LR scheduler:
09/16 09:43:57 AM: 	Best result seen so far for macro_avg: 0.893
09/16 09:43:57 AM: 	# validation passes without improvement: 0
09/16 09:43:57 AM: edges-srl-ontonotes_loss: training: 0.011365 validation: 0.009666
09/16 09:43:57 AM: macro_avg: validation: 0.888073
09/16 09:43:57 AM: micro_avg: validation: 0.000000
09/16 09:43:57 AM: edges-srl-ontonotes_mcc: training: 0.866257 validation: 0.887045
09/16 09:43:57 AM: edges-srl-ontonotes_acc: training: 0.813665 validation: 0.848434
09/16 09:43:57 AM: edges-srl-ontonotes_precision: training: 0.902535 validation: 0.922312
09/16 09:43:57 AM: edges-srl-ontonotes_recall: training: 0.835166 validation: 0.856285
09/16 09:43:57 AM: edges-srl-ontonotes_f1: training: 0.867544 validation: 0.888073
09/16 09:43:57 AM: Global learning rate: 2.5e-05
09/16 09:43:57 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:44:05 AM: Update 19102: task edges-srl-ontonotes, batch 102 (19102): mcc: 0.8687, acc: 0.8166, precision: 0.9020, recall: 0.8404, f1: 0.8701, edges-srl-ontonotes_loss: 0.0109
09/16 09:44:15 AM: Update 19203: task edges-srl-ontonotes, batch 203 (19203): mcc: 0.8652, acc: 0.8123, precision: 0.9015, recall: 0.8341, f1: 0.8665, edges-srl-ontonotes_loss: 0.0112
09/16 09:44:25 AM: Update 19306: task edges-srl-ontonotes, batch 306 (19306): mcc: 0.8575, acc: 0.8019, precision: 0.8954, recall: 0.8251, f1: 0.8588, edges-srl-ontonotes_loss: 0.0118
09/16 09:44:35 AM: Update 19410: task edges-srl-ontonotes, batch 410 (19410): mcc: 0.8549, acc: 0.7981, precision: 0.8943, recall: 0.8212, f1: 0.8562, edges-srl-ontonotes_loss: 0.0121
09/16 09:44:45 AM: Update 19503: task edges-srl-ontonotes, batch 503 (19503): mcc: 0.8537, acc: 0.7967, precision: 0.8939, recall: 0.8194, f1: 0.8550, edges-srl-ontonotes_loss: 0.0122
09/16 09:44:55 AM: Update 19634: task edges-srl-ontonotes, batch 634 (19634): mcc: 0.8610, acc: 0.8067, precision: 0.8994, recall: 0.8282, f1: 0.8623, edges-srl-ontonotes_loss: 0.0117
09/16 09:45:05 AM: Update 19762: task edges-srl-ontonotes, batch 762 (19762): mcc: 0.8643, acc: 0.8114, precision: 0.9011, recall: 0.8328, f1: 0.8656, edges-srl-ontonotes_loss: 0.0115
09/16 09:45:15 AM: Update 19871: task edges-srl-ontonotes, batch 871 (19871): mcc: 0.8688, acc: 0.8172, precision: 0.9042, recall: 0.8385, f1: 0.8701, edges-srl-ontonotes_loss: 0.0111
09/16 09:45:24 AM: ***** Step 20000 / Validation 20 *****
09/16 09:45:24 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:45:24 AM: Validating...
09/16 09:45:25 AM: Evaluate: task edges-srl-ontonotes, batch 17 (157): mcc: 0.8974, acc: 0.8543, precision: 0.9353, recall: 0.8639, f1: 0.8982, edges-srl-ontonotes_loss: 0.0086
09/16 09:45:35 AM: Evaluate: task edges-srl-ontonotes, batch 149 (157): mcc: 0.8919, acc: 0.8537, precision: 0.9286, recall: 0.8597, f1: 0.8928, edges-srl-ontonotes_loss: 0.0093
09/16 09:45:36 AM: Updating LR scheduler:
09/16 09:45:36 AM: 	Best result seen so far for macro_avg: 0.893
09/16 09:45:36 AM: 	# validation passes without improvement: 1
09/16 09:45:36 AM: edges-srl-ontonotes_loss: training: 0.010732 validation: 0.009500
09/16 09:45:36 AM: macro_avg: validation: 0.890772
09/16 09:45:36 AM: micro_avg: validation: 0.000000
09/16 09:45:36 AM: edges-srl-ontonotes_mcc: training: 0.874352 validation: 0.889847
09/16 09:45:36 AM: edges-srl-ontonotes_acc: training: 0.824626 validation: 0.851436
09/16 09:45:36 AM: edges-srl-ontonotes_precision: training: 0.908049 validation: 0.926712
09/16 09:45:36 AM: edges-srl-ontonotes_recall: training: 0.845431 validation: 0.857517
09/16 09:45:36 AM: edges-srl-ontonotes_f1: training: 0.875622 validation: 0.890772
09/16 09:45:36 AM: Global learning rate: 2.5e-05
09/16 09:45:36 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:45:45 AM: Update 20138: task edges-srl-ontonotes, batch 138 (20138): mcc: 0.9156, acc: 0.8782, precision: 0.9381, recall: 0.8960, f1: 0.9166, edges-srl-ontonotes_loss: 0.0075
09/16 09:45:55 AM: Update 20274: task edges-srl-ontonotes, batch 274 (20274): mcc: 0.9119, acc: 0.8737, precision: 0.9367, recall: 0.8903, f1: 0.9129, edges-srl-ontonotes_loss: 0.0078
09/16 09:46:05 AM: Update 20422: task edges-srl-ontonotes, batch 422 (20422): mcc: 0.9118, acc: 0.8747, precision: 0.9362, recall: 0.8906, f1: 0.9128, edges-srl-ontonotes_loss: 0.0079
09/16 09:46:15 AM: Update 20554: task edges-srl-ontonotes, batch 554 (20554): mcc: 0.9123, acc: 0.8754, precision: 0.9361, recall: 0.8916, f1: 0.9133, edges-srl-ontonotes_loss: 0.0078
09/16 09:46:25 AM: Update 20693: task edges-srl-ontonotes, batch 693 (20693): mcc: 0.9124, acc: 0.8755, precision: 0.9361, recall: 0.8918, f1: 0.9134, edges-srl-ontonotes_loss: 0.0078
09/16 09:46:35 AM: Update 20791: task edges-srl-ontonotes, batch 791 (20791): mcc: 0.9112, acc: 0.8743, precision: 0.9347, recall: 0.8908, f1: 0.9122, edges-srl-ontonotes_loss: 0.0080
09/16 09:46:46 AM: Update 20941: task edges-srl-ontonotes, batch 941 (20941): mcc: 0.9104, acc: 0.8737, precision: 0.9336, recall: 0.8904, f1: 0.9115, edges-srl-ontonotes_loss: 0.0081
09/16 09:46:49 AM: ***** Step 21000 / Validation 21 *****
09/16 09:46:49 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:46:49 AM: Validating...
09/16 09:46:56 AM: Evaluate: task edges-srl-ontonotes, batch 90 (157): mcc: 0.8899, acc: 0.8483, precision: 0.9310, recall: 0.8537, f1: 0.8907, edges-srl-ontonotes_loss: 0.0095
09/16 09:47:01 AM: Updating LR scheduler:
09/16 09:47:01 AM: 	Best result seen so far for macro_avg: 0.893
09/16 09:47:01 AM: 	# validation passes without improvement: 2
09/16 09:47:01 AM: edges-srl-ontonotes_loss: training: 0.008042 validation: 0.009383
09/16 09:47:01 AM: macro_avg: validation: 0.892769
09/16 09:47:01 AM: micro_avg: validation: 0.000000
09/16 09:47:01 AM: edges-srl-ontonotes_mcc: training: 0.910692 validation: 0.891847
09/16 09:47:01 AM: edges-srl-ontonotes_acc: training: 0.874207 validation: 0.854130
09/16 09:47:01 AM: edges-srl-ontonotes_precision: training: 0.933633 validation: 0.928067
09/16 09:47:01 AM: edges-srl-ontonotes_recall: training: 0.890887 validation: 0.860057
09/16 09:47:01 AM: edges-srl-ontonotes_f1: training: 0.911760 validation: 0.892769
09/16 09:47:01 AM: Global learning rate: 2.5e-05
09/16 09:47:01 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:47:06 AM: Update 21068: task edges-srl-ontonotes, batch 68 (21068): mcc: 0.9115, acc: 0.8750, precision: 0.9318, recall: 0.8942, f1: 0.9126, edges-srl-ontonotes_loss: 0.0083
09/16 09:47:16 AM: Update 21205: task edges-srl-ontonotes, batch 205 (21205): mcc: 0.8923, acc: 0.8495, precision: 0.9191, recall: 0.8694, f1: 0.8935, edges-srl-ontonotes_loss: 0.0095
09/16 09:47:26 AM: Update 21323: task edges-srl-ontonotes, batch 323 (21323): mcc: 0.8873, acc: 0.8428, precision: 0.9146, recall: 0.8640, f1: 0.8886, edges-srl-ontonotes_loss: 0.0098
09/16 09:47:36 AM: Update 21432: task edges-srl-ontonotes, batch 432 (21432): mcc: 0.8828, acc: 0.8368, precision: 0.9119, recall: 0.8579, f1: 0.8841, edges-srl-ontonotes_loss: 0.0103
09/16 09:47:46 AM: Update 21557: task edges-srl-ontonotes, batch 557 (21557): mcc: 0.8787, acc: 0.8315, precision: 0.9086, recall: 0.8532, f1: 0.8800, edges-srl-ontonotes_loss: 0.0105
09/16 09:47:56 AM: Update 21665: task edges-srl-ontonotes, batch 665 (21665): mcc: 0.8755, acc: 0.8275, precision: 0.9065, recall: 0.8491, f1: 0.8768, edges-srl-ontonotes_loss: 0.0108
09/16 09:48:06 AM: Update 21747: task edges-srl-ontonotes, batch 747 (21747): mcc: 0.8740, acc: 0.8256, precision: 0.9057, recall: 0.8471, f1: 0.8754, edges-srl-ontonotes_loss: 0.0109
09/16 09:48:16 AM: Update 21884: task edges-srl-ontonotes, batch 884 (21884): mcc: 0.8762, acc: 0.8283, precision: 0.9076, recall: 0.8493, f1: 0.8775, edges-srl-ontonotes_loss: 0.0107
09/16 09:48:25 AM: ***** Step 22000 / Validation 22 *****
09/16 09:48:25 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:48:25 AM: Validating...
09/16 09:48:26 AM: Evaluate: task edges-srl-ontonotes, batch 13 (157): mcc: 0.9040, acc: 0.8690, precision: 0.9366, recall: 0.8752, f1: 0.9048, edges-srl-ontonotes_loss: 0.0081
09/16 09:48:36 AM: Evaluate: task edges-srl-ontonotes, batch 145 (157): mcc: 0.8978, acc: 0.8640, precision: 0.9295, recall: 0.8701, f1: 0.8988, edges-srl-ontonotes_loss: 0.0089
09/16 09:48:37 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:48:37 AM: Best result seen so far for macro.
09/16 09:48:37 AM: Updating LR scheduler:
09/16 09:48:37 AM: 	Best result seen so far for macro_avg: 0.896
09/16 09:48:37 AM: 	# validation passes without improvement: 0
09/16 09:48:37 AM: edges-srl-ontonotes_loss: training: 0.010638 validation: 0.009136
09/16 09:48:37 AM: macro_avg: validation: 0.896343
09/16 09:48:37 AM: micro_avg: validation: 0.000000
09/16 09:48:37 AM: edges-srl-ontonotes_mcc: training: 0.877510 validation: 0.895294
09/16 09:48:37 AM: edges-srl-ontonotes_acc: training: 0.829951 validation: 0.861443
09/16 09:48:37 AM: edges-srl-ontonotes_precision: training: 0.908554 validation: 0.926617
09/16 09:48:37 AM: edges-srl-ontonotes_recall: training: 0.850987 validation: 0.867986
09/16 09:48:37 AM: edges-srl-ontonotes_f1: training: 0.878829 validation: 0.896343
09/16 09:48:37 AM: Global learning rate: 2.5e-05
09/16 09:48:37 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:48:46 AM: Update 22091: task edges-srl-ontonotes, batch 91 (22091): mcc: 0.8863, acc: 0.8422, precision: 0.9157, recall: 0.8610, f1: 0.8875, edges-srl-ontonotes_loss: 0.0101
09/16 09:48:56 AM: Update 22219: task edges-srl-ontonotes, batch 219 (22219): mcc: 0.8857, acc: 0.8422, precision: 0.9144, recall: 0.8612, f1: 0.8870, edges-srl-ontonotes_loss: 0.0099
09/16 09:49:06 AM: Update 22342: task edges-srl-ontonotes, batch 342 (22342): mcc: 0.8868, acc: 0.8427, precision: 0.9159, recall: 0.8618, f1: 0.8880, edges-srl-ontonotes_loss: 0.0099
09/16 09:49:16 AM: Update 22462: task edges-srl-ontonotes, batch 462 (22462): mcc: 0.8840, acc: 0.8392, precision: 0.9134, recall: 0.8589, f1: 0.8853, edges-srl-ontonotes_loss: 0.0101
09/16 09:49:26 AM: Update 22590: task edges-srl-ontonotes, batch 590 (22590): mcc: 0.8831, acc: 0.8381, precision: 0.9129, recall: 0.8576, f1: 0.8844, edges-srl-ontonotes_loss: 0.0102
09/16 09:49:36 AM: Update 22679: task edges-srl-ontonotes, batch 679 (22679): mcc: 0.8825, acc: 0.8375, precision: 0.9121, recall: 0.8572, f1: 0.8838, edges-srl-ontonotes_loss: 0.0102
09/16 09:49:46 AM: Update 22805: task edges-srl-ontonotes, batch 805 (22805): mcc: 0.8792, acc: 0.8329, precision: 0.9097, recall: 0.8532, f1: 0.8805, edges-srl-ontonotes_loss: 0.0104
09/16 09:49:56 AM: Update 22948: task edges-srl-ontonotes, batch 948 (22948): mcc: 0.8770, acc: 0.8300, precision: 0.9080, recall: 0.8506, f1: 0.8783, edges-srl-ontonotes_loss: 0.0106
09/16 09:50:02 AM: ***** Step 23000 / Validation 23 *****
09/16 09:50:02 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:50:02 AM: Validating...
09/16 09:50:06 AM: Evaluate: task edges-srl-ontonotes, batch 56 (157): mcc: 0.8897, acc: 0.8510, precision: 0.9277, recall: 0.8564, f1: 0.8906, edges-srl-ontonotes_loss: 0.0096
09/16 09:50:14 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:50:14 AM: Best result seen so far for macro.
09/16 09:50:14 AM: Updating LR scheduler:
09/16 09:50:14 AM: 	Best result seen so far for macro_avg: 0.898
09/16 09:50:14 AM: 	# validation passes without improvement: 0
09/16 09:50:14 AM: edges-srl-ontonotes_loss: training: 0.010642 validation: 0.008915
09/16 09:50:14 AM: macro_avg: validation: 0.898073
09/16 09:50:14 AM: micro_avg: validation: 0.000000
09/16 09:50:14 AM: edges-srl-ontonotes_mcc: training: 0.876295 validation: 0.897109
09/16 09:50:14 AM: edges-srl-ontonotes_acc: training: 0.829079 validation: 0.861904
09/16 09:50:14 AM: edges-srl-ontonotes_precision: training: 0.907364 validation: 0.930144
09/16 09:50:14 AM: edges-srl-ontonotes_recall: training: 0.849783 validation: 0.868140
09/16 09:50:14 AM: edges-srl-ontonotes_f1: training: 0.877630 validation: 0.898073
09/16 09:50:14 AM: Global learning rate: 2.5e-05
09/16 09:50:14 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:50:16 AM: Update 23026: task edges-srl-ontonotes, batch 26 (23026): mcc: 0.8724, acc: 0.8235, precision: 0.9064, recall: 0.8431, f1: 0.8736, edges-srl-ontonotes_loss: 0.0109
09/16 09:50:26 AM: Update 23142: task edges-srl-ontonotes, batch 142 (23142): mcc: 0.8694, acc: 0.8183, precision: 0.9043, recall: 0.8395, f1: 0.8707, edges-srl-ontonotes_loss: 0.0109
09/16 09:50:37 AM: Update 23259: task edges-srl-ontonotes, batch 259 (23259): mcc: 0.8681, acc: 0.8172, precision: 0.9013, recall: 0.8399, f1: 0.8695, edges-srl-ontonotes_loss: 0.0110
09/16 09:50:47 AM: Update 23367: task edges-srl-ontonotes, batch 367 (23367): mcc: 0.8623, acc: 0.8098, precision: 0.8970, recall: 0.8328, f1: 0.8637, edges-srl-ontonotes_loss: 0.0114
09/16 09:50:57 AM: Update 23485: task edges-srl-ontonotes, batch 485 (23485): mcc: 0.8579, acc: 0.8046, precision: 0.8931, recall: 0.8280, f1: 0.8593, edges-srl-ontonotes_loss: 0.0118
09/16 09:51:07 AM: Update 23597: task edges-srl-ontonotes, batch 597 (23597): mcc: 0.8570, acc: 0.8032, precision: 0.8926, recall: 0.8268, f1: 0.8585, edges-srl-ontonotes_loss: 0.0118
09/16 09:51:17 AM: Update 23700: task edges-srl-ontonotes, batch 700 (23700): mcc: 0.8556, acc: 0.8011, precision: 0.8919, recall: 0.8249, f1: 0.8571, edges-srl-ontonotes_loss: 0.0119
09/16 09:51:27 AM: Update 23827: task edges-srl-ontonotes, batch 827 (23827): mcc: 0.8544, acc: 0.7997, precision: 0.8910, recall: 0.8234, f1: 0.8559, edges-srl-ontonotes_loss: 0.0120
09/16 09:51:37 AM: Update 23930: task edges-srl-ontonotes, batch 930 (23930): mcc: 0.8537, acc: 0.7991, precision: 0.8905, recall: 0.8226, f1: 0.8552, edges-srl-ontonotes_loss: 0.0121
09/16 09:51:43 AM: ***** Step 24000 / Validation 24 *****
09/16 09:51:43 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:51:43 AM: Validating...
09/16 09:51:47 AM: Evaluate: task edges-srl-ontonotes, batch 59 (157): mcc: 0.8855, acc: 0.8452, precision: 0.9226, recall: 0.8530, f1: 0.8864, edges-srl-ontonotes_loss: 0.0098
09/16 09:51:55 AM: Updating LR scheduler:
09/16 09:51:55 AM: 	Best result seen so far for macro_avg: 0.898
09/16 09:51:55 AM: 	# validation passes without improvement: 1
09/16 09:51:55 AM: edges-srl-ontonotes_loss: training: 0.011936 validation: 0.009020
09/16 09:51:55 AM: macro_avg: validation: 0.896755
09/16 09:51:55 AM: micro_avg: validation: 0.000000
09/16 09:51:55 AM: edges-srl-ontonotes_mcc: training: 0.855340 validation: 0.895733
09/16 09:51:55 AM: edges-srl-ontonotes_acc: training: 0.801002 validation: 0.859749
09/16 09:51:55 AM: edges-srl-ontonotes_precision: training: 0.891964 validation: 0.927672
09/16 09:51:55 AM: edges-srl-ontonotes_recall: training: 0.824246 validation: 0.867832
09/16 09:51:55 AM: edges-srl-ontonotes_f1: training: 0.856769 validation: 0.896755
09/16 09:51:55 AM: Global learning rate: 2.5e-05
09/16 09:51:55 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:51:57 AM: Update 24033: task edges-srl-ontonotes, batch 33 (24033): mcc: 0.8809, acc: 0.8315, precision: 0.9099, recall: 0.8563, f1: 0.8823, edges-srl-ontonotes_loss: 0.0104
09/16 09:52:07 AM: Update 24158: task edges-srl-ontonotes, batch 158 (24158): mcc: 0.8738, acc: 0.8241, precision: 0.9064, recall: 0.8459, f1: 0.8751, edges-srl-ontonotes_loss: 0.0108
09/16 09:52:17 AM: Update 24270: task edges-srl-ontonotes, batch 270 (24270): mcc: 0.8727, acc: 0.8238, precision: 0.9054, recall: 0.8448, f1: 0.8740, edges-srl-ontonotes_loss: 0.0108
09/16 09:52:27 AM: Update 24402: task edges-srl-ontonotes, batch 402 (24402): mcc: 0.8735, acc: 0.8247, precision: 0.9062, recall: 0.8456, f1: 0.8749, edges-srl-ontonotes_loss: 0.0107
09/16 09:52:38 AM: Update 24508: task edges-srl-ontonotes, batch 508 (24508): mcc: 0.8733, acc: 0.8240, precision: 0.9061, recall: 0.8452, f1: 0.8746, edges-srl-ontonotes_loss: 0.0107
09/16 09:52:48 AM: Update 24622: task edges-srl-ontonotes, batch 622 (24622): mcc: 0.8739, acc: 0.8249, precision: 0.9067, recall: 0.8458, f1: 0.8752, edges-srl-ontonotes_loss: 0.0107
09/16 09:52:58 AM: Update 24752: task edges-srl-ontonotes, batch 752 (24752): mcc: 0.8745, acc: 0.8256, precision: 0.9071, recall: 0.8465, f1: 0.8758, edges-srl-ontonotes_loss: 0.0107
09/16 09:53:10 AM: Update 24869: task edges-srl-ontonotes, batch 869 (24869): mcc: 0.8757, acc: 0.8271, precision: 0.9083, recall: 0.8478, f1: 0.8770, edges-srl-ontonotes_loss: 0.0105
09/16 09:53:20 AM: Update 24976: task edges-srl-ontonotes, batch 976 (24976): mcc: 0.8744, acc: 0.8252, precision: 0.9075, recall: 0.8461, f1: 0.8757, edges-srl-ontonotes_loss: 0.0106
09/16 09:53:22 AM: ***** Step 25000 / Validation 25 *****
09/16 09:53:22 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:53:22 AM: Validating...
09/16 09:53:30 AM: Evaluate: task edges-srl-ontonotes, batch 95 (157): mcc: 0.8902, acc: 0.8503, precision: 0.9294, recall: 0.8557, f1: 0.8911, edges-srl-ontonotes_loss: 0.0091
09/16 09:53:35 AM: Updating LR scheduler:
09/16 09:53:35 AM: 	Best result seen so far for macro_avg: 0.898
09/16 09:53:35 AM: 	# validation passes without improvement: 2
09/16 09:53:35 AM: edges-srl-ontonotes_loss: training: 0.010694 validation: 0.009133
09/16 09:53:35 AM: macro_avg: validation: 0.893846
09/16 09:53:35 AM: micro_avg: validation: 0.000000
09/16 09:53:35 AM: edges-srl-ontonotes_mcc: training: 0.873850 validation: 0.892900
09/16 09:53:35 AM: edges-srl-ontonotes_acc: training: 0.824464 validation: 0.856362
09/16 09:53:35 AM: edges-srl-ontonotes_precision: training: 0.907133 validation: 0.928068
09/16 09:53:35 AM: edges-srl-ontonotes_recall: training: 0.845332 validation: 0.862058
09/16 09:53:35 AM: edges-srl-ontonotes_f1: training: 0.875143 validation: 0.893846
09/16 09:53:35 AM: Global learning rate: 2.5e-05
09/16 09:53:35 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:53:40 AM: Update 25066: task edges-srl-ontonotes, batch 66 (25066): mcc: 0.8627, acc: 0.8115, precision: 0.8981, recall: 0.8326, f1: 0.8641, edges-srl-ontonotes_loss: 0.0113
09/16 09:53:51 AM: Update 25182: task edges-srl-ontonotes, batch 182 (25182): mcc: 0.8661, acc: 0.8161, precision: 0.9016, recall: 0.8357, f1: 0.8674, edges-srl-ontonotes_loss: 0.0112
09/16 09:54:01 AM: Update 25314: task edges-srl-ontonotes, batch 314 (25314): mcc: 0.8676, acc: 0.8168, precision: 0.9024, recall: 0.8378, f1: 0.8689, edges-srl-ontonotes_loss: 0.0112
09/16 09:54:11 AM: Update 25436: task edges-srl-ontonotes, batch 436 (25436): mcc: 0.8670, acc: 0.8156, precision: 0.9026, recall: 0.8365, f1: 0.8683, edges-srl-ontonotes_loss: 0.0112
09/16 09:54:21 AM: Update 25549: task edges-srl-ontonotes, batch 549 (25549): mcc: 0.8665, acc: 0.8148, precision: 0.9021, recall: 0.8360, f1: 0.8678, edges-srl-ontonotes_loss: 0.0112
09/16 09:54:31 AM: Update 25672: task edges-srl-ontonotes, batch 672 (25672): mcc: 0.8659, acc: 0.8142, precision: 0.9015, recall: 0.8355, f1: 0.8673, edges-srl-ontonotes_loss: 0.0113
09/16 09:54:41 AM: Update 25795: task edges-srl-ontonotes, batch 795 (25795): mcc: 0.8656, acc: 0.8134, precision: 0.9013, recall: 0.8352, f1: 0.8669, edges-srl-ontonotes_loss: 0.0113
09/16 09:54:51 AM: Update 25883: task edges-srl-ontonotes, batch 883 (25883): mcc: 0.8658, acc: 0.8136, precision: 0.9013, recall: 0.8354, f1: 0.8671, edges-srl-ontonotes_loss: 0.0113
09/16 09:55:00 AM: ***** Step 26000 / Validation 26 *****
09/16 09:55:00 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:55:00 AM: Validating...
09/16 09:55:01 AM: Evaluate: task edges-srl-ontonotes, batch 9 (157): mcc: 0.8819, acc: 0.8448, precision: 0.9120, recall: 0.8561, f1: 0.8832, edges-srl-ontonotes_loss: 0.0091
09/16 09:55:11 AM: Evaluate: task edges-srl-ontonotes, batch 142 (157): mcc: 0.8940, acc: 0.8579, precision: 0.9261, recall: 0.8659, f1: 0.8950, edges-srl-ontonotes_loss: 0.0091
09/16 09:55:12 AM: Updating LR scheduler:
09/16 09:55:12 AM: 	Best result seen so far for macro_avg: 0.898
09/16 09:55:12 AM: 	# validation passes without improvement: 3
09/16 09:55:12 AM: edges-srl-ontonotes_loss: training: 0.011207 validation: 0.009316
09/16 09:55:12 AM: macro_avg: validation: 0.892957
09/16 09:55:12 AM: micro_avg: validation: 0.000000
09/16 09:55:12 AM: edges-srl-ontonotes_mcc: training: 0.866745 validation: 0.891895
09/16 09:55:12 AM: edges-srl-ontonotes_acc: training: 0.814560 validation: 0.855592
09/16 09:55:12 AM: edges-srl-ontonotes_precision: training: 0.902221 validation: 0.924294
09/16 09:55:12 AM: edges-srl-ontonotes_recall: training: 0.836386 validation: 0.863675
09/16 09:55:12 AM: edges-srl-ontonotes_f1: training: 0.868057 validation: 0.892957
09/16 09:55:12 AM: Global learning rate: 2.5e-05
09/16 09:55:12 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:55:21 AM: Update 26112: task edges-srl-ontonotes, batch 112 (26112): mcc: 0.8760, acc: 0.8282, precision: 0.9096, recall: 0.8472, f1: 0.8773, edges-srl-ontonotes_loss: 0.0109
09/16 09:55:31 AM: Update 26227: task edges-srl-ontonotes, batch 227 (26227): mcc: 0.8740, acc: 0.8252, precision: 0.9073, recall: 0.8456, f1: 0.8753, edges-srl-ontonotes_loss: 0.0108
09/16 09:55:41 AM: Update 26353: task edges-srl-ontonotes, batch 353 (26353): mcc: 0.8743, acc: 0.8248, precision: 0.9074, recall: 0.8459, f1: 0.8756, edges-srl-ontonotes_loss: 0.0107
09/16 09:55:51 AM: Update 26459: task edges-srl-ontonotes, batch 459 (26459): mcc: 0.8707, acc: 0.8201, precision: 0.9047, recall: 0.8416, f1: 0.8720, edges-srl-ontonotes_loss: 0.0109
09/16 09:56:01 AM: Update 26560: task edges-srl-ontonotes, batch 560 (26560): mcc: 0.8667, acc: 0.8149, precision: 0.9019, recall: 0.8366, f1: 0.8680, edges-srl-ontonotes_loss: 0.0113
09/16 09:56:11 AM: Update 26665: task edges-srl-ontonotes, batch 665 (26665): mcc: 0.8644, acc: 0.8114, precision: 0.9003, recall: 0.8337, f1: 0.8657, edges-srl-ontonotes_loss: 0.0114
09/16 09:56:21 AM: Update 26756: task edges-srl-ontonotes, batch 756 (26756): mcc: 0.8632, acc: 0.8099, precision: 0.8995, recall: 0.8322, f1: 0.8646, edges-srl-ontonotes_loss: 0.0115
09/16 09:56:31 AM: Update 26886: task edges-srl-ontonotes, batch 886 (26886): mcc: 0.8664, acc: 0.8145, precision: 0.9015, recall: 0.8364, f1: 0.8678, edges-srl-ontonotes_loss: 0.0112
09/16 09:56:40 AM: ***** Step 27000 / Validation 27 *****
09/16 09:56:40 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:56:40 AM: Validating...
09/16 09:56:41 AM: Evaluate: task edges-srl-ontonotes, batch 21 (157): mcc: 0.8994, acc: 0.8605, precision: 0.9376, recall: 0.8654, f1: 0.9001, edges-srl-ontonotes_loss: 0.0083
09/16 09:56:51 AM: Evaluate: task edges-srl-ontonotes, batch 154 (157): mcc: 0.8943, acc: 0.8579, precision: 0.9292, recall: 0.8638, f1: 0.8953, edges-srl-ontonotes_loss: 0.0091
09/16 09:56:52 AM: Updating LR scheduler:
09/16 09:56:52 AM: 	Best result seen so far for macro_avg: 0.898
09/16 09:56:52 AM: 	# validation passes without improvement: 0
09/16 09:56:52 AM: edges-srl-ontonotes_loss: training: 0.010970 validation: 0.009187
09/16 09:56:52 AM: macro_avg: validation: 0.894554
09/16 09:56:52 AM: micro_avg: validation: 0.000000
09/16 09:56:52 AM: edges-srl-ontonotes_mcc: training: 0.870155 validation: 0.893608
09/16 09:56:52 AM: edges-srl-ontonotes_acc: training: 0.819369 validation: 0.857055
09/16 09:56:52 AM: edges-srl-ontonotes_precision: training: 0.904282 validation: 0.928524
09/16 09:56:52 AM: edges-srl-ontonotes_recall: training: 0.840954 validation: 0.862982
09/16 09:56:52 AM: edges-srl-ontonotes_f1: training: 0.871469 validation: 0.894554
09/16 09:56:52 AM: Global learning rate: 1.25e-05
09/16 09:56:52 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:57:01 AM: Update 27105: task edges-srl-ontonotes, batch 105 (27105): mcc: 0.8980, acc: 0.8544, precision: 0.9243, recall: 0.8753, f1: 0.8991, edges-srl-ontonotes_loss: 0.0088
09/16 09:57:11 AM: Update 27265: task edges-srl-ontonotes, batch 265 (27265): mcc: 0.9089, acc: 0.8687, precision: 0.9332, recall: 0.8880, f1: 0.9100, edges-srl-ontonotes_loss: 0.0080
09/16 09:57:21 AM: Update 27406: task edges-srl-ontonotes, batch 406 (27406): mcc: 0.9114, acc: 0.8729, precision: 0.9349, recall: 0.8911, f1: 0.9125, edges-srl-ontonotes_loss: 0.0079
09/16 09:57:32 AM: Update 27563: task edges-srl-ontonotes, batch 563 (27563): mcc: 0.9135, acc: 0.8757, precision: 0.9373, recall: 0.8928, f1: 0.9145, edges-srl-ontonotes_loss: 0.0078
09/16 09:57:42 AM: Update 27698: task edges-srl-ontonotes, batch 698 (27698): mcc: 0.9130, acc: 0.8753, precision: 0.9371, recall: 0.8921, f1: 0.9140, edges-srl-ontonotes_loss: 0.0078
09/16 09:57:52 AM: Update 27856: task edges-srl-ontonotes, batch 856 (27856): mcc: 0.9136, acc: 0.8759, precision: 0.9374, recall: 0.8928, f1: 0.9146, edges-srl-ontonotes_loss: 0.0078
09/16 09:58:03 AM: Update 27999: task edges-srl-ontonotes, batch 999 (27999): mcc: 0.9137, acc: 0.8764, precision: 0.9375, recall: 0.8930, f1: 0.9147, edges-srl-ontonotes_loss: 0.0078
09/16 09:58:03 AM: ***** Step 28000 / Validation 28 *****
09/16 09:58:03 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:58:03 AM: Validating...
09/16 09:58:13 AM: Evaluate: task edges-srl-ontonotes, batch 133 (157): mcc: 0.8979, acc: 0.8626, precision: 0.9310, recall: 0.8690, f1: 0.8989, edges-srl-ontonotes_loss: 0.0089
09/16 09:58:15 AM: Updating LR scheduler:
09/16 09:58:15 AM: 	Best result seen so far for macro_avg: 0.898
09/16 09:58:15 AM: 	# validation passes without improvement: 1
09/16 09:58:15 AM: edges-srl-ontonotes_loss: training: 0.007773 validation: 0.009166
09/16 09:58:15 AM: macro_avg: validation: 0.895552
09/16 09:58:15 AM: micro_avg: validation: 0.000000
09/16 09:58:15 AM: edges-srl-ontonotes_mcc: training: 0.913703 validation: 0.894553
09/16 09:58:15 AM: edges-srl-ontonotes_acc: training: 0.876297 validation: 0.859133
09/16 09:58:15 AM: edges-srl-ontonotes_precision: training: 0.937518 validation: 0.927652
09/16 09:58:15 AM: edges-srl-ontonotes_recall: training: 0.892973 validation: 0.865599
09/16 09:58:15 AM: edges-srl-ontonotes_f1: training: 0.914704 validation: 0.895552
09/16 09:58:15 AM: Global learning rate: 1.25e-05
09/16 09:58:15 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:58:23 AM: Update 28126: task edges-srl-ontonotes, batch 126 (28126): mcc: 0.9063, acc: 0.8713, precision: 0.9270, recall: 0.8888, f1: 0.9075, edges-srl-ontonotes_loss: 0.0087
09/16 09:58:33 AM: Update 28281: task edges-srl-ontonotes, batch 281 (28281): mcc: 0.9100, acc: 0.8753, precision: 0.9306, recall: 0.8925, f1: 0.9112, edges-srl-ontonotes_loss: 0.0083
09/16 09:58:43 AM: Update 28395: task edges-srl-ontonotes, batch 395 (28395): mcc: 0.9036, acc: 0.8663, precision: 0.9262, recall: 0.8843, f1: 0.9048, edges-srl-ontonotes_loss: 0.0088
09/16 09:58:53 AM: Update 28532: task edges-srl-ontonotes, batch 532 (28532): mcc: 0.8987, acc: 0.8595, precision: 0.9231, recall: 0.8778, f1: 0.8999, edges-srl-ontonotes_loss: 0.0091
09/16 09:59:03 AM: Update 28647: task edges-srl-ontonotes, batch 647 (28647): mcc: 0.8957, acc: 0.8554, precision: 0.9212, recall: 0.8739, f1: 0.8969, edges-srl-ontonotes_loss: 0.0093
09/16 09:59:13 AM: Update 28770: task edges-srl-ontonotes, batch 770 (28770): mcc: 0.8903, acc: 0.8485, precision: 0.9172, recall: 0.8674, f1: 0.8916, edges-srl-ontonotes_loss: 0.0097
09/16 09:59:23 AM: Update 28889: task edges-srl-ontonotes, batch 889 (28889): mcc: 0.8869, acc: 0.8437, precision: 0.9149, recall: 0.8630, f1: 0.8882, edges-srl-ontonotes_loss: 0.0099
09/16 09:59:35 AM: Update 28985: task edges-srl-ontonotes, batch 985 (28985): mcc: 0.8851, acc: 0.8411, precision: 0.9136, recall: 0.8607, f1: 0.8864, edges-srl-ontonotes_loss: 0.0101
09/16 09:59:36 AM: ***** Step 29000 / Validation 29 *****
09/16 09:59:36 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:59:36 AM: Validating...
09/16 09:59:45 AM: Evaluate: task edges-srl-ontonotes, batch 117 (157): mcc: 0.8987, acc: 0.8634, precision: 0.9322, recall: 0.8693, f1: 0.8997, edges-srl-ontonotes_loss: 0.0089
09/16 09:59:48 AM: Updating LR scheduler:
09/16 09:59:48 AM: 	Best result seen so far for macro_avg: 0.898
09/16 09:59:48 AM: 	# validation passes without improvement: 2
09/16 09:59:48 AM: edges-srl-ontonotes_loss: training: 0.010068 validation: 0.009042
09/16 09:59:48 AM: macro_avg: validation: 0.897586
09/16 09:59:48 AM: micro_avg: validation: 0.000000
09/16 09:59:48 AM: edges-srl-ontonotes_mcc: training: 0.885161 validation: 0.896578
09/16 09:59:48 AM: edges-srl-ontonotes_acc: training: 0.841159 validation: 0.861827
09/16 09:59:48 AM: edges-srl-ontonotes_precision: training: 0.913762 validation: 0.928571
09/16 09:59:48 AM: edges-srl-ontonotes_recall: training: 0.860720 validation: 0.868601
09/16 09:59:48 AM: edges-srl-ontonotes_f1: training: 0.886448 validation: 0.897586
09/16 09:59:48 AM: Global learning rate: 1.25e-05
09/16 09:59:48 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 09:59:55 AM: Update 29094: task edges-srl-ontonotes, batch 94 (29094): mcc: 0.8876, acc: 0.8434, precision: 0.9160, recall: 0.8632, f1: 0.8888, edges-srl-ontonotes_loss: 0.0100
09/16 10:00:05 AM: Update 29231: task edges-srl-ontonotes, batch 231 (29231): mcc: 0.8862, acc: 0.8418, precision: 0.9162, recall: 0.8605, f1: 0.8875, edges-srl-ontonotes_loss: 0.0099
09/16 10:00:15 AM: Update 29351: task edges-srl-ontonotes, batch 351 (29351): mcc: 0.8890, acc: 0.8448, precision: 0.9181, recall: 0.8640, f1: 0.8902, edges-srl-ontonotes_loss: 0.0098
09/16 10:00:25 AM: Update 29479: task edges-srl-ontonotes, batch 479 (29479): mcc: 0.8896, acc: 0.8453, precision: 0.9183, recall: 0.8650, f1: 0.8908, edges-srl-ontonotes_loss: 0.0097
09/16 10:00:35 AM: Update 29609: task edges-srl-ontonotes, batch 609 (29609): mcc: 0.8892, acc: 0.8445, precision: 0.9182, recall: 0.8643, f1: 0.8905, edges-srl-ontonotes_loss: 0.0097
09/16 10:00:45 AM: Update 29731: task edges-srl-ontonotes, batch 731 (29731): mcc: 0.8866, acc: 0.8411, precision: 0.9160, recall: 0.8614, f1: 0.8878, edges-srl-ontonotes_loss: 0.0099
09/16 10:00:55 AM: Update 29864: task edges-srl-ontonotes, batch 864 (29864): mcc: 0.8865, acc: 0.8412, precision: 0.9157, recall: 0.8614, f1: 0.8877, edges-srl-ontonotes_loss: 0.0099
09/16 10:01:05 AM: Update 29966: task edges-srl-ontonotes, batch 966 (29966): mcc: 0.8856, acc: 0.8402, precision: 0.9150, recall: 0.8603, f1: 0.8868, edges-srl-ontonotes_loss: 0.0100
09/16 10:01:08 AM: ***** Step 30000 / Validation 30 *****
09/16 10:01:08 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:01:08 AM: Validating...
09/16 10:01:15 AM: Evaluate: task edges-srl-ontonotes, batch 101 (157): mcc: 0.9004, acc: 0.8625, precision: 0.9362, recall: 0.8688, f1: 0.9012, edges-srl-ontonotes_loss: 0.0087
09/16 10:01:19 AM: Best result seen so far for edges-srl-ontonotes.
09/16 10:01:19 AM: Best result seen so far for macro.
09/16 10:01:19 AM: Updating LR scheduler:
09/16 10:01:19 AM: 	Best result seen so far for macro_avg: 0.901
09/16 10:01:19 AM: 	# validation passes without improvement: 0
09/16 10:01:19 AM: edges-srl-ontonotes_loss: training: 0.010016 validation: 0.008838
09/16 10:01:19 AM: macro_avg: validation: 0.900621
09/16 10:01:19 AM: micro_avg: validation: 0.000000
09/16 10:01:19 AM: edges-srl-ontonotes_mcc: training: 0.885018 validation: 0.899669
09/16 10:01:19 AM: edges-srl-ontonotes_acc: training: 0.839619 validation: 0.864906
09/16 10:01:19 AM: edges-srl-ontonotes_precision: training: 0.914440 validation: 0.931988
09/16 10:01:19 AM: edges-srl-ontonotes_recall: training: 0.859803 validation: 0.871296
09/16 10:01:19 AM: edges-srl-ontonotes_f1: training: 0.886280 validation: 0.900621
09/16 10:01:19 AM: Global learning rate: 1.25e-05
09/16 10:01:19 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 10:01:25 AM: Update 30081: task edges-srl-ontonotes, batch 81 (30081): mcc: 0.8633, acc: 0.8110, precision: 0.8996, recall: 0.8323, f1: 0.8647, edges-srl-ontonotes_loss: 0.0111
09/16 10:01:35 AM: Update 30212: task edges-srl-ontonotes, batch 212 (30212): mcc: 0.8623, acc: 0.8098, precision: 0.8970, recall: 0.8328, f1: 0.8637, edges-srl-ontonotes_loss: 0.0114
09/16 10:01:45 AM: Update 30321: task edges-srl-ontonotes, batch 321 (30321): mcc: 0.8645, acc: 0.8126, precision: 0.8994, recall: 0.8348, f1: 0.8659, edges-srl-ontonotes_loss: 0.0113
09/16 10:01:55 AM: Update 30448: task edges-srl-ontonotes, batch 448 (30448): mcc: 0.8660, acc: 0.8143, precision: 0.9003, recall: 0.8368, f1: 0.8674, edges-srl-ontonotes_loss: 0.0112
09/16 10:02:05 AM: Update 30561: task edges-srl-ontonotes, batch 561 (30561): mcc: 0.8657, acc: 0.8141, precision: 0.8995, recall: 0.8369, f1: 0.8671, edges-srl-ontonotes_loss: 0.0112
09/16 10:02:15 AM: Update 30680: task edges-srl-ontonotes, batch 680 (30680): mcc: 0.8634, acc: 0.8109, precision: 0.8982, recall: 0.8337, f1: 0.8647, edges-srl-ontonotes_loss: 0.0114
09/16 10:02:25 AM: Update 30798: task edges-srl-ontonotes, batch 798 (30798): mcc: 0.8607, acc: 0.8075, precision: 0.8955, recall: 0.8312, f1: 0.8621, edges-srl-ontonotes_loss: 0.0116
09/16 10:02:36 AM: Update 30913: task edges-srl-ontonotes, batch 913 (30913): mcc: 0.8596, acc: 0.8060, precision: 0.8946, recall: 0.8299, f1: 0.8610, edges-srl-ontonotes_loss: 0.0117
09/16 10:02:42 AM: ***** Step 31000 / Validation 31 *****
09/16 10:02:42 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:02:42 AM: Validating...
09/16 10:02:46 AM: Evaluate: task edges-srl-ontonotes, batch 44 (157): mcc: 0.8908, acc: 0.8516, precision: 0.9263, recall: 0.8597, f1: 0.8918, edges-srl-ontonotes_loss: 0.0096
09/16 10:02:54 AM: Updating LR scheduler:
09/16 10:02:54 AM: 	Best result seen so far for macro_avg: 0.901
09/16 10:02:54 AM: 	# validation passes without improvement: 1
09/16 10:02:54 AM: edges-srl-ontonotes_loss: training: 0.011726 validation: 0.008837
09/16 10:02:54 AM: macro_avg: validation: 0.900155
09/16 10:02:54 AM: micro_avg: validation: 0.000000
09/16 10:02:54 AM: edges-srl-ontonotes_mcc: training: 0.858437 validation: 0.899127
09/16 10:02:54 AM: edges-srl-ontonotes_acc: training: 0.804495 validation: 0.865060
09/16 10:02:54 AM: edges-srl-ontonotes_precision: training: 0.893599 validation: 0.929415
09/16 10:02:54 AM: edges-srl-ontonotes_recall: training: 0.828615 validation: 0.872681
09/16 10:02:54 AM: edges-srl-ontonotes_f1: training: 0.859881 validation: 0.900155
09/16 10:02:54 AM: Global learning rate: 1.25e-05
09/16 10:02:54 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 10:02:56 AM: Update 31019: task edges-srl-ontonotes, batch 19 (31019): mcc: 0.8605, acc: 0.8070, precision: 0.8965, recall: 0.8299, f1: 0.8619, edges-srl-ontonotes_loss: 0.0126
09/16 10:03:06 AM: Update 31133: task edges-srl-ontonotes, batch 133 (31133): mcc: 0.8550, acc: 0.8003, precision: 0.8918, recall: 0.8238, f1: 0.8565, edges-srl-ontonotes_loss: 0.0121
09/16 10:03:16 AM: Update 31223: task edges-srl-ontonotes, batch 223 (31223): mcc: 0.8589, acc: 0.8056, precision: 0.8950, recall: 0.8283, f1: 0.8603, edges-srl-ontonotes_loss: 0.0117
09/16 10:03:26 AM: Update 31338: task edges-srl-ontonotes, batch 338 (31338): mcc: 0.8652, acc: 0.8130, precision: 0.9001, recall: 0.8355, f1: 0.8666, edges-srl-ontonotes_loss: 0.0112
09/16 10:03:36 AM: Update 31450: task edges-srl-ontonotes, batch 450 (31450): mcc: 0.8694, acc: 0.8185, precision: 0.9035, recall: 0.8402, f1: 0.8707, edges-srl-ontonotes_loss: 0.0109
09/16 10:03:46 AM: Update 31553: task edges-srl-ontonotes, batch 553 (31553): mcc: 0.8704, acc: 0.8198, precision: 0.9046, recall: 0.8412, f1: 0.8717, edges-srl-ontonotes_loss: 0.0109
09/16 10:03:56 AM: Update 31668: task edges-srl-ontonotes, batch 668 (31668): mcc: 0.8710, acc: 0.8205, precision: 0.9054, recall: 0.8416, f1: 0.8723, edges-srl-ontonotes_loss: 0.0108
09/16 10:04:06 AM: Update 31790: task edges-srl-ontonotes, batch 790 (31790): mcc: 0.8720, acc: 0.8220, precision: 0.9060, recall: 0.8429, f1: 0.8733, edges-srl-ontonotes_loss: 0.0107
09/16 10:04:16 AM: Update 31895: task edges-srl-ontonotes, batch 895 (31895): mcc: 0.8728, acc: 0.8234, precision: 0.9062, recall: 0.8443, f1: 0.8741, edges-srl-ontonotes_loss: 0.0107
09/16 10:04:25 AM: ***** Step 32000 / Validation 32 *****
09/16 10:04:25 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:04:25 AM: Validating...
09/16 10:04:26 AM: Evaluate: task edges-srl-ontonotes, batch 14 (157): mcc: 0.8976, acc: 0.8581, precision: 0.9330, recall: 0.8664, f1: 0.8985, edges-srl-ontonotes_loss: 0.0082
09/16 10:04:36 AM: Evaluate: task edges-srl-ontonotes, batch 147 (157): mcc: 0.8979, acc: 0.8621, precision: 0.9321, recall: 0.8678, f1: 0.8988, edges-srl-ontonotes_loss: 0.0087
09/16 10:04:37 AM: Updating LR scheduler:
09/16 10:04:37 AM: 	Best result seen so far for macro_avg: 0.901
09/16 10:04:37 AM: 	# validation passes without improvement: 2
09/16 10:04:37 AM: edges-srl-ontonotes_loss: training: 0.010643 validation: 0.008917
09/16 10:04:37 AM: macro_avg: validation: 0.897011
09/16 10:04:37 AM: micro_avg: validation: 0.000000
09/16 10:04:37 AM: edges-srl-ontonotes_mcc: training: 0.873707 validation: 0.896067
09/16 10:04:37 AM: edges-srl-ontonotes_acc: training: 0.824500 validation: 0.860211
09/16 10:04:37 AM: edges-srl-ontonotes_precision: training: 0.906780 validation: 0.930077
09/16 10:04:37 AM: edges-srl-ontonotes_recall: training: 0.845388 validation: 0.866215
09/16 10:04:37 AM: edges-srl-ontonotes_f1: training: 0.875009 validation: 0.897011
09/16 10:04:37 AM: Global learning rate: 1.25e-05
09/16 10:04:37 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 10:04:48 AM: Update 32115: task edges-srl-ontonotes, batch 115 (32115): mcc: 0.8831, acc: 0.8351, precision: 0.9155, recall: 0.8551, f1: 0.8843, edges-srl-ontonotes_loss: 0.0101
09/16 10:04:59 AM: Update 32245: task edges-srl-ontonotes, batch 245 (32245): mcc: 0.8747, acc: 0.8252, precision: 0.9075, recall: 0.8466, f1: 0.8760, edges-srl-ontonotes_loss: 0.0108
09/16 10:05:09 AM: Update 32373: task edges-srl-ontonotes, batch 373 (32373): mcc: 0.8716, acc: 0.8220, precision: 0.9046, recall: 0.8434, f1: 0.8729, edges-srl-ontonotes_loss: 0.0109
09/16 10:05:19 AM: Update 32494: task edges-srl-ontonotes, batch 494 (32494): mcc: 0.8707, acc: 0.8205, precision: 0.9047, recall: 0.8416, f1: 0.8720, edges-srl-ontonotes_loss: 0.0110
09/16 10:05:29 AM: Update 32621: task edges-srl-ontonotes, batch 621 (32621): mcc: 0.8705, acc: 0.8201, precision: 0.9046, recall: 0.8412, f1: 0.8718, edges-srl-ontonotes_loss: 0.0110
09/16 10:05:39 AM: Update 32738: task edges-srl-ontonotes, batch 738 (32738): mcc: 0.8700, acc: 0.8194, precision: 0.9042, recall: 0.8407, f1: 0.8713, edges-srl-ontonotes_loss: 0.0110
09/16 10:05:49 AM: Update 32847: task edges-srl-ontonotes, batch 847 (32847): mcc: 0.8694, acc: 0.8184, precision: 0.9038, recall: 0.8400, f1: 0.8707, edges-srl-ontonotes_loss: 0.0111
09/16 10:05:59 AM: Update 32969: task edges-srl-ontonotes, batch 969 (32969): mcc: 0.8689, acc: 0.8178, precision: 0.9031, recall: 0.8396, f1: 0.8702, edges-srl-ontonotes_loss: 0.0111
09/16 10:06:01 AM: ***** Step 33000 / Validation 33 *****
09/16 10:06:01 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:06:01 AM: Validating...
09/16 10:06:09 AM: Evaluate: task edges-srl-ontonotes, batch 101 (157): mcc: 0.8925, acc: 0.8544, precision: 0.9289, recall: 0.8605, f1: 0.8934, edges-srl-ontonotes_loss: 0.0090
09/16 10:06:13 AM: Updating LR scheduler:
09/16 10:06:13 AM: 	Best result seen so far for macro_avg: 0.901
09/16 10:06:13 AM: 	# validation passes without improvement: 3
09/16 10:06:13 AM: edges-srl-ontonotes_loss: training: 0.011067 validation: 0.009031
09/16 10:06:13 AM: macro_avg: validation: 0.896011
09/16 10:06:13 AM: micro_avg: validation: 0.000000
09/16 10:06:13 AM: edges-srl-ontonotes_mcc: training: 0.868906 validation: 0.895012
09/16 10:06:13 AM: edges-srl-ontonotes_acc: training: 0.817928 validation: 0.859595
09/16 10:06:13 AM: edges-srl-ontonotes_precision: training: 0.902983 validation: 0.927929
09/16 10:06:13 AM: edges-srl-ontonotes_recall: training: 0.839789 validation: 0.866215
09/16 10:06:13 AM: edges-srl-ontonotes_f1: training: 0.870240 validation: 0.896011
09/16 10:06:13 AM: Global learning rate: 1.25e-05
09/16 10:06:13 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 10:06:19 AM: Update 33064: task edges-srl-ontonotes, batch 64 (33064): mcc: 0.8610, acc: 0.8082, precision: 0.8961, recall: 0.8311, f1: 0.8624, edges-srl-ontonotes_loss: 0.0116
09/16 10:06:29 AM: Update 33190: task edges-srl-ontonotes, batch 190 (33190): mcc: 0.8681, acc: 0.8178, precision: 0.9017, recall: 0.8396, f1: 0.8695, edges-srl-ontonotes_loss: 0.0112
09/16 10:06:39 AM: Update 33309: task edges-srl-ontonotes, batch 309 (33309): mcc: 0.8702, acc: 0.8203, precision: 0.9032, recall: 0.8420, f1: 0.8715, edges-srl-ontonotes_loss: 0.0110
09/16 10:06:49 AM: Update 33394: task edges-srl-ontonotes, batch 394 (33394): mcc: 0.8711, acc: 0.8217, precision: 0.9034, recall: 0.8436, f1: 0.8725, edges-srl-ontonotes_loss: 0.0109
09/16 10:06:59 AM: Update 33517: task edges-srl-ontonotes, batch 517 (33517): mcc: 0.8719, acc: 0.8227, precision: 0.9047, recall: 0.8439, f1: 0.8732, edges-srl-ontonotes_loss: 0.0108
09/16 10:07:09 AM: Update 33640: task edges-srl-ontonotes, batch 640 (33640): mcc: 0.8729, acc: 0.8240, precision: 0.9055, recall: 0.8450, f1: 0.8742, edges-srl-ontonotes_loss: 0.0107
09/16 10:07:19 AM: Update 33741: task edges-srl-ontonotes, batch 741 (33741): mcc: 0.8702, acc: 0.8203, precision: 0.9037, recall: 0.8415, f1: 0.8715, edges-srl-ontonotes_loss: 0.0110
09/16 10:07:29 AM: Update 33858: task edges-srl-ontonotes, batch 858 (33858): mcc: 0.8680, acc: 0.8176, precision: 0.9024, recall: 0.8386, f1: 0.8693, edges-srl-ontonotes_loss: 0.0111
09/16 10:07:39 AM: Update 33964: task edges-srl-ontonotes, batch 964 (33964): mcc: 0.8658, acc: 0.8146, precision: 0.9008, recall: 0.8359, f1: 0.8671, edges-srl-ontonotes_loss: 0.0112
09/16 10:07:43 AM: ***** Step 34000 / Validation 34 *****
09/16 10:07:43 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:07:43 AM: Validating...
09/16 10:07:49 AM: Evaluate: task edges-srl-ontonotes, batch 83 (157): mcc: 0.8903, acc: 0.8524, precision: 0.9255, recall: 0.8596, f1: 0.8913, edges-srl-ontonotes_loss: 0.0094
09/16 10:07:55 AM: Updating LR scheduler:
09/16 10:07:55 AM: 	Best result seen so far for macro_avg: 0.901
09/16 10:07:55 AM: 	# validation passes without improvement: 0
09/16 10:07:55 AM: edges-srl-ontonotes_loss: training: 0.011265 validation: 0.009017
09/16 10:07:55 AM: macro_avg: validation: 0.896746
09/16 10:07:55 AM: micro_avg: validation: 0.000000
09/16 10:07:55 AM: edges-srl-ontonotes_mcc: training: 0.865790 validation: 0.895689
09/16 10:07:55 AM: edges-srl-ontonotes_acc: training: 0.814621 validation: 0.861135
09/16 10:07:55 AM: edges-srl-ontonotes_precision: training: 0.900804 validation: 0.926601
09/16 10:07:55 AM: edges-srl-ontonotes_recall: training: 0.835889 validation: 0.868755
09/16 10:07:55 AM: edges-srl-ontonotes_f1: training: 0.867133 validation: 0.896746
09/16 10:07:55 AM: Global learning rate: 6.25e-06
09/16 10:07:55 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 10:07:59 AM: Update 34062: task edges-srl-ontonotes, batch 62 (34062): mcc: 0.8927, acc: 0.8519, precision: 0.9187, recall: 0.8705, f1: 0.8939, edges-srl-ontonotes_loss: 0.0092
09/16 10:08:09 AM: Update 34183: task edges-srl-ontonotes, batch 183 (34183): mcc: 0.8915, acc: 0.8488, precision: 0.9181, recall: 0.8688, f1: 0.8928, edges-srl-ontonotes_loss: 0.0094
09/16 10:08:22 AM: Update 34306: task edges-srl-ontonotes, batch 306 (34306): mcc: 0.8925, acc: 0.8498, precision: 0.9192, recall: 0.8697, f1: 0.8938, edges-srl-ontonotes_loss: 0.0093
09/16 10:08:32 AM: Update 34444: task edges-srl-ontonotes, batch 444 (34444): mcc: 0.9001, acc: 0.8598, precision: 0.9250, recall: 0.8788, f1: 0.9013, edges-srl-ontonotes_loss: 0.0087
09/16 10:08:42 AM: Update 34583: task edges-srl-ontonotes, batch 583 (34583): mcc: 0.9043, acc: 0.8649, precision: 0.9285, recall: 0.8835, f1: 0.9054, edges-srl-ontonotes_loss: 0.0084
09/16 10:08:52 AM: Update 34712: task edges-srl-ontonotes, batch 712 (34712): mcc: 0.9054, acc: 0.8661, precision: 0.9298, recall: 0.8844, f1: 0.9065, edges-srl-ontonotes_loss: 0.0083
09/16 10:09:02 AM: Update 34854: task edges-srl-ontonotes, batch 854 (34854): mcc: 0.9073, acc: 0.8686, precision: 0.9316, recall: 0.8862, f1: 0.9084, edges-srl-ontonotes_loss: 0.0082
09/16 10:09:13 AM: Update 34981: task edges-srl-ontonotes, batch 981 (34981): mcc: 0.9085, acc: 0.8703, precision: 0.9326, recall: 0.8877, f1: 0.9096, edges-srl-ontonotes_loss: 0.0081
09/16 10:09:14 AM: ***** Step 35000 / Validation 35 *****
09/16 10:09:14 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:09:14 AM: Validating...
09/16 10:09:23 AM: Evaluate: task edges-srl-ontonotes, batch 117 (157): mcc: 0.8969, acc: 0.8600, precision: 0.9323, recall: 0.8657, f1: 0.8978, edges-srl-ontonotes_loss: 0.0089
09/16 10:09:26 AM: Updating LR scheduler:
09/16 10:09:26 AM: 	Best result seen so far for macro_avg: 0.901
09/16 10:09:26 AM: 	# validation passes without improvement: 1
09/16 10:09:26 AM: edges-srl-ontonotes_loss: training: 0.008089 validation: 0.008989
09/16 10:09:26 AM: macro_avg: validation: 0.897598
09/16 10:09:26 AM: micro_avg: validation: 0.000000
09/16 10:09:26 AM: edges-srl-ontonotes_mcc: training: 0.908596 validation: 0.896640
09/16 10:09:26 AM: edges-srl-ontonotes_acc: training: 0.870431 validation: 0.860596
09/16 10:09:26 AM: edges-srl-ontonotes_precision: training: 0.932653 validation: 0.930010
09/16 10:09:26 AM: edges-srl-ontonotes_recall: training: 0.887787 validation: 0.867370
09/16 10:09:26 AM: edges-srl-ontonotes_f1: training: 0.909667 validation: 0.897598
09/16 10:09:26 AM: Global learning rate: 6.25e-06
09/16 10:09:26 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 10:09:33 AM: Update 35102: task edges-srl-ontonotes, batch 102 (35102): mcc: 0.9119, acc: 0.8743, precision: 0.9344, recall: 0.8924, f1: 0.9129, edges-srl-ontonotes_loss: 0.0078
09/16 10:09:43 AM: Update 35246: task edges-srl-ontonotes, batch 246 (35246): mcc: 0.9146, acc: 0.8779, precision: 0.9376, recall: 0.8947, f1: 0.9156, edges-srl-ontonotes_loss: 0.0077
09/16 10:09:53 AM: Update 35410: task edges-srl-ontonotes, batch 410 (35410): mcc: 0.9135, acc: 0.8775, precision: 0.9350, recall: 0.8950, f1: 0.9146, edges-srl-ontonotes_loss: 0.0079
09/16 10:10:05 AM: Update 35558: task edges-srl-ontonotes, batch 558 (35558): mcc: 0.9131, acc: 0.8772, precision: 0.9340, recall: 0.8951, f1: 0.9141, edges-srl-ontonotes_loss: 0.0080
09/16 10:10:15 AM: Update 35685: task edges-srl-ontonotes, batch 685 (35685): mcc: 0.9070, acc: 0.8689, precision: 0.9302, recall: 0.8870, f1: 0.9081, edges-srl-ontonotes_loss: 0.0084
09/16 10:10:25 AM: Update 35804: task edges-srl-ontonotes, batch 804 (35804): mcc: 0.9036, acc: 0.8647, precision: 0.9279, recall: 0.8828, f1: 0.9048, edges-srl-ontonotes_loss: 0.0086
09/16 10:10:35 AM: Update 35915: task edges-srl-ontonotes, batch 915 (35915): mcc: 0.9005, acc: 0.8607, precision: 0.9254, recall: 0.8792, f1: 0.9017, edges-srl-ontonotes_loss: 0.0089
09/16 10:10:42 AM: ***** Step 36000 / Validation 36 *****
09/16 10:10:42 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:10:42 AM: Validating...
09/16 10:10:45 AM: Evaluate: task edges-srl-ontonotes, batch 45 (157): mcc: 0.8901, acc: 0.8490, precision: 0.9286, recall: 0.8562, f1: 0.8909, edges-srl-ontonotes_loss: 0.0096
09/16 10:10:53 AM: Updating LR scheduler:
09/16 10:10:53 AM: 	Best result seen so far for macro_avg: 0.901
09/16 10:10:53 AM: 	# validation passes without improvement: 2
09/16 10:10:53 AM: edges-srl-ontonotes_loss: training: 0.009107 validation: 0.008924
09/16 10:10:53 AM: macro_avg: validation: 0.898484
09/16 10:10:53 AM: micro_avg: validation: 0.000000
09/16 10:10:53 AM: edges-srl-ontonotes_mcc: training: 0.897409 validation: 0.897509
09/16 10:10:53 AM: edges-srl-ontonotes_acc: training: 0.856582 validation: 0.861981
09/16 10:10:53 AM: edges-srl-ontonotes_precision: training: 0.922978 validation: 0.930054
09/16 10:10:53 AM: edges-srl-ontonotes_recall: training: 0.875485 validation: 0.868986
09/16 10:10:53 AM: edges-srl-ontonotes_f1: training: 0.898605 validation: 0.898484
09/16 10:10:53 AM: Global learning rate: 6.25e-06
09/16 10:10:53 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 10:10:55 AM: Update 36019: task edges-srl-ontonotes, batch 19 (36019): mcc: 0.8653, acc: 0.8096, precision: 0.9015, recall: 0.8343, f1: 0.8666, edges-srl-ontonotes_loss: 0.0112
09/16 10:11:05 AM: Update 36140: task edges-srl-ontonotes, batch 140 (36140): mcc: 0.8612, acc: 0.8103, precision: 0.8945, recall: 0.8330, f1: 0.8626, edges-srl-ontonotes_loss: 0.0117
09/16 10:11:15 AM: Update 36248: task edges-srl-ontonotes, batch 248 (36248): mcc: 0.8660, acc: 0.8158, precision: 0.8993, recall: 0.8377, f1: 0.8674, edges-srl-ontonotes_loss: 0.0114
09/16 10:11:25 AM: Update 36369: task edges-srl-ontonotes, batch 369 (36369): mcc: 0.8733, acc: 0.8240, precision: 0.9059, recall: 0.8455, f1: 0.8747, edges-srl-ontonotes_loss: 0.0109
09/16 10:11:35 AM: Update 36510: task edges-srl-ontonotes, batch 510 (36510): mcc: 0.8772, acc: 0.8288, precision: 0.9088, recall: 0.8502, f1: 0.8785, edges-srl-ontonotes_loss: 0.0105
09/16 10:11:45 AM: Update 36612: task edges-srl-ontonotes, batch 612 (36612): mcc: 0.8798, acc: 0.8323, precision: 0.9109, recall: 0.8532, f1: 0.8811, edges-srl-ontonotes_loss: 0.0104
09/16 10:11:55 AM: Update 36725: task edges-srl-ontonotes, batch 725 (36725): mcc: 0.8809, acc: 0.8341, precision: 0.9114, recall: 0.8547, f1: 0.8822, edges-srl-ontonotes_loss: 0.0103
09/16 10:12:06 AM: Update 36857: task edges-srl-ontonotes, batch 857 (36857): mcc: 0.8825, acc: 0.8360, precision: 0.9126, recall: 0.8567, f1: 0.8838, edges-srl-ontonotes_loss: 0.0102
09/16 10:12:16 AM: Update 36986: task edges-srl-ontonotes, batch 986 (36986): mcc: 0.8828, acc: 0.8364, precision: 0.9130, recall: 0.8569, f1: 0.8841, edges-srl-ontonotes_loss: 0.0102
09/16 10:12:17 AM: ***** Step 37000 / Validation 37 *****
09/16 10:12:17 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:12:17 AM: Validating...
09/16 10:12:26 AM: Evaluate: task edges-srl-ontonotes, batch 120 (157): mcc: 0.9017, acc: 0.8671, precision: 0.9331, recall: 0.8742, f1: 0.9026, edges-srl-ontonotes_loss: 0.0086
09/16 10:12:29 AM: Best result seen so far for edges-srl-ontonotes.
09/16 10:12:29 AM: Best result seen so far for macro.
09/16 10:12:29 AM: Updating LR scheduler:
09/16 10:12:29 AM: 	Best result seen so far for macro_avg: 0.901
09/16 10:12:29 AM: 	# validation passes without improvement: 3
09/16 10:12:29 AM: edges-srl-ontonotes_loss: training: 0.010164 validation: 0.008779
09/16 10:12:29 AM: macro_avg: validation: 0.900663
09/16 10:12:29 AM: micro_avg: validation: 0.000000
09/16 10:12:29 AM: edges-srl-ontonotes_mcc: training: 0.882786 validation: 0.899633
09/16 10:12:29 AM: edges-srl-ontonotes_acc: training: 0.836529 validation: 0.865753
09/16 10:12:29 AM: edges-srl-ontonotes_precision: training: 0.912979 validation: 0.929625
09/16 10:12:29 AM: edges-srl-ontonotes_recall: training: 0.856910 validation: 0.873451
09/16 10:12:29 AM: edges-srl-ontonotes_f1: training: 0.884056 validation: 0.900663
09/16 10:12:29 AM: Global learning rate: 6.25e-06
09/16 10:12:29 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 10:12:36 AM: Update 37093: task edges-srl-ontonotes, batch 93 (37093): mcc: 0.8850, acc: 0.8409, precision: 0.9167, recall: 0.8577, f1: 0.8862, edges-srl-ontonotes_loss: 0.0101
09/16 10:12:46 AM: Update 37208: task edges-srl-ontonotes, batch 208 (37208): mcc: 0.8802, acc: 0.8332, precision: 0.9128, recall: 0.8522, f1: 0.8814, edges-srl-ontonotes_loss: 0.0104
09/16 10:12:56 AM: Update 37331: task edges-srl-ontonotes, batch 331 (37331): mcc: 0.8769, acc: 0.8291, precision: 0.9086, recall: 0.8498, f1: 0.8782, edges-srl-ontonotes_loss: 0.0106
09/16 10:13:06 AM: Update 37455: task edges-srl-ontonotes, batch 455 (37455): mcc: 0.8724, acc: 0.8230, precision: 0.9054, recall: 0.8443, f1: 0.8738, edges-srl-ontonotes_loss: 0.0109
09/16 10:13:17 AM: Update 37551: task edges-srl-ontonotes, batch 551 (37551): mcc: 0.8725, acc: 0.8227, precision: 0.9057, recall: 0.8441, f1: 0.8738, edges-srl-ontonotes_loss: 0.0109
09/16 10:13:27 AM: Update 37682: task edges-srl-ontonotes, batch 682 (37682): mcc: 0.8714, acc: 0.8214, precision: 0.9042, recall: 0.8435, f1: 0.8728, edges-srl-ontonotes_loss: 0.0109
09/16 10:13:37 AM: Update 37806: task edges-srl-ontonotes, batch 806 (37806): mcc: 0.8717, acc: 0.8217, precision: 0.9049, recall: 0.8433, f1: 0.8730, edges-srl-ontonotes_loss: 0.0109
09/16 10:13:47 AM: Update 37929: task edges-srl-ontonotes, batch 929 (37929): mcc: 0.8692, acc: 0.8190, precision: 0.9029, recall: 0.8405, f1: 0.8706, edges-srl-ontonotes_loss: 0.0111
09/16 10:13:53 AM: ***** Step 38000 / Validation 38 *****
09/16 10:13:53 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:13:53 AM: Validating...
09/16 10:13:57 AM: Evaluate: task edges-srl-ontonotes, batch 55 (157): mcc: 0.8935, acc: 0.8535, precision: 0.9305, recall: 0.8608, f1: 0.8943, edges-srl-ontonotes_loss: 0.0095
09/16 10:14:04 AM: Best result seen so far for edges-srl-ontonotes.
09/16 10:14:04 AM: Best result seen so far for macro.
09/16 10:14:04 AM: Updating LR scheduler:
09/16 10:14:04 AM: 	Best result seen so far for macro_avg: 0.901
09/16 10:14:04 AM: 	# validation passes without improvement: 0
09/16 10:14:04 AM: edges-srl-ontonotes_loss: training: 0.011162 validation: 0.008758
09/16 10:14:04 AM: macro_avg: validation: 0.901177
09/16 10:14:04 AM: micro_avg: validation: 0.000000
09/16 10:14:04 AM: edges-srl-ontonotes_mcc: training: 0.867768 validation: 0.900207
09/16 10:14:04 AM: edges-srl-ontonotes_acc: training: 0.817025 validation: 0.865676
09/16 10:14:04 AM: edges-srl-ontonotes_precision: training: 0.901701 validation: 0.931771
09/16 10:14:04 AM: edges-srl-ontonotes_recall: training: 0.838819 validation: 0.872527
09/16 10:14:04 AM: edges-srl-ontonotes_f1: training: 0.869124 validation: 0.901177
09/16 10:14:04 AM: Global learning rate: 6.25e-06
09/16 10:14:04 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 10:14:07 AM: Update 38031: task edges-srl-ontonotes, batch 31 (38031): mcc: 0.8536, acc: 0.8059, precision: 0.8899, recall: 0.8229, f1: 0.8551, edges-srl-ontonotes_loss: 0.0123
09/16 10:14:17 AM: Update 38144: task edges-srl-ontonotes, batch 144 (38144): mcc: 0.8469, acc: 0.7938, precision: 0.8852, recall: 0.8144, f1: 0.8483, edges-srl-ontonotes_loss: 0.0127
09/16 10:14:27 AM: Update 38279: task edges-srl-ontonotes, batch 279 (38279): mcc: 0.8501, acc: 0.7960, precision: 0.8878, recall: 0.8182, f1: 0.8516, edges-srl-ontonotes_loss: 0.0124
09/16 10:14:37 AM: Update 38409: task edges-srl-ontonotes, batch 409 (38409): mcc: 0.8517, acc: 0.7975, precision: 0.8899, recall: 0.8192, f1: 0.8531, edges-srl-ontonotes_loss: 0.0122
09/16 10:14:47 AM: Update 38499: task edges-srl-ontonotes, batch 499 (38499): mcc: 0.8568, acc: 0.8037, precision: 0.8939, recall: 0.8251, f1: 0.8581, edges-srl-ontonotes_loss: 0.0119
09/16 10:14:57 AM: Update 38618: task edges-srl-ontonotes, batch 618 (38618): mcc: 0.8607, acc: 0.8085, precision: 0.8973, recall: 0.8296, f1: 0.8621, edges-srl-ontonotes_loss: 0.0116
09/16 10:15:08 AM: Update 38735: task edges-srl-ontonotes, batch 735 (38735): mcc: 0.8632, acc: 0.8114, precision: 0.8990, recall: 0.8326, f1: 0.8645, edges-srl-ontonotes_loss: 0.0114
09/16 10:15:18 AM: Update 38849: task edges-srl-ontonotes, batch 849 (38849): mcc: 0.8647, acc: 0.8133, precision: 0.8999, recall: 0.8347, f1: 0.8661, edges-srl-ontonotes_loss: 0.0112
09/16 10:15:28 AM: Update 38972: task edges-srl-ontonotes, batch 972 (38972): mcc: 0.8668, acc: 0.8157, precision: 0.9018, recall: 0.8368, f1: 0.8681, edges-srl-ontonotes_loss: 0.0111
09/16 10:15:30 AM: ***** Step 39000 / Validation 39 *****
09/16 10:15:30 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:15:30 AM: Validating...
09/16 10:15:38 AM: Evaluate: task edges-srl-ontonotes, batch 103 (157): mcc: 0.8989, acc: 0.8627, precision: 0.9324, recall: 0.8694, f1: 0.8998, edges-srl-ontonotes_loss: 0.0087
09/16 10:15:42 AM: Updating LR scheduler:
09/16 10:15:42 AM: 	Best result seen so far for macro_avg: 0.901
09/16 10:15:42 AM: 	# validation passes without improvement: 1
09/16 10:15:42 AM: edges-srl-ontonotes_loss: training: 0.011080 validation: 0.008786
09/16 10:15:42 AM: macro_avg: validation: 0.900667
09/16 10:15:42 AM: micro_avg: validation: 0.000000
09/16 10:15:42 AM: edges-srl-ontonotes_mcc: training: 0.867214 validation: 0.899648
09/16 10:15:42 AM: edges-srl-ontonotes_acc: training: 0.816268 validation: 0.866061
09/16 10:15:42 AM: edges-srl-ontonotes_precision: training: 0.902071 validation: 0.929983
09/16 10:15:42 AM: edges-srl-ontonotes_recall: training: 0.837419 validation: 0.873143
09/16 10:15:42 AM: edges-srl-ontonotes_f1: training: 0.868543 validation: 0.900667
09/16 10:15:42 AM: Global learning rate: 6.25e-06
09/16 10:15:42 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 10:15:48 AM: Update 39059: task edges-srl-ontonotes, batch 59 (39059): mcc: 0.8754, acc: 0.8272, precision: 0.9076, recall: 0.8479, f1: 0.8767, edges-srl-ontonotes_loss: 0.0107
09/16 10:15:58 AM: Update 39177: task edges-srl-ontonotes, batch 177 (39177): mcc: 0.8805, acc: 0.8340, precision: 0.9105, recall: 0.8549, f1: 0.8818, edges-srl-ontonotes_loss: 0.0104
09/16 10:16:08 AM: Update 39295: task edges-srl-ontonotes, batch 295 (39295): mcc: 0.8818, acc: 0.8353, precision: 0.9121, recall: 0.8558, f1: 0.8831, edges-srl-ontonotes_loss: 0.0102
09/16 10:16:18 AM: Update 39409: task edges-srl-ontonotes, batch 409 (39409): mcc: 0.8788, acc: 0.8315, precision: 0.9096, recall: 0.8526, f1: 0.8801, edges-srl-ontonotes_loss: 0.0103
09/16 10:16:28 AM: Update 39538: task edges-srl-ontonotes, batch 538 (39538): mcc: 0.8758, acc: 0.8276, precision: 0.9083, recall: 0.8480, f1: 0.8771, edges-srl-ontonotes_loss: 0.0105
09/16 10:16:38 AM: Update 39654: task edges-srl-ontonotes, batch 654 (39654): mcc: 0.8741, acc: 0.8251, precision: 0.9072, recall: 0.8458, f1: 0.8754, edges-srl-ontonotes_loss: 0.0107
09/16 10:16:48 AM: Update 39749: task edges-srl-ontonotes, batch 749 (39749): mcc: 0.8730, acc: 0.8236, precision: 0.9062, recall: 0.8446, f1: 0.8743, edges-srl-ontonotes_loss: 0.0108
09/16 10:16:58 AM: Update 39878: task edges-srl-ontonotes, batch 878 (39878): mcc: 0.8727, acc: 0.8232, precision: 0.9062, recall: 0.8440, f1: 0.8740, edges-srl-ontonotes_loss: 0.0108
09/16 10:17:08 AM: Update 39992: task edges-srl-ontonotes, batch 992 (39992): mcc: 0.8718, acc: 0.8224, precision: 0.9054, recall: 0.8431, f1: 0.8731, edges-srl-ontonotes_loss: 0.0109
09/16 10:17:09 AM: ***** Step 40000 / Validation 40 *****
09/16 10:17:09 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:17:09 AM: Validating...
09/16 10:17:18 AM: Evaluate: task edges-srl-ontonotes, batch 123 (157): mcc: 0.8985, acc: 0.8622, precision: 0.9323, recall: 0.8687, f1: 0.8994, edges-srl-ontonotes_loss: 0.0087
09/16 10:17:21 AM: Updating LR scheduler:
09/16 10:17:21 AM: 	Best result seen so far for macro_avg: 0.901
09/16 10:17:21 AM: 	# validation passes without improvement: 2
09/16 10:17:21 AM: edges-srl-ontonotes_loss: training: 0.010871 validation: 0.008846
09/16 10:17:21 AM: macro_avg: validation: 0.898674
09/16 10:17:21 AM: micro_avg: validation: 0.000000
09/16 10:17:21 AM: edges-srl-ontonotes_mcc: training: 0.871488 validation: 0.897718
09/16 10:17:21 AM: edges-srl-ontonotes_acc: training: 0.821981 validation: 0.861904
09/16 10:17:21 AM: edges-srl-ontonotes_precision: training: 0.905085 validation: 0.930727
09/16 10:17:21 AM: edges-srl-ontonotes_recall: training: 0.842744 validation: 0.868755
09/16 10:17:21 AM: edges-srl-ontonotes_f1: training: 0.872803 validation: 0.898674
09/16 10:17:21 AM: Global learning rate: 6.25e-06
09/16 10:17:21 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 10:17:28 AM: Update 40093: task edges-srl-ontonotes, batch 93 (40093): mcc: 0.8621, acc: 0.8101, precision: 0.8987, recall: 0.8308, f1: 0.8634, edges-srl-ontonotes_loss: 0.0115
09/16 10:17:38 AM: Update 40214: task edges-srl-ontonotes, batch 214 (40214): mcc: 0.8652, acc: 0.8125, precision: 0.9010, recall: 0.8346, f1: 0.8665, edges-srl-ontonotes_loss: 0.0113
09/16 10:17:48 AM: Update 40324: task edges-srl-ontonotes, batch 324 (40324): mcc: 0.8672, acc: 0.8160, precision: 0.9020, recall: 0.8374, f1: 0.8685, edges-srl-ontonotes_loss: 0.0112
09/16 10:17:58 AM: Update 40446: task edges-srl-ontonotes, batch 446 (40446): mcc: 0.8689, acc: 0.8187, precision: 0.9023, recall: 0.8404, f1: 0.8703, edges-srl-ontonotes_loss: 0.0111
09/16 10:18:08 AM: Update 40576: task edges-srl-ontonotes, batch 576 (40576): mcc: 0.8697, acc: 0.8196, precision: 0.9028, recall: 0.8414, f1: 0.8711, edges-srl-ontonotes_loss: 0.0110
09/16 10:18:18 AM: Update 40659: task edges-srl-ontonotes, batch 659 (40659): mcc: 0.8707, acc: 0.8210, precision: 0.9036, recall: 0.8427, f1: 0.8721, edges-srl-ontonotes_loss: 0.0109
09/16 10:18:28 AM: Update 40775: task edges-srl-ontonotes, batch 775 (40775): mcc: 0.8714, acc: 0.8214, precision: 0.9045, recall: 0.8432, f1: 0.8727, edges-srl-ontonotes_loss: 0.0108
09/16 10:18:38 AM: Update 40890: task edges-srl-ontonotes, batch 890 (40890): mcc: 0.8719, acc: 0.8221, precision: 0.9044, recall: 0.8441, f1: 0.8732, edges-srl-ontonotes_loss: 0.0108
09/16 10:18:49 AM: Update 40992: task edges-srl-ontonotes, batch 992 (40992): mcc: 0.8705, acc: 0.8200, precision: 0.9035, recall: 0.8423, f1: 0.8718, edges-srl-ontonotes_loss: 0.0109
09/16 10:18:49 AM: ***** Step 41000 / Validation 41 *****
09/16 10:18:49 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:18:49 AM: Validating...
09/16 10:18:59 AM: Evaluate: task edges-srl-ontonotes, batch 127 (157): mcc: 0.8996, acc: 0.8638, precision: 0.9330, recall: 0.8701, f1: 0.9005, edges-srl-ontonotes_loss: 0.0087
09/16 10:19:01 AM: Updating LR scheduler:
09/16 10:19:01 AM: 	Best result seen so far for macro_avg: 0.901
09/16 10:19:01 AM: 	# validation passes without improvement: 3
09/16 10:19:01 AM: edges-srl-ontonotes_loss: training: 0.010882 validation: 0.008879
09/16 10:19:01 AM: macro_avg: validation: 0.898770
09/16 10:19:01 AM: micro_avg: validation: 0.000000
09/16 10:19:01 AM: edges-srl-ontonotes_mcc: training: 0.870313 validation: 0.897810
09/16 10:19:01 AM: edges-srl-ontonotes_acc: training: 0.819796 validation: 0.862289
09/16 10:19:01 AM: edges-srl-ontonotes_precision: training: 0.903445 validation: 0.930668
09/16 10:19:01 AM: edges-srl-ontonotes_recall: training: 0.842039 validation: 0.868986
09/16 10:19:01 AM: edges-srl-ontonotes_f1: training: 0.871662 validation: 0.898770
09/16 10:19:01 AM: Global learning rate: 6.25e-06
09/16 10:19:01 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 10:19:09 AM: Update 41084: task edges-srl-ontonotes, batch 84 (41084): mcc: 0.8496, acc: 0.7909, precision: 0.8880, recall: 0.8171, f1: 0.8510, edges-srl-ontonotes_loss: 0.0126
09/16 10:19:19 AM: Update 41195: task edges-srl-ontonotes, batch 195 (41195): mcc: 0.8526, acc: 0.7948, precision: 0.8910, recall: 0.8200, f1: 0.8540, edges-srl-ontonotes_loss: 0.0122
09/16 10:19:29 AM: Update 41309: task edges-srl-ontonotes, batch 309 (41309): mcc: 0.8616, acc: 0.8065, precision: 0.8981, recall: 0.8304, f1: 0.8630, edges-srl-ontonotes_loss: 0.0116
09/16 10:19:39 AM: Update 41440: task edges-srl-ontonotes, batch 440 (41440): mcc: 0.8715, acc: 0.8199, precision: 0.9061, recall: 0.8419, f1: 0.8728, edges-srl-ontonotes_loss: 0.0109
09/16 10:19:49 AM: Update 41560: task edges-srl-ontonotes, batch 560 (41560): mcc: 0.8777, acc: 0.8283, precision: 0.9107, recall: 0.8494, f1: 0.8790, edges-srl-ontonotes_loss: 0.0104
09/16 10:19:59 AM: Update 41710: task edges-srl-ontonotes, batch 710 (41710): mcc: 0.8860, acc: 0.8393, precision: 0.9164, recall: 0.8599, f1: 0.8872, edges-srl-ontonotes_loss: 0.0098
09/16 10:20:09 AM: Update 41856: task edges-srl-ontonotes, batch 856 (41856): mcc: 0.8920, acc: 0.8473, precision: 0.9207, recall: 0.8672, f1: 0.8931, edges-srl-ontonotes_loss: 0.0094
09/16 10:20:19 AM: Update 41971: task edges-srl-ontonotes, batch 971 (41971): mcc: 0.8943, acc: 0.8509, precision: 0.9225, recall: 0.8701, f1: 0.8955, edges-srl-ontonotes_loss: 0.0092
09/16 10:20:21 AM: ***** Step 42000 / Validation 42 *****
09/16 10:20:21 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:20:21 AM: Validating...
09/16 10:20:29 AM: Evaluate: task edges-srl-ontonotes, batch 110 (157): mcc: 0.8973, acc: 0.8602, precision: 0.9331, recall: 0.8657, f1: 0.8981, edges-srl-ontonotes_loss: 0.0089
09/16 10:20:33 AM: Updating LR scheduler:
09/16 10:20:33 AM: 	Best result seen so far for macro_avg: 0.901
09/16 10:20:33 AM: 	# validation passes without improvement: 0
09/16 10:20:33 AM: edges-srl-ontonotes_loss: training: 0.009127 validation: 0.008885
09/16 10:20:33 AM: macro_avg: validation: 0.899029
09/16 10:20:33 AM: micro_avg: validation: 0.000000
09/16 10:20:33 AM: edges-srl-ontonotes_mcc: training: 0.894945 validation: 0.898079
09/16 10:20:33 AM: edges-srl-ontonotes_acc: training: 0.851698 validation: 0.862751
09/16 10:20:33 AM: edges-srl-ontonotes_precision: training: 0.922930 validation: 0.931134
09/16 10:20:33 AM: edges-srl-ontonotes_recall: training: 0.870798 validation: 0.869063
09/16 10:20:33 AM: edges-srl-ontonotes_f1: training: 0.896107 validation: 0.899029
09/16 10:20:33 AM: Global learning rate: 3.125e-06
09/16 10:20:33 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 10:20:39 AM: Update 42097: task edges-srl-ontonotes, batch 97 (42097): mcc: 0.9173, acc: 0.8801, precision: 0.9430, recall: 0.8946, f1: 0.9182, edges-srl-ontonotes_loss: 0.0075
09/16 10:20:49 AM: Update 42242: task edges-srl-ontonotes, batch 242 (42242): mcc: 0.9184, acc: 0.8826, precision: 0.9422, recall: 0.8976, f1: 0.9193, edges-srl-ontonotes_loss: 0.0074
09/16 10:20:59 AM: Update 42403: task edges-srl-ontonotes, batch 403 (42403): mcc: 0.9172, acc: 0.8809, precision: 0.9410, recall: 0.8965, f1: 0.9182, edges-srl-ontonotes_loss: 0.0075
09/16 10:21:09 AM: Update 42529: task edges-srl-ontonotes, batch 529 (42529): mcc: 0.9163, acc: 0.8805, precision: 0.9393, recall: 0.8963, f1: 0.9173, edges-srl-ontonotes_loss: 0.0076
09/16 10:21:19 AM: Update 42676: task edges-srl-ontonotes, batch 676 (42676): mcc: 0.9151, acc: 0.8795, precision: 0.9374, recall: 0.8958, f1: 0.9161, edges-srl-ontonotes_loss: 0.0077
09/16 10:21:31 AM: Update 42804: task edges-srl-ontonotes, batch 804 (42804): mcc: 0.9149, acc: 0.8798, precision: 0.9366, recall: 0.8962, f1: 0.9160, edges-srl-ontonotes_loss: 0.0078
09/16 10:21:41 AM: Update 42919: task edges-srl-ontonotes, batch 919 (42919): mcc: 0.9110, acc: 0.8748, precision: 0.9336, recall: 0.8915, f1: 0.9121, edges-srl-ontonotes_loss: 0.0081
09/16 10:21:49 AM: ***** Step 43000 / Validation 43 *****
09/16 10:21:49 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:21:49 AM: Validating...
09/16 10:21:51 AM: Evaluate: task edges-srl-ontonotes, batch 24 (157): mcc: 0.8957, acc: 0.8571, precision: 0.9339, recall: 0.8620, f1: 0.8965, edges-srl-ontonotes_loss: 0.0087
09/16 10:22:01 AM: Evaluate: task edges-srl-ontonotes, batch 140 (157): mcc: 0.9006, acc: 0.8657, precision: 0.9331, recall: 0.8720, f1: 0.9015, edges-srl-ontonotes_loss: 0.0086
09/16 10:22:02 AM: Updating LR scheduler:
09/16 10:22:02 AM: 	Best result seen so far for macro_avg: 0.901
09/16 10:22:02 AM: 	# validation passes without improvement: 1
09/16 10:22:02 AM: edges-srl-ontonotes_loss: training: 0.008184 validation: 0.008858
09/16 10:22:02 AM: macro_avg: validation: 0.899232
09/16 10:22:02 AM: micro_avg: validation: 0.000000
09/16 10:22:02 AM: edges-srl-ontonotes_mcc: training: 0.909160 validation: 0.898258
09/16 10:22:02 AM: edges-srl-ontonotes_acc: training: 0.872432 validation: 0.863213
09/16 10:22:02 AM: edges-srl-ontonotes_precision: training: 0.932294 validation: 0.930512
09/16 10:22:02 AM: edges-srl-ontonotes_recall: training: 0.889215 validation: 0.869987
09/16 10:22:02 AM: edges-srl-ontonotes_f1: training: 0.910245 validation: 0.899232
09/16 10:22:02 AM: Global learning rate: 3.125e-06
09/16 10:22:02 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 10:22:11 AM: Update 43096: task edges-srl-ontonotes, batch 96 (43096): mcc: 0.8835, acc: 0.8382, precision: 0.9163, recall: 0.8551, f1: 0.8846, edges-srl-ontonotes_loss: 0.0101
09/16 10:22:21 AM: Update 43206: task edges-srl-ontonotes, batch 206 (43206): mcc: 0.8717, acc: 0.8251, precision: 0.9039, recall: 0.8443, f1: 0.8731, edges-srl-ontonotes_loss: 0.0109
09/16 10:22:31 AM: Update 43338: task edges-srl-ontonotes, batch 338 (43338): mcc: 0.8680, acc: 0.8191, precision: 0.9008, recall: 0.8402, f1: 0.8694, edges-srl-ontonotes_loss: 0.0112
09/16 10:22:41 AM: Update 43467: task edges-srl-ontonotes, batch 467 (43467): mcc: 0.8688, acc: 0.8195, precision: 0.9012, recall: 0.8412, f1: 0.8702, edges-srl-ontonotes_loss: 0.0112
09/16 10:22:51 AM: Update 43599: task edges-srl-ontonotes, batch 599 (43599): mcc: 0.8736, acc: 0.8255, precision: 0.9055, recall: 0.8463, f1: 0.8749, edges-srl-ontonotes_loss: 0.0108
09/16 10:23:01 AM: Update 43733: task edges-srl-ontonotes, batch 733 (43733): mcc: 0.8763, acc: 0.8296, precision: 0.9073, recall: 0.8499, f1: 0.8777, edges-srl-ontonotes_loss: 0.0106
09/16 10:23:11 AM: Update 43830: task edges-srl-ontonotes, batch 830 (43830): mcc: 0.8771, acc: 0.8303, precision: 0.9080, recall: 0.8507, f1: 0.8784, edges-srl-ontonotes_loss: 0.0106
09/16 10:23:21 AM: Update 43951: task edges-srl-ontonotes, batch 951 (43951): mcc: 0.8787, acc: 0.8325, precision: 0.9092, recall: 0.8527, f1: 0.8800, edges-srl-ontonotes_loss: 0.0104
09/16 10:23:25 AM: ***** Step 44000 / Validation 44 *****
09/16 10:23:25 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:23:25 AM: Validating...
09/16 10:23:31 AM: Evaluate: task edges-srl-ontonotes, batch 83 (157): mcc: 0.8971, acc: 0.8591, precision: 0.9309, recall: 0.8673, f1: 0.8980, edges-srl-ontonotes_loss: 0.0090
09/16 10:23:37 AM: Updating LR scheduler:
09/16 10:23:37 AM: 	Best result seen so far for macro_avg: 0.901
09/16 10:23:37 AM: 	# validation passes without improvement: 2
09/16 10:23:37 AM: edges-srl-ontonotes_loss: training: 0.010403 validation: 0.008766
09/16 10:23:37 AM: macro_avg: validation: 0.900448
09/16 10:23:37 AM: micro_avg: validation: 0.000000
09/16 10:23:37 AM: edges-srl-ontonotes_mcc: training: 0.879173 validation: 0.899407
09/16 10:23:37 AM: edges-srl-ontonotes_acc: training: 0.832998 validation: 0.865060
09/16 10:23:37 AM: edges-srl-ontonotes_precision: training: 0.909739 validation: 0.929168
09/16 10:23:37 AM: edges-srl-ontonotes_recall: training: 0.853051 validation: 0.873451
09/16 10:23:37 AM: edges-srl-ontonotes_f1: training: 0.880484 validation: 0.900448
09/16 10:23:37 AM: Global learning rate: 3.125e-06
09/16 10:23:37 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 10:23:41 AM: Update 44061: task edges-srl-ontonotes, batch 61 (44061): mcc: 0.8958, acc: 0.8556, precision: 0.9232, recall: 0.8722, f1: 0.8970, edges-srl-ontonotes_loss: 0.0091
09/16 10:23:51 AM: Update 44175: task edges-srl-ontonotes, batch 175 (44175): mcc: 0.8899, acc: 0.8473, precision: 0.9167, recall: 0.8669, f1: 0.8911, edges-srl-ontonotes_loss: 0.0096
09/16 10:24:01 AM: Update 44293: task edges-srl-ontonotes, batch 293 (44293): mcc: 0.8869, acc: 0.8440, precision: 0.9143, recall: 0.8636, f1: 0.8882, edges-srl-ontonotes_loss: 0.0098
09/16 10:24:12 AM: Update 44416: task edges-srl-ontonotes, batch 416 (44416): mcc: 0.8852, acc: 0.8414, precision: 0.9139, recall: 0.8606, f1: 0.8864, edges-srl-ontonotes_loss: 0.0099
09/16 10:24:22 AM: Update 44537: task edges-srl-ontonotes, batch 537 (44537): mcc: 0.8810, acc: 0.8352, precision: 0.9116, recall: 0.8547, f1: 0.8823, edges-srl-ontonotes_loss: 0.0103
09/16 10:24:32 AM: Update 44661: task edges-srl-ontonotes, batch 661 (44661): mcc: 0.8792, acc: 0.8325, precision: 0.9104, recall: 0.8525, f1: 0.8805, edges-srl-ontonotes_loss: 0.0104
09/16 10:24:43 AM: Update 44770: task edges-srl-ontonotes, batch 770 (44770): mcc: 0.8781, acc: 0.8310, precision: 0.9094, recall: 0.8513, f1: 0.8794, edges-srl-ontonotes_loss: 0.0105
09/16 10:24:53 AM: Update 44895: task edges-srl-ontonotes, batch 895 (44895): mcc: 0.8774, acc: 0.8299, precision: 0.9092, recall: 0.8502, f1: 0.8787, edges-srl-ontonotes_loss: 0.0105
09/16 10:25:02 AM: ***** Step 45000 / Validation 45 *****
09/16 10:25:02 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:25:02 AM: Validating...
09/16 10:25:03 AM: Evaluate: task edges-srl-ontonotes, batch 9 (157): mcc: 0.9014, acc: 0.8661, precision: 0.9332, recall: 0.8736, f1: 0.9024, edges-srl-ontonotes_loss: 0.0080
09/16 10:25:13 AM: Evaluate: task edges-srl-ontonotes, batch 144 (157): mcc: 0.9032, acc: 0.8691, precision: 0.9337, recall: 0.8764, f1: 0.9041, edges-srl-ontonotes_loss: 0.0085
09/16 10:25:14 AM: Best result seen so far for edges-srl-ontonotes.
09/16 10:25:14 AM: Best result seen so far for macro.
09/16 10:25:14 AM: Updating LR scheduler:
09/16 10:25:14 AM: 	Best result seen so far for macro_avg: 0.902
09/16 10:25:14 AM: 	# validation passes without improvement: 0
09/16 10:25:14 AM: edges-srl-ontonotes_loss: training: 0.010547 validation: 0.008738
09/16 10:25:14 AM: macro_avg: validation: 0.901850
09/16 10:25:14 AM: micro_avg: validation: 0.000000
09/16 10:25:14 AM: edges-srl-ontonotes_mcc: training: 0.876456 validation: 0.900852
09/16 10:25:14 AM: edges-srl-ontonotes_acc: training: 0.828601 validation: 0.866600
09/16 10:25:14 AM: edges-srl-ontonotes_precision: training: 0.908265 validation: 0.931283
09/16 10:25:14 AM: edges-srl-ontonotes_recall: training: 0.849244 validation: 0.874221
09/16 10:25:14 AM: edges-srl-ontonotes_f1: training: 0.877764 validation: 0.901850
09/16 10:25:14 AM: Global learning rate: 3.125e-06
09/16 10:25:14 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 10:25:23 AM: Update 45080: task edges-srl-ontonotes, batch 80 (45080): mcc: 0.8684, acc: 0.8184, precision: 0.9015, recall: 0.8403, f1: 0.8698, edges-srl-ontonotes_loss: 0.0111
09/16 10:25:33 AM: Update 45188: task edges-srl-ontonotes, batch 188 (45188): mcc: 0.8590, acc: 0.8058, precision: 0.8946, recall: 0.8288, f1: 0.8604, edges-srl-ontonotes_loss: 0.0118
09/16 10:25:43 AM: Update 45300: task edges-srl-ontonotes, batch 300 (45300): mcc: 0.8566, acc: 0.8027, precision: 0.8924, recall: 0.8263, f1: 0.8581, edges-srl-ontonotes_loss: 0.0120
09/16 10:25:53 AM: Update 45413: task edges-srl-ontonotes, batch 413 (45413): mcc: 0.8542, acc: 0.8000, precision: 0.8904, recall: 0.8236, f1: 0.8557, edges-srl-ontonotes_loss: 0.0121
09/16 10:26:03 AM: Update 45539: task edges-srl-ontonotes, batch 539 (45539): mcc: 0.8529, acc: 0.7987, precision: 0.8894, recall: 0.8220, f1: 0.8544, edges-srl-ontonotes_loss: 0.0122
09/16 10:26:13 AM: Update 45664: task edges-srl-ontonotes, batch 664 (45664): mcc: 0.8543, acc: 0.7997, precision: 0.8907, recall: 0.8234, f1: 0.8557, edges-srl-ontonotes_loss: 0.0121
09/16 10:26:23 AM: Update 45774: task edges-srl-ontonotes, batch 774 (45774): mcc: 0.8578, acc: 0.8040, precision: 0.8940, recall: 0.8271, f1: 0.8592, edges-srl-ontonotes_loss: 0.0118
09/16 10:26:33 AM: Update 45893: task edges-srl-ontonotes, batch 893 (45893): mcc: 0.8606, acc: 0.8080, precision: 0.8959, recall: 0.8306, f1: 0.8620, edges-srl-ontonotes_loss: 0.0116
09/16 10:26:43 AM: Update 45981: task edges-srl-ontonotes, batch 981 (45981): mcc: 0.8627, acc: 0.8107, precision: 0.8977, recall: 0.8330, f1: 0.8641, edges-srl-ontonotes_loss: 0.0115
09/16 10:26:45 AM: ***** Step 46000 / Validation 46 *****
09/16 10:26:45 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:26:45 AM: Validating...
09/16 10:26:53 AM: Evaluate: task edges-srl-ontonotes, batch 109 (157): mcc: 0.8996, acc: 0.8641, precision: 0.9321, recall: 0.8711, f1: 0.9006, edges-srl-ontonotes_loss: 0.0087
09/16 10:26:57 AM: Updating LR scheduler:
09/16 10:26:57 AM: 	Best result seen so far for macro_avg: 0.902
09/16 10:26:57 AM: 	# validation passes without improvement: 1
09/16 10:26:57 AM: edges-srl-ontonotes_loss: training: 0.011440 validation: 0.008753
09/16 10:26:57 AM: macro_avg: validation: 0.900901
09/16 10:26:57 AM: micro_avg: validation: 0.000000
09/16 10:26:57 AM: edges-srl-ontonotes_mcc: training: 0.862998 validation: 0.899874
09/16 10:26:57 AM: edges-srl-ontonotes_acc: training: 0.810829 validation: 0.865984
09/16 10:26:57 AM: edges-srl-ontonotes_precision: training: 0.897939 validation: 0.929871
09/16 10:26:57 AM: edges-srl-ontonotes_recall: training: 0.833248 validation: 0.873682
09/16 10:26:57 AM: edges-srl-ontonotes_f1: training: 0.864385 validation: 0.900901
09/16 10:26:57 AM: Global learning rate: 3.125e-06
09/16 10:26:57 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 10:27:03 AM: Update 46074: task edges-srl-ontonotes, batch 74 (46074): mcc: 0.8722, acc: 0.8223, precision: 0.9075, recall: 0.8417, f1: 0.8734, edges-srl-ontonotes_loss: 0.0108
09/16 10:27:13 AM: Update 46198: task edges-srl-ontonotes, batch 198 (46198): mcc: 0.8777, acc: 0.8297, precision: 0.9088, recall: 0.8512, f1: 0.8790, edges-srl-ontonotes_loss: 0.0103
09/16 10:27:24 AM: Update 46309: task edges-srl-ontonotes, batch 309 (46309): mcc: 0.8771, acc: 0.8295, precision: 0.9086, recall: 0.8501, f1: 0.8784, edges-srl-ontonotes_loss: 0.0103
09/16 10:27:34 AM: Update 46438: task edges-srl-ontonotes, batch 438 (46438): mcc: 0.8789, acc: 0.8314, precision: 0.9098, recall: 0.8525, f1: 0.8802, edges-srl-ontonotes_loss: 0.0103
09/16 10:27:44 AM: Update 46566: task edges-srl-ontonotes, batch 566 (46566): mcc: 0.8800, acc: 0.8328, precision: 0.9104, recall: 0.8540, f1: 0.8813, edges-srl-ontonotes_loss: 0.0102
09/16 10:27:54 AM: Update 46683: task edges-srl-ontonotes, batch 683 (46683): mcc: 0.8798, acc: 0.8326, precision: 0.9105, recall: 0.8535, f1: 0.8811, edges-srl-ontonotes_loss: 0.0102
09/16 10:28:04 AM: Update 46809: task edges-srl-ontonotes, batch 809 (46809): mcc: 0.8778, acc: 0.8300, precision: 0.9091, recall: 0.8511, f1: 0.8791, edges-srl-ontonotes_loss: 0.0104
09/16 10:28:14 AM: Update 46922: task edges-srl-ontonotes, batch 922 (46922): mcc: 0.8763, acc: 0.8278, precision: 0.9084, recall: 0.8489, f1: 0.8776, edges-srl-ontonotes_loss: 0.0105
09/16 10:28:20 AM: ***** Step 47000 / Validation 47 *****
09/16 10:28:20 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:28:20 AM: Validating...
09/16 10:28:24 AM: Evaluate: task edges-srl-ontonotes, batch 55 (157): mcc: 0.8908, acc: 0.8524, precision: 0.9277, recall: 0.8584, f1: 0.8917, edges-srl-ontonotes_loss: 0.0095
09/16 10:28:32 AM: Updating LR scheduler:
09/16 10:28:32 AM: 	Best result seen so far for macro_avg: 0.902
09/16 10:28:32 AM: 	# validation passes without improvement: 2
09/16 10:28:32 AM: edges-srl-ontonotes_loss: training: 0.010545 validation: 0.008784
09/16 10:28:32 AM: macro_avg: validation: 0.899710
09/16 10:28:32 AM: micro_avg: validation: 0.000000
09/16 10:28:32 AM: edges-srl-ontonotes_mcc: training: 0.875539 validation: 0.898716
09/16 10:28:32 AM: edges-srl-ontonotes_acc: training: 0.826900 validation: 0.864291
09/16 10:28:32 AM: edges-srl-ontonotes_precision: training: 0.907665 validation: 0.930215
09/16 10:28:32 AM: edges-srl-ontonotes_recall: training: 0.848055 validation: 0.871142
09/16 10:28:32 AM: edges-srl-ontonotes_f1: training: 0.876848 validation: 0.899710
09/16 10:28:32 AM: Global learning rate: 3.125e-06
09/16 10:28:32 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 10:28:34 AM: Update 47029: task edges-srl-ontonotes, batch 29 (47029): mcc: 0.8713, acc: 0.8224, precision: 0.9055, recall: 0.8421, f1: 0.8726, edges-srl-ontonotes_loss: 0.0107
09/16 10:28:44 AM: Update 47148: task edges-srl-ontonotes, batch 148 (47148): mcc: 0.8624, acc: 0.8121, precision: 0.8985, recall: 0.8315, f1: 0.8637, edges-srl-ontonotes_loss: 0.0114
09/16 10:28:54 AM: Update 47241: task edges-srl-ontonotes, batch 241 (47241): mcc: 0.8659, acc: 0.8158, precision: 0.9017, recall: 0.8353, f1: 0.8673, edges-srl-ontonotes_loss: 0.0112
09/16 10:29:04 AM: Update 47358: task edges-srl-ontonotes, batch 358 (47358): mcc: 0.8672, acc: 0.8172, precision: 0.9017, recall: 0.8377, f1: 0.8685, edges-srl-ontonotes_loss: 0.0111
09/16 10:29:14 AM: Update 47488: task edges-srl-ontonotes, batch 488 (47488): mcc: 0.8663, acc: 0.8159, precision: 0.9005, recall: 0.8371, f1: 0.8676, edges-srl-ontonotes_loss: 0.0112
09/16 10:29:24 AM: Update 47597: task edges-srl-ontonotes, batch 597 (47597): mcc: 0.8668, acc: 0.8160, precision: 0.9010, recall: 0.8376, f1: 0.8681, edges-srl-ontonotes_loss: 0.0111
09/16 10:29:34 AM: Update 47717: task edges-srl-ontonotes, batch 717 (47717): mcc: 0.8679, acc: 0.8173, precision: 0.9017, recall: 0.8391, f1: 0.8693, edges-srl-ontonotes_loss: 0.0111
09/16 10:29:44 AM: Update 47841: task edges-srl-ontonotes, batch 841 (47841): mcc: 0.8689, acc: 0.8187, precision: 0.9024, recall: 0.8403, f1: 0.8702, edges-srl-ontonotes_loss: 0.0110
09/16 10:29:54 AM: Update 47953: task edges-srl-ontonotes, batch 953 (47953): mcc: 0.8698, acc: 0.8198, precision: 0.9033, recall: 0.8412, f1: 0.8711, edges-srl-ontonotes_loss: 0.0109
09/16 10:29:58 AM: ***** Step 48000 / Validation 48 *****
09/16 10:29:58 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:29:58 AM: Validating...
09/16 10:30:04 AM: Evaluate: task edges-srl-ontonotes, batch 86 (157): mcc: 0.8949, acc: 0.8568, precision: 0.9317, recall: 0.8625, f1: 0.8958, edges-srl-ontonotes_loss: 0.0090
09/16 10:30:10 AM: Updating LR scheduler:
09/16 10:30:10 AM: 	Best result seen so far for macro_avg: 0.902
09/16 10:30:10 AM: 	# validation passes without improvement: 3
09/16 10:30:10 AM: edges-srl-ontonotes_loss: training: 0.010904 validation: 0.008822
09/16 10:30:10 AM: macro_avg: validation: 0.899248
09/16 10:30:10 AM: micro_avg: validation: 0.000000
09/16 10:30:10 AM: edges-srl-ontonotes_mcc: training: 0.869946 validation: 0.898269
09/16 10:30:10 AM: edges-srl-ontonotes_acc: training: 0.820067 validation: 0.863752
09/16 10:30:10 AM: edges-srl-ontonotes_precision: training: 0.903331 validation: 0.930370
09/16 10:30:10 AM: edges-srl-ontonotes_recall: training: 0.841446 validation: 0.870141
09/16 10:30:10 AM: edges-srl-ontonotes_f1: training: 0.871291 validation: 0.899248
09/16 10:30:10 AM: Global learning rate: 3.125e-06
09/16 10:30:10 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 10:30:14 AM: Update 48056: task edges-srl-ontonotes, batch 56 (48056): mcc: 0.8726, acc: 0.8204, precision: 0.9064, recall: 0.8436, f1: 0.8738, edges-srl-ontonotes_loss: 0.0106
09/16 10:30:26 AM: Update 48172: task edges-srl-ontonotes, batch 172 (48172): mcc: 0.8741, acc: 0.8238, precision: 0.9084, recall: 0.8447, f1: 0.8754, edges-srl-ontonotes_loss: 0.0106
09/16 10:30:36 AM: Update 48272: task edges-srl-ontonotes, batch 272 (48272): mcc: 0.8665, acc: 0.8137, precision: 0.9037, recall: 0.8346, f1: 0.8678, edges-srl-ontonotes_loss: 0.0112
09/16 10:30:46 AM: Update 48380: task edges-srl-ontonotes, batch 380 (48380): mcc: 0.8628, acc: 0.8091, precision: 0.9005, recall: 0.8304, f1: 0.8640, edges-srl-ontonotes_loss: 0.0114
09/16 10:30:57 AM: Update 48485: task edges-srl-ontonotes, batch 485 (48485): mcc: 0.8608, acc: 0.8063, precision: 0.8988, recall: 0.8284, f1: 0.8621, edges-srl-ontonotes_loss: 0.0116
09/16 10:31:07 AM: Update 48623: task edges-srl-ontonotes, batch 623 (48623): mcc: 0.8678, acc: 0.8158, precision: 0.9035, recall: 0.8372, f1: 0.8691, edges-srl-ontonotes_loss: 0.0111
09/16 10:31:17 AM: Update 48760: task edges-srl-ontonotes, batch 760 (48760): mcc: 0.8734, acc: 0.8234, precision: 0.9075, recall: 0.8441, f1: 0.8747, edges-srl-ontonotes_loss: 0.0107
09/16 10:31:27 AM: Update 48907: task edges-srl-ontonotes, batch 907 (48907): mcc: 0.8798, acc: 0.8318, precision: 0.9123, recall: 0.8519, f1: 0.8811, edges-srl-ontonotes_loss: 0.0102
09/16 10:31:32 AM: ***** Step 49000 / Validation 49 *****
09/16 10:31:32 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:31:32 AM: Validating...
09/16 10:31:37 AM: Evaluate: task edges-srl-ontonotes, batch 62 (157): mcc: 0.8907, acc: 0.8518, precision: 0.9282, recall: 0.8577, f1: 0.8916, edges-srl-ontonotes_loss: 0.0095
09/16 10:31:44 AM: Updating LR scheduler:
09/16 10:31:44 AM: 	Best result seen so far for macro_avg: 0.902
09/16 10:31:44 AM: 	# validation passes without improvement: 0
09/16 10:31:44 AM: edges-srl-ontonotes_loss: training: 0.009940 validation: 0.008832
09/16 10:31:44 AM: macro_avg: validation: 0.899689
09/16 10:31:44 AM: micro_avg: validation: 0.000000
09/16 10:31:44 AM: edges-srl-ontonotes_mcc: training: 0.883601 validation: 0.898742
09/16 10:31:44 AM: edges-srl-ontonotes_acc: training: 0.836707 validation: 0.863829
09/16 10:31:44 AM: edges-srl-ontonotes_precision: training: 0.915069 validation: 0.931580
09/16 10:31:44 AM: edges-srl-ontonotes_recall: training: 0.856499 validation: 0.869910
09/16 10:31:44 AM: edges-srl-ontonotes_f1: training: 0.884816 validation: 0.899689
09/16 10:31:44 AM: Global learning rate: 1.5625e-06
09/16 10:31:44 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 10:31:47 AM: Update 49049: task edges-srl-ontonotes, batch 49 (49049): mcc: 0.9257, acc: 0.8923, precision: 0.9479, recall: 0.9062, f1: 0.9266, edges-srl-ontonotes_loss: 0.0069
09/16 10:31:57 AM: Update 49165: task edges-srl-ontonotes, batch 165 (49165): mcc: 0.9184, acc: 0.8833, precision: 0.9398, recall: 0.8998, f1: 0.9194, edges-srl-ontonotes_loss: 0.0072
09/16 10:32:07 AM: Update 49311: task edges-srl-ontonotes, batch 311 (49311): mcc: 0.9183, acc: 0.8829, precision: 0.9405, recall: 0.8990, f1: 0.9192, edges-srl-ontonotes_loss: 0.0074
09/16 10:32:17 AM: Update 49440: task edges-srl-ontonotes, batch 440 (49440): mcc: 0.9171, acc: 0.8813, precision: 0.9393, recall: 0.8978, f1: 0.9181, edges-srl-ontonotes_loss: 0.0074
09/16 10:32:27 AM: Update 49593: task edges-srl-ontonotes, batch 593 (49593): mcc: 0.9159, acc: 0.8799, precision: 0.9381, recall: 0.8966, f1: 0.9169, edges-srl-ontonotes_loss: 0.0075
09/16 10:32:38 AM: Update 49737: task edges-srl-ontonotes, batch 737 (49737): mcc: 0.9161, acc: 0.8802, precision: 0.9383, recall: 0.8969, f1: 0.9171, edges-srl-ontonotes_loss: 0.0075
09/16 10:32:48 AM: Update 49908: task edges-srl-ontonotes, batch 908 (49908): mcc: 0.9150, acc: 0.8792, precision: 0.9366, recall: 0.8963, f1: 0.9160, edges-srl-ontonotes_loss: 0.0077
09/16 10:32:53 AM: ***** Step 50000 / Validation 50 *****
09/16 10:32:53 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:32:53 AM: Validating...
09/16 10:32:58 AM: Evaluate: task edges-srl-ontonotes, batch 63 (157): mcc: 0.8894, acc: 0.8500, precision: 0.9268, recall: 0.8566, f1: 0.8903, edges-srl-ontonotes_loss: 0.0096
09/16 10:33:05 AM: Updating LR scheduler:
09/16 10:33:05 AM: 	Best result seen so far for macro_avg: 0.902
09/16 10:33:05 AM: 	# validation passes without improvement: 1
09/16 10:33:05 AM: edges-srl-ontonotes_loss: training: 0.007656 validation: 0.008831
09/16 10:33:05 AM: macro_avg: validation: 0.899610
09/16 10:33:05 AM: micro_avg: validation: 0.000000
09/16 10:33:05 AM: edges-srl-ontonotes_mcc: training: 0.914828 validation: 0.898662
09/16 10:33:05 AM: edges-srl-ontonotes_acc: training: 0.879280 validation: 0.863444
09/16 10:33:05 AM: edges-srl-ontonotes_precision: training: 0.936327 validation: 0.931498
09/16 10:33:05 AM: edges-srl-ontonotes_recall: training: 0.896284 validation: 0.869833
09/16 10:33:05 AM: edges-srl-ontonotes_f1: training: 0.915868 validation: 0.899610
09/16 10:33:05 AM: Global learning rate: 1.5625e-06
09/16 10:33:05 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 10:33:08 AM: Update 50046: task edges-srl-ontonotes, batch 46 (50046): mcc: 0.9077, acc: 0.8715, precision: 0.9276, recall: 0.8909, f1: 0.9089, edges-srl-ontonotes_loss: 0.0080
09/16 10:33:18 AM: Update 50170: task edges-srl-ontonotes, batch 170 (50170): mcc: 0.8892, acc: 0.8456, precision: 0.9184, recall: 0.8640, f1: 0.8904, edges-srl-ontonotes_loss: 0.0095
09/16 10:33:28 AM: Update 50303: task edges-srl-ontonotes, batch 303 (50303): mcc: 0.8876, acc: 0.8447, precision: 0.9165, recall: 0.8627, f1: 0.8888, edges-srl-ontonotes_loss: 0.0097
09/16 10:33:38 AM: Update 50387: task edges-srl-ontonotes, batch 387 (50387): mcc: 0.8854, acc: 0.8416, precision: 0.9151, recall: 0.8599, f1: 0.8866, edges-srl-ontonotes_loss: 0.0099
09/16 10:33:48 AM: Update 50508: task edges-srl-ontonotes, batch 508 (50508): mcc: 0.8799, acc: 0.8343, precision: 0.9110, recall: 0.8533, f1: 0.8812, edges-srl-ontonotes_loss: 0.0104
09/16 10:33:58 AM: Update 50630: task edges-srl-ontonotes, batch 630 (50630): mcc: 0.8775, acc: 0.8310, precision: 0.9090, recall: 0.8506, f1: 0.8788, edges-srl-ontonotes_loss: 0.0105
09/16 10:34:08 AM: Update 50747: task edges-srl-ontonotes, batch 747 (50747): mcc: 0.8760, acc: 0.8288, precision: 0.9082, recall: 0.8483, f1: 0.8773, edges-srl-ontonotes_loss: 0.0106
09/16 10:34:18 AM: Update 50899: task edges-srl-ontonotes, batch 899 (50899): mcc: 0.8782, acc: 0.8310, precision: 0.9100, recall: 0.8509, f1: 0.8794, edges-srl-ontonotes_loss: 0.0104
09/16 10:34:25 AM: ***** Step 51000 / Validation 51 *****
09/16 10:34:25 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:34:25 AM: Validating...
09/16 10:34:28 AM: Evaluate: task edges-srl-ontonotes, batch 46 (157): mcc: 0.8933, acc: 0.8546, precision: 0.9288, recall: 0.8621, f1: 0.8942, edges-srl-ontonotes_loss: 0.0094
09/16 10:34:36 AM: Updating LR scheduler:
09/16 10:34:36 AM: 	Best result seen so far for macro_avg: 0.902
09/16 10:34:36 AM: 	# validation passes without improvement: 2
09/16 10:34:36 AM: edges-srl-ontonotes_loss: training: 0.010355 validation: 0.008780
09/16 10:34:36 AM: macro_avg: validation: 0.900278
09/16 10:34:36 AM: micro_avg: validation: 0.000000
09/16 10:34:36 AM: edges-srl-ontonotes_mcc: training: 0.879029 validation: 0.899251
09/16 10:34:36 AM: edges-srl-ontonotes_acc: training: 0.832096 validation: 0.865060
09/16 10:34:36 AM: edges-srl-ontonotes_precision: training: 0.910804 validation: 0.929502
09/16 10:34:36 AM: edges-srl-ontonotes_recall: training: 0.851773 validation: 0.872835
09/16 10:34:36 AM: edges-srl-ontonotes_f1: training: 0.880300 validation: 0.900278
09/16 10:34:36 AM: Global learning rate: 1.5625e-06
09/16 10:34:36 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 10:34:38 AM: Update 51026: task edges-srl-ontonotes, batch 26 (51026): mcc: 0.8934, acc: 0.8468, precision: 0.9198, recall: 0.8708, f1: 0.8946, edges-srl-ontonotes_loss: 0.0095
09/16 10:34:48 AM: Update 51158: task edges-srl-ontonotes, batch 158 (51158): mcc: 0.8864, acc: 0.8409, precision: 0.9149, recall: 0.8619, f1: 0.8876, edges-srl-ontonotes_loss: 0.0099
09/16 10:34:58 AM: Update 51304: task edges-srl-ontonotes, batch 304 (51304): mcc: 0.8900, acc: 0.8455, precision: 0.9175, recall: 0.8666, f1: 0.8913, edges-srl-ontonotes_loss: 0.0096
09/16 10:35:08 AM: Update 51413: task edges-srl-ontonotes, batch 413 (51413): mcc: 0.8881, acc: 0.8434, precision: 0.9158, recall: 0.8645, f1: 0.8894, edges-srl-ontonotes_loss: 0.0097
09/16 10:35:18 AM: Update 51559: task edges-srl-ontonotes, batch 559 (51559): mcc: 0.8866, acc: 0.8412, precision: 0.9145, recall: 0.8629, f1: 0.8879, edges-srl-ontonotes_loss: 0.0098
09/16 10:35:28 AM: Update 51688: task edges-srl-ontonotes, batch 688 (51688): mcc: 0.8853, acc: 0.8398, precision: 0.9133, recall: 0.8613, f1: 0.8866, edges-srl-ontonotes_loss: 0.0099
09/16 10:35:38 AM: Update 51829: task edges-srl-ontonotes, batch 829 (51829): mcc: 0.8822, acc: 0.8358, precision: 0.9112, recall: 0.8575, f1: 0.8836, edges-srl-ontonotes_loss: 0.0101
09/16 10:35:48 AM: Update 51959: task edges-srl-ontonotes, batch 959 (51959): mcc: 0.8803, acc: 0.8333, precision: 0.9098, recall: 0.8552, f1: 0.8817, edges-srl-ontonotes_loss: 0.0103
09/16 10:35:53 AM: ***** Step 52000 / Validation 52 *****
09/16 10:35:53 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:35:53 AM: Validating...
09/16 10:35:58 AM: Evaluate: task edges-srl-ontonotes, batch 64 (157): mcc: 0.8919, acc: 0.8530, precision: 0.9276, recall: 0.8607, f1: 0.8929, edges-srl-ontonotes_loss: 0.0095
09/16 10:36:06 AM: Updating LR scheduler:
09/16 10:36:06 AM: 	Best result seen so far for macro_avg: 0.902
09/16 10:36:06 AM: 	# validation passes without improvement: 3
09/16 10:36:06 AM: edges-srl-ontonotes_loss: training: 0.010321 validation: 0.008746
09/16 10:36:06 AM: macro_avg: validation: 0.900731
09/16 10:36:06 AM: micro_avg: validation: 0.000000
09/16 10:36:06 AM: edges-srl-ontonotes_mcc: training: 0.880036 validation: 0.899744
09/16 10:36:06 AM: edges-srl-ontonotes_acc: training: 0.832806 validation: 0.865445
09/16 10:36:06 AM: edges-srl-ontonotes_precision: training: 0.909545 validation: 0.930995
09/16 10:36:06 AM: edges-srl-ontonotes_recall: training: 0.854885 validation: 0.872373
09/16 10:36:06 AM: edges-srl-ontonotes_f1: training: 0.881369 validation: 0.900731
09/16 10:36:06 AM: Global learning rate: 1.5625e-06
09/16 10:36:06 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 10:36:09 AM: Update 52037: task edges-srl-ontonotes, batch 37 (52037): mcc: 0.8790, acc: 0.8298, precision: 0.9065, recall: 0.8559, f1: 0.8805, edges-srl-ontonotes_loss: 0.0105
09/16 10:36:19 AM: Update 52169: task edges-srl-ontonotes, batch 169 (52169): mcc: 0.8749, acc: 0.8274, precision: 0.9043, recall: 0.8499, f1: 0.8763, edges-srl-ontonotes_loss: 0.0108
09/16 10:36:31 AM: Update 52288: task edges-srl-ontonotes, batch 288 (52288): mcc: 0.8706, acc: 0.8209, precision: 0.9012, recall: 0.8447, f1: 0.8721, edges-srl-ontonotes_loss: 0.0109
09/16 10:36:41 AM: Update 52409: task edges-srl-ontonotes, batch 409 (52409): mcc: 0.8644, acc: 0.8127, precision: 0.8972, recall: 0.8365, f1: 0.8658, edges-srl-ontonotes_loss: 0.0114
09/16 10:36:51 AM: Update 52531: task edges-srl-ontonotes, batch 531 (52531): mcc: 0.8615, acc: 0.8094, precision: 0.8954, recall: 0.8328, f1: 0.8629, edges-srl-ontonotes_loss: 0.0116
09/16 10:37:01 AM: Update 52641: task edges-srl-ontonotes, batch 641 (52641): mcc: 0.8610, acc: 0.8086, precision: 0.8954, recall: 0.8318, f1: 0.8624, edges-srl-ontonotes_loss: 0.0117
09/16 10:37:11 AM: Update 52763: task edges-srl-ontonotes, batch 763 (52763): mcc: 0.8599, acc: 0.8080, precision: 0.8945, recall: 0.8306, f1: 0.8614, edges-srl-ontonotes_loss: 0.0117
09/16 10:37:21 AM: Update 52879: task edges-srl-ontonotes, batch 879 (52879): mcc: 0.8590, acc: 0.8066, precision: 0.8939, recall: 0.8295, f1: 0.8605, edges-srl-ontonotes_loss: 0.0118
09/16 10:37:31 AM: Update 52985: task edges-srl-ontonotes, batch 985 (52985): mcc: 0.8606, acc: 0.8084, precision: 0.8950, recall: 0.8314, f1: 0.8620, edges-srl-ontonotes_loss: 0.0117
09/16 10:37:32 AM: ***** Step 53000 / Validation 53 *****
09/16 10:37:32 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:37:32 AM: Validating...
09/16 10:37:41 AM: Evaluate: task edges-srl-ontonotes, batch 118 (157): mcc: 0.9012, acc: 0.8660, precision: 0.9343, recall: 0.8721, f1: 0.9021, edges-srl-ontonotes_loss: 0.0086
09/16 10:37:44 AM: Updating LR scheduler:
09/16 10:37:44 AM: 	Best result seen so far for macro_avg: 0.902
09/16 10:37:44 AM: 	# validation passes without improvement: 0
09/16 10:37:44 AM: Minimum LR reached. Stopping training.
09/16 10:37:44 AM: edges-srl-ontonotes_loss: training: 0.011642 validation: 0.008747
09/16 10:37:44 AM: macro_avg: validation: 0.900887
09/16 10:37:44 AM: micro_avg: validation: 0.000000
09/16 10:37:44 AM: edges-srl-ontonotes_mcc: training: 0.861103 validation: 0.899916
09/16 10:37:44 AM: edges-srl-ontonotes_acc: training: 0.809046 validation: 0.865368
09/16 10:37:44 AM: edges-srl-ontonotes_precision: training: 0.895447 validation: 0.931590
09/16 10:37:44 AM: edges-srl-ontonotes_recall: training: 0.831965 validation: 0.872142
09/16 10:37:44 AM: edges-srl-ontonotes_f1: training: 0.862539 validation: 0.900887
09/16 10:37:44 AM: Global learning rate: 7.8125e-07
09/16 10:37:44 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-mix/run
09/16 10:37:44 AM: Stopped training after 53 validation checks
09/16 10:37:44 AM: Trained edges-srl-ontonotes for 53000 batches or 7.327 epochs
09/16 10:37:44 AM: ***** VALIDATION RESULTS *****
09/16 10:37:44 AM: edges-srl-ontonotes_f1 (for best val pass 45): edges-srl-ontonotes_loss: 0.00874, macro_avg: 0.90185, micro_avg: 0.00000, edges-srl-ontonotes_mcc: 0.90085, edges-srl-ontonotes_acc: 0.86660, edges-srl-ontonotes_precision: 0.93128, edges-srl-ontonotes_recall: 0.87422, edges-srl-ontonotes_f1: 0.90185
09/16 10:37:44 AM: micro_avg (for best val pass 1): edges-srl-ontonotes_loss: 0.02123, macro_avg: 0.77680, micro_avg: 0.00000, edges-srl-ontonotes_mcc: 0.78104, edges-srl-ontonotes_acc: 0.67385, edges-srl-ontonotes_precision: 0.89674, edges-srl-ontonotes_recall: 0.68517, edges-srl-ontonotes_f1: 0.77680
09/16 10:37:44 AM: macro_avg (for best val pass 45): edges-srl-ontonotes_loss: 0.00874, macro_avg: 0.90185, micro_avg: 0.00000, edges-srl-ontonotes_mcc: 0.90085, edges-srl-ontonotes_acc: 0.86660, edges-srl-ontonotes_precision: 0.93128, edges-srl-ontonotes_recall: 0.87422, edges-srl-ontonotes_f1: 0.90185
09/16 10:37:44 AM: Evaluating...
09/16 10:37:44 AM: Loaded model state from ./experiments/srl-ontonotes-sts-mix/run/edges-srl-ontonotes/model_state_target_train_val_45.best.th
09/16 10:37:44 AM: Evaluating on: edges-srl-ontonotes, split: val
09/16 10:38:14 AM: 	Task edges-srl-ontonotes: batch 360
09/16 10:38:44 AM: 	Task edges-srl-ontonotes: batch 698
09/16 10:39:11 AM: Task 'edges-srl-ontonotes': sorting predictions by 'idx'
09/16 10:39:11 AM: Finished evaluating on: edges-srl-ontonotes
09/16 10:39:13 AM: Task 'edges-srl-ontonotes': joining predictions with input split 'val'
09/16 10:39:17 AM: Task 'edges-srl-ontonotes': Wrote predictions to ./experiments/srl-ontonotes-sts-mix/run
09/16 10:39:17 AM: Wrote all preds for split 'val' to ./experiments/srl-ontonotes-sts-mix/run
09/16 10:39:17 AM: Evaluating on: edges-srl-ontonotes, split: test
09/16 10:39:47 AM: 	Task edges-srl-ontonotes: batch 354
09/16 10:40:18 AM: 	Task edges-srl-ontonotes: batch 718
09/16 10:40:20 AM: Task 'edges-srl-ontonotes': sorting predictions by 'idx'
09/16 10:40:20 AM: Finished evaluating on: edges-srl-ontonotes
09/16 10:40:20 AM: Task 'edges-srl-ontonotes': joining predictions with input split 'test'
09/16 10:40:24 AM: Task 'edges-srl-ontonotes': Wrote predictions to ./experiments/srl-ontonotes-sts-mix/run
09/16 10:40:24 AM: Wrote all preds for split 'test' to ./experiments/srl-ontonotes-sts-mix/run
09/16 10:40:24 AM: Writing results for split 'val' to ./experiments/srl-ontonotes-sts-mix/results.tsv
09/16 10:40:24 AM: micro_avg: 0.000, macro_avg: 0.900, edges-srl-ontonotes_mcc: 0.899, edges-srl-ontonotes_acc: 0.865, edges-srl-ontonotes_precision: 0.929, edges-srl-ontonotes_recall: 0.872, edges-srl-ontonotes_f1: 0.900
09/16 10:40:24 AM: Done!
09/16 10:40:24 AM: Fatal error in main():
Traceback (most recent call last):
  File "main.py", line 16, in <module>
    main(sys.argv[1:])
  File "/srv/home/ericwallace/jiant/jiant/__main__.py", line 610, in main
    exit("Done exited")
  File "/home/ericwallace/miniconda3/envs/jiant/lib/python3.6/_sitebuiltins.py", line 26, in __call__
    raise SystemExit(code)
SystemExit: Done exited
