09/16 09:10:58 AM: Git branch: master
09/16 09:10:58 AM: Git SHA: 1a42459c6cbb693793b9c0d01bca567d99b0baac
09/16 09:10:58 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/srl-ontonotes-rte-top/",
  "exp_name": "experiments/srl-ontonotes-rte-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/srl-ontonotes-rte-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/rte",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/srl-ontonotes-rte-top__run",
  "run_dir": "./experiments/srl-ontonotes-rte-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-srl-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 09:10:58 AM: Saved config to ./experiments/srl-ontonotes-rte-top/run/params.conf
09/16 09:10:58 AM: Using random seed 1234
09/16 09:10:59 AM: Using GPU 0
09/16 09:10:59 AM: Loading tasks...
09/16 09:10:59 AM: Writing pre-preprocessed tasks to ./experiments/srl-ontonotes-rte-top/
09/16 09:10:59 AM: 	Creating task edges-srl-ontonotes from scratch.
09/16 09:11:05 AM: Read=231480, Skip=21590, Total=253070 from ./probing_data/edges/ontonotes/srl/train.json.retokenized.bert-base-uncased
09/16 09:11:05 AM: Read=32486, Skip=2811, Total=35297 from ./probing_data/edges/ontonotes/srl/development.json.retokenized.bert-base-uncased
09/16 09:11:05 AM: Read=23800, Skip=2915, Total=26715 from ./probing_data/edges/ontonotes/srl/test.json.retokenized.bert-base-uncased
09/16 09:11:08 AM: 	Task 'edges-srl-ontonotes': |train|=231480 |val|=32486 |test|=23800
09/16 09:11:08 AM: 	Finished loading tasks: edges-srl-ontonotes.
09/16 09:11:08 AM: 	Building vocab from scratch.
09/16 09:11:08 AM: 	Counting units for task edges-srl-ontonotes.
09/16 09:11:14 AM: 	Task 'edges-srl-ontonotes': adding vocab namespace 'edges-srl-ontonotes_labels'
09/16 09:11:15 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:11:15 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 09:11:15 AM: 	Saved vocab to ./experiments/srl-ontonotes-rte-top/vocab
09/16 09:11:15 AM: Loading token dictionary from ./experiments/srl-ontonotes-rte-top/vocab.
09/16 09:11:15 AM: 	Loaded vocab from ./experiments/srl-ontonotes-rte-top/vocab
09/16 09:11:15 AM: 	Vocab namespace bert_uncased: size 30524
09/16 09:11:15 AM: 	Vocab namespace tokens: size 23662
09/16 09:11:15 AM: 	Vocab namespace edges-srl-ontonotes_labels: size 66
09/16 09:11:15 AM: 	Vocab namespace chars: size 76
09/16 09:11:15 AM: 	Finished building vocab.
09/16 09:11:15 AM: 	Task edges-srl-ontonotes (train): Indexing from scratch.
09/16 09:11:54 AM: 	Task edges-srl-ontonotes (train): Saved 231480 instances to ./experiments/srl-ontonotes-rte-top/preproc/edges-srl-ontonotes__train_data
09/16 09:11:54 AM: 	Task edges-srl-ontonotes (val): Indexing from scratch.
09/16 09:11:58 AM: 	Task edges-srl-ontonotes (val): Saved 32486 instances to ./experiments/srl-ontonotes-rte-top/preproc/edges-srl-ontonotes__val_data
09/16 09:11:58 AM: 	Task edges-srl-ontonotes (test): Indexing from scratch.
09/16 09:12:02 AM: 	Task edges-srl-ontonotes (test): Saved 23800 instances to ./experiments/srl-ontonotes-rte-top/preproc/edges-srl-ontonotes__test_data
09/16 09:12:02 AM: 	Finished indexing tasks
09/16 09:12:02 AM: 	Creating trimmed target-only version of edges-srl-ontonotes train.
09/16 09:12:02 AM: 	  Training on 
09/16 09:12:02 AM: 	  Evaluating on edges-srl-ontonotes
09/16 09:12:02 AM: 	Finished loading tasks in 62.838s
09/16 09:12:02 AM: 	 Tasks: ['edges-srl-ontonotes']
09/16 09:12:02 AM: Building model...
09/16 09:12:02 AM: Using BERT model (bert-base-uncased).
09/16 09:12:02 AM: LOADING A FUNETUNED MODEL from: 
09/16 09:12:02 AM: models/rte
09/16 09:12:02 AM: loading configuration file models/rte/config.json
09/16 09:12:02 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "rte",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 09:12:02 AM: loading weights file models/rte/pytorch_model.bin
09/16 09:12:05 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpbgodnmd8
09/16 09:12:07 AM: copying /tmp/tmpbgodnmd8 to cache at ./experiments/srl-ontonotes-rte-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:12:07 AM: creating metadata file for ./experiments/srl-ontonotes-rte-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:12:07 AM: removing temp file /tmp/tmpbgodnmd8
09/16 09:12:07 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/srl-ontonotes-rte-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:12:07 AM: Initializing parameters
09/16 09:12:07 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 09:12:07 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 09:12:07 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 09:12:07 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 09:12:07 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 09:12:07 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 09:12:07 AM: 	Task 'edges-srl-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-srl-ontonotes"
}
09/16 09:12:11 AM: Model specification:
09/16 09:12:11 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-srl-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (proj2): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (span_extractor2): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Sequential(
        (0): Linear(in_features=1024, out_features=256, bias=True)
        (1): Tanh()
        (2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)
        (3): Dropout(p=0.3)
        (4): Linear(in_features=256, out_features=66, bias=True)
      )
    )
  )
)
09/16 09:12:11 AM: Model parameters:
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:11 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:11 AM: 	edges-srl-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 09:12:11 AM: 	edges-srl-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 09:12:11 AM: 	edges-srl-ontonotes_mdl.proj2.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 09:12:11 AM: 	edges-srl-ontonotes_mdl.proj2.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 09:12:11 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.0.weight: Trainable parameter, count 262144 with torch.Size([256, 1024])
09/16 09:12:11 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.0.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 09:12:11 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.2.weight: Trainable parameter, count 256 with torch.Size([256])
09/16 09:12:11 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.2.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 09:12:11 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.4.weight: Trainable parameter, count 16896 with torch.Size([66, 256])
09/16 09:12:11 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.4.bias: Trainable parameter, count 66 with torch.Size([66])
09/16 09:12:11 AM: Total number of parameters: 110155842 (1.10156e+08)
09/16 09:12:11 AM: Number of trainable parameters: 673602 (673602)
09/16 09:12:11 AM: Finished building model in 9.539s
09/16 09:12:11 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-srl-ontonotes 

09/16 09:12:26 AM: patience = 9
09/16 09:12:26 AM: val_interval = 1000
09/16 09:12:26 AM: max_vals = 250
09/16 09:12:26 AM: cuda_device = 0
09/16 09:12:26 AM: grad_norm = 5.0
09/16 09:12:26 AM: grad_clipping = None
09/16 09:12:26 AM: lr_decay = 0.99
09/16 09:12:26 AM: min_lr = 1e-06
09/16 09:12:26 AM: keep_all_checkpoints = 0
09/16 09:12:26 AM: val_data_limit = 5000
09/16 09:12:26 AM: max_epochs = -1
09/16 09:12:26 AM: dec_val_scale = 250
09/16 09:12:26 AM: training_data_fraction = 1
09/16 09:12:26 AM: type = adam
09/16 09:12:26 AM: parameter_groups = None
09/16 09:12:26 AM: Number of trainable parameters: 673602
09/16 09:12:26 AM: infer_type_and_cast = True
09/16 09:12:26 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:12:26 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:12:26 AM: lr = 0.0001
09/16 09:12:26 AM: amsgrad = True
09/16 09:12:26 AM: type = reduce_on_plateau
09/16 09:12:26 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:12:26 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:12:26 AM: mode = max
09/16 09:12:26 AM: factor = 0.5
09/16 09:12:26 AM: patience = 3
09/16 09:12:26 AM: threshold = 0.0001
09/16 09:12:26 AM: threshold_mode = abs
09/16 09:12:26 AM: verbose = True
09/16 09:12:26 AM: type = adam
09/16 09:12:26 AM: parameter_groups = None
09/16 09:12:26 AM: Number of trainable parameters: 673602
09/16 09:12:26 AM: infer_type_and_cast = True
09/16 09:12:26 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:12:26 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:12:26 AM: lr = 0.0001
09/16 09:12:26 AM: amsgrad = True
09/16 09:12:26 AM: type = reduce_on_plateau
09/16 09:12:26 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:12:26 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:12:26 AM: mode = max
09/16 09:12:26 AM: factor = 0.5
09/16 09:12:26 AM: patience = 3
09/16 09:12:26 AM: threshold = 0.0001
09/16 09:12:26 AM: threshold_mode = abs
09/16 09:12:26 AM: verbose = True
09/16 09:12:26 AM: Starting training without restoring from a checkpoint.
09/16 09:12:26 AM: Training examples per task, before any subsampling: {'edges-srl-ontonotes': 231480}
09/16 09:12:26 AM: Beginning training with stopping criteria based on metric: edges-srl-ontonotes_f1
09/16 09:12:36 AM: Update 120: task edges-srl-ontonotes, batch 120 (120): mcc: 0.0644, acc: 0.0441, precision: 0.0649, recall: 0.1045, f1: 0.0801, edges-srl-ontonotes_loss: 0.2013
09/16 09:12:46 AM: Update 231: task edges-srl-ontonotes, batch 231 (231): mcc: 0.0540, acc: 0.0307, precision: 0.0734, recall: 0.0614, f1: 0.0669, edges-srl-ontonotes_loss: 0.1393
09/16 09:12:56 AM: Update 342: task edges-srl-ontonotes, batch 342 (342): mcc: 0.0771, acc: 0.0475, precision: 0.1132, recall: 0.0683, f1: 0.0852, edges-srl-ontonotes_loss: 0.1116
09/16 09:13:06 AM: Update 466: task edges-srl-ontonotes, batch 466 (466): mcc: 0.1566, acc: 0.1049, precision: 0.2263, recall: 0.1215, f1: 0.1582, edges-srl-ontonotes_loss: 0.0937
09/16 09:13:16 AM: Update 591: task edges-srl-ontonotes, batch 591 (591): mcc: 0.2390, acc: 0.1633, precision: 0.3396, recall: 0.1800, f1: 0.2353, edges-srl-ontonotes_loss: 0.0818
09/16 09:13:26 AM: Update 683: task edges-srl-ontonotes, batch 683 (683): mcc: 0.2882, acc: 0.1989, precision: 0.4049, recall: 0.2163, f1: 0.2820, edges-srl-ontonotes_loss: 0.0754
09/16 09:13:36 AM: Update 796: task edges-srl-ontonotes, batch 796 (796): mcc: 0.3356, acc: 0.2345, precision: 0.4648, recall: 0.2529, f1: 0.3276, edges-srl-ontonotes_loss: 0.0693
09/16 09:13:47 AM: Update 890: task edges-srl-ontonotes, batch 890 (890): mcc: 0.3705, acc: 0.2620, precision: 0.5066, recall: 0.2812, f1: 0.3616, edges-srl-ontonotes_loss: 0.0652
09/16 09:13:57 AM: Update 976: task edges-srl-ontonotes, batch 976 (976): mcc: 0.3964, acc: 0.2829, precision: 0.5361, recall: 0.3031, f1: 0.3872, edges-srl-ontonotes_loss: 0.0620
09/16 09:13:59 AM: ***** Step 1000 / Validation 1 *****
09/16 09:13:59 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:13:59 AM: Validating...
09/16 09:14:07 AM: Evaluate: task edges-srl-ontonotes, batch 86 (157): mcc: 0.6922, acc: 0.5490, precision: 0.8642, recall: 0.5600, f1: 0.6796, edges-srl-ontonotes_loss: 0.0263
09/16 09:14:13 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:14:13 AM: Best result seen so far for micro.
09/16 09:14:13 AM: Best result seen so far for macro.
09/16 09:14:13 AM: Updating LR scheduler:
09/16 09:14:13 AM: 	Best result seen so far for macro_avg: 0.691
09/16 09:14:13 AM: 	# validation passes without improvement: 0
09/16 09:14:13 AM: edges-srl-ontonotes_loss: training: 0.061237 validation: 0.025762
09/16 09:14:13 AM: macro_avg: validation: 0.691207
09/16 09:14:13 AM: micro_avg: validation: 0.000000
09/16 09:14:13 AM: edges-srl-ontonotes_mcc: training: 0.402700 validation: 0.702427
09/16 09:14:13 AM: edges-srl-ontonotes_acc: training: 0.287998 validation: 0.563159
09/16 09:14:13 AM: edges-srl-ontonotes_precision: training: 0.543102 validation: 0.867302
09/16 09:14:13 AM: edges-srl-ontonotes_recall: training: 0.308513 validation: 0.574552
09/16 09:14:13 AM: edges-srl-ontonotes_f1: training: 0.393497 validation: 0.691207
09/16 09:14:13 AM: Global learning rate: 0.0001
09/16 09:14:13 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:14:17 AM: Update 1037: task edges-srl-ontonotes, batch 37 (1037): mcc: 0.6416, acc: 0.4941, precision: 0.7920, recall: 0.5267, f1: 0.6327, edges-srl-ontonotes_loss: 0.0295
09/16 09:14:27 AM: Update 1144: task edges-srl-ontonotes, batch 144 (1144): mcc: 0.6601, acc: 0.5165, precision: 0.8033, recall: 0.5491, f1: 0.6523, edges-srl-ontonotes_loss: 0.0283
09/16 09:14:37 AM: Update 1253: task edges-srl-ontonotes, batch 253 (1253): mcc: 0.6653, acc: 0.5266, precision: 0.8010, recall: 0.5595, f1: 0.6588, edges-srl-ontonotes_loss: 0.0277
09/16 09:14:47 AM: Update 1355: task edges-srl-ontonotes, batch 355 (1355): mcc: 0.6685, acc: 0.5322, precision: 0.7996, recall: 0.5658, f1: 0.6627, edges-srl-ontonotes_loss: 0.0272
09/16 09:14:57 AM: Update 1472: task edges-srl-ontonotes, batch 472 (1472): mcc: 0.6755, acc: 0.5410, precision: 0.8026, recall: 0.5754, f1: 0.6703, edges-srl-ontonotes_loss: 0.0267
09/16 09:15:07 AM: Update 1574: task edges-srl-ontonotes, batch 574 (1574): mcc: 0.6814, acc: 0.5484, precision: 0.8045, recall: 0.5840, f1: 0.6767, edges-srl-ontonotes_loss: 0.0262
09/16 09:15:17 AM: Update 1688: task edges-srl-ontonotes, batch 688 (1688): mcc: 0.6798, acc: 0.5461, precision: 0.8020, recall: 0.5831, f1: 0.6752, edges-srl-ontonotes_loss: 0.0261
09/16 09:15:27 AM: Update 1786: task edges-srl-ontonotes, batch 786 (1786): mcc: 0.6801, acc: 0.5465, precision: 0.8013, recall: 0.5840, f1: 0.6756, edges-srl-ontonotes_loss: 0.0260
09/16 09:15:40 AM: Update 1879: task edges-srl-ontonotes, batch 879 (1879): mcc: 0.6804, acc: 0.5469, precision: 0.8006, recall: 0.5851, f1: 0.6761, edges-srl-ontonotes_loss: 0.0259
09/16 09:15:50 AM: Update 1980: task edges-srl-ontonotes, batch 980 (1980): mcc: 0.6823, acc: 0.5492, precision: 0.8008, recall: 0.5881, f1: 0.6782, edges-srl-ontonotes_loss: 0.0257
09/16 09:15:52 AM: ***** Step 2000 / Validation 2 *****
09/16 09:15:52 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:15:52 AM: Validating...
09/16 09:16:00 AM: Evaluate: task edges-srl-ontonotes, batch 97 (157): mcc: 0.7451, acc: 0.6266, precision: 0.8648, recall: 0.6476, f1: 0.7406, edges-srl-ontonotes_loss: 0.0206
09/16 09:16:05 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:16:05 AM: Best result seen so far for macro.
09/16 09:16:05 AM: Updating LR scheduler:
09/16 09:16:05 AM: 	Best result seen so far for macro_avg: 0.749
09/16 09:16:05 AM: 	# validation passes without improvement: 0
09/16 09:16:05 AM: edges-srl-ontonotes_loss: training: 0.025699 validation: 0.020188
09/16 09:16:05 AM: macro_avg: validation: 0.748830
09/16 09:16:05 AM: micro_avg: validation: 0.000000
09/16 09:16:05 AM: edges-srl-ontonotes_mcc: training: 0.682506 validation: 0.752715
09/16 09:16:05 AM: edges-srl-ontonotes_acc: training: 0.549415 validation: 0.637595
09/16 09:16:05 AM: edges-srl-ontonotes_precision: training: 0.800550 validation: 0.867024
09/16 09:16:05 AM: edges-srl-ontonotes_recall: training: 0.588740 validation: 0.658995
09/16 09:16:05 AM: edges-srl-ontonotes_f1: training: 0.678499 validation: 0.748830
09/16 09:16:05 AM: Global learning rate: 0.0001
09/16 09:16:05 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:16:10 AM: Update 2054: task edges-srl-ontonotes, batch 54 (2054): mcc: 0.7039, acc: 0.5806, precision: 0.8058, recall: 0.6217, f1: 0.7019, edges-srl-ontonotes_loss: 0.0238
09/16 09:16:20 AM: Update 2171: task edges-srl-ontonotes, batch 171 (2171): mcc: 0.6954, acc: 0.5690, precision: 0.7986, recall: 0.6124, f1: 0.6932, edges-srl-ontonotes_loss: 0.0241
09/16 09:16:30 AM: Update 2266: task edges-srl-ontonotes, batch 266 (2266): mcc: 0.7025, acc: 0.5783, precision: 0.8023, recall: 0.6219, f1: 0.7007, edges-srl-ontonotes_loss: 0.0237
09/16 09:16:40 AM: Update 2363: task edges-srl-ontonotes, batch 363 (2363): mcc: 0.7085, acc: 0.5862, precision: 0.8048, recall: 0.6305, f1: 0.7071, edges-srl-ontonotes_loss: 0.0232
09/16 09:16:50 AM: Update 2468: task edges-srl-ontonotes, batch 468 (2468): mcc: 0.7122, acc: 0.5917, precision: 0.8053, recall: 0.6367, f1: 0.7111, edges-srl-ontonotes_loss: 0.0229
09/16 09:17:00 AM: Update 2568: task edges-srl-ontonotes, batch 568 (2568): mcc: 0.7168, acc: 0.5980, precision: 0.8079, recall: 0.6427, f1: 0.7159, edges-srl-ontonotes_loss: 0.0226
09/16 09:17:10 AM: Update 2677: task edges-srl-ontonotes, batch 677 (2677): mcc: 0.7190, acc: 0.6014, precision: 0.8084, recall: 0.6463, f1: 0.7183, edges-srl-ontonotes_loss: 0.0224
09/16 09:17:20 AM: Update 2788: task edges-srl-ontonotes, batch 788 (2788): mcc: 0.7212, acc: 0.6042, precision: 0.8092, recall: 0.6494, f1: 0.7205, edges-srl-ontonotes_loss: 0.0222
09/16 09:17:30 AM: Update 2861: task edges-srl-ontonotes, batch 861 (2861): mcc: 0.7228, acc: 0.6067, precision: 0.8100, recall: 0.6517, f1: 0.7223, edges-srl-ontonotes_loss: 0.0221
09/16 09:17:40 AM: Update 2960: task edges-srl-ontonotes, batch 960 (2960): mcc: 0.7245, acc: 0.6086, precision: 0.8107, recall: 0.6541, f1: 0.7240, edges-srl-ontonotes_loss: 0.0220
09/16 09:17:45 AM: ***** Step 3000 / Validation 3 *****
09/16 09:17:45 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:17:45 AM: Validating...
09/16 09:17:50 AM: Evaluate: task edges-srl-ontonotes, batch 54 (157): mcc: 0.7478, acc: 0.6430, precision: 0.8409, recall: 0.6710, f1: 0.7464, edges-srl-ontonotes_loss: 0.0202
09/16 09:18:00 AM: Evaluate: task edges-srl-ontonotes, batch 137 (157): mcc: 0.7619, acc: 0.6603, precision: 0.8511, recall: 0.6878, f1: 0.7608, edges-srl-ontonotes_loss: 0.0190
09/16 09:18:03 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:18:03 AM: Best result seen so far for macro.
09/16 09:18:03 AM: Updating LR scheduler:
09/16 09:18:03 AM: 	Best result seen so far for macro_avg: 0.761
09/16 09:18:03 AM: 	# validation passes without improvement: 0
09/16 09:18:03 AM: edges-srl-ontonotes_loss: training: 0.021899 validation: 0.019096
09/16 09:18:03 AM: macro_avg: validation: 0.761354
09/16 09:18:03 AM: micro_avg: validation: 0.000000
09/16 09:18:03 AM: edges-srl-ontonotes_mcc: training: 0.725375 validation: 0.762393
09/16 09:18:03 AM: edges-srl-ontonotes_acc: training: 0.609631 validation: 0.661381
09/16 09:18:03 AM: edges-srl-ontonotes_precision: training: 0.811293 validation: 0.850546
09/16 09:18:03 AM: edges-srl-ontonotes_recall: training: 0.655156 validation: 0.689092
09/16 09:18:03 AM: edges-srl-ontonotes_f1: training: 0.724912 validation: 0.761354
09/16 09:18:03 AM: Global learning rate: 0.0001
09/16 09:18:03 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:18:10 AM: Update 3063: task edges-srl-ontonotes, batch 63 (3063): mcc: 0.7611, acc: 0.6537, precision: 0.8316, recall: 0.7026, f1: 0.7617, edges-srl-ontonotes_loss: 0.0197
09/16 09:18:21 AM: Update 3152: task edges-srl-ontonotes, batch 152 (3152): mcc: 0.7534, acc: 0.6453, precision: 0.8281, recall: 0.6915, f1: 0.7537, edges-srl-ontonotes_loss: 0.0201
09/16 09:18:31 AM: Update 3256: task edges-srl-ontonotes, batch 256 (3256): mcc: 0.7469, acc: 0.6386, precision: 0.8229, recall: 0.6843, f1: 0.7472, edges-srl-ontonotes_loss: 0.0205
09/16 09:18:41 AM: Update 3371: task edges-srl-ontonotes, batch 371 (3371): mcc: 0.7428, acc: 0.6349, precision: 0.8210, recall: 0.6784, f1: 0.7430, edges-srl-ontonotes_loss: 0.0206
09/16 09:18:51 AM: Update 3476: task edges-srl-ontonotes, batch 476 (3476): mcc: 0.7409, acc: 0.6329, precision: 0.8199, recall: 0.6759, f1: 0.7410, edges-srl-ontonotes_loss: 0.0207
09/16 09:19:01 AM: Update 3586: task edges-srl-ontonotes, batch 586 (3586): mcc: 0.7408, acc: 0.6327, precision: 0.8195, recall: 0.6759, f1: 0.7408, edges-srl-ontonotes_loss: 0.0207
09/16 09:19:11 AM: Update 3690: task edges-srl-ontonotes, batch 690 (3690): mcc: 0.7395, acc: 0.6304, precision: 0.8186, recall: 0.6745, f1: 0.7396, edges-srl-ontonotes_loss: 0.0207
09/16 09:19:21 AM: Update 3789: task edges-srl-ontonotes, batch 789 (3789): mcc: 0.7394, acc: 0.6305, precision: 0.8180, recall: 0.6748, f1: 0.7395, edges-srl-ontonotes_loss: 0.0207
09/16 09:19:31 AM: Update 3911: task edges-srl-ontonotes, batch 911 (3911): mcc: 0.7391, acc: 0.6306, precision: 0.8171, recall: 0.6750, f1: 0.7393, edges-srl-ontonotes_loss: 0.0206
09/16 09:19:40 AM: ***** Step 4000 / Validation 4 *****
09/16 09:19:40 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:19:40 AM: Validating...
09/16 09:19:41 AM: Evaluate: task edges-srl-ontonotes, batch 6 (157): mcc: 0.7875, acc: 0.7091, precision: 0.8555, recall: 0.7303, f1: 0.7879, edges-srl-ontonotes_loss: 0.0186
09/16 09:19:52 AM: Evaluate: task edges-srl-ontonotes, batch 104 (157): mcc: 0.7552, acc: 0.6502, precision: 0.8574, recall: 0.6709, f1: 0.7528, edges-srl-ontonotes_loss: 0.0192
09/16 09:19:58 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:19:58 AM: Best result seen so far for macro.
09/16 09:19:58 AM: Updating LR scheduler:
09/16 09:19:58 AM: 	Best result seen so far for macro_avg: 0.764
09/16 09:19:58 AM: 	# validation passes without improvement: 0
09/16 09:19:58 AM: edges-srl-ontonotes_loss: training: 0.020634 validation: 0.018630
09/16 09:19:58 AM: macro_avg: validation: 0.763532
09/16 09:19:58 AM: micro_avg: validation: 0.000000
09/16 09:19:58 AM: edges-srl-ontonotes_mcc: training: 0.738589 validation: 0.765313
09/16 09:19:58 AM: edges-srl-ontonotes_acc: training: 0.629953 validation: 0.664229
09/16 09:19:58 AM: edges-srl-ontonotes_precision: training: 0.816407 validation: 0.860438
09/16 09:19:58 AM: edges-srl-ontonotes_recall: training: 0.674634 validation: 0.686244
09/16 09:19:58 AM: edges-srl-ontonotes_f1: training: 0.738780 validation: 0.763532
09/16 09:19:58 AM: Global learning rate: 0.0001
09/16 09:19:58 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:20:02 AM: Update 4041: task edges-srl-ontonotes, batch 41 (4041): mcc: 0.7352, acc: 0.6278, precision: 0.8123, recall: 0.6719, f1: 0.7354, edges-srl-ontonotes_loss: 0.0208
09/16 09:20:12 AM: Update 4129: task edges-srl-ontonotes, batch 129 (4129): mcc: 0.7372, acc: 0.6323, precision: 0.8130, recall: 0.6750, f1: 0.7376, edges-srl-ontonotes_loss: 0.0206
09/16 09:20:22 AM: Update 4228: task edges-srl-ontonotes, batch 228 (4228): mcc: 0.7455, acc: 0.6411, precision: 0.8195, recall: 0.6845, f1: 0.7459, edges-srl-ontonotes_loss: 0.0201
09/16 09:20:32 AM: Update 4337: task edges-srl-ontonotes, batch 337 (4337): mcc: 0.7496, acc: 0.6467, precision: 0.8224, recall: 0.6896, f1: 0.7501, edges-srl-ontonotes_loss: 0.0199
09/16 09:20:42 AM: Update 4442: task edges-srl-ontonotes, batch 442 (4442): mcc: 0.7500, acc: 0.6474, precision: 0.8217, recall: 0.6908, f1: 0.7506, edges-srl-ontonotes_loss: 0.0199
09/16 09:20:52 AM: Update 4547: task edges-srl-ontonotes, batch 547 (4547): mcc: 0.7519, acc: 0.6495, precision: 0.8229, recall: 0.6932, f1: 0.7525, edges-srl-ontonotes_loss: 0.0197
09/16 09:21:02 AM: Update 4663: task edges-srl-ontonotes, batch 663 (4663): mcc: 0.7530, acc: 0.6510, precision: 0.8239, recall: 0.6944, f1: 0.7536, edges-srl-ontonotes_loss: 0.0196
09/16 09:21:12 AM: Update 4741: task edges-srl-ontonotes, batch 741 (4741): mcc: 0.7515, acc: 0.6496, precision: 0.8232, recall: 0.6923, f1: 0.7521, edges-srl-ontonotes_loss: 0.0198
09/16 09:21:22 AM: Update 4838: task edges-srl-ontonotes, batch 838 (4838): mcc: 0.7494, acc: 0.6471, precision: 0.8219, recall: 0.6895, f1: 0.7499, edges-srl-ontonotes_loss: 0.0199
09/16 09:21:32 AM: Update 4937: task edges-srl-ontonotes, batch 937 (4937): mcc: 0.7484, acc: 0.6459, precision: 0.8218, recall: 0.6879, f1: 0.7489, edges-srl-ontonotes_loss: 0.0200
09/16 09:21:38 AM: ***** Step 5000 / Validation 5 *****
09/16 09:21:38 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:21:38 AM: Validating...
09/16 09:21:42 AM: Evaluate: task edges-srl-ontonotes, batch 50 (157): mcc: 0.7619, acc: 0.6711, precision: 0.8379, recall: 0.6987, f1: 0.7620, edges-srl-ontonotes_loss: 0.0193
09/16 09:21:52 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:21:52 AM: Best result seen so far for macro.
09/16 09:21:52 AM: Updating LR scheduler:
09/16 09:21:52 AM: 	Best result seen so far for macro_avg: 0.768
09/16 09:21:52 AM: 	# validation passes without improvement: 0
09/16 09:21:52 AM: edges-srl-ontonotes_loss: training: 0.019974 validation: 0.018676
09/16 09:21:52 AM: macro_avg: validation: 0.768229
09/16 09:21:52 AM: micro_avg: validation: 0.000000
09/16 09:21:52 AM: edges-srl-ontonotes_mcc: training: 0.748515 validation: 0.768294
09/16 09:21:52 AM: edges-srl-ontonotes_acc: training: 0.645950 validation: 0.676314
09/16 09:21:52 AM: edges-srl-ontonotes_precision: training: 0.822253 validation: 0.845428
09/16 09:21:52 AM: edges-srl-ontonotes_recall: training: 0.687673 validation: 0.703949
09/16 09:21:52 AM: edges-srl-ontonotes_f1: training: 0.748965 validation: 0.768229
09/16 09:21:52 AM: Global learning rate: 0.0001
09/16 09:21:52 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:21:55 AM: Update 5009: task edges-srl-ontonotes, batch 9 (5009): mcc: 0.7357, acc: 0.6350, precision: 0.8096, recall: 0.6751, f1: 0.7362, edges-srl-ontonotes_loss: 0.0216
09/16 09:22:05 AM: Update 5135: task edges-srl-ontonotes, batch 135 (5135): mcc: 0.7548, acc: 0.6505, precision: 0.8282, recall: 0.6941, f1: 0.7553, edges-srl-ontonotes_loss: 0.0194
09/16 09:22:15 AM: Update 5263: task edges-srl-ontonotes, batch 263 (5263): mcc: 0.7642, acc: 0.6629, precision: 0.8341, recall: 0.7060, f1: 0.7647, edges-srl-ontonotes_loss: 0.0189
09/16 09:22:25 AM: Update 5396: task edges-srl-ontonotes, batch 396 (5396): mcc: 0.7724, acc: 0.6731, precision: 0.8394, recall: 0.7167, f1: 0.7732, edges-srl-ontonotes_loss: 0.0182
09/16 09:22:35 AM: Update 5520: task edges-srl-ontonotes, batch 520 (5520): mcc: 0.7808, acc: 0.6836, precision: 0.8457, recall: 0.7265, f1: 0.7816, edges-srl-ontonotes_loss: 0.0177
09/16 09:22:46 AM: Update 5635: task edges-srl-ontonotes, batch 635 (5635): mcc: 0.7874, acc: 0.6922, precision: 0.8501, recall: 0.7348, f1: 0.7883, edges-srl-ontonotes_loss: 0.0172
09/16 09:22:56 AM: Update 5753: task edges-srl-ontonotes, batch 753 (5753): mcc: 0.7897, acc: 0.6949, precision: 0.8512, recall: 0.7380, f1: 0.7906, edges-srl-ontonotes_loss: 0.0171
09/16 09:23:06 AM: Update 5878: task edges-srl-ontonotes, batch 878 (5878): mcc: 0.7933, acc: 0.6994, precision: 0.8536, recall: 0.7427, f1: 0.7943, edges-srl-ontonotes_loss: 0.0168
09/16 09:23:16 AM: Update 5965: task edges-srl-ontonotes, batch 965 (5965): mcc: 0.7946, acc: 0.7010, precision: 0.8540, recall: 0.7446, f1: 0.7956, edges-srl-ontonotes_loss: 0.0168
09/16 09:23:19 AM: ***** Step 6000 / Validation 6 *****
09/16 09:23:19 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:23:19 AM: Validating...
09/16 09:23:26 AM: Evaluate: task edges-srl-ontonotes, batch 90 (157): mcc: 0.7963, acc: 0.7112, precision: 0.8790, recall: 0.7263, f1: 0.7954, edges-srl-ontonotes_loss: 0.0167
09/16 09:23:32 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:23:32 AM: Best result seen so far for macro.
09/16 09:23:32 AM: Updating LR scheduler:
09/16 09:23:32 AM: 	Best result seen so far for macro_avg: 0.802
09/16 09:23:32 AM: 	# validation passes without improvement: 0
09/16 09:23:32 AM: edges-srl-ontonotes_loss: training: 0.016741 validation: 0.016316
09/16 09:23:32 AM: macro_avg: validation: 0.802420
09/16 09:23:32 AM: micro_avg: validation: 0.000000
09/16 09:23:32 AM: edges-srl-ontonotes_mcc: training: 0.795376 validation: 0.802551
09/16 09:23:32 AM: edges-srl-ontonotes_acc: training: 0.702060 validation: 0.721499
09/16 09:23:32 AM: edges-srl-ontonotes_precision: training: 0.854528 validation: 0.875945
09/16 09:23:32 AM: edges-srl-ontonotes_recall: training: 0.745670 validation: 0.740282
09/16 09:23:32 AM: edges-srl-ontonotes_f1: training: 0.796396 validation: 0.802420
09/16 09:23:32 AM: Global learning rate: 0.0001
09/16 09:23:32 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:23:36 AM: Update 6060: task edges-srl-ontonotes, batch 60 (6060): mcc: 0.8118, acc: 0.7204, precision: 0.8659, recall: 0.7660, f1: 0.8129, edges-srl-ontonotes_loss: 0.0157
09/16 09:23:46 AM: Update 6207: task edges-srl-ontonotes, batch 207 (6207): mcc: 0.8154, acc: 0.7287, precision: 0.8659, recall: 0.7728, f1: 0.8168, edges-srl-ontonotes_loss: 0.0153
09/16 09:23:56 AM: Update 6338: task edges-srl-ontonotes, batch 338 (6338): mcc: 0.8165, acc: 0.7308, precision: 0.8675, recall: 0.7734, f1: 0.8177, edges-srl-ontonotes_loss: 0.0152
09/16 09:24:06 AM: Update 6482: task edges-srl-ontonotes, batch 482 (6482): mcc: 0.8196, acc: 0.7356, precision: 0.8699, recall: 0.7769, f1: 0.8208, edges-srl-ontonotes_loss: 0.0150
09/16 09:24:17 AM: Update 6607: task edges-srl-ontonotes, batch 607 (6607): mcc: 0.8185, acc: 0.7345, precision: 0.8691, recall: 0.7757, f1: 0.8197, edges-srl-ontonotes_loss: 0.0151
09/16 09:24:27 AM: Update 6725: task edges-srl-ontonotes, batch 725 (6725): mcc: 0.8124, acc: 0.7273, precision: 0.8642, recall: 0.7688, f1: 0.8137, edges-srl-ontonotes_loss: 0.0156
09/16 09:24:37 AM: Update 6838: task edges-srl-ontonotes, batch 838 (6838): mcc: 0.8086, acc: 0.7227, precision: 0.8610, recall: 0.7644, f1: 0.8098, edges-srl-ontonotes_loss: 0.0158
09/16 09:24:47 AM: Update 6945: task edges-srl-ontonotes, batch 945 (6945): mcc: 0.8043, acc: 0.7176, precision: 0.8577, recall: 0.7594, f1: 0.8055, edges-srl-ontonotes_loss: 0.0161
09/16 09:24:52 AM: ***** Step 7000 / Validation 7 *****
09/16 09:24:52 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:24:52 AM: Validating...
09/16 09:24:57 AM: Evaluate: task edges-srl-ontonotes, batch 60 (157): mcc: 0.8026, acc: 0.7280, precision: 0.8715, recall: 0.7441, f1: 0.8028, edges-srl-ontonotes_loss: 0.0167
09/16 09:25:07 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:25:07 AM: Best result seen so far for macro.
09/16 09:25:07 AM: Updating LR scheduler:
09/16 09:25:07 AM: 	Best result seen so far for macro_avg: 0.817
09/16 09:25:07 AM: 	# validation passes without improvement: 0
09/16 09:25:07 AM: edges-srl-ontonotes_loss: training: 0.016294 validation: 0.015500
09/16 09:25:07 AM: macro_avg: validation: 0.817415
09/16 09:25:07 AM: micro_avg: validation: 0.000000
09/16 09:25:07 AM: edges-srl-ontonotes_mcc: training: 0.801208 validation: 0.816816
09/16 09:25:07 AM: edges-srl-ontonotes_acc: training: 0.713851 validation: 0.747133
09/16 09:25:07 AM: edges-srl-ontonotes_precision: training: 0.855550 validation: 0.878161
09/16 09:25:07 AM: edges-srl-ontonotes_recall: training: 0.755587 validation: 0.764529
09/16 09:25:07 AM: edges-srl-ontonotes_f1: training: 0.802467 validation: 0.817415
09/16 09:25:07 AM: Global learning rate: 0.0001
09/16 09:25:07 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:25:07 AM: Update 7002: task edges-srl-ontonotes, batch 2 (7002): mcc: 0.8096, acc: 0.7188, precision: 0.8652, recall: 0.7625, f1: 0.8106, edges-srl-ontonotes_loss: 0.0175
09/16 09:25:17 AM: Update 7118: task edges-srl-ontonotes, batch 118 (7118): mcc: 0.7729, acc: 0.6790, precision: 0.8312, recall: 0.7246, f1: 0.7742, edges-srl-ontonotes_loss: 0.0182
09/16 09:25:27 AM: Update 7224: task edges-srl-ontonotes, batch 224 (7224): mcc: 0.7700, acc: 0.6777, precision: 0.8311, recall: 0.7193, f1: 0.7712, edges-srl-ontonotes_loss: 0.0186
09/16 09:25:37 AM: Update 7326: task edges-srl-ontonotes, batch 326 (7326): mcc: 0.7770, acc: 0.6864, precision: 0.8377, recall: 0.7265, f1: 0.7782, edges-srl-ontonotes_loss: 0.0182
09/16 09:25:47 AM: Update 7430: task edges-srl-ontonotes, batch 430 (7430): mcc: 0.7791, acc: 0.6882, precision: 0.8399, recall: 0.7285, f1: 0.7802, edges-srl-ontonotes_loss: 0.0179
09/16 09:25:57 AM: Update 7539: task edges-srl-ontonotes, batch 539 (7539): mcc: 0.7835, acc: 0.6935, precision: 0.8434, recall: 0.7336, f1: 0.7846, edges-srl-ontonotes_loss: 0.0176
09/16 09:26:07 AM: Update 7631: task edges-srl-ontonotes, batch 631 (7631): mcc: 0.7859, acc: 0.6963, precision: 0.8451, recall: 0.7364, f1: 0.7870, edges-srl-ontonotes_loss: 0.0174
09/16 09:26:17 AM: Update 7732: task edges-srl-ontonotes, batch 732 (7732): mcc: 0.7873, acc: 0.6984, precision: 0.8462, recall: 0.7382, f1: 0.7885, edges-srl-ontonotes_loss: 0.0173
09/16 09:26:27 AM: Update 7835: task edges-srl-ontonotes, batch 835 (7835): mcc: 0.7900, acc: 0.7019, precision: 0.8483, recall: 0.7412, f1: 0.7911, edges-srl-ontonotes_loss: 0.0171
09/16 09:26:37 AM: Update 7930: task edges-srl-ontonotes, batch 930 (7930): mcc: 0.7903, acc: 0.7023, precision: 0.8483, recall: 0.7417, f1: 0.7914, edges-srl-ontonotes_loss: 0.0171
09/16 09:26:44 AM: ***** Step 8000 / Validation 8 *****
09/16 09:26:44 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:26:44 AM: Validating...
09/16 09:26:48 AM: Evaluate: task edges-srl-ontonotes, batch 38 (157): mcc: 0.8141, acc: 0.7484, precision: 0.8736, recall: 0.7635, f1: 0.8148, edges-srl-ontonotes_loss: 0.0153
09/16 09:26:58 AM: Evaluate: task edges-srl-ontonotes, batch 147 (157): mcc: 0.8277, acc: 0.7626, precision: 0.8831, recall: 0.7803, f1: 0.8285, edges-srl-ontonotes_loss: 0.0142
09/16 09:26:58 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:26:58 AM: Best result seen so far for macro.
09/16 09:26:58 AM: Updating LR scheduler:
09/16 09:26:58 AM: 	Best result seen so far for macro_avg: 0.827
09/16 09:26:58 AM: 	# validation passes without improvement: 0
09/16 09:26:58 AM: edges-srl-ontonotes_loss: training: 0.017116 validation: 0.014411
09/16 09:26:58 AM: macro_avg: validation: 0.827383
09/16 09:26:58 AM: micro_avg: validation: 0.000000
09/16 09:26:58 AM: edges-srl-ontonotes_mcc: training: 0.790256 validation: 0.826560
09/16 09:26:58 AM: edges-srl-ontonotes_acc: training: 0.702205 validation: 0.760988
09/16 09:26:58 AM: edges-srl-ontonotes_precision: training: 0.848066 validation: 0.882568
09/16 09:26:58 AM: edges-srl-ontonotes_recall: training: 0.741888 validation: 0.778693
09/16 09:26:58 AM: edges-srl-ontonotes_f1: training: 0.791432 validation: 0.827383
09/16 09:26:59 AM: Global learning rate: 0.0001
09/16 09:26:59 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:27:08 AM: Update 8096: task edges-srl-ontonotes, batch 96 (8096): mcc: 0.7893, acc: 0.7083, precision: 0.8463, recall: 0.7416, f1: 0.7905, edges-srl-ontonotes_loss: 0.0172
09/16 09:27:19 AM: Update 8186: task edges-srl-ontonotes, batch 186 (8186): mcc: 0.7830, acc: 0.6990, precision: 0.8415, recall: 0.7342, f1: 0.7842, edges-srl-ontonotes_loss: 0.0175
09/16 09:27:29 AM: Update 8289: task edges-srl-ontonotes, batch 289 (8289): mcc: 0.7778, acc: 0.6915, precision: 0.8371, recall: 0.7285, f1: 0.7790, edges-srl-ontonotes_loss: 0.0179
09/16 09:27:39 AM: Update 8408: task edges-srl-ontonotes, batch 408 (8408): mcc: 0.7742, acc: 0.6865, precision: 0.8354, recall: 0.7234, f1: 0.7754, edges-srl-ontonotes_loss: 0.0182
09/16 09:27:49 AM: Update 8500: task edges-srl-ontonotes, batch 500 (8500): mcc: 0.7732, acc: 0.6847, precision: 0.8351, recall: 0.7217, f1: 0.7743, edges-srl-ontonotes_loss: 0.0182
09/16 09:27:59 AM: Update 8604: task edges-srl-ontonotes, batch 604 (8604): mcc: 0.7714, acc: 0.6825, precision: 0.8335, recall: 0.7198, f1: 0.7725, edges-srl-ontonotes_loss: 0.0182
09/16 09:28:09 AM: Update 8740: task edges-srl-ontonotes, batch 740 (8740): mcc: 0.7719, acc: 0.6829, precision: 0.8339, recall: 0.7204, f1: 0.7730, edges-srl-ontonotes_loss: 0.0182
09/16 09:28:19 AM: Update 8832: task edges-srl-ontonotes, batch 832 (8832): mcc: 0.7714, acc: 0.6821, precision: 0.8333, recall: 0.7199, f1: 0.7725, edges-srl-ontonotes_loss: 0.0182
09/16 09:28:29 AM: Update 8915: task edges-srl-ontonotes, batch 915 (8915): mcc: 0.7689, acc: 0.6791, precision: 0.8311, recall: 0.7174, f1: 0.7701, edges-srl-ontonotes_loss: 0.0183
09/16 09:28:38 AM: ***** Step 9000 / Validation 9 *****
09/16 09:28:38 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:28:38 AM: Validating...
09/16 09:28:40 AM: Evaluate: task edges-srl-ontonotes, batch 13 (157): mcc: 0.8272, acc: 0.7655, precision: 0.8719, recall: 0.7894, f1: 0.8286, edges-srl-ontonotes_loss: 0.0145
09/16 09:28:50 AM: Evaluate: task edges-srl-ontonotes, batch 121 (157): mcc: 0.8287, acc: 0.7677, precision: 0.8793, recall: 0.7856, f1: 0.8298, edges-srl-ontonotes_loss: 0.0142
09/16 09:28:53 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:28:53 AM: Best result seen so far for macro.
09/16 09:28:53 AM: Updating LR scheduler:
09/16 09:28:53 AM: 	Best result seen so far for macro_avg: 0.828
09/16 09:28:53 AM: 	# validation passes without improvement: 0
09/16 09:28:53 AM: edges-srl-ontonotes_loss: training: 0.018504 validation: 0.014326
09/16 09:28:53 AM: macro_avg: validation: 0.827998
09/16 09:28:53 AM: micro_avg: validation: 0.000000
09/16 09:28:53 AM: edges-srl-ontonotes_mcc: training: 0.765685 validation: 0.826812
09/16 09:28:53 AM: edges-srl-ontonotes_acc: training: 0.674988 validation: 0.765068
09/16 09:28:53 AM: edges-srl-ontonotes_precision: training: 0.829096 validation: 0.876645
09/16 09:28:53 AM: edges-srl-ontonotes_recall: training: 0.713161 validation: 0.784466
09/16 09:28:53 AM: edges-srl-ontonotes_f1: training: 0.766771 validation: 0.827998
09/16 09:28:53 AM: Global learning rate: 0.0001
09/16 09:28:53 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:29:00 AM: Update 9060: task edges-srl-ontonotes, batch 60 (9060): mcc: 0.7579, acc: 0.6678, precision: 0.8263, recall: 0.7013, f1: 0.7587, edges-srl-ontonotes_loss: 0.0192
09/16 09:29:10 AM: Update 9132: task edges-srl-ontonotes, batch 132 (9132): mcc: 0.7600, acc: 0.6703, precision: 0.8255, recall: 0.7058, f1: 0.7610, edges-srl-ontonotes_loss: 0.0191
09/16 09:29:20 AM: Update 9227: task edges-srl-ontonotes, batch 227 (9227): mcc: 0.7579, acc: 0.6672, precision: 0.8250, recall: 0.7025, f1: 0.7588, edges-srl-ontonotes_loss: 0.0192
09/16 09:29:30 AM: Update 9318: task edges-srl-ontonotes, batch 318 (9318): mcc: 0.7564, acc: 0.6645, precision: 0.8233, recall: 0.7011, f1: 0.7573, edges-srl-ontonotes_loss: 0.0192
09/16 09:29:41 AM: Update 9438: task edges-srl-ontonotes, batch 438 (9438): mcc: 0.7566, acc: 0.6645, precision: 0.8240, recall: 0.7009, f1: 0.7575, edges-srl-ontonotes_loss: 0.0192
09/16 09:29:51 AM: Update 9559: task edges-srl-ontonotes, batch 559 (9559): mcc: 0.7613, acc: 0.6710, precision: 0.8269, recall: 0.7069, f1: 0.7622, edges-srl-ontonotes_loss: 0.0188
09/16 09:30:01 AM: Update 9689: task edges-srl-ontonotes, batch 689 (9689): mcc: 0.7650, acc: 0.6756, precision: 0.8297, recall: 0.7114, f1: 0.7660, edges-srl-ontonotes_loss: 0.0186
09/16 09:30:11 AM: Update 9807: task edges-srl-ontonotes, batch 807 (9807): mcc: 0.7667, acc: 0.6786, precision: 0.8310, recall: 0.7132, f1: 0.7677, edges-srl-ontonotes_loss: 0.0185
09/16 09:30:21 AM: Update 9939: task edges-srl-ontonotes, batch 939 (9939): mcc: 0.7701, acc: 0.6826, precision: 0.8335, recall: 0.7174, f1: 0.7711, edges-srl-ontonotes_loss: 0.0182
09/16 09:30:26 AM: ***** Step 10000 / Validation 10 *****
09/16 09:30:26 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:30:26 AM: Validating...
09/16 09:30:31 AM: Evaluate: task edges-srl-ontonotes, batch 66 (157): mcc: 0.8070, acc: 0.7413, precision: 0.8663, recall: 0.7568, f1: 0.8079, edges-srl-ontonotes_loss: 0.0155
09/16 09:30:37 AM: Updating LR scheduler:
09/16 09:30:37 AM: 	Best result seen so far for macro_avg: 0.828
09/16 09:30:37 AM: 	# validation passes without improvement: 1
09/16 09:30:37 AM: edges-srl-ontonotes_loss: training: 0.018197 validation: 0.014495
09/16 09:30:37 AM: macro_avg: validation: 0.823912
09/16 09:30:37 AM: micro_avg: validation: 0.000000
09/16 09:30:37 AM: edges-srl-ontonotes_mcc: training: 0.770143 validation: 0.822754
09/16 09:30:37 AM: edges-srl-ontonotes_acc: training: 0.682413 validation: 0.761450
09/16 09:30:37 AM: edges-srl-ontonotes_precision: training: 0.833550 validation: 0.874029
09/16 09:30:37 AM: edges-srl-ontonotes_recall: training: 0.717485 validation: 0.779232
09/16 09:30:37 AM: edges-srl-ontonotes_f1: training: 0.771175 validation: 0.823912
09/16 09:30:37 AM: Global learning rate: 0.0001
09/16 09:30:37 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:30:41 AM: Update 10046: task edges-srl-ontonotes, batch 46 (10046): mcc: 0.7905, acc: 0.7149, precision: 0.8466, recall: 0.7437, f1: 0.7918, edges-srl-ontonotes_loss: 0.0169
09/16 09:30:51 AM: Update 10133: task edges-srl-ontonotes, batch 133 (10133): mcc: 0.7904, acc: 0.7140, precision: 0.8443, recall: 0.7456, f1: 0.7919, edges-srl-ontonotes_loss: 0.0169
09/16 09:31:01 AM: Update 10265: task edges-srl-ontonotes, batch 265 (10265): mcc: 0.7915, acc: 0.7117, precision: 0.8467, recall: 0.7455, f1: 0.7929, edges-srl-ontonotes_loss: 0.0169
09/16 09:31:11 AM: Update 10389: task edges-srl-ontonotes, batch 389 (10389): mcc: 0.7920, acc: 0.7112, precision: 0.8478, recall: 0.7454, f1: 0.7933, edges-srl-ontonotes_loss: 0.0169
09/16 09:31:21 AM: Update 10511: task edges-srl-ontonotes, batch 511 (10511): mcc: 0.7880, acc: 0.7061, precision: 0.8446, recall: 0.7407, f1: 0.7893, edges-srl-ontonotes_loss: 0.0171
09/16 09:31:31 AM: Update 10637: task edges-srl-ontonotes, batch 637 (10637): mcc: 0.7866, acc: 0.7045, precision: 0.8449, recall: 0.7378, f1: 0.7877, edges-srl-ontonotes_loss: 0.0172
09/16 09:31:41 AM: Update 10740: task edges-srl-ontonotes, batch 740 (10740): mcc: 0.7856, acc: 0.7035, precision: 0.8445, recall: 0.7364, f1: 0.7868, edges-srl-ontonotes_loss: 0.0172
09/16 09:31:51 AM: Update 10868: task edges-srl-ontonotes, batch 868 (10868): mcc: 0.7841, acc: 0.7014, precision: 0.8439, recall: 0.7342, f1: 0.7852, edges-srl-ontonotes_loss: 0.0173
09/16 09:32:01 AM: Update 11000: task edges-srl-ontonotes, batch 1000 (11000): mcc: 0.7837, acc: 0.7009, precision: 0.8437, recall: 0.7336, f1: 0.7848, edges-srl-ontonotes_loss: 0.0173
09/16 09:32:01 AM: ***** Step 11000 / Validation 11 *****
09/16 09:32:01 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:32:01 AM: Validating...
09/16 09:32:11 AM: Evaluate: task edges-srl-ontonotes, batch 137 (157): mcc: 0.8172, acc: 0.7506, precision: 0.8731, recall: 0.7698, f1: 0.8182, edges-srl-ontonotes_loss: 0.0147
09/16 09:32:13 AM: Updating LR scheduler:
09/16 09:32:13 AM: 	Best result seen so far for macro_avg: 0.828
09/16 09:32:13 AM: 	# validation passes without improvement: 2
09/16 09:32:13 AM: edges-srl-ontonotes_loss: training: 0.017301 validation: 0.014870
09/16 09:32:13 AM: macro_avg: validation: 0.817070
09/16 09:32:13 AM: micro_avg: validation: 0.000000
09/16 09:32:13 AM: edges-srl-ontonotes_mcc: training: 0.783707 validation: 0.816106
09/16 09:32:13 AM: edges-srl-ontonotes_acc: training: 0.700882 validation: 0.749211
09/16 09:32:13 AM: edges-srl-ontonotes_precision: training: 0.843713 validation: 0.872052
09/16 09:32:13 AM: edges-srl-ontonotes_recall: training: 0.733605 validation: 0.768609
09/16 09:32:13 AM: edges-srl-ontonotes_f1: training: 0.784816 validation: 0.817070
09/16 09:32:13 AM: Global learning rate: 0.0001
09/16 09:32:13 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:32:21 AM: Update 11102: task edges-srl-ontonotes, batch 102 (11102): mcc: 0.7760, acc: 0.6917, precision: 0.8358, recall: 0.7263, f1: 0.7772, edges-srl-ontonotes_loss: 0.0176
09/16 09:32:31 AM: Update 11236: task edges-srl-ontonotes, batch 236 (11236): mcc: 0.7739, acc: 0.6893, precision: 0.8356, recall: 0.7226, f1: 0.7750, edges-srl-ontonotes_loss: 0.0178
09/16 09:32:41 AM: Update 11326: task edges-srl-ontonotes, batch 326 (11326): mcc: 0.7757, acc: 0.6908, precision: 0.8374, recall: 0.7243, f1: 0.7768, edges-srl-ontonotes_loss: 0.0176
09/16 09:32:52 AM: Update 11454: task edges-srl-ontonotes, batch 454 (11454): mcc: 0.7775, acc: 0.6942, precision: 0.8381, recall: 0.7270, f1: 0.7786, edges-srl-ontonotes_loss: 0.0175
09/16 09:33:02 AM: Update 11588: task edges-srl-ontonotes, batch 588 (11588): mcc: 0.7808, acc: 0.6989, precision: 0.8406, recall: 0.7310, f1: 0.7820, edges-srl-ontonotes_loss: 0.0174
09/16 09:33:12 AM: Update 11709: task edges-srl-ontonotes, batch 709 (11709): mcc: 0.7824, acc: 0.7005, precision: 0.8416, recall: 0.7330, f1: 0.7835, edges-srl-ontonotes_loss: 0.0172
09/16 09:33:22 AM: Update 11843: task edges-srl-ontonotes, batch 843 (11843): mcc: 0.7845, acc: 0.7028, precision: 0.8434, recall: 0.7353, f1: 0.7857, edges-srl-ontonotes_loss: 0.0171
09/16 09:33:32 AM: Update 11953: task edges-srl-ontonotes, batch 953 (11953): mcc: 0.7844, acc: 0.7030, precision: 0.8430, recall: 0.7355, f1: 0.7856, edges-srl-ontonotes_loss: 0.0171
09/16 09:33:36 AM: ***** Step 12000 / Validation 12 *****
09/16 09:33:36 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:33:36 AM: Validating...
09/16 09:33:42 AM: Evaluate: task edges-srl-ontonotes, batch 77 (157): mcc: 0.8062, acc: 0.7407, precision: 0.8667, recall: 0.7550, f1: 0.8070, edges-srl-ontonotes_loss: 0.0157
09/16 09:33:48 AM: Updating LR scheduler:
09/16 09:33:48 AM: 	Best result seen so far for macro_avg: 0.828
09/16 09:33:48 AM: 	# validation passes without improvement: 3
09/16 09:33:48 AM: edges-srl-ontonotes_loss: training: 0.017227 validation: 0.014896
09/16 09:33:48 AM: macro_avg: validation: 0.818613
09/16 09:33:48 AM: micro_avg: validation: 0.000000
09/16 09:33:48 AM: edges-srl-ontonotes_mcc: training: 0.782963 validation: 0.817586
09/16 09:33:48 AM: edges-srl-ontonotes_acc: training: 0.701182 validation: 0.755215
09/16 09:33:48 AM: edges-srl-ontonotes_precision: training: 0.842228 validation: 0.872203
09/16 09:33:48 AM: edges-srl-ontonotes_recall: training: 0.733536 validation: 0.771226
09/16 09:33:48 AM: edges-srl-ontonotes_f1: training: 0.784133 validation: 0.818613
09/16 09:33:48 AM: Global learning rate: 0.0001
09/16 09:33:48 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:33:52 AM: Update 12044: task edges-srl-ontonotes, batch 44 (12044): mcc: 0.7639, acc: 0.6732, precision: 0.8353, recall: 0.7046, f1: 0.7644, edges-srl-ontonotes_loss: 0.0188
09/16 09:34:02 AM: Update 12153: task edges-srl-ontonotes, batch 153 (12153): mcc: 0.7617, acc: 0.6721, precision: 0.8330, recall: 0.7025, f1: 0.7622, edges-srl-ontonotes_loss: 0.0185
09/16 09:34:13 AM: Update 12255: task edges-srl-ontonotes, batch 255 (12255): mcc: 0.7667, acc: 0.6786, precision: 0.8352, recall: 0.7097, f1: 0.7674, edges-srl-ontonotes_loss: 0.0183
09/16 09:34:23 AM: Update 12398: task edges-srl-ontonotes, batch 398 (12398): mcc: 0.7776, acc: 0.6930, precision: 0.8408, recall: 0.7250, f1: 0.7786, edges-srl-ontonotes_loss: 0.0177
09/16 09:34:33 AM: Update 12533: task edges-srl-ontonotes, batch 533 (12533): mcc: 0.7858, acc: 0.7021, precision: 0.8459, recall: 0.7355, f1: 0.7868, edges-srl-ontonotes_loss: 0.0171
09/16 09:34:44 AM: Update 12671: task edges-srl-ontonotes, batch 671 (12671): mcc: 0.7943, acc: 0.7131, precision: 0.8513, recall: 0.7465, f1: 0.7954, edges-srl-ontonotes_loss: 0.0165
09/16 09:34:54 AM: Update 12831: task edges-srl-ontonotes, batch 831 (12831): mcc: 0.8040, acc: 0.7256, precision: 0.8577, recall: 0.7589, f1: 0.8053, edges-srl-ontonotes_loss: 0.0158
09/16 09:35:04 AM: Update 12966: task edges-srl-ontonotes, batch 966 (12966): mcc: 0.8090, acc: 0.7318, precision: 0.8613, recall: 0.7649, f1: 0.8102, edges-srl-ontonotes_loss: 0.0155
09/16 09:35:06 AM: ***** Step 13000 / Validation 13 *****
09/16 09:35:06 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:35:06 AM: Validating...
09/16 09:35:14 AM: Evaluate: task edges-srl-ontonotes, batch 110 (157): mcc: 0.8260, acc: 0.7621, precision: 0.8815, recall: 0.7786, f1: 0.8269, edges-srl-ontonotes_loss: 0.0144
09/16 09:35:17 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:35:17 AM: Best result seen so far for macro.
09/16 09:35:17 AM: Updating LR scheduler:
09/16 09:35:17 AM: 	Best result seen so far for macro_avg: 0.829
09/16 09:35:17 AM: 	# validation passes without improvement: 0
09/16 09:35:17 AM: edges-srl-ontonotes_loss: training: 0.015422 validation: 0.014328
09/16 09:35:17 AM: macro_avg: validation: 0.828502
09/16 09:35:17 AM: micro_avg: validation: 0.000000
09/16 09:35:17 AM: edges-srl-ontonotes_mcc: training: 0.810353 validation: 0.827447
09/16 09:35:17 AM: edges-srl-ontonotes_acc: training: 0.733592 validation: 0.765299
09/16 09:35:17 AM: edges-srl-ontonotes_precision: training: 0.862404 validation: 0.879419
09/16 09:35:17 AM: edges-srl-ontonotes_recall: training: 0.766504 validation: 0.783158
09/16 09:35:17 AM: edges-srl-ontonotes_f1: training: 0.811631 validation: 0.828502
09/16 09:35:17 AM: Global learning rate: 0.0001
09/16 09:35:17 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:35:24 AM: Update 13092: task edges-srl-ontonotes, batch 92 (13092): mcc: 0.8335, acc: 0.7646, precision: 0.8779, recall: 0.7958, f1: 0.8348, edges-srl-ontonotes_loss: 0.0138
09/16 09:35:34 AM: Update 13198: task edges-srl-ontonotes, batch 198 (13198): mcc: 0.8402, acc: 0.7728, precision: 0.8834, recall: 0.8034, f1: 0.8415, edges-srl-ontonotes_loss: 0.0134
09/16 09:35:44 AM: Update 13334: task edges-srl-ontonotes, batch 334 (13334): mcc: 0.8423, acc: 0.7747, precision: 0.8844, recall: 0.8064, f1: 0.8436, edges-srl-ontonotes_loss: 0.0133
09/16 09:35:54 AM: Update 13466: task edges-srl-ontonotes, batch 466 (13466): mcc: 0.8435, acc: 0.7758, precision: 0.8856, recall: 0.8077, f1: 0.8449, edges-srl-ontonotes_loss: 0.0132
09/16 09:36:04 AM: Update 13566: task edges-srl-ontonotes, batch 566 (13566): mcc: 0.8433, acc: 0.7761, precision: 0.8848, recall: 0.8082, f1: 0.8447, edges-srl-ontonotes_loss: 0.0132
09/16 09:36:14 AM: Update 13723: task edges-srl-ontonotes, batch 723 (13723): mcc: 0.8448, acc: 0.7781, precision: 0.8859, recall: 0.8099, f1: 0.8462, edges-srl-ontonotes_loss: 0.0131
09/16 09:36:24 AM: Update 13859: task edges-srl-ontonotes, batch 859 (13859): mcc: 0.8433, acc: 0.7767, precision: 0.8843, recall: 0.8085, f1: 0.8447, edges-srl-ontonotes_loss: 0.0132
09/16 09:36:34 AM: Update 13992: task edges-srl-ontonotes, batch 992 (13992): mcc: 0.8379, acc: 0.7700, precision: 0.8804, recall: 0.8020, f1: 0.8393, edges-srl-ontonotes_loss: 0.0136
09/16 09:36:35 AM: ***** Step 14000 / Validation 14 *****
09/16 09:36:35 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:36:35 AM: Validating...
09/16 09:36:44 AM: Evaluate: task edges-srl-ontonotes, batch 129 (157): mcc: 0.8399, acc: 0.7849, precision: 0.8885, recall: 0.7982, f1: 0.8409, edges-srl-ontonotes_loss: 0.0134
09/16 09:36:46 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:36:46 AM: Best result seen so far for macro.
09/16 09:36:46 AM: Updating LR scheduler:
09/16 09:36:46 AM: 	Best result seen so far for macro_avg: 0.835
09/16 09:36:46 AM: 	# validation passes without improvement: 0
09/16 09:36:46 AM: edges-srl-ontonotes_loss: training: 0.013597 validation: 0.013767
09/16 09:36:46 AM: macro_avg: validation: 0.835156
09/16 09:36:46 AM: micro_avg: validation: 0.000000
09/16 09:36:46 AM: edges-srl-ontonotes_mcc: training: 0.837749 validation: 0.834122
09/16 09:36:46 AM: edges-srl-ontonotes_acc: training: 0.769769 validation: 0.777307
09/16 09:36:46 AM: edges-srl-ontonotes_precision: training: 0.880195 validation: 0.884907
09/16 09:36:46 AM: edges-srl-ontonotes_recall: training: 0.801798 validation: 0.790701
09/16 09:36:46 AM: edges-srl-ontonotes_f1: training: 0.839169 validation: 0.835156
09/16 09:36:46 AM: Global learning rate: 0.0001
09/16 09:36:46 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:36:54 AM: Update 14115: task edges-srl-ontonotes, batch 115 (14115): mcc: 0.8146, acc: 0.7429, precision: 0.8622, recall: 0.7747, f1: 0.8161, edges-srl-ontonotes_loss: 0.0152
09/16 09:37:04 AM: Update 14225: task edges-srl-ontonotes, batch 225 (14225): mcc: 0.8014, acc: 0.7250, precision: 0.8537, recall: 0.7576, f1: 0.8028, edges-srl-ontonotes_loss: 0.0161
09/16 09:37:14 AM: Update 14357: task edges-srl-ontonotes, batch 357 (14357): mcc: 0.7954, acc: 0.7184, precision: 0.8483, recall: 0.7513, f1: 0.7969, edges-srl-ontonotes_loss: 0.0165
09/16 09:37:24 AM: Update 14489: task edges-srl-ontonotes, batch 489 (14489): mcc: 0.7938, acc: 0.7163, precision: 0.8472, recall: 0.7492, f1: 0.7952, edges-srl-ontonotes_loss: 0.0166
09/16 09:37:34 AM: Update 14605: task edges-srl-ontonotes, batch 605 (14605): mcc: 0.7981, acc: 0.7211, precision: 0.8512, recall: 0.7537, f1: 0.7995, edges-srl-ontonotes_loss: 0.0163
09/16 09:37:44 AM: Update 14758: task edges-srl-ontonotes, batch 758 (14758): mcc: 0.8015, acc: 0.7253, precision: 0.8538, recall: 0.7578, f1: 0.8029, edges-srl-ontonotes_loss: 0.0160
09/16 09:37:54 AM: Update 14891: task edges-srl-ontonotes, batch 891 (14891): mcc: 0.8043, acc: 0.7285, precision: 0.8564, recall: 0.7605, f1: 0.8056, edges-srl-ontonotes_loss: 0.0159
09/16 09:38:02 AM: ***** Step 15000 / Validation 15 *****
09/16 09:38:02 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:38:02 AM: Validating...
09/16 09:38:04 AM: Evaluate: task edges-srl-ontonotes, batch 33 (157): mcc: 0.8282, acc: 0.7759, precision: 0.8718, recall: 0.7914, f1: 0.8297, edges-srl-ontonotes_loss: 0.0138
09/16 09:38:13 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:38:13 AM: Best result seen so far for macro.
09/16 09:38:13 AM: Updating LR scheduler:
09/16 09:38:13 AM: 	Best result seen so far for macro_avg: 0.844
09/16 09:38:13 AM: 	# validation passes without improvement: 0
09/16 09:38:13 AM: edges-srl-ontonotes_loss: training: 0.015739 validation: 0.012982
09/16 09:38:13 AM: macro_avg: validation: 0.843528
09/16 09:38:13 AM: micro_avg: validation: 0.000000
09/16 09:38:13 AM: edges-srl-ontonotes_mcc: training: 0.805969 validation: 0.842252
09/16 09:38:13 AM: edges-srl-ontonotes_acc: training: 0.730930 validation: 0.789547
09/16 09:38:13 AM: edges-srl-ontonotes_precision: training: 0.857671 validation: 0.886373
09/16 09:38:13 AM: edges-srl-ontonotes_recall: training: 0.762564 validation: 0.804634
09/16 09:38:13 AM: edges-srl-ontonotes_f1: training: 0.807326 validation: 0.843528
09/16 09:38:13 AM: Global learning rate: 0.0001
09/16 09:38:13 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:38:14 AM: Update 15014: task edges-srl-ontonotes, batch 14 (15014): mcc: 0.8155, acc: 0.7483, precision: 0.8611, recall: 0.7773, f1: 0.8170, edges-srl-ontonotes_loss: 0.0152
09/16 09:38:24 AM: Update 15154: task edges-srl-ontonotes, batch 154 (15154): mcc: 0.8143, acc: 0.7427, precision: 0.8613, recall: 0.7748, f1: 0.8158, edges-srl-ontonotes_loss: 0.0151
09/16 09:38:34 AM: Update 15299: task edges-srl-ontonotes, batch 299 (15299): mcc: 0.8090, acc: 0.7354, precision: 0.8584, recall: 0.7676, f1: 0.8105, edges-srl-ontonotes_loss: 0.0155
09/16 09:38:47 AM: Update 15432: task edges-srl-ontonotes, batch 432 (15432): mcc: 0.8086, acc: 0.7354, precision: 0.8581, recall: 0.7670, f1: 0.8100, edges-srl-ontonotes_loss: 0.0155
09/16 09:38:57 AM: Update 15561: task edges-srl-ontonotes, batch 561 (15561): mcc: 0.8032, acc: 0.7283, precision: 0.8541, recall: 0.7607, f1: 0.8047, edges-srl-ontonotes_loss: 0.0159
09/16 09:39:07 AM: Update 15706: task edges-srl-ontonotes, batch 706 (15706): mcc: 0.8012, acc: 0.7258, precision: 0.8531, recall: 0.7577, f1: 0.8026, edges-srl-ontonotes_loss: 0.0161
09/16 09:39:17 AM: Update 15836: task edges-srl-ontonotes, batch 836 (15836): mcc: 0.7983, acc: 0.7220, precision: 0.8510, recall: 0.7542, f1: 0.7997, edges-srl-ontonotes_loss: 0.0162
09/16 09:39:27 AM: Update 15971: task edges-srl-ontonotes, batch 971 (15971): mcc: 0.7973, acc: 0.7211, precision: 0.8499, recall: 0.7533, f1: 0.7987, edges-srl-ontonotes_loss: 0.0162
09/16 09:39:29 AM: ***** Step 16000 / Validation 16 *****
09/16 09:39:29 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:39:29 AM: Validating...
09/16 09:39:37 AM: Evaluate: task edges-srl-ontonotes, batch 104 (157): mcc: 0.8428, acc: 0.7906, precision: 0.8880, recall: 0.8042, f1: 0.8440, edges-srl-ontonotes_loss: 0.0128
09/16 09:39:41 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:39:41 AM: Best result seen so far for macro.
09/16 09:39:41 AM: Updating LR scheduler:
09/16 09:39:41 AM: 	Best result seen so far for macro_avg: 0.846
09/16 09:39:41 AM: 	# validation passes without improvement: 0
09/16 09:39:41 AM: edges-srl-ontonotes_loss: training: 0.016217 validation: 0.012790
09/16 09:39:41 AM: macro_avg: validation: 0.846281
09/16 09:39:41 AM: micro_avg: validation: 0.000000
09/16 09:39:41 AM: edges-srl-ontonotes_mcc: training: 0.797519 validation: 0.844962
09/16 09:39:41 AM: edges-srl-ontonotes_acc: training: 0.721244 validation: 0.794704
09/16 09:39:41 AM: edges-srl-ontonotes_precision: training: 0.850119 validation: 0.887416
09/16 09:39:41 AM: edges-srl-ontonotes_recall: training: 0.753562 validation: 0.808791
09/16 09:39:41 AM: edges-srl-ontonotes_f1: training: 0.798934 validation: 0.846281
09/16 09:39:41 AM: Global learning rate: 0.0001
09/16 09:39:41 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:39:47 AM: Update 16072: task edges-srl-ontonotes, batch 72 (16072): mcc: 0.7920, acc: 0.7144, precision: 0.8469, recall: 0.7461, f1: 0.7933, edges-srl-ontonotes_loss: 0.0165
09/16 09:39:57 AM: Update 16205: task edges-srl-ontonotes, batch 205 (16205): mcc: 0.7757, acc: 0.6953, precision: 0.8354, recall: 0.7262, f1: 0.7770, edges-srl-ontonotes_loss: 0.0177
09/16 09:40:07 AM: Update 16337: task edges-srl-ontonotes, batch 337 (16337): mcc: 0.7735, acc: 0.6922, precision: 0.8328, recall: 0.7243, f1: 0.7748, edges-srl-ontonotes_loss: 0.0178
09/16 09:40:17 AM: Update 16436: task edges-srl-ontonotes, batch 436 (16436): mcc: 0.7723, acc: 0.6905, precision: 0.8317, recall: 0.7230, f1: 0.7736, edges-srl-ontonotes_loss: 0.0179
09/16 09:40:27 AM: Update 16568: task edges-srl-ontonotes, batch 568 (16568): mcc: 0.7720, acc: 0.6901, precision: 0.8326, recall: 0.7217, f1: 0.7732, edges-srl-ontonotes_loss: 0.0179
09/16 09:40:37 AM: Update 16685: task edges-srl-ontonotes, batch 685 (16685): mcc: 0.7739, acc: 0.6923, precision: 0.8344, recall: 0.7236, f1: 0.7751, edges-srl-ontonotes_loss: 0.0178
09/16 09:40:47 AM: Update 16805: task edges-srl-ontonotes, batch 805 (16805): mcc: 0.7775, acc: 0.6967, precision: 0.8372, recall: 0.7278, f1: 0.7787, edges-srl-ontonotes_loss: 0.0175
09/16 09:40:57 AM: Update 16934: task edges-srl-ontonotes, batch 934 (16934): mcc: 0.7807, acc: 0.7006, precision: 0.8394, recall: 0.7317, f1: 0.7819, edges-srl-ontonotes_loss: 0.0173
09/16 09:41:03 AM: ***** Step 17000 / Validation 17 *****
09/16 09:41:03 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:41:03 AM: Validating...
09/16 09:41:07 AM: Evaluate: task edges-srl-ontonotes, batch 53 (157): mcc: 0.8279, acc: 0.7724, precision: 0.8763, recall: 0.7869, f1: 0.8292, edges-srl-ontonotes_loss: 0.0141
09/16 09:41:15 AM: Updating LR scheduler:
09/16 09:41:15 AM: 	Best result seen so far for macro_avg: 0.846
09/16 09:41:15 AM: 	# validation passes without improvement: 1
09/16 09:41:15 AM: edges-srl-ontonotes_loss: training: 0.017202 validation: 0.013038
09/16 09:41:15 AM: macro_avg: validation: 0.844008
09/16 09:41:15 AM: micro_avg: validation: 0.000000
09/16 09:41:15 AM: edges-srl-ontonotes_mcc: training: 0.781926 validation: 0.842636
09/16 09:41:15 AM: edges-srl-ontonotes_acc: training: 0.702412 validation: 0.791933
09/16 09:41:15 AM: edges-srl-ontonotes_precision: training: 0.840318 validation: 0.884641
09/16 09:41:15 AM: edges-srl-ontonotes_recall: training: 0.733297 validation: 0.806943
09/16 09:41:15 AM: edges-srl-ontonotes_f1: training: 0.783169 validation: 0.844008
09/16 09:41:15 AM: Global learning rate: 0.0001
09/16 09:41:15 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:41:17 AM: Update 17029: task edges-srl-ontonotes, batch 29 (17029): mcc: 0.8020, acc: 0.7292, precision: 0.8566, recall: 0.7561, f1: 0.8032, edges-srl-ontonotes_loss: 0.0158
09/16 09:41:27 AM: Update 17158: task edges-srl-ontonotes, batch 158 (17158): mcc: 0.8083, acc: 0.7371, precision: 0.8592, recall: 0.7656, f1: 0.8097, edges-srl-ontonotes_loss: 0.0156
09/16 09:41:37 AM: Update 17286: task edges-srl-ontonotes, batch 286 (17286): mcc: 0.8061, acc: 0.7350, precision: 0.8571, recall: 0.7632, f1: 0.8075, edges-srl-ontonotes_loss: 0.0157
09/16 09:41:47 AM: Update 17411: task edges-srl-ontonotes, batch 411 (17411): mcc: 0.8067, acc: 0.7357, precision: 0.8575, recall: 0.7641, f1: 0.8081, edges-srl-ontonotes_loss: 0.0156
09/16 09:41:57 AM: Update 17545: task edges-srl-ontonotes, batch 545 (17545): mcc: 0.8087, acc: 0.7383, precision: 0.8598, recall: 0.7658, f1: 0.8100, edges-srl-ontonotes_loss: 0.0155
09/16 09:42:08 AM: Update 17635: task edges-srl-ontonotes, batch 635 (17635): mcc: 0.8083, acc: 0.7375, precision: 0.8601, recall: 0.7648, f1: 0.8096, edges-srl-ontonotes_loss: 0.0155
09/16 09:42:18 AM: Update 17767: task edges-srl-ontonotes, batch 767 (17767): mcc: 0.8069, acc: 0.7360, precision: 0.8590, recall: 0.7631, f1: 0.8082, edges-srl-ontonotes_loss: 0.0156
09/16 09:42:28 AM: Update 17890: task edges-srl-ontonotes, batch 890 (17890): mcc: 0.8052, acc: 0.7338, precision: 0.8579, recall: 0.7609, f1: 0.8065, edges-srl-ontonotes_loss: 0.0158
09/16 09:42:36 AM: ***** Step 18000 / Validation 18 *****
09/16 09:42:36 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:42:36 AM: Validating...
09/16 09:42:38 AM: Evaluate: task edges-srl-ontonotes, batch 17 (157): mcc: 0.8315, acc: 0.7759, precision: 0.8775, recall: 0.7924, f1: 0.8328, edges-srl-ontonotes_loss: 0.0133
09/16 09:42:48 AM: Evaluate: task edges-srl-ontonotes, batch 154 (157): mcc: 0.8396, acc: 0.7854, precision: 0.8854, recall: 0.8005, f1: 0.8408, edges-srl-ontonotes_loss: 0.0132
09/16 09:42:48 AM: Updating LR scheduler:
09/16 09:42:48 AM: 	Best result seen so far for macro_avg: 0.846
09/16 09:42:48 AM: 	# validation passes without improvement: 2
09/16 09:42:48 AM: edges-srl-ontonotes_loss: training: 0.015852 validation: 0.013230
09/16 09:42:48 AM: macro_avg: validation: 0.840314
09/16 09:42:48 AM: micro_avg: validation: 0.000000
09/16 09:42:48 AM: edges-srl-ontonotes_mcc: training: 0.803611 validation: 0.839079
09/16 09:42:48 AM: edges-srl-ontonotes_acc: training: 0.731739 validation: 0.784851
09/16 09:42:48 AM: edges-srl-ontonotes_precision: training: 0.856872 validation: 0.884887
09/16 09:42:48 AM: edges-srl-ontonotes_recall: training: 0.758882 validation: 0.800015
09/16 09:42:48 AM: edges-srl-ontonotes_f1: training: 0.804906 validation: 0.840314
09/16 09:42:48 AM: Global learning rate: 0.0001
09/16 09:42:48 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:42:58 AM: Update 18134: task edges-srl-ontonotes, batch 134 (18134): mcc: 0.8006, acc: 0.7246, precision: 0.8570, recall: 0.7532, f1: 0.8017, edges-srl-ontonotes_loss: 0.0161
09/16 09:43:08 AM: Update 18249: task edges-srl-ontonotes, batch 249 (18249): mcc: 0.8002, acc: 0.7248, precision: 0.8563, recall: 0.7531, f1: 0.8014, edges-srl-ontonotes_loss: 0.0161
09/16 09:43:18 AM: Update 18389: task edges-srl-ontonotes, batch 389 (18389): mcc: 0.7971, acc: 0.7216, precision: 0.8526, recall: 0.7506, f1: 0.7983, edges-srl-ontonotes_loss: 0.0163
09/16 09:43:28 AM: Update 18509: task edges-srl-ontonotes, batch 509 (18509): mcc: 0.7965, acc: 0.7208, precision: 0.8524, recall: 0.7496, f1: 0.7977, edges-srl-ontonotes_loss: 0.0163
09/16 09:43:38 AM: Update 18592: task edges-srl-ontonotes, batch 592 (18592): mcc: 0.7969, acc: 0.7214, precision: 0.8530, recall: 0.7499, f1: 0.7981, edges-srl-ontonotes_loss: 0.0163
09/16 09:43:48 AM: Update 18721: task edges-srl-ontonotes, batch 721 (18721): mcc: 0.7986, acc: 0.7246, precision: 0.8536, recall: 0.7525, f1: 0.7999, edges-srl-ontonotes_loss: 0.0161
09/16 09:43:58 AM: Update 18852: task edges-srl-ontonotes, batch 852 (18852): mcc: 0.7993, acc: 0.7257, precision: 0.8538, recall: 0.7537, f1: 0.8006, edges-srl-ontonotes_loss: 0.0161
09/16 09:44:08 AM: Update 18961: task edges-srl-ontonotes, batch 961 (18961): mcc: 0.8007, acc: 0.7276, precision: 0.8548, recall: 0.7553, f1: 0.8020, edges-srl-ontonotes_loss: 0.0160
09/16 09:44:12 AM: ***** Step 19000 / Validation 19 *****
09/16 09:44:12 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:44:12 AM: Validating...
09/16 09:44:18 AM: Evaluate: task edges-srl-ontonotes, batch 89 (157): mcc: 0.8283, acc: 0.7701, precision: 0.8799, recall: 0.7844, f1: 0.8294, edges-srl-ontonotes_loss: 0.0137
09/16 09:44:23 AM: Updating LR scheduler:
09/16 09:44:23 AM: 	Best result seen so far for macro_avg: 0.846
09/16 09:44:23 AM: 	# validation passes without improvement: 3
09/16 09:44:23 AM: edges-srl-ontonotes_loss: training: 0.015995 validation: 0.013306
09/16 09:44:23 AM: macro_avg: validation: 0.839002
09/16 09:44:23 AM: micro_avg: validation: 0.000000
09/16 09:44:23 AM: edges-srl-ontonotes_mcc: training: 0.800957 validation: 0.837826
09/16 09:44:23 AM: edges-srl-ontonotes_acc: training: 0.728124 validation: 0.782619
09/16 09:44:23 AM: edges-srl-ontonotes_precision: training: 0.854869 validation: 0.885092
09/16 09:44:23 AM: edges-srl-ontonotes_recall: training: 0.755726 validation: 0.797475
09/16 09:44:23 AM: edges-srl-ontonotes_f1: training: 0.802246 validation: 0.839002
09/16 09:44:23 AM: Global learning rate: 0.0001
09/16 09:44:23 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:44:28 AM: Update 19069: task edges-srl-ontonotes, batch 69 (19069): mcc: 0.8163, acc: 0.7484, precision: 0.8650, recall: 0.7752, f1: 0.8176, edges-srl-ontonotes_loss: 0.0150
09/16 09:44:39 AM: Update 19188: task edges-srl-ontonotes, batch 188 (19188): mcc: 0.8087, acc: 0.7373, precision: 0.8616, recall: 0.7642, f1: 0.8100, edges-srl-ontonotes_loss: 0.0154
09/16 09:44:49 AM: Update 19302: task edges-srl-ontonotes, batch 302 (19302): mcc: 0.7955, acc: 0.7207, precision: 0.8525, recall: 0.7477, f1: 0.7967, edges-srl-ontonotes_loss: 0.0163
09/16 09:44:59 AM: Update 19421: task edges-srl-ontonotes, batch 421 (19421): mcc: 0.7920, acc: 0.7161, precision: 0.8502, recall: 0.7433, f1: 0.7932, edges-srl-ontonotes_loss: 0.0165
09/16 09:45:09 AM: Update 19529: task edges-srl-ontonotes, batch 529 (19529): mcc: 0.7929, acc: 0.7171, precision: 0.8517, recall: 0.7435, f1: 0.7939, edges-srl-ontonotes_loss: 0.0165
09/16 09:45:19 AM: Update 19677: task edges-srl-ontonotes, batch 677 (19677): mcc: 0.7994, acc: 0.7246, precision: 0.8563, recall: 0.7516, f1: 0.8005, edges-srl-ontonotes_loss: 0.0161
09/16 09:45:30 AM: Update 19814: task edges-srl-ontonotes, batch 814 (19814): mcc: 0.8027, acc: 0.7289, precision: 0.8582, recall: 0.7560, f1: 0.8039, edges-srl-ontonotes_loss: 0.0158
09/16 09:45:40 AM: Update 19986: task edges-srl-ontonotes, batch 986 (19986): mcc: 0.8112, acc: 0.7395, precision: 0.8638, recall: 0.7669, f1: 0.8124, edges-srl-ontonotes_loss: 0.0152
09/16 09:45:41 AM: ***** Step 20000 / Validation 20 *****
09/16 09:45:41 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:45:41 AM: Validating...
09/16 09:45:50 AM: Evaluate: task edges-srl-ontonotes, batch 128 (157): mcc: 0.8432, acc: 0.7909, precision: 0.8874, recall: 0.8056, f1: 0.8445, edges-srl-ontonotes_loss: 0.0129
09/16 09:45:52 AM: Updating LR scheduler:
09/16 09:45:52 AM: 	Best result seen so far for macro_avg: 0.846
09/16 09:45:52 AM: 	# validation passes without improvement: 0
09/16 09:45:52 AM: edges-srl-ontonotes_loss: training: 0.015191 validation: 0.013144
09/16 09:45:52 AM: macro_avg: validation: 0.840778
09/16 09:45:52 AM: micro_avg: validation: 0.000000
09/16 09:45:52 AM: edges-srl-ontonotes_mcc: training: 0.811939 validation: 0.839545
09/16 09:45:52 AM: edges-srl-ontonotes_acc: training: 0.740416 validation: 0.787083
09/16 09:45:52 AM: edges-srl-ontonotes_precision: training: 0.864329 validation: 0.885257
09/16 09:45:52 AM: edges-srl-ontonotes_recall: training: 0.767739 validation: 0.800554
09/16 09:45:52 AM: edges-srl-ontonotes_f1: training: 0.813176 validation: 0.840778
09/16 09:45:52 AM: Global learning rate: 5e-05
09/16 09:45:52 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:46:00 AM: Update 20128: task edges-srl-ontonotes, batch 128 (20128): mcc: 0.8526, acc: 0.7915, precision: 0.8915, recall: 0.8195, f1: 0.8540, edges-srl-ontonotes_loss: 0.0119
09/16 09:46:10 AM: Update 20290: task edges-srl-ontonotes, batch 290 (20290): mcc: 0.8533, acc: 0.7925, precision: 0.8935, recall: 0.8190, f1: 0.8546, edges-srl-ontonotes_loss: 0.0122
09/16 09:46:21 AM: Update 20440: task edges-srl-ontonotes, batch 440 (20440): mcc: 0.8548, acc: 0.7948, precision: 0.8947, recall: 0.8206, f1: 0.8560, edges-srl-ontonotes_loss: 0.0122
09/16 09:46:31 AM: Update 20618: task edges-srl-ontonotes, batch 618 (20618): mcc: 0.8549, acc: 0.7942, precision: 0.8943, recall: 0.8212, f1: 0.8562, edges-srl-ontonotes_loss: 0.0122
09/16 09:46:42 AM: Update 20753: task edges-srl-ontonotes, batch 753 (20753): mcc: 0.8551, acc: 0.7949, precision: 0.8945, recall: 0.8215, f1: 0.8564, edges-srl-ontonotes_loss: 0.0122
09/16 09:46:52 AM: Update 20922: task edges-srl-ontonotes, batch 922 (20922): mcc: 0.8531, acc: 0.7925, precision: 0.8925, recall: 0.8195, f1: 0.8545, edges-srl-ontonotes_loss: 0.0123
09/16 09:46:56 AM: ***** Step 21000 / Validation 21 *****
09/16 09:46:56 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:46:56 AM: Validating...
09/16 09:47:02 AM: Evaluate: task edges-srl-ontonotes, batch 78 (157): mcc: 0.8366, acc: 0.7820, precision: 0.8879, recall: 0.7926, f1: 0.8376, edges-srl-ontonotes_loss: 0.0132
09/16 09:47:08 AM: Updating LR scheduler:
09/16 09:47:08 AM: 	Best result seen so far for macro_avg: 0.846
09/16 09:47:08 AM: 	# validation passes without improvement: 1
09/16 09:47:08 AM: edges-srl-ontonotes_loss: training: 0.012244 validation: 0.012745
09/16 09:47:08 AM: macro_avg: validation: 0.845348
09/16 09:47:08 AM: micro_avg: validation: 0.000000
09/16 09:47:08 AM: edges-srl-ontonotes_mcc: training: 0.853976 validation: 0.844200
09/16 09:47:08 AM: edges-srl-ontonotes_acc: training: 0.793533 validation: 0.792780
09/16 09:47:08 AM: edges-srl-ontonotes_precision: training: 0.892859 validation: 0.890308
09/16 09:47:08 AM: edges-srl-ontonotes_recall: training: 0.820829 validation: 0.804711
09/16 09:47:08 AM: edges-srl-ontonotes_f1: training: 0.855330 validation: 0.845348
09/16 09:47:08 AM: Global learning rate: 5e-05
09/16 09:47:08 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:47:12 AM: Update 21066: task edges-srl-ontonotes, batch 66 (21066): mcc: 0.8575, acc: 0.7973, precision: 0.8924, recall: 0.8281, f1: 0.8590, edges-srl-ontonotes_loss: 0.0120
09/16 09:47:22 AM: Update 21201: task edges-srl-ontonotes, batch 201 (21201): mcc: 0.8331, acc: 0.7681, precision: 0.8745, recall: 0.7982, f1: 0.8346, edges-srl-ontonotes_loss: 0.0136
09/16 09:47:32 AM: Update 21323: task edges-srl-ontonotes, batch 323 (21323): mcc: 0.8273, acc: 0.7613, precision: 0.8701, recall: 0.7913, f1: 0.8288, edges-srl-ontonotes_loss: 0.0141
09/16 09:47:42 AM: Update 21432: task edges-srl-ontonotes, batch 432 (21432): mcc: 0.8226, acc: 0.7554, precision: 0.8673, recall: 0.7850, f1: 0.8241, edges-srl-ontonotes_loss: 0.0145
09/16 09:47:52 AM: Update 21562: task edges-srl-ontonotes, batch 562 (21562): mcc: 0.8175, acc: 0.7486, precision: 0.8641, recall: 0.7783, f1: 0.8190, edges-srl-ontonotes_loss: 0.0148
09/16 09:48:02 AM: Update 21687: task edges-srl-ontonotes, batch 687 (21687): mcc: 0.8140, acc: 0.7445, precision: 0.8617, recall: 0.7741, f1: 0.8155, edges-srl-ontonotes_loss: 0.0151
09/16 09:48:12 AM: Update 21781: task edges-srl-ontonotes, batch 781 (21781): mcc: 0.8133, acc: 0.7431, precision: 0.8616, recall: 0.7726, f1: 0.8147, edges-srl-ontonotes_loss: 0.0151
09/16 09:48:23 AM: Update 21931: task edges-srl-ontonotes, batch 931 (21931): mcc: 0.8156, acc: 0.7458, precision: 0.8637, recall: 0.7751, f1: 0.8170, edges-srl-ontonotes_loss: 0.0150
09/16 09:48:27 AM: ***** Step 22000 / Validation 22 *****
09/16 09:48:27 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:48:27 AM: Validating...
09/16 09:48:33 AM: Evaluate: task edges-srl-ontonotes, batch 65 (157): mcc: 0.8386, acc: 0.7900, precision: 0.8815, recall: 0.8022, f1: 0.8400, edges-srl-ontonotes_loss: 0.0130
09/16 09:48:40 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:48:40 AM: Best result seen so far for macro.
09/16 09:48:40 AM: Updating LR scheduler:
09/16 09:48:40 AM: 	Best result seen so far for macro_avg: 0.853
09/16 09:48:40 AM: 	# validation passes without improvement: 0
09/16 09:48:40 AM: edges-srl-ontonotes_loss: training: 0.014907 validation: 0.012264
09/16 09:48:40 AM: macro_avg: validation: 0.853267
09/16 09:48:40 AM: micro_avg: validation: 0.000000
09/16 09:48:40 AM: edges-srl-ontonotes_mcc: training: 0.816649 validation: 0.851911
09/16 09:48:40 AM: edges-srl-ontonotes_acc: training: 0.746952 validation: 0.805250
09/16 09:48:40 AM: edges-srl-ontonotes_precision: training: 0.864532 validation: 0.891405
09/16 09:48:40 AM: edges-srl-ontonotes_recall: training: 0.776367 validation: 0.818259
09/16 09:48:40 AM: edges-srl-ontonotes_f1: training: 0.818081 validation: 0.853267
09/16 09:48:40 AM: Global learning rate: 5e-05
09/16 09:48:40 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:48:43 AM: Update 22033: task edges-srl-ontonotes, batch 33 (22033): mcc: 0.8212, acc: 0.7489, precision: 0.8694, recall: 0.7805, f1: 0.8226, edges-srl-ontonotes_loss: 0.0147
09/16 09:48:53 AM: Update 22153: task edges-srl-ontonotes, batch 153 (22153): mcc: 0.8257, acc: 0.7589, precision: 0.8728, recall: 0.7859, f1: 0.8271, edges-srl-ontonotes_loss: 0.0142
09/16 09:49:03 AM: Update 22291: task edges-srl-ontonotes, batch 291 (22291): mcc: 0.8288, acc: 0.7606, precision: 0.8749, recall: 0.7897, f1: 0.8302, edges-srl-ontonotes_loss: 0.0140
09/16 09:49:13 AM: Update 22422: task edges-srl-ontonotes, batch 422 (22422): mcc: 0.8261, acc: 0.7580, precision: 0.8718, recall: 0.7876, f1: 0.8276, edges-srl-ontonotes_loss: 0.0143
09/16 09:49:23 AM: Update 22559: task edges-srl-ontonotes, batch 559 (22559): mcc: 0.8229, acc: 0.7549, precision: 0.8695, recall: 0.7835, f1: 0.8243, edges-srl-ontonotes_loss: 0.0145
09/16 09:49:35 AM: Update 22678: task edges-srl-ontonotes, batch 678 (22678): mcc: 0.8218, acc: 0.7540, precision: 0.8682, recall: 0.7826, f1: 0.8232, edges-srl-ontonotes_loss: 0.0145
09/16 09:49:45 AM: Update 22810: task edges-srl-ontonotes, batch 810 (22810): mcc: 0.8181, acc: 0.7495, precision: 0.8655, recall: 0.7782, f1: 0.8195, edges-srl-ontonotes_loss: 0.0148
09/16 09:49:55 AM: Update 22955: task edges-srl-ontonotes, batch 955 (22955): mcc: 0.8152, acc: 0.7460, precision: 0.8638, recall: 0.7744, f1: 0.8166, edges-srl-ontonotes_loss: 0.0150
09/16 09:49:59 AM: ***** Step 23000 / Validation 23 *****
09/16 09:49:59 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:49:59 AM: Validating...
09/16 09:50:05 AM: Evaluate: task edges-srl-ontonotes, batch 78 (157): mcc: 0.8442, acc: 0.7939, precision: 0.8897, recall: 0.8053, f1: 0.8454, edges-srl-ontonotes_loss: 0.0124
09/16 09:50:11 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:50:11 AM: Best result seen so far for macro.
09/16 09:50:11 AM: Updating LR scheduler:
09/16 09:50:11 AM: 	Best result seen so far for macro_avg: 0.855
09/16 09:50:11 AM: 	# validation passes without improvement: 0
09/16 09:50:11 AM: edges-srl-ontonotes_loss: training: 0.015063 validation: 0.012011
09/16 09:50:11 AM: macro_avg: validation: 0.854649
09/16 09:50:11 AM: micro_avg: validation: 0.000000
09/16 09:50:11 AM: edges-srl-ontonotes_mcc: training: 0.814308 validation: 0.853415
09/16 09:50:11 AM: edges-srl-ontonotes_acc: training: 0.744867 validation: 0.805635
09/16 09:50:11 AM: edges-srl-ontonotes_precision: training: 0.863187 validation: 0.895163
09/16 09:50:11 AM: edges-srl-ontonotes_recall: training: 0.773194 validation: 0.817643
09/16 09:50:11 AM: edges-srl-ontonotes_f1: training: 0.815716 validation: 0.854649
09/16 09:50:11 AM: Global learning rate: 5e-05
09/16 09:50:11 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:50:15 AM: Update 23059: task edges-srl-ontonotes, batch 59 (23059): mcc: 0.8057, acc: 0.7323, precision: 0.8566, recall: 0.7630, f1: 0.8071, edges-srl-ontonotes_loss: 0.0153
09/16 09:50:25 AM: Update 23203: task edges-srl-ontonotes, batch 203 (23203): mcc: 0.8019, acc: 0.7313, precision: 0.8539, recall: 0.7584, f1: 0.8033, edges-srl-ontonotes_loss: 0.0156
09/16 09:50:35 AM: Update 23314: task edges-srl-ontonotes, batch 314 (23314): mcc: 0.7996, acc: 0.7292, precision: 0.8513, recall: 0.7565, f1: 0.8011, edges-srl-ontonotes_loss: 0.0157
09/16 09:50:45 AM: Update 23446: task edges-srl-ontonotes, batch 446 (23446): mcc: 0.7929, acc: 0.7212, precision: 0.8458, recall: 0.7488, f1: 0.7944, edges-srl-ontonotes_loss: 0.0162
09/16 09:50:55 AM: Update 23577: task edges-srl-ontonotes, batch 577 (23577): mcc: 0.7909, acc: 0.7175, precision: 0.8450, recall: 0.7458, f1: 0.7923, edges-srl-ontonotes_loss: 0.0164
09/16 09:51:05 AM: Update 23687: task edges-srl-ontonotes, batch 687 (23687): mcc: 0.7906, acc: 0.7169, precision: 0.8452, recall: 0.7451, f1: 0.7920, edges-srl-ontonotes_loss: 0.0164
09/16 09:51:15 AM: Update 23809: task edges-srl-ontonotes, batch 809 (23809): mcc: 0.7891, acc: 0.7151, precision: 0.8443, recall: 0.7431, f1: 0.7905, edges-srl-ontonotes_loss: 0.0165
09/16 09:51:27 AM: Update 23930: task edges-srl-ontonotes, batch 930 (23930): mcc: 0.7886, acc: 0.7142, precision: 0.8439, recall: 0.7425, f1: 0.7900, edges-srl-ontonotes_loss: 0.0166
09/16 09:51:32 AM: ***** Step 24000 / Validation 24 *****
09/16 09:51:32 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:51:32 AM: Validating...
09/16 09:51:37 AM: Evaluate: task edges-srl-ontonotes, batch 65 (157): mcc: 0.8383, acc: 0.7883, precision: 0.8814, recall: 0.8017, f1: 0.8397, edges-srl-ontonotes_loss: 0.0131
09/16 09:51:44 AM: Updating LR scheduler:
09/16 09:51:44 AM: 	Best result seen so far for macro_avg: 0.855
09/16 09:51:44 AM: 	# validation passes without improvement: 1
09/16 09:51:44 AM: edges-srl-ontonotes_loss: training: 0.016426 validation: 0.012140
09/16 09:51:44 AM: macro_avg: validation: 0.853362
09/16 09:51:44 AM: micro_avg: validation: 0.000000
09/16 09:51:44 AM: edges-srl-ontonotes_mcc: training: 0.790126 validation: 0.851970
09/16 09:51:44 AM: edges-srl-ontonotes_acc: training: 0.715858 validation: 0.805481
09/16 09:51:44 AM: edges-srl-ontonotes_precision: training: 0.845019 validation: 0.890609
09/16 09:51:44 AM: edges-srl-ontonotes_recall: training: 0.744347 validation: 0.819106
09/16 09:51:44 AM: edges-srl-ontonotes_f1: training: 0.791495 validation: 0.853362
09/16 09:51:44 AM: Global learning rate: 5e-05
09/16 09:51:44 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:51:47 AM: Update 24041: task edges-srl-ontonotes, batch 41 (24041): mcc: 0.8196, acc: 0.7501, precision: 0.8696, recall: 0.7773, f1: 0.8209, edges-srl-ontonotes_loss: 0.0148
09/16 09:51:57 AM: Update 24166: task edges-srl-ontonotes, batch 166 (24166): mcc: 0.8105, acc: 0.7406, precision: 0.8613, recall: 0.7679, f1: 0.8119, edges-srl-ontonotes_loss: 0.0153
09/16 09:52:07 AM: Update 24278: task edges-srl-ontonotes, batch 278 (24278): mcc: 0.8104, acc: 0.7401, precision: 0.8611, recall: 0.7677, f1: 0.8117, edges-srl-ontonotes_loss: 0.0152
09/16 09:52:17 AM: Update 24416: task edges-srl-ontonotes, batch 416 (24416): mcc: 0.8133, acc: 0.7437, precision: 0.8635, recall: 0.7710, f1: 0.8146, edges-srl-ontonotes_loss: 0.0150
09/16 09:52:27 AM: Update 24546: task edges-srl-ontonotes, batch 546 (24546): mcc: 0.8128, acc: 0.7435, precision: 0.8634, recall: 0.7703, f1: 0.8142, edges-srl-ontonotes_loss: 0.0150
09/16 09:52:37 AM: Update 24665: task edges-srl-ontonotes, batch 665 (24665): mcc: 0.8131, acc: 0.7439, precision: 0.8635, recall: 0.7705, f1: 0.8144, edges-srl-ontonotes_loss: 0.0150
09/16 09:52:47 AM: Update 24786: task edges-srl-ontonotes, batch 786 (24786): mcc: 0.8134, acc: 0.7449, precision: 0.8634, recall: 0.7713, f1: 0.8148, edges-srl-ontonotes_loss: 0.0150
09/16 09:52:57 AM: Update 24879: task edges-srl-ontonotes, batch 879 (24879): mcc: 0.8152, acc: 0.7472, precision: 0.8648, recall: 0.7733, f1: 0.8165, edges-srl-ontonotes_loss: 0.0149
09/16 09:53:07 AM: ***** Step 25000 / Validation 25 *****
09/16 09:53:07 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:53:07 AM: Validating...
09/16 09:53:07 AM: Evaluate: task edges-srl-ontonotes, batch 4 (157): mcc: 0.8805, acc: 0.8400, precision: 0.9141, recall: 0.8514, f1: 0.8817, edges-srl-ontonotes_loss: 0.0103
09/16 09:53:17 AM: Evaluate: task edges-srl-ontonotes, batch 141 (157): mcc: 0.8527, acc: 0.8075, precision: 0.8910, recall: 0.8202, f1: 0.8541, edges-srl-ontonotes_loss: 0.0120
09/16 09:53:19 AM: Updating LR scheduler:
09/16 09:53:19 AM: 	Best result seen so far for macro_avg: 0.855
09/16 09:53:19 AM: 	# validation passes without improvement: 2
09/16 09:53:19 AM: edges-srl-ontonotes_loss: training: 0.015040 validation: 0.012240
09/16 09:53:19 AM: macro_avg: validation: 0.852445
09/16 09:53:19 AM: micro_avg: validation: 0.000000
09/16 09:53:19 AM: edges-srl-ontonotes_mcc: training: 0.813612 validation: 0.851047
09/16 09:53:19 AM: edges-srl-ontonotes_acc: training: 0.745276 validation: 0.805173
09/16 09:53:19 AM: edges-srl-ontonotes_precision: training: 0.863595 validation: 0.889884
09/16 09:53:19 AM: edges-srl-ontonotes_recall: training: 0.771524 validation: 0.818028
09/16 09:53:19 AM: edges-srl-ontonotes_f1: training: 0.814967 validation: 0.852445
09/16 09:53:19 AM: Global learning rate: 5e-05
09/16 09:53:19 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:53:27 AM: Update 25125: task edges-srl-ontonotes, batch 125 (25125): mcc: 0.8028, acc: 0.7332, precision: 0.8560, recall: 0.7582, f1: 0.8041, edges-srl-ontonotes_loss: 0.0158
09/16 09:53:37 AM: Update 25251: task edges-srl-ontonotes, batch 251 (25251): mcc: 0.8047, acc: 0.7342, precision: 0.8577, recall: 0.7601, f1: 0.8060, edges-srl-ontonotes_loss: 0.0157
09/16 09:53:47 AM: Update 25388: task edges-srl-ontonotes, batch 388 (25388): mcc: 0.8053, acc: 0.7351, precision: 0.8591, recall: 0.7601, f1: 0.8066, edges-srl-ontonotes_loss: 0.0156
09/16 09:53:57 AM: Update 25502: task edges-srl-ontonotes, batch 502 (25502): mcc: 0.8052, acc: 0.7345, precision: 0.8591, recall: 0.7599, f1: 0.8065, edges-srl-ontonotes_loss: 0.0157
09/16 09:54:08 AM: Update 25641: task edges-srl-ontonotes, batch 641 (25641): mcc: 0.8042, acc: 0.7331, precision: 0.8583, recall: 0.7587, f1: 0.8055, edges-srl-ontonotes_loss: 0.0157
09/16 09:54:18 AM: Update 25768: task edges-srl-ontonotes, batch 768 (25768): mcc: 0.8038, acc: 0.7324, precision: 0.8579, recall: 0.7583, f1: 0.8051, edges-srl-ontonotes_loss: 0.0157
09/16 09:54:28 AM: Update 25863: task edges-srl-ontonotes, batch 863 (25863): mcc: 0.8038, acc: 0.7328, precision: 0.8580, recall: 0.7583, f1: 0.8051, edges-srl-ontonotes_loss: 0.0157
09/16 09:54:38 AM: Update 25998: task edges-srl-ontonotes, batch 998 (25998): mcc: 0.8052, acc: 0.7346, precision: 0.8587, recall: 0.7601, f1: 0.8064, edges-srl-ontonotes_loss: 0.0156
09/16 09:54:38 AM: ***** Step 26000 / Validation 26 *****
09/16 09:54:38 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:54:38 AM: Validating...
09/16 09:54:48 AM: Evaluate: task edges-srl-ontonotes, batch 135 (157): mcc: 0.8488, acc: 0.8016, precision: 0.8887, recall: 0.8149, f1: 0.8502, edges-srl-ontonotes_loss: 0.0123
09/16 09:54:49 AM: Updating LR scheduler:
09/16 09:54:49 AM: 	Best result seen so far for macro_avg: 0.855
09/16 09:54:49 AM: 	# validation passes without improvement: 3
09/16 09:54:49 AM: edges-srl-ontonotes_loss: training: 0.015578 validation: 0.012490
09/16 09:54:49 AM: macro_avg: validation: 0.848402
09/16 09:54:49 AM: micro_avg: validation: 0.000000
09/16 09:54:49 AM: edges-srl-ontonotes_mcc: training: 0.805242 validation: 0.847039
09/16 09:54:49 AM: edges-srl-ontonotes_acc: training: 0.734638 validation: 0.799015
09/16 09:54:49 AM: edges-srl-ontonotes_precision: training: 0.858802 validation: 0.887917
09/16 09:54:49 AM: edges-srl-ontonotes_recall: training: 0.760198 validation: 0.812255
09/16 09:54:49 AM: edges-srl-ontonotes_f1: training: 0.806497 validation: 0.848402
09/16 09:54:49 AM: Global learning rate: 5e-05
09/16 09:54:49 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:54:58 AM: Update 26112: task edges-srl-ontonotes, batch 112 (26112): mcc: 0.8120, acc: 0.7436, precision: 0.8628, recall: 0.7693, f1: 0.8133, edges-srl-ontonotes_loss: 0.0151
09/16 09:55:08 AM: Update 26236: task edges-srl-ontonotes, batch 236 (26236): mcc: 0.8138, acc: 0.7460, precision: 0.8635, recall: 0.7719, f1: 0.8151, edges-srl-ontonotes_loss: 0.0150
09/16 09:55:18 AM: Update 26367: task edges-srl-ontonotes, batch 367 (26367): mcc: 0.8161, acc: 0.7486, precision: 0.8659, recall: 0.7742, f1: 0.8175, edges-srl-ontonotes_loss: 0.0148
09/16 09:55:28 AM: Update 26475: task edges-srl-ontonotes, batch 475 (26475): mcc: 0.8126, acc: 0.7443, precision: 0.8636, recall: 0.7696, f1: 0.8139, edges-srl-ontonotes_loss: 0.0151
09/16 09:55:38 AM: Update 26588: task edges-srl-ontonotes, batch 588 (26588): mcc: 0.8081, acc: 0.7384, precision: 0.8610, recall: 0.7636, f1: 0.8094, edges-srl-ontonotes_loss: 0.0154
09/16 09:55:48 AM: Update 26708: task edges-srl-ontonotes, batch 708 (26708): mcc: 0.8060, acc: 0.7355, precision: 0.8596, recall: 0.7610, f1: 0.8073, edges-srl-ontonotes_loss: 0.0156
09/16 09:55:58 AM: Update 26828: task edges-srl-ontonotes, batch 828 (26828): mcc: 0.8065, acc: 0.7359, precision: 0.8600, recall: 0.7616, f1: 0.8078, edges-srl-ontonotes_loss: 0.0155
09/16 09:56:08 AM: Update 26979: task edges-srl-ontonotes, batch 979 (26979): mcc: 0.8101, acc: 0.7401, precision: 0.8620, recall: 0.7663, f1: 0.8113, edges-srl-ontonotes_loss: 0.0152
09/16 09:56:10 AM: ***** Step 27000 / Validation 27 *****
09/16 09:56:10 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:56:10 AM: Validating...
09/16 09:56:18 AM: Evaluate: task edges-srl-ontonotes, batch 115 (157): mcc: 0.8470, acc: 0.7972, precision: 0.8905, recall: 0.8098, f1: 0.8483, edges-srl-ontonotes_loss: 0.0125
09/16 09:56:21 AM: Updating LR scheduler:
09/16 09:56:21 AM: 	Best result seen so far for macro_avg: 0.855
09/16 09:56:21 AM: 	# validation passes without improvement: 0
09/16 09:56:21 AM: edges-srl-ontonotes_loss: training: 0.015175 validation: 0.012455
09/16 09:56:21 AM: macro_avg: validation: 0.850608
09/16 09:56:21 AM: micro_avg: validation: 0.000000
09/16 09:56:21 AM: edges-srl-ontonotes_mcc: training: 0.810661 validation: 0.849352
09/16 09:56:21 AM: edges-srl-ontonotes_acc: training: 0.740884 validation: 0.800246
09/16 09:56:21 AM: edges-srl-ontonotes_precision: training: 0.862383 validation: 0.891835
09/16 09:56:21 AM: edges-srl-ontonotes_recall: training: 0.767099 validation: 0.813024
09/16 09:56:21 AM: edges-srl-ontonotes_f1: training: 0.811955 validation: 0.850608
09/16 09:56:21 AM: Global learning rate: 2.5e-05
09/16 09:56:21 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:56:28 AM: Update 27060: task edges-srl-ontonotes, batch 60 (27060): mcc: 0.8249, acc: 0.7600, precision: 0.8716, recall: 0.7855, f1: 0.8263, edges-srl-ontonotes_loss: 0.0138
09/16 09:56:38 AM: Update 27217: task edges-srl-ontonotes, batch 217 (27217): mcc: 0.8458, acc: 0.7852, precision: 0.8866, recall: 0.8111, f1: 0.8472, edges-srl-ontonotes_loss: 0.0126
09/16 09:56:49 AM: Update 27373: task edges-srl-ontonotes, batch 373 (27373): mcc: 0.8515, acc: 0.7924, precision: 0.8906, recall: 0.8181, f1: 0.8528, edges-srl-ontonotes_loss: 0.0122
09/16 09:56:59 AM: Update 27535: task edges-srl-ontonotes, batch 535 (27535): mcc: 0.8518, acc: 0.7917, precision: 0.8916, recall: 0.8178, f1: 0.8531, edges-srl-ontonotes_loss: 0.0123
09/16 09:57:09 AM: Update 27686: task edges-srl-ontonotes, batch 686 (27686): mcc: 0.8533, acc: 0.7935, precision: 0.8927, recall: 0.8197, f1: 0.8546, edges-srl-ontonotes_loss: 0.0122
09/16 09:57:19 AM: Update 27855: task edges-srl-ontonotes, batch 855 (27855): mcc: 0.8541, acc: 0.7945, precision: 0.8932, recall: 0.8208, f1: 0.8554, edges-srl-ontonotes_loss: 0.0122
09/16 09:57:32 AM: Update 27999: task edges-srl-ontonotes, batch 999 (27999): mcc: 0.8542, acc: 0.7948, precision: 0.8929, recall: 0.8212, f1: 0.8556, edges-srl-ontonotes_loss: 0.0122
09/16 09:57:32 AM: ***** Step 28000 / Validation 28 *****
09/16 09:57:32 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:57:32 AM: Validating...
09/16 09:57:42 AM: Evaluate: task edges-srl-ontonotes, batch 128 (157): mcc: 0.8542, acc: 0.8057, precision: 0.8953, recall: 0.8190, f1: 0.8555, edges-srl-ontonotes_loss: 0.0120
09/16 09:57:44 AM: Updating LR scheduler:
09/16 09:57:44 AM: 	Best result seen so far for macro_avg: 0.855
09/16 09:57:44 AM: 	# validation passes without improvement: 1
09/16 09:57:44 AM: edges-srl-ontonotes_loss: training: 0.012185 validation: 0.012243
09/16 09:57:44 AM: macro_avg: validation: 0.852058
09/16 09:57:44 AM: micro_avg: validation: 0.000000
09/16 09:57:44 AM: edges-srl-ontonotes_mcc: training: 0.854162 validation: 0.850825
09/16 09:57:44 AM: edges-srl-ontonotes_acc: training: 0.794716 validation: 0.801863
09/16 09:57:44 AM: edges-srl-ontonotes_precision: training: 0.892872 validation: 0.893355
09/16 09:57:44 AM: edges-srl-ontonotes_recall: training: 0.821169 validation: 0.814410
09/16 09:57:44 AM: edges-srl-ontonotes_f1: training: 0.855521 validation: 0.852058
09/16 09:57:44 AM: Global learning rate: 2.5e-05
09/16 09:57:44 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:57:52 AM: Update 28127: task edges-srl-ontonotes, batch 127 (28127): mcc: 0.8509, acc: 0.7913, precision: 0.8908, recall: 0.8169, f1: 0.8523, edges-srl-ontonotes_loss: 0.0127
09/16 09:58:02 AM: Update 28302: task edges-srl-ontonotes, batch 302 (28302): mcc: 0.8544, acc: 0.7955, precision: 0.8925, recall: 0.8220, f1: 0.8558, edges-srl-ontonotes_loss: 0.0123
09/16 09:58:12 AM: Update 28420: task edges-srl-ontonotes, batch 420 (28420): mcc: 0.8458, acc: 0.7848, precision: 0.8864, recall: 0.8112, f1: 0.8471, edges-srl-ontonotes_loss: 0.0129
09/16 09:58:22 AM: Update 28563: task edges-srl-ontonotes, batch 563 (28563): mcc: 0.8401, acc: 0.7775, precision: 0.8822, recall: 0.8043, f1: 0.8415, edges-srl-ontonotes_loss: 0.0133
09/16 09:58:32 AM: Update 28680: task edges-srl-ontonotes, batch 680 (28680): mcc: 0.8359, acc: 0.7724, precision: 0.8787, recall: 0.7998, f1: 0.8374, edges-srl-ontonotes_loss: 0.0135
09/16 09:58:42 AM: Update 28807: task edges-srl-ontonotes, batch 807 (28807): mcc: 0.8303, acc: 0.7654, precision: 0.8743, recall: 0.7932, f1: 0.8318, edges-srl-ontonotes_loss: 0.0139
09/16 09:58:52 AM: Update 28938: task edges-srl-ontonotes, batch 938 (28938): mcc: 0.8274, acc: 0.7620, precision: 0.8723, recall: 0.7894, f1: 0.8288, edges-srl-ontonotes_loss: 0.0141
09/16 09:58:59 AM: ***** Step 29000 / Validation 29 *****
09/16 09:58:59 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:58:59 AM: Validating...
09/16 09:59:02 AM: Evaluate: task edges-srl-ontonotes, batch 44 (157): mcc: 0.8384, acc: 0.7878, precision: 0.8847, recall: 0.7989, f1: 0.8396, edges-srl-ontonotes_loss: 0.0133
09/16 09:59:10 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:59:10 AM: Best result seen so far for macro.
09/16 09:59:10 AM: Updating LR scheduler:
09/16 09:59:10 AM: 	Best result seen so far for macro_avg: 0.856
09/16 09:59:10 AM: 	# validation passes without improvement: 0
09/16 09:59:10 AM: edges-srl-ontonotes_loss: training: 0.014155 validation: 0.012093
09/16 09:59:10 AM: macro_avg: validation: 0.855848
09/16 09:59:10 AM: micro_avg: validation: 0.000000
09/16 09:59:10 AM: edges-srl-ontonotes_mcc: training: 0.826570 validation: 0.854506
09/16 09:59:10 AM: edges-srl-ontonotes_acc: training: 0.761039 validation: 0.808406
09/16 09:59:10 AM: edges-srl-ontonotes_precision: training: 0.872163 validation: 0.893476
09/16 09:59:10 AM: edges-srl-ontonotes_recall: training: 0.788072 validation: 0.821261
09/16 09:59:10 AM: edges-srl-ontonotes_f1: training: 0.827988 validation: 0.855848
09/16 09:59:10 AM: Global learning rate: 2.5e-05
09/16 09:59:10 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 09:59:12 AM: Update 29028: task edges-srl-ontonotes, batch 28 (29028): mcc: 0.8157, acc: 0.7469, precision: 0.8679, recall: 0.7716, f1: 0.8169, edges-srl-ontonotes_loss: 0.0148
09/16 09:59:22 AM: Update 29180: task edges-srl-ontonotes, batch 180 (29180): mcc: 0.8263, acc: 0.7587, precision: 0.8737, recall: 0.7861, f1: 0.8276, edges-srl-ontonotes_loss: 0.0141
09/16 09:59:32 AM: Update 29310: task edges-srl-ontonotes, batch 310 (29310): mcc: 0.8291, acc: 0.7627, precision: 0.8751, recall: 0.7901, f1: 0.8305, edges-srl-ontonotes_loss: 0.0140
09/16 09:59:42 AM: Update 29430: task edges-srl-ontonotes, batch 430 (29430): mcc: 0.8317, acc: 0.7662, precision: 0.8771, recall: 0.7932, f1: 0.8331, edges-srl-ontonotes_loss: 0.0138
09/16 09:59:52 AM: Update 29567: task edges-srl-ontonotes, batch 567 (29567): mcc: 0.8311, acc: 0.7657, precision: 0.8760, recall: 0.7932, f1: 0.8325, edges-srl-ontonotes_loss: 0.0138
09/16 10:00:02 AM: Update 29692: task edges-srl-ontonotes, batch 692 (29692): mcc: 0.8279, acc: 0.7621, precision: 0.8734, recall: 0.7894, f1: 0.8293, edges-srl-ontonotes_loss: 0.0141
09/16 10:00:12 AM: Update 29832: task edges-srl-ontonotes, batch 832 (29832): mcc: 0.8269, acc: 0.7611, precision: 0.8722, recall: 0.7886, f1: 0.8283, edges-srl-ontonotes_loss: 0.0141
09/16 10:00:22 AM: Update 29967: task edges-srl-ontonotes, batch 967 (29967): mcc: 0.8256, acc: 0.7596, precision: 0.8710, recall: 0.7873, f1: 0.8270, edges-srl-ontonotes_loss: 0.0142
09/16 10:00:25 AM: ***** Step 30000 / Validation 30 *****
09/16 10:00:25 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:00:25 AM: Validating...
09/16 10:00:32 AM: Evaluate: task edges-srl-ontonotes, batch 100 (157): mcc: 0.8565, acc: 0.8115, precision: 0.8937, recall: 0.8249, f1: 0.8579, edges-srl-ontonotes_loss: 0.0117
09/16 10:00:36 AM: Best result seen so far for edges-srl-ontonotes.
09/16 10:00:36 AM: Best result seen so far for macro.
09/16 10:00:36 AM: Updating LR scheduler:
09/16 10:00:36 AM: 	Best result seen so far for macro_avg: 0.860
09/16 10:00:36 AM: 	# validation passes without improvement: 0
09/16 10:00:36 AM: edges-srl-ontonotes_loss: training: 0.014261 validation: 0.011769
09/16 10:00:36 AM: macro_avg: validation: 0.860395
09/16 10:00:36 AM: micro_avg: validation: 0.000000
09/16 10:00:36 AM: edges-srl-ontonotes_mcc: training: 0.824766 validation: 0.858952
09/16 10:00:36 AM: edges-srl-ontonotes_acc: training: 0.758643 validation: 0.815026
09/16 10:00:36 AM: edges-srl-ontonotes_precision: training: 0.870300 validation: 0.893951
09/16 10:00:36 AM: edges-srl-ontonotes_recall: training: 0.786375 validation: 0.829266
09/16 10:00:36 AM: edges-srl-ontonotes_f1: training: 0.826212 validation: 0.860395
09/16 10:00:36 AM: Global learning rate: 2.5e-05
09/16 10:00:36 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:00:42 AM: Update 30087: task edges-srl-ontonotes, batch 87 (30087): mcc: 0.8061, acc: 0.7358, precision: 0.8578, recall: 0.7626, f1: 0.8074, edges-srl-ontonotes_loss: 0.0157
09/16 10:00:52 AM: Update 30224: task edges-srl-ontonotes, batch 224 (30224): mcc: 0.8014, acc: 0.7304, precision: 0.8532, recall: 0.7580, f1: 0.8028, edges-srl-ontonotes_loss: 0.0159
09/16 10:01:02 AM: Update 30317: task edges-srl-ontonotes, batch 317 (30317): mcc: 0.8002, acc: 0.7294, precision: 0.8525, recall: 0.7564, f1: 0.8016, edges-srl-ontonotes_loss: 0.0159
09/16 10:01:12 AM: Update 30450: task edges-srl-ontonotes, batch 450 (30450): mcc: 0.8014, acc: 0.7309, precision: 0.8528, recall: 0.7584, f1: 0.8029, edges-srl-ontonotes_loss: 0.0157
09/16 10:01:22 AM: Update 30579: task edges-srl-ontonotes, batch 579 (30579): mcc: 0.8014, acc: 0.7309, precision: 0.8527, recall: 0.7585, f1: 0.8029, edges-srl-ontonotes_loss: 0.0157
09/16 10:01:32 AM: Update 30709: task edges-srl-ontonotes, batch 709 (30709): mcc: 0.7986, acc: 0.7276, precision: 0.8506, recall: 0.7552, f1: 0.8001, edges-srl-ontonotes_loss: 0.0160
09/16 10:01:42 AM: Update 30842: task edges-srl-ontonotes, batch 842 (30842): mcc: 0.7971, acc: 0.7252, precision: 0.8496, recall: 0.7533, f1: 0.7986, edges-srl-ontonotes_loss: 0.0161
09/16 10:01:52 AM: Update 30969: task edges-srl-ontonotes, batch 969 (30969): mcc: 0.7961, acc: 0.7237, precision: 0.8492, recall: 0.7518, f1: 0.7975, edges-srl-ontonotes_loss: 0.0162
09/16 10:01:55 AM: ***** Step 31000 / Validation 31 *****
09/16 10:01:55 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:01:55 AM: Validating...
09/16 10:02:02 AM: Evaluate: task edges-srl-ontonotes, batch 104 (157): mcc: 0.8547, acc: 0.8101, precision: 0.8920, recall: 0.8231, f1: 0.8562, edges-srl-ontonotes_loss: 0.0118
09/16 10:02:06 AM: Updating LR scheduler:
09/16 10:02:06 AM: 	Best result seen so far for macro_avg: 0.860
09/16 10:02:06 AM: 	# validation passes without improvement: 1
09/16 10:02:06 AM: edges-srl-ontonotes_loss: training: 0.016177 validation: 0.011826
09/16 10:02:06 AM: macro_avg: validation: 0.858468
09/16 10:02:06 AM: micro_avg: validation: 0.000000
09/16 10:02:06 AM: edges-srl-ontonotes_mcc: training: 0.795580 validation: 0.857029
09/16 10:02:06 AM: edges-srl-ontonotes_acc: training: 0.722951 validation: 0.813178
09/16 10:02:06 AM: edges-srl-ontonotes_precision: training: 0.848831 validation: 0.892833
09/16 10:02:06 AM: edges-srl-ontonotes_recall: training: 0.751101 validation: 0.826649
09/16 10:02:06 AM: edges-srl-ontonotes_f1: training: 0.796981 validation: 0.858468
09/16 10:02:06 AM: Global learning rate: 2.5e-05
09/16 10:02:06 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:02:13 AM: Update 31079: task edges-srl-ontonotes, batch 79 (31079): mcc: 0.7998, acc: 0.7263, precision: 0.8542, recall: 0.7543, f1: 0.8011, edges-srl-ontonotes_loss: 0.0161
09/16 10:02:23 AM: Update 31176: task edges-srl-ontonotes, batch 176 (31176): mcc: 0.7942, acc: 0.7210, precision: 0.8479, recall: 0.7493, f1: 0.7956, edges-srl-ontonotes_loss: 0.0162
09/16 10:02:33 AM: Update 31303: task edges-srl-ontonotes, batch 303 (31303): mcc: 0.8034, acc: 0.7319, precision: 0.8555, recall: 0.7598, f1: 0.8048, edges-srl-ontonotes_loss: 0.0156
09/16 10:02:43 AM: Update 31431: task edges-srl-ontonotes, batch 431 (31431): mcc: 0.8088, acc: 0.7390, precision: 0.8597, recall: 0.7660, f1: 0.8102, edges-srl-ontonotes_loss: 0.0152
09/16 10:02:53 AM: Update 31543: task edges-srl-ontonotes, batch 543 (31543): mcc: 0.8106, acc: 0.7418, precision: 0.8607, recall: 0.7684, f1: 0.8120, edges-srl-ontonotes_loss: 0.0152
09/16 10:03:03 AM: Update 31664: task edges-srl-ontonotes, batch 664 (31664): mcc: 0.8117, acc: 0.7432, precision: 0.8613, recall: 0.7699, f1: 0.8131, edges-srl-ontonotes_loss: 0.0151
09/16 10:03:13 AM: Update 31800: task edges-srl-ontonotes, batch 800 (31800): mcc: 0.8135, acc: 0.7458, precision: 0.8627, recall: 0.7722, f1: 0.8149, edges-srl-ontonotes_loss: 0.0150
09/16 10:03:23 AM: Update 31916: task edges-srl-ontonotes, batch 916 (31916): mcc: 0.8144, acc: 0.7470, precision: 0.8633, recall: 0.7732, f1: 0.8158, edges-srl-ontonotes_loss: 0.0149
09/16 10:03:30 AM: ***** Step 32000 / Validation 32 *****
09/16 10:03:30 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:03:30 AM: Validating...
09/16 10:03:33 AM: Evaluate: task edges-srl-ontonotes, batch 50 (157): mcc: 0.8387, acc: 0.7870, precision: 0.8870, recall: 0.7974, f1: 0.8398, edges-srl-ontonotes_loss: 0.0129
09/16 10:03:41 AM: Updating LR scheduler:
09/16 10:03:41 AM: 	Best result seen so far for macro_avg: 0.860
09/16 10:03:41 AM: 	# validation passes without improvement: 2
09/16 10:03:41 AM: edges-srl-ontonotes_loss: training: 0.014870 validation: 0.011901
09/16 10:03:41 AM: macro_avg: validation: 0.856500
09/16 10:03:41 AM: micro_avg: validation: 0.000000
09/16 10:03:41 AM: edges-srl-ontonotes_mcc: training: 0.814757 validation: 0.855271
09/16 10:03:41 AM: edges-srl-ontonotes_acc: training: 0.747726 validation: 0.808714
09/16 10:03:41 AM: edges-srl-ontonotes_precision: training: 0.863559 validation: 0.896549
09/16 10:03:41 AM: edges-srl-ontonotes_recall: training: 0.773701 validation: 0.819875
09/16 10:03:41 AM: edges-srl-ontonotes_f1: training: 0.816164 validation: 0.856500
09/16 10:03:41 AM: Global learning rate: 2.5e-05
09/16 10:03:41 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:03:43 AM: Update 32028: task edges-srl-ontonotes, batch 28 (32028): mcc: 0.8256, acc: 0.7661, precision: 0.8695, recall: 0.7888, f1: 0.8272, edges-srl-ontonotes_loss: 0.0142
09/16 10:03:53 AM: Update 32125: task edges-srl-ontonotes, batch 125 (32125): mcc: 0.8261, acc: 0.7618, precision: 0.8729, recall: 0.7864, f1: 0.8274, edges-srl-ontonotes_loss: 0.0142
09/16 10:04:03 AM: Update 32264: task edges-srl-ontonotes, batch 264 (32264): mcc: 0.8161, acc: 0.7508, precision: 0.8646, recall: 0.7752, f1: 0.8175, edges-srl-ontonotes_loss: 0.0149
09/16 10:04:13 AM: Update 32397: task edges-srl-ontonotes, batch 397 (32397): mcc: 0.8147, acc: 0.7479, precision: 0.8645, recall: 0.7727, f1: 0.8160, edges-srl-ontonotes_loss: 0.0151
09/16 10:04:24 AM: Update 32524: task edges-srl-ontonotes, batch 524 (32524): mcc: 0.8131, acc: 0.7456, precision: 0.8635, recall: 0.7707, f1: 0.8145, edges-srl-ontonotes_loss: 0.0151
09/16 10:04:34 AM: Update 32658: task edges-srl-ontonotes, batch 658 (32658): mcc: 0.8114, acc: 0.7433, precision: 0.8622, recall: 0.7687, f1: 0.8128, edges-srl-ontonotes_loss: 0.0152
09/16 10:04:44 AM: Update 32782: task edges-srl-ontonotes, batch 782 (32782): mcc: 0.8100, acc: 0.7416, precision: 0.8611, recall: 0.7671, f1: 0.8114, edges-srl-ontonotes_loss: 0.0152
09/16 10:04:54 AM: Update 32921: task edges-srl-ontonotes, batch 921 (32921): mcc: 0.8104, acc: 0.7417, precision: 0.8613, recall: 0.7675, f1: 0.8117, edges-srl-ontonotes_loss: 0.0152
09/16 10:04:59 AM: ***** Step 33000 / Validation 33 *****
09/16 10:04:59 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:04:59 AM: Validating...
09/16 10:05:04 AM: Evaluate: task edges-srl-ontonotes, batch 58 (157): mcc: 0.8362, acc: 0.7856, precision: 0.8815, recall: 0.7977, f1: 0.8375, edges-srl-ontonotes_loss: 0.0130
09/16 10:05:11 AM: Updating LR scheduler:
09/16 10:05:11 AM: 	Best result seen so far for macro_avg: 0.860
09/16 10:05:11 AM: 	# validation passes without improvement: 3
09/16 10:05:11 AM: edges-srl-ontonotes_loss: training: 0.015250 validation: 0.012069
09/16 10:05:11 AM: macro_avg: validation: 0.855146
09/16 10:05:11 AM: micro_avg: validation: 0.000000
09/16 10:05:11 AM: edges-srl-ontonotes_mcc: training: 0.809874 validation: 0.853856
09/16 10:05:11 AM: edges-srl-ontonotes_acc: training: 0.741241 validation: 0.807559
09/16 10:05:11 AM: edges-srl-ontonotes_precision: training: 0.860938 validation: 0.894228
09/16 10:05:11 AM: edges-srl-ontonotes_recall: training: 0.766926 validation: 0.819336
09/16 10:05:11 AM: edges-srl-ontonotes_f1: training: 0.811217 validation: 0.855146
09/16 10:05:11 AM: Global learning rate: 2.5e-05
09/16 10:05:11 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:05:14 AM: Update 33038: task edges-srl-ontonotes, batch 38 (33038): mcc: 0.8021, acc: 0.7301, precision: 0.8490, recall: 0.7632, f1: 0.8038, edges-srl-ontonotes_loss: 0.0155
09/16 10:05:24 AM: Update 33161: task edges-srl-ontonotes, batch 161 (33161): mcc: 0.8111, acc: 0.7423, precision: 0.8622, recall: 0.7681, f1: 0.8124, edges-srl-ontonotes_loss: 0.0154
09/16 10:05:34 AM: Update 33287: task edges-srl-ontonotes, batch 287 (33287): mcc: 0.8140, acc: 0.7466, precision: 0.8642, recall: 0.7716, f1: 0.8153, edges-srl-ontonotes_loss: 0.0151
09/16 10:05:44 AM: Update 33379: task edges-srl-ontonotes, batch 379 (33379): mcc: 0.8158, acc: 0.7492, precision: 0.8654, recall: 0.7740, f1: 0.8172, edges-srl-ontonotes_loss: 0.0150
09/16 10:05:54 AM: Update 33515: task edges-srl-ontonotes, batch 515 (33515): mcc: 0.8161, acc: 0.7499, precision: 0.8654, recall: 0.7746, f1: 0.8175, edges-srl-ontonotes_loss: 0.0149
09/16 10:06:04 AM: Update 33643: task edges-srl-ontonotes, batch 643 (33643): mcc: 0.8171, acc: 0.7510, precision: 0.8660, recall: 0.7759, f1: 0.8185, edges-srl-ontonotes_loss: 0.0148
09/16 10:06:14 AM: Update 33754: task edges-srl-ontonotes, batch 754 (33754): mcc: 0.8129, acc: 0.7460, precision: 0.8635, recall: 0.7703, f1: 0.8142, edges-srl-ontonotes_loss: 0.0151
09/16 10:06:24 AM: Update 33876: task edges-srl-ontonotes, batch 876 (33876): mcc: 0.8105, acc: 0.7423, precision: 0.8625, recall: 0.7667, f1: 0.8118, edges-srl-ontonotes_loss: 0.0153
09/16 10:06:34 AM: Update 33990: task edges-srl-ontonotes, batch 990 (33990): mcc: 0.8095, acc: 0.7409, precision: 0.8624, recall: 0.7649, f1: 0.8107, edges-srl-ontonotes_loss: 0.0154
09/16 10:06:35 AM: ***** Step 34000 / Validation 34 *****
09/16 10:06:35 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:06:35 AM: Validating...
09/16 10:06:44 AM: Evaluate: task edges-srl-ontonotes, batch 116 (157): mcc: 0.8516, acc: 0.8058, precision: 0.8926, recall: 0.8165, f1: 0.8528, edges-srl-ontonotes_loss: 0.0120
09/16 10:06:47 AM: Updating LR scheduler:
09/16 10:06:47 AM: 	Best result seen so far for macro_avg: 0.860
09/16 10:06:47 AM: 	# validation passes without improvement: 0
09/16 10:06:47 AM: edges-srl-ontonotes_loss: training: 0.015395 validation: 0.012085
09/16 10:06:47 AM: macro_avg: validation: 0.854239
09/16 10:06:47 AM: micro_avg: validation: 0.000000
09/16 10:06:47 AM: edges-srl-ontonotes_mcc: training: 0.809313 validation: 0.852930
09/16 10:06:47 AM: edges-srl-ontonotes_acc: training: 0.740746 validation: 0.807328
09/16 10:06:47 AM: edges-srl-ontonotes_precision: training: 0.862274 validation: 0.893163
09/16 10:06:47 AM: edges-srl-ontonotes_recall: training: 0.764681 validation: 0.818567
09/16 10:06:47 AM: edges-srl-ontonotes_f1: training: 0.810551 validation: 0.854239
09/16 10:06:47 AM: Global learning rate: 1.25e-05
09/16 10:06:47 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:06:54 AM: Update 34110: task edges-srl-ontonotes, batch 110 (34110): mcc: 0.8350, acc: 0.7720, precision: 0.8785, recall: 0.7981, f1: 0.8364, edges-srl-ontonotes_loss: 0.0135
09/16 10:07:04 AM: Update 34253: task edges-srl-ontonotes, batch 253 (34253): mcc: 0.8355, acc: 0.7724, precision: 0.8793, recall: 0.7983, f1: 0.8369, edges-srl-ontonotes_loss: 0.0135
09/16 10:07:14 AM: Update 34369: task edges-srl-ontonotes, batch 369 (34369): mcc: 0.8379, acc: 0.7758, precision: 0.8823, recall: 0.8002, f1: 0.8392, edges-srl-ontonotes_loss: 0.0133
09/16 10:07:24 AM: Update 34549: task edges-srl-ontonotes, batch 549 (34549): mcc: 0.8461, acc: 0.7859, precision: 0.8877, recall: 0.8107, f1: 0.8475, edges-srl-ontonotes_loss: 0.0127
09/16 10:07:34 AM: Update 34713: task edges-srl-ontonotes, batch 713 (34713): mcc: 0.8482, acc: 0.7882, precision: 0.8889, recall: 0.8134, f1: 0.8495, edges-srl-ontonotes_loss: 0.0126
09/16 10:07:44 AM: Update 34875: task edges-srl-ontonotes, batch 875 (34875): mcc: 0.8505, acc: 0.7908, precision: 0.8907, recall: 0.8161, f1: 0.8518, edges-srl-ontonotes_loss: 0.0124
09/16 10:07:52 AM: ***** Step 35000 / Validation 35 *****
09/16 10:07:52 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:07:52 AM: Validating...
09/16 10:07:54 AM: Evaluate: task edges-srl-ontonotes, batch 30 (157): mcc: 0.8503, acc: 0.8016, precision: 0.8938, recall: 0.8130, f1: 0.8515, edges-srl-ontonotes_loss: 0.0123
09/16 10:08:04 AM: Evaluate: task edges-srl-ontonotes, batch 153 (157): mcc: 0.8559, acc: 0.8087, precision: 0.8953, recall: 0.8222, f1: 0.8572, edges-srl-ontonotes_loss: 0.0119
09/16 10:08:04 AM: Updating LR scheduler:
09/16 10:08:04 AM: 	Best result seen so far for macro_avg: 0.860
09/16 10:08:04 AM: 	# validation passes without improvement: 1
09/16 10:08:04 AM: edges-srl-ontonotes_loss: training: 0.012371 validation: 0.011981
09/16 10:08:04 AM: macro_avg: validation: 0.856489
09/16 10:08:04 AM: micro_avg: validation: 0.000000
09/16 10:08:04 AM: edges-srl-ontonotes_mcc: training: 0.851032 validation: 0.855180
09/16 10:08:04 AM: edges-srl-ontonotes_acc: training: 0.791738 validation: 0.807944
09/16 10:08:04 AM: edges-srl-ontonotes_precision: training: 0.890800 validation: 0.894693
09/16 10:08:04 AM: edges-srl-ontonotes_recall: training: 0.817153 validation: 0.821415
09/16 10:08:04 AM: edges-srl-ontonotes_f1: training: 0.852388 validation: 0.856489
09/16 10:08:04 AM: Global learning rate: 1.25e-05
09/16 10:08:04 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:08:14 AM: Update 35169: task edges-srl-ontonotes, batch 169 (35169): mcc: 0.8573, acc: 0.7982, precision: 0.8937, recall: 0.8264, f1: 0.8587, edges-srl-ontonotes_loss: 0.0119
09/16 10:08:24 AM: Update 35303: task edges-srl-ontonotes, batch 303 (35303): mcc: 0.8586, acc: 0.7999, precision: 0.8953, recall: 0.8273, f1: 0.8599, edges-srl-ontonotes_loss: 0.0119
09/16 10:08:34 AM: Update 35454: task edges-srl-ontonotes, batch 454 (35454): mcc: 0.8577, acc: 0.7985, precision: 0.8946, recall: 0.8263, f1: 0.8591, edges-srl-ontonotes_loss: 0.0120
09/16 10:08:44 AM: Update 35571: task edges-srl-ontonotes, batch 571 (35571): mcc: 0.8569, acc: 0.7979, precision: 0.8937, recall: 0.8256, f1: 0.8583, edges-srl-ontonotes_loss: 0.0121
09/16 10:08:54 AM: Update 35709: task edges-srl-ontonotes, batch 709 (35709): mcc: 0.8509, acc: 0.7903, precision: 0.8895, recall: 0.8181, f1: 0.8523, edges-srl-ontonotes_loss: 0.0125
09/16 10:09:04 AM: Update 35841: task edges-srl-ontonotes, batch 841 (35841): mcc: 0.8481, acc: 0.7872, precision: 0.8877, recall: 0.8144, f1: 0.8495, edges-srl-ontonotes_loss: 0.0127
09/16 10:09:14 AM: Update 35964: task edges-srl-ontonotes, batch 964 (35964): mcc: 0.8430, acc: 0.7811, precision: 0.8839, recall: 0.8083, f1: 0.8444, edges-srl-ontonotes_loss: 0.0130
09/16 10:09:17 AM: ***** Step 36000 / Validation 36 *****
09/16 10:09:17 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:09:17 AM: Validating...
09/16 10:09:24 AM: Evaluate: task edges-srl-ontonotes, batch 104 (157): mcc: 0.8550, acc: 0.8080, precision: 0.8962, recall: 0.8197, f1: 0.8563, edges-srl-ontonotes_loss: 0.0119
09/16 10:09:28 AM: Updating LR scheduler:
09/16 10:09:28 AM: 	Best result seen so far for macro_avg: 0.860
09/16 10:09:28 AM: 	# validation passes without improvement: 2
09/16 10:09:28 AM: edges-srl-ontonotes_loss: training: 0.013127 validation: 0.011894
09/16 10:09:28 AM: macro_avg: validation: 0.858380
09/16 10:09:28 AM: micro_avg: validation: 0.000000
09/16 10:09:28 AM: edges-srl-ontonotes_mcc: training: 0.841920 validation: 0.857076
09/16 10:09:28 AM: edges-srl-ontonotes_acc: training: 0.779857 validation: 0.811100
09/16 10:09:28 AM: edges-srl-ontonotes_precision: training: 0.883109 validation: 0.896081
09/16 10:09:28 AM: edges-srl-ontonotes_recall: training: 0.807000 validation: 0.823724
09/16 10:09:28 AM: edges-srl-ontonotes_f1: training: 0.843341 validation: 0.858380
09/16 10:09:28 AM: Global learning rate: 1.25e-05
09/16 10:09:28 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:09:35 AM: Update 36082: task edges-srl-ontonotes, batch 82 (36082): mcc: 0.8020, acc: 0.7331, precision: 0.8518, recall: 0.7604, f1: 0.8035, edges-srl-ontonotes_loss: 0.0157
09/16 10:09:45 AM: Update 36218: task edges-srl-ontonotes, batch 218 (36218): mcc: 0.8082, acc: 0.7383, precision: 0.8587, recall: 0.7658, f1: 0.8096, edges-srl-ontonotes_loss: 0.0155
09/16 10:09:55 AM: Update 36354: task edges-srl-ontonotes, batch 354 (36354): mcc: 0.8174, acc: 0.7492, precision: 0.8656, recall: 0.7769, f1: 0.8188, edges-srl-ontonotes_loss: 0.0149
09/16 10:10:05 AM: Update 36506: task edges-srl-ontonotes, batch 506 (36506): mcc: 0.8202, acc: 0.7525, precision: 0.8677, recall: 0.7802, f1: 0.8216, edges-srl-ontonotes_loss: 0.0146
09/16 10:10:15 AM: Update 36618: task edges-srl-ontonotes, batch 618 (36618): mcc: 0.8239, acc: 0.7572, precision: 0.8702, recall: 0.7848, f1: 0.8253, edges-srl-ontonotes_loss: 0.0143
09/16 10:10:25 AM: Update 36761: task edges-srl-ontonotes, batch 761 (36761): mcc: 0.8260, acc: 0.7599, precision: 0.8717, recall: 0.7874, f1: 0.8274, edges-srl-ontonotes_loss: 0.0142
09/16 10:10:35 AM: Update 36894: task edges-srl-ontonotes, batch 894 (36894): mcc: 0.8264, acc: 0.7605, precision: 0.8718, recall: 0.7881, f1: 0.8278, edges-srl-ontonotes_loss: 0.0141
09/16 10:10:42 AM: ***** Step 37000 / Validation 37 *****
09/16 10:10:42 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:10:42 AM: Validating...
09/16 10:10:45 AM: Evaluate: task edges-srl-ontonotes, batch 37 (157): mcc: 0.8478, acc: 0.7998, precision: 0.8905, recall: 0.8114, f1: 0.8491, edges-srl-ontonotes_loss: 0.0125
09/16 10:10:54 AM: Best result seen so far for edges-srl-ontonotes.
09/16 10:10:54 AM: Best result seen so far for macro.
09/16 10:10:54 AM: Updating LR scheduler:
09/16 10:10:54 AM: 	Best result seen so far for macro_avg: 0.861
09/16 10:10:54 AM: 	# validation passes without improvement: 0
09/16 10:10:54 AM: edges-srl-ontonotes_loss: training: 0.014195 validation: 0.011677
09/16 10:10:54 AM: macro_avg: validation: 0.861282
09/16 10:10:54 AM: micro_avg: validation: 0.000000
09/16 10:10:54 AM: edges-srl-ontonotes_mcc: training: 0.825389 validation: 0.859938
09/16 10:10:54 AM: edges-srl-ontonotes_acc: training: 0.759492 validation: 0.814795
09/16 10:10:54 AM: edges-srl-ontonotes_precision: training: 0.870709 validation: 0.897040
09/16 10:10:54 AM: edges-srl-ontonotes_recall: training: 0.787175 validation: 0.828266
09/16 10:10:54 AM: edges-srl-ontonotes_f1: training: 0.826838 validation: 0.861282
09/16 10:10:54 AM: Global learning rate: 1.25e-05
09/16 10:10:54 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:10:55 AM: Update 37015: task edges-srl-ontonotes, batch 15 (37015): mcc: 0.8124, acc: 0.7391, precision: 0.8693, recall: 0.7641, f1: 0.8133, edges-srl-ontonotes_loss: 0.0146
09/16 10:11:05 AM: Update 37150: task edges-srl-ontonotes, batch 150 (37150): mcc: 0.8203, acc: 0.7550, precision: 0.8670, recall: 0.7810, f1: 0.8218, edges-srl-ontonotes_loss: 0.0144
09/16 10:11:15 AM: Update 37280: task edges-srl-ontonotes, batch 280 (37280): mcc: 0.8141, acc: 0.7466, precision: 0.8623, recall: 0.7737, f1: 0.8156, edges-srl-ontonotes_loss: 0.0149
09/16 10:11:25 AM: Update 37423: task edges-srl-ontonotes, batch 423 (37423): mcc: 0.8111, acc: 0.7423, precision: 0.8600, recall: 0.7701, f1: 0.8126, edges-srl-ontonotes_loss: 0.0151
09/16 10:11:35 AM: Update 37513: task edges-srl-ontonotes, batch 513 (37513): mcc: 0.8102, acc: 0.7413, precision: 0.8596, recall: 0.7688, f1: 0.8117, edges-srl-ontonotes_loss: 0.0153
09/16 10:11:45 AM: Update 37640: task edges-srl-ontonotes, batch 640 (37640): mcc: 0.8092, acc: 0.7400, precision: 0.8587, recall: 0.7676, f1: 0.8106, edges-srl-ontonotes_loss: 0.0153
09/16 10:11:55 AM: Update 37776: task edges-srl-ontonotes, batch 776 (37776): mcc: 0.8101, acc: 0.7412, precision: 0.8597, recall: 0.7685, f1: 0.8115, edges-srl-ontonotes_loss: 0.0152
09/16 10:12:05 AM: Update 37897: task edges-srl-ontonotes, batch 897 (37897): mcc: 0.8080, acc: 0.7387, precision: 0.8582, recall: 0.7660, f1: 0.8095, edges-srl-ontonotes_loss: 0.0154
09/16 10:12:13 AM: ***** Step 38000 / Validation 38 *****
09/16 10:12:13 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:12:13 AM: Validating...
09/16 10:12:15 AM: Evaluate: task edges-srl-ontonotes, batch 28 (157): mcc: 0.8528, acc: 0.8032, precision: 0.8974, recall: 0.8145, f1: 0.8539, edges-srl-ontonotes_loss: 0.0121
09/16 10:12:25 AM: Updating LR scheduler:
09/16 10:12:25 AM: 	Best result seen so far for macro_avg: 0.861
09/16 10:12:25 AM: 	# validation passes without improvement: 1
09/16 10:12:25 AM: edges-srl-ontonotes_loss: training: 0.015465 validation: 0.011693
09/16 10:12:25 AM: macro_avg: validation: 0.860197
09/16 10:12:25 AM: micro_avg: validation: 0.000000
09/16 10:12:25 AM: edges-srl-ontonotes_mcc: training: 0.806640 validation: 0.858849
09/16 10:12:25 AM: edges-srl-ontonotes_acc: training: 0.736866 validation: 0.813871
09/16 10:12:25 AM: edges-srl-ontonotes_precision: training: 0.857464 validation: 0.896221
09/16 10:12:25 AM: edges-srl-ontonotes_recall: training: 0.764003 validation: 0.826957
09/16 10:12:25 AM: edges-srl-ontonotes_f1: training: 0.808040 validation: 0.860197
09/16 10:12:25 AM: Global learning rate: 1.25e-05
09/16 10:12:25 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:12:25 AM: Update 38008: task edges-srl-ontonotes, batch 8 (38008): mcc: 0.7880, acc: 0.7331, precision: 0.8394, recall: 0.7454, f1: 0.7896, edges-srl-ontonotes_loss: 0.0168
09/16 10:12:35 AM: Update 38115: task edges-srl-ontonotes, batch 115 (38115): mcc: 0.7854, acc: 0.7112, precision: 0.8399, recall: 0.7401, f1: 0.7869, edges-srl-ontonotes_loss: 0.0169
09/16 10:12:45 AM: Update 38250: task edges-srl-ontonotes, batch 250 (38250): mcc: 0.7912, acc: 0.7172, precision: 0.8456, recall: 0.7459, f1: 0.7926, edges-srl-ontonotes_loss: 0.0165
09/16 10:12:55 AM: Update 38380: task edges-srl-ontonotes, batch 380 (38380): mcc: 0.7902, acc: 0.7172, precision: 0.8440, recall: 0.7453, f1: 0.7916, edges-srl-ontonotes_loss: 0.0165
09/16 10:13:05 AM: Update 38503: task edges-srl-ontonotes, batch 503 (38503): mcc: 0.7948, acc: 0.7225, precision: 0.8478, recall: 0.7505, f1: 0.7962, edges-srl-ontonotes_loss: 0.0161
09/16 10:13:15 AM: Update 38633: task edges-srl-ontonotes, batch 633 (38633): mcc: 0.8000, acc: 0.7295, precision: 0.8518, recall: 0.7566, f1: 0.8014, edges-srl-ontonotes_loss: 0.0158
09/16 10:13:26 AM: Update 38735: task edges-srl-ontonotes, batch 735 (38735): mcc: 0.8030, acc: 0.7332, precision: 0.8543, recall: 0.7602, f1: 0.8045, edges-srl-ontonotes_loss: 0.0156
09/16 10:13:36 AM: Update 38874: task edges-srl-ontonotes, batch 874 (38874): mcc: 0.8055, acc: 0.7363, precision: 0.8562, recall: 0.7631, f1: 0.8069, edges-srl-ontonotes_loss: 0.0155
09/16 10:13:46 AM: Update 39000: task edges-srl-ontonotes, batch 1000 (39000): mcc: 0.8076, acc: 0.7385, precision: 0.8583, recall: 0.7650, f1: 0.8090, edges-srl-ontonotes_loss: 0.0153
09/16 10:13:46 AM: ***** Step 39000 / Validation 39 *****
09/16 10:13:46 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:13:46 AM: Validating...
09/16 10:13:56 AM: Evaluate: task edges-srl-ontonotes, batch 137 (157): mcc: 0.8607, acc: 0.8181, precision: 0.8951, recall: 0.8315, f1: 0.8621, edges-srl-ontonotes_loss: 0.0115
09/16 10:13:58 AM: Updating LR scheduler:
09/16 10:13:58 AM: 	Best result seen so far for macro_avg: 0.861
09/16 10:13:58 AM: 	# validation passes without improvement: 2
09/16 10:13:58 AM: edges-srl-ontonotes_loss: training: 0.015307 validation: 0.011732
09/16 10:13:58 AM: macro_avg: validation: 0.859482
09/16 10:13:58 AM: micro_avg: validation: 0.000000
09/16 10:13:58 AM: edges-srl-ontonotes_mcc: training: 0.807584 validation: 0.858034
09/16 10:13:58 AM: edges-srl-ontonotes_acc: training: 0.738521 validation: 0.814333
09/16 10:13:58 AM: edges-srl-ontonotes_precision: training: 0.858314 validation: 0.893234
09/16 10:13:58 AM: edges-srl-ontonotes_recall: training: 0.765005 validation: 0.828189
09/16 10:13:58 AM: edges-srl-ontonotes_f1: training: 0.808977 validation: 0.859482
09/16 10:13:58 AM: Global learning rate: 1.25e-05
09/16 10:13:58 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:14:06 AM: Update 39093: task edges-srl-ontonotes, batch 93 (39093): mcc: 0.8183, acc: 0.7521, precision: 0.8648, recall: 0.7792, f1: 0.8198, edges-srl-ontonotes_loss: 0.0147
09/16 10:14:16 AM: Update 39215: task edges-srl-ontonotes, batch 215 (39215): mcc: 0.8272, acc: 0.7619, precision: 0.8727, recall: 0.7888, f1: 0.8286, edges-srl-ontonotes_loss: 0.0143
09/16 10:14:26 AM: Update 39331: task edges-srl-ontonotes, batch 331 (39331): mcc: 0.8260, acc: 0.7617, precision: 0.8720, recall: 0.7872, f1: 0.8274, edges-srl-ontonotes_loss: 0.0143
09/16 10:14:36 AM: Update 39445: task edges-srl-ontonotes, batch 445 (39445): mcc: 0.8223, acc: 0.7568, precision: 0.8695, recall: 0.7824, f1: 0.8237, edges-srl-ontonotes_loss: 0.0145
09/16 10:14:47 AM: Update 39577: task edges-srl-ontonotes, batch 577 (39577): mcc: 0.8202, acc: 0.7546, precision: 0.8679, recall: 0.7799, f1: 0.8216, edges-srl-ontonotes_loss: 0.0147
09/16 10:14:57 AM: Update 39675: task edges-srl-ontonotes, batch 675 (39675): mcc: 0.8174, acc: 0.7513, precision: 0.8657, recall: 0.7766, f1: 0.8188, edges-srl-ontonotes_loss: 0.0148
09/16 10:15:07 AM: Update 39812: task edges-srl-ontonotes, batch 812 (39812): mcc: 0.8158, acc: 0.7491, precision: 0.8651, recall: 0.7742, f1: 0.8171, edges-srl-ontonotes_loss: 0.0149
09/16 10:15:17 AM: Update 39942: task edges-srl-ontonotes, batch 942 (39942): mcc: 0.8156, acc: 0.7489, precision: 0.8650, recall: 0.7740, f1: 0.8169, edges-srl-ontonotes_loss: 0.0150
09/16 10:15:22 AM: ***** Step 40000 / Validation 40 *****
09/16 10:15:22 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:15:22 AM: Validating...
09/16 10:15:27 AM: Evaluate: task edges-srl-ontonotes, batch 65 (157): mcc: 0.8435, acc: 0.7947, precision: 0.8880, recall: 0.8055, f1: 0.8447, edges-srl-ontonotes_loss: 0.0126
09/16 10:15:34 AM: Updating LR scheduler:
09/16 10:15:34 AM: 	Best result seen so far for macro_avg: 0.861
09/16 10:15:34 AM: 	# validation passes without improvement: 3
09/16 10:15:34 AM: edges-srl-ontonotes_loss: training: 0.015038 validation: 0.011782
09/16 10:15:34 AM: macro_avg: validation: 0.858930
09/16 10:15:34 AM: micro_avg: validation: 0.000000
09/16 10:15:34 AM: edges-srl-ontonotes_mcc: training: 0.814944 validation: 0.857626
09/16 10:15:34 AM: edges-srl-ontonotes_acc: training: 0.748005 validation: 0.812640
09/16 10:15:34 AM: edges-srl-ontonotes_precision: training: 0.864508 validation: 0.896459
09/16 10:15:34 AM: edges-srl-ontonotes_recall: training: 0.773195 validation: 0.824417
09/16 10:15:34 AM: edges-srl-ontonotes_f1: training: 0.816306 validation: 0.858930
09/16 10:15:34 AM: Global learning rate: 1.25e-05
09/16 10:15:34 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:15:37 AM: Update 40044: task edges-srl-ontonotes, batch 44 (40044): mcc: 0.8065, acc: 0.7407, precision: 0.8572, recall: 0.7640, f1: 0.8079, edges-srl-ontonotes_loss: 0.0156
09/16 10:15:47 AM: Update 40182: task edges-srl-ontonotes, batch 182 (40182): mcc: 0.8012, acc: 0.7340, precision: 0.8521, recall: 0.7586, f1: 0.8026, edges-srl-ontonotes_loss: 0.0156
09/16 10:15:57 AM: Update 40309: task edges-srl-ontonotes, batch 309 (40309): mcc: 0.8048, acc: 0.7373, precision: 0.8561, recall: 0.7618, f1: 0.8062, edges-srl-ontonotes_loss: 0.0155
09/16 10:16:07 AM: Update 40446: task edges-srl-ontonotes, batch 446 (40446): mcc: 0.8088, acc: 0.7423, precision: 0.8589, recall: 0.7667, f1: 0.8102, edges-srl-ontonotes_loss: 0.0152
09/16 10:16:17 AM: Update 40587: task edges-srl-ontonotes, batch 587 (40587): mcc: 0.8113, acc: 0.7458, precision: 0.8604, recall: 0.7701, f1: 0.8127, edges-srl-ontonotes_loss: 0.0151
09/16 10:16:27 AM: Update 40689: task edges-srl-ontonotes, batch 689 (40689): mcc: 0.8125, acc: 0.7469, precision: 0.8618, recall: 0.7711, f1: 0.8139, edges-srl-ontonotes_loss: 0.0150
09/16 10:16:37 AM: Update 40828: task edges-srl-ontonotes, batch 828 (40828): mcc: 0.8145, acc: 0.7491, precision: 0.8635, recall: 0.7732, f1: 0.8159, edges-srl-ontonotes_loss: 0.0149
09/16 10:16:47 AM: Update 40943: task edges-srl-ontonotes, batch 943 (40943): mcc: 0.8140, acc: 0.7484, precision: 0.8631, recall: 0.7728, f1: 0.8154, edges-srl-ontonotes_loss: 0.0149
09/16 10:16:52 AM: ***** Step 41000 / Validation 41 *****
09/16 10:16:52 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:16:52 AM: Validating...
09/16 10:16:57 AM: Evaluate: task edges-srl-ontonotes, batch 71 (157): mcc: 0.8464, acc: 0.7976, precision: 0.8915, recall: 0.8078, f1: 0.8476, edges-srl-ontonotes_loss: 0.0123
09/16 10:17:03 AM: Updating LR scheduler:
09/16 10:17:03 AM: 	Best result seen so far for macro_avg: 0.861
09/16 10:17:03 AM: 	# validation passes without improvement: 0
09/16 10:17:03 AM: edges-srl-ontonotes_loss: training: 0.014969 validation: 0.011832
09/16 10:17:03 AM: macro_avg: validation: 0.857510
09/16 10:17:03 AM: micro_avg: validation: 0.000000
09/16 10:17:03 AM: edges-srl-ontonotes_mcc: training: 0.813306 validation: 0.856259
09/16 10:17:03 AM: edges-srl-ontonotes_acc: training: 0.747296 validation: 0.810715
09/16 10:17:03 AM: edges-srl-ontonotes_precision: training: 0.862757 validation: 0.896740
09/16 10:17:03 AM: edges-srl-ontonotes_recall: training: 0.771706 validation: 0.821569
09/16 10:17:03 AM: edges-srl-ontonotes_f1: training: 0.814696 validation: 0.857510
09/16 10:17:03 AM: Global learning rate: 6.25e-06
09/16 10:17:03 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:17:07 AM: Update 41044: task edges-srl-ontonotes, batch 44 (41044): mcc: 0.8050, acc: 0.7312, precision: 0.8663, recall: 0.7530, f1: 0.8057, edges-srl-ontonotes_loss: 0.0163
09/16 10:17:17 AM: Update 41166: task edges-srl-ontonotes, batch 166 (41166): mcc: 0.7958, acc: 0.7224, precision: 0.8558, recall: 0.7454, f1: 0.7968, edges-srl-ontonotes_loss: 0.0164
09/16 10:17:27 AM: Update 41286: task edges-srl-ontonotes, batch 286 (41286): mcc: 0.8014, acc: 0.7296, precision: 0.8584, recall: 0.7534, f1: 0.8025, edges-srl-ontonotes_loss: 0.0160
09/16 10:17:37 AM: Update 41428: task edges-srl-ontonotes, batch 428 (41428): mcc: 0.8115, acc: 0.7424, precision: 0.8646, recall: 0.7667, f1: 0.8127, edges-srl-ontonotes_loss: 0.0152
09/16 10:17:47 AM: Update 41563: task edges-srl-ontonotes, batch 563 (41563): mcc: 0.8184, acc: 0.7508, precision: 0.8690, recall: 0.7757, f1: 0.8197, edges-srl-ontonotes_loss: 0.0147
09/16 10:17:57 AM: Update 41740: task edges-srl-ontonotes, batch 740 (41740): mcc: 0.8284, acc: 0.7633, precision: 0.8751, recall: 0.7888, f1: 0.8297, edges-srl-ontonotes_loss: 0.0140
09/16 10:18:07 AM: Update 41866: task edges-srl-ontonotes, batch 866 (41866): mcc: 0.8338, acc: 0.7699, precision: 0.8787, recall: 0.7956, f1: 0.8351, edges-srl-ontonotes_loss: 0.0136
09/16 10:18:15 AM: ***** Step 42000 / Validation 42 *****
09/16 10:18:15 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:18:15 AM: Validating...
09/16 10:18:17 AM: Evaluate: task edges-srl-ontonotes, batch 28 (157): mcc: 0.8492, acc: 0.7990, precision: 0.8963, recall: 0.8086, f1: 0.8502, edges-srl-ontonotes_loss: 0.0123
09/16 10:18:27 AM: Updating LR scheduler:
09/16 10:18:27 AM: 	Best result seen so far for macro_avg: 0.861
09/16 10:18:27 AM: 	# validation passes without improvement: 1
09/16 10:18:27 AM: edges-srl-ontonotes_loss: training: 0.013371 validation: 0.011836
09/16 10:18:27 AM: macro_avg: validation: 0.857304
09/16 10:18:27 AM: micro_avg: validation: 0.000000
09/16 10:18:27 AM: edges-srl-ontonotes_mcc: training: 0.837334 validation: 0.856088
09/16 10:18:27 AM: edges-srl-ontonotes_acc: training: 0.774371 validation: 0.808791
09/16 10:18:27 AM: edges-srl-ontonotes_precision: training: 0.881208 validation: 0.897391
09/16 10:18:27 AM: edges-srl-ontonotes_recall: training: 0.800086 validation: 0.820645
09/16 10:18:27 AM: edges-srl-ontonotes_f1: training: 0.838690 validation: 0.857304
09/16 10:18:27 AM: Global learning rate: 6.25e-06
09/16 10:18:27 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:18:27 AM: Update 42008: task edges-srl-ontonotes, batch 8 (42008): mcc: 0.8708, acc: 0.8114, precision: 0.9112, recall: 0.8357, f1: 0.8718, edges-srl-ontonotes_loss: 0.0118
09/16 10:18:37 AM: Update 42171: task edges-srl-ontonotes, batch 171 (42171): mcc: 0.8608, acc: 0.8023, precision: 0.8998, recall: 0.8273, f1: 0.8620, edges-srl-ontonotes_loss: 0.0118
09/16 10:18:47 AM: Update 42335: task edges-srl-ontonotes, batch 335 (42335): mcc: 0.8631, acc: 0.8056, precision: 0.8992, recall: 0.8323, f1: 0.8644, edges-srl-ontonotes_loss: 0.0116
09/16 10:18:58 AM: Update 42491: task edges-srl-ontonotes, batch 491 (42491): mcc: 0.8615, acc: 0.8043, precision: 0.8978, recall: 0.8306, f1: 0.8629, edges-srl-ontonotes_loss: 0.0117
09/16 10:19:08 AM: Update 42658: task edges-srl-ontonotes, batch 658 (42658): mcc: 0.8610, acc: 0.8040, precision: 0.8975, recall: 0.8298, f1: 0.8623, edges-srl-ontonotes_loss: 0.0118
09/16 10:19:19 AM: Update 42804: task edges-srl-ontonotes, batch 804 (42804): mcc: 0.8608, acc: 0.8036, precision: 0.8977, recall: 0.8293, f1: 0.8622, edges-srl-ontonotes_loss: 0.0118
09/16 10:19:29 AM: Update 42935: task edges-srl-ontonotes, batch 935 (42935): mcc: 0.8566, acc: 0.7986, precision: 0.8944, recall: 0.8244, f1: 0.8580, edges-srl-ontonotes_loss: 0.0122
09/16 10:19:34 AM: ***** Step 43000 / Validation 43 *****
09/16 10:19:34 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:19:34 AM: Validating...
09/16 10:19:39 AM: Evaluate: task edges-srl-ontonotes, batch 75 (157): mcc: 0.8482, acc: 0.7997, precision: 0.8922, recall: 0.8105, f1: 0.8494, edges-srl-ontonotes_loss: 0.0123
09/16 10:19:46 AM: Updating LR scheduler:
09/16 10:19:46 AM: 	Best result seen so far for macro_avg: 0.861
09/16 10:19:46 AM: 	# validation passes without improvement: 2
09/16 10:19:46 AM: edges-srl-ontonotes_loss: training: 0.012234 validation: 0.011773
09/16 10:19:46 AM: macro_avg: validation: 0.859068
09/16 10:19:46 AM: micro_avg: validation: 0.000000
09/16 10:19:46 AM: edges-srl-ontonotes_mcc: training: 0.855429 validation: 0.857773
09/16 10:19:46 AM: edges-srl-ontonotes_acc: training: 0.797084 validation: 0.811870
09/16 10:19:46 AM: edges-srl-ontonotes_precision: training: 0.893509 validation: 0.896760
09/16 10:19:46 AM: edges-srl-ontonotes_recall: training: 0.822981 validation: 0.824417
09/16 10:19:46 AM: edges-srl-ontonotes_f1: training: 0.856796 validation: 0.859068
09/16 10:19:46 AM: Global learning rate: 6.25e-06
09/16 10:19:46 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:19:49 AM: Update 43042: task edges-srl-ontonotes, batch 42 (43042): mcc: 0.8222, acc: 0.7580, precision: 0.8669, recall: 0.7847, f1: 0.8238, edges-srl-ontonotes_loss: 0.0142
09/16 10:19:59 AM: Update 43152: task edges-srl-ontonotes, batch 152 (43152): mcc: 0.8179, acc: 0.7503, precision: 0.8651, recall: 0.7783, f1: 0.8194, edges-srl-ontonotes_loss: 0.0147
09/16 10:20:09 AM: Update 43288: task edges-srl-ontonotes, batch 288 (43288): mcc: 0.8125, acc: 0.7427, precision: 0.8611, recall: 0.7716, f1: 0.8139, edges-srl-ontonotes_loss: 0.0151
09/16 10:20:19 AM: Update 43428: task edges-srl-ontonotes, batch 428 (43428): mcc: 0.8116, acc: 0.7421, precision: 0.8605, recall: 0.7706, f1: 0.8131, edges-srl-ontonotes_loss: 0.0151
09/16 10:20:29 AM: Update 43568: task edges-srl-ontonotes, batch 568 (43568): mcc: 0.8158, acc: 0.7480, precision: 0.8643, recall: 0.7751, f1: 0.8172, edges-srl-ontonotes_loss: 0.0149
09/16 10:20:40 AM: Update 43708: task edges-srl-ontonotes, batch 708 (43708): mcc: 0.8188, acc: 0.7511, precision: 0.8668, recall: 0.7784, f1: 0.8202, edges-srl-ontonotes_loss: 0.0147
09/16 10:20:50 AM: Update 43807: task edges-srl-ontonotes, batch 807 (43807): mcc: 0.8201, acc: 0.7525, precision: 0.8678, recall: 0.7799, f1: 0.8215, edges-srl-ontonotes_loss: 0.0146
09/16 10:21:00 AM: Update 43934: task edges-srl-ontonotes, batch 934 (43934): mcc: 0.8226, acc: 0.7557, precision: 0.8694, recall: 0.7831, f1: 0.8240, edges-srl-ontonotes_loss: 0.0144
09/16 10:21:04 AM: ***** Step 44000 / Validation 44 *****
09/16 10:21:04 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:21:04 AM: Validating...
09/16 10:21:10 AM: Evaluate: task edges-srl-ontonotes, batch 59 (157): mcc: 0.8480, acc: 0.8018, precision: 0.8898, recall: 0.8123, f1: 0.8493, edges-srl-ontonotes_loss: 0.0125
09/16 10:21:17 AM: Best result seen so far for edges-srl-ontonotes.
09/16 10:21:17 AM: Best result seen so far for macro.
09/16 10:21:17 AM: Updating LR scheduler:
09/16 10:21:17 AM: 	Best result seen so far for macro_avg: 0.862
09/16 10:21:17 AM: 	# validation passes without improvement: 0
09/16 10:21:17 AM: edges-srl-ontonotes_loss: training: 0.014391 validation: 0.011632
09/16 10:21:17 AM: macro_avg: validation: 0.862134
09/16 10:21:17 AM: micro_avg: validation: 0.000000
09/16 10:21:17 AM: edges-srl-ontonotes_mcc: training: 0.823348 validation: 0.860755
09/16 10:21:17 AM: edges-srl-ontonotes_acc: training: 0.756631 validation: 0.817181
09/16 10:21:17 AM: edges-srl-ontonotes_precision: training: 0.870222 validation: 0.896724
09/16 10:21:17 AM: edges-srl-ontonotes_recall: training: 0.783782 validation: 0.830113
09/16 10:21:17 AM: edges-srl-ontonotes_f1: training: 0.824744 validation: 0.862134
09/16 10:21:17 AM: Global learning rate: 6.25e-06
09/16 10:21:17 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:21:20 AM: Update 44035: task edges-srl-ontonotes, batch 35 (44035): mcc: 0.8495, acc: 0.7900, precision: 0.8856, recall: 0.8191, f1: 0.8510, edges-srl-ontonotes_loss: 0.0127
09/16 10:21:30 AM: Update 44175: task edges-srl-ontonotes, batch 175 (44175): mcc: 0.8330, acc: 0.7694, precision: 0.8758, recall: 0.7968, f1: 0.8345, edges-srl-ontonotes_loss: 0.0136
09/16 10:21:40 AM: Update 44327: task edges-srl-ontonotes, batch 327 (44327): mcc: 0.8288, acc: 0.7644, precision: 0.8739, recall: 0.7907, f1: 0.8302, edges-srl-ontonotes_loss: 0.0139
09/16 10:21:50 AM: Update 44464: task edges-srl-ontonotes, batch 464 (44464): mcc: 0.8258, acc: 0.7611, precision: 0.8716, recall: 0.7873, f1: 0.8273, edges-srl-ontonotes_loss: 0.0142
09/16 10:22:00 AM: Update 44603: task edges-srl-ontonotes, batch 603 (44603): mcc: 0.8211, acc: 0.7550, precision: 0.8679, recall: 0.7817, f1: 0.8225, edges-srl-ontonotes_loss: 0.0145
09/16 10:22:10 AM: Update 44729: task edges-srl-ontonotes, batch 729 (44729): mcc: 0.8189, acc: 0.7524, precision: 0.8658, recall: 0.7794, f1: 0.8203, edges-srl-ontonotes_loss: 0.0147
09/16 10:22:20 AM: Update 44868: task edges-srl-ontonotes, batch 868 (44868): mcc: 0.8182, acc: 0.7514, precision: 0.8653, recall: 0.7785, f1: 0.8196, edges-srl-ontonotes_loss: 0.0147
09/16 10:22:30 AM: ***** Step 45000 / Validation 45 *****
09/16 10:22:30 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:22:30 AM: Validating...
09/16 10:22:30 AM: Evaluate: task edges-srl-ontonotes, batch 9 (157): mcc: 0.8498, acc: 0.8073, precision: 0.8895, recall: 0.8160, f1: 0.8512, edges-srl-ontonotes_loss: 0.0115
09/16 10:22:40 AM: Evaluate: task edges-srl-ontonotes, batch 148 (157): mcc: 0.8614, acc: 0.8178, precision: 0.8981, recall: 0.8300, f1: 0.8627, edges-srl-ontonotes_loss: 0.0115
09/16 10:22:41 AM: Updating LR scheduler:
09/16 10:22:41 AM: 	Best result seen so far for macro_avg: 0.862
09/16 10:22:41 AM: 	# validation passes without improvement: 1
09/16 10:22:41 AM: edges-srl-ontonotes_loss: training: 0.014752 validation: 0.011632
09/16 10:22:41 AM: macro_avg: validation: 0.861236
09/16 10:22:41 AM: micro_avg: validation: 0.000000
09/16 10:22:41 AM: edges-srl-ontonotes_mcc: training: 0.816345 validation: 0.859882
09/16 10:22:41 AM: edges-srl-ontonotes_acc: training: 0.749293 validation: 0.815873
09/16 10:22:41 AM: edges-srl-ontonotes_precision: training: 0.863739 validation: 0.896759
09/16 10:22:41 AM: edges-srl-ontonotes_recall: training: 0.776514 validation: 0.828420
09/16 10:22:41 AM: edges-srl-ontonotes_f1: training: 0.817807 validation: 0.861236
09/16 10:22:41 AM: Global learning rate: 6.25e-06
09/16 10:22:41 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:22:50 AM: Update 45090: task edges-srl-ontonotes, batch 90 (45090): mcc: 0.8031, acc: 0.7338, precision: 0.8542, recall: 0.7603, f1: 0.8045, edges-srl-ontonotes_loss: 0.0154
09/16 10:23:01 AM: Update 45202: task edges-srl-ontonotes, batch 202 (45202): mcc: 0.7941, acc: 0.7218, precision: 0.8470, recall: 0.7500, f1: 0.7955, edges-srl-ontonotes_loss: 0.0161
09/16 10:23:11 AM: Update 45310: task edges-srl-ontonotes, batch 310 (45310): mcc: 0.7935, acc: 0.7200, precision: 0.8468, recall: 0.7490, f1: 0.7949, edges-srl-ontonotes_loss: 0.0163
09/16 10:23:21 AM: Update 45424: task edges-srl-ontonotes, batch 424 (45424): mcc: 0.7915, acc: 0.7180, precision: 0.8453, recall: 0.7467, f1: 0.7930, edges-srl-ontonotes_loss: 0.0165
09/16 10:23:31 AM: Update 45557: task edges-srl-ontonotes, batch 557 (45557): mcc: 0.7907, acc: 0.7173, precision: 0.8448, recall: 0.7456, f1: 0.7921, edges-srl-ontonotes_loss: 0.0165
09/16 10:23:41 AM: Update 45678: task edges-srl-ontonotes, batch 678 (45678): mcc: 0.7927, acc: 0.7198, precision: 0.8463, recall: 0.7480, f1: 0.7941, edges-srl-ontonotes_loss: 0.0164
09/16 10:23:51 AM: Update 45799: task edges-srl-ontonotes, batch 799 (45799): mcc: 0.7974, acc: 0.7255, precision: 0.8499, recall: 0.7535, f1: 0.7988, edges-srl-ontonotes_loss: 0.0161
09/16 10:24:01 AM: Update 45922: task edges-srl-ontonotes, batch 922 (45922): mcc: 0.8008, acc: 0.7299, precision: 0.8528, recall: 0.7573, f1: 0.8022, edges-srl-ontonotes_loss: 0.0158
09/16 10:24:10 AM: ***** Step 46000 / Validation 46 *****
09/16 10:24:10 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:24:10 AM: Validating...
09/16 10:24:11 AM: Evaluate: task edges-srl-ontonotes, batch 11 (157): mcc: 0.8557, acc: 0.8132, precision: 0.8914, recall: 0.8254, f1: 0.8571, edges-srl-ontonotes_loss: 0.0112
09/16 10:24:21 AM: Evaluate: task edges-srl-ontonotes, batch 150 (157): mcc: 0.8610, acc: 0.8175, precision: 0.8971, recall: 0.8303, f1: 0.8624, edges-srl-ontonotes_loss: 0.0115
09/16 10:24:21 AM: Updating LR scheduler:
09/16 10:24:21 AM: 	Best result seen so far for macro_avg: 0.862
09/16 10:24:21 AM: 	# validation passes without improvement: 2
09/16 10:24:21 AM: edges-srl-ontonotes_loss: training: 0.015690 validation: 0.011654
09/16 10:24:21 AM: macro_avg: validation: 0.861083
09/16 10:24:21 AM: micro_avg: validation: 0.000000
09/16 10:24:21 AM: edges-srl-ontonotes_mcc: training: 0.802458 validation: 0.859692
09/16 10:24:21 AM: edges-srl-ontonotes_acc: training: 0.731812 validation: 0.815950
09/16 10:24:21 AM: edges-srl-ontonotes_precision: training: 0.854058 validation: 0.895709
09/16 10:24:21 AM: edges-srl-ontonotes_recall: training: 0.759250 validation: 0.829035
09/16 10:24:21 AM: edges-srl-ontonotes_f1: training: 0.803868 validation: 0.861083
09/16 10:24:21 AM: Global learning rate: 6.25e-06
09/16 10:24:21 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:24:31 AM: Update 46131: task edges-srl-ontonotes, batch 131 (46131): mcc: 0.8217, acc: 0.7558, precision: 0.8671, recall: 0.7834, f1: 0.8231, edges-srl-ontonotes_loss: 0.0145
09/16 10:24:41 AM: Update 46255: task edges-srl-ontonotes, batch 255 (46255): mcc: 0.8229, acc: 0.7585, precision: 0.8700, recall: 0.7831, f1: 0.8243, edges-srl-ontonotes_loss: 0.0143
09/16 10:24:51 AM: Update 46371: task edges-srl-ontonotes, batch 371 (46371): mcc: 0.8232, acc: 0.7587, precision: 0.8704, recall: 0.7832, f1: 0.8245, edges-srl-ontonotes_loss: 0.0142
09/16 10:25:01 AM: Update 46507: task edges-srl-ontonotes, batch 507 (46507): mcc: 0.8247, acc: 0.7603, precision: 0.8718, recall: 0.7850, f1: 0.8261, edges-srl-ontonotes_loss: 0.0142
09/16 10:25:11 AM: Update 46629: task edges-srl-ontonotes, batch 629 (46629): mcc: 0.8261, acc: 0.7617, precision: 0.8732, recall: 0.7862, f1: 0.8274, edges-srl-ontonotes_loss: 0.0141
09/16 10:25:21 AM: Update 46756: task edges-srl-ontonotes, batch 756 (46756): mcc: 0.8237, acc: 0.7591, precision: 0.8712, recall: 0.7836, f1: 0.8251, edges-srl-ontonotes_loss: 0.0143
09/16 10:25:31 AM: Update 46879: task edges-srl-ontonotes, batch 879 (46879): mcc: 0.8215, acc: 0.7562, precision: 0.8694, recall: 0.7810, f1: 0.8229, edges-srl-ontonotes_loss: 0.0144
09/16 10:25:41 AM: Update 46994: task edges-srl-ontonotes, batch 994 (46994): mcc: 0.8199, acc: 0.7543, precision: 0.8681, recall: 0.7793, f1: 0.8213, edges-srl-ontonotes_loss: 0.0146
09/16 10:25:42 AM: ***** Step 47000 / Validation 47 *****
09/16 10:25:42 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:25:42 AM: Validating...
09/16 10:25:51 AM: Evaluate: task edges-srl-ontonotes, batch 129 (157): mcc: 0.8615, acc: 0.8181, precision: 0.8977, recall: 0.8306, f1: 0.8629, edges-srl-ontonotes_loss: 0.0114
09/16 10:25:53 AM: Updating LR scheduler:
09/16 10:25:53 AM: 	Best result seen so far for macro_avg: 0.862
09/16 10:25:53 AM: 	# validation passes without improvement: 3
09/16 10:25:53 AM: edges-srl-ontonotes_loss: training: 0.014564 validation: 0.011678
09/16 10:25:53 AM: macro_avg: validation: 0.860230
09/16 10:25:53 AM: micro_avg: validation: 0.000000
09/16 10:25:53 AM: edges-srl-ontonotes_mcc: training: 0.819891 validation: 0.858862
09/16 10:25:53 AM: edges-srl-ontonotes_acc: training: 0.754243 validation: 0.814641
09/16 10:25:53 AM: edges-srl-ontonotes_precision: training: 0.868087 validation: 0.895750
09/16 10:25:53 AM: edges-srl-ontonotes_recall: training: 0.779230 validation: 0.827419
09/16 10:25:53 AM: edges-srl-ontonotes_f1: training: 0.821262 validation: 0.860230
09/16 10:25:53 AM: Global learning rate: 6.25e-06
09/16 10:25:53 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:26:01 AM: Update 47110: task edges-srl-ontonotes, batch 110 (47110): mcc: 0.8036, acc: 0.7358, precision: 0.8571, recall: 0.7586, f1: 0.8049, edges-srl-ontonotes_loss: 0.0156
09/16 10:26:13 AM: Update 47233: task edges-srl-ontonotes, batch 233 (47233): mcc: 0.8101, acc: 0.7418, precision: 0.8631, recall: 0.7655, f1: 0.8114, edges-srl-ontonotes_loss: 0.0153
09/16 10:26:23 AM: Update 47354: task edges-srl-ontonotes, batch 354 (47354): mcc: 0.8102, acc: 0.7417, precision: 0.8629, recall: 0.7659, f1: 0.8115, edges-srl-ontonotes_loss: 0.0153
09/16 10:26:33 AM: Update 47490: task edges-srl-ontonotes, batch 490 (47490): mcc: 0.8086, acc: 0.7396, precision: 0.8612, recall: 0.7644, f1: 0.8099, edges-srl-ontonotes_loss: 0.0153
09/16 10:26:43 AM: Update 47608: task edges-srl-ontonotes, batch 608 (47608): mcc: 0.8093, acc: 0.7406, precision: 0.8610, recall: 0.7659, f1: 0.8107, edges-srl-ontonotes_loss: 0.0153
09/16 10:26:53 AM: Update 47740: task edges-srl-ontonotes, batch 740 (47740): mcc: 0.8110, acc: 0.7429, precision: 0.8621, recall: 0.7680, f1: 0.8123, edges-srl-ontonotes_loss: 0.0152
09/16 10:27:03 AM: Update 47863: task edges-srl-ontonotes, batch 863 (47863): mcc: 0.8122, acc: 0.7446, precision: 0.8630, recall: 0.7694, f1: 0.8135, edges-srl-ontonotes_loss: 0.0151
09/16 10:27:13 AM: ***** Step 48000 / Validation 48 *****
09/16 10:27:13 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:27:13 AM: Validating...
09/16 10:27:13 AM: Evaluate: task edges-srl-ontonotes, batch 1 (157): mcc: 0.8772, acc: 0.8427, precision: 0.9048, recall: 0.8539, f1: 0.8786, edges-srl-ontonotes_loss: 0.0101
09/16 10:27:23 AM: Evaluate: task edges-srl-ontonotes, batch 137 (157): mcc: 0.8601, acc: 0.8174, precision: 0.8970, recall: 0.8286, f1: 0.8614, edges-srl-ontonotes_loss: 0.0115
09/16 10:27:25 AM: Updating LR scheduler:
09/16 10:27:25 AM: 	Best result seen so far for macro_avg: 0.862
09/16 10:27:25 AM: 	# validation passes without improvement: 0
09/16 10:27:25 AM: edges-srl-ontonotes_loss: training: 0.014986 validation: 0.011731
09/16 10:27:25 AM: macro_avg: validation: 0.859076
09/16 10:27:25 AM: micro_avg: validation: 0.000000
09/16 10:27:25 AM: edges-srl-ontonotes_mcc: training: 0.813707 validation: 0.857710
09/16 10:27:25 AM: edges-srl-ontonotes_acc: training: 0.746641 validation: 0.814102
09/16 10:27:25 AM: edges-srl-ontonotes_precision: training: 0.864078 validation: 0.895053
09/16 10:27:25 AM: edges-srl-ontonotes_recall: training: 0.771267 validation: 0.825879
09/16 10:27:25 AM: edges-srl-ontonotes_f1: training: 0.815039 validation: 0.859076
09/16 10:27:25 AM: Global learning rate: 3.125e-06
09/16 10:27:25 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:27:34 AM: Update 48119: task edges-srl-ontonotes, batch 119 (48119): mcc: 0.8225, acc: 0.7593, precision: 0.8720, recall: 0.7806, f1: 0.8238, edges-srl-ontonotes_loss: 0.0145
09/16 10:27:44 AM: Update 48212: task edges-srl-ontonotes, batch 212 (48212): mcc: 0.8183, acc: 0.7527, precision: 0.8684, recall: 0.7759, f1: 0.8196, edges-srl-ontonotes_loss: 0.0148
09/16 10:27:54 AM: Update 48331: task edges-srl-ontonotes, batch 331 (48331): mcc: 0.8076, acc: 0.7386, precision: 0.8620, recall: 0.7617, f1: 0.8087, edges-srl-ontonotes_loss: 0.0156
09/16 10:28:04 AM: Update 48449: task edges-srl-ontonotes, batch 449 (48449): mcc: 0.8060, acc: 0.7360, precision: 0.8617, recall: 0.7591, f1: 0.8072, edges-srl-ontonotes_loss: 0.0157
09/16 10:28:14 AM: Update 48578: task edges-srl-ontonotes, batch 578 (48578): mcc: 0.8098, acc: 0.7407, precision: 0.8629, recall: 0.7650, f1: 0.8110, edges-srl-ontonotes_loss: 0.0154
09/16 10:28:24 AM: Update 48721: task edges-srl-ontonotes, batch 721 (48721): mcc: 0.8159, acc: 0.7484, precision: 0.8669, recall: 0.7729, f1: 0.8172, edges-srl-ontonotes_loss: 0.0150
09/16 10:28:34 AM: Update 48853: task edges-srl-ontonotes, batch 853 (48853): mcc: 0.8203, acc: 0.7538, precision: 0.8694, recall: 0.7787, f1: 0.8216, edges-srl-ontonotes_loss: 0.0147
09/16 10:28:44 AM: Update 48995: task edges-srl-ontonotes, batch 995 (48995): mcc: 0.8260, acc: 0.7611, precision: 0.8731, recall: 0.7860, f1: 0.8273, edges-srl-ontonotes_loss: 0.0142
09/16 10:28:44 AM: ***** Step 49000 / Validation 49 *****
09/16 10:28:44 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:28:44 AM: Validating...
09/16 10:28:54 AM: Evaluate: task edges-srl-ontonotes, batch 128 (157): mcc: 0.8604, acc: 0.8151, precision: 0.8985, recall: 0.8278, f1: 0.8617, edges-srl-ontonotes_loss: 0.0115
09/16 10:28:56 AM: Updating LR scheduler:
09/16 10:28:56 AM: 	Best result seen so far for macro_avg: 0.862
09/16 10:28:56 AM: 	# validation passes without improvement: 1
09/16 10:28:56 AM: edges-srl-ontonotes_loss: training: 0.014209 validation: 0.011727
09/16 10:28:56 AM: macro_avg: validation: 0.859206
09/16 10:28:56 AM: micro_avg: validation: 0.000000
09/16 10:28:56 AM: edges-srl-ontonotes_mcc: training: 0.826203 validation: 0.857919
09/16 10:28:56 AM: edges-srl-ontonotes_acc: training: 0.761358 validation: 0.811793
09/16 10:28:56 AM: edges-srl-ontonotes_precision: training: 0.873324 validation: 0.897060
09/16 10:28:56 AM: edges-srl-ontonotes_recall: training: 0.786328 validation: 0.824417
09/16 10:28:56 AM: edges-srl-ontonotes_f1: training: 0.827546 validation: 0.859206
09/16 10:28:56 AM: Global learning rate: 3.125e-06
09/16 10:28:56 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:29:04 AM: Update 49126: task edges-srl-ontonotes, batch 126 (49126): mcc: 0.8669, acc: 0.8095, precision: 0.9024, recall: 0.8364, f1: 0.8682, edges-srl-ontonotes_loss: 0.0113
09/16 10:29:14 AM: Update 49289: task edges-srl-ontonotes, batch 289 (49289): mcc: 0.8636, acc: 0.8080, precision: 0.9012, recall: 0.8313, f1: 0.8649, edges-srl-ontonotes_loss: 0.0116
09/16 10:29:25 AM: Update 49424: task edges-srl-ontonotes, batch 424 (49424): mcc: 0.8616, acc: 0.8056, precision: 0.8989, recall: 0.8298, f1: 0.8629, edges-srl-ontonotes_loss: 0.0117
09/16 10:29:35 AM: Update 49595: task edges-srl-ontonotes, batch 595 (49595): mcc: 0.8605, acc: 0.8042, precision: 0.8980, recall: 0.8283, f1: 0.8618, edges-srl-ontonotes_loss: 0.0118
09/16 10:29:45 AM: Update 49737: task edges-srl-ontonotes, batch 737 (49737): mcc: 0.8605, acc: 0.8039, precision: 0.8974, recall: 0.8291, f1: 0.8619, edges-srl-ontonotes_loss: 0.0117
09/16 10:29:55 AM: Update 49916: task edges-srl-ontonotes, batch 916 (49916): mcc: 0.8604, acc: 0.8041, precision: 0.8969, recall: 0.8293, f1: 0.8618, edges-srl-ontonotes_loss: 0.0118
09/16 10:30:00 AM: ***** Step 50000 / Validation 50 *****
09/16 10:30:00 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:30:00 AM: Validating...
09/16 10:30:05 AM: Evaluate: task edges-srl-ontonotes, batch 74 (157): mcc: 0.8510, acc: 0.8024, precision: 0.8944, recall: 0.8138, f1: 0.8522, edges-srl-ontonotes_loss: 0.0122
09/16 10:30:11 AM: Updating LR scheduler:
09/16 10:30:11 AM: 	Best result seen so far for macro_avg: 0.862
09/16 10:30:11 AM: 	# validation passes without improvement: 2
09/16 10:30:11 AM: edges-srl-ontonotes_loss: training: 0.011758 validation: 0.011717
09/16 10:30:11 AM: macro_avg: validation: 0.860192
09/16 10:30:11 AM: micro_avg: validation: 0.000000
09/16 10:30:11 AM: edges-srl-ontonotes_mcc: training: 0.861041 validation: 0.858926
09/16 10:30:11 AM: edges-srl-ontonotes_acc: training: 0.804854 validation: 0.812486
09/16 10:30:11 AM: edges-srl-ontonotes_precision: training: 0.897080 validation: 0.898207
09/16 10:30:11 AM: edges-srl-ontonotes_recall: training: 0.830324 validation: 0.825264
09/16 10:30:11 AM: edges-srl-ontonotes_f1: training: 0.862412 validation: 0.860192
09/16 10:30:11 AM: Global learning rate: 3.125e-06
09/16 10:30:11 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:30:15 AM: Update 50051: task edges-srl-ontonotes, batch 51 (50051): mcc: 0.8502, acc: 0.7933, precision: 0.8885, recall: 0.8177, f1: 0.8516, edges-srl-ontonotes_loss: 0.0124
09/16 10:30:25 AM: Update 50188: task edges-srl-ontonotes, batch 188 (50188): mcc: 0.8329, acc: 0.7710, precision: 0.8773, recall: 0.7954, f1: 0.8343, edges-srl-ontonotes_loss: 0.0136
09/16 10:30:35 AM: Update 50328: task edges-srl-ontonotes, batch 328 (50328): mcc: 0.8337, acc: 0.7707, precision: 0.8778, recall: 0.7962, f1: 0.8351, edges-srl-ontonotes_loss: 0.0137
09/16 10:30:45 AM: Update 50418: task edges-srl-ontonotes, batch 418 (50418): mcc: 0.8294, acc: 0.7652, precision: 0.8743, recall: 0.7915, f1: 0.8308, edges-srl-ontonotes_loss: 0.0140
09/16 10:30:55 AM: Update 50544: task edges-srl-ontonotes, batch 544 (50544): mcc: 0.8244, acc: 0.7593, precision: 0.8708, recall: 0.7851, f1: 0.8258, edges-srl-ontonotes_loss: 0.0144
09/16 10:31:05 AM: Update 50683: task edges-srl-ontonotes, batch 683 (50683): mcc: 0.8227, acc: 0.7567, precision: 0.8700, recall: 0.7829, f1: 0.8241, edges-srl-ontonotes_loss: 0.0146
09/16 10:31:15 AM: Update 50818: task edges-srl-ontonotes, batch 818 (50818): mcc: 0.8229, acc: 0.7567, precision: 0.8700, recall: 0.7831, f1: 0.8242, edges-srl-ontonotes_loss: 0.0145
09/16 10:31:25 AM: Update 50974: task edges-srl-ontonotes, batch 974 (50974): mcc: 0.8252, acc: 0.7594, precision: 0.8718, recall: 0.7859, f1: 0.8266, edges-srl-ontonotes_loss: 0.0143
09/16 10:31:27 AM: ***** Step 51000 / Validation 51 *****
09/16 10:31:27 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:31:27 AM: Validating...
09/16 10:31:35 AM: Evaluate: task edges-srl-ontonotes, batch 113 (157): mcc: 0.8587, acc: 0.8146, precision: 0.8957, recall: 0.8272, f1: 0.8601, edges-srl-ontonotes_loss: 0.0116
09/16 10:31:39 AM: Updating LR scheduler:
09/16 10:31:39 AM: 	Best result seen so far for macro_avg: 0.862
09/16 10:31:39 AM: 	# validation passes without improvement: 3
09/16 10:31:39 AM: edges-srl-ontonotes_loss: training: 0.014324 validation: 0.011644
09/16 10:31:39 AM: macro_avg: validation: 0.861210
09/16 10:31:39 AM: micro_avg: validation: 0.000000
09/16 10:31:39 AM: edges-srl-ontonotes_mcc: training: 0.825272 validation: 0.859829
09/16 10:31:39 AM: edges-srl-ontonotes_acc: training: 0.759403 validation: 0.816257
09/16 10:31:39 AM: edges-srl-ontonotes_precision: training: 0.871673 validation: 0.896073
09/16 10:31:39 AM: edges-srl-ontonotes_recall: training: 0.786078 validation: 0.828959
09/16 10:31:39 AM: edges-srl-ontonotes_f1: training: 0.826666 validation: 0.861210
09/16 10:31:39 AM: Global learning rate: 3.125e-06
09/16 10:31:39 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:31:45 AM: Update 51088: task edges-srl-ontonotes, batch 88 (51088): mcc: 0.8266, acc: 0.7557, precision: 0.8740, recall: 0.7865, f1: 0.8280, edges-srl-ontonotes_loss: 0.0141
09/16 10:31:55 AM: Update 51244: task edges-srl-ontonotes, batch 244 (51244): mcc: 0.8311, acc: 0.7658, precision: 0.8755, recall: 0.7936, f1: 0.8326, edges-srl-ontonotes_loss: 0.0137
09/16 10:32:06 AM: Update 51353: task edges-srl-ontonotes, batch 353 (51353): mcc: 0.8324, acc: 0.7678, precision: 0.8761, recall: 0.7956, f1: 0.8339, edges-srl-ontonotes_loss: 0.0136
09/16 10:32:16 AM: Update 51500: task edges-srl-ontonotes, batch 500 (51500): mcc: 0.8304, acc: 0.7653, precision: 0.8743, recall: 0.7933, f1: 0.8319, edges-srl-ontonotes_loss: 0.0138
09/16 10:32:26 AM: Update 51632: task edges-srl-ontonotes, batch 632 (51632): mcc: 0.8286, acc: 0.7634, precision: 0.8737, recall: 0.7905, f1: 0.8300, edges-srl-ontonotes_loss: 0.0139
09/16 10:32:36 AM: Update 51748: task edges-srl-ontonotes, batch 748 (51748): mcc: 0.8269, acc: 0.7614, precision: 0.8723, recall: 0.7885, f1: 0.8283, edges-srl-ontonotes_loss: 0.0141
09/16 10:32:46 AM: Update 51876: task edges-srl-ontonotes, batch 876 (51876): mcc: 0.8235, acc: 0.7567, precision: 0.8704, recall: 0.7840, f1: 0.8249, edges-srl-ontonotes_loss: 0.0143
09/16 10:32:56 AM: ***** Step 52000 / Validation 52 *****
09/16 10:32:56 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:32:56 AM: Validating...
09/16 10:32:56 AM: Evaluate: task edges-srl-ontonotes, batch 4 (157): mcc: 0.8867, acc: 0.8543, precision: 0.9177, recall: 0.8600, f1: 0.8879, edges-srl-ontonotes_loss: 0.0096
09/16 10:33:06 AM: Evaluate: task edges-srl-ontonotes, batch 140 (157): mcc: 0.8617, acc: 0.8187, precision: 0.8972, recall: 0.8315, f1: 0.8631, edges-srl-ontonotes_loss: 0.0114
09/16 10:33:07 AM: Updating LR scheduler:
09/16 10:33:07 AM: 	Best result seen so far for macro_avg: 0.862
09/16 10:33:07 AM: 	# validation passes without improvement: 0
09/16 10:33:07 AM: edges-srl-ontonotes_loss: training: 0.014450 validation: 0.011613
09/16 10:33:07 AM: macro_avg: validation: 0.861233
09/16 10:33:07 AM: micro_avg: validation: 0.000000
09/16 10:33:07 AM: edges-srl-ontonotes_mcc: training: 0.821552 validation: 0.859858
09/16 10:33:07 AM: edges-srl-ontonotes_acc: training: 0.754456 validation: 0.815950
09/16 10:33:07 AM: edges-srl-ontonotes_precision: training: 0.868654 validation: 0.896213
09/16 10:33:07 AM: edges-srl-ontonotes_recall: training: 0.781832 validation: 0.828882
09/16 10:33:07 AM: edges-srl-ontonotes_f1: training: 0.822959 validation: 0.861233
09/16 10:33:07 AM: Global learning rate: 1.5625e-06
09/16 10:33:07 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:33:16 AM: Update 52120: task edges-srl-ontonotes, batch 120 (52120): mcc: 0.8122, acc: 0.7421, precision: 0.8604, recall: 0.7717, f1: 0.8137, edges-srl-ontonotes_loss: 0.0149
09/16 10:33:26 AM: Update 52255: task edges-srl-ontonotes, batch 255 (52255): mcc: 0.8088, acc: 0.7383, precision: 0.8587, recall: 0.7669, f1: 0.8102, edges-srl-ontonotes_loss: 0.0151
09/16 10:33:36 AM: Update 52384: task edges-srl-ontonotes, batch 384 (52384): mcc: 0.8062, acc: 0.7351, precision: 0.8575, recall: 0.7631, f1: 0.8075, edges-srl-ontonotes_loss: 0.0155
09/16 10:33:46 AM: Update 52522: task edges-srl-ontonotes, batch 522 (52522): mcc: 0.8014, acc: 0.7297, precision: 0.8534, recall: 0.7578, f1: 0.8028, edges-srl-ontonotes_loss: 0.0158
09/16 10:33:56 AM: Update 52620: task edges-srl-ontonotes, batch 620 (52620): mcc: 0.8012, acc: 0.7294, precision: 0.8535, recall: 0.7573, f1: 0.8025, edges-srl-ontonotes_loss: 0.0159
09/16 10:34:06 AM: Update 52763: task edges-srl-ontonotes, batch 763 (52763): mcc: 0.7999, acc: 0.7281, precision: 0.8523, recall: 0.7561, f1: 0.8013, edges-srl-ontonotes_loss: 0.0160
09/16 10:34:16 AM: Update 52900: task edges-srl-ontonotes, batch 900 (52900): mcc: 0.7985, acc: 0.7263, precision: 0.8508, recall: 0.7548, f1: 0.7999, edges-srl-ontonotes_loss: 0.0161
09/16 10:34:24 AM: ***** Step 53000 / Validation 53 *****
09/16 10:34:24 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:34:24 AM: Validating...
09/16 10:34:26 AM: Evaluate: task edges-srl-ontonotes, batch 27 (157): mcc: 0.8542, acc: 0.8071, precision: 0.8988, recall: 0.8158, f1: 0.8553, edges-srl-ontonotes_loss: 0.0121
09/16 10:34:35 AM: Updating LR scheduler:
09/16 10:34:35 AM: 	Best result seen so far for macro_avg: 0.862
09/16 10:34:35 AM: 	# validation passes without improvement: 1
09/16 10:34:35 AM: edges-srl-ontonotes_loss: training: 0.015877 validation: 0.011618
09/16 10:34:35 AM: macro_avg: validation: 0.861510
09/16 10:34:35 AM: micro_avg: validation: 0.000000
09/16 10:34:35 AM: edges-srl-ontonotes_mcc: training: 0.800964 validation: 0.860162
09/16 10:34:35 AM: edges-srl-ontonotes_acc: training: 0.729568 validation: 0.815488
09/16 10:34:35 AM: edges-srl-ontonotes_precision: training: 0.852476 validation: 0.897083
09/16 10:34:35 AM: edges-srl-ontonotes_recall: training: 0.757879 validation: 0.828651
09/16 10:34:35 AM: edges-srl-ontonotes_f1: training: 0.802399 validation: 0.861510
09/16 10:34:35 AM: Global learning rate: 1.5625e-06
09/16 10:34:35 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:34:36 AM: Update 53010: task edges-srl-ontonotes, batch 10 (53010): mcc: 0.8242, acc: 0.7646, precision: 0.8642, recall: 0.7909, f1: 0.8260, edges-srl-ontonotes_loss: 0.0143
09/16 10:34:46 AM: Update 53145: task edges-srl-ontonotes, batch 145 (53145): mcc: 0.8228, acc: 0.7548, precision: 0.8729, recall: 0.7803, f1: 0.8240, edges-srl-ontonotes_loss: 0.0143
09/16 10:34:56 AM: Update 53266: task edges-srl-ontonotes, batch 266 (53266): mcc: 0.8212, acc: 0.7544, precision: 0.8690, recall: 0.7809, f1: 0.8226, edges-srl-ontonotes_loss: 0.0143
09/16 10:35:06 AM: Update 53410: task edges-srl-ontonotes, batch 410 (53410): mcc: 0.8216, acc: 0.7558, precision: 0.8693, recall: 0.7813, f1: 0.8229, edges-srl-ontonotes_loss: 0.0143
09/16 10:35:19 AM: Update 53540: task edges-srl-ontonotes, batch 540 (53540): mcc: 0.8215, acc: 0.7561, precision: 0.8693, recall: 0.7812, f1: 0.8229, edges-srl-ontonotes_loss: 0.0143
09/16 10:35:29 AM: Update 53678: task edges-srl-ontonotes, batch 678 (53678): mcc: 0.8230, acc: 0.7583, precision: 0.8699, recall: 0.7834, f1: 0.8244, edges-srl-ontonotes_loss: 0.0142
09/16 10:35:39 AM: Update 53813: task edges-srl-ontonotes, batch 813 (53813): mcc: 0.8241, acc: 0.7595, precision: 0.8713, recall: 0.7842, f1: 0.8255, edges-srl-ontonotes_loss: 0.0142
09/16 10:35:49 AM: Update 53930: task edges-srl-ontonotes, batch 930 (53930): mcc: 0.8230, acc: 0.7582, precision: 0.8701, recall: 0.7833, f1: 0.8244, edges-srl-ontonotes_loss: 0.0143
09/16 10:35:55 AM: ***** Step 54000 / Validation 54 *****
09/16 10:35:55 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:35:55 AM: Validating...
09/16 10:36:00 AM: Evaluate: task edges-srl-ontonotes, batch 70 (157): mcc: 0.8512, acc: 0.8056, precision: 0.8918, recall: 0.8165, f1: 0.8525, edges-srl-ontonotes_loss: 0.0121
09/16 10:36:06 AM: Updating LR scheduler:
09/16 10:36:06 AM: 	Best result seen so far for macro_avg: 0.862
09/16 10:36:06 AM: 	# validation passes without improvement: 2
09/16 10:36:06 AM: Ran out of early stopping patience. Stopping training.
09/16 10:36:06 AM: edges-srl-ontonotes_loss: training: 0.014342 validation: 0.011628
09/16 10:36:06 AM: macro_avg: validation: 0.861783
09/16 10:36:06 AM: micro_avg: validation: 0.000000
09/16 10:36:06 AM: edges-srl-ontonotes_mcc: training: 0.822232 validation: 0.860430
09/16 10:36:06 AM: edges-srl-ontonotes_acc: training: 0.757307 validation: 0.816257
09/16 10:36:06 AM: edges-srl-ontonotes_precision: training: 0.869301 validation: 0.897135
09/16 10:36:06 AM: edges-srl-ontonotes_recall: training: 0.782523 validation: 0.829112
09/16 10:36:06 AM: edges-srl-ontonotes_f1: training: 0.823632 validation: 0.861783
09/16 10:36:06 AM: Global learning rate: 1.5625e-06
09/16 10:36:06 AM: Saving checkpoints to: ./experiments/srl-ontonotes-rte-top/run
09/16 10:36:06 AM: Stopped training after 54 validation checks
09/16 10:36:06 AM: Trained edges-srl-ontonotes for 54000 batches or 7.465 epochs
09/16 10:36:06 AM: ***** VALIDATION RESULTS *****
09/16 10:36:06 AM: edges-srl-ontonotes_f1 (for best val pass 44): edges-srl-ontonotes_loss: 0.01163, macro_avg: 0.86213, micro_avg: 0.00000, edges-srl-ontonotes_mcc: 0.86076, edges-srl-ontonotes_acc: 0.81718, edges-srl-ontonotes_precision: 0.89672, edges-srl-ontonotes_recall: 0.83011, edges-srl-ontonotes_f1: 0.86213
09/16 10:36:06 AM: micro_avg (for best val pass 1): edges-srl-ontonotes_loss: 0.02576, macro_avg: 0.69121, micro_avg: 0.00000, edges-srl-ontonotes_mcc: 0.70243, edges-srl-ontonotes_acc: 0.56316, edges-srl-ontonotes_precision: 0.86730, edges-srl-ontonotes_recall: 0.57455, edges-srl-ontonotes_f1: 0.69121
09/16 10:36:06 AM: macro_avg (for best val pass 44): edges-srl-ontonotes_loss: 0.01163, macro_avg: 0.86213, micro_avg: 0.00000, edges-srl-ontonotes_mcc: 0.86076, edges-srl-ontonotes_acc: 0.81718, edges-srl-ontonotes_precision: 0.89672, edges-srl-ontonotes_recall: 0.83011, edges-srl-ontonotes_f1: 0.86213
09/16 10:36:06 AM: Evaluating...
09/16 10:36:06 AM: Loaded model state from ./experiments/srl-ontonotes-rte-top/run/edges-srl-ontonotes/model_state_target_train_val_44.best.th
09/16 10:36:06 AM: Evaluating on: edges-srl-ontonotes, split: val
09/16 10:36:36 AM: 	Task edges-srl-ontonotes: batch 368
09/16 10:37:06 AM: 	Task edges-srl-ontonotes: batch 714
09/16 10:37:31 AM: Task 'edges-srl-ontonotes': sorting predictions by 'idx'
09/16 10:37:31 AM: Finished evaluating on: edges-srl-ontonotes
09/16 10:37:33 AM: Task 'edges-srl-ontonotes': joining predictions with input split 'val'
09/16 10:37:38 AM: Task 'edges-srl-ontonotes': Wrote predictions to ./experiments/srl-ontonotes-rte-top/run
09/16 10:37:38 AM: Wrote all preds for split 'val' to ./experiments/srl-ontonotes-rte-top/run
09/16 10:37:38 AM: Evaluating on: edges-srl-ontonotes, split: test
09/16 10:38:08 AM: 	Task edges-srl-ontonotes: batch 363
09/16 10:38:38 AM: 	Task edges-srl-ontonotes: batch 735
09/16 10:38:39 AM: Task 'edges-srl-ontonotes': sorting predictions by 'idx'
09/16 10:38:39 AM: Finished evaluating on: edges-srl-ontonotes
09/16 10:38:39 AM: Task 'edges-srl-ontonotes': joining predictions with input split 'test'
09/16 10:38:42 AM: Task 'edges-srl-ontonotes': Wrote predictions to ./experiments/srl-ontonotes-rte-top/run
09/16 10:38:42 AM: Wrote all preds for split 'test' to ./experiments/srl-ontonotes-rte-top/run
09/16 10:38:42 AM: Writing results for split 'val' to ./experiments/srl-ontonotes-rte-top/results.tsv
09/16 10:38:42 AM: micro_avg: 0.000, macro_avg: 0.861, edges-srl-ontonotes_mcc: 0.859, edges-srl-ontonotes_acc: 0.815, edges-srl-ontonotes_precision: 0.897, edges-srl-ontonotes_recall: 0.827, edges-srl-ontonotes_f1: 0.861
09/16 10:38:42 AM: Done!
09/16 10:38:42 AM: Fatal error in main():
Traceback (most recent call last):
  File "main.py", line 16, in <module>
    main(sys.argv[1:])
  File "/srv/home/ericwallace/jiant/jiant/__main__.py", line 610, in main
    exit("Done exited")
  File "/home/ericwallace/miniconda3/envs/jiant/lib/python3.6/_sitebuiltins.py", line 26, in __call__
    raise SystemExit(code)
SystemExit: Done exited
