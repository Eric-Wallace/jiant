09/17 12:19:09 AM: Git branch: master
09/17 12:19:09 AM: Git SHA: 4086cd8f278243816795989a620c769378a6ab56
09/17 12:19:10 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/",
  "exp_name": "experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/RANDOM_WITH_GOOD_EMBEDDINGS",
  "pytorch_transformers_output_mode": "only",
  "remote_log_name": "experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only__run",
  "run_dir": "./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-pos-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/17 12:19:10 AM: Saved config to ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run/params.conf
09/17 12:19:10 AM: Using random seed 1234
09/17 12:19:10 AM: Using GPU 0
09/17 12:19:10 AM: Loading tasks...
09/17 12:19:10 AM: Writing pre-preprocessed tasks to ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/
09/17 12:19:10 AM: 	Creating task edges-pos-ontonotes from scratch.
09/17 12:19:30 AM: Read=110514, Skip=5298, Total=115812 from ./probing_data/edges/ontonotes/const/pos/train.json.retokenized.bert-base-uncased
09/17 12:19:31 AM: Read=15060, Skip=620, Total=15680 from ./probing_data/edges/ontonotes/const/pos/development.json.retokenized.bert-base-uncased
09/17 12:19:35 AM: Read=11462, Skip=755, Total=12217 from ./probing_data/edges/ontonotes/const/pos/test.json.retokenized.bert-base-uncased
09/17 12:19:49 AM: 	Task 'edges-pos-ontonotes': |train|=110514 |val|=15060 |test|=11462
09/17 12:19:49 AM: 	Finished loading tasks: edges-pos-ontonotes.
09/17 12:19:49 AM: 	Building vocab from scratch.
09/17 12:19:49 AM: 	Counting units for task edges-pos-ontonotes.
09/17 12:19:51 AM: 	Task 'edges-pos-ontonotes': adding vocab namespace 'edges-pos-ontonotes_labels'
09/17 12:19:52 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/17 12:19:52 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/17 12:19:52 AM: 	Saved vocab to ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/vocab
09/17 12:19:52 AM: Loading token dictionary from ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/vocab.
09/17 12:19:52 AM: 	Loaded vocab from ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/vocab
09/17 12:19:52 AM: 	Vocab namespace bert_uncased: size 30524
09/17 12:19:52 AM: 	Vocab namespace tokens: size 24015
09/17 12:19:52 AM: 	Vocab namespace edges-pos-ontonotes_labels: size 48
09/17 12:19:52 AM: 	Vocab namespace chars: size 81
09/17 12:19:52 AM: 	Finished building vocab.
09/17 12:19:52 AM: 	Task edges-pos-ontonotes (train): Indexing from scratch.
09/17 12:20:39 AM: 	Task edges-pos-ontonotes (train): Saved 110514 instances to ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/preproc/edges-pos-ontonotes__train_data
09/17 12:20:39 AM: 	Task edges-pos-ontonotes (val): Indexing from scratch.
09/17 12:20:43 AM: 	Task edges-pos-ontonotes (val): Saved 15060 instances to ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/preproc/edges-pos-ontonotes__val_data
09/17 12:20:43 AM: 	Task edges-pos-ontonotes (test): Indexing from scratch.
09/17 12:20:46 AM: 	Task edges-pos-ontonotes (test): Saved 11462 instances to ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/preproc/edges-pos-ontonotes__test_data
09/17 12:20:46 AM: 	Finished indexing tasks
09/17 12:20:46 AM: 	Creating trimmed target-only version of edges-pos-ontonotes train.
09/17 12:20:46 AM: 	  Training on 
09/17 12:20:46 AM: 	  Evaluating on edges-pos-ontonotes
09/17 12:20:46 AM: 	Finished loading tasks in 95.585s
09/17 12:20:46 AM: 	 Tasks: ['edges-pos-ontonotes']
09/17 12:20:46 AM: Building model...
09/17 12:20:46 AM: Using BERT model (bert-base-uncased).
09/17 12:20:46 AM: LOADING A RANDOMLY WEIGHTS BERT
09/17 12:20:48 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpmb0bsemx
09/17 12:20:50 AM: copying /tmp/tmpmb0bsemx to cache at ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/17 12:20:50 AM: creating metadata file for ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/17 12:20:50 AM: removing temp file /tmp/tmpmb0bsemx
09/17 12:20:50 AM: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/pytorch_transformers_cache/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.bf3b9ea126d8c0001ee8a1e8b92229871d06d36d8808208cc2449280da87785c
09/17 12:20:50 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/17 12:20:51 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpqvfuo65a
09/17 12:23:43 AM: copying /tmp/tmpqvfuo65a to cache at ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/17 12:23:44 AM: creating metadata file for ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/17 12:23:44 AM: removing temp file /tmp/tmpqvfuo65a
09/17 12:23:44 AM: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/pytorch_transformers_cache/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
09/17 12:23:48 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpljmramtz
09/17 12:23:53 AM: copying /tmp/tmpljmramtz to cache at ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/17 12:23:53 AM: creating metadata file for ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/17 12:23:53 AM: removing temp file /tmp/tmpljmramtz
09/17 12:23:53 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/17 12:23:53 AM: Initializing parameters
09/17 12:23:53 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/17 12:23:53 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/17 12:23:53 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/17 12:23:53 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/17 12:23:53 AM:    _text_field_embedder.model.pooler.dense.bias
09/17 12:23:53 AM:    _text_field_embedder.model.pooler.dense.weight
09/17 12:23:53 AM: 	Task 'edges-pos-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-pos-ontonotes"
}
09/17 12:23:57 AM: Model specification:
09/17 12:23:57 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-pos-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=48, bias=True)
    )
  )
)
09/17 12:23:57 AM: Model parameters:
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/17 12:23:57 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/17 12:23:57 AM: 	edges-pos-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/17 12:23:57 AM: 	edges-pos-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/17 12:23:57 AM: 	edges-pos-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 24576 with torch.Size([48, 512])
09/17 12:23:57 AM: 	edges-pos-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 48 with torch.Size([48])
09/17 12:23:57 AM: Total number of parameters: 109703728 (1.09704e+08)
09/17 12:23:57 AM: Number of trainable parameters: 221488 (221488)
09/17 12:23:57 AM: Finished building model in 191.396s
09/17 12:23:57 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-pos-ontonotes 

09/17 12:25:12 AM: patience = 9
09/17 12:25:12 AM: val_interval = 1000
09/17 12:25:12 AM: max_vals = 250
09/17 12:25:12 AM: cuda_device = 0
09/17 12:25:12 AM: grad_norm = 5.0
09/17 12:25:12 AM: grad_clipping = None
09/17 12:25:12 AM: lr_decay = 0.99
09/17 12:25:12 AM: min_lr = 1e-06
09/17 12:25:12 AM: keep_all_checkpoints = 0
09/17 12:25:12 AM: val_data_limit = 5000
09/17 12:25:12 AM: max_epochs = -1
09/17 12:25:12 AM: dec_val_scale = 250
09/17 12:25:12 AM: training_data_fraction = 1
09/17 12:25:12 AM: type = adam
09/17 12:25:12 AM: parameter_groups = None
09/17 12:25:12 AM: Number of trainable parameters: 221488
09/17 12:25:12 AM: infer_type_and_cast = True
09/17 12:25:12 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/17 12:25:12 AM: CURRENTLY DEFINED PARAMETERS: 
09/17 12:25:12 AM: lr = 0.0001
09/17 12:25:12 AM: amsgrad = True
09/17 12:25:12 AM: type = reduce_on_plateau
09/17 12:25:12 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/17 12:25:12 AM: CURRENTLY DEFINED PARAMETERS: 
09/17 12:25:12 AM: mode = max
09/17 12:25:12 AM: factor = 0.5
09/17 12:25:12 AM: patience = 3
09/17 12:25:12 AM: threshold = 0.0001
09/17 12:25:12 AM: threshold_mode = abs
09/17 12:25:12 AM: verbose = True
09/17 12:25:12 AM: type = adam
09/17 12:25:12 AM: parameter_groups = None
09/17 12:25:12 AM: Number of trainable parameters: 221488
09/17 12:25:12 AM: infer_type_and_cast = True
09/17 12:25:12 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/17 12:25:12 AM: CURRENTLY DEFINED PARAMETERS: 
09/17 12:25:12 AM: lr = 0.0001
09/17 12:25:12 AM: amsgrad = True
09/17 12:25:12 AM: type = reduce_on_plateau
09/17 12:25:12 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/17 12:25:12 AM: CURRENTLY DEFINED PARAMETERS: 
09/17 12:25:12 AM: mode = max
09/17 12:25:12 AM: factor = 0.5
09/17 12:25:12 AM: patience = 3
09/17 12:25:12 AM: threshold = 0.0001
09/17 12:25:12 AM: threshold_mode = abs
09/17 12:25:12 AM: verbose = True
09/17 12:25:12 AM: Starting training without restoring from a checkpoint.
09/17 12:25:12 AM: Training examples per task, before any subsampling: {'edges-pos-ontonotes': 110514}
09/17 12:25:12 AM: Beginning training with stopping criteria based on metric: edges-pos-ontonotes_f1
09/17 12:25:22 AM: Update 68: task edges-pos-ontonotes, batch 68 (68): mcc: 0.0814, acc: 0.1159, precision: 0.0369, recall: 0.6101, f1: 0.0695, edges-pos-ontonotes_loss: 0.5605
09/17 12:25:33 AM: Update 151: task edges-pos-ontonotes, batch 151 (151): mcc: 0.0868, acc: 0.1707, precision: 0.0418, recall: 0.5183, f1: 0.0774, edges-pos-ontonotes_loss: 0.4511
09/17 12:25:43 AM: Update 249: task edges-pos-ontonotes, batch 249 (249): mcc: 0.0971, acc: 0.2137, precision: 0.0475, recall: 0.4845, f1: 0.0866, edges-pos-ontonotes_loss: 0.3834
09/17 12:25:53 AM: Update 315: task edges-pos-ontonotes, batch 315 (315): mcc: 0.1071, acc: 0.2430, precision: 0.0522, recall: 0.4821, f1: 0.0941, edges-pos-ontonotes_loss: 0.3567
09/17 12:26:03 AM: Update 400: task edges-pos-ontonotes, batch 400 (400): mcc: 0.1174, acc: 0.2712, precision: 0.0569, recall: 0.4858, f1: 0.1018, edges-pos-ontonotes_loss: 0.3410
09/17 12:26:13 AM: Update 463: task edges-pos-ontonotes, batch 463 (463): mcc: 0.1241, acc: 0.2858, precision: 0.0602, recall: 0.4864, f1: 0.1072, edges-pos-ontonotes_loss: 0.3286
09/17 12:26:23 AM: Update 525: task edges-pos-ontonotes, batch 525 (525): mcc: 0.1310, acc: 0.2987, precision: 0.0640, recall: 0.4860, f1: 0.1131, edges-pos-ontonotes_loss: 0.3183
09/17 12:26:33 AM: Update 585: task edges-pos-ontonotes, batch 585 (585): mcc: 0.1373, acc: 0.3096, precision: 0.0675, recall: 0.4862, f1: 0.1186, edges-pos-ontonotes_loss: 0.3069
09/17 12:26:44 AM: Update 627: task edges-pos-ontonotes, batch 627 (627): mcc: 0.1411, acc: 0.3154, precision: 0.0698, recall: 0.4853, f1: 0.1220, edges-pos-ontonotes_loss: 0.2996
09/17 12:26:54 AM: Update 672: task edges-pos-ontonotes, batch 672 (672): mcc: 0.1448, acc: 0.3195, precision: 0.0724, recall: 0.4816, f1: 0.1259, edges-pos-ontonotes_loss: 0.2942
09/17 12:27:04 AM: Update 713: task edges-pos-ontonotes, batch 713 (713): mcc: 0.1489, acc: 0.3232, precision: 0.0754, recall: 0.4774, f1: 0.1302, edges-pos-ontonotes_loss: 0.2886
09/17 12:27:14 AM: Update 767: task edges-pos-ontonotes, batch 767 (767): mcc: 0.1531, acc: 0.3271, precision: 0.0785, recall: 0.4736, f1: 0.1347, edges-pos-ontonotes_loss: 0.2805
09/17 12:27:25 AM: Update 818: task edges-pos-ontonotes, batch 818 (818): mcc: 0.1579, acc: 0.3309, precision: 0.0822, recall: 0.4693, f1: 0.1399, edges-pos-ontonotes_loss: 0.2727
09/17 12:27:35 AM: Update 874: task edges-pos-ontonotes, batch 874 (874): mcc: 0.1627, acc: 0.3345, precision: 0.0860, recall: 0.4654, f1: 0.1452, edges-pos-ontonotes_loss: 0.2641
09/17 12:27:45 AM: Update 932: task edges-pos-ontonotes, batch 932 (932): mcc: 0.1691, acc: 0.3387, precision: 0.0914, recall: 0.4603, f1: 0.1525, edges-pos-ontonotes_loss: 0.2550
09/17 12:27:55 AM: Update 979: task edges-pos-ontonotes, batch 979 (979): mcc: 0.1736, acc: 0.3405, precision: 0.0955, recall: 0.4553, f1: 0.1579, edges-pos-ontonotes_loss: 0.2481
09/17 12:28:01 AM: ***** Step 1000 / Validation 1 *****
09/17 12:28:01 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 12:28:01 AM: Validating...
09/17 12:28:05 AM: Evaluate: task edges-pos-ontonotes, batch 23 (157): mcc: 0.5503, acc: 0.4040, precision: 0.7602, recall: 0.4078, f1: 0.5308, edges-pos-ontonotes_loss: 0.0943
09/17 12:28:15 AM: Evaluate: task edges-pos-ontonotes, batch 91 (157): mcc: 0.5829, acc: 0.4309, precision: 0.7995, recall: 0.4337, f1: 0.5623, edges-pos-ontonotes_loss: 0.0891
09/17 12:28:25 AM: Evaluate: task edges-pos-ontonotes, batch 128 (157): mcc: 0.5737, acc: 0.4219, precision: 0.7913, recall: 0.4248, f1: 0.5528, edges-pos-ontonotes_loss: 0.0899
09/17 12:28:33 AM: Best result seen so far for edges-pos-ontonotes.
09/17 12:28:33 AM: Best result seen so far for micro.
09/17 12:28:33 AM: Best result seen so far for macro.
09/17 12:28:33 AM: Updating LR scheduler:
09/17 12:28:33 AM: 	Best result seen so far for macro_avg: 0.542
09/17 12:28:33 AM: 	# validation passes without improvement: 0
09/17 12:28:33 AM: edges-pos-ontonotes_loss: training: 0.244944 validation: 0.090498
09/17 12:28:33 AM: macro_avg: validation: 0.541720
09/17 12:28:33 AM: micro_avg: validation: 0.000000
09/17 12:28:33 AM: edges-pos-ontonotes_mcc: training: 0.175668 validation: 0.563320
09/17 12:28:33 AM: edges-pos-ontonotes_acc: training: 0.341291 validation: 0.411061
09/17 12:28:33 AM: edges-pos-ontonotes_precision: training: 0.097427 validation: 0.783353
09/17 12:28:33 AM: edges-pos-ontonotes_recall: training: 0.453176 validation: 0.414013
09/17 12:28:33 AM: edges-pos-ontonotes_f1: training: 0.160375 validation: 0.541720
09/17 12:28:33 AM: Global learning rate: 0.0001
09/17 12:28:33 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 12:28:35 AM: Update 1007: task edges-pos-ontonotes, batch 7 (1007): mcc: 0.5013, acc: 0.3739, precision: 0.6774, recall: 0.3820, f1: 0.4886, edges-pos-ontonotes_loss: 0.0954
09/17 12:28:46 AM: Update 1048: task edges-pos-ontonotes, batch 48 (1048): mcc: 0.5053, acc: 0.3716, precision: 0.6943, recall: 0.3783, f1: 0.4898, edges-pos-ontonotes_loss: 0.0934
09/17 12:28:56 AM: Update 1084: task edges-pos-ontonotes, batch 84 (1084): mcc: 0.5254, acc: 0.3774, precision: 0.7383, recall: 0.3834, f1: 0.5047, edges-pos-ontonotes_loss: 0.0901
09/17 12:29:06 AM: Update 1127: task edges-pos-ontonotes, batch 127 (1127): mcc: 0.5400, acc: 0.3816, precision: 0.7709, recall: 0.3872, f1: 0.5155, edges-pos-ontonotes_loss: 0.0869
09/17 12:29:16 AM: Update 1162: task edges-pos-ontonotes, batch 162 (1162): mcc: 0.5506, acc: 0.3845, precision: 0.7954, recall: 0.3896, f1: 0.5230, edges-pos-ontonotes_loss: 0.0844
09/17 12:29:27 AM: Update 1214: task edges-pos-ontonotes, batch 214 (1214): mcc: 0.5600, acc: 0.3870, precision: 0.8175, recall: 0.3916, f1: 0.5295, edges-pos-ontonotes_loss: 0.0814
09/17 12:29:46 AM: Update 1253: task edges-pos-ontonotes, batch 253 (1253): mcc: 0.5662, acc: 0.3893, precision: 0.8308, recall: 0.3936, f1: 0.5341, edges-pos-ontonotes_loss: 0.0792
09/17 12:29:57 AM: Update 1319: task edges-pos-ontonotes, batch 319 (1319): mcc: 0.5750, acc: 0.3938, precision: 0.8472, recall: 0.3977, f1: 0.5413, edges-pos-ontonotes_loss: 0.0760
09/17 12:30:07 AM: Update 1372: task edges-pos-ontonotes, batch 372 (1372): mcc: 0.5812, acc: 0.3972, precision: 0.8579, recall: 0.4010, f1: 0.5465, edges-pos-ontonotes_loss: 0.0737
09/17 12:30:17 AM: Update 1422: task edges-pos-ontonotes, batch 422 (1422): mcc: 0.5865, acc: 0.4007, precision: 0.8659, recall: 0.4044, f1: 0.5513, edges-pos-ontonotes_loss: 0.0718
09/17 12:30:27 AM: Update 1482: task edges-pos-ontonotes, batch 482 (1482): mcc: 0.5922, acc: 0.4049, precision: 0.8739, recall: 0.4083, f1: 0.5566, edges-pos-ontonotes_loss: 0.0697
09/17 12:30:37 AM: Update 1527: task edges-pos-ontonotes, batch 527 (1527): mcc: 0.5957, acc: 0.4076, precision: 0.8786, recall: 0.4109, f1: 0.5600, edges-pos-ontonotes_loss: 0.0683
09/17 12:30:47 AM: Update 1566: task edges-pos-ontonotes, batch 566 (1566): mcc: 0.5985, acc: 0.4099, precision: 0.8818, recall: 0.4132, f1: 0.5627, edges-pos-ontonotes_loss: 0.0671
09/17 12:30:57 AM: Update 1615: task edges-pos-ontonotes, batch 615 (1615): mcc: 0.6020, acc: 0.4128, precision: 0.8858, recall: 0.4160, f1: 0.5662, edges-pos-ontonotes_loss: 0.0658
09/17 12:31:08 AM: Update 1660: task edges-pos-ontonotes, batch 660 (1660): mcc: 0.6051, acc: 0.4156, precision: 0.8888, recall: 0.4188, f1: 0.5693, edges-pos-ontonotes_loss: 0.0647
09/17 12:31:18 AM: Update 1709: task edges-pos-ontonotes, batch 709 (1709): mcc: 0.6080, acc: 0.4183, precision: 0.8917, recall: 0.4214, f1: 0.5724, edges-pos-ontonotes_loss: 0.0636
09/17 12:31:28 AM: Update 1754: task edges-pos-ontonotes, batch 754 (1754): mcc: 0.6102, acc: 0.4205, precision: 0.8935, recall: 0.4236, f1: 0.5747, edges-pos-ontonotes_loss: 0.0626
09/17 12:31:38 AM: Update 1804: task edges-pos-ontonotes, batch 804 (1804): mcc: 0.6126, acc: 0.4227, precision: 0.8955, recall: 0.4259, f1: 0.5772, edges-pos-ontonotes_loss: 0.0616
09/17 12:31:48 AM: Update 1850: task edges-pos-ontonotes, batch 850 (1850): mcc: 0.6148, acc: 0.4250, precision: 0.8972, recall: 0.4281, f1: 0.5796, edges-pos-ontonotes_loss: 0.0608
09/17 12:31:58 AM: Update 1884: task edges-pos-ontonotes, batch 884 (1884): mcc: 0.6162, acc: 0.4263, precision: 0.8981, recall: 0.4295, f1: 0.5811, edges-pos-ontonotes_loss: 0.0602
09/17 12:32:09 AM: Update 1933: task edges-pos-ontonotes, batch 933 (1933): mcc: 0.6182, acc: 0.4284, precision: 0.8992, recall: 0.4317, f1: 0.5833, edges-pos-ontonotes_loss: 0.0593
09/17 12:32:19 AM: Update 1991: task edges-pos-ontonotes, batch 991 (1991): mcc: 0.6206, acc: 0.4309, precision: 0.9007, recall: 0.4343, f1: 0.5861, edges-pos-ontonotes_loss: 0.0582
09/17 12:32:20 AM: ***** Step 2000 / Validation 2 *****
09/17 12:32:20 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 12:32:20 AM: Validating...
09/17 12:32:29 AM: Evaluate: task edges-pos-ontonotes, batch 78 (157): mcc: 0.6191, acc: 0.4483, precision: 0.8693, recall: 0.4483, f1: 0.5915, edges-pos-ontonotes_loss: 0.0444
09/17 12:32:39 AM: Evaluate: task edges-pos-ontonotes, batch 126 (157): mcc: 0.6341, acc: 0.4513, precision: 0.9046, recall: 0.4513, f1: 0.6022, edges-pos-ontonotes_loss: 0.0439
09/17 12:32:44 AM: Best result seen so far for edges-pos-ontonotes.
09/17 12:32:44 AM: Best result seen so far for macro.
09/17 12:32:44 AM: Updating LR scheduler:
09/17 12:32:44 AM: 	Best result seen so far for macro_avg: 0.605
09/17 12:32:44 AM: 	# validation passes without improvement: 0
09/17 12:32:44 AM: edges-pos-ontonotes_loss: training: 0.058022 validation: 0.043697
09/17 12:32:44 AM: macro_avg: validation: 0.604830
09/17 12:32:44 AM: micro_avg: validation: 0.000000
09/17 12:32:44 AM: edges-pos-ontonotes_mcc: training: 0.620920 validation: 0.638147
09/17 12:32:44 AM: edges-pos-ontonotes_acc: training: 0.431252 validation: 0.451718
09/17 12:32:44 AM: edges-pos-ontonotes_precision: training: 0.900921 validation: 0.914742
09/17 12:32:44 AM: edges-pos-ontonotes_recall: training: 0.434685 validation: 0.451771
09/17 12:32:44 AM: edges-pos-ontonotes_f1: training: 0.586426 validation: 0.604830
09/17 12:32:44 AM: Global learning rate: 0.0001
09/17 12:32:44 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 12:32:49 AM: Update 2030: task edges-pos-ontonotes, batch 30 (2030): mcc: 0.6719, acc: 0.4853, precision: 0.9287, recall: 0.4927, f1: 0.6438, edges-pos-ontonotes_loss: 0.0402
09/17 12:32:59 AM: Update 2094: task edges-pos-ontonotes, batch 94 (2094): mcc: 0.6846, acc: 0.5016, precision: 0.9332, recall: 0.5087, f1: 0.6585, edges-pos-ontonotes_loss: 0.0386
09/17 12:33:09 AM: Update 2142: task edges-pos-ontonotes, batch 142 (2142): mcc: 0.6799, acc: 0.4957, precision: 0.9320, recall: 0.5024, f1: 0.6529, edges-pos-ontonotes_loss: 0.0385
09/17 12:33:20 AM: Update 2192: task edges-pos-ontonotes, batch 192 (2192): mcc: 0.6829, acc: 0.5001, precision: 0.9317, recall: 0.5070, f1: 0.6567, edges-pos-ontonotes_loss: 0.0380
09/17 12:33:30 AM: Update 2273: task edges-pos-ontonotes, batch 273 (2273): mcc: 0.6989, acc: 0.5224, precision: 0.9328, recall: 0.5301, f1: 0.6760, edges-pos-ontonotes_loss: 0.0363
09/17 12:33:40 AM: Update 2356: task edges-pos-ontonotes, batch 356 (2356): mcc: 0.7115, acc: 0.5401, precision: 0.9341, recall: 0.5484, f1: 0.6911, edges-pos-ontonotes_loss: 0.0350
09/17 12:33:50 AM: Update 2434: task edges-pos-ontonotes, batch 434 (2434): mcc: 0.7211, acc: 0.5541, precision: 0.9344, recall: 0.5629, f1: 0.7026, edges-pos-ontonotes_loss: 0.0339
09/17 12:34:02 AM: Update 2505: task edges-pos-ontonotes, batch 505 (2505): mcc: 0.7287, acc: 0.5657, precision: 0.9340, recall: 0.5749, f1: 0.7118, edges-pos-ontonotes_loss: 0.0331
09/17 12:34:12 AM: Update 2613: task edges-pos-ontonotes, batch 613 (2613): mcc: 0.7309, acc: 0.5707, precision: 0.9305, recall: 0.5805, f1: 0.7150, edges-pos-ontonotes_loss: 0.0331
09/17 12:34:22 AM: Update 2717: task edges-pos-ontonotes, batch 717 (2717): mcc: 0.7341, acc: 0.5764, precision: 0.9288, recall: 0.5867, f1: 0.7191, edges-pos-ontonotes_loss: 0.0325
09/17 12:34:32 AM: Update 2837: task edges-pos-ontonotes, batch 837 (2837): mcc: 0.7373, acc: 0.5824, precision: 0.9266, recall: 0.5931, f1: 0.7233, edges-pos-ontonotes_loss: 0.0317
09/17 12:34:42 AM: Update 2982: task edges-pos-ontonotes, batch 982 (2982): mcc: 0.7396, acc: 0.5877, precision: 0.9248, recall: 0.5981, f1: 0.7264, edges-pos-ontonotes_loss: 0.0310
09/17 12:34:43 AM: ***** Step 3000 / Validation 3 *****
09/17 12:34:43 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 12:34:43 AM: Validating...
09/17 12:34:52 AM: Evaluate: task edges-pos-ontonotes, batch 64 (157): mcc: 0.6917, acc: 0.5391, precision: 0.8981, recall: 0.5399, f1: 0.6744, edges-pos-ontonotes_loss: 0.0366
09/17 12:35:02 AM: Evaluate: task edges-pos-ontonotes, batch 136 (157): mcc: 0.6720, acc: 0.5109, precision: 0.8954, recall: 0.5114, f1: 0.6510, edges-pos-ontonotes_loss: 0.0387
09/17 12:35:05 AM: Best result seen so far for edges-pos-ontonotes.
09/17 12:35:05 AM: Best result seen so far for macro.
09/17 12:35:05 AM: Updating LR scheduler:
09/17 12:35:05 AM: 	Best result seen so far for macro_avg: 0.647
09/17 12:35:05 AM: 	# validation passes without improvement: 0
09/17 12:35:05 AM: edges-pos-ontonotes_loss: training: 0.030874 validation: 0.039205
09/17 12:35:05 AM: macro_avg: validation: 0.647036
09/17 12:35:05 AM: micro_avg: validation: 0.000000
09/17 12:35:05 AM: edges-pos-ontonotes_mcc: training: 0.739868 validation: 0.668122
09/17 12:35:05 AM: edges-pos-ontonotes_acc: training: 0.588355 validation: 0.507095
09/17 12:35:05 AM: edges-pos-ontonotes_precision: training: 0.924459 validation: 0.892015
09/17 12:35:05 AM: edges-pos-ontonotes_recall: training: 0.598655 validation: 0.507625
09/17 12:35:05 AM: edges-pos-ontonotes_f1: training: 0.726711 validation: 0.647036
09/17 12:35:05 AM: Global learning rate: 0.0001
09/17 12:35:05 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 12:35:12 AM: Update 3090: task edges-pos-ontonotes, batch 90 (3090): mcc: 0.7600, acc: 0.6408, precision: 0.8990, recall: 0.6494, f1: 0.7541, edges-pos-ontonotes_loss: 0.0254
09/17 12:35:22 AM: Update 3161: task edges-pos-ontonotes, batch 161 (3161): mcc: 0.7239, acc: 0.5886, precision: 0.8897, recall: 0.5963, f1: 0.7141, edges-pos-ontonotes_loss: 0.0283
09/17 12:35:32 AM: Update 3224: task edges-pos-ontonotes, batch 224 (3224): mcc: 0.7002, acc: 0.5543, precision: 0.8840, recall: 0.5620, f1: 0.6871, edges-pos-ontonotes_loss: 0.0318
09/17 12:35:42 AM: Update 3271: task edges-pos-ontonotes, batch 271 (3271): mcc: 0.6946, acc: 0.5454, precision: 0.8848, recall: 0.5527, f1: 0.6804, edges-pos-ontonotes_loss: 0.0332
09/17 12:35:52 AM: Update 3322: task edges-pos-ontonotes, batch 322 (3322): mcc: 0.6918, acc: 0.5406, precision: 0.8855, recall: 0.5479, f1: 0.6769, edges-pos-ontonotes_loss: 0.0344
09/17 12:36:02 AM: Update 3381: task edges-pos-ontonotes, batch 381 (3381): mcc: 0.6907, acc: 0.5382, precision: 0.8868, recall: 0.5453, f1: 0.6753, edges-pos-ontonotes_loss: 0.0349
09/17 12:36:13 AM: Update 3457: task edges-pos-ontonotes, batch 457 (3457): mcc: 0.6896, acc: 0.5359, precision: 0.8878, recall: 0.5429, f1: 0.6738, edges-pos-ontonotes_loss: 0.0355
09/17 12:36:23 AM: Update 3461: task edges-pos-ontonotes, batch 461 (3461): mcc: 0.6895, acc: 0.5359, precision: 0.8876, recall: 0.5429, f1: 0.6737, edges-pos-ontonotes_loss: 0.0355
09/17 12:36:33 AM: Update 3582: task edges-pos-ontonotes, batch 582 (3582): mcc: 0.6959, acc: 0.5447, precision: 0.8896, recall: 0.5517, f1: 0.6810, edges-pos-ontonotes_loss: 0.0344
09/17 12:36:43 AM: Update 3690: task edges-pos-ontonotes, batch 690 (3690): mcc: 0.7005, acc: 0.5511, precision: 0.8909, recall: 0.5581, f1: 0.6863, edges-pos-ontonotes_loss: 0.0337
09/17 12:36:54 AM: Update 3774: task edges-pos-ontonotes, batch 774 (3774): mcc: 0.7033, acc: 0.5552, precision: 0.8914, recall: 0.5622, f1: 0.6895, edges-pos-ontonotes_loss: 0.0331
09/17 12:37:04 AM: Update 3825: task edges-pos-ontonotes, batch 825 (3825): mcc: 0.7034, acc: 0.5552, precision: 0.8916, recall: 0.5622, f1: 0.6896, edges-pos-ontonotes_loss: 0.0332
09/17 12:37:14 AM: Update 3882: task edges-pos-ontonotes, batch 882 (3882): mcc: 0.7033, acc: 0.5549, precision: 0.8915, recall: 0.5621, f1: 0.6895, edges-pos-ontonotes_loss: 0.0332
09/17 12:37:24 AM: Update 3947: task edges-pos-ontonotes, batch 947 (3947): mcc: 0.7040, acc: 0.5555, precision: 0.8919, recall: 0.5629, f1: 0.6902, edges-pos-ontonotes_loss: 0.0331
09/17 12:37:31 AM: ***** Step 4000 / Validation 4 *****
09/17 12:37:31 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 12:37:31 AM: Validating...
09/17 12:37:34 AM: Evaluate: task edges-pos-ontonotes, batch 38 (157): mcc: 0.7251, acc: 0.5873, precision: 0.9054, recall: 0.5877, f1: 0.7128, edges-pos-ontonotes_loss: 0.0320
09/17 12:37:44 AM: Evaluate: task edges-pos-ontonotes, batch 121 (157): mcc: 0.7147, acc: 0.5721, precision: 0.8996, recall: 0.5749, f1: 0.7015, edges-pos-ontonotes_loss: 0.0320
09/17 12:37:50 AM: Best result seen so far for edges-pos-ontonotes.
09/17 12:37:50 AM: Best result seen so far for macro.
09/17 12:37:50 AM: Updating LR scheduler:
09/17 12:37:50 AM: 	Best result seen so far for macro_avg: 0.685
09/17 12:37:50 AM: 	# validation passes without improvement: 0
09/17 12:37:50 AM: edges-pos-ontonotes_loss: training: 0.033064 validation: 0.033273
09/17 12:37:50 AM: macro_avg: validation: 0.684764
09/17 12:37:50 AM: micro_avg: validation: 0.000000
09/17 12:37:50 AM: edges-pos-ontonotes_mcc: training: 0.704379 validation: 0.699705
09/17 12:37:50 AM: edges-pos-ontonotes_acc: training: 0.555861 validation: 0.551986
09/17 12:37:50 AM: edges-pos-ontonotes_precision: training: 0.892111 validation: 0.893832
09/17 12:37:50 AM: edges-pos-ontonotes_recall: training: 0.563408 validation: 0.554959
09/17 12:37:50 AM: edges-pos-ontonotes_f1: training: 0.690644 validation: 0.684764
09/17 12:37:50 AM: Global learning rate: 0.0001
09/17 12:37:50 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 12:37:54 AM: Update 4042: task edges-pos-ontonotes, batch 42 (4042): mcc: 0.7076, acc: 0.5576, precision: 0.8937, recall: 0.5675, f1: 0.6942, edges-pos-ontonotes_loss: 0.0333
09/17 12:38:04 AM: Update 4090: task edges-pos-ontonotes, batch 90 (4090): mcc: 0.7048, acc: 0.5538, precision: 0.8918, recall: 0.5643, f1: 0.6912, edges-pos-ontonotes_loss: 0.0328
09/17 12:38:15 AM: Update 4150: task edges-pos-ontonotes, batch 150 (4150): mcc: 0.6935, acc: 0.5398, precision: 0.8868, recall: 0.5497, f1: 0.6787, edges-pos-ontonotes_loss: 0.0348
09/17 12:38:25 AM: Update 4199: task edges-pos-ontonotes, batch 199 (4199): mcc: 0.6899, acc: 0.5359, precision: 0.8846, recall: 0.5454, f1: 0.6748, edges-pos-ontonotes_loss: 0.0352
09/17 12:38:35 AM: Update 4250: task edges-pos-ontonotes, batch 250 (4250): mcc: 0.6896, acc: 0.5354, precision: 0.8844, recall: 0.5452, f1: 0.6745, edges-pos-ontonotes_loss: 0.0353
09/17 12:38:45 AM: Update 4314: task edges-pos-ontonotes, batch 314 (4314): mcc: 0.6893, acc: 0.5351, precision: 0.8840, recall: 0.5449, f1: 0.6742, edges-pos-ontonotes_loss: 0.0356
09/17 12:38:55 AM: Update 4368: task edges-pos-ontonotes, batch 368 (4368): mcc: 0.6894, acc: 0.5355, precision: 0.8831, recall: 0.5456, f1: 0.6745, edges-pos-ontonotes_loss: 0.0356
09/17 12:39:05 AM: Update 4401: task edges-pos-ontonotes, batch 401 (4401): mcc: 0.6892, acc: 0.5355, precision: 0.8828, recall: 0.5456, f1: 0.6744, edges-pos-ontonotes_loss: 0.0356
09/17 12:39:15 AM: Update 4446: task edges-pos-ontonotes, batch 446 (4446): mcc: 0.6883, acc: 0.5344, precision: 0.8827, recall: 0.5441, f1: 0.6732, edges-pos-ontonotes_loss: 0.0357
09/17 12:39:25 AM: Update 4496: task edges-pos-ontonotes, batch 496 (4496): mcc: 0.6884, acc: 0.5344, precision: 0.8834, recall: 0.5439, f1: 0.6733, edges-pos-ontonotes_loss: 0.0357
09/17 12:39:35 AM: Update 4553: task edges-pos-ontonotes, batch 553 (4553): mcc: 0.6878, acc: 0.5336, precision: 0.8837, recall: 0.5428, f1: 0.6725, edges-pos-ontonotes_loss: 0.0358
09/17 12:39:45 AM: Update 4622: task edges-pos-ontonotes, batch 622 (4622): mcc: 0.6881, acc: 0.5336, precision: 0.8846, recall: 0.5426, f1: 0.6726, edges-pos-ontonotes_loss: 0.0357
09/17 12:39:56 AM: Update 4688: task edges-pos-ontonotes, batch 688 (4688): mcc: 0.6885, acc: 0.5337, precision: 0.8854, recall: 0.5427, f1: 0.6729, edges-pos-ontonotes_loss: 0.0357
09/17 12:40:06 AM: Update 4739: task edges-pos-ontonotes, batch 739 (4739): mcc: 0.6888, acc: 0.5341, precision: 0.8857, recall: 0.5431, f1: 0.6733, edges-pos-ontonotes_loss: 0.0356
09/17 12:40:16 AM: Update 4785: task edges-pos-ontonotes, batch 785 (4785): mcc: 0.6892, acc: 0.5346, precision: 0.8861, recall: 0.5434, f1: 0.6737, edges-pos-ontonotes_loss: 0.0356
09/17 12:40:26 AM: Update 4835: task edges-pos-ontonotes, batch 835 (4835): mcc: 0.6899, acc: 0.5354, precision: 0.8868, recall: 0.5441, f1: 0.6744, edges-pos-ontonotes_loss: 0.0355
09/17 12:40:36 AM: Update 4887: task edges-pos-ontonotes, batch 887 (4887): mcc: 0.6905, acc: 0.5361, precision: 0.8872, recall: 0.5448, f1: 0.6750, edges-pos-ontonotes_loss: 0.0354
09/17 12:40:46 AM: Update 4938: task edges-pos-ontonotes, batch 938 (4938): mcc: 0.6910, acc: 0.5367, precision: 0.8878, recall: 0.5452, f1: 0.6756, edges-pos-ontonotes_loss: 0.0354
09/17 12:40:57 AM: Update 4984: task edges-pos-ontonotes, batch 984 (4984): mcc: 0.6915, acc: 0.5372, precision: 0.8882, recall: 0.5457, f1: 0.6760, edges-pos-ontonotes_loss: 0.0353
09/17 12:41:01 AM: ***** Step 5000 / Validation 5 *****
09/17 12:41:01 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 12:41:01 AM: Validating...
09/17 12:41:07 AM: Evaluate: task edges-pos-ontonotes, batch 42 (157): mcc: 0.7177, acc: 0.5802, precision: 0.8983, recall: 0.5806, f1: 0.7053, edges-pos-ontonotes_loss: 0.0327
09/17 12:41:17 AM: Evaluate: task edges-pos-ontonotes, batch 101 (157): mcc: 0.7269, acc: 0.5907, precision: 0.9045, recall: 0.5911, f1: 0.7150, edges-pos-ontonotes_loss: 0.0315
09/17 12:41:27 AM: Evaluate: task edges-pos-ontonotes, batch 149 (157): mcc: 0.7137, acc: 0.5689, precision: 0.9016, recall: 0.5720, f1: 0.7000, edges-pos-ontonotes_loss: 0.0321
09/17 12:41:28 AM: Best result seen so far for edges-pos-ontonotes.
09/17 12:41:28 AM: Best result seen so far for macro.
09/17 12:41:28 AM: Updating LR scheduler:
09/17 12:41:28 AM: 	Best result seen so far for macro_avg: 0.699
09/17 12:41:28 AM: 	# validation passes without improvement: 0
09/17 12:41:28 AM: edges-pos-ontonotes_loss: training: 0.035307 validation: 0.032151
09/17 12:41:28 AM: macro_avg: validation: 0.699025
09/17 12:41:28 AM: micro_avg: validation: 0.000000
09/17 12:41:28 AM: edges-pos-ontonotes_mcc: training: 0.691654 validation: 0.712874
09/17 12:41:28 AM: edges-pos-ontonotes_acc: training: 0.537347 validation: 0.567902
09/17 12:41:28 AM: edges-pos-ontonotes_precision: training: 0.888386 validation: 0.901283
09/17 12:41:28 AM: edges-pos-ontonotes_recall: training: 0.545820 validation: 0.570907
09/17 12:41:28 AM: edges-pos-ontonotes_f1: training: 0.676192 validation: 0.699025
09/17 12:41:28 AM: Global learning rate: 0.0001
09/17 12:41:28 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 12:41:43 AM: Update 5026: task edges-pos-ontonotes, batch 26 (5026): mcc: 0.7112, acc: 0.5591, precision: 0.9029, recall: 0.5673, f1: 0.6968, edges-pos-ontonotes_loss: 0.0330
09/17 12:41:53 AM: Update 5082: task edges-pos-ontonotes, batch 82 (5082): mcc: 0.7038, acc: 0.5521, precision: 0.8962, recall: 0.5598, f1: 0.6891, edges-pos-ontonotes_loss: 0.0340
09/17 12:42:03 AM: Update 5132: task edges-pos-ontonotes, batch 132 (5132): mcc: 0.7025, acc: 0.5511, precision: 0.8949, recall: 0.5586, f1: 0.6879, edges-pos-ontonotes_loss: 0.0340
09/17 12:42:13 AM: Update 5182: task edges-pos-ontonotes, batch 182 (5182): mcc: 0.7036, acc: 0.5521, precision: 0.8963, recall: 0.5594, f1: 0.6889, edges-pos-ontonotes_loss: 0.0338
09/17 12:42:23 AM: Update 5229: task edges-pos-ontonotes, batch 229 (5229): mcc: 0.7033, acc: 0.5518, precision: 0.8957, recall: 0.5593, f1: 0.6886, edges-pos-ontonotes_loss: 0.0338
09/17 12:42:33 AM: Update 5273: task edges-pos-ontonotes, batch 273 (5273): mcc: 0.7035, acc: 0.5520, precision: 0.8962, recall: 0.5595, f1: 0.6889, edges-pos-ontonotes_loss: 0.0338
09/17 12:42:43 AM: Update 5318: task edges-pos-ontonotes, batch 318 (5318): mcc: 0.7039, acc: 0.5525, precision: 0.8958, recall: 0.5602, f1: 0.6893, edges-pos-ontonotes_loss: 0.0338
09/17 12:42:53 AM: Update 5348: task edges-pos-ontonotes, batch 348 (5348): mcc: 0.7027, acc: 0.5515, precision: 0.8938, recall: 0.5596, f1: 0.6883, edges-pos-ontonotes_loss: 0.0337
09/17 12:43:03 AM: Update 5414: task edges-pos-ontonotes, batch 414 (5414): mcc: 0.7058, acc: 0.5556, precision: 0.8942, recall: 0.5642, f1: 0.6919, edges-pos-ontonotes_loss: 0.0330
09/17 12:43:14 AM: Update 5473: task edges-pos-ontonotes, batch 473 (5473): mcc: 0.7085, acc: 0.5589, precision: 0.8952, recall: 0.5679, f1: 0.6950, edges-pos-ontonotes_loss: 0.0324
09/17 12:43:24 AM: Update 5536: task edges-pos-ontonotes, batch 536 (5536): mcc: 0.7114, acc: 0.5625, precision: 0.8965, recall: 0.5717, f1: 0.6982, edges-pos-ontonotes_loss: 0.0319
09/17 12:43:34 AM: Update 5589: task edges-pos-ontonotes, batch 589 (5589): mcc: 0.7122, acc: 0.5631, precision: 0.8969, recall: 0.5727, f1: 0.6990, edges-pos-ontonotes_loss: 0.0316
09/17 12:43:44 AM: Update 5639: task edges-pos-ontonotes, batch 639 (5639): mcc: 0.7132, acc: 0.5643, precision: 0.8972, recall: 0.5741, f1: 0.7002, edges-pos-ontonotes_loss: 0.0313
09/17 12:43:54 AM: Update 5700: task edges-pos-ontonotes, batch 700 (5700): mcc: 0.7175, acc: 0.5699, precision: 0.8982, recall: 0.5802, f1: 0.7050, edges-pos-ontonotes_loss: 0.0308
09/17 12:44:04 AM: Update 5783: task edges-pos-ontonotes, batch 783 (5783): mcc: 0.7238, acc: 0.5785, precision: 0.9000, recall: 0.5892, f1: 0.7122, edges-pos-ontonotes_loss: 0.0299
09/17 12:44:14 AM: Update 5897: task edges-pos-ontonotes, batch 897 (5897): mcc: 0.7320, acc: 0.5897, precision: 0.9020, recall: 0.6009, f1: 0.7213, edges-pos-ontonotes_loss: 0.0289
09/17 12:44:24 AM: Update 5991: task edges-pos-ontonotes, batch 991 (5991): mcc: 0.7373, acc: 0.5972, precision: 0.9030, recall: 0.6089, f1: 0.7273, edges-pos-ontonotes_loss: 0.0283
09/17 12:44:24 AM: ***** Step 6000 / Validation 6 *****
09/17 12:44:24 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 12:44:24 AM: Validating...
09/17 12:44:34 AM: Evaluate: task edges-pos-ontonotes, batch 93 (157): mcc: 0.7206, acc: 0.5736, precision: 0.9137, recall: 0.5750, f1: 0.7059, edges-pos-ontonotes_loss: 0.0308
09/17 12:44:44 AM: Updating LR scheduler:
09/17 12:44:44 AM: 	Best result seen so far for macro_avg: 0.699
09/17 12:44:44 AM: 	# validation passes without improvement: 1
09/17 12:44:44 AM: edges-pos-ontonotes_loss: training: 0.028225 validation: 0.032213
09/17 12:44:44 AM: macro_avg: validation: 0.682908
09/17 12:44:44 AM: micro_avg: validation: 0.000000
09/17 12:44:44 AM: edges-pos-ontonotes_mcc: training: 0.737467 validation: 0.701025
09/17 12:44:44 AM: edges-pos-ontonotes_acc: training: 0.597521 validation: 0.541901
09/17 12:44:44 AM: edges-pos-ontonotes_precision: training: 0.903064 validation: 0.911582
09/17 12:44:44 AM: edges-pos-ontonotes_recall: training: 0.609186 validation: 0.545954
09/17 12:44:44 AM: edges-pos-ontonotes_f1: training: 0.727570 validation: 0.682908
09/17 12:44:44 AM: Global learning rate: 0.0001
09/17 12:44:44 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 12:44:44 AM: Update 6006: task edges-pos-ontonotes, batch 6 (6006): mcc: 0.7761, acc: 0.6603, precision: 0.9034, recall: 0.6735, f1: 0.7717, edges-pos-ontonotes_loss: 0.0237
09/17 12:44:54 AM: Update 6109: task edges-pos-ontonotes, batch 109 (6109): mcc: 0.7934, acc: 0.6836, precision: 0.9051, recall: 0.7019, f1: 0.7907, edges-pos-ontonotes_loss: 0.0226
09/17 12:45:04 AM: Update 6199: task edges-pos-ontonotes, batch 199 (6199): mcc: 0.7971, acc: 0.6907, precision: 0.9047, recall: 0.7088, f1: 0.7948, edges-pos-ontonotes_loss: 0.0221
09/17 12:45:14 AM: Update 6290: task edges-pos-ontonotes, batch 290 (6290): mcc: 0.7966, acc: 0.6903, precision: 0.9041, recall: 0.7083, f1: 0.7943, edges-pos-ontonotes_loss: 0.0218
09/17 12:45:24 AM: Update 6417: task edges-pos-ontonotes, batch 417 (6417): mcc: 0.7930, acc: 0.6885, precision: 0.9001, recall: 0.7052, f1: 0.7908, edges-pos-ontonotes_loss: 0.0220
09/17 12:45:34 AM: Update 6542: task edges-pos-ontonotes, batch 542 (6542): mcc: 0.7906, acc: 0.6867, precision: 0.8980, recall: 0.7027, f1: 0.7885, edges-pos-ontonotes_loss: 0.0217
09/17 12:45:44 AM: Update 6611: task edges-pos-ontonotes, batch 611 (6611): mcc: 0.7825, acc: 0.6758, precision: 0.8945, recall: 0.6913, f1: 0.7799, edges-pos-ontonotes_loss: 0.0223
09/17 12:45:55 AM: Update 6684: task edges-pos-ontonotes, batch 684 (6684): mcc: 0.7661, acc: 0.6524, precision: 0.8887, recall: 0.6674, f1: 0.7623, edges-pos-ontonotes_loss: 0.0238
09/17 12:46:05 AM: Update 6745: task edges-pos-ontonotes, batch 745 (6745): mcc: 0.7538, acc: 0.6347, precision: 0.8849, recall: 0.6493, f1: 0.7490, edges-pos-ontonotes_loss: 0.0247
09/17 12:46:15 AM: Update 6804: task edges-pos-ontonotes, batch 804 (6804): mcc: 0.7465, acc: 0.6242, precision: 0.8828, recall: 0.6386, f1: 0.7411, edges-pos-ontonotes_loss: 0.0254
09/17 12:46:25 AM: Update 6865: task edges-pos-ontonotes, batch 865 (6865): mcc: 0.7413, acc: 0.6167, precision: 0.8815, recall: 0.6307, f1: 0.7353, edges-pos-ontonotes_loss: 0.0260
09/17 12:46:35 AM: Update 6907: task edges-pos-ontonotes, batch 907 (6907): mcc: 0.7387, acc: 0.6129, precision: 0.8812, recall: 0.6267, f1: 0.7325, edges-pos-ontonotes_loss: 0.0264
09/17 12:46:45 AM: Update 6953: task edges-pos-ontonotes, batch 953 (6953): mcc: 0.7380, acc: 0.6120, precision: 0.8810, recall: 0.6257, f1: 0.7317, edges-pos-ontonotes_loss: 0.0266
09/17 12:46:52 AM: ***** Step 7000 / Validation 7 *****
09/17 12:46:52 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 12:46:52 AM: Validating...
09/17 12:46:55 AM: Evaluate: task edges-pos-ontonotes, batch 16 (157): mcc: 0.7132, acc: 0.5756, precision: 0.8942, recall: 0.5761, f1: 0.7007, edges-pos-ontonotes_loss: 0.0314
09/17 12:47:05 AM: Evaluate: task edges-pos-ontonotes, batch 84 (157): mcc: 0.7433, acc: 0.6187, precision: 0.9020, recall: 0.6194, f1: 0.7345, edges-pos-ontonotes_loss: 0.0287
09/17 12:47:15 AM: Evaluate: task edges-pos-ontonotes, batch 129 (157): mcc: 0.7148, acc: 0.5764, precision: 0.8921, recall: 0.5800, f1: 0.7030, edges-pos-ontonotes_loss: 0.0302
09/17 12:47:22 AM: Updating LR scheduler:
09/17 12:47:22 AM: 	Best result seen so far for macro_avg: 0.699
09/17 12:47:22 AM: 	# validation passes without improvement: 2
09/17 12:47:22 AM: edges-pos-ontonotes_loss: training: 0.026586 validation: 0.030945
09/17 12:47:22 AM: macro_avg: validation: 0.691767
09/17 12:47:22 AM: micro_avg: validation: 0.000000
09/17 12:47:22 AM: edges-pos-ontonotes_mcc: training: 0.738148 validation: 0.704979
09/17 12:47:22 AM: edges-pos-ontonotes_acc: training: 0.612349 validation: 0.562632
09/17 12:47:22 AM: edges-pos-ontonotes_precision: training: 0.881014 validation: 0.889871
09/17 12:47:22 AM: edges-pos-ontonotes_recall: training: 0.625851 validation: 0.565806
09/17 12:47:22 AM: edges-pos-ontonotes_f1: training: 0.731829 validation: 0.691767
09/17 12:47:22 AM: Global learning rate: 0.0001
09/17 12:47:22 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 12:47:25 AM: Update 7034: task edges-pos-ontonotes, batch 34 (7034): mcc: 0.7479, acc: 0.6292, precision: 0.8825, recall: 0.6412, f1: 0.7427, edges-pos-ontonotes_loss: 0.0269
09/17 12:47:36 AM: Update 7141: task edges-pos-ontonotes, batch 141 (7141): mcc: 0.7481, acc: 0.6287, precision: 0.8833, recall: 0.6408, f1: 0.7428, edges-pos-ontonotes_loss: 0.0259
09/17 12:47:46 AM: Update 7232: task edges-pos-ontonotes, batch 232 (7232): mcc: 0.7491, acc: 0.6292, precision: 0.8851, recall: 0.6412, f1: 0.7437, edges-pos-ontonotes_loss: 0.0257
09/17 12:47:56 AM: Update 7290: task edges-pos-ontonotes, batch 290 (7290): mcc: 0.7412, acc: 0.6173, precision: 0.8835, recall: 0.6292, f1: 0.7350, edges-pos-ontonotes_loss: 0.0266
09/17 12:48:06 AM: Update 7355: task edges-pos-ontonotes, batch 355 (7355): mcc: 0.7372, acc: 0.6108, precision: 0.8834, recall: 0.6225, f1: 0.7304, edges-pos-ontonotes_loss: 0.0272
09/17 12:48:17 AM: Update 7415: task edges-pos-ontonotes, batch 415 (7415): mcc: 0.7343, acc: 0.6062, precision: 0.8827, recall: 0.6183, f1: 0.7272, edges-pos-ontonotes_loss: 0.0276
09/17 12:48:27 AM: Update 7489: task edges-pos-ontonotes, batch 489 (7489): mcc: 0.7325, acc: 0.6026, precision: 0.8826, recall: 0.6152, f1: 0.7251, edges-pos-ontonotes_loss: 0.0279
09/17 12:48:46 AM: Update 7547: task edges-pos-ontonotes, batch 547 (7547): mcc: 0.7313, acc: 0.6010, precision: 0.8821, recall: 0.6137, f1: 0.7239, edges-pos-ontonotes_loss: 0.0280
09/17 12:48:56 AM: Update 7589: task edges-pos-ontonotes, batch 589 (7589): mcc: 0.7259, acc: 0.5939, precision: 0.8788, recall: 0.6071, f1: 0.7181, edges-pos-ontonotes_loss: 0.0284
09/17 12:49:06 AM: Update 7633: task edges-pos-ontonotes, batch 633 (7633): mcc: 0.7224, acc: 0.5894, precision: 0.8771, recall: 0.6026, f1: 0.7144, edges-pos-ontonotes_loss: 0.0288
09/17 12:49:16 AM: Update 7688: task edges-pos-ontonotes, batch 688 (7688): mcc: 0.7198, acc: 0.5860, precision: 0.8755, recall: 0.5994, f1: 0.7116, edges-pos-ontonotes_loss: 0.0292
09/17 12:49:26 AM: Update 7762: task edges-pos-ontonotes, batch 762 (7762): mcc: 0.7179, acc: 0.5835, precision: 0.8746, recall: 0.5969, f1: 0.7096, edges-pos-ontonotes_loss: 0.0296
09/17 12:49:36 AM: Update 7810: task edges-pos-ontonotes, batch 810 (7810): mcc: 0.7170, acc: 0.5820, precision: 0.8745, recall: 0.5955, f1: 0.7085, edges-pos-ontonotes_loss: 0.0298
09/17 12:49:46 AM: Update 7857: task edges-pos-ontonotes, batch 857 (7857): mcc: 0.7160, acc: 0.5806, precision: 0.8741, recall: 0.5941, f1: 0.7074, edges-pos-ontonotes_loss: 0.0300
09/17 12:49:56 AM: Update 7886: task edges-pos-ontonotes, batch 886 (7886): mcc: 0.7147, acc: 0.5788, precision: 0.8739, recall: 0.5921, f1: 0.7059, edges-pos-ontonotes_loss: 0.0301
09/17 12:50:07 AM: Update 7933: task edges-pos-ontonotes, batch 933 (7933): mcc: 0.7135, acc: 0.5770, precision: 0.8738, recall: 0.5902, f1: 0.7046, edges-pos-ontonotes_loss: 0.0303
09/17 12:50:17 AM: Update 7978: task edges-pos-ontonotes, batch 978 (7978): mcc: 0.7127, acc: 0.5758, precision: 0.8741, recall: 0.5888, f1: 0.7036, edges-pos-ontonotes_loss: 0.0305
09/17 12:50:22 AM: ***** Step 8000 / Validation 8 *****
09/17 12:50:22 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 12:50:22 AM: Validating...
09/17 12:50:27 AM: Evaluate: task edges-pos-ontonotes, batch 37 (157): mcc: 0.7307, acc: 0.6042, precision: 0.8933, recall: 0.6049, f1: 0.7213, edges-pos-ontonotes_loss: 0.0294
09/17 12:50:37 AM: Evaluate: task edges-pos-ontonotes, batch 107 (157): mcc: 0.7392, acc: 0.6116, precision: 0.9017, recall: 0.6129, f1: 0.7298, edges-pos-ontonotes_loss: 0.0287
09/17 12:50:46 AM: Best result seen so far for edges-pos-ontonotes.
09/17 12:50:46 AM: Best result seen so far for macro.
09/17 12:50:46 AM: Updating LR scheduler:
09/17 12:50:46 AM: 	Best result seen so far for macro_avg: 0.715
09/17 12:50:46 AM: 	# validation passes without improvement: 0
09/17 12:50:46 AM: edges-pos-ontonotes_loss: training: 0.030546 validation: 0.029694
09/17 12:50:46 AM: macro_avg: validation: 0.715254
09/17 12:50:46 AM: micro_avg: validation: 0.000000
09/17 12:50:46 AM: edges-pos-ontonotes_mcc: training: 0.712331 validation: 0.726130
09/17 12:50:46 AM: edges-pos-ontonotes_acc: training: 0.575252 validation: 0.590844
09/17 12:50:46 AM: edges-pos-ontonotes_precision: training: 0.874057 validation: 0.897745
09/17 12:50:46 AM: edges-pos-ontonotes_recall: training: 0.588169 validation: 0.594421
09/17 12:50:46 AM: edges-pos-ontonotes_f1: training: 0.703165 validation: 0.715254
09/17 12:50:46 AM: Global learning rate: 0.0001
09/17 12:50:46 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 12:50:47 AM: Update 8002: task edges-pos-ontonotes, batch 2 (8002): mcc: 0.6843, acc: 0.5443, precision: 0.8577, recall: 0.5540, f1: 0.6732, edges-pos-ontonotes_loss: 0.0334
09/17 12:50:57 AM: Update 8059: task edges-pos-ontonotes, batch 59 (8059): mcc: 0.7022, acc: 0.5574, precision: 0.8808, recall: 0.5673, f1: 0.6901, edges-pos-ontonotes_loss: 0.0332
09/17 12:51:07 AM: Update 8110: task edges-pos-ontonotes, batch 110 (8110): mcc: 0.7011, acc: 0.5561, precision: 0.8795, recall: 0.5664, f1: 0.6890, edges-pos-ontonotes_loss: 0.0331
09/17 12:51:17 AM: Update 8163: task edges-pos-ontonotes, batch 163 (8163): mcc: 0.7023, acc: 0.5580, precision: 0.8800, recall: 0.5680, f1: 0.6904, edges-pos-ontonotes_loss: 0.0329
09/17 12:51:27 AM: Update 8201: task edges-pos-ontonotes, batch 201 (8201): mcc: 0.7024, acc: 0.5587, precision: 0.8795, recall: 0.5685, f1: 0.6906, edges-pos-ontonotes_loss: 0.0330
09/17 12:51:37 AM: Update 8254: task edges-pos-ontonotes, batch 254 (8254): mcc: 0.7039, acc: 0.5602, precision: 0.8809, recall: 0.5701, f1: 0.6922, edges-pos-ontonotes_loss: 0.0328
09/17 12:51:48 AM: Update 8310: task edges-pos-ontonotes, batch 310 (8310): mcc: 0.7052, acc: 0.5615, precision: 0.8819, recall: 0.5713, f1: 0.6934, edges-pos-ontonotes_loss: 0.0328
09/17 12:51:58 AM: Update 8361: task edges-pos-ontonotes, batch 361 (8361): mcc: 0.7057, acc: 0.5617, precision: 0.8829, recall: 0.5715, f1: 0.6938, edges-pos-ontonotes_loss: 0.0328
09/17 12:52:08 AM: Update 8414: task edges-pos-ontonotes, batch 414 (8414): mcc: 0.7068, acc: 0.5632, precision: 0.8835, recall: 0.5729, f1: 0.6950, edges-pos-ontonotes_loss: 0.0327
09/17 12:52:18 AM: Update 8467: task edges-pos-ontonotes, batch 467 (8467): mcc: 0.7074, acc: 0.5637, precision: 0.8840, recall: 0.5735, f1: 0.6957, edges-pos-ontonotes_loss: 0.0326
09/17 12:52:28 AM: Update 8500: task edges-pos-ontonotes, batch 500 (8500): mcc: 0.7075, acc: 0.5640, precision: 0.8842, recall: 0.5736, f1: 0.6958, edges-pos-ontonotes_loss: 0.0326
09/17 12:52:38 AM: Update 8544: task edges-pos-ontonotes, batch 544 (8544): mcc: 0.7075, acc: 0.5642, precision: 0.8839, recall: 0.5738, f1: 0.6958, edges-pos-ontonotes_loss: 0.0325
09/17 12:52:48 AM: Update 8593: task edges-pos-ontonotes, batch 593 (8593): mcc: 0.7079, acc: 0.5645, precision: 0.8843, recall: 0.5740, f1: 0.6962, edges-pos-ontonotes_loss: 0.0325
09/17 12:52:59 AM: Update 8639: task edges-pos-ontonotes, batch 639 (8639): mcc: 0.7081, acc: 0.5647, precision: 0.8845, recall: 0.5743, f1: 0.6964, edges-pos-ontonotes_loss: 0.0325
09/17 12:53:09 AM: Update 8692: task edges-pos-ontonotes, batch 692 (8692): mcc: 0.7083, acc: 0.5650, precision: 0.8845, recall: 0.5746, f1: 0.6967, edges-pos-ontonotes_loss: 0.0324
09/17 12:53:19 AM: Update 8745: task edges-pos-ontonotes, batch 745 (8745): mcc: 0.7087, acc: 0.5655, precision: 0.8848, recall: 0.5752, f1: 0.6971, edges-pos-ontonotes_loss: 0.0324
09/17 12:53:29 AM: Update 8788: task edges-pos-ontonotes, batch 788 (8788): mcc: 0.7088, acc: 0.5658, precision: 0.8847, recall: 0.5754, f1: 0.6972, edges-pos-ontonotes_loss: 0.0324
09/17 12:53:39 AM: Update 8823: task edges-pos-ontonotes, batch 823 (8823): mcc: 0.7088, acc: 0.5658, precision: 0.8841, recall: 0.5757, f1: 0.6973, edges-pos-ontonotes_loss: 0.0323
09/17 12:53:50 AM: Update 8874: task edges-pos-ontonotes, batch 874 (8874): mcc: 0.7099, acc: 0.5671, precision: 0.8845, recall: 0.5772, f1: 0.6986, edges-pos-ontonotes_loss: 0.0320
09/17 12:54:00 AM: Update 8938: task edges-pos-ontonotes, batch 938 (8938): mcc: 0.7115, acc: 0.5690, precision: 0.8853, recall: 0.5792, f1: 0.7002, edges-pos-ontonotes_loss: 0.0317
09/17 12:54:10 AM: Update 8990: task edges-pos-ontonotes, batch 990 (8990): mcc: 0.7125, acc: 0.5700, precision: 0.8859, recall: 0.5804, f1: 0.7013, edges-pos-ontonotes_loss: 0.0314
09/17 12:54:12 AM: ***** Step 9000 / Validation 9 *****
09/17 12:54:12 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 12:54:12 AM: Validating...
09/17 12:54:20 AM: Evaluate: task edges-pos-ontonotes, batch 56 (157): mcc: 0.7389, acc: 0.6039, precision: 0.9128, recall: 0.6049, f1: 0.7276, edges-pos-ontonotes_loss: 0.0294
09/17 12:54:30 AM: Evaluate: task edges-pos-ontonotes, batch 110 (157): mcc: 0.7297, acc: 0.5893, precision: 0.9126, recall: 0.5903, f1: 0.7169, edges-pos-ontonotes_loss: 0.0293
09/17 12:54:40 AM: Evaluate: task edges-pos-ontonotes, batch 152 (157): mcc: 0.7195, acc: 0.5737, precision: 0.9118, recall: 0.5746, f1: 0.7050, edges-pos-ontonotes_loss: 0.0299
09/17 12:54:41 AM: Updating LR scheduler:
09/17 12:54:41 AM: 	Best result seen so far for macro_avg: 0.715
09/17 12:54:41 AM: 	# validation passes without improvement: 1
09/17 12:54:41 AM: edges-pos-ontonotes_loss: training: 0.031379 validation: 0.029976
09/17 12:54:41 AM: macro_avg: validation: 0.703779
09/17 12:54:41 AM: micro_avg: validation: 0.000000
09/17 12:54:41 AM: edges-pos-ontonotes_mcc: training: 0.712677 validation: 0.718482
09/17 12:54:41 AM: edges-pos-ontonotes_acc: training: 0.570216 validation: 0.572198
09/17 12:54:41 AM: edges-pos-ontonotes_precision: training: 0.886016 validation: 0.911554
09/17 12:54:41 AM: edges-pos-ontonotes_recall: training: 0.580628 validation: 0.573140
09/17 12:54:41 AM: edges-pos-ontonotes_f1: training: 0.701528 validation: 0.703779
09/17 12:54:41 AM: Global learning rate: 0.0001
09/17 12:54:41 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 12:54:50 AM: Update 9061: task edges-pos-ontonotes, batch 61 (9061): mcc: 0.7441, acc: 0.6081, precision: 0.8999, recall: 0.6222, f1: 0.7357, edges-pos-ontonotes_loss: 0.0261
09/17 12:55:10 AM: Update 9112: task edges-pos-ontonotes, batch 112 (9112): mcc: 0.7440, acc: 0.6077, precision: 0.9006, recall: 0.6217, f1: 0.7356, edges-pos-ontonotes_loss: 0.0260
09/17 12:55:20 AM: Update 9232: task edges-pos-ontonotes, batch 232 (9232): mcc: 0.7718, acc: 0.6472, precision: 0.9084, recall: 0.6623, f1: 0.7661, edges-pos-ontonotes_loss: 0.0238
09/17 12:55:30 AM: Update 9336: task edges-pos-ontonotes, batch 336 (9336): mcc: 0.7846, acc: 0.6665, precision: 0.9107, recall: 0.6825, f1: 0.7802, edges-pos-ontonotes_loss: 0.0228
09/17 12:55:40 AM: Update 9436: task edges-pos-ontonotes, batch 436 (9436): mcc: 0.7915, acc: 0.6771, precision: 0.9111, recall: 0.6939, f1: 0.7878, edges-pos-ontonotes_loss: 0.0223
09/17 12:55:50 AM: Update 9569: task edges-pos-ontonotes, batch 569 (9569): mcc: 0.7934, acc: 0.6812, precision: 0.9092, recall: 0.6986, f1: 0.7901, edges-pos-ontonotes_loss: 0.0221
09/17 12:56:00 AM: Update 9723: task edges-pos-ontonotes, batch 723 (9723): mcc: 0.7968, acc: 0.6873, precision: 0.9087, recall: 0.7050, f1: 0.7940, edges-pos-ontonotes_loss: 0.0216
09/17 12:56:10 AM: Update 9876: task edges-pos-ontonotes, batch 876 (9876): mcc: 0.7949, acc: 0.6868, precision: 0.9055, recall: 0.7043, f1: 0.7923, edges-pos-ontonotes_loss: 0.0216
09/17 12:56:16 AM: ***** Step 10000 / Validation 10 *****
09/17 12:56:16 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 12:56:16 AM: Validating...
09/17 12:56:20 AM: Evaluate: task edges-pos-ontonotes, batch 36 (157): mcc: 0.7348, acc: 0.6122, precision: 0.8847, recall: 0.6176, f1: 0.7274, edges-pos-ontonotes_loss: 0.0304
09/17 12:56:30 AM: Evaluate: task edges-pos-ontonotes, batch 109 (157): mcc: 0.7283, acc: 0.5992, precision: 0.8891, recall: 0.6038, f1: 0.7192, edges-pos-ontonotes_loss: 0.0301
09/17 12:56:37 AM: Updating LR scheduler:
09/17 12:56:37 AM: 	Best result seen so far for macro_avg: 0.715
09/17 12:56:37 AM: 	# validation passes without improvement: 2
09/17 12:56:37 AM: edges-pos-ontonotes_loss: training: 0.021312 validation: 0.031836
09/17 12:56:37 AM: macro_avg: validation: 0.691335
09/17 12:56:37 AM: micro_avg: validation: 0.000000
09/17 12:56:37 AM: edges-pos-ontonotes_mcc: training: 0.795014 validation: 0.703562
09/17 12:56:37 AM: edges-pos-ontonotes_acc: training: 0.688096 validation: 0.564346
09/17 12:56:37 AM: edges-pos-ontonotes_precision: training: 0.904359 validation: 0.883020
09/17 12:56:37 AM: edges-pos-ontonotes_recall: training: 0.705332 validation: 0.568029
09/17 12:56:37 AM: edges-pos-ontonotes_f1: training: 0.792542 validation: 0.691335
09/17 12:56:37 AM: Global learning rate: 0.0001
09/17 12:56:37 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 12:56:40 AM: Update 10034: task edges-pos-ontonotes, batch 34 (10034): mcc: 0.7718, acc: 0.6716, precision: 0.8771, recall: 0.6865, f1: 0.7702, edges-pos-ontonotes_loss: 0.0222
09/17 12:56:50 AM: Update 10092: task edges-pos-ontonotes, batch 92 (10092): mcc: 0.7181, acc: 0.5916, precision: 0.8618, recall: 0.6062, f1: 0.7118, edges-pos-ontonotes_loss: 0.0282
09/17 12:57:00 AM: Update 10144: task edges-pos-ontonotes, batch 144 (10144): mcc: 0.7073, acc: 0.5763, precision: 0.8586, recall: 0.5907, f1: 0.6999, edges-pos-ontonotes_loss: 0.0306
09/17 12:57:10 AM: Update 10213: task edges-pos-ontonotes, batch 213 (10213): mcc: 0.7040, acc: 0.5707, precision: 0.8584, recall: 0.5855, f1: 0.6961, edges-pos-ontonotes_loss: 0.0317
09/17 12:57:20 AM: Update 10292: task edges-pos-ontonotes, batch 292 (10292): mcc: 0.7041, acc: 0.5701, precision: 0.8596, recall: 0.5846, f1: 0.6959, edges-pos-ontonotes_loss: 0.0322
09/17 12:57:30 AM: Update 10365: task edges-pos-ontonotes, batch 365 (10365): mcc: 0.7036, acc: 0.5690, precision: 0.8604, recall: 0.5834, f1: 0.6953, edges-pos-ontonotes_loss: 0.0324
09/17 12:57:41 AM: Update 10438: task edges-pos-ontonotes, batch 438 (10438): mcc: 0.7070, acc: 0.5736, precision: 0.8620, recall: 0.5879, f1: 0.6990, edges-pos-ontonotes_loss: 0.0317
09/17 12:57:51 AM: Update 10529: task edges-pos-ontonotes, batch 529 (10529): mcc: 0.7126, acc: 0.5813, precision: 0.8644, recall: 0.5953, f1: 0.7050, edges-pos-ontonotes_loss: 0.0307
09/17 12:58:01 AM: Update 10602: task edges-pos-ontonotes, batch 602 (10602): mcc: 0.7163, acc: 0.5863, precision: 0.8661, recall: 0.6002, f1: 0.7091, edges-pos-ontonotes_loss: 0.0300
09/17 12:58:11 AM: Update 10693: task edges-pos-ontonotes, batch 693 (10693): mcc: 0.7202, acc: 0.5914, precision: 0.8678, recall: 0.6054, f1: 0.7132, edges-pos-ontonotes_loss: 0.0292
09/17 12:58:21 AM: Update 10752: task edges-pos-ontonotes, batch 752 (10752): mcc: 0.7203, acc: 0.5913, precision: 0.8682, recall: 0.6053, f1: 0.7133, edges-pos-ontonotes_loss: 0.0292
09/17 12:58:31 AM: Update 10822: task edges-pos-ontonotes, batch 822 (10822): mcc: 0.7208, acc: 0.5914, precision: 0.8692, recall: 0.6054, f1: 0.7137, edges-pos-ontonotes_loss: 0.0292
09/17 12:58:41 AM: Update 10890: task edges-pos-ontonotes, batch 890 (10890): mcc: 0.7213, acc: 0.5918, precision: 0.8700, recall: 0.6058, f1: 0.7143, edges-pos-ontonotes_loss: 0.0291
09/17 12:58:51 AM: Update 10974: task edges-pos-ontonotes, batch 974 (10974): mcc: 0.7220, acc: 0.5923, precision: 0.8709, recall: 0.6063, f1: 0.7149, edges-pos-ontonotes_loss: 0.0290
09/17 12:58:54 AM: ***** Step 11000 / Validation 11 *****
09/17 12:58:54 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 12:58:54 AM: Validating...
09/17 12:59:01 AM: Evaluate: task edges-pos-ontonotes, batch 69 (157): mcc: 0.7598, acc: 0.6411, precision: 0.9075, recall: 0.6429, f1: 0.7527, edges-pos-ontonotes_loss: 0.0266
09/17 12:59:11 AM: Evaluate: task edges-pos-ontonotes, batch 139 (157): mcc: 0.7268, acc: 0.5931, precision: 0.8950, recall: 0.5974, f1: 0.7165, edges-pos-ontonotes_loss: 0.0285
09/17 12:59:14 AM: Updating LR scheduler:
09/17 12:59:14 AM: 	Best result seen so far for macro_avg: 0.715
09/17 12:59:14 AM: 	# validation passes without improvement: 3
09/17 12:59:14 AM: edges-pos-ontonotes_loss: training: 0.029032 validation: 0.028934
09/17 12:59:14 AM: macro_avg: validation: 0.712214
09/17 12:59:14 AM: micro_avg: validation: 0.000000
09/17 12:59:14 AM: edges-pos-ontonotes_mcc: training: 0.722137 validation: 0.722894
09/17 12:59:14 AM: edges-pos-ontonotes_acc: training: 0.592252 validation: 0.588156
09/17 12:59:14 AM: edges-pos-ontonotes_precision: training: 0.871147 validation: 0.893406
09/17 12:59:14 AM: edges-pos-ontonotes_recall: training: 0.606298 validation: 0.592125
09/17 12:59:14 AM: edges-pos-ontonotes_f1: training: 0.714984 validation: 0.712214
09/17 12:59:14 AM: Global learning rate: 0.0001
09/17 12:59:14 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 12:59:21 AM: Update 11041: task edges-pos-ontonotes, batch 41 (11041): mcc: 0.6941, acc: 0.5567, precision: 0.8489, recall: 0.5758, f1: 0.6862, edges-pos-ontonotes_loss: 0.0327
09/17 12:59:31 AM: Update 11108: task edges-pos-ontonotes, batch 108 (11108): mcc: 0.6987, acc: 0.5610, precision: 0.8568, recall: 0.5779, f1: 0.6902, edges-pos-ontonotes_loss: 0.0329
09/17 12:59:41 AM: Update 11178: task edges-pos-ontonotes, batch 178 (11178): mcc: 0.7010, acc: 0.5636, precision: 0.8599, recall: 0.5794, f1: 0.6923, edges-pos-ontonotes_loss: 0.0327
09/17 12:59:51 AM: Update 11252: task edges-pos-ontonotes, batch 252 (11252): mcc: 0.7012, acc: 0.5641, precision: 0.8597, recall: 0.5798, f1: 0.6926, edges-pos-ontonotes_loss: 0.0327
09/17 01:00:11 AM: Update 11320: task edges-pos-ontonotes, batch 320 (11320): mcc: 0.7022, acc: 0.5651, precision: 0.8607, recall: 0.5807, f1: 0.6936, edges-pos-ontonotes_loss: 0.0327
09/17 01:00:21 AM: Update 11389: task edges-pos-ontonotes, batch 389 (11389): mcc: 0.7017, acc: 0.5639, precision: 0.8625, recall: 0.5787, f1: 0.6927, edges-pos-ontonotes_loss: 0.0327
09/17 01:00:31 AM: Update 11451: task edges-pos-ontonotes, batch 451 (11451): mcc: 0.7014, acc: 0.5632, precision: 0.8638, recall: 0.5775, f1: 0.6922, edges-pos-ontonotes_loss: 0.0328
09/17 01:00:41 AM: Update 11516: task edges-pos-ontonotes, batch 516 (11516): mcc: 0.7017, acc: 0.5631, precision: 0.8652, recall: 0.5770, f1: 0.6923, edges-pos-ontonotes_loss: 0.0327
09/17 01:00:52 AM: Update 11559: task edges-pos-ontonotes, batch 559 (11559): mcc: 0.7022, acc: 0.5633, precision: 0.8661, recall: 0.5771, f1: 0.6926, edges-pos-ontonotes_loss: 0.0327
09/17 01:01:02 AM: Update 11599: task edges-pos-ontonotes, batch 599 (11599): mcc: 0.7025, acc: 0.5636, precision: 0.8668, recall: 0.5771, f1: 0.6929, edges-pos-ontonotes_loss: 0.0326
09/17 01:01:13 AM: Update 11633: task edges-pos-ontonotes, batch 633 (11633): mcc: 0.7028, acc: 0.5639, precision: 0.8674, recall: 0.5773, f1: 0.6932, edges-pos-ontonotes_loss: 0.0326
09/17 01:01:24 AM: Update 11675: task edges-pos-ontonotes, batch 675 (11675): mcc: 0.7034, acc: 0.5646, precision: 0.8680, recall: 0.5779, f1: 0.6938, edges-pos-ontonotes_loss: 0.0326
09/17 01:01:34 AM: Update 11739: task edges-pos-ontonotes, batch 739 (11739): mcc: 0.7043, acc: 0.5654, precision: 0.8694, recall: 0.5784, f1: 0.6946, edges-pos-ontonotes_loss: 0.0325
09/17 01:01:44 AM: Update 11788: task edges-pos-ontonotes, batch 788 (11788): mcc: 0.7048, acc: 0.5659, precision: 0.8701, recall: 0.5787, f1: 0.6951, edges-pos-ontonotes_loss: 0.0324
09/17 01:01:54 AM: Update 11841: task edges-pos-ontonotes, batch 841 (11841): mcc: 0.7054, acc: 0.5664, precision: 0.8710, recall: 0.5790, f1: 0.6956, edges-pos-ontonotes_loss: 0.0324
09/17 01:02:04 AM: Update 11885: task edges-pos-ontonotes, batch 885 (11885): mcc: 0.7059, acc: 0.5668, precision: 0.8715, recall: 0.5794, f1: 0.6961, edges-pos-ontonotes_loss: 0.0323
09/17 01:02:14 AM: Update 11927: task edges-pos-ontonotes, batch 927 (11927): mcc: 0.7060, acc: 0.5670, precision: 0.8717, recall: 0.5795, f1: 0.6962, edges-pos-ontonotes_loss: 0.0323
09/17 01:02:25 AM: Update 11953: task edges-pos-ontonotes, batch 953 (11953): mcc: 0.7063, acc: 0.5674, precision: 0.8721, recall: 0.5797, f1: 0.6965, edges-pos-ontonotes_loss: 0.0323
09/17 01:02:35 AM: Update 11992: task edges-pos-ontonotes, batch 992 (11992): mcc: 0.7065, acc: 0.5676, precision: 0.8723, recall: 0.5799, f1: 0.6967, edges-pos-ontonotes_loss: 0.0322
09/17 01:02:37 AM: ***** Step 12000 / Validation 12 *****
09/17 01:02:37 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:02:37 AM: Validating...
09/17 01:02:45 AM: Evaluate: task edges-pos-ontonotes, batch 62 (157): mcc: 0.7480, acc: 0.6297, precision: 0.8969, recall: 0.6308, f1: 0.7407, edges-pos-ontonotes_loss: 0.0284
09/17 01:02:55 AM: Evaluate: task edges-pos-ontonotes, batch 135 (157): mcc: 0.7279, acc: 0.5960, precision: 0.8934, recall: 0.6002, f1: 0.7181, edges-pos-ontonotes_loss: 0.0291
09/17 01:02:58 AM: Best result seen so far for edges-pos-ontonotes.
09/17 01:02:58 AM: Best result seen so far for macro.
09/17 01:02:58 AM: Updating LR scheduler:
09/17 01:02:58 AM: 	Best result seen so far for macro_avg: 0.716
09/17 01:02:58 AM: 	# validation passes without improvement: 0
09/17 01:02:58 AM: edges-pos-ontonotes_loss: training: 0.032242 validation: 0.029192
09/17 01:02:58 AM: macro_avg: validation: 0.715963
09/17 01:02:58 AM: micro_avg: validation: 0.000000
09/17 01:02:58 AM: edges-pos-ontonotes_mcc: training: 0.706539 validation: 0.726263
09/17 01:02:58 AM: edges-pos-ontonotes_acc: training: 0.567621 validation: 0.593193
09/17 01:02:58 AM: edges-pos-ontonotes_precision: training: 0.872388 validation: 0.894486
09/17 01:02:58 AM: edges-pos-ontonotes_recall: training: 0.579905 validation: 0.596844
09/17 01:02:58 AM: edges-pos-ontonotes_f1: training: 0.696695 validation: 0.715963
09/17 01:02:58 AM: Global learning rate: 0.0001
09/17 01:02:58 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 01:03:05 AM: Update 12047: task edges-pos-ontonotes, batch 47 (12047): mcc: 0.7087, acc: 0.5673, precision: 0.8790, recall: 0.5789, f1: 0.6981, edges-pos-ontonotes_loss: 0.0314
09/17 01:03:15 AM: Update 12117: task edges-pos-ontonotes, batch 117 (12117): mcc: 0.7109, acc: 0.5708, precision: 0.8795, recall: 0.5821, f1: 0.7005, edges-pos-ontonotes_loss: 0.0314
09/17 01:03:25 AM: Update 12193: task edges-pos-ontonotes, batch 193 (12193): mcc: 0.7133, acc: 0.5732, precision: 0.8818, recall: 0.5844, f1: 0.7029, edges-pos-ontonotes_loss: 0.0314
09/17 01:03:35 AM: Update 12258: task edges-pos-ontonotes, batch 258 (12258): mcc: 0.7142, acc: 0.5744, precision: 0.8822, recall: 0.5856, f1: 0.7039, edges-pos-ontonotes_loss: 0.0313
09/17 01:03:45 AM: Update 12318: task edges-pos-ontonotes, batch 318 (12318): mcc: 0.7152, acc: 0.5761, precision: 0.8812, recall: 0.5880, f1: 0.7054, edges-pos-ontonotes_loss: 0.0307
09/17 01:03:55 AM: Update 12408: task edges-pos-ontonotes, batch 408 (12408): mcc: 0.7201, acc: 0.5815, precision: 0.8843, recall: 0.5938, f1: 0.7105, edges-pos-ontonotes_loss: 0.0297
09/17 01:04:05 AM: Update 12459: task edges-pos-ontonotes, batch 459 (12459): mcc: 0.7223, acc: 0.5840, precision: 0.8856, recall: 0.5965, f1: 0.7129, edges-pos-ontonotes_loss: 0.0292
09/17 01:04:16 AM: Update 12501: task edges-pos-ontonotes, batch 501 (12501): mcc: 0.7231, acc: 0.5848, precision: 0.8862, recall: 0.5974, f1: 0.7137, edges-pos-ontonotes_loss: 0.0290
09/17 01:04:26 AM: Update 12546: task edges-pos-ontonotes, batch 546 (12546): mcc: 0.7244, acc: 0.5862, precision: 0.8869, recall: 0.5991, f1: 0.7151, edges-pos-ontonotes_loss: 0.0288
09/17 01:04:36 AM: Update 12583: task edges-pos-ontonotes, batch 583 (12583): mcc: 0.7265, acc: 0.5888, precision: 0.8878, recall: 0.6019, f1: 0.7174, edges-pos-ontonotes_loss: 0.0285
09/17 01:04:46 AM: Update 12647: task edges-pos-ontonotes, batch 647 (12647): mcc: 0.7324, acc: 0.5965, precision: 0.8900, recall: 0.6099, f1: 0.7238, edges-pos-ontonotes_loss: 0.0278
09/17 01:04:56 AM: Update 12715: task edges-pos-ontonotes, batch 715 (12715): mcc: 0.7378, acc: 0.6038, precision: 0.8918, recall: 0.6175, f1: 0.7297, edges-pos-ontonotes_loss: 0.0271
09/17 01:05:06 AM: Update 12790: task edges-pos-ontonotes, batch 790 (12790): mcc: 0.7435, acc: 0.6117, precision: 0.8935, recall: 0.6258, f1: 0.7361, edges-pos-ontonotes_loss: 0.0264
09/17 01:05:16 AM: Update 12877: task edges-pos-ontonotes, batch 877 (12877): mcc: 0.7493, acc: 0.6196, precision: 0.8954, recall: 0.6341, f1: 0.7424, edges-pos-ontonotes_loss: 0.0257
09/17 01:05:26 AM: Update 12996: task edges-pos-ontonotes, batch 996 (12996): mcc: 0.7536, acc: 0.6259, precision: 0.8961, recall: 0.6407, f1: 0.7472, edges-pos-ontonotes_loss: 0.0252
09/17 01:05:26 AM: ***** Step 13000 / Validation 13 *****
09/17 01:05:26 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:05:26 AM: Validating...
09/17 01:05:36 AM: Evaluate: task edges-pos-ontonotes, batch 94 (157): mcc: 0.7279, acc: 0.6032, precision: 0.8873, recall: 0.6045, f1: 0.7191, edges-pos-ontonotes_loss: 0.0286
09/17 01:05:46 AM: Updating LR scheduler:
09/17 01:05:46 AM: 	Best result seen so far for macro_avg: 0.716
09/17 01:05:46 AM: 	# validation passes without improvement: 1
09/17 01:05:46 AM: edges-pos-ontonotes_loss: training: 0.025148 validation: 0.030177
09/17 01:05:46 AM: macro_avg: validation: 0.689735
09/17 01:05:46 AM: micro_avg: validation: 0.000000
09/17 01:05:46 AM: edges-pos-ontonotes_mcc: training: 0.753650 validation: 0.701944
09/17 01:05:46 AM: edges-pos-ontonotes_acc: training: 0.626056 validation: 0.562854
09/17 01:05:46 AM: edges-pos-ontonotes_precision: training: 0.896072 validation: 0.881302
09/17 01:05:46 AM: edges-pos-ontonotes_recall: training: 0.640865 validation: 0.566579
09/17 01:05:46 AM: edges-pos-ontonotes_f1: training: 0.747280 validation: 0.689735
09/17 01:05:46 AM: Global learning rate: 0.0001
09/17 01:05:46 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 01:05:46 AM: Update 13004: task edges-pos-ontonotes, batch 4 (13004): mcc: 0.8134, acc: 0.7165, precision: 0.9034, recall: 0.7385, f1: 0.8127, edges-pos-ontonotes_loss: 0.0215
09/17 01:05:56 AM: Update 13137: task edges-pos-ontonotes, batch 137 (13137): mcc: 0.8117, acc: 0.7163, precision: 0.9031, recall: 0.7359, f1: 0.8110, edges-pos-ontonotes_loss: 0.0199
09/17 01:06:06 AM: Update 13281: task edges-pos-ontonotes, batch 281 (13281): mcc: 0.8041, acc: 0.7074, precision: 0.8971, recall: 0.7271, f1: 0.8032, edges-pos-ontonotes_loss: 0.0200
09/17 01:06:16 AM: Update 13442: task edges-pos-ontonotes, batch 442 (13442): mcc: 0.7991, acc: 0.7029, precision: 0.8933, recall: 0.7213, f1: 0.7982, edges-pos-ontonotes_loss: 0.0202
09/17 01:06:31 AM: Update 13511: task edges-pos-ontonotes, batch 511 (13511): mcc: 0.7965, acc: 0.6998, precision: 0.8918, recall: 0.7180, f1: 0.7955, edges-pos-ontonotes_loss: 0.0202
09/17 01:06:41 AM: Update 13583: task edges-pos-ontonotes, batch 583 (13583): mcc: 0.7718, acc: 0.6646, precision: 0.8823, recall: 0.6822, f1: 0.7695, edges-pos-ontonotes_loss: 0.0219
09/17 01:06:51 AM: Update 13636: task edges-pos-ontonotes, batch 636 (13636): mcc: 0.7616, acc: 0.6504, precision: 0.8787, recall: 0.6674, f1: 0.7586, edges-pos-ontonotes_loss: 0.0229
09/17 01:07:01 AM: Update 13706: task edges-pos-ontonotes, batch 706 (13706): mcc: 0.7517, acc: 0.6362, precision: 0.8752, recall: 0.6530, f1: 0.7480, edges-pos-ontonotes_loss: 0.0239
09/17 01:07:11 AM: Update 13754: task edges-pos-ontonotes, batch 754 (13754): mcc: 0.7464, acc: 0.6283, precision: 0.8737, recall: 0.6452, f1: 0.7422, edges-pos-ontonotes_loss: 0.0245
09/17 01:07:21 AM: Update 13814: task edges-pos-ontonotes, batch 814 (13814): mcc: 0.7421, acc: 0.6220, precision: 0.8728, recall: 0.6385, f1: 0.7375, edges-pos-ontonotes_loss: 0.0251
09/17 01:07:32 AM: Update 13851: task edges-pos-ontonotes, batch 851 (13851): mcc: 0.7399, acc: 0.6188, precision: 0.8722, recall: 0.6353, f1: 0.7351, edges-pos-ontonotes_loss: 0.0254
09/17 01:07:42 AM: Update 13919: task edges-pos-ontonotes, batch 919 (13919): mcc: 0.7405, acc: 0.6198, precision: 0.8727, recall: 0.6360, f1: 0.7358, edges-pos-ontonotes_loss: 0.0254
09/17 01:07:52 AM: Update 13977: task edges-pos-ontonotes, batch 977 (13977): mcc: 0.7409, acc: 0.6204, precision: 0.8729, recall: 0.6365, f1: 0.7362, edges-pos-ontonotes_loss: 0.0254
09/17 01:07:56 AM: ***** Step 14000 / Validation 14 *****
09/17 01:07:56 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:07:56 AM: Validating...
09/17 01:08:02 AM: Evaluate: task edges-pos-ontonotes, batch 36 (157): mcc: 0.7423, acc: 0.6135, precision: 0.9061, recall: 0.6150, f1: 0.7327, edges-pos-ontonotes_loss: 0.0278
09/17 01:08:12 AM: Evaluate: task edges-pos-ontonotes, batch 89 (157): mcc: 0.7503, acc: 0.6255, precision: 0.9073, recall: 0.6272, f1: 0.7417, edges-pos-ontonotes_loss: 0.0270
09/17 01:08:22 AM: Evaluate: task edges-pos-ontonotes, batch 126 (157): mcc: 0.7276, acc: 0.5929, precision: 0.8969, recall: 0.5973, f1: 0.7171, edges-pos-ontonotes_loss: 0.0283
09/17 01:08:31 AM: Updating LR scheduler:
09/17 01:08:31 AM: 	Best result seen so far for macro_avg: 0.716
09/17 01:08:31 AM: 	# validation passes without improvement: 2
09/17 01:08:31 AM: edges-pos-ontonotes_loss: training: 0.025391 validation: 0.029106
09/17 01:08:31 AM: macro_avg: validation: 0.706645
09/17 01:08:31 AM: micro_avg: validation: 0.000000
09/17 01:08:31 AM: edges-pos-ontonotes_mcc: training: 0.741029 validation: 0.718399
09/17 01:08:31 AM: edges-pos-ontonotes_acc: training: 0.620513 validation: 0.579352
09/17 01:08:31 AM: edges-pos-ontonotes_precision: training: 0.872984 validation: 0.895149
09/17 01:08:31 AM: edges-pos-ontonotes_recall: training: 0.636579 validation: 0.583722
09/17 01:08:31 AM: edges-pos-ontonotes_f1: training: 0.736270 validation: 0.706645
09/17 01:08:31 AM: Global learning rate: 0.0001
09/17 01:08:31 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 01:08:32 AM: Update 14008: task edges-pos-ontonotes, batch 8 (14008): mcc: 0.7530, acc: 0.6363, precision: 0.8846, recall: 0.6483, f1: 0.7482, edges-pos-ontonotes_loss: 0.0250
09/17 01:08:42 AM: Update 14097: task edges-pos-ontonotes, batch 97 (14097): mcc: 0.7608, acc: 0.6469, precision: 0.8838, recall: 0.6620, f1: 0.7570, edges-pos-ontonotes_loss: 0.0239
09/17 01:08:53 AM: Update 14155: task edges-pos-ontonotes, batch 155 (14155): mcc: 0.7565, acc: 0.6413, precision: 0.8823, recall: 0.6558, f1: 0.7524, edges-pos-ontonotes_loss: 0.0242
09/17 01:09:03 AM: Update 14218: task edges-pos-ontonotes, batch 218 (14218): mcc: 0.7455, acc: 0.6248, precision: 0.8796, recall: 0.6392, f1: 0.7404, edges-pos-ontonotes_loss: 0.0256
09/17 01:09:13 AM: Update 14285: task edges-pos-ontonotes, batch 285 (14285): mcc: 0.7401, acc: 0.6163, precision: 0.8781, recall: 0.6312, f1: 0.7345, edges-pos-ontonotes_loss: 0.0263
09/17 01:09:23 AM: Update 14339: task edges-pos-ontonotes, batch 339 (14339): mcc: 0.7374, acc: 0.6119, precision: 0.8775, recall: 0.6271, f1: 0.7315, edges-pos-ontonotes_loss: 0.0266
09/17 01:09:33 AM: Update 14400: task edges-pos-ontonotes, batch 400 (14400): mcc: 0.7366, acc: 0.6106, precision: 0.8778, recall: 0.6255, f1: 0.7305, edges-pos-ontonotes_loss: 0.0268
09/17 01:09:43 AM: Update 14456: task edges-pos-ontonotes, batch 456 (14456): mcc: 0.7360, acc: 0.6098, precision: 0.8776, recall: 0.6247, f1: 0.7298, edges-pos-ontonotes_loss: 0.0270
09/17 01:09:53 AM: Update 14510: task edges-pos-ontonotes, batch 510 (14510): mcc: 0.7303, acc: 0.6020, precision: 0.8740, recall: 0.6178, f1: 0.7239, edges-pos-ontonotes_loss: 0.0275
09/17 01:10:03 AM: Update 14581: task edges-pos-ontonotes, batch 581 (14581): mcc: 0.7259, acc: 0.5966, precision: 0.8718, recall: 0.6121, f1: 0.7192, edges-pos-ontonotes_loss: 0.0282
09/17 01:10:13 AM: Update 14650: task edges-pos-ontonotes, batch 650 (14650): mcc: 0.7230, acc: 0.5928, precision: 0.8700, recall: 0.6085, f1: 0.7161, edges-pos-ontonotes_loss: 0.0287
09/17 01:10:24 AM: Update 14711: task edges-pos-ontonotes, batch 711 (14711): mcc: 0.7215, acc: 0.5907, precision: 0.8692, recall: 0.6065, f1: 0.7145, edges-pos-ontonotes_loss: 0.0289
09/17 01:10:34 AM: Update 14758: task edges-pos-ontonotes, batch 758 (14758): mcc: 0.7206, acc: 0.5895, precision: 0.8688, recall: 0.6054, f1: 0.7136, edges-pos-ontonotes_loss: 0.0291
09/17 01:10:44 AM: Update 14790: task edges-pos-ontonotes, batch 790 (14790): mcc: 0.7199, acc: 0.5885, precision: 0.8688, recall: 0.6043, f1: 0.7128, edges-pos-ontonotes_loss: 0.0292
09/17 01:10:54 AM: Update 14836: task edges-pos-ontonotes, batch 836 (14836): mcc: 0.7187, acc: 0.5868, precision: 0.8687, recall: 0.6024, f1: 0.7114, edges-pos-ontonotes_loss: 0.0294
09/17 01:11:04 AM: Update 14883: task edges-pos-ontonotes, batch 883 (14883): mcc: 0.7176, acc: 0.5852, precision: 0.8686, recall: 0.6006, f1: 0.7102, edges-pos-ontonotes_loss: 0.0295
09/17 01:11:14 AM: Update 14924: task edges-pos-ontonotes, batch 924 (14924): mcc: 0.7170, acc: 0.5841, precision: 0.8690, recall: 0.5993, f1: 0.7094, edges-pos-ontonotes_loss: 0.0296
09/17 01:11:24 AM: Update 14973: task edges-pos-ontonotes, batch 973 (14973): mcc: 0.7162, acc: 0.5828, precision: 0.8691, recall: 0.5980, f1: 0.7085, edges-pos-ontonotes_loss: 0.0297
09/17 01:11:28 AM: ***** Step 15000 / Validation 15 *****
09/17 01:11:28 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:11:28 AM: Validating...
09/17 01:11:34 AM: Evaluate: task edges-pos-ontonotes, batch 67 (157): mcc: 0.7503, acc: 0.6366, precision: 0.8935, recall: 0.6372, f1: 0.7439, edges-pos-ontonotes_loss: 0.0272
09/17 01:11:44 AM: Evaluate: task edges-pos-ontonotes, batch 139 (157): mcc: 0.7316, acc: 0.6043, precision: 0.8952, recall: 0.6050, f1: 0.7220, edges-pos-ontonotes_loss: 0.0282
09/17 01:11:47 AM: Best result seen so far for edges-pos-ontonotes.
09/17 01:11:47 AM: Best result seen so far for macro.
09/17 01:11:47 AM: Updating LR scheduler:
09/17 01:11:47 AM: 	Best result seen so far for macro_avg: 0.720
09/17 01:11:47 AM: 	# validation passes without improvement: 0
09/17 01:11:47 AM: edges-pos-ontonotes_loss: training: 0.029790 validation: 0.028429
09/17 01:11:47 AM: macro_avg: validation: 0.719836
09/17 01:11:47 AM: micro_avg: validation: 0.000000
09/17 01:11:47 AM: edges-pos-ontonotes_mcc: training: 0.716092 validation: 0.729631
09/17 01:11:47 AM: edges-pos-ontonotes_acc: training: 0.582548 validation: 0.601448
09/17 01:11:47 AM: edges-pos-ontonotes_precision: training: 0.869317 validation: 0.894777
09/17 01:11:47 AM: edges-pos-ontonotes_recall: training: 0.597613 validation: 0.602114
09/17 01:11:47 AM: edges-pos-ontonotes_f1: training: 0.708303 validation: 0.719836
09/17 01:11:47 AM: Global learning rate: 0.0001
09/17 01:11:47 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 01:11:54 AM: Update 15048: task edges-pos-ontonotes, batch 48 (15048): mcc: 0.7078, acc: 0.5699, precision: 0.8722, recall: 0.5821, f1: 0.6982, edges-pos-ontonotes_loss: 0.0318
09/17 01:12:11 AM: Update 15093: task edges-pos-ontonotes, batch 93 (15093): mcc: 0.7075, acc: 0.5695, precision: 0.8725, recall: 0.5814, f1: 0.6978, edges-pos-ontonotes_loss: 0.0320
09/17 01:12:21 AM: Update 15157: task edges-pos-ontonotes, batch 157 (15157): mcc: 0.7102, acc: 0.5728, precision: 0.8749, recall: 0.5842, f1: 0.7006, edges-pos-ontonotes_loss: 0.0318
09/17 01:12:31 AM: Update 15207: task edges-pos-ontonotes, batch 207 (15207): mcc: 0.7111, acc: 0.5737, precision: 0.8762, recall: 0.5846, f1: 0.7013, edges-pos-ontonotes_loss: 0.0317
09/17 01:12:41 AM: Update 15250: task edges-pos-ontonotes, batch 250 (15250): mcc: 0.7114, acc: 0.5740, precision: 0.8767, recall: 0.5848, f1: 0.7016, edges-pos-ontonotes_loss: 0.0317
09/17 01:12:52 AM: Update 15296: task edges-pos-ontonotes, batch 296 (15296): mcc: 0.7120, acc: 0.5746, precision: 0.8771, recall: 0.5856, f1: 0.7023, edges-pos-ontonotes_loss: 0.0316
09/17 01:13:02 AM: Update 15352: task edges-pos-ontonotes, batch 352 (15352): mcc: 0.7130, acc: 0.5757, precision: 0.8779, recall: 0.5866, f1: 0.7033, edges-pos-ontonotes_loss: 0.0315
09/17 01:13:12 AM: Update 15399: task edges-pos-ontonotes, batch 399 (15399): mcc: 0.7137, acc: 0.5765, precision: 0.8783, recall: 0.5875, f1: 0.7041, edges-pos-ontonotes_loss: 0.0314
09/17 01:13:22 AM: Update 15433: task edges-pos-ontonotes, batch 433 (15433): mcc: 0.7136, acc: 0.5765, precision: 0.8782, recall: 0.5874, f1: 0.7040, edges-pos-ontonotes_loss: 0.0314
09/17 01:13:32 AM: Update 15479: task edges-pos-ontonotes, batch 479 (15479): mcc: 0.7135, acc: 0.5763, precision: 0.8780, recall: 0.5873, f1: 0.7038, edges-pos-ontonotes_loss: 0.0314
09/17 01:13:42 AM: Update 15525: task edges-pos-ontonotes, batch 525 (15525): mcc: 0.7133, acc: 0.5759, precision: 0.8782, recall: 0.5870, f1: 0.7037, edges-pos-ontonotes_loss: 0.0313
09/17 01:13:52 AM: Update 15579: task edges-pos-ontonotes, batch 579 (15579): mcc: 0.7136, acc: 0.5762, precision: 0.8785, recall: 0.5872, f1: 0.7039, edges-pos-ontonotes_loss: 0.0313
09/17 01:14:02 AM: Update 15647: task edges-pos-ontonotes, batch 647 (15647): mcc: 0.7139, acc: 0.5766, precision: 0.8785, recall: 0.5877, f1: 0.7043, edges-pos-ontonotes_loss: 0.0312
09/17 01:14:12 AM: Update 15718: task edges-pos-ontonotes, batch 718 (15718): mcc: 0.7143, acc: 0.5770, precision: 0.8789, recall: 0.5880, f1: 0.7046, edges-pos-ontonotes_loss: 0.0312
09/17 01:14:23 AM: Update 15767: task edges-pos-ontonotes, batch 767 (15767): mcc: 0.7143, acc: 0.5770, precision: 0.8783, recall: 0.5885, f1: 0.7047, edges-pos-ontonotes_loss: 0.0310
09/17 01:14:33 AM: Update 15825: task edges-pos-ontonotes, batch 825 (15825): mcc: 0.7158, acc: 0.5787, precision: 0.8791, recall: 0.5903, f1: 0.7063, edges-pos-ontonotes_loss: 0.0307
09/17 01:14:43 AM: Update 15906: task edges-pos-ontonotes, batch 906 (15906): mcc: 0.7173, acc: 0.5802, precision: 0.8801, recall: 0.5921, f1: 0.7079, edges-pos-ontonotes_loss: 0.0303
09/17 01:14:53 AM: Update 15995: task edges-pos-ontonotes, batch 995 (15995): mcc: 0.7197, acc: 0.5829, precision: 0.8816, recall: 0.5951, f1: 0.7105, edges-pos-ontonotes_loss: 0.0298
09/17 01:14:53 AM: ***** Step 16000 / Validation 16 *****
09/17 01:14:53 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:14:53 AM: Validating...
09/17 01:15:03 AM: Evaluate: task edges-pos-ontonotes, batch 90 (157): mcc: 0.7422, acc: 0.6143, precision: 0.9048, recall: 0.6158, f1: 0.7328, edges-pos-ontonotes_loss: 0.0281
09/17 01:15:13 AM: Evaluate: task edges-pos-ontonotes, batch 156 (157): mcc: 0.7227, acc: 0.5833, precision: 0.9042, recall: 0.5845, f1: 0.7100, edges-pos-ontonotes_loss: 0.0291
09/17 01:15:13 AM: Updating LR scheduler:
09/17 01:15:13 AM: 	Best result seen so far for macro_avg: 0.720
09/17 01:15:13 AM: 	# validation passes without improvement: 1
09/17 01:15:13 AM: edges-pos-ontonotes_loss: training: 0.029791 validation: 0.029061
09/17 01:15:13 AM: macro_avg: validation: 0.710010
09/17 01:15:13 AM: micro_avg: validation: 0.000000
09/17 01:15:13 AM: edges-pos-ontonotes_mcc: training: 0.719796 validation: 0.722621
09/17 01:15:13 AM: edges-pos-ontonotes_acc: training: 0.582909 validation: 0.583278
09/17 01:15:13 AM: edges-pos-ontonotes_precision: training: 0.881667 validation: 0.904198
09/17 01:15:13 AM: edges-pos-ontonotes_recall: training: 0.595102 validation: 0.584484
09/17 01:15:13 AM: edges-pos-ontonotes_f1: training: 0.710581 validation: 0.710010
09/17 01:15:13 AM: Global learning rate: 0.0001
09/17 01:15:13 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 01:15:23 AM: Update 16081: task edges-pos-ontonotes, batch 81 (16081): mcc: 0.7750, acc: 0.6544, precision: 0.9042, recall: 0.6709, f1: 0.7703, edges-pos-ontonotes_loss: 0.0230
09/17 01:15:33 AM: Update 16195: task edges-pos-ontonotes, batch 195 (16195): mcc: 0.7968, acc: 0.6858, precision: 0.9100, recall: 0.7040, f1: 0.7939, edges-pos-ontonotes_loss: 0.0214
09/17 01:15:43 AM: Update 16313: task edges-pos-ontonotes, batch 313 (16313): mcc: 0.8055, acc: 0.6990, precision: 0.9117, recall: 0.7179, f1: 0.8032, edges-pos-ontonotes_loss: 0.0207
09/17 01:15:53 AM: Update 16397: task edges-pos-ontonotes, batch 397 (16397): mcc: 0.8060, acc: 0.7009, precision: 0.9101, recall: 0.7200, f1: 0.8040, edges-pos-ontonotes_loss: 0.0208
09/17 01:16:03 AM: Update 16493: task edges-pos-ontonotes, batch 493 (16493): mcc: 0.8068, acc: 0.7030, precision: 0.9092, recall: 0.7222, f1: 0.8049, edges-pos-ontonotes_loss: 0.0205
09/17 01:16:13 AM: Update 16584: task edges-pos-ontonotes, batch 584 (16584): mcc: 0.8078, acc: 0.7051, precision: 0.9084, recall: 0.7245, f1: 0.8061, edges-pos-ontonotes_loss: 0.0204
09/17 01:16:25 AM: Update 16658: task edges-pos-ontonotes, batch 658 (16658): mcc: 0.8087, acc: 0.7069, precision: 0.9079, recall: 0.7264, f1: 0.8071, edges-pos-ontonotes_loss: 0.0202
09/17 01:16:35 AM: Update 16751: task edges-pos-ontonotes, batch 751 (16751): mcc: 0.8061, acc: 0.7047, precision: 0.9053, recall: 0.7241, f1: 0.8046, edges-pos-ontonotes_loss: 0.0204
09/17 01:16:45 AM: Update 16856: task edges-pos-ontonotes, batch 856 (16856): mcc: 0.8047, acc: 0.7040, precision: 0.9034, recall: 0.7232, f1: 0.8033, edges-pos-ontonotes_loss: 0.0203
09/17 01:16:57 AM: Update 16971: task edges-pos-ontonotes, batch 971 (16971): mcc: 0.8027, acc: 0.7023, precision: 0.9014, recall: 0.7212, f1: 0.8013, edges-pos-ontonotes_loss: 0.0202
09/17 01:17:04 AM: ***** Step 17000 / Validation 17 *****
09/17 01:17:04 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:17:04 AM: Validating...
09/17 01:17:07 AM: Evaluate: task edges-pos-ontonotes, batch 20 (157): mcc: 0.7178, acc: 0.5906, precision: 0.8827, recall: 0.5910, f1: 0.7080, edges-pos-ontonotes_loss: 0.0303
09/17 01:17:17 AM: Evaluate: task edges-pos-ontonotes, batch 108 (157): mcc: 0.7332, acc: 0.6088, precision: 0.8924, recall: 0.6096, f1: 0.7244, edges-pos-ontonotes_loss: 0.0285
09/17 01:17:24 AM: Updating LR scheduler:
09/17 01:17:24 AM: 	Best result seen so far for macro_avg: 0.720
09/17 01:17:24 AM: 	# validation passes without improvement: 2
09/17 01:17:24 AM: edges-pos-ontonotes_loss: training: 0.020654 validation: 0.030095
09/17 01:17:24 AM: macro_avg: validation: 0.696242
09/17 01:17:24 AM: micro_avg: validation: 0.000000
09/17 01:17:24 AM: edges-pos-ontonotes_mcc: training: 0.795348 validation: 0.707890
09/17 01:17:24 AM: edges-pos-ontonotes_acc: training: 0.692045 validation: 0.573288
09/17 01:17:24 AM: edges-pos-ontonotes_precision: training: 0.898004 validation: 0.884093
09/17 01:17:24 AM: edges-pos-ontonotes_recall: training: 0.710981 validation: 0.574230
09/17 01:17:24 AM: edges-pos-ontonotes_f1: training: 0.793623 validation: 0.696242
09/17 01:17:24 AM: Global learning rate: 0.0001
09/17 01:17:24 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 01:17:27 AM: Update 17021: task edges-pos-ontonotes, batch 21 (17021): mcc: 0.6934, acc: 0.5624, precision: 0.8431, recall: 0.5787, f1: 0.6863, edges-pos-ontonotes_loss: 0.0339
09/17 01:17:37 AM: Update 17078: task edges-pos-ontonotes, batch 78 (17078): mcc: 0.6964, acc: 0.5635, precision: 0.8482, recall: 0.5801, f1: 0.6890, edges-pos-ontonotes_loss: 0.0334
09/17 01:17:47 AM: Update 17141: task edges-pos-ontonotes, batch 141 (17141): mcc: 0.6994, acc: 0.5660, precision: 0.8519, recall: 0.5824, f1: 0.6918, edges-pos-ontonotes_loss: 0.0332
09/17 01:17:57 AM: Update 17191: task edges-pos-ontonotes, batch 191 (17191): mcc: 0.7006, acc: 0.5669, precision: 0.8536, recall: 0.5832, f1: 0.6929, edges-pos-ontonotes_loss: 0.0332
09/17 01:18:07 AM: Update 17245: task edges-pos-ontonotes, batch 245 (17245): mcc: 0.7016, acc: 0.5679, precision: 0.8551, recall: 0.5837, f1: 0.6938, edges-pos-ontonotes_loss: 0.0332
09/17 01:18:17 AM: Update 17300: task edges-pos-ontonotes, batch 300 (17300): mcc: 0.7016, acc: 0.5677, precision: 0.8556, recall: 0.5834, f1: 0.6938, edges-pos-ontonotes_loss: 0.0331
09/17 01:18:28 AM: Update 17301: task edges-pos-ontonotes, batch 301 (17301): mcc: 0.7017, acc: 0.5678, precision: 0.8556, recall: 0.5835, f1: 0.6939, edges-pos-ontonotes_loss: 0.0331
09/17 01:18:38 AM: Update 17380: task edges-pos-ontonotes, batch 380 (17380): mcc: 0.7087, acc: 0.5775, precision: 0.8582, recall: 0.5932, f1: 0.7015, edges-pos-ontonotes_loss: 0.0314
09/17 01:18:48 AM: Update 17461: task edges-pos-ontonotes, batch 461 (17461): mcc: 0.7144, acc: 0.5849, precision: 0.8614, recall: 0.6004, f1: 0.7076, edges-pos-ontonotes_loss: 0.0303
09/17 01:18:58 AM: Update 17540: task edges-pos-ontonotes, batch 540 (17540): mcc: 0.7187, acc: 0.5907, precision: 0.8633, recall: 0.6061, f1: 0.7122, edges-pos-ontonotes_loss: 0.0293
09/17 01:19:10 AM: Update 17614: task edges-pos-ontonotes, batch 614 (17614): mcc: 0.7222, acc: 0.5954, precision: 0.8652, recall: 0.6107, f1: 0.7160, edges-pos-ontonotes_loss: 0.0287
09/17 01:19:20 AM: Update 17677: task edges-pos-ontonotes, batch 677 (17677): mcc: 0.7223, acc: 0.5953, precision: 0.8653, recall: 0.6107, f1: 0.7161, edges-pos-ontonotes_loss: 0.0287
09/17 01:19:30 AM: Update 17742: task edges-pos-ontonotes, batch 742 (17742): mcc: 0.7230, acc: 0.5960, precision: 0.8659, recall: 0.6115, f1: 0.7168, edges-pos-ontonotes_loss: 0.0286
09/17 01:19:40 AM: Update 17799: task edges-pos-ontonotes, batch 799 (17799): mcc: 0.7235, acc: 0.5962, precision: 0.8668, recall: 0.6117, f1: 0.7172, edges-pos-ontonotes_loss: 0.0286
09/17 01:19:50 AM: Update 17847: task edges-pos-ontonotes, batch 847 (17847): mcc: 0.7240, acc: 0.5965, precision: 0.8676, recall: 0.6120, f1: 0.7177, edges-pos-ontonotes_loss: 0.0286
09/17 01:20:00 AM: Update 17915: task edges-pos-ontonotes, batch 915 (17915): mcc: 0.7247, acc: 0.5972, precision: 0.8681, recall: 0.6127, f1: 0.7184, edges-pos-ontonotes_loss: 0.0285
09/17 01:20:10 AM: Update 17947: task edges-pos-ontonotes, batch 947 (17947): mcc: 0.7231, acc: 0.5949, precision: 0.8670, recall: 0.6109, f1: 0.7167, edges-pos-ontonotes_loss: 0.0286
09/17 01:20:21 AM: Update 17993: task edges-pos-ontonotes, batch 993 (17993): mcc: 0.7215, acc: 0.5929, precision: 0.8661, recall: 0.6089, f1: 0.7151, edges-pos-ontonotes_loss: 0.0288
09/17 01:20:22 AM: ***** Step 18000 / Validation 18 *****
09/17 01:20:22 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:20:22 AM: Validating...
09/17 01:20:31 AM: Evaluate: task edges-pos-ontonotes, batch 63 (157): mcc: 0.7591, acc: 0.6539, precision: 0.8893, recall: 0.6550, f1: 0.7544, edges-pos-ontonotes_loss: 0.0262
09/17 01:20:41 AM: Evaluate: task edges-pos-ontonotes, batch 114 (157): mcc: 0.7453, acc: 0.6283, precision: 0.8925, recall: 0.6294, f1: 0.7382, edges-pos-ontonotes_loss: 0.0269
09/17 01:20:51 AM: Best result seen so far for edges-pos-ontonotes.
09/17 01:20:51 AM: Best result seen so far for macro.
09/17 01:20:51 AM: Updating LR scheduler:
09/17 01:20:51 AM: 	Best result seen so far for macro_avg: 0.724
09/17 01:20:51 AM: 	# validation passes without improvement: 0
09/17 01:20:51 AM: edges-pos-ontonotes_loss: training: 0.028802 validation: 0.028113
09/17 01:20:51 AM: macro_avg: validation: 0.723853
09/17 01:20:51 AM: micro_avg: validation: 0.000000
09/17 01:20:51 AM: edges-pos-ontonotes_mcc: training: 0.721540 validation: 0.732585
09/17 01:20:51 AM: edges-pos-ontonotes_acc: training: 0.592873 validation: 0.608263
09/17 01:20:51 AM: edges-pos-ontonotes_precision: training: 0.866136 validation: 0.891181
09/17 01:20:51 AM: edges-pos-ontonotes_recall: training: 0.608879 validation: 0.609427
09/17 01:20:51 AM: edges-pos-ontonotes_f1: training: 0.715074 validation: 0.723853
09/17 01:20:51 AM: Global learning rate: 0.0001
09/17 01:20:51 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 01:20:51 AM: Update 18001: task edges-pos-ontonotes, batch 1 (18001): mcc: 0.7119, acc: 0.5748, precision: 0.8639, recall: 0.5946, f1: 0.7044, edges-pos-ontonotes_loss: 0.0308
09/17 01:21:01 AM: Update 18050: task edges-pos-ontonotes, batch 50 (18050): mcc: 0.7061, acc: 0.5721, precision: 0.8579, recall: 0.5892, f1: 0.6986, edges-pos-ontonotes_loss: 0.0315
09/17 01:21:11 AM: Update 18106: task edges-pos-ontonotes, batch 106 (18106): mcc: 0.7048, acc: 0.5705, precision: 0.8582, recall: 0.5868, f1: 0.6970, edges-pos-ontonotes_loss: 0.0322
09/17 01:21:21 AM: Update 18172: task edges-pos-ontonotes, batch 172 (18172): mcc: 0.7069, acc: 0.5731, precision: 0.8597, recall: 0.5892, f1: 0.6992, edges-pos-ontonotes_loss: 0.0319
09/17 01:21:31 AM: Update 18228: task edges-pos-ontonotes, batch 228 (18228): mcc: 0.7084, acc: 0.5751, precision: 0.8605, recall: 0.5911, f1: 0.7008, edges-pos-ontonotes_loss: 0.0317
09/17 01:21:41 AM: Update 18273: task edges-pos-ontonotes, batch 273 (18273): mcc: 0.7074, acc: 0.5735, precision: 0.8612, recall: 0.5890, f1: 0.6995, edges-pos-ontonotes_loss: 0.0319
09/17 01:21:52 AM: Update 18340: task edges-pos-ontonotes, batch 340 (18340): mcc: 0.7066, acc: 0.5718, precision: 0.8625, recall: 0.5868, f1: 0.6984, edges-pos-ontonotes_loss: 0.0320
09/17 01:22:02 AM: Update 18377: task edges-pos-ontonotes, batch 377 (18377): mcc: 0.7065, acc: 0.5712, precision: 0.8634, recall: 0.5859, f1: 0.6981, edges-pos-ontonotes_loss: 0.0320
09/17 01:22:12 AM: Update 18419: task edges-pos-ontonotes, batch 419 (18419): mcc: 0.7065, acc: 0.5710, precision: 0.8640, recall: 0.5856, f1: 0.6980, edges-pos-ontonotes_loss: 0.0320
09/17 01:22:22 AM: Update 18466: task edges-pos-ontonotes, batch 466 (18466): mcc: 0.7064, acc: 0.5706, precision: 0.8648, recall: 0.5849, f1: 0.6979, edges-pos-ontonotes_loss: 0.0319
09/17 01:22:32 AM: Update 18541: task edges-pos-ontonotes, batch 541 (18541): mcc: 0.7074, acc: 0.5714, precision: 0.8664, recall: 0.5855, f1: 0.6987, edges-pos-ontonotes_loss: 0.0318
09/17 01:22:42 AM: Update 18595: task edges-pos-ontonotes, batch 595 (18595): mcc: 0.7077, acc: 0.5717, precision: 0.8670, recall: 0.5855, f1: 0.6990, edges-pos-ontonotes_loss: 0.0318
09/17 01:22:52 AM: Update 18665: task edges-pos-ontonotes, batch 665 (18665): mcc: 0.7084, acc: 0.5725, precision: 0.8681, recall: 0.5859, f1: 0.6996, edges-pos-ontonotes_loss: 0.0317
09/17 01:23:02 AM: Update 18739: task edges-pos-ontonotes, batch 739 (18739): mcc: 0.7093, acc: 0.5732, precision: 0.8693, recall: 0.5865, f1: 0.7004, edges-pos-ontonotes_loss: 0.0316
09/17 01:23:12 AM: Update 18808: task edges-pos-ontonotes, batch 808 (18808): mcc: 0.7098, acc: 0.5738, precision: 0.8699, recall: 0.5869, f1: 0.7009, edges-pos-ontonotes_loss: 0.0316
09/17 01:23:22 AM: Update 18853: task edges-pos-ontonotes, batch 853 (18853): mcc: 0.7104, acc: 0.5744, precision: 0.8704, recall: 0.5875, f1: 0.7015, edges-pos-ontonotes_loss: 0.0316
09/17 01:23:32 AM: Update 18901: task edges-pos-ontonotes, batch 901 (18901): mcc: 0.7105, acc: 0.5745, precision: 0.8706, recall: 0.5875, f1: 0.7016, edges-pos-ontonotes_loss: 0.0315
09/17 01:23:42 AM: Update 18959: task edges-pos-ontonotes, batch 959 (18959): mcc: 0.7110, acc: 0.5750, precision: 0.8713, recall: 0.5878, f1: 0.7020, edges-pos-ontonotes_loss: 0.0315
09/17 01:23:49 AM: ***** Step 19000 / Validation 19 *****
09/17 01:23:49 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:23:49 AM: Validating...
09/17 01:23:52 AM: Evaluate: task edges-pos-ontonotes, batch 27 (157): mcc: 0.7281, acc: 0.5900, precision: 0.9062, recall: 0.5919, f1: 0.7161, edges-pos-ontonotes_loss: 0.0293
09/17 01:24:03 AM: Evaluate: task edges-pos-ontonotes, batch 101 (157): mcc: 0.7415, acc: 0.6117, precision: 0.9069, recall: 0.6131, f1: 0.7316, edges-pos-ontonotes_loss: 0.0278
09/17 01:24:13 AM: Evaluate: task edges-pos-ontonotes, batch 153 (157): mcc: 0.7281, acc: 0.5916, precision: 0.9012, recall: 0.5953, f1: 0.7169, edges-pos-ontonotes_loss: 0.0285
09/17 01:24:13 AM: Updating LR scheduler:
09/17 01:24:13 AM: 	Best result seen so far for macro_avg: 0.724
09/17 01:24:13 AM: 	# validation passes without improvement: 1
09/17 01:24:13 AM: edges-pos-ontonotes_loss: training: 0.031446 validation: 0.028567
09/17 01:24:13 AM: macro_avg: validation: 0.715988
09/17 01:24:13 AM: micro_avg: validation: 0.000000
09/17 01:24:13 AM: edges-pos-ontonotes_mcc: training: 0.711286 validation: 0.727273
09/17 01:24:13 AM: edges-pos-ontonotes_acc: training: 0.575306 validation: 0.590400
09/17 01:24:13 AM: edges-pos-ontonotes_precision: training: 0.871664 validation: 0.901254
09/17 01:24:13 AM: edges-pos-ontonotes_recall: training: 0.588112 validation: 0.593902
09/17 01:24:13 AM: edges-pos-ontonotes_f1: training: 0.702349 validation: 0.715988
09/17 01:24:13 AM: Global learning rate: 0.0001
09/17 01:24:13 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 01:24:23 AM: Update 19042: task edges-pos-ontonotes, batch 42 (19042): mcc: 0.7134, acc: 0.5755, precision: 0.8777, recall: 0.5874, f1: 0.7038, edges-pos-ontonotes_loss: 0.0310
09/17 01:24:33 AM: Update 19095: task edges-pos-ontonotes, batch 95 (19095): mcc: 0.7147, acc: 0.5771, precision: 0.8773, recall: 0.5898, f1: 0.7054, edges-pos-ontonotes_loss: 0.0311
09/17 01:24:43 AM: Update 19150: task edges-pos-ontonotes, batch 150 (19150): mcc: 0.7144, acc: 0.5772, precision: 0.8770, recall: 0.5895, f1: 0.7050, edges-pos-ontonotes_loss: 0.0310
09/17 01:24:58 AM: Update 19179: task edges-pos-ontonotes, batch 179 (19179): mcc: 0.7137, acc: 0.5768, precision: 0.8762, recall: 0.5889, f1: 0.7044, edges-pos-ontonotes_loss: 0.0310
09/17 01:25:08 AM: Update 19233: task edges-pos-ontonotes, batch 233 (19233): mcc: 0.7157, acc: 0.5791, precision: 0.8763, recall: 0.5922, f1: 0.7067, edges-pos-ontonotes_loss: 0.0302
09/17 01:25:18 AM: Update 19290: task edges-pos-ontonotes, batch 290 (19290): mcc: 0.7197, acc: 0.5838, precision: 0.8787, recall: 0.5970, f1: 0.7109, edges-pos-ontonotes_loss: 0.0294
09/17 01:25:29 AM: Update 19348: task edges-pos-ontonotes, batch 348 (19348): mcc: 0.7236, acc: 0.5881, precision: 0.8815, recall: 0.6014, f1: 0.7150, edges-pos-ontonotes_loss: 0.0288
09/17 01:25:39 AM: Update 19405: task edges-pos-ontonotes, batch 405 (19405): mcc: 0.7261, acc: 0.5906, precision: 0.8834, recall: 0.6042, f1: 0.7176, edges-pos-ontonotes_loss: 0.0283
09/17 01:25:49 AM: Update 19458: task edges-pos-ontonotes, batch 458 (19458): mcc: 0.7276, acc: 0.5920, precision: 0.8846, recall: 0.6058, f1: 0.7191, edges-pos-ontonotes_loss: 0.0279
09/17 01:25:59 AM: Update 19517: task edges-pos-ontonotes, batch 517 (19517): mcc: 0.7317, acc: 0.5973, precision: 0.8863, recall: 0.6114, f1: 0.7237, edges-pos-ontonotes_loss: 0.0274
09/17 01:26:09 AM: Update 19616: task edges-pos-ontonotes, batch 616 (19616): mcc: 0.7410, acc: 0.6095, precision: 0.8899, recall: 0.6242, f1: 0.7338, edges-pos-ontonotes_loss: 0.0263
09/17 01:26:19 AM: Update 19714: task edges-pos-ontonotes, batch 714 (19714): mcc: 0.7497, acc: 0.6213, precision: 0.8929, recall: 0.6365, f1: 0.7432, edges-pos-ontonotes_loss: 0.0254
09/17 01:26:30 AM: Update 19805: task edges-pos-ontonotes, batch 805 (19805): mcc: 0.7561, acc: 0.6302, precision: 0.8950, recall: 0.6457, f1: 0.7502, edges-pos-ontonotes_loss: 0.0247
09/17 01:26:40 AM: Update 19901: task edges-pos-ontonotes, batch 901 (19901): mcc: 0.7594, acc: 0.6353, precision: 0.8952, recall: 0.6512, f1: 0.7540, edges-pos-ontonotes_loss: 0.0243
09/17 01:26:49 AM: ***** Step 20000 / Validation 20 *****
09/17 01:26:49 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:26:49 AM: Validating...
09/17 01:26:50 AM: Evaluate: task edges-pos-ontonotes, batch 3 (157): mcc: 0.7080, acc: 0.5710, precision: 0.8858, recall: 0.5733, f1: 0.6961, edges-pos-ontonotes_loss: 0.0309
09/17 01:27:00 AM: Evaluate: task edges-pos-ontonotes, batch 72 (157): mcc: 0.7396, acc: 0.6239, precision: 0.8777, recall: 0.6306, f1: 0.7339, edges-pos-ontonotes_loss: 0.0277
09/17 01:27:10 AM: Evaluate: task edges-pos-ontonotes, batch 121 (157): mcc: 0.7162, acc: 0.5884, precision: 0.8718, recall: 0.5961, f1: 0.7080, edges-pos-ontonotes_loss: 0.0290
09/17 01:27:18 AM: Updating LR scheduler:
09/17 01:27:18 AM: 	Best result seen so far for macro_avg: 0.724
09/17 01:27:18 AM: 	# validation passes without improvement: 2
09/17 01:27:18 AM: edges-pos-ontonotes_loss: training: 0.023723 validation: 0.030003
09/17 01:27:18 AM: macro_avg: validation: 0.692737
09/17 01:27:18 AM: micro_avg: validation: 0.000000
09/17 01:27:18 AM: edges-pos-ontonotes_mcc: training: 0.762875 validation: 0.702762
09/17 01:27:18 AM: edges-pos-ontonotes_acc: training: 0.640377 validation: 0.568410
09/17 01:27:18 AM: edges-pos-ontonotes_precision: training: 0.895952 validation: 0.869717
09/17 01:27:18 AM: edges-pos-ontonotes_recall: training: 0.656499 validation: 0.575606
09/17 01:27:18 AM: edges-pos-ontonotes_f1: training: 0.757758 validation: 0.692737
09/17 01:27:18 AM: Global learning rate: 0.0001
09/17 01:27:18 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 01:27:20 AM: Update 20016: task edges-pos-ontonotes, batch 16 (20016): mcc: 0.8204, acc: 0.7298, precision: 0.9061, recall: 0.7488, f1: 0.8200, edges-pos-ontonotes_loss: 0.0187
09/17 01:27:30 AM: Update 20106: task edges-pos-ontonotes, batch 106 (20106): mcc: 0.8190, acc: 0.7283, precision: 0.9044, recall: 0.7477, f1: 0.8186, edges-pos-ontonotes_loss: 0.0190
09/17 01:27:40 AM: Update 20211: task edges-pos-ontonotes, batch 211 (20211): mcc: 0.8035, acc: 0.7087, precision: 0.8947, recall: 0.7281, f1: 0.8029, edges-pos-ontonotes_loss: 0.0192
09/17 01:27:50 AM: Update 20336: task edges-pos-ontonotes, batch 336 (20336): mcc: 0.7991, acc: 0.7047, precision: 0.8912, recall: 0.7231, f1: 0.7984, edges-pos-ontonotes_loss: 0.0194
09/17 01:28:01 AM: Update 20440: task edges-pos-ontonotes, batch 440 (20440): mcc: 0.7871, acc: 0.6880, precision: 0.8857, recall: 0.7063, f1: 0.7859, edges-pos-ontonotes_loss: 0.0201
09/17 01:28:11 AM: Update 20498: task edges-pos-ontonotes, batch 498 (20498): mcc: 0.7707, acc: 0.6649, precision: 0.8791, recall: 0.6828, f1: 0.7686, edges-pos-ontonotes_loss: 0.0216
09/17 01:28:21 AM: Update 20547: task edges-pos-ontonotes, batch 547 (20547): mcc: 0.7584, acc: 0.6476, precision: 0.8744, recall: 0.6653, f1: 0.7556, edges-pos-ontonotes_loss: 0.0227
09/17 01:28:31 AM: Update 20616: task edges-pos-ontonotes, batch 616 (20616): mcc: 0.7497, acc: 0.6351, precision: 0.8715, recall: 0.6525, f1: 0.7463, edges-pos-ontonotes_loss: 0.0239
09/17 01:28:41 AM: Update 20666: task edges-pos-ontonotes, batch 666 (20666): mcc: 0.7437, acc: 0.6263, precision: 0.8694, recall: 0.6437, f1: 0.7397, edges-pos-ontonotes_loss: 0.0246
09/17 01:28:52 AM: Update 20714: task edges-pos-ontonotes, batch 714 (20714): mcc: 0.7393, acc: 0.6200, precision: 0.8682, recall: 0.6372, f1: 0.7350, edges-pos-ontonotes_loss: 0.0251
09/17 01:29:02 AM: Update 20770: task edges-pos-ontonotes, batch 770 (20770): mcc: 0.7361, acc: 0.6152, precision: 0.8673, recall: 0.6324, f1: 0.7314, edges-pos-ontonotes_loss: 0.0255
09/17 01:29:12 AM: Update 20855: task edges-pos-ontonotes, batch 855 (20855): mcc: 0.7374, acc: 0.6171, precision: 0.8681, recall: 0.6341, f1: 0.7329, edges-pos-ontonotes_loss: 0.0254
09/17 01:29:22 AM: Update 20935: task edges-pos-ontonotes, batch 935 (20935): mcc: 0.7387, acc: 0.6189, precision: 0.8687, recall: 0.6359, f1: 0.7343, edges-pos-ontonotes_loss: 0.0254
09/17 01:29:30 AM: ***** Step 21000 / Validation 21 *****
09/17 01:29:30 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:29:30 AM: Validating...
09/17 01:29:32 AM: Evaluate: task edges-pos-ontonotes, batch 12 (157): mcc: 0.7279, acc: 0.5938, precision: 0.9016, recall: 0.5947, f1: 0.7167, edges-pos-ontonotes_loss: 0.0288
09/17 01:29:42 AM: Evaluate: task edges-pos-ontonotes, batch 80 (157): mcc: 0.7536, acc: 0.6310, precision: 0.9083, recall: 0.6320, f1: 0.7454, edges-pos-ontonotes_loss: 0.0265
09/17 01:29:52 AM: Evaluate: task edges-pos-ontonotes, batch 130 (157): mcc: 0.7272, acc: 0.5931, precision: 0.8963, recall: 0.5971, f1: 0.7167, edges-pos-ontonotes_loss: 0.0280
09/17 01:29:56 AM: Updating LR scheduler:
09/17 01:29:56 AM: 	Best result seen so far for macro_avg: 0.724
09/17 01:29:56 AM: 	# validation passes without improvement: 3
09/17 01:29:56 AM: edges-pos-ontonotes_loss: training: 0.025242 validation: 0.028657
09/17 01:29:56 AM: macro_avg: validation: 0.708481
09/17 01:29:56 AM: micro_avg: validation: 0.000000
09/17 01:29:56 AM: edges-pos-ontonotes_mcc: training: 0.739788 validation: 0.719850
09/17 01:29:56 AM: edges-pos-ontonotes_acc: training: 0.620395 validation: 0.583140
09/17 01:29:56 AM: edges-pos-ontonotes_precision: training: 0.869260 validation: 0.894390
09/17 01:29:56 AM: edges-pos-ontonotes_recall: training: 0.637247 validation: 0.586558
09/17 01:29:56 AM: edges-pos-ontonotes_f1: training: 0.735388 validation: 0.708481
09/17 01:29:56 AM: Global learning rate: 0.0001
09/17 01:29:56 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 01:30:02 AM: Update 21057: task edges-pos-ontonotes, batch 57 (21057): mcc: 0.7557, acc: 0.6393, precision: 0.8815, recall: 0.6551, f1: 0.7516, edges-pos-ontonotes_loss: 0.0243
09/17 01:30:12 AM: Update 21101: task edges-pos-ontonotes, batch 101 (21101): mcc: 0.7435, acc: 0.6230, precision: 0.8769, recall: 0.6379, f1: 0.7385, edges-pos-ontonotes_loss: 0.0259
09/17 01:30:23 AM: Update 21153: task edges-pos-ontonotes, batch 153 (21153): mcc: 0.7366, acc: 0.6124, precision: 0.8747, recall: 0.6278, f1: 0.7310, edges-pos-ontonotes_loss: 0.0269
09/17 01:30:33 AM: Update 21216: task edges-pos-ontonotes, batch 216 (21216): mcc: 0.7345, acc: 0.6083, precision: 0.8744, recall: 0.6245, f1: 0.7286, edges-pos-ontonotes_loss: 0.0273
09/17 01:30:43 AM: Update 21286: task edges-pos-ontonotes, batch 286 (21286): mcc: 0.7342, acc: 0.6078, precision: 0.8747, recall: 0.6238, f1: 0.7282, edges-pos-ontonotes_loss: 0.0272
09/17 01:30:53 AM: Update 21352: task edges-pos-ontonotes, batch 352 (21352): mcc: 0.7335, acc: 0.6065, precision: 0.8748, recall: 0.6226, f1: 0.7275, edges-pos-ontonotes_loss: 0.0273
09/17 01:31:10 AM: Update 21387: task edges-pos-ontonotes, batch 387 (21387): mcc: 0.7332, acc: 0.6062, precision: 0.8744, recall: 0.6225, f1: 0.7272, edges-pos-ontonotes_loss: 0.0273
09/17 01:31:20 AM: Update 21423: task edges-pos-ontonotes, batch 423 (21423): mcc: 0.7288, acc: 0.6004, precision: 0.8715, recall: 0.6171, f1: 0.7226, edges-pos-ontonotes_loss: 0.0277
09/17 01:31:30 AM: Update 21481: task edges-pos-ontonotes, batch 481 (21481): mcc: 0.7251, acc: 0.5957, precision: 0.8691, recall: 0.6126, f1: 0.7187, edges-pos-ontonotes_loss: 0.0282
09/17 01:31:40 AM: Update 21525: task edges-pos-ontonotes, batch 525 (21525): mcc: 0.7226, acc: 0.5928, precision: 0.8675, recall: 0.6096, f1: 0.7161, edges-pos-ontonotes_loss: 0.0286
09/17 01:31:50 AM: Update 21578: task edges-pos-ontonotes, batch 578 (21578): mcc: 0.7211, acc: 0.5911, precision: 0.8668, recall: 0.6077, f1: 0.7145, edges-pos-ontonotes_loss: 0.0289
09/17 01:32:00 AM: Update 21643: task edges-pos-ontonotes, batch 643 (21643): mcc: 0.7197, acc: 0.5893, precision: 0.8660, recall: 0.6060, f1: 0.7130, edges-pos-ontonotes_loss: 0.0292
09/17 01:32:11 AM: Update 21695: task edges-pos-ontonotes, batch 695 (21695): mcc: 0.7192, acc: 0.5886, precision: 0.8658, recall: 0.6053, f1: 0.7125, edges-pos-ontonotes_loss: 0.0293
09/17 01:32:21 AM: Update 21726: task edges-pos-ontonotes, batch 726 (21726): mcc: 0.7180, acc: 0.5870, precision: 0.8654, recall: 0.6036, f1: 0.7111, edges-pos-ontonotes_loss: 0.0295
09/17 01:32:31 AM: Update 21769: task edges-pos-ontonotes, batch 769 (21769): mcc: 0.7169, acc: 0.5854, precision: 0.8652, recall: 0.6018, f1: 0.7098, edges-pos-ontonotes_loss: 0.0296
09/17 01:32:41 AM: Update 21814: task edges-pos-ontonotes, batch 814 (21814): mcc: 0.7163, acc: 0.5846, precision: 0.8656, recall: 0.6006, f1: 0.7092, edges-pos-ontonotes_loss: 0.0297
09/17 01:32:51 AM: Update 21859: task edges-pos-ontonotes, batch 859 (21859): mcc: 0.7159, acc: 0.5837, precision: 0.8659, recall: 0.5997, f1: 0.7086, edges-pos-ontonotes_loss: 0.0298
09/17 01:33:02 AM: Update 21903: task edges-pos-ontonotes, batch 903 (21903): mcc: 0.7154, acc: 0.5829, precision: 0.8663, recall: 0.5986, f1: 0.7080, edges-pos-ontonotes_loss: 0.0299
09/17 01:33:12 AM: Update 21969: task edges-pos-ontonotes, batch 969 (21969): mcc: 0.7151, acc: 0.5822, precision: 0.8668, recall: 0.5977, f1: 0.7075, edges-pos-ontonotes_loss: 0.0300
09/17 01:33:16 AM: ***** Step 22000 / Validation 22 *****
09/17 01:33:16 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:33:16 AM: Validating...
09/17 01:33:22 AM: Evaluate: task edges-pos-ontonotes, batch 63 (157): mcc: 0.7523, acc: 0.6394, precision: 0.8937, recall: 0.6404, f1: 0.7461, edges-pos-ontonotes_loss: 0.0270
09/17 01:33:32 AM: Evaluate: task edges-pos-ontonotes, batch 135 (157): mcc: 0.7338, acc: 0.6061, precision: 0.8931, recall: 0.6101, f1: 0.7250, edges-pos-ontonotes_loss: 0.0279
09/17 01:33:35 AM: Updating LR scheduler:
09/17 01:33:35 AM: 	Best result seen so far for macro_avg: 0.724
09/17 01:33:35 AM: 	# validation passes without improvement: 0
09/17 01:33:35 AM: edges-pos-ontonotes_loss: training: 0.030060 validation: 0.028103
09/17 01:33:35 AM: macro_avg: validation: 0.722619
09/17 01:33:35 AM: micro_avg: validation: 0.000000
09/17 01:33:35 AM: edges-pos-ontonotes_mcc: training: 0.714868 validation: 0.731825
09/17 01:33:35 AM: edges-pos-ontonotes_acc: training: 0.581929 validation: 0.603151
09/17 01:33:35 AM: edges-pos-ontonotes_precision: training: 0.866811 validation: 0.893351
09/17 01:33:35 AM: edges-pos-ontonotes_recall: training: 0.597357 validation: 0.606675
09/17 01:33:35 AM: edges-pos-ontonotes_f1: training: 0.707290 validation: 0.722619
09/17 01:33:35 AM: Global learning rate: 5e-05
09/17 01:33:35 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 01:33:42 AM: Update 22029: task edges-pos-ontonotes, batch 29 (22029): mcc: 0.7064, acc: 0.5702, precision: 0.8667, recall: 0.5836, f1: 0.6975, edges-pos-ontonotes_loss: 0.0318
09/17 01:33:52 AM: Update 22098: task edges-pos-ontonotes, batch 98 (22098): mcc: 0.7134, acc: 0.5781, precision: 0.8734, recall: 0.5904, f1: 0.7045, edges-pos-ontonotes_loss: 0.0313
09/17 01:34:02 AM: Update 22153: task edges-pos-ontonotes, batch 153 (22153): mcc: 0.7144, acc: 0.5792, precision: 0.8739, recall: 0.5916, f1: 0.7056, edges-pos-ontonotes_loss: 0.0311
09/17 01:34:12 AM: Update 22198: task edges-pos-ontonotes, batch 198 (22198): mcc: 0.7154, acc: 0.5800, precision: 0.8749, recall: 0.5925, f1: 0.7066, edges-pos-ontonotes_loss: 0.0310
09/17 01:34:22 AM: Update 22236: task edges-pos-ontonotes, batch 236 (22236): mcc: 0.7150, acc: 0.5796, precision: 0.8753, recall: 0.5917, f1: 0.7061, edges-pos-ontonotes_loss: 0.0310
09/17 01:34:32 AM: Update 22273: task edges-pos-ontonotes, batch 273 (22273): mcc: 0.7151, acc: 0.5798, precision: 0.8755, recall: 0.5917, f1: 0.7062, edges-pos-ontonotes_loss: 0.0310
09/17 01:34:42 AM: Update 22315: task edges-pos-ontonotes, batch 315 (22315): mcc: 0.7154, acc: 0.5800, precision: 0.8758, recall: 0.5920, f1: 0.7065, edges-pos-ontonotes_loss: 0.0310
09/17 01:34:53 AM: Update 22340: task edges-pos-ontonotes, batch 340 (22340): mcc: 0.7153, acc: 0.5799, precision: 0.8758, recall: 0.5918, f1: 0.7063, edges-pos-ontonotes_loss: 0.0310
09/17 01:35:03 AM: Update 22381: task edges-pos-ontonotes, batch 381 (22381): mcc: 0.7152, acc: 0.5796, precision: 0.8760, recall: 0.5915, f1: 0.7062, edges-pos-ontonotes_loss: 0.0310
09/17 01:35:13 AM: Update 22421: task edges-pos-ontonotes, batch 421 (22421): mcc: 0.7156, acc: 0.5799, precision: 0.8766, recall: 0.5917, f1: 0.7065, edges-pos-ontonotes_loss: 0.0310
09/17 01:35:23 AM: Update 22459: task edges-pos-ontonotes, batch 459 (22459): mcc: 0.7151, acc: 0.5793, precision: 0.8763, recall: 0.5912, f1: 0.7061, edges-pos-ontonotes_loss: 0.0310
09/17 01:35:33 AM: Update 22501: task edges-pos-ontonotes, batch 501 (22501): mcc: 0.7154, acc: 0.5795, precision: 0.8767, recall: 0.5914, f1: 0.7063, edges-pos-ontonotes_loss: 0.0310
09/17 01:35:43 AM: Update 22543: task edges-pos-ontonotes, batch 543 (22543): mcc: 0.7154, acc: 0.5795, precision: 0.8767, recall: 0.5914, f1: 0.7063, edges-pos-ontonotes_loss: 0.0310
09/17 01:35:53 AM: Update 22582: task edges-pos-ontonotes, batch 582 (22582): mcc: 0.7153, acc: 0.5792, precision: 0.8767, recall: 0.5912, f1: 0.7062, edges-pos-ontonotes_loss: 0.0310
09/17 01:36:03 AM: Update 22617: task edges-pos-ontonotes, batch 617 (22617): mcc: 0.7151, acc: 0.5790, precision: 0.8765, recall: 0.5910, f1: 0.7060, edges-pos-ontonotes_loss: 0.0310
09/17 01:36:14 AM: Update 22640: task edges-pos-ontonotes, batch 640 (22640): mcc: 0.7142, acc: 0.5780, precision: 0.8756, recall: 0.5901, f1: 0.7051, edges-pos-ontonotes_loss: 0.0310
09/17 01:36:24 AM: Update 22680: task edges-pos-ontonotes, batch 680 (22680): mcc: 0.7147, acc: 0.5787, precision: 0.8755, recall: 0.5911, f1: 0.7057, edges-pos-ontonotes_loss: 0.0308
09/17 01:36:34 AM: Update 22733: task edges-pos-ontonotes, batch 733 (22733): mcc: 0.7160, acc: 0.5802, precision: 0.8762, recall: 0.5928, f1: 0.7071, edges-pos-ontonotes_loss: 0.0305
09/17 01:36:44 AM: Update 22793: task edges-pos-ontonotes, batch 793 (22793): mcc: 0.7180, acc: 0.5825, precision: 0.8774, recall: 0.5952, f1: 0.7093, edges-pos-ontonotes_loss: 0.0301
09/17 01:36:54 AM: Update 22848: task edges-pos-ontonotes, batch 848 (22848): mcc: 0.7192, acc: 0.5838, precision: 0.8781, recall: 0.5967, f1: 0.7105, edges-pos-ontonotes_loss: 0.0299
09/17 01:37:05 AM: Update 22914: task edges-pos-ontonotes, batch 914 (22914): mcc: 0.7209, acc: 0.5856, precision: 0.8792, recall: 0.5987, f1: 0.7123, edges-pos-ontonotes_loss: 0.0295
09/17 01:37:15 AM: Update 22958: task edges-pos-ontonotes, batch 958 (22958): mcc: 0.7218, acc: 0.5865, precision: 0.8798, recall: 0.5997, f1: 0.7132, edges-pos-ontonotes_loss: 0.0293
09/17 01:37:20 AM: ***** Step 23000 / Validation 23 *****
09/17 01:37:20 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:37:20 AM: Validating...
09/17 01:37:25 AM: Evaluate: task edges-pos-ontonotes, batch 32 (157): mcc: 0.7324, acc: 0.5987, precision: 0.9055, recall: 0.5993, f1: 0.7212, edges-pos-ontonotes_loss: 0.0286
09/17 01:37:35 AM: Evaluate: task edges-pos-ontonotes, batch 95 (157): mcc: 0.7438, acc: 0.6152, precision: 0.9082, recall: 0.6160, f1: 0.7341, edges-pos-ontonotes_loss: 0.0274
09/17 01:37:45 AM: Evaluate: task edges-pos-ontonotes, batch 153 (157): mcc: 0.7282, acc: 0.5902, precision: 0.9078, recall: 0.5910, f1: 0.7159, edges-pos-ontonotes_loss: 0.0283
09/17 01:37:46 AM: Updating LR scheduler:
09/17 01:37:46 AM: 	Best result seen so far for macro_avg: 0.724
09/17 01:37:46 AM: 	# validation passes without improvement: 1
09/17 01:37:46 AM: edges-pos-ontonotes_loss: training: 0.028997 validation: 0.028366
09/17 01:37:46 AM: macro_avg: validation: 0.714605
09/17 01:37:46 AM: micro_avg: validation: 0.000000
09/17 01:37:46 AM: edges-pos-ontonotes_mcc: training: 0.724049 validation: 0.727056
09/17 01:37:46 AM: edges-pos-ontonotes_acc: training: 0.589311 validation: 0.588463
09/17 01:37:46 AM: edges-pos-ontonotes_precision: training: 0.880685 validation: 0.907716
09/17 01:37:46 AM: edges-pos-ontonotes_recall: training: 0.602739 validation: 0.589246
09/17 01:37:46 AM: edges-pos-ontonotes_f1: training: 0.715673 validation: 0.714605
09/17 01:37:46 AM: Global learning rate: 5e-05
09/17 01:37:46 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 01:37:55 AM: Update 23072: task edges-pos-ontonotes, batch 72 (23072): mcc: 0.8085, acc: 0.7017, precision: 0.9153, recall: 0.7202, f1: 0.8061, edges-pos-ontonotes_loss: 0.0209
09/17 01:38:05 AM: Update 23150: task edges-pos-ontonotes, batch 150 (23150): mcc: 0.8112, acc: 0.7062, precision: 0.9152, recall: 0.7250, f1: 0.8091, edges-pos-ontonotes_loss: 0.0206
09/17 01:38:15 AM: Update 23231: task edges-pos-ontonotes, batch 231 (23231): mcc: 0.8135, acc: 0.7091, precision: 0.9162, recall: 0.7282, f1: 0.8115, edges-pos-ontonotes_loss: 0.0203
09/17 01:38:30 AM: Update 23265: task edges-pos-ontonotes, batch 265 (23265): mcc: 0.8134, acc: 0.7095, precision: 0.9155, recall: 0.7286, f1: 0.8114, edges-pos-ontonotes_loss: 0.0203
09/17 01:38:40 AM: Update 23363: task edges-pos-ontonotes, batch 363 (23363): mcc: 0.8109, acc: 0.7076, precision: 0.9125, recall: 0.7267, f1: 0.8090, edges-pos-ontonotes_loss: 0.0205
09/17 01:38:51 AM: Update 23462: task edges-pos-ontonotes, batch 462 (23462): mcc: 0.8107, acc: 0.7081, precision: 0.9113, recall: 0.7274, f1: 0.8090, edges-pos-ontonotes_loss: 0.0204
09/17 01:39:01 AM: Update 23557: task edges-pos-ontonotes, batch 557 (23557): mcc: 0.8111, acc: 0.7090, precision: 0.9107, recall: 0.7285, f1: 0.8095, edges-pos-ontonotes_loss: 0.0202
09/17 01:39:11 AM: Update 23652: task edges-pos-ontonotes, batch 652 (23652): mcc: 0.8085, acc: 0.7063, precision: 0.9080, recall: 0.7262, f1: 0.8070, edges-pos-ontonotes_loss: 0.0203
09/17 01:39:21 AM: Update 23765: task edges-pos-ontonotes, batch 765 (23765): mcc: 0.8060, acc: 0.7043, precision: 0.9056, recall: 0.7236, f1: 0.8044, edges-pos-ontonotes_loss: 0.0204
09/17 01:39:31 AM: Update 23860: task edges-pos-ontonotes, batch 860 (23860): mcc: 0.8037, acc: 0.7020, precision: 0.9037, recall: 0.7212, f1: 0.8022, edges-pos-ontonotes_loss: 0.0203
09/17 01:39:41 AM: Update 23920: task edges-pos-ontonotes, batch 920 (23920): mcc: 0.7960, acc: 0.6917, precision: 0.9000, recall: 0.7105, f1: 0.7941, edges-pos-ontonotes_loss: 0.0206
09/17 01:39:51 AM: Update 23972: task edges-pos-ontonotes, batch 972 (23972): mcc: 0.7859, acc: 0.6779, precision: 0.8955, recall: 0.6964, f1: 0.7835, edges-pos-ontonotes_loss: 0.0213
09/17 01:39:56 AM: ***** Step 24000 / Validation 24 *****
09/17 01:39:56 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:39:56 AM: Validating...
09/17 01:40:01 AM: Evaluate: task edges-pos-ontonotes, batch 38 (157): mcc: 0.7378, acc: 0.6050, precision: 0.9054, recall: 0.6081, f1: 0.7275, edges-pos-ontonotes_loss: 0.0277
09/17 01:40:11 AM: Evaluate: task edges-pos-ontonotes, batch 118 (157): mcc: 0.7310, acc: 0.5945, precision: 0.9064, recall: 0.5965, f1: 0.7195, edges-pos-ontonotes_loss: 0.0277
09/17 01:40:17 AM: Updating LR scheduler:
09/17 01:40:17 AM: 	Best result seen so far for macro_avg: 0.724
09/17 01:40:17 AM: 	# validation passes without improvement: 2
09/17 01:40:17 AM: edges-pos-ontonotes_loss: training: 0.021712 validation: 0.028772
09/17 01:40:17 AM: macro_avg: validation: 0.703176
09/17 01:40:17 AM: micro_avg: validation: 0.000000
09/17 01:40:17 AM: edges-pos-ontonotes_mcc: training: 0.782479 validation: 0.716615
09/17 01:40:17 AM: edges-pos-ontonotes_acc: training: 0.673254 validation: 0.573785
09/17 01:40:17 AM: edges-pos-ontonotes_precision: training: 0.893947 validation: 0.902795
09/17 01:40:17 AM: edges-pos-ontonotes_recall: training: 0.691695 validation: 0.575849
09/17 01:40:17 AM: edges-pos-ontonotes_f1: training: 0.779922 validation: 0.703176
09/17 01:40:17 AM: Global learning rate: 5e-05
09/17 01:40:17 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 01:40:21 AM: Update 24029: task edges-pos-ontonotes, batch 29 (24029): mcc: 0.6989, acc: 0.5628, precision: 0.8573, recall: 0.5779, f1: 0.6904, edges-pos-ontonotes_loss: 0.0330
09/17 01:40:32 AM: Update 24078: task edges-pos-ontonotes, batch 78 (24078): mcc: 0.6983, acc: 0.5624, precision: 0.8554, recall: 0.5782, f1: 0.6900, edges-pos-ontonotes_loss: 0.0330
09/17 01:40:42 AM: Update 24155: task edges-pos-ontonotes, batch 155 (24155): mcc: 0.7019, acc: 0.5663, precision: 0.8578, recall: 0.5824, f1: 0.6937, edges-pos-ontonotes_loss: 0.0324
09/17 01:40:52 AM: Update 24221: task edges-pos-ontonotes, batch 221 (24221): mcc: 0.7020, acc: 0.5669, precision: 0.8570, recall: 0.5831, f1: 0.6940, edges-pos-ontonotes_loss: 0.0324
09/17 01:41:02 AM: Update 24337: task edges-pos-ontonotes, batch 337 (24337): mcc: 0.7143, acc: 0.5833, precision: 0.8623, recall: 0.5996, f1: 0.7073, edges-pos-ontonotes_loss: 0.0298
09/17 01:41:12 AM: Update 24422: task edges-pos-ontonotes, batch 422 (24422): mcc: 0.7200, acc: 0.5915, precision: 0.8644, recall: 0.6076, f1: 0.7136, edges-pos-ontonotes_loss: 0.0286
09/17 01:41:22 AM: Update 24509: task edges-pos-ontonotes, batch 509 (24509): mcc: 0.7248, acc: 0.5982, precision: 0.8665, recall: 0.6141, f1: 0.7187, edges-pos-ontonotes_loss: 0.0278
09/17 01:41:32 AM: Update 24576: task edges-pos-ontonotes, batch 576 (24576): mcc: 0.7261, acc: 0.5995, precision: 0.8679, recall: 0.6152, f1: 0.7200, edges-pos-ontonotes_loss: 0.0277
09/17 01:41:42 AM: Update 24654: task edges-pos-ontonotes, batch 654 (24654): mcc: 0.7264, acc: 0.5992, precision: 0.8688, recall: 0.6151, f1: 0.7202, edges-pos-ontonotes_loss: 0.0278
09/17 01:41:52 AM: Update 24722: task edges-pos-ontonotes, batch 722 (24722): mcc: 0.7268, acc: 0.5997, precision: 0.8692, recall: 0.6154, f1: 0.7206, edges-pos-ontonotes_loss: 0.0278
09/17 01:42:02 AM: Update 24793: task edges-pos-ontonotes, batch 793 (24793): mcc: 0.7271, acc: 0.5999, precision: 0.8696, recall: 0.6156, f1: 0.7209, edges-pos-ontonotes_loss: 0.0278
09/17 01:42:13 AM: Update 24848: task edges-pos-ontonotes, batch 848 (24848): mcc: 0.7272, acc: 0.5998, precision: 0.8697, recall: 0.6157, f1: 0.7210, edges-pos-ontonotes_loss: 0.0278
09/17 01:42:23 AM: Update 24911: task edges-pos-ontonotes, batch 911 (24911): mcc: 0.7248, acc: 0.5964, precision: 0.8685, recall: 0.6127, f1: 0.7185, edges-pos-ontonotes_loss: 0.0281
09/17 01:42:33 AM: Update 24955: task edges-pos-ontonotes, batch 955 (24955): mcc: 0.7234, acc: 0.5946, precision: 0.8675, recall: 0.6109, f1: 0.7170, edges-pos-ontonotes_loss: 0.0282
09/17 01:42:43 AM: Update 25000: task edges-pos-ontonotes, batch 1000 (25000): mcc: 0.7225, acc: 0.5935, precision: 0.8670, recall: 0.6099, f1: 0.7161, edges-pos-ontonotes_loss: 0.0284
09/17 01:42:43 AM: ***** Step 25000 / Validation 25 *****
09/17 01:42:43 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:42:43 AM: Validating...
09/17 01:42:53 AM: Evaluate: task edges-pos-ontonotes, batch 68 (157): mcc: 0.7599, acc: 0.6523, precision: 0.8934, recall: 0.6534, f1: 0.7548, edges-pos-ontonotes_loss: 0.0260
09/17 01:43:03 AM: Evaluate: task edges-pos-ontonotes, batch 118 (157): mcc: 0.7458, acc: 0.6267, precision: 0.8960, recall: 0.6277, f1: 0.7383, edges-pos-ontonotes_loss: 0.0268
09/17 01:43:12 AM: Best result seen so far for edges-pos-ontonotes.
09/17 01:43:12 AM: Best result seen so far for macro.
09/17 01:43:12 AM: Updating LR scheduler:
09/17 01:43:12 AM: 	Best result seen so far for macro_avg: 0.725
09/17 01:43:12 AM: 	# validation passes without improvement: 0
09/17 01:43:12 AM: edges-pos-ontonotes_loss: training: 0.028357 validation: 0.027806
09/17 01:43:12 AM: macro_avg: validation: 0.725466
09/17 01:43:12 AM: micro_avg: validation: 0.000000
09/17 01:43:12 AM: edges-pos-ontonotes_mcc: training: 0.722522 validation: 0.734438
09/17 01:43:12 AM: edges-pos-ontonotes_acc: training: 0.593520 validation: 0.608951
09/17 01:43:12 AM: edges-pos-ontonotes_precision: training: 0.866952 validation: 0.894467
09/17 01:43:12 AM: edges-pos-ontonotes_recall: training: 0.609928 validation: 0.610178
09/17 01:43:12 AM: edges-pos-ontonotes_f1: training: 0.716075 validation: 0.725466
09/17 01:43:12 AM: Global learning rate: 5e-05
09/17 01:43:12 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 01:43:14 AM: Update 25004: task edges-pos-ontonotes, batch 4 (25004): mcc: 0.7036, acc: 0.5680, precision: 0.8588, recall: 0.5845, f1: 0.6955, edges-pos-ontonotes_loss: 0.0318
09/17 01:43:24 AM: Update 25050: task edges-pos-ontonotes, batch 50 (25050): mcc: 0.7091, acc: 0.5739, precision: 0.8629, recall: 0.5906, f1: 0.7013, edges-pos-ontonotes_loss: 0.0321
09/17 01:43:34 AM: Update 25094: task edges-pos-ontonotes, batch 94 (25094): mcc: 0.7079, acc: 0.5737, precision: 0.8594, recall: 0.5910, f1: 0.7004, edges-pos-ontonotes_loss: 0.0317
09/17 01:43:44 AM: Update 25146: task edges-pos-ontonotes, batch 146 (25146): mcc: 0.7085, acc: 0.5745, precision: 0.8596, recall: 0.5919, f1: 0.7010, edges-pos-ontonotes_loss: 0.0319
09/17 01:43:59 AM: Update 25160: task edges-pos-ontonotes, batch 160 (25160): mcc: 0.7081, acc: 0.5743, precision: 0.8593, recall: 0.5915, f1: 0.7007, edges-pos-ontonotes_loss: 0.0318
09/17 01:44:09 AM: Update 25208: task edges-pos-ontonotes, batch 208 (25208): mcc: 0.7079, acc: 0.5735, precision: 0.8610, recall: 0.5900, f1: 0.7002, edges-pos-ontonotes_loss: 0.0318
09/17 01:44:20 AM: Update 25249: task edges-pos-ontonotes, batch 249 (25249): mcc: 0.7071, acc: 0.5723, precision: 0.8614, recall: 0.5883, f1: 0.6991, edges-pos-ontonotes_loss: 0.0318
09/17 01:44:30 AM: Update 25294: task edges-pos-ontonotes, batch 294 (25294): mcc: 0.7066, acc: 0.5717, precision: 0.8618, recall: 0.5874, f1: 0.6986, edges-pos-ontonotes_loss: 0.0319
09/17 01:44:40 AM: Update 25339: task edges-pos-ontonotes, batch 339 (25339): mcc: 0.7067, acc: 0.5716, precision: 0.8625, recall: 0.5870, f1: 0.6986, edges-pos-ontonotes_loss: 0.0319
09/17 01:44:50 AM: Update 25386: task edges-pos-ontonotes, batch 386 (25386): mcc: 0.7067, acc: 0.5715, precision: 0.8630, recall: 0.5866, f1: 0.6984, edges-pos-ontonotes_loss: 0.0319
09/17 01:45:00 AM: Update 25429: task edges-pos-ontonotes, batch 429 (25429): mcc: 0.7072, acc: 0.5719, precision: 0.8640, recall: 0.5867, f1: 0.6988, edges-pos-ontonotes_loss: 0.0318
09/17 01:45:12 AM: Update 25473: task edges-pos-ontonotes, batch 473 (25473): mcc: 0.7072, acc: 0.5719, precision: 0.8641, recall: 0.5866, f1: 0.6988, edges-pos-ontonotes_loss: 0.0317
09/17 01:45:22 AM: Update 25542: task edges-pos-ontonotes, batch 542 (25542): mcc: 0.7081, acc: 0.5729, precision: 0.8651, recall: 0.5874, f1: 0.6997, edges-pos-ontonotes_loss: 0.0317
09/17 01:45:32 AM: Update 25608: task edges-pos-ontonotes, batch 608 (25608): mcc: 0.7085, acc: 0.5734, precision: 0.8657, recall: 0.5876, f1: 0.7001, edges-pos-ontonotes_loss: 0.0317
09/17 01:45:42 AM: Update 25665: task edges-pos-ontonotes, batch 665 (25665): mcc: 0.7089, acc: 0.5738, precision: 0.8664, recall: 0.5879, f1: 0.7005, edges-pos-ontonotes_loss: 0.0316
09/17 01:45:52 AM: Update 25734: task edges-pos-ontonotes, batch 734 (25734): mcc: 0.7096, acc: 0.5746, precision: 0.8671, recall: 0.5886, f1: 0.7012, edges-pos-ontonotes_loss: 0.0315
09/17 01:46:02 AM: Update 25791: task edges-pos-ontonotes, batch 791 (25791): mcc: 0.7101, acc: 0.5753, precision: 0.8675, recall: 0.5891, f1: 0.7017, edges-pos-ontonotes_loss: 0.0315
09/17 01:46:12 AM: Update 25854: task edges-pos-ontonotes, batch 854 (25854): mcc: 0.7104, acc: 0.5755, precision: 0.8680, recall: 0.5892, f1: 0.7019, edges-pos-ontonotes_loss: 0.0315
09/17 01:46:22 AM: Update 25907: task edges-pos-ontonotes, batch 907 (25907): mcc: 0.7107, acc: 0.5757, precision: 0.8685, recall: 0.5894, f1: 0.7022, edges-pos-ontonotes_loss: 0.0314
09/17 01:46:33 AM: Update 25958: task edges-pos-ontonotes, batch 958 (25958): mcc: 0.7108, acc: 0.5757, precision: 0.8687, recall: 0.5893, f1: 0.7023, edges-pos-ontonotes_loss: 0.0314
09/17 01:46:41 AM: ***** Step 26000 / Validation 26 *****
09/17 01:46:41 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:46:41 AM: Validating...
09/17 01:46:43 AM: Evaluate: task edges-pos-ontonotes, batch 12 (157): mcc: 0.7390, acc: 0.6117, precision: 0.9024, recall: 0.6121, f1: 0.7294, edges-pos-ontonotes_loss: 0.0287
09/17 01:46:53 AM: Evaluate: task edges-pos-ontonotes, batch 105 (157): mcc: 0.7430, acc: 0.6223, precision: 0.8963, recall: 0.6230, f1: 0.7351, edges-pos-ontonotes_loss: 0.0273
09/17 01:47:01 AM: Updating LR scheduler:
09/17 01:47:01 AM: 	Best result seen so far for macro_avg: 0.725
09/17 01:47:01 AM: 	# validation passes without improvement: 1
09/17 01:47:01 AM: edges-pos-ontonotes_loss: training: 0.031384 validation: 0.028120
09/17 01:47:01 AM: macro_avg: validation: 0.721678
09/17 01:47:01 AM: micro_avg: validation: 0.000000
09/17 01:47:01 AM: edges-pos-ontonotes_mcc: training: 0.711076 validation: 0.730947
09/17 01:47:01 AM: edges-pos-ontonotes_acc: training: 0.575945 validation: 0.602199
09/17 01:47:01 AM: edges-pos-ontonotes_precision: training: 0.869042 validation: 0.892883
09/17 01:47:01 AM: edges-pos-ontonotes_recall: training: 0.589579 validation: 0.605564
09/17 01:47:01 AM: edges-pos-ontonotes_f1: training: 0.702539 validation: 0.721678
09/17 01:47:01 AM: Global learning rate: 5e-05
09/17 01:47:01 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 01:47:03 AM: Update 26014: task edges-pos-ontonotes, batch 14 (26014): mcc: 0.7130, acc: 0.5779, precision: 0.8743, recall: 0.5891, f1: 0.7039, edges-pos-ontonotes_loss: 0.0309
09/17 01:47:13 AM: Update 26083: task edges-pos-ontonotes, batch 83 (26083): mcc: 0.7128, acc: 0.5778, precision: 0.8735, recall: 0.5893, f1: 0.7038, edges-pos-ontonotes_loss: 0.0308
09/17 01:47:23 AM: Update 26146: task edges-pos-ontonotes, batch 146 (26146): mcc: 0.7191, acc: 0.5850, precision: 0.8756, recall: 0.5982, f1: 0.7108, edges-pos-ontonotes_loss: 0.0295
09/17 01:47:33 AM: Update 26227: task edges-pos-ontonotes, batch 227 (26227): mcc: 0.7244, acc: 0.5913, precision: 0.8779, recall: 0.6053, f1: 0.7166, edges-pos-ontonotes_loss: 0.0284
09/17 01:47:43 AM: Update 26287: task edges-pos-ontonotes, batch 287 (26287): mcc: 0.7275, acc: 0.5942, precision: 0.8805, recall: 0.6086, f1: 0.7197, edges-pos-ontonotes_loss: 0.0278
09/17 01:47:53 AM: Update 26343: task edges-pos-ontonotes, batch 343 (26343): mcc: 0.7306, acc: 0.5973, precision: 0.8829, recall: 0.6119, f1: 0.7229, edges-pos-ontonotes_loss: 0.0274
09/17 01:48:03 AM: Update 26390: task edges-pos-ontonotes, batch 390 (26390): mcc: 0.7323, acc: 0.5992, precision: 0.8839, recall: 0.6141, f1: 0.7247, edges-pos-ontonotes_loss: 0.0271
09/17 01:48:13 AM: Update 26430: task edges-pos-ontonotes, batch 430 (26430): mcc: 0.7351, acc: 0.6025, precision: 0.8856, recall: 0.6175, f1: 0.7276, edges-pos-ontonotes_loss: 0.0267
09/17 01:48:23 AM: Update 26493: task edges-pos-ontonotes, batch 493 (26493): mcc: 0.7422, acc: 0.6118, precision: 0.8886, recall: 0.6272, f1: 0.7354, edges-pos-ontonotes_loss: 0.0260
09/17 01:48:33 AM: Update 26559: task edges-pos-ontonotes, batch 559 (26559): mcc: 0.7487, acc: 0.6204, precision: 0.8911, recall: 0.6361, f1: 0.7423, edges-pos-ontonotes_loss: 0.0253
09/17 01:48:43 AM: Update 26624: task edges-pos-ontonotes, batch 624 (26624): mcc: 0.7543, acc: 0.6279, precision: 0.8934, recall: 0.6439, f1: 0.7484, edges-pos-ontonotes_loss: 0.0248
09/17 01:48:54 AM: Update 26685: task edges-pos-ontonotes, batch 685 (26685): mcc: 0.7590, acc: 0.6344, precision: 0.8949, recall: 0.6507, f1: 0.7535, edges-pos-ontonotes_loss: 0.0243
09/17 01:49:04 AM: Update 26735: task edges-pos-ontonotes, batch 735 (26735): mcc: 0.7618, acc: 0.6384, precision: 0.8957, recall: 0.6549, f1: 0.7566, edges-pos-ontonotes_loss: 0.0241
09/17 01:49:14 AM: Update 26806: task edges-pos-ontonotes, batch 806 (26806): mcc: 0.7647, acc: 0.6426, precision: 0.8964, recall: 0.6593, f1: 0.7597, edges-pos-ontonotes_loss: 0.0238
09/17 01:49:24 AM: Update 26882: task edges-pos-ontonotes, batch 882 (26882): mcc: 0.7672, acc: 0.6465, precision: 0.8967, recall: 0.6633, f1: 0.7625, edges-pos-ontonotes_loss: 0.0235
09/17 01:49:34 AM: Update 26968: task edges-pos-ontonotes, batch 968 (26968): mcc: 0.7699, acc: 0.6505, precision: 0.8972, recall: 0.6675, f1: 0.7655, edges-pos-ontonotes_loss: 0.0231
09/17 01:49:37 AM: ***** Step 27000 / Validation 27 *****
09/17 01:49:37 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:49:37 AM: Validating...
09/17 01:49:44 AM: Evaluate: task edges-pos-ontonotes, batch 66 (157): mcc: 0.7543, acc: 0.6382, precision: 0.8999, recall: 0.6392, f1: 0.7475, edges-pos-ontonotes_loss: 0.0268
09/17 01:49:54 AM: Evaluate: task edges-pos-ontonotes, batch 136 (157): mcc: 0.7176, acc: 0.5828, precision: 0.8883, recall: 0.5870, f1: 0.7069, edges-pos-ontonotes_loss: 0.0286
09/17 01:49:57 AM: Updating LR scheduler:
09/17 01:49:57 AM: 	Best result seen so far for macro_avg: 0.725
09/17 01:49:57 AM: 	# validation passes without improvement: 2
09/17 01:49:57 AM: edges-pos-ontonotes_loss: training: 0.022967 validation: 0.029021
09/17 01:49:57 AM: macro_avg: validation: 0.701032
09/17 01:49:57 AM: micro_avg: validation: 0.000000
09/17 01:49:57 AM: edges-pos-ontonotes_mcc: training: 0.770841 validation: 0.712392
09/17 01:49:57 AM: edges-pos-ontonotes_acc: training: 0.651876 validation: 0.575923
09/17 01:49:57 AM: edges-pos-ontonotes_precision: training: 0.897407 validation: 0.886942
09/17 01:49:57 AM: edges-pos-ontonotes_recall: training: 0.668962 validation: 0.579553
09/17 01:49:57 AM: edges-pos-ontonotes_f1: training: 0.766526 validation: 0.701032
09/17 01:49:57 AM: Global learning rate: 5e-05
09/17 01:49:57 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 01:50:04 AM: Update 27052: task edges-pos-ontonotes, batch 52 (27052): mcc: 0.7937, acc: 0.6893, precision: 0.8964, recall: 0.7093, f1: 0.7919, edges-pos-ontonotes_loss: 0.0199
09/17 01:50:14 AM: Update 27150: task edges-pos-ontonotes, batch 150 (27150): mcc: 0.7844, acc: 0.6817, precision: 0.8870, recall: 0.7006, f1: 0.7829, edges-pos-ontonotes_loss: 0.0205
09/17 01:50:24 AM: Update 27318: task edges-pos-ontonotes, batch 318 (27318): mcc: 0.7887, acc: 0.6905, precision: 0.8872, recall: 0.7079, f1: 0.7875, edges-pos-ontonotes_loss: 0.0203
09/17 01:50:37 AM: Update 27351: task edges-pos-ontonotes, batch 351 (27351): mcc: 0.7867, acc: 0.6877, precision: 0.8867, recall: 0.7049, f1: 0.7854, edges-pos-ontonotes_loss: 0.0200
09/17 01:50:47 AM: Update 27416: task edges-pos-ontonotes, batch 416 (27416): mcc: 0.7583, acc: 0.6475, precision: 0.8749, recall: 0.6647, f1: 0.7554, edges-pos-ontonotes_loss: 0.0222
09/17 01:50:57 AM: Update 27459: task edges-pos-ontonotes, batch 459 (27459): mcc: 0.7485, acc: 0.6336, precision: 0.8713, recall: 0.6505, f1: 0.7449, edges-pos-ontonotes_loss: 0.0232
09/17 01:51:07 AM: Update 27505: task edges-pos-ontonotes, batch 505 (27505): mcc: 0.7417, acc: 0.6236, precision: 0.8693, recall: 0.6404, f1: 0.7375, edges-pos-ontonotes_loss: 0.0240
09/17 01:51:17 AM: Update 27556: task edges-pos-ontonotes, batch 556 (27556): mcc: 0.7361, acc: 0.6155, precision: 0.8678, recall: 0.6320, f1: 0.7314, edges-pos-ontonotes_loss: 0.0248
09/17 01:51:28 AM: Update 27606: task edges-pos-ontonotes, batch 606 (27606): mcc: 0.7315, acc: 0.6090, precision: 0.8660, recall: 0.6257, f1: 0.7265, edges-pos-ontonotes_loss: 0.0254
09/17 01:51:38 AM: Update 27654: task edges-pos-ontonotes, batch 654 (27654): mcc: 0.7280, acc: 0.6037, precision: 0.8646, recall: 0.6208, f1: 0.7227, edges-pos-ontonotes_loss: 0.0260
09/17 01:51:48 AM: Update 27712: task edges-pos-ontonotes, batch 712 (27712): mcc: 0.7273, acc: 0.6028, precision: 0.8643, recall: 0.6198, f1: 0.7220, edges-pos-ontonotes_loss: 0.0262
09/17 01:51:58 AM: Update 27801: task edges-pos-ontonotes, batch 801 (27801): mcc: 0.7298, acc: 0.6062, precision: 0.8656, recall: 0.6230, f1: 0.7245, edges-pos-ontonotes_loss: 0.0260
09/17 01:52:08 AM: Update 27889: task edges-pos-ontonotes, batch 889 (27889): mcc: 0.7323, acc: 0.6096, precision: 0.8669, recall: 0.6263, f1: 0.7272, edges-pos-ontonotes_loss: 0.0257
09/17 01:52:18 AM: Update 27964: task edges-pos-ontonotes, batch 964 (27964): mcc: 0.7338, acc: 0.6116, precision: 0.8677, recall: 0.6283, f1: 0.7288, edges-pos-ontonotes_loss: 0.0257
09/17 01:52:26 AM: ***** Step 28000 / Validation 28 *****
09/17 01:52:26 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:52:26 AM: Validating...
09/17 01:52:28 AM: Evaluate: task edges-pos-ontonotes, batch 18 (157): mcc: 0.7293, acc: 0.6039, precision: 0.8891, recall: 0.6056, f1: 0.7204, edges-pos-ontonotes_loss: 0.0284
09/17 01:52:38 AM: Evaluate: task edges-pos-ontonotes, batch 96 (157): mcc: 0.7491, acc: 0.6311, precision: 0.8965, recall: 0.6329, f1: 0.7420, edges-pos-ontonotes_loss: 0.0265
09/17 01:52:48 AM: Evaluate: task edges-pos-ontonotes, batch 149 (157): mcc: 0.7222, acc: 0.5928, precision: 0.8841, recall: 0.5973, f1: 0.7129, edges-pos-ontonotes_loss: 0.0281
09/17 01:52:50 AM: Updating LR scheduler:
09/17 01:52:50 AM: 	Best result seen so far for macro_avg: 0.725
09/17 01:52:50 AM: 	# validation passes without improvement: 3
09/17 01:52:50 AM: edges-pos-ontonotes_loss: training: 0.025632 validation: 0.028312
09/17 01:52:50 AM: macro_avg: validation: 0.710795
09/17 01:52:50 AM: micro_avg: validation: 0.000000
09/17 01:52:50 AM: edges-pos-ontonotes_mcc: training: 0.734261 validation: 0.720159
09/17 01:52:50 AM: edges-pos-ontonotes_acc: training: 0.612099 validation: 0.590463
09/17 01:52:50 AM: edges-pos-ontonotes_precision: training: 0.868191 validation: 0.882917
09/17 01:52:50 AM: edges-pos-ontonotes_recall: training: 0.628692 validation: 0.594834
09/17 01:52:50 AM: edges-pos-ontonotes_f1: training: 0.729282 validation: 0.710795
09/17 01:52:50 AM: Global learning rate: 5e-05
09/17 01:52:50 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 01:52:58 AM: Update 28055: task edges-pos-ontonotes, batch 55 (28055): mcc: 0.7299, acc: 0.6011, precision: 0.8736, recall: 0.6174, f1: 0.7235, edges-pos-ontonotes_loss: 0.0282
09/17 01:53:08 AM: Update 28126: task edges-pos-ontonotes, batch 126 (28126): mcc: 0.7286, acc: 0.5990, precision: 0.8738, recall: 0.6151, f1: 0.7220, edges-pos-ontonotes_loss: 0.0281
09/17 01:53:19 AM: Update 28190: task edges-pos-ontonotes, batch 190 (28190): mcc: 0.7286, acc: 0.5994, precision: 0.8735, recall: 0.6154, f1: 0.7221, edges-pos-ontonotes_loss: 0.0280
09/17 01:53:29 AM: Update 28248: task edges-pos-ontonotes, batch 248 (28248): mcc: 0.7294, acc: 0.6001, precision: 0.8738, recall: 0.6164, f1: 0.7229, edges-pos-ontonotes_loss: 0.0280
09/17 01:53:39 AM: Update 28306: task edges-pos-ontonotes, batch 306 (28306): mcc: 0.7309, acc: 0.6017, precision: 0.8746, recall: 0.6183, f1: 0.7245, edges-pos-ontonotes_loss: 0.0278
09/17 01:53:49 AM: Update 28339: task edges-pos-ontonotes, batch 339 (28339): mcc: 0.7249, acc: 0.5944, precision: 0.8698, recall: 0.6119, f1: 0.7184, edges-pos-ontonotes_loss: 0.0283
09/17 01:53:59 AM: Update 28388: task edges-pos-ontonotes, batch 388 (28388): mcc: 0.7223, acc: 0.5909, precision: 0.8684, recall: 0.6084, f1: 0.7155, edges-pos-ontonotes_loss: 0.0287
09/17 01:54:09 AM: Update 28433: task edges-pos-ontonotes, batch 433 (28433): mcc: 0.7195, acc: 0.5879, precision: 0.8663, recall: 0.6054, f1: 0.7127, edges-pos-ontonotes_loss: 0.0291
09/17 01:54:20 AM: Update 28485: task edges-pos-ontonotes, batch 485 (28485): mcc: 0.7177, acc: 0.5859, precision: 0.8647, recall: 0.6035, f1: 0.7109, edges-pos-ontonotes_loss: 0.0294
09/17 01:54:30 AM: Update 28549: task edges-pos-ontonotes, batch 549 (28549): mcc: 0.7162, acc: 0.5841, precision: 0.8637, recall: 0.6017, f1: 0.7093, edges-pos-ontonotes_loss: 0.0296
09/17 01:54:41 AM: Update 28620: task edges-pos-ontonotes, batch 620 (28620): mcc: 0.7155, acc: 0.5834, precision: 0.8631, recall: 0.6010, f1: 0.7086, edges-pos-ontonotes_loss: 0.0298
09/17 01:54:51 AM: Update 28683: task edges-pos-ontonotes, batch 683 (28683): mcc: 0.7136, acc: 0.5811, precision: 0.8627, recall: 0.5982, f1: 0.7065, edges-pos-ontonotes_loss: 0.0301
09/17 01:55:01 AM: Update 28748: task edges-pos-ontonotes, batch 748 (28748): mcc: 0.7134, acc: 0.5805, precision: 0.8635, recall: 0.5973, f1: 0.7062, edges-pos-ontonotes_loss: 0.0302
09/17 01:55:11 AM: Update 28797: task edges-pos-ontonotes, batch 797 (28797): mcc: 0.7128, acc: 0.5797, precision: 0.8635, recall: 0.5963, f1: 0.7054, edges-pos-ontonotes_loss: 0.0303
09/17 01:55:21 AM: Update 28844: task edges-pos-ontonotes, batch 844 (28844): mcc: 0.7126, acc: 0.5792, precision: 0.8639, recall: 0.5957, f1: 0.7051, edges-pos-ontonotes_loss: 0.0304
09/17 01:55:32 AM: Update 28890: task edges-pos-ontonotes, batch 890 (28890): mcc: 0.7124, acc: 0.5789, precision: 0.8640, recall: 0.5952, f1: 0.7049, edges-pos-ontonotes_loss: 0.0304
09/17 01:55:44 AM: Update 28933: task edges-pos-ontonotes, batch 933 (28933): mcc: 0.7123, acc: 0.5789, precision: 0.8641, recall: 0.5951, f1: 0.7048, edges-pos-ontonotes_loss: 0.0305
09/17 01:55:54 AM: Update 28976: task edges-pos-ontonotes, batch 976 (28976): mcc: 0.7124, acc: 0.5790, precision: 0.8643, recall: 0.5950, f1: 0.7048, edges-pos-ontonotes_loss: 0.0305
09/17 01:56:00 AM: ***** Step 29000 / Validation 29 *****
09/17 01:56:00 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:56:00 AM: Validating...
09/17 01:56:04 AM: Evaluate: task edges-pos-ontonotes, batch 29 (157): mcc: 0.7344, acc: 0.6100, precision: 0.8931, recall: 0.6110, f1: 0.7256, edges-pos-ontonotes_loss: 0.0282
09/17 01:56:15 AM: Evaluate: task edges-pos-ontonotes, batch 93 (157): mcc: 0.7485, acc: 0.6325, precision: 0.8939, recall: 0.6338, f1: 0.7417, edges-pos-ontonotes_loss: 0.0268
09/17 01:56:25 AM: Evaluate: task edges-pos-ontonotes, batch 136 (157): mcc: 0.7354, acc: 0.6090, precision: 0.8920, recall: 0.6135, f1: 0.7270, edges-pos-ontonotes_loss: 0.0276
09/17 01:56:29 AM: Updating LR scheduler:
09/17 01:56:29 AM: 	Best result seen so far for macro_avg: 0.725
09/17 01:56:29 AM: 	# validation passes without improvement: 0
09/17 01:56:29 AM: edges-pos-ontonotes_loss: training: 0.030488 validation: 0.027882
09/17 01:56:29 AM: macro_avg: validation: 0.724297
09/17 01:56:29 AM: micro_avg: validation: 0.000000
09/17 01:56:29 AM: edges-pos-ontonotes_mcc: training: 0.712546 validation: 0.733101
09/17 01:56:29 AM: edges-pos-ontonotes_acc: training: 0.579182 validation: 0.605702
09/17 01:56:29 AM: edges-pos-ontonotes_precision: training: 0.864584 validation: 0.892122
09/17 01:56:29 AM: edges-pos-ontonotes_recall: training: 0.595098 validation: 0.609617
09/17 01:56:29 AM: edges-pos-ontonotes_f1: training: 0.704965 validation: 0.724297
09/17 01:56:29 AM: Global learning rate: 2.5e-05
09/17 01:56:29 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 01:56:35 AM: Update 29026: task edges-pos-ontonotes, batch 26 (29026): mcc: 0.7181, acc: 0.5838, precision: 0.8747, recall: 0.5972, f1: 0.7098, edges-pos-ontonotes_loss: 0.0304
09/17 01:56:45 AM: Update 29081: task edges-pos-ontonotes, batch 81 (29081): mcc: 0.7186, acc: 0.5850, precision: 0.8754, recall: 0.5975, f1: 0.7102, edges-pos-ontonotes_loss: 0.0310
09/17 01:56:55 AM: Update 29129: task edges-pos-ontonotes, batch 129 (29129): mcc: 0.7168, acc: 0.5825, precision: 0.8748, recall: 0.5950, f1: 0.7082, edges-pos-ontonotes_loss: 0.0312
09/17 01:57:05 AM: Update 29175: task edges-pos-ontonotes, batch 175 (29175): mcc: 0.7160, acc: 0.5820, precision: 0.8736, recall: 0.5945, f1: 0.7075, edges-pos-ontonotes_loss: 0.0311
09/17 01:57:16 AM: Update 29224: task edges-pos-ontonotes, batch 224 (29224): mcc: 0.7154, acc: 0.5812, precision: 0.8734, recall: 0.5936, f1: 0.7069, edges-pos-ontonotes_loss: 0.0311
09/17 01:57:33 AM: Update 29246: task edges-pos-ontonotes, batch 246 (29246): mcc: 0.7157, acc: 0.5818, precision: 0.8732, recall: 0.5942, f1: 0.7072, edges-pos-ontonotes_loss: 0.0311
09/17 01:57:43 AM: Update 29307: task edges-pos-ontonotes, batch 307 (29307): mcc: 0.7145, acc: 0.5804, precision: 0.8728, recall: 0.5926, f1: 0.7059, edges-pos-ontonotes_loss: 0.0311
09/17 01:57:53 AM: Update 29356: task edges-pos-ontonotes, batch 356 (29356): mcc: 0.7139, acc: 0.5800, precision: 0.8719, recall: 0.5922, f1: 0.7053, edges-pos-ontonotes_loss: 0.0311
09/17 01:58:03 AM: Update 29426: task edges-pos-ontonotes, batch 426 (29426): mcc: 0.7132, acc: 0.5788, precision: 0.8717, recall: 0.5912, f1: 0.7046, edges-pos-ontonotes_loss: 0.0312
09/17 01:58:13 AM: Update 29499: task edges-pos-ontonotes, batch 499 (29499): mcc: 0.7136, acc: 0.5791, precision: 0.8723, recall: 0.5914, f1: 0.7049, edges-pos-ontonotes_loss: 0.0312
09/17 01:58:23 AM: Update 29544: task edges-pos-ontonotes, batch 544 (29544): mcc: 0.7137, acc: 0.5791, precision: 0.8724, recall: 0.5915, f1: 0.7050, edges-pos-ontonotes_loss: 0.0311
09/17 01:58:33 AM: Update 29590: task edges-pos-ontonotes, batch 590 (29590): mcc: 0.7140, acc: 0.5796, precision: 0.8721, recall: 0.5922, f1: 0.7054, edges-pos-ontonotes_loss: 0.0309
09/17 01:58:43 AM: Update 29644: task edges-pos-ontonotes, batch 644 (29644): mcc: 0.7158, acc: 0.5818, precision: 0.8727, recall: 0.5948, f1: 0.7074, edges-pos-ontonotes_loss: 0.0306
09/17 01:58:54 AM: Update 29700: task edges-pos-ontonotes, batch 700 (29700): mcc: 0.7170, acc: 0.5834, precision: 0.8730, recall: 0.5966, f1: 0.7088, edges-pos-ontonotes_loss: 0.0302
09/17 01:59:04 AM: Update 29775: task edges-pos-ontonotes, batch 775 (29775): mcc: 0.7192, acc: 0.5859, precision: 0.8744, recall: 0.5992, f1: 0.7111, edges-pos-ontonotes_loss: 0.0297
09/17 01:59:14 AM: Update 29828: task edges-pos-ontonotes, batch 828 (29828): mcc: 0.7207, acc: 0.5875, precision: 0.8752, recall: 0.6010, f1: 0.7127, edges-pos-ontonotes_loss: 0.0295
09/17 01:59:24 AM: Update 29872: task edges-pos-ontonotes, batch 872 (29872): mcc: 0.7220, acc: 0.5889, precision: 0.8762, recall: 0.6026, f1: 0.7141, edges-pos-ontonotes_loss: 0.0293
09/17 01:59:34 AM: Update 29956: task edges-pos-ontonotes, batch 956 (29956): mcc: 0.7268, acc: 0.5951, precision: 0.8783, recall: 0.6090, f1: 0.7193, edges-pos-ontonotes_loss: 0.0286
09/17 01:59:40 AM: ***** Step 30000 / Validation 30 *****
09/17 01:59:40 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 01:59:40 AM: Validating...
09/17 01:59:44 AM: Evaluate: task edges-pos-ontonotes, batch 26 (157): mcc: 0.7320, acc: 0.5989, precision: 0.9047, recall: 0.5992, f1: 0.7210, edges-pos-ontonotes_loss: 0.0287
09/17 01:59:54 AM: Evaluate: task edges-pos-ontonotes, batch 111 (157): mcc: 0.7422, acc: 0.6126, precision: 0.9086, recall: 0.6132, f1: 0.7322, edges-pos-ontonotes_loss: 0.0272
09/17 02:00:02 AM: Updating LR scheduler:
09/17 02:00:02 AM: 	Best result seen so far for macro_avg: 0.725
09/17 02:00:02 AM: 	# validation passes without improvement: 1
09/17 02:00:02 AM: edges-pos-ontonotes_loss: training: 0.028227 validation: 0.028061
09/17 02:00:02 AM: macro_avg: validation: 0.716854
09/17 02:00:02 AM: micro_avg: validation: 0.000000
09/17 02:00:02 AM: edges-pos-ontonotes_mcc: training: 0.729496 validation: 0.728932
09/17 02:00:02 AM: edges-pos-ontonotes_acc: training: 0.598397 validation: 0.591786
09/17 02:00:02 AM: edges-pos-ontonotes_precision: training: 0.879541 validation: 0.907458
09/17 02:00:02 AM: edges-pos-ontonotes_recall: training: 0.612521 validation: 0.592421
09/17 02:00:02 AM: edges-pos-ontonotes_f1: training: 0.722138 validation: 0.716854
09/17 02:00:02 AM: Global learning rate: 2.5e-05
09/17 02:00:02 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 02:00:05 AM: Update 30037: task edges-pos-ontonotes, batch 37 (30037): mcc: 0.8122, acc: 0.7077, precision: 0.9164, recall: 0.7259, f1: 0.8101, edges-pos-ontonotes_loss: 0.0205
09/17 02:00:15 AM: Update 30152: task edges-pos-ontonotes, batch 152 (30152): mcc: 0.8144, acc: 0.7114, precision: 0.9162, recall: 0.7299, f1: 0.8125, edges-pos-ontonotes_loss: 0.0204
09/17 02:00:25 AM: Update 30246: task edges-pos-ontonotes, batch 246 (30246): mcc: 0.8107, acc: 0.7081, precision: 0.9118, recall: 0.7269, f1: 0.8089, edges-pos-ontonotes_loss: 0.0206
09/17 02:00:35 AM: Update 30384: task edges-pos-ontonotes, batch 384 (30384): mcc: 0.8101, acc: 0.7086, precision: 0.9101, recall: 0.7272, f1: 0.8085, edges-pos-ontonotes_loss: 0.0205
09/17 02:00:45 AM: Update 30513: task edges-pos-ontonotes, batch 513 (30513): mcc: 0.8079, acc: 0.7061, precision: 0.9073, recall: 0.7255, f1: 0.8063, edges-pos-ontonotes_loss: 0.0204
09/17 02:00:55 AM: Update 30696: task edges-pos-ontonotes, batch 696 (30696): mcc: 0.8037, acc: 0.7018, precision: 0.9034, recall: 0.7213, f1: 0.8021, edges-pos-ontonotes_loss: 0.0204
09/17 02:01:05 AM: Update 30819: task edges-pos-ontonotes, batch 819 (30819): mcc: 0.7982, acc: 0.6953, precision: 0.9001, recall: 0.7144, f1: 0.7966, edges-pos-ontonotes_loss: 0.0205
09/17 02:01:15 AM: Update 30902: task edges-pos-ontonotes, batch 902 (30902): mcc: 0.7831, acc: 0.6747, precision: 0.8935, recall: 0.6931, f1: 0.7807, edges-pos-ontonotes_loss: 0.0216
09/17 02:01:25 AM: Update 30978: task edges-pos-ontonotes, batch 978 (30978): mcc: 0.7719, acc: 0.6594, precision: 0.8886, recall: 0.6775, f1: 0.7688, edges-pos-ontonotes_loss: 0.0225
09/17 02:01:28 AM: ***** Step 31000 / Validation 31 *****
09/17 02:01:28 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 02:01:28 AM: Validating...
09/17 02:01:35 AM: Evaluate: task edges-pos-ontonotes, batch 70 (157): mcc: 0.7556, acc: 0.6311, precision: 0.9129, recall: 0.6320, f1: 0.7469, edges-pos-ontonotes_loss: 0.0262
09/17 02:01:45 AM: Evaluate: task edges-pos-ontonotes, batch 139 (157): mcc: 0.7226, acc: 0.5831, precision: 0.9049, recall: 0.5840, f1: 0.7098, edges-pos-ontonotes_loss: 0.0280
09/17 02:01:48 AM: Updating LR scheduler:
09/17 02:01:48 AM: 	Best result seen so far for macro_avg: 0.725
09/17 02:01:48 AM: 	# validation passes without improvement: 2
09/17 02:01:48 AM: edges-pos-ontonotes_loss: training: 0.022767 validation: 0.028367
09/17 02:01:48 AM: macro_avg: validation: 0.705523
09/17 02:01:48 AM: micro_avg: validation: 0.000000
09/17 02:01:48 AM: edges-pos-ontonotes_mcc: training: 0.768716 validation: 0.718696
09/17 02:01:48 AM: edges-pos-ontonotes_acc: training: 0.655176 validation: 0.577902
09/17 02:01:48 AM: edges-pos-ontonotes_precision: training: 0.887071 validation: 0.903414
09/17 02:01:48 AM: edges-pos-ontonotes_recall: training: 0.673211 validation: 0.578749
09/17 02:01:48 AM: edges-pos-ontonotes_f1: training: 0.765485 validation: 0.705523
09/17 02:01:48 AM: Global learning rate: 2.5e-05
09/17 02:01:48 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 02:01:55 AM: Update 31055: task edges-pos-ontonotes, batch 55 (31055): mcc: 0.7042, acc: 0.5693, precision: 0.8614, recall: 0.5837, f1: 0.6958, edges-pos-ontonotes_loss: 0.0321
09/17 02:02:05 AM: Update 31100: task edges-pos-ontonotes, batch 100 (31100): mcc: 0.7019, acc: 0.5659, precision: 0.8585, recall: 0.5819, f1: 0.6936, edges-pos-ontonotes_loss: 0.0323
09/17 02:02:18 AM: Update 31141: task edges-pos-ontonotes, batch 141 (31141): mcc: 0.7006, acc: 0.5646, precision: 0.8569, recall: 0.5808, f1: 0.6923, edges-pos-ontonotes_loss: 0.0324
09/17 02:02:28 AM: Update 31210: task edges-pos-ontonotes, batch 210 (31210): mcc: 0.7124, acc: 0.5803, precision: 0.8619, recall: 0.5968, f1: 0.7052, edges-pos-ontonotes_loss: 0.0298
09/17 02:02:38 AM: Update 31311: task edges-pos-ontonotes, batch 311 (31311): mcc: 0.7231, acc: 0.5949, precision: 0.8666, recall: 0.6112, f1: 0.7168, edges-pos-ontonotes_loss: 0.0281
09/17 02:02:48 AM: Update 31399: task edges-pos-ontonotes, batch 399 (31399): mcc: 0.7283, acc: 0.6024, precision: 0.8685, recall: 0.6185, f1: 0.7225, edges-pos-ontonotes_loss: 0.0271
09/17 02:03:06 AM: Update 31454: task edges-pos-ontonotes, batch 454 (31454): mcc: 0.7310, acc: 0.6061, precision: 0.8700, recall: 0.6220, f1: 0.7254, edges-pos-ontonotes_loss: 0.0267
09/17 02:03:16 AM: Update 31514: task edges-pos-ontonotes, batch 514 (31514): mcc: 0.7307, acc: 0.6053, precision: 0.8708, recall: 0.6208, f1: 0.7248, edges-pos-ontonotes_loss: 0.0269
09/17 02:03:26 AM: Update 31578: task edges-pos-ontonotes, batch 578 (31578): mcc: 0.7306, acc: 0.6046, precision: 0.8718, recall: 0.6200, f1: 0.7246, edges-pos-ontonotes_loss: 0.0270
09/17 02:03:36 AM: Update 31641: task edges-pos-ontonotes, batch 641 (31641): mcc: 0.7303, acc: 0.6039, precision: 0.8721, recall: 0.6192, f1: 0.7242, edges-pos-ontonotes_loss: 0.0271
09/17 02:03:46 AM: Update 31702: task edges-pos-ontonotes, batch 702 (31702): mcc: 0.7302, acc: 0.6036, precision: 0.8723, recall: 0.6189, f1: 0.7241, edges-pos-ontonotes_loss: 0.0272
09/17 02:03:56 AM: Update 31750: task edges-pos-ontonotes, batch 750 (31750): mcc: 0.7302, acc: 0.6032, precision: 0.8727, recall: 0.6186, f1: 0.7240, edges-pos-ontonotes_loss: 0.0272
09/17 02:04:06 AM: Update 31777: task edges-pos-ontonotes, batch 777 (31777): mcc: 0.7289, acc: 0.6015, precision: 0.8717, recall: 0.6171, f1: 0.7226, edges-pos-ontonotes_loss: 0.0273
09/17 02:04:16 AM: Update 31816: task edges-pos-ontonotes, batch 816 (31816): mcc: 0.7267, acc: 0.5983, precision: 0.8703, recall: 0.6144, f1: 0.7203, edges-pos-ontonotes_loss: 0.0276
09/17 02:04:26 AM: Update 31855: task edges-pos-ontonotes, batch 855 (31855): mcc: 0.7252, acc: 0.5961, precision: 0.8695, recall: 0.6125, f1: 0.7187, edges-pos-ontonotes_loss: 0.0277
09/17 02:04:37 AM: Update 31914: task edges-pos-ontonotes, batch 914 (31914): mcc: 0.7235, acc: 0.5936, precision: 0.8688, recall: 0.6102, f1: 0.7169, edges-pos-ontonotes_loss: 0.0280
09/17 02:04:47 AM: Update 31969: task edges-pos-ontonotes, batch 969 (31969): mcc: 0.7223, acc: 0.5920, precision: 0.8681, recall: 0.6087, f1: 0.7156, edges-pos-ontonotes_loss: 0.0282
09/17 02:04:55 AM: ***** Step 32000 / Validation 32 *****
09/17 02:04:55 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 02:04:55 AM: Validating...
09/17 02:04:57 AM: Evaluate: task edges-pos-ontonotes, batch 14 (157): mcc: 0.7418, acc: 0.6190, precision: 0.8986, recall: 0.6194, f1: 0.7334, edges-pos-ontonotes_loss: 0.0282
09/17 02:05:07 AM: Evaluate: task edges-pos-ontonotes, batch 82 (157): mcc: 0.7557, acc: 0.6455, precision: 0.8930, recall: 0.6467, f1: 0.7501, edges-pos-ontonotes_loss: 0.0262
09/17 02:05:17 AM: Evaluate: task edges-pos-ontonotes, batch 128 (157): mcc: 0.7398, acc: 0.6179, precision: 0.8944, recall: 0.6190, f1: 0.7316, edges-pos-ontonotes_loss: 0.0272
09/17 02:05:24 AM: Updating LR scheduler:
09/17 02:05:24 AM: 	Best result seen so far for macro_avg: 0.725
09/17 02:05:24 AM: 	# validation passes without improvement: 3
09/17 02:05:24 AM: edges-pos-ontonotes_loss: training: 0.028287 validation: 0.027761
09/17 02:05:24 AM: macro_avg: validation: 0.723972
09/17 02:05:24 AM: micro_avg: validation: 0.000000
09/17 02:05:24 AM: edges-pos-ontonotes_mcc: training: 0.721363 validation: 0.733039
09/17 02:05:24 AM: edges-pos-ontonotes_acc: training: 0.590848 validation: 0.607215
09/17 02:05:24 AM: edges-pos-ontonotes_precision: training: 0.867462 validation: 0.893682
09/17 02:05:24 AM: edges-pos-ontonotes_recall: training: 0.607638 validation: 0.608432
09/17 02:05:24 AM: edges-pos-ontonotes_f1: training: 0.714667 validation: 0.723972
09/17 02:05:24 AM: Global learning rate: 2.5e-05
09/17 02:05:24 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 02:05:27 AM: Update 32018: task edges-pos-ontonotes, batch 18 (32018): mcc: 0.7129, acc: 0.5772, precision: 0.8666, recall: 0.5943, f1: 0.7051, edges-pos-ontonotes_loss: 0.0315
09/17 02:05:37 AM: Update 32070: task edges-pos-ontonotes, batch 70 (32070): mcc: 0.7064, acc: 0.5704, precision: 0.8599, recall: 0.5882, f1: 0.6986, edges-pos-ontonotes_loss: 0.0321
09/17 02:05:48 AM: Update 32103: task edges-pos-ontonotes, batch 103 (32103): mcc: 0.7049, acc: 0.5692, precision: 0.8598, recall: 0.5859, f1: 0.6969, edges-pos-ontonotes_loss: 0.0321
09/17 02:05:58 AM: Update 32149: task edges-pos-ontonotes, batch 149 (32149): mcc: 0.7047, acc: 0.5683, precision: 0.8614, recall: 0.5844, f1: 0.6964, edges-pos-ontonotes_loss: 0.0320
09/17 02:06:08 AM: Update 32194: task edges-pos-ontonotes, batch 194 (32194): mcc: 0.7054, acc: 0.5690, precision: 0.8624, recall: 0.5849, f1: 0.6970, edges-pos-ontonotes_loss: 0.0319
09/17 02:06:18 AM: Update 32241: task edges-pos-ontonotes, batch 241 (32241): mcc: 0.7056, acc: 0.5691, precision: 0.8634, recall: 0.5845, f1: 0.6971, edges-pos-ontonotes_loss: 0.0319
09/17 02:06:28 AM: Update 32288: task edges-pos-ontonotes, batch 288 (32288): mcc: 0.7063, acc: 0.5697, precision: 0.8644, recall: 0.5851, f1: 0.6978, edges-pos-ontonotes_loss: 0.0318
09/17 02:06:38 AM: Update 32342: task edges-pos-ontonotes, batch 342 (32342): mcc: 0.7068, acc: 0.5702, precision: 0.8654, recall: 0.5851, f1: 0.6982, edges-pos-ontonotes_loss: 0.0318
09/17 02:06:49 AM: Update 32393: task edges-pos-ontonotes, batch 393 (32393): mcc: 0.7067, acc: 0.5705, precision: 0.8650, recall: 0.5852, f1: 0.6981, edges-pos-ontonotes_loss: 0.0317
09/17 02:06:59 AM: Update 32442: task edges-pos-ontonotes, batch 442 (32442): mcc: 0.7070, acc: 0.5710, precision: 0.8651, recall: 0.5856, f1: 0.6984, edges-pos-ontonotes_loss: 0.0317
09/17 02:07:09 AM: Update 32485: task edges-pos-ontonotes, batch 485 (32485): mcc: 0.7073, acc: 0.5715, precision: 0.8652, recall: 0.5860, f1: 0.6988, edges-pos-ontonotes_loss: 0.0317
09/17 02:07:20 AM: Update 32520: task edges-pos-ontonotes, batch 520 (32520): mcc: 0.7077, acc: 0.5722, precision: 0.8654, recall: 0.5866, f1: 0.6993, edges-pos-ontonotes_loss: 0.0317
09/17 02:07:30 AM: Update 32556: task edges-pos-ontonotes, batch 556 (32556): mcc: 0.7081, acc: 0.5726, precision: 0.8657, recall: 0.5870, f1: 0.6996, edges-pos-ontonotes_loss: 0.0316
09/17 02:07:40 AM: Update 32599: task edges-pos-ontonotes, batch 599 (32599): mcc: 0.7087, acc: 0.5733, precision: 0.8665, recall: 0.5875, f1: 0.7002, edges-pos-ontonotes_loss: 0.0316
09/17 02:07:50 AM: Update 32637: task edges-pos-ontonotes, batch 637 (32637): mcc: 0.7091, acc: 0.5738, precision: 0.8667, recall: 0.5879, f1: 0.7006, edges-pos-ontonotes_loss: 0.0315
09/17 02:08:00 AM: Update 32676: task edges-pos-ontonotes, batch 676 (32676): mcc: 0.7095, acc: 0.5742, precision: 0.8671, recall: 0.5883, f1: 0.7010, edges-pos-ontonotes_loss: 0.0315
09/17 02:08:12 AM: Update 32706: task edges-pos-ontonotes, batch 706 (32706): mcc: 0.7100, acc: 0.5748, precision: 0.8675, recall: 0.5889, f1: 0.7015, edges-pos-ontonotes_loss: 0.0315
09/17 02:08:22 AM: Update 32743: task edges-pos-ontonotes, batch 743 (32743): mcc: 0.7099, acc: 0.5748, precision: 0.8676, recall: 0.5888, f1: 0.7015, edges-pos-ontonotes_loss: 0.0315
09/17 02:08:32 AM: Update 32784: task edges-pos-ontonotes, batch 784 (32784): mcc: 0.7103, acc: 0.5751, precision: 0.8679, recall: 0.5890, f1: 0.7018, edges-pos-ontonotes_loss: 0.0314
09/17 02:08:42 AM: Update 32825: task edges-pos-ontonotes, batch 825 (32825): mcc: 0.7104, acc: 0.5752, precision: 0.8681, recall: 0.5891, f1: 0.7019, edges-pos-ontonotes_loss: 0.0314
09/17 02:08:52 AM: Update 32865: task edges-pos-ontonotes, batch 865 (32865): mcc: 0.7104, acc: 0.5753, precision: 0.8681, recall: 0.5892, f1: 0.7019, edges-pos-ontonotes_loss: 0.0314
09/17 02:09:03 AM: Update 32903: task edges-pos-ontonotes, batch 903 (32903): mcc: 0.7105, acc: 0.5754, precision: 0.8682, recall: 0.5892, f1: 0.7020, edges-pos-ontonotes_loss: 0.0314
09/17 02:09:13 AM: Update 32937: task edges-pos-ontonotes, batch 937 (32937): mcc: 0.7104, acc: 0.5753, precision: 0.8682, recall: 0.5891, f1: 0.7019, edges-pos-ontonotes_loss: 0.0314
09/17 02:09:23 AM: Update 32975: task edges-pos-ontonotes, batch 975 (32975): mcc: 0.7106, acc: 0.5754, precision: 0.8684, recall: 0.5892, f1: 0.7021, edges-pos-ontonotes_loss: 0.0314
09/17 02:09:30 AM: ***** Step 33000 / Validation 33 *****
09/17 02:09:30 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 02:09:30 AM: Validating...
09/17 02:09:33 AM: Evaluate: task edges-pos-ontonotes, batch 14 (157): mcc: 0.7328, acc: 0.6041, precision: 0.8988, recall: 0.6044, f1: 0.7228, edges-pos-ontonotes_loss: 0.0285
09/17 02:09:43 AM: Evaluate: task edges-pos-ontonotes, batch 70 (157): mcc: 0.7529, acc: 0.6409, precision: 0.8932, recall: 0.6417, f1: 0.7469, edges-pos-ontonotes_loss: 0.0267
09/17 02:09:53 AM: Evaluate: task edges-pos-ontonotes, batch 111 (157): mcc: 0.7427, acc: 0.6215, precision: 0.8946, recall: 0.6237, f1: 0.7350, edges-pos-ontonotes_loss: 0.0271
09/17 02:10:02 AM: Updating LR scheduler:
09/17 02:10:02 AM: 	Best result seen so far for macro_avg: 0.725
09/17 02:10:02 AM: 	# validation passes without improvement: 0
09/17 02:10:02 AM: edges-pos-ontonotes_loss: training: 0.031400 validation: 0.027915
09/17 02:10:02 AM: macro_avg: validation: 0.723271
09/17 02:10:02 AM: micro_avg: validation: 0.000000
09/17 02:10:02 AM: edges-pos-ontonotes_mcc: training: 0.710642 validation: 0.732230
09/17 02:10:02 AM: edges-pos-ontonotes_acc: training: 0.575540 validation: 0.604591
09/17 02:10:02 AM: edges-pos-ontonotes_precision: training: 0.868462 validation: 0.892231
09/17 02:10:02 AM: edges-pos-ontonotes_recall: training: 0.589270 validation: 0.608115
09/17 02:10:02 AM: edges-pos-ontonotes_f1: training: 0.702130 validation: 0.723271
09/17 02:10:02 AM: Global learning rate: 1.25e-05
09/17 02:10:02 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 02:10:03 AM: Update 33004: task edges-pos-ontonotes, batch 4 (33004): mcc: 0.7041, acc: 0.5707, precision: 0.8615, recall: 0.5835, f1: 0.6957, edges-pos-ontonotes_loss: 0.0322
09/17 02:10:17 AM: Update 33019: task edges-pos-ontonotes, batch 19 (33019): mcc: 0.6976, acc: 0.5641, precision: 0.8523, recall: 0.5791, f1: 0.6896, edges-pos-ontonotes_loss: 0.0315
09/17 02:10:27 AM: Update 33100: task edges-pos-ontonotes, batch 100 (33100): mcc: 0.7267, acc: 0.5988, precision: 0.8696, recall: 0.6150, f1: 0.7205, edges-pos-ontonotes_loss: 0.0270
09/17 02:10:37 AM: Update 33176: task edges-pos-ontonotes, batch 176 (33176): mcc: 0.7316, acc: 0.6038, precision: 0.8730, recall: 0.6207, f1: 0.7255, edges-pos-ontonotes_loss: 0.0268
09/17 02:10:47 AM: Update 33228: task edges-pos-ontonotes, batch 228 (33228): mcc: 0.7330, acc: 0.6049, precision: 0.8749, recall: 0.6217, f1: 0.7269, edges-pos-ontonotes_loss: 0.0266
09/17 02:10:57 AM: Update 33287: task edges-pos-ontonotes, batch 287 (33287): mcc: 0.7352, acc: 0.6070, precision: 0.8772, recall: 0.6237, f1: 0.7291, edges-pos-ontonotes_loss: 0.0263
09/17 02:11:07 AM: Update 33339: task edges-pos-ontonotes, batch 339 (33339): mcc: 0.7378, acc: 0.6101, precision: 0.8791, recall: 0.6266, f1: 0.7317, edges-pos-ontonotes_loss: 0.0261
09/17 02:11:17 AM: Update 33428: task edges-pos-ontonotes, batch 428 (33428): mcc: 0.7487, acc: 0.6248, precision: 0.8840, recall: 0.6414, f1: 0.7434, edges-pos-ontonotes_loss: 0.0252
09/17 02:11:27 AM: Update 33528: task edges-pos-ontonotes, batch 528 (33528): mcc: 0.7584, acc: 0.6377, precision: 0.8882, recall: 0.6546, f1: 0.7537, edges-pos-ontonotes_loss: 0.0243
09/17 02:11:37 AM: Update 33641: task edges-pos-ontonotes, batch 641 (33641): mcc: 0.7658, acc: 0.6476, precision: 0.8918, recall: 0.6646, f1: 0.7616, edges-pos-ontonotes_loss: 0.0237
09/17 02:11:47 AM: Update 33717: task edges-pos-ontonotes, batch 717 (33717): mcc: 0.7688, acc: 0.6521, precision: 0.8925, recall: 0.6691, f1: 0.7649, edges-pos-ontonotes_loss: 0.0234
09/17 02:11:57 AM: Update 33813: task edges-pos-ontonotes, batch 813 (33813): mcc: 0.7719, acc: 0.6568, precision: 0.8933, recall: 0.6740, f1: 0.7683, edges-pos-ontonotes_loss: 0.0230
09/17 02:12:07 AM: Update 33929: task edges-pos-ontonotes, batch 929 (33929): mcc: 0.7750, acc: 0.6613, precision: 0.8940, recall: 0.6786, f1: 0.7716, edges-pos-ontonotes_loss: 0.0227
09/17 02:12:13 AM: ***** Step 34000 / Validation 34 *****
09/17 02:12:13 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 02:12:13 AM: Validating...
09/17 02:12:17 AM: Evaluate: task edges-pos-ontonotes, batch 45 (157): mcc: 0.7431, acc: 0.6192, precision: 0.9007, recall: 0.6200, f1: 0.7345, edges-pos-ontonotes_loss: 0.0270
09/17 02:12:27 AM: Evaluate: task edges-pos-ontonotes, batch 125 (157): mcc: 0.7337, acc: 0.6032, precision: 0.8979, recall: 0.6066, f1: 0.7240, edges-pos-ontonotes_loss: 0.0274
09/17 02:12:33 AM: Updating LR scheduler:
09/17 02:12:33 AM: 	Best result seen so far for macro_avg: 0.725
09/17 02:12:33 AM: 	# validation passes without improvement: 1
09/17 02:12:33 AM: edges-pos-ontonotes_loss: training: 0.022689 validation: 0.028045
09/17 02:12:33 AM: macro_avg: validation: 0.714091
09/17 02:12:33 AM: micro_avg: validation: 0.000000
09/17 02:12:33 AM: edges-pos-ontonotes_mcc: training: 0.775011 validation: 0.724819
09/17 02:12:33 AM: edges-pos-ontonotes_acc: training: 0.661600 validation: 0.590294
09/17 02:12:33 AM: edges-pos-ontonotes_precision: training: 0.893390 validation: 0.895580
09/17 02:12:33 AM: edges-pos-ontonotes_recall: training: 0.679193 validation: 0.593765
09/17 02:12:33 AM: edges-pos-ontonotes_f1: training: 0.771704 validation: 0.714091
09/17 02:12:33 AM: Global learning rate: 1.25e-05
09/17 02:12:33 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 02:12:38 AM: Update 34069: task edges-pos-ontonotes, batch 69 (34069): mcc: 0.7849, acc: 0.6839, precision: 0.8823, recall: 0.7053, f1: 0.7839, edges-pos-ontonotes_loss: 0.0203
09/17 02:12:48 AM: Update 34184: task edges-pos-ontonotes, batch 184 (34184): mcc: 0.7808, acc: 0.6794, precision: 0.8801, recall: 0.6998, f1: 0.7796, edges-pos-ontonotes_loss: 0.0207
09/17 02:12:58 AM: Update 34272: task edges-pos-ontonotes, batch 272 (34272): mcc: 0.7783, acc: 0.6760, precision: 0.8805, recall: 0.6950, f1: 0.7768, edges-pos-ontonotes_loss: 0.0207
09/17 02:13:08 AM: Update 34325: task edges-pos-ontonotes, batch 325 (34325): mcc: 0.7529, acc: 0.6404, precision: 0.8701, recall: 0.6591, f1: 0.7500, edges-pos-ontonotes_loss: 0.0227
09/17 02:13:18 AM: Update 34381: task edges-pos-ontonotes, batch 381 (34381): mcc: 0.7397, acc: 0.6221, precision: 0.8654, recall: 0.6400, f1: 0.7358, edges-pos-ontonotes_loss: 0.0242
09/17 02:13:28 AM: Update 34432: task edges-pos-ontonotes, batch 432 (34432): mcc: 0.7323, acc: 0.6116, precision: 0.8632, recall: 0.6291, f1: 0.7278, edges-pos-ontonotes_loss: 0.0252
09/17 02:13:38 AM: Update 34481: task edges-pos-ontonotes, batch 481 (34481): mcc: 0.7274, acc: 0.6043, precision: 0.8621, recall: 0.6216, f1: 0.7224, edges-pos-ontonotes_loss: 0.0259
09/17 02:13:48 AM: Update 34530: task edges-pos-ontonotes, batch 530 (34530): mcc: 0.7232, acc: 0.5986, precision: 0.8607, recall: 0.6156, f1: 0.7178, edges-pos-ontonotes_loss: 0.0265
09/17 02:13:58 AM: Update 34574: task edges-pos-ontonotes, batch 574 (34574): mcc: 0.7203, acc: 0.5945, precision: 0.8596, recall: 0.6115, f1: 0.7146, edges-pos-ontonotes_loss: 0.0270
09/17 02:14:08 AM: Update 34603: task edges-pos-ontonotes, batch 603 (34603): mcc: 0.7186, acc: 0.5923, precision: 0.8588, recall: 0.6092, f1: 0.7128, edges-pos-ontonotes_loss: 0.0273
09/17 02:14:18 AM: Update 34676: task edges-pos-ontonotes, batch 676 (34676): mcc: 0.7217, acc: 0.5962, precision: 0.8609, recall: 0.6129, f1: 0.7161, edges-pos-ontonotes_loss: 0.0269
09/17 02:14:28 AM: Update 34733: task edges-pos-ontonotes, batch 733 (34733): mcc: 0.7237, acc: 0.5987, precision: 0.8622, recall: 0.6154, f1: 0.7182, edges-pos-ontonotes_loss: 0.0268
09/17 02:14:39 AM: Update 34801: task edges-pos-ontonotes, batch 801 (34801): mcc: 0.7263, acc: 0.6018, precision: 0.8639, recall: 0.6184, f1: 0.7208, edges-pos-ontonotes_loss: 0.0266
09/17 02:14:49 AM: Update 34871: task edges-pos-ontonotes, batch 871 (34871): mcc: 0.7283, acc: 0.6046, precision: 0.8651, recall: 0.6210, f1: 0.7230, edges-pos-ontonotes_loss: 0.0263
09/17 02:14:59 AM: Update 34914: task edges-pos-ontonotes, batch 914 (34914): mcc: 0.7295, acc: 0.6060, precision: 0.8657, recall: 0.6226, f1: 0.7243, edges-pos-ontonotes_loss: 0.0262
09/17 02:15:09 AM: Update 34960: task edges-pos-ontonotes, batch 960 (34960): mcc: 0.7295, acc: 0.6057, precision: 0.8665, recall: 0.6220, f1: 0.7241, edges-pos-ontonotes_loss: 0.0263
09/17 02:15:18 AM: ***** Step 35000 / Validation 35 *****
09/17 02:15:18 AM: edges-pos-ontonotes: trained on 1000 batches, 0.290 epochs
09/17 02:15:18 AM: Validating...
09/17 02:15:19 AM: Evaluate: task edges-pos-ontonotes, batch 6 (157): mcc: 0.7134, acc: 0.5754, precision: 0.8958, recall: 0.5754, f1: 0.7007, edges-pos-ontonotes_loss: 0.0285
09/17 02:15:29 AM: Evaluate: task edges-pos-ontonotes, batch 64 (157): mcc: 0.7583, acc: 0.6452, precision: 0.8994, recall: 0.6463, f1: 0.7521, edges-pos-ontonotes_loss: 0.0259
09/17 02:15:39 AM: Evaluate: task edges-pos-ontonotes, batch 118 (157): mcc: 0.7332, acc: 0.6062, precision: 0.8930, recall: 0.6091, f1: 0.7242, edges-pos-ontonotes_loss: 0.0270
09/17 02:15:45 AM: Updating LR scheduler:
09/17 02:15:45 AM: 	Best result seen so far for macro_avg: 0.725
09/17 02:15:45 AM: 	# validation passes without improvement: 2
09/17 02:15:45 AM: Ran out of early stopping patience. Stopping training.
09/17 02:15:45 AM: edges-pos-ontonotes_loss: training: 0.026389 validation: 0.028017
09/17 02:15:45 AM: macro_avg: validation: 0.708988
09/17 02:15:45 AM: micro_avg: validation: 0.000000
09/17 02:15:45 AM: edges-pos-ontonotes_mcc: training: 0.729354 validation: 0.719455
09/17 02:15:45 AM: edges-pos-ontonotes_acc: training: 0.605233 validation: 0.586156
09/17 02:15:45 AM: edges-pos-ontonotes_precision: training: 0.866955 validation: 0.888770
09/17 02:15:45 AM: edges-pos-ontonotes_recall: training: 0.621342 validation: 0.589701
09/17 02:15:45 AM: edges-pos-ontonotes_f1: training: 0.723882 validation: 0.708988
09/17 02:15:45 AM: Global learning rate: 1.25e-05
09/17 02:15:45 AM: Saving checkpoints to: ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 02:15:45 AM: Stopped training after 35 validation checks
09/17 02:15:45 AM: Trained edges-pos-ontonotes for 35000 batches or 10.133 epochs
09/17 02:15:45 AM: ***** VALIDATION RESULTS *****
09/17 02:15:45 AM: edges-pos-ontonotes_f1 (for best val pass 25): edges-pos-ontonotes_loss: 0.02781, macro_avg: 0.72547, micro_avg: 0.00000, edges-pos-ontonotes_mcc: 0.73444, edges-pos-ontonotes_acc: 0.60895, edges-pos-ontonotes_precision: 0.89447, edges-pos-ontonotes_recall: 0.61018, edges-pos-ontonotes_f1: 0.72547
09/17 02:15:45 AM: micro_avg (for best val pass 1): edges-pos-ontonotes_loss: 0.09050, macro_avg: 0.54172, micro_avg: 0.00000, edges-pos-ontonotes_mcc: 0.56332, edges-pos-ontonotes_acc: 0.41106, edges-pos-ontonotes_precision: 0.78335, edges-pos-ontonotes_recall: 0.41401, edges-pos-ontonotes_f1: 0.54172
09/17 02:15:45 AM: macro_avg (for best val pass 25): edges-pos-ontonotes_loss: 0.02781, macro_avg: 0.72547, micro_avg: 0.00000, edges-pos-ontonotes_mcc: 0.73444, edges-pos-ontonotes_acc: 0.60895, edges-pos-ontonotes_precision: 0.89447, edges-pos-ontonotes_recall: 0.61018, edges-pos-ontonotes_f1: 0.72547
09/17 02:15:45 AM: Evaluating...
09/17 02:15:45 AM: Loaded model state from ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run/edges-pos-ontonotes/model_state_target_train_val_25.best.th
09/17 02:15:45 AM: Evaluating on: edges-pos-ontonotes, split: val
09/17 02:16:15 AM: 	Task edges-pos-ontonotes: batch 192
09/17 02:16:45 AM: 	Task edges-pos-ontonotes: batch 318
09/17 02:17:02 AM: Task 'edges-pos-ontonotes': sorting predictions by 'idx'
09/17 02:17:02 AM: Finished evaluating on: edges-pos-ontonotes
09/17 02:17:02 AM: Task 'edges-pos-ontonotes': joining predictions with input split 'val'
09/17 02:17:13 AM: Task 'edges-pos-ontonotes': Wrote predictions to ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 02:17:13 AM: Wrote all preds for split 'val' to ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 02:17:13 AM: Evaluating on: edges-pos-ontonotes, split: test
09/17 02:17:43 AM: 	Task edges-pos-ontonotes: batch 198
09/17 02:18:02 AM: Task 'edges-pos-ontonotes': sorting predictions by 'idx'
09/17 02:18:02 AM: Finished evaluating on: edges-pos-ontonotes
09/17 02:18:02 AM: Task 'edges-pos-ontonotes': joining predictions with input split 'test'
09/17 02:18:10 AM: Task 'edges-pos-ontonotes': Wrote predictions to ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 02:18:10 AM: Wrote all preds for split 'test' to ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/run
09/17 02:18:10 AM: Writing results for split 'val' to ./experiments/pos-ontonotes-RANDOM_WITH_GOOD_EMBEDDINGS-only/results.tsv
09/17 02:18:10 AM: micro_avg: 0.000, macro_avg: 0.725, edges-pos-ontonotes_mcc: 0.734, edges-pos-ontonotes_acc: 0.608, edges-pos-ontonotes_precision: 0.893, edges-pos-ontonotes_recall: 0.610, edges-pos-ontonotes_f1: 0.725
09/17 02:18:12 AM: Done!
09/17 02:18:12 AM: Fatal error in main():
Traceback (most recent call last):
  File "main.py", line 16, in <module>
    main(sys.argv[1:])
  File "/srv/home/ericwallace/jiant/jiant/__main__.py", line 610, in main
    exit("Done exited")
  File "/home/ericwallace/miniconda3/envs/jiant/lib/python3.6/_sitebuiltins.py", line 26, in __call__
    raise SystemExit(code)
SystemExit: Done exited
