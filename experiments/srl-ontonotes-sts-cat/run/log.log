09/16 09:10:58 AM: Git branch: master
09/16 09:10:58 AM: Git SHA: 1a42459c6cbb693793b9c0d01bca567d99b0baac
09/16 09:10:58 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/srl-ontonotes-sts-cat/",
  "exp_name": "experiments/srl-ontonotes-sts-cat",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/srl-ontonotes-sts-cat/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/sts",
  "pytorch_transformers_output_mode": "cat",
  "remote_log_name": "experiments/srl-ontonotes-sts-cat__run",
  "run_dir": "./experiments/srl-ontonotes-sts-cat/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-srl-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 09:10:58 AM: Saved config to ./experiments/srl-ontonotes-sts-cat/run/params.conf
09/16 09:10:58 AM: Using random seed 1234
09/16 09:10:59 AM: Using GPU 0
09/16 09:10:59 AM: Loading tasks...
09/16 09:10:59 AM: Writing pre-preprocessed tasks to ./experiments/srl-ontonotes-sts-cat/
09/16 09:10:59 AM: 	Creating task edges-srl-ontonotes from scratch.
09/16 09:11:04 AM: Read=231480, Skip=21590, Total=253070 from ./probing_data/edges/ontonotes/srl/train.json.retokenized.bert-base-uncased
09/16 09:11:04 AM: Read=32486, Skip=2811, Total=35297 from ./probing_data/edges/ontonotes/srl/development.json.retokenized.bert-base-uncased
09/16 09:11:05 AM: Read=23800, Skip=2915, Total=26715 from ./probing_data/edges/ontonotes/srl/test.json.retokenized.bert-base-uncased
09/16 09:11:08 AM: 	Task 'edges-srl-ontonotes': |train|=231480 |val|=32486 |test|=23800
09/16 09:11:08 AM: 	Finished loading tasks: edges-srl-ontonotes.
09/16 09:11:08 AM: 	Building vocab from scratch.
09/16 09:11:08 AM: 	Counting units for task edges-srl-ontonotes.
09/16 09:11:15 AM: 	Task 'edges-srl-ontonotes': adding vocab namespace 'edges-srl-ontonotes_labels'
09/16 09:11:16 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:11:16 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 09:11:16 AM: 	Saved vocab to ./experiments/srl-ontonotes-sts-cat/vocab
09/16 09:11:16 AM: Loading token dictionary from ./experiments/srl-ontonotes-sts-cat/vocab.
09/16 09:11:16 AM: 	Loaded vocab from ./experiments/srl-ontonotes-sts-cat/vocab
09/16 09:11:16 AM: 	Vocab namespace bert_uncased: size 30524
09/16 09:11:16 AM: 	Vocab namespace tokens: size 23662
09/16 09:11:16 AM: 	Vocab namespace edges-srl-ontonotes_labels: size 66
09/16 09:11:16 AM: 	Vocab namespace chars: size 76
09/16 09:11:16 AM: 	Finished building vocab.
09/16 09:11:16 AM: 	Task edges-srl-ontonotes (train): Indexing from scratch.
09/16 09:11:50 AM: 	Task edges-srl-ontonotes (train): Saved 231480 instances to ./experiments/srl-ontonotes-sts-cat/preproc/edges-srl-ontonotes__train_data
09/16 09:11:50 AM: 	Task edges-srl-ontonotes (val): Indexing from scratch.
09/16 09:11:54 AM: 	Task edges-srl-ontonotes (val): Saved 32486 instances to ./experiments/srl-ontonotes-sts-cat/preproc/edges-srl-ontonotes__val_data
09/16 09:11:54 AM: 	Task edges-srl-ontonotes (test): Indexing from scratch.
09/16 09:11:57 AM: 	Task edges-srl-ontonotes (test): Saved 23800 instances to ./experiments/srl-ontonotes-sts-cat/preproc/edges-srl-ontonotes__test_data
09/16 09:11:57 AM: 	Finished indexing tasks
09/16 09:11:57 AM: 	Creating trimmed target-only version of edges-srl-ontonotes train.
09/16 09:11:57 AM: 	  Training on 
09/16 09:11:57 AM: 	  Evaluating on edges-srl-ontonotes
09/16 09:11:57 AM: 	Finished loading tasks in 58.155s
09/16 09:11:57 AM: 	 Tasks: ['edges-srl-ontonotes']
09/16 09:11:57 AM: Building model...
09/16 09:11:57 AM: Using BERT model (bert-base-uncased).
09/16 09:11:57 AM: LOADING A FUNETUNED MODEL from: 
09/16 09:11:57 AM: models/sts
09/16 09:11:57 AM: loading configuration file models/sts/config.json
09/16 09:11:57 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "sts-b",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 1,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 09:11:57 AM: loading weights file models/sts/pytorch_model.bin
09/16 09:12:00 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpzkhcpa5j
09/16 09:12:04 AM: copying /tmp/tmpzkhcpa5j to cache at ./experiments/srl-ontonotes-sts-cat/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:12:04 AM: creating metadata file for ./experiments/srl-ontonotes-sts-cat/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:12:04 AM: removing temp file /tmp/tmpzkhcpa5j
09/16 09:12:04 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/srl-ontonotes-sts-cat/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 09:12:04 AM: Initializing parameters
09/16 09:12:04 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 09:12:04 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 09:12:04 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 09:12:04 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 09:12:04 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 09:12:04 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 09:12:04 AM: 	Task 'edges-srl-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-srl-ontonotes"
}
09/16 09:12:08 AM: Model specification:
09/16 09:12:08 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-srl-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(1536, 256, kernel_size=(1,), stride=(1,))
    (proj2): Conv1d(1536, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (span_extractor2): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Sequential(
        (0): Linear(in_features=1024, out_features=256, bias=True)
        (1): Tanh()
        (2): LayerNorm(torch.Size([256]), eps=1e-05, elementwise_affine=True)
        (3): Dropout(p=0.3)
        (4): Linear(in_features=256, out_features=66, bias=True)
      )
    )
  )
)
09/16 09:12:08 AM: Model parameters:
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 09:12:08 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 09:12:08 AM: 	edges-srl-ontonotes_mdl.proj1.weight: Trainable parameter, count 393216 with torch.Size([256, 1536, 1])
09/16 09:12:08 AM: 	edges-srl-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 09:12:08 AM: 	edges-srl-ontonotes_mdl.proj2.weight: Trainable parameter, count 393216 with torch.Size([256, 1536, 1])
09/16 09:12:08 AM: 	edges-srl-ontonotes_mdl.proj2.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 09:12:08 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.0.weight: Trainable parameter, count 262144 with torch.Size([256, 1024])
09/16 09:12:08 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.0.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 09:12:08 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.2.weight: Trainable parameter, count 256 with torch.Size([256])
09/16 09:12:08 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.2.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 09:12:08 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.4.weight: Trainable parameter, count 16896 with torch.Size([66, 256])
09/16 09:12:08 AM: 	edges-srl-ontonotes_mdl.classifier.classifier.4.bias: Trainable parameter, count 66 with torch.Size([66])
09/16 09:12:08 AM: Total number of parameters: 110549058 (1.10549e+08)
09/16 09:12:08 AM: Number of trainable parameters: 1066818 (1.06682e+06)
09/16 09:12:08 AM: Finished building model in 10.540s
09/16 09:12:08 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-srl-ontonotes 

09/16 09:12:22 AM: patience = 9
09/16 09:12:22 AM: val_interval = 1000
09/16 09:12:22 AM: max_vals = 250
09/16 09:12:22 AM: cuda_device = 0
09/16 09:12:22 AM: grad_norm = 5.0
09/16 09:12:22 AM: grad_clipping = None
09/16 09:12:22 AM: lr_decay = 0.99
09/16 09:12:22 AM: min_lr = 1e-06
09/16 09:12:22 AM: keep_all_checkpoints = 0
09/16 09:12:22 AM: val_data_limit = 5000
09/16 09:12:22 AM: max_epochs = -1
09/16 09:12:22 AM: dec_val_scale = 250
09/16 09:12:22 AM: training_data_fraction = 1
09/16 09:12:22 AM: type = adam
09/16 09:12:22 AM: parameter_groups = None
09/16 09:12:22 AM: Number of trainable parameters: 1066818
09/16 09:12:22 AM: infer_type_and_cast = True
09/16 09:12:22 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:12:22 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:12:22 AM: lr = 0.0001
09/16 09:12:22 AM: amsgrad = True
09/16 09:12:22 AM: type = reduce_on_plateau
09/16 09:12:22 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:12:22 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:12:22 AM: mode = max
09/16 09:12:22 AM: factor = 0.5
09/16 09:12:22 AM: patience = 3
09/16 09:12:22 AM: threshold = 0.0001
09/16 09:12:22 AM: threshold_mode = abs
09/16 09:12:22 AM: verbose = True
09/16 09:12:22 AM: type = adam
09/16 09:12:22 AM: parameter_groups = None
09/16 09:12:22 AM: Number of trainable parameters: 1066818
09/16 09:12:22 AM: infer_type_and_cast = True
09/16 09:12:22 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:12:22 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:12:22 AM: lr = 0.0001
09/16 09:12:22 AM: amsgrad = True
09/16 09:12:22 AM: type = reduce_on_plateau
09/16 09:12:22 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 09:12:22 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 09:12:22 AM: mode = max
09/16 09:12:22 AM: factor = 0.5
09/16 09:12:22 AM: patience = 3
09/16 09:12:22 AM: threshold = 0.0001
09/16 09:12:22 AM: threshold_mode = abs
09/16 09:12:22 AM: verbose = True
09/16 09:12:22 AM: Starting training without restoring from a checkpoint.
09/16 09:12:22 AM: Training examples per task, before any subsampling: {'edges-srl-ontonotes': 231480}
09/16 09:12:22 AM: Beginning training with stopping criteria based on metric: edges-srl-ontonotes_f1
09/16 09:12:32 AM: Update 122: task edges-srl-ontonotes, batch 122 (122): mcc: 0.0436, acc: 0.0306, precision: 0.0509, recall: 0.0730, f1: 0.0600, edges-srl-ontonotes_loss: 0.1940
09/16 09:12:42 AM: Update 258: task edges-srl-ontonotes, batch 258 (258): mcc: 0.1128, acc: 0.0888, precision: 0.1422, recall: 0.1091, f1: 0.1235, edges-srl-ontonotes_loss: 0.1256
09/16 09:12:52 AM: Update 375: task edges-srl-ontonotes, batch 375 (375): mcc: 0.2045, acc: 0.1588, precision: 0.2640, recall: 0.1737, f1: 0.2096, edges-srl-ontonotes_loss: 0.1006
09/16 09:13:02 AM: Update 518: task edges-srl-ontonotes, batch 518 (518): mcc: 0.3051, acc: 0.2348, precision: 0.3944, recall: 0.2489, f1: 0.3052, edges-srl-ontonotes_loss: 0.0829
09/16 09:13:12 AM: Update 628: task edges-srl-ontonotes, batch 628 (628): mcc: 0.3664, acc: 0.2829, precision: 0.4702, recall: 0.2974, f1: 0.3644, edges-srl-ontonotes_loss: 0.0739
09/16 09:13:22 AM: Update 760: task edges-srl-ontonotes, batch 760 (760): mcc: 0.4137, acc: 0.3194, precision: 0.5269, recall: 0.3358, f1: 0.4102, edges-srl-ontonotes_loss: 0.0663
09/16 09:13:32 AM: Update 898: task edges-srl-ontonotes, batch 898 (898): mcc: 0.4552, acc: 0.3536, precision: 0.5736, recall: 0.3717, f1: 0.4511, edges-srl-ontonotes_loss: 0.0604
09/16 09:13:40 AM: ***** Step 1000 / Validation 1 *****
09/16 09:13:40 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:13:40 AM: Validating...
09/16 09:13:42 AM: Evaluate: task edges-srl-ontonotes, batch 31 (157): mcc: 0.7269, acc: 0.6109, precision: 0.8439, recall: 0.6321, f1: 0.7228, edges-srl-ontonotes_loss: 0.0243
09/16 09:13:52 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:13:52 AM: Best result seen so far for micro.
09/16 09:13:52 AM: Best result seen so far for macro.
09/16 09:13:52 AM: Updating LR scheduler:
09/16 09:13:52 AM: 	Best result seen so far for macro_avg: 0.729
09/16 09:13:52 AM: 	# validation passes without improvement: 0
09/16 09:13:52 AM: edges-srl-ontonotes_loss: training: 0.056909 validation: 0.023376
09/16 09:13:52 AM: macro_avg: validation: 0.729319
09/16 09:13:52 AM: micro_avg: validation: 0.000000
09/16 09:13:52 AM: edges-srl-ontonotes_mcc: training: 0.478610 validation: 0.733391
09/16 09:13:52 AM: edges-srl-ontonotes_acc: training: 0.373537 validation: 0.621353
09/16 09:13:52 AM: edges-srl-ontonotes_precision: training: 0.598724 validation: 0.850087
09/16 09:13:52 AM: edges-srl-ontonotes_recall: training: 0.392674 validation: 0.638596
09/16 09:13:52 AM: edges-srl-ontonotes_f1: training: 0.474286 validation: 0.729319
09/16 09:13:52 AM: Global learning rate: 0.0001
09/16 09:13:52 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:13:52 AM: Update 1008: task edges-srl-ontonotes, batch 8 (1008): mcc: 0.6825, acc: 0.5597, precision: 0.8049, recall: 0.5855, f1: 0.6779, edges-srl-ontonotes_loss: 0.0264
09/16 09:14:02 AM: Update 1135: task edges-srl-ontonotes, batch 135 (1135): mcc: 0.6931, acc: 0.5709, precision: 0.8109, recall: 0.5992, f1: 0.6891, edges-srl-ontonotes_loss: 0.0258
09/16 09:14:13 AM: Update 1253: task edges-srl-ontonotes, batch 253 (1253): mcc: 0.6996, acc: 0.5771, precision: 0.8151, recall: 0.6070, f1: 0.6958, edges-srl-ontonotes_loss: 0.0251
09/16 09:14:23 AM: Update 1375: task edges-srl-ontonotes, batch 375 (1375): mcc: 0.7018, acc: 0.5817, precision: 0.8123, recall: 0.6129, f1: 0.6986, edges-srl-ontonotes_loss: 0.0247
09/16 09:14:33 AM: Update 1501: task edges-srl-ontonotes, batch 501 (1501): mcc: 0.7121, acc: 0.5950, precision: 0.8178, recall: 0.6265, f1: 0.7095, edges-srl-ontonotes_loss: 0.0239
09/16 09:14:43 AM: Update 1617: task edges-srl-ontonotes, batch 617 (1617): mcc: 0.7139, acc: 0.5976, precision: 0.8175, recall: 0.6299, f1: 0.7116, edges-srl-ontonotes_loss: 0.0236
09/16 09:14:53 AM: Update 1743: task edges-srl-ontonotes, batch 743 (1743): mcc: 0.7136, acc: 0.5975, precision: 0.8163, recall: 0.6304, f1: 0.7114, edges-srl-ontonotes_loss: 0.0236
09/16 09:15:03 AM: Update 1866: task edges-srl-ontonotes, batch 866 (1866): mcc: 0.7143, acc: 0.5986, precision: 0.8162, recall: 0.6317, f1: 0.7122, edges-srl-ontonotes_loss: 0.0235
09/16 09:15:13 AM: Update 1953: task edges-srl-ontonotes, batch 953 (1953): mcc: 0.7163, acc: 0.6007, precision: 0.8174, recall: 0.6343, f1: 0.7143, edges-srl-ontonotes_loss: 0.0233
09/16 09:15:18 AM: ***** Step 2000 / Validation 2 *****
09/16 09:15:18 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:15:18 AM: Validating...
09/16 09:15:23 AM: Evaluate: task edges-srl-ontonotes, batch 77 (157): mcc: 0.7663, acc: 0.6692, precision: 0.8629, recall: 0.6860, f1: 0.7644, edges-srl-ontonotes_loss: 0.0193
09/16 09:15:30 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:15:30 AM: Best result seen so far for macro.
09/16 09:15:30 AM: Updating LR scheduler:
09/16 09:15:30 AM: 	Best result seen so far for macro_avg: 0.779
09/16 09:15:30 AM: 	# validation passes without improvement: 0
09/16 09:15:30 AM: edges-srl-ontonotes_loss: training: 0.023249 validation: 0.018413
09/16 09:15:30 AM: macro_avg: validation: 0.778885
09/16 09:15:30 AM: micro_avg: validation: 0.000000
09/16 09:15:30 AM: edges-srl-ontonotes_mcc: training: 0.716923 validation: 0.780452
09/16 09:15:30 AM: edges-srl-ontonotes_acc: training: 0.601595 validation: 0.685705
09/16 09:15:30 AM: edges-srl-ontonotes_precision: training: 0.817520 validation: 0.872150
09/16 09:15:30 AM: edges-srl-ontonotes_recall: training: 0.635217 validation: 0.703641
09/16 09:15:30 AM: edges-srl-ontonotes_f1: training: 0.714930 validation: 0.778885
09/16 09:15:30 AM: Global learning rate: 0.0001
09/16 09:15:30 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:15:33 AM: Update 2051: task edges-srl-ontonotes, batch 51 (2051): mcc: 0.7400, acc: 0.6308, precision: 0.8275, recall: 0.6680, f1: 0.7393, edges-srl-ontonotes_loss: 0.0216
09/16 09:15:43 AM: Update 2171: task edges-srl-ontonotes, batch 171 (2171): mcc: 0.7325, acc: 0.6241, precision: 0.8206, recall: 0.6604, f1: 0.7318, edges-srl-ontonotes_loss: 0.0217
09/16 09:15:53 AM: Update 2273: task edges-srl-ontonotes, batch 273 (2273): mcc: 0.7381, acc: 0.6323, precision: 0.8238, recall: 0.6676, f1: 0.7375, edges-srl-ontonotes_loss: 0.0214
09/16 09:16:03 AM: Update 2383: task edges-srl-ontonotes, batch 383 (2383): mcc: 0.7475, acc: 0.6444, precision: 0.8297, recall: 0.6797, f1: 0.7472, edges-srl-ontonotes_loss: 0.0207
09/16 09:16:14 AM: Update 2505: task edges-srl-ontonotes, batch 505 (2505): mcc: 0.7525, acc: 0.6504, precision: 0.8328, recall: 0.6860, f1: 0.7523, edges-srl-ontonotes_loss: 0.0204
09/16 09:16:24 AM: Update 2628: task edges-srl-ontonotes, batch 628 (2628): mcc: 0.7558, acc: 0.6554, precision: 0.8346, recall: 0.6904, f1: 0.7557, edges-srl-ontonotes_loss: 0.0202
09/16 09:16:34 AM: Update 2749: task edges-srl-ontonotes, batch 749 (2749): mcc: 0.7585, acc: 0.6592, precision: 0.8360, recall: 0.6941, f1: 0.7585, edges-srl-ontonotes_loss: 0.0199
09/16 09:16:44 AM: Update 2840: task edges-srl-ontonotes, batch 840 (2840): mcc: 0.7617, acc: 0.6635, precision: 0.8380, recall: 0.6983, f1: 0.7618, edges-srl-ontonotes_loss: 0.0197
09/16 09:16:54 AM: Update 2961: task edges-srl-ontonotes, batch 961 (2961): mcc: 0.7653, acc: 0.6685, precision: 0.8403, recall: 0.7028, f1: 0.7654, edges-srl-ontonotes_loss: 0.0194
09/16 09:16:58 AM: ***** Step 3000 / Validation 3 *****
09/16 09:16:58 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:16:58 AM: Validating...
09/16 09:17:04 AM: Evaluate: task edges-srl-ontonotes, batch 87 (157): mcc: 0.7827, acc: 0.7036, precision: 0.8506, recall: 0.7258, f1: 0.7832, edges-srl-ontonotes_loss: 0.0179
09/16 09:17:10 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:17:10 AM: Best result seen so far for macro.
09/16 09:17:10 AM: Updating LR scheduler:
09/16 09:17:10 AM: 	Best result seen so far for macro_avg: 0.797
09/16 09:17:10 AM: 	# validation passes without improvement: 0
09/16 09:17:10 AM: edges-srl-ontonotes_loss: training: 0.019395 validation: 0.017046
09/16 09:17:10 AM: macro_avg: validation: 0.797258
09/16 09:17:10 AM: micro_avg: validation: 0.000000
09/16 09:17:10 AM: edges-srl-ontonotes_mcc: training: 0.765976 validation: 0.796546
09/16 09:17:10 AM: edges-srl-ontonotes_acc: training: 0.669601 validation: 0.720807
09/16 09:17:10 AM: edges-srl-ontonotes_precision: training: 0.840651 validation: 0.859891
09/16 09:17:10 AM: edges-srl-ontonotes_recall: training: 0.703781 validation: 0.743130
09/16 09:17:10 AM: edges-srl-ontonotes_f1: training: 0.766152 validation: 0.797258
09/16 09:17:10 AM: Global learning rate: 0.0001
09/16 09:17:10 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:17:14 AM: Update 3055: task edges-srl-ontonotes, batch 55 (3055): mcc: 0.7994, acc: 0.7137, precision: 0.8618, recall: 0.7467, f1: 0.8001, edges-srl-ontonotes_loss: 0.0171
09/16 09:17:24 AM: Update 3175: task edges-srl-ontonotes, batch 175 (3175): mcc: 0.7895, acc: 0.7034, precision: 0.8533, recall: 0.7359, f1: 0.7903, edges-srl-ontonotes_loss: 0.0176
09/16 09:17:35 AM: Update 3297: task edges-srl-ontonotes, batch 297 (3297): mcc: 0.7847, acc: 0.6973, precision: 0.8500, recall: 0.7301, f1: 0.7855, edges-srl-ontonotes_loss: 0.0179
09/16 09:17:45 AM: Update 3408: task edges-srl-ontonotes, batch 408 (3408): mcc: 0.7831, acc: 0.6954, precision: 0.8489, recall: 0.7281, f1: 0.7838, edges-srl-ontonotes_loss: 0.0180
09/16 09:17:55 AM: Update 3528: task edges-srl-ontonotes, batch 528 (3528): mcc: 0.7833, acc: 0.6956, precision: 0.8483, recall: 0.7289, f1: 0.7841, edges-srl-ontonotes_loss: 0.0179
09/16 09:18:05 AM: Update 3649: task edges-srl-ontonotes, batch 649 (3649): mcc: 0.7827, acc: 0.6943, precision: 0.8480, recall: 0.7280, f1: 0.7834, edges-srl-ontonotes_loss: 0.0179
09/16 09:18:15 AM: Update 3757: task edges-srl-ontonotes, batch 757 (3757): mcc: 0.7835, acc: 0.6953, precision: 0.8484, recall: 0.7291, f1: 0.7842, edges-srl-ontonotes_loss: 0.0178
09/16 09:18:25 AM: Update 3882: task edges-srl-ontonotes, batch 882 (3882): mcc: 0.7841, acc: 0.6963, precision: 0.8488, recall: 0.7299, f1: 0.7849, edges-srl-ontonotes_loss: 0.0178
09/16 09:18:35 AM: ***** Step 4000 / Validation 4 *****
09/16 09:18:35 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:18:35 AM: Validating...
09/16 09:18:35 AM: Evaluate: task edges-srl-ontonotes, batch 2 (157): mcc: 0.8270, acc: 0.7557, precision: 0.8839, recall: 0.7784, f1: 0.8278, edges-srl-ontonotes_loss: 0.0160
09/16 09:18:46 AM: Evaluate: task edges-srl-ontonotes, batch 104 (157): mcc: 0.7995, acc: 0.7234, precision: 0.8683, recall: 0.7413, f1: 0.7998, edges-srl-ontonotes_loss: 0.0168
09/16 09:18:50 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:18:50 AM: Best result seen so far for macro.
09/16 09:18:50 AM: Updating LR scheduler:
09/16 09:18:50 AM: 	Best result seen so far for macro_avg: 0.808
09/16 09:18:50 AM: 	# validation passes without improvement: 0
09/16 09:18:50 AM: edges-srl-ontonotes_loss: training: 0.017777 validation: 0.016384
09/16 09:18:50 AM: macro_avg: validation: 0.808177
09/16 09:18:50 AM: micro_avg: validation: 0.000000
09/16 09:18:50 AM: edges-srl-ontonotes_mcc: training: 0.783962 validation: 0.807659
09/16 09:18:50 AM: edges-srl-ontonotes_acc: training: 0.696503 validation: 0.735124
09/16 09:18:50 AM: edges-srl-ontonotes_precision: training: 0.848450 validation: 0.871793
09/16 09:18:50 AM: edges-srl-ontonotes_recall: training: 0.729938 validation: 0.753214
09/16 09:18:50 AM: edges-srl-ontonotes_f1: training: 0.784745 validation: 0.808177
09/16 09:18:50 AM: Global learning rate: 0.0001
09/16 09:18:50 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:18:56 AM: Update 4070: task edges-srl-ontonotes, batch 70 (4070): mcc: 0.7895, acc: 0.7037, precision: 0.8519, recall: 0.7372, f1: 0.7904, edges-srl-ontonotes_loss: 0.0176
09/16 09:19:06 AM: Update 4188: task edges-srl-ontonotes, batch 188 (4188): mcc: 0.7933, acc: 0.7109, precision: 0.8526, recall: 0.7434, f1: 0.7943, edges-srl-ontonotes_loss: 0.0172
09/16 09:19:16 AM: Update 4308: task edges-srl-ontonotes, batch 308 (4308): mcc: 0.7961, acc: 0.7147, precision: 0.8558, recall: 0.7460, f1: 0.7971, edges-srl-ontonotes_loss: 0.0170
09/16 09:19:26 AM: Update 4430: task edges-srl-ontonotes, batch 430 (4430): mcc: 0.7996, acc: 0.7196, precision: 0.8581, recall: 0.7504, f1: 0.8007, edges-srl-ontonotes_loss: 0.0168
09/16 09:19:36 AM: Update 4545: task edges-srl-ontonotes, batch 545 (4545): mcc: 0.8011, acc: 0.7213, precision: 0.8587, recall: 0.7526, f1: 0.8021, edges-srl-ontonotes_loss: 0.0166
09/16 09:19:46 AM: Update 4671: task edges-srl-ontonotes, batch 671 (4671): mcc: 0.8015, acc: 0.7215, precision: 0.8597, recall: 0.7525, f1: 0.8026, edges-srl-ontonotes_loss: 0.0166
09/16 09:19:56 AM: Update 4761: task edges-srl-ontonotes, batch 761 (4761): mcc: 0.7993, acc: 0.7187, precision: 0.8584, recall: 0.7494, f1: 0.8002, edges-srl-ontonotes_loss: 0.0167
09/16 09:20:06 AM: Update 4855: task edges-srl-ontonotes, batch 855 (4855): mcc: 0.7979, acc: 0.7171, precision: 0.8576, recall: 0.7477, f1: 0.7989, edges-srl-ontonotes_loss: 0.0168
09/16 09:20:16 AM: Update 4948: task edges-srl-ontonotes, batch 948 (4948): mcc: 0.7969, acc: 0.7158, precision: 0.8569, recall: 0.7465, f1: 0.7979, edges-srl-ontonotes_loss: 0.0169
09/16 09:20:22 AM: ***** Step 5000 / Validation 5 *****
09/16 09:20:22 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:20:22 AM: Validating...
09/16 09:20:26 AM: Evaluate: task edges-srl-ontonotes, batch 56 (157): mcc: 0.8023, acc: 0.7298, precision: 0.8605, recall: 0.7532, f1: 0.8033, edges-srl-ontonotes_loss: 0.0165
09/16 09:20:34 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:20:34 AM: Best result seen so far for macro.
09/16 09:20:34 AM: Updating LR scheduler:
09/16 09:20:34 AM: 	Best result seen so far for macro_avg: 0.815
09/16 09:20:34 AM: 	# validation passes without improvement: 0
09/16 09:20:34 AM: edges-srl-ontonotes_loss: training: 0.016820 validation: 0.015689
09/16 09:20:34 AM: macro_avg: validation: 0.814633
09/16 09:20:34 AM: micro_avg: validation: 0.000000
09/16 09:20:34 AM: edges-srl-ontonotes_mcc: training: 0.797271 validation: 0.813572
09/16 09:20:34 AM: edges-srl-ontonotes_acc: training: 0.716251 validation: 0.743669
09/16 09:20:34 AM: edges-srl-ontonotes_precision: training: 0.857213 validation: 0.868485
09/16 09:20:34 AM: edges-srl-ontonotes_recall: training: 0.746812 validation: 0.767070
09/16 09:20:34 AM: edges-srl-ontonotes_f1: training: 0.798213 validation: 0.814633
09/16 09:20:34 AM: Global learning rate: 0.0001
09/16 09:20:34 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:20:38 AM: Update 5009: task edges-srl-ontonotes, batch 9 (5009): mcc: 0.7795, acc: 0.6958, precision: 0.8408, recall: 0.7285, f1: 0.7806, edges-srl-ontonotes_loss: 0.0180
09/16 09:20:48 AM: Update 5140: task edges-srl-ontonotes, batch 140 (5140): mcc: 0.8098, acc: 0.7301, precision: 0.8623, recall: 0.7655, f1: 0.8110, edges-srl-ontonotes_loss: 0.0154
09/16 09:20:58 AM: Update 5273: task edges-srl-ontonotes, batch 273 (5273): mcc: 0.8184, acc: 0.7416, precision: 0.8687, recall: 0.7759, f1: 0.8197, edges-srl-ontonotes_loss: 0.0149
09/16 09:21:08 AM: Update 5397: task edges-srl-ontonotes, batch 397 (5397): mcc: 0.8288, acc: 0.7552, precision: 0.8766, recall: 0.7883, f1: 0.8301, edges-srl-ontonotes_loss: 0.0143
09/16 09:21:18 AM: Update 5552: task edges-srl-ontonotes, batch 552 (5552): mcc: 0.8398, acc: 0.7695, precision: 0.8847, recall: 0.8016, f1: 0.8411, edges-srl-ontonotes_loss: 0.0136
09/16 09:21:28 AM: Update 5692: task edges-srl-ontonotes, batch 692 (5692): mcc: 0.8445, acc: 0.7761, precision: 0.8880, recall: 0.8073, f1: 0.8458, edges-srl-ontonotes_loss: 0.0133
09/16 09:21:38 AM: Update 5842: task edges-srl-ontonotes, batch 842 (5842): mcc: 0.8493, acc: 0.7828, precision: 0.8916, recall: 0.8132, f1: 0.8506, edges-srl-ontonotes_loss: 0.0129
09/16 09:21:48 AM: Update 5948: task edges-srl-ontonotes, batch 948 (5948): mcc: 0.8516, acc: 0.7859, precision: 0.8933, recall: 0.8159, f1: 0.8529, edges-srl-ontonotes_loss: 0.0128
09/16 09:21:52 AM: ***** Step 6000 / Validation 6 *****
09/16 09:21:52 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:21:52 AM: Validating...
09/16 09:21:58 AM: Evaluate: task edges-srl-ontonotes, batch 79 (157): mcc: 0.8237, acc: 0.7607, precision: 0.8854, recall: 0.7709, f1: 0.8242, edges-srl-ontonotes_loss: 0.0151
09/16 09:22:05 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:22:05 AM: Best result seen so far for macro.
09/16 09:22:05 AM: Updating LR scheduler:
09/16 09:22:05 AM: 	Best result seen so far for macro_avg: 0.834
09/16 09:22:05 AM: 	# validation passes without improvement: 0
09/16 09:22:05 AM: edges-srl-ontonotes_loss: training: 0.012738 validation: 0.014396
09/16 09:22:05 AM: macro_avg: validation: 0.833633
09/16 09:22:05 AM: micro_avg: validation: 0.000000
09/16 09:22:05 AM: edges-srl-ontonotes_mcc: training: 0.852545 validation: 0.832945
09/16 09:22:05 AM: edges-srl-ontonotes_acc: training: 0.787465 validation: 0.772766
09/16 09:22:05 AM: edges-srl-ontonotes_precision: training: 0.893907 validation: 0.889772
09/16 09:22:05 AM: edges-srl-ontonotes_recall: training: 0.817152 validation: 0.784158
09/16 09:22:05 AM: edges-srl-ontonotes_f1: training: 0.853808 validation: 0.833633
09/16 09:22:05 AM: Global learning rate: 0.0001
09/16 09:22:05 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:22:08 AM: Update 6055: task edges-srl-ontonotes, batch 55 (6055): mcc: 0.8676, acc: 0.8101, precision: 0.9006, recall: 0.8394, f1: 0.8690, edges-srl-ontonotes_loss: 0.0117
09/16 09:22:18 AM: Update 6207: task edges-srl-ontonotes, batch 207 (6207): mcc: 0.8720, acc: 0.8166, precision: 0.9045, recall: 0.8442, f1: 0.8733, edges-srl-ontonotes_loss: 0.0114
09/16 09:22:28 AM: Update 6334: task edges-srl-ontonotes, batch 334 (6334): mcc: 0.8717, acc: 0.8165, precision: 0.9050, recall: 0.8433, f1: 0.8731, edges-srl-ontonotes_loss: 0.0114
09/16 09:22:39 AM: Update 6487: task edges-srl-ontonotes, batch 487 (6487): mcc: 0.8726, acc: 0.8188, precision: 0.9051, recall: 0.8449, f1: 0.8740, edges-srl-ontonotes_loss: 0.0114
09/16 09:22:49 AM: Update 6619: task edges-srl-ontonotes, batch 619 (6619): mcc: 0.8682, acc: 0.8130, precision: 0.9017, recall: 0.8397, f1: 0.8696, edges-srl-ontonotes_loss: 0.0117
09/16 09:22:59 AM: Update 6749: task edges-srl-ontonotes, batch 749 (6749): mcc: 0.8615, acc: 0.8044, precision: 0.8964, recall: 0.8319, f1: 0.8630, edges-srl-ontonotes_loss: 0.0121
09/16 09:23:09 AM: Update 6877: task edges-srl-ontonotes, batch 877 (6877): mcc: 0.8573, acc: 0.7990, precision: 0.8935, recall: 0.8265, f1: 0.8587, edges-srl-ontonotes_loss: 0.0125
09/16 09:23:19 AM: Update 6988: task edges-srl-ontonotes, batch 988 (6988): mcc: 0.8509, acc: 0.7904, precision: 0.8889, recall: 0.8186, f1: 0.8523, edges-srl-ontonotes_loss: 0.0129
09/16 09:23:20 AM: ***** Step 7000 / Validation 7 *****
09/16 09:23:20 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:23:20 AM: Validating...
09/16 09:23:30 AM: Evaluate: task edges-srl-ontonotes, batch 104 (157): mcc: 0.8461, acc: 0.7905, precision: 0.8952, recall: 0.8038, f1: 0.8471, edges-srl-ontonotes_loss: 0.0132
09/16 09:23:35 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:23:35 AM: Best result seen so far for macro.
09/16 09:23:35 AM: Updating LR scheduler:
09/16 09:23:35 AM: 	Best result seen so far for macro_avg: 0.847
09/16 09:23:35 AM: 	# validation passes without improvement: 0
09/16 09:23:35 AM: edges-srl-ontonotes_loss: training: 0.012942 validation: 0.013299
09/16 09:23:35 AM: macro_avg: validation: 0.847355
09/16 09:23:35 AM: micro_avg: validation: 0.000000
09/16 09:23:35 AM: edges-srl-ontonotes_mcc: training: 0.850443 validation: 0.846256
09/16 09:23:35 AM: edges-srl-ontonotes_acc: training: 0.789838 validation: 0.792703
09/16 09:23:35 AM: edges-srl-ontonotes_precision: training: 0.888638 validation: 0.892781
09/16 09:23:35 AM: edges-srl-ontonotes_recall: training: 0.818036 validation: 0.806327
09/16 09:23:35 AM: edges-srl-ontonotes_f1: training: 0.851877 validation: 0.847355
09/16 09:23:35 AM: Global learning rate: 0.0001
09/16 09:23:35 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:23:40 AM: Update 7075: task edges-srl-ontonotes, batch 75 (7075): mcc: 0.8153, acc: 0.7407, precision: 0.8673, recall: 0.7714, f1: 0.8165, edges-srl-ontonotes_loss: 0.0154
09/16 09:23:50 AM: Update 7191: task edges-srl-ontonotes, batch 191 (7191): mcc: 0.8120, acc: 0.7383, precision: 0.8628, recall: 0.7692, f1: 0.8134, edges-srl-ontonotes_loss: 0.0156
09/16 09:24:01 AM: Update 7317: task edges-srl-ontonotes, batch 317 (7317): mcc: 0.8183, acc: 0.7469, precision: 0.8681, recall: 0.7763, f1: 0.8196, edges-srl-ontonotes_loss: 0.0152
09/16 09:24:11 AM: Update 7450: task edges-srl-ontonotes, batch 450 (7450): mcc: 0.8232, acc: 0.7528, precision: 0.8708, recall: 0.7830, f1: 0.8246, edges-srl-ontonotes_loss: 0.0148
09/16 09:24:21 AM: Update 7568: task edges-srl-ontonotes, batch 568 (7568): mcc: 0.8277, acc: 0.7588, precision: 0.8733, recall: 0.7891, f1: 0.8291, edges-srl-ontonotes_loss: 0.0144
09/16 09:24:31 AM: Update 7707: task edges-srl-ontonotes, batch 707 (7707): mcc: 0.8307, acc: 0.7625, precision: 0.8755, recall: 0.7928, f1: 0.8321, edges-srl-ontonotes_loss: 0.0142
09/16 09:24:41 AM: Update 7839: task edges-srl-ontonotes, batch 839 (7839): mcc: 0.8333, acc: 0.7657, precision: 0.8773, recall: 0.7960, f1: 0.8347, edges-srl-ontonotes_loss: 0.0139
09/16 09:24:51 AM: Update 7961: task edges-srl-ontonotes, batch 961 (7961): mcc: 0.8333, acc: 0.7661, precision: 0.8772, recall: 0.7961, f1: 0.8347, edges-srl-ontonotes_loss: 0.0140
09/16 09:24:54 AM: ***** Step 8000 / Validation 8 *****
09/16 09:24:54 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:24:54 AM: Validating...
09/16 09:25:01 AM: Evaluate: task edges-srl-ontonotes, batch 87 (157): mcc: 0.8519, acc: 0.8007, precision: 0.8954, recall: 0.8145, f1: 0.8530, edges-srl-ontonotes_loss: 0.0124
09/16 09:25:06 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:25:06 AM: Best result seen so far for macro.
09/16 09:25:06 AM: Updating LR scheduler:
09/16 09:25:06 AM: 	Best result seen so far for macro_avg: 0.857
09/16 09:25:06 AM: 	# validation passes without improvement: 0
09/16 09:25:06 AM: edges-srl-ontonotes_loss: training: 0.013955 validation: 0.012166
09/16 09:25:06 AM: macro_avg: validation: 0.857200
09/16 09:25:06 AM: micro_avg: validation: 0.000000
09/16 09:25:06 AM: edges-srl-ontonotes_mcc: training: 0.833661 validation: 0.855953
09/16 09:25:06 AM: edges-srl-ontonotes_acc: training: 0.766552 validation: 0.807944
09/16 09:25:06 AM: edges-srl-ontonotes_precision: training: 0.877471 validation: 0.896613
09/16 09:25:06 AM: edges-srl-ontonotes_recall: training: 0.796581 validation: 0.821107
09/16 09:25:06 AM: edges-srl-ontonotes_f1: training: 0.835072 validation: 0.857200
09/16 09:25:06 AM: Global learning rate: 0.0001
09/16 09:25:06 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:25:11 AM: Update 8063: task edges-srl-ontonotes, batch 63 (8063): mcc: 0.8315, acc: 0.7659, precision: 0.8762, recall: 0.7937, f1: 0.8329, edges-srl-ontonotes_loss: 0.0141
09/16 09:25:23 AM: Update 8186: task edges-srl-ontonotes, batch 186 (8186): mcc: 0.8294, acc: 0.7639, precision: 0.8718, recall: 0.7938, f1: 0.8310, edges-srl-ontonotes_loss: 0.0141
09/16 09:25:33 AM: Update 8329: task edges-srl-ontonotes, batch 329 (8329): mcc: 0.8238, acc: 0.7554, precision: 0.8677, recall: 0.7869, f1: 0.8253, edges-srl-ontonotes_loss: 0.0146
09/16 09:25:43 AM: Update 8455: task edges-srl-ontonotes, batch 455 (8455): mcc: 0.8204, acc: 0.7514, precision: 0.8655, recall: 0.7825, f1: 0.8219, edges-srl-ontonotes_loss: 0.0148
09/16 09:25:53 AM: Update 8577: task edges-srl-ontonotes, batch 577 (8577): mcc: 0.8201, acc: 0.7506, precision: 0.8659, recall: 0.7816, f1: 0.8216, edges-srl-ontonotes_loss: 0.0148
09/16 09:26:03 AM: Update 8706: task edges-srl-ontonotes, batch 706 (8706): mcc: 0.8197, acc: 0.7504, precision: 0.8653, recall: 0.7815, f1: 0.8213, edges-srl-ontonotes_loss: 0.0148
09/16 09:26:13 AM: Update 8825: task edges-srl-ontonotes, batch 825 (8825): mcc: 0.8209, acc: 0.7517, precision: 0.8661, recall: 0.7830, f1: 0.8224, edges-srl-ontonotes_loss: 0.0147
09/16 09:26:23 AM: Update 8948: task edges-srl-ontonotes, batch 948 (8948): mcc: 0.8165, acc: 0.7463, precision: 0.8625, recall: 0.7779, f1: 0.8180, edges-srl-ontonotes_loss: 0.0150
09/16 09:26:27 AM: ***** Step 9000 / Validation 9 *****
09/16 09:26:27 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:26:27 AM: Validating...
09/16 09:26:33 AM: Evaluate: task edges-srl-ontonotes, batch 68 (157): mcc: 0.8451, acc: 0.7906, precision: 0.8924, recall: 0.8045, f1: 0.8462, edges-srl-ontonotes_loss: 0.0129
09/16 09:26:40 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:26:40 AM: Best result seen so far for macro.
09/16 09:26:40 AM: Updating LR scheduler:
09/16 09:26:40 AM: 	Best result seen so far for macro_avg: 0.860
09/16 09:26:40 AM: 	# validation passes without improvement: 0
09/16 09:26:40 AM: edges-srl-ontonotes_loss: training: 0.015063 validation: 0.011986
09/16 09:26:40 AM: macro_avg: validation: 0.859781
09/16 09:26:40 AM: micro_avg: validation: 0.000000
09/16 09:26:40 AM: edges-srl-ontonotes_mcc: training: 0.815234 validation: 0.858739
09/16 09:26:40 AM: edges-srl-ontonotes_acc: training: 0.744949 validation: 0.807405
09/16 09:26:40 AM: edges-srl-ontonotes_precision: training: 0.861690 validation: 0.902931
09/16 09:26:40 AM: edges-srl-ontonotes_recall: training: 0.776287 validation: 0.820568
09/16 09:26:40 AM: edges-srl-ontonotes_f1: training: 0.816762 validation: 0.859781
09/16 09:26:40 AM: Global learning rate: 0.0001
09/16 09:26:40 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:26:43 AM: Update 9033: task edges-srl-ontonotes, batch 33 (9033): mcc: 0.7980, acc: 0.7197, precision: 0.8522, recall: 0.7526, f1: 0.7993, edges-srl-ontonotes_loss: 0.0162
09/16 09:26:53 AM: Update 9126: task edges-srl-ontonotes, batch 126 (9126): mcc: 0.8013, acc: 0.7283, precision: 0.8511, recall: 0.7597, f1: 0.8028, edges-srl-ontonotes_loss: 0.0161
09/16 09:27:03 AM: Update 9251: task edges-srl-ontonotes, batch 251 (9251): mcc: 0.8016, acc: 0.7259, precision: 0.8532, recall: 0.7584, f1: 0.8030, edges-srl-ontonotes_loss: 0.0161
09/16 09:27:13 AM: Update 9375: task edges-srl-ontonotes, batch 375 (9375): mcc: 0.8028, acc: 0.7282, precision: 0.8531, recall: 0.7608, f1: 0.8043, edges-srl-ontonotes_loss: 0.0159
09/16 09:27:23 AM: Update 9484: task edges-srl-ontonotes, batch 484 (9484): mcc: 0.8041, acc: 0.7304, precision: 0.8548, recall: 0.7617, f1: 0.8056, edges-srl-ontonotes_loss: 0.0158
09/16 09:27:33 AM: Update 9604: task edges-srl-ontonotes, batch 604 (9604): mcc: 0.8091, acc: 0.7370, precision: 0.8583, recall: 0.7680, f1: 0.8106, edges-srl-ontonotes_loss: 0.0155
09/16 09:27:43 AM: Update 9726: task edges-srl-ontonotes, batch 726 (9726): mcc: 0.8113, acc: 0.7398, precision: 0.8599, recall: 0.7706, f1: 0.8128, edges-srl-ontonotes_loss: 0.0153
09/16 09:27:53 AM: Update 9839: task edges-srl-ontonotes, batch 839 (9839): mcc: 0.8131, acc: 0.7423, precision: 0.8613, recall: 0.7726, f1: 0.8145, edges-srl-ontonotes_loss: 0.0152
09/16 09:28:03 AM: Update 9956: task edges-srl-ontonotes, batch 956 (9956): mcc: 0.8150, acc: 0.7448, precision: 0.8625, recall: 0.7750, f1: 0.8164, edges-srl-ontonotes_loss: 0.0150
09/16 09:28:07 AM: ***** Step 10000 / Validation 10 *****
09/16 09:28:07 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:28:07 AM: Validating...
09/16 09:28:13 AM: Evaluate: task edges-srl-ontonotes, batch 74 (157): mcc: 0.8427, acc: 0.7908, precision: 0.8899, recall: 0.8023, f1: 0.8438, edges-srl-ontonotes_loss: 0.0130
09/16 09:28:20 AM: Updating LR scheduler:
09/16 09:28:20 AM: 	Best result seen so far for macro_avg: 0.860
09/16 09:28:20 AM: 	# validation passes without improvement: 1
09/16 09:28:20 AM: edges-srl-ontonotes_loss: training: 0.015022 validation: 0.012350
09/16 09:28:20 AM: macro_avg: validation: 0.852508
09/16 09:28:20 AM: micro_avg: validation: 0.000000
09/16 09:28:20 AM: edges-srl-ontonotes_mcc: training: 0.815275 validation: 0.851380
09/16 09:28:20 AM: edges-srl-ontonotes_acc: training: 0.745263 validation: 0.802479
09/16 09:28:20 AM: edges-srl-ontonotes_precision: training: 0.862764 validation: 0.895929
09/16 09:28:20 AM: edges-srl-ontonotes_recall: training: 0.775391 validation: 0.813101
09/16 09:28:20 AM: edges-srl-ontonotes_f1: training: 0.816747 validation: 0.852508
09/16 09:28:20 AM: Global learning rate: 0.0001
09/16 09:28:20 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:28:23 AM: Update 10040: task edges-srl-ontonotes, batch 40 (10040): mcc: 0.8233, acc: 0.7554, precision: 0.8661, recall: 0.7873, f1: 0.8249, edges-srl-ontonotes_loss: 0.0144
09/16 09:28:33 AM: Update 10124: task edges-srl-ontonotes, batch 124 (10124): mcc: 0.8349, acc: 0.7703, precision: 0.8771, recall: 0.7991, f1: 0.8363, edges-srl-ontonotes_loss: 0.0140
09/16 09:28:44 AM: Update 10246: task edges-srl-ontonotes, batch 246 (10246): mcc: 0.8343, acc: 0.7707, precision: 0.8766, recall: 0.7985, f1: 0.8357, edges-srl-ontonotes_loss: 0.0139
09/16 09:28:54 AM: Update 10367: task edges-srl-ontonotes, batch 367 (10367): mcc: 0.8356, acc: 0.7723, precision: 0.8783, recall: 0.7996, f1: 0.8371, edges-srl-ontonotes_loss: 0.0138
09/16 09:29:04 AM: Update 10475: task edges-srl-ontonotes, batch 475 (10475): mcc: 0.8330, acc: 0.7686, precision: 0.8764, recall: 0.7963, f1: 0.8345, edges-srl-ontonotes_loss: 0.0140
09/16 09:29:14 AM: Update 10593: task edges-srl-ontonotes, batch 593 (10593): mcc: 0.8309, acc: 0.7653, precision: 0.8753, recall: 0.7933, f1: 0.8323, edges-srl-ontonotes_loss: 0.0141
09/16 09:29:24 AM: Update 10694: task edges-srl-ontonotes, batch 694 (10694): mcc: 0.8295, acc: 0.7634, precision: 0.8747, recall: 0.7912, f1: 0.8309, edges-srl-ontonotes_loss: 0.0142
09/16 09:29:34 AM: Update 10816: task edges-srl-ontonotes, batch 816 (10816): mcc: 0.8284, acc: 0.7617, precision: 0.8740, recall: 0.7897, f1: 0.8297, edges-srl-ontonotes_loss: 0.0142
09/16 09:29:44 AM: Update 10944: task edges-srl-ontonotes, batch 944 (10944): mcc: 0.8286, acc: 0.7619, precision: 0.8743, recall: 0.7899, f1: 0.8300, edges-srl-ontonotes_loss: 0.0142
09/16 09:29:48 AM: ***** Step 11000 / Validation 11 *****
09/16 09:29:48 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:29:48 AM: Validating...
09/16 09:29:54 AM: Evaluate: task edges-srl-ontonotes, batch 77 (157): mcc: 0.8368, acc: 0.7843, precision: 0.8802, recall: 0.7999, f1: 0.8382, edges-srl-ontonotes_loss: 0.0136
09/16 09:30:00 AM: Updating LR scheduler:
09/16 09:30:00 AM: 	Best result seen so far for macro_avg: 0.860
09/16 09:30:00 AM: 	# validation passes without improvement: 2
09/16 09:30:00 AM: edges-srl-ontonotes_loss: training: 0.014239 validation: 0.012811
09/16 09:30:00 AM: macro_avg: validation: 0.848300
09/16 09:30:00 AM: micro_avg: validation: 0.000000
09/16 09:30:00 AM: edges-srl-ontonotes_mcc: training: 0.828639 validation: 0.846874
09/16 09:30:00 AM: edges-srl-ontonotes_acc: training: 0.761987 validation: 0.797398
09/16 09:30:00 AM: edges-srl-ontonotes_precision: training: 0.874461 validation: 0.886409
09/16 09:30:00 AM: edges-srl-ontonotes_recall: training: 0.789871 validation: 0.813332
09/16 09:30:00 AM: edges-srl-ontonotes_f1: training: 0.830016 validation: 0.848300
09/16 09:30:00 AM: Global learning rate: 0.0001
09/16 09:30:00 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:30:04 AM: Update 11038: task edges-srl-ontonotes, batch 38 (11038): mcc: 0.8252, acc: 0.7601, precision: 0.8660, recall: 0.7910, f1: 0.8268, edges-srl-ontonotes_loss: 0.0145
09/16 09:30:14 AM: Update 11165: task edges-srl-ontonotes, batch 165 (11165): mcc: 0.8218, acc: 0.7549, precision: 0.8670, recall: 0.7837, f1: 0.8233, edges-srl-ontonotes_loss: 0.0146
09/16 09:30:24 AM: Update 11287: task edges-srl-ontonotes, batch 287 (11287): mcc: 0.8235, acc: 0.7568, precision: 0.8681, recall: 0.7860, f1: 0.8250, edges-srl-ontonotes_loss: 0.0144
09/16 09:30:34 AM: Update 11374: task edges-srl-ontonotes, batch 374 (11374): mcc: 0.8226, acc: 0.7560, precision: 0.8678, recall: 0.7845, f1: 0.8241, edges-srl-ontonotes_loss: 0.0145
09/16 09:30:44 AM: Update 11502: task edges-srl-ontonotes, batch 502 (11502): mcc: 0.8255, acc: 0.7598, precision: 0.8699, recall: 0.7880, f1: 0.8269, edges-srl-ontonotes_loss: 0.0142
09/16 09:30:54 AM: Update 11621: task edges-srl-ontonotes, batch 621 (11621): mcc: 0.8279, acc: 0.7624, precision: 0.8719, recall: 0.7907, f1: 0.8293, edges-srl-ontonotes_loss: 0.0141
09/16 09:31:04 AM: Update 11731: task edges-srl-ontonotes, batch 731 (11731): mcc: 0.8288, acc: 0.7631, precision: 0.8728, recall: 0.7917, f1: 0.8302, edges-srl-ontonotes_loss: 0.0140
09/16 09:31:14 AM: Update 11860: task edges-srl-ontonotes, batch 860 (11860): mcc: 0.8303, acc: 0.7652, precision: 0.8740, recall: 0.7933, f1: 0.8317, edges-srl-ontonotes_loss: 0.0139
09/16 09:31:24 AM: Update 11973: task edges-srl-ontonotes, batch 973 (11973): mcc: 0.8296, acc: 0.7643, precision: 0.8737, recall: 0.7924, f1: 0.8310, edges-srl-ontonotes_loss: 0.0140
09/16 09:31:26 AM: ***** Step 12000 / Validation 12 *****
09/16 09:31:26 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:31:26 AM: Validating...
09/16 09:31:34 AM: Evaluate: task edges-srl-ontonotes, batch 99 (157): mcc: 0.8446, acc: 0.7910, precision: 0.8924, recall: 0.8035, f1: 0.8457, edges-srl-ontonotes_loss: 0.0129
09/16 09:31:39 AM: Updating LR scheduler:
09/16 09:31:39 AM: 	Best result seen so far for macro_avg: 0.860
09/16 09:31:39 AM: 	# validation passes without improvement: 3
09/16 09:31:39 AM: edges-srl-ontonotes_loss: training: 0.014022 validation: 0.012599
09/16 09:31:39 AM: macro_avg: validation: 0.850248
09/16 09:31:39 AM: micro_avg: validation: 0.000000
09/16 09:31:39 AM: edges-srl-ontonotes_mcc: training: 0.828931 validation: 0.849085
09/16 09:31:39 AM: edges-srl-ontonotes_acc: training: 0.763563 validation: 0.799015
09/16 09:31:39 AM: edges-srl-ontonotes_precision: training: 0.873164 validation: 0.893554
09/16 09:31:39 AM: edges-srl-ontonotes_recall: training: 0.791604 validation: 0.810946
09/16 09:31:39 AM: edges-srl-ontonotes_f1: training: 0.830386 validation: 0.850248
09/16 09:31:39 AM: Global learning rate: 0.0001
09/16 09:31:39 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:31:44 AM: Update 12062: task edges-srl-ontonotes, batch 62 (12062): mcc: 0.8083, acc: 0.7377, precision: 0.8598, recall: 0.7650, f1: 0.8097, edges-srl-ontonotes_loss: 0.0155
09/16 09:31:54 AM: Update 12175: task edges-srl-ontonotes, batch 175 (12175): mcc: 0.8143, acc: 0.7449, precision: 0.8652, recall: 0.7714, f1: 0.8156, edges-srl-ontonotes_loss: 0.0150
09/16 09:32:05 AM: Update 12255: task edges-srl-ontonotes, batch 255 (12255): mcc: 0.8169, acc: 0.7484, precision: 0.8672, recall: 0.7745, f1: 0.8182, edges-srl-ontonotes_loss: 0.0148
09/16 09:32:15 AM: Update 12394: task edges-srl-ontonotes, batch 394 (12394): mcc: 0.8289, acc: 0.7637, precision: 0.8750, recall: 0.7899, f1: 0.8303, edges-srl-ontonotes_loss: 0.0140
09/16 09:32:25 AM: Update 12534: task edges-srl-ontonotes, batch 534 (12534): mcc: 0.8375, acc: 0.7740, precision: 0.8806, recall: 0.8009, f1: 0.8389, edges-srl-ontonotes_loss: 0.0134
09/16 09:32:35 AM: Update 12670: task edges-srl-ontonotes, batch 670 (12670): mcc: 0.8467, acc: 0.7854, precision: 0.8872, recall: 0.8122, f1: 0.8481, edges-srl-ontonotes_loss: 0.0128
09/16 09:32:45 AM: Update 12829: task edges-srl-ontonotes, batch 829 (12829): mcc: 0.8566, acc: 0.7982, precision: 0.8943, recall: 0.8245, f1: 0.8580, edges-srl-ontonotes_loss: 0.0121
09/16 09:32:55 AM: Update 12987: task edges-srl-ontonotes, batch 987 (12987): mcc: 0.8628, acc: 0.8061, precision: 0.8990, recall: 0.8318, f1: 0.8641, edges-srl-ontonotes_loss: 0.0117
09/16 09:32:55 AM: ***** Step 13000 / Validation 13 *****
09/16 09:32:55 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:32:55 AM: Validating...
09/16 09:33:05 AM: Evaluate: task edges-srl-ontonotes, batch 123 (157): mcc: 0.8548, acc: 0.8048, precision: 0.8990, recall: 0.8168, f1: 0.8559, edges-srl-ontonotes_loss: 0.0124
09/16 09:33:07 AM: Updating LR scheduler:
09/16 09:33:07 AM: 	Best result seen so far for macro_avg: 0.860
09/16 09:33:07 AM: 	# validation passes without improvement: 0
09/16 09:33:07 AM: edges-srl-ontonotes_loss: training: 0.011641 validation: 0.012507
09/16 09:33:07 AM: macro_avg: validation: 0.854767
09/16 09:33:07 AM: micro_avg: validation: 0.000000
09/16 09:33:07 AM: edges-srl-ontonotes_mcc: training: 0.863126 validation: 0.853689
09/16 09:33:07 AM: edges-srl-ontonotes_acc: training: 0.806580 validation: 0.802094
09/16 09:33:07 AM: edges-srl-ontonotes_precision: training: 0.899200 validation: 0.898583
09/16 09:33:07 AM: edges-srl-ontonotes_recall: training: 0.832316 validation: 0.815026
09/16 09:33:07 AM: edges-srl-ontonotes_f1: training: 0.864466 validation: 0.854767
09/16 09:33:07 AM: Global learning rate: 5e-05
09/16 09:33:07 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:33:15 AM: Update 13119: task edges-srl-ontonotes, batch 119 (13119): mcc: 0.8916, acc: 0.8432, precision: 0.9228, recall: 0.8646, f1: 0.8927, edges-srl-ontonotes_loss: 0.0096
09/16 09:33:25 AM: Update 13260: task edges-srl-ontonotes, batch 260 (13260): mcc: 0.8917, acc: 0.8446, precision: 0.9203, recall: 0.8670, f1: 0.8929, edges-srl-ontonotes_loss: 0.0096
09/16 09:33:35 AM: Update 13416: task edges-srl-ontonotes, batch 416 (13416): mcc: 0.8926, acc: 0.8455, precision: 0.9207, recall: 0.8683, f1: 0.8938, edges-srl-ontonotes_loss: 0.0096
09/16 09:33:45 AM: Update 13532: task edges-srl-ontonotes, batch 532 (13532): mcc: 0.8909, acc: 0.8446, precision: 0.9187, recall: 0.8671, f1: 0.8921, edges-srl-ontonotes_loss: 0.0097
09/16 09:33:55 AM: Update 13682: task edges-srl-ontonotes, batch 682 (13682): mcc: 0.8902, acc: 0.8445, precision: 0.9179, recall: 0.8666, f1: 0.8915, edges-srl-ontonotes_loss: 0.0097
09/16 09:34:05 AM: Update 13820: task edges-srl-ontonotes, batch 820 (13820): mcc: 0.8897, acc: 0.8448, precision: 0.9169, recall: 0.8665, f1: 0.8910, edges-srl-ontonotes_loss: 0.0098
09/16 09:34:15 AM: Update 13931: task edges-srl-ontonotes, batch 931 (13931): mcc: 0.8844, acc: 0.8378, precision: 0.9128, recall: 0.8601, f1: 0.8857, edges-srl-ontonotes_loss: 0.0102
09/16 09:34:22 AM: ***** Step 14000 / Validation 14 *****
09/16 09:34:22 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:34:22 AM: Validating...
09/16 09:34:25 AM: Evaluate: task edges-srl-ontonotes, batch 50 (157): mcc: 0.8556, acc: 0.8079, precision: 0.8979, recall: 0.8192, f1: 0.8567, edges-srl-ontonotes_loss: 0.0125
09/16 09:34:33 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:34:33 AM: Best result seen so far for macro.
09/16 09:34:33 AM: Updating LR scheduler:
09/16 09:34:33 AM: 	Best result seen so far for macro_avg: 0.865
09/16 09:34:33 AM: 	# validation passes without improvement: 0
09/16 09:34:33 AM: edges-srl-ontonotes_loss: training: 0.010341 validation: 0.011649
09/16 09:34:33 AM: macro_avg: validation: 0.865261
09/16 09:34:33 AM: micro_avg: validation: 0.000000
09/16 09:34:33 AM: edges-srl-ontonotes_mcc: training: 0.881785 validation: 0.864034
09/16 09:34:33 AM: edges-srl-ontonotes_acc: training: 0.834228 validation: 0.820337
09/16 09:34:33 AM: edges-srl-ontonotes_precision: training: 0.910831 validation: 0.902516
09/16 09:34:33 AM: edges-srl-ontonotes_recall: training: 0.857020 validation: 0.830960
09/16 09:34:33 AM: edges-srl-ontonotes_f1: training: 0.883107 validation: 0.865261
09/16 09:34:34 AM: Global learning rate: 5e-05
09/16 09:34:34 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:34:35 AM: Update 14026: task edges-srl-ontonotes, batch 26 (14026): mcc: 0.8557, acc: 0.7990, precision: 0.8884, recall: 0.8283, f1: 0.8573, edges-srl-ontonotes_loss: 0.0122
09/16 09:34:46 AM: Update 14134: task edges-srl-ontonotes, batch 134 (14134): mcc: 0.8516, acc: 0.7949, precision: 0.8873, recall: 0.8216, f1: 0.8532, edges-srl-ontonotes_loss: 0.0126
09/16 09:34:56 AM: Update 14256: task edges-srl-ontonotes, batch 256 (14256): mcc: 0.8401, acc: 0.7797, precision: 0.8785, recall: 0.8077, f1: 0.8417, edges-srl-ontonotes_loss: 0.0134
09/16 09:35:06 AM: Update 14378: task edges-srl-ontonotes, batch 378 (14378): mcc: 0.8364, acc: 0.7748, precision: 0.8759, recall: 0.8031, f1: 0.8379, edges-srl-ontonotes_loss: 0.0136
09/16 09:35:18 AM: Update 14493: task edges-srl-ontonotes, batch 493 (14493): mcc: 0.8363, acc: 0.7745, precision: 0.8764, recall: 0.8026, f1: 0.8379, edges-srl-ontonotes_loss: 0.0136
09/16 09:35:28 AM: Update 14623: task edges-srl-ontonotes, batch 623 (14623): mcc: 0.8410, acc: 0.7804, precision: 0.8805, recall: 0.8077, f1: 0.8426, edges-srl-ontonotes_loss: 0.0132
09/16 09:35:38 AM: Update 14755: task edges-srl-ontonotes, batch 755 (14755): mcc: 0.8435, acc: 0.7834, precision: 0.8822, recall: 0.8107, f1: 0.8450, edges-srl-ontonotes_loss: 0.0130
09/16 09:35:48 AM: Update 14855: task edges-srl-ontonotes, batch 855 (14855): mcc: 0.8442, acc: 0.7842, precision: 0.8829, recall: 0.8116, f1: 0.8457, edges-srl-ontonotes_loss: 0.0130
09/16 09:35:58 AM: ***** Step 15000 / Validation 15 *****
09/16 09:35:58 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:35:58 AM: Validating...
09/16 09:35:58 AM: Evaluate: task edges-srl-ontonotes, batch 5 (157): mcc: 0.8781, acc: 0.8360, precision: 0.9160, recall: 0.8451, f1: 0.8791, edges-srl-ontonotes_loss: 0.0102
09/16 09:36:08 AM: Evaluate: task edges-srl-ontonotes, batch 135 (157): mcc: 0.8767, acc: 0.8370, precision: 0.9099, recall: 0.8481, f1: 0.8779, edges-srl-ontonotes_loss: 0.0105
09/16 09:36:10 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:36:10 AM: Best result seen so far for macro.
09/16 09:36:10 AM: Updating LR scheduler:
09/16 09:36:10 AM: 	Best result seen so far for macro_avg: 0.874
09/16 09:36:10 AM: 	# validation passes without improvement: 0
09/16 09:36:10 AM: edges-srl-ontonotes_loss: training: 0.012801 validation: 0.010853
09/16 09:36:10 AM: macro_avg: validation: 0.873898
09/16 09:36:10 AM: micro_avg: validation: 0.000000
09/16 09:36:10 AM: edges-srl-ontonotes_mcc: training: 0.846863 validation: 0.872629
09/16 09:36:10 AM: edges-srl-ontonotes_acc: training: 0.787650 validation: 0.832268
09/16 09:36:10 AM: edges-srl-ontonotes_precision: training: 0.885158 validation: 0.907006
09/16 09:36:10 AM: edges-srl-ontonotes_recall: training: 0.814468 validation: 0.843122
09/16 09:36:10 AM: edges-srl-ontonotes_f1: training: 0.848343 validation: 0.873898
09/16 09:36:10 AM: Global learning rate: 5e-05
09/16 09:36:10 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:36:18 AM: Update 15111: task edges-srl-ontonotes, batch 111 (15111): mcc: 0.8602, acc: 0.8024, precision: 0.8950, recall: 0.8306, f1: 0.8616, edges-srl-ontonotes_loss: 0.0116
09/16 09:36:28 AM: Update 15232: task edges-srl-ontonotes, batch 232 (15232): mcc: 0.8543, acc: 0.7958, precision: 0.8894, recall: 0.8246, f1: 0.8558, edges-srl-ontonotes_loss: 0.0122
09/16 09:36:38 AM: Update 15370: task edges-srl-ontonotes, batch 370 (15370): mcc: 0.8523, acc: 0.7942, precision: 0.8881, recall: 0.8221, f1: 0.8539, edges-srl-ontonotes_loss: 0.0124
09/16 09:36:48 AM: Update 15469: task edges-srl-ontonotes, batch 469 (15469): mcc: 0.8512, acc: 0.7931, precision: 0.8874, recall: 0.8206, f1: 0.8527, edges-srl-ontonotes_loss: 0.0125
09/16 09:36:59 AM: Update 15595: task edges-srl-ontonotes, batch 595 (15595): mcc: 0.8469, acc: 0.7872, precision: 0.8844, recall: 0.8152, f1: 0.8484, edges-srl-ontonotes_loss: 0.0128
09/16 09:37:09 AM: Update 15731: task edges-srl-ontonotes, batch 731 (15731): mcc: 0.8454, acc: 0.7852, precision: 0.8836, recall: 0.8132, f1: 0.8469, edges-srl-ontonotes_loss: 0.0129
09/16 09:37:19 AM: Update 15853: task edges-srl-ontonotes, batch 853 (15853): mcc: 0.8440, acc: 0.7829, precision: 0.8824, recall: 0.8116, f1: 0.8455, edges-srl-ontonotes_loss: 0.0130
09/16 09:37:29 AM: Update 15981: task edges-srl-ontonotes, batch 981 (15981): mcc: 0.8429, acc: 0.7815, precision: 0.8814, recall: 0.8104, f1: 0.8444, edges-srl-ontonotes_loss: 0.0130
09/16 09:37:30 AM: ***** Step 16000 / Validation 16 *****
09/16 09:37:30 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:37:30 AM: Validating...
09/16 09:37:39 AM: Evaluate: task edges-srl-ontonotes, batch 114 (157): mcc: 0.8731, acc: 0.8307, precision: 0.9106, recall: 0.8407, f1: 0.8743, edges-srl-ontonotes_loss: 0.0107
09/16 09:37:42 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:37:42 AM: Best result seen so far for macro.
09/16 09:37:42 AM: Updating LR scheduler:
09/16 09:37:42 AM: 	Best result seen so far for macro_avg: 0.875
09/16 09:37:42 AM: 	# validation passes without improvement: 0
09/16 09:37:42 AM: edges-srl-ontonotes_loss: training: 0.012990 validation: 0.010715
09/16 09:37:42 AM: macro_avg: validation: 0.874590
09/16 09:37:42 AM: micro_avg: validation: 0.000000
09/16 09:37:42 AM: edges-srl-ontonotes_mcc: training: 0.842817 validation: 0.873422
09/16 09:37:42 AM: edges-srl-ontonotes_acc: training: 0.781351 validation: 0.831499
09/16 09:37:42 AM: edges-srl-ontonotes_precision: training: 0.881403 validation: 0.910112
09/16 09:37:42 AM: edges-srl-ontonotes_recall: training: 0.810272 validation: 0.841737
09/16 09:37:42 AM: edges-srl-ontonotes_f1: training: 0.844342 validation: 0.874590
09/16 09:37:42 AM: Global learning rate: 5e-05
09/16 09:37:42 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:37:49 AM: Update 16080: task edges-srl-ontonotes, batch 80 (16080): mcc: 0.8412, acc: 0.7823, precision: 0.8789, recall: 0.8095, f1: 0.8428, edges-srl-ontonotes_loss: 0.0131
09/16 09:37:59 AM: Update 16211: task edges-srl-ontonotes, batch 211 (16211): mcc: 0.8216, acc: 0.7567, precision: 0.8644, recall: 0.7858, f1: 0.8232, edges-srl-ontonotes_loss: 0.0144
09/16 09:38:09 AM: Update 16333: task edges-srl-ontonotes, batch 333 (16333): mcc: 0.8197, acc: 0.7539, precision: 0.8634, recall: 0.7831, f1: 0.8213, edges-srl-ontonotes_loss: 0.0145
09/16 09:38:19 AM: Update 16425: task edges-srl-ontonotes, batch 425 (16425): mcc: 0.8183, acc: 0.7520, precision: 0.8632, recall: 0.7807, f1: 0.8199, edges-srl-ontonotes_loss: 0.0147
09/16 09:38:29 AM: Update 16548: task edges-srl-ontonotes, batch 548 (16548): mcc: 0.8181, acc: 0.7518, precision: 0.8638, recall: 0.7798, f1: 0.8196, edges-srl-ontonotes_loss: 0.0147
09/16 09:38:39 AM: Update 16674: task edges-srl-ontonotes, batch 674 (16674): mcc: 0.8188, acc: 0.7521, precision: 0.8645, recall: 0.7803, f1: 0.8203, edges-srl-ontonotes_loss: 0.0146
09/16 09:38:49 AM: Update 16767: task edges-srl-ontonotes, batch 767 (16767): mcc: 0.8214, acc: 0.7556, precision: 0.8664, recall: 0.7837, f1: 0.8230, edges-srl-ontonotes_loss: 0.0144
09/16 09:38:59 AM: Update 16873: task edges-srl-ontonotes, batch 873 (16873): mcc: 0.8244, acc: 0.7593, precision: 0.8688, recall: 0.7871, f1: 0.8259, edges-srl-ontonotes_loss: 0.0142
09/16 09:39:09 AM: Update 16990: task edges-srl-ontonotes, batch 990 (16990): mcc: 0.8263, acc: 0.7617, precision: 0.8702, recall: 0.7894, f1: 0.8278, edges-srl-ontonotes_loss: 0.0141
09/16 09:39:11 AM: ***** Step 17000 / Validation 17 *****
09/16 09:39:11 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:39:11 AM: Validating...
09/16 09:39:19 AM: Evaluate: task edges-srl-ontonotes, batch 107 (157): mcc: 0.8737, acc: 0.8311, precision: 0.9086, recall: 0.8436, f1: 0.8749, edges-srl-ontonotes_loss: 0.0107
09/16 09:39:23 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:39:23 AM: Best result seen so far for macro.
09/16 09:39:23 AM: Updating LR scheduler:
09/16 09:39:23 AM: 	Best result seen so far for macro_avg: 0.875
09/16 09:39:23 AM: 	# validation passes without improvement: 0
09/16 09:39:23 AM: edges-srl-ontonotes_loss: training: 0.014098 validation: 0.010793
09/16 09:39:23 AM: macro_avg: validation: 0.875269
09/16 09:39:23 AM: micro_avg: validation: 0.000000
09/16 09:39:23 AM: edges-srl-ontonotes_mcc: training: 0.826116 validation: 0.874029
09/16 09:39:23 AM: edges-srl-ontonotes_acc: training: 0.761418 validation: 0.833038
09/16 09:39:23 AM: edges-srl-ontonotes_precision: training: 0.869926 validation: 0.908624
09/16 09:39:23 AM: edges-srl-ontonotes_recall: training: 0.789258 validation: 0.844277
09/16 09:39:23 AM: edges-srl-ontonotes_f1: training: 0.827631 validation: 0.875269
09/16 09:39:23 AM: Global learning rate: 5e-05
09/16 09:39:23 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:39:29 AM: Update 17081: task edges-srl-ontonotes, batch 81 (17081): mcc: 0.8430, acc: 0.7820, precision: 0.8809, recall: 0.8110, f1: 0.8445, edges-srl-ontonotes_loss: 0.0132
09/16 09:39:39 AM: Update 17211: task edges-srl-ontonotes, batch 211 (17211): mcc: 0.8436, acc: 0.7830, precision: 0.8815, recall: 0.8117, f1: 0.8451, edges-srl-ontonotes_loss: 0.0129
09/16 09:39:49 AM: Update 17325: task edges-srl-ontonotes, batch 325 (17325): mcc: 0.8436, acc: 0.7829, precision: 0.8825, recall: 0.8108, f1: 0.8451, edges-srl-ontonotes_loss: 0.0129
09/16 09:39:59 AM: Update 17459: task edges-srl-ontonotes, batch 459 (17459): mcc: 0.8449, acc: 0.7849, precision: 0.8843, recall: 0.8114, f1: 0.8463, edges-srl-ontonotes_loss: 0.0129
09/16 09:40:09 AM: Update 17583: task edges-srl-ontonotes, batch 583 (17583): mcc: 0.8458, acc: 0.7862, precision: 0.8848, recall: 0.8127, f1: 0.8473, edges-srl-ontonotes_loss: 0.0128
09/16 09:40:19 AM: Update 17678: task edges-srl-ontonotes, batch 678 (17678): mcc: 0.8447, acc: 0.7849, precision: 0.8841, recall: 0.8113, f1: 0.8461, edges-srl-ontonotes_loss: 0.0129
09/16 09:40:29 AM: Update 17811: task edges-srl-ontonotes, batch 811 (17811): mcc: 0.8437, acc: 0.7836, precision: 0.8836, recall: 0.8099, f1: 0.8451, edges-srl-ontonotes_loss: 0.0130
09/16 09:40:39 AM: Update 17933: task edges-srl-ontonotes, batch 933 (17933): mcc: 0.8431, acc: 0.7828, precision: 0.8833, recall: 0.8090, f1: 0.8445, edges-srl-ontonotes_loss: 0.0130
09/16 09:40:46 AM: ***** Step 18000 / Validation 18 *****
09/16 09:40:46 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:40:46 AM: Validating...
09/16 09:40:49 AM: Evaluate: task edges-srl-ontonotes, batch 51 (157): mcc: 0.8567, acc: 0.8087, precision: 0.8998, recall: 0.8195, f1: 0.8578, edges-srl-ontonotes_loss: 0.0120
09/16 09:40:58 AM: Updating LR scheduler:
09/16 09:40:58 AM: 	Best result seen so far for macro_avg: 0.875
09/16 09:40:58 AM: 	# validation passes without improvement: 1
09/16 09:40:58 AM: edges-srl-ontonotes_loss: training: 0.013079 validation: 0.011126
09/16 09:40:58 AM: macro_avg: validation: 0.869280
09/16 09:40:58 AM: micro_avg: validation: 0.000000
09/16 09:40:58 AM: edges-srl-ontonotes_mcc: training: 0.841964 validation: 0.868075
09/16 09:40:58 AM: edges-srl-ontonotes_acc: training: 0.781548 validation: 0.823955
09/16 09:40:58 AM: edges-srl-ontonotes_precision: training: 0.882585 validation: 0.905723
09/16 09:40:58 AM: edges-srl-ontonotes_recall: training: 0.807566 validation: 0.835655
09/16 09:40:58 AM: edges-srl-ontonotes_f1: training: 0.843410 validation: 0.869280
09/16 09:40:58 AM: Global learning rate: 5e-05
09/16 09:40:58 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:41:00 AM: Update 18021: task edges-srl-ontonotes, batch 21 (18021): mcc: 0.8286, acc: 0.7642, precision: 0.8669, recall: 0.7967, f1: 0.8303, edges-srl-ontonotes_loss: 0.0140
09/16 09:41:10 AM: Update 18151: task edges-srl-ontonotes, batch 151 (18151): mcc: 0.8426, acc: 0.7811, precision: 0.8839, recall: 0.8076, f1: 0.8440, edges-srl-ontonotes_loss: 0.0131
09/16 09:41:20 AM: Update 18269: task edges-srl-ontonotes, batch 269 (18269): mcc: 0.8424, acc: 0.7804, precision: 0.8837, recall: 0.8075, f1: 0.8439, edges-srl-ontonotes_loss: 0.0131
09/16 09:41:30 AM: Update 18394: task edges-srl-ontonotes, batch 394 (18394): mcc: 0.8401, acc: 0.7779, precision: 0.8818, recall: 0.8047, f1: 0.8415, edges-srl-ontonotes_loss: 0.0132
09/16 09:41:40 AM: Update 18525: task edges-srl-ontonotes, batch 525 (18525): mcc: 0.8392, acc: 0.7768, precision: 0.8808, recall: 0.8041, f1: 0.8407, edges-srl-ontonotes_loss: 0.0133
09/16 09:41:50 AM: Update 18600: task edges-srl-ontonotes, batch 600 (18600): mcc: 0.8398, acc: 0.7779, precision: 0.8814, recall: 0.8046, f1: 0.8413, edges-srl-ontonotes_loss: 0.0133
09/16 09:42:00 AM: Update 18725: task edges-srl-ontonotes, batch 725 (18725): mcc: 0.8414, acc: 0.7797, precision: 0.8824, recall: 0.8066, f1: 0.8428, edges-srl-ontonotes_loss: 0.0132
09/16 09:42:10 AM: Update 18852: task edges-srl-ontonotes, batch 852 (18852): mcc: 0.8424, acc: 0.7813, precision: 0.8830, recall: 0.8079, f1: 0.8438, edges-srl-ontonotes_loss: 0.0131
09/16 09:42:20 AM: Update 18964: task edges-srl-ontonotes, batch 964 (18964): mcc: 0.8425, acc: 0.7814, precision: 0.8831, recall: 0.8080, f1: 0.8439, edges-srl-ontonotes_loss: 0.0131
09/16 09:42:23 AM: ***** Step 19000 / Validation 19 *****
09/16 09:42:23 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:42:23 AM: Validating...
09/16 09:42:30 AM: Evaluate: task edges-srl-ontonotes, batch 92 (157): mcc: 0.8622, acc: 0.8201, precision: 0.8972, recall: 0.8324, f1: 0.8636, edges-srl-ontonotes_loss: 0.0116
09/16 09:42:35 AM: Updating LR scheduler:
09/16 09:42:35 AM: 	Best result seen so far for macro_avg: 0.875
09/16 09:42:35 AM: 	# validation passes without improvement: 2
09/16 09:42:35 AM: edges-srl-ontonotes_loss: training: 0.013037 validation: 0.011318
09/16 09:42:35 AM: macro_avg: validation: 0.867740
09/16 09:42:35 AM: micro_avg: validation: 0.000000
09/16 09:42:35 AM: edges-srl-ontonotes_mcc: training: 0.842918 validation: 0.866326
09/16 09:42:35 AM: edges-srl-ontonotes_acc: training: 0.782011 validation: 0.826649
09/16 09:42:35 AM: edges-srl-ontonotes_precision: training: 0.883499 validation: 0.899265
09/16 09:42:35 AM: edges-srl-ontonotes_recall: training: 0.808527 validation: 0.838350
09/16 09:42:35 AM: edges-srl-ontonotes_f1: training: 0.844352 validation: 0.867740
09/16 09:42:35 AM: Global learning rate: 5e-05
09/16 09:42:35 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:42:40 AM: Update 19060: task edges-srl-ontonotes, batch 60 (19060): mcc: 0.8486, acc: 0.7886, precision: 0.8916, recall: 0.8119, f1: 0.8499, edges-srl-ontonotes_loss: 0.0126
09/16 09:42:50 AM: Update 19178: task edges-srl-ontonotes, batch 178 (19178): mcc: 0.8479, acc: 0.7867, precision: 0.8896, recall: 0.8123, f1: 0.8492, edges-srl-ontonotes_loss: 0.0125
09/16 09:43:00 AM: Update 19276: task edges-srl-ontonotes, batch 276 (19276): mcc: 0.8399, acc: 0.7776, precision: 0.8833, recall: 0.8031, f1: 0.8413, edges-srl-ontonotes_loss: 0.0132
09/16 09:43:10 AM: Update 19387: task edges-srl-ontonotes, batch 387 (19387): mcc: 0.8370, acc: 0.7742, precision: 0.8802, recall: 0.8004, f1: 0.8384, edges-srl-ontonotes_loss: 0.0134
09/16 09:43:20 AM: Update 19497: task edges-srl-ontonotes, batch 497 (19497): mcc: 0.8347, acc: 0.7711, precision: 0.8789, recall: 0.7972, f1: 0.8360, edges-srl-ontonotes_loss: 0.0135
09/16 09:43:30 AM: Update 19625: task edges-srl-ontonotes, batch 625 (19625): mcc: 0.8418, acc: 0.7799, precision: 0.8838, recall: 0.8061, f1: 0.8432, edges-srl-ontonotes_loss: 0.0129
09/16 09:43:40 AM: Update 19765: task edges-srl-ontonotes, batch 765 (19765): mcc: 0.8464, acc: 0.7858, precision: 0.8871, recall: 0.8118, f1: 0.8478, edges-srl-ontonotes_loss: 0.0126
09/16 09:43:50 AM: Update 19871: task edges-srl-ontonotes, batch 871 (19871): mcc: 0.8516, acc: 0.7924, precision: 0.8907, recall: 0.8183, f1: 0.8529, edges-srl-ontonotes_loss: 0.0122
09/16 09:43:59 AM: ***** Step 20000 / Validation 20 *****
09/16 09:43:59 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:43:59 AM: Validating...
09/16 09:44:00 AM: Evaluate: task edges-srl-ontonotes, batch 21 (157): mcc: 0.8865, acc: 0.8394, precision: 0.9286, recall: 0.8494, f1: 0.8872, edges-srl-ontonotes_loss: 0.0098
09/16 09:44:10 AM: Evaluate: task edges-srl-ontonotes, batch 148 (157): mcc: 0.8702, acc: 0.8268, precision: 0.9096, recall: 0.8360, f1: 0.8713, edges-srl-ontonotes_loss: 0.0110
09/16 09:44:11 AM: Updating LR scheduler:
09/16 09:44:11 AM: 	Best result seen so far for macro_avg: 0.875
09/16 09:44:11 AM: 	# validation passes without improvement: 3
09/16 09:44:11 AM: edges-srl-ontonotes_loss: training: 0.011799 validation: 0.011205
09/16 09:44:11 AM: macro_avg: validation: 0.869642
09/16 09:44:11 AM: micro_avg: validation: 0.000000
09/16 09:44:11 AM: edges-srl-ontonotes_mcc: training: 0.857917 validation: 0.868542
09/16 09:44:11 AM: edges-srl-ontonotes_acc: training: 0.800592 validation: 0.824879
09/16 09:44:11 AM: edges-srl-ontonotes_precision: training: 0.895121 validation: 0.908512
09/16 09:44:11 AM: edges-srl-ontonotes_recall: training: 0.826209 validation: 0.833962
09/16 09:44:11 AM: edges-srl-ontonotes_f1: training: 0.859286 validation: 0.869642
09/16 09:44:11 AM: Global learning rate: 5e-05
09/16 09:44:11 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:44:20 AM: Update 20129: task edges-srl-ontonotes, batch 129 (20129): mcc: 0.9019, acc: 0.8563, precision: 0.9275, recall: 0.8799, f1: 0.9031, edges-srl-ontonotes_loss: 0.0085
09/16 09:44:30 AM: Update 20298: task edges-srl-ontonotes, batch 298 (20298): mcc: 0.8988, acc: 0.8532, precision: 0.9257, recall: 0.8755, f1: 0.8999, edges-srl-ontonotes_loss: 0.0088
09/16 09:44:41 AM: Update 20444: task edges-srl-ontonotes, batch 444 (20444): mcc: 0.8983, acc: 0.8528, precision: 0.9248, recall: 0.8755, f1: 0.8995, edges-srl-ontonotes_loss: 0.0088
09/16 09:44:51 AM: Update 20620: task edges-srl-ontonotes, batch 620 (20620): mcc: 0.8988, acc: 0.8539, precision: 0.9247, recall: 0.8766, f1: 0.9000, edges-srl-ontonotes_loss: 0.0089
09/16 09:45:01 AM: Update 20753: task edges-srl-ontonotes, batch 753 (20753): mcc: 0.8987, acc: 0.8543, precision: 0.9242, recall: 0.8768, f1: 0.8999, edges-srl-ontonotes_loss: 0.0089
09/16 09:45:11 AM: Update 20921: task edges-srl-ontonotes, batch 921 (20921): mcc: 0.8970, acc: 0.8530, precision: 0.9224, recall: 0.8753, f1: 0.8982, edges-srl-ontonotes_loss: 0.0090
09/16 09:45:16 AM: ***** Step 21000 / Validation 21 *****
09/16 09:45:16 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:45:16 AM: Validating...
09/16 09:45:21 AM: Evaluate: task edges-srl-ontonotes, batch 69 (157): mcc: 0.8631, acc: 0.8159, precision: 0.9075, recall: 0.8247, f1: 0.8641, edges-srl-ontonotes_loss: 0.0117
09/16 09:45:29 AM: Updating LR scheduler:
09/16 09:45:29 AM: 	Best result seen so far for macro_avg: 0.875
09/16 09:45:29 AM: 	# validation passes without improvement: 0
09/16 09:45:29 AM: edges-srl-ontonotes_loss: training: 0.009050 validation: 0.011013
09/16 09:45:29 AM: macro_avg: validation: 0.871772
09/16 09:45:29 AM: micro_avg: validation: 0.000000
09/16 09:45:29 AM: edges-srl-ontonotes_mcc: training: 0.897146 validation: 0.870732
09/16 09:45:29 AM: edges-srl-ontonotes_acc: training: 0.853572 validation: 0.826033
09/16 09:45:29 AM: edges-srl-ontonotes_precision: training: 0.922394 validation: 0.911335
09/16 09:45:29 AM: edges-srl-ontonotes_recall: training: 0.875537 validation: 0.835501
09/16 09:45:29 AM: edges-srl-ontonotes_f1: training: 0.898355 validation: 0.871772
09/16 09:45:29 AM: Global learning rate: 2.5e-05
09/16 09:45:29 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:45:31 AM: Update 21028: task edges-srl-ontonotes, batch 28 (21028): mcc: 0.8914, acc: 0.8527, precision: 0.9141, recall: 0.8723, f1: 0.8927, edges-srl-ontonotes_loss: 0.0095
09/16 09:45:41 AM: Update 21138: task edges-srl-ontonotes, batch 138 (21138): mcc: 0.8766, acc: 0.8293, precision: 0.9036, recall: 0.8538, f1: 0.8780, edges-srl-ontonotes_loss: 0.0106
09/16 09:45:51 AM: Update 21273: task edges-srl-ontonotes, batch 273 (21273): mcc: 0.8682, acc: 0.8168, precision: 0.8989, recall: 0.8423, f1: 0.8697, edges-srl-ontonotes_loss: 0.0112
09/16 09:46:01 AM: Update 21388: task edges-srl-ontonotes, batch 388 (21388): mcc: 0.8619, acc: 0.8089, precision: 0.8946, recall: 0.8342, f1: 0.8634, edges-srl-ontonotes_loss: 0.0117
09/16 09:46:11 AM: Update 21511: task edges-srl-ontonotes, batch 511 (21511): mcc: 0.8568, acc: 0.8018, precision: 0.8904, recall: 0.8284, f1: 0.8583, edges-srl-ontonotes_loss: 0.0120
09/16 09:46:21 AM: Update 21639: task edges-srl-ontonotes, batch 639 (21639): mcc: 0.8531, acc: 0.7975, precision: 0.8877, recall: 0.8239, f1: 0.8546, edges-srl-ontonotes_loss: 0.0123
09/16 09:46:32 AM: Update 21739: task edges-srl-ontonotes, batch 739 (21739): mcc: 0.8511, acc: 0.7948, precision: 0.8867, recall: 0.8211, f1: 0.8526, edges-srl-ontonotes_loss: 0.0125
09/16 09:46:42 AM: Update 21892: task edges-srl-ontonotes, batch 892 (21892): mcc: 0.8530, acc: 0.7971, precision: 0.8882, recall: 0.8232, f1: 0.8545, edges-srl-ontonotes_loss: 0.0123
09/16 09:46:49 AM: ***** Step 22000 / Validation 22 *****
09/16 09:46:49 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:46:49 AM: Validating...
09/16 09:46:52 AM: Evaluate: task edges-srl-ontonotes, batch 38 (157): mcc: 0.8719, acc: 0.8292, precision: 0.9078, recall: 0.8411, f1: 0.8732, edges-srl-ontonotes_loss: 0.0108
09/16 09:47:01 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:47:01 AM: Best result seen so far for macro.
09/16 09:47:01 AM: Updating LR scheduler:
09/16 09:47:01 AM: 	Best result seen so far for macro_avg: 0.877
09/16 09:47:01 AM: 	# validation passes without improvement: 0
09/16 09:47:01 AM: edges-srl-ontonotes_loss: training: 0.012246 validation: 0.010478
09/16 09:47:01 AM: macro_avg: validation: 0.877368
09/16 09:47:01 AM: micro_avg: validation: 0.000000
09/16 09:47:01 AM: edges-srl-ontonotes_mcc: training: 0.854005 validation: 0.876141
09/16 09:47:01 AM: edges-srl-ontonotes_acc: training: 0.798492 validation: 0.836040
09/16 09:47:01 AM: edges-srl-ontonotes_precision: training: 0.889388 validation: 0.910295
09/16 09:47:01 AM: edges-srl-ontonotes_recall: training: 0.824106 validation: 0.846740
09/16 09:47:01 AM: edges-srl-ontonotes_f1: training: 0.855503 validation: 0.877368
09/16 09:47:01 AM: Global learning rate: 2.5e-05
09/16 09:47:01 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:47:02 AM: Update 22012: task edges-srl-ontonotes, batch 12 (22012): mcc: 0.8528, acc: 0.7914, precision: 0.8856, recall: 0.8254, f1: 0.8544, edges-srl-ontonotes_loss: 0.0121
09/16 09:47:12 AM: Update 22142: task edges-srl-ontonotes, batch 142 (22142): mcc: 0.8626, acc: 0.8085, precision: 0.8950, recall: 0.8353, f1: 0.8641, edges-srl-ontonotes_loss: 0.0116
09/16 09:47:22 AM: Update 22281: task edges-srl-ontonotes, batch 281 (22281): mcc: 0.8642, acc: 0.8085, precision: 0.8974, recall: 0.8359, f1: 0.8656, edges-srl-ontonotes_loss: 0.0113
09/16 09:47:32 AM: Update 22402: task edges-srl-ontonotes, batch 402 (22402): mcc: 0.8620, acc: 0.8069, precision: 0.8956, recall: 0.8335, f1: 0.8635, edges-srl-ontonotes_loss: 0.0115
09/16 09:47:42 AM: Update 22537: task edges-srl-ontonotes, batch 537 (22537): mcc: 0.8592, acc: 0.8039, precision: 0.8930, recall: 0.8306, f1: 0.8607, edges-srl-ontonotes_loss: 0.0117
09/16 09:47:52 AM: Update 22670: task edges-srl-ontonotes, batch 670 (22670): mcc: 0.8591, acc: 0.8042, precision: 0.8928, recall: 0.8306, f1: 0.8605, edges-srl-ontonotes_loss: 0.0117
09/16 09:48:02 AM: Update 22759: task edges-srl-ontonotes, batch 759 (22759): mcc: 0.8568, acc: 0.8015, precision: 0.8911, recall: 0.8278, f1: 0.8583, edges-srl-ontonotes_loss: 0.0119
09/16 09:48:12 AM: Update 22891: task edges-srl-ontonotes, batch 891 (22891): mcc: 0.8538, acc: 0.7976, precision: 0.8889, recall: 0.8242, f1: 0.8554, edges-srl-ontonotes_loss: 0.0121
09/16 09:48:21 AM: ***** Step 23000 / Validation 23 *****
09/16 09:48:21 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:48:21 AM: Validating...
09/16 09:48:22 AM: Evaluate: task edges-srl-ontonotes, batch 10 (157): mcc: 0.8870, acc: 0.8425, precision: 0.9239, recall: 0.8547, f1: 0.8880, edges-srl-ontonotes_loss: 0.0092
09/16 09:48:32 AM: Evaluate: task edges-srl-ontonotes, batch 134 (157): mcc: 0.8840, acc: 0.8461, precision: 0.9128, recall: 0.8594, f1: 0.8853, edges-srl-ontonotes_loss: 0.0099
09/16 09:48:34 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:48:34 AM: Best result seen so far for macro.
09/16 09:48:34 AM: Updating LR scheduler:
09/16 09:48:34 AM: 	Best result seen so far for macro_avg: 0.881
09/16 09:48:34 AM: 	# validation passes without improvement: 0
09/16 09:48:34 AM: edges-srl-ontonotes_loss: training: 0.012215 validation: 0.010186
09/16 09:48:34 AM: macro_avg: validation: 0.881351
09/16 09:48:34 AM: micro_avg: validation: 0.000000
09/16 09:48:34 AM: edges-srl-ontonotes_mcc: training: 0.852459 validation: 0.880050
09/16 09:48:34 AM: edges-srl-ontonotes_acc: training: 0.795465 validation: 0.841121
09/16 09:48:34 AM: edges-srl-ontonotes_precision: training: 0.888183 validation: 0.910538
09/16 09:48:34 AM: edges-srl-ontonotes_recall: training: 0.822288 validation: 0.853976
09/16 09:48:34 AM: edges-srl-ontonotes_f1: training: 0.853966 validation: 0.881351
09/16 09:48:34 AM: Global learning rate: 2.5e-05
09/16 09:48:34 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:48:42 AM: Update 23107: task edges-srl-ontonotes, batch 107 (23107): mcc: 0.8453, acc: 0.7869, precision: 0.8811, recall: 0.8153, f1: 0.8469, edges-srl-ontonotes_loss: 0.0125
09/16 09:48:52 AM: Update 23239: task edges-srl-ontonotes, batch 239 (23239): mcc: 0.8451, acc: 0.7870, precision: 0.8817, recall: 0.8143, f1: 0.8467, edges-srl-ontonotes_loss: 0.0126
09/16 09:49:02 AM: Update 23349: task edges-srl-ontonotes, batch 349 (23349): mcc: 0.8413, acc: 0.7813, precision: 0.8787, recall: 0.8099, f1: 0.8429, edges-srl-ontonotes_loss: 0.0130
09/16 09:49:12 AM: Update 23477: task edges-srl-ontonotes, batch 477 (23477): mcc: 0.8356, acc: 0.7737, precision: 0.8748, recall: 0.8028, f1: 0.8372, edges-srl-ontonotes_loss: 0.0134
09/16 09:49:22 AM: Update 23599: task edges-srl-ontonotes, batch 599 (23599): mcc: 0.8338, acc: 0.7713, precision: 0.8740, recall: 0.8001, f1: 0.8354, edges-srl-ontonotes_loss: 0.0135
09/16 09:49:32 AM: Update 23713: task edges-srl-ontonotes, batch 713 (23713): mcc: 0.8328, acc: 0.7700, precision: 0.8731, recall: 0.7989, f1: 0.8344, edges-srl-ontonotes_loss: 0.0136
09/16 09:49:42 AM: Update 23837: task edges-srl-ontonotes, batch 837 (23837): mcc: 0.8325, acc: 0.7696, precision: 0.8735, recall: 0.7980, f1: 0.8340, edges-srl-ontonotes_loss: 0.0137
09/16 09:49:53 AM: Update 23930: task edges-srl-ontonotes, batch 930 (23930): mcc: 0.8312, acc: 0.7682, precision: 0.8724, recall: 0.7966, f1: 0.8328, edges-srl-ontonotes_loss: 0.0138
09/16 09:49:59 AM: ***** Step 24000 / Validation 24 *****
09/16 09:49:59 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:49:59 AM: Validating...
09/16 09:50:03 AM: Evaluate: task edges-srl-ontonotes, batch 47 (157): mcc: 0.8678, acc: 0.8237, precision: 0.9065, recall: 0.8344, f1: 0.8690, edges-srl-ontonotes_loss: 0.0112
09/16 09:50:11 AM: Updating LR scheduler:
09/16 09:50:11 AM: 	Best result seen so far for macro_avg: 0.881
09/16 09:50:11 AM: 	# validation passes without improvement: 1
09/16 09:50:11 AM: edges-srl-ontonotes_loss: training: 0.013664 validation: 0.010316
09/16 09:50:11 AM: macro_avg: validation: 0.879888
09/16 09:50:11 AM: micro_avg: validation: 0.000000
09/16 09:50:11 AM: edges-srl-ontonotes_mcc: training: 0.832331 validation: 0.878722
09/16 09:50:11 AM: edges-srl-ontonotes_acc: training: 0.769463 validation: 0.838504
09/16 09:50:11 AM: edges-srl-ontonotes_precision: training: 0.873454 validation: 0.913497
09/16 09:50:11 AM: edges-srl-ontonotes_recall: training: 0.797754 validation: 0.848664
09/16 09:50:11 AM: edges-srl-ontonotes_f1: training: 0.833889 validation: 0.879888
09/16 09:50:11 AM: Global learning rate: 2.5e-05
09/16 09:50:11 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:50:13 AM: Update 24018: task edges-srl-ontonotes, batch 18 (24018): mcc: 0.8633, acc: 0.8127, precision: 0.9030, recall: 0.8292, f1: 0.8645, edges-srl-ontonotes_loss: 0.0117
09/16 09:50:23 AM: Update 24145: task edges-srl-ontonotes, batch 145 (24145): mcc: 0.8482, acc: 0.7878, precision: 0.8880, recall: 0.8144, f1: 0.8496, edges-srl-ontonotes_loss: 0.0126
09/16 09:50:33 AM: Update 24256: task edges-srl-ontonotes, batch 256 (24256): mcc: 0.8495, acc: 0.7897, precision: 0.8883, recall: 0.8165, f1: 0.8509, edges-srl-ontonotes_loss: 0.0124
09/16 09:50:43 AM: Update 24390: task edges-srl-ontonotes, batch 390 (24390): mcc: 0.8503, acc: 0.7920, precision: 0.8881, recall: 0.8182, f1: 0.8517, edges-srl-ontonotes_loss: 0.0123
09/16 09:50:53 AM: Update 24513: task edges-srl-ontonotes, batch 513 (24513): mcc: 0.8501, acc: 0.7920, precision: 0.8880, recall: 0.8180, f1: 0.8515, edges-srl-ontonotes_loss: 0.0124
09/16 09:51:03 AM: Update 24625: task edges-srl-ontonotes, batch 625 (24625): mcc: 0.8501, acc: 0.7922, precision: 0.8878, recall: 0.8181, f1: 0.8515, edges-srl-ontonotes_loss: 0.0123
09/16 09:51:13 AM: Update 24756: task edges-srl-ontonotes, batch 756 (24756): mcc: 0.8507, acc: 0.7934, precision: 0.8882, recall: 0.8189, f1: 0.8521, edges-srl-ontonotes_loss: 0.0124
09/16 09:51:25 AM: Update 24869: task edges-srl-ontonotes, batch 869 (24869): mcc: 0.8526, acc: 0.7958, precision: 0.8898, recall: 0.8211, f1: 0.8541, edges-srl-ontonotes_loss: 0.0122
09/16 09:51:35 AM: Update 24999: task edges-srl-ontonotes, batch 999 (24999): mcc: 0.8504, acc: 0.7929, precision: 0.8880, recall: 0.8185, f1: 0.8518, edges-srl-ontonotes_loss: 0.0124
09/16 09:51:35 AM: ***** Step 25000 / Validation 25 *****
09/16 09:51:35 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:51:35 AM: Validating...
09/16 09:51:45 AM: Evaluate: task edges-srl-ontonotes, batch 129 (157): mcc: 0.8800, acc: 0.8421, precision: 0.9118, recall: 0.8527, f1: 0.8812, edges-srl-ontonotes_loss: 0.0103
09/16 09:51:47 AM: Updating LR scheduler:
09/16 09:51:47 AM: 	Best result seen so far for macro_avg: 0.881
09/16 09:51:47 AM: 	# validation passes without improvement: 2
09/16 09:51:47 AM: edges-srl-ontonotes_loss: training: 0.012368 validation: 0.010515
09/16 09:51:47 AM: macro_avg: validation: 0.878134
09/16 09:51:47 AM: micro_avg: validation: 0.000000
09/16 09:51:47 AM: edges-srl-ontonotes_mcc: training: 0.850343 validation: 0.876905
09/16 09:51:47 AM: edges-srl-ontonotes_acc: training: 0.792897 validation: 0.837503
09/16 09:51:47 AM: edges-srl-ontonotes_precision: training: 0.887911 validation: 0.910700
09/16 09:51:47 AM: edges-srl-ontonotes_recall: training: 0.818519 validation: 0.847818
09/16 09:51:47 AM: edges-srl-ontonotes_f1: training: 0.851804 validation: 0.878134
09/16 09:51:47 AM: Global learning rate: 2.5e-05
09/16 09:51:47 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:51:55 AM: Update 25100: task edges-srl-ontonotes, batch 100 (25100): mcc: 0.8419, acc: 0.7851, precision: 0.8803, recall: 0.8095, f1: 0.8434, edges-srl-ontonotes_loss: 0.0130
09/16 09:52:05 AM: Update 25217: task edges-srl-ontonotes, batch 217 (25217): mcc: 0.8419, acc: 0.7830, precision: 0.8819, recall: 0.8081, f1: 0.8434, edges-srl-ontonotes_loss: 0.0130
09/16 09:52:15 AM: Update 25340: task edges-srl-ontonotes, batch 340 (25340): mcc: 0.8432, acc: 0.7839, precision: 0.8830, recall: 0.8096, f1: 0.8447, edges-srl-ontonotes_loss: 0.0129
09/16 09:52:25 AM: Update 25470: task edges-srl-ontonotes, batch 470 (25470): mcc: 0.8439, acc: 0.7844, precision: 0.8843, recall: 0.8096, f1: 0.8453, edges-srl-ontonotes_loss: 0.0129
09/16 09:52:35 AM: Update 25583: task edges-srl-ontonotes, batch 583 (25583): mcc: 0.8424, acc: 0.7824, precision: 0.8831, recall: 0.8080, f1: 0.8439, edges-srl-ontonotes_loss: 0.0130
09/16 09:52:45 AM: Update 25708: task edges-srl-ontonotes, batch 708 (25708): mcc: 0.8424, acc: 0.7823, precision: 0.8831, recall: 0.8079, f1: 0.8438, edges-srl-ontonotes_loss: 0.0130
09/16 09:52:57 AM: Update 25808: task edges-srl-ontonotes, batch 808 (25808): mcc: 0.8419, acc: 0.7815, precision: 0.8828, recall: 0.8072, f1: 0.8433, edges-srl-ontonotes_loss: 0.0130
09/16 09:53:07 AM: Update 25936: task edges-srl-ontonotes, batch 936 (25936): mcc: 0.8430, acc: 0.7832, precision: 0.8831, recall: 0.8091, f1: 0.8445, edges-srl-ontonotes_loss: 0.0130
09/16 09:53:11 AM: ***** Step 26000 / Validation 26 *****
09/16 09:53:11 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:53:11 AM: Validating...
09/16 09:53:17 AM: Evaluate: task edges-srl-ontonotes, batch 70 (157): mcc: 0.8674, acc: 0.8258, precision: 0.9026, recall: 0.8372, f1: 0.8687, edges-srl-ontonotes_loss: 0.0114
09/16 09:53:23 AM: Updating LR scheduler:
09/16 09:53:23 AM: 	Best result seen so far for macro_avg: 0.881
09/16 09:53:23 AM: 	# validation passes without improvement: 3
09/16 09:53:23 AM: edges-srl-ontonotes_loss: training: 0.012903 validation: 0.010710
09/16 09:53:23 AM: macro_avg: validation: 0.875204
09/16 09:53:23 AM: micro_avg: validation: 0.000000
09/16 09:53:23 AM: edges-srl-ontonotes_mcc: training: 0.843594 validation: 0.873858
09/16 09:53:23 AM: edges-srl-ontonotes_acc: training: 0.783718 validation: 0.834501
09/16 09:53:23 AM: edges-srl-ontonotes_precision: training: 0.883701 validation: 0.905648
09/16 09:53:23 AM: edges-srl-ontonotes_recall: training: 0.809622 validation: 0.846740
09/16 09:53:23 AM: edges-srl-ontonotes_f1: training: 0.845041 validation: 0.875204
09/16 09:53:23 AM: Global learning rate: 2.5e-05
09/16 09:53:23 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:53:27 AM: Update 26043: task edges-srl-ontonotes, batch 43 (26043): mcc: 0.8404, acc: 0.7867, precision: 0.8763, recall: 0.8104, f1: 0.8421, edges-srl-ontonotes_loss: 0.0133
09/16 09:53:37 AM: Update 26165: task edges-srl-ontonotes, batch 165 (26165): mcc: 0.8498, acc: 0.7943, precision: 0.8865, recall: 0.8188, f1: 0.8513, edges-srl-ontonotes_loss: 0.0126
09/16 09:53:47 AM: Update 26285: task edges-srl-ontonotes, batch 285 (26285): mcc: 0.8521, acc: 0.7959, precision: 0.8894, recall: 0.8204, f1: 0.8535, edges-srl-ontonotes_loss: 0.0124
09/16 09:53:57 AM: Update 26403: task edges-srl-ontonotes, batch 403 (26403): mcc: 0.8516, acc: 0.7953, precision: 0.8897, recall: 0.8193, f1: 0.8531, edges-srl-ontonotes_loss: 0.0123
09/16 09:54:07 AM: Update 26502: task edges-srl-ontonotes, batch 502 (26502): mcc: 0.8481, acc: 0.7903, precision: 0.8872, recall: 0.8149, f1: 0.8495, edges-srl-ontonotes_loss: 0.0126
09/16 09:54:17 AM: Update 26620: task edges-srl-ontonotes, batch 620 (26620): mcc: 0.8448, acc: 0.7861, precision: 0.8848, recall: 0.8109, f1: 0.8462, edges-srl-ontonotes_loss: 0.0128
09/16 09:54:27 AM: Update 26734: task edges-srl-ontonotes, batch 734 (26734): mcc: 0.8434, acc: 0.7841, precision: 0.8838, recall: 0.8092, f1: 0.8449, edges-srl-ontonotes_loss: 0.0129
09/16 09:54:37 AM: Update 26858: task edges-srl-ontonotes, batch 858 (26858): mcc: 0.8467, acc: 0.7882, precision: 0.8860, recall: 0.8134, f1: 0.8481, edges-srl-ontonotes_loss: 0.0126
09/16 09:54:47 AM: ***** Step 27000 / Validation 27 *****
09/16 09:54:47 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:54:47 AM: Validating...
09/16 09:54:47 AM: Evaluate: task edges-srl-ontonotes, batch 1 (157): mcc: 0.9015, acc: 0.8764, precision: 0.9186, recall: 0.8876, f1: 0.9029, edges-srl-ontonotes_loss: 0.0087
09/16 09:54:57 AM: Evaluate: task edges-srl-ontonotes, batch 130 (157): mcc: 0.8783, acc: 0.8405, precision: 0.9101, recall: 0.8510, f1: 0.8796, edges-srl-ontonotes_loss: 0.0103
09/16 09:54:59 AM: Updating LR scheduler:
09/16 09:54:59 AM: 	Best result seen so far for macro_avg: 0.881
09/16 09:54:59 AM: 	# validation passes without improvement: 0
09/16 09:54:59 AM: edges-srl-ontonotes_loss: training: 0.012271 validation: 0.010583
09/16 09:54:59 AM: macro_avg: validation: 0.876759
09/16 09:54:59 AM: micro_avg: validation: 0.000000
09/16 09:54:59 AM: edges-srl-ontonotes_mcc: training: 0.851486 validation: 0.875514
09/16 09:54:59 AM: edges-srl-ontonotes_acc: training: 0.793643 validation: 0.836502
09/16 09:54:59 AM: edges-srl-ontonotes_precision: training: 0.889809 validation: 0.909429
09/16 09:54:59 AM: edges-srl-ontonotes_recall: training: 0.818929 validation: 0.846355
09/16 09:54:59 AM: edges-srl-ontonotes_f1: training: 0.852899 validation: 0.876759
09/16 09:54:59 AM: Global learning rate: 1.25e-05
09/16 09:54:59 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:55:07 AM: Update 27081: task edges-srl-ontonotes, batch 81 (27081): mcc: 0.8817, acc: 0.8310, precision: 0.9083, recall: 0.8592, f1: 0.8830, edges-srl-ontonotes_loss: 0.0102
09/16 09:55:17 AM: Update 27236: task edges-srl-ontonotes, batch 236 (27236): mcc: 0.8969, acc: 0.8509, precision: 0.9231, recall: 0.8744, f1: 0.8981, edges-srl-ontonotes_loss: 0.0091
09/16 09:55:27 AM: Update 27381: task edges-srl-ontonotes, batch 381 (27381): mcc: 0.9000, acc: 0.8549, precision: 0.9245, recall: 0.8790, f1: 0.9012, edges-srl-ontonotes_loss: 0.0088
09/16 09:55:37 AM: Update 27542: task edges-srl-ontonotes, batch 542 (27542): mcc: 0.8992, acc: 0.8544, precision: 0.9246, recall: 0.8774, f1: 0.9004, edges-srl-ontonotes_loss: 0.0089
09/16 09:55:48 AM: Update 27686: task edges-srl-ontonotes, batch 686 (27686): mcc: 0.8998, acc: 0.8557, precision: 0.9253, recall: 0.8779, f1: 0.9010, edges-srl-ontonotes_loss: 0.0088
09/16 09:55:58 AM: Update 27838: task edges-srl-ontonotes, batch 838 (27838): mcc: 0.8998, acc: 0.8556, precision: 0.9255, recall: 0.8778, f1: 0.9010, edges-srl-ontonotes_loss: 0.0088
09/16 09:56:08 AM: Update 27993: task edges-srl-ontonotes, batch 993 (27993): mcc: 0.8999, acc: 0.8561, precision: 0.9254, recall: 0.8781, f1: 0.9011, edges-srl-ontonotes_loss: 0.0088
09/16 09:56:12 AM: ***** Step 28000 / Validation 28 *****
09/16 09:56:12 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:56:12 AM: Validating...
09/16 09:56:18 AM: Evaluate: task edges-srl-ontonotes, batch 91 (157): mcc: 0.8741, acc: 0.8315, precision: 0.9122, recall: 0.8412, f1: 0.8752, edges-srl-ontonotes_loss: 0.0107
09/16 09:56:24 AM: Updating LR scheduler:
09/16 09:56:24 AM: 	Best result seen so far for macro_avg: 0.881
09/16 09:56:24 AM: 	# validation passes without improvement: 1
09/16 09:56:24 AM: edges-srl-ontonotes_loss: training: 0.008850 validation: 0.010533
09/16 09:56:24 AM: macro_avg: validation: 0.877938
09/16 09:56:24 AM: micro_avg: validation: 0.000000
09/16 09:56:24 AM: edges-srl-ontonotes_mcc: training: 0.899716 validation: 0.876801
09/16 09:56:24 AM: edges-srl-ontonotes_acc: training: 0.855808 validation: 0.836810
09/16 09:56:24 AM: edges-srl-ontonotes_precision: training: 0.925164 validation: 0.913043
09/16 09:56:24 AM: edges-srl-ontonotes_recall: training: 0.877840 validation: 0.845431
09/16 09:56:24 AM: edges-srl-ontonotes_f1: training: 0.900881 validation: 0.877938
09/16 09:56:24 AM: Global learning rate: 1.25e-05
09/16 09:56:24 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:56:29 AM: Update 28077: task edges-srl-ontonotes, batch 77 (28077): mcc: 0.8955, acc: 0.8531, precision: 0.9167, recall: 0.8778, f1: 0.8968, edges-srl-ontonotes_loss: 0.0094
09/16 09:56:39 AM: Update 28230: task edges-srl-ontonotes, batch 230 (28230): mcc: 0.8952, acc: 0.8524, precision: 0.9181, recall: 0.8759, f1: 0.8965, edges-srl-ontonotes_loss: 0.0094
09/16 09:56:49 AM: Update 28355: task edges-srl-ontonotes, batch 355 (28355): mcc: 0.8910, acc: 0.8474, precision: 0.9162, recall: 0.8696, f1: 0.8923, edges-srl-ontonotes_loss: 0.0097
09/16 09:56:59 AM: Update 28491: task edges-srl-ontonotes, batch 491 (28491): mcc: 0.8824, acc: 0.8369, precision: 0.9093, recall: 0.8597, f1: 0.8838, edges-srl-ontonotes_loss: 0.0103
09/16 09:57:09 AM: Update 28625: task edges-srl-ontonotes, batch 625 (28625): mcc: 0.8783, acc: 0.8311, precision: 0.9063, recall: 0.8547, f1: 0.8798, edges-srl-ontonotes_loss: 0.0105
09/16 09:57:19 AM: Update 28752: task edges-srl-ontonotes, batch 752 (28752): mcc: 0.8715, acc: 0.8219, precision: 0.9013, recall: 0.8464, f1: 0.8730, edges-srl-ontonotes_loss: 0.0110
09/16 09:57:29 AM: Update 28884: task edges-srl-ontonotes, batch 884 (28884): mcc: 0.8672, acc: 0.8160, precision: 0.8984, recall: 0.8409, f1: 0.8687, edges-srl-ontonotes_loss: 0.0113
09/16 09:57:39 AM: Update 28989: task edges-srl-ontonotes, batch 989 (28989): mcc: 0.8652, acc: 0.8133, precision: 0.8968, recall: 0.8384, f1: 0.8666, edges-srl-ontonotes_loss: 0.0115
09/16 09:57:40 AM: ***** Step 29000 / Validation 29 *****
09/16 09:57:40 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:57:40 AM: Validating...
09/16 09:57:49 AM: Evaluate: task edges-srl-ontonotes, batch 123 (157): mcc: 0.8795, acc: 0.8411, precision: 0.9130, recall: 0.8507, f1: 0.8807, edges-srl-ontonotes_loss: 0.0102
09/16 09:57:52 AM: Updating LR scheduler:
09/16 09:57:52 AM: 	Best result seen so far for macro_avg: 0.881
09/16 09:57:52 AM: 	# validation passes without improvement: 2
09/16 09:57:52 AM: edges-srl-ontonotes_loss: training: 0.011445 validation: 0.010428
09/16 09:57:52 AM: macro_avg: validation: 0.878917
09/16 09:57:52 AM: micro_avg: validation: 0.000000
09/16 09:57:52 AM: edges-srl-ontonotes_mcc: training: 0.865236 validation: 0.877752
09/16 09:57:52 AM: edges-srl-ontonotes_acc: training: 0.813300 validation: 0.838427
09/16 09:57:52 AM: edges-srl-ontonotes_precision: training: 0.896935 validation: 0.912921
09/16 09:57:52 AM: edges-srl-ontonotes_recall: training: 0.838457 validation: 0.847356
09/16 09:57:52 AM: edges-srl-ontonotes_f1: training: 0.866711 validation: 0.878917
09/16 09:57:52 AM: Global learning rate: 1.25e-05
09/16 09:57:52 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:57:59 AM: Update 29109: task edges-srl-ontonotes, batch 109 (29109): mcc: 0.8676, acc: 0.8145, precision: 0.9030, recall: 0.8373, f1: 0.8689, edges-srl-ontonotes_loss: 0.0115
09/16 09:58:09 AM: Update 29266: task edges-srl-ontonotes, batch 266 (29266): mcc: 0.8677, acc: 0.8156, precision: 0.9028, recall: 0.8377, f1: 0.8690, edges-srl-ontonotes_loss: 0.0113
09/16 09:58:19 AM: Update 29399: task edges-srl-ontonotes, batch 399 (29399): mcc: 0.8665, acc: 0.8138, precision: 0.9007, recall: 0.8374, f1: 0.8679, edges-srl-ontonotes_loss: 0.0113
09/16 09:58:29 AM: Update 29532: task edges-srl-ontonotes, batch 532 (29532): mcc: 0.8665, acc: 0.8136, precision: 0.9001, recall: 0.8378, f1: 0.8679, edges-srl-ontonotes_loss: 0.0113
09/16 09:58:40 AM: Update 29658: task edges-srl-ontonotes, batch 658 (29658): mcc: 0.8651, acc: 0.8116, precision: 0.8992, recall: 0.8360, f1: 0.8665, edges-srl-ontonotes_loss: 0.0114
09/16 09:58:50 AM: Update 29785: task edges-srl-ontonotes, batch 785 (29785): mcc: 0.8637, acc: 0.8097, precision: 0.8979, recall: 0.8347, f1: 0.8651, edges-srl-ontonotes_loss: 0.0115
09/16 09:59:00 AM: Update 29919: task edges-srl-ontonotes, batch 919 (29919): mcc: 0.8633, acc: 0.8096, precision: 0.8971, recall: 0.8346, f1: 0.8647, edges-srl-ontonotes_loss: 0.0115
09/16 09:59:06 AM: ***** Step 30000 / Validation 30 *****
09/16 09:59:06 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 09:59:06 AM: Validating...
09/16 09:59:10 AM: Evaluate: task edges-srl-ontonotes, batch 51 (157): mcc: 0.8729, acc: 0.8326, precision: 0.9087, recall: 0.8420, f1: 0.8741, edges-srl-ontonotes_loss: 0.0108
09/16 09:59:18 AM: Best result seen so far for edges-srl-ontonotes.
09/16 09:59:18 AM: Best result seen so far for macro.
09/16 09:59:18 AM: Updating LR scheduler:
09/16 09:59:18 AM: 	Best result seen so far for macro_avg: 0.882
09/16 09:59:18 AM: 	# validation passes without improvement: 0
09/16 09:59:18 AM: edges-srl-ontonotes_loss: training: 0.011639 validation: 0.010071
09/16 09:59:18 AM: macro_avg: validation: 0.882353
09/16 09:59:18 AM: micro_avg: validation: 0.000000
09/16 09:59:18 AM: edges-srl-ontonotes_mcc: training: 0.861659 validation: 0.881132
09/16 09:59:18 AM: edges-srl-ontonotes_acc: training: 0.807423 validation: 0.842583
09/16 09:59:18 AM: edges-srl-ontonotes_precision: training: 0.895775 validation: 0.913473
09/16 09:59:18 AM: edges-srl-ontonotes_recall: training: 0.832719 validation: 0.853283
09/16 09:59:18 AM: edges-srl-ontonotes_f1: training: 0.863097 validation: 0.882353
09/16 09:59:18 AM: Global learning rate: 1.25e-05
09/16 09:59:18 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 09:59:20 AM: Update 30021: task edges-srl-ontonotes, batch 21 (30021): mcc: 0.8503, acc: 0.7908, precision: 0.8855, recall: 0.8207, f1: 0.8519, edges-srl-ontonotes_loss: 0.0122
09/16 09:59:30 AM: Update 30169: task edges-srl-ontonotes, batch 169 (30169): mcc: 0.8420, acc: 0.7828, precision: 0.8806, recall: 0.8095, f1: 0.8436, edges-srl-ontonotes_loss: 0.0129
09/16 09:59:40 AM: Update 30265: task edges-srl-ontonotes, batch 265 (30265): mcc: 0.8409, acc: 0.7803, precision: 0.8805, recall: 0.8076, f1: 0.8425, edges-srl-ontonotes_loss: 0.0131
09/16 09:59:50 AM: Update 30405: task edges-srl-ontonotes, batch 405 (30405): mcc: 0.8442, acc: 0.7846, precision: 0.8827, recall: 0.8117, f1: 0.8457, edges-srl-ontonotes_loss: 0.0128
09/16 10:00:00 AM: Update 30535: task edges-srl-ontonotes, batch 535 (30535): mcc: 0.8441, acc: 0.7847, precision: 0.8826, recall: 0.8117, f1: 0.8456, edges-srl-ontonotes_loss: 0.0127
09/16 10:00:10 AM: Update 30657: task edges-srl-ontonotes, batch 657 (30657): mcc: 0.8416, acc: 0.7815, precision: 0.8808, recall: 0.8086, f1: 0.8431, edges-srl-ontonotes_loss: 0.0129
09/16 10:00:20 AM: Update 30782: task edges-srl-ontonotes, batch 782 (30782): mcc: 0.8380, acc: 0.7771, precision: 0.8780, recall: 0.8043, f1: 0.8395, edges-srl-ontonotes_loss: 0.0132
09/16 10:00:30 AM: Update 30900: task edges-srl-ontonotes, batch 900 (30900): mcc: 0.8373, acc: 0.7763, precision: 0.8775, recall: 0.8035, f1: 0.8389, edges-srl-ontonotes_loss: 0.0133
09/16 10:00:38 AM: ***** Step 31000 / Validation 31 *****
09/16 10:00:38 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:00:38 AM: Validating...
09/16 10:00:40 AM: Evaluate: task edges-srl-ontonotes, batch 26 (157): mcc: 0.8831, acc: 0.8402, precision: 0.9242, recall: 0.8470, f1: 0.8839, edges-srl-ontonotes_loss: 0.0100
09/16 10:00:50 AM: Updating LR scheduler:
09/16 10:00:50 AM: 	Best result seen so far for macro_avg: 0.882
09/16 10:00:50 AM: 	# validation passes without improvement: 1
09/16 10:00:50 AM: edges-srl-ontonotes_loss: training: 0.013335 validation: 0.010112
09/16 10:00:50 AM: macro_avg: validation: 0.881749
09/16 10:00:50 AM: micro_avg: validation: 0.000000
09/16 10:00:50 AM: edges-srl-ontonotes_mcc: training: 0.836261 validation: 0.880667
09/16 10:00:50 AM: edges-srl-ontonotes_acc: training: 0.774859 validation: 0.839966
09/16 10:00:50 AM: edges-srl-ontonotes_precision: training: 0.876590 validation: 0.916888
09/16 10:00:50 AM: edges-srl-ontonotes_recall: training: 0.802298 validation: 0.849203
09/16 10:00:50 AM: edges-srl-ontonotes_f1: training: 0.837801 validation: 0.881749
09/16 10:00:50 AM: Global learning rate: 1.25e-05
09/16 10:00:50 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 10:00:50 AM: Update 31001: task edges-srl-ontonotes, batch 1 (31001): mcc: 0.9188, acc: 0.8667, precision: 0.9200, recall: 0.9200, f1: 0.9200, edges-srl-ontonotes_loss: 0.0082
09/16 10:01:00 AM: Update 31123: task edges-srl-ontonotes, batch 123 (31123): mcc: 0.8288, acc: 0.7661, precision: 0.8707, recall: 0.7937, f1: 0.8304, edges-srl-ontonotes_loss: 0.0137
09/16 10:01:10 AM: Update 31209: task edges-srl-ontonotes, batch 209 (31209): mcc: 0.8309, acc: 0.7689, precision: 0.8730, recall: 0.7954, f1: 0.8324, edges-srl-ontonotes_loss: 0.0135
09/16 10:01:20 AM: Update 31321: task edges-srl-ontonotes, batch 321 (31321): mcc: 0.8392, acc: 0.7785, precision: 0.8798, recall: 0.8048, f1: 0.8407, edges-srl-ontonotes_loss: 0.0130
09/16 10:01:30 AM: Update 31440: task edges-srl-ontonotes, batch 440 (31440): mcc: 0.8435, acc: 0.7843, precision: 0.8833, recall: 0.8098, f1: 0.8449, edges-srl-ontonotes_loss: 0.0127
09/16 10:01:40 AM: Update 31555: task edges-srl-ontonotes, batch 555 (31555): mcc: 0.8439, acc: 0.7849, precision: 0.8833, recall: 0.8106, f1: 0.8454, edges-srl-ontonotes_loss: 0.0126
09/16 10:01:50 AM: Update 31681: task edges-srl-ontonotes, batch 681 (31681): mcc: 0.8454, acc: 0.7867, precision: 0.8845, recall: 0.8123, f1: 0.8469, edges-srl-ontonotes_loss: 0.0126
09/16 10:02:01 AM: Update 31802: task edges-srl-ontonotes, batch 802 (31802): mcc: 0.8469, acc: 0.7886, precision: 0.8858, recall: 0.8139, f1: 0.8483, edges-srl-ontonotes_loss: 0.0125
09/16 10:02:11 AM: Update 31928: task edges-srl-ontonotes, batch 928 (31928): mcc: 0.8487, acc: 0.7907, precision: 0.8874, recall: 0.8158, f1: 0.8501, edges-srl-ontonotes_loss: 0.0124
09/16 10:02:16 AM: ***** Step 32000 / Validation 32 *****
09/16 10:02:16 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:02:16 AM: Validating...
09/16 10:02:21 AM: Evaluate: task edges-srl-ontonotes, batch 60 (157): mcc: 0.8686, acc: 0.8262, precision: 0.9072, recall: 0.8354, f1: 0.8698, edges-srl-ontonotes_loss: 0.0109
09/16 10:02:28 AM: Updating LR scheduler:
09/16 10:02:28 AM: 	Best result seen so far for macro_avg: 0.882
09/16 10:02:28 AM: 	# validation passes without improvement: 2
09/16 10:02:28 AM: edges-srl-ontonotes_loss: training: 0.012334 validation: 0.010202
09/16 10:02:28 AM: macro_avg: validation: 0.880584
09/16 10:02:28 AM: micro_avg: validation: 0.000000
09/16 10:02:28 AM: edges-srl-ontonotes_mcc: training: 0.849269 validation: 0.879411
09/16 10:02:28 AM: edges-srl-ontonotes_acc: training: 0.791393 validation: 0.840428
09/16 10:02:28 AM: edges-srl-ontonotes_precision: training: 0.887636 validation: 0.913749
09/16 10:02:28 AM: edges-srl-ontonotes_recall: training: 0.816738 validation: 0.849742
09/16 10:02:28 AM: edges-srl-ontonotes_f1: training: 0.850712 validation: 0.880584
09/16 10:02:28 AM: Global learning rate: 1.25e-05
09/16 10:02:28 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 10:02:31 AM: Update 32030: task edges-srl-ontonotes, batch 30 (32030): mcc: 0.8597, acc: 0.8101, precision: 0.8931, recall: 0.8316, f1: 0.8612, edges-srl-ontonotes_loss: 0.0121
09/16 10:02:41 AM: Update 32125: task edges-srl-ontonotes, batch 125 (32125): mcc: 0.8587, acc: 0.8025, precision: 0.8962, recall: 0.8268, f1: 0.8601, edges-srl-ontonotes_loss: 0.0118
09/16 10:02:51 AM: Update 32260: task edges-srl-ontonotes, batch 260 (32260): mcc: 0.8507, acc: 0.7930, precision: 0.8890, recall: 0.8182, f1: 0.8522, edges-srl-ontonotes_loss: 0.0124
09/16 10:03:01 AM: Update 32383: task edges-srl-ontonotes, batch 383 (32383): mcc: 0.8487, acc: 0.7905, precision: 0.8868, recall: 0.8165, f1: 0.8502, edges-srl-ontonotes_loss: 0.0125
09/16 10:03:11 AM: Update 32506: task edges-srl-ontonotes, batch 506 (32506): mcc: 0.8483, acc: 0.7893, precision: 0.8871, recall: 0.8154, f1: 0.8497, edges-srl-ontonotes_loss: 0.0125
09/16 10:03:21 AM: Update 32640: task edges-srl-ontonotes, batch 640 (32640): mcc: 0.8470, acc: 0.7878, precision: 0.8857, recall: 0.8141, f1: 0.8484, edges-srl-ontonotes_loss: 0.0126
09/16 10:03:31 AM: Update 32761: task edges-srl-ontonotes, batch 761 (32761): mcc: 0.8468, acc: 0.7872, precision: 0.8856, recall: 0.8139, f1: 0.8482, edges-srl-ontonotes_loss: 0.0126
09/16 10:03:41 AM: Update 32899: task edges-srl-ontonotes, batch 899 (32899): mcc: 0.8467, acc: 0.7870, precision: 0.8856, recall: 0.8138, f1: 0.8482, edges-srl-ontonotes_loss: 0.0126
09/16 10:03:49 AM: ***** Step 33000 / Validation 33 *****
09/16 10:03:49 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:03:49 AM: Validating...
09/16 10:03:51 AM: Evaluate: task edges-srl-ontonotes, batch 27 (157): mcc: 0.8765, acc: 0.8364, precision: 0.9150, recall: 0.8430, f1: 0.8775, edges-srl-ontonotes_loss: 0.0104
09/16 10:04:01 AM: Updating LR scheduler:
09/16 10:04:01 AM: 	Best result seen so far for macro_avg: 0.882
09/16 10:04:01 AM: 	# validation passes without improvement: 3
09/16 10:04:01 AM: edges-srl-ontonotes_loss: training: 0.012682 validation: 0.010399
09/16 10:04:01 AM: macro_avg: validation: 0.879414
09/16 10:04:01 AM: micro_avg: validation: 0.000000
09/16 10:04:01 AM: edges-srl-ontonotes_mcc: training: 0.846183 validation: 0.878157
09/16 10:04:01 AM: edges-srl-ontonotes_acc: training: 0.786361 validation: 0.840043
09/16 10:04:01 AM: edges-srl-ontonotes_precision: training: 0.885164 validation: 0.910703
09/16 10:04:01 AM: edges-srl-ontonotes_recall: training: 0.813173 validation: 0.850204
09/16 10:04:01 AM: edges-srl-ontonotes_f1: training: 0.847643 validation: 0.879414
09/16 10:04:01 AM: Global learning rate: 1.25e-05
09/16 10:04:01 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 10:04:01 AM: Update 33001: task edges-srl-ontonotes, batch 1 (33001): mcc: 0.9104, acc: 0.8765, precision: 0.9351, recall: 0.8889, f1: 0.9114, edges-srl-ontonotes_loss: 0.0101
09/16 10:04:11 AM: Update 33110: task edges-srl-ontonotes, batch 110 (33110): mcc: 0.8434, acc: 0.7826, precision: 0.8841, recall: 0.8089, f1: 0.8449, edges-srl-ontonotes_loss: 0.0128
09/16 10:04:21 AM: Update 33237: task edges-srl-ontonotes, batch 237 (33237): mcc: 0.8497, acc: 0.7914, precision: 0.8877, recall: 0.8175, f1: 0.8511, edges-srl-ontonotes_loss: 0.0125
09/16 10:04:31 AM: Update 33360: task edges-srl-ontonotes, batch 360 (33360): mcc: 0.8513, acc: 0.7935, precision: 0.8888, recall: 0.8195, f1: 0.8527, edges-srl-ontonotes_loss: 0.0123
09/16 10:04:41 AM: Update 33458: task edges-srl-ontonotes, batch 458 (33458): mcc: 0.8520, acc: 0.7943, precision: 0.8894, recall: 0.8202, f1: 0.8534, edges-srl-ontonotes_loss: 0.0123
09/16 10:04:51 AM: Update 33593: task edges-srl-ontonotes, batch 593 (33593): mcc: 0.8529, acc: 0.7956, precision: 0.8898, recall: 0.8217, f1: 0.8544, edges-srl-ontonotes_loss: 0.0122
09/16 10:05:01 AM: Update 33705: task edges-srl-ontonotes, batch 705 (33705): mcc: 0.8520, acc: 0.7943, precision: 0.8894, recall: 0.8204, f1: 0.8535, edges-srl-ontonotes_loss: 0.0123
09/16 10:05:11 AM: Update 33828: task edges-srl-ontonotes, batch 828 (33828): mcc: 0.8492, acc: 0.7903, precision: 0.8874, recall: 0.8168, f1: 0.8506, edges-srl-ontonotes_loss: 0.0124
09/16 10:05:21 AM: Update 33940: task edges-srl-ontonotes, batch 940 (33940): mcc: 0.8476, acc: 0.7881, precision: 0.8867, recall: 0.8145, f1: 0.8490, edges-srl-ontonotes_loss: 0.0126
09/16 10:05:27 AM: ***** Step 34000 / Validation 34 *****
09/16 10:05:27 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:05:27 AM: Validating...
09/16 10:05:31 AM: Evaluate: task edges-srl-ontonotes, batch 56 (157): mcc: 0.8664, acc: 0.8231, precision: 0.9037, recall: 0.8344, f1: 0.8677, edges-srl-ontonotes_loss: 0.0111
09/16 10:05:39 AM: Updating LR scheduler:
09/16 10:05:39 AM: 	Best result seen so far for macro_avg: 0.882
09/16 10:05:39 AM: 	# validation passes without improvement: 0
09/16 10:05:39 AM: edges-srl-ontonotes_loss: training: 0.012568 validation: 0.010324
09/16 10:05:39 AM: macro_avg: validation: 0.879589
09/16 10:05:39 AM: micro_avg: validation: 0.000000
09/16 10:05:39 AM: edges-srl-ontonotes_mcc: training: 0.847557 validation: 0.878376
09/16 10:05:39 AM: edges-srl-ontonotes_acc: training: 0.788091 validation: 0.839658
09/16 10:05:39 AM: edges-srl-ontonotes_precision: training: 0.886693 validation: 0.912052
09/16 10:05:39 AM: edges-srl-ontonotes_recall: training: 0.814364 validation: 0.849357
09/16 10:05:39 AM: edges-srl-ontonotes_f1: training: 0.848991 validation: 0.879589
09/16 10:05:39 AM: Global learning rate: 6.25e-06
09/16 10:05:39 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 10:05:41 AM: Update 34031: task edges-srl-ontonotes, batch 31 (34031): mcc: 0.8764, acc: 0.8284, precision: 0.9053, recall: 0.8518, f1: 0.8778, edges-srl-ontonotes_loss: 0.0107
09/16 10:05:51 AM: Update 34180: task edges-srl-ontonotes, batch 180 (34180): mcc: 0.8761, acc: 0.8233, precision: 0.9074, recall: 0.8494, f1: 0.8774, edges-srl-ontonotes_loss: 0.0104
09/16 10:06:03 AM: Update 34306: task edges-srl-ontonotes, batch 306 (34306): mcc: 0.8776, acc: 0.8262, precision: 0.9080, recall: 0.8517, f1: 0.8790, edges-srl-ontonotes_loss: 0.0103
09/16 10:06:13 AM: Update 34461: task edges-srl-ontonotes, batch 461 (34461): mcc: 0.8846, acc: 0.8351, precision: 0.9133, recall: 0.8601, f1: 0.8859, edges-srl-ontonotes_loss: 0.0097
09/16 10:06:23 AM: Update 34620: task edges-srl-ontonotes, batch 620 (34620): mcc: 0.8891, acc: 0.8406, precision: 0.9169, recall: 0.8652, f1: 0.8903, edges-srl-ontonotes_loss: 0.0094
09/16 10:06:33 AM: Update 34775: task edges-srl-ontonotes, batch 775 (34775): mcc: 0.8902, acc: 0.8420, precision: 0.9182, recall: 0.8661, f1: 0.8914, edges-srl-ontonotes_loss: 0.0093
09/16 10:06:43 AM: Update 34932: task edges-srl-ontonotes, batch 932 (34932): mcc: 0.8920, acc: 0.8448, precision: 0.9195, recall: 0.8685, f1: 0.8932, edges-srl-ontonotes_loss: 0.0092
09/16 10:06:47 AM: ***** Step 35000 / Validation 35 *****
09/16 10:06:47 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:06:47 AM: Validating...
09/16 10:06:53 AM: Evaluate: task edges-srl-ontonotes, batch 79 (157): mcc: 0.8706, acc: 0.8276, precision: 0.9094, recall: 0.8371, f1: 0.8717, edges-srl-ontonotes_loss: 0.0108
09/16 10:06:59 AM: Updating LR scheduler:
09/16 10:06:59 AM: 	Best result seen so far for macro_avg: 0.882
09/16 10:06:59 AM: 	# validation passes without improvement: 1
09/16 10:06:59 AM: edges-srl-ontonotes_loss: training: 0.009188 validation: 0.010346
09/16 10:06:59 AM: macro_avg: validation: 0.879019
09/16 10:06:59 AM: micro_avg: validation: 0.000000
09/16 10:06:59 AM: edges-srl-ontonotes_mcc: training: 0.892637 validation: 0.877873
09/16 10:06:59 AM: edges-srl-ontonotes_acc: training: 0.845736 validation: 0.838196
09/16 10:06:59 AM: edges-srl-ontonotes_precision: training: 0.920038 validation: 0.913498
09/16 10:06:59 AM: edges-srl-ontonotes_recall: training: 0.869112 validation: 0.847048
09/16 10:06:59 AM: edges-srl-ontonotes_f1: training: 0.893850 validation: 0.879019
09/16 10:06:59 AM: Global learning rate: 6.25e-06
09/16 10:06:59 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 10:07:03 AM: Update 35068: task edges-srl-ontonotes, batch 68 (35068): mcc: 0.8941, acc: 0.8484, precision: 0.9197, recall: 0.8723, f1: 0.8954, edges-srl-ontonotes_loss: 0.0090
09/16 10:07:13 AM: Update 35212: task edges-srl-ontonotes, batch 212 (35212): mcc: 0.8984, acc: 0.8548, precision: 0.9240, recall: 0.8765, f1: 0.8996, edges-srl-ontonotes_loss: 0.0088
09/16 10:07:23 AM: Update 35325: task edges-srl-ontonotes, batch 325 (35325): mcc: 0.8982, acc: 0.8548, precision: 0.9235, recall: 0.8765, f1: 0.8994, edges-srl-ontonotes_loss: 0.0090
09/16 10:07:33 AM: Update 35499: task edges-srl-ontonotes, batch 499 (35499): mcc: 0.8972, acc: 0.8545, precision: 0.9225, recall: 0.8755, f1: 0.8984, edges-srl-ontonotes_loss: 0.0091
09/16 10:07:43 AM: Update 35637: task edges-srl-ontonotes, batch 637 (35637): mcc: 0.8929, acc: 0.8488, precision: 0.9192, recall: 0.8703, f1: 0.8941, edges-srl-ontonotes_loss: 0.0094
09/16 10:07:53 AM: Update 35775: task edges-srl-ontonotes, batch 775 (35775): mcc: 0.8880, acc: 0.8423, precision: 0.9153, recall: 0.8647, f1: 0.8893, edges-srl-ontonotes_loss: 0.0098
09/16 10:08:03 AM: Update 35894: task edges-srl-ontonotes, batch 894 (35894): mcc: 0.8842, acc: 0.8376, precision: 0.9123, recall: 0.8602, f1: 0.8855, edges-srl-ontonotes_loss: 0.0101
09/16 10:08:11 AM: ***** Step 36000 / Validation 36 *****
09/16 10:08:11 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:08:11 AM: Validating...
09/16 10:08:13 AM: Evaluate: task edges-srl-ontonotes, batch 26 (157): mcc: 0.8840, acc: 0.8434, precision: 0.9197, recall: 0.8529, f1: 0.8851, edges-srl-ontonotes_loss: 0.0099
09/16 10:08:23 AM: Updating LR scheduler:
09/16 10:08:23 AM: 	Best result seen so far for macro_avg: 0.882
09/16 10:08:23 AM: 	# validation passes without improvement: 2
09/16 10:08:23 AM: edges-srl-ontonotes_loss: training: 0.010389 validation: 0.010233
09/16 10:08:23 AM: macro_avg: validation: 0.880941
09/16 10:08:23 AM: micro_avg: validation: 0.000000
09/16 10:08:23 AM: edges-srl-ontonotes_mcc: training: 0.879595 validation: 0.879762
09/16 10:08:23 AM: edges-srl-ontonotes_acc: training: 0.831457 validation: 0.840967
09/16 10:08:23 AM: edges-srl-ontonotes_precision: training: 0.908915 validation: 0.913806
09/16 10:08:23 AM: edges-srl-ontonotes_recall: training: 0.854635 validation: 0.850358
09/16 10:08:23 AM: edges-srl-ontonotes_f1: training: 0.880940 validation: 0.880941
09/16 10:08:23 AM: Global learning rate: 6.25e-06
09/16 10:08:23 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 10:08:23 AM: Update 36001: task edges-srl-ontonotes, batch 1 (36001): mcc: 0.7926, acc: 0.7273, precision: 0.8193, recall: 0.7727, f1: 0.7953, edges-srl-ontonotes_loss: 0.0167
09/16 10:08:33 AM: Update 36122: task edges-srl-ontonotes, batch 122 (36122): mcc: 0.8409, acc: 0.7806, precision: 0.8813, recall: 0.8067, f1: 0.8424, edges-srl-ontonotes_loss: 0.0133
09/16 10:08:43 AM: Update 36243: task edges-srl-ontonotes, batch 243 (36243): mcc: 0.8469, acc: 0.7873, precision: 0.8856, recall: 0.8141, f1: 0.8483, edges-srl-ontonotes_loss: 0.0128
09/16 10:08:53 AM: Update 36384: task edges-srl-ontonotes, batch 384 (36384): mcc: 0.8541, acc: 0.7971, precision: 0.8904, recall: 0.8232, f1: 0.8555, edges-srl-ontonotes_loss: 0.0123
09/16 10:09:03 AM: Update 36525: task edges-srl-ontonotes, batch 525 (36525): mcc: 0.8565, acc: 0.8002, precision: 0.8923, recall: 0.8261, f1: 0.8579, edges-srl-ontonotes_loss: 0.0121
09/16 10:09:13 AM: Update 36629: task edges-srl-ontonotes, batch 629 (36629): mcc: 0.8585, acc: 0.8027, precision: 0.8938, recall: 0.8285, f1: 0.8599, edges-srl-ontonotes_loss: 0.0119
09/16 10:09:24 AM: Update 36764: task edges-srl-ontonotes, batch 764 (36764): mcc: 0.8601, acc: 0.8043, precision: 0.8950, recall: 0.8304, f1: 0.8615, edges-srl-ontonotes_loss: 0.0118
09/16 10:09:34 AM: Update 36887: task edges-srl-ontonotes, batch 887 (36887): mcc: 0.8608, acc: 0.8054, precision: 0.8958, recall: 0.8311, f1: 0.8623, edges-srl-ontonotes_loss: 0.0117
09/16 10:09:42 AM: ***** Step 37000 / Validation 37 *****
09/16 10:09:42 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:09:42 AM: Validating...
09/16 10:09:44 AM: Evaluate: task edges-srl-ontonotes, batch 23 (157): mcc: 0.8894, acc: 0.8470, precision: 0.9268, recall: 0.8566, f1: 0.8903, edges-srl-ontonotes_loss: 0.0094
09/16 10:09:54 AM: Evaluate: task edges-srl-ontonotes, batch 154 (157): mcc: 0.8824, acc: 0.8430, precision: 0.9163, recall: 0.8530, f1: 0.8835, edges-srl-ontonotes_loss: 0.0100
09/16 10:09:54 AM: Best result seen so far for edges-srl-ontonotes.
09/16 10:09:54 AM: Best result seen so far for macro.
09/16 10:09:54 AM: Updating LR scheduler:
09/16 10:09:54 AM: 	Best result seen so far for macro_avg: 0.883
09/16 10:09:54 AM: 	# validation passes without improvement: 0
09/16 10:09:54 AM: edges-srl-ontonotes_loss: training: 0.011757 validation: 0.010042
09/16 10:09:54 AM: macro_avg: validation: 0.882960
09/16 10:09:54 AM: micro_avg: validation: 0.000000
09/16 10:09:54 AM: edges-srl-ontonotes_mcc: training: 0.860473 validation: 0.881817
09/16 10:09:54 AM: edges-srl-ontonotes_acc: training: 0.805212 validation: 0.842352
09/16 10:09:54 AM: edges-srl-ontonotes_precision: training: 0.895207 validation: 0.916019
09/16 10:09:54 AM: edges-srl-ontonotes_recall: training: 0.830990 validation: 0.852205
09/16 10:09:54 AM: edges-srl-ontonotes_f1: training: 0.861904 validation: 0.882960
09/16 10:09:54 AM: Global learning rate: 6.25e-06
09/16 10:09:54 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 10:10:04 AM: Update 37127: task edges-srl-ontonotes, batch 127 (37127): mcc: 0.8569, acc: 0.8015, precision: 0.8924, recall: 0.8268, f1: 0.8584, edges-srl-ontonotes_loss: 0.0119
09/16 10:10:14 AM: Update 37246: task edges-srl-ontonotes, batch 246 (37246): mcc: 0.8559, acc: 0.7997, precision: 0.8932, recall: 0.8242, f1: 0.8573, edges-srl-ontonotes_loss: 0.0120
09/16 10:10:24 AM: Update 37381: task edges-srl-ontonotes, batch 381 (37381): mcc: 0.8509, acc: 0.7929, precision: 0.8894, recall: 0.8182, f1: 0.8523, edges-srl-ontonotes_loss: 0.0123
09/16 10:10:35 AM: Update 37483: task edges-srl-ontonotes, batch 483 (37483): mcc: 0.8490, acc: 0.7906, precision: 0.8871, recall: 0.8167, f1: 0.8504, edges-srl-ontonotes_loss: 0.0125
09/16 10:10:45 AM: Update 37600: task edges-srl-ontonotes, batch 600 (37600): mcc: 0.8490, acc: 0.7906, precision: 0.8870, recall: 0.8169, f1: 0.8505, edges-srl-ontonotes_loss: 0.0125
09/16 10:10:55 AM: Update 37727: task edges-srl-ontonotes, batch 727 (37727): mcc: 0.8495, acc: 0.7909, precision: 0.8873, recall: 0.8175, f1: 0.8510, edges-srl-ontonotes_loss: 0.0124
09/16 10:11:05 AM: Update 37852: task edges-srl-ontonotes, batch 852 (37852): mcc: 0.8482, acc: 0.7895, precision: 0.8860, recall: 0.8162, f1: 0.8497, edges-srl-ontonotes_loss: 0.0125
09/16 10:11:15 AM: Update 37984: task edges-srl-ontonotes, batch 984 (37984): mcc: 0.8451, acc: 0.7856, precision: 0.8837, recall: 0.8125, f1: 0.8466, edges-srl-ontonotes_loss: 0.0127
09/16 10:11:16 AM: ***** Step 38000 / Validation 38 *****
09/16 10:11:16 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:11:16 AM: Validating...
09/16 10:11:25 AM: Evaluate: task edges-srl-ontonotes, batch 119 (157): mcc: 0.8836, acc: 0.8436, precision: 0.9178, recall: 0.8540, f1: 0.8847, edges-srl-ontonotes_loss: 0.0099
09/16 10:11:28 AM: Best result seen so far for edges-srl-ontonotes.
09/16 10:11:28 AM: Best result seen so far for macro.
09/16 10:11:28 AM: Updating LR scheduler:
09/16 10:11:28 AM: 	Best result seen so far for macro_avg: 0.883
09/16 10:11:28 AM: 	# validation passes without improvement: 0
09/16 10:11:28 AM: edges-srl-ontonotes_loss: training: 0.012738 validation: 0.009994
09/16 10:11:28 AM: macro_avg: validation: 0.883313
09/16 10:11:28 AM: micro_avg: validation: 0.000000
09/16 10:11:28 AM: edges-srl-ontonotes_mcc: training: 0.844574 validation: 0.882190
09/16 10:11:28 AM: edges-srl-ontonotes_acc: training: 0.784909 validation: 0.841968
09/16 10:11:28 AM: edges-srl-ontonotes_precision: training: 0.883194 validation: 0.916777
09/16 10:11:28 AM: edges-srl-ontonotes_recall: training: 0.811946 validation: 0.852205
09/16 10:11:28 AM: edges-srl-ontonotes_f1: training: 0.846073 validation: 0.883313
09/16 10:11:28 AM: Global learning rate: 6.25e-06
09/16 10:11:28 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 10:11:35 AM: Update 38093: task edges-srl-ontonotes, batch 93 (38093): mcc: 0.8216, acc: 0.7583, precision: 0.8630, recall: 0.7871, f1: 0.8233, edges-srl-ontonotes_loss: 0.0144
09/16 10:11:45 AM: Update 38205: task edges-srl-ontonotes, batch 205 (38205): mcc: 0.8244, acc: 0.7618, precision: 0.8668, recall: 0.7890, f1: 0.8261, edges-srl-ontonotes_loss: 0.0142
09/16 10:11:55 AM: Update 38339: task edges-srl-ontonotes, batch 339 (38339): mcc: 0.8267, acc: 0.7649, precision: 0.8686, recall: 0.7915, f1: 0.8283, edges-srl-ontonotes_loss: 0.0141
09/16 10:12:05 AM: Update 38453: task edges-srl-ontonotes, batch 453 (38453): mcc: 0.8302, acc: 0.7679, precision: 0.8720, recall: 0.7950, f1: 0.8317, edges-srl-ontonotes_loss: 0.0138
09/16 10:12:15 AM: Update 38574: task edges-srl-ontonotes, batch 574 (38574): mcc: 0.8358, acc: 0.7748, precision: 0.8763, recall: 0.8017, f1: 0.8374, edges-srl-ontonotes_loss: 0.0134
09/16 10:12:25 AM: Update 38690: task edges-srl-ontonotes, batch 690 (38690): mcc: 0.8396, acc: 0.7797, precision: 0.8795, recall: 0.8059, f1: 0.8411, edges-srl-ontonotes_loss: 0.0131
09/16 10:12:35 AM: Update 38782: task edges-srl-ontonotes, batch 782 (38782): mcc: 0.8414, acc: 0.7815, precision: 0.8808, recall: 0.8080, f1: 0.8429, edges-srl-ontonotes_loss: 0.0130
09/16 10:12:45 AM: Update 38908: task edges-srl-ontonotes, batch 908 (38908): mcc: 0.8433, acc: 0.7837, precision: 0.8823, recall: 0.8103, f1: 0.8448, edges-srl-ontonotes_loss: 0.0129
09/16 10:12:53 AM: ***** Step 39000 / Validation 39 *****
09/16 10:12:53 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:12:53 AM: Validating...
09/16 10:12:55 AM: Evaluate: task edges-srl-ontonotes, batch 29 (157): mcc: 0.8838, acc: 0.8437, precision: 0.9196, recall: 0.8526, f1: 0.8848, edges-srl-ontonotes_loss: 0.0100
09/16 10:13:05 AM: Updating LR scheduler:
09/16 10:13:05 AM: 	Best result seen so far for macro_avg: 0.883
09/16 10:13:05 AM: 	# validation passes without improvement: 1
09/16 10:13:05 AM: edges-srl-ontonotes_loss: training: 0.012761 validation: 0.010097
09/16 10:13:05 AM: macro_avg: validation: 0.882313
09/16 10:13:05 AM: micro_avg: validation: 0.000000
09/16 10:13:05 AM: edges-srl-ontonotes_mcc: training: 0.844811 validation: 0.881115
09/16 10:13:05 AM: edges-srl-ontonotes_acc: training: 0.785717 validation: 0.842814
09/16 10:13:05 AM: edges-srl-ontonotes_precision: training: 0.883746 validation: 0.914095
09/16 10:13:05 AM: edges-srl-ontonotes_recall: training: 0.811884 validation: 0.852667
09/16 10:13:05 AM: edges-srl-ontonotes_f1: training: 0.846293 validation: 0.882313
09/16 10:13:05 AM: Global learning rate: 6.25e-06
09/16 10:13:05 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 10:13:06 AM: Update 39002: task edges-srl-ontonotes, batch 2 (39002): mcc: 0.8527, acc: 0.8160, precision: 0.8824, recall: 0.8282, f1: 0.8544, edges-srl-ontonotes_loss: 0.0108
09/16 10:13:16 AM: Update 39113: task edges-srl-ontonotes, batch 113 (39113): mcc: 0.8546, acc: 0.7989, precision: 0.8903, recall: 0.8244, f1: 0.8561, edges-srl-ontonotes_loss: 0.0120
09/16 10:13:26 AM: Update 39240: task edges-srl-ontonotes, batch 240 (39240): mcc: 0.8556, acc: 0.7998, precision: 0.8909, recall: 0.8257, f1: 0.8571, edges-srl-ontonotes_loss: 0.0119
09/16 10:13:36 AM: Update 39363: task edges-srl-ontonotes, batch 363 (39363): mcc: 0.8572, acc: 0.8013, precision: 0.8928, recall: 0.8270, f1: 0.8587, edges-srl-ontonotes_loss: 0.0118
09/16 10:13:46 AM: Update 39486: task edges-srl-ontonotes, batch 486 (39486): mcc: 0.8549, acc: 0.7983, precision: 0.8912, recall: 0.8241, f1: 0.8563, edges-srl-ontonotes_loss: 0.0120
09/16 10:13:56 AM: Update 39615: task edges-srl-ontonotes, batch 615 (39615): mcc: 0.8527, acc: 0.7954, precision: 0.8894, recall: 0.8216, f1: 0.8541, edges-srl-ontonotes_loss: 0.0122
09/16 10:14:06 AM: Update 39708: task edges-srl-ontonotes, batch 708 (39708): mcc: 0.8522, acc: 0.7948, precision: 0.8891, recall: 0.8210, f1: 0.8537, edges-srl-ontonotes_loss: 0.0122
09/16 10:14:16 AM: Update 39837: task edges-srl-ontonotes, batch 837 (39837): mcc: 0.8509, acc: 0.7930, precision: 0.8882, recall: 0.8193, f1: 0.8523, edges-srl-ontonotes_loss: 0.0124
09/16 10:14:26 AM: Update 39965: task edges-srl-ontonotes, batch 965 (39965): mcc: 0.8506, acc: 0.7928, precision: 0.8879, recall: 0.8191, f1: 0.8521, edges-srl-ontonotes_loss: 0.0124
09/16 10:14:29 AM: ***** Step 40000 / Validation 40 *****
09/16 10:14:29 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:14:29 AM: Validating...
09/16 10:14:36 AM: Evaluate: task edges-srl-ontonotes, batch 85 (157): mcc: 0.8763, acc: 0.8346, precision: 0.9125, recall: 0.8451, f1: 0.8775, edges-srl-ontonotes_loss: 0.0105
09/16 10:14:41 AM: Updating LR scheduler:
09/16 10:14:41 AM: 	Best result seen so far for macro_avg: 0.883
09/16 10:14:41 AM: 	# validation passes without improvement: 2
09/16 10:14:41 AM: edges-srl-ontonotes_loss: training: 0.012424 validation: 0.010125
09/16 10:14:41 AM: macro_avg: validation: 0.882372
09/16 10:14:41 AM: micro_avg: validation: 0.000000
09/16 10:14:41 AM: edges-srl-ontonotes_mcc: training: 0.850140 validation: 0.881193
09/16 10:14:41 AM: edges-srl-ontonotes_acc: training: 0.792121 validation: 0.842506
09/16 10:14:41 AM: edges-srl-ontonotes_precision: training: 0.887567 validation: 0.914663
09/16 10:14:41 AM: edges-srl-ontonotes_recall: training: 0.818454 validation: 0.852282
09/16 10:14:41 AM: edges-srl-ontonotes_f1: training: 0.851610 validation: 0.882372
09/16 10:14:41 AM: Global learning rate: 6.25e-06
09/16 10:14:41 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 10:14:46 AM: Update 40058: task edges-srl-ontonotes, batch 58 (40058): mcc: 0.8459, acc: 0.7852, precision: 0.8832, recall: 0.8144, f1: 0.8474, edges-srl-ontonotes_loss: 0.0128
09/16 10:14:56 AM: Update 40190: task edges-srl-ontonotes, batch 190 (40190): mcc: 0.8432, acc: 0.7830, precision: 0.8819, recall: 0.8105, f1: 0.8447, edges-srl-ontonotes_loss: 0.0131
09/16 10:15:06 AM: Update 40313: task edges-srl-ontonotes, batch 313 (40313): mcc: 0.8439, acc: 0.7850, precision: 0.8827, recall: 0.8112, f1: 0.8454, edges-srl-ontonotes_loss: 0.0129
09/16 10:15:16 AM: Update 40442: task edges-srl-ontonotes, batch 442 (40442): mcc: 0.8473, acc: 0.7890, precision: 0.8859, recall: 0.8146, f1: 0.8488, edges-srl-ontonotes_loss: 0.0127
09/16 10:15:26 AM: Update 40575: task edges-srl-ontonotes, batch 575 (40575): mcc: 0.8485, acc: 0.7907, precision: 0.8865, recall: 0.8163, f1: 0.8499, edges-srl-ontonotes_loss: 0.0125
09/16 10:15:36 AM: Update 40669: task edges-srl-ontonotes, batch 669 (40669): mcc: 0.8495, acc: 0.7921, precision: 0.8873, recall: 0.8174, f1: 0.8509, edges-srl-ontonotes_loss: 0.0125
09/16 10:15:46 AM: Update 40798: task edges-srl-ontonotes, batch 798 (40798): mcc: 0.8508, acc: 0.7937, precision: 0.8885, recall: 0.8189, f1: 0.8523, edges-srl-ontonotes_loss: 0.0124
09/16 10:15:56 AM: Update 40915: task edges-srl-ontonotes, batch 915 (40915): mcc: 0.8510, acc: 0.7938, precision: 0.8888, recall: 0.8190, f1: 0.8525, edges-srl-ontonotes_loss: 0.0123
09/16 10:16:05 AM: ***** Step 41000 / Validation 41 *****
09/16 10:16:05 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:16:05 AM: Validating...
09/16 10:16:06 AM: Evaluate: task edges-srl-ontonotes, batch 12 (157): mcc: 0.8818, acc: 0.8380, precision: 0.9221, recall: 0.8465, f1: 0.8827, edges-srl-ontonotes_loss: 0.0094
09/16 10:16:16 AM: Evaluate: task edges-srl-ontonotes, batch 142 (157): mcc: 0.8819, acc: 0.8438, precision: 0.9145, recall: 0.8538, f1: 0.8831, edges-srl-ontonotes_loss: 0.0100
09/16 10:16:17 AM: Updating LR scheduler:
09/16 10:16:17 AM: 	Best result seen so far for macro_avg: 0.883
09/16 10:16:17 AM: 	# validation passes without improvement: 3
09/16 10:16:17 AM: edges-srl-ontonotes_loss: training: 0.012390 validation: 0.010211
09/16 10:16:17 AM: macro_avg: validation: 0.881132
09/16 10:16:17 AM: micro_avg: validation: 0.000000
09/16 10:16:17 AM: edges-srl-ontonotes_mcc: training: 0.850102 validation: 0.879935
09/16 10:16:17 AM: edges-srl-ontonotes_acc: training: 0.792609 validation: 0.840967
09/16 10:16:17 AM: edges-srl-ontonotes_precision: training: 0.888261 validation: 0.913417
09/16 10:16:17 AM: edges-srl-ontonotes_recall: training: 0.817738 validation: 0.851051
09/16 10:16:17 AM: edges-srl-ontonotes_f1: training: 0.851542 validation: 0.881132
09/16 10:16:17 AM: Global learning rate: 6.25e-06
09/16 10:16:17 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 10:16:26 AM: Update 41099: task edges-srl-ontonotes, batch 99 (41099): mcc: 0.8372, acc: 0.7747, precision: 0.8801, recall: 0.8009, f1: 0.8386, edges-srl-ontonotes_loss: 0.0133
09/16 10:16:36 AM: Update 41218: task edges-srl-ontonotes, batch 218 (41218): mcc: 0.8360, acc: 0.7739, precision: 0.8789, recall: 0.7997, f1: 0.8374, edges-srl-ontonotes_loss: 0.0133
09/16 10:16:46 AM: Update 41351: task edges-srl-ontonotes, batch 351 (41351): mcc: 0.8489, acc: 0.7906, precision: 0.8885, recall: 0.8153, f1: 0.8503, edges-srl-ontonotes_loss: 0.0125
09/16 10:16:56 AM: Update 41496: task edges-srl-ontonotes, batch 496 (41496): mcc: 0.8587, acc: 0.8028, precision: 0.8961, recall: 0.8268, f1: 0.8600, edges-srl-ontonotes_loss: 0.0117
09/16 10:17:06 AM: Update 41639: task edges-srl-ontonotes, batch 639 (41639): mcc: 0.8663, acc: 0.8125, precision: 0.9010, recall: 0.8367, f1: 0.8677, edges-srl-ontonotes_loss: 0.0112
09/16 10:17:16 AM: Update 41818: task edges-srl-ontonotes, batch 818 (41818): mcc: 0.8742, acc: 0.8226, precision: 0.9067, recall: 0.8464, f1: 0.8755, edges-srl-ontonotes_loss: 0.0106
09/16 10:17:26 AM: Update 41944: task edges-srl-ontonotes, batch 944 (41944): mcc: 0.8785, acc: 0.8283, precision: 0.9100, recall: 0.8516, f1: 0.8798, edges-srl-ontonotes_loss: 0.0103
09/16 10:17:30 AM: ***** Step 42000 / Validation 42 *****
09/16 10:17:30 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:17:30 AM: Validating...
09/16 10:17:36 AM: Evaluate: task edges-srl-ontonotes, batch 88 (157): mcc: 0.8745, acc: 0.8321, precision: 0.9124, recall: 0.8417, f1: 0.8756, edges-srl-ontonotes_loss: 0.0105
09/16 10:17:42 AM: Updating LR scheduler:
09/16 10:17:42 AM: 	Best result seen so far for macro_avg: 0.883
09/16 10:17:42 AM: 	# validation passes without improvement: 0
09/16 10:17:42 AM: edges-srl-ontonotes_loss: training: 0.010215 validation: 0.010240
09/16 10:17:42 AM: macro_avg: validation: 0.880683
09/16 10:17:42 AM: micro_avg: validation: 0.000000
09/16 10:17:42 AM: edges-srl-ontonotes_mcc: training: 0.879772 validation: 0.879543
09/16 10:17:42 AM: edges-srl-ontonotes_acc: training: 0.829848 validation: 0.840120
09/16 10:17:42 AM: edges-srl-ontonotes_precision: training: 0.910876 validation: 0.914677
09/16 10:17:42 AM: edges-srl-ontonotes_recall: training: 0.853126 validation: 0.849126
09/16 10:17:42 AM: edges-srl-ontonotes_f1: training: 0.881056 validation: 0.880683
09/16 10:17:42 AM: Global learning rate: 3.125e-06
09/16 10:17:42 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 10:17:47 AM: Update 42073: task edges-srl-ontonotes, batch 73 (42073): mcc: 0.9043, acc: 0.8621, precision: 0.9296, recall: 0.8825, f1: 0.9054, edges-srl-ontonotes_loss: 0.0086
09/16 10:17:57 AM: Update 42229: task edges-srl-ontonotes, batch 229 (42229): mcc: 0.9023, acc: 0.8600, precision: 0.9272, recall: 0.8808, f1: 0.9034, edges-srl-ontonotes_loss: 0.0086
09/16 10:18:07 AM: Update 42395: task edges-srl-ontonotes, batch 395 (42395): mcc: 0.9013, acc: 0.8584, precision: 0.9262, recall: 0.8799, f1: 0.9025, edges-srl-ontonotes_loss: 0.0087
09/16 10:18:17 AM: Update 42549: task edges-srl-ontonotes, batch 549 (42549): mcc: 0.9003, acc: 0.8573, precision: 0.9251, recall: 0.8791, f1: 0.9015, edges-srl-ontonotes_loss: 0.0088
09/16 10:18:27 AM: Update 42710: task edges-srl-ontonotes, batch 710 (42710): mcc: 0.8986, acc: 0.8558, precision: 0.9232, recall: 0.8775, f1: 0.8998, edges-srl-ontonotes_loss: 0.0089
09/16 10:18:37 AM: Update 42809: task edges-srl-ontonotes, batch 809 (42809): mcc: 0.8975, acc: 0.8544, precision: 0.9223, recall: 0.8763, f1: 0.8987, edges-srl-ontonotes_loss: 0.0090
09/16 10:18:47 AM: Update 42930: task edges-srl-ontonotes, batch 930 (42930): mcc: 0.8932, acc: 0.8486, precision: 0.9193, recall: 0.8710, f1: 0.8945, edges-srl-ontonotes_loss: 0.0093
09/16 10:18:52 AM: ***** Step 43000 / Validation 43 *****
09/16 10:18:52 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:18:52 AM: Validating...
09/16 10:18:57 AM: Evaluate: task edges-srl-ontonotes, batch 59 (157): mcc: 0.8717, acc: 0.8290, precision: 0.9099, recall: 0.8387, f1: 0.8728, edges-srl-ontonotes_loss: 0.0109
09/16 10:19:04 AM: Updating LR scheduler:
09/16 10:19:04 AM: 	Best result seen so far for macro_avg: 0.883
09/16 10:19:04 AM: 	# validation passes without improvement: 1
09/16 10:19:04 AM: edges-srl-ontonotes_loss: training: 0.009416 validation: 0.010134
09/16 10:19:04 AM: macro_avg: validation: 0.881795
09/16 10:19:04 AM: micro_avg: validation: 0.000000
09/16 10:19:04 AM: edges-srl-ontonotes_mcc: training: 0.891917 validation: 0.880613
09/16 10:19:04 AM: edges-srl-ontonotes_acc: training: 0.847185 validation: 0.841737
09/16 10:19:04 AM: edges-srl-ontonotes_precision: training: 0.918353 validation: 0.914222
09/16 10:19:04 AM: edges-srl-ontonotes_recall: training: 0.869331 validation: 0.851590
09/16 10:19:04 AM: edges-srl-ontonotes_f1: training: 0.893169 validation: 0.881795
09/16 10:19:04 AM: Global learning rate: 3.125e-06
09/16 10:19:04 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 10:19:07 AM: Update 43033: task edges-srl-ontonotes, batch 33 (43033): mcc: 0.8659, acc: 0.8094, precision: 0.9024, recall: 0.8346, f1: 0.8671, edges-srl-ontonotes_loss: 0.0114
09/16 10:19:17 AM: Update 43144: task edges-srl-ontonotes, batch 144 (43144): mcc: 0.8543, acc: 0.7992, precision: 0.8890, recall: 0.8250, f1: 0.8558, edges-srl-ontonotes_loss: 0.0122
09/16 10:19:27 AM: Update 43268: task edges-srl-ontonotes, batch 268 (43268): mcc: 0.8495, acc: 0.7927, precision: 0.8868, recall: 0.8179, f1: 0.8510, edges-srl-ontonotes_loss: 0.0126
09/16 10:19:37 AM: Update 43398: task edges-srl-ontonotes, batch 398 (43398): mcc: 0.8479, acc: 0.7906, precision: 0.8855, recall: 0.8161, f1: 0.8494, edges-srl-ontonotes_loss: 0.0127
09/16 10:19:47 AM: Update 43511: task edges-srl-ontonotes, batch 511 (43511): mcc: 0.8494, acc: 0.7918, precision: 0.8871, recall: 0.8174, f1: 0.8508, edges-srl-ontonotes_loss: 0.0126
09/16 10:19:57 AM: Update 43633: task edges-srl-ontonotes, batch 633 (43633): mcc: 0.8535, acc: 0.7969, precision: 0.8901, recall: 0.8224, f1: 0.8549, edges-srl-ontonotes_loss: 0.0123
09/16 10:20:07 AM: Update 43770: task edges-srl-ontonotes, batch 770 (43770): mcc: 0.8563, acc: 0.8007, precision: 0.8920, recall: 0.8260, f1: 0.8577, edges-srl-ontonotes_loss: 0.0121
09/16 10:20:17 AM: Update 43877: task edges-srl-ontonotes, batch 877 (43877): mcc: 0.8570, acc: 0.8015, precision: 0.8923, recall: 0.8271, f1: 0.8585, edges-srl-ontonotes_loss: 0.0120
09/16 10:20:25 AM: ***** Step 44000 / Validation 44 *****
09/16 10:20:25 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:20:25 AM: Validating...
09/16 10:20:27 AM: Evaluate: task edges-srl-ontonotes, batch 26 (157): mcc: 0.8845, acc: 0.8443, precision: 0.9202, recall: 0.8534, f1: 0.8855, edges-srl-ontonotes_loss: 0.0098
09/16 10:20:37 AM: Updating LR scheduler:
09/16 10:20:37 AM: 	Best result seen so far for macro_avg: 0.883
09/16 10:20:37 AM: 	# validation passes without improvement: 2
09/16 10:20:37 AM: edges-srl-ontonotes_loss: training: 0.011910 validation: 0.009998
09/16 10:20:37 AM: macro_avg: validation: 0.883117
09/16 10:20:37 AM: micro_avg: validation: 0.000000
09/16 10:20:37 AM: edges-srl-ontonotes_mcc: training: 0.858483 validation: 0.881941
09/16 10:20:37 AM: edges-srl-ontonotes_acc: training: 0.803339 validation: 0.843661
09/16 10:20:37 AM: edges-srl-ontonotes_precision: training: 0.893522 validation: 0.915201
09/16 10:20:37 AM: edges-srl-ontonotes_recall: training: 0.828775 validation: 0.853206
09/16 10:20:37 AM: edges-srl-ontonotes_f1: training: 0.859931 validation: 0.883117
09/16 10:20:37 AM: Global learning rate: 3.125e-06
09/16 10:20:37 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 10:20:37 AM: Update 44001: task edges-srl-ontonotes, batch 1 (44001): mcc: 0.8566, acc: 0.7978, precision: 0.9114, recall: 0.8090, f1: 0.8571, edges-srl-ontonotes_loss: 0.0120
09/16 10:20:47 AM: Update 44116: task edges-srl-ontonotes, batch 116 (44116): mcc: 0.8712, acc: 0.8195, precision: 0.9029, recall: 0.8443, f1: 0.8726, edges-srl-ontonotes_loss: 0.0109
09/16 10:20:57 AM: Update 44243: task edges-srl-ontonotes, batch 243 (44243): mcc: 0.8664, acc: 0.8133, precision: 0.9001, recall: 0.8377, f1: 0.8678, edges-srl-ontonotes_loss: 0.0112
09/16 10:21:07 AM: Update 44370: task edges-srl-ontonotes, batch 370 (44370): mcc: 0.8640, acc: 0.8107, precision: 0.8974, recall: 0.8357, f1: 0.8654, edges-srl-ontonotes_loss: 0.0114
09/16 10:21:17 AM: Update 44498: task edges-srl-ontonotes, batch 498 (44498): mcc: 0.8597, acc: 0.8049, precision: 0.8938, recall: 0.8308, f1: 0.8611, edges-srl-ontonotes_loss: 0.0118
09/16 10:21:27 AM: Update 44632: task edges-srl-ontonotes, batch 632 (44632): mcc: 0.8573, acc: 0.8016, precision: 0.8920, recall: 0.8278, f1: 0.8587, edges-srl-ontonotes_loss: 0.0119
09/16 10:21:37 AM: Update 44751: task edges-srl-ontonotes, batch 751 (44751): mcc: 0.8556, acc: 0.7996, precision: 0.8909, recall: 0.8258, f1: 0.8571, edges-srl-ontonotes_loss: 0.0120
09/16 10:21:47 AM: Update 44889: task edges-srl-ontonotes, batch 889 (44889): mcc: 0.8560, acc: 0.7998, precision: 0.8914, recall: 0.8261, f1: 0.8575, edges-srl-ontonotes_loss: 0.0120
09/16 10:21:55 AM: ***** Step 45000 / Validation 45 *****
09/16 10:21:55 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:21:55 AM: Validating...
09/16 10:21:57 AM: Evaluate: task edges-srl-ontonotes, batch 25 (157): mcc: 0.8865, acc: 0.8470, precision: 0.9221, recall: 0.8555, f1: 0.8875, edges-srl-ontonotes_loss: 0.0096
09/16 10:22:07 AM: Evaluate: task edges-srl-ontonotes, batch 150 (157): mcc: 0.8841, acc: 0.8458, precision: 0.9164, recall: 0.8562, f1: 0.8853, edges-srl-ontonotes_loss: 0.0098
09/16 10:22:08 AM: Best result seen so far for edges-srl-ontonotes.
09/16 10:22:08 AM: Best result seen so far for macro.
09/16 10:22:08 AM: Updating LR scheduler:
09/16 10:22:08 AM: 	Best result seen so far for macro_avg: 0.884
09/16 10:22:08 AM: 	# validation passes without improvement: 0
09/16 10:22:08 AM: edges-srl-ontonotes_loss: training: 0.012065 validation: 0.009972
09/16 10:22:08 AM: macro_avg: validation: 0.884128
09/16 10:22:08 AM: micro_avg: validation: 0.000000
09/16 10:22:08 AM: edges-srl-ontonotes_mcc: training: 0.855086 validation: 0.882952
09/16 10:22:08 AM: edges-srl-ontonotes_acc: training: 0.798415 validation: 0.844508
09/16 10:22:08 AM: edges-srl-ontonotes_precision: training: 0.890394 validation: 0.915780
09/16 10:22:08 AM: edges-srl-ontonotes_recall: training: 0.825225 validation: 0.854592
09/16 10:22:08 AM: edges-srl-ontonotes_f1: training: 0.856572 validation: 0.884128
09/16 10:22:08 AM: Global learning rate: 3.125e-06
09/16 10:22:08 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 10:22:17 AM: Update 45090: task edges-srl-ontonotes, batch 90 (45090): mcc: 0.8432, acc: 0.7818, precision: 0.8842, recall: 0.8083, f1: 0.8446, edges-srl-ontonotes_loss: 0.0127
09/16 10:22:27 AM: Update 45218: task edges-srl-ontonotes, batch 218 (45218): mcc: 0.8336, acc: 0.7708, precision: 0.8751, recall: 0.7987, f1: 0.8351, edges-srl-ontonotes_loss: 0.0135
09/16 10:22:37 AM: Update 45342: task edges-srl-ontonotes, batch 342 (45342): mcc: 0.8314, acc: 0.7675, precision: 0.8735, recall: 0.7958, f1: 0.8329, edges-srl-ontonotes_loss: 0.0136
09/16 10:22:47 AM: Update 45450: task edges-srl-ontonotes, batch 450 (45450): mcc: 0.8290, acc: 0.7651, precision: 0.8716, recall: 0.7932, f1: 0.8306, edges-srl-ontonotes_loss: 0.0138
09/16 10:22:58 AM: Update 45577: task edges-srl-ontonotes, batch 577 (45577): mcc: 0.8295, acc: 0.7663, precision: 0.8723, recall: 0.7934, f1: 0.8310, edges-srl-ontonotes_loss: 0.0139
09/16 10:23:08 AM: Update 45686: task edges-srl-ontonotes, batch 686 (45686): mcc: 0.8305, acc: 0.7677, precision: 0.8728, recall: 0.7949, f1: 0.8320, edges-srl-ontonotes_loss: 0.0137
09/16 10:23:18 AM: Update 45814: task edges-srl-ontonotes, batch 814 (45814): mcc: 0.8348, acc: 0.7731, precision: 0.8762, recall: 0.7999, f1: 0.8363, edges-srl-ontonotes_loss: 0.0134
09/16 10:23:28 AM: Update 45937: task edges-srl-ontonotes, batch 937 (45937): mcc: 0.8375, acc: 0.7767, precision: 0.8784, recall: 0.8030, f1: 0.8390, edges-srl-ontonotes_loss: 0.0132
09/16 10:23:36 AM: ***** Step 46000 / Validation 46 *****
09/16 10:23:36 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:23:36 AM: Validating...
09/16 10:23:38 AM: Evaluate: task edges-srl-ontonotes, batch 24 (157): mcc: 0.8864, acc: 0.8459, precision: 0.9217, recall: 0.8556, f1: 0.8874, edges-srl-ontonotes_loss: 0.0097
09/16 10:23:48 AM: Evaluate: task edges-srl-ontonotes, batch 154 (157): mcc: 0.8836, acc: 0.8453, precision: 0.9161, recall: 0.8556, f1: 0.8848, edges-srl-ontonotes_loss: 0.0099
09/16 10:23:48 AM: Best result seen so far for edges-srl-ontonotes.
09/16 10:23:48 AM: Best result seen so far for macro.
09/16 10:23:48 AM: Updating LR scheduler:
09/16 10:23:48 AM: 	Best result seen so far for macro_avg: 0.884
09/16 10:23:48 AM: 	# validation passes without improvement: 1
09/16 10:23:48 AM: edges-srl-ontonotes_loss: training: 0.013139 validation: 0.009982
09/16 10:23:48 AM: macro_avg: validation: 0.884182
09/16 10:23:48 AM: micro_avg: validation: 0.000000
09/16 10:23:48 AM: edges-srl-ontonotes_mcc: training: 0.839011 validation: 0.883002
09/16 10:23:48 AM: edges-srl-ontonotes_acc: training: 0.778555 validation: 0.844585
09/16 10:23:48 AM: edges-srl-ontonotes_precision: training: 0.879514 validation: 0.915718
09/16 10:23:48 AM: edges-srl-ontonotes_recall: training: 0.804809 validation: 0.854746
09/16 10:23:48 AM: edges-srl-ontonotes_f1: training: 0.840505 validation: 0.884182
09/16 10:23:48 AM: Global learning rate: 3.125e-06
09/16 10:23:48 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 10:23:58 AM: Update 46119: task edges-srl-ontonotes, batch 119 (46119): mcc: 0.8493, acc: 0.7916, precision: 0.8879, recall: 0.8165, f1: 0.8507, edges-srl-ontonotes_loss: 0.0122
09/16 10:24:08 AM: Update 46230: task edges-srl-ontonotes, batch 230 (46230): mcc: 0.8557, acc: 0.7997, precision: 0.8924, recall: 0.8245, f1: 0.8571, edges-srl-ontonotes_loss: 0.0119
09/16 10:24:18 AM: Update 46329: task edges-srl-ontonotes, batch 329 (46329): mcc: 0.8567, acc: 0.7996, precision: 0.8931, recall: 0.8258, f1: 0.8581, edges-srl-ontonotes_loss: 0.0119
09/16 10:24:28 AM: Update 46449: task edges-srl-ontonotes, batch 449 (46449): mcc: 0.8579, acc: 0.8022, precision: 0.8934, recall: 0.8278, f1: 0.8593, edges-srl-ontonotes_loss: 0.0119
09/16 10:24:38 AM: Update 46569: task edges-srl-ontonotes, batch 569 (46569): mcc: 0.8585, acc: 0.8028, precision: 0.8944, recall: 0.8280, f1: 0.8599, edges-srl-ontonotes_loss: 0.0118
09/16 10:24:48 AM: Update 46684: task edges-srl-ontonotes, batch 684 (46684): mcc: 0.8573, acc: 0.8016, precision: 0.8935, recall: 0.8266, f1: 0.8587, edges-srl-ontonotes_loss: 0.0119
09/16 10:24:58 AM: Update 46800: task edges-srl-ontonotes, batch 800 (46800): mcc: 0.8551, acc: 0.7991, precision: 0.8914, recall: 0.8243, f1: 0.8566, edges-srl-ontonotes_loss: 0.0120
09/16 10:25:08 AM: Update 46919: task edges-srl-ontonotes, batch 919 (46919): mcc: 0.8534, acc: 0.7968, precision: 0.8905, recall: 0.8219, f1: 0.8549, edges-srl-ontonotes_loss: 0.0121
09/16 10:25:15 AM: ***** Step 47000 / Validation 47 *****
09/16 10:25:15 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:25:15 AM: Validating...
09/16 10:25:18 AM: Evaluate: task edges-srl-ontonotes, batch 40 (157): mcc: 0.8752, acc: 0.8335, precision: 0.9118, recall: 0.8436, f1: 0.8764, edges-srl-ontonotes_loss: 0.0106
09/16 10:25:27 AM: Updating LR scheduler:
09/16 10:25:27 AM: 	Best result seen so far for macro_avg: 0.884
09/16 10:25:27 AM: 	# validation passes without improvement: 2
09/16 10:25:27 AM: edges-srl-ontonotes_loss: training: 0.012186 validation: 0.010027
09/16 10:25:27 AM: macro_avg: validation: 0.883506
09/16 10:25:27 AM: micro_avg: validation: 0.000000
09/16 10:25:27 AM: edges-srl-ontonotes_mcc: training: 0.852815 validation: 0.882339
09/16 10:25:27 AM: edges-srl-ontonotes_acc: training: 0.795960 validation: 0.843661
09/16 10:25:27 AM: edges-srl-ontonotes_precision: training: 0.890143 validation: 0.915683
09/16 10:25:27 AM: edges-srl-ontonotes_recall: training: 0.821141 validation: 0.853514
09/16 10:25:27 AM: edges-srl-ontonotes_f1: training: 0.854251 validation: 0.883506
09/16 10:25:27 AM: Global learning rate: 3.125e-06
09/16 10:25:27 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 10:25:28 AM: Update 47014: task edges-srl-ontonotes, batch 14 (47014): mcc: 0.8488, acc: 0.7906, precision: 0.8933, recall: 0.8106, f1: 0.8500, edges-srl-ontonotes_loss: 0.0127
09/16 10:25:38 AM: Update 47135: task edges-srl-ontonotes, batch 135 (47135): mcc: 0.8480, acc: 0.7918, precision: 0.8844, recall: 0.8174, f1: 0.8496, edges-srl-ontonotes_loss: 0.0127
09/16 10:25:49 AM: Update 47233: task edges-srl-ontonotes, batch 233 (47233): mcc: 0.8463, acc: 0.7890, precision: 0.8830, recall: 0.8154, f1: 0.8479, edges-srl-ontonotes_loss: 0.0128
09/16 10:25:59 AM: Update 47357: task edges-srl-ontonotes, batch 357 (47357): mcc: 0.8446, acc: 0.7860, precision: 0.8827, recall: 0.8125, f1: 0.8461, edges-srl-ontonotes_loss: 0.0128
09/16 10:26:09 AM: Update 47483: task edges-srl-ontonotes, batch 483 (47483): mcc: 0.8441, acc: 0.7856, precision: 0.8824, recall: 0.8117, f1: 0.8456, edges-srl-ontonotes_loss: 0.0129
09/16 10:26:19 AM: Update 47603: task edges-srl-ontonotes, batch 603 (47603): mcc: 0.8446, acc: 0.7863, precision: 0.8831, recall: 0.8121, f1: 0.8461, edges-srl-ontonotes_loss: 0.0128
09/16 10:26:29 AM: Update 47731: task edges-srl-ontonotes, batch 731 (47731): mcc: 0.8466, acc: 0.7886, precision: 0.8850, recall: 0.8141, f1: 0.8480, edges-srl-ontonotes_loss: 0.0127
09/16 10:26:39 AM: Update 47852: task edges-srl-ontonotes, batch 852 (47852): mcc: 0.8478, acc: 0.7901, precision: 0.8857, recall: 0.8157, f1: 0.8493, edges-srl-ontonotes_loss: 0.0126
09/16 10:26:49 AM: Update 47969: task edges-srl-ontonotes, batch 969 (47969): mcc: 0.8492, acc: 0.7915, precision: 0.8870, recall: 0.8172, f1: 0.8506, edges-srl-ontonotes_loss: 0.0125
09/16 10:26:52 AM: ***** Step 48000 / Validation 48 *****
09/16 10:26:52 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:26:52 AM: Validating...
09/16 10:26:59 AM: Evaluate: task edges-srl-ontonotes, batch 95 (157): mcc: 0.8786, acc: 0.8380, precision: 0.9129, recall: 0.8489, f1: 0.8798, edges-srl-ontonotes_loss: 0.0102
09/16 10:27:04 AM: Updating LR scheduler:
09/16 10:27:04 AM: 	Best result seen so far for macro_avg: 0.884
09/16 10:27:04 AM: 	# validation passes without improvement: 3
09/16 10:27:04 AM: edges-srl-ontonotes_loss: training: 0.012475 validation: 0.010094
09/16 10:27:04 AM: macro_avg: validation: 0.882660
09/16 10:27:04 AM: micro_avg: validation: 0.000000
09/16 10:27:04 AM: edges-srl-ontonotes_mcc: training: 0.849270 validation: 0.881459
09/16 10:27:04 AM: edges-srl-ontonotes_acc: training: 0.791487 validation: 0.842814
09/16 10:27:04 AM: edges-srl-ontonotes_precision: training: 0.887165 validation: 0.914220
09/16 10:27:04 AM: edges-srl-ontonotes_recall: training: 0.817174 validation: 0.853206
09/16 10:27:04 AM: edges-srl-ontonotes_f1: training: 0.850733 validation: 0.882660
09/16 10:27:04 AM: Global learning rate: 3.125e-06
09/16 10:27:04 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 10:27:09 AM: Update 48055: task edges-srl-ontonotes, batch 55 (48055): mcc: 0.8530, acc: 0.7941, precision: 0.8857, recall: 0.8256, f1: 0.8546, edges-srl-ontonotes_loss: 0.0122
09/16 10:27:21 AM: Update 48172: task edges-srl-ontonotes, batch 172 (48172): mcc: 0.8534, acc: 0.7969, precision: 0.8890, recall: 0.8234, f1: 0.8549, edges-srl-ontonotes_loss: 0.0122
09/16 10:27:31 AM: Update 48288: task edges-srl-ontonotes, batch 288 (48288): mcc: 0.8458, acc: 0.7867, precision: 0.8847, recall: 0.8129, f1: 0.8473, edges-srl-ontonotes_loss: 0.0127
09/16 10:27:42 AM: Update 48404: task edges-srl-ontonotes, batch 404 (48404): mcc: 0.8448, acc: 0.7848, precision: 0.8854, recall: 0.8103, f1: 0.8462, edges-srl-ontonotes_loss: 0.0127
09/16 10:27:52 AM: Update 48512: task edges-srl-ontonotes, batch 512 (48512): mcc: 0.8459, acc: 0.7859, precision: 0.8867, recall: 0.8113, f1: 0.8473, edges-srl-ontonotes_loss: 0.0127
09/16 10:28:02 AM: Update 48664: task edges-srl-ontonotes, batch 664 (48664): mcc: 0.8539, acc: 0.7963, precision: 0.8923, recall: 0.8213, f1: 0.8553, edges-srl-ontonotes_loss: 0.0121
09/16 10:28:12 AM: Update 48802: task edges-srl-ontonotes, batch 802 (48802): mcc: 0.8583, acc: 0.8020, precision: 0.8955, recall: 0.8266, f1: 0.8597, edges-srl-ontonotes_loss: 0.0117
09/16 10:28:22 AM: Update 48961: task edges-srl-ontonotes, batch 961 (48961): mcc: 0.8660, acc: 0.8119, precision: 0.9010, recall: 0.8360, f1: 0.8673, edges-srl-ontonotes_loss: 0.0112
09/16 10:28:24 AM: ***** Step 49000 / Validation 49 *****
09/16 10:28:24 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:28:24 AM: Validating...
09/16 10:28:32 AM: Evaluate: task edges-srl-ontonotes, batch 99 (157): mcc: 0.8789, acc: 0.8376, precision: 0.9149, recall: 0.8477, f1: 0.8800, edges-srl-ontonotes_loss: 0.0101
09/16 10:28:36 AM: Updating LR scheduler:
09/16 10:28:36 AM: 	Best result seen so far for macro_avg: 0.884
09/16 10:28:36 AM: 	# validation passes without improvement: 0
09/16 10:28:36 AM: edges-srl-ontonotes_loss: training: 0.011074 validation: 0.010119
09/16 10:28:36 AM: macro_avg: validation: 0.882081
09/16 10:28:36 AM: micro_avg: validation: 0.000000
09/16 10:28:36 AM: edges-srl-ontonotes_mcc: training: 0.867522 validation: 0.880937
09/16 10:28:36 AM: edges-srl-ontonotes_acc: training: 0.813949 validation: 0.841891
09/16 10:28:36 AM: edges-srl-ontonotes_precision: training: 0.902224 validation: 0.915459
09/16 10:28:36 AM: edges-srl-ontonotes_recall: training: 0.837862 validation: 0.851051
09/16 10:28:36 AM: edges-srl-ontonotes_f1: training: 0.868853 validation: 0.882081
09/16 10:28:36 AM: Global learning rate: 1.5625e-06
09/16 10:28:36 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 10:28:42 AM: Update 49100: task edges-srl-ontonotes, batch 100 (49100): mcc: 0.9050, acc: 0.8633, precision: 0.9304, recall: 0.8829, f1: 0.9061, edges-srl-ontonotes_loss: 0.0082
09/16 10:28:52 AM: Update 49248: task edges-srl-ontonotes, batch 248 (49248): mcc: 0.9025, acc: 0.8598, precision: 0.9283, recall: 0.8803, f1: 0.9036, edges-srl-ontonotes_loss: 0.0085
09/16 10:29:02 AM: Update 49409: task edges-srl-ontonotes, batch 409 (49409): mcc: 0.9007, acc: 0.8573, precision: 0.9271, recall: 0.8780, f1: 0.9019, edges-srl-ontonotes_loss: 0.0086
09/16 10:29:12 AM: Update 49526: task edges-srl-ontonotes, batch 526 (49526): mcc: 0.9009, acc: 0.8579, precision: 0.9270, recall: 0.8784, f1: 0.9020, edges-srl-ontonotes_loss: 0.0086
09/16 10:29:22 AM: Update 49691: task edges-srl-ontonotes, batch 691 (49691): mcc: 0.9006, acc: 0.8576, precision: 0.9267, recall: 0.8781, f1: 0.9017, edges-srl-ontonotes_loss: 0.0086
09/16 10:29:32 AM: Update 49835: task edges-srl-ontonotes, batch 835 (49835): mcc: 0.8999, acc: 0.8568, precision: 0.9256, recall: 0.8778, f1: 0.9011, edges-srl-ontonotes_loss: 0.0087
09/16 10:29:42 AM: Update 49991: task edges-srl-ontonotes, batch 991 (49991): mcc: 0.8992, acc: 0.8563, precision: 0.9245, recall: 0.8775, f1: 0.9004, edges-srl-ontonotes_loss: 0.0088
09/16 10:29:42 AM: ***** Step 50000 / Validation 50 *****
09/16 10:29:42 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:29:42 AM: Validating...
09/16 10:29:52 AM: Evaluate: task edges-srl-ontonotes, batch 125 (157): mcc: 0.8831, acc: 0.8450, precision: 0.9168, recall: 0.8539, f1: 0.8843, edges-srl-ontonotes_loss: 0.0099
09/16 10:29:55 AM: Updating LR scheduler:
09/16 10:29:55 AM: 	Best result seen so far for macro_avg: 0.884
09/16 10:29:55 AM: 	# validation passes without improvement: 1
09/16 10:29:55 AM: edges-srl-ontonotes_loss: training: 0.008837 validation: 0.010087
09/16 10:29:55 AM: macro_avg: validation: 0.882271
09/16 10:29:55 AM: micro_avg: validation: 0.000000
09/16 10:29:55 AM: edges-srl-ontonotes_mcc: training: 0.899300 validation: 0.881158
09/16 10:29:55 AM: edges-srl-ontonotes_acc: training: 0.856496 validation: 0.842352
09/16 10:29:55 AM: edges-srl-ontonotes_precision: training: 0.924505 validation: 0.916404
09/16 10:29:55 AM: edges-srl-ontonotes_recall: training: 0.877668 validation: 0.850589
09/16 10:29:55 AM: edges-srl-ontonotes_f1: training: 0.900478 validation: 0.882271
09/16 10:29:55 AM: Global learning rate: 1.5625e-06
09/16 10:29:55 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 10:30:02 AM: Update 50092: task edges-srl-ontonotes, batch 92 (50092): mcc: 0.8825, acc: 0.8355, precision: 0.9102, recall: 0.8590, f1: 0.8838, edges-srl-ontonotes_loss: 0.0103
09/16 10:30:12 AM: Update 50236: task edges-srl-ontonotes, batch 236 (50236): mcc: 0.8727, acc: 0.8219, precision: 0.9040, recall: 0.8460, f1: 0.8741, edges-srl-ontonotes_loss: 0.0110
09/16 10:30:24 AM: Update 50363: task edges-srl-ontonotes, batch 363 (50363): mcc: 0.8688, acc: 0.8170, precision: 0.9008, recall: 0.8416, f1: 0.8702, edges-srl-ontonotes_loss: 0.0112
09/16 10:30:34 AM: Update 50496: task edges-srl-ontonotes, batch 496 (50496): mcc: 0.8616, acc: 0.8077, precision: 0.8960, recall: 0.8323, f1: 0.8630, edges-srl-ontonotes_loss: 0.0117
09/16 10:30:44 AM: Update 50630: task edges-srl-ontonotes, batch 630 (50630): mcc: 0.8576, acc: 0.8032, precision: 0.8929, recall: 0.8277, f1: 0.8591, edges-srl-ontonotes_loss: 0.0120
09/16 10:30:55 AM: Update 50749: task edges-srl-ontonotes, batch 749 (50749): mcc: 0.8560, acc: 0.8009, precision: 0.8914, recall: 0.8260, f1: 0.8575, edges-srl-ontonotes_loss: 0.0121
09/16 10:31:05 AM: Update 50890: task edges-srl-ontonotes, batch 890 (50890): mcc: 0.8574, acc: 0.8027, precision: 0.8927, recall: 0.8275, f1: 0.8589, edges-srl-ontonotes_loss: 0.0119
09/16 10:31:12 AM: ***** Step 51000 / Validation 51 *****
09/16 10:31:12 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:31:12 AM: Validating...
09/16 10:31:15 AM: Evaluate: task edges-srl-ontonotes, batch 28 (157): mcc: 0.8847, acc: 0.8435, precision: 0.9223, recall: 0.8519, f1: 0.8857, edges-srl-ontonotes_loss: 0.0098
09/16 10:31:25 AM: Evaluate: task edges-srl-ontonotes, batch 146 (157): mcc: 0.8843, acc: 0.8457, precision: 0.9175, recall: 0.8555, f1: 0.8854, edges-srl-ontonotes_loss: 0.0098
09/16 10:31:26 AM: Updating LR scheduler:
09/16 10:31:26 AM: 	Best result seen so far for macro_avg: 0.884
09/16 10:31:26 AM: 	# validation passes without improvement: 2
09/16 10:31:26 AM: edges-srl-ontonotes_loss: training: 0.011874 validation: 0.010018
09/16 10:31:26 AM: macro_avg: validation: 0.883397
09/16 10:31:26 AM: micro_avg: validation: 0.000000
09/16 10:31:26 AM: edges-srl-ontonotes_mcc: training: 0.858382 validation: 0.882249
09/16 10:31:26 AM: edges-srl-ontonotes_acc: training: 0.804048 validation: 0.843584
09/16 10:31:26 AM: edges-srl-ontonotes_precision: training: 0.893121 validation: 0.916157
09/16 10:31:26 AM: edges-srl-ontonotes_recall: training: 0.828955 validation: 0.852898
09/16 10:31:26 AM: edges-srl-ontonotes_f1: training: 0.859843 validation: 0.883397
09/16 10:31:26 AM: Global learning rate: 1.5625e-06
09/16 10:31:26 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 10:31:35 AM: Update 51104: task edges-srl-ontonotes, batch 104 (51104): mcc: 0.8680, acc: 0.8153, precision: 0.9003, recall: 0.8405, f1: 0.8694, edges-srl-ontonotes_loss: 0.0115
09/16 10:31:45 AM: Update 51249: task edges-srl-ontonotes, batch 249 (51249): mcc: 0.8677, acc: 0.8145, precision: 0.9004, recall: 0.8400, f1: 0.8691, edges-srl-ontonotes_loss: 0.0114
09/16 10:31:55 AM: Update 51355: task edges-srl-ontonotes, batch 355 (51355): mcc: 0.8685, acc: 0.8151, precision: 0.9016, recall: 0.8402, f1: 0.8698, edges-srl-ontonotes_loss: 0.0112
09/16 10:32:05 AM: Update 51504: task edges-srl-ontonotes, batch 504 (51504): mcc: 0.8677, acc: 0.8144, precision: 0.9011, recall: 0.8393, f1: 0.8691, edges-srl-ontonotes_loss: 0.0113
09/16 10:32:15 AM: Update 51653: task edges-srl-ontonotes, batch 653 (51653): mcc: 0.8661, acc: 0.8126, precision: 0.8996, recall: 0.8376, f1: 0.8675, edges-srl-ontonotes_loss: 0.0114
09/16 10:32:25 AM: Update 51781: task edges-srl-ontonotes, batch 781 (51781): mcc: 0.8627, acc: 0.8079, precision: 0.8969, recall: 0.8336, f1: 0.8641, edges-srl-ontonotes_loss: 0.0116
09/16 10:32:35 AM: Update 51910: task edges-srl-ontonotes, batch 910 (51910): mcc: 0.8601, acc: 0.8046, precision: 0.8943, recall: 0.8311, f1: 0.8615, edges-srl-ontonotes_loss: 0.0118
09/16 10:32:43 AM: ***** Step 52000 / Validation 52 *****
09/16 10:32:43 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:32:43 AM: Validating...
09/16 10:32:45 AM: Evaluate: task edges-srl-ontonotes, batch 31 (157): mcc: 0.8845, acc: 0.8456, precision: 0.9197, recall: 0.8539, f1: 0.8856, edges-srl-ontonotes_loss: 0.0099
09/16 10:32:55 AM: Updating LR scheduler:
09/16 10:32:55 AM: 	Best result seen so far for macro_avg: 0.884
09/16 10:32:55 AM: 	# validation passes without improvement: 3
09/16 10:32:55 AM: edges-srl-ontonotes_loss: training: 0.011846 validation: 0.009972
09/16 10:32:55 AM: macro_avg: validation: 0.883815
09/16 10:32:55 AM: micro_avg: validation: 0.000000
09/16 10:32:55 AM: edges-srl-ontonotes_mcc: training: 0.858581 validation: 0.882656
09/16 10:32:55 AM: edges-srl-ontonotes_acc: training: 0.802648 validation: 0.843892
09/16 10:32:55 AM: edges-srl-ontonotes_precision: training: 0.892988 validation: 0.916082
09/16 10:32:55 AM: edges-srl-ontonotes_recall: training: 0.829459 validation: 0.853745
09/16 10:32:55 AM: edges-srl-ontonotes_f1: training: 0.860052 validation: 0.883815
09/16 10:32:55 AM: Global learning rate: 1.5625e-06
09/16 10:32:55 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 10:32:55 AM: Update 52007: task edges-srl-ontonotes, batch 7 (52007): mcc: 0.8410, acc: 0.7759, precision: 0.8889, recall: 0.8000, f1: 0.8421, edges-srl-ontonotes_loss: 0.0130
09/16 10:33:05 AM: Update 52143: task edges-srl-ontonotes, batch 143 (52143): mcc: 0.8500, acc: 0.7917, precision: 0.8865, recall: 0.8193, f1: 0.8515, edges-srl-ontonotes_loss: 0.0123
09/16 10:33:15 AM: Update 52281: task edges-srl-ontonotes, batch 281 (52281): mcc: 0.8503, acc: 0.7924, precision: 0.8871, recall: 0.8193, f1: 0.8518, edges-srl-ontonotes_loss: 0.0123
09/16 10:33:25 AM: Update 52403: task edges-srl-ontonotes, batch 403 (52403): mcc: 0.8426, acc: 0.7828, precision: 0.8801, recall: 0.8111, f1: 0.8442, edges-srl-ontonotes_loss: 0.0128
09/16 10:33:35 AM: Update 52525: task edges-srl-ontonotes, batch 525 (52525): mcc: 0.8398, acc: 0.7790, precision: 0.8788, recall: 0.8070, f1: 0.8414, edges-srl-ontonotes_loss: 0.0131
09/16 10:33:45 AM: Update 52611: task edges-srl-ontonotes, batch 611 (52611): mcc: 0.8395, acc: 0.7785, precision: 0.8790, recall: 0.8063, f1: 0.8411, edges-srl-ontonotes_loss: 0.0131
09/16 10:33:55 AM: Update 52747: task edges-srl-ontonotes, batch 747 (52747): mcc: 0.8379, acc: 0.7766, precision: 0.8776, recall: 0.8044, f1: 0.8394, edges-srl-ontonotes_loss: 0.0132
09/16 10:34:05 AM: Update 52880: task edges-srl-ontonotes, batch 880 (52880): mcc: 0.8369, acc: 0.7751, precision: 0.8772, recall: 0.8028, f1: 0.8384, edges-srl-ontonotes_loss: 0.0134
09/16 10:34:15 AM: Update 52999: task edges-srl-ontonotes, batch 999 (52999): mcc: 0.8384, acc: 0.7773, precision: 0.8782, recall: 0.8049, f1: 0.8400, edges-srl-ontonotes_loss: 0.0132
09/16 10:34:15 AM: ***** Step 53000 / Validation 53 *****
09/16 10:34:15 AM: edges-srl-ontonotes: trained on 1000 batches, 0.138 epochs
09/16 10:34:15 AM: Validating...
09/16 10:34:25 AM: Evaluate: task edges-srl-ontonotes, batch 133 (157): mcc: 0.8862, acc: 0.8477, precision: 0.9171, recall: 0.8596, f1: 0.8874, edges-srl-ontonotes_loss: 0.0096
09/16 10:34:27 AM: Updating LR scheduler:
09/16 10:34:27 AM: 	Best result seen so far for macro_avg: 0.884
09/16 10:34:27 AM: 	# validation passes without improvement: 0
09/16 10:34:27 AM: Minimum LR reached. Stopping training.
09/16 10:34:27 AM: edges-srl-ontonotes_loss: training: 0.013198 validation: 0.009966
09/16 10:34:27 AM: macro_avg: validation: 0.883943
09/16 10:34:27 AM: micro_avg: validation: 0.000000
09/16 10:34:27 AM: edges-srl-ontonotes_mcc: training: 0.838467 validation: 0.882759
09/16 10:34:27 AM: edges-srl-ontonotes_acc: training: 0.777346 validation: 0.843507
09/16 10:34:27 AM: edges-srl-ontonotes_precision: training: 0.878240 validation: 0.915471
09/16 10:34:27 AM: edges-srl-ontonotes_recall: training: 0.804952 validation: 0.854515
09/16 10:34:27 AM: edges-srl-ontonotes_f1: training: 0.840001 validation: 0.883943
09/16 10:34:27 AM: Global learning rate: 7.8125e-07
09/16 10:34:27 AM: Saving checkpoints to: ./experiments/srl-ontonotes-sts-cat/run
09/16 10:34:27 AM: Stopped training after 53 validation checks
09/16 10:34:27 AM: Trained edges-srl-ontonotes for 53000 batches or 7.327 epochs
09/16 10:34:27 AM: ***** VALIDATION RESULTS *****
09/16 10:34:27 AM: edges-srl-ontonotes_f1 (for best val pass 46): edges-srl-ontonotes_loss: 0.00998, macro_avg: 0.88418, micro_avg: 0.00000, edges-srl-ontonotes_mcc: 0.88300, edges-srl-ontonotes_acc: 0.84458, edges-srl-ontonotes_precision: 0.91572, edges-srl-ontonotes_recall: 0.85475, edges-srl-ontonotes_f1: 0.88418
09/16 10:34:27 AM: micro_avg (for best val pass 1): edges-srl-ontonotes_loss: 0.02338, macro_avg: 0.72932, micro_avg: 0.00000, edges-srl-ontonotes_mcc: 0.73339, edges-srl-ontonotes_acc: 0.62135, edges-srl-ontonotes_precision: 0.85009, edges-srl-ontonotes_recall: 0.63860, edges-srl-ontonotes_f1: 0.72932
09/16 10:34:27 AM: macro_avg (for best val pass 46): edges-srl-ontonotes_loss: 0.00998, macro_avg: 0.88418, micro_avg: 0.00000, edges-srl-ontonotes_mcc: 0.88300, edges-srl-ontonotes_acc: 0.84458, edges-srl-ontonotes_precision: 0.91572, edges-srl-ontonotes_recall: 0.85475, edges-srl-ontonotes_f1: 0.88418
09/16 10:34:27 AM: Evaluating...
09/16 10:34:27 AM: Loaded model state from ./experiments/srl-ontonotes-sts-cat/run/edges-srl-ontonotes/model_state_target_train_val_46.best.th
09/16 10:34:27 AM: Evaluating on: edges-srl-ontonotes, split: val
09/16 10:34:57 AM: 	Task edges-srl-ontonotes: batch 356
09/16 10:35:27 AM: 	Task edges-srl-ontonotes: batch 687
09/16 10:35:57 AM: Task 'edges-srl-ontonotes': sorting predictions by 'idx'
09/16 10:35:57 AM: Finished evaluating on: edges-srl-ontonotes
09/16 10:35:58 AM: Task 'edges-srl-ontonotes': joining predictions with input split 'val'
09/16 10:36:02 AM: Task 'edges-srl-ontonotes': Wrote predictions to ./experiments/srl-ontonotes-sts-cat/run
09/16 10:36:02 AM: Wrote all preds for split 'val' to ./experiments/srl-ontonotes-sts-cat/run
09/16 10:36:02 AM: Evaluating on: edges-srl-ontonotes, split: test
09/16 10:36:32 AM: 	Task edges-srl-ontonotes: batch 345
09/16 10:37:02 AM: 	Task edges-srl-ontonotes: batch 699
09/16 10:37:06 AM: Task 'edges-srl-ontonotes': sorting predictions by 'idx'
09/16 10:37:06 AM: Finished evaluating on: edges-srl-ontonotes
09/16 10:37:07 AM: Task 'edges-srl-ontonotes': joining predictions with input split 'test'
09/16 10:37:10 AM: Task 'edges-srl-ontonotes': Wrote predictions to ./experiments/srl-ontonotes-sts-cat/run
09/16 10:37:10 AM: Wrote all preds for split 'test' to ./experiments/srl-ontonotes-sts-cat/run
09/16 10:37:10 AM: Writing results for split 'val' to ./experiments/srl-ontonotes-sts-cat/results.tsv
09/16 10:37:10 AM: micro_avg: 0.000, macro_avg: 0.885, edges-srl-ontonotes_mcc: 0.883, edges-srl-ontonotes_acc: 0.844, edges-srl-ontonotes_precision: 0.916, edges-srl-ontonotes_recall: 0.855, edges-srl-ontonotes_f1: 0.885
09/16 10:37:11 AM: Done!
09/16 10:37:11 AM: Fatal error in main():
Traceback (most recent call last):
  File "main.py", line 16, in <module>
    main(sys.argv[1:])
  File "/srv/home/ericwallace/jiant/jiant/__main__.py", line 610, in main
    exit("Done exited")
  File "/home/ericwallace/miniconda3/envs/jiant/lib/python3.6/_sitebuiltins.py", line 26, in __call__
    raise SystemExit(code)
SystemExit: Done exited
