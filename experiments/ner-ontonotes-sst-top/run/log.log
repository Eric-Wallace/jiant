09/16 05:59:29 AM: Git branch: master
09/16 05:59:29 AM: Git SHA: 03401462a9f5f9b569ed41ceca48ecd81700406f
09/16 05:59:30 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/ner-ontonotes-sst-top/",
  "exp_name": "experiments/ner-ontonotes-sst-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/ner-ontonotes-sst-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/sst",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/ner-ontonotes-sst-top__run",
  "run_dir": "./experiments/ner-ontonotes-sst-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-ner-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 05:59:30 AM: Saved config to ./experiments/ner-ontonotes-sst-top/run/params.conf
09/16 05:59:30 AM: Using random seed 1234
09/16 05:59:53 AM: Git branch: master
09/16 05:59:53 AM: Git SHA: 03401462a9f5f9b569ed41ceca48ecd81700406f
09/16 05:59:54 AM: Parsed args: 
{
  "allow_missing_task_map": 1,
  "allow_untrained_encoder_parameters": 1,
  "do_pretrain": 0,
  "exp_dir": "./experiments/ner-ontonotes-sst-top/",
  "exp_name": "experiments/ner-ontonotes-sst-top",
  "input_module": "bert-base-uncased",
  "local_log_path": "./experiments/ner-ontonotes-sst-top/run/log.log",
  "lr_patience": 3,
  "max_seq_len": 512,
  "output_mode": "top",
  "patience": 9,
  "pretrain_tasks": "",
  "pretrained_dir": "models/sst",
  "pytorch_transformers_output_mode": "top",
  "remote_log_name": "experiments/ner-ontonotes-sst-top__run",
  "run_dir": "./experiments/ner-ontonotes-sst-top/run",
  "run_name": "run",
  "sent_enc": "none",
  "sep_embs_for_skip": 1,
  "target_tasks": "edges-ner-ontonotes",
  "tokenizer": "bert-base-uncased",
  "write_preds": "val,test"
}
09/16 05:59:54 AM: Saved config to ./experiments/ner-ontonotes-sst-top/run/params.conf
09/16 05:59:54 AM: Using random seed 1234
09/16 06:00:33 AM: Using GPU 0
09/16 06:00:33 AM: Loading tasks...
09/16 06:00:33 AM: Writing pre-preprocessed tasks to ./experiments/ner-ontonotes-sst-top/
09/16 06:00:33 AM: 	Creating task edges-ner-ontonotes from scratch.
09/16 06:00:33 AM: Using GPU 0
09/16 06:00:33 AM: Loading tasks...
09/16 06:00:33 AM: Writing pre-preprocessed tasks to ./experiments/ner-ontonotes-sst-top/
09/16 06:00:33 AM: 	Creating task edges-ner-ontonotes from scratch.
09/16 06:00:35 AM: Read=49706, Skip=66106, Total=115812 from ./probing_data/edges/ontonotes/ner/train.json.retokenized.bert-base-uncased
09/16 06:00:36 AM: Read=49706, Skip=66106, Total=115812 from ./probing_data/edges/ontonotes/ner/train.json.retokenized.bert-base-uncased
09/16 06:00:36 AM: Read=7610, Skip=8070, Total=15680 from ./probing_data/edges/ontonotes/ner/development.json.retokenized.bert-base-uncased
09/16 06:00:36 AM: Read=5099, Skip=7118, Total=12217 from ./probing_data/edges/ontonotes/ner/test.json.retokenized.bert-base-uncased
09/16 06:00:36 AM: Read=7610, Skip=8070, Total=15680 from ./probing_data/edges/ontonotes/ner/development.json.retokenized.bert-base-uncased
09/16 06:00:36 AM: Read=5099, Skip=7118, Total=12217 from ./probing_data/edges/ontonotes/ner/test.json.retokenized.bert-base-uncased
09/16 06:00:38 AM: 	Task 'edges-ner-ontonotes': |train|=49706 |val|=7610 |test|=5099
09/16 06:00:38 AM: 	Finished loading tasks: edges-ner-ontonotes.
09/16 06:00:38 AM: 	Building vocab from scratch.
09/16 06:00:38 AM: 	Counting units for task edges-ner-ontonotes.
09/16 06:00:39 AM: 	Task 'edges-ner-ontonotes': |train|=49706 |val|=7610 |test|=5099
09/16 06:00:39 AM: 	Finished loading tasks: edges-ner-ontonotes.
09/16 06:00:39 AM: 	Building vocab from scratch.
09/16 06:00:39 AM: 	Counting units for task edges-ner-ontonotes.
09/16 06:00:41 AM: 	Task 'edges-ner-ontonotes': adding vocab namespace 'edges-ner-ontonotes_labels'
09/16 06:00:42 AM: 	Task 'edges-ner-ontonotes': adding vocab namespace 'edges-ner-ontonotes_labels'
09/16 06:00:42 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:42 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 06:00:43 AM: 	Saved vocab to ./experiments/ner-ontonotes-sst-top/vocab
09/16 06:00:43 AM: Loading token dictionary from ./experiments/ner-ontonotes-sst-top/vocab.
09/16 06:00:43 AM: 	Loaded vocab from ./experiments/ner-ontonotes-sst-top/vocab
09/16 06:00:43 AM: 	Vocab namespace edges-ner-ontonotes_labels: size 18
09/16 06:00:43 AM: 	Vocab namespace tokens: size 22840
09/16 06:00:43 AM: 	Vocab namespace bert_uncased: size 30524
09/16 06:00:43 AM: 	Vocab namespace chars: size 77
09/16 06:00:43 AM: 	Finished building vocab.
09/16 06:00:43 AM: 	Task edges-ner-ontonotes (train): Indexing from scratch.
09/16 06:00:43 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ericwallace/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:43 AM: Added pytorch_transformers vocab (bert-base-uncased): 30522 tokens
09/16 06:00:43 AM: vocabulary serialization directory ./experiments/ner-ontonotes-sst-top/vocab is not empty
09/16 06:00:43 AM: 	Saved vocab to ./experiments/ner-ontonotes-sst-top/vocab
09/16 06:00:43 AM: Loading token dictionary from ./experiments/ner-ontonotes-sst-top/vocab.
09/16 06:00:43 AM: 	Loaded vocab from ./experiments/ner-ontonotes-sst-top/vocab
09/16 06:00:43 AM: 	Vocab namespace edges-ner-ontonotes_labels: size 18
09/16 06:00:43 AM: 	Vocab namespace tokens: size 22840
09/16 06:00:43 AM: 	Vocab namespace bert_uncased: size 30524
09/16 06:00:43 AM: 	Vocab namespace chars: size 77
09/16 06:00:43 AM: 	Finished building vocab.
09/16 06:00:43 AM: 	Task 'edges-ner-ontonotes', split 'train': Found preprocessed copy in ./experiments/ner-ontonotes-sst-top/preproc/edges-ner-ontonotes__train_data
09/16 06:00:43 AM: 	Task edges-ner-ontonotes (val): Indexing from scratch.
09/16 06:00:45 AM: 	Task edges-ner-ontonotes (val): Saved 7610 instances to ./experiments/ner-ontonotes-sst-top/preproc/edges-ner-ontonotes__val_data
09/16 06:00:45 AM: 	Task edges-ner-ontonotes (test): Indexing from scratch.
09/16 06:00:47 AM: 	Task edges-ner-ontonotes (test): Saved 5099 instances to ./experiments/ner-ontonotes-sst-top/preproc/edges-ner-ontonotes__test_data
09/16 06:00:47 AM: 	Finished indexing tasks
09/16 06:00:47 AM: 	Creating trimmed target-only version of edges-ner-ontonotes train.
09/16 06:00:47 AM: 	  Training on 
09/16 06:00:47 AM: 	  Evaluating on edges-ner-ontonotes
09/16 06:00:47 AM: 	Finished loading tasks in 13.640s
09/16 06:00:47 AM: 	 Tasks: ['edges-ner-ontonotes']
09/16 06:00:47 AM: Building model...
09/16 06:00:47 AM: Using BERT model (bert-base-uncased).
09/16 06:00:47 AM: LOADING A FUNETUNED MODEL from: 
09/16 06:00:47 AM: models/sst
09/16 06:00:47 AM: loading configuration file models/sst/config.json
09/16 06:00:47 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "sst-2",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 06:00:47 AM: loading weights file models/sst/pytorch_model.bin
09/16 06:00:54 AM: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt not found in cache or force_download set to True, downloading to /tmp/tmpq0z_c6ye
09/16 06:00:56 AM: copying /tmp/tmpq0z_c6ye to cache at ./experiments/ner-ontonotes-sst-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:56 AM: creating metadata file for ./experiments/ner-ontonotes-sst-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:56 AM: removing temp file /tmp/tmpq0z_c6ye
09/16 06:00:56 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/ner-ontonotes-sst-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:00:56 AM: Initializing parameters
09/16 06:00:56 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 06:00:56 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 06:00:56 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 06:00:56 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 06:00:56 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 06:00:56 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 06:00:56 AM: 	Task 'edges-ner-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-ner-ontonotes"
}
09/16 06:00:58 AM: 	Task edges-ner-ontonotes (train): Saved 49706 instances to ./experiments/ner-ontonotes-sst-top/preproc/edges-ner-ontonotes__train_data
09/16 06:00:58 AM: 	Task 'edges-ner-ontonotes', split 'val': Found preprocessed copy in ./experiments/ner-ontonotes-sst-top/preproc/edges-ner-ontonotes__val_data
09/16 06:00:58 AM: 	Task 'edges-ner-ontonotes', split 'test': Found preprocessed copy in ./experiments/ner-ontonotes-sst-top/preproc/edges-ner-ontonotes__test_data
09/16 06:00:58 AM: 	Finished indexing tasks
09/16 06:00:58 AM: 	Creating trimmed target-only version of edges-ner-ontonotes train.
09/16 06:00:58 AM: 	  Training on 
09/16 06:00:58 AM: 	  Evaluating on edges-ner-ontonotes
09/16 06:00:58 AM: 	Finished loading tasks in 24.466s
09/16 06:00:58 AM: 	 Tasks: ['edges-ner-ontonotes']
09/16 06:00:58 AM: Building model...
09/16 06:00:58 AM: Using BERT model (bert-base-uncased).
09/16 06:00:58 AM: LOADING A FUNETUNED MODEL from: 
09/16 06:00:58 AM: models/sst
09/16 06:00:58 AM: loading configuration file models/sst/config.json
09/16 06:00:58 AM: Model config {
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": "sst-2",
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": true,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

09/16 06:00:58 AM: loading weights file models/sst/pytorch_model.bin
09/16 06:01:02 AM: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at ./experiments/ner-ontonotes-sst-top/pytorch_transformers_cache/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084
09/16 06:01:02 AM: Initializing parameters
09/16 06:01:02 AM: Done initializing parameters; the following parameters are using their default initialization from their code
09/16 06:01:02 AM:    _text_field_embedder.model.embeddings.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.embeddings.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.embeddings.position_embeddings.weight
09/16 06:01:02 AM:    _text_field_embedder.model.embeddings.token_type_embeddings.weight
09/16 06:01:02 AM:    _text_field_embedder.model.embeddings.word_embeddings.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.0.attention.output.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.key.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.query.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.0.attention.self.value.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.0.intermediate.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.0.output.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.1.attention.output.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.key.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.query.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.1.attention.self.value.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.1.intermediate.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.1.output.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.10.attention.output.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.key.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.query.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.10.attention.self.value.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.10.intermediate.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.10.output.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.11.attention.output.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.key.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.query.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.11.attention.self.value.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.11.intermediate.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.11.output.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.2.attention.output.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.key.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.query.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.2.attention.self.value.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.2.intermediate.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.2.output.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.3.attention.output.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.key.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.query.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.3.attention.self.value.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.3.intermediate.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.3.output.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.4.attention.output.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.key.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.query.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.4.attention.self.value.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.4.intermediate.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.4.output.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.5.attention.output.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.key.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.query.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.5.attention.self.value.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.5.intermediate.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.5.output.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.6.attention.output.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.key.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.query.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.6.attention.self.value.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.6.intermediate.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.6.output.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.7.attention.output.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.key.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.query.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.7.attention.self.value.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.7.intermediate.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.7.output.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.8.attention.output.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.key.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.query.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.8.attention.self.value.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.8.intermediate.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.8.output.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.9.attention.output.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.key.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.query.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.9.attention.self.value.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.9.intermediate.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.encoder.layer.9.output.dense.weight
09/16 06:01:02 AM:    _text_field_embedder.model.pooler.dense.bias
09/16 06:01:02 AM:    _text_field_embedder.model.pooler.dense.weight
09/16 06:01:02 AM: 	Task 'edges-ner-ontonotes' params: {
  "cls_type": "mlp",
  "d_hid": 256,
  "pool_type": "first",
  "d_proj": 512,
  "shared_pair_attn": 0,
  "attn": 0,
  "d_hid_attn": 512,
  "dropout": 0.3,
  "cls_loss_fn": "sigmoid",
  "cls_span_pooling": "attn",
  "edgeprobe_cnn_context": 0,
  "edgeprobe_symmetric": 0,
  "use_classifier": "edges-ner-ontonotes"
}
09/16 06:01:36 AM: Model specification:
09/16 06:01:36 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-ner-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=18, bias=True)
    )
  )
)
09/16 06:01:36 AM: Model parameters:
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: Model specification:
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: MultiTaskModel(
  (sent_encoder): SentenceEncoder(
    (_text_field_embedder): BertEmbedderModule(
      (model): BertModel(
        (embeddings): BertEmbeddings(
          (word_embeddings): Embedding(30522, 768, padding_idx=0)
          (position_embeddings): Embedding(512, 768)
          (token_type_embeddings): Embedding(2, 768)
          (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
          (dropout): Dropout(p=0.1)
        )
        (encoder): BertEncoder(
          (layer): ModuleList(
            (0): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (1): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (2): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (3): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (4): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (5): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (6): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (7): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (8): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (9): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (10): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (11): BertLayer(
              (attention): BertAttention(
                (self): BertSelfAttention(
                  (query): Linear(in_features=768, out_features=768, bias=True)
                  (key): Linear(in_features=768, out_features=768, bias=True)
                  (value): Linear(in_features=768, out_features=768, bias=True)
                  (dropout): Dropout(p=0.1)
                )
                (output): BertSelfOutput(
                  (dense): Linear(in_features=768, out_features=768, bias=True)
                  (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                  (dropout): Dropout(p=0.1)
                )
              )
              (intermediate): BertIntermediate(
                (dense): Linear(in_features=768, out_features=3072, bias=True)
              )
              (output): BertOutput(
                (dense): Linear(in_features=3072, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
          )
        )
        (pooler): BertPooler(
          (dense): Linear(in_features=768, out_features=768, bias=True)
          (activation): Tanh()
        )
      )
    )
    (_highway_layer): TimeDistributed(
      (_module): Highway(
        (_layers): ModuleList()
      )
    )
    (_phrase_layer): NullPhraseLayer()
    (_dropout): Dropout(p=0.2)
  )
  (edges-ner-ontonotes_mdl): EdgeClassifierModule(
    (proj1): Conv1d(768, 256, kernel_size=(1,), stride=(1,))
    (span_extractor1): EndpointSpanExtractor()
    (classifier): Classifier(
      (classifier): Linear(in_features=512, out_features=18, bias=True)
    )
  )
)
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: Model parameters:
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.word_embeddings.weight: Non-trainable parameter, count 23440896 with torch.Size([30522, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.position_embeddings.weight: Non-trainable parameter, count 393216 with torch.Size([512, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.token_type_embeddings.weight: Non-trainable parameter, count 1536 with torch.Size([2, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.embeddings.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	edges-ner-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 06:01:36 AM: 	edges-ner-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 9216 with torch.Size([18, 512])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 18 with torch.Size([18])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: Total number of parameters: 109688338 (1.09688e+08)
09/16 06:01:36 AM: Number of trainable parameters: 206098 (206098)
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: Finished building model in 49.009s
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-ner-ontonotes 

09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.0.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.1.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.2.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.3.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.4.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.5.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.6.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.7.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.8.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.9.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.10.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.query.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.key.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.self.value.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.attention.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([3072, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.intermediate.dense.bias: Non-trainable parameter, count 3072 with torch.Size([3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.weight: Non-trainable parameter, count 2359296 with torch.Size([768, 3072])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.weight: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.encoder.layer.11.output.LayerNorm.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.weight: Non-trainable parameter, count 589824 with torch.Size([768, 768])
09/16 06:01:36 AM: 	sent_encoder._text_field_embedder.model.pooler.dense.bias: Non-trainable parameter, count 768 with torch.Size([768])
09/16 06:01:36 AM: 	edges-ner-ontonotes_mdl.proj1.weight: Trainable parameter, count 196608 with torch.Size([256, 768, 1])
09/16 06:01:36 AM: 	edges-ner-ontonotes_mdl.proj1.bias: Trainable parameter, count 256 with torch.Size([256])
09/16 06:01:36 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.weight: Trainable parameter, count 9216 with torch.Size([18, 512])
09/16 06:01:36 AM: 	edges-ner-ontonotes_mdl.classifier.classifier.bias: Trainable parameter, count 18 with torch.Size([18])
09/16 06:01:36 AM: Total number of parameters: 109688338 (1.09688e+08)
09/16 06:01:36 AM: Number of trainable parameters: 206098 (206098)
09/16 06:01:36 AM: Finished building model in 38.283s
09/16 06:01:36 AM: Will run the following steps for this experiment:
Re-training model for individual target tasks 
Evaluating model on tasks: edges-ner-ontonotes 

09/16 06:01:42 AM: patience = 9
09/16 06:01:42 AM: val_interval = 1000
09/16 06:01:42 AM: max_vals = 250
09/16 06:01:42 AM: cuda_device = 0
09/16 06:01:42 AM: grad_norm = 5.0
09/16 06:01:42 AM: grad_clipping = None
09/16 06:01:42 AM: lr_decay = 0.99
09/16 06:01:42 AM: min_lr = 1e-06
09/16 06:01:42 AM: keep_all_checkpoints = 0
09/16 06:01:42 AM: val_data_limit = 5000
09/16 06:01:42 AM: max_epochs = -1
09/16 06:01:42 AM: dec_val_scale = 250
09/16 06:01:42 AM: training_data_fraction = 1
09/16 06:01:42 AM: type = adam
09/16 06:01:42 AM: parameter_groups = None
09/16 06:01:42 AM: Number of trainable parameters: 206098
09/16 06:01:42 AM: infer_type_and_cast = True
09/16 06:01:42 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:42 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:42 AM: lr = 0.0001
09/16 06:01:42 AM: amsgrad = True
09/16 06:01:42 AM: type = reduce_on_plateau
09/16 06:01:42 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:42 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:42 AM: mode = max
09/16 06:01:42 AM: factor = 0.5
09/16 06:01:42 AM: patience = 3
09/16 06:01:42 AM: threshold = 0.0001
09/16 06:01:42 AM: threshold_mode = abs
09/16 06:01:42 AM: verbose = True
09/16 06:01:42 AM: type = adam
09/16 06:01:42 AM: parameter_groups = None
09/16 06:01:42 AM: Number of trainable parameters: 206098
09/16 06:01:42 AM: infer_type_and_cast = True
09/16 06:01:42 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:42 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:42 AM: lr = 0.0001
09/16 06:01:42 AM: amsgrad = True
09/16 06:01:42 AM: type = reduce_on_plateau
09/16 06:01:42 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:42 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:42 AM: mode = max
09/16 06:01:42 AM: factor = 0.5
09/16 06:01:42 AM: patience = 3
09/16 06:01:42 AM: threshold = 0.0001
09/16 06:01:42 AM: threshold_mode = abs
09/16 06:01:42 AM: verbose = True
09/16 06:01:42 AM: Starting training without restoring from a checkpoint.
09/16 06:01:42 AM: Training examples per task, before any subsampling: {'edges-ner-ontonotes': 49706}
09/16 06:01:42 AM: Beginning training with stopping criteria based on metric: edges-ner-ontonotes_f1
09/16 06:01:42 AM: patience = 9
09/16 06:01:42 AM: val_interval = 1000
09/16 06:01:42 AM: max_vals = 250
09/16 06:01:42 AM: cuda_device = 0
09/16 06:01:42 AM: grad_norm = 5.0
09/16 06:01:42 AM: grad_clipping = None
09/16 06:01:42 AM: lr_decay = 0.99
09/16 06:01:42 AM: min_lr = 1e-06
09/16 06:01:42 AM: keep_all_checkpoints = 0
09/16 06:01:42 AM: val_data_limit = 5000
09/16 06:01:42 AM: max_epochs = -1
09/16 06:01:42 AM: dec_val_scale = 250
09/16 06:01:42 AM: training_data_fraction = 1
09/16 06:01:42 AM: type = adam
09/16 06:01:42 AM: parameter_groups = None
09/16 06:01:42 AM: Number of trainable parameters: 206098
09/16 06:01:42 AM: infer_type_and_cast = True
09/16 06:01:42 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:42 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:42 AM: lr = 0.0001
09/16 06:01:42 AM: amsgrad = True
09/16 06:01:42 AM: type = reduce_on_plateau
09/16 06:01:42 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:42 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:42 AM: mode = max
09/16 06:01:42 AM: factor = 0.5
09/16 06:01:42 AM: patience = 3
09/16 06:01:42 AM: threshold = 0.0001
09/16 06:01:42 AM: threshold_mode = abs
09/16 06:01:42 AM: verbose = True
09/16 06:01:42 AM: type = adam
09/16 06:01:42 AM: parameter_groups = None
09/16 06:01:42 AM: Number of trainable parameters: 206098
09/16 06:01:42 AM: infer_type_and_cast = True
09/16 06:01:42 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:42 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:42 AM: lr = 0.0001
09/16 06:01:42 AM: amsgrad = True
09/16 06:01:42 AM: type = reduce_on_plateau
09/16 06:01:42 AM: Converting Params object to dict; logging of default values will not occur when dictionary parameters are used subsequently.
09/16 06:01:42 AM: CURRENTLY DEFINED PARAMETERS: 
09/16 06:01:42 AM: mode = max
09/16 06:01:42 AM: factor = 0.5
09/16 06:01:42 AM: patience = 3
09/16 06:01:42 AM: threshold = 0.0001
09/16 06:01:42 AM: threshold_mode = abs
09/16 06:01:42 AM: verbose = True
09/16 06:01:42 AM: Starting training without restoring from a checkpoint.
09/16 06:01:42 AM: Training examples per task, before any subsampling: {'edges-ner-ontonotes': 49706}
09/16 06:01:42 AM: Beginning training with stopping criteria based on metric: edges-ner-ontonotes_f1
09/16 06:01:57 AM: Update 27: task edges-ner-ontonotes, batch 27 (27): mcc: 0.0464, acc: 0.0190, precision: 0.0817, recall: 0.2085, f1: 0.1174, edges-ner-ontonotes_loss: 0.5319
09/16 06:01:57 AM: Update 27: task edges-ner-ontonotes, batch 27 (27): mcc: 0.0464, acc: 0.0190, precision: 0.0817, recall: 0.2085, f1: 0.1174, edges-ner-ontonotes_loss: 0.5319
09/16 06:02:07 AM: Update 118: task edges-ner-ontonotes, batch 118 (118): mcc: 0.0255, acc: 0.0071, precision: 0.0851, recall: 0.0578, f1: 0.0688, edges-ner-ontonotes_loss: 0.2867
09/16 06:02:07 AM: Update 119: task edges-ner-ontonotes, batch 119 (119): mcc: 0.0254, acc: 0.0070, precision: 0.0851, recall: 0.0570, f1: 0.0683, edges-ner-ontonotes_loss: 0.2857
09/16 06:02:17 AM: Update 204: task edges-ner-ontonotes, batch 204 (204): mcc: 0.0370, acc: 0.0159, precision: 0.1112, recall: 0.0453, f1: 0.0644, edges-ner-ontonotes_loss: 0.2338
09/16 06:02:17 AM: Update 207: task edges-ner-ontonotes, batch 207 (207): mcc: 0.0379, acc: 0.0164, precision: 0.1129, recall: 0.0455, f1: 0.0649, edges-ner-ontonotes_loss: 0.2325
09/16 06:02:27 AM: Update 298: task edges-ner-ontonotes, batch 298 (298): mcc: 0.0804, acc: 0.0403, precision: 0.1940, recall: 0.0607, f1: 0.0924, edges-ner-ontonotes_loss: 0.2056
09/16 06:02:27 AM: Update 300: task edges-ner-ontonotes, batch 300 (300): mcc: 0.0817, acc: 0.0410, precision: 0.1964, recall: 0.0613, f1: 0.0935, edges-ner-ontonotes_loss: 0.2051
09/16 06:02:37 AM: Update 345: task edges-ner-ontonotes, batch 345 (345): mcc: 0.1204, acc: 0.0614, precision: 0.2708, recall: 0.0787, f1: 0.1220, edges-ner-ontonotes_loss: 0.1958
09/16 06:02:37 AM: Update 345: task edges-ner-ontonotes, batch 345 (345): mcc: 0.1204, acc: 0.0614, precision: 0.2708, recall: 0.0787, f1: 0.1220, edges-ner-ontonotes_loss: 0.1958
09/16 06:02:47 AM: Update 422: task edges-ner-ontonotes, batch 422 (422): mcc: 0.1959, acc: 0.1035, precision: 0.4058, recall: 0.1179, f1: 0.1828, edges-ner-ontonotes_loss: 0.1823
09/16 06:02:47 AM: Update 420: task edges-ner-ontonotes, batch 420 (420): mcc: 0.1930, acc: 0.1017, precision: 0.4012, recall: 0.1162, f1: 0.1802, edges-ner-ontonotes_loss: 0.1826
09/16 06:02:57 AM: Update 498: task edges-ner-ontonotes, batch 498 (498): mcc: 0.2687, acc: 0.1478, precision: 0.5204, recall: 0.1614, f1: 0.2464, edges-ner-ontonotes_loss: 0.1711
09/16 06:02:57 AM: Update 494: task edges-ner-ontonotes, batch 494 (494): mcc: 0.2645, acc: 0.1451, precision: 0.5144, recall: 0.1587, f1: 0.2425, edges-ner-ontonotes_loss: 0.1716
09/16 06:03:08 AM: Update 569: task edges-ner-ontonotes, batch 569 (569): mcc: 0.3259, acc: 0.1869, precision: 0.5983, recall: 0.2000, f1: 0.2997, edges-ner-ontonotes_loss: 0.1626
09/16 06:03:08 AM: Update 569: task edges-ner-ontonotes, batch 569 (569): mcc: 0.3259, acc: 0.1869, precision: 0.5983, recall: 0.2000, f1: 0.2997, edges-ner-ontonotes_loss: 0.1626
09/16 06:03:18 AM: Update 630: task edges-ner-ontonotes, batch 630 (630): mcc: 0.3668, acc: 0.2175, precision: 0.6476, recall: 0.2302, f1: 0.3396, edges-ner-ontonotes_loss: 0.1561
09/16 06:03:18 AM: Update 628: task edges-ner-ontonotes, batch 628 (628): mcc: 0.3660, acc: 0.2169, precision: 0.6464, recall: 0.2297, f1: 0.3389, edges-ner-ontonotes_loss: 0.1563
09/16 06:03:28 AM: Update 699: task edges-ner-ontonotes, batch 699 (699): mcc: 0.4087, acc: 0.2501, precision: 0.6943, recall: 0.2628, f1: 0.3813, edges-ner-ontonotes_loss: 0.1498
09/16 06:03:28 AM: Update 696: task edges-ner-ontonotes, batch 696 (696): mcc: 0.4066, acc: 0.2484, precision: 0.6920, recall: 0.2612, f1: 0.3792, edges-ner-ontonotes_loss: 0.1500
09/16 06:03:38 AM: Update 768: task edges-ner-ontonotes, batch 768 (768): mcc: 0.4422, acc: 0.2779, precision: 0.7281, recall: 0.2907, f1: 0.4155, edges-ner-ontonotes_loss: 0.1440
09/16 06:03:38 AM: Update 771: task edges-ner-ontonotes, batch 771 (771): mcc: 0.4430, acc: 0.2787, precision: 0.7289, recall: 0.2914, f1: 0.4164, edges-ner-ontonotes_loss: 0.1438
09/16 06:03:48 AM: Update 842: task edges-ner-ontonotes, batch 842 (842): mcc: 0.4740, acc: 0.3063, precision: 0.7553, recall: 0.3197, f1: 0.4492, edges-ner-ontonotes_loss: 0.1382
09/16 06:03:48 AM: Update 847: task edges-ner-ontonotes, batch 847 (847): mcc: 0.4759, acc: 0.3081, precision: 0.7569, recall: 0.3214, f1: 0.4512, edges-ner-ontonotes_loss: 0.1378
09/16 06:03:58 AM: Update 913: task edges-ner-ontonotes, batch 913 (913): mcc: 0.5024, acc: 0.3335, precision: 0.7762, recall: 0.3474, f1: 0.4800, edges-ner-ontonotes_loss: 0.1332
09/16 06:03:58 AM: Update 919: task edges-ner-ontonotes, batch 919 (919): mcc: 0.5045, acc: 0.3356, precision: 0.7778, recall: 0.3495, f1: 0.4823, edges-ner-ontonotes_loss: 0.1328
09/16 06:04:08 AM: Update 970: task edges-ner-ontonotes, batch 970 (970): mcc: 0.5212, acc: 0.3522, precision: 0.7891, recall: 0.3665, f1: 0.5005, edges-ner-ontonotes_loss: 0.1297
09/16 06:04:08 AM: Update 972: task edges-ner-ontonotes, batch 972 (972): mcc: 0.5220, acc: 0.3530, precision: 0.7897, recall: 0.3673, f1: 0.5014, edges-ner-ontonotes_loss: 0.1296
09/16 06:04:12 AM: ***** Step 1000 / Validation 1 *****
09/16 06:04:12 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:04:12 AM: Validating...
09/16 06:04:12 AM: ***** Step 1000 / Validation 1 *****
09/16 06:04:12 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:04:12 AM: Validating...
09/16 06:04:18 AM: Evaluate: task edges-ner-ontonotes, batch 31 (157): mcc: 0.6896, acc: 0.5556, precision: 0.8687, recall: 0.5686, f1: 0.6873, edges-ner-ontonotes_loss: 0.0978
09/16 06:04:18 AM: Evaluate: task edges-ner-ontonotes, batch 33 (157): mcc: 0.6939, acc: 0.5617, precision: 0.8665, recall: 0.5770, f1: 0.6927, edges-ner-ontonotes_loss: 0.0968
09/16 06:04:28 AM: Evaluate: task edges-ner-ontonotes, batch 74 (157): mcc: 0.7420, acc: 0.6174, precision: 0.8950, recall: 0.6345, f1: 0.7425, edges-ner-ontonotes_loss: 0.0850
09/16 06:04:28 AM: Evaluate: task edges-ner-ontonotes, batch 75 (157): mcc: 0.7444, acc: 0.6205, precision: 0.8958, recall: 0.6378, f1: 0.7451, edges-ner-ontonotes_loss: 0.0846
09/16 06:04:45 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.7655, acc: 0.6459, precision: 0.8995, recall: 0.6700, f1: 0.7680, edges-ner-ontonotes_loss: 0.0773
09/16 06:04:45 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.7655, acc: 0.6459, precision: 0.8995, recall: 0.6700, f1: 0.7680, edges-ner-ontonotes_loss: 0.0773
09/16 06:04:55 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:04:55 AM: Best result seen so far for micro.
09/16 06:04:55 AM: Best result seen so far for macro.
09/16 06:04:55 AM: Updating LR scheduler:
09/16 06:04:55 AM: 	Best result seen so far for macro_avg: 0.778
09/16 06:04:55 AM: 	# validation passes without improvement: 0
09/16 06:04:55 AM: edges-ner-ontonotes_loss: training: 0.127942 validation: 0.073441
09/16 06:04:55 AM: macro_avg: validation: 0.777898
09/16 06:04:55 AM: micro_avg: validation: 0.000000
09/16 06:04:55 AM: edges-ner-ontonotes_mcc: training: 0.531217 validation: 0.775351
09/16 06:04:55 AM: edges-ner-ontonotes_acc: training: 0.362535 validation: 0.659615
09/16 06:04:55 AM: edges-ner-ontonotes_precision: training: 0.795846 validation: 0.905875
09/16 06:04:55 AM: edges-ner-ontonotes_recall: training: 0.376849 validation: 0.681605
09/16 06:04:55 AM: edges-ner-ontonotes_f1: training: 0.511495 validation: 0.777898
09/16 06:04:55 AM: Global learning rate: 0.0001
09/16 06:04:55 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:04:55 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:04:55 AM: Best result seen so far for micro.
09/16 06:04:55 AM: Best result seen so far for macro.
09/16 06:04:55 AM: Updating LR scheduler:
09/16 06:04:55 AM: 	Best result seen so far for macro_avg: 0.778
09/16 06:04:55 AM: 	# validation passes without improvement: 0
09/16 06:04:55 AM: edges-ner-ontonotes_loss: training: 0.127942 validation: 0.073441
09/16 06:04:55 AM: macro_avg: validation: 0.777898
09/16 06:04:55 AM: micro_avg: validation: 0.000000
09/16 06:04:55 AM: edges-ner-ontonotes_mcc: training: 0.531217 validation: 0.775351
09/16 06:04:55 AM: edges-ner-ontonotes_acc: training: 0.362535 validation: 0.659615
09/16 06:04:55 AM: edges-ner-ontonotes_precision: training: 0.795846 validation: 0.905875
09/16 06:04:55 AM: edges-ner-ontonotes_recall: training: 0.376849 validation: 0.681605
09/16 06:04:55 AM: edges-ner-ontonotes_f1: training: 0.511495 validation: 0.777898
09/16 06:04:55 AM: Global learning rate: 0.0001
09/16 06:04:55 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:04:55 AM: Update 1002: task edges-ner-ontonotes, batch 2 (1002): mcc: 0.7993, acc: 0.6954, precision: 0.9267, recall: 0.7056, f1: 0.8012, edges-ner-ontonotes_loss: 0.0669
09/16 06:04:56 AM: Update 1001: task edges-ner-ontonotes, batch 1 (1001): mcc: 0.8399, acc: 0.7451, precision: 0.9398, recall: 0.7647, f1: 0.8432, edges-ner-ontonotes_loss: 0.0616
09/16 06:05:05 AM: Update 1077: task edges-ner-ontonotes, batch 77 (1077): mcc: 0.7706, acc: 0.6531, precision: 0.9053, recall: 0.6741, f1: 0.7727, edges-ner-ontonotes_loss: 0.0688
09/16 06:05:06 AM: Update 1072: task edges-ner-ontonotes, batch 72 (1072): mcc: 0.7689, acc: 0.6500, precision: 0.9047, recall: 0.6717, f1: 0.7710, edges-ner-ontonotes_loss: 0.0692
09/16 06:05:15 AM: Update 1149: task edges-ner-ontonotes, batch 149 (1149): mcc: 0.7761, acc: 0.6597, precision: 0.9087, recall: 0.6807, f1: 0.7783, edges-ner-ontonotes_loss: 0.0681
09/16 06:05:16 AM: Update 1143: task edges-ner-ontonotes, batch 143 (1143): mcc: 0.7747, acc: 0.6580, precision: 0.9077, recall: 0.6790, f1: 0.7769, edges-ner-ontonotes_loss: 0.0683
09/16 06:05:25 AM: Update 1228: task edges-ner-ontonotes, batch 228 (1228): mcc: 0.7803, acc: 0.6658, precision: 0.9103, recall: 0.6864, f1: 0.7827, edges-ner-ontonotes_loss: 0.0668
09/16 06:05:28 AM: Update 1218: task edges-ner-ontonotes, batch 218 (1218): mcc: 0.7802, acc: 0.6657, precision: 0.9100, recall: 0.6865, f1: 0.7826, edges-ner-ontonotes_loss: 0.0670
09/16 06:05:35 AM: Update 1287: task edges-ner-ontonotes, batch 287 (1287): mcc: 0.7751, acc: 0.6595, precision: 0.9077, recall: 0.6797, f1: 0.7773, edges-ner-ontonotes_loss: 0.0685
09/16 06:05:40 AM: Update 1273: task edges-ner-ontonotes, batch 273 (1273): mcc: 0.7775, acc: 0.6624, precision: 0.9093, recall: 0.6826, f1: 0.7798, edges-ner-ontonotes_loss: 0.0676
09/16 06:05:46 AM: Update 1364: task edges-ner-ontonotes, batch 364 (1364): mcc: 0.7647, acc: 0.6462, precision: 0.9016, recall: 0.6671, f1: 0.7668, edges-ner-ontonotes_loss: 0.0718
09/16 06:05:50 AM: Update 1346: task edges-ner-ontonotes, batch 346 (1346): mcc: 0.7660, acc: 0.6478, precision: 0.9022, recall: 0.6687, f1: 0.7681, edges-ner-ontonotes_loss: 0.0713
09/16 06:05:56 AM: Update 1442: task edges-ner-ontonotes, batch 442 (1442): mcc: 0.7612, acc: 0.6420, precision: 0.8989, recall: 0.6632, f1: 0.7633, edges-ner-ontonotes_loss: 0.0727
09/16 06:06:00 AM: Update 1425: task edges-ner-ontonotes, batch 425 (1425): mcc: 0.7616, acc: 0.6427, precision: 0.8990, recall: 0.6638, f1: 0.7638, edges-ner-ontonotes_loss: 0.0724
09/16 06:06:07 AM: Update 1520: task edges-ner-ontonotes, batch 520 (1520): mcc: 0.7582, acc: 0.6387, precision: 0.8969, recall: 0.6599, f1: 0.7603, edges-ner-ontonotes_loss: 0.0736
09/16 06:06:10 AM: Update 1502: task edges-ner-ontonotes, batch 502 (1502): mcc: 0.7590, acc: 0.6394, precision: 0.8976, recall: 0.6605, f1: 0.7610, edges-ner-ontonotes_loss: 0.0732
09/16 06:06:17 AM: Update 1588: task edges-ner-ontonotes, batch 588 (1588): mcc: 0.7564, acc: 0.6372, precision: 0.8942, recall: 0.6589, f1: 0.7587, edges-ner-ontonotes_loss: 0.0738
09/16 06:06:20 AM: Update 1571: task edges-ner-ontonotes, batch 571 (1571): mcc: 0.7567, acc: 0.6374, precision: 0.8947, recall: 0.6591, f1: 0.7590, edges-ner-ontonotes_loss: 0.0737
09/16 06:06:27 AM: Update 1683: task edges-ner-ontonotes, batch 683 (1683): mcc: 0.7551, acc: 0.6355, precision: 0.8932, recall: 0.6574, f1: 0.7574, edges-ner-ontonotes_loss: 0.0739
09/16 06:06:30 AM: Update 1662: task edges-ner-ontonotes, batch 662 (1662): mcc: 0.7550, acc: 0.6354, precision: 0.8932, recall: 0.6574, f1: 0.7574, edges-ner-ontonotes_loss: 0.0740
09/16 06:06:37 AM: Update 1771: task edges-ner-ontonotes, batch 771 (1771): mcc: 0.7544, acc: 0.6353, precision: 0.8919, recall: 0.6573, f1: 0.7569, edges-ner-ontonotes_loss: 0.0739
09/16 06:06:40 AM: Update 1747: task edges-ner-ontonotes, batch 747 (1747): mcc: 0.7544, acc: 0.6350, precision: 0.8924, recall: 0.6569, f1: 0.7568, edges-ner-ontonotes_loss: 0.0740
09/16 06:06:47 AM: Update 1857: task edges-ner-ontonotes, batch 857 (1857): mcc: 0.7549, acc: 0.6361, precision: 0.8916, recall: 0.6584, f1: 0.7574, edges-ner-ontonotes_loss: 0.0736
09/16 06:06:50 AM: Update 1838: task edges-ner-ontonotes, batch 838 (1838): mcc: 0.7550, acc: 0.6362, precision: 0.8918, recall: 0.6584, f1: 0.7575, edges-ner-ontonotes_loss: 0.0736
09/16 06:06:57 AM: Update 1923: task edges-ner-ontonotes, batch 923 (1923): mcc: 0.7574, acc: 0.6396, precision: 0.8921, recall: 0.6622, f1: 0.7601, edges-ner-ontonotes_loss: 0.0728
09/16 06:07:00 AM: Update 1906: task edges-ner-ontonotes, batch 906 (1906): mcc: 0.7565, acc: 0.6383, precision: 0.8916, recall: 0.6610, f1: 0.7592, edges-ner-ontonotes_loss: 0.0731
09/16 06:07:09 AM: Update 1999: task edges-ner-ontonotes, batch 999 (1999): mcc: 0.7614, acc: 0.6451, precision: 0.8934, recall: 0.6679, f1: 0.7644, edges-ner-ontonotes_loss: 0.0718
09/16 06:07:10 AM: ***** Step 2000 / Validation 2 *****
09/16 06:07:10 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:07:10 AM: Validating...
09/16 06:07:10 AM: Update 1978: task edges-ner-ontonotes, batch 978 (1978): mcc: 0.7601, acc: 0.6434, precision: 0.8928, recall: 0.6662, f1: 0.7631, edges-ner-ontonotes_loss: 0.0721
09/16 06:07:14 AM: ***** Step 2000 / Validation 2 *****
09/16 06:07:14 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:07:14 AM: Validating...
09/16 06:07:20 AM: Evaluate: task edges-ner-ontonotes, batch 56 (157): mcc: 0.8098, acc: 0.7151, precision: 0.9226, recall: 0.7268, f1: 0.8131, edges-ner-ontonotes_loss: 0.0609
09/16 06:07:21 AM: Evaluate: task edges-ner-ontonotes, batch 33 (157): mcc: 0.7804, acc: 0.6789, precision: 0.9054, recall: 0.6906, f1: 0.7835, edges-ner-ontonotes_loss: 0.0686
09/16 06:07:30 AM: Evaluate: task edges-ner-ontonotes, batch 100 (157): mcc: 0.8265, acc: 0.7364, precision: 0.9279, recall: 0.7513, f1: 0.8303, edges-ner-ontonotes_loss: 0.0569
09/16 06:07:31 AM: Evaluate: task edges-ner-ontonotes, batch 75 (157): mcc: 0.8198, acc: 0.7291, precision: 0.9266, recall: 0.7408, f1: 0.8233, edges-ner-ontonotes_loss: 0.0589
09/16 06:07:40 AM: Evaluate: task edges-ner-ontonotes, batch 149 (157): mcc: 0.8402, acc: 0.7548, precision: 0.9335, recall: 0.7705, f1: 0.8442, edges-ner-ontonotes_loss: 0.0527
09/16 06:07:42 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:07:42 AM: Best result seen so far for macro.
09/16 06:07:42 AM: Updating LR scheduler:
09/16 06:07:42 AM: 	Best result seen so far for macro_avg: 0.843
09/16 06:07:42 AM: 	# validation passes without improvement: 0
09/16 06:07:42 AM: edges-ner-ontonotes_loss: training: 0.071819 validation: 0.052335
09/16 06:07:42 AM: macro_avg: validation: 0.843377
09/16 06:07:42 AM: micro_avg: validation: 0.000000
09/16 06:07:42 AM: edges-ner-ontonotes_mcc: training: 0.761465 validation: 0.839343
09/16 06:07:42 AM: edges-ner-ontonotes_acc: training: 0.645155 validation: 0.753412
09/16 06:07:42 AM: edges-ner-ontonotes_precision: training: 0.893439 validation: 0.932409
09/16 06:07:42 AM: edges-ner-ontonotes_recall: training: 0.667960 validation: 0.769867
09/16 06:07:42 AM: edges-ner-ontonotes_f1: training: 0.764419 validation: 0.843377
09/16 06:07:42 AM: Global learning rate: 0.0001
09/16 06:07:42 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:07:43 AM: Evaluate: task edges-ner-ontonotes, batch 116 (157): mcc: 0.8355, acc: 0.7488, precision: 0.9297, recall: 0.7654, f1: 0.8396, edges-ner-ontonotes_loss: 0.0542
09/16 06:07:50 AM: Update 2046: task edges-ner-ontonotes, batch 46 (2046): mcc: 0.8179, acc: 0.7248, precision: 0.9156, recall: 0.7466, f1: 0.8225, edges-ner-ontonotes_loss: 0.0555
09/16 06:07:51 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:07:51 AM: Best result seen so far for macro.
09/16 06:07:51 AM: Updating LR scheduler:
09/16 06:07:51 AM: 	Best result seen so far for macro_avg: 0.843
09/16 06:07:51 AM: 	# validation passes without improvement: 0
09/16 06:07:51 AM: edges-ner-ontonotes_loss: training: 0.071819 validation: 0.052335
09/16 06:07:51 AM: macro_avg: validation: 0.843377
09/16 06:07:51 AM: micro_avg: validation: 0.000000
09/16 06:07:51 AM: edges-ner-ontonotes_mcc: training: 0.761465 validation: 0.839343
09/16 06:07:51 AM: edges-ner-ontonotes_acc: training: 0.645155 validation: 0.753412
09/16 06:07:51 AM: edges-ner-ontonotes_precision: training: 0.893439 validation: 0.932409
09/16 06:07:51 AM: edges-ner-ontonotes_recall: training: 0.667960 validation: 0.769867
09/16 06:07:51 AM: edges-ner-ontonotes_f1: training: 0.764419 validation: 0.843377
09/16 06:07:51 AM: Global learning rate: 0.0001
09/16 06:07:51 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:07:53 AM: Update 2015: task edges-ner-ontonotes, batch 15 (2015): mcc: 0.8147, acc: 0.7255, precision: 0.9103, recall: 0.7455, f1: 0.8197, edges-ner-ontonotes_loss: 0.0555
09/16 06:08:02 AM: Update 2122: task edges-ner-ontonotes, batch 122 (2122): mcc: 0.8161, acc: 0.7205, precision: 0.9156, recall: 0.7435, f1: 0.8206, edges-ner-ontonotes_loss: 0.0561
09/16 06:08:04 AM: Update 2090: task edges-ner-ontonotes, batch 90 (2090): mcc: 0.8169, acc: 0.7207, precision: 0.9187, recall: 0.7423, f1: 0.8212, edges-ner-ontonotes_loss: 0.0558
09/16 06:08:13 AM: Update 2183: task edges-ner-ontonotes, batch 183 (2183): mcc: 0.8167, acc: 0.7224, precision: 0.9162, recall: 0.7440, f1: 0.8211, edges-ner-ontonotes_loss: 0.0560
09/16 06:08:14 AM: Update 2168: task edges-ner-ontonotes, batch 168 (2168): mcc: 0.8168, acc: 0.7232, precision: 0.9148, recall: 0.7455, f1: 0.8215, edges-ner-ontonotes_loss: 0.0560
09/16 06:08:23 AM: Update 2270: task edges-ner-ontonotes, batch 270 (2270): mcc: 0.8238, acc: 0.7325, precision: 0.9176, recall: 0.7552, f1: 0.8285, edges-ner-ontonotes_loss: 0.0544
09/16 06:08:24 AM: Update 2220: task edges-ner-ontonotes, batch 220 (2220): mcc: 0.8181, acc: 0.7248, precision: 0.9156, recall: 0.7470, f1: 0.8228, edges-ner-ontonotes_loss: 0.0555
09/16 06:08:33 AM: Update 2341: task edges-ner-ontonotes, batch 341 (2341): mcc: 0.8278, acc: 0.7377, precision: 0.9197, recall: 0.7604, f1: 0.8325, edges-ner-ontonotes_loss: 0.0534
09/16 06:08:34 AM: Update 2289: task edges-ner-ontonotes, batch 289 (2289): mcc: 0.8256, acc: 0.7348, precision: 0.9192, recall: 0.7570, f1: 0.8303, edges-ner-ontonotes_loss: 0.0540
09/16 06:08:43 AM: Update 2413: task edges-ner-ontonotes, batch 413 (2413): mcc: 0.8303, acc: 0.7421, precision: 0.9197, recall: 0.7647, f1: 0.8351, edges-ner-ontonotes_loss: 0.0528
09/16 06:08:44 AM: Update 2361: task edges-ner-ontonotes, batch 361 (2361): mcc: 0.8289, acc: 0.7399, precision: 0.9199, recall: 0.7622, f1: 0.8337, edges-ner-ontonotes_loss: 0.0532
09/16 06:08:53 AM: Update 2482: task edges-ner-ontonotes, batch 482 (2482): mcc: 0.8324, acc: 0.7455, precision: 0.9197, recall: 0.7686, f1: 0.8374, edges-ner-ontonotes_loss: 0.0520
09/16 06:08:55 AM: Update 2432: task edges-ner-ontonotes, batch 432 (2432): mcc: 0.8302, acc: 0.7423, precision: 0.9190, recall: 0.7653, f1: 0.8352, edges-ner-ontonotes_loss: 0.0526
09/16 06:09:03 AM: Update 2532: task edges-ner-ontonotes, batch 532 (2532): mcc: 0.8326, acc: 0.7463, precision: 0.9195, recall: 0.7691, f1: 0.8376, edges-ner-ontonotes_loss: 0.0520
09/16 06:09:06 AM: Update 2496: task edges-ner-ontonotes, batch 496 (2496): mcc: 0.8327, acc: 0.7459, precision: 0.9199, recall: 0.7688, f1: 0.8376, edges-ner-ontonotes_loss: 0.0519
09/16 06:09:13 AM: Update 2612: task edges-ner-ontonotes, batch 612 (2612): mcc: 0.8333, acc: 0.7473, precision: 0.9189, recall: 0.7708, f1: 0.8383, edges-ner-ontonotes_loss: 0.0514
09/16 06:09:16 AM: Update 2566: task edges-ner-ontonotes, batch 566 (2566): mcc: 0.8330, acc: 0.7468, precision: 0.9193, recall: 0.7700, f1: 0.8380, edges-ner-ontonotes_loss: 0.0517
09/16 06:09:23 AM: Update 2684: task edges-ner-ontonotes, batch 684 (2684): mcc: 0.8338, acc: 0.7481, precision: 0.9186, recall: 0.7721, f1: 0.8390, edges-ner-ontonotes_loss: 0.0512
09/16 06:09:26 AM: Update 2635: task edges-ner-ontonotes, batch 635 (2635): mcc: 0.8339, acc: 0.7480, precision: 0.9192, recall: 0.7716, f1: 0.8390, edges-ner-ontonotes_loss: 0.0514
09/16 06:09:33 AM: Update 2752: task edges-ner-ontonotes, batch 752 (2752): mcc: 0.8348, acc: 0.7496, precision: 0.9183, recall: 0.7739, f1: 0.8399, edges-ner-ontonotes_loss: 0.0510
09/16 06:09:36 AM: Update 2707: task edges-ner-ontonotes, batch 707 (2707): mcc: 0.8343, acc: 0.7489, precision: 0.9185, recall: 0.7730, f1: 0.8395, edges-ner-ontonotes_loss: 0.0512
09/16 06:09:44 AM: Update 2809: task edges-ner-ontonotes, batch 809 (2809): mcc: 0.8359, acc: 0.7510, precision: 0.9186, recall: 0.7756, f1: 0.8411, edges-ner-ontonotes_loss: 0.0505
09/16 06:09:46 AM: Update 2784: task edges-ner-ontonotes, batch 784 (2784): mcc: 0.8357, acc: 0.7510, precision: 0.9184, recall: 0.7755, f1: 0.8409, edges-ner-ontonotes_loss: 0.0507
09/16 06:09:54 AM: Update 2891: task edges-ner-ontonotes, batch 891 (2891): mcc: 0.8312, acc: 0.7446, precision: 0.9158, recall: 0.7699, f1: 0.8365, edges-ner-ontonotes_loss: 0.0520
09/16 06:09:59 AM: Update 2836: task edges-ner-ontonotes, batch 836 (2836): mcc: 0.8341, acc: 0.7486, precision: 0.9174, recall: 0.7735, f1: 0.8393, edges-ner-ontonotes_loss: 0.0511
09/16 06:10:06 AM: Update 2970: task edges-ner-ontonotes, batch 970 (2970): mcc: 0.8287, acc: 0.7415, precision: 0.9142, recall: 0.7667, f1: 0.8340, edges-ner-ontonotes_loss: 0.0530
09/16 06:10:10 AM: ***** Step 3000 / Validation 3 *****
09/16 06:10:10 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:10:10 AM: Validating...
09/16 06:10:10 AM: Update 2905: task edges-ner-ontonotes, batch 905 (2905): mcc: 0.8306, acc: 0.7437, precision: 0.9155, recall: 0.7690, f1: 0.8359, edges-ner-ontonotes_loss: 0.0522
09/16 06:10:16 AM: Evaluate: task edges-ner-ontonotes, batch 45 (157): mcc: 0.8073, acc: 0.7206, precision: 0.9079, recall: 0.7347, f1: 0.8122, edges-ner-ontonotes_loss: 0.0592
09/16 06:10:22 AM: Update 2971: task edges-ner-ontonotes, batch 971 (2971): mcc: 0.8287, acc: 0.7414, precision: 0.9142, recall: 0.7667, f1: 0.8340, edges-ner-ontonotes_loss: 0.0530
09/16 06:10:28 AM: ***** Step 3000 / Validation 3 *****
09/16 06:10:28 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:10:29 AM: Evaluate: task edges-ner-ontonotes, batch 103 (157): mcc: 0.8456, acc: 0.7694, precision: 0.9286, recall: 0.7842, f1: 0.8503, edges-ner-ontonotes_loss: 0.0502
09/16 06:10:30 AM: Validating...
09/16 06:10:33 AM: Evaluate: task edges-ner-ontonotes, batch 17 (157): mcc: 0.7668, acc: 0.6622, precision: 0.8987, recall: 0.6727, f1: 0.7695, edges-ner-ontonotes_loss: 0.0693
09/16 06:10:40 AM: Evaluate: task edges-ner-ontonotes, batch 144 (157): mcc: 0.8595, acc: 0.7866, precision: 0.9379, recall: 0.8006, f1: 0.8638, edges-ner-ontonotes_loss: 0.0461
09/16 06:10:43 AM: Evaluate: task edges-ner-ontonotes, batch 69 (157): mcc: 0.8285, acc: 0.7470, precision: 0.9210, recall: 0.7606, f1: 0.8332, edges-ner-ontonotes_loss: 0.0547
09/16 06:10:44 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:10:44 AM: Best result seen so far for macro.
09/16 06:10:44 AM: Updating LR scheduler:
09/16 06:10:44 AM: 	Best result seen so far for macro_avg: 0.862
09/16 06:10:44 AM: 	# validation passes without improvement: 0
09/16 06:10:44 AM: edges-ner-ontonotes_loss: training: 0.053333 validation: 0.045804
09/16 06:10:44 AM: macro_avg: validation: 0.862429
09/16 06:10:44 AM: micro_avg: validation: 0.000000
09/16 06:10:44 AM: edges-ner-ontonotes_mcc: training: 0.827727 validation: 0.858041
09/16 06:10:44 AM: edges-ner-ontonotes_acc: training: 0.740185 validation: 0.784198
09/16 06:10:44 AM: edges-ner-ontonotes_precision: training: 0.913757 validation: 0.937027
09/16 06:10:44 AM: edges-ner-ontonotes_recall: training: 0.765431 validation: 0.798832
09/16 06:10:44 AM: edges-ner-ontonotes_f1: training: 0.833043 validation: 0.862429
09/16 06:10:44 AM: Global learning rate: 0.0001
09/16 06:10:44 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:10:51 AM: Update 3041: task edges-ner-ontonotes, batch 41 (3041): mcc: 0.7874, acc: 0.6867, precision: 0.8932, recall: 0.7124, f1: 0.7926, edges-ner-ontonotes_loss: 0.0651
09/16 06:10:53 AM: Evaluate: task edges-ner-ontonotes, batch 118 (157): mcc: 0.8541, acc: 0.7808, precision: 0.9326, recall: 0.7958, f1: 0.8588, edges-ner-ontonotes_loss: 0.0480
09/16 06:11:00 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:11:00 AM: Best result seen so far for macro.
09/16 06:11:00 AM: Updating LR scheduler:
09/16 06:11:00 AM: 	Best result seen so far for macro_avg: 0.862
09/16 06:11:00 AM: 	# validation passes without improvement: 0
09/16 06:11:00 AM: edges-ner-ontonotes_loss: training: 0.053333 validation: 0.045804
09/16 06:11:00 AM: macro_avg: validation: 0.862429
09/16 06:11:00 AM: micro_avg: validation: 0.000000
09/16 06:11:00 AM: edges-ner-ontonotes_mcc: training: 0.827727 validation: 0.858041
09/16 06:11:00 AM: edges-ner-ontonotes_acc: training: 0.740185 validation: 0.784198
09/16 06:11:00 AM: edges-ner-ontonotes_precision: training: 0.913757 validation: 0.937027
09/16 06:11:00 AM: edges-ner-ontonotes_recall: training: 0.765431 validation: 0.798832
09/16 06:11:00 AM: edges-ner-ontonotes_f1: training: 0.833043 validation: 0.862429
09/16 06:11:00 AM: Global learning rate: 0.0001
09/16 06:11:00 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:11:01 AM: Update 3106: task edges-ner-ontonotes, batch 106 (3106): mcc: 0.7849, acc: 0.6856, precision: 0.8901, recall: 0.7106, f1: 0.7903, edges-ner-ontonotes_loss: 0.0664
09/16 06:11:04 AM: Update 3001: task edges-ner-ontonotes, batch 1 (3001): mcc: 0.7929, acc: 0.6567, precision: 0.9574, recall: 0.6716, f1: 0.7895, edges-ner-ontonotes_loss: 0.0612
09/16 06:11:11 AM: Update 3165: task edges-ner-ontonotes, batch 165 (3165): mcc: 0.7845, acc: 0.6869, precision: 0.8865, recall: 0.7130, f1: 0.7903, edges-ner-ontonotes_loss: 0.0657
09/16 06:11:14 AM: Update 3083: task edges-ner-ontonotes, batch 83 (3083): mcc: 0.7849, acc: 0.6864, precision: 0.8881, recall: 0.7123, f1: 0.7905, edges-ner-ontonotes_loss: 0.0659
09/16 06:11:21 AM: Update 3263: task edges-ner-ontonotes, batch 263 (3263): mcc: 0.7883, acc: 0.6902, precision: 0.8898, recall: 0.7168, f1: 0.7939, edges-ner-ontonotes_loss: 0.0642
09/16 06:11:24 AM: Update 3144: task edges-ner-ontonotes, batch 144 (3144): mcc: 0.7855, acc: 0.6880, precision: 0.8890, recall: 0.7127, f1: 0.7911, edges-ner-ontonotes_loss: 0.0660
09/16 06:11:31 AM: Update 3364: task edges-ner-ontonotes, batch 364 (3364): mcc: 0.7904, acc: 0.6919, precision: 0.8912, recall: 0.7192, f1: 0.7960, edges-ner-ontonotes_loss: 0.0631
09/16 06:11:36 AM: Update 3228: task edges-ner-ontonotes, batch 228 (3228): mcc: 0.7869, acc: 0.6886, precision: 0.8880, recall: 0.7159, f1: 0.7927, edges-ner-ontonotes_loss: 0.0649
09/16 06:11:41 AM: Update 3431: task edges-ner-ontonotes, batch 431 (3431): mcc: 0.7919, acc: 0.6934, precision: 0.8923, recall: 0.7210, f1: 0.7976, edges-ner-ontonotes_loss: 0.0625
09/16 06:11:48 AM: Update 3326: task edges-ner-ontonotes, batch 326 (3326): mcc: 0.7906, acc: 0.6922, precision: 0.8913, recall: 0.7196, f1: 0.7963, edges-ner-ontonotes_loss: 0.0635
09/16 06:11:52 AM: Update 3516: task edges-ner-ontonotes, batch 516 (3516): mcc: 0.7978, acc: 0.7018, precision: 0.8948, recall: 0.7290, f1: 0.8035, edges-ner-ontonotes_loss: 0.0610
09/16 06:11:59 AM: Update 3405: task edges-ner-ontonotes, batch 405 (3405): mcc: 0.7908, acc: 0.6921, precision: 0.8913, recall: 0.7198, f1: 0.7965, edges-ner-ontonotes_loss: 0.0628
09/16 06:12:02 AM: Update 3596: task edges-ner-ontonotes, batch 596 (3596): mcc: 0.8037, acc: 0.7101, precision: 0.8971, recall: 0.7374, f1: 0.8095, edges-ner-ontonotes_loss: 0.0594
09/16 06:12:09 AM: Update 3460: task edges-ner-ontonotes, batch 460 (3460): mcc: 0.7944, acc: 0.6969, precision: 0.8930, recall: 0.7246, f1: 0.8001, edges-ner-ontonotes_loss: 0.0617
09/16 06:12:12 AM: Update 3675: task edges-ner-ontonotes, batch 675 (3675): mcc: 0.8073, acc: 0.7153, precision: 0.8989, recall: 0.7423, f1: 0.8131, edges-ner-ontonotes_loss: 0.0582
09/16 06:12:19 AM: Update 3532: task edges-ner-ontonotes, batch 532 (3532): mcc: 0.7996, acc: 0.7043, precision: 0.8955, recall: 0.7316, f1: 0.8053, edges-ner-ontonotes_loss: 0.0606
09/16 06:12:24 AM: Update 3739: task edges-ner-ontonotes, batch 739 (3739): mcc: 0.8106, acc: 0.7192, precision: 0.9008, recall: 0.7465, f1: 0.8164, edges-ner-ontonotes_loss: 0.0573
09/16 06:12:29 AM: Update 3624: task edges-ner-ontonotes, batch 624 (3624): mcc: 0.8057, acc: 0.7130, precision: 0.8983, recall: 0.7401, f1: 0.8115, edges-ner-ontonotes_loss: 0.0588
09/16 06:12:37 AM: Update 3805: task edges-ner-ontonotes, batch 805 (3805): mcc: 0.8155, acc: 0.7253, precision: 0.9036, recall: 0.7527, f1: 0.8212, edges-ner-ontonotes_loss: 0.0562
09/16 06:12:39 AM: Update 3694: task edges-ner-ontonotes, batch 694 (3694): mcc: 0.8086, acc: 0.7169, precision: 0.8997, recall: 0.7439, f1: 0.8144, edges-ner-ontonotes_loss: 0.0579
09/16 06:12:47 AM: Update 3890: task edges-ner-ontonotes, batch 890 (3890): mcc: 0.8203, acc: 0.7316, precision: 0.9057, recall: 0.7593, f1: 0.8260, edges-ner-ontonotes_loss: 0.0550
09/16 06:12:49 AM: Update 3751: task edges-ner-ontonotes, batch 751 (3751): mcc: 0.8112, acc: 0.7199, precision: 0.9010, recall: 0.7472, f1: 0.8169, edges-ner-ontonotes_loss: 0.0572
09/16 06:13:00 AM: Update 3822: task edges-ner-ontonotes, batch 822 (3822): mcc: 0.8165, acc: 0.7267, precision: 0.9040, recall: 0.7541, f1: 0.8223, edges-ner-ontonotes_loss: 0.0560
09/16 06:13:00 AM: Update 3963: task edges-ner-ontonotes, batch 963 (3963): mcc: 0.8234, acc: 0.7359, precision: 0.9071, recall: 0.7635, f1: 0.8291, edges-ner-ontonotes_loss: 0.0541
09/16 06:13:06 AM: ***** Step 4000 / Validation 4 *****
09/16 06:13:06 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:13:06 AM: Validating...
09/16 06:13:11 AM: Evaluate: task edges-ner-ontonotes, batch 34 (157): mcc: 0.8224, acc: 0.7424, precision: 0.9061, recall: 0.7628, f1: 0.8283, edges-ner-ontonotes_loss: 0.0567
09/16 06:13:12 AM: Update 3889: task edges-ner-ontonotes, batch 889 (3889): mcc: 0.8203, acc: 0.7316, precision: 0.9057, recall: 0.7593, f1: 0.8260, edges-ner-ontonotes_loss: 0.0550
09/16 06:13:22 AM: Evaluate: task edges-ner-ontonotes, batch 92 (157): mcc: 0.8652, acc: 0.7962, precision: 0.9339, recall: 0.8143, f1: 0.8700, edges-ner-ontonotes_loss: 0.0452
09/16 06:13:23 AM: Update 3944: task edges-ner-ontonotes, batch 944 (3944): mcc: 0.8229, acc: 0.7351, precision: 0.9070, recall: 0.7628, f1: 0.8286, edges-ner-ontonotes_loss: 0.0543
09/16 06:13:32 AM: Evaluate: task edges-ner-ontonotes, batch 140 (157): mcc: 0.8806, acc: 0.8188, precision: 0.9392, recall: 0.8373, f1: 0.8853, edges-ner-ontonotes_loss: 0.0406
09/16 06:13:33 AM: Update 3999: task edges-ner-ontonotes, batch 999 (3999): mcc: 0.8252, acc: 0.7384, precision: 0.9080, recall: 0.7660, f1: 0.8310, edges-ner-ontonotes_loss: 0.0536
09/16 06:13:33 AM: ***** Step 4000 / Validation 4 *****
09/16 06:13:33 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:13:33 AM: Validating...
09/16 06:13:35 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:13:35 AM: Best result seen so far for macro.
09/16 06:13:35 AM: Updating LR scheduler:
09/16 06:13:35 AM: 	Best result seen so far for macro_avg: 0.883
09/16 06:13:35 AM: 	# validation passes without improvement: 0
09/16 06:13:35 AM: edges-ner-ontonotes_loss: training: 0.053600 validation: 0.040328
09/16 06:13:35 AM: macro_avg: validation: 0.883115
09/16 06:13:35 AM: micro_avg: validation: 0.000000
09/16 06:13:35 AM: edges-ner-ontonotes_mcc: training: 0.825326 validation: 0.878282
09/16 06:13:35 AM: edges-ner-ontonotes_acc: training: 0.738551 validation: 0.815211
09/16 06:13:35 AM: edges-ner-ontonotes_precision: training: 0.908052 validation: 0.937112
09/16 06:13:35 AM: edges-ner-ontonotes_recall: training: 0.766133 validation: 0.835002
09/16 06:13:35 AM: edges-ner-ontonotes_f1: training: 0.831077 validation: 0.883115
09/16 06:13:35 AM: Global learning rate: 0.0001
09/16 06:13:35 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:13:42 AM: Update 4033: task edges-ner-ontonotes, batch 33 (4033): mcc: 0.8697, acc: 0.7999, precision: 0.9283, recall: 0.8275, f1: 0.8750, edges-ner-ontonotes_loss: 0.0401
09/16 06:13:43 AM: Evaluate: task edges-ner-ontonotes, batch 60 (157): mcc: 0.8523, acc: 0.7810, precision: 0.9229, recall: 0.8010, f1: 0.8576, edges-ner-ontonotes_loss: 0.0485
09/16 06:13:52 AM: Update 4073: task edges-ner-ontonotes, batch 73 (4073): mcc: 0.8673, acc: 0.7961, precision: 0.9270, recall: 0.8243, f1: 0.8726, edges-ner-ontonotes_loss: 0.0405
09/16 06:13:53 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.8733, acc: 0.8092, precision: 0.9346, recall: 0.8283, f1: 0.8782, edges-ner-ontonotes_loss: 0.0432
09/16 06:14:02 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:14:02 AM: Best result seen so far for macro.
09/16 06:14:02 AM: Updating LR scheduler:
09/16 06:14:02 AM: 	Best result seen so far for macro_avg: 0.883
09/16 06:14:02 AM: 	# validation passes without improvement: 0
09/16 06:14:02 AM: edges-ner-ontonotes_loss: training: 0.053600 validation: 0.040328
09/16 06:14:02 AM: macro_avg: validation: 0.883115
09/16 06:14:02 AM: micro_avg: validation: 0.000000
09/16 06:14:02 AM: edges-ner-ontonotes_mcc: training: 0.825326 validation: 0.878282
09/16 06:14:02 AM: edges-ner-ontonotes_acc: training: 0.738551 validation: 0.815211
09/16 06:14:02 AM: edges-ner-ontonotes_precision: training: 0.908052 validation: 0.937112
09/16 06:14:02 AM: edges-ner-ontonotes_recall: training: 0.766133 validation: 0.835002
09/16 06:14:02 AM: edges-ner-ontonotes_f1: training: 0.831077 validation: 0.883115
09/16 06:14:02 AM: Global learning rate: 0.0001
09/16 06:14:02 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:14:02 AM: Update 4130: task edges-ner-ontonotes, batch 130 (4130): mcc: 0.8638, acc: 0.7916, precision: 0.9219, recall: 0.8226, f1: 0.8694, edges-ner-ontonotes_loss: 0.0418
09/16 06:14:05 AM: Update 4001: task edges-ner-ontonotes, batch 1 (4001): mcc: 0.8454, acc: 0.7563, precision: 0.9216, recall: 0.7899, f1: 0.8507, edges-ner-ontonotes_loss: 0.0431
09/16 06:14:12 AM: Update 4205: task edges-ner-ontonotes, batch 205 (4205): mcc: 0.8625, acc: 0.7901, precision: 0.9220, recall: 0.8203, f1: 0.8682, edges-ner-ontonotes_loss: 0.0423
09/16 06:14:15 AM: Update 4052: task edges-ner-ontonotes, batch 52 (4052): mcc: 0.8711, acc: 0.8030, precision: 0.9280, recall: 0.8302, f1: 0.8764, edges-ner-ontonotes_loss: 0.0406
09/16 06:14:22 AM: Update 4282: task edges-ner-ontonotes, batch 282 (4282): mcc: 0.8606, acc: 0.7869, precision: 0.9212, recall: 0.8175, f1: 0.8663, edges-ner-ontonotes_loss: 0.0425
09/16 06:14:25 AM: Update 4122: task edges-ner-ontonotes, batch 122 (4122): mcc: 0.8635, acc: 0.7913, precision: 0.9222, recall: 0.8219, f1: 0.8692, edges-ner-ontonotes_loss: 0.0419
09/16 06:14:32 AM: Update 4355: task edges-ner-ontonotes, batch 355 (4355): mcc: 0.8592, acc: 0.7852, precision: 0.9199, recall: 0.8161, f1: 0.8649, edges-ner-ontonotes_loss: 0.0426
09/16 06:14:35 AM: Update 4197: task edges-ner-ontonotes, batch 197 (4197): mcc: 0.8627, acc: 0.7901, precision: 0.9223, recall: 0.8202, f1: 0.8683, edges-ner-ontonotes_loss: 0.0421
09/16 06:14:42 AM: Update 4416: task edges-ner-ontonotes, batch 416 (4416): mcc: 0.8541, acc: 0.7782, precision: 0.9177, recall: 0.8091, f1: 0.8600, edges-ner-ontonotes_loss: 0.0445
09/16 06:14:45 AM: Update 4266: task edges-ner-ontonotes, batch 266 (4266): mcc: 0.8613, acc: 0.7879, precision: 0.9215, recall: 0.8185, f1: 0.8669, edges-ner-ontonotes_loss: 0.0425
09/16 06:14:52 AM: Update 4486: task edges-ner-ontonotes, batch 486 (4486): mcc: 0.8485, acc: 0.7705, precision: 0.9153, recall: 0.8011, f1: 0.8544, edges-ner-ontonotes_loss: 0.0465
09/16 06:14:56 AM: Update 4344: task edges-ner-ontonotes, batch 344 (4344): mcc: 0.8594, acc: 0.7854, precision: 0.9202, recall: 0.8162, f1: 0.8651, edges-ner-ontonotes_loss: 0.0426
09/16 06:15:05 AM: Update 4564: task edges-ner-ontonotes, batch 564 (4564): mcc: 0.8435, acc: 0.7641, precision: 0.9122, recall: 0.7949, f1: 0.8495, edges-ner-ontonotes_loss: 0.0488
09/16 06:15:06 AM: Update 4404: task edges-ner-ontonotes, batch 404 (4404): mcc: 0.8548, acc: 0.7791, precision: 0.9180, recall: 0.8099, f1: 0.8606, edges-ner-ontonotes_loss: 0.0442
09/16 06:15:15 AM: Update 4636: task edges-ner-ontonotes, batch 636 (4636): mcc: 0.8396, acc: 0.7591, precision: 0.9102, recall: 0.7897, f1: 0.8456, edges-ner-ontonotes_loss: 0.0502
09/16 06:15:16 AM: Update 4477: task edges-ner-ontonotes, batch 477 (4477): mcc: 0.8491, acc: 0.7713, precision: 0.9154, recall: 0.8020, f1: 0.8550, edges-ner-ontonotes_loss: 0.0463
09/16 06:15:25 AM: Update 4696: task edges-ner-ontonotes, batch 696 (4696): mcc: 0.8369, acc: 0.7554, precision: 0.9088, recall: 0.7860, f1: 0.8430, edges-ner-ontonotes_loss: 0.0511
09/16 06:15:26 AM: Update 4560: task edges-ner-ontonotes, batch 560 (4560): mcc: 0.8438, acc: 0.7644, precision: 0.9123, recall: 0.7952, f1: 0.8497, edges-ner-ontonotes_loss: 0.0486
09/16 06:15:35 AM: Update 4778: task edges-ner-ontonotes, batch 778 (4778): mcc: 0.8344, acc: 0.7522, precision: 0.9075, recall: 0.7828, f1: 0.8405, edges-ner-ontonotes_loss: 0.0518
09/16 06:15:36 AM: Update 4636: task edges-ner-ontonotes, batch 636 (4636): mcc: 0.8396, acc: 0.7591, precision: 0.9102, recall: 0.7897, f1: 0.8456, edges-ner-ontonotes_loss: 0.0502
09/16 06:15:45 AM: Update 4869: task edges-ner-ontonotes, batch 869 (4869): mcc: 0.8318, acc: 0.7483, precision: 0.9059, recall: 0.7795, f1: 0.8380, edges-ner-ontonotes_loss: 0.0525
09/16 06:15:46 AM: Update 4703: task edges-ner-ontonotes, batch 703 (4703): mcc: 0.8367, acc: 0.7552, precision: 0.9087, recall: 0.7858, f1: 0.8428, edges-ner-ontonotes_loss: 0.0511
09/16 06:15:55 AM: Update 4958: task edges-ner-ontonotes, batch 958 (4958): mcc: 0.8308, acc: 0.7468, precision: 0.9052, recall: 0.7784, f1: 0.8370, edges-ner-ontonotes_loss: 0.0527
09/16 06:15:56 AM: Update 4791: task edges-ner-ontonotes, batch 791 (4791): mcc: 0.8337, acc: 0.7513, precision: 0.9071, recall: 0.7819, f1: 0.8399, edges-ner-ontonotes_loss: 0.0520
09/16 06:16:03 AM: ***** Step 5000 / Validation 5 *****
09/16 06:16:03 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:16:03 AM: Validating...
09/16 06:16:05 AM: Evaluate: task edges-ner-ontonotes, batch 10 (157): mcc: 0.7800, acc: 0.6724, precision: 0.9078, recall: 0.6879, f1: 0.7827, edges-ner-ontonotes_loss: 0.0625
09/16 06:16:08 AM: Update 4878: task edges-ner-ontonotes, batch 878 (4878): mcc: 0.8319, acc: 0.7483, precision: 0.9058, recall: 0.7797, f1: 0.8381, edges-ner-ontonotes_loss: 0.0524
09/16 06:16:15 AM: Evaluate: task edges-ner-ontonotes, batch 72 (157): mcc: 0.8612, acc: 0.7906, precision: 0.9336, recall: 0.8075, f1: 0.8660, edges-ner-ontonotes_loss: 0.0441
09/16 06:16:18 AM: Update 4936: task edges-ner-ontonotes, batch 936 (4936): mcc: 0.8309, acc: 0.7470, precision: 0.9053, recall: 0.7785, f1: 0.8371, edges-ner-ontonotes_loss: 0.0526
09/16 06:16:25 AM: Evaluate: task edges-ner-ontonotes, batch 126 (157): mcc: 0.8798, acc: 0.8154, precision: 0.9432, recall: 0.8322, f1: 0.8842, edges-ner-ontonotes_loss: 0.0389
09/16 06:16:29 AM: Update 4982: task edges-ner-ontonotes, batch 982 (4982): mcc: 0.8301, acc: 0.7459, precision: 0.9047, recall: 0.7775, f1: 0.8363, edges-ner-ontonotes_loss: 0.0529
09/16 06:16:30 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:16:30 AM: Best result seen so far for macro.
09/16 06:16:30 AM: Updating LR scheduler:
09/16 06:16:30 AM: 	Best result seen so far for macro_avg: 0.886
09/16 06:16:30 AM: 	# validation passes without improvement: 0
09/16 06:16:30 AM: edges-ner-ontonotes_loss: training: 0.052802 validation: 0.037694
09/16 06:16:30 AM: macro_avg: validation: 0.885955
09/16 06:16:30 AM: micro_avg: validation: 0.000000
09/16 06:16:30 AM: edges-ner-ontonotes_mcc: training: 0.830224 validation: 0.881559
09/16 06:16:30 AM: edges-ner-ontonotes_acc: training: 0.746014 validation: 0.817031
09/16 06:16:30 AM: edges-ner-ontonotes_precision: training: 0.904920 validation: 0.944306
09/16 06:16:30 AM: edges-ner-ontonotes_recall: training: 0.777580 validation: 0.834395
09/16 06:16:30 AM: edges-ner-ontonotes_f1: training: 0.836431 validation: 0.885955
09/16 06:16:30 AM: Global learning rate: 0.0001
09/16 06:16:30 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:16:32 AM: ***** Step 5000 / Validation 5 *****
09/16 06:16:35 AM: Update 5049: task edges-ner-ontonotes, batch 49 (5049): mcc: 0.8349, acc: 0.7568, precision: 0.9040, recall: 0.7867, f1: 0.8413, edges-ner-ontonotes_loss: 0.0499
09/16 06:16:36 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:16:36 AM: Validating...
09/16 06:16:39 AM: Evaluate: task edges-ner-ontonotes, batch 23 (157): mcc: 0.8031, acc: 0.7180, precision: 0.8971, recall: 0.7365, f1: 0.8089, edges-ner-ontonotes_loss: 0.0580
09/16 06:16:46 AM: Update 5105: task edges-ner-ontonotes, batch 105 (5105): mcc: 0.8385, acc: 0.7590, precision: 0.9070, recall: 0.7906, f1: 0.8448, edges-ner-ontonotes_loss: 0.0482
09/16 06:16:49 AM: Evaluate: task edges-ner-ontonotes, batch 78 (157): mcc: 0.8669, acc: 0.7981, precision: 0.9368, recall: 0.8148, f1: 0.8715, edges-ner-ontonotes_loss: 0.0429
09/16 06:16:56 AM: Update 5163: task edges-ner-ontonotes, batch 163 (5163): mcc: 0.8406, acc: 0.7609, precision: 0.9083, recall: 0.7931, f1: 0.8468, edges-ner-ontonotes_loss: 0.0476
09/16 06:17:00 AM: Evaluate: task edges-ner-ontonotes, batch 131 (157): mcc: 0.8806, acc: 0.8165, precision: 0.9436, recall: 0.8333, f1: 0.8850, edges-ner-ontonotes_loss: 0.0386
09/16 06:17:04 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:17:05 AM: Best result seen so far for macro.
09/16 06:17:05 AM: Updating LR scheduler:
09/16 06:17:05 AM: 	Best result seen so far for macro_avg: 0.886
09/16 06:17:05 AM: 	# validation passes without improvement: 0
09/16 06:17:05 AM: edges-ner-ontonotes_loss: training: 0.052802 validation: 0.037694
09/16 06:17:05 AM: macro_avg: validation: 0.885955
09/16 06:17:05 AM: micro_avg: validation: 0.000000
09/16 06:17:05 AM: edges-ner-ontonotes_mcc: training: 0.830224 validation: 0.881559
09/16 06:17:05 AM: edges-ner-ontonotes_acc: training: 0.746014 validation: 0.817031
09/16 06:17:05 AM: edges-ner-ontonotes_precision: training: 0.904920 validation: 0.944306
09/16 06:17:05 AM: edges-ner-ontonotes_recall: training: 0.777580 validation: 0.834395
09/16 06:17:05 AM: edges-ner-ontonotes_f1: training: 0.836431 validation: 0.885955
09/16 06:17:05 AM: Global learning rate: 0.0001
09/16 06:17:05 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:17:08 AM: Update 5226: task edges-ner-ontonotes, batch 226 (5226): mcc: 0.8413, acc: 0.7618, precision: 0.9091, recall: 0.7937, f1: 0.8475, edges-ner-ontonotes_loss: 0.0473
09/16 06:17:10 AM: Update 5033: task edges-ner-ontonotes, batch 33 (5033): mcc: 0.8318, acc: 0.7531, precision: 0.9043, recall: 0.7809, f1: 0.8381, edges-ner-ontonotes_loss: 0.0501
09/16 06:17:20 AM: Update 5112: task edges-ner-ontonotes, batch 112 (5112): mcc: 0.8384, acc: 0.7588, precision: 0.9069, recall: 0.7904, f1: 0.8447, edges-ner-ontonotes_loss: 0.0483
09/16 06:17:20 AM: Update 5295: task edges-ner-ontonotes, batch 295 (5295): mcc: 0.8439, acc: 0.7648, precision: 0.9110, recall: 0.7967, f1: 0.8500, edges-ner-ontonotes_loss: 0.0463
09/16 06:17:30 AM: Update 5181: task edges-ner-ontonotes, batch 181 (5181): mcc: 0.8413, acc: 0.7620, precision: 0.9086, recall: 0.7942, f1: 0.8475, edges-ner-ontonotes_loss: 0.0475
09/16 06:17:30 AM: Update 5366: task edges-ner-ontonotes, batch 366 (5366): mcc: 0.8481, acc: 0.7709, precision: 0.9129, recall: 0.8025, f1: 0.8541, edges-ner-ontonotes_loss: 0.0449
09/16 06:17:40 AM: Update 5258: task edges-ner-ontonotes, batch 258 (5258): mcc: 0.8424, acc: 0.7632, precision: 0.9100, recall: 0.7949, f1: 0.8486, edges-ner-ontonotes_loss: 0.0469
09/16 06:17:40 AM: Update 5442: task edges-ner-ontonotes, batch 442 (5442): mcc: 0.8509, acc: 0.7751, precision: 0.9142, recall: 0.8064, f1: 0.8569, edges-ner-ontonotes_loss: 0.0442
09/16 06:17:50 AM: Update 5313: task edges-ner-ontonotes, batch 313 (5313): mcc: 0.8448, acc: 0.7659, precision: 0.9112, recall: 0.7980, f1: 0.8509, edges-ner-ontonotes_loss: 0.0460
09/16 06:17:50 AM: Update 5516: task edges-ner-ontonotes, batch 516 (5516): mcc: 0.8538, acc: 0.7789, precision: 0.9160, recall: 0.8101, f1: 0.8598, edges-ner-ontonotes_loss: 0.0437
09/16 06:18:00 AM: Update 5384: task edges-ner-ontonotes, batch 384 (5384): mcc: 0.8483, acc: 0.7712, precision: 0.9127, recall: 0.8030, f1: 0.8543, edges-ner-ontonotes_loss: 0.0449
09/16 06:18:00 AM: Update 5587: task edges-ner-ontonotes, batch 587 (5587): mcc: 0.8561, acc: 0.7819, precision: 0.9173, recall: 0.8129, f1: 0.8619, edges-ner-ontonotes_loss: 0.0431
09/16 06:18:10 AM: Update 5465: task edges-ner-ontonotes, batch 465 (5465): mcc: 0.8518, acc: 0.7762, precision: 0.9146, recall: 0.8077, f1: 0.8578, edges-ner-ontonotes_loss: 0.0441
09/16 06:18:10 AM: Update 5631: task edges-ner-ontonotes, batch 631 (5631): mcc: 0.8564, acc: 0.7824, precision: 0.9173, recall: 0.8136, f1: 0.8623, edges-ner-ontonotes_loss: 0.0430
09/16 06:18:20 AM: Update 5534: task edges-ner-ontonotes, batch 534 (5534): mcc: 0.8545, acc: 0.7799, precision: 0.9163, recall: 0.8110, f1: 0.8604, edges-ner-ontonotes_loss: 0.0435
09/16 06:18:20 AM: Update 5700: task edges-ner-ontonotes, batch 700 (5700): mcc: 0.8576, acc: 0.7842, precision: 0.9173, recall: 0.8157, f1: 0.8635, edges-ner-ontonotes_loss: 0.0427
09/16 06:18:30 AM: Update 5603: task edges-ner-ontonotes, batch 603 (5603): mcc: 0.8564, acc: 0.7824, precision: 0.9174, recall: 0.8134, f1: 0.8623, edges-ner-ontonotes_loss: 0.0430
09/16 06:18:30 AM: Update 5774: task edges-ner-ontonotes, batch 774 (5774): mcc: 0.8585, acc: 0.7855, precision: 0.9180, recall: 0.8167, f1: 0.8644, edges-ner-ontonotes_loss: 0.0424
09/16 06:18:40 AM: Update 5648: task edges-ner-ontonotes, batch 648 (5648): mcc: 0.8567, acc: 0.7828, precision: 0.9174, recall: 0.8140, f1: 0.8626, edges-ner-ontonotes_loss: 0.0429
09/16 06:18:40 AM: Update 5859: task edges-ner-ontonotes, batch 859 (5859): mcc: 0.8594, acc: 0.7868, precision: 0.9182, recall: 0.8181, f1: 0.8653, edges-ner-ontonotes_loss: 0.0423
09/16 06:18:50 AM: Update 5716: task edges-ner-ontonotes, batch 716 (5716): mcc: 0.8578, acc: 0.7845, precision: 0.9172, recall: 0.8160, f1: 0.8637, edges-ner-ontonotes_loss: 0.0426
09/16 06:18:52 AM: Update 5921: task edges-ner-ontonotes, batch 921 (5921): mcc: 0.8600, acc: 0.7876, precision: 0.9183, recall: 0.8191, f1: 0.8659, edges-ner-ontonotes_loss: 0.0422
09/16 06:19:00 AM: Update 5797: task edges-ner-ontonotes, batch 797 (5797): mcc: 0.8587, acc: 0.7857, precision: 0.9181, recall: 0.8169, f1: 0.8645, edges-ner-ontonotes_loss: 0.0424
09/16 06:19:02 AM: Update 5989: task edges-ner-ontonotes, batch 989 (5989): mcc: 0.8570, acc: 0.7835, precision: 0.9166, recall: 0.8151, f1: 0.8629, edges-ner-ontonotes_loss: 0.0433
09/16 06:19:03 AM: ***** Step 6000 / Validation 6 *****
09/16 06:19:03 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:19:03 AM: Validating...
09/16 06:19:10 AM: Update 5857: task edges-ner-ontonotes, batch 857 (5857): mcc: 0.8593, acc: 0.7866, precision: 0.9181, recall: 0.8179, f1: 0.8651, edges-ner-ontonotes_loss: 0.0424
09/16 06:19:12 AM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.8555, acc: 0.7858, precision: 0.9260, recall: 0.8040, f1: 0.8607, edges-ner-ontonotes_loss: 0.0465
09/16 06:19:20 AM: Update 5908: task edges-ner-ontonotes, batch 908 (5908): mcc: 0.8600, acc: 0.7876, precision: 0.9184, recall: 0.8190, f1: 0.8658, edges-ner-ontonotes_loss: 0.0422
09/16 06:19:22 AM: Evaluate: task edges-ner-ontonotes, batch 105 (157): mcc: 0.8761, acc: 0.8124, precision: 0.9369, recall: 0.8312, f1: 0.8809, edges-ner-ontonotes_loss: 0.0408
09/16 06:19:31 AM: Update 5952: task edges-ner-ontonotes, batch 952 (5952): mcc: 0.8584, acc: 0.7853, precision: 0.9175, recall: 0.8168, f1: 0.8642, edges-ner-ontonotes_loss: 0.0428
09/16 06:19:32 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:19:33 AM: Best result seen so far for macro.
09/16 06:19:33 AM: Updating LR scheduler:
09/16 06:19:33 AM: 	Best result seen so far for macro_avg: 0.893
09/16 06:19:33 AM: 	# validation passes without improvement: 0
09/16 06:19:33 AM: edges-ner-ontonotes_loss: training: 0.043533 validation: 0.036858
09/16 06:19:33 AM: macro_avg: validation: 0.892726
09/16 06:19:33 AM: micro_avg: validation: 0.000000
09/16 06:19:33 AM: edges-ner-ontonotes_mcc: training: 0.856523 validation: 0.888231
09/16 06:19:33 AM: edges-ner-ontonotes_acc: training: 0.782850 validation: 0.827950
09/16 06:19:33 AM: edges-ner-ontonotes_precision: training: 0.916425 validation: 0.943881
09/16 06:19:33 AM: edges-ner-ontonotes_recall: training: 0.814489 validation: 0.846830
09/16 06:19:33 AM: edges-ner-ontonotes_f1: training: 0.862456 validation: 0.892726
09/16 06:19:33 AM: Global learning rate: 0.0001
09/16 06:19:33 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:19:33 AM: Update 6001: task edges-ner-ontonotes, batch 1 (6001): mcc: 0.8438, acc: 0.7643, precision: 0.9185, recall: 0.7898, f1: 0.8493, edges-ner-ontonotes_loss: 0.0429
09/16 06:19:40 AM: ***** Step 6000 / Validation 6 *****
09/16 06:19:40 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:19:40 AM: Validating...
09/16 06:19:43 AM: Evaluate: task edges-ner-ontonotes, batch 19 (157): mcc: 0.8071, acc: 0.7155, precision: 0.9101, recall: 0.7325, f1: 0.8117, edges-ner-ontonotes_loss: 0.0542
09/16 06:19:43 AM: Update 6069: task edges-ner-ontonotes, batch 69 (6069): mcc: 0.8195, acc: 0.7339, precision: 0.8976, recall: 0.7649, f1: 0.8259, edges-ner-ontonotes_loss: 0.0578
09/16 06:19:54 AM: Evaluate: task edges-ner-ontonotes, batch 76 (157): mcc: 0.8660, acc: 0.7990, precision: 0.9320, recall: 0.8176, f1: 0.8710, edges-ner-ontonotes_loss: 0.0440
09/16 06:19:54 AM: Update 6124: task edges-ner-ontonotes, batch 124 (6124): mcc: 0.8121, acc: 0.7259, precision: 0.8912, recall: 0.7574, f1: 0.8189, edges-ner-ontonotes_loss: 0.0590
09/16 06:20:04 AM: Evaluate: task edges-ner-ontonotes, batch 125 (157): mcc: 0.8842, acc: 0.8229, precision: 0.9410, recall: 0.8422, f1: 0.8889, edges-ner-ontonotes_loss: 0.0387
09/16 06:20:04 AM: Update 6181: task edges-ner-ontonotes, batch 181 (6181): mcc: 0.8154, acc: 0.7308, precision: 0.8939, recall: 0.7609, f1: 0.8220, edges-ner-ontonotes_loss: 0.0581
09/16 06:20:10 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:20:10 AM: Best result seen so far for macro.
09/16 06:20:10 AM: Updating LR scheduler:
09/16 06:20:10 AM: 	Best result seen so far for macro_avg: 0.893
09/16 06:20:10 AM: 	# validation passes without improvement: 0
09/16 06:20:10 AM: edges-ner-ontonotes_loss: training: 0.043533 validation: 0.036858
09/16 06:20:10 AM: macro_avg: validation: 0.892726
09/16 06:20:10 AM: micro_avg: validation: 0.000000
09/16 06:20:10 AM: edges-ner-ontonotes_mcc: training: 0.856523 validation: 0.888231
09/16 06:20:10 AM: edges-ner-ontonotes_acc: training: 0.782850 validation: 0.827950
09/16 06:20:10 AM: edges-ner-ontonotes_precision: training: 0.916425 validation: 0.943881
09/16 06:20:10 AM: edges-ner-ontonotes_recall: training: 0.814489 validation: 0.846830
09/16 06:20:10 AM: edges-ner-ontonotes_f1: training: 0.862456 validation: 0.892726
09/16 06:20:10 AM: Global learning rate: 0.0001
09/16 06:20:10 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:20:14 AM: Update 6032: task edges-ner-ontonotes, batch 32 (6032): mcc: 0.8269, acc: 0.7415, precision: 0.9040, recall: 0.7724, f1: 0.8331, edges-ner-ontonotes_loss: 0.0548
09/16 06:20:14 AM: Update 6230: task edges-ner-ontonotes, batch 230 (6230): mcc: 0.8142, acc: 0.7300, precision: 0.8926, recall: 0.7600, f1: 0.8210, edges-ner-ontonotes_loss: 0.0585
09/16 06:20:24 AM: Update 6123: task edges-ner-ontonotes, batch 123 (6123): mcc: 0.8114, acc: 0.7251, precision: 0.8906, recall: 0.7567, f1: 0.8182, edges-ner-ontonotes_loss: 0.0592
09/16 06:20:27 AM: Update 6313: task edges-ner-ontonotes, batch 313 (6313): mcc: 0.8145, acc: 0.7288, precision: 0.8924, recall: 0.7607, f1: 0.8213, edges-ner-ontonotes_loss: 0.0576
09/16 06:20:34 AM: Update 6201: task edges-ner-ontonotes, batch 201 (6201): mcc: 0.8153, acc: 0.7306, precision: 0.8938, recall: 0.7607, f1: 0.8219, edges-ner-ontonotes_loss: 0.0585
09/16 06:20:38 AM: Update 6398: task edges-ner-ontonotes, batch 398 (6398): mcc: 0.8137, acc: 0.7276, precision: 0.8911, recall: 0.7604, f1: 0.8205, edges-ner-ontonotes_loss: 0.0573
09/16 06:20:44 AM: Update 6258: task edges-ner-ontonotes, batch 258 (6258): mcc: 0.8150, acc: 0.7296, precision: 0.8925, recall: 0.7614, f1: 0.8217, edges-ner-ontonotes_loss: 0.0578
09/16 06:20:48 AM: Update 6494: task edges-ner-ontonotes, batch 494 (6494): mcc: 0.8146, acc: 0.7289, precision: 0.8912, recall: 0.7618, f1: 0.8214, edges-ner-ontonotes_loss: 0.0565
09/16 06:20:55 AM: Update 6356: task edges-ner-ontonotes, batch 356 (6356): mcc: 0.8146, acc: 0.7287, precision: 0.8923, recall: 0.7609, f1: 0.8214, edges-ner-ontonotes_loss: 0.0573
09/16 06:20:58 AM: Update 6554: task edges-ner-ontonotes, batch 554 (6554): mcc: 0.8153, acc: 0.7290, precision: 0.8917, recall: 0.7626, f1: 0.8221, edges-ner-ontonotes_loss: 0.0560
09/16 06:21:05 AM: Update 6441: task edges-ner-ontonotes, batch 441 (6441): mcc: 0.8142, acc: 0.7283, precision: 0.8911, recall: 0.7613, f1: 0.8211, edges-ner-ontonotes_loss: 0.0569
09/16 06:21:08 AM: Update 6632: task edges-ner-ontonotes, batch 632 (6632): mcc: 0.8204, acc: 0.7356, precision: 0.8943, recall: 0.7694, f1: 0.8272, edges-ner-ontonotes_loss: 0.0545
09/16 06:21:15 AM: Update 6521: task edges-ner-ontonotes, batch 521 (6521): mcc: 0.8140, acc: 0.7277, precision: 0.8910, recall: 0.7610, f1: 0.8209, edges-ner-ontonotes_loss: 0.0565
09/16 06:21:18 AM: Update 6714: task edges-ner-ontonotes, batch 714 (6714): mcc: 0.8232, acc: 0.7396, precision: 0.8955, recall: 0.7734, f1: 0.8300, edges-ner-ontonotes_loss: 0.0537
09/16 06:21:25 AM: Update 6578: task edges-ner-ontonotes, batch 578 (6578): mcc: 0.8169, acc: 0.7312, precision: 0.8925, recall: 0.7648, f1: 0.8237, edges-ner-ontonotes_loss: 0.0556
09/16 06:21:28 AM: Update 6791: task edges-ner-ontonotes, batch 791 (6791): mcc: 0.8268, acc: 0.7440, precision: 0.8977, recall: 0.7779, f1: 0.8335, edges-ner-ontonotes_loss: 0.0527
09/16 06:21:35 AM: Update 6649: task edges-ner-ontonotes, batch 649 (6649): mcc: 0.8210, acc: 0.7364, precision: 0.8946, recall: 0.7703, f1: 0.8278, edges-ner-ontonotes_loss: 0.0543
09/16 06:21:39 AM: Update 6851: task edges-ner-ontonotes, batch 851 (6851): mcc: 0.8287, acc: 0.7463, precision: 0.8987, recall: 0.7804, f1: 0.8354, edges-ner-ontonotes_loss: 0.0520
09/16 06:21:45 AM: Update 6731: task edges-ner-ontonotes, batch 731 (6731): mcc: 0.8245, acc: 0.7412, precision: 0.8964, recall: 0.7749, f1: 0.8313, edges-ner-ontonotes_loss: 0.0534
09/16 06:21:49 AM: Update 6930: task edges-ner-ontonotes, batch 930 (6930): mcc: 0.8327, acc: 0.7517, precision: 0.9012, recall: 0.7854, f1: 0.8393, edges-ner-ontonotes_loss: 0.0509
09/16 06:21:55 AM: Update 6801: task edges-ner-ontonotes, batch 801 (6801): mcc: 0.8271, acc: 0.7442, precision: 0.8980, recall: 0.7781, f1: 0.8338, edges-ner-ontonotes_loss: 0.0526
09/16 06:21:59 AM: Update 6997: task edges-ner-ontonotes, batch 997 (6997): mcc: 0.8362, acc: 0.7563, precision: 0.9031, recall: 0.7899, f1: 0.8427, edges-ner-ontonotes_loss: 0.0500
09/16 06:22:00 AM: ***** Step 7000 / Validation 7 *****
09/16 06:22:00 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:22:00 AM: Validating...
09/16 06:22:05 AM: Update 6851: task edges-ner-ontonotes, batch 851 (6851): mcc: 0.8287, acc: 0.7463, precision: 0.8987, recall: 0.7804, f1: 0.8354, edges-ner-ontonotes_loss: 0.0520
09/16 06:22:09 AM: Evaluate: task edges-ner-ontonotes, batch 62 (157): mcc: 0.8689, acc: 0.8062, precision: 0.9289, recall: 0.8254, f1: 0.8741, edges-ner-ontonotes_loss: 0.0429
09/16 06:22:15 AM: Update 6916: task edges-ner-ontonotes, batch 916 (6916): mcc: 0.8318, acc: 0.7504, precision: 0.9006, recall: 0.7843, f1: 0.8384, edges-ner-ontonotes_loss: 0.0511
09/16 06:22:21 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.8853, acc: 0.8273, precision: 0.9386, recall: 0.8463, f1: 0.8901, edges-ner-ontonotes_loss: 0.0384
09/16 06:22:26 AM: Update 6967: task edges-ner-ontonotes, batch 967 (6967): mcc: 0.8349, acc: 0.7546, precision: 0.9024, recall: 0.7881, f1: 0.8414, edges-ner-ontonotes_loss: 0.0504
09/16 06:22:29 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:22:29 AM: Best result seen so far for macro.
09/16 06:22:29 AM: Updating LR scheduler:
09/16 06:22:29 AM: 	Best result seen so far for macro_avg: 0.898
09/16 06:22:29 AM: 	# validation passes without improvement: 0
09/16 06:22:29 AM: edges-ner-ontonotes_loss: training: 0.049950 validation: 0.035392
09/16 06:22:29 AM: macro_avg: validation: 0.898254
09/16 06:22:29 AM: micro_avg: validation: 0.000000
09/16 06:22:29 AM: edges-ner-ontonotes_mcc: training: 0.836361 validation: 0.893649
09/16 06:22:29 AM: edges-ner-ontonotes_acc: training: 0.756505 validation: 0.838641
09/16 06:22:29 AM: edges-ner-ontonotes_precision: training: 0.903167 validation: 0.942224
09/16 06:22:29 AM: edges-ner-ontonotes_recall: training: 0.790134 validation: 0.858204
09/16 06:22:29 AM: edges-ner-ontonotes_f1: training: 0.842878 validation: 0.898254
09/16 06:22:29 AM: Global learning rate: 0.0001
09/16 06:22:29 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:22:31 AM: Update 7014: task edges-ner-ontonotes, batch 14 (7014): mcc: 0.8806, acc: 0.8191, precision: 0.9240, recall: 0.8514, f1: 0.8862, edges-ner-ontonotes_loss: 0.0369
09/16 06:22:31 AM: ***** Step 7000 / Validation 7 *****
09/16 06:22:33 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:22:33 AM: Validating...
09/16 06:22:36 AM: Evaluate: task edges-ner-ontonotes, batch 20 (157): mcc: 0.8155, acc: 0.7273, precision: 0.9086, recall: 0.7484, f1: 0.8208, edges-ner-ontonotes_loss: 0.0540
09/16 06:22:43 AM: Update 7081: task edges-ner-ontonotes, batch 81 (7081): mcc: 0.8764, acc: 0.8114, precision: 0.9232, recall: 0.8443, f1: 0.8820, edges-ner-ontonotes_loss: 0.0388
09/16 06:22:47 AM: Evaluate: task edges-ner-ontonotes, batch 76 (157): mcc: 0.8729, acc: 0.8104, precision: 0.9341, recall: 0.8281, f1: 0.8779, edges-ner-ontonotes_loss: 0.0423
09/16 06:22:53 AM: Update 7134: task edges-ner-ontonotes, batch 134 (7134): mcc: 0.8769, acc: 0.8110, precision: 0.9252, recall: 0.8434, f1: 0.8824, edges-ner-ontonotes_loss: 0.0382
09/16 06:22:57 AM: Evaluate: task edges-ner-ontonotes, batch 123 (157): mcc: 0.8891, acc: 0.8324, precision: 0.9403, recall: 0.8517, f1: 0.8938, edges-ner-ontonotes_loss: 0.0374
09/16 06:23:03 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:23:03 AM: Best result seen so far for macro.
09/16 06:23:03 AM: Updating LR scheduler:
09/16 06:23:03 AM: 	Best result seen so far for macro_avg: 0.898
09/16 06:23:03 AM: 	# validation passes without improvement: 0
09/16 06:23:03 AM: edges-ner-ontonotes_loss: training: 0.049950 validation: 0.035392
09/16 06:23:03 AM: macro_avg: validation: 0.898254
09/16 06:23:03 AM: micro_avg: validation: 0.000000
09/16 06:23:03 AM: edges-ner-ontonotes_mcc: training: 0.836361 validation: 0.893649
09/16 06:23:03 AM: edges-ner-ontonotes_acc: training: 0.756505 validation: 0.838641
09/16 06:23:03 AM: edges-ner-ontonotes_precision: training: 0.903167 validation: 0.942224
09/16 06:23:03 AM: edges-ner-ontonotes_recall: training: 0.790134 validation: 0.858204
09/16 06:23:03 AM: edges-ner-ontonotes_f1: training: 0.842878 validation: 0.898254
09/16 06:23:03 AM: Global learning rate: 0.0001
09/16 06:23:03 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:23:03 AM: Update 7177: task edges-ner-ontonotes, batch 177 (7177): mcc: 0.8767, acc: 0.8113, precision: 0.9255, recall: 0.8428, f1: 0.8822, edges-ner-ontonotes_loss: 0.0380
09/16 06:23:07 AM: Update 7003: task edges-ner-ontonotes, batch 3 (7003): mcc: 0.9190, acc: 0.8745, precision: 0.9356, recall: 0.9114, f1: 0.9234, edges-ner-ontonotes_loss: 0.0307
09/16 06:23:13 AM: Update 7263: task edges-ner-ontonotes, batch 263 (7263): mcc: 0.8743, acc: 0.8076, precision: 0.9240, recall: 0.8398, f1: 0.8799, edges-ner-ontonotes_loss: 0.0387
09/16 06:23:17 AM: Update 7078: task edges-ner-ontonotes, batch 78 (7078): mcc: 0.8765, acc: 0.8118, precision: 0.9228, recall: 0.8449, f1: 0.8821, edges-ner-ontonotes_loss: 0.0384
09/16 06:23:23 AM: Update 7335: task edges-ner-ontonotes, batch 335 (7335): mcc: 0.8745, acc: 0.8081, precision: 0.9234, recall: 0.8408, f1: 0.8802, edges-ner-ontonotes_loss: 0.0385
09/16 06:23:28 AM: Update 7142: task edges-ner-ontonotes, batch 142 (7142): mcc: 0.8773, acc: 0.8116, precision: 0.9257, recall: 0.8436, f1: 0.8828, edges-ner-ontonotes_loss: 0.0382
09/16 06:23:33 AM: Update 7412: task edges-ner-ontonotes, batch 412 (7412): mcc: 0.8737, acc: 0.8068, precision: 0.9224, recall: 0.8403, f1: 0.8794, edges-ner-ontonotes_loss: 0.0385
09/16 06:23:39 AM: Update 7200: task edges-ner-ontonotes, batch 200 (7200): mcc: 0.8757, acc: 0.8093, precision: 0.9251, recall: 0.8413, f1: 0.8812, edges-ner-ontonotes_loss: 0.0381
09/16 06:23:45 AM: Update 7477: task edges-ner-ontonotes, batch 477 (7477): mcc: 0.8735, acc: 0.8062, precision: 0.9221, recall: 0.8401, f1: 0.8792, edges-ner-ontonotes_loss: 0.0388
09/16 06:23:51 AM: Update 7283: task edges-ner-ontonotes, batch 283 (7283): mcc: 0.8741, acc: 0.8075, precision: 0.9237, recall: 0.8397, f1: 0.8797, edges-ner-ontonotes_loss: 0.0388
09/16 06:23:55 AM: Update 7553: task edges-ner-ontonotes, batch 553 (7553): mcc: 0.8664, acc: 0.7967, precision: 0.9180, recall: 0.8310, f1: 0.8723, edges-ner-ontonotes_loss: 0.0415
09/16 06:24:01 AM: Update 7347: task edges-ner-ontonotes, batch 347 (7347): mcc: 0.8745, acc: 0.8079, precision: 0.9233, recall: 0.8409, f1: 0.8802, edges-ner-ontonotes_loss: 0.0384
09/16 06:24:05 AM: Update 7618: task edges-ner-ontonotes, batch 618 (7618): mcc: 0.8620, acc: 0.7912, precision: 0.9157, recall: 0.8250, f1: 0.8680, edges-ner-ontonotes_loss: 0.0428
09/16 06:24:11 AM: Update 7419: task edges-ner-ontonotes, batch 419 (7419): mcc: 0.8735, acc: 0.8064, precision: 0.9224, recall: 0.8398, f1: 0.8792, edges-ner-ontonotes_loss: 0.0387
09/16 06:24:16 AM: Update 7706: task edges-ner-ontonotes, batch 706 (7706): mcc: 0.8572, acc: 0.7844, precision: 0.9132, recall: 0.8187, f1: 0.8633, edges-ner-ontonotes_loss: 0.0446
09/16 06:24:25 AM: Update 7477: task edges-ner-ontonotes, batch 477 (7477): mcc: 0.8735, acc: 0.8062, precision: 0.9221, recall: 0.8401, f1: 0.8792, edges-ner-ontonotes_loss: 0.0388
09/16 06:24:27 AM: Update 7781: task edges-ner-ontonotes, batch 781 (7781): mcc: 0.8544, acc: 0.7808, precision: 0.9115, recall: 0.8152, f1: 0.8607, edges-ner-ontonotes_loss: 0.0458
09/16 06:24:35 AM: Update 7561: task edges-ner-ontonotes, batch 561 (7561): mcc: 0.8659, acc: 0.7960, precision: 0.9179, recall: 0.8301, f1: 0.8718, edges-ner-ontonotes_loss: 0.0416
09/16 06:24:37 AM: Update 7857: task edges-ner-ontonotes, batch 857 (7857): mcc: 0.8518, acc: 0.7773, precision: 0.9099, recall: 0.8119, f1: 0.8581, edges-ner-ontonotes_loss: 0.0465
09/16 06:24:45 AM: Update 7639: task edges-ner-ontonotes, batch 639 (7639): mcc: 0.8608, acc: 0.7893, precision: 0.9153, recall: 0.8233, f1: 0.8669, edges-ner-ontonotes_loss: 0.0432
09/16 06:24:47 AM: Update 7942: task edges-ner-ontonotes, batch 942 (7942): mcc: 0.8498, acc: 0.7743, precision: 0.9089, recall: 0.8092, f1: 0.8562, edges-ner-ontonotes_loss: 0.0471
09/16 06:24:55 AM: ***** Step 8000 / Validation 8 *****
09/16 06:24:55 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:24:55 AM: Validating...
09/16 06:24:55 AM: Update 7714: task edges-ner-ontonotes, batch 714 (7714): mcc: 0.8568, acc: 0.7838, precision: 0.9130, recall: 0.8182, f1: 0.8630, edges-ner-ontonotes_loss: 0.0448
09/16 06:24:57 AM: Evaluate: task edges-ner-ontonotes, batch 17 (157): mcc: 0.8200, acc: 0.7236, precision: 0.9268, recall: 0.7409, f1: 0.8235, edges-ner-ontonotes_loss: 0.0522
09/16 06:25:05 AM: Update 7771: task edges-ner-ontonotes, batch 771 (7771): mcc: 0.8549, acc: 0.7814, precision: 0.9119, recall: 0.8157, f1: 0.8611, edges-ner-ontonotes_loss: 0.0456
09/16 06:25:07 AM: Evaluate: task edges-ner-ontonotes, batch 75 (157): mcc: 0.8761, acc: 0.8107, precision: 0.9411, recall: 0.8274, f1: 0.8806, edges-ner-ontonotes_loss: 0.0405
09/16 06:25:15 AM: Update 7812: task edges-ner-ontonotes, batch 812 (7812): mcc: 0.8533, acc: 0.7794, precision: 0.9108, recall: 0.8138, f1: 0.8596, edges-ner-ontonotes_loss: 0.0462
09/16 06:25:17 AM: Evaluate: task edges-ner-ontonotes, batch 132 (157): mcc: 0.8932, acc: 0.8339, precision: 0.9505, recall: 0.8499, f1: 0.8974, edges-ner-ontonotes_loss: 0.0354
09/16 06:25:22 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:25:22 AM: Best result seen so far for macro.
09/16 06:25:22 AM: Updating LR scheduler:
09/16 06:25:22 AM: 	Best result seen so far for macro_avg: 0.899
09/16 06:25:22 AM: 	# validation passes without improvement: 0
09/16 06:25:22 AM: edges-ner-ontonotes_loss: training: 0.047503 validation: 0.034488
09/16 06:25:22 AM: macro_avg: validation: 0.898588
09/16 06:25:22 AM: micro_avg: validation: 0.000000
09/16 06:25:22 AM: edges-ner-ontonotes_mcc: training: 0.848429 validation: 0.894487
09/16 06:25:22 AM: edges-ner-ontonotes_acc: training: 0.772265 validation: 0.835608
09/16 06:25:22 AM: edges-ner-ontonotes_precision: training: 0.908069 validation: 0.951054
09/16 06:25:22 AM: edges-ner-ontonotes_recall: training: 0.807460 validation: 0.851608
09/16 06:25:22 AM: edges-ner-ontonotes_f1: training: 0.854815 validation: 0.898588
09/16 06:25:22 AM: Global learning rate: 0.0001
09/16 06:25:22 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:25:25 AM: Update 7886: task edges-ner-ontonotes, batch 886 (7886): mcc: 0.8510, acc: 0.7761, precision: 0.9095, recall: 0.8108, f1: 0.8573, edges-ner-ontonotes_loss: 0.0468
09/16 06:25:27 AM: Update 8041: task edges-ner-ontonotes, batch 41 (8041): mcc: 0.8209, acc: 0.7318, precision: 0.8957, recall: 0.7691, f1: 0.8276, edges-ner-ontonotes_loss: 0.0546
09/16 06:25:35 AM: Update 7981: task edges-ner-ontonotes, batch 981 (7981): mcc: 0.8486, acc: 0.7726, precision: 0.9082, recall: 0.8077, f1: 0.8550, edges-ner-ontonotes_loss: 0.0475
09/16 06:25:38 AM: Update 8100: task edges-ner-ontonotes, batch 100 (8100): mcc: 0.8246, acc: 0.7394, precision: 0.8927, recall: 0.7785, f1: 0.8317, edges-ner-ontonotes_loss: 0.0533
09/16 06:25:38 AM: ***** Step 8000 / Validation 8 *****
09/16 06:25:38 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:25:38 AM: Validating...
09/16 06:25:46 AM: Evaluate: task edges-ner-ontonotes, batch 49 (157): mcc: 0.8642, acc: 0.7930, precision: 0.9352, recall: 0.8114, f1: 0.8689, edges-ner-ontonotes_loss: 0.0436
09/16 06:25:48 AM: Update 8156: task edges-ner-ontonotes, batch 156 (8156): mcc: 0.8362, acc: 0.7565, precision: 0.9002, recall: 0.7925, f1: 0.8429, edges-ner-ontonotes_loss: 0.0498
09/16 06:25:56 AM: Evaluate: task edges-ner-ontonotes, batch 101 (157): mcc: 0.8825, acc: 0.8182, precision: 0.9460, recall: 0.8346, f1: 0.8868, edges-ner-ontonotes_loss: 0.0382
09/16 06:25:58 AM: Update 8212: task edges-ner-ontonotes, batch 212 (8212): mcc: 0.8424, acc: 0.7647, precision: 0.9039, recall: 0.8004, f1: 0.8490, edges-ner-ontonotes_loss: 0.0479
09/16 06:26:06 AM: Evaluate: task edges-ner-ontonotes, batch 152 (157): mcc: 0.8943, acc: 0.8353, precision: 0.9510, recall: 0.8513, f1: 0.8984, edges-ner-ontonotes_loss: 0.0347
09/16 06:26:07 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:26:07 AM: Best result seen so far for macro.
09/16 06:26:07 AM: Updating LR scheduler:
09/16 06:26:07 AM: 	Best result seen so far for macro_avg: 0.899
09/16 06:26:07 AM: 	# validation passes without improvement: 0
09/16 06:26:07 AM: edges-ner-ontonotes_loss: training: 0.047503 validation: 0.034488
09/16 06:26:07 AM: macro_avg: validation: 0.898588
09/16 06:26:07 AM: micro_avg: validation: 0.000000
09/16 06:26:07 AM: edges-ner-ontonotes_mcc: training: 0.848429 validation: 0.894487
09/16 06:26:07 AM: edges-ner-ontonotes_acc: training: 0.772265 validation: 0.835608
09/16 06:26:07 AM: edges-ner-ontonotes_precision: training: 0.908069 validation: 0.951054
09/16 06:26:07 AM: edges-ner-ontonotes_recall: training: 0.807460 validation: 0.851608
09/16 06:26:07 AM: edges-ner-ontonotes_f1: training: 0.854815 validation: 0.898588
09/16 06:26:07 AM: Global learning rate: 0.0001
09/16 06:26:07 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:26:08 AM: Update 8273: task edges-ner-ontonotes, batch 273 (8273): mcc: 0.8434, acc: 0.7660, precision: 0.9048, recall: 0.8013, f1: 0.8499, edges-ner-ontonotes_loss: 0.0469
09/16 06:26:16 AM: Update 8063: task edges-ner-ontonotes, batch 63 (8063): mcc: 0.8216, acc: 0.7335, precision: 0.8966, recall: 0.7696, f1: 0.8283, edges-ner-ontonotes_loss: 0.0541
09/16 06:26:18 AM: Update 8350: task edges-ner-ontonotes, batch 350 (8350): mcc: 0.8458, acc: 0.7696, precision: 0.9063, recall: 0.8043, f1: 0.8522, edges-ner-ontonotes_loss: 0.0462
09/16 06:26:26 AM: Update 8124: task edges-ner-ontonotes, batch 124 (8124): mcc: 0.8332, acc: 0.7517, precision: 0.8985, recall: 0.7885, f1: 0.8399, edges-ner-ontonotes_loss: 0.0510
09/16 06:26:28 AM: Update 8411: task edges-ner-ontonotes, batch 411 (8411): mcc: 0.8473, acc: 0.7712, precision: 0.9077, recall: 0.8056, f1: 0.8536, edges-ner-ontonotes_loss: 0.0457
09/16 06:26:36 AM: Update 8202: task edges-ner-ontonotes, batch 202 (8202): mcc: 0.8416, acc: 0.7635, precision: 0.9037, recall: 0.7991, f1: 0.8482, edges-ner-ontonotes_loss: 0.0482
09/16 06:26:38 AM: Update 8485: task edges-ner-ontonotes, batch 485 (8485): mcc: 0.8508, acc: 0.7757, precision: 0.9094, recall: 0.8107, f1: 0.8572, edges-ner-ontonotes_loss: 0.0448
09/16 06:26:46 AM: Update 8273: task edges-ner-ontonotes, batch 273 (8273): mcc: 0.8434, acc: 0.7660, precision: 0.9048, recall: 0.8013, f1: 0.8499, edges-ner-ontonotes_loss: 0.0469
09/16 06:26:48 AM: Update 8555: task edges-ner-ontonotes, batch 555 (8555): mcc: 0.8549, acc: 0.7810, precision: 0.9113, recall: 0.8162, f1: 0.8611, edges-ner-ontonotes_loss: 0.0438
09/16 06:26:56 AM: Update 8342: task edges-ner-ontonotes, batch 342 (8342): mcc: 0.8456, acc: 0.7693, precision: 0.9063, recall: 0.8039, f1: 0.8520, edges-ner-ontonotes_loss: 0.0463
09/16 06:26:58 AM: Update 8626: task edges-ner-ontonotes, batch 626 (8626): mcc: 0.8582, acc: 0.7856, precision: 0.9136, recall: 0.8201, f1: 0.8643, edges-ner-ontonotes_loss: 0.0429
09/16 06:27:08 AM: Update 8705: task edges-ner-ontonotes, batch 705 (8705): mcc: 0.8606, acc: 0.7889, precision: 0.9150, recall: 0.8232, f1: 0.8667, edges-ner-ontonotes_loss: 0.0422
09/16 06:27:08 AM: Update 8407: task edges-ner-ontonotes, batch 407 (8407): mcc: 0.8472, acc: 0.7713, precision: 0.9075, recall: 0.8057, f1: 0.8536, edges-ner-ontonotes_loss: 0.0457
09/16 06:27:19 AM: Update 8762: task edges-ner-ontonotes, batch 762 (8762): mcc: 0.8627, acc: 0.7915, precision: 0.9166, recall: 0.8256, f1: 0.8687, edges-ner-ontonotes_loss: 0.0417
09/16 06:27:19 AM: Update 8487: task edges-ner-ontonotes, batch 487 (8487): mcc: 0.8510, acc: 0.7759, precision: 0.9094, recall: 0.8109, f1: 0.8573, edges-ner-ontonotes_loss: 0.0447
09/16 06:27:29 AM: Update 8832: task edges-ner-ontonotes, batch 832 (8832): mcc: 0.8638, acc: 0.7930, precision: 0.9170, recall: 0.8272, f1: 0.8698, edges-ner-ontonotes_loss: 0.0415
09/16 06:27:29 AM: Update 8554: task edges-ner-ontonotes, batch 554 (8554): mcc: 0.8548, acc: 0.7810, precision: 0.9112, recall: 0.8161, f1: 0.8611, edges-ner-ontonotes_loss: 0.0438
09/16 06:27:39 AM: Update 8625: task edges-ner-ontonotes, batch 625 (8625): mcc: 0.8581, acc: 0.7855, precision: 0.9135, recall: 0.8200, f1: 0.8643, edges-ner-ontonotes_loss: 0.0429
09/16 06:27:39 AM: Update 8901: task edges-ner-ontonotes, batch 901 (8901): mcc: 0.8651, acc: 0.7947, precision: 0.9177, recall: 0.8288, f1: 0.8710, edges-ner-ontonotes_loss: 0.0411
09/16 06:27:49 AM: Update 8972: task edges-ner-ontonotes, batch 972 (8972): mcc: 0.8652, acc: 0.7949, precision: 0.9178, recall: 0.8290, f1: 0.8711, edges-ner-ontonotes_loss: 0.0410
09/16 06:27:49 AM: Update 8696: task edges-ner-ontonotes, batch 696 (8696): mcc: 0.8604, acc: 0.7886, precision: 0.9148, recall: 0.8230, f1: 0.8665, edges-ner-ontonotes_loss: 0.0423
09/16 06:27:53 AM: ***** Step 9000 / Validation 9 *****
09/16 06:27:54 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:27:54 AM: Validating...
09/16 06:28:00 AM: Update 8745: task edges-ner-ontonotes, batch 745 (8745): mcc: 0.8622, acc: 0.7908, precision: 0.9162, recall: 0.8250, f1: 0.8682, edges-ner-ontonotes_loss: 0.0419
09/16 06:28:00 AM: Evaluate: task edges-ner-ontonotes, batch 35 (157): mcc: 0.8464, acc: 0.7730, precision: 0.9129, recall: 0.7995, f1: 0.8524, edges-ner-ontonotes_loss: 0.0497
09/16 06:28:11 AM: Evaluate: task edges-ner-ontonotes, batch 84 (157): mcc: 0.8810, acc: 0.8200, precision: 0.9362, recall: 0.8407, f1: 0.8859, edges-ner-ontonotes_loss: 0.0403
09/16 06:28:11 AM: Update 8805: task edges-ner-ontonotes, batch 805 (8805): mcc: 0.8638, acc: 0.7931, precision: 0.9172, recall: 0.8270, f1: 0.8698, edges-ner-ontonotes_loss: 0.0415
09/16 06:28:21 AM: Evaluate: task edges-ner-ontonotes, batch 134 (157): mcc: 0.8986, acc: 0.8464, precision: 0.9434, recall: 0.8661, f1: 0.9031, edges-ner-ontonotes_loss: 0.0347
09/16 06:28:21 AM: Update 8861: task edges-ner-ontonotes, batch 861 (8861): mcc: 0.8646, acc: 0.7940, precision: 0.9175, recall: 0.8281, f1: 0.8705, edges-ner-ontonotes_loss: 0.0413
09/16 06:28:25 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:28:25 AM: Best result seen so far for macro.
09/16 06:28:25 AM: Updating LR scheduler:
09/16 06:28:25 AM: 	Best result seen so far for macro_avg: 0.905
09/16 06:28:25 AM: 	# validation passes without improvement: 0
09/16 06:28:25 AM: edges-ner-ontonotes_loss: training: 0.040825 validation: 0.033770
09/16 06:28:25 AM: macro_avg: validation: 0.904542
09/16 06:28:25 AM: micro_avg: validation: 0.000000
09/16 06:28:25 AM: edges-ner-ontonotes_mcc: training: 0.865677 validation: 0.900007
09/16 06:28:25 AM: edges-ner-ontonotes_acc: training: 0.795503 validation: 0.848423
09/16 06:28:25 AM: edges-ner-ontonotes_precision: training: 0.917970 validation: 0.943059
09/16 06:28:25 AM: edges-ner-ontonotes_recall: training: 0.829682 validation: 0.869048
09/16 06:28:25 AM: edges-ner-ontonotes_f1: training: 0.871596 validation: 0.904542
09/16 06:28:25 AM: Global learning rate: 0.0001
09/16 06:28:25 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:28:31 AM: Update 8929: task edges-ner-ontonotes, batch 929 (8929): mcc: 0.8652, acc: 0.7948, precision: 0.9178, recall: 0.8289, f1: 0.8711, edges-ner-ontonotes_loss: 0.0411
09/16 06:28:33 AM: Update 9033: task edges-ner-ontonotes, batch 33 (9033): mcc: 0.8779, acc: 0.8073, precision: 0.9277, recall: 0.8431, f1: 0.8833, edges-ner-ontonotes_loss: 0.0371
09/16 06:28:40 AM: ***** Step 9000 / Validation 9 *****
09/16 06:28:40 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:28:40 AM: Validating...
09/16 06:28:41 AM: Evaluate: task edges-ner-ontonotes, batch 7 (157): mcc: 0.7961, acc: 0.7004, precision: 0.9049, recall: 0.7177, f1: 0.8005, edges-ner-ontonotes_loss: 0.0613
09/16 06:28:43 AM: Update 9098: task edges-ner-ontonotes, batch 98 (9098): mcc: 0.8367, acc: 0.7608, precision: 0.8961, recall: 0.7970, f1: 0.8437, edges-ner-ontonotes_loss: 0.0518
09/16 06:28:51 AM: Evaluate: task edges-ner-ontonotes, batch 68 (157): mcc: 0.8704, acc: 0.8070, precision: 0.9291, recall: 0.8280, f1: 0.8757, edges-ner-ontonotes_loss: 0.0432
09/16 06:28:56 AM: Update 9159: task edges-ner-ontonotes, batch 159 (9159): mcc: 0.8340, acc: 0.7559, precision: 0.8957, recall: 0.7926, f1: 0.8410, edges-ner-ontonotes_loss: 0.0523
09/16 06:29:02 AM: Evaluate: task edges-ner-ontonotes, batch 120 (157): mcc: 0.8936, acc: 0.8398, precision: 0.9399, recall: 0.8602, f1: 0.8983, edges-ner-ontonotes_loss: 0.0364
09/16 06:29:07 AM: Update 9214: task edges-ner-ontonotes, batch 214 (9214): mcc: 0.8320, acc: 0.7522, precision: 0.8952, recall: 0.7896, f1: 0.8391, edges-ner-ontonotes_loss: 0.0531
09/16 06:29:08 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:29:09 AM: Best result seen so far for macro.
09/16 06:29:09 AM: Updating LR scheduler:
09/16 06:29:09 AM: 	Best result seen so far for macro_avg: 0.905
09/16 06:29:09 AM: 	# validation passes without improvement: 0
09/16 06:29:09 AM: edges-ner-ontonotes_loss: training: 0.040825 validation: 0.033770
09/16 06:29:09 AM: macro_avg: validation: 0.904542
09/16 06:29:09 AM: micro_avg: validation: 0.000000
09/16 06:29:09 AM: edges-ner-ontonotes_mcc: training: 0.865677 validation: 0.900007
09/16 06:29:09 AM: edges-ner-ontonotes_acc: training: 0.795503 validation: 0.848423
09/16 06:29:09 AM: edges-ner-ontonotes_precision: training: 0.917970 validation: 0.943059
09/16 06:29:09 AM: edges-ner-ontonotes_recall: training: 0.829682 validation: 0.869048
09/16 06:29:09 AM: edges-ner-ontonotes_f1: training: 0.871596 validation: 0.904542
09/16 06:29:09 AM: Global learning rate: 0.0001
09/16 06:29:09 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:29:12 AM: Update 9024: task edges-ner-ontonotes, batch 24 (9024): mcc: 0.8745, acc: 0.8016, precision: 0.9236, recall: 0.8406, f1: 0.8801, edges-ner-ontonotes_loss: 0.0378
09/16 06:29:19 AM: Update 9296: task edges-ner-ontonotes, batch 296 (9296): mcc: 0.8282, acc: 0.7470, precision: 0.8932, recall: 0.7845, f1: 0.8353, edges-ner-ontonotes_loss: 0.0544
09/16 06:29:22 AM: Update 9073: task edges-ner-ontonotes, batch 73 (9073): mcc: 0.8408, acc: 0.7643, precision: 0.9005, recall: 0.8006, f1: 0.8476, edges-ner-ontonotes_loss: 0.0502
09/16 06:29:29 AM: Update 9355: task edges-ner-ontonotes, batch 355 (9355): mcc: 0.8287, acc: 0.7478, precision: 0.8939, recall: 0.7846, f1: 0.8357, edges-ner-ontonotes_loss: 0.0546
09/16 06:29:32 AM: Update 9159: task edges-ner-ontonotes, batch 159 (9159): mcc: 0.8340, acc: 0.7559, precision: 0.8957, recall: 0.7926, f1: 0.8410, edges-ner-ontonotes_loss: 0.0523
09/16 06:29:39 AM: Update 9434: task edges-ner-ontonotes, batch 434 (9434): mcc: 0.8273, acc: 0.7458, precision: 0.8922, recall: 0.7838, f1: 0.8345, edges-ner-ontonotes_loss: 0.0546
09/16 06:29:42 AM: Update 9235: task edges-ner-ontonotes, batch 235 (9235): mcc: 0.8296, acc: 0.7489, precision: 0.8937, recall: 0.7864, f1: 0.8366, edges-ner-ontonotes_loss: 0.0542
09/16 06:29:49 AM: Update 9518: task edges-ner-ontonotes, batch 518 (9518): mcc: 0.8270, acc: 0.7448, precision: 0.8927, recall: 0.7828, f1: 0.8341, edges-ner-ontonotes_loss: 0.0542
09/16 06:29:52 AM: Update 9316: task edges-ner-ontonotes, batch 316 (9316): mcc: 0.8289, acc: 0.7480, precision: 0.8939, recall: 0.7850, f1: 0.8359, edges-ner-ontonotes_loss: 0.0544
09/16 06:29:59 AM: Update 9607: task edges-ner-ontonotes, batch 607 (9607): mcc: 0.8268, acc: 0.7444, precision: 0.8928, recall: 0.7824, f1: 0.8339, edges-ner-ontonotes_loss: 0.0540
09/16 06:30:02 AM: Update 9383: task edges-ner-ontonotes, batch 383 (9383): mcc: 0.8280, acc: 0.7470, precision: 0.8932, recall: 0.7841, f1: 0.8351, edges-ner-ontonotes_loss: 0.0547
09/16 06:30:09 AM: Update 9666: task edges-ner-ontonotes, batch 666 (9666): mcc: 0.8274, acc: 0.7453, precision: 0.8933, recall: 0.7829, f1: 0.8345, edges-ner-ontonotes_loss: 0.0537
09/16 06:30:12 AM: Update 9473: task edges-ner-ontonotes, batch 473 (9473): mcc: 0.8277, acc: 0.7459, precision: 0.8929, recall: 0.7838, f1: 0.8348, edges-ner-ontonotes_loss: 0.0542
09/16 06:30:20 AM: Update 9745: task edges-ner-ontonotes, batch 745 (9745): mcc: 0.8311, acc: 0.7501, precision: 0.8953, recall: 0.7878, f1: 0.8381, edges-ner-ontonotes_loss: 0.0526
09/16 06:30:23 AM: Update 9560: task edges-ner-ontonotes, batch 560 (9560): mcc: 0.8271, acc: 0.7447, precision: 0.8930, recall: 0.7826, f1: 0.8342, edges-ner-ontonotes_loss: 0.0540
09/16 06:30:31 AM: Update 9823: task edges-ner-ontonotes, batch 823 (9823): mcc: 0.8335, acc: 0.7533, precision: 0.8963, recall: 0.7911, f1: 0.8404, edges-ner-ontonotes_loss: 0.0517
09/16 06:30:33 AM: Update 9641: task edges-ner-ontonotes, batch 641 (9641): mcc: 0.8273, acc: 0.7449, precision: 0.8931, recall: 0.7829, f1: 0.8344, edges-ner-ontonotes_loss: 0.0538
09/16 06:30:41 AM: Update 9909: task edges-ner-ontonotes, batch 909 (9909): mcc: 0.8360, acc: 0.7567, precision: 0.8980, recall: 0.7942, f1: 0.8429, edges-ner-ontonotes_loss: 0.0508
09/16 06:30:43 AM: Update 9696: task edges-ner-ontonotes, batch 696 (9696): mcc: 0.8287, acc: 0.7468, precision: 0.8940, recall: 0.7847, f1: 0.8358, edges-ner-ontonotes_loss: 0.0533
09/16 06:30:52 AM: Update 9963: task edges-ner-ontonotes, batch 963 (9963): mcc: 0.8371, acc: 0.7582, precision: 0.8985, recall: 0.7957, f1: 0.8440, edges-ner-ontonotes_loss: 0.0503
09/16 06:30:53 AM: Update 9773: task edges-ner-ontonotes, batch 773 (9773): mcc: 0.8322, acc: 0.7516, precision: 0.8959, recall: 0.7892, f1: 0.8392, edges-ner-ontonotes_loss: 0.0523
09/16 06:30:56 AM: ***** Step 10000 / Validation 10 *****
09/16 06:30:56 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:30:56 AM: Validating...
09/16 06:31:02 AM: Evaluate: task edges-ner-ontonotes, batch 35 (157): mcc: 0.8478, acc: 0.7748, precision: 0.9191, recall: 0.7964, f1: 0.8534, edges-ner-ontonotes_loss: 0.0476
09/16 06:31:03 AM: Update 9842: task edges-ner-ontonotes, batch 842 (9842): mcc: 0.8339, acc: 0.7539, precision: 0.8966, recall: 0.7917, f1: 0.8409, edges-ner-ontonotes_loss: 0.0515
09/16 06:31:12 AM: Evaluate: task edges-ner-ontonotes, batch 86 (157): mcc: 0.8826, acc: 0.8213, precision: 0.9409, recall: 0.8394, f1: 0.8873, edges-ner-ontonotes_loss: 0.0384
09/16 06:31:13 AM: Update 9905: task edges-ner-ontonotes, batch 905 (9905): mcc: 0.8360, acc: 0.7566, precision: 0.8979, recall: 0.7942, f1: 0.8429, edges-ner-ontonotes_loss: 0.0508
09/16 06:31:23 AM: Update 9960: task edges-ner-ontonotes, batch 960 (9960): mcc: 0.8371, acc: 0.7582, precision: 0.8985, recall: 0.7957, f1: 0.8440, edges-ner-ontonotes_loss: 0.0504
09/16 06:31:23 AM: Evaluate: task edges-ner-ontonotes, batch 135 (157): mcc: 0.8973, acc: 0.8434, precision: 0.9461, recall: 0.8613, f1: 0.9017, edges-ner-ontonotes_loss: 0.0341
09/16 06:31:27 AM: Updating LR scheduler:
09/16 06:31:27 AM: 	Best result seen so far for macro_avg: 0.905
09/16 06:31:27 AM: 	# validation passes without improvement: 1
09/16 06:31:27 AM: edges-ner-ontonotes_loss: training: 0.049784 validation: 0.033410
09/16 06:31:27 AM: macro_avg: validation: 0.903144
09/16 06:31:27 AM: micro_avg: validation: 0.000000
09/16 06:31:27 AM: edges-ner-ontonotes_mcc: training: 0.838806 validation: 0.898769
09/16 06:31:27 AM: edges-ner-ontonotes_acc: training: 0.760476 validation: 0.845390
09/16 06:31:27 AM: edges-ner-ontonotes_precision: training: 0.899747 validation: 0.946406
09/16 06:31:27 AM: edges-ner-ontonotes_recall: training: 0.797634 validation: 0.863664
09/16 06:31:27 AM: edges-ner-ontonotes_f1: training: 0.845619 validation: 0.903144
09/16 06:31:27 AM: Global learning rate: 0.0001
09/16 06:31:27 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:31:34 AM: ***** Step 10000 / Validation 10 *****
09/16 06:31:34 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:31:34 AM: Validating...
09/16 06:31:34 AM: Evaluate: task edges-ner-ontonotes, batch 5 (157): mcc: 0.7621, acc: 0.6537, precision: 0.8863, recall: 0.6746, f1: 0.7661, edges-ner-ontonotes_loss: 0.0702
09/16 06:31:34 AM: Update 10052: task edges-ner-ontonotes, batch 52 (10052): mcc: 0.8841, acc: 0.8211, precision: 0.9279, recall: 0.8540, f1: 0.8894, edges-ner-ontonotes_loss: 0.0349
09/16 06:31:45 AM: Update 10108: task edges-ner-ontonotes, batch 108 (10108): mcc: 0.8814, acc: 0.8178, precision: 0.9269, recall: 0.8501, f1: 0.8868, edges-ner-ontonotes_loss: 0.0370
09/16 06:31:45 AM: Evaluate: task edges-ner-ontonotes, batch 64 (157): mcc: 0.8725, acc: 0.8094, precision: 0.9316, recall: 0.8297, f1: 0.8777, edges-ner-ontonotes_loss: 0.0408
09/16 06:31:55 AM: Update 10161: task edges-ner-ontonotes, batch 161 (10161): mcc: 0.8801, acc: 0.8154, precision: 0.9256, recall: 0.8490, f1: 0.8856, edges-ner-ontonotes_loss: 0.0368
09/16 06:31:55 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.8897, acc: 0.8328, precision: 0.9416, recall: 0.8515, f1: 0.8943, edges-ner-ontonotes_loss: 0.0363
09/16 06:32:03 AM: Updating LR scheduler:
09/16 06:32:03 AM: 	Best result seen so far for macro_avg: 0.905
09/16 06:32:03 AM: 	# validation passes without improvement: 1
09/16 06:32:03 AM: edges-ner-ontonotes_loss: training: 0.049784 validation: 0.033410
09/16 06:32:03 AM: macro_avg: validation: 0.903144
09/16 06:32:03 AM: micro_avg: validation: 0.000000
09/16 06:32:03 AM: edges-ner-ontonotes_mcc: training: 0.838806 validation: 0.898769
09/16 06:32:03 AM: edges-ner-ontonotes_acc: training: 0.760476 validation: 0.845390
09/16 06:32:03 AM: edges-ner-ontonotes_precision: training: 0.899747 validation: 0.946406
09/16 06:32:03 AM: edges-ner-ontonotes_recall: training: 0.797634 validation: 0.863664
09/16 06:32:03 AM: edges-ner-ontonotes_f1: training: 0.845619 validation: 0.903144
09/16 06:32:03 AM: Global learning rate: 0.0001
09/16 06:32:03 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:32:05 AM: Update 10218: task edges-ner-ontonotes, batch 218 (10218): mcc: 0.8810, acc: 0.8169, precision: 0.9264, recall: 0.8498, f1: 0.8865, edges-ner-ontonotes_loss: 0.0363
09/16 06:32:05 AM: Update 10014: task edges-ner-ontonotes, batch 14 (10014): mcc: 0.8817, acc: 0.8207, precision: 0.9191, recall: 0.8581, f1: 0.8875, edges-ner-ontonotes_loss: 0.0351
09/16 06:32:15 AM: Update 10086: task edges-ner-ontonotes, batch 86 (10086): mcc: 0.8806, acc: 0.8175, precision: 0.9258, recall: 0.8497, f1: 0.8861, edges-ner-ontonotes_loss: 0.0368
09/16 06:32:16 AM: Update 10276: task edges-ner-ontonotes, batch 276 (10276): mcc: 0.8803, acc: 0.8159, precision: 0.9255, recall: 0.8494, f1: 0.8858, edges-ner-ontonotes_loss: 0.0363
09/16 06:32:25 AM: Update 10162: task edges-ner-ontonotes, batch 162 (10162): mcc: 0.8802, acc: 0.8156, precision: 0.9256, recall: 0.8491, f1: 0.8857, edges-ner-ontonotes_loss: 0.0368
09/16 06:32:26 AM: Update 10348: task edges-ner-ontonotes, batch 348 (10348): mcc: 0.8796, acc: 0.8154, precision: 0.9245, recall: 0.8490, f1: 0.8851, edges-ner-ontonotes_loss: 0.0363
09/16 06:32:35 AM: Update 10227: task edges-ner-ontonotes, batch 227 (10227): mcc: 0.8811, acc: 0.8171, precision: 0.9263, recall: 0.8502, f1: 0.8866, edges-ner-ontonotes_loss: 0.0363
09/16 06:32:36 AM: Update 10421: task edges-ner-ontonotes, batch 421 (10421): mcc: 0.8788, acc: 0.8138, precision: 0.9238, recall: 0.8483, f1: 0.8844, edges-ner-ontonotes_loss: 0.0363
09/16 06:32:46 AM: Update 10276: task edges-ner-ontonotes, batch 276 (10276): mcc: 0.8803, acc: 0.8159, precision: 0.9255, recall: 0.8494, f1: 0.8858, edges-ner-ontonotes_loss: 0.0363
09/16 06:32:46 AM: Update 10501: task edges-ner-ontonotes, batch 501 (10501): mcc: 0.8788, acc: 0.8138, precision: 0.9241, recall: 0.8479, f1: 0.8843, edges-ner-ontonotes_loss: 0.0365
09/16 06:32:58 AM: Update 10574: task edges-ner-ontonotes, batch 574 (10574): mcc: 0.8787, acc: 0.8136, precision: 0.9239, recall: 0.8480, f1: 0.8843, edges-ner-ontonotes_loss: 0.0367
09/16 06:32:58 AM: Update 10348: task edges-ner-ontonotes, batch 348 (10348): mcc: 0.8796, acc: 0.8154, precision: 0.9245, recall: 0.8490, f1: 0.8851, edges-ner-ontonotes_loss: 0.0363
09/16 06:33:08 AM: Update 10427: task edges-ner-ontonotes, batch 427 (10427): mcc: 0.8786, acc: 0.8136, precision: 0.9235, recall: 0.8482, f1: 0.8842, edges-ner-ontonotes_loss: 0.0364
09/16 06:33:08 AM: Update 10627: task edges-ner-ontonotes, batch 627 (10627): mcc: 0.8765, acc: 0.8106, precision: 0.9231, recall: 0.8447, f1: 0.8822, edges-ner-ontonotes_loss: 0.0378
09/16 06:33:18 AM: Update 10495: task edges-ner-ontonotes, batch 495 (10495): mcc: 0.8786, acc: 0.8136, precision: 0.9238, recall: 0.8479, f1: 0.8842, edges-ner-ontonotes_loss: 0.0365
09/16 06:33:18 AM: Update 10695: task edges-ner-ontonotes, batch 695 (10695): mcc: 0.8712, acc: 0.8035, precision: 0.9200, recall: 0.8378, f1: 0.8770, edges-ner-ontonotes_loss: 0.0395
09/16 06:33:28 AM: Update 10570: task edges-ner-ontonotes, batch 570 (10570): mcc: 0.8788, acc: 0.8137, precision: 0.9240, recall: 0.8480, f1: 0.8844, edges-ner-ontonotes_loss: 0.0367
09/16 06:33:28 AM: Update 10769: task edges-ner-ontonotes, batch 769 (10769): mcc: 0.8679, acc: 0.7990, precision: 0.9180, recall: 0.8337, f1: 0.8738, edges-ner-ontonotes_loss: 0.0409
09/16 06:33:38 AM: Update 10622: task edges-ner-ontonotes, batch 622 (10622): mcc: 0.8769, acc: 0.8111, precision: 0.9233, recall: 0.8452, f1: 0.8825, edges-ner-ontonotes_loss: 0.0376
09/16 06:33:38 AM: Update 10849: task edges-ner-ontonotes, batch 849 (10849): mcc: 0.8641, acc: 0.7942, precision: 0.9154, recall: 0.8293, f1: 0.8702, edges-ner-ontonotes_loss: 0.0424
09/16 06:33:48 AM: Update 10702: task edges-ner-ontonotes, batch 702 (10702): mcc: 0.8706, acc: 0.8027, precision: 0.9197, recall: 0.8372, f1: 0.8765, edges-ner-ontonotes_loss: 0.0398
09/16 06:33:48 AM: Update 10905: task edges-ner-ontonotes, batch 905 (10905): mcc: 0.8622, acc: 0.7918, precision: 0.9142, recall: 0.8269, f1: 0.8684, edges-ner-ontonotes_loss: 0.0432
09/16 06:33:58 AM: Update 10781: task edges-ner-ontonotes, batch 781 (10781): mcc: 0.8674, acc: 0.7983, precision: 0.9178, recall: 0.8329, f1: 0.8733, edges-ner-ontonotes_loss: 0.0412
09/16 06:33:59 AM: Update 10989: task edges-ner-ontonotes, batch 989 (10989): mcc: 0.8601, acc: 0.7887, precision: 0.9131, recall: 0.8240, f1: 0.8663, edges-ner-ontonotes_loss: 0.0440
09/16 06:34:00 AM: ***** Step 11000 / Validation 11 *****
09/16 06:34:00 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:34:00 AM: Validating...
09/16 06:34:08 AM: Update 10841: task edges-ner-ontonotes, batch 841 (10841): mcc: 0.8643, acc: 0.7943, precision: 0.9155, recall: 0.8294, f1: 0.8703, edges-ner-ontonotes_loss: 0.0424
09/16 06:34:09 AM: Evaluate: task edges-ner-ontonotes, batch 54 (157): mcc: 0.8711, acc: 0.8042, precision: 0.9270, recall: 0.8311, f1: 0.8765, edges-ner-ontonotes_loss: 0.0409
09/16 06:34:19 AM: Evaluate: task edges-ner-ontonotes, batch 111 (157): mcc: 0.8896, acc: 0.8298, precision: 0.9415, recall: 0.8514, f1: 0.8942, edges-ner-ontonotes_loss: 0.0358
09/16 06:34:20 AM: Update 10893: task edges-ner-ontonotes, batch 893 (10893): mcc: 0.8626, acc: 0.7922, precision: 0.9146, recall: 0.8272, f1: 0.8687, edges-ner-ontonotes_loss: 0.0431
09/16 06:34:28 AM: Updating LR scheduler:
09/16 06:34:28 AM: 	Best result seen so far for macro_avg: 0.905
09/16 06:34:28 AM: 	# validation passes without improvement: 2
09/16 06:34:28 AM: edges-ner-ontonotes_loss: training: 0.044077 validation: 0.033163
09/16 06:34:28 AM: macro_avg: validation: 0.901808
09/16 06:34:28 AM: micro_avg: validation: 0.000000
09/16 06:34:28 AM: edges-ner-ontonotes_mcc: training: 0.859770 validation: 0.897485
09/16 06:34:28 AM: edges-ner-ontonotes_acc: training: 0.788259 validation: 0.840613
09/16 06:34:28 AM: edges-ner-ontonotes_precision: training: 0.912861 validation: 0.947399
09/16 06:34:28 AM: edges-ner-ontonotes_recall: training: 0.823646 validation: 0.860403
09/16 06:34:28 AM: edges-ner-ontonotes_f1: training: 0.865961 validation: 0.901808
09/16 06:34:28 AM: Global learning rate: 0.0001
09/16 06:34:28 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:34:29 AM: Update 11010: task edges-ner-ontonotes, batch 10 (11010): mcc: 0.8214, acc: 0.7347, precision: 0.8868, recall: 0.7780, f1: 0.8288, edges-ner-ontonotes_loss: 0.0553
09/16 06:34:30 AM: Update 10961: task edges-ner-ontonotes, batch 961 (10961): mcc: 0.8606, acc: 0.7895, precision: 0.9133, recall: 0.8247, f1: 0.8668, edges-ner-ontonotes_loss: 0.0438
09/16 06:34:35 AM: ***** Step 11000 / Validation 11 *****
09/16 06:34:35 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:34:35 AM: Validating...
09/16 06:34:39 AM: Update 11088: task edges-ner-ontonotes, batch 88 (11088): mcc: 0.8234, acc: 0.7365, precision: 0.8937, recall: 0.7755, f1: 0.8304, edges-ner-ontonotes_loss: 0.0519
09/16 06:34:40 AM: Evaluate: task edges-ner-ontonotes, batch 39 (157): mcc: 0.8567, acc: 0.7836, precision: 0.9211, recall: 0.8106, f1: 0.8623, edges-ner-ontonotes_loss: 0.0447
09/16 06:34:49 AM: Update 11148: task edges-ner-ontonotes, batch 148 (11148): mcc: 0.8238, acc: 0.7388, precision: 0.8916, recall: 0.7779, f1: 0.8309, edges-ner-ontonotes_loss: 0.0516
09/16 06:34:50 AM: Evaluate: task edges-ner-ontonotes, batch 95 (157): mcc: 0.8899, acc: 0.8296, precision: 0.9426, recall: 0.8510, f1: 0.8945, edges-ner-ontonotes_loss: 0.0364
09/16 06:35:00 AM: Update 11206: task edges-ner-ontonotes, batch 206 (11206): mcc: 0.8247, acc: 0.7407, precision: 0.8914, recall: 0.7798, f1: 0.8319, edges-ner-ontonotes_loss: 0.0517
09/16 06:35:02 AM: Evaluate: task edges-ner-ontonotes, batch 150 (157): mcc: 0.8979, acc: 0.8411, precision: 0.9474, recall: 0.8611, f1: 0.9022, edges-ner-ontonotes_loss: 0.0334
09/16 06:35:03 AM: Updating LR scheduler:
09/16 06:35:03 AM: 	Best result seen so far for macro_avg: 0.905
09/16 06:35:03 AM: 	# validation passes without improvement: 2
09/16 06:35:03 AM: edges-ner-ontonotes_loss: training: 0.044077 validation: 0.033163
09/16 06:35:03 AM: macro_avg: validation: 0.901808
09/16 06:35:03 AM: micro_avg: validation: 0.000000
09/16 06:35:03 AM: edges-ner-ontonotes_mcc: training: 0.859770 validation: 0.897485
09/16 06:35:03 AM: edges-ner-ontonotes_acc: training: 0.788259 validation: 0.840613
09/16 06:35:03 AM: edges-ner-ontonotes_precision: training: 0.912861 validation: 0.947399
09/16 06:35:03 AM: edges-ner-ontonotes_recall: training: 0.823646 validation: 0.860403
09/16 06:35:03 AM: edges-ner-ontonotes_f1: training: 0.865961 validation: 0.901808
09/16 06:35:03 AM: Global learning rate: 0.0001
09/16 06:35:03 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:35:10 AM: Update 11279: task edges-ner-ontonotes, batch 279 (11279): mcc: 0.8333, acc: 0.7523, precision: 0.8966, recall: 0.7905, f1: 0.8402, edges-ner-ontonotes_loss: 0.0496
09/16 06:35:12 AM: Update 11071: task edges-ner-ontonotes, batch 71 (11071): mcc: 0.8221, acc: 0.7355, precision: 0.8934, recall: 0.7733, f1: 0.8290, edges-ner-ontonotes_loss: 0.0530
09/16 06:35:20 AM: Update 11355: task edges-ner-ontonotes, batch 355 (11355): mcc: 0.8404, acc: 0.7614, precision: 0.9012, recall: 0.7992, f1: 0.8471, edges-ner-ontonotes_loss: 0.0476
09/16 06:35:22 AM: Update 11158: task edges-ner-ontonotes, batch 158 (11158): mcc: 0.8238, acc: 0.7392, precision: 0.8920, recall: 0.7776, f1: 0.8308, edges-ner-ontonotes_loss: 0.0515
09/16 06:35:31 AM: Update 11439: task edges-ner-ontonotes, batch 439 (11439): mcc: 0.8451, acc: 0.7680, precision: 0.9039, recall: 0.8052, f1: 0.8517, edges-ner-ontonotes_loss: 0.0465
09/16 06:35:32 AM: Update 11213: task edges-ner-ontonotes, batch 213 (11213): mcc: 0.8244, acc: 0.7405, precision: 0.8907, recall: 0.7798, f1: 0.8316, edges-ner-ontonotes_loss: 0.0515
09/16 06:35:41 AM: Update 11518: task edges-ner-ontonotes, batch 518 (11518): mcc: 0.8480, acc: 0.7723, precision: 0.9059, recall: 0.8086, f1: 0.8545, edges-ner-ontonotes_loss: 0.0458
09/16 06:35:42 AM: Update 11290: task edges-ner-ontonotes, batch 290 (11290): mcc: 0.8346, acc: 0.7539, precision: 0.8972, recall: 0.7923, f1: 0.8415, edges-ner-ontonotes_loss: 0.0492
09/16 06:35:51 AM: Update 11570: task edges-ner-ontonotes, batch 570 (11570): mcc: 0.8514, acc: 0.7769, precision: 0.9079, recall: 0.8129, f1: 0.8578, edges-ner-ontonotes_loss: 0.0450
09/16 06:35:54 AM: Update 11359: task edges-ner-ontonotes, batch 359 (11359): mcc: 0.8406, acc: 0.7616, precision: 0.9012, recall: 0.7996, f1: 0.8474, edges-ner-ontonotes_loss: 0.0475
09/16 06:36:01 AM: Update 11641: task edges-ner-ontonotes, batch 641 (11641): mcc: 0.8555, acc: 0.7826, precision: 0.9104, recall: 0.8182, f1: 0.8618, edges-ner-ontonotes_loss: 0.0440
09/16 06:36:04 AM: Update 11427: task edges-ner-ontonotes, batch 427 (11427): mcc: 0.8445, acc: 0.7673, precision: 0.9038, recall: 0.8042, f1: 0.8511, edges-ner-ontonotes_loss: 0.0467
09/16 06:36:12 AM: Update 11714: task edges-ner-ontonotes, batch 714 (11714): mcc: 0.8590, acc: 0.7873, precision: 0.9129, recall: 0.8223, f1: 0.8652, edges-ner-ontonotes_loss: 0.0431
09/16 06:36:14 AM: Update 11503: task edges-ner-ontonotes, batch 503 (11503): mcc: 0.8477, acc: 0.7719, precision: 0.9059, recall: 0.8081, f1: 0.8542, edges-ner-ontonotes_loss: 0.0458
09/16 06:36:22 AM: Update 11793: task edges-ner-ontonotes, batch 793 (11793): mcc: 0.8615, acc: 0.7906, precision: 0.9140, recall: 0.8257, f1: 0.8676, edges-ner-ontonotes_loss: 0.0424
09/16 06:36:24 AM: Update 11557: task edges-ner-ontonotes, batch 557 (11557): mcc: 0.8505, acc: 0.7758, precision: 0.9074, recall: 0.8117, f1: 0.8569, edges-ner-ontonotes_loss: 0.0451
09/16 06:36:32 AM: Update 11849: task edges-ner-ontonotes, batch 849 (11849): mcc: 0.8632, acc: 0.7928, precision: 0.9149, recall: 0.8280, f1: 0.8693, edges-ner-ontonotes_loss: 0.0419
09/16 06:36:34 AM: Update 11643: task edges-ner-ontonotes, batch 643 (11643): mcc: 0.8558, acc: 0.7830, precision: 0.9106, recall: 0.8185, f1: 0.8621, edges-ner-ontonotes_loss: 0.0439
09/16 06:36:43 AM: Update 11917: task edges-ner-ontonotes, batch 917 (11917): mcc: 0.8644, acc: 0.7942, precision: 0.9157, recall: 0.8295, f1: 0.8704, edges-ner-ontonotes_loss: 0.0415
09/16 06:36:44 AM: Update 11718: task edges-ner-ontonotes, batch 718 (11718): mcc: 0.8592, acc: 0.7875, precision: 0.9130, recall: 0.8225, f1: 0.8654, edges-ner-ontonotes_loss: 0.0430
09/16 06:36:55 AM: Update 11987: task edges-ner-ontonotes, batch 987 (11987): mcc: 0.8656, acc: 0.7959, precision: 0.9160, recall: 0.8313, f1: 0.8716, edges-ner-ontonotes_loss: 0.0412
09/16 06:36:55 AM: Update 11792: task edges-ner-ontonotes, batch 792 (11792): mcc: 0.8614, acc: 0.7905, precision: 0.9140, recall: 0.8256, f1: 0.8676, edges-ner-ontonotes_loss: 0.0424
09/16 06:36:56 AM: ***** Step 12000 / Validation 12 *****
09/16 06:36:56 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:36:56 AM: Validating...
09/16 06:37:05 AM: Update 11839: task edges-ner-ontonotes, batch 839 (11839): mcc: 0.8628, acc: 0.7923, precision: 0.9147, recall: 0.8275, f1: 0.8689, edges-ner-ontonotes_loss: 0.0420
09/16 06:37:05 AM: Evaluate: task edges-ner-ontonotes, batch 54 (157): mcc: 0.8709, acc: 0.8084, precision: 0.9252, recall: 0.8325, f1: 0.8764, edges-ner-ontonotes_loss: 0.0423
09/16 06:37:15 AM: Evaluate: task edges-ner-ontonotes, batch 108 (157): mcc: 0.8902, acc: 0.8350, precision: 0.9377, recall: 0.8562, f1: 0.8951, edges-ner-ontonotes_loss: 0.0363
09/16 06:37:15 AM: Update 11894: task edges-ner-ontonotes, batch 894 (11894): mcc: 0.8640, acc: 0.7938, precision: 0.9152, recall: 0.8292, f1: 0.8701, edges-ner-ontonotes_loss: 0.0416
09/16 06:37:24 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:37:24 AM: Best result seen so far for macro.
09/16 06:37:24 AM: Updating LR scheduler:
09/16 06:37:24 AM: 	Best result seen so far for macro_avg: 0.909
09/16 06:37:24 AM: 	# validation passes without improvement: 0
09/16 06:37:24 AM: edges-ner-ontonotes_loss: training: 0.041215 validation: 0.032258
09/16 06:37:24 AM: macro_avg: validation: 0.908640
09/16 06:37:24 AM: micro_avg: validation: 0.000000
09/16 06:37:24 AM: edges-ner-ontonotes_mcc: training: 0.865606 validation: 0.904240
09/16 06:37:24 AM: edges-ner-ontonotes_acc: training: 0.795872 validation: 0.854337
09/16 06:37:24 AM: edges-ner-ontonotes_precision: training: 0.915947 validation: 0.945191
09/16 06:37:24 AM: edges-ner-ontonotes_recall: training: 0.831424 validation: 0.874810
09/16 06:37:24 AM: edges-ner-ontonotes_f1: training: 0.871641 validation: 0.908640
09/16 06:37:24 AM: Global learning rate: 0.0001
09/16 06:37:24 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:37:25 AM: Update 12002: task edges-ner-ontonotes, batch 2 (12002): mcc: 0.9044, acc: 0.8547, precision: 0.9200, recall: 0.8994, f1: 0.9096, edges-ner-ontonotes_loss: 0.0309
09/16 06:37:25 AM: Update 11947: task edges-ner-ontonotes, batch 947 (11947): mcc: 0.8650, acc: 0.7951, precision: 0.9159, recall: 0.8303, f1: 0.8710, edges-ner-ontonotes_loss: 0.0413
09/16 06:37:33 AM: ***** Step 12000 / Validation 12 *****
09/16 06:37:33 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:37:33 AM: Validating...
09/16 06:37:35 AM: Update 12070: task edges-ner-ontonotes, batch 70 (12070): mcc: 0.8841, acc: 0.8212, precision: 0.9269, recall: 0.8551, f1: 0.8895, edges-ner-ontonotes_loss: 0.0355
09/16 06:37:35 AM: Evaluate: task edges-ner-ontonotes, batch 17 (157): mcc: 0.8160, acc: 0.7303, precision: 0.9015, recall: 0.7553, f1: 0.8219, edges-ner-ontonotes_loss: 0.0537
09/16 06:37:47 AM: Evaluate: task edges-ner-ontonotes, batch 73 (157): mcc: 0.8762, acc: 0.8153, precision: 0.9296, recall: 0.8380, f1: 0.8815, edges-ner-ontonotes_loss: 0.0411
09/16 06:37:47 AM: Update 12125: task edges-ner-ontonotes, batch 125 (12125): mcc: 0.8835, acc: 0.8198, precision: 0.9255, recall: 0.8553, f1: 0.8890, edges-ner-ontonotes_loss: 0.0360
09/16 06:37:57 AM: Evaluate: task edges-ner-ontonotes, batch 129 (157): mcc: 0.9002, acc: 0.8488, precision: 0.9433, recall: 0.8691, f1: 0.9047, edges-ner-ontonotes_loss: 0.0340
09/16 06:37:58 AM: Update 12165: task edges-ner-ontonotes, batch 165 (12165): mcc: 0.8751, acc: 0.8082, precision: 0.9208, recall: 0.8443, f1: 0.8809, edges-ner-ontonotes_loss: 0.0388
09/16 06:38:02 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:38:02 AM: Best result seen so far for macro.
09/16 06:38:02 AM: Updating LR scheduler:
09/16 06:38:02 AM: 	Best result seen so far for macro_avg: 0.909
09/16 06:38:02 AM: 	# validation passes without improvement: 0
09/16 06:38:02 AM: edges-ner-ontonotes_loss: training: 0.041215 validation: 0.032258
09/16 06:38:02 AM: macro_avg: validation: 0.908640
09/16 06:38:02 AM: micro_avg: validation: 0.000000
09/16 06:38:02 AM: edges-ner-ontonotes_mcc: training: 0.865606 validation: 0.904240
09/16 06:38:02 AM: edges-ner-ontonotes_acc: training: 0.795872 validation: 0.854337
09/16 06:38:02 AM: edges-ner-ontonotes_precision: training: 0.915947 validation: 0.945191
09/16 06:38:02 AM: edges-ner-ontonotes_recall: training: 0.831424 validation: 0.874810
09/16 06:38:02 AM: edges-ner-ontonotes_f1: training: 0.871641 validation: 0.908640
09/16 06:38:02 AM: Global learning rate: 0.0001
09/16 06:38:02 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:38:07 AM: Update 12036: task edges-ner-ontonotes, batch 36 (12036): mcc: 0.8778, acc: 0.8118, precision: 0.9245, recall: 0.8458, f1: 0.8834, edges-ner-ontonotes_loss: 0.0364
09/16 06:38:08 AM: Update 12232: task edges-ner-ontonotes, batch 232 (12232): mcc: 0.8621, acc: 0.7917, precision: 0.9116, recall: 0.8290, f1: 0.8683, edges-ner-ontonotes_loss: 0.0438
09/16 06:38:17 AM: Update 12107: task edges-ner-ontonotes, batch 107 (12107): mcc: 0.8838, acc: 0.8198, precision: 0.9265, recall: 0.8549, f1: 0.8893, edges-ner-ontonotes_loss: 0.0357
09/16 06:38:18 AM: Update 12301: task edges-ner-ontonotes, batch 301 (12301): mcc: 0.8551, acc: 0.7829, precision: 0.9085, recall: 0.8191, f1: 0.8615, edges-ner-ontonotes_loss: 0.0460
09/16 06:38:27 AM: Update 12160: task edges-ner-ontonotes, batch 160 (12160): mcc: 0.8761, acc: 0.8095, precision: 0.9210, recall: 0.8459, f1: 0.8818, edges-ner-ontonotes_loss: 0.0383
09/16 06:38:28 AM: Update 12388: task edges-ner-ontonotes, batch 388 (12388): mcc: 0.8503, acc: 0.7761, precision: 0.9061, recall: 0.8127, f1: 0.8569, edges-ner-ontonotes_loss: 0.0480
09/16 06:38:37 AM: Update 12235: task edges-ner-ontonotes, batch 235 (12235): mcc: 0.8614, acc: 0.7908, precision: 0.9113, recall: 0.8280, f1: 0.8676, edges-ner-ontonotes_loss: 0.0439
09/16 06:38:40 AM: Update 12449: task edges-ner-ontonotes, batch 449 (12449): mcc: 0.8469, acc: 0.7718, precision: 0.9039, recall: 0.8085, f1: 0.8535, edges-ner-ontonotes_loss: 0.0489
09/16 06:38:47 AM: Update 12321: task edges-ner-ontonotes, batch 321 (12321): mcc: 0.8540, acc: 0.7812, precision: 0.9078, recall: 0.8177, f1: 0.8604, edges-ner-ontonotes_loss: 0.0466
09/16 06:38:50 AM: Update 12527: task edges-ner-ontonotes, batch 527 (12527): mcc: 0.8433, acc: 0.7672, precision: 0.9012, recall: 0.8044, f1: 0.8501, edges-ner-ontonotes_loss: 0.0498
09/16 06:38:57 AM: Update 12405: task edges-ner-ontonotes, batch 405 (12405): mcc: 0.8493, acc: 0.7749, precision: 0.9054, recall: 0.8114, f1: 0.8558, edges-ner-ontonotes_loss: 0.0483
09/16 06:39:00 AM: Update 12608: task edges-ner-ontonotes, batch 608 (12608): mcc: 0.8414, acc: 0.7642, precision: 0.9001, recall: 0.8020, f1: 0.8482, edges-ner-ontonotes_loss: 0.0499
09/16 06:39:07 AM: Update 12461: task edges-ner-ontonotes, batch 461 (12461): mcc: 0.8462, acc: 0.7711, precision: 0.9035, recall: 0.8076, f1: 0.8529, edges-ner-ontonotes_loss: 0.0491
09/16 06:39:10 AM: Update 12706: task edges-ner-ontonotes, batch 706 (12706): mcc: 0.8407, acc: 0.7627, precision: 0.8998, recall: 0.8010, f1: 0.8475, edges-ner-ontonotes_loss: 0.0500
09/16 06:39:17 AM: Update 12553: task edges-ner-ontonotes, batch 553 (12553): mcc: 0.8431, acc: 0.7668, precision: 0.9011, recall: 0.8042, f1: 0.8499, edges-ner-ontonotes_loss: 0.0496
09/16 06:39:21 AM: Update 12772: task edges-ner-ontonotes, batch 772 (12772): mcc: 0.8395, acc: 0.7614, precision: 0.8987, recall: 0.7999, f1: 0.8464, edges-ner-ontonotes_loss: 0.0501
09/16 06:39:28 AM: Update 12647: task edges-ner-ontonotes, batch 647 (12647): mcc: 0.8409, acc: 0.7631, precision: 0.8998, recall: 0.8013, f1: 0.8477, edges-ner-ontonotes_loss: 0.0499
09/16 06:39:33 AM: Update 12858: task edges-ner-ontonotes, batch 858 (12858): mcc: 0.8412, acc: 0.7637, precision: 0.8999, recall: 0.8019, f1: 0.8481, edges-ner-ontonotes_loss: 0.0493
09/16 06:39:39 AM: Update 12729: task edges-ner-ontonotes, batch 729 (12729): mcc: 0.8401, acc: 0.7621, precision: 0.8992, recall: 0.8005, f1: 0.8470, edges-ner-ontonotes_loss: 0.0501
09/16 06:39:43 AM: Update 12929: task edges-ner-ontonotes, batch 929 (12929): mcc: 0.8433, acc: 0.7666, precision: 0.9012, recall: 0.8045, f1: 0.8501, edges-ner-ontonotes_loss: 0.0487
09/16 06:39:49 AM: Update 12782: task edges-ner-ontonotes, batch 782 (12782): mcc: 0.8396, acc: 0.7616, precision: 0.8987, recall: 0.8000, f1: 0.8465, edges-ner-ontonotes_loss: 0.0500
09/16 06:39:51 AM: ***** Step 13000 / Validation 13 *****
09/16 06:39:51 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:39:51 AM: Validating...
09/16 06:39:53 AM: Evaluate: task edges-ner-ontonotes, batch 12 (157): mcc: 0.7987, acc: 0.7075, precision: 0.9003, recall: 0.7260, f1: 0.8038, edges-ner-ontonotes_loss: 0.0568
09/16 06:39:59 AM: Update 12840: task edges-ner-ontonotes, batch 840 (12840): mcc: 0.8407, acc: 0.7629, precision: 0.8996, recall: 0.8012, f1: 0.8476, edges-ner-ontonotes_loss: 0.0495
09/16 06:40:03 AM: Evaluate: task edges-ner-ontonotes, batch 71 (157): mcc: 0.8785, acc: 0.8180, precision: 0.9327, recall: 0.8394, f1: 0.8836, edges-ner-ontonotes_loss: 0.0390
09/16 06:40:09 AM: Update 12893: task edges-ner-ontonotes, batch 893 (12893): mcc: 0.8422, acc: 0.7650, precision: 0.9003, recall: 0.8032, f1: 0.8490, edges-ner-ontonotes_loss: 0.0490
09/16 06:40:13 AM: Evaluate: task edges-ner-ontonotes, batch 119 (157): mcc: 0.8980, acc: 0.8457, precision: 0.9426, recall: 0.8657, f1: 0.9025, edges-ner-ontonotes_loss: 0.0340
09/16 06:40:20 AM: Update 12945: task edges-ner-ontonotes, batch 945 (12945): mcc: 0.8439, acc: 0.7674, precision: 0.9016, recall: 0.8052, f1: 0.8507, edges-ner-ontonotes_loss: 0.0485
09/16 06:40:20 AM: Updating LR scheduler:
09/16 06:40:20 AM: 	Best result seen so far for macro_avg: 0.909
09/16 06:40:20 AM: 	# validation passes without improvement: 1
09/16 06:40:20 AM: edges-ner-ontonotes_loss: training: 0.048076 validation: 0.031894
09/16 06:40:20 AM: macro_avg: validation: 0.907641
09/16 06:40:20 AM: micro_avg: validation: 0.000000
09/16 06:40:20 AM: edges-ner-ontonotes_mcc: training: 0.845082 validation: 0.903314
09/16 06:40:20 AM: edges-ner-ontonotes_acc: training: 0.768780 validation: 0.852745
09/16 06:40:20 AM: edges-ner-ontonotes_precision: training: 0.902453 validation: 0.946939
09/16 06:40:20 AM: edges-ner-ontonotes_recall: training: 0.806529 validation: 0.871474
09/16 06:40:20 AM: edges-ner-ontonotes_f1: training: 0.851799 validation: 0.907641
09/16 06:40:20 AM: Global learning rate: 0.0001
09/16 06:40:20 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:40:23 AM: Update 13023: task edges-ner-ontonotes, batch 23 (13023): mcc: 0.8603, acc: 0.7932, precision: 0.9020, recall: 0.8348, f1: 0.8671, edges-ner-ontonotes_loss: 0.0420
09/16 06:40:27 AM: ***** Step 13000 / Validation 13 *****
09/16 06:40:27 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:40:27 AM: Validating...
09/16 06:40:30 AM: Evaluate: task edges-ner-ontonotes, batch 16 (157): mcc: 0.8105, acc: 0.7236, precision: 0.9026, recall: 0.7447, f1: 0.8161, edges-ner-ontonotes_loss: 0.0520
09/16 06:40:34 AM: Update 13076: task edges-ner-ontonotes, batch 76 (13076): mcc: 0.8576, acc: 0.7877, precision: 0.9084, recall: 0.8238, f1: 0.8640, edges-ner-ontonotes_loss: 0.0426
09/16 06:40:40 AM: Evaluate: task edges-ner-ontonotes, batch 79 (157): mcc: 0.8858, acc: 0.8280, precision: 0.9369, recall: 0.8488, f1: 0.8907, edges-ner-ontonotes_loss: 0.0373
09/16 06:40:44 AM: Update 13131: task edges-ner-ontonotes, batch 131 (13131): mcc: 0.8680, acc: 0.8003, precision: 0.9148, recall: 0.8368, f1: 0.8741, edges-ner-ontonotes_loss: 0.0396
09/16 06:40:50 AM: Evaluate: task edges-ner-ontonotes, batch 125 (157): mcc: 0.9002, acc: 0.8487, precision: 0.9446, recall: 0.8681, f1: 0.9047, edges-ner-ontonotes_loss: 0.0336
09/16 06:40:54 AM: Update 13185: task edges-ner-ontonotes, batch 185 (13185): mcc: 0.8698, acc: 0.8030, precision: 0.9153, recall: 0.8397, f1: 0.8759, edges-ner-ontonotes_loss: 0.0390
09/16 06:40:56 AM: Updating LR scheduler:
09/16 06:40:56 AM: 	Best result seen so far for macro_avg: 0.909
09/16 06:40:56 AM: 	# validation passes without improvement: 1
09/16 06:40:56 AM: edges-ner-ontonotes_loss: training: 0.048076 validation: 0.031894
09/16 06:40:56 AM: macro_avg: validation: 0.907641
09/16 06:40:56 AM: micro_avg: validation: 0.000000
09/16 06:40:56 AM: edges-ner-ontonotes_mcc: training: 0.845082 validation: 0.903314
09/16 06:40:56 AM: edges-ner-ontonotes_acc: training: 0.768780 validation: 0.852745
09/16 06:40:56 AM: edges-ner-ontonotes_precision: training: 0.902453 validation: 0.946939
09/16 06:40:56 AM: edges-ner-ontonotes_recall: training: 0.806529 validation: 0.871474
09/16 06:40:56 AM: edges-ner-ontonotes_f1: training: 0.851799 validation: 0.907641
09/16 06:40:56 AM: Global learning rate: 0.0001
09/16 06:40:56 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:41:00 AM: Update 13013: task edges-ner-ontonotes, batch 13 (13013): mcc: 0.8719, acc: 0.8058, precision: 0.9099, recall: 0.8486, f1: 0.8782, edges-ner-ontonotes_loss: 0.0389
09/16 06:41:04 AM: Update 13261: task edges-ner-ontonotes, batch 261 (13261): mcc: 0.8749, acc: 0.8092, precision: 0.9197, recall: 0.8450, f1: 0.8808, edges-ner-ontonotes_loss: 0.0377
09/16 06:41:10 AM: Update 13075: task edges-ner-ontonotes, batch 75 (13075): mcc: 0.8603, acc: 0.7915, precision: 0.9094, recall: 0.8278, f1: 0.8667, edges-ner-ontonotes_loss: 0.0425
09/16 06:41:14 AM: Update 13340: task edges-ner-ontonotes, batch 340 (13340): mcc: 0.8770, acc: 0.8127, precision: 0.9211, recall: 0.8476, f1: 0.8828, edges-ner-ontonotes_loss: 0.0372
09/16 06:41:20 AM: Update 13151: task edges-ner-ontonotes, batch 151 (13151): mcc: 0.8686, acc: 0.8011, precision: 0.9151, recall: 0.8377, f1: 0.8747, edges-ner-ontonotes_loss: 0.0395
09/16 06:41:26 AM: Update 13401: task edges-ner-ontonotes, batch 401 (13401): mcc: 0.8789, acc: 0.8149, precision: 0.9224, recall: 0.8498, f1: 0.8846, edges-ner-ontonotes_loss: 0.0368
09/16 06:41:33 AM: Update 13231: task edges-ner-ontonotes, batch 231 (13231): mcc: 0.8722, acc: 0.8060, precision: 0.9181, recall: 0.8416, f1: 0.8782, edges-ner-ontonotes_loss: 0.0382
09/16 06:41:37 AM: Update 13475: task edges-ner-ontonotes, batch 475 (13475): mcc: 0.8787, acc: 0.8149, precision: 0.9215, recall: 0.8503, f1: 0.8844, edges-ner-ontonotes_loss: 0.0369
09/16 06:41:43 AM: Update 13305: task edges-ner-ontonotes, batch 305 (13305): mcc: 0.8763, acc: 0.8115, precision: 0.9212, recall: 0.8460, f1: 0.8820, edges-ner-ontonotes_loss: 0.0375
09/16 06:41:48 AM: Update 13559: task edges-ner-ontonotes, batch 559 (13559): mcc: 0.8790, acc: 0.8146, precision: 0.9216, recall: 0.8506, f1: 0.8847, edges-ner-ontonotes_loss: 0.0367
09/16 06:41:55 AM: Update 13381: task edges-ner-ontonotes, batch 381 (13381): mcc: 0.8787, acc: 0.8149, precision: 0.9220, recall: 0.8497, f1: 0.8844, edges-ner-ontonotes_loss: 0.0368
09/16 06:42:00 AM: Update 13638: task edges-ner-ontonotes, batch 638 (13638): mcc: 0.8793, acc: 0.8148, precision: 0.9218, recall: 0.8511, f1: 0.8850, edges-ner-ontonotes_loss: 0.0367
09/16 06:42:05 AM: Update 13434: task edges-ner-ontonotes, batch 434 (13434): mcc: 0.8784, acc: 0.8142, precision: 0.9219, recall: 0.8493, f1: 0.8841, edges-ner-ontonotes_loss: 0.0370
09/16 06:42:10 AM: Update 13705: task edges-ner-ontonotes, batch 705 (13705): mcc: 0.8791, acc: 0.8144, precision: 0.9218, recall: 0.8506, f1: 0.8848, edges-ner-ontonotes_loss: 0.0368
09/16 06:42:18 AM: Update 13511: task edges-ner-ontonotes, batch 511 (13511): mcc: 0.8783, acc: 0.8139, precision: 0.9215, recall: 0.8495, f1: 0.8841, edges-ner-ontonotes_loss: 0.0369
09/16 06:42:20 AM: Update 13784: task edges-ner-ontonotes, batch 784 (13784): mcc: 0.8745, acc: 0.8080, precision: 0.9192, recall: 0.8446, f1: 0.8804, edges-ner-ontonotes_loss: 0.0385
09/16 06:42:29 AM: Update 13583: task edges-ner-ontonotes, batch 583 (13583): mcc: 0.8788, acc: 0.8143, precision: 0.9216, recall: 0.8503, f1: 0.8845, edges-ner-ontonotes_loss: 0.0368
09/16 06:42:30 AM: Update 13861: task edges-ner-ontonotes, batch 861 (13861): mcc: 0.8711, acc: 0.8034, precision: 0.9174, recall: 0.8401, f1: 0.8770, edges-ner-ontonotes_loss: 0.0399
09/16 06:42:40 AM: Update 13928: task edges-ner-ontonotes, batch 928 (13928): mcc: 0.8682, acc: 0.7997, precision: 0.9154, recall: 0.8367, f1: 0.8743, edges-ner-ontonotes_loss: 0.0410
09/16 06:42:40 AM: Update 13652: task edges-ner-ontonotes, batch 652 (13652): mcc: 0.8793, acc: 0.8147, precision: 0.9218, recall: 0.8509, f1: 0.8850, edges-ner-ontonotes_loss: 0.0367
09/16 06:42:50 AM: ***** Step 14000 / Validation 14 *****
09/16 06:42:50 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:42:50 AM: Validating...
09/16 06:42:51 AM: Evaluate: task edges-ner-ontonotes, batch 6 (157): mcc: 0.7852, acc: 0.6875, precision: 0.8854, recall: 0.7150, f1: 0.7911, edges-ner-ontonotes_loss: 0.0596
09/16 06:42:51 AM: Update 13707: task edges-ner-ontonotes, batch 707 (13707): mcc: 0.8790, acc: 0.8142, precision: 0.9217, recall: 0.8505, f1: 0.8847, edges-ner-ontonotes_loss: 0.0368
09/16 06:43:01 AM: Evaluate: task edges-ner-ontonotes, batch 67 (157): mcc: 0.8771, acc: 0.8166, precision: 0.9267, recall: 0.8424, f1: 0.8825, edges-ner-ontonotes_loss: 0.0401
09/16 06:43:01 AM: Update 13764: task edges-ner-ontonotes, batch 764 (13764): mcc: 0.8757, acc: 0.8096, precision: 0.9199, recall: 0.8462, f1: 0.8815, edges-ner-ontonotes_loss: 0.0381
09/16 06:43:11 AM: Evaluate: task edges-ner-ontonotes, batch 117 (157): mcc: 0.8976, acc: 0.8439, precision: 0.9422, recall: 0.8655, f1: 0.9022, edges-ner-ontonotes_loss: 0.0348
09/16 06:43:11 AM: Update 13817: task edges-ner-ontonotes, batch 817 (13817): mcc: 0.8729, acc: 0.8058, precision: 0.9186, recall: 0.8423, f1: 0.8788, edges-ner-ontonotes_loss: 0.0393
09/16 06:43:18 AM: Updating LR scheduler:
09/16 06:43:18 AM: 	Best result seen so far for macro_avg: 0.909
09/16 06:43:18 AM: 	# validation passes without improvement: 2
09/16 06:43:18 AM: edges-ner-ontonotes_loss: training: 0.042138 validation: 0.032760
09/16 06:43:18 AM: macro_avg: validation: 0.905783
09/16 06:43:18 AM: micro_avg: validation: 0.000000
09/16 06:43:18 AM: edges-ner-ontonotes_mcc: training: 0.865648 validation: 0.901436
09/16 06:43:18 AM: edges-ner-ontonotes_acc: training: 0.796408 validation: 0.848499
09/16 06:43:18 AM: edges-ner-ontonotes_precision: training: 0.913971 validation: 0.946750
09/16 06:43:18 AM: edges-ner-ontonotes_recall: training: 0.833337 validation: 0.868214
09/16 06:43:18 AM: edges-ner-ontonotes_f1: training: 0.871794 validation: 0.905783
09/16 06:43:18 AM: Global learning rate: 0.0001
09/16 06:43:18 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:43:21 AM: Update 13887: task edges-ner-ontonotes, batch 887 (13887): mcc: 0.8697, acc: 0.8017, precision: 0.9165, recall: 0.8384, f1: 0.8757, edges-ner-ontonotes_loss: 0.0404
09/16 06:43:21 AM: Update 14005: task edges-ner-ontonotes, batch 5 (14005): mcc: 0.8631, acc: 0.7926, precision: 0.9263, recall: 0.8173, f1: 0.8684, edges-ner-ontonotes_loss: 0.0454
09/16 06:43:31 AM: Update 13965: task edges-ner-ontonotes, batch 965 (13965): mcc: 0.8667, acc: 0.7978, precision: 0.9145, recall: 0.8348, f1: 0.8728, edges-ner-ontonotes_loss: 0.0417
09/16 06:43:31 AM: Update 14084: task edges-ner-ontonotes, batch 84 (14084): mcc: 0.8311, acc: 0.7484, precision: 0.8925, recall: 0.7904, f1: 0.8383, edges-ner-ontonotes_loss: 0.0510
09/16 06:43:35 AM: ***** Step 14000 / Validation 14 *****
09/16 06:43:35 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:43:35 AM: Validating...
09/16 06:43:41 AM: Evaluate: task edges-ner-ontonotes, batch 40 (157): mcc: 0.8570, acc: 0.7879, precision: 0.9143, recall: 0.8173, f1: 0.8631, edges-ner-ontonotes_loss: 0.0447
09/16 06:43:42 AM: Update 14154: task edges-ner-ontonotes, batch 154 (14154): mcc: 0.8353, acc: 0.7530, precision: 0.8984, recall: 0.7926, f1: 0.8422, edges-ner-ontonotes_loss: 0.0508
09/16 06:43:51 AM: Evaluate: task edges-ner-ontonotes, batch 96 (157): mcc: 0.8932, acc: 0.8376, precision: 0.9409, recall: 0.8586, f1: 0.8979, edges-ner-ontonotes_loss: 0.0361
09/16 06:43:52 AM: Update 14213: task edges-ner-ontonotes, batch 213 (14213): mcc: 0.8344, acc: 0.7512, precision: 0.8979, recall: 0.7914, f1: 0.8413, edges-ner-ontonotes_loss: 0.0506
09/16 06:44:01 AM: Evaluate: task edges-ner-ontonotes, batch 147 (157): mcc: 0.9016, acc: 0.8488, precision: 0.9468, recall: 0.8685, f1: 0.9060, edges-ner-ontonotes_loss: 0.0332
09/16 06:44:02 AM: Update 14273: task edges-ner-ontonotes, batch 273 (14273): mcc: 0.8341, acc: 0.7509, precision: 0.8975, recall: 0.7911, f1: 0.8410, edges-ner-ontonotes_loss: 0.0504
09/16 06:44:03 AM: Updating LR scheduler:
09/16 06:44:03 AM: 	Best result seen so far for macro_avg: 0.909
09/16 06:44:03 AM: 	# validation passes without improvement: 2
09/16 06:44:03 AM: edges-ner-ontonotes_loss: training: 0.042138 validation: 0.032760
09/16 06:44:03 AM: macro_avg: validation: 0.905783
09/16 06:44:03 AM: micro_avg: validation: 0.000000
09/16 06:44:03 AM: edges-ner-ontonotes_mcc: training: 0.865648 validation: 0.901436
09/16 06:44:03 AM: edges-ner-ontonotes_acc: training: 0.796408 validation: 0.848499
09/16 06:44:03 AM: edges-ner-ontonotes_precision: training: 0.913971 validation: 0.946750
09/16 06:44:03 AM: edges-ner-ontonotes_recall: training: 0.833337 validation: 0.868214
09/16 06:44:03 AM: edges-ner-ontonotes_f1: training: 0.871794 validation: 0.905783
09/16 06:44:03 AM: Global learning rate: 0.0001
09/16 06:44:03 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:44:11 AM: Update 14046: task edges-ner-ontonotes, batch 46 (14046): mcc: 0.8339, acc: 0.7494, precision: 0.8993, recall: 0.7891, f1: 0.8406, edges-ner-ontonotes_loss: 0.0508
09/16 06:44:12 AM: Update 14343: task edges-ner-ontonotes, batch 343 (14343): mcc: 0.8348, acc: 0.7532, precision: 0.8970, recall: 0.7929, f1: 0.8417, edges-ner-ontonotes_loss: 0.0503
09/16 06:44:21 AM: Update 14125: task edges-ner-ontonotes, batch 125 (14125): mcc: 0.8364, acc: 0.7542, precision: 0.8986, recall: 0.7944, f1: 0.8433, edges-ner-ontonotes_loss: 0.0502
09/16 06:44:22 AM: Update 14426: task edges-ner-ontonotes, batch 426 (14426): mcc: 0.8393, acc: 0.7591, precision: 0.8988, recall: 0.7993, f1: 0.8461, edges-ner-ontonotes_loss: 0.0488
09/16 06:44:34 AM: Update 14204: task edges-ner-ontonotes, batch 204 (14204): mcc: 0.8343, acc: 0.7512, precision: 0.8973, recall: 0.7917, f1: 0.8412, edges-ner-ontonotes_loss: 0.0507
09/16 06:44:34 AM: Update 14504: task edges-ner-ontonotes, batch 504 (14504): mcc: 0.8444, acc: 0.7663, precision: 0.9020, recall: 0.8057, f1: 0.8512, edges-ner-ontonotes_loss: 0.0473
09/16 06:44:45 AM: Update 14583: task edges-ner-ontonotes, batch 583 (14583): mcc: 0.8469, acc: 0.7699, precision: 0.9031, recall: 0.8093, f1: 0.8536, edges-ner-ontonotes_loss: 0.0464
09/16 06:44:45 AM: Update 14285: task edges-ner-ontonotes, batch 285 (14285): mcc: 0.8339, acc: 0.7508, precision: 0.8972, recall: 0.7911, f1: 0.8408, edges-ner-ontonotes_loss: 0.0504
09/16 06:44:55 AM: Update 14642: task edges-ner-ontonotes, batch 642 (14642): mcc: 0.8497, acc: 0.7740, precision: 0.9054, recall: 0.8123, f1: 0.8563, edges-ner-ontonotes_loss: 0.0457
09/16 06:44:55 AM: Update 14344: task edges-ner-ontonotes, batch 344 (14344): mcc: 0.8349, acc: 0.7532, precision: 0.8973, recall: 0.7928, f1: 0.8418, edges-ner-ontonotes_loss: 0.0502
09/16 06:45:05 AM: Update 14712: task edges-ner-ontonotes, batch 712 (14712): mcc: 0.8542, acc: 0.7802, precision: 0.9081, recall: 0.8179, f1: 0.8606, edges-ner-ontonotes_loss: 0.0445
09/16 06:45:05 AM: Update 14417: task edges-ner-ontonotes, batch 417 (14417): mcc: 0.8393, acc: 0.7592, precision: 0.8987, recall: 0.7995, f1: 0.8462, edges-ner-ontonotes_loss: 0.0489
09/16 06:45:15 AM: Update 14785: task edges-ner-ontonotes, batch 785 (14785): mcc: 0.8571, acc: 0.7841, precision: 0.9099, recall: 0.8216, f1: 0.8635, edges-ner-ontonotes_loss: 0.0438
09/16 06:45:15 AM: Update 14491: task edges-ner-ontonotes, batch 491 (14491): mcc: 0.8434, acc: 0.7648, precision: 0.9015, recall: 0.8044, f1: 0.8502, edges-ner-ontonotes_loss: 0.0475
09/16 06:45:25 AM: Update 14561: task edges-ner-ontonotes, batch 561 (14561): mcc: 0.8459, acc: 0.7685, precision: 0.9026, recall: 0.8079, f1: 0.8526, edges-ner-ontonotes_loss: 0.0466
09/16 06:45:25 AM: Update 14857: task edges-ner-ontonotes, batch 857 (14857): mcc: 0.8593, acc: 0.7870, precision: 0.9109, recall: 0.8246, f1: 0.8656, edges-ner-ontonotes_loss: 0.0431
09/16 06:45:35 AM: Update 14930: task edges-ner-ontonotes, batch 930 (14930): mcc: 0.8620, acc: 0.7906, precision: 0.9126, recall: 0.8280, f1: 0.8682, edges-ner-ontonotes_loss: 0.0423
09/16 06:45:35 AM: Update 14630: task edges-ner-ontonotes, batch 630 (14630): mcc: 0.8492, acc: 0.7732, precision: 0.9049, recall: 0.8118, f1: 0.8558, edges-ner-ontonotes_loss: 0.0458
09/16 06:45:45 AM: Update 14680: task edges-ner-ontonotes, batch 680 (14680): mcc: 0.8517, acc: 0.7769, precision: 0.9065, recall: 0.8149, f1: 0.8582, edges-ner-ontonotes_loss: 0.0451
09/16 06:45:45 AM: Update 14995: task edges-ner-ontonotes, batch 995 (14995): mcc: 0.8631, acc: 0.7920, precision: 0.9132, recall: 0.8294, f1: 0.8693, edges-ner-ontonotes_loss: 0.0420
09/16 06:45:46 AM: ***** Step 15000 / Validation 15 *****
09/16 06:45:46 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:45:46 AM: Validating...
09/16 06:45:55 AM: Update 14740: task edges-ner-ontonotes, batch 740 (14740): mcc: 0.8552, acc: 0.7816, precision: 0.9086, recall: 0.8193, f1: 0.8617, edges-ner-ontonotes_loss: 0.0442
09/16 06:45:56 AM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.8694, acc: 0.8050, precision: 0.9240, recall: 0.8308, f1: 0.8749, edges-ner-ontonotes_loss: 0.0427
09/16 06:46:06 AM: Update 14793: task edges-ner-ontonotes, batch 793 (14793): mcc: 0.8574, acc: 0.7845, precision: 0.9100, recall: 0.8220, f1: 0.8637, edges-ner-ontonotes_loss: 0.0437
09/16 06:46:06 AM: Evaluate: task edges-ner-ontonotes, batch 105 (157): mcc: 0.8901, acc: 0.8346, precision: 0.9375, recall: 0.8561, f1: 0.8949, edges-ner-ontonotes_loss: 0.0363
09/16 06:46:16 AM: Update 14846: task edges-ner-ontonotes, batch 846 (14846): mcc: 0.8589, acc: 0.7865, precision: 0.9107, recall: 0.8241, f1: 0.8653, edges-ner-ontonotes_loss: 0.0432
09/16 06:46:16 AM: Evaluate: task edges-ner-ontonotes, batch 154 (157): mcc: 0.9041, acc: 0.8541, precision: 0.9444, recall: 0.8753, f1: 0.9085, edges-ner-ontonotes_loss: 0.0322
09/16 06:46:16 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:46:16 AM: Best result seen so far for macro.
09/16 06:46:16 AM: Updating LR scheduler:
09/16 06:46:16 AM: 	Best result seen so far for macro_avg: 0.909
09/16 06:46:16 AM: 	# validation passes without improvement: 0
09/16 06:46:16 AM: edges-ner-ontonotes_loss: training: 0.041977 validation: 0.031919
09/16 06:46:16 AM: macro_avg: validation: 0.909191
09/16 06:46:16 AM: micro_avg: validation: 0.000000
09/16 06:46:16 AM: edges-ner-ontonotes_mcc: training: 0.863158 validation: 0.904783
09/16 06:46:16 AM: edges-ner-ontonotes_acc: training: 0.792135 validation: 0.855096
09/16 06:46:16 AM: edges-ner-ontonotes_precision: training: 0.913221 validation: 0.944881
09/16 06:46:16 AM: edges-ner-ontonotes_recall: training: 0.829487 validation: 0.876099
09/16 06:46:16 AM: edges-ner-ontonotes_f1: training: 0.869342 validation: 0.909191
09/16 06:46:16 AM: Global learning rate: 0.0001
09/16 06:46:16 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:46:26 AM: Update 14917: task edges-ner-ontonotes, batch 917 (14917): mcc: 0.8617, acc: 0.7902, precision: 0.9124, recall: 0.8276, f1: 0.8679, edges-ner-ontonotes_loss: 0.0424
09/16 06:46:26 AM: Update 15065: task edges-ner-ontonotes, batch 65 (15065): mcc: 0.8788, acc: 0.8164, precision: 0.9233, recall: 0.8487, f1: 0.8844, edges-ner-ontonotes_loss: 0.0368
09/16 06:46:37 AM: Update 15141: task edges-ner-ontonotes, batch 141 (15141): mcc: 0.8807, acc: 0.8174, precision: 0.9242, recall: 0.8512, f1: 0.8862, edges-ner-ontonotes_loss: 0.0361
09/16 06:46:37 AM: Update 14976: task edges-ner-ontonotes, batch 976 (14976): mcc: 0.8628, acc: 0.7916, precision: 0.9130, recall: 0.8290, f1: 0.8690, edges-ner-ontonotes_loss: 0.0421
09/16 06:46:42 AM: ***** Step 15000 / Validation 15 *****
09/16 06:46:42 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:46:42 AM: Validating...
09/16 06:46:49 AM: Evaluate: task edges-ner-ontonotes, batch 38 (157): mcc: 0.8537, acc: 0.7838, precision: 0.9155, recall: 0.8102, f1: 0.8597, edges-ner-ontonotes_loss: 0.0474
09/16 06:46:49 AM: Update 15207: task edges-ner-ontonotes, batch 207 (15207): mcc: 0.8813, acc: 0.8181, precision: 0.9246, recall: 0.8520, f1: 0.8868, edges-ner-ontonotes_loss: 0.0359
09/16 06:46:59 AM: Evaluate: task edges-ner-ontonotes, batch 94 (157): mcc: 0.8895, acc: 0.8321, precision: 0.9393, recall: 0.8533, f1: 0.8943, edges-ner-ontonotes_loss: 0.0370
09/16 06:47:01 AM: Update 15257: task edges-ner-ontonotes, batch 257 (15257): mcc: 0.8823, acc: 0.8196, precision: 0.9245, recall: 0.8541, f1: 0.8879, edges-ner-ontonotes_loss: 0.0358
09/16 06:47:09 AM: Evaluate: task edges-ner-ontonotes, batch 142 (157): mcc: 0.9044, acc: 0.8545, precision: 0.9462, recall: 0.8741, f1: 0.9087, edges-ner-ontonotes_loss: 0.0325
09/16 06:47:11 AM: Update 15307: task edges-ner-ontonotes, batch 307 (15307): mcc: 0.8751, acc: 0.8098, precision: 0.9202, recall: 0.8448, f1: 0.8809, edges-ner-ontonotes_loss: 0.0385
09/16 06:47:11 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:47:11 AM: Best result seen so far for macro.
09/16 06:47:11 AM: Updating LR scheduler:
09/16 06:47:11 AM: 	Best result seen so far for macro_avg: 0.909
09/16 06:47:11 AM: 	# validation passes without improvement: 0
09/16 06:47:11 AM: edges-ner-ontonotes_loss: training: 0.041977 validation: 0.031919
09/16 06:47:11 AM: macro_avg: validation: 0.909191
09/16 06:47:11 AM: micro_avg: validation: 0.000000
09/16 06:47:11 AM: edges-ner-ontonotes_mcc: training: 0.863158 validation: 0.904783
09/16 06:47:11 AM: edges-ner-ontonotes_acc: training: 0.792135 validation: 0.855096
09/16 06:47:11 AM: edges-ner-ontonotes_precision: training: 0.913221 validation: 0.944881
09/16 06:47:11 AM: edges-ner-ontonotes_recall: training: 0.829487 validation: 0.876099
09/16 06:47:11 AM: edges-ner-ontonotes_f1: training: 0.869342 validation: 0.909191
09/16 06:47:11 AM: Global learning rate: 0.0001
09/16 06:47:11 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:47:19 AM: Update 15046: task edges-ner-ontonotes, batch 46 (15046): mcc: 0.8756, acc: 0.8133, precision: 0.9190, recall: 0.8469, f1: 0.8815, edges-ner-ontonotes_loss: 0.0372
09/16 06:47:21 AM: Update 15385: task edges-ner-ontonotes, batch 385 (15385): mcc: 0.8662, acc: 0.7981, precision: 0.9138, recall: 0.8345, f1: 0.8724, edges-ner-ontonotes_loss: 0.0420
09/16 06:47:29 AM: Update 15131: task edges-ner-ontonotes, batch 131 (15131): mcc: 0.8809, acc: 0.8173, precision: 0.9249, recall: 0.8511, f1: 0.8865, edges-ner-ontonotes_loss: 0.0359
09/16 06:47:34 AM: Update 15460: task edges-ner-ontonotes, batch 460 (15460): mcc: 0.8615, acc: 0.7916, precision: 0.9110, recall: 0.8286, f1: 0.8678, edges-ner-ontonotes_loss: 0.0437
09/16 06:47:39 AM: Update 15207: task edges-ner-ontonotes, batch 207 (15207): mcc: 0.8813, acc: 0.8181, precision: 0.9246, recall: 0.8520, f1: 0.8868, edges-ner-ontonotes_loss: 0.0359
09/16 06:47:45 AM: Update 15533: task edges-ner-ontonotes, batch 533 (15533): mcc: 0.8566, acc: 0.7851, precision: 0.9080, recall: 0.8224, f1: 0.8631, edges-ner-ontonotes_loss: 0.0457
09/16 06:47:49 AM: Update 15261: task edges-ner-ontonotes, batch 261 (15261): mcc: 0.8806, acc: 0.8174, precision: 0.9233, recall: 0.8520, f1: 0.8862, edges-ner-ontonotes_loss: 0.0361
09/16 06:47:56 AM: Update 15600: task edges-ner-ontonotes, batch 600 (15600): mcc: 0.8543, acc: 0.7822, precision: 0.9062, recall: 0.8198, f1: 0.8608, edges-ner-ontonotes_loss: 0.0466
09/16 06:47:59 AM: Update 15347: task edges-ner-ontonotes, batch 347 (15347): mcc: 0.8692, acc: 0.8021, precision: 0.9157, recall: 0.8381, f1: 0.8752, edges-ner-ontonotes_loss: 0.0409
09/16 06:48:08 AM: Update 15685: task edges-ner-ontonotes, batch 685 (15685): mcc: 0.8526, acc: 0.7792, precision: 0.9057, recall: 0.8172, f1: 0.8592, edges-ner-ontonotes_loss: 0.0471
09/16 06:48:09 AM: Update 15426: task edges-ner-ontonotes, batch 426 (15426): mcc: 0.8639, acc: 0.7946, precision: 0.9128, recall: 0.8311, f1: 0.8701, edges-ner-ontonotes_loss: 0.0427
09/16 06:48:18 AM: Update 15767: task edges-ner-ontonotes, batch 767 (15767): mcc: 0.8509, acc: 0.7769, precision: 0.9047, recall: 0.8151, f1: 0.8575, edges-ner-ontonotes_loss: 0.0474
09/16 06:48:19 AM: Update 15507: task edges-ner-ontonotes, batch 507 (15507): mcc: 0.8583, acc: 0.7870, precision: 0.9092, recall: 0.8242, f1: 0.8646, edges-ner-ontonotes_loss: 0.0451
09/16 06:48:28 AM: Update 15858: task edges-ner-ontonotes, batch 858 (15858): mcc: 0.8491, acc: 0.7740, precision: 0.9035, recall: 0.8129, f1: 0.8558, edges-ner-ontonotes_loss: 0.0477
09/16 06:48:29 AM: Update 15573: task edges-ner-ontonotes, batch 573 (15573): mcc: 0.8554, acc: 0.7837, precision: 0.9071, recall: 0.8210, f1: 0.8619, edges-ner-ontonotes_loss: 0.0462
09/16 06:48:38 AM: Update 15916: task edges-ner-ontonotes, batch 916 (15916): mcc: 0.8487, acc: 0.7737, precision: 0.9032, recall: 0.8125, f1: 0.8555, edges-ner-ontonotes_loss: 0.0476
09/16 06:48:40 AM: Update 15670: task edges-ner-ontonotes, batch 670 (15670): mcc: 0.8530, acc: 0.7798, precision: 0.9058, recall: 0.8179, f1: 0.8596, edges-ner-ontonotes_loss: 0.0469
09/16 06:48:48 AM: Update 15997: task edges-ner-ontonotes, batch 997 (15997): mcc: 0.8506, acc: 0.7761, precision: 0.9045, recall: 0.8147, f1: 0.8572, edges-ner-ontonotes_loss: 0.0468
09/16 06:48:48 AM: ***** Step 16000 / Validation 16 *****
09/16 06:48:48 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:48:48 AM: Validating...
09/16 06:48:50 AM: Update 15749: task edges-ner-ontonotes, batch 749 (15749): mcc: 0.8510, acc: 0.7771, precision: 0.9047, recall: 0.8152, f1: 0.8576, edges-ner-ontonotes_loss: 0.0474
09/16 06:48:58 AM: Evaluate: task edges-ner-ontonotes, batch 64 (157): mcc: 0.8793, acc: 0.8174, precision: 0.9322, recall: 0.8413, f1: 0.8844, edges-ner-ontonotes_loss: 0.0384
09/16 06:49:00 AM: Update 15808: task edges-ner-ontonotes, batch 808 (15808): mcc: 0.8501, acc: 0.7754, precision: 0.9042, recall: 0.8141, f1: 0.8568, edges-ner-ontonotes_loss: 0.0476
09/16 06:49:08 AM: Evaluate: task edges-ner-ontonotes, batch 117 (157): mcc: 0.8984, acc: 0.8448, precision: 0.9441, recall: 0.8651, f1: 0.9029, edges-ner-ontonotes_loss: 0.0338
09/16 06:49:10 AM: Update 15868: task edges-ner-ontonotes, batch 868 (15868): mcc: 0.8491, acc: 0.7741, precision: 0.9034, recall: 0.8130, f1: 0.8558, edges-ner-ontonotes_loss: 0.0477
09/16 06:49:15 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:49:15 AM: Best result seen so far for macro.
09/16 06:49:15 AM: Updating LR scheduler:
09/16 06:49:15 AM: 	Best result seen so far for macro_avg: 0.909
09/16 06:49:15 AM: 	# validation passes without improvement: 0
09/16 06:49:15 AM: edges-ner-ontonotes_loss: training: 0.046821 validation: 0.031576
09/16 06:49:15 AM: macro_avg: validation: 0.909393
09/16 06:49:15 AM: micro_avg: validation: 0.000000
09/16 06:49:15 AM: edges-ner-ontonotes_mcc: training: 0.850661 validation: 0.905202
09/16 06:49:15 AM: edges-ner-ontonotes_acc: training: 0.776145 validation: 0.853503
09/16 06:49:15 AM: edges-ner-ontonotes_precision: training: 0.904612 validation: 0.949501
09/16 06:49:15 AM: edges-ner-ontonotes_recall: training: 0.814682 validation: 0.872536
09/16 06:49:15 AM: edges-ner-ontonotes_f1: training: 0.857295 validation: 0.909393
09/16 06:49:15 AM: Global learning rate: 0.0001
09/16 06:49:15 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:49:18 AM: Update 16025: task edges-ner-ontonotes, batch 25 (16025): mcc: 0.8596, acc: 0.7924, precision: 0.9123, recall: 0.8238, f1: 0.8658, edges-ner-ontonotes_loss: 0.0408
09/16 06:49:20 AM: Update 15919: task edges-ner-ontonotes, batch 919 (15919): mcc: 0.8488, acc: 0.7737, precision: 0.9031, recall: 0.8126, f1: 0.8555, edges-ner-ontonotes_loss: 0.0476
09/16 06:49:28 AM: Update 16094: task edges-ner-ontonotes, batch 94 (16094): mcc: 0.8606, acc: 0.7917, precision: 0.9099, recall: 0.8279, f1: 0.8670, edges-ner-ontonotes_loss: 0.0420
09/16 06:49:30 AM: Update 15992: task edges-ner-ontonotes, batch 992 (15992): mcc: 0.8506, acc: 0.7761, precision: 0.9045, recall: 0.8146, f1: 0.8572, edges-ner-ontonotes_loss: 0.0469
09/16 06:49:34 AM: ***** Step 16000 / Validation 16 *****
09/16 06:49:34 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:49:34 AM: Validating...
09/16 06:49:38 AM: Update 16168: task edges-ner-ontonotes, batch 168 (16168): mcc: 0.8607, acc: 0.7916, precision: 0.9093, recall: 0.8287, f1: 0.8671, edges-ner-ontonotes_loss: 0.0421
09/16 06:49:43 AM: Evaluate: task edges-ner-ontonotes, batch 56 (157): mcc: 0.8776, acc: 0.8150, precision: 0.9310, recall: 0.8394, f1: 0.8828, edges-ner-ontonotes_loss: 0.0390
09/16 06:49:49 AM: Update 16209: task edges-ner-ontonotes, batch 209 (16209): mcc: 0.8640, acc: 0.7954, precision: 0.9112, recall: 0.8330, f1: 0.8703, edges-ner-ontonotes_loss: 0.0411
09/16 06:49:55 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.8967, acc: 0.8421, precision: 0.9436, recall: 0.8624, f1: 0.9012, edges-ner-ontonotes_loss: 0.0342
09/16 06:50:01 AM: Update 16267: task edges-ner-ontonotes, batch 267 (16267): mcc: 0.8666, acc: 0.7989, precision: 0.9126, recall: 0.8363, f1: 0.8728, edges-ner-ontonotes_loss: 0.0400
09/16 06:50:02 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:50:02 AM: Best result seen so far for macro.
09/16 06:50:02 AM: Updating LR scheduler:
09/16 06:50:02 AM: 	Best result seen so far for macro_avg: 0.909
09/16 06:50:02 AM: 	# validation passes without improvement: 0
09/16 06:50:02 AM: edges-ner-ontonotes_loss: training: 0.046821 validation: 0.031576
09/16 06:50:02 AM: macro_avg: validation: 0.909393
09/16 06:50:02 AM: micro_avg: validation: 0.000000
09/16 06:50:02 AM: edges-ner-ontonotes_mcc: training: 0.850661 validation: 0.905202
09/16 06:50:02 AM: edges-ner-ontonotes_acc: training: 0.776145 validation: 0.853503
09/16 06:50:02 AM: edges-ner-ontonotes_precision: training: 0.904612 validation: 0.949501
09/16 06:50:02 AM: edges-ner-ontonotes_recall: training: 0.814682 validation: 0.872536
09/16 06:50:02 AM: edges-ner-ontonotes_f1: training: 0.857295 validation: 0.909393
09/16 06:50:02 AM: Global learning rate: 0.0001
09/16 06:50:02 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:50:05 AM: Update 16006: task edges-ner-ontonotes, batch 6 (16006): mcc: 0.8482, acc: 0.7649, precision: 0.9249, recall: 0.7921, f1: 0.8533, edges-ner-ontonotes_loss: 0.0427
09/16 06:50:12 AM: Update 16350: task edges-ner-ontonotes, batch 350 (16350): mcc: 0.8700, acc: 0.8031, precision: 0.9151, recall: 0.8402, f1: 0.8761, edges-ner-ontonotes_loss: 0.0391
09/16 06:50:15 AM: Update 16079: task edges-ner-ontonotes, batch 79 (16079): mcc: 0.8571, acc: 0.7888, precision: 0.9061, recall: 0.8251, f1: 0.8637, edges-ner-ontonotes_loss: 0.0426
09/16 06:50:22 AM: Update 16418: task edges-ner-ontonotes, batch 418 (16418): mcc: 0.8734, acc: 0.8074, precision: 0.9176, recall: 0.8442, f1: 0.8794, edges-ner-ontonotes_loss: 0.0382
09/16 06:50:25 AM: Update 16147: task edges-ner-ontonotes, batch 147 (16147): mcc: 0.8614, acc: 0.7923, precision: 0.9094, recall: 0.8298, f1: 0.8678, edges-ner-ontonotes_loss: 0.0418
09/16 06:50:32 AM: Update 16490: task edges-ner-ontonotes, batch 490 (16490): mcc: 0.8762, acc: 0.8104, precision: 0.9199, recall: 0.8472, f1: 0.8820, edges-ner-ontonotes_loss: 0.0374
09/16 06:50:35 AM: Update 16203: task edges-ner-ontonotes, batch 203 (16203): mcc: 0.8630, acc: 0.7934, precision: 0.9107, recall: 0.8316, f1: 0.8694, edges-ner-ontonotes_loss: 0.0413
09/16 06:50:42 AM: Update 16538: task edges-ner-ontonotes, batch 538 (16538): mcc: 0.8778, acc: 0.8127, precision: 0.9210, recall: 0.8490, f1: 0.8835, edges-ner-ontonotes_loss: 0.0372
09/16 06:50:45 AM: Update 16282: task edges-ner-ontonotes, batch 282 (16282): mcc: 0.8675, acc: 0.7999, precision: 0.9134, recall: 0.8372, f1: 0.8737, edges-ner-ontonotes_loss: 0.0397
09/16 06:50:52 AM: Update 16612: task edges-ner-ontonotes, batch 612 (16612): mcc: 0.8785, acc: 0.8134, precision: 0.9214, recall: 0.8500, f1: 0.8842, edges-ner-ontonotes_loss: 0.0369
09/16 06:50:55 AM: Update 16357: task edges-ner-ontonotes, batch 357 (16357): mcc: 0.8700, acc: 0.8031, precision: 0.9150, recall: 0.8403, f1: 0.8761, edges-ner-ontonotes_loss: 0.0391
09/16 06:51:02 AM: Update 16682: task edges-ner-ontonotes, batch 682 (16682): mcc: 0.8785, acc: 0.8135, precision: 0.9213, recall: 0.8501, f1: 0.8843, edges-ner-ontonotes_loss: 0.0370
09/16 06:51:06 AM: Update 16426: task edges-ner-ontonotes, batch 426 (16426): mcc: 0.8736, acc: 0.8074, precision: 0.9178, recall: 0.8442, f1: 0.8795, edges-ner-ontonotes_loss: 0.0381
09/16 06:51:12 AM: Update 16747: task edges-ner-ontonotes, batch 747 (16747): mcc: 0.8786, acc: 0.8135, precision: 0.9212, recall: 0.8504, f1: 0.8844, edges-ner-ontonotes_loss: 0.0368
09/16 06:51:16 AM: Update 16498: task edges-ner-ontonotes, batch 498 (16498): mcc: 0.8766, acc: 0.8111, precision: 0.9200, recall: 0.8478, f1: 0.8824, edges-ner-ontonotes_loss: 0.0373
09/16 06:51:24 AM: Update 16823: task edges-ner-ontonotes, batch 823 (16823): mcc: 0.8787, acc: 0.8138, precision: 0.9214, recall: 0.8504, f1: 0.8845, edges-ner-ontonotes_loss: 0.0368
09/16 06:51:26 AM: Update 16556: task edges-ner-ontonotes, batch 556 (16556): mcc: 0.8775, acc: 0.8122, precision: 0.9206, recall: 0.8488, f1: 0.8832, edges-ner-ontonotes_loss: 0.0372
09/16 06:51:36 AM: Update 16895: task edges-ner-ontonotes, batch 895 (16895): mcc: 0.8750, acc: 0.8088, precision: 0.9192, recall: 0.8455, f1: 0.8808, edges-ner-ontonotes_loss: 0.0382
09/16 06:51:36 AM: Update 16628: task edges-ner-ontonotes, batch 628 (16628): mcc: 0.8786, acc: 0.8134, precision: 0.9215, recall: 0.8500, f1: 0.8843, edges-ner-ontonotes_loss: 0.0369
09/16 06:51:46 AM: Update 16963: task edges-ner-ontonotes, batch 963 (16963): mcc: 0.8725, acc: 0.8056, precision: 0.9174, recall: 0.8426, f1: 0.8784, edges-ner-ontonotes_loss: 0.0394
09/16 06:51:46 AM: Update 16695: task edges-ner-ontonotes, batch 695 (16695): mcc: 0.8783, acc: 0.8130, precision: 0.9210, recall: 0.8499, f1: 0.8840, edges-ner-ontonotes_loss: 0.0370
09/16 06:51:51 AM: ***** Step 17000 / Validation 17 *****
09/16 06:51:51 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:51:51 AM: Validating...
09/16 06:51:56 AM: Evaluate: task edges-ner-ontonotes, batch 31 (157): mcc: 0.8504, acc: 0.7808, precision: 0.9082, recall: 0.8110, f1: 0.8568, edges-ner-ontonotes_loss: 0.0478
09/16 06:51:56 AM: Update 16759: task edges-ner-ontonotes, batch 759 (16759): mcc: 0.8788, acc: 0.8139, precision: 0.9212, recall: 0.8507, f1: 0.8845, edges-ner-ontonotes_loss: 0.0367
09/16 06:52:06 AM: Evaluate: task edges-ner-ontonotes, batch 90 (157): mcc: 0.8893, acc: 0.8313, precision: 0.9363, recall: 0.8557, f1: 0.8942, edges-ner-ontonotes_loss: 0.0368
09/16 06:52:07 AM: Update 16813: task edges-ner-ontonotes, batch 813 (16813): mcc: 0.8791, acc: 0.8143, precision: 0.9214, recall: 0.8509, f1: 0.8848, edges-ner-ontonotes_loss: 0.0367
09/16 06:52:16 AM: Evaluate: task edges-ner-ontonotes, batch 137 (157): mcc: 0.9039, acc: 0.8536, precision: 0.9443, recall: 0.8751, f1: 0.9084, edges-ner-ontonotes_loss: 0.0328
09/16 06:52:18 AM: Update 16865: task edges-ner-ontonotes, batch 865 (16865): mcc: 0.8767, acc: 0.8109, precision: 0.9202, recall: 0.8478, f1: 0.8825, edges-ner-ontonotes_loss: 0.0376
09/16 06:52:20 AM: Updating LR scheduler:
09/16 06:52:22 AM: 	Best result seen so far for macro_avg: 0.909
09/16 06:52:22 AM: 	# validation passes without improvement: 1
09/16 06:52:22 AM: edges-ner-ontonotes_loss: training: 0.039932 validation: 0.032321
09/16 06:52:22 AM: macro_avg: validation: 0.908605
09/16 06:52:22 AM: micro_avg: validation: 0.000000
09/16 06:52:22 AM: edges-ner-ontonotes_mcc: training: 0.871147 validation: 0.904142
09/16 06:52:22 AM: edges-ner-ontonotes_acc: training: 0.803967 validation: 0.853958
09/16 06:52:22 AM: edges-ner-ontonotes_precision: training: 0.916569 validation: 0.943791
09/16 06:52:22 AM: edges-ner-ontonotes_recall: training: 0.840975 validation: 0.875948
09/16 06:52:22 AM: edges-ner-ontonotes_f1: training: 0.877146 validation: 0.908605
09/16 06:52:22 AM: Global learning rate: 0.0001
09/16 06:52:22 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:52:26 AM: Update 17032: task edges-ner-ontonotes, batch 32 (17032): mcc: 0.8362, acc: 0.7541, precision: 0.9005, recall: 0.7923, f1: 0.8429, edges-ner-ontonotes_loss: 0.0508
09/16 06:52:28 AM: Update 16950: task edges-ner-ontonotes, batch 950 (16950): mcc: 0.8732, acc: 0.8065, precision: 0.9180, recall: 0.8433, f1: 0.8791, edges-ner-ontonotes_loss: 0.0392
09/16 06:52:35 AM: ***** Step 17000 / Validation 17 *****
09/16 06:52:35 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:52:35 AM: Validating...
09/16 06:52:39 AM: Update 17107: task edges-ner-ontonotes, batch 107 (17107): mcc: 0.8297, acc: 0.7504, precision: 0.8933, recall: 0.7870, f1: 0.8368, edges-ner-ontonotes_loss: 0.0541
09/16 06:52:39 AM: Evaluate: task edges-ner-ontonotes, batch 23 (157): mcc: 0.8203, acc: 0.7422, precision: 0.8897, recall: 0.7734, f1: 0.8275, edges-ner-ontonotes_loss: 0.0547
09/16 06:52:49 AM: Update 17150: task edges-ner-ontonotes, batch 150 (17150): mcc: 0.8338, acc: 0.7551, precision: 0.8952, recall: 0.7928, f1: 0.8409, edges-ner-ontonotes_loss: 0.0531
09/16 06:52:49 AM: Evaluate: task edges-ner-ontonotes, batch 86 (157): mcc: 0.8881, acc: 0.8303, precision: 0.9348, recall: 0.8549, f1: 0.8931, edges-ner-ontonotes_loss: 0.0374
09/16 06:52:59 AM: Evaluate: task edges-ner-ontonotes, batch 136 (157): mcc: 0.9037, acc: 0.8534, precision: 0.9441, recall: 0.8748, f1: 0.9082, edges-ner-ontonotes_loss: 0.0329
09/16 06:52:59 AM: Update 17209: task edges-ner-ontonotes, batch 209 (17209): mcc: 0.8347, acc: 0.7561, precision: 0.8955, recall: 0.7940, f1: 0.8417, edges-ner-ontonotes_loss: 0.0522
09/16 06:53:02 AM: Updating LR scheduler:
09/16 06:53:02 AM: 	Best result seen so far for macro_avg: 0.909
09/16 06:53:02 AM: 	# validation passes without improvement: 1
09/16 06:53:02 AM: edges-ner-ontonotes_loss: training: 0.039932 validation: 0.032321
09/16 06:53:02 AM: macro_avg: validation: 0.908605
09/16 06:53:02 AM: micro_avg: validation: 0.000000
09/16 06:53:02 AM: edges-ner-ontonotes_mcc: training: 0.871147 validation: 0.904142
09/16 06:53:02 AM: edges-ner-ontonotes_acc: training: 0.803967 validation: 0.853958
09/16 06:53:02 AM: edges-ner-ontonotes_precision: training: 0.916569 validation: 0.943791
09/16 06:53:02 AM: edges-ner-ontonotes_recall: training: 0.840975 validation: 0.875948
09/16 06:53:02 AM: edges-ner-ontonotes_f1: training: 0.877146 validation: 0.908605
09/16 06:53:02 AM: Global learning rate: 0.0001
09/16 06:53:02 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:53:09 AM: Update 17288: task edges-ner-ontonotes, batch 288 (17288): mcc: 0.8346, acc: 0.7557, precision: 0.8949, recall: 0.7945, f1: 0.8417, edges-ner-ontonotes_loss: 0.0513
09/16 06:53:09 AM: Update 17051: task edges-ner-ontonotes, batch 51 (17051): mcc: 0.8308, acc: 0.7477, precision: 0.8960, recall: 0.7866, f1: 0.8377, edges-ner-ontonotes_loss: 0.0541
09/16 06:53:19 AM: Update 17379: task edges-ner-ontonotes, batch 379 (17379): mcc: 0.8339, acc: 0.7539, precision: 0.8939, recall: 0.7941, f1: 0.8410, edges-ner-ontonotes_loss: 0.0512
09/16 06:53:20 AM: Update 17117: task edges-ner-ontonotes, batch 117 (17117): mcc: 0.8322, acc: 0.7532, precision: 0.8955, recall: 0.7895, f1: 0.8392, edges-ner-ontonotes_loss: 0.0535
09/16 06:53:29 AM: Update 17442: task edges-ner-ontonotes, batch 442 (17442): mcc: 0.8356, acc: 0.7564, precision: 0.8952, recall: 0.7961, f1: 0.8427, edges-ner-ontonotes_loss: 0.0506
09/16 06:53:30 AM: Update 17215: task edges-ner-ontonotes, batch 215 (17215): mcc: 0.8347, acc: 0.7563, precision: 0.8958, recall: 0.7938, f1: 0.8417, edges-ner-ontonotes_loss: 0.0522
09/16 06:53:39 AM: Update 17521: task edges-ner-ontonotes, batch 521 (17521): mcc: 0.8401, acc: 0.7626, precision: 0.8984, recall: 0.8011, f1: 0.8470, edges-ner-ontonotes_loss: 0.0494
09/16 06:53:40 AM: Update 17298: task edges-ner-ontonotes, batch 298 (17298): mcc: 0.8350, acc: 0.7560, precision: 0.8951, recall: 0.7950, f1: 0.8421, edges-ner-ontonotes_loss: 0.0512
09/16 06:53:49 AM: Update 17597: task edges-ner-ontonotes, batch 597 (17597): mcc: 0.8439, acc: 0.7677, precision: 0.9002, recall: 0.8065, f1: 0.8508, edges-ner-ontonotes_loss: 0.0482
09/16 06:53:50 AM: Update 17378: task edges-ner-ontonotes, batch 378 (17378): mcc: 0.8339, acc: 0.7540, precision: 0.8938, recall: 0.7941, f1: 0.8410, edges-ner-ontonotes_loss: 0.0512
09/16 06:53:59 AM: Update 17683: task edges-ner-ontonotes, batch 683 (17683): mcc: 0.8472, acc: 0.7719, precision: 0.9022, recall: 0.8106, f1: 0.8540, edges-ner-ontonotes_loss: 0.0472
09/16 06:54:00 AM: Update 17435: task edges-ner-ontonotes, batch 435 (17435): mcc: 0.8351, acc: 0.7557, precision: 0.8946, recall: 0.7957, f1: 0.8422, edges-ner-ontonotes_loss: 0.0507
09/16 06:54:09 AM: Update 17745: task edges-ner-ontonotes, batch 745 (17745): mcc: 0.8489, acc: 0.7743, precision: 0.9033, recall: 0.8127, f1: 0.8556, edges-ner-ontonotes_loss: 0.0466
09/16 06:54:10 AM: Update 17520: task edges-ner-ontonotes, batch 520 (17520): mcc: 0.8400, acc: 0.7624, precision: 0.8983, recall: 0.8010, f1: 0.8469, edges-ner-ontonotes_loss: 0.0494
09/16 06:54:20 AM: Update 17817: task edges-ner-ontonotes, batch 817 (17817): mcc: 0.8528, acc: 0.7797, precision: 0.9056, recall: 0.8176, f1: 0.8594, edges-ner-ontonotes_loss: 0.0454
09/16 06:54:20 AM: Update 17595: task edges-ner-ontonotes, batch 595 (17595): mcc: 0.8441, acc: 0.7678, precision: 0.9004, recall: 0.8066, f1: 0.8509, edges-ner-ontonotes_loss: 0.0482
09/16 06:54:31 AM: Update 17664: task edges-ner-ontonotes, batch 664 (17664): mcc: 0.8470, acc: 0.7718, precision: 0.9019, recall: 0.8105, f1: 0.8538, edges-ner-ontonotes_loss: 0.0473
09/16 06:54:31 AM: Update 17886: task edges-ner-ontonotes, batch 886 (17886): mcc: 0.8557, acc: 0.7830, precision: 0.9077, recall: 0.8210, f1: 0.8622, edges-ner-ontonotes_loss: 0.0446
09/16 06:54:43 AM: Update 17961: task edges-ner-ontonotes, batch 961 (17961): mcc: 0.8584, acc: 0.7866, precision: 0.9093, recall: 0.8245, f1: 0.8648, edges-ner-ontonotes_loss: 0.0438
09/16 06:54:44 AM: Update 17743: task edges-ner-ontonotes, batch 743 (17743): mcc: 0.8488, acc: 0.7742, precision: 0.9031, recall: 0.8127, f1: 0.8555, edges-ner-ontonotes_loss: 0.0466
09/16 06:54:48 AM: ***** Step 18000 / Validation 18 *****
09/16 06:54:48 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:54:48 AM: Validating...
09/16 06:54:53 AM: Evaluate: task edges-ner-ontonotes, batch 34 (157): mcc: 0.8576, acc: 0.7930, precision: 0.9163, recall: 0.8165, f1: 0.8636, edges-ner-ontonotes_loss: 0.0464
09/16 06:54:54 AM: Update 17805: task edges-ner-ontonotes, batch 805 (17805): mcc: 0.8524, acc: 0.7792, precision: 0.9052, recall: 0.8172, f1: 0.8590, edges-ner-ontonotes_loss: 0.0456
09/16 06:55:03 AM: Evaluate: task edges-ner-ontonotes, batch 82 (157): mcc: 0.8902, acc: 0.8351, precision: 0.9391, recall: 0.8548, f1: 0.8950, edges-ner-ontonotes_loss: 0.0371
09/16 06:55:04 AM: Update 17863: task edges-ner-ontonotes, batch 863 (17863): mcc: 0.8549, acc: 0.7821, precision: 0.9070, recall: 0.8201, f1: 0.8614, edges-ner-ontonotes_loss: 0.0449
09/16 06:55:13 AM: Evaluate: task edges-ner-ontonotes, batch 135 (157): mcc: 0.9068, acc: 0.8591, precision: 0.9474, recall: 0.8774, f1: 0.9110, edges-ner-ontonotes_loss: 0.0319
09/16 06:55:17 AM: Update 17919: task edges-ner-ontonotes, batch 919 (17919): mcc: 0.8567, acc: 0.7844, precision: 0.9082, recall: 0.8224, f1: 0.8632, edges-ner-ontonotes_loss: 0.0443
09/16 06:55:17 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:55:18 AM: Best result seen so far for macro.
09/16 06:55:18 AM: Updating LR scheduler:
09/16 06:55:18 AM: 	Best result seen so far for macro_avg: 0.912
09/16 06:55:18 AM: 	# validation passes without improvement: 0
09/16 06:55:18 AM: edges-ner-ontonotes_loss: training: 0.043367 validation: 0.031099
09/16 06:55:18 AM: macro_avg: validation: 0.912136
09/16 06:55:18 AM: micro_avg: validation: 0.000000
09/16 06:55:18 AM: edges-ner-ontonotes_mcc: training: 0.860089 validation: 0.907860
09/16 06:55:18 AM: edges-ner-ontonotes_acc: training: 0.788972 validation: 0.860176
09/16 06:55:18 AM: edges-ner-ontonotes_precision: training: 0.910437 validation: 0.947098
09/16 06:55:18 AM: edges-ner-ontonotes_recall: training: 0.826471 validation: 0.879663
09/16 06:55:18 AM: edges-ner-ontonotes_f1: training: 0.866424 validation: 0.912136
09/16 06:55:18 AM: Global learning rate: 0.0001
09/16 06:55:18 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:55:23 AM: Update 18039: task edges-ner-ontonotes, batch 39 (18039): mcc: 0.8884, acc: 0.8292, precision: 0.9304, recall: 0.8597, f1: 0.8937, edges-ner-ontonotes_loss: 0.0342
09/16 06:55:28 AM: Update 17996: task edges-ner-ontonotes, batch 996 (17996): mcc: 0.8599, acc: 0.7887, precision: 0.9103, recall: 0.8263, f1: 0.8663, edges-ner-ontonotes_loss: 0.0434
09/16 06:55:29 AM: ***** Step 18000 / Validation 18 *****
09/16 06:55:29 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:55:29 AM: Validating...
09/16 06:55:34 AM: Update 18088: task edges-ner-ontonotes, batch 88 (18088): mcc: 0.8836, acc: 0.8217, precision: 0.9247, recall: 0.8562, f1: 0.8891, edges-ner-ontonotes_loss: 0.0357
09/16 06:55:39 AM: Evaluate: task edges-ner-ontonotes, batch 59 (157): mcc: 0.8822, acc: 0.8242, precision: 0.9320, recall: 0.8468, f1: 0.8873, edges-ner-ontonotes_loss: 0.0391
09/16 06:55:44 AM: Update 18154: task edges-ner-ontonotes, batch 154 (18154): mcc: 0.8843, acc: 0.8222, precision: 0.9237, recall: 0.8585, f1: 0.8899, edges-ner-ontonotes_loss: 0.0355
09/16 06:55:50 AM: Evaluate: task edges-ner-ontonotes, batch 107 (157): mcc: 0.8943, acc: 0.8418, precision: 0.9400, recall: 0.8614, f1: 0.8990, edges-ner-ontonotes_loss: 0.0351
09/16 06:55:54 AM: Update 18210: task edges-ner-ontonotes, batch 210 (18210): mcc: 0.8845, acc: 0.8220, precision: 0.9244, recall: 0.8582, f1: 0.8900, edges-ner-ontonotes_loss: 0.0353
09/16 06:56:00 AM: Evaluate: task edges-ner-ontonotes, batch 155 (157): mcc: 0.9077, acc: 0.8599, precision: 0.9468, recall: 0.8795, f1: 0.9119, edges-ner-ontonotes_loss: 0.0312
09/16 06:56:01 AM: Best result seen so far for edges-ner-ontonotes.
09/16 06:56:01 AM: Best result seen so far for macro.
09/16 06:56:01 AM: Updating LR scheduler:
09/16 06:56:01 AM: 	Best result seen so far for macro_avg: 0.912
09/16 06:56:01 AM: 	# validation passes without improvement: 0
09/16 06:56:01 AM: edges-ner-ontonotes_loss: training: 0.043367 validation: 0.031099
09/16 06:56:01 AM: macro_avg: validation: 0.912136
09/16 06:56:01 AM: micro_avg: validation: 0.000000
09/16 06:56:01 AM: edges-ner-ontonotes_mcc: training: 0.860089 validation: 0.907860
09/16 06:56:01 AM: edges-ner-ontonotes_acc: training: 0.788972 validation: 0.860176
09/16 06:56:01 AM: edges-ner-ontonotes_precision: training: 0.910437 validation: 0.947098
09/16 06:56:01 AM: edges-ner-ontonotes_recall: training: 0.826471 validation: 0.879663
09/16 06:56:01 AM: edges-ner-ontonotes_f1: training: 0.866424 validation: 0.912136
09/16 06:56:01 AM: Global learning rate: 0.0001
09/16 06:56:01 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:56:04 AM: Update 18270: task edges-ner-ontonotes, batch 270 (18270): mcc: 0.8843, acc: 0.8214, precision: 0.9249, recall: 0.8574, f1: 0.8898, edges-ner-ontonotes_loss: 0.0352
09/16 06:56:12 AM: Update 18056: task edges-ner-ontonotes, batch 56 (18056): mcc: 0.8874, acc: 0.8283, precision: 0.9277, recall: 0.8604, f1: 0.8928, edges-ner-ontonotes_loss: 0.0346
09/16 06:56:14 AM: Update 18347: task edges-ner-ontonotes, batch 347 (18347): mcc: 0.8838, acc: 0.8208, precision: 0.9247, recall: 0.8565, f1: 0.8893, edges-ner-ontonotes_loss: 0.0355
09/16 06:56:22 AM: Update 18131: task edges-ner-ontonotes, batch 131 (18131): mcc: 0.8849, acc: 0.8226, precision: 0.9251, recall: 0.8582, f1: 0.8904, edges-ner-ontonotes_loss: 0.0354
09/16 06:56:24 AM: Update 18403: task edges-ner-ontonotes, batch 403 (18403): mcc: 0.8790, acc: 0.8148, precision: 0.9211, recall: 0.8512, f1: 0.8848, edges-ner-ontonotes_loss: 0.0376
09/16 06:56:32 AM: Update 18205: task edges-ner-ontonotes, batch 205 (18205): mcc: 0.8847, acc: 0.8225, precision: 0.9247, recall: 0.8582, f1: 0.8902, edges-ner-ontonotes_loss: 0.0353
09/16 06:56:34 AM: Update 18474: task edges-ner-ontonotes, batch 474 (18474): mcc: 0.8728, acc: 0.8064, precision: 0.9175, recall: 0.8431, f1: 0.8787, edges-ner-ontonotes_loss: 0.0400
09/16 06:56:42 AM: Update 18276: task edges-ner-ontonotes, batch 276 (18276): mcc: 0.8845, acc: 0.8216, precision: 0.9250, recall: 0.8576, f1: 0.8900, edges-ner-ontonotes_loss: 0.0351
09/16 06:56:44 AM: Update 18542: task edges-ner-ontonotes, batch 542 (18542): mcc: 0.8693, acc: 0.8015, precision: 0.9161, recall: 0.8381, f1: 0.8753, edges-ner-ontonotes_loss: 0.0413
09/16 06:56:52 AM: Update 18349: task edges-ner-ontonotes, batch 349 (18349): mcc: 0.8837, acc: 0.8207, precision: 0.9246, recall: 0.8565, f1: 0.8893, edges-ner-ontonotes_loss: 0.0355
09/16 06:56:54 AM: Update 18617: task edges-ner-ontonotes, batch 617 (18617): mcc: 0.8652, acc: 0.7962, precision: 0.9134, recall: 0.8330, f1: 0.8713, edges-ner-ontonotes_loss: 0.0428
09/16 06:57:02 AM: Update 18409: task edges-ner-ontonotes, batch 409 (18409): mcc: 0.8782, acc: 0.8137, precision: 0.9205, recall: 0.8502, f1: 0.8839, edges-ner-ontonotes_loss: 0.0379
09/16 06:57:05 AM: Update 18674: task edges-ner-ontonotes, batch 674 (18674): mcc: 0.8631, acc: 0.7932, precision: 0.9121, recall: 0.8303, f1: 0.8693, edges-ner-ontonotes_loss: 0.0438
09/16 06:57:14 AM: Update 18483: task edges-ner-ontonotes, batch 483 (18483): mcc: 0.8719, acc: 0.8050, precision: 0.9171, recall: 0.8418, f1: 0.8779, edges-ner-ontonotes_loss: 0.0404
09/16 06:57:15 AM: Update 18753: task edges-ner-ontonotes, batch 753 (18753): mcc: 0.8596, acc: 0.7887, precision: 0.9099, recall: 0.8261, f1: 0.8660, edges-ner-ontonotes_loss: 0.0448
09/16 06:57:24 AM: Update 18565: task edges-ner-ontonotes, batch 565 (18565): mcc: 0.8676, acc: 0.7992, precision: 0.9151, recall: 0.8359, f1: 0.8737, edges-ner-ontonotes_loss: 0.0420
09/16 06:57:26 AM: Update 18836: task edges-ner-ontonotes, batch 836 (18836): mcc: 0.8579, acc: 0.7859, precision: 0.9091, recall: 0.8237, f1: 0.8643, edges-ner-ontonotes_loss: 0.0452
09/16 06:57:34 AM: Update 18646: task edges-ner-ontonotes, batch 646 (18646): mcc: 0.8645, acc: 0.7953, precision: 0.9131, recall: 0.8320, f1: 0.8707, edges-ner-ontonotes_loss: 0.0432
09/16 06:57:36 AM: Update 18924: task edges-ner-ontonotes, batch 924 (18924): mcc: 0.8571, acc: 0.7848, precision: 0.9086, recall: 0.8227, f1: 0.8635, edges-ner-ontonotes_loss: 0.0453
09/16 06:57:44 AM: Update 18712: task edges-ner-ontonotes, batch 712 (18712): mcc: 0.8614, acc: 0.7911, precision: 0.9111, recall: 0.8283, f1: 0.8677, edges-ner-ontonotes_loss: 0.0443
09/16 06:57:46 AM: Update 18994: task edges-ner-ontonotes, batch 994 (18994): mcc: 0.8557, acc: 0.7829, precision: 0.9076, recall: 0.8210, f1: 0.8622, edges-ner-ontonotes_loss: 0.0456
09/16 06:57:46 AM: ***** Step 19000 / Validation 19 *****
09/16 06:57:46 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:57:46 AM: Validating...
09/16 06:57:55 AM: Update 18778: task edges-ner-ontonotes, batch 778 (18778): mcc: 0.8593, acc: 0.7881, precision: 0.9097, recall: 0.8257, f1: 0.8657, edges-ner-ontonotes_loss: 0.0449
09/16 06:57:56 AM: Evaluate: task edges-ner-ontonotes, batch 59 (157): mcc: 0.8845, acc: 0.8237, precision: 0.9347, recall: 0.8484, f1: 0.8895, edges-ner-ontonotes_loss: 0.0368
09/16 06:58:05 AM: Update 18835: task edges-ner-ontonotes, batch 835 (18835): mcc: 0.8579, acc: 0.7859, precision: 0.9091, recall: 0.8238, f1: 0.8643, edges-ner-ontonotes_loss: 0.0452
09/16 06:58:06 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.8994, acc: 0.8449, precision: 0.9454, recall: 0.8658, f1: 0.9038, edges-ner-ontonotes_loss: 0.0330
09/16 06:58:14 AM: Updating LR scheduler:
09/16 06:58:14 AM: 	Best result seen so far for macro_avg: 0.912
09/16 06:58:14 AM: 	# validation passes without improvement: 1
09/16 06:58:14 AM: edges-ner-ontonotes_loss: training: 0.045535 validation: 0.030607
09/16 06:58:14 AM: macro_avg: validation: 0.909982
09/16 06:58:14 AM: micro_avg: validation: 0.000000
09/16 06:58:14 AM: edges-ner-ontonotes_mcc: training: 0.855771 validation: 0.905827
09/16 06:58:14 AM: edges-ner-ontonotes_acc: training: 0.783031 validation: 0.853503
09/16 06:58:14 AM: edges-ner-ontonotes_precision: training: 0.907667 validation: 0.950157
09/16 06:58:14 AM: edges-ner-ontonotes_recall: training: 0.821165 validation: 0.873066
09/16 06:58:14 AM: edges-ner-ontonotes_f1: training: 0.862252 validation: 0.909982
09/16 06:58:14 AM: Global learning rate: 0.0001
09/16 06:58:14 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:58:15 AM: Update 18897: task edges-ner-ontonotes, batch 897 (18897): mcc: 0.8574, acc: 0.7851, precision: 0.9089, recall: 0.8229, f1: 0.8638, edges-ner-ontonotes_loss: 0.0453
09/16 06:58:17 AM: Update 19021: task edges-ner-ontonotes, batch 21 (19021): mcc: 0.8683, acc: 0.7978, precision: 0.9157, recall: 0.8366, f1: 0.8743, edges-ner-ontonotes_loss: 0.0378
09/16 06:58:25 AM: Update 18980: task edges-ner-ontonotes, batch 980 (18980): mcc: 0.8559, acc: 0.7832, precision: 0.9078, recall: 0.8213, f1: 0.8624, edges-ner-ontonotes_loss: 0.0456
09/16 06:58:27 AM: Update 19102: task edges-ner-ontonotes, batch 102 (19102): mcc: 0.8658, acc: 0.7980, precision: 0.9110, recall: 0.8364, f1: 0.8721, edges-ner-ontonotes_loss: 0.0407
09/16 06:58:31 AM: ***** Step 19000 / Validation 19 *****
09/16 06:58:31 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 06:58:31 AM: Validating...
09/16 06:58:35 AM: Evaluate: task edges-ner-ontonotes, batch 28 (157): mcc: 0.8469, acc: 0.7728, precision: 0.9137, recall: 0.7997, f1: 0.8529, edges-ner-ontonotes_loss: 0.0465
09/16 06:58:37 AM: Update 19169: task edges-ner-ontonotes, batch 169 (19169): mcc: 0.8628, acc: 0.7942, precision: 0.9090, recall: 0.8328, f1: 0.8693, edges-ner-ontonotes_loss: 0.0411
09/16 06:58:45 AM: Evaluate: task edges-ner-ontonotes, batch 84 (157): mcc: 0.8917, acc: 0.8333, precision: 0.9412, recall: 0.8556, f1: 0.8964, edges-ner-ontonotes_loss: 0.0351
09/16 06:58:47 AM: Update 19226: task edges-ner-ontonotes, batch 226 (19226): mcc: 0.8665, acc: 0.7984, precision: 0.9126, recall: 0.8361, f1: 0.8727, edges-ner-ontonotes_loss: 0.0401
09/16 06:58:55 AM: Evaluate: task edges-ner-ontonotes, batch 141 (157): mcc: 0.9064, acc: 0.8546, precision: 0.9503, recall: 0.8739, f1: 0.9105, edges-ner-ontonotes_loss: 0.0310
09/16 06:58:58 AM: Updating LR scheduler:
09/16 06:58:58 AM: 	Best result seen so far for macro_avg: 0.912
09/16 06:58:58 AM: 	# validation passes without improvement: 1
09/16 06:58:58 AM: edges-ner-ontonotes_loss: training: 0.045535 validation: 0.030607
09/16 06:58:58 AM: macro_avg: validation: 0.909982
09/16 06:58:58 AM: micro_avg: validation: 0.000000
09/16 06:58:58 AM: edges-ner-ontonotes_mcc: training: 0.855771 validation: 0.905827
09/16 06:58:58 AM: edges-ner-ontonotes_acc: training: 0.783031 validation: 0.853503
09/16 06:58:58 AM: edges-ner-ontonotes_precision: training: 0.907667 validation: 0.950157
09/16 06:58:58 AM: edges-ner-ontonotes_recall: training: 0.821165 validation: 0.873066
09/16 06:58:58 AM: edges-ner-ontonotes_f1: training: 0.862252 validation: 0.909982
09/16 06:58:58 AM: Global learning rate: 0.0001
09/16 06:58:58 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 06:59:01 AM: Update 19287: task edges-ner-ontonotes, batch 287 (19287): mcc: 0.8664, acc: 0.7981, precision: 0.9126, recall: 0.8359, f1: 0.8726, edges-ner-ontonotes_loss: 0.0401
09/16 06:59:05 AM: Update 19063: task edges-ner-ontonotes, batch 63 (19063): mcc: 0.8664, acc: 0.7962, precision: 0.9149, recall: 0.8338, f1: 0.8725, edges-ner-ontonotes_loss: 0.0401
09/16 06:59:11 AM: Update 19336: task edges-ner-ontonotes, batch 336 (19336): mcc: 0.8684, acc: 0.8010, precision: 0.9141, recall: 0.8382, f1: 0.8745, edges-ner-ontonotes_loss: 0.0396
09/16 06:59:15 AM: Update 19136: task edges-ner-ontonotes, batch 136 (19136): mcc: 0.8640, acc: 0.7952, precision: 0.9100, recall: 0.8339, f1: 0.8703, edges-ner-ontonotes_loss: 0.0409
09/16 06:59:21 AM: Update 19405: task edges-ner-ontonotes, batch 405 (19405): mcc: 0.8724, acc: 0.8062, precision: 0.9170, recall: 0.8428, f1: 0.8783, edges-ner-ontonotes_loss: 0.0386
09/16 06:59:25 AM: Update 19203: task edges-ner-ontonotes, batch 203 (19203): mcc: 0.8654, acc: 0.7973, precision: 0.9115, recall: 0.8353, f1: 0.8717, edges-ner-ontonotes_loss: 0.0402
09/16 06:59:31 AM: Update 19477: task edges-ner-ontonotes, batch 477 (19477): mcc: 0.8747, acc: 0.8092, precision: 0.9184, recall: 0.8458, f1: 0.8806, edges-ner-ontonotes_loss: 0.0378
09/16 06:59:36 AM: Update 19278: task edges-ner-ontonotes, batch 278 (19278): mcc: 0.8662, acc: 0.7980, precision: 0.9125, recall: 0.8357, f1: 0.8724, edges-ner-ontonotes_loss: 0.0401
09/16 06:59:41 AM: Update 19561: task edges-ner-ontonotes, batch 561 (19561): mcc: 0.8765, acc: 0.8114, precision: 0.9192, recall: 0.8482, f1: 0.8823, edges-ner-ontonotes_loss: 0.0372
09/16 06:59:46 AM: Update 19329: task edges-ner-ontonotes, batch 329 (19329): mcc: 0.8679, acc: 0.8006, precision: 0.9135, recall: 0.8379, f1: 0.8741, edges-ner-ontonotes_loss: 0.0397
09/16 06:59:51 AM: Update 19615: task edges-ner-ontonotes, batch 615 (19615): mcc: 0.8772, acc: 0.8124, precision: 0.9197, recall: 0.8491, f1: 0.8830, edges-ner-ontonotes_loss: 0.0370
09/16 06:59:56 AM: Update 19408: task edges-ner-ontonotes, batch 408 (19408): mcc: 0.8726, acc: 0.8065, precision: 0.9172, recall: 0.8431, f1: 0.8786, edges-ner-ontonotes_loss: 0.0385
09/16 07:00:01 AM: Update 19688: task edges-ner-ontonotes, batch 688 (19688): mcc: 0.8781, acc: 0.8138, precision: 0.9200, recall: 0.8505, f1: 0.8839, edges-ner-ontonotes_loss: 0.0368
09/16 07:00:06 AM: Update 19477: task edges-ner-ontonotes, batch 477 (19477): mcc: 0.8747, acc: 0.8092, precision: 0.9184, recall: 0.8458, f1: 0.8806, edges-ner-ontonotes_loss: 0.0378
09/16 07:00:11 AM: Update 19761: task edges-ner-ontonotes, batch 761 (19761): mcc: 0.8786, acc: 0.8144, precision: 0.9202, recall: 0.8512, f1: 0.8844, edges-ner-ontonotes_loss: 0.0367
09/16 07:00:16 AM: Update 19548: task edges-ner-ontonotes, batch 548 (19548): mcc: 0.8763, acc: 0.8113, precision: 0.9194, recall: 0.8479, f1: 0.8822, edges-ner-ontonotes_loss: 0.0373
09/16 07:00:21 AM: Update 19830: task edges-ner-ontonotes, batch 830 (19830): mcc: 0.8791, acc: 0.8151, precision: 0.9204, recall: 0.8520, f1: 0.8849, edges-ner-ontonotes_loss: 0.0365
09/16 07:00:27 AM: Update 19612: task edges-ner-ontonotes, batch 612 (19612): mcc: 0.8772, acc: 0.8125, precision: 0.9197, recall: 0.8490, f1: 0.8830, edges-ner-ontonotes_loss: 0.0370
09/16 07:00:32 AM: Update 19906: task edges-ner-ontonotes, batch 906 (19906): mcc: 0.8793, acc: 0.8153, precision: 0.9206, recall: 0.8522, f1: 0.8851, edges-ner-ontonotes_loss: 0.0364
09/16 07:00:38 AM: Update 19690: task edges-ner-ontonotes, batch 690 (19690): mcc: 0.8781, acc: 0.8138, precision: 0.9200, recall: 0.8506, f1: 0.8839, edges-ner-ontonotes_loss: 0.0368
09/16 07:00:42 AM: Update 19970: task edges-ner-ontonotes, batch 970 (19970): mcc: 0.8775, acc: 0.8130, precision: 0.9193, recall: 0.8500, f1: 0.8833, edges-ner-ontonotes_loss: 0.0373
09/16 07:00:45 AM: ***** Step 20000 / Validation 20 *****
09/16 07:00:45 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:00:45 AM: Validating...
09/16 07:00:50 AM: Update 19757: task edges-ner-ontonotes, batch 757 (19757): mcc: 0.8786, acc: 0.8146, precision: 0.9203, recall: 0.8512, f1: 0.8844, edges-ner-ontonotes_loss: 0.0366
09/16 07:00:52 AM: Evaluate: task edges-ner-ontonotes, batch 42 (157): mcc: 0.8699, acc: 0.8069, precision: 0.9200, recall: 0.8354, f1: 0.8757, edges-ner-ontonotes_loss: 0.0418
09/16 07:01:00 AM: Update 19811: task edges-ner-ontonotes, batch 811 (19811): mcc: 0.8789, acc: 0.8148, precision: 0.9203, recall: 0.8517, f1: 0.8847, edges-ner-ontonotes_loss: 0.0366
09/16 07:01:02 AM: Evaluate: task edges-ner-ontonotes, batch 95 (157): mcc: 0.8990, acc: 0.8459, precision: 0.9415, recall: 0.8687, f1: 0.9036, edges-ner-ontonotes_loss: 0.0345
09/16 07:01:10 AM: Update 19867: task edges-ner-ontonotes, batch 867 (19867): mcc: 0.8793, acc: 0.8152, precision: 0.9207, recall: 0.8521, f1: 0.8851, edges-ner-ontonotes_loss: 0.0364
09/16 07:01:12 AM: Evaluate: task edges-ner-ontonotes, batch 143 (157): mcc: 0.9088, acc: 0.8607, precision: 0.9467, recall: 0.8819, f1: 0.9131, edges-ner-ontonotes_loss: 0.0311
09/16 07:01:15 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:01:16 AM: Best result seen so far for macro.
09/16 07:01:16 AM: Updating LR scheduler:
09/16 07:01:16 AM: 	Best result seen so far for macro_avg: 0.912
09/16 07:01:16 AM: 	# validation passes without improvement: 0
09/16 07:01:16 AM: edges-ner-ontonotes_loss: training: 0.037971 validation: 0.030744
09/16 07:01:16 AM: macro_avg: validation: 0.912460
09/16 07:01:16 AM: micro_avg: validation: 0.000000
09/16 07:01:16 AM: edges-ner-ontonotes_mcc: training: 0.875831 validation: 0.908139
09/16 07:01:16 AM: edges-ner-ontonotes_acc: training: 0.810866 validation: 0.859873
09/16 07:01:16 AM: edges-ner-ontonotes_precision: training: 0.918153 validation: 0.945955
09/16 07:01:16 AM: edges-ner-ontonotes_recall: training: 0.848081 validation: 0.881256
09/16 07:01:16 AM: edges-ner-ontonotes_f1: training: 0.881727 validation: 0.912460
09/16 07:01:16 AM: Global learning rate: 0.0001
09/16 07:01:16 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:01:21 AM: Update 19925: task edges-ner-ontonotes, batch 925 (19925): mcc: 0.8797, acc: 0.8158, precision: 0.9208, recall: 0.8527, f1: 0.8854, edges-ner-ontonotes_loss: 0.0364
09/16 07:01:22 AM: Update 20056: task edges-ner-ontonotes, batch 56 (20056): mcc: 0.8352, acc: 0.7589, precision: 0.8980, recall: 0.7928, f1: 0.8421, edges-ner-ontonotes_loss: 0.0529
09/16 07:01:31 AM: Update 19998: task edges-ner-ontonotes, batch 998 (19998): mcc: 0.8760, acc: 0.8111, precision: 0.9183, recall: 0.8483, f1: 0.8819, edges-ner-ontonotes_loss: 0.0379
09/16 07:01:31 AM: ***** Step 20000 / Validation 20 *****
09/16 07:01:31 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:01:31 AM: Validating...
09/16 07:01:33 AM: Update 20130: task edges-ner-ontonotes, batch 130 (20130): mcc: 0.8369, acc: 0.7600, precision: 0.8981, recall: 0.7956, f1: 0.8437, edges-ner-ontonotes_loss: 0.0518
09/16 07:01:41 AM: Evaluate: task edges-ner-ontonotes, batch 58 (157): mcc: 0.8851, acc: 0.8272, precision: 0.9304, recall: 0.8536, f1: 0.8903, edges-ner-ontonotes_loss: 0.0379
09/16 07:01:43 AM: Update 20185: task edges-ner-ontonotes, batch 185 (20185): mcc: 0.8372, acc: 0.7608, precision: 0.8971, recall: 0.7972, f1: 0.8442, edges-ner-ontonotes_loss: 0.0516
09/16 07:01:52 AM: Evaluate: task edges-ner-ontonotes, batch 112 (157): mcc: 0.8989, acc: 0.8473, precision: 0.9393, recall: 0.8705, f1: 0.9036, edges-ner-ontonotes_loss: 0.0338
09/16 07:01:54 AM: Update 20229: task edges-ner-ontonotes, batch 229 (20229): mcc: 0.8351, acc: 0.7580, precision: 0.8957, recall: 0.7947, f1: 0.8421, edges-ner-ontonotes_loss: 0.0529
09/16 07:02:00 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:02:00 AM: Best result seen so far for macro.
09/16 07:02:00 AM: Updating LR scheduler:
09/16 07:02:00 AM: 	Best result seen so far for macro_avg: 0.912
09/16 07:02:00 AM: 	# validation passes without improvement: 0
09/16 07:02:00 AM: edges-ner-ontonotes_loss: training: 0.037971 validation: 0.030744
09/16 07:02:00 AM: macro_avg: validation: 0.912460
09/16 07:02:00 AM: micro_avg: validation: 0.000000
09/16 07:02:00 AM: edges-ner-ontonotes_mcc: training: 0.875831 validation: 0.908139
09/16 07:02:00 AM: edges-ner-ontonotes_acc: training: 0.810866 validation: 0.859873
09/16 07:02:00 AM: edges-ner-ontonotes_precision: training: 0.918153 validation: 0.945955
09/16 07:02:00 AM: edges-ner-ontonotes_recall: training: 0.848081 validation: 0.881256
09/16 07:02:00 AM: edges-ner-ontonotes_f1: training: 0.881727 validation: 0.912460
09/16 07:02:00 AM: Global learning rate: 0.0001
09/16 07:02:00 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:02:03 AM: Update 20001: task edges-ner-ontonotes, batch 1 (20001): mcc: 0.9122, acc: 0.8533, precision: 0.9846, recall: 0.8533, f1: 0.9143, edges-ner-ontonotes_loss: 0.0335
09/16 07:02:04 AM: Update 20316: task edges-ner-ontonotes, batch 316 (20316): mcc: 0.8347, acc: 0.7558, precision: 0.8943, recall: 0.7952, f1: 0.8419, edges-ner-ontonotes_loss: 0.0523
09/16 07:02:13 AM: Update 20078: task edges-ner-ontonotes, batch 78 (20078): mcc: 0.8370, acc: 0.7599, precision: 0.8991, recall: 0.7949, f1: 0.8438, edges-ner-ontonotes_loss: 0.0520
09/16 07:02:14 AM: Update 20401: task edges-ner-ontonotes, batch 401 (20401): mcc: 0.8349, acc: 0.7558, precision: 0.8948, recall: 0.7951, f1: 0.8420, edges-ner-ontonotes_loss: 0.0518
09/16 07:02:23 AM: Update 20153: task edges-ner-ontonotes, batch 153 (20153): mcc: 0.8384, acc: 0.7622, precision: 0.8982, recall: 0.7983, f1: 0.8453, edges-ner-ontonotes_loss: 0.0511
09/16 07:02:25 AM: Update 20481: task edges-ner-ontonotes, batch 481 (20481): mcc: 0.8350, acc: 0.7560, precision: 0.8942, recall: 0.7959, f1: 0.8421, edges-ner-ontonotes_loss: 0.0512
09/16 07:02:35 AM: Update 20542: task edges-ner-ontonotes, batch 542 (20542): mcc: 0.8349, acc: 0.7556, precision: 0.8942, recall: 0.7956, f1: 0.8420, edges-ner-ontonotes_loss: 0.0510
09/16 07:02:36 AM: Update 20229: task edges-ner-ontonotes, batch 229 (20229): mcc: 0.8351, acc: 0.7580, precision: 0.8957, recall: 0.7947, f1: 0.8421, edges-ner-ontonotes_loss: 0.0529
09/16 07:02:45 AM: Update 20628: task edges-ner-ontonotes, batch 628 (20628): mcc: 0.8399, acc: 0.7624, precision: 0.8978, recall: 0.8014, f1: 0.8468, edges-ner-ontonotes_loss: 0.0495
09/16 07:02:47 AM: Update 20314: task edges-ner-ontonotes, batch 314 (20314): mcc: 0.8349, acc: 0.7561, precision: 0.8945, recall: 0.7953, f1: 0.8420, edges-ner-ontonotes_loss: 0.0522
09/16 07:02:55 AM: Update 20710: task edges-ner-ontonotes, batch 710 (20710): mcc: 0.8437, acc: 0.7675, precision: 0.8999, recall: 0.8064, f1: 0.8506, edges-ner-ontonotes_loss: 0.0485
09/16 07:02:58 AM: Update 20396: task edges-ner-ontonotes, batch 396 (20396): mcc: 0.8349, acc: 0.7558, precision: 0.8948, recall: 0.7951, f1: 0.8420, edges-ner-ontonotes_loss: 0.0517
09/16 07:03:05 AM: Update 20787: task edges-ner-ontonotes, batch 787 (20787): mcc: 0.8457, acc: 0.7703, precision: 0.9014, recall: 0.8086, f1: 0.8525, edges-ner-ontonotes_loss: 0.0478
09/16 07:03:08 AM: Update 20485: task edges-ner-ontonotes, batch 485 (20485): mcc: 0.8352, acc: 0.7562, precision: 0.8943, recall: 0.7961, f1: 0.8424, edges-ner-ontonotes_loss: 0.0512
09/16 07:03:18 AM: Update 20855: task edges-ner-ontonotes, batch 855 (20855): mcc: 0.8473, acc: 0.7724, precision: 0.9024, recall: 0.8105, f1: 0.8540, edges-ner-ontonotes_loss: 0.0473
09/16 07:03:18 AM: Update 20544: task edges-ner-ontonotes, batch 544 (20544): mcc: 0.8351, acc: 0.7558, precision: 0.8945, recall: 0.7958, f1: 0.8422, edges-ner-ontonotes_loss: 0.0510
09/16 07:03:28 AM: Update 20925: task edges-ner-ontonotes, batch 925 (20925): mcc: 0.8509, acc: 0.7771, precision: 0.9047, recall: 0.8150, f1: 0.8575, edges-ner-ontonotes_loss: 0.0462
09/16 07:03:28 AM: Update 20618: task edges-ner-ontonotes, batch 618 (20618): mcc: 0.8397, acc: 0.7621, precision: 0.8977, recall: 0.8011, f1: 0.8466, edges-ner-ontonotes_loss: 0.0496
09/16 07:03:38 AM: Update 20994: task edges-ner-ontonotes, batch 994 (20994): mcc: 0.8537, acc: 0.7806, precision: 0.9067, recall: 0.8184, f1: 0.8603, edges-ner-ontonotes_loss: 0.0453
09/16 07:03:39 AM: Update 20692: task edges-ner-ontonotes, batch 692 (20692): mcc: 0.8428, acc: 0.7663, precision: 0.8994, recall: 0.8051, f1: 0.8496, edges-ner-ontonotes_loss: 0.0487
09/16 07:03:39 AM: ***** Step 21000 / Validation 21 *****
09/16 07:03:39 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:03:39 AM: Validating...
09/16 07:03:49 AM: Evaluate: task edges-ner-ontonotes, batch 54 (157): mcc: 0.8788, acc: 0.8203, precision: 0.9251, recall: 0.8470, f1: 0.8843, edges-ner-ontonotes_loss: 0.0403
09/16 07:03:49 AM: Update 20750: task edges-ner-ontonotes, batch 750 (20750): mcc: 0.8446, acc: 0.7689, precision: 0.9004, recall: 0.8075, f1: 0.8514, edges-ner-ontonotes_loss: 0.0482
09/16 07:03:59 AM: Evaluate: task edges-ner-ontonotes, batch 110 (157): mcc: 0.8971, acc: 0.8468, precision: 0.9373, recall: 0.8692, f1: 0.9019, edges-ner-ontonotes_loss: 0.0347
09/16 07:04:00 AM: Update 20808: task edges-ner-ontonotes, batch 808 (20808): mcc: 0.8462, acc: 0.7711, precision: 0.9016, recall: 0.8093, f1: 0.8530, edges-ner-ontonotes_loss: 0.0477
09/16 07:04:08 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:04:08 AM: Best result seen so far for macro.
09/16 07:04:08 AM: Updating LR scheduler:
09/16 07:04:08 AM: 	Best result seen so far for macro_avg: 0.914
09/16 07:04:08 AM: 	# validation passes without improvement: 0
09/16 07:04:08 AM: edges-ner-ontonotes_loss: training: 0.045301 validation: 0.031105
09/16 07:04:08 AM: macro_avg: validation: 0.913624
09/16 07:04:08 AM: micro_avg: validation: 0.000000
09/16 07:04:08 AM: edges-ner-ontonotes_mcc: training: 0.853894 validation: 0.909246
09/16 07:04:08 AM: edges-ner-ontonotes_acc: training: 0.780763 validation: 0.863436
09/16 07:04:08 AM: edges-ner-ontonotes_precision: training: 0.906828 validation: 0.944107
09/16 07:04:08 AM: edges-ner-ontonotes_recall: training: 0.818519 validation: 0.885047
09/16 07:04:08 AM: edges-ner-ontonotes_f1: training: 0.860414 validation: 0.913624
09/16 07:04:08 AM: Global learning rate: 0.0001
09/16 07:04:08 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:04:09 AM: Update 21006: task edges-ner-ontonotes, batch 6 (21006): mcc: 0.8686, acc: 0.8014, precision: 0.8991, recall: 0.8528, f1: 0.8753, edges-ner-ontonotes_loss: 0.0353
09/16 07:04:12 AM: Update 20855: task edges-ner-ontonotes, batch 855 (20855): mcc: 0.8473, acc: 0.7724, precision: 0.9024, recall: 0.8105, f1: 0.8540, edges-ner-ontonotes_loss: 0.0473
09/16 07:04:19 AM: Update 21087: task edges-ner-ontonotes, batch 87 (21087): mcc: 0.8901, acc: 0.8312, precision: 0.9256, recall: 0.8673, f1: 0.8955, edges-ner-ontonotes_loss: 0.0329
09/16 07:04:22 AM: Update 20925: task edges-ner-ontonotes, batch 925 (20925): mcc: 0.8509, acc: 0.7771, precision: 0.9047, recall: 0.8150, f1: 0.8575, edges-ner-ontonotes_loss: 0.0462
09/16 07:04:29 AM: Update 21153: task edges-ner-ontonotes, batch 153 (21153): mcc: 0.8857, acc: 0.8252, precision: 0.9223, recall: 0.8622, f1: 0.8913, edges-ner-ontonotes_loss: 0.0342
09/16 07:04:32 AM: Update 20999: task edges-ner-ontonotes, batch 999 (20999): mcc: 0.8539, acc: 0.7807, precision: 0.9068, recall: 0.8185, f1: 0.8604, edges-ner-ontonotes_loss: 0.0453
09/16 07:04:32 AM: ***** Step 21000 / Validation 21 *****
09/16 07:04:32 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:04:32 AM: Validating...
09/16 07:04:40 AM: Update 21197: task edges-ner-ontonotes, batch 197 (21197): mcc: 0.8855, acc: 0.8238, precision: 0.9224, recall: 0.8618, f1: 0.8911, edges-ner-ontonotes_loss: 0.0344
09/16 07:04:42 AM: Evaluate: task edges-ner-ontonotes, batch 67 (157): mcc: 0.8822, acc: 0.8255, precision: 0.9287, recall: 0.8499, f1: 0.8876, edges-ner-ontonotes_loss: 0.0394
09/16 07:04:52 AM: Update 21250: task edges-ner-ontonotes, batch 250 (21250): mcc: 0.8849, acc: 0.8221, precision: 0.9231, recall: 0.8601, f1: 0.8905, edges-ner-ontonotes_loss: 0.0345
09/16 07:04:52 AM: Evaluate: task edges-ner-ontonotes, batch 116 (157): mcc: 0.9014, acc: 0.8529, precision: 0.9393, recall: 0.8751, f1: 0.9061, edges-ner-ontonotes_loss: 0.0339
09/16 07:05:00 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:05:00 AM: Best result seen so far for macro.
09/16 07:05:00 AM: Updating LR scheduler:
09/16 07:05:00 AM: 	Best result seen so far for macro_avg: 0.914
09/16 07:05:00 AM: 	# validation passes without improvement: 0
09/16 07:05:00 AM: edges-ner-ontonotes_loss: training: 0.045301 validation: 0.031105
09/16 07:05:00 AM: macro_avg: validation: 0.913624
09/16 07:05:00 AM: micro_avg: validation: 0.000000
09/16 07:05:00 AM: edges-ner-ontonotes_mcc: training: 0.853894 validation: 0.909246
09/16 07:05:00 AM: edges-ner-ontonotes_acc: training: 0.780763 validation: 0.863436
09/16 07:05:00 AM: edges-ner-ontonotes_precision: training: 0.906828 validation: 0.944107
09/16 07:05:00 AM: edges-ner-ontonotes_recall: training: 0.818519 validation: 0.885047
09/16 07:05:00 AM: edges-ner-ontonotes_f1: training: 0.860414 validation: 0.913624
09/16 07:05:00 AM: Global learning rate: 0.0001
09/16 07:05:00 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:05:02 AM: Update 21311: task edges-ner-ontonotes, batch 311 (21311): mcc: 0.8846, acc: 0.8211, precision: 0.9228, recall: 0.8597, f1: 0.8902, edges-ner-ontonotes_loss: 0.0345
09/16 07:05:03 AM: Update 21020: task edges-ner-ontonotes, batch 20 (21020): mcc: 0.8784, acc: 0.8139, precision: 0.9184, recall: 0.8526, f1: 0.8843, edges-ner-ontonotes_loss: 0.0359
09/16 07:05:12 AM: Update 21381: task edges-ner-ontonotes, batch 381 (21381): mcc: 0.8842, acc: 0.8208, precision: 0.9224, recall: 0.8595, f1: 0.8898, edges-ner-ontonotes_loss: 0.0349
09/16 07:05:13 AM: Update 21090: task edges-ner-ontonotes, batch 90 (21090): mcc: 0.8896, acc: 0.8301, precision: 0.9248, recall: 0.8672, f1: 0.8951, edges-ner-ontonotes_loss: 0.0329
09/16 07:05:22 AM: Update 21450: task edges-ner-ontonotes, batch 450 (21450): mcc: 0.8848, acc: 0.8214, precision: 0.9234, recall: 0.8597, f1: 0.8904, edges-ner-ontonotes_loss: 0.0348
09/16 07:05:23 AM: Update 21157: task edges-ner-ontonotes, batch 157 (21157): mcc: 0.8863, acc: 0.8259, precision: 0.9225, recall: 0.8632, f1: 0.8919, edges-ner-ontonotes_loss: 0.0341
09/16 07:05:32 AM: Update 21512: task edges-ner-ontonotes, batch 512 (21512): mcc: 0.8824, acc: 0.8186, precision: 0.9219, recall: 0.8567, f1: 0.8881, edges-ner-ontonotes_loss: 0.0358
09/16 07:05:33 AM: Update 21209: task edges-ner-ontonotes, batch 209 (21209): mcc: 0.8846, acc: 0.8226, precision: 0.9214, recall: 0.8612, f1: 0.8903, edges-ner-ontonotes_loss: 0.0348
09/16 07:05:42 AM: Update 21586: task edges-ner-ontonotes, batch 586 (21586): mcc: 0.8775, acc: 0.8124, precision: 0.9186, recall: 0.8506, f1: 0.8833, edges-ner-ontonotes_loss: 0.0382
09/16 07:05:43 AM: Update 21284: task edges-ner-ontonotes, batch 284 (21284): mcc: 0.8850, acc: 0.8215, precision: 0.9230, recall: 0.8603, f1: 0.8906, edges-ner-ontonotes_loss: 0.0345
09/16 07:05:52 AM: Update 21656: task edges-ner-ontonotes, batch 656 (21656): mcc: 0.8727, acc: 0.8059, precision: 0.9158, recall: 0.8445, f1: 0.8787, edges-ner-ontonotes_loss: 0.0398
09/16 07:05:53 AM: Update 21357: task edges-ner-ontonotes, batch 357 (21357): mcc: 0.8838, acc: 0.8203, precision: 0.9216, recall: 0.8594, f1: 0.8894, edges-ner-ontonotes_loss: 0.0349
09/16 07:06:02 AM: Update 21728: task edges-ner-ontonotes, batch 728 (21728): mcc: 0.8690, acc: 0.8012, precision: 0.9134, recall: 0.8400, f1: 0.8752, edges-ner-ontonotes_loss: 0.0413
09/16 07:06:03 AM: Update 21426: task edges-ner-ontonotes, batch 426 (21426): mcc: 0.8845, acc: 0.8210, precision: 0.9232, recall: 0.8593, f1: 0.8901, edges-ner-ontonotes_loss: 0.0348
09/16 07:06:13 AM: Update 21785: task edges-ner-ontonotes, batch 785 (21785): mcc: 0.8667, acc: 0.7982, precision: 0.9122, recall: 0.8370, f1: 0.8729, edges-ner-ontonotes_loss: 0.0421
09/16 07:06:13 AM: Update 21482: task edges-ner-ontonotes, batch 482 (21482): mcc: 0.8852, acc: 0.8221, precision: 0.9235, recall: 0.8603, f1: 0.8908, edges-ner-ontonotes_loss: 0.0347
09/16 07:06:23 AM: Update 21870: task edges-ner-ontonotes, batch 870 (21870): mcc: 0.8637, acc: 0.7939, precision: 0.9101, recall: 0.8335, f1: 0.8701, edges-ner-ontonotes_loss: 0.0430
09/16 07:06:23 AM: Update 21564: task edges-ner-ontonotes, batch 564 (21564): mcc: 0.8792, acc: 0.8145, precision: 0.9198, recall: 0.8527, f1: 0.8850, edges-ner-ontonotes_loss: 0.0374
09/16 07:06:33 AM: Update 21954: task edges-ner-ontonotes, batch 954 (21954): mcc: 0.8617, acc: 0.7910, precision: 0.9088, recall: 0.8311, f1: 0.8682, edges-ner-ontonotes_loss: 0.0435
09/16 07:06:33 AM: Update 21641: task edges-ner-ontonotes, batch 641 (21641): mcc: 0.8732, acc: 0.8067, precision: 0.9161, recall: 0.8452, f1: 0.8792, edges-ner-ontonotes_loss: 0.0396
09/16 07:06:39 AM: ***** Step 22000 / Validation 22 *****
09/16 07:06:39 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:06:39 AM: Validating...
09/16 07:06:43 AM: Evaluate: task edges-ner-ontonotes, batch 27 (157): mcc: 0.8455, acc: 0.7736, precision: 0.9151, recall: 0.7958, f1: 0.8513, edges-ner-ontonotes_loss: 0.0474
09/16 07:06:43 AM: Update 21710: task edges-ner-ontonotes, batch 710 (21710): mcc: 0.8700, acc: 0.8025, precision: 0.9142, recall: 0.8412, f1: 0.8762, edges-ner-ontonotes_loss: 0.0411
09/16 07:06:53 AM: Evaluate: task edges-ner-ontonotes, batch 84 (157): mcc: 0.8949, acc: 0.8389, precision: 0.9438, recall: 0.8590, f1: 0.8994, edges-ner-ontonotes_loss: 0.0352
09/16 07:06:53 AM: Update 21765: task edges-ner-ontonotes, batch 765 (21765): mcc: 0.8677, acc: 0.7994, precision: 0.9128, recall: 0.8382, f1: 0.8739, edges-ner-ontonotes_loss: 0.0417
09/16 07:07:03 AM: Evaluate: task edges-ner-ontonotes, batch 138 (157): mcc: 0.9080, acc: 0.8580, precision: 0.9517, recall: 0.8757, f1: 0.9121, edges-ner-ontonotes_loss: 0.0311
09/16 07:07:03 AM: Update 21810: task edges-ner-ontonotes, batch 810 (21810): mcc: 0.8659, acc: 0.7971, precision: 0.9116, recall: 0.8361, f1: 0.8722, edges-ner-ontonotes_loss: 0.0422
09/16 07:07:06 AM: Updating LR scheduler:
09/16 07:07:06 AM: 	Best result seen so far for macro_avg: 0.914
09/16 07:07:06 AM: 	# validation passes without improvement: 1
09/16 07:07:06 AM: edges-ner-ontonotes_loss: training: 0.043753 validation: 0.030653
09/16 07:07:06 AM: macro_avg: validation: 0.911539
09/16 07:07:06 AM: micro_avg: validation: 0.000000
09/16 07:07:06 AM: edges-ner-ontonotes_mcc: training: 0.860813 validation: 0.907442
09/16 07:07:06 AM: edges-ner-ontonotes_acc: training: 0.789645 validation: 0.856991
09/16 07:07:06 AM: edges-ner-ontonotes_precision: training: 0.908351 validation: 0.951129
09/16 07:07:06 AM: edges-ner-ontonotes_recall: training: 0.829736 validation: 0.875114
09/16 07:07:06 AM: edges-ner-ontonotes_f1: training: 0.867266 validation: 0.911539
09/16 07:07:06 AM: Global learning rate: 0.0001
09/16 07:07:06 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:07:13 AM: Update 22063: task edges-ner-ontonotes, batch 63 (22063): mcc: 0.8487, acc: 0.7682, precision: 0.9044, recall: 0.8114, f1: 0.8554, edges-ner-ontonotes_loss: 0.0463
09/16 07:07:14 AM: Update 21891: task edges-ner-ontonotes, batch 891 (21891): mcc: 0.8630, acc: 0.7929, precision: 0.9097, recall: 0.8325, f1: 0.8694, edges-ner-ontonotes_loss: 0.0432
09/16 07:07:23 AM: Update 22113: task edges-ner-ontonotes, batch 113 (22113): mcc: 0.8454, acc: 0.7664, precision: 0.9029, recall: 0.8066, f1: 0.8521, edges-ner-ontonotes_loss: 0.0468
09/16 07:07:24 AM: Update 21985: task edges-ner-ontonotes, batch 985 (21985): mcc: 0.8612, acc: 0.7901, precision: 0.9086, recall: 0.8302, f1: 0.8676, edges-ner-ontonotes_loss: 0.0437
09/16 07:07:25 AM: ***** Step 22000 / Validation 22 *****
09/16 07:07:25 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:07:25 AM: Validating...
09/16 07:07:33 AM: Update 22180: task edges-ner-ontonotes, batch 180 (22180): mcc: 0.8532, acc: 0.7788, precision: 0.9058, recall: 0.8182, f1: 0.8598, edges-ner-ontonotes_loss: 0.0451
09/16 07:07:34 AM: Evaluate: task edges-ner-ontonotes, batch 53 (157): mcc: 0.8816, acc: 0.8219, precision: 0.9332, recall: 0.8446, f1: 0.8867, edges-ner-ontonotes_loss: 0.0383
09/16 07:07:44 AM: Update 22236: task edges-ner-ontonotes, batch 236 (22236): mcc: 0.8561, acc: 0.7824, precision: 0.9067, recall: 0.8226, f1: 0.8626, edges-ner-ontonotes_loss: 0.0439
09/16 07:07:44 AM: Evaluate: task edges-ner-ontonotes, batch 107 (157): mcc: 0.8961, acc: 0.8407, precision: 0.9449, recall: 0.8601, f1: 0.9005, edges-ner-ontonotes_loss: 0.0340
09/16 07:07:54 AM: Update 22290: task edges-ner-ontonotes, batch 290 (22290): mcc: 0.8586, acc: 0.7859, precision: 0.9091, recall: 0.8250, f1: 0.8650, edges-ner-ontonotes_loss: 0.0432
09/16 07:07:54 AM: Evaluate: task edges-ner-ontonotes, batch 156 (157): mcc: 0.9074, acc: 0.8570, precision: 0.9511, recall: 0.8751, f1: 0.9115, edges-ner-ontonotes_loss: 0.0308
09/16 07:07:54 AM: Updating LR scheduler:
09/16 07:07:54 AM: 	Best result seen so far for macro_avg: 0.914
09/16 07:07:54 AM: 	# validation passes without improvement: 1
09/16 07:07:54 AM: edges-ner-ontonotes_loss: training: 0.043753 validation: 0.030653
09/16 07:07:54 AM: macro_avg: validation: 0.911539
09/16 07:07:54 AM: micro_avg: validation: 0.000000
09/16 07:07:54 AM: edges-ner-ontonotes_mcc: training: 0.860813 validation: 0.907442
09/16 07:07:54 AM: edges-ner-ontonotes_acc: training: 0.789645 validation: 0.856991
09/16 07:07:54 AM: edges-ner-ontonotes_precision: training: 0.908351 validation: 0.951129
09/16 07:07:54 AM: edges-ner-ontonotes_recall: training: 0.829736 validation: 0.875114
09/16 07:07:54 AM: edges-ner-ontonotes_f1: training: 0.867266 validation: 0.911539
09/16 07:07:54 AM: Global learning rate: 0.0001
09/16 07:07:54 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:08:04 AM: Update 22366: task edges-ner-ontonotes, batch 366 (22366): mcc: 0.8599, acc: 0.7882, precision: 0.9099, recall: 0.8266, f1: 0.8663, edges-ner-ontonotes_loss: 0.0426
09/16 07:08:04 AM: Update 22078: task edges-ner-ontonotes, batch 78 (22078): mcc: 0.8451, acc: 0.7650, precision: 0.9004, recall: 0.8085, f1: 0.8519, edges-ner-ontonotes_loss: 0.0468
09/16 07:08:14 AM: Update 22435: task edges-ner-ontonotes, batch 435 (22435): mcc: 0.8627, acc: 0.7921, precision: 0.9112, recall: 0.8305, f1: 0.8690, edges-ner-ontonotes_loss: 0.0416
09/16 07:08:14 AM: Update 22125: task edges-ner-ontonotes, batch 125 (22125): mcc: 0.8479, acc: 0.7698, precision: 0.9043, recall: 0.8100, f1: 0.8546, edges-ner-ontonotes_loss: 0.0464
09/16 07:08:24 AM: Update 22502: task edges-ner-ontonotes, batch 502 (22502): mcc: 0.8665, acc: 0.7971, precision: 0.9135, recall: 0.8353, f1: 0.8726, edges-ner-ontonotes_loss: 0.0406
09/16 07:08:24 AM: Update 22199: task edges-ner-ontonotes, batch 199 (22199): mcc: 0.8550, acc: 0.7813, precision: 0.9063, recall: 0.8210, f1: 0.8616, edges-ner-ontonotes_loss: 0.0445
09/16 07:08:34 AM: Update 22573: task edges-ner-ontonotes, batch 573 (22573): mcc: 0.8692, acc: 0.8008, precision: 0.9150, recall: 0.8388, f1: 0.8752, edges-ner-ontonotes_loss: 0.0398
09/16 07:08:34 AM: Update 22268: task edges-ner-ontonotes, batch 268 (22268): mcc: 0.8577, acc: 0.7852, precision: 0.9081, recall: 0.8243, f1: 0.8642, edges-ner-ontonotes_loss: 0.0435
09/16 07:08:44 AM: Update 22645: task edges-ner-ontonotes, batch 645 (22645): mcc: 0.8719, acc: 0.8044, precision: 0.9171, recall: 0.8418, f1: 0.8778, edges-ner-ontonotes_loss: 0.0390
09/16 07:08:44 AM: Update 22342: task edges-ner-ontonotes, batch 342 (22342): mcc: 0.8596, acc: 0.7877, precision: 0.9095, recall: 0.8264, f1: 0.8660, edges-ner-ontonotes_loss: 0.0427
09/16 07:08:54 AM: Update 22718: task edges-ner-ontonotes, batch 718 (22718): mcc: 0.8740, acc: 0.8072, precision: 0.9183, recall: 0.8446, f1: 0.8799, edges-ner-ontonotes_loss: 0.0383
09/16 07:08:55 AM: Update 22411: task edges-ner-ontonotes, batch 411 (22411): mcc: 0.8614, acc: 0.7902, precision: 0.9106, recall: 0.8287, f1: 0.8677, edges-ner-ontonotes_loss: 0.0420
09/16 07:09:04 AM: Update 22773: task edges-ner-ontonotes, batch 773 (22773): mcc: 0.8749, acc: 0.8085, precision: 0.9188, recall: 0.8459, f1: 0.8808, edges-ner-ontonotes_loss: 0.0381
09/16 07:09:05 AM: Update 22481: task edges-ner-ontonotes, batch 481 (22481): mcc: 0.8657, acc: 0.7962, precision: 0.9129, recall: 0.8344, f1: 0.8719, edges-ner-ontonotes_loss: 0.0408
09/16 07:09:14 AM: Update 22844: task edges-ner-ontonotes, batch 844 (22844): mcc: 0.8759, acc: 0.8096, precision: 0.9192, recall: 0.8472, f1: 0.8817, edges-ner-ontonotes_loss: 0.0377
09/16 07:09:16 AM: Update 22554: task edges-ner-ontonotes, batch 554 (22554): mcc: 0.8686, acc: 0.8000, precision: 0.9148, recall: 0.8380, f1: 0.8747, edges-ner-ontonotes_loss: 0.0400
09/16 07:09:24 AM: Update 22915: task edges-ner-ontonotes, batch 915 (22915): mcc: 0.8768, acc: 0.8111, precision: 0.9197, recall: 0.8485, f1: 0.8826, edges-ner-ontonotes_loss: 0.0375
09/16 07:09:26 AM: Update 22629: task edges-ner-ontonotes, batch 629 (22629): mcc: 0.8711, acc: 0.8034, precision: 0.9164, recall: 0.8411, f1: 0.8771, edges-ner-ontonotes_loss: 0.0392
09/16 07:09:35 AM: Update 22986: task edges-ner-ontonotes, batch 986 (22986): mcc: 0.8775, acc: 0.8119, precision: 0.9202, recall: 0.8492, f1: 0.8833, edges-ner-ontonotes_loss: 0.0373
09/16 07:09:36 AM: Update 22702: task edges-ner-ontonotes, batch 702 (22702): mcc: 0.8732, acc: 0.8062, precision: 0.9175, recall: 0.8439, f1: 0.8792, edges-ner-ontonotes_loss: 0.0385
09/16 07:09:37 AM: ***** Step 23000 / Validation 23 *****
09/16 07:09:37 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:09:37 AM: Validating...
09/16 07:09:45 AM: Evaluate: task edges-ner-ontonotes, batch 56 (157): mcc: 0.8824, acc: 0.8272, precision: 0.9264, recall: 0.8523, f1: 0.8878, edges-ner-ontonotes_loss: 0.0401
09/16 07:09:46 AM: Update 22739: task edges-ner-ontonotes, batch 739 (22739): mcc: 0.8748, acc: 0.8084, precision: 0.9189, recall: 0.8455, f1: 0.8807, edges-ner-ontonotes_loss: 0.0381
09/16 07:09:55 AM: Evaluate: task edges-ner-ontonotes, batch 109 (157): mcc: 0.8965, acc: 0.8477, precision: 0.9359, recall: 0.8694, f1: 0.9014, edges-ner-ontonotes_loss: 0.0349
09/16 07:09:56 AM: Update 22794: task edges-ner-ontonotes, batch 794 (22794): mcc: 0.8754, acc: 0.8090, precision: 0.9190, recall: 0.8465, f1: 0.8813, edges-ner-ontonotes_loss: 0.0379
09/16 07:10:05 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:10:05 AM: Best result seen so far for macro.
09/16 07:10:05 AM: Updating LR scheduler:
09/16 07:10:05 AM: 	Best result seen so far for macro_avg: 0.915
09/16 07:10:05 AM: 	# validation passes without improvement: 0
09/16 07:10:05 AM: edges-ner-ontonotes_loss: training: 0.037240 validation: 0.030735
09/16 07:10:05 AM: macro_avg: validation: 0.914592
09/16 07:10:05 AM: micro_avg: validation: 0.000000
09/16 07:10:05 AM: edges-ner-ontonotes_mcc: training: 0.877698 validation: 0.910221
09/16 07:10:05 AM: edges-ner-ontonotes_acc: training: 0.812187 validation: 0.865635
09/16 07:10:05 AM: edges-ner-ontonotes_precision: training: 0.920301 validation: 0.943848
09/16 07:10:05 AM: edges-ner-ontonotes_recall: training: 0.849490 validation: 0.887094
09/16 07:10:05 AM: edges-ner-ontonotes_f1: training: 0.883478 validation: 0.914592
09/16 07:10:05 AM: Global learning rate: 0.0001
09/16 07:10:05 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:10:05 AM: Update 23001: task edges-ner-ontonotes, batch 1 (23001): mcc: 0.8768, acc: 0.8358, precision: 0.9333, recall: 0.8358, f1: 0.8819, edges-ner-ontonotes_loss: 0.0353
09/16 07:10:07 AM: Update 22851: task edges-ner-ontonotes, batch 851 (22851): mcc: 0.8761, acc: 0.8100, precision: 0.9193, recall: 0.8475, f1: 0.8820, edges-ner-ontonotes_loss: 0.0376
09/16 07:10:15 AM: Update 23054: task edges-ner-ontonotes, batch 54 (23054): mcc: 0.8689, acc: 0.8007, precision: 0.9132, recall: 0.8401, f1: 0.8751, edges-ner-ontonotes_loss: 0.0399
09/16 07:10:17 AM: Update 22926: task edges-ner-ontonotes, batch 926 (22926): mcc: 0.8770, acc: 0.8113, precision: 0.9199, recall: 0.8486, f1: 0.8828, edges-ner-ontonotes_loss: 0.0375
09/16 07:10:25 AM: Update 23128: task edges-ner-ontonotes, batch 128 (23128): mcc: 0.8479, acc: 0.7764, precision: 0.8995, recall: 0.8145, f1: 0.8549, edges-ner-ontonotes_loss: 0.0487
09/16 07:10:27 AM: Update 22997: task edges-ner-ontonotes, batch 997 (22997): mcc: 0.8775, acc: 0.8120, precision: 0.9202, recall: 0.8493, f1: 0.8833, edges-ner-ontonotes_loss: 0.0373
09/16 07:10:27 AM: ***** Step 23000 / Validation 23 *****
09/16 07:10:27 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:10:27 AM: Validating...
09/16 07:10:36 AM: Update 23188: task edges-ner-ontonotes, batch 188 (23188): mcc: 0.8424, acc: 0.7693, precision: 0.8958, recall: 0.8079, f1: 0.8496, edges-ner-ontonotes_loss: 0.0500
09/16 07:10:37 AM: Evaluate: task edges-ner-ontonotes, batch 60 (157): mcc: 0.8860, acc: 0.8311, precision: 0.9287, recall: 0.8569, f1: 0.8914, edges-ner-ontonotes_loss: 0.0389
09/16 07:10:47 AM: Update 23250: task edges-ner-ontonotes, batch 250 (23250): mcc: 0.8418, acc: 0.7680, precision: 0.8958, recall: 0.8067, f1: 0.8489, edges-ner-ontonotes_loss: 0.0505
09/16 07:10:47 AM: Evaluate: task edges-ner-ontonotes, batch 110 (157): mcc: 0.8974, acc: 0.8489, precision: 0.9365, recall: 0.8705, f1: 0.9023, edges-ner-ontonotes_loss: 0.0347
09/16 07:10:56 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:10:56 AM: Best result seen so far for macro.
09/16 07:10:56 AM: Updating LR scheduler:
09/16 07:10:56 AM: 	Best result seen so far for macro_avg: 0.915
09/16 07:10:56 AM: 	# validation passes without improvement: 0
09/16 07:10:56 AM: edges-ner-ontonotes_loss: training: 0.037240 validation: 0.030735
09/16 07:10:56 AM: macro_avg: validation: 0.914592
09/16 07:10:56 AM: micro_avg: validation: 0.000000
09/16 07:10:56 AM: edges-ner-ontonotes_mcc: training: 0.877698 validation: 0.910221
09/16 07:10:56 AM: edges-ner-ontonotes_acc: training: 0.812187 validation: 0.865635
09/16 07:10:56 AM: edges-ner-ontonotes_precision: training: 0.920301 validation: 0.943848
09/16 07:10:56 AM: edges-ner-ontonotes_recall: training: 0.849490 validation: 0.887094
09/16 07:10:56 AM: edges-ner-ontonotes_f1: training: 0.883478 validation: 0.914592
09/16 07:10:56 AM: Global learning rate: 0.0001
09/16 07:10:56 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:10:57 AM: Update 23308: task edges-ner-ontonotes, batch 308 (23308): mcc: 0.8416, acc: 0.7672, precision: 0.8956, recall: 0.8066, f1: 0.8488, edges-ner-ontonotes_loss: 0.0506
09/16 07:10:57 AM: Update 23001: task edges-ner-ontonotes, batch 1 (23001): mcc: 0.8768, acc: 0.8358, precision: 0.9333, recall: 0.8358, f1: 0.8819, edges-ner-ontonotes_loss: 0.0353
09/16 07:11:07 AM: Update 23367: task edges-ner-ontonotes, batch 367 (23367): mcc: 0.8389, acc: 0.7631, precision: 0.8935, recall: 0.8034, f1: 0.8461, edges-ner-ontonotes_loss: 0.0511
09/16 07:11:07 AM: Update 23056: task edges-ner-ontonotes, batch 56 (23056): mcc: 0.8676, acc: 0.7990, precision: 0.9124, recall: 0.8384, f1: 0.8738, edges-ner-ontonotes_loss: 0.0402
09/16 07:11:17 AM: Update 23449: task edges-ner-ontonotes, batch 449 (23449): mcc: 0.8392, acc: 0.7628, precision: 0.8938, recall: 0.8038, f1: 0.8464, edges-ner-ontonotes_loss: 0.0505
09/16 07:11:17 AM: Update 23136: task edges-ner-ontonotes, batch 136 (23136): mcc: 0.8455, acc: 0.7731, precision: 0.8978, recall: 0.8117, f1: 0.8525, edges-ner-ontonotes_loss: 0.0496
09/16 07:11:27 AM: Update 23530: task edges-ner-ontonotes, batch 530 (23530): mcc: 0.8385, acc: 0.7615, precision: 0.8937, recall: 0.8026, f1: 0.8457, edges-ner-ontonotes_loss: 0.0504
09/16 07:11:27 AM: Update 23214: task edges-ner-ontonotes, batch 214 (23214): mcc: 0.8421, acc: 0.7685, precision: 0.8956, recall: 0.8075, f1: 0.8492, edges-ner-ontonotes_loss: 0.0502
09/16 07:11:37 AM: Update 23612: task edges-ner-ontonotes, batch 612 (23612): mcc: 0.8389, acc: 0.7620, precision: 0.8939, recall: 0.8032, f1: 0.8462, edges-ner-ontonotes_loss: 0.0500
09/16 07:11:37 AM: Update 23295: task edges-ner-ontonotes, batch 295 (23295): mcc: 0.8416, acc: 0.7673, precision: 0.8954, recall: 0.8066, f1: 0.8487, edges-ner-ontonotes_loss: 0.0504
09/16 07:11:47 AM: Update 23668: task edges-ner-ontonotes, batch 668 (23668): mcc: 0.8389, acc: 0.7618, precision: 0.8938, recall: 0.8032, f1: 0.8461, edges-ner-ontonotes_loss: 0.0499
09/16 07:11:47 AM: Update 23353: task edges-ner-ontonotes, batch 353 (23353): mcc: 0.8396, acc: 0.7641, precision: 0.8941, recall: 0.8043, f1: 0.8468, edges-ner-ontonotes_loss: 0.0510
09/16 07:12:01 AM: Update 23745: task edges-ner-ontonotes, batch 745 (23745): mcc: 0.8423, acc: 0.7663, precision: 0.8962, recall: 0.8073, f1: 0.8494, edges-ner-ontonotes_loss: 0.0488
09/16 07:12:01 AM: Update 23431: task edges-ner-ontonotes, batch 431 (23431): mcc: 0.8392, acc: 0.7631, precision: 0.8941, recall: 0.8036, f1: 0.8464, edges-ner-ontonotes_loss: 0.0504
09/16 07:12:12 AM: Update 23826: task edges-ner-ontonotes, batch 826 (23826): mcc: 0.8447, acc: 0.7696, precision: 0.8976, recall: 0.8103, f1: 0.8517, edges-ner-ontonotes_loss: 0.0479
09/16 07:12:12 AM: Update 23515: task edges-ner-ontonotes, batch 515 (23515): mcc: 0.8391, acc: 0.7624, precision: 0.8940, recall: 0.8035, f1: 0.8463, edges-ner-ontonotes_loss: 0.0503
09/16 07:12:23 AM: Update 23908: task edges-ner-ontonotes, batch 908 (23908): mcc: 0.8465, acc: 0.7720, precision: 0.8987, recall: 0.8125, f1: 0.8534, edges-ner-ontonotes_loss: 0.0472
09/16 07:12:23 AM: Update 23601: task edges-ner-ontonotes, batch 601 (23601): mcc: 0.8390, acc: 0.7621, precision: 0.8941, recall: 0.8032, f1: 0.8462, edges-ner-ontonotes_loss: 0.0500
09/16 07:12:34 AM: Update 23665: task edges-ner-ontonotes, batch 665 (23665): mcc: 0.8386, acc: 0.7615, precision: 0.8936, recall: 0.8030, f1: 0.8459, edges-ner-ontonotes_loss: 0.0500
09/16 07:12:34 AM: Update 23967: task edges-ner-ontonotes, batch 967 (23967): mcc: 0.8476, acc: 0.7734, precision: 0.8993, recall: 0.8140, f1: 0.8545, edges-ner-ontonotes_loss: 0.0468
09/16 07:12:39 AM: ***** Step 24000 / Validation 24 *****
09/16 07:12:39 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:12:39 AM: Validating...
09/16 07:12:45 AM: Evaluate: task edges-ner-ontonotes, batch 34 (157): mcc: 0.8634, acc: 0.7980, precision: 0.9189, recall: 0.8247, f1: 0.8693, edges-ner-ontonotes_loss: 0.0451
09/16 07:12:45 AM: Update 23731: task edges-ner-ontonotes, batch 731 (23731): mcc: 0.8419, acc: 0.7659, precision: 0.8959, recall: 0.8068, f1: 0.8490, edges-ner-ontonotes_loss: 0.0490
09/16 07:12:55 AM: Update 23788: task edges-ner-ontonotes, batch 788 (23788): mcc: 0.8435, acc: 0.7678, precision: 0.8970, recall: 0.8087, f1: 0.8505, edges-ner-ontonotes_loss: 0.0483
09/16 07:12:55 AM: Evaluate: task edges-ner-ontonotes, batch 90 (157): mcc: 0.8985, acc: 0.8453, precision: 0.9425, recall: 0.8668, f1: 0.9031, edges-ner-ontonotes_loss: 0.0352
09/16 07:13:05 AM: Update 23842: task edges-ner-ontonotes, batch 842 (23842): mcc: 0.8450, acc: 0.7701, precision: 0.8976, recall: 0.8108, f1: 0.8520, edges-ner-ontonotes_loss: 0.0478
09/16 07:13:05 AM: Evaluate: task edges-ner-ontonotes, batch 138 (157): mcc: 0.9103, acc: 0.8634, precision: 0.9477, recall: 0.8836, f1: 0.9145, edges-ner-ontonotes_loss: 0.0313
09/16 07:13:08 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:13:08 AM: Best result seen so far for macro.
09/16 07:13:08 AM: Updating LR scheduler:
09/16 07:13:08 AM: 	Best result seen so far for macro_avg: 0.915
09/16 07:13:08 AM: 	# validation passes without improvement: 0
09/16 07:13:08 AM: edges-ner-ontonotes_loss: training: 0.046318 validation: 0.030635
09/16 07:13:08 AM: macro_avg: validation: 0.914781
09/16 07:13:08 AM: micro_avg: validation: 0.000000
09/16 07:13:08 AM: edges-ner-ontonotes_mcc: training: 0.849298 validation: 0.910552
09/16 07:13:08 AM: edges-ner-ontonotes_acc: training: 0.775533 validation: 0.863512
09/16 07:13:08 AM: edges-ner-ontonotes_precision: training: 0.900546 validation: 0.947364
09/16 07:13:08 AM: edges-ner-ontonotes_recall: training: 0.815960 validation: 0.884365
09/16 07:13:08 AM: edges-ner-ontonotes_f1: training: 0.856169 validation: 0.914781
09/16 07:13:08 AM: Global learning rate: 0.0001
09/16 07:13:08 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:13:15 AM: Update 23910: task edges-ner-ontonotes, batch 910 (23910): mcc: 0.8465, acc: 0.7720, precision: 0.8987, recall: 0.8125, f1: 0.8535, edges-ner-ontonotes_loss: 0.0472
09/16 07:13:15 AM: Update 24050: task edges-ner-ontonotes, batch 50 (24050): mcc: 0.8878, acc: 0.8283, precision: 0.9259, recall: 0.8627, f1: 0.8932, edges-ner-ontonotes_loss: 0.0335
09/16 07:13:25 AM: Update 24128: task edges-ner-ontonotes, batch 128 (24128): mcc: 0.8904, acc: 0.8293, precision: 0.9284, recall: 0.8651, f1: 0.8956, edges-ner-ontonotes_loss: 0.0329
09/16 07:13:26 AM: Update 23967: task edges-ner-ontonotes, batch 967 (23967): mcc: 0.8476, acc: 0.7734, precision: 0.8993, recall: 0.8140, f1: 0.8545, edges-ner-ontonotes_loss: 0.0468
09/16 07:13:31 AM: ***** Step 24000 / Validation 24 *****
09/16 07:13:32 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:13:32 AM: Validating...
09/16 07:13:35 AM: Update 24201: task edges-ner-ontonotes, batch 201 (24201): mcc: 0.8885, acc: 0.8271, precision: 0.9251, recall: 0.8647, f1: 0.8939, edges-ner-ontonotes_loss: 0.0337
09/16 07:13:36 AM: Evaluate: task edges-ner-ontonotes, batch 30 (157): mcc: 0.8536, acc: 0.7873, precision: 0.9143, recall: 0.8111, f1: 0.8596, edges-ner-ontonotes_loss: 0.0477
09/16 07:13:45 AM: Update 24257: task edges-ner-ontonotes, batch 257 (24257): mcc: 0.8889, acc: 0.8276, precision: 0.9254, recall: 0.8654, f1: 0.8944, edges-ner-ontonotes_loss: 0.0335
09/16 07:13:46 AM: Evaluate: task edges-ner-ontonotes, batch 83 (157): mcc: 0.8965, acc: 0.8430, precision: 0.9405, recall: 0.8651, f1: 0.9012, edges-ner-ontonotes_loss: 0.0360
09/16 07:13:55 AM: Update 24297: task edges-ner-ontonotes, batch 297 (24297): mcc: 0.8884, acc: 0.8274, precision: 0.9252, recall: 0.8645, f1: 0.8938, edges-ner-ontonotes_loss: 0.0336
09/16 07:13:56 AM: Evaluate: task edges-ner-ontonotes, batch 136 (157): mcc: 0.9101, acc: 0.8631, precision: 0.9478, recall: 0.8832, f1: 0.9143, edges-ner-ontonotes_loss: 0.0314
09/16 07:14:00 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:14:00 AM: Best result seen so far for macro.
09/16 07:14:00 AM: Updating LR scheduler:
09/16 07:14:00 AM: 	Best result seen so far for macro_avg: 0.915
09/16 07:14:00 AM: 	# validation passes without improvement: 0
09/16 07:14:00 AM: edges-ner-ontonotes_loss: training: 0.046318 validation: 0.030635
09/16 07:14:00 AM: macro_avg: validation: 0.914781
09/16 07:14:00 AM: micro_avg: validation: 0.000000
09/16 07:14:00 AM: edges-ner-ontonotes_mcc: training: 0.849298 validation: 0.910552
09/16 07:14:00 AM: edges-ner-ontonotes_acc: training: 0.775533 validation: 0.863512
09/16 07:14:00 AM: edges-ner-ontonotes_precision: training: 0.900546 validation: 0.947364
09/16 07:14:00 AM: edges-ner-ontonotes_recall: training: 0.815960 validation: 0.884365
09/16 07:14:00 AM: edges-ner-ontonotes_f1: training: 0.856169 validation: 0.914781
09/16 07:14:00 AM: Global learning rate: 0.0001
09/16 07:14:00 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:14:05 AM: Update 24360: task edges-ner-ontonotes, batch 360 (24360): mcc: 0.8879, acc: 0.8266, precision: 0.9245, recall: 0.8643, f1: 0.8934, edges-ner-ontonotes_loss: 0.0337
09/16 07:14:07 AM: Update 24046: task edges-ner-ontonotes, batch 46 (24046): mcc: 0.8885, acc: 0.8285, precision: 0.9256, recall: 0.8642, f1: 0.8939, edges-ner-ontonotes_loss: 0.0335
09/16 07:14:15 AM: Update 24432: task edges-ner-ontonotes, batch 432 (24432): mcc: 0.8876, acc: 0.8260, precision: 0.9247, recall: 0.8637, f1: 0.8931, edges-ner-ontonotes_loss: 0.0341
09/16 07:14:17 AM: Update 24117: task edges-ner-ontonotes, batch 117 (24117): mcc: 0.8899, acc: 0.8290, precision: 0.9273, recall: 0.8652, f1: 0.8952, edges-ner-ontonotes_loss: 0.0330
09/16 07:14:25 AM: Update 24501: task edges-ner-ontonotes, batch 501 (24501): mcc: 0.8875, acc: 0.8256, precision: 0.9243, recall: 0.8637, f1: 0.8930, edges-ner-ontonotes_loss: 0.0342
09/16 07:14:27 AM: Update 24190: task edges-ner-ontonotes, batch 190 (24190): mcc: 0.8878, acc: 0.8264, precision: 0.9253, recall: 0.8634, f1: 0.8933, edges-ner-ontonotes_loss: 0.0339
09/16 07:14:36 AM: Update 24574: task edges-ner-ontonotes, batch 574 (24574): mcc: 0.8874, acc: 0.8255, precision: 0.9243, recall: 0.8635, f1: 0.8929, edges-ner-ontonotes_loss: 0.0342
09/16 07:14:37 AM: Update 24263: task edges-ner-ontonotes, batch 263 (24263): mcc: 0.8892, acc: 0.8282, precision: 0.9253, recall: 0.8660, f1: 0.8947, edges-ner-ontonotes_loss: 0.0334
09/16 07:14:46 AM: Update 24637: task edges-ner-ontonotes, batch 637 (24637): mcc: 0.8838, acc: 0.8207, precision: 0.9224, recall: 0.8588, f1: 0.8894, edges-ner-ontonotes_loss: 0.0357
09/16 07:14:47 AM: Update 24315: task edges-ner-ontonotes, batch 315 (24315): mcc: 0.8880, acc: 0.8270, precision: 0.9250, recall: 0.8640, f1: 0.8935, edges-ner-ontonotes_loss: 0.0337
09/16 07:14:56 AM: Update 24710: task edges-ner-ontonotes, batch 710 (24710): mcc: 0.8792, acc: 0.8144, precision: 0.9197, recall: 0.8529, f1: 0.8850, edges-ner-ontonotes_loss: 0.0376
09/16 07:14:57 AM: Update 24387: task edges-ner-ontonotes, batch 387 (24387): mcc: 0.8880, acc: 0.8268, precision: 0.9246, recall: 0.8644, f1: 0.8935, edges-ner-ontonotes_loss: 0.0337
09/16 07:15:06 AM: Update 24782: task edges-ner-ontonotes, batch 782 (24782): mcc: 0.8763, acc: 0.8107, precision: 0.9179, recall: 0.8492, f1: 0.8822, edges-ner-ontonotes_loss: 0.0389
09/16 07:15:07 AM: Update 24465: task edges-ner-ontonotes, batch 465 (24465): mcc: 0.8875, acc: 0.8257, precision: 0.9246, recall: 0.8636, f1: 0.8930, edges-ner-ontonotes_loss: 0.0341
09/16 07:15:16 AM: Update 24853: task edges-ner-ontonotes, batch 853 (24853): mcc: 0.8732, acc: 0.8068, precision: 0.9159, recall: 0.8453, f1: 0.8792, edges-ner-ontonotes_loss: 0.0401
09/16 07:15:17 AM: Update 24537: task edges-ner-ontonotes, batch 537 (24537): mcc: 0.8874, acc: 0.8255, precision: 0.9242, recall: 0.8637, f1: 0.8929, edges-ner-ontonotes_loss: 0.0342
09/16 07:15:26 AM: Update 24916: task edges-ner-ontonotes, batch 916 (24916): mcc: 0.8712, acc: 0.8042, precision: 0.9145, recall: 0.8429, f1: 0.8773, edges-ner-ontonotes_loss: 0.0409
09/16 07:15:27 AM: Update 24603: task edges-ner-ontonotes, batch 603 (24603): mcc: 0.8863, acc: 0.8242, precision: 0.9236, recall: 0.8621, f1: 0.8918, edges-ner-ontonotes_loss: 0.0346
09/16 07:15:36 AM: ***** Step 25000 / Validation 25 *****
09/16 07:15:36 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:15:37 AM: Update 24687: task edges-ner-ontonotes, batch 687 (24687): mcc: 0.8803, acc: 0.8160, precision: 0.9203, recall: 0.8543, f1: 0.8861, edges-ner-ontonotes_loss: 0.0372
09/16 07:15:38 AM: Validating...
09/16 07:15:38 AM: Evaluate: task edges-ner-ontonotes, batch 1 (157): mcc: 0.7320, acc: 0.6066, precision: 0.8667, recall: 0.6393, f1: 0.7358, edges-ner-ontonotes_loss: 0.0705
09/16 07:15:48 AM: Update 24747: task edges-ner-ontonotes, batch 747 (24747): mcc: 0.8771, acc: 0.8118, precision: 0.9183, recall: 0.8503, f1: 0.8830, edges-ner-ontonotes_loss: 0.0385
09/16 07:15:48 AM: Evaluate: task edges-ner-ontonotes, batch 61 (157): mcc: 0.8879, acc: 0.8299, precision: 0.9399, recall: 0.8499, f1: 0.8926, edges-ner-ontonotes_loss: 0.0365
09/16 07:15:59 AM: Update 24802: task edges-ner-ontonotes, batch 802 (24802): mcc: 0.8750, acc: 0.8090, precision: 0.9171, recall: 0.8475, f1: 0.8809, edges-ner-ontonotes_loss: 0.0393
09/16 07:15:59 AM: Evaluate: task edges-ner-ontonotes, batch 113 (157): mcc: 0.9009, acc: 0.8482, precision: 0.9478, recall: 0.8663, f1: 0.9052, edges-ner-ontonotes_loss: 0.0329
09/16 07:16:07 AM: Updating LR scheduler:
09/16 07:16:07 AM: 	Best result seen so far for macro_avg: 0.915
09/16 07:16:07 AM: 	# validation passes without improvement: 1
09/16 07:16:07 AM: edges-ner-ontonotes_loss: training: 0.041622 validation: 0.030358
09/16 07:16:07 AM: macro_avg: validation: 0.911714
09/16 07:16:07 AM: micro_avg: validation: 0.000000
09/16 07:16:07 AM: edges-ner-ontonotes_mcc: training: 0.869107 validation: 0.907662
09/16 07:16:07 AM: edges-ner-ontonotes_acc: training: 0.801344 validation: 0.857446
09/16 07:16:07 AM: edges-ner-ontonotes_precision: training: 0.913071 validation: 0.952047
09/16 07:16:07 AM: edges-ner-ontonotes_recall: training: 0.840514 validation: 0.874659
09/16 07:16:07 AM: edges-ner-ontonotes_f1: training: 0.875292 validation: 0.911714
09/16 07:16:07 AM: Global learning rate: 0.0001
09/16 07:16:07 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:16:09 AM: Update 24861: task edges-ner-ontonotes, batch 861 (24861): mcc: 0.8729, acc: 0.8065, precision: 0.9157, recall: 0.8450, f1: 0.8789, edges-ner-ontonotes_loss: 0.0403
09/16 07:16:09 AM: Update 25016: task edges-ner-ontonotes, batch 16 (25016): mcc: 0.8303, acc: 0.7468, precision: 0.9002, recall: 0.7820, f1: 0.8369, edges-ner-ontonotes_loss: 0.0477
09/16 07:16:19 AM: Update 24922: task edges-ner-ontonotes, batch 922 (24922): mcc: 0.8710, acc: 0.8039, precision: 0.9144, recall: 0.8428, f1: 0.8771, edges-ner-ontonotes_loss: 0.0410
09/16 07:16:19 AM: Update 25109: task edges-ner-ontonotes, batch 109 (25109): mcc: 0.8330, acc: 0.7502, precision: 0.8933, recall: 0.7930, f1: 0.8402, edges-ner-ontonotes_loss: 0.0489
09/16 07:16:29 AM: ***** Step 25000 / Validation 25 *****
09/16 07:16:29 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:16:29 AM: Validating...
09/16 07:16:31 AM: Update 25196: task edges-ner-ontonotes, batch 196 (25196): mcc: 0.8329, acc: 0.7498, precision: 0.8933, recall: 0.7929, f1: 0.8401, edges-ner-ontonotes_loss: 0.0489
09/16 07:16:31 AM: Evaluate: task edges-ner-ontonotes, batch 9 (157): mcc: 0.8010, acc: 0.7058, precision: 0.9030, recall: 0.7279, f1: 0.8060, edges-ner-ontonotes_loss: 0.0538
09/16 07:16:42 AM: Evaluate: task edges-ner-ontonotes, batch 69 (157): mcc: 0.8839, acc: 0.8242, precision: 0.9394, recall: 0.8432, f1: 0.8887, edges-ner-ontonotes_loss: 0.0374
09/16 07:16:42 AM: Update 25237: task edges-ner-ontonotes, batch 237 (25237): mcc: 0.8372, acc: 0.7557, precision: 0.8961, recall: 0.7979, f1: 0.8442, edges-ner-ontonotes_loss: 0.0481
09/16 07:16:53 AM: Evaluate: task edges-ner-ontonotes, batch 119 (157): mcc: 0.9028, acc: 0.8510, precision: 0.9488, recall: 0.8689, f1: 0.9071, edges-ner-ontonotes_loss: 0.0325
09/16 07:16:53 AM: Update 25289: task edges-ner-ontonotes, batch 289 (25289): mcc: 0.8454, acc: 0.7675, precision: 0.9013, recall: 0.8082, f1: 0.8522, edges-ner-ontonotes_loss: 0.0464
09/16 07:17:01 AM: Updating LR scheduler:
09/16 07:17:01 AM: 	Best result seen so far for macro_avg: 0.915
09/16 07:17:01 AM: 	# validation passes without improvement: 1
09/16 07:17:01 AM: edges-ner-ontonotes_loss: training: 0.041622 validation: 0.030358
09/16 07:17:01 AM: macro_avg: validation: 0.911714
09/16 07:17:01 AM: micro_avg: validation: 0.000000
09/16 07:17:01 AM: edges-ner-ontonotes_mcc: training: 0.869107 validation: 0.907662
09/16 07:17:01 AM: edges-ner-ontonotes_acc: training: 0.801344 validation: 0.857446
09/16 07:17:01 AM: edges-ner-ontonotes_precision: training: 0.913071 validation: 0.952047
09/16 07:17:01 AM: edges-ner-ontonotes_recall: training: 0.840514 validation: 0.874659
09/16 07:17:01 AM: edges-ner-ontonotes_f1: training: 0.875292 validation: 0.911714
09/16 07:17:01 AM: Global learning rate: 0.0001
09/16 07:17:01 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:17:04 AM: Update 25353: task edges-ner-ontonotes, batch 353 (25353): mcc: 0.8506, acc: 0.7754, precision: 0.9039, recall: 0.8153, f1: 0.8573, edges-ner-ontonotes_loss: 0.0450
09/16 07:17:04 AM: Update 25025: task edges-ner-ontonotes, batch 25 (25025): mcc: 0.8304, acc: 0.7466, precision: 0.8959, recall: 0.7859, f1: 0.8373, edges-ner-ontonotes_loss: 0.0480
09/16 07:17:15 AM: Update 25436: task edges-ner-ontonotes, batch 436 (25436): mcc: 0.8544, acc: 0.7801, precision: 0.9064, recall: 0.8198, f1: 0.8609, edges-ner-ontonotes_loss: 0.0441
09/16 07:17:15 AM: Update 25109: task edges-ner-ontonotes, batch 109 (25109): mcc: 0.8330, acc: 0.7502, precision: 0.8933, recall: 0.7930, f1: 0.8402, edges-ner-ontonotes_loss: 0.0489
09/16 07:17:25 AM: Update 25195: task edges-ner-ontonotes, batch 195 (25195): mcc: 0.8332, acc: 0.7500, precision: 0.8937, recall: 0.7930, f1: 0.8403, edges-ner-ontonotes_loss: 0.0489
09/16 07:17:25 AM: Update 25515: task edges-ner-ontonotes, batch 515 (25515): mcc: 0.8571, acc: 0.7843, precision: 0.9078, recall: 0.8234, f1: 0.8635, edges-ner-ontonotes_loss: 0.0434
09/16 07:17:36 AM: Update 25250: task edges-ner-ontonotes, batch 250 (25250): mcc: 0.8398, acc: 0.7597, precision: 0.8980, recall: 0.8011, f1: 0.8468, edges-ner-ontonotes_loss: 0.0476
09/16 07:17:36 AM: Update 25564: task edges-ner-ontonotes, batch 564 (25564): mcc: 0.8592, acc: 0.7876, precision: 0.9088, recall: 0.8263, f1: 0.8656, edges-ner-ontonotes_loss: 0.0428
09/16 07:17:46 AM: Update 25634: task edges-ner-ontonotes, batch 634 (25634): mcc: 0.8620, acc: 0.7917, precision: 0.9103, recall: 0.8300, f1: 0.8683, edges-ner-ontonotes_loss: 0.0420
09/16 07:17:46 AM: Update 25324: task edges-ner-ontonotes, batch 324 (25324): mcc: 0.8492, acc: 0.7730, precision: 0.9029, recall: 0.8137, f1: 0.8560, edges-ner-ontonotes_loss: 0.0455
09/16 07:17:56 AM: Update 25707: task edges-ner-ontonotes, batch 707 (25707): mcc: 0.8656, acc: 0.7963, precision: 0.9127, recall: 0.8344, f1: 0.8718, edges-ner-ontonotes_loss: 0.0410
09/16 07:17:56 AM: Update 25400: task edges-ner-ontonotes, batch 400 (25400): mcc: 0.8532, acc: 0.7788, precision: 0.9055, recall: 0.8185, f1: 0.8598, edges-ner-ontonotes_loss: 0.0445
09/16 07:18:06 AM: Update 25474: task edges-ner-ontonotes, batch 474 (25474): mcc: 0.8562, acc: 0.7828, precision: 0.9075, recall: 0.8220, f1: 0.8627, edges-ner-ontonotes_loss: 0.0436
09/16 07:18:06 AM: Update 25778: task edges-ner-ontonotes, batch 778 (25778): mcc: 0.8683, acc: 0.8001, precision: 0.9145, recall: 0.8377, f1: 0.8744, edges-ner-ontonotes_loss: 0.0402
09/16 07:18:16 AM: Update 25527: task edges-ner-ontonotes, batch 527 (25527): mcc: 0.8570, acc: 0.7842, precision: 0.9076, recall: 0.8235, f1: 0.8635, edges-ner-ontonotes_loss: 0.0433
09/16 07:18:16 AM: Update 25840: task edges-ner-ontonotes, batch 840 (25840): mcc: 0.8708, acc: 0.8035, precision: 0.9160, recall: 0.8408, f1: 0.8768, edges-ner-ontonotes_loss: 0.0396
09/16 07:18:26 AM: Update 25595: task edges-ner-ontonotes, batch 595 (25595): mcc: 0.8602, acc: 0.7892, precision: 0.9093, recall: 0.8278, f1: 0.8666, edges-ner-ontonotes_loss: 0.0424
09/16 07:18:26 AM: Update 25907: task edges-ner-ontonotes, batch 907 (25907): mcc: 0.8719, acc: 0.8049, precision: 0.9166, recall: 0.8422, f1: 0.8779, edges-ner-ontonotes_loss: 0.0392
09/16 07:18:36 AM: Update 25666: task edges-ner-ontonotes, batch 666 (25666): mcc: 0.8642, acc: 0.7944, precision: 0.9119, recall: 0.8325, f1: 0.8704, edges-ner-ontonotes_loss: 0.0415
09/16 07:18:36 AM: Update 25978: task edges-ner-ontonotes, batch 978 (25978): mcc: 0.8725, acc: 0.8058, precision: 0.9169, recall: 0.8432, f1: 0.8785, edges-ner-ontonotes_loss: 0.0390
09/16 07:18:39 AM: ***** Step 26000 / Validation 26 *****
09/16 07:18:39 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:18:39 AM: Validating...
09/16 07:18:46 AM: Update 25731: task edges-ner-ontonotes, batch 731 (25731): mcc: 0.8664, acc: 0.7975, precision: 0.9131, recall: 0.8356, f1: 0.8726, edges-ner-ontonotes_loss: 0.0407
09/16 07:18:46 AM: Evaluate: task edges-ner-ontonotes, batch 45 (157): mcc: 0.8692, acc: 0.8079, precision: 0.9188, recall: 0.8355, f1: 0.8751, edges-ner-ontonotes_loss: 0.0435
09/16 07:18:56 AM: Update 25785: task edges-ner-ontonotes, batch 785 (25785): mcc: 0.8684, acc: 0.8002, precision: 0.9145, recall: 0.8379, f1: 0.8745, edges-ner-ontonotes_loss: 0.0401
09/16 07:18:56 AM: Evaluate: task edges-ner-ontonotes, batch 100 (157): mcc: 0.8924, acc: 0.8401, precision: 0.9358, recall: 0.8619, f1: 0.8974, edges-ner-ontonotes_loss: 0.0363
09/16 07:19:06 AM: Evaluate: task edges-ner-ontonotes, batch 152 (157): mcc: 0.9100, acc: 0.8639, precision: 0.9446, recall: 0.8859, f1: 0.9143, edges-ner-ontonotes_loss: 0.0310
09/16 07:19:07 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:19:07 AM: Best result seen so far for macro.
09/16 07:19:07 AM: Updating LR scheduler:
09/16 07:19:07 AM: 	Best result seen so far for macro_avg: 0.915
09/16 07:19:07 AM: 	# validation passes without improvement: 0
09/16 07:19:07 AM: edges-ner-ontonotes_loss: training: 0.038890 validation: 0.030728
09/16 07:19:07 AM: macro_avg: validation: 0.914978
09/16 07:19:07 AM: micro_avg: validation: 0.000000
09/16 07:19:07 AM: edges-ner-ontonotes_mcc: training: 0.873006 validation: 0.910649
09/16 07:19:07 AM: edges-ner-ontonotes_acc: training: 0.806552 validation: 0.865029
09/16 07:19:07 AM: edges-ner-ontonotes_precision: training: 0.917149 validation: 0.944759
09/16 07:19:07 AM: edges-ner-ontonotes_recall: training: 0.843838 validation: 0.887019
09/16 07:19:07 AM: edges-ner-ontonotes_f1: training: 0.878968 validation: 0.914978
09/16 07:19:07 AM: Global learning rate: 0.0001
09/16 07:19:07 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:19:08 AM: Update 25836: task edges-ner-ontonotes, batch 836 (25836): mcc: 0.8704, acc: 0.8030, precision: 0.9158, recall: 0.8404, f1: 0.8765, edges-ner-ontonotes_loss: 0.0396
09/16 07:19:17 AM: Update 26066: task edges-ner-ontonotes, batch 66 (26066): mcc: 0.8864, acc: 0.8229, precision: 0.9255, recall: 0.8606, f1: 0.8919, edges-ner-ontonotes_loss: 0.0334
09/16 07:19:19 AM: Update 25903: task edges-ner-ontonotes, batch 903 (25903): mcc: 0.8719, acc: 0.8050, precision: 0.9166, recall: 0.8423, f1: 0.8779, edges-ner-ontonotes_loss: 0.0393
09/16 07:19:27 AM: Update 26144: task edges-ner-ontonotes, batch 144 (26144): mcc: 0.8855, acc: 0.8219, precision: 0.9243, recall: 0.8600, f1: 0.8910, edges-ner-ontonotes_loss: 0.0344
09/16 07:19:30 AM: Update 25986: task edges-ner-ontonotes, batch 986 (25986): mcc: 0.8727, acc: 0.8062, precision: 0.9170, recall: 0.8435, f1: 0.8787, edges-ner-ontonotes_loss: 0.0390
09/16 07:19:32 AM: ***** Step 26000 / Validation 26 *****
09/16 07:19:32 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:19:32 AM: Validating...
09/16 07:19:37 AM: Update 26189: task edges-ner-ontonotes, batch 189 (26189): mcc: 0.8745, acc: 0.8079, precision: 0.9172, recall: 0.8466, f1: 0.8805, edges-ner-ontonotes_loss: 0.0388
09/16 07:19:40 AM: Evaluate: task edges-ner-ontonotes, batch 49 (157): mcc: 0.8697, acc: 0.8074, precision: 0.9201, recall: 0.8349, f1: 0.8755, edges-ner-ontonotes_loss: 0.0430
09/16 07:19:47 AM: Update 26242: task edges-ner-ontonotes, batch 242 (26242): mcc: 0.8667, acc: 0.7983, precision: 0.9120, recall: 0.8371, f1: 0.8729, edges-ner-ontonotes_loss: 0.0419
09/16 07:19:50 AM: Evaluate: task edges-ner-ontonotes, batch 102 (157): mcc: 0.8943, acc: 0.8427, precision: 0.9366, recall: 0.8646, f1: 0.8991, edges-ner-ontonotes_loss: 0.0358
09/16 07:19:57 AM: Update 26299: task edges-ner-ontonotes, batch 299 (26299): mcc: 0.8618, acc: 0.7917, precision: 0.9089, recall: 0.8310, f1: 0.8682, edges-ner-ontonotes_loss: 0.0442
09/16 07:20:00 AM: Evaluate: task edges-ner-ontonotes, batch 152 (157): mcc: 0.9100, acc: 0.8639, precision: 0.9446, recall: 0.8859, f1: 0.9143, edges-ner-ontonotes_loss: 0.0310
09/16 07:20:01 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:20:01 AM: Best result seen so far for macro.
09/16 07:20:03 AM: Updating LR scheduler:
09/16 07:20:03 AM: 	Best result seen so far for macro_avg: 0.915
09/16 07:20:03 AM: 	# validation passes without improvement: 0
09/16 07:20:03 AM: edges-ner-ontonotes_loss: training: 0.038890 validation: 0.030728
09/16 07:20:03 AM: macro_avg: validation: 0.914978
09/16 07:20:03 AM: micro_avg: validation: 0.000000
09/16 07:20:03 AM: edges-ner-ontonotes_mcc: training: 0.873006 validation: 0.910649
09/16 07:20:03 AM: edges-ner-ontonotes_acc: training: 0.806552 validation: 0.865029
09/16 07:20:03 AM: edges-ner-ontonotes_precision: training: 0.917149 validation: 0.944759
09/16 07:20:03 AM: edges-ner-ontonotes_recall: training: 0.843838 validation: 0.887019
09/16 07:20:03 AM: edges-ner-ontonotes_f1: training: 0.878968 validation: 0.914978
09/16 07:20:03 AM: Global learning rate: 0.0001
09/16 07:20:03 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:20:07 AM: Update 26369: task edges-ner-ontonotes, batch 369 (26369): mcc: 0.8583, acc: 0.7873, precision: 0.9071, recall: 0.8263, f1: 0.8648, edges-ner-ontonotes_loss: 0.0453
09/16 07:20:10 AM: Update 26058: task edges-ner-ontonotes, batch 58 (26058): mcc: 0.8882, acc: 0.8258, precision: 0.9270, recall: 0.8625, f1: 0.8936, edges-ner-ontonotes_loss: 0.0335
09/16 07:20:19 AM: Update 26447: task edges-ner-ontonotes, batch 447 (26447): mcc: 0.8562, acc: 0.7847, precision: 0.9058, recall: 0.8236, f1: 0.8628, edges-ner-ontonotes_loss: 0.0466
09/16 07:20:20 AM: Update 26139: task edges-ner-ontonotes, batch 139 (26139): mcc: 0.8862, acc: 0.8228, precision: 0.9246, recall: 0.8611, f1: 0.8917, edges-ner-ontonotes_loss: 0.0342
09/16 07:20:31 AM: Update 26510: task edges-ner-ontonotes, batch 510 (26510): mcc: 0.8529, acc: 0.7800, precision: 0.9038, recall: 0.8195, f1: 0.8596, edges-ner-ontonotes_loss: 0.0475
09/16 07:20:31 AM: Update 26200: task edges-ner-ontonotes, batch 200 (26200): mcc: 0.8730, acc: 0.8059, precision: 0.9163, recall: 0.8447, f1: 0.8790, edges-ner-ontonotes_loss: 0.0396
09/16 07:20:42 AM: Update 26591: task edges-ner-ontonotes, batch 591 (26591): mcc: 0.8512, acc: 0.7773, precision: 0.9026, recall: 0.8175, f1: 0.8579, edges-ner-ontonotes_loss: 0.0476
09/16 07:20:42 AM: Update 26279: task edges-ner-ontonotes, batch 279 (26279): mcc: 0.8626, acc: 0.7928, precision: 0.9095, recall: 0.8319, f1: 0.8690, edges-ner-ontonotes_loss: 0.0435
09/16 07:20:52 AM: Update 26674: task edges-ner-ontonotes, batch 674 (26674): mcc: 0.8495, acc: 0.7754, precision: 0.9014, recall: 0.8155, f1: 0.8563, edges-ner-ontonotes_loss: 0.0477
09/16 07:20:52 AM: Update 26356: task edges-ner-ontonotes, batch 356 (26356): mcc: 0.8588, acc: 0.7880, precision: 0.9072, recall: 0.8271, f1: 0.8653, edges-ner-ontonotes_loss: 0.0452
09/16 07:21:02 AM: Update 26757: task edges-ner-ontonotes, batch 757 (26757): mcc: 0.8496, acc: 0.7754, precision: 0.9017, recall: 0.8154, f1: 0.8564, edges-ner-ontonotes_loss: 0.0475
09/16 07:21:02 AM: Update 26436: task edges-ner-ontonotes, batch 436 (26436): mcc: 0.8565, acc: 0.7851, precision: 0.9061, recall: 0.8240, f1: 0.8631, edges-ner-ontonotes_loss: 0.0464
09/16 07:21:12 AM: Update 26814: task edges-ner-ontonotes, batch 814 (26814): mcc: 0.8508, acc: 0.7768, precision: 0.9026, recall: 0.8167, f1: 0.8575, edges-ner-ontonotes_loss: 0.0470
09/16 07:21:12 AM: Update 26497: task edges-ner-ontonotes, batch 497 (26497): mcc: 0.8534, acc: 0.7808, precision: 0.9040, recall: 0.8202, f1: 0.8600, edges-ner-ontonotes_loss: 0.0473
09/16 07:21:22 AM: Update 26896: task edges-ner-ontonotes, batch 896 (26896): mcc: 0.8522, acc: 0.7786, precision: 0.9036, recall: 0.8184, f1: 0.8589, edges-ner-ontonotes_loss: 0.0465
09/16 07:21:22 AM: Update 26578: task edges-ner-ontonotes, batch 578 (26578): mcc: 0.8514, acc: 0.7777, precision: 0.9028, recall: 0.8177, f1: 0.8582, edges-ner-ontonotes_loss: 0.0476
09/16 07:21:32 AM: Update 26973: task edges-ner-ontonotes, batch 973 (26973): mcc: 0.8530, acc: 0.7797, precision: 0.9040, recall: 0.8196, f1: 0.8597, edges-ner-ontonotes_loss: 0.0460
09/16 07:21:32 AM: Update 26660: task edges-ner-ontonotes, batch 660 (26660): mcc: 0.8496, acc: 0.7756, precision: 0.9014, recall: 0.8156, f1: 0.8564, edges-ner-ontonotes_loss: 0.0477
09/16 07:21:35 AM: ***** Step 27000 / Validation 27 *****
09/16 07:21:35 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:21:35 AM: Validating...
09/16 07:21:42 AM: Evaluate: task edges-ner-ontonotes, batch 45 (157): mcc: 0.8756, acc: 0.8160, precision: 0.9247, recall: 0.8415, f1: 0.8812, edges-ner-ontonotes_loss: 0.0399
09/16 07:21:42 AM: Update 26731: task edges-ner-ontonotes, batch 731 (26731): mcc: 0.8496, acc: 0.7754, precision: 0.9017, recall: 0.8154, f1: 0.8564, edges-ner-ontonotes_loss: 0.0475
09/16 07:21:52 AM: Evaluate: task edges-ner-ontonotes, batch 105 (157): mcc: 0.9001, acc: 0.8496, precision: 0.9410, recall: 0.8711, f1: 0.9047, edges-ner-ontonotes_loss: 0.0336
09/16 07:21:52 AM: Update 26769: task edges-ner-ontonotes, batch 769 (26769): mcc: 0.8496, acc: 0.7753, precision: 0.9019, recall: 0.8153, f1: 0.8564, edges-ner-ontonotes_loss: 0.0475
09/16 07:22:02 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:22:02 AM: Best result seen so far for macro.
09/16 07:22:02 AM: Updating LR scheduler:
09/16 07:22:02 AM: 	Best result seen so far for macro_avg: 0.916
09/16 07:22:02 AM: 	# validation passes without improvement: 0
09/16 07:22:02 AM: edges-ner-ontonotes_loss: training: 0.045772 validation: 0.029950
09/16 07:22:02 AM: macro_avg: validation: 0.915968
09/16 07:22:02 AM: micro_avg: validation: 0.000000
09/16 07:22:02 AM: edges-ner-ontonotes_mcc: training: 0.853618 validation: 0.911782
09/16 07:22:02 AM: edges-ner-ontonotes_acc: training: 0.780393 validation: 0.865635
09/16 07:22:02 AM: edges-ner-ontonotes_precision: training: 0.904439 validation: 0.947996
09/16 07:22:02 AM: edges-ner-ontonotes_recall: training: 0.820229 validation: 0.886033
09/16 07:22:02 AM: edges-ner-ontonotes_f1: training: 0.860278 validation: 0.915968
09/16 07:22:02 AM: Global learning rate: 0.0001
09/16 07:22:02 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:22:02 AM: Update 27001: task edges-ner-ontonotes, batch 1 (27001): mcc: 0.9222, acc: 0.8636, precision: 0.9213, recall: 0.9318, f1: 0.9266, edges-ner-ontonotes_loss: 0.0268
09/16 07:22:02 AM: Update 26823: task edges-ner-ontonotes, batch 823 (26823): mcc: 0.8510, acc: 0.7771, precision: 0.9028, recall: 0.8171, f1: 0.8578, edges-ner-ontonotes_loss: 0.0469
09/16 07:22:12 AM: Update 26899: task edges-ner-ontonotes, batch 899 (26899): mcc: 0.8523, acc: 0.7787, precision: 0.9036, recall: 0.8185, f1: 0.8590, edges-ner-ontonotes_loss: 0.0464
09/16 07:22:12 AM: Update 27073: task edges-ner-ontonotes, batch 73 (27073): mcc: 0.8703, acc: 0.8032, precision: 0.9153, recall: 0.8407, f1: 0.8764, edges-ner-ontonotes_loss: 0.0394
09/16 07:22:22 AM: Update 27125: task edges-ner-ontonotes, batch 125 (27125): mcc: 0.8751, acc: 0.8103, precision: 0.9189, recall: 0.8461, f1: 0.8810, edges-ner-ontonotes_loss: 0.0378
09/16 07:22:23 AM: Update 26985: task edges-ner-ontonotes, batch 985 (26985): mcc: 0.8533, acc: 0.7801, precision: 0.9042, recall: 0.8199, f1: 0.8600, edges-ner-ontonotes_loss: 0.0459
09/16 07:22:25 AM: ***** Step 27000 / Validation 27 *****
09/16 07:22:25 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:22:25 AM: Validating...
09/16 07:22:33 AM: Update 27184: task edges-ner-ontonotes, batch 184 (27184): mcc: 0.8810, acc: 0.8180, precision: 0.9216, recall: 0.8544, f1: 0.8867, edges-ner-ontonotes_loss: 0.0363
09/16 07:22:33 AM: Evaluate: task edges-ner-ontonotes, batch 50 (157): mcc: 0.8770, acc: 0.8169, precision: 0.9256, recall: 0.8432, f1: 0.8825, edges-ner-ontonotes_loss: 0.0392
09/16 07:22:43 AM: Update 27240: task edges-ner-ontonotes, batch 240 (27240): mcc: 0.8817, acc: 0.8197, precision: 0.9219, recall: 0.8554, f1: 0.8874, edges-ner-ontonotes_loss: 0.0358
09/16 07:22:43 AM: Evaluate: task edges-ner-ontonotes, batch 102 (157): mcc: 0.8988, acc: 0.8472, precision: 0.9412, recall: 0.8686, f1: 0.9034, edges-ner-ontonotes_loss: 0.0340
09/16 07:22:53 AM: Evaluate: task edges-ner-ontonotes, batch 151 (157): mcc: 0.9114, acc: 0.8650, precision: 0.9481, recall: 0.8852, f1: 0.9156, edges-ner-ontonotes_loss: 0.0302
09/16 07:22:53 AM: Update 27294: task edges-ner-ontonotes, batch 294 (27294): mcc: 0.8846, acc: 0.8233, precision: 0.9238, recall: 0.8589, f1: 0.8902, edges-ner-ontonotes_loss: 0.0350
09/16 07:22:54 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:22:54 AM: Best result seen so far for macro.
09/16 07:22:54 AM: Updating LR scheduler:
09/16 07:22:54 AM: 	Best result seen so far for macro_avg: 0.916
09/16 07:22:54 AM: 	# validation passes without improvement: 0
09/16 07:22:54 AM: edges-ner-ontonotes_loss: training: 0.045772 validation: 0.029950
09/16 07:22:54 AM: macro_avg: validation: 0.915968
09/16 07:22:54 AM: micro_avg: validation: 0.000000
09/16 07:22:54 AM: edges-ner-ontonotes_mcc: training: 0.853618 validation: 0.911782
09/16 07:22:54 AM: edges-ner-ontonotes_acc: training: 0.780393 validation: 0.865635
09/16 07:22:54 AM: edges-ner-ontonotes_precision: training: 0.904439 validation: 0.947996
09/16 07:22:54 AM: edges-ner-ontonotes_recall: training: 0.820229 validation: 0.886033
09/16 07:22:54 AM: edges-ner-ontonotes_f1: training: 0.860278 validation: 0.915968
09/16 07:22:54 AM: Global learning rate: 0.0001
09/16 07:22:54 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:23:03 AM: Update 27040: task edges-ner-ontonotes, batch 40 (27040): mcc: 0.8674, acc: 0.7983, precision: 0.9129, recall: 0.8375, f1: 0.8736, edges-ner-ontonotes_loss: 0.0407
09/16 07:23:03 AM: Update 27375: task edges-ner-ontonotes, batch 375 (27375): mcc: 0.8864, acc: 0.8253, precision: 0.9243, recall: 0.8618, f1: 0.8919, edges-ner-ontonotes_loss: 0.0345
09/16 07:23:14 AM: Update 27098: task edges-ner-ontonotes, batch 98 (27098): mcc: 0.8748, acc: 0.8089, precision: 0.9196, recall: 0.8449, f1: 0.8807, edges-ner-ontonotes_loss: 0.0384
09/16 07:23:14 AM: Update 27443: task edges-ner-ontonotes, batch 443 (27443): mcc: 0.8862, acc: 0.8251, precision: 0.9243, recall: 0.8614, f1: 0.8917, edges-ner-ontonotes_loss: 0.0345
09/16 07:23:25 AM: Update 27169: task edges-ner-ontonotes, batch 169 (27169): mcc: 0.8792, acc: 0.8156, precision: 0.9200, recall: 0.8526, f1: 0.8850, edges-ner-ontonotes_loss: 0.0367
09/16 07:23:25 AM: Update 27513: task edges-ner-ontonotes, batch 513 (27513): mcc: 0.8867, acc: 0.8258, precision: 0.9244, recall: 0.8623, f1: 0.8923, edges-ner-ontonotes_loss: 0.0343
09/16 07:23:36 AM: Update 27247: task edges-ner-ontonotes, batch 247 (27247): mcc: 0.8821, acc: 0.8202, precision: 0.9223, recall: 0.8557, f1: 0.8877, edges-ner-ontonotes_loss: 0.0357
09/16 07:23:37 AM: Update 27583: task edges-ner-ontonotes, batch 583 (27583): mcc: 0.8866, acc: 0.8254, precision: 0.9244, recall: 0.8619, f1: 0.8921, edges-ner-ontonotes_loss: 0.0343
09/16 07:23:46 AM: Update 27314: task edges-ner-ontonotes, batch 314 (27314): mcc: 0.8851, acc: 0.8239, precision: 0.9239, recall: 0.8596, f1: 0.8906, edges-ner-ontonotes_loss: 0.0349
09/16 07:23:47 AM: Update 27653: task edges-ner-ontonotes, batch 653 (27653): mcc: 0.8867, acc: 0.8257, precision: 0.9247, recall: 0.8619, f1: 0.8922, edges-ner-ontonotes_loss: 0.0343
09/16 07:23:57 AM: Update 27713: task edges-ner-ontonotes, batch 713 (27713): mcc: 0.8858, acc: 0.8244, precision: 0.9241, recall: 0.8609, f1: 0.8913, edges-ner-ontonotes_loss: 0.0346
09/16 07:23:57 AM: Update 27392: task edges-ner-ontonotes, batch 392 (27392): mcc: 0.8865, acc: 0.8253, precision: 0.9243, recall: 0.8619, f1: 0.8920, edges-ner-ontonotes_loss: 0.0345
09/16 07:24:07 AM: Update 27782: task edges-ner-ontonotes, batch 782 (27782): mcc: 0.8823, acc: 0.8197, precision: 0.9219, recall: 0.8564, f1: 0.8880, edges-ner-ontonotes_loss: 0.0359
09/16 07:24:07 AM: Update 27459: task edges-ner-ontonotes, batch 459 (27459): mcc: 0.8865, acc: 0.8255, precision: 0.9243, recall: 0.8619, f1: 0.8920, edges-ner-ontonotes_loss: 0.0344
09/16 07:24:17 AM: Update 27857: task edges-ner-ontonotes, batch 857 (27857): mcc: 0.8780, acc: 0.8141, precision: 0.9195, recall: 0.8508, f1: 0.8838, edges-ner-ontonotes_loss: 0.0376
09/16 07:24:17 AM: Update 27535: task edges-ner-ontonotes, batch 535 (27535): mcc: 0.8865, acc: 0.8255, precision: 0.9244, recall: 0.8619, f1: 0.8921, edges-ner-ontonotes_loss: 0.0344
09/16 07:24:27 AM: Update 27931: task edges-ner-ontonotes, batch 931 (27931): mcc: 0.8751, acc: 0.8104, precision: 0.9176, recall: 0.8472, f1: 0.8810, edges-ner-ontonotes_loss: 0.0387
09/16 07:24:28 AM: Update 27603: task edges-ner-ontonotes, batch 603 (27603): mcc: 0.8867, acc: 0.8255, precision: 0.9248, recall: 0.8618, f1: 0.8922, edges-ner-ontonotes_loss: 0.0343
09/16 07:24:37 AM: ***** Step 28000 / Validation 28 *****
09/16 07:24:37 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:24:37 AM: Validating...
09/16 07:24:37 AM: Evaluate: task edges-ner-ontonotes, batch 3 (157): mcc: 0.7102, acc: 0.5833, precision: 0.8411, recall: 0.6225, f1: 0.7155, edges-ner-ontonotes_loss: 0.0757
09/16 07:24:38 AM: Update 27678: task edges-ner-ontonotes, batch 678 (27678): mcc: 0.8868, acc: 0.8259, precision: 0.9247, recall: 0.8620, f1: 0.8922, edges-ner-ontonotes_loss: 0.0344
09/16 07:24:47 AM: Evaluate: task edges-ner-ontonotes, batch 68 (157): mcc: 0.8842, acc: 0.8262, precision: 0.9313, recall: 0.8510, f1: 0.8894, edges-ner-ontonotes_loss: 0.0383
09/16 07:24:48 AM: Update 27716: task edges-ner-ontonotes, batch 716 (27716): mcc: 0.8858, acc: 0.8244, precision: 0.9241, recall: 0.8609, f1: 0.8914, edges-ner-ontonotes_loss: 0.0346
09/16 07:24:57 AM: Evaluate: task edges-ner-ontonotes, batch 115 (157): mcc: 0.9035, acc: 0.8541, precision: 0.9423, recall: 0.8762, f1: 0.9081, edges-ner-ontonotes_loss: 0.0332
09/16 07:24:58 AM: Update 27766: task edges-ner-ontonotes, batch 766 (27766): mcc: 0.8831, acc: 0.8207, precision: 0.9225, recall: 0.8573, f1: 0.8887, edges-ner-ontonotes_loss: 0.0355
09/16 07:25:05 AM: Updating LR scheduler:
09/16 07:25:05 AM: 	Best result seen so far for macro_avg: 0.916
09/16 07:25:05 AM: 	# validation passes without improvement: 1
09/16 07:25:05 AM: edges-ner-ontonotes_loss: training: 0.039836 validation: 0.030433
09/16 07:25:05 AM: macro_avg: validation: 0.914407
09/16 07:25:05 AM: micro_avg: validation: 0.000000
09/16 07:25:05 AM: edges-ner-ontonotes_mcc: training: 0.872741 validation: 0.910129
09/16 07:25:05 AM: edges-ner-ontonotes_acc: training: 0.807097 validation: 0.863057
09/16 07:25:05 AM: edges-ner-ontonotes_precision: training: 0.916387 validation: 0.946301
09/16 07:25:05 AM: edges-ner-ontonotes_recall: training: 0.844069 validation: 0.884592
09/16 07:25:05 AM: edges-ner-ontonotes_f1: training: 0.878742 validation: 0.914407
09/16 07:25:05 AM: Global learning rate: 0.0001
09/16 07:25:05 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:25:08 AM: Update 27839: task edges-ner-ontonotes, batch 839 (27839): mcc: 0.8788, acc: 0.8153, precision: 0.9201, recall: 0.8518, f1: 0.8846, edges-ner-ontonotes_loss: 0.0372
09/16 07:25:09 AM: Update 28009: task edges-ner-ontonotes, batch 9 (28009): mcc: 0.8330, acc: 0.7584, precision: 0.8790, recall: 0.8062, f1: 0.8410, edges-ner-ontonotes_loss: 0.0598
09/16 07:25:18 AM: Update 27919: task edges-ner-ontonotes, batch 919 (27919): mcc: 0.8754, acc: 0.8108, precision: 0.9178, recall: 0.8477, f1: 0.8814, edges-ner-ontonotes_loss: 0.0386
09/16 07:25:19 AM: Update 28091: task edges-ner-ontonotes, batch 91 (28091): mcc: 0.8375, acc: 0.7576, precision: 0.8919, recall: 0.8024, f1: 0.8448, edges-ner-ontonotes_loss: 0.0507
09/16 07:25:28 AM: ***** Step 28000 / Validation 28 *****
09/16 07:25:28 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:25:28 AM: Validating...
09/16 07:25:28 AM: Evaluate: task edges-ner-ontonotes, batch 1 (157): mcc: 0.7431, acc: 0.6230, precision: 0.8696, recall: 0.6557, f1: 0.7477, edges-ner-ontonotes_loss: 0.0678
09/16 07:25:29 AM: Update 28177: task edges-ner-ontonotes, batch 177 (28177): mcc: 0.8346, acc: 0.7519, precision: 0.8909, recall: 0.7980, f1: 0.8419, edges-ner-ontonotes_loss: 0.0512
09/16 07:25:38 AM: Evaluate: task edges-ner-ontonotes, batch 66 (157): mcc: 0.8834, acc: 0.8254, precision: 0.9301, recall: 0.8508, f1: 0.8886, edges-ner-ontonotes_loss: 0.0387
09/16 07:25:39 AM: Update 28238: task edges-ner-ontonotes, batch 238 (28238): mcc: 0.8368, acc: 0.7539, precision: 0.8936, recall: 0.7996, f1: 0.8440, edges-ner-ontonotes_loss: 0.0504
09/16 07:25:48 AM: Evaluate: task edges-ner-ontonotes, batch 118 (157): mcc: 0.9045, acc: 0.8554, precision: 0.9427, recall: 0.8776, f1: 0.9090, edges-ner-ontonotes_loss: 0.0329
09/16 07:25:49 AM: Update 28300: task edges-ner-ontonotes, batch 300 (28300): mcc: 0.8385, acc: 0.7567, precision: 0.8944, recall: 0.8020, f1: 0.8457, edges-ner-ontonotes_loss: 0.0496
09/16 07:25:54 AM: Updating LR scheduler:
09/16 07:25:54 AM: 	Best result seen so far for macro_avg: 0.916
09/16 07:25:54 AM: 	# validation passes without improvement: 1
09/16 07:25:54 AM: edges-ner-ontonotes_loss: training: 0.039836 validation: 0.030433
09/16 07:25:54 AM: macro_avg: validation: 0.914407
09/16 07:25:54 AM: micro_avg: validation: 0.000000
09/16 07:25:54 AM: edges-ner-ontonotes_mcc: training: 0.872741 validation: 0.910129
09/16 07:25:54 AM: edges-ner-ontonotes_acc: training: 0.807097 validation: 0.863057
09/16 07:25:54 AM: edges-ner-ontonotes_precision: training: 0.916387 validation: 0.946301
09/16 07:25:54 AM: edges-ner-ontonotes_recall: training: 0.844069 validation: 0.884592
09/16 07:25:54 AM: edges-ner-ontonotes_f1: training: 0.878742 validation: 0.914407
09/16 07:25:54 AM: Global learning rate: 0.0001
09/16 07:25:54 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:25:58 AM: Update 28010: task edges-ner-ontonotes, batch 10 (28010): mcc: 0.8378, acc: 0.7668, precision: 0.8797, recall: 0.8144, f1: 0.8458, edges-ner-ontonotes_loss: 0.0582
09/16 07:25:59 AM: Update 28361: task edges-ner-ontonotes, batch 361 (28361): mcc: 0.8428, acc: 0.7636, precision: 0.8977, recall: 0.8067, f1: 0.8498, edges-ner-ontonotes_loss: 0.0486
09/16 07:26:08 AM: Update 28086: task edges-ner-ontonotes, batch 86 (28086): mcc: 0.8370, acc: 0.7570, precision: 0.8914, recall: 0.8020, f1: 0.8443, edges-ner-ontonotes_loss: 0.0509
09/16 07:26:09 AM: Update 28440: task edges-ner-ontonotes, batch 440 (28440): mcc: 0.8472, acc: 0.7695, precision: 0.9010, recall: 0.8117, f1: 0.8540, edges-ner-ontonotes_loss: 0.0471
09/16 07:26:19 AM: Update 28165: task edges-ner-ontonotes, batch 165 (28165): mcc: 0.8360, acc: 0.7533, precision: 0.8922, recall: 0.7994, f1: 0.8433, edges-ner-ontonotes_loss: 0.0508
09/16 07:26:19 AM: Update 28519: task edges-ner-ontonotes, batch 519 (28519): mcc: 0.8503, acc: 0.7746, precision: 0.9020, recall: 0.8165, f1: 0.8571, edges-ner-ontonotes_loss: 0.0462
09/16 07:26:29 AM: Update 28252: task edges-ner-ontonotes, batch 252 (28252): mcc: 0.8367, acc: 0.7539, precision: 0.8936, recall: 0.7995, f1: 0.8439, edges-ner-ontonotes_loss: 0.0503
09/16 07:26:30 AM: Update 28596: task edges-ner-ontonotes, batch 596 (28596): mcc: 0.8537, acc: 0.7800, precision: 0.9045, recall: 0.8202, f1: 0.8603, edges-ner-ontonotes_loss: 0.0450
09/16 07:26:39 AM: Update 28323: task edges-ner-ontonotes, batch 323 (28323): mcc: 0.8390, acc: 0.7578, precision: 0.8953, recall: 0.8020, f1: 0.8461, edges-ner-ontonotes_loss: 0.0494
09/16 07:26:40 AM: Update 28665: task edges-ner-ontonotes, batch 665 (28665): mcc: 0.8568, acc: 0.7840, precision: 0.9064, recall: 0.8241, f1: 0.8633, edges-ner-ontonotes_loss: 0.0442
09/16 07:26:49 AM: Update 28398: task edges-ner-ontonotes, batch 398 (28398): mcc: 0.8451, acc: 0.7666, precision: 0.8997, recall: 0.8091, f1: 0.8520, edges-ner-ontonotes_loss: 0.0478
09/16 07:26:50 AM: Update 28740: task edges-ner-ontonotes, batch 740 (28740): mcc: 0.8606, acc: 0.7891, precision: 0.9088, recall: 0.8289, f1: 0.8670, edges-ner-ontonotes_loss: 0.0430
09/16 07:26:59 AM: Update 28469: task edges-ner-ontonotes, batch 469 (28469): mcc: 0.8493, acc: 0.7728, precision: 0.9019, recall: 0.8147, f1: 0.8561, edges-ner-ontonotes_loss: 0.0466
09/16 07:27:00 AM: Update 28809: task edges-ner-ontonotes, batch 809 (28809): mcc: 0.8636, acc: 0.7934, precision: 0.9107, recall: 0.8327, f1: 0.8700, edges-ner-ontonotes_loss: 0.0421
09/16 07:27:10 AM: Update 28542: task edges-ner-ontonotes, batch 542 (28542): mcc: 0.8505, acc: 0.7754, precision: 0.9023, recall: 0.8166, f1: 0.8573, edges-ner-ontonotes_loss: 0.0460
09/16 07:27:10 AM: Update 28883: task edges-ner-ontonotes, batch 883 (28883): mcc: 0.8663, acc: 0.7969, precision: 0.9125, recall: 0.8359, f1: 0.8725, edges-ner-ontonotes_loss: 0.0412
09/16 07:27:20 AM: Update 28617: task edges-ner-ontonotes, batch 617 (28617): mcc: 0.8542, acc: 0.7806, precision: 0.9048, recall: 0.8210, f1: 0.8608, edges-ner-ontonotes_loss: 0.0448
09/16 07:27:23 AM: Update 28948: task edges-ner-ontonotes, batch 948 (28948): mcc: 0.8679, acc: 0.7988, precision: 0.9135, recall: 0.8379, f1: 0.8741, edges-ner-ontonotes_loss: 0.0408
09/16 07:27:30 AM: Update 28679: task edges-ner-ontonotes, batch 679 (28679): mcc: 0.8581, acc: 0.7858, precision: 0.9072, recall: 0.8258, f1: 0.8646, edges-ner-ontonotes_loss: 0.0439
09/16 07:27:30 AM: ***** Step 29000 / Validation 29 *****
09/16 07:27:30 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:27:30 AM: Validating...
09/16 07:27:33 AM: Evaluate: task edges-ner-ontonotes, batch 15 (157): mcc: 0.8070, acc: 0.7268, precision: 0.8878, recall: 0.7513, f1: 0.8139, edges-ner-ontonotes_loss: 0.0553
09/16 07:27:40 AM: Update 28737: task edges-ner-ontonotes, batch 737 (28737): mcc: 0.8605, acc: 0.7889, precision: 0.9087, recall: 0.8288, f1: 0.8669, edges-ner-ontonotes_loss: 0.0431
09/16 07:27:43 AM: Evaluate: task edges-ner-ontonotes, batch 72 (157): mcc: 0.8810, acc: 0.8231, precision: 0.9293, recall: 0.8471, f1: 0.8863, edges-ner-ontonotes_loss: 0.0400
09/16 07:27:50 AM: Update 28789: task edges-ner-ontonotes, batch 789 (28789): mcc: 0.8628, acc: 0.7922, precision: 0.9103, recall: 0.8316, f1: 0.8692, edges-ner-ontonotes_loss: 0.0423
09/16 07:27:53 AM: Evaluate: task edges-ner-ontonotes, batch 122 (157): mcc: 0.9037, acc: 0.8556, precision: 0.9403, recall: 0.8785, f1: 0.9083, edges-ner-ontonotes_loss: 0.0334
09/16 07:27:59 AM: Updating LR scheduler:
09/16 07:27:59 AM: 	Best result seen so far for macro_avg: 0.916
09/16 07:27:59 AM: 	# validation passes without improvement: 2
09/16 07:27:59 AM: edges-ner-ontonotes_loss: training: 0.040468 validation: 0.030767
09/16 07:27:59 AM: macro_avg: validation: 0.915266
09/16 07:27:59 AM: micro_avg: validation: 0.000000
09/16 07:27:59 AM: edges-ner-ontonotes_mcc: training: 0.868922 validation: 0.910930
09/16 07:27:59 AM: edges-ner-ontonotes_acc: training: 0.800421 validation: 0.864953
09/16 07:27:59 AM: edges-ner-ontonotes_precision: training: 0.914055 validation: 0.944427
09/16 07:27:59 AM: edges-ner-ontonotes_recall: training: 0.839252 validation: 0.887853
09/16 07:27:59 AM: edges-ner-ontonotes_f1: training: 0.875058 validation: 0.915266
09/16 07:27:59 AM: Global learning rate: 0.0001
09/16 07:27:59 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:28:00 AM: Update 28850: task edges-ner-ontonotes, batch 850 (28850): mcc: 0.8650, acc: 0.7954, precision: 0.9117, recall: 0.8344, f1: 0.8713, edges-ner-ontonotes_loss: 0.0416
09/16 07:28:04 AM: Update 29031: task edges-ner-ontonotes, batch 31 (29031): mcc: 0.8823, acc: 0.8210, precision: 0.9202, recall: 0.8580, f1: 0.8880, edges-ner-ontonotes_loss: 0.0354
09/16 07:28:10 AM: Update 28921: task edges-ner-ontonotes, batch 921 (28921): mcc: 0.8672, acc: 0.7981, precision: 0.9130, recall: 0.8371, f1: 0.8734, edges-ner-ontonotes_loss: 0.0410
09/16 07:28:14 AM: Update 29106: task edges-ner-ontonotes, batch 106 (29106): mcc: 0.8812, acc: 0.8159, precision: 0.9187, recall: 0.8575, f1: 0.8870, edges-ner-ontonotes_loss: 0.0359
09/16 07:28:20 AM: Update 28967: task edges-ner-ontonotes, batch 967 (28967): mcc: 0.8686, acc: 0.7999, precision: 0.9137, recall: 0.8389, f1: 0.8747, edges-ner-ontonotes_loss: 0.0406
09/16 07:28:24 AM: Update 29187: task edges-ner-ontonotes, batch 187 (29187): mcc: 0.8833, acc: 0.8200, precision: 0.9216, recall: 0.8585, f1: 0.8889, edges-ner-ontonotes_loss: 0.0356
09/16 07:28:25 AM: ***** Step 29000 / Validation 29 *****
09/16 07:28:25 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:28:25 AM: Validating...
09/16 07:28:30 AM: Evaluate: task edges-ner-ontonotes, batch 36 (157): mcc: 0.8578, acc: 0.7944, precision: 0.9106, recall: 0.8222, f1: 0.8641, edges-ner-ontonotes_loss: 0.0462
09/16 07:28:34 AM: Update 29246: task edges-ner-ontonotes, batch 246 (29246): mcc: 0.8865, acc: 0.8239, precision: 0.9244, recall: 0.8619, f1: 0.8920, edges-ner-ontonotes_loss: 0.0346
09/16 07:28:41 AM: Evaluate: task edges-ner-ontonotes, batch 94 (157): mcc: 0.8956, acc: 0.8421, precision: 0.9387, recall: 0.8650, f1: 0.9003, edges-ner-ontonotes_loss: 0.0361
09/16 07:28:44 AM: Update 29288: task edges-ner-ontonotes, batch 288 (29288): mcc: 0.8832, acc: 0.8197, precision: 0.9220, recall: 0.8581, f1: 0.8889, edges-ner-ontonotes_loss: 0.0357
09/16 07:28:51 AM: Evaluate: task edges-ner-ontonotes, batch 145 (157): mcc: 0.9095, acc: 0.8633, precision: 0.9444, recall: 0.8853, f1: 0.9139, edges-ner-ontonotes_loss: 0.0314
09/16 07:28:53 AM: Updating LR scheduler:
09/16 07:28:53 AM: 	Best result seen so far for macro_avg: 0.916
09/16 07:28:53 AM: 	# validation passes without improvement: 2
09/16 07:28:53 AM: edges-ner-ontonotes_loss: training: 0.040468 validation: 0.030767
09/16 07:28:53 AM: macro_avg: validation: 0.915266
09/16 07:28:53 AM: micro_avg: validation: 0.000000
09/16 07:28:53 AM: edges-ner-ontonotes_mcc: training: 0.868922 validation: 0.910930
09/16 07:28:53 AM: edges-ner-ontonotes_acc: training: 0.800421 validation: 0.864953
09/16 07:28:53 AM: edges-ner-ontonotes_precision: training: 0.914055 validation: 0.944427
09/16 07:28:53 AM: edges-ner-ontonotes_recall: training: 0.839252 validation: 0.887853
09/16 07:28:53 AM: edges-ner-ontonotes_f1: training: 0.875058 validation: 0.915266
09/16 07:28:53 AM: Global learning rate: 0.0001
09/16 07:28:53 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:28:54 AM: Update 29346: task edges-ner-ontonotes, batch 346 (29346): mcc: 0.8761, acc: 0.8111, precision: 0.9172, recall: 0.8494, f1: 0.8820, edges-ner-ontonotes_loss: 0.0387
09/16 07:29:01 AM: Update 29055: task edges-ner-ontonotes, batch 55 (29055): mcc: 0.8827, acc: 0.8206, precision: 0.9196, recall: 0.8593, f1: 0.8884, edges-ner-ontonotes_loss: 0.0363
09/16 07:29:04 AM: Update 29419: task edges-ner-ontonotes, batch 419 (29419): mcc: 0.8694, acc: 0.8023, precision: 0.9128, recall: 0.8413, f1: 0.8756, edges-ner-ontonotes_loss: 0.0414
09/16 07:29:11 AM: Update 29130: task edges-ner-ontonotes, batch 130 (29130): mcc: 0.8833, acc: 0.8190, precision: 0.9209, recall: 0.8592, f1: 0.8890, edges-ner-ontonotes_loss: 0.0354
09/16 07:29:14 AM: Update 29490: task edges-ner-ontonotes, batch 490 (29490): mcc: 0.8652, acc: 0.7971, precision: 0.9102, recall: 0.8361, f1: 0.8716, edges-ner-ontonotes_loss: 0.0429
09/16 07:29:21 AM: Update 29200: task edges-ner-ontonotes, batch 200 (29200): mcc: 0.8843, acc: 0.8214, precision: 0.9223, recall: 0.8598, f1: 0.8900, edges-ner-ontonotes_loss: 0.0352
09/16 07:29:25 AM: Update 29564: task edges-ner-ontonotes, batch 564 (29564): mcc: 0.8622, acc: 0.7934, precision: 0.9089, recall: 0.8317, f1: 0.8686, edges-ner-ontonotes_loss: 0.0442
09/16 07:29:31 AM: Update 29270: task edges-ner-ontonotes, batch 270 (29270): mcc: 0.8858, acc: 0.8233, precision: 0.9237, recall: 0.8612, f1: 0.8914, edges-ner-ontonotes_loss: 0.0348
09/16 07:29:35 AM: Update 29624: task edges-ner-ontonotes, batch 624 (29624): mcc: 0.8606, acc: 0.7910, precision: 0.9077, recall: 0.8299, f1: 0.8670, edges-ner-ontonotes_loss: 0.0447
09/16 07:29:41 AM: Update 29349: task edges-ner-ontonotes, batch 349 (29349): mcc: 0.8758, acc: 0.8108, precision: 0.9170, recall: 0.8490, f1: 0.8817, edges-ner-ontonotes_loss: 0.0388
09/16 07:29:45 AM: Update 29712: task edges-ner-ontonotes, batch 712 (29712): mcc: 0.8580, acc: 0.7871, precision: 0.9066, recall: 0.8263, f1: 0.8646, edges-ner-ontonotes_loss: 0.0453
09/16 07:29:51 AM: Update 29427: task edges-ner-ontonotes, batch 427 (29427): mcc: 0.8695, acc: 0.8026, precision: 0.9128, recall: 0.8415, f1: 0.8757, edges-ner-ontonotes_loss: 0.0416
09/16 07:29:55 AM: Update 29797: task edges-ner-ontonotes, batch 797 (29797): mcc: 0.8570, acc: 0.7849, precision: 0.9065, recall: 0.8246, f1: 0.8636, edges-ner-ontonotes_loss: 0.0455
09/16 07:30:02 AM: Update 29508: task edges-ner-ontonotes, batch 508 (29508): mcc: 0.8645, acc: 0.7963, precision: 0.9097, recall: 0.8352, f1: 0.8709, edges-ner-ontonotes_loss: 0.0432
09/16 07:30:08 AM: Update 29878: task edges-ner-ontonotes, batch 878 (29878): mcc: 0.8555, acc: 0.7829, precision: 0.9054, recall: 0.8229, f1: 0.8621, edges-ner-ontonotes_loss: 0.0457
09/16 07:30:12 AM: Update 29571: task edges-ner-ontonotes, batch 571 (29571): mcc: 0.8618, acc: 0.7928, precision: 0.9086, recall: 0.8313, f1: 0.8682, edges-ner-ontonotes_loss: 0.0443
09/16 07:30:18 AM: Update 29959: task edges-ner-ontonotes, batch 959 (29959): mcc: 0.8559, acc: 0.7836, precision: 0.9055, recall: 0.8235, f1: 0.8625, edges-ner-ontonotes_loss: 0.0453
09/16 07:30:22 AM: Update 29651: task edges-ner-ontonotes, batch 651 (29651): mcc: 0.8599, acc: 0.7897, precision: 0.9075, recall: 0.8288, f1: 0.8664, edges-ner-ontonotes_loss: 0.0448
09/16 07:30:23 AM: ***** Step 30000 / Validation 30 *****
09/16 07:30:23 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:30:23 AM: Validating...
09/16 07:30:28 AM: Evaluate: task edges-ner-ontonotes, batch 35 (157): mcc: 0.8673, acc: 0.8039, precision: 0.9233, recall: 0.8277, f1: 0.8729, edges-ner-ontonotes_loss: 0.0420
09/16 07:30:32 AM: Update 29721: task edges-ner-ontonotes, batch 721 (29721): mcc: 0.8579, acc: 0.7868, precision: 0.9066, recall: 0.8260, f1: 0.8644, edges-ner-ontonotes_loss: 0.0453
09/16 07:30:38 AM: Evaluate: task edges-ner-ontonotes, batch 94 (157): mcc: 0.9000, acc: 0.8479, precision: 0.9461, recall: 0.8662, f1: 0.9044, edges-ner-ontonotes_loss: 0.0335
09/16 07:30:42 AM: Update 29780: task edges-ner-ontonotes, batch 780 (29780): mcc: 0.8570, acc: 0.7849, precision: 0.9064, recall: 0.8246, f1: 0.8636, edges-ner-ontonotes_loss: 0.0454
09/16 07:30:48 AM: Evaluate: task edges-ner-ontonotes, batch 148 (157): mcc: 0.9109, acc: 0.8644, precision: 0.9506, recall: 0.8818, f1: 0.9150, edges-ner-ontonotes_loss: 0.0301
09/16 07:30:50 AM: Updating LR scheduler:
09/16 07:30:50 AM: 	Best result seen so far for macro_avg: 0.916
09/16 07:30:50 AM: 	# validation passes without improvement: 3
09/16 07:30:50 AM: edges-ner-ontonotes_loss: training: 0.045003 validation: 0.029779
09/16 07:30:50 AM: macro_avg: validation: 0.915340
09/16 07:30:50 AM: micro_avg: validation: 0.000000
09/16 07:30:50 AM: edges-ner-ontonotes_mcc: training: 0.856506 validation: 0.911258
09/16 07:30:50 AM: edges-ner-ontonotes_acc: training: 0.784233 validation: 0.864726
09/16 07:30:50 AM: edges-ner-ontonotes_precision: training: 0.905708 validation: 0.950666
09/16 07:30:50 AM: edges-ner-ontonotes_recall: training: 0.824324 validation: 0.882545
09/16 07:30:50 AM: edges-ner-ontonotes_f1: training: 0.863102 validation: 0.915340
09/16 07:30:50 AM: Global learning rate: 0.0001
09/16 07:30:50 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:30:52 AM: Update 29846: task edges-ner-ontonotes, batch 846 (29846): mcc: 0.8562, acc: 0.7839, precision: 0.9056, recall: 0.8238, f1: 0.8628, edges-ner-ontonotes_loss: 0.0456
09/16 07:30:58 AM: Update 30074: task edges-ner-ontonotes, batch 74 (30074): mcc: 0.8668, acc: 0.7981, precision: 0.9129, recall: 0.8365, f1: 0.8730, edges-ner-ontonotes_loss: 0.0398
09/16 07:31:02 AM: Update 29901: task edges-ner-ontonotes, batch 901 (29901): mcc: 0.8556, acc: 0.7830, precision: 0.9053, recall: 0.8231, f1: 0.8622, edges-ner-ontonotes_loss: 0.0456
09/16 07:31:08 AM: Update 30151: task edges-ner-ontonotes, batch 151 (30151): mcc: 0.8694, acc: 0.8020, precision: 0.9140, recall: 0.8403, f1: 0.8756, edges-ner-ontonotes_loss: 0.0397
09/16 07:31:12 AM: Update 29969: task edges-ner-ontonotes, batch 969 (29969): mcc: 0.8561, acc: 0.7838, precision: 0.9055, recall: 0.8238, f1: 0.8627, edges-ner-ontonotes_loss: 0.0452
09/16 07:31:16 AM: ***** Step 30000 / Validation 30 *****
09/16 07:31:16 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:31:16 AM: Validating...
09/16 07:31:18 AM: Update 30196: task edges-ner-ontonotes, batch 196 (30196): mcc: 0.8683, acc: 0.7992, precision: 0.9137, recall: 0.8385, f1: 0.8745, edges-ner-ontonotes_loss: 0.0395
09/16 07:31:22 AM: Evaluate: task edges-ner-ontonotes, batch 48 (157): mcc: 0.8774, acc: 0.8185, precision: 0.9281, recall: 0.8417, f1: 0.8828, edges-ner-ontonotes_loss: 0.0393
09/16 07:31:29 AM: Update 30251: task edges-ner-ontonotes, batch 251 (30251): mcc: 0.8722, acc: 0.8044, precision: 0.9166, recall: 0.8429, f1: 0.8782, edges-ner-ontonotes_loss: 0.0383
09/16 07:31:32 AM: Evaluate: task edges-ner-ontonotes, batch 102 (157): mcc: 0.8984, acc: 0.8464, precision: 0.9442, recall: 0.8651, f1: 0.9029, edges-ner-ontonotes_loss: 0.0338
09/16 07:31:39 AM: Update 30302: task edges-ner-ontonotes, batch 302 (30302): mcc: 0.8756, acc: 0.8089, precision: 0.9191, recall: 0.8467, f1: 0.8814, edges-ner-ontonotes_loss: 0.0375
09/16 07:31:43 AM: Evaluate: task edges-ner-ontonotes, batch 152 (157): mcc: 0.9109, acc: 0.8642, precision: 0.9504, recall: 0.8821, f1: 0.9150, edges-ner-ontonotes_loss: 0.0300
09/16 07:31:44 AM: Updating LR scheduler:
09/16 07:31:44 AM: 	Best result seen so far for macro_avg: 0.916
09/16 07:31:44 AM: 	# validation passes without improvement: 3
09/16 07:31:44 AM: edges-ner-ontonotes_loss: training: 0.045003 validation: 0.029779
09/16 07:31:44 AM: macro_avg: validation: 0.915340
09/16 07:31:44 AM: micro_avg: validation: 0.000000
09/16 07:31:44 AM: edges-ner-ontonotes_mcc: training: 0.856506 validation: 0.911258
09/16 07:31:44 AM: edges-ner-ontonotes_acc: training: 0.784233 validation: 0.864726
09/16 07:31:44 AM: edges-ner-ontonotes_precision: training: 0.905708 validation: 0.950666
09/16 07:31:44 AM: edges-ner-ontonotes_recall: training: 0.824324 validation: 0.882545
09/16 07:31:44 AM: edges-ner-ontonotes_f1: training: 0.863102 validation: 0.915340
09/16 07:31:44 AM: Global learning rate: 0.0001
09/16 07:31:44 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:31:49 AM: Update 30368: task edges-ner-ontonotes, batch 368 (30368): mcc: 0.8787, acc: 0.8136, precision: 0.9209, recall: 0.8508, f1: 0.8845, edges-ner-ontonotes_loss: 0.0367
09/16 07:31:53 AM: Update 30064: task edges-ner-ontonotes, batch 64 (30064): mcc: 0.8665, acc: 0.7983, precision: 0.9132, recall: 0.8356, f1: 0.8727, edges-ner-ontonotes_loss: 0.0394
09/16 07:31:59 AM: Update 30443: task edges-ner-ontonotes, batch 443 (30443): mcc: 0.8808, acc: 0.8165, precision: 0.9221, recall: 0.8536, f1: 0.8865, edges-ner-ontonotes_loss: 0.0361
09/16 07:32:03 AM: Update 30138: task edges-ner-ontonotes, batch 138 (30138): mcc: 0.8695, acc: 0.8024, precision: 0.9138, recall: 0.8405, f1: 0.8756, edges-ner-ontonotes_loss: 0.0398
09/16 07:32:09 AM: Update 30505: task edges-ner-ontonotes, batch 505 (30505): mcc: 0.8831, acc: 0.8196, precision: 0.9236, recall: 0.8563, f1: 0.8887, edges-ner-ontonotes_loss: 0.0356
09/16 07:32:14 AM: Update 30195: task edges-ner-ontonotes, batch 195 (30195): mcc: 0.8682, acc: 0.7991, precision: 0.9134, recall: 0.8387, f1: 0.8744, edges-ner-ontonotes_loss: 0.0395
09/16 07:32:20 AM: Update 30596: task edges-ner-ontonotes, batch 596 (30596): mcc: 0.8831, acc: 0.8197, precision: 0.9233, recall: 0.8565, f1: 0.8887, edges-ner-ontonotes_loss: 0.0356
09/16 07:32:25 AM: Update 30269: task edges-ner-ontonotes, batch 269 (30269): mcc: 0.8726, acc: 0.8048, precision: 0.9165, recall: 0.8436, f1: 0.8785, edges-ner-ontonotes_loss: 0.0381
09/16 07:32:30 AM: Update 30670: task edges-ner-ontonotes, batch 670 (30670): mcc: 0.8839, acc: 0.8209, precision: 0.9240, recall: 0.8574, f1: 0.8895, edges-ner-ontonotes_loss: 0.0355
09/16 07:32:37 AM: Update 30335: task edges-ner-ontonotes, batch 335 (30335): mcc: 0.8768, acc: 0.8110, precision: 0.9193, recall: 0.8487, f1: 0.8826, edges-ner-ontonotes_loss: 0.0372
09/16 07:32:40 AM: Update 30743: task edges-ner-ontonotes, batch 743 (30743): mcc: 0.8838, acc: 0.8211, precision: 0.9238, recall: 0.8575, f1: 0.8894, edges-ner-ontonotes_loss: 0.0354
09/16 07:32:47 AM: Update 30406: task edges-ner-ontonotes, batch 406 (30406): mcc: 0.8803, acc: 0.8157, precision: 0.9219, recall: 0.8529, f1: 0.8860, edges-ner-ontonotes_loss: 0.0363
09/16 07:32:50 AM: Update 30816: task edges-ner-ontonotes, batch 816 (30816): mcc: 0.8846, acc: 0.8221, precision: 0.9242, recall: 0.8584, f1: 0.8901, edges-ner-ontonotes_loss: 0.0352
09/16 07:32:57 AM: Update 30485: task edges-ner-ontonotes, batch 485 (30485): mcc: 0.8827, acc: 0.8191, precision: 0.9235, recall: 0.8557, f1: 0.8883, edges-ner-ontonotes_loss: 0.0356
09/16 07:33:00 AM: Update 30861: task edges-ner-ontonotes, batch 861 (30861): mcc: 0.8825, acc: 0.8192, precision: 0.9232, recall: 0.8555, f1: 0.8881, edges-ner-ontonotes_loss: 0.0359
09/16 07:33:07 AM: Update 30543: task edges-ner-ontonotes, batch 543 (30543): mcc: 0.8826, acc: 0.8189, precision: 0.9232, recall: 0.8558, f1: 0.8882, edges-ner-ontonotes_loss: 0.0358
09/16 07:33:10 AM: Update 30939: task edges-ner-ontonotes, batch 939 (30939): mcc: 0.8788, acc: 0.8144, precision: 0.9207, recall: 0.8511, f1: 0.8845, edges-ner-ontonotes_loss: 0.0375
09/16 07:33:17 AM: Update 30624: task edges-ner-ontonotes, batch 624 (30624): mcc: 0.8834, acc: 0.8204, precision: 0.9235, recall: 0.8570, f1: 0.8890, edges-ner-ontonotes_loss: 0.0356
09/16 07:33:20 AM: ***** Step 31000 / Validation 31 *****
09/16 07:33:20 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:33:20 AM: Validating...
09/16 07:33:22 AM: Evaluate: task edges-ner-ontonotes, batch 12 (157): mcc: 0.8139, acc: 0.7260, precision: 0.9006, recall: 0.7523, f1: 0.8198, edges-ner-ontonotes_loss: 0.0541
09/16 07:33:27 AM: Update 30688: task edges-ner-ontonotes, batch 688 (30688): mcc: 0.8838, acc: 0.8208, precision: 0.9239, recall: 0.8573, f1: 0.8893, edges-ner-ontonotes_loss: 0.0355
09/16 07:33:33 AM: Evaluate: task edges-ner-ontonotes, batch 70 (157): mcc: 0.8876, acc: 0.8295, precision: 0.9331, recall: 0.8557, f1: 0.8927, edges-ner-ontonotes_loss: 0.0381
09/16 07:33:37 AM: Update 30748: task edges-ner-ontonotes, batch 748 (30748): mcc: 0.8839, acc: 0.8212, precision: 0.9237, recall: 0.8577, f1: 0.8895, edges-ner-ontonotes_loss: 0.0354
09/16 07:33:44 AM: Evaluate: task edges-ner-ontonotes, batch 119 (157): mcc: 0.9058, acc: 0.8555, precision: 0.9439, recall: 0.8789, f1: 0.9103, edges-ner-ontonotes_loss: 0.0328
09/16 07:33:47 AM: Update 30803: task edges-ner-ontonotes, batch 803 (30803): mcc: 0.8843, acc: 0.8217, precision: 0.9240, recall: 0.8581, f1: 0.8898, edges-ner-ontonotes_loss: 0.0352
09/16 07:33:51 AM: Updating LR scheduler:
09/16 07:33:51 AM: 	Best result seen so far for macro_avg: 0.916
09/16 07:33:51 AM: 	# validation passes without improvement: 0
09/16 07:33:51 AM: edges-ner-ontonotes_loss: training: 0.038206 validation: 0.030311
09/16 07:33:51 AM: macro_avg: validation: 0.915458
09/16 07:33:51 AM: micro_avg: validation: 0.000000
09/16 07:33:51 AM: edges-ner-ontonotes_mcc: training: 0.876685 validation: 0.911262
09/16 07:33:51 AM: edges-ner-ontonotes_acc: training: 0.811477 validation: 0.863209
09/16 07:33:51 AM: edges-ner-ontonotes_precision: training: 0.919405 validation: 0.947945
09/16 07:33:51 AM: edges-ner-ontonotes_recall: training: 0.848472 validation: 0.885123
09/16 07:33:51 AM: edges-ner-ontonotes_f1: training: 0.882515 validation: 0.915458
09/16 07:33:51 AM: Global learning rate: 5e-05
09/16 07:33:51 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:33:54 AM: Update 31034: task edges-ner-ontonotes, batch 34 (31034): mcc: 0.8363, acc: 0.7575, precision: 0.8952, recall: 0.7973, f1: 0.8434, edges-ner-ontonotes_loss: 0.0554
09/16 07:33:58 AM: Update 30847: task edges-ner-ontonotes, batch 847 (30847): mcc: 0.8830, acc: 0.8199, precision: 0.9235, recall: 0.8562, f1: 0.8886, edges-ner-ontonotes_loss: 0.0358
09/16 07:34:04 AM: Update 31107: task edges-ner-ontonotes, batch 107 (31107): mcc: 0.8320, acc: 0.7566, precision: 0.8919, recall: 0.7925, f1: 0.8392, edges-ner-ontonotes_loss: 0.0552
09/16 07:34:08 AM: Update 30926: task edges-ner-ontonotes, batch 926 (30926): mcc: 0.8792, acc: 0.8150, precision: 0.9211, recall: 0.8516, f1: 0.8850, edges-ner-ontonotes_loss: 0.0373
09/16 07:34:14 AM: Update 31165: task edges-ner-ontonotes, batch 165 (31165): mcc: 0.8334, acc: 0.7566, precision: 0.8900, recall: 0.7967, f1: 0.8408, edges-ner-ontonotes_loss: 0.0538
09/16 07:34:16 AM: ***** Step 31000 / Validation 31 *****
09/16 07:34:19 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:34:19 AM: Validating...
09/16 07:34:19 AM: Evaluate: task edges-ner-ontonotes, batch 1 (157): mcc: 0.7431, acc: 0.6230, precision: 0.8696, recall: 0.6557, f1: 0.7477, edges-ner-ontonotes_loss: 0.0692
09/16 07:34:24 AM: Update 31254: task edges-ner-ontonotes, batch 254 (31254): mcc: 0.8335, acc: 0.7550, precision: 0.8905, recall: 0.7964, f1: 0.8409, edges-ner-ontonotes_loss: 0.0529
09/16 07:34:29 AM: Evaluate: task edges-ner-ontonotes, batch 64 (157): mcc: 0.8879, acc: 0.8309, precision: 0.9311, recall: 0.8580, f1: 0.8931, edges-ner-ontonotes_loss: 0.0381
09/16 07:34:34 AM: Update 31324: task edges-ner-ontonotes, batch 324 (31324): mcc: 0.8370, acc: 0.7590, precision: 0.8933, recall: 0.8003, f1: 0.8442, edges-ner-ontonotes_loss: 0.0513
09/16 07:34:40 AM: Evaluate: task edges-ner-ontonotes, batch 115 (157): mcc: 0.9049, acc: 0.8545, precision: 0.9434, recall: 0.8777, f1: 0.9093, edges-ner-ontonotes_loss: 0.0331
09/16 07:34:45 AM: Update 31388: task edges-ner-ontonotes, batch 388 (31388): mcc: 0.8380, acc: 0.7599, precision: 0.8942, recall: 0.8013, f1: 0.8452, edges-ner-ontonotes_loss: 0.0508
09/16 07:34:48 AM: Updating LR scheduler:
09/16 07:34:48 AM: 	Best result seen so far for macro_avg: 0.916
09/16 07:34:48 AM: 	# validation passes without improvement: 0
09/16 07:34:48 AM: edges-ner-ontonotes_loss: training: 0.038206 validation: 0.030311
09/16 07:34:48 AM: macro_avg: validation: 0.915458
09/16 07:34:48 AM: micro_avg: validation: 0.000000
09/16 07:34:48 AM: edges-ner-ontonotes_mcc: training: 0.876685 validation: 0.911262
09/16 07:34:48 AM: edges-ner-ontonotes_acc: training: 0.811477 validation: 0.863209
09/16 07:34:48 AM: edges-ner-ontonotes_precision: training: 0.919405 validation: 0.947945
09/16 07:34:48 AM: edges-ner-ontonotes_recall: training: 0.848472 validation: 0.885123
09/16 07:34:48 AM: edges-ner-ontonotes_f1: training: 0.882515 validation: 0.915458
09/16 07:34:48 AM: Global learning rate: 5e-05
09/16 07:34:48 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:34:51 AM: Update 31011: task edges-ner-ontonotes, batch 11 (31011): mcc: 0.8128, acc: 0.7298, precision: 0.8846, recall: 0.7645, f1: 0.8202, edges-ner-ontonotes_loss: 0.0576
09/16 07:34:55 AM: Update 31447: task edges-ner-ontonotes, batch 447 (31447): mcc: 0.8404, acc: 0.7625, precision: 0.8962, recall: 0.8038, f1: 0.8475, edges-ner-ontonotes_loss: 0.0499
09/16 07:35:01 AM: Update 31092: task edges-ner-ontonotes, batch 92 (31092): mcc: 0.8334, acc: 0.7570, precision: 0.8925, recall: 0.7945, f1: 0.8407, edges-ner-ontonotes_loss: 0.0552
09/16 07:35:05 AM: Update 31520: task edges-ner-ontonotes, batch 520 (31520): mcc: 0.8463, acc: 0.7706, precision: 0.8998, recall: 0.8112, f1: 0.8532, edges-ner-ontonotes_loss: 0.0482
09/16 07:35:11 AM: Update 31149: task edges-ner-ontonotes, batch 149 (31149): mcc: 0.8338, acc: 0.7583, precision: 0.8904, recall: 0.7971, f1: 0.8412, edges-ner-ontonotes_loss: 0.0539
09/16 07:35:15 AM: Update 31607: task edges-ner-ontonotes, batch 607 (31607): mcc: 0.8494, acc: 0.7745, precision: 0.9020, recall: 0.8148, f1: 0.8562, edges-ner-ontonotes_loss: 0.0469
09/16 07:35:21 AM: Update 31229: task edges-ner-ontonotes, batch 229 (31229): mcc: 0.8345, acc: 0.7568, precision: 0.8913, recall: 0.7977, f1: 0.8419, edges-ner-ontonotes_loss: 0.0527
09/16 07:35:25 AM: Update 31686: task edges-ner-ontonotes, batch 686 (31686): mcc: 0.8525, acc: 0.7786, precision: 0.9040, recall: 0.8187, f1: 0.8592, edges-ner-ontonotes_loss: 0.0459
09/16 07:35:32 AM: Update 31321: task edges-ner-ontonotes, batch 321 (31321): mcc: 0.8369, acc: 0.7588, precision: 0.8932, recall: 0.8002, f1: 0.8441, edges-ner-ontonotes_loss: 0.0514
09/16 07:35:37 AM: Update 31747: task edges-ner-ontonotes, batch 747 (31747): mcc: 0.8543, acc: 0.7808, precision: 0.9052, recall: 0.8208, f1: 0.8609, edges-ner-ontonotes_loss: 0.0454
09/16 07:35:42 AM: Update 31414: task edges-ner-ontonotes, batch 414 (31414): mcc: 0.8389, acc: 0.7606, precision: 0.8950, recall: 0.8022, f1: 0.8461, edges-ner-ontonotes_loss: 0.0504
09/16 07:35:47 AM: Update 31827: task edges-ner-ontonotes, batch 827 (31827): mcc: 0.8582, acc: 0.7863, precision: 0.9077, recall: 0.8255, f1: 0.8647, edges-ner-ontonotes_loss: 0.0443
09/16 07:35:52 AM: Update 31473: task edges-ner-ontonotes, batch 473 (31473): mcc: 0.8424, acc: 0.7651, precision: 0.8978, recall: 0.8060, f1: 0.8494, edges-ner-ontonotes_loss: 0.0493
09/16 07:35:59 AM: Update 31903: task edges-ner-ontonotes, batch 903 (31903): mcc: 0.8613, acc: 0.7904, precision: 0.9101, recall: 0.8289, f1: 0.8676, edges-ner-ontonotes_loss: 0.0434
09/16 07:36:02 AM: Update 31548: task edges-ner-ontonotes, batch 548 (31548): mcc: 0.8470, acc: 0.7716, precision: 0.9005, recall: 0.8119, f1: 0.8539, edges-ner-ontonotes_loss: 0.0478
09/16 07:36:09 AM: Update 31978: task edges-ner-ontonotes, batch 978 (31978): mcc: 0.8639, acc: 0.7941, precision: 0.9116, recall: 0.8323, f1: 0.8702, edges-ner-ontonotes_loss: 0.0425
09/16 07:36:12 AM: ***** Step 32000 / Validation 32 *****
09/16 07:36:12 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:36:12 AM: Validating...
09/16 07:36:12 AM: Update 31619: task edges-ner-ontonotes, batch 619 (31619): mcc: 0.8501, acc: 0.7754, precision: 0.9025, recall: 0.8157, f1: 0.8569, edges-ner-ontonotes_loss: 0.0467
09/16 07:36:19 AM: Evaluate: task edges-ner-ontonotes, batch 44 (157): mcc: 0.8722, acc: 0.8127, precision: 0.9206, recall: 0.8391, f1: 0.8780, edges-ner-ontonotes_loss: 0.0424
09/16 07:36:23 AM: Update 31678: task edges-ner-ontonotes, batch 678 (31678): mcc: 0.8524, acc: 0.7785, precision: 0.9041, recall: 0.8183, f1: 0.8591, edges-ner-ontonotes_loss: 0.0460
09/16 07:36:29 AM: Evaluate: task edges-ner-ontonotes, batch 99 (157): mcc: 0.8968, acc: 0.8457, precision: 0.9395, recall: 0.8665, f1: 0.9015, edges-ner-ontonotes_loss: 0.0354
09/16 07:36:33 AM: Update 31732: task edges-ner-ontonotes, batch 732 (31732): mcc: 0.8541, acc: 0.7804, precision: 0.9052, recall: 0.8203, f1: 0.8607, edges-ner-ontonotes_loss: 0.0455
09/16 07:36:39 AM: Evaluate: task edges-ner-ontonotes, batch 154 (157): mcc: 0.9121, acc: 0.8669, precision: 0.9473, recall: 0.8873, f1: 0.9164, edges-ner-ontonotes_loss: 0.0305
09/16 07:36:40 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:36:40 AM: Best result seen so far for macro.
09/16 07:36:40 AM: Updating LR scheduler:
09/16 07:36:40 AM: 	Best result seen so far for macro_avg: 0.917
09/16 07:36:40 AM: 	# validation passes without improvement: 0
09/16 07:36:40 AM: edges-ner-ontonotes_loss: training: 0.042327 validation: 0.030275
09/16 07:36:40 AM: macro_avg: validation: 0.916722
09/16 07:36:40 AM: micro_avg: validation: 0.000000
09/16 07:36:40 AM: edges-ner-ontonotes_mcc: training: 0.864305 validation: 0.912537
09/16 07:36:40 AM: edges-ner-ontonotes_acc: training: 0.794701 validation: 0.867455
09/16 07:36:40 AM: edges-ner-ontonotes_precision: training: 0.911722 validation: 0.947705
09/16 07:36:40 AM: edges-ner-ontonotes_recall: training: 0.832978 validation: 0.887701
09/16 07:36:40 AM: edges-ner-ontonotes_f1: training: 0.870573 validation: 0.916722
09/16 07:36:40 AM: Global learning rate: 5e-05
09/16 07:36:40 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:36:43 AM: Update 31774: task edges-ner-ontonotes, batch 774 (31774): mcc: 0.8556, acc: 0.7827, precision: 0.9062, recall: 0.8223, f1: 0.8622, edges-ner-ontonotes_loss: 0.0451
09/16 07:36:52 AM: Update 32060: task edges-ner-ontonotes, batch 60 (32060): mcc: 0.8986, acc: 0.8456, precision: 0.9312, recall: 0.8776, f1: 0.9036, edges-ner-ontonotes_loss: 0.0312
09/16 07:36:53 AM: Update 31853: task edges-ner-ontonotes, batch 853 (31853): mcc: 0.8595, acc: 0.7881, precision: 0.9089, recall: 0.8269, f1: 0.8660, edges-ner-ontonotes_loss: 0.0440
09/16 07:37:02 AM: Update 32133: task edges-ner-ontonotes, batch 133 (32133): mcc: 0.8945, acc: 0.8383, precision: 0.9305, recall: 0.8707, f1: 0.8996, edges-ner-ontonotes_loss: 0.0335
09/16 07:37:03 AM: Update 31927: task edges-ner-ontonotes, batch 927 (31927): mcc: 0.8619, acc: 0.7913, precision: 0.9105, recall: 0.8297, f1: 0.8682, edges-ner-ontonotes_loss: 0.0432
09/16 07:37:12 AM: Update 32200: task edges-ner-ontonotes, batch 200 (32200): mcc: 0.8932, acc: 0.8363, precision: 0.9293, recall: 0.8695, f1: 0.8984, edges-ner-ontonotes_loss: 0.0328
09/16 07:37:13 AM: Update 31995: task edges-ner-ontonotes, batch 995 (31995): mcc: 0.8641, acc: 0.7945, precision: 0.9116, recall: 0.8328, f1: 0.8704, edges-ner-ontonotes_loss: 0.0424
09/16 07:37:14 AM: ***** Step 32000 / Validation 32 *****
09/16 07:37:14 AM: edges-ner-ontonotes: trained on 1000 batches, 0.644 epochs
09/16 07:37:14 AM: Validating...
09/16 07:37:22 AM: Update 32264: task edges-ner-ontonotes, batch 264 (32264): mcc: 0.8924, acc: 0.8345, precision: 0.9290, recall: 0.8684, f1: 0.8977, edges-ner-ontonotes_loss: 0.0327
09/16 07:37:23 AM: Evaluate: task edges-ner-ontonotes, batch 59 (157): mcc: 0.8858, acc: 0.8308, precision: 0.9318, recall: 0.8536, f1: 0.8910, edges-ner-ontonotes_loss: 0.0386
09/16 07:37:32 AM: Update 32319: task edges-ner-ontonotes, batch 319 (32319): mcc: 0.8903, acc: 0.8322, precision: 0.9274, recall: 0.8660, f1: 0.8956, edges-ner-ontonotes_loss: 0.0335
09/16 07:37:33 AM: Evaluate: task edges-ner-ontonotes, batch 110 (157): mcc: 0.9001, acc: 0.8506, precision: 0.9408, recall: 0.8714, f1: 0.9048, edges-ner-ontonotes_loss: 0.0341
09/16 07:37:43 AM: Best result seen so far for edges-ner-ontonotes.
09/16 07:37:43 AM: Best result seen so far for macro.
09/16 07:37:43 AM: Updating LR scheduler:
09/16 07:37:43 AM: 	Best result seen so far for macro_avg: 0.917
09/16 07:37:43 AM: 	# validation passes without improvement: 0
09/16 07:37:43 AM: edges-ner-ontonotes_loss: training: 0.042327 validation: 0.030275
09/16 07:37:43 AM: macro_avg: validation: 0.916722
09/16 07:37:43 AM: micro_avg: validation: 0.000000
09/16 07:37:43 AM: edges-ner-ontonotes_mcc: training: 0.864305 validation: 0.912537
09/16 07:37:43 AM: edges-ner-ontonotes_acc: training: 0.794701 validation: 0.867455
09/16 07:37:43 AM: edges-ner-ontonotes_precision: training: 0.911722 validation: 0.947705
09/16 07:37:43 AM: edges-ner-ontonotes_recall: training: 0.832978 validation: 0.887701
09/16 07:37:43 AM: edges-ner-ontonotes_f1: training: 0.870573 validation: 0.916722
09/16 07:37:43 AM: Global learning rate: 5e-05
09/16 07:37:43 AM: Saving checkpoints to: ./experiments/ner-ontonotes-sst-top/run
09/16 07:37:43 AM: Update 32373: task edges-ner-ontonotes, batch 373 (32373): mcc: 0.8903, acc: 0.8318, precision: 0.9276, recall: 0.8659, f1: 0.8956, edges-ner-ontonotes_loss: 0.0335
09/16 07:37:45 AM: Update 32001: task edges-ner-ontonotes, batch 1 (32001): mcc: 0.9199, acc: 0.8957, precision: 0.9537, recall: 0.8957, f1: 0.9238, edges-ner-ontonotes_loss: 0.0306
09/16 07:37:53 AM: Update 32448: task edges-ner-ontonotes, batch 448 (32448): mcc: 0.8810, acc: 0.8192, precision: 0.9222, recall: 0.8537, f1: 0.8866, edges-ner-ontonotes_loss: 0.0369
09/16 07:37:56 AM: Update 32060: task edges-ner-ontonotes, batch 60 (32060): mcc: 0.8986, acc: 0.8456, precision: 0.9312, recall: 0.8776, f1: 0.9036, edges-ner-ontonotes_loss: 0.0312
09/16 07:38:04 AM: Update 32529: task edges-ner-ontonotes, batch 529 (32529): mcc: 0.8760, acc: 0.8127, precision: 0.9190, recall: 0.8476, f1: 0.8819, edges-ner-ontonotes_loss: 0.0392
09/16 07:38:06 AM: Update 32138: task edges-ner-ontonotes, batch 138 (32138): mcc: 0.8955, acc: 0.8397, precision: 0.9309, recall: 0.8722, f1: 0.9006, edges-ner-ontonotes_loss: 0.0332
09/16 07:38:14 AM: Update 32598: task edges-ner-ontonotes, batch 598 (32598): mcc: 0.8733, acc: 0.8089, precision: 0.9177, recall: 0.8438, f1: 0.8792, edges-ner-ontonotes_loss: 0.0405
09/16 07:38:16 AM: Update 32209: task edges-ner-ontonotes, batch 209 (32209): mcc: 0.8931, acc: 0.8360, precision: 0.9293, recall: 0.8693, f1: 0.8983, edges-ner-ontonotes_loss: 0.0327
09/16 07:38:24 AM: Update 32674: task edges-ner-ontonotes, batch 674 (32674): mcc: 0.8694, acc: 0.8039, precision: 0.9151, recall: 0.8392, f1: 0.8755, edges-ner-ontonotes_loss: 0.0419
09/16 07:38:26 AM: Update 32290: task edges-ner-ontonotes, batch 290 (32290): mcc: 0.8915, acc: 0.8336, precision: 0.9286, recall: 0.8670, f1: 0.8967, edges-ner-ontonotes_loss: 0.0331
09/16 07:38:34 AM: Update 32742: task edges-ner-ontonotes, batch 742 (32742): mcc: 0.8671, acc: 0.8006, precision: 0.9133, recall: 0.8366, f1: 0.8733, edges-ner-ontonotes_loss: 0.0425
09/16 07:38:38 AM: Update 32369: task edges-ner-ontonotes, batch 369 (32369): mcc: 0.8906, acc: 0.8322, precision: 0.9278, recall: 0.8661, f1: 0.8959, edges-ner-ontonotes_loss: 0.0335
09/16 07:38:45 AM: Update 32840: task edges-ner-ontonotes, batch 840 (32840): mcc: 0.8645, acc: 0.7967, precision: 0.9119, recall: 0.8331, f1: 0.8708, edges-ner-ontonotes_loss: 0.0432
09/16 07:38:49 AM: Update 32443: task edges-ner-ontonotes, batch 443 (32443): mcc: 0.8815, acc: 0.8200, precision: 0.9225, recall: 0.8544, f1: 0.8871, edges-ner-ontonotes_loss: 0.0368
